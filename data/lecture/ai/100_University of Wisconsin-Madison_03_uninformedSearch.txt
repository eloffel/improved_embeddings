uninformed search

chapter 3.1     3.4

1

many ai (and non-ai) tasks can be 
formulated as search problems

goal is to find a sequence of actions

l puzzles
l games
l navigation
l assignment
l motion planning
l scheduling
l routing

models to be studied in cs 540

state-based models

    model task as a graph of all possible states

l called a    state-space graph   

    a state captures all the relevant information about 

the past in order to act (optimally) in the future

    actions correspond to transitions from one state to 

another

    solutions are defined as a sequence of 
steps/actions (i.e., a path in the graph)

search example:  route finding

actions: go straight, turn left, turn right
goal: shortest? fastest? most scenic?

1

search example:  river crossing problem

search example:  8-puzzle

rules:

1) farmer must row the boat
2) only room for one other
3) without the farmer present:

    dog bites sheep
    sheep eats cabbage

goal: all on 
right side of river 

actions: f>, f<, 
fc>, fc<, fd>, 
fd<, fs>, fs<

actions: move tiles (e.g., move2down)
goal: reach a certain configuration

search example:  water jugs problem

search example:  robot motion planning

given 4-liter and 3-liter pitchers, how do you get 

exactly 2 liters into the 4-liter pitcher?

4

3

actions: translate and rotate 
joints

goal: fastest? most energy 
efficient? safest?

2

search example:  8-queens

search example:  natural language 
translation

italian    english:  

la casa blu    the blue house

actions: translate single words (e.g., la     the)

goal: fluent english? preserves meaning?

search example:
remove 5 sticks problem

basic search task assumptions 

(usually, though not games)

remove exactly 5 
of the 17 sticks so 
the resulting figure 
forms exactly 3 
squares

l fully observable
l deterministic
l static
l discrete
l single agent

l solution is a sequence of actions

3

what knowledge does the agent 
need?

l the information needs to be

    sufficient to describe all relevant aspects for 

reaching the goal

    adequate to describe the world state / situation

l fully observable assumption, also known as the 

closed world assumption, means
    all necessary information about a problem domain

is accessible so that each state is a complete 
description of the world; there is no missing 
information at any point in time

what goal does the agent want to 
achieve?

l how do you describe the goal?
    as a task to be accomplished
    as a state to be reached
    as a set of properties to be satisfied

l how do you know when the goal is reached?

    with a goal test that defines what it means

to have achieved/satisfied the goal

    or, with a set of goal states

l determining the goal is usually left to the system 

designer or user to specify

14

16

how should the environment be 
represented?

l id99 problem:

    what information from the sensors is relevant?
    how to represent domain knowledge?

l determining what to represent is difficult and is 

usually left to the system designer to specify
l problem state = representation of all necessary 

information about the environment

l state space (aka problem space) = all possible valid 

configurations of the environment

15

17

what actions does the agent need?

l discrete and deterministic task assumptions imply

l given:

    an action (aka operator or move)
    a description of the current state of the world

l action completely specifies:

    if that action can be applied (i.e., legal)
    what the exact state of the world will be after the 

action is performed in the current state (no "history" 
information needed to compute the successor state)

4

what actions does the agent need?

search example:  8-puzzle

l a finite set of actions/operators needs to be

    decomposed into atomic steps that are discrete and 

indivisible, and therefore can be treated as 
instantaneous

    sufficient to describe all necessary changes

l the number of actions needed depends on how the 

world states are represented

l states = configurations
l actions = up to 4 kinds of moves: up, down, left, 

right

18

water jugs problem
given 4-liter and 3-liter pitchers, how do you get exactly 2 

liters into the 4-liter pitcher?

action / successor functions

1. (x, y | x < 4)   
2. (x, y | y < 3) 
3. (x, y | x > 0)
4. (x, y | y > 0)  
5. (x, y | x+y     4 and y > 0)   

(4, y) 
(x, 3)
(0, y)
(x, 0) 

   fill  4   
   fill  3   
   empty 4   
   empty 3   

(4, y - (4 - x))  

4

3

state: (x, y) for # liters in 4-liter and 3-liter pitchers, respectively
actions: empty, fill, pour water between pitchers
initial state: (0, 0)
goal state:   (2, *)

   pour from 3 to 4 until 4 is full   

6. (x, y | x+y     3 and x > 0)  

(x - (3 - y), 3)  

   pour from 4 to 3 until 3 is full   

7. (x, y | x+y     4 and y > 0)   

(x+y, 0)         

   pour all water from 3 to 4   

5

formalizing search in a state space

formalizing search in a state space

l a state space is a directed graph: (v, e)

    v is a set of nodes (vertices)
    e is a set of arcs (edges)

each arc is directed from one node to another node

l each node is a data structure that contains:

    a state description
    other information such as:

l link to parent node
l name of action that generated this node (from its 

parent) 

l other bookkeeping data

l each arc corresponds to one of the finite number of 

actions:
    when the action is applied to the state associated 

    then the resulting state is the state associated with 

with the arc's source node

the arc's destination node

l each arc has a fixed, positive cost:

    corresponds to the cost of the action

23

formalizing search in a state space

formalizing search in a state space

l each node has a finite set of successor nodes:

    corresponds to all of the legal actions

that can be applied at the source node's state

l expanding a node means:

    generate all of the successor nodes
    add them and their associated arcs to the state-

space search tree

l one or more nodes are designated as start nodes
l a goal test is applied to a node's state to determine 

if it is a goal node

l a solution is a sequence of actions associated with 
a path in the state space from a start to a goal node:
    just the goal state (e.g., cryptarithmetic) 
    a path from start to goal state (e.g., 8-puzzle)

l the cost of a solution is the sum of the arc costs

on the solution path

25

6

22

24

search summary

    solution is an ordered sequence of 

primitive actions (steps)

f(x) = a1, a2,    , an  where x is the input

    model task as a graph of all possible states 

and actions, and a solution as a path

    a state captures all the relevant information 

about the past

what are the components of 
formalizing search in a state space?

sizes of state spaces*

problem

# nodes

103
l tic-tac-toe
1020
l checkers
l chess
1050
l go                          10170

* approximate number of legal states

f              c             d                 s 

formalizing search
a search problem has five components:

s, i, g, actions, cost

1. state space s : all valid configurations

2. initial states i   	s: a set of start states
3. goal states g     s: a set of goal states
4. an action function successors(s)     s: states 

i = {(fcds,)}    	s
g = {(,fcds)}   	s

?

reachable in one step (one arc) from s
successors((fcds,)) = {(cd,fs)}
successors((cdf,s)) = {(cd,fs), (d,fcs), (c,fsd)}

5. a cost function cost(s, s    ):  the cost of moving from 

s to s   

l the goal of search is to find a solution path from a 

state in i to a state in g

7

state space = a directed graph

f              c             d                 s 

d, cfs

dfs, c

csdf,

cd,sf

cdf, s

s, cfd

sf, cd

, csdf

start

c, dsf

csf, d

goal

l in general, there will be many generated, but un-

expanded, states at any given time during a search

l one has to choose which one to    expand    next

formalizing search in a state space
state-space search is the process of searching through 
a state space for a solution by making explicit a 
sufficient portion of an implicit state-space graph, in 
the form of a search tree, to include a goal node:    
tree  search algorithm:

frontier = {s}, where s is the start node
loop do

if frontier is empty then return failure
pick a node, n, from frontier
if n is a goal node then return solution
generate all n   s successor nodes and add     

them all to frontier
remove n from frontier

called 
   expanding    
node n

33

different search strategies
l the generated, but not yet expanded, states 
define the frontier (aka open or fringe) set

l the essential difference is, which state in the 

frontier to expand next?

d, cfs

dfs, c

csdf,

cd,sf

cdf, s

s, cfd

sf, cd

, csdf

start

c, dsf

csf, d

goal

formalizing search in a state space

l this algorithm does not detect goal when 

node is generated

l this algorithm does not detect loops (i.e., 

    a partial solution path from the start node to the 

repeated states) in state space
l each node implicitly represents

given node 

    cost of the partial solution path

l from this node there may be

    many possible paths that have this partial path 

as a prefix

    many possible solutions

34

8

a state space graph

uninformed search on trees

a

d

b

start

p

q

c

t

e

h

u

goal

f

r

v

what is the corresponding search tree?

key issues of
state-space search algorithm

l search process constructs a "search tree"

    root is the start state
    leaf nodes are:

l unexpanded nodes (in the frontier list)
l "dead ends" (nodes that aren't goals and have no 
successors because no operators were applicable)

l goal node is last leaf node found

l uninformed means we only know:

    the goal test
    the successors() function

l but not which non-goal states are better

l for now, also assume state space is a tree

    that is, we won   t worry about repeated states
    we will relax this later

8-puzzle state-space search tree

(not all nodes shown;  
e.g., no    backwards    

moves)

l loops in graph may cause "search tree" to be infinite 

even if state space is small

l changing the frontier ordering leads to different 

search strategies

43

9

uninformed search strategies

uninformed search:  strategies that order nodes 

without using any domain specific information, i.e., 
don   t use any information stored in a state

l bfs: breadth-first search

    queue (fifo) used for the frontier
    remove from front, add to back

l dfs: depth-first search

    stack (lifo) used for the frontier
    remove from front, add to front

breadth-first search (bfs) 
expand the shallowest node first:
1. examine states one step away from the initial states
2. examine states two steps away from the initial states
3. and so on

goal

breadth-first search (bfs)

breadth-first search (bfs)

generalsearch(problem, queue)
# of nodes tested: 0, expanded: 0
expnd. node frontier list

{s}

9
d

7
h

s
start
2
b

6
g
goal

4

1

c

2
f

5
a

4
e

6

generalsearch(problem, queue)
# of nodes tested: 1, expanded: 1
expnd. node frontier list

{s}
{a,b,c}

s not goal

48

9
d

7
h

s
start
2
b

6
g
goal

4

1

c

2
f

5
a

4
e

6

10

45

47

breadth-first search (bfs)

breadth-first search (bfs)

generalsearch(problem, queue)
# of nodes tested: 2, expanded: 2
expnd. node frontier list

s
a not goal

{s}
{a,b,c}
{b,c,d,e}

9
d

7
h

5
a

4
e

breadth-first search (bfs)

generalsearch(problem, queue)
# of nodes tested: 4, expanded: 4
expnd. node frontier list

s
a
b
c not goal

{s}
{a,b,c}
{b,c,d,e}
{c,d,e,g}
{d,e,g,f}

5
a

4
e

9
d

7
h

s
start
2
b

6
g
goal

4

1

c

2
f

s
start
2
b

6
g
goal

4

1

c

2
f

6

6

50

52

49

51

generalsearch(problem, queue)
# of nodes tested: 3, expanded: 3
expnd. node frontier list

s
a
b not goal

{s}
{a,b,c}
{b,c,d,e}
{c,d,e,g}

breadth-first search (bfs)

generalsearch(problem, queue)
# of nodes tested: 5, expanded: 5
expnd. node frontier list

s
a
b
c
d not goal

{s}
{a,b,c}
{b,c,d,e}
{c,d,e,g}
{d,e,g,f}
{e,g,f,h}

9
d

7
h

9
d

7
h

5
a

4
e

5
a

4
e

s
start
2
b

6
g
goal

4

1

c

2
f

s
start
2
b

6
g
goal

4

1

c

2
f

6

6

11

breadth-first search (bfs)

breadth-first search (bfs)

generalsearch(problem, queue)
# of nodes tested: 6, expanded: 6
expnd. node frontier list

s
a
b
c
d
e not goal

{s}
{a,b,c}
{b,c,d,e}
{c,d,e,g}
{d,e,g,f}
{e,g,f,h}
{g,f,h,g}

s
start
2
b

6
g
goal

4

1

c

2
f

s
start
2
b

6
g
goal

4

1

c

2
f

6

6

5
a

4
e

5
a

4
e

path: s,b,g
cost: 8

9
d

7
h

9
d

7
h

53

55

breadth-first search (bfs)

generalsearch(problem, queue)
# of nodes tested: 7, expanded: 6
expnd. node frontier list

s
a
b
c
d
e
g

{s}
{a,b,c}
{b,c,d,e}
{c,d,e,g}
{d,e,g,f}
{e,g,f,h}
{g,f,h,g}
{f,h,g}

generalsearch(problem, queue)
# of nodes tested: 7, expanded: 6
expnd. node frontier list

s
a
b
c
d
e
g goal

{s}
{a,b,c}
{b,c,d,e}
{c,d,e,g}
{d,e,g,f}
{e,g,f,h}
{g,f,h,g}
{f,h,g} no expand

9
d

7
h

s
start
2
b

6
g
goal

4

1

c

2
f

5
a

4
e

6

evaluating search strategies

l completeness

if a solution exists, will it be found?
    a complete algorithm will find a solution (not all)

l optimality / admissibility

if a solution is found, is it guaranteed to be optimal?
    an admissible algorithm will find a solution with 

minimum cost

12

54

57

evaluating search strategies

l time complexity

how long does it take to find a solution?
    usually measured for worst case
    measured by counting number of nodes expanded

l space complexity

how much space is used by the algorithm?
    measured in terms of the maximum size

of the frontier during the search

what   s in the frontier for bfs?

l if goal is at depth d, how big is the frontier (worst 

case)?

goal

breadth-first search (bfs)

breadth-first search (bfs)

l complete

l optimal / admissible

    yes, if all operators (i.e., arcs) have the same 

constant cost, or costs are positive, non-decreasing 
with depth

    otherwise, not optimal but does guarantee finding 

solution of shortest length (i.e., fewest arcs)

l time and space complexity: o(bd) (i.e., exponential)

    d is the depth of the solution
    b is the branching factor at each non-leaf node

l very slow to find solutions with a large number of steps 
because must look at all shorter length possibilities first

61

13

58

60

breadth-first search (bfs)

problem:  given state space

l a complete search tree has a total # of nodes =

1 + b + b2 + ... + bd = (b(d+1) - 1) / (b-1)
    d: the tree's depth
    b: the branching factor at each non-leaf node

l for example: d = 12, b = 10

1 + 10 + 100 + ... + 1012 =  (1013 - 1)/9 = o(1012)
    if bfs expands 1,000 nodes/sec and each node 
uses 100 bytes of storage, then bfs will take 35 
years to run in the worst case, and it will use 111 
terabytes of memory!

62

l assume child nodes visited in increasing 

alphabetical order

l bfs = ?

depth-first search
expand the deepest node first
1. select a direction, go deep to the end
2. slightly change the end
3. slightly change the end some more   
use a stack to order nodes on the frontier

goal

14

depth-first search (dfs)

depth-first search (dfs)

generalsearch(problem, stack)
# of nodes tested: 0, expanded: 0
expnd. node frontier

{s}

9
d

7
h

5
a

4
e

depth-first search (dfs)

generalsearch(problem, stack)
# of nodes tested: 2, expanded: 2
expnd. node frontier

s
a not goal

{s}
{a,b,c}
{d,e,b,c}

9
d

7
h

5
a

4
e

67

69

s
start
2
b

6
g
goal

4

1

c

2
f

s
start
2
b

6
g
goal

4

1

c

2
f

6

6

68

70

generalsearch(problem, stack)
# of nodes tested: 1, expanded: 1
expnd. node frontier

s not goal

{s}
{a,b,c}

9
d

7
h

5
a

4
e

depth-first search (dfs)

generalsearch(problem, stack)
# of nodes tested: 3, expanded: 3
expnd. node frontier

s
a
d not goal

{s}
{a,b,c}
{d,e,b,c}
{h,e,b,c}

9
d

7
h

5
a

4
e

s
start
2
b

6
g
goal

4

1

c

2
f

s
start
2
b

6
g
goal

4

1

c

2
f

6

6

15

depth-first search (dfs)

depth-first search (dfs)

generalsearch(problem, stack)
# of nodes tested: 4, expanded: 4
expnd. node frontier

s
a
d
h not goal

{s}
{a,b,c}
{d,e,b,c}
{h,e,b,c}
{e,b,c}

generalsearch(problem, stack)
# of nodes tested: 5, expanded: 5
expnd. node frontier

s
a
d
h
e not goal

{s}
{a,b,c}
{d,e,b,c}
{h,e,b,c}
{e,b,c}
{g,b,c}

5
a

4
e

5
a

4
e

s
start
2
b

6
g
goal

4

1

c

2
f

s
start
2
b

6
g
goal

4

1

c

2
f

6

6

72

74

9
d

7
h

9
d

7
h

depth-first search (dfs)

depth-first search (dfs)

generalsearch(problem, stack)
# of nodes tested: 6, expanded: 5
expnd. node frontier

s
a
d
h
e
g goal

{s}
{a,b,c}
{d,e,b,c}
{h,e,b,c}
{e,b,c}
{g,b,c}
{b,c} no expand

generalsearch(problem, stack)
# of nodes tested: 6, expanded: 5
expnd. node frontier

s
a
d
h
e
g

{s}
{a,b,c}
{d,e,b,c}
{h,e,b,c}
{e,b,c}
{g,b,c}
{b,c}

9
d

7
h

9
d

7
h

5
a

4
e

5
a

4
e

s
start
2
b

6
g
goal

4

1

c

2
f

s
start
2
b

6
g
goal

4

1

c

2
f

6

6

path: s,a,e,g
cost: 15

16

71

73

problem:  given state space

l assume child nodes visited in increasing 

alphabetical order

l do cycle checking:  don   t add node to frontier if 

its state already occurs on path back to root

l dfs = ?

depth-first search (dfs)

depth-first search (dfs)

l may not terminate without a depth bound

i.e., cutting off search below a fixed depth, d

l not complete

    with or without cycle detection
    and, with or without a depth cutoff

l not optimal / admissible

l can find long solutions quickly if lucky

77

78

l time complexity: o(bd) exponential

space complexity: o(bd) linear
    d is the depth of the solution
    b is the branching factor at each non-leaf node

l performs    chronological backtracking   

    i.e., when search hits a dead end, backs up one

level at a time

    problematic if the mistake occurs because of a bad 

action choice near the top of search tree

17

uniform-cost search (ucs)

uniform-cost search (ucs)

l use a    priority queue    to order nodes on the 

frontier list, sorted by path cost

l let g(n) = cost of path from start node s to current 

node n

l sort nodes by increasing value of g

79

81

uniform-cost search (ucs)

generalsearch(problem, priorityqueue)
# of nodes tested: 1, expanded: 1
expnd. node frontier list

s not goal

{s:0}
{b:2,c:4,a:5}

5
a

4
e

6

9
d

7
h

80

82

s
start
2
b

6
g
goal

4

1

c

2
f

generalsearch(problem, priorityqueue)
# of nodes tested: 0, expanded: 0
expnd. node frontier list

{s}

4
e

6

9
d

7
h

uniform-cost search (ucs)

generalsearch(problem, priorityqueue)
# of nodes tested: 2, expanded: 2
expnd. node frontier list

s
b not goal

{s}
{b:2,c:4,a:5}
{c:4,a:5,g:2+6}

5
a

5
a

4
e

6

9
d

7
h

s
start
2
b

6
g
goal

4

1

c

2
f

s
start
2
b

6
g
goal

4

1

c

2
f

18

uniform-cost search (ucs)

uniform-cost search (ucs)

generalsearch(problem, priorityqueue)
# of nodes tested: 3, expanded: 3
expnd. node frontier list

s
b
c not goal

{s}
{b:2,c:4,a:5}
{c:4,a:5,g:8}
{a:5,f:4+2,g:8}

4
e

6

9
d

7
h

generalsearch(problem, priorityqueue)
# of nodes tested: 4, expanded: 4
expnd. node frontier list

s
b
c
a not goal

{s}
{b:2,c:4,a:5}
{c:4,a:5,g:8}
{a:5,f:6,g:8}
{f:6,g:8,e:5+4,
d:5+9}

4
e

6

9
d

7
h

uniform-cost search (ucs)

uniform-cost search (ucs)

generalsearch(problem, priorityqueue)
# of nodes tested: 5, expanded: 5
expnd. node frontier list

s
b
c
a
f not goal

{s}
{b:2,c:4,a:5}
{c:4,a:5,g:8}
{a:5,f:6,g:8}
{f:6,g:8,e:9,d:14}
{g:4+2+1,g:8,e:9,
d:14}

4
e

6

9
d

7
h

generalsearch(problem, priorityqueue)
# of nodes tested: 6, expanded: 5
expnd. node frontier list

s
b
c
a
f
g goal

{s}
{b:2,c:4,a:5}
{c:4,a:5,g:8}
{a:5,f:6,g:8}
{f:6,g:8,e:9,d:14}
{g:7,g:8,e:9,d:14}
{g:8,e:9,d:14}
no expand

4
e

6

9
d

7
h

5
a

5
a

s
start
2
b

6
g
goal

4

1

c

2
f

s
start
2
b

6
g
goal

4

1

c

2
f

84

86

5
a

5
a

s
start
2
b

6
g
goal

4

1

c

2
f

s
start
2
b

6
g
goal

4

1

c

2
f

19

83

85

uniform-cost search (ucs)

problem:  given state space

generalsearch(problem, priorityqueue)
# of nodes tested: 6, expanded: 5
expnd. node frontier list

{s}
{b:2,c:4,a:5}
{c:4,a:5,g:8}
{a:5,f:6,g:8}
{f:6,g:8,e:9,d:14}
{g:7,g:8,e:9,d:14}
{g:8,e:9,d:14}

s
start
2
b

6
g
goal

4

1

c

2
f

5
a

4
e

6

path: s,c,f,g
cost: 7

9
d

7
h

s
b
c
a
f
g

87

l assume child nodes visited in increasing 

alphabetical order

l ucs = ?

uniform-cost search (ucs)

l called dijkstra's algorithm in the algorithms 

literature

l similar to branch and bound algorithm

in operations research literature

l complete
l optimal / admissible

    requires that the goal test is done when a node is 
removed from the frontier rather than when the 
node is generated by its parent node

90

20

uniform-cost search (ucs)

iterative-deepening search (ids)

l time and space complexity: o(bd)  (i.e., exponential)

    d is the depth of the solution
    b is the branching factor at each non-leaf node

l more precisely, time and space complexity is

o(bc*/   ) where all edge costs (cid:0) (cid:0) > 0, and c* is the 
best goal path cost

91

94

iterative-deepening search (ids)

deepeningsearch(problem)
depth: 1, # of nodes expanded: 0, tested: 0
expnd. node frontier

{s}

9
d

7
h

s
start
2
b

6
g
goal

4

1

c

2
f

5
a

4
e

6

92

95

l requires modification to dfs search algorithm:

    do dfs to depth 1

and treat all children of the start node as leaves

    if no solution found, do dfs to depth 2
    repeat by increasing    depth bound    until a solution 

found

l start node is at depth 0

iterative-deepening search (ids)

deepeningsearch(problem)
depth: 1, # of nodes tested: 1, expanded: 1
expnd. node frontier

s not goal

{s}
{a,b,c}

9
d

7
h

s
start
2
b

6
g
goal

4

1

c

2
f

5
a

4
e

6

21

iterative-deepening search (ids)

iterative-deepening search (ids)

deepeningsearch(problem)
depth: 1, # of nodes tested: 2, expanded: 1
expnd. node frontier

s
a not goal

{s}
{a,b,c}
{b,c} no expand

9
d

7
h

s
start
2
b

6
g
goal

4

1

c

2
f

5
a

4
e

6

iterative-deepening search (ids)

deepeningsearch(problem)
depth: 1, # of nodes tested: 4, expanded: 1
expnd. node frontier

s
a
b
c not goal

{s}
{a,b,c}
{b,c}
{c}
{ } no expand-fail

9
d

7
h

s
start
2
b

6
g
goal

4

1

c

2
f

5
a

4
e

6

96

98

97

99

deepeningsearch(problem)
depth: 1, # of nodes tested: 3, expanded: 1
expnd. node frontier

s
a
b not goal

{s}
{a,b,c}
{b,c}
{c} no expand

9
d

7
h

s
start
2
b

6
g
goal

4

1

c

2
f

5
a

4
e

6

iterative-deepening search (ids)

deepeningsearch(problem)
depth: 2, # of nodes tested: 4(1), expanded: 2
expnd. node frontier

s
a
b
c
s no test

{s}
{a,b,c}
{b,c}
{c}
{ }
{a,b,c}

9
d

7
h

s
start
2
b

6
g
goal

4

1

c

2
f

5
a

4
e

6

22

iterative-deepening search (ids)

iterative-deepening search (ids)

deepeningsearch(problem)
depth: 2, # of nodes tested: 4(2), expanded: 3
expnd. node frontier

s
a
b
c
s
a no test

{s}
{a,b,c}
{b,c}
{c}
{ }
{a,b,c}
{d,e,b,c}

s
start
2
b

6
g
goal

4

1

c

2
f

5
a

4
e

6

deepeningsearch(problem)
depth: 2, # of nodes tested: 5(2), expanded: 3
expnd. node frontier

s
a
b
c
s
a
d not goal

{s}
{a,b,c}
{b,c}
{c}
{ }
{a,b,c}
{d,e,b,c}
{e,b,c} no expand

s
start
2
b

6
g
goal

4

1

c

2
f

5
a

4
e

6

9
d

7
h

9
d

7
h

10
0

10
2

iterative-deepening search (ids)

iterative-deepening search (ids)

deepeningsearch(problem)
depth: 2, # of nodes tested: 6(2), expanded: 3
expnd. node frontier

s
a
b
c
s
a
d
e not goal

{s}
{a,b,c}
{b,c}
{c}
{ }
{a,b,c}
{d,e,b,c}
{e,b,c}
{b,c} no expand

s
start
2
b

6
g
goal

4

1

c

2
f

5
a

4
e

6

deepeningsearch(problem)
depth: 2, # of nodes tested: 6(3), expanded: 4
expnd. node frontier

s
a
b
c
s
a
d
e
b no test

{s}
{a,b,c}
{b,c}
{c}
{ }
{a,b,c}
{d,e,b,c}
{e,b,c}
{b,c}
{g,c}

s
start
2
b

6
g
goal

4

1

c

2
f

5
a

4
e

6

23

10
1

10
3

9
d

7
h

9
d

7
h

iterative-deepening search (ids)

iterative-deepening search (ids)

deepeningsearch(problem)
depth: 2, # of nodes tested: 7(3), expanded: 4
expnd. node frontier

s
a
b
c
s
a
d
e
b
g goal

{s}
{a,b,c}
{b,c}
{c}
{ }
{a,b,c}
{d,e,b,c}
{e,b,c}
{b,c}
{g,c}
{c} no expand

9
d

7
h

s
start
2
b

6
g
goal

4

1

c

2
f

5
a

4
e

6

iterative-deepening search (ids)

l has advantages of bfs

    completeness
    optimality as stated for bfs

l has advantages of dfs

    limited space
    in practice, even with redundant effort it still finds 

longer paths more quickly than bfs

10
4

10
6

10
5

10
7

deepeningsearch(problem)
depth: 2, # of nodes tested: 7(3), expanded: 4
expnd. node frontier

s
a
b
c
s
a
d
e
b
g

{s}
{a,b,c}
{b,c}
{c}
{ }
{a,b,c}
{d,e,b,c}
{e,b,c}
{b,c}
{g,c}
{c}

s
start
2
b

6
g
goal

4

1

c

2
f

5
a

4
e

6

path: s,b,g
cost: 8

9
d

7
h

iterative-deepening search (ids)

l space complexity: o(bd) (i.e., linear like dfs)

l time complexity is a little worse than bfs or dfs

    because nodes near the top of the search tree
are generated multiple times (redundant effort)

l worst case time complexity: o(bd) exponential
    because most nodes are near the bottom of tree

24

iterative-deepening search (ids)

how much redundant effort is done?
l the number of times the nodes are generated:

1bd + 2b(d-1) + ... + db     bd / (1     1/b)2 = o(bd)
    d: the solution's depth
    b: the branching factor at each non-leaf node

l for example: b = 4

4d / (1       )2 =  4d / (.75)2 = 1.78    4d
    in the worst case, 78% more nodes are
    as b increases, this % decreases

searched (redundant effort) than exist at depth d

10
8

bidirectional search
l breadth-first search from both start and goal
l stop when frontiers meet
l generates o(bd/2) instead of o(bd) nodes

start

goal

iterative-deepening search
l trades a little time for a huge reduction in space
    lets you do breadth-first search with (more space 

efficient) depth-first search

l    anytime    algorithm: good for response-time 

critical applications, e.g., games

l an    anytime    algorithm is an algorithm that can return a 
valid solution to a problem even if it's interrupted at any 
time before it ends. the algorithm is expected to find 
better and better solutions the longer it runs.

which direction should we search?

our choices:  forward, backwards, or bidirectional
the issues:  how many start and goal states are there?

branching factors in each direction
how much work is it to compare states?

11
1

25

performance of search algorithms on trees

b: branching factor (assume finite)
optimal

complete

breadth-first 
search
uniform-cost 
search2
depth-first 
search
iterative 
deepening
bidirectional 
search3

y

y

n

y

y

y, if 1

y

n

y, if 1

y, if 1

d: goal depth m: graph depth

time

o(bd) 

space

o(bd) 

o(bc*/  )

o(bc*/  ) 

o(bm)

o(bd) 

o(bm)

o(bd) 

o(bd/2) 

o(bd/2) 

1. edge cost constant, or positive non-decreasing in depth
2. edge costs (cid:0) (cid:0) > 0.  c* is the best goal path cost
3. both directions bfs; not always feasible

if state space is not a tree
l we have to remember already-expanded states 

(called explored (aka closed) set) too

l why?

l when we pick a node from frontier

    remove it from frontier
    add it to explored
    expand node, generating all successors
    for each successor, child, 

l if child is in explored or in frontier, throw child

away

l otherwise, add it to frontier

l called graph-search algorithm in figure 3.7

if state space is not a tree

l the problem: repeated states

d, cfs

dfs, c

csdf,

cd,sf

cdf, s

s, cfd

sf, cd

, csdf

c, dsf

csf, d

l ignoring repeated states: wasteful (bfs) or 

impossible (dfs).  why?

l how to prevent these problems?  

example

s

1            5      8

a

b

c

3          7      9       4        5

d

e

g

how are nodes expanded by

    depth first search
    breadth first search
    uniform cost search
   
iterative deepening

are the solutions the same?

26

nodes expanded by:

l depth-first search: s a d e g

solution found: s a g

l breadth-first search: s a b c d e g

solution found: s a g

l uniform-cost search: s a d b c e g

solution found: s b g 

l iterative-deepening search: s a b c s a d e g

solution found: s a g 

27

