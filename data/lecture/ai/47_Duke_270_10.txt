id48

george konidaris	
gdk@cs.duke.edu

spring 2016

recall: id110

flu

allergy

sinus

nose

headache

recall: bn

flu

flu
true
false

p
0.6
0.4

sinus

sinus
true
false
true
false
true
false
true
false

flu allergy p
true
0.9
0.1
true
true
0.6
0.4
true
false
0.2
0.8
false
0.4
false
false
0.6

true
true
false
false
false
false
true
true

allergy

allergy p
0.2
0.8

true
false

headache

headache

true
false
true
false

sinus p
0.6
true
true
0.4
0.5
false
false
0.5

nose

nose
true
false
true
false

sinus p
true
0.8
0.2
true
false
0.3
0.7
false

joint: 32 (31) entries

id136
given a compute p(b | a).

flu

allergy

sinus

nose

headache

time
id110s (so far) contain no notion of time.	
!
!
however, in many applications:	

    target tracking	
    patient monitoring	
    id103	
    gesture recognition	

!
     how a signal changes over time is critical.

states
in id203 theory, we talked about atomic events:	

    all possible outcomes.	
    mutually exclusive.	

!
!
!
!
in time series, we have state:	

    system is in a state at time t.	
    describes system completely.	
    over time, transition from state to state.

example
the weather today can be:	

    hot	
    cold	
    chilly	
    freezing	

!
the weather has four states.	
!
at each point in time, the system is in one (and only one) state.

p (st|st 1, st 2, ..., s0)

the markov assumption
we are probabilistic modelers, so we   d like to model:	
!
!
!
!
a state has the markov property when we can write this as:	
!
!
!
!
special kind of independence assumption:	
    future independent of past given present.

p (st|st 1)

markov assumption
model that has it is a markov model.	
!
sequence of states thus generated is a markov chain.	
!
can describe transition probabilities with matrix:	

    p(si | sj)	
    steady state probabilities.	
    convergence rates.

state machines

s0

0.4

0.6

0.8

0.2

0.5

s2

s1

0.5

time implicit

p(s0 | s1) = 0.8	
p(s0 | s2) = 0.5	
p(s1 | s0) = 0.4 	
p(s1 | s2) = 0.5	
p(s2 | s0) = 0.6	
p(s2 | s1) = 0.2	

states not	
state vars!

state machines
assumptions:	

    markov assumption.	
    transition probabilities don   t change with time.	
    event space doesn   t change with time.	
    time moves in discrete increments.	

hidden state
state machines are cool but:	

    often state is not observed directly.	
    state is latent, or hidden.	

!
!
!
!
!
!
!
instead you see an observation, which contains information 
about the hidden state.

state: 	
forehand

examples
               state                                         observation	
!
             word                                             phoneme	
!
!
          chemical state                               color, smell etc.     	
!
!
               flu?                                               runny nose	
!
             cardiac arrest?                                  pulse

id48

st

ot

st+1

ot+1

must store:	
    p(o | s)	
    p(st+1 | st)

id48s
monitoring/filtering 

    p(st | e0     et)	
    e.g., estimate patient disease state.	

!
prediction 

    p(st | e0     ek), k < t.	
    given    rst two phonemes, what word?	

!
smoothing 

    p(st | e0     ek), k > t	
    what happened back there?	

!
most likely state sequence. (a path, not a distribution)

example: robot localization

observations:	
walls each side?	

states:	
position	

example: robot localization

we start off not knowing where the robot is.	

example: robot localization

robot sense: obstacles up and down.	

updates distribution.	

example: robot localization

robot moves right: updates distribution.	

example: robot localization

obstacles up and down, updates distribution.	

what happened
this is an instance of robot tracking.	
!
could also:	

    predict (where will the robot be in 3 steps?)	
    smooth (where was the robot?)	
    most likely path (what was the robot   s path?)	

!
!
!

all of these are questions about the id48   s state at 
various times.

most likely path

st

ot

st+1

ot+1

how to compute? (assume we have cpts)

most likely state
(assume all start states equally likely)	
!
consider a path of length 1.	

    p(s0) = p(s0 | o0). 	
    we can just write this down.	

!
now, what about a path of length 2?	
    p(s1)  = p(s0) p(s1 | s0) p(s1 | 01)	
   

         = p(s0 | o0) p(s1 | s0) p(s1 | 01)

see the recursion?

viterbi algortihm
most likely path s0     sn:	
!
for each state sk:	
    v0,k = p(o0 | sk)	
!
for i = 1   n, 	
   for each k: 	
	    v i,k = maxx p(oi | sk) p(sk | sx) vi-1,x	
!
recursive, but values repeat, so save them (dynamic 
programming).

	

viterbi
   the algorithm has found universal application in decoding the 
convolutional codes used in both cdma and gsm digital 
cellular, dial-up modems, satellite, deep-space communications, 
and 802.11 wireless lans.    (wikipedia)

(photo credit: mit)

