adversarial search

george konidaris	
gdk@cs.duke.edu

spring 2016

games

   chess is the drosophila of arti   cial intelligence   	

kronrod, c. 1966 

turochamp, 1948

why study games?
of interest:	
    many human activities (especially intellectual ones) can be 

modeled as games.	

    prestige.	
!
convenient:	
    perfect information.	
    concise, precise rules.	
    well de   ned    score   .	

   solved    games
a game is solved if an optimal strategy is known.	
!
strong solved: all positions.	
weakly solved: some (start) positions.	
!

typical game setting
games are usually:	

    2 player	
    alternating	
    zero-sum	

    gain for one loss for another.	

    perfect information	

!

very much like search:	
    start state	
    successor function	
    terminal states (many)	
    objective function	
but alternating control.

game trees

o

o

player 1 moves

   

o

o

x

o

x

o

   

o

o

o

x

player 2 moves

x

o
x

player 1 moves

   

o

o

x

key differences vs. search

you select to 	
max score

p1

p2

p2

   

p2

p1

p1

p1

they select to 	

min score

only get score here

minimax algorithm
max player: select action to maximize return.	
min player: select action to minimize return.	
!
this is optimal for both players (if zero sum).	
assumes perfect play, worst case.	
!
can run as depth    rst:	

    time o(bd)	
    space o(bd)

minimax

5

p2

5

p1

-3

p2

max

-5

p2

10

p1

5

p1

-3

p1

min
20

p1

-5
p1

2

p1

in practice
depth is too deep. 	

    10s to 100s of moves.	

breadth is too broad. 	

    chess: 35, go: 361.	

!
full search never terminates for non-trivial games.	
!
solution: substitute evaluation function.	
    like a heuristic - estimate value.	
    perhaps run to    xed depth then estimate.

search control
    horizon effects	

    what if something interesting at horizon + 1?	
    how do you know?	

!

    when to generate more nodes?	
    how to selectively expand the frontier?	
    how to allocate    xed move time?

pruning
single most useful search control method:	

    throw away whole branches.	
    use the min-max behavior.	

!

    cutoff search at min nodes where max can force a better 

outcome.	
!

    cutoff search at max nodes when min can force a worse 

outcome.	
!

resulting algorithm: alpha-beta pruning.

alpha-beta

5

p2

p1

p2

max

p2

10

p1

5

p1

-3

p1

min
20

p1

-5
p1

2

p1

alpha-beta
empirically, has the effect of reducing the branching factor by a 
square root for many problems.	
!
effectively doubles the search horizon.	
!
alpha-beta makes the difference between novice and expert 
computer game players. most successful players use alpha-beta.

deep blue (1997)

480 special purpose chips	
200 million positions/sec	
search depth 6-8 moves (up to 20)

games today

world champion level:	
    backgammon	
    chess	
    checkers (solved)	
    othello	
    some poker types:	
   heads-up limit hold   em poker is solved   ,  bowling et al., science, january 2015.	
!
perform well:	
    bridge	
    other poker types	
!
far off: go

go

very recently

0 - 5

alphago	

(google deepmind)

fan hui	

european go 	

champion

