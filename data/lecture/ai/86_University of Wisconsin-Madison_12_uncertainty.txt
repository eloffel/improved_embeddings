representing  uncertainty

chapter 13

uncertainty

    say we have a rule:

if toothache then problem is cavity

    but not all patients have toothaches due to 

cavities, so we could set up rules like:

if toothache and   gum-disease and   filling and ...
then problem = cavity

    this gets complicated;  better method:

if toothache then problem is cavity with 0.8 id203
or   p(cavity | toothache) = 0.8
the id203 of cavity is 0.8 given toothache is observed

uncertainty in the world

    an agent can often be uncertain about the 

state of the world/domain since there is often 
ambiguity and uncertainty

    plausible/probabilistic id136

    i   ve got this evidence; what   s the chance that this 

conclusion is true?
    i   ve got a sore neck; how likely am i to have meningitis?
    a mammogram test is positive; what   s the id203 

that the patient has breast cancer? 

uncertainty

in the world and our models
    true uncertainty:  rules are probabilistic in nature

    quantum mechanics
    rolling dice, flipping a coin

    laziness:  too hard to determine exception-less rules

    takes too much work to determine all of the relevant factors
    too hard to use the enormous rules that result

    theoretical ignorance:  don't know all the rules
    problem domain has no complete, consistent theory (e.g., 

medical diagnosis)

    practical ignorance:  do know all the rules but

    haven't collected all relevant information for a particular case

1

logics

logics are characterized by what they use as 
"primitives"

logic
propositional
first-order
temporal

what exists in world
facts
facts, objects, relations
facts, objects, relations, 
times

knowledge states
true/false/unknown
true/false/unknown
true/false/unknown

id203 theory
fuzzy

facts
degree of truth

degree of belief 0..1
degree of belief 0..1

sample space

    a space of events in which we assign 

probabilities

    events can be binary, multi-valued, or 

continuous

    events are mutually exclusive
    examples

    coin flip: {head, tail}
    die roll: {1,2,3,4,5,6}
    english words: a dictionary
    high temperature tomorrow: {-100,    , 100}

id203 theory

    id203 theory serves as a formal means for

    representing and reasoning with uncertain 

knowledge

    modeling degrees of belief in a proposition (event, 

conclusion, diagnosis, etc.)

    id203 is the    language    of uncertainty

    a key modeling tool in modern ai

random variable

    a variable, x, whose domain is a sample 
space, and whose value is (somewhat) 
uncertain
    examples:

x = coin flip outcome
x = tomorrow   s high temperature 

    for a given task, the user defines a set of 
random variables for describing the world

    each variable has a set of mutually 

exclusive and exhaustive possible values

2

id203 for discrete events

    an agent   s uncertainty is represented by

p(a=a) or simply p(a)
    the agent   s degree of belief that variable a takes on 

value a given no other information related to a

    a single id203 called an unconditional or prior 

id203

source of probabilities

    frequentists

    probabilities come from data
    if 10 of 100 people tested have a cavity, p(cavity) = 0.1
    id203 means the fraction that would be observed

in the limit of infinitely many samples

    objectivists

    probabilities are real aspects of the world
    objects have a propensity to behave in certain ways
    coin has propensity to come up heads with id203 0.5

    subjectivists

    probabilities characterize an agent's belief
    have no external physical significance

3

id203 for discrete events

    examples

    p(head) = p(tail) = 0.5      fair coin
    p(head) = 0.51, p(tail) = 0.49     slightly biased 

coin

    p(first word =    the    when flipping to a random 

page in r&n) = ?

    book:  the book of odds

id203 distributions

given a is a rv taking values in (cid:1)a1,  a2,     , an(cid:1)
    p(a) represents a single id203 where a=a

e.g., if a is sky, then value is one of <clear, partly_cloudy, overcast>

e.g., if a is sky, then p(a) means any one of

p(clear), p(partly_cloudy), p(overcast)

    p(a) represents a id203 distribution

    the set of values: (cid:1)p(a1), p(a2),    , p(an)(cid:1)
    if a takes n values, then p(a) is a set of n probabilities
e.g., if a is sky, then p(sky) is the set of probabilities:
(cid:1)p(clear), p(partly_cloudy), p(overcast)(cid:1)

    property:     p(ai) = p(a1) + p(a2) + ... + p(an) = 1

    sum over all values in the domain of variable a is 1 because the 

domain is mutually exclusive and exhaustive 

the axioms of id203

1. 0     p(a)     1
2. p(true) = 1, p(false) = 0

3. p(a    b) = p(a) + p(b)     p(a    b) 

and p(a    b) means p(a=a    b=b)

note:  here p(a) means p(a=a) for some value a 

id203 table

    weather

sunny
200/365

cloudy
100/365

rainy
65/365

    p(weather = sunny) = p(sunny) = 200/365

    p(weather) = (cid:1)200/365, 100/365, 65/365(cid:2)

    we   ll obtain the probabilities by counting 

frequencies from data

the axioms of id203

   0     p(a)     1
   p(true) = 1, p(false) = 0

   p(a    b) = p(a) + p(b)     p(a    b)

the fraction of a can   t
be smaller than 0

sample
space

4

the axioms of id203

   0     p(a)     1
   p(true) = 1, p(false) = 0

   p(a    b) = p(a) + p(b)     p(a    b)

the fraction of a can   t
be bigger than 1

the axioms of id203

   0     p(a)     1
   p(true) = 1, p(false) = 0

   p(a    b) = p(a) + p(b)     p(a    b)

sample
space

valid sentence: e.g.,    x=head or x=tail   

sample
space

the axioms of id203

   0     p(a)     1
   p(true) = 1, p(false) = 0

   p(a    b) = p(a) + p(b)     p(a    b)

the axioms of id203

   0     p(a)     1
   p(true) = 1, p(false) = 0

   p(a    b) = p(a) + p(b)     p(a    b)

sample
space

invalid sentence: 
e.g.,    x=head and x=tail   

a

b

sample
space

5

some theorems

derived from the axioms

    p(  a) = 1     p(a)

    if a can take k different values a1,    , ak:

p(a=a1) +     + p(a=ak) = 1

    p(b) = p(b      a) + p(b    a), if a is a binary event
    p(b) =    i=1   kp(b    a=ai), if a can take k values

joint id203

shorthand for p(a=a     b=b), i.e., the 

    the joint id203 p(a=a, b=b) is 

id203 of both a=a and b=b happening
p(a=a), e.g., p(1st word on a random page =    san   ) = 0.001

(possibly: san francisco, san diego,    )

p(b=b), e.g., p(2nd word =    francisco   ) = 0.0008

(possibly: san francisco, don francisco, pablo francisco    )

a

called addition or conditioning rule

p(a=a,b=b), e.g., p(1st =   san   , 2nd =   francisco   ) = 0.0007

full joint id203 distribution (fjpd)

full joint id203 distribution (fjpd)

weather

sunny
150/365
50/365

cloudy
40/365
60/365

rainy
5/365
60/365

temp

hot
cold

    p(temp=hot, weather=rainy) = p(hot, rainy) = 

5/365 = 0.014

    the full joint id203 distribution table for n

random variables, each taking k values, has kn
entries

bird
t
t
t
t
f
f
f
f

flier
t
t
f
f
t
t
f
f

young

id203

t
f
t
f
t
f
t
f

0.0
0.2
0.04
0.01
0.01
0.01
0.23
0.5

3 boolean random variables     23     1 = 7    degrees 

of freedom    (dof) or    independent values   

sums to 1

6

computing from the fjpd

    marginal probabilities

    p(bird=t) = p(bird) = 0.0 + 0.2 + 0.04 + 0.01 = 0.25
    p(bird,   flier) = 0.04 + 0.01 = 0.05

    p(bird    flier) = 0.0 + 0.2 + 0.04 + 0.01 + 0.01 + 

0.01 = 0.27

    sum over all other variables
       summing out   
       marginalization   

marginal id203

weather

temp

hot
cold

sunny
150/365
50/365

rainy
5/365
60/365
              200/365     100/365      65/365

cloudy
40/365
60/365

p(weather) = (cid:1)200/365, 100/365, 65/365(cid:2)

id203 distribution for r.v. weather
the name comes from the old days when the 
sums were written in the margin of a page

unconditional / prior id203
    one   s uncertainty or original assumption  

about an event prior to having any data 
about it or anything else in the domain

    p(coin = heads) = 0.5
    p(bird = t) = 0.0 + 0.2 + 0.04 + 0.01 = 0.22
    compute from the fjpd by marginalization

weather

marginal id203

   
this is nothing but p(b) =    i=1   kp(b    a=ai), if 

p(temp) = (cid:1)195/365, 170/365(cid:2)

sunny
150/365
50/365

cloudy
40/365
60/365

rainy
5/365
60/365

hot
cold

temp

a can take k values

195/365 
170/365

7

id155

    conditional probabilities

    formalizes the process of accumulating evidence

and updating probabilities based on new evidence

    specifies the belief in a proposition (event, conclusion, 

diagnosis, etc.) that is conditioned on a proposition 
(evidence, feature, symptom, etc.) being true
    p(a | e): id155 of a=a

given e=e evidence is all that is known true
    p(a | e) = p(a     e) / p(e) =   p(a, e) / p(e)
    id155 can viewed as the joint id203 

p(a, e) normalized by the prior id203, p(e)

id155

    p(san | francisco) 

= p(san     francisco) / p(francisco)

= #(1st=s and 2nd=f) / #(2nd=f)

p(s)=0.001
p(f)=0.0008
p(s,f)=0.0007

= 0.0007 / 0.0008
= 0.875

p(b=b), e.g. p(2nd word =    francisco   ) = 0.0008

a

p(a=a | b=b), e.g. p(1st=   san    | 2nd =   francisco   ) = 0.875

(possibly: san, don, pablo    )

although    san    is rare and    francisco    is rare, 
given    francisco    then    san    is quite likely!

id155

the id155 p(a=a | b=b) is the fraction 
of time a=a, within the region where b=b

p(a=a), e.g. p(1st word on a random page =    san   ) = 0.001

p(b=b), e.g. p(2nd word =    francisco   ) = 0.0008

a

p(a=a | b=b), e.g. p(1st=   san    | 2nd =   francisco   ) = ?

(possibly: san, don, pablo    )

id155

conditional probabilities behave exactly like 
standard probabilities; for example:

0      p(a | e)       1

conditional probabilities are between 0 and 1 inclusive

p(a1 | e) + p(a2 | e) + ... + p(ak | e)  = 1

conditional probabilities sum to 1 where a1,    , ak are all 

values in the domain of random variable a
p(  a | e) = 1     p(a | e)

negation for boolean random variable a

8

computing id155

p(  b|f)

=  ?

p(f)

=  ?

note:  p(  b|f) means p(b=false | f=true)
and p(f) means p(f=true) 

computing id155

p(  b|f)

= p(  b, f)/p(f)
= (p(  b, f, y) + p(  b, f,   y))/p(f)
= (0.01 + 0.01)/p(f)

p(f)

= p(f, b, y) + p(f, b,   y) + p(f,   b, y) + 

p(f,   b,   y)

= 0.0 + 0.2 + 0.01 + 0.01
= 0.22

marginalization

full joint id203 distribution
id203
bird (b)

young (y)

flier (f)

t
t
t
t
f
f
f
f

t
t
f
f
t
t
f
f

t
f
t
f
t
f
t
f

3 boolean random variables     23     1 = 7 

   degrees of freedom    or    independent values   

0.0
0.2
0.04
0.01
0.01
0.01
0.23
0.5

sums to 1

computing id155
    instead of using marginalization to compute 

p(f), can alternatively use id172: 

    p(  b|f) = .02/p(f)        from previous slide
    p(  b|f) + p(b|f) = 1     by definition
    p(b|f) = p(b,f)/p(f) = (0.0 + 0.2)/p(f)
    so, 0.02/p(f) + 0.2/p(f) = 1
    hence, p(f) = 0.22

9

id172

    in general, p(a | b) =     p(a, b)
where     = 1/p(b) = 1/(p(a, b) + p(  a, b))
    p(q | e1,    , ek) =     p(q, e1,    , ek) 
=        y p(q, e1,    , ek, y)

addition rule

id155
    p(x1=x1,    , xk=xk | xk+1=xk+1,    , xn=xn) =

sum of all entries in fjpd where                
x1=x1,    , xn=xn divided by sum of all 
entries where xk+1=xk+1 ,    , xn=xn

    but this means in general we need the entire
fjpd table, requiring an exponential number 
of values to do probabilistic id136 (i.e., 
compute conditional probabilities)

id155 with 

multiple evidence

p(  b | f,   y) = p(  b, f,   y) / p(f,   y)

= p(  b, f,   y) / (p(  b, f,   y) + p(b, f,   y))
= .01 /(.01 + .2)
= 0.048

the chain rule

    from the definition of id155 we 

have

p(a, b) = p(b) * p(a | b) = p(a | b) * p(b)

    it also works the other way around:

p(a, b) = p(a) * p(b | a) = p(b | a) p(a)

    it works with more than 2 events too:
p(a1, a2,    , an) = 
p(a1) * p(a2 | a1) * p(a3| a1, a2) *     

* p(an | a1, a2,    , an-1)

called 
   product 

rule   

called    chain rule   

10

quiz

who are the    robots    appearing in fiction by 
mary shelley, rabbi judah loew, and marvel 
comics?  

frankenstein,  golem,  and  ultron 

probabilistic  reasoning

how do we use probabilities in ai?
    you wake up with a headache
    do you have the flu? 
    h = headache, f = flu

logical id136:  if h then f

(but the world is usually not this simple)

statistical id136:  compute the id203 of a 
query/diagnosis/decision given (i.e., conditioned 
on) evidence/symptom/observation, i.e., p(f | h)

[example from andrew moore]

example

id136 with bayes   s rule

statistical id136:  compute the id203 of a 

diagnosis, f, given symptom, h, where h =    has a 
headache    and f =    has flu   

that is, compute p(f | h)

you know that
    p(h) = 0.1
    p(f) = 0.01
    p(h | f) = 0.9

   one in ten people has a headache   
   one in 100 people has flu   
   90% of people who have flu have a 
headache   

[example from andrew moore]

thomas bayes,    essay towards solving a problem in the doctrine of 
chances,    1764
|

fpfhp
(
(

hfp
(

=

)

)

)

hfp
(
,
hp
)
(

|
)
hp
(

)

=
def of cond. prob.

   one in ten people has a headache   

    p(h) = 0.1
    p(f) = 0.01        one in 100 people has flu   
    p(h|f) = 0.9      90% of people who have flu have a headache   

product rule

    p(f|h) = (0.9 * 0.01) / 0.1 = 0.09
    so, there   s a 9% chance you have flu     much less than 90%
    but it   s higher than p(f) = 1%  since you have a headache

11

bayes   s rule

id136 with bayes   s rule

p(a|b) = p(b | a)p(a) / p(b)
    why do we make things this complicated?

bayes   s rule

    often p(b|a), p(a), p(b) are easier to get

    some terms:

    prior: p(a):  id203 of a before any evidence
    likelihood: p(b|a):  assuming a, how likely is the 

evidence b

    posterior: p(a|b):  id203 of a after knowing 

evidence b

    (deductive) id136:  deriving an unknown id203 

from known ones

bayes   s rule in practice

12

summary of important rules

    id155:  p(a|b) = p(a,b)/p(b)
    product rule:  p(a,b) = p(a|b)p(b)
    chain rule:  p(a,b,c,d) = p(a|b,c,d)p(b|c,d)p(c|d)p(d)
    conditionalized version of chain rule:  

p(a,b|c) = p(a|b,c)p(b|c)

    bayes   s rule:  p(a|b) = p(b|a)p(a)/p(b)
    conditionalized version of bayes   s rule:  

p(a|b,c) = p(b|a,c)p(a|c)/p(b|c)

    addition / conditioning rule:  p(a) = p(a,b) + p(a,  b) 

p(a) = p(a|b)p(b) + p(a|  b)p(  b)

common mistake

    p(a) = 0.3

so p(  a) = 1     p(a) = 0.7

    p(a|b) = 0.4 so p(  a|b) = 1     p(a|b) = 0.6

because p(a|b) + p(  a|b) = 1

but p(a|  b)     0.6         (in general)
because p(a|b) + p(a|  b)     1  in general

quiz

quiz

    a doctor performs a test that has 99% 

reliability, i.e., 99% of people who are sick test 
positive, and 99% of people who are healthy 
test negative.  the doctor estimates that 1% of 
the population is sick.

    a doctor performs a test that has 99% 

reliability, i.e., 99% of people who are sick test 
positive, and 99% of people who are healthy 
test negative.  the doctor estimates that 1% of 
the population is sick.

    question:  a patient tests positive.  what is 

the chance that the patient is sick?

    0-25%, 25-75%, 75-95%, or 95-100%?

    question:  a patient tests positive.  what is 

the chance that the patient is sick?

    0-25%, 25-75%, 75-95%, or 95-100%?
    common answer:  99%;   correct answer:  50%

13

given:  

p(tp | s) = 0.99
p(  tp |   s) = 0.99
p(s) = 0.01

query:

p(s | tp) = ?

tp =    tests positive   
s =    is sick   

p(tp | s) = 0.99
p(  tp |   s) = 0.99
p(s) = 0.01

p(s | tp) = 

p(tp | s) p(s) / p(tp)
= (0.99)(0.01) / p(tp) = 0.0099/p(tp)

p(  s | tp) = p(tp |   s)p(  s) / p(tp)

= (1     0.99)(1     0.01) / p(tp) = 0.0099/p(tp)

0.0099/p(tp) + 0.0099/p(tp) = 1, so p(tp) = 0.0198
so, p(s | tp) = 0.0099 / 0.0198 = 0.5

id136 with bayes   s rule

e: envelope, 1=(r,b), 2=(b,b)
b: the event of drawing a black ball
given:  p(b|e=1) = 0.5, p(b|e=2) = 1, p(e=1) = p(e=2) = 0.5
query:  is p(e=1 | b) > p(e=2 | b)?
use bayes   s rule:  p(e|b) = p(b|e)*p(e) / p(b)
p(b) =  p(b|e=1)p(e=1) + p(b|e=2)p(e=2) = (.5)(.5) + (1)(.5) = .75
p(e=1|b) = p(b|e=1)p(e=1)/p(b) = (.5)(.5)/(.75) =  0.33
p(e=2|b) = p(b|e=2)p(e=2)/p(b) = (1)(.5)/(.75) =  0.67
after seeing a black ball, the posterior id203 of this 
envelope being #1 (thus worth $100) is smaller than it being #2
thus you should switch!

addition rule

id136 with bayes   s rule

    in a bag there are two envelopes

    one has a red ball (worth $100) and a black ball
    one has two black balls.  black balls are worth nothing

    you randomly grab an envelope, and randomly 

take out one ball     it   s black

    at this point you   re given the option to switch 

envelopes.  should you switch or not?

similar to the    monty hall problem   

14

another  example

    1% of women over 40 who are tested have 
breast cancer.  85% of women who really do
have breast cancer have a positive 
mammography test (true positive rate).  8% 
who do not have cancer will have a positive 
mammography (false positive rate).  
    question:  a patient gets a positive 

mammography test.  what is the chance she 
has breast cancer?

compute the posterior id203:    p(c|m)

    let boolean random variable m mean 

   positive mammography test   

    let boolean random variable c mean    has 

breast cancer   

    given: 

p(c) = 0.01
p(m|c) = 0.85
p(m|  c) = 0.08

    p(c|m) = p(m|c)p(c)/p(m)        by bayes   s rule

= (.85)(.01)/p(m)

    p(m) = p(m|c)p(c) + p(m|  c)p(  c) by the 

addition rule

    so, p(c|m) = .0085/[(.85)(.01) + (.08)(1-.01)] 

= 0.097

    so, there is only a 9.7% chance that if you 
have a positive test you really have cancer!

15

independence

two events a, b are independent if the 
following hold:

    p(a, b) = p(a) * p(b)
    p(a,   b) = p(a) * p(  b)

   

    p(a | b) = p(a)
    p(b | a) = p(b)
    p(a |   b) = p(a)

   

independence

    given:  p(b) = 0.001, p(e) = 0.002, p(b|e) = p(b)
    the full joint id203 distribution table (fjpd) is:

burglary

earthquake

prob.

= p(b)p(e)

b

b

  b

  b

e

  e

e

  e

    need only 2 numbers to fill in entire table
    now we can do anything, since we have the fjpd

independence

    independence is a kind of domain 

knowledge
    needs an understanding of causation
    very strong assumption

    example: p(burglary) = 0.001  and 

p(earthquake) = 0.002  
    let   s say they are independent
    the full joint id203 table = ?

independence

    given n independent, boolean random 

variables, the fjpd has 2n entries, but we only 
need n numbers (degrees of freedom) to fill in 
entire table

    given n independent random variables, where 

each can take k values, the fjpd table has: 
    kn entries
    only n(k-1) numbers needed (dofs)

16

conditional  independence

conditional  independence

    random variables can be dependent, but 

conditionally independent

    example:  your house has an alarm

    neighbor john calls when he hears the alarm
    neighbor mary calls when she hears the alarm
    assume john and mary don   t talk to each other

    no     if john called, it is likely the alarm went off, 

    is johncall independent of marycall?  

    p(marycall | johncall)     p(marycall)

which increases the id203 of mary calling

    but, if we know the status of the alarm, johncall

will not affect whether or not mary calls
p(marycall | alarm, johncall) = p(marycall | alarm)

    we say johncall and marycall are conditionally 

independent given alarm

    in general,    a and b are conditionally independent 

given c    means: 
p(a | b, c) = p(a | c)
p(b | a, c) = p(b | c)
p(a, b | c) = p(a | c) p(b | c)

independence vs. conditional independence

    say alice and bob each toss separate coins.  a

represents    alice   s coin toss is heads    and b
represents    bob   s coin toss is heads   

    a and b are independent
    now suppose alice and bob toss the same 

coin.  are a and b independent?
    no.  say the coin may be biased towards heads.  if 
a is heads, it will lead us to increase our belief in b
beings heads.  that is, p(b|a) > p(a)

    say we add a new variable, c:     the coin is 

biased towards heads   

    the values of a and b are dependent on c
    but if we know for certain the value of c
(true or false), then any evidence about a
cannot change our belief about b

    that is, p(b|c) = p(b|a, c)
    a and b are conditionally independent 

given c

17

revisiting earlier example
    let boolean random variable m mean 

   positive mammography test   

    let boolean random variable c mean    has 

breast cancer   

    given: 

p(c) = 0.01
p(m|c) = 0.85
p(m|  c) = 0.08

bayes   s rule with multiple evidence
    say the same patient goes back and gets a 

second mammography and it too is positive.  
now, what is the chance she has cancer?

    let m1, m2 be the 2 positive tests
    m1 and m2 are not independent
    compute posterior:    p(c|m1, m2)

bayes   s rule with multiple evidence
    p(c|m1, m2) = p(m1, m2|c)p(c)/p(m1, m2)    

by bayes   s rule

= p(m1|m2, c)p(m2|c)p(c)/p(m1, m2)

conditionalized chain rule
    p(m1, m2) = p(m1, m2|c)p(c) +                

p(m1, m2|  c)p(  c)     by addition rule

= p(m1|m2, c)p(m2|c)p(c) + 

p(m1|m2,   c)p(m2|  c)p(  c)   
by conditionalized chain rule

cancer    causes    a positive test, so m1 and m2 
are conditionally independent given c, so 
    p(m1|m2, c) = p(m1 | c) = 0.85
    p(m1, m2) = p(m1|m2, c)p(m2|c)p(c) + 

p(m1|m2,   c)p(m2|  c)p(  c)

= p(m1|c)p(m2|c)p(c) + 

p(m1|  c)p(m2|  c)p(  c)   by cond. indep.

= (.85)(.85)(.01) + (.08)(.08)(1-.01)
= 0.01356

so, p(c|m1, m2) = (.85)(.85)(.01)/ .01356

= 0.533 or 53.3%

18

example

    prior id203 of having breast cancer:

p(c) = 0.01

    posterior id203 of having breast cancer 

after 1 positive mammography:
p(c|m1) = 0.097

    posterior id203 of having breast cancer 
after 2 positive mammographies (and cond. 
independence assumption):
p(c|m1, m2) = 0.533

bayes   s rule with multiple evidence
    say the same patient goes back and gets a 
second mammography and it is negative.  
now, what is the chance she has cancer?

    let m1 be the positive test and   m2 be the 

negative test

    compute posterior:    p(c|m1,   m2)

bayes   s rule with multiple evidence
    p(c|m1,   m2) = p(m1,   m2|c)p(c)/ p(m1,   m2)    

by bayes   s rule

= p(m1|c)p(  m2|c)p(c)/p(m1,   m2)
= (.85)(1-.85)(.01)/p(m1,   m2)

    p(m1,   m2) = p(m1,   m2|c)p(c) +                     

p(m1,   m2|  c)p(  c)     by addition rule

= p(m1|  m2, c)p(  m2|c)p(c) + 

p(m1|  m2,   c)p(  m2|  c)p(  c)   
by conditionalized chain rule

cancer    causes    a positive test, so m1 and   m2 
are  conditionally  independent  given  c, so 
p(m1|  m2, c)p(  m2|c)p(c) + 

p(m1|  m2,   c)p(  m2|  c)p(  c)

= p(m1|c)p(  m2|c)p(c) +                                      

p(m1|  c)p(  m2|  c)p(  c)   by cond. indep.

= (.85)(1 - .85)(.01) + (1 - .08)(.08)(1 - .01)
= 0.074139    (= p(m1,   m2))

so, p(c|m1,   m2) = (.85)(1 - .85)(.01)/ .074139

= 0.017 or 1.7%

19

bayes   s rule with multiple evidence 

and conditional independence

conditionalized chain rule + 
conditional independence

chain rule

id136 ignorance

       id136s about testosterone abuse among 

athletes,    2004
    mary decker slaney doping case

       justice flunks math,    2013

    amanda knox trial in italy

na  ve bayes classifier
    classification problem:  find the value of 

class/decision/diagnosis variable y that is most likely 
given evidence/measurements/attributes xi = vi
    use bayes   s rule and conditional independence:  
p(y = c | x1 = v1,x2 = v2,...,xn = vn)
= p(y = c)p(x1 = v1 |y = c)...p(xn = vn |y = c)/ p(x1 = v1,...,xn = vn)
    try all possible values of y and pick the value that 

gives the maximum id203

    but denominator, p(x1=v1,    , xn=vn), is a constant for 

all values of y, so it won   t affect which value of y is 
best

naive bayes classifier testing phase
    for a given test instance defined by x1=v1,    , xn=vn, 

!"#$!%&p(y=c)    ()*+ ,(.(=/( | y=c)

compute

class variable

evidence variable

    assumes all evidence variables are conditionally 

independent of each other given the class variable
    robust because it gives the right answer as long as 

the correct class is more likely than all others  

20

na  ve bayes classifier training phase

p(j) =

j

c
p(c|j) =
p(c|  j) =

z
p(z|j) =
p(z|  j) =

h

p(h|j) =
p(h|  j) =

j
c
z
h

person is junior
brought coat to class
lives in zipcode 53706
saw    hunger games 1    more 
than once

compute from the training set all the necessary 
prior and conditional probabilities

na  ve bayes classifier

p(j) =

j

c
p(c|j) =
p(c|  j) =

z
p(z|j) =
p(z|  j) =

# juniors
----------------------------
# people in database

j
c
z
h

person is junior
brought coat to class
lives in zipcode 53706
saw    hunger games 1    more 
than once

h

p(h|j) =
p(h|  j) =

# juniors who saw h>1
---------------------------------
# juniors

# non-juniors who saw h>1
---------------------------------------
# non-juniors

na  ve bayes classifier
    assume  k classes and n evidence (i.e., 

attribute) variables, each with m possible 
values

    k-1 values needed for computing p(y=c)
    (m-1)k values needed for computing           
p(xi=vi |y=c) for each evidence variable xi

    so, (k-1) + n(m-1)k values needed instead of 

exponential size fjpd table

na  ve bayes classifier

    conditional probabilities can be very, very 
small, so instead use logarithms to avoid 
underflow:
argmaxc logp(y = c) +

logp(

n

xi = vi |y = c)

   
i=1

21

add-1 smoothing

add-1 smoothing

    unseen event problem:  training data may not

include some cases
    flip a coin 3 times, all heads    one-sided coin?
    id155 = 0
    just because a value doesn   t occur in the training 

set doesn   t mean it will never occur

       add-1 smoothing    ensures that every

id155 > 0 by pretending that 
you   ve seen each attribute   s value 1 extra time

    compute prior probabilities as

add-1 smoothing

!"=$ =$%&'("=$ +1
++,

where n = size of the training set, k = number of classes

number of times 
attribute x has value 
vi in all training 
instances with class c

    compute conditional probabilities as

&'=)* +=,)=,/012('=)*,+=,)+1
,/012(+=,)+6
%&'=)*+=, =1
    note:  !"#$

number of training 
instances with class c

where m = number of possible values for attribute x

laplace smoothing

number)

    aka add-   smoothing
    instead of adding 1, add    (a positive real 

    compute conditional probabilities as

!(#=vi | y=c) = $%&'()*+,,.*$/0
$%&'(.*$/01

where m = number of possible values for attribute x

22

