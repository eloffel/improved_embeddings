introduction

    known as

    neural networks (nns)
    id158s (anns)
    connectionist models
    parallel distributed processing (pdp) models

    neural networks are a fine-grained,

parallel, distributed, computing model

recognizing digits using a neural net

recognize segmented images of handwritten decimal digits

neural networks

chapter 18.6.3, 18.6.4, 18.7
and    deep learning    paper

    nns are inspired by the brain:

    knowledge is acquired experientially (learning)
    knowledge stored in connections (weights)

    brain composed of neurons:

    dendrites collect input from ~104 other neurons
    axon sends output to other neurons
    connected at synapses that have varying strength
- this model is greatly simplified

1

recognizing digits using 

a neural network as a classifier

strengths of nn approach

neural
network

normalized 
input image

0
1
2
3
4
5
6
7
8
9

no
no
yes
no
no
no
no
no
no
no

2

output

    massively parallel

    from a large collection of simple processing elements

emerges complex, global behavior

    can do complex tasks

    pattern recognition (handwriting, facial expressions)
    forecasting (stock prices, power grid demand)
    adaptive control (autonomous vehicle control, robot 

control)

    robust computation

    can handle noisy and incomplete data due to fine-

grained, distributed and continuous knowledge 
representation

strengths of nn approach

neural network architecture

    fault tolerant

    ok to have faulty elements and bad connections
    isn't dependent on a fixed set of elements and 

connections

    degrades gracefully

    continues to function, possibly at a lower level of 
performance, when portions of the network are 
faulty

    uses inductive learning

    useful for a wide variety of high-performance apps

    large number of units

    simple neuron-like processing elements
    connected by a large number of links

    directed from one unit to another

    a weight associated with each link

    positive or negative real values
    means of long term storage
    adjusted by learning

    an activation function associated with each unit

    result of the unit's processing
    unit's output

2

neural network architecture

basics of nn

    represent as a graph

    nodes: units
    arcs: links

    single layer
    multi-layer
    feedback (cycles)?
    layer skipping?
    fully connected?

layer 3

layer 2

layer 1

computation by a unit

takes several inputs and computes a single scalar output value

input

x1

x2

x3

w2

w1

w3

a

output

structure of a    unit   :
    set of input links

    from other units or features from the environment

    set of output links

    to other units or effectors of the environment

    an activation function

    computes an output scalar value using a simple 

non-linear function of the linear combination of its 
inputs

basics of nn

= g(in)

given n inputs, the unit's activation (i.e., output) is 
defined by:

n

a = g(w1x1 + w2x2 +...+ wnxn) = g( wixi)
where
    wi are the real-valued weights
    xi are the scalar input values (in general, real values)
    g( ) is a simple, non-linear function, commonly:

   
i=1

    step (ltu):       activation flips from 0 to 1 when in     threshold
    tanh:       g(in) = tanh(in)
    sigmoid / logistic:  g(in) = 1 / (1 + exp(-in))
    rectified linear (relu):  g(in) = max(0, in)

3

step function

(aka linear threshold unit) (ltu)

hyperbolic tangent function

sigmoid function

(aka logistic function)

rectified linear function (relu)

4

id88s

    studied in the 1950s and 1960s as simple networks 
for which there was an effective learning algorithm

    (cid:1)1-layer network(cid:2):  one or more output units
    (cid:1)input units(cid:2) don   t count as a layer because they 

    output units are all linear threshold units (ltus)

don   t compute anything
    a unit's inputs, xi, are weighted, wi, and linearly
combined
    step function computes binary output activation 
value, a
x1
xi
xn

wn

w1

s

a

b

linear threshold units (ltu)

threshold is just another weight (called the bias):

(w1 x1) + (w2 x2) + ... + (wn xn)      b
which is equivalent to
(w1 x1) + (w2 x2) + ... + (wn xn) + (b (-1))     0

use +1 

instead of -1, 

however 

every unit uses a 
fixed threshold = 0

+1

w1

b

wn

x1

xn

a

0

computation by an ltu

takes several inputs and computes a single scalar output value

input

x1

x2

x3

w2

w1

w3

a

output

b

b is a threshold

a =

   
      
   
   
   
   

0   if   wixi < b
1   if   wixi     b

   
   

i

i

id88 examples

+1

-0.75

0.5

    (cid:1)and(cid:2) id88:

    inputs are 0 or 1
    output is 1 when
both x1 and x2 are 1

x1

x2

.5*1+.5*0-.75*1
=-.25 output = 0

l 2d input space

    4 possible
data points

.5*0+.5*0-.75*1
=-.75 output = 0

    weights define linear 

decision boundary

0.5
x1

1

0

a

.5*1+.5*1-.75*1
=.25 output = 1

x2

0

1

5

id88 is a linear classifier

id88 examples

    (cid:1)and(cid:2) id88:

    inputs are 0 or 1
    output is 1 when
both x1 and x2 are 1

x1

x2

l 2d input space

    4 possible
data points

    weights define linear 

decision boundary

w1x1 + w2x2 + b = 0

half-plane 
where a = 0

+1

-0.75

0.5

a

half-plane 
where a = 1

x2

0.5
x1

1

0

0

1

    (cid:1)or(cid:2) id88:
    inputs are 0 or 1
    output is 1 when
either x1 or x2 are 1

x1

x2

.5*1+.5*0-.25*1
=.25 output = 1

l 2d input space

    4 possible
data points

.5*0+.5*0-.25*1
=-.25 output = 0

    weights define linear 

decision boundary

+1

???-0.25

0.5

a

0.5
x1

1

0

.5*1+.5*1-.25*1
=.75 output = 1

x2

0

1

id88 learning

id88 learning algorithm

how are the weights learned by a id88?
    programmer specifies:

    numbers of units in each layer
    connectivity between units

    only unknown is the set of weights
    learning of weights is supervised

    for each training example

a list of values for the input units of the network

    the correct output is given

a list of desired output values for all output units

1. initialize the weights in the network

(usually with random values) 

2. repeat until all examples correctly classified

or some other stopping criterion is met
foreach example, e, in the training set do
o = neural_net_output(network, e); 
t = desired output;  // target or teacher output
update_weights(e, o, t); 

    each pass through all of the training examples is 

called an epoch

    step 2 takes many epochs in general!

6

id88 learning rule

id88 learning rule:

how should the weights be updated? 
    determining how to update the weights is an 

instance of the credit assignment problem

wi = wi +   wi
   is a real-valued constant between 0.0 and 1.0 

where   wi =    xi (t - o)
xi is the input associated with ith input unit

called the learning rate

id88 learning rule properties

     wi =    xi (t - o) doesn't depend on wi
    no change in weight (i.e.,    wi = 0) if:
    correct output, i.e.,  t = o gives   (cid:1)xi (cid:1) 0 = 0
    0 input, i.e., xi = 0 gives   (cid:1) 0 (cid:1) (t - o) = 0

    if t=1 and o=0, increase the weight

so that maybe next time the result will exceed the output unit's 
threshold, causing it to be 1

    if t=0 and o=1, decrease the weight

so that maybe next time the result won't exceed the output unit's 
threshold, causing it to be 0

    so, when error occurs, update the weight so 

that it changes the activation towards the 
desired output/activation value

example:  learning or

      wi =   (t     o)xi = 0.2(t     o)xi
    initial network:

ltu

0.8

ltu

0

0.1

x1

0.5

x2

w1 = 0.1

x1

w2 = 0.5
x2

w3 = -0.8

+1

example:  learning or

bias

x1

x2

t
t

o
a

  w1

0
0
1
1
0
0
1
1
0
0
1
1

0
1
0
1
0
1
0
1
0
1
0
1

0
1
1
1
0
1
1
1
0
1
1
1

0
0
0
1
0
1
0
1
0
1
1
1

0
0
0.2
0
0
0
0.2
0
0
0
0
0

w1
0.1
0.1
0.1
0.3
0.3
0.3
0.3
0.5
0.5
0.5
0.5
0.5
0.5

  w2

0
0.2
0
0
0
0
0
0
0
0
0
0

w2
0.5
0.5
0.7
0.7
0.7
0.7
0.7
0.7
0.7
0.7
0.7
0.7
0.7

  w3

0
0.2
0.2
0
0
0
0.2
0
0
0
0
0

w3
-0.8
-0.8
-0.6
-0.4
-0.4
-0.4
-0.4
-0.2
-0.2
-0.2
-0.2
-0.2
-0.2

7

id88 learning rule (plr)
    plr is a (cid:1)local" learning rule in that only local 

information in the network is needed to update a 
weight

    plr performs id119 (hill-climbing) in 

   weight space   

    iteratively adjusts all weights so that for each 
training example the error decreases (more 
correctly, error is monotonically non-increasing) 

limits of id88 learning

what can be learned by a id88?
    id88's output is determined by the 

separating hyperplane (linear decision 
boundary) defined by

(w1 x1) + (w2 x2) + ... + (wn xn) = b

    so, id88s can only learn functions

that are linearly separable (in input space)

id88 learning rule (plr)
id88 convergence theorem:
    if a set of examples is learnable, then plr will 

find an appropriate set of weights
    in a finite number of steps
    independent of the initial weights
    using a sufficiently small value for   

    this theorem says that if a solution exists,

plr's id119 is guaranteed to find an
optimal solution (i.e., 100% correct 
classification) for any 1-layer neural network

separating hyperplane example

    (cid:1)and(cid:2) id88:

    inputs are 0 or 1
    output is 1 when
both x1 and x2 are 1

    2d    input space   

decision line equation:
0.5x1 + 0.5x2     0.75 = 0
or, in slope-intercept 

form:    x1 =     x2 + 1.5

x1

x2

+1

-0.75

0.5

0.5
x1

1

0

0

1

a

x2

8

limits of id88 learning
    (cid:1)xor(cid:2) id88?

    inputs are 0 or 1
    output is 1 when
x1 is 1 and x2 is 0 or
x1 is 0 and x2 is 1
    2d input space with

4 possible data points
    how do you separate
+ from       using a 
straight line?

+1

x1

x2

???

x1

.5

.5

1

0

0

1

a

x2

id88 learning rule

id88 learning rule:

how should the weights be updated? 
    determining how to update the weights is an 

instance of the credit assignment problem

wi = wi +   wi
   is a real-valued constant between 0.0 and 1.0 

where   wi =    xi (t - o)
xi is the input associated with ith input unit

called the learning rate

id88 learning summary

in general, the goal of learning in a 1-output-
unit id88 is to adjust the separating 
hyperplane (i.e., linear decision boundary)
that divides an n-dimensional    input space,    
where n is the number of input units, by 
modifying the weights (including the bias) 
until all the examples with target value 1 are 
on one side of the hyperplane, and all the 
examples with target value 0 are on the other 
side of the hyperplane

recognizing digits using 

a neural network as a classifier

neural
network

normalized 
input image

0
1
2
3
4
5
6
7
8
9

no
no
yes
no
no
no
no
no
no
no

2

output

9

digit recognition using a id88

input layer

784 units

target 
output

output layer

10 units
0
1
2
3
4
5
6
7
8
9

0
0
0
0
0
0
1
0
0
0

   

   

input 
784 pixels

note:  figure does not show the bias input to each output unit

classification accuracy     90%  (random guessing = 10%)

beyond id88s

    a multi-layer, feed-forward network computes 

a function of the inputs and the weights

    input units

    input values are given

    output units

    activation is the output result

    hidden units (between input and output units)

    cannot observe directly

    id88s have input units followed

by one layer of output units, i.e., no hidden units

beyond id88s

    id88s are too weak a computing model 

because they can only learn linearly-
separable functions

    general nn's can have multiple layers of 
units, which enhance their computational 
power; the challenge is to find a learning rule 
that works for multi-layered networks

beyond id88s

    nn's with one hidden layer of a sufficient 
number of units, can compute functions 
associated with convex classification regions in 
input space
    and can approximate any continuous function

    nn's with two hidden layers are universal 

computing devices, although the complexity
of the function is limited by the number of units
    if too few, the network will be unable to 

represent the function

    if too many, the network can memorize 
examples and is subject to (cid:1)overfitting(cid:2)

10

two-layer, feed-forward

neural network

two-layer, feed-forward

neural network

wi,j

aj

wj,k

input units 
hidden units
output units
weights on links
from input to hidden
weights on links
from hidden to output
network activations

ai=ii
i1
i2
i3
i4
i5
i6

ak

a1 = o1

a2 = o2

two layers:
count layers with units
computing an activation
feed-forward:
each unit in a layer
connects to all units in 
the next layer
no cycles
- links within the same layer
- links to prior layers
no skipping layers

ai=ii
i1
i2
i3
i4
i5
i6

wi,j

aj

wj,k

ak

a1 = o1

a2 = o2

layer 1

layer 2

xor example

xor example

xor  2-layer feed-forward network
-.25
.5

    inputs are 0 or 1
    output is 1 when
i1 is 1 and i2 is 0, or
i1 is 0 and i2 is 1

+1

i1

.5
.5

or

.5
-.75

i2

+1

each unit in hidden layer
acts like a id88
learning a decision line
    top hidden unit acts like

an or id88

    bottom hidden unit acts like

an and id88

and
i1

1

0

0

1

a

.5

-.5

+1

.25

i2

xor  2-layer feed-forward network
-.25
.5

    inputs are 0 or 1
    output is 1 when
i1 is 1 and i2 is 0 or
i1 is 0 and i2 is 1

+1

i1

.5
.5

or

.5
-.75

i2

+1

to classify an example each 
unit in the output layer 
combines these decision lines 
by intersecting their "half-
planes   :

when or is 1 and  and is 0

then output, a, is 1

and
i1

1

0

0

1

a

.5

-.5

+1

.25

i2

11

learning in multi-layer, feed-forward 

neural nets

    plr doesn't work in multi-layered feed-
forward nets because the desired target 
values for the hidden units are not known

    must again solve the credit assignment 

problem
    determine which weights to credit/blame for 
the output error in the network, and how to 
update them

back-propagation algorithm
initialize the weights in the network (usually random values) 
repeat until stopping criterion is met  {
forall p,q in network,   wp,q = 0
foreach example e in training set do {

o = neural_net_output(network, e)   // forward pass
calculate error (t - o) at the output units  // t = teacher output
compute   wj,k for all weights from hidden unit j to output unit k
compute   wi,j for all weights from input unit i to hidden unit j
forall p,q in network    wp,q =   wp,q +   wp,q
}               

backward pass

for all p,q in network    wp,q =   wp,q / num_training_examples
network = update_weights(network,   wp,q) 

note:  uses average gradient for all
training examples when updating weights  

}

learning in multi-layer, feed-forward 

neural nets

back-propogation

    method for learning weights in these networks
    generalizes plr
    rumelhart, hinton and williams, 1986

approach

    gradient-descent algorithm to minimize the total 

error on the training set

    errors are propagated through the network 

starting at the output units and working 
backwards towards the input units 

back-prop using stochastic 
id119 (sgd)

    most practitioners use sgd to update 

weights using the average gradient 
computed using a small batch of examples, 
and repeating this process for many small 
batches from the training set

    in extreme case, update after each example
    called stochastic because each small set of 

examples gives a noisy estimate of the 
average gradient over all training examples    

12

updating the weights

updating the weights

    back-propagation performs a id119 
search in (cid:1)weight space(cid:2) to learn the network 
weights

    given a network with n weights:

    each configuration of weights is a vector, w, of 
length n that defines an instance of the network
    w can be considered a point in an n-dimensional 
weight space, where each dimension is associated 
with one of the connections in the network

updating the weights

visualized as an error surface in    weight space   
l for example, when a network has 2 weights, each point in 

w1 w2  plane is a weight configuration, w

l each point has a total error e
l 2d surface represents errors
for all weight configurations

e

l goal is to find a lower point on the 

error surface (local minimum)
l id119 follows the 
direction of steepest descent,
i.e., where e decreases the most

.3

w2

.8

w1

    given a training set of m examples:

    each network defined by the vector w has an 
associated total error, e, on all the training data
    e is the sum squared error (sse) defined by

e = e1 + e2 + ... + em
where ei is the squared error of the network
on the ith training example
    given t output units in the network:
ei = (t1 - o1)2 + (t2 - o2)2 + ... + (tt - ot)2
    ti is the target value for the ith example
    oi is the network output value for the ith example

updating the weights

    the gradient is defined as

   e = [   e /    w1,   e /    w2,...,   e /    wn]

    update the ith weight using

  wi =         e /    wi

    can't use the step function (ltu) because it   s 

derivative is 0 almost everywhere and 
undefined at the step

    instead, let   s use (for now) the sigmoid 

function

13

back-propagation algorithm

1. make prediction (forward pass)
2. calculate the total error (loss), e
3. calculate gradient of the id168 w.r.t. 

each weight,    e/   wi

4. update all weights by taking a step in the 

opposite direction:

  wi =         e /    wi

5. iterate

id119

   e

e

  w

   weight space   

sigmoid activation function
use a smooth,    soft threshold    function such as 
sigmoid function (aka logistic sigmoid function):
gw(x) = 1 / (1 + e   wx)

first derivative of sigmoid function

g   (x) = g(x) (1 - g(x))

squashes 
numbers to 
range [0,1]

g   (x)

14

updating the weights

tk

ok

k
aj

j

ai

i

output unit

hidden unit

input unit

updating weights in a
2-layer neural network

for weights between input and hidden units:

    we don't have teacher-supplied correct activation 

values for the hidden units

    must infer the error at these units by "back-

propagating   

    error at an output unit is "distributed" back to 
each of the hidden units in proportion to the 
weight of the connection between them

    each hidden unit accumulates some error from 
each of the output units to which it is connected

updating weights in a
2-layer neural network

= -   -aj (tk - ok) g'(ink)
=    aj (tk - ok) ok (1 - ok)
=     aj    k

for weights between hidden and output units, 
generalized plr for sigmoid activation function is
  wj,k =         e /    wj,k
  

wj,k weight on link from hidden unit j to output unit k
aj
tk
ok
g'
   k modified error

learning rate parameter
activation (i.e., output) of hidden unit j
teacher output for output unit k
actual output of output unit k
derivative of the sigmoid activation function, which is g' = g(1     g)

   k = errk (cid:1)g'(ink)

updating weights in a
2-layer neural network
for weights between inputs and hidden units:

  wi,j =         e /    wi,j

k

    (tk    ok)    g (ink)
   

=      (   ai)    g (inj) wj,k
=   ai aj(1    aj) wj,k(tk    ok)
 ok(1   ok)
=   ai    j    where      j =    g (inj) wj,k  k
   

k

k

wi,j weight on link from input i to hidden unit j
wj,k weight on link from hidden unit j to output unit k
  
aj
tk
ok actual output of output unit k
ai
g'

learning rate parameter
activation (i.e., output) of hidden unit j
teacher output for output unit k
input value i
derivative of sigmoid activation function, which is g' = g(1-g)

15

back-propagation algorithm
initialize the weights in the network (usually random values) 
repeat until stopping criterion is met

foreach example, e, in training set do

forward pass

{ o = neural_net_output(network, e)
t = desired output, i.e., target or teacher's output
calculate error (tk - ok) at each output unit k
foreach hidden unit j and output unit k compute  

  wj,k =    aj    k =     aj (tk - ok) g   (ink)

foreach input unit i and hidden unit j compute

 

s
s
a
p
d
r
a
w
k
c
a
b

  wi,j =   ai    j =   ai 

   g (inj) wj,k
forall p, q in network wp,q = wp,q +   wp,q

k

    (tk    ok)    g (ink)
simplistic sgd: 
update all weights 
after each example

}

digit recognition

input layer

784 units

hidden layer

30 units

   

input 
784 pixels

   

output layer

10 units
0
1
2
3
4
5
6
7
8
9

0
0
0
0
0
0
1
0
0
0

95% accuracy

[nielsen 2015]

learning hidden layer representation

learning hidden layer representation
training

can this be learned?

training set size = 8

# epochs

the evolving sum of squared errors for each of the eight 
output units 

slide by guoping qiu

slide by guoping qiu

16

learning hidden layer representation

feature 
detectors

learned hidden layer representation

slide by guoping qiu

what is this 
unit doing?

hidden-layer units learn to be

feature detectors

1                5                10                 15                20                25     
   

1

63

strong positive weight

low/zero weight

17

what does this unit detect? 

what does this unit detect? 

1                5                10                 15                20                25     
   

1                5                10                 15                20                25     
   

strong positive weight

low/zero weight

63

what does this unit detect? 

1                5                10                 15                20                25     
   

1

1

1

1

strong positive weight

low/zero weight

it will send a strong signal for a horizontal
line in the top row, ignoring everywhere else 

63

what does this unit detect? 

1                5                10                 15                20                25     
   

strong positive weight

low/zero weight

63

strong positive weight

low/zero weight

strong signal for a dark area 
in the top left corner 

63

18

multi-layer feed-forward networks
    back-propagation algorithm performs gradient 
descent in the    weight space    of the network
    include a bias input at every (non-input) unit
    in practice, use relu, not sigmoid, for the 

activation function in order to speed up training

    will, in general, find a local, not global, error 

minimum

    training can take thousands of epochs, but can 

be computed efficiently using matrix vector 
operations and gpu implementation

how many weights?

3 layers, 9 units with activation function,
((3x4)+4) + ((4x4)+4) + ((4x1)+1) = 41 weights incl. biases 

rectified linear function (relu)

other issues

how should the learning rate parameter,   , 

be set?

use a tuning set (aka validation set) to train 
using several candidate values for   , and 
then select the value that gives the lowest 
error

19

using data

    training set is used to learn a    model    (i.e., 

the neural network   s weights)

    tuning set is used to judge and select 
parameters (e.g., learning rate and the 
number of hidden units with best accuracy)
    testing set is used to judge in a fair manner 

the final model   s performance accuracy (using 
cross-validation or leave-one-out)

    all 3 datasets must be disjoint! 

tuning sets

e
t
a
r
 
r
o
r
r
e

tuning set

test set

training set

training time (epochs)

other issues

    when should training stop?

    too soon and the concept isn't learned
    too late:

    overfitting, poor generalization
    error rate will go up on the testing set

    train the network until the error rate on a 

tuning set begins increasing rather than 
training until the error (i.e., sse) on the 
training set is minimized

other issues

how many examples should be in the 
training set?

    the more the better, but training takes longer
to obtain 1     e correct classification on testing set, 
the training set should be of size approximately n/e

    n is the number of weights in the network
    e is test set error fraction between 0 and 1

    train to classify 1 - e/2 of the training set correctly
e.g., if n = 80 and e = 0.1 (i.e., 10% error on test set)
    use training set of size is 800
    train until 95% correct classification on training set
    should produce ~90% correct classification on test set

20

back-propagation recap

    back-propagation performs a id119 

search in (cid:1)weight space(cid:2) to learn the neural 
network weights that minimize the total error on 
the training set

    given a neural network with n weights:

    each configuration of weights is a vector, w, of 
length n that defines an instance of the network
    w can be considered a point in an n-dimensional 
weight space, where each dimension is associated 
with one of the connections in the network

updating the weights

    given a training set of m examples:

    each network defined by the vector w has an 
associated total error, e, on all the training data
    for example, if e is defined as the sum squared 
error (sse): e = e1 + e2 + ... + em
where ei is the squared error of the network
on the ith training example
    given t output units in the network:
ei = (t1 - o1)2 + (t2 - o2)2 + ... + (tt - ot)2
    ti is the target value for the ith example
    oi is the network output value for the ith example

back-propagation using sgd
initialize the weights in the network (usually random values) 
repeat until stopping criterion is met

foreach example, ex, in training set do

forward pass

{ o = neural_net_output(network, ex)
t = desired output, i.e., target or teacher's output
calculate error (tk - ok) at each output unit k
foreach hidden unit j and output unit k compute     wj,k
foreach input unit i and hidden unit j compute    wi,j
forall p, q in network wp,q = wp,q +   wp,q

 

s
s
a
p
d
r
a
w
k
c
a
b

}

back-propagation algorithm

1. make prediction (forward pass)
2. calculate the total error (loss), e
3. calculate gradient of the id168 w.r.t. 

each weight,    e/   wi

4. update all weights by taking a step in the 

opposite direction:

  wi =         e /    wi

5. iterate

simplistic sgd: 
update all weights 
after each example

21

updating weights in a
2-layer neural network

= -   -aj (tk - ok) g'(ink)
=    aj (tk - ok) ok (1 - ok)
=     aj    k

for weights between hidden and output units, 
generalized plr for sigmoid activation function is
  wj,k =         e /    wj,k
  

wj,k weight on link from hidden unit j to output unit k
aj
tk
ok
g'
   k modified error

learning rate parameter
activation (i.e., output) of hidden unit j
teacher output for output unit k
actual output of output unit k
derivative of the sigmoid activation function, which is g' = g(1     g)

   k = errk (cid:1)g'(ink)

updating weights in a
2-layer neural network
for weights between inputs and hidden units:

  wi,j =         e /    wi,j

k

    (tk    ok)    g (ink)
   

=      (   ai)    g (inj) wj,k
=   ai aj(1    aj) wj,k(tk    ok)
 ok(1   ok)
=   ai    j    where      j =    g (inj) wj,k  k
   

k

k

wi,j weight on link from input i to hidden unit j
wj,k weight on link from hidden unit j to output unit k
  
aj
tk
ok actual output of output unit k
ai
g'

learning rate parameter
activation (i.e., output) of hidden unit j
teacher output for output unit k
input value i
derivative of sigmoid activation function, which is g' = g(1-g)

other issues

    how many hidden layers should be in 
the network?
    often just one hidden layer is used

    how many hidden units should be in 
a layer?
    too few: concept can't be learned
    too many:

    examples just memorized
    overfitting, poor generalization

how many hidden units?

decision regions learned by a 2-layer network:
larger networks can represent more complicated 
functions, but make it easier to overfit the training data

3 hidden units

6 hidden units

20 hidden units

22

alvinn   s 2-layer network

application:  autonomous driving
    alvinn  (pomerleau, 1988) 

learns to control vehicle steering to stay in the 
middle of its lane

    topology:  2-layer, feed-forward network

using back-propagation learning
    input layer: 480 (cid:1) 512 image @ 15 frames per 

second
    color image is preprocessed to obtain a 30 (cid:1) 32 image
    each pixel is one byte, an integer from 0 to 255

corresponding to the brightness of the image

    networks has 960 input units (= 30 (cid:1) 32)

application:  face detection

2-layer network

nn 

classifier

2 classes:
face/
non-face

   

input = 20 x 20 pixel window, outputs a value ranging from    1 to +1 
signifying the presence or absence of a face in the region
    the window is positioned at every location of the image
    to detect faces larger than 20 x 20 pixel, the image is repeatedly reduced 

in size

[pomerleau, 1995]

23

application:  face detection

    2-layer feed-forward neural network
    three types of hidden units

    4 look at 10 x 10 subregions
    16 look at 5 x 5 subregions
    6 look at 20 x 5 horizontal stripes of pixels

face detection results

    training set

    1,050 initial face images. more face examples 
generated from this set by rotation and scaling. 
desired output:  +1

    non-face training samples:  8,000 non-face training 

samples from 146,212,178 subimage regions! 
desired output:  -1

results

    notice detection at multiple scales 

what is wrong with back-propagation?
    requires labeled training data
    almost all data is unlabeled

    learning time does not scale well

    it is very slow to converge in networks with 
multiple hidden layers

    might get stuck at a poor local optimum
    overfitting problem

from g. hinton

24

sigmoid function

slow learning because    saturated    units    kill    
gradients

derivative near 0

derivative near 0

rectified linear function (relu)

speeding up training
use relu instead of sigmoid (or tanh)
    rectified linear unit:   g(x) = max(0, x)
    relu reaches 25% error rate 6x faster than tanh
    computationally efficient

 

r
o
r
r
e
g
n
n
a
r
t

i

i

relu

tanh

epochs

what   s the derivative of the relu function?

   g (x) =

0,     if x     0
1,  otherwise

   
   
   
      

but this means when x     0 the unit will never 
update because   i = 0

    fix using a variation such as    leaky relu   :

!"#!$% ='(),
),

)<0
)   0

25

notes for hw #4, problem 3

    at each hidden unit, use the relu activation 

function

    in forward pass use the relu activation 

function:  g(x) = max(0, x)

    in backward pass use the derivative of the 

relu function:  

   g (x) =

0,     if x     0
1,  otherwise

   
   
   
      

multi-class classification with neural networks
    at each output unit use the softmax activation 

function:

softmax()*)=

e./
   1234
e.5

where zi is the weighted sum of the inputs to the 
ith output unit, and there are k output units

    means output units all have values between 0 and 1, 

and sum to 1; can be interpreted as probabilities

    note: [3,1,1] does not become [.6, .2, .2] but rather 

[.78, .11, .11] since we are exponentiating before 
normalizing

multi-class classification with neural networks
    use a number of output units equal to the number 

of classes

    represent each class with 1 at a particular output 

unit and 0 at all other output units

100

010

001

cat

dog

toaster

multi-class classification with neural networks

   

for id168 use    cross-id178:   

".$.=   3.45
6 2.log(0.)
where 0. is the computed output at output unit i
!%&'()*+   !%&'()*+
!".$.
!-.

=0.   2.

and ti is the target output at unit i

    derivative has a nice property when used with 

softmax: 

26

notes for hw #4, problem 3

    at all output units, use the softmax activation 

function and define the error (loss) function 
using cross-id178

preventing overfitting:  dropout
to prevent overfitting the training set,    dropout    
is often performed:
    during training:  at each hidden layer,    drop 
out    a random set of units from that layer by 
setting their outputs to 0 in the forward pass
    each unit is retained with id203 p (= 0.5)
    back-propagation is performed only on the 

thinned network

    during testing:  use the whole network (but 

weights must all be re-scaled)

dropout

why dropout?

    if a hidden unit knows 

which other hidden units 
are present, it can co-
adapt to them on the 
training data
    but complex co-

adaptations are likely to go 
wrong on new test data

original neural net

neural net after dropping 
out    x   ed nodes

    big, complex conspiracies 

are not robust

    if a hidden unit has to 

work well with 
combinatorially many 
sets of co-workers, it is 
more likely to do 
something that is 
individually useful
    but it will also tend to do 

something that is only 
marginally useful given 
what its co-workers 
achieve

g. hinton

27

deep learning

    use many hidden layers (often 10-20)
    called deep neural nets or deep nets

    early nns used only 1 or 2 hidden layers 

because training was slow, thought to 
converge to poor local minima, and overfit

    recent results suggest that local minima are 
not a serious problem     regardless of initial 
conditions, bigger nns contain many more 
local minima but nearly all are solutions of 
very similar quality.  and overfitting can be 
avoided using id173 techniques such 
as dropout rather than using fewer units

reading:     deep learning,   
y. lecun, y. bengio and g. hinton, 
nature, 2015

a lot of buzz about deep learning

similarly, big groups at facebook, microsoft, baidu, amazon,    

28

why deep learning?

    biological plausibility     your brain works that way
    problems that can be represented with a polynomial 

number of nodes with k layers, may require an 
exponential number of nodes with k-1 layers

    highly varying functions can be efficiently 

represented with deep architectures
    fewer weights/parameters to update than a less 

efficient shallow representation

why deep learning?

    learn better features:     features matter   

    use context better

    features learned in deep architecture can potentially 

be shared between multiple tasks
    type of transfer/id72

hierarchical, representation learning

successive layers can learn higher-level features

    natural progression 
from low-level to high-
level features as seen in 
natural complexity
    automatically learns 
features from the raw 
data
    easier to monitor what 
is being learned and to 
guide the learner to 
better subspaces 

detect lines in
specific positions

higher level detetors
( horizontal line, 
   rhs vertical lune   
   upper loop   , etc   

v

etc    

etc    

automatically learn higher and higher levels of 
feature representations directly from the raw data

29

difficulties training deep networks
    bottom layers do not get trained easily

    error attenuates as it propagates to earlier layers
    leads to very slow training

    for small data sets, not enough labeled data 

available for training

    use a pre-processing step to initialize 

weights 

    then use traditional back-prop to train the 

full network

id98s

    many applications process array data

    1d:  time-series, acoustic, text data
    2d:  images and audio spectrograms
    3d:  video and volumetric data

    properties of these types of data

    local, shift-invariant processing (i.e., doesn   t 

depend on position in the input array)

    hierarchy of feature descriptions
    noisy data

convolutional neural networks

also called id98s and convnets

id98s are an extension of traditional multi-layer, 
feed-forward networks that incorporate 4 key 
ideas:
    use of many layers

    learn a hierarchy of features

    local    receptive fields   /filters and local 

connections
    layers are not completely connected
    want translation-invariant and distortion-invariant 

local features
    shared weights
    pooling

30

computation by a unit

takes several inputs and computes a single scalar output value

input

x1

x2

x3

w2

w1

w3

a

output

a = g(w1x1 + w2x2 +...+ wnxn) = g( wixi)

n

   
i=1

= g(in)

first step is to compute in, the linear combination of the inputs

image filtering

f

[.,.]

0

0

90

90

90

90

90

0

0

0

0

0

90

90

90

0

90

0

0

0

0

0

90

90

90

90

90

0

0

0

0

0

90

90

90

90

90

0

0

0

0

0

90

90

90

90

90

0

0

0

0

0

0

0

0

0

0

0

90

0

n

0

0

0

0

0

0

0

0

0

0

0

0

0

0

0

0

0

0

0

0

0

0

0

0

0

0

0

0

0

0

0

0

0

0

0

0

0

0

0

0

m

],[g     

-1,-1

-1,0

-1,1

0,-1

0,0

0,1

l

1,-1

1,0

1,1

k

1

  +

,

=

+

nmh
],
[

lnkmf
+

lkg
[],[
lk
1
,
-=
f
h
]5,7[
]4,6[]1,1[
]5,6[]0,1[
-
+
--
g
f
g
]4,7[]1,0[
]6,6[]1,1[
-
+
g
...
]5,7[]0,0[
+

=
f

+

-

g

g

f

f

]

+

credit: s. seitz

1

1

1

1

1

1

1

1

1

],[g     
h
[.,.]

filter

output 
image

0

image filtering

input 
image

f

[.,.]

0
0

0
0

0
0

0
0

0
0

0
0

0
0

0
0

0
0

0
0

0
0

0
0

0
0

0
0

0
0

0
0

0
0

0
0

0
0

0
0

0
0

0
0

0
0

0
0

0
0

0
0

0
0

0
0

90
90

0
0

0
0

0
0

90
90

90
90

90
90

90
90

90
90

0
0

0
0

0
0

0
0

0
0

90
90

90
90

90
90

0
0

90
90

0
0

0
0

0
0

0
0

0
0

90
90

90
90

90
90

90
90

90
90

0
0

0
0

0
0

0
0

0
0

90
90

90
90

90
90

90
90

90
90

0
0

0
0

0
0

0
0

0
0

90
90

90
90

90
90

90
90

90
90

0
0

0
0

0
0

0
0

0
0

0
0

0
0

0
0

0
0

0
0

0
0

0
0

0
0

0
0

0
0

0
0

0
0

0
0

0
0

0
0

0
0

0
0

0
0

nmh
[
],

lkg
],[

=   

lk
,

image filtering

f

[.,.]

0

0

0

0

0

0

0

0

0

0

0

0

0

0

0

0

0

0

0

0

0

0

0

0

0

0

0

0

90

0

0

0

90

90

90

90

90

0

0

0

0

0

90

90

90

0

90

0

0

0

0

0

90

90

90

90

90

0

0

0

0

0

90

90

90

90

90

0

0

0

0

0

90

90

90

90

90

0

0

0

0

0

0

0

0

0

0

0

0

0

0

0

0

0

0

0

0

0

0

0

nmh
[
],

lkg
],[

=   

lk
,

lnkmf
[
+

+

,

]

credit: s. seitz

1

1

1

1

1

1

1

1

1

],[g     
h
[.,.]

0

10

20

30

30

50

lnkmf
[
+

+

,

]

credit: s. seitz

31

example: box filter

image smoothing with box filter

],[g     

1

1

1

1

1

1

1

1

1

=

1/9
1/9
1/9

1/9
1/9
1/9

1/9
1/9
1/9

credit: david lowe

vertical edge detection filter

horizontal edge detection filter

1
2
1

0
0
0

-1
-2
-1

sobel
filter

1
0
-1

2
0
-2

1
0
-1

sobel
filter

vertical edges
(absolute value)

horizontal edges
(absolute value)

32

other filters

why are they called    convolutional    nns?
the image filtering operation defined as
lnkmf
[
]
+

nmh
],
[

lkg
],[

+

,

=   

lk
,

is very similar to the convolution operation defined as

nmh
[
],

lkg
],[

=   

lk
,

lnkmf
[
-

-

,

]

    in id98   s, f corresponds to the inputs from the layer 

below and g corresponds to the weights

    so, id98   s will learn a set of filters! 

credit: k. grauman

3 x 3 filter, stride = 1

convolution layers

    learn    filters    (i.e., weights) that process small 

regions of the layer below it and compute 
   features    at many spatial positions

    example:  32 x 32 x 3 input rgb image, and 

receptive field (filter size):  5 x 5
    each unit in the conv layer will have weights 

connected to a 5 x 5 x 3 region in the input layer, 
with 5*5*3 = 75 weights

    can have multiple units associated with a given 

receptive field in order to compute multiple 
features at each position

       stride    parameter defines shift amount

33

3 x 3 filter, stride = 2

the replicated feature approach:

local connections and shared weights

the red connections 
all have the same 
weight

    use many different copies of the same 
feature detector at different positions
    could also replicate across scale and 

orientation (but tricky and expensive)

    replication greatly reduces the number of 

weights to be learned

    use several different feature types, 
each with its own map of replicated 
detectors
    allows each patch of image to be 

represented in several ways

learned features

96 learned low-level (1st layer) filters: 

34

what does replicating the feature 

detectors achieve?

    equivariant activities
representation by 
active neurons

image

translated 

representation

translated      
image

    invariant knowledge: if a feature is useful in some 
locations during training, detectors for that feature 
will be available in all locations during testing

relu layers

    each convolution layer usually followed by an 
relu layer, which applies the relu function to 
the output of each convolution layer

    no weights to be learned
    layer size equal to size of the layer below it

pooling layers

    each relu layer usually followed by a pooling 

layer

    get a small amount of translational invariance 

and robustness to noise by combining 
neighboring values to give a single output at the 
next layer

    max pooling:  combine by taking the maximum
    average pooling:  combine by taking the 

average

    sub-sampling:  reduces the size of the next 
layer according to the size of the pooling filter
    for example, a 2 x 2 filter reduces the size by    in 

each dimension

max pooling example

top layers fully connected

    top several layers are usually fully-connected, 

feed-forward layers

    hidden layers and output layer

2 x 2 filter with a stride of 2       

adit deshpande

35

convolutional neural network

convolutional layer

pooling

(subsampling)

fully connected 

network

   

   

"$
"#
"%
"&
"'

*

*

*

*

*

input 
image

i.27

kernels

convolution 

+ relu

[lecun et al. 1998]

id98 architecture

convolutions and relu

convolutions and relu

max pooling

max pooling

id98s are an extension of traditional multi-layer, 
feed-forward networks that incorporate 4 key 
ideas:
    use of many layers

    learn a hierarchy of features

    local    receptive fields   /filters and local 

connections
    layers are not completely connected
    want translation-invariant and distortion-invariant 

local features
    shared weights
    pooling

36

lecunn   s digit recognizer:  lenet
http://yann.lecun.com/

lenet

    yann lecun and his collaborators developed a really 

good recognizer for handwritten digits by using 
id26 in a feed-forward net with:
    many hidden layers
    many maps of replicated units in each layer
    pooling of the outputs of nearby replicated units
    a wide net that can cope with several characters 

at once even if they overlap

    this net was used for reading ~10% of the checks in 

north america

the architecture of lenet5

from handwritten digits to 3d 

objects

    recognizing real objects in color photographs 

downloaded from the web is much more complicated 
than recognizing handwritten digits:
    hundred times as many classes (1000 vs 10)
    hundred times as many pixels (256 x 256 color vs

28 x 28 grayscale images)

    cluttered scenes
    multiple objects in each image
    will the same type of id98 work?

37

large scale visual 
recognition challenge (ilsvrc 2010)

training set:  1.2 million 256 x 256 rgb images

    classification task:

   get the    correct    class 
in your top 5 predictions. 
there are 1000 classes

    localization task:

   for each prediction, put 
a box around the object. 
your box must have at 
least 50% overlap with 
the correct box

dalmatian

variety of object classes in ilsvrc

id163

    over 15m labeled high-resolution images
    about 22k categories
    collected from the web and manually labeled by 

amazon mechanical turk

alexnet

a. krizhevsky, i. sutskever, g. hinton, nips 2012

    7 hidden    weight    layers:
    data (cid:1) conv1 (cid:1) pool1 (cid:1) conv2 (cid:1)
pool2 (cid:1) conv3 (cid:1) conv4 (cid:1) conv5 (cid:1)
pool3 (cid:1) full (cid:1) full (cid:1) output
    650k units, 60m weights, 630m connections 
    relus, max pooling, dropout trick
    top feature layer:  4096 units
    output layer:  1000 units
    trained with sgd on two gpus for a week
    classification:     top-1    error rate: 37.5%
   top-5    error rate: 17%

    localization: regression on (x,y,w,h)

38

learned features at 1st layer

dropout observations by g. hinton

    if your deep neural net is significantly 

overfitting, dropout will usually reduce the 
number of errors by a lot
    any net that uses    early stopping    can do better 
by using dropout (at the cost of taking quite a lot 
longer to train) 

    if your deep neural net is not overfitting you 

should be using a bigger one!

learned features at 5th layer

examples from the test set
(with the network   s guesses)

39

ilsvrc 2012

training set:  15 million labeled images from id163, 
20k categories

example classification results

error rates on the ilsvrc 2012 

competition

    university of toronto (id98)
    university of tokyo             
    oxford university
    inria + xerox
    university of amsterdam

classification

classification
& localization
16.4%  
34.1%
26.1%            53.6%
26.9%            50.0%
27.0%
29.5% 

id98s for 
object 
detection 

and 

recognition

40

id98s for id164

id98s for scene parsing

sermanet, cvpr 2014

farabet, pami 2013

id98s for scene semantic labeling 

rgbd images

convolutional neural networks

farabet, 2013

41

id98s for image captioning:

microsoft   s captionbot

https://captionbot.ai

number recognition from google   s 

street view images

deep learning demos and startups
    clarifai

    http://www.clarifai.com

    dextro

    www.dextro.co

    microsoft   s captionbot

    https://www.captionbot.ai
    yann lecun   s digit recognizer

    http://yann.lecun.com/exdb/lenet/

    toronto deep learning demos

    http://deeplearning.cs.toronto.edu/

number recognition from google   s 

street view images

    training set:  200,000 images of (cropped) 

house numbers (up to 5 digits long)

    id98 with 11 hidden layers

    54 x 54 input image layer
    8 convolutional layers

    48 x 54 x 54 = 140,000 units at first hidden layer
    5 x 5 convolution kernels

    1 locally-connected hidden layer
    2 densely-connected hidden layers

    3,072 units in each

42

    training time:  6 days
    accuracy:  transcribed ~100 million numbers 
with ~98% accuracy (meaning all numbers in a 
sequence were recognized correctly) and 95% 
coverage

also have tried using a 1000-layer network!

deep residual learning for image recognition, k. he et al., proc. 
cvpr, 2016 (best paper award)

results on real video

(trained on 80 categories)

43

id98s for video classification

image style transfer using id98

i.31

[karpathy 2014] 

   image style transfer using convolutional neural 
networks,    l. gatys, cvpr 2015

snapchat   s paintbrush

44

google   s deepdream

current trend:  very deep networks 

(using deep residual learning)

input image

output image

current trend:  recurrent 

networks

    long short-term memory (lstm) neural nets

deep learning software

    caffe (berkeley)
    tensorflow (google)
    torch
    deeplearning4j
    opennn
    microsoft cognitive toolkit
    convnetjs
    etc.

45

