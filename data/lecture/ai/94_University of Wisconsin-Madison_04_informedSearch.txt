informed search

chapter 3.5     3.6, 4.1

informed search

    informed searches use domain knowledge

to guide selection of the best path to continue 
searching

    heuristics are used, which are informed guesses

    heuristic means "serving to aid discovery"

function uniform-cost-search (problem)
loop do
if empty?(frontier) then return failure
node = pop(frontier)
if goal?(node) then return solution(node)
insert node in explored
foreach child of node do
if child not in frontier or explored then
insert child in frontier
else if child in frontier with higher cost then
remove that old node from frontier
insert child in frontier

this is the algorithm in figure 3.14 in the textbook; note that if 
child is not in frontier but is in explored, this algorithm will 
throw away child

informed search

define a heuristic function, h(n)

    uses domain-specific information in some way
    is (easily) computable from the current state 

description 

    estimates

    the "goodness" of node n
    how close node n is to a goal
    the cost of minimal cost path from node n to a goal 
state

1

informed search

    h(n)     0
    h(n) close to 0 means we think n is close to a goal state
    h(n) very big means we think n is far from a goal state

for all nodes n

    all domain knowledge used in the search is encoded in 

the heuristic function, h

    an example of a    weak method    for ai because of the 

limited way that domain-specific information is
used to solve a problem (i.e., entirely contained in one 
function definition)  

best-first search

    sort nodes in the frontier list by increasing 
values of an evaluation function, f(n), that 
incorporates domain-specific information

    this is a generic way of referring to the class 

of informed search methods

greedy best-first search

greedy best-first search

    use as an evaluation function, f(n) = h(n), 
sorting nodes in the frontier by increasing 
values of f

    selects the node to expand that is believed 
to be closest (i.e., smallest f value) to a goal 
node

f(n) = h(n)
# of nodes tested: 0, expanded: 0
expnd. node frontier

{s:8}

s
h=8

5
b
h=4
4
g
h=0

8

5

c
h=3

1
a
h=8
7
e
h=   

9

3
d
h=   

2

greedy best-first search

greedy best-first search

f(n) = h(n)
# of nodes tested: 1, expanded: 1
expnd. node frontier

s not goal

{s:8}
{c:3,b:4,a:8}

s
h=8

5
b
h=4
4
g
h=0

8

5

c
h=3

1
a
h=8
7
e
h=   

9

3
d
h=   

f(n) = h(n)
# of nodes tested: 2, expanded: 2
expnd. node frontier

s
c not goal

{s:8}
{c:3,b:4,a:8}
{g:0,b:4,a:8}

s
h=8

5
b
h=4
4
g
h=0

8

5

c
h=3

1
a
h=8
7
e
h=   

9

3
d
h=   

greedy best-first search

greedy best-first search

f(n) = h(n)
# of nodes tested: 3, expanded: 2
expnd. node

s
c
g goal

frontier
{s:8}
{c:3,b:4,a:8}
{g:0,b:4, a:8}
{b:4, a:8} not expanded
3
d
h=   

s
h=8

5
b
h=4
4
g
h=0

8

5

c
h=3

1
a
h=8
7
e
h=   

9

f(n) = h(n)
# of nodes tested: 3, expanded: 2
expnd. node frontier

s
c
g

{s:8}
{c:3,b:4,a:8}
{g:0,b:4, a:8}
{b:4, a:8}

    fast but not optimal

s
h=8

5
b
h=4
4
g
h=0

8

5

c
h=3

1
a
h=8
7
e
h=   

9

3
d
h=   

path: s,c,g
cost: 13

3

example:  find path from s to g in 

state-space graph

    greedy best-first = ?

greedy best-first search

id125

    not complete
    not optimal/admissible
greedy search finds the left goal 
(solution cost of 7)
optimal solution is the path to the 
right goal (solution cost of 5)

s
h=5

2
b
h=4

d
h=1

2

1

g
goal

2
a
h=3

c
h=3

e
h=2

1

1

3

g
goal

    use an evaluation function f(n) = h(n) as in
greedy best-first search, and restrict the 
maximum size of the frontier to a constant, k
    only keep the k best nodes as candidates for 
expansion, and throw away the rest
    more space efficient than greedy best-first 

search, but may throw away a node on a solution 
path

    not complete
    not optimal/admissible

4

is algorithm a optimal?

h=6
a

5

1

s
h=7

3

g

h=0

admissible heuristics are good for 

playing the price is right

algorithm a search

    use as an evaluation function f(n) = g(n) + 
h(n), where g(n) is minimum cost path from 
start to current node n (as defined in ucs)
    the g term adds a    breadth-first component   

to the evaluation function
    nodes in frontier are ranked by the estimated 
cost of a solution, where g(n) is the cost from 
the start node to node n, and h(n) is the 
estimated cost from node n to a goal

algorithm id67

    use the same evaluation function used by algorithm a, 

except add the constraint that for all nodes n in the 
search space, h(n)     h*(n), where h*(n) is the actual
cost of the minimum-cost path from n to a goal

    the cost to the nearest goal is never over-estimated

    when h(n)     h*(n) holds true for all n, h is called an

admissible heuristic function 

    an admissible heuristic guarantees that a node on the 

optimal path cannot look so bad that it is never 
considered

5

algorithm id67

example

    complete
    optimal / admissible

h(n) f(n)
h(n) f(n)

h*(n)
h*(n)

n g(n)
n g(n)
s
s
a
a
b
b
c
c
d
d
e
e
g
g

s
h=8

5
b
h=4
4
g
h=0

8

5

c
h=3

1
a
h=8
7
e
h=   

9

3
d
h=   

g(n) = actual cost to get to node n

from start

example

example

h(n) f(n)

h*(n)

n g(n)
s 0
a
b
c
d
e
g

s
h=8

5
b
h=4
4
g
h=0

8

5

c
h=3

1
a
h=8
7
e
h=   

9

3
d
h=   

g(n) = actual cost to get to node n

from start

h(n) f(n)

h*(n)

n g(n)
s 0
a 1
b
c
d
e
g

s
h=8

5
b
h=4
4
g
h=0

8

5

c
h=3

1
a
h=8
7
e
h=   

9

3
d
h=   

g(n) = actual cost to get to node n

from start

6

example

example

h(n) f(n)

h*(n)

n g(n)
s 0
a 1
b 5
c 8
d
e
g

s
h=8

5
b
h=4
4
g
h=0

8

5

c
h=3

1
a
h=8
7
e
h=   

9

3
d
h=   

g(n) = actual cost to get to node n

from start

h(n) f(n)

h*(n)

n g(n)
s 0
a 1
b 5
c 8
d 1+3 = 4
e
g

s
h=8

5
b
h=4
4
g
h=0

8

5

c
h=3

1
a
h=8
7
e
h=   

9

3
d
h=   

g(n) = actual cost to get to node n

from start

example

example

h(n) f(n)

h*(n)

n g(n)
s 0
a 1
b 5
c 8
d 4
e 1+7 = 8
g

s
h=8

5
b
h=4
4
g
h=0

8

5

c
h=3

1
a
h=8
7
e
h=   

9

3
d
h=   

g(n) = actual cost to get to node n

from start

h(n) f(n)

h*(n)

n g(n)
s 0
a 1
b 5
c 8
d 4
e 8
g 10/9/13

s
h=8

5
b
h=4
4
g
h=0

8

5

c
h=3

1
a
h=8
7
e
h=   

9

3
d
h=   

g(n) = actual cost to get to node n

from start

7

example

h(n) f(n)

h*(n)

n g(n)
s 0
a 1
b 5
c 8
d 4
e 8
g 10/9/13

3
d
h=   
h(n) = estimated cost to get to a goal

from node n

s
h=8

5
b
h=4
4
g
h=0

8

5

c
h=3

1
a
h=8
7
e
h=   

9

example

h*(n)
h*(n)

h(n) f(n)
h(n) f(n)
n g(n)
n g(n)
s 0
s 0
8
8
a 1
a 1
8
b 5
b 5
4
c 8
c 8
3
   
d 4
d 4
e 8
   
e 8
g 10/9/13 0
g 10/9/13

3
d
h=   
h(n) = estimated cost to get to a goal

from node n

example

h*(n)
h*(n)

h(n) f(n)
n g(n)
h(n) f(n)
n g(n)
s 0
s 0
8
8
a 1
a 1
8
8
b 5
b 5
4
4
c 8
c 8
3
3
   
   
d 4
d 4
e 8
   
   
e 8
g 10/9/13 0
g 10/9/13 0

8
9
9
11
   
   
10/9/13

s
h=8

5
b
h=4
4
g
h=0

8

5

c
h=3

1
a
h=8
7
e
h=   

9

3
d
h=   

f(n) = g(n) + h(n)

actual cost to get from start to n
plus estimated cost from n to goal

example

h*(n)

h(n) f(n)
n g(n)
s 0
8
a 1
8
b 5
4
c 8
3
   
d 4
e 8
   
g 10/9/13 0

8
9
9
11
   
   
10/9/13

3
d
h=   
h*(n) = true cost of minimum-cost path

from n to a goal

s
h=8

5
b
h=4
4
g
h=0

8

5

c
h=3

1
a
h=8
7
e
h=   

9

s
h=8

5
b
h=4
4
g
h=0

8

5

c
h=3

1
a
h=8
7
e
h=   

9

8

example

example

h*(n)
9

h(n) f(n)
n g(n)
s 0
8
a 1
8
b 5
4
c 8
3
   
d 4
e 8
   
g 10/9/13 0

8
9
9
11
   
   
10/9/13

3
d
h=   
h*(n) = true cost of minimum-cost path

from n to a goal

s
h=8

5
b
h=4
4
g
h=0

8

5

c
h=3

1
a
h=8
7
e
h=   

9

h*(n)
9
9

h(n) f(n)
n g(n)
s 0
8
a 1
8
b 5
4
c 8
3
   
d 4
e 8
   
g 10/9/13 0

8
9
9
11
   
   
10/9/13

3
d
h=   
h*(n) = true cost of minimum-cost path

from n to a goal

example

example

h*(n)
9
9
4

h(n) f(n)
n g(n)
s 0
8
a 1
8
b 5
4
c 8
3
   
d 4
e 8
   
g 10/9/13 0

8
9
9
11
   
   
10/9/13

3
d
h=   
h*(n) = true cost of minimum-cost path

from n to a goal

s
h=8

5
b
h=4
4
g
h=0

8

5

c
h=3

1
a
h=8
7
e
h=   

9

h(n) f(n)
n g(n)
s 0
8
a 1
8
b 5
4
c 8
3
   
d 4
e 8
   
g 10/9/13 0

8
9
9
11
   
   
10/9/13

h*(n)
9
9
4
5

3
d
h=   
h*(n) = true cost of minimum-cost path

from n to a goal

s
h=8

5
b
h=4
4
g
h=0

8

5

c
h=3

1
a
h=8
7
e
h=   

9

s
h=8

5
b
h=4
4
g
h=0

8

5

c
h=3

1
a
h=8
7
e
h=   

9

9

example

example

h(n) f(n)
n g(n)
h(n) f(n)
n g(n)
s 0
s 0
8
8
a 1
a 1
8
8
b 5
b 5
4
4
c 8
c 8
3
3
   
   
d 4
d 4
e 8
   
   
e 8
g 10/9/13 0
g 10/9/13 0

h*(n)
h*(n)
9
9
8
8
9
9
9
9
4
4
9
9
5
5
11
11
   
   
   
   
   
   
10/9/13 0
10/9/13

3
d
h=   
h*(n) = true cost of minimum-cost path

from n to a goal

s
h=8

5
b
h=4
4
g
h=0

8

5

c
h=3

1
a
h=8
7
e
h=   

9

h(n) f(n)
n g(n)
s 0
8
a 1
8
b 5
4
c 8
3
   
d 4
e 8
   
g 10/9/13 0

h*(n)
9
8
9
9
4
9
5
11
   
   
   
   
10/9/13 0

optimal path = s,b,g
cost = 9

s
h=8

5
b
h=4
4
g
h=0

8

5

c
h=3

1
a
h=8
7
e
h=   

9

3
d
h=   

example

example:  find path from s to g

h*(n)
9
8
9
9
4
9
5
11
   
   
   
   
10/9/13 0

h(n) f(n)
n g(n)
s 0
8
a 1
8
b 5
4
c 8
3
   
d 4
e 8
   
g 10/9/13 0
since h(n)     h*(n) for all n,
h is admissible

s
h=8

5
b
h=4
4
g
h=0

8

5

c
h=3

1
a
h=8
7
e
h=   

9

3
d
h=   

10

    a* = ?

admissible heuristic functions, h

    8-puzzle example
5
3
8

example 
state

1
2
7

6
4

goal 
state

3
6

1
4
7

2
5
8

    which of the following are admissible heuristics?

h(n) = number of tiles in wrong position yes
h(n) = 0  yes, uniform-cost search
h(n) = 1  no, goal state
h(n) = sum of    manhattan distance    between 
each tile and its goal location yes

admissible heuristic functions, h

    8-puzzle example
5
3
8

example 
state

1
2
7

6
4

goal 
state

3
6

1
4
7

2
5
8

    which of the following are admissible heuristics?

h(n) = number of tiles in wrong position
h(n) = 0
h(n) = 1
h(n) = sum of    manhattan distance    between 
each tile and its goal location

note:  manhattan distance = l1 norm

admissible heuristic functions, h

which of the following are admissible heuristics?   

h(n) = h*(n)

h(n) = max(2, h*(n)) 

h(n) = min(2, h*(n))

h(n) = h*(n)     2
h(n) = h*(n)

11

admissible heuristic functions, h

which of the following are admissible heuristics?

h(n) = h*(n)

yes

h(n) = max(2, h*(n)) no

h(n) = min(2, h*(n)) yes

h(n) =     *(#)	

h(n) = h*(n) - 2
h(n) = h*(n)

no, possibly negative

no if h*(n)<1

a* revisiting states 

    one more complication:  a* might revisit a 
state (in frontier or explored), and discover 
a better path

1

1

s
h=1

b
h=1

c

h=900

2

1

999

d
h=1

g
h=0

    solution:  put d back in the priority queue, 

using the smaller g value (and path)

when should a* stop?

    a* should terminate only when a goal is 

removed from the priority queue

1

1

s
h=2

999

1

g
h=0

b
h=1

c
h=2

    same rule as for uniform-cost search (ucs)
    a* with h() = 0 is uniform-cost search

a and a* algorithm for 

general state-space graphs

frontier = {s} where s is the start node
explored ={}
loop do
if frontier is empty then return failure
pick node, n, with min f value from frontier
if n is a goal node then return solution
foreach each child, n   , of n do
then add n    to frontier
else add n    to frontier and remove m

if n    is not in explored or frontier
else if g(n   )     g(m) then throw n    away
remove n from frontier and add n to explored

variant of algorithm in fig. 3.14

note:  m is the node in frontier or 
explored that is the same state as n    

12

consistency

    a heuristic, h, is called consistent (aka monotonic) if, 

for every node n and every successor n    of n, the 
estimated cost of reaching the goal from n is no 
greater than the step cost of getting to n    plus the 
estimated cost of reaching the goal from n   :

c(n, n   )     h(n)     h(n   )
or, equivalently:  h(n)     c(n, n   ) + h(n   )

    triangle inequality for heuristics
    implies values of f along any path are nondecreasing
    when a node is expanded by a*, the optimal path to 

that node has been found

    consistency is a stronger condition than admissibility

id67

is h is admissible 

and/or 

consistent?

f(n) = g(n) + h(n)
# of nodes tested: 0, expanded: 0
expnd. 
node

frontier

{s:0+8}

s
h=8

5
b
h=4
4
g
h=0

8

5

c
h=3

1
a
h=8
7
e
h=   

9

3
d
h=   

h is consistent since h(s)     h(a) = 8     8     1, etc.
and therefore is also admissible

consistency

is this h consistent?

1

b
h=1

2

s
h=1

999

d
h=1

g
h=0

1

1

c

h=900

but h(c)     c(c,d) + h(d) since 
900     1 + 1, so h is not consistent  

h(c)=900, h(d)=1, c(c, d) = 1 

(but h is admissible)    

id67

f(n) = g(n) + h(n)
# of nodes tested: 1, expanded: 1
expnd. 
node

frontier

{s:8}

s not goal {a:1+8,b:5+4,c:8+3}

s
h=8

5
b
h=4
4
g
h=0

8

5

c
h=3

1
a
h=8
7
e
h=   

9

3
d
h=   

13

id67

id67

f(n) = g(n) + h(n)
# of nodes tested: 2, expanded: 2
expnd. 
node

frontier

{s:8}
{a:9,b:9,c:11}

s
a not goal {b:9,g:1+9+0,c:11,
d:1+3+   ,e:1+7+   }

s
h=8

5
b
h=4
4
g
h=0

8

5

c
h=3

1
a
h=8
7
e
h=   

9

3
d
h=   

f(n) = g(n) + h(n)
# of nodes tested: 3, expanded: 3
expnd. 
node

frontier

{s:8}
s
{a:9,b:9,c:11}
{b:9,g:10,c:11,d:   ,e:   }
a
b not goal {g:5+4+0,g:10,c:11,
d:   ,e:   }   replace

s
h=8

5
b
h=4
4
g
h=0

8

5

c
h=3

1
a
h=8
7
e
h=   

9

3
d
h=   

id67

id67

f(n) = g(n) + h(n)
# of nodes tested: 4, expanded: 3
expnd. 
node

frontier

s
a
b
g goal

{s:8}
{a:9,b:9,c:11}
{b:9,g:10,c:11,d:   ,e:   }
{g:9,c:11,d:   ,e:   }
{c:11,d:   ,e:   }
not expanded

s
h=8

5
b
h=4
4
g
h=0

8

5

c
h=3

1
a
h=8
7
e
h=   

9

3
d
h=   

f(n) = g(n) + h(n)
# of nodes tested: 4, expanded: 3
expnd. 
node

frontier

s
a
b
g

{s:8}
{a:9,b:9,c:11}
{b:9,g:10,c:11,d:   ,e:   }
{g:9,c:11,d:   ,e:   }
{c:11,d:   ,e:   }

s
h=8

5
b
h=4
4
g
h=0

8

5

c
h=3

1
a
h=8
7
e
h=   

9

3
d
h=   

    pretty fast and optimal

path: s,b,g
cost: 9

14

example:  find shortest route from 

arad to bucharest

oradea

71

zerind

151

140

75

arad

118

timisoara

111

70

75
drobeta

neamt

87

sibiu

80

99

fagaras

rimnicu vilcea

pitesti

211

101

138

lugoj

97

mehadia

146

120

craiova

85

bucharest

90
giurgiu

iasi
92

142

98

urziceni

vaslui

hirsova

86

eforie

heuristic:  straight-line distance 

to bucharest
234
neamt

71

374
75

380
oradea

zerind

151

140

arad
366
118

329

253
sibiu

99

176
fagaras

timisoara

111

70
241
75
drobeta
242

80
193

244
lugoj

rimnicu vilcea

100
pitesti

211

97

mehadia

146

101

120

138

craiova

160

87

226
iasi
92

199
vaslui

142

98

urziceni

151
hirsova

86

161

eforie

80
85

bucharest

90
giurgiu

77

15

visualizing search methods
    http://qiao.github.io/pathfinding.js/visual/

    bfs, ucs, greedy best-first, a*

16

proof of a* optimality

(by contradiction)

    let

g be the goal in the optimal solution
g2 be a sub-optimal goal found using a* where f(n) 
= g(n) + h(n), and h(n) is admissible
f* be the cost of the optimal path from start to g

    hence g(g2) > f*

that is, a* found a sub-optimal path (which it 
shouldn't)

proof of a* optimality

(by contradiction)

    f(g2)     f*
    g(g2) + h(g2)     f*
by the definition of f

    g(g2)     f*

because h(g2) = 0 since g2 is a goal node

    this contradicts the assumption that g2 was sub-

optimal, g(g2) > f*

    therefore, a* is optimal with respect to path cost; a* 

search never finds a sub-optimal goal

proof of a* optimality

(by contradiction)

    let n be some node on the optimal path but not on the 
    f(n)      f*

path to g2

by admissibility, since f(n) never overestimates the cost 
to the goal, it must be     the cost of the optimal path

since g2 was chosen from frontier rather than n for 
the sub-optimal goal to be found

    f(g2)     f(n)

    f(g2)     f*

combining equations

a* : the dark side

    a* can use lots of memory:

o(number of states)

    for really big search spaces, 
a* will run out of memory 

17

ida* :  memory-bounded search

    iterative-deepening a*
    cutoff based on f = g + h value rather than depth
    at each iteration do loop-avoiding dfs, not 

expanding any node with an f-value that exceeds 
current threshold

    at each iteration increase the f-value threshold by 
setting it to the smallest f-value of any node that 
exceeded the cutoff in the previous iteration

    complete
    optimal / admissible
    linear space required

devising heuristics

heuristics are often defined by relaxing the 
problem, i.e., computing the exact cost of a 
solution to a simplified version of the problem

    remove constraints

    8-puzzle:  each tile moves independently

    simplify problem

    8-puzzle:  1 move to get a tile from current position to 

goal position

    8-puzzle:  a tile can move to any adjacent position   

number of moves to get a tile to its goal position = 
manhattan distance (aka l1 distance)

comparing iterative deepening with a*

[from russell and norvig, fig 3.29]

devising heuristics

for 8-puzzle, average number of states 
expanded over 100 randomly chosen 
problems in which optimal path is 
length    

    4 steps     8 steps     12 steps

depth-first iterative deepening (ids)
id67 using    number of misplaced 
tiles    as the heuristic
a* using    sum of manhattan distances   
as the heuristic

112
13

12

6,300
39

25

3.6 x 106
227

73

    ideally, we want an admissible heuristic that is as close

to the actual cost without going over

    also, it must be relatively fast to compute

    trade off:

use more time to compute a complex heuristic versus
use more time to expand more nodes with a simpler 
heuristic

18

better heuristics

example: linear conflict

linear conflict heuristic for 8-puzzle:

    if 2 tiles are both in the same goal row but 

reversed positions, additional vertical moves 
should be added to the manhattan distance

3

1

1

3

manhattan distance is 2 + 2 = 4 moves

example: linear conflict

example: linear conflict

3 1

1

3

3

1

1

3

manhattan distance is 2 + 2 = 4 moves

manhattan distance is 2 + 2 = 4 moves

19

example: linear conflict

example: linear conflict

3
1

1

3

3

1

1

3

manhattan distance is 2 + 2 = 4 moves

manhattan distance is 2 + 2 = 4 moves

example: linear conflict

example: linear conflict

31

1

3

1

3

1

3

manhattan distance is 2 + 2 = 4 moves

6 moves required whereas manhattan distance is 2 + 2 = 4, so 
linear conflict heuristic adds 2 additional moves for this pattern

20

devising heuristics

devising heuristics

    if h(n) = h*(n) for all n,

    only nodes on optimal solution path are expanded
    no unnecessary work is performed

    if h(n) = 0 for all n,

    the heuristic is admissible
    a* performs exactly as uniform-cost search (ucs)

    the closer h is to h*,

the fewer extra nodes that will be expanded

devising heuristics

for an admissible heuristic
    h is frequently very simple
    therefore search resorts to (almost) ucs

through parts of the search space

if h1(n)     h2(n)     h*(n) for all n,  then                   
h2  dominates h1

    h2 is a better heuristic than h1
    a* using h1 (i.e., a1*) expands at least as many
if not more nodes than using a* with h2 (i.e., a2*)
    a2* is said to be better informed than a1* 

devising heuristics

    if optimality is not required, i.e., a satisficing 

solution is okay, 

    goal of the heuristic is then to get as close as 

possible, either under or over, to the actual cost

    it results in many fewer nodes being expanded 

than using a poor, but provably admissible, 
heuristic

21

devising heuristics

a* often suffers because it cannot venture 
down a single path unless it is almost 
continuously having success (i.e., h is 
decreasing);  any failure to decrease h will 
almost immediately cause the search to 
switch to another path

local searching (chapter 4.1)

systematic (global) searching:  search for a path
from start state to a goal state, then    execute    
solution path   s sequence of operators

    bfs, dfs, ids, ucs, greedy best-first, a, a*, etc.
    ok for small search spaces
    not okay for np-hard problems requiring 

exponential time to find the (optimal) solution

traveling salesperson problem (tsp)

traveling salesperson problem (tsp)

a salesperson wants to visit a list of cities

    stopping in each city only once
    (usually also must return to the first city)
    traveling the shortest distance
    f = total distance traveled

nodes are cities
arcs are labeled with distances 

between cities

adjacency matrix (notice the graph is 

fully connected):

5

a b c d e
a 0 5 8 9 7
b 5 0 6 5 5
c 8 6 0 2 3
d 9 5 2 0 4
e 7 5 3 4 0

b

5

5 city tsp
(not to scale)

a

6

9

7

5

2

8

c

3

d

e

4

22

traveling salesperson problem (tsp)

traveling salesperson problem (tsp)

a solution is a permutation of cities, 

called a tour

5 city tsp
(not to scale)

a b c d e
a 0 5 8 9 7
b 5 0 6 5 5
c 8 6 0 2 3
d 9 5 2 0 4
e 7 5 3 4 0

5

b

5

a

6

9

7

5

2

8

c

3

d

e

4

a solution is a permutation of cities, 

called a tour

e.g. a     b     c     d     e
assume tours can start at any

city and returns home at end

a b c d e
a 0 5 8 9 7
b 5 0 6 5 5
c 8 6 0 2 3
d 9 5 2 0 4
e 7 5 3 4 0

5 city tsp
(not to scale)

a

6

9

7

5

2

8

c

3

5

b

5

d

e

4

how would you solve tsp
using a or a* algorithm?

    how to represent a state?
    successor function?
    heuristics?

traveling salesperson problem (tsp)

classic np-hard problem

how many solutions exist?

n! where n = # of cities

n =   5 results in 120 tours
n = 10 results in 3,628,800 tours
n = 20 results in ~2.4*1018 tours

a b c d e
a 0 5 8 9 7
b 5 0 6 5 5
c 8 6 0 2 3
d 9 5 2 0 4
e 7 5 3 4 0

5 city tsp
(not to scale)

a

6

9

7

5

2

8

c

3

5

b

5

d

e

4

23

solving optimization problems 
using local search methods

now a different setting:

    each state s has a score or cost, f(s), that we can 

compute

    the goal is to find the state with the highest (or 
lowest) score, or a reasonably high (low) score

    we do not care about the path
    use variable-based models

    solution is not a path but an assignment of values 
for a set of variables

    enumerating all the states is intractable
    previous search algorithms are too expensive

other example problems

    n-queens

    place n queens on n x n checkerboard so that no 

queen can    capture    another

    f = number of conflicting queens

    boolean satisfiability

    given a boolean expression containing n boolean 

variables, find an assignment of {t, f} to each 
variable so that the expression evaluates to true
    (a (cid:2)   b (cid:2) c) (cid:1) (  a (cid:2) c (cid:2) d)
    f = number of satisfied clauses

traveling salesperson problem (tsp)

a solution is a permutation of cities, 

called a tour

e.g. a     b     c     d     e
assume tours can start at any

city and returns home at end

a b c d e
a 0 5 8 9 7
b 5 0 6 5 5
c 8 6 0 2 3
d 9 5 2 0 4
e 7 5 3 4 0

5 city tsp
(not to scale)

a

6

9

7

5

2

8

c

3

5

b

5

d

e

4

example problem:  chip layout

channel 
routing

lots of chip real estate

same connectivity, 
much less space

24

example problem:  scheduling

local searching

also:
parking lot layout, 
product design, aero-
dynamic design, 
   million queens    
problem, radiotherapy 
treatment planning,    

local searching

    local searching: every node is a solution
    operators/actions go from one solution to 

another

    can stop at any time and have a valid solution
    goal of search is to find a better/best solution

    no longer searching a state space for a solution 
path and then executing the steps of the solution 
path
    a* isn't a local search since it considers different 
partial solutions by looking at the estimated cost
of a solution path

    hard problems can be solved in polynomial 

time by using either an:
    approximate model:  find an exact solution

to a simpler version of the problem

    approximate solution:  find a non-optimal solution

to the original hard problem

    we'll explore ways to search through a 
solution space by iteratively improving
solutions until one is found that is optimal or 
near optimal

informal characterization

these are problems in which
    there is some combinatorial structure being 

optimized

    there is a cost function:  structure    real 

number, to be optimized, or at least a reasonable 
solution is to be found

    searching all possible structures is intractable
    there   s no known algorithm for finding the 

optimal solution efficiently

       similar    solutions have similar costs

25

local searching

    an operator/action is needed to transform 

one solution to another

    tsp: 2-swap operator

    take two cities and swap their positions in the tour
    a-b-c-d-e  with swap(a,d) yields d-b-c-a-e
    possible since graph is fully connected

    tsp: 2-interchange operator (aka 2-opt swap)

    reverse the path between two cities
    a-b-c-d-e with interchange(a,d) yields d-c-b-a-e

neighbors: tsp

    state: a-b-c-d-e-f-g-h-a
    f = length of tour
    2-interchange

a-b-c-d-e-f-g-h-a

flip

a-e-d-c-b-f-g-h-a

local searching

examples of neighborhoods

    those solutions that can be reached with one 
application of an operator are in the current 
solution's neighborhood (aka    move set   )

    local search considers next only those 

solutions in the neighborhood 

    the neighborhood should be much smaller

than the size of the search space
(otherwise the search degenerates)

    n-queens:  move queen in rightmost, most-
conflicting column to a different position in 
that column

    sat:  flip the assignment of one boolean 

variable

26

neighbors:  sat 

    state: (a=t, b=f, c=t, d=t, e=t)
    f = number of satisfied clauses
    neighbor:  flip the assignment of one variable

a       b     c
  a     c     d
b     d       e
  c       d       e
  a       c     e

(a=f, b=f, c=t, d=t, e=t)
(a=t, b=t, c=t, d=t, e=t)
(a=t, b=f, c=f, d=t, e=t)
(a=t, b=f, c=t, d=f, e=t)
(a=t, b=f, c=t, d=t, e=f)

hill-climbing (hc)

    question:  what   s a neighbor? 

    problem spaces tend to have structure.  a 
small change produces a neighboring state 
    the size of the neighborhood must be small 
enough for efficiency 
    designing the neighborhood is critical;  this is 
the real ingenuity     not the decision to use 
hill-climbing
    the best one (greedy)

    question: pick which neighbor?  
    question: what if no neighbor is better than the 
current state?  stop

local searching

    an evaluation function, f, is used to map each 

solution/state to a number corresponding to the 
quality/cost of that solution

    tsp: use the length of the tour;

a better solution has a shorter tour length

called hill-climbing (gradient ascent if continuous)

    maximize f:

    minimize f:

called or valley-finding (id119 if continuous)

    can be used to maximize/minimize some cost

hill-climbing algorithm

1. pick initial state s
2. pick t in neighbors(s) with the largest f(t)
3.
4. s = t.  goto step 2.

if f(t)     f(s) then stop and return s

    simple
    greedy 
    stops at a local maximum

27

hill-climbing (hc)

    hc exploits the neighborhood

    like greedy best-first search, it chooses what 

looks best locally

    but doesn't allow backtracking or jumping to an 

alternative path since there is no frontier list

    hc is very space efficient

    similar to id125 with a beam width of 1

    hc is very fast and often effective in practice

hill-climbing

visualized as a 2d surface
l height is quality/cost of solution   f = f(x, y)

f(x, y)

l solution space is a 2d 

surface

l initial solution is a point
l goal is to find highest point on 

the surface of solution space

l hill-climbing follows the 
direction of the steepest 
ascent, i.e., where f increases 
the most

x

y

local optima in hill-climbing
    useful mental picture:  f is a surface (   hills   ) in 

state space

global optimum, 
where we want to be

f

current state

state

    but we can   t see the entire landscape all at once.  
can only see a neighborhood;  like climbing in fog

f

fog

state

hill-climbing (hc)

solution found by hc is totally determined by 
the starting point;  its fundamental weakness is 
getting stuck:

f(y)

l at a local maximum
l at plateaus and ridges
global maximum may not be 
found
trade off:
greedily exploiting locality as in hc
vs. exploring state space as in bfs

y

28

hill-climbing with random restarts
very simple modification:

1. when stuck, pick a random new starting state 

and re-run hill-climbing from there

2. repeat this k times
3. return the best of the k local optima found

    can be very effective
    should be tried whenever hill-climbing is used
    fast, easy to implement;  works well for many 
applications where the solution space surface is not 
too    bumpy    (i.e., not too many local maxima)

variations on hill-climbing

    question: how do we make hill-climbing less 

greedy?
    stochastic hill-climbing

    randomly select among the neighbors
    the better, the more likely

    question: what if the neighborhood is too large to 

easily compute?  (e.g., n-queens and we need to pick 
both the column and the row within it)
    first-choice hill-climbing

    randomly generate neighbors, one at a time
    if neighbor is better, take the move

escaping local maxima

    hc gets stuck at a local maximum, limiting

the quality of the solution found

    two ways to modify hc:
1. choice of neighborhood
2. criterion for deciding to move to neighbor

    for example:

1. choose neighbor randomly
2. move to neighbor if it is better or, if it isn't, move 

with some id203, p

life lesson #237

sometimes one needs to temporarily step 
backward in order to move forward

lesson applied to iterative, local search:

    sometimes one needs to move to an 
inferior neighbor in order to escape a 
local optimum

29

hill-climbing example:  sat

i.e., a=true, 
b=false, etc.

5 clauses

5 boolean variables:  
a, b, c, d and e

variations on hill-climbing

walksat [selman, 1996]
1. pick a random unsatisfied clause
2. select and flip a variable from that clause:

    with prob. p, pick a random variable
    with prob. 1-p, pick variable that maximizes 

the number of satisfied clauses

3. repeat until solution found or max 

number of flips attempted

* this is the best known algorithm 
for satisfying boolean formulas

a       b     c
  a     c     d
b     d       e
  c       d       e
  a       c     e

simulated annealing
(stochastic hill-climbing)

1. pick initial state, s
2. randomly pick state t from neighbors of s
3. if f(t) better than f(s)

then s = t
else with small id203  s = t

// t better than s so move there

4. goto step 2 until some stopping criterion 

is met

simulated annealing

origin:

the annealing process of heated solids    
alloys manage to find a near global minimum 
energy state when heated and then slowly cooled

intuition:

by allowing occasional ascent in the 
search process, we might be able to 
escape the traps of local minima

introduced by nicholas metropolis 
in 1953

30

consequences of occasional bad moves

desired effect (when searching for a global minimum):

advantage

helps escape
local optima

disadvantage

but it might pass the global
optimum after reaching it 

idea 1:  use a 
small, fixed 
id203 
threshold, say, 
p = 0.1

control of annealing process

acceptance criterion at each step 
(metropolis criterion) in hill-climbing:

    let the performance change be  

   e = f(newnode)     f(currentnode)

    always accept an ascending step (i.e., better state)

0  de

    accept a descending step only if it passes a test 

based on two parameters,    e and t

escaping local optima
    modified hc can escape from a local 

optimum but
    the chance of making a bad move is the same

at the beginning of the search as at the end
    the magnitude of improvement, or lack of, is 

ignored

    fix by replacing fixed id203, p, that a 
bad move is accepted, with a id203 
that decreases as the search proceeds

    now as the search progresses, the chance of 

taking a bad move goes down

escaping local maxima

let    e = f(newnode)     f(currentnode)  <  0

p = e    e / t (boltzman's equation*)

    as    e    -   , p    0

idea:  p decreases 
as neighbor gets 
worse

i.e., as move gets worse,
id203 of taking it  decreases exponentially

    as t    0,  p    0

i.e., as    temperature,    t, decreases
id203 of taking bad move decreases

* or arrhenius's equation

31

id203 of moving to worse state

x < 0 is region of interest

escaping local maxima

let    e = f(newnode)     f(currentnode)

p = e    e / t
l    e  << t

if badness of move is small compared to t,
move is likely to be accepted

l    e  >> t

if badness of move is large compared to t,
move is unlikely to be accepted

control of annealing process

cooling schedule:

t, the annealing    temperature,    is the 
parameter that control the id203 of 
taking of bad steps

we gradually reduce the temperature, t(k)
at each temperature, the search is allowed 
to proceed for a certain number of steps, 
l(k)

( )
{
}klkt
( )
,
the choice of parameters
is called the cooling schedule

simple cooling schedules

t

t

iteration #

iteration #

32

simulated annealing
(stochastic hill-climbing)

pick initial state, s
k = 0
while k < kmax {

t = temperature(k)
randomly pick state t from neighbors of s
if f(t) > f(s) then s = t
else if (e(f(t)     f(s))/ t ) > random() then s = t
k = k +1
}

return s

what is the id203 of accepting each of the 
following moves assuming we are trying to 
maximize the evaluation function?

p = e  e/t where   e = f(successor)     f(current)

    f(current)=16, f(successor)=15,   e = -1, t=20, 

so p = 0.9512

    f(current)=25, f(successor)=13,   e = -12, t=25, 

so p = 0.6188

    f(current)=76, f(successor)=75,   e=-1, t=276, 

so p = 0.9964

    f(current)=1256, f(successor)=1378,   e=122, 

t=100, so p = 1

simulated annealing demo

searching for a global minimum

33

sa for solving tsp

tsp     4 algorithms

tour length comparison

    random tour:   327,452
    greedy best-first using closest next city:  

36,226

    local search using 2-interchange operator:  

31,887

    simulated annealing:  30,944

simulated annealing summary
    can perform multiple    worse    steps in a row 

to escape a local optimum

    chance of finding a global optimum increased
    fast

    only one neighbor generated at each iteration
    whole neighborhood isn't checked to find best 

neighbor as in hc

    usually finds a good quality solution in a very 

short amount of time

34

simulated annealing summary

requires several parameters to be set

    starting temperature

    must be high enough to escape local optima
but not too high to be random exploration of 
space

    cooling schedule

   

typically exponential
    halting temperature

implementation of simulated 

annealing

    this is a stochastic algorithm; the outcome may 

be different at different trials

    convergence to global optimum can only be 

realized in an asymptotic sense

    with an infinitely slow cooling rate, sa finds 

the global optimum with id203 1

simulated annealing issues
    neighborhood design is critical.  this is the real 

ingenuity

    evaluation function design is often critical
    annealing schedule is often critical
    what if approximate evaluation is cheaper than 

accurate evaluation? 

sa discussion

    simulated annealing is empirically much 
better at avoiding local maxima than hill-
climbing.  it is a successful, frequently-used, 
algorithm.  worth putting in your algorithmic 
toolbox.  

    sadly, not much opportunity to say anything 

formal about it  

    there are many practical, and problem-

specific, papers on improvements

35

summary

local searching

    iteratively improve solution

    nodes: complete solution
    arcs: operator changes to another solution
    can stop at any time
    technique suited for:

    hard problems, e.g., tsp
    optimization problems

summary

local searching

    f(n) evaluates quality of solution by weakly using 
domain knowledge
    hc: maximizes f(n), vf: minimizes f(n)

    solution found determined by starting point
    can get stuck, which prevents finding global 
optimum

    sa: explores, then settles down

    bad moves accepted with id203 that 
decreases as the search progress (t decreases) 
and with the badness of move (  e worsens)
    requires parameters to be set

36

