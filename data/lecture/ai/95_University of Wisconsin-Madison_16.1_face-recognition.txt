face detection and 

recognition 

face recognition problem 

reading:  chapter 18.10 
and, optionally, 
   face recognition using 
eigenfaces    by m. turk and 
a. pentland 

query image 

query face 

database 

face verification problem 

       face verification (1:1 matching) 

application:  access control 

       face recognition (1:n matching) 

www.viisage.com 

www.visionics.com 

biometric  authentication 

pay by selfie 

amazon, mastercard, 
alibaba developing 
methods 

application:  video surveillance 

application: autotagging photos in 
facebook, flickr, picasa, iphoto,     

face scan at airports 

www.facesnap.de 

iphoto 

       can be trained to recognize pets! 

http://www.maclife.com/article/news/iphotos_faces_recognizes_cats 

iphoto 

       things iphoto thinks are faces 

why is face recognition hard?  
the many faces of madonna 

recognition should be invariant to 

intra-class variability 

       faces  with  intra-subject  variations  in  pose,  illumination, 
expression, accessories, color, occlusions, and brightness  

       lighting variation
       head pose variation
       different expressions
       beards, disguises
       glasses, occlusion
       aging, weight gain
          

inter-class similarity 

       different people may have very similar appearance 

face detection in humans 

there are processes for face detection and 

recognition in the brain 

www.marykateandashley.com 

news.bbc.co.uk/hi/english/in_depth/americas/2000/
us_elections 

twins  

father and son  

blurred faces are recognizable 

blurred faces are recognizable 

upside-down faces are 

recognizable 

the    margaret thatcher illusion   , by peter thompson 

michael jordan, woody allen, goldie hawn, bill clinton, tom hanks, 
saddam hussein, elvis presley, jay leno, dustin hoffman, prince 
charles, cher, and richard nixon. the average recognition rate at this 
resolution is one-half.  

by l. harmon and b. julesz, scientific american,1973 

illumination and shading affect 

interpretation 

context is important 

p. sinha and t. poggio, i think i know that face, nature 384, 1996, 404. 

face recognition architecture 

face 
detection 

feature 
extraction 

classification 

face 
identity 

image 
window 

feature  
vector 

p. sinha and t. poggio, last but not least, perception 31, 2002, 133. 

image as a feature vector 

x 2 

x 3 

x 1 

dimensional    image space,    x         n 

       consider an n-pixel image to be a point in an n-

       each pixel value is a coordinate of x 
       preprocess images so faces are cropped and 

(roughly) aligned (position, orientation, and scale) 

key idea 

       expensive to compute nearest neighbor when 

each image is big (n dimensional space) 

 
       not all images are very likely     especially when 
we know that every image contains a face.  that 
is, images of faces are highly correlated, so 
compress them into a low-dimensional, linear 
subspace that retains the key appearance 
characteristics of people   s faces 

 {     j } is a set of training images of frontal faces 

nearest neighbor classifier 

 
id

i
)(

=

arg

dist

(

min
j

 
ir
),

j

i 

    1 

x 2 

x 1 

x 3 

    2 

eigenface representation 

       each face image is represented by a weighted (linear) 

combination of a small number of    component    or    basis    
faces 

       each of these basis faces is called an    eigenface    

eigenface representation 

       these basis faces can be weighted differently to represent 
       so, a vector of weights represents each face 

any face 

eigenfaces  (turk and pentland, 1991) 
       the set of training face images is clustered in a 

   subspace    of the set of all images 

       training phase 

      find best subspace to reduce the 
dimensionality 
      transform all training images into the 
subspace 

       testing phase 

      transform test image into the subspace and 
use a nearest-neighbor classifier to label it 

learning eigenfaces 

       how do we pick the set of basis faces? 
       we take a set of real training faces 
       find the set of basis faces that best 

represent the differences between the 
training faces 

       use a statistical criterion for quantifying 

the    best representation of the differences    

linear subspaces 

       suppose we have points in 2d and we have a 

line through that space 

 
       we can project each point onto that 1d line 
       represent a point by its position on the line 

linear subspaces 

id84 

convert x into v1, v2 coordinates: 
(assume v1 and v2 are orthogonal unit 
vectors) 

       distance to line defined by v1 

       what does the v2 coordinate measure? 
       what does the v1 coordinate measure? 

       distance from            on line defined by v1 

     x

coordinates (since v2 coordinates are all     0) 

       we can represent the orange points well with only their v1 
       this makes it much cheaper to store and compare points 
       a bigger deal for higher dimensional problems 

linear subspaces 

some lines will represent the data well and others 
not, depending on how well the projection 
separates the data points 

principal component analysis (pca) 
       problems arise when performing recognition in a high-

dimensional space (   curse of dimensionality   ) 

       significant improvements can be achieved by first 

mapping the data into a lower-dimensional subspace 

       the goal of pca is to reduce the dimensionality of 

the data while retaining the largest variations 
present in the original data 

principal component analysis (pca) 
      id84 implies information will 
be lost 
      how to determine the best lower dimensional 
subspace? 
      maximize information content in the 
compressed data by finding a set of k 
orthogonal vectors that account for as 
much of the data   s variance as possible 

       best dimension = direction in n-d with max variance 
       2nd best dimension = direction orthogonal to first with 

max variance 

       the covariance between two pixels expresses 

how correlated they are (i.e., to what degree 
they    co-vary   ) 

       the n x n covariance matrix for an image with n 

pixels expresses how correlated each pair of 
pixels is 

       the eigenvectors of this matrix with the largest 
eigenvalues correspond to the pixels in which 
the data varies the most 

principal component analysis (pca) 
       geometric interpretation 

       pca  projects the data along the directions where the data 

       the vectors define a new coordinate system in which to 

varies the most 

represent each image 

eigenvectors 

       an eigenvector is a vector, u, that satisfies 

u c=  
u
i

i

i

    where c is a square matrix, and    is a scalar 

 called the eigenvalue 

       example (for 2d data): 

c

=

32
   
   
12
   

   
   
   

u

=

3
2

   
   
   

   
   
   

   
   
   

2 3
2 1

3
2

   
   
   

   
   
   

   
    =
   

   
   
   

12
8

   
    = 4   
   

   
   
   

3
2

   
   
   

       so eigenvalue    = 4 for this eigenvector, u 

principal component analysis (pca) 

      the best low-dimensional space can be 
determined by the    best    eigenvectors of the 
covariance matrix of the data, i.e., the 
eigenvectors corresponding to the largest 
eigenvalues     also called    principal 
components    

      can be efficiently computed using the 
singular value decomposition (svd) 
algorithm 

algorithm 

       stack all training images together 

n x m 
matrix 

myyy=y

...

21

[

]

       compute the covariance matrix c: 
 

t

t

c

=

yy

1
   =
m

i

iyy
i

       each input image, xi , is an n-d column 
vector of all pixel values (in raster order) 
       compute    average face    image a from all 

m training images of all people: 

       normalize each training image, xi, by 
subtracting the average face: 

algorithm 

a

=

1
m

m

   

1
=

i

ix

y
i

=

x

   

i

a

algorithm 

       compute eigenvalues and eigenvectors of 

c by solving 

u c=  
u
i

i

i

 where the eigenvalues are 
n  

    
1
2

>>

...

>

 
 

 and the corresponding eigenvectors are 
 

 u1, u2,    , un 

 

algorithm 

algorithm 

       each ui is an n x 1 eigenvector called an 
   eigenface    (to be cute!) 
       each ui  is a vector/direction in    face 
space    
uw
nn

uwuwy
i
22

...
++

+

11
n

=
=    

x

i

uw
i

i

+

a

 
       image can be exactly reconstructed by a 

=1

i

linear combination of all eigenvectors 

eigenface representation 

each face image is represented by a weighted combination 
of a small number of    component    or    basis    faces 

w1 = 

w6 = 

       reduce dimensionality by using only the 
best k << n eigenvectors (i.e., the ones 
corresponding to the largest k eigenvalues 

x

k

       

uw
i

+

a

i

 
       each image xi is approximated by a set of 
k    weights    [wi1 , wi2,    , wik ] = wi   where 

=1

i

i

xuw
ij

(t
j

=

   

a
)

i

using eigenfaces 

       (approximate) reconstruction of an 
image of a face from a set of weights 

       recognition of a person from a new face 

image 

face image reconstruction 

reconstruction 

       face x in    face space    coordinates: 

 
 
 
 

= 

       reconstruction: 

= 

= 

^ x 

+ 

a       +    w1u1 + w2u2 + w3u3 + w4u4 +     

eigenfaces recognition algorithm 

modeling (training phase) 
 

1.    given a collection of labeled training images 
2.    compute mean image, a 
3.    compute k eigenvectors, u1 ,    , uk , of 

covariance matrix corresponding to k largest 
eigenvalues 

4.    project each training image, xi, to a point in      

k-dimensional    face space:    
xuw
for 
  
compute
  
   
=
ij
i
xi projects to wi = [wi1 , wi2,    , wik ]  

k
 
...,

 1,

=

t
j

(

j

a
)

the more eigenfaces you use, the better the reconstruction, 
but even a small number gives good quality for matching 

eigenfaces algorithm 

recognition (testing phase) 
 

1.    given a test image, g, project it into face space 

for 

j

=

 1,

k
 
...,

aguw
  
compute
)
  

(

   

=

t
j

j

2.    classify it as the class (person) that is closest to it 

(as long as its distance to the closest person is 
   close enough   ) 

choosing k 

eigenvalues 

i =  

k 

n (number of pixels) 

       how many eigenfaces to use? 
       look at the decay of the eigenvalues 

       the eigenvalue tells you the amount of variance    in 

the direction    of that eigenface 

       ignore eigenfaces with low variance 

example: training images 

note:  faces must 
be approximately 
registered 
(translation, 
rotation, size, 
pose)!   

[ turk & pentland, 2001] 

eigenfaces 

example 

training 
images 
 

average image, a 

7 eigenface images 

103 

example 

top eigenvectors: u1,   uk 

average: a 

104 

difficulties with pca 

       projection may suppress important details 

      smallest variance directions may not be 
unimportant 

       method does not take discriminative task 

into account 
      we want to compute features that allow good 
discrimination 
      not necessarily the same as largest variance 

experimental results 

       training set:  7,562 images of approximately 

       k = 20 eigenfaces computed from a sample of 

3,000 people 

128 images 

       test set accuracy on 200 faces was 95% 

limitations 

       pca assumes that the data has a gaussian 

distribution 

the shape of this dataset is not well described by its principal components 

limitations 

       background (de-emphasize the outside of the face     e.g., 
by multiplying the input image by a 2d gaussian window 
centered on the face) 

       lighting conditions (performance degrades with light 

changes) 

       scale (performance decreases quickly with changes to 

head size); possible solutions: 
       multi-scale eigenspaces 
       scale input image to multiple sizes 

       orientation (performance decreases but not as fast as 

with scale changes) 
       plane rotations can be handled 
       out-of-plane rotations are more difficult to handle 

limitations 
       not robust to misalignment 

111 

extension:  eigenfeatures 

       describe and 

encode a set of 
facial features: 
eigeneyes, 
eigennoses, 
eigenmouths 

 
       use for detecting 

facial features 

recognition 

using 

eigenfeatures 

