neural networks
deep learning - dif   culty of training

feedforward neural network
hugo larochelle

2

d  epartement d   informatique
universit  e de sherbrooke

hugo larochelle

d  epartement d   informatique
universit  e de sherbrooke

hugo.larochelle@usherbrooke.ca

hugo.larochelle@usherbrooke.ca

september 6, 2012

1

...

exp(ac )

exp(ac )

exp(ac )

exp(ac )

exp(ac )

exp(ac )

exp(ac )

    p(y = c|x)

september 6, 2012

    x1 xd b w1 wd
neural network
    w
    p(y = c|x)
    p(y = c|x)
    p(y = c|x)
    o(a) = softmax(a) =h exp(a1)
pc exp(ac)i>
    {
    o(a) = softmax(a) =h exp(a1)
pc exp(ac)i>
pc exp(ac) . . .
    o(a) = softmax(a) =h exp(a1)
pc exp(ac)i>
    p(y = c|x)
    o(a) = softmax(a) =h exp(a1)
pc exp(ac)i>
pc exp(ac) . . .
topics: multilayer neural network
pc exp(ac) . . .
pc exp(ac) . . .
    o(a) = softmax(a) =h exp(a1)
pc exp(ac)i>
    g(a) = a
    f (x)
    could have l hidden layers:
    f (x)
pc exp(ac) . . .
    p(y = c|x)
    p(y = c|x)
    f (x)
    p(y = c|x)
    f (x)
    h(1)(x) h(2)(x) w(1) w(2) w(3) b(1) b(2) b(3)
    g(a) = sigm(a) =
    o(a) = softmax(a) =h exp(a1)
pc exp(ac)i>
    h(1)(x) h(2)(x) w(1) w(2) w(3) b(1) b(2) b(3)
    o(a) = softmax(a) =h exp(a1)
pc exp(ac)i>
    layer input activation for k>0
pc exp(ac)i>
    o(a) = softmax(a) =h exp(a1)
1+exp( a)
    p(y = c|x)
    h(1)(x) h(2)(x) w(1) w(2) w(3) b(1) b(2) b(3)
    a(k)(x) = b(k) + w(k)h(k 1)x (h(0)(x) = x)
exp(ac )
pc exp(ac) . . .
    h(1)(x) h(2)(x) w(1) w(2) w(3) b(1) b(2) b(3)
    f (x)
pc exp(ac) . . .
pc exp(ac) . . .
    o(a) = softmax(a) =h exp(a1)
pc exp(ac)i>
    a(k)(x) = b(k) + w(k)h(k 1)(x) (h(0)(x) = x)
exp(a)+exp( a) = exp(2a) 1
    g(a) = tanh(a) = exp(a) exp( a)
    h(k)(x) = g(a(k)(x))
    f (x)
pc exp(ac) . . .
    a(k)(x) = b(k) + w(k)h(k 1)x (h(0)(x) = x)
1
    a(k)(x) = b(k) + w(k)h(k 1)x (h(0)(x) = x)
...
...
    h(1)(x) h(2)(x) w(1) w(2) w(3) b(1) b(2) b(3)
    p(y = c|x)
    p(y = c|x)
    f (x)
    h(l+1)(x) = o(a(l+1)(x)) = f (x)
    f (x)
    h(1)(x) h(2)(x) w(1) w(2) w(3) b(1) b(2) b(3)
    h(k)(x) = g(a(k)(x))
    o(a) = softmax(a) =h exp(a1)
pc exp(ac)i>
    p(y = c|x)
    h(k)(x) = g(a(k)(x))
    o(a) = softmax(a) =h exp(a1)
pc exp(ac)i>
    f (x)
    h(k)(x) = g(a(k)(x))
    g(a) = max(0, a)
pc exp(ac) . . .
    a(k)(x) = b(k) + w(k)h(k 1)x (h(0) = x)
    hidden layer activation (k from 1 to l):
    a(k)(x) = b(k) + w(k)h(k 1)x (h(0)(x) = x)
    h(1)(x) h(2)(x) w(1) w(2) w(3) b(1) b(2) b(3)
pc exp(ac) . . .
pc exp(ac)i>
    o(a) = softmax(a) =h exp(a1)
    h(1)(x) h(2)(x) w(1) w(2) w(3) b(1) b(2) b(3)
    h(1)(x) h(2)(x) w(1) w(2) w(3) b(1) b(2) b(3)
    h(l+1)(x) = o(a(l+1)(x)) = f (x)
    h(l+1)(x) = o(a(l+1)(x)) = f (x)
exp(ac )
    h(l+1)(x) = o(a(l+1)(x)) = f (x)
pc exp(ac) . . .
    h(k)(x) = g(a(k)(x))
    f (x)
    a(x) = b +pi wixi = b + w>x
1
...
...
    h(k)(x) = g(a(k)(x))
    g(a) = reclin(a) = max(0, a)
    a(k)(x) = b(k) + w(k)h(k 1)x (h(0)(x) = x)
    a(x) = b +pi wixi = b + w>x
    f (x)
    a(k)(x) = b(k) + w(k)h(k 1)x (h(0)(x) = x)
    a(k)(x) = b(k) + w(k)h(k 1)x (h(0) = x)
    h(l+1)(x) = o(a(l+1)(x)) = f (x)
    h(1)(x) h(2)(x) w(1) w(2) w(3) b(1) b(2) b(3)
    f (x)
    h(x) = g(a(x)) = g(b +pi wixi)
    h(k)(x) = g(a(k)(x))
    h(l+1)(x) = o(a(l+1)(x)) = f (x)
    h(x) = g(a(x)) = g(b +pi wixi)
    a(k)(x) = b(k) + w(k)h(k 1)x (h(0)(x) = x)
    h(k)(x) = g(a(k)(x))
    g(  ) b
    h(1)(x) h(2)(x) w(1) w(2) w(3) b(1) b(2) b(3)
    h(k)(x) = g(a(k)(x))
    output layer activation (k=l+1):
    h(1)(x) h(2)(x) w(1) w(2) w(3) b(1) b(2) b(3)
    h(k)(x) = g(a(k)(x))
    h(l+1)(x) = o(a(l+1)(x)) = f (x)
    h(l+1)(x) = o(a(l+1)(x)) = f (x)
1
...
...
    a(k)(x) = b(k) + w(k)h(k 1)x (h(0)(x) = x)
    w (1)
b(1)
    a(k)(x) = b(k) + w(k)h(k 1)x (h(0)(x) = x)
xj h(x)i
    x1 xd
    x1 xd
    h(l+1)(x) = o(a(l+1)(x)) = f (x)
    h(l+1)(x) = o(a(l+1)(x)) = f (x)
i
i,j
    h(k)(x) = g(a(k)(x))
    h(k)(x) = g(a(k)(x))
    w
    w
    h(x) = g(a(x))
    h(l+1)(x) = o(a(l+1)(x)) = f (x)
    h(l+1)(x) = o(a(l+1)(x)) = f (x)
    a(x) = b(1) + w(1)x    a(x)i = b(1)

math for my slides    feedforward neural network   .

abstract

exp(2a)+1

exp(ac )

exp(ac )

exp(ac )

i,j xj   

math for my slides    feedforward neural network   .

abstract

topics: why training is hard
    first hypothesis: optimization is harder
(under   tting)
    vanishing gradient problem
    saturated units block gradient 

propagation

    this is a well known problem in
recurrent neural networks

feedforward neural network
hugo larochelle

3

d  epartement d   informatique
universit  e de sherbrooke

hugo larochelle

d  epartement d   informatique
universit  e de sherbrooke

hugo.larochelle@usherbrooke.ca

hugo.larochelle@usherbrooke.ca

deep learning

1

...

...

    x1 xd b w1 wd
    w
    {
    g(a) = a
    g(a) = sigm(a) =
    g(a) = tanh(a) = exp(a) exp( a)
    g(a) = max(0, a)
1
    g(a) = reclin(a) = max(0, a)
    g(  ) b
...
    w (1)
b(1)
    x1 xd
i
    w
    h(x) = g(a(x))
    a(x) = b(1) + w(1)x    a(x)i = b(1)

    a(x) = b +pi wixi = b + w>x
    h(x) = g(a(x)) = g(b +pi wixi)

...
xj h(x)i
    x1 xd
    w

i,j

...

...

1

september 6, 2012

1+exp( a)
exp(a)+exp( a) = exp(2a) 1
...

exp(2a)+1

abstract

september 6, 2012

abstract

math for my slides    feedforward neural network   .

math for my slides    feedforward neural network   .

    a(x) = b +pi wixi = b + w>x
    h(x) = g(a(x)) = g(b +pi wixi)

1

i,j xj   

4

t pt r   l(f (x(t);    ), y(t))    r      (   )

deep learning

    l(f (x(t);    ), y(t))
       (   )
    l(f (x(t);    ), y(t))
    l(f (x(t);    ), y(t))
    l(f (x(t);    ), y(t))
      =   1
topics: why training is hard
       (   )
       (   )
       (   )
    l(f (x(t);    ), y(t))
    l(f (x(t);    ), y(t))
t pt r   l(f (x(t);    ), y(t))    r      (   )
t pt r   l(f (x(t);    ), y(t))    r      (   )
              +  
      =   1
      =   1
      =   1
    second hypothesis: over   tting
       (   )
       (   )
    {x 2 rd | rxf (x) = 0}
t pt r   l(f (x(t);    ), y(t))    r      (   )
              +  
              +  
              +  
t pt r   l(f (x(t);    ), y(t))    r      (   )
      =   1
    we are exploring a space of complex functions
      =   1
    v>r2
xf (x)v > 0 8v
    {x 2 rd | rxf (x) = 0}
    {x 2 rd | rxf (x) = 0}
    {x 2 rd | rxf (x) = 0}
              +  
    deep nets usually have lots of parameters
              +  
    v>r2
xf (x)v < 0 8v
    v>r2
    v>r2
    v>r2
xf (x)v > 0 8v
xf (x)v > 0 8v
xf (x)v > 0 8v
    {x 2 rd | rxf (x) = 0}
    might be in a high variance / low bias situation
    {x 2 rd | rxf (x) = 0}
      =  r   l(f (x(t);    ), y(t))    r      (   )
    v>r2
    v>r2
    v>r2
xf (x)v < 0 8v
xf (x)v < 0 8v
xf (x)v < 0 8v
    v>r2
xf (x)v > 0 8v
    v>r2
xf (x)v > 0 8v
    (x(t), y(t))
      =  r   l(f (x(t);    ), y(t))    r      (   )
      =  r   l(f (x(t);    ), y(t))    r      (   )
      =  r   l(f (x(t);    ), y(t))    r      (   )
    v>r2
xf (x)v < 0 8v
    v>r2
xf (x)v < 0 8v
possible
    f    f
    (x(t), y(t))
    (x(t), y(t))
    (x(t), y(t))
      =  r   l(f (x(t);    ), y(t))    r      (   )
      =  r   l(f (x(t);    ), y(t))    r      (   )
    f    f
    f    f
    f    f
    (x(t), y(t))
    (x(t), y(t))
possible
    f    f
possible
    f    f

t pt r   l(f (x(t);    ), y(t))    r      (   )

low variance/

high bias

good trade-off

high variance/

low bias

4

t pt r   l(f (x(t);    ), y(t))    r      (   )

deep learning

    l(f (x(t);    ), y(t))
       (   )
    l(f (x(t);    ), y(t))
    l(f (x(t);    ), y(t))
    l(f (x(t);    ), y(t))
      =   1
topics: why training is hard
       (   )
       (   )
       (   )
    l(f (x(t);    ), y(t))
    l(f (x(t);    ), y(t))
t pt r   l(f (x(t);    ), y(t))    r      (   )
t pt r   l(f (x(t);    ), y(t))    r      (   )
              +  
      =   1
      =   1
      =   1
    second hypothesis: over   tting
       (   )
       (   )
    {x 2 rd | rxf (x) = 0}
t pt r   l(f (x(t);    ), y(t))    r      (   )
              +  
              +  
              +  
t pt r   l(f (x(t);    ), y(t))    r      (   )
      =   1
    we are exploring a space of complex functions
      =   1
    v>r2
xf (x)v > 0 8v
    {x 2 rd | rxf (x) = 0}
    {x 2 rd | rxf (x) = 0}
    {x 2 rd | rxf (x) = 0}
              +  
    deep nets usually have lots of parameters
              +  
    v>r2
xf (x)v < 0 8v
    v>r2
    v>r2
    v>r2
xf (x)v > 0 8v
xf (x)v > 0 8v
xf (x)v > 0 8v
    {x 2 rd | rxf (x) = 0}
    might be in a high variance / low bias situation
    {x 2 rd | rxf (x) = 0}
      =  r   l(f (x(t);    ), y(t))    r      (   )
    v>r2
    v>r2
    v>r2
xf (x)v < 0 8v
xf (x)v < 0 8v
xf (x)v < 0 8v
    v>r2
xf (x)v > 0 8v
    v>r2
xf (x)v > 0 8v
    (x(t), y(t))
      =  r   l(f (x(t);    ), y(t))    r      (   )
      =  r   l(f (x(t);    ), y(t))    r      (   )
      =  r   l(f (x(t);    ), y(t))    r      (   )
    v>r2
xf (x)v < 0 8v
    v>r2
xf (x)v < 0 8v
possible
    f    f
    (x(t), y(t))
    (x(t), y(t))
    (x(t), y(t))
      =  r   l(f (x(t);    ), y(t))    r      (   )
      =  r   l(f (x(t);    ), y(t))    r      (   )
    f    f
    f    f
    f    f
    (x(t), y(t))
    (x(t), y(t))
possible
    f    f
possible
    f    f

t pt r   l(f (x(t);    ), y(t))    r      (   )

low variance/

high bias

good trade-off

high variance/

low bias

deep learning

5

topics: why training is hard
    depending on the problem, one or the other situation will 
tend to dominate

    if    rst hypothesis (under   tting): use better optimization

    this is an active area of research

    if second hypothesis (over   tting): use better id173

    unsupervised learning
    stochastic   dropout   training

