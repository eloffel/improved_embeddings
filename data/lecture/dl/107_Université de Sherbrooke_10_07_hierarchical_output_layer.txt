neural networks
natural language processing - hierarchical output layer

bengio, ducharme, vincent and jauvin

neural network language model 2
topics: neural network language model
    solution: model the conditional 
p(wt | wt   (n   1) , ... ,wt   1) 
with a neural network
    learn word representations
to allow transfer to id165s
not observed in training corpus 

i-th output = p(wt = i | context)

most  computation here

softmax

tanh

. . .

. . .

. . .

. . .

bengio, ducharme,
vincent and jauvin, 2003

. . .

c(wt n+1)
. . .
table
look   up
c
in

index for

wt n+1

. . .

c(wt 1)

c

c(wt 2)
. . .
matrix
shared parameters
across words
wt 2

index for

wt 1

index for

bengio, ducharme, vincent and jauvin

neural network language model 2
topics: neural network language model
    solution: model the conditional 
p(wt | wt   (n   1) , ... ,wt   1) 
with a neural network
    learn word representations
to allow transfer to id165s
not observed in training corpus 

i-th output = p(wt = i | context)

most  computation here

softmax

tanh

. . .

. . .

. . .

. . .

bengio, ducharme,
vincent and jauvin, 2003

. . .

c(wt n+1)
. . .
table
look   up
c
in

index for

wt n+1

. . .

c(wt 1)

c

c(wt 2)
. . .
matrix
shared parameters
across words
wt 2

index for

wt 1

index for

neural network language model 3
topics: hierarchical output layer
    example: [       the       ,        dog       ,        and       ,         the       ,         cat        ]

       the       
       dog       
        and       
        the        

.
.
.

.
.
.

p(       cat        | context) = 

1

2

3

4

5

6

7

       dog       

       the       

       and       

       cat       

       he       

       have       

       be       

       oov       

neural network language model 3
topics: hierarchical output layer
    example: [       the       ,        dog       ,        and       ,         the       ,         cat        ]

       the       
       dog       
        and       
        the        

p(       cat        | context) = 

.
.
.

.
.
.

v

1

2

3

4

5

6

7

       dog       

       the       

       and       

       cat       

       he       

       have       

       be       

       oov       

neural network language model 4
topics: hierarchical output layer
    example: [       the       ,        dog       ,        and       ,         the       ,         cat        ]

       the       
       dog       
        and       
        the        

p(       cat        | context) =  p(branch left at 1| context) 

x p(branch right at 2| context) 
x p(branch right at 5| context) 

.
.
.

.
.
.

v

1

2

3

4

5

6

7

       dog       

       the       

       and       

       cat       

       he       

       have       

       be       

       oov       

neural network language model 5
topics: hierarchical output layer
    example: [       the       ,        dog       ,        and       ,         the       ,         cat        ]

       the       
       dog       
        and       
        the        

.
.
.

.
.
.

p(       cat        | context) = (1-p(branch right at 1| context)) 
x p(branch right at 2| context) 
x p(branch right at 5| context) 

v

1

2

3

4

5

6

7

       dog       

       the       

       and       

       cat       

       he       

       have       

       be       

       oov       

neural network language model 6
topics: hierarchical output layer
    example: [       the       ,        dog       ,        and       ,         the       ,         cat        ]

       the       
       dog       
        and       
        the        

p(       cat        | context) =  (1 - sigm(b1 + v1,   h(x)))

x sigm(b2 + v2,   h(x))
x sigm(b5 + v5,   h(x))

.
.
.

.
.
.

v

1

2

3

4

5

6

7

       dog       

       the       

       and       

       cat       

       he       

       have       

       be       

       oov       

neural network language model 7
topics: hierarchical output layer
    how to de   ne the word hierarchy

    can use a randomly generated tree

-

this is likely to be suboptimal

    can use existing linguistic resources, such as id138
- hierarchical probabilistic neural network language model

morin and bengio, 2005
they report a speedup of 258x, with a slight decrease in performance
    can learn the hierarchy using a recursive partitioning strategy

-

- a scalable hierarchical distributed language model

mnih and hinton, 2008
similar speedup factors are reported, without a performance
decrease

-

neural network language model 7
topics: hierarchical output layer
    how to de   ne the word hierarchy

    can use a randomly generated tree

-

this is likely to be suboptimal

    can use existing linguistic resources, such as id138
- hierarchical probabilistic neural network language model

morin and bengio, 2005
they report a speedup of 258x, with a slight decrease in performance
    can learn the hierarchy using a recursive partitioning strategy

-

- a scalable hierarchical distributed language model

mnih and hinton, 2008
similar speedup factors are reported, without a performance
decrease

-

neural network language model 7
topics: hierarchical output layer
    how to de   ne the word hierarchy

    can use a randomly generated tree

-

this is likely to be suboptimal

    can use existing linguistic resources, such as id138
- hierarchical probabilistic neural network language model

morin and bengio, 2005
they report a speedup of 258x, with a slight decrease in performance
    can learn the hierarchy using a recursive partitioning strategy

-

- a scalable hierarchical distributed language model

mnih and hinton, 2008
similar speedup factors are reported, without a performance
decrease

-

neural network language model 7
topics: hierarchical output layer
    how to de   ne the word hierarchy

    can use a randomly generated tree

-

this is likely to be suboptimal

    can use existing linguistic resources, such as id138
- hierarchical probabilistic neural network language model

morin and bengio, 2005
they report a speedup of 258x, with a slight decrease in performance
    can learn the hierarchy using a recursive partitioning strategy

-

- a scalable hierarchical distributed language model

mnih and hinton, 2008
similar speedup factors are reported, without a performance
decrease

-

