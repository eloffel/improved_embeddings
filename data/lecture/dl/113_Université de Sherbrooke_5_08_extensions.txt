neural networks
restricted id82 - extensions

d  epartement d   informatique
universit  e de sherbrooke

restricted id82

hugo.larochelle@usherbrooke.ca

topics: rbm, visible layer, hidden layer, energy function

october 10, 2012

math for my slides    restricted id82s   .

    x(t)   log p(x(t))

energy function:

bj

bias

h
abstract
w connections

hidden layer
(binary units)

ck

x

visible layer
(binary units)

e(x, h) =  h>wx   c>x   b>h
wj,khjxk  xk

=  xj xk

ckxk  xj

bjhj

distribution: p(x, h) = exp( e(x, h))/z

p(x, h) = exp( e(x, h))/z

= exp(h>wx + c>x + b>h)/z

partition function

(intractable)

2

(1)
(2)

(3)
(4)

p(x, h) = exp( e(x, h))/z

topics: gaussian-bernoulli rbm
    inputs     are unbounded reals

    h1 h2 hh 1 hh
    x1 x2 xd
x

= exp(h>wx + c>x + b>h)/z
= exp(h>wx) exp(c>x) exp(b>h)/z

(= w         ehhrwe(x(t), h)   x(t)i   eh [rwe(  x, h)|  x ]   
w (= w +       h(x(t)) x(t)>   h(  x)   x>   
(= w +       h(x(t)) x(t)>   h(  x)   x>   
b (= b +       h(x(t))   h(  x)   
gaussian-bernoulli rbm
c (= c +       x(t)     x   
w (= w +       h(x(t)) x(t)>   h(  x)   x>   
b (= b +       h(x(t))   h(  x)   
c (= c +       x(t)     x   
zyj yk
yk
2 x>x
yj

    ||x(t)     x||2
    e(x, h) =  h>wx   c>x   b>h + 1
    ||x(t)     x||2
    only thing that changes is that            is now a gaussian distribution 
    e(x, h) =  h>wx   c>x   b>h + 1
p(x|h)
    p(x|h)    = c + wx
with mean                     and identity covariance matrix
    p(x|h)    = c + w>h
    recommended to normalize the training set by
- subtracting the mean of each input
- dividing each input       by the training set standard deviation

    add a quadratic term to the energy function

exp(wj,khjxk)

p(x, h) =

exp(ckxk)

exp(bjhj)

2 x>x

1

    ne(zi) zi xk hj

    should use a smaller learning rate than in the regular rbm

p(zi|z1, . . . , zv ) = p(zi|ne(zi))

2

=

p(zi, ne(zi))

2
p(z0i, ne(zi))

pz0i

3

(17)
(18)

(19)

(20)

(21)
(22)

0.3

0.2

0.1

0

0

1

0.9

0.8

0.7

0.6

0.5

0.4

0.3

0.2

0.1

0

0

filters

(larochelle et al., jmlr2009)

0.1

0.2

0.3

0.4

0.5

0.6

0.7

0.8

0.9

1

4

0.1

0.2

0.3

0.4

0.5

0.6

0.7

0.8

0.9

1

figure 12: input weights of a random subset of the hidden units, learned by an rbm with gaussian

other types of observations

5

topics: extensions to other observations
    extensions support other types:
    real-valued: gaussian-bernoulli rbm
    binomial observations:

- rate-coded restricted id82s for face recognition.

yee whye teh and geoffrey hinton, 2001

    multinomial observations:

- replicated softmax: an undirected topic model. 
ruslan salakhutdinov and geoffrey hinton, 2009

- training restricted id82s on word observations.

george dahl, ryan adam and hugo larochelle, 2012

    and more (see course website)

b (= b +       h(x(t))   h(  x)   
c (= c +       x(t)     x   

abstract
october 10, 2012

hugo.larochelle@usherbrooke.ca
abstract
october 10, 2012

october 10, 2012

hugo.larochelle@usherbrooke.ca

hugo.larochelle@usherbrooke.ca

abstract
math for my slides    restricted id82s   .

id82

math for my slides    restricted id82s   .

math for my slides    restricted id82s   .

abstract

abstract

math for my slides    restricted id82s   .

    x(t)   log p(x(t))
    h x

2 x>x
p(x, h) = exp( e(x, h))/z

abstract
math for my slides    restricted id82s   .

    x(t)   log p(x(t))
    x(t)   log p(x(t))
    ||x(t)     x||2
topics: id82
math for my slides    restricted id82s   .
    h x
    h x
    e(x, h) =  h>wx   c>x   b>h + 1
    the original id82 has lateral connections in 
    x(t)   log p(x(t))
    x(t)   log p(x(t))
    x(t)   log p(x(t))
p(x, h) = exp( e(x, h))/z
    p(x|h)    = c + w>h
each layer
= exp(h>wx + b>h + c>x)/z
    h x
    h x
    h x
= exp(h>wx) exp(b>h) exp(c>x)/z
...
    h1 h2 hh 1 hh
    h1 h2 hh 1 hh
    h1 h2 hh 1 hh
    x1 x2 xd
    x1 x2 xd
    x1 x2 xd
...
    h1 h2 hh 1 hh
    h1 h2 hh 1 hh
    h1 h2 hh 1 hh
    x1 x2 xd
    x1 x2 xd
    x1 x2 xd

= exp(h>wx + b>h + c>x)/z
= exp(h>wx + b>h + c>x)/z
= exp(h>wx) exp(b>h) exp(c>x)/z
= exp(h>wx) exp(b>h) exp(c>x)/z
p(x, h) = exp( e(x, h))/z
e(x, h) =  h>wx   c>x   b>h
= exp(h>wx + b>h + c>x)/z
= exp(h>wx) exp(b>h) exp(c>x)/z

= exp(h>wx + b>h + c>x)/z
= exp(h>wx + b>h + c>x)/z
= exp(h>wx) exp(b>h) exp(c>x)/z
= exp(h>wx) exp(b>h) exp(c>x)/z
x>vx  
 

p(x, h) = exp( e(x, h))/z

p(x, h) = exp( e(x, h))/z

p(x, h) = exp( e(x, h))/z

h>uh

1
2

1
2

2
    when only one layer has lateral connection, it   s a 
semi-restricted boltmann machine

6

(1)
(2)
(3)

b (= b +       h(x(t))   h(  x)   
c (= c +       x(t)     x   

abstract
october 10, 2012

hugo.larochelle@usherbrooke.ca
abstract
october 10, 2012

october 10, 2012

hugo.larochelle@usherbrooke.ca

hugo.larochelle@usherbrooke.ca

abstract
math for my slides    restricted id82s   .

id82

math for my slides    restricted id82s   .

math for my slides    restricted id82s   .

abstract

abstract

math for my slides    restricted id82s   .

    x(t)   log p(x(t))
    h x

2 x>x
p(x, h) = exp( e(x, h))/z

abstract
math for my slides    restricted id82s   .

    x(t)   log p(x(t))
    x(t)   log p(x(t))
    ||x(t)     x||2
topics: id82
math for my slides    restricted id82s   .
    h x
    h x
    e(x, h) =  h>wx   c>x   b>h + 1
    the original id82 has lateral connections in 
    x(t)   log p(x(t))
    x(t)   log p(x(t))
    x(t)   log p(x(t))
p(x, h) = exp( e(x, h))/z
    p(x|h)    = c + w>h
each layer
= exp(h>wx + b>h + c>x)/z
    h x
    h x
    h x
= exp(h>wx) exp(b>h) exp(c>x)/z
...
    h1 h2 hh 1 hh
    h1 h2 hh 1 hh
    h1 h2 hh 1 hh
    x1 x2 xd
    x1 x2 xd
    x1 x2 xd
...
    h1 h2 hh 1 hh
    h1 h2 hh 1 hh
    h1 h2 hh 1 hh
    x1 x2 xd
    x1 x2 xd
    x1 x2 xd

= exp(h>wx + b>h + c>x)/z
= exp(h>wx + b>h + c>x)/z
= exp(h>wx) exp(b>h) exp(c>x)/z
= exp(h>wx) exp(b>h) exp(c>x)/z
p(x, h) = exp( e(x, h))/z
e(x, h) =  h>wx   c>x   b>h
= exp(h>wx + b>h + c>x)/z
= exp(h>wx) exp(b>h) exp(c>x)/z

= exp(h>wx + b>h + c>x)/z
= exp(h>wx + b>h + c>x)/z
= exp(h>wx) exp(b>h) exp(c>x)/z
= exp(h>wx) exp(b>h) exp(c>x)/z
x>vx  
 

p(x, h) = exp( e(x, h))/z

p(x, h) = exp( e(x, h))/z

p(x, h) = exp( e(x, h))/z

h>uh

1
2

1
2

2
    when only one layer has lateral connection, it   s a 
semi-restricted boltmann machine

6

(1)
(2)
(3)

b (= b +       h(x(t))   h(  x)   
c (= c +       x(t)     x   

abstract
october 10, 2012

hugo.larochelle@usherbrooke.ca
abstract
october 10, 2012

october 10, 2012

hugo.larochelle@usherbrooke.ca

hugo.larochelle@usherbrooke.ca

abstract
math for my slides    restricted id82s   .

id82

math for my slides    restricted id82s   .

math for my slides    restricted id82s   .

abstract

abstract

math for my slides    restricted id82s   .

    x(t)   log p(x(t))
    h x

2 x>x
p(x, h) = exp( e(x, h))/z

abstract
math for my slides    restricted id82s   .

    x(t)   log p(x(t))
    x(t)   log p(x(t))
    ||x(t)     x||2
topics: id82
math for my slides    restricted id82s   .
    h x
    h x
    e(x, h) =  h>wx   c>x   b>h + 1
    the original id82 has lateral connections in 
    x(t)   log p(x(t))
    x(t)   log p(x(t))
    x(t)   log p(x(t))
p(x, h) = exp( e(x, h))/z
    p(x|h)    = c + w>h
each layer
= exp(h>wx + b>h + c>x)/z
    h x
    h x
    h x
= exp(h>wx) exp(b>h) exp(c>x)/z
...
    h1 h2 hh 1 hh
    h1 h2 hh 1 hh
    h1 h2 hh 1 hh
    x1 x2 xd
    x1 x2 xd
    x1 x2 xd
...
    h1 h2 hh 1 hh
    h1 h2 hh 1 hh
    h1 h2 hh 1 hh
    x1 x2 xd
    x1 x2 xd
    x1 x2 xd

= exp(h>wx + b>h + c>x)/z
= exp(h>wx + b>h + c>x)/z
= exp(h>wx) exp(b>h) exp(c>x)/z
= exp(h>wx) exp(b>h) exp(c>x)/z
p(x, h) = exp( e(x, h))/z
e(x, h) =  h>wx   c>x   b>h
= exp(h>wx + b>h + c>x)/z
= exp(h>wx) exp(b>h) exp(c>x)/z

= exp(h>wx + b>h + c>x)/z
= exp(h>wx + b>h + c>x)/z
= exp(h>wx) exp(b>h) exp(c>x)/z
= exp(h>wx) exp(b>h) exp(c>x)/z
x>vx  
 

p(x, h) = exp( e(x, h))/z

p(x, h) = exp( e(x, h))/z

p(x, h) = exp( e(x, h))/z

h>uh

1
2

1
2

2
    when only one layer has lateral connection, it   s a 
semi-restricted boltmann machine

6

(1)
(2)
(3)

