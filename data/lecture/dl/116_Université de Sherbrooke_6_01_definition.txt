neural networks
autoencoder - de   nition

unsupervised learning

2

math for my slides    restricted id82s   .

topics: unsupervised learning
    unsupervised learning: only use the inputs       for learning

    x(t)   log p(x(t))

    automatically extract meaningful features for your data
    leverage the availability of unlabeled data
    add a data-dependent regularizer to trainings

    we will see 3 neural networks for unsupervised learning

    restricted id82s
    autoencoders
    sparse coding model

hugo larochelle

math for my slides    autoencoders   .
d  epartement d   informatique
universit  e de sherbrooke

hugo larochelle

autoencoder
d  epartement d   informatique
universit  e de sherbrooke

hugo.larochelle@usherbrooke.ca

topics: autoencoder, encoder, decoder, tied weights
hugo.larochelle@usherbrooke.ca
    feed-forward neural network trained to reproduce its input at 
= sigm(b + wx)
october 17, 2012
the output layer

h(x) = g(a(x))

october 16, 2012
decoder

3

ck

 x

abstract

= w 
w 
(tied weights)

math for my slides    autoencoders   .

 
 
    f (x)    bx l(f (x)) =pk(bxk   xk)2

= sigm(c + w   h(x))

= sigm(b + wx)

h(x) = g(a(x))

bx = o(ba(x))

w

x

bj

abstract
= sigm(c + w   h(x))

bx = o(ba(x))
l(f (x)) =  pk (xk log(bxk) + (1   xk) log(1  bxk))

 
for binary inputs
encoder
h(x) = g(a(x))

= sigm(b + wx)

