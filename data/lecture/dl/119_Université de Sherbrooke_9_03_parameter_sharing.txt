neural networks
id161 - parameter sharing

id161

2

topics: id161
    we can design neural networks that are speci   cally adapted 
for such problems
    must deal with very high-dimensional inputs 

- 150 x 150 pixels = 22500 inputs, or 3 x 22500 if rgb pixels

    can exploit the 2d topology of pixels (or 3d for video data)
    can build in invariance to certain variations we can expect 

-

translations, illumination, etc.

    convolutional networks leverage these ideas

    local connectivity
    parameter sharing
    pooling / subsampling hidden units

id161

3

topics: parameter sharing
    second idea: share matrix of parameters across certain units

    units organized into the same       feature map       share parameters
    hidden units within a feature map cover different positions in the image 

feature map 1
...
...

feature map 2
...
...

feature map 3
...
...

same color

= 

same matrix
of connections

6

id161

3

topics: parameter sharing
    second idea: share matrix of parameters across certain units

    units organized into the same       feature map       share parameters
    hidden units within a feature map cover different positions in the image 

feature map 1
...
...

feature map 2
...
...

feature map 3
...
...

same color

= 

same matrix
of connections

6

id161

3

topics: parameter sharing
    second idea: share matrix of parameters across certain units

    units organized into the same       feature map       share parameters
    hidden units within a feature map cover different positions in the image 

feature map 1
...
...

feature map 2
...
...

feature map 3
...
...

same color

= 

same matrix
of connections

6

id161

3

topics: parameter sharing
    second idea: share matrix of parameters across certain units

    units organized into the same       feature map       share parameters
    hidden units within a feature map cover different positions in the image 

feature map 1
...
...

feature map 2
...
...

feature map 3
...
...

same color

= 

same matrix
of connections

6

id161

3

topics: parameter sharing
    second idea: share matrix of parameters across certain units

    units organized into the same       feature map       share parameters
    hidden units within a feature map cover different positions in the image 

feature map 1
...
...

feature map 2
...
...

feature map 3
...
...

same color

= 

same matrix
of connections

wij is the matrix 
connecting the ith 
input channel with 
the jth feature map
6

id161

4

topics: parameter sharing
    solves the following problems:

    reduces even more the number of parameters
    will extract the same features at every position (features are       equivariant      )

feature map 1
...
...

feature map 2
...
...

feature map 3
...
...

same color

= 

same matrix
of connections

wij is the matrix 
connecting the ith 
input channel with 
the jth feature map

id161
jarret et al. 2009

math for my slides    id161   .

topics: parameter sharing
    each feature map forms a 2d grid of features

november 8, 2012

5

abstract

    h x    

    can be computed with a discrete convolution (   ) of a kernel matrix kij which is

the hidden weights matrix wij with its rows and columns    ipped

filter bank layer - fid19: the input of a    lter bank
layer is a 3d array with n1 2d feature maps of size n2    n3.
each component is denoted xijk, and each feature map is
denoted xi. the output is also a 3d array, y composed of
m1 feature maps of size m2    m3. a    lter in the    lter bank
kij has size l1    l2 and connects input feature map xi to
output feature map yj. the module computes:

    xi is the ith channel of input
    kij is the convolution kernel
    gj is a learned scaling factor
    yj is the hidden layer 

   (could have added a bias)

r
e 

at
u

p
s

fe

a

m

figure 1. a example of feature extraction stage of the type fid19   
rabs     n     pa. an input image (or a feature map) is passed
through a non-linear    lterbank, followed by recti   cation, local
contrast id172 and spatial pooling/sub-sampling.

yj = gj tanh(!
i

kij     xi)

figure 1. a example of feature extraction stage of the type fid19   

layer with 4x4 down-sampling is denoted: p 4  4
max-pooling and subsampling layer - pm : building lo-

(1)

