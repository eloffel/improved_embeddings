neural networks
sparse coding - relationship with v1

relationship with v1

b

2

previous theoretical work has shown that neurons in the primary
visual cortex form an efficient code adapted to the statistics of natural
images16,17, but this says nothing about how neurons generalize across

c
    small image regions extracted from an image of nature (forest, grass, ...)

c

images, the model generalizes by learning a compact set of dictionary
sent a model in which neural activity encodes the id203 distri-
elements for image distributions typically encountered in natural
bution most consistent with a given image. trained on natural
scenes. model neurons show a diverse range of properties observed
images, the model generalizes by learning a compact set of dictionary
in cortical cells. these results provide a new functional explanation
elements for image distributions typically encountered in natural
for nonlinear effects in complex cells3   6 and offer insight into coding
scenes. model neurons show a diverse range of properties observed
in cortical cells. these results provide a new functional explanation
as we scan across a complex natural scene, fixations at multiple
for nonlinear effects in complex cells3   6 and offer insight into coding
locations (for example, on the trunk of a tree or along its edge)
produce a coherent percept of the underlying structure (the bark
as we scan across a complex natural scene, fixations at multiple
texture or the contour of the edge), even though individual images
locations (for example, on the trunk of a tree or along its edge)
collected at the retina are inherently highly variable. figure 1 illus-
produce a coherent percept of the underlying structure (the bark
trates the problem our brain solves so effortlessly: perceptually dis-
texture or the contour of the edge), even though individual images
tinct image regions produce response patterns that are highly
collected at the retina are inherently highly variable. figure 1 illus-
overlapping and cannot be easily distinguished using low-level, linear
trates the problem our brain solves so effortlessly: perceptually dis-
representations. what sort of computations are required to achieve
tinct image regions produce response patterns that are highly
overlapping and cannot be easily distinguished using low-level, linear
early visual neurons are typically described as linear feature detec-
representations. what sort of computations are required to achieve
tors1,2. models developed around this idea can accurately capture the
behaviour of neurons from the retina7 to simple cells in the cortex8
early visual neurons are typically described as linear feature detec-
but, as the examples in fig. 1 illustrate, neither individual features nor
tors1,2. models developed around this idea can accurately capture the
linear transformations can reliably discriminate images of one struc-
behaviour of neurons from the retina7 to simple cells in the cortex8
ture from another. more abstract features are presumably computed
but, as the examples in fig. 1 illustrate, neither individual features nor
in later stages of the visual system, but our knowledge of processing
linear transformations can reliably discriminate images of one struc-

a fundamental function of the visual system is to encode the build-
ing blocks of natural scenes   edges, textures and shapes   that sub-
recognition and scene
understanding. essential to this process is the formation of abstract
representations that generalize from specific instances of visual
input. a common view holds that neurons in the early visual system
signal conjunctions of image features1,2, but how these produce
invariant representations is poorly understood. here we propose that
to generalize over similar images, higher-level visual neurons encode
statistical variations that characterize local image regions. we pre-
sent a model in which neural activity encodes the id203 distri-
bution most consistent with a given image. trained on natural
images, the model generalizes by learning a compact set of dictionary
elements for image distributions typically encountered in natural
scenes. model neurons show a diverse range of properties observed
in cortical cells. these results provide a new functional explanation
for nonlinear effects in complex cells3   6 and offer insight into coding
strategies in primary visual cortex (v1) and higher visual areas.

signal conjunctions of image features1,2, but how these produce
representations that generalize from specific instances of visual
invariant representations is poorly understood. here we propose that
input. a common view holds that neurons in the early visual system
to generalize over similar images, higher-level visual neurons encode
signal conjunctions of image features1,2, but how these produce
statistical variations that characterize local image regions. we pre-
invariant representations is poorly understood. here we propose that
sent a model in which neural activity encodes the id203 distri-
to generalize over similar images, higher-level visual neurons encode
topics: v1 neurons vs. sparse coding
bution most consistent with a given image. trained on natural
statistical variations that characterize local image regions. we pre-
images, the model generalizes by learning a compact set of dictionary
sent a model in which neural activity encodes the id203 distri-
    natural image patches:
elements for image distributions typically encountered in natural
bution most consistent with a given image. trained on natural
scenes. model neurons show a diverse range of properties observed
images, the model generalizes by learning a compact set of dictionary
in cortical cells. these results provide a new functional explanation
elements for image distributions typically encountered in natural
for nonlinear effects in complex cells3   6 and offer insight into coding
scenes. model neurons show a diverse range of properties observed
strategies in primary visual cortex (v1) and higher visual areas.
in cortical cells. these results provide a new functional explanation
as we scan across a complex natural scene, fixations at multiple
for nonlinear effects in complex cells3   6 and offer insight into coding
locations (for example, on the trunk of a tree or along its edge)
strategies in primary visual cortex (v1) and higher visual areas.
produce a coherent percept of the underlying structure (the bark
as we scan across a complex natural scene, fixations at multiple
texture or the contour of the edge), even though individual images
locations (for example, on the trunk of a tree or along its edge)
collected at the retina are inherently highly variable. figure 1 illus-
produce a coherent percept of the underlying structure (the bark
trates the problem our brain solves so effortlessly: perceptually dis-
texture or the contour of the edge), even though individual images
tinct image regions produce response patterns that are highly
collected at the retina are inherently highly variable. figure 1 illus-
overlapping and cannot be easily distinguished using low-level, linear
trates the problem our brain solves so effortlessly: perceptually dis-
representations. what sort of computations are required to achieve
tinct image regions produce response patterns that are highly
generalization across natural stimuli?
overlapping and cannot be easily distinguished using low-level, linear
early visual neurons are typically described as linear feature detec-
representations. what sort of computations are required to achieve
tors1,2. models developed around this idea can accurately capture the

a

a

b

c

c

figure 1 | statistical patterns distinguish local regions of natural scenes.
a, a natural scene with four distinct regions outlined (image courtesy of
image taken from:
e. doi). b, the scatter plot shows the joint output of a pair of linear feature
figure 1 | statistical patterns distinguish local regions of natural scenes.
 emergence of complex cell properties 
detectors (oriented gabor filters) for 20 3 20-image patches sampled from
a, a natural scene with four distinct regions outlined (image courtesy of
 by learning to generalize in natural scenes.
the four regions. the outputs from different regions are highly overlapping,
e. doi). b, the scatter plot shows the joint output of a pair of linear feature
 karklin and lewicki, 2009
indicating that linear features provide no means to distinguish between the
detectors (oriented gabor filters) for 20 3 20-image patches sampled from
regions. c, each column shows the joint output of a different pair of linear

c

figure 1 | statistical patterns distinguish local regions of natural scenes.

relationship with v1

3

topics: v1 neurons vs. sparse coding
    when trained on natural image patches

    the dictionary columns 
(      atoms      ) look like edge 
detectors
    each atom is tuned to a
particular position, orientation
and spatial frequency
    v1 neurons in the mammalian
brain have a similar behavior

emergence of simple-cell receptive    eld properties 
by learning a sparse code of natural images.
olshausen and field, 1996.

relationship with v1

4

topics: v1 neurons vs. sparse coding
    suggests that the brain
might be learning a sparse
code of visual stimulus

    since then, many other
models have been shown
to learn similar features
    they usually all incorporate
a notion of sparsity

emergence of simple-cell receptive    eld properties 
by learning a sparse code of natural images.
olshausen and field, 1996.

