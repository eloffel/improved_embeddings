ttic 31230, fundamentals of deep learning

david mcallester, winter 2018

convolutional neural networks     id98s

1

id163 classi   cation. 1000 kinds of objects.

id98s

2016 error rate is 3.0%

2017 error rate is 2.25%

a convolution slides a    lter (a kernel) across an image.

a id98

w

x

y

river trail documentation

y[b, i, j, cy] = w [   i,    j, cx, cy]x[b, i +    i, j +    j, cx]

y[b, i, j, cy] += b[cy]

3

use swap rule to get backward method

y[b, i, j, cy] = w [   i,    j, cx, cy]x[b, i +    i, j +    j, cx]

w.grad[   i,    j, cx, cy] += y.grad[b, i, j, cy]x[b, i +    i, j +    j, cx]

x.grad[b, i+   i, j+   j, cx] += w [   i,    j, cx, cy]y.grad[b, i, j, cy]

4

a convolution class in edf

in edf we would de   ne a class for convolution parameter
packages.

we would then construct the computation node for the output
using python code.

y = relu(conv(phi,x)).

5

padding

jonathan hui

if we pad the input with zeros then the input and output can
have the same spatial dimensions.

6

zero padding in numpy

in numpy we can add a zero padding of width p to an image
as follows:

padded = np.zeros(w + 2*p, h + 2*p)

padded[p:w+p, p:h+p] = x

7

padding

let x(cid:48) (full square) be the padding of x (blue square). y also
has the blue shape.

jonathan hui

y[b, i, j, cy] = w [   i,    j, cx, cy]x(cid:48)[b, i +    i, j +    j, cx] + b[cy]

for padding p and a    lter of width 2p + 1, we get that y has
the same spatial dimensions as x.

8

strides

we can move the    lter by a    stride    s for each spatial step.

y[b, i, j, cy] = w [   i,    j, cx, cy]x[b, s     i +    i, s     j +    j, cx] + b[cy]

9

max pooling

y[b, i, j, c] = max
   i,   j

x[b, s     i +    i, s     j +    j, c]

this is typically done with a stride greater than one so that
the image dimension is reduced.

10

fully connected (fc) layers

we reshape x[b, x, y, c] to x[b, (x, y, c)] and convert to using
an mlp.

11

basics

    padding

    convolution

    stides

    max pooling

    fully connected layers

12

a sequence of    images   

jonathan hui

13

alexnet

stanford cs231

14

vgg, zisserman, 2014

davi frossard

15

vgg

stanford cs231

16

inception, google, 2014

17

id163 classi   cation

1000 kinds of objects.

2016 error rate is 3.0%

2017 error rate is 2.25%

appendix: image to column (im2c)

reduce convolution to id127     more space but
faster.

x(cid:48)[b, i, j,    i,    j, cx] = x[b, i +    i, j +    j, cx]

y[b, i, j, cy]

   i,   j,cx

       (cid:88)
       (cid:88)
       (cid:88)

   i,   j,cx

(   i,   j,cx)

=

=

=

w [   i,    j, cx, cy]     x[b, i +    i, j +    j, cx]

x(cid:48)[b, i, j,    i,    j, cx]     w [   i,    j, cx, cy]

x(cid:48)[(b, i, j), (   i,    j, cx)]     w [(   i,    j, cx), cy]

       + b[cy]
       + b[cy]
       + b[cy]

appendix: dilation

we can    dilate    the    lter by introducing an image step size d
for each step in the    lter coordinates.

y[b, i, j, cy] = w [   i,    j, cx, cy]x[b, i + d        i, j + d        j, cx] + b[cy]

end

