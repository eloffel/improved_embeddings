ttic 31230, fundamentals of deep learning

david mcallester, winter 2018

id5

1

the latent variable cross-id178 objective

we will now drop the negation and switch to argmax.

ey   pop ln q  (y)

      = argmax

  

q  (y) =

(cid:88)

q  (  z, y)

  z

eg identity:

      ln q  (y) = e  z   q  (  z|y)       ln q  (  z, y)

2

id5

      ln q  (y) = e  z   q  (  z|y)       ln q  (  z, y)

except for directed tree models, this gradient must be approx-
imated     exact computation is #-p hard.

id5 approximate q  (  z|y) with a model
supporting easy sampling of   z.

3

generative models

a model for which sampling is easy will be called generative.

in id5 we assume that q  (y|  z) is gener-
ative but that q  (  z|y) is not     that sampling from q  (  z|y)
is hard.

we approximate q  (  z|y) with a generative model.

4

generation replaces search

   generation replaces search    can be viewed as a general prin-
ciple of deep leaning.

rather than search for a   z that generates y we strive to directly
calculate     to generate     a   z that generates y.

   generation replaces search    is exempli   ed in current parsing
architectures.

5

id5

      ln q  (y) = e  z   q  (  z|y)       ln q  (  z, y)

     ,       = argmax

  ,  

ey   pop e  z   p  (  z|y) ln q  (  z, y) + h(p  (  z|y))

here p  (  z|y) is a generative approximation of q  (  z|y).

the quantity being optimized is called the evidence lower bound
(elbo).

6

id5

      ln q  (y) = e  z   q  (  z|y)       ln q  (  z, y)

     ,       = argmax

  ,  

= argmax

  ,  

ey   pop e  z   p  (  z|y) ln q  (  z, y) + h(p  (  z|y))
ey   pop ln q  (y)     kl(p  (  z|y), q  (  z|y))

the equivalence of the two elbo expressions is proved below.
the    rst expression supports sgd training through sampling.
the second expression establishes that the elbo is a lower
bound on the    evidence    ln q  (y) and that p  (  z|y) should
approximate q  (  z|y).

7

derivation of equivalence i

e  z   p  (  z|y) ln q  (  z, y)

= e  z   p  (  z|y) ( ln q  (y) + ln q  (  z|y) )
= ln q  (y) + e  z   p  (  z|y) ln q  (  z|y)
= ln q  (y)     h(p  (  z|y), q  (  z|y))

8

derivation of equivalence ii

e  z   p  (  z|y) ln q  (  z, y) + h(p  (  z|y))

= ln q  (y)     h(p  (  z|y), q  (  z|y)) + h(p  (  z|y))
= ln q  (y)     kl(p  (  z|y), q  (  z|y))

9

em is alternating optimization of the elbo

e  z   p  (  z|y) ln q  (  z, y) + h(p  (  z|y))

= ln q  (y)     kl(p  (  z|y), q  (  z|y))

(1)

(2)

by (2)       = argmin

  

by (1)       = argmax

  

ey   pop kl(p  (  z|y), q  (  z|y))

ey   pop e  z   p  (  z|y) ln q  (  z, y)

em:   t+1 = argmax   ey   pop e  z   q  t(  z|y)

log q  (  z, y)

10

the reparameterization trick

      = argmax

  

ey   pop e  z   p  (  z|y) ln q  (  z, y) + h(p  (  z|y))

how do we di   erentiate the sampling?

11

the reparameterization trick

      = argmax

  

ey   pop e  z   p  (  z|y) ln q  (  z, y) + h(p  (  z|y))

we note that in practice all sampling is computed by a deter-
ministic function of (pseudo) random numbers.

we can make this explicit.
model p  (  z|y) by       noise,   z =   z  (y,  )

12

the reparameterization trick

      = argmax

  

ey   pop e    noise ln q  (  z  (y,  ), y) + h(p  (  z|y))

h(p  (  z|y)) = e    noise ln p  (  z  (y,  )|y)
for vaes we typically we have   z(y,  )     rd with
  z(y,  )[i] =     (y)[i] +     (y)[i]  [i]

 [i]     n (0, 1)

this supports easy calculation of p  (  z  (y,  )|y).

13

decoding with l2 distortion

an autoencoder encodes and decodes.

we can view   z  (y,  ) as the encoding of y.

we now consider a deterministic decoder   y  (  z) and de   ne a
model

(cid:32)   ||y       y  (  z)||2

(cid:33)

2  2

q  (y|  z)     exp

a vae for images

auto-encoding id58, diederik p kingma, max
welling, 2013.

y

  z  (y,  )

  z

  y  (  z)

||y       y||2

[hyeonwoo noh et al.]

15

deconvoution: increasing spatial dimension

consider a stride 2 convolution

y[i, j, cy] = w [   i,    j, cx, cy]x[2i +    i, 2j +    j, cx]
y[i, j, cy] += b[cy]

for deconvolution we use stride 1 with 4 times the channels.

  x[i, j, c  x] = w(cid:48)[   i,    j, c  y, c  x]  y[i +    i, j +    j, c  x]
  x[i, j, c  x] += b[c  x]

the channels at each lower resolution pixel   x[i, j] are divided
among four higher resolution pixels.

this is done by a simple reshaping of   x.

16

decoding with l2 distortion

     ,       = argmax

  ,  

ey   pop e  z   p  (  z|y) ln q  (  z, y) + h(p  (  z|y))

the objective now becomes

(cid:18)

ey   pop e  z   p  (  z|y)

(cid:19)

+h(p  (  z|y))

ln p  (  z)     1

2  2 ||y       y  (  z)||2

17

(cid:19)

(cid:18)

decoding with l2 distortion

switching back to minimization, we can now rewrite the ob-
jective as

min ey, 

|  z  (y,  )|   +

1
2

  ||y       y  (  z  (y,  ))||2

   |  z  (y,  )|  ,y

|  z|   =     log2 p  (  z)

|  z|  ,y =     log2 p  (  z|y)

for   z discrete, |  z|   is the code length of   z(y,  ) under an op-
timal code for p  .
|  z|  ,y is the code length for   z under the code for p  (  z|y).

18

soft em is to hard em as vae is to rate-distortion

(soft) em:   t+1 = argmax   ey   pop e  z   q  t(  z|y)

log q  (  z, y)

hard em:   t+1 = argmax   ey   pop q  (  z(y), y)

  z(y) = argmax

  z

q  t(  z|y)

vae: min ey,  |  z  (y,  )|  +1

2  ||y     y  (  z  (y,  ))||2   |  z  (y,  )|  ,y

rd: min ey |  z  (y)|   + 1

2  ||y       y  (  z  (y))||2

sampling

p  (  z|y)

  z q  (  z, y)

[hyeonwoo noh et al.]

sampling uses just the second half q  (  z, y).

20

sampling from gaussian id5

[alec radford]

21

why blurry?

a common explanation for the blurryness of images generated
from vaes is the use of l2 as the distortion measure.

it does seem that l1 works better (see the slides on image-to-
image gans).

however, training on l2 distortion can produce sharp im-
ages in rate-distortion autoencoders (see the slides on rate-
distortion autoencoders).

22

end

