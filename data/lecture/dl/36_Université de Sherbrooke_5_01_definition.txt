neural networks
restricted id82 - de   nition

unsupervised learning

d  epartement d   informatique
universit  e de sherbrooke

hugo larochelle

2

math for my slides    restricted id82s   .

hugo.larochelle@usherbrooke.ca

topics: unsupervised learning
    unsupervised learning: only use the inputs       for learning

    x(t)   log p(x(t))

    automatically extract meaningful features for your data
    leverage the availability of unlabeled data
    add a data-dependent regularizer to training (                   )
    x(t)   log p(x(t))

math for my slides    restricted id82s   .

october 10, 2012

abstract

    we will see 3 neural networks for unsupervised learning

    restricted id82s
    autoencoders
    sparse coding model

d  epartement d   informatique
universit  e de sherbrooke

restricted id82

hugo.larochelle@usherbrooke.ca

topics: rbm, visible layer, hidden layer, energy function

october 10, 2012

math for my slides    restricted id82s   .

    x(t)   log p(x(t))

energy function:

bj

bias

h
abstract
w connections

hidden layer
(binary units)

ck

x

visible layer
(binary units)

e(x, h) =  h>wx   c>x   b>h
wj,khjxk  xk

=  xj xk

ckxk  xj

bjhj

distribution: p(x, h) = exp( e(x, h))/z

p(x, h) = exp( e(x, h))/z

= exp(h>wx + c>x + b>h)/z

partition function

(intractable)

3

(1)
(2)

(3)
(4)

    x(t)   log p(x(t))

markov network view

hugo.larochelle@usherbrooke.ca
4

abstract

universit  e de sherbrooke

october 10, 2012

topics: markov network (with vector nodes)

math for my slides    restricted id82s   .
e(x, h) =  h>wx   c>x   b>h
wj,khjxk  xk
bjhj
abstract

=  xj xk

ckxk  xj

x

2

   

{

r

    x(t)   log p(x(t))
    h x

|

math for my slides    restricted id82s   .

x

p(x, h) = exp( e(x, h))/z

/2
= exp(h>wx + c>x + b>h)/z
r
= exp(h>wx) exp(c>x) exp(b>h)/z
x
}

p(x, h) = exp( e(x, h))/z

(

)

h

    x(t)   log p(x(t))
    h x

   

{

 

,

u

|

x
u

=
 

u

e
t

u

>i

u

    h1 h2 hh 1 hh

=
1

}

factors

= exp(h>wx + b>h + c>x)/z
= exp(h>wx) exp(b>h) exp(c>x)/z

|

9

p(x, h) = exp( e(x, h))/z
    the notation based on an energy function is simply an 
alternative to the representation as the product of factors
exp(wj,khjxk)

p(x, h) =

= exp(h>wx + b>h + c>x)/z
= exp(h>wx) exp(b>h) exp(c>x)/z

  

}

p

   

r

{

2

1

zyj yk
yk

6
p

h

}

math for my slides    restricted id82s   .

    x(t)   log p(x(t))
    h x

    x(t)   log p(x(t))
    h x
    x(t)   log p(x(t))
    x(t)   log p(x(t))
    h1 h2 hh 1 hh
    h x
    h x
    x1 x2 xd

    x(t)   log p(x(t))
p(x, h) = exp( e(x, h))/z
math for my slides    restricted id82s   .
    h x

abstract
math for my slides    restricted id82s   .

markov network view
= exp(h>wx + c>x + b>h)/z
= exp(h>wx) exp(c>x) exp(b>h)/z
p(x, h) = exp( e(x, h))/z
p(x, h) = exp( e(x, h))/z
p(x, h) = exp( e(x, h))/z
= exp(h>wx + b>h + c>x)/z
= exp(h>wx) exp(b>h) exp(c>x)/z

topics: markov network (with scalar nodes)

x
w

abstract

j
,

  

j

p

j

|

w
9

=
x

    x(t)   log p(x(t))
    h x
...
    h1 h2 hh 1 hh
    h1 h2 hh 1 hh
    h1 h2 hh 1 hh
    x1 x2 xd
    x1 x2 xd
    x1 x2 xd
    h1 h2 hh 1 hh
    h1 h2 hh 1 hh
    h1 h2 hh 1 hh
...
    x1 x2 xd
    x1 x2 xd
    x1 x2 xd

2
x
{
=

x
r

   

(

)

r

5

}

j
=

i

1
=

u

j

>i

u

t
e

u

i

i

 
=

i

u
x

|

u

i

,

i

 
{

   

    the scalar visualization is more informative of the structure 
within the vectors

abstract

   9w,t    x(t   )=pt6=t   wtx(t)
   r(x)={x2rh|9w x=pjwjx  ,j}
   {x2rh|x/2r(x)}
   { i,ui|xui= iuietu>iuj=1i=j}

zyj yk
yk
yj

2
x
{

r

   

exp(bjhj)

unary
factors

(

h

p(x, h) = exp( e(x, h))/z

= exp(h>wx + b>h + c>x)/z
= exp(h>wx + b>h + c>x)/z
= exp(h>wx) exp(b>h) exp(c>x)/z
= exp(h>wx) exp(b>h) exp(c>x)/z
pair-wise factors
p(x, h) = exp( e(x, h))/z
p(x, h) = exp( e(x, h))/z
}
1
= exp(h>wx + b>h + c>x)/z
x
exp(wj,khjxk)
r
= exp(h>wx) exp(b>h) exp(c>x)/z
/2
x

= exp(h>wx + b>h + c>x)/z
= exp(h>wx + b>h + c>x)/z
= exp(h>wx) exp(b>h) exp(c>x)/z
= exp(h>wx) exp(b>h) exp(c>x)/z
exp(ckxk)

|

)

p(x, h) =

abstract
math for my slides    restricted id82s   .

math for my slides    restricted id82s   .

abstract

abstract

6

    x(t)   log p(x(t))
    h x

factor graph view
    x(t)   log p(x(t))
    h x
    x(t)   log p(x(t))
    x(t)   log p(x(t))
    h x
    h x

    x(t)   log p(x(t))
math for my slides    restricted id82s   .
    h x
topics: factor graph of an rbm
    x(t)   log p(x(t))
    h x
...
    h1 h2 hh 1 hh
    h1 h2 hh 1 hh
    h1 h2 hh 1 hh
    x1 x2 xd
    x1 x2 xd
    x1 x2 xd
    h1 h2 hh 1 hh
    h1 h2 hh 1 hh
    h1 h2 hh 1 hh
...
    x1 x2 xd
    x1 x2 xd
    x1 x2 xd

p(x, h) = exp( e(x, h))/z

p(x, h) = exp( e(x, h))/z

p(x, h) = exp( e(x, h))/z
= exp(h>wx + b>h + c>x)/z
= exp(h>wx) exp(b>h) exp(c>x)/z

= exp(h>wx + b>h + c>x)/z
= exp(h>wx + b>h + c>x)/z
= exp(h>wx) exp(b>h) exp(c>x)/z
= exp(h>wx) exp(b>h) exp(c>x)/z
p(x, h) = exp( e(x, h))/z
= exp(h>wx + b>h + c>x)/z
= exp(h>wx) exp(b>h) exp(c>x)/z

= exp(h>wx + b>h + c>x)/z
= exp(h>wx + b>h + c>x)/z
= exp(h>wx) exp(b>h) exp(c>x)/z
= exp(h>wx) exp(b>h) exp(c>x)/z

p(x, h) = exp( e(x, h))/z

p(x, h) = exp( e(x, h))/z

