neural networks
sparse coding - dictionary learning algorithm

2

sparse coding
hugo larochelle
hugo larochelle

hugo.larochelle@usherbrooke.ca

sparse coding

november 1, 2012

hugo larochelle

sparse coding

math for my slides    sparse coding   .

november 1, 2012
abstract

topics: sparse coding
    for each          nd a latent representation       such that:
    x(t) h(t) d

sparse coding
d  epartement d   informatique
universit  e de sherbrooke
d  epartement d   informatique
hugo.larochelle@usherbrooke.ca
math for my slides    sparse coding   .
universit  e de sherbrooke
d  epartement d   informatique
sparse coding
d  epartement d   informatique
hugo.larochelle@usherbrooke.ca
abstract
math for my slides    sparse coding   .
november 1, 2012
universit  e de sherbrooke
d  epartement d   informatique
    x(t) h(t) d
universit  e de sherbrooke
hugo larochelle
txt=1
november 1, 2012
hugo.larochelle@usherbrooke.ca
    it is sparse: the vector        has many zeros
universit  e de sherbrooke
1
1
hugo.larochelle@usherbrooke.ca
2 +  ||h(t)||1
2||x(t)   d h(t)||2
d  epartement d   informatique
arg min
arg min
arg min
arg min
abstract
hugo.larochelle@usherbrooke.ca
t
    we can reconstruct the original input        as much as possible
universit  e de sherbrooke
1
1
d
h(t)
h(t)
    x(t) h(t) d
november 1, 2012
2 +  ||h(t)||1
2||x(t)   d h(t)||2
november 1, 2012
arg min
hugo.larochelle@usherbrooke.ca
txt=1
t
1
   
2||x(t)   d h(t)||2
arg min
november 1, 2012
1
1
h(x(t)) = arg min
2||x(t)   d h(t)||2
2||x(t)   d h(t)||2
2 +  ||h(t)||1
d
abstract
1
2||x(t)   d h(t)||2
h(x(t)) = arg min

sparsity penalty
h(x(t)) = arg min
2 +  ||h(t)||1
abstract

sparse coding
abstract

math for my slides    sparse coding   .

    x(t) h(t) d

abstract
hugo larochelle

abstract
reconstruction error

txt=1

txt=1

arg min

arg min

h(t)
h(t)

 

1
t

1
t

h(t)

1
t

 

d

d

arg min

min
d
1
t

txt=1
 
1
2||x(t)   d h(t)||2
h(t)
min
abstract
math for my slides    sparse coding   .
   
h(t)
 
txt=1
1
math for my slides    sparse coding   .
math for my slides    sparse coding   .
2||x(t)   d h(t)||2
arg min
reconstruction
    x(t) h(t) d bx(t)
d
h(t)
    x(t) h(t) d
1
h(x(t)) = arg min
2||x(t)   d h(t)||2
txt=1
    x(t) h(t) d
arg min
h(t)
txt=1
1
d
2||x(t)   d h(t)||2
h(x(t)) = arg min
arg min
arg min
bx(t) = d h(x(t)) = xk s.t.
   
   
h(t)
- encoder is the minimization
d
h(x(t)) = arg min

reconstruction vs.
2 +  ||h(t)||1
sparsity control
txt=1
math for my slides    sparse coding   .
         is equivalent to the autoencoder output weight matrix
2 +  ||h(t)||1
1
arg min
2 +  ||h(t)||1
2||x(t)   d h(t)||2
    however,             is now a complicated function of      
1
    x(t) h(t) d
2 +  ||h(t)||1
2||x(t)   d h(t)||2
2 +  ||h(t)||1
d  ,k h(x(t))k
1
h(t)
2||x(t)   d h(t)||2
2 +  ||h(t)||1

h(x(t)) = arg min

h(x(t)) = arg min

1
t
1
t

arg min

arg min

h(t)

1
t

h(t)

h(t)

h(t)

d

2 +  ||h(t)||1
1
2||x(t)   d h(t)||2
2 +  ||h(t)||1

h(t)

1
2||x(t)   d h(t)||2

1
1
2||x(t)   d h(t)||2
2 +  ||h(t)||1
t

arg min

txt=1

math for my slides    sparse coding   .

math for my slides    sparse coding   .
    more formally:
   

    x(t) h(t) d bx(t)

   

universit  e de sherbrooke

3

sparse coding
hugo.larochelle@usherbrooke.ca

2

2

d

d

d

   

1
t

1
t

1
t

h(t)

min
d

min
h(t)

arg min

    d>d

    1
txt=1

2 +  ||h(x(t))||1

    x(t) h(t) d

1
2||x(t)   d h(x(t))||2

1
arg min
t
1
2||x(t)   d h(x(t))||2

min
d
1
l(x(t)) = min
t
d
math for my slides    sparse coding   .

hugo.larochelle@usherbrooke.ca
sparse coding
txt=1
txt=1
1
l(x(t)) = min
min
t
txt=1
abstract
november 1, 2012
d
h(t)
1
2 +  ||h(x(t))||1
2||x(t)   d h(x(t))||2
min
d
txt=1
1
1
topics: learning algorithm (putting it all together)
2||x(t)   d h(x(t))||2
min
t
txt=1
d
1
    x(t) h(t) d
2||x(t)   d h(x(t))||2
    learning alternates between id136 and dictionary learning
abstract
   
txt=1
2 =  txt=1
1
1
2||x(t)   d h(t)||2
txt=1
arg min
arg min
math for my slides    sparse coding   .
1
2||x(t)   d h(x(t))||2
t
x(t) h(x(t))>!  txt=1
h(x(t)) h(x(t))>! 1
2 =  txt=1
txt=1
1
    while     has not converged
t
d (=  txt=1
x(t) h(x(t))>!  txt=1
txt=1
1
       nd the sparse codes              for all        in my training set with ista
2||x(t)   d h(t)||2
    x(t) h(t) d
arg min
x(t) h(x(t))>!  txt=1
d (=  txt=1
h(x(t)) h(x(t))>! 1
    update the dictionary:
t=1 x(t) h(x(t))> b (=pt
    a (=pt
 
t=1 h(x(t)) h(x(t))> d (= b a 1
t=1 x(t) h(x(t))> b (=pt
 
h(x(t)) = arg min
t=1 h(x(t)) h(x(t))> d (= b a 1
   
x(t) h(x(t) (=    txt=1
t +1xt=1
 run block-coordinate descent algorithm to update 
    x(t) h(t) d
x(t) h(x(t) (=    txt=1
x(t) h(x(t))>! + (1    )x(t +1) h(x(t +1))>
t +1xt=1
    similar to the em algorithm
h(x(t)) h(x(t) (=    txt=1
t +1xt=1
h(x(t)) h(x(t) (=    txt=1
h(x(t)) h(x(t))>! + (1    )h(x(t +1)) h(x(t +1))>
t +1xt=1

x(t) h(x(t))>!  txt=1
2 +  ||h(t)||1
math for my slides    sparse coding   .
h(x(t)) h(x(t))>! 1
1
2 +  ||h(t)||1
2||x(t)   d h(t)||2

2 +  ||h(t)||1
txt=1
arg min
2 +  ||h(t)||1
x(t) h(x(t))>! + (1    )x(t +1) h(x(t +1))>
h(x(t)) = arg min
txt=1
1
t
h(x(t)) h(x(t))>! + (1    )h(x(t +1)) h(x(t +1))>

math for my slides    sparse coding   .
1
2||x(t)   d h(t)||2

h(x(t)) h(x(t))>! 1

h(x(t)) = arg min

arg min

1
t
h(t)

arg min

arg min

abstract
h(t)

-
-
   
-

1
t

h(t)

h(t)

h(t)

   

   

d

d

d

november 1, 2012

hugo larochelle

d  epartement d   informatique
universit  e de sherbrooke

abstract

hugo.larochelle@usherbrooke.ca

november 1, 2012

arg min

1
2||x(t)   d h(t)||2

1
2||x(t)   d h(t)||2

1
h(t)
2||x(t)   d h(t)||2

