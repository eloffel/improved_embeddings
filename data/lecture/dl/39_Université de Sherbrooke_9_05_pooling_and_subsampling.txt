neural networks
id161 - pooling and subsampling

id161

2

topics: id161
    we can design neural networks that are speci   cally adapted 
for such problems
    must deal with very high-dimensional inputs 

- 150 x 150 pixels = 22500 inputs, or 3 x 22500 if rgb pixels

    can exploit the 2d topology of pixels (or 3d for video data)
    can build in invariance to certain variations we can expect 

-

translations, illumination, etc.

    convolutional networks leverage these ideas

    local connectivity
    parameter sharing
    pooling / subsampling hidden units

id161
jarret et al. 2009

math for my slides    id161   .

topics: parameter sharing
    each feature map forms a 2d grid of features

november 8, 2012

3

abstract

    h x    

    can be computed with a discrete convolution (   ) of a kernel matrix kij which is

the hidden weights matrix wij with its rows and columns    ipped

filter bank layer - fid19: the input of a    lter bank
layer is a 3d array with n1 2d feature maps of size n2    n3.
each component is denoted xijk, and each feature map is
denoted xi. the output is also a 3d array, y composed of
m1 feature maps of size m2    m3. a    lter in the    lter bank
kij has size l1    l2 and connects input feature map xi to
output feature map yj. the module computes:

    xi is the ith channel of input
    kij is the convolution kernel
    gj is a learned scaling factor
    yj is the hidden layer 

   (could have added a bias)

r
e 

at
u

p
s

fe

a

m

figure 1. a example of feature extraction stage of the type fid19   
rabs     n     pa. an input image (or a feature map) is passed
through a non-linear    lterbank, followed by recti   cation, local
contrast id172 and spatial pooling/sub-sampling.

yj = gj tanh(!
i

kij     xi)

figure 1. a example of feature extraction stage of the type fid19   

layer with 4x4 down-sampling is denoted: p 4  4
max-pooling and subsampling layer - pm : building lo-

(1)

hugo larochelle

id161

d  epartement d   informatique
universit  e de sherbrooke
topics: pooling and subsampling
hugo.larochelle@usherbrooke.ca
    third idea: pool hidden units in same neighborhood

4

    pooling is performed in non-overlapping neighborhoods (subsampling)

november 8, 2012

math for my slides    id161   .

abstract

yijk = max
p,q

xi,j+p,k+q

jarret et al. 2009

    xi,j,k is value of the ith 
feature map at position j,k
    p is vertical index in local 
neighborhood
    q is horizontal index in 
local neighborhood
    yijk is pooled and 
subsampled layer

universit  e de sherbrooke

hugo.larochelle@usherbrooke.ca

id161

november 8, 2012
topics: pooling and subsampling
    third idea: pool hidden units in same neighborhood

5

math for my slides    id161   .

    an alternative to       max       pooling is       average       pooling 

abstract

yijk = max
m
p,q

xi,j+p,k+q

yijk =

1

m2xp,q

xi,j+p,k+q

jarret et al. 2009

    xi,j,k is value of the ith 
feature map at position j,k
    p is vertical index in local 
neighborhood
    q is horizontal index in 
local neighborhood
    yijk is pooled and 
subsampled layer
    m is the neighborhood 
height/width

example 
id161

       calcul%d   une%couche%  %complex%cell%  %
topics: pooling and subsampling
       maximum%dans%plusieurs%segments%
    illustration of pooling/subsampling operation

6

0.02% 0.19% 0.19% 0.02%

0.02% 0.19% 0.19% 0.02%

0.02% 0.75% 0.02% 0.02%

0.75% 0.02% 0.02% 0.02%

max%

max%

max%

max%

0.19% 0.19%

0.75% 0.02%

    solves the following problems:
logis6c(%(%%%%%%%%%%%%%n%200%)%/%50%)%

%%%%%
% 
couche)  )simple)cell)  )

 x w
%%%%%
% 

    introduces invariance to local translations
couche)  )complex)cell)  )
    reduces the number of hidden units in hidden layer                                                               
ift%615%

hugo%larochelle%

49%

id161
example 

topics: pooling and subsampling
    illustration of local translation invariance

       la%couche%  %complex%cell%  %est%invariante%aux%transla7ons%locales%
    both images given the same feature map after pooling/subsampling

7

0%

0%

0%

0%

0%

0%

0%

255%

255%

0%

255%

255%

255%

0%

0%

0%

0%

0%

0%

0%

0%

0%

0%

0%

0%

0%

0%

0%

0%

0%

255%

0%

255%

255%

255%

0%

0%

0%

0%

0%

0%

0%

0%

0%

0%

0%

0%

0%

0%

0%

0.19% 0.19%

0.75% 0.02%

couche)  )complex)cell)  )

couches)d   entr  e)

couches)d   entr  e)

ift%615%

hugo%larochelle%

50%

