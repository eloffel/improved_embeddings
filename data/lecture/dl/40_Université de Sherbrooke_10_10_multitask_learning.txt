neural networks
natural language processing - multitask learning

sentence neural network

collobert, weston, bottou, karlen, kavukcuoglu and kuksa

2

topics: sentence convolutional network
    how to model each label sequence
    could use a crf with neural network unary 

potentials, based on a window (context) of words
- not appropriate for id14, because 

relevant context might be very far away

    collobert and weston suggest a convolutional 

network over the whole sentence
- prediction at a given position can exploit information 

from any word in the sentence

the cat
w1
1 w1

2

wk

1 wk

2

p
a
d
d
i
n
g

d

n1

hu

sat
. . .

. . .

on the mat
w1
n

wk
n

m 1

     

n1

hu

n2

hu

input sentence

text

feature 1

...

feature k

p
a
d
d
i
n
g

lookup table

ltw 1

...

ltw k

convolution

max over time

max(  )

linear

m 2

     

hardtanh

linear

m 3

     

n3

hu = #tags

figure 2: sentence approach network.

sentence neural network

3

topics: multitask learning
    could share vector representations of the features across 
tasks
    simply use the same lookup

collobert, weston, bottou, karlen, kavukcuoglu and kuksa

lookup table

lookup table

ltw 1

.

.

.

tables across tasks

    the other parameters of the

neural networks are not
tied

linear

n1

hu

ltw k

m 1      

linear

n1

hu

hardtanh

hardtanh

linear

linear

m 2

     

(t1)

    this is referred to as
multitask learning
    the idea is to transfer knowledge learned within the word representations across 

figure 5: example of multitasking with nn. task 1 and task 2 are two tasks trained with the
window approach architecture presented in figure 1. lookup tables as well as the    rst
hidden layer are shared. the last layer is task speci   c. the principle is the same with
more than two tasks.

task 1

task 2

= #tags

= #tags

hu,(t1)

hu,(t2)

(t2)

     

n2

n2

m 2

the different task

4

set id178 may require prohibitively large training sets.16 the id178 criterion lacks dynamical
range because its numerical value is largely determined by the most frequent phrases. in order to
sentence neural network
learn syntax, rare but legal phrases are no less signi   cant than common phrases.
it is therefore desirable to de   ne alternative training criteria. we propose here to use a pairwise
ranking approach (cohen et al., 1998). we seek a network that computes a higher score when
given a legal phrase than when given an incorrect phrase. because the ranking literature often deals
with information retrieval applications, many authors de   ne complex ranking criteria that give more
weight to the ordering of the best ranking instances (see burges et al., 2007; cl  emenc  on and vayatis,
2007). however, in our case, we do not want to emphasize the most common phrase over the rare
but legal phrases. therefore we use a simple pairwise criterion.
we consider a window approach network, as described in section 3.3.1 and figure 1, with
parameters    which outputs a score f  (x) given a window of text x = [w]
. we minimize the
ranking criterion with respect to   :

topics: language model
    we can design other tasks without any labeled data

      cat sat on the mat          vs          cat sat think the mat      
    can generate impostor examples from unlabeled text (wikipedia)

    train a neural network (with word representations) to assign a higher score to the 

- pick a window of words from unlabeled corpus
-

    identify whether the middle word of a window of text is an       impostor      

replace middle word with a different, randomly chosen word

dwin1

original window
   !       x   x
    similar to id38, except we predict the word in the middle

max!0 , 1     f  (x) + f  (x(w))" ,

original window

   
w   d

with word w

impostor window 

(17)

where x is the set of all possible text windows with dwin words coming from our training corpus, d
is the dictionary of words, and x(w) denotes the text window obtained by replacing the central word

sentence neural network

5

natural language processing (almost) from scratch
natural language processing (almost) from scratch

topics: experimental comparison
    from natural language processing (almost) from scratch 
by collobert et al.
approach
approach
benchmark systems
benchmark systems
nn+wll
nn+sll
nn+sll+lm2
nn+wll+lm1
nn+sll+lm2+mtl
nn+sll+lm1
nn+wll+lm2
nn+sll+lm2
nn+sll+lm2
nn+sll+lm2+mtl

chunk ner srl
chunk ner srl
(f1)
(f1)
(f1)
(f1)
94.29
77.92
77.92
94.29
89.13
55.40
70.99
90.33
93.63
58.18
91.91
94.10
93.65
73.84
92.04
58.34
74.15
93.37
93.63
74.15
93.75
74.29

(f1)
(f1)
89.31
89.31
79.53
81.47
window approach
88.67
85.68
88.62
87.58
sentence approach
86.96
88.78
88.67
88.27

pos
pos
(pwa)
(pwa)
97.24
97.24
96.31
96.37
97.20
97.05
97.22
97.10
97.14
97.12
97.20
97.22

   
   

table 8: comparison in generalization performance of benchmark nlp systems with our (nn) ap-
table 9: effect of multi-tasking on our neural architectures. we trained pos, chunk ner in a
proach on pos, chunking, ner and srl tasks. we report results with both the word-level
mtl way, both for the window and sentence network approaches. srl was only included
log-likelihood (wll) and the sentence-level log-likelihood (sll). we report with (lmn)
in the sentence approach joint training. as a baseline, we show previous results of our
performance of the networks trained from the language model embeddings (table 7). gen-

sentence neural network

5

natural language processing (almost) from scratch
topics: experimental comparison
natural language processing (almost) from scratch
    from natural language processing (almost) from scratch 
natural language processing (almost) from scratch
chunk ner srl
approach
by collobert et al.
(f1)
(f1)
(f1)
approach
chunk ner srl
benchmark systems
89.31
94.29
77.92
chunk ner srl
approach
(f1)
(f1)
(f1)
window approach
(f1)
(f1)
(f1)
benchmark systems
89.31
94.29
77.92
   
nn+sll+lm2
88.67
93.63
benchmark systems
77.92
89.31
94.29
nn+wll
79.53
89.13
55.40
nn+sll+lm2+mtl
   
88.62
94.10
70.99
nn+sll
81.47
90.33
window approach
sentence approach
88.67
93.63
nn+sll+lm2
   
58.18
nn+wll+lm1
85.68
91.91
74.15
nn+sll+lm2
88.78
93.37
nn+sll+lm2+mtl
   
88.62
94.10
73.84
nn+sll+lm1
93.65
87.58
74.29
nn+sll+lm2+mtl
93.75
88.27
sentence approach
58.34
nn+wll+lm2
86.96
92.04
74.15
88.78
93.37
nn+sll+lm2
74.15
nn+sll+lm2
88.67
93.63
74.29
nn+sll+lm2+mtl
88.27
93.75

pos
(pwa)
pos
97.24
pos
(pwa)
(pwa)
97.24
97.20
97.24
96.31
97.22
96.37
97.20
97.05
97.12
97.22
97.10
97.22
97.14
97.12
97.20
97.22

table 9: effect of multi-tasking on our neural architectures. we trained pos, chunk ner in a
mtl way, both for the window and sentence network approaches. srl was only included
in the sentence approach joint training. as a baseline, we show previous results of our
table 8: comparison in generalization performance of benchmark nlp systems with our (nn) ap-
table 9: effect of multi-tasking on our neural architectures. we trained pos, chunk ner in a
window approach system, as well as additional results for our sentence approach system,
proach on pos, chunking, ner and srl tasks. we report results with both the word-level
mtl way, both for the window and sentence network approaches. srl was only included
when trained separately on each task. benchmark system performance is also given for
log-likelihood (wll) and the sentence-level log-likelihood (sll). we report with (lmn)
in the sentence approach joint training. as a baseline, we show previous results of our
comparison.
performance of the networks trained from the language model embeddings (table 7). gen-

5

nn+sll+lm2
nn+sll+lm2+mtl

97.12
97.22

93.37
93.75

88.78
88.27

74.15
74.29

sentence neural network

table 9: effect of multi-tasking on our neural architectures. we trained pos, chunk ner in a
natural language processing (almost) from scratch
mtl way, both for the window and sentence network approaches. srl was only included
topics: experimental comparison
in the sentence approach joint training. as a baseline, we show previous results of our
natural language processing (almost) from scratch
window approach system, as well as additional results for our sentence approach system,
    from natural language processing (almost) from scratch 
natural language processing (almost) from scratch
when trained separately on each task. benchmark system performance is also given for
chunk ner srl
approach
by collobert et al.
comparison.
(f1)
(f1)
(f1)
approach
chunk ner srl
benchmark systems
89.31
94.29
77.92
chunk ner srl
approach
(f1)
(f1)
(f1)
window approach
(f1)
(f1)
(f1)
benchmark systems
89.31
94.29
77.92
   
nn+sll+lm2
88.67
93.63
chunk ner srl
approach
benchmark systems
77.92
89.31
94.29
nn+wll
79.53
89.13
55.40
nn+sll+lm2+mtl
   
88.62
94.10
(f1)
(f1)
nn+sll
70.99
90.33
81.47
window approach
sentence approach
benchmark systems
77.92
94.29
89.31
88.67
93.63
nn+sll+lm2
   
nn+wll+lm1
85.68
91.91
58.18
74.15
nn+sll+lm2
88.78
93.37
88.67
93.63
74.15
nn+sll+lm2
nn+sll+lm2+mtl
   
88.62
94.10
73.84
nn+sll+lm1
93.65
87.58
74.29
nn+sll+lm2+mtl
93.75
88.27
nn+sll+lm2+suf   x2
   
sentence approach
58.34
92.04
nn+wll+lm2
86.96
   
nn+sll+lm2+gazetteer
89.59
74.15
88.78
93.37
nn+sll+lm2
74.15
nn+sll+lm2
88.67
93.63
nn+sll+lm2+pos
88.67
94.32
   
74.29
nn+sll+lm2+mtl
88.27
93.75
74.72
nn+sll+lm2+chunk

table 9: effect of multi-tasking on our neural architectures. we trained pos, chunk ner in a
mtl way, both for the window and sentence network approaches. srl was only included
in the sentence approach joint training. as a baseline, we show previous results of our
table 8: comparison in generalization performance of benchmark nlp systems with our (nn) ap-
table 9: effect of multi-tasking on our neural architectures. we trained pos, chunk ner in a
window approach system, as well as additional results for our sentence approach system,
proach on pos, chunking, ner and srl tasks. we report results with both the word-level
table 10: comparison in generalization performance of benchmark nlp systems with our neural
mtl way, both for the window and sentence network approaches. srl was only included
when trained separately on each task. benchmark system performance is also given for
log-likelihood (wll) and the sentence-level log-likelihood (sll). we report with (lmn)
networks (nns) using increasing task-speci   c engineering. we report results obtained
in the sentence approach joint training. as a baseline, we show previous results of our
comparison.
performance of the networks trained from the language model embeddings (table 7). gen-

pos
(pwa)
pos
97.24
pos
(pwa)
(pwa)
97.24
97.20
pos
97.24
96.31
97.22
(pwa)
96.37
97.24
97.20
97.05
97.12
97.20
97.22
97.10
97.22
97.29
97.14
97.12
97.20
97.22

   
   
   

   
   
   

   

   

sentence neural network

6

topics: experimental comparison
collobert, weston, bottou, karlen, kavukcuoglu and kuksa
    nearest neighbors in word representation space:

france

454

austria
belgium
germany

italy
greece
sweden
norway
europe
hungary

switzerland

jesus
1973
god
sati
christ
satan
kali
indra
vishnu
ananda
parvati
grace

xbox
6909
amiga

playstation

msx
ipod
sega

hd

psnumber

dreamcast

geforce
capcom

reddish
11724
greenish
bluish
pinkish
purplish
brownish
greyish
grayish
whitish
silvery

yellowish

scratched

megabits

87025
octets
mb/s
bit/s
baud
carats
kbit/s

29869
nailed
smashed
punched
popped
crimped
scraped
screwed
megahertz
sectioned megapixels
slashed
ripped

gbit/s
amperes

table 7: id27s in the word lookup table of the language model neural network lm1
trained with a dictionary of size 100,000. for each column the queried word is followed
by its index in the dictionary (higher means more rare) and its 10 nearest neighbors (using
the euclidean metric, which was chosen arbitrarily).

    for a 2d visualization: http://www.cs.toronto.edu/~hinton/turian.png

