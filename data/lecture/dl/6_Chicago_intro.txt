ttic 31230, fundamentals of deep learning, winter 2018

david mcallester

introduction and historical notes

deep learning: a moore   s law of ai?

pascal voc id164

bicycle bus

car motorbike person 20 class average

2007
2008
2009
2010
2011
2012

2013 dnn
2014 dnn
2015 resnet
2016 resnet

36.9
42.0
46.8
54.3
58.1
54.5
56.3

23.2 34.6
23.2 32.0
43.8 37.2
54.2 49.1
57.6 54.4
57.1 49.3
51.4 48.7

27.6
38.6
42.0
51.6
58.3
59.4
59.8

21.3
42.0
41.5
47.5
51.6
46.1
44.4

88.4

86.3 87.8

89.6

90.9

17.1
22.9
27.9
36.8
40.9
41.1
43.2
63.8
83.8
86

1000 kinds of objects.

id163 classi   cation

2016 error rate is 3.0%

2017 error rate is 2.25%

coco challenge 17

detection

segmentation

alphazero

the deep revolution is everywhere

    id161

    id103

    machine translation

    computer games

    information retrieval (google search)

    computational chemistry

    ...

some history of deep learning

mccullock and pitts 1943     introduced the linear threshold    neuron   .

rosenblatt 1962     applied a    hebbian    learning rule.

noviko    1962     proved the id88 convergence theorem.

deep winter i: late 60s through early 80s

robinson 1965     introduces resolution theorem proving.

minsky 1969     wins turing award for    promoting ai   .

mccarthy and hayes 1968     introduced the situation calculus.

minsky and papert 1969     published the book id88s. they proved
that many properties of images could not be determined by (single layer)
id88s. caused a decline of activity in neural network research.

mccarthy, 1971     wins turing award.

minsky 1974     wrote    a framework for representing knowledge   .

mccarthy 1980     introduces    non-monotonic logic   .

deep resurgence i, late 80s

fukushima 1980     introduced the neocognitron (a form of id98)

hinton and sejnowski 1985     introduce the boltzman machine

rummelhart, hinton and williams 1986     demonstrated empirical success
with id26 (itself dating back to 1961).

deep winter ii: late 90s    and 00   s

valiant 1984     introduces the formal de   nition of pac learnability. cred-
ited with starting learning theory as a branch of computer science. turing
award, 2010.

pearl 1995     publishes probabilistic reasoning in intelligent systems:
networks of plausible id136. credited with driving the    statistical
revolution    in ai. turing award, 2011.

id76 and convex relaxations (the marginal polytope of a
graphical model)

nonparametric bayesian id136 (dirichlet processes).

submodular optimization

deep learning in winter ii

schmidhuber et al. 1997     introduces lstms

lecun 1998     introduces convolutional neural networks (id98s) (lenet).

bengio 2003     introduced neural id38

deep learning explodes in 2012

alexnet dominates the 2012 id163 challenge.

google id103 converts to deep learning.

both developments were driven by hinton   s group at the university of
toronto.

the four horsemen of deep learning

geo    hinton, 70, h index = 136

yann lecun, 57, h index = 98

yoshua bengio, 53, h index = 105

juergen schmidhuber, 54, h index = 80

end

