neural networks
feedforward neural network - capacity of single neuron

    a(x)=bipiwixi =bi+w>x
    h(x)=g(a(x))=g(bipiwixi)

abstract

0

1

-1

abstract

-1
math for my slides    feedforward neural network   .
math for my slides    feedforward neural network   .

math for my slides    feedforward neural network   .

topics: connection weights, bias, activation function

    a(x) = b +pi wixi = b + w>x
    h(x) = g(a(x)) = g(b +pi wixi)

artificial neuron
    a(x) = bipi wixi = bi + w>x
    h(x) = g(a(x)) = g(bipi wixi)

    a(x) = b +pi wixi = b + w>x
    h(x) = g(a(x)) = g(b +pi wixi)
sortie k
wkj

    w

y1

x1

zk

2
abstract

-.4

-1

1

0

1

0

y1

.7

y2

    w
    {
range determined 
by 
    g(  ) b

1

-1

x2

    w
    {
bias     only 
    g(  ) b
biais
changes the 
position of 
.5
the riff

    w
    {

0

-1

-1.5

1 1

1

1

cach  ee j
wji
entr  ee i

-1

0

1

0

-1

x1

(from pascal vincent   s slides)

3

1+exp( a)
exp(a)+exp( a) = exp(2a) 1
exp(2a)+1
7

1

    with sigmoid, can interpret neuron as estimating 
    also known as id28 classi   er
    if greater than 0.5,

    g(a) = a
artificial neuron
    g(a) = sigm(a) =
    g(a) = tanh(a) = exp(a) exp( a)
r  eseaux de neurones
topics: capacity, decision boundary of neuron
    g(a) = max(0, a)
    could do binary classi   cation:
    g(a) = reclin(a) = max(0, a)
    p(y = 1|x)
    la puissance expressive des r  eseaux de neurones
    g(  ) b
    w (1)
    h(x) = g(a(x))
    a(x) = b(1) + w(1)x    a(x)i = b(1)
    f (x) = o   b(2) + w(2)>x   
    o(a) = softmax(a) =h exp(a1)

decision boundary is linear
xj h(x)i w(2)
x2
i,j

pc exp(ac) . . .

(similar idea can
 apply with tanh)

deux couches

trois couches

    otherwise, predict

    p(y = c|x)

(from pascal vincent   s slides)

predict class 1

class 0

b(1)
i

b(2)

r2

r1

x1

x2

x1

x2

i

i,j xj   
i +pj w (1)

exp(ac )

pc exp(ac)i>

artificial neuron

4

topics: capacity of single neuron
    can solve linearly separable problems

21

or (x1, x2)

and (x1, x2)

and (x1, x2)

)
2
x

,

1

0

1
)
2
x

,

0

)
2
x

,

1

0

0

1

(x1
xor (x1, x2)

0

(x1

1

0

(x1

1

xor (x1, x2)

1

)

)
2
x

,

1

1

)
2
x

artificial neuron

1

1
)
2
x

)
2
x

5

,

,

,

0

topics: capacity of single neuron
    can   t solve non linearly separable problems...

0

0

1

0

1

0

(x1

0

(x1

1

(x1
xor (x1, x2)

1

)
2
x

,

0

?

0

(x1

1

xor (x1, x2)

)
2
x

,
1
x
(
d
n
a

1

0

0

1

and (x1, x2)

    ... unless the input is transformed in a better representation
figure 1.8     exemple de mod  lisation de xor par un r  seau    une couche cach  e. en
haut, de gauche    droite, illustration des fonctions bool  ennes or(x1, x2), and (x1, x2)

