neural networks
feedforward neural network - biological inspiration

feedforward neural network
hugo larochelle

2

d  epartement d   informatique
universit  e de sherbrooke

hugo larochelle

d  epartement d   informatique
universit  e de sherbrooke

hugo.larochelle@usherbrooke.ca

hugo.larochelle@usherbrooke.ca

september 6, 2012

1

...

exp(ac )

exp(ac )

exp(ac )

exp(ac )

exp(ac )

exp(ac )

exp(ac )

september 6, 2012

neural network

    x1 xd b w1 wd
    w
    p(y = c|x)
    p(y = c|x)
    p(y = c|x)
    o(a) = softmax(a) =h exp(a1)
pc exp(ac)i>
    p(y = c|x)
    {
    o(a) = softmax(a) =h exp(a1)
pc exp(ac)i>
pc exp(ac) . . .
    o(a) = softmax(a) =h exp(a1)
pc exp(ac)i>
    p(y = c|x)
    o(a) = softmax(a) =h exp(a1)
pc exp(ac)i>
pc exp(ac) . . .
topics: multilayer neural network
pc exp(ac) . . .
pc exp(ac) . . .
    o(a) = softmax(a) =h exp(a1)
pc exp(ac)i>
    g(a) = a
    f (x)
    could have l hidden layers:
    f (x)
pc exp(ac) . . .
    p(y = c|x)
    p(y = c|x)
    f (x)
    p(y = c|x)
    f (x)
    h(1)(x) h(2)(x) w(1) w(2) w(3) b(1) b(2) b(3)
    g(a) = sigm(a) =
    o(a) = softmax(a) =h exp(a1)
pc exp(ac)i>
    h(1)(x) h(2)(x) w(1) w(2) w(3) b(1) b(2) b(3)
    o(a) = softmax(a) =h exp(a1)
pc exp(ac)i>
    layer pre-activation for k>0
pc exp(ac)i>
    o(a) = softmax(a) =h exp(a1)
1+exp( a)
    p(y = c|x)
    h(1)(x) h(2)(x) w(1) w(2) w(3) b(1) b(2) b(3)
    a(k)(x) = b(k) + w(k)h(k 1)x (h(0)(x) = x)
exp(ac )
pc exp(ac) . . .
    h(1)(x) h(2)(x) w(1) w(2) w(3) b(1) b(2) b(3)
    f (x)
pc exp(ac) . . .
pc exp(ac) . . .
    o(a) = softmax(a) =h exp(a1)
pc exp(ac)i>
    a(k)(x) = b(k) + w(k)h(k 1)(x) (h(0)(x) = x)
exp(a)+exp( a) = exp(2a) 1
    g(a) = tanh(a) = exp(a) exp( a)
    h(k)(x) = g(a(k)(x))
    f (x)
pc exp(ac) . . .
    a(k)(x) = b(k) + w(k)h(k 1)x (h(0)(x) = x)
1
    a(k)(x) = b(k) + w(k)h(k 1)x (h(0)(x) = x)
...
...
    h(1)(x) h(2)(x) w(1) w(2) w(3) b(1) b(2) b(3)
    p(y = c|x)
    p(y = c|x)
    f (x)
    h(l+1)(x) = o(a(l+1)(x)) = f (x)
    f (x)
    h(1)(x) h(2)(x) w(1) w(2) w(3) b(1) b(2) b(3)
    h(k)(x) = g(a(k)(x))
    o(a) = softmax(a) =h exp(a1)
pc exp(ac)i>
    p(y = c|x)
    h(k)(x) = g(a(k)(x))
    o(a) = softmax(a) =h exp(a1)
pc exp(ac)i>
    f (x)
    h(k)(x) = g(a(k)(x))
    g(a) = max(0, a)
pc exp(ac) . . .
    a(k)(x) = b(k) + w(k)h(k 1)x (h(0) = x)
    hidden layer activation (k from 1 to l):
    a(k)(x) = b(k) + w(k)h(k 1)x (h(0)(x) = x)
    h(1)(x) h(2)(x) w(1) w(2) w(3) b(1) b(2) b(3)
pc exp(ac) . . .
pc exp(ac)i>
    o(a) = softmax(a) =h exp(a1)
    h(1)(x) h(2)(x) w(1) w(2) w(3) b(1) b(2) b(3)
    h(1)(x) h(2)(x) w(1) w(2) w(3) b(1) b(2) b(3)
    h(l+1)(x) = o(a(l+1)(x)) = f (x)
    h(l+1)(x) = o(a(l+1)(x)) = f (x)
exp(ac )
    h(l+1)(x) = o(a(l+1)(x)) = f (x)
pc exp(ac) . . .
    h(k)(x) = g(a(k)(x))
    f (x)
    a(x) = b +pi wixi = b + w>x
1
...
...
    h(k)(x) = g(a(k)(x))
    g(a) = reclin(a) = max(0, a)
    a(k)(x) = b(k) + w(k)h(k 1)x (h(0)(x) = x)
    a(x) = b +pi wixi = b + w>x
    f (x)
    a(k)(x) = b(k) + w(k)h(k 1)x (h(0)(x) = x)
    a(k)(x) = b(k) + w(k)h(k 1)x (h(0) = x)
    h(l+1)(x) = o(a(l+1)(x)) = f (x)
    h(1)(x) h(2)(x) w(1) w(2) w(3) b(1) b(2) b(3)
    f (x)
    h(x) = g(a(x)) = g(b +pi wixi)
    h(k)(x) = g(a(k)(x))
    h(l+1)(x) = o(a(l+1)(x)) = f (x)
    h(x) = g(a(x)) = g(b +pi wixi)
    a(k)(x) = b(k) + w(k)h(k 1)x (h(0)(x) = x)
    h(k)(x) = g(a(k)(x))
    g(  ) b
    h(1)(x) h(2)(x) w(1) w(2) w(3) b(1) b(2) b(3)
    h(k)(x) = g(a(k)(x))
    output layer activation (k=l+1):
    h(1)(x) h(2)(x) w(1) w(2) w(3) b(1) b(2) b(3)
    h(k)(x) = g(a(k)(x))
    h(l+1)(x) = o(a(l+1)(x)) = f (x)
    h(l+1)(x) = o(a(l+1)(x)) = f (x)
1
...
...
    a(k)(x) = b(k) + w(k)h(k 1)x (h(0)(x) = x)
    w (1)
b(1)
    a(k)(x) = b(k) + w(k)h(k 1)x (h(0)(x) = x)
xj h(x)i
    x1 xd
    x1 xd
    h(l+1)(x) = o(a(l+1)(x)) = f (x)
    h(l+1)(x) = o(a(l+1)(x)) = f (x)
i
i,j
    h(k)(x) = g(a(k)(x))
    h(k)(x) = g(a(k)(x))
    w
    w
    h(x) = g(a(x))
    h(l+1)(x) = o(a(l+1)(x)) = f (x)
    h(l+1)(x) = o(a(l+1)(x)) = f (x)
    a(x) = b(1) + w(1)x    a(x)i = b(1)

math for my slides    feedforward neural network   .

abstract

exp(2a)+1

exp(ac )

exp(ac )

exp(ac )

i,j xj   

math for my slides    feedforward neural network   .

abstract

neural network

le syst  me visuel humain 
topics: parallel with the visual cortex
       pourquoi%ne%pas%s   inspirer%du%cerveau%pour%faire%de%la%vision!%

3

18

neural network

le syst  me visuel humain 
topics: parallel with the visual cortex
       pourquoi%ne%pas%s   inspirer%du%cerveau%pour%faire%de%la%vision!%

3

18

neural network

le syst  me visuel humain 
topics: parallel with the visual cortex
       pourquoi%ne%pas%s   inspirer%du%cerveau%pour%faire%de%la%vision!%

3

18

neural network

le syst  me visuel humain 
topics: parallel with the visual cortex
       pourquoi%ne%pas%s   inspirer%du%cerveau%pour%faire%de%la%vision!%

3

18

neural network

le syst  me visuel humain 
topics: parallel with the visual cortex
       pourquoi%ne%pas%s   inspirer%du%cerveau%pour%faire%de%la%vision!%

3

edges

...

18

neural network

le syst  me visuel humain 
topics: parallel with the visual cortex
       pourquoi%ne%pas%s   inspirer%du%cerveau%pour%faire%de%la%vision!%

3

edges

...

nose

mouth

eyes

18

neural network

le syst  me visuel humain 
topics: parallel with the visual cortex
       pourquoi%ne%pas%s   inspirer%du%cerveau%pour%faire%de%la%vision!%

3

edges

...

nose

mouth

eyes

face

18

biological neurons

4

topics: synapse, axon, dendrite
    we estimate around 1010 and 1011 the number of neurons in 
the human brain:
    they receive information from other neurons through their dendrites
    the       process       the information in their cell body (soma)
    they send information through a       cable       called an axon
    the point of connection between the axon branches and other neurons    dendrites 

are called synapses

biological neurons

5

topics: synapse, axon, dendrite
52

3 outline of the visual system

signal
transmission

c

o

m

p

signal
reception

u

t

a

t

i

o

n

synapses

axon

cell
body

dendrites

other neurons

fig. 3.1: a schematic diagram of information-processing in a neuron. flow of information is from
right to left.

(from hyv  rinen, hurri and hoyer   s book)

biological neurons

6

topics: action potential,    ring rate
    an action potential is an electrical impulse that travels through 
the axon:
    this is how neurons communicate
    it generates a       spike       in the electric potential (voltage) of the axon
    an action potential is generated at neuron only if it receives enough (over some 

threshold) of the       right       pattern of spikes from other neurons

    neurons can generate several such spikes every seconds:

    the frequency of the spikes, called    ring rate, is what characterizes the activity of a 

neuron
- neurons are always    ring a little bit, (spontaneous    ring rate), but they will    re more, given 

the right stimulus

biological neurons

7

topics: action potential,    ring rate
    firing rates of different input neurons combine to in   uence 
the    ring rate of other neurons:
    depending on the dendrite and axon, a neuron can either work to increase 

(excite) or descrease (inhibit) the    ring rate of another neuron

    this is what arti   cial neurons approximate:

    the activation corresponds to a       sort of          ring rate
    the weights between neurons model whether neurons excite or inhibit each other
    the activation function and bias model the thresholded behavior of action 

potentials

biological neurons

8

hubel & wiesel experiment

http://www.youtube.com/watch?v=8vdff3egwfg&feature=related

