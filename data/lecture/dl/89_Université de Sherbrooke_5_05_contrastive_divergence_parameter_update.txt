neural networks
restricted id82 - contrastive divergence (parameter update)

training

2

topics: training objective
    to train an rbm, we   d like to minimize the average negative
   log-likelihood (nll)

1

1

1

l(f (x(t))) =

l(f (x(t))) =
1

t xt   log p(x(t))
t xt   log p(x(t))
    we   d like to proceed by stochastic id119
   x(t)    ex,h    @e(x, h)
@   log p(x(t))

t xt
t xt
= eh    @e(x(t), h)

positive phase

negative phase

@   

@   

@   

 

{{

training

2

topics: training objective
    to train an rbm, we   d like to minimize the average negative
   log-likelihood (nll)

1

1

1

l(f (x(t))) =

l(f (x(t))) =
1

t xt   log p(x(t))
t xt   log p(x(t))
    we   d like to proceed by stochastic id119
   x(t)    ex,h    @e(x, h)
@   log p(x(t))

t xt
t xt
= eh    @e(x(t), h)

positive phase

negative phase

@   

@   

@   

 

hard to
compute

{{

3

 

@   

@   log p(x(t))

topics: contrastive divergence
    x(t)   h(t) = h0
    derivation of             for
   e(x, h)

t xt
t xt   log p(x(t))
derivation of the learning rule
   x(t)    ex,h    @e(x, h)
= eh    @e(x(t), h)
bjhj      
ckxk     j
   x(t)     
     
ex,h    @e(x, h)

   wjk        jk
 wjk jk

eh    @e(x(t), h)

wjkhjxk     k

@e(x(t),   h(t))

@e(  x,   h)

  = wjk

=    

wjkhjxk

=  

   e(x, h)

   wjk

@   

@   

@   

@   

@   

@   

    

 

=  hjxk

    (x(t),   h(t))
    rwe(x, h) =  h x>

@   log p(x(t))

= eh    @e(x(t), h)
derivation of the learning rule

   x(t)    ex,h    @e(x, h)

 

@   

@   

4

@   

topics: contrastive divergence
@e(x(t),   h(t))
    derivation of                       for
@   

eh    @e(x(t), h)
   x(t)     
eh       e(x, h)
ex,h    @e(x, h)
     
   x    = eh    hjxk   x    =    hj {0,1}
eh       e(x, h)

   x   

  = wjk

@e(  x,   h)

@   
   wjk

@   

    

eh [rwe(x, h)|x ] =  h(x) x>
   

w (= w          

@ log p(x(t))

 hjxkp(hj|x)

=  xkp(hj = 1|x)
=   p(h1=1|x)
p(hh =1|x)   

h(x)def

...

= sigm(b + wx)

(14)

    rwe(x, h) =  h x>

ex,h    @e(x, h)

@   

derivation of the learning rule
   

@e(  x,   h)

     
@   log p(x(t))

@   

@   

t xt
= eh    @e(x(t), h)

@   

5

t xt   log p(x(t))
   x(t)    ex,h    @e(x, h)

topics: contrastive divergence
    given        and     the learning rule for             becomes

  x

  = w
eh [rwe(x, h)|x ] =  h(x) x>

    x(t)   h(t) = h0
   
eh    @e(x(t), h)
w (= w         rw   log p(x(t))   
(= w         ehhrwe(x(t), h)   x(t)i   ex,h [rwe(x, h)]   
(= w         ehhrwe(x(t), h)   x(t)i   eh [rwe(  x, h)|  x ]   
   
(= w +       h(x(t)) x(t)>   h(  x)   x>   
    (x(t),   h(t))

   x(t)     
     
ex,h    @e(x, h)

@   

@   

@e(x(t),   h(t))

(14)

@   

(15)

(16)

@e(  x,   h)

(17)
@   
(18)

   

    p(x)
   

cd-k: pseudocode

   
topics: contrastive divergence

   

ii. update parameters

1. for each training example
    x(t)   h(t) = h0
  x
   

i. generate a negative sample     using
k steps of id150, starting at 

    x(t)   h(t) = h0
   
w (= w +       h(x(t)) x(t)>   h(  x)   x>   
b (= b +       h(x(t))   h(  x)   
   
c (= c +       x(t)     x   
   
2. go back to 1 until stopping criteria

    (x(t),   h(t))

    (x(t),   h(t))

6

1

l(f (x(t))) =

l(f (x(t))) =
1

t xt
t xt
= eh    @e(x(t), h)
= eh    @e(x(t), h)

@   

@   log p(x(t))

@   
@   log p(x(t))

eh    @e(x(t), h)

@   

(44)

eh    @e(x(t), h)
ex,h    @e(x, h)

@   

@   

ex,h    @e(x, h)

(45)

(46)
(47)

contrastive divergence (cd)

(hinton, neural computation, 2002)

topics: contrastive divergence

7

    cd-k:  contrastive divergence with k 
           iterations of id150
    in general, the bigger k is, the less biased the 
estimate of the gradient will be
    in practice, k=1 works well for pre-training

