deep learning
ift 725 - r  seaux neuronaux

feedforward neural network
hugo larochelle

d  epartement d   informatique
universit  e de sherbrooke

hugo.larochelle@usherbrooke.ca

1

...

exp(ac )

exp(ac )

exp(ac )

exp(ac )

exp(ac )

exp(ac )

exp(ac )

    p(y = c|x)

review

september 6, 2012

    x1 xd b w1 wd
neural network
    w
    p(y = c|x)
    p(y = c|x)
    p(y = c|x)
    o(a) = softmax(a) =h exp(a1)
pc exp(ac)i>
    {
    o(a) = softmax(a) =h exp(a1)
pc exp(ac)i>
pc exp(ac) . . .
    o(a) = softmax(a) =h exp(a1)
pc exp(ac)i>
    p(y = c|x)
    o(a) = softmax(a) =h exp(a1)
pc exp(ac)i>
pc exp(ac) . . .
topics: multilayer neural network
pc exp(ac) . . .
pc exp(ac) . . .
    o(a) = softmax(a) =h exp(a1)
pc exp(ac)i>
    g(a) = a
    f (x)
    could have l hidden layers:
    f (x)
pc exp(ac) . . .
    p(y = c|x)
    p(y = c|x)
    f (x)
    p(y = c|x)
    f (x)
    h(1)(x) h(2)(x) w(1) w(2) w(3) b(1) b(2) b(3)
    g(a) = sigm(a) =
    o(a) = softmax(a) =h exp(a1)
pc exp(ac)i>
    h(1)(x) h(2)(x) w(1) w(2) w(3) b(1) b(2) b(3)
    o(a) = softmax(a) =h exp(a1)
pc exp(ac)i>
    layer input activation for k>0
pc exp(ac)i>
    o(a) = softmax(a) =h exp(a1)
1+exp( a)
    p(y = c|x)
    h(1)(x) h(2)(x) w(1) w(2) w(3) b(1) b(2) b(3)
    a(k)(x) = b(k) + w(k)h(k 1)x (h(0)(x) = x)
exp(ac )
pc exp(ac) . . .
    h(1)(x) h(2)(x) w(1) w(2) w(3) b(1) b(2) b(3)
    f (x)
pc exp(ac) . . .
pc exp(ac) . . .
    o(a) = softmax(a) =h exp(a1)
pc exp(ac)i>
    a(k)(x) = b(k) + w(k)h(k 1)(x) (h(0)(x) = x)
exp(a)+exp( a) = exp(2a) 1
    g(a) = tanh(a) = exp(a) exp( a)
    h(k)(x) = g(a(k)(x))
    f (x)
pc exp(ac) . . .
    a(k)(x) = b(k) + w(k)h(k 1)x (h(0)(x) = x)
1
    a(k)(x) = b(k) + w(k)h(k 1)x (h(0)(x) = x)
...
...
    h(1)(x) h(2)(x) w(1) w(2) w(3) b(1) b(2) b(3)
    p(y = c|x)
    p(y = c|x)
    f (x)
    h(l+1)(x) = o(a(l+1)(x)) = f (x)
    f (x)
    h(1)(x) h(2)(x) w(1) w(2) w(3) b(1) b(2) b(3)
    h(k)(x) = g(a(k)(x))
    o(a) = softmax(a) =h exp(a1)
pc exp(ac)i>
    p(y = c|x)
    h(k)(x) = g(a(k)(x))
    o(a) = softmax(a) =h exp(a1)
pc exp(ac)i>
    f (x)
    h(k)(x) = g(a(k)(x))
    g(a) = max(0, a)
pc exp(ac) . . .
    a(k)(x) = b(k) + w(k)h(k 1)x (h(0) = x)
    hidden layer activation (k from 1 to l):
    a(k)(x) = b(k) + w(k)h(k 1)x (h(0)(x) = x)
    h(1)(x) h(2)(x) w(1) w(2) w(3) b(1) b(2) b(3)
pc exp(ac) . . .
pc exp(ac)i>
    o(a) = softmax(a) =h exp(a1)
    h(1)(x) h(2)(x) w(1) w(2) w(3) b(1) b(2) b(3)
    h(1)(x) h(2)(x) w(1) w(2) w(3) b(1) b(2) b(3)
    h(l+1)(x) = o(a(l+1)(x)) = f (x)
    h(l+1)(x) = o(a(l+1)(x)) = f (x)
exp(ac )
    h(l+1)(x) = o(a(l+1)(x)) = f (x)
pc exp(ac) . . .
    h(k)(x) = g(a(k)(x))
    f (x)
    a(x) = b +pi wixi = b + w>x
1
...
...
    h(k)(x) = g(a(k)(x))
    g(a) = reclin(a) = max(0, a)
    a(k)(x) = b(k) + w(k)h(k 1)x (h(0)(x) = x)
    a(x) = b +pi wixi = b + w>x
    f (x)
    a(k)(x) = b(k) + w(k)h(k 1)x (h(0)(x) = x)
    a(k)(x) = b(k) + w(k)h(k 1)x (h(0) = x)
    h(l+1)(x) = o(a(l+1)(x)) = f (x)
    h(1)(x) h(2)(x) w(1) w(2) w(3) b(1) b(2) b(3)
    f (x)
    h(x) = g(a(x)) = g(b +pi wixi)
    h(k)(x) = g(a(k)(x))
    h(l+1)(x) = o(a(l+1)(x)) = f (x)
    h(x) = g(a(x)) = g(b +pi wixi)
    a(k)(x) = b(k) + w(k)h(k 1)x (h(0)(x) = x)
    h(k)(x) = g(a(k)(x))
    g(  ) b
    h(1)(x) h(2)(x) w(1) w(2) w(3) b(1) b(2) b(3)
    h(k)(x) = g(a(k)(x))
    output layer activation (k=l+1):
    h(1)(x) h(2)(x) w(1) w(2) w(3) b(1) b(2) b(3)
    h(k)(x) = g(a(k)(x))
    h(l+1)(x) = o(a(l+1)(x)) = f (x)
    h(l+1)(x) = o(a(l+1)(x)) = f (x)
1
...
...
    a(k)(x) = b(k) + w(k)h(k 1)x (h(0)(x) = x)
    w (1)
b(1)
    a(k)(x) = b(k) + w(k)h(k 1)x (h(0)(x) = x)
xj h(x)i
    x1 xd
    x1 xd
    h(l+1)(x) = o(a(l+1)(x)) = f (x)
    h(l+1)(x) = o(a(l+1)(x)) = f (x)
i
i,j
    h(k)(x) = g(a(k)(x))
    h(k)(x) = g(a(k)(x))
    w
    w
    h(x) = g(a(x))
    h(l+1)(x) = o(a(l+1)(x)) = f (x)
    h(l+1)(x) = o(a(l+1)(x)) = f (x)
    a(x) = b(1) + w(1)x    a(x)i = b(1)

math for my slides    feedforward neural network   .

exp(ac )

exp(ac )

exp(ac )

2

math for my slides    feedforward neural network   .

deep learning
topics: deep learning, distributed representation
    deep learning is research on learning models with multilayer 
representations
    multilayer (feed-forward) neural network
    multilayer graphical model (deep belief network, deep id82)
    each layer corresponds to a       distributed representation      

    units in layer are not mutually exclusive
- each unit is a separate feature of the input
two units can be       active       at the same time
-

    they do not correspond to a partitioning (id91) of the inputs

-

in id91, an input can only belong to a single cluster

3

deep learning
le syst  me visuel humain 
topics: inspiration from visual cortex
       pourquoi%ne%pas%s   inspirer%du%cerveau%pour%faire%de%la%vision!%

4

deep learning
le syst  me visuel humain 
topics: inspiration from visual cortex
       pourquoi%ne%pas%s   inspirer%du%cerveau%pour%faire%de%la%vision!%

4

deep learning
le syst  me visuel humain 
topics: inspiration from visual cortex
       pourquoi%ne%pas%s   inspirer%du%cerveau%pour%faire%de%la%vision!%

4

deep learning
le syst  me visuel humain 
topics: inspiration from visual cortex
       pourquoi%ne%pas%s   inspirer%du%cerveau%pour%faire%de%la%vision!%

4

deep learning
le syst  me visuel humain 
topics: inspiration from visual cortex
       pourquoi%ne%pas%s   inspirer%du%cerveau%pour%faire%de%la%vision!%

edges

...

4

deep learning
le syst  me visuel humain 
topics: inspiration from visual cortex
       pourquoi%ne%pas%s   inspirer%du%cerveau%pour%faire%de%la%vision!%

edges

...

nose

mouth

eyes

4

deep learning
le syst  me visuel humain 
topics: inspiration from visual cortex
       pourquoi%ne%pas%s   inspirer%du%cerveau%pour%faire%de%la%vision!%

edges

...

nose

mouth

eyes

face

4

deep learning

topics: theoretical justi   cation
    a deep architecture can represent certain functions 
(exponentially) more compactly
    example: boolean functions 

    a boolean circuit is a sort of feed-forward network where hidden units are logic 

gates (i.e. and, or or not functions of their arguments)

    any boolean function can be represented by a       single hidden layer       boolean circuit

- however, it might require an exponential number of hidden units

    it can be shown that there are boolean functions which

-

-

require an exponential number of hidden units in the single layer case
require a polynomial number of hidden units if we can adapt the number of layers

    see       exploring strategies for training deep neural networks       for a discussion.

5

deep learning

topics: success stories (microsoft research)

6

deep learning

topics: success stories (google)

7

deep learning

topics: why training is hard
    first hypothesis: optimization is harder
(under   tting)
    vanishing gradient problem
    saturated units block gradient 

propagation

    this is a well known problem in
recurrent neural networks

feedforward neural network
hugo larochelle

d  epartement d   informatique
universit  e de sherbrooke

hugo.larochelle@usherbrooke.ca

september 6, 2012

1+exp( a)
exp(a)+exp( a) = exp(2a) 1
...

1

1

...

...

    x1 xd b w1 wd
    w
    {
    g(a) = a
    g(a) = sigm(a) =
    g(a) = tanh(a) = exp(a) exp( a)
    g(a) = max(0, a)
1
    g(a) = reclin(a) = max(0, a)
    g(  ) b
...
    w (1)
b(1)
    x1 xd
i
    w
    h(x) = g(a(x))
    a(x) = b(1) + w(1)x    a(x)i = b(1)

    a(x) = b +pi wixi = b + w>x
    h(x) = g(a(x)) = g(b +pi wixi)

...
xj h(x)i
    x1 xd
    w

i,j

...

...

8

math for my slides    feedforward neural network   .

math for my slides    feedforward neural network   .

    a(x) = b +pi wixi = b + w>x
    h(x) = g(a(x)) = g(b +pi wixi)

1

t pt r   l(f (x(t);    ), y(t))    r      (   )

deep learning
    l(f (x(t);    ), y(t))
       (   )
    l(f (x(t);    ), y(t))
    l(f (x(t);    ), y(t))
    l(f (x(t);    ), y(t))
      =   1
topics: why training is hard
       (   )
       (   )
       (   )
    l(f (x(t);    ), y(t))
    l(f (x(t);    ), y(t))
t pt r   l(f (x(t);    ), y(t))    r      (   )
t pt r   l(f (x(t);    ), y(t))    r      (   )
              +  
      =   1
      =   1
      =   1
    second hypothesis: over   tting
       (   )
       (   )
    {x 2 rd | rxf (x) = 0}
t pt r   l(f (x(t);    ), y(t))    r      (   )
              +  
              +  
              +  
t pt r   l(f (x(t);    ), y(t))    r      (   )
      =   1
    we are exploring a space of complex functions
      =   1
    v>r2
xf (x)v > 0 8v
    {x 2 rd | rxf (x) = 0}
    {x 2 rd | rxf (x) = 0}
    {x 2 rd | rxf (x) = 0}
              +  
    deep nets usually have lots of parameters
              +  
    v>r2
xf (x)v < 0 8v
    v>r2
    v>r2
    v>r2
xf (x)v > 0 8v
xf (x)v > 0 8v
xf (x)v > 0 8v
    {x 2 rd | rxf (x) = 0}
    might be in a high variance / low bias situation
    {x 2 rd | rxf (x) = 0}
      =  r   l(f (x(t);    ), y(t))    r      (   )
    v>r2
    v>r2
    v>r2
xf (x)v < 0 8v
xf (x)v < 0 8v
xf (x)v < 0 8v
    v>r2
xf (x)v > 0 8v
    v>r2
xf (x)v > 0 8v
    (x(t), y(t))
      =  r   l(f (x(t);    ), y(t))    r      (   )
      =  r   l(f (x(t);    ), y(t))    r      (   )
      =  r   l(f (x(t);    ), y(t))    r      (   )
    v>r2
xf (x)v < 0 8v
    v>r2
xf (x)v < 0 8v
possible
    f    f
    (x(t), y(t))
    (x(t), y(t))
    (x(t), y(t))
      =  r   l(f (x(t);    ), y(t))    r      (   )
      =  r   l(f (x(t);    ), y(t))    r      (   )
    f    f
    f    f
    f    f
    (x(t), y(t))
    (x(t), y(t))
possible
    f    f
possible
    f    f

t pt r   l(f (x(t);    ), y(t))    r      (   )

low variance/

high bias

good trade-off

high variance/

low bias

9

t pt r   l(f (x(t);    ), y(t))    r      (   )

deep learning
    l(f (x(t);    ), y(t))
       (   )
    l(f (x(t);    ), y(t))
    l(f (x(t);    ), y(t))
    l(f (x(t);    ), y(t))
      =   1
topics: why training is hard
       (   )
       (   )
       (   )
    l(f (x(t);    ), y(t))
    l(f (x(t);    ), y(t))
t pt r   l(f (x(t);    ), y(t))    r      (   )
t pt r   l(f (x(t);    ), y(t))    r      (   )
              +  
      =   1
      =   1
      =   1
    second hypothesis: over   tting
       (   )
       (   )
    {x 2 rd | rxf (x) = 0}
t pt r   l(f (x(t);    ), y(t))    r      (   )
              +  
              +  
              +  
t pt r   l(f (x(t);    ), y(t))    r      (   )
      =   1
    we are exploring a space of complex functions
      =   1
    v>r2
xf (x)v > 0 8v
    {x 2 rd | rxf (x) = 0}
    {x 2 rd | rxf (x) = 0}
    {x 2 rd | rxf (x) = 0}
              +  
    deep nets usually have lots of parameters
              +  
    v>r2
xf (x)v < 0 8v
    v>r2
    v>r2
    v>r2
xf (x)v > 0 8v
xf (x)v > 0 8v
xf (x)v > 0 8v
    {x 2 rd | rxf (x) = 0}
    might be in a high variance / low bias situation
    {x 2 rd | rxf (x) = 0}
      =  r   l(f (x(t);    ), y(t))    r      (   )
    v>r2
    v>r2
    v>r2
xf (x)v < 0 8v
xf (x)v < 0 8v
xf (x)v < 0 8v
    v>r2
xf (x)v > 0 8v
    v>r2
xf (x)v > 0 8v
    (x(t), y(t))
      =  r   l(f (x(t);    ), y(t))    r      (   )
      =  r   l(f (x(t);    ), y(t))    r      (   )
      =  r   l(f (x(t);    ), y(t))    r      (   )
    v>r2
xf (x)v < 0 8v
    v>r2
xf (x)v < 0 8v
possible
    f    f
    (x(t), y(t))
    (x(t), y(t))
    (x(t), y(t))
      =  r   l(f (x(t);    ), y(t))    r      (   )
      =  r   l(f (x(t);    ), y(t))    r      (   )
    f    f
    f    f
    f    f
    (x(t), y(t))
    (x(t), y(t))
possible
    f    f
possible
    f    f

t pt r   l(f (x(t);    ), y(t))    r      (   )

low variance/

high bias

good trade-off

high variance/

low bias

9

deep learning

topics: why training is hard
    depending on the problem, one or the other situation will 
tend to prevail

    if    rst hypothesis (under   tting): use better optimization

    this is an active area of research

    if second hypothesis (over   tting): use unsupervised learning

    will act similarly to a regularizer

    over   tting is more common, so we will focus on this case

10

unsupervised pre-training
topics: unsupervised pre-training
    solution: initialize hidden layers using unsupervised learning

    force network to represent latent structure of input distribution

character image

random image

    encourage hidden layers to encode that structure

11

unsupervised pre-training
topics: unsupervised pre-training
    solution: initialize hidden layers using unsupervised learning

    force network to represent latent structure of input distribution

why is one
a character
and the other

is not ?

character image

random image

    encourage hidden layers to encode that structure

11

unsupervised pre-training
topics: unsupervised pre-training
    solution: initialize hidden layers using unsupervised learning

    this is a harder task than supervised learning (classi   cation)

why is one
a character
and the other

is not ?

character image
    hence we expect less over   tting

random image

12

feedforward neural network

feedforward neural network
hugo larochelle

d  epartement d   informatique
universit  e de sherbrooke

hugo.larochelle@usherbrooke.ca

math for my slides    feedforward neural network   .

math for my slides    feedforward neural network   .

math for my slides    feedforward neural network   .

hugo larochelle

hugo larochelle

hugo.larochelle@usherbrooke.ca

hugo.larochelle@usherbrooke.ca

d  epartement d   informatique
universit  e de sherbrooke

    x1 xd b w1 wd
    w

d  epartement d   informatique
universit  e de sherbrooke

    a(x) = b +pi wixi = b + w>x
    h(x) = g(a(x)) = g(b +pi wixi)

unsupervised pre-training
    a(x) = b +pi wixi = b + w>x
    a(x) = b +pi wixi = b + w>x
    h(x) = g(a(x)) = g(b +pi wixi)
    h(x) = g(a(x)) = g(b +pi wixi)
feedforward neural network
feedforward neural network
topics: unsupervised pre-training
feedforward neural network
feedforward neural network
    x1 xd b w1 wd
    x1 xd b w1 wd
    we will use a greedy, layer-wise procedure
hugo larochelle
hugo larochelle
    w
    w
d  epartement d   informatique
    train one layer at a time, from    rst to last, with unsupervised criterion
d  epartement d   informatique
universit  e de sherbrooke
    {
    {
universit  e de sherbrooke
       x the parameters of previous hidden layers
    g(a) = a
    g(a) = a
    g(a) = a
hugo.larochelle@usherbrooke.ca
...
...
    previous layers viewed as feature extraction
september 6, 2012
september 6, 2012
    g(a) = sigm(a) =
    g(a) = sigm(a) =
    g(a) = sigm(a) =
september 6, 2012
september 6, 2012
1+exp( a)
1+exp( a)
exp(a)+exp( a) = exp(2a) 1
    g(a) = tanh(a) = exp(a) exp( a)
exp(a)+exp( a) = exp(2a) 1
    g(a) = tanh(a) = exp(a) exp( a)
    g(a) = tanh(a) = exp(a) exp( a)
...
...
...
...
abstract
abstract
abstract
abstract
    g(a) = max(0, a)
    g(a) = max(0, a)
    g(a) = max(0, a)
math for my slides    feedforward neural network   .
math for my slides    feedforward neural network   .
math for my slides    feedforward neural network   .
math for my slides    feedforward neural network   .
math for my slides    feedforward neural network   .
...
...
...
...
...
    a(x) = b +pi wixi = b + w>x
    a(x) = b +pi wixi = b + w>x
1
1
    a(x) = b +pi wixi = b + w>x
    a(x) = b +pi wixi = b + w>x
    g(a) = reclin(a) = max(0, a)
    g(a) = reclin(a) = max(0, a)
    g(a) = reclin(a) = max(0, a)
    h(x) = g(a(x)) = g(b +pi wixi)
    h(x) = g(a(x)) = g(b +pi wixi)
    h(x) = g(a(x)) = g(b +pi wixi)
    h(x) = g(a(x)) = g(b +pi wixi)
    g(  ) b
    g(  ) b
    g(  ) b
...
...
...
...
...
    w (1)
    w (1)
b(1)
    w (1)
b(1)
b(1)
    x1 xd
    x1 xd
    x1 xd
    x1 xd
    x1 xd
xj h(x)i
xj h(x)i
i
i
i
    w
    w
    w
    w
    w
    h(x) = g(a(x))
    h(x) = g(a(x))
    h(x) = g(a(x))
    a(x) = b(1) + w(1)x    a(x)i = b(1)
    a(x) = b(1) + w(1)x    a(x)i = b(1)
    a(x) = b(1) + w(1)x    a(x)i = b(1)
    {
    {

...
    a(x) = b +pi wixi = b + w>x
    h(x) = g(a(x)) = g(b +pi wixi)
...
    x1 xd
xj h(x)i
    w
    {

    a(x) = b +pi wixi = b + w>x
    h(x) = g(a(x)) = g(b +pi wixi)

1+exp( a)
exp(a)+exp( a) = exp(2a) 1

hugo.larochelle@usherbrooke.ca

september 6, 2012

i,j xj   
i pj w (1)

i,j xj   
i pj w (1)

exp(2a)+1

exp(2a)+1

13

i,j

i,j

i,j

1

1

1

1

1

1

1

math for my slides    feedforward neural network   .

unsupervised pre-training
topics: unsupervised pre-training
    we call this procedure unsupervised pre-training

       rst layer:    nd hidden unit features that are more common in 
training inputs than in random inputs
    second layer:    nd combinations of hidden unit features that are 
more common than random hidden unit features
    third layer:    nd combinations of combinations of ...
    etc.

    pre-training initializes the parameters in a region such that the near 
local optima over   t less the data

14

math for my slides    feedforward neural network   .

fine-tuning

    a(x) = b +pi wixi = b + w>x
    h(x) = g(a(x)) = g(b +pi wixi)

feedforward neural network

feedforward neural network
hugo larochelle

topics:    ne-tuning
    once all layers are pre-trained

    add output layer
    train the whole network using supervised learning
    supervised learning is performed as in
a regular feed-forward network
    forward propagation, id26 and update

    we call this last phase    ne-tuning

    all parameters are       tuned       for the supervised task

at hand

    representation is adjusted to be more discriminative

d  epartement d   informatique
universit  e de sherbrooke

hugo.larochelle@usherbrooke.ca

1

1

...

...

september 6, 2012

    x1 xd b w1 wd
    w
    {
    g(a) = a
...
    g(a) = sigm(a) =
1+exp( a)
exp(a)+exp( a) = exp(2a) 1
    g(a) = tanh(a) = exp(a) exp( a)
...
    g(a) = max(0, a)
1
    g(a) = reclin(a) = max(0, a)
    g(  ) b
...
    w (1)
b(1)
    x1 xd
i
    w
    h(x) = g(a(x))
    a(x) = b(1) + w(1)x    a(x)i = b(1)

...
    a(x) = b +pi wixi = b + w>x
    h(x) = g(a(x)) = g(b +pi wixi)
...
    x1 xd
xj h(x)i
    w
    {

...
math for my slides    feedforward neural network   .
...

    a(x) = b +pi wixi = b + w>x
    h(x) = g(a(x)) = g(b +pi wixi)

15

i,j

1

1

math for my slides    feedforward neural network   .

   

    p(x|h(1)) p(h(1)) h(1) h(2) p(h(1)) =ph(2) p(h(1), h(2))
 xh(1)
 xh(1)
p(h(1)|x)   
    kl(q||p) =ph(1) q(h(1)|x) log    q(h(1)|x)
    kl(q||p) =ph(1) q(h(1)|x) log    q(h(1)|x)
p(h(1)|x)   
deep learning
    kl(q||p) =ph(1) q(h(1)|x) log    q(h(1)|x)
p(h(1)|x)   
    p(x|h(1)) p(h(1)) h(1) h(2) p(h(1)) =ph(2) p(h(1), h(2))
    kl(q||p) =ph(1) q(h(1)|x) log    q(h(1)|x)
p(h(1)|x)   
    p(x|h(1)) p(h(1)) h(1) h(2) p(h(1)) =ph(2) p(h(1), h(2))
 xh(1)
    kl(q||p) =ph(1) q(h(1)|x) log    q(h(1)|x)
p(h(1)|x)   
    kl(q||p) =ph(1) q(h(1)|x) log    q(h(1)|x)
p(h(1)|x)   
    p(x|h(1)) p(h(1)) h(1) h(2) p(h(1)) =ph(2) p(h(1), h(2))
    p(x|h(1)) p(h(1)) h(1) h(2) p(h(1)) =ph(2) p(h(1), h(2))
    p(x|h(1)) p(h(1)) h(1) h(2) p(h(1)) =ph(2) p(h(1), h(2))
    p(x|h(1)) p(h(1)) h(1) h(2) p(h(1)) =ph(2) p(h(1), h(2))
d =nh(l 1)(x(t))ot
 xh(1)
q(h(1)|x) log p(h(1))
 xh(1)
 xh(1)
 xh(1)
 xh(1)
q(h(1)|x) log p(h(1))
q(h(1)|x) log p(h(1))
d =nh(l 1)(x(t))ot
d =nh(l 1)(x(t))ot
d =nh(l 1)(x(t))ot

 xh(1)
d =nh(l 1)(x(t))ot

    build unsupervised training set (with                     ): 
    w(l+1) b(l+1)

topics: pseudocode
    for l=1 to l

q(h(1)|x) log p(h(1))

h(0)(x) = x

t=1

t=1
t=1

t=1

   

   

   

   
   

   
   

 

h(0)(x) = x

    w(l+1) b(l+1)

 to initialize the deep network parameters        ,

    train       greedy module       (rbm, autoencoder) on 
    use hidden layer weights and biases of greedy module
h(0)(x) = x
h(0)(x) = x
    initialize          ,           randomly (as usual)
    train the whole neural network using (supervised) 
stochastic id119 (with backprop)

    w(l) b(l) w(l+1) b(l+1)
    w(l) b(l) w(l+1) b(l+1)

h(0)(x) = x
h(0)(x) = x

    w(l) b(l) w(l+1) b(l+1)
    w(l) b(l) w(l+1) b(l+1)

16

   r(x)={x2rh|9wx=pjwjx  ,j}
   {x2rh|x/2r(x)}

    w(l) b(l) w(l+1) b(l+1)
    w(l) b(l) w(l+1) b(l+1)

h(0)(x) = x

t=1
t=1

   

   
   

16

    p(x|h(1)) p(h(1)) h(1) h(2) p(h(1)) =ph(2) p(h(1), h(2))
 xh(1)
 xh(1)
p(h(1)|x)   
    kl(q||p) =ph(1) q(h(1)|x) log    q(h(1)|x)
    kl(q||p) =ph(1) q(h(1)|x) log    q(h(1)|x)
p(h(1)|x)   
deep learning
    kl(q||p) =ph(1) q(h(1)|x) log    q(h(1)|x)
p(h(1)|x)   
    p(x|h(1)) p(h(1)) h(1) h(2) p(h(1)) =ph(2) p(h(1), h(2))
    kl(q||p) =ph(1) q(h(1)|x) log    q(h(1)|x)
p(h(1)|x)   
    p(x|h(1)) p(h(1)) h(1) h(2) p(h(1)) =ph(2) p(h(1), h(2))
 xh(1)
    kl(q||p) =ph(1) q(h(1)|x) log    q(h(1)|x)
p(h(1)|x)   
    kl(q||p) =ph(1) q(h(1)|x) log    q(h(1)|x)
p(h(1)|x)   
    p(x|h(1)) p(h(1)) h(1) h(2) p(h(1)) =ph(2) p(h(1), h(2))
    p(x|h(1)) p(h(1)) h(1) h(2) p(h(1)) =ph(2) p(h(1), h(2))
    p(x|h(1)) p(h(1)) h(1) h(2) p(h(1)) =ph(2) p(h(1), h(2))
    p(x|h(1)) p(h(1)) h(1) h(2) p(h(1)) =ph(2) p(h(1), h(2))
d =nh(l 1)(x(t))ot
 xh(1)
q(h(1)|x) log p(h(1))
 xh(1)
 xh(1)
 xh(1)
 xh(1)
q(h(1)|x) log p(h(1))
q(h(1)|x) log p(h(1))
d =nh(l 1)(x(t))ot
d =nh(l 1)(x(t))ot
d =nh(l 1)(x(t))ot

 xh(1)
d =nh(l 1)(x(t))ot

    build unsupervised training set (with                     ): 
    w(l+1) b(l+1)

topics: pseudocode
    for l=1 to l

q(h(1)|x) log p(h(1))

pre-training

t=1

t=1

   

   

   

   
   

 

h(0)(x) = x

    w(l+1) b(l+1)

 to initialize the deep network parameters        ,

    train       greedy module       (rbm, autoencoder) on 
    use hidden layer weights and biases of greedy module
h(0)(x) = x
h(0)(x) = x
    initialize          ,           randomly (as usual)
    train the whole neural network using (supervised) 
stochastic id119 (with backprop)

    w(l) b(l) w(l+1) b(l+1)
    w(l) b(l) w(l+1) b(l+1)

h(0)(x) = x
h(0)(x) = x

   r(x)={x2rh|9wx=pjwjx  ,j}
   {x(t)}
    p(x|h(1)) p(h(1)) h(1) h(2) p(h(1)) =ph(2) p(h(1), h(2))
 xh(1)
 xh(1)
p(h(1)|x)   
    kl(q||p) =ph(1) q(h(1)|x) log    q(h(1)|x)
    kl(q||p) =ph(1) q(h(1)|x) log    q(h(1)|x)
p(h(1)|x)   
deep learning
    kl(q||p) =ph(1) q(h(1)|x) log    q(h(1)|x)
p(h(1)|x)   
    p(x|h(1)) p(h(1)) h(1) h(2) p(h(1)) =ph(2) p(h(1), h(2))
    kl(q||p) =ph(1) q(h(1)|x) log    q(h(1)|x)
p(h(1)|x)   
    p(x|h(1)) p(h(1)) h(1) h(2) p(h(1)) =ph(2) p(h(1), h(2))
 xh(1)
    kl(q||p) =ph(1) q(h(1)|x) log    q(h(1)|x)
p(h(1)|x)   
    kl(q||p) =ph(1) q(h(1)|x) log    q(h(1)|x)
p(h(1)|x)   
   9w,t    x(t   ) =pt6=t   wtx(t)
    p(x|h(1)) p(h(1)) h(1) h(2) p(h(1)) =ph(2) p(h(1), h(2))
    p(x|h(1)) p(h(1)) h(1) h(2) p(h(1)) =ph(2) p(h(1), h(2))
    p(x|h(1)) p(h(1)) h(1) h(2) p(h(1)) =ph(2) p(h(1), h(2))
    p(x|h(1)) p(h(1)) h(1) h(2) p(h(1)) =ph(2) p(h(1), h(2))
   {x2rh|x/2r(x)}
d =nh(l 1)(x(t))ot
 xh(1)
q(h(1)|x) log p(h(1))
 xh(1)
 xh(1)
 xh(1)
 xh(1)
q(h(1)|x) log p(h(1))
q(h(1)|x) log p(h(1))
   r(x)={x2rh|9w x=pjwjx  ,j}
d =nh(l 1)(x(t))ot
d =nh(l 1)(x(t))ot
d =nh(l 1)(x(t))ot
   {x2rh|x /2r(x)}

    train       greedy module       (rbm, autoencoder) on 
    use hidden layer weights and biases of greedy module
h(0)(x) = x
h(0)(x) = x
    initialize          ,           randomly (as usual)
    train the whole neural network using (supervised) 
stochastic id119 (with backprop)

 xh(1)
d =nh(l 1)(x(t))ot

    build unsupervised training set (with                     ): 
    w(l+1) b(l+1)

topics: pseudocode
    for l=1 to l

    w(l) b(l) w(l+1) b(l+1)
    w(l) b(l) w(l+1) b(l+1)

 to initialize the deep network parameters        ,

    w(l+1) b(l+1)

q(h(1)|x) log p(h(1))

    w(l) b(l) w(l+1) b(l+1)
    w(l) b(l) w(l+1) b(l+1)

   ne-
tuning

pre-training

h(0)(x) = x

h(0)(x) = x

h(0)(x) = x
h(0)(x) = x

t=1

t=1
t=1

t=1

   

   

   

   

   
   

   
   

16

 

what kind of unsupervised learning ?
topics: stacked rbms, stacked autoencoders
    stacked restricted id82s:

    hinton, teh and osindero suggested this procedure with rbms

- a fast learning algorithm for deep belief nets. 

hinton, teh, osindero., 2006.

- to recognize shapes,    rst learn to generate images. 

hinton, 2006.

    stacked autoencoders:

    bengio, lamblin, popovici and larochelle studied and generalized the procedure to 

autoencoders
- greedy layer-wise training of deep networks. 
bengio, lamblin, popovici and larochelle, 2007.

    ranzato, poultney, chopra and lecun also generalized it to sparse autoencoders

- ef   cient learning of sparse representations with an energy-based model. 

ranzato, poultney, chopra and lecun, 2007.

17

what kind of unsupervised learning ?
topics: stacked rbms, stacked autoencoders
    stacked denoising autoencoders:

    proposed by vincent, larochelle, bengio and manzagol

- extracting and composing robust features with denoising autoencoders, 
vincent, larochelle, bengio and manzagol, 2008.

    and more:

    stacked semi-supervised embeddings

- deep learning via semi-supervised embedding. weston, ratle and collobert, 2008.

    stacked kernel pca

- kernel methods for deep learning. 

cho and saul, 2009.

    stacked independent subspace analysis

- learning hierarchical invariant spatio-temporal features for action recognition with 

independent subspace analysis. 
le, zou, yeung and ng, 2011.

18

deep learning

topics: datasets
    datasets generated with varying number of factors of 
variations
tall or wide?

variations on mnist

an empirical evaluation of deep architectures on problems with many factors of variation

an empirical evaluation of deep architectures on problems with many factors of variation

mnist-rotation

mnist-random-

background

mnist-image-
background

mnist-

background- 

figure 3. iterative training construction of the stacked au-

(c) predict y

an empirical evaluation of deep architectures on problems with many factors of variation

figure 5. from top to bottom, samples from rectangles and
rectangles-image.

convexe shape or not?

3.2. discrimination between tall and wide

rectangles

rotation
an empirical evaluation of deep architectures on problems with many factors of variation
larochelle, erhan, courville, bergstra and bengio, 2007

in this task, a learning algorithm needs to recognize
whether a rectangle contained in an image has a larger
figure 6. samples from convex, where the    rst, fourth,    fth
width or length. the rectangle can be situated any-
and last samples correspond to convex white pixel sets.
where in the 28   28 pixel image. we generated two
19
datasets for this problem:

figure 4. from top to bottom, samples from mnist-rot,
mnist-back-rand, mnist-back-image, mnist-rot-back-image.

figure 5. from top to bottom, samples from rectangles and

deep learning

topics: impact of initialization

97

network

mnist-small

type

depth

classif. test error

neural network
(random initialization,
+    ne-tuning)

deep net

saa network
(autoassociator learning
+    ne-tuning)

deep net +
autoencoder

1
2
3
4

1
2
3
4

deep net +

srbm network
(cd-1 learning
+    ne-tuning)

rbm

1
2
3
4

mnist-rotation
classif. test error
15.22 %    0.31
10.63 %    0.27
11.98 %    0.28
11.73 %    0.29
11.43%    0.28
9.88 %    0.26
9.22 %    0.25
9.20 %    0.25
10.47 %    0.27
9.54 %    0.26
8.80 %    0.25
8.83 %    0.24

4.14 %    0.17
4.03 %    0.17
4.24 %    0.18
4.47 %    0.18
3.87 %    0.17
3.38 %    0.16
3.37 %    0.16
3.39 %    0.16
3.17 %    0.15
2.74 %    0.14
2.71 %    0.14
2.72 %    0.14

20
tableau 6.3     classi   cation performance on mnist-small and mnist-rotation of dif-

deep learning

erhan, bengio, courville, manzagol, vincent and bengio

topics: impact of initialization

why does unsupervised pre-training help deep learning? 
erhan, bengio, courville, manzagol, vincent and bengio, 2011

figure 9: effect of layer size on the changes brought by unsupervised pre-training, for networks
with 1, 2 or 3 hidden layers. experiments on mnist. error bars have a height of two

21

deep learning

erhan, bengio, courville, manzagol, vincent and bengio

topics: impact of initialization

acts as a regularizer:

- over   ts less with large capacity
- under   ts with small capacity

why does unsupervised pre-training help deep learning? 
erhan, bengio, courville, manzagol, vincent and bengio, 2011

figure 9: effect of layer size on the changes brought by unsupervised pre-training, for networks
with 1, 2 or 3 hidden layers. experiments on mnist. error bars have a height of two

21

3.5%

r
o
r
r
e
 
s
s
a
c

l

3%

deep learning

3%

3.5%

r
o
r
r
e
 
s
s
a
c

l

topics: choice of hidden layer size

total number of hidden units

1500

2.5%

900

3k

6k

2.5%

(a) srbm network.

rbm

srbm

99

900

1500

3k

6k

total number of hidden units

(b) saa network.

autoencoder

saa

4%

figure 6.9     classi   cation performance on mnist-small of 3-layer deep networks for
three kinds of architectures, as a function of the total number of hidden units. the three
architectures have increasing / constant / decreasing layer sizes from the bottom to the
top layers. error-bars represent 95% con   dence intervals.

3.5%

3.5%

4%

decreasing width
constant width
increasing width

decreasing width
constant width
increasing width

r
o
r
r
e
 
s
s
a
c

l

r
o
r
r
e
 
s
s
a
c

l

l
l

a
m

s
-
t
s
n
m

i

n
o
i
t
a
t
o
r
-
t
s
n
m

i

3%

2.5%

900

12.5%

12%

11.5%

1500

3k

6k

total number of hidden units

srbm

(a) srbm network.

decreasing width
constant width
increasing width

3%

2.5%

900

13%

12.5%

12%

1500

3k

6k

total number of hidden units

saa

(b) saa network.

decreasing width
constant width
increasing width

11%

r
o
r
r
e
 
s
s
a
c

figure 6.9     classi   cation performance on mnist-small of 3-layer deep networks for
three kinds of architectures, as a function of the total number of hidden units. the three
architectures have increasing / constant / decreasing layer sizes from the bottom to the
top layers. error-bars represent 95% con   dence intervals.

r
o
r
r
e
 
s
s
a
c

10.5%

11.5%

10.5%

10%

11%

l

l

9.5%

9%

900

1500

3k

6k

total number of hidden units

10%

9.5%

900

1500

3k

6k

total number of hidden units

22

(a) srbm network.

(b) saa network.

extracting and composing robust features with denoising autoencoders

extracting and composing robust features with denoising autoencoders

deep learning

topics: performance on different datasets

table 1. comparison of stacked denoising autoencoders (sda-3) with other models.
test error rate on all considered classi   cation problems is reported together with a 95% con   dence interval. best performer
is in bold, as well as those for which con   dence intervals overlap. sda-3 appears to achieve performance superior or
stacked
equivalent to the best other model on all problems except bg-rand. for sda-3, we also indicate the fraction   of destroyed
input components, as chosen by proper model selection. note that saa-3 is equivalent to sda-3 with   = 0%.

table 1. comparison of stacked denoising autoencoders (sda-3) with other models.
test error rate on all considered classi   cation problems is reported together with a 95% con   dence interval. best performer
is in bold, as well as those for which con   dence intervals overlap. sda-3 appears to achieve performance superior or
equivalent to the best other model on all problems except bg-rand. for sda-3, we also indicate the fraction   of destroyed
input components, as chosen by proper model selection. note that saa-3 is equivalent to sda-3 with   = 0%.

denoising autoencoders

autoencoders

stacked
rbms

stacked

id166rbf
3.03  0.15
11.11  0.28
14.58  0.31
22.61  0.37
55.18  0.44
2.15  0.13
24.04  0.37
19.13  0.34

dataset
id166poly
basic
3.69  0.17
rot
15.42  0.32
bg-rand
16.62  0.33
bg-img
24.01  0.37
rot-bg-img
56.41  0.43
rect
2.15  0.13
rect-img
24.05  0.37
convex
19.82  0.35

id166rbf
dbn-1
3.03  0.15
3.94  0.17
11.11  0.28
14.69  0.31
14.58  0.31
9.80  0.26
22.61  0.37
16.15  0.32
55.18  0.44
52.21  0.44
2.15  0.13
4.71  0.19
24.04  0.37
23.69  0.37
19.13  0.34
19.92  0.35

id166poly
saa-3
3.69  0.17
3.46  0.16
15.42  0.32
10.30  0.27
16.62  0.33
11.28  0.28
24.01  0.37
23.00  0.37
56.41  0.43
51.93  0.44
2.15  0.13
2.41  0.13
24.05  0.37
24.05  0.37
19.82  0.35
18.41  0.34

dbn-1
dbn-3
3.94  0.17
3.11  0.15
14.69  0.31
10.30  0.27
9.80  0.26
6.73  0.22
16.15  0.32
16.31  0.32
52.21  0.44
47.39  0.44
4.71  0.19
2.60  0.14
23.69  0.37
22.50  0.37
19.92  0.35
18.63  0.34

saa-3
sda-3 ( )
3.46  0.16
2.80  0.14 (10%)
10.30  0.27
10.29  0.27 (10%)
11.28  0.28
10.38  0.27 (40%)
23.00  0.37
16.68  0.33 (25%)
51.93  0.44
44.49  0.44 (25%)
2.41  0.13
1.99  0.12 (10%)
24.05  0.37
21.59  0.36 (25%)
18.41  0.34
19.06  0.34 (10%)

dbn-3
3.11  0.15
10.30  0.27
6.73  0.22
16.31  0.32
47.39  0.44
2.60  0.14
22.50  0.37
18.63  0.34

extracting and composing robust features with denoising autoencoders,  
vincent, larochelle, bengio and manzagol, 2008.

23

deep autoencoder

topics: deep autoencoder
    same procedure can be used to initialize a deep autoencoder

    this is an example of a situation 

where under   tting is an issue
- pre-training initializes the 

optimization problem in a region 
with better local optima of training 
objective

    each rbm used to initialize
parameters both in encoder
and decoder (      unrolling      )

    better optimization algorithms

can also help
- deep learning via hessian-free 

optimization. james martens, 2010

from hinton and salakhutdinov, science, 2006

24

deep autoencoder

topics: deep autoencoder
    can be used to reduce the dimensionality of the data
    will have better reconstruction than a single layer network (i.e. pca)

original data

deep autoencoder

reconstruction
pca reconstruction

from hinton and salakhutdinov, science, 2006

25

deep autoencoder

topics: deep autoencoder
    if we reduce to 2d, we can visualize the data (e.g. a collection 
of document)

from hinton and salakhutdinov, science, 2006

26

deep learning

hugo larochelle

deep belief network

hugo larochelle
d  epartement d   informatique
deep learning
universit  e de sherbrooke

d  epartement d   informatique
universit  e de sherbrooke

hugo.larochelle@usherbrooke.ca

october 25, 2012

hugo larochelle
october 25, 2012

hugo.larochelle@usherbrooke.ca
d  epartement d   informatique
universit  e de sherbrooke

topics: deep belief network
    the idea of pre-training came from work on deep belief 
networks (dbns)
abstract
math for my slides    deep learning   .
hugo.larochelle@usherbrooke.ca
    it is a generative model that mixes undirected
...
and directed connections between variables
    top 2 layers    distribution                 is an rbm
    other layers form a id110:
math for my slides    deep learning   .

    x h(1) h(2) h(3)
math for my slides    deep learning   .
    p(h(2), h(3))
    p(xi = 1|h(1)) = sigm(b(0) + w(1)>h(1))
j = 1|h(2)) = sigm(b(1) + w(2)>h(2))
    p(h(1)

dbn   s graphical model
    x h(1) h(2) h(3)

    x h(1) h(2) h(3)
...

math for my slides    deep learning   .

october 25, 2012

abstract

abstract

math for my slides    deep learning   .

    x h(1) h(2) h(3)
    p(h(2), h(3))
the conditional distributions of a layers given the one
    p(xi = 1|h(1)) = sigm(b(0) + w(1)>h(1))
    x h(1) h(2) h(3)
above it are  
j = 1|h(2)) = sigm(b(1) + w(2)>h(2))
    p(h(1)
    p(h(2), h(3))
    p(xi = 1|h(1)) = sigm(b(0) + w(1)>h(1))
j = 1|h(2)) = sigm(b(1) + w(2)>h(2))
    p(h(1)

this is referred to as a sigmoid belief network (sbn)

-

-

    a dbn is not a feed-forward network

math for my slides    deep learning   .

...

    x h(1) h(2) h(3)

math for my slides    deep learning   .

...

    x h(1) h(2) h(3)

27

deep belief network

october 25, 2012

hugo larochelle
october 25, 2012

topics: deep belief network
    the idea of pre-training came from work on deep belief 
networks (dbns)
abstract
math for my slides    deep learning   .
hugo.larochelle@usherbrooke.ca
    it is a generative model that mixes undirected
...
and directed connections between variables
    top 2 layers    distribution                 is an rbm
    other layers form a id110:
math for my slides    deep learning   .

    x h(1) h(2) h(3)
math for my slides    deep learning   .
    p(h(2), h(3))
    p(xi = 1|h(1)) = sigm(b(0) + w(1)>h(1))
j = 1|h(2)) = sigm(b(1) + w(2)>h(2))
    p(h(1)

dbn   s graphical model
    x h(1) h(2) h(3)

    x h(1) h(2) h(3)
...

math for my slides    deep learning   .

rbm
abstract

math for my slides    deep learning   .

    x h(1) h(2) h(3)
    p(h(2), h(3))
the conditional distributions of a layers given the one
    p(xi = 1|h(1)) = sigm(b(0) + w(1)>h(1))
    x h(1) h(2) h(3)
above it are  
j = 1|h(2)) = sigm(b(1) + w(2)>h(2))
    p(h(1)
    p(h(2), h(3))
    p(xi = 1|h(1)) = sigm(b(0) + w(1)>h(1))
j = 1|h(2)) = sigm(b(1) + w(2)>h(2))
    p(h(1)

this is referred to as a sigmoid belief network (sbn)

-

-

    a dbn is not a feed-forward network

math for my slides    deep learning   .

    x h(1) h(2) h(3)

math for my slides    deep learning   .

    x h(1) h(2) h(3)

abstract

october 25, 2012

hugo larochelle

deep learning

hugo.larochelle@usherbrooke.ca

d  epartement d   informatique
universit  e de sherbrooke

hugo larochelle
d  epartement d   informatique
deep learning
universit  e de sherbrooke

hugo.larochelle@usherbrooke.ca
d  epartement d   informatique
universit  e de sherbrooke

   { i,ui|xui= iuietu>iuj=1i=j}
   {x2rh|x/2r(x)}
   r(x)={x2rh|9wx=pjwjx  ,j}
   9w,t   x(t   )=pt6=t   wtx(t)

27

...

...

deep belief network

october 25, 2012

hugo larochelle
october 25, 2012

topics: deep belief network
    the idea of pre-training came from work on deep belief 
networks (dbns)
abstract
math for my slides    deep learning   .
hugo.larochelle@usherbrooke.ca
    it is a generative model that mixes undirected
...
and directed connections between variables
    top 2 layers    distribution                 is an rbm
    other layers form a id110:
math for my slides    deep learning   .

    x h(1) h(2) h(3)
math for my slides    deep learning   .
    p(h(2), h(3))
    p(xi = 1|h(1)) = sigm(b(0) + w(1)>h(1))
j = 1|h(2)) = sigm(b(1) + w(2)>h(2))
    p(h(1)

dbn   s graphical model
    x h(1) h(2) h(3)

    x h(1) h(2) h(3)
...

math for my slides    deep learning   .

rbm
abstract

math for my slides    deep learning   .

    x h(1) h(2) h(3)
    p(h(2), h(3))
the conditional distributions of a layers given the one
    p(xi = 1|h(1)) = sigm(b(0) + w(1)>h(1))
    x h(1) h(2) h(3)
above it are  
j = 1|h(2)) = sigm(b(1) + w(2)>h(2))
    p(h(1)
    p(h(2), h(3))
    p(xi = 1|h(1)) = sigm(b(0) + w(1)>h(1))
j = 1|h(2)) = sigm(b(1) + w(2)>h(2))
    p(h(1)

this is referred to as a sigmoid belief network (sbn)

-

-

    a dbn is not a feed-forward network

math for my slides    deep learning   .

    x h(1) h(2) h(3)

math for my slides    deep learning   .

    x h(1) h(2) h(3)

abstract

october 25, 2012

hugo larochelle

deep learning

hugo.larochelle@usherbrooke.ca

d  epartement d   informatique
universit  e de sherbrooke

hugo larochelle
d  epartement d   informatique
deep learning
universit  e de sherbrooke

hugo.larochelle@usherbrooke.ca
d  epartement d   informatique
universit  e de sherbrooke

   { i,ui|xui= iuietu>iuj=1i=j}
   { i,ui|xui= iuietu>iuj=1i=j}
   {x2rh|x/2r(x)}
   {x2rh|x/2r(x)}
   r(x)={x2rh|9wx=pjwjx  ,j}
   r(x)={x2rh|9wx=pjwjx  ,j}
   9w,t   x(t   )=pt6=t   wtx(t)

sbn

27

...

...

abstract
abstract
abstract

math for my slides    deep learning   .
math for my slides    deep learning   .
math for my slides    deep learning   .

    x h(1) h(2) h(3)
deep belief network
    p(h(2), h(3))
    p(xi = 1|h(1)) = sigm(b(0) + w(1)>h(1))
    x h(1) h(2) h(3)
    x h(1) h(2) h(3)
    x h(1) h(2) h(3)
topics: deep belief network
    p(h(2), h(3))
    p(h(2), h(3))
    p(h(2), h(3))
j = 1|h(2)) = sigm(b(1) + w(2)>h(2))
    p(h(1)
    the full distribution of a dbn is as follows
    p(xi = 1|h(1)) = sigm(b(0) + w(1)>h(1))
    p(xi = 1|h(1)) = sigm(b(0) + w(1)>h(1))
    p(xi = 1|h(1)) = sigm(b(0) + w(1)>h(1))
j = 1|h(2)) = sigm(b(1) + w(2)>h(2))
    p(h(1)
j = 1|h(2)) = sigm(b(1) + w(2)>h(2))
    p(h(1)
    p(x, h(1), h(2), h(3)) = p(h(2), h(3)) p(h(1)|h(2)) p(x|h(1))
j = 1|h(2)) = sigm(b(1) + w(2)>h(2))
    p(h(1)
    p(h(2), h(3)) = exp   h(2)>w(3)h(3) + b(2)>h(2) + b(3)>h(3)    /z
    p(x, h(1), h(2), h(3)) = p(h(2), h(3)) p(h(1)|h(2)) p(x|h(1))
    p(x, h(1), h(2), h(3)) = p(h(2), h(3)) p(h(1)|h(2)) p(x|h(1))
    where:
    p(x, h(1), h(2), h(3)) = p(h(2), h(3)) p(h(1)|h(2)) p(x|h(1))
    p(h(2), h(3)) = exp   h(2)>w(3)h(3) + b(2)>h(2) + b(3)>h(3)    /z
    p(h(2), h(3)) = exp   h(2)>w(3)h(3) + b(2)>h(2) + b(3)>h(3)    /z
    p(h(2), h(3)) = exp   h(2)>w(3)h(3) + b(2)>h(2) + b(3)>h(3)    /z
-
    p(h(1)|h(2)) =qj p(h(1)
    p(h(1)|h(2)) =qj p(h(1)
    p(h(1)|h(2)) =qj p(h(1)
    p(h(1)|h(2)) =qj p(h(1)
    p(x|h(1)) =qi p(xi|h(1))
    p(x|h(1)) =qi p(xi|h(1))
    p(x|h(1)) =qi p(xi|h(1))
    p(x|h(1)) =qi p(xi|h(1))
    http://www.cs.toronto.edu/~hinton/adi/index.htm

    to observe a dbn trained on mnist in action:

|h(2))

|h(2))
|h(2))
|h(2))

 
 
 

j
j
j

j

-

-

    as in a deep feed-forward network, training a dbn is hard

    initialization will play a crucial role on the results

28

d  epartement d   informatique
universit  e de sherbrooke

hugo.larochelle@usherbrooke.ca

deep learning

j

abstract

|h(2))

math for my slides    deep learning   .

hugo larochelle

hugo larochelle

j = 1|h(2)) = sigm(b(1) + w(2)>h(2))

deep learning

d  epartement d   informatique
universit  e de sherbrooke

deep belief network

    p(h(1)
october 25, 2012
    p(x, h(1), h(2), h(3)) = p(h(2), h(3)) p(h(1)|h(2)) p(x|h(1))
    p(h(2), h(3)) = exp   h(2)>w(3)h(3) + b(2)>h(2) + b(3)>h(3)    /z
deep learning
    p(h(1)|h(2)) =qj p(h(1)
    p(x|h(1)) =qi p(xi|h(1))
    p(x) =ph(1) p(x, h(1))
hugo larochelle
    p(x, h(1)) = p(x|h(1))ph(2) p(h(1), h(2))
d  epartement d   informatique
math for my slides    deep learning   .
    p(h(1), h(2)) = p(h(1)|h(2))ph(3) p(h(2), h(3))
universit  e de sherbrooke
    x h(1) h(2) h(3)
october 25, 2012
hugo.larochelle@usherbrooke.ca
math for my slides    deep learning   .
october 25, 2012

    x h(1) h(2) h(3)
    p(h(2), h(3))
    p(xi = 1|h(1)) = sigm(b(0) + w(1)>h(1))
topics: deep belief network
j = 1|h(2)) = sigm(b(1) + w(2)>h(2))
    p(h(1)
    x h(1) h(2) h(3)
    p(x, h(1), h(2), h(3)) = p(h(2), h(3)) p(h(1)|h(2)) p(x|h(1))
    this is where the rbm stacking procedure comes from
    p(h(2), h(3))
    p(h(2), h(3)) = exp   h(2)>w(3)h(3) + b(2)>h(2) + b(3)>h(3)    /z
    p(xi = 1|h(1)) = sigm(b(0) + w(1)>h(1))
    idea: improve prior on last layer by
    p(h(1)|h(2)) =qj p(h(1)
|h(2))
j = 1|h(2)) = sigm(b(1) + w(2)>h(2))
adding another hidden layer
    p(h(1)
    p(x|h(1)) =qi p(xi|h(1))
    how do we train these additional layers?
    p(x, h(1), h(2), h(3)) = p(h(2), h(3)) p(h(1)|h(2)) p(x|h(1))
    p(x) =ph(1) p(x, h(1))
    p(h(2), h(3)) = exp   h(2)>w(3)h(3) + b(2)>h(2) + b(3)>h(3)    /z
    p(x, h(1)) = p(x|h(1))ph(2) p(h(1), h(2))
    p(h(1)|h(2)) =qj p(h(1)
    p(h(1), h(2)) = p(h(1)|h(2))ph(3) p(h(2), h(3))
    x h(1) h(2) h(3)
...
    p(x|h(1)) =qi p(xi|h(1))
    p(x) =ph(1) p(x, h(1))
    p(x, h(1)) = p(x|h(1))ph(2) p(h(1), h(2))
    x h(1) h(2) h(3)
    p(h(1), h(2)) = p(h(1)|h(2))ph(3) p(h(2), h(3))
    x h(1) h(2) h(3)

hugo.larochelle@usherbrooke.ca

    x h(1) h(2) h(3)

    x h(1) h(2) h(3)

29

math for my slides    deep learning   .

math for my slides    deep learning   .

    x h(1) h(2) h(3)
abstract
...

    x h(1) h(2) h(3)

    x h(1) h(2) h(3)

math for my slides    deep learning   .

math for my slides    deep learning   .

math for my slides    deep learning   .

abstract

|h(2))

...

...

...

...

...

...

...

j

j

math for my slides    deep learning   .

math for my slides    deep learning   .

hugo.larochelle@usherbrooke.ca

d  epartement d   informatique
universit  e de sherbrooke

hugo.larochelle@usherbrooke.ca

deep learning

j

abstract

|h(2))

math for my slides    deep learning   .

hugo larochelle

hugo larochelle

j = 1|h(2)) = sigm(b(1) + w(2)>h(2))

deep learning

d  epartement d   informatique
universit  e de sherbrooke

deep belief network

    p(h(1)
october 25, 2012
    p(x, h(1), h(2), h(3)) = p(h(2), h(3)) p(h(1)|h(2)) p(x|h(1))
    p(h(2), h(3)) = exp   h(2)>w(3)h(3) + b(2)>h(2) + b(3)>h(3)    /z
deep learning
    p(h(1)|h(2)) =qj p(h(1)
    p(x|h(1)) =qi p(xi|h(1))
    p(x) =ph(1) p(x, h(1))
hugo larochelle
    p(x, h(1)) = p(x|h(1))ph(2) p(h(1), h(2))
d  epartement d   informatique
math for my slides    deep learning   .
    p(h(1), h(2)) = p(h(1)|h(2))ph(3) p(h(2), h(3))
universit  e de sherbrooke
    x h(1) h(2) h(3)
october 25, 2012
hugo.larochelle@usherbrooke.ca
math for my slides    deep learning   .
october 25, 2012

    x h(1) h(2) h(3)
    p(h(2), h(3))
    p(xi = 1|h(1)) = sigm(b(0) + w(1)>h(1))
topics: deep belief network
j = 1|h(2)) = sigm(b(1) + w(2)>h(2))
    p(h(1)
    x h(1) h(2) h(3)
    p(x, h(1), h(2), h(3)) = p(h(2), h(3)) p(h(1)|h(2)) p(x|h(1))
    this is where the rbm stacking procedure comes from
    p(h(2), h(3))
    p(h(2), h(3)) = exp   h(2)>w(3)h(3) + b(2)>h(2) + b(3)>h(3)    /z
    p(xi = 1|h(1)) = sigm(b(0) + w(1)>h(1))
    idea: improve prior on last layer by
    p(h(1)|h(2)) =qj p(h(1)
|h(2))
j = 1|h(2)) = sigm(b(1) + w(2)>h(2))
adding another hidden layer
    p(h(1)
    p(x|h(1)) =qi p(xi|h(1))
    how do we train these additional layers?
    p(x, h(1), h(2), h(3)) = p(h(2), h(3)) p(h(1)|h(2)) p(x|h(1))
    p(x) =ph(1) p(x, h(1))
    p(h(2), h(3)) = exp   h(2)>w(3)h(3) + b(2)>h(2) + b(3)>h(3)    /z
    p(x, h(1)) = p(x|h(1))ph(2) p(h(1), h(2))
    p(h(1)|h(2)) =qj p(h(1)
    p(h(1), h(2)) = p(h(1)|h(2))ph(3) p(h(2), h(3))
    x h(1) h(2) h(3)
...
    p(x|h(1)) =qi p(xi|h(1))
    p(x) =ph(1) p(x, h(1))
    p(x, h(1)) = p(x|h(1))ph(2) p(h(1), h(2))
    x h(1) h(2) h(3)
    p(h(1), h(2)) = p(h(1)|h(2))ph(3) p(h(2), h(3))
    x h(1) h(2) h(3)

hugo.larochelle@usherbrooke.ca

    x h(1) h(2) h(3)

    x h(1) h(2) h(3)

29

math for my slides    deep learning   .

math for my slides    deep learning   .

    x h(1) h(2) h(3)
abstract
...

    x h(1) h(2) h(3)

    x h(1) h(2) h(3)

math for my slides    deep learning   .

math for my slides    deep learning   .

math for my slides    deep learning   .

abstract

|h(2))

...

...

...

...

...

...

...

j

j

math for my slides    deep learning   .

math for my slides    deep learning   .

hugo.larochelle@usherbrooke.ca

d  epartement d   informatique
universit  e de sherbrooke

hugo.larochelle@usherbrooke.ca

deep learning

j

abstract

|h(2))

math for my slides    deep learning   .

hugo larochelle

hugo larochelle

j = 1|h(2)) = sigm(b(1) + w(2)>h(2))

deep learning

d  epartement d   informatique
universit  e de sherbrooke

deep belief network

    p(h(1)
october 25, 2012
    p(x, h(1), h(2), h(3)) = p(h(2), h(3)) p(h(1)|h(2)) p(x|h(1))
    p(h(2), h(3)) = exp   h(2)>w(3)h(3) + b(2)>h(2) + b(3)>h(3)    /z
deep learning
    p(h(1)|h(2)) =qj p(h(1)
    p(x|h(1)) =qi p(xi|h(1))
    p(x) =ph(1) p(x, h(1))
hugo larochelle
    p(x, h(1)) = p(x|h(1))ph(2) p(h(1), h(2))
d  epartement d   informatique
math for my slides    deep learning   .
    p(h(1), h(2)) = p(h(1)|h(2))ph(3) p(h(2), h(3))
universit  e de sherbrooke
    x h(1) h(2) h(3)
october 25, 2012
hugo.larochelle@usherbrooke.ca
math for my slides    deep learning   .
october 25, 2012

    x h(1) h(2) h(3)
    p(h(2), h(3))
    p(xi = 1|h(1)) = sigm(b(0) + w(1)>h(1))
topics: deep belief network
j = 1|h(2)) = sigm(b(1) + w(2)>h(2))
    p(h(1)
    x h(1) h(2) h(3)
    p(x, h(1), h(2), h(3)) = p(h(2), h(3)) p(h(1)|h(2)) p(x|h(1))
    this is where the rbm stacking procedure comes from
    p(h(2), h(3))
    p(h(2), h(3)) = exp   h(2)>w(3)h(3) + b(2)>h(2) + b(3)>h(3)    /z
    p(xi = 1|h(1)) = sigm(b(0) + w(1)>h(1))
    idea: improve prior on last layer by
    p(h(1)|h(2)) =qj p(h(1)
|h(2))
j = 1|h(2)) = sigm(b(1) + w(2)>h(2))
adding another hidden layer
    p(h(1)
    p(x|h(1)) =qi p(xi|h(1))
    how do we train these additional layers?
    p(x, h(1), h(2), h(3)) = p(h(2), h(3)) p(h(1)|h(2)) p(x|h(1))
    p(x) =ph(1) p(x, h(1))
    p(h(2), h(3)) = exp   h(2)>w(3)h(3) + b(2)>h(2) + b(3)>h(3)    /z
    p(x, h(1)) = p(x|h(1))ph(2) p(h(1), h(2))
    p(h(1)|h(2)) =qj p(h(1)
    p(h(1), h(2)) = p(h(1)|h(2))ph(3) p(h(2), h(3))
    x h(1) h(2) h(3)
...
    p(x|h(1)) =qi p(xi|h(1))
    p(x) =ph(1) p(x, h(1))
    p(x, h(1)) = p(x|h(1))ph(2) p(h(1), h(2))
    x h(1) h(2) h(3)
    p(h(1), h(2)) = p(h(1)|h(2))ph(3) p(h(2), h(3))
    x h(1) h(2) h(3)

hugo.larochelle@usherbrooke.ca

    x h(1) h(2) h(3)

    x h(1) h(2) h(3)

29

math for my slides    deep learning   .

math for my slides    deep learning   .

    x h(1) h(2) h(3)
abstract
...

    x h(1) h(2) h(3)

    x h(1) h(2) h(3)

math for my slides    deep learning   .

math for my slides    deep learning   .

math for my slides    deep learning   .

abstract

|h(2))

...

...

...

...

...

...

...

j

j

math for my slides    deep learning   .

math for my slides    deep learning   .

hugo.larochelle@usherbrooke.ca

j

j

abstract

abstract

|h(2))

october 25, 2012

october 25, 2012

math for my slides    deep learning   .

math for my slides    deep learning   .

j
math for my slides    deep learning   .

    p(x, h(1), h(2), h(3)) = p(h(2), h(3)) p(h(1)|h(2)) p(x|h(1))

    p(x, h(1), h(2), h(3)) = p(h(2), h(3)) p(h(1)|h(2)) p(x|h(1))

    p(h(1)|h(2)) =qj p(h(1)
    p(x|h(1)) =qi p(xi|h(1))
    p(h(2), h(3)) = exp   h(2)>w(3)h(3) + b(2)>h(2) + b(3)>h(3)    /z
    p(h(2), h(3)) = exp   h(2)>w(3)h(3) + b(2)>h(2) + b(3)>h(3)    /z
j = 1|h(2)) = sigm(b(1) + w(2)>h(2))
    p(h(1)
    x h(1) h(2) h(3)
deep belief network
    p(x) =ph(1) p(x, h(1))
    p(h(1)|h(2)) =qj p(h(1)
    p(x, h(1), h(2), h(3)) = p(h(2), h(3)) p(h(1)|h(2)) p(x|h(1))
    p(h(1)|h(2)) =qj p(h(1)
    p(h(2), h(3))
|h(2))
    p(h(2), h(3)) = exp   h(2)>w(3)h(3) + b(2)>h(2) + b(3)>h(3)    /z
    p(x|h(1)) =qi p(xi|h(1))
    p(x|h(1)) =qi p(xi|h(1))
    p(xi = 1|h(1)) = sigm(b(0) + w(1)>h(1))
    p(x, h(1)) = p(x|h(1))ph(2) p(h(1), h(2))
topics: convexity
    x h(1) h(2) h(3)
    p(x) =ph(1) p(x, h(1))
    p(h(1)|h(2)) =qj p(h(1)
    p(x) =ph(1) p(x, h(1))
    x h(1) h(2) h(3)
|h(2))
j = 1|h(2)) = sigm(b(1) + w(2)>h(2))
    p(h(1)
    p(h(2), h(3))
    p(h(1), h(2)) = p(h(1)|h(2))ph(3) p(h(2), h(3))
    p(x, h(1)) = p(x|h(1))ph(2) p(h(1), h(2))
    we will use the fact that the logarithm function is concave:
    p(x, h(1)) = p(x|h(1))ph(2) p(h(1), h(2))
    p(h(2), h(3))
    p(x|h(1)) =qi p(xi|h(1))
    p(x, h(1), h(2), h(3)) = p(h(2), h(3)) p(h(1)|h(2)) p(x|h(1))
    p(xi = 1|h(1)) = sigm(b(0) + w(1)>h(1))
    p(h(1), h(2)) = p(h(1)|h(2))ph(3) p(h(2), h(3))
    p(xi = 1|h(1)) = sigm(b(0) + w(1)>h(1))
    p(h(1), h(2)) = p(h(1)|h(2))ph(3) p(h(2), h(3))
    p(x) =ph(1) p(x, h(1))
    p(h(2), h(3)) = exp   h(2)>w(3)h(3) + b(2)>h(2) + b(3)>h(3)    /z
    log(pi !i ai)  pi !i log(ai) pi !i = 1 !i   0
j = 1|h(2)) = sigm(b(1) + w(2)>h(2))
                                                        (where                and           )
    p(h(1)
    log(pi !i ai)  pi !i log(ai) pi !i = 1 !i   0
    log(pi !i ai)  pi !i log(ai) pi !i = 1 !i   0
    p(x, h(1)) = p(x|h(1))ph(2) p(h(1), h(2))
j = 1|h(2)) = sigm(b(1) + w(2)>h(2))
    p(h(1)
    p(h(1)|h(2)) =qj p(h(1)
    p(h(1), h(2)) = p(h(1)|h(2))ph(3) p(h(2), h(3))
    p(x, h(1), h(2), h(3)) = p(h(2), h(3)) p(h(1)|h(2)) p(x|h(1))
    p(x, h(1), h(2), h(3)) = p(h(2), h(3)) p(h(1)|h(2)) p(x|h(1))
    ai     p(x|h(1))p(h(1))
    ai     p(x|h(1))p(h(1))
!i     q(h(1)|x)
    p(h(2), h(3)) = exp   h(2)>w(3)h(3) + b(2)>h(2) + b(3)>h(3)    /z
    p(x|h(1)) =qi p(xi|h(1))
q(h(1)|x)
    ai     p(x|h(1))p(h(1))
    p(h(2), h(3)) = exp   h(2)>w(3)h(3) + b(2)>h(2) + b(3)>h(3)    /z
q(h(1)|x)
    log(pi !i ai)  pi !i log(ai) pi !i = 1 !i   0
!i     q(h(1)|x)
   
   
    p(x) =ph(1) p(x, h(1))
q(h(1)|x)
    p(h(1)|h(2)) =qj p(h(1)
log p(x) = logxh(1)
log p(x) = logxh(1)
    p(h(1)|h(2)) =qj p(h(1)
    a1 a2 !1 !2
log(!1 a1 + !2 a2) !1 log(a1) + !2 log(a2)
q(h(1)|x)
q(h(1)|x)
    p(x, h(1)) = p(x|h(1))ph(2) p(h(1), h(2))
   
    p(x|h(1)) =qi p(xi|h(1))
    ai !i
    p(x|h(1)) =qi p(xi|h(1))
    p(h(1), h(2)) = p(h(1)|h(2))ph(3) p(h(2), h(3))
q(h(1)|x) log    p(x|h(1))p(h(1))
q(h(1)|x) log    p(x|h(1))p(h(1))
log p(x) = logxh(1)
  xh(1)
  xh(1)
    p(x) =ph(1) p(x, h(1))
    p(x) =ph(1) p(x, h(1))
    log(pi !i ai)  pi !i log(ai) pi !i = 1 !i   0
q(h(1)|x)
    p(x, h(1)) = p(x|h(1))ph(2) p(h(1), h(2))
    p(x, h(1)) = p(x|h(1))ph(2) p(h(1), h(2))
q(h(1)|x)   log p(x|h(1)) + log p(h(1))   
= xh(1)
q(h(1)|x)   log p(x|h(1)) + log p(h(1))   
= xh(1)
    p(h(1), h(2)) = p(h(1)|h(2))ph(3) p(h(2), h(3))
    p(h(1), h(2)) = p(h(1)|h(2))ph(3) p(h(2), h(3))
q(h(1)|x) log    p(x|h(1))p(h(1))
  xh(1)
 xh(1)
    log(pi !i ai)  pi !i log(ai) pi !i = 1 !i   0
    log(pi !i ai)  pi !i log(ai) pi !i = 1 !i   0
 xh(1)
q(h(1)|x) log q(h(1)|x)
q(h(1)|x) log q(h(1)|x)
30

    a1 a2 !1 !2
    ai !i

log(!1 a1 + !2 a2) !1 log(a1) + !2 log(a2)

log(!1 a1 + !2 a2) !1 log(a1) + !2 log(a2)

log(!1 a1 + !2 a2) !1 log(a1) + !2 log(a2)

!i     q(h(1)|x)

    a1 a2 !1 !2

    a1 a2 !1 !2

|h(2))

|h(2))

|h(2))

j

j

j

deep belief network

   

q(h(1)|x)

p(x|h(1))p(h(1))

log p(x) = logxh(1)
topics: variational bound
log p(x) = logxh(1)
q(h(1)|x)
    for any model with latent variables         we can write:
    h(1)
q(h(1)|x) p(h(1)|x)
q(h(1)|x)
  xh(1)
q(h(1)|x) log    p(x|h(1))p(h(1))
!
  xh(1)
p(x|h(1))p(h(1))
= xh(1)
q(h(1)|x)   log p(x|h(1)) + log p(h(1))   
= xh(1)
   
 xh(1)
 xh(1)
q(h(1)|x) log q(h(1)|x)

log p(x) = log xh(1)
q(h(1)|x) log    p(x|h(1))p(h(1))
  xh(1)
q(h(1)|x)   log p(x|h(1)) + log p(h(1))   
= xh(1)
 xh(1)
q(h(1)|x) log q(h(1)|x)
    h(1)
q(h(1)|x) p(h(1)|x)

                   is any approximation of 

q(h(1)|x) p(h(1)|x)

q(h(1)|x)

q(h(1)|x)

q(h(1)|x)

31

    h(1)

j

j

   

}

}

j
,
  

=
x

x
w

w
9

p

    a1 a2 !1 !2
    ai !i

deep belief network

j
=
i
1
=
j
log(!1 a1 + !2 a2) !1 log(a1) + !2 log(a2)
u
>i

    p(x) =ph(1) p(x, h(1))
    p(x, h(1)) = p(x|h(1))ph(2) p(h(1), h(2))
    p(h(1), h(2)) = p(h(1)|h(2))ph(3) p(h(2), h(3))
    log(pi !i ai)  pi !i log(ai) pi !i = 1 !i   0
log p(x) = logxh(1)
topics: variational bound
log p(x) = logxh(1)
p(x|h(1))p(h(1))
q(h(1)|x)
    for any model with latent variables         we can write:
q(h(1)|x) p(h(1)|x)
    h(1)
q(h(1)|x)
  xh(1)
q(h(1)|x) log    p(x|h(1))p(h(1))
!
  xh(1)
p(x|h(1))p(h(1))
= xh(1)
q(h(1)|x)   log p(x|h(1)) + log p(h(1))   
= xh(1)
   
 xh(1)
 xh(1)
q(h(1)|x) log q(h(1)|x)

log p(x) = log xh(1)
q(h(1)|x) log    p(x|h(1))p(h(1))
  xh(1)
q(h(1)|x)   log p(x|h(1)) + log p(h(1))   
= xh(1)
 xh(1)
q(h(1)|x) log q(h(1)|x)
    h(1)
q(h(1)|x) p(h(1)|x)

}
q(h(1)|x)
)
x
r
/2
x

                   is any approximation of 

q(h(1)|x) p(h(1)|x)

2
x
{
=

   

31

p

x
r

2
x
{

q(h(1)|x)

=
x

 
{

 
=

q(h(1)|x)

q(h(1)|x)

h
r

h
r

u
x

t
e

   

   

   

>i

u

u

u

u

u

 

|

|

|

(

)

(

,

i

i

i

i

i

i

i

i

x
w

t

t

   
=

t

=

x

   
t
,

w
9

   

    h(1)

p

q

6
p

t

p

h
r

p

j

j

   

j

j

  

j
,

}

}

|

j
,
  

}

}

1
=

p

x
x
w
w

    a1 a2 !1 !2
    ai !i

deep belief network

    p(x) =ph(1) p(x, h(1))
    p(x) =ph(1) p(x, h(1))
    p(x, h(1)) = p(x|h(1))ph(2) p(h(1), h(2))
    p(x, h(1)) = p(x|h(1))ph(2) p(h(1), h(2))
    p(h(1), h(2)) = p(h(1)|h(2))ph(3) p(h(2), h(3))
    p(h(1), h(2)) = p(h(1)|h(2))ph(3) p(h(2), h(3))
j
    log(pi !i ai)  pi !i log(ai) pi !i = 1 !i   0
=
    log(pi !i ai)  pi !i log(ai) pi !i = 1 !i   0
i
log p(x) = logxh(1)
topics: variational bound
1
log p(x) = logxh(1)
=
p(x|h(1))p(h(1))
    a1 a2 !1 !2
log(!1 a1 + !2 a2) !1 log(a1) + !2 log(a2)
u
q(h(1)|x)
=
    for any model with latent variables         we can write:
j
    h(1)
q(h(1)|x) p(h(1)|x)
log(!1 a1 + !2 a2) !1 log(a1) + !2 log(a2)
u
q(h(1)|x)
=
x
u
>i
    ai !i
  xh(1)
x
q(h(1)|x) log    p(x|h(1))p(h(1))
w
!
  xh(1)
}
t
9
w
)
e
p(x|h(1))p(h(1))
x
9
u
(
r
= xh(1)
 
q(h(1)|x)   log p(x|h(1)) + log p(h(1))   
= xh(1)
   
/2
=
x
u
 xh(1)
x
 xh(1)
q(h(1)|x) log q(h(1)|x)

log p(x) = log xh(1)
q(h(1)|x) log    p(x|h(1))p(h(1))
  xh(1)
q(h(1)|x)   log p(x|h(1)) + log p(h(1))   
= xh(1)
 xh(1)
q(h(1)|x) log q(h(1)|x)
    h(1)
q(h(1)|x) p(h(1)|x)

2
2
x
{
x
=
{
=
x
x
r
r

2
u
x
{
 
{

}
q(h(1)|x)
)
x
r
/2
x

                   is any approximation of 

q(h(1)|x) p(h(1)|x)

   

31

p

2
x
{

 
{

 
=

h
r

u
x

q(h(1)|x)

=
x

t
e

   

   

   

q(h(1)|x)

q(h(1)|x)

h
r

h
r

>i

)
(

u

u

|

|

   

   

   

>i

)

u

u

u

 

,

|

|

|

(

(

,

i

i

i

i

i

i

i

i

q

x
w

t

t

   
=

=

x

   
t
,

w
9

   

    h(1)

6
6
q(h(1)|x) p(h(1)|x)

   

   

   

   

   

   

q(h(1)|x)

q(h(1)|x)

q(h(1)|x) log q(h(1)|x)

q(h(1)|x) log    p(x|h(1))p(h(1))
  xh(1)
 xh(1)
q(h(1)|x)   log p(x|h(1)) + log p(h(1))   
= xh(1)
deep belief network
 xh(1)
q(h(1)|x) log q(h(1)|x)
!
log p(x) = log xh(1)
log p(x) = log xh(1)
topics: variational bound
p(x|h(1))p(h(1))
p(x|h(1))p(h(1))
q(h(1)|x)
log p(x) = log xh(1)
log p(x) = log xh(1)
!
p(x|h(1))p(h(1))
p(x|h(1))p(h(1))
    this is called a variational bound
q(h(1)|x)
q(h(1)|x)
q(h(1)|x) log    p(x|h(1))p(h(1))
   
q(h(1)|x) log    p(x|h(1))p(h(1))
  xh(1)
  xh(1)
log p(x) = log xh(1)
log p(x) = log xh(1)
!
!
q(h(1)|x)   log p(x|h(1)) + log p(h(1))   
q(h(1)|x) log    p(x|h(1))p(h(1))
q(h(1)|x) log    p(x|h(1))p(h(1))
   
q(h(1)|x)
log p(x)   xh(1)
  xh(1)
  xh(1)
p(x|h(1))p(h(1))
q(h(1)|x)
q(h(1)|x)
q(h(1)|x) p(h(1)|x)
q(h(1)|x)   log p(x|h(1)) + log p(h(1))   
q(h(1)|x)   log p(x|h(1)) + log p(h(1))   
= xh(1)
= xh(1)
q(h(1)|x)
q(h(1)|x)   log p(x|h(1)) + log p(h(1))   
q(h(1)|x)   log p(x|h(1)) + log p(h(1))   
   
q(h(1)|x) log    p(x|h(1))p(h(1))
q(h(1)|x) log    p(x|h(1))p(h(1))
   
= xh(1)
= xh(1)
  xh(1)
  xh(1)
 xh(1)
 xh(1)
 xh(1)
q(h(1)|x) log q(h(1)|x)
q(h(1)|x) log q(h(1)|x)
q(h(1)|x) log q(h(1)|x)
q(h(1)|x)
q(h(1)|x)   log p(x|h(1)) + log p(h(1))   
log p(x)   xh(1)
 xh(1)
 xh(1)
q(h(1)|x)   log p(x|h(1)) + log p(h(1))   
q(h(1)|x)   log p(x|h(1)) + log p(h(1))   
= xh(1)
= xh(1)
q(h(1)|x) log q(h(1)|x)
q(h(1)|x) log q(h(1)|x)
 xh(1)
 xh(1)
 xh(1)
    if               is equal to the true conditional              , then we have an equality
q(h(1)|x) log q(h(1)|x)
q(h(1)|x) log q(h(1)|x)
q(h(1)|x) log q(h(1)|x)
    the more              is different from               the less tight the bound is
q(h(1)|x)   log p(x|h(1)) + log p(h(1))   
q(h(1)|x)   log p(x|h(1)) + log p(h(1))   
log p(x)   xh(1)
log p(x)   xh(1)
    in fact, the difference between the left and right terms is the kl divergence 
q(h(1)|x)   log p(x|h(1)) + log p(h(1))   
q(h(1)|x)   log p(x|h(1)) + log p(h(1))   
log p(x)   xh(1)
log p(x)   xh(1)
 xh(1)
 xh(1)
    kl(q||p) =ph(1) q(h(1)|x) log    q(h(1)|x)
p(h(1)|x)   
q(h(1)|x) log q(h(1)|x)
q(h(1)|x) log q(h(1)|x)
 xh(1)
 xh(1)
q(h(1)|x)   log p(x|h(1)) + log p(h(1))   
q(h(1)|x)   log p(x|h(1)) + log p(h(1))   
log p(x)   xh(1)
log p(x)   xh(1)
q(h(1)|x) log q(h(1)|x)
q(h(1)|x) log q(h(1)|x)

q(h(1)|x) p(h(1)|x)
    h(1)
    h(1)
   
   
between               and               :
    h(1)
    h(1)
q(h(1)|x) p(h(1)|x)
   
   

    h(1)
q(h(1)|x) p(h(1)|x)
q(h(1)|x) p(h(1)|x)
   

q(h(1)|x)
p(x|h(1))p(h(1))
q(h(1)|x)
q(h(1)|x)

    h(1)
   

q(h(1)|x) p(h(1)|x)

q(h(1)|x) p(h(1)|x)

q(h(1)|x)

q(h(1)|x)

q(h(1)|x)

32

    h(1)
   

q(h(1)|x) p(h(1)|x)

    h(1)

q(h(1)|x)

q(h(1)|x)

q(h(1)|x)

q(h(1)|x)

q(h(1)|x) p(h(1)|x)

q(h(1)|x) p(h(1)|x)

    h(1)
    h(1)
   
   

q(h(1)|x) log    p(x|h(1))p(h(1))
log p(x) = log xh(1)
!
log p(x) = log xh(1)
  xh(1)
 xh(1)
q(h(1)|x) log    p(x|h(1))p(h(1))
q(h(1)|x) log    p(x|h(1))p(h(1))
q(h(1)|x) log q(h(1)|x)
  xh(1)
  xh(1)
q(h(1)|x)   log p(x|h(1)) + log p(h(1))   
= xh(1)
q(h(1)|x) log    p(x|h(1))p(h(1))
   
q(h(1)|x) log    p(x|h(1))p(h(1))
deep belief network
  xh(1)
  xh(1)
q(h(1)|x)   log p(x|h(1)) + log p(h(1))   
q(h(1)|x)   log p(x|h(1)) + log p(h(1))   
= xh(1)
= xh(1)
 xh(1)
q(h(1)|x)   log p(x|h(1)) + log p(h(1))   
q(h(1)|x) log q(h(1)|x)
q(h(1)|x)   log p(x|h(1)) + log p(h(1))   
= xh(1)
= xh(1)
 xh(1)
 xh(1)
topics: variational bound
q(h(1)|x) log q(h(1)|x)
q(h(1)|x) log q(h(1)|x)
 xh(1)
 xh(1)
q(h(1)|x) log q(h(1)|x)
q(h(1)|x) log q(h(1)|x)
    this is called a variational bound
    h(1)
q(h(1)|x) p(h(1)|x)
log p(x)   xh(1)
log p(x)   xh(1)
q(h(1)|x)   log p(x|h(1)) + log p(h(1))   
log p(x)   xh(1)
q(h(1)|x) p(h(1)|x)
    h(1)
    h(1)
   
q(h(1)|x)   log p(x|h(1)) + log p(h(1))   
log p(x)   xh(1)
q(h(1)|x) p(h(1)|x)
    h(1)
   
   
q(h(1)|x)   log p(x|h(1)) + log p(h(1))   
q(h(1)|x)   log p(x|h(1)) + log p(h(1))   
log p(x)   xh(1)
log p(x)   xh(1)
 xh(1)
   
 xh(1)
q(h(1)|x) log q(h(1)|x)
q(h(1)|x)   log p(x|h(1)) + log p(h(1))   
q(h(1)|x) log q(h(1)|x)
q(h(1)|x)   log p(x|h(1)) + log p(h(1))   
log p(x)   xh(1)
log p(x)   xh(1)
    kl(q||p) =ph(1) q(h(1)|x) log    q(h(1)|x)
    kl(q||p) =ph(1) q(h(1)|x) log    q(h(1)|x)
p(h(1)|x)   
p(h(1)|x)   
 xh(1)
 xh(1)
q(h(1)|x) log q(h(1)|x)
q(h(1)|x) log q(h(1)|x)
 xh(1)
 xh(1)
q(h(1)|x) log q(h(1)|x)
q(h(1)|x) log q(h(1)|x)
    p(x|h(1)) p(h(1)) h(1) h(2) p(h(1)) =ph(2) p(h(1), h(2))
    p(x|h(1)) p(h(1)) h(1) h(2) p(h(1)) =ph(2) p(h(1), h(2))
p(h(1)|x)   
    kl(q||p) =ph(1) q(h(1)|x) log    q(h(1)|x)
    kl(q||p) =ph(1) q(h(1)|x) log    q(h(1)|x)
p(h(1)|x)   
    kl(q||p) =ph(1) q(h(1)|x) log    q(h(1)|x)
p(h(1)|x)   
    p(x|h(1)) p(h(1)) h(1) h(2) p(h(1)) =ph(2) p(h(1), h(2))
    kl(q||p) =ph(1) q(h(1)|x) log    q(h(1)|x)
p(h(1)|x)   
    kl(q||p) =ph(1) q(h(1)|x) log    q(h(1)|x)
p(h(1)|x)   
    p(x|h(1)) p(h(1)) h(1) h(2) p(h(1)) =ph(2) p(h(1), h(2))
    p(x|h(1)) p(h(1)) h(1) h(2) p(h(1)) =ph(2) p(h(1), h(2))
    p(x|h(1)) p(h(1)) h(1) h(2) p(h(1)) =ph(2) p(h(1), h(2))
    p(x|h(1)) p(h(1)) h(1) h(2) p(h(1)) =ph(2) p(h(1), h(2))

they are the parameters of the rbm involving         and        
             is now the marginalization of the second hidden layer

    for a single hidden layer dbn (i.e. an rbm), both               and           depend on 

    when adding a second layer, we model            using a separate set of parameters

the parameters of the    rst layer

q(h(1)|x) p(h(1)|x)

q(h(1)|x) p(h(1)|x)

33

-

-

q(h(1)|x) p(h(1)|x)

q(h(1)|x) p(h(1)|x)

 xh(1)
q(h(1)|x) log q(h(1)|x)
deep belief network
q(h(1)|x)   log p(x|h(1)) + log p(h(1))   
log p(x)   xh(1)
 xh(1)
q(h(1)|x) log q(h(1)|x)
q(h(1)|x)   log p(x|h(1)) + log p(h(1))   
log p(x)   xh(1)
    kl(q||p) =ph(1) q(h(1)|x) log    q(h(1)|x)
p(h(1)|x)   
 xh(1)
q(h(1)|x) log q(h(1)|x)
    p(x|h(1)) p(h(1)) h(1) h(2) p(h(1)) =ph(2) p(h(1), h(2))

topics: variational bound
    this is called a variational bound
   

    we can train the parameters of the new second layer by maximizing the bound

adding 2nd layer means 
untying the parameters in

this is equivalent to minimizing the following, since the other terms are constant:

-

 xh(1)

q(h(1)|x) log p(h(1))

    h(1)
   

-

this is like training an rbm on data generated from                 ! 

q(h(1)|x) p(h(1)|x)

34

log p(x) = log xh(1)
q(h(1)|x) log    p(x|h(1))p(h(1))
  xh(1)
q(h(1)|x)   log p(x|h(1)) + log p(h(1))   
= xh(1)
 xh(1)

   

topics: variational bound
    this process of adding layers can be repeated recursively

deep belief network
log p(x) = log xh(1)
q(h(1)|x) log    p(x|h(1))p(h(1))
  xh(1)
q(h(1)|x)   log p(x|h(1)) + log p(h(1))   
= xh(1)
 xh(1)
q(h(1)|x) log q(h(1)|x)

    we obtain the greedy layer-wise pre-training procedure for feed-forward neural 

    we now see that this procedure corresponds to maximizing a 
bound on the likelihood of the data in a dbn
    in theory, if our approximation              is very far from the true posterior, the 

p(x|h(1))p(h(1))

q(h(1)|x)

q(h(1)|x)

networks

q(h(1)|x) p(h(1)|x)

    h(1)
bound might be very loose 
   

    this only means we might not be improving the true likelihood
    we might still be extracting better features!

q(h(1)|x)   log p(x|h(1)) + log p(h(1))   
log p(x)   xh(1)
 xh(1)
q(h(1)|x) log q(h(1)|x)

35

conclusion

    we described an improved procedure for training deep neural 
networks
    a pre-training phase is used to initialize the parameters
    pre-training was invented in the context of id50
    it has now been generalized to feed-forward networks and to other       greedy 

modules       than rbms

    other interesting deep models:

    deep id82s (dbms): a id82 with multiple layers

- deep id82s.  salakhutdinov and geoffrey hinton, 2009.

    deep energy models: a mix between a feed-forward network and a dbm

- learning deep energy models. ngiam, chen, koh and ng, 2011.

36

