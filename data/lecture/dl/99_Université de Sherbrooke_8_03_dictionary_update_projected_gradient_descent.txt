neural networks
sparse coding - dictionary update with projected id119

2

sparse coding
hugo larochelle
hugo larochelle

hugo.larochelle@usherbrooke.ca

sparse coding

november 1, 2012

hugo larochelle

sparse coding

math for my slides    sparse coding   .

november 1, 2012
abstract

topics: sparse coding
    for each          nd a latent representation       such that:
    x(t) h(t) d

sparse coding
d  epartement d   informatique
universit  e de sherbrooke
d  epartement d   informatique
hugo.larochelle@usherbrooke.ca
math for my slides    sparse coding   .
universit  e de sherbrooke
d  epartement d   informatique
sparse coding
d  epartement d   informatique
hugo.larochelle@usherbrooke.ca
abstract
math for my slides    sparse coding   .
november 1, 2012
universit  e de sherbrooke
d  epartement d   informatique
    x(t) h(t) d
universit  e de sherbrooke
hugo larochelle
txt=1
november 1, 2012
hugo.larochelle@usherbrooke.ca
    it is sparse: the vector        has many zeros
universit  e de sherbrooke
1
1
hugo.larochelle@usherbrooke.ca
2 +  ||h(t)||1
2||x(t)   d h(t)||2
d  epartement d   informatique
arg min
arg min
arg min
arg min
abstract
hugo.larochelle@usherbrooke.ca
t
    we can reconstruct the original input        as much as possible
universit  e de sherbrooke
1
1
d
h(t)
h(t)
    x(t) h(t) d
november 1, 2012
2 +  ||h(t)||1
2||x(t)   d h(t)||2
november 1, 2012
arg min
hugo.larochelle@usherbrooke.ca
txt=1
t
1
   
2||x(t)   d h(t)||2
arg min
november 1, 2012
1
1
h(x(t)) = arg min
2||x(t)   d h(t)||2
2||x(t)   d h(t)||2
2 +  ||h(t)||1
d
abstract
1
2||x(t)   d h(t)||2
h(x(t)) = arg min

sparsity penalty
h(x(t)) = arg min
2 +  ||h(t)||1
abstract

sparse coding
abstract

math for my slides    sparse coding   .

    x(t) h(t) d

abstract
hugo larochelle

abstract
reconstruction error

txt=1

txt=1

arg min

arg min

h(t)
h(t)

 

1
t

1
t

h(t)

1
t

 

d

d

arg min

min
d
1
t

txt=1
 
1
2||x(t)   d h(t)||2
h(t)
min
abstract
math for my slides    sparse coding   .
   
h(t)
 
txt=1
1
math for my slides    sparse coding   .
math for my slides    sparse coding   .
2||x(t)   d h(t)||2
arg min
reconstruction
    x(t) h(t) d bx(t)
d
h(t)
    x(t) h(t) d
1
h(x(t)) = arg min
2||x(t)   d h(t)||2
txt=1
    x(t) h(t) d
arg min
h(t)
txt=1
1
d
2||x(t)   d h(t)||2
h(x(t)) = arg min
arg min
arg min
bx(t) = d h(x(t)) = xk s.t.
   
   
h(t)
- encoder is the minimization
d
h(x(t)) = arg min

reconstruction vs.
2 +  ||h(t)||1
sparsity control
txt=1
math for my slides    sparse coding   .
         is equivalent to the autoencoder output weight matrix
2 +  ||h(t)||1
1
arg min
2 +  ||h(t)||1
2||x(t)   d h(t)||2
    however,             is now a complicated function of      
1
    x(t) h(t) d
2 +  ||h(t)||1
2||x(t)   d h(t)||2
2 +  ||h(t)||1
d  ,k h(x(t))k
1
h(t)
2||x(t)   d h(t)||2
2 +  ||h(t)||1

h(x(t)) = arg min

h(x(t)) = arg min

1
t
1
t

arg min

arg min

h(t)

1
t

h(t)

h(t)

h(t)

d

2 +  ||h(t)||1
1
2||x(t)   d h(t)||2
2 +  ||h(t)||1

h(t)

1
2||x(t)   d h(t)||2

1
1
2||x(t)   d h(t)||2
2 +  ||h(t)||1
t

arg min

txt=1

math for my slides    sparse coding   .

math for my slides    sparse coding   .
    more formally:
   

    x(t) h(t) d bx(t)

   

november 1, 2012

h(t) (= shrink(h(t),       sign(h(t)))

sparse coding

abstract

universit  e de sherbrooke
sparse coding

hugo.larochelle@usherbrooke.ca

3

hugo larochelle

november 1, 2012
d  epartement d   informatique
universit  e de sherbrooke

hugo.larochelle@usherbrooke.ca

abstract

math for my slides    sparse coding   .
    shrink(ai, bi)

topics: dictionary update (algorithm 1)
    going back to our original problem

h(t) (= shrink(h(t),       sign(h(t)))
shrink(a, b) = [. . . , sign(ai) max(|ai|   bi, 0), . . . ]

    x(t) h(t) d bx(t)

h(t)

1
t

1
t

min
d

min
h(t)

1
h(t)
t

txt=1

shrink(a, b) = [. . . , sign(ai) max(|ai|   bi, 0), . . . ]
1
2||x(t)   d h(t)||2
arg min
txt=1
1
1
2||x(t)   d h(x(t))||2
t
math for my slides    sparse coding   .

2 +  ||h(t)||1
2 +  ||h(x(t))||1

arg min
min
d
h(t)

txt=1

    let   s assume          doesn   t depend on     (which is false)
min
d

l(x(t)) = min
d

1
    we must minimize
t

l(x(t)) = min
d

2 +  ||h(t)||1
2 +  ||h(x(t))||1

txt=1
1
txt=1
2||x(t)   d h(t)||2
h(x(t)) = arg min
    x(t) h(t) d
1
2||x(t)   d h(x(t))||2
bx(t) = d h(x(t)) = xk s.t.
txt=1
1
2||x(t)   d h(x(t))||2
2
h(x(t))k6=0
    x(t) h(t) d
l(x(t)) = ||x(t)   d h(t)||2
d
l(x(t)) = (d  ,k)>(d h(t)   x(t)) +   sign(h(t)
k )

math for my slides    sparse coding   .

d  ,k h(x(t))k

    we must also constrain the columns of      to be of unit norm
2 +  ||h(t)||1

arg min

min
d

1
t

   

@

d

arg min

november 1, 2012

1
t

txt=1

1
2||x(t)   d h(t)||2
arg min
abstract
h(t)

1
2||x(t)   d h(t)||2
h(x(t)) = arg min
1
2||x(t)   d h(t)||2

h(t)
arg min

1
t

h(t)

txt=1

sparse coding

1
2

= min
d

txt=1
t    txt=1

= min
= min
d
d

2

1

1

1

1

1

1

1

1
2

(4)

1
t

1
t

(3)

(2)

1
t

1
1
2
t

min
d

d (= d +    

(4)
abstract

universit  e de sherbrooke

hugo.larochelle@usherbrooke.ca
1

hugo.larochelle@usherbrooke.ca
(3)

4
(1)
hugo.larochelle@usherbrooke.ca

d  epartement d   informatique
(2)
universit  e de sherbrooke

(2)
hugo larochelle
(3)
november 1, 2012

2   d h(x(t))   > d h(x(t))
2   d h(x(t))   > d h(x(t))
txt=1
txt=1
x(t)>x(t)   x(t)>d h(x(t)) +
x(t)>x(t)   x(t)>d h(x(t)) +
1
sparse coding
2||x(t)   d h(x(t))||2
november 1, 2012
2  txt=1   d h(x(t))   > d h(x(t)!
t    txt=1
x(t)>d h(x(t))! +
x(t)>d h(x(t))! +
2  txt=1   d h(x(t))   > d h(x(t)!
2   d h(x(t))   > d h(x(t))
txt=1
x(t)>x(t)   x(t)>d h(x(t)) +
topics: dictionary update (algorithm 1)
x(t)>d h(x(t))! +
t    txt=1
2  txt=1   d h(x(t))   > d h(x(t)!
abstract
    a id119 method could be used here too
= min
math for my slides    sparse coding   .
    speci   cally, this is a projected id119 algorithm
d
txt=1
1
math for my slides    sparse coding   .
    while     hasn   t converged
(x(t)   d h(x(t))) h(x(t))>
txt=1
t
(x(t)   d h(x(t))) h(x(t))>
txt=1
    perform gradient update of
    x(t) h(t) d
arg min
arg min
2 =  txt=1
x(t) h(x(t))>!  txt=1
txt=1
1
1
d (= d +    
x(t) h(x(t))>!  txt=1
2 =  txt=1
2||x(t)   d h(x(t))||2
t
    renormalize the columns of 
    x(t) h(t) d
   
2 =  txt=1
-
1
1
2||x(t)   d h(x(t))||2
d  ,j
t
||d  ,j||2
x(t) h(x(t))>!  txt=1

1
2||x(t)   d h(t)||2
txt=1
h(x(t)) h(x(t))>! 1
arg min
h(x(t)) h(x(t))>! 1
1
2 +  ||h(t)||1
2||x(t)   d h(t)||2
x(t) h(x(t))>!  txt=1
h(x(t)) h(x(t))>! 1
1
txt=1
1
2||x(t)   d h(t)||2
h(x(t)) = arg min
2||x(t)   d h(t)||2
arg min
arg min
h(t)
d
h(t)
h(x(t)) h(x(t))>! 1

2 +  ||h(t)||1
abstract
1
2||x(t)   d h(t)||2

1
(x(t)   d h(x(t))) h(x(t))>
t

d  ,j (=
t=1 h(x(t)) h(x(t))> d (= b a 1

d (=  txt=1

1
2||x(t)   d h(t)||2

math for my slides    sparse coding   .
d

november 1, 2012

d  ,j (= d  ,j/||d  ,j||2

h(x(t)) = arg min

h(x(t)) = arg min

for each column          :

arg min

1
t

1
t

(4)

h(t)

h(t)

h(t)

   

d

    x(t) h(t) d
d (= d +    
txt=1

1
t

2||x(t)   d h(x(t))||2

arg min

txt=1
t=1 x(t) h(x(t))> b (=pt

d

2 +  ||h(t)||1

2 +  ||h(t)||1
2 +  ||h(t)||1

2 +  ||h(t)||1

t=1 x(t) h(x(t))> b (=pt

