introduction to nlp
semi-supervised learning on graphs
id93 and id94
drunkard   s walk:
start at position 2 on a line




what is the prob. of reaching 5 before reaching 0? 
id94:
p(0) = 0
p(n) = 1
p(x) =   *p(x-1)+   *p(x+1), for 0<x<n
(in general, replace    with the bias in the walk)
0
1
2
3
4
5
learning id94
the method of relaxations
discrete approximation.
assign fixed values to the boundary points.
assign arbitrary values to all other points.
adjust their values to be the average of their neighbors.
repeat until convergence.
monte carlo method
perform a random walk on the discrete representation.
compute f as the id203 of a random walk ending in a particular fixed point.
eigenvector methods
look at the stationary distribution of a random walk

eigenvectors and eigenvalues
an eigenvector is an implicit    direction    for a matrix 

where v (eigenvector) is non-zero, though    (eigenvalue) can be any complex number in principle
computing eigenvalues:

eigenvectors and eigenvalues
example:


det (a-li) = (-1-l)*(-l)-3*2=0
then: l+l2-6=0;   l1=2;   l2=-3
for l1=2:


solutions: x1=x2
stochastic matrices
stochastic matrices: each row (or column) adds up to 1 and no value is less than 0. example:


the largest eigenvalue of a stochastic matrix e is real:   1 = 1. 
for   1, the left (principal) eigenvector is p, the right eigenvector = 1
in other words, gtp = p.
ergodic (connected) markov chain with transition matrix p








































1   
1   










1   
0.5   
0.5   
a
b
c
d
w=pw
from doyle and snell 2000
electrical networks and id93
electrical networks and id93




1 v
vx is the id203 that a random walk starting at x will reach a before reaching b. 
the random walk interpretation allows us to use monte carlo methods to solve electrical circuits.








































1   
1   










1   
0.5   
0.5   
a
c
d
b
markov chains
a homogeneous markov chain is defined by an initial distribution x and a markov kernel e.
path = sequence (x0, x1,    , xn).
xi = xi-1*e 
the id203 of a path can be computed as a product of probabilities for each step i.
random walk = find xj given x0, e, and j.

stationary solutions
the fundamental ergodic theorem for markov chains [grimmett and stirzaker 1989] says that the markov chain with kernel e has a stationary distribution p under three conditions:
e is stochastic
e is irreducible 
e is aperiodic
to make these conditions true:
all rows of e add up to 1 (and no value is negative)
make sure that e is strongly connected
make sure that e is not bipartite
example: id95 [brin and page 1998]: use    teleportation   
          example



this graph e has a second graph e   
(not drawn) superimposed on it:
e    is the uniform transition graph. 
computing the stationary distribution
function powerstatdist (e):
begin
   p(0) = u;   (or p(0) = [1,0,   0])
   i=1;
   repeat
      p(i) = etp(i-1)
      l = ||p(i)-p(i-1)||1;
      i = i + 1;
   until l <    
   return p(i)
end
solution for the
stationary distribution
convergence rate is o(m)
example
other interesting concepts of id93
hitting time
h  is the expected time in a random walk to reach vertex v starting from vertex u
commute time
the expected time to start from u, reach v, and then return to u
cover time
the expected time to start from u and visit every other vertex at least once
meeting time
the expected time of two id93 to start from u and v and meet at some vertex in between
handwritten digit recognition with pixel-wise similarity
- graph from jerry zhu   s tutorial in icml 07
learning on graphs
search for a lower dimensional manifold
relaxation method
monte carlo method
supervised vs. semi-supervised
example from
zhu et al. 2003
learning on graphs
example:
example from
zhu et al. 2003
semi-supervised classification
 d1 is democratic
 d2 is republican
 what can we say about d3 and d4?
- graph from jerry zhu   s tutorial in icml 07
semi-supervised learning: 
start with limited training data
leverage large scale unlabeled data 
different methods vary on how to use
the unlabeled data
absorbing random walk
absorbing states:
a random walk cannot get out once it reaches that node
absorbing random walk:
random walk with absorbing states

i
s




t
absorption id203 pi(s): 
if the random walk starts from vertex i, how likely it will be eventually absorbed by vertex s?

computing absorption probabilities
i
s




t
for the absorbing state: ps(s) = 1
for other absorbing states: pt(s) = 0
for all other vertices: 
iterative computation
absorption id203 for classification
make the positive nodes and negative nodes as absorbing states;
for each vertex, compute the id203 that it will be absorbed by the positive states
classify this vertex as positive if p > 0.5, and negative otherwise
semi-supervised passage retrieval
graph-based semi-supervised learning.
the idea is to propagate information from labeled nodes to unlabeled nodes using the graph connectivity.
a passage can be either positive (labeled as relevant) or negative (labeled as not relevant), or unlabeled.

otterbacher, erkan and radev 2005
network based approaches
no clear notion of    distance    now, but the    scores    are estimated based on some propagation process. 
score propagation based on random walk
two approaches:
starting from the user, how likely/how long can i reach the object?
starting from the object, how likely/how long can i hit the user? 









natural language processing
spectral id91
case study: spectral id91
ng et al on spectral id91: analysis and algorithm
id116
spectral 
id91
graph partitioning with graph cuts
build document network using similarity
text id91 = cutting edges to get k (e.g., k = 2) disconnected components
but where to cut? (what to optimize?)
what to optimize: minimum cut
mincut - minimize the number (or weight) of edges to cut
objective = s(a, b) = 
s(a, b): (weight) of edges from community a to community b

other graph cut objectives
ratio cut
minimize the weights of cut edges and balance the size of each community
objective: 
normalized cut
minimize the weights of cut edges and balance the degree of each community
objective:  
min-max-cut
minimize the weights of cut edges and balance the edge weights inside each community
objective:    
how to optimize?     spectral id91
find the actual solution of graph cuts using spectral id91.
spectral algorithms
the spectrum of a matrix is the list of all eigenvectors of a matrix.
the eigenvectors in the spectrum are sorted by the absolute value of their corresponding eigenvalues.
in id106, eigenvectors are based on the laplacian of the original matrix.


spectral id91
algorithms that cluster points using eigenvectors of matrices derived from the data
obtain data representation in the low-dimensional space that can be easily clustered
variances on:
what matrix to use? 
which eigenvectors to use? 
how to derive clusters from these eigenvectors?
very hot in machine learning, but math intensive.
good tutorial: http://ranger.uta.edu/~chqding/spectral/ 

laplacian matrix
the laplacian l of a matrix is a symmetric matrix.
l = d     g, where d is the degree matrix corresponding to g.
example:
a
b
c
g
f
e
d
fiedler vector
the fiedler vector is the eigenvector of l(g) with the second smallest eigenvalue.

a
b
c
g
f
e
d
spectral bisection algorithm
compute l2
compute the corresponding v2
for each node n of g
if v2(n) < 0
assign n to cluster c1
else if v2(n) > 0
assign n to cluster c2
else if v2(n) = 0
assign n to cluster c1 or c2 at random
spectral id91: pros and cons
pros:
solid mathematics background
explicit objective function to optimize
yields to very good results in general
effective to handle complex shapes
cons:
usually not efficient
not sure which objective is the right one to use
molistic
naclo problem (2007)
molistic
