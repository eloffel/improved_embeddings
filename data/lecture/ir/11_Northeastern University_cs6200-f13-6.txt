cs6200	
   

informa.on	
   retrieval	
   

david	
   smith	
   

college	
   of	
   computer	
   and	
   informa.on	
   science	
   

northeastern	
   university	
   

previously:	
   indexing	
   process	
   

query	
   process	
   

informa.on	
   needs	
   

       an	
   informa(on	
   need	
   is	
   the	
   underlying	
   cause	
   of	
   

the	
   query	
   that	
   a	
   person	
   submits	
   to	
   a	
   search	
   
engine	
   
      some.mes	
   called	
   query	
   intent	
   

       categorized	
   using	
   variety	
   of	
   dimensions	
   	
   

      e.g.,	
   number	
   of	
   relevant	
   documents	
   being	
   sought	
   
      type	
   of	
   informa.on	
   that	
   is	
   needed	
   
      type	
   of	
   task	
   that	
   led	
   to	
   the	
   requirement	
   for	
   
informa.on	
   

queries	
   and	
   informa.on	
   needs	
   
       a	
   query	
   can	
   represent	
   very	
   di   erent	
   informa.on	
   
needs	
   	
   
       may	
   require	
   di   erent	
   search	
   techniques	
   and	
   ranking	
   

algorithms	
   to	
   produce	
   the	
   best	
   rankings	
   

       a	
   query	
   can	
   be	
   a	
   poor	
   representa.on	
   of	
   the	
   

informa.on	
   need	
   
       user	
   may	
      nd	
   it	
   di   cult	
   to	
   express	
   the	
   informa.on	
   
       user	
   is	
   encouraged	
   to	
   enter	
   short	
   queries	
   both	
   by	
   the	
   

need	
   

search	
   engine	
   interface,	
   and	
   by	
   the	
   fact	
   that	
   long	
   
queries	
   don   t	
   work	
   

interac.on	
   

       interac.on	
   with	
   the	
   system	
   occurs	
   

      during	
   query	
   formula.on	
   and	
   reformula.on	
   
      while	
   browsing	
   the	
   result	
   

       key	
   aspect	
   of	
   e   ec.ve	
   retrieval	
   

      users	
   can   t	
   change	
   ranking	
   algorithm	
   but	
   can	
   
change	
   results	
   through	
   interac.on	
   
      helps	
   re   ne	
   descrip.on	
   of	
   informa.on	
   need	
   

       e.g.,	
   same	
   ini.al	
   query,	
   di   erent	
   informa.on	
   needs	
   
       how	
   does	
   user	
   describe	
   what	
   they	
   don   t	
   know?	
   

ask	
   hypothesis	
   

       belkin	
   et	
   al	
   (1982)	
   proposed	
   a	
   model	
   called	
   

anomalous	
   state	
   of	
   knowledge	
   

       ask	
   hypothesis:	
   

      di   cult	
   for	
   people	
   to	
   de   ne	
   exactly	
   what	
   their	
   
informa.on	
   need	
   is,	
   because	
   that	
   informa.on	
   is	
   a	
   
gap	
   in	
   their	
   knowledge	
   
      search	
   engine	
   should	
   look	
   for	
   informa.on	
   that	
   
   lls	
   those	
   gaps	
   

       interes.ng	
   ideas,	
   lizle	
   prac.cal	
   impact	
   (yet)	
   

keyword	
   queries	
   

       query	
   languages	
   in	
   the	
   past	
   were	
   designed	
   for	
   

professional	
   searchers	
   (intermediaries)	
   

keyword	
   queries	
   

       simple,	
   natural	
   language	
   queries	
   were	
   
designed	
   to	
   enable	
   everyone	
   to	
   search	
   

       current	
   search	
   engines	
   do	
   not	
   perform	
   well	
   
(in	
   general)	
   with	
   natural	
   language	
   queries	
   
       people	
   trained	
   (in	
   e   ect)	
   to	
   use	
   keywords	
   

      compare	
   average	
   of	
   about	
   2.3	
   words/web	
   query	
   
to	
   average	
   of	
   30	
   words/cqa	
   query	
   

       keyword	
   selec.on	
   is	
   not	
   always	
   easy	
   
      query	
   re   nement	
   techniques	
   can	
   help	
   

query	
   reformula.on	
   

match	
   underlying	
   intent	
   

       rewrite	
   or	
   transform	
   original	
   query	
   to	
   bezer	
   
       can	
   happen	
   implicitly	
   or	
   explicitly	
   (sugges.on)	
   
       many	
   techniques	
   

      query-     based	
   id30	
   
      spelling	
   correc.on	
   
      segmenta.on	
   
      subs.tu.on	
   
      expansion	
   

query-     based	
   id30	
   

       make	
   decision	
   about	
   id30	
   at	
   query	
   .me	
   

rather	
   than	
   during	
   indexing	
   
      improved	
      exibility,	
   e   ec.veness	
   

       query	
   is	
   expanded	
   using	
   word	
   variants	
   

      documents	
   are	
   not	
   stemmed	
   
      e.g.,	
      rock	
   climbing   	
   expanded	
   with	
      climb   ,	
   not	
   
stemmed	
   to	
      climb   	
   

stem	
   classes	
   

       a	
   stem	
   class	
   is	
   the	
   group	
   of	
   words	
   that	
   will	
   be	
   

transformed	
   into	
   the	
   same	
   stem	
   by	
   the	
   
id30	
   algorithm	
   
      generated	
   by	
   running	
   stemmer	
   on	
   large	
   corpus	
   
      e.g.,	
   porter	
   stemmer	
   on	
   trec	
   news	
   

stem	
   classes	
   

       stem	
   classes	
   are	
   ocen	
   too	
   big	
   and	
   

inaccurate	
   

       modify	
   using	
   analysis	
   of	
   word	
   co-     occurrence	
   
       assump(on:	
   

      word	
   variants	
   that	
   could	
   subs.tute	
   for	
   each	
   
other	
   should	
   co-     occur	
   ocen	
   in	
   documents	
   
       e.g.,	
   reduces	
   previous	
   example	
   /polic	
   and	
   /bank	
   
classes	
   to	
   

query	
   log	
   

       records	
   all	
   queries	
   and	
   documents	
   clicked	
   on	
   

by	
   users,	
   along	
   with	
   .mestamp	
   

       used	
   heavily	
   for	
   query	
   transforma.on,	
   query	
   

sugges.on	
   

       also	
   used	
   for	
   query-     based	
   id30	
   

      word	
   variants	
   that	
   co-     occur	
   with	
   other	
   query	
   
words	
   can	
   be	
   added	
   to	
   query	
   
       e.g.,	
   for	
   the	
   query	
      tropical	
      sh   ,	
         shes   	
   may	
   be	
   found	
   
with	
      tropical   	
   in	
   query	
   log,	
   but	
   not	
         shing   	
   
       classic	
   example:	
      strong	
   tea   	
   not	
      powerful	
   tea   	
   

modifying	
   stem	
   classes	
   

modifying	
   stem	
   classes	
   
       dices   	
   coe   cient	
   is	
   an	
   example	
   of	
   a	
   term	
   

associa.on	
   measure	
   

       	
   	
   	
   	
   	
   	
   	
   	
   	
   	
   	
   	
   	
   	
   	
   	
   	
   	
   	
   	
   
       where	
   nx	
   is	
   the	
   number	
   of	
   windows	
   containing	
   x	
   
       two	
   ver.ces	
   are	
   in	
   the	
   same	
   connected	
   

component	
   of	
   a	
   graph	
   if	
   there	
   is	
   a	
   path	
   between	
   
them	
   
       forms	
   word	
   clusters	
   

       example	
   output	
   of	
   modi   ca.on	
   
       when	
   would	
   this	
   fail?	
   

query	
   segmenta.on	
   

       break	
   up	
   queries	
   into	
   important	
      chunks   	
   

       e.g.,	
      new	
   york	
   .mes	
   square   	
   becomes	
      new	
   york   	
   

   .mes	
   square   	
   

       possible	
   approaches:	
   

treat	
   each	
   term	
   as	
   a	
   concept	
   

	
   	
   	
   	
   	
   	
   	
   	
   	
   	
   	
   	
   	
   [members]	
   [rock]	
   [group]	
   [nirvana]	
   

treat	
   every	
   adjacent	
   pair	
   of	
   terms	
   as	
   a	
   concept	
   

	
   	
   	
   	
   	
   	
   	
   	
   	
   	
   	
   	
   	
   [members	
   rock]	
   [rock	
   group]	
   [group	
   nirvana]	
   

treat	
   all	
   terms	
   within	
   a	
   noun	
   phrase	
      chunk   	
   as	
   a	
   concept	
   

	
   	
   	
   	
   	
   	
   	
   	
   	
   	
   	
   	
   	
   [members]	
   [rock	
   group	
   nirvana]	
   

treat	
   all	
   terms	
   that	
   occur	
   in	
   common	
   queries	
   as	
   a	
   single	
   concept	
   

	
   	
   	
   	
   	
   	
   	
   	
   	
   	
   	
   	
   	
   [members]	
   [rock	
   group]	
   [nirvana]	
   

the	
   thesaurus	
   

       used	
   in	
   early	
   search	
   engines	
   as	
   a	
   tool	
   for	
   indexing	
   
and	
   query	
   formula(on	
   	
   
       speci   ed	
   preferred	
   terms	
   and	
   rela.onships	
   between	
   
       also	
   called	
   controlled	
   vocabulary	
   
       or	
   authority	
   list	
   

them	
   

       par.cularly	
   useful	
   for	
   query	
   expansion	
   

       adding	
   synonyms	
   or	
   more	
   speci   c	
   terms	
   using	
   query	
   
operators	
   based	
   on	
   thesaurus	
   
       improves	
   search	
   e   ec.veness	
   

mesh	
   thesaurus	
   

query	
   expansion	
   

       a	
   variety	
   of	
   automa(c	
   or	
   semi-     automa(c	
   

query	
   expansion	
   techniques	
   have	
   been	
   
developed	
   
      goal	
   is	
   to	
   improve	
   e   ec.veness	
   by	
   matching	
   
related	
   terms	
   
      semi-     automa.c	
   techniques	
   require	
   user	
   
interac.on	
   to	
   select	
   best	
   expansion	
   terms	
   
       query	
   sugges.on	
   is	
   a	
   related	
   technique	
   

      alterna.ve	
   queries,	
   not	
   necessarily	
   more	
   terms	
   

query	
   expansion	
   

       approaches	
   usually	
   based	
   on	
   an	
   analysis	
   of	
   
term	
   co-     occurrence	
   
      either	
   in	
   the	
   en.re	
   document	
   collec.on,	
   a	
   large	
   
collec.on	
   of	
   queries,	
   or	
   the	
   top-     ranked	
   
documents	
   in	
   a	
   result	
   list	
   
      query-     based	
   id30	
   also	
   an	
   expansion	
   
technique	
   
       automa.c	
   expansion	
   based	
   on	
   general	
   

thesaurus	
   not	
   generally	
   e   ec.ve	
   
      does	
   not	
   take	
   context	
   into	
   account	
   

term	
   associa.on	
   measures	
   

       dice   s	
   coe   cient	
   

       (pointwise)	
   mutual	
   informa(on	
   

term	
   associa.on	
   measures	
   
       mutual	
   informa.on	
   measure	
   favors	
   low	
   

frequency	
   terms	
   

       expected	
   mutual	
   informa(on	
   measure	
   (emim)	
   	
   

      actually	
   only	
   1	
   part	
   of	
   full	
   emim,	
   focused	
   on	
   word	
   
occurrence	
   

term	
   associa.on	
   measures	
   

       pearson   s	
   chi-     squared	
   (  2)	
   measure	
   

      compares	
   the	
   number	
   of	
   co-     occurrences	
   of	
   two	
   
words	
   with	
   the	
   expected	
   number	
   of	
   co-     
occurrences	
   if	
   the	
   two	
   words	
   were	
   independent	
   	
   
      normalizes	
   this	
   comparison	
   by	
   the	
   expected	
   
number	
   
      also	
   limited	
   form	
   focused	
   on	
   word	
   co-     occurrence	
   

associa.on	
   measure	
   summary	
   

associa.on	
   measure	
   example	
   

most	
   strongly	
   associated	
   words	
   for	
      tropical   	
   in	
   a	
   collec.on	
   of	
   trec	
   news	
   
stories.	
   co-     occurrence	
   counts	
   are	
   measured	
   at	
   the	
   document	
   level.	
   

associa.on	
   measure	
   example	
   

most	
   strongly	
   associated	
   words	
   for	
         sh   	
   in	
   a	
   collec.on	
   of	
   trec	
   news	
   stories.	
   

associa.on	
   measure	
   example	
   

most	
   strongly	
   associated	
   words	
   for	
         sh   	
   in	
   a	
   collec.on	
   of	
   trec	
   
news	
   stories.	
   co-     occurrence	
   counts	
   are	
   measured	
   in	
   windows	
   of	
   5	
   
words.	
   

associa.on	
   measures	
   
       associated	
   words	
   are	
   of	
   lizle	
   use	
   for	
   
expanding	
   the	
   query	
      tropical	
      sh   	
   
       expansion	
   based	
   on	
   whole	
   query	
   takes	
   

context	
   into	
   account	
   
      e.g.,	
   using	
   dice	
   with	
   term	
      tropical	
      sh   	
   gives	
   the	
   
following	
   highly	
   associated	
   words:	
   	
   
gold   sh,	
   rep.le,	
   aquarium,	
   coral,	
   frog,	
   exo.c,	
   stripe,	
   
       imprac.cal	
   for	
   all	
   possible	
   queries,	
   other	
   

regent,	
   pet,	
   wet	
   

approaches	
   used	
   to	
   achieve	
   this	
   e   ect	
   

other	
   approaches	
   

       pseudo-     relevance	
   feedback	
   

       expansion	
   terms	
   based	
   on	
   top	
   retrieved	
   documents	
   

for	
   ini.al	
   query	
   
       context	
   vectors	
   

them	
   

       represent	
   words	
   by	
   the	
   words	
   that	
   co-     occur	
   with	
   

       e.g.,	
   top	
   35	
   most	
   strongly	
   associated	
   words	
   for	
      aquarium   	
   (using	
   

dice   s	
   coe   cient):	
   

       rank	
   words	
   for	
   a	
   query	
   by	
   ranking	
   context	
   vectors	
   

other	
   approaches	
   

       query	
   logs	
   

      best	
   source	
   of	
   informa.on	
   about	
   queries	
   and	
   
related	
   terms	
   
       short	
   pieces	
   of	
   text	
   and	
   click	
   data	
   
      e.g.,	
   most	
   frequent	
   words	
   in	
   queries	
   containing	
   
   tropical	
      sh   	
   from	
   msn	
   log:	
   
	
   	
   	
   stores,	
   pictures,	
   live,	
   sale,	
   types,	
   clipart,	
   blue,	
   

freshwater,	
   aquarium,	
   supplies	
   

       group	
   based	
   on	
   click	
   data	
   

      query	
   sugges.on	
   based	
   on	
      nding	
   similar	
   queries	
   
      query	
   reformula.on/expansion	
   based	
   on	
   term	
   
associa.ons	
   in	
   logs	
   

query	
   sugges.on	
   using	
   logs	
   

query	
   reformula.on	
   using	
   logs	
   

spell	
   checking	
   

       important	
   part	
   of	
   query	
   processing	
   

      10-     15%	
   of	
   all	
   web	
   queries	
   have	
   spelling	
   errors	
   

       errors	
   include	
   typical	
   word	
   processing	
   errors	
   

but	
   also	
   many	
   other	
   types,	
   e.g.	
   

spell	
   checking	
   

       basic	
   approach:	
   suggest	
   correc.ons	
   for	
   words	
   

not	
   found	
   in	
   spelling	
   dic(onary	
   

       sugges.ons	
   found	
   by	
   comparing	
   word	
   to	
   

words	
   in	
   dic.onary	
   using	
   similarity	
   measure	
   

       most	
   common	
   similarity	
   measure	
   is	
   edit	
   

distance	
   
      number	
   of	
   opera.ons	
   required	
   to	
   transform	
   one	
   
word	
   into	
   the	
   other	
   

edit	
   distance	
   
       damerau-     levenshtein	
   distance	
   

      counts	
   the	
   minimum	
   number	
   of	
   inser.ons,	
   
dele.ons,	
   subs.tu.ons,	
   or	
   transposi.ons	
   of	
   single	
   
characters	
   required	
   
      e.g.,	
   damerau-     levenshtein	
   distance	
   1	
   

	
   

	
   
      distance	
   2	
   

edit	
   distance	
   

       dynamic	
   programming	
   algorithm	
   (on	
   board)	
   

edit	
   distance	
   

       number	
   of	
   techniques	
   used	
   to	
   speed	
   up	
   

calcula.on	
   of	
   edit	
   distances	
   
      restrict	
   to	
   words	
   star.ng	
   with	
   same	
   character	
   
      restrict	
   to	
   words	
   of	
   same	
   or	
   similar	
   length	
   
      restrict	
   to	
   words	
   that	
   sound	
   the	
   same	
   

       last	
   op.on	
   uses	
   a	
   phone(c	
   code	
   to	
   group	
   

words	
   
      e.g.	
   soundex	
   

soundex	
   code	
   

spelling	
   correc.on	
   issues	
   

          did	
   you	
   mean...   	
   feature	
   requires	
   accurate	
   ranking	
   of	
   

       ranking	
   correc.ons	
   
possible	
   correc.ons	
   

       context	
   
words)	
   

       choosing	
   right	
   sugges.on	
   depends	
   on	
   context	
   (other	
   
       e.g.,	
   lawers	
      	
   lowers,	
   lawyers,	
   layers,	
   lasers,	
   lagers	
   	
   	
   	
   	
   	
   

	
   but	
   	
   trial	
   lawers	
      	
   trial	
   lawyers	
   

       run-     on	
   errors	
   

       e.g.,	
      mainscourcebank   	
   
       missing	
   spaces	
   can	
   be	
   considered	
   another	
   single	
   

character	
   error	
   in	
   right	
   framework	
   

noisy	
   channel	
   model	
   

       user	
   chooses	
   word	
   w	
   based	
   on	
   id203	
   

distribu.on	
   p(w)	
   
      called	
   the	
   language	
   model	
   
      can	
   capture	
   context	
   informa.on,	
   e.g.	
   p(w1|w2)	
   
       user	
   writes	
   word,	
   but	
   noisy	
   channel	
   causes	
   
word	
   e	
   to	
   be	
   wrizen	
   instead	
   with	
   id203	
   
p(e|w)	
   
      called	
   error	
   model	
   
      represents	
   informa.on	
   about	
   the	
   frequency	
   of	
   
spelling	
   errors	
   

noisy	
   channel	
   model	
   

       need	
   to	
   es.mate	
   id203	
   of	
   correc.on	
   
       es.mate	
   language	
   model	
   using	
   context	
   

      p(w|e)	
   =	
   p(e|w)p(w)	
   

      e.g.,	
   p(w)	
   =	
     p(w)	
   +	
   (1	
      	
     )p(w|wp)	
   
      wp	
   is	
   previous	
   word	
   

       e.g.,	
   	
   

            sh	
   .nk   	
   
         tank   	
   and	
      think   	
   both	
   likely	
   correc.ons,	
   but	
   
p(tank|   sh)	
   >	
   p(think|   sh)	
   

noisy	
   channel	
   model	
   

       language	
   model	
   probabili.es	
   es.mated	
   using	
   

corpus	
   and	
   query	
   log	
   

       both	
   simple	
   and	
   complex	
   methods	
   have	
   been	
   

used	
   for	
   es.ma.ng	
   error	
   model	
   
      simple	
   approach:	
   assume	
   all	
   words	
   with	
   same	
   edit	
   
distance	
   have	
   same	
   id203,	
   only	
   edit	
   distance	
   
1	
   and	
   2	
   considered	
   
      more	
   complex	
   approach:	
   incorporate	
   es.mates	
   
based	
   on	
   common	
   typing	
   errors	
   

example	
   spellcheck	
   process	
   

relevant)	
   documents	
   in	
   the	
   ini.al	
   result	
   list	
   

relevance	
   feedback	
   
       user	
   iden.   es	
   relevant	
   (and	
   maybe	
   non-     
       system	
   modi   es	
   query	
   using	
   terms	
   from	
   those	
   
documents	
   and	
   reranks	
   documents	
   
       example	
   of	
   simple	
   machine	
   learning	
   algorithm	
   using	
   
       but,	
   very	
   lizle	
   training	
   data	
   

training	
   data	
   

       pseudo-     relevance	
   feedback	
   just	
   assumes	
   top-     

ranked	
   documents	
   are	
   relevant	
      	
   no	
   user	
   input	
   
       in	
   machine	
   learning,	
   aka	
   self-     training	
   or	
   id64	
   

relevance	
   feedback	
   example	
   

top	
   10	
   documents	
   
for	
      tropical	
      sh   	
   

relevance	
   feedback	
   example	
   

       if	
   we	
   assume	
   top	
   10	
   are	
   relevant,	
   most	
   

frequent	
   terms	
   are	
   (with	
   frequency):	
   

	
   	
   	
   a	
   (926),	
   td	
   (535),	
   href	
   (495),	
   hzp	
   (357),	
   width	
   (345),	
   

com	
   (343),	
   nbsp	
   (316),	
   www	
   (260),	
   tr	
   (239),	
   htm	
   (233),	
   
class	
   (225),	
   jpg	
   (221)	
   
       too	
   many	
   stopwords	
   and	
   html	
   expressions	
   

       use	
   only	
   snippets	
   and	
   remove	
   stopwords	
   
	
   	
   	
   tropical	
   (26),	
      sh	
   (28),	
   aquarium	
   (8),	
   freshwater	
   (5),	
   

breeding	
   (4),	
   informa.on	
   (3),	
   species	
   (3),	
   tank	
   (2),	
   
badman   s	
   (2),	
   page	
   (2),	
   hobby	
   (2),	
   forums	
   (2)	
   

relevance	
   feedback	
   example	
   
       if	
   document	
   7	
   (   breeding	
   tropical	
      sh   )	
   is	
   
explicitly	
   indicated	
   to	
   be	
   relevant,	
   the	
   most	
   
frequent	
   terms	
   are:	
   

coldwater	
   (2),	
   keeping	
   (1),	
   interested	
   (1)	
   

	
   	
   	
   breeding	
   (4),	
      sh	
   (4),	
   tropical	
   (4),	
   marine	
   (2),	
   pond	
   (2),	
   
       speci   c	
   weights	
   and	
   scoring	
   methods	
   used	
   for	
   
relevance	
   feedback	
   depend	
   on	
   retrieval	
   model	
   

	
   

relevance	
   feedback	
   

       both	
   relevance	
   feedback	
   and	
   pseudo-     relevance	
   

feedback	
   are	
   e   ec.ve,	
   but	
   not	
   used	
   in	
   many	
   
applica.ons	
   
       pseudo-     relevance	
   feedback	
   has	
   reliability	
   issues,	
   
especially	
   with	
   queries	
   that	
   don   t	
   retrieve	
   many	
   
relevant	
   documents	
   
       some	
   applica.ons	
   use	
   relevance	
   feedback	
   

          ltering,	
      more	
   like	
   this   	
   

       query	
   sugges.on	
   more	
   popular	
   

       may	
   be	
   less	
   accurate,	
   but	
   can	
   work	
   if	
   ini.al	
   query	
   fails	
   

context	
   and	
   personaliza.on	
   
       if	
   a	
   query	
   has	
   the	
   same	
   words	
   as	
   another	
   

query,	
   should	
   results	
   be	
   the	
   same	
   regardless	
   of	
   
      who	
   submized	
   the	
   query,	
   
      why	
   the	
   query	
   was	
   submized,	
   
      where	
   the	
   query	
   was	
   submized,	
   or	
   
      what	
   other	
   queries	
   were	
   submized	
   in	
   the	
   same	
   
session?	
   

       these	
   other	
   factors	
   (the	
   context)	
   could	
   have	
   a	
   

signi   cant	
   impact	
   on	
   relevance	
   

user	
   models	
   

       generate	
   user	
   pro   les	
   based	
   on	
   documents	
   

that	
   the	
   person	
   looks	
   at	
   
      such	
   as	
   web	
   pages	
   visited,	
   email	
   messages,	
   or	
   
word	
   processing	
   documents	
   on	
   the	
   desktop	
   
       modify	
   queries	
   using	
   words	
   from	
   pro   le	
   
       generally	
   not	
   e   ec.ve	
   

      imprecise	
   pro   les,	
   informa.on	
   needs	
   can	
   change	
   
signi   cantly	
   

query	
   logs	
   

       query	
   logs	
   provide	
   important	
   contextual	
   
informa.on	
   that	
   can	
   be	
   used	
   e   ec.vely	
   

       context	
   in	
   this	
   case	
   is	
   

      previous	
   queries	
   that	
   are	
   the	
   same	
   
      previous	
   queries	
   that	
   are	
   similar	
   
      query	
   sessions	
   including	
   the	
   same	
   query	
   

       query	
   history	
   for	
   individuals	
   could	
   be	
   used	
   for	
   

caching	
   or	
   query	
   transforma.on	
   

local	
   search	
   

       loca.on	
   is	
   context	
   
       local	
   search	
   uses	
   geographic	
   informa.on	
   to	
   

modify	
   the	
   ranking	
   of	
   search	
   results	
   
      loca.on	
   derived	
   from	
   the	
   query	
   text	
   
      loca.on	
   of	
   the	
   device	
   where	
   the	
   query	
   originated	
   

       e.g.,	
   

         underworld	
   3	
   cape	
   cod   	
   
         underworld	
   3   	
   from	
   mobile	
   device	
   in	
   hyannis	
   

local	
   search	
   

       iden.fy	
   the	
   geographic	
   region	
   associated	
   with	
   

web	
   pages	
   
       use	
   loca.on	
   metadata	
   that	
   has	
   been	
   manually	
   added	
   
       or	
   iden.fy	
   loca.ons	
   such	
   as	
   place	
   names,	
   city	
   names,	
   

to	
   the	
   document,	
   

or	
   country	
   names	
   in	
   text	
   

       iden.fy	
   the	
   geographic	
   region	
   associated	
   with	
   
the	
   query	
   	
   
       10-     15%	
   of	
   queries	
   contain	
   some	
   loca.on	
   reference	
   
       rank	
   web	
   pages	
   using	
   loca.on	
   informa.on	
   in	
   

addi.on	
   to	
   text	
   and	
   link-     based	
   features	
   

extrac.ng	
   loca.on	
   informa.on	
   

       type	
   of	
   informa.on	
   extrac.on	
   
       loca.on	
   names	
   are	
   mapped	
   to	
   speci   c	
   

      ambiguity	
   and	
   signi   cance	
   of	
   loca.ons	
   are	
   issues	
   

regions	
   and	
   coordinates	
   

       matching	
   done	
   by	
   inclusion,	
   distance	
   

snippet	
   genera.on	
   

       query-     dependent	
   document	
   summary	
   
       simple	
   summariza.on	
   approach	
   

      rank	
   each	
   sentence	
   in	
   a	
   document	
   using	
   a	
   
signi   cance	
   factor	
   
      select	
   the	
   top	
   sentences	
   for	
   the	
   summary	
   
         rst	
   proposed	
   by	
   luhn	
   in	
   50   s	
   

sentence	
   selec.on	
   

       signi   cance	
   factor	
   for	
   a	
   sentence	
   is	
   calculated	
   
based	
   on	
   the	
   occurrence	
   of	
   signi   cant	
   words	
   
      if	
   fd,w	
   is	
   the	
   frequency	
   of	
   word	
   w	
   in	
   document	
   d,	
   
then	
   w	
   is	
   a	
   signi   cant	
   word	
   if	
   it	
   is	
   not	
   a	
   stopword	
   
and	
   

where	
   sd	
   is	
   the	
   number	
   of	
   sentences	
   in	
   document	
   d	
   
      text	
   is	
   bracketed	
   by	
   signi   cant	
   words	
   (limit	
   on	
   
number	
   of	
   non-     signi   cant	
   words	
   in	
   bracket)	
   

sentence	
   selec.on	
   

       signi   cance	
   factor	
   for	
   bracketed	
   text	
   spans	
   is	
   

computed	
   by	
   dividing	
   the	
   square	
   of	
   the	
   
number	
   of	
   signi   cant	
   words	
   in	
   the	
   span	
   by	
   the	
   
total	
   number	
   of	
   words	
   

       e.g.,	
   

       signi   cance	
   factor	
   =	
   42/7	
   =	
   2.3	
   

snippet	
   genera.on	
   

       involves	
   more	
   features	
   than	
   just	
   signi   cance	
   
       e.g.	
   for	
   a	
   news	
   story,	
   could	
   use	
   

factor	
   

       whether	
   the	
   sentence	
   is	
   a	
   heading	
   	
   
       whether	
   it	
   is	
   the	
      rst	
   or	
   second	
   line	
   of	
   the	
   document	
   	
   
       the	
   total	
   number	
   of	
   query	
   terms	
   occurring	
   in	
   the	
   sentence	
   	
   
       the	
   number	
   of	
   unique	
   query	
   terms	
   in	
   the	
   sentence	
   	
   
       the	
   longest	
   con.guous	
   run	
   of	
   query	
   words	
   in	
   the	
   sentence	
   
       a	
   density	
   measure	
   of	
   query	
   words	
   (signi   cance	
   factor)	
   
       weighted	
   combina.on	
   of	
   features	
   used	
   to	
   

rank	
   sentences	
   

snippet	
   genera.on	
   

       web	
   pages	
   are	
   less	
   structured	
   than	
   news	
   stories	
   

       can	
   be	
   di   cult	
   to	
      nd	
   good	
   summary	
   sentences	
   

       snippet	
   sentences	
   are	
   ocen	
   selected	
   from	
   other	
   

sources	
   
       metadata	
   associated	
   with	
   the	
   web	
   page	
   
       e.g.,	
   <meta	
   name="descrip.on"	
   content=	
   ...>	
   
       external	
   sources	
   such	
   as	
   web	
   directories	
   

       e.g.,	
   open	
   directory	
   project,	
   hzp://www.dmoz.org	
   

       snippets	
   can	
   be	
   generated	
   from	
   text	
   of	
   pages	
   like	
   

wikipedia	
   

snippet	
   guidelines	
   
       all	
   query	
   terms	
   should	
   appear	
   in	
   the	
   

summary,	
   showing	
   their	
   rela.onship	
   to	
   the	
   
retrieved	
   page	
   
       when	
   query	
   terms	
   are	
   present	
   in	
   the	
   .tle,	
   
they	
   need	
   not	
   be	
   repeated	
   
      allows	
   snippets	
   that	
   do	
   not	
   contain	
   query	
   terms	
   

       highlight	
   query	
   terms	
   in	
   urls	
   
       snippets	
   should	
   be	
   readable	
   text,	
   not	
   lists	
   of	
   

keywords	
   

adver.sing	
   

       sponsored	
   search	
      	
   adver.sing	
   presented	
   with	
   

search	
   results	
   

       contextual	
   adver(sing	
      	
   adver.sing	
   presented	
   

when	
   browsing	
   web	
   pages	
   

       both	
   involve	
      nding	
   the	
   most	
   relevant	
   

adver.sements	
   in	
   a	
   database	
   
      an	
   adver.sement	
   usually	
   consists	
   of	
   a	
   short	
   text	
   
descrip.on	
   and	
   a	
   link	
   to	
   a	
   web	
   page	
   describing	
   
the	
   product	
   or	
   service	
   in	
   more	
   detail	
   

searching	
   adver.sements	
   

       factors	
   involved	
   in	
   ranking	
   adver.sements	
   

      similarity	
   of	
   text	
   content	
   to	
   query	
   
      bids	
   for	
   keywords	
   in	
   query	
   
      popularity	
   of	
   adver.sement	
   

       small	
   amount	
   of	
   text	
   in	
   adver.sement	
   

      dealing	
   with	
   vocabulary	
   mismatch	
   is	
   important	
   
      expansion	
   techniques	
   are	
   e   ec.ve	
   

example	
   adver.sements	
   

adver.sements	
   retrieved	
   for	
   query	
         sh	
   tank   	
   

searching	
   adver.sements	
   

       pseudo-     relevance	
   feedback	
   

      expand	
   query	
   and/or	
   document	
   using	
   the	
   web	
   
      use	
   ad	
   text	
   or	
   query	
   for	
   pseudo-     relevance	
   
feedback	
   
      rank	
   exact	
   matches	
      rst,	
   followed	
   by	
   stem	
   
matches,	
   followed	
   by	
   expansion	
   matches	
   
       query	
   reformula.on	
   based	
   on	
   query	
   log	
   

id91	
   results	
   

       result	
   lists	
   ocen	
   contain	
   documents	
   related	
   

to	
   di   erent	
   aspects	
   of	
   the	
   query	
   topic	
   

       id91	
   is	
   used	
   to	
   group	
   related	
   documents	
   

to	
   simplify	
   browsing	
   

example	
   clusters	
   for	
   	
   
query	
      tropical	
      sh   	
   

result	
   list	
   example	
   

top	
   10	
   documents	
   
for	
      tropical	
      sh   	
   

id91	
   results	
   

       requirements	
   
       e   ciency	
   

      must	
   be	
   speci   c	
   to	
   each	
   query	
   and	
   are	
   based	
   on	
   
the	
   top-     ranked	
   documents	
   for	
   that	
   query	
   
      typically	
   based	
   on	
   snippets	
   

       easy	
   to	
   understand	
   

      can	
   be	
   di   cult	
   to	
   assign	
   good	
   labels	
   to	
   groups	
   
      monothe.c	
   vs.	
   polythe.c	
   classi   ca.on	
   

types	
   of	
   classi   ca.on	
   

       monothe.c	
   

      every	
   member	
   of	
   a	
   class	
   has	
   the	
   property	
   that	
   
de   nes	
   the	
   class	
   
      typical	
   assump.on	
   made	
   by	
   users	
   
      easy	
   to	
   understand	
   

       polythe.c	
   

      members	
   of	
   classes	
   share	
   many	
   proper.es	
   but	
   
there	
   is	
   no	
   single	
   de   ning	
   property	
   
      most	
   id91	
   algorithms	
   (e.g.	
   k-     means)	
   produce	
   
this	
   type	
   of	
   output	
   

classi   ca.on	
   example	
   

       possible	
   monothe.c	
   classi   ca.on	
   

      {d1,d2}	
   (labeled	
   using	
   a)	
   and	
   {d2,d3}	
   (labeled	
   e)	
   

       possible	
   polythe.c	
   classi   ca.on	
   

      {d2,d3,d4},	
   d1	
   
      labels?	
   

result	
   clusters	
   

	
   

	
   

	
   

	
   	
   	
   

       simple	
   algorithm	
   
      group	
   based	
   on	
   

	
   words	
   in	
   snippets	
   

       re   nements	
   
      use	
   phrases	
   
      use	
   more	
   features	
   

       whether	
   phrases	
   occurred	
   in	
   .tles	
   or	
   snippets	
   	
   
       length	
   of	
   the	
   phrase	
   
       collec.on	
   frequency	
   of	
   the	
   phrase	
   
       overlap	
   of	
   the	
   resul.ng	
   clusters,	
   

faceted	
   classi   ca.on	
   

       a	
   set	
   of	
   categories,	
   usually	
   organized	
   into	
   a	
   
hierarchy,	
   together	
   with	
   a	
   set	
   of	
   facets	
   that	
   
describe	
   the	
   important	
   proper.es	
   associated	
   
with	
   the	
   category	
   
       manually	
   de   ned	
   

      poten.ally	
   less	
   adaptable	
   than	
   dynamic	
   
classi   ca.on	
   

       easy	
   to	
   understand	
   

      commonly	
   used	
   in	
   e-     commerce	
   

example	
   faceted	
   classi   ca.on	
   

categories	
   for	
      tropical	
      sh   	
   

example	
   faceted	
   classi   ca.on	
   

subcategories	
   and	
   facets	
   for	
      home	
   &	
   garden   	
   

cross-     language	
   search	
   

       query	
   in	
   one	
   language,	
   retrieve	
   documents	
   in	
   

mul.ple	
   other	
   languages	
   

       involves	
   query	
   transla.on,	
   and	
   probably	
   

document	
   transla.on	
   

       query	
   transla.on	
   can	
   be	
   done	
   using	
   bilingual	
   

dic.onaries	
   

       document	
   transla.on	
   requires	
   more	
   

sophis.cated	
   sta(s(cal	
   transla(on	
   models	
   
      similar	
   to	
   some	
   retrieval	
   models	
   

cross-     language	
   search	
   

transla.on	
   

       web	
   search	
   engines	
   use	
   transla.on	
   

      e.g.	
   for	
   query	
      pecheur	
   france   	
   

      transla.on	
   link	
   translates	
   web	
   page	
   
      uses	
   sta.s.cal	
   machine	
   transla.on	
   models	
   

sta.s.cal	
   transla.on	
   models	
   
       models	
   require	
   parallel	
   corpora	
   for	
   training	
   

      id203	
   es.mates	
   based	
   on	
   aligned	
   sentences	
   
       transla.on	
   of	
   unusual	
   words	
   and	
   phrases	
   is	
   a	
   

problem	
   
      also	
   use	
   translitera(on	
   techniques	
   

       e.g.,	
   qatha   ,	
   kadda   ,	
   qada   ,	
   gada   ,	
   gadda   ,	
   katha   ,	
   
kadha   ,	
   qadha   ,	
   qazza   ,	
   kaza   ,	
   qaddafy,	
   qadafy,	
   
quadha   ,	
   gadhdha   ,	
   al-     qadda   ,	
   al-     qadda   	
   

sta.s.cal	
   transla.on	
   models	
   

       transla.on	
   models	
   
          adequacy   	
   
       assign	
   bezer	
   scores	
   to	
   accurate	
   (and	
   complete)	
   transla.ons	
   
       language	
   models	
   
          fluency   	
   
       assign	
   bezer	
   scores	
   to	
   natural	
   target	
   language	
   text	
   
       compare:	
   error	
   models	
   and	
   language	
   models	
   for	
   
spelling	
   correc.on	
   
       warren	
   weaver:	
      when	
   i	
   see	
   an	
   ar.cle	
   in	
   russian,	
   i	
   say,	
   

   this	
   is	
   really	
   wrizen	
   in	
   english,	
   but	
   in	
   some	
   strange	
   
symbols.	
   i	
   will	
   now	
   proceed	
   to	
   decode.   	
      	
   

word	
   transla.on	
   models	
   

auf 

diese 

frage 

habe 

ich 

leider 

keine 

antwort 

bekommen 

blue word links aren   t observed in data. 

null 

i 

did 

not 

unfortunately 

receive 

an 

answer 

to 

this 

question 

features for word-word links: lexica, part-of-
speech, orthography, etc. 

word	
   transla.on	
   models	
   

       usually	
   directed:	
   each	
   word	
   
in	
   the	
   target	
   generated	
   by	
   
one	
   word	
   in	
   the	
   source	
   

       many-     many	
   and	
   null-     many	
   

links	
   allowed	
   

       classic	
   ibm	
   models	
   of	
   

brown	
   et	
   al.	
   

       used	
   now	
   mostly	
   for	
   word	
   
alignment,	
   not	
   transla.on	
   

im 

anfang 

war 

das  wort 

in 

the  beginning  was 

the  word 

phrase	
   transla.on	
   models	
   

not necessarily syntactic phrases 

division into phrases is hidden 

auf 

diese 

frage 

habe 

ich 

leider 

keine 

antwort 

bekommen 

phrase= 0.212121, 0.0550809; lex= 0.0472973, 0.0260183; lcount=2.718 
what are some other features? 

i 

did 

not 

unfortunately 

receive 

an 

answer 

to 

this 

question 

score each phrase pair using several features 

phrase	
   transla.on	
   models	
   

       capture	
   transla.ons	
   in context 
       en amerique:	
   to	
   america
	
   	
   
       en anglais:	
   in	
   english	
   
       state-     of-     the-     art	
   for	
   several	
   years	
   
       each	
   source/target	
   phrase	
   pair	
   is	
   scored	
   by	
   several	
   
       the	
   weighted	
   sum	
   of	
   model	
   features	
   is	
   the	
   whole	
   
       phrases	
   don   t	
   overlap	
   (cf.	
   language	
   models)	
   but	
   have	
   

transla.on   s	
   score.	
   

weighted	
   features.	
   

   reordering   	
   features.	
   

single-     tree	
   transla.on	
   models	
   

minimal	
   parse	
   tree:	
   word-     word	
   dependencies	
   

auf	
   

diese	
   

frage	
   

habe	
   

ich	
   

leider	
   

keine	
   

antwort	
   

bekommen	
   

null	
   

i	
   

did	
   

not	
   

unfortunately	
   

receive	
   

an	
   

answer	
   

to	
   

this	
   

ques.on	
   

parse	
   trees	
   with	
   deeper	
   structure	
   have	
   also	
   been	
   used.	
   

single-     tree	
   transla.on	
   models	
   

       either	
   source	
   or	
   target	
   has	
   a	
   hidden	
   tree/parse	
   
structure	
   
       also	
   known	
   as	
      tree-     to-     string   	
   or	
      tree-     transducer   	
   models	
   
       the	
   side	
   with	
   the	
   tree	
   generates	
   words/phrases	
   in	
   
       nodes	
   in	
   the	
   tree	
   also	
   generate	
   words/phrases	
   on	
   the	
   
       english	
   side	
   is	
   ocen	
   parsed,	
   whether	
   it   s	
   source	
   or	
   

tree,	
   not	
   string,	
   order.	
   

other	
   side.	
   

target,	
   since	
   english	
   parsing	
   is	
   more	
   advanced.	
   

tree-     tree	
   transla.on	
   models	
   

auf	
   

diese	
   

frage	
   

habe	
   

ich	
   

leider	
   

keine	
   

antwort	
   

bekommen	
   

null	
   

i	
   

did	
   

not	
   

unfortunately	
   

receive	
   

an	
   

answer	
   

to	
   

this	
   

ques.on	
   

tree-     tree	
   transla.on	
   models	
   

       both	
   sides	
   have	
   hidden	
   tree	
   structure	
   
       can	
   be	
   represented	
   with	
   a	
      synchronous   	
   grammar	
   
       some	
   models	
   assume	
   isomorphic	
   trees,	
   where	
   parent-     

child	
   rela.ons	
   are	
   preserved;	
   others	
   do	
   not.	
   

       trees	
   can	
   be	
      xed	
   in	
   advance	
   by	
   monolingual	
   parsers	
   

or	
   induced	
   from	
   data	
   (e.g.	
   hiero).	
   

       cheap	
   trees:	
   project	
   from	
   one	
   side	
   to	
   the	
   other	
   

projec.ng	
   hidden	
   structure	
   

projec.on	
   

im	
   

anfang	
   

war	
   

das	
   

wort	
   

in	
   

the	
    beginning	
    was	
   

the	
    word	
   

       train	
   with	
   bitext	
   
       parse	
   one	
   side	
   
       align	
   words	
   
       project	
   dependencies	
   
       many	
   to	
   one	
   links?	
   
       non-     projec.ve	
   and	
   

circular	
   dependencies?	
   

