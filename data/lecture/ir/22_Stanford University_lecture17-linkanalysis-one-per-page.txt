introduc)on	
   to	
   informa)on	
   retrieval	
   

	
   	
   

	
   	
   

introduc*on	
   to	
   
informa(on	
   retrieval	
   

cs276	
   

informa*on	
   retrieval	
   and	
   web	
   search	
   

chris	
   manning	
   and	
   pandu	
   nayak	
   

link	
   analysis	
   

introduc)on	
   to	
   informa)on	
   retrieval	
   

	
   	
   

	
   	
   

today   s	
   lecture	
      	
   hypertext	
   and	
   links	
   
         we	
   look	
   beyond	
   the	
   content	
   of	
   documents	
   

         we	
   begin	
   to	
   look	
   at	
   the	
   hyperlinks	
   between	
   them	
   

         address	
   ques*ons	
   like	
   

         do	
   the	
   links	
   represent	
   a	
   conferral	
   of	
   authority	
   to	
   some	
   

pages?	
   is	
   this	
   useful	
   for	
   ranking?	
   

         how	
   likely	
   is	
   it	
   that	
   a	
   page	
   pointed	
   to	
   by	
   the	
   cern	
   home	
   

page	
   is	
   about	
   high	
   energy	
   physics	
   

         big	
   applica*on	
   areas	
   

         the	
   web	
   
         email	
   
         social	
   networks	
   

introduc)on	
   to	
   informa)on	
   retrieval	
   

	
   	
   

	
   	
   

links	
   are	
   everywhere	
   
         powerful	
   sources	
   of	
   authen*city	
   and	
   authority	
   
         mail	
   spam	
      	
   which	
   email	
   accounts	
   are	
   spammers?	
   
         host	
   quality	
      	
   which	
   hosts	
   are	
      bad   ?	
   
         phone	
   call	
   logs	
   

         the	
   good,	
   the	
   bad	
   and	
   the	
   unknown	
   

good 

? 

? 

? 

? 

bad 

3	
   

introduc)on	
   to	
   informa)on	
   retrieval	
   

	
   	
   

	
   	
   

example	
   1:	
   good/bad/unknown	
   
         the	
   good,	
   the	
   bad	
   and	
   the	
   unknown	
   

         good	
   nodes	
   won   t	
   point	
   to	
   bad	
   nodes	
   
         all	
   other	
   combina*ons	
   plausible	
   

good 

? 

? 

? 

? 

bad 

4	
   

introduc)on	
   to	
   informa)on	
   retrieval	
   

	
   	
   

	
   	
   

simple	
   itera*ve	
   logic	
   
         good	
   nodes	
   won   t	
   point	
   to	
   bad	
   nodes	
   

         if	
   you	
   point	
   to	
   a	
   bad	
   node,	
   you   re	
   bad	
   
         if	
   a	
   good	
   node	
   points	
   to	
   you,	
   you   re	
   good	
   

good 

? 

? 

? 

? 

bad 

5	
   

introduc)on	
   to	
   informa)on	
   retrieval	
   

	
   	
   

	
   	
   

simple	
   itera*ve	
   logic	
   
         good	
   nodes	
   won   t	
   point	
   to	
   bad	
   nodes	
   

         if	
   you	
   point	
   to	
   a	
   bad	
   node,	
   you   re	
   bad	
   
         if	
   a	
   good	
   node	
   points	
   to	
   you,	
   you   re	
   good	
   

good 

? 

bad 

? 

6	
   

introduc)on	
   to	
   informa)on	
   retrieval	
   

	
   	
   

	
   	
   

simple	
   itera*ve	
   logic	
   
         good	
   nodes	
   won   t	
   point	
   to	
   bad	
   nodes	
   

         if	
   you	
   point	
   to	
   a	
   bad	
   node,	
   you   re	
   bad	
   
         if	
   a	
   good	
   node	
   points	
   to	
   you,	
   you   re	
   good	
   

good 

bad 

sometimes need probabilistic analogs     e.g., mail spam 
7	
   

introduc)on	
   to	
   informa)on	
   retrieval	
   

	
   	
   

example	
   2:	
   
in-     links	
   to	
   pages	
      	
   unusual	
   pazerns	
   j   	
   

	
   	
   

spammers	
   
viola*ng	
   

power	
   laws!	
   

8	
   

introduc)on	
   to	
   informa)on	
   retrieval	
   

	
   	
   

	
   	
   

many	
   other	
   examples	
   of	
   link	
   analysis	
   
         social	
   networks	
   are	
   a	
   rich	
   source	
   of	
   grouping	
   

behavior	
   

         e.g.,	
   shoppers   	
   a   nity	
      	
   goel+goldstein	
   2010	
   
         consumers	
   whose	
   friends	
   spend	
   a	
   lot,	
   spend	
   a	
   lot	
   

themselves	
   

         hzp://www.cs.cornell.edu/home/kleinber/networks-     book/	
   

9	
   

introduc)on	
   to	
   informa)on	
   retrieval	
   

	
   	
   

	
   	
   

our	
   primary	
   interest	
   in	
   this	
   course	
   
         link	
   analysis	
   for	
   most	
   ir	
   func*onality	
   thus	
   far	
   based	
   

purely	
   on	
   text	
   
         scoring	
   and	
   ranking	
   
         link-     based	
   id91	
      	
   topical	
   structure	
   from	
   links	
   
         links	
   as	
   features	
   in	
   classi   ca*on	
      	
   documents	
   that	
   link	
   to	
   

one	
   another	
   are	
   likely	
   to	
   be	
   on	
   the	
   same	
   subject	
   

         crawling	
   

         based	
   on	
   the	
   links	
   seen,	
   where	
   do	
   we	
   crawl	
   next?	
   

10	
   

introduc)on	
   to	
   informa)on	
   retrieval	
   

	
   	
   

	
   	
   
sec. 21.1 

the	
   web	
   as	
   a	
   directed	
   graph	
   

page a 

anchor 

hyperlink 

page b 

hypothesis	
   1:	
   a	
   hyperlink	
   between	
   pages	
   denotes	
    	
   

	
   	
   	
   	
   

	
   	
   a	
   conferral	
   of	
   authority	
   (quality	
   signal)	
   

hypothesis	
   2:	
   the	
   text	
   in	
   the	
   anchor	
   of	
   the	
   hyperlink	
   on	
   
page	
   a	
   describes	
   the	
   target	
   page	
   b	
   

introduc)on	
   to	
   informa)on	
   retrieval	
   

	
   	
   

	
   	
   

assump*on	
   1:	
   reputed	
   sites	
   

12	
   

introduc)on	
   to	
   informa)on	
   retrieval	
   

	
   	
   

	
   	
   

assump*on	
   2:	
   annota*on	
   of	
   target	
   

13	
   

introduc)on	
   to	
   informa)on	
   retrieval	
   

	
   	
   

	
   	
   
sec. 21.1.1 

anchor	
   text	
   
	
   www	
   worm	
   -     	
   mcbryan	
   [mcbr94]	
   	
   
         for	
   ibm	
   how	
   to	
   dis*nguish	
   between:	
   

         ibm   s	
   home	
   page	
   (mostly	
   graphical)	
   
         ibm   s	
   copyright	
   page	
   (high	
   term	
   freq.	
   for	
      ibm   )	
   
         rival   s	
   spam	
   page	
   (arbitrarily	
   high	
   term	
   freq.)	
   

   ibm     
a million pieces of 
anchor text with    ibm    
send a strong signal 

   ibm.com    

   ibm home page    

www.ibm.com 

introduc)on	
   to	
   informa)on	
   retrieval	
   

	
   	
   

	
   	
   
sec. 21.1.1 

indexing	
   anchor	
   text	
   
         when	
   indexing	
   a	
   document	
   d,	
   include	
   (with	
   some	
   

weight)	
   anchor	
   text	
   from	
   links	
   poin*ng	
   to	
   d.	
   

armonk, ny-based computer 
giant ibm announced today 

www.ibm.com 

big blue today announced 
record profits for the quarter 

joe   s computer hardware 
links 
sun 
hp 
ibm 

introduc)on	
   to	
   informa)on	
   retrieval	
   

	
   	
   

	
   	
   
sec. 21.1.1 

indexing	
   anchor	
   text	
   
         can	
   some*mes	
   have	
   unexpected	
   e   ects,	
   e.g.,	
   spam,	
   

miserable	
   failure	
   

         can	
   score	
   anchor	
   text	
   with	
   weight	
   depending	
   on	
   the	
   

authority	
   of	
   the	
   anchor	
   page   s	
   website	
   
         e.g.,	
   if	
   we	
   were	
   to	
   assume	
   that	
   content	
   from	
   id98.com	
   or	
   
yahoo.com	
   is	
   authorita*ve,	
   then	
   trust	
   (more)	
   the	
   anchor	
   
text	
   from	
   them	
   

         increase	
   the	
   weight	
   of	
   o   -     site	
   anchors	
   (non-     nepo*s*c	
   

scoring)	
   

introduc)on	
   to	
   informa)on	
   retrieval	
   

	
   	
   

	
   	
   

connec*vity	
   servers	
   
gekng	
   at	
   all	
   that	
   link	
   informa*on	
   
inexpensively	
   

17	
   

introduc)on	
   to	
   informa)on	
   retrieval	
   

	
   	
   

	
   	
   
sec. 20.4 

connec*vity	
   server	
   
         support	
   for	
   fast	
   queries	
   on	
   the	
   web	
   graph	
   

         which	
   urls	
   point	
   to	
   a	
   given	
   url?	
   
         which	
   urls	
   does	
   a	
   given	
   url	
   point	
   to?	
   

stores	
   mappings	
   in	
   memory	
   from	
   

         url	
   to	
   outlinks,	
   url	
   to	
   inlinks	
   

         applica*ons	
   
         link	
   analysis	
   
         web	
   graph	
   analysis	
   

         connec*vity,	
   crawl	
   op*miza*on	
   

         crawl	
   control	
   

introduc)on	
   to	
   informa)on	
   retrieval	
   

	
   	
   

	
   	
   
sec. 20.4 

boldi	
   and	
   vigna	
   2004	
   
         hzp://www2004.org/proceedings/docs/1p595.pdf	
   
         webgraph	
      	
   set	
   of	
   algorithms	
   and	
   a	
   java	
   

implementa*on	
   

         fundamental	
   goal	
      	
   maintain	
   node	
   adjacency	
   

lists	
   in	
   memory	
   
         for	
   this,	
   compressing	
   the	
   adjacency	
   lists	
   is	
   the	
   
cri*cal	
   component	
   

introduc)on	
   to	
   informa)on	
   retrieval	
   

	
   	
   

	
   	
   
sec. 20.4 

adjacency	
   lists	
   
         the	
   set	
   of	
   neighbors	
   of	
   a	
   node	
   
         assume	
   each	
   url	
   represented	
   by	
   an	
   integer	
   
         e.g.,	
   for	
   a	
   4	
   billion	
   page	
   web,	
   need	
   32	
   bits	
   per	
   

node	
   

hyperlink	
   

         naively,	
   this	
   demands	
   64	
   bits	
   to	
   represent	
   each	
   

         boldi/vigna	
   get	
   down	
   to	
   an	
   average	
   of	
   ~3	
   bits/

link	
   
         further	
   work	
   achieves	
   2	
   bits/link	
   

introduc)on	
   to	
   informa)on	
   retrieval	
   

	
   	
   

	
   	
   
sec. 20.4 

adjaceny	
   list	
   compression	
   
         proper*es	
   exploited	
   in	
   compression:	
   

        similarity	
   (between	
   lists)	
   
        locality	
   (many	
   links	
   from	
   a	
   page	
   go	
   to	
   
   nearby   	
   pages)	
   
        use	
   gap	
   encodings	
   in	
   sorted	
   lists	
   
        distribu*on	
   of	
   gap	
   values	
   

introduc)on	
   to	
   informa)on	
   retrieval	
   

	
   	
   

	
   	
   
sec. 20.4 

main	
   ideas	
   of	
   boldi/vigna	
   
         consider	
   lexicographically	
   ordered	
   list	
   of	
   all	
   urls,	
   

e.g.,	
   	
   
         www.stanford.edu/alchemy	
   
         www.stanford.edu/biology	
   
         www.stanford.edu/biology/plant	
   
         www.stanford.edu/biology/plant/copyright	
   
         www.stanford.edu/biology/plant/people	
   
         www.stanford.edu/chemistry	
   

introduc)on	
   to	
   informa)on	
   retrieval	
   

	
   	
   

	
   	
   
sec. 20.4 

boldi/vigna	
   
         each	
   of	
   these	
   urls	
   has	
   an	
   adjacency	
   list	
   
         main	
   idea:	
   due	
   to	
   templates,	
   the	
   adjacency	
   list	
   of	
   a	
   

why 7? 

node	
   is	
   similar	
   to	
   one	
   of	
   the	
   7	
   preceding	
   urls	
   in	
   
the	
   lexicographic	
   ordering	
   

         express	
   adjacency	
   list	
   in	
   terms	
   of	
   one	
   of	
   these	
   
         e.g.,	
   consider	
   these	
   adjacency	
   lists	
   

         1,	
   2,	
   4,	
   8,	
   16,	
   32,	
   64	
   
         1,	
   4,	
   9,	
   16,	
   25,	
   36,	
   49,	
   64	
   
         1,	
   2,	
   3,	
   5,	
   8,	
   13,	
   21,	
   34,	
   55,	
   89,	
   144	
   
         1,	
   4,	
   8,	
   16,	
   25,	
   36,	
   49,	
   64	
   

encode as (-2), remove 9, add 8 

introduc)on	
   to	
   informa)on	
   retrieval	
   

	
   	
   

	
   	
   
sec. 20.4 

gap	
   encodings	
   
         given	
   a	
   sorted	
   list	
   of	
   integers	
   x,	
   y,	
   z,	
      ,	
   
represent	
   by	
   x,	
   y-     x,	
   z-     y,	
      	
   	
   
         compress	
   each	
   integer	
   using	
   a	
   code	
   
            code	
   -     	
   number	
   of	
   bits	
   =	
   1	
   +	
   2	
         lg	
   x       	

           code:	
      	
   
        informa*on	
   theore*c	
   bound:	
   1	
   +	
         lg	
   x       
bits	
   	
   
           code:	
   works	
   well	
   for	
   integers	
   from	
   a	
   
power	
   law	
   boldi	
   vigna	
   dcc	
   2004	
   

introduc)on	
   to	
   informa)on	
   retrieval	
   

	
   	
   

	
   	
   
sec. 20.4 

main	
   advantages	
   of	
   bv	
   
         depends	
   only	
   on	
   locality	
   in	
   a	
   canonical	
   ordering	
   
         adjacency	
   queries	
   can	
   be	
   answered	
   very	
   

         lexicographic	
   ordering	
   works	
   well	
   for	
   the	
   web	
   

e   ciently	
   
         to	
   fetch	
   out-     neighbors,	
   trace	
   back	
   the	
   chain	
   of	
   
prototypes	
   
         this	
   chain	
   is	
   typically	
   short	
   in	
   prac*ce	
   (since	
   similarity	
   
is	
   mostly	
   intra-     host)	
   
         can	
   also	
   explicitly	
   limit	
   the	
   length	
   of	
   the	
   chain	
   during	
   
encoding	
   

         easy	
   to	
   implement	
   one-     pass	
   algorithm	
   

introduc)on	
   to	
   informa)on	
   retrieval	
   

	
   	
   

	
   	
   

link	
   analysis:	
   id95	
   

26	
   

introduc)on	
   to	
   informa)on	
   retrieval	
   

	
   	
   

	
   	
   

cita*on	
   analysis	
   
         cita*on	
   frequency	
   
         bibliographic	
   coupling	
   frequency	
   

         ar*cles	
   that	
   co-     cite	
   the	
   same	
   ar*cles	
   are	
   related	
   	
   

         cita*on	
   indexing	
   

         who	
   is	
   this	
   author	
   cited	
   by?	
   (gar   eld	
   1972)	
   
         id95	
   preview:	
   pinsker	
   and	
   narin	
      60s	
   

         asked:	
   which	
   journals	
   are	
   authorita*ve?	
   

introduc)on	
   to	
   informa)on	
   retrieval	
   

	
   	
   

	
   	
   

the	
   web	
   isn   t	
   scholarly	
   cita*on	
   
         millions	
   of	
   par*cipants,	
   each	
   with	
   self	
   interests	
   
         spamming	
   is	
   widespread	
   
         once	
   search	
   engines	
   began	
   to	
   use	
   links	
   for	
   ranking	
   

(roughly	
   1998),	
   link	
   spam	
   grew	
   
         you	
   can	
   join	
   a	
   link	
   farm	
      	
   a	
   group	
   of	
   websites	
   that	
   heavily	
   

link	
   to	
   one	
   another	
   

28	
   

introduc)on	
   to	
   informa)on	
   retrieval	
   

	
   	
   

	
   	
   
sec. 21.2 

id95	
   scoring	
   
         imagine	
   a	
   user	
   doing	
   a	
   random	
   walk	
   on	
   web	
   pages:	
   

         start	
   at	
   a	
   random	
   page	
   
         at	
   each	
   step,	
   go	
   out	
   of	
   the	
   	
   
current	
   page	
   along	
   one	
   of	
   	
   
the	
   links	
   on	
   that	
   page,	
   equiprobably	
   

1/3 
1/3 
1/3 

            in	
   the	
   long	
   run   	
   each	
   page	
   has	
   a	
   long-     term	
   visit	
   rate	
   

-     	
   use	
   this	
   as	
   the	
   page   s	
   score.	
   

	
   

introduc)on	
   to	
   informa)on	
   retrieval	
   

	
   	
   

	
   	
   
sec. 21.2 

not	
   quite	
   enough	
   
         the	
   web	
   is	
   full	
   of	
   dead-     ends.	
   

         random	
   walk	
   can	
   get	
   stuck	
   in	
   dead-     ends.	
   
         makes	
   no	
   sense	
   to	
   talk	
   about	
   long-     term	
   visit	
   rates.	
   

?? 

introduc)on	
   to	
   informa)on	
   retrieval	
   

	
   	
   

	
   	
   
sec. 21.2 

telepor*ng	
   
         at	
   a	
   dead	
   end,	
   jump	
   to	
   a	
   random	
   web	
   page.	
   
         at	
   any	
   non-     dead	
   end,	
   with	
   id203	
   10%,	
   
jump	
   to	
   a	
   random	
   web	
   page.	
   
        with	
   remaining	
   id203	
   (90%),	
   go	
   out	
   on	
   
a	
   random	
   link.	
   
        10%	
   -     	
   a	
   parameter.	
   

introduc)on	
   to	
   informa)on	
   retrieval	
   

	
   	
   

	
   	
   
sec. 21.2 

result	
   of	
   telepor*ng	
   
        now	
   cannot	
   get	
   stuck	
   locally.	
   
        there	
   is	
   a	
   long-     term	
   rate	
   at	
   which	
   any	
   
page	
   is	
   visited	
   (not	
   obvious,	
   will	
   show	
   
this).	
   
        how	
   do	
   we	
   compute	
   this	
   visit	
   rate?	
   

introduc)on	
   to	
   informa)on	
   retrieval	
   

	
   	
   

	
   	
   
sec. 21.2.1 

markov	
   chains	
   
         a	
   markov	
   chain	
   consists	
   of	
   n	
   states,	
   plus	
   an	
   n  n	
   

transi*on	
   id203	
   matrix	
   p.	
   

         at	
   each	
   step,	
   we	
   are	
   in	
   one	
   of	
   the	
   states.	
   
         for	
   1	
      	
   i,j	
      	
   n,	
   the	
   matrix	
   entry	
   pij	
   tells	
   us	
   the	
   

id203	
   of	
   j	
   being	
   the	
   next	
   state,	
   given	
   we	
   are	
   
currently	
   in	
   state	
   i.	
   	
   

pii>0 
is ok. 

i 

pij 

j 

introduc)on	
   to	
   informa)on	
   retrieval	
   

	
   	
   

	
   	
   
sec. 21.2.1 

n

markov	
   chains	
   
         clearly,	
   for	
   all	
   i,	
   
         	
   markov	
   chains	
   are	
   abstrac*ons	
   of	
   random	
   walks.	
   
         exercise:	
   represent	
   the	
   telepor*ng	
   random	
   walk	
   
from	
   3	
   slides	
   ago	
   as	
   a	
   markov	
   chain,	
   for	
   this	
   case:	
   	
   

=   

p
ij

.1

1
=

j

introduc)on	
   to	
   informa)on	
   retrieval	
   

	
   	
   

	
   	
   
sec. 21.2.1 

ergodic	
   markov	
   chains	
   
         for	
   any	
   ergodic	
   markov	
   chain,	
   there	
   is	
   a	
   
unique	
   long-     term	
   visit	
   rate	
   for	
   each	
   state.	
   
        steady-     state	
   id203	
   distribu)on.	
   

         over	
   a	
   long	
   *me-     period,	
   we	
   visit	
   each	
   state	
   
in	
   propor*on	
   to	
   this	
   rate.	
   
         it	
   doesn   t	
   mazer	
   where	
   we	
   start.	
   

introduc)on	
   to	
   informa)on	
   retrieval	
   

	
   	
   

	
   	
   
sec. 21.2.1 

id203	
   vectors	
   
         a	
   id203	
   (row)	
   vector	
   x	
   =	
   (x1,	
      	
   xn)	
   tells	
   us	
   
where	
   the	
   walk	
   is	
   at	
   any	
   point.	
   
         e.g.,	
   (000   1   000)	
   means	
   we   re	
   in	
   state	
   i.	
   

1 

i 

n 

more generally, the vector x = (x1,     xn) 
means the walk is in state i with id203 xi.  

n

=   

ix

i

1
=

.1

introduc)on	
   to	
   informa)on	
   retrieval	
   

	
   	
   

	
   	
   
sec. 21.2.1 

change	
   in	
   id203	
   vector	
   
         if	
   the	
   id203	
   vector	
   is	
   	
   x	
   =	
   (x1,	
      	
   xn)	
   at	
   
this	
   step,	
   what	
   is	
   it	
   at	
   the	
   next	
   step?	
   
         recall	
   that	
   row	
   i	
   of	
   the	
   transi*on	
   prob.	
   
matrix	
   p	
   tells	
   us	
   where	
   we	
   go	
   next	
   from	
   
state	
   i.	
   
         so	
   from	
   x,	
   our	
   next	
   state	
   is	
   distributed	
   as	
   xp	
   

         the	
   one	
   aser	
   that	
   is	
   xp2,	
   then	
   xp3,	
   etc.	
   
         (where)	
   does	
   this	
   converge?	
   

introduc)on	
   to	
   informa)on	
   retrieval	
   

	
   	
   

	
   	
   
sec. 21.2.2 

how	
   do	
   we	
   compute	
   this	
   vector?	
   
         let	
   a	
   =	
   (a1,	
      	
   an)	
   denote	
   the	
   row	
   vector	
   of	
   steady-     
         if	
   our	
   current	
   posi*on	
   is	
   described	
   by	
   a,	
   then	
   the	
   

state	
   probabili*es.	
   

next	
   step	
   is	
   distributed	
   as	
   ap.	
   

         but	
   a	
   is	
   the	
   steady	
   state,	
   so	
   a=ap.	
   
         solving	
   this	
   matrix	
   equa*on	
   gives	
   us	
   a.	
   

         so	
   a	
   is	
   the	
   (les)	
   eigenvector	
   for	
   p.	
   
         (corresponds	
   to	
   the	
      principal   	
   eigenvector	
   of	
   p	
   with	
   the	
   

largest	
   eigenvalue.)	
   

         transi*on	
   id203	
   matrices	
   always	
   have	
   largest	
   

eigenvalue	
   1.	
   

introduc)on	
   to	
   informa)on	
   retrieval	
   

	
   	
   

	
   	
   

link	
   analysis:	
   hits	
   

39	
   

introduc)on	
   to	
   informa)on	
   retrieval	
   

	
   	
   

	
   	
   
sec. 21.3 

hyperlink-     induced	
   topic	
   search	
   (hits)	
   
         in	
   response	
   to	
   a	
   query,	
   instead	
   of	
   an	
   ordered	
   list	
   of	
   
pages	
   each	
   mee*ng	
   the	
   query,	
      nd	
   two	
   sets	
   of	
   inter-     
related	
   pages:	
   
         hub	
   pages	
   are	
   good	
   lists	
   of	
   links	
   on	
   a	
   subject.	
   

         e.g.,	
      bob   s	
   list	
   of	
   cancer-     related	
   links.   	
   

         authority	
   pages	
   occur	
   recurrently	
   on	
   good	
   hubs	
   for	
   the	
   

subject.	
   

         best	
   suited	
   for	
      broad	
   topic   	
   queries	
   rather	
   than	
   for	
   

page-        nding	
   queries.	
   

         gets	
   at	
   a	
   broader	
   slice	
   of	
   common	
   opinion.	
   

introduc)on	
   to	
   informa)on	
   retrieval	
   

	
   	
   

	
   	
   
sec. 21.3 

hubs	
   and	
   authori*es	
   
         thus,	
   a	
   good	
   hub	
   page	
   for	
   a	
   topic	
   points	
   to	
   
many	
   authorita*ve	
   pages	
   for	
   that	
   topic.	
   
         a	
   good	
   authority	
   page	
   for	
   a	
   topic	
   is	
   pointed	
   
to	
   by	
   many	
   good	
   hubs	
   for	
   that	
   topic.	
   
         circular	
   de   ni*on	
   -     	
   will	
   turn	
   this	
   into	
   an	
   
itera*ve	
   computa*on.	
   

introduc)on	
   to	
   informa)on	
   retrieval	
   

	
   	
   

	
   	
   
sec. 21.3 

the	
   hope	
   

hubs 

                                                    at&t        
 alice                     
 
                                  itim  
bob 
                                  o2 

authorities 

mobile telecom companies 

introduc)on	
   to	
   informa)on	
   retrieval	
   

	
   	
   

	
   	
   
sec. 21.3 

high-     level	
   scheme	
   
        extract	
   from	
   the	
   web	
   a	
   base	
   set	
   of	
   
pages	
   that	
   could	
   be	
   good	
   hubs	
   or	
   
authori*es.	
   
        from	
   these,	
   iden*fy	
   a	
   small	
   set	
   of	
   top	
   
hub	
   and	
   authority	
   pages;	
   
      itera*ve	
   algorithm.	
   

introduc)on	
   to	
   informa)on	
   retrieval	
   

	
   	
   

	
   	
   
sec. 21.3 

base	
   set	
   
         given	
   text	
   query	
   (say	
   browser),	
   use	
   a	
   text	
   
index	
   to	
   get	
   all	
   pages	
   containing	
   browser.	
   
        call	
   this	
   the	
   root	
   set	
   of	
   pages.	
   	
   

         add	
   in	
   any	
   page	
   that	
   either	
   

        points	
   to	
   a	
   page	
   in	
   the	
   root	
   set,	
   or	
   
        is	
   pointed	
   to	
   by	
   a	
   page	
   in	
   the	
   root	
   set.	
   

         call	
   this	
   the	
   base	
   set.	
   

introduc)on	
   to	
   informa)on	
   retrieval	
   

	
   	
   

	
   	
   
sec. 21.3 

visualiza*on	
   

root 
set 

base set 

get in-links (and out-links) from a connectivity server  

introduc)on	
   to	
   informa)on	
   retrieval	
   

	
   	
   

	
   	
   
sec. 21.3 

dis*lling	
   hubs	
   and	
   authori*es	
   
         compute,	
   for	
   each	
   page	
   x	
   in	
   the	
   base	
   set,	
   a	
   hub	
   

score	
   h(x)	
   and	
   an	
   authority	
   score	
   a(x).	
   

         ini*alize:	
   for	
   all	
   x,	
   h(x)   1;	
   a(x)	
      1;	
   
         itera*vely	
   update	
   all	
   h(x),	
   a(x);	
   
key 
         aser	
   itera*ons	
   

         output	
   pages	
   with	
   highest	
   h()	
   scores	
   as	
   top	
   hubs	
   
         	
   highest	
   a()	
   scores	
   as	
   top	
   authori*es.	
   

introduc)on	
   to	
   informa)on	
   retrieval	
   

	
   	
   

	
   	
   
sec. 21.3 

itera*ve	
   update	
   
         repeat	
   the	
   following	
   updates,	
   for	
   all	
   x:	
   

xh
)(

xa
)(

      

x

!

y

      

y

!

x

ya
)(

yh
)(

x 

x 

introduc)on	
   to	
   informa)on	
   retrieval	
   

	
   	
   

	
   	
   
sec. 21.3 

scaling	
   
         to	
   prevent	
   the	
   h()	
   and	
   a()	
   values	
   from	
   
gekng	
   too	
   big,	
   can	
   scale	
   down	
   aser	
   each	
   
itera*on.	
   
         scaling	
   factor	
   doesn   t	
   really	
   mazer:	
   

        we	
   only	
   care	
   about	
   the	
   rela)ve	
   values	
   of	
   
the	
   scores.	
   

introduc)on	
   to	
   informa)on	
   retrieval	
   

	
   	
   

	
   	
   
sec. 21.3 

how	
   many	
   itera*ons?	
   
         claim:	
   rela*ve	
   values	
   of	
   scores	
   will	
   converge	
   

aser	
   a	
   few	
   itera*ons:	
   
         in	
   fact,	
   suitably	
   scaled,	
   h()	
   and	
   a()	
   scores	
   sezle	
   
into	
   a	
   steady	
   state!	
   
         proof	
   of	
   this	
   comes	
   later.	
   

         in	
   prac*ce,	
   ~5	
   itera*ons	
   get	
   you	
   close	
   to	
   stability.	
   

introduc)on	
   to	
   informa)on	
   retrieval	
   

	
   	
   

	
   	
   
sec. 21.3 

proof	
   of	
   convergence	
   

         n  n	
   adjacency	
   matrix	
   a:	
   

         each	
   of	
   the	
   n	
   pages	
   in	
   the	
   base	
   set	
   has	
   a	
   row	
   and	
   

column	
   in	
   the	
   matrix.	
   

         entry	
   aij	
   =	
   1	
   if	
   page	
   i	
   links	
   to	
   page	
   j,	
   else	
   =	
   0.	
   

1 

2 

3 

 1      2      3 
 0      1      0 
 1      1      1 
 1      0      0 

1

 

2
 
3

introduc)on	
   to	
   informa)on	
   retrieval	
   

	
   	
   

	
   	
   
sec. 21.3 

hub/authority	
   vectors	
   
         view	
   the	
   hub	
   scores	
   h()	
   and	
   the	
   authority	
   scores	
   a()	
   

as	
   vectors	
   with	
   n	
   components.	
   

         recall	
   the	
   itera*ve	
   updates	
   

xh
)(

xa
)(

ya
)(

yh
)(

      

x

!

y

      

y

!

x

introduc)on	
   to	
   informa)on	
   retrieval	
   

	
   	
   

	
   	
   
sec. 21.3 

rewrite	
   in	
   matrix	
   form	
   
         h=aa.	
   
         a=ath.	
   

recall at 

is the 

transpose 

of a.  

substituting, h=aath and a=ataa. 

thus, h is an eigenvector of aat and a is an 
eigenvector of ata. 
further, our algorithm is a particular, known algorithm for 
computing eigenvectors: the power iteration method. 

guaranteed to converge. 

introduc)on	
   to	
   informa)on	
   retrieval	
   

	
   	
   

	
   	
   
sec. 21.3 

issues	
   
         topic	
   dris	
   

         o   -     topic	
   pages	
   can	
   cause	
   o   -     topic	
      authori*es   	
   
to	
   be	
   returned	
   
         e.g.,	
   the	
   neighborhood	
   graph	
   can	
   be	
   about	
   a	
      super	
   
topic   	
   

         mutually	
   reinforcing	
   a   liates	
   

         	
   a   liated	
   pages/sites	
   can	
   boost	
   each	
   others   	
   
scores	
   	
   
         linkage	
   between	
   a   liated	
   pages	
   is	
   not	
   a	
   useful	
   signal	
   

introduc)on	
   to	
   informa)on	
   retrieval	
   

	
   	
   

	
   	
   

resources	
   
         iir	
   chap	
   21	
   
         hzp://www2004.org/proceedings/docs/1p309.pdf	
   
         hzp://www2004.org/proceedings/docs/1p595.pdf	
   
         hzp://www2003.org/cdrom/papers/refereed/p270/

kamvar-     270-     xhtml/index.html	
   

         hzp://www2003.org/cdrom/papers/refereed/p641/

xhtml/p641-     mccurley.html	
   

         the	
   webgraph	
   framework	
   i:	
   compression	
   

techniques	
   (boldi	
   et	
   al.	
   2004)	
   

