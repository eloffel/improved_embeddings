ir
information retrieval
query modification and relevance feedback
query modification
also known as query reformulation, query substitution    
problem: initial query may not be the most appropriate to satisfy a given information need
idea: modify the original query so that it gets closer to the right documents in the vector space

types of query modification
morphological:
spelling check
semantic:
id183
query substitution
query suggestion




original query
id183
query substitution
spelling error correction
query suggestion
spelling error correction
roughly 10-15% of the queries sent to search engines contain errors. (cucerzan and brill 2004)
traditional techniques rely on dictionary match, combined with
common keyboard mistakes
phonetic mistakes
context mistakes
cognitive mistakes
modern techniques rely on query log analysis + string similarity
query reformulation     id147
query recommendation/suggestion
recommend alternative queries to the user. alternative queries could be totally different from the original query. 
usually done with query log analysis
id183
refining the information need of search by adding new terms to query
sometimes also remove terms    
traditional methods: 
thesaurus-based expansion
ontology based expansion
hyponyms and hypernyms
corpus-based methods
mining related terms from large scale corpus
feedback: most effective method in ir
query log based methods (later)

id183
id183
corpus-based: mine query logs
nlp-based
vector-space relevance feedback
relevance feedback
problem: initial query may not be the most appropriate to satisfy a given information need.
idea: modify the original query so that it gets closer to the right documents in the vector space
intuition in feedback
id183: feedback can help discover related query terms
query =    information retrieval    
relevant or pseudo-relevant docs may would likely share words related to    information retrieval   , e.g.,    search engine   ,    search   ,    user   ,    query   , etc. 
these words generally have higher frequency in these relevant or pseudo-relevant documents than in the whole collection
they can be used to expand the original query to increase recall and sometimes also precision
a machine learning interpretation
machine learning/pattern recognition
query = a special labeled example
relevant documents = labeled examples (supervised learning)
pseudo-relevant documents = unlabeled examples  (semi-supervised learning) 

overview of feedback techniques 
feedback as machine learning: many possibilities
standard ml: given examples of relevant (and non-relevant) documents, learn how to classify a new document  as either    relevant    or    non-relevant   .
   modified    ml: given a query and examples of relevant (and non-relevant) documents, learn how to rank new documents based on relevance
challenges: 
sparse data 
censored sample
how to deal with query? 
modeling noise in pseudo feedback (as semi-supervised learning)
overview of feedback techniques (cont.) 
feedback as id183: traditional ir 
step 1: term selection
step 2: id183
step 3: query term re-weighting
traditional ir is still robust (rocchio), but ml approaches can potentially be more accurate 
relevance feedback in the vector space model
basic setting: learn from examples
positive examples: docs known to be relevant
negative examples: docs known to be non-relevant
how do you learn from this to improve performance?
general method: query modification
adding new (weighted) terms
adjusting weights of old terms
doing both
the most well-known and effective approach is rocchio [rocchio 1971]


+
rocchio feedback: illustration

q

+
+
+
+
+
+
+
+
+
+
+
+
+
+
+
-
-
-
-
-
-
-
-
-
-
-
-
-
-
-
-
-
-
-
-
-
-
-
-
-
-
-
+
+
+

rocchio feedback: intuition
query is represented as a vector (vsm)
query can be updated by adding document vectors to query vectors
if a document is labeled as relevant     add it to the query vector
if a document is labeled as irrelevant     subtract it from the query vector
weighting needed. 
rocchio feedback: formula
original query 
vector

relevant docs

non-rel docs

parameters



new query vector

relevance feedback
automatic
manual

method: identifying feedback terms
q    = a1q + a2r - a3n
often a1 = 1, a2 = 1/|r| and a3 = 1/|n|
example
q =    safety minivans   
d1 =    car safety minivans tests injury statistics    - relevant
d2 =    liability tests safety    - relevant
d3 =    car passengers injury reviews    - non-relevant
r = ?
n = ?
q    = ?
rocchio in practice
negative (non-relevant) examples are not very important (why?)
often project the vector onto a lower dimension (i.e., consider only a small number of words that have high weights in the centroid vector) (efficiency concern)
avoid    training bias    (keep relatively high weight on the original query weights) (why?)
can be used for relevance feedback and pseudo feedback
usually robust and effective
pseudo relevance feedback
automatic id183
thesaurus-based expansion (e.g., using id45     later   )
distributional similarity
query log mining
examples
book: publication, product, fact, dramatic composition, record 
computer: machine, expert, calculator, reckoner, figurer 
fruit: reproductive structure, consequence, product
politician: leader, schemer 
newspaper: press, publisher, product, paper, newsprint 
distributional id91:
lexical semantics (hypernymy):
book: autobiography, essay, biography, memoirs, novels
computer: adobe, computing, computers, developed, hardware
fruit: leafy, canned, fruits, flowers, grapes
politician: activist, campaigner, politicians, intellectuals, journalist
newspaper:  daily, globe, newspapers, newsday, paper
examples (query logs)
book: booksellers bookmark blue
computer: sales notebook stores shop
fruit: recipes cake salad basket company
games: online play gameboy free video
politician: careers federal office history
newspaper: online website college information
schools: elementary high ranked yearbook
california: berkeley san francisco southern
french: embassy dictionary learn
[otterbacher et al. hlt emnlp 2005]
ir
