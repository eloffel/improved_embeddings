introduction to information retrieval
introduction to information retrieval

introduction to
information retrieval

cs276: information retrieval and web search

pandu nayak and prabhakar raghavan

lecture 3: dictionaries and tolerant retrieval

introduction to information retrieval
introduction to information retrieval

ch. 2

recap of the previous lecture

  the type/token distinction

  terms are normalized types put in the dictionary

  id121 problems:

  hyphens, apostrophes, compounds, cjk

  term equivalence classing:

  numbers, case folding, id30, lemmatization

  skip pointers

  encoding a tree-like structure in a postings list

  biword indexes for phrases

  positional indexes for phrases/proximity queries

2

introduction to information retrieval
introduction to information retrieval

ch. 3

this lecture

  dictionary data structures

     tolerant    retrieval

  wild-card queries

  id147

  soundex

3

introduction to information retrieval
introduction to information retrieval

sec. 3.1

dictionary data structures for inverted 
indexes

  the dictionary data structure stores the term 

vocabulary, document frequency, pointers to each 
postings list     in what data structure?

4

introduction to information retrieval
introduction to information retrieval

sec. 3.1

a na  ve dictionary

  an array of struct:

char[20]   int                   postings *

20 bytes   4/8 bytes        4/8 bytes  

  how do we store a dictionary in memory efficiently?

  how do we quickly look up elements at query time?

5

introduction to information retrieval
introduction to information retrieval

sec. 3.1

dictionary data structures

  two main choices:

  hashtables

  trees

  some ir systems use hashtables, some trees

6

introduction to information retrieval
introduction to information retrieval

sec. 3.1

hashtables

  each vocabulary term is hashed to an integer

  (we assume you   ve seen hashtables before)

  pros:

  lookup is faster than for a tree: o(1)

  cons:

  no easy way to find minor variants:

  judgment/judgement

  no prefix search

[tolerant  retrieval]

  if vocabulary keeps growing, need to occasionally do the 

expensive operation of rehashing everything

7

introduction to information retrieval
introduction to information retrieval

sec. 3.1

tree: binary tree

root

a-m

n-z

a-hu

hy-m

n-sh

si-z

8

introduction to information retrieval
introduction to information retrieval

sec. 3.1

tree: b-tree

a-hu

hy-m

n-z

  definition: every internal nodel has a number of children 

in the interval [a,b] where a, b are appropriate natural 
numbers, e.g., [2,4].

9

introduction to information retrieval
introduction to information retrieval

sec. 3.1

trees

  simplest: binary tree

  more usual: b-trees

  trees require a standard ordering of characters and hence 

strings     but we typically have one

  pros:

  solves the prefix problem (terms starting with hyp)

  cons:

  slower: o(log m)  [and this requires balanced tree]

  rebalancing binary trees is expensive

  but b-trees mitigate the rebalancing problem

10

introduction to information retrieval
introduction to information retrieval

wild-card queries

11

introduction to information retrieval
introduction to information retrieval

sec. 3.2

wild-card queries: *

  mon*: find all docs containing any word beginning 

with    mon   .

  easy with binary tree (or b-tree) lexicon: retrieve all 

words in range: mon     w < moo

  *mon: find words ending in    mon   : harder

  maintain an additional b-tree for terms backwards.

can retrieve all words in range: nom     w < non.

exercise: from this, how can we enumerate all terms
meeting the wild-card query pro*cent ?

12

introduction to information retrieval
introduction to information retrieval

sec. 3.2

query processing

  at this point, we have an enumeration of all terms in 

the dictionary that match the wild-card query.

  we still have to look up the postings for each 

enumerated term.

  e.g., consider the query:

se*ate and fil*er

this may result in the execution of many boolean 
and queries.

13

introduction to information retrieval
introduction to information retrieval

b-trees handle *   s at the end of a 
query term

sec. 3.2

  how can we handle *   s in the middle of query term?

  co*tion

  we could look up co* and *tion in a b-tree and 

intersect the two term sets
  expensive

  the solution: transform wild-card queries so that the 

*   s occur at the end

  this gives rise to the permuterm index.

14

introduction to information retrieval
introduction to information retrieval

sec. 3.2.1

permuterm index

  for term hello, index under:

  hello$, ello$h, llo$he, lo$hel, o$hell, $hello

where $ is a special symbol.

  queries:

  x lookup on x$

x*   lookup on   $x*

  *x   lookup on x$*

*x* lookup on   x*

  x*y lookup on y$x*

x*y*z

??? exercise!

query = hel*o

x=hel, y=o

lookup o$hel*

15

introduction to information retrieval
introduction to information retrieval

sec. 3.2.1

permuterm query processing

  rotate query wild-card to the right

  now use b-tree lookup as before.

  permuterm problem:     quadruples lexicon size

empirical observation for english.

16

introduction to information retrieval
introduction to information retrieval

sec. 3.2.2

bigram (k-gram) indexes

  enumerate all k-grams (sequence of k chars) 

occurring in any term

  e.g., from text    april is the cruelest month    we get 

the 2-grams (bigrams)

$a,ap,pr,ri,il,l$,$i,is,s$,$t,th,he,e$,$c,cr,ru,
ue,el,le,es,st,t$, $m,mo,on,nt,h$

  $ is a special word boundary symbol

  maintain a second inverted index from bigrams to

dictionary terms that match each bigram.

17

introduction to information retrieval
introduction to information retrieval

sec. 3.2.2

bigram index example

  the k-gram index finds terms based on a query 

consisting of k-grams (here k=2).

$m

mo

on

mace

madden

among

amortize

along

among

18

introduction to information retrieval
introduction to information retrieval

sec. 3.2.2

processing wild-cards

  query mon* can now be run as

  $m and mo and on

  gets terms that match and version of our wildcard 

query.

  but we   d enumerate moon.

  must post-filter these terms against query.

  surviving enumerated terms are then looked up in 

the term-document inverted index.

  fast, space efficient (compared to permuterm).

19

introduction to information retrieval
introduction to information retrieval

sec. 3.2.2

processing wild-card queries

  as before, we must execute a boolean query for each 

enumerated, filtered term.

  wild-cards can result in expensive query execution 

(very large disjunctions   )
  pyth* and prog*

  if you encourage    laziness    people will respond!

type your search terms, use    *    if you need to.
e.g., alex* will match alexander.

search

  which web search engines allow wildcard queries?

20

introduction to information retrieval
introduction to information retrieval

id147

21

introduction to information retrieval
introduction to information retrieval

sec. 3.3

spell correction

  two principal uses

  correcting document(s) being indexed

  correcting user queries to retrieve    right    answers

  two main flavors:

  isolated word

  check each word on its own for misspelling

  will not catch typos resulting in correctly spelled words

  e.g., from             form

  context-sensitive

  look at surrounding words, 

  e.g., i flew form heathrow to narita.

22

introduction to information retrieval
introduction to information retrieval

sec. 3.3

document correction

  especially needed for ocr   ed documents

  correction algorithms are tuned for this: rn/m

  can use domain-specific knowledge

  e.g., ocr can confuse o and d more often than it would confuse o 

and i (adjacent on the qwerty keyboard, so more likely 
interchanged in typing).

  but also: web pages and even printed material have 

typos

  goal: the dictionary contains fewer misspellings

  but often we don   t change the documents and 

instead fix the query-document mapping

23

introduction to information retrieval
introduction to information retrieval

sec. 3.3

query mis-spellings

  our principal focus here

  e.g., the query alanis morisett

  we can either

  retrieve documents indexed by the correct spelling, or

  return several suggested alternative queries with the 

correct spelling

  did you mean     ?

24

introduction to information retrieval
introduction to information retrieval

sec. 3.3.2

isolated word correction

  fundamental premise     there is a lexicon from which 

the correct spellings come

  two basic choices for this
  a standard lexicon such as
  webster   s english dictionary

  an    industry-specific    lexicon     hand-maintained

  the lexicon of the indexed corpus

  e.g., all words on the web

  all names, acronyms etc.

  (including the mis-spellings)

25

introduction to information retrieval
introduction to information retrieval

sec. 3.3.2

isolated word correction

  given a lexicon and a character sequence q, return 

the words in the lexicon closest to q

  what   s    closest   ?

  we   ll study several alternatives

  id153 (levenshtein distance)

  weighted id153

  id165 overlap

26

introduction to information retrieval
introduction to information retrieval

sec. 3.3.3

id153

  given two strings s1 and s2, the minimum number of 

operations to convert one to the other

  operations are typically character-level

  insert, delete, replace, (transposition)

  e.g., the id153 from dof to dog is 1
  from cat to act is 2 (just 1 with transpose.)

  from cat to dog is 3.

  generally found by id145.

  see http://www.merriampark.com/ld.htm for a nice 

example plus an applet.

27

introduction to information retrieval
introduction to information retrieval

sec. 3.3.3

weighted id153

  as above, but the weight of an operation depends on 

the character(s) involved
  meant to capture ocr or keyboard errors

example: m more likely to be mis-typed as n than as q

  therefore, replacing m by n is a smaller id153 than 

by q

  this may be formulated as a id203 model

  requires weight matrix as input

  modify id145 to handle weights

28

introduction to information retrieval
introduction to information retrieval

sec. 3.3.4

using id153s

  given query, first enumerate all character sequences 

within a preset (weighted) id153 (e.g., 2)

  intersect this set with list of    correct    words

  show terms you found to user as suggestions

  alternatively, 

  we can look up all possible corrections in our inverted 

index and return all docs     slow

  we can run with a single most likely correction

  the alternatives disempower the user, but save a 

round of interaction with the user

29

introduction to information retrieval
introduction to information retrieval

sec. 3.3.4

id153 to all dictionary terms?

  given a (mis-spelled) query     do we compute its edit 

distance to every dictionary term?
  expensive and slow

  alternative?

  how do we cut the set of candidate dictionary 

terms?

  one possibility is to use id165 overlap for this

  this can also be used by itself for id147.

30

introduction to information retrieval
introduction to information retrieval

sec. 3.3.4

id165 overlap

  enumerate all the id165s in the query string as well 

as in the lexicon

  use the id165 index (recall wild-card search) to 

retrieve all lexicon terms matching any of the query 
id165s

  threshold by number of matching id165s

  variants     weight by keyboard layout, etc.

31

introduction to information retrieval
introduction to information retrieval

sec. 3.3.4

example with trigrams

  suppose the text is november

  trigrams are nov, ove, vem, emb, mbe, ber.

  the query is december

  trigrams are dec, ece, cem, emb, mbe, ber.

  so 3 trigrams overlap (of 6 in each term)

  how can we turn this into a normalized measure of 

overlap?

32

introduction to information retrieval
introduction to information retrieval

sec. 3.3.4

one option     jaccard coefficient

  a commonly-used measure of overlap

  let x and y be two sets; then the j.c. is

yxyx

    /

   

  equals 1 when x and y have the same elements and 

zero when they are disjoint

  x and y don   t have to be of the same size

  always assigns a number between 0 and 1
  now threshold to decide if you have a match

  e.g., if j.c. > 0.8, declare a match 

33

introduction to information retrieval
introduction to information retrieval

sec. 3.3.4

matching trigrams

  consider the query lord     we wish to identify words 

matching 2 of its 3 bigrams (lo, or, rd)

lo

or

rd

alone

lore

sloth

border

lore

morbid

ardent

border card

standard postings    merge    will enumerate     

adapt this to using jaccard (or another) measure.

34

introduction to information retrieval
introduction to information retrieval

sec. 3.3.5

context-sensitive spell correction

  text: i flew from heathrow to narita.

  consider the phrase query    flew form heathrow   

  we   d like to respond

did you mean    flew from heathrow   ?

because no docs matched the query phrase.

35

introduction to information retrieval
introduction to information retrieval

sec. 3.3.5

context-sensitive correction

  need surrounding context to catch this.
  first idea: retrieve dictionary terms close (in 

weighted id153) to each query term

  now try all possible resulting phrases with one word 

   fixed    at a time
  flew from heathrow 
  fled form heathrow
  flea form heathrow

  hit-based id147: suggest the 

alternative that has lots of hits.

36

introduction to information retrieval
introduction to information retrieval

sec. 3.3.5

exercise

  suppose that for    flew form heathrow     we have 7 
alternatives for flew, 19 for form and 3 for heathrow.

how many    corrected    phrases will we enumerate in 

this scheme?

37

introduction to information retrieval
introduction to information retrieval

sec. 3.3.5

another approach

  break phrase query into a conjunction of biwords 

(lecture 2).

  look for biwords that need only one term corrected.

  enumerate only phrases containing    common    

biwords.

38

introduction to information retrieval
introduction to information retrieval

sec. 3.3.5

general issues in spell correction

  we enumerate multiple alternatives for    did you 

mean?   

  need to figure out which to present to the user

  the alternative hitting most docs

  query log analysis

  more generally, rank alternatives probabilistically

argmaxcorr p(corr | query)

  from bayes rule, this is equivalent to

argmaxcorr p(query | corr) * p(corr)

noisy channel

language model

39

introduction to information retrieval
introduction to information retrieval

soundex

40

introduction to information retrieval
introduction to information retrieval

sec. 3.4

soundex

  class of heuristics to expand a query into phonetic

equivalents
  language specific     mainly for names

  e.g., chebyshev     tchebycheff

  invented for the u.s. census     in 1918

41

introduction to information retrieval
introduction to information retrieval

sec. 3.4

soundex     typical algorithm

  turn every token to be indexed into a 4-character 

reduced form

  do the same with query terms

  build and search an index on the reduced forms

  (when the query calls for a soundex match)

 

http://www.creativyst.com/doc/articles/soundex1/soundex1.htm#top

42

introduction to information retrieval
introduction to information retrieval

sec. 3.4

soundex     typical algorithm

1. retain the first letter of the word. 
2. change all occurrences of the following letters to '0' 

(zero):
'a', e', 'i', 'o', 'u', 'h', 'w', 'y'. 

3. change letters to digits as follows: 
  b, f, p, v     1
  c, g, j, k, q, s, x, z     2
  d,t     3
 

l     4

  m, n     5
  r     6

43

introduction to information retrieval
introduction to information retrieval

sec. 3.4

soundex continued

4. remove all pairs of consecutive digits.

5. remove all zeros from the resulting string.

6. pad the resulting string with trailing zeros and 

return the first four positions, which will be of the 
form <uppercase letter> <digit> <digit> <digit>. 

e.g., herman becomes h655.

will hermann generate the same code?

44

introduction to information retrieval
introduction to information retrieval

sec. 3.4

soundex

  soundex is the classic algorithm, provided by most 

databases (oracle, microsoft,    )

  how useful is soundex?

  not very     for information retrieval

  okay for    high recall    tasks (e.g., interpol), though 

biased to names of certain nationalities

  zobel and dart (1996) show that other algorithms for 

phonetic matching perform much better in the 
context of ir

45

introduction to information retrieval
introduction to information retrieval

what queries can we process?

  we have

  positional inverted index with skip pointers

  wild-card index

  spell-correction

  soundex

  queries such as

(spell(moriset) /3 toron*to) or soundex(chaikofski)

46

introduction to information retrieval
introduction to information retrieval

exercise

  draw yourself a diagram showing the various indexes 
in a search engine incorporating all the functionality 
we have talked about

  identify some of the key design choices in the index 

pipeline:
  does id30 happen before the soundex index?

  what about id165s?

  given a query, how would you parse and dispatch 

sub-queries to the various indexes?

47

introduction to information retrieval
introduction to information retrieval

sec. 3.5

resources

  iir 3, mg 4.2

  efficient spell retrieval:

  k. kukich. techniques for automatically correcting words in text. acm 

computing surveys 24(4), dec 1992.

  j. zobel and p. dart. finding approximate matches in large 

lexicons. software - practice and experience 25(3), march 1995. 
http://citeseer.ist.psu.edu/zobel95finding.html

  mikael tillenius: efficient generation and ranking of spelling error 

corrections. master   s thesis at sweden   s royal institute of technology. 
http://citeseer.ist.psu.edu/179155.html

  nice, easy reading on spell correction:

  peter norvig: how to write a spelling corrector 

http://norvig.com/spell-correct.html

48

