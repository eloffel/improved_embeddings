introduction to information retrieval

http://informationretrieval.org

iir 21: link analysis

hinrich sch  utze

center for information and language processing, university of munich

2014-06-18

1 / 80

overview

1 recap

2 anchor text

3 citation analysis

4 id95

5 hits: hubs & authorities

2 / 80

outline

1 recap

2 anchor text

3 citation analysis

4 id95

5 hits: hubs & authorities

3 / 80

applications of id91 in ir

application

search result id91

scatter-gather

collection id91

what is
clustered?
search
results

col-

(subsets
of)
lection
collection

bene   t

example

more e   ective infor-
mation
presentation
to user
alternative user inter-
face:    search without
typing   
e   ective
information
presentation for ex-
ploratory browsing

mckeown et al. 2002,
news.google.com

cluster-based retrieval

collection

higher
faster search

e   ciency:

salton 1971

4 / 80

k -means algorithm

k -means({~x1, . . . , ~xn }, k )

1 (~s1,~s2, . . . ,~sk )     selectrandomseeds({~x1, . . . , ~xn }, k )
2 for k     1 to k
3 do ~  k     ~sk
4 while stopping criterion has not been met
5 do for k     1 to k
6
7
8
9
10
11
12 return {~  1, . . . , ~  k }

do   k     {}
for n     1 to n
do j     arg minj     |~  j         ~xn|

  j       j     {~xn} (reassignment of vectors)

for k     1 to k
do ~  k     1

~x (recomputation of centroids)

|  k | p~x     k

5 / 80

initialization of k -means

random seed selection is just one of many ways k -means can
be initialized.

random seed selection is not very robust: it   s easy to get a
suboptimal id91.
better heuristics:

select seeds not randomly, but using some heuristic (e.g.,    lter
out outliers or    nd a set of seeds that has    good coverage    of
the document space)
use hierarchical id91 to    nd good seeds (next class)
select i (e.g., i = 10) di   erent sets of seeds, do a k -means
id91 for each, select the id91 with lowest rss

6 / 80

take-away today

anchor text: what exactly are links on the web and why are
they important for ir?

citation analysis: the mathematical foundation of id95
and link-based ranking

id95: the original algorithm that was used for link-based
ranking on the web

hubs & authorities: an alternative link-based ranking
algorithm

7 / 80

outline

1 recap

2 anchor text

3 citation analysis

4 id95

5 hits: hubs & authorities

8 / 80

the web as a directed graph

page d1 anchor text

hyperlink

page d2

assumption 1: a hyperlink is a quality signal.

the hyperlink d1     d2 indicates that d1   s author deems d2
high-quality and relevant.

assumption 2: the anchor text describes the content of d2.

we use anchor text somewhat loosely here for: the text
surrounding the hyperlink.
example:    you can    nd cheap cars <a
href=http://...>here</a>.   
anchor text:    you can    nd cheap cars here   

9 / 80

[text of d2] only vs. [text of d2] + [anchor text     d2]

searching on [text of d2] + [anchor text     d2] is often more
e   ective than searching on [text of d2] only.
example: query ibm

matches ibm   s copyright page
matches many spam pages
matches ibm wikipedia article
may not match ibm home page!
. . . if ibm home page is mostly graphics

searching on [anchor text     d2] is better for the query ibm.
in this representation, the page with the most occurrences of
ibm is www.ibm.com.

10 / 80

anchor text containing ibm pointing to www.ibm.com

www.nytimes.com:    ibm acquires webify   

www.slashdot.org:    new ibm optical chip   

www.stanford.edu:    ibm faculty award recipients   

wwww.ibm.com

11 / 80

indexing anchor text

thus: anchor text is often a better description of a page   s
content than the page itself.

anchor text can be weighted more highly than document text.
(based on assumptions 1&2)

12 / 80

exercise: assumptions underlying id95

assumption 1: a link on the web is a quality signal     the
author of the link thinks that the linked-to page is high-quality.

assumption 2: the anchor text describes the content of the
linked-to page.

is assumption 1 true in general?

is assumption 2 true in general?

13 / 80

google bombs

a google bomb is a search with    bad    results due to
maliciously manipulated anchor text.

google introduced a new weighting function in 2007 that    xed
many google bombs.
still some remnants: [dangerous cult] on google, bing, yahoo

coordinated link creation by those who dislike the church of
scientology

defused google bombs: [dumb motherf....], [who is a
failure?], [evil empire]

14 / 80

outline

1 recap

2 anchor text

3 citation analysis

4 id95

5 hits: hubs & authorities

15 / 80

origins of id95: citation analysis (1)

citation analysis: analysis of citations in the scienti   c
literature

example citation:    miller (2001) has shown that physical
activity alters the metabolism of estrogens.   

we can view    miller (2001)    as a hyperlink linking two
scienti   c articles.
one application of these    hyperlinks    in the scienti   c
literature:

measure the similarity of two articles by the overlap of other
articles citing them.
this is called cocitation similarity.
cocitation similarity on the web: google   s    related:    operator,
e.g. [related:www.ford.com]

16 / 80

origins of id95: citation analysis (2)

another application: citation frequency can be used to
measure the impact of a scienti   c article.

simplest measure: each citation gets one vote.
on the web: citation frequency = inlink count

however: a high inlink count does not necessarily mean high
quality . . .

. . . mainly because of link spam.
better measure: weighted citation frequency or citation rank

an citation   s vote is weighted according to its citation impact.
circular? no: can be formalized in a well-de   ned way.

17 / 80

origins of id95: citation analysis (3)

better measure: weighted citation frequency or citation rank

this is basically id95.

id95 was invented in the context of citation analysis by
pinsker and narin in the 1960s.

citation analysis is a big deal: the budget and salary of this
lecturer are / will be determined by the impact of his
publications!

18 / 80

origins of id95: summary

we can use the same formal representation for

citations in the scienti   c literature
hyperlinks on the web

appropriately weighted citation frequency is an excellent
measure of quality . . .

. . . both for web pages and for scienti   c publications.

next: id95 algorithm for computing weighted citation
frequency on the web

19 / 80

outline

1 recap

2 anchor text

3 citation analysis

4 id95

5 hits: hubs & authorities

20 / 80

model behind id95: random walk

imagine a web surfer doing a random walk on the web

start at a random page
at each step, go out of the current page along one of the links
on that page, equiprobably

in the steady state, each page has a long-term visit rate.

this long-term visit rate is the page   s id95.

id95 = long-term visit rate = steady state id203

21 / 80

formalization of random walk: markov chains

a markov chain consists of n states, plus an n    n transition
id203 matrix p.

state = page

at each step, we are on exactly one of the pages.
for 1     i , j     n, the matrix entry pij tells us the id203
of j being the next page, given we are currently on page i .
clearly, for all i, pn

j=1 pij = 1

pij

dj

di

22 / 80

example web graph

d0

gm

car

benz

d2

ford

d1

honda

jag

jaguar

d5

tiger

leopard

cheetah

d3

jaguar

d6

speed

cat

lion

d4

d0
d1
d2
d3
d4
d5
d6

id95
0.05
0.04
0.11
0.25
0.21
0.04
0.31
id95(d2)<
id95(d6):
why?

a
0.10
0.01
0.12
0.47
0.16

h
0.03
0.04
0.33
0.18
0.04

d0
d1
d2
d3
d

23 / 80

link matrix for example

d0
0
0
1
0
0
0
0

d1
0
1
0
0
0
0
0

d2
1
1
1
0
0
0
0

d3
0
0
1
1
0
0
1

d4
0
0
0
1
0
0
1

d5
0
0
0
0
0
1
0

d6
0
0
0
0
1
1
1

d0
d1
d2
d3
d4
d5
d6

24 / 80

transition id203 matrix p for example

d0
0.00
0.00
0.33
0.00
0.00
0.00
0.00

d1
0.00
0.50
0.00
0.00
0.00
0.00
0.00

d2
1.00
0.50
0.33
0.00
0.00
0.00
0.00

d3
0.00
0.00
0.33
0.50
0.00
0.00
0.33

d4
0.00
0.00
0.00
0.50
0.00
0.00
0.33

d5
0.00
0.00
0.00
0.00
0.00
0.50
0.00

d6
0.00
0.00
0.00
0.00
1.00
0.50
0.33

d0
d1
d2
d3
d4
d5
d6

25 / 80

long-term visit rate

recall: id95 = long-term visit rate

long-term visit rate of page d is the id203 that a web
surfer is at page d at a given point in time.

next: what properties must hold of the web graph for the
long-term visit rate to be well de   ned?

the web graph must correspond to an ergodic markov chain.

first a special case: the web graph must not contain dead
ends.

26 / 80

dead ends

??

the web is full of dead ends.

random walk can get stuck in dead ends.

if there are dead ends, long-term visit rates are not
well-de   ned (or non-sensical).

27 / 80

teleporting     to get us out of dead ends

at a dead end, jump to a random web page with prob. 1/n.

at a non-dead end, with id203 10%, jump to a random
web page (to each with a id203 of 0.1/n).
with remaining id203 (90%), go out on a random
hyperlink.

for example, if the page has 4 outgoing links: randomly
choose one with id203 (1-0.10)/4=0.225

10% is a parameter, the teleportation rate.

note:    jumping    from dead end is independent of
teleportation rate.

28 / 80

result of teleporting

with teleporting, we cannot get stuck in a dead end.

but even without dead ends, a graph may not have
well-de   ned long-term visit rates.

more generally, we require that the markov chain be
ergodic.

29 / 80

ergodic markov chains

a markov chain is ergodic i    it is irreducible and aperiodic.

irreducibility. roughly: there is a path from any page to any
other page.

aperiodicity. roughly: the pages cannot be partitioned such
that the random walker visits the partitions sequentially.

a non-ergodic markov chain:

1.0

1.0

30 / 80

ergodic markov chains

theorem: for any ergodic markov chain, there is a unique
long-term visit rate for each state.

this is the steady-state id203 distribution.

over a long time period, we visit each state in proportion to
this rate.

it doesn   t matter where we start.

teleporting makes the web graph ergodic.

    web-graph+teleporting has a steady-state id203
distribution.

    each page in the web-graph+teleporting has a
id95.

31 / 80

where we are

we now know what to do to make sure we have a well-de   ned
id95 for each page.

next: how to compute id95

32 / 80

formalization of    visit   : id203 vector

a id203 (row) vector ~x = (x1, . . . , xn ) tells us where the
random walk is at any point.
. . .
. . .

0
. . .
. . . n-2 n-1 n

example:

1
i

0
1

0
2

0
3

0

0

)

(

more generally: the random walk is on page i with id203
xi .
example:
0.05
1

. . .
. . . n-2 n-1 n

0.01
2

0.0
3

0.2
i

. . .
. . .

0.01

0.05

0.03

(

p xi = 1

)

33 / 80

change in id203 vector

if the id203 vector is ~x = (x1, . . . , xn ) at this step, what
is it at the next step?

recall that row i of the transition id203 matrix p tells us
where we go next from state i .

so from ~x, our next state is distributed as ~xp.

34 / 80

steady state in vector notation

the steady state in vector notation is simply a vector
~   = (  1,   2, . . . ,   n ) of probabilities.
(we use ~   to distinguish it from the notation for the
id203 vector ~x.)
  i is the long-term visit rate (or id95) of page i .
so we can think of id95 as a very long vector     one
entry per page.

35 / 80

steady-state distribution: example

what is the id95 / steady state in this example?

0
.
2
5

d1

0.75

0.25

d2

5
7
.
0

36 / 80

steady-state distribution: example

x1
pt(d1) pt (d2)

x2

t0
t1

0.25
0.25

0.75
0.75

p11 = 0.25 p12 = 0.75
p21 = 0.25 p22 = 0.75
0.25

0.75

(convergence)

id95

vector = ~   = (  1,   2) = (0.25, 0.75)
pt (d1) = pt   1(d1)     p11 + pt   1(d2)     p21

pt (d2) = pt   1(d1)     p12 + pt   1(d2)     p22

37 / 80

how do we compute the steady state vector?

in other words: how do we compute id95?
recall: ~   = (  1,   2, . . . ,   n ) is the id95 vector, the
vector of steady-state probabilities . . .

. . . and if the distribution in this step is ~x, then the
distribution in the next step is ~xp.

but ~   is the steady state!

so: ~   = ~  p

solving this matrix equation gives us ~  .

~   is the principal left eigenvector for p . . .

. . . that is, ~   is the left eigenvector with the largest eigenvalue.

all transition id203 matrices have largest eigenvalue 1.

38 / 80

one way of computing the id95 ~  

start with any distribution ~x, e.g., uniform distribution

after one step, we   re at ~xp.
after two steps, we   re at ~xp 2.
after k steps, we   re at ~xp k .
algorithm: multiply ~x by increasing powers of p until
convergence.

this is called the power method.

recall: regardless of where we start, we eventually reach the
steady state ~  .

thus: we will eventually (in asymptotia) reach the steady
state.

39 / 80

power method: example

what is the id95 / steady state in this example?

0
.
1

d1

0.9

0.3

d2

7
.
0

the steady state distribution (= the id95s) in this
example are 0.25 for d1 and 0.75 for d2.

40 / 80

computing id95: power method

x1
pt (d1) pt (d2)

x2

t0
t1
t2
t3

0
0.3
0.24
0.252

1
0.7
0.76
0.748

p11 = 0.1 p12 = 0.9
p21 = 0.3 p22 = 0.7
0.3
0.24
0.252
0.2496

0.7
0.76
0.748
0.7504

t    0.25

0.75

0.25

. . .

0.75

id95 vector = ~   = (  1,   2) = (0.25, 0.75)

pt (d1) = pt   1(d1)     p11 + pt   1(d2)     p21

pt (d2) = pt   1(d1)     p12 + pt   1(d2)     p22

= ~xp
= ~xp 2
= ~xp 3
= ~xp 4
. . .
= ~xp    

41 / 80

power method: example

what is the id95 / steady state in this example?

0
.
1

d1

0.9

0.3

d2

7
.
0

the steady state distribution (= the id95s) in this
example are 0.25 for d1 and 0.75 for d2.

42 / 80

exercise: compute id95 using power method

0
.
7

d1

0.3

0.2

d2

8
.
0

43 / 80

solution

x1
pt (d1) pt (d2)

x2

t0
t1
t2
t3

0
0.2
0.3
0.35

1
0.8
0.7
0.65

p11 = 0.7 p12 = 0.3
p21 = 0.2 p22 = 0.8
0.2
0.3
0.35
0.375

0.8
0.7
0.65
0.625

t    0.4

0.6

0.4

. . .

0.6

vector = ~   = (  1,   2) = (0.4, 0.6)
pt (d1) = pt   1(d1)     p11 + pt   1(d2)     p21

pt (d2) = pt   1(d1)     p12 + pt   1(d2)     p22

id95

44 / 80

id95 summary

preprocessing

given graph of links, build matrix p
apply teleportation
from modi   ed matrix, compute ~  
~  i is the id95 of page i.

query processing

retrieve pages satisfying the query
rank them by their id95
return reranked list to the user

45 / 80

id95 issues

real surfers are not random surfers.

examples of nonrandom sur   ng: back button, short vs. long
paths, bookmarks, directories     and search!
    markov model is not a good model of sur   ng.
but it   s good enough as a model for our purposes.

simple id95 ranking (as described on previous slide)
produces bad results for many pages.

consider the query [video service]
the yahoo home page (i) has a very high id95 and (ii)
contains both video and service.
if we rank all boolean hits according to id95, then the
yahoo home page would be top-ranked.
clearly not desirable

in practice: rank according to weighted combination of raw
text match, anchor text match, id95 & other factors

    see lecture on learning to rank

46 / 80

example web graph

d0

gm

car

benz

d2

ford

d1

honda

jag

jaguar

d5

tiger

leopard

cheetah

d3

jaguar

d6

speed

cat

lion

d4

d0
d1
d2
d3
d4
d5
d6

id95
0.05
0.04
0.11
0.25
0.21
0.04
0.31
id95(d2)<
id95(d6):
why?

a
0.10
0.01
0.12
0.47
0.16

h
0.03
0.04
0.33
0.18
0.04

d0
d1
d2
d3
d

47 / 80

transition (id203) matrix

d0
0.00
0.00
0.33
0.00
0.00
0.00
0.00

d1
0.00
0.50
0.00
0.00
0.00
0.00
0.00

d2
1.00
0.50
0.33
0.00
0.00
0.00
0.00

d3
0.00
0.00
0.33
0.50
0.00
0.00
0.33

d4
0.00
0.00
0.00
0.50
0.00
0.00
0.33

d5
0.00
0.00
0.00
0.00
0.00
0.50
0.00

d6
0.00
0.00
0.00
0.00
1.00
0.50
0.33

d0
d1
d2
d3
d4
d5
d6

48 / 80

transition matrix with teleporting

d0
0.02
0.02
0.31
0.02
0.02
0.02
0.02

d1
0.02
0.45
0.02
0.02
0.02
0.02
0.02

d2
0.88
0.45
0.31
0.02
0.02
0.02
0.02

d3
0.02
0.02
0.31
0.45
0.02
0.02
0.31

d4
0.02
0.02
0.02
0.45
0.02
0.02
0.31

d5
0.02
0.02
0.02
0.02
0.02
0.45
0.02

d6
0.02
0.02
0.02
0.02
0.88
0.45
0.31

d0
d1
d2
d3
d4
d5
d6

49 / 80

power method vectors ~x p k

~x
0.14
0.14
0.14
0.14
0.14
0.14
0.14

~xp 1
0.06
0.08
0.25
0.16
0.12
0.08
0.25

~xp 2
0.09
0.06
0.18
0.23
0.16
0.06
0.23

~xp 3
0.07
0.04
0.17
0.24
0.19
0.04
0.25

~xp 4
0.07
0.04
0.15
0.24
0.19
0.04
0.27

~xp 5
0.06
0.04
0.14
0.24
0.20
0.04
0.28

~xp 6
0.06
0.04
0.13
0.24
0.21
0.04
0.29

~xp 7
0.06
0.04
0.12
0.25
0.21
0.04
0.29

~xp 8
0.06
0.04
0.12
0.25
0.21
0.04
0.30

~xp 9
0.05
0.04
0.12
0.25
0.21
0.04
0.30

~xp 10
0.05
0.04
0.12
0.25
0.21
0.04
0.30

~xp 11
0.05
0.04
0.11
0.25
0.21
0.04
0.30

~xp 12
0.05
0.04
0.11
0.25
0.21
0.04
0.31

~xp 13
0.05
0.04
0.11
0.25
0.21
0.04
0.31

d0
d1
d2
d3
d4
d5
d6

50 / 80

example web graph

d0

gm

car

benz

d2

ford

d1

honda

jag

jaguar

d5

tiger

leopard

cheetah

d3

jaguar

d6

speed

cat

lion

d4

d0
d1
d2
d3
d4
d5
d6

id95
0.05
0.04
0.11
0.25
0.21
0.04
0.31
id95(d2)<
id95(d6):
why?

a
0.10
0.01
0.12
0.47
0.16

h
0.03
0.04
0.33
0.18
0.04

d0
d1
d2
d3
d

51 / 80

how important is id95?

frequent claim: id95 is the most important component
of web ranking.
the reality:

there are several components that are at least as important:
e.g., anchor text, phrases, proximity, tiered indexes . . .
rumor has it that id95 in its original form (as presented
here) now has a negligible impact on ranking!
however, variants of a page   s id95 are still an essential
part of ranking.
adressing link spam is di   cult and crucial.

52 / 80

outline

1 recap

2 anchor text

3 citation analysis

4 id95

5 hits: hubs & authorities

53 / 80

hits     hyperlink-induced topic search

premise: there are two di   erent types of relevance on the web.
relevance type 1: hubs. a hub page is a good list of [links to
pages answering the information need].

e.g., for query [chicago bulls]: bob   s list of recommended
resources on the chicago bulls sports team

relevance type 2: authorities. an authority page is a direct
answer to the information need.

the home page of the chicago bulls sports team
by de   nition: links to authority pages occur repeatedly on
hub pages.

most approaches to search (including id95 ranking)
don   t make the distinction between these two very di   erent
types of relevance.

54 / 80

hubs and authorities: de   nition

a good hub page for a topic links to many authority pages for
that topic.

a good authority page for a topic is linked to by many hub
pages for that topic.

circular de   nition     we will turn this into an iterative
computation.

55 / 80

example for hubs and authorities

hubs

authorities

www.bestfares.com

www.airlinesquality.com

blogs.usatoday.com/sky

aviationblog.dallasnews.com

www.aa.com

www.delta.com

www.united.com

56 / 80

how to compute hub and authority scores

do a regular web search    rst

call the search result the root set

find all pages that are linked to or link to pages in the root set

call this larger set the base set

finally, compute hubs and authorities for the base set (which
we   ll view as a small web graph)

57 / 80

root set and base set (1)

base set

root set

the root set nodes that root set nodes link to nodes that link to
root set nodes the base set

58 / 80

root set and base set (2)

root set typically has 200   1000 nodes.

base set may have up to 5000 nodes.
computation of base set, as shown on previous slide:

follow outlinks by parsing the pages in the root set
find d   s inlinks by searching for all pages containing a link to
d

59 / 80

hub and authority scores

compute for each page d in the base set a hub score h(d) and
an authority score a(d)

initialization: for all d: h(d) = 1, a(d) = 1

iteratively update all h(d), a(d)
after convergence:

output pages with highest h scores as top hubs
output pages with highest a scores as top authorities
so we output two ranked lists

60 / 80

iterative update

for all d: h(d) = pd7   y a(y )

y1

y2

y3

d

d

y1

y2

for all d: a(d) = py 7   d h(y )
iterate these two steps until convergence

y3

61 / 80

details

scaling

to prevent the a() and h() values from getting too big, can
scale down after each iteration
scaling factor doesn   t really matter.
we care about the relative (as opposed to absolute) values of
the scores.

in most cases, the algorithm converges after a few
iterations.

62 / 80

authorities for query [chicago bulls]

0.85 www.nba.com/bulls
0.25 www.essex1.com/people/jmiller/bulls.htm

   da bulls   

0.20 www.nando.net/sportserver/basketball/nba/chi.html

0.15

   the chicago bulls   
users.aol.com/rynocub/bulls.htm
   the chicago bulls home page   

0.13 www.geocities.com/colosseum/6095

   chicago bulls   

(ben-shaul et al, www8)

63 / 80

the authority page for [chicago bulls]

64 / 80

hubs for query [chicago bulls]

1.62 www.geocities.com/colosseum/1778

   unbelieveabulls!!!!!   

1.24 www.webring.org/cgi-bin/webring?ring=chbulls

   erin   s chicago bulls page   

0.74 www.geocities.com/hollywood/lot/3330/bulls.html

   chicago bulls   

0.52 www.nobull.net/web position/kw-search-15-m2.htm

   excite search results: bulls   

0.52 www.halcyon.com/wordsltd/bball/bulls.htm

   chicago bulls links   

(ben-shaul et al, www8)

65 / 80

a hub page for [chicago bulls]

66 / 80

hubs & authorities: comments

hits can pull together good pages regardless of page content.

once the base set is assembled, we only do link analysis, no
text matching.

pages in the base set often do not contain any of the query
words.
in theory, an english query can retrieve japanese-language
pages!

if supported by the link structure between english and
japanese pages

danger: topic drift     the pages found by following links may
not be related to the original query.

67 / 80

proof of convergence

we de   ne an n    n adjacency matrix a. (we called this the
link matrix earlier.
for 1     i , j     n, the matrix entry aij tells us whether there is
a link from page i to page j (aij = 1) or not (aij = 0).
example:

d1

d2

d3

d1
0
1
1

d2
1
1
0

d3
0
1
0

d1
d2
d3

68 / 80

write update rules as matrix operations

de   ne the hub vector ~h = (h1, . . . , hn ) as the vector of hub
scores. hi is the hub score of page di .
similarly for ~a, the vector of authority scores
now we can write h(d) = pd7   y a(y ) as a matrix operation:
~h = a~a . . .
. . . and we can write a(d) = py 7   d h(y ) as ~a = at~h
hits algorithm in matrix notation:

compute ~h = a~a
compute ~a = at~h
iterate until convergence

69 / 80

hits as eigenvector problem

hits algorithm in matrix notation. iterate:

compute ~h = a~a
compute ~a = at~h

by substitution we get: ~h = aat~h and ~a = at a~a
thus, ~h is an eigenvector of aat and ~a is an eigenvector of
at a.
so the hits algorithm is actually a special case of the power
method and hub and authority scores are eigenvector values.

hits and id95 both formalize link analysis as
eigenvector problems.

70 / 80

example web graph

d0

gm

car

benz

d2

ford

d1

honda

jag

jaguar

d5

tiger

leopard

cheetah

d3

jaguar

d6

speed

cat

lion

d4

d0
d1
d2
d3
d4
d5
d6

id95
0.05
0.04
0.11
0.25
0.21
0.04
0.31
id95(d2)<
id95(d6):
why?

a
0.10
0.01
0.12
0.47
0.16

h
0.03
0.04
0.33
0.18
0.04

d0
d1
d2
d3
d

71 / 80

raw matrix a for hits

d0
0
0
1
0
0
0
0

d1
0
1
0
0
0
0
0

d2
1
1
1
0
0
0
0

d3
0
0
2
1
0
0
2

d4
0
0
0
1
0
0
1

d5
0
0
0
0
0
1
0

d6
0
0
0
0
1
1
1

d0
d1
d2
d3
d4
d5
d6

72 / 80

hub vectors h0,~hi = 1
di

a    ~ai , i     1

~h0
0.14
0.14
0.14
0.14
0.14
0.14
0.14

~h1
0.06
0.08
0.28
0.14
0.06
0.08
0.30

~h2
0.04
0.05
0.32
0.17
0.04
0.05
0.33

~h3
0.04
0.04
0.33
0.18
0.04
0.04
0.34

~h4
0.03
0.04
0.33
0.18
0.04
0.04
0.35

~h5
0.03
0.04
0.33
0.18
0.04
0.04
0.35

d0
d1
d2
d3
d4
d5
d6

73 / 80

authority vectors ~ai = 1
ci

at    ~hi   1, i     1

~a1
0.06
0.06
0.19
0.31
0.13
0.06
0.19

~a2
0.09
0.03
0.14
0.43
0.14
0.03
0.14

~a3
0.10
0.01
0.13
0.46
0.16
0.02
0.13

~a4
0.10
0.01
0.12
0.46
0.16
0.01
0.13

~a5
0.10
0.01
0.12
0.46
0.16
0.01
0.13

~a6
0.10
0.01
0.12
0.47
0.16
0.01
0.13

~a7
0.10
0.01
0.12
0.47
0.16
0.01
0.13

d0
d1
d2
d3
d4
d5
d6

74 / 80

example web graph

d0

gm

car

benz

d2

ford

d1

honda

jag

jaguar

d5

tiger

leopard

cheetah

d3

jaguar

d6

speed

cat

lion

d4

d0
d1
d2
d3
d4
d5
d6

id95
0.05
0.04
0.11
0.25
0.21
0.04
0.31
id95(d2)<
id95(d6):
why?

a
0.10
0.01
0.12
0.47
0.16

h
0.03
0.04
0.33
0.18
0.04

d0
d1
d2
d3
d

75 / 80

example web graph

d0

gm

car

benz

d2

ford

d1

honda

jag

jaguar

d5

tiger

leopard

cheetah

d3

jaguar

d6

speed

cat

lion

d4

d0
d1
d2
d3
d4
d5
d6

id95
0.05
0.04
0.11
0.25
0.21
0.04
0.31
id95(d2)<
id95(d6):
why?

a
0.10
0.01
0.12
0.47
0.16

h
0.03
0.04
0.33
0.18
0.04

d0
d1
d2
d3
d

76 / 80

id95 vs. hits: discussion

id95 can be precomputed, hits has to be computed at
query time.

hits is too expensive in most application scenarios.

id95 and hits make two di   erent design choices
concerning (i) the eigenproblem formalization (ii) the set of
pages to apply the formalization to.
these two are orthogonal.

we could also apply hits to the entire web and id95 to
a small base set.

claim: on the web, a good hub almost always is also a good
authority.

the actual di   erence between id95 ranking and hits
ranking is therefore not as large as one might expect.

77 / 80

exercise

why is a good hub almost always also a good authority?

78 / 80

take-away today

anchor text: what exactly are links on the web and why are
they important for ir?

citation analysis: the mathematical foundation of id95
and link-based ranking

id95: the original algorithm that was used for link-based
ranking on the web

hubs & authorities: an alternative link-based ranking
algorithm

79 / 80

resources

chapter 21 of iir
resources at http://cislmu.org

american mathematical society article on id95 (popular
science style)
jon kleinberg   s home page (main person behind hits)
a google bomb and its defusing
google   s o   cial description of id95: id95 re   ects
our view of the importance of web pages by considering more
than 500 million variables and 2 billion terms. pages that we
believe are important pages receive a higher id95 and are
more likely to appear at the top of the search results.

80 / 80

