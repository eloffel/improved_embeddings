introduction to information retrieval

http://informationretrieval.org

iir 10: xml retrieval

hinrich sch  utze, christina lioma

center for information and language processing, university of munich

2010-07-12

1 / 42

overview

1

introduction

2 basic xml concepts

3 challenges in xml ir

4 vector space model for xml ir

5 evaluation of xml ir

2 / 42

outline

1

introduction

2 basic xml concepts

3 challenges in xml ir

4 vector space model for xml ir

5 evaluation of xml ir

3 / 42

ir and id208

ir systems are often contrasted with id208 (rdb).

traditionally, ir systems retrieve information from
unstructured text (   raw    text without markup).

rdb systems are used for querying relational data: sets of
records that have values for prede   ned attributes such as
employee number, title and salary.

objects
main data structure
model
queries

rdb search
records
table
relational model
sql

unstructured ir
unstructured docs
inverted index
vector space & others
free text queries

some structured data sources containing text are best modeled as
structured documents rather than relational data ( structured
retrieval).

4 / 42

structured retrieval

basic setting: queries are structured or unstructured; documents
are structured.

applications of structured retrieval
digital libraries, patent databases, blogs, tagged text with entities
like persons and locations (named entity tagging).

example

digital libraries: give me a full-length article on fast fourier
transforms

patents: give me patents whose claims mention rsa public
key encryption and that cite us patent 4,405,829

entity-tagged text: give me articles about sightseeing tours of
the vatican and the coliseum

5 / 42

why rdb is not suitable in this case

three main problems

1 an unranked system (db) would return a potentially large
number of articles that mention the vatican, the coliseum
and sightseeing tours without ranking them by relevance to
the query.

2 di   cult for users to precisely state structural constraints -

may not know which structured elements are supported by the
system.
tours and(country:vatican or
landmark:coliseum) ?
tours and (state:vatican or building:coliseum) ?

3 users may be completely unfamiliar with structured search

and advanced search interfaces or unwilling to use them.

solution: adapt ranked retrieval to structured documents to
address these problems.

6 / 42

structured retrieval

rdb search, unstructured ir, structured ir

objects
main data
structure
model
queries

rdb search
records
table

unstructured retrieval
unstructured docs
inverted index

structured retrieval
trees with text at leaves
?

relational model
sql

vector space & others
free text queries

?
?

standard for encoding structured documents: extensible markup
language ( xml)

structured ir     xml ir

also applicable to other types of markup (html, sgml, ...)

7 / 42

outline

1

introduction

2 basic xml concepts

3 challenges in xml ir

4 vector space model for xml ir

5 evaluation of xml ir

8 / 42

xml document

ordered, labeled tree

each node of the tree is
an xml element, written
with an opening and
closing xml tag (e.g.
<title...>, </title...>)

an element can have one
or more xml attributes
(e.g. number)

attributes can have values
(e.g. vii)

attributes can have child
elements (e.g. title, verse)

<play>
<author>shakespeare</author>
<title>macbeth</title>
<act number=    i   >
<scene number=    vii   >
<title>macbeth   s
castle</title>
<verse>will i with wine
...</verse>
</scene>
</act>
</play>

9 / 42

xml document

root element

play

element

author

element

act

text

shakespeare

attribute

number=   i   

attribute

number=   vii   

element

scene

element

verse

element

title

text

macbeth

element

title

text

text

will i with ...

macbeth   s castle

10 / 42

xml document

the leaf nodes consist of text

root element

play

element

author

element

act

text

shakespeare

attribute

number=   i   

element

scene

element

title

text

macbeth

attribute

element

element

11 / 42

xml document

the internal nodes encode document structure or metadata functions

root element

play

element

author

element

act

text

shakespeare

attribute

number=   i   

attribute

number=   vii   

element
scene

element

verse

element

title

text

macbeth

element

title

text

text

will i with ...

macbeth   s castle

12 / 42

xml basics

xml document object model (xml dom): standard for
accessing and processing xml documents

the dom represents elements, attributes and text within
elements as nodes in a tree.
with a dom api, we can process an xml document by
starting at the root element and then descending down the
tree from parents to children.

xpath: standard for enumerating paths in an xml document
collection.

we will also refer to paths as xml contexts or simply contexts
schema: puts constraints on the structure of allowable xml
documents. e.g. a schema for shakespeare   s plays: scenes
can only occur as children of acts.

two standards for schemas for xml documents are: xml
dtd (document type de   nition) and xml schema.

13 / 42

outline

1

introduction

2 basic xml concepts

3 challenges in xml ir

4 vector space model for xml ir

5 evaluation of xml ir

14 / 42

first challenge: document parts to retrieve

structured or xml retrieval: users want us to return parts of
documents (i.e., xml elements), not entire documents as ir
systems usually do in unstructured retrieval.

example
if we query shakespeare   s plays for macbeth   s castle, should we
return the scene, the act or the entire play?

in this case, the user is probably looking for the scene.

however, an otherwise unspeci   ed search for macbeth should
return the play of this name, not a subunit.

solution: structured document retrieval principle

15 / 42

structured document retrieval principle

structured document retrieval principle
one criterion for selecting the most appropriate part of a
document:

a system should always retrieve the most speci   c part of
a document answering the query.

motivates a retrieval strategy that returns the smallest unit
that contains the information sought, but does not go below
this level.
hard to implement this principle algorithmically. e.g. query:
title:macbeth can match both the title of the tragedy,
macbeth, and the title of act i, scene vii, macbeth   s castle.

but in this case, the title of the tragedy (higher node) is
preferred.
di   cult to decide which level of the tree satis   es the query.

16 / 42

second challenge: document parts to index

central notion for indexing and ranking in ir: document unit or
indexing unit.

in unstructured retrieval, usually straightforward:    les on your
desktop, email messages, web pages on the web etc.
in structured retrieval, there are four main di   erent
approaches to de   ning the indexing unit.

top down

1 non-overlapping pseudodocuments
2
3 bottom up
4 all

17 / 42

xml indexing unit: approach 1

group nodes into non-overlapping pseudodocuments.

indexing units: books, chapters, sections, but without overlap.
disadvantage: pseudodocuments may not make sense to the user
because they are not coherent units.

18 / 42

xml indexing unit: approach 2

top down (2-stage process):

1

2

start with one of the largest elements as the indexing unit,
e.g. the book element in a collection of books

then, postprocess search results to    nd for each book the
subelement that is the best hit.

this two-stage retrieval process often fails to return the best
subelement because the relevance of a whole book is often not a
good predictor of the relevance of small subelements within it.

19 / 42

xml indexing unit: approach 3

bottom up:
instead of retrieving large units and identifying subelements (top
down), we can search all leaves, select the most relevant ones and
then extend them to larger units in postprocessing.
similar problem as top down: the relevance of a leaf element is
often not a good predictor of the relevance of elements it is
contained in.

20 / 42

xml indexing unit: approach 4

index all elements: the least restrictive approach. also
problematic:

many xml elements are not meaningful search results, e.g.,
an isbn number.

indexing all elements means that search results will be highly
redundant.

example
for the query macbeth   s castle we would return all of the play,
act, scene and title elements on the path between the root node
and macbeth   s castle. the leaf node would then occur 4 times in
the result set: 1 directly and 3 as part of other elements.

we call elements that are contained within each other nested
elements. returning redundant nested elements in a list of
returned hits is not very user-friendly.

21 / 42

third challenge: nested elements

because of the redundancy caused by nested elements it is
common to restrict the set of elements eligible for retrieval.
restriction strategies include:

discard all small elements

discard all element types that users do not look at (working
xml retrieval system logs)

discard all element types that assessors generally do not judge
to be relevant (if relevance assessments are available)

only keep element types that a system designer or librarian
has deemed to be useful search results

in most of these approaches, result sets will still contain nested
elements.

22 / 42

third challenge: nested elements

further techniques:

remove nested elements in a postprocessing step to reduce
redundancy.

collapse several nested elements in the results list and use
highlighting of query terms to draw the user   s attention to
the relevant passages.

highlighting

gain 1: enables users to scan medium-sized elements (e.g., a
section); thus, if the section and the paragraph both occur in
the results list, it is su   cient to show the section.

gain 2: paragraphs are presented in-context (i.e., their
embedding section). this context may be helpful in
interpreting the paragraph.

23 / 42

nested elements and term statistics

further challenge related to nesting: we may need to distinguish
di   erent contexts of a term when we compute term statistics for
ranking, in particular inverse document frequency (idf).

example
the term gates under the node author is unrelated to an
occurrence under a content node like section if used to refer to the
plural of gate. it makes little sense to compute a single document
frequency for gates in this example.

solution: compute idf for xml-context term pairs.

sparse data problems (many xml-context pairs occur too
rarely to reliably estimate df)

compromise: consider the parent node x of the term and not
the rest of the path from the root to x to distinguish contexts.

24 / 42

outline

1

introduction

2 basic xml concepts

3 challenges in xml ir

4 vector space model for xml ir

5 evaluation of xml ir

25 / 42

main idea: lexicalised subtrees

aim: to have each dimension of the vector space encode a word
together with its position within the xml tree.
how: map xml documents to lexicalised subtrees.

26 / 42

main idea: lexicalised subtrees

1 take each text node (leaf) and break it into multiple nodes,
one for each word. e.g. split bill gates into bill and gates.

2 de   ne the dimensions of the vector space to be lexicalized
subtrees of documents     subtrees that contain at least one
vocabulary term.

27 / 42

lexicalised subtrees

we can now represent queries and documents as vectors in this
space of lexicalized subtrees and compute matches between them,
e.g. using the vector space formalism.

vector space formalism in unstructured vs. structured ir
the main di   erence is that the dimensions of vector space in
unstructured retrieval are vocabulary terms whereas they are
lexicalized subtrees in xml retrieval.

28 / 42

structural term

there is a tradeo    between the dimensionality of the space and
accuracy of query results.

if we restrict dimensions to vocabulary terms, then we have a
standard vector space retrieval system that will retrieve many
documents that do not match the structure of the query (e.g.,
gates in the title as opposed to the author element).

if we create a separate dimension for each lexicalized subtree
occurring in the collection, the dimensionality of the space
becomes too large.

compromise: index all paths that end in a single vocabulary term,
in other words, all xml-context term pairs. we call such an
xml-context term pair a structural term and denote it by hc, ti: a
pair of xml-context c and vocabulary term t.

29 / 42

context resemblance

a simple measure of the similarity of a path cq in a query and a
path cd in a document is the following context resemblance
function cr:

cr(cq, cd ) =( 1+|cq|

1+|cd |
0

if cq matches cd
if cq does not match cd

(1)

|cq| and |cd | are the number of nodes in the query path and
document path, resp.
cq matches cd i    we can transform cq into cd by inserting
additional nodes.

30 / 42

context resemblance example

book

book

book

author

author

book

creator

   rstname

lastname

gates

gates

gates

bill

gates

q3

q4

d2

d3

cr(cq, cd ) =( 1+|cq|

1+|cd |
0

if cq matches cd
if cq does not match cd

cr(cq4 , cd2 ) = 3/4 = 0.75. the value of cr(cq, cd ) is 1.0 if q
and d are identical.

31 / 42

context resemblance exercise

book

book

book

author

author

book

creator

   rstname

lastname

gates

gates

gates

bill

gates

q3

q4

d2

d3

cr(cq, cd ) =( 1+|cq|

1+|cd |
0

if cq matches cd
if cq does not match cd

cr(cq4 , cd3 ) =? cr(cq4 , cd3 ) = 3/5 = 0.6.

32 / 42

document similarity measure

the    nal score for a document is computed as a variant of the
cosine measure, which we call simnomerge.
simnomerge(q, d) =

xck    b xcl    b

cr(ck , cl )xt   v

weight(q, t, ck )

weight(d, t, cl )

qpc   b ,t   v weight2(d, t, c)

v is the vocabulary of non-structural terms

b is the set of all xml contexts

weight(q, t, c), weight(d, t, c) are the weights of term t in
xml context c in query q and document d, resp. (standard
weighting e.g. idft    wft ,d , where idft depends on which
elements we use to compute dft. )

simnomerge(q, d) is not a true cosine measure since its value
can be larger than 1.0.

33 / 42

simnomerge algorithm

scoredocumentswithsimnomerge(q, b, v , n, normalizer )

for each c     b
do if cr(cq, c) > 0

1 for n     1 to n
2 do score[n]     0
3 for each hcq, ti     q
4 do wq     weight(q, t, cq)
5
6
7
8
9
10
11 for n     1 to n
12 do score[n]     score[n]/normalizer [n]
13 return score

then postings     getpostings(hc, ti)

for each posting     postings
do x     cr(cq, c)     wq     weight(posting )

score[docid(posting )]+ = x

34 / 42

outline

1

introduction

2 basic xml concepts

3 challenges in xml ir

4 vector space model for xml ir

5 evaluation of xml ir

35 / 42

initiative for the evaluation of xml retrieval (inex)

inex: standard benchmark evaluation (yearly) that has produced
test collections (documents, sets of queries, and relevance
judgments).
based on ieee journal collection (since 2006 inex uses the much
larger english wikipedia as a test collection).
the relevance of documents is judged by human assessors.

inex 2002 collection statistics

12,107
494 mb
1995   2002
1,532
6.9
30
30

number of documents
size
time of publication of articles
average number of xml nodes per document
average depth of a node
number of cas topics
number of co topics

36 / 42

inex topics

two types:

1 content-only or co topics: regular keyword queries as in

unstructured information retrieval

2 content-and-structure or cas topics: have structural

constraints in addition to keywords

since cas queries have both structural and content criteria,
relevance assessments are more complicated than in unstructured
retrieval.

37 / 42

inex relevance assessments

inex 2002 de   ned component coverage and topical relevance as
orthogonal dimensions of relevance.

component coverage
evaluates whether the element retrieved is    structurally    correct, i.e.,
neither too low nor too high in the tree.

we distinguish four cases:

1 exact coverage (e): the information sought is the main topic of

the component and the component is a meaningful unit of
information.

2 too small (s): the information sought is the main topic of the

component, but the component is not a meaningful
(self-contained) unit of information.

3 too large (l): the information sought is present in the

component, but is not the main topic.

4 no coverage (n): the information sought is not a topic of the

component.

38 / 42

inex relevance assessments

the topical relevance dimension also has four levels: highly
relevant (3), fairly relevant (2), marginally relevant (1) and
nonrelevant (0).

combining the relevance dimensions
components are judged on both dimensions and the judgments are
then combined into a digit-letter code, e.g. 2s is a fairly relevant
component that is too small. in theory, there are 16 combinations
of coverage and relevance, but many cannot occur. for example, a
nonrelevant component cannot have exact coverage, so the
combination 3n is not possible.

39 / 42

inex relevance assessments

the relevance-coverage combinations are quantized as follows:

q(rel , cov ) =

1.00 if
0.75 if
0.50 if
0.25 if
0.00 if

(rel , cov ) = 3e
(rel , cov )     {2e, 3l}
(rel , cov )     {1e, 2l, 2s}
(rel , cov )     {1s, 1l}
(rel , cov ) = 0n

                  
               

this evaluation scheme takes account of the fact that binary
relevance judgments, which are standard in unstructured ir, are
not appropriate for xml retrieval. the quantization function q
does not impose a binary choice relevant/nonrelevant and instead
allows us to grade the component as partially relevant. the
number of relevant components in a retrieved set a of components
can then be computed as:

#(relevant items retrieved) =xc   a

q(rel (c), cov (c))

40 / 42

inex evaluation measures

as an approximation, the standard de   nitions of precision and
recall can be applied to this modi   ed de   nition of relevant items
retrieved, with some subtleties because we sum graded as opposed
to binary relevance assessments.

drawback
overlap is not accounted for. accentuated by the problem of
multiple nested elements occurring in a search result.

recent inex focus: develop algorithms and evaluation measures
that return non-redundant results lists and evaluate them properly.

41 / 42

recap

structured or xml ir: e   ort to port unstructured (standard)
ir know-how onto a scenario that uses structured (db-like)
data

specialised applications (e.g. patents, digital libraries)

a decade old, unsolved problem

http://inex.is.informatik.uni-duisburg.de/

42 / 42

