introduction to information retrieval

http://informationretrieval.org

iir 19: web search

hinrich sch  utze

center for information and language processing, university of munich

2014-07-02

1 / 123

overview

1 recap

2 big picture

3 ads

4 duplicate detection

5 spam

6 web ir

queries
links
context
users
documents
size

7 size of the web

2 / 123

outline

1 recap

2 big picture

3 ads

4 duplicate detection

5 spam

6 web ir

queries
links
context
users
documents
size

7 size of the web

3 / 123

indexing anchor text

anchor text is often a better description of a page   s content
than the page itself.

anchor text can be weighted more highly than the text on the
page.
a google bomb is a search with    bad    results due to
maliciously manipulated anchor text.

[dangerous cult] on google, bing, yahoo

4 / 123

id95

model: a web surfer doing a random walk on the web

formalization: markov chain

id95 is the long-term visit rate of the random surfer or
the steady-state distribution.

need teleportation to ensure well-de   ned id95
power method to compute id95

id95 is the principal left eigenvector of the transition
id203 matrix.

5 / 123

computing id95: power method

x1
pt (d1) pt (d2)

x2

t0
t1
t2
t3

0
0.3
0.24
0.252

1
0.7
0.76
0.748

p11 = 0.1 p12 = 0.9
p21 = 0.3 p22 = 0.7
0.3
0.24
0.252
0.2496

0.7
0.76
0.748
0.7504

t    0.25

0.75

0.25

. . .
0.75

id95 vector = ~   = (  1,   2) = (0.25, 0.75)

pt (d1) = pt   1(d1)     p11 + pt   1(d2)     p21

pt (d2) = pt   1(d1)     p12 + pt   1(d2)     p22

= ~xp
= ~xp 2
= ~xp 3
= ~xp 4

= ~xp    

6 / 123

hits: hubs and authorities

hubs

authorities

www.bestfares.com

www.airlinesquality.com

blogs.usatoday.com/sky

aviationblog.dallasnews.com

www.aa.com

www.delta.com

www.united.com

7 / 123

hits update rules

a: link matrix
~h: vector of hub scores
~a: vector of authority scores
hits algorithm:

compute ~h = a~a
compute ~a = at~h
iterate until convergence
output (i) list of hubs ranked according to hub score and (ii)
list of authorities ranked according to authority score

8 / 123

outline

1 recap

2 big picture

3 ads

4 duplicate detection

5 spam

6 web ir

queries
links
context
users
documents
size

7 size of the web

9 / 123

web search overview

10 / 123

search is a top activity on the web

11 / 123

without search engines, the web wouldn   t work

without search, content is hard to    nd.
    without search, there is no incentive to create content.

why publish something if nobody will read it?
why publish something if i don   t get ad revenue from it?

somebody needs to pay for the web.

servers, web infrastructure, content creation
a large part today is paid by search ads.
search pays for the web.

12 / 123

interest aggregation

unique feature of the web: a small number of geographically
dispersed people with similar interests can    nd each other.

elementary school kids with hemophilia
people interested in translating r5r5 scheme into relatively
portable c (open source project)
search engines are a key enabler for interest aggregation.

13 / 123

ir on the web vs. ir in general

on the web, search is not just a nice feature.

search is a key enabler of the web: . . .
. . .    nancing, content creation, interest aggregation etc.

    look at search ads
the web is a chaotic und uncoordinated collection.     lots of
duplicates     need to detect duplicates
no control / restrictions on who can author content     lots of
spam     need to detect spam
the web is very large.     need to know how big it is

14 / 123

take-away today

big picture

ads     they pay for the web

duplicate detection     addresses one aspect of chaotic content
creation

spam detection     addresses one aspect of lack of central
access control
probably won   t get to today
web information retrieval
size of the web

15 / 123

outline

1 recap

2 big picture

3 ads

4 duplicate detection

5 spam

6 web ir

queries
links
context
users
documents
size

7 size of the web

16 / 123

first generation of search ads: goto (1996)

17 / 123

first generation of search ads: goto (1996)

buddy blake bid the maximum ($0.38) for this search.

he paid $0.38 to goto every time somebody clicked on the
link.

pages were simply ranked according to bid     revenue
maximization for goto.

no separation of ads/docs. only one result list!

upfront and honest. no relevance ranking, . . .

. . . but goto did not pretend there was any.

18 / 123

second generation of search ads: google (2000/2001)

strict separation of search results and search ads

19 / 123

two ranked lists: web pages (left) and ads (right)

sogotrade
pears
in
results.

ap-
search

sogotrade
pears in ads.

ap-

do search engines
rank
advertis-
ers
than
non-advertisers?

higher

all major
engines claim no.

search

20 / 123

do ads in   uence editorial content?

similar problem at newspapers / tv channels

a newspaper is reluctant to publish harsh criticism of its
major advertisers.

the line often gets blurred at newspapers / on tv.

no known case of this happening with search engines yet?

21 / 123

how are the ads on the right ranked?

22 / 123

how are ads ranked?

advertisers bid for keywords     sale by auction.

open system: anybody can participate and bid on keywords.

advertisers are only charged when somebody clicks on your ad.

how does the auction determine an ad   s rank and the price
paid for the ad?

basis is a second price auction, but with twists
for the bottom line, this is perhaps the most important
research area for search engines     computational advertising.

squeezing an additional fraction of a cent from each ad means
billions of additional revenue for the search engine.

23 / 123

how are ads ranked?

first cut: according to bid price `a la goto

bad idea: open to abuse
example: query [treatment for cancer?]     how to write your
last will
we don   t want to show nonrelevant or o   ensive ads.

instead: rank based on bid price and relevance
key measure of ad relevance: clickthrough rate

clickthrough rate = ctr = clicks per impressions

result: a nonrelevant ad will be ranked low.

even if this decreases search engine revenue short-term
hope: overall acceptance of the system and overall revenue is
maximized if users get useful information.

other ranking factors: location, time of day, quality and
loading speed of landing page

the main ranking factor: the query

24 / 123

google adwords demo

25 / 123

google   s second price auction

advertiser
a
b
c
d

bid
$4.00
$3.00
$2.00
$1.00

ctr ad rank
0.01
0.03
0.06
0.08

0.04
0.09
0.12
0.08

rank
4
2
1
3

paid
(minimum)
$2.68
$1.51
$0.51

bid: maximum bid for a click by advertiser

ctr: click-through rate: when an ad is displayed, what
percentage of time do users click on it? ctr is a measure of
relevance.
ad rank: bid    ctr: this trades o    (i) how much money the
advertiser is willing to pay against (ii) how relevant the ad is

rank: rank in auction

paid: second price auction price paid by advertiser

second price auction: the advertiser pays the minimum amount
necessary to maintain their position in the auction (plus 1 cent).

26 / 123

keywords with high bids

according to http://www.cwire.org/highest-paying-search-terms/

$69.1 mesothelioma treatment options
personal injury lawyer michigan
$65.9
student loans consolidation
$62.6
car accident attorney los angeles
$61.4
$59.4
online car insurance quotes
arizona dui lawyer
$59.4
asbestos cancer
$46.4
$40.1
home equity line of credit
life insurance quotes
$39.8
re   nancing
$39.2
equity line of credit
$38.7
$38.0
lasik eye surgery new york city
2nd mortgage
$37.0
$35.9
free car insurance quote

27 / 123

search ads: a win-win-win?

the search engine company gets revenue every time
somebody clicks on an ad.
the user only clicks on an ad if they are interested in the ad.

search engines punish misleading and nonrelevant ads.
as a result, users are often satis   ed with what they    nd after
clicking on an ad.

the advertiser    nds new customers in a cost-e   ective way.

28 / 123

exercise

why is web search potentially more attractive for advertisers
than tv spots, newspaper ads or radio spots?

the advertiser pays for all this. how can the advertiser be
cheated?

any way this could be bad for the user?

any way this could be bad for the search engine?

29 / 123

not a win-win-win: keyword arbitrage

buy a keyword on google
then redirect tra   c to a third party that is paying much more
than you are paying google.

e.g., redirect to a page full of ads

this rarely makes sense for the user.

ad spammers keep inventing new tricks.

the search engines need time to catch up with them.

30 / 123

not a win-win-win: violation of trademarks

example: geico

during part of 2005: the search term    geico    on google was
bought by competitors.

geico lost this case in the united states.

louis vuitton lost similar case in europe.

see http://google.com/tm complaint.html

it   s potentially misleading to users to trigger an ad o    of a
trademark if the user can   t buy the product on the site.

31 / 123

outline

1 recap

2 big picture

3 ads

4 duplicate detection

5 spam

6 web ir

queries
links
context
users
documents
size

7 size of the web

32 / 123

duplicate detection

the web is full of duplicated content.

more so than many other collections
exact duplicates

easy to eliminate
e.g., use hash/   ngerprint

near-duplicates

abundant on the web
di   cult to eliminate

for the user, it   s annoying to get a search result with
near-identical documents.

marginal relevance is zero: even a highly relevant document
becomes nonrelevant if it appears below a (near-)duplicate.

we need to eliminate near-duplicates.

33 / 123

near-duplicates: example

34 / 123

exercise

how would you eliminate near-duplicates on the web?

35 / 123

detecting near-duplicates

compute similarity with an edit-distance measure
we want    syntactic    (as opposed to semantic) similarity.

true semantic similarity (similarity in content) is too di   cult
to compute.

we do not consider documents near-duplicates if they have
the same content, but express it with di   erent words.

use similarity threshold    to make the call    is/isn   t a
near-duplicate   .

e.g., two documents are near-duplicates if similarity
>    = 80%.

36 / 123

represent each document as set of shingles

a shingle is simply a word id165.

shingles are used as features to measure syntactic similarity of
documents.
for example, for n = 3,    a rose is a rose is a rose    would be
represented as this set of shingles:
{ a-rose-is, rose-is-a, is-a-rose }

we can map shingles to 1..2m (e.g., m = 64) by    ngerprinting.
from now on: sk refers to the shingle   s    ngerprint in 1..2m.
we de   ne the similarity of two documents as the jaccard
coe   cient of their shingle sets.

37 / 123

recall: jaccard coe   cient

a commonly used measure of overlap of two sets

let a and b be two sets

jaccard coe   cient:

jaccard(a, b) =

|a     b|
|a     b|

(a 6=     or b 6=    )
jaccard(a, a) = 1
jaccard(a, b) = 0 if a     b = 0

a and b don   t have to be the same size.

always assigns a number between 0 and 1.

38 / 123

jaccard coe   cient: example

three documents:
d1:    jack london traveled to oakland   
d2:    jack london traveled to the city of oakland   
d3:    jack traveled from oakland to london   
based on shingles of size 2 (2-grams or bigrams), what are the
jaccard coe   cients j(d1, d2) and j(d1, d3)?
j(d1, d2) = 3/8 = 0.375
j(d1, d3) = 0
note: very sensitive to dissimilarity

39 / 123

represent each document as a sketch

the number of shingles per document is large.

to increase e   ciency, we will use a sketch, a cleverly chosen
subset of the shingles of a document.

the size of a sketch is, say, n = 200 . . .
. . . and is de   ned by a set of permutations   1 . . .   200.
each   i is a random permutation on 1..2m
the sketch of d is de   ned as:
< mins    d   1(s), mins    d   2(s), . . . , mins    d   200(s) >
(a vector of 200 numbers).

40 / 123

permutation and minimum: example

document 1: {sk }

document 2: {sk }

1

1

1

   

2m

s

s

s1

s2

s

s

s3

s4

xk =   (sk )

   

x3

s

s

   

x1

   

x4

s

s

   

x2

   

2m

xk

   

x3

   

x1

   

x4

   

x2

   

2m

1

1

1

   

2m

s

s1

s

s5

s

s

s3

s4

xk =   (sk )

   

x3

s

   

x1

s

   

s

s

x4

   

   

x5

2m

xk

   

x1

   

x5

   

x3

   

   

x2

2m

minsk   (sk )

minsk   (sk )

1

   

   

2m

1

   

x3
we use mins    d1   (s) = mins    d2   (s) as a test for: are d1 and d2
near-duplicates? in this case: permutation    says: d1     d2

x3

   

2m

41 / 123

computing jaccard for sketches

sketches: each document is now a vector of n = 200
numbers.

much easier to deal with than the very high-dimensional space
of shingles

but how do we compute jaccard?

42 / 123

computing jaccard for sketches (2)

how do we compute jaccard?
let u be the union of the set of shingles of d1 and d2 and i
the intersection.
there are |u|! permutations on u.
for s         i , for how many permutations    do we have
arg mins    d1   (s) = s     = arg mins    d2   (s)?
answer: (|u|     1)!
there is a set of (|u|     1)! di   erent permutations for each s
in i .     |i |(|u|     1)! permutations make
arg mins    d1   (s) = arg mins    d2   (s) true
thus, the proportion of permutations that make
mins    d1   (s) = mins    d2   (s) true is:

|i |(|u|     1)!

|u|!

=

|i |
|u|

= j(d1, d2)

43 / 123

estimating jaccard

thus, the proportion of successful permutations is the jaccard
coe   cient.

permutation    is successful i    mins   d1   (s) = mins   d2   (s)

picking a permutation at random and outputting 1
(successful) or 0 (unsuccessful) is a bernoulli trial.

estimator of id203 of success: proportion of successes in
n bernoulli trials. (n = 200)

our sketch is based on a random selection of permutations.

thus, to compute jaccard, count the number k of successful
permutations for < d1, d2 > and divide by n = 200.
k/n = k/200 estimates j(d1, d2).

44 / 123

implementation

we use hash functions as an e   cient type of permutation:
hi : {1..2m}     {1..2m}
scan all shingles sk in union of two sets in arbitrary order
for each hash function hi and documents d1, d2, . . .: keep slot
for minimum value found so far

if hi (sk ) is lower than minimum found so far: update slot

45 / 123

example

d1
1
0
1
1
0

d2
0
1
1
0
1

s1
s2
s3
s4
s5

h(x) = x mod 5
g (x) = (2x + 1) mod 5
min(h(d1)) = 1 6= 0 =
min(h(d2)) min(g (d1)) =

2 6= 0 = min(g (d2))

  j(d1, d2) = 0+0

2 = 0

h
g
h(1) = 1
g (1) = 3
h(2) = 2
g (2) = 0
h(3) = 3
g (3) = 2
h(4) = 4
g (4) = 4
h(5) = 0
g (5) = 1

d1 slot
   
   
1
3
1
3
1
2
1
2
1
2

1
3
   
   
3
2
4
4
   
   

d2 slot
   
   
       
       
2
2
0
0
2
3
2
0
2
   
0
   
0
0
1
0

   nal sketches

46 / 123

exercise

d1
0
1
0
1

d2
1
0
1
0

d3
1
1
0
0

s1
s2
s3
s4

  j(d1, d3),   j(d2, d3)

h(x) = 5x + 5 mod 4
g (x) = (3x + 1) mod 4

estimate   j(d1, d2),

47 / 123

solution (1)

d1
0
1
0
1

d2
1
0
1
0

d3
1
1
0
0

s1
s2
s3
s4

h(x) = 5x + 5 mod 4
g (x) = (3x + 1) mod 4

h(1) = 2
g (1) = 0
h(2) = 3
g (2) = 3
h(3) = 0
g (3) = 2
h(4) = 1
g (4) = 1

d1 slot
   
   

        2
        0
   
3
   
3
   
0
2
   
   
1
1
   

3
3
3
3
1
1

d2 slot
   
   
2
0
2
0
0
0
0
0

   nal sketches

d3 slot
   
   
2
0
2
0
2
0
2
0

2
0
3
3
   
   
   
   

48 / 123

solution (2)

  j(d1, d2) =

  j(d1, d3) =

  j(d2, d3) =

0 + 0

2

0 + 0

2

0 + 1

2

= 0

= 0

= 1/2

49 / 123

shingling: summary

input: n documents

choose id165 size for shingling, e.g., n = 5

pick 200 random permutations, represented as hash functions
compute n sketches: 200    n matrix shown on previous
slide, one row per permutation, one column per document
compute n   (n   1)
transitive closure of documents with similarity >   

pairwise similarities

2

index only one document from each equivalence class

50 / 123

e   cient near-duplicate detection

now we have an extremely e   cient method for estimating a
jaccard coe   cient for a single pair of two documents.
but we still have to estimate o(n2) coe   cients where n is
the number of web pages.

still intractable

one solution: locality sensitive hashing (lsh)

another solution: sorting (henzinger 2006)

51 / 123

take-away today

big picture

ads     they pay for the web

duplicate detection     addresses one aspect of chaotic content
creation

spam detection     addresses one aspect of lack of central
access control
probably won   t get to today
web information retrieval
size of the web

52 / 123

outline

1 recap

2 big picture

3 ads

4 duplicate detection

5 spam

6 web ir

queries
links
context
users
documents
size

7 size of the web

53 / 123

the goal of spamming on the web

you have a page that will generate lots of revenue for you if
people visit it.

therefore, you would like to direct visitors to this page.

one way of doing this: get your page ranked highly in search
results.

exercise: how can i get my page ranked highly?

54 / 123

spam technique: keyword stu   ng / hidden text

misleading meta-tags, excessive repetition

hidden text with colors, style sheet tricks etc.

used to be very e   ective, most search engines now catch these

55 / 123

keyword stu   ng

56 / 123

spam technique: doorway and lander pages

doorway page: optimized for a single keyword, redirects to
the real target page

lander page: optimized for a single keyword or a misspelled
domain name, designed to attract surfers who will then click
on ads

57 / 123

lander page

number one hit on google for the search    composita   

the only purpose of this page: get people to click on the ads
and make money for the page owner

58 / 123

spam technique: duplication

get good content from somewhere (steal it or produce it
yourself)

publish a large number of slight variations of it

for example, publish the answer to a tax question with the
spelling variations of    tax deferred    on the previous slide

59 / 123

spam technique: cloaking

serve fake content to search engine spider

so do we just penalize this always?

no: legitimate uses (e.g., di   erent content to us vs.
european users)

60 / 123

spam technique: link spam

create lots of links pointing to the page you want to promote
put these links on pages with high (or at least non-zero)
id95

newly registered domains (domain    ooding)
a set of pages that all point to each other to boost each
other   s id95 (mutual admiration society)
pay somebody to put your link on their highly ranked page
(   schuetze horoskop    example)
leave comments that include the link on blogs

61 / 123

seo: search engine optimization

promoting a page in the search rankings is not necessarily
spam.

it can also be a legitimate business     which is called seo.

you can hire an seo    rm to get your page highly ranked.
there are many legitimate reasons for doing this.
for example, google bombs like who is a failure?

and there are many legitimate ways of achieving this:

restructure your content in a way that makes it easy to index
talk with in   uential bloggers and have them link to your site
add more interesting and original content

62 / 123

the war against spam

quality indicators

links, statistically analyzed (id95 etc)
usage (users visiting a page)
no adult content (e.g., no pictures with    esh-tone)
distribution and structure of text (e.g., no keyword stu   ng)

combine all of these indicators and use machine learning
editorial intervention

blacklists
top queries audited
complaints addressed
suspect patterns detected

63 / 123

webmaster guidelines

major search engines have guidelines for webmasters.

these guidelines tell you what is legitimate seo and what is
spamming.

ignore these guidelines at your own risk

once a search engine identi   es you as a spammer, all pages
on your site may get low ranks (or disappear from the index
entirely).

there is often a    ne line between spam and legitimate seo.

scienti   c study of    ghting spam on the web: adversarial
information retrieval

64 / 123

outline

1 recap

2 big picture

3 ads

4 duplicate detection

5 spam

6 web ir

queries
links
context
users
documents
size

7 size of the web

65 / 123

web ir: di   erences from traditional ir

links: the web is a hyperlinked document collection.

queries: web queries are di   erent, more varied and there are
a lot of them. how many?     109
users: users are di   erent, more varied and there are a lot of
them. how many?     109
documents: documents are di   erent, more varied and there
are a lot of them. how many?     1011
context: context is more important on the web than in many
other ir applications.

ads and spam

66 / 123

outline

1 recap

2 big picture

3 ads

4 duplicate detection

5 spam

6 web ir

queries
links
context
users
documents
size

7 size of the web

67 / 123

query distribution (1)

most frequent queries on a large search engine on 2002.10.26.

sex
1
(artifact)
2
(artifact)
3
porno
4
mp3
5
halloween
6
sexo
7
chat
8
porn
9
yahoo
10
11 kazaa
12
13 hentai
14
15

lyrics
hotmail

xxx

crack
games
pussy
cracks
lolita
britney spears
ebay
sexe

pamela anderson

16
17
18
19
20
21
22
23
24
25 warez
26
27
28
29
30

divx
gay
harry potter
playboy
lolitas

jennifer lopez
tits
free porn
cheats
yahoo.com
eminem

31
juegos
32
nude
33 music
34 musica
35
36
37
38
39 winzip
40
41 wallpaper
42
43
44
45

46 caramail
47 msn
48
49
50
anal
51
free6
avril lavigne
52
hotmail.com 53
54
55
56
hotmail.com 57
postales
shakira
traductor

letras de canciones
hardcore
58 weather
59 wallpapers
60

christina aguilera
incest

lingerie

fuck

more than 1/3 of these are queries for adult content. exercise:
does this mean that most people are looking for adult content?

68 / 123

query distribution (2)

queries have a power law distribution.

recall zipf   s law: a few very frequent words, a large number
of very rare words

same here: a few very frequent queries, a large number of
very rare queries

examples of rare queries: search for names, towns, books etc

the proportion of adult queries is much lower than 1/3

69 / 123

types of queries / user needs in web search

informational user needs: i need information on something.
   low hemoglobin   

we called this    information need    earlier in the class.

on the web, information needs proper are only a subclass of
user needs.

other user needs: navigational and transactional

navigational user needs: i want to go to this web site.
   hotmail   ,    myspace   ,    united airlines   
transactional user needs: i want to make a transaction.

buy something:    macbook air   
download something:    acrobat reader   
chat with someone:    live soccer chat   

di   cult problem: how can the search engine tell what the
user need or intent for a particular query is?

70 / 123

outline

1 recap

2 big picture

3 ads

4 duplicate detection

5 spam

6 web ir

queries
links
context
users
documents
size

7 size of the web

71 / 123

search in a hyperlinked collection

web search in most cases is interleaved with navigation . . .

. . . i.e., with following links.

di   erent from most other ir collections

72 / 123

bowtie structure of the web

strongly connected component (scc) in the center
lots of pages that get linked to, but don   t link (out)
lots of pages that link to other pages, but don   t get linked to (in)
tendrils, tubes, islands

74 / 123

outline

1 recap

2 big picture

3 ads

4 duplicate detection

5 spam

6 web ir

queries
links
context
users
documents
size

7 size of the web

75 / 123

user intent: answering the need behind the query

what can we do to guess user intent?
guess user intent independent of context:

spell correction
precomputed    typing    of queries (next slide)

better: guess user intent based on context:

geographic context (slide after next)
context of user in this session (e.g., previous query)
context provided by personal pro   le (yahoo/msn do this,
google claims it doesn   t)

76 / 123

guessing of user intent by    typing    queries

calculation: 5+4

unit conversion: 1 kg in pounds

currency conversion: 1 euro in kronor

tracking number: 8167 2278 6764

flight info: lh 454

area code: 650

map: columbus oh

stock price: msft

albums/movies etc: coldplay

77 / 123

the spatial context: geo-search

three relevant locations

server (nytimes.com     new york)
web page (nytimes.com article about albania)
user (located in palo alto)

locating the user

ip address
information provided by user (e.g., in user pro   le)
mobile phone

geo-tagging: parse text and identify the coordinates of the
geographic entities

example: east palo alto ca     latitude: 37.47 n, longitude:
122.14 w
important nlp problem

78 / 123

how do we use context to modify query results?

result restriction: don   t consider inappropriate results

for user on google.fr . . .
. . . only show .fr results

ranking modulation: use a rough generic ranking, rerank
based on personal context

contextualization / personalization is an area of search with a
lot of potential for improvement.

79 / 123

outline

1 recap

2 big picture

3 ads

4 duplicate detection

5 spam

6 web ir

queries
links
context
users
documents
size

7 size of the web

80 / 123

users of web search

use short queries (average < 3)

rarely use operators

don   t want to spend a lot of time on composing a query

only look at the    rst couple of results

want a simple ui, not a search engine start page overloaded
with graphics
extreme variability in terms of user needs, user expectations,
experience, knowledge, . . .

industrial/developing world, english/estonian, old/young,
rich/poor, di   erences in culture and class

one interface for hugely divergent needs

81 / 123

how do users evaluate search engines?

classic ir relevance (as measured by f ) can also be used for
web ir.

equally important: trust, duplicate elimination, readability,
loads fast, no pop-ups
on the web, precision is more important than recall.

precision at 1, precision at 10, precision on the    rst 2-3 pages
but there is a subset of queries where recall matters.

82 / 123

web information needs that require high recall

has this idea been patented?

searching for info on a prospective    nancial advisor

searching for info on a prospective employee

searching for info on a date

83 / 123

outline

1 recap

2 big picture

3 ads

4 duplicate detection

5 spam

6 web ir

queries
links
context
users
documents
size

7 size of the web

84 / 123

web documents: di   erent from other ir collections

distributed content creation: no design, no coordination

   democratization of publishing   
result: extreme heterogeneity of documents on the web

unstructured (text, html), semistructured (html, xml),
structured/relational (databases)

dynamically generated content

85 / 123

dynamic content

dynamic pages are generated from scratch when the user
requests them     usually from underlying data in a database.

example: current status of    ight lh 454

86 / 123

dynamic content (2)

most (truly) dynamic content is ignored by web spiders.

it   s too much to index it all.

actually, a lot of    static    content is also assembled on the    y
(asp, php etc.: headers, date, ads etc)

87 / 123

web pages change frequently (fetterly 1997)

88 / 123

multilinguality

documents in a large number of languages

queries in a large number of languages

first cut: don   t return english results for a japanese query

however: frequent mismatches query/document languages

many people can understand, but not query in a language

translation is important.

google example:    beaujolais nouveau -wine   

89 / 123

duplicate documents

signi   cant duplication     30%   40% duplicates in some studies

duplicates in the search results were common in the early
days of the web.

today   s search engines eliminate duplicates very e   ectively.

key for high user satisfaction

90 / 123

trust

for many collections, it is easy to assess the trustworthiness of
a document.

a collection of reuters newswire articles
a collection of tass (telegraph agency of the soviet union)
newswire articles from the 1980s
your outlook email from the last three years

web documents are di   erent: in many cases, we don   t know
how to evaluate the information.

hoaxes abound.

91 / 123

outline

1 recap

2 big picture

3 ads

4 duplicate detection

5 spam

6 web ir

queries
links
context
users
documents
size

7 size of the web

92 / 123

growth of the web

the web keeps growing.
but growth is no longer exponential?

93 / 123

size of the web: issues

what is size? number of web servers? number of pages?
terabytes of data available?
some servers are seldom connected.

example: your laptop running a web server
is it part of the web?

the    dynamic    web is in   nite.

any sum of two numbers is its own dynamic page on google.
(example:    2+4   )

94 / 123

   search engine index contains n pages   : issues

can i claim a page is in the index if i only index the    rst 4000
bytes?
can i claim a page is in the index if i only index anchor text
pointing to the page?

there used to be (and still are?) billions of pages that are only
indexed by anchor text.

95 / 123

simple method for determining a lower bound

or-query of frequent words in a number of languages

http://ifnlp.org/ir/sizeoftheweb.html
according to this query: size of web     21,450,000,000 on
2007.07.07 and     25,350,000,000 on 2008.07.03

but page counts of google search results are only rough
estimates.

96 / 123

outline

1 recap

2 big picture

3 ads

4 duplicate detection

5 spam

6 web ir

queries
links
context
users
documents
size

7 size of the web

97 / 123

size of the web: who cares?

media
users

they may switch to the search engine that has the best
coverage of the web.
users (sometimes) care about recall. if we underestimate the
size of the web, search engine results may have low recall.

search engine designers (how many pages do i need to be able
to handle?)

crawler designers (which policy will crawl close to n pages?)

98 / 123

what is the size of the web? any guesses?

99 / 123

simple method for determining a lower bound

or-query of frequent words in a number of languages

http://ifnlp.org/lehre/teaching/2007-ss/ir/sizeoftheweb.html
according to this query: size of web     21,450,000,000 on
2007.07.07

big if: page counts of google search results are correct.
(generally, they are just rough estimates.)

but this is just a lower bound, based on one search engine.

how can we do better?

100 / 123

size of the web: issues

the    dynamic    web is in   nite.

any sum of two numbers is its own dynamic page on google.
(example:    2+4   )
many other dynamic sites generating in   nite number of pages

the static web contains duplicates     each    equivalence class   
should only be counted once.
some servers are seldom connected.

example: your laptop
is it part of the web?

101 / 123

   search engine index contains n pages   : issues

can i claim a page is in the index if i only index the    rst 4000
bytes?
can i claim a page is in the index if i only index anchor text
pointing to the page?

there used to be (and still are?) billions of pages that are only
indexed by anchor text.

102 / 123

how can we estimate the size of the web?

103 / 123

sampling methods

random queries

random searches

random ip addresses

id93

104 / 123

variant: estimate relative sizes of indexes

there are signi   cant di   erences between indexes of di   erent
search engines.
di   erent engines have di   erent preferences.

max url depth, max count/host, anti-spam rules, priority rules
etc.

di   erent engines index di   erent things under the same url.

anchor text, frames, meta-keywords, size of pre   x etc.

105 / 123

sampling urls

ideal strategy: generate a random url

problem: random urls are hard to    nd (and sampling
distribution should re   ect    user interest   )
approach 1: id93 / ip addresses

in theory: might give us a true estimate of the size of the web
(as opposed to just relative sizes of indexex)

approach 2: generate a random url contained in a given
engine

su   ces for accurate estimation of relative size

107 / 123

random urls from random queries

idea: use vocabulary of the web for query generation

vocabulary can be generated from web crawl
use conjunctive queries w1 and w2

example: vocalists and rsi

get result set of one hundred urls from the source engine

choose a random url from the result set

this sampling method induces a weight w (p) for each page
p.

method was used by bharat and broder (1998).

108 / 123

checking if a page is in the index

either: search for url if the engine supports this
or: create a query that will    nd doc d with high id203

download doc, extract words
use 8 low frequency word as and query
call this a strong query for d
run query
check if d is in result set

problems

near duplicates
redirects
engine time-outs

109 / 123

random searches

choose random searches extracted from a search engine log
(lawrence & giles 97)

use only queries with small result sets
for each random query: compute ratio size(r1)/size(r2) of the
two result sets

average over random searches

112 / 123

advantages & disadvantages

advantage

might be a better re   ection of the human perception of
coverage

issues

samples are correlated with source of log (unfair advantage for
originating search engine)
duplicates
technical statistical problems (must have non-zero results,
ratio average not statistically sound)

113 / 123

random ip addresses [onei97,lawr99]

[lawr99] exhaustively crawled 2500 servers and extrapolated

estimated size of the web to be 800 million

117 / 123

advantages and disadvantages

advantages

can, in theory, estimate the size of the accessible web (as
opposed to the (relative) size of an index)
clean statistics
independent of crawling strategies

disadvantages

many hosts share one ip (    oversampling)
hosts with large web sites don   t get more weight than hosts
with small web sites (    possible undersampling)
sensitive to spam (multiple ips for same spam server)
again, duplicates

118 / 123

conclusion

many di   erent approaches to web size estimation.

none is perfect.

the problem has gotten much harder.

there hasn   t been a good study for a couple of years.

great topic for a thesis!

122 / 123

resources

chapter 19 of iir
resources at http://cislmu.org

hal varian explains google second price auction:
http://www.youtube.com/watch?v=k7l0a2pvhpq
size of the web queries
trademark issues (geico and vuitton cases)
how ads are priced
henzinger, finding near-duplicate web pages: a large-scale
evaluation of algorithms, acm sigir 2006.

123 / 123

