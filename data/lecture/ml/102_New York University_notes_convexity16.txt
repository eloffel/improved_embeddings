gradient, subgradient and how they may a   ect your

grade(ient)

david sontag & yoni halpern

february 7, 2016

1

introduction

the goal of this note is to give background on id76 and the pegasos algorithm
by shalev-schwartz et al. the pegasos algorithm is a stochastic sub-id119 method
for solving id166 problems which takes advantage of the structure and convexity of the id166
id168. we describe each of these terms in the upcoming sections.

2 convexity

a set x     rd is a convex set if for any (cid:126)x, (cid:126)y     x and 0            1,

  (cid:126)x + (1       )(cid:126)y     x

informally, if for any two points (cid:126)x, (cid:126)y that are in the set every point on the line connecting
(cid:126)x and (cid:126)y is also included in the set, then the set is convex. see figure 1 for examples of
non-convex and convex sets.

a function f : x     r is convex for a convex set x if    (cid:126)x, (cid:126)y     x and 0            1,

f (  (cid:126)x + (1       )(cid:126)y)       f ((cid:126)x) + (1       )f ((cid:126)y)

(1)

informally, a function is convex if the line between any two points on the curve always upper
bounds the function (see figure 3). we call a function strictly convex if the inequality in
eq. 1 is a strict inequality. see see figure 2 for examples of non-convex and convex functions.

1

figure 1: illustration of a non-convex and two convex sets in r2.

a function f (x) is concave is    f (x) is convex. importantly, it can be shown that strictly
convex functions always have a unique minima.

for a function f (x) de   ned over the real line, one can show that f (x) is convex if and
only if d2
dx2 f     0    x. just as before, strict convexity occurs when the inequality is strict.
for example, consider f (x) = x2. the    rst derivative of f (x) is given by d
dx f = 2x and its
second derivative by d2
dx2 f = 2. since this is always strictly greater than 0, we have proven
that f (x) = x2 is strictly convex. as a second example, consider f (x) = log(x). the    rst
derivative is d
x2 . since this is negative
for all x > 0, we have proven that log(x) is a concave function over r+.

x, and its second derivative is given by d2

dx2 f =     1

dxf = 1

this matters because optimization for convex functions is easy. in particular, one can
show that nearly any reasonable optimization method, such as id119 (where one
starts at arbitrary point, moves a little bit in the direction opposite to the gradient, and then
repeats), is guaranteed to reach a global optimum of the function. note that whereas the
minimization of convex functions is easy, likewise, the maximization of concave functions is
easy.

figure 2: illustration of a non-convex and two convex functions over x = r.

2

not convex:convex:x={   x   r2:a   x   b}set speci   ed by linear inequalities:not convex:convex:xf(x)xxf(x)f(x)=x2(cid:88)

i

figure 3: convexity: taking a weigted average of the values of the function (green) is greater
than or equal to evaluating the function at a point which is the weighted average of the
arguments (red).

2.1 combining convex functions

certain methods of combining convex functions preserves their convexity. these combination
rules are useful to be able to look at a function composed of simple parts and determine
quickly that it is also convex. for our purposes now, we note that a non-negative weighted
sum of convex functions is convex:

g =

cifi is convex if all fi are convex and ci     0.

additionally, a pointwise maximum of convex functions is convex.

h = max{fi(w), fj(w)} is convex if all fi and fj are convex.

(2)

(3)

for more detail on convexity preserving operations see chapter 3 of boyd and vandenberghe   s
id76 (link).

2.2 the primal id166 objective is convex in w and b

recall that primal id166 objective can be written as:

f (w, b) =

1
2||w||2 +

(cid:88)

i

max{0, 1     (yiw    xi     b)}.

3

check for yourself that the above rules can be used to quickly prove that the above function
is convex by breaking it into simpler parts with recognizable convexity.

2.3 convex functions and greedy descent

convex functions have an important property that allows us to search for a minimum using

a greedy search method. if f is convex, with a global minimizer w    (i.e. f (w   )     f (w)    w)
then from any point w0, there is a connected path w0     w    such that for every point wi
along the path, we have that f (wi)     f (w0). this property allows us to use a greedy search
method which always takes steps to reduce f (w) without worrying that it will lead to a
sub-optimal solution. this property follows from the de   nition of convexity (i.e. equation 1).
this brings us to our next section on greedy descent methods.

3 greedy descent methods

let   s say we want to minimize some di   erentiable function f (w). the following greedy
descent algorithm is a template for many optimization techniques. we will give some more
detail about each of these steps in the upcoming sections.

algorithm 1 greedy descent

input: a convex, di   erentiable function f .
output: wt, a minimizer of f .
initialize w0 = 0, t = 0
while not converged do
choose a direction pt
choose a stepsize   t
update wt+1     wt +   tpt
test for convergence
t     t + 1
end while

3.1 choosing a direction p

we can choose p =       f (steepest descent). later in this note we will see the stochastic
id119 algorithm which uses an approximation to the gradient. many other methods
exist for choosing a direction, but we will not discuss them here.

4

3.2 choosing a stepsize

many options here:

    constant stepsize:   t = c.
    decaying stepsize:   t = c/t (can also use di   erent rates of decay (e.g.
    backtracking linesearch: start with   t = c. check for a decrease: is f (wt +   tp) lower
than f (wt)? if the decrease condition is not met, multiply   t by a decaying factor   ,
(common choice is    = 0.5) and repeat until the decrease condition is met. (prove to
yourself that this method will not terminate until it reaches a local minimum.)

1   
t

).

the ipython notebook linked to on the course website gives interactive examples of the e   ects
of choosing a stepsize rule.

3.3 test for convergence

again, many options exist here:

    fixed number of iterations: terminate if t     t .
    small increase: terminate if f (wt+1)     f (wt)      .
    small change: terminate if ||wt+1     wt||      .

4 sub-id119 methods

notice that the id166 objective is not continously di   erentiable. we cannot directly apply
id119 but we can apply subid119.

the subgradient of a convex function f at w0 is formally de   ned as all vectors v such that

for any other point w

f (w)     f (w0)     v    (w     w0)

(4)

if f is di   erentiable at w0, then the subgradient contains only one vector which is the
gradient    f (w0). however, when f is not di   erentiable, there may be many di   erent values
for v that satisfy this inequality (figure 4).

5

figure 4: subgradient: function a is di   erentiable and only has a single subgradient at
each point function b is not di   erentiable at a single point. at that point it has many
subgradients. (subtangent lines are shown in blue.)

5 stochastic sub-id119 methods

notice that the id166 objective contains an average over data points. we can approximate
this average by looking at a single data point at a time. this serves as the basis for stochastic
id119 methods. at each iteration we randomly choose a single data point to look
at, uniformly from the set of all data points.

instead of calculating the exact gradient by summing over all data points, we approximate
it by looking at only a single data point. (mini-batch methods exist which interpolate
between the two extremes of stochastic id119 and traditional id119. in
a mini-batch method, the sum is approximated by looking at a small set of training points.)

6 putting it all together

the pegasos algorithm by shalev-schwartz et al. is a stochastic subid119 method
on the primal objective of the id166 function (by now you should know what each of those
terms means).

recall once more the id166 objective with m data points:

f (w) =

1
2||w||2 + c

max{0, 1     (yiw    xi)}.

m   1(cid:88)

i=0

here we assume that b = 0, so we are solving the id166 with an unbiased hyperplane. the

6

following is a subgradient with respect to w (verify for yourself):

m   1(cid:88)

i=1

g(w) = w     c

1 [yiw    xi < 1] yixi

a stochastic version of the algorithm uses the following approximation to the subgradient:

  g(w) = w     cm 1 [yiwt    xi < 1] yixi

where i is chosen uniformly at random from [0... m-1] at each step.

the subgradient gives a direction of movement, we also need to choose a stepsize. the

pegasos algorithm uses a decaying stepsize of   t = cm
t

.
we can now put the full pesasos algorithm together:

algorithm 2 pegasos algorithm

output: wt, an approximate minimizer of f , the id166 primal objective function.
initialize w1 = 0, t = 1
while not converged do

choose a direction: pt          g(wt, bt)
choose a stepsize:   t     cm
update wt+1     wt +   tpt
t     t + 1
test for convergence
end while

t

7

