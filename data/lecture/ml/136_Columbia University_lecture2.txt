machine learning for

data science

basic concepts

k-nearest neighbors

ansaf salleb-aouissi

coms 4721     spring 2014

outline

1. unsupervised learning

2. supervised learning

3. binary classi   cation

4. instance-based learning: k-nearest neighbors

5. training and testing

coprtight c(cid:13)ansaf salleb-aouissi: coms 4721     machine learning for data science.

1

unsupervised learning

coprtight c(cid:13)ansaf salleb-aouissi: coms 4721     machine learning for data science.

2

!"#$%&"'('!"#$%&"')'unsupervised learning

examples: id116, gaussian mixtures, hierarchical id91,
spectral id91, etc.

coprtight c(cid:13)ansaf salleb-aouissi: coms 4721     machine learning for data science.

3

!"#$%&"'('!"#$%&"')'supervised learning

coprtight c(cid:13)ansaf salleb-aouissi: coms 4721     machine learning for data science.

4

!"#$%&"'('!"#$%&"')'supervised learning

examples: support vector machines, neural networks, decision
trees, k-nearest neighbors, naive bayes, etc.

coprtight c(cid:13)ansaf salleb-aouissi: coms 4721     machine learning for data science.

5

!"#$%&"'('!"#$%&"')'*"+,-,./'0.%/1#&2'supervised vs. unsupervised

unsupervised learning:
learning a model from unlabeled data.

supervised learning:
learning a model from labeled data.

coprtight c(cid:13)ansaf salleb-aouissi: coms 4721     machine learning for data science.

6

supervised learning

training data:   examples    x with    labels    y.

(x1, y1), . . . , (xn, yn) / xi     rd

    classi   cation: y is discrete. to simplify, y     {   1, +1}

f : rd        {   1, +1}

f is called a binary classi   er.

    regression: y is a real value, y     r

f : rd        r

f is called a regressor.

coprtight c(cid:13)ansaf salleb-aouissi: coms 4721     machine learning for data science.

7

supervised learning

classi   cation:

coprtight c(cid:13)ansaf salleb-aouissi: coms 4721     machine learning for data science.

8

!"#$%&"'('!"#$%&"')'!"#$%&"'('!"#$%&"')'!"#$%&"'('!"#$%&"')'!"#$%&"'('!"#$%&"')'!"#$%&"'('!"#$%&"')'supervised learning

regression:

example: income in function of age.

coprtight c(cid:13)ansaf salleb-aouissi: coms 4721     machine learning for data science.

9

!"#$%&'($")"supervised learning

regression:

coprtight c(cid:13)ansaf salleb-aouissi: coms 4721     machine learning for data science.

10

!"#$%&'($")"supervised learning

regression:

coprtight c(cid:13)ansaf salleb-aouissi: coms 4721     machine learning for data science.

11

!"#$%&'($")"supervised learning

regression:

coprtight c(cid:13)ansaf salleb-aouissi: coms 4721     machine learning for data science.

12

!"#$%&'($")"training and testing

coprtight c(cid:13)ansaf salleb-aouissi: coms 4721     machine learning for data science.

13

!"#$%$%&'()*'+,'-.&/"$*01'+/2).'345'training and testing

coprtight c(cid:13)ansaf salleb-aouissi: coms 4721     machine learning for data science.

14

!"#$%$%&'()*'+,'-.&/"$*01'+/2).'345'6%7/1)8''&)%2)"8''#&)8''4#1$.9'(*#*:(8';$<7/2)'=")2$*'#1/:%*'>'=")2$*'9)(?%/'training and testing

note: not every ml method builds a model!

coprtight c(cid:13)ansaf salleb-aouissi: coms 4721     machine learning for data science.

15

!"#$%$%&'()*'+,'-.&/"$*01'+/2).'345'6%7/1)8''&)%2)"8''#&)8''4#1$.9'(*#*:(8';$<7/2)'=")2$*'#1/:%*'>'=")2$*'9)(?%/'k-nearest neighbors
    a basic non-parametric instance-based learning method.
    lazy learning (why?).
    assumes all examples (instances) are points in the d dimen-

sional space rd.

    uses the standard euclidian distance to de   ne nearest neigh-
bors. the distance between two instances (examples) xi and
xj is de   ned by:

(cid:118)(cid:117)(cid:117)(cid:117)(cid:116) d(cid:88)

k=1

d(xi, xj) =

(xik     xjk)2

    what do we do when features are at di   erent scales? (e.g.,

weight in pounds and height in feet).

    label can be either discrete-valued or real-valued (qualitative

or quantitative).

coprtight c(cid:13)ansaf salleb-aouissi: coms 4721     machine learning for data science.

16

k-nearest neighbors

training algorithm:
add each training example (x, y) to the dataset d.
x     rd, y     {+1,    1}.

classi   cation algorithm:

given an example xq to be classi   ed. suppose nk(xq) is the set of
the k-nearest neighbors of xq.

  yq = sign( (cid:88)

yi)

xi   nk(xq)

coprtight c(cid:13)ansaf salleb-aouissi: coms 4721     machine learning for data science.

17

k-nearest neighbors

training algorithm:
add each training example (x, y) to the dataset d
x     rd, y     {+1,    1}.

classi   cation algorithm:

given an example xq to be classi   ed. suppose nk(xq) is the set of
the k-nearest neighbors of xq.

  yq = sign( (cid:88)

yi)

xi   nk(xq)

question1: what if the sum is zero?

question2: how to extend it to the regression problem?

coprtight c(cid:13)ansaf salleb-aouissi: coms 4721     machine learning for data science.

18

k-nearest neighbors

3-nn. credit: introduction to statistical learning.

coprtight c(cid:13)ansaf salleb-aouissi: coms 4721     machine learning for data science.

19

k-nearest neighbors

credit: introduction to statistical learning.

question: can you draw an approximate decision boundary for k = 3?

coprtight c(cid:13)ansaf salleb-aouissi: coms 4721     machine learning for data science.

20

k-nearest neighbors

credit: introduction to statistical learning.

question: what are the pros and cons of id92?

coprtight c(cid:13)ansaf salleb-aouissi: coms 4721     machine learning for data science.

21

k-nearest neighbors

pros:
+ simple to implement.
+ works well in practice.
+ does not require to build a model, make assumptions, tune

parameters.

+ can be extended easily with news examples.

cons:

- requires large space to store the entire training dataset.
- slow! given n examples and d features. the method takes

o(n    d) to run.

- su   ers from curse of dimensionality.

question: improvements?

coprtight c(cid:13)ansaf salleb-aouissi: coms 4721     machine learning for data science.

22

applications of id92

credit: document spectrum for layout analysis. l. o   gorman. tpami 1993

coprtight c(cid:13)ansaf salleb-aouissi: coms 4721     machine learning for data science.

23

applications of id92

document spectrum for document analysis.

credit: document spectrum for layout analysis. l. o   gorman. tpami 1993

coprtight c(cid:13)ansaf salleb-aouissi: coms 4721     machine learning for data science.

24

applications of id92

1. information retrieval.
2. handwritten character classi   cation using nearest neighbor in

large databases. pami 1994.

3. oversampling.
4. etc.

further readings:
1. duda and hart book.
2. tom mitchell book.

coprtight c(cid:13)ansaf salleb-aouissi: coms 4721     machine learning for data science.

25

training and testing

question: how can we be con   dent about f predicting y given x?

coprtight c(cid:13)ansaf salleb-aouissi: coms 4721     machine learning for data science.

26

!"#$%$%&'()*'+,'-.&/"$*01'+/2).'345'6%7/1)8''&)%2)"8''#&)8''4#1$.9'(*#*:(8';$<7/2)'=")2$*'#1/:%*'>'=")2$*'9)(?%/'