csc321 lecture 14: optimizing the input

roger grosse

roger grosse

csc321 lecture 14: optimizing the input

1 / 29

overview

recall the computation graph:

from this graph, you could compute    l/   x, but we never made use
of this.

this lecture: lots of fun things you can do by running gradient
descent on the input!

roger grosse

csc321 lecture 14: optimizing the input

2 / 29

overview

use cases for input gradients:

visualizing what learned features represent

visualizing image gradients
optimizing an image to maximize activations

adversarial inputs

   deep dream   

roger grosse

csc321 lecture 14: optimizing the input

3 / 29

feature visualization

recall: we can understand what    rst-layer features are doing by
visualizing the weight matrices.
higher-level weight matrices are hard to interpret.

fully connected

convolutional

the better the input matches these weights, the more the feature
activates.

obvious generalization: visualize higher-level features by seeing what
inputs activate them.

roger grosse

csc321 lecture 14: optimizing the input

4 / 29

826m.d.zeilerandr.fergus(a)(b)(c)(d)fig.5.(a):1stlayerfeatureswithoutfeaturescaleclipping.notethatonefeaturedom-inates.(b):1stlayerfeaturesfromkrizhevskyetal.[18].(c):our1stlayerfeatures.thesmallerstride(2vs4)and   ltersize(7x7vs11x11)resultsinmoredistinctivefeaturesandfewer   dead   features.(d):visualizationsof2ndlayerfeaturesfromkrizhevskyetal.[18].(e):visualizationsofour2ndlayerfeatures.thesearecleaner,withnoaliasingartifactsthatarevisiblein(d).1&2).thismodel,showninfig.3,signi   cantlyoutperformsthearchitectureofkrizhevskyetal.[18],beatingtheirsinglemodelresultby1.7%(testtop-5).whenwecombinemultiplemodels,weobtainatesterrorof14.8%,animprove-mentof1.6%.thisresultisclosetothatproducedbythedata-augmentationapproachesofhoward[15],whichcouldeasilybecombinedwithourarchitec-ture.however,ourmodelissomewayshortofthewinnerofthe2013id163classi   cationcompetition[28].table1.id1632012/2013classi   cationerrorrates.the   indicatesmodelsthatweretrainedonbothid1632011and2012trainingsets.valvaltesterror%top-1top-5top-5gunjietal.[12]--26.2decaf[7]--19.2krizhevskyetal.[18],1convnet40.718.2      krizhevskyetal.[18],5convnets38.116.416.4krizhevskyetal.   [18],1convnets39.016.6      krizhevskyetal.   [18],7convnets36.715.415.3ourreplicationofkrizhevskyetal.,1convnet40.518.1      1convnetasperfig.338.416.5      5convnetsasperfig.3   (a)36.715.315.31convnetasperfig.3butwithlayers3,4,5:512,1024,512maps   (b)37.516.016.16convnets,(a)&(b)combined36.014.714.8howard[15]--13.5clarifai[28]--11.7varyingid163modelsizes:intable2,we   rstexplorethearchitectureofkrizhevskyetal.[18]byadjustingthesizeoflayers,orremovingthementirely.ineachcase,themodelistrainedfromscratchwiththerevisedarchitecture.removingthefullyconnectedlayers(6,7)onlygivesaslightincreaseinerror(infeature visualization

one way to formalize: pick the images in the training set which
activate a unit most strongly.

here   s the visualization for layer 1:

roger grosse

csc321 lecture 14: optimizing the input

5 / 29

feature visualization

layer 3:

roger grosse

csc321 lecture 14: optimizing the input

6 / 29

feature visualization

layer 4:

roger grosse

csc321 lecture 14: optimizing the input

7 / 29

feature visualization

layer 5:

roger grosse

csc321 lecture 14: optimizing the input

8 / 29

feature visualization

higher layers seem to pick up more abstract, high-level information.
problems?

roger grosse

csc321 lecture 14: optimizing the input

9 / 29

feature visualization

higher layers seem to pick up more abstract, high-level information.
problems?

can   t tell what the unit is actually responding to in the image.
we may read too much into the results, e.g. a unit may detect red, and
the images that maximize its activation will all be stop signs.

roger grosse

csc321 lecture 14: optimizing the input

9 / 29

feature visualization

higher layers seem to pick up more abstract, high-level information.
problems?

can   t tell what the unit is actually responding to in the image.
we may read too much into the results, e.g. a unit may detect red, and
the images that maximize its activation will all be stop signs.

can use input gradients to diagnose what the unit is responding to.
two possibilities:

see how to change an image to increase a unit   s activation
optimize an image from scratch to increase a unit   s activation

roger grosse

csc321 lecture 14: optimizing the input

9 / 29

overview

use cases for input gradients:

visualizing what learned features represent

visualizing image gradients
optimizing an image to maximize activations

adversarial inputs

   deep dream   

roger grosse

csc321 lecture 14: optimizing the input

10 / 29

feature visualization

input gradients can be hard to interpret.

take a good object recognition conv net (alex net) and compute the
gradient of log p(y =    cat   |x):

original image

gradient for    cat   

the full explanation is beyond the scope of this course.

part of it is that the network tries to detect cats everywhere; a pixel
may be consistent with cats in one location, but inconsistent with cats
in other locations.

roger grosse

csc321 lecture 14: optimizing the input

11 / 29

typical gradient of a neuron   visualize the gradient of a particular neuron with respect to the input x   do a forward pass:   compute the gradient of a particular neuron using backprop:typical gradient of a neuron   visualize the gradient of a particular neuron with respect to the input x   do a forward pass:   compute the gradient of a particular neuron using backprop:feature visualization

guided backprop is a total hack to prevent this cancellation.
do the backward pass as normal, but apply the relu nonlinearity to
all the activation error signals.

(cid:40)

y = relu(z)

  z =

  y
0

if z > 0 and   y > 0
otherwise

note: this isn   t really the gradient of anything!
we want to visualize what excites a given unit, not what suppresses it.
results

roger grosse

csc321 lecture 14: optimizing the input

12 / 29

guided id26backpropguided backpropguided backprop

roger grosse

csc321 lecture 14: optimizing the input

13 / 29

guided id26springerberget al, striving for simplicity: the all convolutional net (iclr 2015 workshops)overview

use cases for input gradients:

visualizing what learned features represent

visualizing image gradients
optimizing an image to maximize activations

adversarial inputs

   deep dream   

roger grosse

csc321 lecture 14: optimizing the input

14 / 29

gradient ascent on images

can do gradient ascent on an image to maximize the activation of a
given neuron.

requires a few tricks to make this work; see
https://distill.pub/2017/feature-visualization/

roger grosse

csc321 lecture 14: optimizing the input

15 / 29

gradient ascent on images

roger grosse

csc321 lecture 14: optimizing the input

16 / 29

gradient ascent on images

higher layers in the network often learn higher-level, more
interpretable representations

https://distill.pub/2017/feature-visualization/

roger grosse

csc321 lecture 14: optimizing the input

17 / 29

gradient ascent on images

higher layers in the network often learn higher-level, more
interpretable representations

roger grosse

csc321 lecture 14: optimizing the input

18 / 29

https://distill.pub/2017/feature-visualization/

overview

use cases for input gradients:

visualizing what learned features represent

visualizing image gradients
optimizing an image to maximize activations

adversarial inputs
   deep dream   

roger grosse

csc321 lecture 14: optimizing the input

19 / 29

adversarial examples

one of the most surprising    ndings about neural nets has been the
existence of adversarial inputs, i.e. inputs optimized to fool an
algorithm.
given an image for one category (e.g.    cat   ), compute the image
gradient to maximize the network   s output unit for a di   erent
category (e.g.    dog   )

perturb the image very slightly in this direction, and chances are, the
network will think it   s a dog!
works slightly better if you take the sign of the entries in the gradient;
this is called the fast gradient sign method.

roger grosse

csc321 lecture 14: optimizing the input

20 / 29

adversarial examples

the following adversarial examples are misclassi   ed as ostriches.
(middle = perturbation   10.)

roger grosse

csc321 lecture 14: optimizing the input

21 / 29

adversarial examples

2013: ha ha, how cute!

the paper which introduced adversarial examples was titled    intriguing
properties of neural networks.   

roger grosse

csc321 lecture 14: optimizing the input

22 / 29

adversarial examples

2013: ha ha, how cute!

the paper which introduced adversarial examples was titled    intriguing
properties of neural networks.   

2018: serious security threat

nobody has found a reliable method yet to defend against them.

7 of 8 proposed defenses accepted to iclr 2018 were cracked within
days.

adversarial examples transfer to di   erent networks trained on a totally
separate training set!
you don   t need access to the original network; you can train up a new
network to match its predictions, and then construct adversarial
examples for that.

attack carried out against proprietary classi   cation networks accessed
using prediction apis (metamind, amazon, google)

roger grosse

csc321 lecture 14: optimizing the input

22 / 29

adversarial examples

you can print out an adversarial image and take a picture of it, and it
still works!

can someone paint over a stop sign to fool a self-driving car?

roger grosse

csc321 lecture 14: optimizing the input

23 / 29

adversarial examples

an adversarial example in the physical world (network thinks it   s a
gun, from a variety of viewing angles!)

roger grosse

csc321 lecture 14: optimizing the input

24 / 29

overview

use cases for input gradients:

visualizing what learned features represent

visualizing image gradients
optimizing an image to maximize activations

adversarial inputs
   deep dream   

roger grosse

csc321 lecture 14: optimizing the input

25 / 29

deep dream

start with an image, and run a conv net on it.

pick a layer in the network.
change the image such that units which were already highly activated
get activated even more strongly.    rich get richer.   

i.e., set h = h, and then do backprop.
aside: this is a situation where you   d pass in something other than 1 to
backward pass in autograd.

repeat.

this will accentuate whatever features of an image already kind of
resemble the object.

roger grosse

csc321 lecture 14: optimizing the input

26 / 29

deep dream

roger grosse

csc321 lecture 14: optimizing the input

27 / 29

deep dream

roger grosse

csc321 lecture 14: optimizing the input

28 / 29

deep dream

roger grosse

csc321 lecture 14: optimizing the input

29 / 29

deep dreamcsc321: intro to machine learning and neural networks, winter 2016michael guerzhoy