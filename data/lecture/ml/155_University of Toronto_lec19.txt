csc321 lecture 19: id3

roger grosse

roger grosse

csc321 lecture 19: id3

1 / 25

overview

in generative modeling, we   d like to train a network that models a
distribution, such as a distribution over images.

one way to judge the quality of the model is to sample from it.

this    eld has seen rapid progress:

2009

2015

2018

roger grosse

csc321 lecture 19: id3

2 / 25

overview

four modern approaches to generative modeling:

id3 (today)

reversible architectures (next lecture)

autoregressive models (lecture 7, and next lecture)

id5 (csc412)

all four approaches have di   erent pros and cons.

roger grosse

csc321 lecture 19: id3

3 / 25

implicit generative models

implicit generative models implicitly de   ne a id203 distribution
start by sampling the code vector z from a    xed, simple distribution
(e.g. spherical gaussian)

the generator network computes a di   erentiable function g mapping
z to an x in data space

roger grosse

csc321 lecture 19: id3

4 / 25

implicit generative models

a 1-dimensional example:

roger grosse

csc321 lecture 19: id3

5 / 25

implicit generative models

https://blog.openai.com/generative-models/

roger grosse

csc321 lecture 19: id3

6 / 25

implicit generative models

this sort of architecture sounded preposterous to many of us, but
amazingly, it works.

roger grosse

csc321 lecture 19: id3

7 / 25

id3

the advantage of implicit generative models: if you have some
criterion for evaluating the quality of samples, then you can compute
its gradient with respect to the network parameters, and update the
network   s parameters to make the sample a little better
the idea behind id3 (gans): train two
di   erent networks

the generator network tries to produce realistic-looking samples
the discriminator network tries to    gure out whether an image came
from the training set or the generator network

the generator network tries to fool the discriminator network

roger grosse

csc321 lecture 19: id3

8 / 25

id3

roger grosse

csc321 lecture 19: id3

9 / 25

id3

let d denote the discriminator   s predicted id203 of being data
discriminator   s cost function: cross-id178 loss for task of classifying
real vs. fake images

jd = ex   d[    log d(x)] + ez[    log(1     d(g (z)))]

one possible cost function for the generator: the opposite of the
discriminator   s

jg =    jd

= const + ez[log(1     d(g (z)))]

this is called the minimax formulation, since the generator and
discriminator are playing a zero-sum game against each other:

jd

max

g

min
d

roger grosse

csc321 lecture 19: id3

10 / 25

id3

updating the discriminator:

roger grosse

csc321 lecture 19: id3

11 / 25

id3

updating the generator:

roger grosse

csc321 lecture 19: id3

12 / 25

id3

alternating training of the generator and discriminator:

roger grosse

csc321 lecture 19: id3

13 / 25

a better cost function

we introduced the minimax cost function for the generator:

jg = ez[log(1     d(g (z)))]

one problem with this is saturation.
recall from our lecture on classi   cation: when the prediction is really
wrong,

   logistic + squared error    gets a weak gradient signal
   logistic + cross-id178    gets a strong gradient signal

here, if the generated sample is really bad, the discriminator   s
prediction is close to 0, and the generator   s cost is    at.

roger grosse

csc321 lecture 19: id3

14 / 25

a better cost function

original minimax cost:

jg = ez[log(1     d(g (z)))]

modi   ed generator cost:

jg = ez[    log d(g (z))]

this    xes the saturation problem.

roger grosse

csc321 lecture 19: id3

15 / 25

id3

since gans were introduced in 2014, there have been hundreds of
papers introducing various architectures and training methods.

most modern architectures are based on the deep convolutional gan
(dc-gan), where the generator and discriminator are both conv nets.
gan zoo: https://github.com/hindupuravinash/the-gan-zoo

good source of horrible puns (veegan, checkhov gan, etc.)

roger grosse

csc321 lecture 19: id3

16 / 25

gan samples

celebrities:

karras et al., 2017. progressive growing of gans for improved quality, stability, and variation

roger grosse

csc321 lecture 19: id3

17 / 25

gan samples

bedrooms:

karras et al., 2017. progressive growing of gans for improved quality, stability, and variation

roger grosse

csc321 lecture 19: id3

18 / 25

gan samples

objects:

karras et al., 2017. progressive growing of gans for improved quality, stability, and variation

roger grosse

csc321 lecture 19: id3

19 / 25

gan samples

gans revolutionized generative modeling by producing crisp,
high-resolution images.
the catch: we don   t know how well they   re modeling the distribution.

can   t measure the log-likelihood they assign to held-out data.
could they be memorizing training examples? (e.g., maybe they
sometimes produce photos of real celebrities?)
we have no way to tell if they are dropping important modes from the
distribution.
see wu et al.,    on the quantitative analysis of decoder-based
generative models    for partial answers to these questions.

roger grosse

csc321 lecture 19: id3

20 / 25

cyclegan

style transfer problem: change the style of an image while preserving the
content.

data: two unrelated collections of images, one for each style

roger grosse

csc321 lecture 19: id3

21 / 25

cyclegan

if we had paired data (same content in both styles), this would be a
supervised learning problem. but this is hard to    nd.
the cyclegan architecture learns to do it from unpaired data.

train two di   erent generator nets to go from style 1 to style 2, and
vice versa.
make sure the generated samples of style 2 are indistinguishable from
real images by a discriminator net.
make sure the generators are cycle-consistent: mapping from style 1 to
style 2 and back again should give you almost the original image.

roger grosse

csc321 lecture 19: id3

22 / 25

cyclegan

roger grosse

csc321 lecture 19: id3

23 / 25

cyclegan

style transfer between aerial photos and maps:

roger grosse

csc321 lecture 19: id3

24 / 25

cyclegan

style transfer between road scenes and semantic segmentations (labels of
every pixel in an image by object category):

roger grosse

csc321 lecture 19: id3

25 / 25

