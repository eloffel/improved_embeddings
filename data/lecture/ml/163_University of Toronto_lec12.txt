csc321 lecture 12: image classi   cation

roger grosse

roger grosse

csc321 lecture 12: image classi   cation

1 / 20

midterm

tuesday, march 6, during class

50 minutes
what you   re responsible for:

lectures, up through l12 (this one)
tutorials, up through t4 (this week)
weekly homeworks, up through hw6
programming assignments, up through pa2

emphasis on concepts covered in multiple of the above

there will be some conceptual questions and some mathematical
questions (similar to individual steps of the weekly homeworks)

no formal proofs necessary, but you should justify your answers.

practice exams will be posted.

roger grosse

csc321 lecture 12: image classi   cation

2 / 20

overview

object recognition is the task of identifying which object category is
present in an image.

it   s challenging because objects can di   er widely in position, size,
shape, appearance, etc., and we have to deal with occlusions, lighting
changes, etc.
why we care about it

direct applications to image search
closely related to id164, the task of locating all instances of
an object in an image

e.g., a self-driving car detecting pedestrians or stop signs

for the past 5 years, all of the best object recognizers have been
various kinds of conv nets.

roger grosse

csc321 lecture 12: image classi   cation

3 / 20

recognition datasets

in order to train and evaluate a machine learning system, we need to
collect a dataset. the design of the dataset can have major
implications.
some questions to consider:

which categories to include?
where should the images come from?
how many images to collect?
how to normalize (preprocess) the images?

roger grosse

csc321 lecture 12: image classi   cation

4 / 20

image classi   cation

conv nets are just one of many possible approaches to image
classi   cation. however, they have been by far the most successful for
the last 5 years.
biggest image classi   cation    advances    of the last two decades

datasets have gotten much larger (because of digital cameras and the
internet)
computers got much faster

graphics processing units (gpus) turned out to be really good at
training big neural nets; they   re generally about 30 times faster than
cpus.

as a result, we could    t bigger and bigger neural nets.

roger grosse

csc321 lecture 12: image classi   cation

5 / 20

mnist dataset

mnist dataset of handwritten digits

categories: 10 digit classes
source: scans of handwritten zip codes from envelopes
size: 60,000 training images and 10,000 test images, grayscale, of size
28    28
id172: centered within in the image, scaled to a consistent
size

the assumption is that the digit recognizer would be part of a larger
pipeline that segments and normalizes images.

in 1998, yann lecun and colleagues built a conv net called lenet
which was able to classify digits with 98.9% test accuracy.

it was good enough to be used in a system for automatically reading
numbers on checks.

roger grosse

csc321 lecture 12: image classi   cation

6 / 20

id163

id163 is the modern object recognition benchmark dataset. it was
introduced in 2009, and has led to amazing progress in object recognition
since then.

roger grosse

csc321 lecture 12: image classi   cation

7 / 20

id163

used for the id163 large scale visual recognition challenge (ilsvrc),
an annual benchmark competition for object recognition algorithms

design decisions

categories: taken from a lexical database called id138

id138 consists of    synsets   , or sets of synonymous words
they tried to use as many of these as possible; almost 22,000 as of
2010
of these, they chose the 1000 most common for the ilsvrc
the categories are really speci   c, e.g. hundreds of kinds of dogs

size: 1.2 million full-sized images for the ilsvrc
source: results from image search engines, hand-labeled by
mechanical turkers

labeling such speci   c categories was challenging; annotators had to be
given the id138 hierarchy, wikipedia, etc.

id172: none, although the contestants are free to do
preprocessing

roger grosse

csc321 lecture 12: image classi   cation

8 / 20

id163

images and object categories vary on
a lot of dimensions

russakovsky et al.

roger grosse

csc321 lecture 12: image classi   cation

9 / 20

id163

size on disk:

mnist
60 mb

id163

50 gb

roger grosse

csc321 lecture 12: image classi   cation

10 / 20

lenet

here   s the lenet architecture, which was applied to handwritten digit
recognition on mnist in 1998:

roger grosse

csc321 lecture 12: image classi   cation

11 / 20

the!architecture!of!lenet5!size of a conv net

ways to measure the size of a network:

number of units. this is important because

roger grosse

csc321 lecture 12: image classi   cation

12 / 20

size of a conv net

ways to measure the size of a network:

number of units. this is important because the activations need to
be stored in memory during training (i.e. backprop).

roger grosse

csc321 lecture 12: image classi   cation

12 / 20

size of a conv net

ways to measure the size of a network:

number of units. this is important because the activations need to
be stored in memory during training (i.e. backprop).
number of weights. this is important because

roger grosse

csc321 lecture 12: image classi   cation

12 / 20

size of a conv net

ways to measure the size of a network:

number of units. this is important because the activations need to
be stored in memory during training (i.e. backprop).
number of weights. this is important because the weights need to
be stored in memory, and because the number of parameters
determines the amount of over   tting.

roger grosse

csc321 lecture 12: image classi   cation

12 / 20

size of a conv net

ways to measure the size of a network:

number of units. this is important because the activations need to
be stored in memory during training (i.e. backprop).
number of weights. this is important because the weights need to
be stored in memory, and because the number of parameters
determines the amount of over   tting.
number of connections. this is important because

roger grosse

csc321 lecture 12: image classi   cation

12 / 20

size of a conv net

ways to measure the size of a network:

number of units. this is important because the activations need to
be stored in memory during training (i.e. backprop).
number of weights. this is important because the weights need to
be stored in memory, and because the number of parameters
determines the amount of over   tting.
number of connections. this is important because there are
approximately 3 add-multiply operations per connection (1 for the
forward pass, 2 for the backward pass).

roger grosse

csc321 lecture 12: image classi   cation

12 / 20

size of a conv net

ways to measure the size of a network:

number of units. this is important because the activations need to
be stored in memory during training (i.e. backprop).
number of weights. this is important because the weights need to
be stored in memory, and because the number of parameters
determines the amount of over   tting.
number of connections. this is important because there are
approximately 3 add-multiply operations per connection (1 for the
forward pass, 2 for the backward pass).

we saw that a fully connected layer with m input units and n output
units has mn connections and mn weights.

the story for conv nets is more complicated.

roger grosse

csc321 lecture 12: image classi   cation

12 / 20

size of a conv net

roger grosse

csc321 lecture 12: image classi   cation

13 / 20

size of a conv net

# output units

fully connected layer

convolution layer

roger grosse

csc321 lecture 12: image classi   cation

13 / 20

size of a conv net

# output units

whi

whi

fully connected layer

convolution layer

roger grosse

csc321 lecture 12: image classi   cation

13 / 20

size of a conv net

# output units
# weights

fully connected layer

convolution layer

whi

whi

roger grosse

csc321 lecture 12: image classi   cation

13 / 20

size of a conv net

fully connected layer

convolution layer

# output units
# weights

whi

w 2h 2ij

whi

roger grosse

csc321 lecture 12: image classi   cation

13 / 20

size of a conv net

fully connected layer

convolution layer

# output units
# weights

whi

w 2h 2ij

whi
k 2ij

roger grosse

csc321 lecture 12: image classi   cation

13 / 20

size of a conv net

# output units
# weights
# connections

fully connected layer

convolution layer

whi

w 2h 2ij

whi
k 2ij

roger grosse

csc321 lecture 12: image classi   cation

13 / 20

size of a conv net

fully connected layer

convolution layer

# output units
# weights
# connections

whi

w 2h 2ij
w 2h 2ij

whi
k 2ij

roger grosse

csc321 lecture 12: image classi   cation

13 / 20

size of a conv net

fully connected layer

convolution layer

# output units
# weights
# connections

whi

w 2h 2ij
w 2h 2ij

whi
k 2ij

whk 2ij

roger grosse

csc321 lecture 12: image classi   cation

13 / 20

size of a conv net

sizes of layers in lenet:

layer

type

c1
s2
c3
s4
f5
f6

output

convolution

pooling

convolution

pooling

fully connected
fully connected
fully connected

# units # connections # weights
150
0
2400
0
48,000
10,080
840

117,600
4704
240,000
1600
48,000
10,080
840

4704
1176
1600
400
120
84
10

conclusions?

roger grosse

csc321 lecture 12: image classi   cation

14 / 20

size of a conv net

rules of thumb:

most of the units and connections are in the convolution layers.
most of the weights are in the fully connected layers.

if you try to make layers larger, you   ll run up against various resource
limitations (i.e. computation time, memory)

conv nets have gotten a lot larger since 1998!

roger grosse

csc321 lecture 12: image classi   cation

15 / 20

size of a conv net

classi   cation task

lenet (1989)
digits

lenet (1998) alexnet (2012)
digits

objects

roger grosse

csc321 lecture 12: image classi   cation

16 / 20

size of a conv net

classi   cation task
categories

lenet (1989)
digits
10

lenet (1998) alexnet (2012)
digits
10

objects
1,000

roger grosse

csc321 lecture 12: image classi   cation

16 / 20

size of a conv net

classi   cation task
categories
image size

lenet (1989)
digits
10
16    16

lenet (1998) alexnet (2012)
digits
10
28    28

objects
1,000
256    256    3

roger grosse

csc321 lecture 12: image classi   cation

16 / 20

size of a conv net

classi   cation task
categories
image size
training examples

lenet (1989)
digits
10
16    16
7,291

lenet (1998) alexnet (2012)
digits
10
28    28
60,000

objects
1,000
256    256    3
1.2 million

roger grosse

csc321 lecture 12: image classi   cation

16 / 20

size of a conv net

classi   cation task
categories
image size
training examples
units

lenet (1989)
digits
10
16    16
7,291
1,256

lenet (1998) alexnet (2012)
digits
10
28    28
60,000
8,084

objects
1,000
256    256    3
1.2 million
658,000

roger grosse

csc321 lecture 12: image classi   cation

16 / 20

size of a conv net

classi   cation task
categories
image size
training examples
units
parameters

lenet (1989)
digits
10
16    16
7,291
1,256
9,760

lenet (1998) alexnet (2012)
digits
10
28    28
60,000
8,084
60,000

objects
1,000
256    256    3
1.2 million
658,000
60 million

roger grosse

csc321 lecture 12: image classi   cation

16 / 20

size of a conv net

classi   cation task
categories
image size
training examples
units
parameters
connections

lenet (1989)
digits
10
16    16
7,291
1,256
9,760
65,000

lenet (1998) alexnet (2012)
digits
10
28    28
60,000
8,084
60,000
344,000

objects
1,000
256    256    3
1.2 million
658,000
60 million
652 million

roger grosse

csc321 lecture 12: image classi   cation

16 / 20

size of a conv net

classi   cation task
categories
image size
training examples
units
parameters
connections
total operations

lenet (1989)
digits
10
16    16
7,291
1,256
9,760
65,000
11 billion

lenet (1998) alexnet (2012)
digits
10
28    28
60,000
8,084
60,000
344,000
412 billion

objects
1,000
256    256    3
1.2 million
658,000
60 million
652 million
200 quadrillion (est.)

roger grosse

csc321 lecture 12: image classi   cation

16 / 20

alexnet

alexnet, 2012. 8 weight layers. 16.4% top-5 error (i.e. the network gets 5 tries to
guess the right category).

(krizhevsky et al., 2012)

they used lots of tricks we   ve covered in this course (relu units, weight decay,
data augmentation, sgd with momentum, dropout)

alexnet   s stunning performance on the ilsvrc is what set o    the deep learning
boom of the last 5 years.

roger grosse

csc321 lecture 12: image classi   cation

17 / 20

figure2:anillustrationofthearchitectureofourid98,explicitlyshowingthedelineationofresponsibilitiesbetweenthetwogpus.onegpurunsthelayer-partsatthetopofthe   gurewhiletheotherrunsthelayer-partsatthebottom.thegpuscommunicateonlyatcertainlayers.thenetwork   sinputis150,528-dimensional,andthenumberofneuronsinthenetwork   sremaininglayersisgivenby253,440   186,624   64,896   64,896   43,264   4096   4096   1000.neuronsinakernelmap).thesecondconvolutionallayertakesasinputthe(response-normalizedandpooled)outputofthe   rstconvolutionallayerand   ltersitwith256kernelsofsize5   5   48.thethird,fourth,and   fthconvolutionallayersareconnectedtooneanotherwithoutanyinterveningpoolingorid172layers.thethirdconvolutionallayerhas384kernelsofsize3   3   256connectedtothe(normalized,pooled)outputsofthesecondconvolutionallayer.thefourthconvolutionallayerhas384kernelsofsize3   3   192,andthe   fthconvolutionallayerhas256kernelsofsize3   3   192.thefully-connectedlayershave4096neuronseach.4reducingover   ttingourneuralnetworkarchitecturehas60millionparameters.althoughthe1000classesofilsvrcmakeeachtrainingexampleimpose10bitsofconstraintonthemappingfromimagetolabel,thisturnsouttobeinsuf   cienttolearnsomanyparameterswithoutconsiderableover   tting.below,wedescribethetwoprimarywaysinwhichwecombatover   tting.4.1dataaugmentationtheeasiestandmostcommonmethodtoreduceover   ttingonimagedataistoarti   ciallyenlargethedatasetusinglabel-preservingtransformations(e.g.,[25,4,5]).weemploytwodistinctformsofdataaugmentation,bothofwhichallowtransformedimagestobeproducedfromtheoriginalimageswithverylittlecomputation,sothetransformedimagesdonotneedtobestoredondisk.inourimplementation,thetransformedimagesaregeneratedinpythoncodeonthecpuwhilethegpuistrainingonthepreviousbatchofimages.sothesedataaugmentationschemesare,ineffect,computationallyfree.the   rstformofdataaugmentationconsistsofgeneratingimagetranslationsandhorizontalre   ec-tions.wedothisbyextractingrandom224   224patches(andtheirhorizontalre   ections)fromthe256   256imagesandtrainingournetworkontheseextractedpatches4.thisincreasesthesizeofourtrainingsetbyafactorof2048,thoughtheresultingtrainingexamplesare,ofcourse,highlyinter-dependent.withoutthisscheme,ournetworksuffersfromsubstantialover   tting,whichwouldhaveforcedustousemuchsmallernetworks.attesttime,thenetworkmakesapredictionbyextracting   ve224   224patches(thefourcornerpatchesandthecenterpatch)aswellastheirhorizontalre   ections(hencetenpatchesinall),andaveragingthepredictionsmadebythenetwork   ssoftmaxlayeronthetenpatches.thesecondformofdataaugmentationconsistsofalteringtheintensitiesofthergbchannelsintrainingimages.speci   cally,weperformpcaonthesetofrgbpixelvaluesthroughouttheid163trainingset.toeachtrainingimage,weaddmultiplesofthefoundprincipalcomponents,4thisisthereasonwhytheinputimagesinfigure2are224   224   3-dimensional.5googlenet

googlenet, 2014.

22 weight layers

fully convolutional (no fully
connected layers)

convolutions are broken down
into a bunch of smaller
convolutions

6.6% test error on id163

roger grosse

csc321 lecture 12: image classi   cation

(szegedy et al., 2014)
18 / 20

googlenet

they were really aggressive about cutting the number of parameters.
motivation: train the network on a large cluster, run it on a cell phone

memory at test time is the big constraint.
having lots of units is ok, since the activations only need to be stored
at training time (for id26).
parameters need to be stored both at training and test time, so these
are the memory bottleneck.

how they did it

no fully connected layers (remember, these have most of the weights)
break down convolutions into multiple smaller convolutions (since this
requires fewer parameters total)

googlenet has    only    2 million parameters, compared with 60 million
for alexnet
this turned out to improve generalization as well. (over   tting can still
be a problem, even with over a million images!)

roger grosse

csc321 lecture 12: image classi   cation

19 / 20

classi   cation

id163 results over the years. note that errors are top-5 errors (the network gets to
make 5 guesses).

year model
2010 hand-designed descriptors + id166
2011
compressed fisher vectors + id166
2012 alexnet
2013
2014 googlenet
2015

a variant of alexnet

deep residual nets

top-5 error

28.2%
25.8%
16.4%
11.7%
6.6%
4.5%

we   ll cover deep residual nets later in the course, since they require an idea we haven   t
covered yet.

human-performance is around 5.1%.

they stopped running the object recognition competition because the performance is
already so good.

roger grosse

csc321 lecture 12: image classi   cation

20 / 20

