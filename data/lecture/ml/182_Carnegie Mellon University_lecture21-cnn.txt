10-     601   introduction   to   machine   learning

machine   learning   department
school   of   computer   science
carnegie   mellon   university

deep   learning

(id98s)

deep   learning   readings:
murphy   28
bishop   -     -     
htf   -     -     
mitchell   -     -     

matt   gorid113y
lecture   21
april   05,   2017

1

reminders

    homework 5 (part ii):   peer   review

expectation:   you   

should   spend   at   most   1   
hour   on   your   reviews

    release:   wed,   mar.   29
    due:   wed,   apr.   05   at   11:59pm

    peer   tutoring
    homework 7:   deep   learning

    release:   wed,   apr.   05   
    watch for multiple due dates!!

2

id26

3

background

a   recipe   for   

machine   learning

1.   given   training   data:

3.   define   goal:

2.   choose   each   of   these:

    decision   function

    loss   function

4.   train   with   sgd:
(take   small   steps   
opposite   the   gradient)

4

training

id26

whiteboard

    example:   id26   for   calculus   quiz   #1

calculus   quiz   #1:
suppose   x   =   2   and   z   =   3,   what   are   dy/dx   
and   dy/dz for   the   function   below?

5

training

id26

automatic   differentiation       reverse   mode   (aka.   id26)

forward   computation
1. write   an   algorithm for   evaluating   the   function   y   =   f(x).   the   

algorithm   defines   a   directed   acyclic   graph,   where   each   variable   is   a   
node   (i.e.   the      computation   graph   )
2. visit   each   node   in   topological   order.   
for   variable   ui with   inputs   v1,   ,   vn
a. compute   ui =   gi(v1,   ,   vn)
b. store   the   result   at   the   node

backward   computation
1.
2. visit   each   node   in   reverse   topological   order.   

initialize all   partial   derivatives   dy/duj to   0   and   dy/dy =   1.
for   variable   ui =   gi(v1,   ,   vn)
a. we   already   know   dy/dui
b.

increment   dy/dvj by   (dy/dui)(dui/dvj)
(choice   of   algorithm   ensures   computing   (dui/dvj)   is   easy)

return   partial   derivatives   dy/dui   for   all   variables

6

training

id26

simple example: the goal is to compute j = (cid:43)(cid:81)(cid:98)((cid:98)(cid:66)(cid:77)(x2) + 3x2)
on the forward pass and the derivative dj

dx on the backward pass.

forward

j = cos(u)

u = u1 + u2

u1 = sin(t)

u2 = 3t

t = x2

(cid:89)=  sin(u)
du
(cid:89)=
du1
du1
dt
du2
dt

backward
dj
du
dj
du1
dj
dt
dj
dt
dj
dx

dj
du
dj
du1
dj
du2
dj
dt

dt
dx

(cid:89)=

(cid:89)=

(cid:89)=

dj
du2

(cid:89)=

dj
du

du
du2

,

du
du2

= 1

,

,

,

du
du1
du1
dt
du2
dt

= 1

= (cid:43)(cid:81)(cid:98)(t)

= 3

,

dt
dx

= 2x

7

training

id26

simple example: the goal is to compute j = (cid:43)(cid:81)(cid:98)((cid:98)(cid:66)(cid:77)(x2) + 3x2)
on the forward pass and the derivative dj

dx on the backward pass.

forward

j = cos(u)

u = u1 + u2

u1 = sin(t)

u2 = 3t

t = x2

(cid:89)=  sin(u)
du
(cid:89)=
du1
du1
dt
du2
dt

backward
dj
du
dj
du1
dj
dt
dj
dt
dj
dx

dj
du
dj
du1
dj
du2
dj
dt

dt
dx

(cid:89)=

(cid:89)=

(cid:89)=

dj
du2

(cid:89)=

dj
du

du
du2

,

du
du2

= 1

,

,

,

du
du1
du1
dt
du2
dt

= 1

= (cid:43)(cid:81)(cid:98)(t)

= 3

,

dt
dx

= 2x

8

training

case   1:
logistic   
regression

id26

output

input

  1

  2

  3

  m

   

forward
j = y  (cid:72)(cid:81)(cid:59) y + (1   y ) (cid:72)(cid:81)(cid:59)(1   y)

y =

a =

1

1 + (cid:50)(cid:116)(cid:84)( a)
d j=0

 jxj

=

backward
y 
dj
y
dy
dj
dj
dy
da

=

(1   y )
y   1
dy
=
da

,

+

dy
da

dj
da

da
d j

,

da
d j

dj
d j

dj
dxj

=

=

(cid:50)(cid:116)(cid:84)( a)

((cid:50)(cid:116)(cid:84)( a) + 1)2
= xj

dj
da

da
dxj

,

da
dxj

=  j

9

training

id26

(f) loss
j = 1

2 (y   y(d))2

output

hidden   layer

   

(e) output (sigmoid)
1+(cid:50)(cid:116)(cid:84)( b)

y =

1

(d) output (linear)

j=0  jzj

b = d

input

   

zj =

1

1+(cid:50)(cid:116)(cid:84)( aj ) ,  j

(c) hidden (sigmoid)

(b) hidden (linear)

i=0  jixi,  j

aj = m
(a) input
given xi,  i

10

training

id26

(f) loss
j = 1

2 (y   y )2

output

hidden   layer

   

(e) output (sigmoid)
1+(cid:50)(cid:116)(cid:84)( b)

y =

1

(d) output (linear)

j=0  jzj

b = d

input

   

zj =

1

1+(cid:50)(cid:116)(cid:84)( aj ) ,  j

(c) hidden (sigmoid)

(b) hidden (linear)

i=0  jixi,  j

aj = m
(a) input
given xi,  i

11

training

id26

case   2:
neural   
network

   

   

forward
j = y  (cid:72)(cid:81)(cid:59) y + (1   y ) (cid:72)(cid:81)(cid:59)(1   y)

y =

b =

1

1 + (cid:50)(cid:116)(cid:84)( b)
d j=0

 jzj

zj =

aj =

1

1 + (cid:50)(cid:116)(cid:84)( aj)
m i=0

 jixi

=

backward
y 
dj
y
dy
dj
dj
dy
db

=

+

dy
db

(1   y )
y   1
dy
=
db

,

dj
d j

dj
dzj
dj
daj

=

dj
db

db
d j

,

db
d j

=

=

dj
db
dj
dzj

,

db
dzj
dzj
daj

,

db
dzj
dzj
daj

=  j

=

dj
d ji

=

dj
daj

daj
d ji

,

daj
d ji

dj
dxi

=

dj
daj

daj
dxi

,

daj
dxi

=

(cid:50)(cid:116)(cid:84)( b)

((cid:50)(cid:116)(cid:84)( b) + 1)2
= zj

(cid:50)(cid:116)(cid:84)( aj)

((cid:50)(cid:116)(cid:84)( aj) + 1)2
= xi

 ji

d j=0

12

training

id26

case   2:
neural   
loss
network

sigmoid

   

   

linear

sigmoid

linear

forward
j = y  (cid:72)(cid:81)(cid:59) y + (1   y ) (cid:72)(cid:81)(cid:59)(1   y)

y =

b =

1

1 + (cid:50)(cid:116)(cid:84)( b)
d j=0

 jzj

zj =

aj =

1

1 + (cid:50)(cid:116)(cid:84)( aj)
m i=0

 jixi

=

backward
y 
dj
y
dy
dj
dj
dy
db

=

+

dy
db

(1   y )
y   1
dy
=
db

,

dj
d j

dj
dzj
dj
daj

=

dj
db

db
d j

,

db
d j

=

=

dj
db
dj
dzj

,

db
dzj
dzj
daj

,

db
dzj
dzj
daj

=  j

=

dj
d ji

=

dj
daj

daj
d ji

,

daj
d ji

dj
dxi

=

dj
daj

daj
dxi

,

daj
dxi

=

(cid:50)(cid:116)(cid:84)( b)

((cid:50)(cid:116)(cid:84)( b) + 1)2
= zj

(cid:50)(cid:116)(cid:84)( aj)

((cid:50)(cid:116)(cid:84)( aj) + 1)2
= xi

 ji

d j=0

13

training

id26

whiteboard

    sgd   for   neural   network
    example:   id26   for   neural   network

14

training

id26

id26   (auto.diff.   -      reverse   mode)

forward   computation
1. write   an   algorithm for   evaluating   the   function   y   =   f(x).   the   

algorithm   defines   a   directed   acyclic   graph,   where   each   variable   is   a   
node   (i.e.   the      computation   graph   )
2. visit   each   node   in   topological   order.   

a. compute   the   corresponding   variable   s   value
b. store   the   result   at   the   node

backward   computation
1.
2. visit   each   node   in   reverse   topological   order.   

initialize all   partial   derivatives   dy/duj to   0   and   dy/dy =   1.

for   variable   ui =   gi(v1,   ,   vn)
a. we   already   know   dy/dui
b.

increment   dy/dvj by   (dy/dui)(dui/dvj)
(choice   of   algorithm   ensures   computing   (dui/dvj)   is   easy)

return   partial   derivatives   dy/dui   for   all   variables

15

background

a   recipe   for   

gradients

machine   learning

1.   given   training   data:

3.   define   goal:

id26 can   compute   this   
gradient!   
and   it   s   a   special   case   of   a   more   
general   algorithm   called   reverse-     
mode   automatic   differentiation   that   
4.   train   with   sgd:
can   compute   the   gradient   of   any   
differentiable   function   efficiently!
(take   small   steps   
opposite   the   gradient)

2.   choose   each   of   these:

    decision   function

    loss   function

16

summary

1. neural   networks   

    provide   a   way   of   learning   features
    are   highly   nonlinear   prediction   functions
    (can   be)   a   highly   parallel   network   of   logistic   

regression   classifiers

    discover   useful   hidden   representations   of   the   

input

2. id26   

    provides   an   efficient   way   to   compute   gradients
    is   a   special   case   of   reverse-     mode   automatic   

differentiation

17

deep   learning

18

deep   learning   outline

    background:   computer   vision

    image   classification
    ilsvrc   2010   -      2016
    traditional   feature   extraction   methods
    convolution   as   feature   extraction
convolutional   neural   networks   (id98s)
    learning   feature   abstractions
    common   id98   layers:
    convolutional   layer
    max-     pooling   layer
   
    softmax layer
    relu layer

fully-     connected   layer   (w/tensor   input)

    background:   subgradient
    architecture:   lenet
    architecture:   alexnet
training   a   id98
    sgd   for   id98s
    id26   for   id98s

   

   

19

motivation

why   is   everyone   talking   
about   deep   learning?

    because   a   lot   of   money   is   invested   in   it   

    deepmind:      acquired   by   google   for   $400   

million

    dnnresearch:      three   person   startup   

(including   geoff   hinton)   acquired   by   google   
for   unknown   price   tag

    enlitic,   ersatz,   metamind,   nervana,   skylab:   

deep   learning   startups   commanding   millions   
of   vc   dollars

    because   it   made   the   front   page   of   the   

new   york   times

20

motivation

why   is   everyone   talking   
about   deep   learning?

1960s

1980s

1990s

2006

2016

deep   learning:   

    has   won   numerous   pattern   recognition   

    does   so   with   minimal   feature   

competitions

engineering

this   wasn   t   always   the   case!
since   1980s:    form   of   models   hasn   t   changed   much,   
but   lots   of   new   tricks   
    more   hidden   units
    better   (online)   optimization
    new   nonlinear   functions   (relus)
    faster   computers   (cpus   and   gpus)

21

background:   computer   vision

22

example:   image   classification

    id163 lsvrc-     2011   contest:   

    dataset:   1.2   million   labeled   images,   1000   classes
    task:   given   a   new   image,   label   it   with   the   correct   class
    multiclass classification   problem

    examples   from   http://image-     net.org/

23

24

25

26

example:   image   classification
traditional   feature   extraction   for   images:

    sift
    hog

27

example:   image   classification

id98   for   image   classification
(krizhevsky,   sutskever &   hinton,   2012)
15.3%   error   on   id163 lsvrc-     2012   contest

input   
image   
(pixels)

   

five   convolutional   layers   
(w/max-     pooling)

    three   fully   connected   layers

1000-     way   
softmax

28
figure 2: an illustration of the architecture of our id98, explicitly showing the delineation of responsibilities
between the two gpus. one gpu runs the layer-parts at the top of the    gure while the other runs the layer-parts

id98s   for   image   recognition

(slide from kaiming he   s recent presentation)

slide   from   kaiming he

fei-fei li & andrej karpathy & justin johnson
fei-fei li & andrej karpathy & justin johnson

lecture 7 -
lecture 7 -

78

27 jan 2016
27 jan 2016

29

convolution

30

what   s   a   convolution?

    basic   idea:

    key   point:

    pick   a   3x3   matrix   f   of   weights
    slide   this   over   an   image   and   compute   the      inner   product      

(similarity)   of   f   and   the   corresponding   field   of   the   image,   and   
replace   the   pixel   in   the   center   of   the   field   with   the   output   of   the   
inner   product   operation

    different   convolutions   extract   different   types   of   low-     level   

   features      from   an   image

    all   that   we   need   to   vary   to   generate   these   different   features   is   the   

weights   of   f

slide   adapted   from   william   cohen

background:   image   processing

a   convolution   matrix   is   used   in   image   processing   for   
tasks   such   as   edge   detection,   blurring,   sharpening,   etc.

input image

0
1
0
0
1
0
0

0
1
0
1
0
0
0

0
1
1
0
0
0
0

0
1
0
0
0
0
0

0
0
0
0
0
0
0

0
0
0
0
0
0
0

0
1
1
1
1
1
0

convolution

0
0
0

0
1
1

0
1
0

convolved   image

1
1
1
1
1

1
0
0
1
0

1
0
1
0
0

1
1
0
0
0

1
0
0
0
0

32

background:   image   processing

a   convolution   matrix   is   used   in   image   processing   for   
tasks   such   as   edge   detection,   blurring,   sharpening,   etc.

input image

0
1
0
0
1
0
0

0
1
0
1
0
0
0

0
1
1
0
0
0
0

0
1
0
0
0
0
0

0
0
0
0
0
0
0

0
0
0
0
0
0
0

0
1
1
1
1
1
0

convolution

0
0
0

0
1
1

0
1
0

convolved   image

3
2
2
3
1

2
0
2
1
0

2
2
1
0
0

3
1
0
0
0

1
0
0
0
0

33

background:   image   processing

a   convolution   matrix   is   used   in   image   processing   for   
tasks   such   as   edge   detection,   blurring,   sharpening,   etc.

convolution

input image

0
1
0
0
1
0
0

0
1
0
1
0
0
0

0
1
1
0
0
0
0

0
1
0
0
0
0
0

0
0
0
0
0
0
0

0
0
0
0
0
0
0

0
1
1
1
1
1
0

convolved   image

3
2
2
3
1

2
0
2
1
0

2
2
1
0
0

3
1
0
0
0

1
0
0
0
0

34

background:   image   processing

a   convolution   matrix   is   used   in   image   processing   for   
tasks   such   as   edge   detection,   blurring,   sharpening,   etc.

convolution

input image

0
1
0
0
1
0
0

0
1
0
1
0
0
0

0
1
1
0
0
0
0

0
1
0
0
0
0
0

0
0
0
0
0
0
0

0
0
0
0
0
0
0

0
1
1
1
1
1
0

convolved   image

3
2
2
3
1

2
0
2
1
0

2
2
1
0
0

3
1
0
0
0

1
0
0
0
0

35

background:   image   processing

a   convolution   matrix   is   used   in   image   processing   for   
tasks   such   as   edge   detection,   blurring,   sharpening,   etc.

convolution

input image

0
1
0
0
1
0
0

0
1
0
1
0
0
0

0
1
1
0
0
0
0

0
1
0
0
0
0
0

0
0
0
0
0
0
0

0
0
0
0
0
0
0

0
1
1
1
1
1
0

convolved   image

3
2
2
3
1

2
0
2
1
0

2
2
1
0
0

3
1
0
0
0

1
0
0
0
0

36

background:   image   processing

a   convolution   matrix   is   used   in   image   processing   for   
tasks   such   as   edge   detection,   blurring,   sharpening,   etc.

convolved   image

convolution

3

input image

0
1
0
0
1
0
0

0
1
0
1
0
0
0

0
1
1
0
0
0
0

0
1
0
0
0
0
0

0
0
0
0
0
0
0

0
0
0
0
0
0
0

0
1
1
1
1
1
0

37

background:   image   processing

a   convolution   matrix   is   used   in   image   processing   for   
tasks   such   as   edge   detection,   blurring,   sharpening,   etc.

convolved   image

convolution

3

2

input image

0
1
0
0
1
0
0

0
1
0
1
0
0
0

0
1
1
0
0
0
0

0
1
0
0
0
0
0

0
0
0
0
0
0
0

0
0
0
0
0
0
0

0
1
1
1
1
1
0

38

background:   image   processing

a   convolution   matrix   is   used   in   image   processing   for   
tasks   such   as   edge   detection,   blurring,   sharpening,   etc.

convolution

convolved   image

3

2

2

input image

0
1
0
0
1
0
0

0
1
0
1
0
0
0

0
1
1
0
0
0
0

0
1
0
0
0
0
0

0
0
0
0
0
0
0

0
0
0
0
0
0
0

0
1
1
1
1
1
0

39

background:   image   processing

a   convolution   matrix   is   used   in   image   processing   for   
tasks   such   as   edge   detection,   blurring,   sharpening,   etc.

convolution

convolved   image

3

2

2

3

input image

0
1
0
0
1
0
0

0
1
0
1
0
0
0

0
1
1
0
0
0
0

0
1
0
0
0
0
0

0
0
0
0
0
0
0

0
0
0
0
0
0
0

0
1
1
1
1
1
0

40

background:   image   processing

a   convolution   matrix   is   used   in   image   processing   for   
tasks   such   as   edge   detection,   blurring,   sharpening,   etc.

convolution

convolved   image

3

2

2

3

1

input image

0
1
0
0
1
0
0

0
1
0
1
0
0
0

0
1
1
0
0
0
0

0
1
0
0
0
0
0

0
0
0
0
0
0
0

0
0
0
0
0
0
0

0
1
1
1
1
1
0

41

background:   image   processing

a   convolution   matrix   is   used   in   image   processing   for   
tasks   such   as   edge   detection,   blurring,   sharpening,   etc.

convolution

convolved   image

2

2

3

1

3
2

input image

0
1
0
0
1
0
0

0
1
0
1
0
0
0

0
1
1
0
0
0
0

0
1
0
0
0
0
0

0
0
0
0
0
0
0

0
0
0
0
0
0
0

0
1
1
1
1
1
0

42

background:   image   processing

a   convolution   matrix   is   used   in   image   processing   for   
tasks   such   as   edge   detection,   blurring,   sharpening,   etc.

convolution

convolved   image

2

3

1

3
2

2
0

input image

0
1
0
0
1
0
0

0
1
0
1
0
0
0

0
1
1
0
0
0
0

0
1
0
0
0
0
0

0
0
0
0
0
0
0

0
0
0
0
0
0
0

0
1
1
1
1
1
0

43

background:   image   processing

a   convolution   matrix   is   used   in   image   processing   for   
tasks   such   as   edge   detection,   blurring,   sharpening,   etc.

convolution

input image

0
1
0
0
1
0
0

0
1
0
1
0
0
0

0
1
1
0
0
0
0

0
1
0
0
0
0
0

0
0
0
0
0
0
0

0
0
0
0
0
0
0

0
1
1
1
1
1
0

convolved   image

3
2
2
3
1

2
0
2
1
0

2
2
1
0
0

3
1
0
0
0

1
0
0
0
0

44

background:   image   processing

a   convolution   matrix   is   used   in   image   processing   for   
tasks   such   as   edge   detection,   blurring,   sharpening,   etc.

input image

0
1
0
0
1
0
0

0
1
0
1
0
0
0

0
1
1
0
0
0
0

0
1
0
0
0
0
0

0
0
0
0
0
0
0

0
0
0
0
0
0
0

0
1
1
1
1
1
0

identity   

convolution
0
0
0
0
0
0

0
1
0

convolved   image

1
1
1
1
1

1
0
0
1
0

1
0
1
0
0

1
1
0
0
0

1
0
0
0
0

45

background:   image   processing

a   convolution   matrix   is   used   in   image   processing   for   
tasks   such   as   edge   detection,   blurring,   sharpening,   etc.

input image

0
1
0
0
1
0
0

0
1
0
1
0
0
0

0
1
1
0
0
0
0

0
1
0
0
0
0
0

0
0
0
0
0
0
0

0
0
0
0
0
0
0

0
1
1
1
1
1
0

blurring

convolution
.1
.1
.1
.1
.1
.1

.1
.2
.1

convolved   image

.4 .5 .5 .5 .4
.4 .2
.3 .6 .3
.1
.5 .4 .4 .2
0
.1
.5 .6 .2
.4 .3
.1
0
0

46

what   s   a   convolution?

http://matlabtricks.com/post-     5/3x3-     convolution-     kernels-     with-     online-     demo

slide   from   william   cohen

what   s   a   convolution?

http://matlabtricks.com/post-     5/3x3-     convolution-     kernels-     with-     online-     demo

slide   from   william   cohen

what   s   a   convolution?

http://matlabtricks.com/post-     5/3x3-     convolution-     kernels-     with-     online-     demo

slide   from   william   cohen

what   s   a   convolution?

http://matlabtricks.com/post-     5/3x3-     convolution-     kernels-     with-     online-     demo

slide   from   william   cohen

what   s   a   convolution?

http://matlabtricks.com/post-     5/3x3-     convolution-     kernels-     with-     online-     demo

slide   from   william   cohen

what   s   a   convolution?

http://matlabtricks.com/post-     5/3x3-     convolution-     kernels-     with-     online-     demo

slide   from   william   cohen

what   s   a   convolution?

    basic   idea:

    key   point:

    pick   a   3x3   matrix   f   of   weights
    slide   this   over   an   image   and   compute   the      inner   product      

(similarity)   of   f   and   the   corresponding   field   of   the   image,   and   
replace   the   pixel   in   the   center   of   the   field   with   the   output   of   the   
inner   product   operation

    different   convolutions   extract   different   types   of   low-     level   

   features      from   an   image

    all   that   we   need   to   vary   to   generate   these   different   features   is   the   

weights   of   f

slide   adapted   from   william   cohen

downsampling

    suppose   we   use   a   convolution   with   stride   2
    only   9   patches   visited   in   input,   so   only   9   pixels   in   output

input image

1
0
0
1
0
0

1
0
1
0
0
0

1
1
0
0
0
0

1
0
0
0
0
0

0
0
0
0
0
0

1
1
1
1
1
0

convolved   image

convolution

1
1

1
1

54

downsampling

    suppose   we   use   a   convolution   with   stride   2
    only   9   patches   visited   in   input,   so   only   9   pixels   in   output

input image

1
0
0
1
0
0

1
0
1
0
0
0

1
1
0
0
0
0

1
0
0
0
0
0

0
0
0
0
0
0

1
1
1
1
1
0

convolved   image

3

convolution

1
1

1
1

55

downsampling

    suppose   we   use   a   convolution   with   stride   2
    only   9   patches   visited   in   input,   so   only   9   pixels   in   output

input image

1
0
0
1
0
0

1
0
1
0
0
0

1
1
0
0
0
0

1
0
0
0
0
0

0
0
0
0
0
0

1
1
1
1
1
0

convolved   image

3

3

convolution

1
1

1
1

56

downsampling

    suppose   we   use   a   convolution   with   stride   2
    only   9   patches   visited   in   input,   so   only   9   pixels   in   output

input image

1
0
0
1
0
0

1
0
1
0
0
0

1
1
0
0
0
0

1
0
0
0
0
0

0
0
0
0
0
0

1
1
1
1
1
0

convolved   image

3

3

1

convolution

1
1

1
1

57

downsampling

    suppose   we   use   a   convolution   with   stride   2
    only   9   patches   visited   in   input,   so   only   9   pixels   in   output

input image

1
0
0
1
0
0

1
0
1
0
0
0

1
1
0
0
0
0

1
0
0
0
0
0

0
0
0
0
0
0

1
1
1
1
1
0

convolution

1
1

1
1

convolved   image

3

1

3
3

58

downsampling

    suppose   we   use   a   convolution   with   stride   2
    only   9   patches   visited   in   input,   so   only   9   pixels   in   output

input image

1
0
0
1
0
0

1
0
1
0
0
0

1
1
0
0
0
0

1
0
0
0
0
0

0
0
0
0
0
0

1
1
1
1
1
0

convolution

1
1

1
1

convolved   image

1

3
3

3
1

59

downsampling

    suppose   we   use   a   convolution   with   stride   2
    only   9   patches   visited   in   input,   so   only   9   pixels   in   output

input image

1
0
0
1
0
0

1
0
1
0
0
0

1
1
0
0
0
0

1
0
0
0
0
0

0
0
0
0
0
0

1
1
1
1
1
0

convolution

1
1

1
1

convolved   image

3
3

3
1

1
0

60

downsampling

    suppose   we   use   a   convolution   with   stride   2
    only   9   patches   visited   in   input,   so   only   9   pixels   in   output

input image

1
0
0
1
0
0

1
0
1
0
0
0

1
1
0
0
0
0

1
0
0
0
0
0

0
0
0
0
0
0

1
1
1
1
1
0

convolution

1
1

1
1

convolved   image

3
1

1
0

3
3
1

61

downsampling

    suppose   we   use   a   convolution   with   stride   2
    only   9   patches   visited   in   input,   so   only   9   pixels   in   output

input image

1
0
0
1
0
0

1
0
1
0
0
0

1
1
0
0
0
0

1
0
0
0
0
0

0
0
0
0
0
0

1
1
1
1
1
0

convolution

1
1

1
1

convolved   image

1
0

3
3
1

3
1
0

62

downsampling

    suppose   we   use   a   convolution   with   stride   2
    only   9   patches   visited   in   input,   so   only   9   pixels   in   output

input image

1
0
0
1
0
0

1
0
1
0
0
0

1
1
0
0
0
0

1
0
0
0
0
0

0
0
0
0
0
0

1
1
1
1
1
0

convolution

1
1

1
1

convolved   image

3
3
1

3
1
0

1
0
0

63

convolutional   neural   nets

64

deep   learning   outline

    background:   computer   vision

    image   classification
    ilsvrc   2010   -      2016
    traditional   feature   extraction   methods
    convolution   as   feature   extraction
convolutional   neural   networks   (id98s)
    learning   feature   abstractions
    common   id98   layers:
    convolutional   layer
    max-     pooling   layer
   
    softmax layer
    relu layer

fully-     connected   layer   (w/tensor   input)

    background:   subgradient
    architecture:   lenet
    architecture:   alexnet
training   a   id98
    sgd   for   id98s
    id26   for   id98s

   

   

65

convolutional   neural   network   (id98)
   

typical   layers   include:
    convolutional   layer
    max-     pooling   layer
    fully-     connected   (linear)   layer
    relu layer   (or   some   other   nonlinear   activation   function)
    softmax
these   can   be   arranged   into   arbitrarily   deep   topologies

   

architecture   #1:   lenet-     5

66

convolutional   layer
id98   key   idea:   

treat   convolution   matrix   as   
parameters   and   learn   them!

input image

0
1
0
0
1
0
0

0
1
0
1
0
0
0

0
1
1
0
0
0
0

0
1
0
0
0
0
0

0
0
0
0
0
0
0

0
0
0
0
0
0
0

0
1
1
1
1
1
0

learned

convolution
  11   12   13
  21   22   23
  31   32   33

convolved   image

.4 .5 .5 .5 .4
.4 .2
.3 .6 .3
.1
.5 .4 .4 .2
0
.1
.5 .6 .2
.4 .3
.1
0
0

67

downsampling by   averaging
    downsampling by   averaging   used   to   be a   common   approach
    this   is   a   special   case   of   convolution   where   the   weights   are   fixed   to   a   

uniform   distribution

    the   example   below   uses   a   stride   of   2

input image

1
0
0
1
0
0

1
0
1
0
0
0

1
1
0
0
0
0

1
0
0
0
0
0

0
0
0
0
0
0

1
1
1
1
1
0

convolution

1/4 1/4
1/4 1/4

convolved   image

3/4 3/4 1/4
3/4 1/4 0
1/4 0
0

68

max-     pooling

    max-     pooling   is   another   (common)   form   of   downsampling
   

instead   of   averaging,   we   take   the   max   value   within   the   same   range   as   
the   equivalently-     sized   convolution

    the   example   below   uses   a   stride   of   2

input image

1
0
0
1
0
0

1
0
1
0
0
0

1
1
0
0
0
0

1
0
0
0
0
0

0
0
0
0
0
0

1
1
1
1
1
0

max-     
pooling

xi,j

xi,j+1

xi+1,j xi+1,j+1

max-     pooled   

image

1
1
1

1
1
0

1
0
0

69

multi-     class   output

output

   

hidden   layer

   

input

   

71

multi-     class   output

softmax layer:

(cid:50)(cid:116)(cid:84)(bk)
l=1 (cid:50)(cid:116)(cid:84)(bl)

yk =

output

 k

   

hidden   layer

   

input

   

k=1 y k (cid:72)(cid:81)(cid:59)(yk)

(f) loss

j = k
 k
bk = d

(e) output (softmax)
yk = (cid:50)(cid:116)(cid:84)(bk)

l=1 (cid:50)(cid:116)(cid:84)(bl)

(d) output (linear)

j=0  kjzj  k

(c) hidden (nonlinear)
zj =  (aj),  j

(b) hidden (linear)

i=0  jixi,  j

aj = m
(a) input
given xi,  i

72

training   a   id98

whiteboard

    sgd   for   id98s
    id26   for   id98s

73

common   id98   layers

whiteboard

    relu layer
    background:   subgradient
    fully-     connected   layer   (w/tensor   input)
    softmax layer
    convolutional   layer
    max-     pooling   layer

74

convolutional   layer

75

convolutional   layer

76

max-     pooling   layer

77

max-     pooling   layer

78

convolutional   neural   network   (id98)
   

typical   layers   include:
    convolutional   layer
    max-     pooling   layer
    fully-     connected   (linear)   layer
    relu layer   (or   some   other   nonlinear   activation   function)
    softmax
these   can   be   arranged   into   arbitrarily   deep   topologies

   

architecture   #1:   lenet-     5

79

architecture   #2:   alexnet

id98   for   image   classification
(krizhevsky,   sutskever &   hinton,   2012)
15.3%   error   on   id163 lsvrc-     2012   contest

input   
image   
(pixels)

   

five   convolutional   layers   
(w/max-     pooling)

    three   fully   connected   layers

1000-     way   
softmax

80
figure 2: an illustration of the architecture of our id98, explicitly showing the delineation of responsibilities
between the two gpus. one gpu runs the layer-parts at the top of the    gure while the other runs the layer-parts

id98s   for   image   recognition

(slide from kaiming he   s recent presentation)

slide   from   kaiming he

fei-fei li & andrej karpathy & justin johnson
fei-fei li & andrej karpathy & justin johnson

lecture 7 -
lecture 7 -

78

27 jan 2016
27 jan 2016

81

id98   visualizations

83

3d   visualization   of   id98
http://scs.ryerson.ca/~aharley/vis/conv/

convolution   of   a   color   image
    color   images   consist   of   3   floats   per   pixel   for   

rgb   (red,   green   blue)   color   values

a closer look at spatial dimensions:

    convolution   must   also   be   3-     dimensional

32x32x3 image
5x5x3 filter

32

activation map

28

convolve (slide) over all 
spatial locations

32

3

28

1

figure   from   fei-     fei li   &   andrej   karpathy &   justin   johnson   (cs231n)   
fei-fei li & andrej karpathy & justin johnson
fei-fei li & andrej karpathy & justin johnson

lecture 7 -
lecture 7 -

23

85
27 jan 2016
27 jan 2016

animation   of   3d   convolution

http://cs231n.github.io/convolutional-     networks/

figure   from   fei-     fei li   &   andrej   karpathy &   justin   johnson   (cs231n)   

86

mnist   digit   recognition   with   id98s   

(in   your   browser)

https://cs.stanford.edu/people/karpathy/convnetjs/demo/mnist.html

figure   from   andrej   karpathy

87

id98   summary

id98s

    are   used   for   all   aspects   of   computer   vision,   and   

have   won   numerous   pattern   recognition   
competitions

    able   learn   interpretable   features   at   different   levels   

of   abstraction

    typically,   consist   of   convolution layers,   pooling
layers,   nonlinearities,   and   fully   connected   layers

other   resources:

    readings   on   course   website
    andrej   karpathy,   cs231n   notes

http://cs231n.github.io/convolutional-     networks/

88

