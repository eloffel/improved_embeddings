the boosting approach to 

machine learning 

maria-florina balcan 

03/16/2015 

boosting 

    general method for improving the accuracy of any given 

learning algorithm. 

    works by creating a series of challenge datasets s.t. even 

modest performance on these can be used to produce an 
overall high-accuracy predictor. 

    works amazingly well in practice --- adaboost and its 

variations one of the top 10 algorithms. 

    backed up by solid foundations. 

readings:  

    the boosting approach to machine learning: an 

overview.  rob schapire, 2001 

 
    theory and applications of boosting.  nips tutorial.   
 

http://www.cs.princeton.edu/~schapire/talks/nips-tutorial.pdf 

plan for today:  

    motivation. 
     a bit of history. 
     adaboost: algo, guarantees, discussion. 

    focus on supervised classification. 

an example: spam detection 

    e.g., classify which emails are spam and which are important. 

not spam 

spam 

key observation/motivation: 

    easy to find rules of thumb that are often correct. 
 

    e.g.,    if buy now in the message, then predict spam.    
 
    e.g.,    if say good-bye to debt in the message, then predict spam.    
 

    harder to find single rule that is very highly accurate. 

an example: spam detection 

    boosting: meta-procedure that takes in an algo for finding rules 
of thumb (weak learner). produces a highly accurate rule, by calling 
the weak learner repeatedly on cleverly chosen datasets. 
 

 
s
l
i
a
m
e

         
         
         
   
 
         

   
   
   
   

apply weak learner to a subset of emails,  obtain rule of thumb 
apply to 2nd subset of emails, obtain 2nd rule of thumb 
apply to 3rd subset of emails, obtain 3rd rule of thumb 
repeat t times; combine weak rules into a single highly accurate rule. 

boosting: important aspects 

how to choose examples on each round? 
 

    typically, concentrate on    hardest    examples (those most 

often misclassified by previous rules of thumb) 

how to combine rules of thumb into single 
prediction rule? 

   

take (weighted) majority vote of rules of thumb 

historically   . 

weak learning vs strong/pac learning 

[kearns & valiant    88]:  defined weak learning: 
   
being able to predict better than random guessing 
(error    

        ) , consistently. 

1
2

    posed an open pb:    does there exist a boosting algo that 

turns a weak learner into a strong pac learner (that can 
produce arbitrarily accurate hypotheses)?    

    informally, given    weak    learning algo that can consistently 

find classifiers of error    
provably construct a single classifier with error         . 

        , a boosting algo would 

1
2

weak learning vs strong/pac learning 

strong (pac) learning 

weak learning 

        algo a 
                      
            
             > 0 
             > 0 
    a produces h s.t.: 

pr                                     

        algo a 
            > 0 
                      
            

         

             >

1
2
             > 0 
    a produces h s.t. 

   

[kearns & valiant    88]:  defined weak learning & 
posed an open pb of finding a boosting algo. 

pr                                     

surprisingly   . 

weak learning =strong (pac) learning 

original construction [schapire    89]: 
    poly-time boosting algo, exploits that we can 

learn a little on every distribution. 

    a modest booster obtained via calling the weak learning 

algorithm on 3 distributions. 

error =      <

1
2

             error 3    2     2    3 

    then amplifies the modest boost of accuracy by 

running this somehow recursively. 

    cool conceptually and technically, not very practical. 

an explosion of subsequent work 

adaboost (adaptive boosting) 

   a decision-theoretic generalization of on-line 
learning and an application to boosting    

[freund-schapire, jcss   97] 

godel prize winner 2003  

informal description adaboost 

    boosting: turns a weak algo into a strong (pac) learner. 

input: s={(x1,     1),    ,(xm,     m)};  
weak learning algo a (e.g., na  ve bayes, decision stumps) 

xi         ,                   = {   1,1} 

+ 

    for t=1,2,     ,t 
 

    construct dt on {x1,    , xm} 
    run a on dt producing ht:          {   1,1} (weak classifier) 

+ 

+ 

ht 

+ 

+ 
+ 

+ 

+ 

- 
- 

- 
- 
- 
- 

- 
- 

  t = pxi ~dt(ht xi     yi) error of ht over dt 

    output hfinal      = sign  
 

    =1

                    

 

roughly speaking dt+1 increases weight on xi if ht incorrect on xi ; 
decreases it on xi if ht  correct. 

adaboost (adaptive boosting) 

    weak learning algorithm a. 
    for t=1,2,     ,t 
 

    construct          on {        ,    ,         } 
    run a on dt producing ht 

constructing          

   

 d1 uniform on {x1,    , xm} 

[i.e., d1      =

1

    ] 

    given dt and ht set 

             
        
             
        

 e                if          =                    

 e             if                                 

        +1      =

             
        

 e                                     

   

        +1      =
         +1      =
 

         =

1
2

ln

1             

        

> 0 

dt+1 puts half of weight on examples 
xi  where  ht  is  incorrect  &  half  on 
examples where ht is correct  

final hyp: hfinal      = sign                       

    

 

adaboost: a toy example 

weak classifiers:  vertical or horizontal half-planes (a.k.a. decision stumps) 

adaboost: a toy example 

adaboost: a toy example 

adaboost (adaptive boosting) 

    weak learning algorithm a. 
    for t=1,2,     ,t 
 

    construct          on {        ,    ,         } 
    run a on dt producing ht 

constructing          

   

 d1 uniform on {x1,    , xm} 

[i.e., d1      =

1

    ] 

    given dt and ht set 

             
        
             
        

 e                if          =                    

 e             if                                 

        +1      =

             
        

 e                                     

   

        +1      =
         +1      =
 

         =

1
2

ln

1             

        

> 0 

dt+1 puts half of weight on examples 
xi  where  ht  is  incorrect  &  half  on 
examples where ht is correct  

final hyp: hfinal      = sign                       

    

 

nice features of adaboost 

    very general: a meta-procedure, it can use any weak learning 

algorithm!!!  

(e.g., na  ve bayes, decision stumps) 

    very fast (single pass through data each round) & simple to 

code, no parameters to tune. 

    shift in mindset: goal is now just to find classifiers a 

bit better than random guessing. 

    grounded in rich theory. 

    relevant for big data age: quickly focuses on    core 

difficulties   , well-suited to distributed settings, where data 
must be communicated efficiently [balcan-blum-fine-mansour colt   12]. 

analyzing training error 

theorem          = 1/2              (error of         over         ) 

2
                                              exp     2            

 

    

so, if         ,                   > 0, then                                               exp     2     2      

the training error drops exponentially in t!!! 

to get                                                   , need only      =     

1
    2 log

1
    

 rounds  

adaboost is adaptive 

    does not need to know      or t a priori 
    can exploit                      

understanding the updates & id172 
claim: dt+1 puts half of the weight on xi where ht was incorrect  and 
half of the weight on xi where ht was correct. 

recall         +1      =

             
        

 e                                     

   

probabilities are equal!   

pr
        +1

                             

  =  

    :                           

             
        

            

= 

          

 

1
        

              = 

        
        

 

1             

        

=

        

1             

         1             

        

 

=

1                      

        

 

 
1             
 
                 =  

        

 

         =                 

  =  

    :        =                

             
        

               

=

1             

        

 
 
pr
        +1

 
 

         =                                                         

 

=                                

+                             

 

    :        =                

 

    :        =                

    :                           

 
 
= 1                              +                      = 2          1               
 

analyzing training error: proof intuition 
theorem          = 1/2              (error of         over         ) 

2
                                              exp     2            

 

    

    on round     , we increase weight of          for which         is wrong.   
    if                          incorrectly classifies         , 

- then          incorrectly classified by (wtd) majority of           s. 
- which implies final prob. weight of          is large. 

can show id203    

1
    

1

          

    

 

    since sum of prob. = 1, can   t have too many of high weight.   

can show # incorrectly classified                     

    

.  

and (          )     0

    

. 

analyzing training error: proof math 

step 1: unwrapping recurrence:         +1      =  
where               =                           

. 

    

[unthresholded weighted vote of         on          ] 

1
    

  exp                         

          

    

 

step 2: errs                                        .

    

 

step 3:            =   2          1             

    

    

2
=   1     4        

    

2
           2           

    

 

analyzing training error: proof math 

step 1: unwrapping recurrence:         +1      =  
where               =                           

. 

    

1
    

  exp                         

          

    

 

recall     1      =

1
    

 and         +1      =                

exp                                    

 

        

          +1      = 
                  
= 

exp                                    

exp                                    

        

        

        . 
 

exp                                    

        

= 
 
                     
=

1
    

                  

  

exp                       1          1         

           1

              1       

         

exp                1   1         

    1

 

  1
    

 

 exp            (    1   1          +   +                         )

    1           

=

 

1
    

 

exp                         

          

    

 

analyzing training error: proof math 

step 1: unwrapping recurrence:         +1      =  
where               =                           

. 

    

1
    

step 2: errs                                        .
 

    

  exp                         

          

    

 

 errs                          =

  1                                            
    

 

1
    
1
    

=

  1                         0
    

 

   

1
    

  exp                         
    

 

=           +1                

 

 =           .
 

    

    

    

exp loss 

0/1 loss 

1 

0 

analyzing training error: proof math 

step 1: unwrapping recurrence:         +1      =  
where               =                           

. 

    

1
    

step 2: errs                                        .

    

 

  exp                         

          

    

 

step 3:            =   2          1             

    

    

2
=   1     4        

    

2
           2           

    

 

note: recall          = 1                              +                      = 2          1               

         minimizer of          1                          +                  

analyzing training error: proof intuition 
theorem          = 1/2              (error of         over         ) 

2
                                              exp     2            

 

    

    on round     , we increase weight of          for which         is wrong.   
    if                          incorrectly classifies         , 

- then          incorrectly classified by (wtd) majority of           s. 
- which implies final prob. weight of          is large. 

can show id203    

1
    

1

          

    

 

    since sum of prob. = 1, can   t have too many of high weight.   

can show # incorrectly classified                     

    

.  

and (          )     0

    

. 

generalization guarantees 

theorem 

2
                                              exp     2            

 

where          = 1/2              

    

how about generalization guarantees? 
  original analysis [freund&schapire   97]  

    h space of weak hypotheses; d=vcdim(h) 

                          is a weighted vote, so the hypothesis class is:  

g={all fns of the form sign( 

    
    =1

               (    )) 

} 

theorem [freund&schapire   97]  
                 ,                                             +      

        
    

    t= # of rounds 

key reason: vcd              =                 plus typical vc bounds. 

generalization guarantees 
theorem [freund&schapire   97]  

                     (    ),                                             +      

        
    

    where d=vcdim(h) 

error 

train error 

generalization 

error 

complexity 

t= # of rounds 

generalization guarantees 

    experiments with boosting showed that the test error of 

the generated classifier usually does not increase as its 
size becomes very large. 

    experiments showed that continuing to add new weak 

learners after correct classification of the training set had 
been achieved could further improve test set performance!!! 

generalization guarantees 

    experiments with boosting showed that the test error of 

the generated classifier usually does not increase as its 
size becomes very large. 

    experiments showed that continuing to add new weak 

learners after correct classification of the training set had 
been achieved could further improve test set performance!!! 

    these results seem to contradict fs   87 bound and occam   s 

razor (in order achieve good test error the classifier should be as 
simple as possible)! 

how can we explain the experiments? 

r. schapire, y. freund, p. bartlett, w. s. lee. present in 
   boosting the margin: a new explanation for the effectiveness 
of voting methods    a nice theoretical explanation. 

key idea: 

training error does not tell the whole story.  

we need also to consider the classification confidence!! 

