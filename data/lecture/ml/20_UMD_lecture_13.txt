slides adapted from prof carpuat and duraiswami

cmsc 422 introduction to machine learning

lecture 13 binary classification with linear models

furong huang / furongh@cs.umd.edu

project 1     regrading requests on 
piazza
    all grade requests submitted by friday 

will be handled by friday evening
requests submitted during spring break 
or the week after will be handled daily 
starting the monday after spring break
    all grade requests must be submitted 

   

by the thursday after spring break.

common misunderstandings - i
misunderstanding i: the classifier is best when 
performance on test and training are equal. (knn problem)

the best classifier here is for k = 5? (reasoning, "since the training and test 
are equal we are generalizing perfectly." ?) no
in this case, it may not matter much as the difference in accuracy is only .02, 
but if you had training 95 & test 90, you wouldn't want to choose training 60 
test 60 just because they're equal.

common misunderstandings - ii
misunderstanding ii: generally misunderstanding underfitting
(nn eps problem)

misunderstanding ii(a):    we are underfitting for eps < .35.
because the test accuracy increases with eps, it is clear we
have not learned everything we can learn from our dataset,
therefore we are underfitting.     no

common misunderstandings - ii
misunderstanding ii: generally misunderstanding underfitting
(nn eps problem)

training
   test accuracy shows how well you generalize,
accuracy shows how much you've learned." with 100%
training and 50% test, we've learned too much, cannot
generalize. therefore, we're overfitting not underfitting.

common misunderstandings - ii

misunderstanding ii: generally misunderstanding underfitting
(nn eps problem)

misunderstanding ii(b): "although training accuracy is 
decreasing, test accuracy is increasing, therefore we can not 
be overfitting". 

common misunderstandings -
performance on low examples
*case 1* why does the training accuracy decrease? 
"there is too much noise in the data" or "it's too hard to 
learn 1200 examples" ? no

it was because the dt had a fixed max-depth of 9. 
also, this example has 100% accuracy early on. 

xor example : dt with a depth of 2, we can get 100% 
accuracy, but with a depth of 1 we cannot. 

by limiting the max-depth we limit what we can learn.

common misunderstandings -
performance on low examples
*case 2* why is there jaggedness on the left?

dt

knn

the behavior can be very random when you've only 
seen a few examples.

what we learned last time

    ranking

    bias and fairness

    unsupervised adaptation

supervised adaptation

goal: learn a classifier f that achieves low 
expected loss under new distribution

given labeled training data from old distribution 

and labeled examples from new distribution

one solution: feature augmentation

map inputs to a new augmented representation

one solution: feature augmentation

    transform dold and dnew training 

examples

    train a classifier on new 

representations

    done!

one solution: feature augmentation

    adding instance weighting might be 

useful if n >> m

    most effective when distributions are 

   not too close but not too far   
   

in practice, always try    old only   ,    new only   , 
   union of old and new    as well!

bias and how to deal with it

    train/test mismatch

    unsupervised adaptation

    supervised adaptation

topics

linear models

id168s
id173

id119
calculus refresher

convexity
gradients

[ciml chapter 6]

binary classification
via hyperplanes

a classifier is a hyperplane (w,b)
at test time, we check on what 
side of the hyperplane examples 
fall

!"=$%&'()*++-)

this is a linear classifier

because the prediction is a linear 
combination of feature values x

learning a linear classifier
as an optimization problem

objective 
function

id168

measures how well 
classifier fits training 

data

regularizer

prefers solutions 
that generalize 

well

indicator function: 1 if (.) is true, 0 otherwise

the id168 above is called the 0-1 loss

learning a linear classifier
as an optimization problem

    problem: the 0-1 loss above is np-hard to optimize 

exactly/approximately in general

    solution: different id168 approximations and 

regularizers lead to specific algorithms

(e.g., id88, support vector machines,  logistic 

regression, etc.)

the 0-1 loss

small changes in w,b can lead to big 
changes in the loss value
0-1 loss is non-smooth, non-convex

calculus refresher:
smooth functions, convex functions

approximating the 0-1 loss with 
surrogate id168s

examples (with b = 0)

hinge loss
log loss
exponential loss

all are convex upper-
bounds on the 0-1 loss

approximating the 0-1 loss with 
surrogate id168s

examples (with b = 0)

hinge loss
log loss
exponential loss

q: which of these loss 
functions is not 
smooth?

approximating the 0-1 loss with 
surrogate id168s

examples (with b = 0)

hinge loss
log loss
exponential loss

q: which of these loss 
functions is most 
sensitive to outliers?

casting linear classification
as an optimization problem

objective 
function

id168

measures how well 
classifier fits training 

data

regularizer

prefers solutions 
that generalize 

well

indicator function: 1 if (.) is true, 0 otherwise

the id168 above is called the 0-1 loss

the regularizer term

goal: find simple solutions  (inductive bias)

ideally, we want most entries of w to be zero, so 
prediction depends only on a small number of 
features.
formally, we want to minimize:

that   s np-hard, so we use approximations instead. 

e.g., we encourage wd   s to be small

norm-based regularizers

!" norms can be used as regularizers

contour
plots for

p = 2

p = 1

p < 1

smaller p favors sparse vectors w

norm-based regularizers

!" norms can be used as regularizers
!# norm: convex, smooth, easy to optimize
!$ norm:  encourages sparse w, convex, but not 
%<1    norm becomes non convex and hard to 

i.e. most entries of w are close or equal to 0

smooth at axis points

optimize

casting linear classification
as an optimization problem

objective 
function

id168

measures how well 
classifier fits training 

data

regularizer

prefers solutions 
that generalize 

well

indicator function: 1 if (.) is true, 0 otherwise

the id168 above is called the 0-1 loss

what is the id88 optimizing?

id168 is a variant of the hinge loss

recap: linear models

general framework for binary classification
cast learning as optimization problem
optimization objective combines 2 terms

id168: measures how well classifier fits training 
data 
regularizer: measures how simple classifier is

    does not assume data is linearly separable
lets us separate model definition from 
training algorithm

calculus refresher:
gradients

id119

a general solution for our optimization problem

idea: take iterative steps to update parameters in the direction 
of the gradient

id119 algorithm

recap: linear models

general framework for binary classification
cast learning as optimization problem
optimization objective combines 2 terms

id168: measures how well classifier fits training 
data 
regularizer: measures how simple classifier is

    does not assume data is linearly separable
lets us separate model definition from 
training algorithm (id119)

furong huang

3251 a.v. williams, college park, md 20740

301.405.8010 / furongh@cs.umd.edu

