machine learning 10-601 

tom m. mitchell 

machine learning department 

carnegie mellon university 

january 14, 2015 

 

 

 

today: 
       the big picture 
       overfitting 
       review: id203 

readings: 
id90, overfiting 
       mitchell, chapter 3 

id203 review 
       bishop ch. 1 thru 1.2.3 
       bishop, ch. 2 thru 2.2 
       andrew moore   s online 

tutorial 

function approximation:   

problem setting: 
       set of possible instances x  

       unknown target function f : x     y

       set of function hypotheses h={ h | h : x     y }

input: 
       training examples {<x(i),y(i)>} of unknown target function f
output: 
       hypothesis h     h that best approximates target function f

function approximation: decision tree learning 

problem setting: 
       set of possible instances x 

       each instance x in x is a feature vector  

       unknown target function f : x     y

x = < x1, x2     xn> 
       y is discrete valued 

       set of function hypotheses h={ h | h : x     y }

       each hypothesis h is a decision tree 

input: 
       training examples {<x(i),y(i)>} of unknown target function f
output: 
       hypothesis h     h that best approximates target function f

information gain (also called mutual information) 
between input attribute a and target variable y 
 
information gain is the expected reduction in id178 
of target variable y for data sample s, due to sorting 
on variable a  
 

function approximation as search 
for the best hypothesis 

         performs heuristic 

search through space of 
id90 

function approximation: the big picture 

which tree should we output? 

         performs heuristic 

search through space of 
id90 

       it stops at smallest 

acceptable tree. why? 

occam   s razor: prefer the 
simplest hypothesis that 
fits the data 

why prefer short hypotheses? (occam   s razor) 

arguments in favor: 
 
 
 
 
 
arguments opposed:  

why prefer short hypotheses? (occam   s razor) 

argument in favor: 
       fewer short hypotheses than long ones 
        a short hypothesis that fits the data is less likely to be 

a statistical coincidence 

 
 
argument opposed: 
       also fewer hypotheses containing a prime number of 

nodes and attributes beginning with    z    

       what   s so special about    short    hypotheses, instead 

of    prime number of nodes and edges   ? 

overfitting 
consider a hypothesis h and its 
       error rate over training data: 
       true error rate over all data:  

overfitting 
consider a hypothesis h and its 
       error rate over training data: 
       true error rate over all data:  
 
we say h overfits the training data if 
 
 
amount of overfitting =  

split data into training and validation set
create tree that classi   es training set correctly

decision tree learning, formal guarantees 

supervised learning or function approximation  

data 
source 

distribution d on x 

expert / oracle 

learning 
algorithm 

   labeled examples   

(x1,c*(x1)),   , (xm,c*(xm)) 

alg.outputs 

h : x ! y 

x1 > 5 

c* : x ! y 

x6 > 2 

+1 

+1 

-1 

supervised learning or function approximation  

data 
source 

distribution d on x 

learning 
algorithm 

expert/oracle 

   labeled examples   

(x1,c*(x1)),   , (xm,c*(xm)) 

alg.outputs 

h : x ! y 

c* : x ! y 

       algo sees training sample s: (x1,c*(x1)),   , (xm,c*(xm)), xi i.i.d. from d 
         does optimization over s, finds hypothesis h (e.g., a decision tree). 

         goal:  h has small error over d. 

  err(h)=prx 2 d(h(x)     c*(x)) 

two core aspects of machine learning 

algorithm design. how to optimize? 

computation 

automatically generate rules that do well on observed data. 

confidence bounds, generalization 

(labeled) data 

confidence for rule effectiveness on future data. 
       very well understood: occam   s bound, vc theory, etc. 
       id90: if we were able to find a small decision tree that 

explains data well, then good generalization guarantees.  

       np-hard [hyafil-rivest   76]   

top down id90 algorithms 

       id90: if we were able to find a small decision tree 

consistent with the data, then good generalization guarantees.  
       np-hard [hyafil-rivest   76]   

       very nice practical heuristics;  top down algorithms, e.g,   

       natural greedy approaches where we grow the tree from the root to the 

leaves by repeatedly replacing an existing leaf with an internal node. 

       key point: splitting criterion. 
        : split the leaf that decreases the id178 the most. 
       why not split according to error rate --- this is what we care 

about after all? 
       there are examples where we can get stuck in local minima!!! 

id178 as a better splitting measure 

0  0  0 
0  0  1 
0  1  0 
0  1  1 
1  0  0 
1  0  1 
1  1  0 
1  1  1 

initial error rate is 1/4  (25% positive, 75% negative) 

error rate after split is   (left leaf is 100% negative; 

right leaf is 50/50) 

overall error doesn   t decrease! 

id178 as a better splitting measure 

0  0  0 
0  0  1 
0  1  0 
0  1  1 
1  0  0 
1  0  1 
1  1  0 
1  1  1 

initial id178 is  

id178 after split is  

id178 decreases! 

top down id90 algorithms 

       natural greedy approaches where we grow the tree from the root to the 

leaves by repeatedly replacing an existing leaf with an internal node. 

       key point: splitting criterion. 
        : split the leaf that decreases the id178 the most. 
       why not split according to error rate --- this is what we care 

about after all? 
       there are examples where you can get stuck!!! 

      

[kearns-mansour   96]: if measure of progress is id178, we can 
always guarantees success under some formal relationships 
between the class of splits and the target (the class of splits can 
weakly approximate the target function).   

       provides a way to think about the effectiveness of 

various top down algos. 

top down id90 algorithms 
       key: strong concavity of the splitting crieterion 

pr[c*=1]=q 

v 

h 

pr[h=0]=u 
0 
v1 

pr[h=1]=1-u 

1 

v2 

pr[c*=1| h=0]=p 

pr[c*=1| h=1]=r 

p 

q 

r 

       q=up + (1-u) r. 

want to lower bound: g(q)     [ug(p) + (1-u)g(r)] 

       if: g(q) =min(q,1-q) (error rate), then g(q) = ug(p) + (1-u)g(r)  
       if: g(q) =h(q) (id178), then g(q)     [ug(p) + (1-u)g(r)] >0 if r-p> 

0 and u    1, u    0 (this happens under the weak learning 
assumption)

two core aspects of machine learning 

algorithm design. how to optimize? 

computation 

automatically generate rules that do well on observed data. 

confidence bounds, generalization 

(labeled) data 

confidence for rule effectiveness on future data. 

what you should know: 
       well posed function approximation problems: 

       instance space, x 
       sample of labeled training data { <x(i), y(i)>} 
       hypothesis space, h = { f: x     y } 

       learning is a search/optimization problem over h 

       various objective functions 

       minimize training error (0-1 loss)  
       among hypotheses that minimize training error, select smallest (?) 

       but inductive learning without some bias is futile ! 

       decision tree learning 

       greedy top-down learning of id90 ( , c4.5, ...) 
       overfitting and tree post-pruning 
       extensions    

extra slides 

extensions to decision tree learning 

 
 

questions to think about (1) 
         and c4.5 are heuristic algorithms that 

search through the space of id90.  
why not just do an exhaustive search? 

questions to think about (2) 
       consider target function f: <x1,x2>       y, 

where x1 and x2 are real-valued, y is 
boolean.  what is the set of decision surfaces 
describable with id90 that use each 
attribute at most once? 

questions to think about (3) 
       why use information gain to select attributes 
in id90?  what other criteria seem 
reasonable, and what are the tradeoffs in 
making this choice?   

questions to think about (4) 
       what is the relationship between learning 
id90, and learning if-then rules 

machine learning 10-601 

tom m. mitchell 

machine learning department 

carnegie mellon university 

january 14, 2015 

 

 

 

today: 
       review: id203 

many of these slides are 

derived from william cohen, 
andrew moore, aarti singh, 
eric xing. thanks! 

readings: 
 
id203 review 
       bishop ch. 1 thru 1.2.3 
       bishop, ch. 2 thru 2.2 
       andrew moore   s online 

tutorial 

id203 overview 
       events  

       discrete random variables, continuous random variables, 

       what defines a reasonable theory of uncertainty 
independent events 

compound events 

       axioms of id203 

      
       conditional probabilities 
       bayes rule and beliefs 
       joint id203 distribution 
       expectations 
      

independence, conditional independence 

random variables 

      

informally, a is a random variable if 
       a denotes something about which we are uncertain 
       perhaps the outcome of a randomized experiment  

       examples 

a = true if a randomly drawn person from our class is female 
a = the hometown of a randomly drawn person from our class 
a = true if two randomly drawn persons from our class have same birthday 
 

       define p(a) as    the fraction of possible worlds in which a is true    or       

   the fraction of times a holds, in repeated runs of the random experiment    
       the set of possible worlds is called the sample space, s 
       a random variable a is a function defined over s 

                        a: s       {0,1} 
 

a little formalism 

more formally, we have 
       a sample space s (e.g., set of students in our class) 

       aka the set of possible worlds 

       a random variable is a function defined over the sample 

space 
       gender: s       { m, f } 
       height: s       reals 

       an event is a subset of s 

       e.g., the subset of s for which gender=f 
       e.g., the subset of s for which (gender=m) and (eyecolor=blue) 
       we   re often interested in probabilities of specific events 
       and of specific events conditioned on other specific events  

visualizing a 

sample space 
of all possible 
worlds 

its area is 1 

 
 
 
 
 
 
 
 

 
 
worlds in which 
 
a is true 
 

p(a) = area of 
reddish oval 

worlds in which a is false 

the axioms of id203 

       0 <= p(a) <= 1 
       p(true) = 1 
       p(false) = 0 
       p(a or b) = p(a) + p(b) - p(a and b) 

 

[di finetti 1931]: 
 
when gambling based on    uncertainty formalism a    you can 
be exploited by an opponent 
 
iff 
 
your uncertainty formalism a violates these axioms 

elementary id203 in 
pictures 
       p(~a) + p(a) = 1 

 
a 
 

~a 

a useful theorem 

       0 <= p(a) <= 1, p(true) = 1, p(false) = 0, 
    p(a or b) = p(a) + p(b) - p(a and b) 
 

      p(a) = p(a ^ b) + p(a ^ ~b) 
 

a =  [a and (b or ~b)]  =  [(a and b) or (a and ~b)] 
p(a) = p(a and b) + p(a and ~b)     p((a and b) and (a and ~b)) 
p(a) = p(a and b) + p(a and ~b)     p(a and b and a and ~b) 
 

elementary id203 in pictures 

       p(a) = p(a ^ b) + p(a ^ ~b) 

a ^ b 

 
b 
 

a ^ ~b 

definition of id155 

                     p(a ^ b)  
p(a|b)  =  ----------- 
                    p(b)  

a 

 
b 
 

definition of conditional 
id203 

                     p(a ^ b)  
p(a|b)  =  ----------- 
                    p(b)  

corollary: the chain rule 
p(a ^ b) = p(a|b) p(b)  

bayes rule 
       let   s write 2 expressions for p(a ^ b)  

a ^ b 

 
b 
 

a 

p(a|b) = 

p(b|a) * p(a) 

p(b) 

bayes    rule 

we call p(a) the    prior    
 
and p(a|b) the    posterior    

bayes, thomas (1763) an essay 
towards solving a problem in the doctrine 
of chances. philosophical transactions of 
the royal society of london, 53:370-418 

   by no means merely a curious speculation in the doctrine of chances, 
but necessary to be solved in order to a sure foundation for all our 
reasonings concerning past facts, and what is likely to be hereafter   . 
necessary to be considered by any that would give a clear account of the 
strength of analogical or inductive reasoning    

other forms of bayes rule 

bap
(
)|

=

apabp
(
)
(
)
(
|~(

|
+

apabpapabp
(
)

(~)

)

)

|

xbap
(

   

|

)

=

xapxabp
(

|

   

(
   
xbp
(
)

)
   

)

applying bayes rule 

p(a|b) =

p(b| a)p(a)

p(b| a)p(a)+p(b|~ a)p(~ a)

a = you have the flu,   b = you just coughed 
 
assume: 
p(a) = 0.05 
p(b|a) = 0.80 
p(b| ~a) = 0.2 
 
what is p(flu | cough) = p(a|b)? 

what does all this have to do with 
function approximation? 

the joint distribution 

recipe for making a joint 

distribution of m variables: 

example: boolean 
variables a, b, c 

the joint distribution 

recipe for making a joint 

distribution of m variables: 

 
1.    make a truth table listing all 

combinations of values of 
your variables (if there are 
m boolean variables then 
the table will have 2m rows). 

example: boolean 
variables a, b, c 

a 
0 

0 

0 

0 

1 

1 

1 

1 

b 
0 

0 

1 

1 

0 

0 

1 

1 

c 
0 

1 

0 

1 

0 

1 

0 

1 

the joint distribution 

recipe for making a joint 

distribution of m variables: 

 
1.    make a truth table listing all 

combinations of values of 
your variables (if there are 
m boolean variables then 
the table will have 2m rows). 

2.    for each combination of 

values, say how probable it 
is. 

example: boolean 
variables a, b, c 

a 
0 

0 

0 

0 

1 

1 

1 

1 

b 
0 

0 

1 

1 

0 

0 

1 

1 

c 
0 

1 

0 

1 

0 

1 

0 

1 

prob 
0.30 

0.05 

0.10 

0.05 

0.05 

0.10 

0.25 

0.10 

the joint distribution 

recipe for making a joint 

distribution of m variables: 

 
1.    make a truth table listing all 

combinations of values of 
your variables (if there are 
m boolean variables then 
the table will have 2m rows). 

2.    for each combination of 

values, say how probable it 
is. 

3.    if you subscribe to the 

axioms of id203, those 
numbers must sum to 1. 

a 
0 

0 

0 

0 

1 

1 

1 

1 

b 
0 

0 

1 

1 

0 

0 

1 

1 

c 
0 

1 

0 

1 

0 

1 

0 

1 

prob 
0.30 

0.05 

0.10 

0.05 

0.05 

0.10 

0.25 

0.10 

0.05 
a 
 
0.25 
 
b 
 

0.10 
0.10 

0.10 

0.05 

c 

0.05 

0.30 

using the 
joint 
distribution 

one you have the jd 
you can ask for the 
id203 of any logical 
expression involving 
your attribute 

ep
(

)

   =

p
row(
e
 
rows
matching
 

)

using the 
joint 

p(poor male) = 0.4654 

ep
(

)

   =

p
row(
e
 
rows
matching
 

)

using the 
joint 

p(poor) = 0.7604 

ep
(

)

   =

p
row(
e
 
rows
matching
 

)

id136 
with the 
joint 

eep
(

|

1

)

2

=

)

2

ep
(
   
1
ep
(

2

e
)

=

)

p
row(
   
e
e
and
 
 
matching
rows
 
 1
p
row(
   
e
matching
 
rows
 

)

 2

2

id136 
with the 
joint 

eep
(

|

1

)

2

=

)

2

ep
(
   
1
ep
(

2

e
)

=

)

p
row(
   
e
e
and
 
 
matching
rows
 
 1
p
row(
   
e
matching
 
rows
 

)

 2

2

p(male | poor) = 0.4654 / 0.7604 = 0.612   

you should know 
       events  

compound events 

       axioms of id203 

       discrete random variables, continuous random variables, 

       what defines a reasonable theory of uncertainty 

       conditional probabilities 
       chain rule 
       bayes rule 
       joint distribution over multiple random variables 

       how to calculate other quantities from the joint distribution 

expected values 
given discrete random variable x, the expected value of 

x, written e[x] is 

 
 
 
 
we also can talk about the expected value of functions 

of x 

covariance 
given two discrete r.v.   s x and y, we define the 

covariance of x and y as 

 
 
e.g., x=gender, y=playsfootball 
or     x=gender, y=lefthanded 
 
 
remember: 

