never-ending language learning 

tom mitchell, william cohen, and many collaborators 

carnegie mellon university 

 
 
 
 
 
 
 
 
 

 
we will never really understand learning 
until we build machines that  
      
      
      
       and become better learners over time. 

learn many different things,  
from years of diverse experience, 
in a staged, curricular fashion,  

tenet 2:  
natural language understanding requires 
a belief system 
 
a natural language understanding system 
should react to text by saying either: 
      
      
      
 
 

i understand, and already knew that 
i understand, and didn   t know, but accept it 
i understand, and disagree because     

initial ontology (categories and relations) 

nell: never-ending language learner 
inputs: 
      
       dozen examples of each ontology predicate 
      
       occasional interaction with human trainers 
 
the task: 
       run 24x7, forever 
       each day: 

the web 

1.    extract more facts from the web to populate the ontology 
2.   

learn to read (perform #1) better than yesterday 

nell today 

running 24x7, since january, 12, 2010 

 

result: 

       knowledge base with 90 million candidate beliefs 
       learning to read  
       learning to reason 
       extending ontology 
 

nell knowledge fragment 
* including only correct beliefs 

uses 

equipment 

football 

climbing 

skates  helmet 

canada 

sunnybrook 

country 

hospital 

wilson 

toronto 

cfrb  

radio 

home town 

city 

stadium 

team 

stadium 

city 
paper 

politician 

airport 

miller 

 
 
 
 
 
 
pearson 
 
 
 
 
 
 
connaught 
 
city 
 
  

city 

stadium 

company 

uses 

equipment 
hockey 

detroit 

city 

company 

gm 

hired 

play 

hometown 

maple leafs 

stanley 

cup 

won 

won 

red 
wings 

competes 

with 

toyota 

league 

league 

acquired 

air canada 

centre 

member 

nhl 

plays in 

globe and mail 

skydome 

writer 

milson 

sundin 

toskala 

created 

hino 

economic 

sector 

automobile 

prius 

corrola 

nell is improving over time (jan 2010 to nov 2014) 
mean avg. precision 

precision@10 

top 1000 

all beliefs 

high conf. beliefs 

 
s
n
o

i
l
l
i

m

 
f

o
 
s
0
1

   

 
s
n
o

i
l
l
i

m

number of nell beliefs vs. time 

reading accuracy vs. time 
(average over 31 predicates)  

human feedback vs. time 

(average 2.4 feedbacks per predicate per month) 

nell today 
       eg.    diabetes   ,    avandia   ,    tea   ,    ibm   ,    love       baseball        san juan    

   bacteriacausescondition       kitchenitem       clothinggoeswithclothing             

 

portuguese nell  

[estevam hruschka, 2014] 

how does nell work? 

semi-supervised bootstrap learning 

learn which 
noun phrases 
are cities: 

paris 
pittsburgh 
seattle 
montpelier 

 

it   s underconstrained!! 

 

san francisco 
berlin 
denial 

anxiety 
selfishness 
london 

mayor of  arg1 
live in  arg1 

arg1 is home of 
traits such as arg1 

key idea 1: coupled semi-supervised training 
of many functions 

person 

noun phrase 

 hard 

(underconstrained) 
semi-supervised 
learning problem 

much easier (more constrained) 
semi-supervised learning problem 

type 1 coupling: co-training, multi-view learning 

 
supervised training of 1 function: 
 
minimize:  
 

person 

 

np: 

type 1 coupling: co-training, multi-view learning 

 
coupled training of 2 functions: 
 
minimize:  
 

person 

 

np: 

type 1 coupling: co-training, multi-view learning 
[blum & mitchell; 98] 
[dasgupta et al; 01 ] 
[ganchev et al., 08] 
[sridharan & kakade, 08] 
[wang & zhou, icml10] 

person 

 

np: 

nell: learned reading strategies 
mountain:  
      "volcanic crater of _"  "volcanic eruptions like _"  "volcanic peak of _"  "volcanic 

region of _"  "volcano , called _"  "volcano called _"  "volcano is called _"  
"volcano known as _"  "volcano mt _"  "volcano named _"  "volcanoes , 
including _"  "volcanoes , like _"  "volcanoes , such as _"  "volcanoes include 
_"  "volcanoes including _"  "volcanoes such as _"  "we 've climbed _"  
"weather atop _"  "weather station atop _"  "week hiking in _"  "weekend trip 
through _"  "west face of _"  "west ridge of _"  "west to beyond _"  "white 
ledge in _"  "white summit of _"  "whole earth , is _"  "wilderness area 
surrounding _"  "wilderness areas around _"  "wind rent _"  "winter ascent of _"  
"winter ascents in _"  "winter ascents of _"  "winter expedition to _"  "wooded 
foothills of _"  "world famous view of _"  "world famous views of _"  "you 're 
popping by _"  "you 've just climbed _"  "you just climbed _"  "you   ve climbed _"  
"_ ' crater"  "_ ' eruption"  "_ ' foothills"  "_ ' glaciers"  "_ ' new dome"  "_ 's base 
camp"  "_ 's drug guide"  "_ 's east rift zone"  "_ 's main summit"  "_ 's north 
face"  "_ 's north peak"  "_ 's north ridge"  "_ 's northern slopes"  "_ 's 
southeast ridge"  "_ 's summit caldera"  "_ 's west face"  "_ 's west ridge"  "_ 
's west ridge"  "_ (d,ddd ft"      "_ climbing permits"  "_ climbing safari"  "_ 
consult el diablo"  "_ cooking planks"  "_ dominates the sky line"  "_ dominates 
the western skyline"  "_ dominating the scenery    

type 1 coupling: co-training, multi-view learning 
[blum & mitchell; 98] 
[dasgupta et al; 01 ] 
[ganchev et al., 08] 
[sridharan & kakade, 08] 
[wang & zhou, icml10] 

person 

 

np: 

multi-view, multi-task coupling 

athlete 

person 

coach 

sport 

team 

[blum & mitchell; 98] 
[dasgupta et al; 01 ] 
[ganchev et al., 08] 
[sridharan & kakade, 08] 
[wang & zhou, icml10] 
[taskar et al., 2009] 
[carlson et al., 2009] 

np: 

np text 
context 

distribution 

np 

morphology 

np html 
contexts 

athlete(np)       person(np) 

athlete(np)       not sport(np) 
not athlete(np)       sport(np) 

type 3 coupling: relation argument types 

playssport(a,s) 

playsforteam(a,t) 

teamplayssport(t,s) 

coachesteam(c,t) 

np1 

np2 

type 3 coupling: relation argument types 
playssport(np1,np2)       athlete(np1), sport(np2) 

playssport(a,s) 

playsforteam(a,t) 

teamplayssport(t,s) 

coachesteam(c,t) 

athlete 

person 

sport 

coach 

team 

athlete 

person 

sport 

coach 

team 

np1 

np2 

over 2500 coupled 
functions in nell 

pure em approach to coupled training 

e: estimate labels for each 

function of each unlabeled 
example 

 
m: retrain all functions, using 

these probabilistic labels 

 

scaling problem: 
       e step: 25m np   s,  1014 np pairs to label 
       m step: 50m text contexts to consider for each function       

1010 parameters to retrain 

       even more url-html contexts    
 

nell   s approximation to em 
e    step: 
       re-estimate the knowledge base:   

       but consider only a growing subset of the latent variable 

assignments  

       category variables: up to 250 new np   s per category per iteration 
       relation variables: add only if confident and args of correct type 
       this set of explicit latent assignments *is* the knowledge base 

m    step: 
       each view-based learner retrains itself from the updated kb 
          context    methods create growing subsets of contexts 

initial nell architecture 

knowledge base 
(latent variables) 

 beliefs 

candidate 

beliefs 

 
 
 
 
 
 

knowledge 
integrator 

 

morphology 

classifier 

 

(cml) 

human 
advice 

 
 

 
 
 
 
 

text 

context 
patterns 
(cpl) 

html-url 

context 
patterns 
(seal) 

 

                     continually learning reading components 

if coupled learning is the key, 
how can we get new coupling constraints? 

key idea 2:  
 
discover new coupling constraints 

      

learn horn clause rules/constraints: 
 0.93  athleteplayssport(?x,?y)       athleteplaysforteam(?x,?z) 
                                                       teamplayssport(?z,?y) 
       learned by data mining the knowledge base 
       connect previously uncoupled relation predicates 
       infer new unread beliefs 
       modified version of foil [quinlan] 
 

learned probabilistic horn clause rules 

 0.93  playssport(?x,?y)       playsforteam(?x,?z), teamplayssport(?z,?y) 

playssport(a,s) 

playsforteam(a,t) 

teamplayssport(t,s) 

coachesteam(c,t) 

athlete 

person 

sport 

person 

sport 

athlete 

coach 

team 

coach 

team 

np1 

np2 

infer new beliefs 

[lao, mitchell, cohen, emnlp 2011] 

economic sector  

if:  

x1 

competes 

with 
(x1,x2) 

x2 

economic 

sector 
(x2, x3) 

x3 

then:   economic sector (x1, x3) 

id136 by id93 

pra:  [lao, mitchell, cohen, emnlp 2011] 

economic sector  

pra: 
 
1. restrict 
precondition  
to a  chain. 
 
2. id136 
by random 
walks 

if:  

x1 

 
 
 

competes 

with 
(x1,x2) 

x2 

economic 

sector 
(x2, x3) 

x3 

then:   economic sector (x1, x3) 

id136 by kb id93 

[lao, mitchell, cohen, emnlp 2011] 

kb:  

random walk 
path type:  

pr( r(x,y) ): 

x 

competes 

with 

? 

economic 

sector 

y 

logistic function for r(x,y) 
 
where ith feature = id203 of arriving at 
node y starting at node x, and taking a random 
walk along path of type i 

citylocatedincountry(pittsburgh) = ?  

[lao, mitchell, cohen, emnlp 2011] 

pittsburgh  

 
     feature = typed path 
     cityinstate, cityinstate-1, citylocatedincountry                

 

feature value 

logistic  

regresssion 

weight 
             0.32 

citylocatedincountry(pittsburgh) = ?  

pennsylvania 

[lao, mitchell, cohen, emnlp 2011] 

pittsburgh  

 
weight 
     feature = typed path 
     cityinstate, cityinstate-1, citylocatedincountry                                               0.32 
   

feature value 

logistic  

regresssion 

citylocatedincountry(pittsburgh) = ?  

pennsylvania 

[lao, mitchell, cohen, emnlp 2011] 

   (14) 

pittsburgh  

philadelphia  harisburg 

 
weight 
     feature = typed path 
     cityinstate, cityinstate-1, citylocatedincountry                                               0.32 
     

feature value 

logistic  

regresssion 

citylocatedincountry(pittsburgh) = ?  

pennsylvania 

[lao, mitchell, cohen, emnlp 2011] 

u.s. 

   (14) 

pittsburgh  

philadelphia  harisburg 

 
     feature = typed path 
     cityinstate, cityinstate-1, citylocatedincountry                                              0.32 
     

feature value 

weight 

logistic  

regresssion 

citylocatedincountry(pittsburgh) = ?  

pennsylvania 

[lao, mitchell, cohen, emnlp 2011] 

u.s. 

   (14) 

pittsburgh  

philadelphia  harisburg 

pr(u.s. | pittsburgh, typedpath) 

 

 

logistic  

regresssion 

 
     feature = typed path 
     cityinstate, cityinstate-1, citylocatedincountry               0.8                          0.32 
     

feature value 

weight 

citylocatedincountry(pittsburgh) = ?  

pennsylvania 

[lao, mitchell, cohen, emnlp 2011] 

u.s. 

   (14) 

pittsburgh  

philadelphia  harisburg 

 
     feature = typed path 
     cityinstate, cityinstate-1, citylocatedincountry               0.8                          0.32 
     atlocation-1, atlocation, citylocatedincountry                                               0.20 
       

feature value 

weight 

logistic  

regresssion 

citylocatedincountry(pittsburgh) = ?  

pennsylvania 

[lao, mitchell, cohen, emnlp 2011] 

u.s. 

   (14) 

pittsburgh  

philadelphia  harisburg 

ppg 

delta 

 
     feature = typed path 
     cityinstate, cityinstate-1, citylocatedincountry               0.8                          0.32 
     atlocation-1, atlocation, citylocatedincountry                                               0.20 
       

feature value 

weight 

logistic  

regresssion 

citylocatedincountry(pittsburgh) = ?  

pennsylvania 

[lao, mitchell, cohen, emnlp 2011] 

u.s. 

   (14) 

pittsburgh  

philadelphia  harisburg 

a t l o c a ti o n  

atlanta 

dallas 

tokyo 

ppg 

delta 

 
     feature = typed path 
     cityinstate, cityinstate-1, citylocatedincountry               0.8                          0.32 
     atlocation-1, atlocation, citylocatedincountry                                               0.20 
       

feature value 

weight 

logistic  

regresssion 

citylocatedincountry(pittsburgh) = ?  

[lao, mitchell, cohen, emnlp 2011] 

pennsylvania 

u.s. 

   (14) 

pittsburgh  

philadelphia  harisburg 

a t l o c a ti o n  

atlanta 

dallas 

ppg 

delta 

japan 
y 
r
t
n
u
o
c
n
i
d
e
t
a
c
o
l
y
cit
tokyo 

 
     feature = typed path 
     cityinstate, cityinstate-1, citylocatedincountry               0.8                          0.32 
     atlocation-1, atlocation, citylocatedincountry                0.6                          0.20 
       

feature value 

weight 

logistic  

regresssion 

citylocatedincountry(pittsburgh) = ?  

[lao, mitchell, cohen, emnlp 2011] 

pennsylvania 

u.s. 

   (14) 

pittsburgh  

philadelphia  harisburg 

a t l o c a ti o n  

atlanta 

dallas 

ppg 

delta 

japan 
y 
r
t
n
u
o
c
n
i
d
e
t
a
c
o
l
y
cit
tokyo 

 
     feature = typed path 
     cityinstate, cityinstate-1, citylocatedincountry               0.8                          0.32 
     atlocation-1, atlocation, citylocatedincountry                0.6                          0.20 
                                                                                                                                    

feature value 

weight 

logistic  

regresssion 

citylocatedincountry(pittsburgh) = u.s.    p=0.58 

citylocatedincountry(pittsburgh) = ?  

[lao, mitchell, cohen, emnlp 2011] 

pittsburgh  

philadelphia  harisburg 

pennsylvania 

u.s. 

1.    tractable   

(bounded length) 

   (14) 

2.    anytime 
3.    accuracy increases as 

atlanta 

a t l o c a ti o n  

kb grows 

4.    combines probabilities 

from different horn 
clauses 

dallas 

japan 
y 
r
t
n
u
o
c
n
i
d
e
t
a
c
o
l
y
cit
tokyo 

logistic  

regresssion 

ppg 

delta 

 
     feature = typed path 
     cityinstate, cityinstate-1, citylocatedincountry               0.8                          0.32 
     atlocation-1, atlocation, citylocatedincountry                0.6                          0.20 
                                                                                                                                    

feature value 

weight 

citylocatedincountry(pittsburgh) = u.s.    p=0.58 

random walk id136: learned rules 

citylocatedincountry(city, country): 
 
8.04 cityliesonriver, cityliesonriver-1, citylocatedincountry  
5.42 hasofficeincity-1, hasofficeincity, citylocatedincountry 
4.98 cityalsoknownas, cityalsoknownas, citylocatedincountry 
2.85 citycapitalofcountry,citylocatedincountry-1,citylocatedincountry  
2.29 agentactsinlocation-1, agentactsinlocation, citylocatedincountry 
1.22 statehascapital-1, statelocatedincountry  
0.66 citycapitalofcountry 
 . 
 . 
 .  
7 of the 2985 learned rules for citylocatedincountry 

[gardner et al, 2014] 

opportunity:  
   can infer more if we start with more  
   densely connected id13 

         as nell learns, it will become more dense 

         augment id13 with a second 

graph of corpus statistics:  

    <subject, verb, object> triples 

nell:  concepts  and    noun phrases    

[gardner et al, 2014] 

c:penguins 

hometown 

c:pittsburgh 

river flows 
 through 

 

c:monongahela 

 

o
t
 
r
e
f
e
r
 
n
a
c

 

o
t
 
r
e
f
e
r
 
n
a
c

 

o
t
 
r
e
f
e
r
 
n
a
c

    penguins    

    pens    

    pittsburgh    

    pgh    

    monongahela    
    mon river    

nell:  concepts  and    noun phrases    

[gardner et al, 2014] 

team:penguins 

hometown 

city:pittsburgh 

river flows 
 through 

 

river:monongahela 

 

o
t
 
r
e
f
e
r
 
n
a
c

    pens    

  
    remain in    
 
    penguins    
 
  
 
 
  

    supports    

    began in    

    reminded    

 

o
t
 
r
e
f
e
r
 
n
a
c

    pittsburgh    

    pgh    

 

o
t
 
r
e
f
e
r
 
n
a
c

    overlooks    

  
    sits astride    
 
 
  
 
 
    runs through    
  

    enters    

    monongahela    
    mon river    

svo triples from 500 m dependency parsed web pages (thank you chris re!) 

nell:  concepts  and    noun phrases    

[gardner et al, 2014] 

c:penguins 

hometown 

 

o
t
 
r
e
f
e
r
 
n
a
c

    pens    

  
    remain in    
 
    penguins    
 
  
 
 
  

    supports    

    began in    

    reminded    

 

-    circumvents nell   s fixed vocabulary of relations! 
-    sadly, adding these does not help: too sparse 
-    but id91 verb phrases based on latent 

river flows 
 through 

c:monongahela 

c:pittsburgh 

 

 

 

embedding (nnmf), produces significant 
improvement 
-   

{   lies on   ,    runs through   ,    flows through   ,    } 

o
t
 
r
e
f
e
r
 
n
a
c

o
t
 
r
e
f
e
r
 
n
a
c

-    precision/recall over 15 nell relations: 
    pittsburgh    

    pgh    

    overlooks    
 kb only:            0.80 / 0.33 
 kb + svolatent:  0.87 / 0.42 

    monongahela    
    mon river    

[gardner et al., 2014] 

  
    sits astride    
 
 
  
 
 
    runs through    
  

    enters    

svo triples from 500 m dependency parsed web pages (thank you chris re!) 

key idea 3:  
   automatically extend ontology 

ontology extension (1) 

[mohamed et al., emnlp 2011] 

goal: 
       add new relations to ontology 
 
approach: 
       for each pair of categories c1, c2,  

       cluster pairs of known instances, in terms of 

text contexts that connect them   

 

suggested 

name 

master 

example discovered relations 

[mohamed et al. emnlp 2011] 

category pair 

frequent instance pairs 

text contexts 

musicinstrument 

musician 

disease 
disease 

celltype 
chemical 

 

mammals 

plant 

river 
city 

sitar, george harrison 
tenor sax, stan getz 

trombone, tommy dorsey 

vibes, lionel hampton 

arg1 master arg2 
arg1 virtuoso arg2 
arg1 legend arg2 
arg2 plays arg1 

pinched nerve, herniated disk 

tennis elbow, tendonitis 
blepharospasm, dystonia 

arg1 is due to arg2 

arg1 is caused by arg2 

isdueto 

epithelial cells, surfactant 

neurons, serotonin 
mast cells, histomine 
koala bears, eucalyptus 

sheep, grasses 
goats, saplings 

seine, paris 
nile, cairo 

tiber river, rome 

arg1 that release arg2 
arg2 releasing arg1 

thatrelease 

arg1 eat arg2 

arg2 eating arg1 

eat 

arg1 in heart of arg2 

arg1 which flows through 

arg2 

inheartof 

nell: sample of self-added relations 
       clothinggoeswithclothing 
       athletewonaward 
       bacteriacausesphyscondition 
       animaleatsfood 
       buildingmadeofmaterial 
      
languagetaughtincity 
       clothingmadefromplant 
       emotionassociatedwithdisease 
      
       beverageservedwithfood 
      
       agriculturalproductattractsinsect 
       arteryarisesfromartery 
       athletebeatathlete 
       athleteinjuredbodypart 
       countryhassportsfans 
       bakedgoodservedwithbeverage 
       arthropodfeedsoninsect 
       beveragecontainsprotein 
       animaleatsvegetable 
       plantrepresentsemotion 
       animalcandevelopdisease 
       beveragemadefrombeverage 
      

fooddecreasesriskofdisease 

foodcancausedisease 

fishservedwithfood 

ontology extension (2) 

[burr settles] 

goal: 
       add new subcategories 
 
approach: 
       for each category c,  

       train nell to read the relation  
   subsetofc: c       c 
 

  

*no new software here, 
 just add this relation to 
 ontology 

nell: subcategories discovered by reading 
animal: 
       pets 

       hamsters, ferrets, birds, dog, cats, 
rabbits, snakes, parrots, kittens,     

       predators 

       bears, foxes, wolves, coyotes, 
snakes, racoons, eagles, lions, 
leopards, hawks, humans,     

animalsubset(arg1,arg2) 

learned reading patterns for      
"arg1 and other medium sized arg2"  
"arg1 and other jungle arg2     "arg1 and 
other magnificent arg2" "arg1 and other 
pesky arg2" "arg1 and other mammals 
and arg2"  "arg1 and other ice age 
arg2" "arg1 or other biting arg2" "arg1 
and other marsh arg2"  "arg1 and other 
migrant arg2     "arg1 and other 
monogastric arg2"  "arg1 and other 
mythical arg2"  "arg1 and other nesting 
arg2"  "arg1 and other night arg2"  "arg1 
and other nocturnal arg2"  "arg1 and 

nell: subcategories discovered by reading 
animal: 
       pets 

chemical: 
       fossil fuels 

       hamsters, ferrets, birds, dog, cats, 
rabbits, snakes, parrots, kittens,     

       carbon, natural gas, coal, diesel, 

monoxide, gases,     

       predators 

       bears, foxes, wolves, coyotes, 
snakes, racoons, eagles, lions, 
leopards, hawks, humans,     

       gases 

       helium, carbon dioxide, methane, 

oxygen, propane, ozone, radon     

learned reading patterns: 
"arg1 and other medium sized arg2"  
"arg1 and other jungle arg2     "arg1 and 
other magnificent arg2" "arg1 and other 
pesky arg2" "arg1 and other mammals 
and arg2"  "arg1 and other ice age 
arg2" "arg1 or other biting arg2" "arg1 
and other marsh arg2"  "arg1 and other 
migrant arg2     "arg1 and other 
monogastric arg2"  "arg1 and other 
mythical arg2"  "arg1 and other nesting 
arg2"  "arg1 and other night arg2"  "arg1 
and other nocturnal arg2"  "arg1 and 

learned reading patterns: 
"arg1 and other hydrocarbon arg2     "arg1 
and other aqueous arg2     "arg1 and other 
hazardous air arg2"  "arg1 and oxygen 
are arg2      "arg1 and such synthetic arg2     
"arg1 as a lifting arg2"  "arg1 as a tracer 
arg2"  "arg1 as the carrier arg2     "arg1 as 
the inert arg2"  "arg1 as the primary 
cleaning arg2     "arg1 and other noxious 
arg2"  "arg1 and other trace arg2"   "arg1 
as the reagent arg2"  "arg1 as the tracer 
arg2     

nell architecture 

knowledge base 
(latent variables) 

 beliefs 

candidate 

beliefs 

 
 
 
 
 
 

orthographic

classifier 

 

(cml) 

evidence 
integrator 

 

url specific 

html 
patterns 
(seal) 

human 
advice 

 
 

actively 
search for 
web text 

(openeval) 

infer new 
beliefs from 

 
 
old 
 
 

(pra) 

image 
classifier 

 

(neil) 

ontology 
extender 

 

(ontext) 

 
 
 
 
 
 

text 

context 
patterns 
(cpl) 

key idea 4:  cumulative, staged learning 

learning x improves ability to learn y 

1.    classify noun phrases (np   s) by category 
2.    classify np pairs by relation 
3.    discover rules to predict new relation instances 
4.    learn which np   s (co)refer to which latent concepts 
5.    discover new relations to extend ontology 
6.    learn to infer relation instances via targeted id93 
7.    vision: connect nell and neil  
nell is here  
8.    learn to microread single sentences 
9.    learn to assign temporal scope to beliefs 
10.    goal-driven reading: predict, then read to corroborate/correct 
11.    make nell a conversational agent on twitter 
12.    add a robot body to nell 
 

consistency  
correctness  
self reflection  

the core problem: 
       agents can measure internal consistency,  

but not correctness 

 
challenge: 
       under what conditions does consistency       correctness? 

the core problem: 
       agents can measure internal consistency,  

but not correctness 

 
challenge: 
       under what conditions does consistency       correctness? 
       can an autonomous agent determine its accuracy from 

observed consistency? 

 

problem setting:  
       have n different estimates               of target function 

[platanios, blum, mitchell, uai 2014] 

       agreement between fi, fj  : 

problem setting:  
       have n different estimates               of target function 

[platanios, blum, mitchell, uai 2014] 

       agreement between fi, fj  : 
 
key insight: errors and agreement rates are related 

pr[neither makes error] + pr[both make error] 

prob. fi and fi 

 agree 

prob. fi 
 error 

prob. fj 
error 

prob.  fi and fj 
both make error 

estimating error from unlabeled data 
1.    if f1 , f2 ,  f3 make indep. errors, and accuracies > 0.5 
     then  
               
 
measure errors from unlabeled data: 
 - use unlabeled data to estimate a12, a13, a23 
 - solve three equations for three unknowns e1, e2, e3 
 
   

estimating error from unlabeled data 
1.    if f1 , f2 ,  f3 make indep. errors, accuracies > 0.5 
     then  
               
 
2. but if errors not independent 
     

estimating error from unlabeled data 
1.    if f1 , f2 ,  f3 make indep. errors, accuracies > 0.5 
     then  
               
 
2. but if errors not independent 
 

 
 
 
 
 
 
 
 

true error (red), estimated error (blue) 

[platanios, blum, mitchell, uai 2014] 

nell classifiers: 

true error (red), estimated error (blue) 

[platanios, blum, mitchell, uai 2014] 

nell classifiers: 

brain image fmri classifiers: 

summary 
1.    use coupled training for semi-supervised learning 
2.    datamine the kb to learn probabilistic id136 rules 
3.    automatically extend ontology 
4.    use staged learning curriculum  

incorporate vision with neil (abhinav gupta) 

new directions: 
       self-reflection, self-estimates of accuracy (a. platanios) 
      
       microreading (jayant krishnamurthy, ndapa nakashole) 
       aggressive ontology expansion (derry wijaya) 
       portuguese nell (estevam hrushka) 
       never-ending learning phones?  robots?  traffic lights? 

thank you 
 
 
and thanks to: 
       darpa, google, nsf, yahoo!, microsoft, fulbright, intel 
 
follow nell on twitter:  @cmunell 
browse/download nell   s kb at http://rtw.ml.cmu.edu 
 
 

