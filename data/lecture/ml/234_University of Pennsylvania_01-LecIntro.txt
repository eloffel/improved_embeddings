cis 519/419 

applied machine learning

www.seas.upenn.edu/~cis519

dan roth
danroth@seas.upenn.edu
http://www.cis.upenn.edu/~danroth/
461c, 3401 walnut

slides were created by dan roth (for cis519/419 at penn or cs446 at uiuc), eric eaton 
for cis519/419 at penn, or from other authors who have made their ml slides available. 

cis419/519 spring    18

course overview

introduction: basic problems and questions

   
    a detailed example: linear classifiers; key algorithmic idea
   

two basic paradigms:
    discriminative learning & generative/probablistic learning 
learning protocols: 
   

supervised; unsupervised; semi-supervised

   

    algorithms

linear representations: (id88; id166s; kernels)

    id119
    id90 
   
    neural networks/deep learning
   
    unsupervised /semi supervised: em
    id91; id84

probabilistic representations (na  ve bayes)

    modeling; evaluation; real world challenges 
   

ethics 

cis419/519 spring    18

2

cis519 on the web

    check our class website:

    schedule, slides, videos, policies

    http://www.seas.upenn.edu/~cis519/spring2018/

    sign up, participate in our piazza forum:

    announcements and discussions
    http://piazza.com/upenn/spring2018/cis419519

    check out our team

    office hours

    canvas:

    notes, homework and videos will be open. 

   

[optional] discussion sessions:

    starting this wednesday, 5:30pm: python tutorial
    active learning class,  3401 wing b/c

    scribing the class [good writers; latex]?

cis419/519 spring    18

3

what is learning

    the badges game      

    this is an example of the key learning protocol: supervised learning

    first question: are you sure you got it?

    why?

cis419/519 spring    18

4

training data
+ peter bartlett
- eric baum
+ welton becket
- shai ben-david
+ george berg
+ neil berkman
+ malini bhandaru
+ bir bhanu
+ reinhard blasig
- avrim blum
- anselm blumer
+ justin boyan

+ carla e. brodley
+ nader bshouty
- wray buntine
- andrey burago
+ tom bylander
+ bill byrne
- claire cardie
+ john case
+ jason catlett
- philip chan
- zhixiang chen
- chris darken

+ naoki abe
- myriam abramson
+ david w. aha
+ kamal m. ali
- eric allender
+ dana angluin
- chidanand apte
+ minoru asada
+ lars asker
+ javed aslam
+ jose l. balcazar
- cristina baroglio

cis419/519 spring    18

5

the badges game

   

+ naoki abe

- eric baum

    conference attendees to the 1994 machine learning 

conference were given name badges labeled with + or    .

    what function was used to assign these labels? 

cis419/519 spring    18

6

raw test data
j. r. quinlan
priscilla rasmussen
dan roth
yoram singer
lyle h. ungar

shivani agarwal
gerald f. dejong
chris drummond
yolanda gil
attilio giordana
jiarong hong

cis419/519 spring    18

7

labeled test data

? shivani agarwal
+ gerald f. dejong
- chris drummond
+ yolanda gil
- attilio giordana
+ jiarong hong

- j. r. quinlan
- priscilla rasmussen
+ dan roth
+ yoram singer
- lyle h. ungar

cis419/519 spring    18

8

what is learning

    the badges game      

    this is an example of the key learning protocol: supervised learning

    first question: are you sure you got it?

    why?
    issues:

    which problem was easier?
    prediction or modeling?
    representation
    problem setting
    background knowledge
    when did learning take place?
    algorithm: can you write a program that takes this data as input and 

predicts the label for your name?

cis419/519 spring    18

9

supervised learning

input

x    x

an item x

drawn from an 
input space x

system 
y = f(x)

output

y    y

an item y

drawn from an 
output space y

    we consider systems that apply a function f() 
to input items x and return an output y = f(x).

cis419/519 spring    18

10

supervised learning

input

x    x

an item x

drawn from an 
input space x

system 
y = f(x)

output

y    y

an item y

drawn from an 
output space y

    in (supervised) machine learning, we deal with 

systems whose f(x) is learned from examples.

cis419/519 spring    18

11

why use learning?

    we typically use machine learning when the function f(x) 

we want the system to apply is unknown to us, and we 
cannot    think    about it. the function could actually be 
simple. 

cis419/519 spring    18

12

supervised learning

input

x    x

target function

y = f(x)

learned model

y = g(x)

output

y    y

an item x

drawn from an 
instance space x

an item y

drawn from a label 

space y

cis419/519 spring    18

13

supervised learning: training

labeled training 

data
d train
(x1, y1)
(x2, y2)

   

(xn, yn) 

can you suggest other 

learning protocols?

learning 
algorithm

learned 
model
g(x)

    give the learner examples in d train
    the learner returns a model g(x)

cis419/519 spring    18

g(x) is the model we   ll 
use in our application
14

supervised learning: testing

labeled
test data

d test
(x   1, y   1)
(x   2, y   2)

   

(x   m, y   m) 

    reserve some labeled data for testing

cis419/519 spring    18

15

supervised learning: testing

labeled
test data

d test
(x   1, y   1)
(x   2, y   2)

   

(x   m, y   m) 

raw test 

data
x test
x   1
x   2
   .
x   m

cis419/519 spring    18

test 
labels
y test
y   1
y   2
...
y   m

16

supervised learning: testing

can you use the test 
data otherwise?

raw test 

    apply the model to the raw test data
    evaluate by comparing predicted labels against the test labels
test 
labels
y test
y   1
y   2
...
y   m

predicted
labels
g(x test)
g(x   1)
g(x   2)
   .
g(x   m)

data
x test
x   1
x   2
   .
x   m

learned 
model
g(x)

cis419/519 spring    18

17

supervised  learning : examples

    disease diagnosis  

    x: properties of patient (symptoms, lab tests)
f : disease (or maybe: recommended therapy)
   

    part-of-speech tagging  

    x: an english sentence (e.g., the can will rust)
   

f : the part of speech of a word in the sentence

    face recognition 

    x: bitmap picture of person   s face
   

f : name the person (or maybe: a property of)

    automatic steering

    x: bitmap picture of road surface in front of car
   

f : degrees to turn the steering wheel 

many problems 
that do not seem 
like classification 
problems can be 
decomposed to 
classification 
problems. 

cis419/519 spring    18

18

course overview

introduction: basic problems and questions

   
    a detailed example: linear classifiers; key algorithmic idea
   

two basic paradigms:
    discriminative learning & generative/probablistic learning 
learning protocols: 
   

supervised; unsupervised; semi-supervised

   

    algorithms

linear representations: (id88; id166s; kernels)

    id119
    id90 
   
    neural networks/deep learning
   
    unsupervised /semi supervised: em
    id91; id84

probabilistic representations (na  ve bayes)

    modeling; evaluation; real world challenges 
   

ethics 

cis419/519 spring    18

19

key issues in machine learning
    modeling

    how to formulate application problems as machine learning 

problems ?  how to represent the data?

    learning protocols (where is the data & labels coming from?) 

    representation

    what functions should we learn (hypothesis spaces) ? 
    how to map raw input to  an instance space?
    any rigorous way to find these? any general approach?

    algorithms

    what are good algorithms? 
    how do we define success? 
    generalization vs. over fitting
    the computational problem

cis419/519 spring    18

20

using supervised learning

    what is our instance space?

    gloss: what kind of features are we using?

    what is our label space?

    gloss: what kind of learning task are we dealing with?

    what is our hypothesis space?

    gloss: what kind of functions (models) are we learning?

    what learning algorithm do we use?

    gloss: how do we learn the model from the labeled data?

    what is our id168/evaluation metric?

    gloss: how do we measure success? what drives learning?

cis419/519 spring    18

21

1. the instance space x
input
output

x   x

an item x

drawn from an 
instance space x

learned
model
y = g(x)

y   y

an item y

drawn from a label 

space y

    designing an appropriate instance space x 

is crucial for how well we can predict y.

cis419/519 spring    18

22

1. the instance space x

does it add anything?

    when we apply machine learning to a task, we first need 

to define the instance space x.

    instances x     x are defined by features:

    boolean features:

    does this email contain the word    money   ?  
    does this email contains the word    money    and the word    send   

    numerical features: 

    how often does    money    occur in this email? 
    what is the width/height of this bounding box?
    what is the length of the first name?

cis419/519 spring    18

23

what   s x for the badges game?

    possible features:

    gender/age/country of the person?
    length of their first or last name?
    does the name contain letter    x   ? 
    how many vowels does their name contain? 
   
    height; 
    shoe size 

is the n-th letter a vowel? 

cis419/519 spring    18

24

x as a vector space

    each dimension = one feature.

    x is an n-dimensional vector space (e.g. <n) 
    each x is a feature vector (hence the boldface x).
    think of x  = [x1     xn] as a point in x :

x2

cis419/519 spring    18

x1

25

good features are essential

    the choice of features is crucial for how well a task can be 

learned.
   

in many application areas (language, vision, etc.),  a lot of work 
goes into designing suitable features.

    this requires domain expertise.

    think about the badges game     what if you were focusing 

on visual features? 

    we can   t teach you what specific features 

to use for your task.
    but we will touch on some general principles

cis419/519 spring    18

27

2. the label space y

input

x   x

an item x

drawn from an 
instance space x

learned 
model
y = g(x)

output

y   y

an item y

space y

drawn from a label 

    the label space y determines what kind of 
supervised learning task we are dealing with

cis419/519 spring    18

28

supervised learning tasks i

    binary classification: two possible labels
    multiclass classification: k possible labels

    output labels y   y are categorical:
    output labels y   y are structured objects (sequences of labels, 

parse trees, etc.)
    structure learning

cis419/519 spring    18

29

supervised learning tasks ii

    output labels y   y are numerical:

    regression (linear/polynomial): 
    labels are continuous-valued 
    learn a linear/polynomial function f(x)

    ranking: 

    labels are ordinal 
    learn an ordering f(x1) > f(x2) over input

cis419/519 spring    18

30

3. the model g(x)

input

x   x

an item x

drawn from an 
instance space x

learned 
model
y = g(x)

output

y   y

an item y

space y

drawn from a label 

    we need to choose what kind of model 

we want to learn

cis419/519 spring    18

31

a learning problem

x1
x2
x3
x4

unknown
function

y  = f (x1, x2, x3, x4)

can you learn this function? 

what is it? 

example  x1 x2 x3 x4     y
1
0     0     1     0     0
2
0     1     0     0     0
0     0     1     1     1
3
4          1      0     0     1     1
0      1    1     0     0
5
1      1    0     0     0
6 
7 
0      1     0     1    0

cis419/519 spring    18

32

hypothesis space

complete ignorance: 
there are 216 = 65536 possible functions 
over four input features.

we can   t figure out which one is 
correct until we   ve seen every 
possible input-output pair. 

after observing seven examples we still
have 29 possibilities for f

1
2 

example  x1 x2 x3 x4     y
0     0     0     0      ?
0     0     0     1      ?
    there are |y||x| possible 
0     0     1     0   0
functions f(x) from the instance 
0     0     1     1 
1
space x to the label space y. 
0     1     0     0      0
0     1     0     1 
0
    learners typically consider only 
0     1     1     0 
0
0     1     1     1     ?
a subset of the functions from x
1     0     0     0     ?
to y, called the hypothesis 
1     0     0     1     1
1     0     1     0     ?
1     0     1     1     ?
1     1     0     0      0
1     1     0     1     ?
1     1     1     0     ?
1     1     1     1     ?

space h . h    |y||x|

16   

is learning possible?

cis419/519 spring    18

33

hypothesis space (2)

0     0     1     0     0
1
0     1     0     0     0
2
0     0     1     1    1
3
4           1     0     0    1     1
5
0      1    1     0     0
1      1    0     0     0
6 
7 
0      1     0     1    0

simple rules: there are  only 16 simple conjunctive rules 
of the form     y=xi    xj    xk

rule               counterexample
y=c
x1 
x2 
x3 
x4 
x1    x2
x1     x3 
x1    x4 

1100  0
0100  0
0110  0
0101  1
1100   0
0011  1
0011  1

rule               counterexample
x2    x3
x2    x4
x3    x4 
x1    x2    x3 
x1    x2    x4 
x1    x3    x4 
x2    x3    x4 
x1    x2    x3    x4 

0011  1
0011  1
1001  1
0011 1
0011 1
0011 1
0011 1
0011 1

no simple rule explains the data. the same is true for simple clauses.

cis419/519 spring    18

34

hypothesis space (3)

don   t worry, this function is 
actually a neural network   

notation: 2 variables from the set on the 
left. value: index of the counterexample.

m-of-n rules:  there are 32 possible rules 
of the form    y = 1  if and only if at least m 
of the following n variables are 1   

0     0     1     0     0
1
0     1     0     0     0
2
0     0     1     1    1
3
4           1      0     0     1     1
5
0      1    1     0     0
1      1    0     0     0
6 
7 
0      1     0     1    0

variables         1-of 2-of 3-of 4-of
{x1}
{x2}
{x3}
{x4}
{x1,x2}
{x1, x3}
{x1, x4}
{x2,x3}

-
3      -
found a consistent hypothesis!
2      -
-
-
1      -
-
7      -
2      3      -
1      3      -
6      3      -
2     3      -

variables         1-of 2-of 3-of 4-of
{x2, x4}
{x3, x4}
{x1,x2, x3}
{x1,x2, x4}
{x1,x3,x4}
{x2, x3,x4}
{x1, x2, x3,x4}

-
2      3      -
4      4       -
-
1      3       3      -
2      3       3      -
1              
3      -
1      5       3      -
1      5       3      3

-
-
-
-
-
-
-
-

cis419/519 spring    18

35

views of learning

    learning is the removal of our remaining uncertainty: 
    suppose we knew that the unknown function was an m-of-n 
boolean function, then we could use the training data to infer 
which function it is.

    learning requires guessing a good hypothesis class: 

    we can start with a very small class and enlarge it until it contains 

an hypothesis that fits the data.

    we could be wrong !

    our prior knowledge might be wrong:   
    y=x4     one-of (x1, x3) is also consistent

    our guess of the hypothesis space could be wrong

    if this is the unknown function, then we will make errors when we are 

given new  examples, and are asked to predict the value of the 
function

cis419/519 spring    18

36

general strategies for machine 

learning
    develop flexible hypothesis spaces:  

    id90, neural networks, nested collections.

    develop representation languages for restricted classes of 

functions:
    serve to limit the expressivity of the target models
    e.g., functional representation (n-of-m); grammars;  linear 

functions; stochastic models; 

    get flexibility by augmenting the feature space  

    in either case:

    develop algorithms for finding a hypothesis in our hypothesis 

space, that fits the data 

    and hope that they will generalize well

cis419/519 spring    18

37

administration

    the class is still full. 
    we had a first python session yesterday. 

    we will continue next week.

    discussion sessions will be held each week on

    tuesday, 6:30
    wednesday, 5:30pm: python
    active learning class,  3401 walnut, 401b 

    the next two will still be about python. we   ll move to give other 
complementary material that is relevant to the class and the hw.

    both sessions will be identical

    anyone wants to go but cannot make any of these?
    questions?

    please ask/comment during class.

cis419/519 spring    18

40

key issues in machine learning
    modeling

    how to formulate application problems as machine learning 

problems ?  how to represent the data?

    learning protocols (where is the data & labels coming from?) 

    representation

    what functions should we learn (hypothesis spaces) ? 
    how to map raw input to  an instance space?
    any rigorous way to find these? any general approach?

    algorithms

    what are good algorithms? 
    how do we define success? 
    generalization vs. over fitting
    the computational problem

cis419/519 spring    18

41

an example: modeling

i don   t know {whether, weather} to laugh or cry

how can we make this a learning problem?

this is the modeling step

    we will look for a function 

f: sentences    {whether, weather}

    we need to define the domain of this function better.

what is the hypothesis space? 

    an option: for each word w in english define a boolean feature xw :  

[xw =1] iff w is in the sentence

    this maps a sentence to a point in {0,1}50,000
    in this space:   some points are whether points

some are weather points

learning protocol?
supervised? unsupervised?
42

cis419/519 spring    18

representation step: what   s good? 

sgn(z) =0 if z<0; 

                                         
                           =           =1

1 otherwise
    learning problem: 
find a function that 

best separates the data

    what function?
    what   s best?
    (how to find it?)

linear = linear in the feature space
x= data representation; w = the classifier 
(w, x, column vectors of dimensionality n)

y = sgn {wtx}

memorizing vs. learning
accuracy vs. simplicity

how well will you do?

on what? 

impact on generalization

    a possibility: define the learning problem to be:         

    a (linear) function that best separates the data

cis419/519 spring    18

43

probabilistic classifiers as well

expressivity  

    many functions are linear 

    conjunctions:

    y = x1    x3    x5                                        

f(x) = sgn {                           -   } = sgn{           =1                                          -    }
    y = sgn{1     x1 + 1     x3 + 1     x5 - 3};             w = (1, 0, 1, 0, 1)   =3
    y = sgn{1     x1 + 1     x3 + 1     x5 - 2} };           w = (1, 0, 1, 0, 1)   =2
    xor: y = (x1    x2 )   (          1      x2 )

    non trivial dnf: y = ( x1    x2 )    (  x3    x4 ) 

    y = at least 2 of {x1 ,x3, x5 }       

    at least m of n:

    many functions are not

    but can be made linear
    note: all the variables above are boolean variables

cis419/519 spring    18

44

functions can be made linear

    data are not linearly separable in one dimension
    not separable if you insist on using a specific class of 

functions (e.g., linear)

x

cis419/519 spring    18

45

blown up feature space

    data are separable in <x, x2> space
key issue: representation:
what features to use.
computationally, can be 
done implicitly  (kernels) 

x2

not always ideal.

cis419/519 spring    18

46

x

exclusive-or  (xor)

in general: a parity function.

(x1    x2)    (  {x1}     {x2})
xi    {0,1}

f(x1, x2,   , xn) = 1 

iff     xi is even

x2

   
   

   
   

this function is not 
linearly separable.

cis419/519 spring    18

x1

47

functions can be made linear

a real weather/whether 
example

discrete case

x1 x2 x4    x2 x4 x5    x1 x3 x7

whether

y3    y4    y7

new discriminator is 
functionally simpler

weather

space: x= x1, x2,   , xn

input transformation

cis419/519 spring    18

new space: y = {y1,y2,   } = {xi,xi xj, xi xj xj,   }
48

representation (1)

feature types:

(what does the algorithm know about the input): 
1. relative position (+/-1) has this pos/w
2. conjunctions of size two 
3. word w occurs in (-2,+2) window around target

note: 4 feature types; many features

the feature resulting from instantiating the 
type in the given data
some statistics (not 
part of the learning 
process; just for the 
understanding of the 
problem) 

cis419/519 spring    18

49

representation (2)

extracting features from the data:

(what does the algorithm know about the input): 
1. relative position (+/-1); pos/w
2. conjunctions of size two 

note: 2 feature types; many features
for each feature type, the data gives rise to multiple 
features; you don   t know which, before you see the 
data. 

cis419/519 spring    18

50

representation (3)

each example corresponds to one target occurrence; 
all the features for this target are collected into a 
vector, and the label is added.
here: 
- sparse representation of the feature vector. why?
- variable size: why?

here the first index 
(0/1) is the label)

cis419/519 spring    18

51

third step: how to learn? 

    a possibility: local search

   

start with a linear threshold function. 
see how well you are doing.

   
    correct
    repeat until you converge.

    there are other ways that

do not search directly in
the hypotheses space
    directly compute the 

hypothesis

cis419/519 spring    18

52

a general framework for 

learning

   

   

goal: predict an unobserved output value y 2 y 
based on an observed input vector x  2 x
estimate a functional relationship y~f(x) 
from a set  {(x,y)i}i=1,n

    most relevant - classification: y     {0,1} (or y     {1,2,   k} )

   

(but, within the same framework can also talk about regression, y 2 < )

simple id168: # of mistakes

[   ] is a indicator function

    what do we want f(x) to satisfy? 

    we want to minimize the risk:  l(f()) = e x,y( [f(x)   y] )
    where: e x,y denotes the expectation with respect to the true 

distribution.

cis419/519 spring    18

53

a general framework for 

learning (ii)

    we want to minimize the loss:   l(f()) = e x,y( [f(x)   y] )
    where: e x,y denotes the expectation with respect to the true distribution.

side note: if the distribution over x  y is known, 
predict:         y = argmaxy p(y|x)
this is the best possible (the optimal bayes' error).

    we cannot minimize this loss  
    instead, we try to minimize the empirical classification error. 
    for a set of training examples {(xi,yi)}i=1,m
   

try to minimize:             l   (f()) = 1/m   i [f(xi)   yi]         (m=# of examples) 
   

(issue i: why/when is this good enough? not now)

    this minimization problem is typically np hard. 
   

to alleviate this computational problem, minimize a new function     a convex 
upper bound of the classification error function

i(f(x),y) =[f(x)    y] = {1 when f(x)   y; 0 otherwise} 

cis419/519 spring    18

54

algorithmic view of learning: an 

optimization problem

    a id168 l(f(x),y) measures the penalty incurred by 

a classifier f on example (x,y).

    there are many different id168s one could define:

    misclassification error:

l(f(x),y) = 0 if f(x) = y;       1 otherwise

    squared loss:

l(f(x),y) = (f(x)     y)2

   

input dependent loss:

a continuous convex  loss 
function allows  a simpler 
optimization algorithm.

l

l(f(x),y) = 0 if f(x)= y;     c(x)otherwise.

cis419/519 spring    18

f(x)    y

55

loss

here f(x) is the prediction 2 <
y 2 {-1,1} is the correct value
0-1 loss     l(y,f(x))=    (1-sgn(yf(x)))
log loss     1/ln2 log (1+exp{-yf(x)})
hinge loss l(y, f(x)) = max(0, 1 - y  f(x))
square loss l(y, f(x)) = (y - f(x))2

cis419/519 spring    18

0-1 loss     x axis = yf(x)
log loss =  x axis = yf(x) 
hinge loss: x axis = yf(x) 
square loss: x axis  = (y - f(x)+1)

56

administration

    the class is still full. 
    we will continue with python sessions this week.

    tuesday, 6:30
    wednesday, 5:30pm
    active learning class,  3401 walnut, 401b 

    we   ll move to give other complementary material that is 

relevant to the class and the hw.
    both sessions will be identical

    hw 1 will be released on thursday
    quiz 1 will be released on friday 

    deadline: monday 11:59pm . 

    questions?

    please ask/comment during class.

cis419/519 spring    18

57

example

putting it all together:

a learning algorithm

cis419/519 spring    18

third step: how to learn? 

    a possibility: local search

   

start with a linear threshold function. 
see how well you are doing.

   
    correct
    repeat until you converge.

    there are other ways that

do not search directly in
the hypotheses space
    directly compute the 

hypothesis

cis419/519 spring    18

59

learning linear separators

(ltu=linear threshold unit)  

f(x) = sgn {                           -   } = sgn{           =1                                          -    }

    xt= (x1 ,x2,    ,xn)     {0,1}n
    wt= (w1 ,w2,    ,wn)     rn

is the target function. 
       determines the shift

is the feature based 
encoding of the data point

  

with respect to the origin

w

cis419/519 spring    18

60

canonical representation

f(x) = sgn {                           -   } = sgn{           =1                                          -    }

    note: sgn {                           -   }  = sgn {                                 } 

    where: 

    x    = (x, -1)  and w    = (w,   ) 

    moved from an n dimensional representation to an (n+1) 

dimensional representation, but now can look for 
hyperplanes that go through the origin. 

    basically, that means that we learn both w and   

cis419/519 spring    18

61

the risk (err)  e: 
a function of w

general learning principle 

    our goal is to find a w that 
minimizes the expected risk
e(w) = e x,y q(x, y, w) 

    we cannot do it.  
    instead, we  approximate e(w) 

using a finite training set of 
independent samples (xi, yi) 

e(w) ~=~ 1/m    1,m q(xi ,yi, w) 
    to find the minimum, we use a

batch id119 algorithm
    that is, we successively compute 

the loss q: a function of x, w and y

  

w

estimates wt of the optimal parameter vector w:

wt+1 = wt - r e(w) = wt - 1/m    1,m r q(xi ,yi, w) 

cis419/519 spring    18

t here is    time    
or    iteration    # 

62

id119

    we use id119 to determine the weight vector that 

minimizes e(w) (= err (w)) ;

    fixing the set d of examples, e=err is a function of w
    at each step, the weight vector is modified in the direction that 

produces the steepest descent along the error surface.

e(w)

cis419/519 spring    18

w4 w3 w2 w1

w

63

lms: an optimization algorithm

    our hypothesis space is the collection of linear threshold units
    id168:       

    squared loss: lms  (least mean square, l2)
    q(x, y, w) =    (wt x     y)2

  

w

cis419/519 spring    18

64

(i  (subscript)     vector component;    j  (superscript) - time; d     example #)

   

possibly, no weight vector is consistent with the data.  

lms: an optimization algorithm
assumption: x     rn; u     rn is the target weight vector; 
the target (label) is td = u                    noise has been added; so, 
                =        (        )                    =            =1                         (        )                 
        (        )=err(                ) = 12   d           (                                   )2

    let  td be the target value for this example)
    the error the current hypothesis makes on  the data set is:

    let   w(j) be the current weight vector we have
    our prediction on the d-th example x is:

cis419/519 spring    18

65

id119

    to find the best direction in the weight space w we compute 

the gradient of e with respect to each of the components of

                         =[                                 1,                                 2,                                             ]

    this vector specifies the direction that produces the steepest 

increase in e;

    we want to modify          in the direction of -                        

    where (with a fixed step size r):

                =                   1+   w
   w = -r                        

cis419/519 spring    18

66

id119: lms

    we have:         (        )=err(                ) = 12   d           (                                   )2

    therefore:

cis419/519 spring    18

   
w
   
i
   
w
   

=

dd
   

e
   
w
   
i
      
1
=    
2
1
=    
2
dd
   
=    
(t
dd
   
      

      

1
2

   

dd
   

(t

d

   

2

)o
d

=

(t

d

   

2

)o
d

=

i

2(t

d

   

)o
d

d    

o

d

)(-x

id

   
w
   
)

(t

d

   

   
w

d

   
)x
d

   

=

i

67

alg1: id119: lms

    id119 algorithm for training linear units:

    weight update rule: 

   wi =           d           (                                   )                        
    evaluate the linear unit                 =        (        )                    =            =1                         (        )                 
    update w by adding    wi to each component

    start with an initial random weight vector
    for every example d with target value td  do: 

    continue until e below some threshold

this algorithm always converges to a local minimum of e(w), for small enough steps. 
here (lms for id75), the surface contains only a single global minimum, 
so the algorithm converges to a  weight vector with minimum error, regardless of 
whether the examples are linearly separable.
the surface may have local minimum if the  id168 is different.

cis419/519 spring    18

68

(lms)

alg 2: incremental (stochastic) id119: 
dropped the averaging operation.
instead of averaging the gradient of 
the loss over the complete training 
set, choose at random a sample 
(x,y) (or a subset of examples) and 

    weight update rule:   wi =                                                                   

    id119 algorithm for training linear units:

update wt

    start with an initial random weight vector
    for every example d with target value td  do: 

    evaluate the linear unit                 =        (        )                    =            =1                         (        )                 
    update w by  incrementally by adding    wi to each component  

(update without summing over all data)
    continue until e below some threshold 

    in general - does not converge to global minimum
    decreasing r with time guarantees convergence  
    but, on-line algorithms are sometimes advantageous   

cis419/519 spring    18

69

learning rates and convergence

    in the general (non-separable) case the learning rate r 

must decrease to zero to guarantee convergence.

    the learning rate is called the step size. there are more 

sophisticated algorithms that choose the step size 
automatically and converge faster. 

    choosing a better starting point also has impact. 

    the id119 and its stochastic version are very 
simple algorithms, but almost all the algorithms we will 
learn in the class can be traced back to gradient decent 
algorithms for different id168s and different 
hypotheses spaces. 

cis419/519 spring    18

70

computational issues

    assume the data is linearly separable.
    sample complexity:

   

suppose we want to ensure that our ltu has an error rate (on new examples) of 
less than    with high id203 (at least (1-  ))

    how large does m (the number of examples) must be in order to achieve this ? it 

can be shown that for n dimensional problems

m = o(1/    [ln(1/   ) + (n+1) ln(1/   ) ].

    computational complexity: what can be said?

   

   

   

it can be shown that there exists a polynomial time algorithm for finding  
consistent ltu (by reduction from id135). 
[contrast with the np hardness for 0-1 loss optimization]
(on-line algorithms have inverse quadratic dependence on the margin)

cis419/519 spring    18

71

other methods for ltus

    fisher linear discriminant:
    a direct computation method

    probabilistic methods (na  ve bayes):

    produces a stochastic classifier that can be viewed as a linear 

threshold unit.

    winnow/id88

    a multiplicative/additive update algorithm with some sparsity
properties in the function space (a large number of irrelevant 
attributes) or features space (sparse examples)

    id28, id166   many other algorithms

cis419/519 spring    18

72

