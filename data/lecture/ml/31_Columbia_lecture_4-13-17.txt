coms 4721: machine learning for data science

lecture 21, 4/13/2017

prof. john paisley

department of electrical engineering

& data science institute

columbia university

id48

overview

motivation
we have seen how markov models can model sequential data.
(cid:73) we assumed the observation was the sequence of states.
(cid:73) instead, each state may de   ne a distribution on observations.

hidden markov model
a hidden markov model treats a sequence of data slightly differently.

(cid:73) assume a hidden (i.e., unobserved, latent) sequence of states.
(cid:73) an observation is drawn from the distribution associated with its state.

s1s2s3s4markov modelsn   1snsn+1xn   1xnxn+1s1s2x1x2hidden markov modelmarkov to id48

markov models
imagine we have three possible states in r2.
the data is a sequence of these positions.

since there are only three unique positions,
we can give an index in place of coordinates.

for example, the sequence (1, 2, 1, 3, 2, . . . )
would map to a sequence of 2-d vectors.

using the notation of the    gure, a is a 3    3 transition matrix. aij is the
id203 of transitioning from state i to state j.

a12a23a31a21a32a13a11a22a33k=1k=2k=3markov to id48

id48
now imagine the same three states, but each
time the coordinates are randomly permuted.

the state sequence is still a set of indexes,
e.g., (1, 2, 1, 3, 2, . . . ) of positions in r2.

however, if   1 is the position of state #1,
then we observe xi =   1 +  i if si = 1.

exactly as before, we have a state transition matrix a (in this case 3    3).
however, the observed data is a sequence (x1, x2, x3, . . . ) where each x     r2
is a random perturbation of the state it   s assigned to {  1,   2,   3}.

k=1k=2k=300.5100.51markov to id48

a continuous hidden markov model
this id48 is continuous because each x     r2 in the sequence (x1, . . . , xt ).
(left) a markov state transition distribution for an unobserved sequence

(middle) the state-dependent distributions used to generate observations
(right) the data sequence. colors indicate the distribution (state) used.

a12a23a31a21a32a13a11a22a33k=1k=2k=3k=1k=2k=300.5100.5100.5100.51id48

de   nition
a hidden markov model (id48) consists of:
(cid:73) an s    s markov transition matrix a for transitioning between s states.
(cid:73) an initial state distribution    for selecting the    rst state.
(cid:73) a state-dependent emission distribution, prob(xi|si = k) = p(xi|  si).
the model generates a sequence (x1, x2, x3 . . . ) by:
1. sampling the    rst state s1     discrete(  ) and x1     p(x|  s1 ).
2. sampling the markov chain of states, si|{si   1 = k}     discrete(ak,:),

followed by the observation xi|si     p(x|  si).

continuous id48: p(x|  s) is a continuous distribution, often gaussian.
discrete id48: p(x|  s) is a discrete distribution,   s a vector of probabilities.

we focus on discrete case. let b be a matrix, where bk,: =   k (from above).

example: dishonest casino

problem
here is an example of a discrete hidden markov model.

(cid:73) consider two dice, one is fair and one is unfair.
(cid:73) at each roll, we either keep the current dice, or switch to the other one.
(cid:73) the observation is the sequence of numbers rolled.

the transition matrix is

(cid:20) 0.95

0.10

(cid:21)

0.05

0.90

a =

(cid:20) 1

the emission matrix is

b =

6
1
10
let    = [ 1
2

1
6
1
10

1
6
1
10

1
6
1
10

1
6
1
2

1
6
1
10

1
2 ].

(cid:21)

(cid:20)(cid:29)(cid:3)(cid:3)(cid:20)(cid:18)(cid:25)(cid:21)(cid:29)(cid:3)(cid:3)(cid:20)(cid:18)(cid:25)(cid:22)(cid:29)(cid:3)(cid:3)(cid:20)(cid:18)(cid:25)(cid:23)(cid:29)(cid:3)(cid:3)(cid:20)(cid:18)(cid:25)(cid:24)(cid:29)(cid:3)(cid:3)(cid:20)(cid:18)(cid:25)(cid:25)(cid:29)(cid:3)(cid:3)(cid:20)(cid:18)(cid:25)(cid:20)(cid:29)(cid:3)(cid:3)(cid:20)(cid:18)(cid:20)(cid:19)(cid:21)(cid:29)(cid:3)(cid:3)(cid:20)(cid:18)(cid:20)(cid:19)(cid:22)(cid:29)(cid:3)(cid:3)(cid:20)(cid:18)(cid:20)(cid:19)(cid:23)(cid:29)(cid:3)(cid:3)(cid:20)(cid:18)(cid:20)(cid:19)(cid:24)(cid:29)(cid:3)(cid:3)(cid:20)(cid:18)(cid:20)(cid:19)(cid:25)(cid:29)(cid:3)(cid:3)(cid:24)(cid:18)(cid:20)(cid:19)(cid:19)(cid:17)(cid:28)(cid:24)(cid:19)(cid:17)(cid:28)(cid:19)(cid:19)(cid:17)(cid:20)(cid:19)(cid:17)(cid:19)(cid:24)some estimation problems

state estimation
(cid:73) given: an id48 {  , a, b} and observation sequence (x1, . . . , xt )
(cid:73) estimate: state id203 for xi using    forward-backward algorithm,   

p(si = k | x1, . . . , xt ,   , a, b).

state sequence
(cid:73) given: an id48 {  , a, b} and observation sequence (x1, . . . , xt )
(cid:73) estimate: most probable state sequence using the    viterbi algorithm,   

s1, . . . , st = arg max

s

p(s1, . . . , st | x1, . . . , xt ,   , a, b).

learn an id48

(cid:73) given: an observation sequence (x1, . . . , xt )
(cid:73) estimate: id48 parameters   , a, b using maximum likelihood

  ml, aml, bml = arg max
  ,a,b

p(x1, . . . , xt |   , a, b)

examples

before we look at the details, here are examples for the dishonest casino.
(cid:73) not shown is that   , a, b were learned    rst in order to calculate this.
(cid:73) notice that the right plot isn   t just a rounding of the left plot.

state estimation result

state sequence result

gray bars: loaded dice used

blue: id203 p(si = loaded|x1:t ,   , a, b)

gray bars: loaded dice used

blue: most probable state sequence

05010015020025030000.51roll numberp(loaded)filtered05010015020025030000.51roll numbermap state (0=fair,1=loaded)viterbilearning the id48

learning the id48: the likelihood

we focus on the discrete id48. to learn the id48 parameters, maximize

s(cid:88)
s(cid:88)

s1=1

      

      

s(cid:88)
s(cid:88)

st =1

t(cid:89)

p(x|  , a, b) =

=

p(x, s1, . . . , st |   , a, b)

p(xi | si, b) p(si | si   1,   , a)

s1=1

st =1

i=1

(cid:73) p(xi | si, b) = bsi,xi     si indexes the distribution, xi is the observation
(cid:73) p(si | si   1,   , a) = asi   1,si (or   s1 )     since s1, . . . , st is a markov chain

learning the id48: the log likelihood

s(cid:88)

s(cid:88)

t(cid:89)

(cid:73) maximizing p(x|  , a, b) is hard since the objective has log-sum form

ln p(x|  , a, b) = ln

      

p(xi | si, b) p(si | si   1,   , a)

s1=1

st =1

i=1

(cid:73) however, if we had or learned s it would be easy (remove the sums).

(cid:73) in addition, we can calculate p(s| x,   , a, b), though it   s much more

complicated than in previous models.

(cid:73) therefore, we can use the em algorithm! the following is high-level.

learning the id48: the log likelihood

e-step: using q(s) = p(s| x,   , a, b), calculate

l(x,   , a, b) = eq [ln p(x, s|   , a, b)] .

m-step: maximize l with respect to   , a, b.

this part is tricky since we need to take the expectation using q(s) of

ln p(x, s|   , a, b) =

s(cid:88)
t(cid:88)
(cid:124)
s(cid:88)
t(cid:88)

k=1

i=1

+

(cid:123)(cid:122)
(cid:124)

s(cid:88)

s(cid:88)

k=1

(cid:124)

(cid:125)

(cid:123)(cid:122)

1(si   1 = j, si = k) ln aj,k

i=2

j=1

k=1

markov chain

1(si = k) ln bk,xi

+

1(s1 = k) ln   k

observations

initial state

(cid:125)

(cid:123)(cid:122)
(cid:125)

the following is an overview to help you better navigate the books/tutorials.1

1see the classic tutorial: rabiner, l.r. (1989).    a tutorial on id48 and

selected applications in id103.    proceedings of the ieee 77(2), 257   285.

learning the id48 with em

e-step
let   s de   ne the following conditional posterior quantities:

  i(k) = the posterior id203 that si = k

  i(j, k) = the posterior id203 that si   1 = j and si = k

therefore,   i is a vector and   i is a matrix, both varying over i.

we can calculate both of these using the    forward-backward    algorithm.
(we won   t cover it in this class, but rabiner   s tutorial is good.)

given these values the e-step is:

s(cid:88)

l =

  1(k) ln   k +

t(cid:88)

s(cid:88)

s(cid:88)

  i(j, k) ln aj,k +

t(cid:88)

s(cid:88)

i=1

k=1

  i(k) ln bk,xi

k=1

i=2

j=1

k=1

this gives us everything we need to update   , a, b.

learning the id48 with em

m-step
the updates for the id48 parameters are:

  1(k)(cid:80)

j   1(j)

  k =

, aj,k =

(cid:80)t
(cid:80)s
(cid:80)t

i=2

i=2   i(j, k)

l=1   i(j, l)

(cid:80)t
(cid:80)t
i=1   i(k)1{xi = v}

i=1   i(k)

, bk,v =

the updates can be understood as follows:
(cid:73) aj,k is the expected fraction of transitions j     k when we start at j

(cid:73) numerator: expected count of transitions j     k
(cid:73) denominator: expected total number of transitions from j

(cid:73) bk,v is the expected fraction of data coming from state k and equal to v

(cid:73) numerator: expected number of observations = v from state k
(cid:73) denominator: expected total number of observations from state k

(cid:73)    has interpretation similar to a

learning the id48 with em

m-step: n sequences
usually we   ll have multiple sequences that are modeled by an id48. in this
case, the updates for the id48 parameters with n sequences are:

(cid:80)n
(cid:80)n

(cid:80)

n=1  n
n=1

1 (k)
j   n

  k =

bk,v =

n=1

(cid:80)tn
(cid:80)n
(cid:80)s
(cid:80)tn
(cid:80)n
(cid:80)tn
i (k)1{xi = v}
i=1   n

i (k)

n=1

i=2

1 (j)

(cid:80)n

, aj,k =

(cid:80)tn
(cid:80)n

i=1   n
n=1

n=1

i=2   n

i (j, k)
l=1   n

i (j, l)

,

the modi   cations are:

(cid:73) each sequence can be of different length, tn
(cid:73) each sequence has its own set of    and    values
(cid:73) using this we sum over the sequences, with the interpretation the same.

application: speech

recognition

application: id103

problem
given speech in the form of an audio signal, determine the words spoken.

method

(cid:73) words are broken down into small sound units (called phonemes). the

states in the id48 are intended to represent phonemes.

(cid:73) the incoming sound signal is transformed into a sequence of vectors

(feature extraction). each vector xi is indexed by a time step i.

(cid:73) the sequence x1:t of feature vectors is the data used to learn the id48.

phoneme models

phoneme
a phoneme is de   ned as the smallest unit of sound in a language that
distinguishes between distinct meanings. english uses about 50 phonemes.

example

zero
one
two
three
four
five

z ih r ow
w ah n
t uw
th r iy
f ow r
f ay v

six
seven
eight
nine
oh

s ih k s

s eh v ax n

ey t
n ay n

ow

preprocessing speech

e
d
u
t
i
l
p
m
a

y
c
n
e
u
q
e
r
f

time

time

feature extraction

(cid:73) a speech signal is measured as amplitude over time.
(cid:73) the signal is typically transformed into features by breaking down

frequency content of the signal in a sliding time-window.

(cid:73) (above) each column is the frequency content of about 50 milliseconds

(10,000+ dimensional). this can be further reduced to, e.g., 40 dims.

data quantization

we could work directly with the extracted features and learn a gaussian
distribution for each state, i.e., a continuous id48.

to transition to a discrete id48, we can perform vector quantization using a
codebook learned by id116.

id116codebooknew signal(2 2 6 4 4 4 5 5 ... )quantized sequencetraining seta id103 model

these models and problems can become more complex. for now, imagine a
simple automated phone conversation using a question/answer format.

training data: quantized feature sequences of words, e.g.,    yes,       no   

learn: an id48 for each word using all training sequences of that word

predict: let w index the word. predict the word of a new sequence using

wnew = arg max
w

(cid:124)

(cid:123)(cid:122)

p(xnew |   w, aw, bw)

p(w)

requires forward-backward

(cid:125)

notice that this is a bayes classi   er!

(cid:73) we   re learning a class-conditional discrete id48.
(cid:73) we could try something else, e.g., a gmm instead of an id48.
(cid:73) if the gmm predicts better, then use it instead. (but we anticipate that

it won   t since the id48 models sequential information.)

