coms 4721: machine learning for data science

lecture 23, 4/20/2017

prof. john paisley

department of electrical engineering

& data science institute

columbia university

association analysis

setup

many businesses have massive amounts of customer purchasing data.

(cid:73) amazon has your order history
(cid:73) a grocery store knows objects purchased in each transaction
(cid:73) other retailers have data on purchases in their stores

using this data, we may want to    nd sub-groups of products that tend to
co-occur in purchasing or viewing behavior.

(cid:73) retailers can use this to cross-promote products through    deals   
(cid:73) grocery stores can use this to strategically place items
(cid:73) online retailers can use this to recommend content
(cid:73) this is more general than    nding purchasing patterns

market basket analysis

association analysis is the task of understanding these patterns.

for example consider the following    market baskets    of    ve customers.

using such data, we want to analyze patterns of co-occurance within it. we
can use these patterns to de   ne association rules. for example,

{diapers}     {beer}

association analysis and rules

imagine we have:
(cid:73) p different objects indexed by {1, . . . , p}
(cid:73) a collection of subsets of these objects xn     {1, . . . , p}. think of xn as

the index of things purchased by customer n = 1, . . . , n.

association analysis: find subsets of objects that often appear together. for
example, if k     {1, . . . , p} indexes objects that frequently co-occur, then

p(k) =

#{n such that k     xn}

n

is large relatively speaking

example: k = {peanut_butter, jelly, bread}

association rules: learn correlations. let a and b be disjoint sets. then
a     b means purchasing a increases likelihood of also purchasing b.
example: {peanut_butter, jelly}     {bread}

processing the basket

figure: an example of 5 baskets.

figure: a binary representation of these 5 baskets for analysis.

processing the basket

want to    nd subsets that occur with id203 above some threshold.
for example, does {bread, milk} occur relatively frequently?
(cid:73) go to each of the 5 baskets and count the number that contain both.
(cid:73) divide this number by 5 to get the frequency.
(cid:73) aside: notice that the basket might have more items in it.

when n = 5 and p = 6 as in this case, we can easily check every possible
combination. however, real problems might have n     108 and p     104.

some combinatorics

some combinatorial analysis will show that brute-force search isn   t possible.

q: how many different subsets k     {1, . . . , p} are there?

a: each subset can be represented by a binary indicator vector of length p.

the total number of possible vectors is 2p.

q: nobody will have a basket with every item in it, so we shouldn   t check

every combination. how about if we only check up to k items?

a: the number of sets of size k picked from p items is(cid:0)p
example, if p = 104 and k = 5, then(cid:0)p

(cid:1)     1018.

(cid:1) = p!

k!(p   k)!. for

k

k

takeaway: though the problem only requires counting, we need an
algorithm that can tell us which k we should count and which we can ignore.

quantities of interest

before we    nd an ef   cient counting algorithm, what do we want to count?

(cid:73) again, let k     {1, . . . , p} and a, b     k, where a     b = k, a     b =    .

we   re interested in the following empirically-calculated probabilities:
1. p(k) = p(a, b): the prevalence (or support) of items in set k. we

want to    nd which combinations co-occur often.

2. p(b|a) = p(k)

p(a) : the con   dence that b appears in the basket given a is

in the basket. we use this to de   ne a rule a     b.

3. l(a, b) = p(a,b)

p(a)p(b) = p(b|a)

p(b) : the lift of the rule a     b. this is a

measure of how much more con   dent we are in b given that we see a.

example

for example, let

k = {peanut_butter, jelly, bread},

a = {peanut_butter, jelly}, b = {bread}

(cid:73) a prevalence of 0.03 means that peanut_butter, jelly and

bread appeared together in 3% of baskets.

(cid:73) a con   dence of 0.82 means that when both peanut_butter and

jelly were purchased, 82% of the time bread was also purchased.

(cid:73) a lift of 1.95 means that it   s 1.95 more probable that bread will be
purchased given that peanut_butter and jelly were purchased.

apriori algorithm

the goal of the apriori algorithm is to quickly    nd all of the subsets
k     {1, . . . , p} that have id203 greater than a prede   ned threshold t.
(cid:73) such a k will contain items that appear in at least n    t of the n baskets.
(cid:73) a small fraction of such k should exist out of the 2p possibilities.

apriori uses properties about p(k) to reduce the number of subsets that
need to be checked to a small fraction of all 2p sets.
(cid:73) it starts with k containing 1 item. it then moves to 2 items, etc.
(cid:73) sets of size k     1 that    survive    help determine sets of size k to check.
(cid:73) important: apriori    nds every set k such that p(k) > t.

next slide: the structure of the problem can be organized in a lattice.

lattice representation

frequency dependence

we can use two properties to develop an algorithm for ef   ciently counting.

1. if the set k is not big enough, then k(cid:48) = k     a with a     {1, . . . , p} is

not big enough. in other words: p(k) < t implies p(k(cid:48)) < t
e.g., let k = {a, b}. if these items appear together in x baskets, then
the set of items k(cid:48) = {a, b, c} appears in     x baskets since k     k(cid:48).
mathematically: p(k(cid:48)) = p(k, a) = p(a|k)p(k)     p(k) < t

2. by the converse, if p(k) > t and a     k, then p(a) > p(k) > t.

frequency dependence: property 1

frequency dependence: property 2

apriori algorithm (one version)

here is a basic version of the algorithm. it can be improved in clever ways.

apriori algorithm
set a threshold n    t, where 0 < t < 1 (but relatively small).
1. |k| = 1: check each object and keep those that appear in     n    t baskets.
2. |k| = 2: check all pairs of objects that survived step 1 and keep the sets
...
k. |k| = k: using all sets of size k     1 that appear in     n    t baskets,

that appear in     n    t baskets.

(cid:73) increment each set with an object surviving step 1 not already in the set.
(cid:73) keep all sets that appear in     n    t baskets

it should be clear that as k increases, we can hope that the number of sets that
survive decrease. at a certain k < p, no sets will survive and we   re done.

more considerations

1. we can show that this algorithm returns every set k for which p(k) > t.
(cid:73) imagine we know every set of size k     1 for which p(k) > t. then

every potential set of size k that could have p(k) > t will be checked.
e.g. let k = 3: the set {a, b, c} appears in > n    t baskets. will we check it?

known: {a, b} and {c} must appear in > n    t baskets.
assumption: we   ve found k = {a, b} as a set satisfying p(k) > t.
apriori algorithm: we know p({c}) > t and so will check {a, b}   {c}.
induction: we have all |k| = 1 by brute-force search (start induction).
2. as written, this can lead to duplicate sets for checking, e.g., {a, b}     {c}
and {a, c}     {b}. indexing methods can ensure we create {a, b, c} once.
3. for each proposed k, should we iterate through each basket for checking?

there are tricks to make this faster that takes structure into account.

finding association rules

we   ve found all k such that

p(k) > t.

now we want to    nd association rules.
these are of the form p(a|b) > t2
where we split k into subsets a and b.

notice:
1. p(a|b) = p(k)
p(b) .
2. if p(k) > t and a and b partition k, then p(a) > t and p(b) > t.
3. since apriori found all k such that p(k) > t, it found p(a) and p(b),

so we can calculate p(a|b) without counting again.

example

data
n = 6876 questionnaires
14 questions coded into p = 50 items
for example:

(cid:73) ordinal (2 items): pick the item
based on value being     median

(cid:73) categorical: item = category
x categories     x items

(cid:73) based on the item encoding, it   s clear that no    basket    can have every item.

(cid:73) we see that association analysis extends to more than consumer analysis.

example

12