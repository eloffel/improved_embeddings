machine learning

cs 4900/5900

lecture 01

razvan c. bunescu

school of electrical engineering and computer science

bunescu@ohio.edu

what is (human) learning?

    merriam-webster:

    learn = to acquire knowledge, understanding, or skill     by study, 

instruction, or experience.

    why do we learn?

    to improve performance on a given task.

    what (tasks) do we learn:

1.
2.

categorize email, recognize faces, diagnose diseases, translate,    
id91 (fish, insects, birds, mice, humans), summarization, 
sound source separation,    

3. walk, play backgammon, ride bikes, drive cars, fly helicopters,    

lecture 01

2

what is machine learning?

    machine learning = constructing computer programs that 

automatically improve with experience:
    supervised learning i.e. learning from labeled examples.

labeled
training 
examples

unlabeled

test

examples

ml algorithm

model

model

lecture 01

labels

3

what is learning?

?
6

1

2

class c1

lecture 01

3

4

5

class c2

4

occam   s razor

william of occam (1288     1348)

    english franciscan friar, theologian and philosopher.

       entia non sunt multiplicanda praeter necessitatem   

    entities must not be multiplied beyond necessity.

i.e.  do not make things needlessly complicated.
i.e.  prefer the simplest hypothesis that fits the data.

lecture 01

5

what is learning?

?
7

6

1

2

class c1

lecture 01

3

4

5

class c2

6

what is learning?

?
8

6

1

2

class c1

lecture 01

3

7

4

5

class c2

7

what is learning?

?
9

6

1

8

2

class c1

lecture 01

3

7

4

5

class c2

8

what is learning?

?
10

6

1

8

2

3

9

5

7

4

class c1

lecture 01

class c2

9

what is learning?

10

6

1

8

2

3

9

5

7

4

class c1

lecture 01

class c2

10

ml concepts & notation

    a (labeled) example (x, t) consists of:

    instance / observation / raw feature vector x.
    label t.

    examples:

1. digit recognition:

instance x = ?
label t = ?

2. language modelling:

       machine .......... is a hot topic in ai   

eat

...
...
learning

on

instance x = ?
label t = ?

11

ml concepts & notation

    often, a raw observation x is pre-processed and further transformed   

into a feature vector   (x) = [  1(x),   1(x),    ,   k(x)]t.
    where do the features   k come from?

    feature engineering, e.g. in polynomial curve fitting:

    manual, can be time consuming (e.g. sift).

    (unsupervised) id171, e.g. in modern id161

    automatic, used in deep learning models.

lecture 01

12

ml concepts & notation

    a training dataset is a set of (training) examples (x1,t1), (x2,t2),     

(xn,tn):
    the data matrix x contains all instance vectors x1, x2,    , xn row-

wise.

    the label vector t = [t1, t2,    , tn]t.

    a test dataset is a set of (test) examples (xn+1,tn+1),    , (xn+m,tn+m):

    must be different from the training examples!

lecture 01

13

ml concepts & notation

    there is a function f that maps an instance x to its label t = f(x).

    f is unknown / not given.
    but we observe samples from f : (x1,t1), (x2,t2),     (xn,tn).

    learning means finding a model h that maps an instance x to a label 

h(x)     f(x), i.e. close to the true label of x.
    machine learning = finding a model h that approximates well the 

unknown function f.

    machine learning = function approximation!

lecture 01

14

ml concepts & notation

    machine learning is inductive:

    inductive hypothesis: if a model performs well on training examples, 

it is expected to also perform well on unseen (test) examples.

    the model y is often specified through a set of parameters w:

    x is mapped by the model to h(x, w).

    the objective function j(w) captures how poorly the model does on the 

    want to find     "=argmin
    

training dataset:

    (    )

    machine learning = optimization!

lecture 01

15

fitting vs. generalization

    fitting performance = how well the model performs on 

training examples.

    generalization performance = how well the model 

performs on unseen (test) examples.

    we are interested in generalization:

    prefer finding patterns to memorizing examples!

    overfitting:
    id173:

lecture 01

16

training

training examples

(xk, tk)

testing

model h

supervised learning

learning 
algorithm

model h

generalization 
performance

test examples

(x, t)

lecture 01

machine learning vs. deep learning

    
    1,k(x)

    (x)

h

h(    (x),w)

h(    1,k (x),w)

h

x

x

h(x,w)

    1(x)

    2

h

    1

    1,2(x)

   

x

    k

lecture 01

18

what is machine learning?

    machine learning = constructing computer programs that 

automatically improve with experience:
    supervised learning i.e. learning from labeled examples:

    classification
    regression

    unsupervised learning i.e. learning from unlabeled examples:

    id91.
    id84 (visualization).
    density estimation.

    id23 i.e. learning with delayed feedback.

lecture 01

19

supervised learning

    task = learn a function f : x    t that maps input instances 

x    x to output targets t    t:
    classification:

    the output t    t is one of a finite set of discrete categories.

    regression:

    the output t    t is continuous, or has a continuous component.

    supervision = set of training examples:

(x1,t1), (x2,t2),     (xn,tn)

lecture 01

20

classification vs. regression

1

0

-1

0

x

1

0

-1

1

0

xi

lecture 01

1

21

classification: junk email filtering

[sahami, dumais & heckerman, aaai   98]

from: tammy jordan
jordant@oak.cats.ohiou.edu
subject: spring 2015 course
--------------------------------------
cs690: machine learning

instructor: razvan bunescu
email: bunescu@ohio.edu
time and location: tue, thu 9:00 am , arc 101
website: http://ace.cs.ohio.edu/~razvan/courses/ml6830

course description:
machine learning is concerned with the design and analysis of
algorithms that enable computers to automatically find patterns 
in the data. this introductory course will give an overview    

    email filtering:

from: uk national lottery 
edreyes@uknational.co.uk
subject: award winning notice
--------------------------------------
uk  national  lottery.  government 
accredited  licensed  lottery.
registered under the united kingdom  
data protection act;

we happily announce to you the draws of ( uk 
national lottery promotion ) international 
programs held in london , england your email address 
attached to ticket number :3456 with serial number 
:7576/06 drew the lucky number 4-2-274, which 
subsequently won you the lottery in the first category    

    provide emails labeled as {spam, ham}.
    train na  ve bayes model to discriminate between the two.

lecture 01

22

classification: routing in wireless sensor 

networks

[wang, martonosi & peh, secon   06]

    link quality prediction:

    provide a set of training links:

    received signal strength, send/forward buffer sizes
    node depth from base station, forward/backward id203
o lqi = link quality indication, binarized as {good, bad}

- train  id90 model to predict lq using runtime features.

lecture 01

23

classification: handwritten zip code 

recognition

[le cun et al., neural computation    89]

    handwritten digit recognition:

    provide images of handwritten digits, labeled as  {0, 1,    , 9}.
    train neural network model to recognize digits from input images.

lecture 01

24

classification: medical diagnosis

[krishnapuram et al., gensips   02]

    cancer diagnosis from gene expression signatures:

    create database of gene expression profiles (x) from tissues of 

known cancer status (y):

    human accute leukemia dataset:

    http://www.broadinstitute.org/cgi-bin/cancer/datasets.cgi

    colon cancer microarray data:

    http://microarray.princeton.edu/oncology

    train id28 / id166 / rvm model to classify the gene 

expression of a tissue of unknown cancer status.

lecture 01

25

ml for software verification / atp

    software verification requires theorem proving.

    proving a mathematical theorem requires finding and using 

relevant previous theorems and definitions:
    the space of existing theorems and definitions is huge.
    use machine learning to narrow the search space to relevant 

theorems and definitions:

       premise selection for mathematics by corpus analysis and 

kernel methods   , alama et al., jar 2012.

       deepmath     deep sequence models for premise selection   , 

alemi et al., nips 2016.

lecture 01

26

software verification / atp for ml

    an ml model is a program i.e. ml algorithms induce 

programs.

    ml models such as (deep) neural networks may lack 

robustness:
    adversarial methods can fool the networks, e.g. classifying a 

school bus as an ostrich.

    software verification / atp methods can be used to prove an ml 

model has (or not) desirable properties:

       reluplex: an efficient smt solver for verifying deep 

neural networks   , katz et al., cav 2017

    used to prove adversarial robustness for collision 

avoidance system for unmanned aircraft.

lecture 01

27

classification: other examples

    handwritten letter recognition
    face recognition
    credit card applications/transactions
    recommender systems: books, music,    
    fraud detection in e-commerce
    worm detection in network packets
    tone recognition
    chord recognition
    id39

lecture 01

28

regression: examples

1. stock market prediction:

    use the current stock market conditions (x    x) to predict 

tomorrow   s value of a particular stock (t    t).

2. oil price, gdp, income prediction.

3. chemical processes:

    predict the yield in a chemical process based on the concentrations 

of reactants, temperature and pressure.

    algorithms:

    id75, neural networks, support vector machines,    

lecture 01

29

unsupervised learning: hierarchical 

id91

pan troglodytes

homo sapiens

lecture 01

30

100

e
l
a
c
s
 
y
t
i
r
a
l
i

m
i
s

80

60

40

20

0

31

lecture 01

unsupervised learning: id91

    partition unlabeled examples into disjoint clusters such that:

    examples in the same cluster are very similar.
    examples in different clusters are very different.

lecture 01

32

unsupervised learning: id91

    partition unlabeled examples into disjoint clusters such that:

    examples in the same cluster are very similar.
    examples in different clusters are very different.

    need to provide:

- number of clusters (k = 2)
- similarity measure (euclidean)

lecture 01

33

unsupervised learning: dimensionality 

reduction

    manifold learning:

    data lies on a low-dimensional manifold embedded in a high-

dimensional space.

    useful for feature extraction and visualization.

lecture 01

34

id23

   

interaction between agent and environment modeled as a 
sequence of actions & states:
    learn policy for mapping states to actions in order to maximize a 

reward.

    reward given at the end state => delayed reward.
    states may be only partially observable.
    trade-off between exploration and exploitation.

    examples:

    backgammon [tesauro, cacm   95].
    aerobatic helicopter flight [abbeel, nips   07].
    49 atari games, using deep rl [mnih et al., nature   15].

lecture 01

35

id23: td-gammon

[tesauro, cacm   95]

    learn to play backgammon:

    immediate reward:

    +100 if win
    -100 if lose
    0 for all other states

    temporal difference learning with a multilayer id88.
    trained by playing 1.5 million games against itself.
    played competitively against top-ranked players in international 

tournaments.

lecture 01

36

relevant disciplines

    mathematics:

    id203 & statistics
    id205
    id202
    optimization

    algorithms:

    computational complexity

    artificial intelligence

    search

    psychology
    neurobiology

lecture 01

37

readings

    prml 1.2, 2.1     2.1.1, 2.2     2.2.1, 2.3 (2.3.4, 2.3.9).
    prml appendix b and c.

lecture 01

38

