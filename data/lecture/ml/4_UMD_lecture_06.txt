slides adapted from prof. carpuat

cmsc 422 introduction to machine learning

lecture 6 the id88

furong huang / furongh@cs.umd.edu

impact of initialization

optimization view of id116

given a set of observations ("#,"%,   ,"') where each 
observation is a )-dimensional real vector
id116 id91 aims to partition the * observations 
into k(   ") sets s= s#,s%,   ,/0 so as to minimize 
argmin7 88 "   :; %=argmin< 8/;	var(/;)
	
where :; is the mean of points in /;. 

the within-cluster sum of squares.

formally, the objective is to find:

?
;c#

@   7b

?
;

this week

    a new model/algorithm

   the id88
   and its variants: voted, averaged

    fundamental machine learning concepts

   online vs. batch learning
   error-driven learning

    project 1 coming soon!

geometry concept: hyperplane

q separates a d-dimensional 
space into two half-spaces

pointing normal vector 	"      %
q " is orthogonal to any vector 

q defined by an outward 

lying on the hyperplane

q hyperplane passes through 

the origin, unless we also 
define a bias term b

binary classification
via hyperplanes

q let   s assume that the 
decision boundary is a 
hyperplane

finding a hyperplane !

q then, training consists in 

that separates positive 
from negative examples

binary classification
via hyperplanes

at test time, we check on 
what side of the hyperplane 
examples fall

!"=$%&'()*++-)

function approximation
with id88
    problem setting

    set of possible instances !
    each instance "	   ! is a feature vector "=["',   ,"*]
    unknown target function ,:!	   /
    / is binary valued {-1; +1}
    set of function hypotheses 0=    		   :!	   /}
    each hypothesis 3 is a hyperplane in d-dimensional space
    training examples {"',5' ,    "6,56 } of unknown target 
function ,
    hypothesis    	   0	that best approximates target function ,

    output

input

   

perception: prediction algorithm

aside: biological inspiration

analogy: the 
id88
as a neuron

id88 training algorithm

id88 update: 
geometric interpretation

a training example %,' is misclassified, i.e.,
let   s say '=+1

()*+,"#$- %+/    '

!"#$

id88 update: 
geometric interpretation

update: %&'(   %"#$++,, i.e., %&'(   %"#$+,

!"#$

id88 update: 
geometric interpretation

update: (%&'   ("#$++,, i.e., (%&'   ("#$+,

!"#$

!%&'

properties of the id88 training 
algorithm

q online

q we look at one example at a time, and update 

the model as soon as we make an error

q as opposed to batch algorithms that update 
parameters after seeing the entire training set

q error-driven

q we only update parameters/model if we make 

an error

practical considerations

q the order of training examples matters!

q random is better

q early stopping

q good strategy to avoid overfitting

q simple modifications dramatically 

improve performance
q voting or averaging

predicting with

    the voted id88

    the averaged id88

require keeping track of    survival time    of weight vectors
.

how would you modify this algorithm 
for voted id88?

how would you modify this algorithm for 
averaged id88?

averaged id88 decision rule

can be rewritten as

averaged id88 training

can the id88 always find a 
hyperplane to separate positive 
from negative examples?

this week

a new model/algorithm

the id88
and its variants: voted, averaged

fundamental machine learning concepts

online vs. batch learning
error-driven learning

project 1 coming soon!

furong huang

3251 a.v. williams, college park, md 20740

301.405.8010 / furongh@cs.umd.edu

