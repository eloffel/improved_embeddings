lecture slides for 
introduction  
to  
machine  
learning 
3rd edition 

ethem alpaydin 
   the mit press, 2014 
 
alpaydin@boun.edu.tr 
http://www.cmpe.boun.edu.tr/~ethem/i2ml3e 

chapter 4:  
parametric methods 

parametric estimation 

3 

    x = { xt }t where xt ~ p (x) 
    parametric estimation:  

  assume a form for p (x |q ) and estimate q , its sufficient 

statistics, using x 

  e.g., n (   ,   2) where q = {   ,   2} 

id113 

4 

    likelihood of q given the sample x 
 

l (  |x) = p (x |  ) =    

 p (xt|  ) 
t

 

 

    log likelihood 

 l(  |x) = log l (  |x) =    

 log p (xt|  ) 
t

 

 

 

    maximum likelihood estimator (id113) 

 

 

  * = argmax   l(  |x) 

examples: bernoulli/multinomial 

5 

    bernoulli: two states, failure/success, x in {0,1}  

x (1     po ) 

(1     x) 

p (x) = po
     
id113: po =    
 

t

 
 xt / n  

l (po|x) = log    

 po

xt (1     po ) 

(1     xt)  

t

    multinomial: k>2 states, xi in {0,1} 

p (x1,x2,...,xk) =    
i
     
id113: pi =    

 
 xi

t / n 

t

xi 
 pi
l(p1,p2,...,pk|x) = log    

t 

   
i

 pi

xi

t  

gaussian (normal) distribution 

    p(x) = n (   ,   2) 
 

 

 

 

   

   

    id113 for    and   2: 

6 

                                                222exp21x-xp      nmxsnxmtttt               22                                       22221            xxpexpbias and variance 

7 

unknown parameter q 
estimator di = d (xi) on sample xi  
 
bias: bq(d) = e [d]     q 
variance: e [(d   e [d])2] 
 
mean square error:  
r (d,q) = e [(d   q)2] 
 
 

= (e [d]     q)2 + e [(d   e [d])2] 
= bias2 + variance  

q 

bayes    estimator 

8 

    treat    as a random var with prior p (  ) 
    bayes    rule: p (  |x) = p(x|  ) p(  ) / p(x)  
    full: p(x|x) =     p(x|  ) p(  |x) d   
    maximum a posteriori (map): 
  map = argmax   p(  |x) 

 
    maximum likelihood (ml):   ml = argmax   p(x|  ) 
    bayes   :   bayes    = e[  |x] =        p(  |x) d    

 

bayes    estimator: example 

2) and    ~ n (   ,   2) 

    xt ~ n (  ,   o
      ml = m 
      map =   bayes    = 

9 

                           q220222020111//////|            nmnnexparametric classification 

10 

                                    iiiiiicpcxpxgcpcxpxg log| log or|                                       iiiiiiiiicpxxgxcxp log log logexp|                                             22222221221                            given the sample 

 

 

 

    ml estimates are 

 

 

 

 

    discriminant 

11 

nttt,rx1}{      x      x                         , if   if  ijxxrjtitticc01                                       ttittiitittittitittiirrmxsrrxmnrcp22                          iiiiicpsmxsxg   log log log                  222221   equal variances 

single boundary at 
halfway between means 

12 

variances are different 

two boundaries 

13 

14 

regression 

15 

                                    220   q      q   ,n,n|~|~|:estimatorxgxrpxgxfr                                                         nttntttntttxpxrprxp111 log| log, log|xlqregression: from logl to error 

16 

                                                2121222121212221                                                                     ntttntttttntxgrexgrnxgrqqq            q      q|||log |exp log|xxlid75 

17 

      0101wxwwwxgtt      ,|                                 tttttttttttxwxwxrxwnwr21010                                                                                                            tttttttttttxrrwwxxxnyw    102ayw1      apolynomial regression 

18 

                  0122012wxwxwxwwwwwxgttktkkt                     ,,,,|                                                                                                                              nnnnkkrrrxxxxxxxxx               212222221211111r   d      rwttddd1      other error measures 

19 

    square error:  

 

 

    relative square error: 

 

    absolute error: e (   |x) =    t
      -sensitive error:  

 |rt     g(xt|   )| 

 

 

 

e (   |x) =     
 1(|rt     g(xt|   )|>  ) (|rt     g(xt|  )|       ) 
t

 

 

                  2121            ntttxgreqq||x                        2121                     nttntttrrxgreqq||xbias and variance 

20 

noise 

squared error 

bias 

variance 

                                                                              222|||xgexgexgexrexxgxreexxxx                                                                     222xgxrexxrerexxgre               ||||estimating bias and variance 

21 

    m samples xi={xt
  are used to fit gi (x), i =1,...,m 

i}, i=1,...,m  

i , rt

                                                                                       titittitttxgmxgxgxgnmgxfxgng111222variancebiasbias/variance dilemma 

22 

    example: gi(x)=2 has no variance and high bias 
  gi(x)=    t

i/n has lower bias with variance 

 rt

 

    as we increase complexity,  

 

 

 

 

bias decreases (a better fit to data) and  

variance increases (fit varies more with data) 

    bias/variance dilemma: (geman et al., 1992) 

23 

f 

f 
bias 

g 

gi 

variance 

polynomial regression 

24 

best fit    min error    

25 

best fit,    elbow    

model selection 

26 

    cross-validation: measure generalization accuracy 

by testing on data unused during training 
    id173: penalize complex models 
e   =error on data +    model complexity 
 
  akaike   s information criterion (aic), bayesian 

 

information criterion (bic) 

    minimum description length (mdl): kolmogorov 

complexity, shortest description of data 

    structural risk minimization (srm) 

bayesian model selection 

27 

    prior on models, p(model) 

 

 

 

    id173, when prior favors simpler models 
    bayes, map of the posterior, p(model|data) 
    average over a number of models with high 

posterior (voting, ensembles: chapter 17) 
 

                        datamodel model|datadata|modelpppp   regression example 

28 

coefficients increase in 
magnitude as order 
increases: 
1: [-0.0769, 0.0016] 
2: [0.1682, -0.6657, 
0.0080] 
3: [0.4238, -2.5778, 
3.4675, -0.0002 
4: [-0.1093, 1.4356,  
-5.5007, 6.0454, -0.0019] 

id173 (l2): 

                                    iintttwxgre22121   ww||x