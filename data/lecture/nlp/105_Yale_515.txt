nlp
introduction to nlp
id88: discriminative classifier
the id88
a simple but very important classifier
model a neuron
input excitations
if excitation > inhibition, send an electrical signal out the axon
earliest neural network
invented in 1957!
id88 idea
x0
x1
x2
input
  
w0
w1
w2
> threshold?
-1
1
no
yes
question: where can we get these weights?
quick reminder: dot products
3
x

2
y

5
z

7
this equation
can be written as a dot product of two vectors: 
3
x
2
y
5
z
so we can rewrite
x0
x1
x2
  
w0
w1
w2
as a dot product of two vectors
derivatives and gradients
updating parameters
basic approach
we want to increase the id203 of the entire data set


gradient ascent
take the derivative of the log likelihood with respect to the parameters 
make a little change to the parameters in the direction the derivative tells you is uphill:

   here is the learning rate
how much do you want to change each time? 
id88 algorithm
input:
algorithm:
output:
[example: chris bishop]
gradient ascent example
starting value
w = (1,-1,-2,3)
accuracy 66%
next value
w = (2,-2,-1,2)
accuracy 73%
next value
w = (3,-2,-1,4)
accuracy 80%
etc.
id173
penalize large weights (we don   t want weights of 500,000)
l2 regularizer


l1 regularizer




updating parameters
stochastic gradient ascent
batch mode
consider each data point for each update of w
this is slow
stochastic mode
update w after each data point
id28 stochastic update (p is between 0 and 1)

id88 stochastic update (y is 0 or 1; approximation for lr)

notes
datasets:
http://blog.webkid.io/datasets-for-machine-learning/ 
nlp
