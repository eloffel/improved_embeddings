nlp
introduction to nlp
feature selection
feature selection: the    2 test
for a term t:



c=class, it = feature
testing for independence: p(c=0,it=0) should be equal to p(c=0) p(it=0)

p(c=0) = (k00+k01)/n
p(c=1) = 1-p(c=0) = (k10+k11)/n
p(it=0) = (k00+k10)/n
p(it=1) = 1-p(it=0) = (k01+k11)/n
feature selection: the    2 test


high values of    2 indicate lower belief in independence.
in practice, compute    2 for all words and pick the top k among them.
mutual information
measures amount of information
x = word; y = class



if the distribution is the same as the background distribution, then mi=0
documents are assumed to be generated according to the multinomial model
nlp
