nlp
introduction to nlp
evaluation of classification
evaluation of text classification
microaveraging 
average over classes
macroaveraging 
uses pooled table
well-known datasets
20 newsgroups
http://qwone.com/~jason/20newsgroups/ 
reuters-21578
http://www.daviddlewis.com/resources/testcollections/reuters21578/ 
cats: grain, acquisitions, corn, crude, wheat, trade   
webkb
http://www-2.cs.cmu.edu/~webkb/ 
course, student, faculty, staff, project, dept, other
rcv1
http://www.daviddlewis.com/resources/testcollections/rcv1/
larger reuters corpus
the 2-by-2 contingency table
precision and recall
precision: % of selected items that are correct
recall: % of correct items that are selected

pick a card   
a combined measure: f
a combined measure that assesses the p/r tradeoff is f measure (weighted harmonic mean):




the harmonic mean is a very conservative average; see iir    8.3
people usually use balanced f1 measure
  i.e., with     = 1 (that is,     =   ):   		     f = 2pr/(p+r)
common categories
(#train, #test)
classic reuters-21578 data set 
 earn (2877, 1087) 
 acquisitions (1650, 179)
 money-fx (538, 179)
 grain (433, 149)
 crude (389, 189)
 trade (369,119)
 interest (347, 131)
 ship (197, 89)
 wheat (212, 71)
 corn (182, 56)
most (over)used data set, 21,578 docs (each 90 types, 200 toknens)
9603 training, 3299 test articles (modapte/lewis split)
118 categories
an article can be in more than one category
learn 118 binary category distinctions
average document (with at least one category) has 1.24 classes
only about 10 out of 118 categories are large
confusion matrix c
for each pair of classes <c1,c2> how many documents from c1 were incorrectly assigned to c2?
c3,2: 90 wheat documents incorrectly assigned to poultry

10
micro- vs. macro-averaging
if we have more than one class, how do we combine multiple performance measures into one quantity?
macroaveraging: compute performance for each class, then average.
microaveraging: collect decisions for all classes, compute contingency table, evaluate.

which classifier works the best?
id166 gives the best performance
discriminative approaches tend to be more effective than generative approaches, but in general, the difference between different classifiers is not so significant as that between different feature extraction methods
need to consider other factors (e.g., efficiency, interpretability)
nlp
