lecture 6:

representing words

kai-wei chang
cs @ ucla

kw@kwchang.net

couse webpage: https://uclanlp.github.io/cs269-17/

ml in nlp

1

bag-of-words with id165s 

v id165s: a contiguous sequence of n 

tokens from a given piece of text

http://recognize-speech.com/language-model/id165-model/comparison

cs 6501: natural language processing

2

language model

v id203 distributions over sentences 

(i.e., word sequences )

p(w) = p(    "    #    $    %          )
p(              #    $    %          )")

v can use them to generate strings

v rank possible sentences

v p(   today is tuesday   ) > p(   tuesday today is   )
v p(   today is tuesday   ) > p(   today is los angeles   )

cs 6501: natural language processing

3

v bigram model: 

id165 models

v unigram model:         "        #        $        (    ,)
        "        #|    "        $|    #        (    ,|    ,)")
        "        #|    "        $|    #,    "        (    ,|    ,)"    ,)#)
        "        #|    "         (    ,|    ,)"    ,)#       ,)0)

v trigram model:

v id165 model:

cs 6501: natural language processing

4

random language via id165

v http://www.cs.jhu.edu/~jason/465/powerpo

int/lect01,3tr-ngram-gen.pdf

collection of id165
v https://research.googleblog.com/2006/08/al

l-our-id165-are-belong-to-you.html

cs 6501: natural language processing

5

id165 viewer

https://books.google.com/ngrams

ml in nlp

6

how to represent words?

v id165  -- cannot capture word similarity

v word clusters

v brown id91
v part-of-speech tagging

v continuous space representation 

v id27

ml in nlp

7

brown id91

v similar to language model

but, basic unit is    word clusters   

v intuition: similar words appear in similar context
v recap: bigram language models

v        1,    ",    #,   ,    ,	
=         "     1         #    "             ,     ,)"
=  56"	7 p(w:       :)")
    1 is	a	dummy	word	representing	   begin	of	a	sentence   

6501 natural language processing

8

motivation example

v    a dog is chasing a cat   

v        1,          ,                  ,   ,                  	
=                    1                                                            

          

v assume every word belongs to a cluster

cluster	3

a
the

cluster	46
dog		cat		
fox		rabbit
bird	boy

cluster	64

is	
was

cluster	64
chasing
following
biting   

6501 natural language processing

9

motivation example

v assume every word belongs to a cluster

v    a dog is chasing a cat   

c3

c46

c64

c8

c3

c46

cluster	3

a
the

cluster	46
dog		cat		
fox		rabbit
bird	boy

cluster	64

is	
was

cluster	8
chasing
following
biting   

6501 natural language processing

10

motivation example

v assume every word belongs to a cluster

v    a dog is chasing a cat   

c3

c46

c64

c8

c3

c46

a																		dog																is													chasing														a																		cat

cluster	3

a
the

cluster	46
dog		cat		
fox		rabbit
bird	boy

cluster	64

is	
was

cluster	8
chasing
following
biting   

6501 natural language processing

11

motivation example

v assume every word belongs to a cluster

v    the boy is following a rabbit   

c3

c46

c64

c8

c3

c46

the															boy																is													following														a											rabbit

cluster	3

a
the

cluster	46
dog		cat		
fox		rabbit
bird	boy

cluster	64

is	
was

cluster	8
chasing
following
biting   

6501 natural language processing

12

motivation example

v assume every word belongs to a cluster

v    a fox was chasing a bird   

c3

c46

c64

c8

c3

c46

a																			fox														was											chasing															a															bird

cluster	3

a
the

cluster	46
dog		cat		
fox		rabbit
bird	boy

cluster	64

is	
was

cluster	8
chasing
following
biting   

6501 natural language processing

13

brown id91

v let          denote the cluster that      belongs to

v    a dog is chasing a cat   

c3

c46

c64

c8

c3

c46

a																		dog																is													chasing														a																		cat

p(c(dog)|c(a))
cluster	46
cluster	3
dog		cat		
fox		rabbit
bird	boy

a
the

p(cat|c(cat))

cluster	8
chasing
following
biting   

cluster	64

is	
was

6501 natural language processing

14

brown id91 model

v p(   a dog is chasing a cat   )

= p(c(   a   )|    1) p(c(   dog   )|c(   a   )) p(c(   dog   )|c(   a   ))   

p(   a   |c(   a   ))p(   dog   |c(   dog   ))...

c3

c46

c64

c8

c3

c46

a																		dog																is													chasing														a																		cat

p(c(dog)|c(a))

cluster	3

a
the

cluster	46
dog		cat		
fox		rabbit
bird	boy

p(cat|c(cat))

cluster	8
chasing
following
biting   

cluster	64

is	
was

6501 natural language processing

15

brown id91 model

v p(   a dog is chasing a cat   )

p(   a   |c(   a   ))p(   dog   |c(   dog   ))...

= p(c(   a   )|    1) p(c(   dog   )|c(   a   )) p(c(   dog   )|c(   a   ))   
        1,    ",    #,   ,    ,	
        ,)"
=         (    ")         1         (    #)    (    ")                 ,
    (    "|        "        #        #        (    ,|        ,)
=  56"	7 p     w:
        :)"     (    :           :)

v in general

6501 natural language processing

16

model parameters

        :)"     (    :           :)

parameter	set	1:

        1,    ",    #,   ,    ,	
=  56"	7 p     w:
    (    (    :)|        :)")
        :

parameter	set	3:
cluster	3
a
the

c3

c46

c64

c8

c3

c46

a																		dog																		is													chasing														a																		cat

cluster	46
dog		cat		
fox		rabbit
bird	boy

cluster	64

is	
was

cluster	8
chasing
following
biting   

    (    :|        :)

parameter	set	2:

6501 natural language processing

17

model parameters

        :)"     (    :           :)

        1,    ",    #,   ,    ,	
=  56"	7 p     w:
v a vocabulary set     
v a function     :       {1,2,3,       	}
v id155     (              ) for     ,    n    1,   ,    
v id155     (           ) for     ,    n    1,   ,    ,           
     represents	the		set	of	conditional	id203	parameters

v a partition of vocabulary into k classes

c	represents	the	id91	

6501 natural language processing

18

log likelihood

ll(    ,    	) = log          1,    ",    #,   ,    ,     ,    
=log	  56"	7 p     w:
        :)"     (    :           :)
        :)" +log    (    :           :) ]
=   56"	7
[log	p     w:
v maximizing ll(    ,    ) can be done by 
alternatively update     	 and     	
1.max\   ]	        (    ,    )
2.max_ 	        (    ,    )

6501 natural language processing

19

max\   ]	        (    ,    )
ll(    ,    	) = log          1,    ",    #,   ,    ,     ,    
        :)"     (    :           :)
=log	  56"	7 p     w:
        :)" +log    (    :           :) ]
=   56"	7
[log	p     w:
v    (              ) = #(ab,a)#a
v    (           ) = #(c,a)#a

this	part	is	the	same	as	training	
a	pos	tagging	model

see	section	9.2:
http://ciml.info/dl/v0_99/ciml-v0_99-ch09.pdf

6501 natural language processing

20

max_ 	        (    ,    )
max_ 		   56"	7
        :)" +log    (    :           :) ]
[log	p     w:
   
= n    
eae(ab)+    
        ,    n
log ea,ab
   an6"
   a6"
			         = #a    #(a)
			,
        ,    n = #a,ab
v    : cluster of w:,        :cluster of w:)"
   
#(a,ab)
 h
 h,hb
eae(ab)=e        n
ea,ab
ea

where g is a constant
v here, 

(mutual information)

see	classnote here:
http://web.cs.ucla.edu/~kwchang/teaching
/nlp16/slides/classnote.pdf

v

6501 natural language processing

21

algorithm 1 

v start with |v| clusters 

each word is in its own cluster

v pick 2 clusters and merge them

v the goal is to get k clusters
v we run |v|-k merge steps:

v each step pick the merge maximizing	        (    ,    )
v cost?  (can be improved to 			    (    $))
o(|v|-k)						    (    #)						    	(    #) = 			    (    k)

#iters

#pairs   compute ll

6501 natural language processing

22

algorithm 2

v m : a hyper-parameter, sort words by frequency
v take the top m most frequent words, put each of 

them in its own cluster     ",    #,    $,       l
v for     =     +1    |    |
v create a new cluster     lo"	 (we have m+1 clusters)
            ,     and merge     back to m clusters
v carry out (m-1) final merges     full hierarchy 
v running time o         #+     ,

v choose two cluster from m+1 clusters based on 

n=#words in corpus

6501 natural language processing

23

example clusters (brown+1992)

6501 natural language processing

24

example hierarchy(miller+2004)

6501 natural language processing

25

