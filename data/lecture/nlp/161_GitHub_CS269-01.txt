lecture 1:
introduction

kai-wei chang
cs @ ucla

kw@kwchang.net

couse webpage: https://uclanlp.github.io/cs269-17/

ml in nlp

1

announcements

v waiting list: start attending the first few lectures 

as if you are registered. given that some students 
will drop the class, some space will free up. 

v we will use piazza as an online discussion 

platform. please sign up here: 
piazza.com/ucla/fall2017/cs269

ml in nlp

2

staff

v instructor: kai-wei chang
v email: ml17@kwchang.net
v office:  bh 3732j
v office hour: 4:00     5:00, tue (after class).

v ta: md rizwan parvez

v email: wua4nw@virginia.edu
v office: bh 3809 
v office hour: 12:00     2:00, wed

ml in nlp

3

this lecture

v course overview

v what is nlp? why it is important?
v what types of ml methods used in nlp?
v what will you learn from this course?

v course information
v what are the challenges?
v key nlp components
v key ml ideas in nlp

ml in nlp

4

what is nlp

v wiki: natural language processing (nlp) is 

a field of computer science, artificial 
intelligence, and computational linguistics 
concerned with the interactions between 
computers and human (natural) languages.

ml in nlp

5

go beyond the keyword matching

v identify the structure and meaning of 

words, sentences, texts and conversations

v deep understanding of broad language
v nlp is all around us

ml in nlp

6

machine translation

facebook	translation,	image	credit:	meedan.org

ml in nlp

7

id151

image	credit:	julia	hockenmaier,	intro	to	nlp

ml in nlp

8

id71

ml in nlp

9

sentiment/opinion analysis

ml in nlp

10

text classification 

v other applications?

www.wired.com

ml in nlp

11

id53

'watson' computer wins at 'jeopardy'

ml in nlp

12

credit:	ifunny.com

id53

v go beyond search

ml in nlp

13

natural language instruction

https://youtu.be/kkoceatkhic?t=1m28s

ml in nlp

14

digital personal assistant
more	on	natural	language	instruction

credit:	techspot.com

v id29     understand tasks
v entity linking        my wife    =    kellie    in the phone 

book

ml in nlp

15

information extraction 

v unstructured text to database entries

yoav artzi:	natural	language	processing

ml in nlp

16

language comprehension

christopher robin is alive and well. he is the same 
person that you read about in the book, winnie the pooh. 
as a boy, chris lived in a pretty home called cotchfield
farm.  when chris was three years old, his father wrote 
a poem about him. the poem was printed in a magazine 
for others to read.  mr. robin then wrote a book

v q: who wrote winnie the pooh?
v q: where is chris lived?

ml in nlp

17

what will you learn from this course

v the nlp pipeline

v key components for
understanding text

v nlp systems/applications

v current techniques & limitation

v build realistic nlp tools

ml in nlp

18

what   s not covered by this course

v id103     no signal processing

v id86

v details of ml algorithms / theory

v id111 / information retrieval 

ml in nlp

19

this lecture

v course overview

v what is nlp? why it is important?
v what will you learn from this course?

v course information
v what are the challenges?
v key nlp components

ml in nlp

20

overview

v new course, first time being offered

v comments are welcomed
v target at first- or second- year phd students

v lecture + seminar
v no course prerequisites, but i assume

v programming experience (for the final project)
v basic ml/ai background
v basics of id203 calculus, and linear 

algebra (hw0) 

ml in nlp

21

grading

v attendance & participations (10%)

v participate in discussion

v paper summarization report (20%)
v paper presentation (30%)
v final project (40%)

v proposal (5%)
v final paper (25%)
v presentation (10%)

ml in nlp

22

paper summarization

v 1 page maximum
v pick one paper from recent 
acl/naacl/emnlp/eacl

v summarize the paper (use you own words)

v write a blog post using markdown or jupyter

notebook:

v https://einstein.ai/research/learned-in-
translation-contextualized-word-vectors

v https://github.com/uclanlp/reducingbias/blob/ma

ster/src/faircrf_gender_ratio.ipynb

ml in nlp

23

ml in nlp

24

ml in nlp

25

paper presentation

v each group has 2~3 students
v read and understand 2~3 related papers
v cannot be the same as your paper summary
v can be related to your final project
v register your choice next week

v 30 min presentation/ q&a
v grading rubric: 

40% technical understanding, 40% 
presentation, 20% interaction

ml in nlp

26

final project

v work in groups (3 students)
v project proposal

v 1 page maximum  (template)

v project report 

v similar to the paper summary
v due before the final presentation

v project presentation 

v in-class presentation (tentative) 

ml in nlp

27

late policy

v submission site will be closed 1hr after the 

deadline.

v no late submission

v unless under emergency situation

ml in nlp

28

cheating/plagiarism

v no. ask if you have concerns
v rules of thumb: 

v cite your references
v clearly state what are your contributions

ml in nlp

29

lectures and office hours

v participation is highly appreciated!
v ask questions if you are still confusing
v feedbacks are welcomed
v lead the discussion in this class
v enroll piazza

ml in nlp

30

topics of this class

v fundamental nlp problems
v machine learning & statistical approaches 

for nlp

v nlp applications
v recent trends in nlp 

ml in nlp

31

what to read?

v natural language processing

acl, naacl, eacl, emnlp, conll, coling, tacl
aclweb.org/anthology
v machine learning

icml, nips, ecml, aistats, iclr, jmlr, mlj

v artificial intelligence
aaai, ijcai, uai, jair

ml in nlp

32

questions?

ml in nlp

33

this lecture

v course overview

v what is nlp? why it is important?
v what will you learn from this course?

v course information
v what are the challenges?
v key nlp components
v key ml ideas in nlp

ml in nlp

34

challenges     ambiguity

v word sense ambiguity

ml in nlp

35

challenges     ambiguity

v word sense / meaning ambiguity

credit:	http://stuffsirisaid.com

ml in nlp

36

challenges     ambiguity

v pp attachment ambiguity

credit: mark liberman, http://languagelog.ldc.upenn.edu/nll/?p=17711

ml in nlp

37

challenges -- ambiguity

v ambiguous headlines:

v include your children when baking cookies
v local high school dropouts cut in half
v hospitals are sued by 7 foot doctors
v iraqi head seeks arms

v safety experts say school bus passengers 

should be belted

v teacher strikes idle kids

ml in nlp

38

challenges     ambiguity

v pronoun reference ambiguity

credit:	http://www.printwand.com/blog/8-catastrophic-examples-of-word-choice-mistakes

ml in nlp

39

challenges     language is not static

v language grows and changes

v e.g., cyber lingo 

lol
g2g
bfn
b4n
idk
fwiw
luwamh

laugh	out loud
got	to	go
bye	for	now
bye	for	now
i	don   t	know
for	what	it   s	worth
love	you	with	all	my	heart

ml in nlp

40

challenges--language is compositional

carefully 

slide

ml in nlp

41

challenges--language is compositional

      : 
carefully
careful
take 
care
caution 

      : 
slide
landslip
wet floor
smooth

ml in nlp

42

challenges     scale

v examples:

v bible (king james version): ~700k
v penn tree bank ~1m from wall street journal
v newswire collection: 500m+
v wikipedia: 2.9 billion word (english)
v web: several billions of words

ml in nlp

43

this lecture

v course overview

v what is nlp? why it is important?
v what will you learn from this course?

v course information
v what are the challenges?
v key nlp components
v key ml ideas in nlp

ml in nlp

44

id52

ml in nlp

45

syntactic (constituency) parsing

ml in nlp

46

syntactic structure => meaning

image	credit:	julia	hockenmaier,	intro	to	nlp

ml in nlp

47

id33

ml in nlp

48

semantic analysis

v id51 
v id14

credit:	ivan	titov

ml in nlp

49

q: [chris] = [mr. robin] ?
christopher robin is alive and well. he is the 
same person that you read about in the book,
winnie the pooh. as a boy, chris lived in a 
pretty home called cotchfield farm.  when 
chris was three years old, his father wrote a 
poem about him. the poem was printed in a 
magazine for others to read.  mr. robin then 
wrote a book

slide modified from dan roth

ml in nlp

50

co-reference resolution

christopher robin is alive and well. he is the 
same person that you read about in the book, 
winnie the pooh. as a boy, chris lived in a 
pretty home called cotchfield farm.  when 
chris was three years old, his father wrote a 
poem about him. the poem was printed in a 
magazine for others to read.  mr. robin then 
wrote a book

ml in nlp

51

this lecture

v course overview

v what is nlp? why it is important?
v what will you learn from this course?

v course information
v what are the challenges?
v key nlp components
v key ml ideas in nlp

ml in nlp

52

machine learning 101

cs6501- advanced machine learning

53

cs6501- advanced machine learning

54

id88,	decision	tree,	support	vector	machine
id92,	na  ve	bayes,	logistic	regression   .

cs6501- advanced machine learning

55

classification is generally well-understood

v theoretically: generalization bound

v # examples to train a good model

v algorithmically:

v efficient algorithm for large data set

v e.g., take a few second to train a linear id166 on 

data with millions instances and features

v algorithms for non-linear model

v e.g., kernel methods

is	this	enough	to	solve	all	real-world	problems?

cs6501- advanced machine learning

56

reading comprehension

cs6501- advanced machine learning

57

challenges

algorithm 2 is shown to perform 
a local-optimality guarantee. 
better berg-kirkpatrick, acl 
methods for learning to search 
can learning to search work even 
bill clinton, recently elected as the president of 
consequently, lols can 
robin is alive and well. he is the 
2010. it can also be expected to 
the usa, has been invited by the russian 
for id170 typically 
when the reference is poor?
improve upon the reference 
president], [vladimir putin, to visit russia. 
same person that you read about 
converge faster -- anyway, the e-
imitate a reference policy, with 
we provide a new learning to 
president clinton said that he looks forward to 
policy, unlike previous 
in the book, winnie the pooh. as 
step changes the auxiliary 
strengthening ties between usa and russia
existing theoretical guarantees 
search algorithm, lols, which 
algorithms. this enables us to 
a boy, chris lived in a pretty 
function by changing the 
demonstrating low regret 
does well relative to the 
develop structured contextual 
home called cotchfield farm.  
expected counts, so there's no 
compared to that reference. this 
reference policy, but additionally 
bandits, a partial information 
when chris was three years old, 
point in finding a local maximum 
is unsatisfactory in many 
guarantees low regret compared 
id170 setting with 
his father wrote a poem about 
of the auxiliary 
applications where the reference 
to deviations from the learned 
many potential applications.
him. the poem was printed in a 
function in each iteration
policy is suboptimal and the goal 
policy.
magazine for others to read.  mr. 
of learning is to
robin then wrote a book

robin is alive and well. he is the same 
person that you read about in the book, 
winnie the pooh. as a boy, chris lived 
in a pretty home called cotchfield
farm.  when chris was three years old, 
his father wrote a poem about him. the 
poem was printed in a magazine for 
others to read.  mr. robin then wrote a 
book

vmodeling challenges

structured	prediction	models

vhow to model a complex decision?

vrepresentation challenges

deep	learning	models

vhow to extract features?
valgorithmic challenges 

id136	/	learning	algorithms
v large amount of data and complex decision structure

58

modeling challenges

v how to model a complex decision? 
v why this is important?

robin is alive and well. he is the same 
person that you read about in the book, 
winnie the pooh. as a boy, chris lived 
in a pretty home called cotchfield
farm.  when chris was three years old, 
his father wrote a poem about him. the 
poem was printed in a magazine for 
others to read.  mr. robin then wrote a 
book

cs6501- advanced machine learning

59

language is structural

cs6501- advanced machine learning

60

hand written recognition 

v what is this letter?

cs6501- advanced machine learning

61

hand written recognition 

v what is this letter?

cs6501- advanced machine learning

62

visual recognition

cs6501- advanced machine learning

63

human body recognition

cs6501- advanced machine learning

64

bridge the gap

v simple classifiers are not designed for handle 

complex output

v need to make multiple decisions jointly
v example: id52:

can	you	can	a	can	as	a	canner	can	can	a	can

example	from	vivek srikumar

cs6501- advanced machine learning

65

make multiple decisions jointly

v example: id52:

can	you	can	a	can	as	a	canner	can	can	a	can

v each part needs a label

v assign tag (v., n., a.,    ) to each word in the sentence 

v the decisions are mutually dependent

v cannot have verb followed by a verb

v results are evaluated jointly

cs6501- advanced machine learning

66

id170 problems

v problems that 

v have multiple interdependent output variables
v and the output assignments are evaluated jointly
v need a joint assignment to all the output variables
v we called it joint id136, global infernece or 

simply id136

cs6501- advanced machine learning

67

a

can can

v input:
v truth:

a general learning setting
i
can
pro md vb dt nn
pro md md dt vb
pro md md dt nn
pro md nn dt md
pro md nn dt vb

		           
y          (    )
v predicted:    (    )       (    )
		                    ,       
find            such that    x        (    )
minimizing		    3,4~6                    ,       
samples     8,    8~    

based on     

goal: make joint prediction to minimize a joint loss

v loss:

kai-wei chang (university of virginia)

68

can can

v input:
v truth:

combinatorial output space
i
can
pro md vb dt nn
pro md md dt vb
pro md md dt nn
pro md nn dt md
pro md nn dt vb

		           
y          (    )
v predicted:    (    )       (    )
		                    ,       
45<==3.4  10<d

# pos tags: 45
how many possible outputs for sentence with 10 
words?

v loss:

a

observation:	not	all	sequences	are	valid,
and	we	don   t	need	to	consider	all	of	them

kai-wei chang (university of virginia)

69

representation of interdependent output variables 

v a compact way to represent output 

combinations 
v abstract away unnecessary complexities
v we know how to process them

v graph algorithms for linear chain, tree, etc.

pronoun

verb

noun

and

noun

root they			operate			ships				and				banks		.

cs6501- advanced machine learning

70

algorithms/models for id170 

v many learning algorithms can be 
generalized to the structured case

v id88     structured id88 
v id166     structured id166
v id28     conditional random field
v id170     multi-class     binary

v can be solved by a reduction stack

(a.k.a. id148)

cs6501- advanced machine learning

71

representation challenges

v how to obtain features?

robin is alive and well. he is the same person that 
you read about in the book, winnie the pooh. as a 
boy, chris lived in a pretty home called cotchfield
farm.  when chris was three years old, his father
wrote a poem about him. the poem was printed in a 
magazine for others to read.  mr. robin then wrote a 
book

cs6501- advanced machine learning

72

representation challenges

v how to obtain features?

1. design features based on domain knowledge 

v e.g., by patterns in parse trees

when chris was three years old, his father wrote a poem about him.

v by nicknames

christopher robin is alive and well. he is the same person that you read 
about in the book, winnie the pooh. as a boy, chris lived in a pretty home 
called cotchfield farm.  

v need human experts/knowledge

cs6501- advanced machine learning

73

representation challenges

v how to obtain features?

1. design features based on domain knowledge 
2. design feature templates and then let machine 

find the right ones
v e.g., use all words, pairs of words,    

robin is alive and well. he is the same person that you read about 
in the book, winnie the pooh. as a boy, chris lived in a pretty 
home called cotchfield farm.  when chris was three years old, his 
father wrote a poem about him. the poem was printed in a 
magazine for others to read.  mr. robin then wrote a book

cs6501- advanced machine learning

74

representation challenges

v how to obtain features?

1. design features based on domain knowledge 
2. design feature templates and then let machine 

find the right ones

v challenges:

v # featuers can be very large
v # english words: 171k (oxford)

v # bigram: 171     h~3  10<=,	# trigram?

v for some domains, it is hard to design features

cs6501- advanced machine learning

75

representation learning

v learn compact representations of features

v combinatorial (continuous representation)

cs6501- advanced machine learning

76

representation learning

v learn compact representations of features

v combinatorial (continuous representation)
v hieratical/compositional

cs6501- advanced machine learning

77

what will learn from this course

v id170

v models / id136/ learning 

v representation (deep) learning

v input/output representations

v combining structured models and deep 

learning

cs6501- advanced machine learning

78

