lexicalized probabilistic context-free

grammars

michael collins, columbia university

overview

(cid:73) lexicalization of a treebank

(cid:73) lexicalized id140

(cid:73) parameter estimation in lexicalized probabilistic context-free

grammars

(cid:73) accuracy of lexicalized id140

heads in context-free rules

add annotations specifying the    head    of each rule:
vi     sleeps
vt     saw
nn     man
nn     woman
nn     telescope
dt     the
in     with
in     in

s     np vp
vp     vi
vp     vt np
vp     vp pp
np     dt nn
np     np pp
pp     in
np

more about heads

(cid:73) each context-free rule has one    special    child that is the

head of the rule. e.g.,
s     np vp
vp     vt np
np     dt nn nn

(cid:73) a core idea in syntax

(vp is the head)
(vt is the head)
(nn is the head)

(e.g., see x-bar theory, head-driven phrase structure
grammar)

(cid:73) some intuitions:

(cid:73) the central sub-constituent of each rule.
(cid:73) the semantic predicate in each rule.

rules which recover heads: an example for nps

if the rule contains nn, nns, or nnp:

choose the rightmost nn, nns, or nnp

else if the rule contains an np: choose the leftmost np

else if the rule contains a jj: choose the rightmost jj

else if the rule contains a cd: choose the rightmost cd

else choose the rightmost child

e.g.,

np     dt nnp nn
np     dt nn
nnp
np     np pp
np     dt jj
np     dt

rules which recover heads: an example for vps

if the rule contains vi or vt: choose the leftmost vi or vt

else if the rule contains an vp: choose the leftmost vp

else choose the leftmost child

e.g.,

vp     vt np
vp     vp pp

adding headwords to trees

s

np

vp

dt

the

nn

lawyer

vt

np

questioned

dt

the

nn

witness

   

s(questioned)

np(lawyer)

vp(questioned)

dt(the)

nn(lawyer)

the

lawyer

vt(questioned)

np(witness)

questioned

dt(the)

nn(witness)

the

witness

adding headwords to trees (continued)

s(questioned)

np(lawyer)

vp(questioned)

dt(the)

nn(lawyer)

the

lawyer

vt(questioned)

np(witness)

questioned

dt(the)

nn(witness)

witness
(cid:73) a constituent receives its headword from its head child.

the

s     np vp
vp     vt
np
np     dt

nn

(s receives headword from vp)
(vp receives headword from vt)
(np receives headword from nn)

overview

(cid:73) lexicalization of a treebank

(cid:73) lexicalized id140

(cid:73) parameter estimation in lexicalized probabilistic context-free

grammars

(cid:73) accuracy of lexicalized id140

chomsky normal form

a id18 g = (n,   , r, s) in chomsky normal
form is as follows

(cid:73) n is a set of non-terminal symbols
(cid:73)    is a set of terminal symbols
(cid:73) r is a set of rules which take one of two forms:

(cid:73) x     y1y2 for x     n , and y1, y2     n
(cid:73) x     y for x     n , and y       

(cid:73) s     n is a distinguished start symbol

we can    nd the highest scoring parse under a pid18 in
this form, in o(n3|n|3) time where n is the length of the
string being parsed.

lexicalized context-free grammars in chomsky
normal form

(cid:73) n is a set of non-terminal symbols
(cid:73)    is a set of terminal symbols
(cid:73) r is a set of rules which take one of three forms:

(cid:73) x(h)    1 y1(h) y2(w) for x     n , and y1, y2     n , and
(cid:73) x(h)    2 y1(w) y2(h) for x     n , and y1, y2     n , and
(cid:73) x(h)     h for x     n , and h       

h, w       
h, w       

(cid:73) s     n is a distinguished start symbol

an example

   2 np(man) vp(saw)
np(dog)
nn(man)
nn(dog)

s(saw)
vp(saw)    1 vt(saw)
np(man)    2 dt(the)
np(dog)    2 dt(the)
vt(saw)     saw
dt(the)     the
nn(man)     man
nn(dog)     dog

parameters in a lexicalized pid18

(cid:73) an example parameter in a pid18:

q(s     np vp)

(cid:73) an example parameter in a lexicalized pid18:
q(s(saw)    2 np(man) vp(saw))

parsing with lexicalized id18s

(cid:73) the new form of grammar looks just like a chomsky normal
form id18, but with potentially o(|  |2    |n|3) possible rules.

(cid:73) naively, parsing an n word sentence using the dynamic

programming algorithm will take o(n3|  |2|n|3) time. but
|  | can be huge!!

(cid:73) crucial observation: at most o(n2    |n|3) rules can be
applicable to a given sentence w1, w2, . . . wn of length n.
this is because any rules which contain a lexical item that is
not one of w1 . . . wn, can be safely discarded.
(cid:73) the result: we can parse in o(n5|n|3) time.

overview

(cid:73) lexicalization of a treebank

(cid:73) lexicalized id140

(cid:73) parameter estimation in lexicalized probabilistic context-free

grammars

(cid:73) accuracy of lexicalized id140

s(saw)

np(man)

vp(saw)

dt(the)

nn(man)

the

man

vp(saw)

pp(with)

vt(saw)

np(dog)

in(with)

np(telescope)

saw

dt(the)

nn(dog)

with

the

dog

dt(the)

nn(telescope)

the

telescope

p(t) = q(s(saw)    2 np(man) vp(saw))

  q(np(man)    2 dt(the) nn(man))
  q(vp(saw)    1 vp(saw) pp(with))
  q(vp(saw)    1 vt(saw) np(dog))
  q(pp(with)    1 in(with) np(telescope))
   . . .

a model from charniak (1997)

(cid:73) an example parameter in a lexicalized pid18:
q(s(saw)    2 np(man) vp(saw))

(cid:73) first step: decompose this parameter into a product of two

parameters

q(s(saw)    2 np(man) vp(saw))

= q(s    2 np vp|s, saw)    q(man|s    2 np vp, saw)

a model from charniak (1997) (continued)

q(s(saw)    2 np(man) vp(saw))

= q(s    2 np vp|s, saw)    q(man|s    2 np vp, saw)

(cid:73) second step: use smoothed estimation for the two parameter

estimates

q(s    2 np vp|s, saw)

=   1    qm l(s    2 np vp|s, saw) +   2    qm l(s    2 np vp|s)

a model from charniak (1997) (continued)

q(s(saw)    2 np(man) vp(saw))

= q(s    2 np vp|s, saw)    q(man|s    2 np vp, saw)

(cid:73) second step: use smoothed estimation for the two parameter

estimates

q(s    2 np vp|s, saw)

=   1    qm l(s    2 np vp|s, saw) +   2    qm l(s    2 np vp|s)

=   3    qm l(man|s    2 np vp, saw) +   4    qm l(man|s    2 np vp)

q(man|s    2 np vp, saw)

+  5    qm l(man|np)

other important details

(cid:73) need to deal with rules with more than two children, e.g.,
vp(told)     v(told) np(him) pp(on) sbar(that)

other important details

(cid:73) need to deal with rules with more than two children, e.g.,
vp(told)     v(told) np(him) pp(on) sbar(that)

(cid:73) need to incorporate parts of speech (useful in smoothing)

vp-v(told)     v(told) np-prp(him) pp-in(on) sbar-comp(that)

other important details

(cid:73) need to deal with rules with more than two children, e.g.,
vp(told)     v(told) np(him) pp(on) sbar(that)

(cid:73) need to incorporate parts of speech (useful in smoothing)

vp-v(told)     v(told) np-prp(him) pp-in(on) sbar-comp(that)

(cid:73) need to encode preferences for close attachment

john was believed to have been shot by bill

other important details

(cid:73) need to deal with rules with more than two children, e.g.,
vp(told)     v(told) np(him) pp(on) sbar(that)

(cid:73) need to incorporate parts of speech (useful in smoothing)

vp-v(told)     v(told) np-prp(him) pp-in(on) sbar-comp(that)

(cid:73) need to encode preferences for close attachment

john was believed to have been shot by bill

(cid:73) further reading:

michael collins. 2003. head-driven statistical models
for natural language parsing. in computational
linguistics.

overview

(cid:73) lexicalization of a treebank

(cid:73) lexicalized id140

(cid:73) parameter estimation in lexicalized probabilistic context-free

grammars

(cid:73) accuracy of lexicalized id140

evaluation: representing trees as constituents

s

np

vp

dt

nn

the

lawyer

vt

np

questioned

dt

nn

label

start point

end point

the

witness

np
np
vp
s

1
4
3
1

2
5
5
5

precision and recall

label

start point

end point

label

start point

end point

2
5
8
8
8
8
8

1
4
4
6
7
3
1

np
np
pp
np
vp
s

np
np
np
pp
np
vp
s
(cid:73) g = number of constituents in gold standard = 7
(cid:73) p = number in parse output = 6
(cid:73) c = number correct = 6

1
4
6
7
3
1

2
5
8
8
8
8

recall = 100%    c
g

= 100%    6
7

precision = 100%    c
p

= 100%    6
6

results

(cid:73) training data: 40,000 sentences from the penn wall street
journal treebank. testing: around 2,400 sentences from the
penn wall street journal treebank.

(cid:73) results for a pid18: 70.6% recall, 74.8% precision

(cid:73) magerman (1994): 84.0% recall, 84.3% precision

(cid:73) results for a lexicalized pid18: 88.1% recall, 88.3% precision

(from collins (1997, 2003))

(cid:73) more recent results: 90.7% recall/91.4% precision (carreras
et al., 2008); 91.7% recall, 92.0% precision (petrov 2010);
91.2% recall, 91.8% precision (charniak and johnson, 2005)

s(saw)

np(man)

vp(saw)

dt(the)

nn(man)

the

man

vp(saw)

pp(with)

vt(saw)

np(dog)

in(with)

np(telescope)

saw

dt(the)

nn(dog)

with

the

dog

(cid:104) root0,
(cid:104) saw3,
(cid:104) man2,
(cid:104) saw3,
(cid:104) saw3,
(cid:104) dog5,
(cid:104) with6,
(cid:104) telescope8,

root (cid:105)
saw3,
s    2 np vp (cid:105)
man2,
np    2 dt nn (cid:105)
the1,
vp    1 vp pp (cid:105)
with6,
vp    1 vt np (cid:105)
dog5,
np    2 dt nn (cid:105)
the4,
telescope8, pp    1 in np (cid:105)
np    2 dt nn (cid:105)
the7,

dt(the)

nn(telescope)

the

telescope

dependency accuracies

(cid:73) all parses for a sentence with n words have n dependencies

report a single    gure, dependency accuracy

(cid:73) results from collins, 2003: 88.3% dependency accuracy

(cid:73) can calculate precision/recall on particular dependency types

e.g., look at all subject/verb dependencies    
all dependencies with label s    2 np vp
recall =

number of subject/verb dependencies correct

number of subject/verb dependencies in gold standard

precision =

number of subject/verb dependencies correct

number of subject/verb dependencies in parser   s output

strengths and weaknesses of modern parsers

(numbers taken from collins (2003))

(cid:73) subject-verb pairs: over 95% recall and precision
(cid:73) object-verb pairs: over 92% recall and precision
(cid:73) other arguments to verbs:     93% recall and precision
(cid:73) non-recursive np boundaries:     93% recall and precision
(cid:73) pp attachments:     82% recall and precision
(cid:73) coordination ambiguities:     61% recall and precision

summary

(cid:73) key weakness of pid18s: lack of sensitivity to lexical

information

(cid:73) lexicalized pid18s:

(cid:73) lexicalize a treebank using head rules
(cid:73) estimate the parameters of a lexicalized pid18 using

smoothed estimation

(cid:73) accuracy of lexicalized pid18s: around 88% in recovering

constituents or depenencies

