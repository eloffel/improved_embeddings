informatics 2a: lecture 20

shay cohen

31 october 2017

1 / 32

last class

constituents and phrases: a phrase inherits the category of its
head.

ambiguity: a sentence can have multiple parse trees (or multiple
pos analyses)

recursive descent parsing: a top-down parser. iterate through all
rules, in a depth-   rst style, until a parse that matches the sentence
is found. exhuastive search, essentially.

id132: two operations     shift: put a word with
its pos tag on the stack. reduce: take a sequence of top
symbols on the stack and pop them if they match with a
right-hand side of a rule, and then place the left-hand side on the
top of the stack.

why not ll(1)? we have ambiguous grammars!

2 / 32

1 problems with parsing as search

grammar restructuring
problems with parsing as search

2 the cyk algorithm

parsing as id145
the cyk algorithm
properties of the algorithm

3 / 32

1 problems with parsing as search

grammar restructuring
problems with parsing as search

2 the cyk algorithm

parsing as id145
the cyk algorithm
properties of the algorithm

4 / 32

5 / 32

grammar restructuring

deterministic parsing (e.g., ll(1)) aims to address a limited
amount of local ambiguity     the problem of not being able to
decide uniquely which grammar rule to use next in a left-to-right
analysis of the input string.

by re-structuring the grammar, the parser can make a unique
decision, based on a limited amount of look-ahead.

recursive descent parsing also demands grammar restructuring, in
order to eliminate left-recursive rules that can get it into a hopeless
loop.

6 / 32

left recursion

but grammars for natural human languages should be revealing,
re-structuring the grammar may destroy this. (indirectly)
left-recursive rules are needed in english.

np     det n
np     npr
det     np    s

these rules generate nps with possessive modi   ers such as:

john   s sister
john   s mother   s sister
john   s mother   s uncle   s sister
john   s mother   s uncle   s sister   s niece

7 / 32

left recursion

we don   t want to re-structure our grammar rules just to be able to
use a particular approach to parsing. need an alternative.

8 / 32

npndetnpjohnnpr   smothernpsisterndetnpndetuncle   s   snpjohnnpr   sdetnpsisterndetnp   smotheid56pdetnpjohnnpr   ssisternhow many parses are there?

if our grammar is ambiguous (inherently, or by design) then how
many possible parses are there?

9 / 32

how many parses are there?

if our grammar is ambiguous (inherently, or by design) then how
many possible parses are there?

in general: an in   nite number, if we allow unary recursion.

9 / 32

how many parses are there?

if our grammar is ambiguous (inherently, or by design) then how
many possible parses are there?

in general: an in   nite number, if we allow unary recursion.

more speci   c: suppose that we have a grammar in chomsky
normal form. how many possible parses are there for a sentence of
n words? imagine that every nonterminal can rewrite as every pair
of nonterminals (a   bc) and every nonterminal (a   a)

1 n
2 n2
3 n log n
(2n)!

4

(n+1)!n!

9 / 32

how many parses are there?

a

aa

10 / 32

how many parses are there?

a

aa

a

a

a

a

a

a

a

aa

aa

a

10 / 32

how many parses are there?

a

aa

a

a

a

a

a

a

a

aa

aa

a

a

a

a

a

a

a

a

a

aa

aa

aa

aa

10 / 32

how many parses are there?

a

aa

a

a

a

a

a

a

a

aa

aa

a

a

a

a

a

a

a

a

a

a

a

a

a

a

aa

aa

aa

aa

aaa

a

a

a

aa

a

a

a

10 / 32

how many parses are there?

a

aa

a

a

a

a

a

a

a

aa

aa

a

a

a

a

a

a

a

a

a

a

a

a

a

a

a

a

a

aa

aa

aa

aa

aaa

a

a

a

aa

a

a

a

aa

aa

10 / 32

how many parses are there?

intution. let c (n) be the number of binary trees over a sentence
of length n. the root of this tree has two subtrees: one over k
words (1     k < n), and one over n     k words. hence, for all values
of k, we can combine any subtree over k words with any subtree
over n     k words:

n   1(cid:88)

c (n) =

c (k)    c (n     k)

k=1

11 / 32

how many parses are there?

intution. let c (n) be the number of binary trees over a sentence
of length n. the root of this tree has two subtrees: one over k
words (1     k < n), and one over n     k words. hence, for all values
of k, we can combine any subtree over k words with any subtree
over n     k words:

n   1(cid:88)

c (n) =

c (k)    c (n     k)

k=1

c (n) =

(2n)!

(n + 1)!n!

these numbers are called the catalan numbers. they   re big
numbers!
1
1

10
1430

11
4862

8
132

9
429

5
14

6
42

c (n)

2
1

3
2

4
5

n

12

16796

11 / 32

problems with parsing as search

1 a recursive descent parser (top-down) will do badly if there

are many di   erent rules for the same lhs. hopeless for
rewriting parts of speech (preterminals) with words
(terminals).

2 a shift-reduce parser (bottom-up) does a lot of useless
work: many phrase structures will be locally possible, but
globally impossible. also ine   cient when there is much lexical
ambiguity.

3 both strategies do repeated work by re-analyzing the same

substring many times.

we will see how chart parsing solves the re-parsing problem, and
also copes well with ambiguity.

12 / 32

id145

with a id18, a parser should be able to avoid re-analyzing
sub-strings because the analysis of any sub-string is independent of
the rest of the parse.

the parser   s exploration of its search space can exploit this
independence if the parser uses id145.

id145 is the basis for all chart parsing algorithms.

13 / 32

the  dog  saw  a  man  in  the  park npnpnpnpparsing as id145

given a problem, systematically    ll a table of solutions to
sub-problems: this is called memoization.

once solutions to all sub-problems have been accumulated,
solve the overall problem by composing them.

for parsing, the sub-problems are analyses of sub-strings and
correspond to constituents that have been found.

sub-trees are stored in a chart (aka well-formed substring
table), which is a record of all the substructures that have
ever been built during the parse.

solves re-parsing problem: sub-trees are looked up, not re-parsed!
solves ambiguity problem: chart implicitly stores all parses!

14 / 32

depicting a chart

a chart can be depicted as a matrix:

rows and columns of the matrix correspond to the start and
end positions of a span (ie, starting right before the    rst word,
ending right after the    nal one);

a cell in the matrix corresponds to the sub-string that starts
at the row index and ends at the column index.

it can contain information about the type of constituent (or
constituents) that span(s) the substring, pointers to its
sub-constituents, and/or predictions about what constituents
might follow the substring.

15 / 32

cyk algorithm

cyk (cocke, younger, kasami) is an algorithm for recognizing and
recording constituents in the chart.

assumes that the grammar is in chomsky normal form: rules
all have form a     bc or a     w .
conversion to cnf can be done automatically.

np     det nom
nom     n | optap nom nom     book | orange
| orange
| orange

| optadv a
| orange

a     heavy

np     det nom
ap     heavy
a     heavy
det     a
adv     very

optap      
det     a
optadv      

| very

n     book | orange

| ap nom
| adv a

16 / 32

cyk: an example

let   s look at a simple example before we explain the general case.

grammar rules in cnf

np     det nom
nom     book | orange
| orange
ap     heavy
| orange
a     heavy
det     a
adv     very

| ap nom
| adv a

(n.b. converting to cnf sometimes breeds duplication!)

now let   s parse: a very heavy orange book

17 / 32

filling out the cyk chart

0 a 1 very 2 heavy 3 orange 4 book 5

1
a

2
very

3
heavy

4
orange

5
book

0
1
2
3
4

a
very
heavy
orange
book

18 / 32

filling out the cyk chart

0 a 1 very 2 heavy 3 orange 4 book 5

1
a

2
very

3
heavy

4
orange

5
book

0
1
2
3
4

a det

very
heavy
orange
book

18 / 32

filling out the cyk chart

0 a 1 very 2 heavy 3 orange 4 book 5

1
a

2
very

3
heavy

4
orange

5
book

0
1
2
3
4

a det

very
heavy
orange
book

adv

18 / 32

filling out the cyk chart

0 a 1 very 2 heavy 3 orange 4 book 5

1
a

2
very

3
heavy

4
orange

5
book

0
1
2
3
4

a det

very
heavy
orange
book

adv

a,ap

18 / 32

filling out the cyk chart

0 a 1 very 2 heavy 3 orange 4 book 5

1
a

2
very

3
heavy

4
orange

5
book

0
1
2
3
4

a det

very
heavy
orange
book

adv ap

a,ap

18 / 32

filling out the cyk chart

0 a 1 very 2 heavy 3 orange 4 book 5

1
a

2
very

3
heavy

4
orange

5
book

0
1
2
3
4

a det

very
heavy
orange
book

adv ap

a,ap

nom,a,ap

18 / 32

filling out the cyk chart

0 a 1 very 2 heavy 3 orange 4 book 5

1
a

2
very

3
heavy

4
orange

5
book

0
1
2
3
4

a det

very
heavy
orange
book

adv ap

a,ap nom

nom,a,ap

18 / 32

filling out the cyk chart

0 a 1 very 2 heavy 3 orange 4 book 5

1
a

2
very

3
heavy

4
orange

5
book

0
1
2
3
4

a det

very
heavy
orange
book

adv ap

nom
a,ap nom

nom,a,ap

18 / 32

filling out the cyk chart

0 a 1 very 2 heavy 3 orange 4 book 5

1
a

2
very

a det

3
heavy

4
orange
np
nom
a,ap nom

adv ap

nom,a,ap

0
1
2
3
4

very
heavy
orange
book

5
book

18 / 32

filling out the cyk chart

0 a 1 very 2 heavy 3 orange 4 book 5

1
a

2
very

a det

3
heavy

4
orange
np
nom
a,ap nom

adv ap

5
book

0
1
2
3
4

very
heavy
orange
book

nom,a,ap

nom

18 / 32

filling out the cyk chart

0 a 1 very 2 heavy 3 orange 4 book 5

1
a

2
very

a det

3
heavy

4
orange
np
nom
a,ap nom

adv ap

5
book

0
1
2
3
4

very
heavy
orange
book

nom,a,ap nom
nom

18 / 32

filling out the cyk chart

0 a 1 very 2 heavy 3 orange 4 book 5

1
a

2
very

a det

3
heavy

4
orange
np
nom
a,ap nom

adv ap

5
book

nom
nom,a,ap nom
nom

0
1
2
3
4

very
heavy
orange
book

18 / 32

filling out the cyk chart

0 a 1 very 2 heavy 3 orange 4 book 5

1
a

2
very

a det

3
heavy

4
orange
np
nom
a,ap nom

adv ap

5
book

nom
nom
nom,a,ap nom
nom

0
1
2
3
4

very
heavy
orange
book

18 / 32

filling out the cyk chart

0 a 1 very 2 heavy 3 orange 4 book 5

1
a

2
very

a det

adv ap

3
heavy

4
orange
np
nom
a,ap nom

5
book
np
nom
nom
nom,a,ap nom
nom

0
1
2
3
4

very
heavy
orange
book

18 / 32

cyk: the general algorithm

function cky-parse(words, grammar ) returns table for
j    from 1 to length(words) do
table[j     1, j]     {a | a     words[j]     grammar}
for i    from j     2 downto 0 do
for k     i + 1 to j     1 do
table[i, j]     table[i, j]   

{a | a     bc     grammar ,

b     table[i, k]
c     table[k, j]}

19 / 32

cyk: the general algorithm

function cky-parse(words, grammar ) returns table for
j    from 1 to length(words) do

loop over the columns
table[j     1, j]     {a | a     words[j]     grammar}    ll bottom cell
for i    from j     2 downto 0 do
   ll row i in column j
for k     i + 1 to j     1 do

loop over split locations

table[i, j]     table[i, j]    between i and j

{a | a     bc     grammar , check the grammar

b     table[i, k]
c     table[k, j]}

for rules that
link the constituents
in [i, k] with those
in [k, j]. for each
rule found store
lhs in cell [i, j].

20 / 32

a succinct representation of cky

we have a boolean table called chart, such that chart[a, i, j] is
true if there is a sub-phrase according the grammar that dominates
words i through words j

build this chart recursively, similarly to the viterbi algorithm:

for j > i + 1:

chart[a, i, j] =

j   1(cid:95)

(cid:95)

k=i+1

a   b c

chart[b, i, k]     chart[c , k, j]

seed the chart, for i + 1 = j:
chart[a, i, i + 1] = true if there exists a rule a     wi+1 where
wi+1 is the (i + 1)th word in the string

21 / 32

from cyk recognizer to cyk parser

so far, we just have a chart recognizer, a way of determining
whether a string belongs to the given language.

changing this to a parser requires recording which existing
constituents were combined to make each new constituent.

this requires another    eld to record the one or more ways in
which a constituent spanning (i,j) can be made from
constituents spanning (i,k) and (k,j). (more clearly displayed
in graph representation, see next lecture.)

in any case, for a    xed grammar, the cyk algorithm runs in
time o(n3) on an input string of n tokens.
the algorithm identi   es all possible parses.

22 / 32

cyk-style parse charts

even without converting a grammar to cnf, we can draw
cyk-style parse charts:

1
a

2
very

a det

optadv optap

3
heavy

4
orange
np
nom
a,optap nom

5
book
np
nom
nom
n,nom,a,ap nom

n,nom

0
1
2
3
4

very
heavy
orange
book

(we haven   t attempted to show  -phrases here. could in principle
use cells below the main diagonal for this . . . )
however, cyk-style parsing will have run-time worse than o(n3) if
e.g. the grammar has rules a     bcd.

23 / 32

second example

grammar rules in cnf

s     np vp
s     x 1 vp
x 1     aux vp
s     book|include|prefer
s     verb np
s     x 2
s     verb pp
s     vp pp
np     twa|houston
np     det nominal
verb     book|include|prefer noun     book|   ight|money

nominal     book|   ight|money
nominal     nominal noun
nominal     nominal pp
vp     book|include|prefer
vpverb     np
vp     x 2 pp
x 2     verb np
vp     verb np
vp     vp pp
pp     preposition np

let   s parse book the    ight through houston!

24 / 32

second example

grammar rules in cnf

s     np vp
s     x 1 vp
x 1     aux vp
s     book|include|prefer
s     verb np
s     x 2
s     verb pp
s     vp pp
np     twa|houston
np     det nominal
verb     book|include|prefer noun     book|   ight|money

nominal     book|   ight|money
nominal     nominal noun
nominal     nominal pp
vp     book|include|prefer
vpverb     np
vp     x 2 pp
x 2     verb np
vp     verb np
vp     vp pp
pp     preposition np

let   s parse book the    ight through houston!

24 / 32

second example

the

   ight

through houston

book
s, vp, verb,
nominal,
noun
[0, 1]

25 / 32

second example

the

   ight

through houston

book
s, vp, verb,
nominal,
noun
[0, 1]

det
[1, 2]

25 / 32

second example

the

   ight

through houston

book
s, vp, verb,
nominal,
noun
[0, 1]

det
[1, 2]

nominal,
noun
[2, 3]

25 / 32

second example

the

   ight

through houston

book
s, vp, verb,
nominal,
noun
[0, 1]

det
[1, 2]

nominal,
noun
[2, 3]

prep
[3, 4]

25 / 32

second example

the

   ight

through houston

book
s, vp, verb,
nominal,
noun
[0, 1]

det
[1, 2]

nominal,
noun
[2, 3]

prep
[3, 4]

np, proper-
noun
[4, 5]

25 / 32

second example

book
s, vp, verb,
nominal,
noun
[0, 1]

the

   ight

through houston

[0, 2]
det
[1, 2]

nominal,
noun
[2, 3]

prep
[3, 4]

np, proper-
noun
[4, 5]

25 / 32

second example

book
s, vp, verb,
nominal,
noun
[0, 1]

the

   ight

through houston

[0, 2]
det
[1, 2]

np
[1, 3]
nominal,
noun
[2, 3]

prep
[3, 4]

np, proper-
noun
[4, 5]

25 / 32

second example

book
s, vp, verb,
nominal,
noun
[0, 1]

the

[0, 2]
det
[1, 2]

through houston

   ight
s,
vp,
x2
[0, 3]
np
[1, 3]
nominal,
noun
[2, 3]

prep
[3, 4]

np, proper-
noun
[4, 5]

25 / 32

second example

book
s, vp, verb,
nominal,
noun
[0, 1]

the

[0, 2]
det
[1, 2]

   ight
s,
vp,
x2
[0, 3]
np
[1, 3]
nominal,
noun
[2, 3]

through houston

[2, 4]
prep
[3, 4]

np, proper-
noun
[4, 5]

25 / 32

second example

book
s, vp, verb,
nominal,
noun
[0, 1]

the

[0, 2]
det
[1, 2]

   ight
s,
vp,
x2
[0, 3]
np
[1, 3]
nominal,
noun
[2, 3]

through houston

[1, 4]

[2, 4]
prep
[3, 4]

np, proper-
noun
[4, 5]

25 / 32

second example

book
s, vp, verb,
nominal,
noun
[0, 1]

the

[0, 2]
det
[1, 2]

   ight
s,
vp,
x2
[0, 3]
np
[1, 3]
nominal,
noun
[2, 3]

through houston

[0, 4]

[1, 4]

[2, 4]
prep
[3, 4]

np, proper-
noun
[4, 5]

25 / 32

second example

book
s, vp, verb,
nominal,
noun
[0, 1]

the

[0, 2]
det
[1, 2]

   ight
s,
vp,
x2
[0, 3]
np
[1, 3]
nominal,
noun
[2, 3]

through houston

[0, 4]

[1, 4]

[2, 4]
prep
[3, 4]

pp
[3, 5]
np, proper-
noun
[4, 5]

25 / 32

second example

book
s, vp, verb,
nominal,
noun
[0, 1]

the

[0, 2]
det
[1, 2]

   ight
s,
vp,
x2
[0, 3]
np
[1, 3]
nominal,
noun
[2, 3]

through houston

[0, 4]

[1, 4]

[2, 4]
prep
[3, 4]

nominal

[2, 5]
pp
[3, 5]
np, proper-
noun
[4, 5]

25 / 32

second example

book
s, vp, verb,
nominal,
noun
[0, 1]

the

[0, 2]
det
[1, 2]

   ight
s,
vp,
x2
[0, 3]
np
[1, 3]
nominal,
noun
[2, 3]

through houston

[0, 4]

[1, 4]

[2, 4]
prep
[3, 4]

np
[1, 5]
nominal

[2, 5]
pp
[3, 5]
np, proper-
noun
[4, 5]

25 / 32

second example

book
s, vp, verb,
nominal,
noun
[0, 1]

the

[0, 2]
det
[1, 2]

   ight
s,
vp,
x2
[0, 3]
np
[1, 3]
nominal,
noun
[2, 3]

through houston

[0, 4]

[1, 4]

[2, 4]
prep
[3, 4]

s1, vp, x2,
s2, vp,
s3

[0, 5]
np
[1, 5]
nominal

[2, 5]
pp
[3, 5]
np, proper-
noun
[4, 5]

25 / 32

visualizing the chart

26 / 32

visualizing the chart

27 / 32

id145 as a problem-solving technique

given a problem, systematically    ll a table of solutions to
sub-problems: this is called memoization.

once solutions to all sub-problems have been accumulated,
solve the overall problem by composing them.

for parsing, the sub-problems are analyses of sub-strings and
correspond to constituents that have been found.

sub-trees are stored in a chart (aka well-formed substring
table), which is a record of all the substructures that have
ever been built during the parse.

solves re-parsing problem: sub-trees are looked up, not re-parsed!
solves ambiguity problem: chart implicitly stores all parses!

28 / 32

a tribute to cky (part 1/3)

you, my cky algorithm,
dictate every parser   s rhythm,
if cocke, younger and kasami hadn   t bothered,
all of our parsing dreams would have been shattered.

you are so simple, yet so powerful,
and with the proper semiring and time,
you will be truthful,
to return the best parse - anything less would be a crime.

with id145 or memoization,
you are one of a kind,
i really don   t need to mention,
if it werent for you, all syntax trees would be behind.

29 / 32

a tribute to cky (part 2/3)

failed attempts have been made to show there are better,
for example, by using id127,
all of these impractical algorithms didn   t matter
you came out stronger, insisting on just using summation.

all parsing algorithms to you hail,
at least those with backbones which are context-free,
you will never become stale,
as long as we need to have a syntax tree.

it doesn   t matter that the c is always in front,
or that the k and y can swap,
you are still on the same hunt,
maximizing and summing, nonstop.

30 / 32

a tribute to cky (part 3/3)

every informatics student knows you intimately,
they have seen your variants dozens of times,
you have earned that respect legitimately,
and you will follow them through their primes.

cky, going backward and forward,
inside and out,
it is so straightforward -
you are the best, there is no doubt.

31 / 32

summary

parsing as search is ine   cient (typically exponential time).

alternative: use id145 and memoize
sub-analysis in a chart to avoid duplicate work.

the chart can be visualized as as a matrix.
the cyk algorithm builds a chart in o(n3) time. the basic
version gives just a recognizer, but it can be made into a
parser if more info is recorded in the chart.

reading:

next lecture:

j&m (2nd ed), chapter. 13, sections 13.3   13.4
nltk book, chapter. 8 (analyzing sentence
structure), section 8.4
the earley parser or id145 for top-
down parsing

32 / 32

