parts-of-speech and the lexicon in natural

language

informatics 2a: lecture 16

shay cohen

school of informatics
university of edinburgh

23 october 2017

1 / 32

last class

we discussed morphological analysis (parsing, generation and
recognition).

we described a    nite-state transducer for analysing the
morphological properties of nouns

this fst is a cascade of two fsts: one for translating a string
from an lexical form to an intermediate form, and one for
translating a string from an intermediate form to a surface form

2 / 32

1 word classes and pos tags

2 some speci   c word classes

3 lexical ambiguity and word frequency

reading: jurafsky & martin, chapter 5.

3 / 32

parts of speech in nl grammar

linguists have been classifying words for a long
time . . .

dionysius thrax of alexandria (c. 100
bc) wrote a grammatical sketch of greek
involving 8 parts-of-speech:

nouns
adverbs

verbs

conjunctions

pronouns
participles

prepositions

articles

thrax   s list and minor variations on it dominated european
language grammars and dictionaries for 2000 years.

(anyone sees an important pos missing?)

4 / 32

modern tagsets

in modern (english) nlp, larger (and more    ne-grained) tagsets
are preferred. e.g.

id32
brown corpus
c7 tagset

45 tags
87 tags
146 tags

http://bit.ly/1gwbird
http://bit.ly/1jg9i2p
http://bit.ly/1mh36kx

trade-o    between complexity and precision . . . and whatever tagset
we use, there   ll be some words that are hard to classify.

why do we need so many tags? we will see soon.

5 / 32

distributional equivalence

recall that for prog langs, a parser typically works entirely with
tags produced by the lexer (e.g. ident, num). it won   t care
whether an identi   er is x or y, or whether a numeral is 0 or 5.
consequence: x and y have the same distribution: x can occur
wherever y can, and vice versa.

the idea of pos tags is much the same: group the words of a
language into classes of words with the same (or similar)
distributions. e.g. the words

crocodile

pencil

mistake

are very di   erent as regards meaning, but grammatically can occur
in the same contexts. so let   s classify them all as nouns.
(more speci   cally, as singular, countable, common nouns.)

6 / 32

distributional equivalence

we can operationalize the idea of distributional equivalence by
using tests: can one word substitute for another?

kim saw the elephant before we did.

kim saw the movie before we did.

kim saw the mountain before we did.

kim saw the error before we did.

tests can be too strict:

(*) kim saw the sam before we did

(*) kim arrived the movie before we did

7 / 32

criteria for classifying words

when should words be put into the same class?

three di   erent criteria might be considered . . .

distributional criteria: where can the words occur?

morphological criteria: what form does the word have? (e.g.
-tion, -ize). what a   xes can it take? (e.g. -s, -ing, -est).

notional (or semantic) criteria: what sort of concept does the
word refer to? (e.g. nouns often refer to    people, places or
things   ). more problematic: less useful for us.

we   ll look at various parts-of-speech in terms of these criteria.

8 / 32

open and closed classes in natural language

there   s a broad distinction between open and closed word classes:

open classes are typically large, have    uid membership, and
are often stable under translation.
four major open classes are widely found in languages
worldwide: nouns, verbs, adjectives, adverbs.

virtually all languages have at least the    rst two.
all indo-european languages (e.g. english) have all four.

closed classes are typically small, have relatively    xed
membership, and the repertoire of classes varies widely
between languages. e.g. prepositions (english, german),
post-positions (hungarian, urdu, korean), particles
(japanese), classi   ers (chinese), etc.

closed-class words (e.g. of, which, could) often play a
structural role in the grammar as function words.

9 / 32

nouns

notionally, nouns generally refer to living things (mouse), places
(scotland), non-living things (harpoon), or concepts (marriage).

formally, -ness, -tion, -ity, and -ance tend to indicate nouns.
(happiness, exertion, levity, signi   cance).

distributionally, we can examine the contexts where a noun
appears and other words that appear in the same contexts.
for example, nouns can appear with possession:    his car   ,    her
idea   .

10 / 32

verbs

notionally, verbs refer to actions (observe, think, give).

formally, words that end in -ate or -ize tend to be verbs, and ones
that end in -ing are often the present participle of a verb
(automate, calibrate, equalize, modernize; rising, washing,
grooming ).

distributionally, we can examine the contexts where a verb appears
and at other words that appear in the same contexts, which may
include their arguments.

di   erent types of verbs have di   erent distributional properties. for
example, base form verbs can appear as in   nitives:    to jump   ,    to
learn   .

11 / 32

example of noun and verb classes

nouns:

proper nouns: names such as regina, ibm, edinburgh

pronouns: he, she, it, they, we

common nouns

count nouns: e.g. goat
mass nouns: e.g. snow (? snows)

verbs can be in base form, past tense, gerund... also, consider
auxiliary verbs.

12 / 32

why do we need so many tags?

what is the part of speech tag for    walking   ? use linguistic tests.

13 / 32

why do we need so many tags?

what is the part of speech tag for    walking   ? use linguistic tests.
verb tests:

example
walking quickly is awkward
quickly walking is awkward

13 / 32

why do we need so many tags?

what is the part of speech tag for    walking   ? use linguistic tests.
verb tests:

example
walking quickly is awkward
quickly walking is awkward

noun tests:

example
walking is awkward
her walking is awkward
fast walking is awkward

13 / 32

why do we need so many tags?

what is the part of speech tag for    walking   ? use linguistic tests.
verb tests:

example
walking quickly is awkward
quickly walking is awkward

noun tests:

example
walking is awkward
her walking is awkward
fast walking is awkward

   walking    has both properties of both noun and verb. a separate
tag for gerunds?

13 / 32

adjectives

notionally, adjectives convey properties of or opinions about things
that are nouns (small, wee, sensible, excellent).

formally, words that end in -al, -ble, and -ous tend to be
adjectives (formal, gradual, sensible, salubrious, parlous)

distributionally, adjectives usually appear before a noun or after a
form of be.

14 / 32

adverbs

notionally, adverbs convey properties of or opinions about actions
or events (quickly, often, possibly, unfortunately ) or adjectives
(really ).

formally, words that end in -ly tend to be adverbs.

distributionally, adverbs can appear next to a verb, or an adjective,
or at the start of a sentence.

15 / 32

other classes (closed)

prepositions: on, under, over, near, by, at, from, to, with
determiners: a, an, the
conjunctions: and, but, or, as, if, when
particles: up, down, on, o   , in, out, at, by
numerals: one, two, three,    rst, second, third

16 / 32

importance of formal and distributional criteria

often in reading, we come across unknown words. (especially in
computing literature!)

bootloader, distros, whitelist, diskdrak, borked
(http://www.linux.com/feature/150441)
revved, femtosecond, dogfooding
(http://hardware.slashdot.org/)

even if we don   t know its meaning, formal and distributional
criteria help people (and machines) recognize which (open) class
an unknown word belongs to.

i really wish mandriva would redesign the diskdrak ui. the orphan
bit is borked.

17 / 32

18 / 32

example of pos id136

those zorls you splarded were malgy.

what is the part of speech of the word malgy?

1 adverb

2 noun

3 verb

4 adjective

19 / 32

example of pos id136

the highly-valued share plummeted over the course of the busy
week .

can you decide on the tags of each word?

20 / 32

example of pos id136

the highly-valued share plummeted over the course of the busy
week .

can you decide on the tags of each word?

the/ highly-valued/
course/

of/

the/ busy/ week/ .

share/ plummeted/ over/

the/

20 / 32

example of pos id136

the highly-valued share plummeted over the course of the busy
week .

can you decide on the tags of each word?

the/dt highly-valued/jj share/nn plummeted/vbd over/in
the/dt course/nn of/in the/dt busy/jj week/nn ./.

21 / 32

the tagging problem

given an input text, we want to tag each word correctly:

the/dt grand/jj jury/nn commented/vbd on/in a/dt
number/nn of/in other/jj topics/nns ./.

there/ex was/vbd still/jj lemonade/nn in/in the/dt
bottle/nn ./.

(many brown/penn tags are quite counterintuitive!)

in the above, number and bottle are nouns not verbs     but
how does our tagger tell?

in the second example, still could be an adjective or an adverb
    which seems more likely?

these issues lead us to consider word frequencies, which serve as
the basis of the idea of model estimation. (among other things).

22 / 32

types of lexical ambiguity

part of speech (pos) ambiguity: e.g., still:

1 adverb: at present, as yet

2 noun: (1) silence; (2) individual frame from a    lm; (3) vessel

for distilling alcohol

3 adjective: motionless, quiet

4

transitive verb: to calm

sense ambiguity: e.g., intelligence:

1 power of understanding

2 obtaining or dispersing secret information; also the persons

engaged in obtaining or dispersing secret information

23 / 32

word frequencies in di   erent languages

ambiguity by part-of-speech tags:

language type-ambiguous token-ambiguous
english
greek
japanese
czech
turkish

56.2%
19.14%
50.2%
14.5%
35.2%

13.2%
<1%
7.6%
<1%
2.5%

taken from real data for treebanks annotated with their pos tags

24 / 32

word frequency     properties of words in use

take any corpus of english like the brown corpus or tom sawyer
and sort its words by how often they occur.

word
the
and
a
he
but
be
there
one
about
more
never
oh

freq. (f ) rank (r )
3332
2972
1775
877
410
294
222
172
158
138
124
116

1
2
3
10
20
30
40
50
60
70
80
90

f    r
3332
5944
5235
8770
8400
8820
8880
8600
9480
9660
9920
10440

25 / 32

word frequency     properties of words in use

take any corpus of english like the brown corpus or tom sawyer
and sort its words by how often they occur.

word
two
turned
you   ll
name
comes
group
lead
friends
begin
family
brushed
sins

freq. (f ) rank (r )
104
51
30
21
16
13
11
10
9
8
4
2

100
200
300
400
500
600
700
800
900
1000
2000
3000

f    r
10400
10200
9000
8400
8000
7800
7700
8000
8100
8000
8000
6000

26 / 32

zipf   s law

given some corpus of natural language utterances, the frequency
of any word is inversely proportional to its rank in the frequency
table (observation made by harvard linguist george kingsley zipf).

zipf   s law states that: f     1
there is a constant k such that: f    r = k.

r

27 / 32

zipf   s law for the brown corpus

28 / 32

zipf   s law

according to zipf   s law:

there is a very small number of very common words.

there is a small-medium number of middle frequency words.

there is a very large number of words that are infrequent.

(it   s not fully understood why zipf   s law works so well for word
frequencies.)
in fact, many other kinds of data conform closely to a zip   an
distribution:

populations of cities.

sizes of earthquakes.

amazon sales rankings.

29 / 32

rule-based tagging

old pos taggers used to work in two stages, based on
hand-written rules: the    rst stage identi   es a set of possible pos
for each word in the sentence (based on a lexicon), and the second
uses a set of hand-crafted rules in order to select a pos from each
of the lists for each word.

example:

1

if a word belongs to the set of determiners, tag is at dt.

2 tag a word next to a determiner as an adjective (jj), if it

3

ends with -ed.
if a word appears after is or are and it ends with ing, tag it
as a verb vbg.

30 / 32

why do we need pos tags?

they are often an essential ingredient in natural language
applications

usually appear at the    bottom    of the pipeline

for example: most of the syntactic variability (we will learn
about that later) is determined by the sequence of pos tags
in a sentence. pos tags are easier to predict than the full
syntax, and therefore, by predicting the pos tags, we pave
the way for identi   cation of full phrases: noun phrases, verb
phrases, etc.

31 / 32

extreme pos ambiguity...

bu   alo bu   alo bu   alo bu   alo bu   alo bu   alo bu   alo bu   alo

32 / 32

extreme pos ambiguity...

bu   alo bu   alo bu   alo bu   alo bu   alo bu   alo bu   alo bu   alo

bison from bu   alo, which bison from bu   alo bully, themselves
bully bison from bu   alo.

32 / 32

extreme pos ambiguity...

bu   alo bu   alo bu   alo bu   alo bu   alo bu   alo bu   alo bu   alo

bison from bu   alo, which bison from bu   alo bully, themselves
bully bison from bu   alo.

if police police police police, who police police police? police
police police police police police

look it up!

32 / 32

