id140

informatics 2a: lecture 22

shay cohen

6 november, 2017

1 / 30

last class

the earley algorithm (three important operators that are run
until we    nd a parse: predictor, scanner and
completer)
the complexity of cyk and the earley algorithm: o(n3).
(but, grammar constants can be large!)

the example that i went through is available online. go step
by step through it to understand it

2 / 30

1 motivation

2 id140

de   nition
conditional probabilities
applications
probabilistic cyk

3 / 30

why id203?

id203 is one of the most important tools in reasoning under
uncertainty

we build a probabilistic model of a phenomenon in the world

the model allows more than one outcome for a given scenario

that way, we can reason in various contexts depending on the
situation. in our case, id203 mostly helps managing ambiguity

often, we will be interested in the most likely outcome

we already saw a case of that with part-of-speech tagging

4 / 30

motivation

three things motivate the use of probabilities in grammars and
parsing:

1 syntactic disambiguation. ambiguity is unavoidable in natural

language (grammars).

2 coverage. what if there is a production that we haven   t seen
before? might want to allow with small id203 (seemingly
extreme but actually common use case: all productions are
possible!).

3 representativeness. suppose we want to adapt a parser to a
new domain, where some words have di   erent usage, hence
di   erent part-of-speech.

5 / 30

motivation 1: ambiguity

amount of ambiguity increases with sentence length.

real sentences are fairly long (avg. sentence length in the
wall street journal is 25 words).

the amount of (unexpected!) ambiguity increases rapidly with
sentence length. this poses a problem, even for chart parsers,
if they have to keep track of all possible analyses.

it would reduce the amount of work required if we could
ignore improbable analyses.

a second provision passed by the senate and house would
eliminate a rule allowing companies that post losses
resulting from lbo debt to receive refunds of taxes paid
over the previous three years. [wsj 1822] (33 words)

6 / 30

motivation 2: coverage

it is actually very di   cult to write a grammar that covers all
the constructions used in ordinary text or speech.

typically hundreds of rules are required in order to capture
both all the di   erent linguistic patterns and all the di   erent
possible analyses of the same pattern. (how many grammar
rules did we have to add to cover three di   erent analyses of
you made her duck?)

ideally, one wants to induce (learn) a grammar from a corpus.

grammar induction requires probabilities.

7 / 30

motivation 3: representativeness

the likelihood of a particular construction can vary, depending on:

register (formal vs. informal): eg, greenish, alot, subject-drop
(want a beer? ) are all more probable in informal than formal
register;

genre (newspapers, essays, mystery stories, jokes, ads,
twitter, etc.): pos-taggers trained on di   erent genres often
have very di   erent distributions.

domain (biology, patent law, football, etc.).

probabilistic grammars and parsers can re   ect these kinds of
distributions.

8 / 30

what have we achieved so far?

a zoo of parsing algorithms: recursive descent parsing,
id132, cyk algorithm, earley algorithm

they all work as recognisers, or with backpointers: parsers
that return all possible parses

is there a notion of best parse? or is it better to keep all of
these parses?

9 / 30

example parses for an ambiguous sentence

s

vp

det

the

verb

book

book the dinner    ight.

s

vp

np

nominal

nominal

noun

noun

   ight

dinner

verb

np

np

book

det

nominal

nominal

the

nominal

noun

noun

   ight

dinner

10 / 30

id140

a pid18 (cid:104)n,   , r, s(cid:105) is de   ned as follows:
n is the set of non-terminal symbols
   is the terminals (disjoint from n)
r is a set of rules of the form a       [p]
where a     n and        (       n)   ,
and p is a number between 0 and 1
a start symbol, s     n

s

a pid18 is a id18 in which each rule is associated with a
id203.

11 / 30

more about pid18s

what does the p associated with each rule express?

it expresses the id203 that the lhs non-terminal will be
expanded as the rhs sequence.

(cid:80)

p(a       |a)

p(a       |a) = 1

  
the sum of the probabilities associated with all of the rules
expanding the non-terminal a is required to be 1.

a        [p]

or p(a       |a) = p

or p(a       ) = p

12 / 30

example grammar

s     np vp
s     aux np vp
s     vp
np     pronoun
np     proper -noun
np     det nominal
np     nominal
nominal     noun
nominal     nominal noun
vp     verb
vp     verb np
vp     verb np pp
vp     verb pp

[.80] det     the
[.15] det     a
[.05] noun     book
[.35] noun        ight
[.30] noun     dinner
[.20] proper -noun     houston
[.15] proper -noun     nwa
[.75] aux     does
[.05] aux     can
[.35] verb     book
[.20] verb     include
[.10] verb     prefer
[.15] verb     sleep

[.10]
[.90]
[.10]
[.30]
[.60]
[.60]
[.40]
[.60]
[.40]
[.30]
[.30]
[.20]
[.20]

13 / 30

pid18s as a random process

start with the root node, and at each step, probabilistically expand
the nodes until you hit a terminal symbol:

14 / 30

pid18s and consistency

qustion: does this process always have to terminate?

15 / 30

pid18s and consistency

qustion: does this process always have to terminate?

consider the grammar, for some   > 0:

example
s     s s with id203 0.5 +  
s     a with id203 0.5      

15 / 30

pid18s and consistency

qustion: does this process always have to terminate?

consider the grammar, for some   > 0:

example
s     s s with id203 0.5 +  
s     a with id203 0.5      

whenever a nonterminal is expanded, it is more probable that the
result will increase rather than decrease the number of
nonterminals in the intermediate string.

hence, the id203 of seeing a    nite tree is less than one!

fortunately, most (but not all) common methods of assigning
probabilities do not have this problem.

15 / 30

id48s and pid18s

we know that context-free formalisms are more powerful than
   nite state transducers.

as such, id48 can be represented as
id140:

for each emission p(w | t ) include a rule t [pre]     w with
the corresponding id203
for each transition p(t | t (cid:48)) include a rule t     t [pre]t (cid:48)
with the corresponding id203
add the starting rule s     t for each t with probabilities
p(t | start)
add the rules t       with probabilities p(stop | t )

we will get right branching trees

16 / 30

independence assumptions in random process of pid18s

we have a    markovian    process here (limited memory of history)

everything above a given node in the tree is conditionally
independent of everything below that node if we know what is the
nonterminal in that node

another way to think about it: once we get to a new nonterminal
and continue from there, we forget the whole derivation up to that
point, and focus on that nonterminal as if it is a new root node

too strong independence assumptions for natural language data.

17 / 30

pid18s and disambiguation

a pid18 assigns a id203 to every parse tree or derivation
associated with a sentence.

this id203 is the product of the rules applied in building
the parse tree.

p(t , s)

=

p(ai       i ) n is number of rules in t

n(cid:81)

i=1

= p(t )p(s|t ) = p(s)p(t|s) by de   nition

p(t , s)
but p(s|t ) = 1

so p(t , s) = p(t )

because s is determined by t

18 / 30

application 1: disambiguation

s

vp

det

the

verb

book

s

vp

np

nominal

nominal

noun

noun

   ight

dinner

verb

np

np

book

det

nominal

nominal

the

noun

noun

dinner

   ight

p(tleft) = .05     .20     .20     .20     .75     .30     .60     .10     .40 = 2.2    10   6
p(tright) = .05   .10   .20   .15   .75   .75   .30   .60   .10   .40 = 6.1    10   7

19 / 30

application 1: disambiguation

s

vp

det

the

verb

book

s

vp

np

nominal

nominal

noun

noun

   ight

dinner

verb

np

np

book

det

nominal

nominal

the

noun

noun

dinner

   ight

p(tleft) = .05     .20     .20     .20     .75     .30     .60     .10     .40 = 2.2    10   6
p(tright) = .05   .10   .20   .15   .75   .75   .30   .60   .10   .40 = 6.1    10   7

19 / 30

application 1: disambiguation

s

vp

det

the

verb

book

s

vp

np

nominal

nominal

noun

noun

   ight

dinner

verb

np

np

book

det

nominal

nominal

the

noun

noun

dinner

   ight

p(tleft) = .05     .20     .20     .20     .75     .30     .60     .10     .40 = 2.2    10   6
p(tright) = .05   .10   .20   .15   .75   .75   .30   .60   .10   .40 = 6.1    10   7

19 / 30

application 1: disambiguation

s

vp

det

the

verb

book

s

vp

np

nominal

nominal

noun

noun

   ight

dinner

verb

np

np

book

det

nominal

nominal

the

noun

noun

dinner

   ight

p(tleft) = .05     .20     .20     .20     .75     .30     .60     .10     .40 = 2.2    10   6
p(tright) = .05   .10   .20   .15   .75   .75   .30   .60   .10   .40 = 6.1    10   7

19 / 30

application 1: disambiguation

s

vp

det

the

verb

book

s

vp

np

nominal

nominal

noun

noun

   ight

dinner

verb

np

np

book

det

nominal

nominal

the

noun

noun

dinner

   ight

p(tleft) = .05     .20     .20     .20     .75     .30     .60     .10     .40 = 2.2    10   6
p(tright) = .05   .10   .20   .15   .75   .75   .30   .60   .10   .40 = 6.1    10   7

19 / 30

application 1: disambiguation

s

vp

det

the

verb

book

s

vp

np

nominal

nominal

noun

noun

   ight

dinner

verb

np

np

book

det

nominal

nominal

the

noun

noun

dinner

   ight

p(tleft) = .05     .20     .20     .20     .75     .30     .60     .10     .40 = 2.2    10   6
p(tright) = .05   .10   .20   .15   .75   .75   .30   .60   .10   .40 = 6.1    10   7

19 / 30

application 1: disambiguation

s

vp

det

the

verb

book

s

vp

np

nominal

nominal

noun

noun

   ight

dinner

verb

np

np

book

det

nominal

nominal

the

noun

noun

dinner

   ight

p(tleft) = .05     .20     .20     .20     .75     .30     .60     .10     .40 = 2.2    10   6
p(tright) = .05   .10   .20   .15   .75   .75   .30   .60   .10   .40 = 6.1    10   7

19 / 30

application 1: disambiguation

s

vp

det

the

verb

book

s

vp

np

nominal

nominal

noun

noun

   ight

dinner

verb

np

np

book

det

nominal

nominal

the

noun

noun

dinner

   ight

p(tleft) = .05     .20     .20     .20     .75     .30     .60     .10     .40 = 2.2    10   6
p(tright) = .05   .10   .20   .15   .75   .75   .30   .60   .10   .40 = 6.1    10   7

19 / 30

application 1: disambiguation

s

vp

det

the

verb

book

s

vp

np

nominal

nominal

noun

noun

   ight

dinner

verb

np

np

book

det

nominal

nominal

the

noun

noun

dinner

   ight

p(tleft) = .05     .20     .20     .20     .75     .30     .60     .10     .40 = 2.2    10   6
p(tright) = .05   .10   .20   .15   .75   .75   .30   .60   .10   .40 = 6.1    10   7

19 / 30

application 1: disambiguation

s

vp

det

the

verb

book

s

vp

np

nominal

nominal

noun

noun

   ight

dinner

verb

np

np

book

det

nominal

nominal

the

noun

noun

dinner

   ight

p(tleft) = .05     .20     .20     .20     .75     .30     .60     .10     .40 = 2.2    10   6
p(tright) = .05   .10   .20   .15   .75   .75   .30   .60   .10   .40 = 6.1    10   7

19 / 30

application 1: disambiguation

s

vp

det

the

verb

book

s

vp

np

nominal

nominal

noun

noun

   ight

dinner

verb

np

np

book

det

nominal

nominal

the

noun

noun

dinner

   ight

p(tleft) = .05     .20     .20     .20     .75     .30     .60     .10     .40 = 2.2    10   6
p(tright) = .05   .10   .20   .15   .75   .75   .30   .60   .10   .40 = 6.1    10   7

19 / 30

application 1: disambiguation

s

vp

det

the

verb

book

s

vp

np

nominal

nominal

noun

noun

   ight

dinner

verb

np

np

book

det

nominal

nominal

the

noun

noun

dinner

   ight

p(tleft) = .05     .20     .20     .20     .75     .30     .60     .10     .40 = 2.2    10   6
p(tright) = .05   .10   .20   .15   .75   .75   .30   .60   .10   .40 = 6.1    10   7

19 / 30

application 1: disambiguation

s

vp

det

the

verb

book

s

vp

np

nominal

nominal

noun

noun

   ight

dinner

verb

np

np

book

det

nominal

nominal

the

noun

noun

dinner

   ight

p(tleft) = .05     .20     .20     .20     .75     .30     .60     .10     .40 = 2.2    10   6
p(tright) = .05   .10   .20   .15   .75   .75   .30   .60   .10   .40 = 6.1    10   7

19 / 30

application 1: disambiguation

s

vp

det

the

verb

book

s

vp

np

nominal

nominal

noun

noun

   ight

dinner

verb

np

np

book

det

nominal

nominal

the

noun

noun

dinner

   ight

p(tleft) = .05     .20     .20     .20     .75     .30     .60     .10     .40 = 2.2    10   6
p(tright) = .05   .10   .20   .15   .75   .75   .30   .60   .10   .40 = 6.1    10   7

19 / 30

application 1: disambiguation

s

vp

det

the

verb

book

s

vp

np

nominal

nominal

noun

noun

   ight

dinner

verb

np

np

book

det

nominal

nominal

the

noun

noun

dinner

   ight

p(tleft) = .05     .20     .20     .20     .75     .30     .60     .10     .40 = 2.2    10   6
p(tright) = .05   .10   .20   .15   .75   .75   .30   .60   .10   .40 = 6.1    10   7

19 / 30

application 1: disambiguation

s

vp

det

the

verb

book

s

vp

np

nominal

nominal

noun

noun

   ight

dinner

verb

np

np

book

det

nominal

nominal

the

noun

noun

dinner

   ight

p(tleft) = .05     .20     .20     .20     .75     .30     .60     .10     .40 = 2.2    10   6
p(tright) = .05   .10   .20   .15   .75   .75   .30   .60   .10   .40 = 6.1    10   7

19 / 30

application 1: disambiguation

s

vp

det

the

verb

book

s

vp

np

nominal

nominal

noun

noun

   ight

dinner

verb

np

np

book

det

nominal

nominal

the

noun

noun

dinner

   ight

p(tleft) = .05     .20     .20     .20     .75     .30     .60     .10     .40 = 2.2    10   6
p(tright) = .05   .10   .20   .15   .75   .75   .30   .60   .10   .40 = 6.1    10   7

19 / 30

application 1: disambiguation

s

vp

det

the

verb

book

s

vp

np

nominal

nominal

noun

noun

   ight

dinner

verb

np

np

book

det

nominal

nominal

the

noun

noun

dinner

   ight

p(tleft) = .05     .20     .20     .20     .75     .30     .60     .10     .40 = 2.2    10   6
p(tright) = .05   .10   .20   .15   .75   .75   .30   .60   .10   .40 = 6.1    10   7

19 / 30

application 1: disambiguation

s

vp

det

the

verb

book

s

vp

np

nominal

nominal

noun

noun

   ight

dinner

verb

np

np

book

det

nominal

nominal

the

noun

noun

dinner

   ight

p(tleft) = .05     .20     .20     .20     .75     .30     .60     .10     .40 = 2.2    10   6
p(tright) = .05   .10   .20   .15   .75   .75   .30   .60   .10   .40 = 6.1    10   7

19 / 30

application 1: disambiguation

s

vp

det

the

verb

book

s

vp

np

nominal

nominal

noun

noun

   ight

dinner

verb

np

np

book

det

nominal

nominal

the

noun

noun

dinner

   ight

p(tleft) = .05     .20     .20     .20     .75     .30     .60     .10     .40 = 2.2    10   6
p(tright) = .05   .10   .20   .15   .75   .75   .30   .60   .10   .40 = 6.1    10   7

19 / 30

application 1: disambiguation

s

vp

det

the

verb

book

s

vp

np

nominal

nominal

noun

noun

   ight

dinner

verb

np

np

book

det

nominal

nominal

the

noun

noun

dinner

   ight

p(tleft) = .05     .20     .20     .20     .75     .30     .60     .10     .40 = 2.2    10   6
p(tright) = .05   .10   .20   .15   .75   .75   .30   .60   .10   .40 = 6.1    10   7

notice that shared parts have same id203!

19 / 30

application 2: language modelling

as well as assigning probabilities to parse trees, a pid18 assigns a
id203 to every sentence generated by the grammar. this is
useful for language modelling.

the id203 of a sentence is the sum of the probabilities of each
parse tree associated with the sentence:

(cid:88)
(cid:88)

p(s) =

ts.t.yield(t )=s

p(s) =

p(t , s)

p(t )

s.t.yield(t )=s

when is it useful to know the id203 of a sentence?
when ranking the output of id103, machine
translation, and error correction systems.

20 / 30

probabilistic parsing

with id48s, we were interested in the most likely sequence
of tags given the sentence

with pid18s, we are interested in the most likely derivation
given the sentence:

arg max

t

p(t | s) = arg max

t

p(t , s)

p(s)

= arg max

t

p(t , s)

therefore, due to bayes    rule, we need to    nd the most likely
derivation for a sentence, without having to compute the
id203 of a sentence (summing over all derivations)

21 / 30

probabilistic cyk

many probabilistic parsers use a probabilistic version of the cyk
bottom-up chart parsing algorithm.

sentence s of length n and id18 grammar with v non-terminals
ordinary cyk
2-d(n + 1)     (n + 1) array where a value in cell (i, j) is list of
non-terminals spanning position i through j in s.

probabilistic cyk
3-d(n + 1)     (n + 1)     v array where a value in cell (i, j, k ) is
id203 of non-terminal k spanning position i through j in s

as with regular cyk, probabilistic cyk assumes that the grammar
is in chomsky-normal form (rules a     b c or a     w ).

22 / 30

recursive description of probabilistic cyk

call chart[a, i, j] the id203 of the highest-id203
derivation of wi+1...wj from a. stated mathematically:
chart[a, i, i + i] =p(a     wi+1)

chart[a, i, j] = max

max

{b,c :a   b c   g}

{k:i<k<j}
chart[b, i, k]    chart[c , k, j]    p(a     b c )

23 / 30

recursive description of probabilistic cyk

call chart[a, i, j] the id203 of the highest-id203
derivation of wi+1...wj from a. stated mathematically:
chart[a, i, i + i] =p(a     wi+1)

chart[a, i, j] = max

max

{b,c :a   b c   g}

{k:i<k<j}
chart[b, i, k]    chart[c , k, j]    p(a     b c )

seem familiar?

23 / 30

recursive description of probabilistic cyk

call chart[a, i, j] the id203 of the highest-id203
derivation of wi+1...wj from a. stated mathematically:
chart[a, i, i + i] =p(a     wi+1)

chart[a, i, j] = max

max

{b,c :a   b c   g}

{k:i<k<j}
chart[b, i, k]    chart[c , k, j]    p(a     b c )

seem familiar?

remember cyk (where chart[a, i, j] was simply true or false):

chart[a, i, j] =true i    a     wi+1     g

chart[a, i, j] =

chart[b, i, k]     chart[c , k, j]

j   1(cid:95)

(cid:95)

k=i+1

a   b c

powerful abstraction: probabilistic cyk is just cyk with a
di   erent semiring.

23 / 30

probabilistic cyk

function probabilistic-cyk(words, grammar ) returns most
probable parse and its id203
for j    from 1 to length(words) do
for all {a|a     words[j]     grammar}
table[j     1, j, a]     p(a     words[j])
for i    from j     2 downto 0 do
for all {a|a     bc     grammar ,
if(table[i, j, a]<p(a   bc )  table[i, k, b]  table[k, j, c ])then
table[i, j, a]     p(a     bc )    table[i, k, b]    table[k, j, c ]
back[i, j, a]     {k, b, c}

and table[i, k, b] > 0 and table[k, j, c ] > 0}

return
build tree(back[1,length(words), s]), table[1,length(words), s]

24 / 30

visualizing the chart

   ight

includes

a

meal

the

det: .40

[0, 1]

s     np vp .80 det     the.40
np     det n .30 det     a .40
vp     v np .20 n     meal .01
v     includes.05 n        ight.02

25 / 30

visualizing the chart

   ight

includes

a

meal

the

det: .40

[0, 1]

n: .02
[1, 2]

s     np vp .80 det     the.40
np     det n .30 det     a .40
vp     v np .20 n     meal .01
v     includes.05 n        ight.02

25 / 30

visualizing the chart

   ight

includes

a

meal

the

det: .40

[0, 1]

n: .02
[1, 2]

v: .05

[2, 3]

s     np vp .80 det     the.40
np     det n .30 det     a .40
vp     v np .20 n     meal .01
v     includes.05 n        ight.02

25 / 30

visualizing the chart

   ight

includes

a

meal

the

det: .40

[0, 1]

n: .02
[1, 2]

v: .05

[2, 3]

s     np vp .80 det     the.40
np     det n .30 det     a .40
vp     v np .20 n     meal .01
v     includes.05 n        ight.02

det: .40

[3, 4]

25 / 30

visualizing the chart

   ight

includes

a

meal

the

det: .40

[0, 1]

n: .02
[1, 2]

v: .05

[2, 3]

s     np vp .80 det     the.40
np     det n .30 det     a .40
vp     v np .20 n     meal .01
v     includes.05 n        ight.02

det: .40

[3, 4]

n: .01
[4, 5]

25 / 30

visualizing the chart

the

det: .40 np:

includes

a

meal

  

   ight
.30  .40
.02 = .0024
[0, 2]
n: .02
[1, 2]

[0, 1]

v: .05

[2, 3]

s     np vp .80 det     the.40
np     det n .30 det     a .40
vp     v np .20 n     meal .01
v     includes.05 n        ight.02

det: .40

[3, 4]

n: .01
[4, 5]

25 / 30

visualizing the chart

the

det: .40 np:

[0, 1]

   ight
.30  .40
.02 = .0024
[0, 2]
n: .02
[1, 2]

includes

a

meal

  

[1, 3]
v: .05

[2, 3]

s     np vp .80 det     the.40
np     det n .30 det     a .40
vp     v np .20 n     meal .01
v     includes.05 n        ight.02

det: .40

[3, 4]

n: .01
[4, 5]

25 / 30

visualizing the chart

the

det: .40 np:

[0, 1]

   ight
.30  .40
.02 = .0024
[0, 2]
n: .02
[1, 2]

includes

a

meal

  

[0, 3]

[1, 3]
v: .05

[2, 3]

s     np vp .80 det     the.40
np     det n .30 det     a .40
vp     v np .20 n     meal .01
v     includes.05 n        ight.02

det: .40

[3, 4]

n: .01
[4, 5]

25 / 30

includes

a

meal

visualizing the chart

the

det: .40 np:

[0, 1]

   ight
.30  .40
.02 = .0024
[0, 2]
n: .02
[1, 2]

  

[0, 3]

[1, 3]
v: .05

[2, 3]

s     np vp .80 det     the.40
np     det n .30 det     a .40
vp     v np .20 n     meal .01
v     includes.05 n        ight.02

[2, 4]
det: .40

[3, 4]

n: .01
[4, 5]

25 / 30

visualizing the chart

the

det: .40 np:

[0, 1]

   ight
.30  .40
.02 = .0024
[0, 2]
n: .02
[1, 2]

  

[0, 3]

[1, 3]
v: .05

[2, 3]

s     np vp .80 det     the.40
np     det n .30 det     a .40
vp     v np .20 n     meal .01
v     includes.05 n        ight.02

includes

a

meal

[1, 4]

[2, 4]
det: .40

[3, 4]

n: .01
[4, 5]

25 / 30

visualizing the chart

the

det: .40 np:

[0, 1]

   ight
.30  .40
.02 = .0024
[0, 2]
n: .02
[1, 2]

includes

a

meal

  

[0, 3]

[0, 4]

[1, 3]
v: .05

[1, 4]

[2, 3]

[2, 4]
det: .40

s     np vp .80 det     the.40
np     det n .30 det     a .40
vp     v np .20 n     meal .01
v     includes.05 n        ight.02

[3, 4]

n: .01
[4, 5]

25 / 30

visualizing the chart

the

det: .40 np:

includes

a

meal

  

   ight
.30  .40
.02 = .0024
[0, 2]
n: .02
[1, 2]

[0, 1]

[0, 3]

[0, 4]

[1, 3]
v: .05

[1, 4]

[2, 3]

[2, 4]
det: .40

s     np vp .80 det     the.40
np     det n .30 det     a .40
vp     v np .20 n     meal .01
v     includes.05 n        ight.02

[3, 4]

np: .30    .40   
.01 = 0.0012
[3, 5]

n: .01
[4, 5]

25 / 30

visualizing the chart

the

det: .40 np:

includes

a

meal

  

   ight
.30  .40
.02 = .0024
[0, 2]
n: .02
[1, 2]

[0, 1]

[0, 3]

[0, 4]

[1, 3]
v: .05

[1, 4]

[2, 3]

[2, 4]
det: .40

s     np vp .80 det     the.40
np     det n .30 det     a .40
vp     v np .20 n     meal .01
v     includes.05 n        ight.02

[3, 4]

.20   
vp:
.05    0.0012 =
0.000012
[2, 5]
np: .30    .40   
.01 = 0.0012
[3, 5]

n: .01
[4, 5]

25 / 30

visualizing the chart

the

det: .40 np:

includes

a

meal

  

   ight
.30  .40
.02 = .0024
[0, 2]
n: .02
[1, 2]

[0, 1]

[0, 3]

[0, 4]

[1, 3]
v: .05

[1, 4]

[2, 3]

[2, 4]
det: .40

s     np vp .80 det     the.40
np     det n .30 det     a .40
vp     v np .20 n     meal .01
v     includes.05 n        ight.02

[3, 4]

[1, 5]
.20   
vp:
.05    0.0012 =
0.000012
[2, 5]
np: .30    .40   
.01 = 0.0012
[3, 5]

n: .01
[4, 5]

25 / 30

visualizing the chart

the

det: .40 np:

[0, 1]

   ight
.30  .40
.02 = .0024
[0, 2]
n: .02
[1, 2]

includes

a

  

[0, 3]

[0, 4]

[1, 3]
v: .05

[1, 4]

[2, 3]

[2, 4]
det: .40

s     np vp .80 det     the.40
np     det n .30 det     a .40
vp     v np .20 n     meal .01
v     includes.05 n        ight.02

[3, 4]

meal

s: .80    .0024   
=
.000012
.000000023
[0, 5]

[1, 5]
.20   
vp:
.05    0.0012 =
0.000012
[2, 5]
np: .30    .40   
.01 = 0.0012
[3, 5]

n: .01
[4, 5]

25 / 30

probabilistic cyk: more tricky example

s     np vp (1.0)
np     n (0.6)
vp     v (0.8)
n     orange (0.3)
a     orange (1.0)
v     blossoms (1.0)
adv     early (1.0)

| a np (0.2)
| v adv (0.2)

| np n (0.2)

| tree (0.5)

| blossoms (0.2)

(not quite in cnf, but never mind.) we   ll parse:

orange tree blossoms early

26 / 30

the probabilistic cyk-style chart

orange
orange n (0.3)
a (1.0)
np (0.18)

tree

blossoms

early

tree
np (0.06)

blossoms
s (0.048)
np (0.0024)

early
s (0.012)

n (0.5)
np (0.3)

np (0.012)

s (0.06)

n (0.2)
v (1.0)
np (0.12)
vp (0.8)

vp (0.2)

adv(1.0)

27 / 30

the probabilistic cyk-style chart: some comments

the phrase orange tree gets 0.06 for its best analysis as an
np, since

0.06 = 0.2*1.0*0.3
beats 0.018 = 0.18*0.5*0.2

(for np     a np)
(for np     np n).
only the higher id203 is recorded in the chart.

for orange tree blossoms, there are now two analyses as np,
each with id203 0.0024.

there is also an analysis of orange tree blossoms as s. this
doesn   t compete with its analysis as np, so both are recorded.

28 / 30

how to turn earley into probabilistic earley?

each item carries a id203 as a weight.

maintain backpointers as usual.

when scanning a word in an rhs with a lexical rule, multiply
in the rule id203 into the item.

when completing a constituent, multiply in the rule
id203 into the complete item.

if you ever need to    re-create    an item that was already
created, replace its backpointers with the new ones only if the
new re-created item has a larger id203.

id117 can also be represented using id145
equations.

29 / 30

summary

a pid18 is a id18 with each rule annotated with a id203;

the sum of the probabilities of all rules that expand the same
non-terminal must be 1;

id203 of a parse tree is the product of the probabilities of
all the rules used in this parse;

id203 of sentence is sum of probabilities of all its parses;

applications for pid18s: disambiguation, id38;

probabilistic cyk algorithm.

next lecture: but where do the rule probabilities come from?

30 / 30

