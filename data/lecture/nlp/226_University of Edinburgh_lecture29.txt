id87
id181
cross-id178

id87
id181
cross-id178

formal modeling in cognitive science

lecture 29: id87 and applications;

id181; cross-id178

frank keller

school of informatics
university of edinburgh
keller@inf.ed.ac.uk

march 14, 2006

1 id87

channel capacity
properties of channel capacity
applications

2 id181

3 cross-id178

frank keller

formal modeling in cognitive science

1

frank keller

formal modeling in cognitive science

2

id87
id181
cross-id178

channel capacity
properties of channel capacity
applications

id87
id181
cross-id178

channel capacity
properties of channel capacity
applications

id87

channel capacity

so far, we have looked at encoding a message e(cid:14)ciently, put what
about transmitting the message?

the transmission of a message can be modeled using a noisy
channel:

a message w is encoded, resulting in a string x ;

x is transmitted through a channel with the id203
distribution f (y jx);

the resulting string y is decoded, yielding an estimate of the
message ^w .

w

message

encoder

x

channel
f(y|x)

y

decoder

w^

estimate
of message

we are interested in the mathematical properties of the channel
used to transmit the message, and in particular in its capacity.

de(cid:12)nition: discrete channel
a discrete channel consists of an input alphabet x , an output
alphabet y and a id203 distribution f (y jx) that expresses the
id203 of observing symbol y given that symbol x is sent.

de(cid:12)nition: channel capacity
the channel capacity of a discrete channel is:

c = max
f (x)

i (x ; y )

the capacity of a channel is the maximum of the mutual
information of x and y over all input distributions f (x).

frank keller

formal modeling in cognitive science

3

frank keller

formal modeling in cognitive science

4

id87
id181
cross-id178

channel capacity
properties of channel capacity
applications

id87
id181
cross-id178

channel capacity
properties of channel capacity
applications

channel capacity

channel capacity

example: noiseless binary channel
assume a binary channel whose input is reproduced exactly at the
output. each transmitted bit is received without error:

0

1

0

1

the channel capacity of this channel is:

c = max
f (x)

i (x ; y ) = 1 bit

example: binary symmetric channel

assume a binary channel whose input is (cid:13)ipped (0 transmitted a 1 or 1
transmitted as 0) with id203 p:

0

1

1 - p

1 - p

p
p

0

1

the mutual information of this channel is bounded by:

i (x ; y ) = h(y ) (cid:0) h(x jy ) = h(y ) (cid:0) px f (x)h(y jx = x)
= h(y ) (cid:0) px f (x)h(p) = h(y ) (cid:0) h(p) (cid:20) 1 (cid:0) h(p)

this maximum is achieved with f (0) = 1

2 and f (1) = 1
2 .

the channel capacity is therefore:

c = max
f (x)

i (x ; y ) = 1 (cid:0) h(p) bits

frank keller

formal modeling in cognitive science

5

frank keller

formal modeling in cognitive science

6

id87
id181
cross-id178

channel capacity
properties of channel capacity
applications

id87
id181
cross-id178

channel capacity
properties of channel capacity
applications

channel capacity

properties channel capacity

a binary data sequence of length 10,000 transmitted over a binary
symmetric channel with p = 0:1:

0

1

1 - p

1 - p

p
p

0

1

theorem: properties of channel capacity

1 c (cid:21) 0 since i (x ; y ) (cid:21) 0;

2 c (cid:20) log jx j, since c = max i (x ; y ) (cid:20) max h(x ) (cid:20) log jx j;

3 c (cid:20) log jy j for the same reason.

frank keller

formal modeling in cognitive science

7

frank keller

formal modeling in cognitive science

8

id87
id181
cross-id178

channel capacity
properties of channel capacity
applications

id87
id181
cross-id178

channel capacity
properties of channel capacity
applications

applications of the id87

applications of the id87

the noisy channel can be applied to decoding processes involving
linguistic information. a typical formulation of such a problem is:

we start with a linguistic input i ;

i is transmitted through a noisy channel with the id203
distribution f (oji);

the resulting output o is decoded, yielding an estimate of the
input ^i .

i

noisy channel

f(o|i)

o

decoder

i^

application
machine trans-
lation

optical charac-
ter recognition
part of speech
tagging

input
target
language
word
sequences
actual text

pos
sequences

output
source
language
word
sequences
text with
mistakes
word
sequences

speech recog-
nition

word
sequences

speech sig-
nal

f (i)
target
language
model

language
model
id203
of
pos
sequences
language
model

f (oji)
translation
model

model
of
ocr errors
f (w jt)

acoustic
model

frank keller

formal modeling in cognitive science

9

frank keller

formal modeling in cognitive science

10

id87
id181
cross-id178

channel capacity
properties of channel capacity
applications

id87
id181
cross-id178

channel capacity
properties of channel capacity
applications

applications of the id87

example output: spanish{english

let   s look at machine translation in more detail. assume that the
french text (f ) passed through a noisy channel and came out as
english (e ). we decode it to estimate the original french ( ^f ):

f

noisy channel

f(e|f)

e

decoder

^
f

we compute ^f using bayes    theorem:

^f = arg max

f

f (f je) = arg max

f

f (f )f (ejf )

f (e)

= arg max

f

f (f )f (ejf )

here f (ejf ) is the translation model, f (f ) is the french language
model, and f (e) is the english language model (constant).

we all know very well that the current treaties are insu(cid:14)cient and that ,
in the future , it will be necessary to develop a better structure and
di(cid:11)erent for the european union , a structure more constitutional also
make it clear what the competences of the member states and which
belong to the union . messages of concern in the (cid:12)rst place just before
the economic and social problems for the present situation , and in spite
of sustained growth , as a result of years of e(cid:11)ort on the part of our
citizens . the current situation , unsustainable above all for many
self-employed drivers and in the area of agriculture , we must improve
without doubt . in itself , it is good to reach an agreement on procedures
, but we have to ensure that this system is not likely to be used as a
weapon policy . now they are also clear rights to be respected . i agree
with the signal warning against the return , which some are tempted to
the intergovernmental methods . there are many of us that we want a
federation of nation states .

frank keller

formal modeling in cognitive science

11

frank keller

formal modeling in cognitive science

12

id87
id181
cross-id178

channel capacity
properties of channel capacity
applications

example output: finnish{english

id87
id181
cross-id178

id181

the rapporteurs have drawn attention to the quality of the debate and
also the need to go further : of course , i can only agree with them . we
know very well that the current treaties are not enough and that in future
, it is necessary to develop a better structure for the union and , therefore
perustuslaillisempi structure , which also expressed more clearly what the
member states and the union is concerned . (cid:12)rst of all , kohtaamiemme
economic and social di(cid:14)culties , there is concern , even if growth is
sustainable and the result of the e(cid:11)orts of all , on the part of our citizens
. the current situation , which is unacceptable , in particular , for many
carriers and responsible for agriculture , is in any case , to be improved .
agreement on procedures in itself is a good thing , but there is a need to
ensure that the system cannot be used as a political lyomaaseena . they
also have a clear picture of the rights of now , in which they have to work
. i agree with him when he warned of the consenting to return to
intergovernmental methods . many of us want of a federal state of the
national member states .

de(cid:12)nition: id181

for two id203 distributions f (x) and g (x) for a random
variable x , the id181 or relative id178 is
given as:

d(f jjg ) = x

f (x) log

x 2x

f (x)
g (x)

the kl divergence compares the id178 of two distributions over
the same random variable.

intuitively, the kl divergence number of additional bits required
when encoding a random variable with a distribution f (x) using
the alternative distribution g (x).

frank keller

formal modeling in cognitive science

13

frank keller

formal modeling in cognitive science

14

id87
id181
cross-id178

id181

id87
id181
cross-id178

id181

theorem: properties of the id181

1 d(f jjg ) (cid:21) 0;

2 d(f jjg ) = 0 i(cid:11) f (x) = g (x) for all x 2 x ;

3 d(f jjg ) 6= d(g jjf );

4

i (x ; y ) = d(f (x ; y )jjf (x)f (y )).

so the mutual information is the kl divergence between f (x ; y )
and f (x)f (y ). it measures how far a distribution is from
independence.

example

for a random variable x = f0; 1g assume two distributions f (x)
and g (x) with f (0) = 1 (cid:0) r , f (1) = r and g (0) = 1 (cid:0) s, g (1) = s:

d(f jjg ) = (1 (cid:0) r ) log 1(cid:0)r
d(g jjf ) = (1 (cid:0) s) log 1(cid:0)s

1(cid:0)s + r log r
1(cid:0)r + s log s

s

r

if r = s then d(f jjg ) = d(g jjf ) = 0. if r = 1

2 and r = 1
4 :

d(f jjg ) = 1

2 log

d(g jjf ) = 3

4 log

1
2
3
4
3
4
1
2

+ 1

2 log

+ 1

4 log

1
2
1
4
1
4
1
2

= 0:2075

= 0:1887

frank keller

formal modeling in cognitive science

15

frank keller

formal modeling in cognitive science

16

id87
id181
cross-id178

cross-id178

id87
id181
cross-id178

cross-id178

de(cid:12)nition: cross-id178

for a random variable x with the id203 distribution f (x) the
cross-id178 for the id203 distribution g (x) is given as:

h(x ; g ) = (cid:0) x

f (x) log g (x)

x 2x

the cross-id178 can also be expressed in terms of id178 and
kl divergence:

h(x ; g ) = h(x ) + d(f jjg )

intuitively, the cross-id178 is the total number of bits required
when encoding a random variable with a distribution f (x) using
the alternative distribution g (x).

example
in the last lecture, we constructed a code for the following
distribution using hu(cid:11)man coding:

x

f (x)

(cid:0) log f (x)

a

0.12
3.06

e

0.42
1.25

i

0.09
3.47

o

0.30
1.74

u

0.07
3.84

the id178 of this distribution is h(x ) = 1:995. now compute
the distribution g (x) = 2(cid:0)l(x) associated with the hu(cid:11)man code:

x

c (x)
l(x)
g (x)

a

001
3
1
8

e
1
1
1
2

i

0001

4
1
16

o
01
2
1
4

u

0000

4
1
16

frank keller

formal modeling in cognitive science

17

frank keller

formal modeling in cognitive science

18

id87
id181
cross-id178

cross-id178

example

then the cross-id178 for g (x) is:

h(x ; g ) = (cid:0) px 2x f (x) log g (x)

= (cid:0)(0:12 log 1
+ 0:07 log 1

8 + 0:43 log 1
16 )

2 + 0:09 log 1

16 + 0:30 log 1

4

= 2:030

the kl divergence is:

d(f jjg ) = h(x ; g ) (cid:0) h(x ) = 0:035

this means we are losing on average 0.035 bits by using the
hu(cid:11)man code rather then the theoretically optimal code given by
the shannon information.

id87
id181
cross-id178

summary

the noisy channel can model the errors and loss when
transmitting a message with input x and output y ;

the capacity of the channel is given by the maximum of the
mutual information of x and y ;

a binary symmetric channel is one where each bit is (cid:13)ipped
with id203 p;

the id87 can be applied to linguistic problems,
e.g., machine translation;

the id181 is the distance between two
distributions (the cost of encoding f (x) through g (x)).

frank keller

formal modeling in cognitive science

19

frank keller

formal modeling in cognitive science

20

