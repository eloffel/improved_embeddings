id178 rate
mutual information

id178 rate
mutual information

formal modeling in cognitive science
lecture 26: id178 rate; mutual information

frank keller

school of informatics
university of edinburgh
keller@inf.ed.ac.uk

march 6, 2006

1 id178 rate

id178 rate
the id178 of english

2 mutual information

mutual information over distributions
pointwise mutual information

frank keller

formal modeling in cognitive science

1

frank keller

formal modeling in cognitive science

2

id178 rate
mutual information

id178 rate
the id178 of english

id178 rate
mutual information

id178 rate
the id178 of english

id178 rate

id178 rate

id178 rate takes the length of the message into account:

de(cid:12)nition: id178 rate
the id178 rate of a sequence of random variables x1; x2; : : : ; xn is
de(cid:12)ned as:

hrate =

1
n

h(x1; x2; : : : ; xn)

= (cid:0)

1
n x

x12x1

x
x22x2

(cid:1) (cid:1) (cid:1) x
xn 2xn

f (x1; x2; : : : ; xn) log f (x1; x2; : : : ; xn)

note that we have to extend our notion of joint distribution f (x ; y )
and joint id178 h(x ; y ) to arbitrarily many random variables.

id178 depends on the length of the message; longer
messages have higher id178 (all else being equal);

id178 rate takes this into account, it normalizes by n, the
length of the message;

intuitively, id178 rate is the id178 per character or per
word in a message.

example: simpli(cid:12)ed polynesian
in the previous example, we computed the joint id178 of a
consonant and a vowel. the per character id178 is:

hrate =

1
n

h(x1; x2; : : : ; xn) =

1
2

h(c ; v ) = 1:218 bits

frank keller

formal modeling in cognitive science

3

frank keller

formal modeling in cognitive science

4

id178 rate
mutual information

id178 rate
the id178 of english

id178 rate
mutual information

id178 rate
the id178 of english

shannon   s experiments

shannon   s experiments

guessing game: an experimental subject is given a sample of
english text and is asked to guess the next letter (shannon 1951).

assumption: subject will guess the most probably letter (cid:12)rst, then
the second most probable letter, etc.

this way we get a id203 distribution over the number of
guesses required to get the correct letter:

no. of guesses
id203

1
0.79

2
0.08

3
0.03

4
0.02

5
0.02

> 5
0.06

then we can then use this distribution to compute the id178
rate of english. the results show:

hrate(english) is between 0.6 and 1.3 bits per character if
estimated by humans;
if humans gamble on the outcome, hrate(english) is between
1.25 and 1.35 bpc;

if we estimated it from a 500m word corpus, then
hrate(english) 1.75 bpc.

modern estimates use word-guessing, not letter-guessing.

frank keller

formal modeling in cognitive science

5

frank keller

formal modeling in cognitive science

6

id178 rate
mutual information

mutual information over distributions
pointwise mutual information

id178 rate
mutual information

mutual information over distributions
pointwise mutual information

mutual information

mutual information

de(cid:12)nition: mutual information
if x and y are discrete random variables and f (x ; y ) is the value
of their joint id203 distribution at (x ; y ), and f (x) and f (y )
are the marginal distributions of x and y , respectively, then:

i (x ; y ) = x

x

f (x ; y ) log

x 2x

y 2y

f (x ; y )
f (x)f (y )

is the mutual information (mi) of x and y .

intuitively, mutual information is the reduction in uncertainty of x
due to the knowledge of y .

we can also express mutual information in terms of id178:

theorem: mutual information
if x and y are discrete random variables with joint id178
h(x ; y ) and the marginal id178 of x is h(x ), then:

i (x ; y ) = h(x ) (cid:0) h(x jy )

= h(y ) (cid:0) h(y jx )

= h(x ) + h(y ) (cid:0) h(x ; y )

this follows from the de(cid:12)nition of conditional id178 in terms of
joint id178.

frank keller

formal modeling in cognitive science

7

frank keller

formal modeling in cognitive science

8

id178 rate
mutual information

mutual information over distributions
pointwise mutual information

id178 rate
mutual information

mutual information over distributions
pointwise mutual information

mutual information

mutual information

the relationship between mutual information and id178 can be
visualized using a venn diagram:

h(x,y)

h(x|y)

i(x;y)

h(y|x)

h(x)

h(y)

properties of mutual information:

intuitively, i (x ; y ) is the amount of information x and y
contain about each other;

i (x ; y ) (cid:21) 0 and i (x ; y ) = i (y ; x );
i (x ; y ) is a measure of the dependence between x and y :

i (x ; y ) = 0 if and only if x and y are independent;
i (x ; y ) grows not only with the dependence of x and y , but
also with h(x ) and h(y );

i (x ; x ) = h(x ); id178 as \self-information" of x .

frank keller

formal modeling in cognitive science

9

frank keller

formal modeling in cognitive science

10

id178 rate
mutual information

mutual information over distributions
pointwise mutual information

id178 rate
mutual information

mutual information over distributions
pointwise mutual information

mutual information

mutual information

example: simpli(cid:12)ed polynesian
back to simpli(cid:12)ed polynesian, with the following joint id203
distribution:

f (x ; y )

a
i
u

f (x)

p
1
16
1
16
0
1
8

t
3
8
3
16
3
16
3
4

k
1
16
0
1
16
1
8

f (y )

1
2
1
4
1
4

let   s compute the mutual information of a consonant and a vowel:

i (v ; c ) = h(v ) (cid:0) h(v jc )

example: simpli(cid:12)ed polynesian
first compute the id178 of a vowel:

h(v ) = (cid:0) x

f (y ) log f (y )

y 2v
1
2

= (cid:0)(

log

1
2

+

1
4

log

1
4

+

1
4

log

1
4

)

= 1:5 bits

we have already computed h(v jc ) = 1:375 bits (last lecture), so
we can now compute:

i (v ; c ) = h(v ) (cid:0) h(v jc ) = 0:125 bits

frank keller

formal modeling in cognitive science

11

frank keller

formal modeling in cognitive science

12

id178 rate
mutual information

mutual information over distributions
pointwise mutual information

id178 rate
mutual information

mutual information over distributions
pointwise mutual information

pointwise mutual information

pointwise mutual information

mutual information is de(cid:12)ned over random variables.

pointwise mutual information is de(cid:12)ned over values of random
variables;

example: mi over vowels and consonants; pointwise mi over
the letters a and p;

intuitively, pointwise mi is the amount of information provided
by the occurrence of event y about the occurrence of event x.

de(cid:12)nition: pointwise mutual information
if x and y are discrete random variables with the joint distribution
f (x ; y ) and the marginal distributions f (x) and f (y ), then:

i (x; y ) = log

f (x ; y )
f (x)f (y )

is the pointwise mutual information at (x ; y ).

frank keller

formal modeling in cognitive science

13

frank keller

formal modeling in cognitive science

14

id178 rate
mutual information

mutual information over distributions
pointwise mutual information

id178 rate
mutual information

mutual information over distributions
pointwise mutual information

pointwise mutual information

summary

example: simpli(cid:12)ed polynesian
compute the pointwise mutual information of a and p and of
i and p:

i (a; p) = log

i (i; p) = log

f (a; p)
f (a)f (p)

= log

f (i ; p)
f (i)f (p)

= log

1
16

1

8 (cid:1) 1

2

1
16

1

8 (cid:1) 1

4

= 0

= 1

id178 rate is the per-word or per-character id178;

the id178 rate of english can be estimated using
experiments with humans or approximated using a large
corpus;

mutual information i (x ; y ) is the reduction in uncertainty of
x due to the knowledge of y ;

graphically, it   s the intersection of two entropies;

if x and y are independent, then i (x ; y ) = 0;

pointwise mutual information: same for points of a
distributions, instead of for the whole distribution.

frank keller

formal modeling in cognitive science

15

frank keller

formal modeling in cognitive science

16

id178 rate
mutual information

mutual information over distributions
pointwise mutual information

references

shannon, claude e. 1951. prediction and id178 of printed english. bell systems

technical journal 30:50{64.

frank keller

formal modeling in cognitive science

17

