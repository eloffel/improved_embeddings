coding theorems
hu(cid:11)man coding

coding theorems
hu(cid:11)man coding

formal modeling in cognitive science

lecture 28: kraft inequality; source coding theorem;

hu(cid:11)man coding

frank keller

school of informatics
university of edinburgh
keller@inf.ed.ac.uk

march 13, 2006

1 coding theorems
kraft inequality
shannon information
source coding theorem

2 hu(cid:11)man coding

frank keller

formal modeling in cognitive science

1

frank keller

formal modeling in cognitive science

2

coding theorems
hu(cid:11)man coding

kraft inequality
shannon information
source coding theorem

coding theorems
hu(cid:11)man coding

kraft inequality
shannon information
source coding theorem

kraft inequality

kraft inequality

problem: construct an instantaneous code of minimum expected
length for a given random variable. the following inequality holds:

theorem: kraft inequality
for an instantaneous code c for a random variable x , the code
word lengths l(x) must satisfy the inequality:

2(cid:0)l(x) (cid:20) 1

x

x 2x

conversely, if the code word lengths satisfy this inequality, then
there exists an instantaneous code with these word lengths.

we can illustrate the kraft inequality using a coding tree. start
with a tree that contains all three-bit codes:

(cid:8)

(cid:8)

h

h

(cid:8)

(cid:8)

h

h

h

h

1

(cid:8)

(cid:8)

0

(cid:8)

(cid:8)

h

h

h

01

(cid:8)

00

(cid:8)

(cid:8)

h

h

h

11

(cid:8)

10

(cid:8)(cid:8) hh

(cid:8)(cid:8) hh

(cid:8)(cid:8) hh

(cid:8)(cid:8) hh

000

001

010

011

100

101

110

111

frank keller

formal modeling in cognitive science

3

frank keller

formal modeling in cognitive science

4

coding theorems
hu(cid:11)man coding

kraft inequality
shannon information
source coding theorem

coding theorems
hu(cid:11)man coding

kraft inequality
shannon information
source coding theorem

kraft inequality

kraft inequality

for each code word, prune all the branches below it (as they
violate the pre(cid:12)x condition). for example, if we decide to use the
code word 0, we get the following tree:

(cid:8)

(cid:8)

0

(cid:8)(cid:8)

hh

h

h

1

(cid:8)

(cid:8)

h

h

h

11

(cid:8)

10

(cid:8)(cid:8) hh

(cid:8)(cid:8) hh

100

101

110

111

now if we decide to use the code word 10:

(cid:8)(cid:8)

hh

h

1

(cid:8)

0

(cid:8)

(cid:8)

h

h

10

11

(cid:8)(cid:8) hh

110

111

the remaining leaves constitute a pre(cid:12)x code. kraft inequality:

2(cid:0)l(x) = 2(cid:0)1 + 2(cid:0)2 + 2(cid:0)3 + 2(cid:0)3 =

x

x 2x

1
2

+

1
4

+

1
8

+

1
8

= 1

frank keller

formal modeling in cognitive science

5

frank keller

formal modeling in cognitive science

6

coding theorems
hu(cid:11)man coding

kraft inequality
shannon information
source coding theorem

coding theorems
hu(cid:11)man coding

kraft inequality
shannon information
source coding theorem

shannon information

shannon information

the kraft inequality tells us that an instantaneous code exists. but
we are interested in (cid:12)nding the optimal code, i.e., one that
minimized the expected code length l(c ).

theorem: shannon information
the expected length l(c ) of a code c for the random variable x
with distribution f (x) is minimal if the code word lengths l(x) are
given by:

l(x) = (cid:0) log f (x)

this quantity is called the shannon information.

shannon information is pointwise id178. (see mutual information
and pointwise mutual information.)

example
consider the following random variable with the optimal code
lengths given by the shannon information:

x

f (x)
l(x)

a
1
2
1

b
1
4
2

c
1
8
3

d
1
8
3

the expected code length l(c ) for the optimal code is:

l(c ) = x

f (x)l(x) = (cid:0) x

f (x) log f (x) = 1:75

x 2x

x 2x

note that this is the same as the id178 of x , h(x ).

frank keller

formal modeling in cognitive science

7

frank keller

formal modeling in cognitive science

8

coding theorems
hu(cid:11)man coding

kraft inequality
shannon information
source coding theorem

coding theorems
hu(cid:11)man coding

kraft inequality
shannon information
source coding theorem

lower bound on expected length

upper bound on expected length

this observation about the relation between the id178 and the
expected length of the optimal code can be generalized:

theorem: lower bound on expected length
let c be an instantaneous code for the random variable x . then
the expected code length l(c ) is bounded by:

l(c ) (cid:21) h(x )

of course we are more interested in (cid:12)nding an upper bound, i.e., a
code that has a maximum expected length:

theorem: source coding theorem

let c a code with optimal code lengths, i.e, l(x) = (cid:0) log f (x) for
the random variable x with distribution f (x). then the expected
length l(c ) is bounded by:

h(x ) (cid:20) l(c ) < h(x ) + 1

why is the upper bound h(x ) + 1 and not h(x )? because
sometimes the shannon information gives us fractional lengths; we
have to round up.

frank keller

formal modeling in cognitive science

9

frank keller

formal modeling in cognitive science

10

coding theorems
hu(cid:11)man coding

kraft inequality
shannon information
source coding theorem

coding theorems
hu(cid:11)man coding

kraft inequality
shannon information
source coding theorem

source coding theorem

source coding theorem

example
consider the following random variable with the optimal code
lengths given by the shannon information:

x

f (x)
l(x)

a

0.25
2.0

b

0.25
2.0

c
0.2
2.3

d

0.15
2.7

e

0.15
2.7

the id178 of this random variable is h(x ) = 2:2855. the source
coding theorem tells us:

2:2855 (cid:20) l(c ) < 3:2855

where l(c ) is the code length of the optimal code.

example
now consider the following code that tries to the code words on
the optimal code lengths as closely as possible:

x

c (x)
l(x)

a
00
2

b
10
2

c
11
2

d
010
3

e

011
3

the expected code length for this code is therefore l(c ) = 2:30.
this is very close to the optimal code length of h(x ) = 2:2855.

frank keller

formal modeling in cognitive science

11

frank keller

formal modeling in cognitive science

12

coding theorems
hu(cid:11)man coding

hu(cid:11)man coding

coding theorems
hu(cid:11)man coding

hu(cid:11)man coding

the source coding theorem tells us the properties of the optimal
code, but not how to (cid:12)nd it. a number of algorithms exists for this.

here, we consider hu(cid:11)man coding , an algorithm that constructs a
code with the following properties:

instantaneous (pre(cid:12)x code);

optimal (shortest expected length code).

the expected code length of the hu(cid:11)man code is bounded by
h(x ) + 1.

1 find the two symbols with the smallest id203 and

combine them into a new symbol and add their probabilities.

2 repeat step (2) until there is only one symbol left with a

id203 of 1.

3 draw all the symbols in the form of a tree which branches

every time two symbols are combined.

4 label all the left branches of the tree with a 0 and all the

right branches with a 1.

5 the code for a symbol is the sequence of 0s and 1s that lead
to it on the tree, starting from the root (with id203 1).

frank keller

formal modeling in cognitive science

13

frank keller

formal modeling in cognitive science

14

coding theorems
hu(cid:11)man coding

hu(cid:11)man coding

example
assume we want to encode the set of all vowels, and we have the
following id203 distribution:

x

f (x)

(cid:0) log f (x)

a

0.12
3.06

e

0.42
1.25

i

0.09
3.47

o

0.30
1.74

u

0.07
3.84

the hu(cid:11)man code for this distribution is:

x

c (x)
l(x)

a

001
3

e
1
1

i

0001

4

o
01
2

u

0000

4

generate this code by drawing the hu(cid:11)man coding tree.

coding theorems
hu(cid:11)man coding

hu(cid:11)man coding

example

u

0.07
0

1

i

0.09

ui 0.16

a 0.12

0

1

uia

0.28

o

0.30

0

1

uiao

0.58
0

1

e

0.42

uiaoe

1.0

frank keller

formal modeling in cognitive science

15

frank keller

formal modeling in cognitive science

16

coding theorems
hu(cid:11)man coding

summary

the optimal length of a code word is given by its shannon
information: (cid:0) log f (x);

source coding theorem: the expected length of the optimal
code is bounded by id178: h(x ) (cid:20) l(c ) < h(x ) + 1.

hu(cid:11)man coding is an algorithm for (cid:12)nding an optimal
instantaneous code for a given random variable.

frank keller

formal modeling in cognitive science

17

