algorithms for natural language processing

lexical semantics:

word senses, relations, and classes

(based on slides by philipp koehn and sharon goldwater)

nathan schneider

7 february 2018

nathan schneider

enlp (cosc/ling-272) lecture 8

7 february 2018

a concrete goal

    we would like to build

    a machine that answers questions in natural language.
    may have access to knowledge bases
    may have access to vast quantities of english text

    basically, a smarter google
    this is typically called id53

nathan schneider

enlp (cosc/ling-272) lecture 8

1

semantics

    to build our qa system we will need to deal with issues in semantics, i.e.,

meaning.

    lexical semantics: the meanings of individual words (next few lectures)
    sentential semantics: how word meanings combine (after that)
    consider some examples to highlight problems in lexical semantics

nathan schneider

enlp (cosc/ling-272) lecture 8

2

example question

    question

when was barack obama born?

    text available to the machine

barack obama was born on august 4, 1961

    this is easy.

    just phrase a google query properly:
"barack obama was born on *"

    syntactic rules that convert questions into statements are straight-forward

nathan schneider

enlp (cosc/ling-272) lecture 8

3

example question (2)

    question

what plants are native to scotland?

    text available to the machine

a new chemical plant was opened in scotland.

    what is hard?

    words may have di   erent meanings (senses)
    we need to be able to disambiguate between them

nathan schneider

enlp (cosc/ling-272) lecture 8

4

example question (3)

    question

where did david cameron go on vacation?

    text available to the machine

david cameron spent his holiday in cornwall

    what is hard?

    words may have the same meaning (synonyms)
    we need to be able to match them

nathan schneider

enlp (cosc/ling-272) lecture 8

5

example question (4)

    question

which animals love to swim?

    text available to the machine

polar bears love to swim in the freezing waters of the arctic.

    what is hard?

    words can refer to a subset (hyponym) or superset (hypernym) of the

concept referred to by another word

    we need to have database of such a is-a b relationships, called an ontology

nathan schneider

enlp (cosc/ling-272) lecture 8

6

example question (5)

    question

what is a good way to remove wine stains?

    text available to the machine

salt is a great way to eliminate wine stains

    what is hard?

    words may be related in other ways, including similarity and gradation
    we need to be able to recognize these to give appropriate responses

nathan schneider

enlp (cosc/ling-272) lecture 8

7

example question (6)

    question

did poland reduce its carbon emissions since 1989?

    text available to the machine

due to the collapse of the industrial sector after the end of communism
in 1989, all countries in central europe saw a fall in carbon emissions.

poland is a country in central europe.

    what is hard?

    we need to do id136
    a problem for sentential, not lexical, semantics

nathan schneider

enlp (cosc/ling-272) lecture 8

8

id138

    some of these problems can be solved with a good ontology, e.g., id138
    id138 (english) is a hand-built resource containing 117,000 synsets: sets

of synonymous words (see http://id138.princeton.edu/)

    synsets are connected by relations such as

    hyponym/hypernym (is-a: chair-furniture)
    meronym (part-whole: leg-chair)
    antonym (opposites: good-bad)

    globalid138.org now lists id138s in over 50 languages (but variable

size/quality/licensing)

nathan schneider

enlp (cosc/ling-272) lecture 8

9

word sense ambiguity

    not all problems can be solved by id138 alone.
    two completely di   erent words can be spelled the same (homonyms):

i put my money in the bank.
you can do it!

vs. he rested at the bank of the river.
vs.

she bought a can of soda.

    more generally, words can have multiple (related or unrelated) senses

(polysemes)

    polysemous words often fall into (semi-)predictable patterns: see next slides

(from hugh rabagliati in ppls).

nathan schneider

enlp (cosc/ling-272) lecture 8

10

28 29 30 how many senses?

    5 min. exercise: how many senses does the word interest have?

nathan schneider

enlp (cosc/ling-272) lecture 8

14

how many senses?

nathan schneider

enlp (cosc/ling-272) lecture 8

15

how many senses?

    how many senses does the word interest have?

    she pays 3% interest on the loan.
    he showed a lot of interest in the painting.
    microsoft purchased a controlling interest in google.
    it is in the national interest to invade the bahamas.
    i only have your best interest in mind.
    playing chess is one of my interests.
    business interests lobbied for the legislation.

    are these seven di   erent senses? four? three?
    also note: distinction between polysemy and homonymy not always clear!

nathan schneider

enlp (cosc/ling-272) lecture 8

16

id69 requires data

nathan schneider

enlp (cosc/ling-272) lecture 8

17

lumping vs. splitting

    for any given word, lexicographer faces the choice:
    lump usages into a small number of senses? or
    split senses to re   ect    ne-grained distinctions?

nathan schneider

enlp (cosc/ling-272) lecture 8

18

id138 senses for interest

synonym: involvement

or exciting etc.), synonym: interestingness

    s1: a sense of concern with and curiosity about someone or something,
    s2: the power of attracting or holding one   s interest (because it is unusual
    s3: a reason for wanting something done, synonym: sake
    s4: a    xed charge for borrowing money; usually a percentage of the amount
    s5: a diversion that occupies one   s time and thoughts (usually pleasantly),
    s6:
a right or legal share of something; a    nancial involvement with
    s7: (usually plural) a social group whose members control some    eld of

synonyms: pastime, pursuit

something, synonym: stake

borrowed

activity and who have common aims, synonym: interest group

nathan schneider

enlp (cosc/ling-272) lecture 8

19

synsets and relations in id138

    synsets (   synonym sets   , e   ectively senses) are the basic unit of organization

in id138.

    each synset is speci   c to nouns (.n), verbs (.v), adjectives (.a, .s), or

    synonymous words belong to the same synset:

adverbs (.r).
{car,auto,automobile}.
{car,elevator car}. numbered roughly in descending order of frequency.
    synsets are organized into a network by several kinds of relations, including:

    polysemous words belong to multiple

car1 (car.n.01) =

car1 vs.

car4 =

synsets:

    hypernymy (is-a): hyponym {ambulance} is a kind of hypernym car1
    meronymy (part-whole): meronym {air bag} is a part of holonym car1

nathan schneider

enlp (cosc/ling-272) lecture 8

20

visualizing id138

nathan schneider

enlp (cosc/ling-272) lecture 8

21

using id138

    nltk provides an excellent api for looking things up in id138:

>>> from nltk . corpus import id138 as wn
>>> wn . synsets ( ' car ' )
[ synset ( ' car . n .01 ' ) , synset ( ' car . n .02 ' ) ,
(cid:44)    synset ( ' car . n .03 ' ) ,
synset ( ' car . n .04 ' ) , synset ( ' c a b l e _ c a r . n .01 ' ) ]
>>> wn . synset ( ' car . n .01 ' ) . d e f i n i t i o n ()
u ' a motor vehicle with four wheels ; usually
(cid:44)    p r o p e l l e d by an
i n t e r n a l c o m b u s t i o n engine '
>>> wn . synset ( ' car . n .01 ' ) . h y p e r n y m s ()
[ synset ( ' m o t o r _ v e h i c l e . n .01 ' ) ]

    (id138 uses an obscure custom    le format, so reading the    les directly is not recommended!)

nathan schneider

enlp (cosc/ling-272) lecture 8

22

polysemy and coverage in id138

    online stats:

    155k unique strings, 118k unique synsets, 207k pairs
    nouns have an average 1.24 senses (2.79 if exluding monosemous words)
    verbs have an average 2.17 senses (3.57 if exluding monosemous words)

    too    ne-grained?
    id138 is a snapshot of the english lexicon, but by no means complete.

    e.g.,

consider multiword expressions

(including noncompositional
idioms): hot dog, take place, carry out, kick the bucket

expressions,
are in id138, but not take a break, stress out, pay attention

    neologisms: hoodie, facepalm
    names: microsoft

nathan schneider

enlp (cosc/ling-272) lecture 8

23

di   erent sense = di   erent translation

    another way to de   ne senses:

if occurrences of the word have di   erent

translations, these indicate di   erent sense
    example interest translated into german

    zins:    nancial charge paid for load (id138 sense 4)
    anteil: stake in a company (id138 sense 6)
    interesse: all other senses

    other examples might have distinct words in english but a polysemous word

in german.

nathan schneider

enlp (cosc/ling-272) lecture 8

24

semcor in nltk

in the semcor corpus, words and multiword units are annotated with their part
of speech:
>>> semcor . t a g g e d _ s e n t s () [0]
[ tree ( ' dt ' , [ ' the ' ]) ,
tree ( ' nnp ' , [ ' fulton ' , ' county ' , ' grand ' , ' jury ' ]) ,
tree ( ' vb ' , [ ' said ' ]) ,
tree ( ' nn ' , [ ' friday ' ]) ,
tree ( ' dt ' , [ ' an ' ]) ,
tree ( ' nn ' , [ ' i n v e s t i g a t i o n ' ]) ,
tree ( ' in ' , [ ' of ' ]) ,
tree ( ' nn ' , [ ' atlanta ' ]) , ...]
each sentence consists of a series of chunks with 1 or more words.

in the tagset used in semcor, dt = determiner, nn = common noun, nnp =
proper noun, vb = verb, etc.

nathan schneider

enlp (cosc/ling-272) lecture 8

25

semcor in nltk

in addition, nouns, verbs, adjectives, and adverbs are annotated with a id138
synset:
>>> semcor . t a g g e d _ s e n t s ( tag = ' sem ' ) [0]
[[ ' the ' ] ,
tree ( lemma ( ' group . n .01. group ' ) , [ tree ( ' ne ' ,
(cid:44)    [ ' fulton ' , ' county ' , ' grand ' , ' jury ' ]) ]) ,
tree ( lemma ( ' state . v .01. say ' ) , [ ' said ' ]) ,
tree ( lemma ( ' friday . n .01. friday ' ) , [ ' friday ' ]) ,
[ ' an ' ] ,
tree ( lemma ( ' probe . n .01. i n v e s t i g a t i o n ' ) ,
(cid:44)    [ ' i n v e s t i g a t i o n ' ]) ,

[ ' of ' ] ,
tree ( lemma ( ' atlanta . n .01. atlanta ' ) , [ ' atlanta ' ]) ,
note that fulton county grand jury is a named entity (ne) not in id138,
so it receives a high-level synset group.n.01.

nathan schneider

enlp (cosc/ling-272) lecture 8

26

id51 (wsd)

    for many applications, we would like to disambiguate senses

    we may be only interested in one sense
    searching for chemical plant on the web, we do not want to know about

chemicals in bananas

    task: given a polysemous word,    nd the sense in a given context
    popular topic, data driven methods perform well

nathan schneider

enlp (cosc/ling-272) lecture 8

27

wsd as classi   cation

    given a word token in context, which sense (class) does it belong to?
    we can train a supervised classi   er, assuming sense-labeled training data:

    she pays 3% interest/interest-money on the loan.
    he showed a lot of interest/interest-curiosity in the painting.
    playing chess is one of my interests/interest-hobby.

    senseval and later semeval competitions provide such data

    held every 1-3 years since 1998
    provide annotated corpora in many languages for wsd and other semantic

tasks

nathan schneider

enlp (cosc/ling-272) lecture 8

28

semantic classes

    other approaches, such as id39 and supersense
tagging, de   ne coarse-grained semantic categories like person, location,
artifact.

    like senses, can disambiguate: apple as organization vs. food.
    unlike senses, which are re   nements of particular words, classes are typically

larger groupings.

    unlike senses, classes can be applied to words/names not listed in a lexicon.

nathan schneider

enlp (cosc/ling-272) lecture 8

29

id39

    recognizing and classifying proper names in text is important for many

applications. a kind of information extraction.

    di   erent datasets/named entity recognizers use di   erent inventories of classes.

    smaller: person, organization, location, miscellaneous
    larger: sometimes also product, work of art, historical event,

etc., as well as numeric value types (time, money, etc.)

    ner systems typically use some form of feature-based sequence tagging, with

features like capitalization being important.

    lists of known names called gazetteers are also important.

nathan schneider

enlp (cosc/ling-272) lecture 8

30

supersenses

    as a practical measure, id138 noun and verb synset entries were divided

into multiple    les (   lexicographer    les   ) on a semantic basis.

    later, people realized these provided a nice inventory of high-level semantic

classes, and called them supersenses.

    supersenses o   er an alternative, broad-coverage, language-neutral approach to

corpus annotation.

nathan schneider

enlp (cosc/ling-272) lecture 8

31

supersenses

v:cognition
v:communication

n:object
n:tops
n:person
n:act
n:phenomenon v:competition
n:animal
v:consumption
n:plant
n:artifact
n:possession
v:contact
n:attribute
v:creation
n:process
n:body
v:emotion
n:cognition
n:quantity
n:communication n:relation
v:motion
v:perception
n:event
n:feeling
v:possession
v:social
n:food
n:group
v:stative
n:location
v:weather
n:motive

n:shape
n:state
n:substance
n:time
v:body
v:change

    the supersense tagging goes beyond ner to cover all nouns and verbs.

nathan schneider

enlp (cosc/ling-272) lecture 8

32

summary (1)

    in order to support technologies like id53, we need ways to reason
computationally about meaning. lexical semantics addresses meaning at
the word level.

    words can be ambiguous (polysemy), sometimes with related meanings,

and other times with unrelated meanings (homonymy).
    di   erent words can mean the same thing (synonymy).

    computational lexical databases, notably id138, organize words in terms of

their meanings.

    synsets and relations between them such as hypernymy and meronymy.

nathan schneider

enlp (cosc/ling-272) lecture 8

33

summary (2)

    id51 is the task of choosing the right sense for the

context.

    classi   cation with contextual features
    relying on dictionary senses has limitations in granularity and coverage

    semantic classes, as in ner and supersense tagging, are a coarser-grained

representation for semantic disambiguation and generalization.

nathan schneider

enlp (cosc/ling-272) lecture 8

34

