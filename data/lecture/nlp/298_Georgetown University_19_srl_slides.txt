a note about nlp tools

    nltk is primarily a teaching tool   its built-in taggers, 

parsers, etc. are not especially accurate. 

    open source software suites you may want to use for your 

projects: 
    stanford corenlp (java) 
    spacy (python) 
    both support id121, ner, id52, parsing in 

english and a few other languages. stanford also 
supports coreference resolution, id31.

1

lecture 19 

id14 
and argument structure

nathan schneider   
enlp | 11 april 2018

   
language is    exible.

i   m thrilled to visit sunny california. 
i   m thrilled to visit california, where the weather is sunny. 
i   m thrilled to visit california, where it   s sunny. 
i   m excited to visit california, where it   s sunny. 
i   m excited to visit california, where it   s sunny out. 
i   m excited to spend time in california, where it   s sunny out.
i   m not excited to visit sunny california. 
i   m thrilled to visit sunny florida. 
i   m thrilled to visit sunny mountain view. 
i   m thrilled to visit california because it   s sunny. 
i   m sort of happy about the california visit.

                                                 .

.                                                               

3

lexical semantics

    so far, we   ve seen approaches that concern the choice of 

individual words: 
    sense disambiguation 

    semantic relations in a lexicon or similarity space 

    today: words that are fully understood by    plugging in    

information from elsewhere in the sentence. 
    speci   cally, understanding words that are (semantic) 

predicates, in relation to their arguments. 

    especially verbs. 
    who did what to whom?

4

argument structure 

alternations

    mary opened the door.   

the door opened. 

    john slices the bread with a knife.   

the bread slices easily.   
the knife slices easily. 

    mary loaded the truck with hay.   
mary loaded hay onto the truck.   
the truck was loaded with hay (by mary).   
hay was loaded onto the truck (by mary). 

    john got mary a present.   

john got a present for mary.   
mary got a present from john.

5

stanford dependencies
    mary loaded the truck with hay.   

nsubj

dobj

prep_with

    hay was loaded onto the truck by mary.   

nsubj_pass

prep_onto

prep_by   

syntax is not enough!

6

   
   
   
   
   
syntax-semantics 

relationship

7

outline

    syntax     semantics 

    the semantic roles played by different participants in the 
sentence are not trivially inferable from syntactic relations 

       though there are patterns! 

    two computational datasets/approaches that describe sentences in 

terms of semantic roles: 
    propbank     simpler, more data 
    framenet      richer, less data 

    the idea of semantic roles can be combined with other aspects of 

meaning. glimpse of amr, which is one way to do this.

8

propbank

    abstracts away from syntax to predicate-argument structures 

    predicate-argument lexicon + annotations of full wsj ptb 

corpus and other data (such as ontonotes) 

    originally verbs only (kingsbury & palmer 2002); now has many 

nouns, adjectives, light verb constructions, etc. (bonial et al. 
2014) 

    strongly lexicalized: no synonymy, hypernymy, etc. of 

predicates with different stems; very coarse-grained sense 
distinctions 

    phrase structure constituents of ptb(-style) trees

9

propbank

mary loaded the truck with hay at the depot on friday.
    load: load.01    cause to be burdened      

roles:   
  arg0-pag: loader, agent   
  arg1-gol: beast of burden   
  arg2-ppt: cargo   
  arg3-mnr: instrument 

    load_up: load.02    phrasal cause to be burdened    

    load: load.03       x, set up to cheat   

10

propbank

mary loaded the truck with hay at the depot on friday.

11

propbank

mary loaded the truck with hay at the depot on friday.

load.01
a0 loader   
a1 bearer   
a2 cargo   
a3 instrument

am-loc   
am-tmp   
am-prp   
am-mnr   

   

12

propbank

mary loaded the truck with hay at the depot on friday.

load.01
a0 loader   
a1 bearer   
a2 cargo   
a3 instrument

am-loc   
am-tmp   
am-prp   
am-mnr   

   

13

propbank

mary loaded the truck with hay at the depot on friday.

load.01
a0 loader   
a1 bearer   
a2 cargo   
a3 instrument

am-loc   
am-tmp   
am-prp   
am-mnr   

   

14

propbank

mary loaded the truck with hay at the depot on friday.

load.01
a0 loader   
a1 bearer   
a2 cargo   
a3 instrument

am-loc   
am-tmp   
am-prp   
am-mnr   

   

15

propbank

mary loaded the truck with hay at the depot on friday.

load.01
a0 loader   
a1 bearer   
a2 cargo   
a3 instrument

am-loc   
am-tmp   
am-prp   
am-mnr   

   

16

propbank

mary loaded the truck with hay at the depot on friday.

mary loaded hay onto the truck at the depot on friday.

17

propbank

mary loaded the truck with hay at the depot on friday.
load.01
am-loc   
a0 loader   
am-tmp   
a1 bearer   
am-prp   
a2 cargo   
am-mnr   
a3 instrument

   

mary loaded hay onto the truck at the depot on friday.

18

propbank

mary loaded the truck with hay at the depot on friday.
load.01
am-loc   
a0 loader   
am-tmp   
a1 bearer   
am-prp   
a2 cargo   
am-mnr   
a3 instrument

   

mary loaded hay onto the truck at the depot on friday.

19

propbank

mary loaded the truck with hay at the depot on friday.
mary loaded hay onto the truck at the depot on friday.
load.01
am-loc   
a0 loader   
am-tmp   
a1 bearer   
am-prp   
a2 cargo   
am-mnr   
a3 instrument

can be expressed in logic: e.g. 

   

load(mary, the truck, hay) 

neo-davidsonian: 

   e: load(e)    a0(e, mary)    a1(e, the truck)    a2(e, hay) 

    loc(e, the depot)    tmp(e, friday)

20

propbank

    abstracts away from syntax to predicate-argument structures 

    predicate-argument lexicon + annotations of full wsj ptb 

corpus and other data (such as ontonotes) 

    originally verbs only (kingsbury & palmer 2002); now has many 

nouns, adjectives, light verb constructions, etc. (bonial et al. 
2014) 

    strongly lexicalized: no synonymy, hypernymy, etc. of 
predicates with different stems; very coarse-grained    
sense distinctions 

    phrase structure constituents of ptb(-style) trees

21

   propbank

argument structure 

alternations

    mary opened the door.   

the door opened. 

    john slices the bread with a knife.   

the bread slices easily.   
the knife slices easily. 

    mary loaded the truck with hay.   
mary loaded hay onto the truck.   
the truck was loaded with hay (by mary).   
hay was loaded onto the truck (by mary). 

    john got mary a present.   

john got a present for mary.   
mary got a present from john.

22

id14

    traditional pipeline: 

1. (assume syntactic parse and predicate senses as 

given) 

2. argument identi   cation: select the predicate   s 

argument phrases 

3. argument classi   cation: select a role for each 
argument 
useful feature: predicate    * argument path in tree

    see palmer et al. 2010 for a review

23

limitation of propbank

    numbered roles (arg0, arg1, etc.) are predicate-

speci   c. 

    load.arg1: beast of burden, whereas 

    put.arg1: thing put 

    load.arg1 corresponds to put.arg2

24

thematic roles

    linguists talk about general classes of semantic roles: 

    agent = animate entity who is volitionally acting 
    theme = participant that is undergoing motion, for example 
    patient = participant that undergoes some internal change of 
    destination = intended endpoint of motion 
    recipient = party to which something is transferred 

state (e.g., breaking) 

    the verbnet resource uses these and a couple dozen other roles. 
    but it is hard to come up with a small list of these roles that will 

suf   ce for all verbs. 

    and there are correspondences that these roles do not expose: 
e.g., that someone who buys is on the receiving end of selling.

25

berkeley framenet 

https://framenet.icsi.berkeley.edu/

26

paraphrase

    james snapped a photo of me with sheila.   

    sheila and i had our picture taken by james.

27

   
   
   
   
   
what   s in common

    james snapped a photo of me with sheila.   

    sheila and i had our picture taken by james.

28

   
   
   
   
   
what   s in common

    james snapped a photo of me with sheila.   

    sheila and i had our picture taken by james.

29

   
   
   
   
   
idealized stanford 

dependencies

    james snapped a photo of me with sheila.   

nsubj(snap, james)   
dobj(snap, photo)   
prep_of(photo, me)   
prep_with(me, sheila)   
det(photo, a) 

    sheila and i had our picture taken by james.   

nsubjpass(taken, sheila)   
nsubjpass(taken, i)   
conj_and(sheila, i)   
aux(taken, had)   
dobj(taken, picture)   
poss(picture, our)   
agent(taken, james)

30

   
   
frame semantics

   meanings are relativized 

to scenes      
(fillmore 1977)

31

   
frame semantics

http://www.swisslark.com/2012/08/jana-manja-photography-special-offer_29.html

32

captured_image 

frame semantics

1. photographer identi   es subject to be depicted in a 
2. photographer puts the subject in view of the camera 
3. photographer operates the camera to create the 

captured_image

subject

photographer

camera

captured_image

33

captured_image 

1. photographer identi   es subject to be depicted in a 
2. photographer puts the subject in view of the camera 
3. photographer operates the camera to create the 

captured_image

time

duration
frequency

photographer

subject
camera

captured_image

manner
location
reason

photograph.v

take ((picture)).v

snap picture.v

34

frame name

textual de   nition explaining the scene and how 

the frame elements relate to one another

core
frame
elements

non-core

fes

predicate1.v

predicate2.n

predicate3.a

35

36

event

create_representation

intentionally_act

intentionally_create

uses

create_physical_artwork

uses

physical_artworks

framenet

37

framenet: lexicon

    ~1000 frames represent scenarios. most are 

associated with lexical units (a.k.a. predicates). 
berkeley framenet currently has 13k lus (5k nouns, 5k 
verbs, 2k adjectives). 

    frame elements (a.k.a. roles) represent participants/
components of those scenarios. core vs. non-core. 

    frames and their corresponding roles are linked 

together in the lexicon. 

    frames are explained with textual descriptions.

38

framenet annotations

    sheila and i had our picture taken by james.

physical_artworks 

creator
artifact
represented

   

   picture   

   our   

create_physical_artwork 
   james   

creator
representation

   our picture   

uses

41

languages with framenets

42

srl demos

    mateplus/framat (propbank, framenet):   

http://www.coli.uni-saarland.de/~mroth/demo.html 

    semafor (framenet):    

http://demo.ark.cs.cmu.edu/parse 

    allennlp (propbank): http://demo.allennlp.org/

43

advanced 

topic

abstract meaning 
representation

(banarescu et al., law 2013)

a graph-based representation of lexical concepts and typed relations 
between those concepts that are denoted by an english sentence. 

amr integrates several aspects of lexical/relational meaning   

abstracting away from the grammatical details   in a single structure 
designed to support rapid corpus annotation and data-driven nlp.

amrs

l

instance

like-01

:arg0

:arg1

r

instance

duck

rain-01

d
instance

(l / like-01   
  :arg0 (d / duck)   
  :arg1 (r / rain-01)) 
    ducks like rain 
    the duck liked that it was raining

45

(l / like-01   
  :arg0 (d / duck)   
  :arg1 (r / rain-01)) 

amrs

(s2 / see-01   
   :arg0 (i / i)   
   :arg1 (d / duck   
            :poss (s / she))) 
    i saw her duck

46

(l / like-01   
  :arg0 (d / duck)   
  :arg1 (r / rain-01)) 

amrs

(s2 / see-01   
   :arg0 (i / i)   
   :arg1 (d / duck   
            :poss (s / she))) 

(s2 / see-01   
   :arg0 (i / i)   
   :arg1 (d / duck-01   
            :arg0 (s / she))) 
    i saw her duck [alternate interpretation]

47

(l / like-01   
  :arg0 (d / duck)   
  :arg1 (r / rain-01)) 

amrs

(s2 / see-01   
   :arg0 (i / i)   
   :arg1 (d / duck   
            :poss (s / she))) 

:arg0

(s2 / see-01   
   :arg0 (s / she)   
   :arg1 (d / duck   
            :poss s)) 
    she saw her (own) duck

s
instance

s2

instance

see-01

:arg1

:poss

d

instance

she

duck

48

(l / like-01   
  :arg0 (d / duck)   
  :arg1 (r / rain-01)) 

amrs

(s2 / see-01   
   :arg0 (i / i)   
   :arg1 (d / duck   
            :poss (s / she))) 

s2

instance

:arg1

:arg0

(s2 / see-01   
   :arg0 (s / she)   
s
   :arg1 (d / duck   
instance
            :poss (s3 / she))) 
    she saw her (someone else   s) duck

:poss
s3
instance

she

d

instance

duck

see-01

49

(l / like-01   
  :arg0 (d / duck)   
  :arg1 (r / rain-01)) 

amrs

(h / happy   
   :domain (d / duck   
              :arg0-of (l / like-01   
                          :arg1 (r / rain-01)))) 
    ducks who like rain are happy

50

(l / like-01   
  :arg0 (d / duck)   
  :arg1 (r / rain-01)) 

amrs

(h / happy   
   :domain (d / duck   
              :arg0-of (l / like-01   
                          :arg1 (r / rain-01)))) 
    ducks who like rain are happy

51

(l / like-01   
  :arg0 (d / duck)   
  :arg1 (r / rain-01)) 

amrs
(h / happy   
   :domain (d / duck   
              :arg0-of (l / like-01   
                          :arg1 (r / rain-01)))) 

(l / like-01   
   :arg0 (d / duck   
            :domain-of/:mod (h / happy))   
   :arg1 (r / rain-01)) 
    happy ducks like rain

52

police release security footage of the man they believe 

assaulted a 12-year-old in her home.

(r / release-01   
      :arg0 (p / police)   
      :arg1 (f / footage   
            :mod (s / security)   
            :topic (m / man   
                  :arg0-of (a / assault-01   
                        :arg1 (g / girl   
                              :age (t / temporal-quantity :quant 12   
                                    :unit (y / year)))   
                        :arg1-of (b / believe-01   
                              :arg0 p)   
                        :location (h / home   
                              :poss g)))))

53

police release security footage of the man they believe 

assaulted a 12-year-old in her home.

(r / release-01   
      :arg0 (p / police)   
      :arg1 (f / footage   
            :mod (s / security)   
            :topic (m / man   
                  :arg0-of (a / assault-01   
                        :arg1 (g / girl   
                              :age (t / temporal-quantity :quant 12   
                                    :unit (y / year)))   
                        :arg1-of (b / believe-01   
                              :arg0 p)   
                        :location (h / home   
                              :poss g)))))

54

amr features

    propbank predicate-argument semantics 

    name & value entities; entity linking (wiki   cation) 

    coreference 

entities & events

    modality, negation, questions 

    relations between nominals 

history teacher     (p / person    
                                 :arg0-of (t / teach-01    
                                                   :arg1 (h / history))) 

    canonicalization of content words (remove in   ectional 

morphology, convert adv     adj     noun     verb where possible) 
his trial     (t / try-02 :arg1 (h / he)) 

       all in a single graph!

55

amr assets

    snazzy annotation tool 

    evaluation method (smatch) 

    extensive documentation (guidelines, help pages in tool, 

heuristics in tool) 

    tutorial: https://github.com/nschneid/amr-tutorial 

    close coordination with propbank 

    annotation sites: cu, isi, sdl, ldc 

    data: ~40,000 amrs released (as of 2016)

56

abstract meaning 
representation (amr)

(banarescu et al., law 2013)

a graph-based representation of lexical concepts and typed relations 
between those concepts that are denoted by an english sentence. 

amr integrates several aspects of lexical/relational meaning   

abstracting away from the grammatical details   in a single structure 
designed to support rapid corpus annotation and data-driven nlp.

(flanigan et al., acl 2014)

amr parsing: jamr

    open source system from cmu 
    pipeline: 

1. preprocessing: id33, ner 
2. concept identi   cation: map word sequences to 

graph fragments 

3. relation identi   cation: connect the fragments 

into a rooted dag (novel mscg algorithm) 

    see flanigan et al. 2014 for details

58

(g / girl   
    :age (t / temporal-quantity :quant 12   
(a / assault-01)
               :unit (y / year)))

assaulted a 12-year-old

                   (a / assault-01   
                        :arg1 (g / girl   
                                        :age (t / temporal-quantity :quant 12   
                                                   :unit (y / year))))

arg1

59

summary

    for verbs (and other semantic predicates), there are complicated patterns 

of argument structure   how semantic arguments/roles correspond to 
syntactic slots. 

    lexicons formalize this in different ways: propbank, verbnet, framenet 

    corpora annotated according to each of these lexicons for training 

semantic role labelers.

    framenet is the richest theory (deep frames), but that imposes 
practical limits on the size of the lexicon and annotated corpora. 

    propbank has good coverage of english verbs, and large amount of 
annotated corpora (wsj + more!). but a bit super   cial (verb-speci   c 
frames).

    propbank event predicates are used in amr, a meaning representation 
that also captures named entities, negation/modality, coreference, and 
other aspects of semantics in a graph for each sentence.

60

