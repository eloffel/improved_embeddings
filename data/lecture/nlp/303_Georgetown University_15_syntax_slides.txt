lecture 15: 

english syntax & id18s

nathan schneider   

(most slides from marine carpuat)   

enlp | 19 march 2018

   
today   s agenda

    from sequences to trees
    syntax

    constituent, grammatical relations, 

dependency relations

    formal grammars

    context-free grammar
    dependency grammars

    treebanks

s  ntaxis (setting out or arranging) 
    the ordering of words and how they 

group into phrases

   [ [the old man] [is yawning] ]
   [ [the old] [man the boats] ]

credit:  lori levin

syntax and grammar

    goal of syntactic theory

       explain how people combine words to form 

sentences and how children attain knowledge of 
sentence structure   

    grammar 

    implicit knowledge of a native speaker
    acquired without explicit instruction
    minimally able to generate all and only the possible 

sentences of the language

[philips, 2003]

syntax vs. meaning

   colorless green ideas sleep furiously.    

    noam chomsky (1957)
you can tell that the words are in the right order. 
       and that    colorless    and    green    modify 

   ideas    

       and that ideas sleep
       and that the sleeping is done furiously
       and that it sounds like an english sentence, 

even if you can   t imagine what it means.

    contrast with:    sleep green furiously ideas 

colorless   

credit:  lori levin

but isn   t meaning more important?

[ send [the text message from james] [to sharon] ]

[ translate [the message] [from hindi] [to english] ]

    when you say these to your phone, you want 

it to respond appropriately.

    we will see that syntax helps you find the 

meaning.

adapted from:  lori levin

syntax in nlp

    syntactic analysis often a key component 

in applications
    id131s
    dialogue systems
    id53 
    information extraction
    machine translation
       

two views of syntactic structure
    constituency (phrase structure)

    phrase structure organizes words in nested 

constituents

    dependency structure

    shows which words depend on (modify or are 

arguments of) which on other words

constituency parsing & 
id18s

constituency

    basic idea: groups of words act as a single 

unit

    constituents form coherent classes that 

behave similarly
    with respect to their internal structure: e.g., at 

the core of a noun phrase is a noun

    with respect to other constituents: e.g., noun 

phrases generally occur before verbs

constituency: example
    the following are all noun phrases in 

english...

    why? 

    they can all precede verbs
    they can all be preposed/postposed
       

grammars and constituency

    for a particular language:

    what are the    right    set of constituents?
    what rules govern how they combine?

    answer: not obvious and difficult

    that   s why there are many different theories of 

grammar and competing analyses of the same data!

    our approach

    focus primarily on the    machinery   

finite-state/regular grammars
    you   ve already seen one class of 
grammars: id157
   a pattern like ^[a-z][0-9]$ corresponds 
to a grammar which accepts (matches) 
some strings but not others.

   can regular languages define infinite

languages?

   can regular languages define arbitrarily 

complex languages?

finite-state/regular grammars
    you   ve already seen one class of 
grammars: id157
   a pattern like ^[a-z][0-9]$ corresponds 
to a grammar which accepts (matches) 
some strings but not others.

   can regular languages define infinite

languages? yes, e.g.: a*

   can regular languages define arbitrarily 
complex languages? no. cannot match all 
strings with matched parentheses 
(recursion/arbitrary nesting).

context-free grammars

    context-free grammars (id18s)
    aka phrase structure grammars
    aka backus-naur form (bnf)

    consist of

    rules 
    terminals
    non-terminals

context-free grammars

    we   ll take these to be words (for now)

    the constituents in a language (e.g., noun 

    terminals

    non-terminals

phrase)

    rules

    consist of a single non-terminal on the left 

and any number of terminals and non-
terminals on the right

an example grammar

id18: formal definition

three-fold view of id18s

    generator

    acceptor

    parser

derivations and parsing
    a derivation is a sequence of rules 

applications that
    covers all tokens in the input string
    covers only the tokens in the input string

    parsing: given a string and a grammar, 

recover the derivation
    derivation can be represented as a parse tree
    multiple derivations?

parse tree: example

note: equivalence between parse trees and bracket notation

an english grammar fragment

    sentences
    noun phrases

    issue: agreement

    verb phrases

    issue: subcategorization

sentence types

    declaratives: a plane left.

s (cid:111) np vp

    imperatives: leave!

s (cid:111) vp

    yes-no questions: did the plane leave?

s (cid:111) aux np vp

    wh questions: when did the plane leave?

s (cid:111) wh-np aux np vp

noun phrases

    we have seen rules such as

    but nps are a bit more complex than that!
    e.g.    all the morning flights from denver to 

tampa leaving before 10   

a complex noun phrase

   head    = central, most 
critical part of the np

determiners

    noun phrases can start with determiners...
    determiners can be

    simple lexical items: the, this, a, an, etc. (e.g., 

   a car   )

    or simple possessives (e.g.,    john   s car   )
    or complex recursive versions thereof (e.g., 

john   s sister   s husband   s son   s car)

premodifiers

    come before the head
    examples:

    cardinals, ordinals, etc. (e.g.,    three cars   )
    adjectives (e.g.,    large car   )

    ordering constraints

       three large cars    vs.    ?large three cars   

postmodifiers

    come after the head
    three kinds

    prepositional phrases (e.g.,    from seattle   )
    non-finite clauses (e.g.,    arriving before noon   )
    relative clauses (e.g.,    that serve breakfast   )

    similar recursive rules to handle these

    nominal (cid:111) nominal pp
    nominal (cid:111) nominal gerundvp
    nominal (cid:111) nominal relclause

a complex noun phrase revisited

subject and object

syntactic (not semantic):
the batter hit the ball [subject is semantic agent]
the ball was hit by the batter [subject is semantic patient]
the ball was given a whack by the batter
[subject is semantic recipient]
{george, the key, the wind} opened the door
subject     topic:
   i just married the most beautiful woman in the world
   now beans, i like
   as for democracy, i think it   s the best form of government

credit:  lori levin, archna bhatia

subject and object

    english subjects 

   agree with the verb
   when pronouns, in nominative case 

(i/she/he/we/they)

   omitted from infinitive clauses 

(i tried _ to read the book, i hoped _ to be chosen)

    english objects

   when pronouns, in accusative case 

(me/her/him/us/them)

   become subjects in passive sentences

credit:  lori levin, archna bhatia

agreement

    agreement: constraints that hold among 

various constituents

    example, number agreement in english

this flight
those flights
one flight
two flights

*this flights
*those flight
*one flights
*two flight

problem

    our np rules don   t capture agreement 

constraints
    accepts grammatical examples (this flight)
    also accepts ungrammatical examples (*these 

flight)

    such rules overgenerate

possible id18 solution
    encode agreement in non-terminals:

    sgs (cid:111) sgnp sgvp
    pls (cid:111) plnp plvp
    sgnp (cid:111) sgdet sgnom
    plnp (cid:111) pldet plnom
    plvp (cid:111) plv np
    sgvp (cid:111) sgv np

verb phrases

    english verb phrases consists of

    head verb
    zero or more following constituents (called 

arguments)
    sample rules:

subcategorization

    not all verbs are allowed to participate in all vp 

rules
    we can subcategorize verbs according to argument 

patterns (sometimes called    frames   )

    modern grammars may have 100s of such classes

subcategorization

    sneeze: john sneezed
    find:  please find [a flight to ny]np
    give: give [me]np [a cheaper fare]np
    help: can you help [me]np [with a flight]pp
    prefer: i prefer [to leave earlier]to-vp
    told: i was told [united has a flight]s
       

subcategorization

    subcategorization at work:

    *john sneezed the book
    *i prefer united has a flight
    *give with a flight

    but some verbs can participate in multiple 

frames:
    i ate
    i ate the apple

    how do we formally encode these constraints?

why?

    as presented, the various rules for vps 

overgenerate:

    john sneezed [the book]np
    allowed by the second rule   

possible id18 solution
    encode agreement in non-terminals:

    sgs (cid:111) sgnp sgvp
    pls (cid:111) plnp plvp
    sgnp (cid:111) sgdet sgnom
    plnp (cid:111) pldet plnom
    plvp (cid:111) plv np
    sgvp (cid:111) sgv np

    can use the same trick for verb 

subcategorization

grammar formalisms
    linguists have invented grammar 

formalisms that overcome the limitations 
of context-free grammars 

   lexical functional grammar
   head-driven phrase structure grammar
   id35
   lexicalized tree-adjoining grammar
   grammatical framework

    we sometimes teach a class on these. 

credit:  lori levin

recap: three-fold view of id18s
    generator
    acceptor
    parser

recap: why use id18s in nlp?
    id18s have about just the right amount of 
machinery to account for basic syntactic 
structure in english
    lot   s of issues though...

    good enough for many applications!

    but there are many alternatives out there   

dependency grammars

dependency grammars

    id18s focus on constituents

    non-terminals don   t actually appear in the sentence

    in dependency grammar, a parse is a graph 

(usually a tree) where:
    nodes represent words
    edges represent dependency relations between words 

(typed or untyped, directed or undirected)

dependency grammars

    syntactic structure = lexical items linked by 

binary asymmetrical relations called 
dependencies 

example dependency parse

they hid the letter on the shelf

compare with constituent parse    what   s the relation?

treebanks

treebanks

    treebanks are corpora in which each sentence 

has been paired with a parse tree

    these are generally created:

    by first parsing the collection with an automatic 

    and then having human annotators correct each 

parse as necessary

parser

    but

    detailed annotation guidelines are needed
    explicit instructions for dealing with particular 

constructions

id32

    id32 is a widely used treebank
    1 million words from the wall street journal

    treebanks implicitly define a grammar for 

the language

id32: example

treebank grammars
    such grammars tend to be very flat

    recursion avoided to ease annotators burden

    id32 has 4500 different rules for 

vps, including   
    vp (cid:111) vbd pp
    vp (cid:111) vbd pp pp
    vp (cid:111) vbd pp pp pp
    vp (cid:111) vbd pp pp pp pp

summary

    syntax & grammar

    two views of syntactic structures

    context-free grammars
    dependency grammars
    can be used to capture various facts about the 

structure of language (but not all!)

    treebanks as an important resource for nlp

