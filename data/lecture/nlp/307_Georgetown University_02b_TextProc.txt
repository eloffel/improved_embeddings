basic	text	
processing

regular	expressions

slp3	slides	
(jurafsky &	martin)

regular	expressions

    a	formal	language	for	specifying	text	strings
    how	can	we	search	for	any	of	these?

    woodchuck
    woodchucks
    woodchuck
    woodchucks

regular	expressions:	disjunctions

    letters	inside	square	brackets	[]

pattern
[ww]oodchuck
[1234567890]

matches
woodchuck, woodchuck
any	digit

    ranges [a-z]

pattern
[a-z]
[a-z]
[0-9]

matches
an	upper	case	letter drenched blossoms
a	lower	case	letter
a	single digit

my beans were impatient
chapter 1: down the rabbit hole

regular	expressions:	negation	in	disjunction

    negations [^ss]

    carat	means	negation	only	when	first	in	[]

pattern
[^a-z]
[^ss]
[^e^]
a^b

matches
not an	upper	case	letter oyfn pripetchik
neither	   s   	nor	   s   
neither	e	nor	^
the	pattern a carat b

i have no exquisite reason   
look here
look up a^b now

regular	expressions:	more	disjunction

    woodchucks	is	another	name	for	groundhog!
    the	pipe	|	for	disjunction

pattern
groundhog|woodchuck
yours|mine

a|b|c
[gg]roundhog|[ww]oodchuck

matches

yours
mine
=	[abc]

regular	expressions:	? *  +  .

matches
optional
previous	char
0	or	more	of
previous	char
1	or	more	of	
previous	char

pattern
colou?r

oo*h!

o+h!

baa+
beg.n

color

colour

oh! ooh! oooh! ooooh!

oh! ooh! oooh! ooooh!

baa baaa baaaa baaaaa
begin begun begun beg3n

stephen	c	kleene

kleene *,			kleene +			

regular	expressions:	anchors		^			$

pattern
^[a-z] 
^[^a-za-z] 
\.$
.$

matches
palo alto
1
the end.
the end? the end!

   hello   

example

    find	me	all	instances	of	the	word	   the   	in	a	text.

the

misses	capitalized	examples

[tt]he

[^a-za-z][tt]he[^a-za-z]

incorrectly	returns	other or	theology

refer	to	http://people.cs.georgetown.edu/nschneid/cosc572/s18/02_py-notes.html
and	links	on	that	page	for	further	regex	notation,	and	advice	for	using	regexes	in	
python	3.

9

errors

    the	process	we	just	went	through	was	based	on	fixing	

two	kinds	of	errors
    matching	strings	that	we	should	not	have	matched	(there,	
then,	other)
    false	positives	(type	i)

    not	matching	things	that	we	should	have	matched	(the)

    false	negatives	(type	ii)

errors	cont.

    in	nlp	we	are	always	dealing	with	these	kinds	of	

errors.

    reducing	the	error	rate	for	an	application	often	

involves	two	antagonistic	efforts:	
    increasing	accuracy	or	precision	(minimizing	false	positives)
    increasing	coverage	or	recall	(minimizing	false	negatives).

summary

    regular	expressions	play	a	surprisingly	large	role

    sophisticated	sequences	of	regular	expressions	are	often	the	first	model	

for	any	text	processing	text

    for	many	hard	tasks,	we	use	machine	learning	classifiers

    but	regular	expressions	are	used	as	features	in	the	classifiers
    can	be	very	useful	in	capturing	generalizations

12

basic	text	
processing

word	id172	and	

id30

id172

    need	to	   normalize   	terms	

    information	retrieval:	indexed	text	&	query	terms	must	have	same	form.

    we	want	to	match	u.s.a. and	usa

    we	implicitly	define	equivalence	classes	of	terms

    e.g.,	deleting	periods	in	a	term

    alternative:	asymmetric	expansion:
search:	window,	windows
search:	windows,	windows,	window
search:	windows
    potentially	more	powerful,	but	less	efficient

    enter:	window
    enter:	windows
    enter:	windows

    applications	like	ir:	reduce	all	letters	to	lower	case

    since	users	tend	to	use	lower	case
    possible	exception:	upper	case	in	mid-sentence?

case	folding

    e.g.,	general	motors
    fed vs.	fed
    sail vs.	sail

    for	sentiment	analysis,	mt,	information	extraction

    case	is	helpful	(us versus	us	is	important)

lemmatization

    reduce	inflections	or	variant	forms	to	base	form

    am,	are, is	   be
    car,	cars,	car's,	cars'    car
the	boy's	cars	are	different	colors    the	boy	car	be	different	color

   
    lemmatization:	have	to	find	correct	dictionary	headword	form
    machine	translation

    spanish	quiero (   i	want   ),	quieres (   you	want   )	same	lemma	as	querer

   want   

morphology

    morphemes:

    the	small	meaningful	units	that	make	up	words
    stems:	the	core	meaning-bearing	units
    affixes:	bits	and	pieces	that	adhere	to	stems

    often	with	grammatical	functions

id30

    reduce	terms	to	their	stems	in	information	retrieval
    id30 is	crude	chopping	of	affixes

    language	dependent
    e.g.,	automate(s),	automatic,	automation all	reduced	to	automat.

for	example	compressed	
and	compression	are	both	
accepted	as	equivalent	to	
compress.

for	exampl compress	and
compress	ar both	accept
as	equival to	compress

