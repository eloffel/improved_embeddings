classi   cation:    
na  ve bayes

nathan schneider   

(slides adapted from chris dyer, noah smith, et al.) 

enlp | 5 february 2018

1

id31

    recall the task:   

filled with horri   c dialogue, laughable 
characters, a laughable plot, ad really no 
interesting stakes during this    lm, "star 
wars episode i: the phantom menace" is 
not at all what i wanted from a    lm that is 
supposed to be the huge opening to the 
segue into the fantastic original trilogy. 
the positives include the score, the sound 

id31

id31

or

goal: predict the opinion expressed in a piece of text. e.g., + or  . (or a rating
on a scale.)

goal: predict the opinion expressed in a piece of text. e.g., + or  . (or a rating
on a scale.)

nathan schneider

enlp lecture 2

nathan schneider

enlp lecture 2

6

    this is a classification task: we have open-ended text as input 

and a fixed set of  discrete classes as output. 

    by convention, the input/observed information is denoted x, 

and the output/predicted information is y.

6

2

   
   
   
   
   
   
id31

    recall the task:   

filled with horri   c dialogue, laughable 
characters, a laughable plot, ad really no 
interesting stakes during this    lm, "star 
wars episode i: the phantom menace" is 
not at all what i wanted from a    lm that is 
supposed to be the huge opening to the 
segue into the fantastic original trilogy. 
the positives include the score, the sound 

c

id31

id31

or

goal: predict the opinion expressed in a piece of text. e.g., + or  . (or a rating
on a scale.)

goal: predict the opinion expressed in a piece of text. e.g., + or  . (or a rating
on a scale.)

nathan schneider

enlp lecture 2

nathan schneider

enlp lecture 2

6

    this is a classification task: we have open-ended text as input 

and a fixed set of  discrete classes as output. 

    by convention, the input/observed information is denoted x, 

and the output/predicted information is y.

6

3

   
   
   
   
   
   
a rule-based classi   er

good = {'yay', 'cool',    } 
bad = {'ugh', ':(',    } 

score = 0 
for w in x: 
  if w in good: 
    score += 1 
  elif w in bad: 
    score -= 1 
return int(score>0)

x

c

y

4

supervised classi   cation 

    we can probably do better with data 

    our intuitions about word sentiment aren   t perfect 

    supervised = generalizations are learned from labeled data 

    so, we need a training corpus of  reviews with gold 

(correct) sentiment labels 

    and a learning algorithm 

    this course: inductive learning algorithms   collect statistics 

from training corpus, but the resulting classifier does not 
rely on the training corpus itself

5

a rule-based classi   er

supervised
good = {   from training data   } 
bad = {   from training data   } 

score = 0 
for w in x: 
  if w in good: 
    score += 1 
  elif w in bad: 
    score -= 1 
return int(score>0)

x

c

y

6

notation

    training examples:  x = (x1, x2, ..., xn) 

    their categories:      y = (y1, y2, ..., yn) 

    a classi   er c seeks to map xi to yi:

x

c

    a learner l infers c from (x, y):   

x
y

l

y

c

7

counting as learning

x

y

from collections import counter 
scores = counter() 
for x,y in zip(x,y):   
  for w in x: 
    if y==thumbs_up: 
      scores[w] += 1 
    elif y==thumbs_down: 
      scores[w] -= 1 
good, bad = set(), set() 
for w,score in scores.items(): 
  if score>0: good.add(w) 
l
  else: bad.add(w) 
return good, bad

c

8

limitations

    our classifier doesn   t know that: 

    some words are more strongly indicative of  sentiment 

than others 

    the data may skew positive or negative (e.g., more or 

longer positive reviews than negative) 

   

infrequent words may occur only in the positive 
examples or only in the negative examples by accident 

   

instead of  raw counts, we can use a probabilistic 
model

9

review questions: conditional 

id203

1. if  p is a id203 mass function, which is true by 

the definition of  id155:    
p(x | y, z) = 

a. p(x)/p(y,z) 

b. p(y)p(z)/p(x,y,z) 

c. p(x,y,z)/p(y,z) 

d. p(x)p(x|y)p(x|z)

10

review questions: conditional 

id203

2. which is/are guaranteed to be true? 

a.    y    z,   x p(x | y, z) = 1 
b.    x,   y   z p(x | y, z) = 1 
c.   x p(x) = 1 
d.    y    z,   x p(x)p(y|x)p(z|x,y) = 1

11

probabilistic classi   ers

return  
arg maxy    p(y    | x)

x

c

y

12

probabilistic classi   ers

id31

id31

or

return  
arg maxy    p(y    | x)

goal: predict the opinion expressed in a piece of text. e.g., + or  . (or a rating
on a scale.)

nathan schneider

nathan schneider

enlp lecture 2

enlp lecture 2

6

goal: predict the opinion expressed in a piece of text. e.g., + or  . (or a rating
on a scale.)

6

c

y

13

x

probabilistic classi   ers

return  
arg maxy    p(y    | x)

filled with horri   c dialogue, laughable 
characters, a laughable plot, ad really no 
interesting stakes during this    lm, "star 
wars episode i: the phantom menace" is 
not at all what i wanted from a    lm that is 
supposed to be the huge opening to the 
segue into the fantastic original trilogy. 
the positives include the score, the sound 

c

x

y

14

probabilistic classi   ers

return  
arg maxy    p(y    | x)   
 = p(y    | filled, with, horrific,    )
c

how can we compute this?
we can   t compute the usual id113 

unless this exact document 
appeared in the training data!

y

15

x

a probabilistic model that 

generalizes

instead of  estimating p(y    | filled, with, horri   c,    ) 
directly, we make two modeling assumptions:  

   

1. the bag of words (bow) assumption: assume the 
order of  the words in the document is irrelevant to 
the task. i.e., stipulate that    
p(y    | filled, with, horri   c) = p(y    | filled, horri   c, with)   

so called because a bag or multiset is a set that 
allows elements to occur more than once. it stores 
their counts but not their order.   

16

   
p
h
o
t
o
:
 
j
o
n
a
t
h
a
n
h
u
a
n
g

 

17

art installation in cmu   s machine learning department

bag of words

figure from j&m 3rd ed. draft, sec 7.1

sharon goldwater

fnlp lecture 7

5

a probabilistic model that 

generalizes

instead of  estimating p(y    | filled, with, horri   c,    ) 
directly, we make two modeling assumptions:  

   

1. the bag of words (bow) assumption: assume the 
order of  the words in the document is irrelevant to 
the task. i.e., stipulate that    
p(y    | filled, with, horri   c) = p(y    | filled, horri   c, with)   

so called because a bag or multiset is a data 
structure that stores counts of  elements, but not 
their order.   

19

   
a probabilistic model that 

generalizes

    the bow assumption isn   t enough, though, unless 
documents with all the same words occurred in the 
training data. hence: 

2. the na  ve bayes assumption: assume the words are 

independent conditioned on the class y      
p(filled, with, horri   c | y   ) 
= p(filled | y   )    p(with | y   )    p(horri   c | y   ) 

hang on, we actually wanted:
p(y    | filled, with, horri   c)   
how to reverse the order?

20

   
   
bayes    rule

p(b | a) = p(b)    p(a | b)   

                 p(a)

21

prove it!

p(b | a) = p(b)    p(a | b)   
p(b | a) = p(b)    p(a | b)   

multiply both sides by p(a)

                 p(a)
                 p(a) 

p(a)    p(b | a) = p(b)    p(a | b) 

chain rule

p(a, b) = p(b, a)

   which is true by definition of  joint id203

22

bayes    rule

p(b | a) = p(b)    p(a | b)   

                 p(a)

p(b | a)     p(b)    p(a | b)
posterior
likelihood

prior

23

a probabilistic model that 

generalizes

    the bow assumption isn   t enough, though, unless 
documents with all the same words occurred in the 
training data. hence: 

2. the na  ve bayes assumption: assume the words are 

independent conditioned on the class y      
p(filled, with, horri   c | y   ) 
= p(filled | y   )    p(with | y   )    p(horri   c | y   ) 

hang on, we actually wanted:
p(y    | filled, with, horri   c)   
how to reverse the order?

24

   
   
a probabilistic model that 

generalizes

    the bow assumption isn   t enough, though, unless 
documents with all the same words occurred in the 
training data. hence: 

2. the na  ve bayes assumption: assume the words are 

independent conditioned on the class y      
p(filled, with, horri   c | y   ) 
= p(filled | y   )    p(with | y   )    p(horri   c | y   ) 
p(y    | filled, with, horri   c) 
    p(y   )    p(filled, with, horri   c | y   ) 
 = p(y   )    p(filled | y   )    p(with | y   )    p(horri   c | y   )

25

   
is this a good model?

    what is wrong with these assumptions?

26

is this a good model?

    george box, statistician:    essentially, all models 

are wrong, but some are useful   ) 

   

it turns out that na  ve bayes + bow works pretty 
well for many text classification tasks, like spam 
detection.

27

na  ve bayes classi   er

wj     [words(x)]j 
return    
arg maxy    p(y   )      j p(wj | y   )

in other words: loop over class labels, 

choose the one that makes the document 

most probable (prior    likelihood)

c

x

y

28

na  ve bayes learner

id31

id31

x
y

   y, p(y)  

   y,    w,  p(w | y)

p(      )     (#       in y)        
              (# docs in x)

goal: predict the opinion expressed in a piece of text. e.g., + or  . (or a rating
on a scale.)

goal: predict the opinion expressed in a piece of text. e.g., + or  . (or a rating
on a scale.)

nathan schneider

enlp lecture 2

nathan schneider

6

enlp lecture 2

6

w,

p

id31

id31

p(horrific |      )     (#       docs with horrific)        
                                (#       docs)

id31

goal: predict the opinion expressed in a piece of text. e.g., + or  . (or a rating
on a scale.)

goal: predict the opinion expressed in a piece of text. e.g., + or  . (or a rating
on a scale.)

nathan schneider

enlp lecture 2

nathan schneider

6

enlp lecture 2

goal: predict the opinion expressed in a piece of text. e.g., + or  . (or a rating
on a scale.)

nathan schneider

enlp lecture 2

6

l

6

29

parameters

    each id203 (or other value) that is learned 
and used by the classifier is called a parameter 
    e.g., a single id203 in a distribution 

    na  ve bayes has two kinds of  distributions: 

   
   

the class prior distribution, p(y) 

the likelihood distribution, p(w | y) 

    so how many parameters total, if  there are k 

classes and v words in the training data?

30

smoothing p(w | y)
p(horrific |      )     (#       docs with horrific)        
                                (#       docs)

id31

id31

id31

goal: predict the opinion expressed in a piece of text. e.g., + or  . (or a rating
on a scale.)

goal: predict the opinion expressed in a piece of text. e.g., + or  . (or a rating
on a scale.)

nathan schneider

enlp lecture 2

nathan schneider

6

enlp lecture 2

6

goal: predict the opinion expressed in a piece of text. e.g., + or  . (or a rating
on a scale.)

    what if  we encounter the word distraught in a test 
document, but it has never been seen in training? 
    can   t estimate p(distraught |      ) or p(distraught |      ): 

id31

id31

nathan schneider

enlp lecture 2

6

numerator will be 0 

goal: predict the opinion expressed in a piece of text. e.g., + or  . (or a rating
on a scale.)

goal: predict the opinion expressed in a piece of text. e.g., + or  . (or a rating
on a scale.)

nathan schneider

enlp lecture 2

6

    because the word probabilities are multiplied together 

nathan schneider

enlp lecture 2

6

for each document, the id203 of  the whole 
document will be 0

31

smoothing p(w | y)

id31

id31

id31

p(horrific |      )     (#       docs with horrific) + 1        
                                (#       docs) + v + 1

id31

p(oov |      )                    1        
                           (#       docs) + v + 1

id31

goal: predict the opinion expressed in a piece of text. e.g., + or  . (or a rating
on a scale.)

goal: predict the opinion expressed in a piece of text. e.g., + or  . (or a rating
on a scale.)

goal: predict the opinion expressed in a piece of text. e.g., + or  . (or a rating
on a scale.)

nathan schneider

enlp lecture 2

nathan schneider

6

enlp lecture 2

6

nathan schneider

enlp lecture 2

6

goal: predict the opinion expressed in a piece of text. e.g., + or  . (or a rating
on a scale.)

nathan schneider

enlp lecture 2

v is the size of  the vocabulary of  the training corpus

goal: predict the opinion expressed in a piece of text. e.g., + or  . (or a rating
on a scale.)

nathan schneider

enlp lecture 2

6

6

    smoothing techniques adjust probabilities to avoid 

overfitting to the training data 
    above: laplace (add-1) smoothing 
    oov (out-of-vocabulary/unseen) words now have small 

id203, which decreases the model   s confidence in the 
prediction without ignoring the other words 

    id203 of  each seen word is reduced slightly to save 

id203 mass for unseen words

32

smoothing p(w | y)

id31

id31

id31

p(horrific |      )     (#       docs with horrific) + 1        
                                (#       docs) + v + 1

id31

p(oov |      )                    1        
                           (#       docs) + v + 1

id31

goal: predict the opinion expressed in a piece of text. e.g., + or  . (or a rating
on a scale.)

goal: predict the opinion expressed in a piece of text. e.g., + or  . (or a rating
on a scale.)

goal: predict the opinion expressed in a piece of text. e.g., + or  . (or a rating
on a scale.)

nathan schneider

enlp lecture 2

nathan schneider

6

enlp lecture 2

6

nathan schneider

enlp lecture 2

6

goal: predict the opinion expressed in a piece of text. e.g., + or  . (or a rating
on a scale.)

nathan schneider

enlp lecture 2

v is the size of  the vocabulary of  the training corpus

goal: predict the opinion expressed in a piece of text. e.g., + or  . (or a rating
on a scale.)

nathan schneider

enlp lecture 2

6

6

    laplace (add-1) smoothing, above, uses a pseudo-count of  1, 

which is kind of  arbitrary. 

    for some datasets, it   s overkill   better to smooth less. 
    lidstone (add-  ) smoothing: tune the amount of  smoothing on 

development data:

id31

id31

id31

p(horrific |      )     (#       docs with horrific) +           
                                (#       docs) +   (v + 1)

id31

goal: predict the opinion expressed in a piece of text. e.g., + or  . (or a rating
on a scale.)

goal: predict the opinion expressed in a piece of text. e.g., + or  . (or a rating
on a scale.)

p(oov |      )                              
                         (#       docs) +   (v+1)

id31

goal: predict the opinion expressed in a piece of text. e.g., + or  . (or a rating
on a scale.)

nathan schneider

enlp lecture 2

nathan schneider

6

enlp lecture 2

6

nathan schneider

enlp lecture 2

6

goal: predict the opinion expressed in a piece of text. e.g., + or  . (or a rating
on a scale.)

goal: predict the opinion expressed in a piece of text. e.g., + or  . (or a rating
on a scale.)

33

na  ve bayes classi   er

wj     [words(x)]j 
return    
arg maxy    p(y   )      j p(wj | y   )

in other words: loop over class labels, 

choose the one that makes the document 

most probable (prior    likelihood)

c

x

can get 
very small

y

34

avoiding under   ow

    multiplying 2 very small floating point numbers 

can yield a number that is too small for the 
computer to represent. this is called underflow. 

   

instead of  storing p(   ), store log p(   ) 

in implementing probabilistic models, we use log 
probabilities to get around this. 
   
    p(   )    p   (   )     log p(   ) + log p   (   ) 
    p(   ) + p   (   )     numpy.logaddexp(log p(   ), log p   (   ))

35

id87
p(x | y)
p(y)

source

y

x

what proportion of emails are expected   
to be spam vs. not spam?
what proportion of product reviews are   
expected to get 1,2,3,4,5 stars?

channel

decode

36

noisy channel classifiers

return 
arg maxy p(y)    p(x | y)

x

y

c

conclusions

    we have seen how labeled training data and 

supervised learning can produce a better-informed 
classifier 
    classifier takes an input (such as a text document) 

and predicts an output (such as a class label) 

    learner takes training data and produces (statistics 

necessary for) the classifier

38

conclusions

    because most pieces of  text are unique, it   s not very 

practical to assume the one being classified has occurred 
in the training data 
    we need to make modeling assumptions that help the 

learner to generalize to unseen inputs 

    the na  ve bayes model + bag-of-words assumption are a simple, 

fast probabilistic approach to text classification 

    works well for many tasks, despite being a dumb na  ve 

model of  language: we know that 

    good, not as bad as expected     bad, not as good as expected 

id31

id31

id31

    p(star wars |     )     p(star |     )    p(wars |     )

goal: predict the opinion expressed in a piece of text. e.g., + or  . (or a rating
on a scale.)

goal: predict the opinion expressed in a piece of text. e.g., + or  . (or a rating
on a scale.)

goal: predict the opinion expressed in a piece of text. e.g., + or  . (or a rating
on a scale.)

nathan schneider

enlp lecture 2

6

nathan schneider

enlp lecture 2

6

nathan schneider

enlp lecture 2

6

39

conclusions

   

   

in practice, we need smoothing to avoid assuming 
that everything that might come up at test time is in 
the training data 

implementation trick: use log probabilities to avoid 
underflow

40

