cs 585: introduction to 
natural language 
processing 

guest lecture: gaja jarosz 

gradient phonotactics 

1 

         how good are these as 
novel words of english? 
        stin 
        blick 
        mip 
        skell 
        blafe 
        bwip 
        shmy 

        smum 
        dlap 
        bzack 
        mrock 
        dmell 
        lnoot 
        mdap 

gradient phonotactics 

2 

         how good are these as 
novel words of english? 
        stin 
        blick 
        mip 
        skell 
        blafe 
        bwip 
        shmy 

        smum 
        dlap 
        bzack 
        mrock 
        dmell 
        lnoot 
        mdap 

gradient phonotactics 

3 

         knowledge of gradient phonotactics has been 

illustrated in a range of tasks 
         lexical access 

n       faster recognition of more phonotactically probable words 

         word learning 

n       faster acquisition of more phonotactically probable words 

         id40 by children and adults 

n       this is the main information we think infants use to segment speech 
n       example: mattys & jusczyk (2001) 

n       ..bean gaffe hold..
n       ..fang gaffe tine..

 [ng] and [fh] occur infrequently within words 
 [  g] and [ft] occur frequently within words 

what   s phonotactic id203? 

4 

         what   s the id203 of? 

        blick vs. shmy vs. mrock 

         ideas? 

id165s! 

5 

         pr(#abcd#) 
         pr(a | b) = ? 
         chain rule 

        pr(a,b) = pr(a | b)pr(b) 
        pr(a,b,c) = pr(a | b,c)pr(b | c)pr(c) 
 = pr(c | a,b)pr(b | a)pr(a) 
         apply chain rule to pr(#abcd#)? 

 

id165s! 

6 

         pr(#abcd#)? 
        pr(a | #) * 
        pr(b | #,a) * 
        pr(c | #,a,b) * 
        pr(d | #,a,b,c) * 
        pr(# | #,a,b,c,d) 

         id165s make an independence assumption that 

only a fixed amount of history matters    
        unigrams, bigrams, trigrams, etc. 

id165s 

7 

         we can   t condition on every possible preceding 

sequence - there   s too many! 
         jack and jill went up the hill 

         id165 models condition on n-1 previous symbols: 

         unigrams: no history 

n       p(jack)p(and)p(jill)p(went)p(up)p(the)p(hill) 

         bigrams: 1 previous symbol 

n       p(jack | #)p(and | jack)p(jill | and)p(went | jill)    

         trigrams: 2 previous symbols 

n       p(jack | ##)p(and | # jack)p(jill | jack and)p(went | and jill)    

what   s phonotactic id203? 

8 

         what   s the bigram id203 of? 

        blick vs. shmy vs. mrock 

what   s phonotactic id203? 

9 

         what   s the bigram id203 of? 

        blick vs. shmy vs. mrock 

         p(b | #)p(l | b)p(i | l)    

        how can we estimate these probabilities? 

baseline: phoneme bi-grams 

10 

         example 

feature-based generalisation as a source of gradient acceptability

biphone

stin

bleif

1
2
3
4
5

log (prob)

#s
st
ti
in
n#

0  118
0  205
0  192
0  108
0  151

   4  12

#b
bl
lei
eif
f#

0  057
0  106
0  042
0  007
0  067

   6  93

table i

biphone transitional properties of stin and blafe.

about the goodness of a particular id165 by collecting more words.3
bailey & hahn (2001)    nd that even triphones are of little or no use in
predicting acceptability of english monosyllables, though taking at least
triphones into consideration would probably be advantageous in evalu-

what   s phonotactic id203? 

11 

         what   s the bigram id203 of? 

        blick vs. shmy vs. mrock 

         if we   re primarily interested in the initial consonant 
sequences, there are several ways we could use n-
grams to model these sequences    
        pros and cons? 

12 

(a)

g
n
i
t
a
r
 
n
a
e
m

how do bigrams do? (albright 2009) 

feature-based generalisation as a source of gradient acceptability

29

6

5

4

3

2

wis

pint

stin

daiz

baiz

sleim
  aif

stai  

sp  k
ta  k
neis
g  el

p  nk
m#n
pleik
deip
gli:d
tes
ti:p
caind
sk  aid
b  ej
   ij

gez
skik
   et

stip
mip
glit
ge  
p  i:k
lvm
plim
gu:d
d  it
kwi:d

blig

pvm
splin

kiv

snel

skel

tvnk
skwil

    sk
t  isk
s#n
g  aint
ceik

silk

bleif

skoil

   i:p
nould

glip
zei
d  ais
cu:l
saint
twu smvm

nvn

  aint

skwolk

zeips

s  u:ks

gwenj

swu:z
sme  g

smi  g

snoiks
t  ilb
t  oiks
k  ilg
dwouj ploumf

f  ilg
s m e    f

smi:lt

sfu:nd

pwip

sklu:nd

twi:ks
plount

smi:nt teipt

sp  a  f

pwvdz

   23

   20

   17

   14

   11

   8

segmental biphones (log prob)

(b)

6

sleim

wis

how do bigrams do? 

13 

         overall correlations with human judgments? 

        training on just onsets: 

n      r = 0.88 

n       hayes & wilson (2008) 
        training on whole words: 

n      r = 0.78 (with syllable boundaries), = .50 (without) 

n       daland et al. (2011) 

 

problem! 

14 

         people show gradient judgments of two kinds 
         attested onset clusters 

         stin > blin > bwin 

         and unattested onset clusters 

         bnick > bzick > mbick  

         high correlations due to differences across not within 
         this latter category gives us crucial clues about how 

people learn and represent these patterns 

         however,  

         positional bigrams cannot model this. why? 
         whole-word bigrams do very poorly (r = 0.22). why? 

so what are people doing? 

15 

         why do people have these judgments then? 

         bnick > bzick > mbick  

         notice: this is a problem with generalization 

        we want models to generalize correctly to new data 
        cognitive scientists & linguists are interested in 

modeling how humans generalize (correct = whatever 
humans do) 

        id165s already generalize, just not in the right way! 

         ideas? intuitions? can we save this approach? 

        hint: this is not a solved problem yet! 

so what are people doing? 

16 

         why do people have these judgments then? 

         bnick > bzick > mbick  

         two recent models 

        albright 2009 featural bigrams 
        hayes & wilson 2008 maximum id178 model 

albright   s proposal 

17 

         bn is relatively good because it   s similar to existing 

         bl 
         br 
         sn 
             

         bd is not as similar to existing sequences 

         bl is farther from bd than from bn 
         br is farther from bd than from bn 
             

         how to formalize similar?

 
         phonetic/phonological features! 

  

phonological features 

18 

diacritic 
examples 
t'  th  t(cid:23) 

                                        coronal                     palatal                            non-coronal                                                                             (sonorant consonants) 
                                      obstruents                    obstruents                            obstruents                        laryngeals             affricates                   nasals & liquids             glides                            vowels 
                                      [+cons, -son, +cor]              [+cor + dors]                       [+cons, -son, -cor]                      [-cons,-son]         [+cons,-son -/+cont]                  [+cons,+son]                     [-cons, +son]                        [-cons, +son]    

t(cid:100)(cid:53) d(cid:100)(cid:60) ts dz kx pf m  n  (cid:48)  (cid:212)  (cid:213)  (cid:146)  l  (cid:148)  r  (cid:136)  (cid:93)  j  w  (cid:196)  (cid:194) 

phonological features chart 

 

 

-

-

- 

- 

- 

- 

- 

-
-

-
-

-
-

-
-

-
- 

-
- 

-
- 

-
- 

- 
- 

- 
- 

- 
- 

- 
- 

- 
- 

- 
- 

- 
- 

- 
- 

- 
- 

-
- 
-

-
- 
-

-
- 
-

-
- 
-

-
- 
-

-
- 
-

- 
- 
- 

- 
- 
- 

- 
- 
- 

- 
- 
- 

- 
- 
- 

- 
- 
- 

- 
- 
- 

- 
- 
- 

- 
- 
- 

- 
- 
- 

- 
- 
- 

- 
- 
- 

- 
- 
- 

- 
- 
- 

- 
- 
- 

-
-
- 
-

-  + - 
- 
- 

 labial 
      round 
 coronal 
      ant 
      distrib 
 dorsal 
      high 
      low 
      back 
      tense 
 phrngl 
      atr 

- 
- 
-  +  +  - 

-
-
- 
- 
-
-
0 0 0
-
-
0 0 0
0 0 0

-
- 
- 
- 
-  +  +  + + + + -

-
- 
-
0 0 0 0
-
-
-  0  0  0 0 0 0 0 0 0 0
-  +  +  +  +  +  +  0  0  0 0 0 0 0 0 0 0
- 

t  d  s  z  (cid:160)  (cid:46)  (cid:54)  (cid:38)  (cid:53)  (cid:60)  c  (cid:204)  (cid:37)  (cid:163)  p  b  f  v  (cid:150)  (cid:36)  k  (cid:73)  x  (cid:162) q  (cid:41)  (cid:58)  (cid:175)  (cid:205)  (cid:158)  h  (cid:215)  (cid:33) 
-
cons  +  +  +  +  +  +  +  +  +  +  +  +  +  +  +  +  +  +  +  + + + + + + + + + + + + + + -
-
-
son 
- 
- 
syll 
-
-
0 0 0
-
-
0 0 0
0 0 0
-
-
0 0 0 high  + + 0 0 +  0  0  0  + - + -
-
0 0 0
0 0 0 back -
-
0 0 0 tense
- 
-  phar

-
-
- 
- 
-
-
0 0 0
-
-
0 0 0
0 0 0
-
0 0
-  0  0  0 0 0 0
0 0
-  0  0  0 0 0 0 + + + + + + + + 0 0
-  0  0  0 0 0 0
0 0
- 
-

- 
- 
- 
- 
0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0 
+  +  +  +  +  +  +  +  +  +  +  +  +  +  +  +  +  - 
+  +  +  +  +  +  +  +  +  +  +  - 
- 
- 
0  0  0  0  0  0  0  0  0  0  0  0  0  +  +  +  +  0  0  0 0 0 0 + + + + -
-
0  0  0  0  0  0  0  0  0  0  0  0  0 
0  0  0  0  0  0  0  0  0  0  0  0  0 
-
0  0  0  0  0  0  0  0  0  0  0  0  0 
- 
-
- 
0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0 0 0 0 0 0 0 0
- 
- 
-  +  - 
- 
- 
- 
- 
- 
- 

- 
-  +  -  +  -  +  -  +  -  +  -  +  -  +  -  +  - + - + - + - + - + - + -
- 
- 
- 
- 
- 
- 
- 
- 
- 

- 
- 
- + + + + + + -
-
-
-
- 
- d rel + + + + +  +  - 
- 
-
- nasal

0 0
0 0 +  0  0  0  + -
0 0
- 
- 
atr  0 0 0
0 0  0  0  0  0
voi 
s.g. 
- + c.g. 

- 
- 
- 
- 
-  +  +  +  +  +  +  +  +  - 
-  +  +  - 
-  +  +  - 
- 
- 
- 
- 
- 
- 
- 
- 
- 

- 
- 
- 
- 
-  + + + + -
-
- 
-
- 
-
- 
- 
-

cons  + + + + +  +  +  +  + + + + + + + + + -
-
-
son 
- 
- 
syll 
-
-
lab 
rnd  0 0 0
0 0 
cor  + + + + - 
ant 
dist  + + -
dor  + + -

cont                      - 
strid + + + + -  +  - 
lat 

- 
- 
- 
- 
-  +  +  - 
- 
- 
- 
- 
- 
- 
- 
- 

- 
- 
- 
- 
- + + -
-
-
- 
-
- 
-
-
-

voice 
s.g. 
c.g.  +  - 
- 
- 
cont 
- 
strident  - 
- 
- 
lateral 
- 
- 
del rel 
- 
- 
nasal 

- 
-  +  +  - 
- 
- 
- 
- 

- + - + - 
- 
-
-
- 

-  0 0 0
-
- + -
-  + + -
- 

-
- + + - 
0

- + + + + + + + + -

- + + 0  0  0  +  0

-
-
-
-
0 0 0

-  0  0  0 
- 

-  +  +  +  +  - 

-  +  - 
- 
- 

-
- +  - 

-  0  0  0 

0  0  0 

- 
- 
- 
- 

- 
- 
- 
- 

- 
- 
- 
- 

- 
- 
- 
- 

- 
- 
- 
- 

-
- 
- 
-

-
- 
- 
-

-
- 
- 
-

-
- 
- 
-

-
- 
- 
-

-
- 
- 
-

-
-
-
- 

- 
- 
- 

- 
- 
- 

- 
- 
- 

-
-
-
-

-
-
-
-

-
-
-
-

-
-
-
-

-
-
-
-

-
-
-
-

low 

- 
- 

- 
- 

- 
- 

- 
- 

- 
- 

- 
- 

- 
- 

- 
- 

- 
- 

- 
- 

- 
- 

- 
- 

- 
- 

- 
- 

- 
- 

- 
- 

- 
- 

-
-

-
-

-
-

-
-

-
-

-
-

-
-

-
-

-
-

-
-

- 

- 

- 

- 

- 

- 

- 

- 

- 

- 

- 

- 

- 

- 

- 

- 

- 

- 

- 

- 

- 

-

-

-

-

-

-

-

-

-

-

-

-

-

-

-

-

-

-

-

-

-

-

-

-

 

 
s
s
a
l
c

 
s
e
r
u
t
a
e
f

 
s
e
r
u
t
a
e
f
 
e
c
a
l
p

 
l
a
e
g
n
y
r
a
l

 
s
e
r
u
t
a
e
f

 
r
e
n
n
a
m

 
s
e
r
u
t
a
e
f

 

place and  
manner of 
articulation  l

 
l
a
i

b
a

 
l
a
t
n
e
d
o
i
b

 
l
a
t
n
e
d

 
r
a
l
o
e
v
l
a

 
 

x
e
l
f
o
r
t
e

 
r
a
l
o
e
v
l
a
t
s

 
l
a
t
a
l
a
p

 
r
a
l
e
v

 
r
a
l

u
v
u

 
l
a
e
g
n
y
r
a

 
l
a
t
t
o
l
g

more sounds 

 

variants
s(cid:189)  =  (cid:53)  (cid:104) bilabial click 
c(cid:189)  =  t(cid:53) 
|  dental click 

 

feature geometry  

 (prosodic) 
 skeleton:                   c,v 
 

 
 

albright   s proposal 

19 

         do bigrams over phonological classes not phonemes 
         bn is b[+voi, +son, +cor, -strid, +nas] 

         bl is b[+voi, +son, +cor, -strid, +nas] 

n       we can group n and l into a small natural class b[n l r j] 
n       frequency of this specific combination is high 

n       bl, br, bj are all attested 

         bd is b[+voi, -son, +cor, -cont] 

         bl is b[+voi, -son, +cor, -cont] 

n       l and d have less in common, need larger class b[n l r j z n d]  
n       frequency of this combination is high, but not very related to bd 

albright   s proposal: formally 

20 

         phonotactic id203 tradeoff between 
frequency and specificity 
count(ab)
count(..)    p(a | a)   p(b | b)
          
        where 

score(ab) = max
a,b   nat
1
| a |

p(a | a) =

n        

        how does this deal with bd vs. bn vs. bl? 

hayes & wilson (2008) 

21 

         maximum id178 model of phonotactics 

        closely related to regression models (in fact they are 
equivalent to multinomial id28 models) 
        you have some observation c to assign id203 to 
          
        you do so on the basis of various features x1     xn 

e(w0 +w1x1 +w2x2 +...+wnxn )

e fc (x)
z =

p(y = c) =

z

         for phonotactics, these features reflect phonological 

    

preferences and restrictions. 
        in linguistics, features are called constraints 
        constraint-based models of various kinds are widely 

used in theoretical phonology  

top maxent constraints (hw 2008) 

m a x i m u m e n t r o p y p h o n o t a c t i c s

397

table 4
the learned grammar for english onsets

22 

constraint

weight

comment

*[   ]
*[  ]

examples

*   , *s   
*   (see also

#16)

1. *[   son,   dors]
2. *[   cont,   voice,   ant]

3. *         voice

   strid    [   approx]

   ant

4. *[ ][   cont]

5. *[ ][   voice]

6. *[   son][ ]
7. *[   strid][   cons]

8. *[ ][   strid]

9. *[   lab]          approx
   
10. *[   ant]          approx
   

   cor

   ant

11. *[   cont,   voice][ ]

12. *[   cont,   ant][ ]

13. *[ ][   back]

14. *[   ant,   strid][   ant]

5.64
3.28

5.91

5.17

5.37

6.66
4.40

1.31

4.96

4.84

4.84

3.17

5.04

2.80

nasals and obstruents may only be

*kt, *kk, *skt

preceded (within the onset) by [s].

fricatives may not cluster with

*sf, *s   , *sh,

preceding c.

*sfl

voiced obstruents may not cluster

*sb, *sd, *sgr

with preceding c.

sonorants may only be onset-final.
nonstrident coronals may not

*rt
*dl, *tl, *   1

precede nonglides.

stridents must be initial in a cluster.

*st+ (see also
#14, #22)

the only consonants that may follow *pw vs. pl, pr

labials are [l] and [r].

only [r] may follow nonanterior

coronals.

*+l vs. +r

voiced fricatives must be final in an

*vr, *vl vs. fr,

onset.

[t+] and [d  ] must be final in an

onset.

[j] may not cluster with a preceding
c; see above for assumed syllabic
parsing of [ju].

sibilants must agree in anteriority

fl

*t+r, *d  r vs.
tr, dr (see
also #22)

*[bj]ons

*sr vs. +r (see

results comparison (daland et al 2011) 

216 robert daland et al.

23 

syllabi   cation

no syllabi   cation

model

albright

bigram

coleman

gnm.   g
gnm.oral
gnm.writ
gnm.lin

hw[100]
hw[150]
hw[200]
hw[250]
hw[300]
hw[350]
hw[400]

vl.uni
vl.bi

at-

tested
0  21
0  19
0  35
0  07
0  28
0  17
0  32
0  00
0  00
   0  09
   0  09
   0  39
   0  39
   0  39
0  27
0  30

mar-
ginal
0  03
0  16
0  31
0  25
0  23
0  24
0  23
0  02
0  06
0  03
0  13
0  04
0  03
0  04

0  11
0  06

at-

tested

0  13

0  23

   

0  06
0  26
0  16
0  30

0  00
0  00
0  00
0  00
0  00
0  00
0  00

0  30
0  30

unat-
tested
0  55
0  22
   0  01
   0  29
   0  28
   0  17
   0  22
0  76
0  69
0  64
0  64
0  54
0  51
0  52

0  38
0  27

over-

all
0  51
0  78
0  55
0  15
0  22
0  24
0  31
0  83
0  82
0  80
0  84
0  80
0  80
0  81

0  43
0  56

table v

unat-
tested

mar-
ginal
   0  07
0  18
0  01    0  14
   
   
   0  32
   0  28
   0  30
   0  26
0  79
0  67
0  69
0  70
0  70
0  67
0  68

0  24
0  23
0  24
0  22
   0  31
0  04
0  05
0  00
   0  02
   0  10
0  00

0  19
0  08

0  34
0  22

over-

all

0  26

0  50

   

0  08
0  21
0  15
0  24

0  68
0  75
0  77
0  80
0  81
0  81
0  80

0  36
0  54

correlations of model ratings with experiment 2 scores.

results discussion 

24 

         observations 

         bigram (.78) and maxent (.83) do well overall 

n       but it   s easy to do well overall 

         bigrams (.22) do terribly on unattesteds 
         maxent does well on unattesteds (.76) 
         no model does great on attesteds 

         conclusions? 

         long way to go    
         but     

n       features/similarity are important 
n       syllabification/higher level structure is important 

         ideas? critiques? questions? 

other work 

25 

         one example of computational modeling to 

address cognitive questions 
        main argument: human phonological generalization is 

feature-based and structure sensitive 

         modeling can also be used to address questions 

about learning bias to show how humans 
systematically ignore or depart from certain 
properties of the input 

sonority sequencing principle 

26 

         sonority sequencing principle (ssp) 

         [lb]ack     [mb]ack     [bd]ack     [bn]ack     [b  ]ack     [bj]ack  
         -2 
       3 
         typological generalizations (clements 1988, selkirk 1984) 

       0  

    2

 -1

 1

n       [bn]ack     [bl]ack 

         consistent findings of sonority projection in english 

         preferences between unobserved clusters (nb vs db) 
         production, perception, acceptability; aural, written  

(berent et al. 2007, berent & lennertz 2009, berent et al. 2009, davidson et al. 2004, davidson 
2006, daland et al. 2011) 

         debate: where do these preferences come from? 

         daland et al examine ssp and argue models like maxent can 

capture these effects    

how can this be? statistics over classes! 

27 

oo	
   
st	
    521	
   
sp	
    313	
   
sk	
    278	
   

on	
   
sn	
   109	
   
sm	
    82	
   

1112  
(17.4%)	
   

191  
(3.0%)	
   

og	
   
ol	
   
kw	
    201	
   
pr	
   1046	
   
sw	
    153	
   
tr	
    515	
   
hw	
    111	
   
kr	
    387	
   
gr	
    331	
   
tw	
    55	
   
br	
    319	
    dw	
    17	
   
fl	
    290	
    gw	
    11	
   
kl	
    285	
      w	
   
4	
   
fr	
    254	
   
pl	
    238	
   
bl	
    213	
   
sl	
    213	
   
dr	
    211	
   
gl	
    131	
   
  r	
    73	
   
  r	
    40	
   
4546 
(71.0%)	
   

552  
(8.6)%	
   

       plenty of ssp evidence 

       lo
       no
       oo
       on
       ol

 none 
 none 
 only so 
 only sn 
 71% 

       higher level 

       son rise
       son plat.
       son fall

 82.6% 
 17.4% 
 0% 

polish clusters 

28 

         my ongoing work 

         english is the wrong language to test! 

n       predictions based on input and based on bias are the same! 

         change tactic: look at a language that admits all these 

sequences! 
         what are predictions based on input? 
         what are predictions based on universal bias? 
         build models for both and evaluate! 

         polish onsets 
         whole scale! 
         [wb]ack     [lb]ack     [mb]ack     [bd]ack     [bn]ack     [b  ]ack     [bj]ack  
            -3

        2        3 

       0

       1

 -1

 -2

polish clusters: examples 

29 

p"
  "
f"
  "
n"
  "
l"
  "
g"
  "

f"

l"

g"

n"

[  w  va] "head""
[bjaw  ] "white""

[dn  ] "bottom""
[d  a] "day""
[      k] "snow""

[p    j  t    ] "to come""
[k       w     ka] "book""
[xfila] "moment""

p"
[klu  ] "key""
[ptak] "bird""
[dr    a] "road""
[kt  ] "who""
[vlat    ] "to pour"" [vwa      ] "exactly""
[  pi] "sleeps""
[fruvat    ] "to fly""[zw  ] "bad""
[st  ] "one hundred""[f    stk  ] "everything""[sm  k] "dragon""
[m    ] "me (inst.)""
[mdw  ] "dull""
[ml  k  ] "milk""
[mn    a] "multiple"" [mrufka] "ant""
[mgwa] "fog""
[l  an  ] "linen" (adj)"
[rt    t    ] "mercury"" [lv  ] "lions""
[rd  za]    rust   "
[rvat    ]    tear   "
[lnu] "linen" (gen)"
[wba] "head (gen)"" [wza] "tear""
[wkat    ] "sob""

[mjaw] "he had""
[mjut] "honey""

[m  a] "mass""
[m    t  sa] "mite""

what do kids learning polish do? 

30 

ssp effects using scale:  p   f   n   l   g   v 
this is how accurate children are at producing onset 
clusters as a function of sonority rise degree. strong 
relationship! 
 

0.6 

0.7 

0.5 

0.4 

0.3 

0.2 

0.1 

0 

-1 

0 

1 

2 

3 

4 

polish clusters: statistics 

31 

         could kids get these preferences from input statistics? 

         relative frequency very different from english 
         half the input is obstruent-obstruent! 

         i consider various ways of modeling the input 

         segment bigrams 
         class-based bigrams 
         maxent 

         none can capture the kids    preferences    
 

sonority profile	
   
token frequency 
type frequency 

oo	
   

nn	
   

lo	
   
0.04%  50.90%  0.50%  3.60%  0.20%  20.40%  3.00%  21.30% 
0.10%  47.70%  0.20%  6.70%  0.60%  19.60%  2.90%  22.30% 

on	
   

ng	
   

og	
   

nl	
   

ol	
   

thanks! 

32 

         two brief examples of what we do 
         lots of other people in linguistics interested in 

computational modeling (not just phonology) 

         if you   re interested in more    

        come talk to us! 
        check out our classes! 

