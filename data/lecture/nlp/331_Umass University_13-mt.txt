machine translation (part 1)

cs 585, fall 2015

introduction to natural language processing

http://people.cs.umass.edu/~brenocon/inlp2015/

brendan o   connor

college of information and computer sciences

university of massachusetts amherst

tuesday, october 27, 15

[some slides borrowed from j&m + mt-class.org]

nlp news of the day

the system helps mountain view, 
california-based google deal with 
the 15 percent of queries a day it 
gets which its systems have never 
seen before, he said.  for example, 
it   s adept at dealing with ambiguous 
queries, like,    what   s the title of the 
consumer at the highest level of a 
food chain?    and rankbrain   s usage 
of ai means it works differently 
than the other technologies in the 
search engine.
   the other signals, they   re all based 
on discoveries and insights that 
people in information retrieval have 
had, but there   s no learning,    
corrado said.

tuesday, october 27, 15

http://www.bloomberg.com/news/articles/2015-10-26/google-turning-its-lucrative-web-search-over-to-ai-machines

2

graders at work

    midterms back on thursday
    project feedback: by tomorrow
    hw2 still underway (sorry!)

tuesday, october 27, 15

3

machine translation

    intro
    classic mt
    statistical mt
    training
    evaluation

tuesday, october 27, 15

4

mt is amazing

tuesday, october 27, 15

5

mt is hard

    word order, word meanings

tuesday, october 27, 15

6

mt is hard
    word meaning:

many-to-many and context dependent

    translation itself is hard: metaphors, cultural 

references, etc.

7

tuesday, october 27, 15

mt goals

    motivation: human translation is expensive
    high precision translation
    rough translation
    assistance for human translators
    comparison: bilingual dictionary

tuesday, october 27, 15

8

mt: major types
    rule-based transfer

    manually program lexicons/rules
    systran (altavista babel   sh)

    statistical mt:

    learn translation rules from data,
search for high-scoring translation outputs
    phrase or syntactic transformations

    key research in the early 90s
    google translate (mid 00s)
    moses, cdec  (open-source)

   

[active current work: semantic mt? neural mt?]

tuesday, october 27, 15

9

vauquois triangle

tuesday, october 27, 15

10

glish into spanish:

figure 25.5
is the bilingual dictionary.

direct machine translation. the major component, indicated by size here,

let   s look at a simpli   ed direct system on our    rst example, translating from en-

adjectives after nouns when translating from english to french.
the guiding intuition of the direct approach is that we translate by incrementally
transforming the source language text into a target language text. while the pure
direct (word-based) transfer
direct approach is no longer used, this transformational intuition underlies all modern
systems, both statistical and non-statistical.

11draft

(25.11) mary didn   t slap the green witch
bofetada
slap

the four steps outlined in fig. 25.5 would proceed as shown in fig. 25.6.
step 2 presumes that the bilingual dictionary has the phrase dar una bofetada a
as the spanish translation of english slap. the local reordering step 3 would need
to switch the adjective-noun ordering from green witch to bruja verde. and some
combination of ordering rules and the dictionary would deal with the negation and
past tense in english didn   t. these dictionary entries can be quite complex; a sample

maria
mary

verde
green

bruja
witch

di  o
gave

una
a

no
not

tuesday, october 27, 15

la
the

a
to

into french. the parser does not need to bother to    gure out where the prepositional
phrase attaches, because both possibilities lead to the same french sentence.
once we have parsed the source language, we   ll need rules for syntactic transfer
and lexical transfer. the syntactic transfer rules will tell us how to modify the source
parse tree to resemble the target parse tree.

draft

figure 25.10 gives an intuition for simple cases like adjective-noun reordering; we
transform one parse tree, suitable for describing an english phrase, into another parse
tree, suitable for describing a spanish sentence. these syntactic transformations are
operations that map from one tree structure to another.
the transfer approach and this rule can be applied to our example mary did not
slap the green witch. besides this transformation rule, we   ll need to assume that the
morphological processing    gures out that didn   t is composed of do-past plus not, and
that the parser attaches the past feature onto the vp. lexical transfer, via lookup in
the bilingual dictionary, will then remove do, change not to no, and turn slap into the
phrase dar una bofetada a, with a slight rearrangement of the parse tree, as suggested
in fig. 25.11.
for translating from svo languages like english to sov languages like japanese,
we   ll need even more complex transformations, for moving the verb to the end, chang-
ing prepositions into postpositions, and so on. an example of the result of such rules is
shown in fig. 25.12. an informal sketch of some transfer rules is shown in fig. 25.13.

syntactic transfer

a simple transformation that reorders adjectives and nouns

    nominal
noun adj

nominal
adj noun

figure 25.10

syntactic
transformations

tuesday, october 27, 15

12

interlingua

   mary did not slap the green witch   

    more like classic logic-based ai
    works in narrow domains
    broad domain currently fails

    coverage: id99 for all possible semantics?
    can you parse to it?
    can you generate from it?

tuesday, october 27, 15

13

rules are hard
    coverage
    complexity (context dependence)
    maintenance

tuesday, october 27, 15

14

statistical mt

naturally.  learn rules from data?

    mt as ml:   translation is something people do 
    parallel data:  (source, target) text pairs
    e.g. 20 million words of european parliament 

proceedings
http://www.statmt.org/europarl/

tuesday, october 27, 15

15

id87

original

text

hypothesized transmission process

id136 problem

observed

text

codebreaking
p(plaintext | encrypted text) / p(encrypted text | plaintext) p(plaintext)
id103
p(text | acoustic signal)
id42
p(text | image)
machine translation
p(target text | source text) / p(source text | target text) p(target text)
id147
p(target text | source text) / p(source text | target text) p(target text)

/ p(acoustic signal | text) p(text)
/ p(image | text) p(text)

tuesday, october 27, 15

id87

original

text

hypothesized transmission process

id136 problem

observed

text

one naturally wonders if the problem of translation could 
conceivably be treated as a problem in cryptography. when 
i look at an article in russian, i say:    this is really written in 
english, but it has been coded in some strange symbols. i 

codebreaking
p(plaintext | encrypted text) / p(encrypted text | plaintext) p(plaintext)
id103
p(text | acoustic signal)
id42
p(text | image)
machine translation
p(target text | source text) / p(source text | target text) p(target text)
id147
p(target text | source text) / p(source text | target text) p(target text)

/ p(acoustic signal | text) p(text)
will now proceed to decode.   
/ p(image | text) p(text)
-- warren weaver (1955)

tuesday, october 27, 15

statistical mt

tuesday, october 27, 15

17

statistical mt
    pioneered at ibm, early 1990s

(forerunner of 90s-era statistical revolution in nlp)

historical notes: http://cs.jhu.edu/~post/bitext/

tuesday, october 27, 15

18

statistical mt
    pioneered at ibm, early 1990s
    id87 borrowed from

id103 processing

(forerunner of 90s-era statistical revolution in nlp)

"every time i    re a linguist,
the performance of the speech recognizer goes up"
[fred jelinek]

tuesday, october 27, 15

19

resulting noisy channel equation shows that we need two components: a translation
best-translation   t = argmaxt faithfulness(t,s)    uency(t)
model p(f|e), and a language model p(e).

statistical mt

problem formulation

importance of both faithfulness and    uency. statistical mt is the name for a class
of approaches that do just this, by building probabilistic models of faithfulness and
   uency, and then combining these models to choose the most probable translation. if
we chose the product of faithfulness and    uency as our quality metric, we could model
the translation from a source language sentence s to a target language sentence   t as:

20draft
draft

this intuitive equation clearly resembles the bayesian id87 we   ve
seen in ch. 5 for spelling and ch. 9 for speech. let   s make the analogy perfect and
formalize the id87 for id151.
first of all, for the rest of this chapter, we   ll assume we are translating from a
foreign language sentence f = f1, f2, ..., fm to english. for some examples we   ll use
french as the foreign language, and for others spanish. but in each case we are trans-
lating into english (although of course the statistical model also works for translating
out of english). in a probabilistic model, the best english sentence   e = e1,e2, ...,el
is the one whose id203 p(e|f) is the highest. as is usual in the noisy channel
model, we can rewrite this via bayes rule:

= argmaxe
= argmaxep(f|e)p(e)

  e = argmaxep(e|f)

noisy channel
p(f|e)p(e)

  e = argmax
e   english

translation model

language model

source sentence

p(f|e)
! "# $

!"#$p(e)

p(f)

tuesday, october 27, 15

notice that applying the id87 to machine translation requires that
we think of things backwards, as shown in fig. 25.15. we pretend that the foreign
(source language) input f we must translate is a corrupted version of some english
(target language) sentence e, and that our task is to discover the hidden (target lan-
guage) sentence e that generated our observation sentence f.

(search algo)

decoder

phrase-based model

    learning p(f | e) phrase translation tables:

assume aligned corpus.  then count

    today: lexical translation model (ibm model 1)

tuesday, october 27, 15

21

lexical translation

    how do we translate a word? look it up in the 
haus : house, home, shell, household

dictionary

    multiple translations
    different word senses, different registers, 
    house, home are common
    shell is specialized (the haus of a snail is a shell)

different in   ections (?)

thursday, january 24, 13

tuesday, october 27, 15

how common is each?

translation

count

house

home

shell

household

5000

2000

100

80

thursday, january 24, 13

tuesday, october 27, 15

maximum likelihood 
estimation:  count ratios

id113

  pid113(e | haus) =

0.696 if e = house
0.279 if e = home
0.014 if e = shell
0.011 if e = household
0

otherwise

8>>>>>><>>>>>>:

could learn if we had translation frequencies.

thursday, january 24, 13

tuesday, october 27, 15

lexical translation

e

p(e | f, m)

    goal: a model
    where    and    are complete english and foreign sentences
f
    lexical translation makes the following assumptions:

ei
e = he1, e2, . . . , emi

    each word in     in    is generated from exactly one word 
    thus, we have an alignment     that indicates which word
    given the alignments    , translation decisions are 

f = hf1, f2, . . . , fni
ei
        came from   , speci   cally it came from       .
fai

ai

in

a

e

conditionally independent of each other and depend only 
on the aligned source word    .

f

thursday, january 24, 13

tuesday, october 27, 15

lexical translation

p(e | f, m)

    goal: a model
    where    and    are complete english and foreign sentences
f
    lexical translation makes the following assumptions:

e

f

e

in

ei

    each word in     in    is generated from exactly one word 
    thus, we have an alignment     that indicates which word
    given the alignments    , translation decisions are 

ei
        came from   , speci   cally it came from       .
fai

conditionally independent of each other and depend only 
on the aligned source word      .
fai

ai

a

thursday, january 24, 13

tuesday, october 27, 15

lexical translation
e = he1, e2, ...emi
f = hf1, f2, ...fni
a = ha1, a2, ...ami each ai 2 {0, 1, ..., n}

    putting our assumptions together, we have:
p(e | f, m) = xa2[0,n]m
p(e | f , m) xa2{0,1,..,n}m

p(a | f , m)    

p(a | f, m)    

modeling assumptions

p(ei | fai)

p(ei | fai)

myi=1

myi=1

=

alignment translation | alignment
[alignment]  x  [translation | alignment]

   

thursday, january 24, 13

tuesday, october 27, 15

alignment

p(a | f, m)

most of the action for the    rst 10 years
of mt was here. words weren   t the problem,
word order was hard.

thursday, january 24, 13

tuesday, october 27, 15

alignment

    alignments can be visualized in by drawing 
links between two sentences, and they are 
represented as vectors of positions:

a = (1, 2, 3, 4)>

thursday, january 24, 13

tuesday, october 27, 15

reordering
    words may be reordered during 

translation.

a = (3, 4, 2, 1)>

thursday, january 24, 13

tuesday, october 27, 15

word dropping

    a source word may not be translated at all

a = (2, 3, 4)>

thursday, january 24, 13

tuesday, october 27, 15

word insertion

    words may be inserted during translation

english just does not have an equivalent
but it must be explained - we typically assume
every source sentence contains a null token

a = (1, 2, 3, 0, 4)>

thursday, january 24, 13

tuesday, october 27, 15

one-to-many translation
    a source word may translate into more 

than one target word

a = (1, 2, 3, 4, 4)>

thursday, january 24, 13

tuesday, october 27, 15

many-to-one translation
    more than one source word may 

not translate as a unit in lexical translation

1
das

2

haus

3

brach

4

zusammen

the
1

house

2

collapsed

3

a =???

[ibm model 1 can   t do this]

thursday, january 24, 13

tuesday, october 27, 15

ibm model 1

    simplest possible lexical translation model
    additional assumptions
    the m alignment decisions are independent
    the alignment distribution for each    is uniform 

ai

over all source words and null

for each i 2 [1, 2, . . . , m]

ai     uniform(0, 1, 2, . . . , n)
ei     categorical(   fai

)

thursday, january 24, 13

tuesday, october 27, 15

ibm model 1
for each i 2 [1, 2, . . . , m]

ai     uniform(0, 1, 2, . . . , n)
ei     categorical(   fai

)

p(e, a | f, m) =

myi=1

thursday, january 24, 13

tuesday, october 27, 15

ibm model 1
for each i 2 [1, 2, . . . , m]

ai     uniform(0, 1, 2, . . . , n)
ei     categorical(   fai

)

p(e, a | f, m) =

myi=1

1

1 + n

thursday, january 24, 13

tuesday, october 27, 15

ibm model 1
for each i 2 [1, 2, . . . , m]

ai     uniform(0, 1, 2, . . . , n)
ei     categorical(   fai

)

p(e, a | f, m) =

myi=1

1

1 + n

p(ei | fai)

thursday, january 24, 13

tuesday, october 27, 15

example

0

null

1
das

2

haus

3
ist

4

klein

1

2

3

4

   p(e | f):  assume a foreign sentence and target length.
= p(a | f)  p(e | a, f)

thursday, january 24, 13

tuesday, october 27, 15

example

0

null

1
das

2

haus

3
ist

4

klein

1

2

3

4

   p(e | f):  assume a foreign sentence and target length.
= p(a | f)  p(e | a, f)

thursday, january 24, 13

tuesday, october 27, 15

example

0

null

1
das

2

haus

3
ist

4

klein

1

2

3

the
4

   p(e | f):  assume a foreign sentence and target length.
= p(a | f)  p(e | a, f)

thursday, january 24, 13

tuesday, october 27, 15

example

0

null

1
das

2

haus

3
ist

4

klein

1

2

3

the
4

   p(e | f):  assume a foreign sentence and target length.
= p(a | f)  p(e | a, f)

thursday, january 24, 13

tuesday, october 27, 15

example

0

null

1
das

2

haus

3
ist

4

klein

house

1

2

3

the
4

   p(e | f):  assume a foreign sentence and target length.
= p(a | f)  p(e | a, f)

thursday, january 24, 13

tuesday, october 27, 15

example

0

null

1
das

2

haus

3
ist

4

klein

house

1

2

3

the
4

   p(e | f):  assume a foreign sentence and target length.
= p(a | f)  p(e | a, f)

thursday, january 24, 13

tuesday, october 27, 15

example

0

null

1
das

2

haus

3
ist

4

klein

house

1

is
2

the
4

3

   p(e | f):  assume a foreign sentence and target length.
= p(a | f)  p(e | a, f)

thursday, january 24, 13

tuesday, october 27, 15

example

0

null

1
das

2

haus

3
ist

4

klein

house

1

is
2

the
4

3

   p(e | f):  assume a foreign sentence and target length.
= p(a | f)  p(e | a, f)

thursday, january 24, 13

tuesday, october 27, 15

example

0

null

1
das

2

haus

3
ist

4

klein

house

1

is
2

small

3

the
4

   p(e | f):  assume a foreign sentence and target length.
= p(a | f)  p(e | a, f)

thursday, january 24, 13

tuesday, october 27, 15

a

arg max

learning lexical 
learning lexical 
ibm model 1: id136 and learning
    alignment id136:
translation models
translation models
given lexical translation probabilities,
infer posterior or viterbi alignment
    how do we learn the parameters
p(a | e, f,    )
    how do we learn the parameters
    translation: incorporate into noisy channel
       chicken and egg    problem
       chicken and egg    problem
p(e | f,    ) p(e)
    if we had the alignments, we could 
    if we had the alignments, we could 
    how do we learn translation parameters?
estimate the parameters (id113)
estimate the parameters (id113)
em algorithm (thursday)
    if we had parameters, we could    nd the 
    if we had parameters, we could    nd the 
p(e | f,    )
most likely alignments
most likely alignments
    chicken and egg problem:

(this model isn   t good at this)

p(e | f )
p(e | f )

arg max

arg max

   

e

if we knew alignments, translation 
parameters would be trivial (just counting)

thursday, january 24, 13

thursday, january 24, 13

tuesday, october 27, 15

48

