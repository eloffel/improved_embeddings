syntactic dependencies

cs 585, fall 2015

introduction to natural language processing

http://people.cs.umass.edu/~brenocon/inlp2015/

brendan o   connor

college of information and computer sciences

university of massachusetts amherst

friday, november 20, 15

    today:
    syntactic dependencies
    start on coreference
    longer distance graphs among words and 

phrases in a text.

friday, november 20, 15

2

dependencies

(vs. constituents)

friday, november 20, 15

3

prepositional attachment ambiguity

disambiguation
with lexical information

i ate some dessert with a fork.

s

np

vp

i

v

np

ate

np

pp

some dessert

with a fork

s

np

vp

i

v

np

pp

ate

some dessert

with a fork

    (p)id18 structural information doesn   t tell us much 
    lexical knowledge might help?  (or other knowledge?)

about which is more likely

    dessert -> with -> fork
    ate -> with -> fork

    intuitively: a notion of modi   cation or argument structure.
both are grammatical; is syntax enough to disambiguate?

friday, november 20, 15

4

constits -> deps

    syntactic theory:  every phrase has a head word.  it 
carries the primary syntactic (semantic?) properties of 
the phrase.
    head rules:  for every nonterminal in tree, choose one 
    very simple example:

of its children to be its    head   .

    np -> adj np*
    np -> np* pp
    pp -> prep* np

friday, november 20, 15

5

head rules
s -> np vp*
vp -> v* np
np -> det np*

s

np

vp

dt

the

nn

lawyer

vt

np

questioned

dt

the

nn

witness

rules more complicated for 
nonbinary expansions,
allowing multiple non-heads, e.g.
vp ->  v* pp pp

+

s(questioned)

np(lawyer)

vp(questioned)

dt(the)

nn(lawyer)

the

lawyer

6

vt(questioned)

np(witness)

questioned

dt(the)

nn(witness)

the

witness

friday, november 20, 15

dependency syntax

constits -> deps
connectedness, acyclicity and single-head

    head rules can be used to add words into pid18 nonterminals 

i intuitions:

eat-with-fork vs dessert-with-fork

(   lexicalized pid18s   )
    helps a lot for attachment disambiguation
    or -- why not use dependency graph directly?
i syntactic structure is complete (connectedness).
i syntactic structure is hierarchical (acyclicity).
    grammatical relations are between individual words
i every word has at most one syntactic head (single-head).
    graph is acyclic, connected, with a single root.

i connectedness can be enforced by adding a special root node.

root

p

dobj

amod

nsubj

amod

prep

pmod

amod

root economic news had little e   ect on    nancial markets .
.
root

noun verb adj

noun prep

noun

adj

adj

friday, november 20, 15

7

head rules
s -> np vp*
vp -> v* np
np -> det np*

s

np

vp

dt

the

nn

lawyer

vt

np

questioned

dt

the

nn

witness

graph conversion: (12.7.1):
the head of each non-head-child
is subordinate to the
head of the head-child.

+

s(questioned)

np(lawyer)

vp(questioned)

dt(the)

nn(lawyer)

the

lawyer

8

vt(questioned)

np(witness)

questioned

dt(the)

nn(witness)

the

witness

friday, november 20, 15

constits -> deps

based) constit->deps converter

    two ways to parse to dependencies:
    run a constit parser, then run a (typically rule-
    direct id33
    dependencies useful for many applications
    dependency annotations are available for more 
languages ... perhaps better suited for a wider 
variety of languages  (e.g. free word order)

friday, november 20, 15

9

dependency parse
    edges between core words
    dag (sometimes tree).  options to expand coordination, etc.

bell, based in los angeles,
makes and distributes
electronic, computer and building 
products.

makes

  conj_and

nsubj

distributes

  dobj

nsubj

dobj

bell

products

  partmod

  amod

based

amod

electronic

amod

  prep_in

conj_and

  conj_and

angeles

computer

building

  nn

los

10

    x --relation--> y  graph edge
e.g.  nsubj(makes, bell)
    x: governor, head (parent...)
    y: dependent, modi   er, subordinate 

(child...)

    grammatical relations: see    stanford 
dependencies manual   
    nsubj: nominal subject
    dobj: direct object
    prep_x: prepositional argument
    amod: adjective modi   er
    ...
    using the graph: word-relation-word 
edges, paths, subgraphs...

figure 1: graphical representation of the stanford dependencies for the sentence: bell, based in los

friday, november 20, 15

dependency paths
    information extraction with long(er)-distance 

connections.  skip over modi   ers and subclauses.

<--nsubj-- meet --prep--> with --pobj-->
   x  meets with  y   

of   cials <--nsubj-- meet --prep--> with --pobj--> counterparts

british <--amod-- (np) <--nsubj-- meet --prep--> with --pobj--> (np) --pobj--> iranian

friday, november 20, 15

11

[]

[]

middle

feature type

left window

[astronomer]

right window

lexical
lexical
lexical
syntactic
syntactic
syntactic
syntactic
syntactic
syntactic
syntactic
syntactic
syntactic

dependency paths
    information extraction with long(er)-distance 

[was/verb born/verb in/closed]
[was/verb born/verb in/closed]
[was/verb born/verb in/closed]
[*s was +pred born +mod in +pcomp n]
[*s was +pred born +mod in +pcomp n]
[*s was +pred born +mod in +pcomp n]
[*s was +pred born +mod in +pcomp n]
[*s was +pred born +mod in +pcomp n]
[*s was +pred born +mod in +pcomp n]
[*s was +pred born +mod in +pcomp n]
[*s was +pred born +mod in +pcomp n]
task:  get features which describe
[*s was +pred born +mod in +pcomp n]

[#pad#, astronomer]
[edwin hubble +lex mod]
[astronomer +lex mod]
[edwin hubble +lex mod]
[astronomer +lex mod]
[edwin hubble +lex mod]
[astronomer +lex mod]
the    x was born in y    semantic relation

connections.  skip over modi   ers and subclauses.

ne2
loc
loc
loc
loc
loc
loc
loc
loc
loc
loc [+inside missouri]
loc [+inside missouri]
loc [+inside missouri]

table 3: features for    astronomer edwin hubble was born in marsh   eld, missouri   .

ne1
per
per
per
per
per
per
per
per
per
per
per
per

[+lex mod ,]
[+lex mod ,]
[+lex mod ,]

[, missouri]

[]
[]
[]

[]
[,]

[]

[]

lex-mod

s

pred

mod

pcomp-n

lex-mod

inside

astronomer

edwin hubble

was

born

in

marsh   eld

,

missouri

[]

[]
[,]

middle

left window

[astronomer]

right window

ne1
per
per
per
per
per
per
per
per
per
per
per
per

[#pad#, astronomer]
[edwin hubble +lex mod]
[astronomer +lex mod]
[edwin hubble +lex mod]
[astronomer +lex mod]
[edwin hubble +lex mod]
[astronomer +lex mod]

feature type
figure 1: dependency parse with dependency path from    edwin hubble    to    marsh   eld    highlighted in
lexical
boldface.
lexical
lexical
syntactic
syntactic
syntactic
syntactic
syntactic
syntactic
syntactic
syntactic
syntactic

[]
5.2 syntactic features
in addition to lexical features we extract a num-
[]
ber of features based on syntax. in order to gener-
ate these features we parse each sentence with the
broad-coverage dependency parser minipar (lin,
1998).

[was/verb born/verb in/closed]
[was/verb born/verb in/closed]
[was/verb born/verb in/closed]
[*s was +pred born +mod in +pcomp n]
[*s was +pred born +mod in +pcomp n]
[*s was +pred born +mod in +pcomp n]
[*s was +pred born +mod in +pcomp n]
[*s was +pred born +mod in +pcomp n]
[*s was +pred born +mod in +pcomp n]
[*s was +pred born +mod in +pcomp n]
[*s was +pred born +mod in +pcomp n]
[*s was +pred born +mod in +pcomp n]

ne2
loc
loc
loc
loc
loc
loc
loc
loc
loc
loc [+inside missouri]
loc [+inside missouri]
loc [+inside missouri]

[]
5.3 named entity tag features
[]
[]
every feature contains, in addition to the content
described above, named entity tags for the two en-
tities. we perform named entity tagging using the
stanford four-class named entity tagger (finkel et
al., 2005). the tagger provides each word with a
label from {person, location, organization, miscel-
laneous, none}.
5.4 feature conjunction

a dependency parse consists of a set of words
and chunks (e.g.
   edwin hubble   ,    missouri   ,
12
   born   ), linked by directional dependencies (e.g.
   pred   ,    lex-mod   ), as in figure 1.
for each

table 3: features for    astronomer edwin hubble was born in marsh   eld, missouri   .

[+lex mod ,]
[+lex mod ,]
[+lex mod ,]

[, missouri]

pcomp-n

lex-mod

lex-mod

inside

pred

mod

[]

s

friday, november 20, 15

dependency paths

character evidence

    rule-based semantic id36
typed dependency 
information anchored 
on each character.

agent

agent

luke watches as vader kills kenobi

patient

agent

luke runs away

agent patient

the soldiers shoot at him

friday, november 20, 15

13

dependency paths

character evidence

    rule-based semantic id36
typed dependency 
information anchored 
and objects denote 
on each character.
arguments in an event

    e.g. assume a verb   s subjects 

agent

luke watches as vader kills kenobi

agent

patient

agent

luke runs away

agent patient

the soldiers shoot at him

friday, november 20, 15

13

dependency paths

character evidence

    rule-based semantic id36
typed dependency 
information anchored 
and objects denote 
on each character.
arguments in an event

    e.g. assume a verb   s subjects 

agent

luke watches as vader kills kenobi

agent

patient

    but gets complicated 

(syntax-semantics interface)

agent

luke runs away

agent patient

the soldiers shoot at him

friday, november 20, 15

13

dependency paths

character evidence

    rule-based semantic id36
typed dependency 
information anchored 
and objects denote 
on each character.
arguments in an event

    e.g. assume a verb   s subjects 

agent

luke watches as vader kills kenobi

agent

patient

    but gets complicated 
(syntax-semantics interface)
       the death star   s 

destruction   

agent

luke runs away

agent patient

the soldiers shoot at him

friday, november 20, 15

13

should you use a parser in your project?

    dependency id165s as features
    e.g. dep bigrams (word, rel, word)
    parsers performance and ef   ciency varies
       shift-reduce    or    incremental    dependency 
    performance: is your data similar to newswire text?  

parsers: tend to be fastest, currently

(the usual training data)

friday, november 20, 15

14

