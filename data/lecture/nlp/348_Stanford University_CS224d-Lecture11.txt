cs224d:	deep	nlp

lecture	11:

advanced	recursive	neural	networks

richard	socher

richard@metamind.io

    pset2	please	read	instructions	for	submissions
    please	followpiazza for	questions	and	announcements
    because	of	some	ambiguities	in	pset2,	we	will	be	lenient	in	

grading.	tf	is	a	super	useful	skill.

   

if	re-grade	question	or	request,	please	come	to	office	hours	or	
send	a	message	on	piazza.

    to	improve	learning	and	your	experience,	we	will	publish	

solutions	to	psets.

lecture	1,	slide	2

richard	socher

5/5/16

recursive	neural	networks
    focused	on	compositional	representation	learning	of	
    hierarchical	structure,	features	and	predictions
    different	combinations	of:
1. training	objective

2. composition	function

v
wscore

w

s
p

c1

c2

3. tree	structure

overview

last	lecture:	recursive	neural	networks

this	lecture:	different	id56	composition	functions	and	nlp	tasks

1.

standard	id56s:

2. matrix-vector	id56s:	

paraphrase	detection

relation	classification

3. recursive	neural	tensor	networks:	

sentiment	analysis

4.

tree	lstms:

phrase	similarity

next	lecture
   

review	for	midterm.	going	over	common	problems/questions	from	office	
hours.	please	prepare	questions.

4

richard	socher

5/5/16

applications	and	models
    note:	all	models	can	be	applied	to	all	tasks

    more	powerful	models	are	needed	for	harder	tasks

    models	get	increasingly	more	expressive	and	powerful:
1. standard	id56s:
2. matrix-vector	id56s:	
3. recursive	neural	tensor	networks:	
4. tree	lstms:

paraphrase	detection
relation	classification
sentiment	analysis
phrase	similarity

lecture	1,	slide	5

richard	socher

5/5/16

paraphrase	detection

pollack	said	the	plaintiffs	failed	to	show	that	merrill	and	
blodget directly	caused	their	losses
basically	,	the	plaintiffs	did	not	show	that	omissions	in	
merrill   s	research	caused	the	claimed	losses

the	initial	report	was	made	to	modesto	police	december	
28
it	stems	from	a	modesto	police	report
6

how	to	compare

the	meaning

of	two	sentences?

7

id56s	for	paraphrase	detection

unsupervised	id56s	and	a	pair-wise	sentence	comparison	of	nodes	
in	parsed	trees	(socher	et	al.,	nips	2011)

8

id56s	for	paraphrase	detection
experiments	on	microsoft	research	paraphrase	corpus	
(dolan	et	al.	2004)
method
rus et	al.(2008)
mihalcea	et	al.(2006)
islam	et	al.(2007)
qiu et	al.(2006)	
fernando	et	al.(2008)
wan	et	al.(2006)
das	and	smith	(2009)	
das	and	smith	(2009)	+	18	surface	features
f.	bu	et	al.	(acl	2012):	string	re-writing	kernel
unfolding	recursive	autoencoder	 (nips	2011)

acc.
70.6
70.3
72.6
72.0
74.1
75.6
73.9
76.1
76.3
76.8

f1
80.5
81.3
81.3
81.6
82.4
83.0
82.3
82.7
--
83.6

9

dataset	is	problematic,	a	better	evaluation	is	introduced	later

id56s	for	paraphrase	detection

10

recursive	deep	learning

1. standard	id56s:
2. matrix-vector	id56s:	
3. recursive	neural	tensor	networks:	
4. tree	lstms:

paraphrase	detection
relation	classification
sentiment	analysis
phrase	similarity

11

compositionality	through	recursive	matrix-vector	spaces

p		=		tanh(w							+	b)

c1
c2

one	way	to	make	the	composition	function	more	powerful	was	by	
untying	the	weights	w

but	what	if	words	act	mostly	as	an	operator,	e.g.	   very   	in

very	good

proposal:	a	new	composition	function

12

compositionality	through	recursive	matrix-vector	
recursive	neural	networks

p		=		tanh(w							+	b)

c1
c2

p		=		tanh(w												+	b)

c2c1
c1c2

13

predicting	sentiment	distributions
good	example	for	non-linearity	in	language

14

mv-id56	for	relationship	classification

relationship	

cause-
effect(e2,e1)

entity-
origin(e1,e2)

message-
topic(e2,e1)

15

sentence	with	labeled	nouns	for	which	
to	predict	relationships
avian	[influenza]e1 is	an	infectious	
disease	caused	by	type	a	strains	of	the	
influenza	[virus]e2.
the	[mother]e1 left	her	native	[land]e2
about	the	same	time	and	they	were	
married	in	that	city.
roadside	[attractions]e1 are	frequently	
advertised	with	[billboards]e2 to	attract	
tourists.

sentiment	detection

sentiment	detection	is	crucial	to	business	
intelligence,	stock		trading,	   

16

sentiment	detection	and	bag-of-words	models

most	methods	start	with	a	bag	of	words
+	linguistic	features/processing/lexica

but	such	methods	(including	tf-idf)	can   t	
distinguish:

+	white	blood	cells	destroying	an	infection
   	an	infection	destroying	white	blood	cells

17

sentiment	detection	and	bag-of-words	models

    sentiment	is	that	sentiment	is	   easy   
    detection	accuracy	for	longer	documents	   90%
    lots	of	easy	cases	(   	horrible	   	or	   	awesome    )
    for	dataset	of	single	sentence	movie	reviews	
(pang	and	lee,	2005)		accuracy	never	reached	
above	80%	for	>7	years

    harder	cases	require	actual	understanding	of	
negation	and	its	scope	+	other	semantic	effects

data:	movie	reviews

stealing	harvard	doesn   t	care	about	
cleverness,	wit	or	any	other	kind	of	
intelligent	humor.

there	are	slow	and	repetitive	parts	
but	it	has	just	enough	spice	to	keep	it	
interesting.

19

two	missing	pieces	for	improving	sentiment

1. compositional	training	data

2. better	compositional	model

1.	new	sentiment	treebank	

1.	new	sentiment	treebank	
    parse	trees	of	11,855	sentences
    215,154	phrases	with	labels
    allows	training	and	evaluating	
with	compositional	information

better	dataset	helped	all	models
    positive/negative	full	sentence	classification

84
83
82
81
80
79
78
77
76
75

bi	nb
id56
mv-id56

training	with	treebank

training	with	sentence	

labels

    but	hard	negation	cases	are	still	mostly	incorrect
    we	also	need	a	more	powerful	model!

better	dataset	helped
    this	improved	performance	for	full	sentence	
positive/negative	classification	by	2	    3	%

    yay!

    but	a	more	in	depth	analysis	shows:	hard	
negation	cases	are	still	mostly	incorrect

    we	also	need	a	more	powerful	model!

2.	new	compositional	model
    recursive	neural	tensor	network
    more	expressive	than	previous	id56s
   

idea:	allow	more	interactions	of	vectors

2.	new	compositional	model
    recursive	neural	tensor	network

2.	new	compositional	model
    recursive	neural	tensor	network

recursive	neural	tensor	network
recursive	deep	models	for	semantic	compositionality	over	a	sentiment	treebank	
socher	et	al.	2013

@vi = ( ii   a)+@(a)vi

2.4.1 first order

2.4 derivatives of matrices, vectors and scalar forms

details:	tensor	id26 training
    main	new	matrix	derivative	

@xt a
needed	for	a	tensor:
@x
@at xb

@at x
@x

=

= abt

= a

@x

@at xt b

@x
@at xa

@x

@x
@xij
@(xa)ij
@xmn
@(xt a)ij

@xmn

= bat

=

@at xt a

@x

= jij

= aat

=  im(a)nj = (jmna)ij

=  in(a)mj = (jnma)ij

(69)

(70)

(71)

(72)

(73)

(74)

(75)

petersen & pedersen, the matrix cookbook, version: november 15, 2012, page 10

details:	tensor	id26 training
    minimizing	cross	id178	error:

    standard	softmax error	message:

    for	each	slice,	we	have	update:	
    main	backprop rule	to	pass	error	down	from	parent:

    finally,	add	errors	from	parent	and	current	softmax:	

positive/negative	results	on	treebank
classifying	sentences:	accuracy	improves	to	85.4
86

84

82

80

78

76

74

training	with	sentence	labels

training	with	treebank

bi	nb
id56
mv-id56
rntn

fine	grained	results	on	treebank

negation	results

negation	results
    most	methods	capture	that	negation	often	makes	

things	more	negative	(see	potts,	2010)

    analysis	on	negation	dataset
    accuracy:

results	on	negating	negatives
    but	how	about	negating	negatives?
    no	flips,	but	positive	activation	should	increase!

not								bad

results	on	negating	negatives
    evaluation:	positive	activation	should	increase

37

visualizing	deep	learning:	word	embeddings

lstms
    remember	lstms?

    historically	only	over	temporal	sequences

we	used

lecture	1,	slide	39

richard	socher

5/5/16

tree	lstms
    we	can	use	those	ideas	in	
grammatical	tree	structures!

    paper:	tai	et	al.	2015:

improved	semantic	representations	from
tree-structured	long	short-term	memory	networks	

   

idea:	sum	the	child	vectors
in	a	tree	structure

    each	child	has	its	own	

forget	gate

    same	softmax on	h

lecture	1,	slide	40

richard	socher

5/5/16

results	on	stanford	sentiment	treebank	

method
rae (socher et al., 2013)
mv-id56 (socher et al., 2013)
rntn (socher et al., 2013)
did98 (blunsom et al., 2014)
paragraph-vec (le and mikolov, 2014)
id98-non-static (kim, 2014)
id98-multichannel (kim, 2014)
did56 (irsoy and cardie, 2014)
lstm
bidirectional lstm
2-layer lstm
2-layer bidirectional lstm
constituency tree lstm (no tuning)
constituency tree lstm

fine-grained binary
82.4
82.9
85.4
86.8
87.8
87.2
88.1
86.6
86.7
86.8
85.5
84.8
86.6
86.9

43.2
44.4
45.7
48.5
48.7
48.0
47.4
49.8
45.8
49.1
47.5
46.2
46.7
50.6

lecture	1,	slide	41

table 2: test set accuracies on the stanford senti-
ment treebank. fine-grained: 5-class sentiment
5/5/16
classi   cation. binary: positive/negative senti-

richard	socher

method
mean vectors
dt-id56 (socher et al., 2014)
sdt-id56 (socher et al., 2014)
illinois-lh (lai and hockenmaier, 2014)
unal-nlp (jimenez et al., 2014)
meaning factory (bjerva et al., 2014)
ecnu (zhao et al., 2014)
lstm
bidirectional lstm
2-layer lstm
2-layer bidirectional lstm
constituency tree lstm
dependency tree lstm

of	word	vectors

table 3: test set results on the sick semantic
relatedness subtask. the id74 are
pearson   s r, spearman   s    , and mean squared er-
ror. results are grouped as follows: (1) our own

semantic	similarity
    better	than	binary	paraphrase	classification!
    dataset	from	a	competition:

semeval-2014	task	1:	evaluation	of	compositional	distributional	
semantic	models	on	full	sentences	through	semantic	
relatedness	[and	textual	entailment]

relatedness score

example

1.6

2.9

3.6

4.9

a:    a man is jumping into an empty pool   
b:    there is no biker jumping in the air   

a:    two children are lying in the snow and are making snow angels   
b:    two angels are making snow on the lying children   

a:    the young boys are playing outdoors and the man is smiling nearby   
b:    there is no boy playing outdoors and there is no man smiling   

a:    a person in a black jacket is doing tricks on a motorbike   
b:    a man in a black jacket is doing tricks on a motorbike   

table 1: examples of sentence pairs with their gold relatedness scores (on a 5-point rating scale).

lecture	1,	slide	42

richard	socher

5/5/16

semantic	similarity	results	(correlation	and	mse)

method
mean vectors
dt-id56 (socher et al., 2014)
sdt-id56 (socher et al., 2014)
illinois-lh (lai and hockenmaier, 2014)
unal-nlp (jimenez et al., 2014)
meaning factory (bjerva et al., 2014)
ecnu (zhao et al., 2014)
lstm
bidirectional lstm
2-layer lstm
2-layer bidirectional lstm
constituency tree lstm
dependency tree lstm

pearson   s	r,	spearman   s	  

r

   

0.8046
0.7863
0.7886
0.7993
0.8070
0.8268
0.8414
0.8477
0.8522
0.8411
0.8488
0.8491
0.8627

0.7294
0.7305
0.7280
0.7538
0.7489
0.7721

   

0.7921
0.7952
0.7849
0.7926
0.7873
0.8032

mse
0.3595
0.3983
0.3859
0.3692
0.3550
0.3224

   

0.2949
0.2850
0.2980
0.2893
0.2852
0.2635

lecture	1,	slide	43

table 3: test set results on the sick semantic

the window [`   2, ` + 2]. examples in the tail
of the length distribution are batched in the    nal
semantic	similarity	results,	pearson	correlation
window (` = 45).

lecture	1,	slide	44

figure 4: pearson correlations r between pre-

richard	socher

5/5/16

468101214161820meansentencelength0.780.800.820.840.860.880.90rdeptree-lstmlstmbi-lstmconsttree-lstmnext	lecture:	midterm	review	session
    go	over	materials	with	different	viewpoints

    come	with	questions	!

lecture	1,	slide	45

richard	socher

5/5/16

