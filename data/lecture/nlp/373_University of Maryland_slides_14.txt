from id33
to imitation learning

cmsc 723 / ling 723 / inst 725

marine carpuat

fig credits: joakim nivre, yoav
goldberg, hal daume iii

today   s topics:
addressing compounding error

    improving on gold parse oracle

    research highlight: [goldberg & nivre, 2012]

    imitation learning for id170

    ciml ch 18

improving the oracle
in transition-based id33

    issues with oracle we   ve used so far

    based on configuration sequence that produces gold tree
    what if there are multiple sequences for a single gold tree?
    how can we recover if the parser deviates from gold sequence?

    goldberg & nivre [2012] propose an improved oracle

exercise:  which of these transition sequences 
produces the gold tree on the left?

stack

buffer

dependency 

arcs

arc from position j to position i, 

with dependency label l

which of these transition sequences 
does the oracle algorithm produce?

improving the oracle
in transition-based id33

    issues with oracle we   ve used so far

    based on configuration sequence that produces gold tree
    what if there are multiple sequences for a single gold tree?
    how can we recover if the parser deviates from gold sequence?

    goldberg & nivre [2012] propose an improved oracle

shift

at test time, suppose the 4th transition predicted is 
shift instead of raiobj
what happens if we apply the oracle next?

measuring distance from gold tree

    labeled attachment loss: number of arcs in gold tree that are not 

found in the predicted tree

loss = 3

loss = 1

improving the oracle
in transition-based id33

    issues with oracle we   ve used so far

    based on configuration sequence that produces gold tree
    what if there are multiple sequences for a single gold tree?
    how can we recover if the parser deviates from gold sequence?

    goldberg & nivre [2012] propose an improved oracle

proposed solution: 
2 key changes to training algorithm

any transition that can possibly 

lead to a correct tree is 

considered correct

explore non-optimal transitions

proposed solution: 
2 key changes to training algorithm

defining the cost of a transition

    loss difference between minimum loss trees achievable before and 

after transition

    loss for trees nicely decomposes into losses for arcs

    we can compute transition cost by counting gold arcs that are no longer 

reachable after transition

today   s topics
addressing compounding error

    improving on gold parse oracle

    research highlight: [goldberg & nivre, 2012]

    imitation learning for id170

    ciml ch 18

imitation learning
aka learning by demonstration 

    sequential decision making problem

    at each point in time      

    receive input information         
    take action         
    suffer loss         
    move to next time step until time t

    goal

    learn a policy function     (        ) =         
    that minimizes expected total loss over all trajectories enabled by f

supervised imitation learning

supervised imitation learning

problem with 

supervised approach:
compounding error

how can we train system to make better 
predictions off the expert path?

    we want a policy f that leads to good performance in configurations 

that f encounters

    a chicken and egg problem

    can be addressed by iterative approach

dagger: simple & effective imitation 
learning via data aggregation

requires interaction 

with expert!

when is dagger used in practice?

    interaction with expert is not always possible

    classic use case

    expert = slow algorithm
    use dagger to learn a faster algorithm that imitates expert
    example: game playing where expert = brute-force search in simulation mode 

    but also id170

sequence labeling via imitation learning

    what is the    expert    here?

    given a id168 (e.g., hamming loss)
    expert takes action that minimizes long-term loss

output prefix 

at time t

loss of best reachable 
output starting with 

prefix                

    when expert can be computed exactly, it is called an 

oracle

    key advantages 

    can define features
    no restriction to markov features

today   s topics

    improving on gold parse oracle

    research highlight: [goldberg & nivre, 2012]

    imitation learning for id170

    ciml ch 18

