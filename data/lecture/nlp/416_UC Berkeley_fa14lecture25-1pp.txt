natural  language  processing

diachronics

dan  klein      uc  berkeley

includes  joint  work  with  alex  bouchard   cote,  tom  griffiths,  and  david  hall

12/1/2014

1

the  task

12/1/2014

2

lexical  reconstruction

latin
focus

french

feu

spanish
fuego

italian
fuoco

portuguese

fogo

12/1/2014

3

tree  of  languages

    we  assume  the  

phylogeny  is  known
    much  work  in  

biology,  e.g.  work  by  
warnow,  felsenstein,  
steele   

    also  in  linguistics,  e.g.  

warnow et  al.,  gray  
and  atkinson   

http://andromeda.rutgers.edu/~jlynch/language.html

12/1/2014

4

evolution  through  sound  changes

12/1/2014

eng.  camera  from  latin,  

   camera  obscura   

latin

camera /kamera/
deletion: /e/, /a/ 
change: /k/ .. /t   / .. /   /

insertion: /b/

french

chambre /   amb  /

eng.  chamber  from  old  fr.  
before  the  initial /t/ dropped

5

changes  are  systematic

camera /kamera/

numerus /numerus/

e     _

e     _

camra /kamra/

numrus /numrus/

12/1/2014

6

changes  are  contextual

camera /kamera/

e     _
e     _  /  after  stress

camra /kamra/

12/1/2014

7

changes  have  structure

camra /kamra/

_     b
_     b  /  m_r
_     [stop  x]  /  [nasal  x]_r

cambra /kambra/

12/1/2014

8

changes  are  systematic

english  great  vowel  shift  (simplified!)

   time     =  teem

   time     =  taim

i

e

a

12/1/2014

9

diachronic  evidence

yahoo!  answers  [ca  2000]

appendix  probi [ca  300]

tonight  not  tonite

tonitru non  tonotru

12/1/2014

10

synchronic  (comparative)  evidence

key  idea:  changes  occur  uniformly  across  the  lexicon

12/1/2014

11

the  data

12/1/2014

12

the  data

    data  sets

    small:  romance

    french,  italian,  portuguese,  spanish
    2344  words
    complete  cognate  sets
    target:  (vulgar)  latin

fr it

pt

es

12/1/2014

13

the  data

    data  sets

    small:  romance

    french,  italian,  portuguese,  spanish
    2344  words
    complete  cognate  sets
    target:  (vulgar)  latin

    large:  austronesian

    637  languages
    140k  words
    incomplete  cognate  sets
    target:  proto   austronesian

fr it

pt

es

12/1/2014

14

austronesian

12/1/2014

15

austronesian  examples

from  the  austronesian  basic  vocabulary  database

12/1/2014

16

the  model

12/1/2014

17

12/1/2014

simple  model:  single  characters

g

g

c

g

cg

cc

cc

gg

[cf.  felsenstein 81]

18

changes  are  systematic

/fokus/
/fokus/
/kentrum/

/fogo/
/fogo/
/sentro/

/fw   ko/
/fw   ko/
/t     ntro/

/fwe  o/
/fwe  o/
/sentro/

/fogo/
/fogo/
/sentro/

12/1/2014

19

12/1/2014

parameters  are  branch   specific

   es

   it

la

focus 
/fokus/

ib

/fogo/

   ib

   pt

fuoco 
/fw   ko/

fuego 
/fwe  o/

fogo 
/fogo/

it                   es                   pt

[bouchard   cote,  griffiths,  klein,  07]

20

edits  are  contextual,  structured

#

#

f

f

o

w    

/fokus/

   it

/fw   ko/

12/1/2014

21

id136

12/1/2014

22

learning:  objective

z

w

/fokus/

/fogo/

/fw   ko/

/fwe  o/

/fogo/

12/1/2014

23

learning:  em
    m   step

    find  parameters  which  fit  
(expected)  sound  change  
counts

    easy:  gradient  ascent  on  

theta

    e   step

    find  (expected)  change  
counts  given  parameters
    hard:  variables  are  string   

valued

/fokus/

/fogo/

/fw   ko/

/fwe  o/

/fogo/

/fokus/

/fogo/

/fw   ko/

/fwe  o/

/fogo/

12/1/2014

24

computing  expectations

standard  approach,  e.g.  [holmes  2001]:  
gibbs  sampling  each  sequence

   grass   

[holmes  01,  bouchard   cote,  griffiths,  klein  07]

12/1/2014

25

12/1/2014

a  gibbs  sampler

   grass   

26

12/1/2014

a  gibbs  sampler

   grass   

27

12/1/2014

a  gibbs  sampler

   grass   

28

getting  stuck

?

how  could  we  jump  to  a  state  where  
the  liquids /r/ and  /l/ have  a  common  

ancestor?

12/1/2014

29

getting  stuck

12/1/2014

30

efficient  sampling:  vertical  slices

12/1/2014

single  
sequence  
resampling

ancestry  
resampling

[bouchard   cote,  griffiths,  klein,  08]

31

results

12/1/2014

32

results:  romance

12/1/2014

33

learned  rules  /  mutations

12/1/2014

34

learned  rules  /  mutations

12/1/2014

35

results:  austronesian

12/1/2014

36

12/1/2014

examples:  austronesian

[bouchard   cote,  hall,  griffiths,  klein,  13]

37

result:  more  languages  help

distance  from  blust [1993]  reconstructions

e
c
n
a
t
s
i
d
  
t
i
d
e
n
a
e
m

  

number  of  modern  languages  used

12/1/2014

38

visualization:  learned  universals

*the  model  did  not have  features  encoding  natural  classes

12/1/2014

39

regularity  and  functional  load

in  a  language,  some  pairs  of  sounds  are  more  
contrastive than  others  (higher  functional  load)

example: english  p/d versus  t/th

high  load:  p/d:    pot/dot,  pin/din

dress/press,  pew/dew,  ...

low  load:  t/th:    thin/tin

12/1/2014

40

functional  load:  timeline

1955:  functional  load  hypothesis  (flh): sound  changes  are  

less  frequent  when  they  merge  phonemes  with  high  
functional  load        [martinet,  55]

1967:  previous  research  within  linguistics:     flh  does  not  

seem  to  be  supported  by  the  data     [king,  67]  (based  on  4  
languages  as  noted  by  [hocket,  67;  surandran et  al.,  06])

our  approach: we  reexamined  the  question  with  two  orders  
of  magnitude  more  data  [bouchard   cote,  hall,  griffiths,  
klein,  13]

12/1/2014

41

regularity  and  functional  load

data: only  4 languages  from  the  austronesian  data

y
t
i
l
i

b
a
b
o
r
p
  
r
o
i
r
e
t
s
o
p
  
r
e
g
r
e
m

each  dot  is  a  sound  change  
identified  by  the  system

functional  load  as  computed  by  [king,  67]

12/1/2014

42

regularity  and  functional  load

data: all  637 languages  from  the  austronesian  data

y
t
i
l
i

b
a
b
o
r
p
  
r
o
i
r
e
t
s
o
p
  
r
e
g
r
e
m

functional  load  as  computed  by  [king,  67]

12/1/2014

43

extensions

12/1/2014

44

12/1/2014

cognate  detection

   

   fire   

/fw   ko/

/v  rbo/

/t     ntro/

/sentro/

/ber  o/

/fwe  o/

/v  rbo/

/fogo/

/s  ntro/

[hall  and  klein,  11]

45

12/1/2014

grammar  induction

avg rel gain:  29%  

ie

gl

rm

g

wg

ng

h
s

i
l

g
n
e

h
c
t

u
d

i

h
s
n
a
d

i

h
s
d
e
w
s

i

h
s
n
a
p
s

e
s
e
u
g
u

t
r
o
p

e
n
e
v
o
s

l

e
s
e
n
h
c

i

[berg   kirkpatrick  and  klein,  07]

46

70
60
50
40
30
20
10
0

12/1/2014

language  diversity

why  are  the  languages  of  the  world  so  similar?

universal  grammar  answer:  hardware  constraints

common  source  answer:  not  much  time  has  passed

[rafferty,  griffiths,  and  klein,  09]

47

