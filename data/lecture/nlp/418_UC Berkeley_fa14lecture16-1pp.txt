natural  language  processing

compositional  semantics

dan  klein      uc  berkeley

1

truth   conditional  semantics

2

truth   conditional  semantics

s

sings(bob)

vp

sings

np

bob

    linguistic  expressions:

       bob  sings   

    logical  translations:

    sings(bob)
    could  be  p_1218(e_397)

    denotation:

    [[bob]]  =  some  specific  person  (in  some  context)
    [[sings(bob)]]  =  ???

    types  on  translations:

    bob  :  e  
    sings(bob)  :  t

(for  entity)
(for  truth   value)

3

truth   conditional  semantics

    proper  names:

    refer  directly  to  some  entity  in  the  world
    bob  :  bob                    [[bob]]w     ???

    sentences:

    are  either  true  or  false  (given

how  the  world  actually  is)

    bob  sings :  sings(bob)

s

sings(bob)

vp

sings

   y.sings(y)

np

bob
bob

    so  what  about  verbs  (and  verb  phrases)?

    sings must  combine  with  bob to  produce  sings(bob)
    the        calculus  is  a  notation  for  functions  whose  arguments  are  not  yet  

    sings  :     x.sings(x)
    this  is  predicate     a  function  which  takes  an  entity  (type  e)  and  

produces  a  truth  value  (type  t).    we  can  write  its  type  as  e   t.

filled.

    adjectives?

4

compositional  semantics

    so  now  we  have  meanings  for  the  words
    how  do  we  know  how  to  combine  words?
    associate  a  combination  rule  with  each  grammar  rule:

    s  :     (   )     np  :      vp  :     
    vp  :     x  .     (x)         (x)     vp  :     and  :      vp  :      (intersection)

(function  application)

    example:

sings(bob)     dances(bob)
[   x.sings(x)     dances(x)](bob)

s

vp

and

vp

   x.sings(x)     dances(x)

vp

sings

   y.sings(y)

dances

   z.dances(z)

np

bob
bob

5

denotation

    what  do  we  do  with  logical  translations?

    translation  language  (logical  form)  has  fewer  ambiguities
    can  check  truth  value  against  a  database

    denotation  (   evaluation   )  calculated  using  the  database
    more  usefully:  assert  truth  and  modify  a  database
    questions:  check  whether  a  statement  in  a  corpus  entails  

the  (question,  answer)  pair:
       bob  sings  and  dances            who  sings?     +     bob   

    chain  together  facts  and  use  them  for  comprehension

6

other  cases

    transitive  verbs:

    likes :     x.   y.likes(y,x)
    two   place  predicates  of  type  e   (e   t).
    likes  amy :     y.likes(y,amy) is  just  like  a  one   place  predicate.

    quantifiers:

    what  does     everyone     mean  here?
    everyone  :     f.   x.f(x)
    mostly  works,  but  some  problems

    have  to  change  our  np/vp  rule.
    won   t  work  for     amy  likes  everyone.   

       everyone  likes  someone.   
    this  gets  tricky  quickly!

   x.likes(x,amy)
[   f.   x.f(x)](   y.likes(y,amy))

s

np

vp

   y.likes(y,amy)

everyone
   f.   x.f(x)

vbp

likes

   x.   y.likes(y,x)

np

amy
amy

7

indefinites

    first  try

       bob  ate  a  waffle     :  ate(bob,waffle)
       amy  ate  a  waffle    :  ate(amy,waffle)

    can   t  be  right!

        x  :  waffle(x)      ate(bob,x)
    what  does  the  translation

of     a    have  to  be?
    what  about     the   ?
    what  about     every   ?

np

bob

s

vp

vbd

np

ate

a waffle

8

grounding

    grounding

with  actual  liking?

    so  why  does  the  translation  likes :     x.   y.likes(y,x) have  anything  to  do  

    it  doesn   t  (unless  the  denotation  model  says  so)
    sometimes  that   s  enough:  wire  up  bought  to  the  appropriate  entry  in  

a  database

    meaning  postulates

    insist,  e.g     x,y.likes(y,x)     knows(y,x)
    this  gets  into  lexical  semantics  issues

    statistical  version?

9

tense  and  events

    in  general,  you  don   t  get  far  with  verbs  as  predicates
    better  to  have  event  variables  e

       alice  danced    :  danced(alice)
        e  :  dance(e)      agent(e,alice)      (time(e)  <  now)

    event  variables  let  you  talk  about  non   trivial  tense  /  aspect  

structures
       alice  had  been  dancing  when  bob  sneezed   
        e,  e     :  

dance(e)      agent(e,alice)     
sneeze(e   )      agent(e   ,bob)     
(start(e)  <  start(e   )      end(e)  =  end(e   ))     
(time(e   )  <  now)

10

adverbs

    what  about  adverbs?

       bob  sings  terribly   
    terribly(sings(bob))?
    (terribly(sings))(bob)?
       e  present(e)      type(e,  
singing)      agent(e,bob)  
    manner(e,  terrible)  ?

    it   s  really  not  this  

simple   

np

bob

s

vp

vbp

advp

sings

terribly

11

propositional  attitudes

       bob  thinks  that  i  am  a  gummi  bear   

    thinks(bob,  gummi(me))  ?
    thinks(bob,     i  am  a  gummi  bear   )  ?
    thinks(bob,  ^gummi(me))  ?

    usual  solution  involves  intensions  (^x)  which  are,  roughly,  the  

set  of  possible  worlds  (or  conditions)  in  which  x is  true

    hard  to  deal  with  computationally

    modeling  other  agents  models,  etc
    can  come  up  in  simple  dialog  scenarios,  e.g.,  if  you  want  to  talk  about  

what  your  bill  claims  you  bought  vs.  what  you  actually  bought

12

trickier  stuff

    non   intersective  adjectives

    green  ball :     x.[green(x)      ball(x)]
    fake  diamond :     x.[fake(x)      diamond(x)]  ?

    generalized  quantifiers

   x.[fake(diamond(x))

    the  :     f.[unique   member(f)]
    all :     f.     g  [   x.f(x)      g(x)]
    most?
    could  do  with  more  general  second  order  predicates,  too  (why  worse?)

    the(cat,  meows),  all(cat,  meows)

    generics

       cats  like  naps   
       the  players  scored  a  goal   

    pronouns  (and  bound  anaphora)

   

   if  you  have  a  dime,  put  it in  the  meter.   

         the  list  goes  on  and  on!

13

multiple  quantifiers

    quantifier  scope

    groucho  marx  celebrates  quantifier  order  ambiguity:

   in  this  country  a  woman gives  birth  every  15  min.
our  job  is  to  find  that  woman  and  stop  her.   

    deciding  between  readings

       bob  bought  a  pumpkin  every  halloween   
       bob  uses  a  phone  as  an  alarm  each  morning   
    multiple  ways  to  work  this  out

    make  it  syntactic  (movement)
    make  it  lexical  (type   shifting)

14

modeling  uncertainty

    big  difference  between  statistical  disambiguation  and  statistical  

reasoning.

the scout saw the enemy soldiers with night goggles.

    with  probabilistic  parsers,  can  say  things  like     72%  belief  that  the  pp  

attaches  to  the  np.   

    that  means  that  probably the  enemy  has  night  vision  goggles.
    however,  you  can   t  throw  a  logical  assertion  into  a  theorem  prover with  

72%  confidence.

    use  this  to  decide  the  expected  utility  of  calling  reinforcements?

    in  short,  we  need  probabilistic  reasoning,  not  just  probabilistic  

disambiguation  followed  by  symbolic  reasoning

15

logical  form  translation

16

    combinatory  

categorial  grammar
    fully  (mono   )  

lexicalized  grammar
    categories  encode  

argument  sequences
    very  closely  related  

to  the  lambda  
calculus

    can  have  spurious  
ambiguities  (why?)

id35  parsing

17

mapping  to  lf:  zettlemoyer  &  collins  05/07  

the  task:

input: list one way flights to prague.

output:       x.flight(x)    one_way(x)    to(x,prg)

challenging  learning  problem:

    derivations  (or  parses)  are  not  annotated
    approach:  [zettlemoyer &  collins  2005]
    learn  a  lexicon  and  parameters  for  a  weighted  combinatory  

categorial grammar  (id35)

[slides from luke zettlemoyer]

18

background

    combinatory  categorial  grammar  (id35)

    weighted  id35s  

    learning  lexical  entries:  genlex

19

id35  lexicon

category

n :    x.flight(x)

(n\n)/np :    x.   f.   y.f(x)     to(y,x)

np : prg

np : nyc

   

words

flights

to

prague

new york city

   

20

parsing  rules  (combinators)

application
    x/y : f      y : a  =>   x : f(a)
y : a    x\y : f  =>   x : f(a)
   

composition
    x/y : f   y/z : g   =>  x/z :    x.f(g(x))
    y\z : f   x\y : g   =>  x\z :    x.f(g(x))
additional  rules:
    type  raising
    crossed  composition

21

id35  parsing

show me
s/n
   f.f

flights
   x.flight(x)

n

to

(n\n)/np

prague

np
prg

   y.   f.   x.f(y)   to(x,y)
n\n

   f.   x.f(x)   to(x,prg)

   x.flight(x)   to(x,prg)

n

   x.flight(x)   to(x,prg)

s

22

weighted  id35

given  a  log   linear  model  with  a  id35  lexicon     ,  a  

feature  vector  f,  and  weights  w.
    the  best  parse  is:

y*     argmax

y

w     f (x,y)

where  we  consider  all  possible  parses y for  

the  sentence x given  the  lexicon    .

23

lexical  generation

input training example
show me flights to prague.
   x.flight(x)    to(x,prg)

output lexicon

category
s/n :    f.f

n :    x.flight(x)

(n\n)/np :    x.   f.   y.f(x)     to(y,x)

np : prg

...

sentence: 
logic form:

words
show me
flights

to

prague

...

24

genlex:  substrings  x  categories

input training example

sentence: 
logic form:

show me flights to prague.
   x.flight(x)    to(x,prg)

output lexicon

all  possible  substrings:
show 
me
flights 

   show me
show me flights 
   
show me flights to

x

categories  created  by  rules  that  
trigger  on  the  logical  form:

np : prg
n :    x.flight(x)
(s\np)/np :    x.   y.to(y,x)
(n\n)/np :    y.   f.   x.    

   

[zettlemoyer & collins 2005]

25

robustness

the  lexical  entries  that  work  for:

show me the latest flight from boston to prague on friday

s/np     np/n      n        n\n        n\n       n\n

                                                             

will  not  parse:

boston to prague the latest on friday

np     n\n       np/n       n\n
                                      

26

relaxed  parsing  rules

two  changes

    add  application  and  composition  rules  that  relax  

word  order

    add  type  shifting  rules  to  recover  missing  words

these  rules  significantly  relax  the  grammar  

    introduce  features  to  count  the  number  of  times  

each  new  rule  is  used  in  a  parse

27

review:  application

x/y : f      y : a   =>   x : f(a)
y : a      x\y : f   =>   x : f(a)

28

disharmonic  application

    reverse  the  direction  of  the  principal  category:  

x\y : f      y : a   =>   x : f(a)
y : a      x/y : f   =>   x : f(a)

flights

n

   x.flight(x)

one way
n/n

   f.   x.f(x)   one_way(x)

n

   x.flight(x)   one_way(x)

29

missing  content  words

insert  missing  semantic  content

    np : c  =>  n\n :    f.   x.f(x)     p(x,c)

flights

n

   x.flight(x)

boston

np
bos
n\n

   f.   x.f(x)   from(x,bos)

to prague

n\n

   f.   x.f(x)   to(x,prg)

n

   x.flight(x)   from(x,bos)
n

   x.flight(x)   from(x,bos)   to(x,prg)

30

missing  content   free  words

bypass  missing  nouns

    n\n : f =>  n : f(   x.true)

northwest air

n/n

   f.   x.f(x)   airline(x,nwa)

to prague

n\n

   f.   x.f(x)   to(x,prg)

n

   x.to(x,prg)

   x.airline(x,nwa)     to(x,prg)

n

31

inputs: training set {(xi, zi) | i=1   n} of sentences and logical forms.  initial 

lexicon    .  initial parameters w.  number of iterations t.

training: for t = 1   t, i =1   n:

step 1: check correctness  
w     f (xi,y)

    let
    if l(y*) = zi, go to the next example

y*     argmax

y

step 2: lexical generation

               genlex(xi,zi)
    set 
      
   y     arg max
    let 
    define    i to be the lexical entries in y^
    set lexicon to                    i

w     f (xi,y)

y s.t. l(y)    zi

step 3: update parameters

      y      argmax

w     f (xi,y)

y

    let
    if

l(       y )     zi
    set 

output: lexicon     and parameters w.

w     w     f (xi,    y )     f (xi,

      y )

32

related  work  for  evaluation

hidden  vector  state  model:  he  and  young  2006

    learns  a  probabilistic  push   down  automaton  with  em
    is  integrated  with  speech  recognition

      wasp:  wong  &  mooney  2007

    builds  a  synchronous  id18  with  statistical  machine  translation  

techniques

    easily  applied  to  different  languages

zettlemoyer  and  collins  2005

    uses  genlex  with  maximum  likelihood  batch  training  and  stricter  

grammar

33

two  natural  language  interfaces

atis  (travel  planning)

    manually   transcribed  speech  queries
    4500  training  examples
    500  example  development  set
    500  test  examples

geo880  (geography)
    edited  sentences
    600  training  examples
    280  test  examples

34

evaluation  metrics

precision,  recall,  and  f   measure  for:
    completely  correct  logical  forms
    attribute  /  value  partial  credit

   x.flight(x)     from(x,bos)     to(x,prg)

is  represented  as:

{from = bos, to = prg }

35

two   pass  parsing

simple  method  to  improve  recall:
    for  each  test  sentence  that  can  not  be  parsed:

    reparse  with  word  skipping
   
    output  the  highest  scoring  new  parse

every  skipped  word  adds  a  constant  penalty  

36

atis  test  set  [z+c  2007]

exact  match  accuracy:

single-pass

two-pass

precision

90.61

85.75

recall

81.92

84.60

f1

86.05

85.16

37

geo880  test  set

exact match accuracy:

single-pass

two-pass

zettlemoyer & collins 2005

wong & mooney 2007

precision

recall

95.49

91.63

96.25

93.72

83.20

86.07

79.29

80.00

f1

88.93

88.76

86.95

86.31

38

