grouping words 

linguistic objects in this course 

(cid:1)(cid:1) trees (with strings at the nodes) 

(cid:1)(cid:1) syntax, semantics 
(cid:1)(cid:1) algorithms: generation, parsing, inside-outside, build semantics 

(cid:1)(cid:1) sequences (of strings) 

(cid:1)(cid:1) id165s, tag sequences 
(cid:1)(cid:1) morpheme sequences, phoneme sequences 
(cid:1)(cid:1) algorithms: finite-state, best-paths, forward-backward 

(cid:1)(cid:1)    atoms    (unanalyzed strings) 

(cid:1)(cid:1) words, morphemes 
(cid:1)(cid:1) represent by contexts     other words they occur with 
(cid:1)(cid:1) algorithms: grouping similar words, splitting words into senses 

600.465 - intro to nlp - j. eisner 

1 

600.465 - intro to nlp - j. eisner 

2 

a concordance for    party    
     from www.webcorp.org.uk 

a concordance for    party    
     from www.webcorp.org.uk 

thing. she was talking at a party thrown at daphne's restaurant in  

(cid:1)(cid:1)
(cid:1)(cid:1) have turned it into the hot dinner-party topic. the comedy is the 
(cid:1)(cid:1) selection for the world cup party, which will be announced on may 1  
(cid:1)(cid:1)
in the 1983 general election for a party which, when it could not bear to  
(cid:1)(cid:1)
to attack the scottish national party, who look set to seize perth and  
(cid:1)(cid:1)
that had been passed to a second party who made a financial decision 
(cid:1)(cid:1)
the by-pass there will be a street party. "then," he says, "we are going   
(cid:1)(cid:1) number-crunchers within the labour party, there now seems little doubt 
(cid:1)(cid:1) political tradition and the same party. they are both relatively anglophilic  
(cid:1)(cid:1) he told tony blair's modernised party they must not retreat into "warm   
(cid:1)(cid:1) "oh no, i'm just here for the party," they said. "i think it's terrible   
(cid:1)(cid:1) a future obliges each party to the contract to fulfil it by 
(cid:1)(cid:1) be signed by or on behalf of each party to the contract." mr david n 

600.465 - intro to nlp - j. eisner 

3 

600.465 - intro to nlp - j. eisner 

4 

what good are word senses? 

what good are word senses? 

thing. she was talking at a party thrown at daphne's restaurant in  

(cid:1)(cid:1)
(cid:1)(cid:1) have turned it into the hot dinner-party topic. the comedy is the 
(cid:1)(cid:1) selection for the world cup party, which will be announced on may 1  
(cid:1)(cid:1)
in the 1983 general election for a party which, when it could not bear to  
(cid:1)(cid:1)
to attack the scottish national party, who look set to seize perth and  
(cid:1)(cid:1)
that had been passed to a second party who made a financial decision 
(cid:1)(cid:1)
the by-pass there will be a street party. "then," he says, "we are going   
(cid:1)(cid:1) number-crunchers within the labour party, there now seems little doubt 
(cid:1)(cid:1) political tradition and the same party. they are both relatively anglophilic  
(cid:1)(cid:1) he told tony blair's modernised party they must not retreat into "warm   
(cid:1)(cid:1) "oh no, i'm just here for the party," they said. "i think it's terrible   
(cid:1)(cid:1) a future obliges each party to the contract to fulfil it by 
(cid:1)(cid:1) be signed by or on behalf of each party to the contract." mr david n 

thing. she was talking at a party thrown at daphne's restaurant in  

(cid:1)(cid:1)
(cid:1)(cid:1) have turned it into the hot dinner-party topic. the comedy is the 
(cid:1)(cid:1) selection for the world cup party, which will be announced on may 1  
(cid:1)(cid:1)
the by-pass there will be a street party. "then," he says, "we are going   
(cid:1)(cid:1) "oh no, i'm just here for the party," they said. "i think it's terrible   

in the 1983 general election for a party which, when it could not bear to  
to attack the scottish national party, who look set to seize perth and  

(cid:1)(cid:1)
(cid:1)(cid:1)
(cid:1)(cid:1) number-crunchers within the labour party, there now seems little doubt 
(cid:1)(cid:1) political tradition and the same party. they are both relatively anglophilic  
(cid:1)(cid:1) he told tony blair's modernised party they must not retreat into "warm   

that had been passed to a second party who made a financial decision 

(cid:1)(cid:1)
(cid:1)(cid:1) a future obliges each party to the contract to fulfil it by 
(cid:1)(cid:1) be signed by or on behalf of each party to the contract." mr david n 

600.465 - intro to nlp - j. eisner 

5 

600.465 - intro to nlp - j. eisner 

6 

what good are word senses? 

what good are word senses? 

(cid:1)(cid:1) john threw a    rain forest    party last 

december.  his living room was full of 
plants and his box was playing brazilian 
music     

(cid:1)(cid:1) replace word w with sense s  

(cid:1)(cid:1) splits w into senses: distinguishes this token 

of w from tokens with sense t 

(cid:1)(cid:1) groups w with other words: groups this token 

of w with tokens of x that also have sense s 

600.465 - intro to nlp - j. eisner 

7 

600.465 - intro to nlp - j. eisner 

8 

what good are word senses? 

what good are word senses? 

thing. she was talking at a party thrown at daphne's restaurant in  

(cid:1)(cid:1) number-crunchers within the labour party, there now seems little doubt 
(cid:1)(cid:1) political tradition and the same party. they are both relatively anglophilic  
(cid:1)(cid:1) he told tony blair's modernised party they must not retreat into "warm   
(cid:1)(cid:1)
(cid:1)(cid:1) have turned it into the hot dinner-party topic. the comedy is the 
(cid:1)(cid:1) selection for the world cup party, which will be announced on may 1  
(cid:1)(cid:1)
the by-pass there will be a street party. "then," he says, "we are going   
(cid:1)(cid:1) "oh no, i'm just here for the party," they said. "i think it's terrible   

 an appearance at the annual awards bash , but feels in no fit state to 
-known families at a fundraising bash on thursday night for learning 

(cid:1)(cid:1)
(cid:1)(cid:1)
(cid:1)(cid:1) who was paying for the bash? the only clue was the name asprey,  
(cid:1)(cid:1) mail, always hosted the annual bash for the scottish labour front- 
(cid:1)(cid:1) popular. their method is to bash sense into criminals with a short,  
(cid:1)(cid:1)
just cut off people's heads and bash their brains out over the floor,  

(cid:1)(cid:1) number-crunchers within the labour party, there now seems little doubt 
(cid:1)(cid:1) political tradition and the same party. they are both relatively anglophilic  
(cid:1)(cid:1) he told tony blair's modernised party they must not retreat into "warm   

thing. she was talking at a party thrown at daphne's restaurant in  

(cid:1)(cid:1)
(cid:1)(cid:1) have turned it into the hot dinner-party topic. the comedy is the 
(cid:1)(cid:1) selection for the world cup party, which will be announced on may 1  
(cid:1)(cid:1)
the by-pass there will be a street party. "then," he says, "we are going   
(cid:1)(cid:1) "oh no, i'm just here for the party," they said. "i think it's terrible   
(cid:1)(cid:1)
 an appearance at the annual awards bash, but feels in no fit state to 
(cid:1)(cid:1)
-known families at a fundraising bash on thursday night for learning 
(cid:1)(cid:1) who was paying for the bash? the only clue was the name asprey,  
(cid:1)(cid:1) mail, always hosted the annual bash for the scottish labour front- 

(cid:1)(cid:1) popular. their method is to bash sense into criminals with a short,  
(cid:1)(cid:1)
just cut off people's heads and bash their brains out over the floor,  

600.465 - intro to nlp - j. eisner 

9 

600.465 - intro to nlp - j. eisner 

10 

what good are word senses? 

cues to word sense 

(cid:1)(cid:1) semantics / text understanding 

(cid:1)(cid:1) axioms about transfer apply to (some tokens of) throw 
(cid:1)(cid:1) axioms about building apply to (some tokens of) bank 

(cid:1)(cid:1) machine translation 
(cid:1)(cid:1)

info retrieval / id53 / text categ. 
(cid:1)(cid:1) query or pattern might not match document exactly 

(cid:1)(cid:1) backoff for just about anything 

(cid:1)(cid:1) what word comes next?  (id103, language id,    ) 

(cid:1)(cid:1) trigrams are sparse but tri-meanings might not be 

(cid:1)(cid:1) bilexical pid18s: p(s[devour] (cid:3) np[lion] vp[devour] | s[devour]) 

(cid:1)(cid:1) approximate by p(s[eat] (cid:3) np[lion] vp[eat] | s[eat]) 

(cid:1)(cid:1) speaker   s real intention is senses; words are a noisy channel 

(cid:1)(cid:1) adjacent words (or their senses) 
(cid:1)(cid:1) grammatically related words (subject, object,    ) 
(cid:1)(cid:1) other nearby words 
(cid:1)(cid:1) topic of document 
(cid:1)(cid:1) sense of other tokens of the word in the 

same document 

600.465 - intro to nlp - j. eisner 

11 

600.465 - intro to nlp - j. eisner 

12 

word classes by tagging 

word classes by tagging 

(cid:1)(cid:1) every tag is a kind of class 
(cid:1)(cid:1) tagger assigns a class to each word token 

(cid:1)(cid:1) every tag is a kind of class 
(cid:1)(cid:1) tagger assigns a class to each word token 

probs 
from tag 
bigram 
model 

0.4 

0.6 

start pn   verb    det     noun  prep noun   prep  

0.001 

probs from 
unigram 
replacement 

bill  directed   a    cortege  of   autos  throug

(cid:1)(cid:1) simultaneously groups and splits words 
(cid:1)(cid:1)    party    gets split into n and v senses 
(cid:1)(cid:1)    bash    gets split into n and v senses 
(cid:1)(cid:1) {party/n, bash/n}  vs.  {party/v, bash/v} 
(cid:1)(cid:1) what good are these groupings? 

600.465 - intro to nlp - j. eisner 

13 

600.465 - intro to nlp - j. eisner 

14 

learning word classes 

words as vectors  

(cid:1)(cid:1) every tag is a kind of class 
(cid:1)(cid:1) tagger assigns a class to each word token 

(cid:1)(cid:1) {party/n, bash/n}  vs.  {party/v, bash/v} 
(cid:1)(cid:1) what good are these groupings? 
(cid:1)(cid:1) good for predicting next word or its class! 

(cid:1)(cid:1) role of forward-backward algorithm? 

(cid:1)(cid:1) it adjusts classes etc. in order to predict sequence of 

words better (with lower perplexity) 

(cid:1)(cid:1) represent each word type w by a point in k-

dimensional space 
(cid:1)(cid:1) e.g., k is size of vocabulary  
(cid:1)(cid:1) the 17th coordinate of w represents strength of w   s 

association with vocabulary word 17 

count too high 
(too influential) 

(0,    0,    3,    1,    0,    7,            . . .                 1,    0)  

from 
corpus: 

jim jeffords abandoned the republican party. 
there were lots of abbots and nuns dancing at that party.  
the party above the art gallery was, above all, a laboratory  

for synthesizing zygotes and beer.   

count 
too low 

600.465 - intro to nlp - j. eisner 

15 

600.465 - intro to nlp - j. eisner 

16 

words as vectors  

words as vectors  

(cid:1)(cid:1) represent each word type w by a point in k-

dimensional space 
(cid:1)(cid:1) e.g., k is size of vocabulary  
(cid:1)(cid:1) the 17th coordinate of w represents strength of w   s 

association with vocabulary word 17 

(cid:1)(cid:1) represent each word type w by a point in k-

dimensional space 
(cid:1)(cid:1) e.g., k is size of vocabulary  
(cid:1)(cid:1) the 17th coordinate of w represents strength of w   s 

association with vocabulary word 17 

how might you 
measure this? 

(0,    0,    3,    1,    0,    7,            . . .                 1,    0)  

(0,    0,    3,    1,    0,    7,            . . .                 1,    0)  

(cid:1)(cid:1) how often words appear next to each other 
(cid:1)(cid:1) how often words appear near each other 
(cid:1)(cid:1) how often words are syntactically linked 
(cid:1)(cid:1) should correct for commonness of word (e.g.,    above   ) 

(cid:1)(cid:1) plot all word types in k-dimensional space 
(cid:1)(cid:1) look for clusters of close-together types 

600.465 - intro to nlp - j. eisner 

17 

600.465 - intro to nlp - j. eisner 

18 

learning classes by id91  

bottom-up id91  

(cid:1)(cid:1) plot all word types in k-dimensional space 
(cid:1)(cid:1) look for clusters of close-together types 

plot in k dimensions (here k=3) 

(cid:1)(cid:1) start with one cluster per point 
(cid:1)(cid:1) repeatedly merge 2 closest clusters 

(cid:1)(cid:1) single-link: dist(a,b) = min dist(a,b) for a(cid:1)a, b(cid:1)b 
(cid:1)(cid:1) complete-link: dist(a,b) = max dist(a,b) for a(cid:1)a, b(cid:1)b 

600.465 - intro to nlp - j. eisner 

19 

600.465 - intro to nlp - j. eisner 

20 

bottom-up id91     single-link 

bottom-up id91     single-link 

example from manning & sch  tze 

example from manning & sch  tze 

merge 

each word type is 

a single-point cluster 

again, merge closest pair of clusters: 

again, merge closest pair of clusters: 

single-link: clusters are close if any of their points are 

single-link: clusters are close if any of their points are 

             dist(a,b) = min dist(a,b) for a(cid:1)a, b(cid:1)b 

             dist(a,b) = min dist(a,b) for a(cid:1)a, b(cid:1)b 

fast, but tend to get long, stringy, meandering clusters 

600.465 - intro to nlp - j. eisner 

21 

600.465 - intro to nlp - j. eisner 

22 

bottom-up id91     complete-link 

bottom-up id91     complete-link 

example from manning & sch  tze 

example from manning & sch  tze 

distance 
between 
clusters 

distance 
between 
clusters 

again, merge closest pair of clusters: 

again, merge closest pair of clusters: 

complete-link: clusters are close only if all of their points are 
                     dist(a,b) = max dist(a,b) for a(cid:1)a, b(cid:1)b 

600.465 - intro to nlp - j. eisner 

23 

complete-link: clusters are close only if all of their points are 
                     dist(a,b) = max dist(a,b) for a(cid:1)a, b(cid:1)b 

slow to find closest pair     need quadratically many distances 
24 

600.465 - intro to nlp - j. eisner 

bottom-up id91  

em id91 (for k clusters) 

(cid:1)(cid:1) start with one cluster per point 
(cid:1)(cid:1) repeatedly merge 2 closest clusters 

(cid:1)(cid:1) single-link: dist(a,b) = min dist(a,b) for a(cid:1)a, b(cid:1)b 
(cid:1)(cid:1) complete-link: dist(a,b) = max dist(a,b) for a(cid:1)a, b(cid:1)b 

(cid:1)(cid:1) too slow to update cluster distances after each merge; but (cid:2) alternatives! 

(cid:1)(cid:1) average-link: dist(a,b) = mean dist(a,b) for a(cid:1)a, b(cid:1)b 
(cid:1)(cid:1) centroid-link: dist(a,b) = dist(mean(a),mean(b)) 

(cid:1)(cid:1) stop when clusters are    big enough    

(cid:1)(cid:1) e.g., provide adequate support for backoff (on a development corpus) 

(cid:1)(cid:1) some flexibility in defining dist(a,b) 
(cid:1)(cid:1) might not be euclidean distance; e.g., use vector angle 

(cid:1)(cid:1) em algorithm 

(cid:1)(cid:1) viterbi version     called    id116 id91    
(cid:1)(cid:1) full em version     called    gaussian mixtures    

(cid:1)(cid:1) expectation step: use current parameters (and observations) to 

reconstruct hidden structure 

(cid:1)(cid:1) maximization step: use that hidden structure (and observations) 

to reestimate parameters 

(cid:1)(cid:1) parameters: k points representing cluster centers 
(cid:1)(cid:1) hidden structure: for each data point (word type),  

which center generated it? 

600.465 - intro to nlp - j. eisner 

25 

600.465 - intro to nlp - j. eisner 

26 

em id91 (for k clusters) 

(cid:1)(cid:1) [see spreadsheet animation] 

600.465 - intro to nlp - j. eisner 

27 

