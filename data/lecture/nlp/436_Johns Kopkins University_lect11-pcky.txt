weighted parsing,
probabilistic parsing

600.465 - intro to nlp - j. eisner

1

our bane: ambiguity
    john saw mary

    typhoid mary
    phillips screwdriver mary
note how rare rules interact

    i see a bird

    is this 4 nouns     parsed like    city park scavenger bird   ?
rare parts of speech, plus systematic ambiguity in noun sequences

    time flies like an arrow
    fruit flies like a banana
    time reactions like this one
    time reactions like a chemist
    or is it just an np?

600.465 - intro to nlp - j. eisner

2

our bane: ambiguity
    john saw mary

    typhoid mary
    phillips screwdriver mary
note how rare rules interact

    i see a bird

    is this 4 nouns     parsed like    city park scavenger bird   ?
rare parts of speech, plus systematic ambiguity in noun sequences

    time | flies like an arrow
    fruit flies | like a banana
    time | reactions like this one
    time reactions | like a chemist
    or is it just an np?

600.465 - intro to nlp - j. eisner

np vp
np vp
v[stem] np
s pp

3

how to solve this combinatorial
explosion of ambiguity?

1. first try parsing without any weird rules,

throwing them in only if needed.
2. better: every rule has a weight.

a tree   s weight is total weight of all its rules.
pick the overall lightest parse of sentence.

3. can we pick the weights automatically?

we   ll get to this later    

600.465 - intro to nlp - j. eisner

4

time 1 flies 2

like 3

an 4 arrow 5

np 3
vst 3

0

1

2
3
4

np 4
vp 4

p 2
v 5

det 1

n 8

1  s     np vp
6  s     vst np
2  s     s pp
1  vp     v np
2  vp     vp pp
1  np     det n
2  np     np pp
3  np     np np
0  pp     p np

time 1 flies 2

like 3

an 4 arrow 5

np 3
vst 3

0

1

2
3
4

np 4
vp 4

p 2
v 5

det 1

n 8

1  s     np vp
6  s     vst np
2  s     s pp
1  vp     v np
2  vp     vp pp
1  np     det n
2  np     np pp
3  np     np np
0  pp     p np

time 1 flies 2

like 3

an 4 arrow 5

np 3
vst 3

np 10

0

1

2
3
4

np 4
vp 4

p 2
v 5

det 1

n 8

1  s     np vp
6  s     vst np
2  s     s pp
1  vp     v np
2  vp     vp pp
1  np     det n
2  np     np pp
3  np     np np
0  pp     p np

time 1 flies 2

like 3

an 4 arrow 5

np 3
vst 3

np 10
8
s

0

1

2
3
4

np 4
vp 4

p 2
v 5

det 1

n 8

1  s     np vp
6  s     vst np
2  s     s pp
1  vp     v np
2  vp     vp pp
1  np     det n
2  np     np pp
3  np     np np
0  pp     p np

time 1 flies 2

like 3

an 4 arrow 5

np 3
vst 3

np 10
8
s
13
s

np 4
vp 4

p 2
v 5

det 1

n 8

1  s     np vp
6  s     vst np
2  s     s pp
1  vp     v np
2  vp     vp pp
1  np     det n
2  np     np pp
3  np     np np
0  pp     p np

0

1

2
3
4

time 1 flies 2

like 3

an 4 arrow 5

np 3
vst 3

np 10
8
s
13
s

np 4
vp 4

p 2
v 5

det 1

n 8

1  s     np vp
6  s     vst np
2  s     s pp
1  vp     v np
2  vp     vp pp
1  np     det n
2  np     np pp
3  np     np np
0  pp     p np

0

1

2
3
4

time 1 flies 2

like 3

an 4 arrow 5

np 3
vst 3

np 10
8
s
13
s

np 4
vp 4

p 2
v 5

det 1

np 10
n 8

1  s     np vp
6  s     vst np
2  s     s pp
1  vp     v np
2  vp     vp pp
1  np     det n
2  np     np pp
3  np     np np
0  pp     p np

0

1

2
3
4

time 1 flies 2

like 3

an 4 arrow 5

np 3
vst 3

np 10
8
s
13
s

np 4
vp 4

p 2
v 5

det 1

np 10
n 8

1  s     np vp
6  s     vst np
2  s     s pp
1  vp     v np
2  vp     vp pp
1  np     det n
2  np     np pp
3  np     np np
0  pp     p np

0

1

2
3
4

time 1 flies 2

like 3

an 4 arrow 5

np 3
vst 3

np 10
8
s
13
s

np 4
vp 4

0

1

2
3
4

1  s     np vp
6  s     vst np
2  s     s pp
1  vp     v np
2  vp     vp pp
1  np     det n
2  np     np pp
3  np     np np
0  pp     p np

p 2
v 5

det 1

pp 12

np 10
n 8

time 1 flies 2

like 3

an 4 arrow 5

np 3
vst 3

np 10
8
s
13
s

np 4
vp 4

0

1

2
3
4

1  s     np vp
6  s     vst np
2  s     s pp
1  vp     v np
2  vp     vp pp
1  np     det n
2  np     np pp
3  np     np np
0  pp     p np

p 2
v 5

det 1

pp 12
vp 16
np 10
n 8

time 1 flies 2

like 3

an 4 arrow 5

np 3
vst 3

np 10
8
s
13
s

np 4
vp 4

0

1

2
3
4

1  s     np vp
6  s     vst np
2  s     s pp
1  vp     v np
2  vp     vp pp
1  np     det n
2  np     np pp
3  np     np np
0  pp     p np

p 2
v 5

det 1

pp 12
vp 16
np 10
n 8

time 1 flies 2

like 3

an 4 arrow 5

np 3
vst 3

np 10
8
s
13
s

np 4
vp 4

0

1

2
3
4

1  s     np vp
6  s     vst np
2  s     s pp
1  vp     v np
2  vp     vp pp
1  np     det n
2  np     np pp
3  np     np np
0  pp     p np

np 18

pp 12
vp 16
np 10
n 8

p 2
v 5

det 1

time 1 flies 2

like 3

an 4 arrow 5

np 3
vst 3

np 10
8
s
13
s

np 4
vp 4

0

1

2
3
4

1  s     np vp
6  s     vst np
2  s     s pp
1  vp     v np
2  vp     vp pp
1  np     det n
2  np     np pp
3  np     np np
0  pp     p np

np 18
21
s

pp 12
vp 16
np 10
n 8

p 2
v 5

det 1

time 1 flies 2

like 3

an 4 arrow 5

np 3
vst 3

np 10
8
s
13
s

np 4
vp 4

0

1

2
3
4

1  s     np vp
6  s     vst np
2  s     s pp
1  vp     v np
2  vp     vp pp
1  np     det n
2  np     np pp
3  np     np np
0  pp     p np

np 18
21
s
vp 18
pp 12
vp 16
np 10
n 8

p 2
v 5

det 1

time 1 flies 2

like 3

an 4 arrow 5

np 3
vst 3

np 10
8
s
13
s

np 4
vp 4

0

1

2
3
4

1  s     np vp
6  s     vst np
2  s     s pp
1  vp     v np
2  vp     vp pp
1  np     det n
2  np     np pp
3  np     np np
0  pp     p np

np 18
21
s
vp 18
pp 12
vp 16
np 10
n 8

p 2
v 5

det 1

time 1 flies 2

like 3

an 4 arrow 5

np 3
vst 3

np 10
8
s
13
s

np 4
vp 4

0

1

2
3
4

p 2
v 5

det 1

np 24

np 18
21
s
vp 18
pp 12
vp 16
np 10
n 8

1  s     np vp
6  s     vst np
2  s     s pp
1  vp     v np
2  vp     vp pp
1  np     det n
2  np     np pp
3  np     np np
0  pp     p np

time 1 flies 2

like 3

an 4 arrow 5

np 3
vst 3

np 10
8
s
13
s

np 4
vp 4

0

1

2
3
4

p 2
v 5

det 1

np 24
22
s

np 18
21
s
vp 18
pp 12
vp 16
np 10
n 8

1  s     np vp
6  s     vst np
2  s     s pp
1  vp     v np
2  vp     vp pp
1  np     det n
2  np     np pp
3  np     np np
0  pp     p np

time 1 flies 2

like 3

an 4 arrow 5

np 3
vst 3

np 10
8
s
13
s

np 4
vp 4

0

1

2
3
4

p 2
v 5

det 1

np 24
22
s
27
s

np 18
21
s
vp 18
pp 12
vp 16
np 10
n 8

1  s     np vp
6  s     vst np
2  s     s pp
1  vp     v np
2  vp     vp pp
1  np     det n
2  np     np pp
3  np     np np
0  pp     p np

time 1 flies 2

like 3

an 4 arrow 5

np 3
vst 3

np 10
8
s
13
s

np 4
vp 4

0

1

2
3
4

p 2
v 5

det 1

np 24
22
s
27
s

np 18
21
s
vp 18
pp 12
vp 16
np 10
n 8

1  s     np vp
6  s     vst np
2  s     s pp
1  vp     v np
2  vp     vp pp
1  np     det n
2  np     np pp
3  np     np np
0  pp     p np

time 1 flies 2

like 3

an 4 arrow 5

np 3
vst 3

np 10
8
s
13
s

np 4
vp 4

0

1

2
3
4

p 2
v 5

det 1

np 24
22
s
s
27
np 24

np 18
21
s
vp 18
pp 12
vp 16
np 10
n 8

1  s     np vp
6  s     vst np
2  s     s pp
1  vp     v np
2  vp     vp pp
1  np     det n
2  np     np pp
3  np     np np
0  pp     p np

time 1 flies 2

like 3

an 4 arrow 5

np 3
vst 3

np 10
8
s
13
s

np 4
vp 4

0

1

2
3
4

p 2
v 5

det 1

np 24
22
s
s
27
np 24
27
s

np 18
21
s
vp 18
pp 12
vp 16
np 10
n 8

1  s     np vp
6  s     vst np
2  s     s pp
1  vp     v np
2  vp     vp pp
1  np     det n
2  np     np pp
3  np     np np
0  pp     p np

time 1 flies 2

like 3

an 4 arrow 5

np 3
vst 3

np 10
8
s
13
s

np 4
vp 4

0

1

2
3
4

p 2
v 5

det 1

np 24
22
s
s
27
np 24
27
s
s
22

np 18
21
s
vp 18
pp 12
vp 16
np 10
n 8

1  s     np vp
6  s     vst np
2  s     s pp
1  vp     v np
2  vp     vp pp
1  np     det n
2  np     np pp
3  np     np np
0  pp     p np

time 1 flies 2

like 3

an 4 arrow 5

np 3
vst 3

np 10
8
s
13
s

np 4
vp 4

0

1

2
3
4

p 2
v 5

det 1

np 24
22
s
s
27
np 24
27
s
s
22
s
27
np 18
21
s
vp 18
pp 12
vp 16
np 10
n 8

1  s     np vp
6  s     vst np
2  s     s pp
1  vp     v np
2  vp     vp pp
1  np     det n
2  np     np pp
3  np     np np
0  pp     p np

follow backpointers    
time 1 flies 2

an 4 arrow 5

like 3

np 3
vst 3

np 10
8
s
13
s

np 4
vp 4

0

1

2
3
4

p 2
v 5

det 1

np 24
22
s
s
27
np 24
27
s
s
22
s
27
np 18
21
s
vp 18
pp 12
vp 16
np 10
n 8

s

1  s     np vp
6  s     vst np
2  s     s pp
1  vp     v np
2  vp     vp pp
1  np     det n
2  np     np pp
3  np     np np
0  pp     p np

time 1 flies 2

like 3

an 4 arrow 5

np 3
vst 3

np 10
8
s
13
s

np 4
vp 4

0

1

2
3
4

p 2
v 5

det 1

np 24
22
s
s
27
np 24
27
s
s
22
s
27
np 18
21
s
vp 18
pp 12
vp 16
np 10
n 8

s

np vp

1 s     np vp
6  s     vst np
2  s     s pp
1  vp     v np
2  vp     vp pp
1  np     det n
2  np     np pp
3  np     np np
0  pp     p np

time 1 flies 2

like 3

an 4 arrow 5

np 3
vst 3

np 10
8
s
13
s

np 4
vp 4

0

1

2
3
4

p 2
v 5

det 1

np 24
22
s
s
27
np 24
27
s
s
22
s
27
np 18
21
s
vp 18
pp 12
vp 16
np 10
n 8

s

np vp

vp

pp

1  s     np vp
6  s     vst np
2  s     s pp
1  vp     v np
2  vp     vp pp
1  np     det n
2  np     np pp
3  np     np np
0  pp     p np

time 1 flies 2

like 3

an 4 arrow 5

np 3
vst 3

np 10
8
s
13
s

np 4
vp 4

0

1

2
3
4

p 2
v 5

det 1

np 24
22
s
s
27
np 24
27
s
s
22
s
27
np 18
21
s
vp 18
pp 12
vp 16
np 10
n 8

s

np vp

vp

pp
p np

1  s     np vp
6  s     vst np
2  s     s pp
1  vp     v np
2  vp     vp pp
1  np     det n
2  np     np pp
3  np     np np
0  pp     p np

time 1 flies 2

like 3

an 4 arrow 5

np 3
vst 3

np 10
8
s
13
s

np 4
vp 4

0

1

2
3
4

p 2
v 5

det 1

np 24
22
s
s
27
np 24
27
s
s
22
s
27
np 18
21
s
vp 18
pp 12
vp 16
np 10
n 8

s

np vp

vp

pp
p np

det n

1  s     np vp
6  s     vst np
2  s     s pp
1  vp     v np
2  vp     vp pp
1  np     det n
2  np     np pp
3  np     np np
0  pp     p np

which entries do we need?
time 1 flies 2

an 4 arrow 5

like 3

np 3
vst 3

np 10
8
s
13
s

np 4
vp 4

0

1

2
3
4

p 2
v 5

det 1

np 24
22
s
s
27
np 24
27
s
s
22
s
27
np 18
21
s
vp 18
pp 12
vp 16
np 10
n 8

1  s     np vp
6  s     vst np
2  s     s pp
1  vp     v np
2  vp     vp pp
1  np     det n
2  np     np pp
3  np     np np
0  pp     p np

which entries do we need?
time 1 flies 2

an 4 arrow 5

like 3

np 3
vst 3

np 10
8
s
13
s

np 4
vp 4

0

1

2
3
4

p 2
v 5

det 1

np 24
22
s
s
27
np 24
27
s
s
22
s
27
np 18
21
s
vp 18
pp 12
vp 16
np 10
n 8

1  s     np vp
6  s     vst np
2  s     s pp
1  vp     v np
2  vp     vp pp
1  np     det n
2  np     np pp
3  np     np np
0  pp     p np

not worth keeping    
time 1 flies 2
an 4 arrow 5

like 3

np 3
vst 3

np 10
8
s
13
s

np 4
vp 4

0

1

2
3
4

p 2
v 5

det 1

np 24
22
s
s
27
np 24
27
s
s
22
s
27
np 18
21
s
vp 18
pp 12
vp 16
np 10
n 8

1  s     np vp
6  s     vst np
2  s     s pp
1  vp     v np
2  vp     vp pp
1  np     det n
2  np     np pp
3  np     np np
0  pp     p np

    since it just breeds worse options
time 1 flies 2

an 4 arrow 5

like 3

np 3
vst 3

np 10
8
s
13
s

np 4
vp 4

0

1

2
3
4

p 2
v 5

det 1

np 24
22
s
s
27
np 24
27
s
s
22
s
27
np 18
21
s
vp 18
pp 12
vp 16
np 10
n 8

1  s     np vp
6  s     vst np
2  s     s pp
1  vp     v np
2  vp     vp pp
1  np     det n
2  np     np pp
3  np     np np
0  pp     p np

keep only best-in-class!
time 1 flies 2

an 4 arrow 5

like 3

np 3
vst 3

np 10
8
s
13
s

inferior stock

np 4
vp 4

p 2
v 5

det 1

0

1

2
3
4

np 24
22
s
s
27
np 24
27
s
s
22
s
27
np 18
21
s
vp 18
pp 12
vp 16
np 10
n 8

1  s     np vp
6  s     vst np
2  s     s pp
1  vp     v np
2  vp     vp pp
1  np     det n
2  np     np pp
3  np     np np
0  pp     p np

keep only best-in-class!

(and its backpointers so you can recover best parse)

time 1 flies 2
0 np 3
vst 3

np 10
s
8
np 4
vp 4

1

2
3
4

like 3

an 4 arrow 5

p 2
v 5

det 1

np 24
s
22
np 18
s
21
vp 18
pp 12
vp 16
np 10
n 8

1  s     np vp
6  s     vst np
2  s     s pp
1  vp     v np
2  vp     vp pp
1  np     det n
2  np     np pp
3  np     np np
0  pp     p np

chart parsing
phrase(x,i,j) :- rewrite(x,w), word(w,i,j).
phrase(x,i,j) :- rewrite(x,y,z), phrase(y,i,mid), phrase(z,mid,j).
goal

:- phrase(start_symbol, 0, sentence_length).

39

weighted chart parsing (   min cost   )
phrase(x,i,j) min= rewrite(x,w) + word(w,i,j).
phrase(x,i,j) min= rewrite(x,y,z) + phrase(y,i,mid) + phrase(z,mid,j).
goal

min=  phrase(start_symbol, 0, sentence_length).

40

probabilistic trees
    instead of lightest weight tree, take highest

id203 tree

    given any tree, your assignment 1 generator would

have some id203 of producing it!

    just like using id165s to choose among strings    
    what is the id203 of this tree?

s

vp

np
time
vp
flies

pp
p
like

np

det
an

n
arrow

41

600.465 - intro to nlp - j. eisner

probabilistic trees
    instead of lightest weight tree, take highest

id203 tree

    given any tree, your assignment 1 generator would

have some id203 of producing it!

    just like using id165s to choose among strings    
    what is the id203 of this tree?

s

p(

    you rolled a lot of

independent dice    

600.465 - intro to nlp - j. eisner

| s)

vp

np
time
vp
flies

pp
p
like

np

det
an

n
arrow

42

chain rule: one word at a time

p(time flies like an arrow)

= p(time)

* p(flies | time)
* p(like | time flies)
* p(an | time flies like)
* p(arrow | time flies like an)

600.465 - intro to nlp - j. eisner

43

chain rule + backoff
(to get trigram model)

p(time flies like an arrow)

= p(time)

* p(flies | time)
* p(like | time flies)
* p(an | time flies like)
* p(arrow | time flies like an)

600.465 - intro to nlp - j. eisner

44

chain rule     written differently

p(time flies like an arrow)

= p(time)

* p(time flies | time)
* p(time flies like | time flies)
* p(time flies like an | time flies like)
* p(time flies like an arrow | time flies like an)

proof: p(x,y | x) = p(x | x) * p(y | x, x) = 1 * p(y | x)

600.465 - intro to nlp - j. eisner

45

chain rule + backoff

p(time flies like an arrow)

= p(time)

* p(time flies | time)
* p(time flies like | time flies)
* p(time flies like an | time flies like)
* p(time flies like an arrow | time flies like an)

proof: p(x,y | x) = p(x | x) * p(y | x, x) = 1 * p(y | x)

600.465 - intro to nlp - j. eisner

46

chain rule: one node at a time

s

| s) = p( s
np vp

| s) * p( s

|

vp

s

np vp

)

np
time

p(

vp

np
time
vp
flies

pp
p
like

np

det
an

n
arrow

* p(

* p(

s

|

vp

np
time
vp
s

np
time
vp
flies

pp
|

pp

vp

s

vp

np
time

)

s

np
time
vp

) *    

vp

pp

47

600.465 - intro to nlp - j. eisner

model you used
in homework 1!
(called    pid18   )

|

vp

s

np vp

)

chain rule + backoff

s

| s) = p( s
np vp

| s) * p( s

np
time

p(

vp

np
time
vp
flies

pp
p
like

np

det
an

n
arrow

* p(

* p(

s

|

vp

np
time
vp
s

np
time
vp
flies

pp
|

pp

vp

s

vp

np
time

)

s

np
time
vp

) *    

vp

pp

48

600.465 - intro to nlp - j. eisner

simplified notation

s

model you used
in homework 1!
(called    pid18   )

| s) = p(s     np vp | s) * p(np     time | np)

p(

vp

np
time
vp
flies

pp
p
like

np

det
an

n
arrow

* p(vp     vp np | vp)

* p(vp     flies | vp) *    

600.465 - intro to nlp - j. eisner

49

already have a cky alg for weights    

s

| s) = w(s     np vp)     + w(np     time)

w(

vp

np
time
vp
flies

pp
p
like

np

det
an

n
arrow

+ w(vp     vp np)

+ w(vp     flies) +    

just let w(x     y z) = -log p(x     y z | x)
then lightest tree has highest prob

50

weighted chart parsing (   min cost   )
phrase(x,i,j) min= rewrite(x,w) + word(w,i,j).
phrase(x,i,j) min= rewrite(x,y,z) + phrase(y,i,mid) + phrase(z,mid,j).
goal

min=  phrase(start_symbol, 0, sentence_length).

51

probabilistic chart parsing (   max prob   )

phrase(x,i,j) max= rewrite(x,w) * word(w,i,j).
phrase(x,i,j) max= rewrite(x,y,z) * phrase(y,i,mid) * phrase(z,mid,j).
goal

max= phrase(start_symbol, 0, sentence_length).

52

time 1 flies 2

like 3

an 4 arrow 5

np 3
vst 3

np 10
8
s
13
s

2-8

multiply to get 2-22

np 4
vp 4

p 2
v 5

2-12

det 1

0

1

2
3
4

np 24
22
s
s
27
np 24
27
s
s
22
s
27
np 18
21
s
vp 18
pp 12
vp 16
np 10
n 8

2-2

1  s     np vp
6  s     vst np
2  s     s pp
1  vp     v np
2  vp     vp pp
1  np     det n
2  np     np pp
3  np     np np
0  pp     p np

need only best-in-class to get best parse

time 1 flies 2

like 3

an 4 arrow 5

np 3
vst 3

2-13

np 10
8
s
13
s

2-8

multiply to get 2-22

np 4
vp 4

p 2
v 5

2-12

det 1

0

1

2
3
4

np 24
22
s
s
27
np 24
27
s
s
22
s
27
np 18
21
s
vp 18
pp 12
vp 16
np 10
n 8

2-2

1  s     np vp
6  s     vst np
2  s     s pp
1  vp     v np
2  vp     vp pp
1  np     det n
2  np     np pp
3  np     np np
0  pp     p np

why probabilities not weights?

    we just saw probabilities are really just a special case of

weights    

        but we can estimate them from training data by counting

and smoothing! yay!
    warning: what kind of training corpus do we need (if we want to

estimate rule probabilities simply by counting and smoothing)?

    probabilities tell us how likely our best parse actually is:

    might improve user interface (e.g. ask for clarification if not sure)
    might help when learning the rule probabilities (later in course)
    should help combination with other systems

    text understanding: even if the 3rd-best parse is 40x less probable

syntactically, might still use it if it   s> 40x more probable semantically
    ambiguity-preserving translation: if the top 3 parses are all probable,
try to find a translation that would be ok regardless of which is correct

600.465 - intro to nlp - j. eisner

55

a slightly different task

    been asking: what is id203 of generating a

given tree with your homework 1 generator?
    to pick tree with highest prob: useful in parsing.

    but could also ask: what is id203 of

generating a given string with the generator?
(i.e., with the    t option turned off)
    to pick string with highest prob: useful in speech

recognition, as substitute for an id165 model.
    (   put the file in the folder    vs.    put the file and the folder   )

    to get prob of generating string, must add up

probabilities of all trees for the string    

600.465 - intro to nlp - j. eisner

56

could just add up the parse probabilities

time 1 flies 2

like 3

an 4 arrow 5

np 3
vst 3

np 10
8
s
13
s

np 4
vp 4

0

1

2
3
4

2-22
2-27

2-27
2-22
2-27

p 2
v 5

det 1

np 24
22
s
s
27
np 24
27
s
s
22
s
27
np 18
21
s
vp 18
pp 12
vp 16
np 10
n 8

oops, back to finding
exponentially many

parses

1  s     np vp
6  s     vst np
2  s     s pp
1  vp     v np
2  vp     vp pp
1  np     det n
2  np     np pp
3  np     np np
0  pp     p np

any more efficient way?

time 1 flies 2

like 3

an 4 arrow 5

np 3
vst 3

np 10
s
2-8
s     2-13

np 4
vp 4

0

1

2
3
4

p 2
v 5

det 1

np 24
22
s
s
27
np 24
s
27
s
2-22
s
2-27
np 18
21
s
vp 18
pp  2-12
vp 16
np 10
n 8

1  s     np vp
6  s     vst np
2-2 s     s pp
1  vp     v np
2  vp     vp pp
1  np     det n
2  np     np pp
3  np     np np
0  pp     p np

add as we go     (the    inside algorithm   )

time 1 flies 2

like 3

an 4 arrow 5

np 3
vst 3

np 10
s

2-8+2-13

0

1

2
3
4

np 4
vp 4

p 2
v 5

det 1

np 24
22
s
s
27
np 24
27
s
s
2-22
+2-27
np 18
21
s
vp 18
pp  2-12
vp 16
np 10
n 8

1  s     np vp
6  s     vst np
2-2 s     s pp
1  vp     v np
2  vp     vp pp
1  np     det n
2  np     np pp
3  np     np np
0  pp     p np

add as we go     (the    inside algorithm   )

time 1 flies 2

like 3

an 4 arrow 5

np 3
vst 3

np 10
s

2-8+2-13

0

1

2
3
4

np 4
vp 4

p 2
v 5

det 1

s

np

2-22
+2-27
2-22
+2-27
+2-27
+(2-22
+2-27)
np 18
21
s
vp 18
pp  2-12
vp 16
np 10
n 8

1  s     np vp
6  s     vst np
2-2 s     s pp
1  vp     v np
2  vp     vp pp
1  np     det n
2  np     np pp
3  np     np np
0  pp     p np

probabilistic chart parsing (   max prob   )

phrase(x,i,j) max= rewrite(x,w) * word(w,i,j).
phrase(x,i,j) max= rewrite(x,y,z) * phrase(y,i,mid) * phrase(z,mid,j).
goal

max= phrase(start_symbol, 0, sentence_length).

61

the    inside algorithm   
phrase(x,i,j) += rewrite(x,w) * word(w,i,j).
phrase(x,i,j) += rewrite(x,y,z) * phrase(y,i,mid) * phrase(z,mid,j).
goal

+=  phrase(start_symbol, 0, sentence_length).

62

bottom-up id136
agenda of pending updates

pp(i,k) += prep(i,j)  * np(j,k)
pp(2,5)
np(3,5)
+= 0.3
+= 0.3

s(i,k)  +=  np(i,j)  *  vp(j,k)
prep(i,3)
prep(2,3)
vp(5,k)
vp(5,9)
s(3,9)
s(3,7)
vp(5,7)
= ?
= ?
= 0.5
+= 0.15
= 1.0
+= 0.21
= 0.7

we updated np(3,5);

what else must therefore change?

no more matches
prep(i,3)?
to this query

vp(5,k)?

np(3,5)
= 0.1+0.3
0.4

chart of derived items with current values

rules of program

if np(3,5) hadn   t been
in the chart already,
we would have added it.

63

parameterization    

* word(w,i,j).

phrase(x,i,j) += rewrite(x,w)
phrase(x,i,j) += rewrite(x,y,z) * phrase(y,i,mid) * phrase(z,mid,j).
goal
    rewrite(x,y,z)   s value represents the rule id203 p(y z | x).
    this could be defined by a formula instead of a number.
    simple conditional log-linear model (each rule has 4 features):

+=  phrase(start_symbol, 0, sentence_length).

    urewrite(x,y,z) *= exp(weight_xy(x,y)). % exp    xy,x,y
    urewrite(x,y,z) *= exp(weight_xz(x,z)).
    urewrite(x,y,z) *= exp(weight_yz(y,z)).
    urewrite(same,same,z) *= exp(weight_adjunction). % exp    adjunction

    urewrite(x) += urewrite(x,y,z).
    rewrite(x,y,z) = urewrite(x,y,z) / urewrite(x). % p(x     y z | x)
64

% normalizing constant

parameterization    

* word(w,i,j).

phrase(x,i,j) += rewrite(x,w)
phrase(x,i,j) += rewrite(x,y,z) * phrase(y,i,mid) * phrase(z,mid,j).
goal
    rewrite(x,y,z)   s value represents the rule id203 p(y z | x).
    simple conditional log-linear model    

+=  phrase(start_symbol, 0, sentence_length).

    what if the program uses the unnormalized id203 urewrite

instead of rewrite?

    different model!  each parse has an overall unnormalized prob:
uprob(parse) = exp(total weight of all features in the parse)

    can still normalize at the end:

p(parse | sentence) = uprob(parse) / z

where z is the sum of all uprob(parse): given by goal!

65

chart parsing: recognition algorithm

phrase(x,i,j) :- rewrite(x,w), word(w,i,j).
phrase(x,i,j) :- rewrite(x,y,z), phrase(y,i,mid), phrase(z,mid,j).
goal

:- phrase(start_symbol, 0, sentence_length).

66

chart parsing: viterbi algorithm (min-
cost)

phrase(x,i,j) min= rewrite(x,w) + word(w,i,j).
phrase(x,i,j) min= rewrite(x,y,z) + phrase(y,i,mid) + phrase(z,mid,j).
goal

min=  phrase(start_symbol, 0, sentence_length).

67

chart parsing: viterbi algorithm (max-prob)

phrase(x,i,j) max= rewrite(x,w) * word(w,i,j).
phrase(x,i,j) max= rewrite(x,y,z) * phrase(y,i,mid) * phrase(z,mid,j).
goal

max= phrase(start_symbol, 0, sentence_length).

68

chart parsing: inside algorithm

phrase(x,i,j) += rewrite(x,w) * word(w,i,j).
phrase(x,i,j) += rewrite(x,y,z) * phrase(y,i,mid) * phrase(z,mid,j).
goal

+=  phrase(start_symbol, 0, sentence_length).

69

generalization: semiring-weighted chart parsing

phrase(x,i,j)    = rewrite(x,w)     word(w,i,j).
phrase(x,i,j)    = rewrite(x,y,z)     phrase(y,i,mid)     phrase(z,mid,j).
goal

   = phrase(start_symbol, 0, sentence_length).

70

unweighted cky: recognition algorithm

    initialize all entries of chart to false
    for i := 1 to n

    for each rule r of the form x     word[i]

    chart[x,i-1,i] ||= in_grammar(r)

    for width := 2 to n

    for start := 0 to n-width

    define end := start + width
    for mid := start+1 to end-1

pay attention to the
orange code    

    for each rule r of the form x     y z
   

chart[x,start,end] ||= in_grammar(r) &&
chart[y,start,mid] && chart[z,mid,end]

    return chart[root,0,n]
600.465 - intro to nlp - j. eisner

71

weighted cky: viterbi algorithm (min-cost)

    initialize all entries of chart to    
    for i := 1 to n

    for each rule r of the form x     word[i]

    chart[x,i-1,i] min= weight(r)

    for width := 2 to n

    for start := 0 to n-width

    define end := start + width
    for mid := start+1 to end-1

pay attention to the
orange code    

    for each rule r of the form x     y z
   

chart[x,start,end] min= weight(r) +

chart[y,start,mid] + chart[z,mid,end]

    return chart[root,0,n]
600.465 - intro to nlp - j. eisner

72

probabilistic cky: inside algorithm

    initialize all entries of chart to 0
    for i := 1 to n

    for each rule r of the form x     word[i]

    chart[x,i-1,i] += prob(r)

    for width := 2 to n

    for start := 0 to n-width

    define end := start + width
    for mid := start+1 to end-1

pay attention to the
orange code    

    for each rule r of the form x     y z
chart[x,start,end] += prob(r) *
   

chart[y,start,mid] * chart[z,mid,end]

    return chart[root,0,n]
600.465 - intro to nlp - j. eisner

73

semiring-weighted cky: general algorithm!

    initialize all entries of chart to    
    for i := 1 to n

    for each rule r of the form x     word[i]
    chart[x,i-1,i]    = semiring_weight(r)

    for width := 2 to n

    for start := 0 to n-width

    define end := start + width
    for mid := start+1 to end-1

    is like    and   /   :
combines all of several
pieces into an x
    is like    or   /   :
considers the alternative
ways to build the x

    for each rule r of the form x     y z
   

chart[x,start,end]    = semiring_weight(r)    

chart[y,start,mid]     chart[z,mid,end]

    return chart[root,0,n]
600.465 - intro to nlp - j. eisner

74

semiring-weighted cky: general algorithm!

    initialize all entries of chart to    
    for i := 1 to n

    for each rule r of the form x     word[i]
    chart[x,i-1,i]    = semiring_weight(r)

    for width := 2 to n

    for start := 0 to n-width

    define end := start + width
    for mid := start+1 to end-1

?

    for each rule r of the form x     y z
   

chart[x,start,end]    = semiring_weight(r)    

chart[y,start,mid]     chart[z,mid,end]

    return chart[root,0,n]
600.465 - intro to nlp - j. eisner

75

weighted cky, general version

    initialize all entries of chart to    
    for i := 1 to n

    for each rule r of the form x     word[i]
    chart[x,i-1,i]    = semiring_weight(r)
   
   
+
and

    for width := 2 to n
total prob (inside)
min weight
recognizer
    for each rule r of the form x     y z
   

weights
   
    for start := 0 to n-width
[0,1]
+
    define end := start + width
[0,   ] min
    for mid := start+1 to end-1
or
{true,false}

   
0
   
false

chart[x,start,end]    = semiring_weight(r)    

chart[y,start,mid]     chart[z,mid,end]

    return chart[root,0,n]
600.465 - intro to nlp - j. eisner

76

other uses of semirings

    the semiring weight of a constituent, chart[x,i,k], is a

flexible bookkeeping device.

    if you want to build up information about larger

constituents from smaller ones, design a semiring:
    id203 of best parse, or its log
    number of parses
    total id203 of all parses, or its log
    the gradient of the total log-id203 with respect to the

parameters (use this to optimize the grammar weights)
    the id178 of the id203 distribution over parses
    the 5 most probable parses
    possible translations of the constituent (this is how mt is done!)
    we   ll see semirings again later with id122.
600.465 - intro to nlp - j. eisner
77

some weight semirings

log

total prob (inside)
max prob
min weight
= -log(max prob)
log(total prob)
recognizer
semiring elements are
log-probabilities lp, lq;
helps prevent underflow

weights
   
[0,1]
+
[0,1] max
[0,   ] min

   
   
   
+

   
0
0
   

   
1
1
0

[-   ,0]
{true,false}

log+
or

+
and

-   
0
false true

lp     lq = log(exp(lp)   exp(lq)) = lp+lq

lp     lq = log(exp(lp)+exp(lq)), denoted log+(lp,lq)

600.465 - intro to nlp - j. eisner

78

the semiring interface

public interface semiring<k extends semiring> {

public k oplus(k k);   //    
public k otimes(k k);  //    
public k zero();       //    
public k one();        //    

}
public class minweight implements semiring<minweight> {

protected float f;
public minweight(float f) { this.f =  f; }
public float tofloat() { return f; }
public minweight oplus(minweight k) {

return (f <= k.tofloat()) ? this : k; }

public minweight otimes(minweight k) {

return new minweight(f + k.tofloat()); }

static minweight zero = new minweight(float.positive_infinity);
static minweight one = new minweight(0);
public minweight zero() { return zero; }
public minweight one() { return one; } }
600.465 - intro to nlp - j. eisner

79

a generic parser for any semiring k

public interface semiring<k extends semiring> {

public k oplus(k k);   //    
public k otimes(k k);  //    
public k zero();       //    
public k one();        //    

}

public class contextfreegrammar<k extends semiring<k>> {

    // id18 with rule weights in k

}
public class ckyparser<k extends semiring<k>> {

    // parser for a id18 whose rule weights are in k
k parse(vector<string> input) {     }

// returns    total    weight (using    ) of all parses

}
g = new contextfreegrammar<minweight>(   );
p = new ckyparser<minweight>(g);
minweight = p.parse(input); // returns min weight of any parse

600.465 - intro to nlp - j. eisner

80

the semiring axioms

public interface semiring<k extends semiring> {

public k oplus(k k);   //    
public k otimes(k k);  //    
public k zero();       //    
public k one();        //    

}

an implementation of semiring must satisfy the semiring axioms:
    commutativity of    : a     b = b     a
    associativity: (a     b)     c = a     (b     c),
(a     b)     c = a     (b     c)

    distributivity: a     (b     c) = (a     b)     (a     c),
(b     c)     a = (b     a)     (c     a)

    identities: a         =         a = a,     a         =         a = a
    annihilation: a         =    
otherwise the parser won   t work correctly.  why not?  (look back at it.)
600.465 - intro to nlp - j. eisner
81

rule binarization can speed up program

phrase(x,i,j) += rewrite(x,y,z) * phrase(y,i,mid) * phrase(z,mid,j).

x

+=

x

y
y

z
z

i

j

i

mid

mid

j

82

rule binarization can speed up program

phrase(x,i,j) +=  phrase(y,i,mid) * phrase(z,mid,j) * rewrite(x,y,z).

folding transformation: asymp. speedup!
temp(x\y,mid,j)  +=                         phrase(z,mid,j) * rewrite(x,y,z).
phrase(x,i,j)

+=  phrase(y,i,mid) * temp(x\y,mid,j).

x

y
y

z
z

y

x\y

x

i

mid

mid

j

i

mid

mid

j

i

j

83

rule binarization can speed up program

phrase(x,i,j) +=  phrase(y,i,mid) * phrase(z,mid,j) * rewrite(x,y,z).

folding transformation: asymp. speedup!
temp(x\y,mid,j)  +=                         phrase(z,mid,j) * rewrite(x,y,z).
phrase(x,i,j)     +=  phrase(y,i,mid) * temp(x\y,mid,j).

   

zy

,

,

mid

phrase(y,i,mid) * phrase(z,mid,j) * rewrite(x,y,z)

id114
constraint programming
multi-way database join

phrase(y,i,mid)       phrase(z,mid,j) * rewrite(x,y,z)

   

y ,

mid

   

z

84

earley   s algorithm in dyna

phrase(x,i,j) += rewrite(x,w)
phrase(x,i,j) += rewrite(x,y,z) * phrase(y,i,mid) * phrase(z,mid,j).
goal

+=  phrase(start_symbol, 0, sentence_length).
magic templates transformation

* word(w,i,j).

(as noted by minnen 1996)

need(start_symbol,0) = true.
need(nonterm,j) :- phrase(_/[nonterm|_],_,j).
phrase(nonterm/needed,i,i)

+= need(nonterm,i), rewrite(nonterm,needed).

phrase(nonterm/needed,i,k)

+= phrase(nonterm/[w|needed],i,j) * word(w,j,k).

phrase(nonterm/needed,i,k)

+= phrase(nonterm/[x|needed],i,j) * phrase(x/[],j,k).

goal += phrase(start_symbol/[],0,sentence_length).

85

