nlp
introduction to nlp
evaluation of language models
evaluation of lm
extrinsic
use in an application
intrinsic
cheaper
correlate the two for validation purposes
id205
uncertainty	
id178
motivating id178
adding probabilities
average surprise
id178 example
simplified polynesian
id178 calculation
designing a better code
joint id178
conditional id178
chain rule for id178
syllables
syllables (cont   d)
polynesian syllables
polynesian syllables (cont   d)
polynesian syllables (cont   d)
exercise
pointwise mutual information
mutual information
mutual information (cont   d)
relative id178
notes on relative id178
divergence as mutual information
perplexity
does the model fit the data?
a good model will give a high id203 to a real sentence
perplexity
average branching factor in predicting the next word
lower is better (lower perplexity -> higher id203)
n = number of words

perplexity
example:
a sentence consisting of n equiprobable words: p(wi) = 1/k



per = ((k-1)n)(-1/n) = k
perplexity is like a branching factor
logarithmic version
the exponent is = #bits to encode each word)


the shannon game
consider the shannon game:
new york governor andrew cuomo said ...
what is the perplexity of guessing a digit if all digits are equally likely? do the math.
10
how about a letter?
26
how about guessing a (   operator   ) with a id203 of 1/4, b (   sales   ) with a id203 of 1/4 and 10,000 other cases with a id203 of 1/2 total
example modified from joshua goodman.
perplexity across distributions
what if the actual distribution is very different from the expected one?
example:
all of the 10,000 other cases are equally likely but p(a) = p(b) = 0.
cross-id178 = log (perplexity), measured in bits

sample values for perplexity
wall street journal (wsj) corpus
38 m words (tokens)
20 k types
perplexity
evaluated on a separate 1.5m sample of wsj documents
unigram 962
bigram 170
trigram 109
word error rate
another evaluation metric
number of insertions, deletions, and substitutions
normalized by sentence length
same as levenshtein id153
example:
governor dan malloy met with the mayor
the governor met the senator
3 deletions + 1 insertion + 1 substitution = wer of 5
issues
out of vocabulary words (oov)
split the training set into two parts
label all words in part 2 that were not in part 1 as <unk>
id91
e.g., dates, monetary amounts, organizations, years
long distance dependencies
this is where id165 language models fail by definition
missing syntactic information
the students who participated in the game are tired
the student who participated in the game is tired
missing semantic information
the pizza that i had last night was tasty
the class that i had last night was interesting
other ideas in lm
syntactic models
condition words on other words that appear in a specific syntactic relation with them
caching models
take advantage of the fact that words appear in bursts
external resources
sri-lm
http://www.speech.sri.com/projects/srilm/
cmu-lm
http://www.speech.cs.cmu.edu/slm/toolkit.html
google id165 corpus
http://googleresearch.blogspot.com/2006/08/all-our-id165-are-belong-to-you.html
google book id165s
http://ngrams.googlelabs.com/
example google id165s
house a		302435
house after	118894
house all	105970
house and	3880495
house are	136475
house arrest	254629
house as	339590
house at	694739
house before	102663
house built	189451
house but	137151
house by	249118
house can	133187
house cleaning	125206
house design	120500
house down	109663
house fire	112325
house for	1635280
house former	112559
house from	249091
house had	154848
house has	440396
house he	115434


house hotel	139282
house in	3553052
house is	1962473
house music	199346
house near	131889
house now	127043
house of	3164591
house on	1077835
house or	1172783
house party	162668
house plan	172765
house plans	434398
house price	158422
house prices	643669
house rental	209614
house rules	108025
house share	101238
house so	133405
house that	687925
house the	478204
house to	1452996
house training	163056
house value	135820
id165 external links
http://googleresearch.blogspot.com/2006/08/all-our-id165-are-belong-to-you.html
http://norvig.com/mayzner.html 
http://storage.googleapis.com/books/ngrams/books/datasetsv2.html
https://books.google.com/ngrams/
http://www.elsewhere.org/pomo/ 
http://pdos.csail.mit.edu/scigen/ 
http://www.magliery.com/band/ 
http://www.magliery.com/country/
http://johno.jsmf.net/knowhow/ngrams/index.php
http://www.decontextualize.com/teaching/rwet/id165s-and-markov-chains/
http://gregstevens.com/2012/08/16/simulating-h-p-lovecraft 
http://kingjamesprogramming.tumblr.com/ 
nlp
