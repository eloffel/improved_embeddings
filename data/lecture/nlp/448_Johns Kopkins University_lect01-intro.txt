601.465/665
natural language processing

prof: jason eisner

webpage: http://cs.jhu.edu/~jason/465

syllabus,
announcements,
slides,
homeworks

1

goals of the field

computers would be a lot more useful if they

could handle our email, do our library
research, talk to us    

but they are fazed by natural human language.

how can we tell computers about language?

(or help them learn it as kids do?)

600.465     intro to nlp     j. eisner

2

a few applications of nlp

    id147, grammar checking    
    better search engines
    information extraction
    psychotherapy; harlequin romances; etc.

    new interfaces:

    id103 (and text-to-speech)
    dialogue systems (uss enterprise onboard computer)
    machine translation (the babel fish)

600.465     intro to nlp     j. eisner

3

goals of the course

    introduce you to nlp problems & solutions
    relation to linguistics & statistics

    at the end you should:

    agree that language is subtle & interesting
    feel some ownership over the formal & statistical

models

    understand research papers in the field

600.465     intro to nlp     j. eisner

4

ambiguity: favorite headlines

    iraqi head seeks arms
    is there a ring of debris around uranus?
    juvenile court to try shooting defendant
    teacher strikes idle kids
    stolen painting found by tree
    kids make nutritious snacks
    local hs dropouts cut in half
    obesity study looks for larger test group

600.465     intro to nlp     j. eisner

5

ambiguity: favorite headlines

    british left waffles on falkland islands
    never withhold herpes infection from loved

one

    red tape holds up new bridges
    man struck by lightning faces battery charge
    clinton wins on budget, but more lies ahead
    hospitals are sued by 7 foot doctors

600.465     intro to nlp     j. eisner

6

levels of language

    id102/phonology/morphology: what
words (or subwords) are we dealing with?
    syntax: what phrases are we dealing with?

which words modify one another?

    semantics: what   s the literal meaning?
    pragmatics: what should you conclude

from the fact that i said something?  how
should you react?

600.465     intro to nlp     j. eisner

7

subtler ambiguity

    q: why does my high school give me a

suspension for skipping class?

    a: administrative error.  they   re supposed
to give you a suspension for auto shop, and
a jump rope for skipping class.

(*rim shot*)

600.465     intro to nlp     j. eisner

8

what   s hard about this story?

john stopped at the donut store on his way

home from work.  he thought a coffee was
good every few hours.  but it turned out to
be too expensive there.

600.465     intro to nlp     j. eisner

9

what   s hard about this story?

john stopped at the donut store on his way

home from work.  he thought a coffee was
good every few hours.  but it turned out to
be too expensive there.

to get a donut (spare tire) for his car?

600.465     intro to nlp     j. eisner

10

what   s hard about this story?

john stopped at the donut store on his way

home from work.  he thought a coffee was
good every few hours.  but it turned out to
be too expensive there.

store where donuts shop?  or is run by donuts?
or looks like a big donut?  or made of donut?
or has an emptiness at its core?

600.465     intro to nlp     j. eisner

11

what   s hard about this story?

i stopped smoking freshman year, but
john stopped at the donut store on his way

home from work.  he thought a coffee was
good every few hours.  but it turned out to
be too expensive there.

600.465     intro to nlp     j. eisner

12

what   s hard about this story?

john stopped at the donut store on his way

home from work.  he thought a coffee was
good every few hours.  but it turned out to
be too expensive there.

describes where the store is?  or when he

stopped?

600.465     intro to nlp     j. eisner

13

what   s hard about this story?

john stopped at the donut store on his way

home from work.  he thought a coffee was
good every few hours.  but it turned out to
be too expensive there.

well, actually, he stopped there from hunger

and exhaustion, not just from work.

600.465     intro to nlp     j. eisner

14

what   s hard about this story?

john stopped at the donut store on his way

home from work. he thought a coffee was
good every few hours.  but it turned out to
be too expensive there.

at that moment, or habitually?

(similarly: mozart composed music.)

600.465     intro to nlp     j. eisner

15

what   s hard about this story?

john stopped at the donut store on his way

home from work.  he thought a coffee was
good every few hours.  but it turned out to
be too expensive there.

that   s how often he thought it?

600.465     intro to nlp     j. eisner

16

what   s hard about this story?

john stopped at the donut store on his way

home from work.  he thought a coffee was
good every few hours.  but it turned out to
be too expensive there.

but actually, a coffee only stays good for

about 10 minutes before it gets cold.

600.465     intro to nlp     j. eisner

17

what   s hard about this story?

john stopped at the donut store on his way

home from work.  he thought a coffee was
good every few hours.  but it turned out to
be too expensive there.

similarly: in america a woman has a baby
every 15 minutes.  our job is to find that
woman and stop her.

600.465     intro to nlp     j. eisner

18

what   s hard about this story?

john stopped at the donut store on his way

home from work.  he thought a coffee was
good every few hours.  but it turned out to
be too expensive there.

the particular coffee that was good every few

hours?  the donut store?  the situation?

600.465     intro to nlp     j. eisner

19

what   s hard about this story?

john stopped at the donut store on his way

home from work.  he thought a coffee was
good every few hours.  but it turned out to
be too expensive there.

too expensive for what?  what are we

supposed to conclude about what john did?

how do we connect    it    to    expensive   ?

600.465     intro to nlp     j. eisner

20

id165s

    letter or word frequencies: 1-grams

(= unigrams)

    useful in solving cryptograms: etaoinshrdlu   

    if you know the previous letter: 2-grams

(= bigrams)

       h    is rare in english (4%; 4 points in scrabble)
    but    h    is common after    t    (20%)

    if you know the previous two letters: 3-grams (= trigrams)

       h    is really common after    (space) t   

etc.    

600.465     intro to nlp     j. eisner

21

some random id165 text    

600.465     intro to nlp     j. eisner

22

