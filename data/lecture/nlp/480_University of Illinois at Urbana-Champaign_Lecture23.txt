introduction
induction: hdp-pid18
bayesian id136
induction experiments
re   nement: hdp-pid18-gr
re   nement experiments

probabilistic grammars and hierarchical dirichlet

processes (liang et. al 2009)

sean massung & gourab kundu

cs 598jhm

april 9th 2013

sean massung & gourab kundu

probabilistic grammars and hierarchical dirichlet processes

introduction
induction: hdp-pid18
bayesian id136
induction experiments
re   nement: hdp-pid18-gr
re   nement experiments

background
mathematical de   nitions
focus

background

this paper (chapter of a book) describes a bayesian approach to
the problem of syntactic parsing and the underlying problems of
grammar induction and grammar re   nement.

grammar induction: estimating grammars based on raw
sentences alone, without any other type of supervision
original approaches had poor performance due to the
coarse-grained nature of the syntactic categories

grammar re   nement:    splitting    coarse-grained syntactic
categories into    ner, more accurate and descriptive labels

e.g. parent annotation (syntactic), lexicalization (semantic)

sean massung & gourab kundu

probabilistic grammars and hierarchical dirichlet processes

introduction
induction: hdp-pid18
bayesian id136
induction experiments
re   nement: hdp-pid18-gr
re   nement experiments

background
mathematical de   nitions
focus

pid18 example

    

spppp
    

vbp

np

prp

vppppp
     

npxxxxx

they

have

jj

jj

nns

many

theoretical

ideas

  

s
s     np vp
s     s conj s
np     jj jj nns
np     prp
vp     vp np
vp     vbp np
vp     vbg np

  s (  )
0.9
0.1
0.5
0.5
0.4
0.3
0.3

sean massung & gourab kundu

probabilistic grammars and hierarchical dirichlet processes

introduction
induction: hdp-pid18
bayesian id136
induction experiments
re   nement: hdp-pid18-gr
re   nement experiments

background
mathematical de   nitions
focus

mathematical de   nition

formally, a pid18 is speci   ed by the following:

  , a set of terminal symbols (the words in the sentence)

s, a set of nonterminal symbols (the syntactic categories)
root     s, a designated nonterminal starting symbol
  , rule probabilities:    = (  s (  ) : s     s,               (s    s)),

such that   s (  )     0 and(cid:80)

     s (  ) = 1

note the restriction on   , that           or        (s    s). such
transitions make a pid18 in chomsky normal form.

sean massung & gourab kundu

probabilistic grammars and hierarchical dirichlet processes

introduction
induction: hdp-pid18
bayesian id136
induction experiments
re   nement: hdp-pid18-gr
re   nement experiments

background
mathematical de   nitions
focus

mathematical de   nition ii

a parse tree has a set of nonterminal nodes n along with the
corresponding symbols s = (si     s, i     n). now, let

ne denote nodes having one terminal child,
nb denote nodes having two nonterminal children

the tree structure is represented by

c = (cj (i) : i     nb , j = 1, 2) for nonterminal nodes
x = (xi : i     ne ) for terminal nodes (the    yield   )

the joint id203 of a parse tree z = (n, s, c) and x is then

p(x, z|  ) =

  si (sc1(i), sc2(i))

  si (xi )

(cid:89)

i   nb

(cid:89)

i   ne

sean massung & gourab kundu

probabilistic grammars and hierarchical dirichlet processes

introduction
induction: hdp-pid18
bayesian id136
induction experiments
re   nement: hdp-pid18-gr
re   nement experiments

background
mathematical de   nitions
focus

hdp-pid18: generating the parse tree and its yield

so, given rule probabilities   , for each syntactic category z
consisting of   t
parameters), and   b
and its parse in the following way:

z (rule type parameters),   e

z (binary productions), we can generate a tree

z (emission

for each node i in the parse tree:

)

zi

ti     mult(  t
if ti = emission, xi     mult(  e
if ti = binaryproduction, (zc1(i), zc2(i))     mult(  b

zi

)

)

zi

sean massung & gourab kundu

probabilistic grammars and hierarchical dirichlet processes

introduction
induction: hdp-pid18
bayesian id136
induction experiments
re   nement: hdp-pid18-gr
re   nement experiments

background
mathematical de   nitions
focus

this paper   s focus

traditionally, pid18s are de   ned with a    xed,    nite s and the
parameters    are    t using smoothed maximum likelihood

this paper develops a nonparametric version of the pid18
that allows s to be countably in   nite

the model then performs posterior id136 over s and the
set of parse trees to    nd   

this model is called a hierarchical dirichlet process pid18
(hdp-pid18), and is described in the next section

sean massung & gourab kundu

probabilistic grammars and hierarchical dirichlet processes

introduction
induction: hdp-pid18
bayesian id136
induction experiments
re   nement: hdp-pid18-gr
re   nement experiments

the model
discussion

hdp-pid18: generating the grammar

       gem(  )
for each grammar symbol z     {1, 2, . . .}:

z     dir (  t )
  t
z     dir (  e )
  e
z     dp(  b ,     (cid:62))
  b

what do   ,   

{t ,e ,b}
z

, and     (cid:62) look like?

sean massung & gourab kundu

probabilistic grammars and hierarchical dirichlet processes

introduction
induction: hdp-pid18
bayesian id136
induction experiments
re   nement: hdp-pid18-gr
re   nement experiments

the model
discussion

hdp-pid18: the whole process

       gem(  )
for each grammar symbol z     {1, 2, . . .}:

z     dir (  t )
  t
z     dir (  e )
  e
z     dp(  b ,     (cid:62))
  b

for each node i in the parse tree:

)

zi

ti     mult(  t
if ti = emission, xi     mult(  e
if ti = binaryproduction, (zc1(i), zc2(i))     mult(  b

zi

)

)

zi

sean massung & gourab kundu

probabilistic grammars and hierarchical dirichlet processes

introduction
induction: hdp-pid18
bayesian id136
induction experiments
re   nement: hdp-pid18-gr
re   nement experiments

the model
discussion

why is an hdp model advantageous?

allows the complexity of the grammar to grow as more
training data is available; a dp prior penalizes the use of more
symbols than are supported in the training data

. . . which in turn means the level of sophistication of the
grammar can adequately match the corpus

can you think of any disadvantages?

sean massung & gourab kundu

probabilistic grammars and hierarchical dirichlet processes

introduction
induction: hdp-pid18
bayesian id136
induction experiments
re   nement: hdp-pid18-gr
re   nement experiments

the model
discussion

hierarchical dirichlet process

how is this a hierarchical dp?

how is this related to the hdp-id48 from thursday?

why not a simpler model: for each symbol z, draw a
distribution separately over left children lz     dp(  ) and right
children rz     dp(  )?

sean massung & gourab kundu

probabilistic grammars and hierarchical dirichlet processes

introduction
induction: hdp-pid18
bayesian id136
induction experiments
re   nement: hdp-pid18-gr
re   nement experiments

framing the problem
coordinate ascent

bayesian id136 for hdp-pid18

the authors chose to use structured mean-   eld approximation
(variational id136 with kl-divergence as a dissimilarity
function)

the random variables of interest are the parameters
   = (  ,   ), the parse tree z, and the observed yield x
thus the goal is to approximate the posterior p(  , z|x). we
want to    nd a q(  , z) such that

kl(q(  , z)||p(  , z|x))

argmin
q   q

where q is a tractable subset of distributions.

sean massung & gourab kundu

probabilistic grammars and hierarchical dirichlet processes

introduction
induction: hdp-pid18
bayesian id136
induction experiments
re   nement: hdp-pid18-gr
re   nement experiments

framing the problem
coordinate ascent

bayesian id136 for hdp-pid18

the set of approximate distributions q are de   ned to be those
that factor as follows:

(cid:35)

(cid:41)

(cid:40)

(cid:34)

k(cid:89)

q =

q :

q(  )

q(  t

z )q(  e

z )q(  b
z )

q(z)

additionally, other constraints are introduced:

z=1

q(  ) is degenerate and truncated

{t ,e ,b}
z

q(  

) are dirichlet distributions

q(z) is any multinomial distribution

note that we have a    xed k . how does this a   ect the
approximation?

sean massung & gourab kundu

probabilistic grammars and hierarchical dirichlet processes

introduction
induction: hdp-pid18
bayesian id136
induction experiments
re   nement: hdp-pid18-gr
re   nement experiments

framing the problem
coordinate ascent

coordinate ascent

the optimization problem to    nd the best q is non-convex

they use a coordinate ascent algorithm to    nd a local
optimum
iteratively,

1 optimize q(z), keeping q(  ) and q(  )    xed
2 optimize q(  ), keeping q(z) and q(  )    xed
3 optimize q(  ), keeping q(z) and q(  )    xed

sean massung & gourab kundu

probabilistic grammars and hierarchical dirichlet processes

introduction
induction: hdp-pid18
bayesian id136
induction experiments
re   nement: hdp-pid18-gr
re   nement experiments

framing the problem
coordinate ascent

prediction

we want to parse a new sentence with the induced grammar.

the prediction is given by

z   
new = argmax

znew

ep(  ,z|x)p(znew|  , xnew )

sean massung & gourab kundu

probabilistic grammars and hierarchical dirichlet processes

introduction
induction: hdp-pid18
bayesian id136
induction experiments
re   nement: hdp-pid18-gr
re   nement experiments

synthetic experiment

from a grammar of 15 rules, 1000 sentences were sampled

with latent symbols, pid18 recovered a grammar of 150
active rules

hdp-pid18 yielded a grammar of 25 active rules

sean massung & gourab kundu

probabilistic grammars and hierarchical dirichlet processes

introduction
induction: hdp-pid18
bayesian id136
induction experiments
re   nement: hdp-pid18-gr
re   nement experiments

sample grammar inductions

true grammar

    np vp
s
    dt nn
np
    dt npbar
np
npbar     jj nn
npbar     jj nbpar
    vb np
vp
    the
dt
    a
dt
    big
jj
    black
jj
    mouse
nn
    cat
nn
    dog
nn
    chased
vb
    ate
vb

1.0
0.5
0.5
0.5
0.5
1.0
0.5
0.5
0.5
0.5
0.33
0.33
0.33
0.5
0.5

induced grammar

    np vp
s
    dt nn
np
    dt npbar
np
    vb np
vp
    jj2 npbar
npbar
    jj1 npbar
npbar
    jj-big nn
npbar
    jj2 nn
npbar
    jj2 nn-{cat, dog}
npbar
    a
dt
    the
dt
    big
jj1
    black
jj1
    big
jj-big
    black
jj2
    big
jj2
    mouse
nn
    dog
nn
    cat
nn
nn-{cat, dog}     cat
nn-{cat, dog}     dog
    chased
vb
    ate
vb

1.0
0.5
0.5
1.0
0.11
0.36
0.07
0.42
0.02
0.5
0.5
0.52
0.48
1.0
0.59
0.41
0.35
0.32
0.33
0.47
0.53
0.49
0.51

sean massung & gourab kundu

probabilistic grammars and hierarchical dirichlet processes

introduction
induction: hdp-pid18
bayesian id136
induction experiments
re   nement: hdp-pid18-gr
re   nement experiments

sample parse trees

true parse

induced parse

    
np
ll,,

spppp
   
vb

dt

nn

the

cat

ate

nphhh

vphhh
   
dt

the

    
np
ll,,
nn

spppp
!!!
vb

dt1

the

cat

ate

npbar
qq  
nn
jj

vpaaa
   
dt2

the

nphhh

npbar
qq  
nn
jj2

black

mouse

black

mouse

sean massung & gourab kundu

probabilistic grammars and hierarchical dirichlet processes

introduction
induction: hdp-pid18
bayesian id136
induction experiments
re   nement: hdp-pid18-gr
re   nement experiments

hdp-pid18-gr

we want to use treebanks as labeled data
treebank symbols (node types) are coarse

noun phrase can be subject or object and have a di   erent
behavior

we need to model subsymbols

npsubj , npobj , etc

each node is now a combination of a symbol and a subsymbol

sean massung & gourab kundu

probabilistic grammars and hierarchical dirichlet processes

introduction
induction: hdp-pid18
bayesian id136
induction experiments
re   nement: hdp-pid18-gr
re   nement experiments

the generative process

for each symbol s     s

  s     gem(  )
for each subsymbol z     {1, 2, ...}

sz     dir (  t )
  t
sz     dir (  e (s))
  e
sz     dir (  u(s))
  u
for each child symbol s(cid:48)     s

szs(cid:48)     dp(  u ,   s(cid:48) )
  u

sz     dir (  b(s))
  b
for each pair of child symbols (s(cid:48), s(cid:48)(cid:48))     s    s

szs(cid:48)s(cid:48)(cid:48)     dp(  b ,   s(cid:48) ,   t
  b
s(cid:48)(cid:48) )

sean massung & gourab kundu

probabilistic grammars and hierarchical dirichlet processes

introduction
induction: hdp-pid18
bayesian id136
induction experiments
re   nement: hdp-pid18-gr
re   nement experiments

the generative process ii

for each node i in the parse tree

ti     mult(  t
)
if ti = emission
xi     mult(  e

si ,zi

si ,zi )
sc1(i)     mult(  u
zc1(i)     mult(  u

if ti = unaryproduction

si ,zi )
si ,zi ,sc1(i)

)

if ti = binaryproduction
(sc1(i), sc2(i))     mult(  si ,zi )
(zc1(i), zc2(i))     mult(  b

si ,zi ,sc2(i)

)

sean massung & gourab kundu

probabilistic grammars and hierarchical dirichlet processes

introduction
induction: hdp-pid18
bayesian id136
induction experiments
re   nement: hdp-pid18-gr
re   nement experiments

synthetic re   nement experiment

2000 trees were constructed and xi was replaced by x
20 subsymbols were used for both s and x

s     x1x1|x2x2|x3x3|x4x4
x1     a1|b1|c1|d1
x2     a2|b2|c2|d2
x3     a3|b3|c3|d3
x4     a4|b4|c4|d4

!!!
xi

saaa
xj

{ai bi ci di}

{aj bj cj dj}

sean massung & gourab kundu

probabilistic grammars and hierarchical dirichlet processes

introduction
induction: hdp-pid18
bayesian id136
induction experiments
re   nement: hdp-pid18-gr
re   nement experiments

results

pid18 used all 20 subsymbols of both s and x

hdp-pid18-gr used only 4 subsymbols of x and one from s

sean massung & gourab kundu

probabilistic grammars and hierarchical dirichlet processes

introduction
induction: hdp-pid18
bayesian id136
induction experiments
re   nement: hdp-pid18-gr
re   nement experiments

real dataset experiment i

hdp-pid18-gr trained on section 2 and tested on section 22 of
the id32

k

1
2
4
8
12
16
20

pid18-gr
size
f1
2558
3788
3141
4262
7297
19616
27593

60.47
69.53
75.98
74.32
70.99
66.99
64.44

pid18-gr (smoothed)

hdp-pid18-gr

f1

60.36
69.38
77.11
79.26
78.80
79.20
79.27

size
2597
4614
12436
120598
160403
261444
369699

f1

60.50
71.08
77.17
79.15
78.94
78.24
77.81

size
2557
4264
9710
50629
86386
131377
202767

sean massung & gourab kundu

probabilistic grammars and hierarchical dirichlet processes

introduction
induction: hdp-pid18
bayesian id136
induction experiments
re   nement: hdp-pid18-gr
re   nement experiments

real dataset experiment ii

they experimented with the standard parsing setting by training
on sections 2-21. hdp-pid18-gr gave comparable performance
with the smaller grammar

k

16

pid18-gr
f1
size

hdp-pid18-gr

f1

size

88.36

706157

87.08

428375

sean massung & gourab kundu

probabilistic grammars and hierarchical dirichlet processes

