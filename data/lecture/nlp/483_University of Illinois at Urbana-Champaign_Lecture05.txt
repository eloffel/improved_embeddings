cs598jhm: advanced nlp  (spring 2013)
http://courses.engr.illinois.edu/cs598jhm/

lecture 5:
sampling 
(monte carlo methods)

julia hockenmaier
juliahmr@illinois.edu
3324 siebel center
of   ce hours: by appointment

the goal of monte carlo methods
given a target distribution p(x) that we cannot evaluate 
exactly, we use monte carlo (= sampling) methods to:
1. generate samples { x(1) ... x(r)... x(r) } from p(x)

2. estimate the expectation of functions   (x) under p(x)
in bayesian approaches, model parameters    are also 
random variables. so, the target distribution p(x) may 
in fact be p(   | d), the posterior of    given the data  

bayesian methods in nlp

2

the expectation    of   (x):

   =      (x)   p(x) =    x p(x)  (x)

we can estimate    by monte carlo integration: 
draw a    nite number of samples {x(1)...x(r)} from p(x) 
and estimate    as

    =

 (x(r))

1

rxr

the variance of    is a function of   2 /r 
(  2 is the variance of   (x);  r is the number of samples).
   2  = e[(         )2 | x] =    x p(x) (  (x)       )2

the accuracy of    is independent of the dimensionality of x. 
a dozen independent samples from p(x) may be enough

bayesian methods in nlp

3

why is sampling hard?
we need to be able to draw independent samples from p(x)
this is dif   cult, because:

-our models are often of the form p(x)     f(x)  
i.e p(x) = f(x) / z 

-  we often cannot compute the partition function z =    x    f(x   ) 
because we usually operate in very high dimensions 
(or very large state spaces).

bayesian methods in nlp

4

sampling methods
sampling from a    xed proposal distribution q(x)     p(x):

-uniform sampling
-importance sampling
-rejection sampling
id115 (mcmc)
sampling from a markov chain: the id203 of the next 
sample (= proposal distribution) depends on the current state

-metropolis-hastings
-id150

bayesian methods in nlp

5

uniform sampling 
assume q(x) is uniform. draw samples x(r)      q(x) (uniformly) 
from the state space, evaluate p(x(r))  at x(r) 
this gives a new distribution

estimate      (x)   p(x) as

p 0(x(r)) =

f (x(r))
i=1 f (x(i))

pr

    =xr

 (x(r))p 0(x(r))

problem: unless p(x) itself is close to uniform, this strategy will 
be very inef   cient. in high-dimensional spaces, most regions of 
the state space have typically very low id203

bayesian methods in nlp

6

importance sampling

importance sampling can be used to compute expectations   
assumptions: 

- we can evaluate p(x)     f(x) at any point
- we have a simple sample density q(x)     g(x), 
which we can evaluate and draw samples from,
- for any x: if p(x) > 0, then also q(x) > 0 

algorithm 

- draw samples from q(x)     g(x)
- re-weight samples by wr = f(x(r))/g(x(r))
- estimate     as 

  r wrf (x(r))

  f =

  r wr

this converges to   . but:  we can   t estimate the variance of   . 
the empirical variances of wr and wr  (x(r)) may not be a good 
indicator of their true variances
bayesian methods in nlp

7

f(x) g(x)rejection sampling
assumptions: 

- we can evaluate p(x)     f(x) at any point
- we have a simple proposal density q(x)     g(x), 
which we can evaluate and draw samples from
- we know the value of a constant c such that cg(x) > f(x)

algorithm:

- sample x     q(x) and evaluate cg(x) 
- sample y     uniform([0, cg(x)])
- if f(x)     y, accept x, else reject x

this returns independent samples from p(x)
problems:
acceptance rate:    p(x)dx/   cq(x) dx = 1/c 
but c grows exponentially with the dimensionality of x
bayesian methods in nlp

cg(x   )

cg(x)

y   

x   

y

x

8

f(x) cg(x)reject x!accept x!x(1)

...

id115
rejection sampling and importance sampling
only work well when q(x) is similar to p(x).
this is dif   cult to achieve in high dimensions.
id115 methods generate
a sequence of samples x(1)... x(t)... x(t)  
 x(t+1)  is drawn from a proposal distribution q(x; x(t)) 
which depends on the last sample x(t) 
advantage: q(x; x(t)) does not have to be similar to p(x)
disadvantage: the samples x(t) are correlated, and not 
independent. we may have to generate a lot of samples 
(t     r) to get a sequence of r independent samples x(1)... x(r)
bayesian methods in nlp

...
x(25)

9

f(x) q(x;x(1))f(x) q(x;x(25))markov chains
a (discrete-time, discrete-state) markov chain 
over n states {x1,...,xn} is de   ned by

-an n-dimensional multinomial p(0), 
the initial distribution over  the states {x1,...,xn}

-an n  n transition matrix a 
that de   nes the transition id203 
of moving from state xi to state xj :
aij = p(x(t+1) = xj | x(t) = xi) 

the markov chain de   nes a sequence of distributions p(0)...p(t)... 
over the states  {x1,...,xn}:

p(t) = p(t -1)    a =  p(0)    a(t-1)

bayesian methods in nlp

10

more markov chain terminology
a markov chain is irreducible if any state can be reached from 
any other state with nonzero id203.
an irreducible markov chain is recurrent if the id203 of 
reaching any state xj from any state xi in    nite time is 1.
an irreducible, recurrent markov chain is positive recurrent 
if it has a stationary (= equilibrium) distribution     = lim t      p(t)
an ergodic markov chain will converge to    
regardless of its start state.
a reversible markov chain obeys detailed balance:
  (xi) p(x(t+1) = xj | x(t) = xi) =   (xj) p(x(t+1) = xi | x(t) = xj)

bayesian methods in nlp

11

mcmc: metropolis-hastings

algorithm:
1. given the last sample x(t), generate x        q(x; x(t))

2. compute

a =

f (x0)
f (x(t))

q(x(t);x0)
q(x0;x(t))

=

p(x0)
p(x(t))

q(x(t);x0)
q(x0;x(t))

3. if a > 1: accept x` 
  otherwise, accept x` with id203 a

4. if x    is accepted: x(t+1) = x`
  otherwise, x(t+1) = x(t)

regardless of q(x; x(t)), this algorithm samples from an ergodic 
markov chain with states x and stationary distribution p(x).

bayesian methods in nlp

12

why q(x; x(t)) can be any distribution

ai j

accept(xi,x j)
accept(xi,x j) < 1

=

f (x j)
f (xi)

q(xi;x j)
q(xi;x j)

=

p(x j)
p(xi)

q(xi;x j)
q(xi;x j)

=

1
a ji

= min(1,ai j)
) accept(x j,xi) = 1

x j 6= xi
x j = xi

the transition matrix of the markov chain is de   ned as

p(x j|xi) = q(x j;xi)accept(xi,x j)
p(x j|xi) = q(x j;xi) +   1 z q(xk;xi)accept(xi,xk) dxk

assume accept(xi , xj) = aij < 1. thus accept(xj , xi) = 1

accept(xi , xj ) p(xi) q(xj ; xi ) = p(xj) q(xi ; xj ) accept(xj , xi) 

p(xi) p(xj | xi ) = p(xj) p(xi | xj ) 

this obeys detailed balance. 
the equilibrium distribution is p(xi) regardless of q(x   ; x )

bayesian methods in nlp

13

why q(x; x(t)) still matters
convergence:
how many steps does it take to reach the equilibrium distribution?
-if q is positive (q(x   ; x) > 0 for all x   ; x), the distribution of x(t) is 
guaranteed to converge to  p(x) in the limit.
- but: convergence is dif   cult to assess.
- the steps before equilibrium is reached should be ignored 
(burn-in)

mixing: how fast does the chain move around the state space?
rejection rate:

- if the step size (distance btw. x    and x(t)) is large, 
the rejection id203 can be high
- if the step size is too small, only a small region of the sample 
space may be explored (= slow mixing)

bayesian methods in nlp

14

mcmc variants
metropolis algorithm
q(x   ; x) is symmetric: q(x   ; x) = q(x; x   )

a =

f (x0)
f (x(t))

=

p(x0)
p(x(t))

single-component metropolis-hastings
-x is divided into components x1...xn
notation: x-i  := {x1, ..., xi-1, xi+1, ..., xn} (all components other than xi)
-at each iteration t, sample each xi in turn, using 
the full conditional distribution p(xi | x -i) = p(x)/   p(x)dxi
and proposal distributions qi(xi | xi(t), x -i(t)) and qi(xi(t) | xi, x-i(t))

bayesian methods in nlp

15

 mcmc: id150
assumptions:

- x is a multivariate random variable: x = (x1,...,xn)
- the full conditionals p(xi |  x1,...,xi-1,  xi+1,...,xn ) (=the conditional 
probabilities of each component given the rest), are easy to 
evaluate (also true if we split the components of x into blocks)

algorithm:
 for t = 1...t:
    for i = 1...n:
       sample xi(t)     p(xi |  x1(t),...,xi-1(t),    xi+1(t-1),...,xn(t-1))
 
id150 is single-component metropolis-hastings without 
rejection. think of it as using the full conditionals as proposal 
distributions (so the two fractions cancel, and hence a = 1)

qi(xi | xi(t), x -i(t)) =  p(xi |  x1(t),...,xi-1(t),    xi+1(t-1),...,xn(t-1))
qi(xi(t) | xi, x-i(t)) =  p(xi(t) |  x1(t),...,xi-1(t),    xi+1(t-1),...,xn(t-1))

bayesian methods in nlp

16

how should we generate samples?

the longer a chain runs, the more likely it is to 
have converged.
but it   s dif   cult to know from a single chain
whether it has converged (or is just slow to mix).

multiple parallel chains (with independent 
starting points) can help identify convergence/
mixing problems: do they all generate the same 
(=indistinguishable) sequences of samples?

compare within-sequence variance and across-
sequence variance.

n.b.: starting points may come from simpler 
models.

17

bayesian methods in nlp

burn-insamplingsamplingsamplingsamplingsamplingsamplingburn-insamplingsamplingburn-insamplingsamplingburn-insamplingsamplingburn-insamplingburn-insamplingburn-insamplingburn-insamplingburn-insamplingburn-insampling