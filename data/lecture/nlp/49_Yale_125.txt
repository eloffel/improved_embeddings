nlp
introduction to nlp
bayes    theorem
bayes    theorem
formula for joint id203
p(a,b) = p(b|a)p(a)
p(a,b) = p(a|b)p(b)
therefore
p(b|a) = p(a|b)p(b)/p(a)
bayes    theorem is used to calculate p(a|b) given p(b|a)

example
diagnostic test
test accuracy
p(positive |    disease) = 0.05               false positive
p(negative | disease) = 0.05                false negative
so: p(positive | disease) = 1-0.05 = 0.95
same for p(negative |    disease)
in general the rates of false positives and false negatives are different
example
diagnostic test with errors
example
what is p(disease | positive)?
p(disease|positive) = p(positive|disease)*p(disease)/p(positive)
p(   disease|positive) = p(positive|    disease)*p(   disease)/p(positive)
p(disease|positive)/p(   disease|positive) = ?
we don   t really care about p(positive)
as long as it is not zero, we can divide both sides by this quantity
example
p(disease|positive) / p(   disease|positive) = 
	(p(positive|disease) x p(disease))/(p(positive|   disease) x p(   disease))
suppose p(disease) = 0.001  
so p(   disease) = 0.999
p(disease|positive) / p(   disease|positive) = (0.95 x 0.001)/(0.05 x 0.999) 	=0.019
p(disease|positive) + p(   disease|positive) = 1
p(disease|positive)     0.02
notes
p(disease) is called the prior id203
p(disease|positive) is called the posterior id203
in this example the posterior is 20 times larger than the prior

example
p(well)=0.9, p(cold)=0.05, p(allergy)=0.05
p(sneeze|well)=0.1
p(sneeze|cold)=0.9
p(sneeze|allergy)=0.9
p(cough|well)=0.1
p(cough|cold)=0.8
p(cough|allergy)=0.7
p(fever|well)=0.01
p(fever|cold)=0.7
p(fever|allergy)=0.4
example from ray mooney
example (cont   d)
features: sneeze, cough, no fever
p(well|e)=(.9) * (.1)(.1)(.99) / p(e)=0.0089/p(e)
p(cold|e)=(.05) * (.9)(.8)(.3) / p(e)=0.01/p(e)
p(allergy|e)=(.05) * (.9)(.7)(.6) / p(e)=0.019/p(e)
p(e) = 0.0089+0.01+0.019=0.379
p(well|e)=.23
p(cold|e)=.26
p(allergy|e)=.50
bayes    theorem
hypothesis space: h={h1 ,    , hn}		evidence: e
if we want to pick the most likely hypothesis h*,  we can drop p(e)
in text classification: h: class space; e: data (features)
[slide from qiaozhu mei]
getting to statistics ...
we are flipping an unfair coin, but p(head)=? 
(parameter estimation)
if we see the results of a huge number of random experiments, then 


but, what if we only see a small sample (e.g., 2)? is this estimate still reliable? we flip twice and got two tails, does it mean p(head) = 0?
in general, statistics has to do with drawing conclusions on the whole population based on observations of a sample (data)
[slide from qiaozhu mei]
parameter estimation
general setting:
given a (hypothesized & probabilistic) model that governs the random experiment
the model gives a id203 of any data p(d|   ) that depends on the parameter    
now, given actual sample data x={x1,   ,xn},  what can we say about the value of    ?
intuitively, take your best guess of    
   best    means    best explaining/fitting the data   
generally, this is an optimization problem
[slide from qiaozhu mei]
maximum likelihood vs. bayesian
id113
   best    means    data likelihood reaches maximum   

problem: small sample
bayesian estimation
   best    means being consistent with our    prior    knowledge and explaining data well
problem: how to define the prior?
[slide from qiaozhu mei]

posterior:
 p(   |x)    p(x|   )p(   )


   


[slide from qiaozhu mei]
bayesian estimation
example: an unfair die
it   s more likely to get a 6 and less likely to get a 1
p(6) > p(1)
how likely?
what if you toss the die 1000 times, 
and observe    6    501 times, 
   1    108 times?
p(6) = 501/1000 = 0.501
p(1) = 108/1000 = 0.108
as simple as counting, but principled     maximum likelihood estimate
[slide from qiaozhu mei]
what if the die has more faces?
suitable to represent documents
every face corresponds to a word in vocabulary
the author tosses a die 
to write a word
apparently, an unfair die
[slide from qiaozhu mei]
nlp
