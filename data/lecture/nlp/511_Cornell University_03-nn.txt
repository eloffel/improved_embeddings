cs5740: natural language processing

spring 2018

neural networks

instructor: yoav artzi

slides adapted from dan klein, dan jurafsky, chris manning, 
michael collins, luke zettlemoyer, yejin choi, and slav petrov

overview

    introduction to neural networks
    word representations
    nn optimization tricks

some history

    neural network algorithms date from the 80   s

    originally inspired by early neuroscience

    historically slow, complex, and unwieldy
    now: term is abstract enough to encompass 

almost any model     but useful!

    dramatic shift in last 2-3 years away from 

maxent (linear, convex) to    neural net    (non-
linear architecture)

the    promise   

    most ml works well because of human-

designed representations and input features

    ml becomes just optimizing weights
    representation learning attempts to 
automatically learn good features and 
representations

    deep learning attempts to learn multiple 

levels of representation of increasing 
complexity/abstraction

neuron

    neural networks comes with their 

terminological baggage

    parameters: 

    weights: wi and b
    activation function
you of something?

    if we drop the activation function, reminds 

biological    inspiration   

neural network

neural network

matrix notation
w00(w0a + b0) + b00

o1 = w0011h1 + w0012h2 + b001

h1 = w011a1 + w012a2 + b01
w00

w0

<latexit sha1_base64="9wbipsfwccy6fyt0zwnfj2uiyn0=">aaab8nicbvbnswmxfhzrz61fvy9egkxqqeykon6kxjxwcg2hu5rsmm1ds8msziwy9g948adi1v/jzx9jtt2dtg4ehpn3ejojus60cd1vz2v1bx1js7jv3d7z3duvhrw+apkpqn0iuvtdcgvkmac+yybtbqootijoo9h4tva7t1rpjswdmaq0tpbqsjgrbkwubak2oyjoo9ngo1+ru013brrmvjluous7x/skbpjkcrwgckx1z3nte+zyguy4nvadtnmukzee0p6laiduh/ks8xsdwmwayqnsewbn1n8bou60nisrnswy6kwvep/zepmjr8kcitqzvjd5otjjyehufiagtffi+mqstbszwrezyywjstvvbqne4pexix/evg669xf11k3zrgwo4qtowinlamedtmehaik8wyu8oznz4rw7h/prfafcoyi/cd5/ap2xkta=</latexit>
<latexit sha1_base64="9wbipsfwccy6fyt0zwnfj2uiyn0=">aaab8nicbvbnswmxfhzrz61fvy9egkxqqeykon6kxjxwcg2hu5rsmm1ds8msziwy9g948adi1v/jzx9jtt2dtg4ehpn3ejojus60cd1vz2v1bx1js7jv3d7z3duvhrw+apkpqn0iuvtdcgvkmac+yybtbqootijoo9h4tva7t1rpjswdmaq0tpbqsjgrbkwubak2oyjoo9ngo1+ru013brrmvjluous7x/skbpjkcrwgckx1z3nte+zyguy4nvadtnmukzee0p6laiduh/ks8xsdwmwayqnsewbn1n8bou60nisrnswy6kwvep/zepmjr8kcitqzvjd5otjjyehufiagtffi+mqstbszwrezyywjstvvbqne4pexix/evg669xf11k3zrgwo4qtowinlamedtmehaik8wyu8oznz4rw7h/prfafcoyi/cd5/ap2xkta=</latexit>
<latexit sha1_base64="9wbipsfwccy6fyt0zwnfj2uiyn0=">aaab8nicbvbnswmxfhzrz61fvy9egkxqqeykon6kxjxwcg2hu5rsmm1ds8msziwy9g948adi1v/jzx9jtt2dtg4ehpn3ejojus60cd1vz2v1bx1js7jv3d7z3duvhrw+apkpqn0iuvtdcgvkmac+yybtbqootijoo9h4tva7t1rpjswdmaq0tpbqsjgrbkwubak2oyjoo9ngo1+ru013brrmvjluous7x/skbpjkcrwgckx1z3nte+zyguy4nvadtnmukzee0p6laiduh/ks8xsdwmwayqnsewbn1n8bou60nisrnswy6kwvep/zepmjr8kcitqzvjd5otjjyehufiagtffi+mqstbszwrezyywjstvvbqne4pexix/evg669xf11k3zrgwo4qtowinlamedtmehaik8wyu8oznz4rw7h/prfafcoyi/cd5/ap2xkta=</latexit>

a1

a2

h2 = w021a1 + w022a2 + b02

o2 = w0021h1 + w0022h2 + b002

neuron and other models

    a single neuron is a id88
    strong connection to maxent     how? 

from maxent to neural nets

    vector form maxent:

    for two classes:

p (y1|x; w) =

=

=

=

logisitc
function
(sigmoid)

ew> (x,y)

py0 ew> (x,y0)

p (y|x; w) =

ew> (x,y1)

ew> (x,y1) + ew> (x,y2)

ew> (x,y1)

ew> (x,y1) + ew> (x,y2)

1

e w> (x,y1)
e w> (x,y1)

1 + ew>( (x,y2)  (x,y2))
1 + e w>z = f (w>z)

1

z =  (x, y1)    (x, y2)

from maxent to neural nets

    vector form maxent:

    for two classes:

p (y|x; w) =

ew> (x,y)

py0 ew> (x,y0)
1 + e w>z = f (w>z)

1

p (y1|x; w) =

    add an    always on    feature for class prior    bias 

    neuron:
term (b)

hw,b(z) = f (w>z + b)

f (u) =

1

1 + e u

neural net = several maxent

models

    feed a number of 
maxent models   
vector of outputs

    and repeat    

neural net = several maxent

models

    but: how do we tell the hidden layer what to do?

    learning will figure it out

how to train?

    no hidden layer:

    supervised
    just like maxent

    with hidden layers:

    latent units    not convex
    what do we do?

    back-propagate the gradient
    about the same, but no guarantees

probabilistic output from neural 

nets

    what if we want the 

output to be a 
id203 distribution 
over possible outputs?
    normalize the output 

activations using 
softmax:

y = softmax(w    z + b)
softmax(q) =

    where      is the output 
pk

eq
j=1 eqj

layer

word representations

       hotel   ,    conference   ,    walking   ,    ___ing   

    so far, atomic symbols:
    but neural networks take vector input
    how can we bridge the gap?
    one-hot vectors

hotel =           [0 0 0 0     0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0]
conference = [0 0 0 0     0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0]
    dimensionality:
    size of vocabulary
    20k for speech
    500k for broad-coverage domains
    13m for google corpora

word representations

    one-hot vectors:

hotel =           [0 0 0 0     0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0]
conference = [0 0 0 0     0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0]
hotels         = [0 0 0 0     0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1]
    problems?
    information sharing? 

       hotel    vs.    hotels   

id27s

    each word is represented using a dense 

low-dimensional vector
    low-dimensional << vocabulary size

    if trained well, similar words will have 

    how to train? what objective to maximize? 

similar vectors

    soon    

id27s as features
    example: sentiment classification 

    very positive, positive, neutral, negative, very 

negative

    feature-based models: bag of words
    any good neural net architecture?

    concatenate all the vectors

    problem: different document    different length

    instead: sum, average, etc.

neural bag-of-words

deep 
averaging 
networks

imdb id31
bow + fancy 
smoothing + id166
nbow + dan

89.4

88.23

[iyyer et al. 2015; wang and manning 2012]

practical tips

    select network structure appropriate for the problem

    window vs. recurrent vs. recursive
    non-linearity function

    if you build from scratch

    gradient checks to identify bugs
    parameter initialization
    model is powerful enough?

    if not, make it larger 
    yes, so regularize, otherwise it will overfit

    know your non-linearity function and its gradient

    example tanh(x)

@
@x

<latexit sha1_base64="mxdcfmue8hmbi35xmpkn1bc8ou4=">aaacjxicbzdlssnafiyn9vbrlerszwar6sksfefdfipuxfywttdgmplo2qgtszizsevo07jxvdy4qck48lwctmfl6w8dh/85hzpn9yjgpbksdyo3tlyyupzfl2xsbm3vmlt7dzkmbsyodlkomh6shffoheuvi81iebr4jds8wvvabzwqiwnib9uoim6aepz6fcolry5zbfsc4aqdiaeoyunvgkpnioak8f64ndygvwifwb/rvqlnjlm0ytzucbhsdiogu71jttrdemcb4qozjgxltilljulkzmi40i4liraeob5paeqoinjnpmeo4zf2utaphx5cwan7eyjbgzsjwnodavj9ov9lzf9qrvj5525cerqrwvfskr8zqekyzga7vbcs2egdwolqv0lcrzo3pzmt6bds+zmxwamul8rwzwmxdpmlkqch4bcuga3oqa1cgzpwaaap4blmwkvxzlwyb8b7rdvnzdp74i+mzy8ahaul</latexit>
<latexit sha1_base64="mxdcfmue8hmbi35xmpkn1bc8ou4=">aaacjxicbzdlssnafiyn9vbrlerszwar6sksfefdfipuxfywttdgmplo2qgtszizsevo07jxvdy4qck48lwctmfl6w8dh/85hzpn9yjgpbksdyo3tlyyupzfl2xsbm3vmlt7dzkmbsyodlkomh6shffoheuvi81iebr4jds8wvvabzwqiwnib9uoim6aepz6fcolry5zbfsc4aqdiaeoyunvgkpnioak8f64ndygvwifwb/rvqlnjlm0ytzucbhsdiogu71jttrdemcb4qozjgxltilljulkzmi40i4liraeob5paeqoinjnpmeo4zf2utaphx5cwan7eyjbgzsjwnodavj9ov9lzf9qrvj5525cerqrwvfskr8zqekyzga7vbcs2egdwolqv0lcrzo3pzmt6bds+zmxwamul8rwzwmxdpmlkqch4bcuga3oqa1cgzpwaaap4blmwkvxzlwyb8b7rdvnzdp74i+mzy8ahaul</latexit>
<latexit sha1_base64="mxdcfmue8hmbi35xmpkn1bc8ou4=">aaacjxicbzdlssnafiyn9vbrlerszwar6sksfefdfipuxfywttdgmplo2qgtszizsevo07jxvdy4qck48lwctmfl6w8dh/85hzpn9yjgpbksdyo3tlyyupzfl2xsbm3vmlt7dzkmbsyodlkomh6shffoheuvi81iebr4jds8wvvabzwqiwnib9uoim6aepz6fcolry5zbfsc4aqdiaeoyunvgkpnioak8f64ndygvwifwb/rvqlnjlm0ytzucbhsdiogu71jttrdemcb4qozjgxltilljulkzmi40i4liraeob5paeqoinjnpmeo4zf2utaphx5cwan7eyjbgzsjwnodavj9ov9lzf9qrvj5525cerqrwvfskr8zqekyzga7vbcs2egdwolqv0lcrzo3pzmt6bds+zmxwamul8rwzwmxdpmlkqch4bcuga3oqa1cgzpwaaap4blmwkvxzlwyb8b7rdvnzdp74i+mzy8ahaul</latexit>

tanh(x) = 1   tanh2(x)

avoiding overfitting

    reduce model size (but not too much)
    l1 and l2 id173
    early stopping (e.g., patience)
    dropout (hinton et al. 2012)

    randomly set 50% of inputs in each layer to 0

