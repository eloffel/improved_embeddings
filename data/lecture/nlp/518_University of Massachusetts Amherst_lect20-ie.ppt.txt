information extraction

introduction to natural language processing

cmpsci 585, fall 2007
university of massachusetts  amherst

andrew mccallum

goal:

mine actionable knowledge
from unstructured text.

an hr office

jobs, but not hr jobs

jobs, but not hr jobs

example: a solution

extracting job openings from the web

foodscience.com-job2

 jobtitle: ice cream guru
 employer: foodscience.com
 jobcategory: travel/hospitality
 jobfunction: food services
 joblocation: upper midwest
contact phone: 800-488-2611
 dateextracted: january 8, 2001
 source: www.foodscience.com/jobs_midwest.html
 othercompanyjobs: foodscience.com-job1

data mining the extracted job information

   ie from research papers

[mccallum et al    99]

mining research papers

[rosen-zvi, griffiths, steyvers,
 smyth, 2004]

[giles et al]

what is    information extraction   

as a task:

filling slots in a database from sub-segments of text.

october 14, 2002, 4:00 a.m. pt

for years, microsoft corporation ceo bill
gates railed against the economic philosophy
of open-source software with orwellian fervor,
denouncing its communal licensing as a
"cancer" that stifled technological innovation.

today, microsoft claims to "love" the open-
source concept, by which software code is
made public to encourage improvement and
development by outside programmers. gates
himself says microsoft will gladly disclose its
crown jewels--the coveted code behind the
windows operating system--to select
customers.

"we can be open source. we love the concept
of shared source," said bill veghte, a
microsoft vp. "that's a super-important shift
for us in terms of code access.   

richard stallman, founder of the free
software foundation, countered saying   

name              title   organization

what is    information extraction   

as a task:

filling slots in a database from sub-segments of text.

october 14, 2002, 4:00 a.m. pt

for years, microsoft corporation ceo bill
gates railed against the economic philosophy
of open-source software with orwellian fervor,
denouncing its communal licensing as a
"cancer" that stifled technological innovation.

today, microsoft claims to "love" the open-
source concept, by which software code is
made public to encourage improvement and
development by outside programmers. gates
himself says microsoft will gladly disclose its
crown jewels--the coveted code behind the
windows operating system--to select
customers.

"we can be open source. we love the concept
of shared source," said bill veghte, a
microsoft vp. "that's a super-important shift
for us in terms of code access.   

richard stallman, founder of the free
software foundation, countered saying   

ie

name              title   organization
bill gates        ceo      microsoft
bill veghte       vp       microsoft
richard stallman  founder  free soft..

what is    information extraction   

as a family
of techniques:

october 14, 2002, 4:00 a.m. pt

information extraction =
  segmentation + classification + id91 + association

for years, microsoft corporation ceo bill
gates railed against the economic philosophy
of open-source software with orwellian fervor,
denouncing its communal licensing as a
"cancer" that stifled technological innovation.

today, microsoft claims to "love" the open-
source concept, by which software code is
made public to encourage improvement and
development by outside programmers. gates
himself says microsoft will gladly disclose its
crown jewels--the coveted code behind the
windows operating system--to select
customers.

"we can be open source. we love the concept
of shared source," said bill veghte, a
microsoft vp. "that's a super-important shift
for us in terms of code access.   

richard stallman, founder of the free
software foundation, countered saying   

microsoft corporation
ceo
bill gates
microsoft
gates
microsoft
bill veghte
microsoft
vp
richard stallman
founder
free software foundation

what is    information extraction   

as a family
of techniques:

october 14, 2002, 4:00 a.m. pt

information extraction =
  segmentation + classification + association + id91

for years, microsoft corporation ceo bill
gates railed against the economic philosophy
of open-source software with orwellian fervor,
denouncing its communal licensing as a
"cancer" that stifled technological innovation.

today, microsoft claims to "love" the open-
source concept, by which software code is
made public to encourage improvement and
development by outside programmers. gates
himself says microsoft will gladly disclose its
crown jewels--the coveted code behind the
windows operating system--to select
customers.

"we can be open source. we love the concept
of shared source," said bill veghte, a
microsoft vp. "that's a super-important shift
for us in terms of code access.   

richard stallman, founder of the free
software foundation, countered saying   

microsoft corporation
ceo
bill gates
microsoft
gates
microsoft
bill veghte
microsoft
vp
richard stallman
founder
free software foundation

what is    information extraction   

as a family
of techniques:

october 14, 2002, 4:00 a.m. pt

information extraction =
  segmentation + classification + association + id91

for years, microsoft corporation ceo bill
gates railed against the economic philosophy
of open-source software with orwellian fervor,
denouncing its communal licensing as a
"cancer" that stifled technological innovation.

today, microsoft claims to "love" the open-
source concept, by which software code is
made public to encourage improvement and
development by outside programmers. gates
himself says microsoft will gladly disclose its
crown jewels--the coveted code behind the
windows operating system--to select
customers.

"we can be open source. we love the concept
of shared source," said bill veghte, a
microsoft vp. "that's a super-important shift
for us in terms of code access.   

richard stallman, founder of the free
software foundation, countered saying   

microsoft corporation
ceo
bill gates
microsoft
gates
microsoft
bill veghte
microsoft
vp
richard stallman
founder
free software foundation

what is    information extraction   

information extraction =
  segmentation + classification + association + id91

as a family
of techniques:

october 14, 2002, 4:00 a.m. pt

for years, microsoft corporation ceo bill
gates railed against the economic philosophy
of open-source software with orwellian fervor,
denouncing its communal licensing as a
"cancer" that stifled technological innovation.

today, microsoft claims to "love" the open-
source concept, by which software code is
made public to encourage improvement and
development by outside programmers. gates
himself says microsoft will gladly disclose its
crown jewels--the coveted code behind the
windows operating system--to select
customers.

"we can be open source. we love the concept
of shared source," said bill veghte, a
microsoft vp. "that's a super-important shift
for us in terms of code access.   

richard stallman, founder of the free
software foundation, countered saying   

*

*

*

*

microsoft corporation
ceo
bill gates
microsoft
gates
microsoft
bill veghte
microsoft
vp
richard stallman
founder
free software foundation

t
f
o
s
o
r
c
i
m

t
f
o
s
o
r
c
i
m

n
o
i
t
a
z
i
n
a
g
r
o
 
 
 
e
l
t
i
t

o
e
c

p
v

.
.
t
f
o
s
 
e
e
r
f

r
e
d
n
u
o
f

n
a
m
l
l
a
t
s
 
d
r
a
h
c
i
r

 
 
 
 
 
 
e
m
a
n

e
t
h
g
e
v
 
l
l
i
b

s
e
t
a
g
 
l
l
i
b

ie in context

create ontology

spider

filter by relevance

ie
segment
classify
associate
cluster

load db

database

document
collection

train extraction models

query,
search

label training data

data mine

why information extraction (ie)?

    science

    grand old dream of ai: build large kb* and reason with it.

ie enables the automatic creation of this kb.

    ie is a complex problem that inspires new advances in machine

learning.

    profit

    many companies interested in leveraging data currently    locked in

unstructured text on the web   .

    not yet a monopolistic winner in this space.

    fun!

    build tools that we researchers like to use ourselves:

cora & citeseer, mrqe.com, faqfinder,   
    see our work get used by the general public.

* kb =    knowledge base   

outline

    examples of ie and data mining
    landscape of problems and solutions
    techniques for segmentation and classification

    sliding window and boundary detection
    ie with id48
    introduction to id49 (crfs)
    examples of ie with crfs

    ie + data mining

ie history

pre-web
    mostly news articles

    de jong   s frump [1982]

    hand-built system to fill schank-style    scripts    from news wire

    message understanding conference (muc) darpa [   87-   95],

tipster [   92-   96]

    most early work dominated by hand-built models

    e.g. sri   s fastus, hand-built id122s.
    but by 1990   s, some machine learning: lehnert, cardie, grishman and

then id48s: elkan [leek    97], bbn [bikel et al    98]

web
    aaai    94 spring symposium on    software agents   

    much discussion of ml applied to web. maes, mitchell, etzioni.

    tom mitchell   s webkb,    96
    build kb   s from the web.

    wrapper induction

    initially hand-build, then ml: [soderland    96], [kushmeric    97],   

what makes ie from the web different?

less grammar, but more formatting & linking
web

newswire

www.apple.com/retail

www.apple.com/retail/soho

www.apple.com/retail/soho/theatre.html

apple to open its first retail store

in new york city

macworld expo, new york--july 17, 2002--
apple's first retail store in new york city will open in
manhattan's soho district on thursday, july 18 at
8:00 a.m. edt. the soho store will be apple's
largest retail store to date and is a stunning example
of apple's commitment to offering customers the
world's best computer shopping experience.

"fourteen months after opening our first retail store,
our 31 stores are attracting over 100,000 visitors
each week," said steve jobs, apple's ceo. "we
hope our soho store will surprise and delight both
mac and pc users who want to see everything the
mac can do to enhance their digital lifestyles."

the directory structure, link structure,
formatting & layout of the web is its own
new grammar.

landscape of ie tasks (1/4):

pattern feature domain

text paragraphs
without formatting
astro teller is the ceo and co-founder of
bodymedia. astro holds a ph.d. in artificial
intelligence from carnegie mellon university,
where he was inducted as a national hertz fellow.
his m.s. in symbolic and heuristic computation
and b.s. in computer science are from stanford
university. his work in science, literature and
business has appeared in international media from
the new york times to id98 to npr.

noid165matical snippets,

rich formatting & links

grammatical sentences

and some formatting & links

tables

landscape of ie tasks (2/4):

pattern scope

web site specific
formatting

amazon.com book pages

genre specific

wide, non-specific

layout
resumes

language

university names

landscape of ie tasks (3/4):

pattern complexity

e.g. word patterns:
closed set

u.s. states
he was born in alabama   

the big wyoming sky   

complex pattern

u.s. postal addresses
university of arkansas
p.o. box 140
hope, ar  71802

headquarters:
1128 main street, 4th floor
cincinnati, ohio 45210

regular set

u.s. phone numbers
phone: (413) 545-1323

the cald main office can be 
reached at 412-268-1299

ambiguous patterns,
needing context and
many sources of evidence

person names
   was among the six houses
sold by hope feldman that year.
pawel opalinski, software
engineer at whizbang labs.

landscape of ie tasks (4/4):

pattern combinations

jack welch will retire as ceo of general electric tomorrow.  the top role 
at the connecticut company will be filled by jeffrey immelt.

single entity

binary relationship

n-ary record

person:  jack welch

person:  jeffrey immelt

relation:  person-title
person:   jack welch
title: 

 ceo

location:  connecticut

relation:    company-location
company: general electric
location:   connecticut

relation:    succession
company:  general electric
title:           ceo
out:            jack welsh
in:               jeffrey immelt

   named entity    extraction

evaluation of single entity extraction

truth:

michael kearns and sebastian seung will start monday   s tutorial, followed by richard m. karpe and martin cooke.

pred:

michael kearns and sebastian seung will start monday   s tutorial, followed by richard   m. karpe and martin
cooke.

precision =                                                                   = 

# correctly predicted segments             2            

# predicted segments                   6           

recall       =                                                                   = 

# correctly predicted segments             2           

# true segments                            4     

f1            =      harmonic mean of precision & recall   = 

1

((1/p) + (1/r)) / 2

state of the art performance

    id39

    person, location, organization,    
    f1 in high 80   s or low- to mid-90   s

    binary id36

    contained-in (location1, location2)
member-of (person1, organization1)

    f1 in 60   s or 70   s or 80   s

    wrapper induction

    extremely accurate performance obtainable
    human effort (~30min) required on each site

landscape of ie techniques (1/1):

models

lexicons

classify pre-segmented

candidates

sliding window

abraham lincoln was born in kentucky.

abraham lincoln was born in kentucky.

abraham lincoln was born in kentucky.

member?

classifier

alabama
alaska
   
wisconsin
wyoming

which class?

classifier

which class?

try alternate
window sizes:

boundary models

abraham lincoln was born in kentucky.

finite state machines
abraham lincoln was born in kentucky.

id18s

abraham lincoln was born in kentucky.

begin

classifier

which class?

begin end begin end

most likely state sequence?

nnp

nnp

v

v

p

np

most likely parse?

pp

vp

np

s

vp
   and beyond

any of these models can be used to capture words, formatting or both.

outline

    examples of ie and data mining
    landscape of problems and solutions
    techniques for segmentation and classification

    sliding window and boundary detection
    ie with id48
    introduction to id49 (crfs)
    examples of ie with crfs

    ie + data mining

extraction by sliding window

    grand challenges for machine learning

           jaime carbonell
       school of computer science
      carnegie mellon university

               3:30 pm
            7500 wean hall

machine learning has evolved from obscurity
in the 1970s into a vibrant and popular
discipline in artificial intelligence
during the 1980s and 1990s.   as a result
of its success and growth, machine learning
is evolving into a collection of related
disciplines: inductive concept acquisition,
analytic learning in problem solving (e.g.
analogy, explanation-based learning),
learning theory (e.g. pac learning),
id107, connectionist learning,
hybrid systems, and so on.

cmu usenet seminar announcement

e.g.looking forseminarlocationextraction by sliding window

    grand challenges for machine learning

           jaime carbonell
       school of computer science
      carnegie mellon university

               3:30 pm
            7500 wean hall

machine learning has evolved from obscurity
in the 1970s into a vibrant and popular
discipline in artificial intelligence
during the 1980s and 1990s.   as a result
of its success and growth, machine learning
is evolving into a collection of related
disciplines: inductive concept acquisition,
analytic learning in problem solving (e.g.
analogy, explanation-based learning),
learning theory (e.g. pac learning),
id107, connectionist learning,
hybrid systems, and so on.

cmu usenet seminar announcement

e.g.looking forseminarlocationextraction by sliding window

    grand challenges for machine learning

           jaime carbonell
       school of computer science
      carnegie mellon university

               3:30 pm
            7500 wean hall

machine learning has evolved from obscurity
in the 1970s into a vibrant and popular
discipline in artificial intelligence
during the 1980s and 1990s.   as a result
of its success and growth, machine learning
is evolving into a collection of related
disciplines: inductive concept acquisition,
analytic learning in problem solving (e.g.
analogy, explanation-based learning),
learning theory (e.g. pac learning),
id107, connectionist learning,
hybrid systems, and so on.

cmu usenet seminar announcement

e.g.looking forseminarlocationextraction by sliding window

    grand challenges for machine learning

           jaime carbonell
       school of computer science
      carnegie mellon university

               3:30 pm
            7500 wean hall

machine learning has evolved from obscurity
in the 1970s into a vibrant and popular
discipline in artificial intelligence
during the 1980s and 1990s.   as a result
of its success and growth, machine learning
is evolving into a collection of related
disciplines: inductive concept acquisition,
analytic learning in problem solving (e.g.
analogy, explanation-based learning),
learning theory (e.g. pac learning),
id107, connectionist learning,
hybrid systems, and so on.

cmu usenet seminar announcement

e.g.looking forseminarlocation   na  ve bayes    sliding window results

domain: cmu usenet seminar announcements

    grand challenges for machine learning

           jaime carbonell
       school of computer science
      carnegie mellon university

               3:30 pm
            7500 wean hall

machine learning has evolved from obscurity
in the 1970s into a vibrant and popular
discipline in artificial intelligence during
the 1980s and 1990s.   as a result of its
success and growth, machine learning is
evolving into a collection of related
disciplines: inductive concept acquisition,
analytic learning in problem solving (e.g.
analogy, explanation-based learning),
learning theory (e.g. pac learning), genetic
algorithms, connectionist learning, hybrid
systems, and so on.

field
f1 
person name: 30%
61%
location:
start time:
98%

problems with sliding windows

and boundary finders

    decisions in neighboring parts of the input are

made independently from each other.

    na  ve bayes sliding window may predict a

   seminar end time    before the    seminar start time   .
    it is possible for two overlapping windows to both

be above threshold.

    in a boundary-finding system, left boundaries are

laid down independently from right boundaries,
and their pairing happens as a separate step.

outline

    examples of ie and data mining
    landscape of problems and solutions
    techniques for segmentation and classification

    sliding window and boundary detection
    ie with id48
    introduction to id49 (crfs)
    examples of ie with crfs

    ie + data mining

id48

id48s are the standard sequence modeling tool in 
genomics, music, speech, nlp,    

finite state model

generates:

state
  sequence
observation
   sequence

o1     o2    o3     o4     o5     o6    o7     o8

graphical model
s t-1

s t

s t+1

transitions

...

observations

o

t -1

o t

o t +1

...

...

parameters: for all states s={s1,s2,   }
    start state probabilities: p(st )
    transition probabilities:  p(st|st-1 )
    observation (emission) probabilities: p(ot|st )
training:
    maximize id203 of training observations (w/ prior)

usually a multinomial over
atomic, fixed alphabet

!="#||11)|()|(),(otttttsopsspospvvvie with id48

given a sequence of observations:

yesterday pedro domingos spoke this example sentence.

and a trained id48:

person name
location name
background

find the most likely state sequence:  (viterbi)

yesterday pedro domingos spoke this example sentence.

any words said to be generated by the designated    person name   
state extract as a person name:

person name: pedro domingos 

!!!!!!!!!!!!!!!!id48 example:    nymble   

[bikel, et al 1998], 
[bbn    identifinder   ]

transition
probabilities
p(st | st-1, ot-1 ) p(ot | st , st-1 )

observation
probabilities

or

p(ot | st , ot-1 )

back-off to:
p(st | st-1 )
p(st )

back-off to:
p(ot | st )
p(ot )

task: named entity extraction

start-of-
sentence

end-of-
sentence

person

org

 
(five other name classes)

other

train on 450k words of news wire text.
results:

case    language    
mixed    english
upper english
mixed spanish

f1  .
93%
91%
90%

other examples of shrinkage for id48s in ie: [freitag and mccallum    99]

we want more than an atomic view of words

would like richer representation of text:
many arbitrary, overlapping features of the words.

identity of word
ends in    -ski   
is capitalized
is part of a noun phrase
is in a list of city names
is under node x in id138
is in bold font
is indented
is in hyperlink anchor
last person name was female
next two words are    and associates   

is    wisniewski   

part of
noun phrase

s t-1

s t

s t+1

ends in
    -ski   
o

t -1

o t

o t +1

   

   

problems with richer representation

and a generative model

these arbitrary features are not independent.

    multiple levels of granularity (chars, words, phrases)
    multiple dependent modalities (words, formatting, layout)
    past & future

two choices:

model the dependencies.
each state would have its own
bayes net.  but we are already
starved for training data!

s t-1

s t

s t+1

ignore the dependencies.
this causes    over-counting    of
evidence (ala na  ve bayes).
big problem when combining
evidence, as in viterbi!

s t-1

s t

s t+1

o

t -1

o t

o t +1

o

t -1

o t

o t +1

conditional sequence models

    we prefer a model that is trained to maximize a

id155 rather than joint id203:
p(s|o) instead of p(s,o):

    can examine features, but not responsible for generating them.
    don   t have to explicitly model their dependencies.
    don   t    waste modeling effort    trying to generate what we are

given at test time anyway.

outline

    examples of ie and data mining
    landscape of problems and solutions
    techniques for segmentation and classification

    sliding window and boundary detection
    ie with id48
    introduction to id49 (crfs)
    examples of ie with crfs

    ie + data mining

from id48s to id49
[lafferty, mccallum, pereira 2001]

joint

conditional

where

st-1

st

st+1
...

ot-1

ot

ot+1

...

st-1

st

st+1
...

ot-1

ot

ot+1

...

(a super-special case of 
 id49.)

set parameters by maximum likelihood, using optimization method on   l.

  ! p(v s ,v o )=p(st|st"1)p(ot|st)t=1|v o |#  ! v s =s1,s2,...snv o =o1,o2,...on  ! p(v s |v o )=1p(v o )p(st|st"1)p(ot|st)t=1|v o |#  ! =1z(v o )"s(st,st#1)"o(ot,st)t=1|v o |$! "o(t)=exp#kfk(st,ot)k$% &     ( ) * linear chain id49

[lafferty, mccallum, pereira 2001]

st

st+1

st+2

st+3

st+4

markov on s, conditional dependency on o.

o = ot, ot+1, ot+2, ot+3, ot+4

hammersley-clifford-besag theorem stipulates that the crf
has this form   an exponential function of the cliques in the graph.

assuming that the dependency structure of the states is tree-shaped
(linear chain is a trivial tree), id136 can be done by dynamic
programming in time o(|o| |s|2)   just like id48s.

  ! p(v s |v o )"1zv o exp#jfj(st,st$1,v o ,t)j%&     ( ( ) * + + t=1|v o |,crfs vs. id48s

    more general and expressive modeling technique

    comparable computational efficiency

    features may be arbitrary functions of any or all observations

    parameters need not fully specify generation of observations;

require less training data

    easy to incorporate domain knowledge

    state means only    state of process   , vs

   state of process    and    observational history i   m keeping   

training crfs

feature count using

correct labels

-

feature count using

predicted labels

-

smoothing penalty

  ! log-likelihood gradient:  "l"#k=ck(v s (i),v o (i))i$%p{#k}(v s |v o (i)) ck(v s ,v o (i))v s $i$%#k2   ck(v s ,v o )=fk(t$v o ,t,st%1,st)  ! maximize log-likelihood of parameters given training data:   l({"k}|{v o ,v s (i)})outline

    examples of ie and data mining
    landscape of problems and solutions
    techniques for segmentation and classification

    sliding window and boundary detection
    ie with id48
    introduction to id49 (crfs)
    examples of ie with crfs

    ie + data mining

table extraction from government reports

cash receipts from marketings of milk during 1995 at $19.9 billion dollars, was 
slightly below 1994. producer returns averaged $12.93 per hundredweight,        
$0.19 per hundredweight below 1994.  marketings totaled 154 billion pounds,     
1 percent above 1994.  marketings include whole milk sold to plants and dealers 
as well as milk sold directly to consumers.                                     
                                                                                
an estimated 1.56 billion pounds of milk were used on farms where produced,     
8 percent less than 1994.  calves were fed 78 percent of this milk with the     
remainder consumed in producer households.                                      
                                                                                
                                                                                
                  milk cows and production of milk and milkfat:                 
                             united states, 1993-95                             
--------------------------------------------------------------------------------
           :            :           production of milk and milkfat 2/           
           :   number   :-------------------------------------------------------
    year   :     of     :   per milk cow    :   percentage   :      total       
           :milk cows 1/:-------------------: of fat in all  :------------------
           :            :  milk  : milkfat  : milk produced  : milk  : milkfat  
--------------------------------------------------------------------------------
           : 1,000 head   --- pounds ---         percent       million pounds   
           :                                                                    
1993       :   9,589      15,704     575           3.66       150,582  5,514.4  
1994       :   9,500      16,175     592           3.66       153,664  5,623.7  
1995       :   9,461      16,451     602           3.66       155,644  5,694.3  
--------------------------------------------------------------------------------
1/  average number during year, excluding heifers not yet fresh.                
2/  excludes milk sucked by calves.                                             

table extraction from government reports
[pinto, mccallum, wei, croft, 2003 sigir]

100+ documents from www.fedstats.gov

crf

cash receipts from marketings of milk during 1995 at $19.9 billion dollars, was
slightly below 1994. producer returns averaged $12.93 per hundredweight,
$0.19 per hundredweight below 1994.  marketings totaled 154 billion pounds,
1 percent above 1994.  marketings include whole milk sold to plants and dealers
as well as milk sold directly to consumers.

an estimated 1.56 billion pounds of milk were used on farms where produced,
8 percent less than 1994.  calves were fed 78 percent of this milk with the
remainder consumed in producer households.

                  milk cows and production of milk and milkfat:
                             united states, 1993-95
--------------------------------------------------------------------------------
           :            :           production of milk and milkfat 2/
           :   number   :-------------------------------------------------------
    year   :     of     :   per milk cow    :   percentage   :      total
           :milk cows 1/:-------------------: of fat in all  :------------------
           :            :  milk  : milkfat  : milk produced  : milk  : milkfat
--------------------------------------------------------------------------------
           : 1,000 head   --- pounds ---         percent       million pounds

1993       :   9,589      15,704     575           3.66       150,582  5,514.4

... (12 in all)

labels:
    non-table
    table title
    table header
    table data row
    table section data row
    table footnote
   
features:
    percentage of digit chars
    percentage of alpha chars
   
    contains 5+ consecutive spaces
    whitespace in this line aligns with prev.
   
    conjunctions of all previous features,

indented

...

time offset: {0,0}, {-1,0}, {0,1}, {1,2}.

table extraction experimental results

[pinto, mccallum, wei, croft, 2003 sigir]

line labels,

percent correct

table segments,

f1

id48

stateless
maxent

65 %

85 %

crf

95 %

64 %

-

92 %

   ie from research papers

[mccallum et al    99]

ie from research papers

field-level f1

id48 (id48s)

[seymore, mccallum, rosenfeld, 1999]

support vector machines (id166s)

[han, giles, et al, 2003]

id49 (crfs)

[peng, mccallum, 2004]

75.6

89.7

93.9

   error
40%

id39

cricket -
millns signs for boland

cape town 1996-08-22

south african provincial side
boland said on thursday they
had signed leicestershire fast
bowler david millns on a one
year contract.
millns, who toured australia with
england a in 1992, replaces
former england all-rounder
phillip defreitas as boland's
overseas professional.

labels:

 examples:

per

org

loc

misc

yayuk basuki
innocent butare
3m
kdp
cleveland
cleveland
nirmal hriday
the oval
java
basque
1,000 lakes rally

automatically induced features

[mccallum & li, 2003, conll]

feature
index
inside-noun-phrase (ot-1)
0
stopword (ot)
5
capitalized (ot+1)
20
word=the (ot)
75
in-person-lexicon (ot-1)
100
word=in (ot+2)
200
word=republic (ot+1)
500
word=rbi (ot) & header=baseball
711
header=cricket (ot) & in-english-county-lexicon (ot)
1027
company-suffix-word (firstmentiont+2)
1298
4040
location (ot) & pos=nnp (ot) & capitalized (ot) & stopword (ot-1)
4945 moderately-rare-first-name (ot-1) & very-common-last-name (ot)
4474

word=the (ot-2) & word=of (ot)

named entity extraction results

[mccallum & li, 2003, conll]

method

id48s bbn's identifinder

f1

73%

crfs w/out feature induction 83%

crfs with feature induction
based on likelihoodgain

90%

related work

    crfs are widely used for information extraction
...including more complex structures, like trees:
    [zhu, nie, zhang, wen, icml 2007] dynamic
hierarchical markov random fields and their
application to web data extraction

    [viola & narasimhan]: learning to extract information

from semi-structured text using a discriminative
id18

    [jousse et al 2006]: id49 for

xml trees

outline

    examples of ie and data mining
    landscape of problems and solutions
    techniques for segmentation and classification

    sliding window and boundary detection
    ie with id48
    introduction to id49 (crfs)
    examples of ie with crfs

    ie + data mining

from text to actionable knowledge

spider

filter

ie

segment
classify
associate
cluster

document
collection

data
mining
discover patterns
  - entity types
  - links / relations
  - events

database

actionable
knowledge

prediction
  outlier detection
   decision support

problem:

combined in serial juxtaposition,
ie and dm are unaware of each others   
weaknesses and opportunities.

1) dm begins from a populated db, unaware of

where the data came from, or its inherent
errors and uncertainties.

regularities in the db.

2) ie is unaware of emerging patterns and
 
the accuracy of both suffers, and significant mining

of complex text sources is beyond reach.

segmentclassifyassociateclusteriedocumentcollectiondatabasediscover patterns  - entity types  - links / relations  - eventsknowledgediscoveryactionableknowledgesolution:

spider

filter

ie

segment
classify
associate
cluster

document
collection

uncertainty info

data
mining
discover patterns
  - entity types
  - links / relations
  - events

database

emerging patterns

actionable
knowledge

prediction
  outlier detection
   decision support

solution:

spider

filter

ie

segment
classify
associate
cluster

unified model

data
mining
discover patterns
  - entity types
  - links / relations
  - events

probabilistic

model

document
collection

discriminatively-trained undirected id114

id49
 [lafferty, mccallum, pereira]

conditional prms
 [koller   ], [jensen   ], 
 [geetor   ], [domingos   ]
complex id136 and learning
just what we researchers like to sink our teeth into!

actionable
knowledge

prediction
  outlier detection
   decision support

scientific questions

    what model structures will capture salient dependencies?

    will joint id136 actually improve accuracy?

    how to do id136 in these large id114?

    how to do parameter estimation efficiently in these models,

which are built from multiple large components?

    how to do structure discovery in these models?

broader view

now touch on some other issues

3

create ontology

spider

filter by relevance

ie
segment
classify
associate
cluster

tokenize

1
2

load db

database

document
collection

4

train extraction models

query,
search

label training data

5

data mine

1

managing and understanding

connections of people in our email world

workplace effectiveness ~ ability to leverage network of acquaintances

but filling contacts db by hand is tedious, and incomplete.

email inbox

contacts db

automatically

www

system overview

email

www

crf

person
name

extraction

name

coreference

homepage
retrieval

contact
info and
person
name

extraction

names

keyword
extraction

social
network
analysis

an example

to:    andrew mccallum    mccallum@cs.umass.edu
subject ... 

first
name:

middle
name:

last
name:

andrew

kachites

mccallum

search for
new people

jobtitle:

associate professor

company:
street
address:

city:
state:

zip:
company
phone:

links:

university of massachusetts
140 governor   s dr.

amherst
ma

01003
(413) 545-1323

fernando pereira, sam
roweis,   

key
words:

information extraction,
 social network,   

id36 - data

    270 wikipedia articles
    1000 paragraphs
    4700 relations

    52 relation types

    jobtitle, birthday, friend, sister, husband,

employer, cousin, competition, education,    

    targeted for density of relations

    bush/kennedy/manning/coppola families and friends

george w. bush
   his father george h. w. bush   
   his cousin john prescott ellis   

george h. w. bush
   his sister nancy ellis bush   

nancy ellis bush
   her son john prescott ellis   

cousin = father   s sister   s son

george hw bush

son

george w bush

x

sibling

cousin

nancy ellis bush

son

john prescott ellis

y

john kerry
   celebrated with  stuart forbes   

likely a cousin

name

rosemary forbes

james forbes

name

son

john kerry
stuart forbes

sibling

rosemary forbes

james forbes

rosemary forbes

son

john kerry

sibling

cousin

james forbes

son

stuart forbes

examples of discovered relational

features

    mother: father   wife
    cousin: mother   husband   nephew
    friend: education   student
    education: father   education
    boss: boss   son
    memberof: grandfather   memberof
    competition: politicalparty   member   competition

