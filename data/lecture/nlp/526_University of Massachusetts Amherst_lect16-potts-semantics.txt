the pragmatics of questions and answers

christopher potts

umass amherst linguistics

cmpsci 585, november 6, 2007

background

pragbot

this lecture

1 a brief, semi-historial overview of linguistic pragmatics
2 a few notes on the subtle project
3 some illustrative examples
4 the partition semantics for questions
5 a decision-theoretic approach
6 research challenges

useful follow-up reading: chapters 23 and 24 of jurafsky and
martin (chapters 18 and 19 of the 1st edition)

background

pragbot

the merest sketch

background

pragbot

the merest sketch

   so here is the miracle: from a merest,
sketchiest squiggle of lines, you and i con-
verge to    nd adumbration of a coherent
scene   
   the problem of utterance interpretation
is not dissimilar to this visual miracle. an
utterance is not, as it were, a verdical
model or    snapshot    of the scene it de-
scribes   

   levinson (2000)

background

pragbot

the birth of gricean pragmatics

in the early 1960s, chomsky showed us how
to give compact, general speci   cations of
natural language syntax.

in the late 1960s, philosopher and linguist
h. paul grice had the inspired idea to do
the same for (rational) social interactions.

background

pragbot

rules and maxims

rules

maxims

s     np vp

np     n|pn

n     hippo|         

vp     vs s
vp     vtrans np
vs     realize|         

quality above all, be truthful!
relevance and be relevant!
quantity within those bounds, be
as informative as you can!
manner and do it as clearly and
concisely as possible!

syntactic rules are like physical laws.
breaking them should lead to nonsense (or falsi   cation).

pragmatic rules (maxims) are like laws of the land.
breaking them can have noteworthy consequences.

background

pragbot

pragmatic pressures

maxims

quality above all, be truthful!

relevance and be relevant!

quantity within those bounds,
be as informative as you can!

manner and do it as clearly
and concisely as possible!

background

pragbot

   then a miracle occurs   

the maxims do not yield
easily to a treatment in
the usual terms of seman-
tic theory. one can usu-
ally be precise up to a
point, but then . . .

background

pragbot

   then a miracle occurs   

the maxims do not yield
easily to a treatment in
the usual terms of seman-
tic theory. one can usu-
ally be precise up to a
point, but then . . .

background

pragbot

the id203 of formalizing the maxims

some are skeptical:

    beaver (2001:29) calls formalization in this area

   notoriously problematic   .

    bach (1999) is more decisive, o   ering various reasons why
   it seems futile for linguists to seek a formal pragmatics   .

    devitt and sterelny (1987:  7.4) strike a similar chord.

it   s a harsh verdict. maxims (at least one) are the main engine
behind all pragmatic theories.

background

pragbot

a probable breakthrough

things are looking up.
researchers are making signi   cant progress with
decision-theoretic and game-theoretic models.

the chief innovation
a shift in emphasis from truth-conditions to probabilities.

background

subtle

pragbot

situation understanding bot through language &
environment

subtle team
   we must move from robust
sentence processing to robust
utterance understanding    

mitch marcus, norm badler,
aravind joshi, george pap-
pas, fernando pereira, maribel
romero (penn); andrew and
me (umass amherst); holly
yanco (umass lowell)

background

pragbot

pragbot data-gatherer

    pragbot is a game played on the net, in a browser.
    the players comunicate via an instant messaging function
that logs all their messages and actions in the game world.
    pragbot scenarios mirror search-and-rescue scenarios, but

with simpli   cations that make linguistic modelling more
tractable.

(pragbot was developed by andrew mccallum, chris potts,
and karl shultz, and coded by karl schultz.)

background

pragbot

a screenshot

background

pragbot

fast and    exible data collection

pragbot is lightweight and    exible. we have changed the
interface and the task descriptions a number of times, with
each change bringing in linguistically richer interactions.

mention all/some domains

identi   cation speci   city granularity polarity gradability plurals over-answering deviousness

illustrative data

we begin with a range of cases involving questions and their
answers. the primary question:

what counts as a resolving answer?

we chose the data with the following general scenario in mind:
a human operator is querying a bot. the bot should give
resolving answers (where his knowledge base permits them).

mention all/some domains

identi   cation speci   city granularity polarity gradability plurals over-answering deviousness

mention-all vs. mention-some

where can we buy supplies?

mention all/some domains

identi   cation speci   city granularity polarity gradability plurals over-answering deviousness

mention-all vs. mention-some

where can we buy supplies?

mention-all

    context: we   re writing a comprehensive guide to the

area.

    resolvedness condition: an exhaustive listing of the

(reasonable) shopping places.

mention all/some domains

identi   cation speci   city granularity polarity gradability plurals over-answering deviousness

mention-all vs. mention-some

where can we buy supplies?

mention-all

    context: we   re writing a comprehensive guide to the

area.

    resolvedness condition: an exhaustive listing of the

(reasonable) shopping places.

mention-some

    context: we   re low on food and water.
    resolvedness condition: mentioning the best (closest,

safest, etc.) place, or a few good options.

mention all/some domains

identi   cation speci   city granularity polarity gradability plurals over-answering deviousness

mention-all vs. mention-some

who has a light?

mention all/some domains

identi   cation speci   city granularity polarity gradability plurals over-answering deviousness

mention-all vs. mention-some

who has a light?

mention-all

    context: speaker needs to ensure that no one in the

group is going to get stopped by airport security.

    resolvedness condition: listing of everyone who has a

light.

mention all/some domains

identi   cation speci   city granularity polarity gradability plurals over-answering deviousness

mention-all vs. mention-some

who has a light?

mention-all

    context: speaker needs to ensure that no one in the

group is going to get stopped by airport security.

    resolvedness condition: listing of everyone who has a

light.

mention-some

    context: speaker needs to light her cigar.
    resolvedness condition: just name one (friendly,

willing, nearby) person with a lighter.

mention all/some domains

identi   cation speci   city granularity polarity gradability plurals over-answering deviousness

domain restrictions

what cards do you have?

mention all/some domains

identi   cation speci   city granularity polarity gradability plurals over-answering deviousness

domain restrictions

what cards do you have?

wide domain

    context: speaker dealt the cards and noticed that some

were missing.

    resolvedness condition: list everything you   re holding.

mention all/some domains

identi   cation speci   city granularity polarity gradability plurals over-answering deviousness

domain restrictions

what cards do you have?

wide domain

    context: speaker dealt the cards and noticed that some

were missing.

    resolvedness condition: list everything you   re holding.

narrowed domain

    context: speaker folds. he wants to know what beat

him.

    resolvedness condition: just name the good cards (if

there are any).

mention all/some domains

identi   cation speci   city granularity polarity gradability plurals over-answering deviousness

domain restrictions

example (pragbot data)

did you find anything?

mention all/some domains

identi   cation speci   city granularity polarity gradability plurals over-answering deviousness

domain restrictions

example (pragbot data)

context: player 2 is looking for

player 2: did you find anything?

[...]

player 1: yep, h at the top exit

mention all/some domains

identi   cation speci   city granularity polarity gradability plurals over-answering deviousness

domain restrictions

example (pragbot data)

context: player 2 is looking for

player 2: did you find anything?

[...]

player 1: yep, h at the top exit

(

)

mention all/some domains

identi   cation speci   city granularity polarity gradability plurals over-answering deviousness

domain restrictions

example (pragbot data)

have you found anything?

mention all/some domains

identi   cation speci   city granularity polarity gradability plurals over-answering deviousness

domain restrictions

example (pragbot data)
context: the players are trying to get six consecutive hearts,
but they are still in the process of deciding which six.

player 2: i got 2h
player 1: i found a 3h
player 2: sweet.

[...]

player 1: have you found anything?
player 2: no, just 2h

mention all/some domains

identi   cation speci   city granularity polarity gradability plurals over-answering deviousness

domain restrictions

example (pragbot data)
context: the players are trying to get six consecutive hearts,
but they are still in the process of deciding which six.

player 2: i got 2h
player 1: i found a 3h
player 2: sweet.

[...]

player 1: have you found anything?
player 2: no, just 2h

no suggestion that player
2 didn   t see 3d, kd, etc.

(

)

mention all/some domains

identi   cation speci   city granularity polarity gradability plurals over-answering deviousness

identi   cation conditions

who is arnold schwarzenegger?

mention all/some domains

identi   cation speci   city granularity polarity gradability plurals over-answering deviousness

identi   cation conditions

who is arnold schwarzenegger?

    the governor of california.

mention all/some domains

identi   cation speci   city granularity polarity gradability plurals over-answering deviousness

identi   cation conditions

who is arnold schwarzenegger?

    a famous bodybuilder.

mention all/some domains

identi   cation speci   city granularity polarity gradability plurals over-answering deviousness

identi   cation conditions

who is arnold schwarzenegger?

    the terminator.

mention all/some domains

identi   cation speci   city granularity polarity gradability plurals over-answering deviousness

identi   cation conditions

who is arnold schwarzenegger?

    that guy over there.

mention all/some domains

identi   cation speci   city granularity polarity gradability plurals over-answering deviousness

identi   cation conditions

who is arnold schwarzenegger?

    the governor of california.
    a famous bodybuilder.
    the terminator.
    that guy over there.

mention all/some domains

identi   cation speci   city granularity polarity gradability plurals over-answering deviousness

levels of speci   city

who was at the meeting?

mention all/some domains

identi   cation speci   city granularity polarity gradability plurals over-answering deviousness

levels of speci   city

who was at the meeting?

general

    context: the speaker wants to get a sense for what

kind of meeting it was.

    resolvedness condition: some linguists, some

computer scientists, some mathematicians.

mention all/some domains

identi   cation speci   city granularity polarity gradability plurals over-answering deviousness

levels of speci   city

who was at the meeting?

general

    context: the speaker wants to get a sense for what

kind of meeting it was.

    resolvedness condition: some linguists, some

computer scientists, some mathematicians.

speci   c

    context: the speaker is checking against a list of likely

attendees.

    resolvedness condition: chris, alan, mitch, . . .

mention all/some domains

identi   cation speci   city granularity polarity gradability plurals over-answering deviousness

granularity

where are you from?

mention all/some domains

identi   cation speci   city granularity polarity gradability plurals over-answering deviousness

granularity

where are you from?

    massachusetts.

mention all/some domains

identi   cation speci   city granularity polarity gradability plurals over-answering deviousness

granularity

    the u.s.

where are you from?

mention all/some domains

identi   cation speci   city granularity polarity gradability plurals over-answering deviousness

granularity

where are you from?

    planet earth.

mention all/some domains

identi   cation speci   city granularity polarity gradability plurals over-answering deviousness

granularity

where are you from?

    connecticut. (my birthplace.)

mention all/some domains

identi   cation speci   city granularity polarity gradability plurals over-answering deviousness

granularity

where are you from?

    umass amherst. (my university.)

mention all/some domains

identi   cation speci   city granularity polarity gradability plurals over-answering deviousness

granularity

where are you from?

    belgium. (my ancestral home.)

mention all/some domains

identi   cation speci   city granularity polarity gradability plurals over-answering deviousness

granularity

where are you from?

    massachusetts.
    the u.s.
    planet earth.
    connecticut. (my birthplace.)
    umass amherst. (my university.)
    belgium. (my ancestral home.)

mention all/some domains

identi   cation speci   city granularity polarity gradability plurals over-answering deviousness

granularity

pragbot players can   t see each other, but they must coordinate
their movements. as a result, they ask many versions of

where are you?

they answer at di   erent levels of granularity depending on

    the task they were assigned
    the current subtask
    the nature of the environment
    their current knowledge of each other   s whereabouts

mention all/some domains

identi   cation speci   city granularity polarity gradability plurals over-answering deviousness

granularity

example (pragbot data)

player a: where are you?

player b: in the first box-like region in the

center, 2nd row

player b: i   m sort of in the middle.
player b: still at the right bottom corner

    unattested:    in the pragbot world   

(redundant in context)

    attested confusion:    in northampton   

(at the start of the game; players not yet fully engaged)

mention all/some domains

identi   cation speci   city granularity polarity gradability plurals over-answering deviousness

polarity variation

how high is a helicopter permitted to    y?

mention all/some domains

identi   cation speci   city granularity polarity gradability plurals over-answering deviousness

polarity variation

how high is a helicopter permitted to    y?

lower bound

    context: we need to avoid the powerlines while still

getting close to the ground.

    resolvedness condition: the lowest safe height.

mention all/some domains

identi   cation speci   city granularity polarity gradability plurals over-answering deviousness

polarity variation

how high is a helicopter permitted to    y?

lower bound

    context: we need to avoid the powerlines while still

getting close to the ground.

    resolvedness condition: the lowest safe height.

upper bound

    context: we need to be sure the atmosphere isn   t too

thin.

    resolvedness condition: the highest safe height.

mention all/some domains

identi   cation speci   city granularity polarity gradability plurals over-answering deviousness

gradable modi   ers

is the door open?

mention all/some domains

identi   cation speci   city granularity polarity gradability plurals over-answering deviousness

gradable modi   ers

is the door open?

maximal interpretation

    context: we need to get a vehicle out of the building.

it barely    ts through the doorway.

    intended:

is the door completely open?

mention all/some domains

identi   cation speci   city granularity polarity gradability plurals over-answering deviousness

gradable modi   ers

is the door open?

maximal interpretation

    context: we need to get a vehicle out of the building.

it barely    ts through the doorway.

    intended:

is the door completely open?

minimal interpretation

    context: we need to secure the building.
    intended:

is the door even a little bit open?

mention all/some domains

identi   cation speci   city granularity polarity gradability plurals over-answering deviousness

plurals

are the windows are open?

mention all/some domains

identi   cation speci   city granularity polarity gradability plurals over-answering deviousness

plurals

are the windows are open?

existential reading

    context: we need to ensure the building is locked up.
    the windows     some of the windows

mention all/some domains

identi   cation speci   city granularity polarity gradability plurals over-answering deviousness

plurals

are the windows are open?

existential reading

    context: we need to ensure the building is locked up.
    the windows     some of the windows

universal reading

    context: we are painting the sills.
    the windows     all the windows

mention all/some domains

identi   cation speci   city granularity polarity gradability plurals over-answering deviousness

pragmatically required over-answering

ali calls a hotel

ali:

is lisa simpson in room 343?

clerk a: she   s in room 400.
clerk b: she checked out yesterday.
clerk c: #no.

(implicit    no   )
(implicit    no   )

mention all/some domains

identi   cation speci   city granularity polarity gradability plurals over-answering deviousness

pragmatically required over-answering

example (pragbot data)

can you take the inside of the cube.

the answers expected by the form (   yes   ,    no   ) are
infelicitous because their content is mutually known. (the
players have freedom of movement.)

mention all/some domains

identi   cation speci   city granularity polarity gradability plurals over-answering deviousness

pragmatically required over-answering

example (pragbot data)
context: the players are planning their search strategy

player 1: can you take the inside of the cube.
player 2: ok i take the inside
player 1: i   ll look on the outside

the answers expected by the form (   yes   ,    no   ) are
infelicitous because their content is mutually known. (the
players have freedom of movement.)

mention all/some domains

identi   cation speci   city granularity polarity gradability plurals over-answering deviousness

pragmatically required over-answering

example (worcester cold storage fire)
context: firemen lost inside a large, maze-like building with
a    oor-plan that e   ectively changed by the minute as rooms
   lled with smoke and walls collapsed.

car 3 okay, do we have fire coming up through

the roof yet?

l-1/p1 we have a lot of hot embers blowing

through.

inferred pragmatically no, but . . .

(a mere    no    would be disastrous here.)

mention all/some domains

identi   cation speci   city granularity polarity gradability plurals over-answering deviousness

devious exploitation of pragmatic inferencing

from bronston v. united states

q: do you have any bank accounts in swiss banks,

mr. bronston?

a: no, sir.
q: have you ever?
a: the company had an account there for about six months,

in zurich.

mention all/some domains

identi   cation speci   city granularity polarity gradability plurals over-answering deviousness

devious exploitation of pragmatic inferencing

from bronston v. united states

q: do you have any bank accounts in swiss banks,

mr. bronston?

a: no, sir.
q: have you ever?
a: the company had an account there for about six months,

in zurich.

the truth
bronston once had a large personal swiss account.

the issue
the cooperative id136 of the previous slide has gotten us
into trouble here.

partition semantics

answer values

implicatures

desiderata

partition semantics and answer values

groenendijk and stokhof (1982): the semantic value of an
interrogative is a partition of the information state w into
equivalence classes based on the extension of the question
predicate.

partition semantics

answer values

implicatures

desiderata

partition semantics and answer values

groenendijk and stokhof (1982): the semantic value of an
interrogative is a partition of the information state w into
equivalence classes based on the extension of the question
predicate.

answering

    fully congruent answers identify a single cell.
    partial answers overlap with more than one cell.
    over-answers identify a proper subset of one of the cells.

partition semantics

answer values

implicatures

desiderata

partition semantics and answer values

groenendijk and stokhof (1982): the semantic value of an
interrogative is a partition of the information state w into
equivalence classes based on the extension of the question
predicate.

answering

    fully congruent answers identify a single cell.
    partial answers overlap with more than one cell.
    over-answers identify a proper subset of one of the cells.

groenendijk (1999) is a dynamic logic of questions and their
answers. ten cate and shan (2007) give it a proof theory and
show that it is fruitfully thought of from a variety of
perspectives. vermeulen (2000) is, in a sense, an extension to
genuinely strategic, multi-agent settings.

partition semantics

answer values

implicatures

desiderata

polar questions

[[did sam laugh?]] =

n{v     w | v     [[laughed(sam)]] i    w     [[laughed(sam)]]}(cid:12)(cid:12)(cid:12)

w     w

[[laughed(sam)]] w     [[laughed(sam)]]

partition semantics

answer values

implicatures

desiderata

polar questions

[[did sam laugh?]] =

n{v     w | v     [[laughed(sam)]] i    w     [[laughed(sam)]]}(cid:12)(cid:12)(cid:12)

w     w

[[laughed(sam)]] w     [[laughed(sam)]]

answers

partition semantics

answer values

implicatures

desiderata

polar questions

[[did sam laugh?]] =

n{v     w | v     [[laughed(sam)]] i    w     [[laughed(sam)]]}(cid:12)(cid:12)(cid:12)

w     w

[[laughed(sam)]] w     [[laughed(sam)]]

answers

   yes   

partition semantics

answer values

implicatures

desiderata

polar questions

[[did sam laugh?]] =

n{v     w | v     [[laughed(sam)]] i    w     [[laughed(sam)]]}(cid:12)(cid:12)(cid:12)

w     w

[[laughed(sam)]] w     [[laughed(sam)]]

answers

   no   

partition semantics

answer values

implicatures

desiderata

constituent questions

[[who laughed?]] =

n{v     w |    d . [[laugh]](d )(v ) i    [[laugh]](d )(w )o (cid:12)(cid:12)(cid:12)

 (cid:10)  
    
    
 (cid:12)
    
    
    
    
    
 (cid:12)  
 (cid:12)

w     wo

 
 
partition semantics

answer values

implicatures

desiderata

constituent questions

[[who laughed?]] =

n{v     w |    d . [[laugh]](d )(v ) i    [[laugh]](d )(w )o (cid:12)(cid:12)(cid:12)

 (cid:10)  
    
    
 (cid:12)
    
    
    
    
    
 (cid:12)  
 (cid:12)

w     wo

answers

 
 
partition semantics

answer values

implicatures

desiderata

constituent questions

[[who laughed?]] =

n{v     w |    d . [[laugh]](d )(v ) i    [[laugh]](d )(w )o (cid:12)(cid:12)(cid:12)

 (cid:10)  
    
    
 (cid:12)
    
    
    
    
    
 (cid:12)  
 (cid:12)

w     wo

answers

   bart and lisa   

 
 
partition semantics

answer values

implicatures

desiderata

constituent questions

[[who laughed?]] =

n{v     w |    d . [[laugh]](d )(v ) i    [[laugh]](d )(w )o (cid:12)(cid:12)(cid:12)

 (cid:10)  
    
    
 (cid:12)
    
    
    
    
    
 (cid:12)  
 (cid:12)

w     wo

answers

   bart, lisa, maggie,
burns   

and

 
 
partition semantics

answer values

implicatures

desiderata

constituent questions

[[who laughed?]] =

n{v     w |    d . [[laugh]](d )(v ) i    [[laugh]](d )(w )o (cid:12)(cid:12)(cid:12)

 (cid:10)  
    
    
 (cid:12)
    
    
    
    
    
 (cid:12)  
 (cid:12)

w     wo

answers

   no one   

 
 
partition semantics

answer values

implicatures

desiderata

answer values

we get a rough measure of the extent to which p answers q
by inspecting the cells in q with which p has a nonempty
intersection:
de   nition (answer values)

ans(p, q) =(cid:8)q     q | p     q 6=    (cid:9)

example

bart: did sam laugh?
lisa:

[[laughed(sam)]]

w     [[laughed(sam)]]

partition semantics

answer values

implicatures

desiderata

answer values

we get a rough measure of the extent to which p answers q
by inspecting the cells in q with which p has a nonempty
intersection:
de   nition (answer values)

ans(p, q) =(cid:8)q     q | p     q 6=    (cid:9)

example

bart: did sam laugh?
lisa: yes.

| ans | = 1

[[laughed(sam)]]

w     [[laughed(sam)]]

partition semantics

answer values

implicatures

desiderata

answer values

we get a rough measure of the extent to which p answers q
by inspecting the cells in q with which p has a nonempty
intersection:
de   nition (answer values)

ans(p, q) =(cid:8)q     q | p     q 6=    (cid:9)

example

bart: did sam laugh?
lisa: no.

| ans | = 1

[[laughed(sam)]]

w     [[laughed(sam)]]

partition semantics

answer values

implicatures

desiderata

answer values

we get a rough measure of the extent to which p answers q
by inspecting the cells in q with which p has a nonempty
intersection:
de   nition (answer values)

ans(p, q) =(cid:8)q     q | p     q 6=    (cid:9)

example

bart: did sam laugh?
lisa: i heard some giggling.

| ans | = 2

[[laughed(sam)]]

w     [[laughed(sam)]]

partition semantics

answer values

implicatures

desiderata

over-informative answers

ans values are a bit too blunt, since ans(p, q) = ans(p   
wherever p        p, for all questions q.

, q)

example

bart: is sam happy at his new job?
lisa:

[[happy(sam)]] w     [[happy(sam)]]

partition semantics

answer values

implicatures

desiderata

over-informative answers

ans values are a bit too blunt, since ans(p, q) = ans(p   
wherever p        p, for all questions q.

, q)

example

bart: is sam happy at his new job?
lisa: yes.

| ans | = 1

[[happy(sam)]] w     [[happy(sam)]]

partition semantics

answer values

implicatures

desiderata

over-informative answers

ans values are a bit too blunt, since ans(p, q) = ans(p   
wherever p        p, for all questions q.

, q)

example

bart: is sam happy at his new job?
lisa: yes, and he hasn   t been to jail yet. | ans | =

1

[[happy(sam)]] w     [[happy(sam)]]

partition semantics

answer values

implicatures

desiderata

a preference ordering

de   nition (relevance (g&s, van rooij))

p    q q

i    ans(p, q)     ans(q, q) or

ans(p, q) = ans(q, q) and q     p

partition semantics

answer values

implicatures

desiderata

a preference ordering

de   nition (relevance (g&s, van rooij))

p    q q

i    ans(p, q)     ans(q, q) or

ans(p, q) = ans(q, q) and q     p

example
in the previous example,

[[happy(sam)]]    [[?happy(sam)]] [[happy(sam)     no-jail(sam)]]

while their ans values are the same, the    rst is a superset of
the second.

partition semantics

answer values

implicatures

desiderata

example: granularity

example

where are you from?            
         

    which planet are you from?
    which country are you from?
    which city are you from?

        

partition semantics

answer values

implicatures

desiderata

example: granularity

example

where are you from?            
         

    which planet are you from?
    which country are you from?
    which city are you from?

        

de   nition (fine-grainedness (van rooy, 2004))
a question q is more    ne-grained than question q     i   

q     q     i       q     q    q        q     q     q   

if q is more    ne-grained than q    , then an exhaustive answer
to q is more informative than an exhausitive answer to q    .

partition semantics

answer values

implicatures

desiderata

conversational implicatures

partition semantics

answer values

implicatures

desiderata

partial answers

ans values bring us part of the way towards understanding
relevance implicatures.

example (partial answer)

tom: which city does barbara live in?
jerry: barbara lives in russia.

(| ans | > 1)

   

implicature: jerry doesn   t know which city.

partition semantics

answer values

implicatures

desiderata

partial answers

ans values bring us part of the way towards understanding
relevance implicatures.

example (partial answer)

tom: which city does barbara live in?
jerry: barbara lives in russia.

(| ans | > 1)

   

implicature: jerry doesn   t know which city.

example (complete answer)

tom: which country does barbara live in?
jerry: barbara lives in russia.

(| ans | = 1)

    no implicature about jerry   s city-level knowledge.

partition semantics

answer values

implicatures

desiderata

over-answer implicatures

when speakers over-answer, they seem to communicate that
the original qud is not (quite) appropriate. they address
their answers to a di   erent qud.

example

is sam happy at his new job?

bart:
lisa: yes, and he hasn   t been to jail yet.

example

sam: do you know what time it is?
sue: yes, it   s 4:15.

partition semantics

answer values

implicatures

desiderata

pragmatic principles

let q be the question under discussion (qud).

for speakers
answer q with a proposition p such that

p    q p    for all p        doxs

partition semantics

answer values

implicatures

desiderata

pragmatic principles

let q be the question under discussion (qud).

for speakers
answer q with a proposition p such that

p    q p    for all p        doxs

for hearers
let p be the speaker   s answer. for all q such that such that
q    q p, the speaker is not positioned to o   er q felicitously.

    if q     p, then the speaker lacks su   cient evidence for q.
    if p     q, then the speaker is answering a di   erent qud,

thereby implicating that q is not the right qud.

partition semantics

answer values

implicatures

desiderata

desiderata

1 discourse participants negotiate the nature of questions.

what motivates them?

partition semantics

answer values

implicatures

desiderata

desiderata

1 discourse participants negotiate the nature of questions.

what motivates them?

2 it is essential that we achieve more precise statements of

the implicatures and their calculations.

partition semantics

answer values

implicatures

desiderata

desiderata

1 discourse participants negotiate the nature of questions.

what motivates them?

2 it is essential that we achieve more precise statements of

the implicatures and their calculations.

3 ideally, we would reduce the pragmatic principles involved

in relevance implicature calculations to something more
fundamental.

partition semantics

answer values

implicatures

desiderata

desiderata

1 discourse participants negotiate the nature of questions.

what motivates them?

2 it is essential that we achieve more precise statements of

the implicatures and their calculations.

3 ideally, we would reduce the pragmatic principles involved

in relevance implicature calculations to something more
fundamental.

4 we   d like an account of the pragmatic variability of

questions discussed earlier (mention-some vs. mention-all,
and so forth).

decision problems

applications

looking ahead

decision problems

decision problems

applications

looking ahead

decision problems

as a    rst step towards satisfying our desires for this analysis,
we   ll inject some decision theory into our pragmatics, as a way
of making sense primarily of answers.

de   nition (decision problems)
a decision problem is a structure dp = (w , s , ps , a, us):

    w is a space of possible states of a   airs;
    s is an agent;
    ps is a (subjective) id203 distribution (for agent s);
    a is a set of actions that s can take; and
    us is a utility function for s, mapping action   world pairs

to real numbers.

decision problems

applications

looking ahead

example: schlepp the umbrella?

example (the decision problem schlepp)

    w = {w1 . . . w10}. assume it rains in {w1 . . . w7} and

not in {w8 . . . w10}.

    ps ({wi }) = ps({wj }) for all wi , wj     w
    a = {umbrella, no-umbrella}
   

u(umbrella, wi ) =
2
u(umbrella, wi ) =    2
u(no-umbrella, wi ) =    8
u(no-umbrella, wi ) =
4

if it rains in wi
if it doesn   t rain in wi
if it rains in wi
if it doesn   t rain in wi

umbrella
no-umbrella

rain
2
   8

no rain

   2
4

s is deciding under uncertainty. what   s his best move?

decision problems

applications

looking ahead

expected utilities

expected utilities take risk into account when measuring the
usefulness of performing an action.

de   nition
for decision problem dp = (w , s , ps , a, us) the expected
utility of an action a     a

eudp(a) = xw    w

p({w })    u(a, w )

decision problems

applications

looking ahead

solving decision problems

de   nition (utility value of a decision problem)
let dp = (w , s , ps , a, us ) be a decision problem.

uv(dp) = max
a   a

eudp(a)

de   nition (solving a decision problem)
let dp = (w , s , ps , a, us ) be a decision problem. the
solution to dp is

choose a such that eudp(a) = uv(dp)

decision problems

applications

looking ahead

solving the umbrella problem

rain (.7)

no rain (.3)

umbrella
no-umbrella

2
   8

   2
4

eu
.8
   4.4

    uv(schlepp) = maxa   {umbrella,no-umbrella} eu(a)

= .8

    the optimal action is umbrella.

decision problems

applications

looking ahead

utility value of new information

incoming information might change the decision problem by
changing the expected utilities.

de   nition (conditional expected utility)
let dp = (w , s , ps , a, us ) be a decision problem.

eudp(a|p) = xw    w

p({w }|p)    u(a, w )

decision problems

applications

looking ahead

utility value of new information

incoming information might change the decision problem by
changing the expected utilities.

de   nition (conditional expected utility)
let dp = (w , s , ps , a, us ) be a decision problem.

eudp(a|p) = xw    w

p({w }|p)    u(a, w )

example

    eu(no-umbrella) =    4.4
    eu(no-umbrella|{w8, w9, w10}) = 4
    eu(umbrella) = .8
    eu(umbrella|{w8, w9, w10}) =    2

(given no rain)

(given no rain)

decision problems

applications

looking ahead

changes to the utility value

the utility value of new information is a measure of the extent
to which it changes the utility value of the decision problem.

de   nition

uvdp(p) = max
a   a

uvdp(a|p)     uv(dp)

example
for the umbrella example, the utility value jumps from .8 to 4
when we learn that it will be sunny. thus:

uvschlepp({w8, w9, w10}) = 3.2

decision problems

applications

looking ahead

applications

decision problems

applications

looking ahead

action propositions

de   nition
if dp = (w , s , ps , a, us) is a decision problem and a is an
action in a, then

a    = {w     w | us(a, w ) > us (a   

, w ) for a        a}

if there is a unique optimal action in every world, then a   , the
set of propositions a        a, is a partition. but we won   t impose
this condition.

decision problems

applications

looking ahead

example: visiting barbara

   

w = {w1, . . . , w4}

[[b lives in moscow]] = {w1}

[[b lives in prague]] = {w3}

[[b lives in petersburg]] = {w2} [[b lives in budapest]] = {w4}

    ps ({wi }) = ps({wj }) for all wi , wj     w
    a = ax, where

x     {moscow, petersburg, prague, budapest}
    u(ax , w ) = 10 if barbara lives in x in w , else

u(ax , w ) = 0.

decision problems

applications

looking ahead

example: visiting barbara

   

w = {w1, . . . , w4}

[[b lives in moscow]] = {w1}

[[b lives in prague]] = {w3}

[[b lives in petersburg]] = {w2} [[b lives in budapest]] = {w4}

    ps ({wi }) = ps({wj }) for all wi , wj     w
    a = ax, where

x     {moscow, petersburg, prague, budapest}
    u(ax , w ) = 10 if barbara lives in x in w , else

u(ax , w ) = 0.

action propositions

a   
moscow = {w1}
a   
petersburg = {w2} a   

a   
prague = {w3}
budapest = {w4}

decision problems

applications

looking ahead

resolving the problem

example
assume the decision problem that bart   s question gives rise to
(or, the one that gives rise to his question) is as before.

bart: where does barbara live?

lisa: russia.

(cid:26) {w1} {w2}
{w3} {w4} (cid:27)

    does not resolve the decision problem.

lisa: petersburg (moscow, prague, . . . ).

    resolves the decision problem

decision problems

applications

looking ahead

example: which country?

   

w = {w1, . . . , w4}

[[b lives in moscow]] = {w1}

[[b lives in prague]] = {w3}

[[b lives in petersburg]] = {w2} [[b lives in budapest]] = {w4}

    ps ({wi }) = ps({wj }) for all wi , wj     w
    a = ax, where x     {russia, czech, budapest}
    u(ax , w ) = 10 if barbara lives in x in w , else

u(ax , w ) = 0.

decision problems

applications

looking ahead

example: which country?

   

w = {w1, . . . , w4}

[[b lives in moscow]] = {w1}

[[b lives in prague]] = {w3}

[[b lives in petersburg]] = {w2} [[b lives in budapest]] = {w4}

    ps ({wi }) = ps({wj }) for all wi , wj     w
    a = ax, where x     {russia, czech, budapest}
    u(ax , w ) = 10 if barbara lives in x in w , else

u(ax , w ) = 0.

action propositions

(

a   
russia = {w1, w2}

hungary = {w4} )

a   
czech = {w3} a   

decision problems

applications

looking ahead

resolving the problem

bart: where does barbara live?

lisa: russia.

{w3} {w4} (cid:27)
(cid:26) {w1} {w2}

    resolves the decision problem even though it doesn   t
correspond to a cell in bart   s question.

decision problems

applications

looking ahead

resolving the problem

bart: where does barbara live?

lisa: russia.

{w3} {w4} (cid:27)
(cid:26) {w1} {w2}

    resolves the decision problem even though it doesn   t
correspond to a cell in bart   s question.
lisa: petersburg (moscow, prague, . . . ).

    resolves the decision problem but provides too much
information.

decision problems

applications

looking ahead

resolving the problem

bart: where does barbara live?

lisa: russia.

{w3} {w4} (cid:27)
(cid:26) {w1} {w2}

    resolves the decision problem even though it doesn   t
correspond to a cell in bart   s question.
lisa: petersburg (moscow, prague, . . . ).

    resolves the decision problem but provides too much
information.

p    q q

i    ans(p, q)     ans(q, q) or

ans(p, q) = ans(q, q) and q     p

p    a    q

i    ans(p, a   )     ans(q, a   ) or

ans(p, a   ) = ans(q, a   ) and q     p

decision problems

applications

looking ahead

mention-some questions

example (craige roberts)
i   m working on a rush plumbing project and need some parts.

where can one buy faucet washers?

decision problems

applications

looking ahead

mention-some questions

example (craige roberts)
i   m working on a rush plumbing project and need some parts.

where can one buy faucet washers?

   

w = {w1, . . . , w3}

[[parts at moe   s]] = {w1, w2} [[parts at larry   s]] = {w2, w3}

    ps ({wi }) = ps({wj }) for all wi , wj     w
   

u w1 w2 w3
0
10 10

amoe   s 10 10
alarry   s

0

decision problems

applications

looking ahead

mention-some questions

example (craige roberts)
i   m working on a rush plumbing project and need some parts.

where can one buy faucet washers?

   

w = {w1, . . . , w3}

[[parts at moe   s]] = {w1, w2} [[parts at larry   s]] = {w2, w3}

    ps ({wi }) = ps({wj }) for all wi , wj     w
   

u w1 w2 w3
0
10 10

amoe   s 10 10
alarry   s

0

a   
moe   s = {w1, w2} a   

larry   s = {w2, w3}

decision problems

applications

looking ahead

domain restrictions

example (van rooy 2003)
i fold. i   m curious about whether i did the right thing.

what (cards) do you have?

decision problems

applications

looking ahead

domain restrictions

example (van rooy 2003)
i fold. i   m curious about whether i did the right thing.

what (cards) do you have?

a choice of domain leads to a choice of granularity for a   .
the order    a    can then home in on the optimal choice.

decision problems

applications

looking ahead

expected utility values of questions

euvdp(q) gives the average utility of the members of q.

de   nition
let dp = (w , s , ps , a, us ) be a decision problem. then

euvdp(q) =xq   q

ps(q)    uvdp(q)

the following ordering is determined largely by euv, but it
resorts to the measure of granularity to resolve ties.

de   nition

q    dp q     i    euvdp(q) > euvdp(q    ) or

euvdp(q) = euvdp(q    ) and q         q

decision problems

applications

looking ahead

pragmatic principles, decision-theoretically

let dp i ,j = (w , s , pi ,j , a, ui ,j) be a pair of decision
problems di   ering only in the agent (i or j).

decision problems

applications

looking ahead

pragmatic principles, decision-theoretically

let dp i ,j = (w , s , pi ,j , a, ui ,j) be a pair of decision
problems di   ering only in the agent (i or j).

for interrogator i
ask a question q such that

q    dp i q     for all q            (   (w ))

decision problems

applications

looking ahead

pragmatic principles, decision-theoretically

let dp i ,j = (w , s , pi ,j , a, ui ,j) be a pair of decision
problems di   ering only in the agent (i or j).

for interrogator i
ask a question q such that

q    dp i q     for all q            (   (w ))

for the witness j
answer q with a proposition p such that

p    a    p    for p        doxj

decision problems

applications

looking ahead

pragmatic principles, decision-theoretically

let dp i ,j = (w , s , pi ,j , a, ui ,j) be a pair of decision
problems di   ering only in the agent (i or j).

for interrogator i
ask a question q such that

q    dp i q     for all q            (   (w ))

for the witness j
answer q with a proposition p such that

p    a    p    for p        doxj

in both cases, the speaker   s behavior is shaped by the decision
problem.

decision problems

applications

looking ahead

looking ahead

1 continue the project begun by malamud (2006a,b) of

extending van rooy   s (2004) approach to questions into
new areas:

decision problems

applications

looking ahead

looking ahead

1 continue the project begun by malamud (2006a,b) of

extending van rooy   s (2004) approach to questions into
new areas:

    situations (what counts as minimal?)

decision problems

applications

looking ahead

looking ahead

1 continue the project begun by malamud (2006a,b) of

extending van rooy   s (2004) approach to questions into
new areas:

    situations (what counts as minimal?)
    reference (which mode is best?)

decision problems

applications

looking ahead

looking ahead

1 continue the project begun by malamud (2006a,b) of

extending van rooy   s (2004) approach to questions into
new areas:

    situations (what counts as minimal?)
    reference (which mode is best?)
    comparatives (which contextual standard?)

decision problems

applications

looking ahead

looking ahead

1 continue the project begun by malamud (2006a,b) of

extending van rooy   s (2004) approach to questions into
new areas:

    situations (what counts as minimal?)
    reference (which mode is best?)
    comparatives (which contextual standard?)

2 further articulate the role of decisions by moving to a

game-theoretic setting.

decision problems

applications

looking ahead

looking ahead

1 continue the project begun by malamud (2006a,b) of

extending van rooy   s (2004) approach to questions into
new areas:

    situations (what counts as minimal?)
    reference (which mode is best?)
    comparatives (which contextual standard?)

2 further articulate the role of decisions by moving to a

game-theoretic setting.

3 get a better grip on how these pragmatic factors can

in   uence embedded readings.

references

references i

aloni, maria. 2000. quanti   cation under conceptual covers. ph.d. thesis, universiteit

van amsterdam, amsterdam. published in the illc dissertation series, 2001-1.

bach, kent. 1999. the semantics   pragmatics distinction: what it is and why it

matters. in ken turner, ed., the semantics   pragmatics interface from di   erent
points of view, 65   84. oxford: elsevier. url
http://online.sfsu.edu/~ kbach/spd.htm.

beaver, david ian. 2001. presupposition and assertion in dynamic semantics.

stanford, ma: csli.

beck, sigrid and hotze rullmann. 1999. a    exible approach to exhaustivity in

questions. natural language semantics 7(3):249   298.

ten cate, balder and chung-shieh shan. 2007. axiomatizing groenendijk   s logic of

interrogation. in maria aloni; alastair butler; and paul dekker, eds., questions in
dynamic semantics, volume 17 of current research in the semantics/pragmatics
interface, 63   82. amsterdam: elsevier.

devitt, michael and kim sterelny. 1987. language and reality: an introduction to

the philosophy of language. cambridge, ma: mit press.

ginzburg, jonathan. 1996. interrogatives: questions, facts, and dialogue. in shalom
lappin, ed., the handbook of contemporary semantic theory, 385   422. oxford:
blackwell.

ginzburg, jonathan and ivan a. sag. 2001. interrogative investigations: the form,

meaning, and use of english interrogatives. stanford, ca: csli.

references

references ii

groenendijk, jeroen. 1999. the logic of interrogation. in tanya matthews and devon
strolovitch, eds., proceedings of salt ix, 109   126. ithaca, ny: cornell university.
groenendijk, jeroen and martin stokhof. 1982. semantic analysis of wh-complements.

linguistics and philosophy 5(2):175   233.

kennedy, christopher. 2007. vagueness and grammar: the semantics of relative and

absolute gradable adjective. linguistics and philosophy 30(1):1   45.

kennedy, christopher and louise mcnally. 2005. scale structure and the semantic

typology of gradable predicates. language 81(2):345   381.

levinson, stephen c. 2000. presumptive meanings: the theory of generalized

conversational implicature. cambridge, ma: mit press.

malamud, sophia. 2006a. (non)-maximality and distributivity: a decision theory

approach. paper presented at salt 16, tokyo, japan.

malamud, sophia. 2006b. semantics and pragmatics of arbitrariness. ph.d. thesis,

penn.

roberts, craige. 1996. information structure: towards an integrated formal theory of

pragmatics. in jae hak yoon and andreas kathol, eds., osu working papers in
linguistics, volume 49: papers in semantics, 91   136. columbus, oh: the ohio
state university department of linguistics. revised 1998.

van rooy, robert. 2003. questioning to resolve decision problems. linguistics and

philosophy 26(6):727   763.

van rooy, robert. 2004. signalling games select horn strategies. linguistics and

philosophy 27(4):493   527.

references

references iii

rullmann, hotze. 1995. maximality in the semantics of wh-constructions. ph.d.

thesis, umass amherst. published by the glsa.

schulz, katrin and robert van rooij. 2006. pragmatic meaning and non-monotonic

reasoning: the case of exhaustive interpretation. linguistics and philosophy
29(2):205   250.

solan, lawrence m. and peter m. tiersma. 2005. speaking of crime: the language

of criminal justice. chicago, il: university of chicago press.

vermeulen, kees. 2000. information in discourse: a game for many agents. in

lawrence cavdeon; patrick blackburn; nick braisby; and atsushi shimojima, eds.,
logic, language and computation, volume 3, chapter 15, 295     318. csli
publications.

