information extraction:

coreference and id36

lecture #20

computational linguistics
cmpsci 591n, spring 2006

university of massachusetts  amherst

andrew mccallum

1

information extraction:

coreference and id36

lecture #20

computational linguistics
cmpsci 591n, spring 2006

university of massachusetts  amherst

andrew mccallum

2

what is    information extraction   

as a family
of techniques:

october 14, 2002, 4:00 a.m. pt

information extraction =
  segmentation + classification + association + id91

*

*

*

*

for years, microsoft corporation ceo bill gates
railed against the economic philosophy of
open-source software with orwellian fervor,
denouncing its communal licensing as a
"cancer" that stifled technological innovation.

today, microsoft claims to "love" the open-
source concept, by which software code is
made public to encourage improvement and
development by outside programmers. gates
himself says microsoft will gladly disclose its
crown jewels--the coveted code behind the
windows operating system--to select
customers.

"we can be open source. we love the concept
of shared source," said bill veghte, a microsoft
vp. "that's a super-important shift for us in
terms of code access.   

richard stallman, founder of the free software
foundation, countered saying   

microsoft corporation
ceo
bill gates

microsoft
gates

bill veghte
microsoft
vp

richard stallman
founder
free software foundation

n
o
i
t
a
z
i
n
a
g
r
o
 
 
 
e
l
t
i
t

.
.
t
f
o
s
 
e
e
r
f

t
f
o
s
o
r
c
i
m

t
f
o
s
o
r
c
i
m

o
e
c

p
v

r
e
d
n
u
o
f

n
a
m
l
l
a
t
s
 
d
r
a
h
c
i
r

 
 
 
 
 
 
e
m
a
n

s
e
t
a
g
 
l
l
i
b

e
t
h
g
e
v
 
l
l
i
b

3

ie in context

create ontology

spider

filter by relevance

ie
segment
classify
associate
cluster

load db

database

document
collection

train extraction models

query,
search

label training data

data mine

4

main points

co-reference
    how to cast as classification [cardie]
    joint resolution [mccallum et al]
    canopies (time permitting..)

5

coreference resolution

aka "record linkage", "database record deduplication", 
   "citation matching", "object correspondence", "identity uncertainty"

input
news article,
 with named-entity "mentions" tagged

today secretary of state colin powell
met with . . . . . . . . . . . . . . . . . . . . . . . . .
. . . . . . . . . . . . . . . . . . . . . . . . he . . . . . .
. . . . . . . . . . . . . condoleezza rice . . . . .
. . . . mr powell . . . . . . . . . .she . . . . . . .
 . . . . . . . . . . . . . . powell . . . . . . . . . . . .
. . . president bush . . . . . . . . . . . . . . . .
. . . . . . . . . . . . . . . . . . rice . . . . . . . . . .
 . . . . . . bush . . . . . . . . . . . . . . . . . . . . .
. . . . . . . . . . . . . . . . . . . . . . . . . . .
. . . . . . . . . . . . . . . . . . . . . . . . .

output

number of entities, n = 3

#1
     secretary of state colin powell
     he
     mr. powell
     powell

#2
     condoleezza rice
     she
     rice

#3
     president bush
     bush

6

noun phrase coreference

identify all noun phrases that refer to the same entity

queen elizabeth set about transforming her husband,
king george vi, into a viable monarch. logue,
a renowned speech therapist, was summoned to help
the king overcome his speech impediment...

7

noun phrase coreference

identify all noun phrases that refer to the same entity

queen elizabeth set about transforming her husband,
king george vi, into a viable monarch. logue,
a renowned speech therapist, was summoned to help
the king overcome his speech impediment...

8

noun phrase coreference

identify all noun phrases that refer to the same entity

queen elizabeth set about transforming her husband,
king george vi, into a viable monarch. logue,
a renowned speech therapist, was summoned to help
the king overcome his speech impediment...

9

noun phrase coreference

identify all noun phrases that refer to the same entity

queen elizabeth set about transforming her husband,
king george vi, into a viable monarch. logue,
a renowned speech therapist, was summoned to help
the king overcome his speech impediment...

10

ie example: coreference

san salvador, 15 jan 90 (acan-efe) -- [text] armando
calderon sol, president of the nationalist republican
alliance (arena), the ruling salvadoran party, today
called for an investigation into any possible connection
between the military personnel implicated in the
assassination of jesuit priests.
"it is something so horrendous, so monstrous, that we
must investigate the possibility that the fmln
(farabundo marti national liberation front) staged
these murders to discredit the government," calderon
sol said.
salvadoran president alfredo cristiani implicated four
officers, including one colonel, and five members of the
armed forces in the assassination of six jesuit priests
and two women on 16 november at the central american
university.

13

why it   s hard

many sources of information play a role

    ibm executives = the executives

    head noun matches
    syntactic constraints
    john helped himself to...
    john helped him to   

    number and gender agreement
    discourse focus, recency, syntactic parallelism,

semantic class, world knowledge,    

14

why it   s hard

    no single source is a completely reliable

indicator
    number agreement

    the assassination = these murders

    identifying each of these features

automatically, accurately, and in context, is
hard

    coreference resolution subsumes the

problem of pronoun resolution   

15

a machine learning approach

    classification

    given a description of two noun phrases, npi and npj,
classify the pair as coreferent or not coreferent

coref ?

coref ?

[queen elizabeth] set about transforming [her] [husband], ...

not coref ?

aone & bennett [1995]; connolly et al. [1994]; mccarthy & lehnert [1995];
soon et al. [2001]; ng & cardie [2002];    

16

a machine learning approach

    id91

    coordinates pairwise coreference decisions

not
coref

coref

id91
algorithm

[queen elizabeth],
set about transforming
[her]
[husband]
...

not coref

queen elizabeth
queen elizabeth
her

king george vi

husband
king george vi
the king
his

logue

logue
a renowned speech
therapist

17

machine learning issues

    training data creation
    instance representation
    learning algorithm
    id91 algorithm

18

training data creation

    creating training instances

    texts annotated with coreference information

    one instance inst(npi, npj) for each pair of nps
    assumption: npi precedes npj
    feature vector: describes the two nps and context
    class value:

coref               pairs on the same coreference chain
not coref         otherwise

20

instance representation

    25 features per instance

    lexical (3)
    grammatical (18)

    string matching for pronouns, proper names, common nouns

    pronoun, demonstrative (the, this), indefinite (it is raining),    
    number, gender, animacy
    appositive (george, the king), predicate nominative (a horse is a mammal)
    binding constraints, simple contra-indexing constraints,    
    span, maximalnp,    

    semantic (2)

    same id138 class
    alias

    positional (1)
    knowledge-based (1)

    distance between the nps in terms of # of sentences
    na  ve pronoun resolution algorithm

21

learning algorithm

    ripper (cohen, 1995)

c4.5 (quinlan, 1994)
    rule learners

    input: set of training instances
    output: coreference classifier

    learned classifier
    input: test instance (represents pair of nps)
    output: classification

confidence of classification

22

id91 algorithm
    best-first single-link id91

    mark each npj as belonging to its own class:
npj     cj
    proceed through the nps in left-to-right order.
    for each np, npj, create test instances, inst(npi, npj),
for all of its preceding nps, npi.
    select as the antecedent for npj the highest-confidence
coreferent np, npi, according to the coreference
classifier (or none if all have below .5 confidence);
    merge cj and cj .

23

evaluation

    muc-6 and muc-7 coreference data sets
    documents annotated w.r.t. coreference
    30 + 30 training texts (dry run)
    30 + 20 test texts (formal evaluation)
    scoring program

    recall
    precision
    f-measure: 2pr/(p+r)

    types
    muc
    ace
    bcubed
    pairwise

key

a   b

c   d

system output

24

baseline results

25

muc-6 muc-7  r p f r p f baseline 40.7 73.5 52.4 27.2 86.3 41.3 worst muc system 36 44 40 52.5 21.4 30.4 best muc system 59 72 65 56.1 68.8 61.8   problem 1

    coreference is a rare relation
    skewed class distributions (2% positive instances)
    remove some negative instances

np1

np2

np3

np4

np5

np6

np7

np8

np9

farthest antecedent

26

problem 2

    coreference is a discourse-level problem
    different solutions for different types of nps
    proper names: string matching and aliasing

    inclusion of    hard    positive training instances
    positive example selection: selects easy positive training

instances (cf. harabagiu et al. (2001))

queen elizabeth set about transforming her husband,
king george vi, into a viable monarch. logue,
the renowned speech therapist, was summoned to help
the king overcome his speech impediment...

27

problem 3

    coreference is an equivalence relation

    loss of transitivity
    need to tighten the connection between classification and

    prune learned rules w.r.t. the id91-level coreference

id91

scoring function

coref ?

coref ?

[queen elizabeth] set about transforming [her] [husband], ...

not coref ?

28

results

    ultimately: large increase in f-measure, due to gains in recall

29

muc-6 muc-7  r p f r p f baseline 40.7 73.5 52.4 27.2 86.3 41.3 neg-select 46.5 67.8 55.2 37.4 59.7 46.0 pos-select 53.1 80.8 64.1 41.1 78.0 53.8 neg-select + pos-select 63.4 76.3 69.3 59.5 55.1 57.2 neg-select + pos-select + rule-select 63.3  76.9 69.5 54.2 76.3 63.4    comparison with best muc systems

30

muc-6 muc-7  r p f r p f neg-select + pos-select + rule-select 63.3  76.9 69.5 54.2 76.3 63.4 best muc system 59 72 65 56.1 68.8 61.8   main points

co-reference
    how to cast as classification [cardie]
    joint resolution [mccallum et al]

32

joint co-reference among all pairs

affinity matrix crf

. . . mr powell . . .

   entity resolution   
   object correspondence   

y/n

   99

45

y/n

y/n

11

. . . she . . .

id136:
correlational id91
graph partitioning
[bansal, blum, chawla, 2002]

. . . powell . . .

~25% reduction in error on
    co-reference of
    proper nouns in newswire.

[mccallum, wellner, ijcai ws 2003, nips 2004]

33

coreference resolution

aka "record linkage", "database record deduplication", 
   "citation matching", "object correspondence", "identity uncertainty"

input
news article,
 with named-entity "mentions" tagged

today secretary of state colin powell
met with . . . . . . . . . . . . . . . . . . . . . . . . .
. . . . . . . . . . . . . . . . . . . . . . . . he . . . . . .
. . . . . . . . . . . . . condoleezza rice . . . . .
. . . . mr powell . . . . . . . . . .she . . . . . . .
 . . . . . . . . . . . . . . powell . . . . . . . . . . . .
. . . president bush . . . . . . . . . . . . . . . .
. . . . . . . . . . . . . . . . . . rice . . . . . . . . . .
 . . . . . . bush . . . . . . . . . . . . . . . . . . . . .
. . . . . . . . . . . . . . . . . . . . . . . . . . .
. . . . . . . . . . . . . . . . . . . . . . . . .

output

number of entities, n = 3

#1
     secretary of state colin powell
     he
     mr. powell
     powell

#2
     condoleezza rice
     she
     rice

#3
     president bush
     bush

34

inside the traditional solution

pair-wise affinity metric

mention (3)

. . . mr powell . . .

y/n?

mention (4)

. . . powell . . .

n
y
y
y
y
n
y
y
n
y
n
n
y
y

two words in common
one word in common
"normalized" mentions are string identical
capitalized word in common
> 50% character tri-gram overlap
< 25% character tri-gram overlap
in same sentence
within two sentences
further than 3 sentences apart
"hobbs distance" < 3
number of entities in between two mentions = 0
number of entities in between two mentions > 4
font matches
default

overall score = 

29
13
39
17
19
-34
9
8
-1
11
12
-3
1
-19
98     > threshold=0

35

the problem

. . . mr powell . . .

affinity =    104

n

. . . she . . .

affinity = 98

y

. . . powell . . .

y

affinity = 11

affinity measures are noisy and imperfect.

pair-wise merging
decisions are being
made independently
from each other

they should be made
in relational dependence
with each other.

36

a markov random field for co-reference
[mccallum & wellner, 2003, icml]

(mrf)

. . . mr powell . . .

y/n

   30

. . . she . . .

45

y/n

y/n

11

. . . powell . . .

make pair-wise merging
decisions in dependent
relation to each other by
- calculating a joint prob.
- including all edge weights
- adding dependence on
  consistent triangles.

37

  ! p(v y |v x )=1zv x exp"lfl(xi,xj,yij)+"'f'(yij,yjk,yik)i,j,k#l#i,j#$ % & &     ( ) ) a markov random field for co-reference

(mrf)

. . . mr powell . . .

y/n

   30

. . . she . . .

45

y/n

y/n

11

[mccallum & wellner, 2003]

. . . powell . . .

make pair-wise merging
decisions in dependent
relation to each other by
- calculating a joint prob.
- including all edge weights
- adding dependence on
  consistent triangles.

38

!"  ! p(v y |v x )=1zv x exp"lfl(xi,xj,yij)+"'f'(yij,yjk,yik)i,j,k#l#i,j#$ % & &     ( ) ) a markov random field for co-reference

(mrf)

. . . mr powell . . .

 n

   (   30)

. . . she . . .

+(45)

 y

 y

+(11)

[mccallum & wellner, 2003]

. . . powell . . .

   infinity

40

  ! p(v y |v x )=1zv x exp"lfl(xi,xj,yij)+"'f'(yij,yjk,yik)i,j,k#l#i,j#$ % & &     ( ) ) a markov random field for co-reference

(mrf)

[mccallum & wellner, 2003]

. . . mr powell . . .

 n

   (   30)

+(45)

 y

 n

   (11)

. . . powell . . .

. . . she . . .

64

41

  ! p(v y |v x )=1zv x exp"lfl(xi,xj,yij)+"'f'(yij,yjk,yik)i,j,k#l#i,j#$ % & &     ( ) ) id136 in these mrfs = graph partitioning
[boykov, vekler, zabih, 1999], [kolmogorov & zabih, 2002], [yu, cross, shi, 2002]

. . . mr powell . . .

   30

. . . she . . .

45

    106

11

10

. . . powell . . .

    134

. . . condoleezza rice . . .

42

  ! logp(v y |v x )()"#lfl(xi,xj,yij)l$i,j$=wiji,j w/inparitions$%wiji,j acrossparitions$id136 in these mrfs = graph partitioning
[boykov, vekler, zabih, 1999], [kolmogorov & zabih, 2002], [yu, cross, shi, 2002]

. . . mr powell . . .

   30

. . . she . . .

45

    106

11

10

. . . powell . . .

    134

. . . condoleezza rice . . .

=    22

43

  ! logp(v y |v x )()"#lfl(xi,xj,yij)l$i,j$=wiji,j w/inparitions$%wiji,j acrossparitions$id136 in these mrfs = graph partitioning
[boykov, vekler, zabih, 1999], [kolmogorov & zabih, 2002], [yu, cross, shi, 2002]

. . . mr powell . . .

   30

. . . she . . .

45

    106

11

10

. . . powell . . .

    134

. . . condoleezza rice . . .

= 314

44

  ! logp(v y |v x )()"#lfl(xi,xj,yij)l$i,j$=wiji,j w/inparitions$+w'iji,j acrossparitions$co-reference experimental results

[mccallum & wellner, 2003]

proper noun co-reference

darpa ace broadcast news transcripts, 117 stories

single-link threshold
best prev match [morton]
mrfs

partition f1
16 %
83 %
88 %
  error=30%

pair f1
18 %
89 %
92 %
  error=28%

darpa muc-6 newswire article corpus, 30 stories

single-link threshold
best prev match [morton]
mrfs

partition f1
11%
70 %
74 %
  error=13%

pair f1
7 %
76 %
80 %
  error=17%

45

joint co-reference for
multiple entity types

[culotta & mccallum 2005]

people

stuart russell

y/n

y/n

y/n

s. russel

stuart russell

46

joint co-reference for
multiple entity types

[culotta & mccallum 2005]

people

organizations

stuart russell

university of california at berkeley

y/n

y/n

y/n

stuart russell

y/n

y/n

y/n

berkeley

s. russel

berkeley

47

joint co-reference for
multiple entity types

[culotta & mccallum 2005]

people

organizations

stuart russell

university of california at berkeley

y/n

y/n

y/n

stuart russell

y/n

y/n

y/n

berkeley

s. russel

reduces error by 22%

berkeley

48

the canopies approach

    two distance metrics: cheap & expensive
    first pass

    very inexpensive distance metric
    create overlapping canopies

    second pass

    expensive, accurate distance metric
    canopies determine which distances calculated

49

main points

    important ie task
    coreference as classification
    coreference as crf
    joint resolution of different object type

50

reference matching

    fahlman, scott & lebiere, christian (1989).  the cascade-correlation

learning architecture.  in touretzky, d., editor, advances in neural
information processing systems (volume 2), (pp. 524-532), san mateo,
ca.  morgan kaufmann.

    fahlman, s.e. and lebiere, c.,    the cascade correlation learning
architecture,    nips, vol. 2, pp. 524-532, morgan kaufmann, 1990.

    fahlman, s. e. (1991) the recurrent cascade-correlation learning
architecture.  in lippman, r.p. moody, j.e., and touretzky, d.s.,
editors, nips 3, 190-205.

51

the citation id91 data

    over 1,000,000 citations
    about 100,000 unique papers
    about 100,000 unique vocabulary words

    over 1 trillion distance calculations

52

the canopies approach

    two distance metrics: cheap & expensive
    first pass

    very inexpensive distance metric
    create overlapping canopies

    second pass

    expensive, accurate distance metric
    canopies determine which distances calculated

53

illustrating canopies

54

overlapping canopies

55

creating canopies with

two thresholds

    put all points in d
    loop:

    pick a point x from d
    put points within
    kloose of x in canopy
    remove points within

ktight of x from d

tight

56

loose

using canopies with

greedy agglomerative id91

    calculate expensive
distances between
points in the same
canopy
    all other distances
default to infinity
    sort finite distances and
iteratively merge closest

57

computational savings

    inexpensive metric << expensive metric
    # canopies per data point: f (small, but > 1)
    number of canopies: c (large)
    complexity reduction:

58

!!"#$$%&cfo2the experimental dataset

    all citations for authors:
    michael kearns
    robert schapire
    yoav freund
    1916 citations
    121 unique papers
    similar dataset used for parameter tuning

59

inexpensive distance metric

for text

    word-level matching (tfidf)
    inexpensive using an inverted index

aardvark

ant
apple
...
...
zoo

60

expensive distance metric

 for text

    string id153
    compute with dynamic
    costs for character:

programming

    insertion
    deletion
    substitution
    ...

a

c

e

s

t
0.0 0.7 1.4 2.1 2.8 3.5
s 0.7 0.0 0.7 1.1 1.4 1.8
c
1.4 0.7 1.0 0.7 1.4 1.8
o 2.1 1.1 1.7 1.4 1.7 2.4
t
2.8 1.4 2.1 1.8 2.4 1.7
t
3.5 1.8 2.4 2.1 2.8 2.4

do fahlman vs falman

61

experimental results

f1
canopies gac 0.838
complete gac 0.835
0.784
0.697

old cora
author/year

minutes
7.65

134.09
0.03
0.03

add precision, recall along side f1

63

main points

co-reference
    how to cast as classification [cardie]
    measures of string similarity [cohen]
    scaling up [mccallum et al]

64

