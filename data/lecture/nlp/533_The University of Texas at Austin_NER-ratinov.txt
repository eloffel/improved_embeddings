proceedings of the thirteenth conference on computational natural language learning (conll), pages 147   155,

boulder, colorado, june 2009. c(cid:13)2009 association for computational linguistics

147

designchallengesandmisconceptionsinnamedentityrecognition         levratinovdanrothcomputersciencedepartmentuniversityofillinoisurbana,il61801usa{ratinov2,danr}@uiuc.eduabstractweanalyzesomeofthefundamentaldesignchallengesandmisconceptionsthatunderliethedevelopmentofanef   cientandrobustnersystem.inparticular,weaddressissuessuchastherepresentationoftextchunks,theid136approachneededtocombinelocalnerdecisions,thesourcesofpriorknowl-edgeandhowtousethemwithinannersystem.intheprocessofcomparingseveralsolutionstothesechallengeswereachsomesurprisingconclusions,aswellasdevelopannersystemthatachieves90.8f1scoreontheconll-2003nersharedtask,thebestreportedresultforthisdataset.1introductionnaturallanguageprocessingapplicationsarechar-acterizedbymakingcomplexinterdependentdeci-sionsthatrequirelargeamountsofpriorknowledge.inthispaperweinvestigateonesuchapplication   namedentityrecognition(ner).figure1illus-tratesthenecessityofusingpriorknowledgeandnon-localdecisionsinner.intheabsenceofmixedcaseinformationitisdif   culttounderstandthat   thesystemandthewebpagesdatasetareavailableat:http://l2r.cs.uiuc.edu/   cogcomp/software.php   thisworkwassupportedbynsfgrantnsfsod-hcer-0613885,bymias,adhs-idscenterformultimodalin-formationaccessandsynthesisatuiucandbyanndiippprojectfromthenationallibraryofcongress.   wethanknicholasrizzoloforthebaselinelbjnersystem,xaviercarrerasforsuggestingthewordclassmodels,andmultiplereviewersforinsightfulcomments.soccer-[perblinker]banlifted.[loclondon]1996-12-06[miscdutch]forward[perreggieblinker]hadhisinde   nitesuspensionliftedby[orgfifa]onfridayandwassettomakehis[orgshef   eldwednesday]comebackagainst[orgliverpool]onsaturday.[perblinker]missedhisclub   slasttwogamesafter[orgfifa]slappedaworldwidebanonhimforappearingtosigncontractsforboth[orgwednesday]and[orgudinese]whilehewasplayingfor[orgfeyenoord].figure1:exampleillustratingchallengesinner.   blinker   isaperson.likewise,itisnotobvi-ousthatthelastmentionof   wednesday   isanorga-nization(infact,the   rstmentionof   wednesday   canalsobeunderstoodasa   comeback   whichhap-pensonwednesday).annersystemcouldtakead-vantageofthefactthat   blinker   isalsomentionedlaterinthetextastheeasilyidenti   able   reggieblinker   .itisalsousefultoknowthatudineseisasoccerclub(anentryaboutthisclubappearsinwikipedia),andtheexpression   bothwednesdayandudinese   impliesthat   wednesday   and   udi-nese   shouldbeassignedthesamelabel.theabovediscussionfocusesontheneedforex-ternalknowledgeresources(forexample,thatudi-nesecanbeasoccerclub)andtheneedfornon-localfeaturestoleveragethemultipleoccurrencesofnamedentitiesinthetext.whilethesetwoneedshavemotivatedsomeoftheresearchinnerinthelastdecade,severalotherfundamentaldecisionsmustbemade.theseinclude:whatmodeltousefor148

sequentialid136,howtorepresenttextchunksandwhatid136(decoding)algorithmtouse.despitetherecentprogressinner,theefforthasbeendispersedinseveraldirectionsandtherearenopublishedattemptstocompareorcombinethere-centadvances,leadingtosomedesignmisconcep-tionsandlessthanoptimalperformance.inthispaperweanalyzesomeofthefundamentaldesignchallengesandmisconceptionsthatunderliethede-velopmentofanef   cientandrobustnersystem.we   ndthatbilourepresentationoftextchunkssigni   cantlyoutperformsthewidelyadoptedbio.surprisingly,naivegreedyid136performscom-parablytobeamsearchorviterbi,whilebeingcon-siderablymorecomputationallyef   cient.weana-lyzeseveralapproachesformodelingnon-localde-pendenciesproposedintheliteratureand   ndthatnoneofthemclearlyoutperformstheothersacrossseveraldatasets.however,asweshow,thesecontri-butionsare,toalargeextent,independentand,asweshow,theapproachescanbeusedtogethertoyieldbetterresults.ourexperimentscorroboraterecentlypublishedresultsindicatingthatwordclassmodelslearnedonunlabeledtextcansigni   cantlyimprovetheperformanceofthesystemandcanbeanal-ternativetothetraditionalsemi-supervisedlearningparadigm.combiningrecentadvances,wedevelopapubliclyavailablenersystemthatachieves90.8f1scoreontheconll-2003nersharedtask,thebestreportedresultforthisdataset.oursystemisro-bust   itconsistentlyoutperformsallpubliclyavail-ablenersystems(e.g.,thestanfordnersystem)onallthreedatasets.2datasetsandevaluationmethodologynersystemshouldberobustacrossmultipledo-mains,asitisexpectedtobeappliedonadiversesetofdocuments:historicaltexts,newsarticles,patentapplications,webpagesetc.therefore,wehavecon-sideredthreedatasets:conll03sharedtaskdata,muc7dataandasetofwebpageswehaveanno-tatedmanually.intheexperimentsthroughoutthepaper,wetesttheabilityofthetaggertoadapttonewtestdomains.throughoutthiswork,wetrainontheconll03dataandtestontheotherdatasetswithoutretraining.thedifferencesinannotationschemesacrossdatasetscreatedevaluationchallenges.wediscussthedatasetsandtheevaluationmethodsbe-low.theconll03sharedtaskdataisasubsetofreuters1996newscorpusannotatedwith4entitytypes:per,org,loc,misc.itisimportanttonoticethatboththetrainingandthedevelopmentdatasetsarenewsfeedsfromaugust1996,whilethetestsetcontainsnewsfeedsfromdecember1996.thenamedentitiesmentionedinthetestdatasetareconsiderablydifferentfromthosethatappearinthetrainingorthedevelopmentset.asaresult,thetestdatasetisconsiderablyharderthanthedevelopmentset.evaluation:followingtheconvention,were-portphrase-levelf1score.themuc7datasetisasubsetofthenorthamericannewstextcorporaannotatedwithawidevarietyofentitiesincludingpeople,locations,or-ganizations,temporalevents,monetaryunits,andsoon.sincetherewasnodirectmappingfromtemporalevents,monetaryunits,andotherentitiesfrommuc7andthemisclabelintheconll03dataset,wemeasureperformanceonlyonper,organdloc.evaluation:thereareseveralsourcesofinconsistencyinannotationbetweenmuc7andconll03.forexample,sincethemuc7datasetdoesnotcontainthemisclabel,inthesentence   balloon,calledthevirginglobalchallenger   ,theexpressionvirginglobalchallengershouldbela-beledasmiscaccordingtoconll03guidelines.however,thegoldannotationinmuc7is   balloon,calledthe[orgvirgin]globalchallenger   .theseandotherannotationinconsistencieshavepromptedustorelaxtherequirementsof   ndingtheexactphraseboundariesandmeasureperformanceusingtoken-levelf1.webpages-wehaveassembledandmanuallyan-notatedacollectionof20webpages,includingper-sonal,academicandcomputer-scienceconferencehomepages.thedatasetcontains783entities(96-loc,223-org,276-per,188-misc).evaluation:thenamedentitiesinthewebpageswerehighlyam-biguousandverydifferentfromthenamedentitiesseeninthetrainingdata.forexample,thedatain-cludedsentencessuchas:   hear,oisrael,thelordourgod,thelordisone.   wecouldnotagreeonwhether   oisrael   shouldbelabeledasorg,loc,orper.similarly,wecouldnotagreeonwhether   god   and   lord   isanorgorper.theseissues149

ledustoreporttoken-levelentity-identi   cationf1scoreforthisdataset.thatis,ifanamedentityto-kenwasidenti   edassuch,wecounteditasacorrectpredictionignoringthenamedentitytype.3designchallengesinnerinthissectionweintroducethebaselinenersys-tem,andraisethefundamentalquestionsunderlyingrobustandef   cientdesign.thesequestionsde   netheoutlineofthispaper.neristypicallyviewedasasequentialpredictionproblem,thetypicalmod-elsincludeid48(rabiner,1989),crf(laffertyetal.,2001),andsequentialapplicationofper-ceptronorwinnow(collins,2002).thatis,letx=(x1,...,xn)beaninputsequenceandy=(y1,...,yn)betheoutputsequence.thesequentialpredictionproblemistoestimatetheprobabilitiesp(yi|xi   k...xi+l,yi   m...yi   1),wherek,landmaresmallnumberstoallowtractableid136andavoidover   tting.thiscon-ditionalid203distributionisestimatedinnerusingthefollowingbaselinesetoffeatures(zhangandjohnson,2003):(1)previoustwopredictionsyi   1andyi   2(2)currentwordxi(3)xiwordtype(all-capitalized,is-capitalized,all-digits,alphanu-meric,etc.)(4)pre   xesandsuf   xesofxi(5)tokensinthewindowc=(xi   2,xi   1,xi,xi+1,xi+2)(6)capitalizationpatterninthewindowc(7)conjunc-tionofcandyi   1.mostnersystemsuseadditionalfeatures,suchaspostags,shallowparsinginformationandgazetteers.wediscussadditionalfeaturesinthefol-lowingsections.wenotethatwenormalizedatesandnumbers,thatis12/3/2008becomes*date*,1980becomes*dddd*and212-325-4751becomes*ddd*-*ddd*-*dddd*.thisallowsadegreeofab-stractiontoyears,phonenumbers,etc.ourbaselinenersystemusesaregularizedaver-agedid88(freundandschapire,1999).sys-temsbasedonid88havebeenshowntobecompetitiveinnerandtextchunking(kazamaandtorisawa,2007b;punyakanokandroth,2001;car-rerasetal.,2003)wespecifythemodelandthefea-tureswiththelbj(rizzoloandroth,2007)mod-elinglanguage.wenowstatethefourfundamentaldesigndecisionsinnersystemwhichde   nethestructureofthispaper.algorithmbaselinesystemfinalsystemgreedy83.2990.57beamsize=1083.3890.67beamsize=10083.3890.67viterbi83.71n/atable1:phrase-levelf1performanceofdifferentid136methodsonconll03testdata.viterbicannotbeusedintheendsystemduetonon-localfeatures.keydesigndecisionsinannersystem.1)howtorepresenttextchunksinnersystem?2)whatid136algorithmtouse?3)howtomodelnon-localdependencies?4)howtouseexternalknowledgeresourcesinner?4id136&chunkrepresentationinthissectionwecomparetheperformanceofsev-eralid136(decoding)algorithms:greedyleft-to-rightdecoding,viterbiandbeamsearch.itmayappearthatbeamsearchorviterbiwillperformmuchbetterthannaivegreedyleft-to-rightdecoding,whichcanbeseenasbeamsearchofsizeone.theviterbialgorithmhasthelimitationthatitdoesnotallowincorporatingsomeofthenon-localfeatureswhichwillbediscussedlater,therefore,wecannotuseitinourendsystem.however,ithastheappeal-ingqualityof   ndingthemostlikelyassignmenttoasecond-ordermodel,andsincethebaselinefea-turesonlyhavesecondorderdependencies,wehavetesteditonthebaselinecon   guration.table1comparesbetweenthegreedydecoding,beamsearchwithvaryingbeamsize,andviterbi,bothforthesystemwithbaselinefeaturesandfortheendsystem(tobepresentedlater).surprisingly,thegreedypolicyperformswell,thisphenmenonwasalsoobservedinthepostaggingtask(toutanovaetal.,2003;rothandzelenko,1998).theimpli-cationsaresubtle.first,duetothesecond-orderofthemodel,thegreedydecodingisover100timesfasterthanviterbi.thereasonisthatwiththebilouencodingoffournetypes,eachtokencantake21states(o,b-per,i-per,u-per,etc.).totagatoken,thegreedypolicyrequires21compar-isons,whiletheviterbirequires213,andthisanaly-siscarriesovertothenumberofclassi   erinvoca-tions.furthermore,bothbeamsearchandviterbirequiretransformingthepredictionsoftheclassi-150

rep.conll03muc7schemetestdevdevtestbio89.1593.6186.7685.15bilou90.5793.2888.0985.62table2:endsystemperformancewithbilouandbioschemes.bilououtperformsthemorewidelyusedbio.   erstoprobabilitiesasdiscussedin(niculescu-mizilandcaruana,2005),incurringadditionaltimeoverhead.second,thisresultreinforcestheintuitionthatglobalid136overthesecond-orderid48featuresdoesnotcapturethenon-localpropertiesofthetask.thereasonisthatthenestendtobeshortchunksseparatedbymultiple   outside   to-kens.thisseparation   breaks   theviterbidecisionprocesstoindependentmaximizationofassignmentovershortchunks,wherethegreedypolicyperformswell.ontheotherhand,dependenciesbetweeniso-latednamedentitychunkshavelonger-rangedepen-denciesandarenotcapturedbysecond-ordertran-sitionfeatures,thereforerequiringseparatemecha-nisms,whichwediscussinsection5.anotherimportantquestionthathasbeenstud-iedextensivelyinthecontextofshallowparsingandwassomewhatoverlookedinthenerliteratureistherepresentationoftextsegments(veenstra,1999).relatedworksincludevotingbetweenseveralrep-resentationschemes(shenandsarkar,2005),lex-icalizingtheschemes(molinaandpla,2002)andautomaticallysearchingforbestencoding(edward,2007).however,wearenotawareofsimilarworkinthenersettings.duetospacelimitations,wedonotdiscussalltherepresentationschemesandcom-biningpredictionsbyvoting.wefocusinsteadontwomostpopularschemes   bioandbilou.thebioschemesuggeststolearnclassi   ersthatiden-tifythebeginning,theinsideandtheoutsideofthetextsegments.thebilouschemesuggeststolearnclassi   ersthatidentifythebeginning,theinsideandthelasttokensofmulti-tokenchunksaswellasunit-lengthchunks.thebilouschemeallowstolearnamoreexpressivemodelwithonlyasmallincreaseinthenumberofparameterstobelearned.table2comparestheendsystem   sperfor-mancewithbioandbilou.examiningtheresults,wereachtwoconclusions:(1)choiceofencod-ingschemehasabigimpactonthesystemperfor-manceand(2)thelessusedbilouformalismsig-ni   cantlyoutperformsthewidelyadoptedbiotag-gingscheme.weusethebilouschemethroughoutthepaper.5non-localfeaturesthekeyintuitionbehindnon-localfeaturesinnerhasbeenthatidenticaltokensshouldhaveidenti-callabelassignments.thesampletextdiscussedintheintroductionshowsonesuchexample,wherealloccurrencesof   blinker   areassignedtheperlabel.however,ingeneral,thisisnotalwaysthecase;forexamplewemightseeinthesamedoc-umentthewordsequences   australia   and   thebankofaustralia   .the   rstinstanceshouldbela-beledasloc,andthesecondasorg.weconsiderthreeapproachesproposedintheliteratureinthefol-lowingsections.beforecontinuingthediscussion,wenotethatwefoundthatadjacentdocumentsintheconll03andthemuc7datasetsoftendiscussthesameentities.therefore,weignoredocumentboundariesandanalyzeglobaldependenciesin200and1000tokenwindows.theseconstantswerese-lectedbyhandaftertryingasmallnumberofval-ues.webelievethatthisapproachwillalsomakeoursystemmorerobustincaseswhenthedocumentboundariesarenotgiven.5.1contextaggregation(chieuandng,2003)usedfeaturesthataggre-gate,foreachdocument,thecontexttokensappearin.samplefeaturesare:thelongestcapitilizedse-quenceofwordsinthedocumentwhichcontainsthecurrenttokenandthetokenappearsbeforeacompanymarkersuchasltd.elsewhereintext.inthiswork,wecallthistypeoffeaturescon-textaggregationfeatures.manuallydesignedcon-textaggregationfeaturesclearlyhavelowcoverage,thereforeweusedthefollowingapproach.recallthatforeachtokeninstancexi,weuseasfeaturesthetokensinthewindowofsizetwoaroundit:ci=(xi   2,xi   1,xi,xi+1,xi+2).whenthesametokentypetappearsinseverallocationsinthetext,sayxi1,xi2,...,xin,foreachinstancexij,inad-ditiontothecontextfeaturescij,wealsoaggregatethecontextacrossallinstanceswithin200tokens:c=   j=nj=1cij.151

conll03conll03muc7muc7webcomponenttestdatadevdatadevtestpages1)baseline83.6589.2574.7271.2871.412)(1)+contextaggregation85.4089.9979.1671.5370.763)(1)+extendedpredictionhistory85.5790.9778.5674.2772.194)(1)+two-stagepredictionaggregation85.0189.9775.4872.1672.725)allnon-localfeatures(1-4)86.5390.6981.4173.6171.21table3:theutilityofnon-localfeatures.thesystemwastrainedonconll03dataandtestedonconnl03,muc7andwebpages.nosingletechniqueoutperformedtherestonalldomains.thecombinationofalltechniquesisthemostrobust.5.2two-stagepredictionaggregationcontextaggregationasdoneabovecanleadtoex-cessivenumberoffeatures.(krishnanandmanning,2006)usedtheintuitionthatsomeinstancesofato-kenappearineasily-identi   ablecontexts.thereforetheyapplyabaselinenersystem,andusethere-sultingpredictionsasfeaturesinasecondlevelofin-ference.wecallthetechniquetwo-stagepredictionaggregation.weimplementedthetoken-majorityandtheentity-majorityfeaturesdiscussedin(krish-nanandmanning,2006);however,insteadofdocu-mentandcorpusmajoritytags,weusedrelativefre-quencyofthetagsina1000tokenwindow.5.3extendedpredictionhistorybothcontextaggregationandtwo-stagepredictionaggregationtreatalltokensinthetextsimilarly.however,weobservedthatthenamedentitiesinthebeginningofthedocumentstendedtobemoreeasilyidenti   ableandmatchedgazetteersmoreoften.thisisduetothefactthatwhenanamedentityisintro-ducedforthe   rsttimeintext,acanonicalnameisused,whileinthefollowingdiscussionabbreviatedmentions,pronouns,andotherreferencesareused.tobreakthesymmetry,whenusingbeamsearchorgreedyleft-to-rightdecoding,weusethefactthatwhenwearemakingapredictionfortokeninstancexi,wehavealreadymadepredictionsy1,...,yi   1fortokeninstancesx1,...,xi   1.whenmakingthepredictionfortokeninstancexi,werecordthela-belassignmentdistributionforalltokeninstancesforthesametokentypeintheprevious1000words.thatis,ifthetokeninstanceis   australia   ,andintheprevious1000tokens,thetokentype   australia   wastwiceassignedthelabell-organdthreetimesthelabelu-loc,thenthepredictionhistoryfeaturewillbe:(l   org:25;u   loc:35).5.4utilityofnon-localfeaturestable3summarizestheresults.surprisingly,nosingletechniqueoutperformedtheothersonalldatasets.theextendedpredictionhistorymethodwasthebestonconll03dataandmuc7testset.contextaggregationwasthebestmethodformuc7developmentsetandtwo-stagepredictionwasthebestforwebpages.non-localfeaturesprovedlesseffectiveformuc7testsetandthewebpages.sincethenamedentitiesinwebpageshavelesscontext,thisresultisexpectedforthewebpages.however,weareunsurewhymuc7testsetbene   tsfromnon-localfeaturesmuchlessthanmuc7developmentset.ourkeyconclusionisthatnosingleapproachisbetterthantherestandthattheapproachesarecomplimentary-theircombinationisthemoststableandbestperforming.6externalknowledgeaswehaveillustratedintheintroduction,nerisaknowledge-intensivetask.inthissection,wedis-cusstwoimportantknowledgeresources   gazetteersandunlabeledtext.6.1unlabeledtextrecentsuccessfulsemi-supervisedsystems(andoandzhang,2005;suzukiandisozaki,2008)haveillustratedthatunlabeledtextcanbeusedtoim-provetheperformanceofnersystems.inthiswork,weanalyzeasimpletechniqueofusingwordclustersgeneratedfromunlabeledtext,whichhasbeenshowntoimproveperformanceofdependencyparsing(kooetal.,2008),chinesewordsegmen-tation(liang,2005)andner(milleretal.,2004).thetechniqueisbasedonwordclassmodels,pio-neeredby(brownetal.,1992),whichhierarchically152

conll03conll03muc7muc7webcomponenttestdatadevdatadevtestpages1)baseline83.6589.2574.7271.2871.412)(1)+gazetteermatch87.2291.6185.8380.4374.463)(1)+wordclassmodel86.8290.8580.2579.8872.264)allexternalknowledge88.5592.4984.5083.2374.44table4:utilityofexternalknowledge.thesystemwastrainedonconll03dataandtestedonconnl03,muc7andwebpages.clusterswords,producingabinarytreeasinfig-ure2.figure2:anextractfromwordclusterhierarchy.theapproachisrelated,butnotidentical,todis-tributionalsimilarity(fordetails,see(brownetal.,1992)and(liang,2005)).forexample,sincethewordsfridayandtuesdayappearinsimilarcon-texts,thebrownalgorithmwillassignthemtothesamecluster.successfulabstractionofbothasadayoftheweek,addressesthedatasparsityprob-lemcommoninnlptasks.inthiswork,weusetheimplementationandtheclustersobtainedin(liang,2005)fromrunningthealgorithmonthereuters1996dataset,asupersetoftheconll03nerdataset.withinthebinarytreeproducedbytheal-gorithm,eachwordcanbeuniquelyidenti   edbyitspathfromtheroot,andthispathcanbecom-pactlyrepresentedwithabitstring.pathsofdif-ferentdepthsalongthepathfromtheroottothewordprovidedifferentlevelsofwordabstraction.forexample,pathsatdepth4closelycorrespondtopostags.sincewordclassmodelsuselargeamountsofunlabeleddata,theyareessentiallyasemi-supervisedtechnique,whichweusetoconsid-erablyimprovetheperformanceofoursystem.inthiswork,weusedpathpre   xesoflength4,6,10,and20.whenbrownclustersareusedasfeaturesinthefollowingsections,itimpliesthatallfeaturesinthesystemwhichcontainawordformwillbeduplicatedandanewsetoffeaturescon-tainingthepathsofvaryinglengthwillbeintro-duced.forexample,ifthesystemcontainsthefea-tureconcatenationofthecurrenttokenandthesys-tempredictiononthepreviousword,fournewfea-tureswillbeintroducedwhichareconcatenationsofthepreviouspredictionandthe4,6,10,20lengthpath-representationsofthecurrentword.6.2gazetteersanimportantquestionattheinceptionofthenertaskwaswhethermachinelearningtechniquesarenecessaryatall,andwhethersimpledictionarylookupwouldbesuf   cientforgoodperformance.indeed,thebaselinefortheconll03sharedtaskwasessentiallyadictionarylookupoftheenti-tieswhichappearedinthetrainingdata,anditachieves71.91f1scoreonthetestset(tjonganddemeulder,2003).itturnsoutthatwhileprob-lemsofcoverageandambiguitypreventstraightfor-wardlookup,injectionofgazetteermatchesasfea-turesinmachine-learningbasedapproachesiscrit-icalforgoodperformance(cohen,2004;kazamaandtorisawa,2007a;toralandmunoz,2006;flo-rianetal.,2003).giventhese   ndings,severalap-proacheshavebeenproposedtoautomaticallyex-tractcomprehensivegazetteersfromthewebandfromlargecollectionsofunlabeledtext(etzionietal.,2005;riloffandjones,1999)withlim-itedimpactonner.recently,(toralandmunoz,2006;kazamaandtorisawa,2007a)havesuccess-fullyconstructedhighqualityandhighcoveragegazetteersfromwikipedia.inthiswork,weuseacollectionof14high-precision,low-recalllistsextractedfromthewebthatcovercommonnames,countries,monetaryunits,temporalexpressions,etc.whilethesegazetteershaveexcellentaccuracy,theydonotpro-videsuf   cientcoverage.tofurtherimprovethecoverage,wehaveextracted16gazetteersfromwikipedia,whichcollectivelycontainover1.5men-tities.overall,wehave30gazetteers(availablefordownloadwiththesystem),andmatchesagainst153

conll03conll03muc7muc7webcomponenttestdatadevdatadevtestpages1)baseline83.6589.2574.7271.2871.412)(1)+externalknowledge88.5592.4984.5083.2374.443)(1)+non-local86.5390.6981.4173.6171.214)allfeatures90.5793.5089.1986.1574.535)allfeatures(trainwithdev)90.80n/a89.1986.1574.33table5:endsystemperformancebycomponent.resultscon   rmthatnerisaknowledge-intensivetask.eachoneareweightedasaseparatefeatureinthesystem(thisallowsustotrusteachgazetteertoadif-ferentdegree).wealsonotethatwehavedevelopedatechniqueforinjectingnon-exactstringmatchingtogazetteers,whichhasmarginallyimprovedtheperformance,butisnotcoveredinthepaperduetospacelimitations.intherestofthissection,wedis-cusstheconstructionofgazetteersfromwikipedia.wikipediaisanopen,collaborativeencyclopediawithseveralattractiveproperties.(1)itiskeptup-datedmanuallybyitcollaborators,hencenewenti-tiesareconstantlyaddedtoit.(2)wikipediacon-tainsredirectionpages,mappingseveralvariationsofspellingofthesamenametoonecanonicalen-try.forexample,sukerisredirectedtoanentryaboutdavor  suker,thecroatianfootballer(3)theentriesinwikipediaaremanuallytaggedwithcate-gories.forexample,theentryaboutthemicrosoftinwikipediahasthefollowingcategories:companieslistedonnasdaq;cloudcomputingvendors;etc.both(toralandmunoz,2006)and(kazamaandtorisawa,2007a)usedthefree-textdescriptionofthewikipediaentitytoreasonabouttheentitytype.weuseasimplermethodtoextracthighcoverageandhighqualitygazetteersfromwikipedia.byinspectionoftheconll03sharedtaskannotationguidelinesandofthetrainingset,wemanuallyag-gregatedseveralcategoriesintoahigher-levelcon-cept(notnecessarilynertype).whenawikipediaentrywastaggedbyoneofthecategoriesintheta-ble,itwasaddedtothecorrespondinggazetteer.6.3utilityofexternalknowledgetable4summarizestheresultsofthetechniquesforinjectingexternalknowledge.itisimportanttonotethat,althoughtheworldclassmodelwaslearnedonthesupersetofconll03data,andal-thoughthewikipediagazetteerswereconstructeddatasetstanford-nerlbj-nermuc7test80.6285.71muc7dev84.6787.99webpages72.5074.89reuters2003test87.0490.74reuters2003dev92.3693.94table6:comparison:token-basedf1scoreoflbj-nerandstanfordnertaggeracrossseveraldomainsbasedonconll03annotationguidelines,thesefea-turesprovedextremelygoodonalldatasets.wordclassmodelsdiscussedinsection6.1arecomputedof   ine,areavailableonline1,andprovideanalter-nativetotraditionalsemi-supervisedlearning.itisimportanttonotethatthewordclassmodelsandthegazetteersandindependedntandaccumulative.fur-thermore,despitethenumberandthegiganticsizeoftheextractedgazetteers,thegazeteersalonearenotsuf   cientforadequateperformance.whenwemodi   edtheconll03baselinetoincludegazetteermatches,theperformancewentupfrom71.91to82.3ontheconll03testset,belowourbaselinesystem   sresultof83.65.whenwehaveinjectedthegazetteersintooursystem,theperformancewentupto87.22.wordclassmodelandnonlocalfeaturesfurtherimprovetheperformanceto90.57(seeta-ble5),bymorethan3f1points.7finalsystemperformanceanalysisasa   nalexperiment,wehavetrainedoursystembothonthetrainingandonthedevelopmentset,whichgaveusourbestf1scoreof90.8ontheconll03data,yetitfailedtoimprovetheperfor-manceonotherdatasets.table5summarizestheperformanceofthesystem.next,wehavecomparedtheperformanceofour1http://people.csail.mit.edu/maestro/papers/bllip-clusters.gz154

systemtothatofthestanfordnertagger,acrossthedatasetsdiscussedabove.wehavechosentocom-pareagainstthestanfordtaggerbecausetothebestofourknowledge,itisthebestpubliclyavailablesystemwhichistrainedonthesamedata.wehavedownloadedthestanfordnertaggerandusedthestrongestprovidedmodeltrainedontheconll03datawithdistributionalsimilarityfeatures.there-sultsweobtainedontheconll03testsetwereconsistentwithwhatwasreportedin(finkeletal.,2005).ourgoalwastocomparetheperformanceofthetaggersacrossseveraldatasets.forthemostre-alisticcomparison,wehavepresentedeachsystemwitharawtext,andreliedonthesystem   ssentencesplitterandtokenizer.whenevaluatingthesystems,wematchedagainstthegoldid121ignoringpunctuationmarks.table6summarizestheresults.notethatduetodifferencesinsentencesplitting,to-kenizationandevaluation,theseresultsarenotiden-ticaltothosereportedintable5.alsonotethatinthisexperimentwehaveusedtoken-levelaccuracyontheconlldatasetaswell.finally,tocompletethecomparisontoothersystems,intable7wesum-marizethebestresultsreportedfortheconll03datasetinliterature.8conclusionswehavepresentedasimplemodelfornerthatusesexpressivefeaturestoachievenewstateoftheartperformanceonthenamedentityrecognitiontask.weexploredfourfundamentaldesigndeci-sions:textchunksrepresentation,id136algo-rithm,usingnon-localfeaturesandexternalknowl-edge.weshowedthatbilouencodingschemesig-ni   cantlyoutperformsbioandthat,surprisingly,aconditionalmodelthatdoesnottakeintoaccountin-teractionsattheoutputlevelperformscomparablytobeamsearchorviterbi,whilebeingconsiderablymoreef   cientcomputationally.weanalyzedsev-eralapproachesformodelingnon-localdependen-ciesandfoundthatnoneofthemclearlyoutperformstheothersacrossseveraldatasets.ourexperimentscorroboraterecentlypublishedresultsindicatingthatwordclassmodelslearnedonunlabeledtextcanbeanalternativetothetraditionalsemi-supervisedlearningparadigm.nerprovestobeaknowledge-intensivetask,anditwasreassuringtoobservethatsystemresourcesusedf1+lbj-nerwikipedia,nonlocalfea-tures,word-classmodel90.80-(suzukiandisozaki,2008)semi-supervisedon1g-wordunlabeleddata89.92-(andoandzhang,2005)semi-supervisedon27m-wordunlabeleddata89.31-(kazamaandtorisawa,2007a)wikipedia88.02-(krishnanandmanning,2006)non-localfeatures87.24-(kazamaandtorisawa,2007b)non-localfeatures87.17+(finkeletal.,2005)non-localfeatures86.86table7:resultsforconll03datareportedintheliterature.publiclyavailablesystemsmarkedby+.knowledge-driventechniquesadaptwellacrosssev-eraldomains.weobservedconsistentperformancegainsacrossseveraldomains,mostinterestinglyinwebpages,wherethenamedentitieshadlesscontextandweredifferentinnaturefromthenamedentitiesinthetrainingset.oursystemsigni   cantlyoutper-formsthecurrentstateoftheartandisavailabletodownloadunderaresearchlicense.apendix   wikipediagazetters&categories1)people:people,births,deaths.extracts494,699wikipediatitlesand382,336redirectlinks.2)organizations:cooper-atives,federations,teams,clubs,departments,organizations,organisations,banks,legislatures,recordlabels,constructors,manufacturers,ministries,ministers,militaryunits,militaryformations,universities,radiostations,newspapers,broad-casters,politicalparties,televisionnetworks,companies,busi-nesses,agencies.extracts124,403titlesand130,588redi-rects.3)locations:airports,districts,regions,countries,ar-eas,lakes,seas,oceans,towns,villages,parks,bays,bases,cities,landmarks,rivers,valleys,deserts,locations,places,neighborhoods.extracts211,872titlesand194,049redirects.4)namedobjects:aircraft,spacecraft,tanks,ri   es,weapons,ships,   rearms,automobiles,computers,boats.extracts28,739titlesand31,389redirects.5)artwork:novels,books,paint-ings,operas,plays.extracts39,800titlesand34037redirects.6)films:   lms,telenovelas,shows,musicals.extracts50,454titlesand49,252redirects.7)songs:songs,singles,albums.extracts109,645titlesand67,473redirects.8)events:playoffs,championships,races,competitions,battles.extracts20,176ti-tlesand15,182redirects.155

referencesr.k.andoandt.zhang.2005.ahigh-performancesemi-supervisedlearningmethodfortextchunking.inacl.p.f.brown,p.v.desouza,r.l.mercer,v.j.d.pietra,andj.c.lai.1992.class-basedid165mod-elsofnaturallanguage.computationallinguistics,18(4):467   479.x.carreras,l.m`arquez,andl.padr  o.2003.learn-ingaid88-basednamedentitychunkerviaon-linerecognitionfeedback.inconll.h.chieuandh.t.ng.2003.namedentityrecognitionwithamaximumid178approach.inproceedingsofconll.w.w.cohen.2004.exploitingdictionariesinnamedentityextraction:combiningsemi-markovextractionprocessesanddataintegrationmethods.inkdd.m.collins.2002.discriminativetrainingmethodsforhiddenmarkovmodels:theoryandexperimentswithid88algorithms.inemnlp.l.edward.2007.findinggoodsequentialmodelstruc-turesusingoutputtransformations.inemnlp).o.etzioni,m.j.cafarella,d.downey,a.popescu,t.shaked,s.soderland,d.s.weld,anda.yates.2005.unsupervisednamed-entityextractionfromtheweb:anexperimentalstudy.arti   cialintelligence,165(1):91   134.j.r.finkel,t.grenager,andc.d.manning.2005.in-corporatingnon-localinformationintoinformationex-tractionsystemsbygibbssampling.inacl.r.florian,a.ittycheriah,h.jing,andt.zhang.2003.namedentityrecognitionthroughclassi   ercombina-tion.inconll.y.freundandr.schapire.1999.largemarginclas-si   cationusingtheid88algorithm.machinelearning,37(3):277   296.j.kazamaandk.torisawa.2007a.exploitingwikipediaasexternalknowledgefornamedentityrecognition.inemnlp.j.kazamaandk.torisawa.2007b.anewid88al-gorithmforsequencelabelingwithnon-localfeatures.inemnlp-conll.t.koo,x.carreras,andm.collins.2008.simplesemi-superviseddependencyparsing.inacl.v.krishnanandc.d.manning.2006.aneffectivetwo-stagemodelforexploitingnon-localdependenciesinnamedentityrecognition.inacl.j.lafferty,a.mccallum,andf.pereira.2001.con-ditionalrandom   elds:probabilisticmodelsforseg-mentingandlabelingsequencedata.inicml.mor-gankaufmann.p.liang.2005.semi-supervisedlearningfornaturallanguage.mastersthesis,massachusettsinstituteoftechnology.s.miller,j.guinness,anda.zamanian.2004.nametaggingwithwordclustersanddiscriminativetraining.inhlt-naacl.a.molinaandf.pla.2002.shallowparsingusingspe-cializedid48s.thejournalofmachinelearningre-search,2:595   613.a.niculescu-mizilandr.caruana.2005.predictinggoodprobabilitieswithsupervisedlearning.inicml.v.punyakanokandd.roth.2001.theuseofclassi   ersinsequentialid136.innips.l.r.rabiner.1989.atutorialonhiddenmarkovmod-elsandselectedapplicationsinspeechrecognition.inieee.e.riloffandr.jones.1999.learningdictionariesforinformationextractionbymulti-levelid64.inaaai.n.rizzoloandd.roth.2007.modelingdiscriminativeglobalid136.inicsc.d.rothandd.zelenko.1998.partofspeechtaggingus-inganetworkoflinearseparators.incoling-acl.h.shenanda.sarkar.2005.votingbetweenmultipledatarepresentationsfortextchunking.advancesinarti   cialintelligence,pages389   400.j.suzukiandh.isozaki.2008.semi-supervisedsequen-tiallabelingandsegmentationusinggiga-wordscaleunlabeleddata.inacl.e.tjong,k.andf.demeulder.2003.introductiontotheconll-2003sharedtask:language-independentnamedentityrecognition.inconll.a.toralandr.munoz.2006.aproposaltoautomat-icallybuildandmaintaingazetteersfornamedentityrecognitionbyusingwikipedia.ineacl.k.toutanova,d.klein,c.manning,andy.singer.2003.feature-richpart-of-speechtaggingwithacyclicdependencynetwork.innaacl.j.veenstra.1999.representingtextchunks.ineacl.t.zhangandd.johnson.2003.arobustriskmini-mizationbasednamedentityrecognitionsystem.inconll.