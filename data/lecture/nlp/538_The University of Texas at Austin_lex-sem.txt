   

jurafsky, d. and martin, j. h. (2009): speech and language processing. an 
introduction to natural language processing, computational linguistics and 
id103. second edition. pearson: new jersey: chapter 20

    agirre, e., edmonds, p. (2006): id51: algorithms and 
applications (text, speech and language technology). springer, heidelberg

knowledge-based, supervised, word sense induction, topic features
id51

adapted and extended by ido dagan 
for bar-ilan university class

ss2013 |  computer science department  |   fg langtech - prof. dr. chris biemann  |

1

id138     an online lexical database
http://id138.princeton.edu/

    high coverage lexical-semantic network built by psychologists

    relations:

    isa-relation (hyponom - hypernym, taxonomic backbone)
    part-of (meronym - holonym)
    type-instance (e.g. obama is an instance of president)
    opposite-of (antonym), mostly for adjectives
    derivative (pertainym), e.g. crime     criminal
    some semantic roles between verbs and nouns, e.g. agent, instrument    

    a useful source for lexical expansions/id136s (but coverage limited)

ss2013 |  computer science department  |   fg langtech - prof. dr. chris biemann  |

2

synsets for    magazine#n   

    l

synset

sample use

gloss

semcor count

lexical members

ss2013 |  computer science department  |   fg langtech - prof. dr. chris biemann  |

3

id138 hypernym chain

level

of

abstraction

ss2013 |  computer science department  |   fg langtech - prof. dr. chris biemann  |

4

types of ambiguity

    homonymy: two or more meanings happen to be expressed with the 

same string
    withdrawing money from the bank
    embark on a boat from the river bank

    polysemy: the same string has different, but related senses, id30 

from the same origin
    the bank was robbed by billy the kid
    the bank was constructed by a famous architect

ss2013 |  computer science department  |   fg langtech - prof. dr. chris biemann  |

5

approaches to wsd

    knowledge based approaches (   unsupervised   )

    rely on knowledge resources like id138, thesaurus etc.
    may use hand coded rules for disambiguation.

    machine learning based approaches (   supervised   )

    rely on corpus evidence.
    train a model using tagged or untagged corpus.
    probabilistic/statistical models. 

    hybrid approaches

    use corpus evidence as well as semantic relations from id138.

ss2013 |  computer science department  |   fg langtech - prof. dr. chris biemann  |

6

wsd using selectional preferences and 
arguments

sense 1

sense 2

this airline serves dinner in 
the evening flight.
    serve (verb)

this airline serves the sector 
between munich and rome.
    serve (verb)

    agent
    object     edible

    agent
    object     sector

requires exhaustive enumeration of:
    argument-structure of verbs.
    selectional preferences of arguments.
    description of properties of words such that meeting the selectional

preference criteria can be decided.

e.g. this flight serves the    region    between paris and warsaw.

how do you decide if    region    is compatible with    sector   

ss2013 |  computer science department  |   fg langtech - prof. dr. chris biemann  |

7

overlap-based approaches

    requires a machine readable dictionary (mrd).
    find the overlap between the features of different senses of an 

ambiguous word (sense bag) and the features of the words in its context 
(context bag).

    these features could be sense definitions, example sentences, etc. 
    the sense which has the maximum overlap is selected as the 

contextually appropriate sense.

ss2013 |  computer science department  |   fg langtech - prof. dr. chris biemann  |

8

lesk (1986) algorithm

    identify senses of words in context using definition overlap for senses and 

context words

    can use various fields/expansions in resource to test overlap with context
    main problem: zero overlap for most contexts
function simplifiedlesk(word, sentence) {

bestsense= mostfrequentsense(word);

maxoverlap =0;

context = allwords(sentence);

foreach sense in allsenses(word) {

signature=signature(sense);

overlap = overlap(signature, context);

if (overlap > maxoverlap) {

maxoverlap = overlap;

bestsense - sense

}}

return bestsense;

}

dictionary functions
    mostfrequentsense: 

returns most frequent / first 
sense identifier from dictionary 
    allsenses: returns all sense 

identifiers for a word from 
dictionary

    signature: returns set of 

words from sense definition in 
dictionary

ss2013 |  computer science department  |   fg langtech - prof. dr. chris biemann  |

9

lesk, m. (1986). automatic sense disambiguation using machine readable dictionaries: how to tell a pine 
cone from an ice cream cone. in sigdoc '86: proceedings of the 5th annual international conference on 
systems documentation, pages 24-26, new york, ny, usa. acm.

simplified lesk algoritm

    lesk algorithm relies on definitions of context words to disambiguate the 

senses of a target word

    simplified lesk: 

    measure the overlap between the (sentence) context of the target, and the 

definition of its senses

    if no overlap, use most frequent sense (mfs)

1, 2 or 3 ?

   with the music, the dance started with slow movements.    

ss2013 |  computer science department  |   fg langtech  - prof. dr. chris biemann  |

10

extended lesk (banerjee and pedersen, 2002)

    utilize link structure of id138 to pull in related glosses for overlap 

computation

    addresses the overlap sparseness issue
    do this for one ambiguous word at-a-time
    reweighting: for id165 overlaps, add a score of n2

final judgment:    a 

judgment disposing of the case 

before the court of law   

   the bench pronounced the sentence   

hypernym

overlap score = 9

sentence:    the 

penalty meted out to one

adjudged guilty   

bench:    persons

who hear cases in a  

court of law   

overlap score = 0

(banerjee and pedersen, 2002). extended gloss overlaps as a measure of semantic relatedness. proceedings of the 
eighteenth international joint conference on artificial intelligence, pp. 805-810, august 9-15, 2003, acapulco, mexico.

ss2013 |  computer science department  |   fg langtech - prof. dr. chris biemann  |

11

id138 similarity measures
http://search.cpan.org/dist/id138-similarity

    distance measures on id138 graph, see lecture    lexical semantic 

methods for language understanding   

    simple method: count number of links between two concepts
    more advanced methods use weighted counts depending on the depth in 

the hierarchy, the frequency of terms in corpora etc.

    core idea: distance between the correct senses is smaller than distance 

between unrelated senses

    simultaneous disambiguation of 

all words per sentence, using e.g. 
graph-based methods
    good results using id93
(personalized id95, agirre)

ravi sinha and rada mihalcea, unsupervised graph-based id51 using measures of word semantic 
similarity, in proceedings of the ieee international conference on semantic computing (icsc 2007), irvine, ca, september 2007

ss2013 |  computer science department  |   fg langtech - prof. dr. chris biemann  |

12

one-sense-per-discourse hypothesis

    idea: when a word is used several times in a document, it probably has 

the same meaning in all occurrences. 

    this means that we can gather evidence from all contexts per document, 

which reduces sparseness

    holds for homonymous, not polysemous nouns, does not hold for verbs 

and adjectives as much

    measuring the validity of the hypothesis 

(small study on 12 nouns)

    applicability: how often do we in fact 

observe an ambiguous word more than 
once in a document?

    accuracy: if we observe an ambiguous 

word more than once per document, how 
often do these occurrences have the same 
meaning?

gale william, kenneth church, and david yarowsky,    one sense per discourse   , in proceedings of the arpa workshop on 
speech and natural language processing, pp. 233    237, 1992. 

ss2013 |  computer science department  |   fg langtech - prof. dr. chris biemann  |

13

semeval: shared task for semantic evaluations

    shared task initiative since 2001 (started as senseeval)
    increasing number of tasks and systems
    core wsd tasks (for many languages):

    lexical sample task: for a small set of ambiguous target words, a large number 

of labeled examples

    all word task: every word in a short text is labeled with the appropriate sense

    other tasks include:

    (cross-lingual) lexical substitution
    word sense induction
    semantic role annotation
    metonymy resolution
    temporal relation identification
    semantic text similarity
       

ss2013 |  computer science department  |   fg langtech - prof. dr. chris biemann  |

14

e.g. semeval-2 english lex. sample

algorithm precision

recall

f1

sval-1st

0.402

0.401

0.401

ext lesk

0.351

0.342

0.346

sval-2nd

0.293

0.293

0.293

lesk

0.183

0.183

0.183

random

0.141

0.141

0.141

senseval/semeval all-word task

example annotation
homeless
<head id="d00.s08.t01">people</head>
not
only
<head id="d00.s08.t04">lack</head>
safety
,
privacy
and
<head id="d00.s08.t09">shelter</head>
,
they
also
<head id="d00.s08.t13">lack</head>
the
elementary
<head id="d00.s08.t16">necessities</head>
of
nutrition
,
cleanliness
and
basic
health
care
.

    no training data, can only use lexical 

resources (   knowledge-based, 
unsupervised   ) and sense-labeled 
corpora

    all ambiguous words are marked and 

need to be assigned a sense

    fine-grained scoring: upper bound is 

inter-annotator-agreement, which is at 
about 75%

    coarse-grained scoring: inter-annotator-

agreement at around 90%

    top system performances: 65% (fine-
grained), 82% (coarse-grained); mfs 
baseline: 78% (coarse-grained)

ss2013 |  computer science department  |   fg langtech - prof. dr. chris biemann  |

15

senseval/semeval lexical sample task

example annotation

<instance id="11:0@2@wsj/14/wsj_1404@wsj" corpus="wsj">
<answer lemma="double" pos="v" on="1" wn="1" wn-version="2.1"/>
groupe ag 's chairman said 0 the belgian insurer is prepared *-1 to 
give up some of its independence to a white knight if * necessary * to 
repel a raider . amid heavy buying of shares in belgium 's largest 
insurer , maurice lippens also warned in an interview that a white 
knight , in *-1 buying out a raider , could leave speculators with big 
losses on their ag stock . since the beginning of the year , the stock 
has nearly <head> doubled </head> , * giving ag a market value of 
about 105 billion belgian francs -lrb- $ 2.7 billion *u* -rrb- . the 
most likely white knight would be societe generale de belgique s.a. , 
which *t*-2 already owns 18 % of ag and which *t*-3 itself is 
controlled *-1 by cie . financiere de suez , the acquisitive french 
financial conglomerate . but mr. lippens said 0 a rescue also could 
involve asahi mutual life insurance co. , which *t*-1 owns 5 % of ag .
</instance>

<instance id="8:0@37@wsj/14/wsj_1432@wsj" corpus="wsj">
<answer lemma="double" pos="v" on="1" wn="1" wn-version="2.1"/>
we 'll coordinate on this end to places like bangkok , singapore and 
manila . '' asian traffic , which *t*-1 currently accounts for 65 % of 
cathay 's business , is expected *-2 to continue as the carrier 's 
mainstay . cathay has long stated its desire * to <head> double 
</head> its weekly flights into china to 14 , and it is applying *-1 to 
restart long-canceled flights into vietnam . further expansion into 
southern europe is also possible , says 0 *t*-1 mr. bell , the 
spokesman . while a large number of hong kong companies have 
reincorporated offshore ahead of 1997 , such a move is n't an option for 
cathay because it would jeopardize its landing rights in hong kong .
</instance>

    training and test data: can use a 
supervised system in a machine 
learning setup

    can also use knowledge-based 

systems

    supervised systems show about 5-

7% better performance in 
evaluations

    performance: about 87% (coarse-

grained)

    variations

    ml learning algorithm
    features computed on the context
    features computed through analysis 

of large background corpora

ss2013 |  computer science department  |   fg langtech - prof. dr. chris biemann  |

16

local context features for word sense 
disambiguation

standard features for wsd
    word window
    lemma/baseform/stem window
    morphological information, e.g. gender, number, tense
    open class words in proximity, e.g. closest adjectives to target
    pos of target and context
    syntactic relations, e.g. headwords

knowledge-based features (in hybrid systems)
    id138 similarity with context -    lesk   
    id138 hypernym chains

ss2013 |  computer science department  |   fg langtech - prof. dr. chris biemann  |

17

topical features for wsd

    topical features are computed from the global context: statistics over a 

corpus as a whole

    structure discovered on the corpus level can be used to characterize 

individual instance

    some of the methods presented here have not been developed as wsd 

features, but we can treat them as such

selection of methods
    topic signatures
    word sense induction features
    latent semantic analysis vector space similarity
    topic models
    lexical expansion

ss2013 |  computer science department  |   fg langtech - prof. dr. chris biemann  |

18

examples for significant 
features

    senses of drug (gale et al. 1992):

   medication   

prices, prescription, patent,

   illegal substance   

increase, consumer,

pharmaceutical

abuse, paraphernalia, illicit,

alcohol, cocaine, traffickers

89-680 dagan

19

19

topic signatures

    idea: get more    training data per word sense 
    if people issue an ambiguous query in a search, they add more words to 

narrow down the meaning of the query

    can do this automatically using id138:
topicsignatures(ambiguous word w):

senses=findwnconcepts(w);

foreach sense s {

query=w + findrelatedwnwords(s);

resultset = issuequery(query, contextcollection);

topicsignatures= getrepresentation(resultset); }

strategies:
    findrelatedwords: only monosemous vs. all, synset-only vs. 

neighborhood, number of related words,    

    contextcollection: sentences from corpus vs. www
    getrepresentation: sig(w, resultword), lsa vectors,     

ss2013 |  computer science department  |   fg langtech - prof. dr. chris biemann  |

20

word sense discrimination as features

    unsupervised, knowledge-free sense discovery

pistol

firearm

blade

    compute similarities of words using corpus-based methods
    cluster local neighborhood of similarity graph per word
    collect typical features of clusters
    use these for disambiguation

elbow

leg

arm

    example: similarities by comparing dependencies

arm@0: thigh, spear, crest, stick, wrist, rack, throat, tip, beak, eye, mouth, mount, trunk, 
leg, edge, piece, fin, shoulder, back, motor, jaw, abdomen, paw, pair, face, belly, chair, 
claw, shaft, elbow, rib, vertebra, collar, skull, hand, blade, wing, stem, hammer, end, 
handle, roof, forehead, pole, neck, ankle, ton, axle, frame, cord, foot, shield, needle, 
fracture, knee, nose, penis, bottom, turret, slide, hook, limb, lever, chest, ear, bay, sword, 
head, flag, tail, half, banner, hip, joint, beam, breast, bone, backward, horn, spine, 
forearm, bow, badge, finger, toe, thumb, mirror (87)

limb

arm@1: pistol, saber, grenade, firearm, launcher, weapon, rifle, ammunition, shotgun, 
mortar (10)

arm@2: venture, fund, boom (3)

ss2013 |  computer science department  |   fg langtech - prof. dr. chris biemann  |

21

hip

ss2013 |  computer science department  |   fg langtech - prof. dr. chris biemann  |

22

at his hip he wore a 
pistol in an ancient 
leather holster .

i had a hip
replacement operation 
on my left side , after 
which i immediately 
broke my right leg .

ss2013 |  computer science department  |   fg langtech - prof. dr. chris biemann  |

23

this hybrid mix of 
reggae and hip hop
follows acid jazz , 
belgian new beat 
...

ho , hey , ho hi , ho , 
hey , ho , hip hop 
hooray , funky , get 
down , a-boogie , get 
down .

example: different id91 parameters

1. id91 
    bank0: largest, north, branches, eastern, opposite, km, east, west, branch, thames, banks, 

located, danube, town, south, situated, river, rhine, river, western, commercial, central, 
southern

    bank1: right, left
    bank2: money, robbers, deposit, robberies, cash, currency, account, deposits, bank, 

robbery, funds, financial, banking, loans, notes, robber, rob, accounts, credit, assets, teller, 
banco, loan, investment, savings 

2. id91
    bank0: eastern, banks, central, river, km, western, south, southern, located, largest, east, 

deposits, commercial, thames, north, west, danube, town, situated, rhine, river

    bank1: branches, branch
    bank2: robberies, robbers, robbery, robber
    bank3: right, left, opposite
    bank4: loans, cash, investment, teller, account, financial, loan, deposit, credit, funds, 

accounts, assets, savings, banking, money, rob

    bank5: banco, currency, notes, bank

ss2013 |  computer science department  |   fg langtech - prof. dr. chris biemann  |

24

combination of several cluster features

    learning curve

    x axis: amount of training
    y axis: performance

    several cluster features improve performance, especially for small 

amounts of training

ss2013 |  computer science department  |   fg langtech - prof. dr. chris biemann  |

25

  distributional thesaurus (dt)

    computed from distributional similarity statistics
    entry for a target word consists of a ranked list of neighbors

meeting
meeting
meetings
hearing
session
conference
summit
forum
workshop
hearings
ceremony
sessions
briefing
event
convention
gathering
...

288
102
89
68
62
51
46
46
46
45
41
40
40
38
36

articulate
articulate
explain
understand
communicate
defend
establish
deliver
evaluate
adjust
manage
speak
change
answer
maintain
...

89
19
17
17
16
15
14
14
14
13
13
13
13
13

first order

amod(church,@@)

immaculate

amod(condition,@@)

perfect

amod(timing,@@)

nsubj(@@,hair)

cop(@@,remains)

second order

immaculate

3

perfect

26

lexical expansion: 2d text

    knowledge-based id51 (   la lesk)

a patient fell over a stack of magazines in an aisle at a physiotherapist practice.

customer
student
individual
person
mother
user
passenger
..

fell 
rose
dropped
climbed
increased
slipped
declined
tumbled
surged
   

stack 
pile
pile
copy
lots
dozens
array
collection
collection
amount
ton
ton
   

zero word 
overlap

field
hill
line
river
stairs
road
hall
driveway
   

physician
attorney
psychiatrist
scholar
engineer
journalist
contractor
   

session
game
camp
workouts
training
meeting
work
   

id138: s: (n) magazine (product consisting of a paperback periodic publication 
as a physical object) "tripped over a pile of magazines   

pile 

jumped
woke
turned
drove
walked
blew
put
fell
fell
..

stack
stack
tons
tons
piece
heap
collection
collection
bag
loads
mountain
..

overlap = 2
overlap = 1

overlap = 2

ss2013 |  computer science department  |   fg langtech - prof. dr. chris biemann  |

27

combining (extended) lesk and 2d text

    expansions help in simplified lesk (sl) and simplified extended lesk (sel)
    the less material comes from the resource (sl), the more the expansions help
    unsupervised, knowledge-based method exceeds mfs for the first time when 

not using sense frequency information

tristan miller, chris biemann, torsten zesch, iryna gurevych (2012): using distributional similarity for lexical expansion in knowledge-based word 
sense disambiguation. proceedings of coling-2012, mumbai, india

ss2013 |  computer science department  |   fg langtech  - prof. dr. chris biemann  |

28

conclusions on wsd

    assuming a finite and discrete set of senses, a gross simplification of the 

complexity of word meaning, as studied in lexical semantics.
    word meaning is in principle infinitely variable and context-sensitive

    common and traditional characterization of wsd as an explicit and 
separate process of disambiguation, over a fixed inventory of senses

    hard to show positive impact on other tasks
    a sense inventory cannot be task-independent. example: the ambiguity 
of mouse (animal or device) is not relevant in english-german machine 
translation, but is relevant in information retrieval.

    different algorithms for different applications, e.g. precision-oriented vs. 

recall-oriented

    lexical-expansion open question:

    id138 was found useful in certain lexical expansion settings; can its 

contribution be increased with wsd?

ss2013 |  computer science department  |   fg langtech - prof. dr. chris biemann  |

29

wikification (from claudio guiliano)
what, where, and how to link?

the port city of akko

the port city of akko is located on a promontory at
the northern end of haifa bay. the earliest city was
founded during the bronze age at tel akko just east
of the excavations at tel akko attest to the long and
uninterrupted occupation of
the site during biblical
times.

    wikipedia is a rich source of lexical expansions

30

