id36 (re) 

via supervised classification

see:

   

jurafsky & martin slp book, chapter 22

    exploring various knowledge in id36. zhou 

guodong su jian zhang jie zhang min, acl 2005.

1

relations between entities 

    classification instance: a (ordered) pair of entities

    typically in a sentence

    arguments not always named entities, can be common 

noun phrases (e.g. for attack) 

    this requires segmentation (iob     like ner)

    may target single or multiple relations

    annotated training for relation instances

    relation type, argument spans and their roles

    negative examples may be all entity pairs that are not 

annotated as having a relation

    a restricted case of information extraction (ie)

    extract richer templates

2

classification architectures

    binary class for each relation, one-versus-all 

    highest classification score wins (or ranking of positives)

    all classifications negative implies no relation

    multi-class classifiers, with no-relation as a class

    two tier classification:

    is there a relation? (binary)

    relation type 

    multi-class, possibly one vs. all (highest negative score may win)

    argument role may be distinguished by its ner 
type (e.g. employee-of), or by directional features

    may classify each participant to its role

3

    usually done in template-filling ie

features 

(based on james martin     4 slides)

    we can group the re features into three 

categories

    features of the named entities/arguments 

involved

    features derived from the words between and 

around the named entities

    features derived from the syntactic 

environment that governs the two entities

4

speech and language processing - jurafsky and martin       

features

    features of the entities

    their types

    concatenation of the types

    headwords of the entities

    george washington bridge

    words in the entities

    notice: arguments aren   t only named entities, can be (common-) 

noun phrases

    features between and around

    particular positions to the left and right of the entities

    +/- 1, 2, 3

    bag of words/ id165s between

    words related to the predicate words, e.g. id138 synonyms

5

speech and language processing - jurafsky and martin       

features

    syntactic environment

    constituent path through the tree from one to 

the other

    base syntactic chunk sequence from one to the 

other

    dependency path 

    indicators of certain edges/labels along the path

    e.g. apposition

    tree-distance between arguments

6

speech and language processing - jurafsky and martin       

example

    for the following example, we   re interested in the 

possible relation between american airlines and tim 
wagner.

    american airlines, a unit of amr, immediately matched the 

move, spokesman tim wagner said.

7

speech and language 
processing - jurafsky and martin       

tuning and analysis

    look at the data

    examine feature weights 

    most positive/negative

    analyze classification errors

    false positives, false negatives

    try alternative feature selection policies

8

what about lexical variability?

    relevant for both relation and argument words

    without external resources - variability needs to 

be covered in training data

    external lexical similarity resources, manual 

and/or statistical, may be used for    lexical 
expansion   ; but it   s not trivial to gain substantial 
benefit from them in a supervised setting

    dirt-style rules may be useful for relation variability, 

there has been work in this direction in the ie field

9

template/event information extraction

    goal: extract complete templates with slots, 

often about events

    attack, acquisition, conviction,    

    extending the re supervised scheme

    possible architecture

    classifier for event trigger

    classifier for each slot

    possibly joint classification rather than pipeline

10

