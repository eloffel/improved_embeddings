id33

yoav goldberg

bar ilan university

(with slides from michael collins, sasha rush)

1 / 1

reminder

constituency trees

s

vt

heard

np

prp

i

vp

sbar

in

that

s

np

dt

nn

the

lawyer

vp

vbd

np

pp

questioned

dt

nn

in

np

np

nn

the

witness

under

nn

yesterday

oath

2 / 1

reminder

pid18 parsing

(cid:73) assume trees are generated by a (p)id18.
(cid:73) extract grammar rules from treebank.
(cid:73) each rule in a derivation has a score.
(cid:73) parsing:    nd the tree with the overall best score.

(cid:73) using the cky algorithm

3 / 1

parsing with pid18

(cid:73) parsing with a pid18 is    nding the most probable

derivation for a given sentence.

(cid:73) this can be done quite ef   ciently with dynamic

programming (the cky algorithm)

4 / 1

problems with pid18s

5 / 1

weaknessesofprobabilisticcontext-freegrammarsmichaelcollins,columbiauniversityweaknessesofpid18silackofsensitivitytolexicalinformationilackofsensitivitytostructuralfrequenciessnpnnpibmvpvtboughtnpnnplotusp(t)=q(s   npvp)  q(nnp   ibm)  q(vp   vnp)  q(vt   bought)  q(np   nnp)  q(nnp   lotus)  q(np   nnp)anothercaseofppattachmentambiguity(a)snpnnsworkersvpvpvbddumpednpnnssacksppinintonpdtannbin(b)snpnnsworkersvpvbddumpednpnpnnssacksppinintonpdtannbin(a)ruless   npvpnp   nnsvp   vpppvp   vbdnpnp   nnspp   innpnp   dtnnnns   workersvbd   dumpednns   sacksin   intodt   ann   bin(b)ruless   npvpnp   nnsnp   npppvp   vbdnpnp   nnspp   innpnp   dtnnnns   workersvbd   dumpednns   sacksin   intodt   ann   binifq(np   nppp)>q(vp   vppp)then(b)ismoreprobable,else(a)ismoreprobable.attachmentdecisioniscompletelyindependentofthewordslexicalized pid18s

pid18 problem 1
lack of sensitivity to lexical information (words)

solution

(cid:73) make pid18 aware of words (lexicalized pid18)
(cid:73) main idea: head words

6 / 1

head words

each constituent has one words which captures its    essence   .

7 / 1

head words

each constituent has one words which captures its    essence   .

(cid:73) (s john saw the young boy with the large hat)
(cid:73) (vp saw the young boy with the large hat)
(cid:73) (np the young boy with the large hat)
(cid:73) (np the large hat)

7 / 1

addingheadwordstotreessnpdtthennlawyervpvtquestionednpdtthennwitness   s(questioned)np(lawyer)dt(the)thenn(lawyer)lawyervp(questioned)vt(questioned)questionednp(witness)dt(the)thenn(witness)witnessdependency representation

8 / 1

dependency representation

if we take the head-annotated trees and    forget    about the
constituents, we get a representation called    dependency
structure   .

dependency structure capture the relation between words in a
sentence.

9 / 1

dependency representation

s(questioned)

np(lawyer)

vp(questioned)

dt(the)

nn(lawyer)

the

lawyer

vt(questioned)

np(witness)

questioned

dt(the)

nn(witness)

the

witness

10 / 1

dependency representation

questioned

lawyer

questioned

the

lawyer

the

lawyer

questioned

witness

questioned

the

witness

the

witness

10 / 1

dependency representation

questioned

lawyer

questioned

the

lawyer

the

lawyer

questioned

witness

questioned

the

witness

the

witness

10 / 1

dependency representation

questioned

lawyer

witness

the

the

10 / 1

dependency representation

questioned

lawyer

witness

the

the

10 / 1

dependency representation

10 / 1

dependency representation

10 / 1

dependency representation

dependency representation is very common.
topic of today   s class.

10 / 1

dependency representations

there are many different dependency representations

(cid:73) different choice of heads.
(cid:73) different set of labels.
(cid:73) each language usually has its own treebank, with own

choices

11 / 1

dependency representations

there are many different dependency representations

(cid:73) different choice of heads.
(cid:73) different set of labels.
(cid:73) each language usually has its own treebank, with own

choices

(cid:73) a common (and good) one for english:

stanford dependencies

(cid:73) prefer relations between words as heads.
(cid:73) about 50 labels.

11 / 1

dependency representations

there are many different dependency representations

(cid:73) different choice of heads.
(cid:73) different set of labels.
(cid:73) each language usually has its own treebank, with own

choices

(cid:73) a common (and good) one for english:

stanford dependencies

(cid:73) prefer relations between words as heads.
(cid:73) about 50 labels.

(cid:73) recently, trees in stanford-dependencies available for

different languages.

(cid:73) google   s universal dependency treebank

11 / 1

universal dependencies

(cid:73) a multi-national project aiming at producing a consistent
set of dependency annotations in many (all!) languages.

12 / 1

universal dependencies

(cid:73) a multi-national project aiming at producing a consistent
set of dependency annotations in many (all!) languages.

(cid:73) abstract over linguistic differences.
(cid:73) same set of parts-of-speech and morphology features.
(cid:73) same dependency relations.
(cid:73) same choice of heads.

12 / 1

universal dependencies

(cid:73) a multi-national project aiming at producing a consistent
set of dependency annotations in many (all!) languages.

(cid:73) abstract over linguistic differences.
(cid:73) same set of parts-of-speech and morphology features.
(cid:73) same dependency relations.
(cid:73) same choice of heads.
(cid:73) why is this good? why is this interesting?

12 / 1

universal dependencies

(cid:73) a multi-national project aiming at producing a consistent
set of dependency annotations in many (all!) languages.

(cid:73) abstract over linguistic differences.
(cid:73) same set of parts-of-speech and morphology features.
(cid:73) same dependency relations.
(cid:73) same choice of heads.
(cid:73) why is this good? why is this interesting?
(cid:73) interesting project/research idea: are the annotations

really consistent across languages? do languages differ
only in word order?

12 / 1

let   s analyze!

john saw mary .

let   s analyze!

john saw mary .

a yellow garbage can

let   s analyze!

he said that the boy who was wearing the blue shirt with

the white pockets has left the building .

let   s analyze!

a large pile of carrots and peas was closely guarded by dogs .

let   s analyze!

they wanted to buy cakes and eat them on the road .

some tricky cases

i bought soda and pizza for john and mary .

some tricky cases

i bought soda and pizza for 4 and 57 cents.

some tricky cases

i ordered    ve books but received four.

some tricky cases

while sue has many toys, alice doesn   t have any.

some tricky cases

cut, chop and peel the tomatoes.

some tricky cases

cut the tomatoes. put in a bowl.

(cid:73) coordination is interesting and important.
(cid:73) missing elements are interesting and important.

(cid:73) on the border of syntax and discourse.

(cid:73) lots of work to do!

id33

24 / 1

evaluation measures

(cid:73) uas. unlabeled attachment scores

(% of words with correct head)

(cid:73) las. labeled attachment scores

(% of words with correct head and label)

(cid:73) root

(% of sentences with correct root)

(cid:73) exact

(% of sentences with exact correct structure)

25 / 1

evaluation measures

(cid:73) uas. unlabeled attachment scores

(% of words with correct head)

90-93 (eng, wsj)

(cid:73) las. labeled attachment scores

(% of words with correct head and label)

87-90 (eng, wsj)

(cid:73) root

(% of sentences with correct root)

(cid:73) exact

   90 (eng, wsj)
40-50 (eng, wsj)

(% of sentences with exact correct structure)

25 / 1

three main approaches to id33

conversion

(cid:73) parse to constituency structure.
(cid:73) extract dependencies from the trees.

global optimization (graph based)

(cid:73) de   ne a scoring function over <sentence,tree> pairs.
(cid:73) search for best-scoring structure.
(cid:73) simpler scoring     easier search.
(cid:73) (similar to how we do tagging, constituency parsing.)

greedy decoding (transition based)

(cid:73) start with an unparsed sentence.
(cid:73) apply locally-optimal actions until sentence is parsed.

26 / 1

three main approaches to id33

conversion

(cid:73) parse to constituency structure.
(cid:73) extract dependencies from the trees.

global optimization (graph based)

argmax over combinatorial space

(cid:73) de   ne a scoring function over <sentence,tree> pairs.
(cid:73) search for best-scoring structure.
(cid:73) simpler scoring     easier search.
(cid:73) (similar to how we do tagging, constituency parsing.)

greedy decoding (transition based)

while (!done) { do best thing }

(cid:73) start with an unparsed sentence.
(cid:73) apply locally-optimal actions until sentence is parsed.

26 / 1

graph-based parsing (global search)

27 / 1

dependencyparsingalexanderrushsrush@csail.mit.edunyucs3033arcsdependencyparsingisconcernedwithhead-modi   errelationships.de   nitions:ihead;themainwordinaphraseimodi   er;anauxiliarywordinaphrasemeaningdependsonunderlyinglinguisticformalism.commontousehead   modi   erarcnotation*millionsonthecoastfacefreakstorminputnotationinput:ix=(w,t)iw1...wn;thewordsofthesentenceit1...tn;thetagsofthesentenceispecialsymbolw0=   ;thepseudo-rootnote:unlikeinid18parsing,weassumetagsaregiven.outputnotationoutput:isetofpossibledependencyarcsa={(h,m):h   {0...n},m   {1...n}}iy   {0,1}|a|;setofallvaliddependencyparsesiy   y;avaliddependencyparseexample*millions/non/pthe/dcoast/nface/vfreak/astorm/niw0=   ,w1=millions,w2=on,w3=the,...it0=   ,t1=n,t2=p,t3=d,...iy(0,5)=1,y(5,1)=1,y(1,2)=1...example*millions/non/pthe/dcoast/nface/vfreak/astorm/niw0=   ,w1=millions,w2=on,w3=the,...it0=   ,t1=n,t2=p,t3=d,...iy(0,5)=1,y(5,1)=1,y(1,2)=1...example*millions/non/pthe/dcoast/nface/vfreak/astorm/niw0=   ,w1=millions,w2=on,w3=the,...it0=   ,t1=n,t2=p,t3=d,...iy(0,5)=1,y(5,1)=1,y(1,2)=1...forbiddenstructuresieach(non-root)wordmustmodifyexactlyoneword.*millionsonthecoastfacefreakstormiarcsmustformatree.*millionsonthecoastfacefreakstormi(projective)arcsmaynotcrosseachother.*millionsonthecoastfacefreakstormmain idea

(cid:73) de   ne a scoring function g(y; x,   )
(cid:73) this function will tell us, for every x (sentence) and y (tree)

pair, how good the pair is.

(cid:73)    are the parameters, or weights (we called them w before)

(cid:73) for example: g(y; x,   ) =(cid:80)i   i(x, y)  i =   (x, y)      

(cid:73) (a linear model)

(cid:73) look for the best y for a given sentence arg maxy g(y; x,   )

28 / 1

atisagooddependencyparse?y   =argmaxy   yg(y;x,  )method:ide   nefeaturesforthisproblem.ilearnparameters  fromcorpusdata.imaximizeobjectiveto   ndbestparsey   .first-orderscoringfunctionscoringfunctiong(y;x,  )isthesumof   rst-orderarcscores*millionsonthecoastfacefreakstorm*millionsonthecoastfacefreakstorm*millionsonthecoastfacefreakstorm*millionsonthecoastfacefreakstorm*millionsonthecoastfacefreakstorm*millionsonthecoastfacefreakstorm*millionsonthecoastfacefreakstorm*millionsonthecoastfacefreakstormg(y;x,  )=score(coast   the)+score(on   coast)+score(millions   on)+score(face   millions)+score(face   storm)+score(storm   freak)+score(      face)first-orderscoringfunctionscoringfunctiong(y;x,  )isthesumof   rst-orderarcscores*millionsonthecoastfacefreakstorm*millionsonthecoastfacefreakstorm*millionsonthecoastfacefreakstorm*millionsonthecoastfacefreakstorm*millionsonthecoastfacefreakstorm*millionsonthecoastfacefreakstorm*millionsonthecoastfacefreakstorm*millionsonthecoastfacefreakstormg(y;x,  )=score(coast   the)+score(on   coast)+score(millions   on)+score(face   millions)+score(face   storm)+score(storm   freak)+score(      face)first-orderscoringfunctionscoringfunctiong(y;x,  )isthesumof   rst-orderarcscores*millionsonthecoastfacefreakstorm*millionsonthecoastfacefreakstorm*millionsonthecoastfacefreakstorm*millionsonthecoastfacefreakstorm*millionsonthecoastfacefreakstorm*millionsonthecoastfacefreakstorm*millionsonthecoastfacefreakstorm*millionsonthecoastfacefreakstormg(y;x,  )=score(coast   the)+score(on   coast)+score(millions   on)+score(face   millions)+score(face   storm)+score(storm   freak)+score(      face)first-orderscoringfunctionscoringfunctiong(y;x,  )isthesumof   rst-orderarcscores*millionsonthecoastfacefreakstorm*millionsonthecoastfacefreakstorm*millionsonthecoastfacefreakstorm*millionsonthecoastfacefreakstorm*millionsonthecoastfacefreakstorm*millionsonthecoastfacefreakstorm*millionsonthecoastfacefreakstorm*millionsonthecoastfacefreakstormg(y;x,  )=score(coast   the)+score(on   coast)+score(millions   on)+score(face   millions)+score(face   storm)+score(storm   freak)+score(      face)first-orderscoringfunctionscoringfunctiong(y;x,  )isthesumof   rst-orderarcscores*millionsonthecoastfacefreakstorm*millionsonthecoastfacefreakstorm*millionsonthecoastfacefreakstorm*millionsonthecoastfacefreakstorm*millionsonthecoastfacefreakstorm*millionsonthecoastfacefreakstorm*millionsonthecoastfacefreakstorm*millionsonthecoastfacefreakstormg(y;x,  )=score(coast   the)+score(on   coast)+score(millions   on)+score(face   millions)+score(face   storm)+score(storm   freak)+score(      face)first-orderscoringfunctionscoringfunctiong(y;x,  )isthesumof   rst-orderarcscores*millionsonthecoastfacefreakstorm*millionsonthecoastfacefreakstorm*millionsonthecoastfacefreakstorm*millionsonthecoastfacefreakstorm*millionsonthecoastfacefreakstorm*millionsonthecoastfacefreakstorm*millionsonthecoastfacefreakstorm*millionsonthecoastfacefreakstormg(y;x,  )=score(coast   the)+score(on   coast)+score(millions   on)+score(face   millions)+score(face   storm)+score(storm   freak)+score(      face)first-orderscoringfunctionscoringfunctiong(y;x,  )isthesumof   rst-orderarcscores*millionsonthecoastfacefreakstorm*millionsonthecoastfacefreakstorm*millionsonthecoastfacefreakstorm*millionsonthecoastfacefreakstorm*millionsonthecoastfacefreakstorm*millionsonthecoastfacefreakstorm*millionsonthecoastfacefreakstorm*millionsonthecoastfacefreakstormg(y;x,  )=score(coast   the)+score(on   coast)+score(millions   on)+score(face   millions)+score(face   storm)+score(storm   freak)+score(      face)first-orderscoringfunctionscoringfunctiong(y;x,  )isthesumof   rst-orderarcscores*millionsonthecoastfacefreakstorm*millionsonthecoastfacefreakstorm*millionsonthecoastfacefreakstorm*millionsonthecoastfacefreakstorm*millionsonthecoastfacefreakstorm*millionsonthecoastfacefreakstorm*millionsonthecoastfacefreakstorm*millionsonthecoastfacefreakstormg(y;x,  )=score(coast   the)+score(on   coast)+score(millions   on)+score(face   millions)+score(face   storm)+score(storm   freak)+score(      face)generativemodelonepossibility:score(wh   wm)=p(wm|wh)where:ip;amultinomialdistributionoverwords.intuition:abigram-likemodelforarcs.note:notoftenused(exceptunsupervisedparsing)conditionalmodel(e.g.crf)de   ne:score(wh   wm)=  (x,hh,mi)    where:i  (x,hh,mi):x  a   {0,1}p;afeaturefunctioni     rp;aparametervector(assumegiven)ip;numberoffeaturesfeaturesifeaturesarecriticalfordependencyparsingperformance.ispeci   edasavectorofindicators.  name(ht,wi,hh,mi)=(cid:26)1,iftm=u0,o.w.ieachfeaturehasacorrespondingreal-valueweight.  name=9.23features:tags   u   t  tag:m:u(ht,wi,hh,mi)=(cid:26)1,iftm=u0,o.w.   u   t  tag:h:u(ht,wi,hh,mi)=(cid:26)1,ifth=u0,o.w.   u,v   t  tag:h:m:u:v(ht,wi,hh,mi)=(cid:26)1,ifth=uandtm=v0,o.w.*millions/non/pthe/dcoast/nface/vfreak/astorm/nfeatures:words   u   w  word:m:u(ht,wi,hh,mi)=(cid:26)1,ifwm=u0,o.w.   u   w  word:h:u(ht,wi,hh,mi)=(cid:26)1,ifwh=u0,o.w.   u,v   w  word:h:m:u:v(ht,wi,hh,mi)=(cid:26)1,ifwh=uandwm=v0,o.w.*millions/non/pthe/dcoast/nface/vfreak/astorm/nfeatures:contexttags   u   t4  con:   1:   1:u(ht,wi,hh,mi)=         1,ifth   1=u1andth=u2andtm   1=u3andtm=u40,o.w.   u   t4  con:1:   1:u(ht,wi,hh,mi)=         1,ifth+1=u1andth=u2andtm   1=u3andtm=u40,o.w.*millions/non/pthe/dcoast/nface/vfreak/astorm/nfeatures:betweentags   u   t  bet:u(ht,wi,hh,mi)=(cid:26)1,ifti=uforibetweenhandm0,o.w.*millions/non/pthe/dcoast/nface/vfreak/astorm/nfeatures:direction  right(ht,wi,hh,mi)=(cid:26)1,ifh>m0,o.w.  left(ht,wi,hh,mi)=(cid:26)1,ifh<m0,o.w.*millions/non/pthe/dcoast/nface/vfreak/astorm/nfeatures:length  len:2(ht,wi,hh,mi)=(cid:26)1,if|h   m|>20,o.w.  len:5(ht,wi,hh,mi)=(cid:26)1,if|h   m|>50,o.w.  len:10(ht,wi,hh,mi)=(cid:26)1,if|h   m|>100,o.w.*millions/non/pthe/dcoast/nface/vfreak/astorm/nfeatures:backo   sandcombinationsiadditionallyincludebacko   .   u   t3  con:   1:u(ht,wi,hh,mi)=         1,ifth   1=u1andth=u2andtm=u30,o.w.iaswellascombinationfeatures.   u   w  len:2:dir:left:tag:m:u(ht,wi,hh,mi)=(cid:26)1,ifallon0,o.w.first-orderresultsmodelaccuracynoposcontextbetween86.0noedge87.3noattachmentordistance88.1nobilex90.6full90.7frommcdonald(2006)improvingthemodelicangetatinybitbetterwithmorefeatures.ineedtoimprovethemodelforlargergainshigher-ordermodeliinsteadofarcseta={(h,m):h   {0...n},m   {1...n}}iusesecond-orderseta(2)={(h,s,m):h   {0...n},s   {1...n},m   {1...n}}iincludesthe   sibling   :previousmodi   ertoh.second-ordermodel*millionsonthecoastfacefreakstorm*millionsonthecoastfacefreakstorm*millionsonthecoastfacefreakstorm*millionsonthecoastfacefreakstorm*millionsonthecoastfacefreakstorm*millionsonthecoastfacefreakstorm*millionsonthecoastfacefreakstorm*millionsonthecoastfacefreakstormg(2)(y;x,  )=score(face   coast,null)+score(face   the,coast)+score(face   on,the)+score(face   millions,on)+score(face   freak,null)+score(face   storm,freak)+score(      face,null)second-ordermodel*millionsonthecoastfacefreakstorm*millionsonthecoastfacefreakstorm*millionsonthecoastfacefreakstorm*millionsonthecoastfacefreakstorm*millionsonthecoastfacefreakstorm*millionsonthecoastfacefreakstorm*millionsonthecoastfacefreakstorm*millionsonthecoastfacefreakstormg(2)(y;x,  )=score(face   coast,null)+score(face   the,coast)+score(face   on,the)+score(face   millions,on)+score(face   freak,null)+score(face   storm,freak)+score(      face,null)second-ordermodel*millionsonthecoastfacefreakstorm*millionsonthecoastfacefreakstorm*millionsonthecoastfacefreakstorm*millionsonthecoastfacefreakstorm*millionsonthecoastfacefreakstorm*millionsonthecoastfacefreakstorm*millionsonthecoastfacefreakstorm*millionsonthecoastfacefreakstormg(2)(y;x,  )=score(face   coast,null)+score(face   the,coast)+score(face   on,the)+score(face   millions,on)+score(face   freak,null)+score(face   storm,freak)+score(      face,null)second-ordermodel*millionsonthecoastfacefreakstorm*millionsonthecoastfacefreakstorm*millionsonthecoastfacefreakstorm*millionsonthecoastfacefreakstorm*millionsonthecoastfacefreakstorm*millionsonthecoastfacefreakstorm*millionsonthecoastfacefreakstorm*millionsonthecoastfacefreakstormg(2)(y;x,  )=score(face   coast,null)+score(face   the,coast)+score(face   on,the)+score(face   millions,on)+score(face   freak,null)+score(face   storm,freak)+score(      face,null)second-ordermodel*millionsonthecoastfacefreakstorm*millionsonthecoastfacefreakstorm*millionsonthecoastfacefreakstorm*millionsonthecoastfacefreakstorm*millionsonthecoastfacefreakstorm*millionsonthecoastfacefreakstorm*millionsonthecoastfacefreakstorm*millionsonthecoastfacefreakstormg(2)(y;x,  )=score(face   coast,null)+score(face   the,coast)+score(face   on,the)+score(face   millions,on)+score(face   freak,null)+score(face   storm,freak)+score(      face,null)second-ordermodel*millionsonthecoastfacefreakstorm*millionsonthecoastfacefreakstorm*millionsonthecoastfacefreakstorm*millionsonthecoastfacefreakstorm*millionsonthecoastfacefreakstorm*millionsonthecoastfacefreakstorm*millionsonthecoastfacefreakstorm*millionsonthecoastfacefreakstormg(2)(y;x,  )=score(face   coast,null)+score(face   the,coast)+score(face   on,the)+score(face   millions,on)+score(face   freak,null)+score(face   storm,freak)+score(      face,null)second-ordermodel*millionsonthecoastfacefreakstorm*millionsonthecoastfacefreakstorm*millionsonthecoastfacefreakstorm*millionsonthecoastfacefreakstorm*millionsonthecoastfacefreakstorm*millionsonthecoastfacefreakstorm*millionsonthecoastfacefreakstorm*millionsonthecoastfacefreakstormg(2)(y;x,  )=score(face   coast,null)+score(face   the,coast)+score(face   on,the)+score(face   millions,on)+score(face   freak,null)+score(face   storm,freak)+score(      face,null)second-ordermodel*millionsonthecoastfacefreakstorm*millionsonthecoastfacefreakstorm*millionsonthecoastfacefreakstorm*millionsonthecoastfacefreakstorm*millionsonthecoastfacefreakstorm*millionsonthecoastfacefreakstorm*millionsonthecoastfacefreakstorm*millionsonthecoastfacefreakstormg(2)(y;x,  )=score(face   coast,null)+score(face   the,coast)+score(face   on,the)+score(face   millions,on)+score(face   freak,null)+score(face   storm,freak)+score(      face,null)conditionalmodel(e.g.crf)de   ne:score(wh   wm)=  (x,hh,mi)    where:i  (x,hh,mi):x  a(2)   {0,1}p;afeaturefunctioni     rp;aparametervector(assumegiven)ip;numberoffeaturessecond-orderresultsmodelaccuracynoposcontextbetween90.0noedge89.5noattachmentordistance91.3nobilex91.5full91.5frommcdonald(2006)what   sleftide   nefeaturesforthisproblem.ilearnparameters  fromcorpusdata.imaximizeobjectiveto   ndbestparsey   .downside:higher-ordermodelsmakeid136moredi   culty   =argmaxy   yg(y;x,  )what   sleftide   nefeaturesforthisproblem.ilearnparameters  fromcorpusdata.imaximizeobjectiveto   ndbestparsey   .downside:higher-ordermodelsmakeid136moredi   culty   =argmaxy   yg(y;x,  )parsinggoal:findingthebestparse.y   =argmaxy   yg(y;x,  )graphalgorithmsalgorithm2:usegraphalgorithmsforparsing.findthemaximumdirectedspanningtree.ichou-liu-edmondsalgorithmo(n3)itarjan   sextensiono(n2)graphalgorithmsalgorithm2:usegraphalgorithmsforparsing.findthemaximumdirectedspanningtree.ichou-liu-edmondsalgorithmo(n3)itarjan   sextensiono(n2)maximumdirectedspanningtreealgorithmissueswithmstalgorithmiallowsnon-projectiveparses.*millionsonthecoastfacefreakstormigoodforsomelanguages.icannotincorporatehigher-orderparts.iproblembecomesnp-hard.dynamicprogrammingforparsingalgorithm3:useaspecializeddynamicprogrammingalgorithm.itheeisneralgorithm(1996)forbilexicalparsing.iusesplit-headtrick.handleleftandrightdependenciesseparately.dependencyparsingnewexample*asmcgwireneared,fanswentwildbasecase*asmcgwireneared,fanswentwild;dependencyparsingalgorithm-first-ordermodelhm   hr+mr+1he   hm+meparsing*asmcgwireneared,fanswentwild*asmcgwireneared,fanswentwild*asmcgwireneared,fanswentwild*asmcgwireneared,fanswentwild*asmcgwireneared,fanswentwild*asmcgwireneared,fanswentwild*asmcgwireneared,fanswentwild*asmcgwireneared,fanswentwild*asmcgwireneared,fanswentwildparsing*asmcgwireneared,fanswentwild*asmcgwireneared,fanswentwild*asmcgwireneared,fanswentwild*asmcgwireneared,fanswentwild*asmcgwireneared,fanswentwild*asmcgwireneared,fanswentwild*asmcgwireneared,fanswentwild*asmcgwireneared,fanswentwild*asmcgwireneared,fanswentwildparsing*asmcgwireneared,fanswentwild*asmcgwireneared,fanswentwild*asmcgwireneared,fanswentwild*asmcgwireneared,fanswentwild*asmcgwireneared,fanswentwild*asmcgwireneared,fanswentwild*asmcgwireneared,fanswentwild*asmcgwireneared,fanswentwild*asmcgwireneared,fanswentwildparsing*asmcgwireneared,fanswentwild*asmcgwireneared,fanswentwild*asmcgwireneared,fanswentwild*asmcgwireneared,fanswentwild*asmcgwireneared,fanswentwild*asmcgwireneared,fanswentwild*asmcgwireneared,fanswentwild*asmcgwireneared,fanswentwild*asmcgwireneared,fanswentwildparsing*asmcgwireneared,fanswentwild*asmcgwireneared,fanswentwild*asmcgwireneared,fanswentwild*asmcgwireneared,fanswentwild*asmcgwireneared,fanswentwild*asmcgwireneared,fanswentwild*asmcgwireneared,fanswentwild*asmcgwireneared,fanswentwild*asmcgwireneared,fanswentwildparsing*asmcgwireneared,fanswentwild*asmcgwireneared,fanswentwild*asmcgwireneared,fanswentwild*asmcgwireneared,fanswentwild*asmcgwireneared,fanswentwild*asmcgwireneared,fanswentwild*asmcgwireneared,fanswentwild*asmcgwireneared,fanswentwild*asmcgwireneared,fanswentwildparsing*asmcgwireneared,fanswentwild*asmcgwireneared,fanswentwild*asmcgwireneared,fanswentwild*asmcgwireneared,fanswentwild*asmcgwireneared,fanswentwild*asmcgwireneared,fanswentwild*asmcgwireneared,fanswentwild*asmcgwireneared,fanswentwild*asmcgwireneared,fanswentwildparsing*asmcgwireneared,fanswentwild*asmcgwireneared,fanswentwild*asmcgwireneared,fanswentwild*asmcgwireneared,fanswentwild*asmcgwireneared,fanswentwild*asmcgwireneared,fanswentwild*asmcgwireneared,fanswentwild*asmcgwireneared,fanswentwild*asmcgwireneared,fanswentwildparsing*asmcgwireneared,fanswentwild*asmcgwireneared,fanswentwild*asmcgwireneared,fanswentwild*asmcgwireneared,fanswentwild*asmcgwireneared,fanswentwild*asmcgwireneared,fanswentwild*asmcgwireneared,fanswentwild*asmcgwireneared,fanswentwild*asmcgwireneared,fanswentwildalgorithmkeyil;left-facingitemir;right-facingitemic;completeditem(triangle)ii;incompleteitem(trapezoid)algorithminitialize:foriin0...ndo  [c,l,i,i]=0  [c,r,i,i]=0  [i,l,i,i]=0  [i,r,i,i]=0innerloop:forkin1...ndoforsin0...ndot   k+sift   nthenbreak  [i,l,s,t]=maxr   s...t   1  [c,r,s,r]+  [c,l,r+1,t]  [i,r,s,t]=maxr   s...t   1  [c,r,s,r]+  [c,l,r+1,t]  [c,l,s,t]=maxr   s...t   1  [c,l,s,r]+  [i,l,r,t]  [c,r,s,t]=maxr   s+1...t  [i,r,s,r]+  [c,r,r,t]return  [c,r,0,n]graph-based parsing algorithm

(cid:73) begin with a tagged sentence (can use a pos-tagger)

29 / 1

graph-based parsing algorithm

(cid:73) begin with a tagged sentence (can use a pos-tagger)
(cid:73) extract a set of    parts   

(cid:73) for a    rst-order model, each part is a (h, m) pair

(cid:73) for a second-order model, each part is a (h, m1, m2) tuple

(o(n2) parts)

(o(n3) parts)

29 / 1

graph-based parsing algorithm

(cid:73) begin with a tagged sentence (can use a pos-tagger)
(cid:73) extract a set of    parts   

(cid:73) for a    rst-order model, each part is a (h, m) pair

(cid:73) for a second-order model, each part is a (h, m1, m2) tuple

(o(n2) parts)

(o(n3) parts)

(cid:73) calculate a score for each part (using feature-extractor   

and parameters   )

29 / 1

graph-based parsing algorithm

(cid:73) begin with a tagged sentence (can use a pos-tagger)
(cid:73) extract a set of    parts   

(cid:73) for a    rst-order model, each part is a (h, m) pair

(cid:73) for a second-order model, each part is a (h, m1, m2) tuple

(o(n2) parts)

(o(n3) parts)

(cid:73) calculate a score for each part (using feature-extractor   

and parameters   )

(cid:73) find a valid parse tree that is composed of the best parts.

(cid:73) using chu-liu-edmunds (for    rst-order non-projective)

(cid:73) using a dynamic-programming algorithm (for    rst- and

(o(n2))

second-order projective)
(o(n3))

29 / 1

graph-based parsing algorithm

(cid:73) begin with a tagged sentence (can use a pos-tagger)
(cid:73) extract a set of    parts   

(cid:73) for a    rst-order model, each part is a (h, m) pair

(cid:73) for a second-order model, each part is a (h, m1, m2) tuple

(o(n2) parts)

(o(n3) parts)

(cid:73) calculate a score for each part (using feature-extractor   

and parameters   )

(cid:73) find a valid parse tree that is composed of the best parts.

(cid:73) using chu-liu-edmunds (for    rst-order non-projective)

(cid:73) using a dynamic-programming algorithm (for    rst- and

(o(n2))

second-order projective)
(o(n3))

does this remind you of anything?

29 / 1

id136ifullalgorithmso(n3).imuchfasterthanstandardlexicalizedparsing.iotherwaystofurtherimprovespeed.training - setting values for   

30 / 1

note: we need values such that g(y; x,   ) of gold tree y is larger
than g(y(cid:48); x,   ) for all other trees y(cid:48).

31 / 1

id88sketch:part1i(x1,y1)...(xn,yn);trainingdataigoldfeaturesxa   a:y(a)=1  (xi,a)idea:increasevalue(in  )ofgoldfeatures.id88sketch:part2ibest-scoringstructurezi=argmaxz   yg(z;x,  )ibest-scoringstructurefeaturesxa   a:z(a)=1  (xi,a)idea:decreasevalue(in  )ofwrongbest-scoringfeaturesid88algorithm     0fort=1...t,i=1...ndozi=argmaxy   yg(y;xi,  )gold   xa   a:yi(a)=1  (xi,a)best   xa   a:zi(a)=1  (xi,a)       +gold   bestreturn  theoryiifpossible,id88willseparatethecorrectstructurefromtheincorrectstructure.ithatis,itwill   nda  thatassignsyiahigherscorethanothery   yforeachexample.practicaltrainingconsiderationsitrainingrequiressolvingid136manytimes.ioftentimescomputingfeaturevaluesistimeconsuming.iinpractice,averagedid88variantpreferred(collins,2002).conclusionmethod:ide   nefeaturesforthisproblem.ilearnparameters  fromcorpusdata.imaximizeobjectiveto   ndbestparsey   .structuredpredictionframework,applicabletomanyproblems.transition-based parsing

32 / 1

transition-based (greedy) parsing

1. start with an unparsed sentence.
2. apply locally-optimal actions until sentence is parsed.

33 / 1

transition-based (greedy) parsing

1. start with an unparsed sentence.
2. apply locally-optimal actions until sentence is parsed.
3. use whatever features you want.
4. surprisingly accurate.
5. can be extremely fast.

33 / 1

intro to transition-based id33

an abstract machine composed of a stack and a buffer.

machine is initialized with the words of a sentence.

a set of actions process the words by moving them from buffer
to stack, removing them from the stack, or adding links between
them.

a speci   c set of actions de   ne a transition system.

34 / 1

the arc-eager transition system

(cid:73) shift move    rst word from buffer

to stack.
(pre: buffer not empty.)

a a b c d

a a b c d

35 / 1

the arc-eager transition system

(cid:73) shift move    rst word from buffer

to stack.
(pre: buffer not empty.)

(cid:73) leftarclabel make    rst word in
buffer head of top of stack, pop
the stack.
(pre: stack not empty. top of stack does
not have a parent.)

a a b c d

a a b c d

35 / 1

the arc-eager transition system

(cid:73) shift move    rst word from buffer

to stack.
(pre: buffer not empty.)

(cid:73) leftarclabel make    rst word in
buffer head of top of stack, pop
the stack.
(pre: stack not empty. top of stack does
not have a parent.)

(cid:73) rightarclabel make top of stack
head of    rst in buffer, move    rst
in buffer to stack.
(pre: buffer not empty.)

a a b c d

a a b c d

35 / 1

the arc-eager transition system

(cid:73) shift move    rst word from buffer

to stack.
(pre: buffer not empty.)

(cid:73) leftarclabel make    rst word in
buffer head of top of stack, pop
the stack.
(pre: stack not empty. top of stack does
not have a parent.)

(cid:73) rightarclabel make top of stack
head of    rst in buffer, move    rst
in buffer to stack.
(pre: buffer not empty.)

(cid:73) reduce pop the stack

(pre: stack not empty. top of stack has a
parent.)

a a b c d

a a b c d

35 / 1

parsing example

a

she ate pizza with pleasure

36 / 1

parsing example

a she

ate pizza with pleasure

36 / 1

parsing example

a she

ate pizza with pleasure

36 / 1

parsing example

a she ate

pizza with pleasure

36 / 1

parsing example

a she ate pizza with pleasure

36 / 1

parsing example

a she ate pizza with pleasure

36 / 1

parsing example

a she ate pizza with

pleasure

36 / 1

parsing example

a she ate pizza with pleasure

36 / 1

parsing example

a she ate pizza with pleasure

36 / 1

parsing example

a she ate pizza with pleasure

36 / 1

parsing example

a she ate pizza with pleasure

36 / 1

what do we know about the arc-eager transition
system?

(cid:73) every sequence of actions result in a valid projective

structure.

(cid:73) every projective tree is derivable by (at least one)

sequence of actions.

(cid:73) given a tree,    nding a sequence of actions for deriving it.

("oracle")

we know these things also for the

arc-standard, arc-hybrid and other transition systems

37 / 1

this knowledge is quite powerful

parsing with an oracle sequence

sequence     oracle(sentence, tree)
con   guration     initialize(sentence)
while not con   guration.isfinal() do

action     sequence.next()
con   guration     con   guration.apply(action)

return con   guration.tree

   she ate pizza with pleasure   

38 / 1

this knowledge is quite powerful

parsing with an oracle sequence

sequence     oracle(sentence, tree)
con   guration     initialize(sentence)
while not con   guration.isfinal() do

action     sequence.next()
con   guration     con   guration.apply(action)

return con   guration.tree

   she ate pizza with pleasure   

sh left sh right re right right re re re

38 / 1

this knowledge is quite powerful

parsing with an oracle sequence

sequence     oracle(sentence, tree)
con   guration     initialize(sentence)
while not con   guration.isfinal() do

action     sequence.next()
con   guration     con   guration.apply(action)

return con   guration.tree

   she ate pizza with pleasure   

sh left sh right re right right re re re

a

she ate pizza with pleasure

38 / 1

this knowledge is quite powerful

parsing with an oracle sequence

sequence     oracle(sentence, tree)
con   guration     initialize(sentence)
while not con   guration.isfinal() do

action     sequence.next()
con   guration     con   guration.apply(action)

return con   guration.tree

   she ate pizza with pleasure   

sh left sh right re right right re re re

a

she ate pizza with pleasure

38 / 1

this knowledge is quite powerful

parsing with an oracle sequence

sequence     oracle(sentence, tree)
con   guration     initialize(sentence)
while not con   guration.isfinal() do

action     sequence.next()
con   guration     con   guration.apply(action)

return con   guration.tree

   she ate pizza with pleasure   

sh left sh right re right right re re re

a she

ate pizza with pleasure

38 / 1

this knowledge is quite powerful

parsing with an oracle sequence

sequence     oracle(sentence, tree)
con   guration     initialize(sentence)
while not con   guration.isfinal() do

action     sequence.next()
con   guration     con   guration.apply(action)

return con   guration.tree

   she ate pizza with pleasure   

sh left sh right re right right re re re

a she

ate pizza with pleasure

38 / 1

this knowledge is quite powerful

parsing with an oracle sequence

sequence     oracle(sentence, tree)
con   guration     initialize(sentence)
while not con   guration.isfinal() do

action     sequence.next()
con   guration     con   guration.apply(action)

return con   guration.tree

   she ate pizza with pleasure   

sh left sh right re right right re re re

a she

ate pizza with pleasure

38 / 1

this knowledge is quite powerful

parsing with an oracle sequence

sequence     oracle(sentence, tree)
con   guration     initialize(sentence)
while not con   guration.isfinal() do

action     sequence.next()
con   guration     con   guration.apply(action)

return con   guration.tree

   she ate pizza with pleasure   

sh left sh right re right right re re re

a she

ate pizza with pleasure

38 / 1

this knowledge is quite powerful

parsing with an oracle sequence

sequence     oracle(sentence, tree)
con   guration     initialize(sentence)
while not con   guration.isfinal() do

action     sequence.next()
con   guration     con   guration.apply(action)

return con   guration.tree

   she ate pizza with pleasure   

sh left sh right re right right re re re

a she ate

pizza with pleasure

38 / 1

this knowledge is quite powerful

parsing with an oracle sequence

sequence     oracle(sentence, tree)
con   guration     initialize(sentence)
while not con   guration.isfinal() do

action     sequence.next()
con   guration     con   guration.apply(action)

return con   guration.tree

   she ate pizza with pleasure   

sh left sh right re right right re re re

a she ate

pizza with pleasure

38 / 1

this knowledge is quite powerful

parsing with an oracle sequence

sequence     oracle(sentence, tree)
con   guration     initialize(sentence)
while not con   guration.isfinal() do

action     sequence.next()
con   guration     con   guration.apply(action)

return con   guration.tree

   she ate pizza with pleasure   

sh left sh right re right right re re re

a she ate pizza with pleasure

38 / 1

this knowledge is quite powerful

parsing with an oracle sequence

sequence     oracle(sentence, tree)
con   guration     initialize(sentence)
while not con   guration.isfinal() do

action     sequence.next()
con   guration     con   guration.apply(action)

return con   guration.tree

   she ate pizza with pleasure   

sh left sh right re right right re re re

a she ate pizza with pleasure

38 / 1

this knowledge is quite powerful

parsing with an oracle sequence

sequence     oracle(sentence, tree)
con   guration     initialize(sentence)
while not con   guration.isfinal() do

action     sequence.next()
con   guration     con   guration.apply(action)

return con   guration.tree

   she ate pizza with pleasure   

sh left sh right re right right re re re

a she ate pizza with pleasure

38 / 1

this knowledge is quite powerful

parsing with an oracle sequence

sequence     oracle(sentence, tree)
con   guration     initialize(sentence)
while not con   guration.isfinal() do

action     sequence.next()
con   guration     con   guration.apply(action)

return con   guration.tree

   she ate pizza with pleasure   

sh left sh right re right right re re re

a she ate pizza with pleasure

38 / 1

this knowledge is quite powerful

parsing with an oracle sequence

sequence     oracle(sentence, tree)
con   guration     initialize(sentence)
while not con   guration.isfinal() do

action     sequence.next()
con   guration     con   guration.apply(action)

return con   guration.tree

   she ate pizza with pleasure   

sh left sh right re right right re re re

a she ate pizza with

pleasure

38 / 1

this knowledge is quite powerful

parsing with an oracle sequence

sequence     oracle(sentence, tree)
con   guration     initialize(sentence)
while not con   guration.isfinal() do

action     sequence.next()
con   guration     con   guration.apply(action)

return con   guration.tree

   she ate pizza with pleasure   

sh left sh right re right right re re re

a she ate pizza with

pleasure

38 / 1

this knowledge is quite powerful

parsing with an oracle sequence

sequence     oracle(sentence, tree)
con   guration     initialize(sentence)
while not con   guration.isfinal() do

action     sequence.next()
con   guration     con   guration.apply(action)

return con   guration.tree

   she ate pizza with pleasure   

sh left sh right re right right re re re

a she ate pizza with pleasure

38 / 1

this knowledge is quite powerful

parsing with an oracle sequence

sequence     oracle(sentence, tree)
con   guration     initialize(sentence)
while not con   guration.isfinal() do

action     sequence.next()
con   guration     con   guration.apply(action)

return con   guration.tree

   she ate pizza with pleasure   

sh left sh right re right right re re re

a she ate pizza with pleasure

38 / 1

this knowledge is quite powerful

parsing with an oracle sequence

sequence     oracle(sentence, tree)
con   guration     initialize(sentence)
while not con   guration.isfinal() do

action     sequence.next()
con   guration     con   guration.apply(action)

return con   guration.tree

   she ate pizza with pleasure   

sh left sh right re right right re re re

a she ate pizza with pleasure

38 / 1

this knowledge is quite powerful

parsing with an oracle sequence

sequence     oracle(sentence, tree)
con   guration     initialize(sentence)
while not con   guration.isfinal() do

action     sequence.next()
con   guration     con   guration.apply(action)

return con   guration.tree

   she ate pizza with pleasure   

sh left sh right re right right re re re

a she ate pizza with pleasure

38 / 1

this knowledge is quite powerful

parsing with an oracle sequence

sequence     oracle(sentence, tree)
con   guration     initialize(sentence)
while not con   guration.isfinal() do

action     sequence.next()
con   guration     con   guration.apply(action)

return con   guration.tree

   she ate pizza with pleasure   

sh left sh right re right right re re re

a she ate pizza with pleasure

38 / 1

this knowledge is quite powerful

parsing with an oracle sequence

sequence     oracle(sentence, tree)
con   guration     initialize(sentence)
while not con   guration.isfinal() do

action     sequence.next()
con   guration     con   guration.apply(action)

return con   guration.tree

   she ate pizza with pleasure   

sh left sh right re right right re re re

a she ate pizza with pleasure

38 / 1

this knowledge is quite powerful

parsing with an oracle sequence

sequence     oracle(sentence, tree)
con   guration     initialize(sentence)
while not con   guration.isfinal() do

action     sequence.next()
con   guration     con   guration.apply(action)

return con   guration.tree

   she ate pizza with pleasure   

sh left sh right re right right re re re

a she ate pizza with pleasure

38 / 1

this knowledge is quite powerful

parsing with an oracle sequence

sequence     oracle(sentence, tree)
con   guration     initialize(sentence)
while not con   guration.isfinal() do

action     sequence.next()
con   guration     con   guration.apply(action)

return con   guration.tree

   she ate pizza with pleasure   

sh left sh right re right right re re re

a she ate pizza with pleasure

38 / 1

this knowledge is quite powerful

parsing without an oracle

sequence     oracle(sentence, tree)
con   guration     initialize(sentence)
while not con   guration.isfinal() do

action     sequence.next()
con   guration     con   guration.apply(action)

return con   guration.tree

39 / 1

this knowledge is quite powerful

parsing without an oracle

start with weight vector w
con   guration     initialize(sentence)
while not con   guration.isfinal() do

action     predict(w,   (con   guration))
con   guration     con   guration.apply(action)

return con   guration.tree

39 / 1

this knowledge is quite powerful

parsing without an oracle

summarize the con   guration

as a feature vector
start with weight vector w
con   guration     initialize(sentence)
while not con   guration.isfinal() do

action     predict(w,   (con   guration))
con   guration     con   guration.apply(action)

return con   guration.tree

39 / 1

this knowledge is quite powerful

parsing without an oracle

summarize the con   guration

as a feature vector
start with weight vector w
con   guration     initialize(sentence)
while not con   guration.isfinal() do

action     predict(w,   (con   guration))
con   guration     con   guration.apply(action)

return con   guration.tree

predict the action based on the features

39 / 1

this knowledge is quite powerful

parsing without an oracle

summarize the con   guration

as a feature vector
start with weight vector w
con   guration     initialize(sentence)
while not con   guration.isfinal() do

action     predict(w,   (con   guration))
con   guration     con   guration.apply(action)

return con   guration.tree

predict the action based on the features

need to learn the correct weights

39 / 1

this knowledge is quite powerful

parsing with an oracle sequence

sequence     oracle(sentence, tree)
con   guration     initialize(sentence)
while not con   guration.isfinal() do

action     sequence.next()
con   guration     con   guration.apply(action)

40 / 1

this knowledge is quite powerful

learning a parser (batch)

sequence     oracle(sentence, tree)
con   guration     initialize(sentence)
while not con   guration.isfinal() do

action     sequence.next()

con   guration     con   guration.apply(action)

40 / 1

this knowledge is quite powerful

learning a parser (batch)
training_set     []
for sentence,tree pair in corpus do

sequence     oracle(sentence, tree)
con   guration     initialize(sentence)
while not con   guration.isfinal() do

action     sequence.next()
features       (con   guration)
training_set.add(features, action)
con   guration     con   guration.apply(action)

train a classi   er on training_set

40 / 1

this knowledge is quite powerful

learning a parser (batch)
training_set     []
for sentence,tree pair in corpus do

sequence     oracle(sentence, tree)
con   guration     initialize(sentence)
while not con   guration.isfinal() do

action     sequence.next()
features       (con   guration)
training_set.add(features, action)
con   guration     con   guration.apply(action)

train a classi   er on training_set

40 / 1

this knowledge is quite powerful

learning a parser (online)
training_set     []
for sentence,tree pair in corpus do

sequence     oracle(sentence, tree)
con   guration     initialize(sentence)
while not con   guration.isfinal() do

action     sequence.next()
features       (con   guration)
training_set.add(features, action)
con   guration     con   guration.apply(action)

train a classi   er on training_set

40 / 1

this knowledge is quite powerful

learning a parser (online)
w     0
for sentence,tree pair in corpus do

sequence     oracle(sentence, tree)
con   guration     initialize(sentence)
while not con   guration.isfinal() do

action     sequence.next()
features       (con   guration)
predicted     predict(w,   (con   guration))
if predicted (cid:54)= action then
con   guration     con   guration.apply(action)

w.update(  (con   guration), action, predicted)

return w

40 / 1

this knowledge is quite powerful

learning a parser (online)
w     0
for sentence,tree pair in corpus do

sequence     oracle(sentence, tree)
con   guration     initialize(sentence)
while not con   guration.isfinal() do

action     sequence.next()
features       (con   guration)
predicted     predict(w,   (con   guration))
if predicted (cid:54)= action then
con   guration     con   guration.apply(action)

w.update(  (con   guration), action, predicted)

return w

40 / 1

this knowledge is quite powerful

parsing time

con   guration     initialize(sentence)
while not con   guration.isfinal() do

action     predict(w,   (con   guration))
con   guration     con   guration.apply(action)

return con   guration.tree

41 / 1

in short

(cid:73) summarize con   guration by a set of features.
(cid:73) learn the best action to take at each con   guration.
(cid:73) hope this generalizes well.

42 / 1

transition based parsing

(cid:73) a different approach.
(cid:73) very common.
(cid:73) can be as accurate as    rst-order graph-based parsing.

(cid:73) higher-order graph-based are still better.

(cid:73) easy to implement.
(cid:73) very fast. (o(n))
(cid:73) can be improved further:

(cid:73) easy-   rst
(cid:73) dynamic oracle
(cid:73) id125

44 / 1

hybrid approaches

45 / 1

hybrid-approaches

(cid:73) different parsers have different strengths.
    combine several parsers.

46 / 1

hybrid-approaches

(cid:73) different parsers have different strengths.
    combine several parsers.
stacking

(cid:73) run parser a.
(cid:73) use tree from parser a to add features to parser b.

46 / 1

hybrid-approaches

(cid:73) different parsers have different strengths.
    combine several parsers.
stacking

(cid:73) run parser a.
(cid:73) use tree from parser a to add features to parser b.

voting

(cid:73) parse the sentence with k different parsers.
(cid:73) each parser    votes    on its dependency arcs.
(cid:73) run    rst-order graph-parser to    nd tree with best arcs

according to votes.

46 / 1

semi-supervised-approaches

(cid:73) we only see very few words (and word-pairs) in training

data.

(cid:73) if we know (eat, carrot) is a good pair, what do we know

about (eat, tomato)?

(cid:73) nothing, if the pair is not in our training data!
    use unlabeled data.

47 / 1

semi-supervised-approaches

(cid:73) we only see very few words (and word-pairs) in training

data.

(cid:73) if we know (eat, carrot) is a good pair, what do we know

about (eat, tomato)?

(cid:73) nothing, if the pair is not in our training data!
    use unlabeled data.

47 / 1

semi-supervised-approaches

(cid:73) we only see very few words (and word-pairs) in training

data.

(cid:73) if we know (eat, carrot) is a good pair, what do we know

about (eat, tomato)?

(cid:73) nothing, if the pair is not in our training data!
    use unlabeled data.
cluster features

(cid:73) represent words as context vectors.
(cid:73) de   ne a similarity measure between vectors.
(cid:73) use a id91 algorithm to cluster the words.
(cid:73) we hope that:

(cid:73) (eat, drink, devour,. . . ) are in the same cluster.
(cid:73) (tomato, carrot, pizza, . . . ) are in the same cluster.

(cid:73) use clusters as additional features to the parser.

47 / 1

semi-supervised-approaches

(cid:73) we only see very few words (and word-pairs) in training

data.

(cid:73) if we know (eat, carrot) is a good pair, what do we know

about (eat, tomato)?

(cid:73) nothing, if the pair is not in our training data!
    use unlabeled data.
cluster features

(cid:73) represent words as context vectors.
(cid:73) de   ne a similarity measure between vectors.
(cid:73) use a id91 algorithm to cluster the words.
(cid:73) we hope that:

(cid:73) (eat, drink, devour,. . . ) are in the same cluster.
(cid:73) (tomato, carrot, pizza, . . . ) are in the same cluster.

(cid:73) use clusters as additional features to the parser.

(cid:73) this works well (better?) also for pos-tagging, ner.

47 / 1

available software

there are many parsers available for download, including:
constituency (pid18)

(cid:73) stanford parser (can produce also dependencies)
(cid:73) berkeley parser
(cid:73) charniak parser
(cid:73) collins parser

dependency

(cid:73) rbgparser, turboparser (graph based)
(cid:73) zpar (transition+beam)
(cid:73) clearnlp (many variants)
(cid:73) easyfirst (my own)
(cid:73) bist parser (from bgu lab, bilstm, graph + transition)
(cid:73) spacy (nice api, super fast!!)

48 / 1

summary

dependency parsers

(cid:73) conversion from constituency
(cid:73) graph-based
(cid:73) transition-based
(cid:73) hybrid / ensemble
(cid:73) semi-supervised (cluster features)

49 / 1

