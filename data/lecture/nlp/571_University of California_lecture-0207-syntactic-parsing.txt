syntactic	parsing

prof.	sameer	singh
cs	295:	statistical	nlp
winter	2017

february	7,	2017

based	on	slides	from	nathan	schneider,	noah	smith,	marine	carpuat,	dan	jurafsky,	and	everyone	else	they	copied	from.

outline

syntactic	parsing

context	free	grammars

parsing:	cky	algorithm

cs	295:	statistical	nlp	(winter	2017)

2

outline

syntactic	parsing

context	free	grammars

parsing:	cky	algorithm

cs	295:	statistical	nlp	(winter	2017)

3

limitations	of	sequence	tags

john	smith	shot	bill	in	his	pajamas.

what	happened?
who	shot	who?
who	was	wearing	the	pajamas?

using	http://nlp.stanford.edu:8080/corenlp/process

cs	295:	statistical	nlp	(winter	2017)

4

constituents

    constituent	behave	as	a	unit	that	can	be	rearranged:

john	talked	[to	the	children]	[about	drugs].
john	talked	[about	drugs]	[to	the	children].
john	talked	drugs	to	the	children	about

    or	substituted/expanded:

john	talked	[to	the	children	taking	the	drugs]	[about	alcohol].

harry	the	horse
a	high-class	spot	such	as	mindy   s
the	broadway	coppers
the	reason	he	comes	into	the	hot	box
they
three	parties	from	brooklyn

x

arrive(s)
attract(s)
love(s)
sit(s)

   noun	phrases	appear	before	verbs	in	english.   

cs	295:	statistical	nlp	(winter	2017)

5

constituents	and	grammars

grammar
    tells	you	how	the	constituents	can	be	arranged
   
    generate	all,	and	only,	the	possible	sentences	of	the	language
    different	from	meaning:

implicit	knowledge	for	us	(we	often	can   t	tell	why	something	is	wrong)

colorless	green	ideas	sleep	furiously.

    the	words	are	in	the	right	order,
    and	that	ideas	are	green	and	colorless,
    and	that	ideas	sleep,
    and	that	sleeping	is	done	furiously,
    as	opposed	to:	   sleep	green	furiously	ideas	colorless   

cs	295:	statistical	nlp	(winter	2017)

6

uses	of	parsing

[	send	[the	text	message	from	james]	[to	sharon]	]

[	translate	[the	message]	[from	hindi]	[to	english]	]

    grammar	checkers
    dialog	systems
    high	precision	question	answering
    named	entity	recognition
    sentence	compression
    extracting opinions	about	products
   
    helping	linguists	find	data
    machine	translation
    relation	extraction	systems

improved	interaction	in	computer	games

cs	295:	statistical	nlp	(winter	2017)

7

outline

syntactic	parsing

context	free	grammars

parsing:	cky	algorithm

cs	295:	statistical	nlp	(winter	2017)

8

basic	grammar:	regular	expr.

    you	can	capture	individual	words:

(man|dog|cat)

    simple	sentences:

   

   

   

infinite	length?	yes!

    men	(who	like	(cats|dogs))*	cry.

(man|dog|cat)(ate|loves|consumed)(.|food|lunch)

finite	state	
machine

men

s1

cry

start

end

who

s2

like

s3

dogs

cats

but	too	weak	for	english.

cs	295:	statistical	nlp	(winter	2017)

9

context-free	grammars

grammar,	g

terminal	symbols

non-terminal	symbols

rules

grammar	applies	rules	recursively..
if	we	can	construct	the	input	sentence,	it	is	in	the	grammar,	otherwise	not.

cs	295:	statistical	nlp	(winter	2017)

10

example	id18

cs	295:	statistical	nlp	(winter	2017)

11

example	parse	tree

i	prefer	a	morning	flight.

cs	295:	statistical	nlp	(winter	2017)

12

example	parse	tree:	brackets

i	prefer	a	morning	flight.

cs	295:	statistical	nlp	(winter	2017)

13

more	details:	noun	phrases

simple	noun	phrases

np	  propernoun
np	  det nominal

nominal	  noun	|	noun	nominal

complex	noun	phrases

   all	the	morning	flights	from	denver	
to	tampa	leaving	before	10   

cs	295:	statistical	nlp	(winter	2017)

14

recursive	noun	phrases

this	is	the	house

this	is	the	house	that	jack	built

this	is	the	cat	that	lives	in	the	house	that	jack	built

this	is	the	dog	that	chased	the	cat	that	lives	in	the	house	that	jack	built

this	is	the	flea	that	bit	the	dog	that	chased	the	cat	that	lives	in	the	house	the	jack	built

this	is	the	virus	that	infected	the	flea	that	bit	the	dog	that	chased	the	cat	that	lives	in	the	
house	that	jack	built

cs	295:	statistical	nlp	(winter	2017)

15

more	details:	verb	phrases

simple	verb	phrases

vp	  verb
vp	  verb	np
vp	  verb np	pp
vp	  verb pp

disappear
prefer	a	morning	flight
leave	boston	in	the	morning
leave	in	the	morning

but	all	verbs	are	not	the	same!
(this	grammar	overgenerates)

solution:	subcategorize!

sneezed: john	sneezed.
find:
give:
help:
prefer:
told:

please	find	a	flight	to	ny.
give	me	a	cheaper	fare.
can	you	help	me	with	a	flight?
i	prefer	to	leave	earlier.
i	was	told	united	has	a	flight.

cs	295:	statistical	nlp	(winter	2017)

16

types	of	sentences

declarative

s	  np	vp

a	plane	left.

imperative

s	  vp

show	the	plane.

yes/no	questions

s	  aux	np	vp

did	the	plane	leave?

wh-questions

s	  whnp aux	np	vp

when	did	the	plane	leave?

cs	295:	statistical	nlp	(winter	2017)

17

source	of	grammar?

manual

write	symbolic	grammar	(id18	or	often	richer)	and	lexicon

s	   np	vp
np	   (dt)	nn
np	   nn	nns
np	   nnp
vp	   v	np

nn	   interest
nns	   rates
nns	   raises
vbp	   interest
vbz	   rates

noam	chomsky

used	grammar/proof	systems	to	prove	parses	from	words
fed	raises	interest	rates	0.5%	in	effort	to	control	inflation
    minimal	grammar:
    simple	10	rule	grammar:
    real-size	broad-coverage	grammar:

36	parses
592	parses
millions	of	parses

cs	295:	statistical	nlp	(winter	2017)

18

source	of	grammar?

from	data!

the	penn	treebank

building	a	treebank	seems	a	lot	slower	and	less	useful	than	building	a	grammar

but	a	treebank	gives	us	many	things

    reusability	of	the	labor

    many	parsers,	pos	taggers,	etc.
    valuable	resource	for	linguistics

    broad	coverage
    frequencies	and	distributional	information
    a	way	to	evaluate	systems

[marcus	et	al.	1993,	computational	linguistics]

cs	295:	statistical	nlp	(winter	2017)

19

( (s

(np-sbj (dt the) (nn move))
(vp (vbd followed)

(np

(np (dt a) (nn round))
(pp (in of)

(np

(np (jj similar) (nns increases))
(pp (in by)

(np (jj other) (nns lenders)))

(pp (in against)

(np (nnp arizona) (jj real) (nn estate) (nns loans))))))

(, ,)
(s-adv

(np-sbj (-none- *))
(vp (vbg reflecting)

(np

(np (dt a) (vbg continuing) (nn decline))
(pp-loc (in in)

(np (dt that) (nn market)))))))

(. .)))

cs	295:	statistical	nlp	(winter	2017)

20

some	of	the	rules,	with	counts

40717	pp	   	in	np
33803	s	   	np-sbj	vp
22513	np-sbj	   	-none-
21877	np	   	np	pp
20740	np	   	dt	nn
14153	s	   	np-sbj	vp	.
12922	vp	   	to	vp
11881	pp-loc	   	in	np
11467	np-sbj	   	prp
11378	np	   	-none-
11291	np	   	nn
...
989	vp	   	vbg	s
985	np-sbj	   	nn
983	pp-mnr	   	in	np
983	np-sbj	   	dt
969	vp	   	vbn	vp

100	vp	   	vbd	pp-prd
100	prn	   	:	np	:
100	np	   	dt	jjs
100	np-clr	   	nn
99	np-sbj-1	   	dt	nnp
98	vp	   	vbn	np	pp-dir
98	vp	   	vbd	pp-tmp
98	pp-tmp	   	vbg	np
97	vp	   	vbd	advp-tmp	vp
...
10	whnp-1	   	wrb	jj
10	vp	   	vp	cc	vp	pp-tmp
10	vp	   	vp	cc	vp
advp-mnr
10	vp	   	vbz	s	,	sbar-adv
10	vp	   	vbz	s	advp-tmp

4500	rules

for	vp!

cs	295:	statistical	nlp	(winter	2017)

21

evaluating	parses

each	parse	tree	is	represented	by	a	list	of	tuples:

use	this	to	estimate	precision/recall!

cs	295:	statistical	nlp	(winter	2017)

22

evaluating	parses:	example

cs	295:	statistical	nlp	(winter	2017)

23

outline

syntactic	parsing

context	free	grammars

parsing:	cky	algorithm

cs	295:	statistical	nlp	(winter	2017)

24

the	parsing	problem

given	sentence	x and		grammar	g,

recognition

is	sentence	x in	the	grammar?	if	so,	prove	it.
   proof   	is	a	deduction,	valid	parse	tree.

parsing

show	one	or	more	derivations	for	x in	g.

even	with	small	grammars,	brute	force	grows	exponentially!

   book	that	flight   

cs	295:	statistical	nlp	(winter	2017)

25

top	down	parsing

considers	only	valid	trees
but	are	inconsistent	with	the	words!

   book	that	flight   

cs	295:	statistical	nlp	(winter	2017)

26

bottom-up	parsing

   book	that	flight   

builds	only	consistent	trees
but	most	of	them	are	invalid	(don   t	go	anywhere)!

cs	295:	statistical	nlp	(winter	2017)

27

chomsky	normal	form

context	free	grammar	where	all	non-terminals	to	go:
- 2	non-terminals,	or
- a	single	terminal

a	  b	c

d	  w

converting	to	cnf

case	1

case	2

a	  b
b	  c	d
b	  w

a	  c	d
a	  w

a	  b	c	d	e

a	  x	e
x	  y	d
y	  b	c

cs	295:	statistical	nlp	(winter	2017)

28

original	grammar

chomsky	normal	form

cs	295:	statistical	nlp	(winter	2017)

29

dynamic	programming

table[i,j]	=	set	of	all	valid	non-terminals	for	the	constituent	span	(i,j)

base	case

rule:	a	  word[j]
a	should	be	in	table[j-1,j]

recursion

rule:	a	  b	c

a (j-1,j)

word[j]

(i,j)
a

if	you	find	a	k	such	that

b	is	in	table[i,k],	and
c	is	in	table[k,j],	then	a	should	be	in	table[i,j]

b
(i,k)

c
(k,j)

cs	295:	statistical	nlp	(winter	2017)

30

cky	algorithm

book

the

flight through twa

cs	295:	statistical	nlp	(winter	2017)

31

outline

syntactic	parsing

context	free	grammars

parsing:	cky	algorithm

cs	295:	statistical	nlp	(winter	2017)

32

upcoming   

homework

    homework	2	is	due	in	a	week:	february	13,	2017
    homework	1	grades	will	be	available	tonight

project

    proposal	is	due	on	tonight
    only	2	pages

summaries

    paper	summaries:	february	17,	february	28,	march	14
    only	1 page	each

cs	295:	statistical	nlp	(winter	2017)

33

