vector	space	models

prof.	sameer	singh
cs	295:	statistical	nlp
winter	2017

january	19,	2017

based	on	slides	from	jacob	eisenstein,	noah	smith,	mohit bansal,	richard	socher,	and	everyone	else	they	copied	from.

outline

latent	semantic	analysis

vector	models	for	words

reducing	the	dimensions

direct	embeddings

cs	295:	statistical	nlp	(winter	2017)

2

outline

latent	semantic	analysis

vector	models	for	words

reducing	the	dimensions

direct	embeddings

cs	295:	statistical	nlp	(winter	2017)

3

example:	documents

c1:	human	machine	interface	for	abc	computer	applications
c2:	a	survey	of	user	opinion	of	computer	system	response	time
c3:	the	eps	user	interface	management	system
c4:	system	and	human	system	engineering	testing	of	eps
c5:	relation	of	user	perceived	response	time	to	error	measurement

m1:	the	generation	of	random,	binary,	ordered	trees
m2:	the	intersection	graph	of	paths	in	trees
m3:	graph	minors	iv:	widths	of	trees	and	well-quasi-ordering
m4:	graph	minors:	a	survey

cs	295:	statistical	nlp	(winter	2017)

4

from	http://lsa.colorado.edu/papers/dp1.lsaintro.pdf

example:	term-doc	matrix

c1 c2 c3 c4 c5 m1 m2 m3 m4

human
interface
computer
user
system
response
time
eps
survey
trees
graph
minors

cs	295:	statistical	nlp	(winter	2017)

5

problems	with	sparse	vectors

c2:	a	survey	of	user	opinion	of	computer	system	response	time

m4:	graph	minors:	a	survey

c1:	human	machine	interface	
for	abc	computer	applications

cs	295:	statistical	nlp	(winter	2017)

6

example:	distance	matrix

c1 c2 c3 c4 c5 m1 m2 m3 m4

c1
c2
c3
c4
c5
m1
m2
m3
m4

cs	295:	statistical	nlp	(winter	2017)

7

option	2:	svd

cs	295:	statistical	nlp	(winter	2017)

8

latent	semantic	analysis	(lsa)

cs	295:	statistical	nlp	(winter	2017)

9

example:	decomposition

c1 c2 c3 c4 c5 m1 m2 m3 m4

human
interface
computer
user
system
response
time
eps
survey
trees
graph
minors

cs	295:	statistical	nlp	(winter	2017)

10

new	document	vectors

cs	295:	statistical	nlp	(winter	2017)

11

example:	reconstruction

human
interface
computer
user
system
response
time
eps
survey
trees
graph
minors

cs	295:	statistical	nlp	(winter	2017)

12

example:	distance	matrix

cs	295:	statistical	nlp	(winter	2017)

13

outline

latent	semantic	analysis

vector	models	for	words

reducing	the	dimensions

direct	embeddings

cs	295:	statistical	nlp	(winter	2017)

14

let   s	look	at	words

a	bottle	of	tezguino is	on	the	table.
everybody	likes	tezguino.
tezguino makes	you	drunk.
we	make	tezguino out	of	corn.

what	does	tezguino mean?
loud,	motor	oil,	tortillas,	choices,	wine

you	shall	know	a	word	by	the	company	keeps.
(firth,	1957)

cs	295:	statistical	nlp	(winter	2017)

15

term-context	matrix

c1:	a	bottle	of	______	is	on	the	table.
c2:	everybody	likes	______.
c3:	_____	makes	you	drunk.
c4:	we	make	_____	out	of	corn.

c1				c2				c3				c4

tezguino
loud
motor	oil
tortillas
choices
wine

cs	295:	statistical	nlp	(winter	2017)

16

what	is	a	   context   ?

can	be	anything	you	want!
    entire	contents	of	the	sentence
    one	word	before	and	after
    words	in	the	same	sentence
    document	it	appears	in
    many	other	variations   

a	bottle	of	tezguino is	on	the	table.
tezguino makes	you	drunk.
   
i	had	a	fancy	bottle	of	wine and	
got	drunk	last	night!
the	terrible	wine is	on	the	table.

cs	295:	statistical	nlp	(winter	2017)

17

what	is	a	   context   ?

can	be	anything	you	want!
    entire	contents	of	the	sentence

    unlikely	to	occur	again!
    one	word	before	and	after
    words	in	the	same	sentence
    document	id	it	appears	in
    many	other	variations   

a	bottle	of	tezguino is	on	the	table.
tezguino makes	you	drunk.
   
i	had	a	fancy	bottle	of	wine and	
got	drunk	last	night!
the	terrible	wine is	on	the	table.

c1				c2				c3					c4

tezguino

wine

cs	295:	statistical	nlp	(winter	2017)

18

what	is	a	   context   ?

can	be	anything	you	want!
    entire	contents	of	the	sentence
    one	word	before	and	after

    or	n-words

    words	in	the	same	sentence
    document	it	appears	in
    many	other	variations   

a	bottle	of	tezguino is	on	the	table.
tezguino makes	you	drunk.
   
i	had	a	fancy	bottle	of	wine and	
got	drunk	last	night!
the	terrible	wine is	on	the	table.

bottle-of		is-of		makes-you		and-got		the-terrible		is-on

tezguino

wine

cs	295:	statistical	nlp	(winter	2017)

19

what	is	a	   context   ?

a	bottle	of	tezguino is	on	the	table.
tezguino makes	you	drunk.
   
i	had	a	fancy	bottle	of	wine and	
got	drunk	last	night!
the	terrible	wine is	on	the	table.

bottle				table				you			drunk				fancy				night					terrible

can	be	anything	you	want!
    entire	contents	of	the	sentence
    one	word	before	and	after
    words	in	the	same	sentence
    filter:	nouns	and	verbs?
    bag	of	words	in	a	window

    document	it	appears	in
    many	other	variations   

tezguino

wine

cs	295:	statistical	nlp	(winter	2017)

20

what	is	a	   context   ?

can	be	anything	you	want!
    entire	contents	of	the	sentence
    one	word	before	and	after
    words	in	the	same	sentence
    document	it	appears	in

    term-document	matrix!
   
latent	semantic	analysis

    many	other	variations   

a	bottle	of	tezguino is	on	the	table.
tezguino makes	you	drunk.
   
i	had	a	fancy	bottle	of	wine and	
got	drunk	last	night!
the	terrible	wine is	on	the	table.

d1					d2				d3					d4

tezguino
table
bottle
drunk
wine

cs	295:	statistical	nlp	(winter	2017)

21

pointwise	mutual	information

raw	counts	are	not	good

    skewed	towards	common	words/contexts
    many	of	them	are	not	informative

   

is,	the,	it,	they,	   

pmi(w,c)

    how	much	more	likely	is	w	to	occur	in	c,	than	just	randomly?

cs	295:	statistical	nlp	(winter	2017)

22

outline

latent	semantic	analysis

vector	models	for	words

reducing	the	dimensions

direct	embeddings

cs	295:	statistical	nlp	(winter	2017)

23

option	1:	revisiting	id91

cs	295:	statistical	nlp	(winter	2017)

24

hierarchical	id91

cs	295:	statistical	nlp	(winter	2017)

25

example

cs	295:	statistical	nlp	(winter	2017)

26

brown	clusters	for	twitter

http://www.cs.cmu.edu/~ark/tweetnlp/cluster_viewer.html

cs	295:	statistical	nlp	(winter	2017)

27

option	2:	svd

cs	295:	statistical	nlp	(winter	2017)

28

example	word	projection

cs	295:	statistical	nlp	(winter	2017)

29

problem	with	svd	&	id91

computational	complexity

    svd:	o(mn2)
    id91:	o(knm)	per	iteration,	or	o(n3)
    but,	n	can	be	100,000!

   one	shot   

    difficult	to	add	new	documents	or	words
    cannot	work	with	streaming	data

cs	295:	statistical	nlp	(winter	2017)

30

outline

latent	semantic	analysis

vector	models	for	words

reducing	the	dimensions

direct	embeddings

cs	295:	statistical	nlp	(winter	2017)

31

predict	surrounding	words

a								bottle										of													tezguino
u
v

is													on														the														table.

cs	295:	statistical	nlp	(winter	2017)

32

estimating	the	word	vectors

cs	295:	statistical	nlp	(winter	2017)

33

similar	meaning	=	close

cs	295:	statistical	nlp	(winter	2017)

34

similar	meaning	=	close

https://siddhant7.github.io/vector-representation-of-words/

cs	295:	statistical	nlp	(winter	2017)

35

vectors	   know   	gender

male	:	female	::	king	:

queen

king	- male	+	female

queen

https://siddhant7.github.io/vector-representation-of-words/

cs	295:	statistical	nlp	(winter	2017)

36

they	   know   	tenses!

walking	:	walked	::	swimming	: swam

swimming	    walking	+	walked swam

https://siddhant7.github.io/vector-representation-of-words/

cs	295:	statistical	nlp	(winter	2017)

37

they	   know   	facts!

country	    capital	+		spain

madrid

https://siddhant7.github.io/vector-representation-of-words/

cs	295:	statistical	nlp	(winter	2017)

38

upcoming   

homework

    homework	1	is	up!
    no	more	material	will	be	covered
    due:	january	26,	2017

project

    project	pitch	is	due	january	23,	2017!
    start	assembling	teams	now
    tons	of	datasets	on	the	   projects   	page	on	website

cs	295:	statistical	nlp	(winter	2017)

39

