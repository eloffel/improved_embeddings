data intensive linguistics

lecture 17

machine translation (iv): phrase-based models

philipp koehn

3 march 2008

philipp koehn

emnlp lecture 17

3 march 2008

word alignment

1

    notion of word alignment valuable
    shared task at naacl 2003 and acl 2005 workshops

philipp koehn

emnlp lecture 17

3 march 2008

marianodabaunabofetadaalabrujaverdemarywitchgreentheslapnotdidword alignment with ibm models

2

    ibm models create a many-to-one mapping

    words are aligned using an alignment function
    a function may return the same value for di   erent input

(one-to-many mapping)

    a function can not return multiple values for one input

(no many-to-one mapping)

    but we need many-to-many mappings

philipp koehn

emnlp lecture 17

3 march 2008

symmetrizing word alignments

3

    intersection of giza++ bidirectional alignments

philipp koehn

emnlp lecture 17

3 march 2008

marianodabaunabofetadaalabrujaverdemarywitchgreentheslapnotdidmarianodabaunabofetadaalabrujaverdemarywitchgreentheslapnotdidmarianodabaunabofetadaalabrujaverdemarywitchgreentheslapnotdidenglish to spanishspanish to englishintersectionsymmetrizing word alignments

4

    grow additional alignment points [och and ney, compling2003]

philipp koehn

emnlp lecture 17

3 march 2008

marianodabaunabofetadaalabrujaverdemarywitchgreentheslapnotdid5

growing heuristic

grow-diag-final(e2f,f2e):

neighboring = ((-1,0),(0,-1),(1,0),(0,1),(-1,-1),(-1,1),(1,-1),(1,1))
alignment = intersect(e2f,f2e);
grow-diag(); final(e2f); final(f2e);

grow-diag():

iterate until no new points added

for english word e = 0 ... en

for foreign word f = 0 ... fn

if ( e aligned with f )

for each neighboring point ( e-new, f-new ):

if ( ( e-new not aligned and f-new not aligned ) and

( e-new, f-new ) in union( e2f, f2e ) )

add alignment point ( e-new, f-new )

final(a):

for english word e-new = 0 ... en

for foreign word f-new = 0 ... fn

if ( ( e-new not aligned or f-new not aligned ) and

( e-new, f-new ) in alignment a )
add alignment point ( e-new, f-new )

philipp koehn

emnlp lecture 17

3 march 2008

phrase-based translation

6

    foreign input is segmented in phrases

    any sequence of words, not necessarily linguistically motivated

    each phrase is translated into english
    phrases are reordered

philipp koehn

emnlp lecture 17

3 march 2008

morgen  fliege  ich   nach kanada  zur konferenztomorrow  i  will fly   to the conference  in canadaphrase-based translation model

7

    major components of phrase-based model

    phrase translation model   (f|e)
    reordering model   length(e)
    language model plm(e)

    bayes rule

argmaxep(e|f) = argmaxep(f|e)p(e)

    sentence f is decomposed into i phrases   f i
    decomposition of   (f|e)
1|  ei
  (   f i

= argmaxe  (f|e)plm(e)  length(e)
iy

1 =   f1, ...,   fi

  (   fi|  ei)d(ai     bi   1)

1) =

philipp koehn

emnlp lecture 17

3 march 2008

i=1

8

advantages of phrase-based translation

    many-to-many translation can handle non-compositional phrases
    use of local context in translation
    the more data, the longer phrases can be learned

philipp koehn

emnlp lecture 17

3 march 2008

phrase translation table

    phrase translations for den vorschlag
  (e|f)
0.6227
0.1068
0.0341
0.0250
0.0227
0.0205
0.0159
0.0159

english
the proposal
   s proposal
a proposal
the idea
this proposal
proposal
of the proposal
the proposals

english
the suggestions
the proposed
the motion
the idea of
the proposal ,
its proposal
it
...

9

  (e|f)
0.0114
0.0114
0.0091
0.0091
0.0068
0.0068
0.0068
...

philipp koehn

emnlp lecture 17

3 march 2008

how to learn the phrase translation table?

10

    start with the word alignment:

    collect all phrase pairs that are consistent with the word alignment

philipp koehn

emnlp lecture 17

3 march 2008

marianodabaunabofetadaalabrujaverdemarywitchgreentheslapnotdidconsistent with word alignment

11

    consistent with the word alignment :=

phrase alignment has to contain all alignment points for all covered words

(e, f)     bp    

   ei     e : (ei, fj)     a     fj     f
and    fj     f : (ei, fj)     a     ei     e

philipp koehn

emnlp lecture 17

3 march 2008

marianodabamaryslapnotdidmarianodabamaryslapnotdidxconsistentinconsistentmarianodabamaryslapnotdidxinconsistentword alignment induced phrases

12

(maria, mary), (no, did not), (slap, daba una bofetada), (a la, the), (bruja, witch), (verde, green)

philipp koehn

emnlp lecture 17

3 march 2008

marianodabaunabofetadaalabrujaverdemarywitchgreentheslapnotdidword alignment induced phrases

13

(maria, mary), (no, did not), (slap, daba una bofetada), (a la, the), (bruja, witch), (verde, green),

(maria no, mary did not), (no daba una bofetada, did not slap), (daba una bofetada a la, slap the),
(bruja verde, green witch)

philipp koehn

emnlp lecture 17

3 march 2008

marianodabaunabofetadaalabrujaverdemarywitchgreentheslapnotdidword alignment induced phrases

14

(maria, mary), (no, did not), (slap, daba una bofetada), (a la, the), (bruja, witch), (verde, green),

(maria no, mary did not), (no daba una bofetada, did not slap), (daba una bofetada a la, slap the),
(bruja verde, green witch), (maria no daba una bofetada, mary did not slap),
(no daba una bofetada a la, did not slap the), (a la bruja verde, the green witch)

philipp koehn

emnlp lecture 17

3 march 2008

marianodabaunabofetadaalabrujaverdemarywitchgreentheslapnotdidword alignment induced phrases

15

(maria, mary), (no, did not), (slap, daba una bofetada), (a la, the), (bruja, witch), (verde, green),

(maria no, mary did not), (no daba una bofetada, did not slap), (daba una bofetada a la, slap the),
(bruja verde, green witch), (maria no daba una bofetada, mary did not slap),
(no daba una bofetada a la, did not slap the), (a la bruja verde, the green witch),
(maria no daba una bofetada a la, mary did not slap the),
(daba una bofetada a la bruja verde, slap the green witch)

philipp koehn

emnlp lecture 17

3 march 2008

marianodabaunabofetadaalabrujaverdemarywitchgreentheslapnotdidword alignment induced phrases (5)

16

(maria, mary), (no, did not), (slap, daba una bofetada), (a la, the), (bruja, witch), (verde, green),

(maria no, mary did not), (no daba una bofetada, did not slap), (daba una bofetada a la, slap the),
(bruja verde, green witch), (maria no daba una bofetada, mary did not slap),
(no daba una bofetada a la, did not slap the), (a la bruja verde, the green witch),
(maria no daba una bofetada a la, mary did not slap the), (daba una bofetada a la bruja verde,
slap the green witch), (no daba una bofetada a la bruja verde, did not slap the green witch),
(maria no daba una bofetada a la bruja verde, mary did not slap the green witch)

philipp koehn

emnlp lecture 17

3 march 2008

marianodabaunabofetadaalabrujaverdemarywitchgreentheslapnotdidid203 distribution of phrase pairs

17

    we need a id203 distribution   (f|e) over the collected phrase pairs
    possible choices

    relative frequency of collected phrases:   (f|e) = count(f ,e)
f count(f ,e)
    or, conversely   (e|f)
    use lexical translation probabilities

p

philipp koehn

emnlp lecture 17

3 march 2008

reordering

18

    monotone translation

    do not allow any reordering
    worse translations
    limiting reordering (to movement over max. number of words) helps
    distance-based reordering cost

    moving a foreign phrase over n words: cost   n

    lexicalized reordering model

philipp koehn

emnlp lecture 17

3 march 2008

lexicalized reordering models

19

    three orientation types: monotone, swap, discontinuous
    id203 p(swap|e, f) depends on foreign (and english) phrase involved

[from koehn et al., 2005, iwslt]

philipp koehn

emnlp lecture 17

3 march 2008

mmsddf1f2f3f4f5f6f7e1e2e3e4e5e6learning lexicalized reordering models

20

    orientation type is learned during phrase extractions
    alignment point to the top left (monotone) or top right (swap)?
    for more, see [tillmann, 2003] or [koehn et al., 2005]

[from koehn et al., 2005, iwslt]

philipp koehn

emnlp lecture 17

3 march 2008

??id148

21

    ibm models provided mathematical

justi   cation for factoring components

together

plm    pt m    pd

    these may be weighted
t m    p  d

lm    p  t m
p  lm

d

    many components pi with weights   i

    q
    logq

i = exp(p
i =p

i p  i

i p  i

i   ilog(pi))
i   ilog(pi)

philipp koehn

emnlp lecture 17

3 march 2008

knowledge sources

22

    many di   erent knowledge sources useful

    language model
    reordering (distortion) model
    phrase translation model
    word translation model
    word count
    phrase count
    drop word feature
    phrase pair frequency
    additional language models
    additional features

philipp koehn

emnlp lecture 17

3 march 2008

23

set feature weights

    contribution of components pi determined by weight   i
    methods

    manual setting of weights: try a few, take best
    automate this process

    learn weights

    set aside a development corpus
    set the weights,

so that optimal translation performance on this

development corpus is achieved

    requires automatic scoring method (e.g., id7)

philipp koehn

emnlp lecture 17

3 march 2008

learn feature weights

24

philipp koehn

emnlp lecture 17

3 march 2008

modelgeneraten-best listscore translationsfindfeature weightsthat move upgood translations123456123456365241changefeature weightsdiscriminative vs. generative models

25

    generative models

    translation process is broken down to steps
    each step is modeled by a id203 distribution
    each id203 distribution is estimated from the data by maximum

likelihood

    discriminative models

    model consist of a number of features (e.g. the language model score)
    each feature has a weight, measuring its value for judging a translation as

correct

    feature weights are optimized on development data, so that the system

output matches correct translations as close as possible

philipp koehn

emnlp lecture 17

3 march 2008

discriminative training

26

    training set (development set)

    di   erent from original training set
    small (maybe 1000 sentences)
    must be di   erent from test set

    current model translates this development set
    n-best list of translations (n=100, 10000)
    translations in n-best list can be scored

    feature weights are adjusted
    n-best list generation and feature weight adjustment repeated for a number

of iterations

philipp koehn

emnlp lecture 17

3 march 2008

learning task

27

    task:    nd weights, so that feature vector of the correct translations ranked

   rst

philipp koehn

emnlp lecture 17

3 march 2008

1  mary not give slap witch green .              -17.2  -5.2  -7       12  mary not slap the witch green .               -16.3  -5.7  -7       13  mary not give slap of the green witch .       -18.1  -4.9  -9       1    4  mary not give of green witch .                -16.5  -5.1  -8       15  mary did not slap the witch green .           -20.1  -4.7  -8       16  mary did not slap green witch .               -15.5  -3.2  -7       17  mary not slap of the witch green .            -19.2  -5.3  -8       18  mary did not give slap of witch green .       -23.2  -5.0  -9       19  mary did not give slap of the green witch .   -21.8  -4.4 -10       1          10 mary did slap the witch green .               -15.5  -6.9  -7       1 11 mary did not slap the green witch .           -17.4  -5.3  -8       0        12 mary did slap witch green .                   -16.9  -6.9  -6       1                13 mary did slap the green witch .               -14.3  -7.1  -7       114 mary did not slap the of green witch .        -24.2  -5.3  -9       1         translation                                    lm     tm   wp      serrank translation                                    feature vector      15 mary did not give slap the witch green .      -25.2  -5.5  -9       1methods to adjust feature weights

28

    maximum id178 [och and ney, acl2002]

    match expectation of feature values of model and data

    minimum error rate training [och, acl2003]
    try to rank best translations    rst in n-best list
    can be adapted for various error metrics, even id7

    ordinal regression [shen et al., naacl2004]
    separate k worst from the k best translations

philipp koehn

emnlp lecture 17

3 march 2008

