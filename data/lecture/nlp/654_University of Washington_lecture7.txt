natural language processing (csep 517):

predicate-argument and id152

noah smith

c(cid:13) 2017

university of washington

nasmith@cs.washington.edu

may 8, 2017

1 / 113

to-do list

(cid:73) online quiz: due sunday
(cid:73) jurafsky and martin (2016); (jurafsky and martin, 2008, ch. 18), steedman

(1996)

(cid:73) a4 due may 14 (sunday)

2 / 113

semantics vs. syntax

syntactic theories and representations focus on the question of which strings in v    are
in the language.

semantics is about understanding what a string in v    means.

sidestepping a lengthy and philosophical discussion of what    meaning    is, we   ll
consider two meaning representations:

(cid:73) predicate-argument structures, also known as event frames
(cid:73) truth conditions represented in    rst-order logic

3 / 113

motivating example: who did what to who(m)?

(cid:73) warren bought the stock.
(cid:73) they sold the stock to warren.
(cid:73) the stock was bought by warren.
(cid:73) the purchase of the stock by warren surprised no one.
(cid:73) warren   s stock purchase surprised no one.

4 / 113

motivating example: who did what to who(m)?

(cid:73) warren bought the stock.
(cid:73) they sold the stock to warren.
(cid:73) the stock was bought by warren.
(cid:73) the purchase of the stock by warren surprised no one.
(cid:73) warren   s stock purchase surprised no one.

5 / 113

motivating example: who did what to who(m)?

(cid:73) warren bought the stock.
(cid:73) they sold the stock to warren.
(cid:73) the stock was bought by warren.
(cid:73) the purchase of the stock by warren surprised no one.
(cid:73) warren   s stock purchase surprised no one.

6 / 113

motivating example: who did what to who(m)?

(cid:73) warren bought the stock.
(cid:73) they sold the stock to warren.
(cid:73) the stock was bought by warren.
(cid:73) the purchase of the stock by warren surprised no one.
(cid:73) warren   s stock purchase surprised no one.

7 / 113

motivating example: who did what to who(m)?

(cid:73) warren bought the stock.
(cid:73) they sold the stock to warren.
(cid:73) the stock was bought by warren.
(cid:73) the purchase of the stock by warren surprised no one.
(cid:73) warren   s stock purchase surprised no one.

in this buying/purchasing event/situation, warren played the role of the buyer, and
there was some stock that played the role of the thing purchased.

8 / 113

motivating example: who did what to who(m)?

(cid:73) warren bought the stock.
(cid:73) they sold the stock to warren.
(cid:73) the stock was bought by warren.
(cid:73) the purchase of the stock by warren surprised no one.
(cid:73) warren   s stock purchase surprised no one.

in this buying/purchasing event/situation, warren played the role of the buyer, and
there was some stock that played the role of the thing purchased.

also, there was presumably a seller, only mentioned in one example.

9 / 113

motivating example: who did what to who(m)?

(cid:73) warren bought the stock.
(cid:73) they sold the stock to warren.
(cid:73) the stock was bought by warren.
(cid:73) the purchase of the stock by warren surprised no one.
(cid:73) warren   s stock purchase surprised no one.

in this buying/purchasing event/situation, warren played the role of the buyer, and
there was some stock that played the role of the thing purchased.

also, there was presumably a seller, only mentioned in one example.

in some examples, a separate    event    involving surprise did not occur.

10 / 113

semantic roles: breaking

(cid:73) jesse broke the window.
(cid:73) the window broke.
(cid:73) jesse is always breaking things.
(cid:73) the broken window testi   ed to jesse   s malfeasance.

11 / 113

semantic roles: breaking

(cid:73) jesse broke the window.
(cid:73) the window broke. ?
(cid:73) jesse is always breaking things.
(cid:73) the broken window testi   ed to jesse   s malfeasance.

a breaking event has a breaker and a breakee.

12 / 113

semantic roles: eating

(cid:73) eat!
(cid:73) we ate dinner.
(cid:73) we already ate.
(cid:73) the pies were eaten up quickly.
(cid:73) our gluttony was complete.

13 / 113

semantic roles: eating

(cid:73) eat! (you, listener) ?
(cid:73) we ate dinner.
(cid:73) we already ate. ?
(cid:73) the pies were eaten up quickly. ?
(cid:73) our gluttony was complete. ?

an eating event has an eater and food, neither of which needs to be mentioned
explicitly.

14 / 113

abstraction?

breaker ?

= eater

15 / 113

abstraction?

breaker ?

= eater

both are actors that have some causal responsibility for changes in the world around
them.

16 / 113

abstraction?

breaker ?

= eater

both are actors that have some causal responsibility for changes in the world around
them.

breakee ?

= food

17 / 113

abstraction?

breaker ?

= eater

both are actors that have some causal responsibility for changes in the world around
them.

breakee ?

= food

both are greatly a   ected by the event, which    happened to    them.

18 / 113

thematic roles
(jurafsky and martin, 2016, with modi   cations)

agent
experiencer
force
theme
result

content

instrument

beneficiary
source
goal

the waiter spilled the soup.
john has a headache.
the wind blows debris from the mall into our yards.
jesse broke the window
the city built a regulation-size baseball diamond .
mona asked,     you met mary ann at a supermarket?    
he poached cat   sh, stunning them with a shocking device .
ann callahan makes hotel reservations for her boss .
i    ew in from boston .
i drove to portland .

19 / 113

verb alternation examples: breaking and giving

breaking:

(cid:73) agent/subject; theme/object; instrument/ppwith
(cid:73) instrument/subject; theme/object
(cid:73) theme/subject

giving:

(cid:73) agent/subject; goal/object; theme/second-object
(cid:73) agent/subject; theme/object; goal/ppto

levin (1993) codi   ed english verbs into classes that share patterns (e.g., verbs of
throwing: throw/kick/pass).

20 / 113

remarks

(cid:73) fillmore (1968), among others, argued for semantic roles in linguistics.

21 / 113

remarks

(cid:73) fillmore (1968), among others, argued for semantic roles in linguistics.
(cid:73) by now, it should be clear that the expressiveness of nl (at least english) makes

semantic analysis rather distinct from syntax.

22 / 113

remarks

(cid:73) fillmore (1968), among others, argued for semantic roles in linguistics.
(cid:73) by now, it should be clear that the expressiveness of nl (at least english) makes

semantic analysis rather distinct from syntax.
(cid:73) general challenges to analyzing semantic roles:

(cid:73) what are the predicates/events/frames/situations?
(cid:73) what are the roles/participants for each one?
(cid:73) what algorithms can accurately identify and label all of them?

23 / 113

id14

input: a sentence x

output:

(cid:73) a collection of predicates, each consisting of:

(cid:73) a label, sometimes called the frame
(cid:73) a span
(cid:73) a set of arguments, each consisting of:

(cid:73) a label, usually called the role
(cid:73) a span

in principle, spans might have gaps, though in most conventions they usually do not.

24 / 113

the importance of lexicons

like syntax, any annotated dataset is the product of extensive development of
conventions.

many conventions are speci   c to particular words, and this information is codi   ed in
structured objects called lexicons.

you should think of every semantically annotated dataset as both the data and the
lexicon.

we consider two examples.

25 / 113

propbank
(palmer et al., 2005)

(cid:73) frames are verb senses (later extended, though)
(cid:73) lexicon maps verb-sense-speci   c roles onto a small set of abstract roles (e.g.,

arg0, arg1, etc.)

(cid:73) annotated on top of the id32, so that arguments are always

constituents.

26 / 113

fall.01 (move downward)

(cid:73) arg1: logical subject, patient, thing falling
(cid:73) arg2: extent, amount fallen
(cid:73) arg3: starting point
(cid:73) arg4: ending point
(cid:73) argm-loc: medium

(cid:73) sales fell to $251.2 million from $278.8 million.
(cid:73) the average junk bond fell by 4.2%.
(cid:73) the meteor fell through the atmosphere, crashing into palo alto.

27 / 113

fall.01 (move downward)

(cid:73) arg1: logical subject, patient, thing falling
(cid:73) arg2: extent, amount fallen
(cid:73) arg3: starting point
(cid:73) arg4: ending point
(cid:73) argm-loc: medium

(cid:73) sales fell to $251.2 million from $278.8 million.
(cid:73) the average junk bond fell by 4.2%.
(cid:73) the meteor fell through the atmosphere, crashing into palo alto.

28 / 113

fall.01 (move downward)

(cid:73) arg1: logical subject, patient, thing falling
(cid:73) arg2: extent, amount fallen
(cid:73) arg3: starting point
(cid:73) arg4: ending point
(cid:73) argm-loc: medium

(cid:73) sales fell to $251.2 million from $278.8 million.
(cid:73) the average junk bond fell by 4.2%.
(cid:73) the meteor fell through the atmosphere, crashing into palo alto.

29 / 113

fall.01 (move downward)

(cid:73) arg1: logical subject, patient, thing falling
(cid:73) arg2: extent, amount fallen
(cid:73) arg3: starting point
(cid:73) arg4: ending point
(cid:73) argm-loc: medium

(cid:73) sales fell to $251.2 million from $278.8 million.
(cid:73) the average junk bond fell by 4.2%.
(cid:73) the meteor fell through the atmosphere, crashing into palo alto.

30 / 113

fall.01 (move downward)

(cid:73) arg1: logical subject, patient, thing falling
(cid:73) arg2: extent, amount fallen
(cid:73) arg3: starting point
(cid:73) arg4: ending point
(cid:73) argm-loc: medium

(cid:73) sales fell to $251.2 million from $278.8 million.
(cid:73) the average junk bond fell by 4.2%.
(cid:73) the meteor fell through the atmosphere, crashing into palo alto.

31 / 113

fall.01 (move downward)

(cid:73) arg1: logical subject, patient, thing falling
(cid:73) arg2: extent, amount fallen
(cid:73) arg3: starting point
(cid:73) arg4: ending point
(cid:73) argm-loc: medium

(cid:73) sales fell to $251.2 million from $278.8 million.
(cid:73) the average junk bond fell by 4.2%.
(cid:73) the meteor fell through the atmosphere, crashing into palo alto.

32 / 113

fall.08 (fall back, rely on in emergency)

(cid:73) arg0: thing falling back
(cid:73) arg1: thing fallen back on

(cid:73) world bank president paul wolfowitz has fallen back on his last resort.

33 / 113

fall.08 (fall back, rely on in emergency)

(cid:73) arg0: thing falling back
(cid:73) arg1: thing fallen back on

(cid:73) world bank president paul wolfowitz has fallen back on his last resort.

34 / 113

fall.08 (fall back, rely on in emergency)

(cid:73) arg0: thing falling back
(cid:73) arg1: thing fallen back on

(cid:73) world bank president paul wolfowitz has fallen back on his last resort.

35 / 113

fall.10 (fall for a trick; be fooled by)

(cid:73) arg1: the fool
(cid:73) arg2: the trick

(cid:73) many people keep falling for the idea that lowering taxes on the rich bene   ts

everyone.

36 / 113

fall.10 (fall for a trick; be fooled by)

(cid:73) arg1: the fool
(cid:73) arg2: the trick

(cid:73) many people keep falling for the idea that lowering taxes on the rich bene   ts

everyone.

37 / 113

fall.10 (fall for a trick; be fooled by)

(cid:73) arg1: the fool
(cid:73) arg2: the trick

(cid:73) many people keep falling for the idea that lowering taxes on the rich bene   ts

everyone.

38 / 113

framenet
(baker et al., 1998)

(cid:73) frames can be any content word (verb, noun, adjective, adverb)
(cid:73) about 1,000 frames, each with its own roles
(cid:73) both frames and roles are hierarchically organized
(cid:73) annotated without syntax, so that arguments can be anything

https://framenet.icsi.berkeley.edu

39 / 113

change position on a scale

(cid:73) item: entity that has a position on the scale
(cid:73) attribute: scalar property that the item possesses
(cid:73) difference: distance by which an item changes its position
(cid:73) final state: item   s state after the change
(cid:73) final value: position on the scale where item ends up
(cid:73) initial state: item   s state before the change
(cid:73) initial value: position on the scale from which the item moves
(cid:73) value range: portion of the scale along which values of attribute    uctuate
(cid:73) duration: length of time over which the change occurs
(cid:73) speed: rate of change of the value
(cid:73) group: the group in which an item changes the value of an attribute

40 / 113

framenet example

attacks

on

civilians
over
change position on a scale

decreased

the

last

four months

item

duration

the attribute is left un   lled but is understood from context (i.e.,    frequency   ).

41 / 113

change position on a scale

verbs: advance, climb, decline, decrease, diminish, dip, double, drop, dwindle, edge,
explode, fall,    uctuate, gain, grow, increase, jump, move, mushroom, plummet, reach,
rise, rocket, shift, skyrocket, slide, soar, swell, swing, triple, tumble

nouns: decline, decrease, escalation, explosion, fall,    uctuation, gain, growth, hike,
increase, rise, shift, tumble

adverb: increasingly

42 / 113

change position on a scale

event

birth scenario . . .

change position on a scale

. . . waking up

change of temperature

proliferating in number

(birth scenario also inherits from sexual reproduction scenario.)

43 / 113

id14 tasks

the paper that started it all: gildea and jurafsky (2002) used framenet lexicon
(which includes prototypes, not really a corpus).

(cid:73) when framenet started releasing corpora, the task was reformulated. example

open-source system: semafor (das et al., 2014).

44 / 113

id14 tasks

the paper that started it all: gildea and jurafsky (2002) used framenet lexicon
(which includes prototypes, not really a corpus).

(cid:73) when framenet started releasing corpora, the task was reformulated. example

open-source system: semafor (das et al., 2014).

the propbank corpus is used directly for training/testing.

45 / 113

id14 tasks

the paper that started it all: gildea and jurafsky (2002) used framenet lexicon
(which includes prototypes, not really a corpus).

(cid:73) when framenet started releasing corpora, the task was reformulated. example

open-source system: semafor (das et al., 2014).

the propbank corpus is used directly for training/testing.

conference on computational natural language learning (conll) shared task in
2004, 2005, 2008, 2009, all propbank-based.

(cid:73) in 2008 and 2009, the task was cast as a kind of id33.
(cid:73) in 2009, seven languages were included in the task.

46 / 113

methods

boils down to labeling spans (with frames and roles).

it   s mostly about features.

47 / 113

example: path features

np-sbj

dt

the

nnp

nnp

nnp

san

francisco

examiner

s

vbd

issued

vp

np

pp-tmp

dt

jj

nn

in

nn

np-tmp

a

special

edition

around

noon

nn

yesterday

48 / 113

example: path features

np-sbj

dt

the

nnp

nnp

nnp

san

francisco

examiner

s

vbd

issued

vp

np

pp-tmp

dt

jj

nn

in

nn

np-tmp

a

special

edition

around

noon

nn

yesterday

path from

np-sbj

to issued: np   s   vp   vbd

the san francisco examiner

49 / 113

example: path features

np-sbj

dt

the

nnp

nnp

nnp

san

francisco

examiner

s

vbd

issued

vp

np

pp-tmp

dt

jj

nn

in

nn

np-tmp

a

special

edition

around

noon

nn

yesterday

path from

np

to issued: np   vp   vbd

a special edition

50 / 113

methods: beyond features

the span-labeling decisions interact a lot!

(cid:73) presence of a frame increases the expectation of certain roles
(cid:73) roles for the same predicate shouldn   t overlap
(cid:73) some roles are mutually exclusive or require each other (e.g.,    resemble   )

51 / 113

methods: beyond features

the span-labeling decisions interact a lot!

(cid:73) presence of a frame increases the expectation of certain roles
(cid:73) roles for the same predicate shouldn   t overlap
(cid:73) some roles are mutually exclusive or require each other (e.g.,    resemble   )

ensuring well-formed outputs:

(cid:73) using syntax as a sca   old allows e   cient prediction; you   re essentially labeling the

parse tree (toutanova et al., 2008).

(cid:73) others have formulated the problem as constrained, discrete optimization

(punyakanok et al., 2008).

(cid:73) also greedy methods (bj  orkelund et al., 2010) and joint methods for syntactic

and semantic dependencies (henderson et al., 2013).

52 / 113

methods: beyond features

the span-labeling decisions interact a lot!

(cid:73) presence of a frame increases the expectation of certain roles
(cid:73) roles for the same predicate shouldn   t overlap
(cid:73) some roles are mutually exclusive or require each other (e.g.,    resemble   )

ensuring well-formed outputs:

(cid:73) using syntax as a sca   old allows e   cient prediction; you   re essentially labeling the

parse tree (toutanova et al., 2008).

(cid:73) others have formulated the problem as constrained, discrete optimization

(punyakanok et al., 2008).

(cid:73) also greedy methods (bj  orkelund et al., 2010) and joint methods for syntactic

and semantic dependencies (henderson et al., 2013).

current work:

(cid:73) some recent attempts to merge framenet and propbank have shown promise

(fitzgerald et al., 2015; kshirsagar et al., 2015)

53 / 113

related problems in    relational    semantics

(cid:73) coreference resolution: which mentions (within or across texts) refer to the

same entity or event?

(cid:73) entity linking: ground such mentions in a structured knowledge base (e.g.,

wikipedia)

(cid:73) id36: characterize the relation among speci   c mentions

information extraction: transform text into a structured id99

(cid:73) classical ie starts with a prede   ned schema
(cid:73)    open    ie includes the automatic construction of the schema; see

http://ai.cs.washington.edu/projects/open-information-extraction

54 / 113

general remarks

criticisms of id14:

(cid:73) semantic roles are just    syntax++    since they don   t allow much in the way of

reasoning (e.g., id53).

55 / 113

general remarks

criticisms of id14:

(cid:73) semantic roles are just    syntax++    since they don   t allow much in the way of

reasoning (e.g., id53).

(cid:73) lexicon building is slow and requires expensive expertise. can we do this for every

(sub)language?

56 / 113

general remarks

criticisms of id14:

(cid:73) semantic roles are just    syntax++    since they don   t allow much in the way of

reasoning (e.g., id53).

(cid:73) lexicon building is slow and requires expensive expertise. can we do this for every

(sub)language?

we   ve now had a taste of two branches of semantics:

(cid:73) lexical semantics (e.g., supersense tagging)
(cid:73) relational semantics (e.g., id14)

57 / 113

general remarks

criticisms of id14:

(cid:73) semantic roles are just    syntax++    since they don   t allow much in the way of

reasoning (e.g., id53).

(cid:73) lexicon building is slow and requires expensive expertise. can we do this for every

(sub)language?

we   ve now had a taste of two branches of semantics:

(cid:73) lexical semantics (e.g., supersense tagging)
(cid:73) relational semantics (e.g., id14)

next up, a third:

(cid:73) id152

58 / 113

bridging the gap between language and the world

in order to link nl to a knowledge base, we might want to design a formal way to
represent meaning.
desiderata for a meaning representation language:

59 / 113

bridging the gap between language and the world

in order to link nl to a knowledge base, we might want to design a formal way to
represent meaning.
desiderata for a meaning representation language:

(cid:73) represent the state of the world, i.e., a knowledge base

60 / 113

bridging the gap between language and the world

in order to link nl to a knowledge base, we might want to design a formal way to
represent meaning.
desiderata for a meaning representation language:

(cid:73) represent the state of the world, i.e., a knowledge base
(cid:73) query the knowledge base (e.g., verify that a statement is true, or answer a

question)

61 / 113

bridging the gap between language and the world

in order to link nl to a knowledge base, we might want to design a formal way to
represent meaning.
desiderata for a meaning representation language:

(cid:73) represent the state of the world, i.e., a knowledge base
(cid:73) query the knowledge base (e.g., verify that a statement is true, or answer a

question)

(cid:73) handle ambiguity, vagueness, and non-canonical forms

(cid:73)    i wanna eat someplace that   s close to uw   
(cid:73)    something not too spicy   

62 / 113

bridging the gap between language and the world

in order to link nl to a knowledge base, we might want to design a formal way to
represent meaning.
desiderata for a meaning representation language:

(cid:73) represent the state of the world, i.e., a knowledge base
(cid:73) query the knowledge base (e.g., verify that a statement is true, or answer a

question)

(cid:73) handle ambiguity, vagueness, and non-canonical forms

(cid:73)    i wanna eat someplace that   s close to uw   
(cid:73)    something not too spicy   

(cid:73) support id136 and reasoning
(cid:73)    can karen eat at schultzy   s?   

63 / 113

bridging the gap between language and the world

in order to link nl to a knowledge base, we might want to design a formal way to
represent meaning.
desiderata for a meaning representation language:

(cid:73) represent the state of the world, i.e., a knowledge base
(cid:73) query the knowledge base (e.g., verify that a statement is true, or answer a

question)

(cid:73) handle ambiguity, vagueness, and non-canonical forms

(cid:73)    i wanna eat someplace that   s close to uw   
(cid:73)    something not too spicy   

(cid:73) support id136 and reasoning
(cid:73)    can karen eat at schultzy   s?   

eventually (but not today):

(cid:73) deal with non-literal meanings
(cid:73) expressiveness across a wide range of subject matter

64 / 113

a (tiny) world model

(cid:73) domain: adrian, brook, chris, donald, schultzy   s sausage, din tai fung,

banana leaf, american, chinese, thai

(cid:73) property: din tai fung has a long wait, schultzy   s is noisy; alice, bob, and

charles are human

(cid:73) relations: schultzy   s serves american, din tai fung serves chinese, and banana

leaf serves thai

simple questions are easy:

(cid:73) is schultzy   s noisy?
(cid:73) does din tai fung serve thai?

65 / 113

a (tiny) world model

(cid:73) domain: adrian, brook, chris, donald, schultzy   s sausage, din tai fung,

banana leaf, american, chinese, thai
a, b, c, d, ss, dtf , bl , am, ch, th

(cid:73) property: din tai fung has a long wait, schultzy   s is noisy; alice, bob, and

charles are human
longwait = {dtf }, noisy = {ss}, human = {a, b, c}

(cid:73) relations: schultzy   s serves american, din tai fung serves chinese, and banana

leaf serves thai
serves = {(ss, am), (dtf , ch), (bl , th)}, likes = {(a, ss), (a, dtf ), . . .}

simple questions are easy:

(cid:73) is schultzy   s noisy?
(cid:73) does din tai fung serve thai?

66 / 113

a quick tour of id85

(cid:73) term: a constant (ss) or a variable
(cid:73) formula: de   ned inductively . . .

(cid:73) if r is an n-ary relation and t1, . . . , tn are terms, then r(t1, . . . , tn) is a formula.
(cid:73) if    is a formula, then its negation,     , is a formula.
(cid:73) if    and    are formulas, then binary logical connectives can be used to create

formulas:
(cid:73)          
(cid:73)          
(cid:73)          
(cid:73)          

(cid:73) if    is a formula and v is a variable, then quanti   ers can be used to create formulas:

(cid:73) universal quanti   er:    v,   
(cid:73) existential quanti   er:    v,   

note: leaving out functions, because we don   t need them in a single lecture on fol
for nl.

67 / 113

translating between fol and nl

1. schultzy   s is not loud

2. some human likes chinese

3. if a person likes thai, then they aren   t friends with donald
4.    x, restaurant(x)     (longwait(x)       likes(a, x))
5.    x,   y,  likes(x, y)
6.    y,   x,  likes(x, y)

68 / 113

translating between fol and nl

1. schultzy   s is not loud

2. some human likes chinese

3. if a person likes thai, then they aren   t friends with donald
4.    x, restaurant(x)     (longwait(x)       likes(a, x))
5.    x,   y,  likes(x, y)
6.    y,   x,  likes(x, y)

  noisy(ss)

69 / 113

translating between fol and nl

1. schultzy   s is not loud

2. some human likes chinese

  noisy(ss)
   x, human(x )     likes(x, ch)

3. if a person likes thai, then they aren   t friends with donald
4.    x, restaurant(x)     (longwait(x)       likes(a, x))
5.    x,   y,  likes(x, y)
6.    y,   x,  likes(x, y)

70 / 113

translating between fol and nl

1. schultzy   s is not loud

2. some human likes chinese

  noisy(ss)
   x, human(x )     likes(x, ch)

3. if a person likes thai, then they aren   t friends with donald

   x, human(x )     likes(x, th)       friends(x, d)

4.    x, restaurant(x)     (longwait(x)       likes(a, x))
5.    x,   y,  likes(x, y)
6.    y,   x,  likes(x, y)

71 / 113

translating between fol and nl

1. schultzy   s is not loud

2. some human likes chinese

  noisy(ss)
   x, human(x )     likes(x, ch)

3. if a person likes thai, then they aren   t friends with donald

   x, human(x )     likes(x, th)       friends(x, d)

4.    x, restaurant(x)     (longwait(x)       likes(a, x))

every restaurant has a long wait or is disliked by adrian.

5.    x,   y,  likes(x, y)
6.    y,   x,  likes(x, y)

72 / 113

translating between fol and nl

1. schultzy   s is not loud

2. some human likes chinese

  noisy(ss)
   x, human(x )     likes(x, ch)

3. if a person likes thai, then they aren   t friends with donald

   x, human(x )     likes(x, th)       friends(x, d)

4.    x, restaurant(x)     (longwait(x)       likes(a, x))

every restaurant has a long wait or is disliked by adrian.

5.    x,   y,  likes(x, y)

everybody has something they don   t like.

6.    y,   x,  likes(x, y)

73 / 113

translating between fol and nl

1. schultzy   s is not loud

2. some human likes chinese

  noisy(ss)
   x, human(x )     likes(x, ch)

3. if a person likes thai, then they aren   t friends with donald

   x, human(x )     likes(x, th)       friends(x, d)

4.    x, restaurant(x)     (longwait(x)       likes(a, x))

every restaurant has a long wait or is disliked by adrian.

5.    x,   y,  likes(x, y)

everybody has something they don   t like.

6.    y,   x,  likes(x, y)

there exists something that nobody likes.

74 / 113

logical semantics
(montague, 1970)

the denotation of a nl sentence is the set of conditions that must hold in the (model)
world for the sentence to be true.

every restaurant has a long wait or adrian doesn   t like it.

is true if and only if

   x, restaurant(x)     (longwait(x)       likes(a, x))

is true.

this is sometimes called the logical form of the nl sentence.

75 / 113

the principle of compositionality

the meaning of a nl phrase is determined by the meanings of its sub-phrases.

76 / 113

the principle of compositionality

the meaning of a nl phrase is determined by the meanings of its sub-phrases.

i.e., semantics is derived from syntax.

77 / 113

the principle of compositionality

the meaning of a nl phrase is determined by the meanings of its sub-phrases.

i.e., semantics is derived from syntax.

we need a way to express semantics of phrases, and compose them together!

78 / 113

  -calculus

(much more powerful than what we   ll see today; ask your pl professor!)

informally, two extensions:

(cid:73)   -abstraction is another way to    scope    variables.

(cid:73) if    is a fol formula and v is a variable, then   v.   is a   -term, meaning: an

unnamed function from values (of v) to formulas (usually involving v)

(cid:73) application of such functions: if we have   v.   and   , then [  v.  ](  ) is a

formula.

(cid:73) it can be reduced by substituting    in for every instance of v in   .

79 / 113

  -calculus

(much more powerful than what we   ll see today; ask your pl professor!)

informally, two extensions:

(cid:73)   -abstraction is another way to    scope    variables.

(cid:73) if    is a fol formula and v is a variable, then   v.   is a   -term, meaning: an

unnamed function from values (of v) to formulas (usually involving v)

(cid:73) application of such functions: if we have   v.   and   , then [  v.  ](  ) is a

formula.

(cid:73) it can be reduced by substituting    in for every instance of v in   .

example:
  x.likes(x, dtf ) maps things to statements that they like din tai fung

80 / 113

  -calculus

(much more powerful than what we   ll see today; ask your pl professor!)

informally, two extensions:

(cid:73)   -abstraction is another way to    scope    variables.

(cid:73) if    is a fol formula and v is a variable, then   v.   is a   -term, meaning: an

unnamed function from values (of v) to formulas (usually involving v)

(cid:73) application of such functions: if we have   v.   and   , then [  v.  ](  ) is a

formula.

(cid:73) it can be reduced by substituting    in for every instance of v in   .

example:
[  x.likes(x, dtf )](c) reduces to likes(c, dtf )

81 / 113

  -calculus

(much more powerful than what we   ll see today; ask your pl professor!)

informally, two extensions:

(cid:73)   -abstraction is another way to    scope    variables.

(cid:73) if    is a fol formula and v is a variable, then   v.   is a   -term, meaning: an

unnamed function from values (of v) to formulas (usually involving v)

(cid:73) application of such functions: if we have   v.   and   , then [  v.  ](  ) is a

formula.

(cid:73) it can be reduced by substituting    in for every instance of v in   .

example:
  x.  y.friends(x, y) maps things x to maps of things y to statements that x and y are
friends

82 / 113

  -calculus

(much more powerful than what we   ll see today; ask your pl professor!)

informally, two extensions:

(cid:73)   -abstraction is another way to    scope    variables.

(cid:73) if    is a fol formula and v is a variable, then   v.   is a   -term, meaning: an

unnamed function from values (of v) to formulas (usually involving v)

(cid:73) application of such functions: if we have   v.   and   , then [  v.  ](  ) is a

formula.

(cid:73) it can be reduced by substituting    in for every instance of v in   .

example:
[  x.  y.friends(x, y)](b) reduces to   y.friends(b, y)

83 / 113

  -calculus

(much more powerful than what we   ll see today; ask your pl professor!)

informally, two extensions:

(cid:73)   -abstraction is another way to    scope    variables.

(cid:73) if    is a fol formula and v is a variable, then   v.   is a   -term, meaning: an

unnamed function from values (of v) to formulas (usually involving v)

(cid:73) application of such functions: if we have   v.   and   , then [  v.  ](  ) is a

formula.

(cid:73) it can be reduced by substituting    in for every instance of v in   .

example:
[[  x.  y.friends(x, y)](b)](a) reduces to [  y.friends(b, y)](a), which reduces to
friends(b, a)

84 / 113

semantic attachments to id18

(cid:73) nnp     adrian {a}
(cid:73) vbz     likes {  f.  y.   xf (x)     likes(y, x)}
(cid:73) jj     expensive {  x.expensive(x)}
(cid:73) nns     restaurants {  x.restaurant(x)}
(cid:73) np     nnp {nnp.sem}
(cid:73) np     jj nns {  x.jj.sem(x)     nns.sem(x)}
(cid:73) vp     vbz np {vbz.sem(np.sem)}
(cid:73) s     np vp {vp.sem(np.sem)}

85 / 113

example

s

vbz

likes

np

nnp

adrian

vp

np

jj

nns

expensive

restaurants

86 / 113

example

s : vp.sem(np.sem)

np : nnp.sem

vp : vbz.sem(np.sem)

nnp : a

adrian

vbz : . . .

np :   v.jj.sem(v)     nns.sem(v)

likes

jj :   z.expensive(z)

nns :   w.restaurant(w)

expensive

restaurants

87 / 113

example

s : vp.sem(np.sem)

np : nnp.sem

vp : vbz.sem(np.sem)

nnp : a

adrian

vbz : . . .

np :   v.expensive(v)     restaurant(v)

likes

jj :   z.expensive(z)

nns :   w.restaurant(w)

expensive

        z.expensive(z)
       (v)    
(cid:124)
(cid:125)

(cid:123)(cid:122)

restaurants

        w.restaurant(w)
       (v)
(cid:125)
(cid:124)

(cid:123)(cid:122)

jj.sem

nns.sem

  v.

88 / 113

example

...

vp : vbz.sem(np.sem)

vbz :   f.  y.   xf (x)     likes(y, x)

np :   v.expensive(v)     restaurant(v)

likes

expensive restaurants

89 / 113

example

...

vp :   y.   x, expensive(x)     restaurant(x)     likes(y, x)

vbz :   f.  y.   xf (x)     likes(y, x)

np :   v.expensive(v)     restaurant(v)

likes

        f.  y.   xf (x)     likes(y, x)
(cid:124)
(cid:125)

(cid:123)(cid:122)

expensive restaurants

              v.expensive(v)     restaurant(v)
      
(cid:124)
(cid:125)

(cid:123)(cid:122)

vbz.sem

  y.   x [  v.expensive(v)     restaurant(v)] (x)     likes(y, x)
  y.   x, expensive(x)     restaurant(x)     likes(y, x)

np.sem

90 / 113

example

s : vp.sem(np.sem)

np : nnp.sem

vp :   y.   x, expensive(x)     restaurant(x)     likes(y, x)

nnp : a

adrian

likes expensive restaurants

91 / 113

example

s : vp.sem(np.sem)

vp :   y.   x, expensive(x)     restaurant(x)     likes(y, x)

likes expensive restaurants

np : a

nnp : a

adrian

92 / 113

example

s :    x, expensive(x)     restaurant(x)     likes(a, x)

vp :   y.   x, expensive(x)     restaurant(x)     likes(y, x)

np : a

nnp : a

likes expensive restaurants

adrian

        y.   x, expensive(x)     restaurant(x)     likes(y, x)
             a(cid:124)(cid:123)(cid:122)(cid:125)
(cid:125)
(cid:124)

(cid:123)(cid:122)

      

np.sem

vp.sem

   x, expensive(x)     restaurant(x)     likes(a, x)

93 / 113

graph-based representations
id15 (banarescu et al., 2013)

   the boy wants to visit new york city.   
designed for (1) annotation-ability and (2) eventual use in machine translation.

94 / 113

want-01boyvisit-01cityname   new      york      city   arg0arg1arg0arg1nameop1op2op3id35
(steedman, 2000)

id35 is a grammatical formalism that is well-suited for tying together syntax and
semantics.

formally, it is more powerful than id18   it can represent some of the context-sensitive
languages (which we do not have time to de   ne formally).

95 / 113

id35 types

instead of the    n     of id18s, id35s can have an in   nitely large set of structured
categories (called types).

(cid:73) primitive types: typically s, np, n, and maybe more
(cid:73) complex types, built with    slashes,    for example:

(cid:73) s/np is    an s, except that it lacks an np to the right   
(cid:73) s\np is    an s, except that it lacks an np to its left   
(cid:73) (s\np)/np is    an s, except that it lacks an np to its right, and its left   

you can think of complex types as functions, e.g., s/np maps nps to ss.

96 / 113

id35 combinators

instead of the production rules of id18s, id35s have a very small set of generic
combinators that tell us how we can put types together.

convention writes the rule di   erently from id18: x y     z means that x and y
combine to form a z (the    parent    in the tree).

97 / 113

application combinator

forward (x/y

y     x) and backward (y x\y     x)

98 / 113

application combinator

forward (x/y

y     x) and backward (y x\y     x)

np

np/n

n

the

dog

99 / 113

application combinator

forward (x/y

y     x) and backward (y x\y     x)

np

np/n

n

the

n/n

n

yellow

dog

100 / 113

application combinator

forward (x/y

y     x) and backward (y x\y     x)

s

np

s\np

np/n

n

(s\np)/np

np

the

dog

bit

john

101 / 113

conjunction combinator

x and x     x

np

np

and np

cats

dogs

102 / 113

conjunction combinator

x and x     x

s

s\np

np

john

s\np

and

s\np

(s\np)/np

np

(s\np)/np

np

ate

anchovies

drank

beer

103 / 113

conjunction combinator

x and x     x

np

np/n

n

the

dog

s

s\np

(s\np)/np

(s\np)/np

and

(s\np)/np

bit

infected

np

john

104 / 113

composition combinator

forward (x/y

y /z     x/z) and backward (y \z x\y     x\z)

s

s\np

(s\np)/np

np

i

(s\np)/(s\np)

(s\np)/np

would

prefer

np

olives

105 / 113

composition combinator

forward (x/y

y /z     x/z) and backward (y \z x\y     x\z)

np

i

s

s\np

(s\np)/(s\np)

s \np

would

(s\np)/np

np

prefer

olives

106 / 113

type-raising combinator

forward (x     y /(y \x)) and backward (x     y \(y /x))
s

s/np

np

chocolate

s/np

and

s/np

s/(s\np)

(s\np)/np

s/(s\np)

(s\np)/np

np

i

love

np

hates

karen

107 / 113

back to semantics

each combinator also tells us what to do with the semantic attachments.

(cid:73) forward application: x/y : f y : g     x : f (g)
(cid:73) forward composition: x/y : f y /z : g     x/z :   x.f (g(x))
(cid:73) forward type-raising: x : g     y /(y \x) :   f.f (g)

108 / 113

id35 lexicon

most of the work is done in the lexicon!

syntactic and semantic information is much more formal here.

(cid:73) slash categories de   ne where all the syntactic arguments are expected to be
(cid:73)   -expressions de   ne how the expected arguments get    used    to build up a fol

expression

extensive discussion: carpenter (1997)

109 / 113

some topics we don   t have time for

(cid:73) tasks, evaluations, annotated datasets (e.g., id35bank, hockenmaier and

steedman, 2007)

(cid:73) learning for id29 (zettlemoyer and collins, 2005) and id35 parsing

(clark and curran, 2004a)

(cid:73) using id35 to represent other kinds of semantics (e.g., predicate-argument

structures; lewis and steedman, 2014)

(cid:73) integrating continuous representations in id29 (lewis and steedman,

2013; krishnamurthy and mitchell, 2013)

(cid:73) id55 (clark and curran, 2004b) and making id29 e   cient

(lewis and steedman, 2014)

(cid:73) grounding meaning in visual (or other perceptual) experience

110 / 113

references i

collin f. baker, charles j. fillmore, and john b. lowe. the berkeley framenet project. in proc. of

acl-coling, 1998.

laura banarescu, claire bonial, shu cai, madalina georgescu, kira gri   tt, ulf hermjakob, kevin knight,

philipp koehn, martha palmer, and nathan schneider. id15 for sembanking. in
proc. of the linguistic annotation workshop and interoperability with discourse, 2013.

anders bj  orkelund, bernd bohnet, love hafdell, and pierre nugues. a high-performance syntactic and semantic

dependency parser. in proc. of coling, 2010.

bob carpenter. type-logical semantics. mit press, 1997.

stephen clark and james r. curran. parsing the wsj using id35 and id148. in proc. of acl, 2004a.

stephen clark and james r. curran. the importance of id55 for wide-coverage id35 parsing. in proc.

of coling, 2004b.

dipanjan das, desai chen, andr  e f. t. martins, nathan schneider, and noah a. smith. frame-semantic

parsing. computational linguistics, 40(1):9   56, 2014.

charles j. fillmore. the case for case. in bach and harms, editors, universals in linguistic theory. holt,

rinehart, and winston, 1968.

nicholas fitzgerald, oscar t  ackstr  om, kuzman ganchev, and dipanjan das. id14 with neural

network factors. in proc. of emnlp, 2015.

daniel gildea and daniel jurafsky. automatic labeling of semantic roles. computational linguistics, 24(3):

245   288, 2002.

111 / 113

references ii

james henderson, paola merlo, ivan titov, and gabriele musillo. multilingual joint parsing of syntactic and

semantic dependencies with a latent variable model. computational linguistics, 39(4):949   998, 2013.

julia hockenmaier and mark steedman. id35bank: a corpus of id35 derivations and dependency structures

extracted from the id32. computational linguistics, 33(3):355   396, 2007.

daniel jurafsky and james h. martin. speech and language processing: an introduction to natural language

processing, computational linguistics, and id103. prentice hall, second edition, 2008.

daniel jurafsky and james h. martin. id14 and argument structure (draft chapter), 2016.

url https://web.stanford.edu/~jurafsky/slp3/22.pdf.

jayant krishnamurthy and tom mitchell. vector space id29: a framework for compositional vector

space models. 2013.

meghana kshirsagar, sam thomson, nathan schneider, jaime carbonell, noah a. smith, and chris dyer.

frame-id14 with heterogeneous annotations. in proc. of acl, 2015.

beth levin. english verb classes and alternations: a preliminary investigation. university of chicago press, 1993.

mike lewis and mark steedman. combining distributional and logical semantics. transactions of the

association for computational linguistics, 1:179   192, 2013.

mike lewis and mark steedman. a* id35 parsing with a supertag-factored model. in proc. of emnlp, 2014.

richard montague. universal grammar. theoria, 36:373   398, 1970.

martha palmer, daniel gildea, and paul kingsbury. the proposition bank: an annotated corpus of semantic

roles. computational linguistics, 31(1):71   105, 2005.

112 / 113

references iii

vasin punyakanok, dan roth, and wen-tau yih. the importance of syntactic parsing and id136 in semantic

role labeling. computational linguistics, 34(2):257   287, 2008.

mark steedman. a very short introduction to id35, 1996. url

http://www.inf.ed.ac.uk/teaching/courses/id86/readings/id35intro.pdf.

mark steedman. the syntactic process. mit press, 2000.

kristina toutanova, aria haghighi, and christopher d. manning. a global joint model for semantic role

labeling. computational linguistics, 34(2):161   191, 2008.

luke zettlemoyer and michael collins. learning to map sentences to logical form: structured classi   cation with

probabilistic categorial grammars. in proc. of uai, 2005.

113 / 113

