cs11-747 neural networks for nlp 
conditioned generation

graham neubig

https://phontron.com/class/nn4nlp2017/

site

language models

    language models are generative models of text

s ~ p(x)

   the malfoys!    said hermione. 

harry was watching him. he looked like madame maxime. when she strode 
up the wrong staircase to visit himself.   

   i   m afraid i   ve definitely been suspended from power, no chance         indeed?    
said snape. he put his head back behind them and read groups as they crossed 
a corner and fluttered down onto their ink lamp, and picked up his spoon. the 
doorbell rang. it was a lot cleaner down in london.

text credit: max deutsch (https://medium.com/deep-writing/)

conditioned language models
    not just generate text, generate text according to 
some speci   cation

input x

structured data

english
document
utterance
image
speech

output y (text)
nl description

japanese

task

nl generation

translation

short description

summarization

response

response generation

text

transcript

image captioning
id103

formulation and modeling

calculating the id203 of 

a sentence
iyi=1

p (xi | x1, . . . , xi 1)
next word

context

p (x) =

conditional language 

models
jyj=1

p (y |x) =

p (yj | x, y1, . . . , yj 1)
added context!

(one type of) language model 

(mikolov et al. 2011)
this

hate

i

<s>

movie

lstm

lstm

lstm

lstm

lstm

predict

i

predict
hate

predict
this

predict
movie

predict
</s>

(one type of) conditional language model 
encoder

(sutskever et al. 2014)

kono

eiga

ga

kirai

</s>

lstm

lstm

lstm

lstm

lstm

i

hate

this

movie

lstm

lstm

lstm

lstm

argmax
hate

argmax

i
decoder

argmax
this

argmax
movie

argmax
</s>

how to pass hidden state?
    initialize decoder w/ encoder (sutskever et al. 2014)

encoder

decoder
    transform (can be different dimensions)

encoder

transform

decoder

    input at every time step (kalchbrenner & blunsom 2013)

decoder

decoder

decoder

encoder

methods of generation

the generation problem

    we have a model of p(y|x), how do we use it to 

generate a sentence? 

    two methods: 

    sampling: try to generate a random sentence 

according to the id203 distribution. 

    argmax: try to generate the sentence with the 

highest id203.

ancestral sampling

    randomly generate words one-by-one.   

while yj-1 !=    </s>   : 
  yj ~ p(yj | x, y1,    , yj-1)

    an exact method for sampling from p(x), no further 

work needed.

   
   
   
greedy search

    one by one, pick the single highest-id203 word

while yj-1 !=    </s>   : 
  yj = argmax p(yj | x, y1,    , yj-1)

    not exact, real problems:

    will often generate the    easy    words    rst 

    will prefer multiple common words to one rare word

id125

    instead of picking one high-id203 word, 

maintain several paths

    some in reading materials, more in a later class

let   s try it out! 

enc_dec.py

model ensembling

ensembling

    combine predictions from multiple models

<s>

<s>

lstm1

lstm2

predict1

predict2

i

    why? 

    multiple models make somewhat uncorrelated errors 
    models tend to be more uncertain when they are about to make errors 
    smooths over idiosyncrasies of the model

linear interpolation

    take a weighted average of the m model probabilities

p (yj | x, y1, . . . , yj 1) =

mxm=1

pm(yj | x, y1, . . . , yj 1)p (m | x, y1, . . . , yj 1)
id203 according 

id203 of 

to model m

model m

    second term often set to uniform distribution 1/m

log-linear interpolation

    weighted combination of log probabilities, normalize

p (yj | x, y1, . . . , yj 1) =

softmax  mxm=1

 m(x, y1, . . . , yj 1) log pm(yj | x, y1, . . . , yj 1)!

normalize

interpolation coef   cient 

for model m

log id203 

of model m

    interpolation coef   cient often set to uniform distribution 1/m

linear or log linear?

    think of it in logic! 
    linear:    logical or    

    the interpolated model likes any choice that a model gives a 

high id203 

    use models with models that capture different traits 
    necessary when any model can assign zero id203 

    log linear:    logical and    

    interpolated model only likes choices where all models agree 
    use when you want to restrict possible answers

parameter averaging

    problem: ensembling means we have to use m 
models at test time, increasing our time/memory 
complexity 

    parameter averaging is a cheap way to get some 

good effects of ensembling 

    basically, write out models several times near the 

end of training, and take the average of parameters

ensemble distillation 
(e.g. kim et al. 2016)

    problem: parameter averaging only works for models 

within the same run 

    knowledge distillation trains a model to copy the 

ensemble 
    speci   cally, it tries to match the description over 

predicted words 

    why? we want the model to make the same mistakes as 

an ensemble 

    shown to increase accuracy notably

stacking

    what if we have two very different models where 

prediction of outputs is done in very different ways? 

    e.g. a word-by-word translation model and 
character-by-character translation model 

    stacking uses the output of one system in 

calculating features for another system

how do we evaluate?

basic evaluation paradigm

    use parallel test set 

    use system to generate translations 

    compare target translations w/ reference

human evaluation

    ask a human to do evaluation

    final goal, but slow, expensive, and sometimes inconsistent

id7

    works by comparing id165 overlap w/ reference

    pros: easy to use, good for measuring system improvement 
    cons: often doesn   t match human eval, bad for comparing 

very different systems

meteor

    like id7 in overall principle, with many other 
tricks: consider paraphrases, reordering, and 
function word/content word difference 

    pros: generally signi   cantly better than id7, 

esp. for high-resource languages 

    cons: requires extra resources for new languages 

(although these can be made automatically), and 
more complicated

perplexity

    calculate the perplexity of the words in the held-out 

set without doing generation 

    pros: naturally solves multiple-reference problem! 
    cons: doesn   t consider decoding or actually 

generating output. 

    may be reasonable for problems with lots of 

ambiguity.

what do we condition on?

from structured data 

(e.g. wen et al 2015)

    when you say    id86    to 

an old-school nlper, it means this

from input + labels 
(e.g. zhou and neubig 2017)

    for example, word + morphological tags -> in   ected word

    other options: politeness/gender in translation, etc.

from images 
(e.g. karpathy et al. 2015)

    input is image features, output is text

other auxiliary information

    name of a recipe + ingredients -> recipe (kiddon 

et al. 2016) 

    ted talk description -> ted talk (hoang et al. 

2016) 

    etc. etc.

questions?

