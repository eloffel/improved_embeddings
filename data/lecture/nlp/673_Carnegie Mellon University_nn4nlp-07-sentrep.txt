cs11-747 neural networks for nlp 

using/evaluating sentence 

representations

graham neubig

https://phontron.com/class/nn4nlp2017/

site

sentence representations

    we can create a vector or sequence of vectors 

from a sentence 

this is an example

this is an example

obligatory quote!
   you can   t cram the meaning of a whole %&!$ing 

sentence into a single $&!*ing vector!    

    ray mooney

how do we use/evaluate   
sentence representations?
    sentence classi   cation 

    paraphrase identi   cation 

    semantic similarity 

    entailment 

    retrieval

goal for today

    introduce tasks/id74
    introduce common data sets
    introduce methods, and particularly state of the art 

results

sentence classi   cation

sentence classi   cation

    classify sentences according to various traits 

    topic, sentiment, subjectivity/objectivity, etc.

i   hate   this  movie

i   love   this   movie

very good 

good 
neutral 
bad 

very bad

very good 

good 
neutral 
bad 

very bad

model overview (review)

i

hate

this movie

lookup

lookup

lookup

lookup

some complicated 
function to extract 
combination features 

(usually a id98)

scores

probs

softmax

data example:   

stanford sentiment treebank 

(socher et al. 2013)

    in addition to standard tags, each constituent tagged with a sentiment value

paraphrase identi   cation

paraphrase identi   cation 

(dolan and brockett 2005)

    identify whether a and b mean the same thing

charles o. prince, 53, was named as mr. weill   s successor.

mr. weill   s longtime con   dant, charles o. prince, 53, was 

named as his successor. 

    note: exactly the same thing is too restrictive, so 

use a loose sense of similarity

data example:    

microsoft research paraphrase corpus 
    construction procedure 

(dolan and brockett 2005)

    crawl large news corpus 
    identify sentences that are similar automatically using 

heuristics or classi   er 

    have raters determine whether they are in fact similar 

(67% were) 

    corpus is high quality but small, 5,800 sentences 
    c.f. other corpora based on translation, image captioning

models for paraphrase 

detection (1)

    calculate vector representation 

    feed vector representation into classi   er

this is an example

this is another example

classi   er

yes/no

model example:   

skip-thought vectors 

(kiros et al. 2015)

    general method for sentence representation 

    unsupervised training: predict surrounding sentences 

on large-scale data (using encoder-decoder) 

    use resulting representation as sentence representation

    train id28 on [|u-v|; u*v] (component-wise)

models for paraphrase 

detection (2)

    calculate multiple-vector representation, and 

combine to make a decision

this is an example

this is an example

classi   er

yes/no

model example: convolutional features   
+ matrix-based pooling (yin and schutze 2015)

model example: paraphrase detection 

w/ discriminative embeddings 

(ji and eisenstein 2013)

    perform matrix 

factorization of word/
context vectors 

    weight word/context 

vectors based on 
discriminativeness

    also add features regarding surface match
    current state-of-the-art on msrpc

semantic similarity

semantic similarity/relatedness 
    do two sentences mean something similar?

(marelli et al. 2014)

    like paraphrase identi   cation, but with shades of gray.

data example: sick dataset 

(marelli et al. 2014)

    procedure to create sentences 

    start with short    ickr/video description sentences
    normalize sentences (11 transformations such as 

active(cid:15511)passive, replacing w/ synonyms, etc.) 

    create opposites (insert negation, invert determiners, 

replace words w/ antonyms) 

    scramble words

    finally ask humans to measure semantic relatedness 
on 1-5 likert scale of    completely unrelated - very related   

evaluation procedure

    input two sentences into model, calculate score 

    measure correlation of the machine score with 

human score (e.g. pearson   s correlation)

model example:   

siamese lstm architecture   

(mueller and thyagarajan 2016)

    use siamese lstm architecture with e^-l1 as a similarity metric

this is an example

this is another example

similarity

[0,1]

e ||h1 h2||1

    simple model! good results due to engineering? 

including pre-training, using pre-trained word 
embeddings, etc. 

    results in best reported accuracies for sick task

id123

id123 

(dagan et al. 2006, marelli et al. 2014)
    entailment: if a is true, then b is true (c.f. paraphrase, 

where opposite is also true) 
    the woman bought a sandwich for lunch   

    the woman bought lunch 

    contradiction: if a is true, then b is not true 
    the woman bought a sandwich for lunch   
    the woman did not buy a sandwich 
    neutral: cannot say either of the above 

    the woman bought a sandwich for lunch   

    the woman bought a sandwich for dinner

stanford natural language id136 dataset 

data example:   

(bowman et al. 2015)

    data created from flickr captions 
    crowdsource creation of one entailed, neutral, and 

contradicted caption for each caption 

    verify the captions with 5 judgements, 89% 

agreement between annotator and    gold    label 
    also, expansion to multiple genres: multinli

model example: multi-perspective 

matching for nli (wang et al. 2017)

    encode, aggregate 
information in both 
directions, encode 
one more time, predict 

    strong results on snli

    lots of other examples on snli web site:   

https://nlp.stanford.edu/projects/snli/

interesting result: 

entailment     generalize 

(conneau et al. 2017)

    skip-thought vectors are unsupervised training
    simply: can supervised training for a task such as 

id136 learn generalizable embeddings? 

    task is more dif   cult and requires capturing 

nuance     yes? 

    data is much smaller     no? 
    answer: yes, generally better

retrieval

retrieval idea

    given an input sentence,    nd something that 

matches 
    text     text (huang et al. 2013) 
    text     image (socher et al. 2014) 
    anything to anything really!

basic idea

    first, encode entire target database into vectors 

    encode source query into vector 

    find vector with minimal distance
db
he ate some things
my database entry
this is another example

source

this is an example

a first attempt at training
    try to get the score of the correct answer higher 

than the other answers

this is an example

he ate some things
my database entry

this is another example

0.6
-1.0
0.4

bad

margin-based training

    just    better    is not good enough, want to exceed 

by a margin (e.g. 1)

this is an example

he ate some things
my database entry

this is another example

0.6
-1.0
0.8

bad

negative sampling

    the database is too big, so only use a small 

portion of the database as negative samples

this is an example

he ate some things
my database entry

this is another example

x

0.6

0.8

id168 in equations
l(x   , y   , s) =xx2s

max(0, 1 + s(x, y   )   s(x   , y   ))
correct 
score

negative 
samples

incorrect score 

plus one

correct 
input

correct 
output

evaluating retrieval 

accuracy

    recall@x:    is the correct answer in the top x 

choices?    

    mean average precision: area under the precision 

recall curve for all queries

let   s try it out 
(on text-to-text) 
lstm-retrieval.py

ef   cient training

    ef   ciency improved when using mini-batch 

training

    sample a mini-batch, calculate representations for 

all inputs and outputs 

    use other elements of the minibatch as negative 

samples

bidirectional loss

    calculate the hinge loss in both directions 
    gives a bit of extra training signal
    free computationally (when combined with mini-

batch training)

ef   cient retrieval

    again, the database may be too big to retrieve, use 

approximate nearest neighbor search 

    example: locality sensitive hashing

image credit: https://micvog.com/2013/09/08/storm-   rst-story-detection/

data example:   

flickr8k id162   

(hodosh et al. 2013)

    input text, output image 

    8000 images x 5 captions each 

    gathered by asking amazon mechanical turkers to 

generate captions

questions?

