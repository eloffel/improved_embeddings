cs11-747 neural networks for nlp 

models of dialog and 

conversation

graham neubig

https://phontron.com/class/nn4nlp2017/

site

types of dialog

    who is talking? 

    human-human 

    human-computer 

    why are they talking? 

    task driven 

    chat

models of chat

two paradigms

    generation-based models 

    take input, generate output 

    good if you want to be creative 

    retrieval-based models 

    take input,    nd most appropriate output 

    good if you want to be safe

generation-based models 

(ritter et al. 2011)

    train phrase-based machine translation system to perform 

translation from utterance to response 

    lots of    ltering, etc., to make sure that the extracted translation 

rules are reliable

neural models for dialog 
response generation 

(sordoni et al. 2015, sheng et al. 2015, vinyals and le 2015)

    like other 

translation tasks, 
dialog response 
generation can be 
done with 
encoder-decoders 

    sheng et al. 

(2015) present 
simplest model, 
translating from 
previous 
utterance

problem 1: dialog more 

dependent on global coherence
    considering only a single previous utterance will lead to 

locally coherent but globally incoherent output 

    necessary to consider more context! (sordoni et al. 2015)

    contrast to mt, where context sometimes is (matsuzaki et 

al. 2015) and sometimes isn   t (jean et al. 2015) helpful

one solution: use standard 
architecture w/ more context

    sordoni et al. (2015) consider one additional previous context 

utterance concatenated together 

    vinyals et al. (2015) just concatenate together all previous utterances 

and hope an id56 an learn

hierarchical encoder-

decoder model (serban et al. 2016)

    also have utterance-level id56 track overall dialog state

discourse-level vae model   

(zhao et al. 2017)

    encode entire previous dialog context as latent variable in vae 

    also meta-information such as dialog acts

also, bag-of-words loss

problem 2: dialog allows 

much more varied responses

    for translation, there is lexical variation but content remains 

the same 

    for dialog, content will also be different! (e.g. li et al. 2016)

diversity promoting objective 

for conversation (li et al. 2016)

    basic idea: we want responses that are likely given the 

context, unlikely otherwise 

    method: subtract weighted unconditioned log id203 from 

conditioned id203 (calculated only on    rst few words)

diversity is a problem for 

evaluation!

    translation uses id7 score; while imperfect, not horrible 

    in dialog, id7 shows very little correlation (liu et al. 2016)

using multiple references with 

human evaluation scores (galley et al. 2015)

    retrieve good-looking responses, perform human 

evaluation, up-weight good ones, down-weight bad ones

learning to evaluate

    use context, true response, and actual response to learn a 

regressor that predicts goodness (lowe et al. 2017) 

    important: similar to model, but has access to reference!

    adversarial evaluation: try to determine whether 

response is true or fake (li et al. 2017) 

    one caveat from mt: learnable metrics tend to over   t

problem 3: dialog agents 
should have personality

    if we train on all of our data, our agent will be a 
mish-mash of personalities (e.g. li et al. 2016)   

    we would like our agents to be consistent!

   
   
   
   
personality infused dialog 

(mairesse et al. 2007)

    train a generation 

system with 
controllable    knobs    
based on personality 
traits 

    e.g. extraversion: 

    non-neural, but well 
done and perhaps 
applicable

persona-based neural 
dialog model (li et al. 2017)

    model each speaker in embedding space

    also model who the speaker is speaking to in 

speaker-addressee model

retrieval-based models

dialog response retrieval

    idea: many things can be answered 

with template 

    simply    nd most relevant response 

out of existing ones in corpus

template responses

image credit: google

retrieval-based chat 

(lee et al. 2009)

    basic idea: given an utterance,    nd the most 

similar in the database and return it

    similarity based on exact word match, plus 

extracted features regarding discourse

neural response retrieval 

(nio et al. 2014)

    idea: use neural models to soften the connection 

between input and output and do more    exible matching

    model uses socher et al. (2011) recursive auto-

encoder + dynamic pooling

smart reply for email 
retrieval (kannan et al. 2016)

    implemented in gmail smart reply 
    similar response model with lstm id195 scoring, but 

many improvements 
    id125 over response space for scalability 
    canonicalization of syntactic variants and id91 of 

similar responses 

    human curation of responses  
    enforcement of diversity through omission of redundant 

responses and enforcing positive/negative

task-driven dialog

chat vs. task completion

    chat is basically to keep the user entertained 

    what if we want to do an actual task? 

    book a    ight 

    access information from a database

traditional task-completion 

dialog framework

    in semantic frame based dialog: 
    natural language understanding to    ll the slots in the 

frame based on the user utterance 

    dialog state tracking to keep track of the overall dialog 

state over multiple turns 

    dialog control to decide the next action based on state 
    id86 to generate utterances 

based on current state

nlu (for slot filling) w/ 
neural nets (mesnil et al. 2015)

    slot    ling expressed as bio scheme

    id56-crf based model for tags

dialog state tracking

    track the belief about our current frame-   lling state (williams et al. 2013)

    henderson et al. (2014) present id56 model that encodes multiple 

asr hypotheses and generalizes by abstracting details

language generation from dialog 
state w/ neural nets (wen et al. 2015)
    condition lstm 

units based on the 
dialog input, output 
english

end-to-end dialog control   

(williams et al. 2017)

    train an lstm that takes in text and entities and 

directly chooses an action to take (reply or api call)

    trained using combination of supervised and 

id23

questions?

