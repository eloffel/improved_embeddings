basic	
   text	
   
processing

regular	
   expressions

regular	
   expressions

    a	
   formal	
   language	
   for	
   specifying	
   text	
   strings
    how	
   can	
   we	
   search	
   for	
   any	
   of	
   these?

    woodchuck
    woodchucks
    woodchuck
    woodchucks

regular	
   expressions:	
   disjunctions

    letters	
   inside	
   square	
   brackets	
   []

pattern
[ww]oodchuck
[1234567890]

matches
woodchuck, woodchuck
any	
   digit

    ranges [a-z]

pattern
[a-z]
[a-z]
[0-9]

matches
an	
   upper	
   case	
   letter drenched blossoms
a	
   lower	
   case	
   letter
a	
   single digit

my beans were impatient
chapter 1: down the rabbit hole

regular	
   expressions:	
   negation	
   in	
   disjunction

    negations [^ss]

    carat	
   means	
   negation	
   only	
   when	
   first	
   in	
   []

pattern
[^a-z]
[^ss]
[^e^]
a^b

matches
not an	
   upper	
   case	
   letter oyfn pripetchik
neither	
      s   	
   nor	
      s   
neither	
   e	
   nor	
   ^
the	
   pattern a carat b

i have no exquisite reason   
look here
look up a^b now

regular	
   expressions:	
   more	
   disjunction

    woodchucks	
   is	
   another	
   name	
   for	
   groundhog!
    the	
   pipe	
   |	
   for	
   disjunction

pattern
groundhog|woodchuck
yours|mine

a|b|c
[gg]roundhog|[ww]oodchuck

matches

yours
mine
=	
   [abc]

regular	
   expressions:	
   ? *  +  .

matches
optional
previous	
   char
0	
   or	
   more	
   of
previous	
   char
1	
   or	
   more	
   of	
   
previous	
   char

pattern
colou?r

oo*h!

o+h!

baa+
beg.n

color

colour

oh! ooh! oooh! ooooh!

oh! ooh! oooh! ooooh!

baa baaa baaaa baaaaa
begin begun begun beg3n

stephen	
   c	
   kleene

kleene *,	
   	
   	
   kleene +	
   	
   	
   

regular	
   expressions:	
   anchors	
   	
   ^	
   	
   	
   $

pattern
^[a-z] 
^[^a-za-z] 
\.$
.$

matches
palo alto
1
the end.
the end? the end!

   hello   

example

    find	
   me	
   all	
   instances	
   of	
   the	
   word	
      the   	
   in	
   a	
   text.

the

misses	
   capitalized	
   examples

[tt]he

[^a-za-z][tt]he[^a-za-z]

incorrectly	
   returns	
   other or	
   theology

errors

    the	
   process	
   we	
   just	
   went	
   through	
   was	
   based	
   on	
   fixing	
   

two	
   kinds	
   of	
   errors
    matching	
   strings	
   that	
   we	
   should	
   not	
   have	
   matched	
   (there,	
   
then,	
   other)
    false	
   positives	
   (type	
   i)

    not	
   matching	
   things	
   that	
   we	
   should	
   have	
   matched	
   (the)

    false	
   negatives	
   (type	
   ii)

errors	
   cont.

    in	
   nlp	
   we	
   are	
   always	
   dealing	
   with	
   these	
   kinds	
   of	
   

errors.

    reducing	
   the	
   error	
   rate	
   for	
   an	
   application	
   often	
   

involves	
   two	
   antagonistic	
   efforts:	
   
    increasing	
   accuracy	
   or	
   precision	
   (minimizing	
   false	
   positives)
    increasing	
   coverage	
   or	
   recall	
   (minimizing	
   false	
   negatives).

summary

    regular	
   expressions	
   play	
   a	
   surprisingly	
   large	
   role

    sophisticated	
   sequences	
   of	
   regular	
   expressions	
   are	
   often	
   the	
   first	
   model	
   

for	
   any	
   text	
   processing	
   text

    for	
   many	
   hard	
   tasks,	
   we	
   use	
   machine	
   learning	
   classifiers

    but	
   regular	
   expressions	
   are	
   used	
   as	
   features	
   in	
   the	
   classifiers
    can	
   be	
   very	
   useful	
   in	
   capturing	
   generalizations

11

basic	
   text	
   
processing

regular	
   expressions

basic	
   text	
   
processing

word	
   id121

text	
   id172

    every	
   nlp	
   task	
   needs	
   to	
   do	
   text	
   
id172:	
   
1. segmenting/tokenizing	
   words	
   in	
   running	
   text
2. normalizing	
   word	
   formats
3. segmenting	
   sentences	
   in	
   running	
   text

how	
   many	
   words?

    i	
   do	
   uh	
   main-      mainly	
   business	
   data	
   processing

    fragments,	
   filled	
   pauses

    seuss   s	
   cat	
   in	
   the	
   hat	
   is	
   different	
   from	
   other cats!	
   
    lemma:	
   same	
   stem,	
   part	
   of	
   speech,	
   rough	
   word	
   sense

    cat	
   and	
   cats	
   =	
   same	
   lemma

    wordform:	
   the	
   full	
   inflected	
   surface	
   form

    cat	
   and	
   cats	
   =	
   different	
   wordforms

how	
   many	
   words?

they	
   lay	
   back	
   on	
   the	
   san	
   francisco	
   grass	
   and	
   looked	
   at	
   the	
   stars	
   and	
   their

    type:	
   an	
   element	
   of	
   the	
   vocabulary.
    token:	
   an	
   instance	
   of	
   that	
   type	
   in	
   running	
   text.
    how	
   many?

    15	
   tokens	
   (or	
   14)
    13	
   types	
   (or	
   12)	
   (or	
   11?)

how	
   many	
   words?

n =	
   number	
   of	
   tokens
v =	
   vocabulary	
   =	
   set	
   of	
   types
|v| is	
   the	
   size	
   of	
   the	
   vocabulary

switchboard	
   phone
conversations
shakespeare
google	
   n-     grams

tokens	
   =	
   n
2.4	
   million

884,000
1	
   trillion

church	
   and	
   gale	
   (1990):	
   |v|	
   >	
   o(n  )

types	
   =	
   |v|
20 thousand

31 thousand
13	
   million

simple	
   id121	
   in	
   unix

(inspired	
   by	
   ken	
   church   s	
   unix	
   for	
   poets.)

   
    given	
   a	
   text	
   file,	
   output	
   the	
   word	
   tokens	
   and	
   their	
   frequencies
tr -sc    a-za-z       \n    < shakes.txt
sort in alphabetical order

change all non-alpha to newlines

merge and count each type

| sort 
| uniq    c 

1945 a

72 aaron
19 abbess
5 abbot

... ...

25 aaron
6 abate
1 abates
5 abbess
6 abbey
3 abbot
....	
   	
   	
      

the	
   first	
   step:	
   tokenizing

tr -sc    a-za-z       \n    < shakes.txt | head

the
sonnets
by
william
shakespeare
from
fairest
creatures
we
...

the	
   second	
   step:	
   sorting

tr -sc    a-za-z       \n    < shakes.txt | sort | head

a
a
a
a
a
a
a
a
a
...

more	
   counting

    merging	
   upper	
   and	
   lower	
   case
tr    a-z       a-z    < shakes.txt | tr    sc    a-za-z       \n    | sort | uniq    c 
    sorting	
   the	
   counts
tr    a-z       a-z    < shakes.txt | tr    sc    a-za-z       \n    | sort | uniq    c | sort    n    r

23243 the
22225 i
18618 and
16339 to
15687 of
12780 a
12163 you
10839 my
10005 in
8954  d

what happened here?

issues	
   in	
   id121

    finland   s capital      finland finlands finland   s  ?
    what   re, i   m, isn   t     what are, i am, is not
    hewlett-packard 
    hewlett packard ?
    state-of-the-art         state of the art ?
    lowercase
    san francisco     one	
   token	
   or	
   two?
    m.p.h.,	
   phd.

    lower-case lowercase lower case ?

    ??

id121:	
   language	
   issues

    french

    l'ensemble     one	
   token	
   or	
   two?

    l	
   ?	
   l   	
   ?	
   le	
   ?
    want	
   l   ensemble to	
   match	
   with	
   un	
   ensemble

    german	
   noun	
   compounds	
   are	
   not	
   segmented

    lebensversicherungsgesellschaftsangestellter
       life	
   insurance	
   company	
   employee   
    german	
   information	
   retrieval	
   needs	
   compound	
   splitter

id121:	
   language	
   issues
    chinese	
   and	
   japanese	
   no	
   spaces	
   between	
   words:

                                                                
                                                                    
    sharapova now	
   

lives	
   in	
   	
   	
   	
    us	
   	
   	
   	
   	
   	
   	
   southeastern	
   	
   	
   	
   	
   florida

    further	
   complicated	
   in	
   japanese,	
   with	
   multiple	
   alphabets	
   

intermingled
    dates/amounts	
   in	
   multiple	
   formats

                  500                                       $500k(   6,000      )

katakana

romaji
end-     user	
   can	
   express	
   query	
   entirely	
   in	
   hiragana!

hiragana

kanji

word	
   id121	
   in	
   chinese

    also	
   called	
   word	
   segmentation
    chinese	
   words	
   are	
   composed	
   of	
   characters

    characters	
   are	
   generally	
   1	
   syllable	
   and	
   1	
   morpheme.
    average	
   word	
   is	
   2.4	
   characters	
   long.

    standard	
   baseline	
   segmentation	
   algorithm:	
   

    maximum	
   matching	
    (also	
   called	
   greedy)

maximum	
   matching
word	
   segmentation	
   algorithm

   
1)
2)

given	
   a	
   wordlist	
   of	
   chinese,	
   and	
   a	
   string.
start	
   a	
   pointer	
   at	
   the	
   beginning	
   of	
   the	
   string
find	
   the	
   longest	
   word	
   in	
   dictionary	
   that	
   matches	
   the	
   string	
   
starting	
   at	
   pointer

3) move	
   the	
   pointer	
   over	
   the	
   word	
   in	
   string
4) go	
   to	
   2

max-     match	
   segmentation	
   illustration

    thecatinthehat
    thetabledownthere

the cat in the hat

the table down there

theta bled own there

    doesn   t	
   generally	
   work	
   in	
   english!

    but	
   works	
   astonishingly	
   well	
   in	
   chinese

                                                                
                                                                    

    modern	
   probabilistic	
   segmentation	
   algorithms	
   even	
   better

basic	
   text	
   
processing

word	
   id121

basic	
   text	
   
processing

word	
   id172	
   and	
   

id30

id172

    need	
   to	
      normalize   	
   terms	
   

    information	
   retrieval:	
   indexed	
   text	
   &	
   query	
   terms	
   must	
   have	
   same	
   form.

    we	
   want	
   to	
   match	
   u.s.a. and	
   usa

    we	
   implicitly	
   define	
   equivalence	
   classes	
   of	
   terms

    e.g.,	
   deleting	
   periods	
   in	
   a	
   term

    alternative:	
   asymmetric	
   expansion:
search:	
   window,	
   windows
search:	
   windows,	
   windows,	
   window
search:	
   windows
    potentially	
   more	
   powerful,	
   but	
   less	
   efficient

    enter:	
   window
    enter:	
   windows
    enter:	
   windows

    applications	
   like	
   ir:	
   reduce	
   all	
   letters	
   to	
   lower	
   case

    since	
   users	
   tend	
   to	
   use	
   lower	
   case
    possible	
   exception:	
   upper	
   case	
   in	
   mid-     sentence?

case	
   folding

    e.g.,	
   general	
   motors
    fed vs.	
   fed
    sail vs.	
   sail

    for	
   sentiment	
   analysis,	
   mt,	
   information	
   extraction

    case	
   is	
   helpful	
   (us versus	
   us	
   is	
   important)

lemmatization

    reduce	
   inflections	
   or	
   variant	
   forms	
   to	
   base	
   form

    am,	
   are, is	
       be
    car,	
   cars,	
   car's,	
   cars'     car
the	
   boy's	
   cars	
   are	
   different	
   colors     the	
   boy	
   car	
   be	
   different	
   color

   
    lemmatization:	
   have	
   to	
   find	
   correct	
   dictionary	
   headword	
   form
    machine	
   translation

    spanish	
   quiero (   i	
   want   ),	
   quieres (   you	
   want   )	
   same	
   lemma	
   as	
   querer

   want   

morphology

    morphemes:

    the	
   small	
   meaningful	
   units	
   that	
   make	
   up	
   words
    stems:	
   the	
   core	
   meaning-     bearing	
   units
    affixes:	
   bits	
   and	
   pieces	
   that	
   adhere	
   to	
   stems

    often	
   with	
   grammatical	
   functions

id30

    reduce	
   terms	
   to	
   their	
   stems	
   in	
   information	
   retrieval
    id30 is	
   crude	
   chopping	
   of	
   affixes

    language	
   dependent
    e.g.,	
   automate(s),	
   automatic,	
   automation all	
   reduced	
   to	
   automat.

for	
   example	
   compressed	
   
and	
   compression	
   are	
   both	
   
accepted	
   as	
   equivalent	
   to	
   
compress.

for	
   exampl compress	
   and
compress	
   ar both	
   accept
as	
   equival to	
   compress

porter   s	
   algorithm
the	
   most	
   common	
   english	
   stemmer

step	
   1a

sses     ss
ies     i
ss     ss
s          

caresses     caress
ponies       poni
caress       caress
cats          cat

step	
   1b

step	
   2	
   (for	
   long	
   stems)

ational    ate relational    relate
izer    ize
ator    ate
   

digitizer     digitize
operator      operate

step	
   3	
   (for	
   longer	
   stems)

(*v*)ing        walking       walk
sing          sing

(*v*)ed        plastered     plaster
   

al          
able        
ate         
   

revival        reviv
adjustable     adjust
activate       activ

viewing	
   morphology	
   in	
   a	
   corpus
why	
   only	
   strip	
      ing if	
   there	
   is	
   a	
   vowel?

(*v*)ing        walking       walk
sing          sing

36

viewing	
   morphology	
   in	
   a	
   corpus
why	
   only	
   strip	
      ing if	
   there	
   is	
   a	
   vowel?
(*v*)ing        walking       walk
sing          sing

tr -sc 'a-za-z' '\n' < shakes.txt | grep    ing$' | sort | uniq -c | sort    nr 

1312 king
548 being
541 nothing
388 king
375 bring
358 thing
307 ring
152 something
145 coming
130 morning 

548 being
541 nothing
152 something
145 coming
130 morning
122 having
120 living
117 loving
116 being
102 going

tr -sc 'a-za-z' '\n' < shakes.txt | grep '[aeiou].*ing$' | sort | uniq -c | sort    nr

37

dealing	
   with	
   complex	
   morphology	
   is	
   
sometimes	
   necessary

    some	
   languages	
   requires	
   complex	
   morpheme	
   segmentation

    turkish
    uygarlastiramadiklarimizdanmissinizcasina
    `(behaving)	
   as	
   if	
   you	
   are	
   among	
   those	
   whom	
   we	
   could	
   not	
   civilize   
    uygar `civilized   	
   +	
   las `become   	
   

+	
   tir `cause   	
   +	
   ama `not	
   able   	
   
+	
   dik `past   	
   +	
   lar    plural   
+	
   imiz    p1pl   	
   +	
   dan    abl   	
   
+	
   mis    past   	
   +	
   siniz    2pl   	
   +	
   casina    as	
   if   	
   

basic	
   text	
   
processing

word	
   id172	
   and	
   

id30

basic	
   text	
   
processing

sentence	
   segmentation	
   

and	
   decision	
   trees

sentence	
   segmentation

   
!,	
   ?	
   are	
   relatively	
   unambiguous
    period	
      .   	
   is	
   quite	
   ambiguous

    sentence	
   boundary
    abbreviations	
   like	
   inc.	
   or	
   dr.
    numbers	
   like	
   .02%	
   or	
   4.3
    build	
   a	
   binary	
   classifier

    looks	
   at	
   a	
      .   
    decides	
   endofsentence/notendofsentence
    classifiers:	
   hand-     written	
   rules,	
   regular	
   expressions,	
   or	
   machine-     learning

determining	
   if	
   a	
   word	
   is	
   end-     of-     sentence:	
   
a	
   decision	
   tree

more	
   sophisticated	
   decision	
   tree	
   features

    case	
   of	
   word	
   with	
      .   :	
   upper,	
   lower,	
   cap,	
   number
    case	
   of	
   word	
   after	
      .   :	
   upper,	
   lower,	
   cap,	
   number

    numeric	
   features

    length	
   of	
   word	
   with	
      .   
    id203(word	
   with	
      .   	
   occurs	
   at	
   end-     of-     s)
    id203(word	
   after	
      .   	
   occurs	
   at	
   beginning-     of-     s)

implementing	
   decision	
   trees
    a	
   decision	
   tree	
   is	
   just	
   an	
   if-     then-     else	
   statement
    the	
   interesting	
   research	
   is	
   choosing	
   the	
   features
    setting	
   up	
   the	
   structure	
   is	
   often	
   too	
   hard	
   to	
   do	
   by	
   hand
    hand-     building	
   only	
   possible	
   for	
   very	
   simple	
   features,	
   domains
    for	
   numeric	
   features,	
   it   s	
   too	
   hard	
   to	
   pick	
   each	
   threshold

    instead,	
   structure	
   usually	
   learned	
   by	
   machine	
   learning	
   from	
   a	
   training	
   

corpus

decision	
   trees	
   and	
   other	
   classifiers
    we	
   can	
   think	
   of	
   the	
   questions	
   in	
   a	
   decision	
   tree
    as	
   features	
   that	
   could	
   be	
   exploited	
   by	
   any	
   kind	
   of	
   

classifier
    logistic	
   regression
    id166
    neural	
   nets
    etc.

basic	
   text	
   
processing

sentence	
   segmentation	
   

and	
   decision	
   trees

