text	
   classification	
   
and	
   na  ve	
   bayes

the	
   task	
   of	
   text	
   
classification

is	
   this	
   spam?

who	
   wrote	
   which	
   federalist	
   papers?

    1787-     8:	
   anonymous	
   essays	
   try	
   to	
   convince	
   new	
   york	
   
to	
   ratify	
   u.s	
   constitution:	
    jay,	
   madison,	
   hamilton.	
   	
   

    authorship	
   of	
   12	
   of	
   the	
   letters	
   in	
   dispute
    1963:	
   solved	
   by	
   mosteller and	
   wallace	
   using	
   

bayesian	
   methods

james	
   madison

alexander	
   hamilton

male	
   or	
   female	
   author?

1. by	
   1925	
   present-     day	
   vietnam	
   was	
   divided	
   into	
   three	
   parts	
   
under	
   french	
   colonial	
   rule.	
   the	
   southern	
   region	
   embracing	
   
saigon	
   and	
   the	
   mekong	
   delta	
   was	
   the	
   colony	
   of	
   cochin-     china;	
   
the	
   central	
   area	
   with	
   its	
   imperial	
   capital	
   at	
   hue	
   was	
   the	
   
protectorate	
   of	
   annam   

2. clara	
   never	
   failed	
   to	
   be	
   astonished	
   by	
   the	
   extraordinary	
   felicity	
   

of	
   her	
   own	
   name.	
   she	
   found	
   it	
   hard	
   to	
   trust	
   herself	
   to	
   the	
   
mercy	
   of	
   fate,	
   which	
   had	
   managed	
   over	
   the	
   years	
   to	
   convert	
   
her	
   greatest	
   shame	
   into	
   one	
   of	
   her	
   greatest	
   assets   

s.	
   argamon,	
   m.	
   koppel,	
   j.	
   fine,	
   a.	
   r.	
   shimoni,	
   2003.	
      gender,	
   genre,	
   and	
   writing	
   style	
   in	
   formal	
   written	
   texts,   	
   text,	
   volume	
   23,	
   number	
   3,	
   pp.	
   
321   346

positive	
   or	
   negative	
   movie	
   review?

    unbelievably	
   disappointing	
   
    full	
   of	
   zany	
   characters	
   and	
   richly	
   applied	
   satire,	
   and	
   some	
   

great	
   plot	
   twists
this	
   is	
   the	
   greatest	
   screwball	
   comedy	
   ever	
   filmed
it	
   was	
   pathetic.	
   the	
   worst	
   part	
   about	
   it	
   was	
   the	
   boxing	
   
scenes.

   
   

5

what	
   is	
   the	
   subject	
   of	
   this	
   article?

medline article

6

?

mesh subject	
   category	
   hierarchy

    antogonists and	
   inhibitors
    blood	
   supply
    chemistry
    drug	
   therapy
    embryology
    epidemiology
       

text	
   classification

    assigning	
   subject	
   categories,	
   topics,	
   or	
   genres
    spam	
   detection
    authorship	
   identification
    age/gender	
   identification
    language	
   identification
    sentiment	
   analysis
       

text	
   classification:	
   definition

    input:

    a	
   document	
   d
    a	
   fixed	
   set	
   of	
   classes	
   	
   c	
   = {c1,	
   c2,   ,	
   cj}

    output:	
   a	
   predicted	
   class	
   c     c

classification	
   methods:	
   
hand-     coded	
   rules

    rules	
   based	
   on	
   combinations	
   of	
   words	
   or	
   other	
   features
    spam:	
   black-     list-     address	
   or	
   (   dollars   	
   and   have been	
   selected   )

    accuracy	
   can	
   be	
   high

    if	
   rules	
   carefully	
   refined	
   by	
   expert

    but	
   building	
   and	
   maintaining	
   these	
   rules	
   is	
   expensive

classification	
   methods:
supervised	
   machine	
   learning

    input:	
   

    a	
   document	
   d
    a	
   fixed	
   set	
   of	
   classes	
   	
   c	
   = {c1,	
   c2,   ,	
   cj}
    a	
   training	
   set	
   of	
   m hand-     labeled	
   documents	
   (d1,c1),....,(dm,cm)

    output:	
   

    a	
   learned	
   classifier	
     :d      c

10

classification	
   methods:
supervised	
   machine	
   learning

    any	
   kind	
   of	
   classifier

    na  ve bayes
    logistic	
   regression
    support-     vector	
   machines
    k-     nearest	
   neighbors

       

text	
   classification	
   
and	
   na  ve	
   bayes

the	
   task	
   of	
   text	
   
classification

text	
   classification	
   
and	
   na  ve	
   bayes

na  ve bayes	
   (i)

na  ve	
   bayes	
   intuition

    simple	
   (   na  ve   )	
   classification	
   method	
   based	
   on	
   

    relies	
   on	
   very	
   simple	
   representation	
   of	
   document

bayes	
   rule

    bag	
   of	
   words

the	
   bag	
   of	
   words	
   representation

i love this movie! it's sweet, 
i love this movie! it's sweet, 
i love this movie! it's sweet, 
but with satirical humor. the 
but with satirical humor. the 
but with satirical humor. the 
dialogue is great and the 
dialogue is great and the 
dialogue is great and the 
adventure scenes are fun... 
adventure scenes are fun... 
adventure scenes are fun... 
it manages to be whimsical 
it manages to be whimsical 
it manages to be whimsical 
and romantic while laughing 
and romantic while laughing 
and romantic while laughing 
at the conventions of the 
at the conventions of the 
at the conventions of the 
fairy tale genre. i would 
fairy tale genre. i would 
fairy tale genre. i would 
recommend it to just about 
recommend it to just about 
anyone. i've seen it several 
recommend it to just about 
anyone. i've seen it several 
times, and i'm always happy 
anyone. i've seen it several 
times, and i'm always happy 
to see it again whenever i 
times, and i'm always happy 
to see it again whenever i 
have a friend who hasn't 
have a friend who hasn't 
to see it again whenever i 
seen it yet!
seen it yet!
have a friend who hasn't 
seen it yet!
15

it
fairy
fairy
it
love
always
it
fairy
love
always
to
always
love
to
to
it
it
it
whimsical
it
it
whimsical
i
it
whimsical
i
areanyone
and
i
seen
and
areanyone
areanyone
and
seen
seen
friend
dialogue
friend
friend
happy
dialogue
dialogue
happy
happy
recommend
recommend
adventure
recommend
adventure
satirical
adventure
sweet
of
satirical
sweet
of
who
it
satirical
movie
who
it
sweet
of
movie
i
to
who
it
it
romantic
but
i
to
movie
i
but
romantic
it
i
i
to
yet
several
it
but
romantic
yet
i
several
humor
again
the
humor
yet
it
several
again
the
it
the
humor
would
seen
the
the
again
would
seen
it
to
i
scenes
the
manages
the
to
scenes
i
would
seen
the
manages
the
the
fun
times
i
scenes
to
and
i
times
fun
the
manages
and
i
and
and
about
the
while
about
fun
times
whenever
while
have
and
i
whenever
and
have
conventions
about
conventions
while
with
whenever
with
have
conventions
with

it 
6 
it 
6 
it 
i
5
i
5
i
the
4
the
4
the
to
3
to
3
to
3
and
and
3
and
2
seen
2
seen
seen
yet
1
yet
1
yet
1
would
would
1
would
whimsical
1
whimsical
1
whimsical
times
1
1
times
times
sweet
1
sweet
1
1
satirical
sweet
1
satirical
adventure
1
satirical
adventure
1
genre
1
adventure
1
genre
fairy
1
fairy
1
genre
1
humor
1
humor
fairy
have
1
1
have
humor
1
great
1
great
have
   
   
   
   
great
   

the	
   bag	
   of	
   words	
   representation

seen
sweet
whimsical
recommend
happy

...

2
1
1
1
1
...

)=c

  
(

text	
   classification	
   
and	
   na  ve	
   bayes

na  ve bayes	
   (i)

text	
   classification	
   
and	
   na  ve	
   bayes

formalizing	
   the	
   

na  ve bayes	
   
classifier

bayes   	
   rule	
   applied	
   to	
   documents	
   and	
   
classes

   for	
   a	
   document	
   d and	
   a	
   class	
   c

p(c | d) =

p(d |c)p(c)

p(d)

na  ve bayes	
   classifier	
   (i)
p(c | d)
cmap = argmax
p(d |c)p(c)
= argmax
c   c
= argmax

p(d |c)p(c)

p(d)

c   c

c   c

map is    maximum a 
posteriori     = most 
likely class

bayes rule

dropping the 
denominator

na  ve bayes	
   classifier	
   (ii)

cmap = argmax
= argmax

c   c

c   c

p(d |c)p(c)
p(x1, x2,   , xn |c)p(c)

document d 
represented as 
features 
x1..xn

na  ve bayes	
   classifier	
   (iv)

cmap = argmax

c   c

p(x1, x2,   , xn |c)p(c)

o(|x|n   |c|)	
   parameters

could	
   only	
   be	
   estimated	
   if	
   a	
   
very,	
   very	
   large	
   number	
   of	
   
training	
   examples	
   was	
   
available.

how often does this 
class occur?

we can just count the 
relative frequencies in 
a corpus

multinomial	
   na  ve bayes	
   independence	
   
assumptions

p(x1, x2,   , xn |c)

    bag	
   of	
   words	
   assumption:	
   assume	
   position	
   doesn   t	
   

matter

    conditional	
   independence:	
   assume	
   the	
   feature	
   

probabilities	
   p(xi|cj)	
   are	
   independent	
   given	
   the	
   class	
   c.
p(x1,   , xn |c) = p(x1 |c)   p(x2 |c)   p(x3 |c)   ...   p(xn |c)

multinomial	
   na  ve bayes	
   classifier
p(x1, x2,   , xn |c)p(c)

cmap = argmax

c   c

cnb = argmax

c   c

p(cj)

   
x   x

p(x |c)

applying	
   multinomial	
   naive	
   bayes	
   
classifiers	
   to	
   text	
   classification

positions     all	
   word	
   positions	
   in	
   test	
   document	
   	
   	
   	
   	
   	
   

cnb = argmax
cj   c

p(cj)

   
i   positions

p(xi |cj)

text	
   classification	
   
and	
   na  ve	
   bayes

formalizing	
   the	
   

na  ve bayes	
   
classifier

text	
   classification	
   
and	
   na  ve	
   bayes

na  ve bayes:	
   

learning

sec.13.3

learning	
   the	
   multinomial	
   na  ve bayes	
   model
    first	
   attempt:	
   maximum	
   likelihood	
   estimates

    simply	
   use	
   the	
   frequencies	
   in	
   the	
   data

  p(cj) =
  p(wi |cj) =

doccount(c = cj)

ndoc

count(wi,cj)
count(w,cj)
   
w   v

parameter	
   estimation

  p(wi |cj) =

count(wi,cj)
count(w,cj)
   
w   v

fraction	
   of	
   times	
   word	
   wi appears	
   

among	
   all	
   words	
   in	
   documents	
   of	
   topic	
   cj

    create	
   mega-     document	
   for	
   topic	
   j by	
   concatenating	
   all	
   docs	
   in	
   

this	
   topic
    use	
   frequency	
   of	
   w in	
   mega-     document

sec.13.3

problem	
   with	
   maximum	
   likelihood

    what	
   if	
   we	
   have	
   seen	
   no	
   training	
   documents	
   with	
   the	
   word	
   
fantastic and	
   classified	
   in	
   the	
   topic	
   positive (thumbs-     up)?

  p("fantastic"  positive)  =   count("fantastic", positive)
)

count(w,positive

  =  0

   
w   v

    zero	
   probabilities	
   cannot	
   be	
   conditioned	
   away,	
   no	
   matter	
   

the	
   other	
   evidence!

cmap = argmaxc   p(c)

i   

  p(xi |c)

laplace	
   (add-     1)	
   smoothing	
   for	
   na  ve bayes

  p(wi |c) =
  p(wi |c) =

count(wi,c) +1
count(wi,c)
count(w,c)
count(w,c) +1
   
   
(
(
)
)
w   v
w   v

count(wi,c) +1
&
((  +   v
count(w,c
'

)

=

#
%%
$

   
w   v

multinomial	
   na  ve	
   bayes:	
   learning

    from	
   training	
   corpus,	
   extract	
   vocabulary
    calculate	
   p(cj) terms
    for	
   each	
   cj in	
   c do

docsj     all	
   docs	
   with	
   	
   class	
   =cj
p(cj)    

| docsj |

| total # documents|

    calculate	
   p(wk | cj) terms

    textj     single	
   doc	
   containing	
   all	
   docsj
    foreach	
   word	
   wk in	
   vocabulary
nk +  

nk     #	
   of	
   occurrences	
   of	
   wk in	
   textj
p(wk |cj)    

n +  |vocabulary |

text	
   classification	
   
and	
   na  ve	
   bayes

na  ve bayes:	
   

learning

text	
   classification	
   
and	
   na  ve	
   bayes

na  ve bayes:	
   
relationship	
   to	
   

language	
   modeling

generative	
   model	
   for	
   multinomial	
   na  ve bayes

c=china

x1=shanghai

x2=and

x3=shenzhen

x4=issue

x5=bonds

35

na  ve bayes	
   and	
   language	
   modeling
    na  ve bayes classifiers	
   can	
   use	
   any	
   sort	
   of	
   feature

    url,	
   email	
   address,	
   dictionaries,	
   network	
   features

    but	
   if,	
   as	
   in	
   the	
   previous	
   slides

    we	
   use	
   only word	
   features	
   
    we	
   use	
   all of	
   the	
   words	
   in	
   the	
   text	
   (not	
   a	
   subset)

    then	
   

    na  ve bayes has	
   an	
   important	
   similarity	
   to	
   language	
   
modeling.

36

each	
   class	
   =	
   a	
   unigram	
   language	
   model

sec.13.2.1

    assigning	
   each	
   word:	
   p(word	
   |	
   c)
    assigning	
   each	
   sentence:	
   p(s|c)=   p(word|c)
class	
   pos
0.1
0.1
0.01
0.05
0.1
   

i
love
this
fun
film

love
0.1

this
.05

i
0.1

fun
film
0.01 0.1

p(s	
   |	
   pos)	
   =	
   0.0000005	
   

sec.13.2.1

na  ve bayes	
   as	
   a	
   language	
   model
    which	
   class	
   assigns	
   the	
   higher	
   id203	
   to	
   s?

model	
   pos
0.1
0.1
0.01
0.05
0.1

i
love
this
fun
film

model	
   neg

0.2
0.001
0.01
0.005
0.1

i
love
this
fun
film

i

0.1
0.2

love

0.1
0.001

this

0.01
0.01

fun

film

0.05
0.005

0.1
0.1

p(s|pos)	
   	
   >	
   	
   p(s|neg)

text	
   classification	
   
and	
   na  ve	
   bayes

na  ve bayes:	
   
relationship	
   to	
   

language	
   modeling

text	
   classification	
   
and	
   na  ve	
   bayes

multinomial	
   na  ve
bayes:	
   a	
   worked	
   

example

  p(c) =

nc
n
count(w,c) +1
count(c)+|v |

training

test

doc words
1
2
3
4
5

chinese beijing	
   chinese
chinese	
   chinese	
   shanghai
chinese	
   macao
tokyo	
   japan	
   chinese
chinese	
   chinese	
   chinese	
   tokyo japan

class
c
c
c
j
?

  p(w |c) =

priors:
p(c)=	
   
p(j)=	
   

3
4 1
4

conditional	
   probabilities:
p(chinese|c)	
   =
p(tokyo|c)	
   	
   	
   	
   =
p(japan|c)	
   	
   	
   	
   	
   =
p(chinese|j)	
   =
p(tokyo|j)	
   	
   	
   	
   	
   =
p(japan|j)	
   	
   	
   	
   	
   	
   =	
   

(5+1)	
   /	
   (8+6)	
   =	
   6/14	
   =	
   3/7
(0+1)	
   /	
   (8+6)	
   =	
   1/14
(0+1)	
   /	
   (8+6)	
   =	
   1/14
(1+1)	
   /	
   (3+6)	
   =	
   2/9	
   
(1+1)	
   /	
   (3+6)	
   =	
   2/9	
   
(1+1)	
   /	
   (3+6)	
   =	
   2/9	
   

41

choosing	
   a	
   class:
p(c|d5)	
   

   

3/4	
   *	
   (3/7)3 *	
   1/14	
   *	
   1/14	
   

   	
   0.0003

p(j|d5)	
   

   

1/4	
   *	
   (2/9)3 *	
   2/9	
   *	
   2/9	
   

   	
   0.0001

na  ve bayes	
   in	
   spam	
   filtering

    spamassassin features:

    mentions	
   generic	
   viagra
    online	
   pharmacy
    mentions	
   millions	
   of	
   (dollar)	
   ((dollar)	
   nn,nnn,nnn.nn)
    phrase:	
   impress	
   ...	
   girl
    from:	
   starts	
   with	
   many	
   numbers
    subject	
   is	
   all	
   capitals
    html	
   has	
   a	
   low	
   ratio	
   of	
   text	
   to	
   image	
   area
    one	
   hundred	
   percent	
   guaranteed
    claims	
   you	
   can	
   be	
   removed	
   from	
   the	
   list
   
'prestigious	
   non-     accredited	
   universities'
    http://spamassassin.apache.org/tests_3_3_x.html

summary:	
   naive	
   bayes	
   is	
   not	
   so	
   naive

    very	
   fast,	
   low	
   storage	
   requirements
    robust	
   to	
   irrelevant	
   features
    very	
   good	
   in	
   domains	
   with	
   many	
   equally	
   important	
   features

irrelevant	
   features	
   cancel	
   each	
   other	
   without	
   affecting	
   results

decision	
   trees	
   suffer	
   from	
   fragmentation in	
   such	
   cases	
       especially	
   if	
   little	
   data

    optimal	
   if	
   the	
   independence	
   assumptions	
   hold:	
   if	
   assumed	
   
independence	
   is	
   correct,	
   then	
   it	
   is	
   the	
   bayes	
   optimal	
   classifier	
   for	
   problem
    a	
   good	
   dependable	
   baseline	
   for	
   text	
   classification

    but	
   we	
   will	
   see	
   other	
   classifiers	
   that	
   give	
   better	
   accuracy

text	
   classification	
   
and	
   na  ve	
   bayes

multinomial	
   na  ve
bayes:	
   a	
   worked	
   

example

text	
   classification	
   
and	
   na  ve bayes

precision,	
   recall,	
   and	
   

the	
   f	
   measure

the	
   2-     by-     2	
   contingency	
   table

correct

not	
   correct

selected
not	
   selected

tp
fn

fp
tn

precision	
   and	
   recall

    precision:	
   %	
   of	
   selected	
   items	
   that	
   are	
   correct

recall:	
   %	
   of	
   correct	
   items	
   that	
   are	
   selected

correct

not	
   correct

selected
not	
   selected

tp
fn

fp
tn

a	
   combined	
   measure:	
   f

    a	
   combined	
   measure	
   that	
   assesses	
   the	
   p/r	
   tradeoff	
   is	
   f	
   measure	
   

(weighted	
   harmonic	
   mean):

f

=

  

1
p

1
1(
   +

1)
  
r

=

2

(
  
  

2

pr
)1
+
rp
+

    the	
   harmonic	
   mean	
   is	
   a	
   very	
   conservative	
   average;	
   see	
   iir   

8.3

   

    people	
   usually	
   use	
   balanced	
   f1	
   measure

i.e.,	
   with	
      =	
   1	
   (that	
   is,	
      =	
     ):	
   	
   	
   

f =	
   2pr/(p+r)

text	
   classification	
   
and	
   na  ve bayes

precision,	
   recall,	
   and	
   

the	
   f	
   measure

text	
   classification	
   
and	
   na  ve	
   bayes

text	
   classification:	
   

evaluation

more	
   than	
   two	
   classes:	
   
sets	
   of	
   binary	
   classifiers

    dealing	
   with	
   any-     of	
   or	
   multivalue classification

    a	
   document	
   can	
   belong	
   to	
   0,	
   1,	
   or	
   >1	
   classes.

sec.14.5

    for	
   each	
   class	
   c   c

    given	
   test	
   doc	
   d,	
   

    build	
   a	
   classifier	
     c to	
   distinguish	
   c from	
   all	
   other	
   classes	
   c   	
      c

    evaluate	
   it	
   for	
   membership	
   in	
   each	
   class	
   using	
   each	
     c
    d belongs	
   to	
   any class	
   for	
   which   c returns	
   true

51

more	
   than	
   two	
   classes:	
   
sets	
   of	
   binary	
   classifiers

sec.14.5

    one-     of	
   or	
   multinomial	
   classification

    classes	
   are	
   mutually	
   exclusive:	
   	
   each	
   document	
   in	
   exactly	
   one	
   class

    for	
   each	
   class	
   c   c

    given	
   test	
   doc	
   d,	
   

    build	
   a	
   classifier	
     c to	
   distinguish	
   c from	
   all	
   other	
   classes	
   c   	
      c

    evaluate	
   it	
   for	
   membership	
   in	
   each	
   class	
   using	
   each	
     c
    d belongs	
   to	
   the	
   one class	
   with	
   maximum	
   score

52

evaluation:	
   
classic	
   reuters-     21578	
   data	
   set	
   

sec. 15.2.4

    most	
   (over)used	
   data	
   set,	
   21,578	
   docs	
   (each	
   90	
   types,	
   200	
   toknens)
    9603	
   training,	
   3299	
   test	
   articles	
   (modapte/lewis	
   split)
    118	
   categories

    an	
   article	
   can	
   be	
   in	
   more	
   than	
   one	
   category
    learn	
   118	
   binary	
   category	
   distinctions

    average	
   document	
   (with	
   at	
   least	
   one	
   category)	
   has	
   1.24	
   classes
    only	
   about	
   10	
   out	
   of	
   118	
   categories	
   are	
   large

common categories
(#train, #test)
53

    earn   (2877,   1087)   
    acquisitions   (1650,   179)
    money-  fx (538,   179)
    grain   (433,   149)
    crude   (389,   189)

    trade   (369,119)
    interest   (347,   131)
    ship   (197,   89)
    wheat   (212,   71)
    corn   (182,   56)

reuters	
   text	
   categorization	
   data	
   set	
   
(reuters-     21578)	
   document

sec. 15.2.4

<reuters topics="yes"  lewissplit="train"  cgisplit="training-set"  oldid="12981" 
newid="798">
<date> 2-mar-1987 16:51:43.42</date>
<topics><d>livestock</d><d>hog</d></topics>
<title>american  pork congress kicks off tomorrow</title>
<dateline>     chicago, march 2 - </dateline><body>the  american pork congress kicks off tomorrow, 
march 3, in indianapolis with 160 of the nations pork producers from 44 member states determining industry positions 
on a number of issues, according to the national pork producers council, nppc.

delegates to the three day congress will be considering 26 resolutions concerning various issues, including the future 
direction of farm policy and the tax law as it applies to the agriculture sector. the delegates will also debate whether to 
endorse concepts of a national prv (pseudorabies virus) control and eradication program, the nppc said.

a large trade show, in conjunction with the congress, will feature the latest in technology in all areas of the industry, 

the nppc added. reuter
54
&#3;</body></text></reuters>

confusion	
   matrix	
   c

    for	
   each	
   pair	
   of	
   classes	
   <c1,c2>	
   how	
   many	
   documents	
   from	
   c1

docs	
   in	
   test	
   set assigned

were	
   incorrectly	
   assigned	
   to	
   c2?
    c3,2:	
   90	
   wheat	
   documents	
   incorrectly	
   assigned	
   to	
   poultry
assigned	
   
interest
1
0
0
3
26
5

assigned	
   
poultry
1
1
90
0
1
0

assigned	
   
wheat
13
0
0
0
2
2

assigned	
   
coffee
0
0
1
34
13
14

true	
   uk
true	
   poultry
true	
   wheat
true	
   coffee
true	
   interest
true	
   trade

uk
95
0
10
0
-     
0

assigned	
   
trade
0
0
0
7
5
10

55

per	
   class	
   evaluation	
   measures

recall:	
   

fraction	
   of	
   docs	
   in	
   class	
   i classified	
   correctly:

precision:	
   

fraction	
   of	
   docs	
   assigned	
   class	
   i that	
   are	
   

actually	
   about	
   class	
   i:

accuracy:	
   (1	
   -      error	
   rate)	
   

fraction	
   of	
   docs	
   classified	
   correctly:

56

sec. 15.2.4

cii
cij
   
j
cii
cji
   
j

cii
   
i
cij
   
   
i
j

micro-      vs.	
   macro-     averaging

sec. 15.2.4

    if	
   we	
   have	
   more	
   than	
   one	
   class,	
   how	
   do	
   we	
   combine	
   
multiple	
   performance	
   measures	
   into	
   one	
   quantity?

    macroaveraging:	
   compute	
   performance	
   for	
   each	
   class,	
   

then	
   average.

    microaveraging:	
   collect	
   decisions	
   for	
   all	
   classes,	
   

compute	
   contingency	
   table,	
   evaluate.

57

sec.	
   15.2.4

micro-      vs.	
   macro-     averaging:	
   example
micro	
   ave.	
   table

class	
   2

class	
   1

truth:	
   
yes
10

truth:	
   
no
10

classifier:	
   yes

truth:	
   
yes
90

truth:	
   
no
10

truth:	
   
yes
100

classifier:	
   yes

classifier:	
   yes

classifier:	
   no

10

970

classifier:	
   no

10

890

classifier:	
   no

20

truth:	
   
no
20

1860

    macroaveraged precision:	
   (0.5	
   +	
   0.9)/2	
   =	
   0.7
    microaveraged precision:	
   100/120	
   =	
   .83
    microaveraged score	
   is	
   dominated	
   by	
   score	
   on	
   common	
   classes

58

development	
   test	
   sets	
   and	
   cross-     validation

development test set

training	
   set
    metric:	
   p/r/f1	
   	
   or	
   accuracy
    unseen	
   test	
   set

    avoid	
   overfitting (   tuning	
   to	
   the	
   test	
   set   )
    more	
   conservative	
   estimate	
   of	
   performance
    cross-     validation	
   over	
   multiple	
   splits

    handle	
   sampling	
   errors	
   from	
   different	
   datasets

    pool	
   results	
   over	
   each	
   split
    compute	
   pooled	
   dev set	
   performance

test	
   set

training	
   set

dev test

training	
   set

dev test

dev test

training	
   set

test	
   set

text	
   classification	
   
and	
   na  ve	
   bayes

text	
   classification:	
   

evaluation

text	
   classification	
   
and	
   na  ve	
   bayes

text	
   classification:	
   

practical	
   issues

sec. 15.3.1

the	
   real	
   world

    gee,	
   i   m	
   building	
   a	
   text	
   classifier	
   for	
   real,	
   now!
    what	
   should	
   i	
   do?

62

no	
   training	
   data?
manually	
   written	
   rules

sec. 15.3.1

if	
   (wheat	
   or	
   grain)	
   and	
   not	
   (whole	
   or	
   bread)	
   then

categorize	
   as	
   grain
    need	
   careful	
   crafting	
   

    human	
   tuning	
   on	
   development	
   data
    time-     consuming:	
   2	
   days	
   per	
   class

63

very	
   little	
   data?

sec. 15.3.1

    na  ve	
   bayes	
   is	
   a	
      high-     bias   	
   algorithm	
   (ng	
   and	
   jordan	
   2002	
   nips)

    use	
   na  ve bayes
    get	
   more	
   labeled	
   data	
   
    try	
   semi-     supervised	
   training	
   methods:

    find	
   clever	
   ways	
   to	
   get	
   humans	
   to	
   label	
   data	
   for	
   you

    id64,	
   em	
   over	
   unlabeled	
   documents,	
      

64

a	
   reasonable	
   amount	
   of	
   data?

sec. 15.3.1

    perfect	
   for	
   all	
   the	
   clever	
   classifiers

    id166
    regularized	
   logistic	
   regression

    you	
   can	
   even	
   use	
   user-     interpretable	
   decision	
   trees

    users	
   like	
   to	
   hack
    management	
   likes	
   quick	
   fixes

65

sec. 15.3.1

a	
   huge	
   amount	
   of	
   data?

    can	
   achieve	
   high	
   accuracy!
    at	
   a	
   cost:

    id166s	
   (train	
   time)	
   or	
   knn (test	
   time)	
   can	
   be	
   too	
   slow
    regularized	
   logistic	
   regression	
   can	
   be	
   somewhat	
   better
    so	
   na  ve	
   bayes	
   can	
   come	
   back	
   into	
   its	
   own	
   again!

66

accuracy	
   as	
   a	
   function	
   of	
   data	
   size

sec. 15.3.1

    with	
   enough	
   data

    classifier	
   may	
   not	
   matter

67

brill	
   and	
   banko on	
   spelling	
   correction

real-     world	
   systems	
   generally	
   combine:

    automatic	
   classification	
   
    manual	
   review	
   of	
   uncertain/difficult/"new   	
   cases

68

underflow	
   prevention:	
   log	
   space

    multiplying	
   lots	
   of	
   probabilities	
   can	
   result	
   in	
   floating-     point	
   underflow.
   

since	
   log(xy)	
   =	
   log(x)	
   +	
   log(y)
    better	
   to	
   sum	
   logs	
   of	
   probabilities	
   instead	
   of	
   multiplying	
   probabilities.

    class	
   with	
   highest	
   un-     normalized	
   log	
   id203	
   score	
   is	
   still	
   most	
   probable.

cnb = argmax
cj   c

logp(cj) +
    model	
   is	
   now	
   just	
   max	
   of	
   sum	
   of	
   weights

   
i   positions

logp(xi |cj)

how	
   to	
   tweak	
   performance

sec. 15.3.2

    domain-     specific	
   features	
   and	
   weights:	
   very	
   important	
   in	
   real	
   

performance

    sometimes	
   need	
   to	
   collapse	
   terms:

    part	
   numbers,	
   chemical	
   formulas,	
      
    but	
   id30	
   generally	
   doesn   t	
   help

    upweighting:	
   counting	
   a	
   word	
   as	
   if	
   it	
   occurred	
   twice:

    title	
   words	
   (cohen	
   &	
   singer	
   1996)
    first	
   sentence	
   of	
   each	
   paragraph	
   (murata,	
   1999)
    in	
   sentences	
   that	
   contain	
   title	
   words	
   (ko et	
   al, 2002)

70

text	
   classification	
   
and	
   na  ve	
   bayes

text	
   classification:	
   

practical	
   issues

