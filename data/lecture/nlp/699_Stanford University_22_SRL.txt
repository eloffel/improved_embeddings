semantic	
   role	
   

labeling

semantic	
   role	
   

labeling

introduction

applications 

semantic	
   role	
   labeling

(cid:96) question & answer systems 

   who      did what to whom      at where? 

 

the police officer detained the suspect at the scene of the crime 

arg0 
agent

v 

predicate

arg2 
theme

am-loc 
location

can	
   we	
   figure	
   out	
   that	
   these	
   have	
   the	
   
same	
   meaning?

xyz	
   corporation	
   bought the	
   stock.
they	
   sold the	
   stock	
   to	
   xyz	
   corporation.
the	
   stock	
   was	
   bought by	
   xyz	
   corporation.
the	
   purchase of	
   the	
   stock	
   by	
   xyz	
   corporation...	
   
the	
   stock	
   purchase by	
   xyz	
   corporation...	
   

4

a	
   shallow	
   semantic	
   representation:	
   
semantic	
   roles

predicates	
   (bought,	
   sold,	
   purchase)	
   represent	
   an	
   event
semantic	
   roles	
   express	
   the	
   abstract	
   role	
   that	
   arguments	
   of	
   a	
   
predicate	
   can	
   take	
   in	
   the	
   event

more	
   specific

more	
   general

buyer

agent

proto-     agent

5

semantic	
   role	
   

labeling

semantic	
   roles

the destination of an object of a transfer event
goal
figure 22.1 some commonly used thematic roles with their de   nitions.

getting	
   to	
   semantic	
   roles

(22.1) sasha broke the window.
(22.2) pat opened the door.

neo-     davidsonian event	
   representation:

a neo-davidsonian event representation of these two sentences would be

sasha	
   broke	
   the	
   window
pat	
   opened	
   the	
   door

9e,x,y breaking(e)^ breaker(e,sasha)
9e,x,y opening(e)^ opener(e,pat)

^brokent hing(e,y)^window(y)
^openedt hing(e,y)^ door(y)

deep roles

subjects	
   of	
   break	
   and	
   open:	
   breaker and	
   opener
deep	
   roles	
   specific	
   to	
   each	
   event	
   (breaking,	
   opening)
hard	
   to	
   reason	
   about	
   them	
   for	
   nlu	
   applications	
   like	
   qa

in this representation, the roles of the subjects of the verbs break and open are
breaker and opener respectively. these deep roles are speci   c to each event; break-
ing events have breakers, opening events have openers, and so on.

if we are going to be able to answer questions, perform id136s, or do any
further kinds of natural language understanding of these events, we   ll need to know
a little more about the semantics of these arguments. breakers and openers have

7

thematic	
   roles

    breaker and	
   opener have	
   something	
   in	
   common!

    volitional	
   actors
    often	
   animate
    direct	
   causal	
   responsibility	
   for	
   their	
   events

    thematic	
   roles	
   are	
   a	
   way	
   to	
   capture	
   this	
   semantic	
   commonality	
   

between	
   breakers	
   and	
   eaters.	
   

    they	
   are	
   both	
   agents.	
   
    the	
   brokenthing and	
   openedthing,	
   are	
   themes.

    prototypically	
   inanimate	
   objects	
   affected	
   in	
   some	
   way	
   by	
   the	
   action

8

thematic	
   roles

    one	
   of	
   the	
   oldest	
   linguistic	
   models

    indian	
   grammarian	
   panini	
   between	
   the	
   7th	
   and	
   4th	
   centuries	
   bce	
   

    modern	
   formulation	
   from	
   fillmore	
   (1966,1968),	
   gruber	
   (1965)

    fillmore	
   influenced	
   by	
   lucien	
   tesni  re   s (1959)	
     l  ments de	
   syntaxe

structurale,	
   the	
   book	
   that	
   introduced	
   dependency	
   grammar

    fillmore	
   first	
   referred	
   to	
   roles	
   as	
   actants (fillmore,	
   1966)	
   but	
   switched	
   to	
   

the	
   term	
   case

9

thematic	
   roles

2 chapter 22

    a	
   typical	
   set:
    id14

22.2

    diathesis alternations

3

thematic role
de   nition
thematic role
the volitional causer of an event
agent
agent
the experiencer of an event
experiencer
experiencer
the non-volitional causer of the event
force
force
the participant most directly affected by an event
theme
theme
the end product of an event
result
result
the proposition or content of a propositional event
content
content
an instrument used in an event
instrument
instrument
the bene   ciary of an event
beneficiary
beneficiary
the origin of the object of a transfer event
source
source
the destination of an object of a transfer event
goal
goal
figure 22.2 some prototypical examples of various thematic roles.
figure 22.1 some commonly used thematic roles with their de   nitions.

example
the waiter spilled the soup.
john has a headache.
the wind blows debris from the mall into our yards.
only after benjamin franklin broke the ice...
the city built a regulation-size baseball diamond...
mona asked    you met mary ann at a supermarket?   
he poached cat   sh, stunning them with a shocking device...
whenever ann callahan makes hotel reservations for her boss...
i    ew in from boston.
i drove to portland.

(22.1) sasha broke the window.
(22.2) pat opened the door.

10

22.2 diathesis alternations

a neo-davidsonian event representation of these two sentences would be

the main reason computational systems use semantic roles is to act as a shallow
meaning representation that can let us make simple id136s that aren   t possible

agent

(22.3) john

broke the window.

earlier examples, if a document says that company a acquired company b, we   d
like to know that this answers the query was company b acquired? despite the fact
broke the window
that the two sentences have very different surface syntax. similarly, this shallow
semantics might act as a useful intermediate language in machine translation.

thematic	
   grid,	
   case	
   frame,	
     -     grid

theme
broke the window.
semantic roles thus help generalize over different surface realizations of pred-
icate arguments. for example, while the agent is often realized as the subject of
the sentence, in other cases the theme can be the subject. consider these possible
realizations of the thematic arguments of the verb break:
was broken by john.
(22.3) john

example	
   usages	
   of	
      break   
broke the window.

agent
(22.5) the rock

(22.6) the window

(22.7) the window

(22.4) john

instrument

broke.

theme

theme

theme
thematic grid, case frame,   -grid
break:
theme

agent

with a rock.

instrument

agent

theme

(22.4) john

broke the window

agent
(22.5) the rock

theme
broke the window.

instrument

theme

(22.6) the window

broke.

theme

(22.7) the window

was broken by john.

theme

agent

with a rock.
thematic grid
instrument
case frame

agent, theme, instrument. 

these examples suggest that break has (at least) the possible arguments agent,
theme, and instrument. the set of thematic role arguments taken by a verb is
often called the thematic grid, q-grid, or case frame. we can see that there are
(among others) the following possibilities for the realization of these arguments of
break:

some	
   realizations:
agent/subject, theme/object
agent/subject, theme/object,
instrument/subject, theme/object
theme/subject

instrument/ppwith

these examples suggest that break has (at least) the possible arguments agent,
11
theme, and instrument. the set of thematic role arguments taken by a verb is

it turns out that many verbs allow their thematic roles to be realized in various
syntactic positions. for example, verbs like give can realize the theme and goal
arguments in two different ways:

    id14
gave the book

a. doris
agent
b. doris
agent

to cary.
goal

theme

gave cary
goal

the book.
theme

diathesis	
   alternations	
   (or	
   verb	
   alternation)

break: agent, instrument, or theme as 
subject

give:  theme and goal in either order

dative	
   alternation:	
   particular	
   semantic	
   classes	
   of	
   verbs,	
      verbs	
   of	
   future	
   having   	
   
these multiple argument structure realizations (the fact that break can take agent,
(advance,	
   allocate,	
   offer,	
   owe),	
      send	
   verbs   	
   (forward,	
   hand,	
   mail),	
      verbs	
   of	
   
instrument, or theme as subject, and give can realize its theme and goal in
throwing   	
   (kick,	
   pass,	
   throw),	
   etc.
either order) are called verb alternations or diathesis alternations. the alternation
levin	
   (1993):	
   47	
   semantic	
   classes	
   (   levin	
   classes   )	
   for	
   3100	
   english	
   verbs	
   and	
   
we showed above for give, the dative alternation, seems to occur with particular se-
alternations.	
   in	
   online	
   resource	
   verbnet.
mantic classes of verbs, including    verbs of future having    (advance, allocate, offer,
12
owe),    send verbs    (forward, hand, mail),    verbs of throwing    (kick, pass, throw),

problems	
   with	
   thematic	
   roles

hard	
   to	
   create	
   standard	
   set	
   of	
   roles	
   or	
   formally	
   define	
   them
often	
   roles	
   need	
   to	
   be	
   fragmented	
   to	
   be	
   defined.

levin	
   and	
   rappaport	
   hovav (2015):	
   two	
   kinds	
   of	
   instruments
intermediary instruments	
   that	
   can	
   appear	
   as	
   subjects	
   

the	
   cook	
   opened	
   the	
   jar	
   with	
   the	
   new	
   gadget.	
   
the	
   new	
   gadget	
   opened	
   the	
   jar.	
   

enabling	
   instruments	
   that	
   cannot

shelly	
   ate	
   the	
   sliced	
   banana	
   with	
   a	
   fork.	
   
*the	
   fork	
   ate	
   the	
   sliced	
   banana.	
   

13

alternatives	
   to	
   thematic	
   roles

1. fewer	
   roles:	
   generalized	
   semantic	
   roles,	
   defined	
   as	
   

prototypes	
   (dowty 1991)
proto-     agent	
   
proto-     patient	
   

propbank

2. more	
   roles:	
   define	
   roles	
   specific	
   to	
   a	
   group	
   of	
   predicates

framenet

14

semantic	
   role	
   

labeling

the	
   proposition	
   bank	
   

(propbank)

propbank

    palmer,	
   martha,	
   daniel	
   gildea,	
   and	
   paul	
   kingsbury.	
   2005.	
   the	
   

proposition	
   bank:	
   an	
   annotated	
   corpus	
   of	
   semantic	
   roles.	
   
computational	
   linguistics,	
   31(1):71   106	
   

16

propbank roles

following dowty 1991

proto-     agent

    volitional	
   involvement	
   in	
   event	
   or	
   state
    sentience	
   (and/or	
   perception)
    causes	
   an	
   event	
   or	
   change	
   of	
   state	
   in	
   another	
   participant	
   
    movement	
   (relative	
   to	
   position	
   of	
   another	
   participant)

proto-     patient

    undergoes	
   change	
   of	
   state
    causally	
   affected	
   by	
   another	
   participant
    stationary	
   relative	
   to	
   movement	
   of	
   another	
   participant

17

propbank roles

    following	
   dowty 1991

    role	
   definitions	
   determined	
   verb	
   by	
   verb,	
   with	
   respect	
   to	
   the	
   other	
   roles	
   
    semantic	
   roles	
   in	
   propbank are	
   thus	
   verb-     sense	
   specific.

    each	
   verb	
   sense	
   has	
   numbered	
   argument:	
   arg0,	
   arg1,	
   arg2,   

arg0:	
   proto-     agent
arg1: proto-     patient
arg2:	
   usually:	
   benefactive,	
   instrument,	
   attribute,	
   or	
   end	
   state
arg3:	
   usually:	
   start	
   point,	
   benefactive,	
   instrument,	
   or	
   attribute
arg4	
   the	
   end	
   point
(arg2-     arg5	
   are	
   not	
   really	
   that	
   consistent,	
   causes	
   a	
   problem	
   for	
   labeling)

18

de   nitions.
(22.11) agree.01
(22.11) agree.01

arg0: agreer
arg0: agreer
arg1: proposition
arg1: proposition
arg2: other entity agreeing
arg2: other entity agreeing

propbank frame	
   files

ex1:
ex1:
ex2:
ex2:

[arg0 the group] agreed [arg1 it wouldn   t make an offer].
[arg0 the group] agreed [arg1 it wouldn   t make an offer].
[argm-tmp usually] [arg0 john] agrees [arg2 with mary]
[argm-tmp usually] [arg0 john] agrees [arg2 with mary]
[arg1 on everything].
[arg1 on everything].

(22.12) fall.01
(22.12) fall.01

arg1: logical subject, patient, thing falling
arg1: logical subject, patient, thing falling
arg2: extent, amount fallen
arg2: extent, amount fallen
arg3: start point
arg3: start point
arg4: end point, end state of arg1
arg4: end point, end state of arg1
ex1:
ex1:
ex2:
ex2:

[arg1 sales] fell [arg4 to $25 million] [arg3 from $27 million].
[arg1 sales] fell [arg4 to $25 million] [arg3 from $27 million].
[arg1 the average junk bond] fell [arg2 by 4.2%].
[arg1 the average junk bond] fell [arg2 by 4.2%].

note that there is no arg0 role for fall, because the normal subject of fall is a
note that there is no arg0 role for fall, because the normal subject of fall is a

19

the propbank semantic roles can be useful in recovering shallow semantic in-

    id14
the propbank semantic roles can be useful in recovering shallow semantic in-

formation about verbal arguments. consider the verb increase:
(22.13) increase.01    go up incrementally   

advantage	
   of	
   a	
   probbank labeling
formation about verbal arguments. consider the verb increase:
(22.13) increase.01    go up incrementally   

thing increasing

arg0: causer of increase
arg1:
arg0: causer of increase
arg2: amount increased by, ext, or mnr
arg1:
arg3: start point
arg2: amount increased by, ext, or mnr
arg4: end point
arg3: start point
arg4: end point

thing increasing

a propbank id14 would allow us to infer the commonality in
the event structures of the following three examples, that is, that in each case big
fruit co. is the agent and the price of bananas is the theme, despite the differing
this	
   would	
   allow	
   us	
   to	
   see	
   the	
   commonalities	
   in	
   these	
   3	
   sentences:
surface forms.
(22.14)
(22.15)
(22.16)
20

a propbank id14 would allow us to infer the commonality in
the event structures of the following three examples, that is, that in each case big
fruit co. is the agent and the price of bananas is the theme, despite the differing
[arg0 big fruit co. ] increased [arg1 the price of bananas].
surface forms.
[arg1 the price of bananas] was increased again [arg0 by big fruit co. ]
[arg1 the price of bananas] increased [arg2 5%].
(22.14)
(22.15)

[arg0 big fruit co. ] increased [arg1 the price of bananas].
[arg1 the price of bananas] was increased again [arg0 by big fruit co. ]

propbank also has a number of non-numbered arguments called argms, (argm-

[arg1 the price of bananas] increased [arg2 5%].

(22.16)
modifiers	
   or	
   adjuncts	
   of	
   the	
   predicate:	
   
propbank also has a number of non-numbered arguments called argms, (argm-
tmp, argm-loc, etc) which represent modi   cation or adjunct meanings. these are
arg-     m
relatively stable across predicates, so aren   t listed with each frame    le. data labeled
with these modi   ers can be helpful in training systems to detect temporal, location,
or directional modi   cation across predicates. some of the argm   s include:

argm-

yesterday evening, now
at the museum, in san francisco
down, to bangkok
clearly, with much enthusiasm
because ... , in response to the ruling
themselves, each other

tmp
when?
loc
where?
dir
where to/from?
mnr
how?
prp/cau why?
rec
adv
prd
while propbank focuses on verbs, a related project, nombank (meyers et al.,
2004) adds annotations to noun predicates. for example the noun agreement in
apple   s agreement with ibm would be labeled with apple as the arg0 and ibm as
the arg2. this allows semantic role labelers to assign labels to arguments of both
verbal and nominal predicates.

miscellaneous
secondary predication

...ate the meat raw

21

propbanking a	
   sentence
propbank - a treebanked sentence 

martha	
   palmer	
   2013

a sample 
parse tree

s 

vp 

have  vp 

(s (np-sbj analysts) 
     (vp have 
         (vp been 
             (vp expecting 

np-sbj 
analysts 

been  vp 

expecting np 

a gm-jaguar 

np 

pact 

whnp-1 

that 

           (np (np a gm-jaguar pact) 
                   (sbar (whnp-1 that) 
 
                (s (np-sbj *t*-1) 
                           (vp would 
 
 
 
                                  (np the u.s. car maker) 
 
 
 
 
 

            (vp give 

sbar 

s 

               (np (np an eventual (adjp 30 %) stake) 
 

          (pp-loc in (np the british company)))))))))))) 

np-sbj 
*t*-1 

would 

vp 

vp 

analysts have been expecting a gm-jaguar  
pact that  would give the u.s. car maker an  
eventual 30% stake in the british company. 

22

give 
np 

the us car 

maker 

np 

np 

an eventual 
30% stake 

in 

pp-loc 

np 

the british 
company 

the	
   same	
   parse	
   tree	
   propbanked
the same sentence, propbanked 

have been expecting 

arg0 

arg1 

analysts 

a gm-jaguar 

pact 

(s arg0 (np-sbj analysts) 
     (vp have 
         (vp been 
             (vp expecting 

           arg1 (np (np a gm-jaguar pact) 
                   (sbar (whnp-1 that) 
 
 
 

                      (s arg0 (np-sbj *t*-1) 
                           (vp would 
 

                  (vp give  

                                        arg2 (np the u.s. car maker) 

martha	
   palmer	
   2013

arg0 

 
 
company)))))))))))) 
that would give 

 
 

arg1 

                  arg1 (np (np an eventual (adjp 30 %) stake) 
 

           (pp-loc in (np the british 

*t*-1 

arg2 

an eventual 30% stake in the 

british company 

23

the us car 

maker 

 
expect(analysts, gm-j pact) 
give(gm-j pact, us car maker, 30% stake) 

verb frames coverage by language      
current count of senses (lexical units) 

annotated	
   propbank data

    penn	
   english	
   treebank,	
   
ontonotes 5.0.	
   
    total	
   ~2	
   million	
   words
    penn	
   chinese	
   treebank
    hindi/urdu	
   propbank
    arabic	
   propbank

24

2013	
   verb	
   frames	
   coverage	
   
count	
   of	
   word	
   sense	
   (lexical	
   units)

language 

final count 

english 
chinese 
arabic 

  10,615* 
24, 642 
    7,015 

estimated coverage 

       only 111 english adjectives 

from	
   martha	
   palmer	
   2013	
   tutorial

english noun and lvc annotation 

plus	
   nouns	
   and	
   light	
   verbs

!    example noun: decision 

!    roleset: arg0: decider, arg1: decision    

!          [yourarg0] [decisionrel]  
    [to say look i don't want to go through this anymorearg1]    

!    example within an lvc: make a decision 

!          [the presidentarg0] [maderel-lvb]  
     the [fundamentally correctargm-adj]  
    [decisionrel]  [to get on offensearg1]    

25

slide	
   from	
   palmer	
   2013

semantic	
   role	
   

labeling

framenet

capturing	
   descriptions	
   of	
   the	
   same	
   event	
   
while making id136s about the semantic commonalities across different sen-
by	
   different	
   nouns/verbs
tences with increase is useful, it would be even more useful if we could make such
id136s in many more situations, across different verbs, and also between verbs
and nouns. for example, we   d like to extract the similarity among these three sen-
tences:
(22.17)
(22.18)
(22.19) there has been a [arg2 5%] rise [arg1 in the price of bananas].

[arg1 the price of bananas] increased [arg2 5%].
[arg1 the price of bananas] rose [arg2 5%].

note that the second example uses the different verb rise, and the third example
uses the noun rather than the verb rise. we   d like a system to recognize that the

27

framenet

    baker	
   et	
   al.	
   1998,	
   fillmore	
   et	
   al.	
   2003,	
   fillmore	
   and	
   baker	
   2009,	
   

ruppenhofer et	
   al.	
   2006	
   

    roles	
   in	
   propbank are	
   specific	
   to	
   a	
   verb
    role	
   in	
   framenet are	
   specific	
   to	
   a	
   frame:	
   a	
   background	
   
knowledge	
   structure	
   that	
   defines	
   a	
   set	
   of	
   frame-     specific	
   
semantic	
   roles,	
   called frame	
   elements,	
   
    includes	
   a	
   set	
   of	
   pred cates	
   that	
   use	
   these	
   roles
    each	
   word	
   evokes	
   a	
   frame	
   and	
   profiles	
   some	
   aspect	
   of	
   the	
   frame

28

sentences.

for example, the change position on a scale frame is de   ned as follows:
this frame consists of words that indicate the change of an item   s posi-
tion on a scale (the attribute) from a starting point (initial value) to an
end point (final value).

the	
      change	
   position	
   on	
   a	
   scale   	
   frame

core roles
non-core roles

this	
   frame	
   consists	
   of	
   words	
   that	
   indicate	
   the	
   change	
   of	
   an	
   item   s	
   
some of the semantic roles (frame elements) in the frame are de   ned as in
fig. 22.3. note that these are separated into core roles, which are frame speci   c, and
position	
   on	
   a	
   scale	
   (the	
   attribute)	
   from	
   a	
   starting	
   point	
   (initial
non-core roles, which are more like the arg-m arguments in propbank, expressed
more general properties of time, location, and so on.
value)	
   to	
   an	
   end	
   point	
   (final value)
here are some example sentences:

(22.20)
(22.21)
(22.22)
(22.23)

[item oil] rose [attribute in price] [difference by 2%].
[item it] has increased [final state to having them 1 day a month].
[item microsoft shares] fell [final value to 7 5/8].
[item colon cancer incidence] fell [difference by 50%] [group among

men].

(22.24) a steady increase [initial value from 9.5] [final value to 14.3] [item

in dividends]

29

(22.25) a [difference 5%] [item dividend] increase...

note from these example sentences that the frame includes target words like rise,

the group in which an item changes the value of an
attribute in a speci   ed way.

figure 22.3 the frame elements in the change position on a scale frame from the framenet labelers
guide (ruppenhofer et al., 2006).

the	
      change	
   position	
   on	
   a	
   scale   	
   frame

soar
mushroom swell
swing
triple
tumble

edge
explode plummet
fall

verbs: dwindle move
advance
climb
decline
decrease    uctuate rise
diminish gain
grow
dip
double
increase skyrocket
jump
drop

rocket
shift

reach

slide

nouns: hike
decline
decrease

increase
rise

tumble

escalation shift
explosion
fall
   uctuation adverbs:
increasingly
gain
growth

30

framenet also codes relationships between frames, allowing frames to inherit

the	
      change	
   position	
   on	
   a	
   scale   	
   frame

8 chapter 22

    id14
core roles

attribute
difference
final state

the attribute is a scalar property that the item possesses.
the distance by which an item changes its position on the scale.
a description that presents the item   s state after the change in the attribute   s
value as an independent predication.
the position on the scale where the item ends up.

final value
initial state a description that presents the item   s state before the change in the at-

tribute   s value as an independent predication.

initial value the initial position on the scale from which the item moves away.
item
value range a portion of the scale, typically identi   ed by its end points, along which the

the entity that has a position on the scale.

values of the attribute    uctuate.

some non-core roles

duration
speed
group

31

the length of time over which the change takes place.
the rate of change of the value.
the group in which an item changes the value of an
attribute in a speci   ed way.

figure 22.3 the frame elements in the change position on a scale frame from the framenet labelers

relation	
   between	
   frames

inherits	
   from:	
   
is	
   inherited	
   by:
perspective	
   on:	
   
is	
   perspectivized in:	
   
uses:	
   
is	
   used	
   by:	
   
subframe of:	
   
has	
   subframe(s):	
   
precedes:	
   
is	
   preceded	
   by:	
   
is	
   inchoative	
   of:	
   
is	
   causative	
   of:

32

diminish gain
dip
grow
increase skyrocket
double
drop
jump

rocket
shift

slide

growth

nouns: hike
decline
decrease

increase
rise

relation	
   between	
   frames

framenet also codes relationships between frames, allowing frames to inherit
from each other, or representing relations between frames like causation (and gen-
   cause	
   change	
   position	
   on	
   a	
   scale   
eralizations among frame elements in different frames can be representing by inher-
is	
   causative	
   of:	
   change_position_on_a_scale
itance as well). thus, there is a cause change of position on a scale frame that is
linked to the change of position on a scale frame by the cause relation, but that
adds	
   an	
   agent	
   role
adds an agent role and is used for causative examples such as the following:
(22.26)

[agent they] raised [item the price of their soda] [difference by 2%].
    add.v,	
   crank.v,	
   curtail.v,	
   cut.n,	
   cut.v,	
   decrease.v,	
   development.n,	
   
together, these two frames would allow an understanding system to extract the
common event semantics of all the verbal and nominal causative and non-causative
diminish.v,	
   double.v,	
   drop.v,	
   enhance.v,	
   growth.n,	
   increase.v,	
   
usages.
knock	
   down.v,	
   lower.v,	
   move.v,	
   promote.v,	
   push.n,	
   push.v,	
   
framenets have also been developed for many other languages including span-
raise.v,	
   reduce.v,	
   reduction.n,	
   slash.v,	
   step	
   up.v,	
   swell.v

ish, german, japanese, portuguese, italian, and chinese.

33

22.6 id14

relations	
   between	
   frames

event

event

place

time

event.n, happen.v, 

occur.v, take place.v, ...

objective_influence

place

time

in   uencing_entity

in   uencing_situation

dependent_entity

affect.v, effect.n, 

impact.n, impact.v, ...

transitive_action

cause_to_make_noise

make_noise

event

place

time

agent

cause

patient

   

purpose

place

time

agent

cause

sound_maker

blare.v, honk.v, play.v, 

ring.v, toot.v, ...

sound

place

time

noisy_event

sound_source
cough.v, gobble.v, 

hiss.v, ring.v, yodel.v, ...

inheritance relation

causative_of relation

excludes relation

34

figure 2:
cause to make noise frame, from the framenet lexicon.

figure	
   from	
   das	
   et	
   al	
   2010

related to the
   core    roles are    lled

illustration of

and lus

frames,

partial

roles,

that frame. experiments demonstrating favorable performance to the previous state of
the art on semeval 2007 and framenet data sets are described in each section. some
novel aspects of our approach include a latent-variable model (section 5.2) and a semi-
supervised extension of the predicate lexicon (section 5.5) to facilitate disambiguation of
words not in the framenet lexicon; a uni   ed model for    nding and labeling arguments

schematic	
   of	
   frame	
   semantics

figure 1
35
an example sentence from the annotations released as part of framenet 1.5 with three targets
marked in bold. note that this annotation is partial because not all potential targets have been

figure	
   from	
   das	
   et	
   al	
   (2014)

framenet complexity

introduction

1

but

there

still

are

n't

enough

ringers

to

ring

more than six of the eight

bells

.

agent

entity

sound_maker

item

enabled_situation

n_m
 
 

frame
noise_makers
cause_to_make_noise
sufficiency
existence

lu
bell.n
ring.v
enough.a
there be.v

figure 1: a sentence from propbank and the semeval   07 training data, and a partial
depiction of gold framenet annotations. each frame is a row below the sentence (or-
dered for readability). thick lines indicate targets that evoke frames; thin solid/dotted
lines with labels indicate arguments.    n m    under bells is short for the noise maker
role of the noise makers frame   it is a denoted frame element because it is also the
target. the last row indicates that there. . . are is a discontinuous target. in propbank, the
36
verb ring is the only annotated predicate for this sentence, and it is not related to other
predicates with similar meanings.

from	
   das	
   et	
   al.	
   2010

framenet and	
   propbank representations

computational linguistics

volume 40, number 1

37

(a)

(b)

semantic	
   role	
   

labeling

semantic	
   role	
   labeling	
   

algorithm

semantic	
   role	
   labeling	
   (srl)	
   

    id14

22.6

9

predicate	
   in	
   a	
   sentence.

    the	
   task	
   of	
   finding	
   the	
   semantic	
   roles	
   of	
   each	
   argument	
   of	
   each	
   
recall that the difference between these two models of semantic roles is that
framenet (22.27) employs many frame-speci   c frame elements as roles, while prop-
bank (22.28) uses a smaller number of numbered argument labels that can be inter-
preted as verb-speci   c labels, along with the more general argm labels. some
examples:

    framenet versus	
   propbank:

(22.27)

(22.28)

[the program]

can   t [blame]

[you]
cognizer
[the san francisco examiner]
arg0

target evaluee
issued
target arg1

[for being unable to identify it]
reason

[a special edition]

[yesterday]
argm-tmp

a simpli   ed id14 algorithm is sketched in fig. 22.4. while
there are a large number of algorithms, many of them use some version of the steps
in this algorithm.

39

history

    semantic	
   roles	
   as	
   a	
   intermediate	
   semantics,	
   used	
   early	
   in

    machine	
   translation	
   (wilks,	
   1973)
    question-     answering	
   (hendrix	
   et	
   al.,	
   1973)
    spoken-     language	
   understanding	
   (nash-     webber,	
   1975)
    dialogue	
   systems	
   (bobrow et	
   al.,	
   1977)

    early	
   srl	
   systems

simmons	
   1973,	
   marcus	
   1980:	
   

    parser	
   followed	
   by	
   hand-     written	
   rules	
   for	
   each	
   verb
    dictionaries	
   with	
   verb-     specific	
   case	
   frames	
   (levin	
   1977)	
   

40

why	
   semantic	
   role	
   labeling

    a	
   useful	
   shallow	
   semantic	
   representation
    improves	
   nlp	
   tasks	
   like:

    question	
   answering	
   

shen	
   and	
   lapata 2007,	
   surdeanu et	
   al.	
   2011

    machine	
   translation	
   

liu	
   and	
   gildea 2010,	
   lo	
   et	
   al.	
   2013

41

extra none role for non-role constituents. most standard classi   cation algorithms
have been used (id28, id166, etc). finally, for each test sentence to be
labeled, the classi   er is run on each relevant constituent. we give more details of
the algorithm after we discuss features.

a	
   simple	
   modern	
   algorithm

function semanticrolelabel(words) returns labeled tree

parse  parse(words)
for each predicate in parse do
for each node in parse do

featurevector  extractfeatures(node, predicate, parse)
classifynode(node, featurevector, parse)

figure 22.4 a generic semantic-role-labeling algorithm. classifynode is a 1-of-n clas-
si   er that assigns a semantic role (or none for non-role constituents), trained on labeled data
such as framenet or propbank.
42

how	
   do	
   we	
   decide	
   what	
   is	
   a	
   predicate

if	
   we   re	
   just	
   doing	
   propbank verbs
    choose	
   all	
   verbs
    possibly	
   removing	
   light	
   verbs	
   (from	
   a	
   list)
if	
   we   re	
   doing	
   framenet (verbs,	
   nouns,	
   adjectives)
    choose	
   every	
   word	
   that	
   was	
   labeled	
   as	
   a	
   target	
   in	
   training	
   data

   

   

43

10 chapter 22

semantic	
   role	
   labeling

    id14

s

np-sbj = arg0

vp

dt

nnp

nnp

nnp

the

san

francisco examiner

vbd = target

np = arg1

pp-tmp = argm-tmp

issued

dt

jj

nn

in

np

a

special

edition

around

nn

np-tmp

noon

yesterday

44
figure 22.5 parse tree for a propbank sentence, showing the propbank argument labels. the dotted line
shows the path feature np"s#vp#vbd for arg0, the np-sbj constituent the san francisco examiner.

features

s

np-sbj = arg0

vp

dt

nnp

nnp

nnp

the

san

francisco examiner

headword	
   of	
   constituent

examiner

headword	
   pos

nnp

voice	
   of	
   the	
   clause

active

subcategorization of	
   pred

vp	
   -     >	
   vbd	
   np	
   pp

45

vbd = target

np = arg1

pp-tmp = argm-tmp

issued

dt

jj

nn

in

np

a

special

edition

around

nn

np-tmp

noon

yesterday

figure 22.5 parse tree for a propbank sentence, showing the propbank argument labels. the dotted line
shows the path feature np"s#vp#vbd for arg0, the np-sbj constituent the san francisco examiner.

named	
   entity	
   type	
   of	
   constit

    the headword of the constituent, examiner. the headword of a constituent
can be computed with standard head rules, such as those given in chapter 11
in fig. ??. certain headwords (e.g., pronouns) place strong constraints on the
possible semantic roles they are likely to    ll.

first	
   and	
   last	
   words	
   of	
   constit

organization

    the headword part of speech of the constituent, nnp.
    the path in the parse tree from the constituent to the predicate. this path is
marked by the dotted line in fig. 22.5. following gildea and jurafsky (2000),
linear	
   position,clause re:	
   predicate
we can use a simple linear representation of the path, np"s#vp#vbd. " and
# represent upward and downward movement in the tree, respectively. the
path is very useful as a compact representation of many kinds of grammatical
function relationships between the constituent and the predicate.

the,	
   examiner

before

path	
   features

    the headword part of speech of the constituent, nnp.
    the path in the parse tree from the constituent to the predicate. this path is
marked by the dotted line in fig. 22.5. following gildea and jurafsky (2000),
we can use a simple linear representation of the path, np"s#vp#vbd. " and
# represent upward and downward movement in the tree, respectively. the
path is very useful as a compact representation of many kinds of grammatical
function relationships between the constituent and the predicate.
    the voice of the clause in which the constituent appears, in this case, active
(as contrasted with passive). passive sentences tend to have strongly different
linkings of semantic roles to surface form than do active ones.

10 chapter 22

francisco examiner

vbd = target

np-sbj = arg0

46

issued

nnp

nnp

nnp

the

san

dt

dt

s

a

    id14

vp

np = arg1

pp-tmp = argm-tmp

jj

special

nn

in

np

edition

around

nn

np-tmp

noon

yesterday

figure 22.5 parse tree for a propbank sentence, showing the propbank argument labels. the dotted line

path in	
   the	
   parse	
   tree	
   from	
   the	
   constituent	
   to	
   the	
   predicate	
   

the most common values of the path feature, along with interpretations, are shown in ta-

ble 3.1.

frequent	
   path	
   features
table 3.1: most frequent values of path feature in the training data.

frequency path

14.2% vb   vp   pp
11.8 vb   vp   s   np
10.1 vb   vp   np
7.9 vb   vp   vp   s   np
4.1 vb   vp   advp
3.0 nn   np   np   pp
1.7 vb   vp   prt
1.6 vb   vp   vp   vp   s   np
14.2
31.4 other

description
pp argument/adjunct
subject
object
subject (embedded vp)
adverbial adjunct
prepositional complement of noun
adverbial particle
subject (embedded vp)
no matching parse constituent

47

for the purposes of choosing a frame element label for a constituent, the path feature is similar

from	
   palmer,	
   gildea,	
   xue 2010

shows the path feature np"s#vp#vbd for arg0, the np-sbj constituent the san francisco examiner.

final	
   feature	
   vector
    for	
      the	
   san	
   francisco	
   examiner   ,	
   
    arg0,	
   [issued,	
   np,	
   examiner,	
   nnp,	
   active,	
   before,	
   vp     np	
   pp,	
   

    the headword of the constituent, examiner. the headword of a constituent
can be computed with standard head rules, such as those given in chapter 11
in fig. ??. certain headwords (e.g., pronouns) place strong constraints on the
possible semantic roles they are likely to    ll.
    the headword part of speech of the constituent, nnp.
    the path in the parse tree from the constituent to the predicate. this path is
marked by the dotted line in fig. 22.5. following gildea and jurafsky (2000),
we can use a simple linear representation of the path, np"s#vp#vbd. " and
# represent upward and downward movement in the tree, respectively. the
path is very useful as a compact representation of many kinds of grammatical
function relationships between the constituent and the predicate.
    the voice of the clause in which the constituent appears, in this case, active
(as contrasted with passive). passive sentences tend to have strongly different
linkings of semantic roles to surface form than do active ones.
    the binary linear position of the constituent with respect to the predicate,
either before or after.
    the subcategorization of the predicate, the set of expected arguments that

    sets	
   of	
   n-     grams	
   inside	
   the	
   constituent
    other	
   path	
   features

    other	
   features	
   could	
   be	
   used	
   as	
   well

    the	
   upward	
   or	
   downward	
   halves
    whether	
   particular	
   nodes	
   occur	
   in	
   the	
   path	
   

org,	
   the,	
   examiner,	
   	
   	
   	
   	
   	
   	
   	
   	
   	
   	
   	
   	
   	
   	
   	
   	
   	
   	
   	
   	
   	
   	
   	
   	
   ]

48

3-     step	
   version	
   of	
   srl	
   algorithm

1. pruning:	
   use	
   simple	
   heuristics	
   to	
   prune	
   unlikely	
   constituents.	
   
2.

identification:	
    a	
   binary	
   classification	
   of	
   each	
   node	
   as	
   an	
   
argument	
   to	
   be	
   labeled	
   or	
   a	
   none.	
   

3. classification:	
   a	
   1-     of-     n	
   classification	
   of	
   all	
   the	
   constituents	
   that	
   

were	
   labeled	
   as	
   arguments	
   by	
   the	
   previous	
   stage	
   

49

why	
   add	
   pruning	
   and	
   identification	
   steps?

   

    algorithm	
   is	
   looking	
   at	
   one	
   predicate	
   at	
   a	
   time
    very	
   few	
   of	
   the	
   nodes	
   in	
   the	
   tree	
   could	
   possible	
   be	
   arguments	
   

of	
   that	
   one	
   predicate
imbalance	
   between	
   
    positive	
   samples	
   (constituents	
   that	
   are	
   arguments	
   of	
   predicate)
    negative	
   samples	
   (constituents	
   that	
   are	
   not	
   arguments	
   of	
   predicate)
imbalanced	
   data	
   can	
   be	
   hard	
   for	
   many	
   classifiers

   
    so	
   we	
   prune	
   the	
   very unlikely	
   constituents	
   first,	
   and	
   then	
   use	
   a	
   

classifier	
   to	
   get	
   rid	
   of	
   the	
   rest.

50

pruning	
   heuristics	
       xue and	
   palmer	
   (2004)

and then a binary classi   er is trained to further separate the positive samples from the negative
samples. the goal of this    ltering process is just to decide whether a constituent is an argument or
not. then a multi-class classi   er is trained to decide the speci   c semantic role for this argument.
in the    ltering stage, it is generally a good idea to be conservative and err on the side of keeping
too many constituents rather than being too aggressive and    ltering out true arguments. this can
be achieved by lowering the threshold for positive samples, or conversely, raising the threshold for
negative samples.
    but	
   ignoring	
   anything	
   in	
   a	
   coordination	
   structure
(20)

    add	
   sisters	
   of	
   the	
   predicate,	
   then	
   aunts,	
   then	
   great-     aunts,	
   etc

s

np

vp

strikes
and

vbd

mismanagement

were

51

s

cc

and

np

premier
ryzhkov

s

vp

vbd

pp

warned

of tough measures

vp

vbd

cited

a	
   common	
   final	
   stage:	
   joint	
   id136

    the	
   algorithm	
   so	
   far	
   classifies	
   everything	
   locally	
       each	
   decision	
   

about	
   a	
   constituent	
   is	
   made	
   independently	
   of	
   all	
   others
    but	
   this	
   can   t	
   be	
   right:	
   lots	
   of	
   global	
   or joint interactions	
   

between	
   arguments
    constituents	
   in	
   framenet and	
   propbank must	
   be	
   non-     overlapping.	
   

    a	
   local	
   system	
   may	
   incorrectly	
   label	
   two	
   overlapping	
   constituents	
   as	
   

arguments	
   

    propbank does	
   not	
   allow	
   multiple	
   identical	
   arguments

    labeling	
   one	
   constituent	
   arg0	
   
    thus	
   should	
   increase	
   the	
   id203	
   of	
   another	
   being	
   arg1	
   

52

how	
   to	
   do	
   joint	
   id136

    reranking

    the	
   first	
   stage	
   srl	
   system	
   produces	
   multiple	
   
possible	
   labels	
   for	
   each	
   constituent
    the	
   second	
   stage	
   classifier	
   the	
   best	
   global label	
   for	
   
all	
   constituents
    often	
   a	
   classifier	
   that	
   takes	
   all	
   the	
   inputs	
   along	
   with	
   
other	
   features	
   (sequences	
   of	
   labels)

53

a 1-of-n classi   er is then trained to predict a semantic role for each constituent
given these features, where n is the number of potential semantic roles plus an
extra none role for non-role constituents. most standard classi   cation algorithms
given these features, where n is the number of potential semantic roles plus an
extra none role for non-role constituents. most standard classi   cation algorithms
have been used (id28, id166, etc). finally, for each test sentence to be
extra none role for non-role constituents. most standard classi   cation algorithms
have been used (id28, id166, etc). finally, for each test sentence to be
labeled, the classi   er is run on each relevant constituent. we give more details of
have been used (id28, id166, etc). finally, for each test sentence to be
labeled, the classi   er is run on each relevant constituent. we give more details of
the algorithm after we discuss features.
labeled, the classi   er is run on each relevant constituent. we give more details of
the algorithm after we discuss features.
the algorithm after we discuss features.

more	
   complications:	
   framenet

we	
   need	
   an	
   extra	
   step	
   to	
   find	
   the	
   frame

function semanticrolelabel(words) returns labeled tree
function semanticrolelabel(words) returns labeled tree
function semanticrolelabel(words) returns labeled tree

parse  parse(words)
for each predicate in parse do
parse  parse(words)
predicatevector       extractframefeatures(predicate,parse)
for each node in parse do
for each predicate in parse do
parse  parse(words)
frame	
         classifyframe(predicate,predicatevector)
featurevector  extractfeatures(node, predicate, parse)
for each node in parse do
for each predicate in parse do
classifynode(node, featurevector, parse)
featurevector  extractfeatures(node, predicate, parse)
for each node in parse do
classifynode(node, featurevector, parse)
featurevector  extractfeatures(node, predicate, parse)
classifynode(node, featurevector, parse)

,	
   frame)

figure 22.4 a generic semantic-role-labeling algorithm. classifynode is a 1-of-n clas-
si   er that assigns a semantic role (or none for non-role constituents), trained on labeled data
figure 22.4 a generic semantic-role-labeling algorithm. classifynode is a 1-of-n clas-
such as framenet or propbank.
si   er that assigns a semantic role (or none for non-role constituents), trained on labeled data
figure 22.4 a generic semantic-role-labeling algorithm. classifynode is a 1-of-n clas-
54
such as framenet or propbank.
si   er that assigns a semantic role (or none for non-role constituents), trained on labeled data
such as framenet or propbank.

das	
   et	
   al	
   (2014)

features	
   for	
   frame	
   identification
table 4
features used for frame identi   cation (equation (2)). all also incorporate f , the frame being
scored.     =    w   ,          consists of the words and pos tags20 of a target seen in an exemplar or
training sentence as evoking f . the features with starred bullets were also used by johansson
and nugues (2007).
    the pos of the parent of the head word of ti
       the set of syntactic dependencies of the head word21 of ti
       if the head word of ti is a verb, then the set of dependency labels of its children
    the dependency label on the edge connecting the head of ti and its parent
    the sequence of words in the prototype, w   
    the lemmatized sequence of words in the prototype
    the lemmatized sequence of words in the prototype and their part-of-speech tags      
    id138 relation22    holds between     and ti
    id138 relation22    holds between     and ti, and the prototype is    
    id138 relation22    holds between     and ti, the pos tag sequence of     is      , and the pos

tag sequence of ti is   t

exemplar sentences. note that this model makes an independence assumption: each
frame is predicted independently of all others in the document. in this way the model
is similar to j&n   07. however, ours is a single conditional model that shares features
55
and weights across all targets, frames, and prototypes, whereas the approach of j&n   07

a constituent in a parse tree receives multiple semantic roles when there is argument sharing where
this constituent plays a role for multiple predicates. this can happen in a coordination structure
when multiple predicates are conjoined and share a subject. this can also happen in subject control
or object control structures when two verbs share a subject or an object.

not	
   just	
   english

(22)

arg0

(cid:44)(cid:51)

(cid:57)(cid:51)

(cid:49)(cid:51)(cid:16)(cid:54)(cid:37)(cid:45)

argm-tmp

argm-mnr

(cid:57)(cid:51)

      
(cid:83)(cid:82)(cid:79)(cid:76)(cid:70)(cid:72)

(cid:36)(cid:39)(cid:57)(cid:51)(cid:16)(cid:55)(cid:48)(cid:51)

(cid:36)(cid:39)(cid:57)(cid:51)(cid:16)(cid:48)(cid:49)(cid:53)

      
(cid:81)(cid:82)(cid:90)

      

(cid:87)(cid:75)(cid:82)(cid:88)(cid:85)(cid:82)(cid:88)(cid:74)(cid:75)(cid:79)(cid:92)

rel

(cid:57)(cid:57)

      

(cid:76)(cid:81)(cid:89)(cid:72)(cid:86)(cid:87)(cid:76)(cid:74)(cid:68)(cid:87)(cid:72)

56

(cid:179)(cid:55)(cid:75)(cid:72) (cid:83)(cid:82)(cid:79)(cid:76)(cid:70)(cid:72) (cid:68)(cid:85)(cid:72) (cid:87)(cid:75)(cid:82)(cid:85)(cid:82)(cid:88)(cid:74)(cid:75)(cid:79)(cid:92) (cid:76)(cid:81)(cid:89)(cid:72)(cid:86)(cid:87)(cid:76)(cid:74)(cid:68)(cid:87)(cid:76)(cid:81)(cid:74) (cid:87)(cid:75)(cid:72) (cid:70)(cid:68)(cid:88)(cid:86)(cid:72) (cid:82)(cid:73) (cid:87)(cid:75)(cid:72) (cid:68)(cid:70)(cid:70)(cid:76)(cid:71)(cid:72)(cid:81)(cid:87)(cid:17)(cid:180)

arg1

(cid:49)(cid:51)(cid:16)(cid:50)(cid:37)(cid:45)

(cid:49)(cid:49)

      
(cid:70)(cid:68)(cid:88)(cid:86)(cid:72)

(cid:49)(cid:49)

      

(cid:68)(cid:70)(cid:70)(cid:76)(cid:71)(cid:72)(cid:81)(cid:87)

not	
   just	
   verbs:	
   nombank

meyers	
   et	
   al.	
   2004

s

                  

np

                  
               

vbd

vp

(arg0)

                   

nnp

nnp

ben

bernanke

was

               
               

vp

vbn
(support)

nominated

               
               

pp

in

as

               
np
            
            
nn
np
         
ppp
greenspan    s

(arg1)

predicate

replacement

57

figure	
   from	
   jiang	
   and	
   ng	
   2006
figure 1: a sample sentence and its parse tree la-

2004) experimented with an automatic srl sys-
tem developed using a relatively small set of man-
ually selected nominalizations from framenet and
penn chinese treebank. the srl accuracy of
their system is not directly comparable to ours.
3 model training and testing
we treat the nombank-based srl task as a clas-
si   cation problem and divide it into two phases:
argument identi   cation and argument classi   ca-
tion. during the argument identi   cation phase,
each parse tree node is marked as either argument

additional	
   issues	
   for	
   nouns

    features:

    nominalization	
   lexicon	
   (employment      employ)
    morphological	
   stem

    healthcare,	
   medicate	
         care

    different	
   positions

    most	
   arguments	
   of	
   nominal	
   predicates	
   occur	
   inside	
   the	
   np
    others	
   are	
   introduced	
   by	
   support	
   verbs
    especially	
   light	
   verbs	
   	
      x	
   made	
   an	
   argument   ,	
      y	
   took	
   a	
   nap   

58

semantic	
   role	
   

labeling

conclusion

semantic	
   role	
   labeling

    a	
   level	
   of	
   shallow	
   semantics	
   for	
   representing	
   events	
   and	
   their	
   

participants
    intermediate	
   between	
   parses	
   and	
   full	
   semantics

    two	
   common	
   architectures,	
   for	
   various	
   languages

    framenet:	
   frame-     specific	
   roles
    propbank:	
   proto-     roles

    current	
   systems	
   extract	
   by	
   

    parsing	
   sentence
    finding	
   predicates	
   in	
   the	
   sentence

60

    for	
   each	
   one,	
   classify	
   each	
   parse	
   tree	
   constituent

