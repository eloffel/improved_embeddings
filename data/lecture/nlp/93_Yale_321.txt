nlp
text similarity
the vector space model
vectors, matrices, and tensors
x = <x1, x2,    , xn>: a vector of n dimensions. 
x1,    , xn can take either binary values {0, 1}, or real values
vectors and matrices provide a natural way to represent the occurrence of words in a document/query. 
in text analysis, n is usually the size of the vocabulary, so each dimension corresponds to a unique word
x can be used to represent a document, or a query, or    
so xi indicates either    whether the i-th word in the vocabulary appears    (binary value), or    how many times does the i-th word appear    (real value). 
the entire collection is thus represented as a matrix. 
how?
example of document vectors
doc 1=    information retrieval   
doc 2 =    computer information retrieval   
doc 3 =    computer retrieval   

vocabulary: information, retrieval, computer
doc 1 = <1, 1, 0>
doc 2 = <1, 1, 1>
doc 3 = <0, 1, 1>



question: doc 4 =    retrieval information retrieval    ?


d = 
information, retrieval, computer
documents in a vector space
doc 1=    information retrieval   
doc 2 =    computer information retrieval   
doc 3 =    computer retrieval   


vocabulary: information, retrieval, computer
doc 1 = <1, 1, 0>





term 1: information
term 3: computer
term 2:
retrieval

doc 1
relevance as vector similarities
doc 1=    information retrieval   
doc 2 =    computer information retrieval   
doc 3 =    computer retrieval   







doc 1
doc 2
doc 3
which document is closer to doc 1? doc 2 or doc 3?
what if we have a query    retrieval   ?
term 3: computer
term 2:
retrieval
term 1: information
document similarity
used in information retrieval to determine which document (d1 or d2) is more similar to a given query q.
documents and queries are represented in the same space.
angle (or cosine) is a proxy for similarity between two vectors

distance/similarity calculation
the similarity/relevance of two vectors can be calculated based on distance/similarity measures
s: x, y     (0, 1)
x: <x1, x2,    , xn>
y: <y1, y2,    , yn>

s(x, y) = ?
the more dimensions in common, the larger the similarity
what about real values?
id172 needed.

similarity measures
similarity measures




x
y

z
euclidean distance     distance of two points
similarity measures (cont.)



x
y


which one do you think is suitable for retrieval?
jaccard? euclidean? cosine? 
cosine similarity: similarity of two vectors, normalized
example
what is the cosine similarity between:
d=    cat,dog,dog    = <1,2,0>
q=    cat,dog,mouse,mouse    = <1,1,2>
answer:


in comparison:

quiz
given three documents
d1 = <1,3>
d2 = <10,30>
d3 = <3,1>
compute the cosine scores
  (d1,d2) 
  (d1,d3)
what do the numbers tell you?
answers to the quiz
  (d1,d2) = 1
one of the two documents is a scaled version of the other
  (d1,d3) = 0.6
swapping the two dimensions results in a lower similarity
quiz
what is the range of values that the cosine scores can take?
answer to the quiz
mathematically, the cosine function has a  range of [-1,1]
however, when the two vectors are both in the first quadrant (since all word counts are non-negative), the range is [0,1]
for id27s, the range is [-1,1] (since the values don   t have to be non-negative)
nlp
