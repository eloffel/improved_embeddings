extending a single-document summarizer to multi-document: a

hierarchical approach

lu    s marujo1,2,3, ricardo ribeiro1,4, david martins de matos1,2,

jo  ao p. neto1,2, anatole gershman3, and jaime carbonell3

1inesc-id lisboa, 2ist/ulisboa, 4iscte-iul, lisboa, portugal

3school of computer science, cmu, pittsburgh, usa
{lmarujo,anatoleg,jgc}@cs.cmu.edu

{ricardo.ribeiro,david.matos,joao.neto}@inesc-id.pt

5
1
0
2

 
l
u
j
 

0
1

 
 
]

r

i
.
s
c
[
 
 

1
v
7
0
9
2
0

.

7
0
5
1
:
v
i
x
r
a

abstract

the increasing amount of online content mo-
tivated the development of multi-document
summarization methods.
in this work, we
explore straightforward approaches to extend
single-document summarization methods to
id57.
the pro-
posed methods are based on the hierarchical
combination of single-document summaries,
and achieves state of the art results.

introduction

1
the use of the internet to ful   ll generic informa-
tion needs motivated pioneer multi-document sum-
marization efforts as newsinessence (radev et al.,
2005) or newsblaster (mckeown et al., 2002), on-
line since 2001.
in general, multi-document sum-
marization approaches have to address two differ-
ent problems: passage selection and information or-
dering. current multi-document systems adopt, for
passage selection, approaches similar to the ones
used in single-document summarization, and use the
chronological order of the documents for informa-
tion ordering (christensen et al., 2013). the prob-
lem is that most approaches fail to generate sum-
maries that cover generic topics which comprehend
different, equally important, subtopics.

a

we

extend

to
state-of-the-art
propose
single-document
summarization method, kp-
centrality (ribeiro et al., 2013), capable of
focusing on diverse important topics while ignoring
unimportant ones, to perform multi-document sum-
marization. we explore two hierarchical strategies
to perform this extension.

this document is organized as follows: sect. 2 ad-
dresses the related work; sect. 3 presents our multi-
document summarization appproach; experimental
results close the paper.

2 related work

most of the current work in automatic summariza-
tion focuses on extractive summarization. the most
popular baselines for multi-document summariza-
tion fall into one of the following general mod-
els: centrality-based (radev et al., 2004; erkan
and radev, 2004; wang et al., 2008; ribeiro and
de matos, 2011), maximal marginal relevance
(mmr) (carbonell and goldstein, 1998; guo and
sanner, 2010; sanner et al., 2011; lim et al., 2012),
and coverage-base methods (lin and hovy, 2000;
sipos et al., 2012). additionally, methods such as
kp-centrality (ribeiro et al., 2013), which is
centrality and coverage-based, follow more than one
paradigm. in general, centrality-based models are
used to produce generic summaries, while the mmr
family generates query-oriented ones. coverage-
base models produce summaries driven by words,
topics or events.

centrality-as-relevance methods base the detec-
tion of the most salient passages on the identi   cation
of the central passages of the input source(s). one of
the main representatives of this family is passage-
to-centroid similarity-based centrality. centroid-
based methods build on the idea of a pseudo-passage
that represents the central topic of the input source   
the centroid   selecting as passages to be included in
the summary the ones that are close to the centroid.
another approach to centrality estimation is to com-

pare each candidate passage to every other passage
and select the ones with higher scores (the ones that
are closer to every other passage): the pair-wise pas-
sage similarity-based centrality.

mmr (carbonell and goldstein, 1998) is a query
driven relevance model based on the following
mathematical model:

arg max

si

  (sim1(si, q))   (1     )(max

sj

sim2(si, sj))

(cid:104)

(cid:105)

where sim1 and sim2 are similarity metrics that
do not have to be different; si are the yet unselected
passages and sj are the previously selected ones; q
is the required query to apply the model; and,    is
a parameter that allows to con   gure the result to be
from a standard relevance-ranked list (   = 1) to a
maximal diversity ranking (   = 0).

coverage-based summarization de   nes a set of
concepts that need to occur in the sentences selected
for the summaries. the concepts are events (filatova
and hatzivassiloglou, 2004), topics (lin and hovy,
2000), salient words (lin and bilmes, 2010; sipos
et al., 2012), and word id165s (gillick et al., 2008;
almeida and martins, 2013).

3 id57

our multi-document approach is built upon a cen-
trality and coverage-based single-document summa-
rization method, kp-centrality (ribeiro et al.,
2013). this method, through the use of key phrases,
is easily adaptable and has been shown to be robust
in the presence of noisy input. this is an important
aspect considering that using as input several docu-
ments frequently increases the amount of unimpor-
tant content).

when adapting a single-document summarization
method to perform id57,
a possible strategy is to combine the summaries of
each document. to iteratively combine the sum-
maries, we explore two different approaches: single-
layer hierarchical and waterfall. given that the sum-
marization method also uses as input a set of key
phrases, we extract from each input document the
required set of key phrases, join the extracted sets,
and rank the key phrases using their frequency. to
generate each summary, we use the top key phrases,
excluding the ones that do not occur in the input doc-
ument.

3.1 single-document summarization method
to retrieve the most important sentences of an in-
formation source, we used the kp-centrality
method (ribeiro et al., 2013). we chose this model
for its adaptability to different types of information
sources (e.g., text, audio and video), while support-
ing privacy (marujo et al., 2014), and offering state-
of-art performance. it is based on the notion of com-
bining key phrases with support sets. a support set
is a group of the most semantically related passages.
these semantic passages are chosen using heuristics
based on the passage order method (ribeiro and de
matos, 2011). this type of heuristics uses the struc-
ture of the input document (source) to partition the
candidate passages to be included in the support set
in two subsets: the ones closer to the passage asso-
ciated with the support set under construction and
the ones further apart. these heuristics use a per-
n   1, of the distances of the
mutation, di
passages sk to the passage pi, related to the support
k = dist(sk, pi), 1    
set under construction, with di
k     n     1, where n is the number of passages, cor-
responding to the order of occurrence of passages sk
in the input source. the metric that is normally used
is the cosine distance.

2,       , di

1, di

the kp-centrality method consists of two steps.
first, it extracts key phrases using a supervised ap-
proach (marujo et al., 2012) and combines them
with a bag-of-words model in a compact matrix rep-
resentation, given by:

         w(t1, p1) . . . w(t1, pn ) w(t1, k1) . . . w(t1, km )

...

...

w(tt , p1) . . . w(tt , pn ) w(tt , k1) . . . w(tt , km )
(1)
where w is a function of the number of occur-
rences of term ti in passage pj or key phrase kl,
t is the number of terms and m is the number of
key phrases. then, using a segmented information
source i (cid:44) p1, p2, . . . , pn , a support set si is com-
puted for each passage pi using:
si (cid:44) {s     i     k : sim(s, qi) >   i     s (cid:54)= qi}, (2)
for i = 1, . . . , n + m. passages are ranked exclud-
ing the key phrases k (arti   cial passages) accord-
ing to:

(cid:12)(cid:12){si : s     si}(cid:12)(cid:12).

(3)

arg max

s   (   n

i=1si)   k

          ,

3.2 single-layer hierarchical
in this model, we use kp-centrality to generate,
for each news document, an intermediate summary
with the same size of the output summary for the in-
put documents. an aggregated summary is obtained
by concatenating the chronologically ordered inter-
mediate summaries. the output summary is again
generated by applying kp-centrality to the ag-
gregated summary as figure 1 shows.

figure 1: single-layer architecture.

3.3 waterfall
this model differs from the previous one in the
merging process. the underlying merging of the
documents follows a cascaded process: it starts by
merging the intermediate summaries, with the same
size of the output summary, of the    rst two docu-
ments, according to their chronological order. this
document is then summarized and merged with the
summary of following document. we iterate this
process through all the documents until the most re-
cent one as figure 2 illustrates.

figure 2: waterfall architecture.

4 experimental results

we compare the performance of our methods against
other representative models, namely mead, mmr,
expected n-call@k (lim et al., 2012), and the port-
folio theory (wang and zhu, 2009). mead is a
centroid-based method and one of the most popu-
lar centrality-based methods. mmr is one of the
most used query-based methods. expected n-call@k
adapts and extends mmr as a probabilistic model
(probabilistic latent mmr). the portfolio theory
also extends mmr based on the idea of ranking un-
der uncertainty. as baseline, we used the straight-
forward idea of combining all input documents into
a single one, and then submit the document to the
single-document summarization method. consider-
ing that most coverage-based systems explore event
information, we opted for not including them in this
comparative analysis.

to assess the informativeness of the summaries
generated by our methods, we used id8-1 and
id8-2 (lin, 2004) on duc 2007 and tac 2009
datasets. the main summarization task in duc
20071 is the generation of 250-word summaries of
45 clusters of 25 newswire documents (from the
aquaint corpus) and 4 human reference sum-
maries. the tac 2009 summarization task2 has 44
topic clusters. each topic has 2 sets of 10 news docu-
ments obtained from the aquaint 2 corpus.there
are 4 human 100-word reference summaries for each
set, where the reference summaries for the    rst set
are query-oriented, and for the second set are update
summaries. in this work, we used the    rst set of ref-
erence summaries. we evaluate the different models
by generating summaries with 250 words. we only
present the best results.

the used features include the bag-of-words model
representation of the sentences (tf-idf), the key
phrases and the query (obtained from the topics de-
scriptions).
including the query is a new exten-
sion to the kp-centrality method, which, in
general, improved the results. we experimented
with different numbers of key phrases, obtaining
the best results with 40 key phrases. to compare
and rank the sentences, we use several distance met-
rics, namely: frac133 (generic minkowski distance,

1http://www-nlpir.nist.gov/projects/duc/duc2007/tasks.html
2http://www.nist.gov/tac/2009/summarization/

distance
frac133
cosine
frac133
frac133
cosine
cosine
frac133
cosine

model

baseline

waterfall
single-layer
waterfall
single-layer

single-layer (shuf   e)
waterfall (shuf   e)
mead
mmr

e.n-call@k
portfolio
lexrank

duc 2007
r2
r1

tac 2009
r2
r1

0.3565
0.3406
0.3569
0.3775
0.3701
0.3707
0.3689
0.3626
0.3282
0.3269
0.3209
0.3595
0.2881

0.0744
0.0670
0.0765
0.0882
0.0904
0.0822
0.0807
0.0844
0.0765
0.0780
0.0701
0.0792
0.0534

0.4706
0.4746
0.4943
0.4983
0.5137
0.4993
0.5060
0.5107
0.4153
0.3917
0.3873
0.4292
0.3845

0.1268
0.1391
0.1441
0.1526
0.1693
0.1590
0.1483
0.1630
0.0845
0.0801
0.0699
0.0758
0.0623

table 1: id8-1 (r1) and id8-2 (r2) scores.

with n = 1.(3)), euclidean, chebyshev, manhat-
tan, minkowski, the jensen-shannon divergence,
and the cosine similarity. table 1 shows that the
best results were obtained by the proposed hierar-
chical models, in both datasets. overal, the best
performing distance metric for our centrality-based
method was the cosine similarity and the best strat-
egy for combining the information was the water-
fall approach, namely, in terms of id8-2.
in
duc 2007, frac133 using the single-layer method
achieved the best id8-1 score, although the dif-
ference for cosine is hardly noticeable. single-layer
with frac133 shows a performance improvement
of 0.0180 id8-1 points (relative performance
improvement of 5.0%) over the best of the other
systems, portfolio, in duc 2007, and of 0.0845
id8-1 points (19.7% relative performance im-
provement) in tac 2009.
in terms of id8-
2, the waterfall method using cosine achieved an
improvement of 0.0112 (relative performance im-
provement of 14.1%) over portfolio, in duc 2007,
and of 0.0848 (relative performance improvement
of 100.4%) over mead, the best performing of the
reference systems using this metric, in tac 2009.
note that our baseline obtained results similar to the
best reference system in duc 2007 and better re-
sults than all reference systems in tac 2009 (0.0454
id8-1 points corresponding to a 10.6% rela-
tive performance improvement; 0.0546 id8-2

points corresponding to a 64.6% relative perfor-
mance improvement). the better results obtained on
the tac 2009 dataset are due to the small size of
the reference summaries and to the fact that the doc-
uments sets to be summarized contain topics with
higher diversity of subtopics.

the shuf   e results included in table 1 are aver-
ages of 10 trials. they are lower than the other ob-
tained using the documents organized in chronolog-
ical order. this suggests that the order of the input
documents is important to the summarization meth-
ods.

figure 3 shows an example of summary produced
by our multi-document method. the    gure also in-
cludes the respective reference summary for com-
parison.

5 conclusions and future work

in this work, we explore two different approaches to
extend a single-document summarization method to
id57: single-layer hierar-
chical and waterfall.

experimental results show that the proposed ap-
proaches perform better than previous state-of-the-
art methods on standard datasets used to evaluate
this task. in general, the best performing approach is
the waterfall approach using the cosine similarity. in
fact, this con   guration achieves the best results on
the tac 2009 dataset, considering both id8-1

generated summary:

president bill clinton said friday he will appeal a fed-
eral judge   s ruling that struck down a law giving the pres-
ident the power to veto speci   c items in bills passed by
congress. the law, passed by congress last year, allowed
the president for the    rst time to veto particular items in
spending bills and certain limited tax provisions passed
by congress. clinton said the funding that congress
has added to the bill is excessive and threatened to veto
some items by using the line-item veto power. the white
house said that the president used his authority to can-
cel projects that were not requested in the budget and
would not substantially improve the quality of life of mil-
itary service members. judge thomas hogan ruled that
the law     which gives the president the power to strike
items from tax and spending measures without vetoing
the entire bill     violates the traditional balance of pow-
ers between the various branches of government    the
line-item veto act is unconstitutional because it imper-
missibly disrupts the balance of powers among the three
branches of government,    said thomas hogan.    in its ap-
peal, the justice department argues that the new chal-
lengers also do not have standing to challenge the law,
and that in any case the law is in line with the historic
relationship between congress and the president.

reference summary:

congress passed a law authorizing the line item veto
(liv) in 1996 accepting arguments that the measure
would help preserve the integrity of federal spending by
allowing the president to strike unnecessary spending and
tax items from legislation thus encouraging the govern-
ment to live within its means. it was considered in line
with the historic relationship between congress and the
president and would provide a tool for eliminating waste-
ful pork barrel spending while enlivening debate over the
best use of funds. it was argued that the liv would rep-
resent presidential exercise of spending authority dele-
gated by congress. president clinton exercised the liv
on 82 items in 1997 saving $1.9 billion in spending pro-
jected over    ve years. the affected items were projects
for speci   c localities, many in the area of military con-
struction, which had been added to the president   s budget
by congress. the    rst court ruling on the liv act was in
u.s. district court when in february 1998 it was ruled
unconstitutional on the grounds that it violated the sep-
aration of powers. the department of justice appealed
that decision and in june 1998 the supreme court ruled
the liv act unconstitutional but on the grounds that it vi-
olated article i, 7, clause 2 (the    presentment clause   )
of the constitution that establishes the process by which
a bill becomes law. president clinton expressed his deep
disappointment.

figure 3: example of summary produced by our summa-
rizer and the reference summary topic d0730g of duc
2007

and id8-2 metrics, and, although not achieving
the best results in the duc 2007 dataset, in terms of
id8-1, it also achieves a performance improve-
ment over portfolio of 0.0106 id8-1 points (rel-
ative performance improvement of 3%).

in future work, we aim to adapt the proposed
id57 method to perform
abstractive summarization.

acknowledgments
this work has been partially supported by national
funds through fundac    ao para a ci  encia e a tecnolo-
gia (fct) with reference uid/cec/50021/2013, the
grant numbers sfrh/bd/33769/2009 and cmup-
epb/tic/0026/2013. the authors would also like
to thank eduard hovy, isabel trancoso, ricardo
baeza-yates, and the anonymous reviewers for fruit-
ful comments.

references
[almeida and martins2013] miguel almeida and andre
martins. 2013. fast and robust compressive summa-
rization with id209 and multi-task learn-
in proceedings of the 51st annual meeting of
ing.
the association for computational linguistics, pages
196   206, so   a, bulgaria, august. acl.

[carbonell and goldstein1998] jaime carbonell and jade
goldstein. 1998. the use of mmr, diversity-based
reranking for reordering documents and producing
summaries. in proceedings of the 21st annual inter-
national acm sigir conference on research and de-
velopment in information retrieval, pages 335   336.
acm.

[christensen et al.2013] janara christensen, mausam,
stephen soderland, and oren etzioni. 2013. towards
coherent id57. in proceed-
ings of the north american chapter of the association
for computational linguistics. acl.

[erkan and radev2004] g  unes   erkan and dragomir r.
radev. 2004. lexrank: graph-based centrality as
salience in text summarization. journal of arti   cial
intelligence research, 22:457   479.

[filatova and hatzivassiloglou2004] elena filatova and
vasileios hatzivassiloglou. 2004. event-based ex-
tractive summarization. in proc. of acl workshop on
summarization, pages 104   111.

[gillick et al.2008] dan gillick, benoit favre, and dilek
hakkani-tur. 2008. the icsi summarization system
at tac 2008. in proceedings of the text understanding
conference.

[ribeiro et al.2013] ricardo ribeiro, lu    s marujo, david
martins de matos, jo  ao p. neto, anatole gershman,
and jaime carbonell. 2013. self reinforcement for
important passage retrieval. in proceedings of the 36th
international acm sigir conference on research
and development in information retrieval, pages 845   
848. acm.

[sanner et al.2011] scott sanner, shengbo guo, thore
graepel, sadegh kharazmi, and sarvnaz karimi.
2011. diverse retrieval via greedy optimization of ex-
pected 1-call@k in a latent subtopic relevance model.
in proc. of the 20th acm international conference
on information and knowledge management, pages
1977   1980. acm.

[sipos et al.2012] ruben sipos, adith swaminathan, pan-
naga shivaswamy, and thorsten joachims.
2012.
temporal corpus summarization using submodular
word coverage. in proc. of the 21st acm international
conference on information and knowledge manage-
ment. acm.

[wang and zhu2009] jun wang and jianhan zhu. 2009.
portfolio theory of information retrieval. in proceed-
ings of the 32nd international acm sigir confer-
ence on research and development in information re-
trieval, pages 115   122.

[wang et al.2008] dingding wang, tao li, shenghuo
zhu, and chris ding. 2008. multi-document sum-
marization via sentence-level semantic analysis and
in proc. of the 31st
symmetric id105.
annual international acm sigir conference on re-
search and development
in information retrieval,
pages 307   314. acm.

[guo and sanner2010] shengbo guo and scott sanner.
2010.
probabilistic latent maximal marginal rele-
vance. in proc. of the 33rd international acm sigir
conference on research and development in informa-
tion retrieval, pages 833   834. acm.

[lim et al.2012] kar wai lim, scott sanner, and shengbo
guo.
2012. on the math. relationship between
expected n-call@k and the relevance vs. diversity
trade-off. in proc. of the 35th international acm si-
gir conference on research and development in in-
formation retrieval, pages 1117   1118. acm.

[lin and bilmes2010] hui lin and jeff bilmes. 2010.
id57 via budgeted maxi-
mization of submodular functions. in proceedings of
the north american chapter of the association for
computational linguistics, pages 912   920. acl.

[lin and hovy2000] chin-yew lin and eduard hovy.
2000. the automated acquisition of topic signatures
in proceedings of the 18th
for text summarization.
conference on computational linguistics - volume 1,
pages 495   501. acl.

[lin2004] chin-yew lin. 2004. id8: a package for
in text summ.

automatic evaluation of summaries.
branches out: proc. of the acl-04 workshop.

[marujo et al.2012] lu    s marujo, anatole gershman,
jaime carbonell, robert frederking, and jo  ao p.
neto. 2012. supervised topical key phrase extrac-
tion of news stories using id104, light    lter-
ing and co-reference id172. in proceedings of
the eight international conference on language re-
sources and evaluation (lrec   12). elra.
jos  e

port  elo,
david martins de matos, jo  ao p neto, anatole
gershman, jaime carbonell, isabel trancoso, and
bhiksha raj.
2014. privacy-preserving important
passage retrieval. in acm sigir pir workshop.

[marujo et al.2014] lu    s marujo,

[mckeown et al.2002] kathleen r. mckeown, regina
barzilay, david evans, vasileios hatzivassiloglou, ju-
dith l. klavans, ani nenkova, carl sable, barry
schiffman, and sergey sigelman. 2002. tracking and
summarizing news on a daily basis with columbia   s
newsblaster. in hlt.

[radev et al.2004] dragomir r. radev, hongyan jing,
ma  gorzata sty  s, and daniel tam. 2004. centroid-
infor-
based summarization of multiple documents.
mation processing and management, 40.

[radev et al.2005] dragomir r. radev,

jahna otter-
bacher, adam winkel, and sasha blair-goldensohn.
2005. newsinessence: summarizing online news
topics. communications of the acm, 48(10):95   98.

[ribeiro and de matos2011] ricardo

and
david martins de matos. 2011. revisiting centrality-
as-relevance:
support sets and similarity as
geometric proximity. jair, 42:275   308.

ribeiro

