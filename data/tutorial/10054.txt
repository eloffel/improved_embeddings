proceedings of the international meeting on high-dimensional data-driven science (hd3-2015)
december 14   17, 2015, kyoto, japan

6
1
0
2

 

b
e
f
6
1

 

 
 
]

r

i
.
s
c
[
 
 

1
v
0
3
9
4
0

.

2
0
6
1
:
v
i
x
r
a

generalized minimum dominating set and
application in automatic text summarization

yi-zhi xu and hai-jun zhou
state key laboratory of theoretical physics, institute of theoretical physics, chinese
academy of sciences, zhong-guan-cun east road 55, beijing 100190, china

e-mail: xyz@itp.ac.cn, zhouhj@itp.ac.cn

abstract. for a graph formed by vertices and weighted edges, a generalized minimum
dominating set (mds) is a vertex set of smallest cardinality such that the summed weight of
edges from each outside vertex to vertices in this set is equal to or larger than certain threshold
value. this generalized mds problem reduces to the conventional mds problem in the limiting
case of all the edge weights being equal to the threshold value. we treat the generalized mds
problem in the present paper by a replica-symmetric spin glass theory and derive a set of belief-
propagation equations. as a practical application we consider the problem of extracting a set
of sentences that best summarize a given input text document. we carry out a preliminary test
of the statistical physics-inspired method to this automatic text summarization problem.

1. introduction
minimum dominating set (mds) is a well-known concept in the computer science community
(see review [1]). for a given graph, a mds is just a minimum-sized vertex set such that either a
vertex belongs to this set or at least one of its neighbors belongs to this set. in the last few years
researchers from the statistical physics community also got quite interested in this concept, as
it is closely related to various network problems such as network monitoring, network control,
infectious disease suppression, and resource allocation (see, for example, [2, 3, 4, 5, 6, 7, 8, 9, 10]
and review [11]). constructing an exact mds for a large graph is, generally speaking, an
extremely di   cult task and it is very likely that no complete algorithm is capable of solving it
in an e   cient way. on the other hand, by mapping the mds problem into a spin glass system
with local many-body constraints and then treating it by statistical-physics methods, one can
estimate with high empirical con   dence the sizes of minimum dominating sets for single graph
instances [12, 13]. one can also construct close-to-minimum dominating sets quickly through
a physics-inspired heuristic algorithm [12, 13], which might be important for many practical
applications.

in the present work we extend the statistical-physics approach of [12, 13] to edge-weighted
graphs and study a generalized minimum dominating set problem. our work is motivated by
a practical knowledge-mining problem: extracting a set of sentences to best summarize one or
more input text documents [14, 15]. we consider a general graph of vertices and edges, each
edge connecting two di   erent vertices and bearing one weight or a pair of weights (see fig. 1).
in the context of text summarization, a vertex represents a sentence of some text documents
and an edge weight is the similarity between two sentences. various data-id91 problems

figure 1. an graph with n = 12 vertices and m = 21 weighted edges. in this example the two
weights wi,j and wj,i of each edge (i, j) are equal (wi,j = wj,i), and the threshold value of each
vertex is    = 1.0. the vertex set   0 = {3, 5, 6, 7, 10, 11} is a generalized minimum dominating
set for this graph. the summed weight of edges from every vertex j /      0 to vertices in   0 is
equal to or greater than   .

can also be represented as weighted graphs. given such a weighted graph, our task is then to
construct a minimum-cardinality set   0 of vertices such that if a vertex i is not included in   0,
the summed weight of the edges from i to vertices in   0 must reach at least certain threshold
value   . the set   0 is referred to as a (generalized) mds.

we introduce a spin glass model for this generalized mds problem in sec. 2 and then describe
a replica-symmetric (rs) mean    eld theory in sec. 3. a message-passing algorithm bpd (belief-
propagation guided decimation) is outlined in sec. 4, and is then applied to the automatic text
summarization problem in sec. 5. we conclude this work in sec. 6 and discuss a way of modifying
the spin glass model for better treating the text summarization problem.

2. constraints and a spin glass model
we consider a generic graph g formed by n vertices with indices i, j, k, . . .     {1, 2, . . . , n} and
m = (c/2)n edges between pairs of these vertices (fig. 1). the constant c is the mean vertex
degree of the graph (on average a vertex is attached with c edges). each edge (i, j) is associated
with a pair of non-negative weights wi,j and wj,i which may or may not be equal. the meaning
of the edge weights depend on the actual context. for example, wi,j may be interpreted as
the extent that vertex i represents vertex j; in the symmetric case of wi,j = wj,i, we may also
interpret wi,j as the similarity between i and j. two vertices i and j are referred to as mutual
neighbors if they are connected by an edge (i, j). the set of neighbors of vertex i is denoted as
   i, i.e.,    i     {j | (i, j)     g}.

i /      0 (referred to as being empty). for each vertex j /      0 we require that (cid:80)
(cj = 1) or the condition (cid:80)

given a graph g, we want to construct a vertex set   0 that is as small as possible and at
the same time is a good representation of all the other vertices not in this set. let us assign a
state ci     {0, 1} to each vertex i, ci = 1 if i       0 (referred to as being occupied) and ci = 0 if
i      j ciwi,j       ,
where    is a    xed threshold value. a vertex j is regarded as being satis   ed if it is occupied
i      j ciwi,j        holds, otherwise it is regarded as being unsatis   ed.
therefore there are n vertex constraints in the system. a con   guration (c1, c2, . . . , cn ) for the
whole graph is referred to as a satisfying con   guration if and only if it makes all the vertices to
be satis   ed (fig. 1). constructing such a generalized mds   0, i.e., a satisfying con   guration
with the smallest number of occupied vertices, is a 0   1 integer programming problem, but as it
belongs to the nondeterministic polynomial-hard (np-hard) computational complexity class, no

4212563108711910.70.50.80.70.70.70.80.40.30.10.50.90.30.60.30.90.20.50.60.50.8(c1, c2, . . . , cn ) as

algorithm is guaranteed to solve it in polynomial time. we now seek to solve it approximately
through a statistical physics approach.

let us introduce a weighted sum z(  ) of all the 2n possible microscopic con   gurations

(cid:88)

(cid:20)

n(cid:89)

(cid:16)(cid:88)

(cid:17)(cid:21)

z(  ) =

cj e      +   0
  1

cj   

ciwi,j       

,

(1)

j=1
a = 1 if a = b and   b

c1,...,cn
a is the kronecker symbol (  b

i      j
a = 0 if a (cid:54)= b), and   (x) is the heaviside
where   b
step function such that   (x) = 0 for x < 0 and   (x) = 1 for x     0. in the statistical physics
community, z(  ) is known as the partition function and the non-negative parameter    is the
inverse temperature. notice a con   guration (c1, c2, . . . , cn ) has no contribution to z(  ) if it is
not a satisfying con   guration. if a con   guration satis   es all the vertex constraints, it contributes
i=1 ci is the total number of occupied vertices. as   
increases, satisfying con   gurations with smaller n1 values become more important for z(  ), and
at            the partition function is contributed exclusively by the satisfying con   gurations with
the smallest n1. for the purpose of constructing a minimum or close-to-minimum dominating
set, we are therefore interested in the large-   limit of z(  ).

a term e     n1 to z(  ), where n1     (cid:80)n

3. replica-symmetric mean    eld theory
it is very di   cult to compute the partition function z(  ) exactly, here we compute it
approximately using the replica-symmetric mean    eld theory of statistical physics. this rs
mean    eld theory can be understood from the angle of bethe-peierls approximation [16, 17], it
can also be derived through loop expansion of the partition function [18, 19].

3.1. thermodynamic quantities
the marginal id203 that vertex j is in state cj     {0, 1}. due to the
we denote by qcj
j
constraints associated with vertex j and all its neighboring vertices, the state cj is strongly
correlated with those of the neighbors. to write down an approximate expression for qcj
j , let
us assume that the states of all the vertices in set    j are independent before the constraint of
vertex j is enforced. under this bethe-peierls approximation we then obtain that

cj e      (cid:80)
e      (cid:80)

  1

(cid:81)
(cid:81)

{ci : i      j}

i      j

{ci : i      j}

i      j

q(ci,1)
i   j +   0
cj

i   j + (cid:80)

q(ci,1)

{ci : i      j}

  

{ci : i      j}

(cid:80)

(cid:16)(cid:80)
(cid:16)(cid:80)

  

i      j

ciwi,j       

i      j
ciwi,j       

(cid:17) (cid:81)
(cid:17) (cid:81)

i      j

i      j
q(ci,0)
i   j

q(ci,0)
i   j

.

(2)

j    
qcj

(cid:81)

i   j

in the above equation, q(ci,cj )
is the joint id203 that vertex i has state ci and its neighboring
vertex j has state cj when the constraint associated with vertex j is not enforced. the product
is a direct consequence of neglecting the correlations among vertices in    j in the
absence of vertex j   s constraint. the mean fraction        n1/n of occupied vertices is then
obtained through

i      j q(ci,cj )

i   j

q1
j ,

(3)

j=1
this fraction should be a decreasing function of   .

we can de   ne the free energy of the system as f (  ) =     1

theory this free energy can be computed through

f     n f =

n(cid:88)

j=1

fj     (cid:88)

(i,j)   g

   ln z(  ). within the rs mean    eld

f(i,j) ,

(4)

n(cid:88)

   =

1
n

where f is the free energy density; and fj and f(i,j) are, respectively, the free energy contribution
of a vertex j and an edge (i, j):

(cid:89)

(cid:20)
e      (cid:88)
(cid:20)(cid:88)

ci,cj

i      j

{ci : i      j}
q(ci,cj )
i   j q(cj ,ci)
j   i

q(ci,1)
i   j +

(cid:21)

.

fj =     1
  
f(i,j) =     1
  

ln

ln

(cid:88)

{ci : i      j}

(cid:16)(cid:88)

i      j

  

(cid:21)

(cid:17)(cid:89)

i      j

ciwi,j       

q(ci,0)
i   j

,

(5a)

(5b)

the partition function is predominantly contributed by satisfying con   gurations with number
of occupied vertices n1     n   , namely z(  )     e       n    (  ) with    (  ) being the total number of
satisfying con   gurations at occupation density   . then the id178 density s(  )     1
n ln    (  ) of
the system is computed through

s = (       f )   .

(6)

the id178 density is required to be non-negative by de   nition. if s(  ) < 0 as    decreases below
certain value   0, then    (  ) = en s(  )     0 suggests that there is no satisfying con   gurations with
   <   0. we therefore take the value   0 as the fraction of vertices contained in a minimum
dominating set.

3.2. belief-propagation equation
we need to determine the probabilities q(ci,cj )
s. following the bethe-peierls approximation and similar to eq. (2), q(ci,cj )
determined through

i   j

i   j

q(0,0)
i   j =

q(0,1)
i   j =

q(1,0)
i   j = q(1,1)

i   j =

1
zi   j

1
zi   j

1
zi   j

{ck : k      i\j}

(cid:88)
(cid:88)
e      (cid:89)

{ck : k      i\j}

(cid:104)

k      i\j

to compute the thermodynamic densities   , f , and

(cid:16) (cid:88)
(cid:16)

k      i\j

  

  

wj,i +

(cid:17) (cid:89)

ckwk,i       

(cid:88)
(cid:105)

k      i\j

k      i\j
ckwk,i       

q(ck,0)
k   i

(cid:17) (cid:89)

k      i\j

k   i + q(0,1)
q(1,1)
k   i

,

is self-consistently

,

q(ck,0)
k   i

,

(7a)

(7b)

(7c)

where    i\j is the subset of    i with vertex j being deleted, and zi   j is a id172 constant.
equation (7) is called a belief-propagation (bp) equation in the literature. to    nd a solution to
eq. (7) we iterate this equation on all the edges of the input graph g (see, for example, [12, 13]
or [19] for implementing details). however convergence is not guaranteed to achieve.
if the
reweighting parameter    is small this bp iteration quickly reaches a    xed point; while at large
values of    we notice that it usually fails to converge (see next subsection).

3.3. results on erd  os-r  enyi random graphs
we    rst apply the rs mean    eld theory to erd  os-r  enyi (er) random graphs. to generate an
er random graph, we select m di   erent pairs of edges uniformly at random from the whole
set of n (n     1)/2 vertex pairs and then connect each selected pair of vertices by an edge. for
n su   ciently large there is no structural correlations in such a random graph, and the typical
length of a loop in the graph diverges with n in a logarithmic way.

if the two edge weights of every edge (i, j) are equal to the vertex threshold value   
(wi,j = wj,i =   ), the generalized mds problem reduces to the conventional mds problem on
an undirected graph, which has been successfully treated in [12]. for example, for er random

figure 2. replica-symmetric mean    eld results on er random networks of mean vertex degree
c = 10.0. the symmetric edge weights are drawn from the set {0.4, 0.5, 0.6, 0.7, 0.8, 0.9, 1.0} and
the vertex threshold value is    = 1. the cross symbols (bp) are results obtained by belief-
propagation on a single graph instance of size n = 105, while the solid lines (rs) are ensemble-
averaged results obtained by population dynamics simulations. (a) occupation density    versus
inverse temperature   ; (b) free energy density f versus   ; (c) id178 density s versus   ; (d)
id178 density s as a function of    obtained by combining data of (a) and (c).

graphs with mean vertex degree c = 10.0 the mds relative size is   0     0.120 [12]. on the other
hand, if the two edge weights of every edge are strongly non-symmetric such that either wi,j =   
and wj,i = 0 (with id203 1/2) or wi,j = 0 and wj,i =    (also with id203 1/2), the
generalized mds problem reduces to the conventional mds problem on a directed graph, which
again has been successfully treated in [13] (e.g., at c = 10.0 the mds relative size is   0     0.195).
in this paper, as a particular example, we consider a distribution of edge weights with the
following properties: (1) the weights of every edge (i, j) are symmetric, so wi,j = wj,i; (2) the
edge weights of di   erent edges are not correlated but completely independent; (3) for each edge
(i, j) its weight wi,j is assigned the value 0.4   or 1.0   with id203 1/12 each and assigned
values in the set {0.5  , 0.6  , 0.7  , 0.8  , 0.9  } with equal id203 1/6 each.

the bp results on the occupation density   , the free energy density f , and the id178
density s are shown in fig. 2 for a single er random graph of n = 105 vertices and mean degree
c = 10.0. the bp iteration for this this graph instance is convergent for 0            8.3. the
occupation density    and the id178 density s both decrease with inverse temperature   . the
id178 density as a function of occupation density, s(  ), approaches zero at    =   0     0.202,
indicating there is no satisfying con   gurations at occupation density    <   0. the bp results

0.20.30.40.502468    abcdrsbp-0.2-0.10.00.202468f  0.00.20.40.602468s  0.00.20.40.60.20.30.40.5s  figure 3. the relative size   0 of minimum dominating sets for er random graphs of mean
vertex degree c. the edge weight distribution for these random graphs are the same as that of
fig. 2, and the vertex threshold value    = 1.0. the solid-line connected plus symbols are the
predictions of the rs mean    eld theory, while the results obtained by the bpd algorithm at
   = 8.0 are drawn as cross symbols (for graph size n = 103), circles (n = 104), and squares
(n = 105). each bpd data point is the result of a single run on one graph instance.

therefore predict that a mds for this problem instance must contain at least 0.202n vertices.
we can also obtain rs mean    eld results on the thermodynamic densities by averaging over
the whole ensemble of er random graphs (with n         and    xed mean vertex degree c). this
is achieved by population dynamics simulations [16]. we store a population of probabilities
i   j } and update this population using eq. (7), and at the same time compute the densities
{q(ci,cj )
of thermodynamic quantities. a detailed description on the implementation can be found in
section 4.3 of [12]. the ensemble-averaged results for the er random network ensemble of
c = 10.0 and n         are also shown in fig. 2. these results are in good agreement with the
bp results obtained on the single graph instance.

through the rs population dynamics simulations we can estimate the ensemble-averaged
value of   0 (the minimum fraction of occupied vertices) by the equation s(  0) = 0. the value
of   0 obtained in such a way decreases with mean vertex degree c continuously, see fig. 3 (solid
line).

4. belief-propagation-guided decimation algorithm
for    su   ciently large, the marginal occupation id203 qcj
j obtained by eq. (2) tells us the
likelihood of each vertex j to belong to a minimum dominating set. this information can serve
as a guide for constructing close-to-minimum dominating sets. based on the bp equation (2) we
implement a simple belief-propagation-guided decimation (bpd) algorithm as follows. starting
from an input graph g and an empty vertex set   , at each step we (1) iterate the bp equation
for a number of repeats and then estimate the occupation id203 q1
j for all the vertices j
not in   ; and (2) add a tiny fraction (e.g., 1%) of those vertices j with the highest values of
q1
j into the set    and set their state to be cj = 1; (3) then simplify the graph and repeat the
operations (1)   (3) on the simpli   ed graph, until    becomes a dominating set.

the detailed implementation of this bpd algorithm is the same as described in section 5 of
[12]. here we only need to emphasize one new feature: after a vertex i is newly occupied, the

00.20.40.60.802468101214  0crsn=100,000n=10,000n=1,000threshold value (say   j) of every neighboring vertex j should be updated as   j     (  j     wi,j),
and if this updated   j is non-positive then vertex j should be regarded as being satis   ed.

for the same graph of fig. 2, a single trial of this bpd algorithm at    = 8.0 results in a
dominating set of size 21009, which is very close to the predicted mds size by the rs mean    eld
theory. equally good performance of the bpd algorithm is also achieved on other er random
graphs with mean vertex degree c ranging from c = 0.5 to c = 14 (see fig. 3), suggesting that
the bpd algorithm is able to construct a dominating set which is very close to a mds. we
emphasize that in the bpd algorithm we do not require the bp iteration to converge.

5. application: automatic text summarization
automatic text summarization is an important issue in the research    eld of natural language
processing [14]. one is faced with the di   cult task of constructing a set of sentences to
summarize a text document (or a collection of text documents) in a most informative and
e   cient way. here we extend the initial idea of shen and li [15] and consider this information
retrieval problem as a generalized minimum dominating set problem.

we represent each sentence of an input text document as a vertex and connect two vertices
(say i and j) by an weighted edge, with the symmetric edge weight wi,j (= wj,i) being equal
to the similarity of the two corresponding sentences. before computing the edge weight a pre-
treatment is applied to all the sentences to remove stop-words (such as    a   ,    an   ,    at   ,    do   ,    but   ,
   of   ,    with   ) and to transform words to their prototypes according to the id138 dictionary
[20] (e.g.,    airier           airy   ,       eshier           eshy,    are           be   ,    children        child,    looking           look   ).
there are di   erent ways to measure sentence similarity, here we consider a simple one, the cosine
similarity [21]. to compute the cosine similarity, we map each sentence i to a high-dimensional
vector (cid:126)si, the k-th element of which is just the number of times the k-th word of the text appears
in this sentence. then the edge weight between vertices i and j is de   ned as

(cid:113)

(cid:126)si    (cid:126)sj

(cid:113)

(cid:126)si    (cid:126)si

(cid:126)sj    (cid:126)sj

wi,j =

.

(8)

to give a simple example, let us consider a document with only two sentences    tom is looking
at his children with a smile.    and    these children are good at singing.   . the word set of this
document is {tom, be, look, child, smile, good, sing}, and the vectors for the two sentences
are (cid:126)s1 = (1, 1, 1, 1, 1, 0, 0) and (cid:126)s2 = (0, 1, 0, 1, 0, 1, 1), respectively. the cosine similarity w12
between these two sentences is then w12 = 2   
   

    0.447.

we    rst test the performance of the bpd algorithm on 32 short english text documents of
di   erent lengths (on average a document has 17.7 sentences). we compare the outputs from
the bpd algorithm with the key sentences manually selected by the    rst author. for each text
document we denote by b and   b the set of key sentences selected by human inspection and
by the algorithm, respectively. on average the set b of human inspection contains a fraction
   = 0.226 of the sentences in the input text document. then we de   ne the coverage ratio rcov
and the di   erence ratio rdif between b and   b as

5

4

(cid:12)(cid:12)b       b(cid:12)(cid:12)
(cid:12)(cid:12)b(cid:12)(cid:12)

(cid:12)(cid:12)   b     b(cid:12)(cid:12)
(cid:12)(cid:12)   b(cid:12)(cid:12)

rcov =

,

rdif =

,

(9)

where (   b   b) denotes the set of sentences belonging to   b but not to b. the ratio rcov quanti   es
the id203 of a manually selected key sentence also being selected by the algorithm, while
the ratio rdif quanti   es the extent that a sentence selected by the algorithm does not belong
to the set of manually selected key sentences.

table 1. averaged performances of the bpd algorithm (   = 8.0), the pr (id95)
algorithm, and the ap (a   nity-propagation) algorithm on 32 english text documents (average
number of sentences per document 17.7). for bpd the vertex threshold is set to    = 0.6
(bpd0.6),    = 0.8 (bpd0.8) and    = 1.0 (bpd1.0). for pr the fraction of sentences selected is
25% (pr25%), 30% (pr30%), and 40% (pr40%). for ap the adjustable parameter is set to be
wi,i = 0.0 (ap0.0) and wi,i = 0.2 (ap0.2).    is the fraction of representative sentences chosen
by the algorithm, and rcov and rdif are two performance measures de   ned by eq. (9). the
average fraction of representative sentences constructed by human inspection is    = 0.226.

bpd0.6 bpd0.8 bpd1.0 pr25% pr30% pr40% ap0.0 ap0.2
0.56
0.39
49.6% 30.0% 41.7% 50.6% 15.6% 39.3%
80.2% 74.2% 71.4% 72.2% 76.3% 77.4%

0.48
47.2%
78.6%

0.44
39.9%
79.4%

0.27

0.17

0.32

0.42

  
rcov
rdif

we also apply two other summarization algorithms to the same set of text documents, one
is the id95 (pr) algorithm [22, 23, 24], and the other is the a   nity-propagation (ap)
algorithm [25]. id95 is based on the idea of random walk on a graph, and it o   ers an
e   cient way of measuring vertex signi   cance. the importance pi of a vertex i is determined by
the following self-consistent equation

pi = (1     p)

1
n

+ p    (cid:88)

pj

j      i

wj,i(cid:80)

k      j wj,k

,

(10)

where p is the id203 to jump from one vertex to a neighboring vertex (we set p = 0.85
following [22]). those vertices i with high values of pi are then selected as the representative
vertices.

on the other hand, a   nity-propagation is a id91 algorithm: each vertex either selects
a neighboring vertex as its exemplar or serves as an exemplar for some or all of its neighbors
[25]. for any pair of vertices i and j, the responsibility ri,j of j to i and the availability ai,j of
j to i are determined by the following set of iterative equations:

ri,j = wi,j     max
k(cid:54)=j

ai,j = min

(cid:9) ,
max(cid:2)0, rk,j

(cid:8)ai,k + wi,k
(cid:104)
(cid:88)
(cid:3) .
max(cid:2)0, ri,j

0, rj,j +

k(cid:54)=i,j

aj,j =

(cid:88)

i(cid:54)=j

(cid:3)(cid:105)

,

(11a)

(11b)

(11c)

in eq. (11a) wi,j is the weight of edge (i, j) for i (cid:54)= j, and wi,i is an adjustable parameter which
a   ects the    nal number of examplars. we iterate the ap equation (11) on the sentence graph
starting from the initial condition of ri,j = ai,j = 0 and, after convergence is reached, then
consider all the vertices i with positive values of (ri,i + ai,i) as the examplar vertices.

for the 32 short text documents used in our preliminary test, the comparative results of
table 1 do not distinguish much the three heuristic algorithms, yet it appears that id95
performs slightly better than bpd and ap. when the fraction of extracted sentences is    = 0.42,
the coverage ratio reached by pr is rcov = 0.51 and the di   erence ratio is rdif = 0.72, while
rcov = 0.40 and rdif = 0.79 for bpd at    = 0.44 and rcov = 0.39 and rdif = 0.77 for ap at
   = 0.39.

we then continue to evaluate the performance of the belief-propagation approach on
a benchmark set of longer text documents, namely the duc (document understanding

table 2. averaged performances of the bpd algorithms bpd100
(   = 0.6 or    = 1.0) and
bpd   (   = 1.0) and the id95 algorithm pr100 on the 533 text documents of duc 2002
[26]. the precision, recall, and f-score values are obtained by averaging over the results of
individual text documents. the inverse temperature of bpd is    xed to be    = 8.0.

  

recall
precision
fscore

pr100 bpd100
0.249
0.455
0.396
0.407
0.429
0.303

0.6 bpd100
0.264
0.410
0.318

1.0 bpd1.0
0.727
0.256
0.359

conference) data set used in [24]. we examine a total number of 533 text documents from
the duc 2002 directory [26]. the average number of sentences per document is about 28 and
the average number of words per sentence is about 20.
the duc data set o   ers, for each of these text documents, two sets b of representative
sentences chosen by two human experts, the total number of words in such a set b being     100.
the id95 algorithm (pr100) and one version of the bpd algorithm (bpd100
,    = 0.6 or
   = 1.0) also construct a set   b of sentences for each of these documents under the constraint that
the total number of words in   b should be about 100. in another version of the bpd algorithm
(bpd  ) the restriction on the words number in   b is removed. we follow the duc convention
and use the toolkit id8 [27] to evaluate the agreement between   b and b in terms of recall,
precision, and f-score:

  

(cid:80)
(cid:80)

word   b

word   b

min(cid:2)c(word),   c(word)(cid:3)
min(cid:2)c(word),   c(word)(cid:3)

wordsnum(b)

wordsnum(   b)
2    precision    recall
precision + recall

.

recall =

precision =

fscore =

,

,

(12a)

(12b)

(12c)

where c(word) is the total number of times a given word appears in the summary b, and
  c(word) is the number of times this word appears in the summary   b; wordsnum(b) is the
total number of words in the summary b and similarly for wordsnum(   b).

the comparative results for the duc 2002 data set are shown in table 2. we notice that
bpd1.0 (   = 1.0) has the highest recall value of 0.727, namely the summary obtained by this
algorithm contains most of contents in the summary of human experts, but its precision value
of 0.256 is much lower than that of the pr100 algorithm, indicating that the bpd algorithm add
more sentences into the summary than the human experts do. in terms of the f-score which
balances recall and precision (the last row of table 2) we conclude that id95 also performs
a little bit better than bpd for the duc 2002 benchmark.

the generalized mds model for the text summarization problem aims at a complete coverage
it is therefore natural that the summary constructed by bpd
of an input text document.
contains more sentences than the summary constructed by the human experts (which may only
choose the sentences that best summarize the key points of a text document). all the tested
documents in the present work are rather short, which may make the advantages of the bpd
message-passing algorithm di   cult to be manifested. more work needs to be done to test the
performance of the bpd algorithm on very long text documents.

figure 4. the word   sentence graph representation for a text document. the m words and
n sentences of an input text document are denoted by squares and circles, respectively, and a
link between a word a and a sentence i is drawn if and only if word a appears in sentence i. to
get a set    of representative sentences we may require that each word must be connected to at
least n (n     1) sentences of the set   .

6. outlook
in this paper we presented a replica-symmetric mean    eld theory for the generalized minimum
dominating set problem, and we considered the task of automatic text summarization as
such a mds problem and applied the bpd message-passing algorithm to construct a set of
representative sentences for a text document. when tested on a set of short text documents
the bpd algorithm has comparable performance as the id95 and the a   nity-propagation
algorithms. we feel that the bpd approach will be most powerful for extracting sentences out
of lengthy text documents (e.g., scienti   c papers containing thousands of sentences). we hope
that our work will stimulate further e   orts on this important application.

the belief-propagation based method for the automatic text summarization problem might
be improved in various ways. for example, it may not be necessary to perform the decimation
step, rather one may run bp on the input sentence graph until convergence (or for a su   cient
number of rounds) and then return an adjustable fraction    of the sentences i according to their
estimated occupation probabilities q1
i .

one may also convert the text summarization problem to other generalized mds problems.
a particularly simple but potentially useful one can be constructed as follows: we    rst construct
a bi-partite graph formed by words, sentences, and the links between words and sentences (see
fig. 4); we then construct a minimum-sized dominating set of sentences    such that every word
of the whole bipartite graph must appear in at least n (n     1) of the sentences of   . such
a generalized mds problem can be studied by slightly modifying the bp equation eq. (7).
we notice that this alternative construction has the advantage of encouraging diversity in the
selected representative sentences.

acknowledgments
we thank jin-hua zhao and yusupjan habibulla for helpful discussions. this research
is partially supported by the national basic research program of china (grant number
2013cb932804) and by the national natural science foundation of china (grand numbers
11121403 and 11225526).

1......123  ......234  wordssentencesreferences
[1] haynes t w, hedetniemi s t and slater p j 1998 fundamentals of domination in graphs (new york:

marcel dekker)

[2] echenique p, g  omez-garde  nes j, moreno y and v  azquez a 2005 distance-d covering problems in scale-free

networks with degree correlations phys. rev. e 71 035102(r)

[3] dall   asta l, pin p and ramezanpour a 2009 statistical mechanics of maximal independent sets phys. rev.

e 80 061136

[4] dall   asta l, pin p and ramezanpour a 2011 optimal equilibria of the best shot game j. public economic

theor. 13 885   901

[5] yang y, wang j and motter a e 2012 network observability transitions phys. rev. lett. 109 258701
[6] moln  ar jr. f, sreenivasan s, szymanski b k and korniss k 2013 minimum dominating sets in scale-free

network ensembles sci. rep. 3 1736

[7] nacher j c and akutsu t 2013 analysis on critical nodes in controlling complex networks using dominating
sets in international conference on signal-image technology & internet-based systems (kyoto) 649   654
[8] takaguchi t, hasegawa t and yoshida y 2014 suppressing epidemics on networks by exploiting observer

nodes phys. rev. e 90 012807

[9] wuchty s 2014 controllability in protein interaction networks proc. natl. acad. sci. usa 111 7156   7160
[10] wang h, zheng h, browne f and wang c 2014 minimum dominating sets in cell cycle speci   c protein
in proceedings of international conference on bioinformatics and biomedicine

interaction networks
(ieee) 25   30

[11] liu y y and barab  asi a l 2015 control principles of complex networks arxiv:1508.05384
[12] zhao j h, habibulla y and zhou h j 2015 statistical mechanics of the minimum dominating set problem

j. stat. phys. 159 1154   1174

[13] habibulla y, zhao j h and zhou h j 2015 the directed dominating set problem: generalized leaf removal

and belief propagation lect. notes comput. sci. 9130 78   88

[14] mani i 1999 advances in automatic text summarization (cambridge, ma: mit press)
[15] shen c and li t 2010 id57 via the minimum dominating set in proceedings of
the 23rd international conference on computational linguistics (beijing) (association for computational
linguistics) 984   992

[16] m  ezard m and parisi g 2001 the bethe lattice spin glass revisited eur. phys. j. b 20 217   233
[17] m  ezard m and montanari a 2009 information, physics, and computation (new york: oxford univ. press)
[18] zhou h j and wang c 2012 region graph partition function expansion and approximate free energy

landscapes: theory and some numerical results j. stat. phys. 148 513   547

[19] zhou h j 2015 spin glass and message passing (beijing: science press)
[20] fellbaum c 1998 id138: an electronic lexical database (cambridge, ma: mit press)
[21] singhal a 2001 modern information retrieval: a brief overview ieee data engineering bulletin 24 35   43
[22] brin s and page l 1998 the anatomy of a large-scale hypertextual web search engine computer networks

and isdn systems 30 107   117

[23] mihalcea r and tarau p 2004 textrank: bringing order into texts

in preceedings of the conference
on empirical methods in natural language processing (barcelona) (association for computational
linguistics) 404   411

[24] erkan g and radev d r 2004 lexrank: graph-based lexical centrality as salience in text summarization

j. arti   cal intelligence res. 22 457   479

[25] frey b j and dueck d 2007 id91 by passing messages between data points science 315 972   976
[26] document understanding conference 2002 http://www-nlpir.nist.gov/projects/duc
[27] lin c y 2004 id8: a package for automatic evaluation of summaries

in preceedings of the acl-04
workshop: text summarization branches out (barcelona) (association for computational linguistics)
74   81

