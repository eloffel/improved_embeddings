5
1
0
2

 

b
e
f
8
2

 

 
 
]
l
c
.
s
c
[
 
 

2
v
5
1
8
6

.

2
1
4
1
:
v
i
x
r
a

under review as a conference paper at iclr 2015

extraction of salient sentences from
labelled documents

misha denil1 alban demiraj1 nando de freitas1,2,3
1university of oxford, united kingdom
2canadian institute for advanced research
3google deepmind
misha.denil@cs.ox.ac.uk
a.demiraj@oxfordalumni.org
nandodefreitas@google.com

abstract

we present a hierarchical convolutional document model with an architec-
ture designed to support introspection of the document structure. using
this model, we show how to use visualisation techniques from the computer
vision literature to identify and extract topic-relevant sentences.
we also introduce a new scalable evaluation technique for automatic sen-
tence extraction systems that avoids the need for time consuming human
annotation of validation data.

1

introduction

the idea of encoding symbolic concepts with distributed representations has excited re-
searchers for decades (hinton, 1986; bengio et al., 2003).
in recent years this idea has
re-emerged following the success of neural networks in many natural language processing
domains such as language modelling (mikolov et al., 2013), machine translation (schwenk,
2012; kalchbrenner & blunsom, 2013a; devlin et al., 2014; cho et al., 2014; bahdanau et al.,
2014; sutskever et al., 2014; hermann & blunsom, 2014), id53 (bordes et al.,
2014; weston et al., 2014), dialogue systems (kalchbrenner & blunsom, 2013b), sentiment
analysis (socher et al., 2011; 2012; hermann & blunsom, 2013), and other natural language
processing tasks such as chunking and id39 (collobert et al., 2011).

distributed representations of language enable us to encode the semantics of language into
the geometry of a continuous vector space. this idea underlies nearly all modern applications
of neural networks to nlp. one intuition behind the success of continuous representations
is that they are more amenable to transformations and optimizations than their discrete
counterparts (bottou, 2014).

following their tremendous success in id161, there have recently been many suc-
cessful applications of convolutional neural networks (convnets for short) to nlp (col-
lobert et al., 2011; kalchbrenner et al., 2014; hermann & blunsom, 2014; dos santos &
gatti, 2014; hu et al., 2014; yu et al., 2014).

in this paper we make two main contributions, continuing the line of research on convnets
for language:

1. we introduce a hierarchical convnet architecture designed to support introspection
of the document structure. we show how our novel model structure allows us to
adapt visualisation techniques from id161 to design a system that can
automatically extract relevant sentences from labelled documents.

2. we describe a new evaluation technique for automatic sentences extraction systems
that can be applied at scale. we can take advantage of the fact that the documents
are labelled to build a simple document classi   er which we then use to classify the
documents extracted by our system. comparing the accuracy of the classi   er on

1

under review as a conference paper at iclr 2015

full documents to its accuracy on the extracted portions alone gives a measure of
how much task-relevant information is preserved by the extraction process.

extracting relevant sentences from documents is an important problem. summaries created
in this way pervade internet search results, restaurant and consumer product review sites
and the front pages of news outlets. our work shows a novel application of neural networks
to this problem, and provides a scalable method for comparing the quality of di   erent
solutions.

2 model description

our convnet model is divided into a sentence level and a document level, both of which
are implemented using convolutions. at the sentence level we use a convnet to transform
embeddings for the words in each sentence into an embedding for the entire sentence. at
the document level we use another convnet to transform sentence embeddings from the
   rst level into a single embedding vector that represents the entire document.

the model is trained by feeding the document embeddings into a softmax classi   er, and the
model is trained by backpropogation through both the sentence and document levels. at
the sentence level the    lter banks that process di   erent sentences are tied, so each sentence
has an embedding that is produced by the same convnet.

the architecture of our model forces information to pass through an intermediate sentence
based representation. this architecture is inspired by gulcehre & bengio (2013) who show
that learning appropriate intermediate representations helps generalisation, and also by
hinton et al. (2011) who show that by forcing information to pass through carefully chosen
bottlenecks it is possible to control the types of intermediate representations that are learned.

forcing the model to represent documents in terms of semantically relevant units is essential
to the extraction application we introduce later in this paper. the fact that speci   c hidden
units in our network are used to represent each sentence is what allows us to measure the
relevance contribution from each sentence separately.

each level of our model in isolation is very similar to the did98 of kalchbrenner et al. (2014);
the main di   erence is in how interactions between embedding dimensions are handled. our
approach (explained below) follows previous work on convnets for nlp (e.g. collobert
et al. (2011)) and is also consistent with convnets for vision. using a more standard form
of convolution makes the model more compact (which is nice when adding more layers)
but is not the focus of this paper. the main di   erence between our model and the did98
is that we extend the model with a multi-level structure for modelling documents, where
kalchbrenner et al. (2014) considered only sentences.

a detailed schematic of our model is shown in figure 1. in the following sections we describe
the inner workings of each part in more detail.1

2.1 embedding matrix

the input to each level of our model is an embedding matrix. at the sentence level the
columns of this matrix correspond to embeddings of the words in the sentence being pro-
cessed, while at the document level the columns correspond to sentence embeddings pro-
duced by the sentence level of the model.

at the sentence level, an embedding matrix for each sentence is built by concatenating
embeddings for each word it contains into the columns of a matrix. the words are drawn
from a    xed vocabulary v , which we represent using a matrix of id27s w    
rd  |v |. each column of this matrix is a d dimensional vector that gives an embedding for
a single word in the vocabulary. the id27 vectors are parameters of the model,
and are optimised using backpropogation.

1code implementing this model will be made available following the review process.

2

under review as a conference paper at iclr 2015

figure 1: id27s are concatenated into columns to form a sentence matrix. the
sentence level convnet applies a cascade of convolution, pooling and nonlinearity operations
to transform the projected sentence matrix into an embedding for the sentence. the sentence
embeddings are then concatenated into columns to form a document matrix. the document
model then applies its own cascade of convolution, pooling and nonlinearity operations to
form an embedding for the whole document which is fed into a softmax layer for classi   cation.

w =

for each sentence s =(cid:2)ws

1

       ws|s|(cid:3) we generate a sentence matrix ss     rd  |s| by con-

catenating together the id27 vector corresponding to each word in the sentence.

(cid:34) |

w1
|

       |

wws
|

1

|
|
       w|v |
|
|

(cid:35)

      

ss =

|
|
       wws|s|
|
|

the sentence level of the model produces an embedding vector for each sentence in the
document. the input to the document level is obtained by assembling these sentence em-
beddings into a document matrix, in the same way id27s are assembled into a
sentence matrix in the level below.

2.2 convolution
each convolutional layer contains a    lter bank f     rd  wf  nf where wf and nf refer to the
width and number of feature maps respectively. the    rst dimension of each feature map
f     rd  wf is equal to the number of dimensions in the embeddings generated by the layer
below.

the convolution operation in our model is one dimensional. we align the    rst axis of each
feature map with the embedding axis and convolve along rows of the embedding matrix. at

3

stackablelayersstackablelayersthecatsatonthemat.theyfounditreallyreallyfunny.ooowordembedding-sentencematrixwideconvolutionfeaturemapk-maxpoolingpooledrepresentationvectorisationsentenceembedding-documentmatrixwideconvolutionfeaturemapk-maxpoolingpooledrepresentationvectorisationdocumentembeddingunder review as a conference paper at iclr 2015

the sentence level this corresponds to convolving across words and at the document level it
corresponds to convolving across sentences.

each feature map generates a 1d row of numbers, where each value is obtained by applying
the feature map at a di   erent location along the sentence matrix. the outputs of di   erent
feature maps are then stacked to form a new matrix of latent representations which is fed
as input to the next layer. in all cases we use wide (   full   ) convolutions in order for all
weights in the feature maps to reach every word/sentence, including ones on the edges.

2.3 k-max pooling

since di   erent sentences and documents have di   erent lengths, not all embedding matrices
will be of the same width. this is not an issue for the convolutional layers, since convolutions
can handle inputs of arbitrary width, but is problematic to use as input to a fully connected
or softmax layer, and at the interface between the sentence and document levels.

the solution we use is k-max pooling, which is applied to each row of the embedding matrix
separately. to apply k-max pooling to a single row, we keep the k largest values along that
row and discard the rest. since k is a    xed parameter this always generates a    xed size
output (if the input has length less than k we pad it with zeros). for example, applying
2-max pooling to [3, 1, 5, 2] yields [3, 5]. this procedure is also illustrated graphically in
figure 1.

2.4 full model

at the sentence level we use a single convolutional pipeline for processing each sentence (ie.
the weights of the sentence models are tied across sentences). the document level of the
model is composed of the same type of convolution and pooling primitives, but the weights
are not shared with the sentence level models.

an important feature of this archetecture is that it forces the model to create an inter-
mediate representation for each sentence in the document.
it is this representation that
allows the extraction technique in section 3 to identify salient sentences. if we had instead
simply applied convolutions to the whole document we would not be able to disentangle the
contributions from individual sentences.

3 sentence extraction through visualisation

deconvolutional networks (zeiler et al., 2010; 2011) have been used to great e   ect to gen-
erate interpretable visualisations of the activations in deep layers of convolutional neural
networks in id161 (zeiler & fergus, 2012). more recent work has shown that
good visualisations can be obtained by using a single backpropogation pass through the
network. in fact this procedure is formally quite similar to the operations carried out in
a deconvolutional net (simonyan et al., 2013). visualisation through backpropogation is a
generalisation of the deconvolutional approach, since one can backpropogate through non-
convolutional layers.

the    rst step in our extraction procedure is to create a saliency map for the document by
assigning an importance score to each sentence. to generate the saliency map for a given
document, we adopt the technique of simonyan et al. (2013) with a modi   ed objective
function.

we    rst perform a forward pass through the network to generate a class prediction for the
document. we then construct a pseudo-label by inverting the network predictions, and feed
this to the id168 as the true label. this choice of pseudo-label allows us to induce
the greatest loss.

to infer saliency for words we take a    rst order taylor expansion of the id168 using
the pseudo-label. formally, if x is a document and f (x) is the network evaluated on x, we

4

under review as a conference paper at iclr 2015

approximate the loss as a linear function

where   y is the inverted label and

w =

   l
   x

l(  y, f (x))     wt x + b

(cid:12)(cid:12)(cid:12)(cid:12)(  y,f (x))

.

the vector w has one entry for each word in the document and we can use |wi| as a measure
of the saliency of word i. these saliency scores can be easily computed by performing a
single pass of backpropogation through the network. the intuition behind using gradient
magnitudes as a saliency measure is that the magnitude of the derivative indicates which
words need to be changed the least to a   ect the score the most.

when training the model we need only backpropogate to the id27 layer to get a
gradient with respect to each id27 vector; however, to evaluate saliency we need
a derivative with respect to the words themselves. to bacpropogate through the embedding
layer, notice that (using the notation of section 2) we can write the sentence matrix as

ss = wis

where is     r|v |  |s| is a matrix whose columns are 1-hot vectors identifying the dictionary
index of each word in the sentence s. if the ith word in s appears at index j in the dictionary
then the derivative with respect to iji is given by

(cid:12)(cid:12)(cid:12)(cid:12)(  y,f (x))

wi =

   l
   iji

= (cid:104)  i, wj(cid:105)

which corresponds to taking the dot product between   i, the backwards message for the ith
embedding vector; and wi, the embedding vector for the ith word.

at the document level the situation is similar, except that the dictionary of sentence em-
beddings is de   ned implicitly by the sentence level of our model. using s to denote the
(huge) implicitly de   ned dictionary of embeddings that contains a column for every possible
sentence we can write down the    rst layer of the of the document level of our model as

dd = sid

where dd is the document matrix and id is a matrix whose columns are (huge) 1-hot vectors
indicating the dictionary index of each sentence in the document d. if the ith sentence in d
appears at index j in the implicit dictionary then the derivative with respect to iji is given
by

(cid:12)(cid:12)(cid:12)(cid:12)(  y,f (x))

wi =

   l
   iji

= (cid:104)  i, sj(cid:105) = (cid:104)  i, fs(xj)(cid:105)

where   i is again the backward message from backpropogation and sj = fs(xj) is the result
of evaluating the sentence level of the model on sentence j.

we use the saliency scores for each sentence to rank the sentences within a document. to
extract a    xed number of sentences we simply choose the k most highly ranked sentences
using this measure.

4 scalable evaluation

the sentence extraction scheme described in section 3 qualitatively produces very good re-
sults (see figure 2 for several examples); however, we would also like a quantitative measure
of performance that allows us to compare di   erent extraction methods. an obvious choice
for evaluation would be metrics used in summarisation; however, since we lack labels for
   correct    extractions we do not have a gold standard to compare against.

instead, we propose a way to measure extraction quality that can be easily applied to labelled
documents at scale. we propose to train a simple    reference    model on full documents, and

5

under review as a conference paper at iclr 2015

proportion convnet id97 rand. fixed
79.79 pick 5
50%
76.72 pick 4
33%
74.87 pick 3
25%
20%
73.20 pick 2
full
first+last

82.74
82.72
82.94
82.84
83.04
68.62

81.98
80.39
80.18
79.70

convnet id97 rand.
80.02
79.05
77.15
74.48

83.12
82.91
82.59
81.71

82.26
81.92
81.48
80.39

table 1: results of classifying extracted documents with the reference model. results
labelled proportion indicate selecting up to the indicated percentage of sentences in the
review, and results labelled fixed show the result of selecting a    xed number of sentences
from each. convnet shows reference model performance on extractions produced by our
convnet. id97 shows reference performance on extractions produced by the shallow
baseline. rand shows reference performance on randomly created extractions. the    nal
two rows show reference accuracy on the full reviews (full ) and when using the common
heuristic of extracting the    rst and last sentence (first+last).

then compare the performance of the reference model on full documents to its performance
on documents created by extracting a small number of sentences.

this evaluation scheme is somewhat unorthodox, but comes with a very intuitive interpre-
tation. if the extraction process chooses task relevant sentences then it should be easy for
the reference model to identify the label of the original document based on an extracted
subset of sentences. on the other hand, choosing irrelevant sentences should confuse the
reference model, reducing its accuracy.

5 experiments

5.1 data preparation

we use the imdb movie review sentiment data set, which was originally introduced by
maas et al. (2011), to demonstrate our extraction technique. this dataset contains a total
of 100000 movie reviews posted on imdb. there are 50000 unlabelled reviews and the
remaining 50000 labelled reviews are divided into a 25000 review training set and a 25000
review test set. each of the labelled reviews has a binary label, either positive or negative.
in our experiments, we use only the labelled portion of this data set.

we pre-process each review by    rst stripping html markup and breaking the review into
sentences and then breaking each sentence into words. we use nltk2 to perform these
tasks. we also map numbers to a generic number token, any symbol that is not in .?! to
symbol and any word that appears fewer than 5 times in the training set to unknown. this
leaves us with a 29493 word vocabulary.

5.2 review summarisation via sentence extraction

we train our convnet model on the imdb movie review data set. the sentence level model
uses 10-dimensional id27s which are convolved with 6 feature maps of width 5,
followed by a 4-max pooling layer and a tanh nonlinearity. the weights of this model are
tied across sentences in a document. the document level model convolves its input with
a bank of 15 feature maps of width 5, followed by 2-max pooling and a tanh nonlinearity.
finally the result is fed into a softmax classi   er which predicts if the sentiment of the review
is positive or negative.

we extract salient sentences from each of the reviews in the imdb movie review test set
using the method of section 3. for evaluation, we also train a reference model using na    ve
bayes on the full training set.

2http://www.nltk.org/

6

under review as a conference paper at iclr 2015

i caught this movie on the sci-fi channel recently. it actually turned out to be pretty decent as
far as b-list horror/suspense    lms go. two guys (one naive and one loud mouthed a **)
take a road trip to stop a wedding but have the worst possible luck when a maniac in a
freaky, make-shift tank/truck hybrid decides to play cat-and-mouse with them. things
are further complicated when they pick up a ridiculously whorish hitchhiker. what makes this
   lm unique is that the combination of comedy and terror actually work in this movie, unlike so
many others. the two guys are likable enough and there are some good chase/suspense scenes.
nice pacing and comic timing make this movie more than passable for the horror/slasher bu   .
definitely worth checking out.

i just saw this on a local independent station in the new york city area. the cast showed
promise but when i saw the director, george cosmotos, i became suspicious. and
sure enough, it was every bit as bad, every bit as pointless and stupid as every george
cosmotos movie i ever saw. he   s like a stupid man   s michael bey     with all the awfulness that
accolade promises. there   s no point to the conspiracy, no burning issues that urge the conspirators
on. we are left to ourselves to connect the dots from one bit of gra   ti on various walls in the    lm
to the next. thus, the current budget crisis, the war in iraq, islamic extremism, the fate of social
security, 47 million americans without health care, stagnating wages, and the death of the middle
class are all subsumed by the sheer terror of gra   ti. a truly, stunningly idiotic    lm.

graphics is far from the best part of the game. this is the number one best th game in
the series. next to underground. it deserves strong love. it is an insane game. there are
massive levels, massive unlockable characters... it   s just a massive game. waste your money on
this game. this is the kind of money that is wasted properly. and even though graphics
suck, thats doesn   t make a game good. actually, the graphics were good at the time. today the
graphics are crap. who cares? as they say in canada, this is the fun game, aye. (you get to
go to canada in thps3) well, i don   t know if they say that, but they might. who knows. well,
canadian people do. wait a minute, i   m getting o    topic. this game rocks. buy it, play it, enjoy
it, love it. it   s pure brilliance.

the    rst was good and original. i was a not bad horror/comedy movie. so i heard a second one
was made and i had to watch it . what really makes this movie work is judd nelson   s character
and the sometimes clever script. a pretty good script for a person who wrote the final
destination    lms and the direction was okay. sometimes there   s scenes where it looks like
it was    lmed using a home video camera with a grainy - look. great made - for - tv movie. it
was worth the rental and probably worth buying just to get that nice eerie feeling and
watch judd nelson   s stanley doing what he does best. i suggest newcomers to watch the
   rst one before watching the sequel, just so you   ll have an idea what stanley is like and get a little
history background.

why do all movies on lifetime have such anemic titles?    an unexpected love    - ooh, how
provocative!!    this much i know    would have been better. the    lm is nothing special. real
people don   t really talk like these characters do and the situations are really hackneyed. the
straight woman who    turns    lesbian seemed more butch than the lesbian character. if you wanna
watch two hot women kiss in a very discreet fashion, you might enjoy this. although it seems like
it was written by someone who doesn   t really get out in the world to observe people. why am i
wasting my time writing about it?

a friend and i went through a phase some (alot of) years ago of selecting the crappest horror
   lms in the video shop for an evening   s entertainment. for some reason, i ended up buying this
one (probably v. v. cheap). the cheap synth soundtrack is a classic of its time and genre.
there   s also a few very amusing scenes. among them is a scene where a man   s being attacked and
defends himself with a number of unlikely objects, it made me laugh at the time (doesn   t seem
quite so funny in retrospect but there you go). apart from that it   s total crap, mind you.
but probably worth a watch if you like    lms like    chopping mall   . yes, i   ve seen that too.

vertigo co - stars stewart (in his last turn as a romantic lead) and novak elevate this, stewart   s
other    christmas movie,    movie to above mid - level entertainment. the chemistry between
the two stars makes for a fairly moving experience and further revelation can be
gleaned from the movie if witchcraft is seen as a metaphor for the private pain that
hampers many people   s relationships. all in all, a nice diversion with legendary stars, 7/10

figure 2: several example extractions chosen by our convnet. the full text of the review is
shown in black and the sentences selected by the convnet appear in colour. while choosing
the    rst and last sentence is a popular pragmatic approach, it is clear from these examples
that this heuristic is not as e   ective as our convnet based scheme. in each example we
select up to 20% of the sentences in the review for extraction.

7

under review as a conference paper at iclr 2015

we compare the performance of our model against several baselines.

1. a shallow neural network model with a single hidden layer. the model uses
id97 to obtain id27s, which it then combines into document embed-
dings by summing the words in the document. it then applies a id28
to the document embedding to predict the sentiment of the document. we apply
the visualisation technique of section 3 to choose sentences to extract in the same
way as for the convnet model.

2. a random model assigns relevance scores to sentences uniformly at random.

3. a    first+last    model which follows the common heuristic that the    rst and last

sentence of a document are often very informative about its content.

the results of this experiment are shown in table 1. even keeping only two sentences from
each review, the accuracy of the reference model drops by less than 1.5% on the test set. in
all cases our convolutional model outperforms all of the baselines we compare against.

we show several examples of extractions created by our model in figure 2. as can be seen,
many of the reviews begin with short descriptions of where the reviewer saw the    lm, or
with a brief summary of the plot. these sentences are not useful since they do not express
an opinion on the movie being reviewed. our model learns to ignore these background
sentences very consistently.

6 conclusion

in this paper we introduced a convnet model for documents with an architecture designed
to support introspection of the document structure. we have also shown that we can apply
the visualisation technique of simonyan et al. (2013) to identify and extract task-speci   c
salient sentences from documents. we demonstrated this technique by extracting sentiment-
relevant sentences from movie reviews.

we also introduced a scalable evaluation method for automatic sentence extraction systems.
by comparing the performance of a reference classi   er on full documents to its performance
on documents created from extracted sentences we can gauge how much task-relevant infor-
mation is preserved by the extraction process.

we compared our convnet extraction model to several baseline extraction methods. our
evaluation shows that our model extracts more task-relevant information than the baseline
methods, even when the total number of extracted sentences is very small.

acknowledgments

we would like to thank phil blunsom and nal kalchbrenner for many interesting discussions
about convnets for nlp and for their contributions to an early version of this work.

references

bahdanau, dzmitry, cho, kyunghyun, and bengio, yoshua. id4 by jointly

learning to align and translate. technical report, university of montreal, 2014.

bengio, yoshua, ducharme, rejean, vincent, pascal, and jauvin, christian. a neural probabilistic

language model. journal of machine learning research, 3:1137   1155, 2003.

bordes, antoine, chopra, sumit, and weston, jason. id53 with subgraph embed-

dings. corr, abs/1406.3676, 2014.

bottou, l  eon. from machine learning to machine reasoning: an essay. machine learning, 94:

133   149, january 2014.

cho, kyunghyun, van merrienboer, bart, gulcehre, caglar, bougares, fethi, schwenk, holger,
and bengio, yoshua. learning phrase representations using id56 encoder-decoder for statistical
machine translation. 2014.

8

under review as a conference paper at iclr 2015

collobert, r, weston, jason, bottou, leon, karlen, michael, kavukcuoglu, koray, and kuksa,
pabvel. natural language processing (almost) from scratch. the journal of machine learning
research, 12:2461   2505, 2011.

devlin, jacob, zbib, rabih, huang, zhongqiang, lamar, thomas, schwartz, richard, and makhoul,
john. fast and robust neural network joint models for id151. in
association for computational linguistics, 2014.

dos santos, ciccero noguelra and gatti, maira. deep convolutional neural networks for sentiment

analysis of short texts. in international conference on computational linguistics, 2014.

gulcehre, caglar and bengio, yoshua. knowledge matters: importance of prior information for

optimization. in international conference on learning representations, 2013.

hermann, karl moritz and blunsom, phil. the role of syntax in vector space models of composi-

tional semantics. proceedings of the acl, pp. 894   904, 2013.

hermann, karl moritz and blunsom, phil. multilingual models for compositional distributional

semantics. in proceedings of acl, 2014.

hinton, g e, krizhevsky, a, and wang, s d. transforming auto-encoders.

in international

conference on arti   cial neural networks, 2011.

hinton, geo   rey e. learning distributed representations of concepts. in annual conference of

the cognitive science society, pp. 1   12, 1986.

hu, baotian, lu, zhengdong, li, hang, and chen, qingcai. convolutional neural network archi-
tectures for matching natural language sentences. in advances in neural information processing
systems 27, pp. 2042   2050, 2014.

kalchbrenner, nal and blunsom, phil. recurrent continuous translation models. in empirical

methods in natural language processing, 2013a.

kalchbrenner, nal and blunsom, phil. recurrent convolutional neural networks for discourse com-
positionality. proceedings of the 2013 workshop on continuous vector space models and their
compositionality, 2013b.

kalchbrenner, nal, grefenstette, edward, and blunsom, phil. a convolutional neural network for

modelling sentences. in association for computational linguistics, 2014.

maas, andrew l, daly, raymond e, pham, peter t, huang, dan, ng, andrew y, and potts,

christopher. learning word vectors for id31. in proceedings of acl, 2011.

mikolov, tomas, chen, kai, corrado, greg, and dean, je   rey. distributed representations of

words and phrases and their compositionality. in nips, 2013.

schwenk, holger. continuous space translation models for phrase-based statistical machine trans-

lation. in international conference on computational linguistics, pp. 1071   1080, 2012.

simonyan, karen, vedaldi, andrea, and zisserman, andrew. deep inside convolutional networks:

visualising image classi   cation models and saliency maps. technical report, 2013.

socher, richard, pennington, je   rey, huang, eric h, ng, andrew y, and manning, christopher d.
semi-supervised recursive autoencoders for predicting sentiment distributions. in conference
on empirical methods in natural language processing, number i, 2011.

socher, richard, huval, brody, manning, christopher d, and ng, andrew y. semantic com-
positionality through recursive matrix-vector spaces. in conference on empirical methods in
natural language processing, 2012.

sutskever, ilya, vinyals, oriol, and le, quoc v. v. sequence to sequence learning with neural

networks. in advances in neural information processing systems 27, pp. 3104   3112, 2014.

weston, jason, chopra, sumit, and bordes, antoine. memory networks. corr, abs/1410.3916,

2014.

yu, lei, hermann, karl moritz, blunsom, phil, and pulman, stephen. deep learning for answer

sentence selection. in nips deep learning workshop, 2014.

zeiler, matthew d and fergus, rob. visualizing and understanding convolutional networks.

technical report, 2012.

zeiler, matthew d, krishnan, dilip, taylor, graham w, and fergus, rob. deconvolutional net-

works. in id161 and pattern recognition, 2010.

zeiler, matthew d, taylor, graham w, and fergus, rob. adaptive deconvolutional networks for
mid and high level id171. in international conference on id161, 2011.

9

