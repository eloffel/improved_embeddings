learning to generate posters of scienti   c papers   

yuting qiang1, yanwei fu2, yanwen guo1   , zhi-hua zhou1 and leonid sigal2
1 national key laboratory for novel software technology, nanjing university, nanjing 210023, china
{qiangyuting.new,ywguo.nju}@gmail.com, zhouzh@nju.edu.cn, {yanwei.fu,lsigal}@disneyresearch.com

2 disney research pittsburgh, 4720 frobes avenue, lower level, 15213, usa

6
1
0
2

 
r
p
a
5

 

 
 
]
i

a
.
s
c
[
 
 

1
v
9
1
2
1
0

.

4
0
6
1
:
v
i
x
r
a

abstract

researchers often summarize their work in the form of
posters. posters provide a coherent and ef   cient way to
convey core ideas from scienti   c papers. generating a
good scienti   c poster, however, is a complex and time
consuming cognitive task, since such posters need to be
readable, informative, and visually aesthetic. in this pa-
per, for the    rst time, we study the challenging prob-
lem of learning to generate posters from scienti   c pa-
pers. to this end, a data-driven framework, that utilizes
id114, is proposed. speci   cally, given con-
tent to display, the key elements of a good poster, in-
cluding panel layout and attributes of each panel, are
learned and inferred from data. then, given inferred lay-
out and attributes, composition of graphical elements
within each panel is synthesized. to learn and validate
our model, we collect and make public a poster-paper
dataset, which consists of scienti   c papers and corre-
sponding posters with exhaustively labelled panels and
attributes. qualitative and quantitative results indicate
the effectiveness of our approach.

introduction

the emergence of large number of scienti   c papers in var-
ious academic    elds and venues (conferences and journals)
is noteworthy. for example, ieee conference on computer
vision and pattern recognition (cvpr) accepted over 600
papers in 2016 alone. it is time-consuming to read all of
these papers for the researchers, particularly those interested
to holistically assess state-of-the-art or emerge with under-
standing of core scienti   c ideas explored in the last year.
converting a conference paper into a poster provides impor-
tant means to ef   ciently and coherently convey core ideas
and    ndings of the original paper. to achieve this goal, it
is therefore essential to keep the posters readable, informa-
tive and visually aesthetic. it is challenging, however, to de-
sign a high-quality scienti   c poster which meets all of the
above design constraints, particularly for those researchers
who may not be pro   cient at design tasks or familiar with
design packages (e.g., adobe illustrator).

   this work is supported by nsfc (61333014, 61373059, and

   corresponding author

61321491) and jiangsusf (bk20150016).
copyright c(cid:13) 2016, association for the advancement of arti   cial
intelligence (www.aaai.org). all rights reserved.

in general, poster design is a complicated and time-
consuming task; both understanding of the paper content and
experience in design are required.

automatic tools for scienti   c poster generation would
help researchers by providing them with an easier way to
effectively share their research. further, given avid amount
of scienti   c papers on arxiv and other on-line repositories,
such tools may also provide a way for other researchers to
consume the content more easily. rather than browsing raw
papers, they may be able to browse automatically generated
poster previews (potentially constructed with their speci   c
preferences in mind).

however, in order to generate a scienti   c poster in accor-
dance with, and representative of, the original paper, many
problems need to be solved: 1) content extraction. both im-
portant textual and graphical content needs to be extracted
from the original paper; 2) panel layout. content should    t
each panel, and the shape and position of panels should be
optimized for readability and design appeal; 3) graphical el-
ement (   gures and tables) arrangement. within each panel,
textual content can typically be sequentially itemized, but
for graphical elements, their size and placement should be
carefully considered. due to these challenges, there are few
automatic tools for scienti   c poster generation.

in this paper, we propose a data-driven method for au-
tomatic scienti   c poster generation (given a corresponding
paper). contents extraction and layout generation are two
key components in this process. for content extraction, we
use textrank (mihalcea and tarau 2004) to extract textual
content, and provide an interface for extraction of graphical
content (e.g.,    gures, tables, etc.). our approach focuses pri-
marily on poster layout generation. we address the layout in
three steps. first, we propose a simple probabilistic graph-
ical model to infer panel attributes. second, we introduce
a tree structure to represent panel layout, based on which
we further design a recursive algorithm to generate new lay-
outs. third, in order to synthesize layout within each panel,
we train another probabilistic graphical model to infer the
attributes of the graphical elements.

compared with posters designed by the authors, our ap-
proach can generate different results to adapt to different
paper sizes/aspect ratios or styles, by training our model
with different dataset, and thus provides more expressive-
ness in poster layout. to the best of our knowledge, this pa-

per presents the    rst framework for poster generation from
the original scienti   c paper.

our paper makes the following contributions:

    probabilistic id114 are proposed to learn sci-
enti   c poster design patterns, including panel attributes
and graphical element attributes, from existing posters.

    a new algorithm, that considers both information con-
veyed and aesthetics, is developed to generate the poster
layout.

    we also collected and make available a poster-paper

dataset with labelled poster panels and attributes.

related work

general graphical design. graphical design has been
studied extensively in computer graphics community. this
involves several related, yet different topics, including text-
based layout generation (jacobs et al. 2003; damera-
venkata, bento, and o   brien-strain 2011; hurst, li, and
marriott 2009), single-page graphical design (o   donovan,
agarwala, and hertzmann 2014; harrington et al. 2004),
photo albums layout (geigel and loui 2003), furniture lay-
out (merrell et al. 2011; yu et al. 2011), and even interface
design (gajos and weld 2005). among them, text-based lay-
out pays more attention on informativeness, while attractive-
ness also needs to be considered in poster generation. other
topics would take aesthetics as the highest priority. however,
some principles (such as alignment or read-order) need to
be followed in poster design. in summary, poster generation
needs to consider readability, informativeness and aesthetics
of the generated posters simultaneously.
manga layout generation. several techniques have been
studied to facilitate layout generation for western comics
or manga. for example,, for example, scene frame extrac-
tion (arai and herman 2010; pang et al. 2014), automatic
stylistic manga layout generation (cao, chan, and lau 2012;
jing et al. 2015), and graphical elements composition (cao,
lau, and chan 2014). for preview generation of comic
episodes (hoashi et al. 2011), both frame extraction and lay-
out generation are considered. other research areas, such as
manga retargeting (matsui, yamasaki, and aizawa 2011)
and manga-like rendering (qu et al. 2008) also draw con-
siderable attention. however, none of these methods can be
directly used to generate scienti   c posters, which is the fo-
cus of this paper.

our panel layout generation is inspired by the recent work
on manga layout (cao, chan, and lau 2012). we use a
binary tree to represent the panel layout. by contrast, the
manga layout trains a dirichlet distribution to sample a
splitting con   guration, and different dirichlet distribution
for each kind of instance need to be trained. instead, we pro-
pose a recursive algorithm to search for the best splitting
con   guration along a tree.

overview

problem formulation. assume that we have a set of posters
m and their corresponding scienti   c papers. each poster
m     m includes a set of panels pm, and each panel p     pm

q   pm

has a set of graphical elements (   gures and tables) gp. each
panel p is characterized by    ve attributes:
text length (lp) text length within a panel;
text ratio (tp) text length within a panel relative to text

length of the whole poster, tp = lp/(cid:80)

lq;

graphical elements ratio (gp) 1 the size of graphical ele-
ments within a panel relative to the total size of graphical
elements in the poster.
panel size (sp) and aspect ratio (rp), sp = wp    hp and
rp = wp/hp, where wp and hp denote the width and
height of a panel with respect to the poster, separately.

each graphical element g     gp has four attributes:
graphical element size (sg) and aspect ratio (rg), sg =
wg    hg and rg = wg/hg, where wg and hg denote the
width and height of a graphical element relative to the
whole paper respectively;

horizontal position (hg) we assume that panel content is
arranged sequentially from top to bottom2; hence only rel-
ative horizontal position needs to be considered, which is
de   ned by a discrete variable hg     {lef t, center, right};
graphical element size in poster (ug) is the ratio of the

width of the graphical element with width of the panel.

to learn how to generate the poster, our goal is to determine
the above attributes of each panel p and each graphical el-
ement g     gp, as well as to infer the arrangement of all
panels.

intuitively, a trivial solution is to use a learning model
(e.g., svr) to learn how to regress these attributes, includ-
ing sp, rp, ug, and hg, while regarding tp, gp , lp, rg, and
sg as features. however, such a solution lacks an insight
mechanism for exploring the relationships between the panel
attributes (e.g., sp) and graphical elements attributes (e.g.,
ug). and it may fail to meet the requirements of readabil-
ity, informativeness, and aesthetics. we thus propose a novel
framework to solve our problem.
overview. to generate a readable, informative and aesthetic
poster, we simulate the rule-of-thumb on how people design
the posters in practice. we generate the panel layout, then ar-
range the textual and graphical elements within each panel.
our framework overall has four steps (as shown in fig-
ure 1). however, the core of our framework focuses on three
speci   c algorithms designed to facilitate poster generation.
we    rst extract textual content from the paper using tex-
trank (mihalcea and tarau 2004)3, this will be detailed in
the experimental result section. non-textual content (   g-
ures and tables) are extracted by user interaction. all these
extracted contents are sequentially arranged and represented
by the    rst blob in figure 1. id136 of the initial panel key

1note that there is a little difference between this variable and
text ratio tp. we do not use the    gure size in poster. instead, we use
the corresponding    gure from the original paper.

2this holds true when using latex beamer to make posters.
3we use textrank for text content extraction, however, tex-
trank can be replaced with other state-of-the-art textual summary
algorithms.

figure 1: overview of the proposed approach.

attributes (such as panel size sp and aspect ratio rp) is then
conducted by learning a probabilistic graphical model from
the training data. furthermore, panel layout is synthesized
by developing a recursive algorithm to further update these
key attributes (i.e., sp and rp) and generate an informative
and aesthetic panel layout. finally, we compose panels by
utilizing the graphical model to further synthesize the visual
properties of each panel (such as the size and position of its
graphical elements).

methodology

panel attribute id136. our approach tries to divide a
scienti   c poster into several rectangular panel blocks. each
panel should not only be of an appropriate size, to contain
corresponding textual and graphical content, but also be in
a suitable shape (aspect ratio) to maximize aesthetic appeal.
our approach learns a probabilistic graphical model to infer
the initial values for the size and aspect ratio of each panel.
as each panel is composed of both textual description and
graphical elements, we assume that panel size (sp) and as-
pect ratio (rp) are conditionally dependent on text ratio tp
and graphical element ratio gp. therefore, the likelihood of
a set of panels p can be de   ned as:

p r(sp, rp|tp, gp) =

p r(sp|tp, gp)p r(rp|tp, gp)

(1)

(cid:89)

p   p

where p r(sp|tp, gp) and p r(rp|tp, gp) are conditional prob-
ability distributions (cpds) of sp and rp given tp and gp. we
de   ne them as two conditional linear gaussian distributions:

(2)

p r(sp|tp, gp) = n (sp; ws    [tp, gp, 1]t,   s)
p r(rp|tp, gp) = n (rp; wr    [tp, gp, 1]t,   r)

(3)
where tp and gp are de   ned by the content extraction step
demonstrated in figure 1; ws and wr are the parameters
that leverage the in   uence of various factors;   s and   r are
the variances. the parameters (ws, wr,   s and   r) are esti-
mated using maximum likelihood from training data. using
the learned parameters, initial attributes of each panel can be
inferred.

note that in order to learn from limited data, this step ac-
tually employs two assumptions: (1) sp and rp are condi-
tionally independent; (2) the attribute sets of panels are in-
dependent. we need the panels to be neither too small in size
(sp), nor too distorted in aspect ratio (rp), to ensure read-
able, informative and aesthetic poster. the two assumptions
introduced here are suf   cient for this task. furthermore, the
attribute values estimated from this step are just good ini-
tial values for the property of each panel. we use the next
two steps to further relax these assumptions and discuss the
relationship between sp and rp, as well as the relationship
among different panels (algorithm 1).
to ease exposition, we denote the set of panels as l =
{(sp1, rp2), (sp2 , rp2 ),       , (spk , rpk )}, where spi and rpi
are the size and aspect ratio of ith panel pi, separately; with
|l| = k.
panel layout generation. one conventional way to design
posters is to simply arrange them in two or three columns
style. this scheme, although simple, however, makes all
posters look similar and unattractive. inspired by manga lay-
out generation (cao, chan, and lau 2012), we propose a
more vivid panel layout generation method. speci   cally, we
arrange the panels with a binary tree structure to help rep-
resent the panel layout. the panel layout generation is then
formulated as a process of recursively splitting of a page, as
is illustrated and explained in figure 2.

conveying information is the most important goal for a
scienti   c poster, thus we attempt to maintain relative size for
each panel during panel layout generation. this motivates
the following id168 for the panel shape variation,

(4)
(cid:48)
pi is the aspect ratio of a panel after optimization.

where r
this will lead to a combined aesthetic loss for the poster,

|

(cid:48)
pi

l(pi) = |rpi     r
k(cid:88)

(cid:48)
loss(l, l

) =

l(pi)

(5)

(cid:48)

where l
is the poster panel set after optimization. in each
splitting step, the combinatorial choices for splitting posi-

i=1

algorithm 1 panel layout generation
input:

panels which we learned from graphical model
l = {(sp1, rp1), (sp2 , rp2 ),       , (spk , rpk )};
rectangular page area x, y, w, h.

output:
1: if k == 1 then
2:

3: else
4:
5:
6:

adjust panels[0] to adapt to the whole rectangular
page area, return the aesthetic loss: |rp0     w/h|;
for each i     [1, k     1] do

t =(cid:80)i

j=1 spj /(cid:80)n

j=1 spj ;

loss1 = panel arrangement((sp1, rp1), (sp2, rp2 ),
       , (spi, rpi), x, y, w, h    t);
loss2 = panel arrangement((spi+1, rpi+1), (spi+2,
rpi+2),       , (spk , rpk ), x, y + h   t, w, h   (1    t));
if loss > loss1 + loss2 then

loss = loss1 + loss2;
record this arrangement;

end if
loss1 = panel arrangement((sp1 , rp1), (sp2, rp2),
       , (spi, rpi), x, y, w    t, h);
loss2 = panel arrangement((spi+1, rpi+1 ), (spi+2,
rpi+2),       , (spk , rpk ), x + w     t, y, w    (1     t),
h);
if loss > loss1 + loss2 then

loss = loss1 + loss2;
record this arrangement;

14:
15:
16:
17:
18:
19: end if
20: return loss and arrangement.

end if
end for

(cid:88)

different from eq. 1, directly inferring hg and ug is not
advisable, since the panel content may exceed the panel
bounding box and affect the aesthetic measure of a poster.
to avoid this problem, we employ the likelihood-weighted
sampling method (fung and chang 1990) to generate sam-
ples from the model, by maximizing the likelihood function
(eq. 6) with this strict constraint,

hp    ug +             lp/wp < hp

(9)

g   p

where    and    denote the width and height of a single char-
acter respectively. the    rst term of the above constraint indi-
cates the height of graphical elements while the second term
represents the height of textual contents.

experimental results

experimental setup. we collect and make available to the
community the    rst poster-paper dataset. speci   cally, we
selected 25 well-designed pairs of scienti   c papers and their
corresponding posters from 600 publicly available pairs we
collected. these papers are all about scienti   c topics, and
their posters have relatively similar design styles. we further

figure 2: panel layout and the corresponding tree structure.
the tree structure of a poster layout contains    ve panels.
the    rst splitting is vertical with the splitting ratio (0.5, 0.5).
the poster is further divided into three panels in the left, and
two panels in the right. this makes the whole page as two
equal columns. for the left column, we resort to a horizontal
splitting with the splitting ratio (0.4, 0.6). the larger one is
further horizontally divided into two panels with the splitting
ratio (0.33, 0.67). we only split the right column once, with
the splitting ratio (0.5, 0.5).

7:

8:
9:
10:
11:
12:

13:

tions can be recursively computed and compared with re-
spect to the id168 above. we choose the panel at-
tributes with the lowest loss (eq. 5). the whole algorithm is
summarized in algorithm 1.
composition within a panel. having inferred layout of the
panels, we turn our attention to composition of graphical
elements within the panels. we model and infer attributes
of graphical elements using another probabilistic graphical
model. particularly, the key attributes we need to estimate
are the horizontal position hg and graphical element size ug.
in our model, horizontal position hg relies on sp, lp and sg,
while ug relies on rp, sg and rg, so the likelihood is
p r(hg, ug|sp, rp, lp, sg, rg) =

p   p

p r(hg|sp, lp, sg)p r(ug|rp, sg, rg) (6)
p r(ug|sp, lp, sg) and p r(hg|rp, sg, rg) are the conditional
id203 distributions (cpds) of ug and hg given
sp, lp, rp, sg and rg respectively. the conditional
linear
gaussian distribution is also used here,

g   p

(cid:89)

(cid:89)

p r(ug|sp, lp, sg) = n (ug|wu    [sp, lp, sg, 1]t,   u)

(7)
where wu is the parameter to balance the in   uence of dif-
ferent factors. since we take horizontal position hg as an
enumerated variable, a natural way to estimate it is to make
it a classi   cation problem by using the softmax function,

p r(hg = i|rp, sg, rg) =

(cid:80)h

ewh i  [rp,sg,rg,1]t
j=1 ewh j  [rp,sg,rg,1]t

(8)

where h is the cardinality of the value set of hg, i.e. h = 3,
whi is the ith row of wh. the maximum likelihood method
is used to estimate parameters, including wu,wh and   u.

stage

text extraction(cid:63)

panel attributes id136

panel layout generation

composition within panel

learn
infer

learn
infer

average time
28.81s
0.85s
0.013s
0.13s
2.17s
0.03s+19.09s(cid:63)

table 1: running time of each step. (cid:63): it takes us 0.03s for
id136 computation and the 19.09s time for latex    le gen-
eration.

annotate panel attributes, such as panel width, panel height
and so on. we make a training and testing split: 20 pairs for
training and    ve for testing. there is total of 173 panels in
our dataset. 143 for training and 30 for testing.

we use textrank to extract textual content from the orig-
inal paper. in order to give different importance of different
sections, we can set different extraction ratio for each sec-
tion. this will result in important sections generating more
content and hence occupying bigger panels. for simplic-
ity, this paper uses equal important weights for all sections.
user-interaction is also required to highlight and select im-
portant    gures and tables from original paper. we use the
id110 toolbox (bnt) (murphy 2002) to esti-
mate key parameters. for graphical element attributes infer-
ence, we generate 1000 samples by the likelihood-weighted
sampling method (fung and chang 1990) for eq. 6 while
the constraint eq.9 is used. with the inferred metadata, the
   nal poster is generated in latex beamerposter format with
lankton theme.

for baseline comparison, we invite three second-year phd
students, who are not familiar with our project, to hand de-
sign posters for the test set. these three students work in
id161 and machine learning and have not yet pub-
lished any papers on these topics; hence they are novices to
research. given the test set papers, we ask the students to
work together and design a poster for each paper.
running time. our framework is very ef   cient. our ex-
periments were done on a pc with an intel xeon 2.0 ghz
cpu and 144gb ram. tab. 1 shows the average time we
needed for each step. strictly speaking, we can not com-
pare with    previous methods   , since we are the    rst work on
poster generation and there is no existing directly compara-
ble work. nevertheless, we argue that the total running time
is signi   cantly less than the time people require to design
a good poster, it is also less than the time spent to generate
the posters made by three novices in quantitative evaluation
section.
quantitative evaluation. we quantitatively evaluate the ef-
fectiveness of our approach.

(1) effectiveness of panel id136. for this step, we
compare the inferred size and aspect ratio of panels with
the trivial solution     svr which trains a linear regressor4

(a)

(b)

figure 4: qualitative comparison of our result (b) and
novice   s result (a). please refer to supplementary material
for larger size    gures.

to predict the panel size and panel aspect ratio from training
data. we use the panel attributes from the original posters5 as
the ground-truth and compute the mean-square error (mse)
of inferred values versus ground-truth values. our results
can achieve 3650.4 and 0.67 for panel size and aspect ra-
tio. by contrast, the values of svr method are 3831.3 and
0.76 respectively. this shows that our algorithm can better
estimates the panel attributes than svr.

(2) user study. user study is employed to compare our
results with original posters and posters made by novices.
we invited 10 researchers (who are experts on the evaluated
topic and kept unknown to our projects) to evaluate these
results on readability, informativeness and aesthetics. each
researcher is sequentially shown the three results generated
(in randomized order) and asked to score the results from
0     10, where 0, 5 and 10 indicate the lowest, middle and
highest scores of corresponding metrics. the    nal results are
averaged for each metric item.

as in tab. 2, our method is comparable to original posters
on readability and informativeness; and it is signi   cantly
better than posters made by novices. this validates the ef-
fectiveness of our method, since the inferred panel attributes
and generated panel layout will save most valuable and im-
portant information. in contrast, our method is lower than
the original posters on aesthetics metric (yet, still higher than
those from novices). this is reasonable, since aesthetics is a
relatively subjective metric and aesthetics generally requires
a    human touch   . it is an open problem to generate more
aesthetic posters from papers.
qualitative evaluation of three methods. we qualita-
tively compare our result (figure 3(b)) with the poster from
novices in figure 3(a) and the original poster figure 3(c).
all of them are for the same paper.

4sp and rp are used as features for svr. the parameters are
chosen using cross-validation. nonlinear kernels (such as rbf)
perform worse due to over-   tting on training data.

5note that, though the panels of original poster may not be the
best ones, they are the best candidate to serve as the ground truth
here.

unnecessarilycomplicatedresearchtitleauthor1author2universityanddepartmentnameabstractinthisdemonstration,wepresentanoveldbms-orientedresearchinfrastructure,calledarizonadatabaselaboratory(azdblab),toassistdatabaseresearchersinconductingalarge-scaleempiricalstudyacrossmultipledbmses.introductionthere,however,havebeenfewdbms-dedicatedlaboratoriesforsupportingsuchscienti   cinvestigation,whilepriorworkmainlyhasfocusedonnetworksandsmartphonesaswewilldiscussinsection3.inthisdemonstration,wepresentanoveldbms-orientedresearchinfrastructure,calledarizonadatabaselaboratory(azdblab),toassistdatabaseresearcherstoconductalarge-scaleempiricalstudyacrossmultipledbmses.notethatthedataprovenanceofthestudyiscollectedintoalabshelf,managedbyacentraldbmsserver.?forconductinglarge-scaleexperiments,azdblabprovidesseveraldecentralizedmonitoringschemes:astand-alonejavaapplication(namedobserver),anajax[1]webapp,andamobileapp.motivationthesecover   (i)cardinalityestimation(identifyingwhataffectstheaccuracyofcardinalityestimates),   (ii)operatorimpact(characterizinghowspeci   ctypesofoperators,e.g.,join,projection,sorting,affecttheaccuracyofcardinalityestimates,executiontimeestimates,andoptimalplanselection),and   (iii)executionplansearchspace(determiningitsdetailedinnerstructure).azdblabsystemoverview   labshelves:theschemaofalabshelfcaptureswho,what,when,which,where,why,andhow,complyingwiththe7-wmodel[8].   decentralizedmonitoringschemes:decentralizedmonitoringschemes:inthissection,wepresentavarietyofnovel,decentralizedmonitoringschemesbeinginuseinazdblab.   forexample,ascenariosourcecode,calledonepass,canbewrittentostudythequerysuboptimalityphenomenonsuchthatwhentheexecutionplansofaquerychangebetweentwoadjacentcardinalities(calledachangepoint),theactualelapsedtimeofthatqueryatalowercardinalityisgreaterthanthatofahighercardinality.observerupdatesitsguitoshowthependingrun.ifanexecutor,tobediscussedinsection4.3,hasanyassignedpendingrun,theexecutorstartstoexecutethatpendingrun,whosestatusthenisupdatedtorunning.   thewebappprovidesthesamefunctionalitiesandguiasobserver,withoutrequiringdirectaccesstothelabshelfserver,therebyachievinggreatersecurity.   theusercannotconductqueryexecutiondataanalysisthroughthemobileapps,buttheusercansetupaconvenientmonitoringenvironmentonthemobileapps.themobileappsalsomakearequesttothesameazdblabwebserver,whichinvokesmethodsfromajaxmanager.   executor:theexecutorthencreatesandpopulatestables,executesqueries,recordsqeresultsintoazdblab.demonstrationourdemoconsistsoftwoparts:1)runningexperimentswithhundredsofqueriesondifferentdbmsesand2)thenanalyzingqeresultsfromthecompletedruns.unnecessarilycomplicatedresearchtitleauthor1author2universityanddepartmentnameabstractusingdensepointtrajectories,ourapproachseparatesanddescribestheforegroundmotionfromthebackground,representstheappearanceoftheextractedstaticbackground,andencodestheglobalcameramotionthatinterestinglyisshowntobediscriminativeforcertainactionclasses.introductioninspiredbythiswork,ourproposedmethodalsomakesuseofthesedensetrajectories;however,weenlistamoregeneralcameramodel(byestimatingthefundamentalmatrixbetweenvideoframes)thatallowsforamorereliableseparationbetweenforegroundandbackgroundpixels,especiallyinnon-planarclutteredscenes.proposedmethodologygivenasetoflabelledvideos,asetoffeaturesisextractedfromeachvideo,representedusingvisualdescriptors,andcombinedintoasinglevideodescriptorusedtotrainamulti-classclassi   erforrecognition.   cameramotion:asobservedinthethreetoprowsoffigure3,thereisacorrelationbetweenhowthecameramoves.   foreground/backgroundseparation:ourproposedseparationwillalloweachtypeoftrajectory(foregroundandbackground)toberepresentedindependentlyandthusmorereliablythanothermethodsthatencodecontextinformationusinginformationfromentirevideoframes[15].   background/contextappearance:unlikeothermethodsthatencodescenecontextholistically(usingbothforegroundandbackground)inavideo[15].   implementationdetails:the   rstfollowsthebagoffeatures(bof)paradigm,usingid116forvisualcodebookgeneration,vqforfeatureencoding,l2id172,anda2kernelid166withinamultichannelapproach(mcid166)[26].experimentalresultswecomparetheperformanceofbothclassi   cationsframeworksmentionedinsection2.4,aswellas,state-of-the-artrecognitionmethodsonbenchmarkdatasets,whenpossible.   datasetsandevaluationprotocols:hollywood2[15]containsalargenumberofvideosretrievedfrom69differenthollywoodmovies.   impactofcontextualfeatures:unlikeothermethodsthatextractcontextinformationfromallthetrajectories(bothbackgroundandforeground)inthevideo,weseethatextractingsurroundingsiftandcammotionfeaturesfromthebackgroundaloneimprovesoverallperformance.   comparisonwithstate-of-the-art:theperformancegainoverthemethodin[23],whichreportsthebestperformanceintheliterature,isasfollows:+2conclusioncontextualfeatures:whencombinedwithforegroundtrajectories,weshowthatthesefeatures,canimprovestate-of-the-artrecognitiononchallengingactiondatasets.(a) designed by novice

(b) our result

(c) original poster

figure 3: results generated by different ways

metric

readability

our method

posters by novices
original posters

6.94
6.69
7.08

informativeness aesthetics avg.
6.95
6.54
7.18

7.06
6.83
7.03

6.86
6.12
7.43

table 2: user study of different posters generated.

it is interesting to show that if compared with the panel
layout of original poster, our panel layout looks more simi-
lar to the original one than the one by novices. this is due to,
   rst, the poster-paper dataset has a relatively similar graphi-
cal design with high quality, and second, our split and panel
layout algorithms that work well to simulate the way how
people design posters. in contrast, the poster designed by
novices in figure 3(a) has two columns, which appears less
attractive to our 10 researchers; it takes the novices around
2 hours to    nish all the posters.
further qualitative evaluation. we further qualitatively
evaluate our results (figure 4) by the general graphical
design principles (o   donovan, agarwala, and hertzmann
2014), i.e.,    ow, alignment,and overlap and boundaries.

flow it is essential for a scienti   c poster to present infor-
mation in a clear read-order, i.e. readability. people always
read a scienti   c poster from left to right and from top to bot-
tom. since algorithm 1 recursively splits the page of poster
into left, right or top, bottom, the panel layout we generate
ensure that the read-order matches the section order of orig-
inal paper. within each panel, our algorithm also sequen-
tially organizes contents which also follow the section order
of original paper and this improves the readability.

alignment. compared with the complex alignment con-
straint in (o   donovan, agarwala, and hertzmann 2014), our
formulation is much simpler and uses an enumeration vari-
able to indicate the horizontal position of graphical elements

hg. this simpli   cation does not spoil our results which still
have reasonable alignment as illustrated in figure 4 and
quantitatively evaluated by three metrics in tab. 2.

overlap and boundaries. overlapped panels will make
the poster less readable and less esthetic. to avoid this, our
approach (1) recursively splits the page for panel layout; (2)
sequentially arranges the panels; (3) enforces the constraint
eq. 9 to penalize the cases of overlapping between graphical
elements and panel boundaries. as a result, our algorithm
can achieve reasonable results without signi   cant overlap-
ping and/or crossing boundaries. similar to the manually
created poster     figure 3(c), our result (i.e., figure 3(b))
does not have signi   cantly overlapped panels and/or bound-
aries.

conclusion and future work

automatic tools for scienti   c poster generation are impor-
tant for poster designers. designers can save a lot of time
with these kinds of tools. design is a hard work, especially
for scienti   c posters, which require careful consideration of
both utility and aesthetics. abstract principles about scien-
ti   c poster design can not help designers directly. by con-
trast, we propose an approach to learn design patterns from
existing examples, and this approach will hopefully lead to
an automatic tool for scienti   c poster generation to aid de-
signers.

facespoofingdetectionthroughpartialleastsquaresandlow-leveldescriptorswilliamrobsonschwartzandersonrochaheliopedriniiinstituteofcomputing,universityofcampinasintroduction   problem:2-dimage-basedfacialveri   cationorrecognitionsystemcanbespoofedwithnodif   culty(apersondisplaysaphotoofanauthorizedsubjecteitherprintedonapiecepaper)   idea:anti-spoo   ngsolutionbasedonaholisticrepresentationofthefaceregionthrougharobustsetoflow-levelfeaturedescriptors,exploitingspatialandtemporalinformation   advantages:plsallowstousemultiplefeaturesandavoidsthenecessityofchoosingbefore-handasmallersetoffeaturesthatmaynotbesuitablefortheproblempartialleastsquares   plsdealswithalargenumberofvariablesandasmallnumberofexamples   datamatrixxandresponsematrixyxn  n=tpt+e,yn  n=uqt+f   practicalsolution:nipalsalgorithmiterativeapproachtocalculateplsfactors   plsweightsthefeaturedescriptorsandestimatesthelocationofthemostdiscriminativeregionsanti-spoofingproposedsolution   avideosampleisdividedintomparts,featureextractionisappliedforeveryk-thframe.theresultingdescriptorsareconcatenatedtocomposethefeaturevector   plsisemployedtoobtainthelatentfeaturespace,inwhichhigherweightsareattributedtofeaturedescriptorsextractedfromregionscontainingdiscriminatorycharacteristicsbetweenthetwoclasses   thetestprocedureevaluatesifanovelsamplebelongseithertotheliveornon-liveclass.whenasamplevideoispresentedtothesystem,thefaceisdetectedandtheframesarecroppedandrescaledexperimentalresultsprint-attackdataset   dataset:200real-accessand200printed-photoattackvideos[1]   setup:facedetection,rescaleto110x40pixels,10framesaresampledforfeatureextraction(hog,intensity,colorfrequency(cf)[2],histogramofshearletcoef   cients(hsc)[3],glcm)   classi   erevaluation:id166typecwithlinearkernelachievedeerof10nuaadataset   dataset:1743liveimagesand1748non-liveimagesfortraining.3362liveand5761non-liveimagesfortesting[4]   setup:facesaredetectedandimagesarescaledto64x64pixels   comparison:tanetal.[4]achievedaucof0.95[1]https://www.idiap.ch/dataset/printattack[2]w.r.schwartz,a.kembhavi,d.harwood,andl.s.davis.humandetectionusingpartialleastsquaresanalysis.inieeeiccv,pages24c31,2009.[3]w.r.schwartz,r.d.dasilva,andh.pedrini.anovelfeaturedescriptorbasedontheshearlettransform.inieeeicip,2011.[4]x.tan,y.li,j.liu,andl.jiang.facelivenessdetectionfromasingleimagewithsparselowrankbilineardiscriminativemodel.ineccv,pages504c517,2010.facespoofingdetectionthroughpartialleastsquaresandlow-leveldescriptorswilliamrobsonschwartzandersonrochaheliopedriniiinstituteofcomputing,universityofcampinasintroduction   problem:2-dimage-basedfacialveri   cationorrecognitionsystemcanbespoofedwithnodi   culty(apersondisplaysaphotoofanauthorizedsubjecteitherprintedonapiecepaper)   idea:anti-spoo   ngsolutionbasedonaholisticrepresentationofthefaceregionthrougharobustsetoflow-levelfeaturedescriptors,exploitingspatialandtemporalinformation   advantages:plsallowstousemultiplefeaturesandavoidsthenecessityofchoosingbefore-handasmallersetoffeaturesthatmaynotbesuitablefortheproblempartialleastsquares   plsdealswithalargenumberofvariablesandasmallnumberofexamples   datamatrixxandresponsematrixyxn  n=tpt+e,yn  n=uqt+f   practicalsolution:nipalsalgorithmiterativeapproachtocalculateplsfactors   plsweightsthefeaturedescriptorsandestimatesthelocationofthemostdiscriminativeregionsanti-spoo   ngproposedsolution   avideosampleisdividedintomparts,featureextractionisappliedforeveryk-thframe.theresultingdescriptorsareconcatenatedtocomposethefeaturevector   plsisemployedtoobtainthelatentfeaturespace,inwhichhigherweightsareattributedtofeaturedescriptorsextractedfromregionscontainingdiscriminatorycharacteristicsbetweenthetwoclasses   thetestprocedureevaluatesifanovelsamplebelongseithertotheliveornon-liveclass.whenasamplevideoispresentedtothesystem,thefaceisdetectedandtheframesarecroppedandrescaledexperimentalresultsprint-attackdataset   dataset:200real-accessand200printed-photoattackvideos[1]   setup:facedetection,rescaleto110x40pixels,10framesaresampledforfeatureextraction(hog,intensity,colorfrequency(cf)[2],histogramofshearletcoe   cients(hsc)[3],glcm)   classi   erevaluation:id166typecwithlinearkernelachievedeerof10nuaadataset   dataset:1743liveimagesand1748non-liveimagesfortraining.3362liveand5761non-liveimagesfortesting[4]   setup:facesaredetectedandimagesarescaledto64x64pixels   comparison:tanetal.[4]achievedaucof0.95[1]https://www.idiap.ch/dataset/printattack[2]w.r.schwartz,a.kembhavi,d.harwood,andl.s.davis.humandetectionusingpartialleastsquaresanalysis.inieeeiccv,pages2431,2009.[3]w.r.schwartz,r.d.dasilva,andh.pedrini.anovelfeaturedescriptorbasedontheshearlettransform.inieeeicip,2011.[4]x.tan,y.li,j.liu,andl.jiang.facelivenessdetectionfromasingleimagewithsparselowrankbilineardiscriminativemodel.ineccv,pages504517,2010.partial least squares problem: 2-d image-based facial verification or recognition system can be spoofed with no difficulty (a person displays a photo of an authorized subject either printed on a piece paper) idea: anti-spoofing solution based on a holistic representation of the face region through a robust set of low-level feature descriptors, exploiting spatial and temporal information advantages: pls allows to use multiple features and avoids the necessity of choosing before-hand a smaller set of features that may not be suitable for the problem introduction anti-spoofing proposed solution experimental results print-attack dataset         dataset: 200 real-access and 200 printed-photo attack videos [1]     setup: face detection, rescale to 110 x 40 pixels, 10 frames are sampled for feature extraction (hog, intensity, color frequency (cf) [2], histogram of shearlet coefficients (hsc) [3], glcm)     classifier evaluation: id166 type c with linear kernel  achieved eer of 10%. pls method achieved eer of 1.67%     a video sample is divided into m parts, feature extraction is applied for every k-th frame. the resulting descriptors are concatenated to compose the feature vector          pls is employed to obtain the latent feature space, in which higher weights are attributed to feature descriptors extracted from regions containing discriminatory characteristics between the two classes      the test procedure evaluates if a novel sample belongs either to the live or non-live class. when a sample video is presented to the system, the face is detected and the frames are cropped and rescaled     pls deals with a large number of variables and a small number of examples     data matrix x and response matrix y        practical solution: nipals algorithm        iterative approach to calculate pls factors     pls weights the feature descriptors and estimates  the location of the most discriminative regions face spoofing detection through partial least squares and low-level descriptors william robson schwartz, anderson rocha, helio pedrini {schwartz, anderson.rocha, helio}@ic.unicamp.br institute of computing, university of campinas loadings residuals scores name # descriptors eer (%) hog 326,880 11.67 intensity 154,000  8.33 cf 27,240 6.67 glcm 159,360 6.67 hsc 581,120 4.33 combination 1,094,600 1.67 feature combination team far (%) frr (%) idiap 0.00 0.00 uoulu 0.00 0.00 amilab 0.00 1.25 casia 0.00 0.00 siani 0.00 21.25 our results 1.25 0.00 comparisons nuaa dataset        dataset: 1743 live images and 1748 non-live images for training. 3362 live and 5761 non-live images for testing [4]     setup: faces are detected and images are scaled to 64 x 64 pixels    comparison: tan et al. [4] achieved auc of 0.95       [1] https://www.idiap.ch/dataset/printattack [2] w. r. schwartz, a. kembhavi, d. harwood, and l. s. davis. human detection using partial least squares analysis. in ieee iccv, pages 24   31, 2009. [3] w. r. schwartz, r. d. da silva, and h. pedrini. a novel feature descriptor based on the shearlet transform. in ieee icip, 2011. [4] x. tan, y. li, j. liu, and l. jiang. face liveness detection from a single image with sparse low rank bilinear discriminative model. in eccv, pages 504   517, 2010. name # descriptors eer (%) auc intensity 4,096 52.20 0.425 hog 6,984 16.80 0.908 hsc 12,416 12.40 0.944 glcm 3,552 9.60 0.960 combination 22,952 8.20 0.966 feature combination y.;

2011.

[jacobs et al. 2003] jacobs, c.; li, w.; schrier, e.; bargeron,
d.; and salesin, d. 2003. adaptive grid-based document
layout. 22(3):838   847.
[jing et al. 2015] jing, g.; hu, y.; guo, y.; yu, y.; and wang,
w. 2015. content-aware video2comics with manga-style
layout. multimedia, ieee transactions on 17(12):2122   
2133.
ya-
[matsui, yamasaki, and aizawa 2011] matsui,
masaki, t.; and aizawa, k.
interactive manga
retargeting. in acm siggraph 2011 posters, 35. acm.
[merrell et al. 2011] merrell, p.; schkufza, e.; li, z.;
agrawala, m.; and koltun, v. 2011.
interactive furniture
layout using interior design guidelines. acm transactions
on graphics (tog) 30(4):87.
[mihalcea and tarau 2004] mihalcea, r., and tarau, p. 2004.
textrank: bringing order into texts. association for compu-
tational linguistics.
[murphy 2002] murphy, k. 2002. bayes net toolbox for mat-
lab.
[o   donovan, agarwala, and hertzmann 2014] o   donovan,
p.; agarwala, a.; and hertzmann, a. 2014. learning layouts
for single-pagegraphic designs. visualization and computer
graphics, ieee transactions on 20(8):1200   1213.
[pang et al. 2014] pang, x.; cao, y.; lau, r. w.; and chan,
a. b. 2014. a robust panel extraction method for manga. in
proceedings of the acm international conference on mul-
timedia, acm mm.
[qu et al. 2008] qu, y.; pang, w.-m.; wong, t.-t.; and
heng, p.-a. 2008. richness-preserving manga screening.
27(5):155.
[yu et al. 2011] yu, l.-f.; yeung, s.-k.; tang, c.-k.; ter-
zopoulos, d.; chan, t. f.; and osher, s. j. 2011. make
it home: automatic optimization of furniture arrangement.
acm transactions on graphics (tog)-proceedings of acm
siggraph 2011, v. 30, no. 4, july 2011, article no. 86.

except for scienti   c poster design, our approach also pro-
vides a framework to learn other kinds of design patterns, for
example web-page design, single-page graphical design and
so on. and by providing different set of training data, our
approach could generate different layout styles. our work
has several limitations. we do not consider font types in our
current implementation and only adopt a simple yet effec-
tive aesthetic metric. we plan to address these problems in
future.

acknowledgements

we would like to thank the anonymous reviewers for their
insightful suggestions in improving this paper.

references

[arai and herman 2010] arai, k., and herman, t.
2010.
method for automatic e-comic scene frame extraction for
reading comic on mobile devices. in information technol-
ogy: new generations (itng), 2010 seventh international
conference on, 370   375. ieee.
[cao, chan, and lau 2012] cao, y.; chan, a. b.; and lau, r.
w. h. 2012. automatic stylistic manga layout. acm trans.
graph. 31(6):141:1   141:10.
[cao, lau, and chan 2014] cao, y.; lau, r. w.; and chan,
a. b. 2014. look over here: attention-directing compo-
sition of manga elements. acm transactions on graphics
(tog) 33(4):94.
[damera-venkata, bento, and o   brien-strain 2011]
damera-venkata, n.; bento, j.; and o   brien-strain, e.
2011. probabilistic document model for automated doc-
in proceedings of the 11th acm
ument composition.
symposium on document engineering, 3   12. acm.
[fung and chang 1990] fung, r. m., and chang, k.-c.
1990. weighing and integrating evidence for stochastic sim-
ulation in id110s. 209   220.
[gajos and weld 2005] gajos, k., and weld, d. s. 2005.
preference elicitation for interface optimization. in proceed-
ings of the 18th annual acm symposium on user interface
software and technology, 173   182. acm.
[geigel and loui 2003] geigel, j., and loui, a. 2003. using
id107 for album page layouts. ieee multimedia
(4):16   27.
[harrington et al. 2004] harrington, s. j.; naveda, j. f.;
jones, r. p.; roetling, p.; and thakkar, n. 2004. aesthetic
measures for automated document layout. in proceedings of
the 2004 acm symposium on document engineering, 109   
111. acm.
[hoashi et al. 2011] hoashi, k.; ono, c.; ishii, d.; and
watanabe, h. 2011. automatic preview generation of comic
episodes for digitized comic search. in proceedings of the
19th acm international conference on multimedia, 1489   
1492. acm.
[hurst, li, and marriott 2009] hurst, n.; li, w.; and mar-
riott, k. 2009. review of automatic document formatting.
in proceedings of the 9th acm symposium on document en-
gineering, 99   108. acm.

