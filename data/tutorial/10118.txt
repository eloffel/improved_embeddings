8
0
0
2

 

y
a
m
6
2

 

 
 
]
h
p
-
c
o
s
.
s
c
i
s
y
h
p
[
 
 

1
v
9
0
9
3

.

5
0
8
0
:
v
i
x
r
a

the diplomat   s dilemma: maximal power for minimal effort in social networks

petter holme1 and gourab ghoshal2
1royalinstituteoftechnology, 10044stockholm, sweden
2department ofphysics, universityofmichigan, annarbor,mi48109,u.s.a.

closeness is a global measure of centrality in networks, and a proxy for how in   uential actors are in social
networks. in most network models, and many empirical networks, closeness is strongly correlated with degree.
however, in social networks there is a cost of maintaining social ties. this leads to a situation (that can occur in
the professional social networks of executives, lobbyists, diplomats and so on) where agents have the con   icting
objectives of aiming for centrality while simultaneously keeping the degree low. we investigate this situation in
an adaptive network-evolution model where agents optimize their positions in the network following individual
strategies, and using only local information. the strategies are also optimized, based on the success of the agent
and its neighbors. we measure and describe the time evolution of the network and the agents    strategies.

i. introduction

to increase or maintain power, or position of in   uence, is a
goal of many professionals. many de   nitions of power recog-
nize that it is not an inherent attribute of an actor,1 but a result
of the interaction between agents. one well-known de   nition
by max weber reads (25):

   power    is the id203 that one actor within a
social relationship will be in position to carry out
his own will despite resistance, regardless of the
basis on which this id203 rests.

de   nitions like this suggest that there is a link between the
power of an actor and its position in the network of social re-
lationships. thus, by examining a social network, one should
be able to say something about the power of the agents. a
major theme in social network studies has been to infer the
power structures in organizations based on the contact pat-
terns of their members (14). in undirected networks of actors,
coupled pairwise by their social ties, one idea of measuring, or
de   ning power, is to say that an actor that is close to others has
more power, than a more peripheral actor does (22). this can
be turned into a network measure called closeness centrality
(which will be de   ned explicitly in the next section). naively,
a way to achieve power would then be to position oneself as
close to everyone else in the network as possible, i.e. to have
a social tie to each one of the network   s actors. in practice,
to make, and maintain, a social tie requires the actor to invest
time and other resources. to have a direct tie to a signi   cant
fraction of the network is thus neither feasible, nor desirable.
we call this situation of two contrasting interests   to maxi-
mize power (in terms of being central), while at the same time
keeping the number of social ties to a minimum   the diplo-
mat   s dilemma.

the diplomat   s dilemma can also be motivated from a more
academic perspective. fueled by the increased availability of
large-scale network datasets, there is a wave of interest in an-
alyzing and modeling systems as graphs. one theme within

1 a person, or other well-de   ned social unit, in the context of our model; we

will use the term agent.

this    eld of complex-id177 (1; 4; 17) has been to
study systems where the network is formed by strategic deci-
sions by the agents (i.e., situations where the success of the
agents depend on the choice of other agents). this problem
has been traditionally been analyzed from a game theory per-
spective. some of the most interesting game-theoretical prob-
lems have been inspired by situations where the agents have
con   icting objectives. in, for example, the iterated prisoner   s
dilemma (2), agents have to choose between trying to achieve
short-time bene   ts by exploiting other agents, and trying to
optimize their long-term pro   t by building a relationship of
mutual trust, but at the same time making them vulnerable
to exploitation. in most real complex networks, and network
models, there is a strong positive correlation between di   er-
ent centrality measures (16) such as the local degree centrality
(the number of neighbors of a vertex), and closeness central-
ity. however, one must note that the correlation between these
quantities, though mathematically possible    high centrality
and low degree (and vice versa)    is not strictly necessary.
a potentially interesting question in the interface between
complex networks and game theory would then be    how can
agents simultaneously maximize their centrality and minimize
their degree?   . another interesting aspect of this problem, in
a more model-theoretic sense, is that the success of the agents
can be estimated from their network positions alone. in most
models of adaptive, coevolutionary networks (8), the score of
the agents is related to some additional traits of the agents
themselves and their interaction. our model di   ers from this
approach in the sense that the success of agents can be mea-
sured from the topological features of the graph itself, rather
than some extremal attribute arti   cially ascribed to the agents.

in this chapter, we will discuss how this problem, the diplo-
mat   s dilemma, can be phrased in more mathematical terms.
we will analyze a model of adaptive agents that try to solve
this problem as the network evolves (10). we will also, dis-
cuss the output of this model, both the evolution of the net-
work and the evolution of strategies of the agents.

ii. definition of the model

a. preliminaries

the framework of our study is a graph g(t) = {v(t), e(t)}
of n vertices v and m(t) edges e(t). the vertex set v is    xed,
but the edge set e(t) varies (both its content and size) with
time. a vertex marks the position of an agent in a social net-
work of edges representing social ties. we will henceforth
also assume the graph to be simple, i.e. no multiple- or self-
edges are allowed. let d(i, j) denote the distance between i
and j. technically we de   ne d(i, j) as the smallest number of
edges in any path (sequence of adjacent edges) connecting i
and j. then, for a connected graph g, the closeness central-
ity (22) is de   ned as:

cc(i) =

.

(1)

n     1

p j   g\{i} d(i, j)

the score function, that the agents seek to optimize, should
increase with closeness centrality and decrease with degree.
a simple choice for such a function is cc(i)/ki (where ki is the
degree of i). however, we do not want to restrict ourselves
to connected networks.
if the network is disconnected, we
make the assumption that being a part of a large component
should contribute to a larger centrality. one way of modifying
closeness centrality to incorporate both these aspects (short
distances and being a part of a large component implies cen-
trality), is to de   ne the centrality c(i) as

c(i) = xj   h(i)\{i}

1

d(i, j)

,

(2)

where h(i) is the connected subgraph i belongs to and d(i, j) is
the graph distance between i and j. the number of elements in
the sum of eq. (2) is proportional to the number of vertices of
i   s connected component which gives a positive contribution
from large components. to obtain this property, we use the
average reciprocal distance, rather than the reciprocal average
distance (as in the original de   nition of closeness centrality).
this adjusted de   nition gives a higher weight on the count of
closer vertices, but captures similar features as closeness does.
with the de   nitions established above, we are now ready to

state the score function:

2

network, and the score function that the agents want to opti-
mize. however, to go from this point to a sensible simulation
scheme, we need to determine how an agent can update its
connections. a    rst, very common assumption, is that the
agents are myopic   that they can receive information from,
and a   ect others in the network only within a certain radius
from itself. this assumption lies behind so much of social
network studies that one may argue that in situations where
the myopic assumption is not needed, so agents can see, and
manipulate the network at large distances, the representation
of the social network as a simple graph is not appropriate.
in our case, we assume that an agent i can change its con-
nections (a   ect the network) within the second neighborhood
  2 = { j     v : d(i, j)     2}, and that i can see the score s( j),
centrality c( j) and degree k j of vertices in   2. (since s and
c are global quantities, some global information reach i indi-
rectly. nevertheless, since the actual contact network cannot
be inferred from this information, we still consider the agents
myopic.)

the simulations proceed iteratively where, each time step,
every vertex can update its network position by adding an edge
to a vertex in   2 and delete an edge to a neighbor. an illustra-
tion of the possible moves can be found in fig. 1.

c. strategies

ideally one would provide the agents with some intelli-
gence and use no further restrictions for how they update their
positions to increase their scores. this is not as easy one can
imagine and, for simpli   cation, one would like to reduce the
capability of the agents further. to do this, we assume that an
agent i updates its position (either by deleting or attaching an
edge), by applying a sequence of tie-breaking actions.

    maxd choose vertices with maximal degree.

    mind choose vertices with minimal degree.

    maxc choose vertices with maximal centrality in the

sense of eq. (2).

    minc choose vertices with minimal centrality.

    rnd pick a vertex at random.

s(i) = ( c(i)/ki

0

if ki > 0
if ki = 0 .

(3)

    no do not add (or remove) any edge.

for the purpose of our simulations, the networks we con-
sider will have a initial con   guration similar to erd  os-r  enyi
networks (6) with m0 number of edges.
in other words,
the network is generated by adding m0 edges one-by-one to
n (isolated) vertices such that no multiple- or self-edge is
formed.

b. moves

we have outlined so far the basic setup for the game   
the underlying graph representing the actors and their social

6

1

,          , sadd

the sequences of actions de   ne the strategies of the agents.
the strategy of an agent i can be stored in two six-tuples
sadd = (sadd
) and sdel representing a priority or-
dering of the addition and deletion actions respectively.
if
sadd(i) = (maxd, minc, no, rnd, mind, maxc) then i
tries at    rst to attach an edge to the vertex in   2(i) with high-
est degree. if more than one vertex has the highest degree,
then one of these is selected by the minc strategy. if still no
unique vertex is found, nothing is done (by application of the
no strategy). note that such a vertex is always found after
strategies no or rnd are applied. if x =     no edge is added
(or deleted).

3

when updating the strategy, i copies the parts of sadd( j) and
sdel( j) that j used the last time step, and let the remaining ac-
tions come in the same order as the strategy vectors prior to
the update. for the purposes of making the set of strategy vec-
tors ergodic, driving the strategy optimization (15; 18), and
modeling irrational moves by the agents (13); we swap, with
id203 ps, two random elements of sadd( j) and sdel( j) ev-
ery strategy vector update. in addition to the strategy space
we also would like to impose ergodicity in the network space
(i.e. the game can generate all n-vertex graphs from any initial
con   guration). in order to ensure this, disconnected clusters
should should have the ability to reconnect to the graph. we
allow this by letting a vertex i attach to any random vertex
of v with id203 pr every trnd   th time step. this is not
unreasonable as even in real social systems, edges may form
between agents out of sight from each other in the social net-
work. in fact some authors have pointed out, that in addition
to information spreading processes, there are other factors that
lead to the evolution of the social networks (cf. ref. (24)).

  2

fig. 1 an illustration of the myopia (the restricted knowledge about
the network). the agents are assumed to have knowledge of, and
be able to a   ect the second neighborhood   2 (shaded in the    gure).
the agent knows the centrality and degree of the neighbors and their
accumulated score the last tstrat time steps. based on this information
the agents can, during a time step, based on their strategies, decide
to delete the edge to a neighbor, and reconnect to a vertex two steps
away.

delete:

mind

minc

no

maxc maxd rnd

e. the entire algorithm

add:

no

rnd mind maxc minc

maxd

c = 0.41

c = 0.55

2

1

4

c = 0.11

3

c = 0.23

fig. 2 an illustration of the strategies of the agents. at a time step,
the agent can delete one edge and add another in order to improve its
score. the way to select a neighbor to delete an edge to (or a next-
nearest neighbor to attach an edge to) is to consecutively omit pos-
sibilities by applying    actions    in a    strategy vector   . this agent   s
leading deletion strategy is mind, meaning it looks for neighbors
with as low degree as possible in the    rst place, to delete the edge to.
in this example there are three neighbors with degree three (marked
with black). to further eliminate neighbors the agent applies the
minc strategy (ranking the neighbors in order of minimum central-
ity c. in this case vertex 1 is the unanimously least central neighbor.
so, at this time step, the agent will delete the edge to 1. as for ad-
dition of edges the leading action is no, meaning no edge will be
added.

to summarize, the algorithm works as follows:

1. initialize the network to a erd  os-r  enyi network with n

vertices and m0 edges.

2. for all agents, start with random permutations of the six

actions as strategy vectors sadd and sdel.

3. calculate the score for all agents.

4. update the agents synchronously by adding and delet-
ing edges as selected by the strategy vectors. with prob-
ability pr, add an edge to a random vertex instead of a
neighbor   s neighbor.

5. every tstrat   th time step, update the strategy vectors. for
each agent, with id203 ps, swap two elements in
it   s strategy vector.

6. increment the simulation time t. if t < ttot, go to step 3.

the parameter navg, averages over di   erent realizations of the
algorithm are performed. we will primarily use the parameter
values m0 = 3n/2, ps = 0.005, tstrat = 10, ttot = 105 and
navg = 100.

d. strategy updates and stochastic rewiring

a. time evolution

iii. numerical results

the strategy vectors are initialized to random permutations
of the six actions. every tstrat   th time step an agent i updates its
strategy vectors by    nding the vertex in   i = { j : d(i, j)     1}
with highest accumulated score since the last strategy update.
this practice of letting the agent mimic the best-performing
neighbor is common in spatial games (19), and is closely re-
lated to the bounded rationality paradigm of economics (13).

to get a feeling for the time evolution, we start by plotting
quantities characterizing the strategies of the agents and the
network structure. the most important parts of the strategy
vectors are the    rst positions sadd
1 . in practice,     90%
of the decisions whether or not to add (or delete) a speci   c
edge do not pass this    rst tiebreaker. in fig. 3(a) and (b) we
can see how complex the time-evolution of sadd
can

and sdel

1

and sdel
1

1

o
n

d
n
r
  
  
  
  

i

d
n
m
  
  
  
  

(a)

0.75

0.25

0.75

0.25

              
              
              
              
       
       
1
              
              
              
              
       
       
       
       
             
             
       
       
             
             
       
       
              
              
              
              
       
       
       
       
             
             
       
       
             
             
       
       
              
              
              
              
       
       
       
       
             
             
       
       
             
             
       
       
              
              
              
              
       
       
       
       
             
             
       
       
             
             
       
       
0.5
              
              
              
              
       
       
       
       
             
             
       
       
             
             
       
       
              
              
              
              
       
       
       
       
             
             
       
       
             
             
       
       
              
              
              
              
       
       
       
       
             
             
       
       
             
             
       
       
              
              
              
              
       
       
       
       
             
             
       
       
             
             
       
       
              
              
              
              
       
       
       
       
             
             
       
       
1
             
             
             
             
       
       
              
        
              
        
        
        
             
             
        
        
             
             
        
              
              
        
        
        
             
             
        
        
             
             
        
              
              
        
        
        
             
             
        
        
             
             
        
              
              
        
        
        
             
             
        
        
             
             
0.5
        
              
              
        
        
        
             
             
        
        
             
             
              
        
              
        
        
        
             
             
        
        
             
             
        
              
              
        
        
        
             
             
        
        
             
             
        
        
              
              
        
        
             
             
        
        
             
             
              
        
        
              
        
        
             
             
0
        
        
             
             
80
(c)
60
40
20
0
15
10
5
0
0.75
0.5
0.25
0

(d)

(b)

(e)

d
x
a
m

c
n
m

i

c
x
a
m

265000

270000

t

275000

  
  
  
  
  
  
  
  

d
d
a

1

  

l
e
d

1

  

i
s
h

i
k
h

1
n

fig. 3 output from an example run of a n = 200 system with
pr = 0.012. (a) and (b) show the fraction of vertices having a certain
leading action for addition   add
(b) respectively.
(c) shows the average score hsi, (d) the average degree k and (e) the
fraction of vertices in the largest connected component n1.

(a) and deletion   add

1

1

4

close to one, meaning that all agents are connected (directly
or indirectly), but sometimes this fraction becomes very low.
it is harder (than for the high-degree peaks) to see the corre-
sponding strategic cause for these fragmented states. there
are usually peaks corresponding to no as the leading addition
action, but these are also accompanied by peaks correspond-
ing to no as the leading deletion action. as we will see, this
feature becomes less pronounced as the system size increases.

(a)

(c)

(b)

(d)

maxc

minc

maxd

mind

rnd

no

fig. 4 four di   erent example networks from a run with the same pa-
rameter values as in fig. 3. the symbols indicate the leading addition
action. (a) shows the common situation where maxc is the lead-
ing addition action.   del
is maxc for almost all agents. (b) shows
1
a transition stage between   add
being
primarily maxc. (c) shows another transient con   guration where a
large number of di   erent addition strategies coexist. (d) shows the
addition strategies in a fragmented state.

being mostly maxd to   add

1

1

be. each sector of the plot corresponds to a leading addition
(or deletion) action, and they have a size in the y-direction pro-
portional to the fraction of vertices having that leading action
value. the time evolution is complex, having sudden cascades
of strategy changes and quasi-stable periods. cascades in the
leading addition action seem to be accompanied by cascades
in the leading deletion action. the particular time-window
shown in fig. 3 was chosen to highlight such cascades. for
the parameter values of fig. 3, cascades involving more than
75% of the vertices happens about once every 105 time steps.
in fig. 3(c) we measure the average score function hsi. be-
ing a non-zero-sum game, the value of hsi can vary signi   -
cantly, a fact which can be seen upon examining the    gure.
most of the time, the system is close to the observed maxi-
mum hsi     80. one reason for lower scores can be seen in
fig. 3(d) where we plot the average degree hki. for some time
steps, the network becomes very dense with an average de-
gree of almost 20. as high degree is not desirable, the average
score is low during this period. this rise in degree has, natu-
rally, a corresponding peak in the leading deletion action no.
another reason of the occasional dips in the average score can
be seen in fig. 3(e) where we plot the fraction n1 that belongs
to the largest connected component. this quantity is usually

b. example networks

in light of the complex time evolution of the system, it is
not surprising that the system attains a great variety of net-
work topologies as time progresses. in fig. 4 we show four
snapshots of the system for a run with the same parameter
values as in fig. 3. in fig. 4(a) the network comes from the
most common strategy con   guration where both the leading
deletion and addition actions are maxc for a majority of the
agents (in this situation, we call the actions dominating). in
this con   guration the network is centered around two indi-
rectly connected hubs. the vertices between these two hubs
have the highest centrality, and since they are within the sec-
ond neighborhood of most vertices in the network, and most
agents have   add
= maxc, these vertices will get an edge
from the majority of agents (thus becoming hubs in the next
time-step). there are 18 isolates with   add
= no. these will
stay isolates until their strategy vectors are mutated, which oc-
curs (on average) every tstrat/ps = 2000   th time step. fig. 4(b)
shows a rather similar network topology with the di   erence
that a majority of the vertices have maxd as their leading ad-
dition action (almost all vertices have   del
= maxc). for this
1

1

1

con   guration, the maxc vertices will move their edges to
the most central vertices whereas the maxd vertices will not
move their edge. in fig. 4(c) we show a more rare, high-hki
con   guration (t     273, 545 in fig. 3). here the leading dele-
tion action is no for about one fourth of the vertices, and the
system is rapidly accumulating edges. in fig. 3(d) we show a
fragmented state, where a number of vertices have the leading
addition action no. the vertices with   add
= no that are not
isolates have   del
= no so they will not fragment the network
1
add,del
= maxc
further. on the other hand, the vertices with   
1
add,del
and   
1

= maxd can fragment the network.

1

c. effects of strategies on the network topology

we are now in a position to examine in detail the net-
work topologies that arise from di   erent dominating addition
and deletion actions. first, we plot histograms (rescaled to
show the id203 density functions) of the network struc-
tural quantities shown in figs. 3(c), (d) and (e)   see fig. 5.
these diagrams all have two peaks   one with low hsi, hki
and hn1i values (where the network is fragmented, the num-
ber of edges small and the scores low), and another broader
peak corresponding to a connected network with higher scores
and more edges. interestingly, the di   erent leading actions
are not completely localized to di   erent peaks but spread out

)
i
s
h
(
p

)
i
k
h
(
p

10

(a)

                   
                   
                   
                   
                   
                   
                   
                   
                   
                   
                   
                   
                   
                   
                   
                   
                   
                   
                   
                   
                   
                   
                   
                   
                   
                   
                   
                   
                   
                   
                   
                   
                   
                   
                   
                   
                   
                   
                   
                   
                   
                   
                   
                   
                   
                   
                   
                   
                   
                   
                   
                   
                   
                   
                   
                   
                   
                   
                   
                   
                   
                   
                   
                   
0
                   
                   
                   
                   
                   
                   
0

20

40

60

80

5

hsi

100

(c)

                     
                     
3
                     
                     
                     
                     
                     
                     
                     
                     
                     
                     
                     
                     
                     
                     
                     
                     
                     
                     
                     
                     
                     
                     
                     
                     
2
                     
                     
                     
                     
                     
                     
                     
                     
                     
                     
                     
                     
                     
                     
                     
                     
                     
                     
                     
                     
                     
                     
1
                     
                     
                     
                     
                     
                     
                     
                     
                     
                     
                     
                     
                     
                     
                     
                     
                     
                     
                     
                     
0
                     
                     
                     
                     
                     
                     
0

1

2

3

4

hki

)
i
s
h
(
p

)
i
k
h
(
p

10

(b)

                   
                   
                   
                   
                   
                   
                   
                   
                   
                   
                   
                   
                   
                   
                   
                   
                   
                   
                   
                   
                   
                   
                   
                   
                   
                   
                   
                   
                   
                   
                   
                   
                   
                   
                   
                   
                   
                   
                   
                   
                   
                   
                   
                   
                   
                   
                   
                   
                   
                   
                   
                   
                   
                   
                   
                   
                   
                   
                   
                   
                   
                   
                   
                   
                   
                   
                   
                   
                   
                   
0
                   
                   
                   
                   
                   
                   
0

20

40

80

60

5

hsi

100

3

2

(d)

                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
0
                    
                    
                    
                    
                    
                    
0

1

1

4

3

2 hki

10

)
i
1
n
h
(
p

(e)

                     
                     
                     
                     
                     
                     
                     
                     
                     
                     
                     
                     
                     
                     
                     
                     
                     
                     
                     
                     
                     
                     
                     
                     
                     
                     
                     
                     
                     
                     
                     
                     
5
                     
                     
                     
                     
                     
                     
                     
                     
                     
                     
                     
                     
                     
                     
                     
                     
                     
                     
                     
                     
                     
                     
                     
                     
                     
                     
                     
                     
                     
                     
                     
                     
                     
                     
0
                     
                     
                     
                     
                     
                     
0
1

0.2

0.4

0.6

0.8

hn1i

)
i
1
n
h
(
p

10

(f)

                     
                     
                     
                     
                     
                     
                     
                     
                     
                     
                     
                     
                     
                     
                     
                     
                     
                     
                     
                     
                     
                     
                     
                     
5
                     
                     
                     
                     
                     
                     
                     
                     
                     
                     
                     
                     
                     
                     
                     
                     
                     
                     
                     
                     
                     
                     
                     
                     
                     
                     
                     
                     
                     
                     
                     
                     
                     
                     
                     
                     
0
                     
                     
                     
                     
                     
                     
0
1

0.4

0.6

0.2

0.8

hn1i

fig. 5 the id203 density function of average scores (a), (b),
average degrees (c), (d), and relative sizes of the largest connected
component (e), (f). the di   erent    elds represent di   erent leading
addition actions (a), (c), (e), and di   erent leading deletion actions
(b), (d), (f). the vertical size of a    eld gives the id203 density
function conditioned to that leading action. the curves are averages
over ten runs of 105 timesteps with the same parameter values as in
fig. 3. the color codes of the actions are the same as in fig. 3.

5

1

over the whole range. another counter-intuitive observation
is that there seems to be more agents with   add
= no in the
1
more dense peaks. these vertices (with   add
= no) seem to
be primarily isolated and do not a   ect the majority of vertices
(connected in the largest component). they will therefore stay
isolated until their strategies have changed or they have been
connected to the rest of the network by random connections.
we also observe that there is a larger variety of leading ad-
dition actions than leading deletion actions. a possible inter-
pretation of this is that the    tness of agents is more dependent
on the leading addition action. this seems natural in a situ-
ation where it is disadvantageous to connect to a majority of
agents (so the choice of neighbor to disconnect is not impor-
tant), however it is bene   cial to connect to to a minority of
well established agents.

1

1

1

1

= no (b). the   add

one of the most widely studied and revealing metrics of
network structure, is the degree distribution   the id203
mass function of the degrees of vertices. in fig. 6 we plot the
degree distribution for dominating actions   add
= maxc (a)
and   add
= maxc graph has two high-k
peaks, corresponding to the hubs in the network. the exis-
tence of two broad peaks as opposed to only one is strange,
and the reasons for this is not immediately apparent. the
  add
= no graphs (whose averaged degree distribution are
shown in (b)) are more dense, as expected. however, they
also have a large-k peak, which is probably related to, either
the strategies of other agents, or a residue from the preceding
period (remember that the periods of dominating   add
= no
is very short compared with the   add
= maxc periods). this
implies that one can separate system-wide e   ects of some
strategy driving the decisions of the majority, but there will
also be other e   ects present in the network. note that, while
many studies have focused on the emergent properties of de-
gree distributions as n        , the interesting features of our
model occurs for smaller system sizes, consequently we be-
lieve this limit is not interesting or relevant to our study and
we do not consider it.

1

1

we now proceed to look at four other measures of di   er-
ent network structures and how they depend on the dominat-
ing addition and deletion actions. the    rst two measures we

1
1

0.1
0.1

0.01
0.01

k
k
p
p

0.001
0.001

10   4
10   4

10   5
10   5

1
1

(a)
(a)

maxc
maxc

10
10

k
k

100
100

1
1

0.1
0.1

0.01
0.01

k
k
p
p

0.001
0.001

10   4
10   4

10   5
10   5

1
1

(b)
(b)

no
no

10
10

k
k

100
100

fig. 6 the degree distribution for systems with the same parameter
values as in fig. 3. panel (a) shows the averaged degree distribution
when more than half of the agents have maxc as their leading addi-
tion actions. panel (b) displays the corresponding plot for the leading
addition action no.

1

= minc and   del
1

consider are the degree k and score s.
in fig. 7(a) and (b)
we plot the average values of these quantities (averaged over
all vertices, regardless of strategy, and averaged over all sam-
ples with a particular dominating strategy). this plot is based
on ten runs for 105 time steps, with network quantities mea-
sured every tenth time step. during these runs, the two lead-
ing actions     add
= mind were never
employed. we note that the most common leading actions
(for both addition and deletion) maxc and maxd gives the
highest average score. this does not mean that all agents have
a high score in these situations   from figs. 4(a) and (b) we
know that the score can di   er much from one agent to another.
the degrees are low for these strategies, which is a necessary
(but not su   cient) condition for a low score. for   add
= no
the average degree is also low, but the score is much lower
than for   add
= maxc and maxd. the reason, as pointed
out above, is that the network can become heavily fragmented
for this leading addition action. the   add
corresponding to
the highest degree is rnd, this might seem strange, but dur-
ing these runs (which is also visible in fig. 3)   add
= rnd is
correlated with   del
= no which is a state naturally leading
1
to a comparatively dense network. the other leading actions
  add
= minc result in low scores and
sparse networks.

= mind and   del
1

1

1

1

1

1

the other two measures we examine are the assortativity
and id91 coe   cient. before discussing our results, let us
   rst de   ne these quantities in detail. the average degree tells
us if the network is sparse or dense. the degree distribution
gives a more nuanced picture of how homogeneous the set of
vertices are with respect to the number of neighbors. the next

i
s
h

60

40

20

0

0.2

i
c
h

0.1

(a)

hki

(c)

5

10

15

i
s
h

60

40

20

0

0.2

i
c
h

0.1

(b)

hki

(d)

5

10

15

0
   0.8

   0.6

   0.4
hri

   0.2

0

0
   0.8

   0.6

maxc

minc

maxd

mind

   0.4
hri

rnd

   0.2

0

no

, or   del

fig. 7 average values of four di   erent network structural quantities
for di   erent dominating addition and deletion actions (i.e. that more
than half of the agents have a speci   c   add
1 ). (a) shows the
average score as a function of degree for di   erent dominating   add
.
(b) is the corresponding plot for   del
1 . (c) displays the id91 coef-
   cient as a function of assortativity for di   erent dominating   add
. (d)
is the corresponding plot for di   erent   del
1 . the bars indicate standard
errors. the data comes from simulation of ten runs (di   erent random
number generator seeds) of 105 time steps. two actions were never
attained during these runs:   add

= mind.

= minc and   del
1

1

1

1

1

6

level of complexity in describing the network with respect to
the agents    degree, is to measure the correlations between the
degrees of vertices at either side of an edge.
in particular,
one can determine if high-degree vertices are primarily con-
nected to similar high degree vertices, or instead are linked to
low-degree vertices. the assortativity r is a measure of ver-
tices    tendency to connect to other vertices of similar type, in
this case those with similar degree (17). in technical terms, r
is the pearson correlation coe   cient of the degrees at either
side of an edge. there is an additional caveat that we need
to consider; since the edges in our networks are undirected,
r has to be symmetric with respect to edge-reversal (i.e. re-
placing (i, j) by ( j, i)). however the the standard de   nition of
the pearson correlation coe   cient does not account for this
symmetry. the way to    x this problem is to let one edge con-
tribute twice to r, i.e. to represent an undirected edge by two
directed edges pointing in opposite directions. if one employs
an edge list representation internally (i.e., if edges are stored
in an array of ordered pairs (i1, j1),          , (im, jm)) then we can
write the adjusted r as,

r =

4hk1 k2i     hk1 + k2i2
2hk2
2i     hk1 + k2i2
1

+ k2

,

(4)

where, for a given edge (i, j), k1 is the degree of the    rst ar-
gument (i.e., the degree of i), k2 is the degree of the second
argument and the brackets h         i denote averaging. the range
of r is [   1, 1] where negative values indicate a preference for
highly connected vertices to attach to low-degree vertices, and
positive values imply that vertices tend to be attached to other
vertices with degrees of similar magnitudes.

the id91 coe   cient, on the other hand, is a measure of
transitivity in the network. in other words it checks whether
neighbors of a node are also connected to each other (thus
forming triangles). it is a well known empirical fact that so-
cial acquaintance networks have a strong tendency to form
triangles (9) and it is therefore a worthwhile exercise to exam-
ine whether the networks generated by our model display this
feature. there is in principle, more than one way to de   ne the
id91 coe   cient. here we employ the most commonly
used one (3),

c = 3ntriangle (cid:14) ntriple,

(5)

where ntriangle is the number of triangles and ntriple is the num-
ber of connected triples (subgraphs consisting of three vertices
and two or three edges). the factor of three is included to nor-
malize the quantity to the interval [0, 1].

now that we have de   ned these quantities we refer back
to fig. 7. we note that the most common leading actions
add,del
= maxc and maxd have the lowest hci and hri val-
  
1
ues. a possible explanation for this could be the following.
consider a triangle, a subgraph of three vertices connected
by three edges. the graph will be connected even if one of
these edges is deleted. in a situation where edges are expen-
sive, this kind of redundancy is not desired. for this reason,
it seems natural that, on average, the most successful strate-
gies maxc and maxd have few triangles. the negative as-
sortativity of these situations are also conspicuous features of

the examples shown in figs. 4(a) and (b) (most vertices there
are only connected to the two hubs, but the hubs are not con-
nected to each other). for networks with a broad spectrum
of degrees, it is known that hci and hri are relatively strongly
correlated (12). this is also true in figs. 7(c) and (d) where
the relationship between hci and hri is monotonically increas-
ing. the network con   gurations with highest hci and hri are
the ones with   add
= minc. since these
networks are both sparse and fragmented, some components
must have a large number of triangles (probably close to be-
ing fully connected). the denser states, with   add
= rnd and
  del
= no, have intermediate hci- and hri-values, meaning
1
that the edges are more homogeneously spread out, similar to
the network in fig. 4(c).

= mind and   del
1

1

1

d. transition probabilities

from fig. 3 it seems likely that the ability of one leading ac-
tion to grow in the population depends on the other predomi-
nant strategies in the system. for example,   add
= rnd dom-
inates after a period of many agents employing   add
= mind
as the leading strategy. consequently, it is worth asking the
question: how does the id203 of one leading action de-
pend on the con   guration at earlier time steps?

1

1

we investigate this qualitatively by calculating the    transi-
tion matrix    t    with elements t    (s1, s   
1) giving the id203
of a vertex with the leading action s1 to have the leading ac-
1 at the next time step. however, note that the dynamics
tion s   
is not fully determined by t   , and is thus not a transition ma-
trix in the sense of other physical models. if that were the
case (i.e. the current strategy is independent of the strategy
adopted in the previous time step) we would have the relation
j. to study the deviation from this null-model,
t    
i j
we assume the diagonal (i.e. the frequencies of the strategies)
given, and calculate t de   ned by,

= qt    
i t    

ti j = t    

i j/qt    
i t    
j.

(6)

the values of t for the parameters de   ned in fig. 3 are dis-
played in tabs. i and ii. the o   -diagonal elements have
much lower values than 1 (the average o   -diagonal    val-
ues are 0.014 for addition strategies and 0.010 for deletion).
this re   ects the contiguous periods of one dominating ac-
tion. note that transitions between maxc and rnd are over-
represented: t    del
rnd,maxc     0.027, which is more
than twice the value of any other o   -diagonal element involv-
ing maxc or rnd. as another token of the problem   s com-
plexity, the matrix is not completely symmetric t    del
rnd,no is
twice (    3 s.d.) as large as t    del
no,rnd meaning that it is easier
for rnd to invade a population with no as a leading deletion
action, than vice versa.

maxc,rnd     t    del

e. dependence on system size and noise

so far we have focused on one set of parameter values. in
this section we investigate how the system behavior depends

7

0
0
8
=

n

0
0
4
=

n

0
0
2
=

n

0.5

1
          
          
          
          
          
          
          
          
          
          
          
          
          
          
          
          
          
          
          
          
          
          
          
          
          
          
          
          
          
          
          
          
          
          
          
          
0
          
          
          
          

          
          
          
          
          
          
          
          
          
          
          
          
          
          
          
          
          
          
          
          
          
          
          
          
          
          
          
          
          
          
          
          
          
          

(a)

0.1

0.2

i

d
d
a
  
h

1

0.5

1
          
          
          
          
          
          
          
          
          
          
          
          
          
          
          
          
          
          
          
          
          
          
          
          
          
          
          
          
          
          
          
          
          
          
          
          
          
          
0
          
          
          
          

          
          
          
          
          
          
          
          
          
          
          
          
          
          
          
          
          
          
          
          
          
          
          
          
          
          
          
          
          
          
          
          
          
          
          
          
          
          

(b)

0.1

0.2

i

d
d
a
  
h

1

pr

pr

0.5

1
          
          
          
          
          
          
          
          
          
          
          
          
          
          
          
          
          
          
          
          
          
          
          
          
          
          
          
          
          
          
          
          
          
          
          
          
0
          
          
          
          

          
          
          
          
          
          
          
          
          
          
          
          
          
          
          
          
          
          
          
          
          
          
          
          
          
          
          
          
          
          
          
          
          
          
          
          

(d)

0.1

0.2

i

l
e
d
  
h

1

pr

1

0.5

0

         
         
         
         
         
         
         
         
         
         
         
         
         
         
         
         
         
         
         
         
         
         
         
         
         
         
         
         
         
         
         
         
         
         
         
         
         
         
         
         
         
         

         
         
         
         
         
         
         
         
         
         
         
         
         
         
         
         
         
         
         
         
         
         
         
         
         
         
         
         
         
         
         
         
         
         
         
         

(e)

0.1

0.2

i

l
e
d
  
h

1

pr

1

0.5

0

1

0.5

0

         
         
         
         
         
         
         
         
         
         
         
         
         
         
         
         
         
         
         
         
         
         
         
         
         
         
         
         
         
         
         
         
         
         
         
         
         
         
         
         
         
         

         
         
         
         
         
         
         
         
         
         
         
         
         
         
         
         
         
         
         
         
         
         
         
         
         
         
         
         
         
         
         
         
         
         
         
         
         
         

(c)

0.1

0.2

pr

         
         
         
         
         
         
         
         
         
         
         
         
         
         
         
         
         
         
         
         
         
         
         
         
         
         
         
         
         
         
         
         
         
         
         
         
         
         
         
         
         
         
         
         

         
         
         
         
         
         
         
         
         
         
         
         
         
         
         
         
         
         
         
         
         
         
         
         
         
         
         
         
         
         

(f)

0.1

0.2

pr

i

1

d
d
a
  
h

i

1

l
e
d
  
h

i
k
h

5

4
3

1
0.9
0.8

0.7

i
1
n
h

0.1

0.2

0.1

0.2

0.3

pr

0.3

pr

(g)

(h)

0.4

0.4

fig. 8 the system   s dependence on the topological noise level (via
the fraction of random rewirings pr) for di   erent system sizes n.
panels (a), (b) and (c) show the fraction h  add
1 i of leading addition
actions   add
for systems of n = 200, 400 and 800. panels (d), (e)
and (f) show the fraction of preferred deletion actions for the same
three system sizes, while (g) shows the average degree and (h) the
average size of the largest connected component hn1i.

1

on the number of agents and the noise level in the deletion
and attachment mechanism. in fig. 8, we tune the noise level
(fraction of random attachments) pr for three system sizes. in
panels (a)   (c) we show the fraction of leading addition ac-
tions among the agents h  add
1 i (averaged over     100 runs and
105 time steps). the quantities   add,del
denotes the fraction
1
add,del
of agents having a speci   c   
. as observed in fig. 3(a)
1
the leading action is maxc followed by maxd and rnd.
the leading deletion actions, as seen in panels (d)   (f), are
ranked similarly except that maxd has a larger (and increas-
ing) presence. if pr = 1, then all actions are equally likely
(they do not have any meaning   all strategies will result in
random moves equal to sadd
= sdel
= rnd). there are trends
1
in the pr-dependences of h  add
1 i, but apparently no emerging
discontinuity. this observation, (which also seems to hold for
the ps-scaling), that there is no phase transition for any param-
eter value governing the id203 of random permutations
in the strategy vectors, is an indication that the results above
can be generalized to a large parameter range. we also note
that, although the system has the opportunity to be passive
(i.e. agents having sadd
= no), this does not happen.
this situation is reminiscent of the    red queen hypothesis    of
evolution (23)   organisms need to keep evolving to maintain
their    tness.

= sdel
1

1

1

next we look at the dependence of the network structure on

maxc
minc
maxd
mind
rnd
no

maxc

1

0.0169(3)
0.0093(3)
0.0115(4)
0.0157(5)
0.0007(0)

minc

0.0164(3)

1

0.0104(7)
0.030(2)
0.024(2)
0.0031(2)

maxd
0.0088(2)
0.0113(6)

1

0.0130(7)
0.020(1)
0.0009(0)

mind

0.0107(4)
0.036(2)
0.0103(6)

1

0.064(5)
0.0036(2)

rnd

0.0151(5)
0.025(2)
0.0206(9)
0.059(5)

1

0.0042(4)

8

no

0.0010(0)
0.0017(3)
0.0003(0)
0.0020(2)
0.0023(5)

1

table i values for the t matrices for addition. (ti j is the deviation from the expected value in a model of random transitions given the
diagonal values.) the values are averaged over 100 realizations of the algorithm. all digits are signi   cant to one s.d. the parameter values are
the same as in fig. 3. numbers in parentheses are the standard errors in units of the last decimal.

maxc
minc
maxd
mind
rnd
no

maxc

1

0.0098(2)
0.0133(4)
0.0087(2)
0.0269(3)
0.0097(3)

minc

0.0100(2)

1

0.0067(3)
0.011(1)
0.0094(4)
0.0076(3)

maxd
0.0131(4)
0.0070(3)

1

0.0054(2)
0.0128(3)
0.0053(2)

mind

0.0094(2)
0.010(1)
0.0055(2)

1

0.0083(2)
0.0078(3)

rnd

0.0266(3)
0.0105(4)
0.0124(3)
0.0101(2)

1

0.0131(3)

no

0.0126(3)
0.0050(3)
0.0062(2)
0.0055(3)
0.0072(3)

1

table ii same as in tab. i but for deletion, instead of addition, strategies.

the number of agents and the noise level. the average degree,
plotted in fig. 3(g) is monotonously increasing with pr. there
is, however, a qualitative di   erence in the size scaling   for
pr . 0.12 the average degree increases with n, for pr & 0.12
this situation is reversed.
in fig. 3(h) we plot the average
largest-component size as a function of pr for di   erent sys-
tem sizes. the behavior is monotonous in both pr and n   
larger pr, or a larger system size, means higher hn1i. in all
network models we are aware of (allowing fragmented net-
works), a decreasing average degree implies a smaller giant
component. for pr & 0.12, in our model the picture is the
opposite   as the system grows the giant component spans an
increasing fraction of the network. this also means that the
agents, on average, reach the twin goals of keeping the degree
low and the graph connected.

iv. discussion

we have presented a general game theoretic network prob-
lem, the diplomat   s dilemma   how can an agent in a network
simultaneously maximize closeness centrality and minimize
degree. the motivation for this problem comes in part from
a type of social optimization situation where agents seek to
gain power (via closeness centrality) and keep the cost (de-
gree) low.
it can also be motivated from a more academic
point of view   interesting dynamics often comes from when
agents simultaneously try to optimize con   icting objectives.
the diplomat   s dilemma is one of the simplest such situations
in a networked system, because the score function does not de-
pend on any additional variable, or trait, of the vertices, only
the vertex    position in the network.

we devise an iterative simulation where at every time step,
an agent can delete it   s connection to a neighbor and add an
edge to a second neighbor, based on the information it pos-

sesses about the network characteristics of vertices within its
local neighborhood (upto second neighbors). the agents use
strategies that they update by imitating the best performing
neighbor within this information horizon. the dynamics are
driven by occasional random moves and random permutations
of the vectors encoding the strategies of the agents. for the
sake of    exibility, the de   nition of the problem as stated in
this chapter, is deliberately vague. to turn it into a mathe-
matically well-de   ned problem, one has to specify how the
agents can a   ect their position in the network and what in-
formation they can use for this objective. there are of course
many choices for how to do this. although we believe our
formulation is natural, it would be very interesting to rephrase
these assumptions. a future enhancement would be to equip
the agents with methods from the machine learning commu-
nity to optimize their position, and to tune the amount of in-
formation accessible to the agents. a mathematical simpli-
   cation of the problem would be to let all agents know the
precise network topology at all times (this may however lead
to some conceptual problems   if the information about the
network is obtained via the network, it would be strange if the
picture of the network close to an agent would not be more
accurate than the picture of more remote sections of the net-
work). another interesting version of the problem would be to
require an edge to represent an agreement between both ver-
tices, so that an agent i cannot add an edge (i, j) unless j    nds
this pro   table.

nevertheless, despite the simplicity of our model, the time
evolution of the simulation is strikingly complex, with quasi-
stable states, trends, spikes and cascades of strategies among
the agents. this complex dynamics is also captured in var-
ious metrics measuring di   erent levels of network structure.
furthermore, the network structure and the agents    strategies
directly in   uence one another.
if the agents stop deleting
edges, the average degree of the network will grow rapidly,

which may bene   t a strategy aiming to lower the degree of the
agents. this feedback from network structure, to the agents
and their decisions about how to update their networks is
a central theme in the    eld of adaptive, coevolutionary net-
works (8). we believe that all forms of social optimization
involve such feedback loops, which is a strong motivation
for studying adaptive networks. the complexity of the time-
evolution, especially in the network structural dynamics is
more striking for intermediate system sizes. indeed, many in-
teresting features of our simulation are not emergent in the
large-system limit, but rather present only for small sizes.
models in theoretical physics have traditionally focused on
properties of the system as n        . in models of social sys-
tems however, extrapolating to in   nite size is not necessarily
a natural limit in the same way (it will of course be interesting
to examine the limiting behavior of such models). we believe
this is a good example of the dangers of taking the large-size
limit by routine   the most interesting relevant features of the
model may be neglected.

in a majority of the cases in our simulations, most of the
agents use a strategy where they both delete, and attach to
vertices according to the maxc action. this implies that the
agent    rst deletes the edge to the most central vertex in the
second neighborhood (in the sense of a modi   ed closeness
centrality), and then reattaches to the most central vertex two
steps away (before the deletion). in practice this means that
an agent typically transfers an edge from it   s most central im-
mediate neighbor to it   s most central neighbor two steps away.
this strategy makes the agent move towards the center with-
out increasing its degree, which clearly seems like a reason-
able procedure in the diplomat   s dilemma. however, this strat-
egy is not evolutionary stable in the presence of noise (hence
the complex time evolution). this strategy creates networks
with low id91 coe   cients, i.e., there are a comparatively
small number of triangles. since forming a triangle introduces
an extra edge, which is expensive, without changing the size
of connected component, one can understand why agents are
reluctant to form these triangles per se in our formulation of
the problem.

di   erent strategies have di   erent ability to invade one an-
other. to test this we measure the deviation from random tran-
sitions from one dominating action to another (given the fre-
quency of particular strategies), concluding for example that
it is about twice as easy for rnd to invade no as a leading
deletion action. another interesting aspect is that (for some
noise levels), as the system size increases, the network be-
comes both more connected (the relative fraction of vertices in
the largest connected component increases), and more sparse
(the average degree decreases). this is in sharp contrast to
all other generative network models that we are aware of, but
de   nitely consistent with the objectives of the general prob-
lem (where large connected components and low degrees are
desired).

what does this result tell us about the real professional life
of diplomats? maybe that they can, by sel   shly optimizing
their positions in the network, self-organize to a connected
business network where they need only a few business con-
tacts, without knowing more about the network than the sec-

9

ond neighborhood. however to make a stronger and more
conclusive statement about the optimal strategy, more results
are needed. this is something we hope to gather from future
studies.

one of the problems facing this type of mechanistic mod-
eling of social information processes (5; 7; 11; 20; 21), is
that they are very hard to validate. information spreading in
social systems is neither routed from agent to agent like the
information packets in the internet, nor do they spread in the
same fashion as epidemics. instead the spreading dynamics
is content dependent. di   erent types of information may be
spreading over di   erent social networks, following di   erent
dynamic rules. there are some promising datasets for study-
ing social information spreading. for example, networks of
blogs, internet communities, or social networking sites gener-
ate large amounts of potentially valuable data, although these
data sets are not necessarily conducive to the questions that
adaptive models such as the one described in this chapter seek
to address. in the near future, we hope mechanistic modeling
of social information processes will be more data driven, ask-
ing questions that can actually be validated through empirical
study.

acknowledgments

p.h. acknowledges support from the swedish foundation
for strategic research. g.g. thanks the james s. mcdonnell
foundation for support. the authors thank matteo marsili for
comments.

references

[1] r. albert and a.-l. barab  asi. statistical mechanics of complex

networks. rev. mod. phys, 74:47   98, 2002.

[2] r. axelrod. the evolution of cooperation. basic books, new

york, 1984.

[3] a. barrat and m. weigt. on the properties of small-world net-

work models. eur. phys. j. b, 13(3):547   560, 2000.

[4] s. n. dorogovtsev and j. f. f. mendes. evolution of networks:
from biological nets to the internet and www. oxford uni-
versity press, oxford, 2003.

[5] g. ehrhardt, m. marsili and f. vega-redondo. di   usion and
growth in an evolving network. int. j. game theory, 34:383   
397, 2006.

[6] p. erd  os and a. r  enyi. on random graphs i. publ. math. de-

brecen, 6:290   297, 1959.

[7] s. gil and d. h. zanette. coevolution of agents and networks:
opinion spreading and community disconnection. physics let-
ters a, 356:89   94, 2006.

[8] t. gross and b. blasius. adaptive coevolutionary networks: a

review. j. roy. soc. interface, 5:259   271, 2008.

[9] p. w. holland and s. leinhardt. some evidence on the transitiv-
ity of positive interpersonal sentiment. am. j. sociol., 72:1205   
1209, 1972.

[10] p. holme and g. ghoshal. dynamics of networking agents
competing for high centrality and low degree. phys. rev. lett.,
96:098701, 2006.

10

[11] p. holme and m. e. j. newman. nonequilibrium phase transi-
tion in the coevolution of networks and opinions. phys. rev. e,
74:056108, 2006.

[12] p. holme and j. zhao. exploring the assortativity   id91
space of a network   s degree sequence. phys. rev. e, 75:046111,
2007.

[13] d. kahneman. maps of bounded rationality: psychology
for behavioral economics. the american economic review,
93:1449   1475, 2003.

[14] d. knoke. political networks: the structural perspective.

cambridge university press, cambridge, 1990.

that outperforms tit-for-tat in the prisoner   s dilemma game. na-
ture, 364:56   58, july 1992.

[19] m. a. nowak and r. m. may. evolutionary games and spatial

chaos. nature, 359:826   829, 1992.

[20] m. rosvall and k. sneppen. modelling dynamics of informa-

tion networks. phys. rev. lett., 91:178701, 2003.

[21] m. rosvall and k. sneppen. modeling self-organization of
communication and topology in social networks. phys. rev.
e, 74:016108, 2006.

[22] g. sabidussi. the centrality index of a graph. psychometrika,

31:581   603, 1966.

[15] k. lindgren and m. g. nordahl. evolutionary dynamics of

[23] l. m. van valen. a new evolutionary law. evolutionary theory,

spatial games. physica d, 75(1-3):292   309, august 1994.

[16] k. nakao. distribution of measures of centrality: enumerated
distributions of freeman   s graph centrality measures. connec-
tions, 13:10   22, 1990.

[17] m. e. j. newman. the structure and function of complex net-

works. siam review, 45:167   256, 2003.

[18] m. nowak and k. sigmund. a strategy of win-stay, lose-shift

1:1   30, 1973.

[24] d. j. watts and s. h. strogatz. collective dynamics of    small-

world    networks. nature, 393:440   442, 1998.

[25] m. weber. the theory of social and economic organization.

oxford university press, new york, 1947.

