9
0
0
2

 
l
u
j
 

7
1

 
 
]
l
d
.
s
c
[
 
 

2
v
3
0
6
4

.

1
1
8
0
:
v
i
x
r
a

frozen footprints

massimo franceschet

department of mathematics and computer science, university of udine

via delle scienze 206     33100 udine, italy

massimo.franceschet@dimi.uniud.it

abstract. bibliometrics has the ambitious goal of measuring science.
to this end, it exploits the way science is disseminated trough scienti   c
publications and the resulting citation network of scienti   c papers. we
survey the main historical contributions to the    eld, the most interesting
bibliometric indicators, and the most popular bibliometric data sources.
moreover, we discuss distributions commonly used to model bibliometric
phenomena and give an overview of methods to build bibliometric maps
of science.

1

introduction

bibliometrics is a research method used in library and information science. it
uses quantitative analysis and statistics in order to:

    determine the in   uence of single scholars or groups of them (e.g., research
groups, institutions, countries) and that of single papers or groups of them
(e.g., journals or entire research    elds);

    describe the relationships between authors, publications, journals, or re-

search    elds.

bibliometrics has become a standard tool of science policy and research man-
agement in the last decades. academic institutions increasingly rely on biblio-
metric analysis for making decisions regarding hiring, promotion, tenure, and
funding of scholars; authors, librarians, and publishers may use citation indica-
tors to evaluate journals and to select those of high impact; editors may choose
reviewers on the basis of their bibliometric scores on a particular subject of in-
terest; worldwide college and university rankings, e.g., the-qs1 and arwu2,
which are partially based on bibliometric criteria, are often consulted by prospec-
tive students and their parents in the college and university admissions process.
today, bibliometrics is one of the rare truly interdisciplinary research    elds, with
important links with history of science, sociology, law, economics, management,
theology, mathematics, statistics, physics, and computer science.

citation analysts retrieve production and citation data from bibliometric
data sources and compute performance indicators to measure the quality of

1 http://www.timeshighereducation.co.uk/
2 http://www.arwu.org/

research of an actor. the bibliographic databases of the institute for scienti   c
information, today thomson-reuters, have been used for decades as a starting
point and often as the only tools for locating citations and conducting citation
analysis. fierce competitors of the databases provided by thomson-reuters are
elsevier   s scopus and the freely accessible google scholar.

actors under evaluation are typically individual scholars and journals, but
bibliometric units can be composed of homogeneous groups of scholars or groups
of journals at di   erent levels of aggregation. bibliometric criteria that charac-
terize research quality are productivity, impact (or popularity), and prestige.
typically bibliometric indicators capture separately some of these criteria, hence
the need of using in the evaluation process several orthogonal metrics capturing
di   erent aspects of research performance.

the outline of this manuscript is as follows. we    rst brie   y review the main
historical contributions to the    eld in section 2. in section 3 we discuss the
controversial role of citations in bibliometrics. section 4 surveys the most in-
teresting bibliometric indicators both at the individual and at the journal level,
while section 5 is devoted to the comparison of the most popular bibliometric
data sources. section 6 investigates the id203 distributions that underlie
most phenomena in bibliometrics. in section 7 we delve into the realm of biblio-
metric maps of science. finally, section 8 contains some of the best quotations
about bibliometrics.

2 historical remarks

bibliometric studies started long time ago. a remarkable early piece of work is
histoire des sciences et des savants depuis deux si`ecles. the author, alphonse
de candolle, describes the scienti   c strength of nations and tries to    nd envi-
ronmental factors for the scienti   c success of a nation [1].

derek john de solla price (1922     1983), an historian of science and infor-
mation scientist born from philip price, a tailor, and fanny de solla, a singer, is
credited as the father of bibliometrics. in his book little science, big science,
he analyzed the recent system of science communication and laid the foundation
of modern research evaluation techniques [2].

the term bibliometrics is introduced by pritchard in 1969 [3]. pritchard

explains the term bibliometrics as:

the application of mathematical and statistical methods to books and other
media of communication

at the same time, nalimov and mulchenko de   ned scientometrics as:

the application of those quantitative methods which are dealing with the
analysis of science viewed as an information process

according to these de   nitions, scientometrics is restricted to science commu-
nication, whereas bibliometrics is designed to deal with more general information

processes. nowadays, the borderlines between the two specialities almost van-
ished and both terms are used almost as synonyms.

the statistical analysis of scienti   c literature began years before the term
bibliometrics was coined. the main contributions are: lotka   s law of scienti   c
productivity, bradford   s law of scatter, and zipf   s law of word occurrence. in
1926, alfred j. lotka published a study on the frequency distribution of scienti   c
productivity determined from a decennial index of chemical abstracts [4] (see
table 1). lotka concluded that:

in a given    eld, the number of authors making n contributions is about
1/n2 of those making one.

lotka   s law means that few authors contribute most of the papers and many
or most of them contribute few publications. for instance, in the original data
of lotka   s study illustrated in table 1, the most proli   c 1350 authors (21% of
the total) wrote more than half of the papers (6429 papers, 51% of the total).

papers observed authors expected authors total papers

1
2
3
4
5
6
7
8
9
10

3991
1059
493
287
184
131
85
64
65
41

total

6400

3991
998
443
249
160
111
81
62
49
40

6890

3991
2118
1473
1148
920
786
595
512
585
410

12538

table 1. original lotka data and    t on the basis of lotka distribution (up to
10 papers)

eight years after lotka   s article appeared, bradford published his study on

the frequency distribution of papers over journals [5]. it states that:

if scienti   c journals are arranged in order of decreasing productivity on
a given subject, they can be divided into groups of di   erent sizes (number
of journals) each containing the same number of papers relevant to the
subject. the size of each group (except the    rst) is given by the size of
the previous group multiplied by a constant.

bradford formulated his law after studying a bibliography of geophysics (ta-
ble 2). journals can be divided in 3 groups of di   erent sizes but containing about

the same number of relevant papers: a core group, columns 1 and 2 of the ta-
ble, containing 2 journals and 179 relevant papers, a second group, columns 3-6,
containing 4 journals and 185 relevant papers, and a third group, columns 7-17,
containing 11 journals and 186 relevant papers.

journal

7 8 9 10 11 12 13 14 15 16 17
productivity 93 86 56 48 46 35 28 20 17 16 16 16 16 15 14 14 146

3 4 5 6

1 2

table 2. original bradford data for subject geophysics. bradford arranged jour-
nals in order of decreasing productivity on the subject and counted the number
of papers in the journal that are relevant to geophysics.

what it means is that for each speciality there are few core journals for
that    eld that contribute a relatively great amount of publications and many
or most of the journals give few contributions. hence, it is su   cient to identify
the core journals for that    eld and look at them. very rarely will researchers
need to go outside that set. this may serve, for example, to guide librarians
in choosing the core journals to stock in any given    eld. bradford   s law also
caused the discovery, which some did not expect, that a few journals like nature
and science were core for all of hard science. the same pattern does not happen
with the humanities or the social science     possibly because objective truth is
so much harder to establish there. the result of this is pressure on scientists to
publish in the best journals, and pressure on universities to ensure access to that
core set of journals.

zipf formulated an interesting law in bibliometrics and quantitative linguis-
tics that he derived from the study of word frequency in texts [6]. zipf   s law
states that:

in relatively lengthy texts, if words occurring within the text are listed
in order of decreasing frequency, then the rank of a word on that list
multiplied by its frequency will equal a constant, which depends on the
analyzed text.

zipf illustrated his law with an analysis of james joyce   s ulysses (table 3). it
means that only a few words are used very often, many or most are used rarely.
why natural language texts conform to zip   an distribution has been a matter
of some controversy. zipf explains his law with the principle of least e   ort,
de   ned as follows:

each individual will adopt a course of action that will involve the expen-
diture of the probably least average of his work.

according to zipf, if the principle of least e   ort works, the speaker (or
writer) tends to minimize number and length of words (this he calls the force of

rank frequency rank * frequency

10
20
30
40
50
100
200
300
400
500
1000
2000
3000
4000
5000
10000
20000
29899

2653
1311
926
717
556
265
133
84
62
50
26
12
8
6
5
2
1
1

26530
26220
27780
28680
27800
26500
26600
25200
24800
25000
26000
24000
24000
24000
25000
20000
20000
29899

table 3. the distribution of words in joyce   s ulysses

uni   cation), by overloading the same word with di   erent meanings, while the
hearer (or reader) calls for a diversi   cation of words (this he calls the force of
diversi   cation), by assigning di   erent meanings to di   erent words. for commu-
nication to be e   ective, these opposite forces need to equilibrate, giving rise to
the mentioned law of word occurrence.

only in the beginning of the 1980   s, with the fast development of computer
science, bibliometrics could evolve into a distinct scienti   c discipline with a spe-
ci   c research pro   le and corresponding communication structures. scientomet-
rics, the    rst international periodical specialized on bibliometric topics, started
in 1979. the fact that bibliometric methods are already applied to the biblio-
metric    eld itself also indicates the rapid growth of the discipline.

3 the role of citations

a central question is: why bibliometric analysis of research performance? peer
review, that is, the evaluation made by expert peers, undoubtedly is an important
procedure of quality judgment. in particular, the results of peer review judgment
and those of bibliometric assessment are not completely independent variables.
indeed, peers take some bibliometric aspects into account in their judgment, for
instance number of publications in the better journals.

but peer review and related expert-based judgments may have serious short-
comings. subjectivity, i.e., dependence of the outcomes on the choice of individ-
ual committee members, is one of the major problems. moreover, peer review is

slow and expensive (at least in terms of hours of volunteer work devoted to ref-
ereeing). in particular, peer review methodology is practically unfeasible when
the number of units to evaluate is consistent, e.g., all papers published by all
members of a large department.

bibliometric assessment of research performance is based on the following

central assumptions [7]:

    scholars who have to say something important do publish their    ndings;
    scholars refer in their own work to earlier work of other scholars to acknowl-

edge intellectual debt and to witness the use of information.

in research evaluation, citations became a widely used measure of the impact of
scienti   c publication. smith [8] stated that:

citations are signposts left behind after information has been utilized.

while cronin [9] de   ned citations as:

frozen footprints in the landscape of scholarly achievement which bear
witness of the passage of ideas.

however, problems with citation analysis as a reliable instrument of mea-
surement and evaluation have been acknowledged. citations re   ect both the
needs and idiosyncrasies of the citer, including such factors as utility, quality,
availability, advertising (self-citations), collaboration or comradeship (in-house
citations), chauvinism, mentoring, personal sympathies and antipathies, compe-
tition, neglect, obliteration by incorporation, augmentation,    attery, convention,
reference copying, reviewing, and secondary referencing [10]. as seglen says ([11],
page 636),    while the sheer number of factors may help to achieve some statisti-
cal balance, we all know of scientists who are cited either much less (ourselves)
or much more than they deserve on the basis of their scienti   c achievements   .
nevertheless, citation analysis has demonstrated its reliability and usefulness
as a tool for ranking and evaluation scholars and their publications [12]. further-
more, the robustness of citations as a method to evaluate impact is particularly
witnessed by the adoption of a similar approach in several other    elds far dif-
ferent from bibliometrics, including web pages connected by hyperlinks [13,14],
patents and corresponding citations [15], published opinions of judges and their
citations within and across opinion circuits [16], and even sections of the bible
and the biblical citations they receive in religious texts [17].

4 bibliometric indicators

assuming the central bibliometric assumptions mentioned in section 3, we may
design quantitative indicators to assess research quality of an actor. but, what
aspects characterize quality of research? moreover, what are the actors under
evaluation?

there is a general agreement that research quality is not characterized by a

single element of performance. van raan [18] claims:

it is not wise to force the assessment of researchers or of research groups
into just one measure, because it reinforces the opinion that scienti   c
performance can be expressed simply by one note. several indicators are
necessary in order to illuminate di   erent aspects of performance.

moreover, gl  anzel [19] adds:

the use of a single index crashes the multidimensional space of biblio-
metrics into one single dimension.

two potential dangers of condensing down quality of research to a single

metric are:

    a person may be damaged by the use of a simple index in a decision-making
process if the index fails to capture important and di   erent aspects of re-
search performance;

    scientists may respond to this by maximizing that particular metric to the

detriment of doing more justi   able work.

quality of research is therefore described by di   erent aspects; the most im-

portant are:

    productivity; this is the amount of scholarly works that are produced by the

actor;

    impact (or popularity); this is the number of endorsements that the actors

receives from other actors;

    prestige; this is the prestige of the works produced by the actor and that of

the endorsing actors.

the actors under bibliometric evaluation may be di   erent, however, the ba-
sic unit of evaluation is a single scholarly work, typically, a journal paper. this
basic unit, a scholarly work, can be aggregated at di   erent levels obtaining more
complex units of evaluation. for instance, single scholars are evaluated in terms
of the set of works they produced. scholars are typically grouped into research
groups, institutions, regions within nations, countries or even international re-
gions. moreover, scholarly works are typically aggregated into journals or con-
ferences and research    elds. the level of aggregation is:

    micro-level, when individuals, research groups or single scholarly works are

considered;

    meso-level, in the case of institutions or journals;
    macro-level, in the case of regions, countries or research    elds.

before delving into the realm of bibliometric indicators, it is important to
understand that di   erent scholarly disciplines can have very di   erent publica-
tion and citation practices, including the absolute number of researchers, the
average number of authors on each paper, the average number of citations in
each paper, and the nature of results [20]. all these factors complicate the use

of id74 across di   erent disciplines. nevertheless, interdisciplinary
indicators have been proposed along the following line. in principle, it is pos-
sible to compute the mean (or median) number of citations per paper for an
entire research discipline [21]. hence, the actual number of citations for a pub-
lication can be compared with the expected number of citations for the    eld of
the publication [7].

4.1 bibliometric measures at the individual level

the traditional bibliometric indexes used to evaluate the performance of indi-
vidual scholars include:

    the number of publications produced by the scholar, possibly divided by the

scholar   s academic age;

    the number of citations that the publications produced by the scholar have
received from other scholarly works, possibly divided by the number of pub-
lications.

a more interesting measure is the h index. the h index of a scholar is the
higher number of papers a scholar has that have each received at least that
number of citations. for instance, my current h index computed with google
scholar is 14, meaning that i am the author of 14 papers each of them cited at
least 14 times. the rest of my papers are all cited a number of times that is less
or equal to 14. the index was proposed by hirsch, a physicist, in 2005 [22] and
it has immediately found interest in the public [23,24] and in the bibliometrics
literature. in particular, it is currently computed by both web of science and
scopus.

the index is meant to capture both productivity and impact of a scholar in
such a way that it is hard to increase it, as well as to rig it, over a certain thresh-
old. it favors researchers who produce a continuous stream of in   uential papers
over those who publish many quickly forgotten ones or a few blockbusters. more-
over, it is di   cult to in   ate the index, for instance with self-citations. indeed,
all self-citations to papers with less than h citations are irrelevant for the com-
putation of the index, as are the self-citations to papers with many more than
h citations.

hirsch argues that the h index is preferable to other single-number criteria
commonly used to evaluate scienti   c output of a researcher [22] and that it has
more predictive power [25]. hirsch suggests that, for a given researcher, h should
increase approximately linearly with time, that is h = m    n, where n is the
academic age in years and m is the slope of the linear function. the parameter
m should provide a useful yardstick to compare scientists of di   erent seniority.
in particular:

    a value of m around 1 characterizes a successful scientist;
    a value of m around 2 characterizes outstanding scientists;
    a value of m around 3 or higher characterizes truly unique individuals.

an additional advantage of the h index is that it is extremely simple and
comprehensible. moreover, it can be easily computed by sorting the published
papers in decreasing order with respect to the number of received citations and
scrolling down the list until the rank of the paper is greater than the number of
citations that it has. the preceding rank equals the h index.

the h index has also been criticized; in particular, gl  anzel [19] and born-
mann and daniel [26] describe opportunities and limitations of the h index. the
following are acknowledged limitations of the index:

1. it puts newcomers at a disadvantage since both publication output and ci-

tation rates will be relatively low;

2. it does not account for the number of authors in a paper;
3. it is discipline dependent;
4. it disadvantages small but highly-cited paper sets too strongly;
5. it allows scientists to rest on their laurels (   your papers do the job for you   )
since the index never decreases and it might increase even if no new papers
are published.

many variations of the index have been proposed to correct the mentioned

   aws:

    hirsch proposes to solve problems number 1 and 5 by dividing the h index

by the scienti   c age of the author [22];

    to address problem number 2 and, partially, issue number 3, batista et al.
[27] suggest to adjust the original h index by dividing it by the mean number
of researchers in the h publications of the hirsch core;

    egghe [28] proposes the g-index to account for problem number 4. given
a set of articles ranked in decreasing order of the number of citations that
they received, the g-index is the (unique) largest number such that the top
g articles received (together) at least g2 citations. moreover, for the same
problem, jin [29] suggests to use the average number of citations received
by articles in the hirsch core (the set of articles that determine the h index
value);

    in order to address issue number 5, katsaros et al. [30] propose the contem-
porary h index. the contemporary h index adds an age-related weighting to
each cited article, giving less weight to older articles.

in fact, all these variations did not attract much attention since they address
a single issue without considering the others; hence the original version of the h
index is still the most adopted.

4.2 bibliometric measures at the journal level

the traditional measure of journal impact is the impact factor. roughly, the
impact factor of a journal is the average number of recent citations received by
articles published in the journal. more precisely, the impact factor of a journal for

a speci   c census year is the mean number of citations that occurred in the census
year to the articles published in the journal during a target window consisting
of the two previous years. such a measure was devised by gar   eld, the founder
of the institute for scienti   c information (isi). today, thomson-reuters, that
acquired the isi in 1992, computes the the impact factor for journals it tracks
and publishes it annually in the journal citation reports (jcr) in separate
editions for the sciences and the social sciences.

the impact factor has become a standard to evaluate the impact of journals.
nevertheless, the impact factor has many faults [31,20,32]; the most commonly
mentioned are:

    the target window (2 years) is too narrow for more theoretical disciplines,
e.g., mathematics, in which results need to be well digested before they are
cited;

    the impact factor does not normalize for the di   erences in citation practices

across di   erent disciplines;

    it does not represent a typical value of the number of citations to articles in
the journal when the citation distribution is skewed (asymmetric), which is
the usual case in bibliometrics (see section 6);

    it counts citations without weighting them with the prestige of the citing

journals.

it follows that impact factors highly vary across disciplines and over time
[33]. moreover, due to the skewness of citation distributions and the fact that the
impact factor is essentially a mean value, it is a (common) misuse of the impact
factor to predict the importance of an individual publication, and hence of an
individual researcher, based on the impact factor of the publication   s journal.
indeed, most papers published in a high impact factor journal will ultimately
be cited many fewer times than the impact factor may seem to suggest. finally,
some journals that have high impact factors are popular publication sources but
are not appreciated by domain experts, that is, they are not prestigious sources
[34].

nunes amaral et al. propose a steady state version of the impact factor
[35]. they show that there exists a steady state period of time speci   c to each
journal such that the number of citations to paper published in the journal in
that period will not signi   cantly change in the future: poorly cited papers have
stopped accruing citations, while the trickle of citations to highly cited ones is
small when compared to the already accrued citations. hence, there are journal-
speci   c census and target windows that well characterize the    nal impact of
journals; such windows highly diverge from the ones exploited in the impact
factor computation.

furthermore, the authors demonstrate that the logarithm of the number of
citations to papers published in a journal in its steady state period is approx-
imately normally distributed and hence it has a well-de   ned typical value (the
mean). the authors propose to use such a mean as an alternative impact met-
ric to the commonly used 2-year impact factor. they show that the suggested

ranking scheme strongly diverges from the 2-year impact factor one, but it is
very similar to the id203 ranking scheme. the latter is the ranking that
maximizes the id203 that given a pair of papers (a, b) from journals a and
b, respectively, paper a is more cited than paper b if a is above b in the rank-
ing. the id203 ranking is regarded as the optimal ranking in the context
of information retrieval [36].

both the impact factor and its steady version equally weights all citations:
citations from highly reputed journals, like nature, science, and proceedings of
the national academy of sciences of usa, are treated as citations from more
obscure ones. in other words, they are measures of popularity, but do not account
for prestige. by contrast, the eigenfactor tm metric [37,38,39] weights journal
citations by the in   uence of the citing journals. as a result, a journal is in   uential
if it is cited by other in   uential journals. the de   nition is clearly recursive in
terms of in   uence and the computation of the eigenfactor scores involves the
search of a stationary distribution, which corresponds to the leading eigenvector
of a perturbed citation matrix.

the eigenfactor method was initially developed by jevin west, ben althouse,
martin rosvall, and carl bergstrom at the university of washington and ted
bergstrom at the university of california santa barbara. eigenfactor scores are
freely accessible at the eigenfactor web site [39] and, from 2007, they have been
incorporated into thomson-reuters journal citation reports (jcr) for both
science and social science journals3.

the idea underlying the eigenfactor method originates from the work of [40]
in the    eld of bibliometrics and from the contribution of [41] in the context
of sociometry, which, in turn, generalizes leontief   s input-output model for the
economic system [42]. notably, brin and page use a similar intuition to design
the popular id95 algorithm that is part of their google search engine: the
importance of a web page is determined by the number of hyperlinks it receives
from other pages as well as by the importance of the linking pages [43,14].

in the following, we illustrate the eigenfactor method to measure journal
in   uence as described at the eigenfactor web site [39]. the eigenfactor compu-
tation uses a census citation window of one year and an earlier target publication
window of    ve years. let us    x a census year and let c = (ci,j ) be a journal-
journal citation matrix such that ci,j is the number of citations from articles
published in journal i in the census year to articles published in journal j dur-
ing the target window consisting of the    ve previous years. hence, the ith row
represents the citations given by journal i to other journals, and the jth column
contains the citations received by journal j from other journals. journal self-
citations are ignored, hence ci,i = 0 for all i. moreover, let a be an article vector
such that ai is the number of articles published by journal i over the    ve-year
target window divided by the total number of articles published by all journals
over the same period. notice that a is normalized to sum to 1.

3 eigenfactor scores from 2007 are added to the eigenfactor web site six months after

they are published in jcr.

a dangling node is a journal i that does not cite any other journals; hence,
if i is dangling, the ith row of the citation matrix has all 0 entries. the citation
matrix c is transformed into a normalized matrix h = (hi,j) such that all rows
that are not dangling nodes are normalized by the row sum, that is,

hi,j =

ci,j

pj ci,j

for all non-dangling i and all j. furthermore, h is mapped to a matrix   h in
which all rows corresponding to dangling nodes are replaced with the article
vector a. notice that   h is row-stochastic, that is all rows are non-negative and
sum to 1.

a new row-stochastic matrix p is de   ned as follows:

p =      h + (1       )a

where a is the matrix with identical rows each equal to the article vector a,
and    is a free parameter of the algorithm, usually set to 0.85. let    be the left
eigenvector of p associated with the unity eigenvalue, that is, the vector    such
that    =   p . it is possible to prove that this vector exists and is unique. the
vector   , called the in   uence vector, contains the scores used to weight citations
allocated in matrix h. finally, the eigenfactor vector r is computed as

r = 100   

  h

pi[  h]i

that is, the eigenfactor score of a journal is the sum of normalized citations
received from other journals weighted by the eigenfactor scores of the citing
journals. the eigenfactor scores are normalized such that they sum to 100.

the eigenfactor metric has a solid mathematical background and an intu-
itive stochastic interpretation. the modi   ed citation matrix p is row-stochastic
and can be interpreted as the transition matrix of a markov chain on a    nite
set of states (journals). hence, the in   uence vector    corresponds to the station-
ary distribution of the associated markov chain. since p is a primitive matrix,
the markov theorem applies, hence    is the unique stationary distribution and,
moreover, the in   uence weight   j of the jth journal is the limit id203 of
being in state j when the number of transition steps of the chain tends to in-
   nity. moreover, the perron theorem for primitive matrices ensures that    is
a strictly positive vector corresponding to the leading eigenvector of p , that
is, the eigenvector associated with the largest eigenvalue     which is 1 because
p is stochastic. the described stochastic markov process has an intuitive in-
terpretation in terms of id93 on the citation network [38]. imagine a
researcher that moves from journal to journal by following chains of citations.
the researcher selects a journal article at random and reads it. then, he retrieves
at random one of the citations in the article and proceeds to the cited journal.
hence, the researcher chooses at random an article from the reached journal and
goes on like this. eventually, the researcher gets bored of following citations,

and selects a random journal in proportion to the number of article published
by each journal. with this model of research, by virtue of the ergodic theorem
for markov chains, the in   uence weight of a journal corresponds to the relative
frequency with which the random researcher visits the journal.

the eigenfactor score is a size-dependent measure of the total in   uence of a
journal, rather than a measure of in   uence per article, like the impact factor. to
make the eigenfactor scores size-independent and comparable to impact factors,
we need to divide the journal in   uence by the number of articles published in
the journal. in fact, this measure, called article in   uencetm, is available both
at the eigenfactor web site and at thomson-reuters   s jcr.

5 bibliometric data sources

bibliometric analysis can be conducted on the bases of any su   ciently large
bibliographic database enhanced with citation counts. a bibliometric data source
may be evaluated according to the following criteria:

    the coverage of the database;
    the supported features for searching, sorting, and exporting bibliographic

data as well as for computing performance indicators on them;

    the availability of the database (free or subscription-based).

in particular, coverage is of crucial importance since it in   uences the out-
comes of the computation for bibliometric indicators. an uneven coverage may
produce performance measures that are too far from the real    gures and this may
lead to wrong decisions. some aspects directly connected to database coverage
are:

    what types (journals, conference papers, books, and so on) of works are

covered and how evenly;

    what research    elds are covered and how evenly;
    what languages other than english and what countries other than north

american and western european ones are covered and how evenly.

the bibliometric databases of the institute for scienti   c information (isi)
have been the most generally accepted data sources for bibliometric analysis. the
isi was founded by eugene gar   eld in 1960. the isi was acquired by thomson
in 1992, one of the world   s largest information companies. in 2007, the thomson
corporation reached an agreement with reuters to combine the two companies
under the name thomson-reuters (tr).

tr maintains web of knowledge, an online academic database which pro-

vides access to many resources, in particular:

    web of science (wos), which includes the science citation index (sci), the
social science citation index (ssci), and the arts and humanities citation
index (ahci);

    journal citation reports (jcr), containing citation information, and in par-
ticular the impact factor, for the journals tracked by tr. jcr are published
annually in separate editions for the sciences and the social sciences.

the use as tr citation databases, in particular as the only bibliographic
source for bibliometric analysis, attracted quite a number of critics. the most
mentioned    aws are:

1. it provides di   erent coverage between research    elds;
2. it is limited to citations from journals but does not count citations from

other sources, mainly from books and most conference proceedings;

3. it covers mainly north american, western european, and english-language

titles;

4. is only available to those academics whose institutions are able and willing

to bear the subscription cost.

flaw number one is particulary serious since it is the main cause of the
variation of the impact factor measure across    elds [33]. the internal coverage
of a bibliometric data source with respect to a    eld is de   ned as the fraction of
citations coming from papers internal to the database and belonging to the    eld
that match a paper in the same data source. the internal coverage highly varies
across disciplines, e.g. 0.803 for molecular and cell biology, 0.552 for mathematics,
and 0.226 for computer science. this means that, for instance, more than 3/4
of the citations from computer science papers indexed in wos are addressed
to papers that are not contained in wos. furthermore, drawback number 2
is critical for disciplines like computer science that heavily rely on conference
publications and for humanities whose scholars frequently publish books.

two major alternatives to web of science are elsevier   s scopus and google
scholar. scopus, as web of science, is a subscription-based proprietary databases.
on the contrary, google scholar is freely accessible. there are many studies that
compare citation data retrieved on di   erent data sources. table 4 displays some
of these. the    rst column shows the publication reference of the study, the second
column contains the set of data sources that are compared, while the research
   eld of the publications considered in the study is given in the third column.
the papers are sorted in chronological order.

the rest of this section illustrates a large-scale comparison between web of
science, scopus and google scholar conducted by meho and yang in 2007 [56].
the study covers more than 10000 citations to approximately 1100 scholarly
works of all 15 faculty members of the school of library and information science
(lis) at indiana university-bloomington. the authors found that both web of
science and scopus provide substantial factual information about the database,
including the number of records and the list of titles indexed. on the contrary,
google scholar refuses to publish information about its coverage and frequency
of updates.

moreover, both web of science and scopus o   er features for searching, sort-
ing, and exporting the bibliographic data. on the contrary, google scholar does

ref compared sources
[44] citeseer and web of science
[45] citeseer and web of science
[46] chemical abstracts and web of sci-

   eld
computer science
computer science
chemistry

ence

[47] web of science, scopus, and google

jasist papers

scholar

[48] web of science, scopus, and google

scholar

current science papers and eugene
gar   eld papers

[49] web of science and google scholar webometrics
[50] web of science and google scholar di   erent disciplines
[51] web of science, scopus, and google

scholar

oncology and condensed matter
physics

[52] web of science and google scholar di   erent disciplines
[53] web of science and google scholar business sciences
[54] csa illumina, web of science, sco-

social sciences

pus, and google scholar

[55] web of science, scopus, and google

di   erent disciplines

scholar

[56] web of science, scopus, and google

library and information science

scholar

[57] web of science and google scholar di   erent disciplines
[58] web of science and google scholar information science
[59] web of science, scopus and google

human-computer interaction

scholar

[60] web of science, scopus, and google

di   erent disciplines

scholar

[61] web of science, scopus and google

scholar

[62] web of science, scopus, google

scholar, and chemical abstracts

library and information science and
information retrieval
chemistry

table 4. literature comparing citation data over di   erent data sources.

not provide the retrieved data in a useful bibliographic format and does not al-
low sorting it in any way. collecting (extracting, verifying, cleaning, organizing,
classifying, and saving into a bibliographic format) data from google scholar
took the authors 30 as much time as collecting web of science data and 15 as
much time as as collecting scopus data.

the authors analyzed the citations to works of lis members published be-
tween 1996 and 2005 divided by document type. for web of science and scopus,
most of these citations come from journals (88.7% and 84.4%, respectively), and
a few from conference papers (11.3% and 15.6%, respectively). on the contrary,
google scholar indexes more types of works, including journal papers (42.5%),
conference papers (33.7%), theses (9.8%), books (5.5%), reports (4.8%) and other
document types (3.7%);

furthermore, the authors studied the distribution of unique and overlap-
ping citations to works of lis members published between 1996 and 2005 that
were found in journal and conference articles only. web of science contains 2023
citations, scopus contains 2301 citations, and google scholar contains 4181 ci-
tations. the overlap of citations between the three databases is relatively low,
with signi   cant di   erences from one research area to another: the overlapping
between web of science and scopus is 1591 citations (58.2%) out of the 2733
citations found in both the databases; web of science misses 710 citations (26%)
of those of scopus while scopus misses 432 citations (15.8%) of those of web of
science.

the overlapping between google scholar and the union of web of science
and scopus is 1629 citations (30.8%) out of the 5285 citations found in all the
three databases; google scholar misses 1104 citations (20.9%) of those found in
the union of web of science and scopus, and the union of web of science and
scopus misses 2552 citations (48.3%) of those found in google scholar.

the former    gure is quite striking, since virtually all citations of web of sci-
ence and scopus come from referred reputable sources. rumors are that some
publishers did not allow google scholar crawlers to enter their databases (no-
tably, elsevier and american chemical society). as for the second    gure, the
authors noticed that:

    most of the citations uniquely found by google scholar are from refereed

sources;

    most of these citations come from low impact sources;
    most of these citations were identi   ed trough documents made available

online by their authors rather than from the source   s o   cial site.

the authors studied the distribution of citations by language and found
that google scholar provides better coverage of non-english language materials
(6.9%) with respect to both web of science (1.1%) and scopus (0.7%).

meho and yang concluded that web of science, scopus, and google scholar
complement rather than replace each other, so they should be used together
rather than separately in citation analysis. in particular, although web of sci-
ence remains an indispensable citation database, it should not be used alone for

locating citations, because both scopus and google scholar identify a consider-
able number of citations not found in web of science. although google scholar
unique citations are not of the same quality of those found in the two proprietary
databases, they could be useful in showing evidence of broader international im-
pact.

the authors also concluded that there is an important impact advantage in
favor of the articles, and the corresponding journals, that their authors make
available online (on personal web pages or on electronic preprints archives like
arxiv) since they are more likely discovered by human and automatic agents
(like crawlers of google scholar), possibly increasing the citation impact.

6 bibliometric distributions

the id203 distributions that are usual suspects in bibliometrics are pareto,
(stretched) exponential, and lognormal distributions.

pareto distribution. also known as power law distribution, it has been used to
model phenomena where most of the e   ects come from few of the causes. the
distribution is named after the italian economist vilfredo pareto who originally
observed it studying the allocation of wealth among individuals: a larger share
of wealth of any society (approximately 80%) is owned by a smaller fraction
(about 20%) of the people in the society [63]. examples of phenomena that
are approximately pareto distributed are: size of human settlements, size of
meteorites, standardized price returns on individual stocks,    le size of internet
tra   c using tpc protocol, duration of transactions in database management
systems, word frequency in relatively lengthy texts (zipf law [6]), and scienti   c
productivity of scholars (lotka law [4]). furthermore, in 1998 redner analyzed
the citation distribution for all papers in journals which were catalogued by
the isi at that time; the author found that the asymptotic tail of the citation
distribution appears to be described by a pareto law [64].

the id203 density function for a pareto distribution is de   ned for x     1

in terms of parameter    > 0 as follows:

f (x) =

  

x  +1

the cumulative distribution function is:

f (x) = 1    

1
x  

the mean is   /(       1) for    > 1, and in   nite otherwise. the median is      2 and
the mode is 1. notice that the mean is greater than the median which is greater
than the mode and the limit for            of both the mean and the median is the
mode 1. skewness is

   =

2(1 +   )

       3 r        2

  

for    > 3, and kurtosis is

   =

6(  3 +   3     6       2)

  (       3)(       4)

for    > 4. both skewness and kurtosis are greater than zero and tend to 2 and 6,
respectively, as           . the raw moments are found to be e(x n) =   /(       n)
for    > n.

stretched exponential distribution. this is a family of extensions of the well-
known exponential distribution characterized by fatter tails. laherr  ere and sor-
nette showed that di   erent phenomena in nature and economy can be described
in the regime of the exponential distribution, including radio and light emission
from galaxies, oil   eld reserve size, agglomeration size, stock market price vari-
ation, biological extinction event, earthquake size, temperature variation of the
earth, and, notably, citation of the most cited physicists in the world [65].

the id203 density function is a simple extension of the exponential

distribution with one additional stretching parameter   :

f (x) =       x     1e   (  x)  

where x     0,    > 0 and 0 <        1. in particular, if the stretching parameter
   = 1, then the distribution is the usual exponential distribution. when the
parameter    is not bounded from 1, the resulting distribution is better known
as the weibull distribution. the cumulative distribution function is:

f (x) = 1     e   (  x)  

it can be shown that the nth raw moment e(x n) is 1
   ), where    (x) is
the gamma function, an extension of the factorial function to real and complex
numbers, de   ned by:

  n    (   +n

   (x) = z    

0

tx   1e   tdt

in particular, it holds that    (1) = 1 and    (x + 1) = x   (x). hence, for a positive
integer n, we have    (n + 1) = n!. notice that, if    = 1, then the raw moments
are given by n!/  n and they correspond to the raw moments of the exponential
distribution. in particular, the mean e(x) is the    rst raw moment that is equal
     log 2 and the mode is 0. notice again
to 1
that the mean is greater than the median that is greater than the mode.

   ). the median is given by 1

      (   +1

  

lognormal distribution. it is the distribution of any random variable whose loga-
rithm is normally distributed. a lognormal distribution characterizes phenomena
determined by the multiplicative product of many independent e   ects. the log-
normal distribution is a usual suspect in bibliometrics. in a 1957 study based
on the publication record of the scienti   c research sta    at brookhaven national
laboratory, shockley observed that the scienti   c publication rate is approxi-
mately lognormally distributed [66]. more recently, stringer et al. studied the
citation distribution for journals indexed in web of science publishing at least

50 articles per year for at least 15 years and demonstrated that in a steady
citational state the logarithm of the number of citations has a journal-speci   c
typical value [35]. finally, radicchi et al. analyzed the distribution of the ratio
between the number of citations received by an article and the average number
of citations received by articles published in the same    eld and year for papers
in di   erent research categories (the category closest to computer science is cy-
bernetics) [21]. they found a similar distribution for each category with a good
   t with the lognormal distribution.

the lognormal id203 density function is de   ned in terms of parameters

   and    > 0 as follows:

f (x) =

1

x     2  

e   

(log(x)     )2

2  2

   1)   e  2     1 > 0. moreover, excess kurtosis is e4  2

for x > 0. the parameters    and    are the mean and standard deviation of
the variable   s natural logarithm. the cumulative distribution function has no
closed-form expression and is de   ned in terms of the density function as for
the normal distribution. the mean is e  +  2/2, the median is e   and the mode is
e       2
. notice that the mean is greater than the median which is greater than the
mode. this suggests a positive asymmetry of the distribution. indeed, skewness
is (e  2
   6 > 0.
the raw moments are given by e(x n) = en  +n2  2/2.
it is interesting to observe that all the above distributions that are com-
monly used to model bibliometric phenomena are positively (right) skewed. a
distribution is symmetric if the values are equally distributed around a typical
   gure (the mean); a well-known example is the normal (gaussian) distribution.
a distribution is right-skewed if it contains many low values and a relatively few
high values. it is left-skewed if it comprises many high values and a relatively
few low values. as a rule of thumb, when the mean is larger than the median
the distribution is right-skewed and when the median dominates the mean the
distribution is left-skewed. a more precise numerical indicator of distribution
skewness is the third standardized central moment, that is

+2e3  2

+3e2  2

   =

e[(x       )3]

  3

where    and    are mean and standard deviation of distribution of random vari-
able x, respectively. a value close to 0 indicates symmetry; a value greater than
0 corresponds to right skewness, and a value lower than 0 means left skewness.
the observed right skewness might be considered as an application of the
more general pareto principle (also known as 80-20 rule) [7]. the principle states
that:

most (approximately 80%) of the e   ects comes from few (about 20%) of
the causes.

it has been suggested that the irreducible skewness of distributions of scholar
productivity and article citedness may be explained by sociological reinforcement

mechanisms such as the principle of cumulative advantage. de solla price for-
mulated this in 1976 as follows [67]:

success seems to breed success. a paper which has been cited many times
is more likely to be cited again than one which has been little cited. an
author of many papers is more likely to publish again than one who has
been less proli   c. a journal which has been frequently consulted for some
purpose is more likely to be turned to again than one of previously infre-
quent use.

the matthew e   ect may additionally contribute to skewness. according to

merton [68]:

the mathew e   ect consists in the accruing of greater increments of
recognition for particular scienti   c contributions to scientists of consid-
erable repute and the withholding of such recognition from scientists who
have not yet made their mark.

it takes the name from the following line in jesus    parable of the talents in
the biblical gospel of mathew: for unto every one that hath shall be given, and
he shall have abundance: but from him that hath not shall be taken away even
that which he hath.

interestingly, seglen claims that skewness is an intrinsic characteristic of
distributions related to extreme types of human e   orts; although scienti   c ability
may be normally distributed in the general population, scientists are likely to
form an extreme-property distribution to their speciality be in terms of citedness
or in terms of productivity. this statistical pattern is expected for di   erent types
of highly specialized human activity, a parallel being found in the distribution
of performance by top athletes [11].

7 bibliometric maps

a    rst and crucial step is the building of a map is de   nition of a research
   eld. there are two main approaches: concept-similarity mapping and citation
mapping. the concept-similarity approach de   nes a research    eld on the basis of
repeated concepts (keywords) in publications [69,70]. it can be further divided
in the two following methods: co-publication analysis, in which publications are
related if they mention the same concepts, and co-concept analysis, in which
concepts are related if they are mentioned together in the same publication.

the citation approach clusters a research    eld on the basis of citations in
publications. two typical methods to identify similar publications are co-citation
coupling [71], in which publications are related when they are cited by the same
papers, and bibliographic coupling [72], in which papers are related when they
cite the same papers. in the following, we introduce these two techniques with
the help of a model suggested in [73] and re   ned in [74]. suppose we have n
publications p1, . . . , pn that cite m references ri, . . . , rm. we build a boolean

citation matrix c = (ci,j) of size n    m such that ci,j = 1 if pi cites rj and
ci,j = 0 otherwise. let ci = pj ci,j be the number of cited references of pi and
cj = pi ci,j be the number of citations received by rj . a measure of bibliographic

coupling between publications pi and pj is:

ri,j = pk ci,k    cj,k
   ci    cj

this is the ratio of the number of references shared by publications pi and pj and
the geometric mean of the number of references of the two papers concerned.
notice that 0     ri,j     1, and ri,j = 0 when publications pi and pj share no
references, while ri,j = 1 when publications pi and pj have the same bibliography.
geometrically, ri,j is the cosine of the angle formed by the ith and jth rows of
the citation matrix, which is 0 when the two vectors are orthogonal, and is 1
when they are parallel. in matrix notation, let a = (ai,j) = cct , that is, ai,j is
the number of references shared by ith and jth publications, and, in particular,
ai,i = ci is the number of references of pi. let d be the diagonal matrix such
that the ith diagonal entry is 1/   ai,i. then we have that r = (ri,j ) is de   ned
as

r = dad

on the other hand, a measure of co-citation coupling between publications

pi and pj is:

si,j = pk ck,i    ck,j
   ci    cj

this is the ratio of the number of articles that cite both publications pi and pj
and the geometric mean of the number of citations received by the two publi-
cations involved. this is also the cosine of the angle formed by the ith and jth
columns of the citation matrix. again, 0     si,j     1, and si,j = 0 when pub-
lications pi and pj are never co-cited, while si,j = 1 when publications pi and
pj are always cited together. in matrix notation, let b = (bi,j ) = ct c, that
is, bi,j is the number of articles that co-cited ith and jth publications, and, in
particular, bi,i = ci is the number of citations gathered by pi. let d    be the
diagonal matrix such that the ith diagonal entry is 1/pbi,i. then we have that

s = (si,j ) is de   ned as

s = d   bd   

it is worth noticing that the similarity formulas used in citation coupling
closely resemble pearson correlation coe   cient formula for two statistical sam-
ples x and y, that is:

rxy =

  xy
  x      y

=

pk(xk       x)    (yk       y)

ppk(xk       x)2   ppk(yk       y)2

in particular, when the means of both statistical samples x and y are null, the
pearson correlation coe   cient is exactly the cosine of the angle formed by the
two sample vectors and the two measures coincide.

once the similarity strength between bibliometric units has been established,
bibliometric units are typically represented as graph nodes and the similarity
relationship between two units is represented as a weighted edge connecting
the units, where weights stand for the similarity intensity. such visualizations
are called bibliometric maps. such maps are powerful but they are often highly
complex. it therefore is helpful to abstract the network into inter-connected
modules of nodes. good abstractions both simplify and highlight the underlying
structure and the relationships that they depict. when the units are publications
or concepts, the identi   ed modules represent in most cases recognizable research
   elds. in the rest of this section, we describe three methods for creating these
abstractions: id91, principal component analysis, and information-theoretic
abstractions.

7.1 id91

informally, id91 is the process of organizing objects into groups whose
members are similar in some way [75,76]. a cluster is a collection of objects
which are similar between them and are dissimilar to objects belonging to other
clusters. id91 can be formalized as follows. we are given a weighted undi-
rected graph g, where the weight function assigns a dissimilarity value to pair of
nodes, and an objective function f that assigns a value of merit to any partition
of the set of nodes of g. id91 problems are optimization problems that
usually have one of the following forms [77]:

    let g be a graph, f be an objective function, and k be an integer. find a
partition of nodes in g with cardinality k and with the least value for the
objective function.

    let g be a graph, f be an objective function, and c be a real number. find
the smallest partition of nodes in g with objective function value less than
or equal to the value c.

the    rst type of id91 problem is usually approached using repeated par-
tition techniques. these techniques choose an initial partition with k clusters and
then move objects between clusters trying to minimize the objective function.
the procedure stops as soon as a local minimum for the objective function is
reached. the most popular algorithm in this category is id116 [78].

hierarchical id91 methods are typically applied to solve the second type
of id91 problem [79]. in this case, the size of the partition is not    xed in
advance. these algorithms are of two kinds: agglomerative and divisive. an
agglomerative strategy starts with a singleton partition containing a cluster for
each object and then merges similar clusters until the universal partition is
obtained. a divisive strategy starts from the universal partition containing a
unique set with all objects and then divides clusters that include dissimilar
objects until the singleton partition is reached. both methods can use di   erent
methods to decide what clusters to join or to divide. they output a hierarchical
structure (a dendrogram) describing the whole merging/dividing process. this

structure can be used to choose the smallest partition among the generated ones
(a small subset of all partitions) with objective function value less than or equal
to the given threshold.

the computational complexity of id91 problems mainly depends on the
properties of the weight function that measures the distance between two objects
and on the objective function that evaluates the goodness of a given partition of
the space. many exact and approximated id91 problems are known to be
hard to solve, in particular np-hard [77,80]. hence a polynomial strategy cannot
guarantee to    nd the optimum solution.

7.2 principal component analysis

principal component analysis (pca) [81,82] is a multivariate statistic method
used to reduce a multi-dimensional space to a lower dimension.

given a set of correlated variables x = {x1, x2, . . . , xn}, the aim of pca
is to    nd new arti   cial variables y = {y1, y2, . . . , ym}, with m < n, such that
(i) each new variable yi is obtained as a linear combination of the original vari-
ables (ii) the new variables yi are pairwise uncorrelated, (iii) the variance of
yi decreases as the index i increases, and (iv) the sum of the variance of the
new variables yi is a signi   cant portion of the sum of the variance of the orig-
inal variables xi. the principal components yi represent the most informative
orthogonal aspects of the data set.

a simple method to    nd principal components is the following:

1.    nd the covariance matrix   x of variables in x;
2. compute the eigenvalues   i of   x and sort them in descending order:   1    
  2     . . .   n     0;
3.    nd the eigenvectors ei associated with the eigenvalues   i. the i-th principal
component yi is pn
j=1 ei,jxj, where ei,j is the j-th component of vector ei;
4. determine the m     n most informative principal components y1, y2, . . . , ym

such that:

  1 +   2 + . . . +   m
  1 +   2 + . . . +   n       
where 0 <        1 is a threshold (often    xed at 0.8).
an alternative method (kaiser method) to isolate the m principal compo-
nents is to choose those components such that   i > 1. notice that, since   x is
semi-de   nite positive, its eigenvalues are greater than or equal to 0. moreover, it
i=1   i =
i=1 var(yi). hence, the most informative principal components contribute at
least a fraction of    to the total variance of the original data set x. if variables
in x have di   erent units of measure, then they must be standardized before
applying the method. this is equivalent to work with the correlation matrix rx
instead of with the covariance matrix   x .

holds that the variance var(yi) =   i and pn
pn

i=1 var(xi) = tr(  x ) = pn

the contribution of the original variable xj to the new variable yi is given by
the eigenvector component ei,j. the highest is ei,j in absolute value, the highest

is the contribution of xj to yi. moreover, it holds that the correlation between yi
and xj is ei,j     i/sd(xj), where sd(xj) is the standard deviation of xj. hence
the sign of ei,j gives the sign of the correlation between yi and xj. it turns out
that variables xj can be clustered by associating each xj to the component yi
such that the two variables are most correlated.

7.3 information-theoretic abstractions

rosvall and bergstrom [83] propose a model for resolving community structure
in complex networks based on id205. they start from the following
observation: when we describe a network as a set of interconnected modules, we
are highlighting certain regularities of the network   s structure while    ltering out
the relatively unimportant details. thus, a modular description of a network can
be viewed as a lossy compression of that network   s topology. the best maps are
those that convey a great deal of information while requiring minimal bandwidth;
i.e., they are good compressions. this view suggests that we can approach the
challenge of identifying the community structure of a complex network as a
problem in id205. the authors envision the process of abstraction
of a complex network as a communication process. the link structure of the
network is a random variable x; this is compressed into a simpli   ed description
y which is sent through a noiseless communication channel. the receiver uses the
abstraction y to make guesses z about the structure of the original network x.
the partition of the original network is achieved by minimizing the length l(y )
of the abstraction y plus the length l(x|y ) of the additional information that is
necessary to describe the original network x given its simpli   ed representation
y . the minimization problem is tackled using the simulated annealing approach.
in a successive work [84], the same authors use ergodic id93 on
complex directed weighted networks to reveal community structure. the intu-
ition here is as following. the local interactions among the subunits of a network
system induce a system-wide    ow of information that characterizes the behavior
of the whole system. consequently, if we want to understand how network struc-
ture relates to system behavior, we need to understand the    ow of information
on the network. a group of nodes among which information    ows quickly and
easily can be aggregated and described as a single well connected module; the
links between modules capture the avenues of information    ow between those
modules. the authors use an in   nite random walk as a proxy of the informa-
tion    ow and identify the modules that compose the network by minimizing the
expected description length of the ergodic random walk within and across the
modules. this is the sum of the id178 of the movements across modules and
of the id178 of movements within modules. hu   man code [85] is exploited
to encode the random walk by assigning short codewords to frequently visited
nodes and modules, and longer codewords to rare ones, much as common words
are short in spoken language [6]. shannon source coding theorem [86] provides
a lower bound to the average length of a codeword. the minimization problem
is approached using a greedy search algorithm and the solution is re   ned with
the aid of simulated annealing.

8 quotations

   measuring is knowing        heike kamerlingh onnes

   not everything that can be counted counts, and not everything that
counts can be counted        albert einstein

   if scientometrics is a mirror of science in action, then scientometri-
cians    particular responsibility is to both polish the mirror and warn
against optical illusions        michel zitt

   no amount of fancy statistical footwork will overcome basic inadequa-
cies in either the appropriateness or the integrity of the data collected   
    goldstein and spiegelhalter

   we think of statistics as facts that we discover, not numbers we create   
    joel best

   citations are frozen footprints in the landscape of scholarly achievement
which bear witness of the passage of ideas        blaise cronin

   the use of a single index crashes the multidimensional space of biblio-
metrics into one single dimension        wolfgang gl  anzel

   for unto every one that hath shall be given, and he shall have abun-
dance: but from him that hath not shall be taken away even that which
he hath        jesus of nazareth

references

1. a. de candolle. histoire des sciences et des savants depuis deux si`ecles.

genve/basel: h. georg, 1873.

2. d. de solla price. little science, big science. columbia university press, new

york, 1963.

3. a. pritchard. statistical bibliography or bibliometrics? journal of documentation,

24:348   349, 1969.

4. a. j. lotka. the frequency distribution of scienti   c productivity. journal of the

washington academy of sciences, 16:317   323, 1926.

5. s. c. bradford. sources of information on speci   c subjects. engineering, 137:85   86,

1934.

6. g. k. zipf. human behavior and the principle of least e   ort: an introduction to

human ecology. addison-wesley, cambridge, ma, 1949.

7. a. f. j. van raan. measuring science. capita selecta of current main issues. in
h. f. moed, w. gl  anzel, and u. schmoch, editors, handbook of quantitative science
and technology research. the use of publication and patent statistics in studies of
s&t systems, pages 19   50. kluwer academic publishers, 2006.
8. l. c. smith. citation analysis. library trends, 30(1):85, 1981.
9. b. cronin. the need for a theory of citation. journal of documentation, 37:16   24,

1981.

10. m. h. macroberts and b. r. macroberts. problems of citation analysis: a critical
review. journal of the american society for information science, 40(5):342   349,
1989.

11. p. o. seglen. the skewness of science. journal of the american society for infor-

mation science, 43(9):628   638, 1992.

12. l. c. h. westney. historical rankings of science and technology: a citationist
perspective. the journal of the association for history and computing, 1(1),
1988.

13. j. m. kleinberg. authoritative sources in a hyperlinked environment. journal of

the acm, 46(5):604   632, 1999.

14. brin, l. page, r. motwani, and t. winograd. the id95 citation ranking:
bringing order to the web. technical report 1999-66, stanford infolab, november
1999. retrieved july 1, 2009, from http://ilpubs.stanford.edu:8090/422/.

15. f. narin. patent bibliometrics. scientometrics, 30(1):147   155, 1994.
16. w. m. landes, l. lessig, and m. e. solimine. judicial in   uence: a citation analysis

of federal courts of appeal judges. journal of legal studies, 27:271   332, 1998.

17. h. murai and a. tokosumi. a network analysis of hermeneutic documents based
on bible citations. in annual conference of the cognitve science society, pages
1565   1570, 2005.

18. a. f. j. van raan. comparison of the hirsch-index with standard bibliometric indi-
cators and with peer judgment for 147 chemistry research groups. scientometrics,
67(3):491   502, 2006.

19. w. gl  anzel. on the opportunities and limitations of the h-index. science focus,

1(1):10   11, 2006.

20. m. amin and m. mabe. impact factors: use and abuse. perspectives in publishing,

1:1   6, 2000.

21. f. radicchi, s. fortunato, and c. castellano. universality of citation distributions:
toward an objective measure of scienti   c impact. proceedings of the national
academy of sciences of usa, 105(45):17268   17272, 2008.

22. j. e. hirsch. an index to quantify an individual   s scienti   c research output. pro-
ceedings of the national academy of sciences of usa, 102(46):16569   16572, 2005.

23. p. ball. index aims to fair ranking of scientists. nature, 436:900, 2005.
24. p. ball. achievement index climbs the ranks. nature, 448:737, 2007.
25. j. e. hirsch. does the h index have predictive power? proceedings of the national

academy of sciences of usa, 104(49):19193   19198, 2007.

26. l. bornmann and h-d. daniel. what do we know about the h index? journal of
the american society for information science and technology, 58(9):1381   1385,
2007.

27. p. d. batista, m. g. campiteli, and o. konouchi. is it possible to compare re-

searchers with di   erent scienti   c interests? scientometrics, 68(1):179   189, 2006.

28. l. egghe. theory and practice of the g-index. scientometrics, 69(1):131   152, 2006.
29. b. h. jin. h-index: an evaluation indicator proposed by scientist. science focus,

1(1):8   9, 2006.

30. c. katsaros, y. manolopoulos, and a. sidiropoulos. generalized h-index for dis-

closing latent facts in id191. scientometrics, 72(2):253   280, 2007.

31. p. o. seglen. why the impact factor of journals should not be used for evaluating

research. british medical journal, 314:498   502, 1997.

32. p. campbell. escape from the impact factor. ethics in science and environmental

politics, 8:5   7, 2008.

33. b m. althouse, j. d. west, c. t. bergstrom, and t. bergstrom. di   erences in
impact factor across    elds and over time. journal of the american society for
information science and technology, 60(1):27   34, 2009.

34. j. bollen, m. a. rodriguez, and h. van de sompel. journal status. scientometrics,

69(3):669   687, 2006.

35. l. a. nunes amaral, m. sales-pardo, and m. j. stringer. e   ectiveness of journal
ranking schemes as a tool for locating information. plos one, 3(2):e1683, 2008.
36. k. s. jones, s. walker, and s. e. robertson. a probabilistic model of informa-
information

tion retrieval: development and comparative experiments: part 1.
processing & management, 36(6):779   808, 2000.

37. c. t. bergstrom. eigenfactor: measuring the value and prestige of scholarly jour-

nals. c&rl news, 68(5):314   316, 2007.

38. c. t. bergstrom, j. d. west, and m. a. wiseman. the eigenfactor metrics.

journal of neuroscience, 28(45):11433   11434, 2008.

39. j. west, b. althouse, c. bergstrom, m. rosvall, and t. bergstrom. eigenfac-
tor.org     ranking and mapping scienti   c knowledge. accessed july 1, 2009, at
http://www.eigenfactor.org, 2009.

40. g. pinski and f. narin. citation in   uence for journal aggregates of scienti   c
publications: theory, with application to the literature of physics. information
processing & management, 12(5):297     312, 1976.

41. c. h. hubbell. an input-output approach to clique identi   cation. sociometry,

28:377   399, 1965.

42. w. w. leontief. the structure of american economy, 1919-1929. harvard uni-

versity press, 1941.

43. s. brin and l. page. the anatomy of a large-scale hypertextual web search engine.

computer networks and isdn systems, 30(1-7):107   117, 1998.

44. a. a. goodrum, k. w. mccain, s. lawrence, and c. l. giles. scholarly publishing
in the internet age: a citation analysis of computer science literature. information
processing & management, 37(5):661   675, 2001.

45. d. z. zhao and e. logan. citation analysis using scienti   c publications on the web
as data source: a case study in the xml research area. scientometrics, 54(3):449   
472, 2002.

46. k. m. whitley. analysis of scifinder scholar and web of science citation
searches. journal of the american society for information science and technology,
53(14):1210   1215, 2002.

47. k. bauer and n. bakkalbasi. an examination of citation counts in a new scholarly
communication environment. d-lib magazine, 11(9), 2005. retrieved december
20, 2008, from http://www.dlib.org/dlib/september05/bauer/09bauer.html.

48. p. jacs`o. as we may search. comparison of major features of the web of sci-
ence, scopus, and google scholar citation-based and citation-enhanced databases.
current science, 89(9):1537   1547, 2005. retrieved december 20, 2008, from
http://www.ias.ac.in/currsci/nov102005/1537.pdf.

49. a. noruzi. google scholar: the new generation of citation indexes. libri,

55(4):170   180, 2005.

50. d. pauly and k. i. stergiou. equivalence of results from two citation analyses:
thomson isi   s citation index and google   s scholar service. ethics in science and
environmental politics, pages 33   35, 2005.

51. n. bakkalbasi, k. bauer, j. glover, and l. wang. three options for ci-
biomed-
from

tation tracking: google scholar, scopus and web of science.
ical digital libraries,
http://www.pubmedcentral.nih.gov/articlerender.fcgi?artid=1533854.

retrieved december 20,

2006.

2008

7,

52. k. kousha and m. thelwall. google scholar citations and google web/url cita-
tions: a multi-discipline exploratory analysis. journal of the american society for
information science and technology, 58(7):1055   1065, 2007.

53. g. saad. exploring the h-index at the author and journal levels using bibliometric
data of productive consumer scholars and business-related journals respectively.
scientometrics, 69(1):117   120, 2006.

54. m. norris and c. oppenheim. comparing alternatives to the web of science for
coverage of the social sciences literature. journal of informetrics, 1(2):161   169,
2007.

55. j. bar-ilan, m. levene, and a. lin.

some measures for comparing citation

databases. journal of informetrics, 1(1):26   34, 2007.

56. l. i. meho and k. yang. impact of data sources on citation counts and rankings of
lis faculty: web of science vs. scopus and google scholar. journal of the american
society for information science and technology, 58(13):2105   2125, 2007.

57. k. kousha and m. thelwall. sources of google scholar citations outside the science
citation index: a comparison between four science disciplines. scientometrics,
74(2):273   294.

58. d. shaw and l. vaughan. a new look at evidence of scholarly citation in citation

indexes and from web sources. scientometrics, 74(2):317   330, 2008.

59. l. i. meho and y rogers. citation counting, citation ranking, and h-index of
human-computer interaction researchers: a comparison between scopus and web of
science. journal of the american society for information science and technology,
2008.

60. j. bar-ilan. which h-index? a comparison of wos, scopus and google scholar.

scientometrics, 74(2):257   271, 2008.

61. m. sanderson. revisiting h measured on uk lis academics. journal of the amer-

ican society for information science and technology, 59(7):1184   1190, 2008.

62. l. bornmann, w. marx, h. schier, e. rahm, a. thor, and h.-d. daniel. conver-
gent validity of bibliometric google scholar data in the    eld of chemistry citation
counts for papers that were accepted by angewandte chemie international edition
or rejected but published elsewhere, using google scholar, science citation index,
scopus, and chemical abstracts. journal of informetrics, 3(1):27   35, 2009.

63. v. pareto. cours d     economie politique, volume 2. universit  e de lausanne, lau-

sanne, 1897.

64. s. redner. how popular is your paper? an empirical study of the citation distri-

bution. the european physical journal b, 4:131   134, 1998.

65. j. laherr  ere and d. sornette. stretched exponential distributions in nature and
economy:    fat    tails with characteristic scales. the european physical journal b,
2:525   539, 1998.

66. w. shockley. on the statistics of individual variations of productivity in research

laboratories. proceedings of the ire, 45:279   290, 1957.

67. d. de solla price. a general theory of bibliometric and other cumulative advantage
processes. journal of the american society for information science, 27:292   306,
1976.

68. r. k. merton. the matthew e   ect in science. science, 159(3810):56   63, 1968.
69. m. callon, j-p. courtial, w. turner, and s. brain. from translations to problem-
atic networks: an introduction to co-word analysis. social science information,
22:191   235, 1983.

70. j-p. courtial. a co-word analysis of scientometrics. scientometrics, 31(3):251   260,

1994.

71. h. small. co-citation in the scienti   c literature: a new measure of the relationship
between two documents. journal of the american society for information science
and technology, 24:265   269, 1973.

72. m. m. kessler. bibliographic coupling between scienti   c papers. american docu-

mentation, 14:10   25, 1963.

73. s. k. sen and s. k. gan. a mathematical extension of the idea of bibliographic cou-
pling and its applications. annals of library science and documentation, 30:78   82.
74. w. gl  anzel and h. j. czerwon. a new methodological approach to bibliographic
coupling and its application to the national, regional and institutional level. sci-
entometrics, 37:195   221.

75. m. r. anderberg. cluster analysis for applications. academic press, 1973.
76. r. c. dubes and a. k. jain. algorithms for id91 data. prentice-hall, inc.,

1988.

77. t. f. gonzalez. id91 to minimize the maximum intercluster distance. the-

oretical computer science, 38:293   306, 1985.

78. j. b. macqueen. some methods for classi   cation and analysis of multivariate
observations. in berkeley symposium on mathematical statistics and id203,
pages 281   297, 1967.

79. s. c. johnson. hierarchical id91 schemes. psycometrika, 4:58   67, 1967.
80. t. f. gonzalez and s. sahni. p-complete approximation problems. journal of the

acm, 23:555   565, 1976.

81. k. pearson. on lines and planes of closest    t to systems of points in space. philo-

sophical magazine, 2(6):559   572, 1901.

82. i. jolli   e. principal component analysis. springer, 2002.
83. m. rosvall and c. t. bergstrom. an information-theoretic framework for resolving
community structure in complex networs. proceedings of the national academy of
sciences of usa, 104(18):7327   7331, 2007.

84. m. rosvall and c. t. bergstrom. maps of id93 on complex networks
reveal community structure. proceedings of the national academy of sciences of
usa, 105(4):1118   1123, 2008.

85. d. hu   man. a method for the construction of minimum-redundancy codes. pro-

ceedings of the ire, 40:1098   1101.

86. c.e. shannon. a mathematical theory of communication. bell system technical

journal, 27:379   423.

