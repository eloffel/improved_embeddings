2
1
0
2

 

b
e
f
4
1

 

 
 
]
n
a
-
a
t
a
d

.
s
c
i
s
y
h
p
[
 
 

1
v
3
0
9
2

.

2
0
2
1
:
v
i
x
r
a

web sciences center, university of electronic science and technology of china, chengdu 610054, people   s republic of china

scaling laws in human language

linyuan l  u, zi-ke zhang, and tao zhou   

department of physics, university of fribourg, chemin du muse, fribourg 1700, switzerland
beijing computational science research center, beijing 100084, people   s republic of china

(dated: september 21, 2018)

zipf   s law on word frequency is observed in english, french, spanish, italian, and so on, yet it
does not hold for chinese, japanese or korean characters. a model for writing process is proposed
to explain the above di   erence, which takes into account the e   ects of    nite vocabulary size. ex-
periments, simulations and analytical solution agree well with each other. the results show that
the frequency distribution follows a power law with exponent being equal to 1, at which the corre-
sponding zipf   s exponent diverges. actually, the distribution obeys exponential form in the zipf   s
plot. deviating from the heaps    law, the number of distinct words grows with the text length in
three stages: it grows linearly in the beginning, then turns to a logarithmical form, and eventually
saturates. this work re   nes previous understanding about zipf   s law and heaps    law in language
systems.

pacs numbers: 89.20.hh, 89.75.hc

uncovering the statistics and dynamics of human lan-
guage helps in characterizing the universality, speci   city
and evolution of cultures [1   11]. two scaling relations,
zipf   s law [12] and heaps    law [13], have attracted much
attention from academic community. denote r the rank
of a word according to its frequency z(r), zipf   s law is
the relation z(r)     r     , with    being the zipf   s expo-
nent. zipf   s law was observed in many human languages,
including english, french, spanish, italian, and so on
[12, 14, 15]. heaps    law is formulated as nt     t  , where
nt is the number of distinct words when the text length is
t, and        1 is the so-called heaps    exponent. these two
laws coexists in many language systems. gelbukh and
sidorov [16] observed these two laws in english, russian
and spanish texts, with di   erent exponents depending on
languages. similar results were recently reported for the
corpus of web texts [17], including the industry sector
database, the open directory and the english wikipedia.
the occurrences of tags for online resources [18, 19], key-
words for scienti   c publications [20] and words contained
by web pages resulted from web searching [21] also simul-
taneously display the zipf   s law and heaps    law. inter-
estingly, even the identi   ers in programs by java, c++
and c languages exhibit the same scaling laws [22].

the zipf   s law in language systems could result from
a rich-get-richer mechanism as suggested by the yule-
simon model [23, 24], where a new word is added to a
text with id203 q and an appeared word is ran-
domly chosen and copied with id203 1     q. a word
appears more frequently thus has high id203 to be
copied, leading to a power-law word frequency distribu-
tion p(k)     k      with    = 1 + 1/(1     q). dorogovtsev
and mendes modeled the language processing as evolu-
tion of a word web with preferential attachment [25].

   electronic address: zhutou@ustc.edu

table i: the basic statistics of the four books.    is the
exponent of the power-law frequency distribution and nt is
the total number of distinct characters.

books

v

nt

kmax kmin   

the battle wizard

the story of the stone

727601 4239 21054
1020336 4178 20028
420935 2182 18992
history of the three kingdoms 157201 1139 5929

into the white night

1
1
1
1

1.09
1.03
1.00
1.07

zanette and montemurro [26] as well as cattuto et al.
[27] accounted for the memory e   ects, say the recently
used words have higher id203 to be chosen than
the words occurred long time ago. these works can be
considered as variants of the yule-simon model. mean-
while, the heaps    law may originate from the memory
and bursty nature of human language [28   30].

real language systems to some extent deviate from
these two scaling laws and display more complicated sta-
tistical regularities. wang et al. [31] analyzed represen-
tative publications in chinese, and showed that the char-
acter frequency distribution exhibits an exponential fea-
ture. l  u et al. [32] pointed out that in a growing system,
if the appearing frequencies of elements obey the zipf   s
law with stable exponent, then the number of distinct
elements grows in a complicated way with the heaps   
law only an asymptotical approximation. this deviation
from the heaps    law was further emphasized and math-
ematically proved by eliazar [33]. empirical analyses
on real language systems showed similar deviation [34].
via extensive analysis on individual chinese, japanese
and korean books, as well as a collection of more than
5    104 chinese books, we found even more complicated
phenomena: (i) the character frequency distribution fol-
lows a power law yet it decays exponentially in the zipf   s
plot; (ii) with the increasing of text length, the number of

slope=1.09

(a1)
100

101

103

104

102
k

104

103

102

)
r
(
z

101

100

slope=0.0014

(a2)
0

1000

3000

4000

2000
r

)
k
(
p

10-1

10-2

10-3

10-4

)
k
(
p

10-1

10-2

10-3

10-4

10-1

10-2

)
k
(
p

10-3

10-1

)
k
(
p

10-2

slope=1.03

(b1)
100

101

102
k

103

104

slope=1.00

(c1)
100

101

103

104

102
k

slope=1.07

10-3

(d1)
100

101

102
k

103

104

104

103

102

)
r
(
z

101

100

104

103

)
r
(
z

102

101

100

104

103

102

101

100

)
r
(
z

103

5000

4000

3000

 

(a3)
105

106

104

102

t

n

101

100

100

103

101

102

103
t

 

 

(b3)
106

105

101

102

104

103
t

102

t

n

101

100

100

103

102

t

n

101

2

 

103
t

 

 

(a4)
105

106

104

t

n

2000

1000

0

100

101

102

5000

4000

3000

t

n

2000

1000

0

100

101

102

104

103
t

 

(b4)
106

105

2000

1600

1200

t

n

800

400

0
100

101

102

t

103

104

(c4)
105

106

1250

1000

750

t

n

500

250

0
100

101

102

104

103

t

(d4)
105

(c2)
0

(d2)
0

500

1000

r

1500

2000

100

100

101

102

103

104

t

(c3)
105

106

slope=0.0024

103

102

t

n

101

250

500

r

750

1000

1250

100

100

101

102

(d3)
105

103

104

t

slope=0.0017

(b2)
0

1000

3000

4000

2000
r

slope=0.0012

fig. 1: (color online) the character frequency distribution of the story of the stone: (a1) p(k) with log-log scale and (a2)
z(r) with log-linear scale. the number of distinct words versus the text length of the story of the stone in (a3) log-log scale
and (a4) linear-log scale. similar plots in (b1-b4), (c1-c4) and (d1-d4) are for the books the battle wizard, into the white
night and the history of the three kingdoms, respectively. the power-law exponent    is obtained by using the maximum
likelihood estimation [35, 36], while the exponent in the zipf   s plot is obtained by the least square method excluding the head
(i.e., r > 500 for chinese books and r > 200 for japanese and korean books).

distinct characters grows in three di   erent stages: linear,
logarithmical and saturated. all these unreported regu-
larities may result from the    nite vocabulary size, which
is further veri   ed by a simple theoretical model.

we    rst show some experimental results about the sta-
tistical regularities on chinese, japanese and korean lit-
eratures, which are typical examples generated from a
vocabulary of very limited size if we look at the character
level. there are in total more than 9    104 chinese char-
acters, yet only 3000 to 4000 of which are used frequently
(taiwan and hong kong respectively identify 4808 and
4759 frequently used characters, while mainland china
has two versions of the list of frequently used charac-
ters, one contains 2500 characters and the other contains
3500 characters), and the number of japanese and ko-
rean characters are even smaller. we start with four fa-
mous books, the    rst two are in chinese, the third one is

in japanese and the last one is in korean: (i) the story
of the stone (aliases: the dream of the red chamber,
a dream of red mansions and hong lou meng), writ-
ten by xueqin cao in the mid-eighteenth century during
the reign of emperor chien-lung of the qing dynasty;
(ii) the battle wizard (aliases: tian long ba bu and
demi-gods and semi-devils), a kung fu novel written
by yong jin; (iii) into the white night, a modern novel
written by higashino keigo; (iv) the history of the three
kingdoms, a very famous history book by shou chen in
china and then translated into korean. these books
cover disparate topics and types and were accomplished
in far di   erent dates. the basic statistics of these books
are presented in table 1.

figure 1 reports the character frequency distribution
p(k), the zipf   s plot on character frequency z(r) and the
growth of the number of distinct characters nt versus

 

104

103

t

n

102

101

100

slope=1

(a)

100 101 102 103 104 105 106 107 108 109 1010

t

15000

10000

 

t

n

5000

0

 

103

102

101

 

t

n

(b)

100 101 102 103 104 105 106 107 108 109 1010

t

100

 
100

102

104

 

  =0.01
  =0.05
  =0.1

v=1000

(a)

106

108

1010

 

v=1000
v=2000
v=3000

  =0.1

  =0.01
  =0.05
  =0.1
v=1000

900

800

700

600

500

400

300

200

100

t

n

 
0
100

102

104

v=1000
v=2000
v=3000

  =0.1

2500

2000

1500

1000

500

t

n

(c)

106

108

1010

 
0
100

102

104

t

t

t

t

3

 

(b)

106

108

1010

 

(d)

106

108

1010

103

102

101

t

n

100

 
100

102

104

fig. 3: (color online) growth of the number of distinct char-
acters versus time for di   erent v and    according to eq. 3.
plots (a) and (c) are in log-log scale while while (b) and (d)
are their corresponding plots in linear-log scale.

used ki times, it will be selected with the id203

ki +   

j=1(kj +   )

=

ki +   

v    + t     1

,

(1)

f (ki) =

pv

where    is the initial attractiveness of each character. as-
suming that at time t, there are nt distinct characters in
the text, and we    rst investigate the dependence of nt
on the text length t. the selection at time t + 1 can be
equivalently divided into two complementary yet repul-
sive actions: (i) to select a character from the original
vocabulary with id203 proportional to   , or (ii) to
select a character from the nt words in the created text
with id203 proportional to its appeared frequency.
therefore the id203 to choose a character from the
original vocabulary is v   
v   +t from the cre-
ated text. a character chosen from the created text is
always old, while a character chosen from the vocabulary
could be new with id203 1     nt
v . accordingly, the
id203 that a new character appears at the t+1 time
step, namely the growing rate of nt, is

v   +t , whereas

t

dnt
dt

=

v   

v    + t (cid:18)1    

nt

v (cid:19) .

(2)

with the boundary conditions n0 = 0 and n    = v , we
derive the solution of eq. 2 as

nt = v (cid:20)1    (cid:18) v   

v    + t(cid:19)  (cid:21) .

(3)

this solution embodies three stages of growth of nt.
(i) in the very early stage, when t is much smaller than
v   , ( v   
v and thus nt     t, corresponding

v   +t )       1     t

fig. 2: (color online) the growth of distinct characters in
the collection of 57755 chinese books. the result is obtained
by averaging over 100 randomly determined orders of these
books.

the total number of characters appeared in the text. as
shown in    gure 1, the character frequency distributions
are power-law, meanwhile the frequency decays exponen-
tially in the zipf   s plot, which is in con   ict to the com-
mon sense that a power-law id203 density function
always corresponds to a power-law decay in the zipf   s
plot. actually, there exists a relation between two expo-
nents    and    as    = 1
     1 [32], and thus when    gets close
to 1, the exponent    will diverge and thus the decaying
function in zipf   s plot could not be well characterized
by a power law. therefore, if we observe a non-power-
law decaying in the zipf   s plot, we cannot immediately
deduce that the corresponding id203 density func-
tion is not a power law     it is possibly a power law with
exponent close to 1. note that, in the zipf   s plots, the
turned-up head contains a few hundreds of characters,
majority of which play the similar role to the auxiliary
words, conjunctions or prepositions in english.

figure 1 also indicates that the growth of distinct char-
acters cannot be described by the heaps    law. indeed,
there are two distinguishable stages: in the early stage,
nt grows approximately linearly with the text length t,
and in the later stage, nt grows logarithmically with t.
figure 3 presents the growth of distinct characters for
a large collection of 57755 chinese books consisting of
about 3.4    109 characters and 12800 distinct characters.
in addition to those observed in    gure 1 and    gure 2,
nt displays a strongly saturated behavior when the text
length t is much bigger than the total distinct charac-
ters in the vocabulary. in summary, the experiments on
chinese, japanese and korean literature show us some
unreported phenomena: the character frequency obeys a
power law with exponent close to 1 yet it decays expo-
nentially in the zipf   s plot, and the number of distinct
characters grows in three distinguishable stages. we next
propose a theoretical model to explain these observations.

consider a vocabulary with    nite number, v , of dis-
tinct characters or words. at each time step, one charac-
ter will be selected from the vocabulary to form the text.
motivated by the rich-get-richer mechanism of the yule-
simon model, at time step t, if the character i has been

to a short period of linear growth. (ii) when t is of the
same order of v   , if    is very small, nt could be much
smaller than v . then eq. 2 can be approximated as

dnt
dt

   

v   

v    + t

,

(4)

)
k
(
p

leading to a logarithmical solution

nt     v   ln(cid:18)1 +

t

v   (cid:19).

(5)

indeed, expanding ( v   

v   +t )   by taylor series as

v   +t and 1     nt

and neglecting the high-order terms (m     2) under the
condition        1, one can also arrive to the solution eq. 5.
(iii) when t gets larger and larger, nt will approach to
v and thus both v   
v are very small, leading
to a very slow growing of nt according to eq. 2. these
three stages predicted by the analytical solution are in
good accordance with the above empirical observations.
in
accordance with the analysis, when t is small, nt grows
in a linear form as shown in fig. 3(a) and 3(c), and from
fig. 3(b) and 3(d), straight lines appear in the middle
region, indicating a logarithmical growth predicted by
eq. 5.

figure 3 reports the numerical results on eq. 3.

10   1

10   2

10   3

10   4

 
100

102

(a)

 

simulation
analytic solution

v=1000,   =0.01

slope=1.08

)
r
(
z

106

105

104

103

102

101

100

slope=0.11

(b)

simulation
analytic solution

v=1000,   =0.01

102

k

104

106

 

10   1

 
0

20

40

80

100

60

r

120

100

80

simulation
analytic solution

v=1000,   =0.01

4

 

 

v=1000,   =0.01

(c)

100

 
100

102

t

104

106

40

20

 
0
100

(d)

102

t

104

106

fig. 4: (color online) comparison between simulations re-
sults (blue data points) and analytical solutions (red curves)
for typical parameters v = 1000 and    = 0.01. the subgraphs
(a) and (c) are plotted in log-log scale, while (b) and (d) are
the same data points to (a) and (b) displayed in log-linear
and linear-log scales, respectively. the results are obtained
by averaging over 100 independent runs with text length be-
ing equal to 106.

v    + t(cid:19)  
(cid:18) v   

=

   

xm=0

1

m! (cid:20)      ln(cid:18) v   

v    + t(cid:19)(cid:21)m

(6)

t

n

101

simulation
analytic solution

t

n

60

denote by n(t, k) the number of distinct characters
that appeared k times until time t, then n(t, k) = ntp(k).
according to the master equations, we have

n(t + 1, k + 1) = n(t, k + 1) [1     f (k + 1)] + n(t, k)f (k).
(7)

substituting eq. 1 into eq. 7, we obtain

where kmin is the smallest frequency. when        1,
k1          1 + (1       )lnk, and thus

p (k > k0) = 1     bln

k0 +   
kmin +   

,

(12)

nt+1p(k + 1) = ntp(k + 1)(cid:18)1    

v    + t
(8)
via continuous approximation, it turns to be the follow-
ing di   erential equation

k + 1 +   

v    + t (cid:19)+

ntp(k)(k + 1)

dp
p

=    (cid:20)1 +

v    + t

nt

(nt+1     nt)(cid:21) dk

k +   

.

(9)

substituting nt+1     nt = dnt/dt and eq. 2, we get the
solution

p(k) = b(k +   )   [1+  ( v

nt

   1)],

(10)

where b is the normalized factor. the result shows that
the character frequency follows a power-law distribution
with exponent changing in time. considering the    nite
vocabulary size, in the large limit of t, nt     v and thus

the power-law exponent,    = 1 +   (cid:16) v

nt

    1(cid:17), approaches

1. under the continuous approximation, the cumulative
distribution of character frequency can be written as

p (k > k0) = 1    z k0

kmin

p(k)dk = 1     b

k1     
1       

|k0
kmin , (11)

.

kmin

kmin+  (cid:17)   1

according to the normal-

highest frequency. according to eq.

where b     (cid:16)ln kmax+  
ization condition r kmax
(cid:16)1     bln k+  
k times will be ranked at r = 1 + (cid:16)1     bln k+  

kmin+  (cid:17) nt characters having appeared more
kmin+  (cid:17) nt.

p(k)dk = 1 and kmax is the
12, there are

than k times. that is to say, a character having appeared

therefore

z(r) = k = (kmin +   )exp(cid:20) 1

b (cid:18)1    

r     1

nt (cid:19)(cid:21)       ,

(13)

and z(1) = kmax, z(nt) = kmin. in a word, this simple
model accounting for the    nite vocabulary size results in
a power-law character frequency distribution p(k)     k     
with exponent    close to 1 and an exponential decay of
z(r) in the zipf   s plot, which perfectly agree with the
empirical observations on chinese, japanese and korean
books.

figure 4 reports the simulation results for typical pa-
rameters. the power-law frequency distribution, the ex-
ponential decay of frequency in the zipf   s plot and the

5

linear to logarithmic transition in the growth of the dis-
tinct number of characters are all clearly observed in the
simulation. the simulation results agree very well with
the analytical solutions presented in eq. 3, eq. 10 and
eq. 13.

previous statistical analyses about human language
overwhelmingly concentrate on indo-european family,
where each language consists of a huge number of words.
in contrast, languages consisting of characters, though
cover more than a billion people, obtained less atten-
tion. these languages include chinese, japanese, ko-
rean, vietnamese, jurchen language, khitan language,
makhi
language, tangut language, and many others.
empirical studies here show remarkably di   erent scaling
laws of character-formed from word-formed languages.
salient features include an exponential decay of character
frequency in the zipf   s plot associated with a power-law
frequency distribution with exponent close to 1, and a
multi-stage growth of the number of distinct characters.
these    ndings not only complement our understanding
of scaling laws in human language, but also re   ne the
knowledge about relationship between the power law and
the zipf   s law, as well as the applicability of the heaps   
law. as a result, we should be careful when applying
the zipf   s plot for a power-law distribution with expo-
nent around 1, such as the cluster size distribution in

two-dimensional self-organized critical systems [37], the
inter-event time distribution in human activities [38], the
family name distribution in korea [39], species lifetime
distribution [40], and so on. meanwhile, we cannot deny
a possibly power-law distribution just from a non-power-
law decay in the zipf   s plot [31].

the currently reported scaling laws can be reproduced
by considering    nite vocabulary size in a rich-get-richer
process. di   erent from the well-known    nite-size ef-
fects that vanish in the thermodynamic limit, the e   ects
caused by    nite vocabulary size get stronger as the in-
creasing of the system size. finite choices must be a
general feature in selecting dynamics, but not a neces-
sary ingredient in growing systems. for example, also
based on the rich-get-richer mechanism, neither the lin-
ear growing model [41] nor the accelerated growing model
[42] (treating total degree as the text length and nodes as
distinct characters, the accelerated networks grow in the
heaps    manner [32]) has considered such ingredient. the
present model could distinguish the selecting dynamics
from general dynamics for growing systems.

this work is partially supported by the swiss na-
tional science foundation (project 200020-132253) and
the fundamental research funds for the central univer-
sities.

[1] j. a. hawkins and m. gell-mann, the evolution
of human languages (addison-wesley, reading, mas-
sachusetts,1992).

2004, 332 (2001).

[17] m. a. serrano, a. flammini, and f. menczer, plos one

4, e5372 (2009).

[2] d. caplan, language: structure, processing and disor-

[18] c. cattuto, v. loreto, and l. pietronero, proc. natl.

ders (mit press, cambidge, 1994).

acad. sci. u.s.a. 104, 1461 (2007).

[3] d. lightfoot, the development of language: acquisition,

changes and evolution (blackwell, oxford, 1999).

[4] m. a. nowak and d. c. krakauer, proc.natl. acad. sci.

[19] c. cattuto, a. barrat, a. baldassarri, g. schehr, and v.
loreto, proc. natl. acad. sci. u.s.a. 106, 10511 (2009).
[20] z.-k. zhang, l. l  u, j.-g. liu and t. zhou, eur. phys.

96, 8028 (1999).

j. b 66, 557 (2008).

[5] ramon ferrer i cancho and r. v. sol  e, proc. r. soc.

[21] j. c. lansey and b. bukiet, j. quant. linguistics 16, 40

lond. b 268, 2261 (2001).

(2009).

[6] m. a. nowak, n. l. komarova and p. niyogl, nature

417, 611 (2002).

[7] m. d. hauser, n. chomsky and w. t. fitch, science

[22] h.-y. zhang, inf. process. manage. 45, 477 (2009).
[23] h. a. simon, biometrika 42, 425 (1955).
[24] m. v. simkin and v. p. roychowdhury, phys. rep. 502,

298, 1569 (2002).

1 (2011).

[8] d. abrams and s. strogatz, nature 424, 900 (2003).
[9] e. lieberman, j.-b. michel, j. jackson, t. tang and m.

[25] s. n. dorogovtsev and j. f. f. mendes, proc. r. soc.

lond. b 268, 2603 (2001).

a. nowak, nature 449, 713 (2007).

[26] d. h. zanette and m. a. montemurro, j. quant. linguis-

[10] r. lambiotte, m. ausloos and m. thelwall, j. informet-

tics 12, 29 (2005).

rics 1, 277 (2007).

[27] c. cattuto, v. loreto, and v. d. p. servedio, europhys.

[11] a. m. petersen, j. tenenbaum, s. havlin, and h. e. stan-

lett. 76, 208 (2006).

ley, arxiv: 1107.3707.

[28] w. ebeling and t. p  oschel, europhys. lett. 26, 241

[12] g. k. zipf, behavior and the principal of least e   ort

(1994).

(addison-wealey, cambridge, ma, 1949).

[13] h. s. heaps. information retrieval-computational and

[29] j. kleinberg, data min. knowl. disc. 7, 373 (2003).
[30] e. g. altmann, j. b. pierrehumbert, and a. e. motter,

theoretical aspects (academic press, 1978).

plos one 4, e7678 (2009).

[14] i. kanter, d. a. kessler, phys. rev. lett. 74, 4559

[31] d.-h. wang, m.-h. li, and z.-r. di, physica a 358, 545

(1995).

(2005).

[15] ramon ferrer i cancho and r. v. sol  e, proc. natl. acad.

[32] l. l  u, z.-k. zhang, and t. zhou, plos one 5, e14139

sci. u.s.a. 100, 788 (2002).

(2010).

[16] a. gelbukh and g. sidorov, lect. notes comput. sci.

[33] i. eliazar, physica a 390, 3189 (2011).

[34] s. bernhardsson, l. e. c. da rocha, and p. minnhagen,

new j. phys. 11, 123015 (2009).

[35] m. l. goldstein, s. a. morris, and g. g. yen, eur. phys.

j. b 41, 255 (2004).

[36] a. clauset, c. r. shalizi, and m. e. j. newman, siam

rev. 51, 661 (2009).

[38] a.-l. barab  asi, nature 435, 207 (2005).
[39] b. j. kim ans s. m. park, physica a 347, 683 (2005).
[40] s. pigolotti, a. flammini, m. marsili, and a. martian,

proc. natl. acad. sci. u.s.a. 102, 15747 (2005).

[41] a.-l. barab  asi and r. albert, science 286, 509 (1999).
[42] s. n. dorogovtsev and j. f. f. mendes, phys. rev. e 63,

[37] p. bak, c. tang, and k. wiesenfeld, phys. rev. a 38,

025101(r) (2001).

364 (1988).

6

