   #[1]meta [2]meta [3]meta

   iframe: [4]https://www.googletagmanager.com/ns.html?id=gtm-tr6twrh

   iframe: [5]https://www.googletagmanager.com/ns.html?id=gtm-tr6twrh

create a new account

   email
   ____________________
   register
   [6]returning user

   can't sign in? forgot your password?

   enter your email address below and we will send you the reset
   instructions
   email
   _______________
   submit
   [7]cancel

   if the address matches an existing account you will receive an email
   with instructions to reset your password
   [8]close

   can't sign in? forgot your username?

   enter your email address below and we will send you your username
   email
   _______________
   submit
   [9]cancel

   if the address matches an existing account you will receive an email
   with instructions to retrieve your username
   [10]close

change password

   old password
   ____________________
   new password
   ____________________
   too short weak medium strong very strong too long
   submit
   [11]cancel

password changed successfully

   your password has been changed
   [12]close

login to your account
     __________________________________________________________________

   username
   _______________
   [13]forgot username?
   password
   ____________________
   [14]forgot password?
   keep me logged in
   [ ]
   login
   new user
   institutional login
   [15][mitpress-logo-main-1483476130433.svg]
   [16]the mit pressjournals

     * [17]books
     * [18]journals
     * [19]digital
     * [20]resources
          + [21]for librarians
               o [22]institutional activation
               o [23]institutional license agreement
               o [24]usage stats
               o [25]document delivery
               o [26]mit press journals vpat
               o [27]join our librarian mailing list
               o [28]librarian faq
         [29]quick guides
               o [30]2019 institutional pricing
               o [31]2019 institutional package options and pricing
               o [32]single issue price list
          + [33]for authors
               o [34]submitting publication agreements
               o [35]author posting guidelines
               o [36]copyright information
               o [37]author reprints
               o [38]publishing open access
               o [39]nih public access policy
               o [40]author discounts
               o [41]the mit press and kudos
         [42]quick guides
               o [43]guide1
               o [44]guide2
               o [45]guide3
          + [46]request permissions
         [47]give to the frank urbanowski fund
         [48]trade sales
         [49]advertising info
         [50]release schedule
         [51]faq
         [52]terminated journals
          +
     * [53]about
          + the mit press is a leading publisher of books and journals at
            the intersection of science, technology, and the arts. mit
            press books and journals are known for their intellectual
            daring, scholarly standards, and distinctive design.

[54]about mitpj statement

[55]statement of publication ethics

[56]events & conferences

[57]publishing services

[58]mit press journals staff

[59]how we use analytics
          +
     * [60]contact
          + location
            the mit press
            one rogers street
            cambridge, ma 02142-1209
            [fpo-map-1493476240117.png]
          + phone
            (800) 207-8354
            (us & canada)
            (617) 253-2889
            (outside us and canada)
            (617) 577-1545
            fax
            mit press business hours are m-f, 9:00 a.m. - 5:00 p.m.
            eastern time
            connect
               o [61]facebook
               o [62]twitter
               o [63]google +
               o [64]pinterest
               o [65]instagram
               o [66]youtube
          + [67]send us a message
         quick email links
               o [68]change your address
               o [69]advertising inquiries
               o [70]list exchange & purchasing
               o [71]rights & permissions
               o [72]payments & wire transfer
               o [73]license agreements & consortia
               o [74]subscriptions & back issues
               o [75]electronic access queries
            to submit proposals to either launch new journals or bring an
            existing journal to mit press, please contact director for
            journals and open access, [76]nick lindsay. to submit an
            article please follow the submission guidelines for the
            appropriate journal(s).
          +

   [77]sign in / register
     * [78]enter words / phrases / doi / isbn / authors / keywords / etc.
       computational lingui _______________ _______________
       _______________ _______________
       ____________________ (button)
       search [79]advanced search
     *
     * 0

     * [80]home >
     * [81]computational linguistics >
     * [82]list of issues >
     * [83]volume 40 , no. 3 >
     * similarity-driven semantic role induction via graph partitioning

   article navigation
   [84]previous [85]next
   [86]publication cover

more about computational linguistics

   [87][arrow-button-1488499533633.svg]

journal resources

   [88]editorial info
   [89]abstracting and indexing
   [90]release schedule
   [91]advertising info
     __________________________________________________________________

author resources

   [92]submission guidelines
   [93]publication agreement
   [94]author reprints
     __________________________________________________________________

reader resources

   [95]rights and permissions
   [96]most read
   [97]most cited

metrics

   [98][arrow-button-1488499533633.svg]

article metrics

altmetric

   about article usage data:

   lorem ipsum dolor sit amet, consectetur adipiscing elit. aenean euismod
   bibendum laoreet. proin gravida dolor sit amet lacus accumsan et
   viverra justo commodo. proin sodales pulvinar tempor. cum sociis
   natoque penatibus et magnis dis parturient montes, nascetur ridiculus
   mus.

open access

   [99][arrow-button-1488499533633.svg]
   [open-access-1493356222797.svg]

   computational linguistics computational linguistics is open access. all
   content is freely available in electronic format (full text html, pdf,
   and pdf plus) to readers across the globe. all articles are published
   under a [100]cc by-nc-nd 4.0 license. for more information on allowed
   uses, please view the cc license.
   [101]support oa at mitp

similarity-driven semantic role induction via graph partitioning

   [102]joel lang and [103]mirella lapata
   posted online september 05, 2014
   [104]https://doi.org/10.1162/coli_a_00195

computational linguistics

   volume 40 | issue 3 | september 2014
   p.633-669
   [105][preview-1489555631417.svg] download options
   [arrow-button-1488499533633.svg]

similarity-driven semantic role induction via graph partitioning

   [106]joel lang and [107]mirella lapata
   [108]https://doi.org/10.1162/coli_a_00195
   received: december 26, 2012
   accepted: november 20, 2013
   published online: september 05, 2014
     * [109]full text
     * [110]authors
     * [111]pdf
     * [112]pdf plus

abstract

   section:
   [choose________________________]
   [113]next section

   as in many natural language processing tasks, data-driven models based
   on supervised learning have become the method of choice for semantic
   role labeling. these models are guaranteed to perform well when given
   sufficient amount of labeled training data. producing this data is
   costly and time-consuming, however, thus raising the question of
   whether unsupervised methods offer a viable alternative. the working
   hypothesis of this article is that semantic roles can be induced
   without human supervision from a corpus of syntactically parsed
   sentences based on three linguistic principles: (1) arguments in the
   same syntactic position (within a specific linking) bear the same
   semantic role, (2) arguments within a clause bear a unique role, and
   (3) clusters representing the same semantic role should be more or less
   lexically and distributionally equivalent. we present a method that
   implements these principles and formalizes the task as a graph
   partitioning problem, whereby argument instances of a verb are
   represented as vertices in a graph whose edges express similarities
   between these instances. the graph consists of multiple edge layers,
   each one capturing a different aspect of argument-instance similarity,
   and we develop extensions of standard id91 algorithms for
   partitioning such multi-layer graphs. experiments for english and
   german demonstrate that our approach is able to induce semantic role
   clusters that are consistently better than a strong baseline and are
   competitive with the state of the art.
      2014 association for computational linguistics
   1.   introduction
   section:
   [choose________________________]
   [114]previous section [115]next section

   recent years have seen increased interest in the shallow semantic
   analysis of natural language text. the term is often used to describe
   the automatic identification and labeling of the semantic roles
   conveyed by sentential constituents (gildea and jurafsky [116]2002).
   semantic roles describe the relations that hold between a predicate and
   its arguments (e.g.,    who    did    what    to    whom   ,    when   ,    where   , and
      how   ) abstracting over surface syntactic configurations. this type of
   semantic information is shallow but relatively straightforward to infer
   automatically and useful for the development of broad-coverage,
   domain-independent language understanding systems. indeed, the analysis
   produced by existing semantic role labelers has been shown to benefit a
   wide spectrum of applications ranging from information extraction
   (surdeanu et al. [117]2003) and id53 (shen and lapata
   [118]2007), to machine translation (wu and fung [119]2009) and
   summarization (melli et al. [120]2005).

   in the example sentences below, window occupies different syntactic
   positions   it is the object of broke in sentences (1a,b), and the
   subject in (1c). in all instances, it bears the same semantic role,
   that is, the patient or physical object affected by the breaking event.
   analogously, ball is the instrument of break both when realized as a
   prepositional phrase in (1a) and as a subject in (1b).

   also notice that all three instances of break in example (1) have
   apparently similar surface syntax with a subject and a noun directly
   following the predicate. however, in sentence (1a) the subject of break
   expresses the agent role, in (1b) it expresses the instrument role, and
   in (1c) the patient role.

   the examples illustrate the fact that predicates can license several
   alternate mappings or linkings between their semantic roles and their
   syntactic realization. pairs of linkings allowed by a single predicate
   are often called diathesis alternations (levin [121]1993). sentence
   pair (1a,b) is an example of the instrument subject alternation, and
   pair (1b,c) illustrates the causative alternation. resolving the
   mapping between the syntactic dependents of a predicate (e.g., subject,
   object) and the semantic roles that they each express is one of the
   major challenges faced by semantic role labelers.

   the semantic roles in the examples are labeled in the style of propbank
   (palmer, gildea, and kingsbury [122]2005), a broad-coverage
   human-annotated corpus of semantic roles and their syntactic
   realizations. under the propbank annotation framework each predicate is
   associated with a set of core roles (named a0, a1, a2, and so on) whose
   interpretations are specific to that predicate[123]^1

   1   more precisely, a0 and a1 have a common interpretation across
   predicates as proto-agent and proto-patient in the sense of dowty
   ([124]1991).
   and a set of adjunct roles such as location or time whose
   interpretation is common across predicates (e.g., last night in
   sentence (1c)). the availability of propbank and related resources
   (e.g., framenet; ruppenhofer et al. [125]2006) has sparked the
   development of a variety id14 systems, most of which
   conceptualize the task as a supervised learning problem and rely on
   role-annotated data for model training. most of these systems implement
   a two-stage architecture consisting of argument identification
   (determining the arguments of the verbal predicate) and argument
   classification (labeling these arguments with semantic roles). current
   approaches deliver reasonably good performance   a system will recall
   around 81% of the arguments correctly and 95% of those will be assigned
   a correct semantic role (see m  rquez et al. [[126]2008] for details),
   although only on languages and domains for which large amounts of
   role-annotated training data are available.

   unfortunately, the reliance on labeled data, which is both difficult
   and expensive to produce, presents a major obstacle to the widespread
   application of id14 across different languages and
   text genres. although corpora with semantic role annotations exist
   nowadays in other languages (e.g., german, spanish, catalan, chinese,
   korean), they tend to be smaller than their english equivalents and of
   limited value for modeling purposes. even within english, a language
   for which two major annotated corpora are available, systems trained on
   propbank demonstrate a marked decrease in performance (approximately by
   10%) when tested on out-of-domain data (pradhan, ward, and martin
   [127]2008). the data requirements for supervised systems and the
   current paucity of such data has given impetus to the development of
   unsupervised methods that learn from unlabeled data. if successful,
   unsupervised approaches could lead to significant resource savings and
   the development of semantic role labelers that require less engineering
   effort. besides being interesting on their own right, from a
   theoretical and linguistic perspective, unsupervised methods can
   provide valuable features for downstream (supervised) processing and
   serve as a preprocessing step for applications that require broad
   coverage understanding. in this article we study the potential of
   unsupervised methods for id14. as in the supervised
   case, we decompose the problem into an argument identification step and
   an argument classification step. our work primarily focuses on argument
   classification, which we term role induction, because there is no
   predefined set of semantic roles in the unsupervised case, and these
   must be induced from data. the goal is to assign argument instances to
   clusters such that each cluster contains arguments corresponding to a
   specific semantic role and each role corresponds to exactly one
   cluster.

   unsupervised learning is known to be challenging for many natural
   language processing problems and role induction is no exception.
   firstly, it is difficult to define a learning objective function whose
   optimization will yield an accurate model. this contrasts with the
   supervised setting, where the objective function can directly reflect
   training error (i.e., some estimate of the mismatch between model
   output and the gold standard) and the model can be tuned to replicate
   human output for a given input under mathematical guarantees regarding
   the accuracy of the trained model. secondly, it is also more difficult
   to incorporate rich feature sets into an unsupervised model
   (berg-kirkpatrick et al. [128]2010). unless we explicitly know exactly
   how features interact, more features may not necessarily lead to a more
   accurate model and may even decrease performance. in the supervised
   setting, feature interactions relevant for a particular learning task
   can be determined to a large extent automatically and thus a large
   number of them can be included even if their significance is not clear
   a priori.

   the lack of an extensional definition (in the form of training
   examples) of the target concept makes a strong case for the development
   of unsupervised methods that use problem specific prior knowledge. the
   idea is to derive a strong inductive bias (gordon and desjardins
   [129]1995) based on this prior knowledge that will guide the learning
   towards the correct target concept. for semantic role induction, we
   propose to build on the following linguistic principles:
   1.   

   semantic roles are unique within a particular frame.
   2.   

   arguments occurring in a specific syntactic position within a specific
   linking all bear the same semantic role.
   3.   

   the (asymptotic) distribution over argument heads is the same for two
   clusters that represent the same semantic role.

   we hypothesize that these three principles are, at least in theory,
   sufficient for inducing high-quality semantic role clusters. a
   challenge, of course, lies in adequately operationalizing them so that
   they guide the unsupervised learner towards meaningful solutions. the
   approach taken in this article translates these principles into
   estimates of similarity (or dissimilarity) between argument instances
   and/or clusters of argument instances. principle (1) states that
   argument instances occurring in the same frame (i.e., clause) cannot
   bear the same semantic role, and are thus dissimilar. from principle
   (2) it follows that arguments occurring in the same syntactic position
   within the same linking can be considered similar (leaving aside for
   the moment the difficulty of representing linkings through syntactic
   cues observable in a corpus). principle (3) states that two clusters of
   instances containing similar distributions over head words should be
   considered similar.

   based on these similarity estimates we construct a graph whose vertices
   represent argument instances and whose edges express similarities
   between these instances. the graphs consist of multiple edge layers,
   each capturing one particular type of argument-instance similarity. for
   example, one layer will be used to represent whether argument instances
   occur in the same frame, and another layer will represent whether two
   arguments have a similar head word, and so on. given this graph
   representation of the data, we formalize role induction as the problem
   of partitioning the graph into clusters of similar vertices. we present
   two algorithms for partitioning multi-layer graphs, which are
   adaptations of standard graph partitioning algorithms to the
   multi-layer setting. the algorithms differ in the way they exploit the
   similarity information encoded in the graph. the first one is based on
   agglomeration, where two clusters containing similar instances are
   grouped into a larger cluster. the second one is based on propagation,
   where role-label information is transferred from one cluster to another
   based on their similarity.

   to understand how the aforementioned principles might allow us to
   handle the ambiguity id30 from alternate linkings, consider again
   example (1). the most important thing to note is that, whereas the
   subject position is ambiguous with respect to the semantic roles it can
   express (it can be a0, a1, or a2), we can resolve the ambiguity by
   exploiting overt syntactic cues of the underlying linking. for example,
   the predicate break is transitive in sentences (1a) and (1b), and
   intransitive in sentence (1c). thus, by taking into account the
   argument's syntactic position and the predicate's transitivity, we can
   guess that the semantic role expressed by the subject in sentence (1c)
   is different from the roles expressed by the subjects in sentences
   (1a,b). now consider the more difficult case of distinguishing between
   the subjects in sentences (1a) and (1b). one linking cue that could
   help here is the prepositional phrase in sentence (1a), which results
   in a syntactic frame different from sentence (1b). were the
   prepositional phrase omitted, we would attempt to disambiguate the
   linkings by resorting to lexical-semantic cues (e.g., by taking into
   account whether the subject is animate). in sum, if we encode
   sufficiently many linking cues, then the resulting fine-grained
   syntactic information will discriminate ambiguous semantic roles. in
   cases where syntactic cues are not discerning enough, we can exploit
   lexical information and group arguments together based on their lexical
   content.

   the remainder of this article is structured as follows. [130]section 2
   provides an overview of unsupervised methods for semantic role
   labeling. [131]sections 3 and [132]4 present the details of our method,
   that is, how the graphs are constructed and partitioned. role induction
   experiments in english and german are described in [133]sections 5 and
   [134]6, respectively. discussion of future work concludes in
   [135]section 7.
   2.   related work
   section:
   [choose________________________]
   [136]previous section [137]next section

   the bulk of previous work on id14 has focused on
   supervised methods (m  rquez et al. [138]2008), although a few
   semi-supervised and unsupervised approaches have been proposed. the
   majority of semi-supervised models have been developed within a
   framework known as annotation projection. the idea is to combine
   labeled and unlabeled data by projecting annotations from a labeled
   source sentence onto an unlabeled target sentence within the same
   language (f  rstenau and lapata [139]2009) or across different languages
   (pad   and lapata [140]2009). beyond annotation projection, gordon and
   swanson ([141]2007) propose to increase the coverage of propbank to
   unseen verbs by finding syntactically similar (labeled) verbs and using
   their annotations as surrogate training data.

   swier and stevenson ([142]2004) were the first to introduce an
   unsupervised id14 system. their algorithm induces
   role labels following a id64 scheme where the set of labeled
   instances is iteratively expanded using a classifier trained on
   previously labeled instances. their method starts with a data set
   containing no role annotations at all, but crucially relies on verbnet
   (kipper, dang, and palmer [143]2000) for identifying the arguments of
   predicates and making initial role assignments. verbnet is a manually
   constructed lexicon of verb classes, each of which is explicitly
   associated with argument realization and semantic role specifications.

   in this article we will not assume the availability of any
   role-semantic resources, although we do assume that sentences are
   syntactically analyzed. there have been two main approaches to role
   induction from parsed data. under the first approach, semantic roles
   are modeled as latent variables in a (directed) graphical model that
   relates a verb, its semantic roles, and their possible syntactic
   realizations (grenager and manning [144]2006). role induction here
   corresponds to inferring the state of the latent variables representing
   the semantic roles of arguments. following up on this work, lang and
   lapata ([145]2010) reformulate role induction as the process of
   detecting alternations and finding a canonical syntactic form for them.
   verbal arguments are then assigned roles, according to their position
   in this canonical form, because each position references a specific
   role. their model extends the logistic classifier with hidden variables
   and is trained in a manner that takes advantage of the close
   relationship between syntactic functions and semantic roles. more
   recently, garg and henderson ([146]2012) extend the latent-variable
   approach by modeling the sequential order of roles.

   the second approach is similarity-driven and based on id91. lang
   and lapata ([147]2011a) propose an algorithm that first splits the set
   of all argument instances of a verb according to their syntactic
   position within a particular linking and then iteratively merges
   clusters. a different clusstering algorithm is adopted in lang and
   lapata ([148]2011b). specifically, they induce semantic roles via graph
   partitioning: each vertex in the graph corresponds to an argument
   instance and edges represent a heuristically defined measure of their
   lexical and syntactic similarity. the similarity-driven approach has
   been recently adopted by titov and klementiev ([149]2012a), who propose
   a bayesian id91 algorithm based on the chinese restaurant
   process. in addition, they present a method that shares linking
   preferences across verbs using a distance-dependent chinese restaurant
   process prior which encourages similar verbs to have similar linking
   preferences. titov and klementiev ([150]2012b) further introduce the
   use of multilingual data for improving role induction.

   there has also been work on unsupervised methods for argument
   identification. abend, reichart, and rappoport ([151]2009) devise a
   method for recognizing the arguments of predicates that relies solely
   on part of speech annotations, whereas abend and rappoport ([152]2010a)
   distinguish between core and adjunct roles, using an unsupervised
   parser and part-of-speech tagger. more generally, shallow semantic
   representations induced from syntactic information are commonly used in
   lexicon acquisition and information extraction tasks. for example, lin
   and pantel ([153]2001) cluster syntactic relations between pairs of
   words as expressed by parse tree paths into semantic relations by
   exploiting lexical distributional similarity. although not compatible
   with propbank or semantic roles as such, poon and domingos ([154]2009)
   and titov and klementiev ([155]2011) also induce semantic information
   from dependency parses and apply it to a id53 task for
   the biomedical domain. another example is the work by gamallo,
   agustini, and lopes ([156]2005), who cluster similar syntactic
   positions in order to develop models of selectional preferences to be
   used for word sense induction and the resolution of attachment
   ambiguities.

   the work described here unifies the two id91 methods presented in
   lang and lapata ([157]2011a and [158]2011b) by reformulating them as
   graph partitioning algorithms. it also extends them by utilizing
   multi-layer graphs which separate the similarities between instances on
   different features (e.g., part-of-speech, argument head) into different
   layers. this has the advantage that similarity scores on individual
   features do not have to be eagerly combined into a similarity score
   between instances. instead, one can first aggregate the similarity
   scores on each feature layer between two clusters and then combine them
   into a similarity score between clusters. this is more robust, as the
   feature-wise similarity scores between clusters can be computed in a
   principled way and the heuristic combination step is deferred to the
   end (see [159]section 4 for details). besides providing a general
   modeling framework for semantic role induction, we discuss in detail
   the linguistic principles guiding our modeling choices and assess their
   applicability across languages. specifically, we show that the
   framework presented here (and the aforementioned principles) can be
   readily applied to english and german with identical parametrizations
   for both languages and without fundamentally changing the underlying
   model features, despite major syntactic differences between the two
   languages.
   3.   graph construction
   section:
   [choose________________________]
   [160]previous section [161]next section

   we begin by explaining how we construct a graph that represents verbs
   and their arguments. next, we describe how edge weights are
   computed   these translate to similarity scores between argument
   instances   and then move on to provide the details of our
   graph-partitioning algorithms.

   as mentioned earlier, we formalize semantic role induction as a
   id91 problem. id91 algorithms (see jain, murty, and flynn
   [[162]1999] for an overview) commonly take a matrix of pairwise
   similarity scores between instances as input and produce a set of
   output clusters, often satisfying some explicitly defined optimality
   criterion. the success or failure of the id91 approach is closely
   tied to the adequacy of the employed similarity function for the task
   at hand. the graph partitioning view of id91 (see schaeffer
   [[163]2007] for a detailed treatment) arises when instances are
   represented as the vertices of a graph and the similarity matrix is
   interpreted as the weight matrix of the graph. for semantic role
   induction, a straightforward application of id91 would be to
   construct a graph for each verbal predicate such that vertices
   correspond to argument instances of the verb and edge weights quantify
   the similarity between these instances.

   lang and lapata ([164]2011b) hand-craft an instance similarity function
   by taking into account different features such as the argument head or
   its syntactic position. defining an appropriate instance-wise
   similarity function is nevertheless problematic as weights have to be
   chosen heuristically. instead, we will represent similarities with
   respect to different features on separate edge layers in the graph. for
   example, one layer will represent the similarity between the head words
   of arguments and another one will represent the similarity between pars
   of speech. so, given m features, the graph will consist of m layers,
   one for each feature. edge weights on a particular layer quantify the
   similarity between the instances with respect to that feature. this is
   illustrated in [165]figure 1 for two argument instances and three
   features. formally, a multi-layer graph is defined as a pair (v, {e[1],
       , e[m]}) consisting of vertices v and a set of edge layers e[f] for f
   = 1     m. the set of vertices v = {v[1],     , v[n]} consists of all n
   argument instances for a particular verb. the edge layer e[f] for
   feature f is constructed by connecting all vertex-pairs with non-zero
   similarity with respect to f:

   where   [f](v[i],v[j]) is a similarity function for feature f, whose
   form will be discussed in the next section. each edge (v[i],v[j])    
   e[f]in layer f is weighted by   [f](v[i],v[j]).
   [166]figure
   figure   1    a multi-layer graph consists of multiple edge layers, one for
   each similarity feature. multi-layer graph partitioning algorithms
   exploit this representation by computing separate similarity scores
   between clusters for each feature layer and then combining them into a
   single overall similarity score. this is advantageous over single-layer
   graph partitioning because it avoids eagerly combining the similarity
   scores for individual features into a heuristic instance-wise
   similarity score.
   3.1   feature similarity functions

   similarities for a specific feature f are measured with a function
     [f](v[i],v[j]) which assigns a [   1,1] value to any pair of instances
   (v[i],v[j]). we assume similarities are measured on an interval
   scale   that is, while sums, differences, and averages of the values of
   some similarity function   [f] express meaningful quantities, products
   and ratios do not. moreover, the values of two distinct similarity
   functions cannot necessarily be meaningfully compared without
   rescaling. positive similarity values indicate that the semantic roles
   are likely to be the same, negative values indicate that roles are
   likely to differ, and zero values indicate that there is no evidence
   for either case. the magnitude of   [f] expresses the degree of
   confidence in the similarity judgment, with extreme values (i.e.,    1
   and 1) indicating maximal confidence.

   in our model, we simply use indicator functions which output either 1
   or    1 iff feature values are equal and 0 otherwise. specifically, we
   define four feature similarity functions that we derive from the
   principles discussed in [167]section 1. our similarity functions are
   based on the following features: the argument head words and their
   parts of speech,[168]^2

   2   we include parts of speech as a simple means of alleviating the
   sparsity of head words.
   the frame constraint, and the syntactic position within a particular
   linking. we measure lexical and part-of-speech similarity as follows:

   the constraint that two argument instances v[i] and v[j] occurring in
   the same frame cannot have the same semantic role is captured by the
   following similarity function:

   finally, we also measure syntactic similarity through an indicator
   function   [syn](v[i],v[j]), which assumes value 1 if two instances
   occur in the same syntactic position within the same linking:

   the syntactic position of an argument is directly given by the parse
   tree and can be encoded, for example, by the full path from predicate
   to argument head, or for practical purposes, in order to reduce
   sparsity, simply through the relation governing the argument head and
   its linear position relative to the predicate (left or right). in
   contrast, linkings are not directly observed, but we can resort to
   overt syntactic cues as a proxy. examples include the verb's voice
   (active/passive), whether it is transitive, the part-of-speech of the
   subject, and so on. we argue that in principle, if sufficiently many
   cues are taken into account, they will capture one particular linking,
   although there may be several encodings for the same linking. note that
   syntactic similarity is not used to construct another graph layer;
   rather, it will be used for deriving initial clusters of instances, as
   we explain in [169]section 4.1.
   4.   graph partitioning
   section:
   [choose________________________]
   [170]previous section [171]next section

   the graph partitioning problem consists of finding a set of clusters
   {c[1],     , c[s]} that form a partition of the vertex-set, namely,
      [i]c[i] = v and c[i]     c[j] =     for all i     j, such that (ideally)
   each cluster contains argument instances of only one particular
   semantic role, and the instances for a particular role are all assigned
   to one and the same cluster. in the following sections we provide two
   algorithms for multi-layer graph partitioning, based on standard
   id91 algorithms for single-layer graphs. both algorithms operate
   on the same graph but differ in terms of the underlying id91
   mechanism they use. the first algorithm is an adaptation of
   agglomerative id91 (jain, murty, and flynn [172]1999) to the
   multi-layer setting: starting from an initial id91, the algorithm
   iteratively merges vertex clusters in order to arrive at increasingly
   accurate representations of semantic roles. rather than greedily
   merging clusters, our second algorithm is based on propagating cluster
   membership information among the set of initial clusters (abney
   [173]2007).

   4.1   agglomerative graph partitioning

   the agglomerative algorithm induces clusters in a bottom   up manner
   starting from an initial cluster assignment that we will subsequently
   discuss in detail. our initialization results in a id91 that has
   high purity but low collocation, that is, argument instances in each
   cluster tend to belong to the same role but argument instances of a
   particular role are scattered among many clusters.[174]^3

   3   we define the terms purity and collocation more formally in
   [175]section 5.4.
   the algorithm then improves collocation by iteratively merging pairs of
   clusters. the agglomeration procedure is described in algorithm 1 . as
   can be seen, pairs of clusters are merged iteratively until a
   termination criterion is met. the decision of which cluster pair to
   merge at each step is made by scoring a set of candidate cluster pairs
   and choosing the highest one (line 5). the scoring function s(c[i],
   c[j   ]) quantifies how likely two clusters are to contain arguments of
   the same role. a key question is how to define this scoring function on
   the basis of the underlying graph representation, that is, with
   reference to the instance similarities expressed by the edges. in order
   to collect evidence for or against a merge, we take into account the
   connectivity of a cluster pair at each feature layer of the graph. this
   crucially involves aggregating over all edges that connect the two
   clusters, and allows us to infer a cluster-level similarity score from
   the individual instance-level similarities encoded in the edges. the
   evidence collected at each layer is then combined together in order to
   arrive at an overall decision (see [176]figure 1 for an illustration).

   although it would be possible to enumerate and score all possible
   cluster pairs at each step, we apply a more efficient and effective
   procedure in which the set of candidates consists of pairs formed by
   combining a fixed cluster c[i] with all clusters larger than c[i]. this
   requires comparing only o(|c|) rather than o(|c|^2) scores and, more
   importantly, it favors merges between large clusters whose score can be
   computed more reliably. as mentioned earlier, our scoring function
   implements an averaging procedure over the instances contained in the
   clusters, and thus yields less noisy scores when clusters are large
   (i.e., contain many instances). this prioritization promotes reliable
   merges over less reliable ones in the earlier phases of the algorithm
   with a positive effect on merges in the later phases. moreover, by
   keeping c[i] fixed, we only require that scores s(c[i],x) and s(c[i],z)
   are comparable (i.e., where one cluster is argument in both scores),
   rather than comparisons between arbitrary cluster pairs (e.g., s(w,x)
   and s(y,z)). in the following, we will provide details on the
   initialization of the algorithm and the computation of the similarity
   scoring function.

   a standard agglomerative id91 algorithm forms clusters bottom   up
   by initially placing each item of interest in its own cluster. in our
   case, initializing the algorithm with as many clusters as argument
   instances would result in a id91 with maximal purity and minimal
   collocation. there are two reasons that justify a more sophisticated
   initialization procedure for our problem. firstly, the scoring function
   we use is more reliable for larger clusters than for smaller clusters
   (see the subsequent discussion). in fact, the standard initialization
   that creates clusters with a single instance would not yield useful
   results as our scoring function crucially relies on initial clusters
   containing several instances on average. secondly, the similarity
   scores for different features are not directly comparable. recall from
   [177]section 3.1 that we introduced different types of similarities
   based on the arguments' head words (  [lex]), parts-of-speech (  [pos]),
   syntactic positions (  [syn]), and frame constraints (  [frame]). as
   discussed earlier, engineering a scoring function that integrates these
   into a single score without resorting to heuristic judgments on how to
   weight them poses a major challenge. in particular, it is difficult to
   weight the contribution of the two forms of positive evidence given by
   lexical and syntactic similarity. this motivates the idea of using
   syntactic similarity for initialization, and lexical similarity (as
   well as the frame constraint) for scoring. this separation avoids the
   difficulty of defining the exact interaction between the two.
   specifically, we obtain an initial id91 by grouping together all
   instances which occur in the same syntactic position within a
   linking   that is, all pairs (v[i], v[j]) for which   [syn](v[i], v[j]) =
   1 are grouped into the same cluster, assuming that arguments occurring
   in a specific syntactic position under a specific linking share the
   same role.

   we specify the syntactic position of an argument using four cues: the
   verb's voice (active/passive), the argument's linear position relative
   to the predicate (left/right), the syntactic relation of the argument
   to its governor (e.g., subject or object), and the preposition used for
   realizing the argument (if any). each argument is assigned a four-tuple
   consisting of these cues and two syntactic positions are assumed equal
   iff they agree on all cues.

   whereas the similarity functions defined in [178]section 3.1 measure
   role-semantic similarity between instances on a particular feature, the
   scoring function measures role-semantic similarity between clusters.
   naturally, the similarity between two clusters is defined in terms of
   the similarities of the instances contained in the clusters. this
   involves two aggregation stages. initially, instance similarities are
   aggregated in each feature layer, resulting in an aggregate score for
   each feature. these layer-specific scores are then integrated into a
   single score, which quantifies the overall similarity between the two
   clusters (see [179]figure 1).

   an obvious way to determine the similarity between two clusters (with
   respect to a particular feature f) would be to analyze their
   connectivity. for example, we could use edge density (schaeffer
   [180]2007) to average over the weights of edges between two clusters.
   however, edge density is an inappropriate measure of similarity in our
   case, because we cannot assume that arbitrary pairs of instances are
   similar with respect to a particular feature, even if two clusters
   represent the same semantic role. consider for example lexical
   similarity: most head words will not agree (even within a cluster) and
   therefore averaging between all pairs would yield low scores,
   regardless of whether the clusters represent the same role or not.
   analogously, the vast majority of instance pairs from any two clusters
   will belong to different frames, and thus averaging over all possible
   pairs of instances would not yield indicative scores.

   we therefore adopt an averaging procedure which finds, for each
   instance in one cluster, the instance in the other cluster that is
   maximally similar or dissimilar and averages over the scores of these
   alignments:

   here, abs max is a functional that returns the extreme value of its
   argument, either positive or negative: abs max[x   x] g(x) = g(arg
   max[x   x] |g(x)|). note that the alignments are unconstrained in the
   sense that v[a]     c[k] can be aligned to v[b]     c[l] in the first term
   of [181]equation (6), while v[b] can be aligned to some other instance
   in the second term. moreover, alignments in each term are many-to-one,
   namely, multiple instances from c[k] can be aligned to the same v[b]    
   c[l] in the first term and likewise in the second term. this means that
   score aggregation does not reflect the distributional properties of
   clusters (e.g., the frequency of head words in each cluster). consider
   for example two clusters with an identical set of head words. because
   many-to-one alignments are allowed, each instance can be aligned with
   maximal score to some other instance regardless of the frequencies of
   these words.

   as an alternative, we also use the well-known cosine similarity
   function   although only for the features based on argument head words
   (lex) and parts of speech (pos):

   here and are vector representations of the cluster containing as
   components the occurrence frequencies of a particular value of the
   feature f (i.e., lex and pos in our case). another solution would be to
   enforce one-to-one alignments and redefine [182]equation (6) as the
   optimal bipartite matching between the two clusters. although this
   solution adheres to the graph formulation (in contrast to [183]equation
   (7)) we see no theoretical reason that makes it superior to cosine
   similarity. moreover, its computation would require cubic runtime in
   the number of vertices using the hungarian algorithm (munkres
   [184]1957), which is prohibitively slow for sufficiently large
   clusters.

   layer-specific similarity scores must be combined into an overall
   cluster similarity score. because similarity scores and their
   aggregates for different features are not directly comparable, their
   combination through summation would require weighting each layer score
   according to its relative strength. due to the difficulty of specifying
   these weights without access to labeled training data, we propose an
   alternative scheme that is based on the distinction between positive
   and negative evidence. negative evidence is used to rule out a merge,
   whereas positive evidence provided by the lexical score is used to
   score merges that have not yet been ruled out:

   when the part-of-speech similarity is below a certain threshold   , or
   when clause-level constraints are satisfied to a lesser extent than
   threshold   , the score takes value    1 and the merge is ruled out. if
   the merge is not ruled out, the lexical similarity score determines the
   magnitude of the overall score, provided that it is above threshold   .
   otherwise, the function returns 0, indicating that neither strong
   positive nor negative evidence is available. the cluster-similarity
   scoring function can be viewed as the decision function of a binary
   classifier for deciding on whether to merge a particular pair of
   clusters. the classifier is informed by the similarity scores for each
   feature layer and outputs a confidence-weighted decision
   (positive/negative), where the sign sgn(  [f](v[i], v[j])) indicates the
   decision and the absolute value |  [f](v[i],v[j])| quantifies
   confidence. the scoring function in [185]equation (8) essentially
   implements a simple decision list classifier, whose decision rules are
   sequentially inspected from top to bottom, applying the first matching
   rule.

   although our definition avoids weighting, it has introduced threshold
   parameters   ,   , and    that we need to somehow estimate. we propose a
   scheme in which parameters    and    are iteratively adjusted, and   , the
   threshold determining the extent to which the frame constraints can be
   violated, is kept fixed. we heuristically set    to     0.05, based on the
   intuition that in principle frame constraints must be satisfied
   although in practice, due to noise we expect a small number of
   violations (i.e., at most 5% of instances can violate the constraint).
   parameters    and    are initially set to their maximal value 1, thereby
   ruling out all merges except those with maximal confidence. the
   parameters then decrease iteratively according to a routine whose
   pseudo-code is specified in algorithm 2 . the parameter    decreases at
   each iteration by a small amount (0.025) until it reaches    = 0.025, at
   which point its value is reset to 1.0 and    is discounted by a factor
   close to one (0.9). this is repeated until    falls below   , upon which
   the algorithm terminates.

   runtime analysis. as described in the previous section, algorithm 1
   stops when the threshold    falls below some small value   . both    and   
   iteratively decrease based on a fixed scheme. the outer loop and
   starting in line 1 is therefore computed in constant time t. each pass
   through the inner loop starting at line 4 iterates over o(|c|) clusters
   and for each one of them a score with o(|c|) other clusters is
   computed. assume that f[i] denotes the fraction of all v instances in
   cluster c[i], namely, f[i] v = |c[i]| and . then, overall, the number
   of instance-wise similarities we need to evaluate is at most o(|v|^2):

   the total runtime in terms of the input is therefore o(t   |v|^2).
   although this could be prohibitively inefficient for large data sets,
   we did not observe long runtimes in our experiments. various
   optimizations are conceivable   for example, the cluster similarity
   scores in line 5 of algorithm 1 can be cached such that they only need
   to be recomputed when a cluster changes (i.e., it is merged with
   another cluster).
   4.2   multi-layer label propagation

   our second graph partitioning algorithm is based on the idea of
   propagating cluster membership information along the edges of a graph,
   subsequently referred to as propagation graph. as we explain in more
   detail subsequently, compared with agglomerative id91, this
   algorithm in principle is less prone to making false greedy decisions
   that cannot be later revoked. moreover, it has lower runtime and thus
   scales better to larger data sets.

   the propagation graph is created by collapsing vertices of the initial
   multi-layer graph. vertices in the propagation graph represent an
   atomic set of instances of the original graph, that is, a group of
   instances that are always assigned to the same cluster. for our
   induction problem, the vertices of the propagation graph correspond to
   the initial clusters of the agglomerative algorithm discussed in
   [186]section 4.1. more formally, let a[i]     a denote the i-th vertex of
   the propagation graph, which references an atomic cluster of vertices
   of the original graph that occur in the same syntactic position within
   the same linking. because each vertex of the propagation graph
   corresponds to a cluster of vertices in the original graph, the edges
   of the propagation graph can be defined in terms of the edges between
   these vertices in the original graph. we reuse [187]equations (6) and
   [188](7) to define the edge weights of the propagation graph as
   aggregates over the edge weights in the original graph. for each
   feature layer we define the set of edges as:

   each edge (a[i], a[j])     b[f] in layer f is accordingly weighted by
   s[f](a[i], a[j]). each vertex a[i] is associated with a label l[i],
   indicating the partition that a[i] and all the vertices in the original
   graph that have been collapsed into a[i] belongs to.

   note that the label propagation algorithm is informed by the same
   similarity functions as agglomerative id91 and uses an identical
   initialization procedure but provides an alternative means of cluster
   id136. initially, each vertex of the propagation graph belongs to
   its own cluster, that is, we let the number of clusters l = |a| and set
   l[i]     i. given this initial vertex labeling, the algorithm proceeds by
   iteratively updating the label for each vertex (lines 4   10 in algorithm
   3). this crucially relies on a scoring procedure in which a score s(l)
   is computed for each possible label l. we discuss the details of the
   scoring procedure below.

   the label scoring procedure required in line 5 of algorithm 3 has
   parallels to the cluster pair scoring procedure of the agglomerative
   algorithm. it also consists of two stages: initially, evidence is
   collected independently on each feature layer by computing label score
   aggregates with respect to each feature and then these feature scores
   are combined in order to arrive at an overall score.

   assume we are updating vertex a[i]. the first step is to compute the
   score for each feature f and each label l:

   where denotes the set of a[i]'s neighbors with label l that are larger
   than a[i]. intuitively, each neighboring vertex votes for the cluster
   it is currently assigned to, where the strength of the vote is
   determined by the similarity to the vertex (i.e., edge weight) being
   updated. the votes of all (larger) neighboring vertices are counted
   together, resulting in a score for each possible label. the condition
   of including only larger vertices for computing the score is analogous
   to the prioritization mechanism of the agglomerative algorithm (only
   merges with larger clusters are considered for a given candidate
   cluster). we impose this restriction for the same reason, namely, that
   scores for larger clusters are more reliable.

   given the scores s[f](l) for a particular label l on each layer f, our
   goal then is to combine them into a single overall score s(l) for the
   label. as in agglomerative partitioning, combining these scores through
   summation is not possible without    guessing    their weights, and
   therefore we use a sequential combination instead:

   analogously to [189]equation (8), negative evidence that stems from
   part-of-speech information or frame constraints can veto a propagation,
   whereas positive evidence id30 from argument head words can promote
   a propagation. if neither strong evidence (positive or negative) is
   available, the label is assigned a zero score. note that the scoring
   function has three parameters with an identical interpretation to those
   in the scoring function of the agglomerative algorithm. the threshold
   update that takes place in line 11 of algorithm 3 is therefore the same
   as the one described in [190]section 4.1 for the agglomerative
   algorithm.

   we now analyze the runtime of our algorithm. let t denote the number of
   iterations of the outer loop starting at line 1 of algorithm 3 . the
   inner loop starting at line 4 iterates over |a| clusters and for each
   one of them it has to evaluate at most |a| neighboring nodes.
   additionally, there are the one-time costs of computing the
   similarities between atomic clusters which take o(|v|^2) time. the
   total runtime is therefore o(t |a|^2 + |v|^2). because |a|^2 < < |v|^2,
   label propagation is substantially faster than agglomerative
   id91.

   4.3   relationship to single-layer graph partitioning

   id91 algorithms typically assume instance-wise similarities as
   input (i.e., single-layer graphs). for our role induction problem, this
   would require a heuristically defined similarity function that combines
   the similarities on individual features into a single similarity score
   between instances. in other words, we would collapse the multiple graph
   layers into a single layer and then partition the resulting
   single-layer graph according to a standard id91 algorithm. a main
   difference between the two approaches is the order in which
   similarities are aggregated: whereas multi-layer graph partitioning
   aggregates similarities on each feature layer first and then combines
   them into an overall cluster-wise similarity score, in the single-layer
   case feature similarities are eagerly combined into an overall
   instance-wise similarity score and then aggregated. thus, in the
   multi-layer setting, aggregation can be done in a principled way by
   considering the individual feature layers in isolation. for large
   clusters the resulting scores for each feature layer will provide
   reliable evidence for or against a merge. combining these cluster-wise
   similarity scores is much less error-prone than the eager combination
   at the instance-level used by the single-layer approach. we
   experimentally confirm this intuition (see [191]section 5.5) by
   comparing against the single-layer partitioning algorithm presented in
   lang and lapata ([192]2011b).
   5.   role induction experiments on english
   section:
   [choose___________________________]
   [193]previous section [194]next section

   we adopt the general architecture of supervised id14
   systems where argument identification and argument classification are
   treated separately. our role labeler is fully unsupervised with respect
   to both tasks   it does not rely on any role annotated data or semantic
   resources. however, our system does not learn from raw text. in common
   with most id14 research, we assume that the input is
   syntactically analyzed. our approach is not tied to a specific
   syntactic representation   both constituent- and dependency-based
   representations can be used. the bulk of our experiments focus on
   english data and a dependency-based representation that simplifies
   argument identification considerably and is consistent with the conll
   2008 benchmark data set used for evaluation in our experiments. to show
   that our method can be applied to other languages and across varying
   syntactic representations, we also report experiments on german using a
   constituent-based representation (see [195]section 6).

   given the parse of a sentence, our system identifies argument instances
   and assigns them to clusters. thereafter, argument instances can be
   labeled with an identifier corresponding to the cluster they have been
   assigned to, similar to propbank core labels (e.g., a0, a1). we view
   argument identification as a syntactic processing step that can be
   largely undertaken deterministically through analysis of the syntactic
   tree. we therefore use a small set of rules to detect arguments with
   high precision and recall. in the following, we first describe the data
   set ([196]section 5.1) on which our experiments were carried out. next,
   we present the argument identification component of our system
   ([197]section 5.2) and the method used for comparison with our
   approach. finally, we explain how system output was evaluated
   ([198]section 5.4).
   5.1   data

   for evaluation purposes, we ran our method on the conll 2008 shared
   task data set (surdeanu et al. [199]2008), which provides propbank
   style gold standard annotations. as our algorithm induces verb-specific
   roles, propbank annotations are a natural choice of gold standard for
   our problem. the data set contains annotations for verbal and nominal
   predicate-argument constructions, but we only considered the former.
   the conll data set was taken from the wall street journal portion of
   the id32 and converted into a dependency format (surdeanu et
   al. [200]2008). input sentences are represented in the dependency
   syntax specified by the conll 2008 shared task (see [201]figure 2 for
   an example). in addition to gold standard dependency parses, the data
   set also contains automatic parses obtained from the maltparser (nivre
   et al. [202]2007), which we will use as an alternative in our
   experiments in order to assess the impact of parse quality. for each
   argument only the head word is annotated with the corresponding
   semantic role, rather than the whole constituent. we assume that
   argument heads are content words (e.g., the head of a prepositional
   phrase is the nominal head rather than the preposition). we do not
   treat split arguments or co-referential arguments (e.g., in relative
   clauses). specifically, we ignore arguments with roles preceded by the
   c- or r- prefix in the gold standard. all argument lemmas were
   normalized to lower case; we also replaced numerical quantities with a
   placeholder; to further reduce data sparsity, we identified the head of
   proper noun phrases heuristically as the most frequent lemma contained
   in the phrase.
   [203]figure
   figure   2    a sample dependency parse with dependency labels sbj
   (subject), obj (object), nmod (nominal modifier), oprd (object
   predicative complement), prd (predicative complement), and im
   (infinitive marker).
   5.2   argument identification

   in the supervised setting, a classifier is used in order to decide for
   each node in the parse tree whether it represents a semantic argument
   or not. nodes classified as arguments are then assigned a semantic
   role. in the unsupervised setting, we slightly reformulate argument
   identification as the task of discarding as many non-semantic arguments
   as possible. this means that the argument identification component does
   not make a final positive decision for any of the argument candidates;
   instead, this decision is deferred to role induction.[204]^4

   4   a few supervised systems implement a similar definition (koomen et
   al. [205]2005), although in most cases the argument identification
   component makes a final positive or negative decision regarding the
   status of an argument candidate.
   we assume here that predicate identification is a precursor to argument
   identification and can be done relatively straightforwardly based on
   part-of-speech information.

   the rules given in [206]table 1 are used to discard or select argument
   candidates for english. they primarily take into account the parts of
   speech and the syntactic relations encountered when traversing the
   dependency tree from predicate to argument. a priori, all words in a
   sentence are considered argument candidates for a given predicate.
   then, for each candidate, the rules are inspected sequentially and the
   first matching rule is applied. we will exemplify how the argument
   identification component works for the predicate expect in the sentence
   the company said it expects its sales to remain steady whose parse tree
   is shown in [207]figure 2. initially, all words except the predicate
   itself are treated as argument candidates. then, the rules from
   [208]table 1 are applied as follows. firstly, the words the and to are
   discarded based on their part of speech (rule 1); then, remain is
   discarded because the path ends with the relation im and said is
   discarded as the path ends with an upward-leading obj relation (rule
   2). rule 3 matches to it, which is therefore added as a candidate.
   next, steady is discarded because there is a downward-leading oprd
   relation along the path and the words company and its are also
   discarded because of the obj relations along the path (rule 4). rule 5
   does not apply but the word sales is kept as a likely argument (rule
   6). finally, rule 7 does not apply, because there are no candidates
   left.

   [209]table
   table   1    argument identification rules for english.

   on the conll 2008 training set, our argument identification rules
   obtain a precision of 87.0% and a recall of 92.1% on gold standard
   parses. on automatic parses, precision is 79.3% and recall 84.8%. here,
   precision measures the percentage of selected arguments that are actual
   semantic arguments, and recall measures the percentage of actual
   arguments that are not filtered out.

   grenager and manning ([210]2006) also devise rules for argument
   identification, unfortunately without providing any details on their
   implementation. more recently, attempts have been made to identify
   arguments without relying on a treebank-trained parser (abend and
   rappoport [211]2010b; abend, reichart, and rappoport [212]2009). the
   idea is to combine a part-of-speech tagger and an unsupervised parser
   in order to identify constituents. likely arguments can be in turn
   identified based on a set of rules and the degree of collocation with
   the predicate. perhaps unsurprisingly, this method does not match the
   quality of a rule-based component operating over trees produced by a
   supervised parser.
   5.3   baseline method for semantic role induction

   the linking between semantic roles and syntactic positions is not
   arbitrary; specific semantic roles tend to map onto specific syntactic
   positions such as subject or object (levin and rappaport [213]2005;
   merlo and stevenson [214]2001). we further illustrate this observation
   in [215]table 2, which shows how often individual semantic roles map
   onto certain syntactic positions. the latter are simply defined as the
   relations governing the argument. the frequencies in the table were
   obtained from the conll 2008 data set and are aggregates across
   predicates. as can be seen, semantic roles often approximately
   correspond to a single syntactic position. for example, a0 is commonly
   mapped onto subject (sbj), whereas a1 is often realized as object
   (obj).

   [216]table
   table   2    contingency table between syntactic position and semantic
   roles. only the eight most frequent syntactic positions and their
   labels are listed (i.e., sbj (subject), obj (object), adv (adverbial),
   tmp (temporal), pmod (preposition and its child), oprd (object
   complement), loc (location), dir (direction)). counts were obtained
   from the conll 2008 training data set using gold standard parses. the
   marginals in the right-most column include all syntactic positions (not
   only the eight most frequent ones). boldface highlights the most
   frequent role per syntactic position (e.g., sbj is frequently a0, obj
   is a1).

   this motivates a baseline that directly assigns instances to clusters
   according to their syntactic position. the pseudo-code is given in
   algorithm 4. for each verb we allocate n = 22 clusters (the maximal
   number of gold standard clusters together with a default cluster).
   apart from the default cluster, each cluster is associated with a
   syntactic position and all instances occurring in that position are
   mapped into the cluster. despite being relatively simple, this baseline
   has been previously used as a point of comparison by other unsupervised
   id14 systems (grenager and manning [217]2006; lang
   and lapata [218]2010) and shown difficult to outperform. this is partly
   due to the fact that almost two thirds of the propbank arguments are
   either a0 or a1. identifying these two roles correctly is therefore the
   most important distinction to make, and because this can be largely
   achieved on the basis of the arguments' syntactic position (see
   [219]table 2), the baseline yields high scores.
   5.4   evaluation

   in this section we describe how we assess the quality of a role
   induction method that assigns labels to units that have been identified
   as likely arguments. we also discuss how we measure whether differences
   in model performance are statistically significant.

   arguments are labeled based on the cluster they have been assigned to,
   which means that in contrast to the supervised setting we cannot verify
   the correctness of these labels directly (e.g., by comparing them to
   the gold standard). instead, we will look at the induced clusters as a
   whole and assess their quality in terms of how well they reflect the
   assumed gold standard. specifically, for each verb, we determine the
   extent to which argument instances in the clusters share the same gold
   standard role (purity) and the extent to which a particular gold
   standard role is assigned to a single cluster (collocation).

   more formally, for each group of verb-specific clusters we measure
   cluster purity as the percentage of instances belonging to the majority
   gold class in their respective cluster. let n denote the total number
   of instances, g[j] the set of instances belonging to the j-th gold
   class, and c[i] the set of instances belonging to the i-th cluster.
   purity can be then written as

   collocation is the inverse of purity (van rijsbergen [220]1974) and
   defined as follows. for each gold role, we determine the cluster with
   the largest number of instances for that role (the role's primary
   cluster) and then compute the percentage of instances that belong to
   the primary cluster for each gold role:

   per-verb scores are aggregated into an overall score by averaging over
   all verbs. we use the micro-average obtained by weighting the scores
   for individual verbs proportionately to the number of instances for
   that verb. finally, we use the harmonic mean of purity and collocation
   as a single measure of id91 quality:

   purity and collocation measure essentially the same data traits as
   precision and recall, which in the context of id91 are, however,
   defined on pairs of instances (manning, raghavan, and sch  tze
   [221]2008), which makes them a bit harder to grasp intuitively. we
   therefore prefer purity and collocation, arguing that these should be
   assessed in combination or together with f1 because they can be traded
   off against each other. purity can be trivially maximized by mapping
   each instance into its own cluster, and collocation can be trivially
   maximized by mapping all instances into a single cluster.

   although it is desirable to report performance with a single score such
   as f1, it is equally important to assess how purity and collocation
   contribute to this score. in particular, if a hypothetical system were
   to be used for automatically annotating data, low collocation would
   result in higher annotation effort and low purity would result in lower
   data quality. therefore high purity is imperative for an effective
   system whereas high collocation contributes to efficient data labeling.
   for assessing our methods we therefore introduce the following
   terminology. if a model attains higher purity than the baseline, we
   will say that it is adequate, because it induced roles that adequately
   represent semantic roles. if a model attains higher f1 than the
   baseline, we will say that it is non-trivial, because it strikes a
   tradeoff between collocation and purity that is non-trivial. our goal
   then is to find models that are both adequate and non-trivial.

   in order to assess whether differences in performance between two
   models are statistically significant, we used a sign test.
   specifically, we obtained a series of score pairs by testing two
   methods on a subsample of the test data. each subsample corresponds to
   a random selection of m = 2,000. we consider the resulting samples to
   be    sufficiently    independent to obtain indicative results from the
   test. as null hypothesis (h[0]) we assume that a model m attains scores
   equal to another model b. under h[0] the id203 that model m
   outperforms model b on a particular test set is . the random variable s
   counting the number of times that score[m] > score[b] in a sample of n
   score pairs is binomially distributed:

   we can therefore use s as our test statistic and reject the null
   hypothesis h[0] if .
   5.5   results

   our results are summarized in [222]tables 3   [223]5, which report
   cluster purity (pu), collocation (co), and their harmonic mean (f1) for
   the baseline and our two multi-layer graph partitioning algorithms. we
   present scores on four data sets that result from the combination of
   automatic parses with automatically identified arguments (auto/auto),
   gold parses with automatic arguments (gold/auto), automatic parses with
   gold arguments (auto/gold), and gold parses with gold arguments
   (gold/gold). we show how performance varies for our methods when
   measuring cluster similarity in the two ways described above: (a) by
   finding for each instance in one cluster the instance in the other
   cluster that is maximally similar or dissimilar and averaging over the
   scores of these alignments (avgmax) and (b) by using cosine similarity
   (see [224]section 4.1). we also report results for the single-layer
   algorithm proposed in lang and lapata ([225]2011b).[226]^5

   5   the results in [227]table 5 differ slightly from those published in
   lang and lapata ([228]2011b). this is due to a small change in the
   preprocessing of the data. for all english experiments reported here,
   we removed arguments with r- and c- role prefixes and replaced numbers
   with a placeholder.
   given a verbal predicate, they construct a single-layer graph whose
   edge weights express instance-wise similarities directly. the graph is
   partitioned into vertex clusters representing semantic roles using a
   variant of chinese whispers, a graph id91 algorithm proposed by
   biemann ([229]2006). the algorithm iteratively assigns cluster labels
   to graph vertices by greedily choosing the most common label among the
   neighbors of the vertex being updated.

   [230]table
   table   3    results for agglomerative partitioning (for avgmax and cosine
   similarity). f1 improvements over the baseline are statistically
   significant in all settings (q < 0.001). boldface highlights the best
   performing system according to purity, collocation, and f1.

   [231]table
   table   4    results for multi-layered label propagation (for avgmax and
   cosine similarity). f1 improvements over the baseline are statistically
   significant in all settings (q < 0.001). boldface highlights the best
   performing system according to purity, collocation, and f1.

   [232]table
   table   5    results for single-layered label propagation using a heuristic
   similarity function. f1 improvements over the baseline are
   statistically significant (q < 0.001) in the auto/gold and gold/gold
   settings. boldface highlights the best performing system according to
   purity, collocation, and f1.

   both agglomerative partitioning and multi-layered label propagation
   algorithms systematically achieve higher f1 scores than the
   baseline   that is, induce non-trivial id91s and more adequate
   semantic roles (by attaining higher purity). for example, on the
   auto/auto data set, the agglomerative algorithm using cosine similarity
   increases f1 by 2.3 points over the baseline and by 7.2 points in terms
   of purity. this increase in purity is achieved by trading off against
   collocation, although in a favorable ratio as indicated by the overall
   higher f1. all improvements over the baseline are statistically
   significant (q < 0.001 according to the test described in [233]section
   5.4). in general, we observe that cosine similarity outperforms avgmax
   similarity. we conjecture that cosine is a more appropriate measure of
   cluster similarity for features where it is beneficial to capture the
   distributional similarity of clusters. the two algorithms perform
   comparably   differences in f1 are not statistically significant (except
   in the gold/auto setting). nevertheless, agglomerative partitioning
   obtains higher purity and f1 than label propagation. the latter trades
   off more purity and in return obtains higher collocation. the
   single-layer method is inferior to the multi-layer algorithms, in
   particular because it is less robust to noise, as demonstrated by the
   markedly worse results on automatic parses. on the auto/auto data set
   the single-layered algorithm is on a par with the baseline and
   marginally outperforms it on the auto/gold and gold/gold
   configurations.

   to help put our results in context, we compare our methods with titov
   and klementiev's ([234]2012a) bayesian id91 models. they report
   results on the conll 2008 data sets with two model variants, a factored
   model that models each verb independently and a coupled model where
   model parameters are shared across verbs. in an attempt to reduce the
   sparsity of the argument fillers, they also present variants of the
   factored and coupled models where the argument heads have been replaced
   by lexical cluster ids id30 from brown et al.'s ([235]1992)
   id91 algorithm on the rcv1 corpus. in [236]table 6 we follow
   titov and klementiev ([237]2012a) and show results on the gold/gold and
   gold/auto settings. as can be seen, both the agglomerative id91
   and label propagation perform comparably to their coupled model, even
   though they do not implement any specific mechanism for sharing
   id91 preferences across verbs. versions of their models that use
   brown word clusters (i.e., factored+br and coupled+br) yield overall
   best results. we expect this type of preprocessing to also increase the
   performance of our models, however we leave this to future work.
   finally, we should point out that titov and klementiev ([238]2012a) do
   not cluster adjunct-like modifier arguments that are already explicitly
   represented in syntax (e.g., tmp, loc, dir). thus, their coupled+mods
   model is most comparable to ours in terms of the id91 objective
   as it treats both core and adjunct arguments and does not make use of
   the brown id91. [239]table 6 shows the performance of
   coupled+mods on the gold/gold setting only because auto/gold results
   are not reported.

   [240]table
   table   6    semantic role induction with graph partitioning and bayesian
   id91.

   we further examined the output of the baseline and our best performing
   model in order to better understand where the performance gains are
   coming from. [241]table 7 shows how the two approaches differ when it
   comes to individual roles. we observe that the agglomerative id91
   algorithm performs better than the baseline on all core roles. there
   are some adjunct roles for which the baseline obtains a higher f1. this
   is not surprising because the parser directly outputs certain labels
   such as loc and tmp which results in high baseline scores for these
   roles. a word of caution is necessary here since core roles are defined
   individually for each verb and need not have a uniform corpus-wide
   interpretation. thus, conflating per-role scores across verbs is only
   meaningful to the extent that these labels actually signify the same
   role (which is mostly true for a0 and a1). furthermore, the purity
   scores we provide in this context are averages over the clusters for
   which the specified role is the majority role.

   [242]table
   table   7    results for individual roles on the auto/auto data set;
   comparison between the baseline and the agglomerative id91
   algorithm with the cosine similarity function. boldface highlights the
   best performing system according to purity, collocation, and f1.

   we further investigated the degree to which the baseline and the
   agglomerative id91 algorithm agree in their role assignments. the
   overall mean overlap was 46.03%. [243]figure 3a shows the percentage of
   verbs for which the baseline and our algorithm have no, some, or
   complete overlap. we discretized overlap into 10 bins of equal size
   ranging from 0 to 100. we observe that the role assignments produced by
   the two methods have nothing in common for approximately 13.6% verbs,
   whereas assignments are identical for 18.1% verbs. aside from these two
   bins (see 0 and 100 in [244]figure 3), a large number of verbs seems to
   exhibit overlap in the range of 40   60%. [245]figure 3b shows how the
   overlap in the cluster assignments varies with verb frequency. perhaps
   unsurprisingly, we can see that overlap is higher for least frequent
   and therefore less ambiguous verbs. in general, although the two
   methods have some degree of overlap, agglomerative id91 does
   indeed manage to change and improve the original role assignments of
   the baseline.
   [246]figure
   figure   3    role assignment overlap between the baseline and
   agglomerative id91 on the auto/auto data set. [247]figure 3a
   shows the percentage of verbs with no overlap (0%), 10% overlap, 20%
   overlap, 30% overlap, and so on. [248]figure 3b shows how role overlap
   varies with verb frequency. results are reported on the auto/auto data
   set.

   an interesting question concerns precisely the type of changes affected
   by the agglomerative id91 algorithm over the assignments of the
   baseline. to be able to characterize these changes we first examined
   the consistency of the role assignments created by the two algorithms.
   specifically, we would expect a verb-argument pair to be mostly
   assigned to the same cluster (i.e., an argument to bear the same role
   label for the same verb). of course this is not a hard constraint as
   arguments and predicates can be ambiguous and their roles may vary in
   specific syntactic configurations and contexts. to give an idea of an
   upper bound, in our gold standard, an argument instance of the same
   verb bears on average 2.23 distinct roles. for comparison, the baseline
   creates (on average) 2.9 role clusters for an argument, whereas
   agglomerative id91 yields more consistent assignments, with an
   average of 2.34 role clusters per argument.

   we further grouped the verbs in our data set into different bins
   according to their polysemy and allowable argument realizations.
   specifically, we followed levin's ([249]1993) taxonomy and grouped
   verbs according to the number of semantic classes they inhabit (e.g.,
   one, two, and so on). we also binned verbs according to the number of
   alternations they exhibit. to give an example, the verb donate is a
   member of the contribute class and participates in the
   causative/inchoative and dative alternations, whereas the verb shower
   is a member of four classes (i.e., spray/load, pelt, dress, and
   weather) and participates in the understood reflexive object and
   spray/load alternations. [250]figures 4a,[251]b show the overlap in
   role assignments between the baseline and agglomerative id91 and
   how it varies according to verb class ambiguity and argument structure;
   figures [252]4c,[253]d illustrate the same for role assignments and
   their consistency. as can be seen, there is less overlap between the
   two methods when the verbs in question are more polysemous
   ([254]figures 4a) or exhibit more variation in their argument structure
   ([255]figure 4b). as far as consistency in role assignments is
   concerned, agglomerative id91 appears overall more consistent
   than the baseline. as expected, the mean role assignment is slightly
   higher for polysemous verbs because differences in meaning manifest
   themselves in different argument realizations.
   [256]figure
   figure   4    comparison between the baseline and the agglomerative
   id91 algorithm in terms of role assignment overlap (a and b) and
   consistency (c and d). verbs are grouped according to polysemy (a and
   c) and number of alternations (b and d). all results are reported on
   the auto/auto data set.

   [257]figure 5 shows how purity, collocation, and f1 vary across
   alternations and verb classes. perhaps unsurprisingly, performance is
   generally better for least ambiguous verbs exhibiting a small number of
   alternations. in general, agglomerative id91 achieves higher
   purity across the board whereas the baseline achieves higher
   collocation. although agglomerative id91 achieves a consistently
   higher f1 over the baseline, the performance of the two algorithms
   converges for the most polysemous verbs (i.e., those inhabiting more
   than six semantic classes; see [258]figure 5f). interestingly, also
   note that f1 is comparable for verbs with less varied argument
   structure (i.e., verbs inhabiting one alternation; see [259]figure 5c).
   for such verbs the performance gap between the baseline and the
   agglomerative algorithm is narrower both in terms of purity and
   collocation. overall, we observe that agglomerative id91 is able
   to change some of the role assignments of the baseline for verbs
   exhibiting a good degree of alternations and polysemy.
   [260]figure
   figure   5    comparison between the baseline and the agglomerative
   id91 algorithm across alternations (a   c) and verb classes (d   f)
   using purity, collocation, and f1. all results are reported on the
   auto/auto data set.

   [261]table 8 reports results for 12 individual verbs for the best
   performing method (i.e., agglomerative partitioning using cosine
   similarity) on the auto/auto data set. these verbs were selected so as
   to exhibit varied occurrence frequencies and alternation patterns. as
   can be seen, the macroscopic result   higher f1 due to significantly
   higher purity   seems to consistently hold also across verbs. an
   important exception is the verb say, for which the baseline attains
   high scores due to little variation in its syntactic realization within
   the corpus. example output is given in [262]table 9, which shows the
   five largest clusters produced by the baseline and agglomerative
   partitioning for the verb increase. for each cluster we list the 10
   most frequent argument head lemmas. in this case, our method managed to
   induce an a0 cluster that is not present in the top five clusters of
   the baseline, although the cluster also incorrectly contains some a1
   arguments that stem from a false merge.

   [263]table
   table   8    results for individual verbs on the auto/auto data set;
   comparison between the baseline and our agglomerative id91
   algorithm with the cosine similarity function. boldface highlights the
   best performing system according to purity, collocation, and f1.

   [264]table
   table   9    five largest clusters created by the baseline and
   agglomerative partitioning for the verb increase. symbols $ and cd are
   used as placeholders for monetary units and cardinal numbers,
   respectively.

   6.   role induction experiments on german
   section:
   [choose___________________________]
   [265]previous section [266]next section

   the applicability of our method to arbitrary languages is important
   from a theoretical and practical perspective. on the one hand,
   linguistic theory calls for models which are universal and generalize
   across languages. this is especially true for models operating on the
   (frame-) semantic level, which is a generalization over surface
   structure and should therefore be less language specific (boas
   [267]2005). on the other hand, a language-independent model can be
   applied to arbitrary languages, genres, and domains and is thus of
   greater practical benefit. because our approach is based on the
   language-independent principles discussed in [268]section 1, we argue
   that it can easily generalize to other languages. to test this claim,
   we further applied our methods to german data.

   although on a high-level, german clauses do not differ drastically from
   english ones with respect to their frame-semantic make-up, there are
   differences in terms of how frame elements are mapped onto specific
   positions on the linear surface structure of a sentence, beyond any
   variations observed among english verbs. in general, german places
   fewer constraints on word order (more precisely phrase order) and
   instead relies on richer morphology to help disambiguate the
   grammatical functions of linguistic units. in particular, verbal
   nominal arguments are marked with a grammatical case[269]^6

   6   german has (partially ambiguous) markers for nominative, accusative,
   dative, and genitive.
   that directly indicates their grammatical function. although in main
   declarative clauses the inflected part of the verb has to occur in
   second position, german is commonly considered a verb-final language.
   this is because the verb often takes the final position in subordinate
   clauses, as do infinitive verbs (brigitta [270]1996).
   6.1   data

   we conducted our experiments on the salsa corpus (burchardt et al.
   [271]2006), a lexical resource for german, which, like framenet for
   english, associates predicates with frames. salsa is built as an extra
   annotation layer over the tiger corpus (brants et al. [272]2002), a
   treebank for german consisting of approximately 40,000 sentences
   (700,000 tokens) of newspaper text taken from the frankfurter
   rundschau, although to date not all predicate-argument structures have
   been annotated. the frame and role inventory of salsa was taken from
   framenet, but has been extended and adapted where necessary due to lack
   of coverage and cross-lingual divergences.

   the syntactic structure of a sentence is represented through a
   constituent tree whose terminal nodes are tokens and non-terminal nodes
   are phrases (see [273]figure 6). in addition to labeling each node with
   a constituent type such as sentence, noun phrase, and verb phrase, the
   edges between a parent and a child node are labeled according to the
   function of the child within the parent constituent, for example,
   accusative object, noun kernel, or head. edges can cross, allowing
   local and non-local dependencies to be encoded in a uniform way and
   eliminating the need for traces. this approach has significant
   advantages for non-configurational languages such as german, which
   exhibit a rich inventory of discontinuous constituents and considerable
   freedom with respect to word order (smith [274]2003). compared with the
   id32 (marcus, santorini, and marcinkiewicz [275]1993), tree
   structures are relatively flat. for example, the tree does not encode
   whether a constituent is a verbal argument or adjunct; this information
   is encoded through the edge labels instead.
   [276]figure
   figure   6    a sample parse tree for the sentence pr  sident jelzin
   verliert die mach ans k  chenkabinett und wird die wahlen kaum gewinnen
   k  nnen [translated in english as president jelzin loses power to the
   kitchen cabinet and will hardly be able to win the elections]. the
   parse tree contains phrase labels np (noun phrase), pp (prepositional
   phrase), vp (verb phrase), s (sentence), and cs (coordinated sentence).
   the dependency labels are nk (noun kernel), sb (subject), ao (object
   accusative), hd (head), mo (modifier), ac (adpositional case marker),
   cj (conjunct), and oc (clausal object).

   the frame annotations contained in salsa do not cover all of the
   predicate-argument structures of the underlying tiger corpus. only a
   subset of around 550 predicates with approximately 18,000 occurrences
   in the corpus have been annotated. moreover, only core roles are
   annotated, whereas adjunct roles are not, resulting in a smaller number
   of arguments per predicate (1.96 on average) compared with the conll
   2008 data set (2.57 on average) described in section 5.1. because our
   method is designed to induce verb-specific frames, we converted the
   salsa frames into propbank-like frames by splitting each frame into
   several verb-specific frames and accordingly mapping frame roles onto
   verb-specific roles. our data set is comparable to the german data set
   released as part of the conll 2009 shared task (haji   et al.
   [277]2009), which was also derived from the salsa corpus. however, we
   did not convert the original constituent-based salsa representation
   into dependencies, as we wanted to assess whether our methods are also
   compatible with phrase structure trees.
   6.2   experimental set-up

   although we follow the same experimental set-up as described in
   [278]section 5 for english, there are some deviations due to
   differences in the data sets utilized for the two languages. firstly,
   in contrast to the conll 2008 data set, the salsa data set (and the
   underlying tiger corpus) does not supply automatic parse trees and we
   therefore conducted our experiments on gold parses only. moreover,
   because adjunct arguments are not annotated in salsa, and because
   argument identification is not the central issue of this work, we chose
   to also consider only the gold argument identification. thus, all our
   experiments for german were carried out on the gold/gold data set.

   a substantial linguistic difference between the german and english data
   sets is the sparsity of the argument head lemmas, which is
   significantly higher for german than for english: in the conll 2008
   data set, the average number of distinct head lemmas per verb is only
   3.69, whereas in the salsa data set it is 20.12. this is partly due to
   the fact that the wall street journal text underlying the english data
   is topically more focused than the rundschau newspaper text, which
   covers a broader range of news beyond economics and politics. moreover,
   noun compounding is more commonly used in german than in english
   (corston-oliver and gamon [279]2004), which leads to higher lexical
   sparsity.

   data sparsity affects our method, which crucially relies on lexical
   similarity for determining the role-equivalence of clusters. therefore,
   we reduced the number of syntactic cues used for cluster initialization
   in order to avoid creating too many small clusters for which
   similarities cannot be reliably computed. specifically, only the
   syntactic position and function word served as cues to initialize our
   clusters. note that, as in english, the relatively small number of
   syntactic cues that determine the syntactic position within a linking
   is a consequence of the size of our evaluation data set (which is
   rather small) and not an inherent limitation of our method. on larger
   data sets, more syntactic cues could and should be incorporated in
   order to increase performance.

   in our experiments we compared the baseline introduced in [280]section
   5.3 against agglomerative partitioning and the label propagation
   algorithm using both cosine- and avgmax-similarity. the parameters   ,
     , and   , which determine the thresholds used in defining overall
   similarity scores, were set and updated identically as for english
   (i.e., these parameters can be considered language-independent).
   6.3   results

   [281]table 10 reports results for the baseline and our role induction
   methods, namely, agglomerative id91 and multi-layered label
   propagation (using the avgmax and cosine similarity functions) on the
   salsa gold/gold data set. for comparison, we also include results on
   the english conll-2008 gold/gold data set. as can be seen, the baseline
   obtains a similar f1 for german and english, although the contributions
   of purity and collocation are different for the two languages. in
   english, purity is noticeably higher than in german, whereas
   collocation is higher in german. this is not surprising when taking
   into account the distribution of syntactic relations governing an
   argument. a few frequent relation labels absorb most of the id203
   mass in german (see [282]figure 7b), whereas the mass is distributed
   more evenly among the labels in english ([283]figure 7a), thus leading
   to higher purity but lower collocation.

   [284]table
   table   10    results of agglomerative partitioning and label propagation
   for cosine and avgmax similarity on german. for comparison purposes
   results for english on the gold/gold data set are also tabulated. all
   improvements over the baseline are statistically significant at
   significance level q < 0.001.

   [285]figure
   figure   7    distribution of syntactic relations governing an argument in
   english and german data sets. only the most frequent relations are
   shown (a key for the english relations is given in [286]table 2; in
   german the relations are sb (subject), oa (object accusative), cj
   (conjunct), da (dative), cd (coordinator), mo (modifier), re
   (subordinate clause), rs (reported speech), oc (object clausal), op
   (object prepositional), nk (noun kernel), and cvc (collocational verb
   construction).

   in german, our role induction algorithms improve over the baseline in
   terms of f1. all four methods perform comparably and manage to strike a
   tradeoff between collocation and purity that is non-trivial and
   represents semantic roles adequately. compared with english, the
   difference between the baseline and our algorithms is narrower. this is
   because we use fewer syntactic cues for initialization in german, due
   to the increased data sparsity discussed in the previous section. this
   also explains why there is little variation in the collocation and
   purity results across methods. however, qualitatively the tradeoff
   between purity and collocation is the same as for english (i.e., purity
   is increased at the cost of collocation).

   [287]tables 11 and [288]12 show per-verb and per-role results,
   respectively, for agglomerative id91 using cosine similarity. we
   report per-verb scores for a selection of 10 verbs (see [289]table
   12a), which in some cases are translations of the verbs used for
   english. with respect to per-role scores, we make use of the fact that
   roles have a common meaning across predicates (like a0 and a1 in
   propbank), and report scores for a selection of 15 different roles
   ([290]table 12b) with varied occurrence frequencies. per-verb results
   confirm that data sparsity affects performance in german. as can be
   seen, agglomerative id91 outperforms the baseline on
   high-frequency verbs that are less affected by sparsity, although this
   is not always the case on lower-frequency verbs. analogously, the
   method tends to perform better on high-frequency roles, whereas there
   is no clear trend on lower-frequency roles. in contrast to english, for
   more than half of the verbs the method manages to outperform the
   baseline in terms of both purity and collocation, which is consistent
   with our macroscopic result, where the tradeoff between purity and
   collocation is not as strong as for english.

   [291]table
   table   11    results for individual verbs on the gold/gold salsa data set;
   comparison between the baseline and the agglomerative id91
   algorithm with the cosine similarity function.

   [292]table
   table   12    results for individual roles on gold/gold salsa data set;
   comparison between the baseline and the agglomerative id91
   algorithm with the cosine similarity function.

   the experiments show that our methods can be successfully applied to
   languages other than english, thereby supporting the claim that they
   are based on a set of language-independent assumptions and principles.
   despite substantial differences between german and english grammar,
   both generally and in terms of the specific syntactic representation
   that was used, our methods increased f1 over the baseline for both
   languages and resulted in a similar tradeoff between purity and
   collocation. improvements were observed in spite of pronounced data
   sparsity in the case of german. recall that we had to reduce the number
   of syntactic initialization cues in order to be able to obtain results
   on the relatively small amount of gold-standard data. we would also
   like to note that porting our system to german did not require any
   additional feature engineering or algorithmic changes.
   7.   conclusions
   section:
   [choose________________________]
   [293]previous section [294]next section

   in this article we described an unsupervised method for semantic role
   induction in which argument-instance graphs are partitioned into
   clusters representing semantic roles. a major hypothesis underlying our
   work has been that semantic roles can be induced without human
   supervision from a corpus of syntactically parsed sentences based on
   three linguistic principles : (1) arguments in the same syntactic
   position (within a specific linking) bear the same semantic role, (2)
   arguments within a clause bear a unique role, and (3) clusters
   representing the same semantic role should be more or less lexically
   and distributionally equivalent. based on these principles we have
   formulated a similarity-driven model and introduced a multi-layer graph
   partitioning approach that represents similarity between clusters on
   multiple feature layers, whose connectivity can be analyzed separately
   and then combined into an overall cluster-similarity score.

   our work has challenged the established view that supervised learning
   is the method of choice for the id14 task. although
   the proposed unsupervised models do yet achieve results comparable to
   their supervised counterparts, we have been able to show that they
   consistently outperform the syntactic baseline across several data sets
   that combine automatic and gold parses, with gold and automatic
   argument identification in english and german. our methods obtain f1
   scores that are systematically above the baseline and the purity of the
   induced clusters is considerably higher, although in most cases this
   increase in purity is achieved by decreasing collocation. in sum, these
   results provide strong empirical evidence towards the soundness of our
   method and the principles they are based on.

   in terms of modeling, we have contributed to the body of work on
   similarity-driven models by demonstrating their suitability for this
   problem, their effectiveness, and their computational efficiency. the
   models are based on judgments regarding the similarity of argument
   instances with respect to their semantic roles. we showed that these
   judgments are comparatively simple to formulate and incorporate into a
   graph representation of the data. we have introduced the idea of
   separating different similarity features into different graph layers,
   which resolves the problem faced by many similarity-based approaches of
   having to heuristically define an instance-wise similarity function and
   brings the advantage that cluster similarities can be computed in a
   more principled way. beyond id14, we hope that the
   multi-layered graph representation described here might be of relevance
   to other unsupervised problems such part-of-speech tagging or
   coreference resolution. the approach is general and amenable to other
   graph partitioning algorithms besides agglomeration and label
   propagation.

   there are two forms of data sparsity that arise in the context of our
   work, namely, the lexical sparsity of argument head lemmas and the
   sparsity of specific combinations of linking and syntactic position. as
   our methods are unsupervised, the conceptually simple solution to
   sparsity is to train on larger data sets. because, with some
   modifications, our graph partitioning approaches could be scaled to
   larger data sets (in terms of orders of magnitude), this is an obvious
   next step and would address both instances of data sparsity. firstly,
   it would allow us to incorporate a richer set of syntactic features for
   initialization and would therefore necessarily result in initial
   id91s of higher purity. secondly, the larger size of clusters
   would result in more reliable similarity scores. augmenting the data
   set would therefore almost surely increase the quality of induced
   id91s; however, we leave this to future work.

   another interesting future direction would be to eliminate the model's
   reliance on a syntactic parser that prohibits its application to
   languages for which parsing resources are not available. it would
   therefore be worthwhile, albeit challenging, to build models that
   operate on more readily available forms of syntactic analysis or even
   raw text. for example, existing work (abend and rappoport [295]2010b;
   abend, reichart, and rappoport [296]2009) attempts to identify
   arguments and distinguish them into core and adjunct ones through
   unsupervised part of speech and grammar induction. as much as making
   our model more unsupervised it would also be interesting to see whether
   some form of weak supervision might help induce higher-quality semantic
   roles without incurring a major labeling effort. the ideas conveyed in
   this article and the proposed methods extend naturally to this setting:
   introducing labels on some of the graph vertices would translate into a
   semi-supervised graph-based learning task, akin to zhu, ghahramani, and
   lafferty ([297]2003).
   appendix a. argument identification rules
   section:
   [choose_________________________]
   [298]previous section [299]next section

   this appendix specifies the full set of relations used by rules (2) and
   (4) of the argument identification rules given for english in
   [300]section 5.2, [301]table 1. the symbols     and     denote the
   direction of the dependency relation (upward and downward,
   respectively). the dependency relations are explained in surdeanu et
   al. ([302]2008), in their [303]table 4.

   the relations in rule (2) from [304]table 1 are im      , prt   , coord      ,
   p      , obj   , pmod   , adv   , sub      , root   , tmp   , sbj   , oprd   .

   the relations in rule (4) are adv      , amod      , appo      , bnf      -, conj      ,
   coord      , dir      , dtv      -, ext      , extr      , hmod      , iobj      , lgs      , loc      ,
   mnr      , nmod      , obj      , oprd      , posthon      , prd      , prn      , prp      , prt      ,
   put      , sbj      , sub      , suffix       tmp      , voc      .
   acknowledgments
   section:
   [choose________________________]
   [305]previous section [306]next section

   we are grateful to the anonymous referees, whose feedback helped to
   substantially improve this article. we also thank the members of the
   probabilistic models reading group at the university of edinburgh for
   helpful discussions and comments. we acknowledge the support of epsrc
   (grant ep/k017845/1).
   references
   section:
   [choose________________________]
   [307]previous section [308]next section
   abend, o. and a. rappoport. 2010a. fully unsupervised core-adjunct
   argument classification. in proceedings of the 48th annual meeting of
   the association for computational linguistics, pages 226   236, uppsala.
   [309]google scholar
   abend, o. and a. rappoport. 2010b. fully unsupervised core-adjunct
   argument classification. in proceedings of the annual meeting of the
   association for computational linguistics, pages 226   236, uppsala.
   [310]google scholar
   abend, o., r. reichart, and a. rappoport. 2009. unsupervised argument
   identification for id14. in proceedings of the annual
   meeting of the association for computational linguistics, pages 28   36,
   suntec. [311]crossref, [312]google scholar
   abney, s. 2007. semisupervised learning for computational linguistics.
   chapman & hall/crc. [313]crossref, [314]google scholar
   berg-kirkpatrick, t., a. bouchard-c  t  , j. denero, and d. klein. 2010.
   painless unsupervised learning with features. in proceedings of the
   conference of the north american chapter of the association for
   computational linguistics, pages 582   590, los angeles, ca. [315]google
   scholar
   biemann, c. 2006. chinese whispers: an efficient graph id91
   algorithm and its application to natural language processing problems.
   in proceedings of textgraphs: the first workshop on graph based methods
   for natural language processing, pages 73   80, new york, ny.
   [316]crossref, [317]google scholar
   boas, h. 2005. semantic frames as interlingual representations for
   multilingual lexical databases. international journal of id69,
   18(4):445   478. [318]crossref, [319]google scholar
   brants, s., s. dipper, s. hansen, w. lezius, and g. smith. 2002. the
   tiger treebank. in proceedings of the 1st workshop on treebanks and
   linguistic theories, pages 24   41, sozopol. [320]google scholar
   brigitta, h. 1996. deutsch ist eine v/2-sprache mit verbendstellung und
   freier wortfolge. in e. lang and g. zifonun, editors, deutsch   
   typologisch, pages 121   141. walter de gruyter. [321]google scholar
   brown, p. f., v. j. della pietra, p. v. desouza, j. c. lai, and r. l.
   mercer. 1992. class-based id165 models of natural language.
   computational linguistics, 18(4):283   298. [322]google scholar
   burchardt, a., k. erk, a. frank, a. kowalski, s. pad  , and m. pinkal.
   2006. the salsa corpus: a german corpus resource for lexical semantics.
   in proceedings of the international conference on language resources
   and evaluation, pages 969   974, genoa. [323]google scholar
   corston-oliver, s. and m. gamon. 2004. normalizing german and english
   inflectional morphology to improve statistical word alignment. in
   robert frederking and kathryn taylor, editors, machine translation:
   from real users to research, volume 3265 of lecture notes in computer
   science. springer, berlin heidelberg, pages 48   57.
   [324]crossref, [325]google scholar
   dowty, d. 1991. thematic proto roles and argument selection. language,
   67(3):547   619. [326]crossref, [327]google scholar
   f  rstenau, h. and m. lapata. 2009. graph alignment for semi-supervised
   id14. in proceedings of the conference on empirical
   methods in natural language processing, pages 11   20, singapore.
   [328]crossref, [329]google scholar
   gamallo, p., a. agustini, and g. lopes. 2005. id91 syntactic
   positions with similar semantic requirements. computational
   linguistics, 31(1):107   146. [330]link, [331]google scholar
   garg, n. and j. henderson. 2012. unsupervised semantic role induction
   with global role ordering. in proceedings of the 50th annual meeting of
   the association for computational linguistics (volume 2: short papers),
   pages 145   149, jeju island. [332]google scholar
   gildea, d. and d. jurafsky. 2002. automatic labeling of semantic roles.
   computational linguistics, 28(3):245   288. [333]link, [334]google
   scholar
   gordon, a. and r. swanson. 2007. generalizing semantic role annotations
   across syntactically similar verbs. in proceedings of the annual
   meeting of the association for computational linguistics, pages
   192   199, prague. [335]google scholar
   gordon, d. and m. desjardins. 1995. evaluation and selection of biases
   in machine learning. machine learning, 20:5   22. [336]google scholar
   grenager, t. and c. manning. 2006. unsupervised discovery of a
   statistical verb lexicon. in proceedings of the 2006 conference on
   empirical methods in natural language processing, pages 1   8, sydney.
   [337]crossref, [338]google scholar
   haji  , j., m. ciaramita, r. johansson, d. kawahara, m. a. mart  , l.
   m  rquez, a. meyers, j. nivre, s. pad  , j.   t  p  nek, p. stra    k, m.
   surdeanu, n. xue, and y. zhang. 2009. the conll 2009 shared task:
   syntactic and semantic dependencies in multiple languages. in
   proceedings of the thirteenth conference on computational natural
   language learning (conll 2009): shared task, pages 1   18, boulder, co.
   [339]crossref, [340]google scholar
   jain, a., m. murty, and p. flynn. 1999. data id91: a review. acm
   computing surveys, 31(3):264   323. [341]crossref, [342]google scholar
   kipper, k., h. t. dang, and m. palmer. 2000. class-based construction
   of a verb lexicon. in proceedings of the aaai conference on artificial
   intelligence, pages 691   696, austin, tx. [343]google scholar
   koomen, p., v. punyakanok, d. roth, and w. yih. 2005. generalized
   id136 with multiple id14 systems. in proceedings
   of the conference on computational natural language learning, pages
   181   184, ann arbor, mi. [344]crossref, [345]google scholar
   lang, j. and m. lapata. 2010. unsupervised induction of semantic roles.
   in proceedings of the north american chapter of the association for
   computational linguistics conference, pages 939   947, los angeles, ca.
   [346]google scholar
   lang, j. and m. lapata. 2011a. unsupervised induction of semantic roles
   via split-merge id91. in proceedings of the 49th annual meeting
   of the association for computational linguistics: human language
   technologies, pages 1,117   1,126, portland, or. [347]google scholar
   lang, j. and m. lapata. 2011b. unsupervised semantic role induction
   with graph partitioning. in proceedings of the conference on empirical
   methods in natural language processing, pages 1,320   1,331, edinburgh.
   [348]google scholar
   levin, b. and m. rappaport. 2005. argument realization. cambridge
   university press. [349]crossref, [350]google scholar
   levin, beth. 1993. english verb classes and alternations: a preliminary
   investigation. university of chicago press, chicago. [351]google
   scholar
   lin, d. and p. pantel. 2001. discovery of id136 rules for
   question-answering. natural langugae engineering, 7:343   360.
   [352]google scholar
   manning, c., p. raghavan, and h. sch  tze. 2008. introduction to
   information retrieval. cambridge university press.
   [353]crossref, [354]google scholar
   marcus, m., b. santorini, and m. marcinkiewicz. 1993. building a large
   annotated corpus of english: the id32. computational
   linguistics, 19(2):313   330. [355]google scholar
   m  rquez, l., x. carras, k. litkowski, and s. stevenson. 2008. semantic
   role labeling: an introduction to the special issue. computational
   linguistics, 34(2):145   159. [356]link, [357]google scholar
   melli, g., y. wang, y. liu, m. m. kashani, z. shi, b. gu, a. sarkar,
   and f. popowich. 2005. description of squash, the sfu question
   answering summary handler for the duc-2005 summarization task. in
   proceedings of the human language technology conference and the
   conference on empirical methods in natural language processing document
   understanding workshop, vancouver. [358]google scholar
   merlo, p. and s. stevenson. 2001. automatic verb classification based
   on statistical distributions of argument structure. computational
   linguistics, 27:373   408. [359]link, [360]google scholar
   munkres, j. 1957. algorithms for the assignment and transportation
   problems. journal of the society for industrial and applied
   mathematics, 5(1):32   38. [361]crossref, [362]google scholar
   nivre, j., j. hall, j. nilsson, g. eryigit, a. chanev, s. k  bler, s.
   marinov, and e. marsi. 2007. malt-parser: a language-independent system
   for data-driven id33. natural language engineering,
   13(2):95   135. [363]google scholar
   pad  , s. and m. lapata. 2009. cross-lingual annotation projection of
   semantic roles. journal of artificial intelligence research,
   36:307   340. [364]google scholar
   palmer, m., d. gildea, and p. kingsbury. 2005. the proposition bank: an
   annotated corpus of semantic roles. computational linguistics,
   31(1):71   106. [365]link, [366]google scholar
   poon, h. and p. domingos. 2009. unsupervised id29. in
   proceedings of the 2009 conference on empirical methods in natural
   language processing, pages 1   10, singapore. [367]crossref, [368]google
   scholar
   pradhan, s., w. ward, and j. martin. 2008. towards robust semantic role
   labeling. computational linguistics, 34(2):289   310.
   [369]link, [370]google scholar
   ruppenhofer, j., m. ellsworth, m. petruck, c. johnson, and j.
   scheffczyk. 2006. framenet ii: extended theory and practice, version
   1.3. technical report, international computer science institute,
   berkeley, ca. [371]google scholar
   schaeffer, s. 2007. graph id91. computer science review,
   1(1):27   64. [372]crossref, [373]google scholar
   shen, d. and m. lapata. 2007. using semantic roles to improve question
   answering. in proceedings of the 2007 joint conference on empirical
   methods in natural language processing and computational natural
   language learning (emnlp-conll), pages 12   21, prague. [374]google
   scholar
   smith, g. 2003. a brief introduction to the tiger treebank, version 1.
   technical report, university of potsdam. [375]google scholar
   surdeanu, m., s. harabagiu, j. williams, and p. aarseth. 2003. using
   predicate-argument structures for information extraction. in
   proceedings of the annual meeting of the association for computational
   linguistics, pages 8   15, sapporo. [376]crossref, [377]google scholar
   surdeanu, m., r. johansson, a. meyers, and l. m  rquez. 2008. the
   conll-2008 shared task on joint parsing of syntactic and semantic
   dependencies. in proceedings of the conference on natural language
   learning, pages 159   177, manchester. [378]crossref, [379]google scholar
   swier, r. and s. stevenson. 2004. unsupervised semantic role labelling.
   in proceedings of the conference on empirical methods in natural
   language processing, pages 95   102, barcelona. [380]google scholar
   titov, i. and a. klementiev. 2011. a bayesian model for unsupervised
   id29. in proceedings of the 49th annual meeting of the
   association for computational linguistics: human language technologies,
   pages 1,445   1,455, portland, or. [381]google scholar
   titov, i. and a. klementiev. 2012a. a bayesian approach to unsupervised
   semantic role induction. in proceedings of the 13th conference of the
   european chapter of the association for computational linguistics,
   pages 12   22, avignon. [382]google scholar
   titov, i. and a. klementiev. 2012b. crosslingual induction of semantic
   roles. in proceedings of the 50th annual meeting of the association for
   computational linguistics (volume 1: long papers), pages 647   656, jeju
   island. [383]google scholar
   van rijsbergen, c. 1974. foundation of evaluation. journal of
   documentation, 30(4):265   374. [384]crossref, [385]google scholar
   wu, d. and p. fung. 2009. semantic roles for smt: a hybrid two-pass
   model. in proceedings of human language technologies: the annual
   conference of the north american chapter of the association for
   computational linguistics, companion volume: short papers, pages 13   16,
   boulder, co. [386]crossref, [387]google scholar
   zhu, x., z. ghahramani, and j. lafferty. 2003. semi-supervised learning
   using gaussian fields and id94. in proceedings of the
   international conference on machine learning, pages 912   919,
   washington, dc. [388]google scholar
   joel lang*
   university of geneva
   mirella lapata**
   university of edinburgh

   *department of computer science, university of geneva, 7 route de
   drize, 1227 caid8, switzerland, e-mail: [389][email protected].

   **institute for language, cognition and computation, school of
   informatics, university of edinburgh, 10 crichton street, eh8 9ab,
   e-mail: [390][email protected].
   [391]https://doi.org/10.1162/coli_a_00195
     * [392]abstract
     * [393]full text
     * [394]authors

abstract

   section:
   [choose________________________]
   [395]next section

   as in many natural language processing tasks, data-driven models based
   on supervised learning have become the method of choice for semantic
   role labeling. these models are guaranteed to perform well when given
   sufficient amount of labeled training data. producing this data is
   costly and time-consuming, however, thus raising the question of
   whether unsupervised methods offer a viable alternative. the working
   hypothesis of this article is that semantic roles can be induced
   without human supervision from a corpus of syntactically parsed
   sentences based on three linguistic principles: (1) arguments in the
   same syntactic position (within a specific linking) bear the same
   semantic role, (2) arguments within a clause bear a unique role, and
   (3) clusters representing the same semantic role should be more or less
   lexically and distributionally equivalent. we present a method that
   implements these principles and formalizes the task as a graph
   partitioning problem, whereby argument instances of a verb are
   represented as vertices in a graph whose edges express similarities
   between these instances. the graph consists of multiple edge layers,
   each one capturing a different aspect of argument-instance similarity,
   and we develop extensions of standard id91 algorithms for
   partitioning such multi-layer graphs. experiments for english and
   german demonstrate that our approach is able to induce semantic role
   clusters that are consistently better than a strong baseline and are
   competitive with the state of the art.
      2014 association for computational linguistics
   1.   introduction
   section:
   [choose________________________]
   [396]previous section [397]next section

   recent years have seen increased interest in the shallow semantic
   analysis of natural language text. the term is often used to describe
   the automatic identification and labeling of the semantic roles
   conveyed by sentential constituents (gildea and jurafsky [398]2002).
   semantic roles describe the relations that hold between a predicate and
   its arguments (e.g.,    who    did    what    to    whom   ,    when   ,    where   , and
      how   ) abstracting over surface syntactic configurations. this type of
   semantic information is shallow but relatively straightforward to infer
   automatically and useful for the development of broad-coverage,
   domain-independent language understanding systems. indeed, the analysis
   produced by existing semantic role labelers has been shown to benefit a
   wide spectrum of applications ranging from information extraction
   (surdeanu et al. [399]2003) and id53 (shen and lapata
   [400]2007), to machine translation (wu and fung [401]2009) and
   summarization (melli et al. [402]2005).

   in the example sentences below, window occupies different syntactic
   positions   it is the object of broke in sentences (1a,b), and the
   subject in (1c). in all instances, it bears the same semantic role,
   that is, the patient or physical object affected by the breaking event.
   analogously, ball is the instrument of break both when realized as a
   prepositional phrase in (1a) and as a subject in (1b).

   also notice that all three instances of break in example (1) have
   apparently similar surface syntax with a subject and a noun directly
   following the predicate. however, in sentence (1a) the subject of break
   expresses the agent role, in (1b) it expresses the instrument role, and
   in (1c) the patient role.

   the examples illustrate the fact that predicates can license several
   alternate mappings or linkings between their semantic roles and their
   syntactic realization. pairs of linkings allowed by a single predicate
   are often called diathesis alternations (levin [403]1993). sentence
   pair (1a,b) is an example of the instrument subject alternation, and
   pair (1b,c) illustrates the causative alternation. resolving the
   mapping between the syntactic dependents of a predicate (e.g., subject,
   object) and the semantic roles that they each express is one of the
   major challenges faced by semantic role labelers.

   the semantic roles in the examples are labeled in the style of propbank
   (palmer, gildea, and kingsbury [404]2005), a broad-coverage
   human-annotated corpus of semantic roles and their syntactic
   realizations. under the propbank annotation framework each predicate is
   associated with a set of core roles (named a0, a1, a2, and so on) whose
   interpretations are specific to that predicate[405]^1

   1   more precisely, a0 and a1 have a common interpretation across
   predicates as proto-agent and proto-patient in the sense of dowty
   ([406]1991).
   and a set of adjunct roles such as location or time whose
   interpretation is common across predicates (e.g., last night in
   sentence (1c)). the availability of propbank and related resources
   (e.g., framenet; ruppenhofer et al. [407]2006) has sparked the
   development of a variety id14 systems, most of which
   conceptualize the task as a supervised learning problem and rely on
   role-annotated data for model training. most of these systems implement
   a two-stage architecture consisting of argument identification
   (determining the arguments of the verbal predicate) and argument
   classification (labeling these arguments with semantic roles). current
   approaches deliver reasonably good performance   a system will recall
   around 81% of the arguments correctly and 95% of those will be assigned
   a correct semantic role (see m  rquez et al. [[408]2008] for details),
   although only on languages and domains for which large amounts of
   role-annotated training data are available.

   unfortunately, the reliance on labeled data, which is both difficult
   and expensive to produce, presents a major obstacle to the widespread
   application of id14 across different languages and
   text genres. although corpora with semantic role annotations exist
   nowadays in other languages (e.g., german, spanish, catalan, chinese,
   korean), they tend to be smaller than their english equivalents and of
   limited value for modeling purposes. even within english, a language
   for which two major annotated corpora are available, systems trained on
   propbank demonstrate a marked decrease in performance (approximately by
   10%) when tested on out-of-domain data (pradhan, ward, and martin
   [409]2008). the data requirements for supervised systems and the
   current paucity of such data has given impetus to the development of
   unsupervised methods that learn from unlabeled data. if successful,
   unsupervised approaches could lead to significant resource savings and
   the development of semantic role labelers that require less engineering
   effort. besides being interesting on their own right, from a
   theoretical and linguistic perspective, unsupervised methods can
   provide valuable features for downstream (supervised) processing and
   serve as a preprocessing step for applications that require broad
   coverage understanding. in this article we study the potential of
   unsupervised methods for id14. as in the supervised
   case, we decompose the problem into an argument identification step and
   an argument classification step. our work primarily focuses on argument
   classification, which we term role induction, because there is no
   predefined set of semantic roles in the unsupervised case, and these
   must be induced from data. the goal is to assign argument instances to
   clusters such that each cluster contains arguments corresponding to a
   specific semantic role and each role corresponds to exactly one
   cluster.

   unsupervised learning is known to be challenging for many natural
   language processing problems and role induction is no exception.
   firstly, it is difficult to define a learning objective function whose
   optimization will yield an accurate model. this contrasts with the
   supervised setting, where the objective function can directly reflect
   training error (i.e., some estimate of the mismatch between model
   output and the gold standard) and the model can be tuned to replicate
   human output for a given input under mathematical guarantees regarding
   the accuracy of the trained model. secondly, it is also more difficult
   to incorporate rich feature sets into an unsupervised model
   (berg-kirkpatrick et al. [410]2010). unless we explicitly know exactly
   how features interact, more features may not necessarily lead to a more
   accurate model and may even decrease performance. in the supervised
   setting, feature interactions relevant for a particular learning task
   can be determined to a large extent automatically and thus a large
   number of them can be included even if their significance is not clear
   a priori.

   the lack of an extensional definition (in the form of training
   examples) of the target concept makes a strong case for the development
   of unsupervised methods that use problem specific prior knowledge. the
   idea is to derive a strong inductive bias (gordon and desjardins
   [411]1995) based on this prior knowledge that will guide the learning
   towards the correct target concept. for semantic role induction, we
   propose to build on the following linguistic principles:
   1.   

   semantic roles are unique within a particular frame.
   2.   

   arguments occurring in a specific syntactic position within a specific
   linking all bear the same semantic role.
   3.   

   the (asymptotic) distribution over argument heads is the same for two
   clusters that represent the same semantic role.

   we hypothesize that these three principles are, at least in theory,
   sufficient for inducing high-quality semantic role clusters. a
   challenge, of course, lies in adequately operationalizing them so that
   they guide the unsupervised learner towards meaningful solutions. the
   approach taken in this article translates these principles into
   estimates of similarity (or dissimilarity) between argument instances
   and/or clusters of argument instances. principle (1) states that
   argument instances occurring in the same frame (i.e., clause) cannot
   bear the same semantic role, and are thus dissimilar. from principle
   (2) it follows that arguments occurring in the same syntactic position
   within the same linking can be considered similar (leaving aside for
   the moment the difficulty of representing linkings through syntactic
   cues observable in a corpus). principle (3) states that two clusters of
   instances containing similar distributions over head words should be
   considered similar.

   based on these similarity estimates we construct a graph whose vertices
   represent argument instances and whose edges express similarities
   between these instances. the graphs consist of multiple edge layers,
   each capturing one particular type of argument-instance similarity. for
   example, one layer will be used to represent whether argument instances
   occur in the same frame, and another layer will represent whether two
   arguments have a similar head word, and so on. given this graph
   representation of the data, we formalize role induction as the problem
   of partitioning the graph into clusters of similar vertices. we present
   two algorithms for partitioning multi-layer graphs, which are
   adaptations of standard graph partitioning algorithms to the
   multi-layer setting. the algorithms differ in the way they exploit the
   similarity information encoded in the graph. the first one is based on
   agglomeration, where two clusters containing similar instances are
   grouped into a larger cluster. the second one is based on propagation,
   where role-label information is transferred from one cluster to another
   based on their similarity.

   to understand how the aforementioned principles might allow us to
   handle the ambiguity id30 from alternate linkings, consider again
   example (1). the most important thing to note is that, whereas the
   subject position is ambiguous with respect to the semantic roles it can
   express (it can be a0, a1, or a2), we can resolve the ambiguity by
   exploiting overt syntactic cues of the underlying linking. for example,
   the predicate break is transitive in sentences (1a) and (1b), and
   intransitive in sentence (1c). thus, by taking into account the
   argument's syntactic position and the predicate's transitivity, we can
   guess that the semantic role expressed by the subject in sentence (1c)
   is different from the roles expressed by the subjects in sentences
   (1a,b). now consider the more difficult case of distinguishing between
   the subjects in sentences (1a) and (1b). one linking cue that could
   help here is the prepositional phrase in sentence (1a), which results
   in a syntactic frame different from sentence (1b). were the
   prepositional phrase omitted, we would attempt to disambiguate the
   linkings by resorting to lexical-semantic cues (e.g., by taking into
   account whether the subject is animate). in sum, if we encode
   sufficiently many linking cues, then the resulting fine-grained
   syntactic information will discriminate ambiguous semantic roles. in
   cases where syntactic cues are not discerning enough, we can exploit
   lexical information and group arguments together based on their lexical
   content.

   the remainder of this article is structured as follows. [412]section 2
   provides an overview of unsupervised methods for semantic role
   labeling. [413]sections 3 and [414]4 present the details of our method,
   that is, how the graphs are constructed and partitioned. role induction
   experiments in english and german are described in [415]sections 5 and
   [416]6, respectively. discussion of future work concludes in
   [417]section 7.
   2.   related work
   section:
   [choose________________________]
   [418]previous section [419]next section

   the bulk of previous work on id14 has focused on
   supervised methods (m  rquez et al. [420]2008), although a few
   semi-supervised and unsupervised approaches have been proposed. the
   majority of semi-supervised models have been developed within a
   framework known as annotation projection. the idea is to combine
   labeled and unlabeled data by projecting annotations from a labeled
   source sentence onto an unlabeled target sentence within the same
   language (f  rstenau and lapata [421]2009) or across different languages
   (pad   and lapata [422]2009). beyond annotation projection, gordon and
   swanson ([423]2007) propose to increase the coverage of propbank to
   unseen verbs by finding syntactically similar (labeled) verbs and using
   their annotations as surrogate training data.

   swier and stevenson ([424]2004) were the first to introduce an
   unsupervised id14 system. their algorithm induces
   role labels following a id64 scheme where the set of labeled
   instances is iteratively expanded using a classifier trained on
   previously labeled instances. their method starts with a data set
   containing no role annotations at all, but crucially relies on verbnet
   (kipper, dang, and palmer [425]2000) for identifying the arguments of
   predicates and making initial role assignments. verbnet is a manually
   constructed lexicon of verb classes, each of which is explicitly
   associated with argument realization and semantic role specifications.

   in this article we will not assume the availability of any
   role-semantic resources, although we do assume that sentences are
   syntactically analyzed. there have been two main approaches to role
   induction from parsed data. under the first approach, semantic roles
   are modeled as latent variables in a (directed) graphical model that
   relates a verb, its semantic roles, and their possible syntactic
   realizations (grenager and manning [426]2006). role induction here
   corresponds to inferring the state of the latent variables representing
   the semantic roles of arguments. following up on this work, lang and
   lapata ([427]2010) reformulate role induction as the process of
   detecting alternations and finding a canonical syntactic form for them.
   verbal arguments are then assigned roles, according to their position
   in this canonical form, because each position references a specific
   role. their model extends the logistic classifier with hidden variables
   and is trained in a manner that takes advantage of the close
   relationship between syntactic functions and semantic roles. more
   recently, garg and henderson ([428]2012) extend the latent-variable
   approach by modeling the sequential order of roles.

   the second approach is similarity-driven and based on id91. lang
   and lapata ([429]2011a) propose an algorithm that first splits the set
   of all argument instances of a verb according to their syntactic
   position within a particular linking and then iteratively merges
   clusters. a different clusstering algorithm is adopted in lang and
   lapata ([430]2011b). specifically, they induce semantic roles via graph
   partitioning: each vertex in the graph corresponds to an argument
   instance and edges represent a heuristically defined measure of their
   lexical and syntactic similarity. the similarity-driven approach has
   been recently adopted by titov and klementiev ([431]2012a), who propose
   a bayesian id91 algorithm based on the chinese restaurant
   process. in addition, they present a method that shares linking
   preferences across verbs using a distance-dependent chinese restaurant
   process prior which encourages similar verbs to have similar linking
   preferences. titov and klementiev ([432]2012b) further introduce the
   use of multilingual data for improving role induction.

   there has also been work on unsupervised methods for argument
   identification. abend, reichart, and rappoport ([433]2009) devise a
   method for recognizing the arguments of predicates that relies solely
   on part of speech annotations, whereas abend and rappoport ([434]2010a)
   distinguish between core and adjunct roles, using an unsupervised
   parser and part-of-speech tagger. more generally, shallow semantic
   representations induced from syntactic information are commonly used in
   lexicon acquisition and information extraction tasks. for example, lin
   and pantel ([435]2001) cluster syntactic relations between pairs of
   words as expressed by parse tree paths into semantic relations by
   exploiting lexical distributional similarity. although not compatible
   with propbank or semantic roles as such, poon and domingos ([436]2009)
   and titov and klementiev ([437]2011) also induce semantic information
   from dependency parses and apply it to a id53 task for
   the biomedical domain. another example is the work by gamallo,
   agustini, and lopes ([438]2005), who cluster similar syntactic
   positions in order to develop models of selectional preferences to be
   used for word sense induction and the resolution of attachment
   ambiguities.

   the work described here unifies the two id91 methods presented in
   lang and lapata ([439]2011a and [440]2011b) by reformulating them as
   graph partitioning algorithms. it also extends them by utilizing
   multi-layer graphs which separate the similarities between instances on
   different features (e.g., part-of-speech, argument head) into different
   layers. this has the advantage that similarity scores on individual
   features do not have to be eagerly combined into a similarity score
   between instances. instead, one can first aggregate the similarity
   scores on each feature layer between two clusters and then combine them
   into a similarity score between clusters. this is more robust, as the
   feature-wise similarity scores between clusters can be computed in a
   principled way and the heuristic combination step is deferred to the
   end (see [441]section 4 for details). besides providing a general
   modeling framework for semantic role induction, we discuss in detail
   the linguistic principles guiding our modeling choices and assess their
   applicability across languages. specifically, we show that the
   framework presented here (and the aforementioned principles) can be
   readily applied to english and german with identical parametrizations
   for both languages and without fundamentally changing the underlying
   model features, despite major syntactic differences between the two
   languages.
   3.   graph construction
   section:
   [choose________________________]
   [442]previous section [443]next section

   we begin by explaining how we construct a graph that represents verbs
   and their arguments. next, we describe how edge weights are
   computed   these translate to similarity scores between argument
   instances   and then move on to provide the details of our
   graph-partitioning algorithms.

   as mentioned earlier, we formalize semantic role induction as a
   id91 problem. id91 algorithms (see jain, murty, and flynn
   [[444]1999] for an overview) commonly take a matrix of pairwise
   similarity scores between instances as input and produce a set of
   output clusters, often satisfying some explicitly defined optimality
   criterion. the success or failure of the id91 approach is closely
   tied to the adequacy of the employed similarity function for the task
   at hand. the graph partitioning view of id91 (see schaeffer
   [[445]2007] for a detailed treatment) arises when instances are
   represented as the vertices of a graph and the similarity matrix is
   interpreted as the weight matrix of the graph. for semantic role
   induction, a straightforward application of id91 would be to
   construct a graph for each verbal predicate such that vertices
   correspond to argument instances of the verb and edge weights quantify
   the similarity between these instances.

   lang and lapata ([446]2011b) hand-craft an instance similarity function
   by taking into account different features such as the argument head or
   its syntactic position. defining an appropriate instance-wise
   similarity function is nevertheless problematic as weights have to be
   chosen heuristically. instead, we will represent similarities with
   respect to different features on separate edge layers in the graph. for
   example, one layer will represent the similarity between the head words
   of arguments and another one will represent the similarity between pars
   of speech. so, given m features, the graph will consist of m layers,
   one for each feature. edge weights on a particular layer quantify the
   similarity between the instances with respect to that feature. this is
   illustrated in [447]figure 1 for two argument instances and three
   features. formally, a multi-layer graph is defined as a pair (v, {e[1],
       , e[m]}) consisting of vertices v and a set of edge layers e[f] for f
   = 1     m. the set of vertices v = {v[1],     , v[n]} consists of all n
   argument instances for a particular verb. the edge layer e[f] for
   feature f is constructed by connecting all vertex-pairs with non-zero
   similarity with respect to f:

   where   [f](v[i],v[j]) is a similarity function for feature f, whose
   form will be discussed in the next section. each edge (v[i],v[j])    
   e[f]in layer f is weighted by   [f](v[i],v[j]).
   [448]figure
   figure   1    a multi-layer graph consists of multiple edge layers, one for
   each similarity feature. multi-layer graph partitioning algorithms
   exploit this representation by computing separate similarity scores
   between clusters for each feature layer and then combining them into a
   single overall similarity score. this is advantageous over single-layer
   graph partitioning because it avoids eagerly combining the similarity
   scores for individual features into a heuristic instance-wise
   similarity score.
   3.1   feature similarity functions

   similarities for a specific feature f are measured with a function
     [f](v[i],v[j]) which assigns a [   1,1] value to any pair of instances
   (v[i],v[j]). we assume similarities are measured on an interval
   scale   that is, while sums, differences, and averages of the values of
   some similarity function   [f] express meaningful quantities, products
   and ratios do not. moreover, the values of two distinct similarity
   functions cannot necessarily be meaningfully compared without
   rescaling. positive similarity values indicate that the semantic roles
   are likely to be the same, negative values indicate that roles are
   likely to differ, and zero values indicate that there is no evidence
   for either case. the magnitude of   [f] expresses the degree of
   confidence in the similarity judgment, with extreme values (i.e.,    1
   and 1) indicating maximal confidence.

   in our model, we simply use indicator functions which output either 1
   or    1 iff feature values are equal and 0 otherwise. specifically, we
   define four feature similarity functions that we derive from the
   principles discussed in [449]section 1. our similarity functions are
   based on the following features: the argument head words and their
   parts of speech,[450]^2

   2   we include parts of speech as a simple means of alleviating the
   sparsity of head words.
   the frame constraint, and the syntactic position within a particular
   linking. we measure lexical and part-of-speech similarity as follows:

   the constraint that two argument instances v[i] and v[j] occurring in
   the same frame cannot have the same semantic role is captured by the
   following similarity function:

   finally, we also measure syntactic similarity through an indicator
   function   [syn](v[i],v[j]), which assumes value 1 if two instances
   occur in the same syntactic position within the same linking:

   the syntactic position of an argument is directly given by the parse
   tree and can be encoded, for example, by the full path from predicate
   to argument head, or for practical purposes, in order to reduce
   sparsity, simply through the relation governing the argument head and
   its linear position relative to the predicate (left or right). in
   contrast, linkings are not directly observed, but we can resort to
   overt syntactic cues as a proxy. examples include the verb's voice
   (active/passive), whether it is transitive, the part-of-speech of the
   subject, and so on. we argue that in principle, if sufficiently many
   cues are taken into account, they will capture one particular linking,
   although there may be several encodings for the same linking. note that
   syntactic similarity is not used to construct another graph layer;
   rather, it will be used for deriving initial clusters of instances, as
   we explain in [451]section 4.1.
   4.   graph partitioning
   section:
   [choose________________________]
   [452]previous section [453]next section

   the graph partitioning problem consists of finding a set of clusters
   {c[1],     , c[s]} that form a partition of the vertex-set, namely,
      [i]c[i] = v and c[i]     c[j] =     for all i     j, such that (ideally)
   each cluster contains argument instances of only one particular
   semantic role, and the instances for a particular role are all assigned
   to one and the same cluster. in the following sections we provide two
   algorithms for multi-layer graph partitioning, based on standard
   id91 algorithms for single-layer graphs. both algorithms operate
   on the same graph but differ in terms of the underlying id91
   mechanism they use. the first algorithm is an adaptation of
   agglomerative id91 (jain, murty, and flynn [454]1999) to the
   multi-layer setting: starting from an initial id91, the algorithm
   iteratively merges vertex clusters in order to arrive at increasingly
   accurate representations of semantic roles. rather than greedily
   merging clusters, our second algorithm is based on propagating cluster
   membership information among the set of initial clusters (abney
   [455]2007).

   4.1   agglomerative graph partitioning

   the agglomerative algorithm induces clusters in a bottom   up manner
   starting from an initial cluster assignment that we will subsequently
   discuss in detail. our initialization results in a id91 that has
   high purity but low collocation, that is, argument instances in each
   cluster tend to belong to the same role but argument instances of a
   particular role are scattered among many clusters.[456]^3

   3   we define the terms purity and collocation more formally in
   [457]section 5.4.
   the algorithm then improves collocation by iteratively merging pairs of
   clusters. the agglomeration procedure is described in algorithm 1 . as
   can be seen, pairs of clusters are merged iteratively until a
   termination criterion is met. the decision of which cluster pair to
   merge at each step is made by scoring a set of candidate cluster pairs
   and choosing the highest one (line 5). the scoring function s(c[i],
   c[j   ]) quantifies how likely two clusters are to contain arguments of
   the same role. a key question is how to define this scoring function on
   the basis of the underlying graph representation, that is, with
   reference to the instance similarities expressed by the edges. in order
   to collect evidence for or against a merge, we take into account the
   connectivity of a cluster pair at each feature layer of the graph. this
   crucially involves aggregating over all edges that connect the two
   clusters, and allows us to infer a cluster-level similarity score from
   the individual instance-level similarities encoded in the edges. the
   evidence collected at each layer is then combined together in order to
   arrive at an overall decision (see [458]figure 1 for an illustration).

   although it would be possible to enumerate and score all possible
   cluster pairs at each step, we apply a more efficient and effective
   procedure in which the set of candidates consists of pairs formed by
   combining a fixed cluster c[i] with all clusters larger than c[i]. this
   requires comparing only o(|c|) rather than o(|c|^2) scores and, more
   importantly, it favors merges between large clusters whose score can be
   computed more reliably. as mentioned earlier, our scoring function
   implements an averaging procedure over the instances contained in the
   clusters, and thus yields less noisy scores when clusters are large
   (i.e., contain many instances). this prioritization promotes reliable
   merges over less reliable ones in the earlier phases of the algorithm
   with a positive effect on merges in the later phases. moreover, by
   keeping c[i] fixed, we only require that scores s(c[i],x) and s(c[i],z)
   are comparable (i.e., where one cluster is argument in both scores),
   rather than comparisons between arbitrary cluster pairs (e.g., s(w,x)
   and s(y,z)). in the following, we will provide details on the
   initialization of the algorithm and the computation of the similarity
   scoring function.

   a standard agglomerative id91 algorithm forms clusters bottom   up
   by initially placing each item of interest in its own cluster. in our
   case, initializing the algorithm with as many clusters as argument
   instances would result in a id91 with maximal purity and minimal
   collocation. there are two reasons that justify a more sophisticated
   initialization procedure for our problem. firstly, the scoring function
   we use is more reliable for larger clusters than for smaller clusters
   (see the subsequent discussion). in fact, the standard initialization
   that creates clusters with a single instance would not yield useful
   results as our scoring function crucially relies on initial clusters
   containing several instances on average. secondly, the similarity
   scores for different features are not directly comparable. recall from
   [459]section 3.1 that we introduced different types of similarities
   based on the arguments' head words (  [lex]), parts-of-speech (  [pos]),
   syntactic positions (  [syn]), and frame constraints (  [frame]). as
   discussed earlier, engineering a scoring function that integrates these
   into a single score without resorting to heuristic judgments on how to
   weight them poses a major challenge. in particular, it is difficult to
   weight the contribution of the two forms of positive evidence given by
   lexical and syntactic similarity. this motivates the idea of using
   syntactic similarity for initialization, and lexical similarity (as
   well as the frame constraint) for scoring. this separation avoids the
   difficulty of defining the exact interaction between the two.
   specifically, we obtain an initial id91 by grouping together all
   instances which occur in the same syntactic position within a
   linking   that is, all pairs (v[i], v[j]) for which   [syn](v[i], v[j]) =
   1 are grouped into the same cluster, assuming that arguments occurring
   in a specific syntactic position under a specific linking share the
   same role.

   we specify the syntactic position of an argument using four cues: the
   verb's voice (active/passive), the argument's linear position relative
   to the predicate (left/right), the syntactic relation of the argument
   to its governor (e.g., subject or object), and the preposition used for
   realizing the argument (if any). each argument is assigned a four-tuple
   consisting of these cues and two syntactic positions are assumed equal
   iff they agree on all cues.

   whereas the similarity functions defined in [460]section 3.1 measure
   role-semantic similarity between instances on a particular feature, the
   scoring function measures role-semantic similarity between clusters.
   naturally, the similarity between two clusters is defined in terms of
   the similarities of the instances contained in the clusters. this
   involves two aggregation stages. initially, instance similarities are
   aggregated in each feature layer, resulting in an aggregate score for
   each feature. these layer-specific scores are then integrated into a
   single score, which quantifies the overall similarity between the two
   clusters (see [461]figure 1).

   an obvious way to determine the similarity between two clusters (with
   respect to a particular feature f) would be to analyze their
   connectivity. for example, we could use edge density (schaeffer
   [462]2007) to average over the weights of edges between two clusters.
   however, edge density is an inappropriate measure of similarity in our
   case, because we cannot assume that arbitrary pairs of instances are
   similar with respect to a particular feature, even if two clusters
   represent the same semantic role. consider for example lexical
   similarity: most head words will not agree (even within a cluster) and
   therefore averaging between all pairs would yield low scores,
   regardless of whether the clusters represent the same role or not.
   analogously, the vast majority of instance pairs from any two clusters
   will belong to different frames, and thus averaging over all possible
   pairs of instances would not yield indicative scores.

   we therefore adopt an averaging procedure which finds, for each
   instance in one cluster, the instance in the other cluster that is
   maximally similar or dissimilar and averages over the scores of these
   alignments:

   here, abs max is a functional that returns the extreme value of its
   argument, either positive or negative: abs max[x   x] g(x) = g(arg
   max[x   x] |g(x)|). note that the alignments are unconstrained in the
   sense that v[a]     c[k] can be aligned to v[b]     c[l] in the first term
   of [463]equation (6), while v[b] can be aligned to some other instance
   in the second term. moreover, alignments in each term are many-to-one,
   namely, multiple instances from c[k] can be aligned to the same v[b]    
   c[l] in the first term and likewise in the second term. this means that
   score aggregation does not reflect the distributional properties of
   clusters (e.g., the frequency of head words in each cluster). consider
   for example two clusters with an identical set of head words. because
   many-to-one alignments are allowed, each instance can be aligned with
   maximal score to some other instance regardless of the frequencies of
   these words.

   as an alternative, we also use the well-known cosine similarity
   function   although only for the features based on argument head words
   (lex) and parts of speech (pos):

   here and are vector representations of the cluster containing as
   components the occurrence frequencies of a particular value of the
   feature f (i.e., lex and pos in our case). another solution would be to
   enforce one-to-one alignments and redefine [464]equation (6) as the
   optimal bipartite matching between the two clusters. although this
   solution adheres to the graph formulation (in contrast to [465]equation
   (7)) we see no theoretical reason that makes it superior to cosine
   similarity. moreover, its computation would require cubic runtime in
   the number of vertices using the hungarian algorithm (munkres
   [466]1957), which is prohibitively slow for sufficiently large
   clusters.

   layer-specific similarity scores must be combined into an overall
   cluster similarity score. because similarity scores and their
   aggregates for different features are not directly comparable, their
   combination through summation would require weighting each layer score
   according to its relative strength. due to the difficulty of specifying
   these weights without access to labeled training data, we propose an
   alternative scheme that is based on the distinction between positive
   and negative evidence. negative evidence is used to rule out a merge,
   whereas positive evidence provided by the lexical score is used to
   score merges that have not yet been ruled out:

   when the part-of-speech similarity is below a certain threshold   , or
   when clause-level constraints are satisfied to a lesser extent than
   threshold   , the score takes value    1 and the merge is ruled out. if
   the merge is not ruled out, the lexical similarity score determines the
   magnitude of the overall score, provided that it is above threshold   .
   otherwise, the function returns 0, indicating that neither strong
   positive nor negative evidence is available. the cluster-similarity
   scoring function can be viewed as the decision function of a binary
   classifier for deciding on whether to merge a particular pair of
   clusters. the classifier is informed by the similarity scores for each
   feature layer and outputs a confidence-weighted decision
   (positive/negative), where the sign sgn(  [f](v[i], v[j])) indicates the
   decision and the absolute value |  [f](v[i],v[j])| quantifies
   confidence. the scoring function in [467]equation (8) essentially
   implements a simple decision list classifier, whose decision rules are
   sequentially inspected from top to bottom, applying the first matching
   rule.

   although our definition avoids weighting, it has introduced threshold
   parameters   ,   , and    that we need to somehow estimate. we propose a
   scheme in which parameters    and    are iteratively adjusted, and   , the
   threshold determining the extent to which the frame constraints can be
   violated, is kept fixed. we heuristically set    to     0.05, based on the
   intuition that in principle frame constraints must be satisfied
   although in practice, due to noise we expect a small number of
   violations (i.e., at most 5% of instances can violate the constraint).
   parameters    and    are initially set to their maximal value 1, thereby
   ruling out all merges except those with maximal confidence. the
   parameters then decrease iteratively according to a routine whose
   pseudo-code is specified in algorithm 2 . the parameter    decreases at
   each iteration by a small amount (0.025) until it reaches    = 0.025, at
   which point its value is reset to 1.0 and    is discounted by a factor
   close to one (0.9). this is repeated until    falls below   , upon which
   the algorithm terminates.

   runtime analysis. as described in the previous section, algorithm 1
   stops when the threshold    falls below some small value   . both    and   
   iteratively decrease based on a fixed scheme. the outer loop and
   starting in line 1 is therefore computed in constant time t. each pass
   through the inner loop starting at line 4 iterates over o(|c|) clusters
   and for each one of them a score with o(|c|) other clusters is
   computed. assume that f[i] denotes the fraction of all v instances in
   cluster c[i], namely, f[i] v = |c[i]| and . then, overall, the number
   of instance-wise similarities we need to evaluate is at most o(|v|^2):

   the total runtime in terms of the input is therefore o(t   |v|^2).
   although this could be prohibitively inefficient for large data sets,
   we did not observe long runtimes in our experiments. various
   optimizations are conceivable   for example, the cluster similarity
   scores in line 5 of algorithm 1 can be cached such that they only need
   to be recomputed when a cluster changes (i.e., it is merged with
   another cluster).
   4.2   multi-layer label propagation

   our second graph partitioning algorithm is based on the idea of
   propagating cluster membership information along the edges of a graph,
   subsequently referred to as propagation graph. as we explain in more
   detail subsequently, compared with agglomerative id91, this
   algorithm in principle is less prone to making false greedy decisions
   that cannot be later revoked. moreover, it has lower runtime and thus
   scales better to larger data sets.

   the propagation graph is created by collapsing vertices of the initial
   multi-layer graph. vertices in the propagation graph represent an
   atomic set of instances of the original graph, that is, a group of
   instances that are always assigned to the same cluster. for our
   induction problem, the vertices of the propagation graph correspond to
   the initial clusters of the agglomerative algorithm discussed in
   [468]section 4.1. more formally, let a[i]     a denote the i-th vertex of
   the propagation graph, which references an atomic cluster of vertices
   of the original graph that occur in the same syntactic position within
   the same linking. because each vertex of the propagation graph
   corresponds to a cluster of vertices in the original graph, the edges
   of the propagation graph can be defined in terms of the edges between
   these vertices in the original graph. we reuse [469]equations (6) and
   [470](7) to define the edge weights of the propagation graph as
   aggregates over the edge weights in the original graph. for each
   feature layer we define the set of edges as:

   each edge (a[i], a[j])     b[f] in layer f is accordingly weighted by
   s[f](a[i], a[j]). each vertex a[i] is associated with a label l[i],
   indicating the partition that a[i] and all the vertices in the original
   graph that have been collapsed into a[i] belongs to.

   note that the label propagation algorithm is informed by the same
   similarity functions as agglomerative id91 and uses an identical
   initialization procedure but provides an alternative means of cluster
   id136. initially, each vertex of the propagation graph belongs to
   its own cluster, that is, we let the number of clusters l = |a| and set
   l[i]     i. given this initial vertex labeling, the algorithm proceeds by
   iteratively updating the label for each vertex (lines 4   10 in algorithm
   3). this crucially relies on a scoring procedure in which a score s(l)
   is computed for each possible label l. we discuss the details of the
   scoring procedure below.

   the label scoring procedure required in line 5 of algorithm 3 has
   parallels to the cluster pair scoring procedure of the agglomerative
   algorithm. it also consists of two stages: initially, evidence is
   collected independently on each feature layer by computing label score
   aggregates with respect to each feature and then these feature scores
   are combined in order to arrive at an overall score.

   assume we are updating vertex a[i]. the first step is to compute the
   score for each feature f and each label l:

   where denotes the set of a[i]'s neighbors with label l that are larger
   than a[i]. intuitively, each neighboring vertex votes for the cluster
   it is currently assigned to, where the strength of the vote is
   determined by the similarity to the vertex (i.e., edge weight) being
   updated. the votes of all (larger) neighboring vertices are counted
   together, resulting in a score for each possible label. the condition
   of including only larger vertices for computing the score is analogous
   to the prioritization mechanism of the agglomerative algorithm (only
   merges with larger clusters are considered for a given candidate
   cluster). we impose this restriction for the same reason, namely, that
   scores for larger clusters are more reliable.

   given the scores s[f](l) for a particular label l on each layer f, our
   goal then is to combine them into a single overall score s(l) for the
   label. as in agglomerative partitioning, combining these scores through
   summation is not possible without    guessing    their weights, and
   therefore we use a sequential combination instead:

   analogously to [471]equation (8), negative evidence that stems from
   part-of-speech information or frame constraints can veto a propagation,
   whereas positive evidence id30 from argument head words can promote
   a propagation. if neither strong evidence (positive or negative) is
   available, the label is assigned a zero score. note that the scoring
   function has three parameters with an identical interpretation to those
   in the scoring function of the agglomerative algorithm. the threshold
   update that takes place in line 11 of algorithm 3 is therefore the same
   as the one described in [472]section 4.1 for the agglomerative
   algorithm.

   we now analyze the runtime of our algorithm. let t denote the number of
   iterations of the outer loop starting at line 1 of algorithm 3 . the
   inner loop starting at line 4 iterates over |a| clusters and for each
   one of them it has to evaluate at most |a| neighboring nodes.
   additionally, there are the one-time costs of computing the
   similarities between atomic clusters which take o(|v|^2) time. the
   total runtime is therefore o(t |a|^2 + |v|^2). because |a|^2 < < |v|^2,
   label propagation is substantially faster than agglomerative
   id91.

   4.3   relationship to single-layer graph partitioning

   id91 algorithms typically assume instance-wise similarities as
   input (i.e., single-layer graphs). for our role induction problem, this
   would require a heuristically defined similarity function that combines
   the similarities on individual features into a single similarity score
   between instances. in other words, we would collapse the multiple graph
   layers into a single layer and then partition the resulting
   single-layer graph according to a standard id91 algorithm. a main
   difference between the two approaches is the order in which
   similarities are aggregated: whereas multi-layer graph partitioning
   aggregates similarities on each feature layer first and then combines
   them into an overall cluster-wise similarity score, in the single-layer
   case feature similarities are eagerly combined into an overall
   instance-wise similarity score and then aggregated. thus, in the
   multi-layer setting, aggregation can be done in a principled way by
   considering the individual feature layers in isolation. for large
   clusters the resulting scores for each feature layer will provide
   reliable evidence for or against a merge. combining these cluster-wise
   similarity scores is much less error-prone than the eager combination
   at the instance-level used by the single-layer approach. we
   experimentally confirm this intuition (see [473]section 5.5) by
   comparing against the single-layer partitioning algorithm presented in
   lang and lapata ([474]2011b).
   5.   role induction experiments on english
   section:
   [choose___________________________]
   [475]previous section [476]next section

   we adopt the general architecture of supervised id14
   systems where argument identification and argument classification are
   treated separately. our role labeler is fully unsupervised with respect
   to both tasks   it does not rely on any role annotated data or semantic
   resources. however, our system does not learn from raw text. in common
   with most id14 research, we assume that the input is
   syntactically analyzed. our approach is not tied to a specific
   syntactic representation   both constituent- and dependency-based
   representations can be used. the bulk of our experiments focus on
   english data and a dependency-based representation that simplifies
   argument identification considerably and is consistent with the conll
   2008 benchmark data set used for evaluation in our experiments. to show
   that our method can be applied to other languages and across varying
   syntactic representations, we also report experiments on german using a
   constituent-based representation (see [477]section 6).

   given the parse of a sentence, our system identifies argument instances
   and assigns them to clusters. thereafter, argument instances can be
   labeled with an identifier corresponding to the cluster they have been
   assigned to, similar to propbank core labels (e.g., a0, a1). we view
   argument identification as a syntactic processing step that can be
   largely undertaken deterministically through analysis of the syntactic
   tree. we therefore use a small set of rules to detect arguments with
   high precision and recall. in the following, we first describe the data
   set ([478]section 5.1) on which our experiments were carried out. next,
   we present the argument identification component of our system
   ([479]section 5.2) and the method used for comparison with our
   approach. finally, we explain how system output was evaluated
   ([480]section 5.4).
   5.1   data

   for evaluation purposes, we ran our method on the conll 2008 shared
   task data set (surdeanu et al. [481]2008), which provides propbank
   style gold standard annotations. as our algorithm induces verb-specific
   roles, propbank annotations are a natural choice of gold standard for
   our problem. the data set contains annotations for verbal and nominal
   predicate-argument constructions, but we only considered the former.
   the conll data set was taken from the wall street journal portion of
   the id32 and converted into a dependency format (surdeanu et
   al. [482]2008). input sentences are represented in the dependency
   syntax specified by the conll 2008 shared task (see [483]figure 2 for
   an example). in addition to gold standard dependency parses, the data
   set also contains automatic parses obtained from the maltparser (nivre
   et al. [484]2007), which we will use as an alternative in our
   experiments in order to assess the impact of parse quality. for each
   argument only the head word is annotated with the corresponding
   semantic role, rather than the whole constituent. we assume that
   argument heads are content words (e.g., the head of a prepositional
   phrase is the nominal head rather than the preposition). we do not
   treat split arguments or co-referential arguments (e.g., in relative
   clauses). specifically, we ignore arguments with roles preceded by the
   c- or r- prefix in the gold standard. all argument lemmas were
   normalized to lower case; we also replaced numerical quantities with a
   placeholder; to further reduce data sparsity, we identified the head of
   proper noun phrases heuristically as the most frequent lemma contained
   in the phrase.
   [485]figure
   figure   2    a sample dependency parse with dependency labels sbj
   (subject), obj (object), nmod (nominal modifier), oprd (object
   predicative complement), prd (predicative complement), and im
   (infinitive marker).
   5.2   argument identification

   in the supervised setting, a classifier is used in order to decide for
   each node in the parse tree whether it represents a semantic argument
   or not. nodes classified as arguments are then assigned a semantic
   role. in the unsupervised setting, we slightly reformulate argument
   identification as the task of discarding as many non-semantic arguments
   as possible. this means that the argument identification component does
   not make a final positive decision for any of the argument candidates;
   instead, this decision is deferred to role induction.[486]^4

   4   a few supervised systems implement a similar definition (koomen et
   al. [487]2005), although in most cases the argument identification
   component makes a final positive or negative decision regarding the
   status of an argument candidate.
   we assume here that predicate identification is a precursor to argument
   identification and can be done relatively straightforwardly based on
   part-of-speech information.

   the rules given in [488]table 1 are used to discard or select argument
   candidates for english. they primarily take into account the parts of
   speech and the syntactic relations encountered when traversing the
   dependency tree from predicate to argument. a priori, all words in a
   sentence are considered argument candidates for a given predicate.
   then, for each candidate, the rules are inspected sequentially and the
   first matching rule is applied. we will exemplify how the argument
   identification component works for the predicate expect in the sentence
   the company said it expects its sales to remain steady whose parse tree
   is shown in [489]figure 2. initially, all words except the predicate
   itself are treated as argument candidates. then, the rules from
   [490]table 1 are applied as follows. firstly, the words the and to are
   discarded based on their part of speech (rule 1); then, remain is
   discarded because the path ends with the relation im and said is
   discarded as the path ends with an upward-leading obj relation (rule
   2). rule 3 matches to it, which is therefore added as a candidate.
   next, steady is discarded because there is a downward-leading oprd
   relation along the path and the words company and its are also
   discarded because of the obj relations along the path (rule 4). rule 5
   does not apply but the word sales is kept as a likely argument (rule
   6). finally, rule 7 does not apply, because there are no candidates
   left.

   [491]table
   table   1    argument identification rules for english.

   on the conll 2008 training set, our argument identification rules
   obtain a precision of 87.0% and a recall of 92.1% on gold standard
   parses. on automatic parses, precision is 79.3% and recall 84.8%. here,
   precision measures the percentage of selected arguments that are actual
   semantic arguments, and recall measures the percentage of actual
   arguments that are not filtered out.

   grenager and manning ([492]2006) also devise rules for argument
   identification, unfortunately without providing any details on their
   implementation. more recently, attempts have been made to identify
   arguments without relying on a treebank-trained parser (abend and
   rappoport [493]2010b; abend, reichart, and rappoport [494]2009). the
   idea is to combine a part-of-speech tagger and an unsupervised parser
   in order to identify constituents. likely arguments can be in turn
   identified based on a set of rules and the degree of collocation with
   the predicate. perhaps unsurprisingly, this method does not match the
   quality of a rule-based component operating over trees produced by a
   supervised parser.
   5.3   baseline method for semantic role induction

   the linking between semantic roles and syntactic positions is not
   arbitrary; specific semantic roles tend to map onto specific syntactic
   positions such as subject or object (levin and rappaport [495]2005;
   merlo and stevenson [496]2001). we further illustrate this observation
   in [497]table 2, which shows how often individual semantic roles map
   onto certain syntactic positions. the latter are simply defined as the
   relations governing the argument. the frequencies in the table were
   obtained from the conll 2008 data set and are aggregates across
   predicates. as can be seen, semantic roles often approximately
   correspond to a single syntactic position. for example, a0 is commonly
   mapped onto subject (sbj), whereas a1 is often realized as object
   (obj).

   [498]table
   table   2    contingency table between syntactic position and semantic
   roles. only the eight most frequent syntactic positions and their
   labels are listed (i.e., sbj (subject), obj (object), adv (adverbial),
   tmp (temporal), pmod (preposition and its child), oprd (object
   complement), loc (location), dir (direction)). counts were obtained
   from the conll 2008 training data set using gold standard parses. the
   marginals in the right-most column include all syntactic positions (not
   only the eight most frequent ones). boldface highlights the most
   frequent role per syntactic position (e.g., sbj is frequently a0, obj
   is a1).

   this motivates a baseline that directly assigns instances to clusters
   according to their syntactic position. the pseudo-code is given in
   algorithm 4. for each verb we allocate n = 22 clusters (the maximal
   number of gold standard clusters together with a default cluster).
   apart from the default cluster, each cluster is associated with a
   syntactic position and all instances occurring in that position are
   mapped into the cluster. despite being relatively simple, this baseline
   has been previously used as a point of comparison by other unsupervised
   id14 systems (grenager and manning [499]2006; lang
   and lapata [500]2010) and shown difficult to outperform. this is partly
   due to the fact that almost two thirds of the propbank arguments are
   either a0 or a1. identifying these two roles correctly is therefore the
   most important distinction to make, and because this can be largely
   achieved on the basis of the arguments' syntactic position (see
   [501]table 2), the baseline yields high scores.
   5.4   evaluation

   in this section we describe how we assess the quality of a role
   induction method that assigns labels to units that have been identified
   as likely arguments. we also discuss how we measure whether differences
   in model performance are statistically significant.

   arguments are labeled based on the cluster they have been assigned to,
   which means that in contrast to the supervised setting we cannot verify
   the correctness of these labels directly (e.g., by comparing them to
   the gold standard). instead, we will look at the induced clusters as a
   whole and assess their quality in terms of how well they reflect the
   assumed gold standard. specifically, for each verb, we determine the
   extent to which argument instances in the clusters share the same gold
   standard role (purity) and the extent to which a particular gold
   standard role is assigned to a single cluster (collocation).

   more formally, for each group of verb-specific clusters we measure
   cluster purity as the percentage of instances belonging to the majority
   gold class in their respective cluster. let n denote the total number
   of instances, g[j] the set of instances belonging to the j-th gold
   class, and c[i] the set of instances belonging to the i-th cluster.
   purity can be then written as

   collocation is the inverse of purity (van rijsbergen [502]1974) and
   defined as follows. for each gold role, we determine the cluster with
   the largest number of instances for that role (the role's primary
   cluster) and then compute the percentage of instances that belong to
   the primary cluster for each gold role:

   per-verb scores are aggregated into an overall score by averaging over
   all verbs. we use the micro-average obtained by weighting the scores
   for individual verbs proportionately to the number of instances for
   that verb. finally, we use the harmonic mean of purity and collocation
   as a single measure of id91 quality:

   purity and collocation measure essentially the same data traits as
   precision and recall, which in the context of id91 are, however,
   defined on pairs of instances (manning, raghavan, and sch  tze
   [503]2008), which makes them a bit harder to grasp intuitively. we
   therefore prefer purity and collocation, arguing that these should be
   assessed in combination or together with f1 because they can be traded
   off against each other. purity can be trivially maximized by mapping
   each instance into its own cluster, and collocation can be trivially
   maximized by mapping all instances into a single cluster.

   although it is desirable to report performance with a single score such
   as f1, it is equally important to assess how purity and collocation
   contribute to this score. in particular, if a hypothetical system were
   to be used for automatically annotating data, low collocation would
   result in higher annotation effort and low purity would result in lower
   data quality. therefore high purity is imperative for an effective
   system whereas high collocation contributes to efficient data labeling.
   for assessing our methods we therefore introduce the following
   terminology. if a model attains higher purity than the baseline, we
   will say that it is adequate, because it induced roles that adequately
   represent semantic roles. if a model attains higher f1 than the
   baseline, we will say that it is non-trivial, because it strikes a
   tradeoff between collocation and purity that is non-trivial. our goal
   then is to find models that are both adequate and non-trivial.

   in order to assess whether differences in performance between two
   models are statistically significant, we used a sign test.
   specifically, we obtained a series of score pairs by testing two
   methods on a subsample of the test data. each subsample corresponds to
   a random selection of m = 2,000. we consider the resulting samples to
   be    sufficiently    independent to obtain indicative results from the
   test. as null hypothesis (h[0]) we assume that a model m attains scores
   equal to another model b. under h[0] the id203 that model m
   outperforms model b on a particular test set is . the random variable s
   counting the number of times that score[m] > score[b] in a sample of n
   score pairs is binomially distributed:

   we can therefore use s as our test statistic and reject the null
   hypothesis h[0] if .
   5.5   results

   our results are summarized in [504]tables 3   [505]5, which report
   cluster purity (pu), collocation (co), and their harmonic mean (f1) for
   the baseline and our two multi-layer graph partitioning algorithms. we
   present scores on four data sets that result from the combination of
   automatic parses with automatically identified arguments (auto/auto),
   gold parses with automatic arguments (gold/auto), automatic parses with
   gold arguments (auto/gold), and gold parses with gold arguments
   (gold/gold). we show how performance varies for our methods when
   measuring cluster similarity in the two ways described above: (a) by
   finding for each instance in one cluster the instance in the other
   cluster that is maximally similar or dissimilar and averaging over the
   scores of these alignments (avgmax) and (b) by using cosine similarity
   (see [506]section 4.1). we also report results for the single-layer
   algorithm proposed in lang and lapata ([507]2011b).[508]^5

   5   the results in [509]table 5 differ slightly from those published in
   lang and lapata ([510]2011b). this is due to a small change in the
   preprocessing of the data. for all english experiments reported here,
   we removed arguments with r- and c- role prefixes and replaced numbers
   with a placeholder.
   given a verbal predicate, they construct a single-layer graph whose
   edge weights express instance-wise similarities directly. the graph is
   partitioned into vertex clusters representing semantic roles using a
   variant of chinese whispers, a graph id91 algorithm proposed by
   biemann ([511]2006). the algorithm iteratively assigns cluster labels
   to graph vertices by greedily choosing the most common label among the
   neighbors of the vertex being updated.

   [512]table
   table   3    results for agglomerative partitioning (for avgmax and cosine
   similarity). f1 improvements over the baseline are statistically
   significant in all settings (q < 0.001). boldface highlights the best
   performing system according to purity, collocation, and f1.

   [513]table
   table   4    results for multi-layered label propagation (for avgmax and
   cosine similarity). f1 improvements over the baseline are statistically
   significant in all settings (q < 0.001). boldface highlights the best
   performing system according to purity, collocation, and f1.

   [514]table
   table   5    results for single-layered label propagation using a heuristic
   similarity function. f1 improvements over the baseline are
   statistically significant (q < 0.001) in the auto/gold and gold/gold
   settings. boldface highlights the best performing system according to
   purity, collocation, and f1.

   both agglomerative partitioning and multi-layered label propagation
   algorithms systematically achieve higher f1 scores than the
   baseline   that is, induce non-trivial id91s and more adequate
   semantic roles (by attaining higher purity). for example, on the
   auto/auto data set, the agglomerative algorithm using cosine similarity
   increases f1 by 2.3 points over the baseline and by 7.2 points in terms
   of purity. this increase in purity is achieved by trading off against
   collocation, although in a favorable ratio as indicated by the overall
   higher f1. all improvements over the baseline are statistically
   significant (q < 0.001 according to the test described in [515]section
   5.4). in general, we observe that cosine similarity outperforms avgmax
   similarity. we conjecture that cosine is a more appropriate measure of
   cluster similarity for features where it is beneficial to capture the
   distributional similarity of clusters. the two algorithms perform
   comparably   differences in f1 are not statistically significant (except
   in the gold/auto setting). nevertheless, agglomerative partitioning
   obtains higher purity and f1 than label propagation. the latter trades
   off more purity and in return obtains higher collocation. the
   single-layer method is inferior to the multi-layer algorithms, in
   particular because it is less robust to noise, as demonstrated by the
   markedly worse results on automatic parses. on the auto/auto data set
   the single-layered algorithm is on a par with the baseline and
   marginally outperforms it on the auto/gold and gold/gold
   configurations.

   to help put our results in context, we compare our methods with titov
   and klementiev's ([516]2012a) bayesian id91 models. they report
   results on the conll 2008 data sets with two model variants, a factored
   model that models each verb independently and a coupled model where
   model parameters are shared across verbs. in an attempt to reduce the
   sparsity of the argument fillers, they also present variants of the
   factored and coupled models where the argument heads have been replaced
   by lexical cluster ids id30 from brown et al.'s ([517]1992)
   id91 algorithm on the rcv1 corpus. in [518]table 6 we follow
   titov and klementiev ([519]2012a) and show results on the gold/gold and
   gold/auto settings. as can be seen, both the agglomerative id91
   and label propagation perform comparably to their coupled model, even
   though they do not implement any specific mechanism for sharing
   id91 preferences across verbs. versions of their models that use
   brown word clusters (i.e., factored+br and coupled+br) yield overall
   best results. we expect this type of preprocessing to also increase the
   performance of our models, however we leave this to future work.
   finally, we should point out that titov and klementiev ([520]2012a) do
   not cluster adjunct-like modifier arguments that are already explicitly
   represented in syntax (e.g., tmp, loc, dir). thus, their coupled+mods
   model is most comparable to ours in terms of the id91 objective
   as it treats both core and adjunct arguments and does not make use of
   the brown id91. [521]table 6 shows the performance of
   coupled+mods on the gold/gold setting only because auto/gold results
   are not reported.

   [522]table
   table   6    semantic role induction with graph partitioning and bayesian
   id91.

   we further examined the output of the baseline and our best performing
   model in order to better understand where the performance gains are
   coming from. [523]table 7 shows how the two approaches differ when it
   comes to individual roles. we observe that the agglomerative id91
   algorithm performs better than the baseline on all core roles. there
   are some adjunct roles for which the baseline obtains a higher f1. this
   is not surprising because the parser directly outputs certain labels
   such as loc and tmp which results in high baseline scores for these
   roles. a word of caution is necessary here since core roles are defined
   individually for each verb and need not have a uniform corpus-wide
   interpretation. thus, conflating per-role scores across verbs is only
   meaningful to the extent that these labels actually signify the same
   role (which is mostly true for a0 and a1). furthermore, the purity
   scores we provide in this context are averages over the clusters for
   which the specified role is the majority role.

   [524]table
   table   7    results for individual roles on the auto/auto data set;
   comparison between the baseline and the agglomerative id91
   algorithm with the cosine similarity function. boldface highlights the
   best performing system according to purity, collocation, and f1.

   we further investigated the degree to which the baseline and the
   agglomerative id91 algorithm agree in their role assignments. the
   overall mean overlap was 46.03%. [525]figure 3a shows the percentage of
   verbs for which the baseline and our algorithm have no, some, or
   complete overlap. we discretized overlap into 10 bins of equal size
   ranging from 0 to 100. we observe that the role assignments produced by
   the two methods have nothing in common for approximately 13.6% verbs,
   whereas assignments are identical for 18.1% verbs. aside from these two
   bins (see 0 and 100 in [526]figure 3), a large number of verbs seems to
   exhibit overlap in the range of 40   60%. [527]figure 3b shows how the
   overlap in the cluster assignments varies with verb frequency. perhaps
   unsurprisingly, we can see that overlap is higher for least frequent
   and therefore less ambiguous verbs. in general, although the two
   methods have some degree of overlap, agglomerative id91 does
   indeed manage to change and improve the original role assignments of
   the baseline.
   [528]figure
   figure   3    role assignment overlap between the baseline and
   agglomerative id91 on the auto/auto data set. [529]figure 3a
   shows the percentage of verbs with no overlap (0%), 10% overlap, 20%
   overlap, 30% overlap, and so on. [530]figure 3b shows how role overlap
   varies with verb frequency. results are reported on the auto/auto data
   set.

   an interesting question concerns precisely the type of changes affected
   by the agglomerative id91 algorithm over the assignments of the
   baseline. to be able to characterize these changes we first examined
   the consistency of the role assignments created by the two algorithms.
   specifically, we would expect a verb-argument pair to be mostly
   assigned to the same cluster (i.e., an argument to bear the same role
   label for the same verb). of course this is not a hard constraint as
   arguments and predicates can be ambiguous and their roles may vary in
   specific syntactic configurations and contexts. to give an idea of an
   upper bound, in our gold standard, an argument instance of the same
   verb bears on average 2.23 distinct roles. for comparison, the baseline
   creates (on average) 2.9 role clusters for an argument, whereas
   agglomerative id91 yields more consistent assignments, with an
   average of 2.34 role clusters per argument.

   we further grouped the verbs in our data set into different bins
   according to their polysemy and allowable argument realizations.
   specifically, we followed levin's ([531]1993) taxonomy and grouped
   verbs according to the number of semantic classes they inhabit (e.g.,
   one, two, and so on). we also binned verbs according to the number of
   alternations they exhibit. to give an example, the verb donate is a
   member of the contribute class and participates in the
   causative/inchoative and dative alternations, whereas the verb shower
   is a member of four classes (i.e., spray/load, pelt, dress, and
   weather) and participates in the understood reflexive object and
   spray/load alternations. [532]figures 4a,[533]b show the overlap in
   role assignments between the baseline and agglomerative id91 and
   how it varies according to verb class ambiguity and argument structure;
   figures [534]4c,[535]d illustrate the same for role assignments and
   their consistency. as can be seen, there is less overlap between the
   two methods when the verbs in question are more polysemous
   ([536]figures 4a) or exhibit more variation in their argument structure
   ([537]figure 4b). as far as consistency in role assignments is
   concerned, agglomerative id91 appears overall more consistent
   than the baseline. as expected, the mean role assignment is slightly
   higher for polysemous verbs because differences in meaning manifest
   themselves in different argument realizations.
   [538]figure
   figure   4    comparison between the baseline and the agglomerative
   id91 algorithm in terms of role assignment overlap (a and b) and
   consistency (c and d). verbs are grouped according to polysemy (a and
   c) and number of alternations (b and d). all results are reported on
   the auto/auto data set.

   [539]figure 5 shows how purity, collocation, and f1 vary across
   alternations and verb classes. perhaps unsurprisingly, performance is
   generally better for least ambiguous verbs exhibiting a small number of
   alternations. in general, agglomerative id91 achieves higher
   purity across the board whereas the baseline achieves higher
   collocation. although agglomerative id91 achieves a consistently
   higher f1 over the baseline, the performance of the two algorithms
   converges for the most polysemous verbs (i.e., those inhabiting more
   than six semantic classes; see [540]figure 5f). interestingly, also
   note that f1 is comparable for verbs with less varied argument
   structure (i.e., verbs inhabiting one alternation; see [541]figure 5c).
   for such verbs the performance gap between the baseline and the
   agglomerative algorithm is narrower both in terms of purity and
   collocation. overall, we observe that agglomerative id91 is able
   to change some of the role assignments of the baseline for verbs
   exhibiting a good degree of alternations and polysemy.
   [542]figure
   figure   5    comparison between the baseline and the agglomerative
   id91 algorithm across alternations (a   c) and verb classes (d   f)
   using purity, collocation, and f1. all results are reported on the
   auto/auto data set.

   [543]table 8 reports results for 12 individual verbs for the best
   performing method (i.e., agglomerative partitioning using cosine
   similarity) on the auto/auto data set. these verbs were selected so as
   to exhibit varied occurrence frequencies and alternation patterns. as
   can be seen, the macroscopic result   higher f1 due to significantly
   higher purity   seems to consistently hold also across verbs. an
   important exception is the verb say, for which the baseline attains
   high scores due to little variation in its syntactic realization within
   the corpus. example output is given in [544]table 9, which shows the
   five largest clusters produced by the baseline and agglomerative
   partitioning for the verb increase. for each cluster we list the 10
   most frequent argument head lemmas. in this case, our method managed to
   induce an a0 cluster that is not present in the top five clusters of
   the baseline, although the cluster also incorrectly contains some a1
   arguments that stem from a false merge.

   [545]table
   table   8    results for individual verbs on the auto/auto data set;
   comparison between the baseline and our agglomerative id91
   algorithm with the cosine similarity function. boldface highlights the
   best performing system according to purity, collocation, and f1.

   [546]table
   table   9    five largest clusters created by the baseline and
   agglomerative partitioning for the verb increase. symbols $ and cd are
   used as placeholders for monetary units and cardinal numbers,
   respectively.

   6.   role induction experiments on german
   section:
   [choose___________________________]
   [547]previous section [548]next section

   the applicability of our method to arbitrary languages is important
   from a theoretical and practical perspective. on the one hand,
   linguistic theory calls for models which are universal and generalize
   across languages. this is especially true for models operating on the
   (frame-) semantic level, which is a generalization over surface
   structure and should therefore be less language specific (boas
   [549]2005). on the other hand, a language-independent model can be
   applied to arbitrary languages, genres, and domains and is thus of
   greater practical benefit. because our approach is based on the
   language-independent principles discussed in [550]section 1, we argue
   that it can easily generalize to other languages. to test this claim,
   we further applied our methods to german data.

   although on a high-level, german clauses do not differ drastically from
   english ones with respect to their frame-semantic make-up, there are
   differences in terms of how frame elements are mapped onto specific
   positions on the linear surface structure of a sentence, beyond any
   variations observed among english verbs. in general, german places
   fewer constraints on word order (more precisely phrase order) and
   instead relies on richer morphology to help disambiguate the
   grammatical functions of linguistic units. in particular, verbal
   nominal arguments are marked with a grammatical case[551]^6

   6   german has (partially ambiguous) markers for nominative, accusative,
   dative, and genitive.
   that directly indicates their grammatical function. although in main
   declarative clauses the inflected part of the verb has to occur in
   second position, german is commonly considered a verb-final language.
   this is because the verb often takes the final position in subordinate
   clauses, as do infinitive verbs (brigitta [552]1996).
   6.1   data

   we conducted our experiments on the salsa corpus (burchardt et al.
   [553]2006), a lexical resource for german, which, like framenet for
   english, associates predicates with frames. salsa is built as an extra
   annotation layer over the tiger corpus (brants et al. [554]2002), a
   treebank for german consisting of approximately 40,000 sentences
   (700,000 tokens) of newspaper text taken from the frankfurter
   rundschau, although to date not all predicate-argument structures have
   been annotated. the frame and role inventory of salsa was taken from
   framenet, but has been extended and adapted where necessary due to lack
   of coverage and cross-lingual divergences.

   the syntactic structure of a sentence is represented through a
   constituent tree whose terminal nodes are tokens and non-terminal nodes
   are phrases (see [555]figure 6). in addition to labeling each node with
   a constituent type such as sentence, noun phrase, and verb phrase, the
   edges between a parent and a child node are labeled according to the
   function of the child within the parent constituent, for example,
   accusative object, noun kernel, or head. edges can cross, allowing
   local and non-local dependencies to be encoded in a uniform way and
   eliminating the need for traces. this approach has significant
   advantages for non-configurational languages such as german, which
   exhibit a rich inventory of discontinuous constituents and considerable
   freedom with respect to word order (smith [556]2003). compared with the
   id32 (marcus, santorini, and marcinkiewicz [557]1993), tree
   structures are relatively flat. for example, the tree does not encode
   whether a constituent is a verbal argument or adjunct; this information
   is encoded through the edge labels instead.
   [558]figure
   figure   6    a sample parse tree for the sentence pr  sident jelzin
   verliert die mach ans k  chenkabinett und wird die wahlen kaum gewinnen
   k  nnen [translated in english as president jelzin loses power to the
   kitchen cabinet and will hardly be able to win the elections]. the
   parse tree contains phrase labels np (noun phrase), pp (prepositional
   phrase), vp (verb phrase), s (sentence), and cs (coordinated sentence).
   the dependency labels are nk (noun kernel), sb (subject), ao (object
   accusative), hd (head), mo (modifier), ac (adpositional case marker),
   cj (conjunct), and oc (clausal object).

   the frame annotations contained in salsa do not cover all of the
   predicate-argument structures of the underlying tiger corpus. only a
   subset of around 550 predicates with approximately 18,000 occurrences
   in the corpus have been annotated. moreover, only core roles are
   annotated, whereas adjunct roles are not, resulting in a smaller number
   of arguments per predicate (1.96 on average) compared with the conll
   2008 data set (2.57 on average) described in section 5.1. because our
   method is designed to induce verb-specific frames, we converted the
   salsa frames into propbank-like frames by splitting each frame into
   several verb-specific frames and accordingly mapping frame roles onto
   verb-specific roles. our data set is comparable to the german data set
   released as part of the conll 2009 shared task (haji   et al.
   [559]2009), which was also derived from the salsa corpus. however, we
   did not convert the original constituent-based salsa representation
   into dependencies, as we wanted to assess whether our methods are also
   compatible with phrase structure trees.
   6.2   experimental set-up

   although we follow the same experimental set-up as described in
   [560]section 5 for english, there are some deviations due to
   differences in the data sets utilized for the two languages. firstly,
   in contrast to the conll 2008 data set, the salsa data set (and the
   underlying tiger corpus) does not supply automatic parse trees and we
   therefore conducted our experiments on gold parses only. moreover,
   because adjunct arguments are not annotated in salsa, and because
   argument identification is not the central issue of this work, we chose
   to also consider only the gold argument identification. thus, all our
   experiments for german were carried out on the gold/gold data set.

   a substantial linguistic difference between the german and english data
   sets is the sparsity of the argument head lemmas, which is
   significantly higher for german than for english: in the conll 2008
   data set, the average number of distinct head lemmas per verb is only
   3.69, whereas in the salsa data set it is 20.12. this is partly due to
   the fact that the wall street journal text underlying the english data
   is topically more focused than the rundschau newspaper text, which
   covers a broader range of news beyond economics and politics. moreover,
   noun compounding is more commonly used in german than in english
   (corston-oliver and gamon [561]2004), which leads to higher lexical
   sparsity.

   data sparsity affects our method, which crucially relies on lexical
   similarity for determining the role-equivalence of clusters. therefore,
   we reduced the number of syntactic cues used for cluster initialization
   in order to avoid creating too many small clusters for which
   similarities cannot be reliably computed. specifically, only the
   syntactic position and function word served as cues to initialize our
   clusters. note that, as in english, the relatively small number of
   syntactic cues that determine the syntactic position within a linking
   is a consequence of the size of our evaluation data set (which is
   rather small) and not an inherent limitation of our method. on larger
   data sets, more syntactic cues could and should be incorporated in
   order to increase performance.

   in our experiments we compared the baseline introduced in [562]section
   5.3 against agglomerative partitioning and the label propagation
   algorithm using both cosine- and avgmax-similarity. the parameters   ,
     , and   , which determine the thresholds used in defining overall
   similarity scores, were set and updated identically as for english
   (i.e., these parameters can be considered language-independent).
   6.3   results

   [563]table 10 reports results for the baseline and our role induction
   methods, namely, agglomerative id91 and multi-layered label
   propagation (using the avgmax and cosine similarity functions) on the
   salsa gold/gold data set. for comparison, we also include results on
   the english conll-2008 gold/gold data set. as can be seen, the baseline
   obtains a similar f1 for german and english, although the contributions
   of purity and collocation are different for the two languages. in
   english, purity is noticeably higher than in german, whereas
   collocation is higher in german. this is not surprising when taking
   into account the distribution of syntactic relations governing an
   argument. a few frequent relation labels absorb most of the id203
   mass in german (see [564]figure 7b), whereas the mass is distributed
   more evenly among the labels in english ([565]figure 7a), thus leading
   to higher purity but lower collocation.

   [566]table
   table   10    results of agglomerative partitioning and label propagation
   for cosine and avgmax similarity on german. for comparison purposes
   results for english on the gold/gold data set are also tabulated. all
   improvements over the baseline are statistically significant at
   significance level q < 0.001.

   [567]figure
   figure   7    distribution of syntactic relations governing an argument in
   english and german data sets. only the most frequent relations are
   shown (a key for the english relations is given in [568]table 2; in
   german the relations are sb (subject), oa (object accusative), cj
   (conjunct), da (dative), cd (coordinator), mo (modifier), re
   (subordinate clause), rs (reported speech), oc (object clausal), op
   (object prepositional), nk (noun kernel), and cvc (collocational verb
   construction).

   in german, our role induction algorithms improve over the baseline in
   terms of f1. all four methods perform comparably and manage to strike a
   tradeoff between collocation and purity that is non-trivial and
   represents semantic roles adequately. compared with english, the
   difference between the baseline and our algorithms is narrower. this is
   because we use fewer syntactic cues for initialization in german, due
   to the increased data sparsity discussed in the previous section. this
   also explains why there is little variation in the collocation and
   purity results across methods. however, qualitatively the tradeoff
   between purity and collocation is the same as for english (i.e., purity
   is increased at the cost of collocation).

   [569]tables 11 and [570]12 show per-verb and per-role results,
   respectively, for agglomerative id91 using cosine similarity. we
   report per-verb scores for a selection of 10 verbs (see [571]table
   12a), which in some cases are translations of the verbs used for
   english. with respect to per-role scores, we make use of the fact that
   roles have a common meaning across predicates (like a0 and a1 in
   propbank), and report scores for a selection of 15 different roles
   ([572]table 12b) with varied occurrence frequencies. per-verb results
   confirm that data sparsity affects performance in german. as can be
   seen, agglomerative id91 outperforms the baseline on
   high-frequency verbs that are less affected by sparsity, although this
   is not always the case on lower-frequency verbs. analogously, the
   method tends to perform better on high-frequency roles, whereas there
   is no clear trend on lower-frequency roles. in contrast to english, for
   more than half of the verbs the method manages to outperform the
   baseline in terms of both purity and collocation, which is consistent
   with our macroscopic result, where the tradeoff between purity and
   collocation is not as strong as for english.

   [573]table
   table   11    results for individual verbs on the gold/gold salsa data set;
   comparison between the baseline and the agglomerative id91
   algorithm with the cosine similarity function.

   [574]table
   table   12    results for individual roles on gold/gold salsa data set;
   comparison between the baseline and the agglomerative id91
   algorithm with the cosine similarity function.

   the experiments show that our methods can be successfully applied to
   languages other than english, thereby supporting the claim that they
   are based on a set of language-independent assumptions and principles.
   despite substantial differences between german and english grammar,
   both generally and in terms of the specific syntactic representation
   that was used, our methods increased f1 over the baseline for both
   languages and resulted in a similar tradeoff between purity and
   collocation. improvements were observed in spite of pronounced data
   sparsity in the case of german. recall that we had to reduce the number
   of syntactic initialization cues in order to be able to obtain results
   on the relatively small amount of gold-standard data. we would also
   like to note that porting our system to german did not require any
   additional feature engineering or algorithmic changes.
   7.   conclusions
   section:
   [choose________________________]
   [575]previous section [576]next section

   in this article we described an unsupervised method for semantic role
   induction in which argument-instance graphs are partitioned into
   clusters representing semantic roles. a major hypothesis underlying our
   work has been that semantic roles can be induced without human
   supervision from a corpus of syntactically parsed sentences based on
   three linguistic principles : (1) arguments in the same syntactic
   position (within a specific linking) bear the same semantic role, (2)
   arguments within a clause bear a unique role, and (3) clusters
   representing the same semantic role should be more or less lexically
   and distributionally equivalent. based on these principles we have
   formulated a similarity-driven model and introduced a multi-layer graph
   partitioning approach that represents similarity between clusters on
   multiple feature layers, whose connectivity can be analyzed separately
   and then combined into an overall cluster-similarity score.

   our work has challenged the established view that supervised learning
   is the method of choice for the id14 task. although
   the proposed unsupervised models do yet achieve results comparable to
   their supervised counterparts, we have been able to show that they
   consistently outperform the syntactic baseline across several data sets
   that combine automatic and gold parses, with gold and automatic
   argument identification in english and german. our methods obtain f1
   scores that are systematically above the baseline and the purity of the
   induced clusters is considerably higher, although in most cases this
   increase in purity is achieved by decreasing collocation. in sum, these
   results provide strong empirical evidence towards the soundness of our
   method and the principles they are based on.

   in terms of modeling, we have contributed to the body of work on
   similarity-driven models by demonstrating their suitability for this
   problem, their effectiveness, and their computational efficiency. the
   models are based on judgments regarding the similarity of argument
   instances with respect to their semantic roles. we showed that these
   judgments are comparatively simple to formulate and incorporate into a
   graph representation of the data. we have introduced the idea of
   separating different similarity features into different graph layers,
   which resolves the problem faced by many similarity-based approaches of
   having to heuristically define an instance-wise similarity function and
   brings the advantage that cluster similarities can be computed in a
   more principled way. beyond id14, we hope that the
   multi-layered graph representation described here might be of relevance
   to other unsupervised problems such part-of-speech tagging or
   coreference resolution. the approach is general and amenable to other
   graph partitioning algorithms besides agglomeration and label
   propagation.

   there are two forms of data sparsity that arise in the context of our
   work, namely, the lexical sparsity of argument head lemmas and the
   sparsity of specific combinations of linking and syntactic position. as
   our methods are unsupervised, the conceptually simple solution to
   sparsity is to train on larger data sets. because, with some
   modifications, our graph partitioning approaches could be scaled to
   larger data sets (in terms of orders of magnitude), this is an obvious
   next step and would address both instances of data sparsity. firstly,
   it would allow us to incorporate a richer set of syntactic features for
   initialization and would therefore necessarily result in initial
   id91s of higher purity. secondly, the larger size of clusters
   would result in more reliable similarity scores. augmenting the data
   set would therefore almost surely increase the quality of induced
   id91s; however, we leave this to future work.

   another interesting future direction would be to eliminate the model's
   reliance on a syntactic parser that prohibits its application to
   languages for which parsing resources are not available. it would
   therefore be worthwhile, albeit challenging, to build models that
   operate on more readily available forms of syntactic analysis or even
   raw text. for example, existing work (abend and rappoport [577]2010b;
   abend, reichart, and rappoport [578]2009) attempts to identify
   arguments and distinguish them into core and adjunct ones through
   unsupervised part of speech and grammar induction. as much as making
   our model more unsupervised it would also be interesting to see whether
   some form of weak supervision might help induce higher-quality semantic
   roles without incurring a major labeling effort. the ideas conveyed in
   this article and the proposed methods extend naturally to this setting:
   introducing labels on some of the graph vertices would translate into a
   semi-supervised graph-based learning task, akin to zhu, ghahramani, and
   lafferty ([579]2003).
   appendix a. argument identification rules
   section:
   [choose_________________________]
   [580]previous section [581]next section

   this appendix specifies the full set of relations used by rules (2) and
   (4) of the argument identification rules given for english in
   [582]section 5.2, [583]table 1. the symbols     and     denote the
   direction of the dependency relation (upward and downward,
   respectively). the dependency relations are explained in surdeanu et
   al. ([584]2008), in their [585]table 4.

   the relations in rule (2) from [586]table 1 are im      , prt   , coord      ,
   p      , obj   , pmod   , adv   , sub      , root   , tmp   , sbj   , oprd   .

   the relations in rule (4) are adv      , amod      , appo      , bnf      -, conj      ,
   coord      , dir      , dtv      -, ext      , extr      , hmod      , iobj      , lgs      , loc      ,
   mnr      , nmod      , obj      , oprd      , posthon      , prd      , prn      , prp      , prt      ,
   put      , sbj      , sub      , suffix       tmp      , voc      .
   acknowledgments
   section:
   [choose________________________]
   [587]previous section [588]next section

   we are grateful to the anonymous referees, whose feedback helped to
   substantially improve this article. we also thank the members of the
   probabilistic models reading group at the university of edinburgh for
   helpful discussions and comments. we acknowledge the support of epsrc
   (grant ep/k017845/1).
   references
   section:
   [choose________________________]
   [589]previous section [590]next section
   abend, o. and a. rappoport. 2010a. fully unsupervised core-adjunct
   argument classification. in proceedings of the 48th annual meeting of
   the association for computational linguistics, pages 226   236, uppsala.
   [591]google scholar
   abend, o. and a. rappoport. 2010b. fully unsupervised core-adjunct
   argument classification. in proceedings of the annual meeting of the
   association for computational linguistics, pages 226   236, uppsala.
   [592]google scholar
   abend, o., r. reichart, and a. rappoport. 2009. unsupervised argument
   identification for id14. in proceedings of the annual
   meeting of the association for computational linguistics, pages 28   36,
   suntec. [593]crossref, [594]google scholar
   abney, s. 2007. semisupervised learning for computational linguistics.
   chapman & hall/crc. [595]crossref, [596]google scholar
   berg-kirkpatrick, t., a. bouchard-c  t  , j. denero, and d. klein. 2010.
   painless unsupervised learning with features. in proceedings of the
   conference of the north american chapter of the association for
   computational linguistics, pages 582   590, los angeles, ca. [597]google
   scholar
   biemann, c. 2006. chinese whispers: an efficient graph id91
   algorithm and its application to natural language processing problems.
   in proceedings of textgraphs: the first workshop on graph based methods
   for natural language processing, pages 73   80, new york, ny.
   [598]crossref, [599]google scholar
   boas, h. 2005. semantic frames as interlingual representations for
   multilingual lexical databases. international journal of id69,
   18(4):445   478. [600]crossref, [601]google scholar
   brants, s., s. dipper, s. hansen, w. lezius, and g. smith. 2002. the
   tiger treebank. in proceedings of the 1st workshop on treebanks and
   linguistic theories, pages 24   41, sozopol. [602]google scholar
   brigitta, h. 1996. deutsch ist eine v/2-sprache mit verbendstellung und
   freier wortfolge. in e. lang and g. zifonun, editors, deutsch   
   typologisch, pages 121   141. walter de gruyter. [603]google scholar
   brown, p. f., v. j. della pietra, p. v. desouza, j. c. lai, and r. l.
   mercer. 1992. class-based id165 models of natural language.
   computational linguistics, 18(4):283   298. [604]google scholar
   burchardt, a., k. erk, a. frank, a. kowalski, s. pad  , and m. pinkal.
   2006. the salsa corpus: a german corpus resource for lexical semantics.
   in proceedings of the international conference on language resources
   and evaluation, pages 969   974, genoa. [605]google scholar
   corston-oliver, s. and m. gamon. 2004. normalizing german and english
   inflectional morphology to improve statistical word alignment. in
   robert frederking and kathryn taylor, editors, machine translation:
   from real users to research, volume 3265 of lecture notes in computer
   science. springer, berlin heidelberg, pages 48   57.
   [606]crossref, [607]google scholar
   dowty, d. 1991. thematic proto roles and argument selection. language,
   67(3):547   619. [608]crossref, [609]google scholar
   f  rstenau, h. and m. lapata. 2009. graph alignment for semi-supervised
   id14. in proceedings of the conference on empirical
   methods in natural language processing, pages 11   20, singapore.
   [610]crossref, [611]google scholar
   gamallo, p., a. agustini, and g. lopes. 2005. id91 syntactic
   positions with similar semantic requirements. computational
   linguistics, 31(1):107   146. [612]link, [613]google scholar
   garg, n. and j. henderson. 2012. unsupervised semantic role induction
   with global role ordering. in proceedings of the 50th annual meeting of
   the association for computational linguistics (volume 2: short papers),
   pages 145   149, jeju island. [614]google scholar
   gildea, d. and d. jurafsky. 2002. automatic labeling of semantic roles.
   computational linguistics, 28(3):245   288. [615]link, [616]google
   scholar
   gordon, a. and r. swanson. 2007. generalizing semantic role annotations
   across syntactically similar verbs. in proceedings of the annual
   meeting of the association for computational linguistics, pages
   192   199, prague. [617]google scholar
   gordon, d. and m. desjardins. 1995. evaluation and selection of biases
   in machine learning. machine learning, 20:5   22. [618]google scholar
   grenager, t. and c. manning. 2006. unsupervised discovery of a
   statistical verb lexicon. in proceedings of the 2006 conference on
   empirical methods in natural language processing, pages 1   8, sydney.
   [619]crossref, [620]google scholar
   haji  , j., m. ciaramita, r. johansson, d. kawahara, m. a. mart  , l.
   m  rquez, a. meyers, j. nivre, s. pad  , j.   t  p  nek, p. stra    k, m.
   surdeanu, n. xue, and y. zhang. 2009. the conll 2009 shared task:
   syntactic and semantic dependencies in multiple languages. in
   proceedings of the thirteenth conference on computational natural
   language learning (conll 2009): shared task, pages 1   18, boulder, co.
   [621]crossref, [622]google scholar
   jain, a., m. murty, and p. flynn. 1999. data id91: a review. acm
   computing surveys, 31(3):264   323. [623]crossref, [624]google scholar
   kipper, k., h. t. dang, and m. palmer. 2000. class-based construction
   of a verb lexicon. in proceedings of the aaai conference on artificial
   intelligence, pages 691   696, austin, tx. [625]google scholar
   koomen, p., v. punyakanok, d. roth, and w. yih. 2005. generalized
   id136 with multiple id14 systems. in proceedings
   of the conference on computational natural language learning, pages
   181   184, ann arbor, mi. [626]crossref, [627]google scholar
   lang, j. and m. lapata. 2010. unsupervised induction of semantic roles.
   in proceedings of the north american chapter of the association for
   computational linguistics conference, pages 939   947, los angeles, ca.
   [628]google scholar
   lang, j. and m. lapata. 2011a. unsupervised induction of semantic roles
   via split-merge id91. in proceedings of the 49th annual meeting
   of the association for computational linguistics: human language
   technologies, pages 1,117   1,126, portland, or. [629]google scholar
   lang, j. and m. lapata. 2011b. unsupervised semantic role induction
   with graph partitioning. in proceedings of the conference on empirical
   methods in natural language processing, pages 1,320   1,331, edinburgh.
   [630]google scholar
   levin, b. and m. rappaport. 2005. argument realization. cambridge
   university press. [631]crossref, [632]google scholar
   levin, beth. 1993. english verb classes and alternations: a preliminary
   investigation. university of chicago press, chicago. [633]google
   scholar
   lin, d. and p. pantel. 2001. discovery of id136 rules for
   question-answering. natural langugae engineering, 7:343   360.
   [634]google scholar
   manning, c., p. raghavan, and h. sch  tze. 2008. introduction to
   information retrieval. cambridge university press.
   [635]crossref, [636]google scholar
   marcus, m., b. santorini, and m. marcinkiewicz. 1993. building a large
   annotated corpus of english: the id32. computational
   linguistics, 19(2):313   330. [637]google scholar
   m  rquez, l., x. carras, k. litkowski, and s. stevenson. 2008. semantic
   role labeling: an introduction to the special issue. computational
   linguistics, 34(2):145   159. [638]link, [639]google scholar
   melli, g., y. wang, y. liu, m. m. kashani, z. shi, b. gu, a. sarkar,
   and f. popowich. 2005. description of squash, the sfu question
   answering summary handler for the duc-2005 summarization task. in
   proceedings of the human language technology conference and the
   conference on empirical methods in natural language processing document
   understanding workshop, vancouver. [640]google scholar
   merlo, p. and s. stevenson. 2001. automatic verb classification based
   on statistical distributions of argument structure. computational
   linguistics, 27:373   408. [641]link, [642]google scholar
   munkres, j. 1957. algorithms for the assignment and transportation
   problems. journal of the society for industrial and applied
   mathematics, 5(1):32   38. [643]crossref, [644]google scholar
   nivre, j., j. hall, j. nilsson, g. eryigit, a. chanev, s. k  bler, s.
   marinov, and e. marsi. 2007. malt-parser: a language-independent system
   for data-driven id33. natural language engineering,
   13(2):95   135. [645]google scholar
   pad  , s. and m. lapata. 2009. cross-lingual annotation projection of
   semantic roles. journal of artificial intelligence research,
   36:307   340. [646]google scholar
   palmer, m., d. gildea, and p. kingsbury. 2005. the proposition bank: an
   annotated corpus of semantic roles. computational linguistics,
   31(1):71   106. [647]link, [648]google scholar
   poon, h. and p. domingos. 2009. unsupervised id29. in
   proceedings of the 2009 conference on empirical methods in natural
   language processing, pages 1   10, singapore. [649]crossref, [650]google
   scholar
   pradhan, s., w. ward, and j. martin. 2008. towards robust semantic role
   labeling. computational linguistics, 34(2):289   310.
   [651]link, [652]google scholar
   ruppenhofer, j., m. ellsworth, m. petruck, c. johnson, and j.
   scheffczyk. 2006. framenet ii: extended theory and practice, version
   1.3. technical report, international computer science institute,
   berkeley, ca. [653]google scholar
   schaeffer, s. 2007. graph id91. computer science review,
   1(1):27   64. [654]crossref, [655]google scholar
   shen, d. and m. lapata. 2007. using semantic roles to improve question
   answering. in proceedings of the 2007 joint conference on empirical
   methods in natural language processing and computational natural
   language learning (emnlp-conll), pages 12   21, prague. [656]google
   scholar
   smith, g. 2003. a brief introduction to the tiger treebank, version 1.
   technical report, university of potsdam. [657]google scholar
   surdeanu, m., s. harabagiu, j. williams, and p. aarseth. 2003. using
   predicate-argument structures for information extraction. in
   proceedings of the annual meeting of the association for computational
   linguistics, pages 8   15, sapporo. [658]crossref, [659]google scholar
   surdeanu, m., r. johansson, a. meyers, and l. m  rquez. 2008. the
   conll-2008 shared task on joint parsing of syntactic and semantic
   dependencies. in proceedings of the conference on natural language
   learning, pages 159   177, manchester. [660]crossref, [661]google scholar
   swier, r. and s. stevenson. 2004. unsupervised semantic role labelling.
   in proceedings of the conference on empirical methods in natural
   language processing, pages 95   102, barcelona. [662]google scholar
   titov, i. and a. klementiev. 2011. a bayesian model for unsupervised
   id29. in proceedings of the 49th annual meeting of the
   association for computational linguistics: human language technologies,
   pages 1,445   1,455, portland, or. [663]google scholar
   titov, i. and a. klementiev. 2012a. a bayesian approach to unsupervised
   semantic role induction. in proceedings of the 13th conference of the
   european chapter of the association for computational linguistics,
   pages 12   22, avignon. [664]google scholar
   titov, i. and a. klementiev. 2012b. crosslingual induction of semantic
   roles. in proceedings of the 50th annual meeting of the association for
   computational linguistics (volume 1: long papers), pages 647   656, jeju
   island. [665]google scholar
   van rijsbergen, c. 1974. foundation of evaluation. journal of
   documentation, 30(4):265   374. [666]crossref, [667]google scholar
   wu, d. and p. fung. 2009. semantic roles for smt: a hybrid two-pass
   model. in proceedings of human language technologies: the annual
   conference of the north american chapter of the association for
   computational linguistics, companion volume: short papers, pages 13   16,
   boulder, co. [668]crossref, [669]google scholar
   zhu, x., z. ghahramani, and j. lafferty. 2003. semi-supervised learning
   using gaussian fields and id94. in proceedings of the
   international conference on machine learning, pages 912   919,
   washington, dc. [670]google scholar
   joel lang*
   university of geneva
   mirella lapata**
   university of edinburgh

   *department of computer science, university of geneva, 7 route de
   drize, 1227 caid8, switzerland, e-mail: [671][email protected].

   **institute for language, cognition and computation, school of
   informatics, university of edinburgh, 10 crichton street, eh8 9ab,
   e-mail: [672][email protected].
   [673]forthcoming
   [674][preview-1489555631417.svg] download options
   [arrow-button-1488499533633.svg]

similarity-driven semantic role induction via graph partitioning

   [675]joel lang and [676]mirella lapata
   [677]https://doi.org/10.1162/coli_a_00195
   received: december 26, 2012
   accepted: november 20, 2013
   published online: september 05, 2014
     * [678]full text
     * [679]authors
     * [680]pdf
     * [681]pdf plus

abstract

   section:
   [choose________________________]
   [682]next section

   as in many natural language processing tasks, data-driven models based
   on supervised learning have become the method of choice for semantic
   role labeling. these models are guaranteed to perform well when given
   sufficient amount of labeled training data. producing this data is
   costly and time-consuming, however, thus raising the question of
   whether unsupervised methods offer a viable alternative. the working
   hypothesis of this article is that semantic roles can be induced
   without human supervision from a corpus of syntactically parsed
   sentences based on three linguistic principles: (1) arguments in the
   same syntactic position (within a specific linking) bear the same
   semantic role, (2) arguments within a clause bear a unique role, and
   (3) clusters representing the same semantic role should be more or less
   lexically and distributionally equivalent. we present a method that
   implements these principles and formalizes the task as a graph
   partitioning problem, whereby argument instances of a verb are
   represented as vertices in a graph whose edges express similarities
   between these instances. the graph consists of multiple edge layers,
   each one capturing a different aspect of argument-instance similarity,
   and we develop extensions of standard id91 algorithms for
   partitioning such multi-layer graphs. experiments for english and
   german demonstrate that our approach is able to induce semantic role
   clusters that are consistently better than a strong baseline and are
   competitive with the state of the art.
      2014 association for computational linguistics
   1.   introduction
   section:
   [choose________________________]
   [683]previous section [684]next section

   recent years have seen increased interest in the shallow semantic
   analysis of natural language text. the term is often used to describe
   the automatic identification and labeling of the semantic roles
   conveyed by sentential constituents (gildea and jurafsky [685]2002).
   semantic roles describe the relations that hold between a predicate and
   its arguments (e.g.,    who    did    what    to    whom   ,    when   ,    where   , and
      how   ) abstracting over surface syntactic configurations. this type of
   semantic information is shallow but relatively straightforward to infer
   automatically and useful for the development of broad-coverage,
   domain-independent language understanding systems. indeed, the analysis
   produced by existing semantic role labelers has been shown to benefit a
   wide spectrum of applications ranging from information extraction
   (surdeanu et al. [686]2003) and id53 (shen and lapata
   [687]2007), to machine translation (wu and fung [688]2009) and
   summarization (melli et al. [689]2005).

   in the example sentences below, window occupies different syntactic
   positions   it is the object of broke in sentences (1a,b), and the
   subject in (1c). in all instances, it bears the same semantic role,
   that is, the patient or physical object affected by the breaking event.
   analogously, ball is the instrument of break both when realized as a
   prepositional phrase in (1a) and as a subject in (1b).

   also notice that all three instances of break in example (1) have
   apparently similar surface syntax with a subject and a noun directly
   following the predicate. however, in sentence (1a) the subject of break
   expresses the agent role, in (1b) it expresses the instrument role, and
   in (1c) the patient role.

   the examples illustrate the fact that predicates can license several
   alternate mappings or linkings between their semantic roles and their
   syntactic realization. pairs of linkings allowed by a single predicate
   are often called diathesis alternations (levin [690]1993). sentence
   pair (1a,b) is an example of the instrument subject alternation, and
   pair (1b,c) illustrates the causative alternation. resolving the
   mapping between the syntactic dependents of a predicate (e.g., subject,
   object) and the semantic roles that they each express is one of the
   major challenges faced by semantic role labelers.

   the semantic roles in the examples are labeled in the style of propbank
   (palmer, gildea, and kingsbury [691]2005), a broad-coverage
   human-annotated corpus of semantic roles and their syntactic
   realizations. under the propbank annotation framework each predicate is
   associated with a set of core roles (named a0, a1, a2, and so on) whose
   interpretations are specific to that predicate[692]^1

   1   more precisely, a0 and a1 have a common interpretation across
   predicates as proto-agent and proto-patient in the sense of dowty
   ([693]1991).
   and a set of adjunct roles such as location or time whose
   interpretation is common across predicates (e.g., last night in
   sentence (1c)). the availability of propbank and related resources
   (e.g., framenet; ruppenhofer et al. [694]2006) has sparked the
   development of a variety id14 systems, most of which
   conceptualize the task as a supervised learning problem and rely on
   role-annotated data for model training. most of these systems implement
   a two-stage architecture consisting of argument identification
   (determining the arguments of the verbal predicate) and argument
   classification (labeling these arguments with semantic roles). current
   approaches deliver reasonably good performance   a system will recall
   around 81% of the arguments correctly and 95% of those will be assigned
   a correct semantic role (see m  rquez et al. [[695]2008] for details),
   although only on languages and domains for which large amounts of
   role-annotated training data are available.

   unfortunately, the reliance on labeled data, which is both difficult
   and expensive to produce, presents a major obstacle to the widespread
   application of id14 across different languages and
   text genres. although corpora with semantic role annotations exist
   nowadays in other languages (e.g., german, spanish, catalan, chinese,
   korean), they tend to be smaller than their english equivalents and of
   limited value for modeling purposes. even within english, a language
   for which two major annotated corpora are available, systems trained on
   propbank demonstrate a marked decrease in performance (approximately by
   10%) when tested on out-of-domain data (pradhan, ward, and martin
   [696]2008). the data requirements for supervised systems and the
   current paucity of such data has given impetus to the development of
   unsupervised methods that learn from unlabeled data. if successful,
   unsupervised approaches could lead to significant resource savings and
   the development of semantic role labelers that require less engineering
   effort. besides being interesting on their own right, from a
   theoretical and linguistic perspective, unsupervised methods can
   provide valuable features for downstream (supervised) processing and
   serve as a preprocessing step for applications that require broad
   coverage understanding. in this article we study the potential of
   unsupervised methods for id14. as in the supervised
   case, we decompose the problem into an argument identification step and
   an argument classification step. our work primarily focuses on argument
   classification, which we term role induction, because there is no
   predefined set of semantic roles in the unsupervised case, and these
   must be induced from data. the goal is to assign argument instances to
   clusters such that each cluster contains arguments corresponding to a
   specific semantic role and each role corresponds to exactly one
   cluster.

   unsupervised learning is known to be challenging for many natural
   language processing problems and role induction is no exception.
   firstly, it is difficult to define a learning objective function whose
   optimization will yield an accurate model. this contrasts with the
   supervised setting, where the objective function can directly reflect
   training error (i.e., some estimate of the mismatch between model
   output and the gold standard) and the model can be tuned to replicate
   human output for a given input under mathematical guarantees regarding
   the accuracy of the trained model. secondly, it is also more difficult
   to incorporate rich feature sets into an unsupervised model
   (berg-kirkpatrick et al. [697]2010). unless we explicitly know exactly
   how features interact, more features may not necessarily lead to a more
   accurate model and may even decrease performance. in the supervised
   setting, feature interactions relevant for a particular learning task
   can be determined to a large extent automatically and thus a large
   number of them can be included even if their significance is not clear
   a priori.

   the lack of an extensional definition (in the form of training
   examples) of the target concept makes a strong case for the development
   of unsupervised methods that use problem specific prior knowledge. the
   idea is to derive a strong inductive bias (gordon and desjardins
   [698]1995) based on this prior knowledge that will guide the learning
   towards the correct target concept. for semantic role induction, we
   propose to build on the following linguistic principles:
   1.   

   semantic roles are unique within a particular frame.
   2.   

   arguments occurring in a specific syntactic position within a specific
   linking all bear the same semantic role.
   3.   

   the (asymptotic) distribution over argument heads is the same for two
   clusters that represent the same semantic role.

   we hypothesize that these three principles are, at least in theory,
   sufficient for inducing high-quality semantic role clusters. a
   challenge, of course, lies in adequately operationalizing them so that
   they guide the unsupervised learner towards meaningful solutions. the
   approach taken in this article translates these principles into
   estimates of similarity (or dissimilarity) between argument instances
   and/or clusters of argument instances. principle (1) states that
   argument instances occurring in the same frame (i.e., clause) cannot
   bear the same semantic role, and are thus dissimilar. from principle
   (2) it follows that arguments occurring in the same syntactic position
   within the same linking can be considered similar (leaving aside for
   the moment the difficulty of representing linkings through syntactic
   cues observable in a corpus). principle (3) states that two clusters of
   instances containing similar distributions over head words should be
   considered similar.

   based on these similarity estimates we construct a graph whose vertices
   represent argument instances and whose edges express similarities
   between these instances. the graphs consist of multiple edge layers,
   each capturing one particular type of argument-instance similarity. for
   example, one layer will be used to represent whether argument instances
   occur in the same frame, and another layer will represent whether two
   arguments have a similar head word, and so on. given this graph
   representation of the data, we formalize role induction as the problem
   of partitioning the graph into clusters of similar vertices. we present
   two algorithms for partitioning multi-layer graphs, which are
   adaptations of standard graph partitioning algorithms to the
   multi-layer setting. the algorithms differ in the way they exploit the
   similarity information encoded in the graph. the first one is based on
   agglomeration, where two clusters containing similar instances are
   grouped into a larger cluster. the second one is based on propagation,
   where role-label information is transferred from one cluster to another
   based on their similarity.

   to understand how the aforementioned principles might allow us to
   handle the ambiguity id30 from alternate linkings, consider again
   example (1). the most important thing to note is that, whereas the
   subject position is ambiguous with respect to the semantic roles it can
   express (it can be a0, a1, or a2), we can resolve the ambiguity by
   exploiting overt syntactic cues of the underlying linking. for example,
   the predicate break is transitive in sentences (1a) and (1b), and
   intransitive in sentence (1c). thus, by taking into account the
   argument's syntactic position and the predicate's transitivity, we can
   guess that the semantic role expressed by the subject in sentence (1c)
   is different from the roles expressed by the subjects in sentences
   (1a,b). now consider the more difficult case of distinguishing between
   the subjects in sentences (1a) and (1b). one linking cue that could
   help here is the prepositional phrase in sentence (1a), which results
   in a syntactic frame different from sentence (1b). were the
   prepositional phrase omitted, we would attempt to disambiguate the
   linkings by resorting to lexical-semantic cues (e.g., by taking into
   account whether the subject is animate). in sum, if we encode
   sufficiently many linking cues, then the resulting fine-grained
   syntactic information will discriminate ambiguous semantic roles. in
   cases where syntactic cues are not discerning enough, we can exploit
   lexical information and group arguments together based on their lexical
   content.

   the remainder of this article is structured as follows. [699]section 2
   provides an overview of unsupervised methods for semantic role
   labeling. [700]sections 3 and [701]4 present the details of our method,
   that is, how the graphs are constructed and partitioned. role induction
   experiments in english and german are described in [702]sections 5 and
   [703]6, respectively. discussion of future work concludes in
   [704]section 7.
   2.   related work
   section:
   [choose________________________]
   [705]previous section [706]next section

   the bulk of previous work on id14 has focused on
   supervised methods (m  rquez et al. [707]2008), although a few
   semi-supervised and unsupervised approaches have been proposed. the
   majority of semi-supervised models have been developed within a
   framework known as annotation projection. the idea is to combine
   labeled and unlabeled data by projecting annotations from a labeled
   source sentence onto an unlabeled target sentence within the same
   language (f  rstenau and lapata [708]2009) or across different languages
   (pad   and lapata [709]2009). beyond annotation projection, gordon and
   swanson ([710]2007) propose to increase the coverage of propbank to
   unseen verbs by finding syntactically similar (labeled) verbs and using
   their annotations as surrogate training data.

   swier and stevenson ([711]2004) were the first to introduce an
   unsupervised id14 system. their algorithm induces
   role labels following a id64 scheme where the set of labeled
   instances is iteratively expanded using a classifier trained on
   previously labeled instances. their method starts with a data set
   containing no role annotations at all, but crucially relies on verbnet
   (kipper, dang, and palmer [712]2000) for identifying the arguments of
   predicates and making initial role assignments. verbnet is a manually
   constructed lexicon of verb classes, each of which is explicitly
   associated with argument realization and semantic role specifications.

   in this article we will not assume the availability of any
   role-semantic resources, although we do assume that sentences are
   syntactically analyzed. there have been two main approaches to role
   induction from parsed data. under the first approach, semantic roles
   are modeled as latent variables in a (directed) graphical model that
   relates a verb, its semantic roles, and their possible syntactic
   realizations (grenager and manning [713]2006). role induction here
   corresponds to inferring the state of the latent variables representing
   the semantic roles of arguments. following up on this work, lang and
   lapata ([714]2010) reformulate role induction as the process of
   detecting alternations and finding a canonical syntactic form for them.
   verbal arguments are then assigned roles, according to their position
   in this canonical form, because each position references a specific
   role. their model extends the logistic classifier with hidden variables
   and is trained in a manner that takes advantage of the close
   relationship between syntactic functions and semantic roles. more
   recently, garg and henderson ([715]2012) extend the latent-variable
   approach by modeling the sequential order of roles.

   the second approach is similarity-driven and based on id91. lang
   and lapata ([716]2011a) propose an algorithm that first splits the set
   of all argument instances of a verb according to their syntactic
   position within a particular linking and then iteratively merges
   clusters. a different clusstering algorithm is adopted in lang and
   lapata ([717]2011b). specifically, they induce semantic roles via graph
   partitioning: each vertex in the graph corresponds to an argument
   instance and edges represent a heuristically defined measure of their
   lexical and syntactic similarity. the similarity-driven approach has
   been recently adopted by titov and klementiev ([718]2012a), who propose
   a bayesian id91 algorithm based on the chinese restaurant
   process. in addition, they present a method that shares linking
   preferences across verbs using a distance-dependent chinese restaurant
   process prior which encourages similar verbs to have similar linking
   preferences. titov and klementiev ([719]2012b) further introduce the
   use of multilingual data for improving role induction.

   there has also been work on unsupervised methods for argument
   identification. abend, reichart, and rappoport ([720]2009) devise a
   method for recognizing the arguments of predicates that relies solely
   on part of speech annotations, whereas abend and rappoport ([721]2010a)
   distinguish between core and adjunct roles, using an unsupervised
   parser and part-of-speech tagger. more generally, shallow semantic
   representations induced from syntactic information are commonly used in
   lexicon acquisition and information extraction tasks. for example, lin
   and pantel ([722]2001) cluster syntactic relations between pairs of
   words as expressed by parse tree paths into semantic relations by
   exploiting lexical distributional similarity. although not compatible
   with propbank or semantic roles as such, poon and domingos ([723]2009)
   and titov and klementiev ([724]2011) also induce semantic information
   from dependency parses and apply it to a id53 task for
   the biomedical domain. another example is the work by gamallo,
   agustini, and lopes ([725]2005), who cluster similar syntactic
   positions in order to develop models of selectional preferences to be
   used for word sense induction and the resolution of attachment
   ambiguities.

   the work described here unifies the two id91 methods presented in
   lang and lapata ([726]2011a and [727]2011b) by reformulating them as
   graph partitioning algorithms. it also extends them by utilizing
   multi-layer graphs which separate the similarities between instances on
   different features (e.g., part-of-speech, argument head) into different
   layers. this has the advantage that similarity scores on individual
   features do not have to be eagerly combined into a similarity score
   between instances. instead, one can first aggregate the similarity
   scores on each feature layer between two clusters and then combine them
   into a similarity score between clusters. this is more robust, as the
   feature-wise similarity scores between clusters can be computed in a
   principled way and the heuristic combination step is deferred to the
   end (see [728]section 4 for details). besides providing a general
   modeling framework for semantic role induction, we discuss in detail
   the linguistic principles guiding our modeling choices and assess their
   applicability across languages. specifically, we show that the
   framework presented here (and the aforementioned principles) can be
   readily applied to english and german with identical parametrizations
   for both languages and without fundamentally changing the underlying
   model features, despite major syntactic differences between the two
   languages.
   3.   graph construction
   section:
   [choose________________________]
   [729]previous section [730]next section

   we begin by explaining how we construct a graph that represents verbs
   and their arguments. next, we describe how edge weights are
   computed   these translate to similarity scores between argument
   instances   and then move on to provide the details of our
   graph-partitioning algorithms.

   as mentioned earlier, we formalize semantic role induction as a
   id91 problem. id91 algorithms (see jain, murty, and flynn
   [[731]1999] for an overview) commonly take a matrix of pairwise
   similarity scores between instances as input and produce a set of
   output clusters, often satisfying some explicitly defined optimality
   criterion. the success or failure of the id91 approach is closely
   tied to the adequacy of the employed similarity function for the task
   at hand. the graph partitioning view of id91 (see schaeffer
   [[732]2007] for a detailed treatment) arises when instances are
   represented as the vertices of a graph and the similarity matrix is
   interpreted as the weight matrix of the graph. for semantic role
   induction, a straightforward application of id91 would be to
   construct a graph for each verbal predicate such that vertices
   correspond to argument instances of the verb and edge weights quantify
   the similarity between these instances.

   lang and lapata ([733]2011b) hand-craft an instance similarity function
   by taking into account different features such as the argument head or
   its syntactic position. defining an appropriate instance-wise
   similarity function is nevertheless problematic as weights have to be
   chosen heuristically. instead, we will represent similarities with
   respect to different features on separate edge layers in the graph. for
   example, one layer will represent the similarity between the head words
   of arguments and another one will represent the similarity between pars
   of speech. so, given m features, the graph will consist of m layers,
   one for each feature. edge weights on a particular layer quantify the
   similarity between the instances with respect to that feature. this is
   illustrated in [734]figure 1 for two argument instances and three
   features. formally, a multi-layer graph is defined as a pair (v, {e[1],
       , e[m]}) consisting of vertices v and a set of edge layers e[f] for f
   = 1     m. the set of vertices v = {v[1],     , v[n]} consists of all n
   argument instances for a particular verb. the edge layer e[f] for
   feature f is constructed by connecting all vertex-pairs with non-zero
   similarity with respect to f:

   where   [f](v[i],v[j]) is a similarity function for feature f, whose
   form will be discussed in the next section. each edge (v[i],v[j])    
   e[f]in layer f is weighted by   [f](v[i],v[j]).
   [735]figure
   figure   1    a multi-layer graph consists of multiple edge layers, one for
   each similarity feature. multi-layer graph partitioning algorithms
   exploit this representation by computing separate similarity scores
   between clusters for each feature layer and then combining them into a
   single overall similarity score. this is advantageous over single-layer
   graph partitioning because it avoids eagerly combining the similarity
   scores for individual features into a heuristic instance-wise
   similarity score.
   3.1   feature similarity functions

   similarities for a specific feature f are measured with a function
     [f](v[i],v[j]) which assigns a [   1,1] value to any pair of instances
   (v[i],v[j]). we assume similarities are measured on an interval
   scale   that is, while sums, differences, and averages of the values of
   some similarity function   [f] express meaningful quantities, products
   and ratios do not. moreover, the values of two distinct similarity
   functions cannot necessarily be meaningfully compared without
   rescaling. positive similarity values indicate that the semantic roles
   are likely to be the same, negative values indicate that roles are
   likely to differ, and zero values indicate that there is no evidence
   for either case. the magnitude of   [f] expresses the degree of
   confidence in the similarity judgment, with extreme values (i.e.,    1
   and 1) indicating maximal confidence.

   in our model, we simply use indicator functions which output either 1
   or    1 iff feature values are equal and 0 otherwise. specifically, we
   define four feature similarity functions that we derive from the
   principles discussed in [736]section 1. our similarity functions are
   based on the following features: the argument head words and their
   parts of speech,[737]^2

   2   we include parts of speech as a simple means of alleviating the
   sparsity of head words.
   the frame constraint, and the syntactic position within a particular
   linking. we measure lexical and part-of-speech similarity as follows:

   the constraint that two argument instances v[i] and v[j] occurring in
   the same frame cannot have the same semantic role is captured by the
   following similarity function:

   finally, we also measure syntactic similarity through an indicator
   function   [syn](v[i],v[j]), which assumes value 1 if two instances
   occur in the same syntactic position within the same linking:

   the syntactic position of an argument is directly given by the parse
   tree and can be encoded, for example, by the full path from predicate
   to argument head, or for practical purposes, in order to reduce
   sparsity, simply through the relation governing the argument head and
   its linear position relative to the predicate (left or right). in
   contrast, linkings are not directly observed, but we can resort to
   overt syntactic cues as a proxy. examples include the verb's voice
   (active/passive), whether it is transitive, the part-of-speech of the
   subject, and so on. we argue that in principle, if sufficiently many
   cues are taken into account, they will capture one particular linking,
   although there may be several encodings for the same linking. note that
   syntactic similarity is not used to construct another graph layer;
   rather, it will be used for deriving initial clusters of instances, as
   we explain in [738]section 4.1.
   4.   graph partitioning
   section:
   [choose________________________]
   [739]previous section [740]next section

   the graph partitioning problem consists of finding a set of clusters
   {c[1],     , c[s]} that form a partition of the vertex-set, namely,
      [i]c[i] = v and c[i]     c[j] =     for all i     j, such that (ideally)
   each cluster contains argument instances of only one particular
   semantic role, and the instances for a particular role are all assigned
   to one and the same cluster. in the following sections we provide two
   algorithms for multi-layer graph partitioning, based on standard
   id91 algorithms for single-layer graphs. both algorithms operate
   on the same graph but differ in terms of the underlying id91
   mechanism they use. the first algorithm is an adaptation of
   agglomerative id91 (jain, murty, and flynn [741]1999) to the
   multi-layer setting: starting from an initial id91, the algorithm
   iteratively merges vertex clusters in order to arrive at increasingly
   accurate representations of semantic roles. rather than greedily
   merging clusters, our second algorithm is based on propagating cluster
   membership information among the set of initial clusters (abney
   [742]2007).

   4.1   agglomerative graph partitioning

   the agglomerative algorithm induces clusters in a bottom   up manner
   starting from an initial cluster assignment that we will subsequently
   discuss in detail. our initialization results in a id91 that has
   high purity but low collocation, that is, argument instances in each
   cluster tend to belong to the same role but argument instances of a
   particular role are scattered among many clusters.[743]^3

   3   we define the terms purity and collocation more formally in
   [744]section 5.4.
   the algorithm then improves collocation by iteratively merging pairs of
   clusters. the agglomeration procedure is described in algorithm 1 . as
   can be seen, pairs of clusters are merged iteratively until a
   termination criterion is met. the decision of which cluster pair to
   merge at each step is made by scoring a set of candidate cluster pairs
   and choosing the highest one (line 5). the scoring function s(c[i],
   c[j   ]) quantifies how likely two clusters are to contain arguments of
   the same role. a key question is how to define this scoring function on
   the basis of the underlying graph representation, that is, with
   reference to the instance similarities expressed by the edges. in order
   to collect evidence for or against a merge, we take into account the
   connectivity of a cluster pair at each feature layer of the graph. this
   crucially involves aggregating over all edges that connect the two
   clusters, and allows us to infer a cluster-level similarity score from
   the individual instance-level similarities encoded in the edges. the
   evidence collected at each layer is then combined together in order to
   arrive at an overall decision (see [745]figure 1 for an illustration).

   although it would be possible to enumerate and score all possible
   cluster pairs at each step, we apply a more efficient and effective
   procedure in which the set of candidates consists of pairs formed by
   combining a fixed cluster c[i] with all clusters larger than c[i]. this
   requires comparing only o(|c|) rather than o(|c|^2) scores and, more
   importantly, it favors merges between large clusters whose score can be
   computed more reliably. as mentioned earlier, our scoring function
   implements an averaging procedure over the instances contained in the
   clusters, and thus yields less noisy scores when clusters are large
   (i.e., contain many instances). this prioritization promotes reliable
   merges over less reliable ones in the earlier phases of the algorithm
   with a positive effect on merges in the later phases. moreover, by
   keeping c[i] fixed, we only require that scores s(c[i],x) and s(c[i],z)
   are comparable (i.e., where one cluster is argument in both scores),
   rather than comparisons between arbitrary cluster pairs (e.g., s(w,x)
   and s(y,z)). in the following, we will provide details on the
   initialization of the algorithm and the computation of the similarity
   scoring function.

   a standard agglomerative id91 algorithm forms clusters bottom   up
   by initially placing each item of interest in its own cluster. in our
   case, initializing the algorithm with as many clusters as argument
   instances would result in a id91 with maximal purity and minimal
   collocation. there are two reasons that justify a more sophisticated
   initialization procedure for our problem. firstly, the scoring function
   we use is more reliable for larger clusters than for smaller clusters
   (see the subsequent discussion). in fact, the standard initialization
   that creates clusters with a single instance would not yield useful
   results as our scoring function crucially relies on initial clusters
   containing several instances on average. secondly, the similarity
   scores for different features are not directly comparable. recall from
   [746]section 3.1 that we introduced different types of similarities
   based on the arguments' head words (  [lex]), parts-of-speech (  [pos]),
   syntactic positions (  [syn]), and frame constraints (  [frame]). as
   discussed earlier, engineering a scoring function that integrates these
   into a single score without resorting to heuristic judgments on how to
   weight them poses a major challenge. in particular, it is difficult to
   weight the contribution of the two forms of positive evidence given by
   lexical and syntactic similarity. this motivates the idea of using
   syntactic similarity for initialization, and lexical similarity (as
   well as the frame constraint) for scoring. this separation avoids the
   difficulty of defining the exact interaction between the two.
   specifically, we obtain an initial id91 by grouping together all
   instances which occur in the same syntactic position within a
   linking   that is, all pairs (v[i], v[j]) for which   [syn](v[i], v[j]) =
   1 are grouped into the same cluster, assuming that arguments occurring
   in a specific syntactic position under a specific linking share the
   same role.

   we specify the syntactic position of an argument using four cues: the
   verb's voice (active/passive), the argument's linear position relative
   to the predicate (left/right), the syntactic relation of the argument
   to its governor (e.g., subject or object), and the preposition used for
   realizing the argument (if any). each argument is assigned a four-tuple
   consisting of these cues and two syntactic positions are assumed equal
   iff they agree on all cues.

   whereas the similarity functions defined in [747]section 3.1 measure
   role-semantic similarity between instances on a particular feature, the
   scoring function measures role-semantic similarity between clusters.
   naturally, the similarity between two clusters is defined in terms of
   the similarities of the instances contained in the clusters. this
   involves two aggregation stages. initially, instance similarities are
   aggregated in each feature layer, resulting in an aggregate score for
   each feature. these layer-specific scores are then integrated into a
   single score, which quantifies the overall similarity between the two
   clusters (see [748]figure 1).

   an obvious way to determine the similarity between two clusters (with
   respect to a particular feature f) would be to analyze their
   connectivity. for example, we could use edge density (schaeffer
   [749]2007) to average over the weights of edges between two clusters.
   however, edge density is an inappropriate measure of similarity in our
   case, because we cannot assume that arbitrary pairs of instances are
   similar with respect to a particular feature, even if two clusters
   represent the same semantic role. consider for example lexical
   similarity: most head words will not agree (even within a cluster) and
   therefore averaging between all pairs would yield low scores,
   regardless of whether the clusters represent the same role or not.
   analogously, the vast majority of instance pairs from any two clusters
   will belong to different frames, and thus averaging over all possible
   pairs of instances would not yield indicative scores.

   we therefore adopt an averaging procedure which finds, for each
   instance in one cluster, the instance in the other cluster that is
   maximally similar or dissimilar and averages over the scores of these
   alignments:

   here, abs max is a functional that returns the extreme value of its
   argument, either positive or negative: abs max[x   x] g(x) = g(arg
   max[x   x] |g(x)|). note that the alignments are unconstrained in the
   sense that v[a]     c[k] can be aligned to v[b]     c[l] in the first term
   of [750]equation (6), while v[b] can be aligned to some other instance
   in the second term. moreover, alignments in each term are many-to-one,
   namely, multiple instances from c[k] can be aligned to the same v[b]    
   c[l] in the first term and likewise in the second term. this means that
   score aggregation does not reflect the distributional properties of
   clusters (e.g., the frequency of head words in each cluster). consider
   for example two clusters with an identical set of head words. because
   many-to-one alignments are allowed, each instance can be aligned with
   maximal score to some other instance regardless of the frequencies of
   these words.

   as an alternative, we also use the well-known cosine similarity
   function   although only for the features based on argument head words
   (lex) and parts of speech (pos):

   here and are vector representations of the cluster containing as
   components the occurrence frequencies of a particular value of the
   feature f (i.e., lex and pos in our case). another solution would be to
   enforce one-to-one alignments and redefine [751]equation (6) as the
   optimal bipartite matching between the two clusters. although this
   solution adheres to the graph formulation (in contrast to [752]equation
   (7)) we see no theoretical reason that makes it superior to cosine
   similarity. moreover, its computation would require cubic runtime in
   the number of vertices using the hungarian algorithm (munkres
   [753]1957), which is prohibitively slow for sufficiently large
   clusters.

   layer-specific similarity scores must be combined into an overall
   cluster similarity score. because similarity scores and their
   aggregates for different features are not directly comparable, their
   combination through summation would require weighting each layer score
   according to its relative strength. due to the difficulty of specifying
   these weights without access to labeled training data, we propose an
   alternative scheme that is based on the distinction between positive
   and negative evidence. negative evidence is used to rule out a merge,
   whereas positive evidence provided by the lexical score is used to
   score merges that have not yet been ruled out:

   when the part-of-speech similarity is below a certain threshold   , or
   when clause-level constraints are satisfied to a lesser extent than
   threshold   , the score takes value    1 and the merge is ruled out. if
   the merge is not ruled out, the lexical similarity score determines the
   magnitude of the overall score, provided that it is above threshold   .
   otherwise, the function returns 0, indicating that neither strong
   positive nor negative evidence is available. the cluster-similarity
   scoring function can be viewed as the decision function of a binary
   classifier for deciding on whether to merge a particular pair of
   clusters. the classifier is informed by the similarity scores for each
   feature layer and outputs a confidence-weighted decision
   (positive/negative), where the sign sgn(  [f](v[i], v[j])) indicates the
   decision and the absolute value |  [f](v[i],v[j])| quantifies
   confidence. the scoring function in [754]equation (8) essentially
   implements a simple decision list classifier, whose decision rules are
   sequentially inspected from top to bottom, applying the first matching
   rule.

   although our definition avoids weighting, it has introduced threshold
   parameters   ,   , and    that we need to somehow estimate. we propose a
   scheme in which parameters    and    are iteratively adjusted, and   , the
   threshold determining the extent to which the frame constraints can be
   violated, is kept fixed. we heuristically set    to     0.05, based on the
   intuition that in principle frame constraints must be satisfied
   although in practice, due to noise we expect a small number of
   violations (i.e., at most 5% of instances can violate the constraint).
   parameters    and    are initially set to their maximal value 1, thereby
   ruling out all merges except those with maximal confidence. the
   parameters then decrease iteratively according to a routine whose
   pseudo-code is specified in algorithm 2 . the parameter    decreases at
   each iteration by a small amount (0.025) until it reaches    = 0.025, at
   which point its value is reset to 1.0 and    is discounted by a factor
   close to one (0.9). this is repeated until    falls below   , upon which
   the algorithm terminates.

   runtime analysis. as described in the previous section, algorithm 1
   stops when the threshold    falls below some small value   . both    and   
   iteratively decrease based on a fixed scheme. the outer loop and
   starting in line 1 is therefore computed in constant time t. each pass
   through the inner loop starting at line 4 iterates over o(|c|) clusters
   and for each one of them a score with o(|c|) other clusters is
   computed. assume that f[i] denotes the fraction of all v instances in
   cluster c[i], namely, f[i] v = |c[i]| and . then, overall, the number
   of instance-wise similarities we need to evaluate is at most o(|v|^2):

   the total runtime in terms of the input is therefore o(t   |v|^2).
   although this could be prohibitively inefficient for large data sets,
   we did not observe long runtimes in our experiments. various
   optimizations are conceivable   for example, the cluster similarity
   scores in line 5 of algorithm 1 can be cached such that they only need
   to be recomputed when a cluster changes (i.e., it is merged with
   another cluster).
   4.2   multi-layer label propagation

   our second graph partitioning algorithm is based on the idea of
   propagating cluster membership information along the edges of a graph,
   subsequently referred to as propagation graph. as we explain in more
   detail subsequently, compared with agglomerative id91, this
   algorithm in principle is less prone to making false greedy decisions
   that cannot be later revoked. moreover, it has lower runtime and thus
   scales better to larger data sets.

   the propagation graph is created by collapsing vertices of the initial
   multi-layer graph. vertices in the propagation graph represent an
   atomic set of instances of the original graph, that is, a group of
   instances that are always assigned to the same cluster. for our
   induction problem, the vertices of the propagation graph correspond to
   the initial clusters of the agglomerative algorithm discussed in
   [755]section 4.1. more formally, let a[i]     a denote the i-th vertex of
   the propagation graph, which references an atomic cluster of vertices
   of the original graph that occur in the same syntactic position within
   the same linking. because each vertex of the propagation graph
   corresponds to a cluster of vertices in the original graph, the edges
   of the propagation graph can be defined in terms of the edges between
   these vertices in the original graph. we reuse [756]equations (6) and
   [757](7) to define the edge weights of the propagation graph as
   aggregates over the edge weights in the original graph. for each
   feature layer we define the set of edges as:

   each edge (a[i], a[j])     b[f] in layer f is accordingly weighted by
   s[f](a[i], a[j]). each vertex a[i] is associated with a label l[i],
   indicating the partition that a[i] and all the vertices in the original
   graph that have been collapsed into a[i] belongs to.

   note that the label propagation algorithm is informed by the same
   similarity functions as agglomerative id91 and uses an identical
   initialization procedure but provides an alternative means of cluster
   id136. initially, each vertex of the propagation graph belongs to
   its own cluster, that is, we let the number of clusters l = |a| and set
   l[i]     i. given this initial vertex labeling, the algorithm proceeds by
   iteratively updating the label for each vertex (lines 4   10 in algorithm
   3). this crucially relies on a scoring procedure in which a score s(l)
   is computed for each possible label l. we discuss the details of the
   scoring procedure below.

   the label scoring procedure required in line 5 of algorithm 3 has
   parallels to the cluster pair scoring procedure of the agglomerative
   algorithm. it also consists of two stages: initially, evidence is
   collected independently on each feature layer by computing label score
   aggregates with respect to each feature and then these feature scores
   are combined in order to arrive at an overall score.

   assume we are updating vertex a[i]. the first step is to compute the
   score for each feature f and each label l:

   where denotes the set of a[i]'s neighbors with label l that are larger
   than a[i]. intuitively, each neighboring vertex votes for the cluster
   it is currently assigned to, where the strength of the vote is
   determined by the similarity to the vertex (i.e., edge weight) being
   updated. the votes of all (larger) neighboring vertices are counted
   together, resulting in a score for each possible label. the condition
   of including only larger vertices for computing the score is analogous
   to the prioritization mechanism of the agglomerative algorithm (only
   merges with larger clusters are considered for a given candidate
   cluster). we impose this restriction for the same reason, namely, that
   scores for larger clusters are more reliable.

   given the scores s[f](l) for a particular label l on each layer f, our
   goal then is to combine them into a single overall score s(l) for the
   label. as in agglomerative partitioning, combining these scores through
   summation is not possible without    guessing    their weights, and
   therefore we use a sequential combination instead:

   analogously to [758]equation (8), negative evidence that stems from
   part-of-speech information or frame constraints can veto a propagation,
   whereas positive evidence id30 from argument head words can promote
   a propagation. if neither strong evidence (positive or negative) is
   available, the label is assigned a zero score. note that the scoring
   function has three parameters with an identical interpretation to those
   in the scoring function of the agglomerative algorithm. the threshold
   update that takes place in line 11 of algorithm 3 is therefore the same
   as the one described in [759]section 4.1 for the agglomerative
   algorithm.

   we now analyze the runtime of our algorithm. let t denote the number of
   iterations of the outer loop starting at line 1 of algorithm 3 . the
   inner loop starting at line 4 iterates over |a| clusters and for each
   one of them it has to evaluate at most |a| neighboring nodes.
   additionally, there are the one-time costs of computing the
   similarities between atomic clusters which take o(|v|^2) time. the
   total runtime is therefore o(t |a|^2 + |v|^2). because |a|^2 < < |v|^2,
   label propagation is substantially faster than agglomerative
   id91.

   4.3   relationship to single-layer graph partitioning

   id91 algorithms typically assume instance-wise similarities as
   input (i.e., single-layer graphs). for our role induction problem, this
   would require a heuristically defined similarity function that combines
   the similarities on individual features into a single similarity score
   between instances. in other words, we would collapse the multiple graph
   layers into a single layer and then partition the resulting
   single-layer graph according to a standard id91 algorithm. a main
   difference between the two approaches is the order in which
   similarities are aggregated: whereas multi-layer graph partitioning
   aggregates similarities on each feature layer first and then combines
   them into an overall cluster-wise similarity score, in the single-layer
   case feature similarities are eagerly combined into an overall
   instance-wise similarity score and then aggregated. thus, in the
   multi-layer setting, aggregation can be done in a principled way by
   considering the individual feature layers in isolation. for large
   clusters the resulting scores for each feature layer will provide
   reliable evidence for or against a merge. combining these cluster-wise
   similarity scores is much less error-prone than the eager combination
   at the instance-level used by the single-layer approach. we
   experimentally confirm this intuition (see [760]section 5.5) by
   comparing against the single-layer partitioning algorithm presented in
   lang and lapata ([761]2011b).
   5.   role induction experiments on english
   section:
   [choose___________________________]
   [762]previous section [763]next section

   we adopt the general architecture of supervised id14
   systems where argument identification and argument classification are
   treated separately. our role labeler is fully unsupervised with respect
   to both tasks   it does not rely on any role annotated data or semantic
   resources. however, our system does not learn from raw text. in common
   with most id14 research, we assume that the input is
   syntactically analyzed. our approach is not tied to a specific
   syntactic representation   both constituent- and dependency-based
   representations can be used. the bulk of our experiments focus on
   english data and a dependency-based representation that simplifies
   argument identification considerably and is consistent with the conll
   2008 benchmark data set used for evaluation in our experiments. to show
   that our method can be applied to other languages and across varying
   syntactic representations, we also report experiments on german using a
   constituent-based representation (see [764]section 6).

   given the parse of a sentence, our system identifies argument instances
   and assigns them to clusters. thereafter, argument instances can be
   labeled with an identifier corresponding to the cluster they have been
   assigned to, similar to propbank core labels (e.g., a0, a1). we view
   argument identification as a syntactic processing step that can be
   largely undertaken deterministically through analysis of the syntactic
   tree. we therefore use a small set of rules to detect arguments with
   high precision and recall. in the following, we first describe the data
   set ([765]section 5.1) on which our experiments were carried out. next,
   we present the argument identification component of our system
   ([766]section 5.2) and the method used for comparison with our
   approach. finally, we explain how system output was evaluated
   ([767]section 5.4).
   5.1   data

   for evaluation purposes, we ran our method on the conll 2008 shared
   task data set (surdeanu et al. [768]2008), which provides propbank
   style gold standard annotations. as our algorithm induces verb-specific
   roles, propbank annotations are a natural choice of gold standard for
   our problem. the data set contains annotations for verbal and nominal
   predicate-argument constructions, but we only considered the former.
   the conll data set was taken from the wall street journal portion of
   the id32 and converted into a dependency format (surdeanu et
   al. [769]2008). input sentences are represented in the dependency
   syntax specified by the conll 2008 shared task (see [770]figure 2 for
   an example). in addition to gold standard dependency parses, the data
   set also contains automatic parses obtained from the maltparser (nivre
   et al. [771]2007), which we will use as an alternative in our
   experiments in order to assess the impact of parse quality. for each
   argument only the head word is annotated with the corresponding
   semantic role, rather than the whole constituent. we assume that
   argument heads are content words (e.g., the head of a prepositional
   phrase is the nominal head rather than the preposition). we do not
   treat split arguments or co-referential arguments (e.g., in relative
   clauses). specifically, we ignore arguments with roles preceded by the
   c- or r- prefix in the gold standard. all argument lemmas were
   normalized to lower case; we also replaced numerical quantities with a
   placeholder; to further reduce data sparsity, we identified the head of
   proper noun phrases heuristically as the most frequent lemma contained
   in the phrase.
   [772]figure
   figure   2    a sample dependency parse with dependency labels sbj
   (subject), obj (object), nmod (nominal modifier), oprd (object
   predicative complement), prd (predicative complement), and im
   (infinitive marker).
   5.2   argument identification

   in the supervised setting, a classifier is used in order to decide for
   each node in the parse tree whether it represents a semantic argument
   or not. nodes classified as arguments are then assigned a semantic
   role. in the unsupervised setting, we slightly reformulate argument
   identification as the task of discarding as many non-semantic arguments
   as possible. this means that the argument identification component does
   not make a final positive decision for any of the argument candidates;
   instead, this decision is deferred to role induction.[773]^4

   4   a few supervised systems implement a similar definition (koomen et
   al. [774]2005), although in most cases the argument identification
   component makes a final positive or negative decision regarding the
   status of an argument candidate.
   we assume here that predicate identification is a precursor to argument
   identification and can be done relatively straightforwardly based on
   part-of-speech information.

   the rules given in [775]table 1 are used to discard or select argument
   candidates for english. they primarily take into account the parts of
   speech and the syntactic relations encountered when traversing the
   dependency tree from predicate to argument. a priori, all words in a
   sentence are considered argument candidates for a given predicate.
   then, for each candidate, the rules are inspected sequentially and the
   first matching rule is applied. we will exemplify how the argument
   identification component works for the predicate expect in the sentence
   the company said it expects its sales to remain steady whose parse tree
   is shown in [776]figure 2. initially, all words except the predicate
   itself are treated as argument candidates. then, the rules from
   [777]table 1 are applied as follows. firstly, the words the and to are
   discarded based on their part of speech (rule 1); then, remain is
   discarded because the path ends with the relation im and said is
   discarded as the path ends with an upward-leading obj relation (rule
   2). rule 3 matches to it, which is therefore added as a candidate.
   next, steady is discarded because there is a downward-leading oprd
   relation along the path and the words company and its are also
   discarded because of the obj relations along the path (rule 4). rule 5
   does not apply but the word sales is kept as a likely argument (rule
   6). finally, rule 7 does not apply, because there are no candidates
   left.

   [778]table
   table   1    argument identification rules for english.

   on the conll 2008 training set, our argument identification rules
   obtain a precision of 87.0% and a recall of 92.1% on gold standard
   parses. on automatic parses, precision is 79.3% and recall 84.8%. here,
   precision measures the percentage of selected arguments that are actual
   semantic arguments, and recall measures the percentage of actual
   arguments that are not filtered out.

   grenager and manning ([779]2006) also devise rules for argument
   identification, unfortunately without providing any details on their
   implementation. more recently, attempts have been made to identify
   arguments without relying on a treebank-trained parser (abend and
   rappoport [780]2010b; abend, reichart, and rappoport [781]2009). the
   idea is to combine a part-of-speech tagger and an unsupervised parser
   in order to identify constituents. likely arguments can be in turn
   identified based on a set of rules and the degree of collocation with
   the predicate. perhaps unsurprisingly, this method does not match the
   quality of a rule-based component operating over trees produced by a
   supervised parser.
   5.3   baseline method for semantic role induction

   the linking between semantic roles and syntactic positions is not
   arbitrary; specific semantic roles tend to map onto specific syntactic
   positions such as subject or object (levin and rappaport [782]2005;
   merlo and stevenson [783]2001). we further illustrate this observation
   in [784]table 2, which shows how often individual semantic roles map
   onto certain syntactic positions. the latter are simply defined as the
   relations governing the argument. the frequencies in the table were
   obtained from the conll 2008 data set and are aggregates across
   predicates. as can be seen, semantic roles often approximately
   correspond to a single syntactic position. for example, a0 is commonly
   mapped onto subject (sbj), whereas a1 is often realized as object
   (obj).

   [785]table
   table   2    contingency table between syntactic position and semantic
   roles. only the eight most frequent syntactic positions and their
   labels are listed (i.e., sbj (subject), obj (object), adv (adverbial),
   tmp (temporal), pmod (preposition and its child), oprd (object
   complement), loc (location), dir (direction)). counts were obtained
   from the conll 2008 training data set using gold standard parses. the
   marginals in the right-most column include all syntactic positions (not
   only the eight most frequent ones). boldface highlights the most
   frequent role per syntactic position (e.g., sbj is frequently a0, obj
   is a1).

   this motivates a baseline that directly assigns instances to clusters
   according to their syntactic position. the pseudo-code is given in
   algorithm 4. for each verb we allocate n = 22 clusters (the maximal
   number of gold standard clusters together with a default cluster).
   apart from the default cluster, each cluster is associated with a
   syntactic position and all instances occurring in that position are
   mapped into the cluster. despite being relatively simple, this baseline
   has been previously used as a point of comparison by other unsupervised
   id14 systems (grenager and manning [786]2006; lang
   and lapata [787]2010) and shown difficult to outperform. this is partly
   due to the fact that almost two thirds of the propbank arguments are
   either a0 or a1. identifying these two roles correctly is therefore the
   most important distinction to make, and because this can be largely
   achieved on the basis of the arguments' syntactic position (see
   [788]table 2), the baseline yields high scores.
   5.4   evaluation

   in this section we describe how we assess the quality of a role
   induction method that assigns labels to units that have been identified
   as likely arguments. we also discuss how we measure whether differences
   in model performance are statistically significant.

   arguments are labeled based on the cluster they have been assigned to,
   which means that in contrast to the supervised setting we cannot verify
   the correctness of these labels directly (e.g., by comparing them to
   the gold standard). instead, we will look at the induced clusters as a
   whole and assess their quality in terms of how well they reflect the
   assumed gold standard. specifically, for each verb, we determine the
   extent to which argument instances in the clusters share the same gold
   standard role (purity) and the extent to which a particular gold
   standard role is assigned to a single cluster (collocation).

   more formally, for each group of verb-specific clusters we measure
   cluster purity as the percentage of instances belonging to the majority
   gold class in their respective cluster. let n denote the total number
   of instances, g[j] the set of instances belonging to the j-th gold
   class, and c[i] the set of instances belonging to the i-th cluster.
   purity can be then written as

   collocation is the inverse of purity (van rijsbergen [789]1974) and
   defined as follows. for each gold role, we determine the cluster with
   the largest number of instances for that role (the role's primary
   cluster) and then compute the percentage of instances that belong to
   the primary cluster for each gold role:

   per-verb scores are aggregated into an overall score by averaging over
   all verbs. we use the micro-average obtained by weighting the scores
   for individual verbs proportionately to the number of instances for
   that verb. finally, we use the harmonic mean of purity and collocation
   as a single measure of id91 quality:

   purity and collocation measure essentially the same data traits as
   precision and recall, which in the context of id91 are, however,
   defined on pairs of instances (manning, raghavan, and sch  tze
   [790]2008), which makes them a bit harder to grasp intuitively. we
   therefore prefer purity and collocation, arguing that these should be
   assessed in combination or together with f1 because they can be traded
   off against each other. purity can be trivially maximized by mapping
   each instance into its own cluster, and collocation can be trivially
   maximized by mapping all instances into a single cluster.

   although it is desirable to report performance with a single score such
   as f1, it is equally important to assess how purity and collocation
   contribute to this score. in particular, if a hypothetical system were
   to be used for automatically annotating data, low collocation would
   result in higher annotation effort and low purity would result in lower
   data quality. therefore high purity is imperative for an effective
   system whereas high collocation contributes to efficient data labeling.
   for assessing our methods we therefore introduce the following
   terminology. if a model attains higher purity than the baseline, we
   will say that it is adequate, because it induced roles that adequately
   represent semantic roles. if a model attains higher f1 than the
   baseline, we will say that it is non-trivial, because it strikes a
   tradeoff between collocation and purity that is non-trivial. our goal
   then is to find models that are both adequate and non-trivial.

   in order to assess whether differences in performance between two
   models are statistically significant, we used a sign test.
   specifically, we obtained a series of score pairs by testing two
   methods on a subsample of the test data. each subsample corresponds to
   a random selection of m = 2,000. we consider the resulting samples to
   be    sufficiently    independent to obtain indicative results from the
   test. as null hypothesis (h[0]) we assume that a model m attains scores
   equal to another model b. under h[0] the id203 that model m
   outperforms model b on a particular test set is . the random variable s
   counting the number of times that score[m] > score[b] in a sample of n
   score pairs is binomially distributed:

   we can therefore use s as our test statistic and reject the null
   hypothesis h[0] if .
   5.5   results

   our results are summarized in [791]tables 3   [792]5, which report
   cluster purity (pu), collocation (co), and their harmonic mean (f1) for
   the baseline and our two multi-layer graph partitioning algorithms. we
   present scores on four data sets that result from the combination of
   automatic parses with automatically identified arguments (auto/auto),
   gold parses with automatic arguments (gold/auto), automatic parses with
   gold arguments (auto/gold), and gold parses with gold arguments
   (gold/gold). we show how performance varies for our methods when
   measuring cluster similarity in the two ways described above: (a) by
   finding for each instance in one cluster the instance in the other
   cluster that is maximally similar or dissimilar and averaging over the
   scores of these alignments (avgmax) and (b) by using cosine similarity
   (see [793]section 4.1). we also report results for the single-layer
   algorithm proposed in lang and lapata ([794]2011b).[795]^5

   5   the results in [796]table 5 differ slightly from those published in
   lang and lapata ([797]2011b). this is due to a small change in the
   preprocessing of the data. for all english experiments reported here,
   we removed arguments with r- and c- role prefixes and replaced numbers
   with a placeholder.
   given a verbal predicate, they construct a single-layer graph whose
   edge weights express instance-wise similarities directly. the graph is
   partitioned into vertex clusters representing semantic roles using a
   variant of chinese whispers, a graph id91 algorithm proposed by
   biemann ([798]2006). the algorithm iteratively assigns cluster labels
   to graph vertices by greedily choosing the most common label among the
   neighbors of the vertex being updated.

   [799]table
   table   3    results for agglomerative partitioning (for avgmax and cosine
   similarity). f1 improvements over the baseline are statistically
   significant in all settings (q < 0.001). boldface highlights the best
   performing system according to purity, collocation, and f1.

   [800]table
   table   4    results for multi-layered label propagation (for avgmax and
   cosine similarity). f1 improvements over the baseline are statistically
   significant in all settings (q < 0.001). boldface highlights the best
   performing system according to purity, collocation, and f1.

   [801]table
   table   5    results for single-layered label propagation using a heuristic
   similarity function. f1 improvements over the baseline are
   statistically significant (q < 0.001) in the auto/gold and gold/gold
   settings. boldface highlights the best performing system according to
   purity, collocation, and f1.

   both agglomerative partitioning and multi-layered label propagation
   algorithms systematically achieve higher f1 scores than the
   baseline   that is, induce non-trivial id91s and more adequate
   semantic roles (by attaining higher purity). for example, on the
   auto/auto data set, the agglomerative algorithm using cosine similarity
   increases f1 by 2.3 points over the baseline and by 7.2 points in terms
   of purity. this increase in purity is achieved by trading off against
   collocation, although in a favorable ratio as indicated by the overall
   higher f1. all improvements over the baseline are statistically
   significant (q < 0.001 according to the test described in [802]section
   5.4). in general, we observe that cosine similarity outperforms avgmax
   similarity. we conjecture that cosine is a more appropriate measure of
   cluster similarity for features where it is beneficial to capture the
   distributional similarity of clusters. the two algorithms perform
   comparably   differences in f1 are not statistically significant (except
   in the gold/auto setting). nevertheless, agglomerative partitioning
   obtains higher purity and f1 than label propagation. the latter trades
   off more purity and in return obtains higher collocation. the
   single-layer method is inferior to the multi-layer algorithms, in
   particular because it is less robust to noise, as demonstrated by the
   markedly worse results on automatic parses. on the auto/auto data set
   the single-layered algorithm is on a par with the baseline and
   marginally outperforms it on the auto/gold and gold/gold
   configurations.

   to help put our results in context, we compare our methods with titov
   and klementiev's ([803]2012a) bayesian id91 models. they report
   results on the conll 2008 data sets with two model variants, a factored
   model that models each verb independently and a coupled model where
   model parameters are shared across verbs. in an attempt to reduce the
   sparsity of the argument fillers, they also present variants of the
   factored and coupled models where the argument heads have been replaced
   by lexical cluster ids id30 from brown et al.'s ([804]1992)
   id91 algorithm on the rcv1 corpus. in [805]table 6 we follow
   titov and klementiev ([806]2012a) and show results on the gold/gold and
   gold/auto settings. as can be seen, both the agglomerative id91
   and label propagation perform comparably to their coupled model, even
   though they do not implement any specific mechanism for sharing
   id91 preferences across verbs. versions of their models that use
   brown word clusters (i.e., factored+br and coupled+br) yield overall
   best results. we expect this type of preprocessing to also increase the
   performance of our models, however we leave this to future work.
   finally, we should point out that titov and klementiev ([807]2012a) do
   not cluster adjunct-like modifier arguments that are already explicitly
   represented in syntax (e.g., tmp, loc, dir). thus, their coupled+mods
   model is most comparable to ours in terms of the id91 objective
   as it treats both core and adjunct arguments and does not make use of
   the brown id91. [808]table 6 shows the performance of
   coupled+mods on the gold/gold setting only because auto/gold results
   are not reported.

   [809]table
   table   6    semantic role induction with graph partitioning and bayesian
   id91.

   we further examined the output of the baseline and our best performing
   model in order to better understand where the performance gains are
   coming from. [810]table 7 shows how the two approaches differ when it
   comes to individual roles. we observe that the agglomerative id91
   algorithm performs better than the baseline on all core roles. there
   are some adjunct roles for which the baseline obtains a higher f1. this
   is not surprising because the parser directly outputs certain labels
   such as loc and tmp which results in high baseline scores for these
   roles. a word of caution is necessary here since core roles are defined
   individually for each verb and need not have a uniform corpus-wide
   interpretation. thus, conflating per-role scores across verbs is only
   meaningful to the extent that these labels actually signify the same
   role (which is mostly true for a0 and a1). furthermore, the purity
   scores we provide in this context are averages over the clusters for
   which the specified role is the majority role.

   [811]table
   table   7    results for individual roles on the auto/auto data set;
   comparison between the baseline and the agglomerative id91
   algorithm with the cosine similarity function. boldface highlights the
   best performing system according to purity, collocation, and f1.

   we further investigated the degree to which the baseline and the
   agglomerative id91 algorithm agree in their role assignments. the
   overall mean overlap was 46.03%. [812]figure 3a shows the percentage of
   verbs for which the baseline and our algorithm have no, some, or
   complete overlap. we discretized overlap into 10 bins of equal size
   ranging from 0 to 100. we observe that the role assignments produced by
   the two methods have nothing in common for approximately 13.6% verbs,
   whereas assignments are identical for 18.1% verbs. aside from these two
   bins (see 0 and 100 in [813]figure 3), a large number of verbs seems to
   exhibit overlap in the range of 40   60%. [814]figure 3b shows how the
   overlap in the cluster assignments varies with verb frequency. perhaps
   unsurprisingly, we can see that overlap is higher for least frequent
   and therefore less ambiguous verbs. in general, although the two
   methods have some degree of overlap, agglomerative id91 does
   indeed manage to change and improve the original role assignments of
   the baseline.
   [815]figure
   figure   3    role assignment overlap between the baseline and
   agglomerative id91 on the auto/auto data set. [816]figure 3a
   shows the percentage of verbs with no overlap (0%), 10% overlap, 20%
   overlap, 30% overlap, and so on. [817]figure 3b shows how role overlap
   varies with verb frequency. results are reported on the auto/auto data
   set.

   an interesting question concerns precisely the type of changes affected
   by the agglomerative id91 algorithm over the assignments of the
   baseline. to be able to characterize these changes we first examined
   the consistency of the role assignments created by the two algorithms.
   specifically, we would expect a verb-argument pair to be mostly
   assigned to the same cluster (i.e., an argument to bear the same role
   label for the same verb). of course this is not a hard constraint as
   arguments and predicates can be ambiguous and their roles may vary in
   specific syntactic configurations and contexts. to give an idea of an
   upper bound, in our gold standard, an argument instance of the same
   verb bears on average 2.23 distinct roles. for comparison, the baseline
   creates (on average) 2.9 role clusters for an argument, whereas
   agglomerative id91 yields more consistent assignments, with an
   average of 2.34 role clusters per argument.

   we further grouped the verbs in our data set into different bins
   according to their polysemy and allowable argument realizations.
   specifically, we followed levin's ([818]1993) taxonomy and grouped
   verbs according to the number of semantic classes they inhabit (e.g.,
   one, two, and so on). we also binned verbs according to the number of
   alternations they exhibit. to give an example, the verb donate is a
   member of the contribute class and participates in the
   causative/inchoative and dative alternations, whereas the verb shower
   is a member of four classes (i.e., spray/load, pelt, dress, and
   weather) and participates in the understood reflexive object and
   spray/load alternations. [819]figures 4a,[820]b show the overlap in
   role assignments between the baseline and agglomerative id91 and
   how it varies according to verb class ambiguity and argument structure;
   figures [821]4c,[822]d illustrate the same for role assignments and
   their consistency. as can be seen, there is less overlap between the
   two methods when the verbs in question are more polysemous
   ([823]figures 4a) or exhibit more variation in their argument structure
   ([824]figure 4b). as far as consistency in role assignments is
   concerned, agglomerative id91 appears overall more consistent
   than the baseline. as expected, the mean role assignment is slightly
   higher for polysemous verbs because differences in meaning manifest
   themselves in different argument realizations.
   [825]figure
   figure   4    comparison between the baseline and the agglomerative
   id91 algorithm in terms of role assignment overlap (a and b) and
   consistency (c and d). verbs are grouped according to polysemy (a and
   c) and number of alternations (b and d). all results are reported on
   the auto/auto data set.

   [826]figure 5 shows how purity, collocation, and f1 vary across
   alternations and verb classes. perhaps unsurprisingly, performance is
   generally better for least ambiguous verbs exhibiting a small number of
   alternations. in general, agglomerative id91 achieves higher
   purity across the board whereas the baseline achieves higher
   collocation. although agglomerative id91 achieves a consistently
   higher f1 over the baseline, the performance of the two algorithms
   converges for the most polysemous verbs (i.e., those inhabiting more
   than six semantic classes; see [827]figure 5f). interestingly, also
   note that f1 is comparable for verbs with less varied argument
   structure (i.e., verbs inhabiting one alternation; see [828]figure 5c).
   for such verbs the performance gap between the baseline and the
   agglomerative algorithm is narrower both in terms of purity and
   collocation. overall, we observe that agglomerative id91 is able
   to change some of the role assignments of the baseline for verbs
   exhibiting a good degree of alternations and polysemy.
   [829]figure
   figure   5    comparison between the baseline and the agglomerative
   id91 algorithm across alternations (a   c) and verb classes (d   f)
   using purity, collocation, and f1. all results are reported on the
   auto/auto data set.

   [830]table 8 reports results for 12 individual verbs for the best
   performing method (i.e., agglomerative partitioning using cosine
   similarity) on the auto/auto data set. these verbs were selected so as
   to exhibit varied occurrence frequencies and alternation patterns. as
   can be seen, the macroscopic result   higher f1 due to significantly
   higher purity   seems to consistently hold also across verbs. an
   important exception is the verb say, for which the baseline attains
   high scores due to little variation in its syntactic realization within
   the corpus. example output is given in [831]table 9, which shows the
   five largest clusters produced by the baseline and agglomerative
   partitioning for the verb increase. for each cluster we list the 10
   most frequent argument head lemmas. in this case, our method managed to
   induce an a0 cluster that is not present in the top five clusters of
   the baseline, although the cluster also incorrectly contains some a1
   arguments that stem from a false merge.

   [832]table
   table   8    results for individual verbs on the auto/auto data set;
   comparison between the baseline and our agglomerative id91
   algorithm with the cosine similarity function. boldface highlights the
   best performing system according to purity, collocation, and f1.

   [833]table
   table   9    five largest clusters created by the baseline and
   agglomerative partitioning for the verb increase. symbols $ and cd are
   used as placeholders for monetary units and cardinal numbers,
   respectively.

   6.   role induction experiments on german
   section:
   [choose___________________________]
   [834]previous section [835]next section

   the applicability of our method to arbitrary languages is important
   from a theoretical and practical perspective. on the one hand,
   linguistic theory calls for models which are universal and generalize
   across languages. this is especially true for models operating on the
   (frame-) semantic level, which is a generalization over surface
   structure and should therefore be less language specific (boas
   [836]2005). on the other hand, a language-independent model can be
   applied to arbitrary languages, genres, and domains and is thus of
   greater practical benefit. because our approach is based on the
   language-independent principles discussed in [837]section 1, we argue
   that it can easily generalize to other languages. to test this claim,
   we further applied our methods to german data.

   although on a high-level, german clauses do not differ drastically from
   english ones with respect to their frame-semantic make-up, there are
   differences in terms of how frame elements are mapped onto specific
   positions on the linear surface structure of a sentence, beyond any
   variations observed among english verbs. in general, german places
   fewer constraints on word order (more precisely phrase order) and
   instead relies on richer morphology to help disambiguate the
   grammatical functions of linguistic units. in particular, verbal
   nominal arguments are marked with a grammatical case[838]^6

   6   german has (partially ambiguous) markers for nominative, accusative,
   dative, and genitive.
   that directly indicates their grammatical function. although in main
   declarative clauses the inflected part of the verb has to occur in
   second position, german is commonly considered a verb-final language.
   this is because the verb often takes the final position in subordinate
   clauses, as do infinitive verbs (brigitta [839]1996).
   6.1   data

   we conducted our experiments on the salsa corpus (burchardt et al.
   [840]2006), a lexical resource for german, which, like framenet for
   english, associates predicates with frames. salsa is built as an extra
   annotation layer over the tiger corpus (brants et al. [841]2002), a
   treebank for german consisting of approximately 40,000 sentences
   (700,000 tokens) of newspaper text taken from the frankfurter
   rundschau, although to date not all predicate-argument structures have
   been annotated. the frame and role inventory of salsa was taken from
   framenet, but has been extended and adapted where necessary due to lack
   of coverage and cross-lingual divergences.

   the syntactic structure of a sentence is represented through a
   constituent tree whose terminal nodes are tokens and non-terminal nodes
   are phrases (see [842]figure 6). in addition to labeling each node with
   a constituent type such as sentence, noun phrase, and verb phrase, the
   edges between a parent and a child node are labeled according to the
   function of the child within the parent constituent, for example,
   accusative object, noun kernel, or head. edges can cross, allowing
   local and non-local dependencies to be encoded in a uniform way and
   eliminating the need for traces. this approach has significant
   advantages for non-configurational languages such as german, which
   exhibit a rich inventory of discontinuous constituents and considerable
   freedom with respect to word order (smith [843]2003). compared with the
   id32 (marcus, santorini, and marcinkiewicz [844]1993), tree
   structures are relatively flat. for example, the tree does not encode
   whether a constituent is a verbal argument or adjunct; this information
   is encoded through the edge labels instead.
   [845]figure
   figure   6    a sample parse tree for the sentence pr  sident jelzin
   verliert die mach ans k  chenkabinett und wird die wahlen kaum gewinnen
   k  nnen [translated in english as president jelzin loses power to the
   kitchen cabinet and will hardly be able to win the elections]. the
   parse tree contains phrase labels np (noun phrase), pp (prepositional
   phrase), vp (verb phrase), s (sentence), and cs (coordinated sentence).
   the dependency labels are nk (noun kernel), sb (subject), ao (object
   accusative), hd (head), mo (modifier), ac (adpositional case marker),
   cj (conjunct), and oc (clausal object).

   the frame annotations contained in salsa do not cover all of the
   predicate-argument structures of the underlying tiger corpus. only a
   subset of around 550 predicates with approximately 18,000 occurrences
   in the corpus have been annotated. moreover, only core roles are
   annotated, whereas adjunct roles are not, resulting in a smaller number
   of arguments per predicate (1.96 on average) compared with the conll
   2008 data set (2.57 on average) described in section 5.1. because our
   method is designed to induce verb-specific frames, we converted the
   salsa frames into propbank-like frames by splitting each frame into
   several verb-specific frames and accordingly mapping frame roles onto
   verb-specific roles. our data set is comparable to the german data set
   released as part of the conll 2009 shared task (haji   et al.
   [846]2009), which was also derived from the salsa corpus. however, we
   did not convert the original constituent-based salsa representation
   into dependencies, as we wanted to assess whether our methods are also
   compatible with phrase structure trees.
   6.2   experimental set-up

   although we follow the same experimental set-up as described in
   [847]section 5 for english, there are some deviations due to
   differences in the data sets utilized for the two languages. firstly,
   in contrast to the conll 2008 data set, the salsa data set (and the
   underlying tiger corpus) does not supply automatic parse trees and we
   therefore conducted our experiments on gold parses only. moreover,
   because adjunct arguments are not annotated in salsa, and because
   argument identification is not the central issue of this work, we chose
   to also consider only the gold argument identification. thus, all our
   experiments for german were carried out on the gold/gold data set.

   a substantial linguistic difference between the german and english data
   sets is the sparsity of the argument head lemmas, which is
   significantly higher for german than for english: in the conll 2008
   data set, the average number of distinct head lemmas per verb is only
   3.69, whereas in the salsa data set it is 20.12. this is partly due to
   the fact that the wall street journal text underlying the english data
   is topically more focused than the rundschau newspaper text, which
   covers a broader range of news beyond economics and politics. moreover,
   noun compounding is more commonly used in german than in english
   (corston-oliver and gamon [848]2004), which leads to higher lexical
   sparsity.

   data sparsity affects our method, which crucially relies on lexical
   similarity for determining the role-equivalence of clusters. therefore,
   we reduced the number of syntactic cues used for cluster initialization
   in order to avoid creating too many small clusters for which
   similarities cannot be reliably computed. specifically, only the
   syntactic position and function word served as cues to initialize our
   clusters. note that, as in english, the relatively small number of
   syntactic cues that determine the syntactic position within a linking
   is a consequence of the size of our evaluation data set (which is
   rather small) and not an inherent limitation of our method. on larger
   data sets, more syntactic cues could and should be incorporated in
   order to increase performance.

   in our experiments we compared the baseline introduced in [849]section
   5.3 against agglomerative partitioning and the label propagation
   algorithm using both cosine- and avgmax-similarity. the parameters   ,
     , and   , which determine the thresholds used in defining overall
   similarity scores, were set and updated identically as for english
   (i.e., these parameters can be considered language-independent).
   6.3   results

   [850]table 10 reports results for the baseline and our role induction
   methods, namely, agglomerative id91 and multi-layered label
   propagation (using the avgmax and cosine similarity functions) on the
   salsa gold/gold data set. for comparison, we also include results on
   the english conll-2008 gold/gold data set. as can be seen, the baseline
   obtains a similar f1 for german and english, although the contributions
   of purity and collocation are different for the two languages. in
   english, purity is noticeably higher than in german, whereas
   collocation is higher in german. this is not surprising when taking
   into account the distribution of syntactic relations governing an
   argument. a few frequent relation labels absorb most of the id203
   mass in german (see [851]figure 7b), whereas the mass is distributed
   more evenly among the labels in english ([852]figure 7a), thus leading
   to higher purity but lower collocation.

   [853]table
   table   10    results of agglomerative partitioning and label propagation
   for cosine and avgmax similarity on german. for comparison purposes
   results for english on the gold/gold data set are also tabulated. all
   improvements over the baseline are statistically significant at
   significance level q < 0.001.

   [854]figure
   figure   7    distribution of syntactic relations governing an argument in
   english and german data sets. only the most frequent relations are
   shown (a key for the english relations is given in [855]table 2; in
   german the relations are sb (subject), oa (object accusative), cj
   (conjunct), da (dative), cd (coordinator), mo (modifier), re
   (subordinate clause), rs (reported speech), oc (object clausal), op
   (object prepositional), nk (noun kernel), and cvc (collocational verb
   construction).

   in german, our role induction algorithms improve over the baseline in
   terms of f1. all four methods perform comparably and manage to strike a
   tradeoff between collocation and purity that is non-trivial and
   represents semantic roles adequately. compared with english, the
   difference between the baseline and our algorithms is narrower. this is
   because we use fewer syntactic cues for initialization in german, due
   to the increased data sparsity discussed in the previous section. this
   also explains why there is little variation in the collocation and
   purity results across methods. however, qualitatively the tradeoff
   between purity and collocation is the same as for english (i.e., purity
   is increased at the cost of collocation).

   [856]tables 11 and [857]12 show per-verb and per-role results,
   respectively, for agglomerative id91 using cosine similarity. we
   report per-verb scores for a selection of 10 verbs (see [858]table
   12a), which in some cases are translations of the verbs used for
   english. with respect to per-role scores, we make use of the fact that
   roles have a common meaning across predicates (like a0 and a1 in
   propbank), and report scores for a selection of 15 different roles
   ([859]table 12b) with varied occurrence frequencies. per-verb results
   confirm that data sparsity affects performance in german. as can be
   seen, agglomerative id91 outperforms the baseline on
   high-frequency verbs that are less affected by sparsity, although this
   is not always the case on lower-frequency verbs. analogously, the
   method tends to perform better on high-frequency roles, whereas there
   is no clear trend on lower-frequency roles. in contrast to english, for
   more than half of the verbs the method manages to outperform the
   baseline in terms of both purity and collocation, which is consistent
   with our macroscopic result, where the tradeoff between purity and
   collocation is not as strong as for english.

   [860]table
   table   11    results for individual verbs on the gold/gold salsa data set;
   comparison between the baseline and the agglomerative id91
   algorithm with the cosine similarity function.

   [861]table
   table   12    results for individual roles on gold/gold salsa data set;
   comparison between the baseline and the agglomerative id91
   algorithm with the cosine similarity function.

   the experiments show that our methods can be successfully applied to
   languages other than english, thereby supporting the claim that they
   are based on a set of language-independent assumptions and principles.
   despite substantial differences between german and english grammar,
   both generally and in terms of the specific syntactic representation
   that was used, our methods increased f1 over the baseline for both
   languages and resulted in a similar tradeoff between purity and
   collocation. improvements were observed in spite of pronounced data
   sparsity in the case of german. recall that we had to reduce the number
   of syntactic initialization cues in order to be able to obtain results
   on the relatively small amount of gold-standard data. we would also
   like to note that porting our system to german did not require any
   additional feature engineering or algorithmic changes.
   7.   conclusions
   section:
   [choose________________________]
   [862]previous section [863]next section

   in this article we described an unsupervised method for semantic role
   induction in which argument-instance graphs are partitioned into
   clusters representing semantic roles. a major hypothesis underlying our
   work has been that semantic roles can be induced without human
   supervision from a corpus of syntactically parsed sentences based on
   three linguistic principles : (1) arguments in the same syntactic
   position (within a specific linking) bear the same semantic role, (2)
   arguments within a clause bear a unique role, and (3) clusters
   representing the same semantic role should be more or less lexically
   and distributionally equivalent. based on these principles we have
   formulated a similarity-driven model and introduced a multi-layer graph
   partitioning approach that represents similarity between clusters on
   multiple feature layers, whose connectivity can be analyzed separately
   and then combined into an overall cluster-similarity score.

   our work has challenged the established view that supervised learning
   is the method of choice for the id14 task. although
   the proposed unsupervised models do yet achieve results comparable to
   their supervised counterparts, we have been able to show that they
   consistently outperform the syntactic baseline across several data sets
   that combine automatic and gold parses, with gold and automatic
   argument identification in english and german. our methods obtain f1
   scores that are systematically above the baseline and the purity of the
   induced clusters is considerably higher, although in most cases this
   increase in purity is achieved by decreasing collocation. in sum, these
   results provide strong empirical evidence towards the soundness of our
   method and the principles they are based on.

   in terms of modeling, we have contributed to the body of work on
   similarity-driven models by demonstrating their suitability for this
   problem, their effectiveness, and their computational efficiency. the
   models are based on judgments regarding the similarity of argument
   instances with respect to their semantic roles. we showed that these
   judgments are comparatively simple to formulate and incorporate into a
   graph representation of the data. we have introduced the idea of
   separating different similarity features into different graph layers,
   which resolves the problem faced by many similarity-based approaches of
   having to heuristically define an instance-wise similarity function and
   brings the advantage that cluster similarities can be computed in a
   more principled way. beyond id14, we hope that the
   multi-layered graph representation described here might be of relevance
   to other unsupervised problems such part-of-speech tagging or
   coreference resolution. the approach is general and amenable to other
   graph partitioning algorithms besides agglomeration and label
   propagation.

   there are two forms of data sparsity that arise in the context of our
   work, namely, the lexical sparsity of argument head lemmas and the
   sparsity of specific combinations of linking and syntactic position. as
   our methods are unsupervised, the conceptually simple solution to
   sparsity is to train on larger data sets. because, with some
   modifications, our graph partitioning approaches could be scaled to
   larger data sets (in terms of orders of magnitude), this is an obvious
   next step and would address both instances of data sparsity. firstly,
   it would allow us to incorporate a richer set of syntactic features for
   initialization and would therefore necessarily result in initial
   id91s of higher purity. secondly, the larger size of clusters
   would result in more reliable similarity scores. augmenting the data
   set would therefore almost surely increase the quality of induced
   id91s; however, we leave this to future work.

   another interesting future direction would be to eliminate the model's
   reliance on a syntactic parser that prohibits its application to
   languages for which parsing resources are not available. it would
   therefore be worthwhile, albeit challenging, to build models that
   operate on more readily available forms of syntactic analysis or even
   raw text. for example, existing work (abend and rappoport [864]2010b;
   abend, reichart, and rappoport [865]2009) attempts to identify
   arguments and distinguish them into core and adjunct ones through
   unsupervised part of speech and grammar induction. as much as making
   our model more unsupervised it would also be interesting to see whether
   some form of weak supervision might help induce higher-quality semantic
   roles without incurring a major labeling effort. the ideas conveyed in
   this article and the proposed methods extend naturally to this setting:
   introducing labels on some of the graph vertices would translate into a
   semi-supervised graph-based learning task, akin to zhu, ghahramani, and
   lafferty ([866]2003).
   appendix a. argument identification rules
   section:
   [choose_________________________]
   [867]previous section [868]next section

   this appendix specifies the full set of relations used by rules (2) and
   (4) of the argument identification rules given for english in
   [869]section 5.2, [870]table 1. the symbols     and     denote the
   direction of the dependency relation (upward and downward,
   respectively). the dependency relations are explained in surdeanu et
   al. ([871]2008), in their [872]table 4.

   the relations in rule (2) from [873]table 1 are im      , prt   , coord      ,
   p      , obj   , pmod   , adv   , sub      , root   , tmp   , sbj   , oprd   .

   the relations in rule (4) are adv      , amod      , appo      , bnf      -, conj      ,
   coord      , dir      , dtv      -, ext      , extr      , hmod      , iobj      , lgs      , loc      ,
   mnr      , nmod      , obj      , oprd      , posthon      , prd      , prn      , prp      , prt      ,
   put      , sbj      , sub      , suffix       tmp      , voc      .
   acknowledgments
   section:
   [choose________________________]
   [874]previous section [875]next section

   we are grateful to the anonymous referees, whose feedback helped to
   substantially improve this article. we also thank the members of the
   probabilistic models reading group at the university of edinburgh for
   helpful discussions and comments. we acknowledge the support of epsrc
   (grant ep/k017845/1).
   references
   section:
   [choose________________________]
   [876]previous section [877]next section
   abend, o. and a. rappoport. 2010a. fully unsupervised core-adjunct
   argument classification. in proceedings of the 48th annual meeting of
   the association for computational linguistics, pages 226   236, uppsala.
   [878]google scholar
   abend, o. and a. rappoport. 2010b. fully unsupervised core-adjunct
   argument classification. in proceedings of the annual meeting of the
   association for computational linguistics, pages 226   236, uppsala.
   [879]google scholar
   abend, o., r. reichart, and a. rappoport. 2009. unsupervised argument
   identification for id14. in proceedings of the annual
   meeting of the association for computational linguistics, pages 28   36,
   suntec. [880]crossref, [881]google scholar
   abney, s. 2007. semisupervised learning for computational linguistics.
   chapman & hall/crc. [882]crossref, [883]google scholar
   berg-kirkpatrick, t., a. bouchard-c  t  , j. denero, and d. klein. 2010.
   painless unsupervised learning with features. in proceedings of the
   conference of the north american chapter of the association for
   computational linguistics, pages 582   590, los angeles, ca. [884]google
   scholar
   biemann, c. 2006. chinese whispers: an efficient graph id91
   algorithm and its application to natural language processing problems.
   in proceedings of textgraphs: the first workshop on graph based methods
   for natural language processing, pages 73   80, new york, ny.
   [885]crossref, [886]google scholar
   boas, h. 2005. semantic frames as interlingual representations for
   multilingual lexical databases. international journal of id69,
   18(4):445   478. [887]crossref, [888]google scholar
   brants, s., s. dipper, s. hansen, w. lezius, and g. smith. 2002. the
   tiger treebank. in proceedings of the 1st workshop on treebanks and
   linguistic theories, pages 24   41, sozopol. [889]google scholar
   brigitta, h. 1996. deutsch ist eine v/2-sprache mit verbendstellung und
   freier wortfolge. in e. lang and g. zifonun, editors, deutsch   
   typologisch, pages 121   141. walter de gruyter. [890]google scholar
   brown, p. f., v. j. della pietra, p. v. desouza, j. c. lai, and r. l.
   mercer. 1992. class-based id165 models of natural language.
   computational linguistics, 18(4):283   298. [891]google scholar
   burchardt, a., k. erk, a. frank, a. kowalski, s. pad  , and m. pinkal.
   2006. the salsa corpus: a german corpus resource for lexical semantics.
   in proceedings of the international conference on language resources
   and evaluation, pages 969   974, genoa. [892]google scholar
   corston-oliver, s. and m. gamon. 2004. normalizing german and english
   inflectional morphology to improve statistical word alignment. in
   robert frederking and kathryn taylor, editors, machine translation:
   from real users to research, volume 3265 of lecture notes in computer
   science. springer, berlin heidelberg, pages 48   57.
   [893]crossref, [894]google scholar
   dowty, d. 1991. thematic proto roles and argument selection. language,
   67(3):547   619. [895]crossref, [896]google scholar
   f  rstenau, h. and m. lapata. 2009. graph alignment for semi-supervised
   id14. in proceedings of the conference on empirical
   methods in natural language processing, pages 11   20, singapore.
   [897]crossref, [898]google scholar
   gamallo, p., a. agustini, and g. lopes. 2005. id91 syntactic
   positions with similar semantic requirements. computational
   linguistics, 31(1):107   146. [899]link, [900]google scholar
   garg, n. and j. henderson. 2012. unsupervised semantic role induction
   with global role ordering. in proceedings of the 50th annual meeting of
   the association for computational linguistics (volume 2: short papers),
   pages 145   149, jeju island. [901]google scholar
   gildea, d. and d. jurafsky. 2002. automatic labeling of semantic roles.
   computational linguistics, 28(3):245   288. [902]link, [903]google
   scholar
   gordon, a. and r. swanson. 2007. generalizing semantic role annotations
   across syntactically similar verbs. in proceedings of the annual
   meeting of the association for computational linguistics, pages
   192   199, prague. [904]google scholar
   gordon, d. and m. desjardins. 1995. evaluation and selection of biases
   in machine learning. machine learning, 20:5   22. [905]google scholar
   grenager, t. and c. manning. 2006. unsupervised discovery of a
   statistical verb lexicon. in proceedings of the 2006 conference on
   empirical methods in natural language processing, pages 1   8, sydney.
   [906]crossref, [907]google scholar
   haji  , j., m. ciaramita, r. johansson, d. kawahara, m. a. mart  , l.
   m  rquez, a. meyers, j. nivre, s. pad  , j.   t  p  nek, p. stra    k, m.
   surdeanu, n. xue, and y. zhang. 2009. the conll 2009 shared task:
   syntactic and semantic dependencies in multiple languages. in
   proceedings of the thirteenth conference on computational natural
   language learning (conll 2009): shared task, pages 1   18, boulder, co.
   [908]crossref, [909]google scholar
   jain, a., m. murty, and p. flynn. 1999. data id91: a review. acm
   computing surveys, 31(3):264   323. [910]crossref, [911]google scholar
   kipper, k., h. t. dang, and m. palmer. 2000. class-based construction
   of a verb lexicon. in proceedings of the aaai conference on artificial
   intelligence, pages 691   696, austin, tx. [912]google scholar
   koomen, p., v. punyakanok, d. roth, and w. yih. 2005. generalized
   id136 with multiple id14 systems. in proceedings
   of the conference on computational natural language learning, pages
   181   184, ann arbor, mi. [913]crossref, [914]google scholar
   lang, j. and m. lapata. 2010. unsupervised induction of semantic roles.
   in proceedings of the north american chapter of the association for
   computational linguistics conference, pages 939   947, los angeles, ca.
   [915]google scholar
   lang, j. and m. lapata. 2011a. unsupervised induction of semantic roles
   via split-merge id91. in proceedings of the 49th annual meeting
   of the association for computational linguistics: human language
   technologies, pages 1,117   1,126, portland, or. [916]google scholar
   lang, j. and m. lapata. 2011b. unsupervised semantic role induction
   with graph partitioning. in proceedings of the conference on empirical
   methods in natural language processing, pages 1,320   1,331, edinburgh.
   [917]google scholar
   levin, b. and m. rappaport. 2005. argument realization. cambridge
   university press. [918]crossref, [919]google scholar
   levin, beth. 1993. english verb classes and alternations: a preliminary
   investigation. university of chicago press, chicago. [920]google
   scholar
   lin, d. and p. pantel. 2001. discovery of id136 rules for
   question-answering. natural langugae engineering, 7:343   360.
   [921]google scholar
   manning, c., p. raghavan, and h. sch  tze. 2008. introduction to
   information retrieval. cambridge university press.
   [922]crossref, [923]google scholar
   marcus, m., b. santorini, and m. marcinkiewicz. 1993. building a large
   annotated corpus of english: the id32. computational
   linguistics, 19(2):313   330. [924]google scholar
   m  rquez, l., x. carras, k. litkowski, and s. stevenson. 2008. semantic
   role labeling: an introduction to the special issue. computational
   linguistics, 34(2):145   159. [925]link, [926]google scholar
   melli, g., y. wang, y. liu, m. m. kashani, z. shi, b. gu, a. sarkar,
   and f. popowich. 2005. description of squash, the sfu question
   answering summary handler for the duc-2005 summarization task. in
   proceedings of the human language technology conference and the
   conference on empirical methods in natural language processing document
   understanding workshop, vancouver. [927]google scholar
   merlo, p. and s. stevenson. 2001. automatic verb classification based
   on statistical distributions of argument structure. computational
   linguistics, 27:373   408. [928]link, [929]google scholar
   munkres, j. 1957. algorithms for the assignment and transportation
   problems. journal of the society for industrial and applied
   mathematics, 5(1):32   38. [930]crossref, [931]google scholar
   nivre, j., j. hall, j. nilsson, g. eryigit, a. chanev, s. k  bler, s.
   marinov, and e. marsi. 2007. malt-parser: a language-independent system
   for data-driven id33. natural language engineering,
   13(2):95   135. [932]google scholar
   pad  , s. and m. lapata. 2009. cross-lingual annotation projection of
   semantic roles. journal of artificial intelligence research,
   36:307   340. [933]google scholar
   palmer, m., d. gildea, and p. kingsbury. 2005. the proposition bank: an
   annotated corpus of semantic roles. computational linguistics,
   31(1):71   106. [934]link, [935]google scholar
   poon, h. and p. domingos. 2009. unsupervised id29. in
   proceedings of the 2009 conference on empirical methods in natural
   language processing, pages 1   10, singapore. [936]crossref, [937]google
   scholar
   pradhan, s., w. ward, and j. martin. 2008. towards robust semantic role
   labeling. computational linguistics, 34(2):289   310.
   [938]link, [939]google scholar
   ruppenhofer, j., m. ellsworth, m. petruck, c. johnson, and j.
   scheffczyk. 2006. framenet ii: extended theory and practice, version
   1.3. technical report, international computer science institute,
   berkeley, ca. [940]google scholar
   schaeffer, s. 2007. graph id91. computer science review,
   1(1):27   64. [941]crossref, [942]google scholar
   shen, d. and m. lapata. 2007. using semantic roles to improve question
   answering. in proceedings of the 2007 joint conference on empirical
   methods in natural language processing and computational natural
   language learning (emnlp-conll), pages 12   21, prague. [943]google
   scholar
   smith, g. 2003. a brief introduction to the tiger treebank, version 1.
   technical report, university of potsdam. [944]google scholar
   surdeanu, m., s. harabagiu, j. williams, and p. aarseth. 2003. using
   predicate-argument structures for information extraction. in
   proceedings of the annual meeting of the association for computational
   linguistics, pages 8   15, sapporo. [945]crossref, [946]google scholar
   surdeanu, m., r. johansson, a. meyers, and l. m  rquez. 2008. the
   conll-2008 shared task on joint parsing of syntactic and semantic
   dependencies. in proceedings of the conference on natural language
   learning, pages 159   177, manchester. [947]crossref, [948]google scholar
   swier, r. and s. stevenson. 2004. unsupervised semantic role labelling.
   in proceedings of the conference on empirical methods in natural
   language processing, pages 95   102, barcelona. [949]google scholar
   titov, i. and a. klementiev. 2011. a bayesian model for unsupervised
   id29. in proceedings of the 49th annual meeting of the
   association for computational linguistics: human language technologies,
   pages 1,445   1,455, portland, or. [950]google scholar
   titov, i. and a. klementiev. 2012a. a bayesian approach to unsupervised
   semantic role induction. in proceedings of the 13th conference of the
   european chapter of the association for computational linguistics,
   pages 12   22, avignon. [951]google scholar
   titov, i. and a. klementiev. 2012b. crosslingual induction of semantic
   roles. in proceedings of the 50th annual meeting of the association for
   computational linguistics (volume 1: long papers), pages 647   656, jeju
   island. [952]google scholar
   van rijsbergen, c. 1974. foundation of evaluation. journal of
   documentation, 30(4):265   374. [953]crossref, [954]google scholar
   wu, d. and p. fung. 2009. semantic roles for smt: a hybrid two-pass
   model. in proceedings of human language technologies: the annual
   conference of the north american chapter of the association for
   computational linguistics, companion volume: short papers, pages 13   16,
   boulder, co. [955]crossref, [956]google scholar
   zhu, x., z. ghahramani, and j. lafferty. 2003. semi-supervised learning
   using gaussian fields and id94. in proceedings of the
   international conference on machine learning, pages 912   919,
   washington, dc. [957]google scholar
   joel lang*
   university of geneva
   mirella lapata**
   university of edinburgh

   *department of computer science, university of geneva, 7 route de
   drize, 1227 caid8, switzerland, e-mail: [958][email protected].

   **institute for language, cognition and computation, school of
   informatics, university of edinburgh, 10 crichton street, eh8 9ab,
   e-mail: [959][email protected].
   [960]favorite [favorite-1488499760477.svg]
   track citations [notify-me-alert-1488499750013.svg]
   [961]download citation [download2-1490507427013.svg]
   [962]rss toc [rss-1488924357683.svg]

   [963]rss citation [rss-1488924357683.svg]
   [964]submit your article
   [965]support oa at mitp [open-access-1493356222797.svg]

   [966][mitpress-logo-main-1483476130433.svg]
     * [967]journals [968]books
     * [969]terms & conditions
     * [970]privacy statement
     * [971]contact us

     * us
          + one rogers street cambridge ma 02142-1209
     * uk
          + suite 2, 1 duchess street london, w1w 6an, uk
     * connect
          + [972]facebook
          + [973]twitter
          + [974]google +
          + [975]pinterest
          + [976]instagram
          + [977]youtube
     *
          +    2019 the mit press
          + technology partner:[978] atypon systems, inc.
          + [979]crossref member
          + [980]counter member
          + the mit press colophon is registered in the u.s. patent and
            trademark office.
          + [981]site help

references

   visible links
   1. https://doi.org/10.1162/coli_a_00195
   2. https://doi.org/10.1162/coli_a_00195
   3. https://doi.org/10.1162/coli_a_00195
   4. https://www.googletagmanager.com/ns.html?id=gtm-tr6twrh
   5. https://www.googletagmanager.com/ns.html?id=gtm-tr6twrh
   6. https://www.mitpressjournals.org/action/showlogin
   7. https://www.mitpressjournals.org/doi/10.1162/coli_a_00195
   8. https://www.mitpressjournals.org/doi/10.1162/coli_a_00195
   9. https://www.mitpressjournals.org/doi/10.1162/coli_a_00195
  10. https://www.mitpressjournals.org/doi/10.1162/coli_a_00195
  11. https://www.mitpressjournals.org/doi/10.1162/coli_a_00195
  12. https://www.mitpressjournals.org/doi/10.1162/coli_a_00195
  13. https://www.mitpressjournals.org/action/requestusername
  14. https://www.mitpressjournals.org/action/requestresetpassword
  15. https://www.mitpressjournals.org/
  16. http://www.mitpressjournals.org/
  17. https://mitpress.mit.edu/
  18. https://www.mitpressjournals.org/action/showpublications
  19. https://www.mitpressjournals.org/digital
  20. https://www.mitpressjournals.org/doi/10.1162/coli_a_00195
  21. https://www.mitpressjournals.org/librarians
  22. https://www.mitpressjournals.org/action/institutionadminactivation
  23. https://www.mitpressjournals.org/pb-assets/pdfs/journals institutional license-1548442853093.pdf
  24. https://www.mitpressjournals.org/action/showinstitutionusagereport
  25. https://www.mitpressjournals.org/document_delivery
  26. https://www.mitpressjournals.org/pb-assets/pdfs/vpat_mitp_journals-1507061346287.pdf
  27. https://www.mitpressjournals.org/subscribe
  28. https://www.mitpressjournals.org/inst_getting_started
  29. https://www.mitpressjournals.org/doi/10.1162/coli_a_00195
  30. https://www.mitpressjournals.org/pb-assets/pdfs/2019 mitpj institution price list-1541020584043.pdf
  31. https://www.mitpressjournals.org/pb-assets/pdfs/2019 mitpj package pricelist-1541020593767.pdf
  32. https://www.mitpressjournals.org/pb-assets/pdfs/2018 mitpj single issue price list-1513815652483.pdf
  33. https://www.mitpressjournals.org/for_authors
  34. https://www.mitpressjournals.org/for_authors#subpubagreements
  35. https://www.mitpressjournals.org/for_authors#authorposting
  36. https://www.mitpressjournals.org/for_authors#copyright
  37. https://www.mitpressjournals.org/for_authors#authorreprints
  38. https://www.mitpressjournals.org/for_authors#publishingoa
  39. https://www.mitpressjournals.org/for_authors#nihpublicaccess
  40. https://www.mitpressjournals.org/for_authors#authordiscounts
  41. https://www.mitpressjournals.org/for_authors#kudos
  42. https://www.mitpressjournals.org/doi/10.1162/coli_a_00195
  43. https://www.mitpressjournals.org/doi/10.1162/coli_a_00195
  44. https://www.mitpressjournals.org/doi/10.1162/coli_a_00195
  45. https://www.mitpressjournals.org/doi/10.1162/coli_a_00195
  46. https://www.mitpressjournals.org/rights_permission
  47. https://mitpress.mit.edu/giving/
  48. https://www.mitpressjournals.org/trade_sales
  49. https://www.mitpressjournals.org/advertising
  50. https://www.mitpressjournals.org/schedule
  51. https://www.mitpressjournals.org/faq
  52. https://www.mitpressjournals.org/terminated_journals
  53. https://www.mitpressjournals.org/doi/10.1162/coli_a_00195
  54. https://www.mitpressjournals.org/aboutmitpj
  55. https://www.mitpressjournals.org/ethics
  56. https://www.mitpressjournals.org/events
  57. https://www.mitpressjournals.org/publishing_services
  58. https://www.mitpressjournals.org/mitpj-staff
  59. https://www.mitpressjournals.org/analytics
  60. https://www.mitpressjournals.org/doi/10.1162/coli_a_00195
  61. https://www.facebook.com/mitpress
  62. http://www.twitter.com/mitpress
  63. https://plus.google.com/106848724929282487337?prsrc=3
  64. https://www.pinterest.com/mitpress/
  65. https://www.instagram.com/mitpress/
  66. https://www.youtube.com/channel/uceh0hmlpjgw2dn0ntmd0fcq
  67. https://www.mitpressjournals.org/contact_info
  68. https://mitpressjournals.mit.edu/shop/customer/account/
  69. https://www.mitpressjournals.org/cdn-cgi/l/email-protection#73191c06011d121f005e121700331e1a075d161706
  70. https://www.mitpressjournals.org/cdn-cgi/l/email-protection#fc9693898e929d908fd195929a93bc919588d2999889
  71. https://www.mitpressjournals.org/cdn-cgi/l/email-protection#c6aca9b3b4a8a7aab5ebb4afa1aeb2b586abafb2e8a3a2b3
  72. https://www.mitpressjournals.org/cdn-cgi/l/email-protection#ff959b8f9c8cd288968d9a8cbf92968bd19a9b8a
  73. https://www.mitpressjournals.org/cdn-cgi/l/email-protection#b9d3ddc9daca94d5d0dadcd7cadccaf9d4d0cd97dcddcc
  74. https://www.mitpressjournals.org/cdn-cgi/l/email-protection#d4bebba1a6bab5b8a7f9b7a794b9bda0fab1b0a1
  75. https://www.mitpressjournals.org/cdn-cgi/l/email-protection#5d3732282f333c312e703c3e3e382e2e1d30342973383928
  76. https://www.mitpressjournals.org/cdn-cgi/l/email-protection#224c4e4b4c4651435b624f4b560c474657
  77. https://www.mitpressjournals.org/action/showlogin?uri=/doi/10.1162/coli_a_00195
  78. https://www.mitpressjournals.org/doi/10.1162/coli_a_00195
  79. https://www.mitpressjournals.org/search/advanced
  80. https://www.mitpressjournals.org/
  81. https://www.mitpressjournals.org/loi/coli
  82. https://www.mitpressjournals.org/loi/coli
  83. https://www.mitpressjournals.org/toc/coli/40/3
  84. http://www.mitpressjournals.org/doi/abs/10.1162/coli_a_00194
  85. http://www.mitpressjournals.org/doi/abs/10.1162/coli_a_00196
  86. https://www.mitpressjournals.org/action/showlargecover?doi=10.1162/coli.2014.40.issue-3&journalcode=coli
  87. https://www.mitpressjournals.org/doi/10.1162/coli_a_00195
  88. https://www.mitpressjournals.org/journals/coli/editorial
  89. https://www.mitpressjournals.org/journals/coli/aandi
  90. https://www.mitpressjournals.org/schedule
  91. https://www.mitpressjournals.org/advertising
  92. http://cljournal.org/
  93. https://www.mitpressjournals.org/pb-assets/pdfs/coli-permission-form_sept2018-1536787440293.pdf
  94. http://www.mitpressjournals.org/for_authors#authorreprints
  95. https://www.mitpressjournals.org/rights_permission
  96. https://www.mitpressjournals.org/action/showmostreadarticles?journalcode=coli
  97. https://www.mitpressjournals.org/action/showmostcitedarticles?journalcode=coli
  98. https://www.mitpressjournals.org/doi/10.1162/coli_a_00195
  99. https://www.mitpressjournals.org/doi/10.1162/coli_a_00195
 100. https://creativecommons.org/licenses/by-nc-nd/4.0/
 101. https://giving.mit.edu/taxonomy/term/79#3920880
 102. https://www.mitpressjournals.org/author/lang,+joel
 103. https://www.mitpressjournals.org/author/lapata,+mirella
 104. https://doi.org/10.1162/coli_a_00195
 105. https://www.mitpressjournals.org/doi/10.1162/coli_a_00195
 106. https://www.mitpressjournals.org/author/lang,+joel
 107. https://www.mitpressjournals.org/author/lapata,+mirella
 108. https://doi.org/10.1162/coli_a_00195
 109. https://www.mitpressjournals.org/doi/full/10.1162/coli_a_00195
 110. https://www.mitpressjournals.org/doi/10.1162/coli_a_00195#authors-content
 111. http://www.mitpressjournals.org/doi/pdf/10.1162/coli_a_00195
 112. http://www.mitpressjournals.org/doi/pdfplus/10.1162/coli_a_00195
 113. https://www.mitpressjournals.org/doi/10.1162/coli_a_00195#_i1
 114. https://www.mitpressjournals.org/doi/10.1162/coli_a_00195#abstract
 115. https://www.mitpressjournals.org/doi/10.1162/coli_a_00195#_i3
 116. https://www.mitpressjournals.org/doi/10.1162/coli_a_00195
 117. https://www.mitpressjournals.org/doi/10.1162/coli_a_00195
 118. https://www.mitpressjournals.org/doi/10.1162/coli_a_00195
 119. https://www.mitpressjournals.org/doi/10.1162/coli_a_00195
 120. https://www.mitpressjournals.org/doi/10.1162/coli_a_00195
 121. https://www.mitpressjournals.org/doi/10.1162/coli_a_00195
 122. https://www.mitpressjournals.org/doi/10.1162/coli_a_00195
 123. https://www.mitpressjournals.org/doi/10.1162/coli_a_00195#fn3
 124. https://www.mitpressjournals.org/doi/10.1162/coli_a_00195
 125. https://www.mitpressjournals.org/doi/10.1162/coli_a_00195
 126. https://www.mitpressjournals.org/doi/10.1162/coli_a_00195
 127. https://www.mitpressjournals.org/doi/10.1162/coli_a_00195
 128. https://www.mitpressjournals.org/doi/10.1162/coli_a_00195
 129. https://www.mitpressjournals.org/doi/10.1162/coli_a_00195
 130. javascript:popref('s2')
 131. javascript:popref('s3')
 132. javascript:popref('s4')
 133. javascript:popref('s5')
 134. javascript:popref('s6')
 135. javascript:popref('s7')
 136. https://www.mitpressjournals.org/doi/10.1162/coli_a_00195#_i1
 137. https://www.mitpressjournals.org/doi/10.1162/coli_a_00195#_i4
 138. https://www.mitpressjournals.org/doi/10.1162/coli_a_00195
 139. https://www.mitpressjournals.org/doi/10.1162/coli_a_00195
 140. https://www.mitpressjournals.org/doi/10.1162/coli_a_00195
 141. https://www.mitpressjournals.org/doi/10.1162/coli_a_00195
 142. https://www.mitpressjournals.org/doi/10.1162/coli_a_00195
 143. https://www.mitpressjournals.org/doi/10.1162/coli_a_00195
 144. https://www.mitpressjournals.org/doi/10.1162/coli_a_00195
 145. https://www.mitpressjournals.org/doi/10.1162/coli_a_00195
 146. https://www.mitpressjournals.org/doi/10.1162/coli_a_00195
 147. https://www.mitpressjournals.org/doi/10.1162/coli_a_00195
 148. https://www.mitpressjournals.org/doi/10.1162/coli_a_00195
 149. https://www.mitpressjournals.org/doi/10.1162/coli_a_00195
 150. https://www.mitpressjournals.org/doi/10.1162/coli_a_00195
 151. https://www.mitpressjournals.org/doi/10.1162/coli_a_00195
 152. https://www.mitpressjournals.org/doi/10.1162/coli_a_00195
 153. https://www.mitpressjournals.org/doi/10.1162/coli_a_00195
 154. https://www.mitpressjournals.org/doi/10.1162/coli_a_00195
 155. https://www.mitpressjournals.org/doi/10.1162/coli_a_00195
 156. https://www.mitpressjournals.org/doi/10.1162/coli_a_00195
 157. https://www.mitpressjournals.org/doi/10.1162/coli_a_00195
 158. https://www.mitpressjournals.org/doi/10.1162/coli_a_00195
 159. javascript:popref('s4')
 160. https://www.mitpressjournals.org/doi/10.1162/coli_a_00195#_i3
 161. https://www.mitpressjournals.org/doi/10.1162/coli_a_00195#_i12
 162. https://www.mitpressjournals.org/doi/10.1162/coli_a_00195
 163. https://www.mitpressjournals.org/doi/10.1162/coli_a_00195
 164. https://www.mitpressjournals.org/doi/10.1162/coli_a_00195
 165. https://www.mitpressjournals.org/doi/10.1162/coli_a_00195
 166. https://www.mitpressjournals.org/doi/10.1162/coli_a_00195
 167. javascript:popref('s1')
 168. https://www.mitpressjournals.org/doi/10.1162/coli_a_00195#fn4
 169. javascript:popref('s4a')
 170. https://www.mitpressjournals.org/doi/10.1162/coli_a_00195#_i4
 171. https://www.mitpressjournals.org/doi/10.1162/coli_a_00195#_i26
 172. https://www.mitpressjournals.org/doi/10.1162/coli_a_00195
 173. https://www.mitpressjournals.org/doi/10.1162/coli_a_00195
 174. https://www.mitpressjournals.org/doi/10.1162/coli_a_00195#fn5
 175. javascript:popref('s5d')
 176. https://www.mitpressjournals.org/doi/10.1162/coli_a_00195
 177. javascript:popref('s3a')
 178. javascript:popref('s3a')
 179. https://www.mitpressjournals.org/doi/10.1162/coli_a_00195
 180. https://www.mitpressjournals.org/doi/10.1162/coli_a_00195
 181. javascript:popref('e1')
 182. javascript:popref('e1')
 183. javascript:popref('e2')
 184. https://www.mitpressjournals.org/doi/10.1162/coli_a_00195
 185. javascript:popref('e3')
 186. javascript:popref('s4a')
 187. javascript:popref('e1')
 188. javascript:popref('e2')
 189. javascript:popref('e3')
 190. javascript:popref('s4a')
 191. javascript:popref('s5e')
 192. https://www.mitpressjournals.org/doi/10.1162/coli_a_00195
 193. https://www.mitpressjournals.org/doi/10.1162/coli_a_00195#_i12
 194. https://www.mitpressjournals.org/doi/10.1162/coli_a_00195#_i62
 195. javascript:popref('s6')
 196. javascript:popref('s5a')
 197. javascript:popref('s5b')
 198. javascript:popref('s5d')
 199. https://www.mitpressjournals.org/doi/10.1162/coli_a_00195
 200. https://www.mitpressjournals.org/doi/10.1162/coli_a_00195
 201. https://www.mitpressjournals.org/doi/10.1162/coli_a_00195
 202. https://www.mitpressjournals.org/doi/10.1162/coli_a_00195
 203. https://www.mitpressjournals.org/doi/10.1162/coli_a_00195
 204. https://www.mitpressjournals.org/doi/10.1162/coli_a_00195#fn6
 205. https://www.mitpressjournals.org/doi/10.1162/coli_a_00195
 206. javascript:popref('t1')
 207. https://www.mitpressjournals.org/doi/10.1162/coli_a_00195
 208. javascript:popref('t1')
 209. javascript:popref('t1')
 210. https://www.mitpressjournals.org/doi/10.1162/coli_a_00195
 211. https://www.mitpressjournals.org/doi/10.1162/coli_a_00195
 212. https://www.mitpressjournals.org/doi/10.1162/coli_a_00195
 213. https://www.mitpressjournals.org/doi/10.1162/coli_a_00195
 214. https://www.mitpressjournals.org/doi/10.1162/coli_a_00195
 215. javascript:popref('t2')
 216. javascript:popref('t2')
 217. https://www.mitpressjournals.org/doi/10.1162/coli_a_00195
 218. https://www.mitpressjournals.org/doi/10.1162/coli_a_00195
 219. javascript:popref('t2')
 220. https://www.mitpressjournals.org/doi/10.1162/coli_a_00195
 221. https://www.mitpressjournals.org/doi/10.1162/coli_a_00195
 222. javascript:popref('t3')
 223. javascript:popref('t5')
 224. javascript:popref('s4a')
 225. https://www.mitpressjournals.org/doi/10.1162/coli_a_00195
 226. https://www.mitpressjournals.org/doi/10.1162/coli_a_00195#fn7
 227. javascript:popref('t5')
 228. https://www.mitpressjournals.org/doi/10.1162/coli_a_00195
 229. https://www.mitpressjournals.org/doi/10.1162/coli_a_00195
 230. javascript:popref('t3')
 231. javascript:popref('t4')
 232. javascript:popref('t5')
 233. javascript:popref('s5d')
 234. https://www.mitpressjournals.org/doi/10.1162/coli_a_00195
 235. https://www.mitpressjournals.org/doi/10.1162/coli_a_00195
 236. javascript:popref('t6')
 237. https://www.mitpressjournals.org/doi/10.1162/coli_a_00195
 238. https://www.mitpressjournals.org/doi/10.1162/coli_a_00195
 239. javascript:popref('t6')
 240. javascript:popref('t6')
 241. javascript:popref('t7')
 242. javascript:popref('t7')
 243. https://www.mitpressjournals.org/doi/10.1162/coli_a_00195
 244. https://www.mitpressjournals.org/doi/10.1162/coli_a_00195
 245. https://www.mitpressjournals.org/doi/10.1162/coli_a_00195
 246. https://www.mitpressjournals.org/doi/10.1162/coli_a_00195
 247. https://www.mitpressjournals.org/doi/10.1162/coli_a_00195
 248. https://www.mitpressjournals.org/doi/10.1162/coli_a_00195
 249. https://www.mitpressjournals.org/doi/10.1162/coli_a_00195
 250. https://www.mitpressjournals.org/doi/10.1162/coli_a_00195
 251. https://www.mitpressjournals.org/doi/10.1162/coli_a_00195
 252. https://www.mitpressjournals.org/doi/10.1162/coli_a_00195
 253. https://www.mitpressjournals.org/doi/10.1162/coli_a_00195
 254. https://www.mitpressjournals.org/doi/10.1162/coli_a_00195
 255. https://www.mitpressjournals.org/doi/10.1162/coli_a_00195
 256. https://www.mitpressjournals.org/doi/10.1162/coli_a_00195
 257. https://www.mitpressjournals.org/doi/10.1162/coli_a_00195
 258. https://www.mitpressjournals.org/doi/10.1162/coli_a_00195
 259. https://www.mitpressjournals.org/doi/10.1162/coli_a_00195
 260. https://www.mitpressjournals.org/doi/10.1162/coli_a_00195
 261. javascript:popref('t8')
 262. javascript:popref('t9')
 263. javascript:popref('t8')
 264. javascript:popref('t9')
 265. https://www.mitpressjournals.org/doi/10.1162/coli_a_00195#_i26
 266. https://www.mitpressjournals.org/doi/10.1162/coli_a_00195#_i76
 267. https://www.mitpressjournals.org/doi/10.1162/coli_a_00195
 268. javascript:popref('s1')
 269. https://www.mitpressjournals.org/doi/10.1162/coli_a_00195#fn8
 270. https://www.mitpressjournals.org/doi/10.1162/coli_a_00195
 271. https://www.mitpressjournals.org/doi/10.1162/coli_a_00195
 272. https://www.mitpressjournals.org/doi/10.1162/coli_a_00195
 273. https://www.mitpressjournals.org/doi/10.1162/coli_a_00195
 274. https://www.mitpressjournals.org/doi/10.1162/coli_a_00195
 275. https://www.mitpressjournals.org/doi/10.1162/coli_a_00195
 276. https://www.mitpressjournals.org/doi/10.1162/coli_a_00195
 277. https://www.mitpressjournals.org/doi/10.1162/coli_a_00195
 278. javascript:popref('s5')
 279. https://www.mitpressjournals.org/doi/10.1162/coli_a_00195
 280. javascript:popref('s5c')
 281. javascript:popref('t10')
 282. https://www.mitpressjournals.org/doi/10.1162/coli_a_00195
 283. https://www.mitpressjournals.org/doi/10.1162/coli_a_00195
 284. javascript:popref('t10')
 285. https://www.mitpressjournals.org/doi/10.1162/coli_a_00195
 286. javascript:popref('t2')
 287. javascript:popref('t11')
 288. javascript:popref('t12')
 289. javascript:popref('t12')
 290. javascript:popref('t12')
 291. javascript:popref('t11')
 292. javascript:popref('t12')
 293. https://www.mitpressjournals.org/doi/10.1162/coli_a_00195#_i62
 294. https://www.mitpressjournals.org/doi/10.1162/coli_a_00195#_i77
 295. https://www.mitpressjournals.org/doi/10.1162/coli_a_00195
 296. https://www.mitpressjournals.org/doi/10.1162/coli_a_00195
 297. https://www.mitpressjournals.org/doi/10.1162/coli_a_00195
 298. https://www.mitpressjournals.org/doi/10.1162/coli_a_00195#_i76
 299. https://www.mitpressjournals.org/doi/10.1162/coli_a_00195#_i78
 300. javascript:popref('s5b')
 301. javascript:popref('t1')
 302. https://www.mitpressjournals.org/doi/10.1162/coli_a_00195
 303. javascript:popref('t4')
 304. javascript:popref('t1')
 305. https://www.mitpressjournals.org/doi/10.1162/coli_a_00195#_i77
 306. https://www.mitpressjournals.org/doi/10.1162/coli_a_00195#_i79
 307. https://www.mitpressjournals.org/doi/10.1162/coli_a_00195#_i78
 308. https://www.mitpressjournals.org/doi/10.1162/coli_a_00195#citart1
 309. http://scholar.google.com/scholar?hl=en&q=abend,+o.+and+a.+rappoport.+2010a.++fully+unsupervised+core-adjunct+argument+classification.+in+proceedings+of+the+48th+annual+meeting+of+the+association+for+computational+linguistics,+pages+226   236,+uppsala.
 310. http://scholar.google.com/scholar?hl=en&q=abend,+o.+and+a.+rappoport.+2010b.++fully+unsupervised+core-adjunct+argument+classification.+in+proceedings+of+the+annual+meeting+of+the+association+for+computational+linguistics,+pages+226   236,+uppsala.
 311. https://www.mitpressjournals.org/servlet/linkout?suffix=r3&dbid=16&doi=10.1162/coli_a_00195&key=10.3115/1687878.1687884
 312. http://scholar.google.com/scholar?hl=en&q=abend,+o.,+r.+reichart,+and+a.+rappoport.+2009.++unsupervised+argument+identification+for+semantic+role+labeling.+in+proceedings+of+the+annual+meeting+of+the+association+for+computational+linguistics,+pages+28   36,+suntec.
 313. https://www.mitpressjournals.org/servlet/linkout?suffix=r4&dbid=16&doi=10.1162/coli_a_00195&key=10.1201/9781420010800
 314. http://scholar.google.com/scholar?hl=en&q=abney,+s.+2007.+semisupervised+learning+for+computational+linguistics.+chapman+&+hall/crc.
 315. http://scholar.google.com/scholar?hl=en&q=berg-kirkpatrick,+t.,+a.+bouchard-c  t  ,+j.+denero,+and+d.+klein.+2010.++painless+unsupervised+learning+with+features.+in+proceedings+of+the+conference+of+the+north+american+chapter+of+the+association+for+computational+linguistics,+pages+582   590,+los+angeles,+ca.
 316. https://www.mitpressjournals.org/servlet/linkout?suffix=r6&dbid=16&doi=10.1162/coli_a_00195&key=10.3115/1654758.1654774
 317. http://scholar.google.com/scholar?hl=en&q=biemann,+c.+2006.++chinese+whispers:+an+efficient+graph+id91+algorithm+and+its+application+to+natural+language+processing+problems.+in+proceedings+of+textgraphs:+the+first+workshop+on+graph+based+methods+for+natural+language+processing,+pages+73   80,+new+york,+ny.
 318. https://www.mitpressjournals.org/servlet/linkout?suffix=r7&dbid=16&doi=10.1162/coli_a_00195&key=10.1093/ijl/eci043
 319. http://scholar.google.com/scholar?hl=en&q=boas,+h.+2005.++semantic+frames+as+interlingual+representations+for+multilingual+lexical+databases.+international+journal+of+id69,+18(4):445   478.
 320. http://scholar.google.com/scholar?hl=en&q=brants,+s.,+s.+dipper,+s.+hansen,+w.+lezius,+and+g.+smith.+2002.++the+tiger+treebank.+in+proceedings+of+the+1st+workshop+on+treebanks+and+linguistic+theories,+pages+24   41,+sozopol.
 321. http://scholar.google.com/scholar?hl=en&q=brigitta,+h.+1996.++deutsch+ist+eine+v/2-sprache+mit+verbendstellung+und+freier+wortfolge.+in+e.+lang+and+g.+zifonun,+editors,+deutsch+  +typologisch,+pages+121   141.+walter+de+gruyter.
 322. http://scholar.google.com/scholar?hl=en&q=brown,+p.+f.,+v.+j.+della+pietra,+p.+v.+desouza,+j.+c.+lai,+and+r.+l.+mercer.+1992.++class-based+id165+models+of+natural+language.+computational+linguistics,+18(4):283   298.
 323. http://scholar.google.com/scholar?hl=en&q=burchardt,+a.,+k.+erk,+a.+frank,+a.+kowalski,+s.+pad  ,+and+m.+pinkal.+2006.++the+salsa+corpus:+a+german+corpus+resource+for+lexical+semantics.+in+proceedings+of+the+international+conference+on+language+resources+and+evaluation,+pages+969   974,+genoa.
 324. https://www.mitpressjournals.org/servlet/linkout?suffix=r12&dbid=16&doi=10.1162/coli_a_00195&key=10.1007/978-3-540-30194-3_6
 325. http://scholar.google.com/scholar?hl=en&q=corston-oliver,+s.+and+m.+gamon.+2004.++normalizing+german+and+english+inflectional+morphology+to+improve+statistical+word+alignment.+in+robert+frederking+and+kathryn+taylor,+editors,+machine+translation:+from+real+users+to+research,+volume+3265+of+lecture+notes+in+computer+science.+springer,+berlin+heidelberg,+pages+48   57.
 326. https://www.mitpressjournals.org/servlet/linkout?suffix=r13&dbid=16&doi=10.1162/coli_a_00195&key=10.2307/415037
 327. http://scholar.google.com/scholar?hl=en&q=dowty,+d.+1991.++thematic+proto+roles+and+argument+selection.+language,+67(3):547   619.
 328. https://www.mitpressjournals.org/servlet/linkout?suffix=r14&dbid=16&doi=10.1162/coli_a_00195&key=10.3115/1699510.1699513
 329. http://scholar.google.com/scholar?hl=en&q=f  rstenau,+h.+and+m.+lapata.+2009.++graph+alignment+for+semi-supervised+semantic+role+labeling.+in+proceedings+of+the+conference+on+empirical+methods+in+natural+language+processing,+pages+11   20,+singapore.
 330. https://www.mitpressjournals.org/doi/10.1162/0891201053630318
 331. http://scholar.google.com/scholar?hl=en&q=gamallo,+p.,+a.+agustini,+and+g.+lopes.+2005.++id91+syntactic+positions+with+similar+semantic+requirements.+computational+linguistics,+31(1):107   146.
 332. http://scholar.google.com/scholar?hl=en&q=garg,+n.+and+j.+henderson.+2012.++unsupervised+semantic+role+induction+with+global+role+ordering.+in+proceedings+of+the+50th+annual+meeting+of+the+association+for+computational+linguistics+(volume+2:+short+papers),+pages+145   149,+jeju+island.
 333. https://www.mitpressjournals.org/doi/10.1162/089120102760275983
 334. http://scholar.google.com/scholar?hl=en&q=gildea,+d.+and+d.+jurafsky.+2002.++automatic+labeling+of+semantic+roles.+computational+linguistics,+28(3):245   288.
 335. http://scholar.google.com/scholar?hl=en&q=gordon,+a.+and+r.+swanson.+2007.++generalizing+semantic+role+annotations+across+syntactically+similar+verbs.+in+proceedings+of+the+annual+meeting+of+the+association+for+computational+linguistics,+pages+192   199,+prague.
 336. http://scholar.google.com/scholar?hl=en&q=gordon,+d.+and+m.+desjardins.+1995.++evaluation+and+selection+of+biases+in+machine+learning.+machine+learning,+20:5   22.
 337. https://www.mitpressjournals.org/servlet/linkout?suffix=r20&dbid=16&doi=10.1162/coli_a_00195&key=10.3115/1610075.1610077
 338. http://scholar.google.com/scholar?hl=en&q=grenager,+t.+and+c.+manning.+2006.++unsupervised+discovery+of+a+statistical+verb+lexicon.+in+proceedings+of+the+2006+conference+on+empirical+methods+in+natural+language+processing,+pages+1   8,+sydney.
 339. https://www.mitpressjournals.org/servlet/linkout?suffix=r21&dbid=16&doi=10.1162/coli_a_00195&key=10.3115/1596409.1596411
 340. http://scholar.google.com/scholar?hl=en&q=haji  ,+j.,+m.+ciaramita,+r.+johansson,+d.+kawahara,+m.+a.+mart  ,+l.+m  rquez,+a.+meyers,+j.+nivre,+s.+pad  ,+j.+  t  p  nek,+p.+stra    k,+m.+surdeanu,+n.+xue,+and+y.+zhang.+2009.++the+conll+2009+shared+task:+syntactic+and+semantic+dependencies+in+multiple+languages.+in+proceedings+of+the+thirteenth+conference+on+computational+natural+language+learning+(conll+2009):+shared+task,+pages+1   18,+boulder,+co.
 341. https://www.mitpressjournals.org/servlet/linkout?suffix=r22&dbid=16&doi=10.1162/coli_a_00195&key=10.1145/331499.331504
 342. http://scholar.google.com/scholar?hl=en&q=jain,+a.,+m.+murty,+and+p.+flynn.+1999.++data+id91:+a+review.+acm+computing+surveys,+31(3):264   323.
 343. http://scholar.google.com/scholar?hl=en&q=kipper,+k.,+h.+t.+dang,+and+m.+palmer.+2000.++class-based+construction+of+a+verb+lexicon.+in+proceedings+of+the+aaai+conference+on+artificial+intelligence,+pages+691   696,+austin,+tx.
 344. https://www.mitpressjournals.org/servlet/linkout?suffix=r24&dbid=16&doi=10.1162/coli_a_00195&key=10.3115/1706543.1706576
 345. http://scholar.google.com/scholar?hl=en&q=koomen,+p.,+v.+punyakanok,+d.+roth,+and+w.+yih.+2005.++generalized+id136+with+multiple+semantic+role+labeling+systems.+in+proceedings+of+the+conference+on+computational+natural+language+learning,+pages+181   184,+ann+arbor,+mi.
 346. http://scholar.google.com/scholar?hl=en&q=lang,+j.+and+m.+lapata.+2010.++unsupervised+induction+of+semantic+roles.+in+proceedings+of+the+north+american+chapter+of+the+association+for+computational+linguistics+conference,+pages+939   947,+los+angeles,+ca.
 347. http://scholar.google.com/scholar?hl=en&q=lang,+j.+and+m.+lapata.+2011a.++unsupervised+induction+of+semantic+roles+via+split-merge+id91.+in+proceedings+of+the+49th+annual+meeting+of+the+association+for+computational+linguistics:+human+language+technologies,+pages+1,117   1,126,+portland,+or.
 348. http://scholar.google.com/scholar?hl=en&q=lang,+j.+and+m.+lapata.+2011b.++unsupervised+semantic+role+induction+with+graph+partitioning.+in+proceedings+of+the+conference+on+empirical+methods+in+natural+language+processing,+pages+1,320   1,331,+edinburgh.
 349. https://www.mitpressjournals.org/servlet/linkout?suffix=r28&dbid=16&doi=10.1162/coli_a_00195&key=10.1017/cbo9780511610479
 350. http://scholar.google.com/scholar?hl=en&q=levin,+b.+and+m.+rappaport.+2005.+argument+realization.+cambridge+university+press.
 351. http://scholar.google.com/scholar?hl=en&q=levin,+beth.+1993.+english+verb+classes+and+alternations:+a+preliminary+investigation.+university+of+chicago+press,+chicago.
 352. http://scholar.google.com/scholar?hl=en&q=lin,+d.+and+p.+pantel.+2001.++discovery+of+id136+rules+for+question-answering.+natural+langugae+engineering,+7:343   360.
 353. https://www.mitpressjournals.org/servlet/linkout?suffix=r31&dbid=16&doi=10.1162/coli_a_00195&key=10.1017/cbo9780511809071
 354. http://scholar.google.com/scholar?hl=en&q=manning,+c.,+p.+raghavan,+and+h.+sch  tze.+2008.+introduction+to+information+retrieval.+cambridge+university+press.
 355. http://scholar.google.com/scholar?hl=en&q=marcus,+m.,+b.+santorini,+and+m.+marcinkiewicz.+1993.++building+a+large+annotated+corpus+of+english:+the+penn+treebank.+computational+linguistics,+19(2):313   330.
 356. https://www.mitpressjournals.org/doi/10.1162/coli.2008.34.2.145
 357. http://scholar.google.com/scholar?hl=en&q=m  rquez,+l.,+x.+carras,+k.+litkowski,+and+s.+stevenson.+2008.++semantic+role+labeling:+an+introduction+to+the+special+issue.+computational+linguistics,+34(2):145   159.
 358. http://scholar.google.com/scholar?hl=en&q=melli,+g.,+y.+wang,+y.+liu,+m.+m.+kashani,+z.+shi,+b.+gu,+a.+sarkar,+and+f.+popowich.+2005.++description+of+squash,+the+sfu+question+answering+summary+handler+for+the+duc-2005+summarization+task.+in+proceedings+of+the+human+language+technology+conference+and+the+conference+on+empirical+methods+in+natural+language+processing+document+understanding+workshop,+vancouver.
 359. https://www.mitpressjournals.org/doi/10.1162/089120101317066122
 360. http://scholar.google.com/scholar?hl=en&q=merlo,+p.+and+s.+stevenson.+2001.++automatic+verb+classification+based+on+statistical+distributions+of+argument+structure.+computational+linguistics,+27:373   408.
 361. https://www.mitpressjournals.org/servlet/linkout?suffix=r36&dbid=16&doi=10.1162/coli_a_00195&key=10.1137/0105003
 362. http://scholar.google.com/scholar?hl=en&q=munkres,+j.+1957.++algorithms+for+the+assignment+and+transportation+problems.+journal+of+the+society+for+industrial+and+applied+mathematics,+5(1):32   38.
 363. http://scholar.google.com/scholar?hl=en&q=nivre,+j.,+j.+hall,+j.+nilsson,+g.+eryigit,+a.+chanev,+s.+k  bler,+s.+marinov,+and+e.+marsi.+2007.++malt-parser:+a+language-independent+system+for+data-driven+dependency+parsing.+natural+language+engineering,+13(2):95   135.
 364. http://scholar.google.com/scholar?hl=en&q=pad  ,+s.+and+m.+lapata.+2009.++cross-lingual+annotation+projection+of+semantic+roles.+journal+of+artificial+intelligence+research,+36:307   340.
 365. https://www.mitpressjournals.org/doi/10.1162/0891201053630264
 366. http://scholar.google.com/scholar?hl=en&q=palmer,+m.,+d.+gildea,+and+p.+kingsbury.+2005.++the+proposition+bank:+an+annotated+corpus+of+semantic+roles.+computational+linguistics,+31(1):71   106.
 367. https://www.mitpressjournals.org/servlet/linkout?suffix=r40&dbid=16&doi=10.1162/coli_a_00195&key=10.3115/1699510.1699512
 368. http://scholar.google.com/scholar?hl=en&q=poon,+h.+and+p.+domingos.+2009.++unsupervised+semantic+parsing.+in+proceedings+of+the+2009+conference+on+empirical+methods+in+natural+language+processing,+pages+1   10,+singapore.
 369. https://www.mitpressjournals.org/doi/10.1162/coli.2008.34.2.289
 370. http://scholar.google.com/scholar?hl=en&q=pradhan,+s.,+w.+ward,+and+j.+martin.+2008.++towards+robust+semantic+role+labeling.+computational+linguistics,+34(2):289   310.
 371. http://scholar.google.com/scholar?hl=en&q=ruppenhofer,+j.,+m.+ellsworth,+m.+petruck,+c.+johnson,+and+j.+scheffczyk.+2006.++framenet+ii:+extended+theory+and+practice,+version+1.3.+technical+report,+international+computer+science+institute,+berkeley,+ca.
 372. https://www.mitpressjournals.org/servlet/linkout?suffix=r43&dbid=16&doi=10.1162/coli_a_00195&key=10.1016/j.cosrev.2007.05.001
 373. http://scholar.google.com/scholar?hl=en&q=schaeffer,+s.+2007.++graph+id91.+computer+science+review,+1(1):27   64.
 374. http://scholar.google.com/scholar?hl=en&q=shen,+d.+and+m.+lapata.+2007.++using+semantic+roles+to+improve+question+answering.+in+proceedings+of+the+2007+joint+conference+on+empirical+methods+in+natural+language+processing+and+computational+natural+language+learning+(emnlp-conll),+pages+12   21,+prague.
 375. http://scholar.google.com/scholar?hl=en&q=smith,+g.+2003.++a+brief+introduction+to+the+tiger+treebank,+version+1.+technical+report,+university+of+potsdam.
 376. https://www.mitpressjournals.org/servlet/linkout?suffix=r46&dbid=16&doi=10.1162/coli_a_00195&key=10.3115/1075096.1075098
 377. http://scholar.google.com/scholar?hl=en&q=surdeanu,+m.,+s.+harabagiu,+j.+williams,+and+p.+aarseth.+2003.++using+predicate-argument+structures+for+information+extraction.+in+proceedings+of+the+annual+meeting+of+the+association+for+computational+linguistics,+pages+8   15,+sapporo.
 378. https://www.mitpressjournals.org/servlet/linkout?suffix=r47&dbid=16&doi=10.1162/coli_a_00195&key=10.3115/1596324.1596352
 379. http://scholar.google.com/scholar?hl=en&q=surdeanu,+m.,+r.+johansson,+a.+meyers,+and+l.+m  rquez.+2008.++the+conll-2008+shared+task+on+joint+parsing+of+syntactic+and+semantic+dependencies.+in+proceedings+of+the+conference+on+natural+language+learning,+pages+159   177,+manchester.
 380. http://scholar.google.com/scholar?hl=en&q=swier,+r.+and+s.+stevenson.+2004.++unsupervised+semantic+role+labelling.+in+proceedings+of+the+conference+on+empirical+methods+in+natural+language+processing,+pages+95   102,+barcelona.
 381. http://scholar.google.com/scholar?hl=en&q=titov,+i.+and+a.+klementiev.+2011.++a+bayesian+model+for+unsupervised+semantic+parsing.+in+proceedings+of+the+49th+annual+meeting+of+the+association+for+computational+linguistics:+human+language+technologies,+pages+1,445   1,455,+portland,+or.
 382. http://scholar.google.com/scholar?hl=en&q=titov,+i.+and+a.+klementiev.+2012a.++a+bayesian+approach+to+unsupervised+semantic+role+induction.+in+proceedings+of+the+13th+conference+of+the+european+chapter+of+the+association+for+computational+linguistics,+pages+12   22,+avignon.
 383. http://scholar.google.com/scholar?hl=en&q=titov,+i.+and+a.+klementiev.+2012b.++crosslingual+induction+of+semantic+roles.+in+proceedings+of+the+50th+annual+meeting+of+the+association+for+computational+linguistics+(volume+1:+long+papers),+pages+647   656,+jeju+island.
 384. https://www.mitpressjournals.org/servlet/linkout?suffix=r52&dbid=16&doi=10.1162/coli_a_00195&key=10.1108/eb026584
 385. http://scholar.google.com/scholar?hl=en&q=van+rijsbergen,+c.+1974.++foundation+of+evaluation.+journal+of+documentation,+30(4):265   374.
 386. https://www.mitpressjournals.org/servlet/linkout?suffix=r53&dbid=16&doi=10.1162/coli_a_00195&key=10.3115/1620853.1620858
 387. http://scholar.google.com/scholar?hl=en&q=wu,+d.+and+p.+fung.+2009.++semantic+roles+for+smt:+a+hybrid+two-pass+model.+in+proceedings+of+human+language+technologies:+the+annual+conference+of+the+north+american+chapter+of+the+association+for+computational+linguistics,+companion+volume:+short+papers,+pages+13   16,+boulder,+co.
 388. http://scholar.google.com/scholar?hl=en&q=zhu,+x.,+z.+ghahramani,+and+j.+lafferty.+2003.++semi-supervised+learning+using+gaussian+fields+and+harmonic+functions.+in+proceedings+of+the+international+conference+on+machine+learning,+pages+912   919,+washington,+dc.
 389. https://www.mitpressjournals.org/cdn-cgi/l/email-protection#63290c060f4d2f020d0423160d0a04064d000b
 390. https://www.mitpressjournals.org/cdn-cgi/l/email-protection#6c01000d1c2c05020a420908420d0f421907
 391. https://doi.org/10.1162/coli_a_00195
 392. https://www.mitpressjournals.org/doi/abs/10.1162/coli_a_00195
 393. https://www.mitpressjournals.org/doi/full/10.1162/coli_a_00195
 394. https://www.mitpressjournals.org/doi/10.1162/coli_a_00195#authors-content
 395. https://www.mitpressjournals.org/doi/10.1162/coli_a_00195#_i1
 396. https://www.mitpressjournals.org/doi/10.1162/coli_a_00195#abstract
 397. https://www.mitpressjournals.org/doi/10.1162/coli_a_00195#_i3
 398. https://www.mitpressjournals.org/doi/10.1162/coli_a_00195
 399. https://www.mitpressjournals.org/doi/10.1162/coli_a_00195
 400. https://www.mitpressjournals.org/doi/10.1162/coli_a_00195
 401. https://www.mitpressjournals.org/doi/10.1162/coli_a_00195
 402. https://www.mitpressjournals.org/doi/10.1162/coli_a_00195
 403. https://www.mitpressjournals.org/doi/10.1162/coli_a_00195
 404. https://www.mitpressjournals.org/doi/10.1162/coli_a_00195
 405. https://www.mitpressjournals.org/doi/10.1162/coli_a_00195#fn3
 406. https://www.mitpressjournals.org/doi/10.1162/coli_a_00195
 407. https://www.mitpressjournals.org/doi/10.1162/coli_a_00195
 408. https://www.mitpressjournals.org/doi/10.1162/coli_a_00195
 409. https://www.mitpressjournals.org/doi/10.1162/coli_a_00195
 410. https://www.mitpressjournals.org/doi/10.1162/coli_a_00195
 411. https://www.mitpressjournals.org/doi/10.1162/coli_a_00195
 412. javascript:popref('s2')
 413. javascript:popref('s3')
 414. javascript:popref('s4')
 415. javascript:popref('s5')
 416. javascript:popref('s6')
 417. javascript:popref('s7')
 418. https://www.mitpressjournals.org/doi/10.1162/coli_a_00195#_i1
 419. https://www.mitpressjournals.org/doi/10.1162/coli_a_00195#_i4
 420. https://www.mitpressjournals.org/doi/10.1162/coli_a_00195
 421. https://www.mitpressjournals.org/doi/10.1162/coli_a_00195
 422. https://www.mitpressjournals.org/doi/10.1162/coli_a_00195
 423. https://www.mitpressjournals.org/doi/10.1162/coli_a_00195
 424. https://www.mitpressjournals.org/doi/10.1162/coli_a_00195
 425. https://www.mitpressjournals.org/doi/10.1162/coli_a_00195
 426. https://www.mitpressjournals.org/doi/10.1162/coli_a_00195
 427. https://www.mitpressjournals.org/doi/10.1162/coli_a_00195
 428. https://www.mitpressjournals.org/doi/10.1162/coli_a_00195
 429. https://www.mitpressjournals.org/doi/10.1162/coli_a_00195
 430. https://www.mitpressjournals.org/doi/10.1162/coli_a_00195
 431. https://www.mitpressjournals.org/doi/10.1162/coli_a_00195
 432. https://www.mitpressjournals.org/doi/10.1162/coli_a_00195
 433. https://www.mitpressjournals.org/doi/10.1162/coli_a_00195
 434. https://www.mitpressjournals.org/doi/10.1162/coli_a_00195
 435. https://www.mitpressjournals.org/doi/10.1162/coli_a_00195
 436. https://www.mitpressjournals.org/doi/10.1162/coli_a_00195
 437. https://www.mitpressjournals.org/doi/10.1162/coli_a_00195
 438. https://www.mitpressjournals.org/doi/10.1162/coli_a_00195
 439. https://www.mitpressjournals.org/doi/10.1162/coli_a_00195
 440. https://www.mitpressjournals.org/doi/10.1162/coli_a_00195
 441. javascript:popref('s4')
 442. https://www.mitpressjournals.org/doi/10.1162/coli_a_00195#_i3
 443. https://www.mitpressjournals.org/doi/10.1162/coli_a_00195#_i12
 444. https://www.mitpressjournals.org/doi/10.1162/coli_a_00195
 445. https://www.mitpressjournals.org/doi/10.1162/coli_a_00195
 446. https://www.mitpressjournals.org/doi/10.1162/coli_a_00195
 447. https://www.mitpressjournals.org/doi/10.1162/coli_a_00195
 448. https://www.mitpressjournals.org/doi/10.1162/coli_a_00195
 449. javascript:popref('s1')
 450. https://www.mitpressjournals.org/doi/10.1162/coli_a_00195#fn4
 451. javascript:popref('s4a')
 452. https://www.mitpressjournals.org/doi/10.1162/coli_a_00195#_i4
 453. https://www.mitpressjournals.org/doi/10.1162/coli_a_00195#_i26
 454. https://www.mitpressjournals.org/doi/10.1162/coli_a_00195
 455. https://www.mitpressjournals.org/doi/10.1162/coli_a_00195
 456. https://www.mitpressjournals.org/doi/10.1162/coli_a_00195#fn5
 457. javascript:popref('s5d')
 458. https://www.mitpressjournals.org/doi/10.1162/coli_a_00195
 459. javascript:popref('s3a')
 460. javascript:popref('s3a')
 461. https://www.mitpressjournals.org/doi/10.1162/coli_a_00195
 462. https://www.mitpressjournals.org/doi/10.1162/coli_a_00195
 463. javascript:popref('e1')
 464. javascript:popref('e1')
 465. javascript:popref('e2')
 466. https://www.mitpressjournals.org/doi/10.1162/coli_a_00195
 467. javascript:popref('e3')
 468. javascript:popref('s4a')
 469. javascript:popref('e1')
 470. javascript:popref('e2')
 471. javascript:popref('e3')
 472. javascript:popref('s4a')
 473. javascript:popref('s5e')
 474. https://www.mitpressjournals.org/doi/10.1162/coli_a_00195
 475. https://www.mitpressjournals.org/doi/10.1162/coli_a_00195#_i12
 476. https://www.mitpressjournals.org/doi/10.1162/coli_a_00195#_i62
 477. javascript:popref('s6')
 478. javascript:popref('s5a')
 479. javascript:popref('s5b')
 480. javascript:popref('s5d')
 481. https://www.mitpressjournals.org/doi/10.1162/coli_a_00195
 482. https://www.mitpressjournals.org/doi/10.1162/coli_a_00195
 483. https://www.mitpressjournals.org/doi/10.1162/coli_a_00195
 484. https://www.mitpressjournals.org/doi/10.1162/coli_a_00195
 485. https://www.mitpressjournals.org/doi/10.1162/coli_a_00195
 486. https://www.mitpressjournals.org/doi/10.1162/coli_a_00195#fn6
 487. https://www.mitpressjournals.org/doi/10.1162/coli_a_00195
 488. javascript:popref('t1')
 489. https://www.mitpressjournals.org/doi/10.1162/coli_a_00195
 490. javascript:popref('t1')
 491. javascript:popref('t1')
 492. https://www.mitpressjournals.org/doi/10.1162/coli_a_00195
 493. https://www.mitpressjournals.org/doi/10.1162/coli_a_00195
 494. https://www.mitpressjournals.org/doi/10.1162/coli_a_00195
 495. https://www.mitpressjournals.org/doi/10.1162/coli_a_00195
 496. https://www.mitpressjournals.org/doi/10.1162/coli_a_00195
 497. javascript:popref('t2')
 498. javascript:popref('t2')
 499. https://www.mitpressjournals.org/doi/10.1162/coli_a_00195
 500. https://www.mitpressjournals.org/doi/10.1162/coli_a_00195
 501. javascript:popref('t2')
 502. https://www.mitpressjournals.org/doi/10.1162/coli_a_00195
 503. https://www.mitpressjournals.org/doi/10.1162/coli_a_00195
 504. javascript:popref('t3')
 505. javascript:popref('t5')
 506. javascript:popref('s4a')
 507. https://www.mitpressjournals.org/doi/10.1162/coli_a_00195
 508. https://www.mitpressjournals.org/doi/10.1162/coli_a_00195#fn7
 509. javascript:popref('t5')
 510. https://www.mitpressjournals.org/doi/10.1162/coli_a_00195
 511. https://www.mitpressjournals.org/doi/10.1162/coli_a_00195
 512. javascript:popref('t3')
 513. javascript:popref('t4')
 514. javascript:popref('t5')
 515. javascript:popref('s5d')
 516. https://www.mitpressjournals.org/doi/10.1162/coli_a_00195
 517. https://www.mitpressjournals.org/doi/10.1162/coli_a_00195
 518. javascript:popref('t6')
 519. https://www.mitpressjournals.org/doi/10.1162/coli_a_00195
 520. https://www.mitpressjournals.org/doi/10.1162/coli_a_00195
 521. javascript:popref('t6')
 522. javascript:popref('t6')
 523. javascript:popref('t7')
 524. javascript:popref('t7')
 525. https://www.mitpressjournals.org/doi/10.1162/coli_a_00195
 526. https://www.mitpressjournals.org/doi/10.1162/coli_a_00195
 527. https://www.mitpressjournals.org/doi/10.1162/coli_a_00195
 528. https://www.mitpressjournals.org/doi/10.1162/coli_a_00195
 529. https://www.mitpressjournals.org/doi/10.1162/coli_a_00195
 530. https://www.mitpressjournals.org/doi/10.1162/coli_a_00195
 531. https://www.mitpressjournals.org/doi/10.1162/coli_a_00195
 532. https://www.mitpressjournals.org/doi/10.1162/coli_a_00195
 533. https://www.mitpressjournals.org/doi/10.1162/coli_a_00195
 534. https://www.mitpressjournals.org/doi/10.1162/coli_a_00195
 535. https://www.mitpressjournals.org/doi/10.1162/coli_a_00195
 536. https://www.mitpressjournals.org/doi/10.1162/coli_a_00195
 537. https://www.mitpressjournals.org/doi/10.1162/coli_a_00195
 538. https://www.mitpressjournals.org/doi/10.1162/coli_a_00195
 539. https://www.mitpressjournals.org/doi/10.1162/coli_a_00195
 540. https://www.mitpressjournals.org/doi/10.1162/coli_a_00195
 541. https://www.mitpressjournals.org/doi/10.1162/coli_a_00195
 542. https://www.mitpressjournals.org/doi/10.1162/coli_a_00195
 543. javascript:popref('t8')
 544. javascript:popref('t9')
 545. javascript:popref('t8')
 546. javascript:popref('t9')
 547. https://www.mitpressjournals.org/doi/10.1162/coli_a_00195#_i26
 548. https://www.mitpressjournals.org/doi/10.1162/coli_a_00195#_i76
 549. https://www.mitpressjournals.org/doi/10.1162/coli_a_00195
 550. javascript:popref('s1')
 551. https://www.mitpressjournals.org/doi/10.1162/coli_a_00195#fn8
 552. https://www.mitpressjournals.org/doi/10.1162/coli_a_00195
 553. https://www.mitpressjournals.org/doi/10.1162/coli_a_00195
 554. https://www.mitpressjournals.org/doi/10.1162/coli_a_00195
 555. https://www.mitpressjournals.org/doi/10.1162/coli_a_00195
 556. https://www.mitpressjournals.org/doi/10.1162/coli_a_00195
 557. https://www.mitpressjournals.org/doi/10.1162/coli_a_00195
 558. https://www.mitpressjournals.org/doi/10.1162/coli_a_00195
 559. https://www.mitpressjournals.org/doi/10.1162/coli_a_00195
 560. javascript:popref('s5')
 561. https://www.mitpressjournals.org/doi/10.1162/coli_a_00195
 562. javascript:popref('s5c')
 563. javascript:popref('t10')
 564. https://www.mitpressjournals.org/doi/10.1162/coli_a_00195
 565. https://www.mitpressjournals.org/doi/10.1162/coli_a_00195
 566. javascript:popref('t10')
 567. https://www.mitpressjournals.org/doi/10.1162/coli_a_00195
 568. javascript:popref('t2')
 569. javascript:popref('t11')
 570. javascript:popref('t12')
 571. javascript:popref('t12')
 572. javascript:popref('t12')
 573. javascript:popref('t11')
 574. javascript:popref('t12')
 575. https://www.mitpressjournals.org/doi/10.1162/coli_a_00195#_i62
 576. https://www.mitpressjournals.org/doi/10.1162/coli_a_00195#_i77
 577. https://www.mitpressjournals.org/doi/10.1162/coli_a_00195
 578. https://www.mitpressjournals.org/doi/10.1162/coli_a_00195
 579. https://www.mitpressjournals.org/doi/10.1162/coli_a_00195
 580. https://www.mitpressjournals.org/doi/10.1162/coli_a_00195#_i76
 581. https://www.mitpressjournals.org/doi/10.1162/coli_a_00195#_i78
 582. javascript:popref('s5b')
 583. javascript:popref('t1')
 584. https://www.mitpressjournals.org/doi/10.1162/coli_a_00195
 585. javascript:popref('t4')
 586. javascript:popref('t1')
 587. https://www.mitpressjournals.org/doi/10.1162/coli_a_00195#_i77
 588. https://www.mitpressjournals.org/doi/10.1162/coli_a_00195#_i79
 589. https://www.mitpressjournals.org/doi/10.1162/coli_a_00195#_i78
 590. https://www.mitpressjournals.org/doi/10.1162/coli_a_00195#citart1
 591. http://scholar.google.com/scholar?hl=en&q=abend,+o.+and+a.+rappoport.+2010a.++fully+unsupervised+core-adjunct+argument+classification.+in+proceedings+of+the+48th+annual+meeting+of+the+association+for+computational+linguistics,+pages+226   236,+uppsala.
 592. http://scholar.google.com/scholar?hl=en&q=abend,+o.+and+a.+rappoport.+2010b.++fully+unsupervised+core-adjunct+argument+classification.+in+proceedings+of+the+annual+meeting+of+the+association+for+computational+linguistics,+pages+226   236,+uppsala.
 593. https://www.mitpressjournals.org/servlet/linkout?suffix=r3&dbid=16&doi=10.1162/coli_a_00195&key=10.3115/1687878.1687884
 594. http://scholar.google.com/scholar?hl=en&q=abend,+o.,+r.+reichart,+and+a.+rappoport.+2009.++unsupervised+argument+identification+for+semantic+role+labeling.+in+proceedings+of+the+annual+meeting+of+the+association+for+computational+linguistics,+pages+28   36,+suntec.
 595. https://www.mitpressjournals.org/servlet/linkout?suffix=r4&dbid=16&doi=10.1162/coli_a_00195&key=10.1201/9781420010800
 596. http://scholar.google.com/scholar?hl=en&q=abney,+s.+2007.+semisupervised+learning+for+computational+linguistics.+chapman+&+hall/crc.
 597. http://scholar.google.com/scholar?hl=en&q=berg-kirkpatrick,+t.,+a.+bouchard-c  t  ,+j.+denero,+and+d.+klein.+2010.++painless+unsupervised+learning+with+features.+in+proceedings+of+the+conference+of+the+north+american+chapter+of+the+association+for+computational+linguistics,+pages+582   590,+los+angeles,+ca.
 598. https://www.mitpressjournals.org/servlet/linkout?suffix=r6&dbid=16&doi=10.1162/coli_a_00195&key=10.3115/1654758.1654774
 599. http://scholar.google.com/scholar?hl=en&q=biemann,+c.+2006.++chinese+whispers:+an+efficient+graph+id91+algorithm+and+its+application+to+natural+language+processing+problems.+in+proceedings+of+textgraphs:+the+first+workshop+on+graph+based+methods+for+natural+language+processing,+pages+73   80,+new+york,+ny.
 600. https://www.mitpressjournals.org/servlet/linkout?suffix=r7&dbid=16&doi=10.1162/coli_a_00195&key=10.1093/ijl/eci043
 601. http://scholar.google.com/scholar?hl=en&q=boas,+h.+2005.++semantic+frames+as+interlingual+representations+for+multilingual+lexical+databases.+international+journal+of+id69,+18(4):445   478.
 602. http://scholar.google.com/scholar?hl=en&q=brants,+s.,+s.+dipper,+s.+hansen,+w.+lezius,+and+g.+smith.+2002.++the+tiger+treebank.+in+proceedings+of+the+1st+workshop+on+treebanks+and+linguistic+theories,+pages+24   41,+sozopol.
 603. http://scholar.google.com/scholar?hl=en&q=brigitta,+h.+1996.++deutsch+ist+eine+v/2-sprache+mit+verbendstellung+und+freier+wortfolge.+in+e.+lang+and+g.+zifonun,+editors,+deutsch+  +typologisch,+pages+121   141.+walter+de+gruyter.
 604. http://scholar.google.com/scholar?hl=en&q=brown,+p.+f.,+v.+j.+della+pietra,+p.+v.+desouza,+j.+c.+lai,+and+r.+l.+mercer.+1992.++class-based+id165+models+of+natural+language.+computational+linguistics,+18(4):283   298.
 605. http://scholar.google.com/scholar?hl=en&q=burchardt,+a.,+k.+erk,+a.+frank,+a.+kowalski,+s.+pad  ,+and+m.+pinkal.+2006.++the+salsa+corpus:+a+german+corpus+resource+for+lexical+semantics.+in+proceedings+of+the+international+conference+on+language+resources+and+evaluation,+pages+969   974,+genoa.
 606. https://www.mitpressjournals.org/servlet/linkout?suffix=r12&dbid=16&doi=10.1162/coli_a_00195&key=10.1007/978-3-540-30194-3_6
 607. http://scholar.google.com/scholar?hl=en&q=corston-oliver,+s.+and+m.+gamon.+2004.++normalizing+german+and+english+inflectional+morphology+to+improve+statistical+word+alignment.+in+robert+frederking+and+kathryn+taylor,+editors,+machine+translation:+from+real+users+to+research,+volume+3265+of+lecture+notes+in+computer+science.+springer,+berlin+heidelberg,+pages+48   57.
 608. https://www.mitpressjournals.org/servlet/linkout?suffix=r13&dbid=16&doi=10.1162/coli_a_00195&key=10.2307/415037
 609. http://scholar.google.com/scholar?hl=en&q=dowty,+d.+1991.++thematic+proto+roles+and+argument+selection.+language,+67(3):547   619.
 610. https://www.mitpressjournals.org/servlet/linkout?suffix=r14&dbid=16&doi=10.1162/coli_a_00195&key=10.3115/1699510.1699513
 611. http://scholar.google.com/scholar?hl=en&q=f  rstenau,+h.+and+m.+lapata.+2009.++graph+alignment+for+semi-supervised+semantic+role+labeling.+in+proceedings+of+the+conference+on+empirical+methods+in+natural+language+processing,+pages+11   20,+singapore.
 612. https://www.mitpressjournals.org/doi/10.1162/0891201053630318
 613. http://scholar.google.com/scholar?hl=en&q=gamallo,+p.,+a.+agustini,+and+g.+lopes.+2005.++id91+syntactic+positions+with+similar+semantic+requirements.+computational+linguistics,+31(1):107   146.
 614. http://scholar.google.com/scholar?hl=en&q=garg,+n.+and+j.+henderson.+2012.++unsupervised+semantic+role+induction+with+global+role+ordering.+in+proceedings+of+the+50th+annual+meeting+of+the+association+for+computational+linguistics+(volume+2:+short+papers),+pages+145   149,+jeju+island.
 615. https://www.mitpressjournals.org/doi/10.1162/089120102760275983
 616. http://scholar.google.com/scholar?hl=en&q=gildea,+d.+and+d.+jurafsky.+2002.++automatic+labeling+of+semantic+roles.+computational+linguistics,+28(3):245   288.
 617. http://scholar.google.com/scholar?hl=en&q=gordon,+a.+and+r.+swanson.+2007.++generalizing+semantic+role+annotations+across+syntactically+similar+verbs.+in+proceedings+of+the+annual+meeting+of+the+association+for+computational+linguistics,+pages+192   199,+prague.
 618. http://scholar.google.com/scholar?hl=en&q=gordon,+d.+and+m.+desjardins.+1995.++evaluation+and+selection+of+biases+in+machine+learning.+machine+learning,+20:5   22.
 619. https://www.mitpressjournals.org/servlet/linkout?suffix=r20&dbid=16&doi=10.1162/coli_a_00195&key=10.3115/1610075.1610077
 620. http://scholar.google.com/scholar?hl=en&q=grenager,+t.+and+c.+manning.+2006.++unsupervised+discovery+of+a+statistical+verb+lexicon.+in+proceedings+of+the+2006+conference+on+empirical+methods+in+natural+language+processing,+pages+1   8,+sydney.
 621. https://www.mitpressjournals.org/servlet/linkout?suffix=r21&dbid=16&doi=10.1162/coli_a_00195&key=10.3115/1596409.1596411
 622. http://scholar.google.com/scholar?hl=en&q=haji  ,+j.,+m.+ciaramita,+r.+johansson,+d.+kawahara,+m.+a.+mart  ,+l.+m  rquez,+a.+meyers,+j.+nivre,+s.+pad  ,+j.+  t  p  nek,+p.+stra    k,+m.+surdeanu,+n.+xue,+and+y.+zhang.+2009.++the+conll+2009+shared+task:+syntactic+and+semantic+dependencies+in+multiple+languages.+in+proceedings+of+the+thirteenth+conference+on+computational+natural+language+learning+(conll+2009):+shared+task,+pages+1   18,+boulder,+co.
 623. https://www.mitpressjournals.org/servlet/linkout?suffix=r22&dbid=16&doi=10.1162/coli_a_00195&key=10.1145/331499.331504
 624. http://scholar.google.com/scholar?hl=en&q=jain,+a.,+m.+murty,+and+p.+flynn.+1999.++data+id91:+a+review.+acm+computing+surveys,+31(3):264   323.
 625. http://scholar.google.com/scholar?hl=en&q=kipper,+k.,+h.+t.+dang,+and+m.+palmer.+2000.++class-based+construction+of+a+verb+lexicon.+in+proceedings+of+the+aaai+conference+on+artificial+intelligence,+pages+691   696,+austin,+tx.
 626. https://www.mitpressjournals.org/servlet/linkout?suffix=r24&dbid=16&doi=10.1162/coli_a_00195&key=10.3115/1706543.1706576
 627. http://scholar.google.com/scholar?hl=en&q=koomen,+p.,+v.+punyakanok,+d.+roth,+and+w.+yih.+2005.++generalized+id136+with+multiple+semantic+role+labeling+systems.+in+proceedings+of+the+conference+on+computational+natural+language+learning,+pages+181   184,+ann+arbor,+mi.
 628. http://scholar.google.com/scholar?hl=en&q=lang,+j.+and+m.+lapata.+2010.++unsupervised+induction+of+semantic+roles.+in+proceedings+of+the+north+american+chapter+of+the+association+for+computational+linguistics+conference,+pages+939   947,+los+angeles,+ca.
 629. http://scholar.google.com/scholar?hl=en&q=lang,+j.+and+m.+lapata.+2011a.++unsupervised+induction+of+semantic+roles+via+split-merge+id91.+in+proceedings+of+the+49th+annual+meeting+of+the+association+for+computational+linguistics:+human+language+technologies,+pages+1,117   1,126,+portland,+or.
 630. http://scholar.google.com/scholar?hl=en&q=lang,+j.+and+m.+lapata.+2011b.++unsupervised+semantic+role+induction+with+graph+partitioning.+in+proceedings+of+the+conference+on+empirical+methods+in+natural+language+processing,+pages+1,320   1,331,+edinburgh.
 631. https://www.mitpressjournals.org/servlet/linkout?suffix=r28&dbid=16&doi=10.1162/coli_a_00195&key=10.1017/cbo9780511610479
 632. http://scholar.google.com/scholar?hl=en&q=levin,+b.+and+m.+rappaport.+2005.+argument+realization.+cambridge+university+press.
 633. http://scholar.google.com/scholar?hl=en&q=levin,+beth.+1993.+english+verb+classes+and+alternations:+a+preliminary+investigation.+university+of+chicago+press,+chicago.
 634. http://scholar.google.com/scholar?hl=en&q=lin,+d.+and+p.+pantel.+2001.++discovery+of+id136+rules+for+question-answering.+natural+langugae+engineering,+7:343   360.
 635. https://www.mitpressjournals.org/servlet/linkout?suffix=r31&dbid=16&doi=10.1162/coli_a_00195&key=10.1017/cbo9780511809071
 636. http://scholar.google.com/scholar?hl=en&q=manning,+c.,+p.+raghavan,+and+h.+sch  tze.+2008.+introduction+to+information+retrieval.+cambridge+university+press.
 637. http://scholar.google.com/scholar?hl=en&q=marcus,+m.,+b.+santorini,+and+m.+marcinkiewicz.+1993.++building+a+large+annotated+corpus+of+english:+the+penn+treebank.+computational+linguistics,+19(2):313   330.
 638. https://www.mitpressjournals.org/doi/10.1162/coli.2008.34.2.145
 639. http://scholar.google.com/scholar?hl=en&q=m  rquez,+l.,+x.+carras,+k.+litkowski,+and+s.+stevenson.+2008.++semantic+role+labeling:+an+introduction+to+the+special+issue.+computational+linguistics,+34(2):145   159.
 640. http://scholar.google.com/scholar?hl=en&q=melli,+g.,+y.+wang,+y.+liu,+m.+m.+kashani,+z.+shi,+b.+gu,+a.+sarkar,+and+f.+popowich.+2005.++description+of+squash,+the+sfu+question+answering+summary+handler+for+the+duc-2005+summarization+task.+in+proceedings+of+the+human+language+technology+conference+and+the+conference+on+empirical+methods+in+natural+language+processing+document+understanding+workshop,+vancouver.
 641. https://www.mitpressjournals.org/doi/10.1162/089120101317066122
 642. http://scholar.google.com/scholar?hl=en&q=merlo,+p.+and+s.+stevenson.+2001.++automatic+verb+classification+based+on+statistical+distributions+of+argument+structure.+computational+linguistics,+27:373   408.
 643. https://www.mitpressjournals.org/servlet/linkout?suffix=r36&dbid=16&doi=10.1162/coli_a_00195&key=10.1137/0105003
 644. http://scholar.google.com/scholar?hl=en&q=munkres,+j.+1957.++algorithms+for+the+assignment+and+transportation+problems.+journal+of+the+society+for+industrial+and+applied+mathematics,+5(1):32   38.
 645. http://scholar.google.com/scholar?hl=en&q=nivre,+j.,+j.+hall,+j.+nilsson,+g.+eryigit,+a.+chanev,+s.+k  bler,+s.+marinov,+and+e.+marsi.+2007.++malt-parser:+a+language-independent+system+for+data-driven+dependency+parsing.+natural+language+engineering,+13(2):95   135.
 646. http://scholar.google.com/scholar?hl=en&q=pad  ,+s.+and+m.+lapata.+2009.++cross-lingual+annotation+projection+of+semantic+roles.+journal+of+artificial+intelligence+research,+36:307   340.
 647. https://www.mitpressjournals.org/doi/10.1162/0891201053630264
 648. http://scholar.google.com/scholar?hl=en&q=palmer,+m.,+d.+gildea,+and+p.+kingsbury.+2005.++the+proposition+bank:+an+annotated+corpus+of+semantic+roles.+computational+linguistics,+31(1):71   106.
 649. https://www.mitpressjournals.org/servlet/linkout?suffix=r40&dbid=16&doi=10.1162/coli_a_00195&key=10.3115/1699510.1699512
 650. http://scholar.google.com/scholar?hl=en&q=poon,+h.+and+p.+domingos.+2009.++unsupervised+semantic+parsing.+in+proceedings+of+the+2009+conference+on+empirical+methods+in+natural+language+processing,+pages+1   10,+singapore.
 651. https://www.mitpressjournals.org/doi/10.1162/coli.2008.34.2.289
 652. http://scholar.google.com/scholar?hl=en&q=pradhan,+s.,+w.+ward,+and+j.+martin.+2008.++towards+robust+semantic+role+labeling.+computational+linguistics,+34(2):289   310.
 653. http://scholar.google.com/scholar?hl=en&q=ruppenhofer,+j.,+m.+ellsworth,+m.+petruck,+c.+johnson,+and+j.+scheffczyk.+2006.++framenet+ii:+extended+theory+and+practice,+version+1.3.+technical+report,+international+computer+science+institute,+berkeley,+ca.
 654. https://www.mitpressjournals.org/servlet/linkout?suffix=r43&dbid=16&doi=10.1162/coli_a_00195&key=10.1016/j.cosrev.2007.05.001
 655. http://scholar.google.com/scholar?hl=en&q=schaeffer,+s.+2007.++graph+id91.+computer+science+review,+1(1):27   64.
 656. http://scholar.google.com/scholar?hl=en&q=shen,+d.+and+m.+lapata.+2007.++using+semantic+roles+to+improve+question+answering.+in+proceedings+of+the+2007+joint+conference+on+empirical+methods+in+natural+language+processing+and+computational+natural+language+learning+(emnlp-conll),+pages+12   21,+prague.
 657. http://scholar.google.com/scholar?hl=en&q=smith,+g.+2003.++a+brief+introduction+to+the+tiger+treebank,+version+1.+technical+report,+university+of+potsdam.
 658. https://www.mitpressjournals.org/servlet/linkout?suffix=r46&dbid=16&doi=10.1162/coli_a_00195&key=10.3115/1075096.1075098
 659. http://scholar.google.com/scholar?hl=en&q=surdeanu,+m.,+s.+harabagiu,+j.+williams,+and+p.+aarseth.+2003.++using+predicate-argument+structures+for+information+extraction.+in+proceedings+of+the+annual+meeting+of+the+association+for+computational+linguistics,+pages+8   15,+sapporo.
 660. https://www.mitpressjournals.org/servlet/linkout?suffix=r47&dbid=16&doi=10.1162/coli_a_00195&key=10.3115/1596324.1596352
 661. http://scholar.google.com/scholar?hl=en&q=surdeanu,+m.,+r.+johansson,+a.+meyers,+and+l.+m  rquez.+2008.++the+conll-2008+shared+task+on+joint+parsing+of+syntactic+and+semantic+dependencies.+in+proceedings+of+the+conference+on+natural+language+learning,+pages+159   177,+manchester.
 662. http://scholar.google.com/scholar?hl=en&q=swier,+r.+and+s.+stevenson.+2004.++unsupervised+semantic+role+labelling.+in+proceedings+of+the+conference+on+empirical+methods+in+natural+language+processing,+pages+95   102,+barcelona.
 663. http://scholar.google.com/scholar?hl=en&q=titov,+i.+and+a.+klementiev.+2011.++a+bayesian+model+for+unsupervised+semantic+parsing.+in+proceedings+of+the+49th+annual+meeting+of+the+association+for+computational+linguistics:+human+language+technologies,+pages+1,445   1,455,+portland,+or.
 664. http://scholar.google.com/scholar?hl=en&q=titov,+i.+and+a.+klementiev.+2012a.++a+bayesian+approach+to+unsupervised+semantic+role+induction.+in+proceedings+of+the+13th+conference+of+the+european+chapter+of+the+association+for+computational+linguistics,+pages+12   22,+avignon.
 665. http://scholar.google.com/scholar?hl=en&q=titov,+i.+and+a.+klementiev.+2012b.++crosslingual+induction+of+semantic+roles.+in+proceedings+of+the+50th+annual+meeting+of+the+association+for+computational+linguistics+(volume+1:+long+papers),+pages+647   656,+jeju+island.
 666. https://www.mitpressjournals.org/servlet/linkout?suffix=r52&dbid=16&doi=10.1162/coli_a_00195&key=10.1108/eb026584
 667. http://scholar.google.com/scholar?hl=en&q=van+rijsbergen,+c.+1974.++foundation+of+evaluation.+journal+of+documentation,+30(4):265   374.
 668. https://www.mitpressjournals.org/servlet/linkout?suffix=r53&dbid=16&doi=10.1162/coli_a_00195&key=10.3115/1620853.1620858
 669. http://scholar.google.com/scholar?hl=en&q=wu,+d.+and+p.+fung.+2009.++semantic+roles+for+smt:+a+hybrid+two-pass+model.+in+proceedings+of+human+language+technologies:+the+annual+conference+of+the+north+american+chapter+of+the+association+for+computational+linguistics,+companion+volume:+short+papers,+pages+13   16,+boulder,+co.
 670. http://scholar.google.com/scholar?hl=en&q=zhu,+x.,+z.+ghahramani,+and+j.+lafferty.+2003.++semi-supervised+learning+using+gaussian+fields+and+harmonic+functions.+in+proceedings+of+the+international+conference+on+machine+learning,+pages+912   919,+washington,+dc.
 671. https://www.mitpressjournals.org/cdn-cgi/l/email-protection#e9a3868c85c7a588878ea99c87808e8cc78a81
 672. https://www.mitpressjournals.org/cdn-cgi/l/email-protection#1c71707d6c5c75727a327978327d7f326977
 673. https://www.mitpressjournals.org/forthcoming/coli
 674. https://www.mitpressjournals.org/doi/10.1162/coli_a_00195
 675. https://www.mitpressjournals.org/author/lang,+joel
 676. https://www.mitpressjournals.org/author/lapata,+mirella
 677. https://doi.org/10.1162/coli_a_00195
 678. https://www.mitpressjournals.org/doi/full/10.1162/coli_a_00195
 679. https://www.mitpressjournals.org/doi/10.1162/coli_a_00195#authors-content
 680. http://www.mitpressjournals.org/doi/pdf/10.1162/coli_a_00195
 681. http://www.mitpressjournals.org/doi/pdfplus/10.1162/coli_a_00195
 682. https://www.mitpressjournals.org/doi/10.1162/coli_a_00195#_i1
 683. https://www.mitpressjournals.org/doi/10.1162/coli_a_00195#abstract
 684. https://www.mitpressjournals.org/doi/10.1162/coli_a_00195#_i3
 685. https://www.mitpressjournals.org/doi/10.1162/coli_a_00195
 686. https://www.mitpressjournals.org/doi/10.1162/coli_a_00195
 687. https://www.mitpressjournals.org/doi/10.1162/coli_a_00195
 688. https://www.mitpressjournals.org/doi/10.1162/coli_a_00195
 689. https://www.mitpressjournals.org/doi/10.1162/coli_a_00195
 690. https://www.mitpressjournals.org/doi/10.1162/coli_a_00195
 691. https://www.mitpressjournals.org/doi/10.1162/coli_a_00195
 692. https://www.mitpressjournals.org/doi/10.1162/coli_a_00195#fn3
 693. https://www.mitpressjournals.org/doi/10.1162/coli_a_00195
 694. https://www.mitpressjournals.org/doi/10.1162/coli_a_00195
 695. https://www.mitpressjournals.org/doi/10.1162/coli_a_00195
 696. https://www.mitpressjournals.org/doi/10.1162/coli_a_00195
 697. https://www.mitpressjournals.org/doi/10.1162/coli_a_00195
 698. https://www.mitpressjournals.org/doi/10.1162/coli_a_00195
 699. javascript:popref('s2')
 700. javascript:popref('s3')
 701. javascript:popref('s4')
 702. javascript:popref('s5')
 703. javascript:popref('s6')
 704. javascript:popref('s7')
 705. https://www.mitpressjournals.org/doi/10.1162/coli_a_00195#_i1
 706. https://www.mitpressjournals.org/doi/10.1162/coli_a_00195#_i4
 707. https://www.mitpressjournals.org/doi/10.1162/coli_a_00195
 708. https://www.mitpressjournals.org/doi/10.1162/coli_a_00195
 709. https://www.mitpressjournals.org/doi/10.1162/coli_a_00195
 710. https://www.mitpressjournals.org/doi/10.1162/coli_a_00195
 711. https://www.mitpressjournals.org/doi/10.1162/coli_a_00195
 712. https://www.mitpressjournals.org/doi/10.1162/coli_a_00195
 713. https://www.mitpressjournals.org/doi/10.1162/coli_a_00195
 714. https://www.mitpressjournals.org/doi/10.1162/coli_a_00195
 715. https://www.mitpressjournals.org/doi/10.1162/coli_a_00195
 716. https://www.mitpressjournals.org/doi/10.1162/coli_a_00195
 717. https://www.mitpressjournals.org/doi/10.1162/coli_a_00195
 718. https://www.mitpressjournals.org/doi/10.1162/coli_a_00195
 719. https://www.mitpressjournals.org/doi/10.1162/coli_a_00195
 720. https://www.mitpressjournals.org/doi/10.1162/coli_a_00195
 721. https://www.mitpressjournals.org/doi/10.1162/coli_a_00195
 722. https://www.mitpressjournals.org/doi/10.1162/coli_a_00195
 723. https://www.mitpressjournals.org/doi/10.1162/coli_a_00195
 724. https://www.mitpressjournals.org/doi/10.1162/coli_a_00195
 725. https://www.mitpressjournals.org/doi/10.1162/coli_a_00195
 726. https://www.mitpressjournals.org/doi/10.1162/coli_a_00195
 727. https://www.mitpressjournals.org/doi/10.1162/coli_a_00195
 728. javascript:popref('s4')
 729. https://www.mitpressjournals.org/doi/10.1162/coli_a_00195#_i3
 730. https://www.mitpressjournals.org/doi/10.1162/coli_a_00195#_i12
 731. https://www.mitpressjournals.org/doi/10.1162/coli_a_00195
 732. https://www.mitpressjournals.org/doi/10.1162/coli_a_00195
 733. https://www.mitpressjournals.org/doi/10.1162/coli_a_00195
 734. https://www.mitpressjournals.org/doi/10.1162/coli_a_00195
 735. https://www.mitpressjournals.org/doi/10.1162/coli_a_00195
 736. javascript:popref('s1')
 737. https://www.mitpressjournals.org/doi/10.1162/coli_a_00195#fn4
 738. javascript:popref('s4a')
 739. https://www.mitpressjournals.org/doi/10.1162/coli_a_00195#_i4
 740. https://www.mitpressjournals.org/doi/10.1162/coli_a_00195#_i26
 741. https://www.mitpressjournals.org/doi/10.1162/coli_a_00195
 742. https://www.mitpressjournals.org/doi/10.1162/coli_a_00195
 743. https://www.mitpressjournals.org/doi/10.1162/coli_a_00195#fn5
 744. javascript:popref('s5d')
 745. https://www.mitpressjournals.org/doi/10.1162/coli_a_00195
 746. javascript:popref('s3a')
 747. javascript:popref('s3a')
 748. https://www.mitpressjournals.org/doi/10.1162/coli_a_00195
 749. https://www.mitpressjournals.org/doi/10.1162/coli_a_00195
 750. javascript:popref('e1')
 751. javascript:popref('e1')
 752. javascript:popref('e2')
 753. https://www.mitpressjournals.org/doi/10.1162/coli_a_00195
 754. javascript:popref('e3')
 755. javascript:popref('s4a')
 756. javascript:popref('e1')
 757. javascript:popref('e2')
 758. javascript:popref('e3')
 759. javascript:popref('s4a')
 760. javascript:popref('s5e')
 761. https://www.mitpressjournals.org/doi/10.1162/coli_a_00195
 762. https://www.mitpressjournals.org/doi/10.1162/coli_a_00195#_i12
 763. https://www.mitpressjournals.org/doi/10.1162/coli_a_00195#_i62
 764. javascript:popref('s6')
 765. javascript:popref('s5a')
 766. javascript:popref('s5b')
 767. javascript:popref('s5d')
 768. https://www.mitpressjournals.org/doi/10.1162/coli_a_00195
 769. https://www.mitpressjournals.org/doi/10.1162/coli_a_00195
 770. https://www.mitpressjournals.org/doi/10.1162/coli_a_00195
 771. https://www.mitpressjournals.org/doi/10.1162/coli_a_00195
 772. https://www.mitpressjournals.org/doi/10.1162/coli_a_00195
 773. https://www.mitpressjournals.org/doi/10.1162/coli_a_00195#fn6
 774. https://www.mitpressjournals.org/doi/10.1162/coli_a_00195
 775. javascript:popref('t1')
 776. https://www.mitpressjournals.org/doi/10.1162/coli_a_00195
 777. javascript:popref('t1')
 778. javascript:popref('t1')
 779. https://www.mitpressjournals.org/doi/10.1162/coli_a_00195
 780. https://www.mitpressjournals.org/doi/10.1162/coli_a_00195
 781. https://www.mitpressjournals.org/doi/10.1162/coli_a_00195
 782. https://www.mitpressjournals.org/doi/10.1162/coli_a_00195
 783. https://www.mitpressjournals.org/doi/10.1162/coli_a_00195
 784. javascript:popref('t2')
 785. javascript:popref('t2')
 786. https://www.mitpressjournals.org/doi/10.1162/coli_a_00195
 787. https://www.mitpressjournals.org/doi/10.1162/coli_a_00195
 788. javascript:popref('t2')
 789. https://www.mitpressjournals.org/doi/10.1162/coli_a_00195
 790. https://www.mitpressjournals.org/doi/10.1162/coli_a_00195
 791. javascript:popref('t3')
 792. javascript:popref('t5')
 793. javascript:popref('s4a')
 794. https://www.mitpressjournals.org/doi/10.1162/coli_a_00195
 795. https://www.mitpressjournals.org/doi/10.1162/coli_a_00195#fn7
 796. javascript:popref('t5')
 797. https://www.mitpressjournals.org/doi/10.1162/coli_a_00195
 798. https://www.mitpressjournals.org/doi/10.1162/coli_a_00195
 799. javascript:popref('t3')
 800. javascript:popref('t4')
 801. javascript:popref('t5')
 802. javascript:popref('s5d')
 803. https://www.mitpressjournals.org/doi/10.1162/coli_a_00195
 804. https://www.mitpressjournals.org/doi/10.1162/coli_a_00195
 805. javascript:popref('t6')
 806. https://www.mitpressjournals.org/doi/10.1162/coli_a_00195
 807. https://www.mitpressjournals.org/doi/10.1162/coli_a_00195
 808. javascript:popref('t6')
 809. javascript:popref('t6')
 810. javascript:popref('t7')
 811. javascript:popref('t7')
 812. https://www.mitpressjournals.org/doi/10.1162/coli_a_00195
 813. https://www.mitpressjournals.org/doi/10.1162/coli_a_00195
 814. https://www.mitpressjournals.org/doi/10.1162/coli_a_00195
 815. https://www.mitpressjournals.org/doi/10.1162/coli_a_00195
 816. https://www.mitpressjournals.org/doi/10.1162/coli_a_00195
 817. https://www.mitpressjournals.org/doi/10.1162/coli_a_00195
 818. https://www.mitpressjournals.org/doi/10.1162/coli_a_00195
 819. https://www.mitpressjournals.org/doi/10.1162/coli_a_00195
 820. https://www.mitpressjournals.org/doi/10.1162/coli_a_00195
 821. https://www.mitpressjournals.org/doi/10.1162/coli_a_00195
 822. https://www.mitpressjournals.org/doi/10.1162/coli_a_00195
 823. https://www.mitpressjournals.org/doi/10.1162/coli_a_00195
 824. https://www.mitpressjournals.org/doi/10.1162/coli_a_00195
 825. https://www.mitpressjournals.org/doi/10.1162/coli_a_00195
 826. https://www.mitpressjournals.org/doi/10.1162/coli_a_00195
 827. https://www.mitpressjournals.org/doi/10.1162/coli_a_00195
 828. https://www.mitpressjournals.org/doi/10.1162/coli_a_00195
 829. https://www.mitpressjournals.org/doi/10.1162/coli_a_00195
 830. javascript:popref('t8')
 831. javascript:popref('t9')
 832. javascript:popref('t8')
 833. javascript:popref('t9')
 834. https://www.mitpressjournals.org/doi/10.1162/coli_a_00195#_i26
 835. https://www.mitpressjournals.org/doi/10.1162/coli_a_00195#_i76
 836. https://www.mitpressjournals.org/doi/10.1162/coli_a_00195
 837. javascript:popref('s1')
 838. https://www.mitpressjournals.org/doi/10.1162/coli_a_00195#fn8
 839. https://www.mitpressjournals.org/doi/10.1162/coli_a_00195
 840. https://www.mitpressjournals.org/doi/10.1162/coli_a_00195
 841. https://www.mitpressjournals.org/doi/10.1162/coli_a_00195
 842. https://www.mitpressjournals.org/doi/10.1162/coli_a_00195
 843. https://www.mitpressjournals.org/doi/10.1162/coli_a_00195
 844. https://www.mitpressjournals.org/doi/10.1162/coli_a_00195
 845. https://www.mitpressjournals.org/doi/10.1162/coli_a_00195
 846. https://www.mitpressjournals.org/doi/10.1162/coli_a_00195
 847. javascript:popref('s5')
 848. https://www.mitpressjournals.org/doi/10.1162/coli_a_00195
 849. javascript:popref('s5c')
 850. javascript:popref('t10')
 851. https://www.mitpressjournals.org/doi/10.1162/coli_a_00195
 852. https://www.mitpressjournals.org/doi/10.1162/coli_a_00195
 853. javascript:popref('t10')
 854. https://www.mitpressjournals.org/doi/10.1162/coli_a_00195
 855. javascript:popref('t2')
 856. javascript:popref('t11')
 857. javascript:popref('t12')
 858. javascript:popref('t12')
 859. javascript:popref('t12')
 860. javascript:popref('t11')
 861. javascript:popref('t12')
 862. https://www.mitpressjournals.org/doi/10.1162/coli_a_00195#_i62
 863. https://www.mitpressjournals.org/doi/10.1162/coli_a_00195#_i77
 864. https://www.mitpressjournals.org/doi/10.1162/coli_a_00195
 865. https://www.mitpressjournals.org/doi/10.1162/coli_a_00195
 866. https://www.mitpressjournals.org/doi/10.1162/coli_a_00195
 867. https://www.mitpressjournals.org/doi/10.1162/coli_a_00195#_i76
 868. https://www.mitpressjournals.org/doi/10.1162/coli_a_00195#_i78
 869. javascript:popref('s5b')
 870. javascript:popref('t1')
 871. https://www.mitpressjournals.org/doi/10.1162/coli_a_00195
 872. javascript:popref('t4')
 873. javascript:popref('t1')
 874. https://www.mitpressjournals.org/doi/10.1162/coli_a_00195#_i77
 875. https://www.mitpressjournals.org/doi/10.1162/coli_a_00195#_i79
 876. https://www.mitpressjournals.org/doi/10.1162/coli_a_00195#_i78
 877. https://www.mitpressjournals.org/doi/10.1162/coli_a_00195#citart1
 878. http://scholar.google.com/scholar?hl=en&q=abend,+o.+and+a.+rappoport.+2010a.++fully+unsupervised+core-adjunct+argument+classification.+in+proceedings+of+the+48th+annual+meeting+of+the+association+for+computational+linguistics,+pages+226   236,+uppsala.
 879. http://scholar.google.com/scholar?hl=en&q=abend,+o.+and+a.+rappoport.+2010b.++fully+unsupervised+core-adjunct+argument+classification.+in+proceedings+of+the+annual+meeting+of+the+association+for+computational+linguistics,+pages+226   236,+uppsala.
 880. https://www.mitpressjournals.org/servlet/linkout?suffix=r3&dbid=16&doi=10.1162/coli_a_00195&key=10.3115/1687878.1687884
 881. http://scholar.google.com/scholar?hl=en&q=abend,+o.,+r.+reichart,+and+a.+rappoport.+2009.++unsupervised+argument+identification+for+semantic+role+labeling.+in+proceedings+of+the+annual+meeting+of+the+association+for+computational+linguistics,+pages+28   36,+suntec.
 882. https://www.mitpressjournals.org/servlet/linkout?suffix=r4&dbid=16&doi=10.1162/coli_a_00195&key=10.1201/9781420010800
 883. http://scholar.google.com/scholar?hl=en&q=abney,+s.+2007.+semisupervised+learning+for+computational+linguistics.+chapman+&+hall/crc.
 884. http://scholar.google.com/scholar?hl=en&q=berg-kirkpatrick,+t.,+a.+bouchard-c  t  ,+j.+denero,+and+d.+klein.+2010.++painless+unsupervised+learning+with+features.+in+proceedings+of+the+conference+of+the+north+american+chapter+of+the+association+for+computational+linguistics,+pages+582   590,+los+angeles,+ca.
 885. https://www.mitpressjournals.org/servlet/linkout?suffix=r6&dbid=16&doi=10.1162/coli_a_00195&key=10.3115/1654758.1654774
 886. http://scholar.google.com/scholar?hl=en&q=biemann,+c.+2006.++chinese+whispers:+an+efficient+graph+id91+algorithm+and+its+application+to+natural+language+processing+problems.+in+proceedings+of+textgraphs:+the+first+workshop+on+graph+based+methods+for+natural+language+processing,+pages+73   80,+new+york,+ny.
 887. https://www.mitpressjournals.org/servlet/linkout?suffix=r7&dbid=16&doi=10.1162/coli_a_00195&key=10.1093/ijl/eci043
 888. http://scholar.google.com/scholar?hl=en&q=boas,+h.+2005.++semantic+frames+as+interlingual+representations+for+multilingual+lexical+databases.+international+journal+of+id69,+18(4):445   478.
 889. http://scholar.google.com/scholar?hl=en&q=brants,+s.,+s.+dipper,+s.+hansen,+w.+lezius,+and+g.+smith.+2002.++the+tiger+treebank.+in+proceedings+of+the+1st+workshop+on+treebanks+and+linguistic+theories,+pages+24   41,+sozopol.
 890. http://scholar.google.com/scholar?hl=en&q=brigitta,+h.+1996.++deutsch+ist+eine+v/2-sprache+mit+verbendstellung+und+freier+wortfolge.+in+e.+lang+and+g.+zifonun,+editors,+deutsch+  +typologisch,+pages+121   141.+walter+de+gruyter.
 891. http://scholar.google.com/scholar?hl=en&q=brown,+p.+f.,+v.+j.+della+pietra,+p.+v.+desouza,+j.+c.+lai,+and+r.+l.+mercer.+1992.++class-based+id165+models+of+natural+language.+computational+linguistics,+18(4):283   298.
 892. http://scholar.google.com/scholar?hl=en&q=burchardt,+a.,+k.+erk,+a.+frank,+a.+kowalski,+s.+pad  ,+and+m.+pinkal.+2006.++the+salsa+corpus:+a+german+corpus+resource+for+lexical+semantics.+in+proceedings+of+the+international+conference+on+language+resources+and+evaluation,+pages+969   974,+genoa.
 893. https://www.mitpressjournals.org/servlet/linkout?suffix=r12&dbid=16&doi=10.1162/coli_a_00195&key=10.1007/978-3-540-30194-3_6
 894. http://scholar.google.com/scholar?hl=en&q=corston-oliver,+s.+and+m.+gamon.+2004.++normalizing+german+and+english+inflectional+morphology+to+improve+statistical+word+alignment.+in+robert+frederking+and+kathryn+taylor,+editors,+machine+translation:+from+real+users+to+research,+volume+3265+of+lecture+notes+in+computer+science.+springer,+berlin+heidelberg,+pages+48   57.
 895. https://www.mitpressjournals.org/servlet/linkout?suffix=r13&dbid=16&doi=10.1162/coli_a_00195&key=10.2307/415037
 896. http://scholar.google.com/scholar?hl=en&q=dowty,+d.+1991.++thematic+proto+roles+and+argument+selection.+language,+67(3):547   619.
 897. https://www.mitpressjournals.org/servlet/linkout?suffix=r14&dbid=16&doi=10.1162/coli_a_00195&key=10.3115/1699510.1699513
 898. http://scholar.google.com/scholar?hl=en&q=f  rstenau,+h.+and+m.+lapata.+2009.++graph+alignment+for+semi-supervised+semantic+role+labeling.+in+proceedings+of+the+conference+on+empirical+methods+in+natural+language+processing,+pages+11   20,+singapore.
 899. https://www.mitpressjournals.org/doi/10.1162/0891201053630318
 900. http://scholar.google.com/scholar?hl=en&q=gamallo,+p.,+a.+agustini,+and+g.+lopes.+2005.++id91+syntactic+positions+with+similar+semantic+requirements.+computational+linguistics,+31(1):107   146.
 901. http://scholar.google.com/scholar?hl=en&q=garg,+n.+and+j.+henderson.+2012.++unsupervised+semantic+role+induction+with+global+role+ordering.+in+proceedings+of+the+50th+annual+meeting+of+the+association+for+computational+linguistics+(volume+2:+short+papers),+pages+145   149,+jeju+island.
 902. https://www.mitpressjournals.org/doi/10.1162/089120102760275983
 903. http://scholar.google.com/scholar?hl=en&q=gildea,+d.+and+d.+jurafsky.+2002.++automatic+labeling+of+semantic+roles.+computational+linguistics,+28(3):245   288.
 904. http://scholar.google.com/scholar?hl=en&q=gordon,+a.+and+r.+swanson.+2007.++generalizing+semantic+role+annotations+across+syntactically+similar+verbs.+in+proceedings+of+the+annual+meeting+of+the+association+for+computational+linguistics,+pages+192   199,+prague.
 905. http://scholar.google.com/scholar?hl=en&q=gordon,+d.+and+m.+desjardins.+1995.++evaluation+and+selection+of+biases+in+machine+learning.+machine+learning,+20:5   22.
 906. https://www.mitpressjournals.org/servlet/linkout?suffix=r20&dbid=16&doi=10.1162/coli_a_00195&key=10.3115/1610075.1610077
 907. http://scholar.google.com/scholar?hl=en&q=grenager,+t.+and+c.+manning.+2006.++unsupervised+discovery+of+a+statistical+verb+lexicon.+in+proceedings+of+the+2006+conference+on+empirical+methods+in+natural+language+processing,+pages+1   8,+sydney.
 908. https://www.mitpressjournals.org/servlet/linkout?suffix=r21&dbid=16&doi=10.1162/coli_a_00195&key=10.3115/1596409.1596411
 909. http://scholar.google.com/scholar?hl=en&q=haji  ,+j.,+m.+ciaramita,+r.+johansson,+d.+kawahara,+m.+a.+mart  ,+l.+m  rquez,+a.+meyers,+j.+nivre,+s.+pad  ,+j.+  t  p  nek,+p.+stra    k,+m.+surdeanu,+n.+xue,+and+y.+zhang.+2009.++the+conll+2009+shared+task:+syntactic+and+semantic+dependencies+in+multiple+languages.+in+proceedings+of+the+thirteenth+conference+on+computational+natural+language+learning+(conll+2009):+shared+task,+pages+1   18,+boulder,+co.
 910. https://www.mitpressjournals.org/servlet/linkout?suffix=r22&dbid=16&doi=10.1162/coli_a_00195&key=10.1145/331499.331504
 911. http://scholar.google.com/scholar?hl=en&q=jain,+a.,+m.+murty,+and+p.+flynn.+1999.++data+id91:+a+review.+acm+computing+surveys,+31(3):264   323.
 912. http://scholar.google.com/scholar?hl=en&q=kipper,+k.,+h.+t.+dang,+and+m.+palmer.+2000.++class-based+construction+of+a+verb+lexicon.+in+proceedings+of+the+aaai+conference+on+artificial+intelligence,+pages+691   696,+austin,+tx.
 913. https://www.mitpressjournals.org/servlet/linkout?suffix=r24&dbid=16&doi=10.1162/coli_a_00195&key=10.3115/1706543.1706576
 914. http://scholar.google.com/scholar?hl=en&q=koomen,+p.,+v.+punyakanok,+d.+roth,+and+w.+yih.+2005.++generalized+id136+with+multiple+semantic+role+labeling+systems.+in+proceedings+of+the+conference+on+computational+natural+language+learning,+pages+181   184,+ann+arbor,+mi.
 915. http://scholar.google.com/scholar?hl=en&q=lang,+j.+and+m.+lapata.+2010.++unsupervised+induction+of+semantic+roles.+in+proceedings+of+the+north+american+chapter+of+the+association+for+computational+linguistics+conference,+pages+939   947,+los+angeles,+ca.
 916. http://scholar.google.com/scholar?hl=en&q=lang,+j.+and+m.+lapata.+2011a.++unsupervised+induction+of+semantic+roles+via+split-merge+id91.+in+proceedings+of+the+49th+annual+meeting+of+the+association+for+computational+linguistics:+human+language+technologies,+pages+1,117   1,126,+portland,+or.
 917. http://scholar.google.com/scholar?hl=en&q=lang,+j.+and+m.+lapata.+2011b.++unsupervised+semantic+role+induction+with+graph+partitioning.+in+proceedings+of+the+conference+on+empirical+methods+in+natural+language+processing,+pages+1,320   1,331,+edinburgh.
 918. https://www.mitpressjournals.org/servlet/linkout?suffix=r28&dbid=16&doi=10.1162/coli_a_00195&key=10.1017/cbo9780511610479
 919. http://scholar.google.com/scholar?hl=en&q=levin,+b.+and+m.+rappaport.+2005.+argument+realization.+cambridge+university+press.
 920. http://scholar.google.com/scholar?hl=en&q=levin,+beth.+1993.+english+verb+classes+and+alternations:+a+preliminary+investigation.+university+of+chicago+press,+chicago.
 921. http://scholar.google.com/scholar?hl=en&q=lin,+d.+and+p.+pantel.+2001.++discovery+of+id136+rules+for+question-answering.+natural+langugae+engineering,+7:343   360.
 922. https://www.mitpressjournals.org/servlet/linkout?suffix=r31&dbid=16&doi=10.1162/coli_a_00195&key=10.1017/cbo9780511809071
 923. http://scholar.google.com/scholar?hl=en&q=manning,+c.,+p.+raghavan,+and+h.+sch  tze.+2008.+introduction+to+information+retrieval.+cambridge+university+press.
 924. http://scholar.google.com/scholar?hl=en&q=marcus,+m.,+b.+santorini,+and+m.+marcinkiewicz.+1993.++building+a+large+annotated+corpus+of+english:+the+penn+treebank.+computational+linguistics,+19(2):313   330.
 925. https://www.mitpressjournals.org/doi/10.1162/coli.2008.34.2.145
 926. http://scholar.google.com/scholar?hl=en&q=m  rquez,+l.,+x.+carras,+k.+litkowski,+and+s.+stevenson.+2008.++semantic+role+labeling:+an+introduction+to+the+special+issue.+computational+linguistics,+34(2):145   159.
 927. http://scholar.google.com/scholar?hl=en&q=melli,+g.,+y.+wang,+y.+liu,+m.+m.+kashani,+z.+shi,+b.+gu,+a.+sarkar,+and+f.+popowich.+2005.++description+of+squash,+the+sfu+question+answering+summary+handler+for+the+duc-2005+summarization+task.+in+proceedings+of+the+human+language+technology+conference+and+the+conference+on+empirical+methods+in+natural+language+processing+document+understanding+workshop,+vancouver.
 928. https://www.mitpressjournals.org/doi/10.1162/089120101317066122
 929. http://scholar.google.com/scholar?hl=en&q=merlo,+p.+and+s.+stevenson.+2001.++automatic+verb+classification+based+on+statistical+distributions+of+argument+structure.+computational+linguistics,+27:373   408.
 930. https://www.mitpressjournals.org/servlet/linkout?suffix=r36&dbid=16&doi=10.1162/coli_a_00195&key=10.1137/0105003
 931. http://scholar.google.com/scholar?hl=en&q=munkres,+j.+1957.++algorithms+for+the+assignment+and+transportation+problems.+journal+of+the+society+for+industrial+and+applied+mathematics,+5(1):32   38.
 932. http://scholar.google.com/scholar?hl=en&q=nivre,+j.,+j.+hall,+j.+nilsson,+g.+eryigit,+a.+chanev,+s.+k  bler,+s.+marinov,+and+e.+marsi.+2007.++malt-parser:+a+language-independent+system+for+data-driven+dependency+parsing.+natural+language+engineering,+13(2):95   135.
 933. http://scholar.google.com/scholar?hl=en&q=pad  ,+s.+and+m.+lapata.+2009.++cross-lingual+annotation+projection+of+semantic+roles.+journal+of+artificial+intelligence+research,+36:307   340.
 934. https://www.mitpressjournals.org/doi/10.1162/0891201053630264
 935. http://scholar.google.com/scholar?hl=en&q=palmer,+m.,+d.+gildea,+and+p.+kingsbury.+2005.++the+proposition+bank:+an+annotated+corpus+of+semantic+roles.+computational+linguistics,+31(1):71   106.
 936. https://www.mitpressjournals.org/servlet/linkout?suffix=r40&dbid=16&doi=10.1162/coli_a_00195&key=10.3115/1699510.1699512
 937. http://scholar.google.com/scholar?hl=en&q=poon,+h.+and+p.+domingos.+2009.++unsupervised+semantic+parsing.+in+proceedings+of+the+2009+conference+on+empirical+methods+in+natural+language+processing,+pages+1   10,+singapore.
 938. https://www.mitpressjournals.org/doi/10.1162/coli.2008.34.2.289
 939. http://scholar.google.com/scholar?hl=en&q=pradhan,+s.,+w.+ward,+and+j.+martin.+2008.++towards+robust+semantic+role+labeling.+computational+linguistics,+34(2):289   310.
 940. http://scholar.google.com/scholar?hl=en&q=ruppenhofer,+j.,+m.+ellsworth,+m.+petruck,+c.+johnson,+and+j.+scheffczyk.+2006.++framenet+ii:+extended+theory+and+practice,+version+1.3.+technical+report,+international+computer+science+institute,+berkeley,+ca.
 941. https://www.mitpressjournals.org/servlet/linkout?suffix=r43&dbid=16&doi=10.1162/coli_a_00195&key=10.1016/j.cosrev.2007.05.001
 942. http://scholar.google.com/scholar?hl=en&q=schaeffer,+s.+2007.++graph+id91.+computer+science+review,+1(1):27   64.
 943. http://scholar.google.com/scholar?hl=en&q=shen,+d.+and+m.+lapata.+2007.++using+semantic+roles+to+improve+question+answering.+in+proceedings+of+the+2007+joint+conference+on+empirical+methods+in+natural+language+processing+and+computational+natural+language+learning+(emnlp-conll),+pages+12   21,+prague.
 944. http://scholar.google.com/scholar?hl=en&q=smith,+g.+2003.++a+brief+introduction+to+the+tiger+treebank,+version+1.+technical+report,+university+of+potsdam.
 945. https://www.mitpressjournals.org/servlet/linkout?suffix=r46&dbid=16&doi=10.1162/coli_a_00195&key=10.3115/1075096.1075098
 946. http://scholar.google.com/scholar?hl=en&q=surdeanu,+m.,+s.+harabagiu,+j.+williams,+and+p.+aarseth.+2003.++using+predicate-argument+structures+for+information+extraction.+in+proceedings+of+the+annual+meeting+of+the+association+for+computational+linguistics,+pages+8   15,+sapporo.
 947. https://www.mitpressjournals.org/servlet/linkout?suffix=r47&dbid=16&doi=10.1162/coli_a_00195&key=10.3115/1596324.1596352
 948. http://scholar.google.com/scholar?hl=en&q=surdeanu,+m.,+r.+johansson,+a.+meyers,+and+l.+m  rquez.+2008.++the+conll-2008+shared+task+on+joint+parsing+of+syntactic+and+semantic+dependencies.+in+proceedings+of+the+conference+on+natural+language+learning,+pages+159   177,+manchester.
 949. http://scholar.google.com/scholar?hl=en&q=swier,+r.+and+s.+stevenson.+2004.++unsupervised+semantic+role+labelling.+in+proceedings+of+the+conference+on+empirical+methods+in+natural+language+processing,+pages+95   102,+barcelona.
 950. http://scholar.google.com/scholar?hl=en&q=titov,+i.+and+a.+klementiev.+2011.++a+bayesian+model+for+unsupervised+semantic+parsing.+in+proceedings+of+the+49th+annual+meeting+of+the+association+for+computational+linguistics:+human+language+technologies,+pages+1,445   1,455,+portland,+or.
 951. http://scholar.google.com/scholar?hl=en&q=titov,+i.+and+a.+klementiev.+2012a.++a+bayesian+approach+to+unsupervised+semantic+role+induction.+in+proceedings+of+the+13th+conference+of+the+european+chapter+of+the+association+for+computational+linguistics,+pages+12   22,+avignon.
 952. http://scholar.google.com/scholar?hl=en&q=titov,+i.+and+a.+klementiev.+2012b.++crosslingual+induction+of+semantic+roles.+in+proceedings+of+the+50th+annual+meeting+of+the+association+for+computational+linguistics+(volume+1:+long+papers),+pages+647   656,+jeju+island.
 953. https://www.mitpressjournals.org/servlet/linkout?suffix=r52&dbid=16&doi=10.1162/coli_a_00195&key=10.1108/eb026584
 954. http://scholar.google.com/scholar?hl=en&q=van+rijsbergen,+c.+1974.++foundation+of+evaluation.+journal+of+documentation,+30(4):265   374.
 955. https://www.mitpressjournals.org/servlet/linkout?suffix=r53&dbid=16&doi=10.1162/coli_a_00195&key=10.3115/1620853.1620858
 956. http://scholar.google.com/scholar?hl=en&q=wu,+d.+and+p.+fung.+2009.++semantic+roles+for+smt:+a+hybrid+two-pass+model.+in+proceedings+of+human+language+technologies:+the+annual+conference+of+the+north+american+chapter+of+the+association+for+computational+linguistics,+companion+volume:+short+papers,+pages+13   16,+boulder,+co.
 957. http://scholar.google.com/scholar?hl=en&q=zhu,+x.,+z.+ghahramani,+and+j.+lafferty.+2003.++semi-supervised+learning+using+gaussian+fields+and+harmonic+functions.+in+proceedings+of+the+international+conference+on+machine+learning,+pages+912   919,+washington,+dc.
 958. https://www.mitpressjournals.org/cdn-cgi/l/email-protection#de94b1bbb2f092bfb0b99eabb0b7b9bbf0bdb6
 959. https://www.mitpressjournals.org/cdn-cgi/l/email-protection#cda0a1acbd8da4a3abe3a8a9e3acaee3b8a6
 960. https://www.mitpressjournals.org/personalize/addfavoritepublication?doi=10.1162/coli_a_00195
 961. https://www.mitpressjournals.org/action/showcitformats?doi=10.1162/coli_a_00195
 962. https://www.mitpressjournals.org/action/showfeed?jc=coli&type=etoc&feed=rss
 963. https://www.mitpressjournals.org/action/showfeed?jc=coli&doi=10.1162/coli_a_00195&type=citrack&feed=rss
 964. https://www.mitpressjournals.org/journals/coli/sub
 965. https://giving.mit.edu/taxonomy/term/79#3920880
 966. https://www.mitpressjournals.org/
 967. http://www.mitpressjournals.org/action/showpublications
 968. http://mitpress.mit.edu/
 969. https://www.mitpressjournals.org/terms
 970. https://www.mitpressjournals.org/privacy
 971. https://www.mitpressjournals.org/contact_info
 972. https://www.facebook.com/mitpress
 973. http://www.twitter.com/mitpress
 974. https://plus.google.com/106848724929282487337?prsrc=3
 975. https://www.pinterest.com/mitpress/
 976. https://www.instagram.com/mitpress/
 977. https://www.youtube.com/channel/uceh0hmlpjgw2dn0ntmd0fcq
 978. https://www.atypon.com/
 979. https://www.crossref.org/
 980. https://www.projectcounter.org/
 981. https://www.mitpressjournals.org/help/main

   hidden links:
 983. https://www.mitpressjournals.org/doi/10.1162/coli_a_00195
 984. https://www.mitpressjournals.org/doi/10.1162/coli_a_00195
 985. https://www.mitpressjournals.org/action/oauth/linkedin?start=1&redirecturi=%2fdoi%2f10.1162%2fcoli_a_00195
 986. https://www.mitpressjournals.org/action/oauth/facebook?start=1&redirecturi=%2fdoi%2f10.1162%2fcoli_a_00195
 987. https://www.mitpressjournals.org/action/oauth/twitter?start=1&redirecturi=%2fdoi%2f10.1162%2fcoli_a_00195
 988. https://www.mitpressjournals.org/action/registration
 989. https://www.mitpressjournals.org/action/ssostart?redirecturi=%2fdoi%2f10.1162%2fcoli_a_00195
 990. https://www.mitpressjournals.org/doi/10.1162/coli_a_00195
 991. https://www.mitpressjournals.org/action/showlogin?uri=%2fdoi%2f10.1162%2fcoli_a_00195
 992. https://www.mitpressjournals.org/action/showcart?flowid=1
 993. javascript:popref('s2')
 994. javascript:popref('s3')
 995. javascript:popref('s4')
 996. javascript:popref('s4a')
 997. javascript:popref('s5')
 998. javascript:popref('s5a')
 999. javascript:popref('s5b')
1000. javascript:popref('s5d')
1001. javascript:popref('s5e')
1002. javascript:popref('t4')
1003. javascript:popref('s6')
1004. javascript:popref('s7')
1005. javascript:popref('s1')
1006. javascript:popref('s2')
1007. javascript:popref('s3')
1008. javascript:popref('s3a')
1009. javascript:popref('s4')
1010. javascript:popref('s4a')
1011. javascript:popref('e1')
1012. javascript:popref('e2')
1013. javascript:popref('e3')
1014. javascript:popref('s5')
1015. javascript:popref('s5a')
1016. javascript:popref('s5b')
1017. javascript:popref('s5c')
1018. javascript:popref('s5d')
1019. javascript:popref('s5e')
1020. javascript:popref('t4')
1021. javascript:popref('s6')
1022. javascript:popref('s7')
1023. javascript:popref('s1')
1024. javascript:popref('s2')
1025. javascript:popref('s3')
1026. javascript:popref('s3a')
1027. javascript:popref('s4')
1028. javascript:popref('s4a')
1029. javascript:popref('e1')
1030. javascript:popref('e2')
1031. javascript:popref('e3')
1032. javascript:popref('s5')
1033. javascript:popref('s5a')
1034. javascript:popref('s5b')
1035. javascript:popref('s5c')
1036. javascript:popref('s5d')
1037. javascript:popref('s5e')
1038. javascript:popref('t4')
1039. javascript:popref('s6')
1040. javascript:popref('s7')
1041. https://www.mitpressjournals.org/action/addcitationalert?doi=10.1162/coli_a_00195&referrer=10.1162/coli_a_00195
