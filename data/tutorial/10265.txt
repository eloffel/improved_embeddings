6
1
0
2

 

g
u
a
5

 

 
 
]
l
c
.
s
c
[
 
 

2
v
9
6
9
7
0

.

1
0
6
1
:
v
i
x
r
a

zipf    s law is a consequence of coherent language production
jake ryland williams,1,     james p. bagrow,2,     andrew j. reagan,2,     sharon
e. alajajian,1,    christopher m. danforth,2,    and peter sheridan dodds2,       

1school of information, university of california,

berkeley 102 south hall #4600 berkeley, ca 94720-4600.

2department of mathematics & statistics, vermont complex systems center,

computational story lab, & the vermont advanced computing core,

the university of vermont, burlington, vt 05401.

(dated: august 9, 2016)

the task of text segmentation may be undertaken at many levels in text analysis   paragraphs,
sentences, words, or even letters. here, we focus on a relatively    ne scale of segmentation, hypothe-
sizing it to be in accord with a stochastic model of language generation, as the smallest scale where
independent units of meaning are produced. our goals in this letter include the development of meth-
ods for the segmentation of these minimal independent units, which produce feature-representations
of texts that align with the independence assumption of the bag-of-terms model, commonly used for
prediction and classi   cation in computational text analysis. we also propose the measurement of
texts    association (with respect to realized segmentations) to the model of language generation. we
   nd (1) that our segmentations of phrases exhibit much better associations to the generation model
than words and (2), that texts which are well    t are generally topically homogeneous. because
our generative model produces zipf   s law, our study further suggests that zipf   s law may be a
consequence of homogeneity in language production.

pacs numbers: 89.65.-s, 89.75.-k, 89.70.-a

in our previous work on text partitioning [1], and again
in our study on the e   ects of text mixing [2], we have
observed the relevance of the selection model proposed
long ago by simon [3]. we will build on this model again,
together with zipf   s law [4, 5], as the basis for a model
of frequency data of text.

the de   ning aspects of simon   s model for language
generation hold that as the terms of a text appear, they
do so independently, and in proportion to their historic
frequencies of occurrence. the    rst assumption (of mem-
oryless term-term independence) is likewise the basis for
the bag-of-terms model that is pervasive in the compu-
tational text analysis community. it is evident that this
assumption fails for strictly de   ned words when one con-
siders the dependence of terms that are bound, like new,
york, and city. as we have argued in [2], dependence
can also be caused by mixing, where the rate of a term   s
occurrence varies in a composite corpus of many texts as
one transitions from document to document.

the two types of dependence indicate that for the
simon model to apply, and consequently, for the bag-
of-terms model to apply, texts should be analyzed on
the homogeneous (unmixed) scales of production (i.e., by
writer, or even topic), and that the terms of texts should
be segmented according to their local dependence (i.e.,
grouped together into irreducible expressions), rendering
distributions of terms of mixed sizes. the    rst criterion
can be relatively easy to satisfy, and in our analyses will
come for free by the curation of the project gutenberg
ebooks [6] database. the second, however, poses a much
greater challenge, as the meanings that bind words into
meaning-irreducible forms are only known a priori to the

typeset by revtex

writers who generate text for their meanings.

in our work on stochastic text partitioning [1], we pro-
posed a simple mechanism for the    ne-grained chunking
of text into phrases. under this framework, sentences
were broken down stochastically, splitting on whitespace
with a uniform bond-breakage id203, q. while this
(uniform) framework is clearly not the ideal mechanism
to isolate phrases for, say, dictionary lookups, we did    nd
that random partitioning of phrases (q = 1
2 ) produced
zipf laws extending many orders of magnitude in rank
beyond the standard version for words only.

here, we wish to explore informed partitions, taking
into account empirical segmentation information. some
interesting options for estimating bond-breakage fre-
quencies exist   in language learning environments, sim-
ilar data are generated through exercises referred to as
phrase-cued text, which have been shown to help learners
develop id144 [7] (the patterns of stress and intonation,
considered to be one of the essential features of reading
   uency [8]). this suggests value in the phrase-scale of
segmentation.

to obtain phrases, surveys (essentially classroom exer-
cises) could be run that would bene   t educators and
students, while developing a base of training data for
informed partitions.
ideally, such surveys would have
students learning a language asked to segment their own
writing. however, this is unconventional in the class-
room, and poses a more di   cult task to request. so, for
now we will turn to expertly-segmented data.

in the computational linguistics (cl) community there
have been recent e   orts to establish benchmarks and
testing sets for multiword expressions (mwes) (loosely

2

de   ned as groups of    tokens in a sentence that cohere
more strongly than ordinary syntactic combinations   )
extraction [9]. while these data can be used to inform a
partitioner, they are alone insu   cient (narrowly focused
on business reviews), and are better used for testing and
benchmarking. furthermore, it is not clear if mwes and
their extraction (used for work in information retrieval
and other cl tasks) coincide with language generation
and distributional representations, which are the focus,
here. we have also executed a companion piece to this
study [10], focused on the task of mwe extraction, where
the text partitioning framework was tuned to exhibit its
ability to perform as strongly, if not better than, the
state-of-the-art [11], with very substantial increases in
speed, while being trained on less data.

for training, we turn to the bond-breakage information
held latently inside of the wiktionary [12] with its trove
of larger-than-word entries and their example usages.
noting that example usages of phrases in the wiktionary
are consistently coded in boldfaced text, we are able to
resolve isolated empirical bond-breakage frequency data.
for example, at the time of writing this letter, the entry
for the phrase    have a ball    was represented by the usage:

the kids had a ball playing in the fountain.

which informed us that (kids, had) is a pair more like-
ly split, and that (had, a) is a pair more likely bound.
the wiktionary examples have the added bonus of being
trustworthy, on account of their being archetypal-usage
examples, and will serve to inform our partitions for all
of the experiments in this letter. however, to make
informed text partitions available in many other lan-
guages (where examples may be less proli   c and/or coded
di   erently), we also construct bond-breakage frequencies
in a similar manner, but from the embedded hyperlinks
on wikipedia, which are ubiquitous and coded-for con-
sistently across languages. from either source of data,
we de   ne the partitioning id203, q(w(cid:96), wr), for an
ordered pair of words, (w(cid:96), wr), according to the total
number of known bond breaking appearances fb(w(cid:96), wr)
and the total number of bond preserving appearances
fp(w(cid:96), wr):

q(w(cid:96), wr) =

fb(w(cid:96), wr)

fp(w(cid:96), wr) + fb(w(cid:96), wr)

,

with the resulting q-values falling on the same side of q =
0.5 for     65% of all unique word pairs (which later will
be all that is necessary to ensure equivalent partitions),
and as much as 75% for those most frequently appearing.
while the two sources share coverage on about 20, 000
word pairs (and disagree on a substantial number), we
note that the wikipedia hyperlinks source is much larger,
with coverage on many proper nouns (names of places,
people, etc.), which were found to be important for mwe
identi   cation in [10].

in our original work on text partitioning [1], we con-
sidered stochastic text partitions, where bonds between
pairs words would either be preserved or broken at ran-
dom (uniformly). despite our solving for the analyt-
ic expectation across all possible partitions of phrase-
partition frequencies, it became necessary to execute one-
o    random partitions for the study of true rank-frequency
distributions. however for cl tasks, these stochastic par-
titions have little value on account of their variation, and
while the variation in the case of informed stochastic par-
titions is reduced, it is still not ideal, as cl tasks require
consistency.

a perhaps unexpected bonus to the na    vet  e of our
assumptions (speci   cally, de   ning the q   s to be indepen-
dent of one another) is that the maximum likelihood par-
tition (mlp), or most frequently occurring partition of a
text, is easily computed. accepting this partition (for a
text) is deterministic, and accomplished simply by break-
ing a bond whenever its bounding pair of words have a
breakage id203 of at least 0.5   note that this con-
servatively sets the ill-determined case of q = 0.5 to bond-
breaking. using this scheme, a text can be segmented
very rapidly based on the wiktionary (with the same
computational complexity as simple word count), and
requires no global information. for all of these reasons   
speed, determinism, and maximum likelihood   we con-
tinue with the mlp in this work.

we now return to simon   s model of language gen-
eration, which analytically produces single-parameter
power-law rank-frequency distributions, and is our
hypothesis as the dominant productive mechanism for
zipf   s law. zipf   s law succinctly formulates a relation-
ship between the frequencies of occurrence of terms, and
their ranks by frequency (descending):

f = c    r     ,

(1)

with a default value of q(w(cid:96), wr) = 1 for all pairs unob-
served in a training set. note that this model is still quite
na    ve, and may be improved by allowing values of q to
vary, depending on terms existing farther away in a text.
however, training a more sophisticated partitioner like
this would be done best if the training data were fully
segmented (which might be accomplished with phrase-
cued text).

for a scaling constant, c. simon   s model has one tun-
able parameter   the rate of term introduction,   . when
language is generated by simon   s model, zipf   s scaling
exponent is given by    = 1       , and in the case of an
empirical text, the term introduction rate can be inferred
as    = n/m , where n is the number of unique term
types in the text, and m is the total number of all terms
occurring in a text.

we note that both sources (examples and hyperlinks)
have a reasonable degree of accord (considering english),

the main caveat for the compatibility of zipf   s empir-
ical law with simon   s theoretical model arises from the

3

goodness of    t for the zipf/simon model, and as a result
of the simon model   s independence assumption, a mea-
sure of the quality of a text   s bag-of-terms representation.
note that this will also give us an opportunity to evaluate
the qualitative nature of language produced by simon   s
model.

since the connection of simon   s model to the parame-
ter    occurs naturally in the complimentary cumulative
distribution function (ccdf) of term frequencies, we
measure and regress all quantities along ccdfs, while
we present all results in the intuitive and familiar rank-
frequency (zipf) representations.

in fig. 1, we plot an example informed partition for
herman melville   s    moby dick    (black line, main axes),
and behind it, the spectrum of uniform stochastic par-
titions ranging from q = 0 (green) sentences/clauses, to
q = 1 (pink) words. one can see the distributions steepen
along the gradient as q is increased (which is generally the
trend throughout the ebooks), and as much can be seen
in the lower inset, where a regressed scaling parameter   
is compared with   mod = 1       . also within the main
axes lies the zipf/simon    t for the the informed partition
(blue, dashed), which appears reasonable by inspection,
and outperforms all uniform partitions (including the
q = 1 word partition) by goodness of    t of the zipf/simon
model (upper inset), where the informed partition is indi-
cated by the black point (in both insets). note that this
increased quality of    t by the zipf/simon model is also
observed readily in the lower inset, where    and 1       
nearly align.

q=1 < r2

q=1 = r2

zooming out to the larger collection of (roughly
20, 000) english ebooks, we focus on comparing two par-
titions for each text   the q = 1 (word) partitions, and
the informed (phrase) partitions. in fig. 2, we compare
the goodness of    t by the zipf/simon model between the
two partition types. this comparison divides the collec-
tion of books into two subsets that we will refer to as the
word-based and phrase-based texts. our demarcation
is given by the line r2
mlp (red, dashed), and
shows that most texts were better bag-models under the
informed (phrase-based, r2
mlp) partition frame-
work. while a good number of texts (    20%) are word-
based, we note that these texts tend to have weaker r2
values in general, which can be seen in fig. 3 where we
apply an r2 cuto    to the books and measure the por-
tion of the data set removed. this quanti   es the num-
bers of phrase-and word-based texts that are strong    ts
(r2 > 0.6) to be in a proportion of more than 12:1,
respectively, indicating that a strongly-   t bag-of-terms
representation of a text is better (and generally quite
signi   cantly) achieved by mlp phrases more than 90%
of the time.
from fig. 3, we can see that r2     0.6 appears near a
sharp drop for the cuto   , which, if applied as a thresh-
old for analysis, results in approximately a 20% loss (red
line/stars) for the dataset (largely due to the low-r2,

fig. 1: the main axes show rank-frequency distributions
from herman melville   s    moby dick    for one-o    uniform
stochastic partitions for values of q ranging from 0 (green) to
1 (pink), together with a one-o   , dictionary-informed stochas-
tic partition (black) and its zipf/simon model (blue, dashed).
in the upper inset we present the zipf/simon goodness of    t
as a function of q (with the black point for the informed par-
tition positioned at the text   s average value of q), and in the
lower inset we present regressed scalings (  ) against those
determined by the zipf/simon model (1       ). in the lower
inset, complete agreement occurs along the (blue dashed) line
1        =   , and for both insets, colors of points correspond to
those in the main axes.

fact that simon   s model is only able to generate single-
scaling rank-frequency distributions with scaling param-
eters    in [0, 1). while many texts exhibit multiple scal-
ings and values of    larger than 1, we have seen that these
anomalies are often the result of text mixing and term
dependence [2]. consequently, we view the degree to
which a particular zipf/simon model aligns with empir-
ical rank-frequency data as a measure of the goodness
of    t for the    bag-of-terms    representation (id121)
of a text (regardless of how the terms are de   ned, i.e.,
words or phrases).

the zipf/simon    t for a text of n unique and m total
words is de   ned as follows. assuming a text was gener-
ated precisely according to simon   s model, the constant
word introduction rate is inferred by the text-wide aver-
age:    = n/m , and an estimate of the scaling exponent
is then   mod = 1       . the exact form of the model   s
   t is then obtained by computing the constant of pro-
portionality: cmod = n   mod, whereupon we may take
the coe   cient of determination, or r2, as a measure of

4

fig. 2: we plot the goodness of    t (r2) of the zipf/simon
model, applied to the texts of the english project gutenberg
ebooks database, where the dictionary-informed one-o    parti-
tions (horizontal axis) are plotted against the q = 1 word par-
titions (vertical axis). the discriminating line (red, dashed,
r2
q=1) helps divide the collection into texts that are
word-based and phrase-based.

mlp = r2

word-based texts). by allowing the books to be either
phrase- or word-based (according to their r2 values), we
are then able to accommodate a strong (r2     0.6)    bag   
analysis for over 80% of the dataset, which is a large
improvement over the conventional, blanket usage of
words (dashed blue line/open circles), which only accom-
modates strong    ts for approximately 37.5% of the col-
lection.

while one can view the     20% of poorly-   t books as a
loss to quality analysis, it is possible that re   nement of
the partition function (through better data or modeling)
would allow one to obtain better id121s/   ts for
all books. however, one can also look at these 20% in
a di   erent way   as potentially being un   t for the bag-
of-terms framework. sorting the ebooks according to
mlp}, we    nd the ten poorest    ts to include
max{r2
dictionaries, spelling books, and books of extremely small
size (often as placeholders for other media), indicating
that low r2 values appropriately identify texts un   t for
analyses.

q=1, r2

mlp (strictly, as r2

to explore the qualitative nature of    t quality and
the zipf/simon model, we also consider the variation of
r2
q=1 is so frequently outperformed)
across the di   erent library of congress classi   cations
(fig. 4, top), and subjects (fig. 4, bottom) provided
in the ebooks collection. this variation can be seen in

fig. 3:
the percent of books in the project gutenberg
english ebooks database that are phrase-based (solid green
line,    lled squares), word-based (solid blue line,    lled circles),
and poorly    t (red line, stars), when a cuto    in r2 is applied
mlp occurs near r2     0.6, which is
(right). a dropo    in r2
denoted by the vertical, black dotted line. we also present
curves that indicate the percents of books remaining above the
cuto    when blanketed usage of either words (blue dashed line,
open circles) or informed phrases (green dashed line, open
squares) are applied.

fig. 4, where we observe stark di   erences in the ranges
of box plots. as the majority of texts have an mlp
representation that is relatively strong (r2
mlp > 0.6),
the medians for most classi   cations are high. howev-
er, it is clear that texts under classi   cation a   general
works, which includes dictionaries, encyclopedias, and
periodicals   are more often poorly-   t. this is of note,
as all other classi   cations, including textbook-reference
classi   cations, such as medicine (r), law (k), and naval
(v) and military (u) science, exhibit medians substan-
tially above 0.6, though we note that many classi   ca-
tions exhibit outliers of low r2
mlp, notably with language
and literature (p), which contains long, brief, and mixed
texts.

the main di   erence we note between classi   cation a
and the other reference classi   cations mentioned is that
the general works of a are frequently not topically homo-
geneous. this observation is echoed in the bottom of
fig. 4, where we consider the ebooks    subjects. here, we
again see low values for dictionaries and periodicals, but
likewise for other heterogeneous subjects, such as ques-
tions and answers, travel, and social life. we also    nd
that poetry, short stories, and science    ction all exhibit
a large proportion of low r2
mlp values. these subjects all

share the commonality of frequent brevity. this makes
some sense in relation to the simon model, as the gener-
ation of a text may not have an opportunity to stabilize
(distributionally). we also note that the science    ction
subject may frequently use phrases that are outside of
the informed partitioner   s training.

our results show that informed text partitioning is
capable of improving the basic methodologies of fea-
ture selection in text analysis on a broad scale, allow-
ing for better adherence to assumptions (speci   cally, for
the bag-of-terms model) that underpin a vast collection
of algorithms currently in practice throughout industry
and academia. additionally, phrase-based text analysis
improves the independent interpretability of features   
in the soft sense, at the level of user experience. with
phrase-based text analysis, end-point users (e.g., poli-
cy makers or product users interpreting lists of phrase-
feature topics from a topic model readout) who may not
understand the workings of an algorithm will be better
able to interpret results, as phrases provide critical con-
text for interpretation. we have also proposed the mea-
surement of association to a model of language genera-
tion, which we have found here to be the likely mech-
anism for the production of topically-homogeneous lan-
guage, allowing us to assert new meaning for the pres-
ence of zipf   s law in natural language   long observed,
though largely a mystery. we also suggest the possibility
that as phrase-segmentation methods improve, associa-
tion to the zipf/simon model might also be used as a
metric for determination of topical breaks in text, since
r2
mlp does appear to increase in the presence of topically-
homogeneous texts.

to make these tools both explorable and avail-
able to the computational text analysis community,
we have with this letter developed a python pack-
age for text partitioning (for detailed information,
see https://github.com/jakerylandwilliams/partitioner),
which makes our
tools available in 11 languages
(english, german, russian, portuguese, polish, dutch,
italian, french, finnish, spanish and greek), and
in addition present an explorable online appendix
(http://jakerylandwilliams.github.io/partitioner/).

    electronic address: jakerylandwilliams@berkeley.edu
    electronic address: james.bagrow@uvm.edu
    electronic address: andrew.reagan@uvm.edu
   electronic address: sharon@ischool.berkeley.edu
   electronic address: chris.danforth@uvm.edu
       electronic address: peter.dodds@uvm.edu
[1] j. r. williams, p. r. lessard, s. desu, e. m.
and
(2015),

j. p. bagrow, c. m. danforth,

clark,
p.
http://arxiv.org/abs/1406.5181.

corr abs/1406.5181

s. dodds,

5

fig. 4: box plots, showing variation of r2
mlp across the
primary library of congress classi   cations (top), and a selec-
tion of the project gutenberg ebooks subjects (bottom). all
boxes represent at least 50 texts.

dodds, corr (2015), http://arxiv.org/abs/1409.3870.

[3] h. a. simon, biometrika 42, 425 (1955).
[4] g. k. zipf, the psycho-biology of language (houghton-

mi   in, 1935).

[5] g. k. zipf, human behaviour and the principle of least-

e   ort (addison-wesley, 1949).

[6] project gutenberg (2010), http://www.gutenberg.org.
[7] m. j. glavach, the practical teacher (2011).
[8] j. miller and p. j. schwanen   ugel, journal of education-

al psychology 98, 839 (2006).

[9] n. schneider, s. onu   er, n. kazour, e. danchik, m. t.
mordowanec, h. conrad, and n. a. smith, in proceed-
ings of the ninth international conference on language
resources and evaluation (lrec   14) (european lan-
guage resources association (elra), reykjavik, ice-
land, 2014), isbn 978-2-9517408-8-4.

[10] j. r. williams,

corr (2016),

url

http:

//people.ischool.berkeley.edu/~jakeryland/
documents/williams2016b.pdf.
[11] n. schneider and n. a. smith,

in proceedings of the
2015 conference of the north american chapter of the
association for computational linguistics: human lan-
guage technologies (association for computational lin-
guistics, denver, colorado, 2015), pp. 1537   1547, url
http://www.aclweb.org/anthology/n15-1177.

[2] j. r. williams, j. p. bagrow, c. m. danforth, and p. s.

[12] wiktionary (2014), http://dumps.wikimedia.org/enwiktionary/2014.

