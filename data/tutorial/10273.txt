6
1
0
2

 

n
a
j
 

2

 
 
]
i
s
.
s
c
[
 
 

1
v
9
3
1
0
0

.

1
0
6
1
:
v
i
x
r
a

group centrality for semantic networks:
a swot analysis featuring id93

camilo garrido, ricardo mora, and claudio gutierrez

department of computer science, universidad de chile, chile

{cgarrido,rmora,cgutierr}@dcc.uchile.cl

abstract. group centrality is an extension of the classical notion of
centrality for individuals, to make it applicable to sets of them. we per-
form a swot (strengths, weaknesses, opportunities and threats) anal-
ysis of the use of group centrality in semantic networks, for di   erent
centrality notions: degree, closeness, betweenness, giving prominence to
id93. among our main results stand out the relevance and np-
hardness of the problem of    nding the most central set in a semantic
network for an speci   c centrality measure.

1

introduction

the notion of centrality in graphs has been thoroughly studied since it was in-
troduced for social networks, being also applied in other contexts ranging from
physics to information retrieval [11], but as freeman writes for social networks
[6],    there is certainly no unanimity on exactly what centrality is or on its con-
ceptual foundations, and there is very little agreement on the proper procedure
for its measurement.    over the years, a great variety of measures of centrality
have been proposed, most of them pointing to the problem of    nding the most
   central    (regarding the notion and/or the measure) node in a network [18].

most of classic work on centrality studies what we could call    individual   
centrality: what is the most central node in a network for a certain measure.
this idea can be extended to a group: given an integer k > 1, what is the
most central set s of nodes, of size k? this is known as group centrality and
was introduced by everett and borgatti [5] for social networks in order to make
individual measures of centrality work with groups of elements.

in this paper we study the application of the idea of group centrality to
semantic networks. to the best of our knowledge, this link has not been explored
before. it can help to shed light on the idea of a    most signi   cative    group of
concepts in a semantic network, which in the age of big (semantic) data, seems
to be indispensable to make sense of notions like summary, table of contents,
compendium, etc. on huge semantic network datasets.

our goal in this paper is to show the robustness of this application, develop its
properties, and present its opportunities, scope and possibilities and limitations.

we perform the study based on some classical centrality measures like de-
gree, closeness and betweenness [6].1 we present in more detail random walk
centrality which is a measure based on the notion of hitting time (informally:
the expected length of a random walk). this idea has been used with success
in modeling semantic relatedness. the intuition is that the    jump    from one
concept to another is better modeled through id93 rather than using
deterministic movements. this approach has been explored in human memory
[2], lexical relations [8] and wikipedia corpus [13].

hooves

frog

antlers

mammal

hair

deer

animal

dog

bat

blood

robin

bird

livingthing

antlers

deer

dog

chicken

hooves

hair

animal

frog

chicken

leaves

tree

mammal

bird

livingthing

blood

feathers

cottonwood

tree

bat

red

robin

red

rose

feathers

   ower

plant

color

daisy

green

cottonwood

leaves

color

plant

green

   ower

rose

daisy

{ livingthing }     { mammal }

k = 1
k = 2
k = 3
k = 4 { plant, red, animal, livingthing }     { mammal, plant, bird, tree }

{ bird, plant, animal }     { mammal, plant, bird }

{ red, livingthing }     {mammal, plant }

fig. 1: networks built by novices (left) and experts (right) over the same set of
25 concepts. in the table, for each k it is shown the most central set of k concepts
of the novice (left) and the expert (right) networks.

let us consider the examples shown in fig. 1. schvaneveldt and social sci-
entists [15] made a study of the process of construction of semantic networks.
they chose 25 natural concepts and devised a method to allow communities to
establish semantic relationships among them. the networks were built using two
di   erent communities: on the left by novices (psychology students) and on the
right by domain experts (biologists). what are the most central concepts here?
first, let us point that the four centrality measures mentioned previously, show
remarkable similarity in their outputs (these measures do not consider labels,
only the structure of the graph). on the novices    network, the four measures

1 degree centrality selects the node with higher degree; closeness indicates the node
that minimizes the distance from all other nodes in the network to it; betweenness
selects the node over which pass the higher number of shortest paths between each
pair of nodes. we will de   ne them formally in section 3.

indicate    livingthing   . as for the biologists    network they indicate    mammal   .2
also, the four of them behaved remarkable similar when searching for central
groups of di   erent sizes, as shown in fig. 1.

what do these examples tell? first of all, they give insights on the possi-
ble relevance and use that group centrality could have for semantic networks.
the contribution of this paper is a study of the assumptions that lie under this
optimistically/naive hypothesis, that is, an analysis of the strengths and oppor-
tunities and weaknesses and obstacles (known as swot analysis) of applying
this idea to semantic networks. (in the related work section we will go over the
work that has been done on ranking semantic networks, that touches some facets
of this problem).

the concrete contributions of this paper are:

1. complexity analysis. we show that for the four previously mentioned cen-
trality measures, the problem of    nding a set with optimal centrality score
is np-hard (and its associated decision problem is np-complete).

2. we present a small-scale study of samples of semantic networks    because
of the hardness of the computations and the di   culties to get a human
evaluation of what is    central    in a huge network, a challenge by itself    to
show tendencies and illustrate the potential and robustness of the idea of
group centrality.

3. we develop the notion of random-walk centrality, and prove several theoret-
ical properties for it. in particular, we show that testing random-walk group
centrality can be done in polynomial time.

the paper is organized as follows. in section 2 we present the main arguments
of the swot analysis and related work on the subject. in section 3 we show
the study of samples of some real semantic networks. in section 4 we include the
proofs and support for the theoretical arguments and in section 5 we present the
conclusions.

2 group centrality in social networks

let us begin by stating formally the notions to be studied.

basic graph notions. an undirected and simple graph is a pair g = (v, e) where
e     [v ]2, and [v ]2 is the set of all 2-elements subsets from v . the elements of
v are the vertices of g, and the ones from e are its edges. when necessary, we
will use the notation v (g) and e(g) for those sets. from now on, an element
{u, v}     e will be denoted simply by uv.
a vertex u is said to be a neighbor of another vertex v, when uv     e. note
that the de   nition of e implies that v is also a neighbor of u. the set of neighbors
of v will be denoted by ng(v). the degree of v, dg(v) is the size of ng(v).

2 in the experiments, the biologists were asked separately to tell the most represen-

tative concept in the list, and they chose    mammal   .

a graph pn =(cid:0){v0, v1, ..., vn},{v0v1, v1v2, ..., vn   1vn}(cid:1) with n     0, where all

vi are distinct is called a path, and the number of edges in it is its length. a cycle
is a special type of path such that v0 = vn. a path pn in g, with n     1 such
that v0 = u and vn = v, is called a u-v path. also g is said to be connected if
for all distinct u, v     v a u-v path exists in g. a connected component of g is
a maximally connected subgraph h.
length of the shortest u-v path in g. for s     v , d(u, s) := minv   s d(u, v).

the distance between u and v (cid:0)denoted by dg(u, v) or just d(u, v)(cid:1) is the

in what follows, all our graphs will considered to be simple, undirected and

connected.

group centrality the centrality measures that we study were designed to work
with single vertices [6] rather than groups of them, thus we use their natural
extension to sets as proposed in [5].
let g = (v, e) be a graph and s     v . we denote by cj(s) for j     {d, c, bc}

the group centrality according to the centrality measure cj.

group degree centrality cd(s) counts the number of vertices not in s that
are connected to some vertex in s. multiple ties to the same vertex are counted
only once. group closeness cc(s) studies the value of the sum of the distances
from s to all vertices not in it. note that for group degree, the higher the value
of cd(s), the more central the set is. whereas for group closeness the reciprocate
holds. formally, they are de   ned as follows:

cd(s) =

|{v     v \ s, n (v)     s (cid:54)=   }|

|v \ s|

,

cc(s) =

v   v \s d(v, s)
|v \ s|

.

group betweenness centrality cbc(s) indicates the proportion of geodesics

connecting pairs of vertices (that are not in s), that pass through s

cbc(s) =

2bc(s)

|v \ s|(|v \ s|     1)

, with bc(s) =

  uv(s)

  uv

,

(cid:80)

(cid:88)

u<v
u,v /   s

where   uv is the total number of shortest paths from u to v and   uv(s) is the
number of those paths that pass through s. as for group degree, the higher the
value of cbc, the better.

2.1 random walk centrality

id93 the next de   nitions come from the work of lov  asz in random
walk theory [10]. let g = (v, e) be a graph such that |v | = n and |e| = m,
where n, m     n. formally, a random walk is a sequence of vertices obtained as
follows: it starts at a vertex v0, and if at the t-th step it is at a vertex vt = u, it
moves to a neighbor v of u with id203 puv = 1/d(u).
let s     v . the hitting time for a set h(u, s) is the expected number of
steps that a random walk starting at vertex u takes to reach some vertex in s
for the    rst time. when s = {v} is a singleton, we will simply write h(u, v).

one of the issues that all three measures of group centrality (presented on
2.1) have in common, is that they only take into consideration shortest paths
between pairs of vertices. a semantic network represents relations between con-
cepts, motivated by an speci   c context. should that context change, new and
more direct connections may arise. in that regard, as much connections as pos-
sible should be taken into consideration, which is precisely what random walk
centrality attempts to do.

de   nition 1 (random walk centrality). the random walk centrality of
s     v is

(cid:80)

h(cid:46)(s) =

v   v \s h(v, s)

|v \ s|

.

essentially random walk centrality is a variation of closeness that takes into
consideration all ways to reach s from a vertex v, rather than only through the
shortest path. as for group closeness, the lower the value of h(cid:46)(s), the more
central the set is.

2.2 the arguments for the swot analysis

let us state them in general terms the arguments of the swot analysis.

obstacles: weaknesses and threats. first of all, the problem is computationally
hard; we prove that for all four measures considered it is np-hard:

theorem 2. the problem of    nding an optimal solution s of size k, is an np-
hard problem for each of the four group centrality measures studied in this paper
(that is, for c     {cd, cc, cbc, h(cid:46)}) .

this theorem points to the di   culties of applying the notion to big data (and
in this paper for experimenting with it) and gives a    rst program of research on
this problem: to develop good approximate algorithms for it.

second, there is a di   culty associated to experimenting with big data due to
the lack of good benchmarks and semantically    marked    data, that is, networks
for which we have a clear agreement on what are their most central concepts at
di   erent granularities (i.e. the size of an optimum candidate). this is a challenge
by itself (the scope of human physical abilities) and that is the reason why we
use small (human-scale) datasets in this paper.

third, the quality of data. it turns out that the output of the centrality and
group centrality methods depends heavily on the    quality    of the network: in
other words, in how well it represents the semantics we are looking for. the ex-
amples we discussed on section 1 are prime cases of excellent semantic networks
(in fact, developed by psychologists based on systematic experimentation). un-
fortunately, the semantic networks that we see in real life (for example rdf
data) are usually not as good. we will show through several sample datasets
that many of our current most popular semantic data representations (e.g. rdf
graphs) have a bias as they are mostly constructed in ad-hoc manners (union

of pieces of information scattered from di   erent sources; without the goal of
completeness, etc).3

strengths and opportunities. first, the notion of group centrality seems to be
worth exploring in the quest for developing summaries, small representations or
give insight about the meaning and contents of big semantic network datasets.
we show samples of di   erent types of networks, including stable rdf datasets
like dbpedia. the results were in all cases encouraging.

second, the notion seems to be robust and become more stable as the size
of the optimum candidate k increases. there are indications from the sample
data we worked out and partial theoretical results (proposition 7), that in the
long term, all measures behave in the same way as k converges to |v |/2 (that
is, there exists a set that is optimum for all four measures). from this we have
a second line of research: to develop concluding analytical and real data studies
that can support this conjecture.

third, the notion of random walk shows in general less variance than other
measures, i.e. gives more    unique    solutions for k > 0. this virtue and the fact
that this measure systematically gives solutions that have elements in common
with those obtained through the use of other measures, are good signals of its
signi   cance. if we link this observation to the fact that its theoretical basis
(the notion of random walk) has been successfully used in semantic networks
(see related work section) there is good ground to make it a candidate for
systematic study at the theoretical and experimental level.

2.3 related work

id93 and semantic networks. the motivation to address random walk
centrality comes from works that have used the notion of id93 and re-
lated it with semantics. the work of abbott et al. [2] compares the functioning
of the human mind when searching for memories with a random walk in a se-
mantic network, as both present a similar behavior. they conclude that these
results can help clarify the possible mechanisms that could account for pager-
ank predicting the prominence of words in semantic memory. yeh et al. [13]
use id93 to determine the semantic relatedness of two elements. in
particular, they use a personalized id95 algorithm with a custom teleport
vector. they conclude that random walk combined with personalized id95
is a feasible and potentially fruitful mean of computing semantic relatedness for
words and texts. hughes et al. [8] introduce a new measure of lexical relatedness
based on the divergence of the stationary distributions computed using random

3 we are well aware of the complexities of determining in a network of concepts which
one is more relevant. this relies on the underlying semantics of the notions involved,
on the domain from which they are taken from, on the goals that the people that
built the network had, and    nally, on the quality of the network itself. probably due
to all of the above, today we do not have standard, nor good benchmark data for
these tasks.

walks over graphs extracted from id138. all these works have been valuable
sources of inspiration for our method.

relevance and quality ranking in the semantic web. as our motivation of
studying group centrality points to its use in the area of relevance in semantic
data, below we discuss some related work made on it. graves et al.[7] propose
a graph-theoretic measure called noc-order for ranking nodes in rdf graphs.
they base their ranking in a variation of closeness centrality, which measures
how costly is to reach all the nodes in the graph from one speci   c vertex. note
that this idea does not use the concept of expected length (via id93).
zhang et al. [14] address the problem of summarizing rdf graphs using an
rdf sentence as the atomic unit. they focus in ranking the rdf sentences to
get a summary of the ontology and base their method in centrality measures
such as degree-, eigenvector-, or betweenness-centrality. cheng et al. [3] address
the problem of ranking features of an entity in a semantic graph. their method
relies on centrality notions enhanced with the information captured by labels.
the topics of these works is related to our work, though we focus in    nding
central elements in the graph as a whole, while they do it in summarizing en-
tities/ontologies; also they do not present a conceptual notion of key elements,
rely only on experimental evaluations and do not address group centrality. ding
et al. [4] address ranking of semantic objects on the web. they concentrate on
documents, terms and rdf graphs as a whole. for terms, they use popularity
measures essentially based on use and population, weighted by some parameters
of the dataset (occurrences, etc.). supekar et al. [12] address the problem of
quality of ontologies. they characterize ontological features to calculate a score
in order to determine the quality of the ontology. they characterize features like
how well the ontology re   ects the domain of interest, correctness of the ontology
with respect to the domain of discourse, how easy the ontology is to understand
or the depth and width of the ontology. these last two papers deal with ranking
of ontologies as such, but do not address the problem of    nding a set of relevant
concepts/nodes in rdf graphs, nor present any conceptual framework to de   ne
them.

3 group centrality on semantic network data

we are interested on knowing what the group centrality approach applied to
semantic networks has to o   er. in order to do this, we apply group degree,
closeness, betweenness, and random walk centrality notions to semantic networks
data and study their behavior. as was stated on section 2, we restrict our analysis
to small networks for two reasons:    nding a set with optimal value for an speci   c
centrality measure is np-hard; and small networks (human scale) allow to get
an insight about which concepts these group centralities select and how those
selections di   er from each other.

3.1 datasets

networks of natural concepts [15]. this is the dataset we presented in the
introduction. there we showed two networks built, respectively, by a group of
undergraduate psychology and by graduate biologist. additionally, we show here
two other networks. a group of students from introductory psychology courses
were asked to rate the degree of relatedness of all pairwise combinations of 25
natural concepts. using this information the authors constructed two networks,
according to two di   erent thresholds of concept relatedness.
perception: semantic network of common sense [16]. this network stores
knowledge about what things look and feel like. it has about 9, 000 manually
annotated relations between 4, 000 mundane concepts, e.g, cat, house, snow, etc.
dbpedia categories [1]. this dataset covers all the wikipedia article cate-
gories and how they are related using the skos vocabulary. the network covers
1, 130, 342 categories with 2, 308, 585 relations between them.
roget   s thesaurus this is a widely used english-language thesaurus that
contains more than 15, 000 words. this network was been used in works studying
semantic similarity and sense disambiguation, among others.

for each of the last 3 networks we extracted samples of 40 nodes using
random-walk sampling according to leskovec and faloutsos [?] until 40 di   erent
nodes were visited and then we extracted the induced subgraph. here we show
two such samples for each dataset.

{11}

closeness

degree
{11}
{4, 11}

{4, 11, 13} , {0, 11,

n
1
{2, 13} , {4, 11}
2
{0, 11, 13} , {4, 11,
3
4 {2, 4, 11, 13} , ... (23) {2, 4, 11, 13} , ... (5)]

{0, 11, 13}
{2, 4, 11, 13}
table 1: solutions for group centrality on proximity semantic network 1.

{4, 11, 13}
{2, 4, 11, 13}

{11}
{4, 11}

{11}
{4, 11}

13} , ... (9)

13} , ... (4)

random-walk

betweenness

degree
{11}
{0, 11}

n
1
2
3
4 {2, 4, 13, 21} , ... (16)

closeness

{11}

{2, 11} , ... (2)
{2, 13, 21}
{2, 4, 13, 21}

{2, 13, 21} , ... (8)

{2, 13, 21}
{2, 4, 13, 21}
table 2: solutions for group centrality on proximity semantic network 2.

{2, 11, 13, 21}

{2, 11, 13}

random-walk

{11}
{2, 11}

betweenness

{11}
{2, 11}

{6}

closeness

betweenness

{6} , {17}

degree
{0, 6}

{0, 6} , {10, 17}

{3, 13, 17} , {3, 10,

n
1
2
3
4 {0, 6, 10, 17} , ... (18) {0, 6, 10, 17} , ... (6)
table 3: solutions for group centrality on proximity semantic network con-
structed by non-biologist students.

{3, 10, 17}
{0, 6, 10, 17}

{0, 13, 17}
{0, 6, 10, 17}

17}, ... (10)

{3, 10, 17}

{17}
{0, 6}

{6}
{0, 6}

random-walk

n
1
2
3 {3, 12, 19}, {3, 12, 21} {3, 12, 21}, {3, 12, 22}

closeness
{12}
{3, 12}

degree
{12}
{3, 12}

4

{3, 12, 19, 23}

{3, 12, 22}, {3, 12, 23}

{3, 12, 22}
{3, 12, 15, 19}, {3, 12, 15, 21} {3, 5, 12, 22}
table 4: solutions for group centrality on proximity semantic network con-
structed by biologist students.

{3, 12, 19}, {3, 12, 21}

{3, 12, 19, 23}

{3, 12, 23}

betweenness

{12}
{3, 12}

random-walk

{12}
{3, 12}

degree
{4} , {20}
{4, 20}

n
1
2
{4, 18, 20}
3
4 {4, 6, 18, 20} , {0, 4, 6, 20} {0, 4, 6, 20} {4, 6, 7, 20} {4, 6, 18, 20}
table 5: solutions for group centrality on dbpedia sample 1.

closeness
{4, 20}
{0, 4, 20}

{20}
{4, 20}
{4, 7, 20}

{4, 6, 20} , {6, 7, 20}

random-walk

{4, 20}

betweenness

{4}

{4}

degree
{13}

n
1
2 {0, 13} , {1, 13} , ... (2)
3
4

{0, 1, 13} , ... (4)
{0, 1, 3, 13} , ... (1)

betweenness random-walk

closeness
{13}
{12, 13}
{1, 13}
{0, 1, 13}
{0, 1, 13}
{0, 1, 3, 13} {0, 1, 3, 13} {0, 1, 3, 13}

{13}
{0, 13}
{0, 1, 13}

{13}

table 6: solutions for group centrality on dbpedia sample 2.

degree
{25}
{14, 25}

n
1
2
3
4 {0, 4, 14, 25} , ... (10)

{4, 14, 25} , ... (5)

closeness

{14}

{5, 14} , {7, 13} , {7, 14} , {8, 13}

{4, 14, 25} , ... (4)
{1, 4, 14, 25} , ... (2)

betweenness

random-walk

{14}

{14, 25}
{4, 14, 25}

{13}
{6, 14}
{0, 6, 14}

{4, 12, 14, 25} {0, 4, 14, 25}

table 7: solutions for group centrality on perception sample 1.

closeness

{29} , ... (1)

degree
{2, 29}

n
1
2
3
4 {2, 8, 29, 39} , ... (2) {2, 26, 29, 39} , ... (1) {2, 8, 10, 29} {2, 26, 29, 39}
table 8: solutions for group centrality on perception sample 2.

{1}
{1, 2}
{1, 2, 8}

{0, 15, 32} , ... (7)

{2, 8, 29} , ... (3)

{29, 39}
{2, 8, 39}

{0, 15} , ... (1)

random-walk

betweenness

{29}

{15}

degree
{10}
{10, 25}

n
1
2
3
4 {10, 17, 25, 39} , ... (87) {10, 17, 25, 39} , ... (87) {10, 17, 25, 35} {10, 17, 25, 39}
table 9: solutions for group centrality on roget   s thesaurus sample 1.

closeness
{10, 25}

{10, 25, 39}

{10, 25, 35}

{10, 25, 39}

{10, 25, 39}

{25, 35}

{10, 25}

random-walk

betweenness

{35}

{35}

{10}

3.2 discussion of results

for each semantic network, and each centrality measure, we computed the op-
timal solutions of size 1, 2, 3, and 4. the results are presented in tables 1 to

degree
{11}
{11, 14}

n
1
2
3
4 {11, 14, 29, 37} , ... (440) {11, 14, 29, 37} , ... (440) {11, 14, 26, 37} {11, 14, 29, 37}
table 10: solutions for group centrality on roget   s thesaurus sample 2.

{11, 14, 29} , ... (6)

{1, 14, 29} , ... (6)

closeness
{14, 26}

{11, 26, 37}

{11, 14, 29}

{14, 26}

{26, 37}

random-walk

betweenness

{37}

{37}

{37}

10. it is important to note that in some cases there were multiple candidates for
optimal solution, but we only include at most two of them4 (if there are more
than two solutions, there is a mark    ... (n)    where n is the number of extra
solutions) .

from the results obtained, we can advance two main observations:

robustness of group centrality. it is noticeable that in the samples the optimal
solutions for all centrality measures become similar as the size k of the set
increases. indeed, for groups of size 1, it can observed that there are networks
for which the solution is di   erent, depending on the centrality notion applied
(e.g. table 13). on the other hand, for groups of size 4, it can be observed that
in most networks there is a common set of nodes selected by all four di   erent
measures used.
non-ambiguity of group random-walk. as stated previously, for a given size k,
more than one optimal solution may exist for group centrality. moreover, from
the results it can be inferred that as k increases, so does the number of optimal
candidates for certain particular measures. for example, table 11 shows that
degree and closeness centrality have 24 (resp. 6) optimal solutions of size 4. there
is even an extreme case in table 23, where degree and closeness have more than
400 di   erent optimal group solutions. in a small sample of 40 nodes this variance
does not help achieve the proposed goal. however, betweenness centrality seems
to behave in general better in this matter (there is some dispersion, e.g. table
14, but it is small). random-walk centrality, on the other hand, is consistently
better in this regard. in our sample selections, it is the only notion for which
there is systematically a unique optimal solution for any size, and for all the
networks.

4 theoretical aspects of group centrality

as we saw in previous sections, group centrality o   ers interesting new insights
on semantic networks. in this section we study the notion from a theoretical
point of view, focusing in the complexity of computing it.

4.1 complexity of group centrality

let us de   ne formally the problem of computing the most central set of nodes
in a network under di   erent centrality measures.

4 the complete results, graphs and labels of the networks can be found in the ap-

pendix.

de   nition 3 (optimumset). given a graph g = (v, e), a positive integer k
and a function c : p(v )     r, de   ne optimumset(g, k, c) as the problem of
   nding a set s     v , of size k such that

s     arg min
u   v ;|u|=k

c(s).

for a real number    > 0, optimumset(g, k, c,   ) will denote the corresponding
decision problem:    nd if there exists a set s     v , of size k such that c(s) =   .

theorem 2. optimumset(g, k, c,   ) is np-complete for all four group central-
ity measures studied in this paper (that is, for c     {cd, cc, cbc, h(cid:46)}).

proof. first note that it is not di   cult to prove that cd, cc and cbc are all com-
putable in polynomial time. same for h(cid:46) but we will leave that demonstration
for later (see proposition 4). thus the corresponding problems are all in np.

now, consider    = 1 and let sd, sc, sbc and sh(cid:46) be solutions of the corre-

sponding decision problems.

note that cc(sc) = 1 (resp. cd(sd) = 1) if and only if sc (resp. sd) is a
dominating set of cardinality k in g. that is, the problem of    nding a dominating
set of cardinality k in g is polynomial time reducible to optimumset(g, k,   , cc)
and optimumset(g, k,   , cd).
indeed, cc(sc) = 1 if and only if d(v, sc) = 1,   v /    sc, which happens if
and only if every vertex v /    sc has at least one neighbor on sc (which is also a
necessary and su   cient condition for cd(sd) = 1). that is, sc (and also sd) is
a dominating set.

on the other hand, cbc(sbc) = 1 (resp. ch(cid:46) (sh(cid:46) ) = 1) if and only if sbc
(resp. sh(cid:46) ) is a vertex cover of g of size k. that is, the problem of    nding a vertex
cover of g of size k is polynomial time reducible to optimumset(g, k,   , ch(cid:46) )
and optimumset(g, k,   , cbc).
indeed, cbc(sbc) = 1 if and only if   uv(sbc) =   uv,   u, v /    sbc with u < v,
which occurs if and only if for every pair    u, v /    sbc with u < v, all shortest
paths that connect u and v have some vertex in sbc. this is equivalent to having
n (v)     sbc for all v     sbc. that is, sbc is a vertex cover of g.
finally, ch(cid:46) (sh(cid:46)) = 1 if and only if h(v, sh(cid:46)) = 1,   v /    sh(cid:46) , but h(v, sh(cid:46)) =
1 occurs if and only if n (v)     s,   v /    sh(cid:46) . that is, sh(cid:46) is a vertex cover of g.(cid:117)(cid:116)

4.2 properties of random walk centrality

the transition probabilities for puv =   (uv)/  (u), with   (u) =(cid:80)

given a graph g = (v, e), we can generalize the notion of random walk to the
case where there is a weight function    : e     r on the edges of g, by changing
w   n (u)   (uw)
(thus the case        1 gives the original de   nition of random walk).
note that the sequence of random vertices (vt : t = 0, 1, ...) is a markov
chain. let pt will denote the distribution of vt: pt(v) = p(vt = v). the vertex
v0 may be    xed, but may also be drawn from an initial distribution p0. this

easily proved that the distribution   (v) :=   (v)/(cid:80)

initial distribution is said to be stationary if p1 = p0 (which will imply that
pt = p0    t     0, because of the construction of the random walk). it can be
v   v   (w) is stationary for
every graph g and weight function   . from now on    will be referred simply as
the stationary distribution (it is not di   cult to prove that this distribution is
unique, which makes this reference valid).
proposition 4. given g = (v, e), a weight function    : e     r, a subset
s     v and v     v , then h(v, s) and h(cid:46)(s) can be computed in polynomial time.

for the proof,    rst we need the following result

lemma 5. for a graph g = (v, e), a weight function    and s     v de   ne gs
as the following weighted graph:

v (gs) = (v \ s)     {vs}
e(gs) = {e     e/e     s =   }     {e = uvs/u     v, ng(u)     s (cid:54)=   }

and   s : e(gs)        n de   ned as:   s(uv) =   (uv) if uv     s =    . otherwise,

i.e. if v = vs, then   s(uv) = (cid:80)

  (uw).

then for u     v \ s we have that hg(u, s) = hgs (u, vs).

w   ng(u)   s

proof. for a vertex w     v \ s, let tw,s and tw,vs be two random variables
that count the number of steps that a random walk (on g and gs respectively)
starting at vertex w takes in order to reach some vertex of s and vs (respectively)
for the    rst time. we will prove that tu,s and tu,vs have the same distribution.

let us proceed by induction on the possible values of tu,s and tu,vs .
if n = 1 then

(cid:80)

p(tu,s = 1) =

w   ng(u)   s
  (u)

=

  s(uvs)
  s(u)

= p(tu,vs = 1).

  (uw)

let n > 1 and assume that the property holds for n     1. then

  (uw)
  (u)

  (uw)
  (u)

p(tw,s = n     1)

p(tw,vs = n     1)

p(tu,s = n) =

=

=

=

w   v \s

(cid:88)
(cid:88)
(cid:88)
(cid:88)

w   v \s

w   v (gs )\vs

w   v (gs )\vs

  (uw)
  (u)

(tw,vs = n     1)

  s(uw)
  s(u)

p(tw,vs = n     1) = p(tu,vs = n).

using this we have that hg(u, s) = e(tu,s) = e(tu,vs ) = hgs (u, vs).

(cid:117)(cid:116)

proof (of proposition 5). let p be the id203 transition matrix associated
to a random walk on g, and the function   . that is, pij =   (ij)
  (i) . de   ne p    as

          .
           (1)   (2) . . .   (n)

...
...
  (1)   (2) . . .   (n)

. . .

...

p    =

where    is the stationary distribution. de   ne also z := (i     (p     p   ))   1 and
let h be the hitting time matrix of g, that is, hij = hg(i, j). then it can be
proved as stated in [17] that for i, j     v

hg(i, j) =

zjj     zij

  (j)

.

(1)

therefore, by combining equation (1) and lemma 5 we can compute h(v, s)
(cid:117)(cid:116)

by inverting a suitable matrix z, which can be made in polynomial time.

lemma 6. there is a parameterized family of graphs for which random walk
centrality behaves systematically di   erently than degree, closeness and between-
ness group centrality.
proof. consider {gm
n }, with n, m     z+ and n << m a family of graphs con-
structed as follows (see fig. 2): for i     {1, ..., m     1}, k i
n is a subgraph of gm
n
that is a n-clique and that is connected to v through an unique vertex ki
n. on
n of height 1 and size n with root tn
the other hand, t i
i the
only vertex in t i
n . suppose we want to    nd a set
n , m + 1, c) for c     {cd, cc, cbc, h(cid:46)}. it is not
s that solves optimumset(gm
di   cult to prove that for group closeness and betweenness centrality the sets
n } are solutions. for group degree
sk = {v, k1
n, ..., km
n } for any 1     j     m
centrality   sk = {tj
are possible solutions. however, one could argue the di   erence in connectivity
between sets sk and st should be accounted for. indeed, for random walk cen-
(cid:117)(cid:116)
trality, sk (a more connected version of st) is the only solution.

n } and st = {v, t1
n, k1

n that is neighbor of v in gm

n } and   st = {kj

n is a subtree of gm

n, ..., km

n, ..., tm

n, ..., tm

n, t1

the following bound shows an interesting relation between random walk

centrality, degree and closeness
proposition 7. there exists a real constant c > 0 such that for s     v

       (cid:88)

u   v \s

             (cid:88)

v   v \s

           c|v \ s|3.

d(u, s)

d(v)

h(cid:46)(s)    

1

|v \ s|

proof. de   ne    (s) := {v     s :    u     v \ s, uv     e}. de   ne the subgraph gs
of g as follows: v (gs) := (v \ s)        (s) and e(gs) := {uv     e : u, v    
v (gs)     u     v \ s}.

first note that for any pair of vertices u     v \ s and v        (s)

hg(u, s) = hgs (u,    (s))     hgs (u, v).

k 1
n

k 2
n

. . .

km   1

n

km
n

v

. . .

t 1
n

t 2
n

t m   1

n

t m
n

fig. 2: which set of size m + 1 is more central? sk or st ?

the equality follows from the fact that the subgraph traversed and the target
hit in both expressions are the same, and the inequality holds because the target
of the expression on the right is more di   cult to hit, thus needs more walking
around.

using this, we have that

(cid:80)

(cid:80)

h(cid:46)(s) =

u   v \s hg(u, s)

|v \ s|

   

u   v \s hgs (u, vu)

|v \ s|

,

with each vu        (s) chosen such that dgs (u, vu) = dg(u, s).
pair of vertices u, v     v (l), hl(u, v)     2|e(l)|dl(u, v), we have that

on the other hand, by using the known fact that for any graph l and any

(cid:80)

u   v \s hgs (u, v)

|v \ s|

(cid:80)
u   v \s 2|e(gs)|dgs (u, vu)

   

   

1

|v \ s|

|v \ s|

       (cid:88)

u   v \s

dg(u, s)

             (cid:88)

       . (cid:117)(cid:116)

dg(v)

v   v \s

5 conclusions

we perform a swot analysis of the application of the notion of group centrality
to semantic networks, putting a particular focus on random walk group central-
ity. the challenges faced were mainly of two types. first, the ambiguity of the
very notion of the    most central    concept in a semantic network; and second,
the size of the networks.

in spite of these obstacles (that we discussed in the paper), we hope we
presented enough evidence that this topic deserves to be explored and researched.
we approached these obstacles by working with small samples and advancing
theoretical results. besides stating the problem at the formal level, we proved
that the problem of computing group centrality is np-hard, and showed that

random walk centrality comes up as a good candidate for capturing the notion
of centrality on semantic networks.

the above opens at least two lines of research on this topic: first, to    nd good
approximation algorithms to compute group centrality particularly for random
walk centrality. second, the task of building a good benchmark of big seman-
tic networks together with their candidate sets to match the most important
concepts in the network.

references

1. dbpedia. http://www.dbpedia.org.
2. j. abbott, j. austerweil, t. gri   ths. human memory search as a random walk

in a semantic network. adv. neur. inf. proc. syst. 25, 3050-58, 2012.

3. g. cheng, th. tran, y. qu. relin: relatedness and informativeness-based cen-

trality for entity summarization. iswc 2011, springer 2011.

4. l. ding, r. pan, t. finin, a. joshi, y. peng, p. kolari. finding and ranking

knowledge on the semantic web. in iswc 2005, 156   170. springer, 2005.

5. m. g. everett, s. p. borgatti. the centrality of groups and classes. journal of

mathematical sociology. 23(3): 181-201.

6. l. c. freeman. centrality in social networks. conceptual clari   cation. social

networks, 1 (1978/79) 215-239.

7. a. graves, s. adali. a method to rank nodes in an rdf graph. 7th. iswc, 2008.
8. t. hughes, d. ramage. lexical semantic relatedness with random graph walks.
2007 j. conf. on emp. meth. in nlp and comp. nat. lang. learning, 581-589.
9. jure leskovec and christos faloutsos. sampling from large graphs. proc. 12th

acm kdd    06, pages 631   636.

10. l. lov  asz id93 on graphs; a survey. bolyai soc., math. studies 2,

1993, pp. 1-46.

11. mark ej newman. the structure and function of complex networks. siam review,

45(2):167   256, 2003.

12. k. supekar, ch. patel, y. lee. characterizing quality of knowledge on semantic

web. aaai florida ai research symp. (flairs-2004), 17   19, 2004.

13. e. yeh, d. ramage, ch. d. manning, e. agirre, a. soroa. wikiwalk: id93
on wikipedia for semantic relatedness. 2009 workshop on graph-based meth. for
nlp, 41   49, stroudsburg, pa, usa, 2009.

14. x. zhang, g. cheng, y. qu. ontology summarization based on rdf sentence graph.

16th intl. conf. on world wide web, 707   716. acm, 2007.

15. r. schvaneveldt, f. durso, and d. dearholt. network structures in proximity data.

the psychology of learning and motivation, 1989, pages 249   284.

16. t. de smedt, f. de bleser, v. van asch, l. nijs, w. daelemans. gravital: natural
language processing for computer graphics. creativity and the agile mind: a multi-
disciplinary study of a multi-faceted phenomenon, 2013, pages 81

17. howard levinson an eigenvalue representation for random walk hitting times

and its application to the rook graph.

18. s. wasserman, k. faust. social netowrk analysis: methods and applications

(structural analysis in the social sciences). cambridge univ. press, 1994.

a appendix

fig. 3: proximity semantic network 1.

proximity semantic network 1 labels:

    0.- animal
    1.- antlers
    2.- bat
    3.- bird
    4.- blood
    5.- chicken
    6.- color
    7.- cottonwood
    8.- daisy
    9.- deer
    10.- dog
    11.- feathers
    12.-    ower

    13.- frog
    14.- green
    15.- hair
    16.- hooves
    17.- leaves
    18.- livingthing
    19.- mammal
    20.- plant
    21.- red
    22.- robin
    23.- rose
    24.- tree

closeness

degree
{11}
{4, 11}

n
1
{2, 13} , {4, 11}
2
{0, 11, 13} , {4, 11,
3
4 {2, 4, 11, 13} , ... (23) {2, 4, 11, 13} , ... (5)]

{4, 11, 13} , {0, 11,

13} , ... (9)

13} , ... (4)

{11}

betweenness

{11}
{4, 11}

{4, 11, 13}
{2, 4, 11, 13}

random-walk

{11}
{4, 11}

{0, 11, 13}
{2, 4, 11, 13}

table 11: solutions for group centrality on proximity semantic network 1.

fig. 4: proximity semantic network 2.

proximity semantic network 2 labels:

    0.- animal
    1.- antlers
    2.- bat
    3.- bird
    4.- blood

    5.- chicken
    6.- color
    7.- cottonwood
    8.- daisy
    9.- deer

    10.- dog
    11.- feathers
    12.-    ower
    13.- frog
    14.- green
    15.- hair
    16.- hooves
    17.- leaves

    18.- livingthing
    19.- mammal
    20.- plant
    21.- red
    22.- robin
    23.- rose
    24.- tree

closeness

degree
{11}
{0, 11}

n
1
2
3
4 {2, 4, 13, 21} , ... (16)
table 12: solutions for group centrality on proximity semantic network 2.

{2, 11} , ... (2)
{2, 13, 21}
{2, 4, 13, 21}

{2, 13, 21}
{2, 4, 13, 21}

{2, 13, 21} , ... (8)

{2, 11, 13, 21}

{11}
{2, 11}

{11}
{2, 11}

{2, 11, 13}

random-walk

betweenness

{11}

fig. 5: proximity network built by non-specialists.

proximity network built by non-specialists labels:

    0.- animal
    1.- antlers
    2.- bat
    3.- bird
    4.- blood
    5.- chicken
    6.- color
    7.- cottonwood
    8.- daisy
    9.- deer
    10.- dog
    11.- feathers
    12.-    ower

    13.- frog
    14.- green
    15.- hair
    16.- hooves
    17.- leaves
    18.- livingthing
    19.- mammal
    20.- plant
    21.- red
    22.- robin
    23.- rose
    24.- tree

{6}

closeness

betweenness

{6} , {17}

degree
{0, 6}

{0, 6} , {10, 17}

{3, 13, 17} , {3, 10,

n
1
2
3
4 {0, 6, 10, 17} , ... (18) {0, 6, 10, 17} , ... (6)
table 13: solutions for group centrality on proximity semantic network con-
structed by non-biologist students.

{3, 10, 17}
{0, 6, 10, 17}

{0, 13, 17}
{0, 6, 10, 17}

17}, ... (10)

{3, 10, 17}

{17}
{0, 6}

{6}
{0, 6}

random-walk

fig. 6: proximity network built by biologists.

proximity network built by biologists labels:

    0.- animal
    1.- antlers
    2.- bat
    3.- bird
    4.- blood
    5.- chicken
    6.- color
    7.- cottonwood
    8.- daisy
    9.- deer
    10.- dog
    11.- feathers
    12.-    ower

    13.- frog
    14.- green
    15.- hair
    16.- hooves
    17.- leaves
    18.- livingthing
    19.- mammal
    20.- plant
    21.- red
    22.- robin
    23.- rose
    24.- tree

n
1
2
3 {3, 12, 19}, {3, 12, 21} {3, 12, 21}, {3, 12, 22}

closeness
{12}
{3, 12}

degree
{12}
{3, 12}

4

{3, 12, 19, 23}

{3, 12, 22}, {3, 12, 23}

{3, 12, 22}
{3, 12, 15, 19}, {3, 12, 15, 21} {3, 5, 12, 22}
table 14: solutions for group centrality on proximity semantic network con-
structed by biologist students.

{3, 12, 19}, {3, 12, 21}

{3, 12, 19, 23}

{3, 12, 23}

betweenness

{12}
{3, 12}

random-walk

{12}
{3, 12}

fig. 7: sample 1 from perception network.

sample 1 from perception network labels:

    0.- akzidenz-grotesk
    1.- christmas
    2.- december
    3.- frutiger
    4.- helvetica
    5.- orient express
    6.- trade gothic
    7.- amusement park
    8.- carousel
    9.- chameleon
    10.- colorful
    11.- consciousness
    12.- deep
    13.- diverse
    14.- exotic
    15.- grotesque
    16.- heat
    17.- hot
    18.- interesting
    19.- locomotive

    20.- loud
    21.- merry-go-round
    22.- mill
    23.- miracle
    24.- mirror
    25.- mysterious
    26.- narrow
    27.- repetitive
    28.- roller coaster
    29.- sans
    30.- sans serif
    31.- season
    32.- sensational
    33.- steam
    34.- summer
    35.- telescope
    36.- turkey
    37.- uniform
    38.- waltz
    39.- winter

degree
{25}
{14, 25}

n
1
2
3
4 {0, 4, 14, 25} , ... (10)

{4, 14, 25} , ... (5)

closeness

{14}

{5, 14} , {7, 13} , {7, 14} , {8, 13}

{4, 14, 25} , ... (4)
{1, 4, 14, 25} , ... (2)

betweenness

random-walk

{14}

{14, 25}
{4, 14, 25}

{13}
{6, 14}
{0, 6, 14}

{4, 12, 14, 25} {0, 4, 14, 25}

table 15: solutions for group centrality on perception sample 1.

fig. 8: sample 2 from perception network.

sample 2 from perception network labels:

    0.- new age
    1.- anger
    2.- astrology
    3.- baby
    4.- bad
    5.- calm
    6.- cathedral
    7.- child
    8.- cirrus
    9.- cold
    10.- comedy
    11.- competition
    12.- dangerous
    13.- dark
    14.- deep
    15.- evolution

    16.- food
    17.- fuzzy
    18.- gene
    19.- joke
    20.- kid
    21.- laugh
    22.- light
    23.- loiter
    24.- negative
    25.- old
    26.- ominous
    27.- park
    28.- pillar
    29.- playground
    30.- reproduction
    31.- safe

    32.- shop
    33.- silent
    34.- sleep
    35.- sly

    36.- supermarket
    37.- territory
    38.- valley
    39.- wicked

closeness

{29} , ... (1)

degree
{2, 29}

n
1
2
3
4 {2, 8, 29, 39} , ... (2) {2, 26, 29, 39} , ... (1) {2, 8, 10, 29} {2, 26, 29, 39}
table 16: solutions for group centrality on perception sample 2.

{1}
{1, 2}
{1, 2, 8}

{0, 15, 32} , ... (7)

{2, 8, 29} , ... (3)

{29, 39}
{2, 8, 39}

{0, 15} , ... (1)

random-walk

betweenness

{29}

{15}

sample 3 from perception network labels:

    0.- duomo di milano
    1.- middle ages
    2.- milan cathedral
    3.- arch
    4.- black
    5.- boot
    6.- calm
    7.- cathedral
    8.- dark
    9.- grassland

    10.- horse
    11.- landscape
    12.- marble
    13.- mosque
    14.- pillar
    15.- prairie
    16.- smooth
    17.- soldier
    18.- stallion
    19.- veldt

fig. 9: sample 3 from perception network.

degree
{11}
{4, 11}

n
1
2
3 {0, 11, 13} , {4, 11, 13} , ... (9) {0, 11, 13} , {4, 11, 13} , ... (4) {4, 11, 13}
4

{2, 4, 11, 13} , ... (23)
table 17: solutions for group centrality on perception sample 3.

{2, 4, 11, 13} , ... (5)

{2, 13} , {4, 11}

{11}
{4, 11}

{0, 11, 13}
{2, 4, 11, 13} {2, 4, 11, 13}

{11}
{4, 11}

random-walk

betweenness

closeness

{11}

fig. 10: sample 1 from dbpedia categories network.

sample 1 from dbpedia categories network labels:

    0.- 1996    lms
    1.- 1990s    lms
    2.- 2000s in animation
    3.- decades in animation
    4.- 1990s in animation
    5.- 1910s in animation
    6.- 1990s animated    lms
    7.- years in animation
    8.- 1964 anime
    9.- 1965 anime
    10.- 1969 anime
    11.- 1990 anime
    12.- 1990 in animation
    13.- 1993 anime
    14.- 1993 in animation
    15.- 1994 anime
    16.- 1994 in animation
    17.- 1996 anime
    18.- 1996 in animation
    19.- 1998 in animation

    20.- anime    lms by year
    21.- 1990 anime    lms
    22.- 1990s anime    lms
    23.- 1996 anime    lms
    24.- 1981 anime    lms
    25.- 1960s anime    lms
    26.- 1998 animated    lms
    27.- 1996 animated    lms
    28.- 1994 animated    lms
    29.- 1993 animated    lms
    30.- 1990 animated    lms
    31.- 1965 anime    lms
    32.- 1969 anime    lms
    33.- 1945 anime    lms
    34.- 1945 anime
    35.- 1990s american animated    lms
    36.- 1990s animated short    lms
    37.- tamil    lms of 1996
    38.- 1964 anime    lms
    39.- 1990s computer-animated    lms

degree
{4} , {20}
{4, 20}

n
1
2
{4, 18, 20}
3
4 {4, 6, 18, 20} , {0, 4, 6, 20} {0, 4, 6, 20} {4, 6, 7, 20} {4, 6, 18, 20}

closeness
{4, 20}
{0, 4, 20}

{20}
{4, 20}
{4, 7, 20}

{4, 6, 20} , {6, 7, 20}

random-walk

{4, 20}

betweenness

{4}

{4}

table 18: solutions for group centrality on dbpedia sample 1.

fig. 11: sample 2 from dbpedia categories network.

sample 2 from dbpedia categories network labels:

    0.- wikipedia categories named after populated places in italy
    1.- provinces of italy
    2.- cities and towns in emilia-romagna
    3.- emilia-romagna
    4.- parma
    5.- turin
    6.- cities and towns in piedmont
    7.- communes of the province of parma
    8.- education in italy by city
    9.- communes of the province of alessandria
    10.- geography of emilia-romagna
    11.- province of pavia geography stubs
    12.- province of pavia
    13.- bologna
    14.- communes of the province of bologna
    15.- buildings and structures in bologna
    16.- province of arezzo
    17.- province of ancona
    18.- province of lucca
    19.- visitor attractions in bologna
    20.- tortona
    21.- novi ligure
    22.- pavia
    23.- communes of the province of lucca
    24.- roman catholic archbishops of bologna
    25.- history of bologna
    26.- education in turin
    27.- palaces in bologna
    28.- education in bologna
    29.- university of pavia
    30.- education in emilia-romagna
    31.- culture in bologna
    32.- culture in emilia-romagna
    33.- buildings and structures in pavia
    34.- buildings and structures in the province of pavia
    35.- companies by region of italy
    36.- companies based in bologna
    37.- companies based in emilia-romagna
    38.- education in italy by region
    39.- media in bologna

degree
{13}

n
1
2 {0, 13} , {1, 13} , ... (2)
3
4

{0, 1, 13} , ... (4)
{0, 1, 3, 13} , ... (1)

betweenness random-walk

closeness
{13}
{12, 13}
{1, 13}
{0, 1, 13}
{0, 1, 13}
{0, 1, 3, 13} {0, 1, 3, 13} {0, 1, 3, 13}

{13}
{0, 13}
{0, 1, 13}

{13}

table 19: solutions for group centrality on dbpedia sample 2.

fig. 12: sample 3 from dbpedia categories network.

sample 3 from dbpedia categories network labels:

    0.- neognathae
    1.- birds by classi   cation
    2.- procellariiformes
    3.- phoenicopteriformes
    4.- pelecaniformes
    5.- hornbills
    6.- bucerotidae
    7.- ardeidae
    8.- egretta
    9.- aceros
    10.- anthracoceros

    11.- buceros
    12.- ceratogymna
    13.- ocyceros
    14.- penelopides
    15.- bucerotinae
    16.- tockus
    17.- phalacrocoracidae
    18.- fregatidae
    19.- falconiformes
    20.- accipitridae
    21.- oceanodroma

    22.- hydrobatinae
    23.- hydrobatidae
    24.- phalacrocorax
    25.- plotopteridae
    26.- bucerotiformes
    27.- limnofregata
    28.- fregata
    29.- oceanitinae
    30.- aviceda

    31.- dryotriorchis
    32.- erythrotriorchis
    33.- anorrhinus
    34.- fregetta
    35.- oceanites
    36.- botaurus
    37.- anhingidae
    38.- rhyticeros
    39.- pelecanus

degree
{5}
{4, 5}

n
1
2
3
4 {4, 5, 20, 23} {4, 5, 20, 23} {4, 5, 20, 23} {4, 5, 20, 23}

closeness
{1}
{1, 5}

{1}
{4, 5}

{1}
{1, 5}

{4, 5, 23}

{4, 5, 23}

{4, 5, 23}

{4, 5, 23}

random-walk

betweenness

table 20: solutions for group centrality on dbpedia sample 3.

fig. 13: sample 1 from roget   s thesaurus network.

sample 1 from roget   s thesaurus network labels:

    0.- jack
    1.- ardor
    2.- chips
    3.- cob
    4.- cordiality
    5.- dress down
    6.- empressement
    7.- fervency
    8.- fervidness
    9.- fervor
    10.-    re
    11.- foment
    12.- give a whipping
    13.- go
    14.- gusto
    15.- heartiness
    16.- hearty
    17.- heat
    18.- jacktar
    19.- kale

    20.- lather
    21.- mariner
    22.- navigator
    23.- passionateness
    24.- sailorman
    25.- salt
    26.- sea dog
    27.- seafarer
    28.- seafaring man
    29.- spondulix
    30.- sugar
    31.- trim
    32.- unction
    33.- vehemence
    34.- verve
    35.- warm
    36.- warm the blood
    37.- warmth
    38.- warmth of feeling
    39.- whale

degree
{10}
{10, 25}

n
1
2
3
4 {10, 17, 25, 39} , ... (87) {10, 17, 25, 39} , ... (87) {10, 17, 25, 35} {10, 17, 25, 39}
table 21: solutions for group centrality on roget   s thesaurus sample 1.

closeness
{10, 25}

{10, 25, 39}

{10, 25, 35}

{10, 25, 39}

{10, 25, 39}

{25, 35}

{10, 25}

random-walk

betweenness

{35}

{35}

{10}

fig. 14: sample 2 from roget   s thesaurus network.

sample 2 from roget   s thesaurus network labels:

    0.- alliterate
    1.- assonate
    2.- bedpan
    3.- blench
    4.- blink
    5.- chevy
    6.- chuck
    7.- chunk
    8.- cracked
    9.- cut
    10.- dash
    11.- dodge
    12.- duck
    13.-    ght shy of
    14.-    ing
    15.- hoar
    16.- lay
    17.- pelt
    18.- poesy
    19.- poetry

    20.- pound
    21.- pull back
    22.- pun
    23.- recoil
    24.- reft
    25.- rhyme
    26.- rime
    27.- scour
    28.- shrink
    29.- shy
    30.- shy at
    31.- side step
    32.- slit
    33.- song
    34.- stab
    35.- submarine
    36.- swerve
    37.- verse
    38.- whack
    39.- whop

degree
{29}
{26, 29}

n
1
2
3
4 {10, 12, 26, 32} , ... (4) {10, 12, 24, 26} , ... (4) {10, 12, 26, 29} {10, 12, 26, 29}

closeness
{26, 29}

{10, 12, 26}

{10, 12, 26}

{10, 12, 26}

{9, 26, 29}

{26, 29}

random-walk

{9, 29}

betweenness

{29}

{9}

{9}

table 22: solutions for group centrality on roget   s thesaurus sample 2.

fig. 15: sample 3 from roget   s thesaurus network.

sample 3 from roget   s thesaurus network labels:

    0.- ass
    1.- bring about
    2.- bring to e   ect
    3.- bring to pass
    4.- burro
    5.- chucklehead
    6.- create
    7.- cuddy
    8.- dickey
    9.- do
    10.- doit
    11.- donkey
    12.- dub
    13.- du   er
    14.- e   ect
    15.- gawk
    16.- gawkhammer
    17.- gawky
    18.- generate
    19.- get

    20.- lobster
    21.- longear
    22.- looby
    23.- loon
    24.- lubber
    25.- lummox
    26.- lump
    27.- lunkhead
    28.- majority
    29.- mass
    30.- moke
    31.- most
    32.- plurality
    33.- preponderance
    34.- preponderancy
    35.- put up a tree
    36.- slouch
    37.- stick
    38.- swab
    39.- the greater number

degree
{11}
{11, 14}

n
1
2
3
4 {11, 14, 29, 37} , ... (440) {11, 14, 29, 37} , ... (440) {11, 14, 26, 37} {11, 14, 29, 37}
table 23: solutions for group centrality on roget   s thesaurus sample 3.

{11, 14, 29} , ... (6)

{1, 14, 29} , ... (6)

closeness
{14, 26}

{11, 26, 37}

{11, 14, 29}

{14, 26}

{26, 37}

random-walk

betweenness

{37}

{37}

{37}

