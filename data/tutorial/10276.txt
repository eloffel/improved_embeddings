7
1
0
2

 

b
e
f
5
2

 

 
 
]
l
c
.
s
c
[
 
 

2
v
6
3
6
9
0

.

6
0
6
1
:
v
i
x
r
a

representation of texts as complex networks: a mesoscopic approach

henrique ferraz de arruda,1 filipi nascimento silva,2 vanessa queiroz
marinho,1 diego raphael amancio   ,1 and luciano da fontoura costa2

1institute of mathematics and computer science,
university of s  o paulo, s  o carlos, sp, brazil.

2s  o carlos institute of physics, university of s  o paulo, s  o carlos, sp, brazil

statistical techniques that analyze texts, referred to as text analytics, have departed from the
use of simple word count statistics towards a new paradigm. id111 now hinges on a more
sophisticated set of methods, including the representations in terms of complex networks. while
well-established word-adjacency (co-occurrence) methods successfully grasp syntactical features of
written texts, they are unable to represent important aspects of textual data, such as its topical
structure, i.e. the sequence of subjects developing at a mesoscopic level along the text. such aspects
are often overlooked by current methodologies. in order to grasp the mesoscopic characteristics of
semantical content in written texts, we devised a network model which is able to analyze documents
in a multi-scale fashion.
in the proposed model, a limited amount of adjacent paragraphs are
represented as nodes, which are connected whenever they share a minimum semantical content.
to illustrate the capabilities of our model, we present, as a case example, a qualitative analysis of
   alice   s adventures in wonderland   . we show that the mesoscopic structure of a document, modeled
as a network, reveals many semantic traits of texts. such an approach paves the way to a myriad of
semantic-based applications. in addition, our approach is illustrated in a machine learning context,
in which texts are classi   ed among real texts and randomized instances.

i.

introduction

the availability of an ever growing amount of data
brought up by the age of information has strongly im-
pacted science, giving rise to a novel perspective on
data analysis. the use and development of system-
atic approaches to analyze data has already become
mandatory in a wide range of knowledge areas, such as
physics [15], biology [13, 22], medicine [12] and even hu-
manities [39, 49]. this also includes techniques devoted
to the systematic analysis of texts, known as text min-
ing [45]. traditionally, approaches involving text an-
alytics were solely based on simple statistics consider-
ing mostly the frequency of words [2, 50], which are, in
general, suitable for the task of text classi   cation [36].
however, more sophisticated methods have been devised
for complex tasks, such as to quantify the words rele-
vance [34, 54] in a document. these techniques can be
employed to detect, for instance, important topics in a
given text [1, 14]. even more challenging are the meth-
ods used to study the relationships among words or top-
ics in a document or a set of documents. this kind of
analysis can be undertaken by considering semantic sim-
ilarities [41] or linguistic characteristics [33]. by using
these new techniques, many other applications could be
achieved, e.g., id54 [17], event sum-
mary from many doccuments [63], id31 [44]
or authorship detection [18]. applications that illustrate
the temporal dynamics [43, 53, 60] are also important.
in these works, texts or movies are analyzed according
to the way entities (mainly characters) interact through
time. recently, [55] investigated how the emotional con-
tent evolves in a story. moreover, text datasets can also
be analyzed in terms of the relationships among their
elements, such as words and paragraphs. so, texts can

be regarded as a complex structure and, therefore, be
suitably represented in terms of complex networks.

a well-known approach to construct complex networks
from texts is the word-adjacency (or co-occurrence) tech-
nique [9, 40], which is based on connecting pairs of words
that are immediately adjacent. the strategy of mapping
texts according to co-occurrence relationships is a sim-
pli   cation of networks formed by syntactical links [28].
despite this seeming limitation, word adjacency net-
works have been employed successfully to address a
great variety of natural language processing problems.
this includes id31 [27], authorship detec-
tion [4, 47, 56], stylometry [5], text classi   cation [24],
id51 [10, 48, 58], text summariza-
tion [8, 11], machine translation [8, 64] and others.

perhaps the most critical disadvantage associated with
the word adjacency approach is its inability to portray
the topical structure presented in many texts. the
topical structure of a text is expected to naturally
emerge from its network representation through a pro-
nounced heterogeneous macro-structure. however, this
hardly happens on typical co-occurrence networks, which
present no community structure [23]. this suggests that
the co-occurrence representation does not e   ectively cap-
ture the information at the mesoscopic structure of the
text, such as topics and subtopics. in addition, the in-
formation regarding the temporal evolution along a text
is also overlooked in co-occurrence networks.

in order to address the above limitations, we propose
a mesoscopic representation of texts, where a node rep-
resents a large context, e.g. a set of adjacent sentences
or paragraphs. more speci   cally, in our approach each
node corresponds to     subsequent paragraphs. the re-
lationship between these nodes is then established by a
similarity criteria. as such, edges are created whenever

from texts to networks

idf(w, d) = log

,

(2)

a large number of words is shared between two nodes.
note that, by doing so, the network structure becomes
more dependent on how the author approaches the topics
along the text. as we shall show, the proposed represen-
tation is able to re   ect the semantic complexity of texts,
a feature that cannot be straightforwardly obtained in
traditional word adjacency networks.

this manuscript is organized as follows: section ii de-
scribes our approach to create the mesoscopic network
from a given document. section iii describes a case study
of our approach. section iv illustrates the mesoscopic ap-
proach in a machine learning context. finally, section v
concludes our paper and suggests perspectives for further
studies.

ii. methods

this section describes the procedure to obtain meso-
scopic complex networks from texts, which include books
and other documents with paragraph structure. here, we
also brie   y present the technique employed to visualize
these networks.

in recent years, a new set of techniques has been intro-
duced to create networks from documents, which takes
into account their mesoscopic structure [23].
in that
work, the networks are generated by connecting words
existing in the same context, which is de   ned in terms
of a    xed window length. this approach was able to
produce modular networks, with each community related
to contextual topics or subtopics of the text [23]. even
though the semantical organization of texts is captured
by this representation, it is not straightforward to obtain
the temporal evolution of the story being told.

here, we extend the concepts introduced by [23] to de-
rive a new technique to construct networks from texts.
our methodology addresses two important aspects typi-
cally overlooked by more traditional approaches: (a) the
mesoscopic structure of a text and (b) its unfolding along
timeunfolding along tim. to consider (a), instead of link-
ing adjacent words, we use larger pieces of text as the
basic representational unit. these pieces are connected
according to the similarity among themselves. the tem-
poral evolution of ideas and concepts is incorporated into
our model because, by construction, successive nodes al-
ways result connected as a consequence of their shared
content.

henceforth, we consider an organized text as a sequence
of words delimitated by paragraphs. in our analysis, the
paragraphs can be retained from the text, or can be in-
ferred from the text own structure, for instance, by con-
sidering sequences with a    xed number of words.

our approach starts with a pre-processing step typi-
cally employed for semantical-based text analysis. first,

2

punctuation marks and numbers are removed. we also
discard words conveying little contextual meaning, i.e.
the stopwords. examples of stopwords are articles and
prepositions. if a lemmatization technique [45] is avail-
able for the language being considered, it is used to nor-
malize concepts. in this step, words are reduced to their
canonical forms, so that in   ections in verbal tense, num-
ber, case or gender are disregarded. for example, the
sentence       oh, i   ve had such a curious dream!    said al-
ice    becomes    curious dream say alice   , after being pre-
processed. next, we employ the tf-idf (term frequency-
inverse document frequency) technique [45], which de-
   nes a map tf-idf(w, d, d) quantifying the importance of
each word w in a given document d from a set of docu-
ments d. the tf-idf(w, d, d) map is computed as

tf-idf(w, d, d) = tf(w, d)    idf(w, d),

(1)

where tf(w, d), the term-frequency component, accounts
for the relevance of w     d and idf(w, d), the inverse
document frequency, quanti   es the frequency of w in all
d     d. many variations of both tf and idf terms have
been proposed [45]. in this paper, we consider tf(w, d)
as the raw frequency of a given word w in a document d.
the idf(w, d) is calculated as

(cid:32)|d|

(cid:33)

fw

where |d| is the total number of documents in d and fw
is the number of documents in which w occurs at least
once.

the mesoscopic network is generated from the prepro-
cessed text, hereafter referred to as organized text o.
the organized text o consists of a sequence of para-
graphs o = (p0, p1, p2 . . . ) with each paragraph pi com-
prising a sequence of words pi = (wi0, wi1, wi2 . . . ). dif-
ferently from the co-occurrence model where nodes repre-
sent words, here, we map entire paragraphs or sequences
of consecutive paragraphs as nodes. in particular, for a
choice of window size    , each possible subsequence com-
prising     paragraphs in o, p    
k = (pk, pk+1, . . . pk+      1),
is represented by a node in the devised mesoscopic net-
work. fig. 1(a) illustrates the process of obtaining the
nodes of the mesoscopic network.

the edges of the mesoscopic network are identi   ed by
calculating a contextual similarity measurement consid-
ering all pairs of sequences of paragraphs p    
k in the in-
vestigated document. here, we employed the traditional
bag of words combined with the cosine similarity mea-
surement [45]. bearing in mind that the number of words
in each paragraph can vary signi   cantly, the cosine simi-
larity was used because it does not depend on the length
of the text chunks being compared [32]. first, for each
considered sequence of paragraphs p , a vector wp , span-
ning the same number of words present in o, is obtained
from the tf-idf(w, p, o) map applied to each word w in
o. note that, when a certain word w is not present in p ,
tf-idf(w, p, o) = 0. the content similarity measurement

3

fig. 1: illustration of the presented methodology. initially, the text is organized in sets of subsequent and overlapping windows
k , each containing 3 structural paragraphs, as shown in (a). next, the cosine similarity is calculated among all pairs of text
p 3
windows (illustrated by the width of the lines in b). the mesoscopic network is obtained by maintaining only connections
among pairs with similarity higher than a threshold value t . this is illustrated by the network visualization in (c).

s(pa, pb) between two paragraph windows pa and pb

is obtained using

(cid:80)
(cid:114) (cid:80)
tf-idf(w, pa, o)2(cid:114) (cid:80)

w     o

w     o

w     o

tf-idf(w, pa, o)    tf-idf(w, pb, o)

tf-idf(w, pb, o)2

.

(3)

s(pa, pb) =

as a result, a fully connected network is created (see
fig. 1(b)), in which the edge weights correspond to the
similarity s(pa, pb) among each pair of nodes. the    nal
mesoscopic network is obtained by pruning the weakest
connections, i.e.
the links whose weight takes a value
below a given threshold t . after this procedure, edge
weights are ignored, resulting in an unweighted network
(see fig. 1(c)).

to better understand the overall structure of meso-
scopic networks, we visualized the network structure
using a technique based on force-directed nodes place-
ment. in particular, we used a technique inspired on the
fruchterman-reingold (fr) [31] algorithm, in which the
network is regarded as a system of nodes behaving like
particles that interact by the action of two types of forces:
attractive forces, existing only between connected nodes,

p03p13p23p33p43p03p13p23p33p43p03p0p1p2p3p4p5p6organizedtext (o)(a)(c)(b)paragraph windows (pk3)p13p23p33p43and repulsive forces, that exist between all pairs of nodes.
by minimizing the energy of that system, the network or-
ganizes itself in a graphically appealing layout. this vi-
sualization technique naturally highlights many aspects
of the topological structure of networks [31].

results evaluation

in order to show the potential of our networks to re-
   ect the document story, we compared networks created
from real texts (rt) with networks created from shuf-
   ed texts (st), where clearly no story exists. the shuf-
   ed texts were created in a two-fold manner: obtained
by shu   ing words (sw) or paragraphs (sp) from real
texts. to generate the sw version, all words from a
given text were shu   ed and the paragraphs were created
with the same number of words as those in the original
document. it is important to highlight that the number
of paragraphs, their respective order and the number of
words in each paragraph were preserved. in the second
version of shu   ed texts, sp, we shu   ed all paragraphs
from a given real text. thus, the structure of each single
paragraph is kept, but the new sequence of paragraphs
may not generate a consistent, coherent story.

for each document, a single weighted mesoscopic net-
work was created for each class (rt, sw, and sp). con-
sequently, the classes have the same number of networks.
considering the classes of text (rt, sw, and sp), for
each weighted network, we generated unweighted net-
works from a set of thresholds (t ). these thresholds
were de   ned according to a given percentage of expected
edges, so that edges with higher weights were main-
tained. after removing edges whose weights were below
the threshold t , we used two measurements to compare
the mesoscopic networks:

1. id91 coe   cient: this measurement is well
known in complex networks analysis [62] and it was
used in many text classi   cation applications [6, 46,
57]. the id91 coe   cient quanti   es the frac-
tion of loops of order three (i.e. triangles), for each
network node and it is computed as

ci =

n   (i)
n3(i)

,

(4)

where n   (i) is the number of connected triangles
in which node i takes part and n3(i) is the number
of connected triples, where i is the central node;

2. matching index:

for each edge, this measure
computes the similarity between the two nodes con-
nected to the edge according to the number of com-
mon neighbors [38, 51, 59].
in other words, this
measurement quanti   es the similarity between two
network regions connected by an edge. this mea-
surement is computed as

(cid:80)
k(cid:54)=j aik +(cid:80)

k(cid:54)=i,j aikajk

(cid:80)

k(cid:54)=i ajk

  i,j =

,

(5)

4

where aij is an element of the adjacency matrix,
and aij = 1 if nodes i and j are connected.

the books were considered in their entirity. as a con-
sequence, the number of network nodes varies, which can
in   uence many complex network measurements. as a so-
lution for this problem, we analyzed the network in terms
of local measurements of id91 and matching index.
in order to provide additional information about the
text, the two measurements were calculated for all
nodes/edges and sorted according to the text sequence,
giving rise to a time series. for the matching index, we
created the time series by establishing the following order
of edges:
{  0,0,   0,1, . . . ,   0,n   1,   1,0,   1,1 . . .   1,n   1, . . . ,   n   1,n   1}.
if there is no edge linking two nodes, the corresponding
value in the time series is not taken into account.

iii. case study: mesoscopic analysis

of    alice   s adventures in

wonderland   

in order to illustrate the potential of modeling real
texts as mesoscopic networks, we applied our methodol-
ogy to the well-kwown book    alice   s adventures in won-
derland   . this story revolves around the adventures of
a little girl, called alice, after she falls in a hole and
arrives in an unknown fantasy world. the book was
written in 1865 by charles lutwidge dodgson under the
pseudonym lewis carroll. it is divided into the following
twelve chapters:

1. down the rabbit-hole

2. the pool of tears

3. a caucus-race and a long tale

4. the rabbit sends in a little bill

5. advice from a caterpillar

6. pig and pepper

7. a mad tea-party

8. the queen   s croquet-ground

9. the mock turtle   s story

10. the lobster quadrille

11. who stole the tarts?

12. alice   s evidence

after the pre-processing steps had been undertaken,
we chose a    xed window size     = 20 paragraphs. two
mesoscopic networks, g1 and g2, were constructed from
the book with distinct thresholds to prune connections,

t1 = 0.31 and t2 = 0.18, respectively. with these
thresholds, only 5% and 10% of the edges, respectively,
remained in the network.
we start the analysis of the mesoscopic structures by
investigating the properties of the g1 network, which is
simpler than g2. for this analysis, we consider a 2d
visualization of g1, which is shown in figure 2. this
visualization was obtained by employing the fr algo-
rithm mentioned in section ii. because nodes sharing
the same paragraphs become strongly connected among
themselves, a pronounced chain-like structure naturally
emerges on the mesoscopic network.
in addition, this
structure is related to the order of the nodes along the
book. this property is better observed in figure 2(a),
where the color of each node indicates its position along
the text.
in mesoscopic networks, connections among
distant nodes indicate regions of high contextual simi-
larity that are not a result of overlapping sequences of
paragraphs.
in these networks, the structure connects
contextually similar regions of nodes which, by its turn,
brings them closer along the chain-like structure of the
network.

in order to better understand the relationship between
the mesoscopic structure and the contextual information
of the book, we segmented the obtained network accord-
ing to the chapter organization of the book. this is visu-
alized in figure 2(b), in which the chapter of each node
is indicated by a color, according to the legend. consid-
ering the connectivity among the chapters of the book,
we derived the following observations:

    in chapter 1, we note that there is no strong con-
nection among its paragraphs and those from other
chapters, except for chapter 2 and 3, which is
explained by the aforementioned overlap between
subsequent paragraphs. the lack of long range con-
nections among the nodes of the    rst chapter may
happen because the main subject of this chapter is
substantially di   erent from almost every other in
the book.
in this chapter, the story unfolds in a
more realistic scenario and it has no descriptions
of the fantasy locations and creatures found in the
rest of the book, except for the rabbit;

    chapters 2, 3, and the beginning of chapter 4 are
connected among themselves. this may be a con-
sequence of the fact that all these chapters describe
the period of the story when alice was very fright-
ened of the world she has just jumped in. in addi-
tion, all these chapters mention when she cried and
it formed a pool of tears;

    in chapter 5, there are strong connections between
regions from the same chapter. this probably hap-
pens because there is a long conversation between
alice and the caterpillar, in which they discuss the
many sizes she had during the previous chapters;
    the connection between chapters 7 and 11 can be
related to the character the hatter, who is drinking

5

tea in both chapters. furthermore, he talked about
speci   c kinds of food related to the tea party in
both situations, e.g. bread and butter;

    there is a group of highly connected nodes in the
end of chapter 9 and in the beginning of chap-
ter 10. this probably happens because alice met
the mock turtle in the last paragraphs of chapter
9 and their conversation ended only in chapter 10.
figure 3 displays a visualization of the g2 network,
which was constructed using a lower threshold value,
t2 = 0.18. by using two threshold choices, it has been
possible to illustrate the potential of our method in de-
scribing the characteristics of the network in a multi-scale
fashion. from figure 3(a), we can observe the network
still has a chain-like structure similar to that found in g1.
however, this network presents more connections among
nodes from di   erent parts of the book. this is because
the g2 network captures more    ne-grained information
about the relationships among the paragraphs. compar-
ing g1 and g2, we note that while chapter 1 is connected
only with chapter 2 and 3 in g1, in g2 it also connects
with other parts of the book, in particular, with chapters
4 and 7. however, the analysis of    ne-grained networks
may present some disadvantages because these networks
tend to incorporate more local characteristics. moreover,
they may include noise and relationships not driven by a
strong contextual content.

iv. discriminating real from

shuffled texts

to illustrate the ability of the proposed representation
to grasp semantical information of texts by considering
topological features, we evaluated the e   ciency of the
method in discriminating real texts from texts convey-
ing no meaning, which are here represented by shu   ed
texts. this is an important potential application of the
proposed approach as a subsidy to fraud identi   cation,
such as inferring if texts in unknown languages are mean-
ingful or not.

in figure 4, we show the two networks obtained from
the book       alice   s adventures in wonderland    and the
respective values of id91 coe   cient (for two thresh-
olds) along the document. note that an interesting pat-
tern emerges in both cases. regions encompassing many
long-range connections are characterized by low values
of id91. in addition, there is a complex pattern of
intermittent appearences of low values of id91 co-
e   cient in regions devoid of long-range connections. a
similar behavior occurred with the matching index (re-
sult not shown). in figure 5, we show the behavior of the
id91 coe   cient along time for the real book and its
two respective meaningless versions formed by shu   ed
paragraphs and words. it is clear from the    gure that,
in average, the id91 coe   cient of all three versions
   uctuates around c (cid:39) 0.78. however, the patterns of

6

fig. 2: visualization of the network g1, representing the book alice   s adventures in wonderland with a threshold t1 = 0.31.
each node indicates a sequence of paragraphs. the order of the nodes according to the story is shown in (a). the    rst nodes
of the story appear in blue, while the last nodes are represented in an orange color. in (b), the chapters of the nodes are
represented with distinct colors.

   uctuations are markedly dissimilar. the largest varia-
tions arise for the real book, while both shu   ed versions
seem to display larger regions of weak    uctuations (see
e.g. nodes from 180 to 280 in figure 5(b)). a similar
pattern was obtained for the matching index measure-
ment. owing to the clear patterns in the    uctuations of
local density discriminating real and meaningless texts,
we applied measurements to quantify the mentioned    uc-
tuations in order to check how much the proposed model
depends on the text unfolding.

the    uctuations observed in figure 5 were character-
ized with the coe   cient of variation in a set of obser-
vations x, where x here represents the ordered set of
values of c or   . the coe   cient of variation (cv(x)) is
de   ned [20] as:

cv(x) =   (x)/(cid:104)x(cid:105),

(6)
where   (x) and (cid:104)x(cid:105) are the standard deviation and
the average of x, respectively. for a choice of a win-
dow size,   , and for each possible subsequence of x,
k = {xk, xk+1, . . . , xk+     1}, the coe   cient of variation,
x   
cv(x   
k ), is calculated. the set of    values used in this
paper was    = {3, 5, 7, 10, 15, 20, 25, 30, 35, 40, 50}. for
each value of window size   , we summarize the values of
   uctuations by averaging over all cv(x   

k ), i.e.:

c  
v(x) =

1
n

cv(x   
k ).

(7)

n     +1(cid:88)

k=1

finally, each network was characterized by the set of fea-
. . .}, with x being the values
tures f = {c  =3
of id91 coe   cient and matching index.

,c  =5

,c  =7

v

v

v

to validate the potential of our mesoscopic model to
extract the information from the document story, we con-
sidered the problem of discriminating real from meaning-
less (shu   ed) texts using a dataset comprising several
books (see details in appendix a). we    rst visualized all
three classes of texts in a bidimensional principal com-
ponent analysis projection [37] (pca). the results are
shown in figure 6(a), in which the two    rst components
account for approximately 76% of the projection. re-
markably, the networks are usually placed close to oth-
ers from the same class, while being well-separated from
other classes. this latter e   ect is con   rmed in terms of
the average distance between classes shown in table i(a).
our results are compared with those obtained with the
traditional approach based on co-occurrence networks
(see details in appendix b). the pca projection of these
networks is shown in figure 6(b). although the sum of
the two main pca components accounts for 70% of the
projection, the group of networks from rt and sp are
not distinguishable. this behavior was expected because
co-occurrence networks were    rst devised to grasp lin-
guistic/syntactical features. when language structure is
kept and only the mesoscopic structure is changed (in
sp texts), the co-occurrence approach is unable to dis-
criminate real from meaningless texts. the poor discrim-

(a)(b)7

fig. 3: visualization of the network g2, representing the book alice   s adventures in wonderland with a threshold t1 = 0.31.
the nodes indicate sets of 20 adjacent paragraphs. item (a) shows the order of the nodes according to the story, where the
   rst nodes of the story appear in blue and the last nodes in an orange. item (b) represents the chapters, in which the nodes
are represented with distinct colors.

fig. 4: visualization of the networks representing    alice   s adventures in wonderland   . item (a) represents the network g1
with a threshold t1 = 0.31 and item (b) represents the network g2 with a threshold t2 = 0.18. the node colors indicate
the value of the id91 coe   cient, in which nodes with the highest values are represented in orange. note that there is a
non-trivial pattern of id91 coe   cient along the network nodes.

inability observed is con   rmed by the distances shown in

table i(b).

(a)(b)(a)(b)8

table i: average distance among networks from the same
class. note that, when using mesoscopic networks, it is pos-
sible to discriminate real texts from those generated by both
shu   ed words and paragraph. conversely, if co-occurrence
networks are used, real texts and texts formed by shu   ed
paragraphs cannot be discriminated.

(a) mesoscopic network.
rt sw sp
rt 0.00 13.67 10.98
sw 13.67 0.00 13.21
sp 10.98 13.21 0.00

(b) co-occurrence

network.
rt sw sp
rt 0.00 7.18 0.12
sw 7.18 0.00 7.08
sp 0.12 7.08 0.00

table ii: comparison of the id116 id91 perfor-
mance among di   erent network approaches. two di   erent
measurements were applied: adjusted rand index (ari) and
accuracy.
in both measurements, 1 indicates that all in-
stances are correctly classi   ed and 0 indicates the opposite.

ari accuracy
mesoscopic (id91)
0.679
mesoscopic (matching index) 0.576
0.749
mesoscopic (all features)
co-occurrence
0.268

0.883
0.833
0.911
0.575

matching index are used, the percentage of incorrectly
assigned instances are 11.7% and 16.7%, respectively.

the unsupervised approach was also used to compare
the proposed methodology and traditional co-occurrence
networks.
in this analysis, we used 10 principal com-
ponents, as this amount of features yielded optimized
results. the quality of clusters was estimated in terms
of the accuracy the adjusted rand index (ari) [35]. the
cluster quality indexes obtained in both types of networks
are shown in table ii. co-occurrence networks could not
properly distinguish rt from sp classes, as expected
from the analysis of figure 6(b). in this scenario, 72.5%
of sp texts were incorrectly classi   ed as rt. this inabil-
ity is also re   ected in the ari, which is much lower in
co-occurrence networks.

a particular feature of the mesoscopic model is the
existence of long-range connections. more speci   cally, a
long-range connection is a link that connects two nodes
that are far apart in the document. this type of link
usually appears when a subject/context previously men-
tioned in the book is revisited in the story. it has been
conjectured that such links, a consequence of the long-
range correlation e   ect [25], are essential for mapping a
multidimensional conceptual space into a smaller dimen-
sional space [3]. to quantify the presence of long-range
links, we show (figure 7) scatterplots of edges weights
versus the time di   erence between linked nodes, where
time corresponds to the natural reading order.
in all
three classes of texts, as imposed by the construction
rules of mesoscopic networks, many edges are established
between successive nodes. long-range connections were
also observed in the three classes of texts (i.e. rt, sw,

(a) rt

(b) sp

(c) sw

fig. 5: id91 coe   cient for all network nodes of real
and shu   ed versions (rt, sw, and sp) created from the book
   alice   s adventures in wonderland". the threshold t1 = 0.31
was chosen to select the strongest semantical links.

the discriminability between real texts and the two
classes of shu   ed texts was also evaluated using an unsu-
pervised approach based on the id116 algorithm [29].
here, we used the 6 principal components as features
as such choice yielded optimized results. considering
all documents of the datasets, only 8.9% of instances
were incorrectly clustered with the mesoscopic approach.
interestingly, the id91 generated by the algorithm
yielded only 0.02% of false negatives for the sp class.
a feature relevance analysis revealed that the cluster-
ing coe   cient outperforms the matching index for the
id91 task, when the algorithm is applied using the
measurements separately. when only the id91 and

9

(a) mesoscopic networks.

(b) co-occurrence networks.

fig. 6: pca projections of the networks generated from real texts (rt), shu   ed paragraphs (sp) texts, and shu   ed words
(sw) texts. the projections (a) and (b) represent the mesoscopic and the co-occurrence networks, respectively.

and sp). however, most of such long connections are very
weak. as depicted in the inset of figure 7, real texts tend
to present stronger long range connections than shu   ed
texts, especially in the time frame of 300 to 400 para-
graphs.

v. conclusion

in order to grasp semantical, mesoscopic properties of
texts modeled as networks, we proposed an approach
that considers the semantical similarity between tex-
tual segments. di   erently from previous representations,
we modeled sequences of adjacent paragraphs as nodes,
whose links are established by content similarity. by do-
ing so, we could capture two important features present
in written texts: long-range correlations and the tempo-
ral unfolding of documents.
in addition, the proposed
approach for text representation also allowed multi-scale
representation of documents. speci   cally, two parame-
ters control the scale: (i)    : the number of consecutive
paragraphs in each window, and (ii) t : the threshold
used to prune connections among nodes with low contex-
tual similarity.

as a case study, we tested our approach in    alice   s ad-
ventures in wonderland   , by employing network visual-
ization techniques on the generated mesoscopic network.
many insights could be drawn from the visualization by
tracing a parallel between its underlying structure and
the story. in particular, we investigated the correspon-
dence between the content of each chapter and the under-
lying network structure arising from the proposed model.
our model uncovered many relationships among di   erent
contexts sharing the same topics, such as similar charac-
ters or places throughout the story. for example, the

high contextual similarity found between chapters 7 and
11 can be explained by the fact that both chapters share
a recurrent subject revolving around the character the
hatter and the tea party thematic. note that similar
textual id136s could not be drawn from models solely
based on local features, as it is the case of traditional
word-adjacency or syntactical networks, as they empha-
size mostly stylistic textual subtleties.

the e   ectiveness of our model was also evaluated with
respect to the task of discriminating real from shu   ed
texts. the shu   ed versions, particularly, were created
by mixing either words or paragraphs of real texts. we
have found that, if we consider only two simple local
density measurements, it is possible to separate all three
classes of texts with high accuracy. the traditional co-
occurrence turned out to grasp only local subtleties, as
the model was not able to discriminate real texts from
those generated by shu   ing paragraphs. this happens
because, when paragraphs are shu   ed, only a few edges    
those at the paragraph boundaries     are modi   ed. these
results con   rm the suitability of the proposed model in
capturing larger contexts in a mesoscopic fashion. a fur-
ther analysis of the model also revealed that real texts are
characterized by stronger long-range links, a feature that
could be explored in tests of informativeness of written
documents [7].

the proposed network representation paves the way for
developing new techniques that could be applied to auto-
matically analyze the mesoscopic structure of documents.
these techniques could improve traditional approaches
used to tackle typical id111 problems under a new
perspective. this capability should be further explored in
future works, for instance, by measuring the e   ciency of
our model in text classi   cation, summarization and sim-
ilar applications in which an accurate semantic analysis

10

(a) rt

(b) sp

(c) sw

fig. 7: time di   erence between linked nodes vs. edges weights. this measurement was computed for all network edges and
the inset represents a region of long-range links, i.e. links with time di   erence larger than 100. comparing the di   erent classes
of texts, it is evident that strong long-range connections are more likely to appear in real networks.

plays a prominent role in the characterization of written
texts.

acknowledgements

the authors acknowledge    nancial

from
capes-brazil, s  o paulo research foundation (fapesp)
(grant no. 2016/19069-9, 2015/08003-4, 2015/05676-8,
2014/20830-0 and 2011/50761-2), cnpq-brazil (grant
no. 307333/2013-2) and nap-prp-usp.

support

appendix a: dataset

11

all the texts used in our dataset were extracted from the open access project gutemberg dataset [65]. we divided
the dataset into two major groups, according to the original language: (i) english and (ii) other languages. the
books, sorted by language and author, are listed below:

english:
    arthur conan doyle: the adventures of sherlock holmes; the tragedy of the korosko; the valley of fear;

through the magic door and uncle bernac - a memory of the empire;

    bram stoker: dracula   s guest; the lair of the white worm; the jewel of seven stars; the man and the

mystery of the sea;

    charles dickens: a tale of two cities; american notes; barnaby rudge: a tale of the riots of eighty;

great expectations and hard times;

    edgar allan poe: the works of edgar allan poe (volume 1 - 5);
    hector h. munro (saki): beasts and super-beasts; the chronicles of clovis; the toys of peace; when

william came and the unbearable bassington;

    p. g. wodehouse: the girl on the boat; my man jeeves; something new; the adventures of sally and the

clicking of cuthbert

    thomas hardy: a pair of blue eyes; far from the madding crowd; jude the obscure; the mayor of

casterbridge and the hand of ethelberta;

    william m. thackeray: barry lyndon; the book of snobs; the history of pendennis; the virginians and

vanity fair
other languages:

1. french:

    gustave aimard: le    ls du soleil;
    jules verne: face au drapeau;
    louis am  d  e achard: pierre de villergl  ;
    louis reybaud: les idoles d   argile;
    victor hugo: han d   islande.

2. german:

    goethe: die wahlverwandtschaften;
    jakob wassermann: der moloch;
    robert walser: geschwister tanner;
    thomas mann: k  nigliche hoheit;
    wilhelm hau   : lichtenstein.

3. italian

    alberto boccardi: il peccato di loreta;
    anton giulio barrili: la montanara;
    enrico castelnuovo: alla finestra;
    guido da verona: sciogli la treccia, maria maddalena;
    virginia mulazzi: la pergamena distrutta.

4. portuguese:

    camilo castelo branco: amor de perdi    o;
    e  a de queir  s: a cidade e as serras;
    faustino da fonseca: os bravos do mindello;
    jaime de magalh  es lima: transviado;
    j  lio dinis: uma fam  lia inglesa.

12

appendix b: characterization of co-occurrence networks

tipically, co-occurrence (or word adjacency) networks are formed by mapping each concept into a distinct node of
the network. the edges are established by adjacency relationships, i.e. if two words are adjacent in the text, they are
connected in the network. such networks have been extensively explored in the context of text analysis and pattern
recognition [46]. in the present work, we compare the properties of the mesoscopic and co-occurrence models.

we compare the mesoscopic results with a set of centrality measurements of co-occurrence networks used in the
ref. [24], which are: accessibility [61], betweenness centrality [30], closeness centrality, id91 coe   cient, degree,
eccentricity [26], eigenvector centrality [16], generalized accessibility [21], modularity [52] (computed from fast greedy
algorithm [19]), neighborhood connectivity, number of nodes, id95 [42], and, symmetry [24]. apart from modu-
larity, we compute the following quantities for each measurement: maximum value (max(x)), median (   x), minimum
value (min(x)), and standard deviation   (x). to create the co-occurrence networks, we trimmed the texts to the
same number of words because many of the above complex network measurements are in   uenced by the number of
nodes. because the number of network nodes varies in mesoscopic networks, we did not use the same set of mea-
surements as for the co-occurrence networks. furthermore, in the co-occurence network analysis, we only used texts
written in english because this kind of representation catches information regarding the syntax, which is di   erent for
each language.

13

[1] alsumait, l., barbar  , d., and domeniconi, c. (2008). on-line lda: adaptive topic models for mining text streams with
applications to topic detection and tracking. in data mining, 2008. icdm   08. eighth ieee international conference on,
pages 3   12. ieee.

[2] altmann, e. g., pierrehumbert, j. b., and motter, a. e. (2009). beyond word frequency: bursts, lulls, and scaling in the

temporal distributions of words. plos one, 4(11):e7678.

[3] alvarez-lacalle, e., dorow, b., eckmann, j.-p., and moses, e. (2006). hierarchical structures induce long-range dynamical

correlations in written texts. proceedings of the national academy of sciences, 103(21):7956   7961.

[4] amancio, d. r. (2015a). authorship recognition via    uctuation analysis of network topology and word intermittency.

journal of statistical mechanics: theory and experiment, 2015(3):p03005.

[5] amancio, d. r. (2015b). a complex network approach to stylometry. plos one, 10(8):e0136076.
[6] amancio, d. r., altmann, e. g., oliveira jr, o. n., and costa, l. d. f. (2011). comparing intermittency and network

measurements of words and their dependence on authorship. new journal of physics, 13(12):123024.

[7] amancio, d. r., altmann, e. g., rybski, d., oliveira jr., o. n., and costa, l. f. (2013). probing the statistical properties

of unknown texts: application to the voynich manuscript. plos one, 8(7):1   10.

[8] amancio, d. r., nunes, m. g., jr., o. n. o., and da f. costa, l. (2012a). extractive summarization using complex

networks and syntactic dependency. physica a: statistical mechanics and its applications, 391(4):1855     1864.

[9] amancio, d. r., oliveira jr., o. n., and costa, l. f. (2012b). structure   semantics interplay in complex networks and its

e   ects on the predictability of similarity in texts. physica a, 391(18):4406     4419.

[10] amancio, d. r., oliveira jr., o. n., and da f. costa, l. (2012c). unveiling the relationship between complex networks

metrics and word senses. epl (europhysics letters), 98(1):18002.

[11] antiqueira, l., oliveira jr., o. n., costa, l. f., and nunes, m. g. v. (2009). a complex network approach to text

summarization. information sciences, 179(5):584     599.

[12] barab  si, a.-l., gulbahce, n., and loscalzo, j. (2011). network medicine: a network-based approach to human disease.

[13] barabasi, a.-l. and oltvai, z. n. (2004). network biology: understanding the cell   s functional organization. nature reviews

[14] blei, d. m., ng, a. y., and jordan, m. i. (2003). id44. the journal of machine learning research,

nature reviews genetics, 12(1):56   68.

genetics, 5(2):101   113.

3:993   1022.

physics reports, 424(4):175   308.

[15] boccaletti, s., latora, v., moreno, y., chavez, m., and hwang, d.-u. (2006). complex networks: structure and dynamics.

[16] bonacich, p. (1987). power and centrality: a family of measures. american journal of sociology, pages 1170   1182.
[17] chang, y.-l. and chien, j.-t. (2009). latent dirichlet learning for document summarization. in acoustics, speech and

signal processing, 2009. icassp 2009. ieee international conference on, pages 1689   1692. ieee.

[18] chen, x., hao, p., chandramouli, r., and subbalakshmi, k. (2011). authorship similarity detection from email messages.

in machine learning and data mining in pattern recognition, pages 375   386. springer.

[19] clauset, a., newman, m. e., and moore, c. (2004). finding community structure in very large networks. physical review

e, 70(6):066111.

pages-4, 5:290.

[20] das, n. (2008). statistical methods-combined edition (volumes i and ii). tata mcgraw hill education private limited,

[21] de arruda, g. f., barbieri, a. l., rodr  guez, p. m., rodrigues, f. a., moreno, y., and costa, l. d. f. (2014). role of

centrality for the identi   cation of in   uential spreaders in complex networks. physical review e, 90(3):032812.

[22] de arruda, h. f., comin, c. h., miazaki, m., viana, m. p., and da fontoura costa, l. (2015). a framework for analyzing
the relationship between gene expression and morphological, topological, and dynamical patterns in neuronal networks.
journal of neuroscience methods, 245:1   14.

[23] de arruda, h. f., costa, l. d. f., and amancio, d. r. (2016a). topic segmentation via community detection in complex

networks. chaos: an interdisciplinary journal of nonlinear science, 26(6).

[24] de arruda, h. f., costa, l. d. f., and amancio, d. r. (2016b). using complex networks for text classi   cation: discrimi-

nating informative and imaginative documents. epl (europhysics letters), 113(2):28007.

[25] ebeling, w. and neiman, a. (1995). long-range correlations between letters and sentences in texts. physica a: statistical

mechanics and its applications, 215(3):233     241.

[26] estrada, e. (2012). the structure of complex networks: theory and applications. oxford university press.
[27] feldman, r. (2013). techniques and applications for id31. commun. acm, 56(4):82   89.
[28] ferrer i cancho, r., sol  , r. v., and k  hler, r. (2004). patterns in syntactic dependency networks. phys. rev. e,

[29] frank, e., hall, m., holmes, g., kirkby, r., pfahringer, b., witten, i. h., and trigg, l. (2009). weka-a machine learning

workbench for data mining. in data mining and knowledge discovery handbook, pages 1269   1277. springer.

[30] freeman, l. (1977). a set of measures of centrality based on betweenness. sociometry, 40:35   41.
[31] fruchterman, t. and reingold, e. (1991). graph drawing by force-directed placement. software-practice & experience,

69:051915.

21:1129   1164.

[32] han, j. (2005). data mining: concepts and techniques. morgan kaufmann publishers inc., san francisco, ca, usa.
[33] hatzivassiloglou, v., gravano, l., and maganti, a. (2000). an investigation of linguistic features and id91 algorithms

14

90(5):311   317.

25(2-3):259   284.

university press.

for topical document id91. in proceedings of the 23rd annual international acm sigir conference on research and
development in information retrieval, pages 224   231. acm.

[34] hotho, a., n  rnberger, a., and paa  , g. (2005). a brief survey of id111. in ldv forum, volume 20, pages 19   62.
[35] hubert, l. and arabie, p. (1985). comparing partitions. journal of classi   cation, 2(1):193   218.
[36] joachims, t. (2001). a statistical learning learning model of text classi   cation for support vector machines. in proceedings
of the 24th annual international acm sigir conference on research and development in information retrieval, pages
128   136. acm.

[37] jolli   e, i. (2002). principal component analysis. wiley online library.
[38] kaiser, m. and hilgetag, c. c. (2004). edge vulnerability in neural and metabolic networks. biological cybernetics,

[39] kalimeri, m., constantoudis, v., papadimitriou, c., karamanos, k., diakonos, f. k., and papageorgiou, h. (2015). word-

length entropies and correlations of natural language written texts. journal of quantitative linguistics, 22(2):101   118.

[40] kulig, a., dro  d  , s., kwapie  , j., and o  wi  ecimka, p. (2015). modeling the average shortest-path length in growth of

word-adjacency networks. phys. rev. e, 91:032810.

[41] landauer, t. k., foltz, p. w., and laham, d. (1998). an introduction to latent semantic analysis. discourse processes,

[42] langville, a. n. and meyer, c. d. (2011). google   s id95 and beyond: the science of search engine rankings. princeton

[43] liu, s., wu, y., wei, e., liu, m., and liu, y. (2013). story   ow: tracking the evolution of stories. ieee transactions on

visualization and computer graphics, 19(12):2436   2445.

[44] maas, a. l., daly, r. e., pham, p. t., huang, d., ng, a. y., and potts, c. (2011). learning word vectors for sentiment
analysis. in proceedings of the 49th annual meeting of the association for computational linguistics: human language
technologies-volume 1, pages 142   150. association for computational linguistics.

[45] manning, c. d. and sch  tze, h. (1999). foundations of statistical natural language processing. mit press, cambridge,

ma, usa.

physica a, 391(7):2429     2437.

[46] masucci, a. and rodgers, g. (2006). network properties of written human language. physical review e, 74(2):026102.
[47] mehri, a., darooneh, a. h., and shariati, a. (2012). the complex networks approach for authorship attribution of books.

[48] mihalcea, r., tarau, p., and figa, e. (2004). id95 on semantic networks, with application to word sense disambigua-
tion. in proceedings of the 20th international conference on computational linguistics, coling    04, stroudsburg, pa,
usa. association for computational linguistics.

[49] moreno, y., nekovee, m., and pacheco, a. f. (2004). dynamics of rumor spreading in complex networks. physical review

e, 69(6):066130.

69(2):026113.

[50] nahm, u. y. and mooney, r. j. (2002). id111 with information extraction. in aaai 2002 spring symposium on

mining answers from texts and knowledge bases, volume 1.

[51] newman, m. (2010). networks: an introduction. oxford university press, inc., new york, ny, usa.
[52] newman, m. e. and girvan, m. (2004). finding and evaluating community structure in networks. physical review e,

[53] prado, s. d., dahmen, s. r., bazzan, a. l., carron, p. m., and kenna, r. (2016). temporal network analysis of literary

texts. advances in complex systems (acs), 19(03).

[54] ramos, j. (2003). using tf-idf to determine word relevance in document queries. in proceedings of the    rst instructional

conference on machine learning.

[55] reagan, a. j., mitchell, l., kiley, d., danforth, c. m., and dodds, p. s. (2016). the emotional arcs of stories are

[56] segarra, s., eisen, m., and ribeiro, a. (2015). authorship attribution through function word adjacency networks. ieee

dominated by six basic shapes. epj data science, 5(1):31.

transactions on signal processing, 63(20):5464   5478.

[57] sheng, l. and li, c. (2009). english and chinese languages as weighted complex networks. physica a: statistical mechanics

[58] silva, t. c. and amancio, d. r. (2012). id51 via high order of learning in complex networks. epl

[59] sporns, o. (2003). id207 methods for the analysis of neural connectivity patterns. in neuroscience databases,

and its applications, 388(12):2561   2570.

(europhysics letters), 98(5):58001.

pages 171   185. springer.

[60] tanahashi, y. and ma, k.-l. (2012). design considerations for optimizing storyline visualizations. ieee transactions on

visualization and computer graphics, 18:2679   2688.

[61] traven  olo, b. a. n. and costa, l. d. f. (2008). accessibility in complex networks. physics letters a, 373(1):89   95.
[62] watts, d. j. and strogatz, s. h. (1998). collective dynamics of    small-world    networks. nature, 393(6684):440   442.
[63] wei, y., singh, l., gallagher, b., and buttler, d. (2016). overlapping target event and story line detection of online
in data science and advanced analytics (dsaa), 2016 ieee international conference on, pages

newspaper articles.
222   232. ieee.

[64] xuan, q. and wu, t.-j. (2009). node matching between complex networks. phys. rev. e, 80:026103.
[65] project gutemberg - https://www.gutenberg.org/

