4
1
0
2

 

v
o
n
3
1

 

 
 
]
l
c
.
s
c
[
 
 

2
v
8
1
7
0

.

0
1
4
1
:
v
i
x
r
a

not all neural embeddings are born equal

felix hill

university of cambridge

kyunghyun cho

universit  e de montr  eal

s  ebastien jean

universit  e de montr  eal

coline devin

harvey mudd college

yoshua bengio

universit  e de montr  eal, cifar senior fellow

abstract

neural language models learn word representations that capture rich linguistic and
conceptual information. here we investigate the embeddings learned by neural
machine translation models. we show that translation-based embeddings outper-
form those learned by cutting-edge monolingual models at single-language tasks
requiring knowledge of conceptual similarity and/or syntactic role. the    ndings
suggest that, while monolingual models learn information about how concepts are
related, neural-translation models better capture their true ontological status.

it is well known that word representations can be learned from the distributional patterns in corpora.
originally, such representations were constructed by counting word co-occurrences, so that the fea-
tures in one word   s representation corresponded to other words [11, 17]. neural language models, an
alternative means to learn word representations, use language data to optimise (latent) features with
respect to a language modelling objective. the objective can be to predict either the next word given
the initial words of a sentence [4, 14, 8], or simply a nearby word given a single cue word [13, 15].
the representations learned by neural models (sometimes called embeddings) generally outperform
those acquired by co-occurrence counting models when applied to nlp tasks [3].
despite these clear results, it is not well understood how the architecture of neural models affects
the information encoded in their embeddings. here, we explore this question by considering the em-
beddings learned by architectures with a very different objective function to monolingual language
models: id4 models. we show that translation-based embeddings outperform
monolingual embeddings on two types of task: those that require knowledge of conceptual similarity
(rather than simply association or relatedness), and those that require knowledge of syntactic role.
we discuss what the    ndings indicate about the information content of different embeddings, and
suggest how this content might emerge as a consequence of the translation objective.

1 learning embeddings from language data

both neural language models and translation models learn real-valued embeddings (of speci   ed di-
mension) for words in some pre-speci   ed vocabulary, v , covering many or all words in their training
corpus. at each training step, a    score    for the current training example (or batch) is computed based
on the embeddings in their current state. this score is compared to the model   s objective function,
and the error is backpropagated to update both the model weights (affecting how the score is com-
puted from the embeddings) and the embedding features. at the end of this process, the embeddings
should encode information that enables the model to optimally satisfy its objective.

1.1 monolingual models

in the original neural language model [4] and subsequent variants [8], each training example consists
of n subsequent words, of which the model is trained to predict the n-th word given the    rst n    

1

1 words. the model    rst represents the input as an ordered sequence of embeddings, which it
transforms into a single    xed length    hidden    representation by, e.g., concatenation and non-linear
projection. based on this representation, a id203 distribution is computed over the vocabulary,
from which the model can sample a guess at the next word. the model weights and embeddings are
updated to maximise the id203 of correct guesses for all sentences in the training corpus.
more recent work has shown that high quality id27s can be learned via models with no
nonlinear hidden layer [13, 15]. given a single word in the corpus, these models simply predict
which other words will occur nearby. for each word w in v , a list of training cases (w, c) : c     v
is extracted from the training corpus. for instance, in the skipgram approach [13], for each    cue
word    w the    context words    c are sampled from windows either side of tokens of w in the corpus
(with c more likely to be sampled if it occurs closer to w).1 for each w in v , the model initialises
both a cue-embedding, representing the w when it occurs as a cue-word, and a context-embedding,
used when w occurs as a context-word. for a cue word w, the model can use the corresponding cue-
embedding and all context-embeddings to compute a id203 distribution over v that re   ects the
id203 of a word occurring in the context of w. when a training example (w, c) is observed,
the model updates both the cue-id27 of w and the context-id27s in order to
increase the id155 of c.

1.2 translation-based embeddings

neural translation models generate an appropriate sentence in their target language st given a sen-
tence ss in their source language [see, e.g., 16, 6]. in doing so, they learn distinct sets of embeddings
for the vocabularies vs and vt in the source and target languages respectively.
observing a training case (ss, st), such a model represents ss as an ordered sequence of embed-
dings of words from vs. the sequence for ss is then encoded into a single representation rs.2
finally, by referencing the embeddings in vt, rs and a representation of what has been generated
thus far, the model decodes a sentence in the target language word by word. if at any stage the
decoded word does not match the corresponding word in the training target st, the error is recorded.
the weights and embeddings in the model, which together parameterise the encoding and decoding
process, are updated based on the accumulated error once the sentence decoding is complete.
although neural translation models can differ in low-level architecture [7, 2], the translation objec-
tive exerts similar pressure on the embeddings in all cases. the source language embeddings must
be such that the model can combine them to form single representations for ordered sequences of
multiple words (which in turn must enable the decoding process). the target language embeddings
must facilitate the process of decoding these representations into correct target-language sentences.

2 comparing mono-lingual and translation-based embeddings

to learn translation-based embeddings, we trained both the id56 encoder-decoder [id56enc, 7] and
the id56 search architectures [2] on a 300m word corpus of english-french sentence pairs. we
conducted all experiments with the resulting (english) source embeddings from these models. for
comparison, we trained a monolingual skipgram model [13] and its glove variant [15] for the same
number of epochs on the english half of the bilingual corpus. we also extracted embeddings from a
full-sentence language model [cw, 8] trained for several months on a larger 1bn word corpus.
as in previous studies [1, 5, 3], we evaluate embeddings by calculating pairwise (cosine) distances
and correlating these distances with (gold-standard) human judgements. table 1 shows the corre-
lations of different model embeddings with three such gold-standard resources, wordsim-353 [1],
men [5] and siid113x-999 [10]. interestingly, translation embeddings perform best on siid113x-999,
while the two sets of monolingual embeddings perform better on modelling the men and wordsim-
353. to interpret these results, it should be noted that siid113x-999 evaluation quanti   es conceptual
similarity (dog - wolf ), whereas men and wordsim-353 (despite its name) quantify more general
relatedness (dog - collar) [10]. the results seem to indicate that translation-based embeddings better
capture similarity, while monolingual embeddings better capture relatedness.

1 subsequent variants use different algorithms for selecting the (w, c) from the training corpus [9, 12]
2alternatively, subsequences (phrases) of ss may be encoded at this stage in place of the whole sentence [2].

2

wordsim-353

siid113x-999

  
men   
  
toefl %
syn/antonym %
nn
nn
nn

teacher
white
heat

skipgram glove
0.55
0.71
0.32
0.78
0.72
student
red
thermal

0.52
0.44
0.29
0.75
0.69
vocational
red
thermal

cw id56enc
0.57
0.51
0.63
0.60
0.52
0.28
0.93
0.64
0.79
0.75
professor
student
blank
black
wind
warmth

search
0.58
0.62
0.49
0.93
0.74
instructor
black
warmth

table 1: translation-based embeddings outperform alternatives on similarity-focused evaluations.

to test this hypothesis further, we ran two more evaluations focused speci   cally on similarity. the
toefl synonym test contains 80 cue words, each with four possible answers, of which one is a
correct synonym [11]. we computed the proportion of questions answered correctly by each model,
where a model   s answer was the nearest (cosine) neighbour to the cue word in its vocabulary.3 in
addition, we tested how well different embeddings enabled a supervised classi   er to distinguish
between synonyms and antonyms. for 500 hand-labelled pairs we presented a gaussian id166 with
the concatenation of the two id27s. we evaluated accuracy using 8-fold cross-validation.
as shown in table 1, translation-based embeddings outperform all monolingual embeddings on
these two additional similarity-focused tasks. qualitative analysis of nearest neighbours (bottom
rows) also supports the conclusion that proximity in the translation embedding space corresponds to
similarity while proximity in the monolingual embedding space re   ects relatedness.

2.1 quantity of training data

in previous work, monolingual models were trained on corpora many times larger than the english
half of our parallel translation corpus. to check if these models simply need more training data to
capture similarity as effectively as translation models, we trained them on increasingly large subsets
of wikipedia.4 the results refute this possibility: the performance of monolingual embeddings on
similarity tasks converges well below the level of the translation-based embeddings (fig. 1).

figure 1: effect of training corpus size on performance. wordsim-353 results were similar to men.

2.2 analogy questions

lexical analogy questions are an alternative way of evaluating word representations [13, 15]. in this
task, models must identify the correct answer (girl) when presented with questions such as    man is
to boy as woman is to ...   . for skipgram-style embeddings, it has been shown that if m, b and w
are the embeddings for man, boy and woman respectively, the correct answer is often the nearest
neighbour in the vocabulary (by cosine distance) to the vector v = w + b     m [13].

3to control for different vocabularies, we restricted the effective vocabulary of each model to the intersection

of all model vocabularies, and excluded all questions that contained an answer outiside of this intersection.

4 we could not do the same for the translation models because of the scarcity of bilingual corpora.

3

lllllllllll0.300.350.400.450.500.555001000corpus size (million words)correlationsiid113x   999lllllllllll0.50.60.70.85001000corpus size (million words)llid56encid56searchskipgram etglove etskipgram wikiglove wikicollobert & westonmenfigure 2: translation-based embeddings perform best on syntactic analogies (run,ran: hide, hid).
monolingual skipgram/glove models are better at semantic analogies (father, man; mother, woman)

we evaluated the embeddings on this task using the same vector-algebra method as [13]. as before
we excluded questions containing a word outside the intersection of all model vocabularies, and re-
stricted all answer searches to this reduced vocabulary, leaving 11,166 analogies. of these, 7219 are
classed as    syntactic   , in that they exemplify mappings between parts-of-speech or syntactic roles
(fast, fastest; heavy     heaviest), and 3947 are classed as    semantic    (ottawa, canada; paris    
france), deriving from wider world knowledge. as shown in fig. 2, the translation-based embed-
dings seem to yield poor answers to semantic analogy questions, but are very effective for syntactic
analogies, outperforming the monolingual embeddings, even those trained on much more data.

3 conclusions

id4 models are more effective than monolingual models at learning embed-
dings that encode information about concept similarity and syntactic role. in contrast, monolingual
models encode general inter-concept relatedness (as applicable to semantic analogy questions), but
struggle to capture similarity, even when training on larger corpora. for skipgram-style models,
whose objective is to predict linguistically collocated pairs, this limitation is perhaps unsurprising,
since co-occurring words are, in general, neither semantically nor syntactically similar. however,
the fact that it also applies to the full-sentence model cw suggests that inferring similarity is prob-
lematic for monolingual models even with knowledge of the precise (ordered) contexts of words.
this may be because very dissimilar words (such as antonyms) actually often occur in identical
linguistic contexts.
when considering the strengths of translation embeddings - similarity and syntactic role - it is no-
table that each item in the three similarity-focused evaluations consists of word groups or pairs
of identical syntactic role. thus, the strong performance of translation embeddings on similarity
tasks cannot be simply a result of their encoding of richer syntactic information. to perform well on
siid113x-999, embeddings must encode information approximating what concepts are (their function
or ontology), even when this contradicts the signal conferred by co-occurrence (as can be the case
for related-but-dissimilar concept pairs) [10]. the translation objective seems particularly effective
at inducing models to encode such ontological or functional information in id27s.
while much remains unknown about this process, one cause might be the different ways in which
words partition the meaning space of a language. in cases where a french word has two possible
english translations (e.g. gagner     win / earn), we note that the (source) embeddings of the two
english words are very close. it appears that, since the translation model, which has limited encod-
ing capacity, is trained to map tokens of win and earn to the same place in the target embedding
space, it is ef   cient to move these concepts closer in the source space. while clear-cut differences
in how languages partition meaning space, such as (gagner = win, earn), may in fact be detrimental
to similarity modelling (win and earn are not synonymous to english speakers), in general, lan-
guages partition meaning space in less drastically different ways. we hypothesize that these small
differences are the key to how neural translation models approximate ontological similarity so ef-
fectively. at the same time, since two dissimilar or even antonymous words in the source language
should never correspond to a single word in the target language, these pairs diverge in the embedding
space, rendering two antonymous embeddings easily distinguishable from those of two synonyms.

4

lllllllllll0.250.500.755001000corpus size (million words)accuracy (%)semanticlllllllllll0.250.500.755001000corpus size (million words)llid56encid56searchskipgram etglove etskipgram wikiglove wikicollobert & westonsyntacticreferences
[1] eneko agirre, enrique alfonseca, keith hall, jana kravalova, marius pasca, and aitor soroa.
a study on similarity and relatedness using distributional and id138-based approaches. in
proceedings of naacl-hlt 2009, 2009.

[2] dzmitry bahdanau, kyunghyun cho, and yoshua bengio. id4 by

jointly learning to align and translate. arxiv:1409.0473 [cs.cl], september 2014.

[3] marco baroni, georgiana dinu, and germ  an kruszewski. don   t count, predict! a systematic
comparison of context-counting vs. context-predicting semantic vectors. in proceedings of the
52nd annual meeting of the association for computational linguistics, volume 1, 2014.

[4] yoshua bengio, r  ejean ducharme, pascal vincent, and christian janvin. a neural probabilistic

language model. j. mach. learn. res., 3:1137   1155, march 2003.

[5] elia bruni, nam-khanh tran, and marco baroni. multimodal id65. j. artif.

intell. res.(jair), 49:1   47, 2014.

[6] kyunghyun cho, bart van merri  enboer, dzmitry bahdanau, and yoshua bengio. on the prop-
erties of id4: encoder   decoder approaches. in eighth workshop on
syntax, semantics and structure in statistical translation, october 2014. to appear.

[7] kyunghyun cho, bart van merrienboer, caglar gulcehre, fethi bougares, holger schwenk,
and yoshua bengio. learning phrase representations using id56 encoder-decoder for statis-
in proceedings of the empiricial methods in natural language
tical machine translation.
processing (emnlp 2014), october 2014. to appear.

[8] ronan collobert and jason weston. a uni   ed architecture for natural language processing:
deep neural networks with multitask learning. in proceedings of the 25th international con-
ference on machine learning, pages 160   167. acm, 2008.

[9] felix hill and anna korhonen. learning abstract concepts from multi-modal data: since you
probably can   t see what i mean. in proceedings of the empiricial methods in natural language
processing (emnlp 2014), october 2014.

[10] felix hill, roi reichart, and anna korhonen. siid113x-999: evaluating semantic models with

(genuine) similarity estimation. arxiv preprint arxiv:1408.3456, 2014.

[11] thomas k landauer and susan t dumais. a solution to plato   s problem: the latent semantic
analysis theory of acquisition, induction, and representation of knowledge. psychological
review, 104(2):211, 1997.

[12] omer levy and yoav goldberg. dependency-based id27s. in proceedings of the

52nd annual meeting of the association for computational linguistics, volume 2, 2014.

[13] tomas mikolov, ilya sutskever, kai chen, greg s corrado, and jeff dean. distributed repre-
sentations of words and phrases and their compositionality. in advances in neural information
processing systems, pages 3111   3119, 2013.

[14] andriy mnih and geoffrey e hinton. a scalable hierarchical distributed language model. in

advances in neural information processing systems, pages 1081   1088, 2009.

[15] jeffrey pennington, richard socher, and christopher manning. glove: global vectors for word
in proceedings of the empiricial methods in natural language processing

representation.
(emnlp 2014), october 2014.

[16] ilya sutskever, oriol vinyals, and quoc v le. sequence to sequence learning with neural

networks. arxiv preprint arxiv:1409.3215, 2014.

[17] peter d turney, patrick pantel, et al. from frequency to meaning: vector space models of

semantics. journal of arti   cial intelligence research, 37(1):141   188, 2010.

5

