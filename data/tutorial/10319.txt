dopelearning: a computational approach to rap lyrics

generation   

eric malmi

aalto university and hiit

espoo, finland

eric.malmi@aalto.   

pyry takala
aalto university
espoo, finland

pyry.takala@aalto.   

hannu toivonen

university of helsinki and hiit
hannu.toivonen@cs.helsinki.   

helsinki, finland

6
1
0
2

 

n
u
j
 

9

 
 
]

g
l
.
s
c
[
 
 

2
v
1
7
7
4
0

.

5
0
5
1
:
v
i
x
r
a

tapani raiko
aalto university
espoo, finland

tapani.raiko@aalto.   

abstract
writing rap lyrics requires both creativity to construct a
meaningful, interesting story and lyrical skills to produce
complex rhyme patterns, which form the cornerstone of good
   ow. we present a rap lyrics generation method that cap-
tures both of these aspects. first, we develop a prediction
model to identify the next line of existing lyrics from a set of
candidate next lines. this model is based on two machine-
learning techniques: the rankid166 algorithm and a deep
neural network model with a novel structure. results show
that the prediction model can identify the true next line
among 299 randomly selected lines with an accuracy of 17%,
i.e., over 50 times more likely than by random. second,
we employ the prediction model to combine lines from ex-
isting songs, producing lyrics with rhyme and a meaning.
an evaluation of the produced lyrics shows that in terms
of quantitative rhyme density, the method outperforms the
best human rappers by 21%. the rap lyrics generator has
been deployed as an online tool called deepbeat, and the
performance of the tool has been assessed by analyzing its
usage logs. this analysis shows that machine-learned rank-
ings correlate with user preferences.

1.

introduction

emerging from a hobby of african american youth in the
1970s, rap music has quickly evolved into a mainstream mu-
sic genre with several artists frequenting billboard top rank-
ings. our objective is to study the problem of computational
creation of rap lyrics. our interest in this problem is moti-
vated by two di   erent di   erent perspectives. first, we are
interested in analyzing the formal structure of rap lyrics and
in developing a model that can lead to generating artistic
   when used as an adjective, dope means cool, nice, or awe-
some.

this is a pre-print of an article appearing at kdd   16.

aristides gionis

aalto university and hiit

espoo, finland

aristides.gionis@aalto.   

work. second, with the number of smart devices increasing
that we use on a daily basis, it is expected that the demand
will increase for systems that interact with humans in non-
mechanical and pleasant ways.

rap is distinguished from other music genres by the formal
structure present in rap lyrics, which makes the lyrics rhyme
well and hence provides better    ow to the music. literature
professor adam bradley compares rap with popular music
and traditional poetry, stating that while popular lyrics lack
much of the formal structure of literary verse, rap crafts
   intricate structures of sound and rhyme, creating some of
the most scrupulously formal poetry composed today    [5].

we approach the problem of lyrics creation from an infor-
mation-retrieval (ir) perspective. we assume that we have
access to a large repository of rap-song lyrics. in this pa-
per, we use a dataset containing over half a million lines
from lyrics of 104 di   erent rap artists. we then view the
lyrics-generation problem as the task of identifying a rele-
vant next line. we consider that a rap song has been par-
tially constructed and treat the    rst m lines of the song as
a query. the ir task is to identify the most relevant next
line from a collection of candidate lines, with respect to the
query. following this approach, new lyrics are constructed
line by line, combining lyrics from di   erent artists in order
to introduce novelty. a key advantage of this approach is
that we can evaluate the performance of the generator by
measuring how well it predicts existing songs. while con-
ceptually one could approach the lyrics-generation problem
by a word-by-word construction, so as to increase novelty,
such an approach would require signi   cantly more complex
models and we leave it for future work.

our work lies in the intersection between the areas of
computational creativity and information retrieval.
in our
approach, we assume that users have a certain concept in
their mind, formulated as a sequence of rap lines, and their
information need is to    nd the missing lines, composing a
song. such an information need does not have a factual an-
swer; nevertheless, users will be able to assess the relevance
of the response provided by the system. the relevance of
the response depends on factors that include rhyming, vo-
cabulary, unexpectedness, semantic coherence, and humor.
tony veale [26] illustrates other linguistically creative uses
of information retrieval, e.g., for metaphor generation. he
argues that phrases extracted from large corpora can be used
as    readymade    or    found    objects, like objets trouv  es in arts,

that can take on fresh meanings when used in a new context.
from the computational perspective, a major challenge
in generating rap lyrics is to produce semantically coherent
lines instead of merely generating complex rhymes. as paul
edwards [9] puts it:    if an artist takes his or her time to craft
phrases that rhyme in intricate ways but still gets across the
message of the song, that is usually seen as the mark of a
highly skilled mc.   1 as a result of record results in com-
puter vision, deep neural networks [1] have become a popu-
lar tool for id171. to avoid hand-crafting a num-
ber of semantic and grammatical features, we introduce a
deep neural network model that maps sentences into a high-
dimensional vector space. this type of vector-space repre-
sentations have attracted much attention in recent years and
have exhibited great empirical performance in tasks requir-
ing semantic analysis of natural language [19, 20].

while some of the features we extract from the analyzed
lyrics are tailored for rap lyrics, a similar approach could
be applied to generate lyrics for other music genres. fur-
thermore, the proposed framework could form the basis for
several other text-synthesis problems, such as generation of
text or conversation responses. practical extended applica-
tions include automation of tasks, such as customer service,
sales, or even news reporting.

our contributions can be summarized as follows:

(i) we propose an information-retrieval approach to rap
lyrics generation. a similar approach could be applied
to other tasks requiring text synthesis.

(ii) we introduce several useful features for predicting the
next line of a rap song and hence for generating new
lyrics.
in particular, we have developed a deep neural
network model for capturing the semantic similarity of
lines. this feature carries the most predictive power of
all the features we have studied.

(iii) we present rhyme density, a measure for the technical
quality of rap lyrics. this measure is validated with a
human subject, a native-speaking rap artist.

(iv) we have built an online demo of the rap lyrics generator
openly available at deepbeat.org. the performance of
the algorithm has been assessed based on the usage logs
of the demo.

the rest of the paper is organized as follows. we start
with a brief discussion of relevant work. next, we discuss
the domain of rap lyrics, introduce the dataset that we have
used, and describe how rhymes can be analyzed. we pro-
ceed by describing the task of nextline and our approach
to solving it, including the used features, the neural lan-
guage model, and the results of our experiments. we apply
the resulting model to the task of lyrics generation, showing
also examples of generated lyrics. the    nal sections discuss
further these tasks, our model, and conclusions of the work.

2. related work

while the study of human-generated lyrics is of interest
to academics in    elds such as linguistics and music, arti   -
cial rhyme generation is also relevant for various sub   elds
of computer science. relevant literature can be found un-
der domains of computational creativity, information extrac-
tion and natural language processing. additionally, relevant

1mc, short for master of ceremonies or microphone con-
troller, is essentially a word for a rap artist.

methods can be found under the domain of machine learn-
ing, for instance, in the emerging    eld of deep learning.

hirjee and brown [12, 13] develop a probabilistic method,
inspired by local alignment protein homology detection al-
gorithms, for detecting rap rhymes. their algorithm ob-
tains a high rhyme detection performance, but it requires a
training dataset with labeled rhyme pairs. we introduce a
simpler, rule-based approach in section 3.3, which seemed
su   cient for our purposes. hirjee and brown obtain a pho-
netic transcription for the lyrics by applying the cmu pro-
nouncing dictionary [16], some hand-crafted rules to handle
slang words, and text-to-phoneme rules to handle out-of-
vocabulary words, whereas we use an open-source speech
synthesizer, espeak, to produce the transcription. the com-
putational generation of rap lyrics has been previously stud-
ied in [29, 28]. these works adopt a machine-translation ap-
proach, whereas we view it as an information-retrieval prob-
lem. furthermore, we have deployed our lyrics generator as
an openly accessible web tool to assess its performance in
the wild.

automated creation of rap lyrics can also be viewed as a
problem within the research    eld of computational creativ-
ity, i.e., study of computational systems which exhibit be-
haviors deemed to be creative [7]. according to boden [4],
creativity is the ability to come up with ideas or artifacts
that are new, surprising, and valuable, and there are three
di   erent types of creativity. our work falls into the class
of    combinatorial creativity    where creative results are pro-
duced as novel combinations of familiar ideas. combina-
torial approaches have been used to create poetry before
but were predominantly based on the idea of copying the
grammar from existing poetry and then substituting con-
tent words with other ones [25].

in the context of web search,

it has been shown that
document ranking accuracy can be signi   cantly improved
by combining multiple features via machine-learning algo-
rithms instead of using a single static ranking, such as page-
rank [21]. this learning-to-rank approach is very popular
nowadays and many methods have been developed for it [17].
in this paper, we use the rankid166 algorithm [14] for com-
bining di   erent relevance features for the next-line predic-
tion problem, which is the basis of our rap-lyrics generator.
neural networks have been recently applied to various re-
lated tasks. for instance, recurrent neural networks (id56s)
have shown promise in predicting text sequences [11, 23].
other applications include tasks such as information extrac-
tion, information retrieval and indexing [8]. question an-
swering has also been approached by using deep learning
to map questions and answers to a latent semantic space,
and then either generating a response [27] or selecting one
[30]. our neural network approach has some similarity to
response selection as we also learn a mapping to a hidden
space. on the other hand, our network architecture uses a
feed-forward net   a suitable choice in our context where sen-
tences are often relatively short and equal in length. also,
generation of lyrics is not typically considered as a response-
selection task but we interpret it as one.

3. anatomy of rap lyrics

in this section, we    rst describe a typical structure of rap
lyrics, as well as di   erent rhyme types that are often used.
this information will be the basis for extracting useful fea-
tures for the next-line prediction problem, which we discuss

in the next section. then we introduce a method for au-
tomatically detecting rhymes, and we de   ne a measure for
rhyme density. we also present experimental results to as-
sess the validity of the rhyme-density measure.
3.1 rhyming

various di   erent rhyme types, such as perfect rhyme, al-
literation, and consonance, are employed in rap lyrics, but
the most common rhyme type nowadays, due to its versa-
tility, is the assonance rhyme [2, 9].
in a perfect rhyme,
the words share exactly the same end sound, as in    slang    
gang,    whereas in an assonance rhyme only the vowel sounds
are shared. for example, words    crazy    and    baby    have dif-
ferent consonant sounds, but the vowel sounds are the same
as can be seen from their phonetic representations    k  eisi   
and    beibi.   

an assonance rhyme does not have to cover only the end
of the rhyming words but it can span multiple words as in
the example below (rhyming part is highlighted). this type
of assonance rhyme is called multisyllabic rhyme.

   this is a job     i get paid to sling some raps,
what you made last year was less than my income tax    [10]

it is stated in [10] that    [multisyllabic rhymes] are hallmarks
of all the dopest    ows, and all the best rappers use them,   
3.2 song structure

a typical rap song follows a pattern of alternating verses
and choruses. these in turn consist of lines, which break
down to individual words and    nally to syllables. a line
equals one musical bar, which typically consists of four beats,
setting limits to how many syllables can be    t into a single
line. verses, which constitute the main body of a song, are
often composed of 16 lines. [9]

consecutive lines can be joined through rhyme, which is
typically placed at the end of the lines but can appear any-
where within the lines. the same end rhyme can be main-
tained for a couple of lines or even throughout an entire
verse. in the verses our algorithm generates, the end rhyme
is kept    xed for four consecutive lines unless otherwise spec-
i   ed by the user (see appendix a for an example).
3.3 automatic rhyme detection

our aim is to automatically detect multisyllabic assonance
rhymes from lyrics given as text. for this, we    rst obtain
a phonetic transcription of the lyrics by applying the text-
to-phonemes functionality of an open source speech synthe-
sizer espeak.2 the synthesizer assumes a typical american   
english pronunciation. from the phonetic transcription, we
can detect rhymes by    nding matching vowel phoneme se-
quences, ignoring consonant phonemes and spaces.
3.3.1 rhyme density measure
in order to quantify the technical quality of lyrics from a
rhyming perspective, we introduce a measure for the rhyme
density of the lyrics. a simpli   ed description3 for the com-
putation of this measure is provided below:

1. compute the phonetic transcription of the lyrics and re-

move all but vowel phonemes.

table 1: a selection of popular rappers and their
rhyme densities, i.e., their average rhyme lengths
per word.

rank artist

rhyme density

1.
2.
3.
30.
31.
32.
33.
39.
40.
50.
63.
77.
78.
94.

inspectah deck
rakim
redrama
the notorious b.i.g.
lil wayne
nicki minaj
2pac
eminem
nas
jay-z
wu-tang clan
snoop dogg
dr. dre
the lonely island

1.187
1.180
1.168
1.059
1.056
1.056
1.054
1.047
1.043
1.026
1.002
0.967
0.966
0.870

2. scan the lyrics word by word.

3. for each word,    nd the longest matching vowel sequence
(=multisyllabic assonance rhyme) in the proximity of the
word.

4. compute the rhyme density by averaging the lengths of

the longest matching vowel sequences of all words.

the rhyme density of an artist is computed as the average
rhyme density of his or her (or its) songs. intuitively speak-
ing, rhyme density means the average length of the longest
rhyme per word.

3.3.2 data
we compiled a list of 104 popular english-speaking rap
artists and scraped all their songs available on a popular
lyrics website. in total, we have 583 669 lines from 10 980
songs.

to make the rhyme densities of di   erent artists compara-
ble, we normalize the lyrics by removing all duplicate lines
within a single song, as in some cases the lyrics contain the
chorus repeated many times, whereas in other cases they
might just have    chorus 4x,    depending on the user who
has provided the lyrics. some songs, like intro tracks, of-
ten contain more regular speech rather than rapping, and
hence, we have removed all songs whose title has one of the
following words:    intro,      outro,      skit,    or    interlude.   

3.3.3 evaluating human rappers    rhyming skills
we initially computed the rhyme density for 94 rappers,
ranked the artists based on this measure, and published the
results online [18]. an excerpt of the results is shown in
table 1.

some of the results are not too surprising; for instance
rakim, who is ranked second, is known for    his pioneering
use of internal rhymes and multisyllabic rhymes.   4 on the
other hand, a limitation of the results is that some artists,
like eminem, who use a lot of multisyllabic rhymes but con-
struct them often by bending words (pronouncing words un-
usually to make them rhyme), are not as high on the list as

2http://espeak.sourceforge.net/
3for the details, see: https://github.com/ekq/raplysaattori

4the wikipedia article on rakim http://en.wikipedia.org/
wiki/rakim (accessed: 2016-02-11)

treat as training data, and which we use to learn a model
between consecutive lines in rap lyrics. then, given a set
of seed lines we can use our model to identify the best next
line among a set of candidate next lines taken from the lyrics
repository. the method can then be used to construct a song
line-by-line, appending relevant lines from di   erent songs.

in order to evaluate this information-retrieval task, we

de   ne the problem of    next-line prediction.   
4.1 problem de   nition

as mentioned above, in the core of our algorithm for gen-
erating rap lyrics is the task of    nding the next line of a
given song. this next line prediction problem is de   ned as
follows.

problem 1. (nextline) consider the lyrics of a rap song
s, which is a sequence of n lines (s1, . . . , sn). assume that
the    rst m lines of s, denoted by b = (s1, . . . , sm), are
known and are considered as    the query.    consider also that
we are given a set of k candidate next lines c = {(cid:96)1, . . . , (cid:96)k},
and the promise that sm+1     c. the goal is to identify sm+1
in the candidate set c, i.e., pick a line (cid:96)i     c such that
(cid:96)i = sm+1.

our approach to solving the nextline problem is to com-
pute a relevance score between the query b and each can-
didate line (cid:96)     c, and return the line that maximizes this
relevance score. the performance of the method can be eval-
uated using standard information retrieval measures, such as
mean reciprocal rank. as the relevance score we use a linear
model over a set of similarity features between the query
song-pre   x b and the candidate next lines (cid:96)     c. the
weights of the linear model are learned using the rankid166
algorithm, described in section 4.3.2.

in the next section, we describe a set of features that we
use for measuring the similarity between the previous lines
b and a candidate next line (cid:96).
4.2 feature extraction

the similarity features we use for the next-line predic-
tion problem can be divided into three groups, capturing (i)
rhyming, (ii) structural similarity, and (iii) semantic simi-
larity.

(i) we extract three di   erent rhyme features based on
the phonetic transcription of the lines, as discussed in sec-
tion 3.3.
endrhyme is the number of matching vowel phonemes at
the end of lines (cid:96) and sm, i.e., the last line of b. spaces
and consonant phonemes are ignored, so for instance, the
following two phrases would have three end rhyme vowels in
common.

line
pay for
stay warm stei wo:  m

phonetic transcription
pei fo:  

endrhyme-1 is the number of matching vowel phonemes at
the end of lines (cid:96) and sm   1, i.e., the line before the last in b.
this feature captures alternating rhyme schemes of the form
   abab.   
otherrhyme is the average number of matching vowel phonemes
per word. for each word in (cid:96), we    nd the longest match-
ing vowel sequence in sm and average the lengths of these
sequences. this captures other than end rhymes.

figure 1: rhyme density distribution of 105 rap-
pers.

table 2: list of rap songs ranked by the algorithm
and by the artist himself according to how technical
he perceives them. correlation is 0.42.

rank by artist rank by algorithm rhyme density

1.
2.

3.   4.
3.   4.

5.

6.   7.
6.   7.
8.   9.
8.   9.
10.
11.

1.
4.
9.
3.
2.
10.
7.
6.
5.
8.
11.

1.542
1.214
0.930
1.492
1.501
0.909
1.047
1.149
1.185
1.009
0.904

one might expect.

in figure 1, we show the distribution of rhyme densities
along with the rhyme density obtained by our lyrics gener-
ator algorithm deepbeat (see section 5.3 for details).
3.4 validating the rhyme density measure

after we had published the results shown in table 1 online,
a rap artist called ahmen contacted us, asking us to compute
the rhyme density for the lyrics of his debut album. before
revealing the rhyme densities of the 11 individual songs he
sent us, we asked the rapper to rank his own lyrics    starting
from the most technical according to where you think you
have used the most and the longest rhymes.    the rankings
produced by the artist and by the algorithm are shown in
table 2.

we can compute the correlation between the artist pro-
duced and algorithm produced rankings by applying the
kendall tau rank correlation coe   cient. assuming that all
ties indicated by the artist are decided unfavorably for the
algorithm, the correlation between the two rankings would
still be 0.42, and the null hypothesis of the rankings being
independent can be rejected (p < 0.05). this suggests that
the rhyme density measure adequately captures the techni-
cal quality of rap lyrics.

4. next line prediction

we approach the problem of rap lyrics generation as an
information-retrieval task. in short, our approach is as fol-
lows: we consider a large repository of rap lyrics, which we

0.911.11.21.31.4051015rhyme density  human rappersdeepbeat generator(ii) with respect to the structural similarity between lines,
we extract one feature measuring the di   erence of the lengths
of the lines.
linelength. typically, consecutive lines are roughly the same
length since they need to be spoken out within one musical
bar of a    xed length. the length similarity of two lines (cid:96)
and s is computed as

1     |len ((cid:96))     len (s)|

max (len ((cid:96)), len (s))

,

where len (  ) is the function that returns the number of char-
acters in a line.5 we compute the length similarity between
a candidate line (cid:96) and the last line sm of the song pre   x b.
(iii) finally, for measuring semantic similarity between

lines, we employ four di   erent features.
bow. first, we tokenize the lines and represent each last
line sm of b as a bag of words sm. we apply the same
procedure and obtain a bag of words l for a candidate line
(cid:96). we then measure semantic similarity between two lines by
computing the jaccard similarity between the corresponding
bags of words

|sm     l|
|sm     l| .

bow5. instead of extracting a bag-of-words representation
from only the last line sm of b, we use the k previous lines.

(cid:12)(cid:12)(cid:12)(cid:16)(cid:83)m
(cid:12)(cid:12)(cid:12)(cid:16)(cid:83)m

j=m   k sj

j=m   k sj

(cid:12)(cid:12)(cid:12)
(cid:17)     l
(cid:12)(cid:12)(cid:12) .
(cid:17)     l

in this way we can incorporate a longer context that could
be relevant with the next line that we want to identify. we
have experimented with various values of k, and we found
out that using the k = 5 previous lines gives the best results.
lsa. bag-of-word models are not able to cope with syn-
onymy nor polysemy. to enhance our model with such ca-
pabilities of use a simple latent semantic analysis (lsa) ap-
proach. as a preprocessing step, we remove stop words and
words that appear less than three times. then we use our
training data to form a line   term matrix and we compute
a rank-100 approximation of this matrix. each line is rep-
resented by a term vector and is projected on the low-rank
matrix space. the lsa similarity between two lines is com-
puted as the cosine similarity of their projected vectors.
nn5. our last semantic feature is based on a neural language
model. it is described in more detail in the next section.
4.3 methods

in this section we present two building blocks of our method:

the neural language model used to incorporate semantic sim-
ilarity with the nn5 feature and the rankid166 method used
to combine the various features.
4.3.1 neural language model
our knowledge of all possible features can never be com-
prehensive, and designing a solid extractor for features such
as semantic or grammatical similarity would be extremely
time-consuming. thus, attempting to learn additional fea-
tures appears a promising approach. since neural networks
5we also tested the number of syllables in a line but the
results were similar.

figure 2: network architecture

can have a vast number of available parameters and can learn
complex nonlinear mappings, we experiment with whether
they could be used to automatically extract relevant fea-
tures. to this end, we design a neural network that learns
to use raw text sequences to predict the relevance of a can-
didate next line given previous lines.

in brief, our neural network starts by    nding distributed
(vector) representations for words. these are combined to
distributed representations of lines, and further combined
to vector representations of multiple lines, where the last
line may be a real line, or a randomly sampled line. based
on this vector representation of text, our network learns to
predict whether it believes that the last line is a suitable
next line candidate or not.

network architecture. at the core of our predictor, we
use multi-layered, fully-connected neural networks, trained
with id26. while the network structure was
originally inspired by the work of collobert et al. [6], our
model di   ers substantially from theirs.
in particular, we
have included new input transformations and our input con-
sists of multiple sentences.

the structure of our model is illustrated in figure 2. we
start by preprocessing all text to a format more easily han-
dled by a neural network, removing most non-ascii charac-
ters and one-word lines, and id30 and lower-casing all
words. our choice of neural network architecture requires

c word-vectors line-vectors lines classification siwn text-vector concatenation ma-transformation legend c c                         siw1         liw1 liwn mlp-layer s softmax s real / random li         fed to the neural model in small batches, and a correspond-
ing id119 update is performed on the weights of
the network. to give our network negative examples, we
follow an approach similar to [6], and generate fake line ex-
amples by choosing for every second example the candidate
line uniformly at random from all lyrics.

a set of technical choices is necessary for constructing and
training our network. we use two word-speci   c neural lay-
ers (500 neurons each), one line-speci   c layer (256 neurons,
and one    nal layer (256 neurons). all layers have recti   ed
linear units as the activation function. our minibatch size is
10, we use the adaptive learning rate adadelta [31], and we
regularize the network with 10% dropout [22]. we train the
network for 20 epochs on a gpu machine, taking advantage
of the theano library [3]. analyzing hyperparameters, we
   nd that we can improve results especially by going from
one previous line to a moderately large context (5 previous
lines), and by using a larger input window, i.e. giving the
network more words from each line.
manual evaluation. to get some understanding of what
our neural network has learnt, we manually analyze 25 ran-
dom sentences where a random candidate line was falsely
classi   ed as being the real next line. for 13 of the lines, we
   nd it di   cult to distinguish whether the real or the random
line should follow. this often relates to the rapper changing
the topic, especially when moving from one verse to another.
for the remaining 12 lines, we notice that the neural net-
work has not succeeded in identifying    ve instances with a
rhyme, three instances with repeating words, two instances
with consistent sentence styles (lines having always e.g., one
sentence per line), one instance with consistent grammar (a
sentence continues to next line), and one instance where the
pronunciation of words is very similar the previous and the
next line. in order to detect the rhymes, the network would
need to learn a phonetic representation of the words, but for
this problem we have developed other features presented in
section 4.2.
4.3.2 ranking candidate lines
we take existing rap lyrics as the ground truth for the
next line prediction problem. the lyrics are transformed
into preferences

sm+1 (cid:31)b (cid:96)i,

which are read as    sm+1 (the true next line) is preferred over
(cid:96)i (a randomly sampled line from the set of all available lines)
in the context of b (the preceding lines)   . when sampling
(cid:54)= sm+1. then we extract features
(cid:96)i we ensure that (cid:96)i
   (b, (cid:96)) listed in section 4.2 to describe the match between
the preceding lines and a candidate next line.

the rankid166 algorithm [14] takes this type of data as
input and tries to learn a linear model which gives relevance
scores for the candidate lines. these relevance scores should
respect the preference relations given as the training data
for the algorithm. the relevance scores are given by

r(b, (cid:96)) = wt    (b, (cid:96)),

(1)

where w is a weight vector of the same length as the number
of features.

the advantage of having a simple linear model is that
it can be trained very e   ciently. we employ the id166rank
software for the learning [15]. furthermore, we can interpret
the weights as importance values for the features. therefore,

figure 3: simpli   ed example of exponential moving-
average transformation

   xed line lengths, so we also remove words exceeding 13
words, and pad shorter lines. we build samples in the for-
mat:    candidate next line ((cid:96)i)   ;    previous lines (s1, . . . , sm).   
for lines with too few previous lines, we add paddings.

the    rst layers of the network are word-speci   c: they
perform the same transformation for each word in a text,
regardless of its position. for each word, we start with
an exponential moving average transformation that turns
a character sequence into a vector. a simpli   ed example of
this is shown in figure 3 .6 we use this transformation as it
is, compared to one-hot encoding, more robust to di   erent
spellings, coping well for instance with slang and spelling
errors.

the transformation works as follows: we create a zero-
vector, with the length of possible characters. starting with
the    rst character in a word, we choose its corresponding
location in the vector. we increment this value with a
value proportional to the character   s position in the word,
counting from the beginning of the word. we get a word-
representation w = (wa wb . . . wz . . .)t , where

(cid:88) (1       )ca

,

z

wa =

where c is the index of the character at hand,    is a decay
hyperparameter, and z is a normalizer proportional to word
length. for further details of this transformation, see [24].

to avoid always giving larger weight to the beginning of a
word, we also concatenate to the vector this transformation
backwards, and a vector of character counts in the word.
following this transformation, we feed each word vector to
a fully-connected neural network.

our word-speci   c vectors are next concatenated in the
word order to a single line-vector, and fed to a line-level
network. next, the line-vectors are concatenated, so that
the candidate next-line is placed    rst, and preceding lines
are then presented in their order of occurrence. this vector
is fed to the    nal layer, and the output is fed to a softmax-
function that outputs a binary prediction indicating whether
it believes one line follows the next or not. in our ensemble
model, we use the activation before the softmax, correspond-
ing to the con   dence the network has in a line being the next
in the lyrics.

training. for training the neural network, we retrieve a list
of previous lines for each of the lyrics lines. these lyrics are

6while we achieve our best results using this transformation,
a traditional    one-hot    vector approach yields nearly as good
results. a model that learns the transformation, such as a
recurrent neural network could also be tested in future work.

a  b  c  d  e  ...     x 0.8    x 0.8 x 0.8    ace    table 3: next line prediction results for k = 300
candidate lines. mrr stands for mean reciprocal
rank and rec@n for recall when retrieving top n
lines.

feature(s)

mean rank mrr rec@1 rec@5 rec@30 rec@150

random
linelength
endrhyme
endrhyme-1
otherrhyme
bow
bow5
lsa
nn5

fastfeats
fastfeatsnn5

all features

150.5
117.6
103.2
126.0
123.3
112.4
99.1
111.3
84.7

73.5
61.2

60.8

0.003
0.002

0.017
0.029

0.010
0.021
0.030
0.177
0.140 0.077 0.181 0.344
0.205
0.075
0.190
0.047
0.116
0.280
0.314
0.110
0.262
0.089
0.067
0.319

0.092
0.055
0.138
0.129
0.107
0.083

0.037
0.016
0.074
0.065
0.051
0.020

0.224
0.272
0.244 0.172 0.306

0.160

0.476
0.524

0.500
0.657
0.480
0.347
0.604
0.516
0.708
0.662
0.793

0.802
0.853

0.243

0.169

0.304

0.527

0.855

when the model is later applied to lyrics generation, the
user could manually adjust the weights, if he or she, for
instance, prefers to have lyrics where the end rhyme plays a
larger/smaller role.
4.4 empirical next line prediction evaluation
our experimental setup is the following. we split the
lyrics by artist randomly into training (50%), validation
(25%), and test (25%). the rankid166 model and the neural
network model are learned using the training set, while vary-
ing a trade-o    parameter c among {1, 101, 102, 103, 104,
105} to    nd the value which maximizes the performance on
the validation set. the    nal performance is evaluated on the
unseen test set.

we use a candidate set containing the true next line and
299 randomly chosen lines. the performance is measured
using mean rank, mean reciprocal rank (reciprocal value of
the harmonic mean of ranks), and recall at n where the
value of n is varied. the results are computed based on a
random sample of 10 000 queries.

table 3 shows the test performance for di   erent feature
sets. each feature alone yields a mean rank of < 150 and
thus carries some predictive power. the best individual fea-
ture with respect to the mean rank is the output of the
neural network model. however, if we look at recall at 1
(the id203 to rank the true next line    rst), the best
performance, 7.7%, is obtained by endrhyme which works
very well in some cases but is in overall inferior to nn5 since
in some cases consecutive lines do not rhyme at all. combin-
ing all features, we achieve a mean rank of 60.8 and can pick
the true next line with 16.9% accuracy. the id203 to
pick the true next line at random is only 0.3%. the features
are combined by taking a linear combination of their values
according to equation (1).

to enable the generation of rap lyrics in real time, we also
tested employing only the features which are fast to evaluate,
i.e., fastfeats = linelength + endrhyme + endrhyme-1 +
bow + bow5, and fastfeatsnn5 = fastfeats + nn5. with
the latter feature set, the performance is almost identical to
using the full feature set and even fastfeats works relatively
well.

algorithm 1: lyrics generation algorithm deepbeat.
input: seed line (cid:96)1, length of the lyrics n.
output: lyrics l = ((cid:96)1, (cid:96)2, . . . , (cid:96)n).
l[1]     (cid:96)1 ;
for i     2 to n do

// initialize a list of lines.

c     retrieve candidates(l[i     1]) ;
  c     n an ;
foreach c     c do

// sec. 5.2.1

/* check relevance and feasibility of the candidate. */
if rel (c, l) > rel (  c, l) & rhyme ok(c, l) then

  c     c;

l[i]       c;

return l;

5. lyrics generation
5.1 overview

the lyrics generation is based on the idea of selecting the
most relevant line given the previous lines, which is repeated
until the whole lyrics have been generated. our algorithm
deepbeat is summarized in algorithm 1.

the relevance scores for candidate lines are computed us-
ing the rankid166 algorithm described in section 4. instead
of selecting the candidate with strictly the highest relevance
score, we    lter some candidates according to rhyme_ok()
function. it checks that consecutive lines are not from the
same song and that they do not end with the same words.
although rhyming the same words can be observed in some
contemporary rap lyrics, it has not always been considered
a valid technique [9]. while it is straightforward to produce
long    rhymes    by repeating the same phrases, it can lead to
uninteresting lyrics.
5.2 online demo

an online demo for the lyrics generation algorithm is avail-
able at deepbeat.org. this web tool was built in order to
(1) make the generator available to the public, (2) provide
the users easy ways of customizing the generated lyrics, and
(3) collect limited usage logs in order to evaluate and im-
prove the algorithm. the website was launched in november
2015 and as of june 2016 it has been visited by more than
42 000 users.

after the initial launch of the project, we started collabo-
rating with some musicians to record the    rst songs written
by deepbeat,7 which showed us the importance of giving the
user su   cient customization capabilities instead of merely
outputting complete lyrics. with this in mind, we designed
the online demo so that users can: (1) de   ne keywords that
must appear in the generated lyrics; (2) ask the algorithm to
give suggestions for the next line and pick the best sugges-
tion manually; and (3) write some of the lines by themselves.
a user can, for example, write the    rst line by herself and let
the algorithm generate the remaining lines. an interesting
mode of usage we noticed some users adopting is to write
every other line by yourself and generate every other.

7the    rst music video is available at:
https://youtu.be/js0hymh31ko
more about the collaboration can be read at:
https://howwegettonext.com/deepbeat-what-happens-
when-a-robot-writes-rhymes-for-rappers-77d07c406   5

when the user generates lyrics line-by-line, asking for sug-
gestions from deepbeat, we log the selected lines. in sec-
tion 5.3.2, we show how to evaluate the algorithm using the
log data. conveniently, we can also use the logs to re   ne the
learned models employing the rankid166 approach as done
in [14].

5.2.1 performance optimization

candidate set retrieval. results in table 3 show that
endrhyme alone is a good predictor. therefore, we de   ne
the set of candidate next lines as the 300 best rhyming lines
instead of 300 random lines. this candidate set has to be
retrieved quickly without evaluating each of the nl = 583 669
lines in our database. conveniently, this can be formulated
as the problem of    nding k strings with the longest common
pre   x with respect to a query string, as follows
1. compute a phonetic transcription for each line.

2. remove all but vowel phonemes.
3. reverse phoneme strings.

we solve the longest common pre   x problem by    rst, sort-
ing the phoneme string as a preprocessing step, second, em-
ploying binary search8 to    nd the line with the longest com-
mon pre   x ((cid:96)long), and third, taking the k     1 lines with
the longest common pre   x around (cid:96)long. the computational
complexity of this approach is o(log nl + k). for the online
demo, we have set k = 300.

feature selection. by default, deepbeat.org employs the
fastfeats feature set by which the generation of an 8-line
verse takes about 0.3 seconds. the user can additionally
enable the nn5 feature in which case the algorithm will re-
trieve the top-30 lines based on fastfeats and then rerank
the top lines based on fastfeatsnn5. we only evaluate 30
lines using nn5 since nn5 is much heavier to compute than
the other features (it increases the generation time to about
35 seconds per 8-line verse) and since recall at 30 is only
3.8 percentage points lower for fastfeats compared to fast-
featsnn5. the nn5 feature could be used more heavily by
acquiring a server which enables gpu computation or via
parallelization (di   erent candidate lines can be evaluated in-
dependently).
5.3 empirical evaluation of generated lyrics

the lyrics generated by deepbeat are evaluated by the
introduced in section 3.3.1, and
rhyme density measure,
by measuring the correlation between relevance scores as-
signed by deepbeat and human preferences recorded via
deepbeat.org.
5.3.1 rhyme density of deepbeat
we ran a single job to generate a hundred 16-bar verses
with random seed lines. a randomly selected example verse
from this set is shown in appendix a. the rhyme density
for the hundred verses is 1.431, which is, quite remarkably,
21% higher than the rhyme density of the top ranked human
rapper, inspectah deck.

one particularly long multisyllabic rhyme created by the

algorithm is given below (the rhyming part is highlighted)

8the candidate set could be found even faster by building a
trie data structure of the phoneme strings. however, in our
experiments, the binary search approach was fast enough
and more memory-e   cient.

   drink and drown in my own iniquity

never smile style is wild only grin strictly   

in this example, the    rst line is from the song rap game
by d-12 and the latter from i don   t give a f**k by az. the
rhyme consists of nine consecutive matching vowel phonemes.
5.3.2 online experiment
in order to evaluate the algorithm, we performed an online
experiment using the demo. the idea was to employ an
approach which is used for optimizing search engines [14]
where the clicked search result ri is logged and the following
pairwise preferences are extracted: ri (cid:31) rj, j = 1, . . . , i     1
(the lines below the selected line are ignored since we cannot
assume that the user has evaluated those). the objective is
to learn a ranking model which assigns relevance scores that
agree with the extracted preferences.

at deepbeat.org, when a user clicks    suggest rhyming
line    button, 20 suggested candidate next lines are shown
to the user. we wanted to see how often the line selected by
the user was assigned a higher score than the lines above the
selection. our hypothesis was that the larger the absolute
di   erence between the algorithm-assigned relevance scores
of two lines was, the more likely the user would pick the line
preferred by the algorithm.

in the initial data we collected through the website, we
noticed that users are more likely to select a line the higher
it appears on the list of suggestions. furthermore, the users
tend to prefer the    fth line since it often appears in the
same location of the screen as the    suggest rhyming line   
button, so if a user is just playing around with the tool with-
out putting much thought to the content of the suggestions,
the user is likely to select the    fth suggestion.
it is very
challenging to get rid of this type of biases entirely when
conducting an uncontrolled experiment in the wild but to
mitigate the biases, we shu   ed the order of the suggested
lines and removed the    rst three selections of each user since
we assumed that in the beginning users are more likely to
play with the tool without thinking too much. moreover, we
wanted to create more variability among the suggestions, as
the top 30 might be almost equally good, so we de   ned the
set of suggested lines as the lines ranked: 1   14., 298   300.,
and three randomly picked lines from range 15   297.

to avoid degrading the usability of the tool too much, we
only applied the aforementioned manipulations when nn5
was not enabled by the user. however, we also stored the
text of the selected line and the previous lines to enable the
computation of the relevance scores with fastfeatsnn5 as a
post-processing step. in total, this experiment resulted in
34 757 pairwise preferences from 1 549 users.9

the results of the experiment are shown in figure 4. they
con   rm our hypothesis that the higher the di   erence be-
tween the relevance scores of two lines the more likely the
users select the line which is evaluated more suitable by
the algorithm. furthermore, including the nn5 feature im-
proves the evaluations, which can be seen by studying the
di   erence of the two data series in the    gure. we may con-
clude that the learned rankid166 model generalizes and is
able to successfully learn human preferences from existing
rap lyrics, and that the developed deep neural network is an
important component of the model.
9an anonymized version of the dataset including the scores
assigned by deepbeat is available at:
https://github.com/ekq/dopelearning

tion which could carry signi   cant business potential when
applied to tasks like customer service automation.

7. conclusions

we developed deepbeat, an algorithm for rap lyrics gen-
eration. lyrics generation was formulated as an information
retrieval task where the objective is to    nd the most rele-
vant next line given the previous lines which are considered
as the query. the algorithm extracts three types of features
of the lyrics   rhyme, structural, and semantic features   and
combines them by employing the rankid166 algorithm. for
the semantic features, we developed a deep neural network
model, which was the single best predictor for the relevance
of a line.

we quantitatively evaluated the algorithm with three mea-
sures. first, we evaluated prediction performance by mea-
suring how well the algorithm predicts the next line of an
existing rap song. the true next line was identi   ed among
299 randomly selected lines with an accuracy of 17%, i.e.,
over 50 times more likely than by random, and it was ranked
in the top 30 with 53% accuracy. second, we introduced a
rhyme density measure and showed that deepbeat outper-
forms the top human rappers by 21% in terms of length and
frequency of the rhymes in the produced lyrics. the validity
of the rhyme density measure was assessed by conducting
a human experiment which showed that the measure corre-
lates with a rapper   s own notion of technically skilled lyrics.
third, the rap lyrics generator was deployed as a web tool
(deepbeat.org) and the analysis of its usage logs showed
that machine evaluations of candidate next lines correlate
with user preferences.

acknowledgments
we would like to thank stephen fenech for developing the
front end for deepbeat.org and jelena luketina, miquel
perell  o nieto, and vikram kamath for useful comments on
the manuscript.

8. references
[1] y. bengio, i. j. goodfellow, and a. courville. deep
learning. book in preparation for mit press, 2015.

[2] d. berger. rap genius university: rhyme types.

http://genius.com/posts/
24-rap-genius-university-rhyme-types. accessed:
2015-05-07.

[3] j. bergstra, o. breuleux, f. bastien, p. lamblin,

r. pascanu, g. desjardins, j. turian,
d. warde-farley, and y. bengio. theano: a cpu and
gpu math expression compiler. proceedings of the
python for scienti   c computing conference (scipy),
2010.

[4] m. a. boden. the creative mind: myths and

mechanisms. psychology press, 2004.

[5] a. bradley. book of rhymes: the poetics of hip hop.

basic books, 2009.

[6] r. collobert, j. weston, l. bottou, m. karlen,

k. kavukcuoglu, and p. kuksa. natural language
processing (almost) from scratch. journal of machine
learning research, 12:2493   2537, 2011.

[7] s. colton and g. a. wiggins. computational

creativity: the    nal frontier? in proceedings of the

figure 4: id203 of a deepbeat.org user to select
a line with a higher score from a pair of lines given
the (binned) score di   erence of the lines. user pref-
erences correlate with the scores assigned by deep-
beat.

6. discussion

according to boden [4], creativity is the ability to come
up with ideas or artifacts that are (1) new, (2) surprising,
and (3) valuable. here, produced lyrics as a whole are novel
by construction as the lines of the lyrics are picked from
di   erent original lyrics, even if individual lines are not novel.
lyrics produced with our method are likely to be at least as
surprising as the original lyrics.

the (aesthetic) value of rap lyrics is more di   cult to esti-
mate objectively. obvious factors contributing to the value
are poetic properties of the lyrics, especially its rhythm and
rhyme, quality of the language, and the meaning or message
of the lyrics. rhyme and rhythm can be controlled with rel-
ative ease, even outperforming human rappers, as we have
demonstrated in our experiments. the quality of individual
lines is exactly as good as the dataset used.

the meaning or semantics is the hardest part for compu-
tational generation. we have applied standard bag-of-words
and lsa methods and additionally introduced a deep neu-
ral network model in order to capture the semantics of the
lyrics. the importance of these features has been proven by
the experimental results for the next line prediction problem
and an online experiment. the features together contribute
towards the semantic coherence of the produced lyrics even
if full control over the meaning is still missing.

the task of predicting the next line can be challenging
even for a human, and our model performs relatively well on
this task. we have used our models for lyrics prediction, but
we see that components that understand semantics could be
very relevant also to other text processing tasks, for instance
conversation prediction.

this work opens several lines for future work. it would
be interesting to study automatic creation of story lines by
analyzing existing rap songs and of novel lines by modi-
fying existing lines or creating them from scratch. even
more, it would be exciting to have a fully automatic rap
bot which would generate lyrics and rap them synthetically
based on some input it receives from the outside world. al-
ternatively, the    ndings of this paper could be transferred
to other text processing tasks, such as conversation predic-

0-0.50.5-11-1.51.5-22-2.52.5-33-3.53.5-44-4.54.5-55-5.5score(line1) - score(line2)0.500.550.600.650.70id203 to select line1deepbeatdeepbeat without nneuropean conference on arti   cial intelligence, pages
21   26, 2012.

[8] l. deng. an overview of deep-structured learning for

information processing. in proceedings of
asian-paci   c signal & information processing annual
summit and conference, pages 1   14, october 2011.
[9] p. edwards. how to rap: the art and science of the

hip   hop mc. chicago review press, 2009.

languages. in proceedings of european symposium on
arti   cial neural networks, computational intelligence
and machine learning, 2016.

[25] j. m. toivanen, h. toivonen, a. valitutti, and

o. gross. corpus-based generation of content and
form in poetry. in proceedings of the third
international conference on computational creativity,
pages 175   179, 2012.

[10] flocabulary. how to write rap lyrics and improve your

[26] t. veale. creative language retrieval: a robust hybrid

rap skills. https://www.   ocabulary.com/multies/.
accessed: 2015-05-07.

[11] a. graves. generating sequences with recurrent neural

networks. in arxiv preprint, arxiv:1308.0850, 2013.
[12] h. hirjee and d. g. brown. automatic detection of

internal and imperfect rhymes in rap lyrics. in
proceedings of the tenth international society for
music information retrieval conference, pages
711   716, 2009.

[13] h. hirjee and d. g. brown. using automated rhyme
detection to characterize rhyming style in rap music.
2010.

[14] t. joachims. optimizing search engines using

clickthrough data. in proceedings of the 8th acm
sigkdd international conference on knowledge
discovery and data mining, pages 133   142, 2002.

[15] t. joachims. training linear id166s in linear time. in
proceedings of the 12th acm sigkdd international
conference on knowledge discovery and data mining,
pages 217   226, 2006.

[16] k. lenzo. the cmu pronouncing dictionary.

http://www.speech.cs.cmu.edu/cgi-bin/cmudict.
accessed: 2015-05-07.

[17] t.-y. liu. learning to rank for information retrieval.

foundations and trends in information retrieval,
3(3):225   331, 2009.

[18] e. malmi. algorithm that counts rap rhymes and

scouts mad lines.
http://mining4meaning.com/2015/02/13/raplyzer/,
2015. blog post.

[19] t. mikolov, i. sutskever, k. chen, g. s. corrado, and

j. dean. distributed representations of words and
phrases and their compositionality. in advances in
neural information processing systems, pages
3111   3119, 2013.

[20] j. pennington, r. socher, and c. d. manning. glove:
global vectors for word representation. proceedings of
the empiricial methods in natural language
processing, 12, 2014.

[21] m. richardson, a. prakash, and e. brill. beyond
id95: machine learning for static ranking. in
proceedings of the 15th international conference on
world wide web, pages 707   715. acm, 2006.

[22] n. srivastava, g. hinton, a. krizhevsky, i. sutskever,

and r. salakhutdinov. dropout: a simple way to
prevent neural networks from over   tting. journal of
machine learning research, 15:1929   1958, 2014.

[23] i. sutskever, j. martens, and g. hinton. generating

text with recurrent neural networks. in proceedings of
the 28th international conference on machine
learning, pages 1017   1024. acm, 2011.

[24] p. takala. id27s for morphologically rich

of information retrieval and linguistic creativity. in
proceedings of the 49th annual meeting of the
association for computational linguistics: human
language technologies   volume 1, pages 278   287.
association for computational linguistics, 2011.

[27] o. vinyals and q. le. a neural conversational model.

in proceedings of icml deep learning workshop,
2015.

[28] d. wu and k. addanki. learning to rap battle with
bilingual id56s. in proceedings of
the 24th international conference on arti   cial
intelligence, pages 2524   2530, 2015.

[29] d. wu, v. s. k. addanki, m. s. saers, and
m. beloucif. learning to freestyle: hip hop
challenge-response induction via transduction rule
segmentation. in proceedings of the empirical methods
in natural language processing conference, pages
102   112, 2013.

[30] l. yu, k. m. hermann, p. blunsom, and s. pulman.

deep learning for answer sentence selection. in
proceedings of nips deep learning workshop, 2014.

[31] m. d. zeiler. adadelta: an adaptive learning rate

method. technical report, 2012.

appendix
a. sample verses

table 4 shows an example of a generated verse.

it was
randomly selected from a set of a hundred verses, exclud-
ing the verses with profane language. the other verses are
available at: https://github.com/ekq/dopelearning

table 4: a randomly selected verse from the set of
100 generated lyrics.

everybody got one
and all the pretty mommies want some
and what i told you all was
but you need to stay such do not touch

(2 chainz - extremely blessed)

(mos def - undeniable)

(lil wayne - welcome back)

(common - heidi hoe)

they really do not want you to vote
what do you condone
music make you lose control
what you need is right here ahh oh

(krs one - the mind)

(cam   ron - bubble music)

(missy elliot - lose control)

(wiz khalifa - right here)

this is for you and me
i had to dedicate this song to you mami
now i see how you can be
i see u smiling i kno u hattig

best i eva had x4
that i had to pay for
do i have the right to take yours
trying to stay warm

(missy elliot - hit em wit da hee)

(fat joe - bendicion mami)

(lil wayne - how to hate)

(wiz khalifa - damn thing)

(nicki minaj - best i ever had)

(ice cube - x bitches)

(common - retrospect for life)

(everlast - 2 pieces of drama)

