comparing convolutional neural networks

to traditional models for slot filling

heike adel and benjamin roth and hinrich sch  utze
center for information and language processing (cis)

lmu munich

oettingenstr. 67, 80538 munich, germany

6
1
0
2

 
r
p
a
4

 

 
 
]
l
c
.
s
c
[
 
 

2
v
7
5
1
5
0

.

3
0
6
1
:
v
i
x
r
a

heike@cis.lmu.de

abstract

we address relation classi   cation in the con-
text of slot    lling, the task of    nding and eval-
uating    llers like    steve jobs    for the slot x
in    x founded apple   . we propose a convo-
lutional neural network which splits the input
sentence into three parts according to the re-
lation arguments and compare it to state-of-
the-art and traditional approaches of relation
classi   cation. finally, we combine different
methods and show that the combination is bet-
ter than individual approaches. we also ana-
lyze the effect of genre differences on perfor-
mance.

1

introduction

structured knowledge about the world is useful for
many natural language processing (nlp) tasks, such
as disambiguation, id53 or semantic
search. however, the extraction of structured infor-
mation from natural language text is challenging be-
cause one relation can be expressed in many differ-
ent ways. the tac slot filling (sf) shared task
de   nes slot    lling as extracting    llers for a set of
prede   ned relations (   slots   ) from a large corpus of
text data. exemplary relations are the city of birth
of a person or the employees or founders of a com-
pany. participants are provided with an evaluation
corpus and a query    le consisting of pairs of enti-
ties and slots. for each entity slot pair (e.g.    ap-
ple    and    founded by   ), the systems have to return
the second argument (      ller   ) of the relation (e.g.
   steve jobs   ) as well as a supporting sentence from
the evaluation corpus. the key challenge in slot

   lling is relation classi   cation: given a sentence s
of the evaluation corpus containing the name of a
queried entity (e.g.,    apple   ) and a    ller candidate
(e.g.,    steve jobs   ), we need to decide whether s ex-
presses the relation (   founded by   , in this case). we
will refer to the mentions of the two arguments of
the relation as name and    ller. performance on re-
lation classi   cation is crucial for slot    lling since its
effectiveness directly depends on it.

in this paper, we investigate three complementary

approaches to relation classi   cation.

the    rst approach is pattern matching, a leading
approach in the tac evaluations. fillers are vali-
dated based on patterns. in this work, we consider
patterns learned with distant supervision and pat-
terns extracted from universal schema relations.

the second approach is support vector machines.
we evaluate two different feature sets: a bag-of-
word feature set (bow) and more sophisticated skip
id165 features.

our third approach is a convolutional neural net-
work (id98). id98s have been applied to nlp tasks
like id31, part-of-speech tagging and
id14. they can recognize phrase
patterns independent of their position in the sen-
tence. furthermore, they make use of word embed-
dings that directly re   ect word similarity (mikolov
et al., 2013). hence, we expect them to be ro-
bust models for the task of classifying    ller candi-
dates and to generalize well to unseen test data. in
this work, we train different variants of id98s: as
a baseline, we reimplement the recently developed
piecewise id98 (zeng et al., 2015). then, we ex-
tend this model by splitting the contexts not only for

currently,

pooling but also for convolution (contextwise id98).
there is no benchmark for slot    ll-
ing. therefore, it is not possible to directly com-
pare results that were submitted to the shared task
to new results. comparable manual annotations for
new results, for instance, cannot be easily obtained.
there are also many different system components,
such as document retrieval from the evaluation cor-
pus and coreference resolution, that affect shared
task performance and that are quite different in na-
ture from relation classi   cation. even in the sub-
task of relation classi   cation, it is not possible to
directly use existing relation classi   cation bench-
marks (e.g. riedel et al. (2013), hendrickx et al.
(2010)) since data and relations can be quite differ-
ent. many benchmark relations, for instance, corre-
spond to freebase relations but not all slots are mod-
eled in freebase and some slots even comprise more
than one freebase relation. while most relation clas-
si   cation benchmarks either use newswire or web
data, the sf task includes documents from both do-
mains (and discussion fora). another difference to
traditional relation classi   cation benchmarks arises
from the pipeline aspect of slot    lling. depending
on the previous steps, the input for the relation clas-
si   cation models can be incomplete, noisy, include
coreferent mentions, etc.

the of   cial sf shared task evaluations only as-
sess whole systems (with potential subsequent faults
in their pipelines (pink et al., 2014)). thus, we ex-
pect component wise comparisons to be a valuable
addition to the shared task: with comparisons of
single components, teams would be able to improve
their modules more speci   cally. to start with one
of the most important components, we have created
a benchmark for slot    lling relation classi   cation,
based on 2012     2014 tac shared task data.
it
will be described below and published along with
this paper.1 in addition to presenting model results
on this benchmark dataset, we also show that these
results correlate with end-to-end sf results. hence,
optimizing a model on this dataset will also help im-
proving results in the end-to-end setting.

in our experiments, we found that our models suf-
fer from large genre differences in the tac data.
hence, the sf shared task is a task that con   ates an

1http://cistern.cis.lmu.de

investigation of domain (or genre) adaptation with
the one of slot    lling. we argue that both problems
are important nlp problems and provide datasets
and results for both within and across genres. we
hope that this new resource will encourage others
to test their models on our dataset and that this will
help promote research on slot    lling.

in summary, our contributions are as follows.
(i) we investigate the complementary strengths and
weaknesses of different approaches to relation clas-
si   cation and show that their combination can better
deal with a diverse set of problems that slot    lling
poses than each of the approaches individually. (ii)
we propose to split the context at the relation ar-
guments before passing it to the id98 in order to
better deal with the special characteristics of a sen-
tence in relation classi   cation. this outperforms the
state-of-the-art piecewise id98. (iii) we analyze the
effect of genre on slot    lling and show that it is an
important con   ating variable that needs to be care-
fully examined in research on slot    lling. (iv) we
provide a benchmark for slot    lling relation classi   -
cation that will facilitate direct comparisons of mod-
els in the future and show that results on this dataset
are correlated with end-to-end system results.

section 2 gives an overview of related work. sec-
tion 3 discusses the challenges that slot    lling sys-
tems face. in section 4, we describe our slot    lling
models. section 5 presents experimental setup and
results. section 6 analyzes the results. we present
our conclusions in section 7 and describe the re-
sources we publish in section 8.

2 related work

slot    lling. the participants of the sf shared task
(surdeanu, 2013) are provided with a large text cor-
pus. for evaluation, they get a collection of queries
and need to provide    llers for prede   ned relations
and an offset of a context which can serve as a justi-
   cation. most participants apply pipeline based sys-
tems. pink et al. (2014) analyzed sources of recall
losses in these pipelines. the results of the systems
show the dif   culty of the task: in the 2014 evalua-
tion, the top-ranked system had an f1 of .37 (angeli
et al., 2014a). to train their models, most groups use
distant supervision (mintz et al., 2009). the top-
ranked systems apply machine learning based ap-

proaches rather than manually developed patterns or
models (surdeanu and ji, 2014). the methods for
extracting and scoring candidates range from pat-
tern based approaches (gonz`alez et al., 2012; liu
and zhao, 2012; li et al., 2012; qiu et al., 2012;
roth et al., 2014) over rule based systems (varma
et al., 2012) to classi   ers (malon et al., 2012; roth
et al., 2013). the top ranked system from 2013
used id166s and patterns for evaluating    ller candi-
dates (roth et al., 2013); their results suggest that
id165 based features are suf   cient to build reli-
able classi   ers for the relation classi   cation module.
they also show that id166s outperform patterns.

id98s for relation classi   cation. zeng et al.
(2014) and dos santos et al. (2015) apply id98s to
the relation classi   cation semeval shared task data
from 2010 and show that id98s outperform other
models. we train id98s on noisy distant supervised
data since (in contrast to the semeval shared task)
clean training sets are not available. malon et al.
(2012) describe a id98 for slot    lling that is based
on the output of a parser. we plan to explore pars-
ing for creating a more linguistically motivated input
representation in the future.

baseline models. in this paper, we will compare
our methods against traditional relation classi   ca-
tion models: mintz++ (mintz et al., 2009; surdeanu
et al., 2012) and mimlre (surdeanu et al., 2012).
mintz++ is a model based on the mintz features (lex-
ical and syntactic features for id36). it
was developed by surdeanu et al. (2012) and used
as a baseline model by them. mimlre is a graph-
ical model designed to cope with multiple instances
and multiple labels in distant supervised data. it is
trained with expectation maximization.

another baseline model which we use in this work
is a piecewise convolutional neural network (zeng
et al., 2015). this recently published network is de-
signed especially for the relation classi   cation task
which allows to split the context into three parts
around the two relation arguments. while it uses
the whole context for convolution, it performs max
pooling over the three parts individually. in contrast,
we propose to split the context even earlier and ap-
ply the convolutional    lters to each part separately.
genre dependency. there are many studies
showing the genre dependency of machine learn-
ing models. in 2012, the sancl shared task fo-

cused on evaluating models on web data that have
been trained on news data (petrov and mcdonald,
2012). the results show that id52 perfor-
mance can decline a lot when the genre is changed.
for other nlp tasks like machine translation or sen-
timent analysis, this is also a well-known challenge
and id20 has been extensively stud-
ied (glorot et al., 2011; foster and kuhn, 2007).
we do not investigate id20 per se, but
show that the genre composition of the slot    lling
source corpus poses challenges to genre independent
models.

3 challenges of slot filling

slot    lling includes nlp challenges of various na-
tures. given a large evaluation corpus, systems    rst
need to    nd documents relevant to the entity of
the query. this involves challenges like alternate
names for the same entity, misspellings of names
and ambiguous names (different entities with the
same name). then for each relevant document, sen-
tences with mentions of the entity need to be ex-
tracted, as well as possible    llers for the given slot.
in most cases, coreference resolution and named en-
tity recognition tools are used for these tasks. fi-
nally, the systems need to decide which    ller candi-
date to output as the solution for the given slot. this
step can be reduced to relation classi   cation. it is
one of the most crucial parts of the whole pipeline
since it directly in   uences the quality of the    nal
output. the most important challenges for rela-
tion classi   cation for slot    lling are little or noisy
(distant supervised) training data, data from differ-
ent domains and test sentences which have been ex-
tracted with a pipeline of different nlp components.
thus, their quality directly depends on the perfor-
mance of the whole pipeline. if, for example, sen-
tence splitting fails, the input can be incomplete or
too long.
if coreference resolution or named en-
tity recognition fails, the relation arguments can be
wrong or incomplete.

4 models for relation classi   cation
patterns. the    rst approach we evaluate for rela-
tion classi   cation is pattern matching. for a given
sentence, the pattern matcher classi   es the relation
as correct if one of the patterns matches; otherwise

in particular, we apply
the candidate is rejected.
two different pattern sets: the    rst set consists of
patterns learned using distant supervision (patdist).
they have been used in the sf challenge by the top-
ranked system in the 2013 shared task (roth et al.,
2013). the second set contains patterns from univer-
sal schema relations for the sf task (patuschema).
universal schema relations are extracted based on
id105 (riedel et al., 2013).
in this
work, we apply the universal schema patterns ex-
tracted for slot    lling by roth et al. (2014).

support vector machines (id166s). our sec-
ond approach is support vector machines. we eval-
uate two different feature sets: bag-of-word fea-
tures (id166bow) and skip id165 features (id166-
skip). based on the results of roth et al. (2013), we
will not use additional syntactic or semantic features
for our classi   ers. for id166bow, the representation
of a sentence consists of a    ag and four bag-of-word
vectors. let m1 and m2 be the mentions of name
and    ller (or    ller and name) in the sentence, with
m1 occurring before m2. the binary    ag indicates
in which order name and    ller occur. the four bow
vectors contain the words in the sentence to the left
of m1, between m1 and m2, to the right of m2 and
all words of the sentence. for id166skip, we use the
previously described bow features and additionally
a feature vector which contains skip id165 features.
they wildcard tokens in the middle of the id165
(cf. roth et al. (2013)). in particular, we use skip
3-grams, skip 4-grams and skip 5-grams. a possi-
ble skip 4-gram of the context    , founder and direc-
tor of   , for example, would be the string    founder
of   , a pattern that could not have been directly ex-
tracted from this context otherwise. we train one
linear id166 (fan et al., 2008) for each relation and
feature set and tune parameter c on dev.

convolutional neural networks (id98s). id98s
are increasingly applied in nlp (collobert et al.,
2011; kalchbrenner et al., 2014). they extract n-
gram based features independent of the position in
the sentence and create (sub-)sentence representa-
tions. the two most important aspects that make this
possible are convolution and pooling. max pooling
(collobert et al., 2011) detects the globally most rel-
evant features obtained by local convolution.

another promising aspect of id98s for relation
classi   cation is that they use an embedding based in-

put representation. with id27s, similar
words are represented by similar vectors and, thus,
we can recognize (near-)synonyms     synonyms of
relation triggers as well as of other important con-
text words.
if the id98 has learned, for example,
that the context    is based in    triggers the relation lo-
cation of headquarters and that    based    has a simi-
lar vector representation as    located   , it may recog-
nize the context    is located in    correctly as another
trigger for the same relation even if it has never seen
it during training. in the following paragraphs, we
describe the different variants of id98s which we
evaluate in this paper. for each variant, we train
one binary id98 per slot and optimize the number
of    lters (    {300, 1000, 3000}), the size of the hid-
den layer (    {100, 300, 1000}) and the    lter width
(    {3, 5}) on dev. we use id97 (mikolov et al.,
2013) to pre-train id27s (dimensionality
d = 50) on a may-2014 english wikipedia corpus.
piecewise id98. our baseline id98 is the model
developed by zeng et al. (2015). it represents the
input sentence by a matrix of word vectors, applies
several    lters for convolution and then divides the
resulting id165 representation into left, middle and
right context based on the positions m1 and m2 of
name and    ller (see id166 description). for each of
the three parts, one max value is extracted by pool-
ing. the results are passed to a softmax classi   er.

contextwise id98. in contrast to the piecewise
id98, we propose to split the context before con-
volution as shown in figure 1. hence, similar to
our bow vectors for the id166, we split the origi-
nal context words into left, middle and right context.
then, we apply convolution and pooling to each of
the contexts separately. in contrast to the piecewise
id98, there is no convolution across relation argu-
ments. thus, the network learns to focus on the con-
text words and cannot be distracted by the presence
of (always present) relation arguments. the    lter
weights w are shared for the three contexts. our in-
tuition is that the most important sequence features
we want to extract by convolution can appear in two
or three of the regions. weight sharing also reduces
the number of parameters and increases robustness.
we also found in initial experiments that sharing    l-
ter weights across left, middle, right outperformed
not sharing weights. the results of convolution are
pooled using k-max pooling (kalchbrenner et al.,

ear combination of the scores of the models:

(cid:88)

qcmb =

  mqm

m=1...m

where qm is the score of model m and   m is its
weight (optimized on dev using grid search). all
weights sum to 1.

for a comparison of different combination possi-
bilities, see, for example, (viswanathan et al., 2015).

5 experiments and results
5.1 training data
we used distant supervision for generating training
data. we created a set of (subject, relation, object)
tuples by querying freebase (bollacker et al., 2008)
for relations that correspond to the slot relations.
then we scanned the following corpora for sen-
tences containing both arguments of a relation in the
tuple set: (i) the tac source corpus (tac, 2014), (ii)
a snapshot of wikipedia (may 2014), (iii) the free-
base description    elds, (iv) a subset of clueweb2,
(v) a new york times corpus (ldc2008t19). the
resulting sentences are positive training examples.
based on the tuple set, we selected negative exam-
ples by scanning the corpora for sentences that (i)
contain a mention of a name occurring in a tuple,
(ii) do not contain the correct    ller, (iii) contain a
mention different from the correct    ller, but with the
same named entity type (based on corenlp ner
(manning et al., 2014)). all negative examples for
date slots, for instance, are sentences containing an
incorrect date.

this procedure gave us a large but noisy train-
ing set for most slots.
in order to reduce incor-
rect labels, we applied a self-training procedure: we
trained id166s on the sf dataset created by angeli
et al. (2014b). with the resulting id166s, we pre-
dicted labels for our training set.
if the predicted
label did not match the distant supervised label, we
deleted the corresponding training example (min et
al., 2012). this procedure was conducted in sev-
eral iterations on different chunks of the training set.
finally, the sf dataset and the    ltered training ex-
amples were merged. (we do not use the sf dataset
directly because (i) it provides few examples per slot

2http://lemurproject.org/clueweb12

figure 1: contextwise id98 for relation classi   cation

2014): only the k = 3 maximum values of each
   lter application are kept. the pooling results are
then concatenated to a single vector and extended
by a    ag indicating whether the name or the    ller
appeared    rst in the sentence.

in initial experiments, we found that a fully con-
nected hidden layer after convolution and pooling
leads to a more powerful model. it connects the rep-
resentations of the three contexts and, thus, can draw
conclusions based on cooccurring patterns across
contexts. therefore, the result vector after convolu-
tion and pooling is fed into a fully connected hidden
layer. a softmax layer makes the    nal decision.

for a fair comparison of models, we also add a
hidden layer to the piecewise id98 and apply k-
max pooling there as well. thus, the number of pa-
rameters to learn is the same for both models. we
call this model id98pieceext. the key difference
between id98pieceext and id98context is the time
when the context is split into three parts: before or
after convolution. this affects the windows of words
to which the convolutional    lters are applied.

model combination (cmb). to combine a set m
of models for classi   cation, we perform a simple lin-

 w1   w2        wc-1 wc  <> wc+1  wc+2      w2c-1 w2c <> w2c+1w2c+2     w3c-1w3c wordvector, case indicatork-max poolingk-max poolingk-max pooling* w* w* wflattenflattenflatten0 | 1softmaxfully connected mlpnh hidden unitsleft contextmiddle contextright context1/0concatinput sentencesplit at relation arguments(min: 1, max: 4960) and (ii) it consists of exam-
ples for which the classi   ers of angeli et al. (2014b)
were indecisive, i.e., presumably contexts that are
hard to classify.) since their contexts are similar, we
also merged city, state-or-province and country slots
to one location slot.

5.2 evaluation data
one of the main challenges in building and evaluat-
ing relation classi   cation models for sf is the short-
age of training and evaluation data. each group has
their own datasets and comparisons across groups
are dif   cult. therefore, we have developed a script
that creates a clean dataset based on manually an-
notated system outputs from previous shared task
evaluations. in the future, it can be used by all par-
ticipants to evaluate components of their slot    lling
systems.3 the script only extracts sentences that
contain mentions of both name and    ller.
it con-
ducts a heuristic check based on ner tags to de-
termine whether the name in the sentence is a valid
mention of the query name or is referring to another
entity. in the latter case, the example is    ltered out.
one dif   culty is that many published offsets are in-
correct. we tried to match these using heuristics. in
general, we apply    lters that ensure high quality of
the resulting evaluation data even if that means that
a considerable part of the tac system output is dis-
carded.
in total, we extracted 39,386 high-quality
evaluation instances out of the 59,755 system output
instances published by tac and annotated as either
completely correct or completely incorrect.

a table in the supplementary material4 gives
statistics: the number of positive and negative exam-
ples per slot and year (without duplicates). for 2013,
the most examples were extracted. the lower num-
ber for 2014 is probably due to the newly introduced
id136 across documents. this limits the number
of sentences with mentions of both name and    ller.
the average ratio of positive to negative examples is
1:4. the number of positive examples per slot and
year ranges from 0 (org:member of, 2014) to 581
(per:title, 2013), the number of negative examples
from 5 (org:website, 2014) to 1886 (per:title, 2013).

3http://cistern.cis.lmu.de. we publish scripts

since we cannot distribute data.

4also available at http://cistern.cis.lmu.de

in contrast to other relation classi   cation bench-
marks, this dataset is not based on a knowledge
base (such as freebase) and unrelated text (such as
web documents) but directly on the sf assessments.
thus, it includes exactly the sf relations and ad-
dresses the challenges of the end-to-end task: noisy
data, possibly incomplete extractions of sentences
and data from different domains.

we use the data from 2012/2013 as development

and the data from 2014 as evaluation set.

5.3 experiments
we evaluate the models described in section 4, se-
lect the best models and combine them.

experiments with patterns. first, we compare
the performance of patdist and patuschema on our
dataset. we evaluate the pattern matchers on all slots
presented in table 1 and calculate their average f1
scores on dev. patdist achieves a score of .35, pat-
uschema of .33. since it performs better, we use
patdist in the following experiments.

experiments with id166s. second, we train and
evaluate id166bow and id166skip. average f1 of
id166skip and id166bow are .62 and .59, respec-
tively. thus, we use id166skip. we expected that
id166skip beats id166bow due to its richer feature
set, but id166bow performs surprisingly well.

experiments with id98s. finally, we compare
the performance of id98piece, id98pieceext and
id98context. while the baseline network id98-
piece (zeng et al., 2015) achieves f1 of .52 on dev,
id98pieceext has an f1 score of .55 and id98con-
text an f1 of .60. the difference of id98piece and
id98pieceext is due to the additional hidden layer
and k-max pooling. the considerable difference
in performance of id98pieceext and id98context
shows that splitting the context for convolution has
a positive effect on the performance of the network.
overall results. table 1 shows the slot wise re-
sults of the best patterns (patdist), id166s (id166-
skip) and id98s (id98context). furthermore,
it
provides a comparison with two baseline models:
mintz++ and mimlre. id166 and id98 clearly out-
perform these baselines. they also outperform pat
for almost all slots. the difference between dev and
eval results varies a lot among the slots. we suspect
that this is a result of genre differences in the data
and analyze this in section 6.4.

per:age
per:alternate names
per:children
per:cause of death
per:date of birth
per:date of death
per:empl memb of
per:location of birth
per:loc of death
per:loc of residence
per:origin
per:parents
per:schools att
per:siblings
per:spouse
per:title
org:alternate names
org:date founded
org:founded by
org:loc of headqu
org:members
org:parents
org:subsidiaries
org:top memb empl
average

mintz++ mimlre
eval
dev
.73
.84
.03
.29
.76
.48
.36
.76
1.0
.60
.45
.67
.37
.38
.56
.22
.43
.65
.18
.14
.46
.40
.64
.65
.75
.75
.66
.59
.27
.58
.49
.40
.48
.49
.73
.41
.65
.60
.13
.20
.16
.58
.17
.32
.35
.32
.35
.46
.42
.53

eval
.71
.03
.43
.42
.60
.45
.36
.22
.41
.11
.48
.59
.78
.59
.23
.39
.46
.71
.62
.19
.06
.14
.43
.44
.41

dev
.83
.29
.77
.75
.99
.67
.41
.56
.66
.15
.42
.68
.76
.64
.59
.49
.50
.42
.70
.14
.55
.36
.35
.37
.54

patdist
eval
dev
.80
.69
.50
.50
.10
.07
.11
.44
.57
.67
.32
.30
.22
.24
.30
.30
.00
.13
.03
.10
.11
.13
.27
.38
.26
.27
.50
.14
.53
.40
.48
.42
.71
.70
.40
.47
.62
.39
.39
.30
.29
.03
.18
.31
.56
.32
.53
.46
.36
.35

id166skip
eval
dev
.86
.74
.02
.35
.81
.68
.82
.32
1.0
.67
.54
.79
.36
.42
.59
.27
.34
.64
.33
.31
.64
.65
.79
.65
.71
.78
.68
.60
.32
.67
.48
.54
.62
.62
.70
.57
.74
.77
.43
.42
.13
.70
.20
.37
.37
.38
.55
.43
.48
.62

id98context
eval
dev
.76
.83
.04
.32
.82
.61
.52
.77
.77
1.0
.48
.72
.37
.41
.59
.23
.28
.63
.23
.20
.39
.43
.65
.78
.55
.72
.70
.63
.30
.67
.57
.46
.66
.65
.71
.64
.68
.80
.43
.45
.04
.65
.16
.41
.44
.36
.43
.53
.46
.60

cmb

dev
.86
.50
.87
.82
1.0
.79
.47
.74
.70
.31
.65
.72
.79
.65
.78
.59
.72
.68
.85
.50
.76
.52
.42
.58
.68

eval
.77
.50
.76
.31
.67
.54
.39
.36
.35
.31
.59
.71
.71
.70
.57
.46
.67
.68
.77
.46
.13
.21
.49
.51
.53

table 1: performance on slot filling benchmark dataset (dev: data from 2012/2013, eval: from 2014). cmb denotes the combina-
tion of patdist, id166skip and id98context.

slot wise results of the other models (pat-
uschema, id166bow, id98piece, id98pieceext) can
be found in the supplementary material.

comparing pat, id166 and id98,5 different pat-
terns emerge for different slots. each is best on a
subset of the slots (see bold numbers). this indi-
cates that relation classi   cation for slot    lling is not
a uniform problem: each slot has special properties
and the three approaches are good at modeling a
different subset of these properties. given the big
differences, we expect to gain performance by com-
bining the three approaches. indeed, cmb (patdist
+ id166skip + id98context), the combination of the
three best performing models, obtains the best re-
sults in average (in bold).

section 6.3 shows that the performance on our
dataset is highly correlated with sf end-to-end per-
5in prior experiments, we also compared with recurrent neu-
ral networks. id56 performance was comparable to id98s, but
required much more training time and parameter tuning. there-
fore, we focus on id98s in this paper. see also vu et al. (2016).

formance. thus, our results indicate that a combina-
tion of different models ist the most promising ap-
proach to getting good performance on slot    lling.

6 analysis
6.1 contribution of each model
to see how much each model contributes to cmb,
we count how often each weight between 0.0 and
1.0 is selected for the linear interpolation. the re-
sults are plotted as a histogram (figure 2). a weight
of 0.0 means that the corresponding model does not
contribute to cmb. we see that all three models con-
tribute to cmb for most of the slots. the id98, for
instance, is included in the combination for 14 of 24
slots.

6.2 comparison of id98 to traditional models
our motivation for using a id98 is that convolution
and max pooling can recognize important id165s
independent of their position in the sentence. to in-

figure 2: # times each weight is selected in cmb

figure 3: analysis of convolution and pooling

vestigate this effect, we select for each id98 the top
   ve kernels whose activations are the most corre-
lated with the    nal score of the positive class. then
we calculate which id165s are selected by these
kernels in the max pooling step. this corresponds to
those id165s which are recognized by the kernel to
be the most informative for the given slot. figure 3
shows the result for an example sentence express-
ing the slot relation org:parents. the height of a bar
is the number of times that the 3-gram around the
corresponding word was selected by k-max pooling;
e.g., the bar above    newest    corresponds to the tri-
gram    its newest subsidiary   . the    gure shows that
the convolutional    lters are able to learn phrases that
trigger a relation, e.g.,    its subsidiary   . in contrast
to patterns, they do not rely on exact matches. the
   rst reason is embeddings. they generalize similar
words and phrases by assigning similar word vectors
to them. for pat and id166, this type of generaliza-
tion is more dif   cult. the second type of generaliza-
tion that the id98 learns concerns insertions, similar
to skip id165 features. the recognition of impor-
tant phrases in convolution is robust against inser-
tions. an example is    newest    in figure 3, a word
that is not important for the slot.

a direct comparison of results with pat shows
that the id98 has better eval scores for about 67%
of the slots (see table 1). our reasoning above can
explain this. compared to the id166, the id98 gen-
eralizes better to unseen data in only 42% of all
cases. the fact that this does not happen in more
cases shows the power of the skip id165 features
of the id166: they also provide a kind of generaliza-
tion against insertions. the id166 might also need
less data to train than the id98. nevertheless, the

   nal scores show that the id98 performs almost as
well as the id166 in average (.60 vs .62 on dev, .46 vs
.48 on eval) and contributes to a better combination
score.

6.3 correlation with end-to-end results
in this section, we show that using the dataset we
provide with this paper allows tuning classi   cation
models for the end-to-end sf task. for each model
and each possible combination of models, we cal-
culate average results on our evaluation set as well
as    nal f1 scores when running the whole slot    ll-
ing pipeline with our in-house system. the best re-
sults of our slot    lling system are an f1 of .29 on
the 2013 queries and of .25 on the 2014 queries. we
calculate pearson   s correlation coef   cient to assess
correlation of relation classi   cation and end-to-end
performances for the n different system con   gura-
tions (i.e., model combinations). the correlation of
the results on our eval dataset with the sf results on
2013 queries is .89, the correlation with the sf re-
sults on 2014 queries is .82. this con   rms that good
results on the dataset we propose lead to good results
on the slot    lling end-to-end task.

6.4 effect of genre and time
the tac source corpus consists of about 1m news
documents, 1m web documents and 100k docu-
ments from discussion forums (tac, 2014). the
distribution of these different genres in the extracted
assessment data is as shown in table 2.

the proportion of non-news more than doubled
from 12.5% to 26.6%. thus, when using 2012/2013
as the development and 2014 as the test set, we are
faced with a id20 problem.

 0 2 4 6 8 10 12 0 0.1 0.2 0.3 0.4 0.5 0.6 0.7 0.8 0.9 1number of weight selectionpatid166id98 1 2 3 4infuturequarters,<filler>'sutilitydivisionwillincludeitsnewestsubsidiary,<name>railroad.pooling resulttop 1top 3top 5news
web + forums

2014
2012/3
87.5% 73.4%
12.5% 26.6%

table 2: distribution of genres

in this section, we show the effect of domain dif-
ferences on our models in more detail. for our genre
analysis, we retrain our models on genre speci   c
training sets web and news    and show within-
genre as well as cross-genre evaluations. to avoid
performance differences due to different training set
sizes, we reduced the news training set to the same
size as the web training set. we refer to this subset
as news   .

cross-genre evaluation. table 3 shows results
of testing models trained on genre-speci   c data: on
data of the same genre and on data of the other genre.
we present results only for a subset of relations in
this paper, however, the numbers for the other slots
follow the same trends.

models trained on news (left part) show clearly
higher performance in the within-genre evaluation
than cross-genre. for models trained on web (right
part), this is different. we suspect that the reason
is that web data is much noiser and thus less pre-
dictable, even for models trained on web. for all
evaluations, the differences among dev and eval are
quite large. especially for slot    lling on web (bot-
tom part of table 3), the results on dev do not seem
much related to the results on eval. this domain ef-
fect increases the dif   culties of training robust re-
lation classi   cation models for slot    lling.
it can
also explain why optimizing models for unseen data
(with unknown genre distributions) as in table 1 is
challenging. since slot    lling by itself is a challeng-
ing task, even in the absence of domain differences,
we will distribute two splits: a split by year and a
split by genre. for training and tuning models for
the slot    lling research challenge, the year split can
be used to cover the challenge of mixing different
genres. for experiments on id20 or
genre-speci   c effects, our genre split can be used.

7 conclusion

in this paper, we presented different approaches to
slot    lling relation classi   cation: patterns, support
vector machines and convolutional neural networks.

train on news   
id98
id166

train on web
id98
id166

ev dev

ev dev

ev dev

s
w
e
n
n
o
t
s
e
t

dev
.79 .80 .88 .87
per:age
.85 .86 .78 .78
per:children
.74 .64 .76 .71
per:spouse
.22 .32 .69 .67
org:alt names
org:loc headqu .51 .50 .53 .51
.30 .32 .29 .34
org:parents
.33 .73 .57 .83
per:age
.59 .33 .70 .33
per:children
.52 .50 .60 .57
per:spouse
.27 .19 .51 .37
org:alt names
org:loc headqu .39 .46 .43 .44
.09 .08 .11 .07
org:parents

ev
.78 .76 .85 .83
.75 .80 .00 .07
.77 .65 .73 .67
.65 .70 .66 .66
.51 .53 .53 .50
.26 .33 .30 .34
.00 .67 .57 .83
.63 .57 .00 .00
.56 .57 .67 .62
.60 .49 .56 .38
.44 .48 .36 .47
.10 .08 .15 .08
table 3: genre speci   c f1 scores. genre speci   c training data
(of the same sizes). top: news results. bottom: web results.

b
e
w
n
o
t
s
e
t

we investigated their complementary strengths and
weaknesses and showed that their combination can
better deal with a diverse set of problems that slot
   lling poses than each of the approaches individu-
ally. we proposed a contextwise id98 which out-
performs the recent state-of-the-art piecewise id98.
furthermore, we analyzed the effect of genre on slot
   lling and showed that it needs to be carefully ex-
amined in research on slot    lling. finally, we pro-
vided a benchmark for slot    lling relation classi   -
cation that will facilitate direct comparisons of ap-
proaches in the future.

8 additional resources
we publish the scripts that we developed to extract
the annotated evaluation data and our splits by genre
and by year as well as the dev/eval splits.

acknowledgments
heike adel is a recipient of the google european
doctoral fellowship in natural language process-
ing and this research is supported by this fellowship.
this research was also supported by deutsche

forschungsgemeinschaft: grant schu 2246/4-2.

we would like to thank gabor angeli for his help

with the mintz++ and mimlre models.

references
[angeli et al.2014a] gabor angeli, sonal gupta, melvin
jose, christopher d. manning, christopher re, julie
tibshirani, jean y. wu, sen wu, and ce zhang.
2014a. stanfords 2014 slot    lling systems. in tac.

[angeli et al.2014b] gabor angeli,

julie tibshirani,
jean y. wu, and christopher d. manning. 2014b.
combining distant and partial supervision for relation
extraction. in emnlp.

[bollacker et al.2008] kurt bollacker, colin evans,
praveen paritosh, tim sturge, and jamie taylor.
a collaboratively created graph
2008.
in acm
database for structuring human knowledge.
sigmod.

freebase:

[collobert et al.2011] ronan collobert, jason weston,
l  eon bottou, michael karlen, koray kavukcuoglu,
and pavel kuksa. 2011. natural language processing
(almost) from scratch. jmlr.

[dos santos et al.2015] c    cero nogueira dos santos,
bing xiang, and bowen zhou. 2015. classifying re-
lations by ranking with convolutional neural networks.
in acl.

[fan et al.2008] rong-en fan, kai-wei chang, cho-jui
hsieh, xiang-rui wang, and chih-jen lin.
2008.
liblinear: a library for large linear classi   cation.
jmlr.

[foster and kuhn2007] george foster and roland kuhn.
2007. mixture-model adaptation for smt. in work-
shop on smt.

[glorot et al.2011] xavier glorot, antoine bordes, and
yoshua bengio. 2011. id20 for large-
scale sentiment classi   cation: a deep learning ap-
proach. in icml.

[gonz`alez et al.2012] e. gonz`alez,

h. rodr    guez,
j. turmo, p. r. comas, a. naderi, a. ageno,
e. sapena, m. vila, and m. a. mart    . 2012. the
talp participation at tac-kbp 2012. in tac.

[hendrickx et al.2010] iris hendrickx, su nam kim, zor-
nitsa kozareva, preslav nakov, diarmuid   o s  eaghdha,
sebastian pad  o, marco pennacchiotti, lorenza ro-
mano, and stan szpakowicz. 2010. semeval-2010
task 8: multi-way classi   cation of semantic relations
between pairs of nominals. in semeval. acl.

[kalchbrenner et al.2014] nal kalchbrenner,

edward
grefenstette, and phil blunsom. 2014. a convolu-
tional neural network for modelling sentences.
in
acl.

[li et al.2012] yan li, sijia chen, zhihua zhou, jie yin,
hao luo, liyin hong, weiran xu, guang chen, and
guo jun. 2012. pris at tac 2012 kbp track.
in
tac.

[liu and zhao2012] fang liu and jun zhao.

2012.
sweat2012: pattern based english slot    lling system
for knowledge base population at tac 2012. in tac.

[malon et al.2012] christopher malon, bing bai, and
kazi saidul hasan. 2012. slot-   lling by substring
extraction at tac kbp 2012 (team papelo). in tac.

john bauer,

[manning et al.2014] christopher d. manning, mihai
jenny finkel, steven j.
surdeanu,
bethard, and david mcclosky. 2014. the stanford
corenlp natural language processing toolkit. in acl:
system demonstrations.

[mikolov et al.2013] tomas mikolov, kai chen, greg
corrado, and jeffrey dean. 2013. ef   cient estimation
of word representations in vector space. in workshop
at iclr.

[min et al.2012] bonan min, xiang li, ralph grishman,
and ang sun. 2012. new york university 2012 system
for kbp slot    lling. in tac.

[mintz et al.2009] mike mintz, steven bills, rion snow,
and dan jurafsky. 2009. distant supervision for rela-
tion extraction without labeled data. in acl-ijcnlp.
[petrov and mcdonald2012] slav petrov and ryan mc-
donald. 2012. overview of the 2012 shared task on
parsing the web. in sancl.

[pink et al.2014] glen pink, joel nothman, and james r
curran. 2014. analysing recall loss in named entity
slot    lling. in emnlp.

[qiu et al.2012] xin ying qiu, xiaoting li, weijian mo,
manli zheng, and zhuhe zheng. 2012. gdufs at slot
   lling tac-kbp 2012. in tac.

[riedel et al.2013] sebastian riedel, limin yao, andrew
mccallum, and benjamin m marlin. 2013. rela-
tion extraction with id105 and universal
schemas. in hlt-naacl.

[roth et al.2013] benjamin roth, tassilo barth, michael
wiegand, mittul singh, and dietrich klakow. 2013.
effective slot    lling based on shallow distant supervi-
sion methods. in tac.

[roth et al.2014] benjamin roth, emma strubell, john
sullivan, lakshmi vikraman, kate silverstein, and
andrew mccallum. 2014. universal schema for slot-
   lling, cold-start kbp and event argument extraction:
umass iesl at tac kbp 2014. in tac.

[surdeanu and ji2014] mihai surdeanu and heng ji.
2014. overview of the english slot    lling track at the
tac 2014 knowledge base population evaluation. in
tac.

[surdeanu et al.2012] mihai surdeanu, julie tibshirani,
ramesh nallapati, and christopher d manning. 2012.
multi-instance multi-label learning for relation extrac-
tion. in emnlp-conll.

[surdeanu2013] mihai surdeanu. 2013. overview of the
tac 2013 knowledge base population evaluation: en-
glish slot    lling and temporal slot    lling. in tac.

[tac2014] tac. 2014. task description for english slot
   lling at tac kbp 2014. http://surdeanu.

info/kbp2014/kbp2014_taskdefinition_
englishslotfilling_1.1.pdf.

[varma et al.2012] vasudeva varma, bhaskar ghosh, mo-
han soundararajan, deepti aggarwal, and priya rad-
hakrishnan. 2012. iiit hyderabad at tac 2012. in
tac.

[viswanathan et al.2015] vidhoon

viswanathan,
nazneen fatema rajani, yinon bentor, and raymond
mooney. 2015. stacked ensembles of information
extractors for knowledge-base population. in acl.

[vu et al.2016] ngoc thang vu, heike adel, pankaj
gupta, and hinrich sch  utze. 2016. combining re-
current and convolutional neural networks for relation
classi   cation. in hlt-naacl.

[zeng et al.2014] daojian zeng, kang liu, siwei lai,
guangyou zhou, and jun zhao. 2014. relation clas-
si   cation via convolutional deep neural network.
in
coling.

[zeng et al.2015] daojian zeng, kang liu, yubo chen,
and jun zhao. 2015. distant supervision for rela-
tion extraction via piecewise convolutional neural net-
works. in emnlp.

