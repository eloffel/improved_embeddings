5
1
0
2

 

b
e
f
9
1

 

 
 
]
e
n
.
s
c
[
 
 

3
v
5
1
6
4

.

0
1
4
1
:
v
i
x
r
a

under review as a conference paper at iclr 2015

learning to execute

wojciech zaremba   
new york university
woj.zaremba@gmail.com

ilya sutskever
google
ilyasu@google.com

abstract

recurrent neural networks (id56s) with long short-term memory units
(lstm) are widely used because they are expressive and are easy to train. our
interest lies in empirically evaluating the expressiveness and the learnability of
lstms in the sequence-to-sequence regime by training them to evaluate short
computer programs, a domain that has traditionally been seen as too complex for
neural networks. we consider a simple class of programs that can be evaluated
with a single left-to-right pass using constant memory. our main result is that
lstms can learn to map the character-level representations of such programs to
their correct outputs. notably, it was necessary to use curriculum learning, and
while conventional curriculum learning proved ineffective, we developed a new
variant of curriculum learning that improved our networks    performance in all
experimental conditions. the improved curriculum had a dramatic impact on an
addition problem, making it possible to train an lstm to add two 9-digit numbers
with 99% accuracy.

   

introduction

1
execution of computer programs requires dealing with a number of nontrivial concepts. to execute
a program, a system has to understand numerical operations, if-statements, variable assignments,
the compositionality of operations, and many more.
we show that recurrent neural networks (id56) with long short-term memory (lstm) units
can accurately evaluate short simple programs in the sequence-to-sequence framework of sutskever
et al. (2014). the lstm reads the program character-by-character and computes the program   s
output. we consider a constrained set of computer programs that can be evaluated in linear time
and constant memory, because the lstm reads the program only once and its memory capacity is
limited (section 3).
we found it dif   cult to train lstms to execute computer programs, so we used curriculum learn-
ing to simplify the learning problem. we design a curriculum procedure which outperforms both
conventional training that uses no curriculum learning (baseline) as well as the naive curriculum
learning of strategy of bengio et al. (2009) (section 4). we provide a plausible explanation for the
effectiveness of our procedure relative to naive curriculum learning (section 7).
finally, in addition to curriculum learning strategies, we examine two simple input transformations
that further simplify the sequence-to-sequence learning problem. we show that, in many cases,
reversing the input sequence (sutskever et al., 2014) and replicating the input sequence improves
the lstm   s performance on a memorization task (section 3.2).
the code for replicating most of the experiments in this work can be found in https://github.
com/wojciechz/learning_to_execute.
   work done while the author was in google brain.

1

under review as a conference paper at iclr 2015

input:

j=8584
for x in range(8):

j+=920

b=(1500+j)
print((b+7567))

target: 25011.

input:

i=8827
c=(i-5347)
print((c+8704) if 2641<8500 else 5308)

target: 12184.

figure 1: example programs on which we train the lstm. the output of each program is a single
integer. a    dot    symbol indicates the end of the integer, which has to be predicted by the lstm.

2 related work
there has been related research that used tree neural networks (also known as recursive neu-
ral networks) to evaluate symbolic mathematical expressions and logical formulas (zaremba et al.,
2014a; bowman et al., 2014; bowman, 2013), which is close in spirit to our work. computer pro-
grams are more complex than mathematical or logical expressions because it is possible to simulate
either with an appropriate computer program.
from a methodological perspective, we formulate the program evaluation task as a sequence-
to-sequence learning problem with a recurrent neural network (sutskever et al., 2014) (see also
(mikolov, 2012; sutskever, 2013; pascanu et al., 2013)). other interesting applications of recurrent
neural networks include id103 (robinson et al., 1996; graves et al., 2013), machine
translation (cho et al., 2014; sutskever et al., 2014), handwriting recognition (pham et al., 2013;
zaremba et al., 2014b), and many more.
maddison & tarlow (2014) trained a language model of program text, and mou et al. (2014) used a
neural network to determine whether two programs are equivalent. both of these approaches require
the parse trees of programs, while the input to our model is a string of character representing our
program.
predicting program output requires that the model deals with long term dependencies that arise
from variable assignment. for this reason, we chose to use the long short-term memory model
(hochreiter & schmidhuber, 1997), although there are many other id56 variants that perform well
on tasks with long term dependencies (cho et al., 2014; jaeger et al., 2007; koutn    k et al., 2014;
martens, 2010; bengio et al., 2013).
initially, we found it dif   cult to train lstms to accurately evaluate programs. the compositional
nature of computer programs suggests that the lstm would learn faster if we    rst taught it about the
individual operators and how to combine them. this approach can be implemented with curriculum
learning (bengio et al., 2009; kumar et al., 2010; lee & grauman, 2011), which prescribes to grad-
ually increase the    dif   culty level    of the examples presented to the lstm. it is partially motivated
by fact that humans and animals learn much faster when they are given hard but manageable tasks.
unfortunately, we found the naive curriculum learning strategy of bengio et al. (2009) to sometimes
be harmful. one of our key contributions is the formulation of a new curriculum learning strategy
that substantially improves the speed and the quality of training in every experimental setting that
we considered.

3 program subclass
we train id56s on the class of short programs that can be evaluated in o (n) time and constant
memory. this restriction is dictated by the computational structure of the id56 itself, as it can only

2

under review as a conference paper at iclr 2015

input:
vqppkn
sqdvfljmnc
y2vxdddsepnimcbvubkomhrpliibtwztbljipcc
target: hkhpg

figure 2: a sample program with its outputs when the characters are scrambled. it helps illustrate
the dif   culty faced by our neural network.

perform a single pass over the program and its memory is limited. our programs use the python
syntax and are constructed from a small number of operations and their compositions (nesting).
we allow the following operations: addition, subtraction, multiplication, variable assignments, if-
statements, and for-loops, but we forbid double loops. every program ends with a single    print   
statement whose output is an integer. two example programs are shown in figure 1.
we select our programs from a family of distributions parametrized by their length and nesting. the
length parameter is the number of digits in the integers that appear in the programs (so the integers
are chosen uniformly from [1, 10length]). the appendix presents the pseudocode 1 of the algorithm
used to generate our programs. for example, two programs that are generated with length = 4 and
nesting = 3 are shown in figure 1.
we impose restrictions on the operands of multiplication and on the ranges of for-loop, since they
pose a greater dif   culty to our model. we constrain one of the arguments of multiplication and the
range of for-loops to be chosen uniformly from the much smaller range [1, 4   length]. we do so since
our models are able to perform linear-time computation while generic integer multiplication requires
superlinear time. similar considerations apply to for-loops, since nested for-loops can implement
integer multiplication.
the nesting parameter is the number of times we are allowed to combine the operations with each
other. higher values of nesting yield programs with deeper parse trees. nesting makes the task much
harder for the lstms, because they do not have a natural way of dealing with compositionality,
unlike tree neural networks. it is surprising that the lstms can handle nested expressions at all.
the programs also do not receive an external input.
it is important to emphasize that the lstm reads the entire input one character at a time and pro-
duces the output one character at a time. the characters are initially meaningless from the model   s
perspective; for instance, the model does not know that    +    means addition or that 6 is followed
by 7. in fact, scrambling the input characters (e.g., replacing    a    with    q   ,    b    with    w   , etc.,) has
no effect on the model   s ability to solve this problem. we demonstrate the dif   culty of the task by
presenting an input-output example with scrambled characters in figure 2.
finally, we wanted to verify that our program are not trivial to evaluate, by ensuring that the bias
coming from benford   s law (hill, 1995) is not too strong. our setup has 12 possible output char-
acters, that is 10 digits, the end of sequence character, and minus. their output distribution is not
uniform, which can be seen by noticing that the minus sign and the dot do not occur with the same
frequency as the other digits. if we assume that the output characters are independent, the probabil-
ity of guessing the correct character is     8.3%. the most common character is 1 which occurs with
id203 12.7% over the entire output.
however, there is a bias in the distribution of the    rst character. there are 11 possible choices, which
can be randomly guessed with a id203 of 9%. the most common character is 1, and it occurs
with a id203 20.3% in its    rst position, indicating a strong bias. still, this value is far below
our model prediction accuracy. moreover, the most probable second character in the    rst position of
the output occurs with id203 12.6%, which is indistinguishable from id203 distribution
of digits in the other positions. the last character is always the end of sequence. the most common
digit prior to the last character is 4, and it occures with id203 10.3%. these statistics are
computed with 10000 randomly generated programs with length = 4 and nesting = 1. the
absence of a strong bias for this con   guration suggests that there will be even less bias in with
greater nesting and longer digits, which we have also con   rmed numerically.

3

under review as a conference paper at iclr 2015

input:
print(398345+425098)
target: 823443

figure 3: a typical data sample for the addition task.

3.1 addition task
it is dif   cult to intuitively assess the accuracy of an lstm on a program evaluation task. for
example, it is not clear whether an accuracy of 50% is impressive. thus, we also evaluate our models
on a more familiar addition task, where the dif   culty is measured by the length of the inputs. we
consider the addition of only two numbers of the same length (figure 3) that are chosen uniformly
from [1, 10length]. adding two number of the same length is simpler than adding variable length
numbers. model doesn   t need to align them.

3.2 memorization task
in addition to program evaluation and addition, we also investigate the task of memorizing a random
sequence of numbers. given an example input 123456789, the lstm reads it one character at a
time, stores it in memory, and then outputs 123456789 one character at a time. we present and
explore two simple performance enhancing techniques: input reversing sutskever et al. (2014) and
input doubling.
the idea of input reversing is to reverse the order of the input (987654321) while keeping the de-
sired output unchanged (123456789). it may appear to be a neutral operation because the average
distance between each input and its corresponding target does not change. however, input reversing
introduces many short term dependencies that make it easier for the lstm to learn to make correct
predictions. this strategy was    rst introduced by sutskever et al. (2014).
the second performance enhancing technique is input doubling, where we present the input se-
quence twice (so the example input becomes 123456789; 123456789), while the output remains
unchanged (123456789). this method is meaningless from a probabilistic perspective as id56s ap-
proximate the conditional distribution p(y|x), yet here we attempt to learn p(y|x, x). still, it gives
noticeable performance improvements. by processing the input several times before producing the
output, the lstm is given the opportunity to correct any mistakes or omissions it made before.

4 curriculum learning
our program generation procedure is parametrized by length and nesting. these two parameters
allow us control the complexity of the program. when length and nesting are large enough, the
learning problem becomes nearly intractable. this indicates that in order to learn to evaluate pro-
grams of a given length = a and nesting = b, it may help to    rst learn to evaluate programs with
length (cid:28) a and nesting (cid:28) b. we evaluate the following curriculum learning strategies:
no curriculum learning (baseline) the baseline approach does not use curriculum learning. this
means that we generate all the training samples with length = a and nesting = b. this strategy is the
most    sound    from statistical perspective, since it is generally recommended to make the training
distribution identical to test distribution.
naive curriculum strategy (naive) we begin with length = 1 and nesting = 1. once learning
stops making progress on the validation set, we increase length by 1. we repeat this process until
its length reaches a, in which case we increase nesting by one and reset length to 1. we can also
choose to    rst increase nesting and then length. however, it does not make a noticeable difference in
performance. we skip this option in the rest of paper, and increase length    rst in all our experiments.
this strategy is has been examined in previous work on curriculum learning (bengio et al., 2009).
however, we show that sometimes it gives even worse performance than baseline.
mixed strategy (mix) to generate a random sample, we    rst pick a random length from [1, a] and
a random nesting from [1, b] independently for every sample. the mixed strategy uses a balanced

4

under review as a conference paper at iclr 2015

mixture of easy and dif   cult examples, so at every point during training, a sizable fraction of the
training samples will have the appropriate dif   culty for the lstm.
combining the mixed strategy with naive curriculum strategy (combined) this strategy com-
bines the mix strategy with the naive strategy. in this approach, every training case is obtained either
by the naive strategy or by the mix strategy. as a result, the combined strategy always exposes the
network at least to some dif   cult examples, which is the key way in which it differs from the naive
curriculum strategy. we noticed that it always outperformed the naive strategy and would generally
(but not always) outperform the mix strategy. we explain why our new curriculum learning strategies
outperform the naive curriculum strategy in section 7.
we evaluate these four strategies on the program evaluation task (section 6.1) and on the memoriza-
tion task (section 6.3).

5 lstm
in this section we brie   y describe the deep lstm (section 5). all vectors are n-dimensional unless
t     rn be a hidden state in layer l in timestep t. let tn,m : rn    
explicitly stated otherwise. let hl
rm be a biased linear mapping (x     w x + b for some w and b). we let (cid:12) be element-wise
t be the input to the deep lstm at timestep t. we use the activations at the
multiplication and let h0
t ) to predict yt where l is the depth of our lstm.
top layer l (namely hl
the structure of the lstm allows it to train on problems with long term dependencies relatively
t     rn. although many
easily. the    long term    memory is stored in a vector of memory cells cl
lstm architectures differ slightly in their connectivity structure and id180, all lstm
architectures have additive memory cells that make it easy to learn to store information for long
periods of time. we used an lstm described by the following equations (from graves et al. (2013)):

t   1     hl

t, cl
t

(cid:18)hl   1

(cid:19)

t
hl
t   1

lstm : hl   1

          i

          =

t

, hl

         sigm

t   1, cl

          t2n,4n

sigm
sigm
tanh
t   1 + i (cid:12) g

f
o
g
t = f (cid:12) cl
cl
t = o (cid:12) tanh(cl
hl
t)

6 experiments
in this section, we report the results of our curriculum learning strategies on the program evaluation
and memorization tasks. in both experiments, we used the same lstm architecture.
our lstm has two layers and is unrolled for 50 steps in both experiments. it has 400 cells per layer
and its parameters are initialized uniformly in [   0.08, 0.08]. this gives total     2.5m parameters.
we initialize the hidden states to zero. we then use the    nal hidden states of the current minibatch
as the initial hidden state of the subsequent minibatch. thus it is possible that a program and its
output could be separated across different minibatches. the size of minibatch is 100. we constrain
the norm of the gradients (normalized by minibatch size) to be no greater than 5 (mikolov et al.,
2010). we keep the learning rate equal to 0.5 until we reach the target length and nesting (we only
vary the length, i.e., the number of digits, in the memorization task).
after reaching the target accuracy (95%) we decrease the learning rate by 0.8. we keep the learning
rate on the same level until there is no improvement on the training set. we decrease it again, when
there is no improvement on training set. the only difference between experiments is the termination
criteria. for the program output prediction, we stop when learning rate becomes smaller than 0.001.
for copying task, we stop training after 20 epochs, where each epoch has 0.5m samples.
we begin training with length = 1 and nesting = 1 (or length=1 for the memorization task). we
ensure that the training, validation, and test sets are disjoint. it is achieved computing the hash value
of each sample and taking it modulo 3.
important note on error rates: we use teacher forcing when we compute the accuracy of our
lstms. that is, when predicting the i-th digit of the target, the lstm is provided with the correct

5

under review as a conference paper at iclr 2015

   rst i     1 digits of the target. this is different from using the lstm to generate the entire output
on its own, as done by sutskever et al. (2014), which would almost surely result in lower numerical
accuracies. to help make intuitive sense of our results, we present a large number of test cases and
the outputs computed by the lstm, albeit with teacher forcing.

6.1 results on program evaluation
we train our lstms using the four strategies described in section 4:

    no curriculum learning (baseline),
    naive curriculum strategy (naive)
    mixed strategy (mix), and
    combined strategy (combined).

figure 4 shows the absolute performance of the baseline strategy (training on the original target
distribution), and of the best performing strategy, combined. moreover, figure 5 shows the perfor-
mance of the three curriculum strategies relative to baseline. finally, we provide several example
predictions on test data in the supplementary materials. the accuracy of a random predictor would
be     8.3%, since there are 12 possible output symbols.

figure 4: absolute prediction accuracy of the baseline strategy and of the combined strategy (see
section 4) on the program evaluation task. deeper nesting and longer integers make the task more
dif   cult. overall, the combined strategy outperformed the baseline strategy in every setting.

figure 5: relative prediction accuracy of the different strategies with respect to the baseline strategy.
the naive curriculum strategy was found to sometime perform worse than baseline. a possible
explanation is provided in section 7. the combined strategy outperforms all other strategies in
every con   guration on program evaluation.

6.2 results on the addition task
figure 6 presents the accuracy achieved by the lstm with the various curriculum strategies on
the addition task. remarkably, the combined curriculum strategy resulted in 99% accuracy on the
addition of 9-digit long numbers, which is a massive improvement over the naive curriculum.

6.3 results on the memorization task
recall that the goal of the memorization task is to read a sequence of digits into the hidden state and
then to reconstruct it from the hidden state. namely, given an input such as 123456789, the goal is

6

under review as a conference paper at iclr 2015

figure 6: the effect of curriculum strategies on the addition task.

figure 7: prediction accuracy on the memorization task for the four curriculum strategies. the input
length ranges from 5 to 65 digits. every strategy is evaluated with the following 4 input modi   cation
schemes: no modi   cation; input inversion; input doubling; and input doubling and inversion. the
training time was not limited; the network was trained till convergence.

to produce the output 123456789. the model processes the input one input character at the time and
has to reconstruct the output only after loading the entire input into its memory. this task provides
insight into the lstm   s ability to learn to remember. we have evaluated our model on sequences
of lengths ranging from 5 to 65. we use the four curriculum strategies of section 4. in addition, we
investigate two strategies to modify the input which increase performance:

    inverting input (sutskever et al., 2014)
    doubling input

both strategies are described in section 3.2. figure 7 shows the absolute performance of the baseline
strategy and of the combined strategy. this figure shows the performance at convergence. we
further present in supplementary material (section 9) results after 20 epochs (figure 8).
for this task, the combined strategy no longer outperforms the mixed strategy in every experimental
setting, although both strategies are always better than using no curriculum and the naive curriculum
strategy. each graph contains 4 settings, which correspond to the possible combinations of input in-
version and input doubling. the result clearly shows that the simultaneously doubling and reversing
the input achieves the best results. random guessing would achieve an accuracy of     9%, since
there are 11 possible output symbols.

7 hidden state allocation hypothesis

our experimental results suggest that a proper curriculum learning strategy is critical for achieving
good performance on very hard problems where conventional stochastic id119 (sgd)

7

under review as a conference paper at iclr 2015

performs poorly. the results on both of our problems (sections 6.3 and 6.1) show that the combined
strategy is better than all other curriculum strategies, including both naive curriculum learning, and
training on the target distribution. we have a plausible explanation for why this is the case.
it seems natural to train models with examples of increasing dif   culty. this way the models have
a chance to learn the correct intermediate concepts, and then utilize them for the more dif   cult
problem instances. otherwise, learning the full task might be just too dif   cult for sgd from a
random initialization. this explanation has been proposed in previous work on curriculum learning
bengio et al. (2009). however, based the on empirical results, the naive strategy of curriculum
learning can sometimes be worse than learning with the target distribution.
in our tasks, the neural network has to perform a lot of memorization. the easier examples usually
require less memorization than the hard examples. for instance, in order to add two 5-digit numbers,
one has to remember at least 5 digits before producing any output. the best way to accurately
memorize 5 numbers could be to spread them over the entire hidden state / memory cell (i.e., use
a distributed representation).
indeed, the network has no incentive to utilize only a fraction of
its state, and it is always better to make use of its entire memory capacity. this implies that the
harder examples would require a restructuring of its memory patterns. it would need to contract its
representations of 5 digit numbers in order to free space for the 6-th number. this process of memory
pattern restructuring might be dif   cult to implement, so it could be the reason for the sometimes poor
performance of the naive curriculum learning strategy relative to baseline.
the combined strategy reduces the need to restructure the memory patterns. the combined strategy
is a combination of the naive curriculum strategy and of the mix strategy, which is a mixture of ex-
amples of all dif   culties. the examples produced by the naive curriculum strategy help to learn the
intermediate input-output mapping, which is useful for solving the target task, while the extra sam-
ples from the mix strategy prevent the network from utilizing all the memory on the easy examples,
thus eliminating the need to restructure its memory patterns.

8 critique

perfect prediction of program output requires a complete understanding of all operands and con-
cepts, and of the precise way in which they are combined. however, imperfect prediction might be
achieved in a multitude of ways, and could heavily rely on memorization, without a genuine un-
derstanding of the underlying concepts. for instance, perfect addition is relatively intricate, as the
lstm needs to know the order of numbers and to correctly compute the carry.
there are many alternatives to the addition algorithm if perfect output is not required. for instance,
one can perform element-wise addition, and as long as there is no carry then the output would be
perfectly correct. another alternative, which requires more memory, but is also more simpler, is to
memorize all results of addition for 2 digit numbers. then multi-digit addition can be broken down
to multiple 2-digits additions element-wise. once again, such an algorithm would have a reasonably
high prediction accuracy, although it would be far from correct.
we do not know how heavily our model relies on memorization and how far the learned algorithm
is from the actual, correct algorithm. this could be tested by creating a big discrepancy between the
training and test data, but in this work, the training and the test distributions are the same. we plan
to examine how well our models would generalize on very different new examples in future work.

9 discussion

we have shown that it is possible to learn to evaluate programs with limited prior knowledge. this
work demonstrate the power and expressiveness of sequence-to-sequence lstms. we also showed
that correct curriculum learning is crucial for achieving good results on very dif   cult tasks that
cannot be optimized with standard sgd. we also found that the general method of doubling the
input reliably improves the performance of sequence-to-sequence lstms.
our results are encouraging but they leave many questions open. for example, we are not able to
evaluate arbitrary programs (e.g., ones that run in more than o (n) time). this cannot be achieved
with conventional id56s or lstms due to their runtime restrictions. we also do not know the

8

under review as a conference paper at iclr 2015

optimal curriculum learning strategy. to understand it, it may be necessary to identify the training
samples that are most bene   cial to the model.

10 acknowledgments

we wish to thank oriol vinyals for useful discussions, and to koray kavukcuoglu for help during code develop-
ment. moreover, we wish to acknowledge marc   aurelio ranzato for useful comments on the    rst version of the
paper. some chunks of our code origin from google deepmind repository. we thank to unknown developers
of lstm function, and auxiliary functions.

references
bengio, yoshua, louradour, j  er  ome, collobert, ronan, and weston, jason. curriculum learning. in proceed-

ings of the 26th annual international conference on machine learning, pp. 41   48. acm, 2009.

bengio, yoshua, boulanger-lewandowski, nicolas, and pascanu, razvan. advances in optimizing recurrent
networks. in acoustics, speech and signal processing (icassp), 2013 ieee international conference on,
pp. 8624   8628. ieee, 2013.

bowman, samuel r. can recursive neural tensor networks learn logical reasoning?

arxiv preprint

arxiv:1312.6192, 2013.

bowman, samuel r, potts, christopher, and manning, christopher d. id56s for learning

logical semantics. arxiv preprint arxiv:1406.1827, 2014.

cho, kyunghyun, van merrienboer, bart, gulcehre, caglar, bougares, fethi, schwenk, holger, and bengio,
yoshua. learning phrase representations using id56 encoder-decoder for id151. arxiv
preprint arxiv:1406.1078, 2014.

graves, alex, mohamed, abdel-rahman, and hinton, geoffrey. id103 with deep recurrent neural
networks. in acoustics, speech and signal processing (icassp), 2013 ieee international conference on,
pp. 6645   6649. ieee, 2013.

hill, theodore p. a statistical derivation of the signi   cant-digit law. statistical science, pp. 354   363, 1995.
hochreiter, sepp and schmidhuber, j  urgen. long short-term memory. neural computation, 9(8):1735   1780,

1997.

jaeger, herbert, luko  sevi  cius, mantas, popovici, dan, and siewert, udo. optimization and applications of

echo state networks with leaky-integrator neurons. neural networks, 20(3):335   352, 2007.

koutn    k, jan, greff, klaus, gomez, faustino, and schmidhuber, j  urgen. a clockwork id56. arxiv preprint

arxiv:1402.3511, 2014.

kumar, m pawan, packer, benjamin, and koller, daphne. self-paced learning for latent variable models. in

advances in neural information processing systems, pp. 1189   1197, 2010.

lee, yong jae and grauman, kristen. learning the easy things    rst: self-paced visual category discovery. in
id161 and pattern recognition (cvpr), 2011 ieee conference on, pp. 1721   1728. ieee, 2011.
maddison, chris j and tarlow, daniel. structured generative models of natural source code. arxiv preprint

arxiv:1401.0514, 2014.

martens, james. deep learning via hessian-free optimization. in proceedings of the 27th international confer-

ence on machine learning (icml-10), pp. 735   742, 2010.

mikolov, tom  a  s. statistical language models based on neural networks. phd thesis, ph. d. thesis, brno

university of technology, 2012.

mikolov, tomas, kara     at, martin, burget, lukas, cernock`y, jan, and khudanpur, sanjeev. recurrent neural

network based language model. in interspeech, pp. 1045   1048, 2010.

mou, lili, li, ge, liu, yuxuan, peng, hao, jin, zhi, xu, yan, and zhang, lu. building program vector

representations for deep learning. arxiv preprint arxiv:1409.3358, 2014.

pascanu, razvan, gulcehre, caglar, cho, kyunghyun, and bengio, yoshua. how to construct deep recurrent

neural networks. arxiv preprint arxiv:1312.6026, 2013.

pham, vu, kermorvant, christopher, and louradour, j  er  ome. dropout improves recurrent neural networks for

handwriting recognition. arxiv preprint arxiv:1312.4569, 2013.

robinson, tony, hochberg, mike, and renals, steve. the use of recurrent neural networks in continuous speech

recognition. in automatic speech and speaker recognition, pp. 233   258. springer, 1996.

sutskever, ilya. training recurrent neural networks. phd thesis, university of toronto, 2013.
sutskever, ilya, vinyals, oriol, and le, quoc v. sequence to sequence learning with neural networks. arxiv

zaremba, wojciech, kurach, karol, and fergus, rob. learning to discover ef   cient mathematical identities.

zaremba, wojciech, sutskever, ilya, and vinyals, oriol. recurrent neural network id173. arxiv

preprint arxiv:1409.3215, 2014.

arxiv preprint arxiv:1406.1584, 2014a.

preprint arxiv:1409.2329, 2014b.

9

under review as a conference paper at iclr 2015

supplementary material

length, nesting

input:
stack = emptystack()
operations = addition, subtraction, multiplication, if-statement,
for-loop, variable assignment
for i = 1 to nesting do

operation = a random operation from operations
values = list
code = list
for params in operation.params do

if not empty stack and uniform(1) > 0.5 then

value, code = stack.pop()

else

value = random.int(10length)
code = tostring(value)

end if
values.append(value)
code.append(code)

end for
new value= operation.evaluate(values)
new code = operation.generate code(codes)
stack.push((new value, new code))

end for
final value, final code = stack.pop()
datasets = training, validation, testing
idx = hash(final code) modulo 3
datasets[idx].add((final value, final code))

algorithm 1: pseudocode of the algorithm used to generate the distribution over the python pro-
gram. programs produced by this algorithm are guaranteed to never have dead code. the type of the
sample (train, test, or validation) is determined by its hash modulo 3.

11 additional results on the memorization problem

we present the algorithm for generating the training cases, and present an extensive qualitative evaluation of
the samples and the kinds of predictions made by the trained lstms.
we emphasize that these predictions rely on teacher forcing. that is, even if the lstm made an incorrect
prediction in the i-th output digit, the lstm will be provided as input the correct i-th output digit for predicting
the i + 1-th digit. while teacher forcing has no effect whenever the lstm makes no errors at all, a sample that
makes an early error and gets the remainder of the digits correctly needs to be interpreted with care.

12 qualitative evaluation of the curriculum strategies

12.1 examples of program evaluation prediction. length = 4, nesting = 1

input:
print(6652).

target:
   baseline    prediction:
   naive    prediction:
   mix    prediction:
   combined    prediction:

6652.
6652.
6652.
6652.
6652.

input:

10

under review as a conference paper at iclr 2015

figure 8: prediction accuracy on the memorization task for the four curriculum strategies. the input
length ranges from 5 to 65 digits. every strategy is evaluated with the following 4 input modi   cation
schemes: no modi   cation; input inversion; input doubling; and input doubling and inversion. the
training time is limited to 20 epochs.

print((5997-738)).

target:
   baseline    prediction:
   naive    prediction:
   mix    prediction:
   combined    prediction:

5259.
5101.
5101.
5249.
5229.

input:
print((16*3071)).

target:
   baseline    prediction:
   naive    prediction:
   mix    prediction:
   combined    prediction:

49136.
49336.
48676.
57026.
49626.

input:
c=2060;
print((c-4387)).

target:
   baseline    prediction:
   naive    prediction:
   mix    prediction:
   combined    prediction:

-2327.
-2320.
-2201.
-2377.
-2317.

input:
print((2*5172)).

11

under review as a conference paper at iclr 2015

target:
   baseline    prediction:
   naive    prediction:
   mix    prediction:
   combined    prediction:

10344.
10344.
10324.
10344.
10344.

input:
print((9891-4715)).

target:
   baseline    prediction:
   naive    prediction:
   mix    prediction:
   combined    prediction:

5176.
5196.
5104.
4246.
5196.

input:
print(4849).

target:
   baseline    prediction:
   naive    prediction:
   mix    prediction:
   combined    prediction:

4849.
4849.
4849.
4849.
4849.

input:
print((4*7054)).

target:
   baseline    prediction:
   naive    prediction:
   mix    prediction:
   combined    prediction:

28216.
28216.
28116.
28216.
28216.

input:
print((4635-5257)).

target:
   baseline    prediction:
   naive    prediction:
   mix    prediction:
   combined    prediction:

-622.
-688.
-628.
-692.
-632.

input:
e=1079
for x in range(10):e+=4729
print(e).

target:
   baseline    prediction:
   naive    prediction:
   mix    prediction:
   combined    prediction:

48369.
48017.
48011.
48101.
48009.

12.2 examples of program evaluation prediction. length = 4, nesting = 2

input:

12

under review as a conference paper at iclr 2015

e=6653
for x in range(14):e+=6311
print(e).

target:
   baseline    prediction:
   naive    prediction:
   mix    prediction:
   combined    prediction:

95007.
94093.
90013.
95015.
94103.

input:
i=6404;
print((i+8074)).

target:
   baseline    prediction:
   naive    prediction:
   mix    prediction:
   combined    prediction:

14478.
14498.
14444.
14482.
14478.

input:
print((8*(5051-648))).

target:
   baseline    prediction:
   naive    prediction:
   mix    prediction:
   combined    prediction:

35224.
34044.
32180.
33284.
33004.

input:
h=(3681 if 9279<3033 else 6191)
for x in range(7):h-=9910
print(h).

target:
   baseline    prediction:
   naive    prediction:
   mix    prediction:
   combined    prediction:

-63179.
-62049.
-63117.
-62013.
-62009.

input:
print(((3210+2472)+1477)).

target:
   baseline    prediction:
   naive    prediction:
   mix    prediction:
   combined    prediction:

7159.
7009.
7019.
7995.
7079.

input:
b=8494
for x in range(2):b+=7484
print((b*14)).

target:
   baseline    prediction:
   naive    prediction:
   mix    prediction:
   combined    prediction:

328468.
318004.
338088.
329220.
338080.

13

under review as a conference paper at iclr 2015

input:
j=6447;
print((12*(j-4689))).

target:
   baseline    prediction:
   naive    prediction:
   mix    prediction:
   combined    prediction:

21096.
21266.
10046.
10606.
20402.

input:
print((13*9201)).

target:
   baseline    prediction:
   naive    prediction:
   mix    prediction:
   combined    prediction:

119613.
118313.
118011.
117669.
119533.

input:
g=1054;
print((6028+(g-1953))).

target:
   baseline    prediction:
   naive    prediction:
   mix    prediction:
   combined    prediction:

5129.
4013.
5035.
4015.
4009.

input:
d=6817
for x in range(7):d-=(4581-2186)
print(d).

target:
   baseline    prediction:
   naive    prediction:
   mix    prediction:
   combined    prediction:

-9948.
-1996.
-1610.
-1882.
-1980.

12.3 examples of program evaluation prediction. length = 4, nesting = 3

input:
f=4692
for x in range(4):f-=1664
j=1443
for x in range(8):j+=f
d=j
for x in range(11):d-=4699
print(d).

target:
   baseline    prediction:
   naive    prediction:
   mix    prediction:
   combined    prediction:

-65958.
-13262.
-73194.
-40188.
-12004.

14

under review as a conference paper at iclr 2015

input:
b=9930
for x in range(11):b-=4369
g=b;
print(((g-8043)+9955)).

target:
   baseline    prediction:
   naive    prediction:
   mix    prediction:
   combined    prediction:

-36217.
-37515.
-38609.
-35893.
-35055.

input:
d=5446
for x in range(8):d+=(2678 if 4803<2829 else 9848)
print((d if 5935<4845 else 3043)).

target:
   baseline    prediction:
   naive    prediction:
   mix    prediction:
   combined    prediction:

3043.
3043.
3043.
3043.
3043.

input:
print((((2578 if 7750<1768 else 8639)-2590)+342)).

target:
   baseline    prediction:
   naive    prediction:
   mix    prediction:
   combined    prediction:

6391.
-555.
6329.
6461.
6105.

input:
print((((841 if 2076<7326 else 1869)*10) if 7827<317 else 7192)).

target:
   baseline    prediction:
   naive    prediction:
   mix    prediction:
   combined    prediction:

7192.
7192.
7192.
7192.
7192.

input:
d=8640;
print((7135 if 6710>((d+7080)*14) else 7200)).

target:
   baseline    prediction:
   naive    prediction:
   mix    prediction:
   combined    prediction:

7200.
7200.
7200.
7200.
7200.

input:
b=6968
for x in range(10):b-=(299 if 3389<9977 else 203)
print((12*b)).

15

under review as a conference paper at iclr 2015

target:
   baseline    prediction:
   naive    prediction:
   mix    prediction:
   combined    prediction:

47736.
-0666.
11262.
48666.
48766.

input:
j=(1*5057);
print(((j+1215)+6931)).

target:
   baseline    prediction:
   naive    prediction:
   mix    prediction:
   combined    prediction:

13203.
13015.
12007.
13379.
13205.

input:
print(((1090-3305)+9466)).

target:
   baseline    prediction:
   naive    prediction:
   mix    prediction:
   combined    prediction:

7251.
7111.
7099.
7595.
7699.

input:
a=8331;
print((a-(15*7082))).

target:
   baseline    prediction:
   naive    prediction:
   mix    prediction:
   combined    prediction:

-97899.
-96991.
-19959.
-95551.
-96397.

12.4 examples of program evaluation prediction. length = 6, nesting = 1

input:
print((71647-548966)).

target:
   baseline    prediction:
   naive    prediction:
   mix    prediction:
   combined    prediction:

-477319.
-472122.
-477591.
-479705.
-475009.

input:
print(1508).

target:
   baseline    prediction:
   naive    prediction:
   mix    prediction:
   combined    prediction:

1508.
1508.
1508.
1508.
1508.

input:

16

under review as a conference paper at iclr 2015

j=611989;
print((j+763864)).

target:
   baseline    prediction:
   naive    prediction:
   mix    prediction:
   combined    prediction:

1375853.
1379920.
1378991.
1375119.
1375173.

input:
print((151108 if 289653>33296 else 564130)).

target:
   baseline    prediction:
   naive    prediction:
   mix    prediction:
   combined    prediction:

151108.
154973.
151108.
151108.
151108.

input:
c=142012
for x in range(12):c-=166776
print(c).

target:
   baseline    prediction:
   naive    prediction:
   mix    prediction:
   combined    prediction:

-1859300.
-1840831.
-1840000.
-1979720.
-1820700.

input:
print((678740+203140)).

target:
   baseline    prediction:
   naive    prediction:
   mix    prediction:
   combined    prediction:

881880.
880475.
881666.
880190.
885920.

input:
print((929067-75246)).

target:
   baseline    prediction:
   naive    prediction:
   mix    prediction:
   combined    prediction:

853821.
851233.
867113.
855615.
853009.

input:
d=960350
for x in range(24):d-=187946
print(d).

target:
   baseline    prediction:
   naive    prediction:
   mix    prediction:
   combined    prediction:

-3550354.
-3571998.
-3699993.
-3899220.
-3507790.

17

under review as a conference paper at iclr 2015

input:
print((8*786463)).

target:
   baseline    prediction:
   naive    prediction:
   mix    prediction:
   combined    prediction:

6291704.
6270804.
6271904.
6297644.
6270004.

input:
print((498592-570324)).

target:
   baseline    prediction:
   naive    prediction:
   mix    prediction:
   combined    prediction:

-71732.
-61086.
-73582.
-19000.
-72842.

12.5 examples of program evaluation prediction. length = 6, nesting = 2

input:
print((39007+416968)).

target:
   baseline    prediction:
   naive    prediction:
   mix    prediction:
   combined    prediction:

455975.
559917.
438887.
458993.
450031.

input:
print((586051+664462)).

target:
   baseline    prediction:
   naive    prediction:
   mix    prediction:
   combined    prediction:

1250513.
1250939.
1240719.
1230881.
1240551.

input:
print(948950).

target:
   baseline    prediction:
   naive    prediction:
   mix    prediction:
   combined    prediction:

948950.
948950.
948950.
948950.
948950.

input:
i=849846
for x in range(15):i-=557574
print((362961 if 881013<597832 else i)).

18

under review as a conference paper at iclr 2015

target:
   baseline    prediction:
   naive    prediction:
   mix    prediction:
   combined    prediction:

-7513764.
-7422756.
-7011048.
-2617777.
-7101146.

input:
g=977055;
print((g-(592222+268807))).

target:
   baseline    prediction:
   naive    prediction:
   mix    prediction:
   combined    prediction:

116026.
132440.
101488.
114988.
125682.

input:
print(((17*711621) if 224989>711768 else 267900)).

target:
   baseline    prediction:
   naive    prediction:
   mix    prediction:
   combined    prediction:

267900.
267900.
267900.
267900.
267900.

input:
j=114940;
print((j+482118)).

target:
   baseline    prediction:
   naive    prediction:
   mix    prediction:
   combined    prediction:

597058.
590006.
690004.
599816.
599990.

input:
print((171932*19)).

target:
   baseline    prediction:
   naive    prediction:
   mix    prediction:
   combined    prediction:

3266708.
3249998.
3131798.
3390158.
3100388.

input:
h=411671;
print((242648 if (h+31605)>679390 else 449699)).

target:
   baseline    prediction:
   naive    prediction:
   mix    prediction:
   combined    prediction:

449699.
449699.
449699.
449699.
449699.

input:
print(11332).

19

under review as a conference paper at iclr 2015

target:
   baseline    prediction:
   naive    prediction:
   mix    prediction:
   combined    prediction:

11332.
11332.
11332.
11332.
11332.

12.6 examples of program evaluation prediction. length = 6, nesting = 3

input:
c=335973;
b=(c+756088);
print((6*(b+66858))).

target:
   baseline    prediction:
   naive    prediction:
   mix    prediction:
   combined    prediction:

6953514.
1099522.
7773362.
6993124.
1044444.

input:
c=935280;
print((765618 if 409621<(c-(329375 if 806201<240281 else 81797)) else

805944)).

target:
   baseline    prediction:
   naive    prediction:
   mix    prediction:
   combined    prediction:

765618.
800988.
765644.
765616.
865618.

input:
print(((670421 if 144271>805597 else 364643)*20)).

target:
   baseline    prediction:
   naive    prediction:
   mix    prediction:
   combined    prediction:

7292860.
1774640.
7134660.
7292860.
7292860.

input:
print((108196 if 714126>847153 else (888873-(381812*13)))).

target:
   baseline    prediction:
   naive    prediction:
   mix    prediction:
   combined    prediction:

-4074683.
13205544.
-4011899.
-4422909.
-4048381.

input:
j=(181489 if 467875>46774 else (127738 if 866523<633391 else 592486))

;

print((j-627483)).

20

under review as a conference paper at iclr 2015

target:
   baseline    prediction:
   naive    prediction:
   mix    prediction:
   combined    prediction:

-445994.
-333153.
-488724.
-440880.
-447944.

input:
f=483654
for x in range(9):f-=913681
a=f
for x in range(12):a-=926785
print((124798 if a>326533 else 576599)).

target:
   baseline    prediction:
   naive    prediction:
   mix    prediction:
   combined    prediction:

576599.
176599.
576599.
576599.
576599.

input:
f=136315;
h=(f+37592);
g=418652;
print((g-(h+234728))).

target:
   baseline    prediction:
   naive    prediction:
   mix    prediction:
   combined    prediction:

10017.
12115.
-1123.
-000..
-0033.

input:
a=768606
for x in range(11):a+=454841
f=a
for x in range(3):f-=696226
print((340434 if f<287035 else 523084)).

target:
   baseline    prediction:
   naive    prediction:
   mix    prediction:
   combined    prediction:

523084.
523084.
523084.
523084.
523084.

input:
b=468503;
print((b-(326264+406077))).

target:
   baseline    prediction:
   naive    prediction:
   mix    prediction:
   combined    prediction:

-263838.
-278797.
-241144.
-252080.
-277882.

input:
g=801925;
print((58095+(g+(824920 if 842317>176260 else 570318)))).

21

under review as a conference paper at iclr 2015

target:
   baseline    prediction:
   naive    prediction:
   mix    prediction:
   combined    prediction:

1684940.
1602221.
1799892.
1677788.
1611888.

12.7 examples of predicting result of addition.
length = 6

input:
print(284993+281178).

target:
   baseline    prediction:
   naive    prediction:
   mix    prediction:
   combined    prediction:

566171.
566199.
566151.
566171.
566171.

input:
print(616216+423489).

target:
   baseline    prediction:
   naive    prediction:
   mix    prediction:
   combined    prediction:

1039705.
1039712.
1039605.
1039605.
1039705.

input:
print(559794+837898).

target:
   baseline    prediction:
   naive    prediction:
   mix    prediction:
   combined    prediction:

1397692.
1397694.
1397662.
1397792.
1397692.

input:
print(830194+551314).

target:
   baseline    prediction:
   naive    prediction:
   mix    prediction:
   combined    prediction:

1381508.
1381401.
1381518.
1381508.
1381508.

input:
print(252849+873177).

target:
   baseline    prediction:
   naive    prediction:
   mix    prediction:
   combined    prediction:

1126026.
1126020.
1126006.
1125026.
1126026.

input:
print(17513+163744).

22

under review as a conference paper at iclr 2015

target:
   baseline    prediction:
   naive    prediction:
   mix    prediction:
   combined    prediction:

181257.
181398.
181287.
181257.
181257.

input:
print(530590+569236).

target:
   baseline    prediction:
   naive    prediction:
   mix    prediction:
   combined    prediction:

1099826.
1099708.
1099826.
1099826.
1099826.

input:
print(856484+436077).

target:
   baseline    prediction:
   naive    prediction:
   mix    prediction:
   combined    prediction:

1292561.
1292589.
1292571.
1292561.
1292561.

input:
print(731632+833163).

target:
   baseline    prediction:
   naive    prediction:
   mix    prediction:
   combined    prediction:

1564795.
1564769.
1564775.
1564795.
1564795.

input:
print(738532+444531).

target:
   baseline    prediction:
   naive    prediction:
   mix    prediction:
   combined    prediction:

1183063.
1183000.
1183063.
1183063.
1183063.

12.8 examples of predicting result of addition.
length = 8

input:
print(32847917+95908452).

target:
   baseline    prediction:
   naive    prediction:
   mix    prediction:
   combined    prediction:

128756369.
128899997.
128756669.
128756369.
128756369.

input:
print(49173072+46963478).

23

under review as a conference paper at iclr 2015

target:
   baseline    prediction:
   naive    prediction:
   mix    prediction:
   combined    prediction:

96136550.
96129999.
96136050.
96136550.
96136550.

input:
print(79385668+60159139).

target:
   baseline    prediction:
   naive    prediction:
   mix    prediction:
   combined    prediction:

139544807.
139679090.
139544707.
139544807.
139544807.

input:
print(16183468+42542767).

target:
   baseline    prediction:
   naive    prediction:
   mix    prediction:
   combined    prediction:

58726235.
58798523.
58726035.
58726235.
58726235.

input:
print(15982788+54043908).

target:
   baseline    prediction:
   naive    prediction:
   mix    prediction:
   combined    prediction:

70026696.
60014022.
70026496.
60026696.
70026696.

input:
print(45356253+31242293).

target:
   baseline    prediction:
   naive    prediction:
   mix    prediction:
   combined    prediction:

76598546.
76699777.
76598246.
76598546.
76598546.

input:
print(93230501+12607891).

target:
   baseline    prediction:
   naive    prediction:
   mix    prediction:
   combined    prediction:

105838392.
105999882.
105838292.
105838392.
105838392.

input:
print(2487336+40625181).

24

under review as a conference paper at iclr 2015

target:
   baseline    prediction:
   naive    prediction:
   mix    prediction:
   combined    prediction:

43112517.
43178441.
43112917.
43112517.
43112517.

input:
print(61854571+75028157).

target:
   baseline    prediction:
   naive    prediction:
   mix    prediction:
   combined    prediction:

136882728.
136860087.
136883928.
136882728.
136882728.

input:
print(13828700+10188872).

target:
   baseline    prediction:
   naive    prediction:
   mix    prediction:
   combined    prediction:

24017572.
24000349.
24018872.
23017572.
24017572.

25

