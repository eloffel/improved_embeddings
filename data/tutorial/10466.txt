a persona-based neural conversation model

jiwei li1* michel galley2

chris brockett2

georgios p. spithourakis3* jianfeng gao2 bill dolan2

1stanford university, dept. of computer science

jiweil@stanford.edu

{mgalley,chrisbkt,jfgao,billdol}@microsoft.com

2microsoft research, redmond

3university college london, dept. of computer science

g.spithourakis@cs.ucl.ac.uk

6
1
0
2

 

n
u
j
 

8

 
 
]
l
c
.
s
c
[
 
 

2
v
5
5
1
6
0

.

3
0
6
1
:
v
i
x
r
a

abstract

we present persona-based models for han-
dling the issue of speaker consistency in
neural response generation. a speaker
model encodes personas in distributed em-
beddings that capture individual charac-
teristics such as background information
and speaking style. a dyadic speaker-
addressee model captures properties of in-
teractions between two interlocutors. our
models yield qualitative performance im-
provements in both perplexity and id7
scores over baseline sequence-to-sequence
models, with similar gains in speaker con-
sistency as measured by human judges.

1

introduction

as conversational agents gain traction as user in-
terfaces, there has been growing research inter-
est in training naturalistic conversation systems
from large volumes of human-to-human interac-
tions (ritter et al., 2011; sordoni et al., 2015;
vinyals and le, 2015; li et al., 2016). one major is-
sue for these data-driven systems is their propensity
to select the response with greatest likelihood   in
effect a consensus response of the humans repre-
sented in the training data. outputs are frequently
vague or non-committal (li et al., 2016), and when
not, they can be wildly inconsistent, as illustrated
in table 1.

in this paper, we address the challenge of consis-
tency and how to endow data-driven systems with
the coherent    persona    needed to model human-
like behavior, whether as personal assistants, per-

* the entirety of this work was conducted at microsoft.

i live in los angeles.
in which city do you live now?
i live in madrid.
in which country do you live now?

message where do you live now?
response
message
response
message
response england, you?
message where were you born?
response
i was born in canada.
message where are you from?
response england, you?
message where did you grow up?
response
i grew up in texas.
message how old are you?
response 16 and you?
message what   s your age?
response 18.
message what is your major?
response
message what did you study in college?
response english lit.

i   m majoring in psychology

inconsistent responses generated by a 4-layer
table 1:
id195 model trained on 25 million twitter conversation
snippets.

sonalized avatar-like agents, or game characters.1
for present purposes, we will de   ne persona
as the character that an arti   cial agent, as actor,
plays or performs during conversational interac-
tions. a persona can be viewed as a composite
of elements of identity (background facts or user
pro   le), language behavior, and interaction style.
a persona is also adaptive, since an agent may
need to present different facets to different human
interlocutors depending on the interaction.

fortunately, neural models of conversation gen-
eration (sordoni et al., 2015; shang et al., 2015;
vinyals and le, 2015; li et al., 2016) provide a
straightforward mechanism for incorporating per-
sonas as embeddings. we therefore explore two per-

1(vinyals and le, 2015) suggest that the lack of a coherent
personality makes it impossible for current systems to pass
the turing test.

sona models, a single-speaker speaker model
and a dyadic speaker-addressee model,
within a sequence-to-sequence (id195) frame-
work (sutskever et al., 2014). the speaker model
integrates a speaker-level vector representation into
the target part of the id195 model. analo-
gously, the speaker-addressee model encodes the
interaction patterns of two interlocutors by con-
structing an interaction representation from their
individual embeddings and incorporating it into
the id195 model. these persona vectors are
trained on human-human conversation data and
used at test time to generate personalized responses.
our experiments on an open-domain corpus of
twitter conversations and dialog datasets compris-
ing tv series scripts show that leveraging persona
vectors can improve relative performance up to
20% in id7 score and 12% in perplexity, with
a commensurate gain in consistency as judged by
human annotators.

2 related work

this work follows the line of investigation initiated
by ritter et al. (2011) who treat generation of con-
versational dialog as a statistical machine transla-
tion (smt) problem. ritter et al. (2011) represents
a break with previous and contemporaneous dialog
work that relies extensively on hand-coded rules,
typically either building statistical models on top
of heuristic rules or templates (levin et al., 2000;
young et al., 2010; walker et al., 2003; pieraccini
et al., 2009; wang et al., 2011) or learning genera-
tion rules from a minimal set of authored rules or
labels (oh and rudnicky, 2000; ratnaparkhi, 2002;
banchs and li, 2012; ameixa et al., 2014; nio et
al., 2014; chen et al., 2013). more recently (wen
et al., 2015) have used a long short-term memory
(lstm) (hochreiter and schmidhuber, 1997) to
learn from unaligned data in order to reduce the
heuristic space of sentence planning and surface
realization.

the smt model proposed by ritter et al., on
the other hand, is end-to-end, purely data-driven,
and contains no explicit model of dialog structure;
the model learns to converse from human-to-human
conversational corpora. progress in smt id30
from the use of neural language models (sutskever
et al., 2014; gao et al., 2014; bahdanau et al., 2015;
luong et al., 2015) has inspired efforts to extend
these neural techniques to smt-based conversa-
tional response generation. sordoni et al. (2015)
augments ritter et al.
(2011) by rescoring out-

puts using a id195 model conditioned on con-
versation history. other researchers have recently
used id195 to directly generate responses in an
end-to-end fashion without relying on smt phrase
tables (serban et al., 2015; shang et al., 2015;
vinyals and le, 2015). serban et al. (2015) propose
a hierarchical neural model aimed at capturing de-
pendencies over an extended conversation history.
recent work by li et al. (2016) measures mutual
information between message and response in or-
der to reduce the proportion of generic responses
typical of id195 systems. yao et al. (2015) em-
ploy an intention network to maintain the relevance
of responses.

modeling of users and speakers has been exten-
sively studied within the standard dialog model-
ing framework (e.g., (wahlster and kobsa, 1989;
kobsa, 1990; schatztnann et al., 2005; lin and
walker, 2011)). since generating meaningful re-
sponses in an open-domain scenario is intrinsi-
cally dif   cult in conventional id71, ex-
isting models often focus on generalizing character
style on the basis of qualitative statistical analysis
(walker et al., 2012; walker et al., 2011). the
present work, by contrast, is in the vein of the
id195 models of vinyals and le (2015) and li
et al. (2016), enriching these models by training
persona vectors directly from conversational data
and relevant side-information, and incorporating
these directly into the decoder.

3 sequence-to-sequence models
given a sequence of inputs x = {x1, x2, ..., xnx},
an lstm associates each time step with an input
gate, a memory gate and an output gate, respec-
tively denoted as it, ft and ot. we distinguish e
and h where et denotes the vector for an individual
text unit (for example, a word or sentence) at time
step t while ht denotes the vector computed by the
lstm model at time t by combining et and ht   1.
ct is the cell state vector at time t, and    denotes the
sigmoid function. then, the vector representation
ht for each time step t is given by:

             it

ft
ot
lt

             =

               

  
  
tanh

             w   

(cid:20) ht   1

(cid:21)

es
t

ct = ft    ct   1 + it    lt
t = ot    tanh(ct)
hs

(1)

(2)

(3)

where wi, wf , wo, wl     rk  2k.
in
id195 generation tasks, each input x is paired
with a sequence of outputs to predict: y =
{y1, y2, ..., yny }. the lstm de   nes a distribu-
tion over outputs and sequentially predicts tokens
using a softmax function:

p(y |x) =

=

ny(cid:89)
ny(cid:89)

t=1

t=1

(cid:80)

p(yt|x1, x2, ..., xt, y1, y2, ..., yt   1)

exp(f (ht   1, eyt))
y(cid:48) exp(f (ht   1, ey(cid:48)))

where f (ht   1, eyt) denotes the activation function
between ht   1 and eyt. each sentence terminates
with a special end-of-sentence symbol eos. in
keeping with common practices, inputs and out-
puts use different lstms with separate parameters
to capture different compositional patterns.

during decoding, the algorithm terminates when
an eos token is predicted. at each time step, either
a greedy approach or id125 can be adopted
for word prediction.

4 personalized response generation

our work introduces two persona-based models:
the speaker model, which models the personal-
ity of the respondent, and the speaker-addressee
model which models the way the respondent adapts
their speech to a given addressee     a linguistic phe-
nomenon known as lexical entrainment (deutsch
and pechmann, 1982).

4.1 notation
for the response generation task,
let m de-
note the input word sequence (message) m =
{m1, m2, ..., mi}. r denotes the word sequence in
response to m, where r = {r1, r2, ..., rj , eos}
and j is the length of the response (terminated
by an eos token). rt denotes a word token that
is associated with a k dimensional distinct word
embedding et. v is the vocabulary size.

4.2 speaker model
our    rst model is the speaker model, which mod-
els the respondent alone. this model represents
each individual speaker as a vector or embedding,
which encodes speaker-speci   c information (e.g.,
dialect, register, age, gender, personal informa-
tion) that in   uences the content and style of her
responses. note that these attributes are not ex-
plicitly annotated, which would be tremendously

expensive for our datasets. instead, our model man-
ages to cluster users along some of these traits (e.g.,
age, country of residence) based on the responses
alone.
figure 1 gives a brief illustration of the speaker
model. each speaker i     [1, n ] is associated with
a user-level representation vi     rk  1. as in stan-
dard id195 models, we    rst encode message
s into a vector representation hs using the source
lstm. then for each step in the target side, hidden
units are obtained by combining the representation
produced by the target lstm at the previous time
step, the word representations at the current time
step, and the speaker embedding vi:

             it

ft
ot
lt

             =

               

  
  
tanh

             w   

       ht   1

es
t
vi

      

(4)

ct = ft    ct   1 + it    lt
t = ot    tanh(ct)
hs

(5)
(6)
where w     r4k  3k. in this way, speaker informa-
tion is encoded and injected into the hidden layer at
each time step and thus helps predict personalized
responses throughout the generation process. the
speaker embedding {vi} is shared across all con-
versations that involve speaker i. {vi} are learned
by back propagating word prediction errors to each
neural component during training.

another useful property of this model is that it
helps infer answers to questions even if the evi-
dence is not readily present in the training set. this
is important as the training data does not contain ex-
plicit information about every attribute of each user
(e.g., gender, age, country of residence). the model
learns speaker representations based on conversa-
tional content produced by different speakers, and
speakers producing similar responses tend to have
similar embeddings, occupying nearby positions
in the vector space. this way, the training data of
speakers nearby in vector space help increase the
generalization capability of the speaker model. for
example, consider two speakers i and j who sound
distinctly british, and who are therefore close in
speaker embedding space. now, suppose that, in
the training data, speaker i was asked where do
you live? and responded in the uk. even if speaker
j was never asked the same question, this answer
can help in   uence a good response from speaker
j, and this without explicitly labeled geo-location
information.

figure 1: illustrative example of the speaker model introduced in this work. speaker ids close in embedding space tend to
respond in the same manner. these speaker embeddings are learned jointly with id27s and all other parameters of
the neural model via id26. in this example, say rob is a speaker clustered with people who often mention england
in the training data, then the generation of the token    england    at time t = 2 would be much more likely than that of    u.s.   . a
non-persona model would prefer generating in the u.s. if    u.s.    is more represented in the training data across all speakers.

4.3 speaker-addressee model
a natural extension of the speaker model is a
model that is sensitive to speaker-addressee inter-
action patterns within the conversation. indeed,
speaking style, register, and content does not vary
only with the identity of the speaker, but also with
that of the addressee. for example, in scripts for
the tv series friends used in some of our exper-
iments, the character ross often talks differently
to his sister monica than to rachel, with whom
he is engaged in an on-again off-again relationship
throughout the series.

the proposed speaker-addressee model oper-
ates as follows: we wish to predict how speaker i
would respond to a message produced by speaker j.
similarly to the speaker model, we associate each
speaker with a k dimensional speaker-level repre-
sentation, namely vi for user i and vj for user j. we
obtain an interactive representation vi,j     rk  1
by linearly combining user vectors vi and vj in
an attempt to model the interactive style of user i
towards user j,

vi,j = tanh(w1    vi + w2    v2)

(7)
where w1, w2     rk  k. vi,j is then linearly in-
corporated into lstm models at each step in the

target:             it

ft
ot
lt

             =

               

  
  
tanh

             w   

       ht   1

es
t
vi,j

      

(8)

ct = ft    ct   1 + it    lt
t = ot    tanh(ct)
hs

(9)

(10)

vi,j depends on both speaker and addressee and
the same speaker will thus respond differently to
a message from different interlocutors. one po-
tential issue with speaker-addressee modelling is
the dif   culty involved in collecting a large-scale
training dataset in which each speaker is involved
in conversation with a wide variety of people.
like the speaker model, however, the speaker-
addressee model derives generalization capabil-
ities from speaker embeddings. even if the two
speakers at test time (i and j) were never involved
in the same conversation in the training data, two
speakers i(cid:48) and j(cid:48) who are respectively close in
embeddings may have been, and this can help mod-
elling how i should respond to j.

4.4 decoding and reranking
for decoding, the n-best lists are generated us-
ing the decoder with beam size b = 200. we set a
maximum length of 20 for the generated candidates.
decoding operates as follows: at each time step,
we    rst examine all b    b possible next-word can-
didates, and add all hypothesis ending with an eos
token to the n-best list. we then preserve the top-b
un   nished hypotheses and move to the next word
position.

to deal with the issue that id195 models
tend to generate generic and commonplace re-
sponses such as i don   t know, we follow li et al.
(2016) by reranking the generated n-best list using

eosrobid27s(50k)englandlondonu.s.greatgoodstayliveokaymondaytuesdayspeaker embeddings(70k)rob_712wheredoyouliveininrobenglandrobengland.rob.eossourcetargetskinnyoflynny2tomcoatezkush_322d_gomes25dreamswallskierongillen5thecharliezthe_football_barthis_is_artfuldigitaldan285jinnmeow3bob_kelly2a scoring function that linearly combines a length
penalty and the log likelihood of the source given
the target:

log p(r|m, v) +    log p(m|r) +   |r|

(11)
where p(r|m, v) denotes the id203 of the
generated response given the message m and the
respondent   s speaker id. |r| denotes the length
of the target and    denotes the associated penalty
weight. we optimize    and    on n-best lists of
response candidates generated from the develop-
ment set using mert (och, 2003) by optimizing
id7. to compute p(m|r), we train an inverse
id195 model by swapping messages and re-
sponses. we trained standard id195 models for
p(m|r) with no speaker information considered.
5 datasets
5.1 twitter persona dataset
data collection training data for the speaker
model was extracted from the twitter firehose for
the six-month period beginning january 1, 2012.
we limited the sequences to those where the respon-
ders had engaged in at least 60 (and at most 300)
3-turn conversational interactions during the period,
in other words, users who reasonably frequently en-
gaged in conversation. this yielded a set of 74,003
users who took part in a minimum of 60 and a max-
imum of 164 conversational turns (average: 92.24,
median: 90). the dataset extracted using responses
by these    conversationalists    contained 24,725,711
3-turn sliding-window (context-message-response)
conversational sequences.

in addition, we sampled 12000 3-turn conversa-
tions from the same user set from the twitter fire-
hose for the three-month period beginning july 1,
2012, and set these aside as development, valida-
tion, and test sets (4000 conversational sequences
each). note that development, validation, and test
sets for this data are single-reference, which is by
design. multiple reference responses would typ-
ically require acquiring responses from different
people, which would confound different personas.
training protocols we
four-layer
id195 models on the twitter corpus following
the approach of (sutskever et al., 2014). details
are as follows:

trained

    4 layer lstm models with 1,000 hidden cells
    batch size is set to 128.

for each layer.

the uniform distribution [   0.1, 0.1].

    learning rate is set to 1.0.
    parameters are initialized by sampling from
    gradients are clipped to avoid gradient explo-
sion with a threshold of 5.
    vocabulary size is limited to 50,000.
    dropout rate is set to 0.2.

source and target lstms use different sets of pa-
rameters. we ran 14 epochs, and training took
roughly a month to    nish on a tesla k40 gpu
machine.

as only speaker ids of responses were speci   ed
when compiling the twitter dataset, experiments
on this dataset were limited to the speaker model.

5.2 twitter sordoni dataset
the twitter persona dataset was collected for this
paper for experiments with speaker id informa-
tion. to obtain a point of comparison with prior
state-of-the-art work (sordoni et al., 2015; li et
al., 2016), we measure our baseline (non-persona)
lstm model against prior work on the dataset
of (sordoni et al., 2015), which we call the twit-
ter sordoni dataset. we only use its test-set por-
tion, which contains responses for 2114 context
and messages. it is important to note that the sor-
doni dataset offers up to 10 references per message,
while the twitter persona dataset has only 1 refer-
ence per message. thus id7 scores cannot be
compared across the two twitter datasets (id7
scores on 10 references are generally much higher
than with 1 reference). details of this dataset are
in (sordoni et al., 2015).

5.3 television series transcripts
data collection for
the dyadic speaker-
addressee model we used scripts from the
american television comedies friends2 and the
big bang theory,3 available from internet movie
script database (imsdb).4 we collected 13
main characters from the two series in a corpus
of 69,565 turns. we split the corpus into train-
ing/development/testing sets, with development
and testing sets each of about 2,000 turns.
training since the relatively small size of the
dataset does not allow for training an open domain
dialog model, we adopted a domain adaption strat-
egy where we    rst trained a standard id195
2https://en.wikipedia.org/wiki/friends
3https://en.wikipedia.org/wiki/the_

big_bang_theory

4http://www.imsdb.com

system
mt baseline (ritter et al., 2011)
standard lstm mmi (li et al., 2016)
standard lstm mmi (our system)
human

id7
3.60%
5.26%
5.82%
6.08%

table 2: id7 on the twitter sordoni dataset (10 references).
we contrast our baseline against an smt baseline (ritter et al.,
2011), and the best result (li et al., 2016) on the established
dataset of (sordoni et al., 2015). the last result is for a human
oracle, but it is not directly comparable as the oracle id7 is
computed in a leave-one-out fashion, having one less reference
available. we nevertheless provide this result to give a sense
that these id7 scores of 5-6% are not unreasonable.

models using a much larger opensubtitles (osdb)
dataset (tiedemann, 2009), and then adapting the
pre-trained model to the tv series dataset.

the osdb dataset is a large, noisy, open-domain
dataset containing roughly 60m-70m scripted lines
spoken by movie characters. this dataset does not
specify which character speaks each subtitle line,
which prevents us from inferring speaker turns. fol-
lowing vinyals et al. (2015), we make the simplify-
ing assumption that each line of subtitle constitutes
a full speaker turn.5 we trained standard id195
models on osdb dataset, following the protocols
already described in section 5.1. we run 10 itera-
tions over the training set.

we initialize id27s and lstm pa-
rameters in the speaker model and the speaker-
addressee model using parameters learned from
opensubtitles datasets. user embeddings are ran-
domly initialized from [   0.1, 0.1]. we then ran 5
additional epochs until the perplexity on the devel-
opment set stabilized.

6 experiments
6.1 evaluation
following (sordoni et al., 2015; li et al., 2016)
we used id7 (papineni et al., 2002) for parame-
ter tuning and evaluation. id7 has been shown
to correlate well with human judgment on the re-
sponse generation task, as demonstrated in (galley
et al., 2015). besides id7 scores, we also report
perplexity as an indicator of model capability.

6.2 baseline
since our main experiments are with a new dataset
(the twitter persona dataset), we    rst show that
our lstm baseline is competitive with the state-of-

5this introduces a degree of noise as consecutive lines are
not necessarily from the same scene or two different speakers.

model

perplexity

standard lstm speaker model
42.2 (   10.6%)

47.2

table 3: perplexity for standard id195 and the speaker
model on the twitter persona development set.

model
standard lstm id113
speaker model id113
standard lstm mmi
speaker model mmi

objective id7
0.92%
1.12% (+21.7%)
1.41%
1.66% (+11.7%)

table 4: id7 on the twitter persona dataset (1 reference),
for the standard id195 model and the speaker model using
as objective either maximum likelihood (id113) or maximum
mutual information (mmi).

the-art (li et al., 2016) on an established dataset,
the twitter sordoni dataset (sordoni et al., 2015).
our baseline is simply our implementation of the
lstm-mmi of (li et al., 2016), so results should
be relatively close to their reported results. table 2
summarizes our results against prior work. we see
that our system actually does better than (li et al.,
2016), and we attribute the improvement to a larger
training corpus, the use of dropout during training,
and possibly to the    conversationalist    nature of
our corpus.

6.3 results
we    rst report performance on the twitter persona
dataset. perplexity is reported in table 3. we ob-
serve about a 10% decrease in perplexity for the
speaker model over the standard id195 model.
in terms of id7 scores (table 4), a signi   cant per-
formance boost is observed for the speaker model
over the standard id195 model, yielding an in-
crease of 21% in the maximum likelihood (id113)
setting and 11.7% for mutual information setting
(mmi). in line with    ndings in (li et al., 2016), we
observe a consistent performance boost introduced
by the mmi objective function over a standard
id195 model based on the id113 objective func-
tion. it is worth noting that our persona models
are more bene   cial to the id113 models than to the
mmi models. this result is intuitive as the persona
models help make standard lstm id113 outputs
more informative and less bland, and thus make the
use of mmi less critical.

for the tv series dataset, perplexity and id7
scores are respectively reported in table 5 and ta-
ble 6. as can be seen, the speaker and speaker-
addressee models respectively achieve perplexity
values of 25.4 and 25.0 on the tv-series dataset,

model

perplexity

standard lstm speaker model speaker-addressee model

25.4 (   7.0%)

25.0 (   8.4%)

27.3

table 5: perplexity for standard id195 and persona models on the tv series dataset.

model standard lstm speaker model
1.82% (+13.7%)
id113
mmi
1.90% (+10.6%)

1.60%
1.70%

speaker-addressee model

1.83% (+14.3%)
1.88% (+10.9%)

table 6: id7 on the tv series dataset (1 reference), for the standard id195 and persona models.

7.0% and 8.4% percent lower than the correspon-
dent standard id195 models. in terms of id7
score, we observe a similar performance boost
as on the twitter dataset, in which the speaker
model and the speaker-addressee model outper-
form the standard id195 model by 13.7% and
10.6%. by comparing the speaker-addressee
model against the speaker model on the tv se-
ries dataset, we do not observe a signi   cant dif-
ference. we suspect that this is primarily due to
the relatively small size of the dataset where the
interactive patterns might not be fully captured.
smaller values of perplexity are observed for the
television series dataset than the twitter dataset,
the perplexity of which is over 40, presumably due
to the noisier nature of twitter dialogues.

6.4 qualitative analysis
diverse responses by different speakers ta-
ble 7 represents responses generated by persona
models in response to three different input ques-
tions. we randomly selected 10 speakers (without
cherry-picking) from the original twitter dataset.
we collected their user level representations from
a speaker look-up table and integrated them into
the decoding models. the model tends to generate
speci   c responses for different people in response
to the factual questions.6

table 8 shows responses generated from the
speaker-addressee model using the tv-series
dataset. interestingly, we regularly observe that
this model is sensitive to the identity of the ad-
dressee, generating words speci   cally targeted at
that addressee (e.g., her name). for example, the
model produces of course, i love you, emily in
response to an input from emily. also, the model
generates of course i love you. ( kisses him), where
the pronoun    him    accurately identi   es the gender
of the addressee.

6there appears to be a population bias in the training set

that favors british users.

message where is your hometown?
baseline

i was born in canada.

user1 i   m from england.
user2 i   m from manchester.
user3 i   m from liverpool.
user4 england. you?
user5 my hometown.
user6 i   m from texas.
user7 i   m from la.
user8 england.
user9 i was born here.
user10 i was born in the us.

message what company do you work for?
baseline

i work for a company.

user1 i don   t have a job.
user2 i   m a manager.
user3 i   m working. #
user4 i work for a company.
user5 i   m working. #
user6 customer service.
user7 i work in retail.
user8 i work in a cafe.
user9 i work at a gas station.
user10 i don   t know #

message what did you have for dinner?
baseline

i had    sh and chips.

user1 i had spag bol.
user2 chicken and chips.
user3 chicken and rice.
user4 fish and chips.
user5 i had spag bol.
user6 i had mexican food.
user7 salad...
user8 i had chicken and chips.
user9 i had spag bol.
user10 pizza.

table 7: responses generated by the baseline (lstm-mmi)
and the speaker model for ten randomly selected users, with-
out cherry picking. # indicates poor-quality responses pro-
duced by the system.

human evaluation we conducted a human eval-
uation of outputs from the speaker model, using
a id104 service. since we cannot expect
crowdsourced human judges to know or attempt to
learn the ground truth of twitter users who are not
well-known public    gures, we designed our experi-
ment to evaluate the consistency of outputs associ-
ated with the speaker ids. to this end, we collected
24 pairs of questions for which we would expect

message do you love me?
baseline of course, i love you.

addressee: emily, speaker: sheldon

response of course, i love you, emily.

addressee: emily, speaker: penny

response of course, i love you, emily.

addressee: leonard, speaker: penny

response of course, i love you, leonard.

addressee: monica, speaker: chandler

response of course i love you. i want to marry you.

addressee: rachel, speaker: chandler

response of course i love you.

addressee: ross, speaker: chandler

response of course i love you.

addressee: ross, speaker: rachel
response of course i love you. (kisses him)
addressee: emily, speaker: rachel

response of course i love you.

table 8: responses to do you love me? from the speaker-
addressee model on the tv-series dataset using different ad-
dressees and speakers.

responses to be consistent if the persona model is
coherent. for example, responses to the questions
what country do you live in? and what city do you
live in? would be considered consistent if the an-
swers were england and london respectively, but
not if they were uk and chicago. similarly, the
responses to are you vegan or vegetarian? and do
you eat beef? are consistent if the answers gener-
ated are vegan and absolutely not, but not if they
are vegan and i love beef. we collected 20 pairs of
outputs for randomly-selected personas provided
by the speaker model for each question pair (480
response pairs total). we also obtained the corre-
sponding outputs from the baseline mmi-enhanced
id195 system.

since our purpose is to measure the gain in con-
sistency over the baseline system, we presented the
pairs of answers system-pairwise, i.e., 4 responses,
2 from each system, displayed on the screen, and
asked judges to decide which of the two systems
was more consistent. the position in which the
system pairs were presented on the screen was ran-
domized. the two systems were judged on 5-point
zero-sum scale, assigning a score of 2 (-2) if one
system was judged more (less) consistent than the
other, and 1 (-1) if one was rated    somewhat    more
(less) consistent. ties were assigned a score of zero.
five judges rated each pair and their scores were
averaged and remapped into 5 equal-width bins.
after discarding ties, we found the persona model
was judged either    more consistent    or    somewhat
more consistent    in 56.7% of cases. if we ignore
the    somewhat more consistent    judgments, the
persona model wins in 6.1% of cases, compared

user1

i   m from england.

i   m from england.
in which city do you live now?
i live in london.
in which country do you live now?
i live in england.

message where is your hometown?
response
message where are you from?
response
message
response
message
response
message what is your major?
response business. you?
message what did you study in college?
response
message how old are you?
response
message what is your age?
response
user2

i did business studies.

i   m 18.

i   m 18.

i live in indonesia.

in which city do you live now?
i live in jakarta.
in which country do you live now?
i live in indonesia.

message where is your hometown?
response
message where are you from?
response england, you?
message
response
message
response
message what is your major?
response business, you?
message what did you study in college?
response psychology, you?
message how old are you?
response
message what is your age?
response

i   m 18.

i   m 16.

table 9: examples of speaker consistency and inconsistency
generated by the speaker model

with only 1.6% for the baseline model. it should
be emphasized that the baseline model is a strong
baseline, since it represents the consensus of all
70k twitter users in the dataset7.

table 9 illustrates how consistency is an emer-
gent property of two arbitrarily selected users. the
model is capable of discovering the relations be-
tween different categories of location such as lon-
don and the uk, jakarta and indonesia. however,
the model also makes inconsistent response de-
cisions, generating different answers in the sec-
ond example in response to questions asking about
age or major. our proposed persona models inte-
grate user embeddings into the lstm, and thus
can be viewed as encapsulating a trade-off between
a persona-speci   c generation model and a general
conversational model.

7i   m not pregnant is an excellent consensus answer to the
question are you pregnant?, while i   m pregnant is consistent
as a response only in the case of someone who also answers
the question are you a guy or a girl? with something in the
vein of i   m a girl.

7 conclusions

we have presented two persona-based response
generation models for open-domain conversation
generation. there are many other dimensions of
speaker behavior, such as mood and emotion, that
are beyond the scope of the current paper and must
be left to future work.

although the gains presented by our new mod-
els are not spectacular, the systems outperform our
baseline id195 systems in terms of id7, per-
plexity, and human judgments of speaker consis-
tency. we have demonstrated that by encoding
personas in distributed representations, we are able
to capture personal characteristics such as speaking
style and background information. in the speaker-
addressee model, moreover, the evidence suggests
that there is bene   t in capturing dyadic interactions.
our ultimate goal is to be able to take the pro-
   le of an arbitrary individual whose identity is
not known in advance, and generate conversations
that accurately emulate that individual   s persona
in terms of linguistic response behavior and other
salient characteristics. such a capability will dra-
matically change the ways in which we interact
with dialog agents of all kinds, opening up rich
new possibilities for user interfaces. given a suf   -
ciently large training corpus in which a suf   ciently
rich variety of speakers is represented, this objec-
tive does not seem too far-fetched.

acknowledgments

we with to thank stephanie lukin, pushmeet kohli,
chris quirk, alan ritter, and dan jurafsky for
helpful discussions.

references
david ameixa, luisa coheur, pedro fialho, and paulo
quaresma. 2014. luke, i am your father: dealing
with out-of-domain requests by using movies sub-
in intelligent virtual agents, pages 13   21.
titles.
springer.

dzmitry bahdanau, kyunghyun cho, and yoshua ben-
gio. 2015. id4 by jointly
learning to align and translate. in proc. of the inter-
national conference on learning representations
(iclr).

rafael e banchs and haizhou li. 2012. iris: a chat-
oriented dialogue system based on the vector space
model. in proc. of the acl 2012 system demonstra-
tions, pages 37   42.

yun-nung chen, wei yu wang, and alexander rud-
nicky. 2013. an empirical investigation of sparse
id148 for improved dialogue act classi   -
cation. in acoustics, speech and signal processing
(icassp), 2013 ieee international conference on,
pages 8317   8321. ieee.

werner deutsch and thomas pechmann. 1982. social
interaction and the development of de   nite descrip-
tions. cognition, 11:159   184.

michel galley, chris brockett, alessandro sordoni,
yangfeng ji, michael auli, chris quirk, margaret
mitchell, jianfeng gao, and bill dolan.
2015.
   id7: a discriminative metric for generation
in proc. of
tasks with intrinsically diverse targets.
acl-ijcnlp, pages 445   450, beijing, china, july.

jianfeng gao, xiaodong he, wen-tau yih, and li deng.
2014. learning continuous phrase representations
in proc. of acl, pages
for translation modeling.
699   709, baltimore, maryland.

sepp hochreiter and j  urgen schmidhuber.

1997.
neural computation,

long short-term memory.
9(8):1735   1780.

alfred kobsa. 1990. user modeling in id71:
potentials and hazards. ai & society, 4(3):214   231.

esther levin, roberto pieraccini, and wieland eckert.
2000. a stochastic model of human-machine inter-
action for learning dialog strategies. ieee transac-
tions on speech and audio processing, 8(1):11   23.

jiwei li, michel galley, chris brockett, jianfeng gao,
and bill dolan. 2016. a diversity-promoting ob-
jective function for neural conversation models. in
proc. of naacl-hlt.

grace i lin and marilyn a walker. 2011. all the
world   s a stage: learning character models from
in proceedings of the seventh aaai confer-
   lm.
ence on arti   cial intelligence and interactive digi-
tal entertainment (aiide).

thang luong, ilya sutskever, quoc le, oriol vinyals,
and wojciech zaremba. 2015. addressing the rare
word problem in id4. in proc.
of acl, pages 11   19, beijing, china, july.

lasguido nio, sakriani sakti, graham neubig, tomoki
toda, mirna adriani, and satoshi nakamura. 2014.
developing non-goal dialog system based on exam-
ples of drama television. in natural interaction with
robots, knowbots and smartphones, pages 355   361.
springer.

franz josef och. 2003. minimum error rate training in
id151. in proceedings of the
41st annual meeting of the association for compu-
tational linguistics, pages 160   167, sapporo, japan,
july. association for computational linguistics.

marilyn a walker, rashmi prasad, and amanda stent.
2003. a trainable generator for recommendations in
multimodal dialog. in interspeech.

marilyn a walker, ricky grant, jennifer sawyer,
grace i lin, noah wardrip-fruin, and michael
buell. 2011. perceived or not perceived: film char-
acter models for expressive id86. in interactive story-
telling, pages 109   121. springer.

marilyn a walker, grace i lin, and jennifer sawyer.
2012. an annotated corpus of    lm dialogue for
learning and characterizing character style.
in
lrec, pages 1373   1378.

william yang wang, ron artstein, anton leuski, and
improving spoken dialogue
in

david traum. 2011.
understanding using phonetic mixture models.
flairs conference.

tsung-hsien wen, milica gasic, nikola mrk  si  c, pei-
hao su, david vandyke, and steve young. 2015.
semantically conditioned lstm-based natural lan-
guage generation for spoken dialogue systems.
in
proc. of emnlp, pages 1711   1721, lisbon, portu-
gal, september. association for computational lin-
guistics.

kaisheng yao, geoffrey zweig, and baolin peng.
2015. attention with intention for a neural network
conversation model. corr, abs/1510.08565.

steve young, milica ga  si  c, simon keizer, franc  ois
mairesse, jost schatzmann, blaise thomson, and
kai yu. 2010. the hidden information state model:
a practical framework for pomdp-based spoken dia-
logue management. computer speech & language,
24(2):150   174.

alice h oh and alexander i rudnicky. 2000. stochas-
tic language generation for spoken dialogue systems.
in proceedings of the 2000 anlp/naacl workshop
on conversational systems-volume 3, pages 27   32.

kishore papineni, salim roukos, todd ward, and wei-
jing zhu. 2002. id7: a method for automatic
evaluation of machine translation. in proc. of acl,
pages 311   318.

roberto pieraccini, david suendermann, krishna
dayanidhi, and jackson liscombe. 2009. are we
there yet? research in commercial spoken dialog
systems. in text, speech and dialogue, pages 3   13.
springer.

adwait ratnaparkhi. 2002. trainable approaches to
surface id86 and their appli-
cation to conversational id71. computer
speech & language, 16(3):435   455.

alan ritter, colin cherry, and william b dolan. 2011.
data-driven response generation in social media. in
proceedings of the conference on empirical meth-
ods in natural language processing, pages 583   
593.

jost schatztnann, matthew n stuttle, karl weilham-
mer, and steve young.
effects of the
user model on simulation-based learning of dialogue
strategies. in automatic id103 and un-
derstanding, 2005 ieee workshop on, pages 220   
225.

2005.

iulian v serban, alessandro sordoni, yoshua bengio,
aaron courville, and joelle pineau. 2015. building
end-to-end dialogue systems using generative hierar-
chical neural network models. in proc. of aaai.

lifeng shang, zhengdong lu, and hang li. 2015.
neural responding machine for short-text conversa-
tion. in acl-ijcnlp, pages 1577   1586.

alessandro sordoni, michel galley, michael auli,
chris brockett, yangfeng ji, meg mitchell, jian-yun
nie, jianfeng gao, and bill dolan. 2015. a neural
network approach to context-sensitive generation of
conversational responses. in proc. of naacl-hlt.

ilya sutskever, oriol vinyals, and quoc v le. 2014.
sequence to sequence learning with neural networks.
in advances in neural information processing sys-
tems (nips), pages 3104   3112.

j  org tiedemann. 2009. news from opus     a collec-
tion of multilingual parallel corpora with tools and
interfaces. in recent advances in natural language
processing, volume 5, pages 237   248.

oriol vinyals and quoc le. 2015. a neural conver-
in proc. of icml deep learning

sational model.
workshop.

wolfgang wahlster and alfred kobsa. 1989. user

models in id71. springer.

