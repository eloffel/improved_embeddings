6
1
0
2

 
r
p
a
6

 

 
 
]
l
c
.
s
c
[
 
 

1
v
6
9
6
1
0

.

4
0
6
1
:
v
i
x
r
a

acorpusandclozeevaluationfordeeperunderstandingofcommonsensestoriesnasrinmostafazadeh1,nathanaelchambers2,xiaodonghe3,deviparikh4,dhruvbatra4,lucyvanderwende3,pushmeetkohli3,jamesallen1,51universityofrochester,2unitedstatesnavalacademy,3microsoftresearch,4virginiatech,5theinstituteforhuman&machinecognition{nasrinm,james}@cs.rochester.edu,nchamber@usna.edu,{parikh,dbatra}@vt.edu,{xiaohe,lucyv,pkohli}@microsoft.comabstractrepresentationandlearningofcommonsenseknowledgeisoneofthefoundationalprob-lemsinthequesttoenabledeeplanguageun-derstanding.thisissueisparticularlychal-lengingforunderstandingcasualandcorre-lationalrelationshipsbetweenevents.whilethistopichasreceivedalotofinterestinthenlpcommunity,researchhasbeenhinderedbythelackofaproperevaluationframework.thispaperattemptstoaddressthisproblemwithanewframeworkforevaluatingstoryunderstandingandscriptlearning:the   storyclozetest   .thistestrequiresasystemtochoosethecorrectendingtoafour-sentencestory.wecreatedanewcorpusof50k   ve-sentencecommonsensestories,rocsto-ries,toenablethisevaluation.thiscorpusisuniqueintwoways:(1)itcapturesarichsetofcausalandtemporalcommonsenserelationsbetweendailyevents,and(2)itisahighqual-itycollectionofeverydaylifestoriesthatcanalsobeusedforstorygeneration.experimen-talevaluationshowsthatahostofbaselinesandstate-of-the-artmodelsbasedonshallowlanguageunderstandingstruggletoachieveahighscoreonthestoryclozetest.wediscusstheseimplicationsforscriptandstorylearn-ing,andoffersuggestionsfordeeperlanguageunderstanding.1introductionstoryunderstandingisanextremelychallengingtaskinnaturallanguageunderstandingwithalong-runninghistoryinai(charniak,1972;winograd,1972;turner,1994;schubertandhwang,2000).recently,therehasbeenarenewedinterestinstoryandnarrativeunderstandingbasedonprogressmadeincorenlptasks.thisrangesfromgenericstorytellingmodelstobuildingsystemswhichcancom-posemeaningfulstoriesincollaborationwithhu-mans(swansonandgordon,2008).perhapsthebiggestchallengeofstoryunderstanding(andstorygeneration)ishavingcommonsenseknowledgefortheinterpretationofnarrativeevents.thequestionishowtoprovidecommonsenseknowledgeregard-ingdailyeventstomachines.alargebodyofworkinstoryunderstandinghasfocusedonlearningscripts(schankandabel-son,1977).scriptsrepresentstructuredknowledgeaboutstereotypicaleventsequencestogetherwiththeirparticipants.itisevidentthatvariousnlpapplications(textsummarization,co-referenceres-olution,questionanswering,etc.)canhugelyben-e   tfromtherichinferentialcapabilitiesthatstruc-turedknowledgeabouteventscanprovide.giventhatdevelopinghand-builtscriptsisextremelytime-consuming,thereisaseriousneedforautomati-callyinducedscripts.mostrelevanttothisissueisworkonunsupervisedlearningof   narrativechains   (chambersandjurafsky,2008)andeventschemas(chambersandjurafsky,2009;balasubramanianetal.,2013;cheungetal.,2013;nguyenetal.,2015).the   rstrequirementofanylearneristodecideonacorpustodrivethelearningprocess.wearefore-mostinterestedinaresourcethatisfulloftemporalandcausalrelationsbetweeneventsbecausecausal-ityisacentralcomponentofcoherency.personalstoriesfromdailyweblogsaregoodsourcesofcom-monsensecausalinformation(gordonandswan-son,2009;manshadietal.,2008),butteasingoutusefulinformationfromnoisyblogentriesisaprob-lemofitsown.considerthefollowingsnippetfromicwsm2011spinn3rdatasetofweblogentries(burtonetal.,2009):   ihadaninterestingdayinthestudiotoday.itwassoin-terestingthatitookpicturesalongthewaytodescribeittoyou.sometimesiliketoreadanautobiography/biographytodiscoverhowsomeonegotfromtheretohere.....howtheystarted,howtheytraveledinmindandspirit,whatmadethemwhotheyarenow.well,today,myworkwasalittlelikethat.   thistextisfullofdiscoursecomplexities.ahostofchallenginglanguageunderstandingtasksarere-quiredtogetatthecommonsenseknowledgeem-beddedwithinsuchtextsnippets.whatisneededisasimpli   edversionofthesenarratives.thispa-perintroducesanewcorpusofsuchshortcommon-sensestories.withcarefulpromptdesignandmul-tiplephasesofqualitycontrol,wecollected50khighquality   ve-sentencestoriesthatarefullofstereotypicalcausalandtemporalrelationsbetweenevents.thecorpusnotonlyservesasaresourceforlearningcommonsensenarrativeschemas,butisalsosuitablefortrainingstorygenerationmodels.wede-scribethiscorpusindetailinsection3.thisnewcorpusalsoaddressesaproblemfacingscriptlearningoverthepastfewyears.despitetheattentionscriptshavereceived,progresshasbeenin-hibitedbythelackofasystematicevaluationframe-work.acommonlyusedevaluationisthe   narra-tiveclozetest   (chambersandjurafsky,2008)inwhichasystempredictsaheld-outevent(averbanditsarguments)givenasetofobservedevents.forexample,thefollowingisonesuchtestwithamissingevent:{xthrew,pulledx,toldx,???,xcompleted}1.asisoftenthecase,severalworksnowoptimizetothisspeci   ctest,achievinghigherscoreswithshallowtechniques.thisisproblematicbecausethemodelsoftenarenotlearningcommon-senseknowledge,butratherhowtobeattheshallowtest.thispaperthusintroducesanewevaluationframeworkcalledthestoryclozetest.insteadofpredictinganevent,thesystemistaskedwithchoos-inganentiresentencetocompletethegivenstory.1narrativeclozetestswerenotmeanttobehumansolvable.wecollected3,742doublyveri   edstoryclozetestcases.thetestisdescribedindetailinsection4.finally,thispaperproposesseveralmodels,in-cludingthemostrecentstate-of-the-artapproachesforthenarrativeclozetest,fortacklingthestoryclozetest.theresultsstronglysuggestthatachiev-ingbetterthanrandomorconstant-chooseperfor-mancerequiresrichersemanticrepresentationofeventstogetherwithdeeperlevelsofmodelingthesemanticspaceofstories.webelievethatswitchingtothestoryclozetestastheempiricalevaluationframeworkforstoryunderstandingandscriptlearn-ingcanhelpdirectthe   eldtoanewdirectionofdeeperlanguageunderstanding.2relatedworkseverallinesofresearchhaverecentlyfocusedonlearningnarrative/eventrepresentations.chambersandjurafsky   rstproposednarrativechains(cham-bersandjurafsky,2008)asapartiallyorderedsetofnarrativeeventsthatshareacommonactorcalledthe   protagonist   .anarrativeeventisatupleofanevent(averb)anditsparticipantsrepresentedastypeddependencies.severalexpansionshavesincebeenproposed,includingnarrativeschemas(cham-bersandjurafsky,2009),scriptsequences(regnerietal.,2010),andrelgrams(balasubramanianetal.,2013).formalprobabilisticmodelshavealsobeenproposedtolearneventschemasandframes(che-ungetal.,2013;bammanetal.,2013;chambers,2013;nguyenetal.,2015).thesearetrainedonsmallercorporaandfocuslessonlarge-scalelearn-ing.amajorshortcomingsofaristhatthesemodelsaremainlytrainedonnewsarticles.littleknowl-edgeabouteverydaylifeeventsarelearned.severalgroupshavedirectlyaddressedscriptlearningbyfocusingexclusivelyonthenarrativeclozetest.jansetal.(jansetal.,2012)rede   nedthetesttobeatextorderedsequenceofevents,whereastheoriginaldidnotrelyontextorder(chambersandjurafsky,2008).sincethen,oth-ershaveshownlanguage-modelingtechniquesper-formwell(pichottaandmooney,2014a;rudingeretal.,2015).thispapershowsthattheseapproachesstruggleonthericherstoryclozeevaluation.therehasalsobeenrenewedattentiontowardnaturallanguagecomprehensionandcommonsensereasoning(levesque,2011;roemmeleetal.,2011;bowmanetal.,2015).thereareafewrecentframe-worksforevaluatinglanguagecomprehension(her-mannetal.,2015;westonetal.,2015),includingthemctest(richardsonetal.,2013)asanotableone.theirframeworkalsoinvolvesstorycompre-hension,however,theirstoriesaremostly   ctional,onaverage212words,andgearedtowardchildreningrades1-4.someprogresshasbeenmadeinstoryunderstandingbylimitingthetasktothespeci   cdo-mainsandquestiontypes.thisincludesresearchonunderstandingnewswireinvolvingterrorismscripts(mueller,2002),storiesaboutpeopleinarestau-rantwhereareasonablenumberofquestionsabouttimeandspacecanbeanswered(mueller,2007),andgeneratingstoriesfromfairytales(mcintyreandlapata,2009).finally,thereisarichbodyofworkonstoryplotgenerationandcreativeorartisticstorytelling(m  endezetal.,2014;riedlandle  on,2008).thispaperisuniquetotheseinitscorpusofshort,simplestorieswithawidevarietyofcommonsenseevents.weshowthesetobeusefulforlearning,butalsoforenablingarichevaluationframeworkfornarrativeunderstanding.3acorpusofshortcommonsensestoriesweaimedtobuildacorpuswithtwogoalsinmind:1.thecorpuscontainsavarietyofcommonsensecausalandtemporalrelationsbetweenevery-dayevents.thisenableslearningnarrativestructureacrossarangeofevents,asopposedtoasingledomainorgenre.2.thecorpusisahighqualitycollectionofnon-   ctionaldailyshortlifestories,whichcanbeusedfortrainingrichcoherentstory-tellingmodels.inordertonarrowdownourfocus,wecarefullyde   neanarrativeorstoryasfollows:   anarrativeorstoryisanythingwhichistoldintheformofacausally(logically)linkedsetofeventsinvolv-ingsomesharedcharacters   .theclassicde   nitionofastoryrequireshavingaplot,(e.g.,acharac-terfollowingagoalandfacingobstacles),however,herewearenotconcernedwithhowentertainingordramaticthestoriesare.instead,wearecon-cernedwiththeessenceofactuallybeingalogi-callymeaningfulstory.wefollowthenotionof   storiness   (forster,1927;bailey,1999),whichisdescribedas   theexpectationsandquestionsthatareadermayhaveasthestorydevelops   ,whereexpectationsare   common-senselogicalid136s   madebytheimaginedreaderofthestory.weproposetosatisfyourtwogoalsbyaskinghundredsofworkersonamazonmechanicalturk(amt)towritenovel   ve-sentencestories.the   ve-sentencelengthgivesenoughcontexttothestorywithoutallowingroomforsidetracksaboutlessim-portantorirrelevantinformationinthestory.inthissectionwedescribethedetailsabouthowwecol-lectedthiscorpus,andprovidestatisticalanalysis.3.1datacollectionmethodologyid104thiscorpusmakesthedatacollec-tionscalableandaddstothediversityofstories.wetestednumerouspilotswithvaryingpromptsandin-structions.wemanuallycheckedthesubmittedsto-riesineachpilotandcountedthenumberofsub-missionswhichdidnothaveourdesiredlevelofco-herencyorwerespeci   cally   ctionaloroffensive.threepeopleparticipatedinthistaskandtheyiter-atedovertheratingsuntileveryoneagreedwiththenextpilot   spromptdesign.weachievedthebestre-sultswhenwelettheworkerswriteaboutanythingtheyhaveinmind,asopposedtomandatingapre-speci   edtopic.the   nalid104promptcanbefoundinsupplementarymaterial.thekeypropertythatwehadenforcedinour   nalpromptwasthefollowing:thestoryshouldreadlikeacoherentstory,withaspeci   cbegin-ningandending,wheresomethinghappensinbe-tween.thisconstraintresultedinmanycausalandtemporallinksbetweenevents.table1showstheexamplesweprovidedtotheworkersforinstruct-ingthemabouttheconstraints.wesetalimitof70characterstothelengthofeachsentence.thispreventedmulti-partsentencesthatincludeunnec-essarydetails.theworkerswerealsoaskedtopro-videatitlethatbestdescribestheirstory.lastbutnotleast,weinstructedtheworkersnottousequo-tationsintheirsentencesandavoidusingslangorinformallanguage.collectinghighqualitystorieswiththesecon-straintsgivesusarichcollectionofcommonsensestorieswhicharefullofstereotypicalinter-eventre-thelittlepuppythoughthewasagreatbasketballplayer.hechallengedthekittentoafriendlygame.thekittenagreed.kittenstartedtopracticereallyhard.eventuallythekittenbeatthepuppyby40points.billthoughthewasagreatbasketballplayer.hechallengedsamtoafriendlygame.samagreed.samstartedtopracticereallyhard.eventuallysambeatbillby40points.iamhappywithmylife.ihavebeenkind.ihavebeensuccessful.iworkout.whynotbehappywhenyoucan?thecityisfullofpeopleandoffersalotofthingstodo.oneofmyfavoritethingsisgoingtotheoutdoorconcerts.ialsolikevisitingthedifferentrestaurantsandmuseums.thereisalwayssomethingexcitingtodointhecity.thesmithfamilywenttothefamilybeachhouseeverysummer.theylovedthebeachhousealot.unfortunatelytherewasabadhurricaneonce.theirbeachhousewaswashedaway.nowtheylamentthelossoftheirbeachhouseeverysummer.mileywasinmiddleschool.shelivedinanapartment.oncemileymadeamistakeandcheatedinoneofherexams.shetriedtohidethetruthfromherparents.afterherparentsfoundout,theygroundedherforamonth.mileywasinmiddleschool.sheusuallygotgoodgradesinschool.oncemileymadeamistakeandcheatedinoneofherexams.shetriedtohidethetruthfromherparents.afterherparentsfoundout,theygroundedherforamonth.table1:examplesofgoodandbadstoriesprovidedtothecrowd-sourcedworkers.eachrowemphasizesoneofthethreepropertiesthateachstoryshouldsatisfy:(1)beingrealistic,(2)havingclearbeginningandending,and(3)notstatinganythingirrelevanttothestory.xchallengeyyagreeplayypracticeybeatxfigure1:anexamplenarrativechainwithcharac-tersxandy.lations.forexample,fromthegoodstoryin   rstrowoftable1,onecanextractthenarrativechainrepresentedinfigure1.developingabetterse-manticrepresentationfornarrativechainswhichcancapturerichinter-eventrelationsinthesestoriesisatopicoffuturework.qualitycontrol:oneissuewithid104ishowtoinstructnon-expertworkers.thistaskisatypeofcreativewriting,andistrickierthanclassi   -cationandtaggingtasks.inordertoensurewegetquali   edworkers,wedesignedaquali   cationtestonamtinwhichtheworkershadtojudgewhetherornotagivenstory(total   vestories)isanaccept-ableone.weused   vecarefullyselectedstoriestobeapartofthequali   cationtest.thisnotonlyelim-inatesanypotentialspammersonamt,butalsopro-videsuswithapoolofcreativestorywriters.fur-thermore,wequalitativelybrowsedthroughthesub-missionsandgavetheworkersdetailedfeedbackbe-foreapprovingtheirsubmissions.weoftenbonusedourtopworkers,encouragingthemtowritenewsto-riesonadailybasis.statistics:figure2showsthedistributionofnumberoftokensofdifferentsentencepositions.the   rstsentencetendstobeshorter,asitusuallyintroducescharactersorsetsthescene,andthe   fthsentenceislonger,providingmoredetailedconclu-sionstothestory.table2summarizesthestatisticsofourid104effort.figure3showsthedis-tributionofthemostfrequent50eventsinthecor-pus.herewecounteventasanyhyponymof   event   or   process   inid138(miller.,1995).thetoptwoevents,   go   and   get   ,eachcompriselessthan2%ofalltheevents,whichillustratestherichdiversityofthecorpus.figure2:numberoftokensineachsentenceposi-tion.#submittedstories49,895#approvedstories49,255#workersparticipated932average#storiesbyoneworker52.84max#storieswrittenbyoneworker3,057averageworktimeamongworkers(minute)4.80medianworktimeamongworkers(minute)2.16averagepaymentperstory(cents)26table2:id104workerstatistics.figure4visualizestheid165distributionofourstorytitles,whereeachradialpathindicatesann-figure3:distributionoftop50eventsinourcorpus.gramsequence.forthisanalysiswesetn=5,wherethemeannumberoftokensintitlesis9.8andme-dianis10.the   end   tokendistinguishestheactualendingofatitlefrom   ve-gramcut-off.this   g-uredemonstratestherangeoftopicsthatourworkershavewrittenabout.thefullcirclere   ectson100%ofthetitleid165sandtheid165pathsinthefaded3/4ofthecirclecompriselessthan0.1%oftheid165s.thisfurtherdemonstratesthattherangeoftopicscoveredbyourcorpusisquitediverse.afulldynamicvisualizationoftheseid165scanbefoundhere:http://goo.gl/qhg60b.figure4:id165distributionofstorytitles.3.2corpusreleasethecorpusispubliclyavailabletothecom-munityandcanbeaccessedthroughhttp://cs.rochester.edu/nlp/rocstories,whichwillbegrownevenfurtheroverthecomingyears.giventhequalitycontrolpipelineandthecreativityrequiredfromworkers,datacollectiongoesslowly.wearealsomakingavailablesemanticparsesofthesestories.sincethesestoriesarenotnewswire,off-the-shelfsyntacticandshallowsemanticparsersforeventextractionoftenfailonthelanguage.toaddressthisissue,wecustomizedsearchparam-etersandaddedafewlexicalentries2totripsbroad-coveragesemanticparser3,optimizingitsper-formanceonourcorpus.tripsparser(allenetal.,2008)producesstate-of-the-artlogicalformsforinputstories,providingsensedisambiguatedandontology-typedrichdeepstructureswhichenableseventextractiontogetherwithsemanticrolesandcoreferencechainsthroughoutthe   vesentences.3.3temporalanalysisbeingabletotemporallyordereventsinthestoriesisapre-requisiteforcompletenarrativeunderstand-ing.temporalanalysisoftheeventsinourshortcommonsensicalstoriesisanimportanttopicoffur-therresearchonitsown.inthissection,wesum-marizetwoofouranalysesregardingthenatureoftemporalorderingofeventsinourcorpus.shuf   ingexperiment:anopenquestioninanytextgenreishowtextorderisrelatedtotempo-ralorder.dothesentencesfollowthereal-worldtemporalorderofevents?thisexperimentshuf-   esthestoriesandasksamtworkerstoarrangethembacktoacoherentstory.thiscanshedlightonthecorrelationbetweentheoriginalpositionofthesentencesandthepositionwhenanotherhumanrearrangestheminacommonsensicallymeaningfulway.wesetupthisexperimentasfollows:wesam-pledtwosetsof50storiesfromourcorpus:good-stories50andrandom-stories50.good-stories504issampledfromasetofstorieswrittenbytopworkers2forexample,newinformalverbssuchas   vape   or   vlog   havebeenaddedtothelexiconofthissemanticparser.3http://trips.ihmc.us/parser/cgi/step4thissetcanbefoundhere:https://goo.gl/vtnj9sgood-stories50random-stories50%perfectlyordered,takingmajorityorderingforeachofthe50stories10086%allsentencesperfectlyordered,outof250orderings95.282.4%   1sentencesmisplaced,rest   owcorrectly,outof250orderings98.096.0%correctplacementsofeachposition,1to598.8,97.6,96,96,98.895.6,86,86.8,91.2,96.8table3:resultsfromthehumantemporalshuf   ingexperiment.whohaveshownshownconsistentqualitythrough-outtheirsubmissions.random-stories505isaran-domsamplingfromallthestoriesinthecorpus.thenwerandomlyshuf   edthesentencesineachstoryandasked   vecrowdworkersonamttorear-rangethesentences.table3summarizestheresultsofthisexperiment.the   rstrowshowstheresultoforderingifwetaketheabsolutemajorityorderingofthe   vecrowdworkersasthe   nalordering.thesecondrowshowstheresultoforderingifweconsidereachofthe250(50storiesx5workersorderingeachone)orderingcasesindependently.asshown,thegoodstoriesareperfectlyorderedwithveryhighaccuracy.itisim-portanttonotethatthisspeci   csetrarelyhadanylinguisticadverbialssuchas      rst   ,   then   ,etc.tohelphumaninfertheordering,sothemainfactorsatplayarethefollowing:(1)thecommonsensicaltemporalandcausalrelationbetweenevents(narra-tiveschemas),e.g.,humanknowsthat   rstsome-onelosesaphonethenstartssearching;(2)thenat-uralwayofnarratingastorywhichstartswithintro-ducingthecharactersandconcludesthestoryattheend.theroleofthelatterfactorisquanti   edinthemisplacementrateofeachpositionreportedintable3,wherethe   rstandlastsentencesaremoreoftencorrectlyplacedthanothers.thehighprecisionoforderinginsentences2upto4furtherveri   estherichnessofourcorpusintermsoflogicalrelationbetweenevents.timemlannotation:timeml-drivenanalysisofthesestoriescangiveus   ner-grainedinsightabouttemporalaspectoftheeventsinthiscorpus.weperformedasimpli   edtimeml-driven(puste-jovskyetal.,2003)expertannotationofasampleof20stories6.amongallthetemporallinks(tlink)annotated,62%were   before   and10%were   simul-taneous   .wewereinterestedtoknowiftheactualtextordermirrorsreal-worldorderofevents.we5thissetcanbefoundhere:https://goo.gl/pgm2kr6theannotationisavailable:http://goo.gl/7qdnsbfoundthatsentenceordermatchestimemlorder55%ofthetime.amorecomprehensivestudyoftemporalandcausalaspectsofthesestoriesrequiresde   ningaspeci   csemanticannotationframeworkwhichcoversnotonlytemporalbutalsocausalre-lationsbetweencommonsenseevents.thisiscap-turedinarecentworkonsemanticannotationofrocstories(mostafazadehetal.,2016).4anewevaluationframeworkasdescribedearlierintheintroduction,thecommonevaluationframeworkforscriptlearningisthe   nar-rativeclozetest   (chambersandjurafsky,2008),whereasystemgeneratesarankedlistofguessesforamissingevent,givensomeobservedevents.theoriginalgoalofthistestwastoprovideacompara-tivemeasuretoevaluatenarrativeknowledge.how-ever,gradually,thecommunitystartedoptimizingtowardstheperformanceonthetestitself,achiev-inghigherscoreswithoutdemonstratingnarrativeknowledgelearning.forinstance,generatingtherankedlistaccordingtotheevent   scorpusfrequency(e.g.,alwayspredicting   xsaid   )wasshowntobeanextremelystrongbaseline(pichottaandmooney,2014b).originally,narrativeclozetestchainswereextractedbyhandandveri   edasgoldchains.how-ever,theclozetestchainsusedinallofthemostrecentworksarenothumanveri   edasgold.itisevidentthatthereisaneedforamoresystem-aticautomaticevaluationframeworkwhichismoreinlinewiththeoriginaldeeperscript/storyunder-standinggoals.itisimportanttonotethatreorder-ingoftemporallyshuf   edstories(section3.3)canserveasaframeworktoevaluateasystem   sstoryun-derstanding.however,reorderingcanbeachievedtoadegreebyusingvarioussurfacefeaturessuchasadverbials,sothiscannotbeafoolproofstoryun-derstandingevaluationframework.ourrocstoriescorpusenablesabrandnewframeworkforevalu-atingstoryunderstanding,calledthe   storyclozetest   .4.1storyclozetesttheclozetask(taylor,1953)isusedtoevaluateahuman(orasystem)forlanguageunderstandingbydeletingarandomwordfromasentenceandhavingahuman   llintheblank.weintroduce   storyclozetest   ,inwhichasystemisgivenafour-sentence   context   andtwoalternativeendingstothestory,called   rightending   and   wrongend-ing   .hence,inthistestthe   fthsentenceisblank.thenthesystem   staskistochoosetherightend-ing.the   rightending   canbeviewedas   entailing   hypothesisinaclassicrecognizingtextualentail-ment(rte)framework(giampiccoloetal.,2007),and   wrong   endingcanbeseenasthe   contradict-ing   hypothesis.table4showsthreeexamplestoryclozetestcases.storyclozetestwillserveasagenericstoryunderstandingevaluationframework,alsoapplica-bletoevaluationofstorygenerationmodels(forinstancebycomputingthelog-likelihoodsassignedtothetwoendingalternativesbythestorygenera-tionmodel),whichdoesnotnecessarilyimplyre-quirementforexplicitnarrativeknowledgelearning.however,itissafetosaythatanymodelthatper-formswellonstoryclozetestisdemonstratingsomelevelofdeeperstoryunderstanding.4.2datacollectionmethodologywerandomlysampled13,500storiesfromrocsto-riescorpusandpresentedonlythe   rstfoursen-tencesofeachtoamtworkers.foreachstory,aworkerwasaskedtowritea   rightending   anda   wrongending   .theworkerswerepromptedtosat-isfytwoconditions:(1)thesentenceshouldfollowupthestorybysharingatleastoneofthecharactersofthestory,and(2)thesentenceshouldbeentirelyrealisticandsensiblewhenreadinisolation.theseconditionsmakesurethatthestoryclozetestcasesarenottrivial.moredetailsonthissetupisdescribedinthesupplementarymaterial.qualitycontrol:theaccuracyofthestoryclozetestcanplayacrucialroleindirectingtheresearchcommunityintherighttrajectory.weim-plementedthefollowingtwo-stepqualitycontrol:1.quali   cationtest:wedesignedaquali   cationtestforthistask,wheretheworkershadtochoosewhetherornotagiven   rightending   and   wrongending   satisfyourconstraints.atthisstagewecollected13,500clozetestcases.2.humanveri   cation:inordertofurthervalidatetheclozetestcases,wecompiledthe13,500storyclozetestcasesinto2  13,500=27,000full   ve-sentencestories.thenforeachstoryweaskedthreecrowdworkerstoverifywhetherornotthegivensequenceof   vesentencesmakessenseasameaningfulandcoherentstory,ratingwithin{-1,0,1}.thenwe   lteredclozetestcaseswhichhad   rightending   withallratings1and   wrongending   withallratings0.thispro-cessensuresthattherearenoboundarycasesof   rightending   and   wrongending   .thisresultedin   nal3,742testcases,whichwasrandomlydi-videdintovalidationandteststoryclozetestsets.wealsomadesuretoremovetheoriginalstoriesusedinthevalidationandtestsetfromourrocstoriescorpus.statistics:table5summarizesthestatisticsofourid104effort.thestoryclozetestsetscanalsobeaccessedthroughourwebsite.5storyclozetestmodelsinthissectionwedemonstratethatstoryclozetestcannotbeeasilytackledbyusingshallowtech-niques,withoutactuallyunderstandingtheunderly-ingnarrative.followingothernaturallanguagein-ferenceframeworkssuchasrte,weevaluatesys-temperformanceaccordingtobasicaccuracymea-sure,whichisde   nedas#correct#testcases.wepresentthefollowingbaselinesandmodelsfortacklingstoryclozetest.allofthemodelsaretestedonthevali-dationandteststoryclozesets,whereonlytheval-idationsetcouldbeusedforanytuningpurposes.1.frequency:ideally,thestoryclozetestcasesshouldnotbeanswerablewithoutthecontext.forexample,ifforsomecontextthetwoalternativesare   hewasmadafterhewon   7and   hewascheerfulafterhewon   ,the   rstalternativeissim-plylessprobableinrealworldthantheotherone.thisbaselinechoosesthealternativewithhighersearchengine8hitsofthemainevent(verb)together7givenourpromptthatthe   wrongending   sentencesshouldmakesenseinisolation,suchcasesshouldberareinourdataset.8https://developers.google.com/custom-search/contextrightendingwrongendingtomandsherylhavebeentogetherfortwoyears.oneday,theywenttoacarnivaltogether.hewonherseveralstuffedbears,andboughtherfunnelcakes.whentheyreachedtheferriswheel,hegotdownononeknee.tomaskedsheryltomarryhim.hewipedmudoffofhisboot.karenwasassignedaroommateher   rstyearofcollege.herroommateaskedhertogotoanearbycityforaconcert.karenagreedhappily.theshowwasabsolutelyexhilarat-ing.karenbecamegoodfriendswithherroommate.karenhatedherroommate.jimgothis   rstcreditcardincollege.hedidn   thaveajobsoheboughteverythingonhiscard.afterhegraduatedheamounteda$10,000debt.jimrealizedthathewasfoolishtospendsomuchmoney.jimdecidedtodeviseaplanforrepayment.jimdecidedtoopenanothercreditcard.table4:threeexamplestoryclozetestcases,completedbyourcrowdworkers.#casescollected13,500#workersparticipated282average#caseswrittenbyoneworker47.8max#caseswrittenbyoneworker1461averagepaymentpertestcase(cents)10sizeofthe   nalset(veri   edbyhuman)3,744table5:statisticsforcrowd-sourcingstoryclozetestinstances.withitssemanticroles(e.g.,   i*poison*   owers   vs   i*nourish*   owers   ).weextractthemainverbanditscorrespondingrolesusingtripssemanticparser.2.id165overlap:simplychoosesthealterna-tivewhichsharesmoreid165swiththecontext.wecomputesmoothed-id7(linandoch,2004)scoreformeasuringuptofour-gramoverlapofanalternativeandthecontext.3.gensim:averageid97:choosethehy-pothesiswithcloseraverageid97(mikolovetal.,2013)embeddingtotheaverageid97em-beddingofthecontext.thisisbasicallyanen-hancedwordoverlapbaseline,whichaccountsforsemanticsimilarity.4.sentiment-full:choosethehypothesisthatmatchestheaveragesentimentofthecontext.weusethestate-of-the-artsentimentanalysismodel(manningetal.,2014)whichassignsanumericalvaluefrom1to5toasentence.5.sentiment-last:choosethehypothesisthatmatchesthesentimentofthelastcontextsentence.6.skip-thoughtsmodel:thismodelusesskip-thoughts   sentence2vecembedding(kirosetal.,2015)whichmodelsthesemanticspaceofnovels.thismodelistrainedonthe   bookcorpus   (zhuetal.,2015)(containing16differentgenres)ofover11,000books.weusetheskip-thoughtsembeddingofthealternativesandcontextsformakingdecisionthesamewayaswithgensimmodel.7.narrativechains-ap:implementsthestandardapproachtolearningchainsofnarrativeeventsbasedonchambersandjurafsky(2008).aneventisrep-resentedasaverbandatypeddependency(e.g.,thesubjectofruns).wecomputedthepmibetweenalleventpairsintheassociatepress(ap)portionoftheenglishgigawordcorpusthatoccuratleast2times.weruncoreferenceoverthegivenstory,andchoosethehypothesiswhosecoreferringentityhasthehighestaveragepmiscorewiththeentity   schaininthestory.ifnoentitycorefersinbothhypotheses,itrandomlychoosesoneofthehypotheses.8.narrativechains-stories:thesamemodelasabove,buttrainedonrocstories.9.deepstructuredsemanticmodel(dssm):thismodel(huangetal.,2013)istrainedtoprojectthefour-sentencescontextandthe   fthsentenceintothesamevectorspace.itconsistsoftwoseparatedeepneuralnetworksforlearningjointlytheem-beddingofthefour-sentencescontextandthe   fthsentence,respectively.assuggestedinhuangetal.(2013),theinputofthedssmisbasedoncontext-dependentcharacters,e.g.,thedistributioncountofletter-trigramsinthecontextandinthe   fthsen-tence,respectively.thehyperparametersofthedssmisdeterminedonthevalidationset,whilethemodel   sparametersaretrainedontherocstoriescorpus.inourexperiment,eachofthetwoneuralnetworksinthedssmhastwolayers:thedimen-constant-choose-   rstfrequencyid165-overlapgensimsentiment-fullsentiment-lastskip-thoughtsnarrative-chains-apnarrative-chains-storiesdssmhumanvalidationset0.5140.5060.4770.5450.4890.5140.5360.4720.5100.6041.0testset0.5130.5200.4940.5390.4920.5220.5520.4780.4940.5851.0table6:theaccuracyofvariousmodelsonthestoryclozevalidationandtestsets.sionofthehiddenlayeris1000,andthedimensionoftheembeddingvectoris300.atruntime,thismodelpicksthecandidatewiththelargestcosinesimilaritybetweenitsvectorrepresentationandthecontext   svectorrepresentation.theresultsofevaluatingthesemodelsonthestoryclozevalidationandtestsetsareshowninta-ble6.theconstant-choose-   rst(51%)andhumanperformance(100%)isalsoprovidedforcompari-son.notethatthesesetsweredoublyveri   edbyhuman,henceitdoesnothaveanyboundarycases,resultingin100%humanperformance.thedssmmodelachievesthehighestaccuracy,butonly7.2pointshigherthanconstant-choose-   rst.erroranal-ysisonthenarrativechainsmodelshowswhythisandotherevent-basedlanguagemodelsarenotsuf-   cientforthetask:often,the   nalsentencesofourstoriescontaincomplexeventsbeyondthemainverb,suchas   billwashighlyunprepared   or   hehadtogotoahomelessshelter   .eventlanguagemodelsonlylookattheverbandsyntacticrelationlike   was-object   and   go-to   .inthatsense,goingtoahomelessshelteristhesameasgoingtothebeach.thissuggeststherequirementofhavingricherse-manticrepresentationforeventsinnarratives.ourproposedstoryclozetestoffersanewchallengetothecommunity.6discussiontherearethreecorecontributionsinthispaper:(1)anewcorpusofcommonsensestories,calledroc-stories,(2)anewevaluationframeworktoevalu-atescript/storylearners,calledstoryclozetest,and(3)ahostof   rstapproachestotacklethisnewtestframework.rocstoriescorpusisthe   rstcrowd-sourcedcorpusofitskindforthecommunity.wehavereleasedabout50kstories,aswellasvalida-tionandtestsetsforstoryclozetest.thisdatasetwilleventuallygrowto100kstories,whichwillbereleasedthroughourwebsite.inordertocontinuemakingmeaningfulprogressonthistask,althoughitispossibletokeepincreasingthesizeofthetrainingdata,weexpectthecommunitytodevelopmodelsthatwilllearntogeneralizetounseencommonsenseconceptsandsituations.thestoryclozetestprovedtobeachallengetoallofthemodelswetested.webelieveitwillserveasaneffectiveevaluationforbothstoryunderstand-ingandscriptknowledgelearners.weencouragethecommunitytobenchmarktheirprogressbyre-portingtheirresultsonstoryclozetestset.com-paredtothepreviousnarrativeclozetest,wefoundthatoneoftheearlymodelsforthattaskactuallyperformsworsethanrandomguessing.wecancon-cludethatnarrativeclozetestspurredinterestinscriptlearning,however,itultimatelydoesnoteval-uatedeeperknowledgeandlanguageunderstanding.acknowledgmentswewouldliketothanktheamazingcrowdworkerswhoseendlesshoursofdailystorywritingmadethisresearchpossible.wethankwilliamdebeaumontandchohmantengfortheirworkontripsparser.wethankalysongrealishforhergreathelpinthequalitycontrolofourcorpus.thisworkwassup-portedinpartbygrantw911nf-15-1-0542withtheusdefenseadvancedresearchprojectsagency(darpa),thearmyresearchof   ce(aro)andtheof   ceofnavalresearch(onr).ourdatacollec-tioneffortwassponsoredbynuancefoundation.referencesjamesf.allen,maryswift,andwilldebeaumont.2008.deepsemanticanalysisoftext.inproceedingsofthe2008conferenceonsemanticsintextprocess-ing,step   08,pages343   354,stroudsburg,pa,usa.associationforcomputationallinguistics.paulbailey.1999.searchingforstoriness:story-generationfromareader   sperspective.inaaaifallsymposiumonnarrativeintelligence.niranjanbalasubramanian,stephensoderland,orenet-zionimausam,andorenetzioni.2013.generatingcoherenteventschemasatscale.inemnlp,pages1721   1731.davidbamman,brendanoconnor,andnoahsmith.2013.learninglatentpersonasof   lmcharacters.acl.samuelrbowman,gaborangeli,christopherpotts,andchristopherdmanning.2015.learningnaturallan-guageid136fromalargeannotatedcorpus.inpro-ceedingsofthe2015conferenceonempiricalmeth-odsinnaturallanguageprocessing,pages632   642,stroudsburg,pa.associationforcomputationallin-guistics.k.burton,a.java,,andi.soboroff.2009.theicwsm2009spinn3rdataset.ininproceedingsofthethirdannualconferenceonweblogsandsocialme-dia(icwsm2009),sanjose,ca.nathanaelchambersanddanieljurafsky.2008.unsu-pervisedlearningofnarrativeeventchains.inkath-leenmckeown,johannad.moore,simoneteufel,jamesallan,andsadaokifurui,editors,acl,pages789   797.theassociationforcomputerlinguistics.nathanaelchambersanddanjurafsky.2009.unsuper-visedlearningofnarrativeschemasandtheirpartici-pants.inproceedingsofthejointconferenceofthe47thannualmeetingoftheaclandthe4thinterna-tionaljointconferenceonnaturallanguageprocess-ingoftheafnlp:volume2-volume2,acl   09,pages602   610,stroudsburg,pa,usa.associationforcomputationallinguistics.nathanaelchambers.2013.eventschemainductionwithaprobabilisticentity-drivenmodel.inemnlp,volume13,pages1797   1807.eugenecharniak.1972.towardamodelofchildren   sstorycomprehension.december.jackiecheung,hoifungpoon,andlucyvanderwende.2013.probabilisticframeinduction.inacl.e.m.forster.1927.aspectsofthenovel.edwardarnold,london.danilogiampiccolo,bernardomagnini,idodagan,andbilldolan.2007.thethirdpascalrecognizingtex-tualentailmentchallenge.inproceedingsoftheacl-pascalworkshopontextualentailmentandpara-phrasing,rte   07,pages1   9,stroudsburg,pa,usa.acl.andrews.gordonandreidswanson.2009.identify-ingpersonalstoriesinmillionsofweblogentries.inthirdinternationalconferenceonweblogsandsocialmedia,datachallengeworkshop,sanjose,ca,may.karlmoritzhermann,tomaskocisky,edwardgrefen-stette,lasseespeholt,willkay,mustafasuleyman,andphilblunsom.2015.teachingmachinestoreadandcomprehend.inc.cortes,n.d.lawrence,d.d.lee,m.sugiyama,andr.garnett,editors,advancesinneuralinformationprocessingsystems28,pages1693   1701.curranassociates,inc.po-senhuang,xiaodonghe,jianfenggao,lideng,alexacero,andlarryheck.2013.learningdeepstructuredsemanticmodelsforwebsearchusingclick-throughdata.inproceedingsofthe22ndacminternationalconferenceoninformation&knowl-edgemanagement,cikm   13,pages2333   2338,newyork,ny,usa.acm.bramjans,stevenbethard,ivanvuli  c,andmariefrancinemoens.2012.skipid165sandrankingfunctionsforpredictingscriptevents.inproceedingsofthe13thconferenceoftheeuropeanchapteroftheassociationforcomputationallinguis-tics,pages336   344.associationforcomputationallinguistics.ryankiros,yukunzhu,ruslansalakhutdinov,richardszemel,antoniotorralba,raquelurtasun,andsanjafidler.2015.skip-thoughtvectors.nips.hectorj.levesque.2011.thewinogradschemachal-lenge.inaaaispringsymposium:logicalformal-izationsofcommonsensereasoning.aaai.chin-yewlinandfranzjosefoch.2004.automaticevaluationofmachinetranslationqualityusinglongestcommonsubsequenceandskip-bigramstatistics.inproceedingsofthe42ndannualmeetingonassocia-tionforcomputationallinguistics,acl   04,strouds-burg,pa,usa.associationforcomputationallin-guistics.christopherd.manning,mihaisurdeanu,johnbauer,jennyfinkel,stevenj.bethard,anddavidmcclosky.2014.thestanfordcorenlpnaturallanguagepro-cessingtoolkit.inproceedingsof52ndannualmeet-ingoftheassociationforcomputationallinguistics:systemdemonstrations,pages55   60.mehdimanshadi,reidswanson,andandrews.gor-don.2008.learningaprobabilisticmodelofeventsequencesfrominternetweblogstories.in21stcon-ferenceofthefloridaaisociety,appliednaturallan-guageprocessingtrack,coconutgrove,fl,may.neilmcintyreandmirellalapata.2009.learningtotelltales:adata-drivenapproachtostorygeneration.inproceedingsofthejointconferenceofthe47than-nualmeetingoftheaclandthe4thinternationaljointconferenceonnaturallanguageprocessingoftheafnlp,pages217   225,singapore.gonzalom  endez,pablogerv  as,andcarlosle  on.2014.amodelofcharacteraf   nityforagent-basedstorygeneration.in9thinternationalconferenceonknowledge,informationandcreativitysupportsys-tems,limassol,cyprus,11/2014.springer-verlag,springer-verlag.tomasmikolov,ilyasutskever,kaichen,gregorys.corrado,andjeffreydean.2013.distributedrep-resentationsofwordsandphrasesandtheircompo-sitionality.inadvancesinneuralinformationpro-cessingsystems26:27thannualconferenceonneu-ralinformationprocessingsystems2013.proceedingsofameetinghelddecember5-8,2013,laketahoe,nevada,unitedstates.,pages3111   3119.g.miller.1995.id138:alexicaldatabaseforenglish.inincommunicationsoftheacm.nasrinmostafazadeh,alysongrealish,nathanaelchambers,jamesf.allen,andlucyvanderwende.2016.semanticannotationofeventstructuresincom-monsensestories.inproceedingsofthethe4thwork-shoponevents:de   nition,detection,coreference,andrepresentation,sandiego,california,june.as-sociationforcomputationallinguistics.erikt.mueller.2002.understandingscript-basedsto-riesusingcommonsensereasoning.cognitivesystemsresearch,5:2004.erikt.mueller.2007.modelingspaceandtimeinnar-rativesaboutrestaurants.llc,22(1):67   84.kiem-hieunguyen,xaviertannier,olivierferret,andromaricbesanc  on.2015.generativeeventschemainductionwithentitydisambiguation.inproceedingsofthe53rdannualmeetingoftheassociationforcom-putationallinguistics(acl-15).karlpichottaandraymondjmooney.2014a.statisti-calscriptlearningwithmulti-argumentevents.eacl2014,page220.karlpichottaandraymondj.mooney.2014b.statis-ticalscriptlearningwithmulti-argumentevents.inproceedingsofthe14thconferenceoftheeuropeanchapteroftheassociationforcomputationallinguis-tics(eacl2014),gothenburg,sweden,april.jamespustejovsky,joscastao,robertingria,rosersaur,robertgaizauskas,andreasetzer,andgrahamkatz.2003.timeml:robustspeci   cationofeventandtemporalexpressionsintext.ininfifthinterna-tionalworkshoponcomputationalsemantics(iwcs-5.michaelaregneri,alexanderkoller,andmanfredpinkal.2010.learningscriptknowledgewithwebexperiments.inproceedingsofthe48thannualmeet-ingoftheassociationforcomputationallinguistics,pages979   988.associationforcomputationallin-guistics.matthewrichardson,christopherj.c.burges,anderinrenshaw.2013.mctest:achallengedatasetfortheopen-domainmachinecomprehensionoftext.inemnlp,pages193   203.acl.m.riedlandcarlosle  on.2008.towardvignette-basedstorygenerationfordramamanagementsystems.inworkshoponintegratingtechnologiesforinteractivestories-2ndinternationalconferenceonintelligenttechnologiesforinteractiveentertainment,8-10/1.melissaroemmele,cosminadrianbejan,andan-drews.gordon.2011.choiceofplausiblealterna-tives:anevaluationofcommonsensecausalreason-ing.inaaaispringsymposiumonlogicalformal-izationsofcommonsensereasoning,stanforduniver-sity,march.rachelrudinger,pushpendrerastogi,francisferraro,andbenjaminvandurme.2015.scriptinductionaslanguagemodeling.inproceedingsofthe2015con-ferenceonempiricalmethodsinnaturallanguageprocessing(emnlp-15).rogerc.schankandrobertp.abelson.1977.scripts,plans,goalsandunderstanding:aninquiryintohu-manknowledgestructures.l.erlbaum,hillsdale,nj.lenhartk.schubertandchungheehwang.2000.episodiclogicmeetslittleredridinghood:acom-prehensive,naturalrepresentationforlanguageun-derstanding.innaturallanguageprocessingandknowledgerepresentation:languageforknowledgeandknowledgeforlanguage.mit/aaaipress.reidswansonandandrews.gordon.2008.sayany-thing:amassivelycollaborativeopendomainstorywritingcompanion.infirstinternationalconfer-enceoninteractivedigitalstorytelling,erfurt,ger-many,november.wilsonltaylor.1953.clozeprocedure:anewtoolformeasuringreadability.journalismquarterly.scottr.turner.1994.thecreativeprocess:acomputermodelofstorytelling.hillsdale:lawrenceerlbaum.jasonweston,antoinebordes,sumitchopra,andtomasmikolov.2015.towardsai-completeques-tionanswering:asetofprerequisitetoytasks.corr,abs/1502.05698.terrywinograd.1972.understandingnaturallan-guage.academicpress,inc.,orlando,fl,usa.yukunzhu,ryankiros,richardzemel,ruslansalakhutdinov,raquelurtasun,antoniotorralba,andsanjafidler.2015.aligningbooksandmovies:towardsstory-likevisualexplanationsbywatch-ingmoviesandreadingbooks.inarxivpreprintarxiv:1506.06724.