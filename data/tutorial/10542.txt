5
1
0
2

 

g
u
a
2
2

 

 
 
]
i

a
.
s
c
[
 
 

1
v
8
0
5
5
0

.

8
0
5
1
:
v
i
x
r
a

towards neural network-based reasoning

baolin peng1    zhengdong lu2 hang li2 kam-fai wong1
1dept. of systems engineering & engineering management,

the chinese university of hong kong
{blpeng, kfwong}@se.cuhk.edu.hk
2noah   s ark lab, huawei technologies

{lu.zhengdong, hangli.hl}@huawei.com

abstract

we propose neural reasoner , a framework for neural network-based reasoning
over natural language sentences. given a question, neural reasoner can infer over
multiple supporting facts and    nd an answer to the question in speci   c forms. neu-
ral reasoner has 1) a speci   c interaction-pooling mechanism, allowing it to examine
multiple facts, and 2) a deep architecture, allowing it to model the complicated logical
relations in reasoning tasks. assuming no particular structure exists in the question and
facts, neural reasoner is able to accommodate di   erent types of reasoning and dif-
ferent forms of language expressions. despite the model complexity, neural reasoner
can still be trained e   ectively in an end-to-end manner. our empirical studies show that
neural reasoner can outperform existing neural reasoning systems with remarkable
margins on two di   cult arti   cial tasks (positional reasoning and path finding) proposed
in [8]. for example, it improves the accuracy on path finding(10k) from 33.4% [6] to over
98%.

1

introduction

reasoning is essential to natural language processing tasks, most obviously in examples like
document summarization, question-answering, and dialogue. previous e   orts in this direction
are built on rule-based models, requiring    rst mapping natural languages to logic forms and
then id136 over them. the mapping (roughly corresponding to id29), and the
id136, are by no means easy, given the variability and    exibility of natural language, the
variety of the reasoning tasks, and the brittleness of a rule-based system.

just recently, there is some new e   ort, mainly represented by memory network and its
dynamic variants [9, 5], trying to build a purely neural network-based reasoning system with
fully distributed semantics that can infer over multiple facts to answer simple questions, all
in natural language, e.g.,

fact1: john travelled to the hallway.
fact2: mary journeyed to the bathroom.
question: where is mary?

the memory nets perform fairly well on simple tasks like the examples above, but poorly

   the work is done when the    rst author worked as intern at noah   s ark lab, huawei technologies.

1

on more complicated ones due to their simple and rigid way of modeling the dynamics of
question-fact interaction and the complex process of reasoning.

in this paper we give a more systematic treatment of the problem and propose a    exible
neural reasoning system, named neural reasoner. it is purely neural network based and
can be trained in an end-to-end way [6], using only supervision from the    nal answer. our
contributions are mainly two-folds

    we propose a novel neural reasoning system neural reasoner that can infer over
multiple facts in a way insensitive to 1) the number of supporting facts, 2)the form of
language, and 3) the type of reasoning;

    we give a particular instantiation of neural reasoner and a multi-task training
method for e   ectively    tting the model with relatively small amount of data, yielding
signi   cantly better results than existing neural models on two arti   cial reasoning task;

2 overview of neural reasoner

neural reasoner has a layered architecture to deal with the complicated logical relations
in reasoning, as illustrated in figure 1. it consists of one encoding layer and multiple reasoning
layers. the encoder layer    rst converts the question and facts from natural language sentences
to vectorial representations. more speci   cally,

encode

q
where q(0)     rdq and f (0)
the reasoning layer recursively updates the representations of questions and facts,

                q(0), fk
k     rdf . with the representations obtained from the encoding layer,

k , k = 1, 2,       , k.

                f (0)

encode

{q((cid:96)) f ((cid:96))

1

       f ((cid:96))

k } reason                {q((cid:96)+1) f ((cid:96)+1)

1

       f ((cid:96)+1)

k

}

through the interaction between question representation and fact representations. intuitively,
this interaction models the reasoning, including examination of the facts and comparison of the
facts and the questions. finally at layer-l, the resulted question representation q(l) is fed to
an answerer, which layer can be a classi   er for choosing between a number of pre-determined
classes (e.g., {yes, no}) or a text generator for create a sentence.

figure 1: high level system diagram of neural reasoner .

2

we argue that neural reasoner has the following desired properties:
    it can handle varying number of facts, including irrelevant ones, and reach the    nal

conclusion through repeated processing of    ltering and combining;

    it makes no assumption about the form of language, as long as enough training examples

are given.

3 model

in this section we give an instantiation of neural reasoner described in section 2, as
illustrated in figure 2.
in a nutshell, question and facts, as symbol sequences, are    rst
converted to vectorial representations in the encoding layer via recurrent neural networks
(id56s). the vectorial representations are then fed to the reasoning layers, where the question
and the facts get updated through an nonlinear transformation jointly controlled by deep
neural networks (dnns)and pooling. finally at the answering layer, the resulted question
representation is used to generate the    nal answer to the question. more speci   cally

    in the encoding layer (layer-0) we use recurrent neural networks (id56s) to convert
question and facts to their vectorial representations, which are then forwarded to the
   rst reasoning layer;

    in each reasoning layer (i.e., layer-(cid:96) with 1     (cid:96)     l     1), we use a deep neural network
(denoted as dnn(cid:96)) to model the pairwise interaction between question representation
q((cid:96)   1) and each fact representation f ((cid:96)   1)
from the previous layer, which yields updated
fact representation f ((cid:96))
k

and updated (fact-dependent) question representation q((cid:96))
k ;

k

    we then fuse the individual updated fact representations {q((cid:96))

k } for the
global updated representation q((cid:96)) through a pooling operation (see section 3.2 for
more details)

2 ,       , q((cid:96))

1 , q((cid:96))

       nally in layer-l, the interaction net (dnnl) returns only question update, which, after

summarization by the pooling operation, will serve as input to the answering layer.

in the rest of this section, we will give details of di   erent components of the model.

3.1 encoding layer

the encoding layer is designed to    nd semantic representations of question and facts. suppose
that we are given a fact or a question as word sequence {x1,       , xt}, the encoding module
summarizes the word sequence with a vector with    xed length. we have di   erent modeling
choices for this purpose, e.g., id98 [4] and id56 [7], while in this paper we use gru [2], a
variant of id56, as the encoding module. gru is shown to be able to alleviate the gradient
vanishing issue of id56 and have similar performance to the more complicated lstm [3].

as shown in figure 3, gru takes as input a sequence of word vectors (for either question

or facts)

x = {x1,       , xt}, xi     r|v|

(1)

3

figure 2: a diagram of our implementation of neural reasoner with l reasoning layers,
operating on one question and k facts.

where |v| stands for the size of vocabulary for input sentences. detailed forward computations
are as follows:

zt =   (wxzext + whzht   1)
rt =   (wxrext + whrht   1)

(cid:98)ht = tanh(wxhext + uhh(rt (cid:12) ht   1))
ht = (1     zt) (cid:12) ht   1 + zt (cid:12)(cid:98)ht

(2)

(3)

(4)

(5)
where e     rm  k is the id27 and wxz, wxr, wxh, whz, whr, uhh are weight
matrices. we take the last hidden state ht as the representation of the word sequence.

4

figure 3: the id56 encoder. the last state is used to summarize the word sequence.

3.2 reasoning layers

the modules in the reasoning layers include those for question-fact interaction, pooling.

3.2.1 question-fact interaction
on reasoning layer (cid:96), the kth interaction is between q((cid:96)   1) and f ((cid:96)   1)
representations q((cid:96))

k

k and f ((cid:96))

k

, resulting in updated

[q((cid:96))

k , f ((cid:96))

k ] def= gdnn(cid:96)([(q((cid:96)   1))(cid:62), f ((cid:96)   1)
k and f ((cid:96))

k

(cid:62)

](cid:62);   (cid:96)),

(6)

with   (cid:96) being the parameters. in general, q((cid:96))
those of the previous layers. in the simplest case with a single layer in dnn(cid:96), we have

can be of di   erent dimensionality as

k

(cid:96) [(q((cid:96)   1))(cid:62), f ((cid:96)   1)
where   (  ) stands for the nonlinear activation function.

def=   (w(cid:62)

q((cid:96))
k

k

(cid:62)

] + b(cid:96)),

(7)

roughly speaking, q((cid:96))
k

the question after its interaction with fact k, while f ((cid:96))
k
therefore, {(q((cid:96))

k )} constitute the    state    of the reasoning process.
,f ((cid:96))

k

contains the update of the system   s understanding on answering
records the change of the kth fact.

3.2.2 pooling

pooling aims to fuse the understanding of the question right after its interaction with all the
facts to form the current status of the question, through which we can enable the comparison
between di   erent facts. there are several strategies for this pooling

    average/max pooling: to obtain the nth element in q((cid:96)), we can take the average
k }. for example,

or the maximum of the elements at the same location from {q((cid:96))
with max-pooling, we have

1 ,       q((cid:96))

q((cid:96))(d) = max({q((cid:96))

1 (d), q((cid:96))

2 (d),       , q((cid:96))

k (d)}), d = 1, 2,       , d(cid:96)

where q((cid:96))(d) stands for the dth element of vector q((cid:96)). clearly this kind of pooling is
the simplest, without any associated parameters;

    gating: we can have an extra gating network g((cid:96))(  ) to determine the certainty of
k ). the output
k , whose nth element, after normaliza-

the features in q((cid:96))
g((cid:96))(q((cid:96)   1), f ((cid:96)   1)
tion, can be used as weight for the corresponding element in q((cid:96))
k

k based on {q((cid:96)   1), f ((cid:96)   1)
) has the same dimension as q((cid:96))

} (the input for getting q((cid:96))

in obtaining q((cid:96)).

k

k

5

    model-based: in the case of temporal-reasoning, there is crucial information in the
sequential order of the facts. to account for this temporal structure, we can use a id98
or id56 to combine the information in {q((cid:96))

1 ,       q((cid:96))
k }.

at layer-l, the query representation q(l) after the pooling will serve as the features for the
   nal decision.

3.3 answering layer

for simplicity, we focus on the reasoning tasks which can be formulated as classi   cation with
predetermined classes. more speci   cally, we apply neural reasoner to deal with the
following two types of questions

    type i: general questions, i.e., questions with yes-no answer;
    type ii: special questions with a small set of candidate answers.

at reasoning layer-l, it performs pooling over the intermediate results to select important
information for further uses.

q = pool({q(l)
y = softmax(w(cid:62)

1

,       , q(l)
k })

, q(l)
2
softmaxq(l))

(8)

(9)

after reaching the last reasoning step, in this paper we take two steps, q2 is sent to a standard
softmax layer to generate an answer which is formulated as a classi   cation problem.

there is another type of prediction as classi   cation where the e   ective classes dynamically
change with instances, e.g., the single-supporting-fact task in [9]. those tasks cannot be
directly solved with neural reasoner. one simple way to circumvent this is to de   ne the
following score function

scorez = gmatch(q(l), wz;   )

where gmatch is a function (e.g., a dnn) parameterized with   , and wz is the embedding for
class z, with z being dynamically determined for the task.

3.4 training
the training of model tunes the parameters in {id560, dnn1,       , dnnl} and those in the
softmax classi   er. similar to [6], we perform end-to-end training, taking the    nal answer as
the only supervision. more speci   cally, we use the cross id178 for the cost of classi   cation

ereasoning =

dce(p(y|rn)||yn)

(cid:88)

n   t

where n indexes the instances in the training set t , and rn = {qn, fn,1,       , fn,kn} stands
for question and facts for the nth instance.

our end-to-end training is the same as [6], while the training in [9]and [5] use the step-
by-step labels on the supporting facts for each instance (see table 1 for examples) in addition
to the answer. as described in [6], those extra labels brings much stronger supervision just
the answer in the end-to-end learning setting, and typically yield signi   cantly better result
on relatively complicated tasks.

6

4 auxiliary training for question/fact representation

we use auxiliary training to facilitate the learning of representations of question and facts.
basically, in addition to using the learned representations of question and facts in the reasoning
process, we also use those representations to reconstruct the original questions or their more
abstract forms with variables (elaborated later in section 4.2).

in the auxiliary training, we intend to achieve the following two goals
    to compensate the lack of supervision in the learning task.

in our experiments, the
supervision can be fairly weak since for each instance it is merely a classi   cation with
no more than 12 classes, while the number of instances are 1k to 10k.

    to introduce bene   cial bias for the representation learning task. since the network is a
complicated nonlinear function, the back-propagation from the answering layer to the
encoding layer can easily fail to learn well.

(a) reconstructing the original sentence

(b) producing an abstract form with variables

figure 4: auxiliary training for question representation. the training for fact representation
is identical and therefore omitted.

4.1 id72 setting

as illustrated in figure 4, we take the simplest way to fuse the auxiliary tasks (recovering)
with the main task (reasoning) through linearly combining their costs with trade-o    parameter
  

e =   erecovering + (1       )ereasoning

(10)

whereereasoning is the cross id178 loss describing the discrepancy of model prediction from
correct answer (see section 3.4), and erecovering is the negative log-likelihood of the sequences
(question or facts) to be recovered. more speci   cally,

erecovering =

log p(fn,k|f (0)

n,k) + log p(qn|q(0)
n )}

(cid:88)

n   t

{ kn(cid:88)

k=1

where the likelihood is estimated as in the encoder-decoder framework proposed in [2]. on
top of the encoding layer (id56), we add another decoding layer (id56) which is trained to
sequentially predict words in the original sentence.

7

4.2 abstract forms with variables

instead of recovering the original sentence in question and facts, we also study the e   ect of
producing a more abstract form in the auxiliary training task. more speci   cally, we let the
decoding id56 to recover a sentence with entities replaced with variables (treated as particular
symbols), e.g.,

the triangle is above the pink rectangle.

the blue square is to the left of the triangle.

               x is above y.
               z is to the left of x.
               is y to the right of the z ?
through this, we intend to teach the system a more abstract way of representing sentences

is the pink rectangle to the right of the square?

recover

recover

recover

(both question and facts) and their interactions. more speci   cally,

    all the entities are only meaningful only when they are compared with each other.
in other words, the model (in the encoding and reasoning layers) should not consider
speci   c entities, but their general notions.

    it helps the model to focus on the relations between the entities, the commonality of

di   erent facts, and the patterns shared between di   erent instances.

5 experiments

we report our empirical study on applying neural reasoner to the question answer task
de   ned in [8], and compare it against state-of-the-art neural models [9, 5].

5.1 setup

babi is a synthetic question and answering dataset. it contains 20 tasks, and each of them
is composed of a set of facts, a question and followed by an answer which is mostly a single
word. for most of the time, only a subset of facts are relevant to the given question. two
versions of the data are available, one has 1k training instances per task and the other has
10k instances per task, while the testing set are the same for the two versions.

we select the two most challenging tasks (among the 20 tasks in [8] ) positional reasoning
and path finding, to test the reasoning ability of neural reasoner. positional reasoning
task tests model   s spatial reasoning ability, while path finding task,    rst proposed in [1] tests
the ability to reason the correct path between objects based on natural language instructions.
in table 1, we give an instance of each task.

5.2 implementation details

in our experiments, we actually used a simpli   ed version of neural reasoner . in the
version

    we choose to keep the representation un-updated on each layer, e.g.,
, k = 1, 2,       , k.

                f (0)

encode

fk

k = f (1)

k =        = f (l   1)
(and its summarization q((cid:96))) to record all the infor-

k

this choice pushes the update q((cid:96))
k
mation in the interaction between facts and question.

8

task i: path    nding

1.the office is east of the hallway.
2.the kitchen is north of the office.
3.the garden is west of the bedroom.
4.the office is west of the garden.
5.the bathroom is north of the garden.
how do you go from the kitchen to the garden? south, east, relies on 2 and 4
how do you go from the office to the bathroom? east, north, relies on 4 and 5

task ii: positional reasoning

1.the triangle is above the pink rectangle.
2.the blue square is to the left of the triangle.
is the pink rectangle to the right of the blue square? yes, relies on 1 and 2
is the blue square below the pink rectangle? no, relies on 1 and 2

table 1: samples of the two tasks: path    nding (upper panel) and positional reasoning (lower
panel), with facts, questions and given answers (following each question). for each panel, we
   rst list facts and then question that one needs to answer based on the given facts. on task
i, the answer to the    rst question is south, east, standing for going south    rst and then east,
obtained based on fact 2 and 4.

    we use only two layers, i.e., l = 2, for the relatively simple task in the experiments.

our model was trained with the standard back-propagation (bp) aiming to maximize
the likelihood of correct answers. all the parameters including the word-embeddings were
initialized by randomly sampling from a uniform distribution [-0.1, 0.1]. no momentum and
weight decay was used. we trained all the tasks for 200 epochs with stochastic gradient
descent and the gradients which had (cid:96)2 norm larger than 40 were clipped, learning rate being
controlled by adadelta [10]. for id72, di   erent mixture ratios were tried, from
0.1 to 0.9.

5.3 neural reasoner vs. competitor models

we compare neural reasoner with the following three neural reasoning models: 1)memory
network, including the one with step-by-step supervision [9](denoted as memory net-step)
and the end-to-end version [6] (denoted as memory net-n2n), and 2) dynamic memory
network, proposed in [5], also with step-by-step supervision.
in table 2, we report the
performance of a particular case of neural reasoner with 1) two reasoning layers, 2)
2-layer dnns as the interaction modules in each reasoning layer, and 3) auxiliary task of
recovering the original question and facts. the results are compared against three neural
competitors. we have the following observations.

    the proposed neural reasoner performs signi   cantly better than memory net-n2n,

especially with more training data.

    although not a fair comparison to our model, neural reasoner is actually better
than memory net-n2n and dynamic memory net on positional reasoning (1k)

9

& (10k) as well as path finding (10k), with about 20% margin on both tasks with 10k
training instances.

posi. reason. (1k) posi. reason. (10k)

step-by-step supervision

memory net-step
dynamic memory net

end-to-end

memory net-n2n
neural reasoner

65.0%
59.6%

59.6%
66.4%

75.4%

-

60.3%
97.9%

path finding (1k) path finding (10k)

step-by-step supervision

memory net-step
dynamic memory net

end-to-end

memory net-n2n
neural reasoner

36.0%
34.5%

17.2%
17.3%

68.1%

-

33.4%
87.0%

table 2: results on two reasoning tasks. the results of memory net-step, memory
net-n2n, and dynamic memory net are taken respectively from [9],[6] and [5].

please note that the results of neural reasoner reported in table 2 are not based
on architectures speci   cally tuned for the tasks. as a matter of fact, with more complicated
models (more reasoning layers and deeper interaction modules), we can achieve even better
results on large datasets (e.g., over 98% accuracy on path finding with 10k instances). we
will however leave the discussion on di   erent architectural variants to the next section.

5.4 architectural variations

this section is devoted to the study of architectural variants of neural reasoner. more
speci   cally, we consider the variations in 1)the number of reasoning layers, 2) the depth of
the interaction dnn, and 3) the auxiliary tasks, with results summarized by table 3. we
have the following observations:

    auxiliary tasks are essential to the e   cacy of neural reasoner, without which the
performances of neural reasoner drop dramatically. the reason, as we conjecture in
section 4, is that the reasoning task alone cannot give enough supervision for learning
accurate word vectors and parameters of the id56 encoder. we note that neural
reasoner can still outperform memory net (n2n) with 10k data on both tasks.

    neural reasoner with shallow architectures, more speci   cally two reasoning lay-
ers and 1-layer dnn, apparently can bene   t from the auxiliary learning of recovering
abstract forms on small datasets (1k on both tasks). however, with deeper architec-
tures or more training data, the improvement over that of recovering original sentences
become smaller, despite the extra information it utilizes.

    when larger training datasets are available, neural reasoner appears to prefer rela-
tively deeper architectures. more importantly, although both tasks require two reason-
ing steps, the performance does not deteriorate with three reasoning layers. on both

10

no auxiliary task

2-layer reasoning, 1-layer dnn
2-layer reasoning, 2-layer dnn
3-layer reasoning, 3-layer dnn

auxiliary task: original

2-layer reasoning, 1-layer dnn
2-layer reasoning, 2-layer dnn
3-layer reasoning, 3-layer dnn

auxiliary task: abstract

2-layer reasoning, 1-layer dnn
2-layer reasoning, 2-layer dnn
3-layer reasoning, 3-layer dnn

no auxiliary task

2-layer reasoning, 1-layer dnn
2-layer reasoning, 2-layer dnn
3-layer reasoning, 3-layer dnn

auxiliary task: original

2-layer reasoning, 1-layer dnn
2-layer reasoning, 2-layer dnn
3-layer reasoning, 3-layer dnn

auxiliary task: abstract

2-layer reasoning, 1-layer dnn
2-layer reasoning, 2-layer dnn
3-layer reasoning, 3-layer dnn

posi. reason. (1k) posi. reason. (10k)

60.2%
59.6%
58.7%

63.1%
66.4%
69.4%

70.9%
66.6%
68.3%

72.1%
69.3%
59.7%

93.8%
97.9%
99.1%

95.2%
95.6%
97.4%

path finding (1k) path finding (10k)

13.6%
12.3%
13.1%

14.1%
17.3%
14.0%

18.1%
15.4%
11.3%

52.2%
54.2%
51.7%

57.0%
87.0%
98.4%

55.8%
87.8%
98.6%

table 3: results on two reasoning tasks yielded by neural reasoner with di   erent archi-
tectural variations.

tasks, with 10k training instances, neural reasoner with three reasoning layers and
3-layer dnn can achieve over 98% accuracy.

6 conclusion and future work

we have proposed neural reasoner, a framework for neural network-based reasoning
over natural language sentences. neural reasoner is    exible, powerful, and language
indepedent. our empirical studies show that neural reasoner can dramatically improve
upon existing neural reasoning systems on two di   cult arti   cial tasks proposed in [9]. for
future work, we will explore 1) tasks with higher di   culty and reasoning depth, e.g., tasks
which require a large number of supporting facts and facts with complex intrinsic structures,
2) the common structure in di   erent but similar reasoning tasks (e.g., multiple tasks all with
general questions), and 3) automatic selection of the reasoning architecture, for example,
determining when to stop the reasoning based on the data.

references

[1] d. l. chen and r. j. mooney. learning to interpret natural language navigation instructions
from observations. in proceedings of the twenty-fifth aaai conference on arti   cial intelligence,

11

aaai 2011, san francisco, california, usa, august 7-11, 2011, 2011.

[2] k. cho, b. van merrienboer, c. gulcehre, f. bougares, h. schwenk, and y. bengio. learning
phrase representations using id56 encoder-decoder for id151. in proceed-
ings of emnlp, pages 1724   1734, 2014.

[3] j. chung, cc. g  ulccehre, k. cho, and y. bengio. empirical evaluation of gated recurrent neural

networks on sequence modeling. corr, abs/1412.3555, 2014.

[4] b. hu, z. lu, h. li, and q. chen. convolutional neural network architectures for matching
in advances in neural information processing systems 27, pages

natural language sentences.
2042   2050, 2014.

[5] a. kumar, o. irsoy, j. su, j. bradbury, r. english, b. pierce, p. ondruska, i. gulrajani, and
r. socher. ask me anything: dynamic memory networks for natural language processing. corr,
abs/1506.07285, 2015.

[6] s. sukhbaatar, a. szlam, j. weston, and r. fergus. weakly supervised memory networks. corr,

abs/1503.08895, 2015.

[7] i. sutskever, o. vinyals, and q. v. le. sequence to sequence learning with neural networks. in

advances in neural information processing systems, pages 3104   3112, 2014.

[8] j. weston, a. bordes, s. chopra, and t. mikolov. towards ai-complete id53: a

set of prerequisite toy tasks. corr, abs/1502.05698, 2015.

[9] j. weston, s. chopra, and a. bordes. memory networks. corr, abs/1410.3916, 2014.

[10] m. d. zeiler. adadelta: an adaptive learning rate method. arxiv preprint arxiv:1212.5701, 2012.

12

