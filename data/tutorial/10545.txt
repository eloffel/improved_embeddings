6
1
0
2

 

b
e
f
9
2

 

 
 
]

g
l
.
s
c
[
 
 

4
v
9
7
2
6
0

.

1
1
5
1
:
v
i
x
r
a

published as a conference paper at iclr 2016

neural programmer-interpreters

scott reed & nando de freitas
google deepmind
london, uk
scott.ellison.reed@gmail.com
nandodefreitas@google.com

abstract

we propose the neural programmer-interpreter (npi): a recurrent and composi-
tional neural network that learns to represent and execute programs. npi has three
learnable components: a task-agnostic recurrent core, a persistent key-value pro-
gram memory, and domain-speci   c encoders that enable a single npi to operate in
multiple perceptually diverse environments with distinct affordances. by learning
to compose lower-level programs to express higher-level programs, npi reduces
sample complexity and increases generalization ability compared to sequence-to-
sequence lstms. the program memory allows ef   cient learning of additional
tasks by building on existing programs. npi can also harness the environment
(e.g. a scratch pad with read-write pointers) to cache intermediate results of com-
putation, lessening the long-term memory burden on recurrent hidden units. in
this work we train the npi with fully-supervised execution traces; each program
has example sequences of calls to the immediate subprograms conditioned on the
input. rather than training on a huge number of relatively weak labels, npi learns
from a small number of rich examples. we demonstrate the capability of our
model to learn several types of compositional programs: addition, sorting, and
canonicalizing 3d models. furthermore, a single npi learns to execute these pro-
grams and all 21 associated subprograms.

introduction

1
teaching machines to learn new programs, to rapidly compose new programs from existing pro-
grams, and to conditionally execute these programs automatically so as to solve a wide variety of
tasks is one of the central challenges of ai. programs appear in many guises in various ai prob-
lems; including motor behaviours, image transformations, id23 policies, classical
algorithms, and symbolic relations.
in this paper, we develop a compositional architecture that learns to represent and interpret pro-
grams. we refer to this architecture as the neural programmer-interpreter (npi). the core module
is an lstm-based sequence model that takes as input a learnable program embedding, program
arguments passed on by the calling program, and a feature representation of the environment. the
output of the core module is a key indicating what program to call next, arguments for the following
program and a    ag indicating whether the program should terminate. in addition to the recurrent
core, the npi architecture includes a learnable key-value memory of program embeddings. this
program-memory is essential for learning and re-using programs in a continual manner. figures 1
and 2 illustrate the npi on two different tasks.
we show in our experiments that the npi architecture can learn 21 programs, including addition,
sorting, and trajectory planning from image pixels. crucially, this can be achieved using a single
core model with the same parameters shared across all tasks. different environments (for example
images, text, and scratch-pads) may require speci   c perception modules or encoders to produce the
features used by the shared core, as well as environment-speci   c actuators. both perception modules
and actuators can be learned from data when training the npi architecture.
to train the npi we use curriculum learning and supervision via example execution traces. each
program has example sequences of calls to the immediate subprograms conditioned on the input.

1

published as a conference paper at iclr 2016

figure 1: example execution of canonicalizing 3d car models. the task is to move the camera such
that a target angle and elevation are reached. there is a read-only scratch pad containing the target
(angle 1, elevation 2 here). the image encoder is a convnet trained from scratch on pixels.

figure 2: example execu-
tion trace of single-digit addi-
tion. the task is to perform
a single-digit add on the num-
bers at pointer locations in the
   rst two rows. the carry (row
3) and output (row 4) should
be updated to re   ect the addi-
tion. at each time step, an ob-
servation of the environment
(viewed from each pointer on
a scratch pad) is encoded into
a    xed-length vector.

by using neural networks to represent the subprograms and learning these from data, the approach
can generalize on tasks involving rich perceptual inputs and uncertainty.
we may envision two approaches to provide supervision. in one, we provide a very large number
of labeled examples, as in object recognition, speech and machine translation.
in the other, the
approached followed in this paper, the aim is to provide far fewer labeled examples, but where
the labels contain richer information allowing the model to learn compositional structure. while
unsupervised and id23 play important roles in perception and motor control, other
cognitive abilities are possible thanks to rich supervision and curriculum learning. this is indeed
the reason for sending our children to school.
an advantage of our approach to model building and training is that the learned programs exhibit
strong generalization. speci   cally, when trained to sort sequences of up to twenty numbers in
length, they can sort much longer sequences at test time. in contrast, the experiments will show that
more standard sequence to sequence lstms only exhibit weak generalization, see figure 6.
a trained npi with    xed parameters and a learned library of programs, can act both as an interpreter
and as a programmer. as an interpreter, it takes input in the form of a program embedding and input
data and subsequently executes the program. as a programmer, it uses samples drawn from a new
task to generate a new program embedding that can be added to its library of programs.

2 related work
several ideas related to our approach have a long history. for example, the idea of using dynam-
ically programmable networks in which the activations of one network become the weights (the

2

inputgotokeyargendhmkeymproggoto()hgoto()lgoto()vgoto()lgoto()act(left)dgoto()act(down)act(left)end state..................hgoto121212goto()1212121212121212inputhgotokeyargendhlgotoinputlgotokeyargendhactinputactkeyargendhactinputlgotokeyargendhinputactkeyargendhvgotoinputgotokeyargendhinputvgotokeyargendhinputdgotokeyargendhdgotoactinputactkeyargendh9343489343482add1()act (4,2,write) 9343482carry()9343482act (3,left)93434812act (3,1,write)9343482add1()9343482carry()inputadd1keyargendhactmkeymproginputactkeyargendhinputadd1keyargendhinputcarrykeyargendhcarryactinputactkeyargendhinputcarrykeyargendhactinputactkeyargendhpublished as a conference paper at iclr 2016

program) of a second network was mentioned in the sigma-pi units section of the in   uential pdp
paper (rumelhart et al., 1986). this idea appeared in (sutskever & hinton, 2009) in the context of
learning higher order symbolic relations and in (donnarumma et al., 2015) as the key ingredient of an
architecture for prefrontal cognitive control. schmidhuber (1992) proposed a related meta-learning
idea, whereby one learns the parameters of a slowly changing network, which in turn generates
context dependent weight changes for a second rapidly changing network. these approaches have
only been demonstrated in very limited settings. in cognitive science, several theories of brain areas
controlling other brain parts so as to carry out multiple tasks have been proposed; see for example
schneider & chein (2003); anderson (2010) and donnarumma et al. (2012).
related problems have been studied in the literature on hierarchical id23 (e.g.,
dietterich (2000); andre & russell (2001); sutton et al. (1999) and schaul et al. (2015)), imitation
and apprenticeship learning (e.g., kolter et al. (2008) and rothkopf & ballard (2013)) and elicita-
tion of options through human interaction (subramanian et al., 2011). these ideas have held great
promise, but have not enjoyed signi   cant impact. we believe the recurrent compositional neural
representations proposed in this paper could help these approaches in the future, and in particular in
overcoming feature engineering.
several recent advancements have extended recurrent networks to solve problems beyond simple
sequence prediction. graves et al. (2014) developed a id63 capable of learning
and executing simple programs such as repeat copying, simple priority sorting and associative recall.
vinyals et al. (2015) developed id193 that generalize the notion of encoder attention in
order to provide the decoder a variable-sized output space depending on the input sequence length.
this model was shown to be effective for combinatorial optimization problems such as the traveling
salesman and delaunay triangulation. while our proposed model is trained on execution traces in-
stead of input and output pairs, in exchange for this richer supervision we bene   t from compositional
program structure, improving data ef   ciency on several problems.
this work is also closely related to program induction. most previous work on program induc-
tion, i.e.
inducing a program given example input and output pairs, has used genetic program-
ming (banzhaf et al., 1998) to evolve useful programs from candidate populations. mou et al.
(2014) process program symbols to learn max-margin program embeddings with the help of parse
trees. zaremba & sutskever (2014) trained lstm models to read in the text of simple programs
character-by-character and correctly predict the program output.
joulin & mikolov (2015) aug-
mented a recurrent network with a pushdown stack, allowing for generalization to longer input
sequences than seen during training for several algorithmic patterns.
contemporary to this work, several papers have also studied program induction with variants of
recurrent neural networks (zaremba & sutskever, 2015; zaremba et al., 2015; kaiser & sutskever,
2015; kurach et al., 2015; neelakantan et al., 2015). while we share a similar motivation, our
approach is distinct in that we explicitly incorporate compositional structure into the network using
a program memory, allowing the model to learn new programs by combining sub-programs.

3 model
the npi core is a long short-term memory (lstm) network (hochreiter & schmidhuber, 1997)
that acts as a router between programs conditioned on the current state observation and previous
hidden unit states. at each time step, the core module can select another program to invoke using
content-based addressing. it emits the id203 of ending the current program with a single binary
unit. if this id203 is over threshold (we used 0.5), control is returned to the caller by popping
the caller   s lstm hidden units and program embedding off of a program call stack and resuming
execution in this context.
the npi may also optionally write arguments (arg) that are passed by reference or value to the
invoked sub-programs. for example, an argument could indicate a speci   c location in the input
sequence (by reference), or it could specify a number to write down at a particular location in the
sequence (by value). the subsequent state consists of these arguments and observations of the
environment. the approach is illustrated in figures 1 and 2.
it must be emphasized that there is a single id136 core. that is, all the lstm instantiations
executing arbitrary programs share the same parameters. different programs correspond to program
embeddings, which are stored in a learnable persistent memory. the programs therefore have a more

3

published as a conference paper at iclr 2016

id136

succinct representation than neural programs encoded as the full set of weights in a neural network
(rumelhart et al., 1986; graves et al., 2014).
the output of an npi, conditioned on an input state and a program to run, is a sequence of actions
in a given environment. in this work, we consider several environments: a 1-d array with read-only
pointers and a swap action, a 2-d scratch pad with read-write pointers, and a cad renderer with
controllable elevation and azimuth movements. note that the sequence of actions for a program is
not    xed, but dependent also on the input state.
3.1
denote the environment observation at time t as et     e, and the current program arguments as
at     a. the form of et can vary dramatically by environment; for example it could be a color
image or an array of numbers. the program arguments at can also vary by environment, but in
the experiments for this paper we always used a 3-tuple of integers (at(1), at(2), at(3)). given
the environment and arguments at time t, a    xed-length state encoding st     rd is extracted by a
domain-speci   c encoder fenc : e  a     rd. in section 4 we provide examples of several encoders.
note that a single npi network can have multiple encoders for multiple environments, and encoders
can potentially also be shared across tasks.
we denote the current program embedding as pt     rp . the previous hidden unit and cell states
t   1     rm , l = 1, ..., l where l is the number of layers in the lstm.
are h(l)
the program and state vectors are then propagated forward through an lstm mapping flstm as in
(sutskever et al., 2014). how to fuse pt and st within flstm is an implementation detail, but in this
work we concatenate and feed through a 2-layer mlp with recti   ed linear (relu) hidden activation
and linear decoder.
t , several decoders generate the outputs. the id203 of
from the top lstm hidden state hl
   nishing the program and returning to the caller 1 is computed by fend : rm     [0, 1]. the lookup
key embedding used for retrieving the next program from memory is computed by fprog : rm    
rk. note that rk can be much smaller than rp because the key only need act as the identi   er
of a program, while the program embedding must have enough capacity to conditionally generate a
sequence of actions. the contents of the arguments to the next program to be called are generated
by farg : rm     a. the feed-forward steps of program id136 are summarized below:

t   1     rm and c(l)

st = fenc(et, at)
ht = flstm(st, pt, ht   1)
rt = fend(ht), kt = fprog(ht), at+1 = farg(ht)

(1)
(2)
(3)
where rt, kt and at+1 correspond to the end-of-program id203, program key embedding, and
output arguments at time t, respectively. these yield input arguments at time t + 1. to simplify the
notation, we have abstracted properties such as layers and cell memory in the sequence-to-sequence
lstm of equation (2); see (sutskever et al., 2014) for details.
the npi representation is equipped with key-value memory structures m key     rn  k and
m prog     rn  p storing program keys and program embeddings, respectively, where n is the
current number of programs in memory. we can add more programs by adding rows to memory.
during training, the next program identi   er is provided to the model as ground-truth, so that its
embedding can be retrieved from the corresponding row of m prog. at test time, we compute the
   program id    by comparing the key embedding kt to each row of m key storing all program keys.
then the program embedding is retrieved from m prog as follows:

i    = arg max

i=1..n

(m key

i,: )t kt , pt+1 = m prog
i   ,:

(4)

the next environmental state et+1 will be determined by the dynamics of the environment and can
be affected by both the choice of program pt and the contents of the output arguments at, i.e.

(5)
the transition mapping fenv is domain-speci   c and will be discussed in section 4. a description of
the id136 procedure is given in algorithm 1.

et+1     fenv(et, pt, at)

1in our implementation, a program may    rst call a subprogram before itself    nishing. the only exception
is the act program that signals a low-level action to the environment, e.g. moving a pointer one step left or
writing a value. by convention act does not call any further sub-programs.

4

published as a conference paper at iclr 2016

algorithm 1 neural programming id136
1: inputs: environment observation e, program id i, arguments a, stop threshold   
2: function run(i, a)
3:
4:
5:
6:
7:

h     0, r     0, p     m prog
while r <    do

s     fenc(e, a), h     flstm(s, p, h)
r     fend(h), k     fprog(h), a2     farg(h)
i2     arg max
if i == act then e     fenv(e, p, a)
else run(i2, a2)

j,: )t k

(m key

j=1..n

8:
9:

i,:

(cid:46) decide the next program to run.

(cid:46) update the environment based on act.
(cid:46) run subprogram i2 with arguments a2

(cid:46) init lstm and return id203.

(cid:46) feed-forward npi one step.

  

(  inp,  out)

(cid:88)

t(cid:88)

each task has a set of actions that affect the environment. for example, in addition there are left
and right actions that move a speci   ed pointer, and a write action which writes a value at
a speci   ed location. these actions are encapsulated into a general-purpose act program shared
across tasks, and the concrete action to be taken is indicated by the npi-generated arguments at.
note that the core lstm module of our npi representation is completely agnostic to the data modal-
ity used to produce the state encoding. as long as the same    xed-length embedding is extracted,
the same module can in practice route between programs related to sorting arrays just as easily as
between programs related to rotating 3d objects. in the experimental sections, we provide details of
the modality-speci   c deep neural networks that we use to produce these    xed-length state vectors.
3.2 training
: {it+1, at+1, rt}, t = 1, ...t , where t is
to train we use execution traces   inp
the sequence length. program ids it and it+1 are row-indices in m key and m prog of the programs
to run at time t and t+1, respectively. we propose to directly maximize the id203 of the correct
execution trace output   out conditioned on   inp:

: {et, it, at} and   out

t

t

      = arg max

log p (  out|  inp;   )

(6)

where    are the parameters of our model. since the traces are variable in length depending on the
input, we apply the chain rule to model the joint id203 over   out

as follows:

, ...,   out

1

t

log p (  out|  inp;   ) =

log p (  out

t

|  inp

1

, ...,   inp

t

;   )

(7)

t=1

t

t

t

1

1

, ...,   inp

, ...,   inp

log p (  out

) = log p (it+1|ht) + log p (at+1|ht) + log p (rt|ht)

note that for many problems the input history   inp
is critical to deciding future actions
because the environment observation at the current time-step et alone does not contain enough in-
formation. the hidden unit activations of the lstm in npi are capable of capturing these temporal
dependencies. the single-step id155 in equation (7) can be factorized into three
further conditional distributions, corresponding to predicting the next program, next arguments, and
whether to halt execution:
|  inp

(8)
where ht is the output of flstm at time t, carrying information from previous time steps. we train
by gradient ascent on the likelihood in equation (7).
we used an adaptive curriculum in which training examples for each mini-batch are fetched with fre-
quency proportional to the model   s current prediction error for the corresponding program. specif-
ically, we set the sampling frequency using a softmax over average prediction error across all pro-
grams, with con   gurable temperature. every 1000 steps of training we re-estimated these prediction
errors. intuitively, this forces the model to focus on learning the program for which it currently per-
forms worst in executing. we found that the adaptive curriculum immediately worked much better
than our best-performing hand-designed curriculum, allowing a multi-task npi to achieve compara-
ble performance to single-task npi on all tasks.
we also note that our program has a distinct memory advantage over basic lstms because all sub-
programs can be trained in parallel. for programs whose execution length grows e.g. quadratically

5

published as a conference paper at iclr 2016

figure 3: illustration of the addition environment used in our experiments.

(a) example scratch pad and pointers
used for computing    96 + 125 = 221   .
carry step is being implemented.

(b) actual trace of addition program generated by our model
on the problem shown to the left. note that we substituted
the act calls in the trace with more human-readable steps.

with the input sequence length, an lstm will by highly constrained by device memory to train on
short sequences. by exploiting compositionality, an effective curriculum can often be developed
with sublinear-length subprograms, enabling our npi model to train on order of magnitude larger
sequences than the lstm.

4 experiments
this section describes the environment and state encoder function for each task, and shows example
outputs and prediction accuracy results. for all tasks, the core lstm had two layers of size 256.
we trained the npi using the adam solver (kingma & ba, 2015) with base learning rate 0.0001,
batch size 1, and decayed the learning rate by a factor of 0.95 every 10,000 steps.

4.1 task and environment descriptions
in this section we provide an overview of the tasks used to evaluate our model. table 2 in the
appendix provides a full listing of all the programs and subprograms learned by our model.

addition

the task in this environment is to read in the digits of two base-10 numbers and produce the digits
of the answer. our goal is to teach the model the standard (at least in the us) grade school algorithm
of adding, in which one works from right to left applying single-digit add and carry operations.
in this environment, the network is endowed with a    scratch pad    with which to store intermediate
computations; e.g. to record carries. there are four pointers; one for each of the two input numbers,
one for the carry, and another to write the output. at each time step, a pointer can be moved left or
right, or it can record a value to the pad. figure 3a illustrates the environment of this model, and
figure 3b provides a real execution trace generated by our model.
for the state encoder fenc, the model is allowed a view of the scratch pad from the perspective of
each of the four pointers. that is, the model sees the current values at pointer locations of the two
inputs, the carry row and the output row, as 1-of-k encodings, where k is 10 because we are working
in base 10. we also append the values of the input argument tuple at:

fenc(q, i1, i2, i3, i4, at) = m lp ([q(1, i1), q(2, i2), q(3, i3), q(4, i4), at(1), at(2), at(3)]) (9)
where q     r4  n  k, and i1, ..., i4 are pointers, one per scratch pad row. the    rst dimension of q
corresponds to scratch pad rows, n is the number of columns (digits) and k is the one-hot encoding
dimension. to begin the add program, we set the initial arguments to a default value and initialize
all pointers to be at the rightmost column. the only subprogram with non-default arguments is act,
in which case the arguments indicate an action to be taken by a speci   ed pointer.

sorting

in this section we apply our model to a setting with potentially much longer execution traces: sorting
an array of numbers using bubblesort. as in the case of addition we can use a scratch pad to store
intermediate states of the array. we de   ne the encoder as follows:

fenc(q, i1, i2, at) = m lp ([q(1, i1), q(1, i2), at(1), at(2), at(3)])

(10)

6

input 1input 2carryoutput00096001250011100021add  add1    write out 1    carry      ptr carry left      write carry 1      ptr carry right  lshift    ptr inp1 left    ptr inp2 left    ptr carry left    ptr out left  add1    write out 2    carry      ptr carry left      write carry 1      ptr carry right  lshift    ptr inp1 left    ptr inp2 left    ptr carry left    ptr out left  add1    write out 2  lshift    ptr inp1 left    ptr inp2 left    ptr carry left    ptr out leftpublished as a conference paper at iclr 2016

figure 4: illustration of the sorting environment used in our experiments.

(a) example scratch pad and pointers
used for sorting. several steps of the
bubble subprogram are shown.

(b) excerpt from the trace of the learned bubblesort program.

where q     r1  n  k is the pad, n is the array length and k is the array entry embedding dimension.
figure 4 shows an example series of array states and an excerpt of an execution trace.

canonicalizing 3d models

we also apply our model to a vision task with a very different perceptual environment - pixels. given
a rendering of a 3d car, we would like to learn a visual program that    canonicalizes    the model with
respect to its pose. whatever the starting position, the program should generate a trajectory of
actions that delivers the camera to the target view, e.g. frontal pose at a 15    elevation. for training
data, we used renderings of the 3d car cad models from (fidler et al., 2012).
this is a nontrivial problem because different starting positions will require quite different trajec-
tories to reach the target. further complicating the problem is the fact that the model will need to
generalize to different car models than it saw during training.
we again use a scratch pad, but here it is a very simple read-only pad that only contains a target
camera elevation and azimuth     i.e., the    canonical pose   . since observations come in the form of
image pixels, we use a convolutional neural network fcn n as the image encoder:

fenc(q, x, i1, i2, at) = m lp ([q(1, i1), q(2, i2), fcn n (x), at(1), at(2), at(3)])

(11)
where x     rh  w  3 is a car rendering at the current pose, q     r2  1  k is the pad containing
canonical azimuth and elevation, i1, i2 are the (   xed at 1) pointer locations, and k is the one-hot
encoding dimension of pose coordinates. we set k = 24 corresponding to 15    pose increments.
note, critically, that our npi model only has access to pixels of the rendering and the target pose,
and is not provided the pose of query frames. we are also aware that one solution to this problem
would be to train a pose classi   er network and then    nd the shortest path to canonical pose via
classical methods. that is also a sensible approach. however, our purpose here is to show that our
method generalizes beyond the scratch pad domain to detailed images of 3d objects, and also to
other environments with a single multi-task model.

4.2 sample complexity and generalization
both lstms and id63s can learn to perform sorting to a limited degree, although
they have not been shown to generalize well to much longer arrays than were seen during training.
however, we are interested not only in whether sorting can be accomplished, but whether a particular
sorting algorithm (e.g. bubblesort) can be learned by the model, and how effectively in terms of
sample complexity and generalization.
we compare the generalization ability of our model to a    at sequence-to-sequence lstm (sutskever
et al., 2014), using the same number of layers (2) and hidden units (256). note that a    at 2 version
of npi could also learn sorting of short arrays, but because bubblesort runs in o(n 2) for arrays of
length n, the execution traces quickly become far too long to store the required number of lstm
states in memory. our npi architecture can train on much larger arrays by exploiting compositional
structure; the memory requirements of any given subprogram can be restricted to o(n ).

2by    at in this case, we mean non-compositional, not making use of subprograms, and only making calls

to act in order to swap values and move pointers.

7

t=032491324912349123491t=1t=2t=3arraybubblesort  bubble    ptr 2 right    bstep      compswap        swap 1 2      rshift        ptr 1 right        ptr 2 right           bstep      compswap              rshift        ptr 1 right        ptr 2 right   reset               lshift      ptr 1 left      ptr 2 left    lshift      ptr 1 left      ptr 2 left             lshift      ptr 1 left      ptr 2 leftbubble                 ptr 2 right    bstep      compswap        swap 1 2      rshift        ptr 1 right        ptr 2 right   ...    bstep      compswap              rshift        ptr 1 right        ptr 2 rightpublished as a conference paper at iclr 2016

figure 5: sample complexity. test accuracy
of sequence-to-sequence lstm versus npi on
length-20 arrays of single-digit numbers. note
that npi is able to mine and train on subprogram
traces from each bubblesort example.

figure 6: strong vs. weak generalization. test
accuracy of sequence-to-sequence lstm ver-
sus npi on varying-length arrays of single-digit
numbers. both models were trained on arrays of
single-digit numbers up to length 20.

a strong indicator of whether a neural network has learned a program well is whether it can run the
program on inputs of previously-unseen sizes. to evaluate this property, we train both the sequence-
to-sequence lstm and npi to perform bubblesort on arrays of single-digit numbers from length 2
to length 20. compared to    xed-length inputs this raises the challenge level during training, but in
exchange we can get a more    exible and generalizable sorting program.
to handle variable-sized inputs, the state representation must have some information about input se-
quence length and the number of steps taken so far. for example, the main bubblesort program
naturally needs to call its helper function bubble a number of times dependent on the sequence
length. we enable this in our model by adding a third pointer that acts as a counter; each time bub-
ble is called the pointer is advanced by one step. the scratch pad environment also provides a bit
indicating whether a pointer is at the start or end of a sequence, equivalent in purpose to end tokens
used in a sequence-to-sequence model.
for each length, we provided 64 example bubblesort traces, for a total of 1,216 examples. then,
we evaluated whether the network can learn to sort arrays beyond length 20. we found that the
trained model generalizes well, and is capable of sorting arrays up to size 60; see figure 6. at 60
and beyond, we observed a failure mode in which sweeps of pointers across the array would take
the wrong number of steps, suggesting that the limiting performance factor is related to counting.
in stark contrast, when provided with the 1,216 examples, the sequence-to-sequence lstms fail to
generalize beyond arrays of length 25 as shown in figure 6.
to study sample complexity further, we    x the length of the arrays to 20 and vary the number of
training examples. we see in figure 5 that npi starts learning with 2 examples and is able to sort
almost perfectly with only 8 examples. the sequence-to-sequence model on the other hand requires
64 examples to start learning and only manages to sort well with over 250 examples.
figure 7 shows several example canonicalization trajectories generated by our model, starting from
the leftmost car. the image encoder was a convolutional network with three passes of stride-2
convolution and pooling, trained on renderings of size 128    128. the canonical target pose in this
case is frontal with 15    elevation. at test time, from an initial rendering, npi is able to canonicalize
cars of varying appearance from multiple starting positions. importantly, it can generalize to car
appearances not encountered in the training set as shown in figure 7.

4.3 learning new programs with a fixed core
one challenge for continual learning of neural-network-based agents is that training on new tasks
and experiences can lead to degraded performance in old tasks. the learning of new tasks may
require that the network weights change substantially, so care must be taken to avoid catastrophic
forgetting (mccloskey & cohen, 1989; oreilly et al., 2014). using npi, one solution is to    x the
weights of the core routing module, and only make sparse updates to the program memory.
when adding a new program the core module   s routing computation will be completely unaffected;
all the learning for a new task occurs in program embedding space. of course, the addition of new
programs to the memory adds a new choice of program at each time step, and an old program could

8

training sequence lengthspublished as a conference paper at iclr 2016

figure 7: example canonicalization of several different test set cars. the network is able to generate
and execute the appropriate plan based on the starting car image. this npi was trained on trajectories
starting at azimuth (   75   ...75   ) , elevation (0   ...60   ) in 15    increments. the training trajectories
target azimuth 0    and elevation 15   , as in the generated traces above.

mistakenly call a newly added program. to overcome this, when learning a new set of program
vectors with a    xed core, in practice we train not only on example traces of the new program, but
also traces of existing programs. alternatively, a simpler approach is to prevent existing programs
from calling subsequently added programs, allowing addition of new programs without ever looking
back at training data for known programs. in either case, note that only the memory slots of the new
programs are updated, and all other weights, including other program embeddings, are    xed.
table 1 shows the result of adding a maximum-   nding program max to a multitask npi trained
on addition, sorting and canonicalization. max    rst calls bubblesort and then a new program
rjmp, which moves pointers to the right of the sorted array, where the max element can be read.
during training we froze all weights except for the two newly-added program embeddings. we
   nd that npi learns max perfectly without forgetting the other tasks. in particular, after training a
single multi-task model as outlined in the following section, learning the max program with this
   xed-core multi-task npi results in no performance deterioration for all three tasks.
4.4 solving multiple tasks with a single network
in this section we perform a controlled experiment to compare the performance of a multi-task npi
with several single-task npi models. table 1 shows the results for addition, sorting and canonical-
izing 3d car models. we trained and evaluated on 10-digit numbers for addition, length-5 arrays for
sorting, and up to four-step trajectories for canonicalization. as shown in table 1, one multi-task
npi can learn all three programs (and necessarily the 21 subprograms) with comparable accuracy
compared to each single-task npi.
task
addition
sorting
canon. seen car
canon. unseen
maximum

table 1: per-sequence % accuracy.    + max   
indicates performance after addition of the ad-
ditional max-   nding subprograms to memory.
   unseen    uses a test set with disjoint car mod-
els from the training set, while    seen car    uses
the same car models but different trajectories.

single multi
97.0
100.0
100.0
100.0
91.4
89.5
88.7
89.9

+ max
97.0
100.0
91.4
89.9
100.0

-

-

5 conclusion
we have shown that the npi can learn programs in very dissimilar environments with different
affordances. in the context of sorting we showed that npi exhibits very strong generalization in
comparison to sequence-to-sequence lstms. we also showed how a trained npi with a    xed core
can continue to learn new programs without forgetting already learned programs.

acknowledgments

we sincerely thank arun nair and ed grefenstette for helpful suggestions.

9

goto 1 2  hgoto    lgoto      act(left)  vgoto    dgoto      act(down)goto 1 2  hgoto    rgoto      act(right)      act(right)      act(right)  vgoto    dgoto      act(down)      act(down)7goto 1 2  hgoto    rgoto      act(right)  vgoto    ugoto      act(up)goto 1 2  hgoto    lgoto      act(left)      act(left)      act(left)      act(left)      act(left)  vgoto    ugoto      act(up)123123456123123456published as a conference paper at iclr 2016

references
anderson, michael l. neural reuse: a fundamental organizational principle of the brain. behavioral

and brain sciences, 33:245   266, 8 2010.

andre, david and russell, stuart j. programmable id23 agents. in advances in

neural information processing systems, pp. 1019   1025. 2001.

banzhaf, wolfgang, nordin, peter, keller, robert e, and francone, frank d. genetic programming:

an introduction, volume 1. morgan kaufmann san francisco, 1998.

dietterich, thomas g. hierarchical id23 with the maxq value function decom-

position. journal of arti   cial intelligence research, 13:227   303, 2000.

donnarumma, francesco, prevete, roberto, and trautteur, giuseppe. programming in the brain: a

neural network theoretical framework. connection science, 24(2-3):71   90, 2012.

donnarumma, francesco, prevete, roberto, chersi, fabian, and pezzulo, giovanni. a programmer-
interpreter neural network architecture for prefrontal cognitive control. international journal of
neural systems, 25(6):1550017, 2015.

fidler, sanja, dickinson, sven, and urtasun, raquel. 3d id164 and viewpoint estimation
with a deformable 3d cuboid model. in advances in neural information processing systems, 2012.

graves, alex, wayne, greg, and danihelka, ivo. id63s.

arxiv:1410.5401, 2014.

arxiv preprint

hochreiter, sepp and schmidhuber, j  urgen. long short-term memory. neural computation, 9(8):

1735   1780, 1997.

joulin, armand and mikolov, tomas. inferring algorithmic patterns with stack-augmented recurrent

nets. in nips, 2015.

kaiser,   ukasz and sutskever, ilya. neural gpus learn algorithms. arxiv preprint arxiv:1511.08228,

2015.

kingma, diederik and ba, jimmy. adam: a method for stochastic optimization. 2015.

kolter, zico, abbeel, pieter, and ng, andrew y. hierarchical apprenticeship learning with appli-
in advances in neural information processing systems, pp.

cation to quadruped locomotion.
769   776. 2008.

kurach, karol, andrychowicz, marcin, and sutskever, ilya. neural random-access machines. arxiv

preprint arxiv:1511.06392, 2015.

mccloskey, michael and cohen, neal j. catastrophic interference in connectionist networks: the
sequential learning problem. in the psychology of learning and motivation, volume 24, pp. 109   
165. 1989.

mou, lili, li, ge, liu, yuxuan, peng, hao, jin, zhi, xu, yan, and zhang, lu. building program

vector representations for deep learning. arxiv preprint arxiv:1409.3358, 2014.

neelakantan, arvind, le, quoc v, and sutskever, ilya. neural programmer: inducing latent pro-

grams with id119. arxiv preprint arxiv:1511.04834, 2015.

oreilly, randall c., bhattacharyya, rajan, howard, michael d., and ketz, nicholas. complemen-

tary learning systems. cognitive science, 38(6):1229   1248, 2014.

rothkopf, constantina. and ballard, danah. modular inverse id23 for visuomo-

tor behavior. biological cybernetics, 107(4):477   490, 2013.

rumelhart, d. e., hinton, g. e., and mcclelland, j. l. parallel distributed processing: explorations
in the microstructure of cognition, vol. 1. chapter a general framework for parallel distributed
processing, pp. 45   76. mit press, 1986.

10

published as a conference paper at iclr 2016

schaul, tom, horgan, daniel, gregor, karol, and silver, david. universal value function approxi-

mators. in international conference on machine learning, 2015.

schmidhuber, j  urgen. learning to control fast-weight memories: an alternative to dynamic recur-

rent networks. neural computation, 4(1):131   139, 1992.

schneider, walter and chein, jason m. controlled and automatic processing: behavior, theory, and

biological mechanisms. cognitive science, 27(3):525   559, 2003.

subramanian, kaushik, isbell, charles, and thomaz, andrea. learning options through human

interaction. in ijcai workshop on agents learning interactively from human teachers, 2011.

sutskever, ilya and hinton, geoffrey e. using matrices to model symbolic relationship. in advances

in neural information processing systems, pp. 1593   1600. 2009.

sutskever, ilya, vinyals, oriol, and le, quoc vv. sequence to sequence learning with neural net-

works. in advances in neural information processing systems, pp. 3104   3112, 2014.

sutton, richard s., precup, doina, and singh, satinder. between mdps and semi-mdps: a frame-
work for temporal abstraction in id23. arti   cial intelligence, 112(1-2):181   
211, 1999.

vinyals, oriol, fortunato, meire, and jaitly, navdeep. id193. advances in neural infor-

mation processing systems (nips), 2015.

zaremba, wojciech and sutskever, ilya. learning to execute. arxiv preprint arxiv:1410.4615, 2014.

zaremba, wojciech and sutskever, ilya. id23 id63s. arxiv

preprint arxiv:1505.00521, 2015.

zaremba, wojciech, mikolov, tomas, joulin, armand, and fergus, rob. learning simple algorithms

from examples. arxiv preprint arxiv:1511.07275, 2015.

11

published as a conference paper at iclr 2016

6 appendix

6.1 listing of learned programs

below we list the programs learned by our model:

program
add
add1
carry
lshift
rshift
act
bubblesort
bubble
reset
bstep
compswap
lshift
rshift
act
goto
hgoto
lgoto
rgoto
vgoto
ugoto
dgoto
act
rjmp
max

descriptions
perform multi-digit addition
perform single-digit addition
mark a 1 in the carry row one unit left
shift a speci   ed pointer one step left
shift a speci   ed pointer one step right
move a pointer or write to the scratch pad
perform bubble sort (ascending order)
perform one sweep of pointers left to right
move both pointers all the way left
conditionally swap and advance pointers
conditionally swap two elements
shift a speci   ed pointer one step left
shift a speci   ed pointer one step right
swap two values at pointer locations or move a pointer
change 3d car pose to match the target
move horizontally to the target angle
move left to match the target angle
move right to match the target angle
move vertically to the target elevation
move up to match the target elevation
move down to match the target elevation
move camera 15    up, down, left or right
move all pointers to the rightmost posiiton
find maximum element of an array

calls
add1, lshift
act, carry
act
act
act
-
bubble, reset
act, bstep
lshift
compswap, rshift
act
act
act
-
hgoto, vgoto
lgoto, rgoto
act
act
ugoto, dgoto
act
act
-
rshift
bubblesort,rjmp

table 2: programs learned for addition, sorting and 3d car canonicalization. note the the act
program has a different effect depending on the environment and on the passed-in arguments.

6.2 generated execution trace of bubblesort
figure 8 shows the sequence of program calls for bubblesort. pointers 1 and 2 are used to im-

figure 8: generated execution trace from our trained npi sorting the array [9,2,5].

plement the    bubble    operation involving the comparison and swapping of adjacent array elements.
the third pointer (referred to in the trace as    ptr 3   ) is used to count the number of calls to bub-
ble. after every call to reset the swapping pointers are moved to the beginning of the array and
the counting pointer is advanced by 1. when it has reached the end of the scratch pad, the model
learns to halt execution of bubblesort.

12

bubblesort  bubble    ptr 2 right    bstep      compswap        swap 1 2      rshift        ptr 1 right        ptr 2 right    bstep      compswap        swap 1 2      rshift        ptr 1 right        ptr 2 right  reset    lshift      ptr 1 left      ptr 2 left    lshift      ptr 1 left      ptr 2 left    ptr 3 right  bubble    ptr 2 right    bstep      compswap      rshift        ptr 1 right        ptr 2 right    bstep      compswap      rshift        ptr 1 right        ptr 2 right  reset    lshift      ptr 1 left      ptr 2 left    lshift      ptr 1 left      ptr 2 left    ptr 3 right  bubble    ptr 2 right    bstep      compswap      rshift        ptr 1 right        ptr 2 right    bstep      compswap      rshift        ptr 1 right        ptr 2 right  reset    lshift      ptr 1 left      ptr 2 left    lshift      ptr 1 left      ptr 2 left    ptr 3 rightpublished as a conference paper at iclr 2016

6.3 additional experiment on addition generalization

based on reviewer feedback, we conducted an additional comparison of npi and sequence-to-
sequence models for the addition task, to evaluate the generalization ability. we implemented addi-
tion in a sequence to sequence model, training to model sequences of the following form, e.g. for
   90 + 160 = 250    we represent the sequence as:

90x160x250

for the simple id195 baseline above (same number of lstm layers and hidden units as npi), we
observed that the model could predict one or two digits reliably, but did not generalize even up to
20-digit addition. however, we are aware that others have gotten multi-digit addition of the above
form to work to some extent with curriculum learning (zaremba & sutskever, 2014). in order to
make a more competitive baseline, we helped id195 in two ways: 1) reverse input digits and
stack the two numbers on top of each other to form a 2-channel sequence, and 2) reverse input digits
and generate reversed output digits immediately at each time step.
in the approach of 1), the id195 model schematically looks like this:

output: xxxx250
input 1: 090xxxx
input 2: 061xxxx

in the approach of 2), the sequence looks like this:

output: 052
input 1: 090
input 2: 061

both 1) which we call s2s-stacked and 2) which we call s2s-easy are much stronger competitors to
npi than even the proposed addition baseline. we compare the generalization performance of npi
to these baselines in the    gure below:

figure 9: comparing npi and id195 variants on addition generalization to longer sequences.

we found that npi trained on 32 examples for problem lengths 1,...,20 generalizes with 100% ac-
curacy to all the lengths we tried (up to 3000). s2s-easy trained on twice as many examples gen-
eralizes to just over length 2000 problems. s2s-stacked barely generalizes beyond 5, even with far
more data. this suggests that locality of computation makes a large impact on generalization per-
formance. even when we carefully ordered and stacked the input numbers for id195, npi still
had an edge in performance. in contrast to id195, npi is taught (supervised for now) to move
its pointers so that the key operations (e.g. single digit add, carry) can be done using only local
information, and this appears to help generalization.

13

