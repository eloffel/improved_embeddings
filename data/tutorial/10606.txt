5
1
0
2

 

p
e
s
1

 

 
 
]

v
c
.
s
c
[
 
 

2
v
4
0
2
6
0

.

6
0
5
1
:
v
i
x
r
a

learningtosegmentobjectcandidatespedroo.pinheiro   ronancollobertpiotrdoll  arpedro@opinheiro.comlocronan@fb.compdollar@fb.comfacebookairesearchabstractrecentobjectdetectionsystemsrelyontwocriticalsteps:(1)asetofobjectpro-posalsispredictedasef   cientlyaspossible,and(2)thissetofcandidateproposalsisthenpassedtoanobjectclassi   er.suchapproacheshavebeenshowntheycanbefast,whileachievingthestateoftheartindetectionperformance.inthispa-per,weproposeanewwaytogenerateobjectproposals,introducinganapproachbasedonadiscriminativeconvolutionalnetwork.ourmodelistrainedjointlywithtwoobjectives:givenanimagepatch,the   rstpartofthesystemoutputsaclass-agnosticsegmentationmask,whilethesecondpartofthesystemoutputsthelikelihoodofthepatchbeingcenteredonafullobject.attesttime,themodelisef   cientlyappliedonthewholetestimageandgeneratesasetofsegmenta-tionmasks,eachofthembeingassignedwithacorrespondingobjectlikelihoodscore.weshowthatourmodelyieldssigni   cantimprovementsoverstate-of-the-artobjectproposalalgorithms.inparticular,comparedtopreviousapproaches,ourmodelobtainssubstantiallyhigherobjectrecallusingfewerproposals.wealsoshowthatourmodelisabletogeneralizetounseencategoriesithasnotseenduringtraining.unlikeallpreviousapproachesforgeneratingobjectmasks,wedonotrelyonedges,superpixels,oranyotherformoflow-levelsegmentation.1introductionobjectdetectionisoneofthemostfoundationaltasksincomputervision[21].untilrecently,thedominantparadigminobjectdetectionwastheslidingwindowframework:aclassi   erisappliedateveryobjectlocationandscale[4,8,32].morerecently,girshicketal.[10]proposedatwo-phaseapproach.first,arichsetofobjectproposals(i.e.,asetofimageregionswhicharelikelytocontainanobject)isgeneratedusingafast(butpossiblyimprecise)algorithm.second,aconvolutionalneuralnetworkclassi   erisappliedoneachoftheproposals.thisapproachprovidesanotablegaininobjectdetectionaccuracycomparedtoclassicslidingwindowapproaches.sincethen,moststate-of-the-artobjectdetectorsforboththepascalvoc[7]andid163[5]datasetsrelyonobjectproposalsasa   rstpreprocessingstep[10,15,33].objectproposalalgorithmsaimto   nddiverseregionsinanimagewhicharelikelytocontainobjects.foref   ciencyanddetectionperformancereasons,anidealproposalmethodshouldpossessthreekeycharacteristics:(i)highrecall(i.e.,theproposedregionsshouldcontainthemaximumnumberofpossibleobjects),(ii)thehighrecallshouldbeachievedwiththeminimumnumberofregionspossible,and(iii)theproposedregionsshouldmatchtheobjectsasaccuratelyaspossible.inthispaper,wepresentanobjectproposalalgorithmbasedonconvolutionalnetworks(con-vnets)[20]thatsatis   estheseconstraintsbetterthanexistingapproaches.convnetsareanim-portantclassofalgorithmswhichhavebeenshowntobestateoftheartinmanylargescaleobjectrecognitiontasks.theycanbeseenasahierarchyoftrainable   lters,interleavedwithnon-linearities   pedroo.pinheiroiswiththeidiapresearchinstituteinmartigny,switzerlandandecolepolytechniquef  ed  eraledelausanne(epfl)inlausanne,switzerland.thisworkwasdoneduringaninternshipatfair.1andpooling.convnetssawaresurgenceafterkrizhevskyetal.[18]demonstratedthattheyper-formverywellontheid163classi   cationbenchmark.moreover,thesemodelslearnsuf   cientlygeneralimagefeatures,whichcanbetransferredtomanydifferenttasks[10,11,3,22,23].givenaninputimagepatch,ouralgorithmgeneratesaclass-agnosticmaskandanassociatedscorewhichestimatesthelikelihoodofthepatchfullycontainingacenteredobject(withoutanynotionofanobjectcategory).thecoreofourmodelisaconvnetwhichjointlypredictsthemaskandtheobjectscore.alargepartofthenetworkissharedbetweenthosetwotasks:onlythelastfewnetworklayersarespecializedforseparatelyoutputtingamaskandscoreprediction.themodelistrainedbyoptimizingacostfunctionthattargetsbothtaskssimultaneously.wetrainonmscoco[21]andevaluatethemodelontwoobjectdetectiondatasets,pascalvoc[7]andmscoco.byleveragingpowerfulconvnetfeaturerepresentationstrainedonid163andadaptedonthelargeamountofsegmentedtrainingdataavailableincoco,weareabletobeatthestateoftheartinobjectproposalsgenerationundermultiplescenarios.ourmostnotableachievementisthatourapproachbeatsothermethodsbyalargemarginwhileconsideringasmallernumberofproposals.moreover,wedemonstratethegeneralizationcapabilitiesofourmodelbytestingitonobjectcate-goriesnotseenduringtraining.finally,unlikeallpreviousapproachesforgeneratingsegmentationproposals,wedonotrelyonedges,superpixels,oranyotherformoflow-levelsegmentation.ourapproachisthe   rsttolearntogeneratesegmentationproposalsdirectlyfromrawimagedata.thepaperisorganizedasfollows:  2presentsrelatedwork,  3describesourarchitecturechoices,and  4describesourexperimentsindifferentdatasets.weconcludein  5.2relatedworkinrecentyears,convnetshavebeenwidelyusedinthecontextofobjectrecognition.notablesystemsarealexnet[18]andmorerecentlygooglenet[29]andvgg[27],whichperformex-ceptionallywellonid163.inthesettingofobjectdetection,girshicketal.[10]proposedr-id98,aconvnet-basedmodelthatbeatsbyalargemarginmodelsrelyingonhand-designedfeatures.theirapproachcanbedividedintotwosteps:selectionofasetofsalientobjectpropos-als[31],followedbyaconvnetclassi   er[18,27].currently,moststate-of-the-artobjectdetectionapproaches[30,12,9,25]relyonthispipeline.althoughtheyareslightlydifferentintheclassi   -cationstep,theyallsharethe   rststep,whichconsistofchoosingarichsetofobjectproposals.mostobjectproposalapproachesleveragelow-levelgroupingandsaliencycues.theseapproachesusuallyfallintothreecategories:(1)objectnessscoring[1,34],inwhichproposalsareextractedbymeasuringtheobjectnessscoreofboundingboxes,(2)seedsegmentation[14,16,17],wheremodelsstartwithmultipleseedregionsandgenerateseparateforeground-backgroundsegmentationforeachseed,and(3)superpixelmerging[31,24],wheremultipleover-segmentationsaremergedaccordingtovariousheuristics.thesemodelsvaryintermsofthetypeofproposalgenerated(boundingboxesorsegmentationmasks)andiftheproposalsarerankedornot.foramorecompletesurveyofobjectproposalmethods,werecommendtherecentsurveyfromhosangetal.[13].althoughourmodelshareshighlevelsimilaritieswiththeseapproaches(wegenerateasetofrankedsegmentationproposals),theseresultsareachievedquitedifferently.allpreviousapproachesforgeneratingsegmentationmasks,including[17]whichhasalearningcomponent,relyonlow-levelsegmentationssuchassuperpixelsoredges.instead,weproposeadata-drivendiscriminativeap-proachbasedonadeep-networkarchitecturetoobtainoursegmentationproposals.mostcloselyrelatedtoourapproach,multibox[6,30]proposedtotrainaconvnetmodeltogen-erateboundingboxobjectproposals.theirapproach,similartoours,generatesasetofrankedclass-agnosticproposals.however,ourmodelgeneratessegmentationproposalsinsteadofthelessinformativeboundingboxproposals.moreover,themodelarchitectures,trainingscheme,etc.,arequitedifferentbetweenourapproachand[30].morerecently,deepbox[19]proposedaconvnetmodelthatlearnstorerankproposalsgeneratedbyedgebox,abottom-upmethodforboundingboxproposals.thissystemsharessomesimilaritiestoourscoringnetwork.ourmodel,however,isabletogeneratetheproposalsandranktheminoneshotfromthetestimage,directlyfromthepixelspace.finally,concurrentlywiththiswork,renetal.[25]proposed   regionproposalnetworks   forgeneratingboxproposalsthatsharessimilaritieswithourwork.weemphasize,however,thatunlikealltheseapproachesourmethodgeneratessegmentationmasksinsteadofboundingboxes.2vgg#1x1#conv#2x2#pool##x:#3x224x224#512x14x14#512x7x7#512x1x1#1024x1x1#fsegm(x):#224x224#fscore(x):#1x1#512x14x14#512x1x1#56x56#figure1:(top)modelarchitecture:thenetworkissplitintotwobranchesafterthesharedfeatureextractionlayers.thetopbranchpredictsasegmentationmaskforthetheobjectlocatedatthecenterwhilethebottombranchpredictsanobjectscorefortheinputpatch.(bottom)examplesoftrainingtriplets:inputpatchx,maskmandlabely.greenpatchescontainobjectsthatsatisfythespeci   edconstraintsandthereforeareassignedthelabely=1.notethatmasksfornegativeexamples(showninred)arenotusedandareshownforillustrativepurposesonly.3deepmaskproposalsourobjectproposalmethodpredictsasegmentationmaskgivenaninputpatch,andassignsascorecorrespondingtohowlikelythepatchistocontainanobject.bothmaskandscorepredictionsareachievedwithasingleconvolutionalnetwork.convnetsare   exiblemodelswhichcanbeappliedtovariouscomputervisiontasksandtheyalleviatetheneedformanuallydesignedfeatures.their   exiblenatureallowsustodesignamodelinwhichthetwotasks(maskandscorepredictions)cansharemostofthelayersofthenetwork.onlythelastlayersaretask-speci   c(seefigure1).duringtraining,thetwotasksarelearnedjointly.comparedtoamodelwhichwouldhavetwodistinctnetworksforthetwotasks,thisarchitecturechoicereducesthecapacityofthemodelandincreasesthespeedoffullsceneid136attesttime.eachsamplekinthetrainingsetisatripletcontaining(1)thergbinputpatchxk,(2)thebinarymaskcorrespondingtotheinputpatchmk(withmijk   {  1},where(i,j)correspondstoapixellocationontheinputpatch)and(3)alabelyk   {  1}whichspeci   eswhetherthepatchcontainsanobject.speci   cally,apatchxkisgivenlabelyk=1ifitsatis   esthefollowingconstraints:(i)thepatchcontainsanobjectroughlycenteredintheinputpatch(ii)theobjectisfullycontainedinthepatchandinagivenscalerangeotherwise,yk=   1,evenifanobjectispartiallypresent.thepositionalandscaletoleranceusedinourexperimentsaregivenshortly.assumingyk=1,thegroundtruthmaskmkhaspositivevaluesonlyforthepixelsthatarepartofthesingleobjectlocatedinthecenterofthepatch.ifyk=   1themaskisnotused.figure1,bottom,showsexamplesoftrainingtriplets.figure1,top,illustratesanoverallviewofourmodel,whichwecalldeepmask.thetopbranchisresponsibleforpredictingahighqualityobjectsegmentationmaskandthebottombranchpredictsthelikelihoodthatanobjectispresentandsatis   estheabovetwoconstraints.wenextdescribeindetaileachpartofthearchitecture,thetrainingprocedure,andthefastid136procedure.3.1networkarchitecturetheparametersforthelayerssharedbetweenthemaskpredictionandtheobjectscorepredictionareinitializedwithanetworkthatwaspre-trainedtoperformclassi   cationontheid163dataset[5].thismodelisthen   ne-tunedforgeneratingobjectproposalsduringtraining.wechoosethevgg-aarchitecture[27]whichconsistsofeight3  3convolutionallayers(followedbyrelunon-linearities)and   ve2  2max-poolinglayersandhasshownexcellentperformance.3asweareinterestedininferringsegmentationmasks,thespatialinformationprovidedinthecon-volutionalfeaturemapsisimportant.wethereforeremoveallthe   nalfullyconnectedlayersofthevgg-amodel.additionallywealsodiscardthelastmax-poolinglayer.theoutputofthesharedlayershasadownsamplingfactorof16duetotheremainingfour2  2max-poolinglayers;givenaninputimageofdimension3  h  w,theoutputisafeaturemapofdimensions512  h16  w16.segmentation:thebranchofthenetworkdedicatedtosegmentationiscomposedofasingle1  1convolutionlayer(andrelunon-linearity)followedbyaclassi   cationlayer.theclassi   cationlayerconsistsofh  wpixelclassi   ers,eachresponsibleforindicatingwhetheragivenpixelbelongstotheobjectinthecenterofthepatch.notethateachpixelclassi   erintheoutputplanemustbeabletoutilizeinformationcontainedintheentirefeaturemap,andthushaveacompleteviewoftheobject.thisiscriticalbecauseunlikeinsemanticsegmentation,ournetworkmustoutputamaskforasingleobjectevenwhenmultipleobjectsarepresent(e.g.,seetheelephantsinfig.1).fortheclassi   cationlayeronecoulduseeitherlocallyorfullyconnectedpixelclassi   ers.bothoptionshavedrawbacks:intheformereachclassi   erhasonlyapartialviewoftheobjectwhileinthelattertheclassi   ershaveamassivenumberofredundantparameters.instead,weopttodecomposetheclassi   cationlayerintotwolinearlayerswithnonon-linearityinbetween.thiscanbeviewedasa   low-rank   variantofusingfullyconnectedlinearclassi   ers.suchanapproachmassivelyreducesthenumberofnetworkparameterswhileallowingeachpixelclassi   ertoleverageinformationfromtheentirefeaturemap.itseffectivenessisshownintheexperiments.finally,tofurtherreducemodelcapacity,wesettheoutputoftheclassi   cationlayertobeho  wowithho<handwo<wandupsampletheoutputtoh  wtomatchtheinputdimensions.scoring:thesecondbranchofthenetworkisdedicatedtopredictingifanimagepatchsatis   esconstraints(i)and(ii):thatisifanobjectiscenteredinthepatchandattheappropriatescale.itiscomposedofa2  2max-poolinglayer,followedbytwofullyconnected(plusrelunon-linearity)layers.the   naloutputisasingle   objectness   scoreindicatingthepresenceofanobjectinthecenteroftheinputpatch(andattheappropriatescale).3.2jointlearninggivenaninputpatchxk   i,themodelistrainedtojointlyinferapixel-wisesegmentationmaskandanobjectscore.thelossfunctionisasumofbinarylogisticregressionlosses,oneforeachlocationofthesegmentationnetworkandonefortheobjectscore,overalltrainingtriplets(xk,mk,yk):l(  )=xk(cid:18)1+yk2wohoxijlog(1+e   mijkfijsegm(xk))+  log(1+e   ykfscore(xk))(cid:19)(1)here  isthesetofparameters,fijsegm(xk)isthepredictionofthesegmentationnetworkatlocation(i,j),andfscore(xk)isthepredictedobjectscore.wealternatebetweenbackpropagatingthroughthesegmentationbranchandscoringbranch(andset  =132).forthescoringbranch,thedataissampledsuchthatthemodelistrainedwithanequalnumberofpositiveandnegativesamples.notethatthefactormultiplyingthe   rsttermofequation1impliesthatweonlybackpropagatetheerroroverthesegmentationbranchifyk=1.analternativewouldbetotrainthesegmentationbranchusingnegativesaswell(settingmijk=0forallpixelsifyk=0).however,wefoundthattrainingwithpositivesonlywascriticalforgeneralizingbeyondtheobjectcategoriesseenduringtrainingandforachievinghighobjectrecall.thisway,duringid136thenetworkattemptstogenerateasegmentationmaskateverypatch,evenifnoknownobjectispresent.3.3fullsceneid136duringfullimageid136,weapplythemodeldenselyatmultiplelocationsandscales.thisisnecessarysothatforeachobjectintheimagewetestatleastonepatchthatfullycontainstheobject(roughlycenteredandattheappropriatescale),satisfyingthetwoassumptionsmadeduringtraining.thisproceduregivesasegmentationmaskandobjectscoreateachimagelocation.figure2illustratesthesegmentationoutputwhenthemodelisapplieddenselytoanimageatasinglescale.thefullimageid136procedureisef   cientsinceallcomputationscanbecomputedconvolution-ally.thevggfeaturescanbecomputeddenselyinafractionofasecondgivenatypicalinputimage.forthesegmentationbranch,thelastfullyconnectedlayercanbecomputedviaconvolu-tionsappliedtothevggfeatures.thescoresarelikewisecomputedbyconvolutionsonthevggfeaturesfollowedbytwo1  1convolutionallayers.exactruntimesaregivenin  4.4figure2:outputofsegmentationmodelapplieddenselytoafullimagewitha16pixelstride(atasinglescaleatthecentralhorizontalimageregion).multiplelocationsgiverisetogoodmasksforeachofthethreemonkeys(scoresnotshown).notethatnomonkeysappearedinourtrainingset.finally,notethatthescoringbranchofthenetworkhasadownsamplingfactor2  largerthanthesegmentationbranchduetotheadditionalmax-poolinglayer.givenaninputtestimageofsizeht  wt,thesegmentationandobjectnetworkgenerateoutputsofdimensionht16  wt16andht32  wt32,respectively.inordertoachieveaone-to-onemappingbetweenthemaskpredictionandobjectscore,weapplytheinterleavingtrickrightbeforethelastmax-poolinglayerforthescoringbranchtodoubleitsoutputresolution(weuseexactlytheimplementationdescribedin[26]).3.4implementationdetailsduringtraining,aninputpatchxkisconsideredtocontaina   canonical   positiveexampleifanobjectispreciselycenteredinthepatchandhasmaximaldimensionequaltoexactly128pixels.however,havingsometoleranceinthepositionofanobjectwithinapatchiscriticalasduringfullimageid136mostobjectswillbeobservedslightlyoffsetfromtheircanonicalposition.therefore,duringtraining,werandomlyjittereach   canonical   positiveexampletoincreasetherobustnessofourmodel.speci   cally,weconsidertranslationshift(of  16pixels),scaledeformation(of2  1/4),andalsohorizontal   ip.inallcasesweapplythesametransformationtoboththeimagepatchxkandthegroundtruthmaskmkandassigntheexampleapositivelabelyk=1.negativeexamples(yk=   1)areanypatchesatleast  32pixelsor2  1inscalefromanycanonicalpositiveexample.duringfullimageid136weapplythemodeldenselyatmultiplelocations(withastrideof16pixels)andscales(scales2   2to21withastepof21/2).thisensuresthatthereisatleastonetestedimagepatchthatfullycontainseachobjectintheimage(withinthetolerancesusedduringtraining).asintheoriginalvgg-anetwork[27],ourmodelisfedwithrgbinputpatchesofdimension3  224  224.sinceweremovedthe   fthpoolinglayer,thecommonbranchoutputsafeaturemapofdimensions512  14  14.thescorebranchofournetworkiscomposedof2  2maxpoolingfollowedbytwofullyconnectedlayers(with512and1024hiddenunits,respectively).bothoftheselayersarefollowedbyrelunon-linearityandadropout[28]procedurewitharateof0.5.a   nallinearlayerthengeneratestheobjectscore.thesegmentationbranchbeginswithasingle1  1convolutionallayerwith512units.thisfeaturemapisthenfullyconnectedtoalowdimensionaloutputofsize512,whichisfurtherfullyconnectedtoeachpixelclassi   ertogenerateanoutputofdimension56  56.asdiscussed,thereisnonon-linearitybetweenthesetwolayers.intotal,ourmodelcontainsaround75mparameters.a   nalbilinearupsamplinglayerisaddedtotransformthe56  56outputpredictiontothefull224  224resolutionoftheground-truth(directlypredictingthefullresolutionoutputwouldhavebeenmuchslower).weoptedforanon-trainablelayerasweobservedthatatrainableonesimplylearnedtobilinearlyupsample.alternatively,wetrieddownsamplingtheground-truthinsteadofupsamplingthenetworkoutput;however,wefoundthatdoingsoslightlyreducedaccuracy.designarchitectureandhyper-parameterswerechosenusingasubsetofthemscocovalidationdata[21](non-overlappingwiththedataweusedforevaluation).weconsideredalearningrateof.001.wetrainedourmodelusingstochasticgradientdescentwithabatchsizeof32examples,momentumof.9,andweightdecayof.00005.asidefromthepre-trainedvggfeatures,weightsareinitializedrandomlyfromauniformdistribution.ourmodeltakesaround5daystotrainonanvidiateslak40m.tobinarizepredictedmaskswesimplythresholdthecontinuousoutput(usingathresholdof.1forpascaland.2forcoco).alltheexperimentswereconductedusingtorch71.1http://torch.ch5figure3:deepmaskproposalswithhighestioutothegroundtruthonselectedimagesfromcoco.missedobjects(nomatchingproposalswithiou>0.5)aremarkedwitharedoutline.4experimentalresultsinthissection,weevaluatetheperformanceofourapproachonthepascalvoc2007testset[7]andonthe   rst5000imagesofthemscoco2014validationset[21].ourmodelistrainedonthecocotrainingsetwhichcontainsabout80,000imagesandatotalofnearly500,000segmentedobjects.althoughourmodelistrainedtogeneratesegmentationproposals,itcanalsobeusedtoprovideboxproposalsbytakingtheboundingboxesenclosingthesegmentationmasks.figures3and6showexamplesofgeneratedproposalswithhighestioutothegroundtruthoncoco.metrics:wemeasureaccuracyusingthecommonintersectionoverunion(iou)metric.iouistheintersectionofacandidateproposalandground-truthannotationdividedbytheareaoftheirunion.thismetriccanbeappliedtobothsegmentationandboxproposals.followinghosangetal.[13],weevaluatetheperformanceoftheproposalmethodsconsideringtheaveragerecall(ar)betweeniou0.5and1.0fora   xednumberofproposals.arhasbeenshowntocorrelateextremelywellwithdetectorperformance(recallatasingleiouthresholdisfarlesspredictive)[13].methods:wecomparetothecurrenttop-   vepublicly-availableproposalmethodsincluding:edge-boxes[34],selectivesearch[31],geodesic[16],rigor[14],andmcg[24].thesemethodsachievetopresultsonobjectdetection(whencoupledwithr-id98s[10])andalsoobtainthebestar[13].results:figure4(a-c)comparestheperformanceofourapproach,deepmask,toexistingproposalmethodsonpascal(usingboxes)andcoco(usingbothboxesandsegmentations).shownisthearofeachmethodasafunctionofthenumberofgeneratedproposals.underallscenariosdeep-mask(anditsvariants)achievessubstantiallybetterarforallnumbersofproposalsconsidered.aratselectedproposalcountsandaveragedacrossallcounts(auc)isreportedintables1and2forcocoandpascal,respectively.notably,deepmaskachievesanorderofmagnitudereductioninthenumberofproposalsnecessarytoreachagivenarundermostscenarios.forexample,with100segmentationproposalsdeepmaskachievesanarof.245oncocowhilecompetingmethodsrequirenearly1000segmentationproposalstoachievesimilarar.6# proposals100101102103average recall00.10.20.30.40.50.60.7deepmaskmcgselectivesearchrigorgeodesicedgeboxes(a)boxproposalsonpascal.# proposals100101102103average recall00.10.20.30.40.50.6deepmaskdeepmaskzoommcgselectivesearchrigorgeodesicedgeboxes(b)boxproposalsoncoco.# proposals100101102103average recall00.10.20.30.40.50.6deepmaskdeepmaskzoommcgselectivesearchrigorgeodesic(c)segm.proposalsoncoco.# proposals100101102103average recall00.10.20.30.40.50.6deepmaskdeepmaskzoommcgselectivesearchrigorgeodesic(d)smallobjects(area<322).# proposals100101102103average recall00.10.20.30.40.50.6deepmaskdeepmaskzoommcgselectivesearchrigorgeodesic(e)mediumobjects.# proposals100101102103average recall00.10.20.30.40.50.6deepmaskdeepmaskzoommcgselectivesearchrigorgeodesic(f)largeobjects(area>962).iou0.50.60.70.80.91recall00.10.20.30.40.50.60.7deepmaskdeepmaskzoommcgselectivesearchrigorgeodesic(g)recallwith10proposals.iou0.50.60.70.80.91recall00.10.20.30.40.50.60.7deepmaskdeepmaskzoommcgselectivesearchrigorgeodesic(h)recallwith100proposals.iou0.50.60.70.80.91recall00.10.20.30.40.50.60.7deepmaskdeepmaskzoommcgselectivesearchrigorgeodesic(i)recallwith1000proposals.figure4:(a-c)averagerecallversusnumberofboxandsegmentationproposalsonvariousdatasets.(d-f)arversusnumberofproposalsfordifferentobjectscalesonsegmentationproposalsincoco.(g-h)recallversusiouthresholdfordifferentnumberofsegmentationproposalsincoco.boxproposalssegmentationproposalsar@10ar@100ar@1000aucar@10ar@100ar@1000aucsaucmauclaucedgeboxes[34].074.178.338.139-------geodesic[16].040.180.359.126.023.123.253.013.086.205.085rigor[14]-.133.337.101-.094.253.022.060.178.074selectivesearch[31].052.163.357.126.025.095.230.006.055.214.074mcg[24].101.246.398.180.077.186.299.031.129.324.137deepmask20.139.286.431.217.109.215.314.020.227.317.164deepmask20   .152.306.432.228.123.233.314.020.257.321.175deepmaskzoom.150.326.482.242.127.261.366.068.263.308.194deepmaskfull.149.310.442.231.118.235.323.020.244.342.176deepmask.153.313.446.233.126.245.331.023.266.336.183table1:resultsonthemscocodatasetforbothboundingboxandsegmentationproposals.wereportaratdifferentnumberofproposals(10,100and1000)andalsoauc(araveragedacrossallproposalcounts).forsegmentationproposalswereportoverallaucandalsoaucatdifferentscales(small/medium/largeobjectsindicatedbysuperscriptss/m/l).seetextfordetails.scale:thecocodatasetcontainsobjectsinawiderangeofscales.inordertoanalyzeperformanceinmoredetail,wedividedtheobjectsinthevalidationsetintoroughlyequallysizedsetsaccordingtoobjectpixelareaa:small(a<322),medium(322   a   962),andlarge(a>962)objects.figure4(d-f)showsperformanceateachscale;allmodelsperformpoorlyonsmallobjects.toimproveaccuracyofdeepmaskweapplyitatanadditionalsmallerscale(deepmaskzoom).thisboostsperformance(especiallyforsmallobjects)butatacostofincreasedid136time.7pascalvoc07ar@10ar@100ar@1000aucedgeboxes[34].203.407.601.309geodesic[16].121.364.596.230rigor[14].164.321.589.239selectivesearch[31].085.347.618.241mcg[24].232.462.634.344deepmask.337.561.690.433table2:resultsonpascalvoc2007test.figure5:fastr-id98resultsonpascal.localization:figure4(g-i)showstherecalleachmodelachievesastheiouvaries,shownfordifferentnumberofproposalsperimage.deepmaskachievesahigherrecallinvirtuallyeveryscenario,exceptatveryhighiou,inwhichitfallsslightlybelowothermodels.thisislikelyduetothefactthatourmethodoutputsadownsampledversionofthemaskateachlocationandscale;amultiscaleapproachorskipconnectionscouldimprovelocalizationatveryhighiou.generalization:toseeifourapproachcangeneralizetounseenclasses[2,19],wetraintwoad-ditionalversionsofourmodel,deepmask20anddeepmask20   .deepmask20istrainedonlywithobjectsbelongingtooneofthe20pascalcategories(subsetofthefull80cococategories).deepmask20   issimilar,exceptweusethescoringnetworkfromtheoriginaldeepmask.resultsforthetwomodelswhenevaluatedonall80cococategories(asinallotherexperiments)areshownintable1.comparedtodeepmask,deepmask20exhibitsadropinar(butstilloutper-formsallpreviousmethods).deepmask20   ,however,matchestheperformanceofdeepmask.thissurprisingresultdemonstratesthatthedropinaccuracyisduetothediscriminativelytrainedscoringbranch(deepmask20isinadvertentlytrainedtoassignlowscorestotheother60categories);thesegmentationbranchgeneralizesextremelywellevenwhentrainedonareducedsetofcategories.architecture:inthesegmentationbranch,theconvolutionalfeaturesarefullyconnectedtoa512   low-rank   layerwhichisinturnconnectedtothe56  56output(withnointermediatenon-linearity),see  3.wealsoexperimentedwitha   full-rank   architecture(deepmaskfull)withover300mpa-rameterswhereeachofthe56  56outputswasdirectlyconnectedtotheconvolutionalfeatures.ascanbeseenintable1,deepmaskfullisslightlyinferiortoour   nalmodel(andmuchslower).detection:asa   nalvalidation,weevaluatehowdeepmaskperformswhencoupledwithanobjectdetectoronpascalvoc2007test.were-trainandevaluatethestate-of-the-artfastr-id98[9]usingproposalsgeneratedbyselectivesearch[31]andourmethod.figure5showsthemeanaverageprecision(map)forfastr-id98withvaryingnumberofproposals.mostnotably,withjust100deepmaskproposalsfastr-id98achievesmapof68.2%andoutperformsthebestresultsobtainedwith2000selectivesearchproposals(mapof66.9%).weemphasizethatwith20  fewerproposalsdeepmaskoutperformsselectivesearch(thisisconsistentwiththearnumbersintable1).with500deepmaskproposals,fastr-id98improvesto69.9%map,afterwhichperformancebeginstodegrade(asimilareffectwasobservedin[9]).speed:id136takesanaverageof1.6sperimageinthecocodataset(1.2sonthesmallerpascalimages).ourruntimeiscompetitivewiththefastestsegmentationproposalmethods(geodesic[16]runsat   1sperpascalimage)andsubstantiallyfasterthanmost(e.g.,mcg[24]takes   30s).id136timecanfurtherbedroppedby   30%byparallelizingallscalesinasinglebatch(eliminatinggpuoverhead).wedo,however,requireuseofagpuforef   cientid136.5conclusioninthispaper,weproposeaninnovativeframeworktogeneratesegmentationobjectproposalsdi-rectlyfromimagepixels.attesttime,themodelisapplieddenselyovertheentireimageatmultiplescalesandgeneratesasetofrankedsegmentationproposals.weshowthatlearningfeaturesforobjectproposalgenerationisnotonlyfeasiblebuteffective.ourapproachsurpassesthepreviousstateoftheartbyalargemargininbothboxandsegmentationproposalgeneration.infuturework,weplanoncouplingourproposalmethodmorecloselywithstate-of-the-artdetectionapproaches.acknowledgements:wewouldliketothankahmadhumayunandtsung-yilinforhelpwithgenerat-ingexperimentalresults,andrewtulloch,omryyadanandalexeyspiridonovforhelpwithcomputationalinfrastructure,androbfergus,yuandongtianandsoumithchintalaforvaluablediscussions.8references[1]b.alexe,t.deselaers,andv.ferrari.measuringtheobjectnessofimagewindows.pami,2012.2[2]n.chavali,h.agrawal,a.mahendru,andd.batra.object-proposalevaluationprotocolis   gameable   .arxiv:1505.05836,2015.8[3]l.chen,g.papandreou,i.kokkinos,k.murphy,anda.l.yuille.semanticimagesegmentationwithdeepconvolutionalnetsandfullyconnectedcrfs.iclr,2015.2[4]n.dalalandb.triggs.histogramsoforientedgradientsforhumandetection.incvpr,2005.1[5]j.deng,w.dong,r.socher,l.li,k.li,andl.fei-fei.id163:alarge-scalehierarchicalimagedatabase.incvpr,2009.1,3[6]d.erhan,c.szegedy,a.toshev,andd.anguelov.scalableobjectdetectionusingdeepneuralnetworks.incvpr,2014.2[7]m.everingham,l.v.gool,c.k.i.williams,j.winn,anda.zisserman.thepascalvisualobjectclasses(voc)challenge.ijcv,2010.1,2,6[8]p.f.felzenszwalb,r.b.girshick,d.mcallester,andd.ramanan.objectdetectionwithdiscrimina-tivelytrainedpart-basedmodels.pami,2010.1[9]r.girshick.fastr-id98.arxiv:1504.08083,2015.2,8[10]r.girshick,j.donahue,t.darrell,andj.malik.richfeaturehierarchiesforaccurateobjectdetectionandsemanticsegmentation.incvpr,2014.1,2,6[11]b.hariharan,p.arbel  aez,r.girshick,andj.malik.hypercolumnsforobjectsegmentationand   ne-grainedlocalization.incvpr,2015.2[12]k.he,x.zhang,s.ren,andj.sun.spatialpyramidpoolingindeepconvolutionalnetworksforvisualrecognition.ineccv,2014.2[13]j.hosang,r.benenson,p.doll  ar,andb.schiele.whatmakesforeffectivedetectionproposals?arxiv:1502.05082,2015.2,6[14]a.humayun,f.li,andj.m.rehg.rigor:reusingid136ingraphcutsforgeneratingobjectregions.incvpr,2014.2,6,7,8[15]h.kaiming,z.xiangyu,r.shaoqing,ands.jian.spatialpyramidpoolingindeepconvolutionalnet-worksforvisualrecognition.ineccv,2014.1[16]p.kr  ahenb  uhlandv.koltun.geodesicobjectproposals.ineccv,2014.2,6,7,8[17]p.kr  ahenb  uhlandv.koltun.learningtoproposeobjects.incvpr,2015.2[18]a.krizhevsky,i.sutskever,andg.hinton.id163classi   cationwithdeepconvolutionalneuralnet-works.innips,2012.2[19]w.kuo,b.hariharan,andj.malik.deepbox:learningobjectnesswithconvolutionalnetworks.inarxiv:505.02146v1,2015.2,8[20]y.lecun,l.bottou,y.bengio,andp.haffner.gradient-basedlearningappliedtodocumentrecognition.proceedingsoftheieee,1998.1[21]t.-y.lin,m.maire,s.belongie,l.bourdev,r.girshick,j.hays,p.perona,d.ramanan,c.l.zitnick,andp.doll  ar.microsoftcoco:commonobjectsincontext.arxiv:1405.0312,2015.1,2,5,6[22]m.oquab,l.bottou,i.laptev,andj.sivic.isobjectlocalizationforfree?   weakly-supervisedlearningwithconvolutionalneuralnetworks.incvpr,2015.2[23]p.o.pinheiroandr.collobert.recurrentconv.neuralnetworksforscenelabeling.inicml,2014.2[24]j.pont-tuset,p.arbel  aez,j.barron,f.marques,andj.malik.multiscalecombinatorialgroupingforimagesegmentationandobjectproposalgeneration.inarxiv:1503.00848,2015.2,6,7,8[25]s.ren,k.he,r.girshick,andj.sun.fasterr-id98:towardsreal-timeobjectdetectionwithregionproposalnetworks.inarxiv:1506.01497,2015.2[26]p.sermanet,d.eigen,x.zhang,m.mathieu,r.fergus,andy.lecun.overfeat:integratedrecognition,localizationanddetectionusingconvolutionalnetworks.iniclr,2014.5[27]k.simonyananda.zisserman.verydeepconvolutionalnetworksforlarge-scaleimagerecognition.iniclr,2015.2,3,5[28]n.srivastava,g.hinton,a.krizhevsky,i.sutskever,andr.salakhutdinov.dropout:asimplewaytopreventneuralnetworksfromover   tting.jmlr,2014.5[29]c.szegedy,w.liu,y.jia,p.sermanet,s.reed,d.anguelov,d.erhan,v.vanhoucke,anda.rabi-novich.goingdeeperwithconvolutions.incvpr,2015.2[30]c.szegedy,s.reed,d.erhan,andd.anguelov.scalable,high-qualityobjectdetection.inarxiv:1412.1441,2014.2[31]j.uijlings,k.vandesande,t.gevers,anda.smeulders.selectivesearchforobjectrecog.ijcv,2013.2,6,7,8[32]p.violaandm.j.jones.robustreal-timefacedetection.ijcv,2004.1[33]z.y.zhu,r.urtasun,r.salakhutdinov,ands.fidler.segdeepm:exploitingsegmentationandcontextindeepneuralnetworksforobjectdetection.incvpr,2015.1[34]c.l.zitnickandp.doll  ar.edgeboxes:locatingobjectproposalsfromedges.ineccv,2014.2,6,7,89figure6:additionaldeepmaskproposalswithhighestioutothegroundtruthonselectedimagesfromcoco.missedobjects(nomatchingproposalswithiou>0.5)aremarkedwitharedoutline.10