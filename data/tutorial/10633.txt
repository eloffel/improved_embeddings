4
1
0
2

 
t
c
o
5
1

 

 
 
]
l
c
.
s
c
[
 
 

1
v
6
7
1
4

.

0
1
4
1
:
v
i
x
r
a

learning distributed word representations for

natural logic reasoning

samuel r. bowman      

christopher potts   

sbowman@stanford.edu

cgpotts@stanford.edu

christopher d. manning         
manning@stanford.edu

   stanford linguistics

   stanford nlp group

   stanford computer science

abstract

natural logic offers a powerful relational conception of meaning that is a natural
counterpart to distributed semantic representations, which have proven valuable in
a wide range of sophisticated language tasks. however, it remains an open ques-
tion whether it is possible to train distributed representations to support the rich,
diverse logical reasoning captured by natural logic. we address this question using
two neural network-based models for learning embeddings: plain neural networks
and neural tensor networks. our experiments evaluate the models    ability to learn
the basic algebra of natural logic relations from simulated data and from the word-
net noun graph. the overall positive results are promising for the future of learned
distributed representations in the applied modeling of logical semantics.

1

introduction

natural logic offers a powerful relational conception of semantics: the meanings for expressions are
given, at least in part, by their inferential connections with other expressions [1, 2]. for instance,
turtle is analyzed, not primarily by its extension in the world, but rather by its lexical network: it
entails reptile, excludes chair, is entailed by sea turtle, and so forth. with generalized notions of
entailment and contradiction, these relationships can be de   ned for all lexical categories as well as
complex phrases, sentences, and even texts. the resulting theories of meaning offer valuable new
analytic tools for tasks involving database id136, id36, and id123.

natural logic aligns well with distributed (e.g., vector) representations, which also naturally model
meaning relationally. distributed representations have been used successfully in a wide array of
sophisticated language tasks (e.g., [3]). however, it remains an open question whether it is possible
to train such representations to support the rich, diverse logical reasoning captured by natural logic;
while they excel at synonymy (similarity), the results are more mixed for entailment, contradiction,
and mutual consistency. using the natural logic of [2] as our formal model, we address this open
question using two neural network-based models for learning embeddings: plain neural networks
and neural tensor networks (ntns). the natural logic is built from the seven relations de   ned in
table 1. its formal properties are now well-understood [4], so it provides a rigorous set of goals for
our neural models. to keep the discussion manageable, we limit attention to experiments involving
the lexicon; for a more extended treatment of complex expressions involving logical connectives
and quanti   ers, see bowman et al. [5].

in our experiments, we evaluate these models    ability to learn the basic algebra of natural logic
relations from simulated data and from the id138 noun graph. the simulated data help us to
achieve analytic insights into what the models learn, and the id138 data show how they fare with
a real natural language vocabulary. we    nd that only the ntn is able to fully learn the underlying
algebra, but that both models excel in the id138 experiment.

1

name

symbol

set-theoretic de   nition

example

entailment
reverse entailment
equivalence
alternation
negation
cover
independence

x     y
x     y
x     y
x | y
x     y
x ` y
x # y

x     y
x     y
x = y
x     y =         x     y 6= d
x     y =         x     y = d
x     y 6=         x     y = d
(else)

turtle, reptile
reptile, turtle
couch, sofa
turtle, warthog
able, unable
animal, non-turtle
turtle, pet

table 1: the seven natural logic relations of [2]. d is the universe of possible objects of the same
type as those being compared, and the relation # applies whenever none of the other six do.

softmax classi   er

p (   ) = 0.8

comparison
n(t)n layer

turtle vs. animal

turtle

turtle

optional embedding

transformation nn layers

learned word vectors

animal

animal

figure 1: the model structure used to compare turtle and animal.

2 neural network models for relation classi   cation

we build embedding-based models using the method of [5], which is centered on the task of labeling
a pair of words or sentences with one of a small set of logical relations. the architecture that we use,
which is limited to only pairs of single terms (such as words), is depicted in figure 1. the model
represents the two input terms as embeddings, which are fed into a comparison function based on
one of two types of neural network layer functions to produce a representation for the relationship
between the two terms. this representation is then fed into a softmax classi   er, which outputs a
distribution over possible labels. the entire network, including the embeddings, is trained using
id26.

the simpler version of the comparison concatenates the two input vectors before feeding them into a
standard neural network (nn) layer. the more powerful neural tensor network (ntn) version uses
an additional third-order tensor parameter to allow for multiplicative interactions between the two
inputs [6]. for more details on the implementation and training of the layer functions, see [5].

this model used here differs from the one described in that work in two ways. first, because the
inputs are single terms, we do not use a composition function here. second, for our experiment on
id138 data, we introduce an additional neural network layer between the embedding input and
the comparison function, which facilitates initializing the embeddings themselves from pretrained
vectors and was found to help performance in that setting.

3 reasoning about semantic relations

in this experiment, we test our model   s ability to learn and use the natural logic id136 rules
schematized in figure 2a. for instance, given that a     b and b     c, one can conclude that a     c, by
basic set-theoretic reasoning (transitivity of    ). similarly, from a     b and b     c, it follows that a | c.
cells in the table containing a dot correspond to pairs of relations for which no valid id136 can
be drawn in our logic.

experiments to test our models    ability to learn these inferential patterns, we create arti   cial
boolean structures in which terms denote sets of entities from a small domain (e.g., figure 2b),
employ logical deduction to identify the valid statements, divide those into train and test sets, and
remove from the test set those statements which cannot be proven from the training statements
(figure 2c). in our experiments, we create 80 randomly generated sets drawn from a domain of

2

   
       
       

       

   

   

|
|
` `
# #

   

   

   
  
`
  
`
  

   

   
  
   
|
|
  
  

   

   

|
`
   
   

   
#

|
|
|
  
   
  
   
  

` #
` #
  
  
  
`
    #
  
   
  
  
  
  

(a) id136 path from premises a r b (row)
and b s c (column) to the relation that holds
between a and c, if any. these id136s
are based on basic set-theoretic truths about
the meanings of the underlying relations as de-
scribed in table 1. we assess our models    abil-
ity to reproduce such inferential paths.

{1, 2, 3}

a, b

{1, 2}

c

{1, 3}

d

{2, 3}

g, h
{3}

e, f
{1}

{2}

{}

(b) simple boolean structure.
the letters name the sets. not
all sets have names, and some
sets have multiple names, so that
learning     is non-trivial.

train

b ` c

c ` d
c     e

c     g

e     c...

test

b     b

b ` d
b     e

c     f

e     b

...

(c) a train/test split of
the atomic statements
about the model. test
statements not prov-
able from the training
data are crossed out.

figure 2: experimental goal and set-up for reasoning about semantic relations.

seven elements. this yields 6400 statements about pairs of formulae, of which 3200 are chosen as a
test set, and that test set is further reduced to the 2960 examples that can be provably derived from
the training data. we trained both the nn model and the ntn model on these data sets.

results we found that the ntn model worked best with 11-dimensional vector representations
for the 80 sets and a 90-dimensional feature vector for the classi   er, though the performance of the
model was not highly dependant on either dimensionality setting. averaging over    ve randomly
generated data sets, the model was able to correctly label 98.1% (standard error 0.67%) of the
provably derivable test examples, and 87.7% (se = 3.59%) of the remaining test examples. the
simpler nn worked best with 11 and 75 dimensions, respectively, but was able to achieve accuracies
of only 84.8% (se = 0.84%) and 68.7% (se = 1.58%), respectively. training accuracy was 99.8%
(se = 0.04%) for the ntn and 94.7% (se = 0.89%) for the nn.

these results are fairly straightforward to interpret. the ntn model was able to accurately encode
the relations between the terms in the geometric relations between their vectors, and was able to
then use that information to recover relations that were not overtly included in the training data. in
contrast, the nn was able to achieve this behavior only incompletely. it is possible but not likely that
it could be made to    nd a good solution with further optimization on different learning algorithms,
or that it would do better on a larger universe of sets, for which there would be a larger set of training
data to learn from, but the ntn is readily able to achieve these effects in the setting discussed here.

4 reasoning about lexical relations in id138

using simulated data as above is reassuring about what the models learn and why, but we also want
to know how they perform with a real natural language vocabulary. unfortunately, as far as we are
aware, there are no available resources labeling such a vocabulary with the relations from table 1.
however, the relations in id138 [7] come close and pose the same substantive challenges within
a somewhat easier classi   cation problem.

we extract three types of relation from id138. hypernym and hyponym can be represented di-
rectly in the id138 graph structure, and correspond closely to the     and     relations from natural
logic. as in natural logic, these relations are mirror images of one another: if dog is a hyponym of
animal (perhaps indirectly by way of canid, mammal, etc.), then animal is a hypernym of dog. we
also extract coordinate terms, which share a direct hypernym, like dalmatian, pug, and puppy, which
are all direct hyponyms of dog. coordinate terms tend to exclude one another, thereby providing
a loose approximation of the natural logic exclusion relation |. id138 de   nes hypernymy and
hyponymy over sets of synonyms, rather than over individual terms, so we do not include a synonym
or equivalent relation, but rather consider only one member of each set of synonyms. word pairs
which do not fall into these three relations are not included in the data set.

3

to limit the size of the vocabulary without otherwise simplifying the learning problem, we extract all
of the instances of these three relations for single word nouns in id138 that are hyponyms of the
node organism.n.01. in order to balance the distribution of the classes, we slightly downsam-
ple instances of the coordinate relation, yielding a total of 36,772 relations among 3,217 terms. we
report results below using crossvalidation, choosing a disjoint 10% test sample for each of    ve runs.
unlike in the previous experiment, it is not straightforward here to determine in advance how much
data should be required to train an accurate model, so we performed training runs with various frac-
tions of the remaining data. embeddings were    xed at 25 dimensions and were initialized randomly
or using distributional vectors from glove [8]. the feature vector produced by the comparison layer
was    xed at 80 dimensions.

results we    nd that the ntn performs perfectly with random initialization, and that the plain nn
performs almost as well, a point of contrast with the results of section 3. we also    nd that initializa-
tion with glove is helpful in allowing the models to maintain fair performance with smaller amounts
of training data. some of the randomly initialized model runs failed to learn usable representations
at all and labeled all examples with the most frequent labels. we excluded these runs from the statis-
tics, but marked settings for which this occurred with the symbol    . for all of the remaining runs,
training accuracy was consistently above 99%.

portion of
training data

100%
33%
11%

nn

w/ glove

99.73 (0.04)
95.96 (0.20)
91.11 (0.24)

w/o glove

99.37    (0.14)
95.30 (0.12)
90.81    (0.20)

ntn

w/ glove

99.61 (0.02)
95.83 (0.35)
91.27 (0.27)

w/o glove
99.95 (0.03)
95.45    (0.31)
90.90    (0.13)

baseline

37.05 (   )
37.05 (   )
37.05 (   )

table 2: mean test % accuracy scores (with standard error) on the id138 data over    ve-fold
crossvalidation. the baseline    gure is the frequency of the most frequent class, hypernym.

5 conclusion

this paper evaluated two neural models on the task of learning natural logic relations between
distributed word representations. the results suggest that at least the neural tensor network has
the capacity to meet this challenge with reasonably-sized training sets, learning both to embed a
vocabulary in a way that encodes a diverse set of relations, and to subsequently use those embeddings
to infer new relations. in [5], we extend these results to include complex expressions involving
logical connectives and quanti   ers, with similar conclusions about (recursive versions of) these
models. these    ndings are promising for the future of learned distributed representations in the
applied modeling of logical semantics.

references

[1] j. van benthem. a brief history of natural logic. in m. chakraborty, b. l  owe, m. nath mitra,
and s. sarukki, editors, logic, navya-nyaya and applications: homage to bimal matilal, 2008.
[2] b. maccartney and c.d. manning. an extended model of natural logic. in proc. iwcs, 2009.
[3] r. collobert, j. weston, l. bottou, m. karlen, k. kavukcuoglu, and p. kuksa. natural language

processing (almost) from scratch. jlmr, 12, 2011.

[4] t.f. icard and l.s. moss. recent progress on monotonicity. linguistic issues in language

technology, 9(7), 2013.

[5] s.r. bowman, c. potts, and c.d. manning. id56s for learning logical

semantics. arxiv manuscript 1406.1827, 2014.

[6] d. chen, r. socher, c.d. manning, and a.y. ng. learning new facts from knowledge bases

with neural tensor networks and semantic word vectors. in proc. iclr, 2013.

[7] c. fellbaum. id138.

springer, 2010.

in theory and applications of ontology: computer applications.

[8] j. pennington, r. socher, and c.d. manning. glove: global vectors for word representation.

in proc. emnlp, 2014.

4

