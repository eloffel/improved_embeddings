semantic representations of word senses and concepts

jos  e camacho-collados, ignacio iacobacci, roberto navigli and mohammad taher pilehvar   

department of computer science, sapienza university of rome
{collados,iacobacci,navigli}@di.uniroma1.it
   language technology lab, dtal, university of cambridge

mp792@cam.ac.uk

1 introduction

2 outline

6
1
0
2

 

g
u
a
2

 

 
 
]
l
c
.
s
c
[
 
 

1
v
1
4
8
0
0

.

8
0
6
1
:
v
i
x
r
a

representing the semantics of linguistic items in a
machine-interpretable form has been a major goal
of natural language processing since its earli-
est days. among the range of different linguis-
tic items, words have attracted the most research
attention. however, word representations have an
important limitation: they con   ate different mean-
ings of a word into a single vector. representa-
tions of word senses have the potential to over-
come this inherent limitation. indeed, the repre-
sentation of individual word senses and concepts
has recently gained in popularity with several ex-
perimental results showing that a considerable per-
formance improvement can be achieved across dif-
ferent nlp applications upon moving from word
level to the deeper sense and concept levels. an-
other interesting point regarding the representation
of concepts and word senses is that these models
can be seaid113ssly applied to other linguistic items,
such as words, phrases and sentences.

this tutorial1 will    rst provide a brief overview
of the recent literature concerning word represen-
tation (both count and neural network based). it
will then describe the advantages of moving from
the word level to the deeper level of word senses
and concepts, providing an extensive review of
state-of-the-art systems. approaches covered will
not only include those which draw upon knowl-
edge resources such as id138, wikipedia, ba-
belnet or freebase as reference, but also the
so-called multi-prototype approaches which learn
sense distinctions by using different id91
techniques. our tutorial will discuss the advan-
tages and potential limitations of all approaches,
showing their most successful applications to date.
we will conclude by presenting current open prob-
lems and lines of future work.

1slides available at http://goo.gl/az7tbd

session provides

2.1 semantic representation: foundations
this
the necessary back-
ground for semantic representation. we will
brie   y cover the traditional vector space model
(turney and pantel, 2010) followed by the more
recent approaches based on neural networks
(mikolov et al., 2013a). we then provide reasons
for the need to produce semantic representations
for the deeper word sense level, focusing on the
main limitation of the word-based approaches
which is their inherent ambiguity. finally, we
show how sense-based representations are bound
to overcome these limitations, hence providing
improvements across several tasks.

2.2 knowledge-based sense representations
we start this session by brie   y introducing some
of the most popular lexical knowledge resources
that have been used by different sense represen-
tation techniques. we put emphasis on id138
(miller et al., 1990), the de facto standard sense
inventory in the community, and wikipedia, the
largest collaboratively-constructed resource of the
type, both of which have been extensively used
by many researchers in the area. we discuss the
advantages each of these resources provides and
show how they are usually viewed as semantic net-
works and exploited for representation purposes.
then, we provide a deep review of different
techniques that learn representations for individ-
ual concepts in a target sense inventory. we cover
all the existing approaches that model concepts
in id138 (pilehvar and navigli, 2015), articles
(hassan and mihalcea, 2011),
in wikipedia
or
inventories
(iacobacci et al., 2015;
such
camacho-collados et al., 2016b)
freebase
(bordes et al., 2011; bordes et al., 2013). we

babelnet

concepts

larger

sense

as

or

in

(chen et al., 2014;

will also cover some approaches that make
use of additional external corpora (or word
representations learned on the basis of statis-
tical clues) besides the target knowledge re-
source
chen et al., 2015;
johansson and pi  na nieto, 2015;
rothe and sch  utze, 2015;
jauhar et al., 2015;
pilehvar and collier, 2016).
the
advantages of these knowledge-based represen-
tations and focus on how neural network-based
learning has played a role in this area in the past
few years.

we discuss

2.3 unsupervised sense representations
in this session we cover the so-called multi-
prototype techniques that learn multiple repre-
sentations per word, each corresponding to a
speci   c meaning of the word. we will illus-
trate how these approaches leverage id91
algorithms for dividing the contexts of a word
into multiple contexts for its different meanings
(reisinger and mooney, 2010; huang et al., 2012;
neelakantan et al., 2014;
tian et al., 2014;
li and jurafsky, 2015;
wu and giles, 2015;
liu et al., 2015;
vu and parker, 2016;
  suster et al., 2016).

2.4 advantages and limitations
this session reviews some of the advantages and
limitations of the knowledge-based and unsuper-
vised techniques, describing the applications for
which they are suitable and mentioning some is-
sues such as the knowledge acquisition bottleneck.

2.5 applications
this session focuses on different applications
of sense representations. we brie   y mention
some of the main applications and tasks to which
sense representations can be applied.
sense
representations may be used in virtually every
task in which word representations have been tra-
ditionally applied. examples of such tasks include
automatic thesaurus generation (crouch, 1988;
ex-
curran and moens, 2002),
traction (laender et al., 2002),
role
labelling (erk, 2007; pennacchiotti et al., 2008),
and word similarity (deerwester et al., 1990;
radinsky et al., 2011;
turney et al., 2003;
mikolov et al., 2013b)
and
id91
(pantel and lin, 2002). we will provide compar-
isons between word and sense representations
performance,
discussing the advantages and

information
semantic

(navigli, 2009;

limitations of each approach. moreover, we
will show how sense representations can also
be applied to a wide variety of additional tasks
such as entity linking and word sense disam-
biguation
chen et al., 2014;
camacho-collados et al., 2015b;
rothe and sch  utze, 2015;
camacho-collados et al., 2016a),
(snow et al., 2007;
sense
camacho-collados et al., 2015a),
alignment of
lexical resources (niemann and gurevych, 2011;
pilehvar and navigli, 2014),
taxonomy learning
(espinosa-anke et al., 2016),
knowledge-base
completion (bordes et al., 2013), information ex-
traction (delli bovi et al., 2015), or sense-based
semantic similarity (budanitsky and hirst, 2006;
pilehvar et al., 2013;
to
name a few.

iacobacci et al., 2015),

id91

2.6 open problems and future work
this last session provides a summary of possible
directions of future work on semantic sense rep-
resentation. we discuss various problems asso-
ciated with the current representation approaches
and propose lines of research in order to effec-
tively apply sense representations in natural lan-
guage understanding tasks.

3 instructors

semantic vector

jos  e camacho collados
is a google doctoral
fellow and phd student at the sapienza univer-
sity of rome2, working under the supervision of
prof. roberto navigli. his research focuses on
natural language processing and on the area of
lexical semantics in particular. he has devel-
oped nasari3 (camacho-collados et al., 2016b),
representation for
a novel
concepts based on wikipedia
features
a high coverage of named entities and has
been successfully used on different nlp tasks.
jos  e has also worked on the development
of evaluation benchmarks for word and sense
representations (camacho-collados et al., 2015c;
camacho-collados and navigli, 2016) and is the
co-organizer of a semeval 2017 task on mul-
tilingual and cross-lingual semantic similarity.
his background education includes an erasmus
mundus master in natural language processing
and human language technology and a 5-year

that

2http://wwwusers.di.uniroma1.it/  collados/
3http://lcl.uniroma1.it/nasari/

bsc degree in mathematics.

language understanding.

is a phd student at

ignacio iacobacci
the
sapienza university of rome4, working under
the supervision of prof. roberto navigli. his
research interests lie in the    elds of machine
learning, natural language processing, neural
networks. he is currently working on word
sense disambiguation and distributional seman-
tics. ignacio presented sensembed5 at acl 2015
(iacobacci et al., 2015), a novel approach for word
and relational similarity built from exploiting se-
mantic knowledge for modeling arbitrary word
senses in a large sense inventory. his background
includes a msc. in computer science and 8 years
as a developer including 4 years as a machine
learning - nlp specialist.

in 2007 he received a ph.d.

roberto navigli
is an associate professor in the
department of computer science at la sapienza
university of rome and a member of the lin-
guistic computing laboratory6. his research
interests lie in the    eld of natural language
processing, including: word sense disambigua-
tion and induction, ontology learning, knowl-
edge representation and acquisition, and mul-
tilinguality.
in
computer science from la sapienza and he was
awarded the marco cadoli 2007 ai*ia national
prize for the best ph.d. thesis in arti   cial in-
telligence.
in 2013 he received the marco so-
malvico ai*ia prize, awarded every two years
to the best young italian researcher in arti   -
cial intelligence. he is the creator and founder
of babelnet7 (navigli and ponzetto, 2012), both
a multilingual encyclopedic dictionary and a se-
mantic network, and its related project babelfy8
(moro et al., 2014), a state-of-the-art multilingual
disambiguation and entity linking system. he is
also the principal investigator of multijedi9, a
1.3m euro 5-year starting grant funded by the
european research council and the responsible
person of the sapienza unit in lider, an eu
project on content analytics and language tech-
nologies. moreover, he is the co-pi of    language
understanding cum knowledge yield    (lucky),
a google focused research award on natural

4https://iiacobac.wordpress.com/
5http://lcl.uniroma1.it/sensembed/
6http://wwwusers.di.uniroma1.it/  navigli/
7http://www.babelnet.org
8http://www.babelfy.org
9http://multijedi.org/

the supervision of prof.

mohammad taher pilehvar
is a research as-
sociate in the language technology lab of the
university of cambridge10 where he is cur-
rently working on nlp in the biomedical do-
main. taher completed his phd in 2015 un-
der
roberto nav-
igli. taher   s research lies in lexical semantics,
mainly focusing on semantic representation, se-
mantic similarity, and word sense disambigua-
tion. he has co-organized three semeval tasks
(jurgens et al., 2014; jurgens and pilehvar, 2016)
and has authored multiple conference and jour-
nal papers on semantic representation and simi-
larity in top tier venues. he is the    rst author
of a paper on semantic similarity that was nom-
inated for the best paper award at acl 2013
(pilehvar and navigli, 2013).

acknowledgments

the authors gratefully acknowledge the support of
the erc starting grant multijedi no. 259234.

references
[bordes et al.2011] antoine bordes, jason weston, ro-
nan collobert, and yoshua bengio. 2011. learn-
ing structured embeddings of knowledge bases. in
twenty-fifth aaai conference on arti   cial intelli-
gence.

[bordes et al.2013] antoine bordes, nicolas usunier,
alberto garcia-duran, jason weston, and oksana
yakhnenko.
2013. translating embeddings for
modeling multi-relational data. in advances in neu-
ral information processing systems, pages 2787   
2795.

[budanitsky and hirst2006] alexander budanitsky and
graeme hirst. 2006. evaluating id138-based
measures of lexical semantic relatedness. com-
putational linguistics, 32(1):13   47.

[camacho-collados and navigli2016] jos  e camacho-
collados and roberto navigli. 2016. find the word
that does not belong: a framework for an intrinsic
evaluation of word vector representations. in pro-
ceedings of the acl workshop on evaluating vector
space representations for nlp, berlin, germany.

[camacho-collados et al.2015a] jos  e

camacho-
collados, mohammad taher pilehvar, and roberto
navigli. 2015a. nasari: a novel approach to
a semantically-aware representation of items. in
proceedings of naacl, pages 567   577.

10http://www.pilevar.com/taher/

[camacho-collados et al.2015b] jos  e

camacho-
collados, mohammad taher pilehvar, and roberto
navigli. 2015b. a uni   ed multilingual semantic
representation of concepts.
in proceedings of
acl, pages 741   751, beijing, china.

[camacho-collados et al.2015c] jos  e

camacho-
collados, mohammad taher pilehvar, and roberto
navigli. 2015c. a framework for the construction
of monolingual and cross-lingual word similarity
datasets. in proceedings of the 53rd annual meet-
ing of the association for computational linguistics
    short papers, pages 1   7, beijing, china.

[camacho-collados et al.2016a] jos  e

camacho-
collados, claudio delli bovi, alessandro raganato,
and roberto navigli. 2016a. a large-scale multi-
lingual disambiguation of glosses.
in proceedings
of the 10th international conference on language
resources and evaluation (lrec 2016), pages
1701   1708, portoroz, slovenia, may. european
language resources association (elra).

[camacho-collados et al.2016b] jos  e

camacho-
collados, mohammad taher pilehvar, and roberto
navigli.
2016b. nasari: integrating explicit
knowledge and corpus statistics for a multilingual
representation of concepts and entities. arti   cial
intelligence.

[chen et al.2014] xinxiong chen, zhiyuan liu, and
a uni   ed model for
maosong sun.
word sense representation and disambiguation.
in
proceedings of emnlp, pages 1025   1035, doha,
qatar.

2014.

2015.

[chen et al.2015] tao chen, ruifeng xu, yulan he, and
xuan wang.
improving distributed rep-
resentation of word sense via id138 gloss com-
position and context id91.
in proceedings
of the 53rd annual meeting of the association for
computational linguistics and the 7th international
joint conference on natural language processing    
short papers, pages 15   20, beijing, china.

[crouch1988] c. j. crouch. 1988. a cluster-based ap-
proach to thesaurus construction. in proceedings of
the 11th annual international acm sigir confer-
ence on research and development in information
retrieval, sigir    88, pages 309   320.

[curran and moens2002] james r. curran and marc
moens. 2002. improvements in automatic thesaurus
extraction.
in proceedings of the acl-02 work-
shop on unsupervised lexical acquisition - volume
9, ula    02, pages 59   66.

[deerwester et al.1990] scott c. deerwester, susan t.
dumais, thomas k. landauer, george w. furnas,
and richard a. harshman. 1990. indexing by latent
semantic analysis. journal of american society for
information science, 41(6):391   407.

[delli bovi et al.2015] claudio delli bovi, luis es-
pinosa anke, and roberto navigli. 2015. knowl-

edge base uni   cation via sense embeddings and dis-
ambiguation.
in proceedings of the 2015 con-
ference on empirical methods in natural lan-
guage processing, pages 726   736, lisbon, portugal,
september. association for computational linguis-
tics.

[erk2007] katrin erk.

2007. a simple, similarity-
based model for selectional preferences.
in pro-
ceedings of the 45th annual meeting of the associa-
tion for computational linguistics, prague, czech
republic.

[espinosa-anke et al.2016] luis espinosa-anke, hora-
cio saggion, francesco ronzano, and roberto nav-
igli. 2016. extasem! extending, taxonomizing
and semantifying domain terminologies. in pro-
ceedings of the 30th conference on arti   cial intelli-
gence (aaai   16).

[hassan and mihalcea2011] samer hassan and rada
mihalcea. 2011. semantic relatedness using salient
semantic analysis.
in proceedings of aaai, pages
884,889.

[huang et al.2012] eric h. huang, richard socher,
christopher d. manning, and andrew y. ng. 2012.
improving word representations via global context
and multiple word prototypes.
in proceedings of
acl, pages 873   882, jeju island, korea.

[iacobacci et al.2015] ignacio

iacobacci, moham-
mad taher pilehvar, and roberto navigli. 2015.
sensembed: learning sense embeddings for word
and relational similarity.
in proceedings of acl,
pages 95   105, beijing, china.

[jauhar et al.2015] sujay kumar jauhar, chris dyer,
and eduard hovy. 2015. ontologically grounded
multi-sense representation learning for semantic
vector space models. in proceedings of naacl.

[johansson and pi  na nieto2015] richard

johansson
and luis pi  na nieto. 2015. embedding a semantic
network in a word space. in proceedings of naacl,
pages 1428   1433.

[jurgens and pilehvar2016] david jurgens and moham-
mad taher pilehvar. 2016. semeval-2016 task 14:
semantic taxonomy enrichment. in proceedings of
the 10th international workshop on semantic eval-
uation, pages 1092   1102, san diego, california,
june.

[jurgens et al.2014] david jurgens, mohammad taher
pilehvar, and roberto navigli. 2014. semeval-2014
task 3: cross-level semantic similarity. semeval
2014, page 17.

[laender et al.2002] alberto h. f. laender, berthier a.
ribeiro-neto, altigran s. da silva, and juliana s.
teixeira. 2002. a brief survey of web data extrac-
tion tools. sigmod rec., 31(2):84   93.

[li and jurafsky2015] jiwei li and dan jurafsky.
2015. do multi-sense embeddings improve natu-
ral language understanding? in proceedings of the
2015 conference on empirical methods in natu-
ral language processing, pages 1722   1732, lisbon,
portugal, september.

[liu et al.2015] yang liu, zhiyuan liu, tat-seng chua,
and maosong sun. 2015. topical word embed-
dings. in aaai, pages 2418   2424.

[pilehvar and collier2016] mohammad taher pilehvar
and nigel collier. 2016. de-con   ated semantic rep-
resentations. in proceedings of the conference on
empirical methods in natural language process-
ing, austin, tx, usa.

[pilehvar and navigli2013] mohammad taher pilehvar
and roberto navigli. 2013. paving the way to a
large-scale pseudosense-annotated dataset. in pro-
ceedings of naacl-hlt, atlanta, usa.

[mikolov et al.2013a] tomas mikolov, kai chen, greg
corrado, and jeffrey dean. 2013a. ef   cient estima-
tion of word representations in vector space. corr,
abs/1301.3781.

[pilehvar and navigli2014] mohammad taher pilehvar
and roberto navigli. 2014. a robust approach to
aligning heterogeneous lexical resources.
in pro-
ceedings of acl, pages 468   478.

[mikolov et al.2013b] tomas mikolov, ilya sutskever,
kai chen, greg s corrado, and jeff dean. 2013b.
distributed representations of words and phrases
and their compositionality.
in advances in neural
information processing systems, pages 3111   3119.

[pilehvar and navigli2015] mohammad taher pilehvar
and roberto navigli. 2015. from senses to texts:
an all-in-one graph-based approach for measuring
semantic similarity. arti   cial intelligence, 228:95   
128.

[miller et al.1990] george a. miller, r.t. beckwith,
christiane d. fellbaum, d. gross, and k. miller.
1990. id138: an online lexical database. inter-
national journal of id69, 3(4):235   244.

[moro et al.2014] andrea moro, alessandro raganato,
and roberto navigli. 2014. entity linking meets
id51: a uni   ed approach.
transactions of the association for computational
linguistics (tacl), 2:231   244.

[navigli and ponzetto2012] roberto navigli and si-
mone paolo ponzetto. 2012. babelnet: the auto-
matic construction, evaluation and application of a
wide-coverage multilingual semantic network. arti-
   cial intelligence, 193:217   250.

[navigli2009] roberto navigli.

2009. word sense
disambiguation: a survey. acm computing sur-
veys, 41(2):1   69.

[neelakantan et al.2014] arvind neelakantan, jeevan
shankar, alexandre passos, and andrew mccal-
lum. 2014. ef   cient non-parametric estimation of
multiple embeddings per word in vector space. in
proceedings of emnlp, pages 1059   1069, doha,
qatar.

[niemann and gurevych2011] elisabeth niemann and
iryna gurevych. 2011. the people   s web meets
linguistic knowledge: automatic sense alignment of
wikipedia and id138. in proceedings of the ninth
international conference on computational seman-
tics, pages 205   214.

[pantel and lin2002] patrick pantel and dekang lin.
2002. discovering word senses from text. in pro-
ceedings of kdd, pages 613   619.

[pennacchiotti et al.2008] marco pennacchiotti, diego
de cao, roberto basili, danilo croce, and michael
roth. 2008. automatic induction of framenet lexi-
cal units. in proceedings of the conference on em-
pirical methods in natural language processing,
emnlp    08, pages 457   465.

[pilehvar et al.2013] mohammad taher pilehvar, david
jurgens, and roberto navigli. 2013. align, dis-
ambiguate and walk: a uni   ed approach for mea-
suring semantic similarity.
in proceedings of the
51st annual meeting of the association for compu-
tational linguistics, pages 1341   1351, so   a, bul-
garia.

[radinsky et al.2011] kira

eugene
radinsky,
agichtein, evgeniy gabrilovich,
and shaul
markovitch. 2011. a word at a time: computing
word relatedness using temporal semantic anal-
ysis.
in proceedings of www, pages 337   346,
hyderabad, india.

[reisinger and mooney2010] joseph reisinger

and
raymond j. mooney. 2010. multi-prototype vector-
space models of word meaning. in proceedings of
acl, pages 109   117.

[rothe and sch  utze2015] sascha rothe and hinrich
sch  utze. 2015. autoextend: extending word em-
beddings to embeddings for synsets and lexemes.
in proceedings of acl, pages 1793   1803, beijing,
china, july. association for computational linguis-
tics.

[snow et al.2007] rion snow, sushant prakash, daniel
jurafsky, and andrew y. ng. 2007. learning to
merge word senses.
in proceedings of the 2007
joint conference on empirical methods in natural
language processing and computational natural
language learning (emnlp-conll), pages 1005   
1014, prague, czech republic.

[   suster et al.2016] simon   suster, ivan titov, and gert-
jan van noord. 2016. bilingual learning of multi-
sense embeddings with discrete autoencoders.
in
proceedings of naacl-hlt.

[tian et al.2014] fei tian, hanjun dai, jiang bian, bin
gao, rui zhang, enhong chen, and tie-yan liu.
2014. a probabilistic model for learning multi-
prototype id27s.
in coling, pages
151   160.

[turney and pantel2010] peter d. turney and patrick
pantel. 2010. from frequency to meaning: vec-
tor space models of semantics. journal of arti   cial
intelligence research, 37:141   188.

[turney et al.2003] peter d. turney, michael l.
littman, jeffrey bigham, and victor shnayder.
2003. combining independent modules to solve
multiple-choice synonym and analogy problems.
in proceedings of recent advances in natural
language processing, pages 482   489, borovets,
bulgaria.

[vu and parker2016] thuy vu and d stott parker.
2016. k-embeddings: learning conceptual embed-
dings for words using context.
in proceedings of
naacl-hlt, pages 1262   1267.

[wu and giles2015] zhaohui wu and c lee giles.
2015.
a
multi-prototype word representation model using
wikipedia. in aaai, pages 2188   2194. citeseer.

sense-aaware semantic analysis:

