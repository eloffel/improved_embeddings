6
1
0
2

 

n
u
j
 

5
1

 
 
]
l
c
.
s
c
[
 
 

1
v
4
5
7
4
0

.

6
0
6
1
:
v
i
x
r
a

a correlational encoder decoder architecture for pivot based sequence

generation

amrita saha

ibm research india
amrsaha4@in.ibm.com

mitesh m khapra
ibm research india
mikhapra@in.ibm.com

sarath chandar

university of montreal
apsarathchandar@gmail.com

janarthanan rajendran

indian institute of technology madras

rsdjjana@gmail.com

kyunghyun cho

new york university
kyunghyun.cho@nyu.edu

abstract

interlingua based machine translation (mt)
aims to encode multiple languages into a com-
mon linguistic representation and then decode
sentences in multiple target languages from
this representation.
in this work we explore
this idea in the context of neural encoder de-
coder architectures, albeit on a smaller scale
and without mt as the end goal. speci   cally,
we consider the case of three languages or
modalities x, z and y wherein we are in-
terested in generating sequences in y starting
from information available in x. however,
there is no parallel training data available be-
tween x and y but, training data is available
between x & z and z & y (as is often the
case in many real world applications). z thus
acts as a pivot/bridge. an obvious solution,
which is perhaps less elegant but works very
well in practice is to train a two stage model
which    rst converts from x to z and then
from z to y . instead we explore an interlin-
gua inspired solution which jointly learns to
do the following (i) encode x and z to a com-
mon representation and (ii) decode y from
this common representation. we evaluate our
model on two tasks: (i) bridge id68
and (ii) bridge captioning. we report promis-
ing results in both these applications and be-
lieve that this is a right step towards truly inter-
lingua inspired encoder decoder architectures.

1

introduction

interlingua based mt (nirenburg, 1994; dorr et al.,
2010) relies on the principle that every language in
the world can be mapped to a common linguistic

representation. further, given this representation,
it should be possible to decode a target sentence in
any language. this implies that given n languages
we just need n decoders and n encoders to translate
between these nc2 language pairs. note that even
though we take inspiration from interlingua based
mt, the focus of this work is not on mt. we be-
lieve that this idea is not just limited to translation
but could be applicable to any kind of conversion in-
volving multiple source and target languages and/or
modalities (for example, id68, multilingual
image captioning, multilingual image question an-
swering, etc.). even though this idea has had lim-
ited success, it is still fascinating and considered by
many as the holy grail of multilingual multimodal
processing.

it is interesting to consider the implications of this
idea when viewed in the statistical context. for ex-
ample, current state of the art statistical systems for
mt (koehn et al., 2003; chiang, 2005; luong et
al., 2015b), id68 (finch et al., 2015; shao
et al., 2015; nicolai et al., 2015), image caption-
ing (vinyals et al., 2015b; xu et al., 2015), etc.
require parallel data between the source and target
views (where a view could be a language or some
other modality like image). thus, given n views,
we require nc2 parallel datasets to build systems
which can convert from any source view to any tar-
get view. obviously, this does not scale well in prac-
tice because it is hard to    nd parallel data between
all nc2 views. for example, publicly available par-
allel datasets for id68 (zhang et al., 2012)
cater to < 20 languages. similarly, publicly avail-
able image caption datasets are available only for

english1 and german2.

this problem of resource scarcity could be alle-
viated if we could learn only n statistical encoders
and n statistical decoders wherein (i) the encoded
representation is common across languages and (ii)
the decoders can decode from this common repre-
sentation (akin to interlingua based conversion). as
a small step in this direction, we consider a scaled
down version of this generic nc2 conversion prob-
lem. speci   cally, we consider the case where we
have three views x, z, y but parallel data is avail-
able only between xz and zy (instead of all 3c2
parallel datasets). at test time, we are interested in
generating natural language sequences in y starting
from information available in x. we refer to this
as the bridge setup as the language z here can be
considered to be a bridge/pivot between x and y .

an obvious solution to the above problem is to
train a two-stage system which    rst converts from x
to z and then from z to y . while this solution may
work very well in practice (as our experiments in-
deed suggest) it is perhaps less elegant and becomes
tedious as the number of views increases. for exam-
ple, consider the case of converting from x to z to
r to y . instead, we suggest a neural network based
model which simultaneously learns the following (i)
a common representation for x and z and (ii) de-
coding y from this common representation. in other
words, instead of training two independent models
using the datasets between xz and zy , the model
jointly learns from the two datasets. the resulting
common representation learned for x and z can be
viewed as a vectorial analogue of the linguistic rep-
resentation sought by interlingua based approaches.
of course, by no means do we suggest that this vec-
torial representation is a substitute for the rich lin-
guistic representation but its easier to learn from par-
allel data (as opposed to a linguistic representation
which requires hand crafted resources).

note that our work should not be confused with
the recent work of (firat et al., 2016), (zoph and
knight, 2016) and (elliott et al., 2015). the last two
works in fact require 3-way parallel data between x,
z and y and learn to decode sequences in y given
both x and z. for example, at test time, (elliott et

1http://mscoco.org/dataset/$#$download
2http://www.statmt.org/wmt16/

multimodal-task.html

al., 2015) generate captions in german, given both
(i) the image and (ii) its corresponding english cap-
tion. this is indeed very different from the problem
addressed in this paper. similarly, even though (fi-
rat et al., 2016) learn a single encoder per language
and a single decoder per language they do not learn
shared representations for multiple languages (only
the attention mechanism is shared). further, in all
their experiments they require parallel data between
the two languages of interest. speci   cally, they do
not consider the case of generating sentences in y
given a sentence in x when no parallel data is avail-
able between x and y .

we present an empirical comparison of jointly
trained models which explicitly aim for shared en-
coder representations with two-stage architectures.
we consider two downstream applications (i) bridge
id68 and (ii) bridge id134. we
use the standard news 2012 dataset (zhang et al.,
2012) for id68. we consider id68
between 12 languages pairs (xy ) using english as
the bridge (z). bridge id134 is a new
task introduced in this paper where the aim is to gen-
erate french captions for an image when no image-
french(xy ) parallel data is available for training.
instead training data is available between image-
english (xz) and english-french (zy ).
in both
these tasks we report promising results. in fact, in
our multilingual id68 experiments we are
able to beat the strong two-stage baseline in many
cases. these results show potential for further re-
search in interlingua inspired neural network archi-
tectures. we do acknowledge that a successful inter-
lingua based statistical solution requiring only n en-
coders and n decoders is a much harder task whereas
our work is only a small step in that direction.

2 related work

encoder decoder based architectures for sequence to
sequence generation were initially proposed in (cho
et al., 2014; sutskever et al., 2014) in the context
of machine translation (mt) and have also been
successfully used for generating captions for images
(vinyals et al., 2015b). however, such sequence
to sequence models are often dif   cult to train as
they aim to encode the entire source sequence us-
ing a    xed encoder representation. bahdanau et al.

(2014) introduced attention based models wherein a
different representation is fed to the decoder at each
time step by focusing the attention on different parts
of the input sequence. such attention based mod-
els have been more successful than vanilla encoder-
decoder models and have been used successfully for
mt (bahdanau et al., 2014), parsing (vinyals et al.,
2015a), id103 (chorowski et al., 2015),
image captioning (xu et al., 2015) among other ap-
plications. all the above mentioned works focus
only on the case when there is one source and one
target. the source can be image, text, or speech sig-
nal but the target is always a text sequence.

encoder decoder models in a multi-source, single
target setting have been explored by (elliott et al.,
2015) and (zoph and knight, 2016). speci   cally,
elliott et al. (2015) try to generate a german caption
from an image and its corresponding english cap-
tion. similarly, zoph and knight (2016) focus on
the problem of generating english translations given
the same sentence in both french and german. we
would like to highlight that both these models re-
quire three-way parallel data while we are focusing
on situations where such data is not available. sin-
gle source, multi-target and multi-source, single tar-
get settings have been considered in (luong et al.,
2015a). recent work by firat et al. (2016) explores
multi-source to multi-target encoder decoder mod-
els in the context of machine translation. however,
firat et al. (2016) focus on id72 with
a shared attention mechanism and the goal is to im-
prove the mt performance for a pair of languages
for which parallel data is available. this is clearly
different from the goal of this paper which is to de-
sign encoder decoder models for a pair of languages
for which no parallel data is available but data is
available only between each of these languages and
a bridge language.

in

of

course,

general
based

the
idea
conversion

of
pivot/bridge/interlingua
is
not new and has been used previously in several
non-neural network settings. for example (khapra
et al., 2010) use a bridge language or pivot language
to do machine id68. similarly, (wu and
wang, 2007; zhu et al., 2014) do pivot based
machine translation. lastly, we would also like
to mention the work in interlingua based machine
translation (nirenburg, 1994; dorr et al., 2010)

which is clearly the inspiration for this work even
though the focus of this work is not on mt.

the main theme explored in this paper is to learn
a common representation for two views with the end
goal of generating a target sequence in a third view.
the idea of learning common representations for
multiple views has been explored well in the past
(klementiev et al., 2012; chandar et al., 2014; her-
mann and blunsom, 2014; chandar et al., 2016; ra-
jendran et al., 2015). for example, andrew et al.
(2013) propose deep cca for learning a common
representation for two views. (chandar et al., 2014;
chandar et al., 2016) propose correlational neural
networks for common representation learning and
rajendran et al. (2015) propose bridge correlational
networks for multilingual multimodal representation
learning. from the point of view of representation
learning, the work of rajendran et al. (2015) is very
similar to our work except that it focuses only on
representation learning and does not consider the
end goal of generating sequences in a target lan-
guage.

3 models

as mentioned earlier, one of the aims of this work is
to compare a jointly trained model with a two stage
model. we    rst brie   y describe such a two stage
encoder decoder architecture and then describe our
model which is a correlation based jointly trained
encoder decoder model.

3.1 a two stage encoder-decoder model
a two stage encoder-decoder is a straight-forward
extension of sequence to sequence models (cho et
al., 2014; sutskever et al., 2014) to the bridge setup.
given parallel data between xz and zy , a two
stage model will learn a generative model for each
of the pairs independently. for the purpose of this
work, the source can be an image or text but the tar-
get is always a natural language text. for encoding
an image, we simply take its feature representation
obtained from one of the fully connected layers of a
convolutional neural network and pass it through a
feed-forward layer. on the other hand, for encoding
the source text sequence, we use a recurrent neural
network. the decoder is always a recurrent neural
network which generates the text sequence, one to-

ken at a time.

figure 1: two stage encoder-decoder model. dashed lines
denote how the model is used during training time and solid
line denotes the test time usage. we can see that two encoder-
decoders are trained independently but used jointly during test-
ing.

i=1

let the two training sets be d1 = {xi, zi}n1
and d2 = {zi, yi}n2
i=1 where xi     x, yi     y and
zi     z. given d1, the    rst encoder learns to encode
xi and decode the corresponding zi from this en-
coded representation. the second encoder is trained
independently of the    rst encoder and uses d2 to en-
code zi     z and decode the corresponding yi     y
from this encoded representation. these indepen-
dent training processes are indicated by the dotted
arrows in figure 1. at test time, the two stages
are run sequentially. in other words, given xj, we
   rst encode it and decode zj from it using the    rst
encoder-decoder model. this decoded zj is then fed
to the second encoder-decoder model to generate yj.
this sequential test process is indicated by solid ar-
rows in figure 1.

while this two stage encoder-decoder model is a
trivial extension of a single encoder-decoder model,
it serves as a very strong baseline as we will see later
in the experiments section.

3.2 a correlation based joint encoder-decoder

model

while the above model works well in practice, it be-
comes cumbersome when more views are involved
(for example, when converting from u to x to y to
z). we desire a more elegant solution which could
scale even when more views are involved (although
for the purpose of this work, we restrict ourselves
to 3 views only). to this end, we propose a joint

model which uses the parallel data d1 (as de   ned
above) to learn one encoder each for x and z such
that the representations of xi and zi are correlated.
in addition and simultaneously the model uses d2
and learns to decode yj from zj. note that this joint
training has the advantage that the encoder for z
bene   ts from instances in d1 and d2.

having given an intuitive explanation of the
model, we now formally de   ne the objective func-
tions used during training. given d1 = {xi, zi}n1
i=1,
the model tries to maximize the correlation between
the encoded representations of xi and zi as de   ned
below.

(1)

jcorr(  ) =       corr(s(hx (x)), s(hz(z)))
where hx is the representation computed by the
encoder for x and hz is the representation com-
puted by the encoder for z. as mentioned earlier,
these encoders could be id56 encoders (in the case
of text) and simple feedforward encoders (in the case
of images). s() is a standardization function which
adjusts the hidden representations hx and hy so that
they have zero-mean and unit-variance. further,    is
a scaling hyper-parameter and corr is the correlation
function as de   ned below:

s(hx (xi))s(hz(zi))t

(2)

n(cid:88)

i=1

we would like to emphasize that s() ensures that
the representations already have zero mean and unit
variance and hence no separate standardization is re-
quired while computing the correlation.
in addition to the above id168, given d2 =
{zi, yi}n2
i=1, the model minimizes the following cross
id178 loss:

where

jce(  ) =

p (yk|zk) =

1
n2

l(cid:89)

i=1

p (yk|zk)

k=1

p (yki|yk<i, zk)

(3)

(4)

where l is the number of tokens in yk.
the dotted lines in figure 2 show the joint train-
ing process where the model simultaneously learns

n2(cid:88)

language pair

en-hi
en-ka
en-ma
en-ta

train-set validation-set

test-set

19918
16556
8500
16857

500
500
500
500

1000
1000
1000
1000

table 1: train, validation and test splits of the news
2012 id68 corpus for the 4 indian languages (hindi,
kannada, tamil, marathi)

use any direct parallel data between any of these lan-
guages. instead we use the standard datasets avail-
able between english and each of these languages
which were released as part of the news 2012
shared task (zhang et al., 2012). just to be explicit,
for the task of transliterating from hindi to kannada,
we construct d1 from the english-hindi dataset and
d2 from the english-kannada dataset. table 1 sum-
marizes the sizes of these parallel datasets. fortu-
nately, the english portion of the test set was com-
mon across all the 4 language pairs mentioned in ta-
ble 1. this allowed us to easily create test sets for
all the 12 language pairs. for example, if hi is the
id68 of the english word ei in the english-
hindi test set and ki is the id68 of the same
english word ei in the english-kannada test set then
we add (hi, ki) as a id68 pair in our hindi-
kannada test set. in this way, we created test sets
containing 1000 words for all the 12 language pairs.

4.2 hyperparameters
for the two stage encoder decoder model, we con-
sidered the following hyperparameters: embedding
size     {1024, 2048} for characters, id56 hidden unit
size     {1024, 2048}, initial learning rate     {0.01,
0.001} and batch size     {32, 64}. the numbers
in bracket indicate the distinct values that we con-
sidered for each hyperparameter. note that the em-
bedding size and id56 size are always kept equal.
all these parameters were tuned independently for
the two stages using their respective validation sets.
for the correlated encoder decoder model, in addi-
tion to the above hyperparamaters we also had       
[0.1, 1.0] as a hyperparameter. here, we tuned the
hyperparameters based on the performance on the
validation set available between zy (since the cor-
related encoder decoder can also decode yi     y
from zi     z). note that we do not use any paral-
lel data between xy for tuning the hyperparame-

figure 2: correlated encoder-decoder model. dashed lines de-
note how the model is used during training time and solid line
denotes the test time usage. we can see that during training,
both the encoders are trained to produce correlated representa-
tions and the decoder for y is trained based on encoder z. dur-
ing test time only encoder for x and decoder for y are used.

to compute correlated representations for xi and zi
and decode yi from zi. the testing process is shown
by the solid lines wherein the model computes a hid-
den representation for xi and then decodes yi from
it directly without transitioning through zi.
while training, we alternately pick mini-batches
from d1 and d2 and use the corresponding objec-
tive function. means and variances for the represen-
tations computed by the two encoders are updated at
the end of every epoch based on the hidden represen-
tations of all instances in the training data. during
the    rst epoch we assume the mean and variance to
be 0 and 1. note that    rescales the value of the cor-
relation loss term so that it is in the same range as
the value of the cross-id178 loss term.

4 experiment 1: bridge id68

we consider the task of id68 between two
languages x and y when no direct data is available
between them but parallel data is available between
x & z and z & y . in the following subsections we
describe the datasets used for our task, the hyper-
parameters considered for our experiments and re-
sults.

4.1 datasets
we consider id68 between 4 languages,
viz., hindi, kannada, tamil and marathi resulting
in 4c2 = 12 language pairs. however, we do not

ppppp

src

tgt

hi
ka
ta
ma

two stage pbsmt

hi

41.3
30.5
46.9

ka
36.3

25.8
33.7

ta
33.2
32.1

30.9

ma
33.6
26.2
19.2

ppppp

src

two stage encoder decoder
tgt

hi

ka
42.1

46.2
37.5
45.8

34.8
34.9

ta
43.4
42.9

31.7

ma
34.8
30.7
23.8

hi
ka
ta
ma

correlational encoder decoder

ppppp

src

tgt

hi
ka
ta
ma

hi

47.5
33.6
59.0

ka
43.1

27.7
37.1

ta
40.6
40.2

34.5

ma
40.9
27.9
17.0

table 2: id68 accuracy on the 12 language pairs involving (hindi, kannada, tamil, marathi) for the three comparative
methods (two stage pbsmt, two stage encoder decoder and the proposed correlational encoder decoder model. an underlined
number in this table signi   es that for that speci   c language pair the corresponding system is performing better than the two stage
pbsmt model and the best performing system for any of the language-pairs is represented in bold font

ters because the general assumption is that no par-
allel data is available between xy . we used adam
(kingma and ba, 2014) as the optimizer for all our
experiments.

4.3 results

we compare our model with the following systems:
1. two stage pbsmt: here, we train two pb-
smt (koehn et al., 2003) based id68 sys-
tems using d1 and d2. this is an additional base-
line to see how well an encoder decoder architecture
compares to a conventional pbsmt based system.
we used moses (koehn et al., 2007) for building
our pbsmt systems. the decoder parameters were
tuned using the validation sets. language model was
trained on the target portion of the parallel corpus.
2. two stage encoder decoder: here, we train two
encoder decoder based id68 systems using
d1 and d2 as described in section 4.

table 2 summarizes the accuracy (% of correct
id68s) of the three systems in the bridge
setup. we observe that in 6 out of the 12 lan-
guage pairs our correlated model does better than
the 2 stage encoder decoder model. further, it does
better than the two-stage pbsmt baseline in 11
out of the 12 language pairs. this is very encour-
aging especially because such 2-stage approaches
are considered to be very strong baselines for these
tasks (khapra et al., 2010). in general, the encoder
decoder based approaches do better than pbsmt
based systems. this is indeed the case even when
we compare the performance of the pbsmt based
system and the encoder decoder based system in-
dependently on the two stages (table 3).

accuracy(%)

pbsmt

source-target pair

en-hi
en-ka
en-ta
en-ma
hi-en
ka-en
ta-en
ma-en

51.7
45.3
50.0
30.2
51.1
47.9
41.4
35.0

encoder-
decoder
61.6
53.7
57.7
38.0
57.3
54.5
46.2
31.1

table 3: id68 accuracy of the pbsmt system and
the encoder-decoder model on the 4 indian languages (hindi,
kannada, tamil, marathi) when transliterated from english
and to english

5 experiment 2: bridge captioning

we now introduce the task of bridge caption gener-
ation. the purpose of introducing this task is two-
fold. firstly, we feel that it is important to put things
in perspective and demonstrate that while interlin-
gua inspired encoder decoder architectures are a step
in the right direction, much more work is needed
when dealing with different modalities in a bridge
setup. secondly, we think that this is an impor-
tant task which has not received any attention in the
past. we would like to formally de   ne and report
some initial baselines to motivate further research in
this area. the formal task de   nition is as follows:
generate captions for images in language l1 (say,
french) when no parallel data is available between
images and l1 but parallel data is available between
image-l2 (d1) and between l1-l2 (d2) where l2
in the follow-
is another language (say, english).
ing subsection we describe the datasets used for this
task, the hyperparameters considered for our exper-
iments and the results.

systems
pseudo im-fr
two stage
correlational encoder decoder

id7-4

id7-3

id7-2

id7-1

id8-l

15.5
16.6
12.6

24.2
25.7
19.3

37.4
39.0
31.1

56.5
58.3
50.5

38.3
39.5
34.3

cider
41.2
49.1
29.8

table 4: image captioning performance in generating french caption for a given image for the three methods: pseudo im-fr, two
stage and our correlational encoder decoder based model.

5.1 datasets

even though we do not have direct training data be-
tween image-french, we need some test data to eval-
uate our model. for this, we use the image-french
test set recently released by (rajendran et al., 2015).
to create this data, they    rst merged the 80k images
from the standard train split and 40k images from
the standard valid split of mscoco data3. they
then randomly split the merged 120k images into
train(118k), validation (1k) and test set (1k). they
then collect french translations for all the 5 captions
for each image in the test set using id104.
crowdflower4 was used as the id104 plat-
form and they solicited one french and one german
translation for each of the 5000 captions using native
speakers. note that (rajendran et al., 2015) report
results for cross modal search and do not address the
problem of crosslingual image captioning.

in our model,

for d1 we use the same
train(118k), validation (1k) and test sets (1k) as
de   ned in (rajendran et al., 2015) and explained
above. choosing d2 was a bit more tricky.
ini-
tially we considered the corpus released as part
of wmt   12 (callison-burch et al., 2012) which
contains roughly 44m english-french parallel sen-
tences from various sources including news, parlia-
mentary proceedings, etc. however, our initial small
scale experiments showed that this does not work
well because there is a clear mismatch between the
vocabulary of this corpus and the vocabulary that we
need for generating captions. also the vocabulary
is much larger (at least an order higher than what
we need for image captioning) and it thus hampers
training. further, the average length and structure
of these sentences is also very different from cap-
tions. domain shift in mt is itself a challenging
problem (not to mention the added complexity in a
multimodal bridge setup). it was unrealistic to ex-

3http://mscoco.org/dataset/$#$download
4https://make.crowdflower.com

pect our model to work in the presence of these or-
thogonal complexities.

to isolate these issues and evaluate our model in
a controlled environment, we needed a parallel cor-
pus which had very similar characteristics to that
observed in captions. since we did not have such
a corpus at our disposal we decided to follow (ra-
jendran et al., 2015) and use a pseudo parallel cor-
pus between english-french. speci   cally, we take
the english captions from the mscoco data and
translate them to french using the publicly available
translation system provided by ibm5. note that our
model still does not see direct parallel data between
image and french during training. we acknowledge
that this is not the ideal thing to do but it is good
enough to do a proof-of-concept evaluation of our
model and understand its potential. we, of course,
account for the liberty taken here by comparing with
equally strong baselines as discussed later in the re-
sults section.

5.2 hyperparameters
our model has the following hyperparameters: em-
bedding size, batch size, hidden representation size,
   and learning rate. based on experiments involv-
ing direct image-to-english id134 we
observed that the following parameters work well :
embedding size = 512, batch size = 80, id56 hidden
unit size = 512, and learning rate = 4e-4 with adam
(kingma and ba, 2014) as the optimizer. we just re-
tained these hyper-parameters and did not tune them
again for the bridge setup. we tuned the value of
   by evaluating the correlation loss on the image-
english validation set. again, we do not use any
image-french data for tuning any hyperparameters.

5.3 results
we now present the results of our experiments where
we compare with the following strong baselines.

5http://www.ibm.com/smarterplanet/us/en/

ibmwatson

s
e
g
a
m

i

o
c
o
c
s
m

r
e
d
o
c
e
d
r
e
d
o
c
n
e

l
a
n
o
i
t
a
l
e
r
r
o
c

e
g
a
t
s
-
o
w
t

r
f
-
m

i

o
d
u
e
s
p

homme
sur

est
un
surfer
une
vague dans l   oc  ean

un skateur est en
train de d  ecoller sur
un skateboard

une plaque avec
un sandwich et un
verre de bi`ere

girafe
dans

est
une
la
debout
pr`es
poussi`ere
d   une arborescence

un bus de transport
en commun dans
une rue de la ville

un salon avec un
canap  e , une table
et un t  el  eviseur

un homme circon-
scription une vague
sur une planche de
surf

cir-
un
homme
conscription
un
skateboard sur une
rampe en bois

plaque

une
de
nourriture sur une
table avec un verre
de vin

un

une girafe debout
dans
champ
avec des arbres en
arri`ereplan

bus

un
double
sandwich au volant
dune rue

un salon avec un
canap  e fauteuil et
une t  el  evision

un internaute dans
une
combinaison
isothermique
est
circonscription une
vague

un jeune garc  on
circonscription un
skateboard dans un
parc

plaque

une
de
nourriture sur une
table en bois

une girafe debout `a
c  ot  e d   un autre gi-
rafe dans une zone

un bus ville faire
baisser une rue de
la ville

un salon avec un
canap  e , une table
et un canap  e

table 5: example captions generated by the three methods on a sample set of mscoco test images

1. two stage : here we use a show & tell model
(vinyals et al., 2015b) trained using d1 to generate
an english caption for the image. we then translate
this caption into french using ibm   s translation sys-
tem as described above.
2. pseudo im-fr : here we train an image-to-
french show & tell model (vinyals et al., 2015b)
by pairing the images in the mscoco dataset with
their pseudo french captions generated by translat-
ing the english captions into french (using ibm   s
translation system).

we observe that our model is unable to beat
the two strong baselines described above but still
comes close to their performance. we believe this
reinforces our belief in this line of research and
hopefully more powerful models (perhaps attention
based) could eventually surpass these two baselines.
as a qualitative evaluation of our model, table 5
shows the captions generated by our model.
it is
exciting that even in a complex multimodal bridge
setup the model is able to capture correlations be-
tween images and english sentences and further de-
code relevant french captions from a given image.

6 conclusion
in this paper, we considered the problem of pivot
based sequence generation. speci   cally, we are in-

terested in generating sequences in a target language
starting from information in a source view. how-
ever, no direct training data is available between the
source and target views but training data is available
between each of these views and a pivot view. to
this end, we take inspiration from interlingua based
mt and propose a neural network based model
which explicitly maximizes the correlation between
the source and pivot view and simultaneously learns
to decode target sequences from this correlated rep-
resentation. we evaluate our model on the task of
bridge id68 and show that it outperforms a
strong two-stage baseline for many language pairs.
finally, we introduce the task of bridge caption gen-
eration and report promising initial results. we hope
this new task will fuel further research in this area.
as future work, we would like to go beyond sim-
ple encoder decoder based correlational models. for
example, we would like to apply the idea of correla-
tion to attention based encoder decoder models. the
ideas expressed here can also be applied to other
tasks such as bridge translation, bridge image qa,
etc. however, for these tasks, additional issues such
as larger vocabulary sizes, complex sentence struc-
tures, non-monotonic alignments between source
and target language pairs need to be addressed. the
model proposed here is just a beginning and much

more work is needed to cater to these complex tasks.

references
[andrew et al.2013] galen andrew, raman arora, jeff
bilmes, and karen livescu. 2013. deep canonical
correlation analysis. icml.

[bahdanau et al.2014] dzmitry bahdanau, kyunghyun
cho, and yoshua bengio.
2014. neural machine
translation by jointly learning to align and translate.
corr, abs/1409.0473.

[callison-burch et al.2012] chris

callison-burch,
philipp koehn, christof monz, matt post, radu
soricut, and lucia specia. 2012. findings of the
2012 workshop on id151. in
seventh workshop on id151,
wmt, pages 10   51, montr  eal, canada.

[chandar et al.2014] sarath chandar, stanislas lauly,
hugo larochelle, mitesh m khapra, balaraman
ravindran, vikas raykar, and amrita saha. 2014. an
autoencoder approach to learning bilingual word rep-
resentations. in proceedings of nips.

[chandar et al.2016] sarath chandar, mitesh m. khapra,
hugo larochelle, and balaraman ravindran. 2016.
correlational neural networks. neural computation,
28(2):257     285.

[chiang2005] david chiang.

2005. a hierarchical
phrase-based model for id151.
in acl 2005, 43rd annual meeting of the associa-
tion for computational linguistics, proceedings of the
conference, 25-30 june 2005, university of michigan,
usa.

[cho et al.2014] kyunghyun cho, bart van merrienboer,
c   aglar g  ulc  ehre, dzmitry bahdanau, fethi bougares,
holger schwenk, and yoshua bengio. 2014. learning
phrase representations using id56 encoder-decoder
for id151. in proceedings of
the 2014 conference on empirical methods in natural
language processing, emnlp 2014, october 25-29,
2014, doha, qatar, a meeting of sigdat, a special
interest group of the acl, pages 1724   1734.

[chorowski et al.2015] jan chorowski, dzmitry bah-
danau, dmitriy serdyuk, kyunghyun cho, and yoshua
bengio. 2015. attention-based models for speech
recognition. in advances in neural information pro-
cessing systems 28: annual conference on neural in-
formation processing systems 2015, december 7-12,
2015, montreal, quebec, canada, pages 577   585.

[dorr et al.2010] bonnie j. dorr, rebecca j. passonneau,
david farwell, rebecca green, nizar habash, stephen
helmreich, eduard h. hovy, lori s. levin, keith j.
miller, teruko mitamura, owen rambow, and ad-
vaith siddharthan. 2010.
interlingual annotation of

parallel text corpora: a new framework for annota-
tion and evaluation. natural language engineering,
16(3):197   243.

[elliott et al.2015] desmond elliott, stella frank, and eva
hasler. 2015. multi-language image description with
neural sequence models. corr, abs/1510.04709.

[finch et al.2015] andrew finch, lemao liu, xiaolin
wang, and eiichiro sumita. 2015. neural network
transduction models in id68 generation. pro-
ceedings of news 2015 the fifth named entities
workshop, page 61.

[firat et al.2016] orhan firat, kyunghyun cho, and
yoshua bengio. 2016. multi-way, multilingual neu-
ral machine translation with a shared attention mecha-
nism. corr, abs/1601.01073.

[hermann and blunsom2014] karl moritz hermann and
phil blunsom. 2014. multilingual models for compo-
in proceedings of the
sitional distributed semantics.
52nd annual meeting of the association for computa-
tional linguistics, acl 2014, june 22-27, 2014, balti-
more, md, usa, volume 1: long papers, pages 58   68.
[khapra et al.2010] mitesh m. khapra, a. kumaran, and
pushpak bhattacharyya. 2010. everybody loves a rich
cousin: an empirical study of id68 through
bridge languages. in human language technologies:
conference of the north american chapter of the as-
sociation of computational linguistics, proceedings,
june 2-4, 2010, los angeles, california, usa, pages
420   428.

[kingma and ba2014] diederik p. kingma and jimmy
ba. 2014. adam: a method for stochastic optimiza-
tion. corr, abs/1412.6980.

[klementiev et al.2012] alexandre klementiev,

ivan
titov, and binod bhattarai. 2012. inducing crosslin-
gual distributed representations of words.
in
proceedings of
the international conference on
computational linguistics (coling).

[koehn et al.2003] philipp koehn, franz josef och, and
daniel marcu. 2003. statistical phrase-based transla-
tion. in hlt-naacl.

[koehn et al.2007] philipp koehn, hieu hoang, alexan-
dra birch, chris callison-burch, marcello federico,
nicola bertoldi, brooke cowan, wade shen, chris-
tine moran, richard zens, chris dyer, ond  rej bo-
jar, alexandra constantin, and evan herbst. 2007.
moses: open source toolkit for statistical machine
translation. in proceedings of the 45th annual meet-
ing of the acl on interactive poster and demonstra-
tion sessions, acl    07, pages 177   180, stroudsburg,
pa, usa. association for computational linguistics.
[luong et al.2015a] minh-thang luong, quoc v. le, ilya
sutskever, oriol vinyals, and lukasz kaiser. 2015a.
multi-task sequence to sequence learning. corr,
abs/1511.06114.

32nd international conference on machine learning,
icml 2015, lille, france, 6-11 july 2015, pages
2048   2057.

[zhang et al.2012] min zhang, haizhou li, a. kumaran,
and ming liu. 2012. report of news 2012 machine
id68 shared task. in proceedings of the 4th
named entity workshop, news    12, pages 10   20,
stroudsburg, pa, usa. association for computational
linguistics.

[zhu et al.2014] xiaoning zhu, zhongjun he, hua wu,
conghui zhu, haifeng wang, and tiejun zhao. 2014.
improving pivot-based id151
by pivoting the co-occurrence count of phrase pairs.
in proceedings of the 2014 conference on empiri-
cal methods in natural language processing, emnlp
2014, october 25-29, 2014, doha, qatar, a meeting
of sigdat, a special interest group of the acl, pages
1665   1675.

[zoph and knight2016] barret zoph and kevin knight.
corr,

translation.

2016. multi-source neural
abs/1601.00710.

[luong et al.2015b] minh-thang luong, hieu pham, and
christopher d. manning.
effective ap-
proaches to attention-based neural machine transla-
tion. corr, abs/1508.04025.

2015b.

[nicolai et al.2015] garrett nicolai, bradley hauer, mo-
hammad salameh, adam st arnaud, ying xu, lei
yao, and grzegorz kondrak. 2015. multiple system
combination for id68. proceedings of news
2015 the fifth named entities workshop, page 72.

[nirenburg1994] sergei nirenburg. 1994. pangloss: a
in human language
machine translation project.
technology, proceedings of a workshop held at plains-
boro, new jerey, usa, march 8-11, 1994.

[rajendran et al.2015] janarthanan rajendran, mitesh m.
khapra, sarath chandar, and balaraman ravindran.
2015. bridge correlational neural networks for mul-
tilingual multimodal representation learning. corr,
abs/1510.03519.

[shao et al.2015] yan shao, j  org tiedemann, and joakim
nivre.
2015. boosting english-chinese machine
id68 via high quality alignment and multilin-
gual resources. proceedings of news 2015 the fifth
named entities workshop, page 56.

[sutskever et al.2014] ilya sutskever, oriol vinyals, and
quoc v. le. 2014. sequence to sequence learning
in advances in neural infor-
with neural networks.
mation processing systems 27: annual conference
on neural information processing systems 2014, de-
cember 8-13 2014, montreal, quebec, canada, pages
3104   3112.

[vinyals et al.2015a] oriol vinyals, lukasz kaiser, terry
koo, slav petrov, ilya sutskever, and geoffrey e. hin-
ton. 2015a. grammar as a foreign language. in ad-
vances in neural information processing systems 28:
annual conference on neural information processing
systems 2015, december 7-12, 2015, montreal, que-
bec, canada, pages 2773   2781.

[vinyals et al.2015b] oriol vinyals, alexander toshev,
samy bengio, and dumitru erhan. 2015b. show and
tell: a neural image caption generator. in ieee con-
ference on id161 and pattern recognition,
cvpr 2015, boston, ma, usa, june 7-12, 2015, pages
3156   3164.

[wu and wang2007] hua wu and haifeng wang. 2007.
pivot language approach for phrase-based statistical
machine translation. in acl 2007, proceedings of the
45th annual meeting of the association for compu-
tational linguistics, june 23-30, 2007, prague, czech
republic.

[xu et al.2015] kelvin xu,

jimmy ba, ryan kiros,
kyunghyun cho, aaron c. courville, ruslan
salakhutdinov, richard s. zemel, and yoshua bengio.
2015. show, attend and tell: neural image caption
generation with visual attention. in proceedings of the

