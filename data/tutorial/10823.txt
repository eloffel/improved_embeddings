6
1
0
2

 
t
c
o
8
2

 

 
 
]
l
c
.
s
c
[
 
 

2
v
7
7
7
8
0

.

9
0
6
1
:
v
i
x
r
a

character sequence models for colorful words

kazuya kawakami    , chris dyer       bryan r. routledge    noah a. smith   
   school of computer science, carnegie mellon university, pittsburgh, pa, usa

   google deepmind, london, uk

   tepper school of business, carnegie mellon university, pittsburgh, pa, usa
   computer science & engineering, university of washington, seattle, wa, usa

{kkawakam,cdyer}@cs.cmu.edu, routledge@cmu.edu, nasmith@cs.washington.edu

abstract

we present a neural network architecture to
predict a point in color space from the se-
quence of characters in the color   s name.
using large scale color   name pairs obtained
from an online color design forum, we eval-
uate our model on a    color turing test    and
   nd that, given a name, the colors predicted
by our model are preferred by annotators
to color names created by humans. our
datasets and demo system are available online
at http://colorlab.us.

1 introduction

color is a valuable vehicle for studying the associa-
tion between words and their nonlinguistic referents.
perception of color has long been studied in psy-
chology, and quantitative models linking physical
stimuli and psychological perception have been in
place since the 1920s (broadbent, 2004). although
perceptually faithful color representations require
only a few dimensions (  2), linguistic expressions
of color often rely on association and    gurative lan-
guage. there are, for example, 34,000 examples of
   blue    in our data. the varieties of blue range can
be emotional, descriptive, metaphoric, literal, and
whimsical. consider these examples (best viewed
in color): murkey blue, blueberry muf   n, greeny
blue, and jazzy blue.

this rich variety of descriptive names of colors
provides an ideal way to study linguistic creativity,
its variation, and an important aspect of visual un-
derstanding. this paper uses predictive modeling to
explore the relationship between colors (represented

in three dimensions) and casual, voluntary linguis-
tic descriptions of them by users of a crafting and
design website (  3).1

in this dataset   s creative vocabulary, word-level
representations are so sparse as to be useless, so
we turn to models that build name representations
out of characters (  4). we evaluate our model on
a    color turing test    and    nd that, given a name, it
tends to generate a color that humans    nd matches
the name better than the color that actually inspired
the name. we also investigate the reverse mapping,
from colors to names (  5). we compare a condi-
tional lstm language model used in caption gener-
ation (karpathy and fei-fei, 2014) to a new latent-
variable model, achieving a 10% perplexity reduc-
tion.
pur-
we
applica-
chase
tions
and
marketing aids (deng et al., 2010), and new meth-
ods for studying the interface between the human
visual and linguistic systems (marcus, 1991).

expect
in
(veale and al-najjar, 2015),

such modeling

computational

creativity

to    nd

design

2 color spaces

in electronic displays and other products, colors are
commonly represented in rgb space where each
color is embedded in {0, . . . , 255}3, with coordi-
nates corresponding to red, green, and blue levels.
while convenient for digital processing, distances
in this space are perceptually non-uniform. we in-
stead use a different three-dimensional representa-
tion, lab, which was originally designed so that
euclidean distances correlate with human-perceived

1http://www.colourlovers.com

train
dev.
test
ggplot2
paint

number of pairs unique names
476,713
52,753
52,760
66
956

670,032
53,166
53,166
66
956

table 1: datasets used in this paper. the train/dev./test split of
the colourlovers data was random. for ggplot2 and paint,
we show the number of test instances which are not in train set.

differences (hunter, 1958). lab is also continuous,
making it more suitable for the gradient-based learn-
ing used in this paper. the transformation from
rgb to lab is nonlinear.

3 task and dataset

the task of predicting a color in
we consider
our dataset is a
lab space given its name.
collection of user-named colors downloaded from
colourlovers,1 a creative community where peo-
ple create and share colors, palettes, and patterns.
our dataset contains 776,364 pairs with 581,483
unique names. examples of the color/name pairs
from colourlovers are the following: sugar
hearts you, vitamin c, haunted milk.

we considered two held-out datasets from other
sources; these do not overlap with the training data.
ggplot2: the 141 of   cially-named colors used in gg-
plot2, a common plotting package for the r pro-
gramming language (e.g., midnightblue. medium-
seagreen),2
paint: the paint manufacturer sherwin williams
has 7,750 named colors (e.g., pompeii red, butter
up).3

4 names to colors

our word-to-color model is used to predict a color
in lab space given the sequence of characters in
a color   s name, c = hc1, c2, . . . , c|c|i, where each
ci is a character in a    nite alphabet. each charac-
ter ci is represented by learned vector embedding in
r300. to build a color out of the sequence, we use
an lstm (hochreiter and schmidhuber, 1997) with
300 hidden units. the    nal hidden state is used as a

2http://sape.inf.usi.ch/quick-reference/ggplot2/colour
3http://bit.ly/paintcolornames

test
model
1018.35
unigram
977.46
bigram
id56
750.26
1-layer lstm 664.11
2-layer lstm 652.49

ggplot2
814.58
723.61
431.90
355.56
343.97

paint
351.54
364.41
305.05
303.03
274.83

table 2: mse in lab space on held-out datasets.

vector representation h     r300 of the sequence. the
associated color value in lab space is then de   ned
to be   y =   (wh + b), where w     r3  300 and
b     r3 transform h.

this model

instantiates the one proposed by
ling et al. (2015) for learning id27s
built from representations of characters.

to learn the parameters of the model (i.e., the pa-
rameters of the lstms, the character embeddings,
and w and b), we use reference color labels y
from our training set and minimize squared error,
||y       y||2, averaged across the training set. learn-
ing is accomplished using id26 and the
adam update rule (kingma and ba, 2014).

4.1 evaluation

we evaluated our model in two ways. first, we
computed mean-squared error on held-out data us-
ing several variants of our model. the baseline
models are id75 models, which predict
a color from a bag of character unigrams and bi-
grams. we compare an id56 and lstms with one
and two layers. table 2 shows that the two-layer
lstm achieves lower error than the unigram and
bigram baselines and an id56. we see the same pat-
tern of results on the out-of-domain test sets.

the color turing test. our second evaluation at-
tempts to assess whether our model   s associations
are human-like. for this evaluation, we asked hu-
man judges to choose the color better described by
a name from one of our test sets: our model   s pre-
dicted color or the color in the data. for each dataset,
we randomly selected 20 examples.
111 judges
considered each instance.4 judges were presented
instances in random order and forced to make a
choice between the two and explicitly directed to

4we excluded results from an additional 19 annotators
who made more than one mistake in a color blindness
test (oliver, 1888).

preference
actual color
predicted color

test

ggplot2

paint
43.2% 32.6% 31.0%
56.7% 67.3% 69.0%

table 3: summary of color turing test results.

make an arbitrary choice if neither was better.5 the
test is shown at http://colorlab.us/turk.
results are shown in table 3; on the ggplot2 and
paint datasets, our prediction is preferred to the ac-
tual names in a majority of cases. the test dataset
from colourlovers is a little bit challenging, with
more noisy and creative names; still, in the majority
of cases, our prediction is preferred.

4.2 visualization and exploration
to better understand our model, we provide illustra-
tions of its predictions on several kinds of inputs.

character by character prediction. we consider
how our model reads color names character by char-
acter. fig. 1 shows some examples, such as blue,
variously modi   ed. the word deep starts dark
brown, but eventually modi   es blue to a dark blue.
our model also performs sensibly on colors named
after things (mint, cream, sand).

figure 2: distribution of euclidean distances in lab from esti-
mated colors of words in each corpus to rgb (128, 128, 128).

(tasse and smith, 2008),6 and 6,000 beer reviews.7
for each corpus, we examine the distribution of eu-
clidean distances of   y from the lab representation of
the    middle    color rgb (128, 128, 128). the eu-
clidean distances from the mean are measuring the
variance of the color of words in a document. fig. 2
shows these distributions; recipes and beer reviews
are more    colorful    than poems, under our model   s
learned de   nition of color.

figure 1: visualization of character-by-character prediction.

figure 3: a recipe from greatist.com.

5 generating names from colors

genre and color. we can use our model to inves-
tigate how colors are evoked in text by predicting the
colors of each word in a text. fig. 3 shows a colored
recipe. noting that many words are rendered in neu-
tral grays and tans, we investigated how our model
colors words in three corpora: 3,300 english poems
(1800   present), 256 recipes from the curd dataset

the    rst of our two color naming models gen-
erates character sequences conditioned on lab
color representations,
following other sequence-
to-sequence
(sutskever et al., 2014;
karpathy and fei-fei, 2014). the transformation
is as follows: first, a linear transformation maps
together
the color vector into 300 dimensions,

approaches

5a preliminary study that allowed a judge to say that there

was no difference led to a similar result.

6http://www.cs.cmu.edu/ ark/curd/
7http://beeradvocate.com

comprising the initial hidden and memory vectors.
next a character lstm is iteratively applied to
the hidden, memory, and next-character vectors,
and the next character produced by applying af   ne
and then softmax functions to the hidden vector.
the model
is trained to maximize conditional
likelihood of each character given its history. we
used 300 dimensions for character embeddings and
recurrence weights. the output vocabulary size was
98 without lowercasing.

we also propose a model

to capture vari-
ations
in color description with latent vari-
ables by extending the variational autoencoder
(kingma and welling, 2013) to a conditional model.
we want to model the id155 of
word y and latent variables z given color x. the la-
tent variable gives the model capacity to account for
the complexity of the color   word mapping. since
p(y, z | x) = p(z)p(y | x, z), the variational objec-
tive is:

e

q  (z|x)[    log q  (z | x) + log p  (y, z | x)]
= e

q  (z|x)[    log q  (z | x) + log p  (y | x, z)p(z)]

       dkl(q  (z | x) || p(z)) +

1
l

l

x

l=1

log p  (y | x, zl)

the    rst term regularizes the shape of posterior,
q(z | x), to be close to prior p(z) where it is a
gaussian distribution, p(z) = n (0, i). the sec-
ond term is the log likelihood of the character se-
quence conditioned on color values. to optimize   
and   , we reparameterize the model, we write z in
terms of a mean and variance and samples from a
standard normal distribution, i.e., z =    +      with
       n (0, i). we predict mean and log variance of
the model with a multi-layer id88 and initial-
ize the decoder-lstm with h0 = tanh(wz + b).
we trained the model with mini-batch size 128 and
adam optimizer. the sample size l was set to 1.

evaluation. we evaluated our models by estimat-
ing perplexity on the test set (table 1). our base-
line is a character-level unconditional lstm lan-
guage model. conditioning on color improved per-
character perplexity by 7% and the latent variable
gave a further 3%; see table 4.

a second dataset we evaluate on is

the
munroe color corpus (munroe, 2010) which con-
tains 2,176,417 color description for 829 words
(i.e., single words have multiple color descrip-

model
lstm-lm
vae
color-conditioned lstm-lm
color-conditioned vae

perplexity
5.9
5.9
5.5
5.3

table 4: comparison of language models.

tions). monroe et al. (2016) have developed word-
based (rather character-based) recurrent neural net-
work model.

our character-based model with 1024 hidden
units achieved 12.48 per-description perplexity,
marginally better than 12.58 obtained with a word-
based neural network model reported in that work.
thus, we see that modeling color names as se-
quences of characters is wholly feasible. however,
since the corpus only contains color description for
829 words, the model trained on the munroe color
corpus does not provide suitable supervision for
evaluation on our more lexically diverse dataset.

6 related work and discussion

in

role
and

important

(wurm et al., 1993)

the lowest-level visual

is one of
playing
an

sig-
color
cog-
nals
behav-
nition
it
ior (maier et al., 2008; lichtenfeld et al., 2009).
plays a role in human object recognition:
to name
an object, we    rst need to encode visual information
such as shape and surface information including
color and texture. given a visual encoding, we
search our memory for a structural, semantic and
phonological description (humphreys et al., 1999).
adding color information to shape signi   cantly
improves naming accuracy and speeds correct
response times (rossion et al., 2004).

colors and their names have some association in
our cognition. the stroop (1935) effect is a well-
known example showing interference of colors and
color terms: when we see a color term printed in a
different color   blue   it takes us longer to name the
word, and we are more prone to naming errors than
when the ink matches   blue (de houwer, 2003).

recent evidence suggests that colors and words
are associated in the brain. the brain uses differ-
ent regions to perceive various modalities, but pro-
cessing a color word activates the same brain region
as the color it denotes (del prado mart    n et al., 2006;

simmons et al., 2007).

closer

to nlp,

stimuli
humans

and their
has
been

the relationship between vi-
linguistic descriptions
sual
by
explored
extensively
through automatic text generation from images
karpathy and fei-fei, 2014;
(kiros et al., 2014;
xu et al., 2015).
color
association with
word semantics has also been investigated in
several
(mohammad, 2011;
heer and stone, 2012;
andreas and klein, 2014;
mcmahan and stone, 2015).

previous

papers

7 conclusion

in this paper, we introduced a computational model
to predict a point in color space from the sequence
of characters in the color   s name. using a large set
of color   name pairs obtained from a color design
forum, we evaluate our model on a    color turing
test    and    nd that, given a name, the colors pre-
dicted by our model are preferred by annotators to
color names created by humans. we also investi-
gate the reverse mapping, from colors to names. we
compare a conditional lstm language model to a
new latent-variable model, achieving a 10% perplex-
ity reduction.

acknowledgments

we thank lucas beyer for very helpful comments
and discussions, and we also appreciate all the par-
ticipants of our color turing test.

references

[andreas and klein2014] jacob andreas and dan klein.
2014. grounding language with points and paths in
continuous spaces. in conll, pages 58   67.

[broadbent2004] arthur d. broadbent. 2004. a critical
review of the development of the cie1931 rgb color-
matching functions. color research & application,
29(4):267   272.

[de houwer2003] jan de houwer. 2003. on the role
of stimulus-response and stimulus-stimulus compat-
ibility in the stroop effect. memory & cognition,
31(3):353   359.

[del prado mart    n et al.2006] ferm    n moscoso

del
prado mart    n, olaf hauk, and friedemann pul-
verm  uller.
category speci   city in the
processing of color-related and form-related words:
an erp study. neuroimage, 29(1):29   37.

2006.

[deng et al.2010] xiaoyan deng, sam k. hui, and
j. wesley hutchinson.
2010. consumer prefer-
ences for color combinations: an empirical analysis of
similarity-based color relationships. journal of con-
sumer psychology, 20(4):476   484.

[heer and stone2012] jeffrey heer and maureen stone.
2012. color naming models for color selection, im-
age editing and palette design. in proc. chi.

[hochreiter and schmidhuber1997] sepp hochreiter and
j  urgen schmidhuber. 1997. long short-term memory.
neural computation, 9(8):1735   1780.

[humphreys et al.1999] glyn w. humphreys, cathy j.
price, and m. jane riddoch. 1999. from objects to
names: a cognitive neuroscience approach. psycho-
logical research, 62(2-3):118   130.

[hunter1958] richard s. hunter. 1958. photoelectric

color difference meter. josa, 48(12):985   993.

[karpathy and fei-fei2014] andrej karpathy and li fei-
deep visual-semantic alignments
arxiv preprint

fei.
for generating image descriptions.
arxiv:1412.2306.

2014.

[kingma and ba2014] diederik kingma and jimmy ba.
2014. adam: a method for stochastic optimization.
arxiv preprint arxiv:1412.6980.

[kingma and welling2013] diederik p. kingma and max
2013. auto-encoding id58.

welling.
arxiv preprint arxiv:1312.6114.

[kiros et al.2014] ryan kiros, ruslan salakhutdinov, and
rich zemel. 2014. multimodal neural language mod-
els.
in proceedings of the 31st international con-
ference on machine learning (icml-14), pages 595   
603.

[lichtenfeld et al.2009] stephanie

lichtenfeld,
markus a. maier, andrew j. elliot, and rein-
hard pekrun.
the semantic red effect:
processing the word red undermines intellectual
performance.
journal of experimental social
psychology, 45(6):1273   1276.

2009.

[ling et al.2015] wang ling,

isabel trancoso, chris
dyer, and alan w black. 2015. character-based neu-
ral machine translation. corr, abs/1511.04586.

[maier et al.2008] markus a. maier, andrew j. elliot,
and stephanie lichtenfeld. 2008. mediation of the
negative effect of red on intellectual performance. per-
sonality and social psychology bulletin.

[marcus1991] aaron marcus. 1991. graphic design for

electronic documents and user interfaces. acm.

[mcmahan and stone2015] brian

and
matthew stone. 2015. a bayesian model of grounded
color semantics. transactions of the association for
computational linguistics, 3:103   115.

mcmahan

[mohammad2011] saif mohammad. 2011. colourful
in

language: measuring word-colour associations.

proceedings of the 2nd workshop on cognitive mod-
eling and computational linguistics, pages 97   106.
association for computational linguistics.

[monroe et al.2016] will monroe, noah d. goodman,
and christopher potts. 2016. learning to generate
compositional color descriptions. in proc. emnlp.

[munroe2010] randall munroe.

2010. color survey

results.
online at blog.xkcd.com/2010/05/03/color-surveyresults.

[oliver1888] charles a oliver. 1888. tests for color-
blindness. transactions of the american ophthalmo-
logical society, 5:86.

[rossion et al.2004] bruno rossion, gilles pourtois, et al.
2004. revisiting snodgrass and vanderwart   s ob-
ject pictorial set: the role of surface detail in basic-
level object recognition. perception-london-,
33(2):217   236.

[simmons et al.2007] w. kyle simmons, vimal ramjee,
michael s. beauchamp, ken mcrae, alex martin, and
lawrence w. barsalou. 2007. a common neural sub-
strate for perceiving and knowing about color. neu-
ropsychologia, 45(12):2802   2810.

[stroop1935] j. ridley stroop. 1935. studies of interfer-
ence in serial verbal reactions. journal of experimen-
tal psychology, 18(6):643.

[sutskever et al.2014] ilya sutskever, oriol vinyals, and
quoc vv le. 2014. sequence to sequence learning
with neural networks. in advances in neural informa-
tion processing systems, pages 3104   3112.

[tasse and smith2008] dan tasse and noah a smith.
2008. sour cream: toward semantic processing of
recipes. technical report, technical report cmu-
lti-08-005, carnegie mellon university, pittsburgh,
pa.

[veale and al-najjar2015] tony veale and khalid al-
najjar.
unweaving the lexical rainbow:
grounding linguistic creativity in perceptual seman-
tics.

2015.

[wurm et al.1993] lee h. wurm, gordon e. legge,
lisa m. isenberg, and andrew luebker. 1993. color
improves object recognition in normal and low vision.
journal of experimental psychology: human percep-
tion and performance, 19(4):899.

[xu et al.2015] kelvin xu, jimmy ba, ryan kiros, aaron
courville, ruslan salakhutdinov, richard zemel, and
yoshua bengio. 2015. show, attend and tell: neural
image id134 with visual attention. arxiv
preprint arxiv:1502.03044.

