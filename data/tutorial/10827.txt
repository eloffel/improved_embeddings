many languages, one parser

waleed ammar    george mulcaire    miguel ballesteros       chris dyer    noah a. smith   

   school of computer science, carnegie mellon university, pittsburgh, pa, usa
   computer science & engineering, university of washington, seattle, wa, usa

   nlp group, pompeu fabra university, barcelona, spain

6
1
0
2

 
l
u
j
 

6
2

 
 
]
l
c
.
s
c
[
 
 

4
v
5
9
5
1
0

.

2
0
6
1
:
v
i
x
r
a

wammar@cs.cmu.edu, gmulc@uw.edu, miguel.ballesteros@upf.edu

cdyer@cs.cmu.edu, nasmith@cs.washington.edu

abstract

languages.

we train one multilingual model for depen-
dency parsing and use it to parse sentences
in several
the parsing model
uses (i) id73 clusters and em-
beddings; (ii) token-level language informa-
tion; and (iii) language-speci   c features (   ne-
grained pos tags). this input representation
enables the parser not only to parse effec-
tively in multiple languages, but also to gener-
alize across languages based on linguistic uni-
versals and typological similarities, making it
more effective to learn from limited annota-
tions. our parser   s performance compares fa-
vorably to strong baselines in a range of data
scenarios, including when the target language
has a large treebank, a small treebank, or no
treebank for training.

1

introduction

developing tools for processing many languages
has long been an important goal in nlp (r  sner,
1988; heid and raab, 1989),1 but it was only when
statistical methods became standard that massively
multilingual nlp became economical. the main-
stream approach for multilingual nlp is to design
language-speci   c models. for each language of in-
terest, the resources necessary for training the model
are obtained (or created), and separate parameters
are    t for each language separately. this approach
is simple and grants the    exibility of customizing

1as of 2007, the total number of native speakers of the
hundred most popular languages only accounts for 85% of the
world   s population (wikipedia, 2016).

the model and features to the needs of each lan-
guage, but it is suboptimal for theoretical and prac-
tical reasons. theoretically, the study of linguistic
typology tells us that many languages share mor-
phological, phonological, and syntactic phenomena
(bender, 2011); therefore, the mainstream approach
misses an opportunity to exploit relevant supervi-
sion from typologically related languages. practi-
cally, it is inconvenient to deploy or distribute nlp
tools that are customized for many different lan-
guages because, for each language of interest, we
need to con   gure, train, tune, monitor, and occasion-
ally update the model. furthermore, code-switching
or code-mixing (mixing more than one language in
the same discourse), which is pervasive in some gen-
res, in particular social media, presents a challenge
for monolingually-trained nlp models (barman et
al., 2014).2

in parsing, the availability of homogeneous syn-
tactic dependency annotations in many languages
(mcdonald et al., 2013; nivre et al., 2015b; agi  c
et al., 2015; nivre et al., 2015a) has created an
opportunity to develop a parser that is capable of
parsing sentences in multiple languages, address-
ing these theoretical and practical concerns.3 a
multilingual parser can potentially replace an array
of language-speci   c monolingually-trained parsers

2while our parser can be used to parse input with code-
switching, we have not evaluated this capability due to the lack
of appropriate data.

3although multilingual dependency treebanks have been
available for a decade via the 2006 and 2007 conll shared
tasks (buchholz and marsi, 2006; nivre et al., 2007), the tree-
bank of each language was annotated independently and with
its own annotation conventions.

(for languages with a large treebank). the same
approach has been used in low-resource scenarios
(with no treebank or a small treebank in the target
language), where indirect supervision from auxiliary
languages improves the parsing quality (cohen et
al., 2011; mcdonald et al., 2011; zhang and barzi-
lay, 2015; duong et al., 2015a; duong et al., 2015b;
guo et al., 2016), but these models may sacri   ce ac-
curacy on source languages with a large treebank. in
this paper, we describe a model that works well for
both low-resource and high-resource scenarios.

we propose a parsing architecture that takes as in-
put sentences in several languages,4 optionally pre-
dicting the part-of-speech (pos) tags and input lan-
guage. the parser is trained on the union of avail-
able universal dependency annotations in different
languages. our approach integrates and critically
relies on several recent developments related to de-
pendency parsing: universal pos tagsets (petrov et
al., 2012), cross-lingual word clusters (t  ckstr  m et
al., 2012), selective sharing (naseem et al., 2012),
universal dependency annotations (mcdonald et al.,
2013; nivre et al., 2015b; agi  c et al., 2015; nivre
et al., 2015a), advances in neural network architec-
tures (chen and manning, 2014; dyer et al., 2015),
and multilingual id27s (gardner et al.,
2015; guo et al., 2016; ammar et al., 2016). we
show that our parser compares favorably to strong
baselines trained on the same treebanks in three data
scenarios: when the target language has a large tree-
bank (table 3), a small treebank (table 7), or no
treebank (table 8). our parser is publicly available.5

2 overview

our goal is to train a dependency parser for a set
of target languages lt, given universal dependency
annotations in a set of source languages ls.
ide-
ally, we would like to have training data in all tar-
get languages (i.e., lt     ls), but we are also inter-
ested in the case where the sets of source and target
languages are disjoint (i.e., lt     ls =    ). when
all languages in lt have a large treebank, the main-
stream approach has been to train one monolingual
parser per target language and route sentences of a

4we discuss data requirements in the next section.
5https://github.com/clab/

language-universal-parser

given language to the corresponding parser at test
time. in contrast, our approach is to train one pars-
ing model with the union of treebanks in ls, then
use this single trained model to parse text in any lan-
guage in lt, hence the name    many languages, one
parser    (malopa). malopa strikes a balance be-
tween: (1) enabling cross-lingual model transfer via
language-invariant input representations; i.e., coarse
pos tags, multilingual id27s and mul-
tilingual word clusters, and (2) tweaking the be-
havior of the parser depending on the current input
language via language-speci   c representations; i.e.,
   ne-grained pos tags and language embeddings.

in addition to universal dependency annotations
in source languages (see table 1), we use the follow-
ing data resources for each language in l = lt   ls:
    universal pos annotations for training a pos tag-

ger,6

    a bilingual dictionary with another language in l

for adding cross-lingual lexical information,7

    language typology information,8
    language-speci   c pos annotations,9 and
    a monolingual corpus.10

novel contributions of this paper include: (i) us-
ing one parser instead of an array of monolingually-
trained parsers without sacri   cing accuracy on lan-
guages with a large treebank, (ii) an effective neural
network architecture for using language embeddings
to improve multilingual parsing, and (iii) a study
of how automatic language identi   cation affects the
performance of a multilingual dependency parser.

while not the primary focus of this paper, we also
show that a variant of our parser outperforms pre-
vious work on multi-source cross-lingual parsing in

6see   3.6 for details.
7our best results make use of this resource. we require that
all languages in l are (transitively) connected. the bilingual
dictionaries we used are based on unsupervised word align-
ments of parallel corpora, as described in guo et al. (2016).
see   3.3 for details.

8see   3.4 for details.
9our best results make use of this resource. see   3.5 for

details.

10this is only used for training id27s with    mul-
ticca,       multicluster    and    translation-invariance    methods in
table 6. we do not use this resource when we compare to pre-
vious work.

udt 2

ud 1.2

german (de)
14118 (264906)
801 (12215)
1001 (16339)
14118 (269626)
799 (12512)
977 (16537)
-

english (en)
39832 (950028)
1703 (40117)
2416 (56684)
12543 (204586)
2002 (25148)
2077 (25096)
50

spanish (es)
14138 (375180)
1579 (40950)
300 (8295)
14187 (382436)
1552 (41975)
274 (8128)
-

french (fr)
14511 (351233)
1620 (38328)
300 (6950)
14552 (355811)
1596 (39869)
298 (7210)
-

italian (it) portuguese (pt)
9600 (239012)
1211 (29873)
1205 (29438)
8800 (201845)
271 (4833)
288 (5867)
866

6389 (149145)
399 (9541)
400 (9187)
11699 (249307)
489 (11656)
489 (11719)
36

swedish (sv)
4447 (66631)
493 (9312)
1219 (20376)
4303 (66645)
504 (9797)
1219 (20377)
134

train
dev.
test
train
dev.
test
tags

table 1: number of sentences (tokens) in each treebank split in universal dependency treebanks (udt)
version 2.0 and universal dependencies version (ud) 1.2 for the languages we experiment with. the last
row gives the number of unique language-speci   c    ne-grained pos tags used in a treebank.

low resource scenarios, where languages in lt have
a small treebank (see table 7) or where lt     ls =    
(see table 8). in the small treebank setup with 3,000
token annotations, we show that our parser consis-
tently outperforms a strong monolingual baseline
with 5.7 absolute las (labeled attachment score)
points per language, on average.

3 parsing model
recent advances suggest that recurrent neural net-
works, especially long short-term memory (lstm)
architectures, are capable of learning useful repre-
sentations for modeling problems of sequential na-
ture (graves et al., 2013; sutskever et al., 2014).
in this section, we describe our language-universal
parser, which extends the id200 (s-lstm)
parser of dyer et al. (2015).

3.1 transition-based parsing with s-lstms
this section brie   y reviews dyer et al.   s s-lstm
parser, which we modify in the following sections.
the core parser can be understood as the sequential
manipulation of three data structures:
    a buffer (from which we read the token sequence),
    a stack (which contains partially-built parse trees),

and

    a list of actions previously taken by the parser.
the parser uses the arc-standard transition system
(nivre, 2004).11 at each timestep t, a transition ac-
tion is applied that alters these data structures ac-
cording to table 2.

11in a preprocessing step, we transform nonprojective trees
in the training treebanks to pseudo-projective trees using the
   baseline    scheme in (nivre and nilsson, 2005). we evaluate
against the original nonprojective test set.

along with the discrete transitions of the arc-
standard system, the parser computes vector repre-
sentations for the buffer, stack and list of actions at
time step t denoted bt, st, and at, respectively.12
the parser state at time t is given by:

pt = max{0, w[st; bt; at] + wbias}

(1)

where the matrix w and the vector wbias are
learned parameters. the matrix w is multiplied by
the vector [st; bt; at] created by the concatenation of
st, bt, at. the parser state pt is then used to de   ne
a categorical distribution over possible next actions
z:13

exp(cid:0)g(cid:62)
z(cid:48) exp(cid:0)g(cid:62)
(cid:80)

(cid:1)
z(cid:48)pt + qz(cid:48)(cid:1)

z pt + qz

p(z | pt) =

(2)

where gz and qz are parameters associated with ac-
tion z. the selected action is then used to update
the buffer, stack and list of actions, and to compute
bt+1, st+1 and at+1 accordingly.

the model

is trained to maximize the log-
likelihood of correct actions. at test time, the parser
greedily chooses the most probable action in every
time step until a complete parse tree is produced.

the following sections describe our extensions of
the core parser. more details about the core parser
can be found in dyer et al. (2015).

3.2 token representations
the vector representations of input tokens feed into
the stack-lstm modules of the buffer and the stack.
12a stack-lstm module is used to compute the vector rep-
resentation for each data structure, as detailed in dyer et al.
(2015).
13the total number of actions is 1+2   the number of unique
dependency labels in the treebank used for training, but we only
consider actions which meet the arc-standard preconditions in
fig. 2.

stackt buffert action
u, v, s
u, v, s
s

u, b shift

b reduce-right(r)
b reduce-left(r)

dependency

u r    v
u r    v
   

stackt+1 buffert+1
b
b
b

u, s
v, s
u, s

table 2: parser transitions indicating the action applied to the stack and buffer at time t and the resulting
stack and buffer at time t + 1.

for monolingual parsing, we represent each token
by concatenating the following vectors:
    a    xed, pretrained embedding of the word type,
    a learned embedding of the word type,
    a learned embedding of the brown cluster,
    a learned embedding of the    ne-grained pos tag,
    a learned embedding of the coarse pos tag.

for multilingual parsing with malopa, we start
with a simple delexicalized model where the token
representation only consists of learned embeddings
of coarse pos tags, which are shared across all lan-
guages to enable model transfer.
in the following
subsections, we enhance the token representation in
malopa to include lexical embeddings, language
embeddings, and    ne-grained pos embeddings.

3.3 lexical embeddings
previous work has shown that sacri   cing lexical fea-
tures amounts to a substantial decrease in the perfor-
mance of a dependency parser (cohen et al., 2011;
t  ckstr  m et al., 2012; tiedemann, 2015; guo et al.,
2015). therefore, we extend the token representa-
tion in malopa by concatenating learned embed-
dings of id73 clusters, and pretrained
multilingual embeddings of word types.
multilingual brown clusters. before training the
parser, we estimate brown clusters of english words
and project them via word alignments to words in
other languages. this is similar to the    projected
clusters    method in t  ckstr  m et al. (2012). to go
from brown clusters to embeddings, we ignore the
hierarchy within brown clusters and assign a unique
parameter vector to each cluster.
multilingual id27s. we also use
guo et al.   s (2016)    robust projection    method to pre-
train multilingual id27s. the    rst step

in    robust projection    is to learn embeddings for en-
glish words using the skip-gram model (mikolov et
al., 2013). then, we compute an embedding of non-
english words as the weighted average of english
id27s, using word alignment probabili-
ties as weights. the last step computes an embed-
ding of non-english words which are not aligned to
any english words by averaging the embeddings of
all words within an id153 of 1 in the same
language. we experiment with two other methods   
   multicca    and    multicluster,    both proposed by
ammar et al. (2016)   for pretraining multilingual
id27s in   4.1.    multicca    uses a lin-
ear operator to project pretrained monolingual em-
beddings in each language (except english) to the
vector space of pretrained english word embed-
dings, while    multicluster    uses the same embed-
ding for translationally-equivalent words in different
languages. the results in table 6 illustrate that the
three methods perform similarly on this task.

3.4 language embeddings

while many languages, especially ones that belong
to the same family, exhibit some similar syntac-
tic phenomena (e.g., all languages have subjects,
verbs, and objects), substantial syntactic differences
abound. some of these differences are easy to char-
acterize (e.g., subject-verb-object vs. verb-subject-
object, prepositions vs. postpositions, adjective-
noun vs. noun-adjective), while others are sub-
tle (e.g., number and positions of negation mor-
phemes). it is not at all clear how to translate de-
scriptive facts about a language   s syntax into fea-
tures for a parser.
consequently,

language-universal
parser on treebanks in multiple source languages
requires caution. while exposing the parser to a
diverse set of syntactic patterns across many lan-
guages has the potential to improve its performance

training a

in each, dependency annotations in one language
will, in some ways, contradict those in typologically
different languages.

for instance, consider a context where the next
word on the buffer is a noun, and the top word on
the stack is an adjective, followed by a noun. tree-
banks of languages where postpositive adjectives
are typical (e.g., french) will often teach the parser
to predict reduce-left, while those of languages
where prepositive adjectives are more typical (e.g.,
english) will teach the parser to predict shift.

inspired by naseem et al. (2012), we address this
problem by informing the parser about the input lan-
guage it is currently parsing. let l be the input vector
representation of a particular language. we consider
three de   nitions for l:14
    one-hot encoding of the language id,
    one-hot encoding of individual word-order prop-

erties,15 and

    averaged one-hot encoding of wals typological

properties (including word-order properties).16

it is worth noting that the    rst de   nition (language

we use a hidden layer with tanh nonlinearity to

id) turns out to work best in our experiments.
compute the language embedding l(cid:48) as:
l(cid:48) = tanh(ll + lbias)

at

where the matrix l and the vector lbias are addi-
tional model parameters. we modify the parsing ar-
chitecture as follows:
    include l(cid:48) in the token representation (which feeds
into the stack-lstm modules of the buffer and
the stack as described in   3.1),
14the
available
language-universal-parser/tree/master/
typological_properties.

contain
are
https://github.com/clab/

   les which

de   nitions

these

15the world atlas of language structures (wals; dryer
and haspelmath, 2013) is an online portal documenting typo-
logical properties of 2,679 languages (as of july 2015). we
use the same set of wals features used by zhang and barzilay
(2015), namely 82a (order of subject and verb), 83a (order of
object and verb), 85a (order of adposition and noun phrase),
86a (order of genitive and noun), and 87a (order of adjective
and noun).

16some wals features are not annotated for all languages.
therefore, we use the average value of all languages in the same
genus. we rescale all values to be in the range [   1, 1].

    include l(cid:48)

in the action vector representation
(which feeds into the stack-lstm module that
represents previous actions as described in   3.1),
and

time t as pt =

    rede   ne the parser state at

max{0, w[st; bt; at; l(cid:48)] + wbias}.
intuitively, the    rst two modi   cations allow the
input language to in   uence the vector representation
of the stack, the buffer and the list of actions. the
third modi   cation allows the input language to in-
   uence the parser state which in turn is used to pre-
dict the next action. in preliminary experiments, we
found that adding the language embeddings at the
token and action level is important. we also experi-
mented with computing more complex functions of
(st, bt, at, l(cid:48)) to de   ne the parser state, but they did
not help.

3.5 fine-grained pos tag embeddings
tiedemann (2015) shows that omitting    ne-grained
pos tags signi   cantly hurts the performance of a de-
pendency parser. however, those    ne-grained pos
tagsets are de   ned monolingually and are only avail-
able for a subset of the languages with universal de-
pendency treebanks.

we extend the token representation to include
a    ne-grained pos embedding (in addition to the
coarse pos embedding). we stochastically dropout
the    ne-grained pos embedding for each token with
50% id203 (srivastava et al., 2014) so that the
parser can make use of    ne-grained pos tags when
available but stay reliable when the    ne-grained
pos tags are missing.

3.6 predicting pos tags
the model discussed thus far conditions on the pos
tags of words in the input sentence. however, gold
pos tags may not be available in real applications
(e.g., parsing the web). here, we describe two mod-
i   cations to (i) model both id52 and depen-
dency parsing, and (ii) increase the robustness of the
parser to incorrect pos predictions.

tagging model. let x1, . . . , xn,
y1, . . . , yn,
z1, . . . , z2n be the sequence of words, pos tags,
and parsing actions, respectively, for a sentence of
length n. we de   ne the joint distribution of a pos

n(cid:89)
   2n(cid:89)

i=1

tag sequence and parsing actions given a sequence
of words as follows:
p(y1, . . . , yn, z1, . . . , z2n | x1, . . . , xn) =

p(yi | x1, . . . , xn)

setting b = 1, e(cid:48) = 0), and is dynamically updated
to match the error rate of the pos tagger on the de-
velopment set. at test time, we never dropout the
predicted pos embedding, i.e., e(cid:48) = e. intuitively,
this method extends the dropout method (srivastava
et al., 2014) to address structured noise in the input
layer.

p(zj | x1, . . . , xn, y1, . . . , yn, z1, . . . , zj   1)

4 experiments

j=1

|
| . . .) is de   ned in eq. 2, and p(yi
where p(zj
x1, . . . , xn) uses a bidirectional lstm (graves et
al., 2013). huang et al. (2015) show that the perfor-
mance of a bidirectional lstm pos tagger is on par
with a conditional random    eld tagger.

we use slightly different token representations for
tagging and parsing in the same model. for tag-
ging, we construct the token representation by con-
catenating the embeddings of the word type (pre-
trained), the brown cluster and the input language.
this token representation feeds into the bidirectional
lstm, followed by a softmax layer (at each posi-
tion) which de   nes a categorical distribution over
possible pos tags. for parsing, we construct the to-
ken representation by further concatenating the em-
beddings of predicted pos tags. this token repre-
sentation feeds into the stack-lstm modules of the
buffer and stack components of the transition-based
parser. this id72 setup enables us to
predict both pos tags and dependency trees in the
same model. we note that pretrained word embed-
dings, cluster embeddings and language embeddings
are shared for tagging and parsing.

block dropout. we use an independently devel-
oped variant of word dropout (iyyer et al., 2015),
which we call block dropout. the token representa-
tion used for parsing includes the embedding of pre-
dicted pos tags, which may be incorrect. we intro-
duce another modi   cation which makes the parser
more robust to incorrect pos tag predictions, by
stochastically zeroing out the entire embedding of
the pos tag. while training the parser, we replace
the pos embedding vector e with another vector (of
the same dimensionality) stochastically computed
as: e(cid:48) = (1     b)/      e, where b     {0, 1} is a
bernoulli-distributed random variable with parame-
ter    which is initialized to 1.0 (i.e., always dropout,

in this section, we evaluate the malopa approach
in three data scenarios: when the target language has
a large treebank (table 3), a small treebank (table 7)
or no treebank (table 8).

data. for experiments where the target language
has a large treebank, we use the standard data splits
for german (de), english (en), spanish (es), french
(fr), italian (it), portuguese (pt) and swedish (sv) in
the latest release (version 1.2) of universal depen-
dencies (nivre et al., 2015a), and experiment with
both gold and predicted pos tags. for experiments
where the target language has no treebank, we use
the standard splits for these languages in the older
universal dependency treebanks v2.0 (mcdonald et
al., 2013) and use gold pos tags, following the base-
lines (zhang and barzilay, 2015; guo et al., 2016).
table 1 gives the number of sentences and words
annotated for each language in both versions. in a
preprocessing step, we lowercase all tokens and re-
move multi-word annotations and language-speci   c
dependency relations. we use the same multilingual
brown clusters and multilingual embeddings of guo
et al. (2016), kindly provided by the authors.

optimization. we follow dyer et al. (2015) in
parameter initialization and optimization.17 how-
ever, when training the parser on multiple languages

17we use stochastic gradient updates with an initial learn-
ing rate of   0 = 0.1 in epoch #0, update the learning rate
in following epochs as   t =   0/(1 + 0.1t). we clip the (cid:96)2
norm of the gradient to avoid    exploding    gradients. unla-
beled attachment score (uas) on the development set deter-
mines early stopping. parameters are initialized with uniform

samples in   (cid:112)6/(r + c) where r and c are the sizes of the

previous and following layer in the nueral network (glorot and
bengio, 2010). the standard deviations of the labeled attach-
ment score (las) due to random initialization in individual tar-
get languages are 0.36 (de), 0.40 (en), 0.37 (es), 0.46 (fr), 0.47
(it), 0.41 (pt) and 0.24 (sv). the standard deviation of the aver-
age las scores across languages is 0.17.

las

de
79.3
monolingual
70.4
malopa
76.7
+lexical
+language id
78.6
+   ne-grained pos 78.9

en
85.9
69.3
82.0
84.2
85.4

target language
es
83.7
72.4
82.7
83.4
84.3

fr
81.7
71.1
81.2
82.4
82.4

it
88.7
78.0
87.6
89.1
89.0

pt
85.7
74.1
82.1
84.2
86.2

sv
83.5
65.4
81.2
82.6
84.5

average

84.0
71.5
81.9
83.5
84.3

table 3: id33:
labeled attachment scores (las) for monolingually-trained parsers and
malopa in the fully supervised scenario where lt = ls. note that we use the universal dependencies
verson 1.2 which only includes annotations for    13,000 english sentences, which explains the relatively
low scores in english. when we instead use the universal dependency treebanks version 2.0 which includes
annotations for    40,000 english sentences (originally from the english id32), we achieve uas
score 93.0 and las score 91.5.

in malopa, instead of updating the parameters
with the gradient of individual sentences, we use
mini-batch updates which include one sentence sam-
pled uniformly (without replacement) from each
language   s treebank, until all sentences in the small-
est treebank are used (which concludes an epoch).
we repeat the same process in following epochs.
we found this to help prevent one source language
with a larger treebank (e.g., german) from dominat-
ing parameter updates at the expense of other source
languages with a smaller treebank (e.g., swedish).

4.1 target languages with a treebank

(lt = ls)

here, we evaluate our malopa parser when the
target language has a treebank.

language,

baseline. for each target
the strong
baseline we use is a monolingually-trained s-lstm
parser with a token representation which concate-
nates: pretrained id27s (50 dimen-
sions),18 learned id27s (50 dimensions),
coarse (universal) pos tag embeddings (12 dimen-
sions),    ne-grained (language-speci   c, when avail-
able) pos tag embeddings (12 dimensions), and em-
beddings of brown clusters (12 dimensions), and
uses a two-layer s-lstm for each of the stack, the
buffer and the list of actions. we independently train
one baseline parser for each target language, and
share no model parameters. this baseline, denoted

   monolingual    in tables 3 and 7, achieves uas score
93.0 and las score 91.5 when trained on the en-
glish id32, which is comparable to dyer
et al. (2015).

malopa. we train malopa on the concante-
nation of training sections of all seven languages. to
balance the development set, we only concatenate
the    rst 300 sentences of each language   s develop-
ment section.

representations. the

token
   rst mal-
opa parser we evaluate uses only coarse pos
embeddings to construct the token representation.19
as shown in table 3,
this parser consistently
underperforms the monolingual baselines, with a
gap of 12.5 las points on average.

augmenting the token representation with lexical
embeddings to the token representation (both mul-
tilingual word clusters and pretrained multilingual
id27s, as described in   3.3) substan-
tially improves the performance of malopa, re-
covering 83% of the gap in average performance.

we experimented with three ways to include
language information in the token representation,
namely:    language id   ,    word order    and    full ty-
pology    (see   3.4 for details), and found all three
to improve the performance of malopa giving
las scores 83.5, 83.2 and 82.5, respectively. it is
noteworthy that the model bene   ts more from lan-

18these embeddings are treated as    xed inputs to the parser,
and are not optimized towards the parsing objective. we use the
same embeddings used in guo et al. (2016).

19we use the same number of dimensions for the coarse pos
embeddings as in the monolingual baselines. the same applies
to all other types of embeddings used in malopa.

left
recall %
89.9
monolingual
85.4
malopa
89.9
+lexical
89.1
+language id
+   ne-grained pos 89.5

right
95.2
93.3
93.8
94.7
95.7

root
86.4
80.2
84.5
86.6
87.8

short
92.9
91.2
92.6
93.2
93.6

long
81.1
73.3
78.6
81.4
82.0

nsubj*
77.3
57.3
73.3
74.7
74.7

dobj
75.5
62.7
73.4
73.0
74.9

conj
66.0
64.2
66.9
71.2
69.7

*comp
45.6
34.0
35.3
48.2
46.0

case
93.3
90.7
91.6
92.8
93.3

*mod
77.0
69.6
75.3
76.3
76.3

table 4: recall of some classes of dependency attachments/relations in german.

las

language id coarse pos

gold

predicted

gold

predicted

gold
gold

predicted
predicted

de
78.6
78.5
71.2
70.8

en
84.2
80.2
79.9
74.1

target language
es
83.4
83.4
80.5
80.5

fr
82.4
82.1
78.5
78.2

it
89.1
88.9
85.0
84.7

pt
84.2
83.9
78.4
77.1

sv
82.6
82.5
75.5
75.5

average

83.5
82.7
78.4
77.2

table 5: effect of automatically predicting language id and pos tags with malopa on las scores.

guage id than from typological properties. using
   language id,    we recover another 12% of the origi-
nal gap.

finally, the best con   guration of malopa adds
   ne-grained pos embeddings to the token represen-
tation.20 surprisingly, adding    ne-grained pos em-
beddings improves the performance even for some
languages where    ne-grained pos tags are not avail-
able (e.g., spanish). this parser outperforms the
monolingual baseline in    ve out of seven target lan-
guages, and wins on average by 0.3 las points. we
emphasize that this model is only trained once on
all languages, and the same model is used to parse
the test set of each language, which simpli   es the
distribution or deployment of multilingual parsing
software.

qualitative analysis. to gain a better understand-
ing of the model behavior, we analyze certain
classes of dependency attachments/relations in ger-
man, which has notably    exible word order, in ta-
ble 4. we consider the recall of left attachments
(where the head word precedes the dependent word
in the sentence), right attachments, root attach-
ments, short-attachments (with distance = 1), long-
attachments (with distance > 6), as well as the fol-
lowing relation groups: nsubj* (nominal subjects:

20fine-grained pos tags were only available for english,
italian, portuguese and swedish. other languages reuse the
coarse pos tags as    ne-grained tags instead of padding the ex-
tra dimensions in the token representation with zeros.

nsubj, nsubjpass), dobj (direct object: dobj),
conj (conjunct: conj), *comp (clausal comple-
ments: ccomp, xcomp), case (clitics and adposi-
tions: case), *mod (modi   ers of a noun: nmod,
nummod, amod, appos), neg (negation modi   er:
neg).21

findings. we found that each of the three im-
provements (lexical embeddings, language embed-
dings and    ne-grained pos embeddings) tends to
improve recall for most classes. malopa un-
derperforms (compared to the monolingual base-
line) in some classes: nominal subjects, direct ob-
jects and modi   ers of a noun. nevertheless, mal-
opa outperforms the baseline in some important
classes such as: root, long attachments and conjunc-
tions.

predicting language ids and pos tags.
in ta-
ble 3, we assume that both gold language id of the
input language and gold pos tags are given at test
time. however, this assumption is not realistic in
practical applications. here, we quantify the degra-
dation in parsing accuracy when language id and
pos tags are only given at training time, but must
be predicted at test time. we do not use    ne-grained

21for each group, we report recall of both the attach-
ment and relation weighted by the number of instances in the
gold annotation. a detailed description of each relation can
be found at http://universaldependencies.org/
u/dep/index.html

pos tags in these experiments because some lan-
guages use a very large    ne-grained pos tag set
(e.g., 866 unique tags in portuguese).

in order to predict

language id, we use the
langid.py library (lui and baldwin, 2012)22 and
classify individual sentences in the test sets to one
of the seven languages of interest, using the default
models included in the library. the macro aver-
age language id prediction accuracy on the test set
across sentences is 94.7%. in order to predict pos
tags, we use the model described in   3.6 with both
input and hidden lstm dimensions of 60, and with
block dropout. the macro average accuracy of the
pos tagger is 93.3%. table 5 summarizes the four
con   gurations: {gold language id, predicted lan-
guage id}    {gold pos tags, predicted pos tags}.
the performance of the parser suffers mildly (   0.8
las points) when using predicted language ids,
but more (   5.1 las points) when using predicted
pos tags. as an alternative approach to predicting
pos tags, we trained the stanford pos tagger, for
each target language, on the coarse pos tag annota-
tions in the training section of the universal depen-
dency treebanks,23 then replaced the gold pos tags
in the test set of each language with predictions of
the monolingual tagger. the resulting degradation
in parsing performance between gold vs. predicted
pos tags is    6.0 las points (on average, compared
to a degradation of    5.1 las points in table 5). the
disparity in parsing results with gold vs. predicted
pos tags is an important open problem, and has
been previously discussed by tiedemann (2015).

the predicted pos results in table 5 use block
dropout. without using block dropout, we lose an
extra 0.2 las points in both con   gurations using
predicted pos tags.
embeddings. several
different multilingual
methods have been proposed for pretraining mul-
tilingual id27s. we compare three of
them:

    multicca (ammar et al., 2016) uses a lin-
22https://github.com/saffsd/langid.py
23we used version 3.6.0 of

the stanford pos tag-
ger, with the following pre-packaged con   guration    les:
german-fast-caseless.tagger.props
english-caseless-
left3words-distsim.tagger.props (en), spanish.tagger.props (es),
french.tagger.props (fr). we reused french.tagger.props for (it,
pt, sv).

(de),

multilingual embeddings uas las
84.1
84.4
84.2

87.7
multicca 87.8
87.8

robust projection

multicluster

table 6: effect of multilingual embedding estima-
tion method on the multilingual parsing with mal-
opa. uas and las scores are macro-averaged
across seven target languages.

ear operator to project pretrained monolingual
embeddings in each language (except english)
to the vector space of pretrained english word
embeddings.

    multicluster (ammar et al., 2016) uses the
same embedding for translationally-equivalent
words in different languages.

    robust projection (guo et al., 2015)    rst pre-
trains monolingual english id27s,
then de   nes the embedding of a non-english
word as the weighted average embedding of
english words aligned to the non-english
words (in a parallel corpus). the embedding of
a non-english word which is not aligned to any
english words is de   ned as the average embed-
ding of words with a unit id153 in the
same language (e.g.,    playz    is the average of
   plays    and    play   ).24

all embeddings are trained on the same data and use
the same number of dimensions (100).25 table 6 il-
lustrates that the three methods perform similarly on
this task. aside from table 6, in this paper, we ex-
clusively use the robust projection multilingual em-
beddings trained in guo et al. (2016).26 the    ro-
bust projection    result in table 6 (which uses 100
dimensions) is comparable to the last row in table 3
(which uses 50 dimensions).

24our

implementation
at

be
https://github.com/gmulcaire/

this method

can

of

found
average-embeddings.

25we share the embedding    les at https://github.

com/clab/language-universal-parser/tree/
master/pretrained_embeddings.

26the embeddings were kindly provided by the authors
of guo et al. (2016) at https://drive.google.com/
file/d/0b1z04ix6jd_dy3lmn2ntdy02nfu/view

las

zhang and barzilay (2015)
guo et al. (2016)
malopa

target language

average

de
54.1
55.9
57.1

es
68.3
73.0
74.6

fr
68.8
71.0
73.9

it
69.4
71.2
72.5

pt
72.5
78.6
77.0

sv
62.5
69.5
68.1

65.9
69.3
70.5

table 8: id33:
simulated low-resource scenario where lt     ls =    .

labeled attachment scores (las) for multi-source transfer parsers in the

las

monolingual
duong et al.
malopa

de
58.0
61.8
63.4

target language
es
64.7
70.5
70.5

fr
63.0
67.2
69.1

it
68.7
71.3
74.1

sv
57.6
62.5
63.4

table 7: small (3,000 token) target treebank setting:
language-universal dependency parser performance.

small target treebank. duong et al. (2015b) con-
sidered a setup where the target language has a small
treebank of    3,000 tokens, and the source language
(english) has a large treebank of    205,000 tokens.
the parser proposed in duong et al. (2015b) is a
neural network parser based on chen and manning
(2014), which shares most of the parameters be-
tween english and the target language, and uses
an (cid:96)2 regularizer to tie the lexical embeddings of
translationally-equivalent words. while not the pri-
mary focus of this paper,27 we compare our pro-
posed method to that of duong et al. (2015b) on
   ve target languages for which multilingual brown
clusters are available from guo et al. (2016). for
each target language, we train the parser on the en-
glish training data in the ud version 1.0 corpus
(nivre et al., 2015b) and a small treebank in the
target language.28 following duong et al. (2015b),
in this setup, we only use gold coarse pos tags,

27the setup cost involved in recruiting linguists, developing
and revising annotation guidelines to annotate a new language
ought to be higher than the cost of annotating 3,000 tokens. af-
ter investing much resources in a language, we believe it is un-
realistic to stop the annotation effort after only 3,000 tokens.

28we thank long duong for

subsampled training corpora in each target
https://github.com/longdt219/universal_
dependency_parser/tree/master/data/
universal-dep/universal-dependencies-1.0.

sharing the processed,
language at

we do not use any development data in the target
languages (we use the english development set in-
stead), and we subsample the english training data
in each epoch to the same number of sentences in the
target language. we use the same hyperparameters
speci   ed before for the single malopa parser and
each of the monolingual baselines. table 7 shows
that our method outperforms duong et al. (2015b)
by 1.4 las points on average. our method consis-
tently outperforms the monolingual baselines in this
setup, with an average improvement of 5.7 absolute
las points.

4.2 target languages without a treebank

(lt     ls =    )

mcdonald et al. (2011) established that, when no
treebank annotations are available in the target lan-
guage, training on multiple source languages out-
performs training on one (i.e., multi-source model
transfer outperforms single-source model transfer).
in this section, we evaluate the performance of our
parser in this setup. we use two strong baseline
multi-source model transfer parsers with no super-
vision in the target language:
    zhang and barzilay (2015) is a graph-based arc-
factored parsing model with a tensor-based scor-
ing function.
it takes typological properties of
a language as input. we compare to the best
reported con   guration (i.e.,
the column titled
   ours    in table 5 of zhang and barzilay, 2015).
    guo et al. (2016) is a transition-based neural-
network parsing model based on chen and man-
ning (2014).
it uses a multilingual embeddings
and brown clusters as lexical features. we com-
pare to the best reported con   guration (i.e., the
column titled    multi-proj    in table 1 of guo
et al., 2016).

following guo et al. (2016), for each target lan-
guage, we train the parser on six other languages in
the google universal dependency treebanks version
2.029 (de, en, es, fr, it, pt, sv, excluding whichever
is the target language), and we use gold coarse pos
tags. our parser uses the same id27s
and word clusters used in guo et al. (2016), and does
not use any typology information.30

the results in table 8 show that, on average, our
parser outperforms both baselines by more than 1
point in las, and gives the best las results in four
(out of six) languages.

5 related work
our work builds on the model transfer approach,
which was pioneered by zeman and resnik (2008)
who trained a parser on a source language treebank
then applied it to parse sentences in a target lan-
guage. cohen et al. (2011) and mcdonald et al.
(2011) trained unlexicalized parsers on treebanks of
multiple source languages and applied the parser to
different languages. naseem et al. (2012), t  ck-
str  m et al. (2013), and zhang and barzilay (2015)
used language typology to improve model trans-
fer. to add lexical information, t  ckstr  m et al.
(2012) used id73 clusters, while xiao
and guo (2014), guo et al. (2015), s  gaard et al.
(2015) and guo et al. (2016) used id73
embeddings. duong et al. (2015b) used a neural
network based model, sharing most of the parame-
ters between two languages, and used an (cid:96)2 regular-
izer to tie the lexical embeddings of translationally-
equivalent words. we incorporate these ideas in
our framework, while proposing a novel neural ar-
chitecture for embedding language typology (see
  3.4), and use a variant of word dropout (iyyer et
al., 2015) for consuming noisy structured inputs.
we also show how to replace an array of mono-
lingually trained parsers with one multilingually-
trained parser without sacri   cing accuracy, which is
related to vilares et al. (2016).

neural network parsing models which preceded
dyer et al. (2015) include henderson (2003), titov
and henderson (2007), henderson and titov (2010)
29https://github.com/ryanmcd/uni-dep-tb/
30in preliminary experiments, we found language embed-
dings to hurt the performance of the parser for target languages
without a treebank.

and chen and manning (2014). related to lexi-
cal features in cross-lingual parsing is durrett et al.
(2012) who de   ned lexico-syntactic features based
on bilingual lexicons. other related work include
  stling (2015), which may be used to induce more
useful typological properties to inform multilingual
parsing.

another popular approach for cross-lingual su-
pervision is to project annotations from the source
language to the target language via a parallel cor-
pus (yarowsky et al., 2001; hwa et al., 2005) or
via automatically-translated sentences (tiedemann
et al., 2014). ma and xia (2014) used id178 regu-
larization to learn from both parallel data (with pro-
jected annotations) and unlabeled data in the target
language. rasooli and collins (2015) trained an
array of target-language parsers on fully annotated
trees, by iteratively decoding sentences in the tar-
get language with incomplete annotations. one re-
search direction worth pursuing is to    nd synergies
between the model transfer approach and annotation
projection approach.

6 conclusion

we presented malopa, a single parser trained on
a multilingual set of treebanks. we showed that
this parser, equipped with language embeddings and
   ne-grained pos embeddings, on average outper-
forms monolingually-trained parsers for target lan-
guages with a treebank. this pattern of results is
quite encouraging. although languages may share
underlying syntactic properties, individual parsing
models must behave quite differently, and our model
allows this while sharing parameters across lan-
guages. the value of this sharing is more pro-
nounced in scenarios where the target language   s
training treebank is small or non-existent, where
our parser outperforms previous cross-lingual multi-
source model transfer methods.

acknowledgments

waleed ammar is supported by the google fellow-
ship in natural language processing. miguel balles-
teros is supported by the european commission un-
der the contract numbers fp7-ict-610411 (project
multisensor) and h2020-ria-645012 (project
kristina). part of this material is based upon

work supported by a subcontract with raytheon
bbn technologies corp. under darpa prime con-
tract no. hr0011-15-c-0013, and part of this re-
search was supported by a google research award
to noah smith. we thank jiang guo for sharing
the multilingual id27s and multilingual
word clusters. we thank lori levin, ryan mc-
donald, j  rg tiedemann, yulia tsvetkov, and yuan
zhang for helpful discussions. last but not least,
we thank the anonymous tacl reviewers for their
valuable feedback.

references
[agi  c et al.2015]   eljko agi  c, maria jesus aranzabe,
aitziber atutxa, cristina bosco, jinho choi, marie-
catherine de marneffe, timothy dozat, rich  rd
farkas, jennifer foster, filip ginter,
iakes goe-
naga, koldo gojenola, yoav goldberg, jan ha-
ji  c, anders tr  rup johannsen, jenna kanerva, juha
kuokkala, veronika laippala, alessandro lenci, kris-
ter lind  n, nikola ljube  i  c, teresa lynn, christopher
manning, h  ctor alonso mart  nez, ryan mcdonald,
anna missil  , simonetta montemagni, joakim nivre,
hanna nurmi, petya osenova, slav petrov, jussi piit-
ulainen, barbara plank, prokopis prokopidis, sampo
pyysalo, wolfgang seeker, mojgan seraji, natalia sil-
veira, maria simi, kiril simov, aaron smith, reut
tsarfaty, veronika vincze, and daniel zeman. 2015.
universal dependencies 1.1. lindat/clarin digi-
tal library at institute of formal and applied linguis-
tics, charles university in prague.

[ammar et al.2016] waleed ammar, george mulcaire,
yulia tsvetkov, guillaume lample, chris dyer, and
noah a. smith. 2016. massively id73
embeddings. arxiv:1602.01925v2.

[barman et al.2014] utsab barman, amitava das,
joachim wagner, and jennifer foster. 2014. code
mixing: a challenge for language identi   cation in the
in emnlp workshop on
language of social media.
computational approaches to code switching.

[bender2011] emily m. bender. 2011. on achieving and
evaluating language-independence in nlp. linguistic
issues in language technology, 6(3):1   26.

[buchholz and marsi2006] sabine buchholz and erwin
marsi. 2006. conll-x shared task on multilingual
id33. in proc. of conll.

[chen and manning2014] danqi chen and christopher
2014. a fast and accurate dependency

manning.
parser using neural networks. in proc. of emnlp.

[cohen et al.2011] shay b. cohen, dipanjan das, and
noah a. smith. 2011. unsupervised structure predic-

tion with non-parallel multilingual guidance. in proc.
of emnlp.

[dryer and haspelmath2013] matthew s. dryer and mar-
2013. wals online.
tin haspelmath, editors.
max planck institute for evolutionary anthropology,
leipzig.

[duong et al.2015a] long duong, trevor cohn, steven
bird, and paul cook. 2015a. low resource depen-
dency parsing: cross-lingual parameter sharing in a
neural network parser. in proc. of acl-ijcnlp.

[duong et al.2015b] long duong, trevor cohn, steven
bird, and paul cook. 2015b. a neural network model
for low-resource universal id33.
in
proc. of emnlp.

[durrett et al.2012] greg durrett, adam pauls, and dan
klein. 2012. syntactic transfer using a bilingual lexi-
con. in proc. of emnlp.

[dyer et al.2015] chris dyer, miguel ballesteros, wang
ling, austin matthews, and noah a. smith. 2015.
transition-based id33 with stack long
short-term memory. in proc. of acl.

[gardner et al.2015] matt gardner, kejun huang, evan-
gelos papalexakis, xiao fu, partha talukdar, christos
faloutsos, nicholas sidiropoulos, and tom mitchell.
2015. translation invariant id27s.
in
proc. of emnlp.

[glorot and bengio2010] xavier glorot and yoshua ben-
gio. 2010. understanding the dif   culty of training
in proc. of ais-
deep feedforward neural networks.
tats.

[graves et al.2013] alan graves, abdel-rahman mo-
hamed, and geoffrey hinton. 2013. speech recog-
nition with deep recurrent neural networks. in proc.
of icassp.

[guo et al.2015] jiang guo, wanxiang che, david
yarowsky, haifeng wang, and ting liu. 2015. cross-
lingual id33 based on distributed rep-
resentations. in proc. of acl.

[guo et al.2016] jiang guo, wanxiang che, david
yarowsky, haifeng wang, and ting liu. 2016. a rep-
resentation learning framework for multi-source trans-
fer parsing. in proc. of aaai.

[heid and raab1989] ulrich heid and sybille raab.
in

1989. collocations in multilingual generation.
proc. of eacl.

[henderson and titov2010] james henderson and ivan
titov. 2010. incremental sigmoid belief networks for
grammar learning. journal of machine learning re-
search, 11:3541   3570.

[henderson2003] james henderson. 2003. inducing his-
tory representations for broad coverage statistical pars-
ing. in proc. of naacl-hlt.

[huang et al.2015] zhiheng huang, wei xu, and kai yu.
2015. bidirectional lstm-crf models for sequence
tagging. arxiv:1508.01991.

[hwa et al.2005] rebecca hwa, philip resnik, amy
weinberg, clara cabezas, and okan kolak. 2005.
id64 parsers via syntactic projection across
natural language engineering,
parallel
11(03):311   325.

texts.

[iyyer et al.2015] mohit iyyer, varun manjunatha, jor-
dan l. boyd-graber, and hal daum  . 2015. deep un-
ordered composition rivals syntactic methods for text
classi   cation. in proc. of acl.

[lui and baldwin2012] marco lui and timothy baldwin.
2012. langid.py: an off-the-shelf language identi   ca-
tion tool. in proc. of acl.

[ma and xia2014] xuezhe ma and fei xia. 2014. un-
supervised id33 with transferring dis-
tribution via parallel guidance and id178 regulariza-
tion. in proc. of acl.

[mcdonald et al.2011] ryan mcdonald, slav petrov, and
keith hall. 2011. multi-source transfer of delexical-
ized dependency parsers. in proc. of emnlp.

[mcdonald et al.2013] ryan mcdonald, joakim nivre,
yvonne quirmbach-brundage, yoav goldberg, di-
panjan das, kuzman ganchev, keith hall, slav petrov,
hao zhang, oscar t  ckstr  m, claudia bedini, n  ria
bertomeu castell  , and jungmee lee. 2013. univer-
sal dependency annotation for multilingual parsing. in
proc. of acl.

[mikolov et al.2013] tomas mikolov, kai chen, greg
corrado, and jeffrey dean. 2013. ef   cient estima-
tion of word representations in vector space. in proc.
of iclr.

[naseem et al.2012] tahira naseem, regina barzilay, and
amir globerson. 2012. selective sharing for multilin-
gual id33. in proc. of acl.

[nivre and nilsson2005] joakim nivre and jens nilsson.
in

pseudo-projective id33.

2005.
proc. of acl.

[nivre et al.2007] joakim nivre,

johan hall, sandra
kubler, ryan mcdonald, jens nilsson, sebastian
riedel, and deniz yuret. 2007. the conll 2007
in proc. of
shared task on id33.
conll.

[nivre et al.2015a] joakim nivre,   eljko agi  c, maria je-
sus aranzabe, masayuki asahara, aitziber atutxa,
miguel ballesteros, john bauer, kepa bengoetxea,
riyaz ahmad bhat, cristina bosco, sam bowman,
giuseppe g. a. celano, miriam connor, marie-
catherine de marneffe, arantza diaz de ilarraza, kaja
dobrovoljc, timothy dozat, toma   erjavec, rich  rd
farkas, jennifer foster, daniel galbraith, filip gin-
ter,
iakes goenaga, koldo gojenola, yoav gold-

berg, berta gonzales, bruno guillaume, jan ha-
ji  c, dag haug, radu ion, elena irimia, anders jo-
hannsen, hiroshi kanayama, jenna kanerva, simon
krek, veronika laippala, alessandro lenci, nikola
ljube  i  c, teresa lynn, christopher manning, c  at  alina
m  ar  anduc, david mare  cek, h  ctor mart  nez alonso,
jan ma  ek, yuji matsumoto, ryan mcdonald, anna
missil  , verginica mititelu, yusuke miyao, simon-
etta montemagni, shunsuke mori, hanna nurmi,
petya osenova, lilja   vrelid, elena pascual, marco
passarotti, cenel-augusto perez, slav petrov, jussi
piitulainen, barbara plank, martin popel, prokopis
prokopidis, sampo pyysalo, loganathan ramasamy,
rudolf rosa, shadi saleh, sebastian schuster, wolf-
gang seeker, mojgan seraji, natalia silveira, maria
simi, radu simionescu, katalin simk  , kiril simov,
aaron smith, jan   t  ep  nek, alane suhr, zsolt sz  nt  ,
takaaki tanaka, reut tsarfaty, sumire uematsu, lar-
raitz uria, viktor varga, veronika vincze, zden  ek
  abokrtsk  , daniel zeman, and hanzhi zhu. 2015a.
universal dependencies 1.2. lindat/clarin digi-
tal library at institute of formal and applied linguis-
tics, charles university in prague.

[nivre et al.2015b] joakim nivre, cristina bosco, jinho
choi, marie-catherine de marneffe, timothy dozat,
rich  rd farkas, jennifer foster, filip ginter, yoav
goldberg, jan haji  c, jenna kanerva, veronika laip-
pala, alessandro lenci, teresa lynn, christopher
manning, ryan mcdonald, anna missil  , simon-
etta montemagni, slav petrov, sampo pyysalo, na-
talia silveira, maria simi, aaron smith, reut tsarfaty,
veronika vincze, and daniel zeman. 2015b. uni-
versal dependencies 1.0. lindat/clarin digital li-
brary at institute of formal and applied linguistics,
charles university in prague.

[nivre2004] joakim nivre. 2004. incrementality in de-
in proceedings of
terministic id33.
the workshop on incremental parsing: bringing en-
gineering and cognition together.

[  stling2015] robert   stling. 2015. word order typol-
ogy through id73 alignment. in proc. of
acl-ijcnlp.

[petrov et al.2012] slav petrov, dipanjan das, and ryan
mcdonald. 2012. a universal part-of-speech tagset.
in proc. of lrec.

[rasooli and collins2015] mohammad sadegh rasooli
and michael collins. 2015. density-driven cross-
in proc. of
lingual transfer of dependency parsers.
emnlp.

[r  sner1988] deitmar r  sner.

the genera-
tion system of the semsyn project: towards a task-
independent generator for german. advances in natu-
ral language generation, 2.

1988.

[s  gaard et al.2015] anders s  gaard,   eljko agi  c, h  c-
tor mart  nez alonso, barbara plank, bernd bohnet,
and anders johannsen. 2015.
inverted indexing for
cross-lingual nlp. in proc. of acl-ijcnlp 2015.

[srivastava et al.2014] nitish srivastava, geoffrey hin-
ton, alex krizhevsky, ilya sutskever, and ruslan
salakhutdinov. 2014. dropout: a simple way to pre-
vent neural networks from over   tting. journal of ma-
chine learning research, 15(1):1929   1958.

[sutskever et al.2014] ilya sutskever, oriol vinyals, and
quoc v. le. 2014. sequence to sequence learning
with neural networks. in nips.

[t  ckstr  m et al.2012] oscar t  ckstr  m, ryan mcdon-
ald, and jakob uszkoreit. 2012. cross-lingual word
clusters for direct transfer of linguistic structure.
in
proc. of naacl-hlt.

[t  ckstr  m et al.2013] oscar t  ckstr  m, dipanjan das,
slav petrov, ryan mcdonald, and joakim nivre.
2013. token and type constraints for cross-lingual
part-of-speech tagging. transactions of the associa-
tion for computational linguistics, 1:1   12.

[tiedemann et al.2014] j  rg tiedemann, zeljko agic, and
joakim nivre. 2014. treebank translation for cross-
lingual parser induction. in proc. of conll.

[tiedemann2015] j  rg tiedemann. 2015. cross-lingual
id33 with universal dependencies and
predicted pos labels. in proc. of depling.

[titov and henderson2007] ivan titov and james hen-
derson. 2007. constituent parsing with incremental
sigmoid belief networks. in proc. of acl.

[vilares et al.2016] david vilares,

carlos g  mez-
rodr  guez, and miguel a. alonso.
2016. one
model, two languages: training bilingual parsers with
harmonized treebanks. arxiv:1507.08449v2.

[wikipedia2016] wikipedia.

2016. list of languages
by number of native speakers. http://bit.ly/
1lup5kj. accessed: 2016-01-26.

[xiao and guo2014] min xiao and yuhong guo. 2014.
distributed word representation learning for cross-
lingual id33. in proc. of conll.

[yarowsky et al.2001] david yarowsky, grace ngai, and
inducing multilingual
richard wicentowski. 2001.
text analysis tools via robust projection across aligned
corpora. in proc. of hlt.

[zeman and resnik2008] daniel zeman

and philip
2008. cross-language parser adaptation

resnik.
between related languages. in proc. of ijcnlp.

[zhang and barzilay2015] yuan zhang and regina barzi-
lay. 2015. hierarchical low-rank tensors for multilin-
gual transfer parsing. in proc. of emnlp.

