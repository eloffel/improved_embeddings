the expressive power of id27s

3
1
0
2

 

y
a
m
9
2

 

 
 
]

g
l
.
s
c
[
 
 

4
v
6
2
2
3

.

1
0
3
1
:
v
i
x
r
a

yanqing chen
bryan perozzi
rami al-rfou   
steven skiena
computer science dept. stony brook university stony brook, ny 11794

cyanqing@cs.stonybrook.edu
bperozzi@cs.stonybrook.edu
ralfrou@cs.stonybrook.edu
skiena@cs.stonybrook.edu

abstract

representations.

we seek to better understand the informa-
tion encoded in id27s. we pro-
pose several tasks that help to distinguish the
characteristics of di   erent publicly released
embeddings. our evaluation shows that em-
beddings are able to capture surprisingly nu-
anced semantics even in the absence of sen-
tence structure. moreover, benchmarking the
embeddings shows great variance in quality
and characteristics of the semantics captured
by the tested embeddings. finally, we show
the impact of varying the number of dimen-
sions and the resolution of each dimension on
the e   ective useful features captured by the
embedding space. our contributions high-
light the importance of embeddings for nlp
tasks and the e   ect of their quality on the
   nal results.

1. introduction

distributed word representations (embeddings) cap-
ture semantic and syntactic features of words out
of raw text corpus without human intervention or
language dependent processing. the features em-
bedding capture are task independent which make
them ideal for id38. however, em-
beddings are hard to interpret and understand. de-
spite the e   orts of visualizing the id27s
(van der maaten and hinton, 2008), points in high di-
mensional spaces carry a lot of information that is hard
to quantify. additionally, publicly available embed-
dings generated by multiple research groups use dif-
ferent data and training procedures and there is not
yet an understanding about the best way to learn these

proceedings of the 30 th international conference on ma-
chine learning, atlanta, georgia, usa, 2013.
jmlr:
w&cp volume 28. copyright 2013 by the author(s).

in this paper, we investigate four public released word
embeddings: (1) hlbl, (2) senna, (3) turian   s and
(4) huang   s. we use context-free classi   cation tasks
rather than sequence labeling tasks (such as part of
speech tagging) to isolate the e   ects of context in mak-
ing decisions and eliminate the complexity of the learn-
ing methods. speci   cally, our work makes the follow-
ing contributions:

    we show through evaluation that embeddings are
able to capture semantics in the absence of sen-
tence structure and that there is a di   erence in
the characteristics of the publicly released word
embeddings.

    we explore the impact of the number of dimen-
sions and the resolution of each dimension on the
quality of the information that can be encoded
in the embeddings space. that shows that mini-
mum e   ective space needed to capture the useful
information in the embeddings.

    we demonstrate the importance of word pair ori-
entation in encoding useful linguistic information.
we run two pair classi   cation tasks and provide
an example with one of them where pair perfor-
mance greatly exceeds that of individual words.

the rest of the work proceeds as follows: first we de-
scribe the id27s we consider. next we dis-
cuss our classi   cation experiments, and present their
results. finally we discuss the e   ects of scaling down
the size of the embeddings space.

2. related work

the original work for generating id27s was
presented by bengio et. al. in (bengio et al., 2003a).
the embeddings were a secondary output when gen-
erating language model. since (bengio et al., 2003a),

3 experimental setup

there has been a signi   cant interest in speeding up the
generation process (bengio et al., 2003b; 2009). these
original language models were evaluated using perplex-
ity. we argue that while perplexity is a good metric of
id38, it is not insightful about how well
the embeddings capture diverse types of information.

senna   s embeddings (collobert, 2011) are gener-
ated using a model that is discriminating and non-
probabilistic.
in each training update, we read an
id165 from the corpus, concatenating the learned
embeddings of these n words. then a corrupted n-
gram is used by replacing the word in the middle
with a random one from the vocabulary. on top of
the two phrases, the model learns a scoring function
that scores the original phrases lower than the cor-
rupted one. the id168 used for training is
hinge loss. (collobert et al., 2011) shows that embed-
dings are able to perform well on several nlp tasks
in the absence of any other features. the nlp tasks
considered by senna all consist of sequence labeling,
which imply that the model might learn from sequence
dependencies. our work enriches the discussion by fo-
cusing on term classi   cation problems.

in (turian et al., 2010), turian et. al. duplicated the
senna embeddings with some di   erences; they cor-
rupt the last word of each id165 instead of the word
in the middle. they also show that using embeddings
in conjunction with typical nlp features improves the
performance on the id39 task.
an additional result of (turian et al., 2010) shows that
most of the embeddings have similar e   ect when added
to an existing nlp task. this gives the wrong impres-
sion. our work illustrates that not all embeddings
are created equal and there are signi   cant di   erences
in the information captured by each publicly released
model exist.

mnih and hinton (mnih and hinton, 2007) proposed
a log-bilinear id168 to model language. given
an id165, the model concatenates the embeddings of
the n-1    rst words, and learns a linear model to predict
the embedding of the last word. mnih and hinton later
proposed hierarchical log-bilinear (hlbl) model em-
beddings (mnih and hinton, 2009) to speed up model
evaluation during training and testing by using a
hierarchical approach (similar to (morin and bengio,
2005)) that prune the search space for the next word
by dividing the prediction into a series of predictions
that    lter region of the space. the language model
eventually is evaluate using perplexity.

a fundamental challenge for neural language models
involves representing words which have multiple mean-
ings. in (huang et al., 2012), huang et. al. incorporate

2

global context to deal with challenges raised by words
with multiple meanings.

recent work by mikolov et. al. (mikolov et al., 2013)
investigates linguistic regularities captured by the rel-
ative positions of points in the embedding space. our
results regarding pair classi   cation are complemen-
tary.

3. experimental setup

we will construct three term classi   cation problems
and two pair classi   cation problems to quantify the
quality of the embeddings.

3.1. evaluation tasks

our evaluation tasks are as follows:

    sentiment polarity: we use lydia   s sentiment
lexicon (godbole et al., 2007) to create sets of
words which have positive or negative connota-
tions and construct the 2-class sentiment polarity
test. the data size is 6923 words.

    noun gender: we use bergsma   s dataset
(bergsma and lin, 2006) to compile a list of mas-
culine and feminine proper nouns. names that co-
refer more frequently with she/he are respectively
considered feminine/masculine. strings that co-
refer the most with it, appear less than 300 times
in the corpus, or consist of multiple words are ig-
nored. the total size is 2133 words.

    plurality: we use id138 (fellbaum, 2010) to
extract nouns in their singular and plural forms.
the data consists of 3012 words.

    synonyms and antonyms: we use word-
net to extract synonym and antonym pairs and
check whether we can part one kind from the
others. the relation is symmetric thus we put
each word pair together with their order-reversed-
counterparts. there are 3446 di   erent word pairs.

    regional spellings: we collect the words
that di   er in spelling between uk english and
the american counterpart from an online source
(limited, 2009). we make this task be a pair
classi   cation task to emphasize relative distances
between embeddings. we have 1565 pairs in this
task.

we ensure that for all tasks the class labels are bal-
anced. this allow our baseline evaluation to be either

3.3 classi   cation

3

sentiment

noun gender

plurality

3.3. classi   cation

samples

samples

positive negative feminine masculine plural singular
good
talent
amazing    aw

steve
roland
leonardo systems system

ada
irena
linda

bad
stupid

cats
tables

cat
table

synonyms and antonyms regional spellings
synonyms
store shop
virgin pure
permit license friend foe

antonyms
rear front
polite impolite driveable drivable
smash-up smashup

uk
colour

us
color

table 1. example input from each task

the random classi   er or the most frequent label clas-
si   er. either of them will give an accuracy of 50%.
table 1 shows examples of each of the 2-class evalua-
tion tasks. the classi   er is asked to identify which of
the classes a term or pair belongs to.

3.2. embeddings    datasets

for classi   cation we used id28 and a
id166 with the rbf-kernel as linear and non-linear
classi   ers. there is a model-selection procedure by
running a grid-search on the parameter space with
the help of the development data. all experiments
were written using the python package scikit-learn
(pedregosa et al., 2011). for the term classi   cation
tasks we o   ered the classi   er only the embedding of
the word as an input. for pairwise experiments, the
input consists of the embeddings of the two words con-
catenated.

the average of four folds of cross validation is used
to evaluate the performance of each classi   er on each
task. 50%, 25%, 25% of the data are used, as train-
ing, development and testing datasets respectively, for
evaluation and model selection.

we choose the following publicly available embeddings
datasets for evaluation.

4. evaluation results

    senna   s embeddings covers 130,000 words

with 50 dimensions for each word.

    turian   s embeddings covers 268,810 words,
each represented either with 25, 50 or 100 dimen-
sions.

    hlbl   s embeddings covers 246,122 words.
these embeddings were trained on same data used
for turian embedding for 100 epochs (7 days), and
have been induced in 50 or 100 dimensions.

    huang   s embeddings covers 100,232 words, in
50 dimensions. huang   s embeddings require con-
text to disambiguate which prototype to use for
a word. our tasks are context free so we average
the multiple prototypes to a single point in the
space. (this was the approach which worked best
in our testing.)

it should be emphasized that each of these models has
been induced under substantially di   erent training pa-
rameters. each model has its own vocabulary, used a
di   erent context size, and was trained for a di   erent
number of epochs on its training set. while the control
of these variables is outside the scope of this study, we
hope to mitigate one of these challenges by running our
experiments on the vocabulary shared by all these em-
beddings. the size of this shared vocabulary is 58,411
words.

here we present the evaluation of both our term and
pair classi   cation results.

4.1. term classi   cation

figure 1 shows the results over all the 2-class term
classi   cation tasks using id28 and rbf-
kernel id166. it is surprising that all the embeddings
we considered did much better than the baseline, even
on a seemingly hard tests like sentiment detection.
what   s more, there is strong performance from both
the senna and huang embeddings. senna embed-
dings seem to capture the plurality relationship better,
which may be from the emphasis that the senna em-
beddings place on shallow syntactic features.

y
c
a
r
u
c
c
a

1.0

0.9

0.8

0.7

0.6

0.5

0.4

sentiment

gender

plurality

senna
hlbl-50
hlbl-100

turian-25
turian-50

turian-100
huang

figure 1. results of the term-based tasks considered,
shaded areas represent improvements using kernel id166.

5

information reduction

table 2 shows examples of words from the test datasets
after classifying them using id28 on the
senna embeddings. the top and bottom rows show
the words that the classi   er is con   dent classifying,
while the rows in the middle show the words that lie
close to the decision boundary. for example, resilient
could have positive and negative connotations in text,
therefore, we    nd it close to the region were the words
are more neutral than being polarized.

for senna, the best performing task was the plural-
ity task. that explains the obvious contrast between
the probabilities given to the words. the top words are
given almost 100% id203 and the bottom ones
are given almost 0%. the results of regional spelling
task is shown here in the term-wise setup. despite not
performing as well as the pair-wise spelling, we can
see that classi   er shows meaningful results. we can
clearly notice that the british spellings of words favor
the usage of hyphens, s over z and ll over l.

t
n
e
m

i
t
n
e
s

positive
world-famous
award-winning
high-quality
achievement
athletic
resilient
ragged
discriminating
stout
lose
bored
bloodshed
burglary
robbery
panic
stone-throwing
negative

prob
99.85
99.83
99.83
99.81
99.81
50.14
50.11
50.10
49.97
49.83
49.81
0.74
0.68
0.58
0.45
0.28
1.0-prob

g
n
i
l
l
e
p
s

l
a
n
o
i
g
e
r

british
kick-o   
hauliers
re-exported
bullet-proof
initialled
paralysed
italicized
exorcise
fusing
lacklustre
subsidizing
signaling
hemorrhagic
tumor
homologue
localize
american

prob
92.37
91.54
89.46
88.69
88.42
50.16
50.04
50.03
49.90
49.78
49.77
32.04
21.69
21.69
19.53
17.50
1.0-prob

4

in our previous plurality test, the senna embed-
dings signi   cantly outperformed huang   s. however in
our regional spelling task (which might seem similar),
huang   s embeddings outperform senna in both term
and pair classi   cation setups. we believe that huang   s
approach for building word prototypes from signi   cant
di   erences in context provide a signi   cant advantage
on this task.

we note that it is surprising that neural language mod-
els may capture the relation between a synonym and
antonym. both the id38 of hlbl and
the way that senna/turian corrupted their exam-
ples favor words that can syntactically replace each
other; e.g. bad can replace good as easily as excellent
can. the result of this syntactic interchangeability is
that both bad and excellent are close to good in the
embedding space.

5. information reduction

distributed word representation exist in continuous
space, which is quite di   erent from common language
modeling techniques. beside the powerful expressive-
ness that we demonstrated previously, another key ad-
vantage of distributed representations is their size -
they require far less memory and disk storage than
other techniques.
in this section we seek to under-
stand exactly how much space id27s need
in order to serve as useful features. we also investigate
whether the powerful representation that embeddings
o   er is a result of having real value coordinates or the
exponential number of regions which can be described
using multiple independent dimensions.

table 2. examples of the results of the id28
classi   er on di   erent tasks.

5.1. bitwise truncation

4.2. pair classi   cation

sometimes however, the choice to use pair classi   ca-
tion can make quite a di   erence in the results. figure
2a shows that classifying individual words according to
their regional usage performs poorly. we can rede   ne
the problem such that the classi   er is asked to decide
if the    rst word, in a pair of words, is the american
spelling or not. figure 2a shows that performance im-
proves a lot. this hints that the words under this crite-
ria are not separable by a hyper-plane in any subspace
of the original embeddings space.
instead, we draw
a similar conclusion as (mikolov et al., 2013) that the
pairs    positions relative to each other is what encodes
such information but not their absolute coordinates,
and relationship between words often indicate the rel-
ative di   erence vector between corresponding points.

to reduce the resolution of the real numbers that make
up the embeddings matrix. first we scale them to 32
bit integer values, then we divide the values by 2b,
where b is the number of bits we wish to remove. fi-
nally, we scale the values back to lie between (   1, 1).
after this preprocessing we give the new values as fea-
tures to our classi   ers. in the extreme case, when we
truncate 31 bits, the values will be all either {1,    1}.

figure 3 shows that when we remove 31 bits (i.e, val-
ues are {1,    1}), the performance of an embedding
dataset drops no more than 7%. this reduced reso-
lution is equivalent to 250 regions which can be en-
coded in the new space. this is still a huge resolution,
but surprisingly seems to be su   cient at solving the
tasks we proposed. a na    ve approximation of this trick
which may be of interest is to simply take the the sign
of the embedding values as the representation of the

6 conclusion

5

y
c
a
r
u
c
c
a

y
c
a
r
u
c
c
a

1.0

0.9

0.8

0.7

0.6

0.5

0.4

1.0

0.9

0.8

0.7

0.6

0.5

0.4

spellings(term)

spellings(pair)

senna
hlbl-50
hlbl-100

turian-25
turian-50

turian-100
huang

(a) uk/us term vs. pair

synonym

spellings

senna
hlbl-50
hlbl-100

turian-25
turian-50

turian-100
huang

(b) 2-class pair results

figure 2. results of the pair-based tests. figure 2a shows
the di   erence between treating the uk/us spellings as a
single word problem, or using a pair of embeddings. figure
2b shows the results of the 2-class pair tests, shaded areas
represent improvements using kernel id166.

embeddings themselves.

5.2. principle component analysis

the bitwise truncation experiment indicates that the
number of dimensions could be a key factor into the
performance of the embeddings. to experiment on this
further, we run pca over the embeddings datasets to
evaluate task performance on a reduced number of di-
mensions. figure 4 shows that reducing the dimen-
sions drops the accuracy of the classi   ers signi   cantly
across all embedding datasets.

another key di   erence between the truncation exper-
iment and the pca experiment is that the trunca-
tion experiment may preserve relationships captured
by non-linearities in the embedding space. linear pca

0.90

0.85

0.80

0.75

0.70

0.65

0.60

0.55

0.50

y
c
a
r
u
c
c
a

1

2

4

8

12

16

bits remaining in each dimension.

senna

hlbl-50

turian-50

huang

figure 3. results of reducing the precision of the embed-
dings, averaged by the geometric mean of classi   ers. we
note that after removing 31 bits, each dimension of the
embeddings is a binary feature.

can not o   er such guarantees and this weakness may
contribute to the di   erence in performance.

0.90

0.85

0.80

0.75

0.70

0.65

0.60

0.55

0.50

y
c
a
r
u
c
c
a

1

2

3

5

10
dimensions

15

20 25

50

senna

hlbl-50

turian-50

huang

figure 4. results of reducing the dimensions of the embed-
dings through pca, averaged by the geometric mean.

6. conclusion

distributed word representations show a lot of promise
to improve supervised learning and semi-supervised
learning. the practical advantages of having dense
representations make them ideal for industrial appli-
cations and software development. the previous work
mainly focused on speeding up the training process
with one metric for evaluation, perplexity. we show
that this metric is not able to provide a nuanced view
of their quality. we develop a suite of linguistic ori-

references

ented tasks which might serve as a part of a com-
prehensive benchmark for id27 evaluation.
the tasks focus on words or pairs of them in isolation
to the actual text. the goal here is not to build a useful
classi   er as much as it is to understand how much su-
pervised learning can bene   t from the features which
are encoded in the embeddings.

we succeed in showing that the publicly available
datasets di   er in their quality and usefulness, and our
results are consistent across tasks and classi   ers. our
future work will try to address the factors that lead to
such diverse quality. the e   ect of training corpus size
and the choice of the objective functions are two main
areas where better understanding is needed.

while our tasks are simple, the di   erences among task
performance shed light on the features encoded by em-
beddings. we showed that in addition to the shallow
syntactic features like plural and gender agreement,
there are signi   cant semantic partitions regarding sen-
timent and synonym/antonym meaning. our current
tasks focus on nouns and adjectives, and the suite of
tasks has to be extended to include tasks that address
verbs and other parts of speech.

acknowledgments

this research was partially supported by nsf grants
dbi-1060572 and iis-1017181, with additional sup-
port from texeltek, inc.

references

y. bengio, r. ducharme, p. vincent, and c. jauvin.
a neural probabilistic language model. journal of
machine learning research, 3:1137   1155, 2003a.

y. bengio, j.s. sen  ecal, et al. quick training of proba-
bilistic neural nets by importance sampling. in ais-
tats conference, 2003b.

y. bengio, j. louradour, r. collobert, and j. weston.
curriculum learning. in proceedings of the 26th an-
nual international conference on machine learning,
pages 41   48. acm, 2009.

shane bergsma and dekang lin. id64 path-
based pronoun resolution. in proceedings of the 21st
international conference on computational lin-
guistics and 44th annual meeting of the association
for computational linguistics, pages 33   40, sydney,
australia, july 2006. association for computational
linguistics.

r. collobert. deep learning for e   cient discriminative

6

parsing.
intelligence and statistics (aistats), 2011.

in international conference on arti   cial

r. collobert, j. weston, l. bottou, m. karlen,
k. kavukcuoglu, and p. kuksa. natural language
processing (almost) from scratch. the journal of
machine learning research, 12:2493   2537, 2011,
jmlr. org.

c. fellbaum. id138. theory and applications of
ontology: computer applications, pages 231   243,
2010, springer.

n. godbole, m. srinivasaiah, and s. skiena. large-
scale id31 for news and blogs. in pro-
ceedings of the international conference on weblogs
and social media (icwsm), volume 2, 2007.

eric h. huang, richard socher, christopher d. man-
ning, and andrew y. ng. improving word represen-
tations via global context and multiple word pro-
totypes.
in proceedings of the 50th annual meet-
ing of the association for computational linguis-
tics: long papers - volume 1, acl    12, pages 873   
882, stroudsburg, pa, usa, 2012. association for
computational linguistics.

words worldwide limited.

word
us/uk spelling variants, may 2009.
http://www.wordsworldwide.co.uk/docs/words-worldwide-word-

of
url

list

tomas mikolov, wen-tau yih, and geo   rey zweig.
linguistic regularities in continuous space word rep-
resentations. in proceedings of naacl-hlt, 2013.

a. mnih and g. hinton. three new id114
for statistical language modelling. in proceedings of
the 24th international conference on machine learn-
ing, pages 641   648. acm, 2007.

a. mnih and g.e. hinton. a scalable hierarchical dis-
tributed language model. advances in neural in-
formation processing systems, 21:1081   1088, 2009,
citeseer.

f. morin and y. bengio. hierarchical probabilistic
neural network language model. in proceedings of
the international workshop on arti   cial intelligence
and statistics, pages 246   252, 2005.

f. pedregosa, g. varoquaux, a. gramfort, v. michel,
b. thirion, o. grisel, m. blondel, p. prettenhofer,
r. weiss, v. dubourg, j. vanderplas, a. pas-
sos, d. cournapeau, m. brucher, m. perrot, and
e. duchesnay. scikit-learn: machine learning in
python. journal of machine learning research, 12:
2825   2830, 2011.

references

j. turian, l. ratinov, and y. bengio. word repre-
sentations: a simple and general method for semi-
supervised learning. urbana, 51:61801, 2010.

l. van der maaten and g. hinton. visualizing data
using id167. journal of machine learning research,
9(2579-2605):85, 2008.

7

supplemental materials

supplemental materials

3-class tests

to strengthen these results, we performed a 3-class
version of the sentiment test, in which we evaluated
the ability to classify words as having positive, nega-
tive, or neutral sentiment value. the results are pre-
sented in figure 5. the results are consistent with
those from our 2-label test, and all embeddings per-
form much higher than the baseline score of 33%.

y
c
a
r
u
c
c
a

1.0

0.9

0.8

0.7

0.6

0.5

0.4

sentiment

3-sentment

senna
hlbl-50
hlbl-100

turian-25
turian-50

turian-100
huang

figure 5. the performance on the 3-class version of the
sentiment task, shaded areas represent improvements using
kernel id166.

in order to investigate the depth to which synonyms
and antonyms are captured, we conducted a 3-class
version of the same test. we now evaluate between
pairs of words that are synonyms, antonyms, or have
no such relation. while such a task is much harder for
the embeddings, the results in figure 6 show that a
nonlinear classi   er can capture the relationship, par-
ticularly with the senna embeddings. an analy-
sis of the confusion matrix for the nonlinear id166
showed that errors occurred roughly evenly between
the classes. we believe that this    nding regarding the
encoding of synonym/antonym relationships is an in-
teresting contribution of our work.

dimensional reduction by task

looking at figure 8a, reducing the words embeddings
to points on a real line almost deletes all the features
that are relevant to the pair classi   cation and to less
a degree the sentiment features. despite the 10%-20%
drop in accuracy in the plurality and gender tasks,
the classi   cation is still higher than random. the re-
sults show that when that shallow syntactic features
such as gender and number agreement are preserved at

8

y
c
a
r
u
c
c
a

1.0

0.9

0.8

0.7

0.6

0.5

0.4

synonym

3-synonym

senna
hlbl-50
hlbl-100

turian-25
turian-50

turian-100
huang

figure 6. the
syn-
onym/antonym task, shaded areas represent improvements
using kernel id166.

performance

3-class

the

of

0.90

0.85

0.80

0.75

0.70

0.65

0.60

0.55

0.50

y
c
a
r
u
c
c
a

1

2

4

8

bits remaining in each dimension.

12

16

spellings

synonym

gender

plural

sentiment

figure 7. results of reducing the precision of the embed-
dings, averaged by the geometric mean of classi   ers across-
ing tasks

the expense of more subtle semantic features such as
sentiment polarity. this gives us insight into what the
hierarchical structure of the embeddings space looks
like. shallow semantic features are present in all as-
pects of the space, and when pca chooses to maximize
this variance of the feature space it is at the expense
of the other semantic properties.

we also illustrate this phenomenon in figure 8b, by
showing how the performance of the linear and non-
linear classi   ers converge for our harder tasks (senti-
ment and synonym) as we reduce the number of di-
mensions with pca.

supplemental materials

9

0.90

0.85

0.80

0.75

0.70

0.65

0.60

0.55

0.50

y
c
a
r
u
c
c
a

0.90

0.85

0.80

0.75

0.70

y
c
a
r
u
c
c
a

0.65

0.60

0.55

0.50

1

2

3

5

10

dimensions

15

20

25

50

1

2

3

5

dimensions

10

15

20

25

50

spellings

synonym

gender

plural

sentiment

(a) by task

synonym (rbf)
plural (rbf)

sentiment (rbf)
synonym (linear)

plural (linear)
sentiment (linear)

(b) linear vs. nonlinear

figure 8. results of reducing the dimensions of the embeddings through pca, averaged by the geometric mean across
tasks (8a). figure 8b shows the di   erence between linear (dashed) and non-linear (solid) classi   ers for our harder tasks
(sentiment and synonym) and an easy task (plural). the performance of the linear and nonlinear classi   ers converges
as pca removes more dimensions. this results in signi   cantly degraded performance on nuanced tasks like sentiment
analysis.

this figure "bit_reduction_by_embedding_after_id172.png" is available in "png"(cid:10) format from:

http://arxiv.org/ps/1301.3226v4

this figure "bit_reduction_by_task_after_id172.png" is available in "png"(cid:10) format from:

http://arxiv.org/ps/1301.3226v4

