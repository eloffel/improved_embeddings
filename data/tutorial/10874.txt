id62 with memory-augmented neural networks

6
1
0
2

 

y
a
m
9
1

 

 
 
]

g
l
.
s
c
[
 
 

1
v
5
6
0
6
0

.

5
0
6
1
:
v
i
x
r
a

adam santoro
google deepmind
sergey bartunov
google deepmind, national research university higher school of economics (hse)
matthew botvinick
daan wierstra
timothy lillicrap
google deepmind

adamsantoro@google.com

sbos@sbos.in

botvinick@google.com
wierstra@google.com
countzero@google.com

abstract

despite recent breakthroughs in the applications
of deep neural networks, one setting that presents
a persistent challenge is that of    one-shot learn-
ing.    traditional gradient-based networks require
a lot of data to learn, often through extensive it-
erative training. when new data is encountered,
the models must inef   ciently relearn their param-
eters to adequately incorporate the new informa-
tion without catastrophic interference. architec-
tures with augmented memory capacities, such as
id63s (ntms), offer the abil-
ity to quickly encode and retrieve new informa-
tion, and hence can potentially obviate the down-
sides of conventional models. here, we demon-
strate the ability of a memory-augmented neu-
ral network to rapidly assimilate new data, and
leverage this data to make accurate predictions
after only a few samples. we also introduce a
new method for accessing an external memory
that focuses on memory content, unlike previous
methods that additionally use memory location-
based focusing mechanisms.

1. introduction
the current success of deep learning hinges on the abil-
ity to apply gradient-based optimization to high-capacity
models. this approach has achieved impressive results on
many large-scale supervised tasks with raw sensory input,
such as image classi   cation (he et al., 2015), speech recog-
nition (yu & deng, 2012), and games (mnih et al., 2015;
silver et al., 2016). notably, performance in such tasks is
typically evaluated after extensive, incremental training on
large data sets. in contrast, many problems of interest re-

quire rapid id136 from small quantities of data. in the
limit of    id62,    single observations should re-
sult in abrupt shifts in behavior.
this kind of    exible adaptation is a celebrated aspect of hu-
man learning (jankowski et al., 2011), manifesting in set-
tings ranging from motor control (braun et al., 2009) to the
acquisition of abstract concepts (lake et al., 2015). gener-
ating novel behavior based on id136 from a few scraps
of information     e.g., inferring the full range of applicabil-
ity for a new word, heard in only one or two contexts     is
something that has remained stubbornly beyond the reach
of contemporary machine intelligence. it appears to present
a particularly daunting challenge for deep learning. in sit-
uations when only a few training examples are presented
one-by-one, a straightforward gradient-based solution is to
completely re-learn the parameters from the data available
at the moment. such a strategy is prone to poor learning,
and/or catastrophic interference. in view of these hazards,
non-parametric methods are often considered to be better
suited.
however, previous work does suggest one potential strat-
egy for attaining rapid learning from sparse data, and
hinges on the notion of meta-learning (thrun, 1998; vi-
lalta & drissi, 2002). although the term has been used
in numerous senses (schmidhuber et al., 1997; caruana,
1997; schweighofer & doya, 2003; brazdil et al., 2003),
meta-learning generally refers to a scenario in which an
agent learns at two levels, each associated with different
time scales. rapid learning occurs within a task, for ex-
ample, when learning to accurately classify within a par-
ticular dataset. this learning is guided by knowledge
accrued more gradually across tasks, which captures the
way in which task structure varies across target domains
(giraud-carrier et al., 2004; rendell et al., 1987; thrun,
1998). given its two-tiered organization, this form of meta-

id62 with memory-augmented neural networks

learning is often described as    learning to learn.   
it has been proposed that neural networks with mem-
ory capacities could prove quite capable of meta-learning
(hochreiter et al., 2001). these networks shift their bias
through weight updates, but also modulate their output by
learning to rapidly cache representations in memory stores
(hochreiter & schmidhuber, 1997). for example, lstms
trained to meta-learn can quickly learn never-before-seen
quadratic functions with a low number of data samples
(hochreiter et al., 2001).
neural networks with a memory capacity provide a promis-
ing approach to meta-learning in deep networks. however,
the speci   c strategy of using the memory inherent in un-
structured recurrent architectures is unlikely to extend to
settings where each new task requires signi   cant amounts
of new information to be rapidly encoded. a scalable so-
lution has a few necessary requirements: first, information
must be stored in memory in a representation that is both
stable (so that it can be reliably accessed when needed) and
element-wise addressable (so that relevant pieces of infor-
mation can be accessed selectively). second, the number
of parameters should not be tied to the size of the mem-
ory. these two characteristics do not arise naturally within
standard memory architectures, such as lstms. how-
ever, recent architectures, such as id63s
(ntms) (graves et al., 2014) and memory networks (we-
ston et al., 2014), meet the requisite criteria. and so, in this
paper we revisit the meta-learning problem and setup from
the perspective of a highly capable memory-augmented
neural network (mann) (note: here on, the term mann
will refer to the class of external-memory equipped net-
works, and not other    internal    memory-based architec-
tures, such as lstms).
we demonstrate that manns are capable of meta-learning
in tasks that carry signi   cant short- and long-term mem-
ory demands. this manifests as successful classi   cation
of never-before-seen omniglot classes at human-like accu-
racy after only a few presentations, and principled function
estimation based on a small number of samples. addition-
ally, we outline a memory access module that emphasizes
memory access by content, and not additionally on mem-
ory location, as in original implementations of the ntm
(graves et al., 2014). our approach combines the best of
two worlds: the ability to slowly learn an abstract method
for obtaining useful representations of raw data, via gra-
dient descent, and the ability to rapidly bind never-before-
seen information after a single presentation, via an external
memory module. the combination supports robust meta-
learning, extending the range of problems to which deep
learning can be effectively applied.

2. meta-learning task methodology
usually, we try to choose parameters    to minimize a learn-
ing cost l across some dataset d. however, for meta-
learning, we choose parameters to reduce the expected
learning cost across a distribution of datasets p(d):

      = argmin  ed   p(d)[l(d;   )].

(1)

to accomplish this, proper task setup is critical (hochre-
iter et al., 2001).
in our setup, a task, or episode, in-
volves the presentation of some dataset d = {dt}t
t=1 =
{(xt, yt)}t
t=1. for classi   cation, yt is the class label for
an image xt, and for regression, yt is the value of a hid-
den function for a vector with real-valued elements xt, or
simply a real-valued number xt (here on, for consistency,
xt will be used).
in this setup, yt is both a target, and
is presented as input along with xt, in a temporally off-
set manner; that is, the network sees the input sequence
(x1, null), (x2, y1), . . . , (xt , yt   1). and so, at time t the
correct label for the previous data sample (yt   1) is pro-
vided as input along with a new query xt (see figure 1 (a)).
the network is tasked to output the appropriate label for
xt (i.e., yt) at the given timestep. importantly, labels are
shuf   ed from dataset-to-dataset. this prevents the network
from slowly learning sample-class bindings in its weights.
instead, it must learn to hold data samples in memory un-
til the appropriate labels are presented at the next time-
step, after which sample-class information can be bound
and stored for later use (see figure 1 (b)). thus, for a given
episode, ideal performance involves a random guess for the
   rst presentation of a class (since the appropriate label can
not be inferred from previous episodes, due to label shuf-
   ing), and the use of memory to achieve perfect accuracy
thereafter. ultimately, the system aims at modelling the
predictive distribution p(yt|xt, d1:t   1;   ), inducing a cor-
responding loss at each time step.
this
exploitable meta-
knowledge: a model that meta-learns would learn to bind
data representations to their appropriate labels regardless
of the actual content of the data representation or label,
and would employ a general scheme to map these bound
representations to appropriate classes or function values
for prediction.

task structure

incorporates

3. memory-augmented model
3.1. id63s

the id63 is a fully differentiable imple-
mentation of a mann. it consists of a controller, such as
a feed-forward network or lstm, which interacts with an
external memory module using a number of read and write
heads (graves et al., 2014). memory encoding and retrieval
in a ntm external memory module is rapid, with vector

id62 with memory-augmented neural networks

(a) task setup

(b) network strategy

figure 1. task structure. (a) omniglot images (or x-values for regression), xt, are presented with time-offset labels (or function values),
yt   1, to prevent the network from simply mapping the class labels to the output. from episode to episode, the classes to be presented
in the episode, their associated labels, and the speci   c samples are all shuf   ed. (b) a successful strategy would involve the use of an
external memory to store bound sample representation-class label information, which can then be retrieved at a later point for successful
classi   cation when a sample from an already-seen class is presented. speci   cally, sample data xt from a particular time step should be
bound to the appropriate class label yt, which is presented in the subsequent time step. later, when a sample from this same class is
seen, it should retrieve this bound information from the external memory to make a prediction. backpropagated error signals from this
prediction step will then shape the weight updates from the earlier steps in order to promote this binding strategy.

representations being placed into or taken out of memory
potentially every time-step. this ability makes the ntm
a perfect candidate for meta-learning and low-shot predic-
tion, as it is capable of both long-term storage via slow up-
dates of its weights, and short-term storage via its exter-
nal memory module. thus, if a ntm can learn a general
strategy for the types of representations it should place into
memory and how it should later use these representations
for predictions, then it may be able use its speed to make
accurate predictions of data that it has only seen once.
the controllers employed in our model are are either
lstms, or feed-forward networks. the controller inter-
acts with an external memory module using read and write
heads, which act to retrieve representations from memory
or place them into memory, respectively. given some in-
put, xt, the controller produces a key, kt, which is then
either stored in a row of a memory matrix mt, or used to
retrieve a particular memory, i, from a row; i.e., mt(i).
when retrieving a memory, mt is addressed using the co-
sine similarity measure,

which is used to produce a read-weight vector, wr
elements computed according to a softmax:

t , with

kt    mt(i)

(cid:107) kt (cid:107)(cid:107) mt(i) (cid:107) ,

k(cid:0)kt, mt(i)(cid:1) =
t (i)     exp(cid:0)k(cid:0)kt, mt(i)(cid:1)(cid:1)
j exp(cid:0)k(cid:0)kt, mt(j)(cid:1)(cid:1) .
(cid:80)
rt    (cid:88)

t (i)mt(i).

wr

wr

i

(2)

(3)

(4)

a memory, rt, is retrieved using this weight vector:

this memory is used by the controller as the input to a clas-
si   er, such as a softmax output layer, and as an additional
input for the next controller state.

3.2. least recently used access

in previous instantiations of the ntm (graves et al., 2014),
memories were addressed by both content and location.
location-based addressing was used to promote iterative
steps, akin to running along a tape, as well as long-distance
jumps across memory. this method was advantageous for
sequence-based prediction tasks. however, this type of ac-
cess is not optimal for tasks that emphasize a conjunctive
coding of information independent of sequence. as such,
writing to memory in our model involves the use of a newly
designed access module called the least recently used
access (lrua) module.
the lrua module is a pure content-based memory writer
that writes memories to either the least used memory lo-
cation or the most recently used memory location. this
module emphasizes accurate encoding of relevant (i.e., re-
cent) information, and pure content-based retrieval. new
information is written into rarely-used locations, preserv-
ing recently encoded information, or it is written to the
last used location, which can function as an update of the
memory with newer, possibly more relevant information.
the distinction between these two options is accomplished
with an interpolation between the previous read weights
and weights scaled according to usage weights wu
t . these
usage weights are updated at each time-step by decaying
the previous usage weights and adding the current read and

id62 with memory-augmented neural networks

write weights:

t       wu
wu

t   1 + wr

t + ww
t .

(5)

(cid:26) 0

1

t is computed as in (3).
here,    is a decay parameter and wr
the least-used weights, wlu
t , for a given time-step can then
be computed using wu
t . first, we introduce the notation
m(v, n) to denote the nth smallest element of the vector v.
elements of wlu

t are set accordingly:

wlu

t (i) =

if wu
if wu

t (i) > m(wu
t (i)     m(wu

t , n)
t , n)

,

(6)

where n is set to equal the number of reads to memory.
to obtain the write weights ww
t , a learnable sigmoid gate
parameter is used to compute a convex combination of the
previous read weights and previous least-used weights:

t       (  )wr
ww

t   1 + (1       (  ))wlu
t   1.

(7)

1

here,   (  ) is a sigmoid function,
1+e   x , and    is a scalar
gate parameter to interpolate between the weights. prior
to writing to memory, the least used memory location is
computed from wu
t   1 and is set to zero. writing to mem-
ory then occurs in accordance with the computed vector of
write weights:

mt(i)     mt   1(i) + ww

t (i)kt,   i

(8)

thus, memories can be written into the zeroed memory slot
or the previously used slot; if it is the latter, then the least
used memories simply get erased.

4. experimental results
4.1. data

two sources of data were used: omniglot, for classi   ca-
tion, and sampled functions from a gaussian process (gp)
with    xed hyperparameters, for regression. the omniglot
dataset consists of over 1600 separate classes with only a
few examples per class, aptly lending to it being called the
transpose of mnist (lake et al., 2015). to reduce the
risk of over   tting, we performed data augmentation by ran-
domly translating and rotating character images. we also
created new classes through 90   , 180    and 270    rotations
of existing data. the training of all models was performed
on the data of 1200 original classes (plus augmentations),
with the rest of the 423 classes (plus augmentations) being
used for test experiments. in order to reduce the computa-
tional time of our experiments we downscaled the images
to 20    20.

4.2. omniglot classi   cation

we performed a number of iterations of the basic task de-
scribed in section 2. first, our mann was trained using

one-hot vector representations as class labels (figure 2).
after training on 100,000 episodes with    ve randomly cho-
sen classes with randomly chosen labels, the network was
given a series of test episodes. in these episodes, no further
learning occurred, and the network was to predict the class
labels for never-before-seen classes pulled from a disjoint
test set from within omniglot. the network exhibited high
classi   cation accuracy on just the second presentation of a
sample from a class within an episode (82.8%), reaching up
to 94.9% accuracy by the    fth instance and 98.1% accuracy
by the tenth.
for classi   cation using one-hot vector representations, one
relevant baseline is human performance. participants were
   rst given instructions detailing the task: an image would
appear, and they must choose an appropriate digit label
from the integers 1 through 5. next, the image was pre-
sented and they were to make an un-timed prediction as
to its class label. the image then disappeared, and they
were given visual feedback as to their correctness, along
with the correct label. the correct label was presented re-
gardless of the accuracy of their prediction, allowing them
to further reinforce correct decisions. after a short delay
of two seconds, a new image appeared and they repeated
the prediction process. the participants were not permitted
to view previous images, or to use a scratch pad for ex-
ternalization of memory. performance of the mann sur-
passed that of a human on each instance. interestingly, the
mann displayed better than random guessing on the    rst
instance within a class. seemingly, it employed a strategy
of educated guessing; if a particular sample produced a key
that was a poor match to any of the bindings stored in ex-
ternal memory, then the network was less likely to choose
the class labels associated with these stored bindings, and
hence increased its id203 of correctly guessing this
new class on the    rst instance. a similar strategy was re-
ported qualitatively by the human participants. we were
unable to accumulate an appreciable amount of data from
participants on the    fteen class case, as it proved much too
dif   cult and highly demotivating. for all intents and pur-
poses, as the number of classes scale to    fteen and beyond,
this type of binding surpasses human working memory ca-
pacity, which is limited to storing only a handful of arbi-
trary bindings (cowan, 2010).
since learning the weights of a classi   er using large one-
hot vectors becomes increasingly dif   cult with scale, a dif-
ferent approach for labeling classes was employed so that
the number of classes presented in a given episode could be
arbitrarily increased. these new labels consisted of strings
of    ve characters, with each character assuming one of    ve
possible values. characters for each label were uniformly
sampled from the set {   a   ,    b   ,    c   ,    d   ,    e   }, producing ran-
dom strings such as    ecdba   . strings were represented as
concatenated one-hot vectors, and hence were of length 25

id62 with memory-augmented neural networks

(a) lstm,    ve random classes/episode, one-hot vector labels

(b) mann,    ve random classes/episode, one-hot vector labels

(c) lstm,    fteen classes/episode,    ve-character string labels

(d) mann,    fteen classes/episode,    ve-character string labels

figure 2. omniglot classi   cation. the network was given either    ve (a-b) or up to    fteen (c-d) random classes per episode, which were
of length 50 or 100 respectively. labels were one-hot vectors in (a-b), and    ve-character strings in (c-d). in (b),    rst instance accuracy is
above chance, indicating that the mann is performing    educated guesses    for new classes based on the classes it has already seen and
stored in memory. in (c-d),    rst instance accuracy is poor, as is expected, since it must make a guess from 3125 random strings. second
instance accuracy, however, approaches 80% during training for the mann (d). at the 100,000 episode mark the network was tested,
without further learning, on distinct classes withheld from the training set, and exhibited comparable performance.

table 1. test-set classi   cation accuracies for humans compared to
machine algorithms trained on the omniglot dataset, using one-
hot encodings of labels and    ve classes presented per episode.

model

human
feedforward
lstm
mann

1st

34.5
24.4
24.4
36.4

instance (% correct)
5th
2nd

3rd

4th

57.3
19.6
49.5
82.8

70.1
21.1
55.3
91.0

71.8
19.9
61.0
92.6

81.4
22.8
63.6
94.9

10th

92.4
19.5
62.5
98.1

with    ve elements assuming a value of 1, and the rest 0.
this combinatorial approach allows for 3125 possible la-
bels, which is nearly twice the number of classes in the
dataset. therefore, the id203 that a given class as-
sumed the same label in any two episodes throughout train-
ing was greatly reduced. this also meant, however, that the
guessing strategy exhibited by the network for the    rst in-
stance of a particular class within an episode would prob-

ably be abolished. nonetheless, this method allowed for
episodes containing a large number of unique classes.
to con   rm that the network was able to learn using these
class representations, the previously described experiment
was repeated (see table 2). notably, a mann with a stan-
dard ntm access module was unable to reach comparable
performance to a mann with lru access. given this
success, the experiment was scaled to up to    fteen unique
classes presented in episodes of length 100, with the net-
work exhibiting similar performance.
we considered a set of baselines, such as a feed-forward
id56, lstm, and a nonparametric nearest neighbours clas-
si   er that used either raw-pixel input or features extracted
by an autoencoder. the autoencoder consisted of an en-
coder and decoder each with two 200-unit layers with leaky
relu activations, and an output bottleneck layer of 32
units. the resultant architecture contained signi   cantly
more parameters than the mann and, additionally, was

id62 with memory-augmented neural networks

allowed to train on three times as much augmented data.
the highest accuracies from our experiments are reported,
which were achieved using a single nearest neighbour for
prediction and features from the output bottleneck layer of
the autoencoder. importantly, the nearest neighbour classi-
   er had an unlimited amount of memory, and could auto-
matically store and retrieve all previously seen examples.
this provided the knn with an distinct advantage, even
when raw pixels were used as input representations. al-
though using rich features extracted by the autoencoder fur-
ther improved performance, the knn baseline was clearly
outperformed by the mann.

4.2.1. persistent memory interference

a good strategy to employ in this classi   cation task, and
the strategy that was arti   cially imposed thus-far, is to wipe
the external memory from episode to episode. since each
episode contains unique classes, with unique labels, any in-
formation persisting in memory across episodes inevitably
acts as interference for the episode at hand. to test the
effects of memory interference, we performed the classi   -
cation task without wiping the external memory between
episodes.
this task proved predictably dif   cult, and the network
was less robust in its ability to achieve accurate classi-
   cation (figure 3). for example, in the case of learn-
ing one-hot vector labels in an episode that contained    ve
unique classes, learning progressed much slower than in
the memory-wipe condition, and did not produce the char-
acteristic fast spike in accuracy seen in the memory-wipe
condition (figure 2). interestingly, there were conditions
in which learning was not compromised appreciably.
in
the case of learning ten unique classes in episodes of length
75, for example, classi   cation accuracy reached compara-
ble levels. exploring the requirements for robust perfor-
mance is a topic of future work.

4.2.2. curriculum training

given the successful one-shot classi   cation in episodes
with    fteen classes, we employed a curriculum training
regime to further scale the classi   cation capabilities of the
model. the network was    rst tasked to classify    fteen
classes per episode, and every 10,000 episodes of train-
ing thereafter, the maximum number of classes presented
per episode incremented by one (figure 4). the network
maintained a high level of accuracy even as the number
of classes incremented higher throughout training. after
training, at the 100,000 episode mark, the network was
tested on episodes with 50 classes. similar tests contin-
ued, increasing the maximum number of classes to 100.
the network generally exhibited gradually decaying per-
formance as the number of classes increased towards 100.

(a) five classes per episode

(b) ten classes per episode

figure 3. persistent memory. to test the effects of interference,
we did not wipe the external memory store from episode-to-
episode. the network indeed struggled in this task (a), but
nonetheless was able to perform comparably under certain setups,
such as when episodes included ten classes and were of length 75
(b).

the training limit of the network seemed to have not been
reached, as its performance continued to rise throughout up
until the 100,000 episode mark. assessing the maximum
capacity of the network offers an interesting opportunity
for future work.

4.3. regression

since our mann architecture generated a broad strategy
for meta-learning, we reasoned that it would be able to
adequately perform regression tasks on never-before-seen
functions. to test this, we generated functions using from
a gp prior with a    xed set of hyper-parameters and trained
our network using unique functions in each episode. each
episode involved the presentation of x-values (either 1, 2,
or 3-dimensional) along with time-offset function values
(i.e., f (xt   1)). a successful strategy involves the binding
of x-values with the appropriate function values and stor-
age of these bindings in the external memory. since indi-
vidual x-values were only presented once per episode, suc-
cessful function prediction involved an accurate content-

id62 with memory-augmented neural networks

(a) mann predictions along all x-inputs after 20 samples

(a) one additional class per 10,000 episodes

figure 4. curriculum classi   cation. the network started with
episodes that included up to 15 unique classes, and every 10,000
episodes this maximum was raised by one. episode lengths were
scaled to a value ten times the max number of classes. at the
100,000 episode mark (when the number of classes reached 25)
the network was tested on episodes with up to 50 unique classes,
which incremented to 100 in steps of    ve.

based look-up of proximal information in memory. thus,
unlike in the image-classi   cation scenario, this task de-
mands a broader read from memory:
the network must
learn to interpolate from previously seen points, which
most likely involves a strategy to have a more blended read-
out from memory. such an interpolation strategy in the im-
age classi   cation scenario is less obvious, and probably not
necessary.
network performance was compared to true gp predictions
of samples presented in the same order as was seen by the
network.
importantly, a gp is able to perform complex
queries over all data points (such as covariance matrix in-
version) in one step. in contrast, a mann can only make
local updates to its memory, and hence can only approxi-
mate such functionality. in our experiments, the gp was
initiated with the correct hyper-parameters for the sampled
function, giving it an advantage in function prediction. as
seen in figure 5, the mann predictions track the underly-
ing function, with its output variance increasing as it pre-
dicts function values that are distance from the values it has
already received.
these results were extended to 2-dimensional and 3-
dimensional cases (fig 6), with the gp again having ac-
cess to the correct hyper-parameters for the sampled func-
tions. in both the 2-dimensional and 3-dimensional cases,
the log-likelihood predictions of the mann tracks appre-
ciably well versus the gp, with predictions becoming more
accurate as samples are stored in the memory.

(b) gp predictions along all x-inputs after 20 samples

figure 5. regression. the network received data samples that
were x-values for a function sampled from a gp with    xed hy-
perparameters, and the labels were the associated function values.
(a) shows the mann   s predictions for all x-values after observ-
ing 20 samples, and (b) shows the same for a gp with access to
the same hyper-parameters used to generate the function.

5. discussion & future work
many important learning problems demand an ability to
draw valid id136s from small amounts of data, rapidly
and knowledgeably adjusting to new information. such
problems pose a particular challenge for deep learning,
which typically relies on slow,
incremental parameter
changes. we investigated an approach to this problem
based on the idea of meta-learning. here, gradual, incre-
mental learning encodes background knowledge that spans
tasks, while a more    exible memory resource binds infor-
mation particular to newly encountered tasks. our central
contribution is to demonstrate the special utility of a par-
ticular class of manns for meta-learning. these are deep-
learning architectures containing a dedicated, addressable
memory resource that is structurally independent from the
mechanisms that implement process control. the mann
examined here was found to display performance superior
to a lstm in two meta-learning tasks, performing well in
classi   cation and regression tasks when only sparse train-
ing data was available.
a critical aspect of the tasks studied is that they cannot
be performed based solely on rote memory. new infor-
mation must be    exibly stored and accessed, with correct
performance demanding more than just accurate retrieval.
speci   cally, it requires that id136s be drawn from new
data based on longer-term experience, a faculty sometimes
referred as    inductive transfer.    manns are well-suited to
meet these dual challenges, given their combination of    ex-
ible memory storage with the rich capacity of deep archi-

id62 with memory-augmented neural networks

table 2. test-set classi   cation accuracies for various architectures on the omniglot dataset after 100000 episodes of training, using    ve-
character-long strings as labels. see the supplemental information for an explanation of 1st instance accuracies for the knn classi   er.

model

controller

# of classes

knn (raw pixels)
knn (deep features)
feedforward
lstm
mann
mann

knn (raw pixels)
knn (deep features)
feedforward
lstm
mann (lrua)
mann (lrua)
mann (ntm)

   
   
   
   
feedforward
lstm

   
   
   
   
feedforward
lstm
lstm

5
5
5
5
5
5

15
15
15
15
15
15
15

1st

4.0
4.0
0.0
0.0
0.0
0.0

0.5
0.4
0.0
0.0
0.1
0.1
0.0

instance (% correct)
5th

3rd

4th

2nd

36.7
51.9
0.2
9.0
8.0
69.5

18.7
32.7
0.1
2.2
12.8
62.6
35.4

41.9
61.0
0.0
14.2
16.2
80.4

23.3
41.2
0.0
2.9
22.3
79.3
61.2

45.7
66.3
0.2
16.9
25.2
87.9

26.5
47.1
0.0
4.3
28.8
86.6
71.7

48.1
69.3
0.0
21.8
30.9
88.4

29.1
50.6
0.0
5.6
32.2
88.7
77.7

10th

57.0
77.5
0.0
25.5
46.8
93.1

37.0
60.0
0.0
12.7
43.4
95.3
88.4

tectures for representation learning.
meta-learning is recognized as a core ingredient of hu-
man intelligence, and an essential test domain for evaluat-
ing models of human cognition. given recent successes in
modeling human skills with deep networks, it seems worth-
while to ask whether manns embody a promising hypoth-
esis concerning the mechanisms underlying human meta-
learning. in informal comparisons against human subjects,
the mann employed in this paper displayed superior per-
formance, even at set-sizes that would not be expected to
overtax human working memory capacity. however, when
memory is not cleared between tasks, the mann suffers
from proactive interference, as seen in many studies of hu-
man memory and id136 (underwood, 1957). these
preliminary observations suggest that manns may pro-
vide a useful heuristic model for further investigation into
the computational basis of human meta-learning.
the work we presented leaves several clear openings for
next-stage development. first, our experiments employed
a new procedure for writing to memory that was prima fa-
cie well suited to the tasks studied. it would be interesting
to consider whether meta-learning can itself discover opti-
mal memory-addressing procedures. second, although we
tested manns in settings where task parameters changed
across episodes, the tasks studied contained a high degree
of shared high-level structure. training on a wider range
of tasks would seem likely to reintroduce standard chal-
lenges associated with continual learning, including the
risk of catastrophic interference. finally, it may be of inter-
est to examine mann performance in meta-learning tasks
requiring active learning, where observations must be ac-
tively selected.

(a) 2d regression log-likelihoods within an episode

(b) 3d regression log-likelihoods within an episode

figure 6. multi-dimensional regression. (a) shows the negative
log likelihoods for 2d samples within a single episode, averaged
across 100 episodes, while (b) shows the same for 3d samples.

id62 with memory-augmented neural networks

6. acknowledgements
the authors would like to thank ivo danihelka and greg
wayne for helpful discussions and prior work on the ntm
and lru access architectures, as well as yori zwols,
and many others at google deepmind for reviewing the
manuscript.

id62 with memory-augmented neural networks

schmidhuber, j  urgen, zhao, jieyu, and wiering, marco.
shifting inductive bias with success-story algo-
rithm, adaptive levin search, and incremental self-
machine learning, 28(1):105   130,
improvement.
1997.

schweighofer, nicolas and doya, kenji. meta-learning
in id23. neural networks, 16(1):5   9,
2003.

silver, david, huang, aja, maddison, chris j, guez,
arthur, sifre, laurent, van den driessche, george,
schrittwieser, julian, antonoglou, ioannis, panneershel-
vam, veda, lanctot, marc, et al. mastering the game of
go with deep neural networks and tree search. nature,
529(7587):484   489, 2016.

thrun, sebastian. lifelong learning algorithms. in learn-

ing to learn, pp. 181   209. springer, 1998.

underwood, benton j.

interference and forgetting. psy-

chological review, 64(1):49, 1957.

vilalta, ricardo and drissi, youssef. a perspective view
and survey of meta-learning. arti   cial intelligence re-
view, 18(2):77   95, 2002.

weston, jason, chopra, sumit, and bordes, antoine. mem-

ory networks. arxiv preprint arxiv:1410.3916, 2014.

yu, dong and deng, li. automatic id103.

springer, 2012.

references
braun, daniel a, aertsen, ad, wolpert, daniel m, and
mehring, carsten. motor task variation induces struc-
tural learning. current biology, 19(4):352   357, 2009.

brazdil, pavel b, soares, carlos,

and da costa,
joaquim pinto. ranking learning algorithms: using ibl
and meta-learning on accuracy and time results. machine
learning, 50(3):251   277, 2003.

caruana, rich. multitask learning. machine learning, 28

(1):41   75, 1997.

cowan, nelson. the magical mystery four how is working
memory capacity limited, and why? current directions
in psychological science, 19(1):51   57, 2010.

giraud-carrier, christophe, vilalta, ricardo, and brazdil,
pavel. introduction to the special issue on meta-learning.
machine learning, 54(3):187   193, 2004.

graves, alex, wayne, greg, and danihelka, ivo. neural
turing machines. arxiv preprint arxiv:1410.5401, 2014.

he, kaiming, zhang, xiangyu, ren, shaoqing, and sun,
jian. delving deep into recti   ers: surpassing human-
arxiv
level performance on id163 classi   cation.
preprint arxiv:1502.01852, 2015.

hochreiter, sepp and schmidhuber, j  urgen. long short-
term memory. neural computation, 9(8):1735   1780,
1997.

hochreiter, sepp, younger, a steven, and conwell, pe-
ter r. learning to learn using id119. in arti   -
cial neural networksicann 2001, pp. 87   94. springer,
2001.

jankowski, norbert, duch, w  odzis  aw, and grabczewski,
krzysztof. meta-learning in computational intelligence,
volume 358. springer science & business media, 2011.

lake, brenden m, salakhutdinov, ruslan, and tenenbaum,
joshua b. human-level concept learning through prob-
abilistic program induction. science, 350(6266):1332   
1338, 2015.

mnih, volodymyr, kavukcuoglu, koray, silver, david,
rusu, andrei a, veness, joel, bellemare, marc g,
graves, alex, riedmiller, martin, fidjeland, andreas k,
ostrovski, georg, et al. human-level control through
deep id23. nature, 518(7540):529   
533, 2015.

rendell, larry a, sheshu, raj, and tcheng, david k.
layered concept-learning and dynamically variable bias
management. in ijcai, pp. 308   314. citeseer, 1987.

id62 with memory-augmented neural networks

supplementary information
6.1. additional model details

our model is a variant of a id63 (ntm)
from graves et al. it consists of a number of differentiable
components: a controller, read and write heads, an external
memory, and an output distribution. the controller receives
input data (see section 7) directly, and also provides an in-
put to the output distribution. each of these components
will be addressed in turn.

(a)

figure 7. mann architecture.

the controllers in our experiments are feed-forward net-
works or long short-term memories (lstms). for the
best performing networks, the controller is a lstm with
200 hidden units. the controller receives some concate-
nated input (xt, yt   1) (see section 7 for details) and up-
dates its state according to:

  gf ,   gi,   go,   u = wxh(xt, yt   1) + whhht   1 + bh,

gf =   (  gf ),
gi =   (  gi),
go =   (  go),
u = tanh(  u),
ct = gf (cid:12) ct   1 + gi (cid:12) u,
ht = go (cid:12) tanh(ct),
ot = (ht, rt)

(9)
(10)
(11)
(12)
(13)
(14)
(15)
(16)

where   gf ,   go, and   gi are the forget gates, output gates,
and input gates, respectively, bh are the hidden state bi-
ases, ct is the cell state, ht is the hidden state, rt is the vec-
tor read from memory, ot is the concatenated output of the
controller, (cid:12) represents element-wise multiplication, and
(  ,  ) represents vector concatenation. wxh are the weights
from the input (xt, yt   1) to the hidden state, and whh
are the weights between hidden states connected through
time. the read vector rt is computed using content-based

addressing using a cosine distance measure, as described in
the main text, and is repeated below for self completion.
the network has an external memory module, mt, that is
both read from and written to. the rows of mt serve as
memory    slots   , with the row vectors themselves constitut-
ing individual memories. for reading, the controller cell
state serves as a query for mt. first, a cosine distance mea-
sure is computed for the query key vector (here notated as
kt) and each individual row in memory:

k(cid:0)kt, mt(i)(cid:1) =

kt    mt(i)

(cid:107) kt (cid:107)(cid:107) mt(i) (cid:107) ,

(17)

next, these similarity measures are used to produce a read-
weight vector wr
t , with elements computed according to a
softmax:

wr

t (i)     exp(cid:0)k(cid:0)kt, mt(i)(cid:1)(cid:1)
j exp(cid:0)k(cid:0)kt, mt(j)(cid:1)(cid:1) .
(cid:80)
rt    (cid:88)

t (i)mt(i).

wr

(18)

(19)

a memory, rt, is then retrieved using these read-weights:

i

finally, rt is concatenated with the controller hidden state,
ht, to produce the network   s output ot (see equation (16)).
the number of reads from memory is a free parameter,
and both one and four reads were experimented with. four
reads was ultimately chosen for the reported experimental
results. multiple reads is implemented as additional con-
catenation to the output vector, rather than any sort of com-
bination or interpolation.
to write to memory, we implemented a new content-based
access module called least recently used access (lrua).
lrua writes to either the most recently read location, or
the least recently used location, so as to preserve recent,
and hence potentially useful memories, or to update re-
cently encoded information. usage weights wu
t are com-
puted each time-step to keep track of the locations most
recently read or written to:
t       wu
wu

t   1 + wr

t + ww
t ,

(20)

where    is a decay parameter. the least-used weights, wlu
t ,
for a given time-step can then be computed using wu
t . first,
we introduce the notation m(v, n) to denote the nth small-
est element of the vector v. elements of wlu
t are set ac-
cordingly:

wlu

t (i) =

if wu
if wu

t (i) > m(wu
t (i)     m(wu

t , n)
t , n)

,

(21)

where n is set to equal the number of reads to memory.

(cid:26) 0

1

id62 with memory-augmented neural networks

to obtain the write weights ww
t , a learnable sigmoid gate
parameter is used to compute a convex combination of the
previous read weights and previous least-used weights:

t       (  )wr
ww

t   1 + (1       (  ))wlu
t   1,

(22)

where    is a dynamic scalar gate parameter to interpolate
between the weights. prior to writing to memory, the least
used memory location is computed from wu
t   1 and is set to
zero. writing to memory then occurs in accordance with
the computed vector of write weights:
mt(i)     mt   1(i) + ww

t (i)kt,   i

(23)

6.2. output distribution

the controller   s output, ot, is propagated to an output dis-
tribution. for classi   cation tasks using one-hot labels, the
controller output is    rst passed through a linear layer with
an output size equal to the number of classes to be classi-
   ed per episode. this linear layer output is then passed as
input to the output distribution. for one-hot classi   cation,
the output distribution is a categorical distribution, imple-
mented as a softmax function. the categorical distribution
produces a vector of class probabilities, pt, with elements:

(cid:80)

pt(i) =

exp(wop(i)ot)
j exp(won(j)ot)

,

(24)

where wop are the weights from the controller output to
the linear layer output.
for classi   cation using string labels, the linear output size
is kept at 25. this allows for the output to be split into
   ve equal parts each of size    ve. each of these parts is
then sent to an independent categorical distribution that
computes probabilities across its    ve inputs. thus, each
of these categorical distributions independently predicts a
   letter,    and these letters are then concatenated to produce
the    ve-character-long string label that serves as the net-
work   s class prediction (see    gure 8).
a similar implementation is used for regression tasks. the
linear output from the controller outputs two values:    and
  , which are passed to a gaussian distribution sampler as
predicted mean and variance values. the gaussian sam-
pling distribution then computes probabilities for the target
value yt using these values.

6.3. learning

for one-hot label classi   cation, given the probabilities out-
put by the network, pt, the network minimizes the episode
loss of the input sequence:

yt

t log pt,

(25)

l(  ) =    (cid:88)

t

where yt is the target one-hot or string label at time t (note:
for a given one-hot class-label vector yt, only one element
assumes the value 1, and for a string-label vector,    ve ele-
ments assume the value 1, one per    ve-element    chunk   ).
for string label classi   cation, the loss is similar:

l(  ) =    (cid:88)

(cid:88)

yt

t (c) log pt(c).

(26)

t

c

here, the (c) indexes a    ve-element long    chunk    of the
vector label, of which there are a total of    ve.
for regression, the network   s output distribution is a gaus-
sian, and as such receives two-values from the controller
output   s linear layer at each time-step: predictive    and   
values, which parameterize the output distribution. thus,
the network minimizes the negative log-probabilities as de-
termined by the gaussian output distribution given these
parameters and the true target yt.

7. classi   cation input data
input sequences consist of    attened, pixel-level representa-
tions of images xt and time-offset labels yt   1 (see    gure
8 for an example sequence of images and class identities
for an episode of length 50, with    ve unique classes). first,
n unique classes are sampled from the omniglot dataset,
where n is the maximum number of unique classes per
episode. n assumes a value of either 5, 10, or 15, which
is indicated in the experiment description or table of results
in the main text. samples from the omniglot source set
are pulled, and are kept if they are members of the set of n
unique classes for that given episode, and discarded other-
wise. 10n samples are kept, and constitute the image data
for the episode. and so, in this setup, the number of sam-
ples per unique class are not necessarily equal, and some
classes may not have any representative samples. omniglot
images are augmented by applying a random rotation uni-
formly sampled between       
16, and by applying a
random translation in the x- and y- dimensions uniformly
sampled between -10 and 10 pixels. the images are then
downscaled to 20x20. a larger class-dependent rotation is
then applied, wherein each sample from a particular class is
2 (note: this class-speci   c ro-
rotated by either 0,   
tation is randomized each episode, so a given class may ex-
perience different rotations from episode-to-episode). the
image is then    attened into a vector, concatenated with a
randomly chosen, episode-speci   c label, and fed as input
to the network controller.
class labels are randomly chosen for each class from
episode-to-episode. for one-hot label experiments, labels
are of size n, where n is the maximum number of unique
classes that can appear in a given episode.

2 ,   , or 3  

16 and   

id62 with memory-augmented neural networks

for a lstm), learning rate (1e   4), and number of reads
from memory (4). other free parameters were left con-
stant: usage decay of the write weights (0.99), minibatch
size (16),

9.1. comparisons and controls id74

9.1.1. human comparison

for the human comparison task, participants perform the
exact same experiment as the network:
they observe se-
quences of images and time-offset labels (sequence length
= 50, number of unique classes = 5), and are challenged
to predict the class identity for the current input image by
inputting a single digit on a keypad. however, partici-
pants view class labels the integers 1 through 5, rather than
one-hot vectors or strings. there is no time limit for their
choice. participants are made aware of the goals of the task
prior to starting, and they perform a single, non-scored trial
run prior to their scored trials. nine participants each per-
formed two scored trials.

9.1.2. knn

when no data is available (i.e., at the start of training), the
knn classi   er randomly returns a single class as its pre-
diction. so, for the    rst data point, the id203 that the
n where n is number of unique
prediction is correct is 1
classes in a given episode. thereafter, it predicts a class
from classes that it has observed. so, all instances of sam-
ples that are not members of the    rst observed class cannot
be correctly classi   ed until at least one instance is passed
to the classi   er. since statistics are averaged across classes,
   rst instance accuracy becomes 1
n 2 , which is
4% and 0.4% for 5 and 15 classes per episode, respectively.

n + 0) = 1

n ( 1

(a) string label encoded as    ve-hot vector

(b) input sequence

figure 8. example string label and input sequence.

8. task
either 5, 10, or 15 unique classes are chosen per episode.
episode lengths are ten times the number of unique classes
(i.e., 50, 100, or 150 respectively), unless explicitly men-
tioned otherwise. training occurs for 100 000 episodes.
at the 100 000 episode mark, the task continues; however,
data are pulled from a disjoint test set (i.e., samples from
classes 1201-1623 in the omniglot dataset), and weight up-
dates are ceased. this is deemed the    test phase.   
for curriculum training, the maximum number of unique
classes per episode increments by 1 every 10 000 training
episodes. accordingly, the episode length increases to 10
times this new maximum.

9. parameters
9.0.1. optimization
rmsprop was used with a learning rate of 1e   4 and max
learning rate of 5e   1, decay of 0.95 and momentum 0.9.

9.0.2. free parameter grid search

a grid search was performed over number of parameters,
with the values used shown in parentheses: memory slots
(128), memory size (40), controller size (200 hidden units

