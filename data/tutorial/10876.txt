6
1
0
2

 

y
a
m
1
1

 

 
 
]
l
m

.
t
a
t
s
[
 
 

3
v
6
0
8
8
0

.

2
1
5
1
:
v
i
x
r
a

common variable learning and invariant representation

learning using siamese neural networks

uri shaham

uri.shaham@yale.edu

department of statistics

yale university

roy r. lederman   

roy@math.princeton.edu

the program in applied &
computational mathematics

princeton university

abstract

we consider the statistical problem of learning common source of variability in data
which are synchronously captured by multiple sensors, and demonstrate that siamese neu-
ral networks can be naturally applied to this problem. this approach is useful in particular
in exploratory, data-driven applications, where neither a model nor label information is
available. in recent years, many researchers have successfully applied siamese neural net-
works to obtain an embedding of data which corresponds to a    semantic similarity   . we
present an interpretation of this    semantic similarity    as learning of equivalence classes. we
discuss properties of the embedding obtained by siamese networks and provide empirical
results that demonstrate the ability of siamese networks to learn common variability.

1 introduction

many machine learning and signal processing methods aim to separate desired variability (   sig-
nal   ) from undesired variability (   noise    and sensor idiosyncrasies). when the variability of
interest is known on some set of data, supervised learning methods (such as regression) may
be applied. alternatively, when a data model is available, classic signal processing techniques
(such as    ltering) may be used to discard noise. the assumption that such knowledge is avail-
able is not always realistic; in many cases, in particular when exploring new data, it is not
clear how to identify and represent the    interesting part of the phenomenon   . for example,
in analysis of epileptic seizures we are interested in recovering patterns of activity that drive
multiple areas of the brain, even though these patterns may be masked by massive nonlinear,
non-additive e   ects of local activity, for which we have no model.

the purpose of this manuscript is to propose an approach for separating desired variability
from irrelevant variability, in the absence of data model or label information. our proposed
approach is purely unsupervised, and is based on coincidence or co-occurrence, as a source

   the majority of this work was done while at the applied mathematics program, yale university.

1

of information from which the desired variability can be recovered. speci   cally, we assume
the data are measured through multiple sensors, and that the desired variability is recorded by
both of the sensors, while the irrelevant e   ects are sensor-speci   c idiosyncrasies (i.e., each sensor
records local phenomena and noise, independently of the other sensors). we use coincidence
(pairs that were measured at the same time by the di   erent sensors) to recognize the common
source of variability. the learning is performed using siamese neural networks.

the modern form of siamese neural networks have been proposed by [1] to obtain an embed-
ding of the input data that corresponds to    semantic similarity   , so that euclidean proximity
between points in the embedding space implies that the points are    semantically similar   .
siamese networks have been used for various tasks, such as id84, learning
invariant representations [2] and learning hashing functions [3]. this manuscript provides a
formal model and a mathematical interpretation for the embedding that siamese networks try
to obtain, as representing equivalence classes.

training of siamese networks requires a collection of pairs of similar and dissimilar input
objects; we refer to the choice of these training collections as    pairing   . in many works on
siamese networks, the pairing is based on information such as given classi   ed samples, or on
knowledge of a data model. for example, in [1] the pairing of objects is based on class member-
ship, and the resulting representation is shown to be invariant to some input transformations
such as pose and illumination of faces in images. in [2] siamese networks are applied to obtain a
low dimensional embedding of the input data; the approach is based on computing a similarity
graph of the input data; in the experiments, the graph is computed using euclidean distance
or knowledge of the model generating the data. we assume no such model. furthermore,
as discussed in section 4.4, euclidean proximity in the input space might not always capture
the desired similarity. in [3] siamese networks are used to obtain hash maps given a similar-
ity measure; the experiments in the manuscript rely of class membership for pairing. in [4]
siamese networks are applied to obtain representations of images of people, which correspond
to pose, and are invariant to undesired variability, such as identity and clothing; in this case
the similarity calculation is based on having images where people were imitating the positions
shown in a    xed set of seed images, i.e., on a known data model. in [5] and [6], variants of
siamese architectures are applied to textual objects; in both cases the availability of pairs of
objects labeled with a degree of similarity is assumed.

our contributions are as follows:    rst, we use the formulation of the common variable
learning problem [7] to interpret what siamese network try to do. speci   cally, we demonstrate
that siamese networks are in fact trained to recognize equivalence classes of an equivalence
relation de   ned by the common variability we aim to learn. put another way, the embedding
obtained from a siamese network corresponds to the quotient space of this relation. second,
we demonstrate how siamese networks can exploit coincidence as an e   cient approach for
separating desired variability from undesired variability in absence of neither data model nor
label information.

the organization of this manuscript is as follows: in section 2, we describe the common
variable learning problem. in section 3, we show how coincidence can be used to train a siamese
network, and brie   y review a typical training algorithm. some mathematical properties of the

2

embedding which siamese networks aim to obtain are discussed in section 4. in section 5, we
present experiments using synthetic data, demonstrating that the common variable is indeed
learned by siamese networks. brief conclusions are presented in section 6.

2 learning by coincidence

2.1 motivation

the purpose of this section is to illustrate the motivation for    learning from coincidence   .
we use a simpli   ed toy example, adapted from [7]. while this example appears to be a simple
image processing problem, which is easily treated with some domain knowledge, we intentionally
refrain from using this domain knowledge in order to demonstrate how the siamese networks
work without the domain knowledge.

the experimental setup is presented in figure 1. three objects, yoda, a bulldog and a
bunny, are placed on spinning tables and each object spins independently of the other objects.
two cameras are used to take simultaneous snapshots: camera 1, whose    eld of view includes
yoda and the bulldog, and camera 2, whose    eld of view includes the bulldog and the bunny.
in this setting, the rotation angle of the bulldog is a common hidden variable, which we will
denote by x; the common variable is manifested in the snapshot taken by both cameras. the
rotation angle of yoda, which we will denote by y , is a sensor-speci   c source of variability
manifested only in snapshots taken by camera 1, and the rotation angle of the bunny, which
we will denote by z, is a sensor-speci   c source of variability manifested only in camera 2. the
three rotation angles are    hidden   , in the sense that they are not measured directly, but only
through the snapshots taken by the cameras. given snapshots from both cameras, our goal
is to obtain a parametrization of the    relevant    common hidden variable x, i.e., the rotation
angle of the bulldog, and ignore the    super   uous    sensor-speci   c idiosyncratic variables y and
z.

this speci   c task can be performed with speci   c knowledge of the problem, by masking the
irrelevant objects, reducing the problem to learning of one variable. indeed, when x is the only
variable in   uencing the measurements, there are various methods to explore the geometry of x
(e.g. id116, di   usion maps [8]). however, in the more interesting case, it is not known a-priori
how the abstract value of y in   uences the measurements, and the measurements need not be
images (for example, see section 5.2). the scenario presented in this section is a simpli   ed case
of data-driven modeling and exploration of systems; x represents some underlying phenomena
which we would like to investigate although we don   t have a model for the phenomena or for
the other variables y and z that in   uence our measurements. in particular, we do not have
any labeled examples of x. furthermore, we do not know in advance that it is possible to
isolate x by masking certain pixels (in fact, we do not know in advance that the samples
represent images). the key to isolating x, from the super   uous y and z is the fact that we
have multiple instances of measurements taken simultaneously by the two cameras; in this case,
while we don   t know anything about the nature of the images, we know that x (which turns
out to be the bulldog) was in the same state when the two cameras took the snapshots. more

3

generally, such measurements that have the same value of x, give us a natural clue that we
can use to reveal the structure of x.

in this manuscript, we argue that the siamese networks, used in this context with the
proper adaptations, attempt to recover a representation of x that ignores the sensor speci   c
y and z. we demonstrate that in this way, siamese networks can be used for unsupervised
data-driven exploration of phenomena with very little domain knowledge, based mainly on
examples that are obtained simultaneously, but without a prior model and without class labels
or target values for regression.

figure 1: the toy dataset experiment. top: the experiment setting, in which yoda, the
bulldog and the bunny on spinning tables and the two cameras. bottom: two sample snapshots,
taken by cameras 1 (left) and 2 (right) at the same time. in both pictures the bulldog is in the
same state x (i.e., rotation angle, with respect to the table).

2.2 common variable learning: formal de   nition

we follow a similar setting to [7], which discussed the problem from a manifold learning per-
spective. let (x, y, z)       x,y,z(x, y, z) be three hidden random variables from the (possibly
high dimensional) spaces x , y and z, with distribution   x,y,z, where, given x, the variables
y and z are independent.

we have access to these hidden variables through two observable random variables s(1) =
g1(x, y ) and s(2) = g2(x, z), where g1 and g2 are bi-lipschitz (therefore, invertible). we

4

denote the range of g1 and g2 by s (1) and s (2), respectively; these ranges may be embedded in
a high dimensional space. we refer to the random variables s(1) and s(2) as the measurement
in sensor 1 and the measurement in sensor 2, respectively. the i-th realization of the system
, s(2)
consists of the hidden triplet (xi, yi, zi) and the corresponding pair of measurements (s(1)
i );
i = g1(xi, yi) and s(2)
while xi, yi and zi are hidden and not available to us directly, s(1)
i =
g2(xi, zi) are observable. we note that both s(1)
are functions of the same realization
xi of x. our dataset is composed of n pairs of corresponding measurements

.
a natural way to obtain such pairs is to measure the same phenomenon x with two di   erent
sensors g1 and g2, with both sensors in   uenced by the same phenomenon x, and each of them
also in   uenced by its own idiosyncratic    irrelevant    state, y or z.
ideally, we would like to construct a function    : s (1)     x that recovers x from g1(x, y),
so that for every x     x , and every y     y, we would have x =    (g1(x, y)). however, since
x and g1 are unknown, we cannot expect to recover x precisely, and we are interested in a
function f1 : s (1)     rd that recovers x up to some scaling and bi-lipschitz transformation. in
particular, we require that for all x     x and y, y(cid:48)     y

and s(2)

(cid:111)n

, s(2)
i )

(cid:110)

(s(1)

i=1

i

i

i

i

f1(g1(x, y)) = f1(g1(x, y(cid:48))),

and for all x (cid:54)= x(cid:48)     x and y, y(cid:48)     y

f1(g1(x, y)) (cid:54)= f1(g1(x(cid:48), y(cid:48))).

3 algorithm

(1)

(2)

in this section we discuss the rationale for siamese networks in the context of the problem
formulated above, and brie   y review the siamese networks algorithm in this context. while
the algorithm given in section 3.3 is a typical variant of a siamese network training algo-
rithm, the key element of our approach is the implementation of learning through coincidence,
which is manifested in the construction of the    positive    and    negative    datasets, described in
sections 3.1 and 3.2.

3.1 rationale
in order to satisfy equations (1) and (2), we would like f1(s(1)
i ) to depend on xi and be invariant
to the value of yi. the crucial information is provided in the dataset through the fact that
both s(1)
in the i-th pair are functions of the same value of xi. the idea is to use this
information to learn maps f1 and f2 such that for all i,

and s(2)

i

i

f1(s(1)

i ) = f2(s(2)
i ).

(3)
for every x     x , y, y(cid:48)     y and z, z(cid:48)     z, the functions f1 and f2 are required to satisfy
f1(g1(x, y)) = f1(g1(x, y(cid:48))) and f2(g2(x, z)) = f2(g2(x, z(cid:48))). to avoid a trivial solution, in which

5

f1 and f2 are simply constant functions, we add the requirement that for all xi (cid:54)= xj, the
functions also satisfy
f1(s(1)

i ) (cid:54)= f2(s(2)
j ),

(4)

so that f1 and f2 cannot simply    ignore    the value of x.
we implement the function f1 by a network which we denote by n1, and the function f2 by
a network which we denote by n2. we are given a dataset dpos of    positive    pairs, (s(1)
, s(2)
i ),
in which both elements correspond to the same realization xi of the common variable x; in
addition we are given (or construct) a dataset dneg of    negative    pairs, (  s(1)
i ) in which
the two elements correspond to di   erent realizations of x (see section 3.2). the idea is that
i )     dpos as input to n1 and n2,
when we introduce to the network a positive pair (s(1)
, s(2)
we require the outputs of n1 to be identical to the output of n2, whereas when we introduce
i )     dneg as input, we require the output of n1 to be
to the network a negative pair (  s(1)
,   s(2)
di   erent from the output of n2.
at the end of the process, the map f1, implemented by n1, computes our approximate
representation; as a useful    side e   ect   , we also obtain the map f2 which computes a similar
approximate representation for the samples obtained from sensor 2.

,   s(2)

i

i

i

i

figure 2: a diagram of the network structure.

in summary, siamese networks try to achieve the following goal, when looking at pairs of

measurements from two di   erent sensors in the context of this manuscript:

    if the two measurements have the same value of x (measurements taken at the same

time), give the same output.

    if the measurements probably don   t have the same value of x, make the outputs of the

two di   erent networks di   erent.

6

3.2 implementing coincidence: constructing datasets of positive pairs and

negative pairs

the algorithm is given a dataset dpos of npos pairs of the form (s(1)
i ) corresponding to
i )     dpos is a pair of measurements
n realizations of x, y, z. hence, each instance (s(1)
, s(2)
that were taken at the same time by the two di   erent sensors. we refer to this dataset as
the positive dataset. in addition, we construct a second dataset, referred to as the negative
dataset dneg, which contains nneg    false pairs   , of the form (  s(1)
,   s(2)
and   s(2)
should be di   erent realizations with di   erent values of x, so that   xi
i; in practice, it
su   ces that   xi (cid:54)=   xi with su   ciently high id203. when dneg is not explicitly available,
an approximation is constructed from dpos by randomly mixing pairs from dpos.

i ). ideally,   s(1)

(cid:54)=   x(cid:48)

, s(2)

i

i

i

i

i

the training data for the siamese network, (i.e., the positive and negative pairs) is obtained
without assuming any class membership, data model or label information. the entire construc-
tion and pairing (as    positive    and    negative    pairs) is based on coincidence, i.e., on the fact
that the data are measured through multiple sensors, with each of the sensors capturing the
variability of interest.

3.3 algorithm

algorithm 1 is a typical training procedure for siamese networks, presented here for complete-
ness of the discussion and to provide the context for the discussion of pairing in section 3.2.

algorithm 1 common variable learning using an ann

i

i=1

i )}n
, s(2)

input: {(s(1)
output: implementation of maps f1 : rd1     rd and f2 : rd2     rd
construct datasets dpos and dneg (see section 3.2)
optimize the parameters of the joint network n (equation 5)
optional: id84 of the learned representation

a typical architecture of a siamese network n is presented in figure 2. the network n
is composed of two networks n1 and n2 and a single output unit, which is connected to the
output layer of both networks. n1 and n2 accept samples from s (1) and s (2), respectively.
the two networks may have di   erent numbers of layers and di   erent con   gurations; however,
they have the same number d of output units.
with s(1) and s(2) the inputs of n1 and n2, respectively, f1(s(1)) and f2(s(2)) the outputs of n1
and n2, respectively, and    the logistic sigmoid function   (x) = 1

the output node of n compares the output of n1 and n2 by computing   (cid:0)(cid:107)f1(s(1))     f2(s(2))(cid:107)2(cid:1),

1+e   x .

7

in our experiments in section 5 we set the training id168 to be

(cid:18) 1
(cid:16)

2

      

1       

(cid:16)(cid:107)f1(s(1))     f2(s(2))(cid:107)2(cid:17)(cid:19)2
(cid:16)(cid:107)f1(s(1))     f2(s(2))(cid:107)2(cid:17)(cid:17)2

+

l(  ) =

  
npos

  

(cid:88)
(cid:88)

(s(1),s(2))   dpos

nneg
(s(1),s(2))   dneg
  (cid:107)  (cid:107)2
2,

+

(5)

respectively.

  (cid:0)(cid:107)f1(s(1))     f2(s(2))(cid:107)2(cid:1) close to   (0) = 1
like to maximize (cid:107)f1(s(1))     f2(s(2))(cid:107)2, thus have   (cid:0)(cid:107)f1(s(1))     f2(s(2))(cid:107)2(cid:1) close to   (   ) = 1.

where    is a vector containing the weight parameters (but not bias parameters) of n1 and n2.
for the positive pairs in dpos, we would like (cid:107)f1(s(1))     f2(s(2))(cid:107)2 to be close to zero, thus
2 ; similarly, for the negative pairs in dneg, we would
once the network n is trained, n1 and n2 implement our proposed functions f1 and f2,
the network n bears some super   cial resemblance to a classi   er that determines whether
or not two measurements from two di   erent sensors share the same value of x (i.e.    real   
pairs or    fake    pairs). however, classi   ers need not construct a representation of the common
variable, which is the goal in this work. in addition, since we do not use any class membership
information, and the entire training is based on coincidence, our proposed training approach
is purely unsupervised. having said that, in our experiments we    nd it useful to measure the
   classi   cation accuracy    of the network as a proxy for the quality of learning. speci   cally, since
the output of the network ranges between 0.5 and 1, we set 0.75 as a classi   cation threshold
for estimating whether (s(1), s(2)) is a    real    or a    fake    pair.

4 discussion

4.1 siamese networks learn equivalence classes
let     be an equivalence relation on the s (1), the space of measurements in sensor 1. we
say that two observations are equivalent if and only if they share the same value of x, i.e.,
i     s(1)
i    xi = xj. this equivalence relation generates the quotient set s (1)/    , where the
s(1)
equivalence class of s(1) = g1(x, y) is [s(1)] = {g1(x, y(cid:48)) : y(cid:48)     y}.

j

we observe that a function f1 that satis   es (1) yields the same value for any member of an
equivalence class [s(1)]. moreover, a function f1 that satis   es (2) also yields a di   erent value
for members of di   erent equivalence classes [s(1)

thus, with a minor abuse of notation, there is a natural way to de   ne f1 : s (1)/        rd
on the quotient set s (1)/     rather than on s (1). furthermore, such f1 is an injective function.
hence, ideally, the function f1 implemented by (a single sub-net of a) siamese network is
e   ectively a map of the equivalence class of its argument.

]     s (1)/    .

] (cid:54)= [s(1)

j

i

8

4.2 comparing measurements from the same sensor

in practice, because of the continuity of the functions g1 and g2 and the continuity of the
computation operations in the networks that we use here, samples that are    close    in x would
have similar representations, so that the representation of x is smooth. informally,

xi     xj     f1(g1(xi, yi))     f1(g1(xj, yj)),

therefore, the function f1 can be used to estimate if two samples s(1)
   close    values xi and xj.
in the space x of the common variable.

i

therefore, from this perspective, the vague    semantic similarity    is interpreted as proximity

(6)

and s(1)

j

in sensor 1 have

4.3 measurements from di   erent sensors become comparable

the algorithm treats the measurements in sensor 1 and the measurements in sensor 2 sym-
metrically, in the sense that it aims to construct maps f1 : s (1)     rd and f2 : s (2)     rd that
map into the same codomain rd and have similar properties. moreover, the algorithm aims to
   nd such f1 and f2 that agree in the sense de   ned in equations (3) and (4).

following the same argument as in section 4.2, the two functions f1 and f2 can be used to
j = g2(xj, zj) from sensor 2 to

compare a sample s(1)
estimate whether the two samples are obtained from    close    values of x; informally,

i = g1(xi, yi) from sensor 1 to a sample s(2)

xi     xj     f1(g1(xi, yi))     f2(g2(xj, zj)).

(7)

the two sensors might measure di   erent modalities, such as audio signals in one and images
in the other, so that the framework proposed here allows to compare two di   erent modalities
in terms of the common variable.

several works propose anns that learn representations of inputs that are measured via two
sources, possibly of di   erent modalities, for example audio and video, or images and texts [9, 10].
these works focus on learning a shared representation, containing information from the two
modalities, and demonstrate that one modality provides information about the other modality.
these works have been particularly interested in recovering the input in one modality from the
input in another modality, for example, through an autoencoder. the problem of learning a
shared representation of objects which are captured via multiple sensors, possibly of di   erent
modalities is discussed also in [11], where di   usion maps are used to obtain the representation.
however, here as well sensor speci   c variability is not removed. in this manuscript, we aim
to discard modality-speci   c attributes, and learn the common hidden variable that underlies
both modalities.

4.4 similarities in the input space

one of the interesting properties of the common variable problem, demonstrated in the toy
example in figure 1, and in the examples in the next section, is that similarity in the common

9

variable, or    semantic similarity   , can have very little to do with the similarity in the input
space. for example, in the toy problem, we can have two di   erent snapshots taken by camera
2 which are supposed to be equivalent because the bulldog (the common variable x) happens
to be in the same place. however, the bunny, which is actually a larger, more dominant
object, may appear in any state in the two snapshots, so the snapshots are very di   erent in
the input space. in other words, snapshots that are very di   erent in the input space may be
equivalent. similarly, snapshots in which the bunny appears in a similar state but the bulldog
does not will be similar in the input space, although they are not equivalent in the sense of the
common variable we wish to capture. therefore, similarity in the input space (measured via,
say, euclidean distance) might have little to do with similarity in the common variable, and
consequently is an inappropriate tool for collecting    positive    pairs in this context.

some siamese networks use the distance in the input space to de   ne pairs (e.g. nearest
neighbors in the input space are paired in [2]), or to regularize the distance in the output space;
this use of similarity in the input space has been demonstrated to be useful in dimensionality
reduction. however, this type of pairing or id173 cannot discard the super   uous vari-
ables because it cannot distinguish between the super   uous variables and the common ones.
therefore, pairing based on the simultaneous measurements, when such measurements are avail-
able, is advantageous in recovering the common variable and in distilling hidden underlying
phenomena.

4.5 connection to cca

a natural approach for discovering common information in a dataset of paired observations is
to use canonical correlation analysis (cca) [12]. the ability of standard cca to discover
such information is limited, since it only considers linear transformations of its inputs. among
non linear versions of cca, the deep-cca architecture proposed in [13] bares resemblance to
siamese network architecture. in this manuscript we follow a di   erent approach in the use of
the dataset, and an architecture that resembles siamese networks more than deep-cca. our
experiment in section 5.4 suggests that the approach proposed in this manuscript better suits
the common variable learning problem.

4.6 learning invariant representations using siamese networks

in this section we will discuss a related problem, learning invariant representation, which can
also be viewed as a problem of learning equivalence classes.
let g be a group that acts on a set s. we say that s     s is equivalent to s(cid:48)     s up to g if
there is g     g such that g.s = s(cid:48) . we denote the equivalence relation by s     s(cid:48). we say that a
map f of s is invariant to g if it satis   es (a) for all g     g, f (s) = f (g.s) and (b) for all s (cid:54)    s(cid:48)
and for all g     g, f (s) (cid:54)= f (g.s(cid:48)).
in the invariant representation learning problem, we have examples of pairs (g.s, g(cid:48).s) with
di   erent randomly selected group actions g, g(cid:48)     g operating on a randomly selected element
s     s and in some cases we may have examples of    negative pairs    (g.s, g(cid:48).s(cid:48)) with s (cid:54)    s(cid:48)     s;
in other
we would like to use such examples to    nd a function f that is invariant to g.

10

words, we would like to learn a map that is de   ned on the equivalence classes of s     s(cid:48). since
siamese networks learn equivalence classes, they can be used to learn invariant representation,
as demonstrated in section 5.3.

neural networks which are invariant to speci   c input transformations, such as translation
and rotation have been proposed in [14], [15], and [16]), for example. however, these networks
are often designed to be invariant to speci   c, well modeled transformations, rather than to
unknown transformations.

5 experimental results

in this section we present experimental results of common variable learning. the experiments
involve synthetic datasets, generated so that the common variable is de   ned explicitly, to
demonstrate that the embedding obtained by the net indeed corresponds to the quotient space
de   ned by the common variable. we also demonstrate how siamese networks can be used to
learn invariant representations.
in experiments where we have more than a single hidden layer in each stack, we pre-train
every hidden layer in n1 and n2 as a denoising autoencoder (dae)[17] with activation sparsity
loss (see [18]). the optimization of the network n is performed using standard stochastic
id119 (sgd) with momentum (see, for example, [19]) and dropout (see, for example,
[20]), or using l-bfgs (see, for example, [21]); in both optimization algorithms, we compute
gradients using standard id26 (see, for example, [22]). the classi   cation accuracy
we report is measured on a test set consisting of positive and negative examples that were not
introduced to the network during training.

5.1 common variable learning: the toy dataset (spinning figures)

i

i

i

i

i

, s(2)

and s(2)

and s(2)

i ), with s(1)

in this experiment we revisit the setup described in section 2.1. here, s(1) is a snapshot taken
by camera 1 and s(2) is a snapshot taken by camera 2. the dataset dpos consists of pairs
of snapshots (s(1)
taken simultaneously by camera 1 and camera 2,
respectively. the dataset dneg was constructed by pairing snapshots that had been taken at
are 60    80 color images; positive and negative
di   erent times. the samples s(1)
examples are presented in figure 3 (top). the training sets dpos and dneg consisted of 10, 000
examples each. both n1 and n2 had three layers, the two hidden layers in each network had 150
units, and the output layers had 100 units. the joint network n was trained using l-bfgs.
the classi   cation accuracy on the test set (as de   ned in section 3.3) was 95.96%.
the learned representations in this experiment (the outputs of the networks n1 and n2),
are 100-dimensional. we used standard id84 algorithms to process the
output for the purpose of visualization and further processing; in figure 3 (bottom) we present
the reduced representation obtained using di   usion maps [8], which we found to be clearer
than the representation obtained using pca. the closed curve and the smooth transitions in
color in the embedding demonstrate that the algorithm recovered a good representation of the

11

common variable x, and that the position along the learned manifold corresponds to the value
of the common variable.

figure 3: the toy dataset experiment. top: two sample examples.
in a positive example
snapshots taken simultaneously, containing two di   erent views on the bulldog at the same
rotation angle. in a negative example the snapshots from the two cameras were not taken at
the same time, hence they do not correspond to same rotation angle of the bulldog. bottom:
embedding of the toy dataset. the color of each point corresponds to the true common hidden
variable, i.e. the rotation angle x of the bulldog.

5.2 common variable learning: two di   erent modalities

in the previous experiment, we used the same type of input in both sensors; in this experiment
we used a di   erent data modality in each sensor: images in one sensor and audio signals in the
other.

12

i

i

we denote by i   an image i rotated by angle   . a measurement s(1)

from sensor 1 is a con-
catenation (ixi, iyi) of two rotations of an image in arbitrary angles . a measurement s(2)
from
sensor 2 is a t dimensional vector vxi,zi(t), t = 1, .., t with entries vxi,zi(t) = sin(2    (xi)t+zi),
where   (  ) is a deterministic function, so that xi determines the frequency of the sine, and zi
determines the phase. in other words, the common variable x determines the rotation of the
left image in the    rst sensor and the frequency of the sine in the second sensor; the sensor
speci   c variables are the rotation angle of the right image in s(1)
, and the phase of the sine in
s(2)
i

. an example from the dataset of this experiment is presented in figure 4 (top).
both n1 and n2 had three layers, with 100 units in each. dpos and dneg consisted of 10, 000
examples each. the accuracy on the test set was 95.8%.
in figure 4 (bottom) we present the di   usion embedding of the outputs of both n1 and
n2, colored by the true value of the common variable xi; the smooth transition of the color
along the manifold implies that the learned representation corresponds to the common variable.
furthermore, the points in figure 4 (bottom) which correspond to output of n1 are indistin-
guishable from the points that correspond to outputs of n2; in other words, data from the
two di   erent modalities has been mapped into a the same space, where data points from same
or di   erent modalities can be compared based on their corresponding value of the common
variable xi.

i

5.3 learning a rotation-invariant representation

the following experiment demonstrates the application of the algorithm to the problem of
learning invariant representations, discussed in section 4.6.

our goal here is to learn maps f1 and f2 that are rotation-invariant. let g be the group
of rotations of images, so that g.s is a rotation of s by g degrees. we used images from the
caltech-101 dataset [23] (converted to gray-scale 50  50 pixels for convenience), and constructed
datasets of rotated images. the positive set dpos was composed of samples (s(1)
i ) where
s(1)
i = g1,i.si and s(2)
i = g2,i.si are two instances of the same base image si rotated by two
randomly chosen angles g1,i, g2,i     g. each sample in the negative dataset was composed of
two di   erent randomly chosen base images, each rotated by a di   erent randomly chosen angle.
positive and negative examples from the dataset and the    rst layer weights of n1 are presented
in figure 5 (top).
the networks n1 and n2 had three layers each; the joint network was trained using l-bfgs.

, s(2)

i

the learned functions achieved a high accuracy score of 99.44%;

to check whether the hidden representation we obtained is indeed invariant to rotation, we
performed the following analysis: we randomly selected an image and rotated it in two random
angles; we denote the resulting images by a and a(cid:48). we then selected a di   erent image and
if the map f1 is indeed
rotated it in a random angle; we denote the resulting image by b.
invariant to rotations, then we expect to have (cid:107)f1(a)    f1(a(cid:48))(cid:107)2 (cid:28) (cid:107)f1(a)    f1(b)(cid:107)2. histograms
of (cid:107)f1(a)     f1(a(cid:48))(cid:107)2 and (cid:107)f1(a)     f1(b)(cid:107)2 for 10,000 repetitions of the above procedure are
presented in figure 5 (bottom); as evident from the histograms, (cid:107)f1(a)     f1(a(cid:48))(cid:107)2 is indeed
signi   cantly smaller than (cid:107)f1(a)     f1(b)(cid:107)2, as expected.

13

i

figure 4: the two modalities dataset. top: a positive example from the dataset. a measure-
ment s(1)
from sensor 1 is a concatenation of two rotations of the image i, in angles xi and
yi. a measurement s(2)
from sensor 2 is a sine, with frequency determined by xi and phase
determined by zi. bottom: embedding of the images and audio signals from the test set in the
two modalities experiment; the color corresponds to the true value of the common variable xi.
data from two di   erent modalities is mapped to the same space, and is parametrized by the
common variable.

i

14

figure 5: the rotation-invariance experiment. top left: two sample examples generated from
the caltech-101 dataset for the rotation-invariance experiment. in a positive example s(1) and
s(2) are the same image, up to rotation. in a negative example s(1) and s(2) are the di   erent
images, rotated in di   erent angles. top right:    rst layer features in the rotation-invariance
experiment. bottom: histograms of (cid:107)f1(a)     f1(a(cid:48))(cid:107)2 (dark blue) and (cid:107)f1(a)     f1(b)(cid:107)2 (light
blue). distances between representations of arbitrarily rotated copies of the same image are
signi   cantly smaller than distances between representations of di   erent images.

15

i

2 so that the cross correlation between f(cid:48)

5.4 comparison to deep cca
i )}n
given realizations {(s(1)
, s(2)
i=1 of random variables s(1) and s(2), the deep cca algorithm
(see [13]) computes maps f(cid:48)
1 and f(cid:48)
2(s(2))
is maximized. we implemented the deep cca network and applied it to the toy dataset
of section 5.1, with the same network structure used in our experiment in section 5.1. the
di   usion embedding that was obtained from the last layer representation of the deep cca
network is presented in figure 6. we observe that in this experiment the position along the
embedded manifold does not correspond to the value of the common variable, i.e., the rotation
angle of the bulldog; moreover, additional analysis indicated that the representation obtained
by deep cca in this experiment re   ects the sensor speci   c super   uous variables (rotation
angles of yoda and the bunny), which we would like to discard.

1(s(1)) and f(cid:48)

figure 6: di   usion embedding obtained from the deep cca network [13] on the toy dataset.
the color of each point corresponds to the value of the common hidden variable, an embedding
that captures the common variable would have a smooth transition of color; the embedding
here does not correspond to the value of the common hidden variable.

6 conclusions

in this manuscript we presented siamese neural networks as a solution to the statistical problem
of common variable learning. we demonstrated that siamese neural networks learn equivalence
relations in the input space. we demonstrated how coincidence can be used for the recovery of
common variables, in the absence of a model or labeled data, using examples of measurements
that are    equivalent    or    related    via an appropriate form of coincidence, and using examples
of measurements that are    not equivalent    or    unrelated   . in addition, we demonstrated how a

16

siamese network can map observations, possibly from di   erent modalities, to a space in which
their respective values of the common variable are comparable.

the experiments presented in this manuscript have been carefully designed to illustrate the
theoretical arguments regarding the embedding obtained by siamese networks representing the
common variable and regarding limited use of domain knowledge. as demonstrated in other
works, when domain knowledge is available it can be used in designing the network architecture:
for example, when the samples are images, it is natural to use convolutional networks.

acknowledgments

the authors would like to thank raphy coifman, sahand n. negahban, andrew r. barron
and ronen talmon, for their help.

references

[1] s. chopra, r. hadsell, and y. lecun,    learning a similarity metric discriminatively,
with application to face veri   cation,    in id161 and pattern recognition, 2005.
cvpr 2005. ieee computer society conference on, vol. 1, pp. 539   546, ieee, 2005.

[2] r. hadsell, s. chopra, and y. lecun,    id84 by learning an invari-
ant mapping,    in id161 and pattern recognition, 2006 ieee computer society
conference on, vol. 2, pp. 1735   1742, ieee, 2006.

[3] j. masci, m. m. bronstein, a. bronstein, and j. schmidhuber,    multimodal similarity-
preserving hashing,    pattern analysis and machine intelligence, ieee transactions on,
vol. 36, no. 4, pp. 824   830, 2014.

[4] g. w. taylor, i. spiro, c. bregler, and r. fergus,    learning invariance through imita-
tion,    in id161 and pattern recognition (cvpr), 2011 ieee conference on,
pp. 2729   2736, ieee, 2011.

[5] w.-t. yih, k. toutanova, j. c. platt, and c. meek,    learning discriminative projections
for text similarity measures,    in proceedings of the fifteenth conference on computational
natural language learning, pp. 247   256, association for computational linguistics, 2011.

[6] k. m. hermann and p. blunsom,    multilingual models for compositional distributed se-

mantics,    arxiv preprint arxiv:1404.4641, 2014.

[7] r. r. lederman and r. talmon,    learning the geometry of common latent variables using

alternating-di   usion,    applied and computational harmonic analysis, 2015.

[8] r. r. coifman and s. lafon,    di   usion maps,    applied and computational harmonic

analysis, vol. 21, no. 1, pp. 5   30, 2006.

17

[9] j. ngiam, a. khosla, m. kim, j. nam, h. lee, and a. y. ng,    multimodal deep learning,   
in proceedings of the 28th international conference on machine learning (icml-11),
pp. 689   696, 2011.

[10] n. srivastava and r. r. salakhutdinov,    multimodal learning with deep boltzmann ma-

chines,    in advances in neural information processing systems, pp. 2222   2230, 2012.

[11] y. keller, r. r. coifman, s. lafon, and s. w. zucker,    audio-visual group recognition
using di   usion maps,    signal processing, ieee transactions on, vol. 58, no. 1, pp. 403   
413, 2010.

[12] h. hotelling,    relations between two sets of variates,    biometrika, pp. 321   377, 1936.

[13] g. andrew, r. arora, j. bilmes, and k. livescu,    deep canonical correlation analysis,   
in proceedings of the 30th international conference on machine learning, pp. 1247   1255,
2013.

[14] m. a. ranzato, f. j. huang, y.-l. boureau, and y. lecun,    unxsupervised learning of
invariant feature hierarchies with applications to object recognition,    in id161
and pattern recognition, 2007. cvpr   07. ieee conference on, pp. 1   8, ieee, 2007.

[15] e. oyallon and s. mallat,    deep roto-translation scattering for object classi   cation,    arxiv

preprint arxiv:1412.8659, 2014.

[16] k. sohn and h. lee,    learning invariant representations with local transformations,   

arxiv preprint arxiv:1206.6418, 2012.

[17] p. vincent, h. larochelle, y. bengio, and p.-a. manzagol,    extracting and composing
robust features with denoising autoencoders,    in proceedings of the 25th international
conference on machine learning, pp. 1096   1103, acm, 2008.

[18] a. ng,    unsupevised id171 and deep learning, stnanford class cs294.    http://
deeplearning.stanford.edu/wiki/index.php/ufldl_tutorial, 2011. accessed: 2016-
01-18.

[19] i. sutskever, j. martens, g. dahl, and g. hinton,    on the importance of initialization
and momentum in deep learning,    in proceedings of the 30th international conference on
machine learning (icml-13), pp. 1139   1147, 2013.

[20] g. e. dahl, t. n. sainath, and g. e. hinton,    improving deep neural networks for
lvcsr using recti   ed linear units and dropout,    in acoustics, speech and signal processing
(icassp), 2013 ieee international conference on, pp. 8609   8613, ieee, 2013.

[21] s. j. wright and j. nocedal, numerical optimization, vol. 2. springer new york, 1999.

[22] r. rojas, neural networks: a systematic introduction. springer science & business media,

1996.

18

[23] l. fei-fei, r. fergus, and p. perona,    learning generative visual models from few training
examples: an incremental bayesian approach tested on 101 object categories,    computer
vision and image understanding, vol. 106, no. 1, pp. 59   70, 2007.

19

