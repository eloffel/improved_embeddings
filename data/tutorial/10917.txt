8
1
0
2

 

p
e
s
0
3

 

 
 
]
l
c
.
s
c
[
 
 

4
v
3
3
9
6
0

.

4
0
7
1
:
v
i
x
r
a

adversarial id4

lijun wu1, yingce xia2, li zhao3, fei tian3, tao qin3, jianhuang lai1,4 and tie-yan liu3

1school of data and computer science, sun yat-sen university

2university of science and technology of china

3microsoft research asia

4guangdong key laboratory of information security technology
{lizo,fetia,taoqin,tie-yan.liu}@microsoft.com; stsljh@mail.sysu.edu.cn

wulijun3@mail2.sysu.edu.cn; yingce.xia@gmail.com;

abstract

in this paper, we study a new learning
paradigm for id4
(id4). instead of maximizing the likeli-
hood of the human translation as in previ-
ous works, we minimize the distinction be-
tween human translation and the translation
given by an id4 model. to achieve this
goal, inspired by the recent success of gener-
ative adversarial networks (gans), we em-
ploy an adversarial training architecture and
name it as adversarial-id4. in adversarial-
id4, the training of the id4 model is as-
sisted by an adversary, which is an elab-
orately designed convolutional neural net-
work (id98). the goal of the adversary is to
differentiate the translation result generated by
the id4 model from that by human. the
goal of the id4 model is to produce high
quality translations so as to cheat the adver-
sary. a policy gradient method is leveraged
to co-train the id4 model and the adversary.
experimental results on english   french and
german   english translation tasks show that
adversarial-id4 can achieve signi   cantly
better translation quality than several strong
baselines.

introduction

1
id4 (id4) (cho et al.,
2014; bahdanau et al., 2014) has drawn more and
more attention in both academia and industry (lu-
ong and manning, 2016; jean et al., 2015; shen et
al., 2016; tu et al., 2016b; sennrich et al., 2016;
wu et al., 2016). compared with traditional sta-
tistical machine translation (smt) (koehn et al.,

2003), id4 achieves similar or even better trans-
lation results in an end-to-end framework. the sen-
tence level maximum likelihood principle and gat-
ing units in lstm/gru (hochreiter and schmid-
huber, 1997; cho et al., 2014), together with atten-
tion mechanisms grant id4 with the ability to bet-
ter translate long sentences.

despite its success, the translation quality of latest
id4 systems is still far from satisfaction and there
remains large room for improvement. for example,
id4 usually adopts the maximum likelihood es-
timation (id113) principle for training, i.e., to maxi-
mize the id203 of the target ground-truth sen-
tence conditioned on the source sentence. such an
objective does not guarantee the translation results
to be natural, suf   cient, and accurate compared with
ground-truth translation by human. there are previ-
ous works (ranzato et al., 2015; shen et al., 2016;
bahdanau et al., 2016) that aim to alleviate such lim-
itations of maximum likelihood training, by adopt-
ing sequence level objectives (e.g., directly maxi-
mizing id7 (papineni et al., 2002)), to reduce the
objective inconsistency between id4 training and
id136. yet somewhat improved, such objectives
still cannot fully bridge the gap between id4 trans-
lations and ground-truth translations.

we,

training objective for id4,

in this paper, adopt a thoroughly differ-
ent
targeting at di-
rectly minimizing the difference between human
translation and the translation given by an id4
model. to achieve this target, inspired by the re-
cent success of id3
(gans) (goodfellow et al., 2014a), we design an
adversarial training protocol for id4 and name it as

adversarial-id4. in adversarial-id4, besides the
typical id4 model, an adversary is introduced to
distinguish the translation generated by id4 from
that by human (i.e., ground truth). meanwhile the
id4 model tries to improve its translation results
such that it can successfully cheat the adversary.

these two modules in adversarial-id4 are co-
trained, and their performances get mutually im-
proved. in particular, the discriminative power of the
adversary can be improved by learning from more
and more training samples (both positive ones gen-
erated by human and negative ones sampled from
id4); and the ability of the id4 model in cheat-
ing the adversary can be improved by taking the
output of the adversary as reward. in this way, the
id4 translation results are professor forced (lamb
et al., 2016) to be as close as possible to ground-truth
translation.

different from previous gans, which assume the
existence of a generator in continuous space, in our
proposed framework, the id4 model is in fact not
a typical generative model, but instead a probabilis-
tic transformation that maps a source language sen-
tence to a target language sentence, both in dis-
crete space. such differences make it necessary
to design both new network architectures and opti-
mization methods to make adversarial training pos-
sible for id4. we therefore on one aspect, lever-
age a specially designed convolutional neural net-
work (id98) model as the adversary, which takes the
(source, target) sentence pair as input; on the other
aspect, we turn to a policy gradient method named
reinforce (williams, 1992), widely used in the
id23 literature (sutton and barto,
1998), to guarantee both the two modules are ef-
fectively optimized in an adversarial manner. we
conduct extensive experiments, which demonstrates
that adversarial-id4 can achieve signi   cantly bet-
ter translation results than traditional id4 models
with even much larger vocabulary size and higher
model complexity.

2 related work

neural

machine

translation
end-to-end
(id4)
(bahdanau et al., 2014; cho et al.,
2014; sutskever et al., 2014; jean et al., 2015; wu
et al., 2016; zhou et al., 2016) has been the recent

research focus of the community. typical id4
system is built within the id56 based encoder-
decoder framework.
in such a framework the
encoder id56 sequentially processes the words in a
source language sentence into    xed length vectors,
which act as the inputs to decoder id56 to decode
the translation sentence. id4 typically adopts
the principle of id113
(id113) for training, i.e., maximizing the per-word
likelihood of target sentence. other training criteria,
such as minimum risk training (mrt) based on
id23 (ranzato et al., 2015; shen
et al., 2016) and translation reconstruction (tu
et al., 2016a), are shown to improve over such
word-level id113 principle since these objectives
take the translation sentence as a whole.

the training principle we propose is based
on the spirit of id3
(gans) (goodfellow et al., 2014a; salimans et
al., 2016), or more generally, adversarial
train-
ing (goodfellow et al., 2014b). in adversarial train-
ing, a discriminator and a generator compete with
each other, forcing the generator to produce high
quality outputs that are able to fool the discriminator.
adversarial training typically succeed in image gen-
eration (goodfellow et al., 2014a; reed et al., 2016),
with limited contribution in natural language pro-
cessing tasks (yu et al., 2016; li et al., 2017), mainly
due to the dif   culty of propagating the error signals
from the discriminator to the generator through the
discretely generated natural language tokens. yu et
al. (2016) alleviates such a dif   culty by reinforce-
ment learning approach for sequence (e.g., music)
generation. however, as far as we know, there are
limited efforts on adversarial training for sequence-
to-sequence task when a conditional mapping be-
tween two sequences is involved, and our work is
among the    rst endeavors to explore the potential
of acting in this way, especially for neural machine
translation (yang et al., 2017).

3 adversarial-id4

the overall framework of our adversarial-id4 is
shown in figure 1. let (x = {x1, x2, ..., xtx}, y =
{y1, y2, ..., yty}) be a bilingual aligned sentence
pair for training, where xi is the i-th word in the
source sentence and yj is the j-th word in the tar-

tx(cid:88)

id203 of generating word yt is:

g(yt|y<t, x)     exp(yt; rt, ct)
rt = g(rt   1, yt   1, ct)

(1)
(2)

where rt is the decoding state from decoder at time
t. here g is the recurrent unit such as the long
short term memory (lstm) unit (hochreiter and
schmidhuber, 1997) or gated recurrent unit (gru)
(cho et al., 2014), and ct is a distinct source repre-
sentation at time t calculated by an attention mecha-
nism (bahdanau et al., 2014):

(cid:80)

ct =

  ithi

i=1

exp{a(hi, rt   1)}
j exp{a(hj, rt   1)}

  it =

(3)

(4)

where tx is the source sentence length, a(  ,  ) is a
feed-forward neural network and hi is the hidden
state from id56 encoder computed by hi   1 and xi:

hi = f (hi   1, xi)

(5)
the translation result y(cid:48) can be sampled from g(  |x)
either in a greedy way for each timestep, or using
id125 (sutskever et al., 2014) to seek globally
optimized result.

3.2 adversary model
the adversary is used to differentiate translation re-
sult y(cid:48) and the ground-truth translation y, given the
source language sentence x. to achieve that, one
needs to measure the translative matching degree of
source-target sentence pair (x, y). we turn to con-
volution neural network (id98) for this task (yin
et al., 2015; hu et al., 2014), since with its layer-
by-layer convolution and pooling strategies, id98
is able to accurately capture the hierarchical corre-
spondence of (x, y) at different abstraction levels.

the general structure is shown in figure 2.
speci   cally, given a sentence pair (x, y), we    rst
construct a 2d image-like representation by simply
concatenating the embedding vectors of words in x
and y. that is, for i-th word xi in x and j-th word yj
in sentence y, we have the following feature map:

z(0)
i,j = [xt

i , yt

j ]t

figure 1: the adversarial-id4 framework.    ref   
is short for    reference    which means the ground-
truth translation and    hyp    is short for    hypothesis   ,
denoting model translation sentence. all the yel-
low parts denote the id4 model g, which maps a
source sentence x to a translation sentence. the red
parts are the adversary network d, which predicts
whether a given target sentence is the ground-truth
translation of the given source sentence x. g and
d combat with each other, generating both sampled
translation y(cid:48) to train d, and the reward signals to
train g by policy gradient (the blue arrows).

get sentence. let y(cid:48) denote the translation sentence
out from an id4 system for the source sentence x.
as previously stated, the goal of adversarial-id4
is to force y(cid:48) to be as    similar    as y. in the perfect
case, y(cid:48) is so similar to the human translation y that
even a human cannot tell whether y(cid:48) is generated by
machine or human. in order to achieve that, we in-
troduce an extra adversary network, which acts sim-
ilarly to the discriminator adopted in gans (good-
fellow et al., 2014a). the goal of the adversary is to
differentiate human translation from machine trans-
lation, and the id4 model g tries to produce a tar-
get sentence as similar as human translation so as to
fool the adversary.

3.1 id4 model

we adopt the recurrent neural network (id56)
based encoder-decoder as the id4 model to seek a
target language translation y(cid:48) given source sentence
x. in particular, a probabilistic mapping g(y|x) is
   rstly learnt and the translation result y(cid:48)     g(  |x)
is sampled from it. to be speci   c, given source
sentence x and previously generated words y<t, the

based on such a 2d image-like representation, we
perform convolution on every 3    3 window, with
the purpose to capture the correspondence between
segments in x and segments in y by the following
feature map of type f:

z(1,f )
i,j =   (w (1,f )z(0)

i,j + b(1,f ))

where   (  ) is the sigmoid active function,   (x) =
1/(1 + exp(   x)).
overlapping 2    2 windows:

after that we perform a max-pooling in non-

2i   1,2j, z(1,f )

2i   1,2j   1, z(1,f )

2i,2j })
i,j = max({z(1,f )
2i,2j   1, z(1,f )
z(2,f )
we could go on for more layers of convolution
and max-pooling, aiming at capturing the corre-
spondence at different levels of abstraction. the
extracted features are then fed into a multi-layer
id88 (mlp), with sigmoid activation at the
last layer to give the id203 that (x, y) is from
ground-truth data,
i.e. d(x, y). the optimiza-
tion target of such id98 adversary is to minimize
the cross id178 loss for binary classi   cation, with
ground-truth data (x, y) as positive instance while
sampled data (from g) (x, y(cid:48)) as negative one.

figure 2: the id98 adversary framework.

3.3 policy gradient algorithm to train

adversarial-id4

with the notations for id4 model g and adversary
model d, the    nal training objective is:

min

g

max

d

v (d, g)

=e(x,y)   pdata(x,y)[log d(x, y)]+
ex   pdata(x),y(cid:48)   g(  |x)[log(1     d(x, y(cid:48)))]

(6)

that is,

translation model g tries to produce
high quality translation y(cid:48) to fool the adversary d

(the outer-loop min), whose objective is to success-
fully classify translation results from real data (i.e.,
ground-truth) and from g (the inner-loop max).

eqn. (6) reveals that it is straightforward to train
the adversary d, by keeping providing d with the
ground-truth sentence pair (x, y) and the sampled
translation pair (x, y(cid:48)) from g, respectively as pos-
itive and negative training data. however, when it
turns to id4 model g, it is non-trivial to design the
training process, given that the discretely sampled y(cid:48)
from g makes it dif   cult to directly back-propagate
the error signals from d to g, making v (d, g) non-
differentiable w.r.t. g   s model parameters   g.

to tackle the above challenge, we leverage
the reinforce algorithm (williams, 1992), a
monte-carlo policy gradient method in reinforce-
ment learning literature to optimize g. note that
the objective of training g under a    xed source lan-
guage sentence x and d is to minimize the following
loss item:

l = ey(cid:48)   g(  |x) log(1     d(x, y(cid:48)))

(7)

whose gradient w.r.t.   g is:

     gl
=     gey(cid:48)   g(  |x)[log(1     d(x, y(cid:48)))]
=ey(cid:48)   g(  |x)[log(1     d(x, y(cid:48)))     g log g(y(cid:48)|x)]
(8)
a sample y(cid:48) from g(  |x) is used to approximate

the above gradient:
     g            g = log(1     d(x, y(cid:48)))     g log g(y(cid:48)|x)
(9)
in which      g log g(y(cid:48)|x) are gradients speci-
   ed with standard sequence-to-sequence id4 net-
works. such a gradient approximation is used to up-
date   g:

  g       g               g

(10)

where    is the learning rate.
using the language of id23, in
the above eqn. (7) to (9), the id4 model g(  |x) is
the conditional policy faced with x, while the term
    log(1     d(x, y(cid:48))), provided by the adversary d,
acts as a monte-carlo estimation of the reward. in-
tuitively speaking, eqn. (9) implies, the more likely

y(cid:48) to successfully fool d (i.e, larger d(x, y(cid:48))), the
larger reward the id4 model will get, and the
   pseudo    training data (x, y(cid:48)) will correspondingly
be more favored to improve the policy g(  |x).
note here we in fact use one sample     log(1    
d(x, y(cid:48))) from a trajectory y(cid:48) to estimate the termi-
nal reward given by d. acting in this way brings
high variance, to reduce the variance, a moving aver-
age of the historical reward values is set as a reward
baseline (weaver and tao, 2001). one can sample
multiple trajectories in each decoding step, by re-
garding g as the roll-out policy to reduce estimation
variance for immediate reward (silver et al., 2016;
yu et al., 2016). however, empirically we    nd such
approach is intolerably time-consuming in our task,
given that the decoding space in id4 is typically
extremely large (the same as vocabulary size).

it is worth comparing our adversarial training
with existing methods that directly maximize se-
quence level measure such as id7 (ranzato et
al., 2015; shen et al., 2016; bahdanau et al., 2016)
in training id4 models, using similar approaches
based on id23 as ours. we argue
that adversarial-id4 makes the optimization eas-
ier compared with these methods. firstly, the re-
ward learned by our adversary d provides rich and
global information to evaluate the translation, which
goes beyond the id7   s simple low-level id165
matching criteria. acting in this way provides much
smoother objective compared with id7 since the
latter is highly sensitive for slight translation dif-
ference at word or phrase level.
the
id4 model g and the adversary d in adversarial-
id4 co-evolves. the dynamics of adversary d
makes id4 model g grows in an adaptive way
rather than controlled by a    xed evaluation metric as
id7. given the above two reasons, adversarial-
id4 makes the optimization process towards se-
quence level objectives much more robust and bet-
ter controlled, which is further veri   ed by its su-
perior performances to the aforementioned methods
that will be reported in the next section 4.

secondly,

4 experiments

4.1 settings
we report
results on both
english   french translation (en   fr for short) and

the experimental

german   english translation (de   en for short).

dataset: for en   fr translation, for the sake of
fair comparison with previous works, we use the
same dataset as (bahdanau et al., 2014; shen et al.,
2016). the dataset is composed of a subset of wmt
2014 training corpus as training set, the combination
of news-test 2012 and news-test 2013 as dev set and
news-test 2014 as test set, which respectively con-
tains roughly 12m, 6k and 3k sentence pairs. the
maximal sentence length is 50. we use top 30k most
frequent english and french words and replace the
other words as    unk    token.
for de   en translation,

following previous
works (ranzato et al., 2015; bahdanau et al., 2016),
the dataset is from iwslt 2014 evaluation cam-
paign (cettolo et al., 2014), consisting of train-
ing/dev/test corpus with approximately 153k, 7k
and 6.5k bilingual sentence pairs respectively. the
maximal sentence length is also set as 50. the
dictionary for english and german corpus respec-
tively include 22, 822 and 32, 009 most frequent
words (bahdanau et al., 2016), with other words re-
placed as a special token    unk   .

implementation details:

in adversarial-id4,
the structure of the id4 model g is the same as
id56search model (bahdanau et al., 2014), a id56
based encoding-decoding framework with attention
mechanism. single layer grus act as encoder and
decoder. for en   fr translation, the dimensions of
id27 and gru hidden state are respec-
tively set as 620 and 1000, and for de   en transla-
tion they are both 256.

for the adversary d, the id98 consists of two
convolution+pooling layers, one mlp layer and one
softmax layer, with 3    3 convolution window size,
2    2 pooling window size, 20 feature map size and
20 mlp hidden layer size.

for the training of id4 model g, similar as what
is commonly done in previous works (shen et al.,
2016; tu et al., 2016a), we warm start g from a
well-trained id56search model, and optimize it us-
ing vanilla sgd with mini-batch size 80 for en   fr
translation and 32 for de   en translation. gradient
clipping is used with clipping value 1 for en   fr
and 10 for de   en. the initial learning rate is
chosen from cross-validation on dev set (0.02 for
en   fr and 0.001 for de   en) and we halve it every
80k iterations.

system

system con   gurations

representative end-to-end id4 systems

lstm with 4 layers + 80k vocabs

sutskever et al. (2014)
bahdanau et al. (2014) id56search
jean et al. (2015)
jean et al. (2015)
luong et al. (2015)
luong et al. (2015)
shen et al. (2016)
sennrich et al. (2016)
he et al. (2016)

id56search + unk replace
id56search + 500k vocabs + unk replace
lstm with 4 layers + 40k vocabs
lstm with 4 layers + 40k vocabs + posunk
id56search +minimum risk training objective
id56search +monolingual data
id56search+ monolingual data + dual objective

this work

id56search + adversarial training objective
id56search + adversarial training objective + unk replace

adversarial-id4

areported in (jean et al., 2015).
breported in (he et al., 2016).

id7

30.59
29.97a
33.08
34.11
29.50
31.80
31.30
30.40 b
32.06
31.91   
34.78

table 1: different id4 systems    performances on en   fr translation. the default setting is single layer
gru + 30k vocabs + id113 training objective, trained with no monolingual data, i.e., the id56search model
proposed by bahdanau et al. (2014).    : signi   cantly better than shen et al. (2016) (   < 0.05).

an important factor we    nd in successfully train-
ing g is that the combination of adversarial objec-
tive with id113. that is, we force 50% randomly
chosen mini-batch data are trained with adversarial-
id4, while apply id113 principle to the other mini-
batches. acting in this way signi   cantly improves
stability in model training, which is also reported
in other tasks such as language model (lamb et
al., 2016) and neural dialogue generation (li et al.,
2017). we conjecture that the reason is that id113
acts as a regularizer to guarantee smooth model up-
date, alleviating the negative effects brought by high
gradient estimation variance of the one-step monte-
carlo sample in reinforce.

as the    rst step,

the id98 adversary network
d is initially pre-trained using the sampled data
(x, y(cid:48)) sampled from the id56search model, and
the ground-truth translation (x, y). after that, in
joint g-d training of adversarial-id4, the adver-
sary is optimized using nesterov sgd (nesterov,
1983) with batch size set as 32. the initial learning
rate is 0.002 for en   fr and 0.001 for de   en, both
chosen by validation on dev set. the dimension of
id27 is the same with that of g, and we
   x the id27s during training. batch nor-
malization (ioffe and szegedy, 2015) is observed to
signi   cantly improve d   s performance. consider-

ing ef   ciency, all the negative training data instances
(x, y(cid:48)) used in d   s training are generated using beam
search with beam size 4.
in generating model translation for evaluation, we
set beam width as 4 and 12 for en   fr and de   en
respectively according to id7 on dev set. the
translation quality is measured by tokenized case-
sensitive id7 (papineni et al., 2002) score 1.
4.2 result on en   fr translation
in table 1 we provide the en   fr translation result
of adversarial-id4, together with several strong
id4 baselines, such as the well representative
attention-based id4 model id56search (bahdanau
et al., 2014).
in addition, to make our compari-
son comprehensive, we would like to cover several
well acknowledged techniques whose effectiveness
has been veri   ed to improve en   fr translation by
previously published works, including the leverage
of 1) using large vocabulary to handle rare words
(jean et al., 2015; luong et al., 2015); 2) differ-
ent training objectives (shen et al., 2016; ranzato et
al., 2015; bahdanau et al., 2016) such as minimum
risk training (mrt) to directly optimize evaluation

1https://github.com/moses-smt/

mosesdecoder/blob/master/scripts/generic/
multi-id7.perl

(a) d: same learning rates; g: different learning rates.
(b) g: same learning rates; d: different learning rates.
figure 3: dev set id7s during en   fr adversarial-id4 training process, with same learning rates for
d, different learning rates for g in left 3(a), and same learning rates for g and different learning rates for
d in right 3(b).

measure (shen et al., 2016), and dual learning to en-
hance both primal and dual tasks (e.g., en   fr and
fr   en) (he et al., 2016); 3) improved id136
process such as id125 optimization (wiseman
and rush, 2016) and postprocessing unk (luong et
al., 2015; jean et al., 2015); 4) leveraging additional
monolingual data (sennrich et al., 2016; zhang and
zong, 2016; he et al., 2016).

from the table, we can clearly observe that
adversarial-id4 obtains satisfactory translation
quality against baseline systems.
in particular, it
even surpasses the performances of other models
with much larger vocabularies (jean et al., 2015),
deeper layers
(luong et al., 2015), much larger
monolingual training corpus (sennrich et al., 2016),
and the goal of directly maximizing id7 (shen et
al., 2016). in fact, as far as we know, adversarial-
id4 achieves state-of-the-art result (34.78) on
en   fr translation for single-layer gru sequence-
to-sequence models trained with only supervised
bilingual corpus on news-test 2014 test set.

human evaluation: apart from the compari-
son based on the objective id7 scores, to bet-
ter appraise the performance of our model, we also
involve human judgements as a subjective mea-
sure. to be more speci   c, we generate the transla-
tion results for 500 randomly selected english sen-
tences from en   fr news-test 2014 dataset using

adversarial-id4

mrt

evaluator 1
evaluator 2
evaluator 3

overall

286 (57.2%)
310 (62.0%)
295 (59.0%)
891 (59.4%)

214 (42.8%)
190 (38.0%)
205 (41.0%)
609 (40.6%)

table 2: human evaluations for adversarial-id4
and mrt on english   french translation.
   286
(57.2%)    means that evaluator 1 made a decision
that 286 (57.2%) out of 500 translations generated
by adversarial-id4 were better than mrt.

both mrt (shen et al., 2016) and our adversarial-
id4. here mrt is chosen since it is the well rep-
resentative of previous id4 methods which max-
imize sequence level objectives, achieving satisfac-
tory results among all single layer models (i.e., 31.3
in table 1). afterwards we ask three human label-
ers to choose the better one from the two versions of
translated sentences. the evaluation process is con-
ducted on amazon mechanical turk 2 with all the
workers to be native english or french speakers.

result in table 2 shows that 59.4% sentences are
better translated by our adversarial-id4, compared
with mrt (shen et al., 2016). such human eval-
uation further demonstrates the effectiveness of our

2https://www.mturk.com

0510152025iteration(*5k)24.525.025.526.026.527.027.5id7lr_g=0.002, lr_d=0.002lr_g=0.020, lr_d=0.002lr_g=0.200, lr_d=0.0020510152025iteration(*5k)26.226.426.626.827.027.227.427.6id7lr_g=0.02, lr_d=0.0200lr_g=0.02, lr_d=0.0020lr_g=0.02, lr_d=0.0002model and matches the expectation that adversarial-
id4 provides more human desired translation.

overall speaking,

adversarial training: slow or fast: in this sub-
section we analyze how to set the pace for training
the id4 model g and adversary d, to make them
speci   cally, for en   fr
combatting effectively.
translation, we inspect how dev set id7 varies
along adversarial training process with different ini-
tial learning rates for g (shown in 3(a)) and for d
(shown in 3(b)), conditioned on the other one    xed.
these two    gures show that
adversarial-id4 is much more robust with regard
to the pace of d making progress than that of
g, since the three curves in 3(b) grow in a sim-
ilar pattern while curves in 3(a) drastically differ
with each other. we conjecture the reason is that
in adversarial-id4, id98 based d is powerful
in classi   cation tasks, especially when it is warm
started with sampled data from id56search. as a
comparison, the translation model g is relatively
weak in providing quali   ed translations. therefore,
training g needs carefully con   gurations of learn-
ing rate: small value (e.g., 0.002) leads to slower
convergence (blue line in 3(a)), while large value
(e.g., 0.2) brings un-stability (green line in 3(a)).
the proper learning rate (e.g. 0.02) induces g to
make fast, meanwhile stable progress along training.
4.3 result on de   en translation
in table 3 we provide the de   en translation result
of adversarial-id4, compared with some strong
baselines such as id56search (bahdanau et al.,
2014) and mrt (shen et al., 2016).

again, we can see that adversarial-id4 per-
forms best against other models from table 3,
achieves 27.94 id7 scores, which is also a state-
of-the-art result.

effect of adversarial training: to better visu-
alize and understand the advantages of adversarial
training brought by adversarial-id4, we show sev-
eral translation cases in table 4. concretely speak-
ing, we give two german   english translation ex-
amples, including the source language sentence x,
the ground-truth translation sentence y, and two
id4 model translation sentences, respectively out
from id56search and adversarial-id4 (trained af-
ter 20 epochs) and emphasized on their different
parts by bold fonts which lead to different transla-

tion quality. for each model translation y(cid:48), we also
list d(x, y(cid:48)), i.e., the id203 that the adversary
d regards y(cid:48) as ground-truth, in the third column,
and the sentence level id7 score of y(cid:48) in the last
column.

since id56search model acts as the warm start
for training adversarial-id4, its translation could
be viewed as the result of adversarial-id4 at its
initial phase. therefore, from table 4, we can ob-
serve:

    with adversarial training goes on, the quality
of translation sentence output by g gets im-
proved, both in terms of subjective feelings and
id7 scores as a quantitative measure.

    correspondingly, the translation quality growth
makes the adversary d deteriorated, as shown
recognition of y(cid:48) by
by d   s
id56search as translated from model, whereas
d makes mistakes in classifying y(cid:48) out from
adversarial-id4 as ground-truth (by human).

successful

5 conclusion

we in this paper propose a novel and intuitive
training objective for id4, that is to force the
translation results be as similar as ground-truth
translations generated by human. such an objec-
tive is achieved via an adversarial training frame-
work called adversarial-id4 which complements
the original id4 model with an adversary based
on id98. adversarial-id4 adopts both new net-
work architectures to re   ect the mapping within
(source, target) sentence, and an ef   cient policy gra-
dient algorithm to tackle the optimization dif   culty
brought by the discrete nature of machine transla-
tion. the experiments on both english   french and
german   english translation tasks clearly demon-
strate the effectiveness of such adversarial training
method for id4.

as to future works, with the hope of achieving
new state-of-the-art performance for id4 system,
we plan to fully exploit the potential of adversarial-
id4 by combining it with other powerful methods
listed in subsection 4.2, such as training with large
vocabulary, minimum-risk principle and deep struc-
tures. we additionally would like to emphasize and
explore the feasibility of adversarial training to other

system

system con   gurations

representative end-to-end id4 systems

bahdanau et al. (2014) id56search
ranzato et al. (2015)
bahdanau et al. (2016) id98 encoder + sequence level actor-critic objective
wiseman et al. (2016)
shen et al. (2016)

id56search + id125 optimization
id56search + minimum risk training objective

id98 encoder + sequence level objective

this work

id56search + adversarial training objective
id56search + adversarial training objective + unk replace

adversarial-id4

areported in (wiseman and rush, 2016).
bresult from our implementation, and we reproduced their reported en   fr result.

id7

23.87 a
21.83
22.45
25.48
25.84 b
26.98   
27.94

table 3: different id4 systems    performances on de   en translation. the default setting is single layer
gru encoder-decoder model with id113 training objective, i.e., the id56search model proposed by bah-
danau et al. (2014).    : signi   cantly better than shen et al. (2016) (   < 0.05).

source sentence x

groundtruth translation y

translation by id56search y(cid:48)

translation by

adversarial-id4 y(cid:48)
source sentence x

ich wei   , dass wir es k  onnen , und soweit es mich betrifft
ist das etwas ,was die welt jetzt braucht .
i know that we can , and as far as i &apos;m concerned ,
that &apos;s something the world needs right now .
i know we can do it , and as far as it &apos;s in time ,
what the world needs now .
i know that we can , and as far as it is to be something
that the world needs now .
wir m  ussen verhindern , dass die menschen kenntnis erlangen
von dingen , vor allem dann , wenn sie wahr sind .
we have to prevent people from    nding about things ,
especially when they are true .

groundtruth translation y
translation by id56search y(cid:48) we need to prevent people who are able to know
that people have to do , especially if they are true .
we need to prevent people who are able to know
about things , especially if they are true .

adversarial-id4 y(cid:48)

translation by

d(x, y(cid:48)) id7

0.14

0.67

27.26

50.28

d(x, y(cid:48)) id7

0.15

0.93

0.00

25.45

table 4: cases-studies to demonstrate the translation quality improvement brought by adversarial-id4.
we provide two de   en translation examples, with the source german sentence, ground-truth english sen-
tence, and two translation results respectively provided by id56search and adversarial-id4. d(x, y(cid:48)) is
the id203 of model translation y(cid:48) being ground-truth translation of x, calculated from the adversary d.
id7 is per-sentence translation id7 score for each translated sentence.

text processing tasks, such as image caption, depen-
dency parsing and sentiment classi   cation.

references
dzmitry bahdanau, kyunghyun cho, and yoshua ben-
2014. id4 by jointly
arxiv preprint

gio.
learning to align and translate.
arxiv:1409.0473.

dzmitry bahdanau, philemon brakel, kelvin xu,
anirudh goyal, ryan lowe, joelle pineau, aaron

courville, and yoshua bengio. 2016. an actor-critic
arxiv preprint
algorithm for sequence prediction.
arxiv:1607.07086.

mauro cettolo, jan niehues, sebastian st  uker, luisa
bentivogli, and marcello federico. 2014. report on
the 11th iwslt evaluation campaign, iwslt 2014.

kyunghyun cho, bart van merrienboer, caglar gulcehre,
dzmitry bahdanau, fethi bougares, holger schwenk,
and yoshua bengio. 2014. learning phrase represen-
tations using id56 encoder   decoder for statistical ma-
chine translation. in emnlp, october.

ian goodfellow, jean pouget-abadie, mehdi mirza,
bing xu, david warde-farley, sherjil ozair, aaron
courville, and yoshua bengio. 2014a. generative ad-
versarial nets. in nips.

ian j goodfellow,

jonathon shlens, and christian
szegedy. 2014b. explaining and harnessing adver-
sarial examples. arxiv preprint arxiv:1412.6572.

di he, yingce xia, tao qin, liwei wang, nenghai yu,
tieyan liu, and wei-ying ma. 2016. dual learning
for machine translation. in d. d. lee, m. sugiyama,
u. v. luxburg, i. guyon, and r. garnett, editors,
nips.

sepp hochreiter and j  urgen schmidhuber. 1997. long

short-term memory. neural computation.

baotian hu, zhengdong lu, hang li, and qingcai chen.
2014. convolutional neural network architectures for
matching natural language sentences. in nips, pages
2042   2050.

sergey ioffe and christian szegedy. 2015. batch nor-
malization: accelerating deep network training by re-
in icml-15, pages
ducing internal covariate shift.
448   456.

s  ebastien jean, kyunghyun cho, roland memisevic, and
yoshua bengio. 2015. on using very large target vo-
cabulary for id4. in acl, july.
philipp koehn, franz josef och, and daniel marcu.
2003. statistical phrase-based translation. in naacl.
association for computational linguistics.

alex m lamb, anirudh goyal alias parth goyal,
ying zhang, saizheng zhang, aaron c courville, and
yoshua bengio. 2016. professor forcing: a new algo-
rithm for training recurrent networks. in nips.

jiwei li, will monroe, tianlin shi, alan ritter, and dan
jurafsky. 2017. adversarial learning for neural dia-
logue generation. arxiv preprint arxiv:1701.06547.

minh-thang luong and christopher d manning. 2016.
achieving open vocabulary id4
with hybrid word-character models. arxiv preprint
arxiv:1604.00788.

thang luong, ilya sutskever, quoc le, oriol vinyals,
and wojciech zaremba. 2015. addressing the rare
word problem in id4. in acl,
july.

yurii nesterov. 1983. a method for unconstrained con-
vex minimization problem with the rate of conver-
gence o (1/k2). in doklady an sssr, pages 543   547.
kishore papineni, salim roukos, todd ward, and wei-
jing zhu. 2002. id7: a method for automatic evalu-
ation of machine translation. in acl. association for
computational linguistics.

marc   aurelio ranzato, sumit chopra, michael auli, and
wojciech zaremba.
sequence level train-
ing with recurrent neural networks. arxiv preprint
arxiv:1511.06732.

2015.

scott reed, zeynep akata, xinchen yan, lajanugen lo-
geswaran, bernt schiele, and honglak lee. 2016.
generative adversarial text to image synthesis.
in
icml.

tim salimans, ian goodfellow, wojciech zaremba, vicki
cheung, alec radford, and xi chen. 2016. improved
techniques for training gans. in nips.

rico sennrich, barry haddow, and alexandra birch.
improving id4 models

2016.
with monolingual data. in acl, august.

shiqi shen, yong cheng, zhongjun he, wei he, hua wu,
maosong sun, and yang liu. 2016. minimum risk
training for id4. in acl, au-
gust.

david silver, aja huang, chris j maddison, arthur guez,
, et al. 2016. mastering the game of go with deep
neural networks and tree search. nature.

ilya sutskever, oriol vinyals, and quoc v le. 2014. se-
quence to sequence learning with neural networks. in
nips.

richard s sutton and andrew g barto. 1998. rein-
forcement learning: an introduction. mit press cam-
bridge.

zhaopeng tu, yang liu, lifeng shang, xiaohua liu, and
hang li. 2016a. id4 with re-
construction. arxiv preprint arxiv:1611.01874.

zhaopeng tu, zhengdong lu, yang liu, xiaohua liu,
and hang li. 2016b. modeling coverage for neural
machine translation. in acl, august.

lex weaver and nigel tao. 2001. the optimal reward
baseline for gradient-based id23. in
proceedings of the seventeenth conference on uncer-
tainty in arti   cial intelligence, pages 538   545. mor-
gan kaufmann publishers inc.

ronald j williams. 1992. simple statistical gradient-
following algorithms for connectionist reinforcement
learning. machine learning.

sam wiseman and alexander m. rush. 2016. sequence-
to-sequence learning as beam-search optimization. in
emnlp, november.

yonghui wu, mike schuster, zhifeng chen, quoc v le,
et al. 2016. google   s id4 sys-
tem: bridging the gap between human and machine
translation. arxiv preprint arxiv:1609.08144.

zhen yang, wei chen, feng wang, and bo xu. 2017.
improving id4 with conditional
sequence generative adversarial nets. arxiv preprint
arxiv:1703.04887.

wenpeng yin, hinrich sch  utze, bing xiang, and bowen
zhou. 2015. abid98: attention-based convolutional
neural network for modeling sentence pairs. arxiv
preprint arxiv:1512.05193.

lantao yu, weinan zhang,

2016.

seqgan:

yu.
sarial nets with policy gradient.
arxiv:1609.05473.

jun wang, and yong
sequence generative adver-
arxiv preprint

jiajun zhang and chengqing zong. 2016. exploiting
source-side monolingual data in neural machine trans-
lation. in emnlp, november.

jie zhou, ying cao, xuguang wang, peng li, and wei
xu. 2016. deep recurrent models with fast-forward
arxiv
connections for id4.
preprint arxiv:1606.04199.

