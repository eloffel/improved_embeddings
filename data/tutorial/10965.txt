7
1
0
2

 
r
a

 

m
1
2

 
 
]
l
c
.
s
c
[
 
 

3
v
2
4
7
5
0

.

2
1
5
1
:
v
i
x
r
a

a survey of available corpora for building

data-driven dialogue systems

iulian vlad serban
diro, universit  e de montr  eal
2920 chemin de la tour, montr  eal, qc h3c 3j7, canada

{iulian.vlad.serban} at umontreal dot ca

ryan lowe
department of computer science, mcgill university
3480 university st, montr  eal, qc h3a 0e9, canada

{ryan.lowe} at mail dot mcgill dot ca

peter henderson
department of computer science, mcgill university
3480 university st, montr  eal, qc h3a 0e9, canada

{peter.henderson} at mail dot mcgill dot ca

laurent charlin
department of computer science, mcgill university
3480 university st, montr  eal, qc h3a 0e9, canada

joelle pineau
department of computer science, mcgill university
3480 university st, montr  eal, qc h3a 0e9, canada

editor: david traum

{lcharlin} at cs dot mcgill dot ca

{jpineau} at cs dot mcgill dot ca

abstract

during the past decade, several areas of speech and language understanding have witnessed sub-
stantial breakthroughs from the use of data-driven models. in the area of dialogue systems, the
trend is less obvious, and most practical systems are still built through signi   cant engineering and
expert knowledge. nevertheless, several recent results suggest that data-driven approaches are fea-
sible and quite promising. to facilitate research in this area, we have carried out a wide survey of
publicly available datasets suitable for data-driven learning of dialogue systems. we discuss im-
portant characteristics of these datasets, how they can be used to learn diverse dialogue strategies,
and their other potential uses. we also examine methods for id21 between datasets and
the use of external knowledge. finally, we discuss appropriate choice of id74 for the
learning objective.

1. introduction

dialogue systems, also known as interactive conversational agents, virtual agents or sometimes
chatterbots, are useful in a wide range of applications ranging from technical support services to
language learning tools and entertainment (young et al., 2013; shawar and atwell, 2007b). large-

1

scale data-driven methods, which use recorded data to automatically infer knowledge and strategies,
are becoming increasingly important in speech and language understanding and generation. speech
recognition performance has increased tremendously over the last decade due to innovations in deep
learning architectures (hinton et al., 2012; goodfellow et al., 2015). similarly, a wide range of data-
driven machine learning methods have been shown to be effective for natural language processing,
including tasks relevant to dialogue, such as dialogue act classi   cation (reithinger and klesen,
1997; stolcke et al., 2000), dialogue state tracking (thomson and young, 2010; wang and lemon,
2013; ren et al., 2013; henderson et al., 2013; williams et al., 2013; henderson et al., 2014c;
kim et al., 2015), id86 (langkilde and knight, 1998; oh and rudnicky,
2000; walker et al., 2002; ratnaparkhi, 2002; stent et al., 2004; rieser and lemon, 2010; mairesse
et al., 2010; mairesse and young, 2014; wen et al., 2015; sharma et al., 2016), and dialogue policy
learning (young et al., 2013). we hypothesize that, in general, much of the recent progress is due
to the availability of large public datasets, increased computing power, and new machine learning
models, such as neural network architectures. to facilitate further research on building data-driven
dialogue systems, this paper presents a broad survey of available dialogue corpora.

corpus-based learning is not the only approach to training dialogue systems. researchers have
also proposed training dialogue systems online through live interaction with humans, and of   ine
using user simulator models and id23 methods (levin et al., 1997; georgila et al.,
2006; paek, 2006; schatzmann et al., 2007; jung et al., 2009; schatzmann and young, 2009; ga  si  c
et al., 2010, 2011; daubigney et al., 2012; ga  si  c et al., 2012; su et al., 2013; gasic et al., 2013;
pietquin and hastie, 2013; young et al., 2013; mohan and laird, 2014; su et al., 2015; piot et al.,
2015; cuay  ahuitl et al., 2015; hiraoka et al., 2016; fatemi et al., 2016; asri et al., 2016; williams
and zweig, 2016; su et al., 2016). however, these approaches are beyond the scope of this survey.
this survey is structured as follows. in the next section, we give a high-level overview of di-
alogue systems. we brie   y discuss the purpose and goal of dialogue systems. then we describe
the individual system components that are relevant for data-driven approaches as well as holistic
end-to-end dialogue systems. in section 3, we discuss types of dialogue interactions and aspects
relevant to building data-driven dialogue systems, from a corpus perspective, as well as modalities
recorded in each corpus (e.g. text, speech and video). we further discuss corpora constructed from
both human-human and human-machine interactions, corpora constructed using natural versus un-
natural or constrained settings, and corpora constructed using works of    ction. in section 4, we
present our survey over dialogue corpora according to the categories laid out in sections 2-3. in
particular, we categorize the corpora based on whether dialogues are between humans or between
a human and a machine, and whether the dialogues are in written or spoken language. we discuss
each corpus in turn while emphasizing how the dialogues were generated and collected, the topic
of the dialogues, and the size of the entire corpus. in section 5, we discuss issues related to: cor-
pus size, id21 between corpora, incorporation of external knowledge into the dialogue
system, data-driven learning for contextualization and personalization, and automatic evaluation
metrics. we conclude the survey in section 6.

2. characteristics of data-driven dialogue systems

this section offers a broad characterization of data-driven dialogue systems, which structures our
presentation of the datasets.

2

2.1 an overview of dialogue systems

the standard architecture for dialogue systems, shown in figure 1, incorporates a speech rec-
ognizer, language interpreter, state tracker, response generator, natural language generator,
and speech synthesizer. in the case of text-based (written) dialogues, the speech recognizer and
speech synthesizer can be left out. while some of the literature on dialogue systems identi   es
only the state tracker and response selection components as belonging inside the dialogue man-
ager (young, 2000), throughout this paper we adopt a broader view where language understanding
and generation are incorporated within the dialogue system. this leaves space for the development
and analysis of end-to-end dialogue systems (ritter et al., 2011; vinyals and le, 2015; lowe et al.,
2015a; sordoni et al., 2015b; shang et al., 2015; li et al., 2015; serban et al., 2016; serban et al.,
2017b,a; dodge et al., 2015; williams and zweig, 2016; weston, 2016).

we focus on corpus-based data-driven dialogue systems. that is, systems composed of machine
learning solutions using corpora constructed from real-world data. these system components have
variables or parameters that are optimized based on statistics observed in dialogue corpora.
in
particular, we focus on systems where the majority of variables and parameters are optimized. such
corpus-based data-driven systems should be contrasted to systems where each component is hand-
crafted by engineers     for example, components de   ned by an a priori    xed set of deterministic
rules (e.g. weizenbaum (1966); mcglashan et al. (1992)). these systems should also be contrasted
with systems learning online, such as when the free variables and parameters are optimized directly
based on interactions with humans (e.g. ga  si  c et al. (2011)). still, it is worth noting that it is
possible to combine different types of learning within one system. for example, some parameters
may be learned using statistics observed in a corpus, while other parameters may be learned through
interactions with humans.

while there are substantial opportunities to improve each of the components in figure 1 through
(corpus-based) data-driven approaches, within this survey we focus primarily on datasets suitable
to enhance the components inside the dialogue system box. it is worth noting that the natural
language interpreter and generator are core problems in natural language processing with appli-
cations well beyond dialogue systems.

figure 1: dialogue system diagram

3

	
   	
   	
   	
   	
   	
   	
   	
   	
   	
   dialogue	
   system	
   automa   c	
   speech	
   recognizer	
   natural	
   language	
   interpreter	
   text-     to-     speech	
   synthesizer	
   natural	
   language	
   generator	
   dialogue	
   state	
   tracker	
   dialogue	
   response	
   selec   on	
   2.2 tasks and objectives

dialogue systems have been built for a wide range of purposes. a useful distinction can be made
between goal-driven dialogue systems, such as technical support services, and non-goal-driven dia-
logue systems, such as language learning tools or computer game characters. although both types
of systems do in fact have objectives, typically the goal-driven dialogue systems have a well-de   ned
measure of performance that is explicitly related to task completion.

non-goal-driven dialogue systems. research on non-goal-driven dialogue systems goes back
to the mid-60s. it began, perhaps, with weizenbaum   s famous program eliza, a system based only
on simple text parsing rules that managed to convincingly mimic a rogerian psychotherapist by
persistently rephrasing statements or asking questions (weizenbaum, 1966). this line of research
was continued by colby (1981), who used simple text parsing rules to construct the dialogue system
parry, which managed to mimic the pathological behaviour of a paranoid patient to the extent that
clinicians could not distinguish it from real patients. however, neither of these two systems used
data-driven learning approaches. later work, such as the megahal system by hutchens and alder
(1998), started to apply data-driven methods (shawar and atwell, 2007b). hutchens and alder
(1998) proposed modelling dialogue as a stochastic sequence of discrete symbols (words) using
4   th order markov chains. given a user utterance, their system generated a response by following
a two-step procedure:    rst, a sequence of topic keywords, used to create a seed reply, was ex-
tracted from the user   s utterance; second, starting from the seed reply, two separate markov chains
generated the words preceding and proceeding the seed keywords. this procedure produced many
candidate responses, from which the highest id178 response was returned to the user. under the
assumption that the coverage of different topics and general    uency is of primary importance, the
4   th order markov chains were trained on a mixture of data sources ranging from real and    ctive
dialogues to arbitrary texts. unfortunately, until very recently, such data-driven dialogue systems
were not applied widely in real-world applications (perez-marin and pascual-nieto, 2011; shawar
and atwell, 2007b). part of the reason for this might be due to their non-goal-driven nature, which
made them hard to commercialize. another barrier to commercialization might have been the lack
of theoretical and empirical understanding of such systems. nevertheless, in a similar spirit over the
past few years, neural network architectures trained on large-scale corpora have been investigated.
these models have demonstrated promising results for several non-goal-driven dialogue tasks (rit-
ter et al., 2011; vinyals and le, 2015; lowe et al., 2015a; sordoni et al., 2015b; shang et al., 2015;
li et al., 2015; serban et al., 2016; serban et al., 2017b,a; dodge et al., 2015; williams and zweig,
2016; weston, 2016). however, they require having suf   ciently large corpora     in the hundreds of
millions or even billions of words     in order to achieve these results.

goal-driven dialogue systems. initial work on goal-driven dialogue systems was primarily
based on deterministic hand-crafted rules coupled with learned id103 models (e.g. off-
the-shelf id103 software). one example is the sundial project, which was capable
of providing timetable information about trains and airplanes, as well as taking airplane reserva-
tions (aust et al., 1995; mcglashan et al., 1992; simpson and eraser, 1993). later, machine learn-
ing techniques were used to classify the intention (or need) of the user, as well as to bridge the
gap between text and speech (e.g. by taking into account uncertainty related to the outputs of the
id103 model) (gorin et al., 1997). research in this area started to take off during the
mid 1990s, when researchers began to formulate dialogue as a sequential decision making problem
based on id100 (singh et al., 1999; young et al., 2013; paek, 2006; pieraccini

4

et al., 2009). unlike non-goal-driven systems, industry played a major role and enabled researchers
to have access to (at the time) relatively large dialogue corpora for certain tasks, such as recordings
from technical support call centres. although research in the past decade has continued to push the
   eld towards data-driven approaches, commercial systems are highly domain-speci   c and heavily
based on hand-crafted rules and features (young et al., 2013). in particular, many of the tasks and
datasets available are constrained to narrow domains.

2.3 learning dialogue system components

modern dialogue systems consist of several components, as illustrated in figure 1. several of the
dialogue system components can be learned through so-called discriminative models, which aim to
predict labels or annotations relevant to other parts of the dialogue system. discriminative models
fall into the machine learning paradigm of supervised learning. when the labels of interest are
discrete, the models are called classi   cation models, which is the most common case. when the
labels of interest are continuous, the models are called regression models. one popular approach
for tackling the discriminative task is to learn a probabilistic model of the labels conditioned on the
available information p (y |x), where y is the label of interest (e.g. a discrete variable representing
the user intent) and x is the available information (e.g. utterances in the conversation). another
popular approach is to use maximum margin classi   ers, such as support vector machines (cristianini
and shawe-taylor, 2000).

although it is beyond the scope of this paper to provide a survey over such system components,
we now give a brief example of each component. this will motivate and facilitate the dataset
analysis.

natural language interpreter. an example of a discriminative model is the user intent clas-
si   cation model, which acts as the natural language interpreter. this model is trained to predict
the intent of a user conditioned on the utterances of that user. in this case, the intent is called the
label (or target or output), and the conditioned utterances are called the conditioning variables (or
inputs). training this model requires examples of pairs of user utterances and intentions. one way
to obtain these example pairs would be to    rst record written dialogues between humans carrying
out a task, and then to have humans annotate each utterance with its intention label. depending
on the complexity of the domain, this may require training the human annotators to reach a certain
level of agreement between annotators.

dialogue state tracker. a dialogue state tracker might similarly be implemented as a classi-
   cation model (williams et al., 2013). at any given point in the dialogue, such a model will take as
input all the user utterances and user intention labels estimated by a natural language interpreter
model so far and output a distribution over possible dialogue states. one common way to represent
dialogue states are through slot-value pairs. for example, a dialogue system providing timetable
information for trains might have three different slots: departure city, arrival city, and departure
time. each slot may take one of several discrete values (e.g. departure city could take values from
a list of city names). the task of the dialogue state tracker is then to output a distribution over
every possible combination of slot-value pairs. this distribution     or alternatively, the k dialogue
states with the highest id203     may then be used by other parts of the dialogue system. the
dialogue state tracker model can be trained on examples of dialogue utterances and dialogue states
labelled by humans.

5

dialogue response selection. given the dialogue state distribution provided by the dialogue
state tracker, the dialogue response selection component must select the correct system response
(or action). this component may also be implemented as a classi   cation model that maps dialogue
states to a id203 over a discrete set of responses. for example, in a dialogue system provid-
ing timetable information for trains, the set of responses might include providing information (e.g.
providing the departure time of the next train with a speci   c departure and arrival city) and clari   -
cation questions (e.g. asking the user to re-state their departure city). the model may be trained on
example pairs of dialogue states and responses.

natural language generator. given a dialogue system response (e.g. a response providing
the departure time of a train), the natural language generator must output the natural language
utterance of the system. this has often been implemented in commercial goal-driven dialogue
systems using hand-crafted rules. another option is to learn a discriminative model to select a
natural language response.
in this case, the output space may be de   ned as a set of so-called
surface form sentences (e.g.    the requested train leaves city x at time y   , where x and y are
placeholder values). given the system response, the classi   cation model must choose an appropriate
surface form. afterwards, the chosen surface form will have the placeholder values substituted in
appropriately (e.g. x will be replaced by the appropriate city name through a database look up). as
with other classi   cation models, this model may be trained on example pairs of system responses
and surface forms.

discriminative models have allowed goal-driven dialogue systems to make signi   cant progress
(williams et al., 2013). with proper annotations, discriminative models can be evaluated automat-
ically and accurately. furthermore, once trained on a given dataset, these models may be plugged
into a fully-deployed dialogue system (e.g. a classi   cation model for user intents may be used as
input to a dialogue state tracker).

2.4 end-to-end dialogue systems

not all dialogue systems conform to the architecture shown in figure 1. in particular, so-called
end-to-end dialogue system architectures based on neural networks have shown promising results
on several dialogue tasks (ritter et al., 2011; vinyals and le, 2015; lowe et al., 2015a; sordoni
et al., 2015b; shang et al., 2015; li et al., 2015; serban et al., 2016; serban et al., 2017b,a; dodge
et al., 2015). in their purest form, these models take as input a dialogue in text form and output
a response (or a distribution over responses). we call these systems end-to-end dialogue systems
because they possess two important properties. first, they do not contain or require learning any
sub-components (such as natural language interpreters or dialogue state trackers). consequently,
there is no need to collect intermediate labels (e.g. user intention or dialogue state labels). second,
all model parameters are optimized w.r.t. a single objective function. often the objective function
chosen is maximum log-likelihood (or cross-id178) on a    xed corpus of dialogues. although in
the original formulation these models depended only on the dialogue context, they may be extended
to also depend on outputs from other components (e.g. outputs from the id103 tracker),
and on external knowledge (e.g. external databases).

end-to-end dialogue systems can be divided into two categories: those that select deterministi-
cally from a    xed set of possible responses, and those that attempt to generate responses by keeping
a posterior distribution over possible utterances. systems in the    rst category map the dialogue his-
tory, tracker outputs and external knowledge (e.g. a database, which can be queried by the system)

6

to a response action:

f   : {dialogue history, tracker outputs, external knowledge}     action at,

(1)

where at is the dialogue system response action at time t, and    is the set of parameters that de   nes
f. information retrieval and ranking-based systems     systems that search through a database of
dialogues and pick responses with the most similar context, such as the model proposed by banchs
and li (2012)     belong to this category. in this case, the mapping function f   projects the dialogue
history into a euclidean space (e.g. using tf-idf bag-of-words representations). the response is
then found by projecting all potential responses into the same euclidean space, and the response
closest to the desirable response region is selected. the neural network proposed by lowe et al.
(2015a) also belongs to this category. in this case, the dialogue history is projected into a euclidean
space using a recurrent neural network encoding the dialogue word-by-word. similarly, a set of can-
didate responses are mapped into the same euclidean space using another recurrent neural network
encoding the response word-by-word. finally, a relevance score is computed between the dialogue
context and each candidate response, and the response with the highest score is returned. hybrid
or combined models, such as the model built on both a phrase-based id151
system and a recurrent neural network proposed by sordoni et al. (2015b), also belong to this cate-
gory. in this case, a response is generated by deterministically creating a    xed number of answers
using the machine translation system and then picking the response according to the score given
by a a neural network. although both of its sub-components are based on probabilistic models, the
   nal model does not construct a id203 distribution over all possible responses.1

in contrast to a deterministic system, a generative system explicitly computes a full posterior

id203 distribution over possible system response actions at every turn:

p  (action at | dialogue history, tracker outputs, external knowledge).

(2)

systems based on generative recurrent neural networks belong to this category (vinyals and le,
2015). by breaking down eq. (2) into a product of probabilities over words, responses can be
generated by sampling word-by-word from their id203 distribution. unlike the deterministic
response models, these systems are also able to generate entirely novel responses (e.g. by sampling
word-by-word). highly probable responses, i.e. the response with the highest id203, can fur-
ther be generated by using a method known as beam-search (graves, 2012). these systems project
each word into a euclidean space (known as a id27) (bengio et al., 2003); they also
project the dialogue history and external knowledge into a euclidean space (wen et al., 2015; lowe
et al., 2015b). similarly, the system proposed by ritter et al. (2011) belongs to this category. their
model uses a id151 model to map a dialogue history to its response. when
trained solely on text, these generative models can be viewed as unsupervised learning models,
because they aim to reproduce data distributions. in other words, the models learn to assign a prob-
ability to every possible conversation, and since they generate responses word by word, they must
learn to simulate the behaviour of the agents in the training corpus.

early id23 dialogue systems with stochastic policies also belong to this cat-
egory (the njfun system (singh et al., 2002) is an example of this).
in contrast to the neural
network and id151 systems, these id23 systems typically

1. although the model does not require intermediate labels, it consists of sub-components whose parameters are trained

with different objective functions. therefore, strictly speaking, this is not an end-to-end model.

7

have very small sets of possible hand-crafted system states (e.g. hand-crafted features describing
the dialogue state). the action space is also limited to a small set of pre-de   ned responses. this
makes it possible to apply established id23 algorithms to train them either online
or of   ine, however it also severely limits their application area. as singh et al. (singh et al., 2002,
p.5) remark:    we view the design of an appropriate state space as application-dependent, and a task
for a skilled system designer.   

3. dialogue interaction types & aspects

this section provides a high-level discussion of different types of dialogue interactions and their
salient aspects. the categorization of dialogues is useful for understanding the utility of various
datasets for particular applications, as well as for grouping these datasets together to demonstrate
available corpora in a given area.

3.1 written, spoken & multi-modal corpora

an important distinction between dialogue corpora is whether participants (interlocutors) interact
through written language, spoken language, or in a multi-modal setting (e.g. using both speech and
visual modalities). written and spoken language differ substantially w.r.t. their linguistic properties.
.spoken language tends to be less formal, containing lower information content and many more
pronouns than written language (carter and mccarthy, 2006; biber and finegan, 2001, 1986). in
particular, the differences are magni   ed when written language is compared to spoken face-to-
face conversations, which are multi-modal and highly socially situated. as biber and finegan
(1986) observed, pronouns, questions, and contradictions, as well as that-clauses and if-clauses,
appear with a high frequency in face-to-face conversations. forchini (2012) summarized these
differences:    ... studies show that face-to-face conversation is interpersonal, situation-dependent
has no narrative concern or as biber and finegan (1986) put it, is a highly interactive, situated
and immediate text type...    due to these differences between spoken and written language, we will
emphasize the distinction between dialogue corpora in written and spoken language in the following
sections.

similarly, dialogues involving visual and other modalities differ from dialogues without these
modalities (card et al., 1983; goodwin, 1981). when a visual modality is available     for example,
when two human interlucators converse face-to-face     body language and eye gaze has a signi   cant
impact on what is said and how it is said (gibson and pick, 1963; lord and haith, 1974; cooper,
1974; chartrand and bargh, 1999; de kok et al., 2013). aside from the visual modality, dialogue
systems may also incorporate other situational modalities, including aspects of virtual environments
(rickel and johnson, 1999; traum and rickel, 2002) and user pro   les (li et al., 2016).

3.2 human-human vs. human-machine corpora

another important distinction between dialogue datasets resides in the types of interlocutors    
notably, whether it involves interactions between two humans, or between a human and a computer2.
the distinction is important because current arti   cial dialogue systems are signi   cantly constrained.

2. machine-machine dialogue corpora are not of interest to us, because they typically differ signi   cantly from natural

human language. furthermore, user simulation models are outside the scope of this survey.

8

these systems do not produce nearly the same distribution of possible responses as humans do under
equivalent circumstances. as stated by williams and young (2007):

(human-human conversation) does not contain the same distribution of understanding
errors, and human   human turn-taking is much richer than human-machine dialog. as
a result, human-machine dialogue exhibits very different traits than human-human dia-
logue (doran et al., 2001; moore and browning, 1992).

the expectation a human interlucator begins with, and the interface through which they interact,
also affect the nature of the conversation (j. and d., 1988).

for goal-driven settings, williams and young (2007) have previously argued against building
data-driven dialogue systems using human-human dialogues:    ... using human-human conversation
data is not appropriate because it does not contain the same distribution of understanding errors,
and because human-human turn-taking is much richer than human-machine dialog.    this line
of reasoning seems particularly applicable to spoken dialogue systems, where id103
errors can have a critical impact on performance and therefore must be taken into account when
learning the dialogue model. the argument is also relevant to goal-driven dialogue systems, where
an effective dialogue model can often be learned using id23 techniques. williams
and young (2007) also argue against learning from corpora generated between humans and existing
dialogue systems:    while it would be possible to use a corpus collected from an existing spoken
dialogue system, supervised learning would simply learn to approximate the policy used by that
spoken dialogue system and an overall performance improvement would therefore be unlikely.   

thus, it appears, for goal-driven spoken dialogue systems in particular, that the most effective
strategy is learning online through interaction with real users. nonetheless, there exists useful
human-machine corpora where the interacting machine uses a stochastic policy that can generate
suf   cient coverage of the task (e.g. enough good and enough bad dialogue examples) to allow an
effective dialogue model to be learned. in this case, the goal is to learn a policy that is eventually
better than the original stochastic policy used to generate the corpus through a process known as
id64.

in this survey we focus on data-driven learning from human-human and human-machine di-
alogue corpora. despite the advantages of learning online through interactions with real users,
learning based on human-human dialogue corpora may be more suitable for open domain dialogue
systems because they re   ect natural dialogue interactions. by natural dialogues, we mean conver-
sations that are unconstrained and unscripted, e.g. between interlocutors who are not instructed to
carry out a particular task, to follow a series of instructions, or to act out a scripted dialogue. in this
setting, the dialogue process is relatively unaffected by researchers, e.g. the interlocutors are not in-
terrupted by question prompts in the middle of a dialogue. as can be expected, such conversations
include a signi   cant amount of turn-taking, pauses and common grounding phenomena (clark and
brennan, 1991). additionally, they are more diverse, and open up the possibility for the model to
learn to understand natural language.

3.3 natural vs. unnatural corpora
the way in which a dialogue corpus is generated and collected can have a signi   cant in   uence on the
trained data-driven dialogue system. in the case of human-human dialogues, an ideal corpus should
closely resemble natural dialogues between humans. arguably, this is the case when conversations

9

between humans are recorded and transcribed, and when the humans in the dialogue represent the
true population of users with whom the dialogue system is intended to interact. it is even better
if they are unaware of the fact that they are being recorded, but this is not always possible due to
ethical considerations and resource constraints.

due to ethical considerations and resource constraints, researchers may be forced to inform the
human interlocutors that they are being recorded or to setup arti   cial experiments in which they
hire humans and instruct them to carry out a particular task by interacting with a dialogue system.
in these cases, there is no guarantee that the interactions in the corpus will re   ect true interactions,
since the hired humans may behave differently from the true user population. one factor that may
cause behavioural differences is the fact that the hired humans may not share the same intentions
and motivations as the true user population (young et al., 2013). the unnaturalness may be further
exacerbated by the hiring process, as well as the platform through which they interact. such factors
are becoming more prevalent as researchers increasingly rely on id104 platforms, such as
amazon mechanical turk, to collect and evaluate dialogue data (jurc  cek et al., 2011).

in the case of wizard-of-oz experiments (bohus and rudnicky, 2008; petrik, 2004), a human
thinks (s)he is speaking to a machine, but a human operator is in fact controlling the dialogue system.
this enables the generation of datasets that are closer in nature to the dialogues humans may wish
to have with a good ai dialogue system. unfortunately, such experiments are expensive and time-
consuming to carry out. ultimately the impact of any unnaturalness in the dialogues depends on the
task and context in which the dialogue system is deployed.

3.4 corpora from fiction

it is also possible to use arti   cial dialogue corpora for data-driven learning. this includes cor-
pora based on works of    ction such as novels, movie manuscripts and audio subtitles. however,
unlike transcribed human-human conversations, novels, movie manuscripts, and audio subtitles de-
pend upon events outside the current conversation, which are not observed. this makes data-driven
learning more dif   cult because the dialogue system has to account for unknown factors. the same
problem is also observed in certain other media, such as microblogging websites (e.g. twitter and
weibo), where conversations also may depend on external unobserved events.

nevertheless, recent studies have found that spoken language in movies resembles spontaneous
human spoken language (forchini, 2009). although movie dialogues are explicitly written to be
spoken and contain certain arti   cial elements, many of the linguistic and paralinguistic features
contained within the dialogues are similar to natural spoken language, including dialogue acts such
as turn-taking and reciprocity (e.g. returning a greeting when greeted). the arti   cial differences that
exist may even be helpful for data-driven dialogue learning since movie dialogues are more compact,
follow a steady rhythm, and contain less garbling and repetition, all while still presenting a clear
event or message to the viewer (dose, 2013; forchini, 2009, 2012). unlike dialogues extracted from
wizard-of-oz human experiments, movie dialogues span many different topics and occur in many
different environments (webb, 2010). they contain different actors with different intentions and
relationships to one another, which could potentially allow a data-driven dialogue system to learn to
personalize itself to different users by making use of different interaction patterns (li et al., 2016).

10

3.5 corpus size

as in other machine learning applications such as machine translation (al-onaizan et al., 2000;
g  ulc  ehre et al., 2015) and id103 (deng and li, 2013; bengio et al., 2014), the size of
the dialogue corpus is important for building an effective data-driven dialogue (lowe et al., 2015a;
serban et al., 2016).

there are two primary perspectives on the importance of dataset size for building data-driven
dialogue systems. the    rst perspective comes from the machine learning literature: larger datasets
place constraints on the dialogue model trained from that data. datasets with few examples may
require strong structural priors placed on the model, such as using a modular system, while large
datasets can be used to train end-to-end dialogue systems with less a priori structure. the second
comes from a statistical natural language processing perspective: since the statistical complexity of a
corpus grows with the linguistic diversity and number of topics, the number of examples required by
a machine learning algorithm to model the patterns in it will also grow with the linguistic diversity
and number of topics. consider two small datasets with the same number of dialogues in the domain
of bus schedule information: in one dataset the conversations between the users and operator is
natural, and the operator can improvise and chitchat; in the other dataset, the operator reads from a
script to provide the bus information. despite having the same size, the second dataset will have less
linguistic diversity and not include chitchat topics. therefore, it will be easier to train a data-driven
dialogue system mimcking the behaviour of the operator in the second dataset, however it will also
exhibit a highly pedantic style and not be able to chitchat. in addition to this, to have an effective
discussion between any two agents, their common knowledge must be represented and understood
by both parties. the process of establishing this common knowledge, also known as grounding,
is especially critical to repair misunderstandings between humans and dialogue systems (cahn and
brennan, 1999). since the number of misunderstandings can grow with the lexical diversity and
number of topics (e.g. misunderstanding the paraphrase of an existing word, or misunderstanding a
rarely seen keyword), the number of examples required to repair these grow with linguistic diversity
and topics. in particular, the effect of linguistic diversity has been observed in practice: vinyals
and le (2015) train a simple encoder-decoder neural network on a proprietary dataset of technical
support dialogues. although it has a similar size and purpose as the ubuntu dialogue corpus (lowe
et al., 2015a), the qualitative examples shown by vinyals and le (2015) are signi   cantly superior
to those obtained by more complex models on the ubuntu corpus (serban et al., 2017a). this
result may likely be explained in part due to the fact that technical support operators often follow a
comprehensive script for solving problems. as such, the script would reduce the linguistic diversity
of their responses.

furthermore, since the majority of human-human dialogues are multi-modal and highly am-
biguous in nature (chartrand and bargh, 1999; de kok et al., 2013), the size of the corpus may
compensate for some of the ambiguity and missing modalities. if the corpus is suf   ciently large,
then the resolved ambiguities and missing modalities may, for example, be approximated using
latent stochastic variables (serban et al., 2017b). thus, we include corpus size as a dimension
of analysis. we also discuss the bene   ts and drawbacks of several popular large-scale datasets in
section 5.1.

11

4. available dialogue datasets

there is a vast amount of data available documenting human communication. much of this data
could be used     perhaps after some pre-processing     to train a dialogue system. however, cov-
ering all such sources of data would be infeasible. thus, we restrict the scope of this survey to
datasets that have already been used to study dialogue or build dialogue systems, and to very large
corpora of interactions   that may or may not be strictly considered dialogue datasets   which could
be leveraged in the near future to build more sophisticated data-driven dialogue models. we restrict
the selection further to contain only corpora generated from spoken or written english, and to cor-
pora which, to the best of our knowledge, either are publicly available or will be made available in
the near future. we    rst give a brief overview of each of the considered corpora, and later high-
light some of the more promising examples, explaining how they could be used to further dialogue
research.3

the dialogue datasets analyzed in this paper are listed in tables 1-5. column features indicate
properties of the datasets, including the number of dialogues, average dialogue length, number of
words, whether the interactions are between humans or with an automated system, and whether
the dialogues are written or spoken. below, we discuss qualitative features of the datasets, while
statistics can be found in the aforementioned table.

4.1 human-machine corpora

as discussed in subsection 3.2, an important distinction between dialogue datasets is whether they
consist of dialogues between two humans or between a human and a machine. thus, we begin by
outlining some of the existing human-machine corpora in several categories based on the types of
systems the humans interact with: restaurant and travel information, open-domain knowledge
retrieval, and other specialized systems. note, we also include human-human corpora here where
one human plays the role of the machine in a wizard-of-oz fashion.

4.1.1 restaurant and travel information

one common theme in human-machine language datasets is interaction with systems which provide
restaurant or travel information. here we   ll brie   y describe some human-machine dialogue datasets
in this domain.

one of the most popular recent sources of such data has come from the datasets for structured
dialogue prediction released in conjunction with the dialog state tracking challenge (dstc)
(williams et al., 2013). as the name implies, these datasets are used to learn a strategy for the di-
alogue state tracker (sometimes called    belief tracking   ), which involves estimating the intentions
of a user throughout a dialog. state tracking is useful as it can increase the robustness of speech
recognition systems, and can provide an implementable framework for real-world dialogue sys-
tems. particularly in the context of goal-oriented dialogue systems (such as those providing travel
and restaurant information), state tracking is necessary for creating coherent conversational inter-
faces. as such, the    rst three datasets in the dstc   referred to as dstc1, dstc2, and dstc3
respectively   are medium-sized spoken datasets obtained from human-machine interactions with

3. we form a live list of the corpora discussed in this work, along with links to downloads, at: http://breakend.
github.io/dialogdatasets. pull requests can be made to the github repository (https://github.
com/breakend/dialogdatasets) hosting the website for continuing updates to the list of corpora.

12

restaurant and travel information systems. all datasets provide labels specifying the current goal
and desired action of the system.

dstc1 (williams et al., 2013) features conversations with an automated bus information in-
terface, where users request bus routes from the system and the system responds with clarifying
queries or the desired information. dstc2 introduces changing user goals in a restaurant booking
system, while trying to provide a desired reservation(henderson et al., 2014b). dstc3 introduces
a small amount of labelled data in the domain of tourist information. it is intended to be used in
conjunction with the dstc2 dataset as a id20 problem (henderson et al., 2014a).

the carnegie mellon communicator corpus (bennett and rudnicky, 2002) also contains
human-machine interactions with a travel booking system. it is a medium-sized dataset of interac-
tions with a system providing up-to-the-minute    ight information, hotel information, and car rentals.
conversations with the system were transcribed, along with the user   s comments at the end of the
interaction.

the atis (air travel information system) pilot corpus (hemphill et al., 1990) is one of
the    rst human-machine corpora. it consists of interactions, lasting about 40 minutes each, between
human participants and a travel-type booking system, secretly operated by humans. unlike the
carnegie mellon communicator corpus, it only contains 1041 utterances.

in the maluuba frames corpus (el asri et al., 2017), one user plays the role of a conversa-
tional agent in a wizard-of-oz fashion, while the other user is tasked with    nding available travel or
vacation accommodations according to a pre-speci   ed task. the wizard is provided with a knowl-
edge database which recorded their actions. semantic frames are annotated in addition to actions
which the wizard performed on the database to accompany a line of dialogue. in this way, the
frames corpus aims to track decision-making processes in travel- and hotel-booking through natu-
ral dialog.

4.1.2 open-domain knowledge retrieval
knowledge retrieval and question & answer (qa) corpora are a broad distinction of corpora that
we will not extensively review here. instead, we include only those qa corpora which explicitly
record interactions of humans with existing systems. the ritel corpus (rosset and petel, 2006) is
a small dataset of 528 dialogs with the wizard-of-oz ritel platform. the project   s purpose was to
integrate spoken language dialogue systems with open-domain information retrieval systems, with
the end goal of allowing humans to ask general questions and iteratively re   ne their search. the
questions in the corpus mostly revolve around politics and the economy, such as    who is currently
presiding the senate?   , along with some conversations about arts and science-related topics.

other similar open-domain corpora in this area include wikiqa yang et al. (2015) and ms
marco nguyen et al. (2016), which compile responses from automated bing searches and hu-
man annotators. however, these do not record dialogs, but rather simply gather possible responses
to queries. as such, we won   t discuss these datasets further, but rather mention them brie   y as
examples of other open-domain corpora in the    eld.

13

.
e
c
n
a
r
e
t
t
u

r
e
p

s
d
r
o
w

f
o

r
e
b
m
u
n

e
g
a
r
e
v
a

e
h
t

n
o

d
e
s
a
b

d
e
t
a
m
i
x
o
r
p
p
a

e
r
a

s
r
e
b
m
u
n

)
*
(

d
e
r
r
a
t
s

.
s
t
e
s
a
t
a
d

e
u
g
o
l
a
i
d

.

n
a
m
u
h
a

y
b

d
e
t
a
r
e
p
o
y
l
t
e
r
c
e
s

s
i

e
n
i
h
c
a
m
e
h
t

e
r
e
h
w

,
s
e
u
g
o
l
a
i
d

z
o

-
f
o
-
d
r
a
z
i

w

e
t
a
c
i
d
n
i

)

(

h
t
i

w
d
e
k
r
a
m

s
t
e
s
a
t
a
d

   

m
e
t
s
y
s
g
n
i
k
o
o
b

d
n
a

g
n
i
n
n
a
l
p
l
e
v
a
r
t

m
e
t
s
y
s

n
o
i
t
a
m
r
o
f
n
i

e
d
i
r

s
u
b

m
e
t
s
y
s
g
n
i
k
o
o
b
t
n
a
r
u
a
t
s
e
r

s
t
s
i
r
u
o
t

r
o
f

n
o
i
t
a
m
r
o
f
n
i

m
7
3

.

k
2
3
4

k
3
0
4

*
m
2

m
e
t
s
y
s
g
n
i
k
o
o
b

d
n
a

g
n
i
n
n
a
l
p
l
e
v
a
r
t

*
k
4
1
1

.

m
e
t
s
y
s

r
e
t
u
p
m
o
c

h
t
i

w

t
c
a
r
e
t
n
i

s
n
a
m
u
h

g
n
i
v
o
r
p
m
e
r
o
e
h
t

l
a
c
i
t
a
m
e
h
t
a
m
o
d
o
t

.
s
t
n
e
m
t
n
i
o
p
p
a

g
n
i
l
u
d
e
h
c
s

r
o
f

m
e
t
s
y
s
a

n
o
i
t
s
e
u
q

n
i
a
m
o
d
-
n
e
p
o

d
e
t
a
t
o
n
n
a

n
a

m
e
t
s
y
s

e
u
g
o
l
a
i
d

n
e
k
o
p
s

g
n
i
r
e
w
s
n
a

.

d
e
t
a
t
o
n
n
a

e
s
a
b
-
e
g
d
e
l
w
o
n
k
a

n
o
n
e
k
a
t

s
n
o
i
t
c
a
d
n
a

d
e
l
e
b
a
l

s
e
m
a
r
f

c
i
t
n
a
m
e
s

s
n
o
i
t
a
t
o
n
n
a

t
c
a

e
u
g
o
l
a
i
d
s
e
d
u
l
c
n
i

.
s
m
e
t
s
y
s

e
u
g
o
l
a
i
d

n
e
v
i
r
d
-
l
a
o
g

r
o
f

k
0
6

*
k
7
8

.

*
k
9
6

0
0
0

,

5
1

0
0
0

,

3

5
6
2

,

2

1
8
4

,

5
1

1
4

2
8
5

6
6

7
4
4

   

9
6
3
1

n
o
i
t
p
i
r
c
s
e
d

#

l
a
t
o
t

s
d
r
o
w

f
o

#

l
a
t
o
t

s
e
u
g
o
l
a
i
d

f
o

#

.

g
v
a

s
n
r
u
t

f
o

6
5

.

3
1

8
8

.

7

7
2

.

8

7
6

.

1
1

4

.

5
2

*
3

.

9

2
1

0

.

4
1

5
1

n
o
i
t
a
m
r
o
f
n
i

t
s
i
r
u
o
t

s
e
l
u
d
e
h
c
s

s
u
b

s
t
n
a
r
u
a
t
s
e
r

s
c
i
p
o
t

l
e
v
a
r
t

l
e
v
a
r
t

s
c
i
p
o
t
e
s
r
e
v
i
d

/
d
e
t
c
i
r
t
s
e
r
n
u

g
n
i
l
u
d
e
h
c
s

t
n
e
m
t
n
i
o
p
p
a

s
c
i
t
a
m
e
h
t
a

m

n
e
k
o
p
s

n
e
k
o
p
s

n
e
k
o
p
s

n
e
k
o
p
s

n
e
k
o
p
s

n
e
k
o
p
s

n
e
k
o
p
s

n
e
k
o
p
s

e
p
y
t

n
o
i
t
a
c
a
v
&

l
e
v
a
r
t

&
a
q

,
t
a
h
c

g
n
i
k
o
o
b

n
o
i
t
a
d
n
e
m
m
o
c
e
r

)
b
4
1
0
2

)
a
4
1
0
2

,
.
l
a

,
.
l
a

t
e
n
o
s
r
e
d
n
e
h

(

t
e
n
o
s
r
e
d
n
e
h

(

)
3
1
0
2

,
.
l
a

t
e

s

m
a
i
l
l
i

w

(

1
c
t
s
d

2
c
t
s
d

3
c
t
s
d

s
u
p
r
o
c

r
o
t
a
c
i
n
u
m
m
o
c
u
m
c

e
m
a
n

)
2
0
0
2

,

y
k
c
i
n
d
u
r
d
n
a

t
t
e
n
n
e
b

(

)
0
9
9
1

,
.
l
a

t
e

   

s
u
p
r
o
c

   

t
o
l
i
p
s
i
t
a

l
l
i
h
p
m
e
h

(

s
u
p
r
o
c

l
e
t
i

r

e
n
i
h
c
a
m
-
n
a
m
u
h

:
1

e
l
b
a
t

)
7
1
0
2

,
.
l
a

t
e

i
r
s
a

l

e
(

)
0
1
0
2

,
.
l
a

t
e

a
l
i
g
r
o
e
g

(

   

s
e
m
a
r
f
a
b
u
u
l
a

m

)
4
0
0
2

,
.
l
a

t
e

   

s
u
p
r
o
c
h
c
t
a
m

a
k
s
l
o
w

(

s
f
o
o
r
p

)
6
0
0
2

,
l
e
t
e
p
d
n
a

t
e
s
s
o
r

(

l
a
c
i
t
a
m
e
h
t
a

m
g
o
l
a
d

i

14

y
l
l
a
b
r
e
v

e
t
a
r
o
b
a
l
l
o
c

t
s
u
m
s
r
e
k
a
e
p
s

h
c
i
h
w
n
i
k
s
a
t
p
a
l
h
m
o
r
f

s
e
u
g
o
l
a
i
d

.
s
r
e
h
t
o

e
h
t

n
o
d
e
t
n
i
r
p

e
t
u
o
r

a

p
a
m
s
t
n
a
p
i
c
i
t
r
a
p

e
n
o
n
o

e
c
u
d
o
r
p
e
r

o
t

n
o
i
t
p
i
r
c
s
e
d

l
a
t
o
t

h
t
g
n
e
l

s
r
h
8
1

#

l
a
t
o
t

s
d
r
o
w

f
o

k
7
4
1

.
s
e
t
a
b
e
d
-
t
s
o
p

d
n
a

-
e
r
p
d
e
d
i
v
o
r
p

s
n
o
i
n
i
p
o

e
c
n
e
i
d
u
a

.
t
c
e
j
b
u
s

e
n
o

o
t

e
c
n
i
v
n
o
c

o
t

s
e
i
r
t

s
g
n
i
l
e
e
f

n
e
e
r
g
-
o
r
p

g
n
o
r
t
s

)
y
l
e
n
i
u
n
e
g
(

h
t
i

w

r
e
d
a
u
s
r
e
p
a

s
r
h
4

*
k
5
3

.
s
e
l
y
t
s
e
f
i
l

n
e
e
r
g

e
r
o
m
g
n
i
t
p
o
d
a

r
e
d
i
s
n
o
c
o
t

s
e
e
d
a
u
s
r
e
p

d
e
n
i
a
r
t
s
n
o
c

h
c
a
e

,
s
e
t
a
b
e
d

e
l
y
t
s
-
d
r
o
f
x
o
n
i

s
c
i
p
o
t

s
u
o
i
r
a
v

*
s
r
h
0
0
2

m
8

.

1

e
s
u
o
h
e
t
i
h
w
d
n
a

s
g
n
i
t
e
e
m
y
t
l
u
c
a
f

m
o
r
f

s
n
o
i
t
c
a
r
e
t
n
i

*
s
r
h
0
2
2

m
2

r
o
t
a
r
e
p
o
n
a

h
t
i

w
s
n
o
i
t
a
s
r
e
v
n
o
c

g
n
i
d
l
o
h

e
l
i
h
w
d
e
d
r
o
c
e
r

e
r
e
w
s
r
e
s
u

s
r
h
0
5

*
k
0
5
4

s
n
o
i
t
a
t
o
n
n
a

h
t
i

w
e
m
a
g
g
n
i
y
a
l
p
-
e
l
o
r

f
l
o
w
e
r
e

w

f
o

g
n
i
d
r
o
c
e
r

a

s
r
h
7

*
k
0
6

.
s
s
e
r
g
o
r
p

e
m
a
g

o
t

d
e
t
a
l
e
r

a

d
n
a

,
c
i
p
o
t

l
a
c
i
t
i
l
o
p
a

n
o

n
o
i
s
s
u
c
s
i
d
a

:
s
t
n
e
m

i
r
e
p
x
e

o
w
t

s
r
h
1
1

*
k
0
0
1

.
e
m
a
g

g
n
i
y
a
l
p
-
e
l
o
r

.
s
e
c
n
e
r
e
f
n
o
c

s
s
e
r
p

,
)
s
t
i
n
u

e
s
r
u
o
c
s
i
d
(

s
e
m
a
r
f

,
s
c
i
p
o
t

n
o
i
s
s
u
c
s
i
d

,
s
t
c
a

e
u
g
o
l
a
i
d

.
s
n
o
r
t
a
p
d
n
a

s
n
a
i
r
a
r
b
i
l

n
e
e
w
t
e
b

s
n
o
i
t
c
a
r
e
t
n
i

e
n
o
h
p
e
l
e
t

d
e
t
a
t
o
n
n
a

*
0
4
1

.
s
n
o
i
t
c
a
e
r

l
a
n
o
i
t
o
m
e

e
k
o
v
e
o
t

d
e
n
g
i
s
e
d
s
e
l
o
r

s
t
p
o
d
a

o
h
w

.
e
p
y
k
s
r
e
v
o
e
g
n
a
h
c
x
e

n
o
i
t
a
m
r
o
f
n
i

t
s
i
r
u
o
t

s
r
h
1
2

k
3
7
2

k
1
2

.
s
n
o
i
t
a
c
o
l

n
i
a
t
r
e
c

d
n
   
o
t

e
n
o
h
p
e
l
e
t

r
e
v
o
g
n
i
t
a
r
o
b
a
l
l
o
c

e
l
p
o
e
p

s
r
h
3
3

*
k
0
0
3

f
o
s
e
i
r
o
e
h
t

d
n
a

g
n
i
s
s
e
c
o
r
p

e
g
a
u
g
n
a
l

,
f
l
e
s
t
i

t
c
e
j
o
r
p

s
u
p
r
o
c

e
h
t

:
e
d
u
l
c
n
i

s
c
i
p
o
t

l
a
r
u
t
a
n

,

n
o
i
t
i
n
g
o
c
e
r

h
c
e
e
p
s

.
s
t
o
p
s

t
o
h

d
n
a

,
s
r
i
a
p

r
e
w
s
n
a
-
n
o
i
t
s
e
u
q

,
s
t
c
a

e
u
g
o
l
a
i
d

c
i
t
a
m
o
t
u
a

.
e
g
a
u
g
n
a
l

.
s
r
i
a
p

r
e
w
s
n
a
-
n
o
i
t
s
e
u
q

.
s
g
n
i
t
e
e
m

i
s
c

i

f
o

s
g
n
i
d
r
o
c
e
r

s
r
h
2
7

*
k
1
1

.
s
e
t
u
o
r

t
h
g
i
e
r
f

d
a
o
r
l
i
a
r

f
o

g
n
i
n
n
a
l
p

e
v
i
t
a
r
o
b
a
l
l
o
c

s
r
h
5

.

6

k
5
5

8
2
1

6
3

8

8
0
1

0
0
2

4
5

5
1

0
0
1

5
3

2
8

5
7

8
9

.
t
c
e
j
o
r
p
l
i
b
o
m
b
r
e
v
e
h
t

r
o
f

.
e
s
e
n
a
p
a
j

d
n
a

d
e
t
c
e
l
l
o
c

,

n
a
m
r
e
g

a
t
a
d

h
c
e
e
p
s

s
u
o
e
n
a
t
n
o
p
s

,

h
s
i
l
g
n
e
n
i

s
i

s
u
p
r
o
c

l
l
u
f

.
s
c
i
t
s
i
t
a
t
s

h
s
i
l
g
n
e
w
o
h
s

y
l
n
o

e

w

s
r
h
8
3

k
0
7
2

6
2
7

g
n
i
c
u
d
o
r
p
e
r
-
p
a
m

k
s
a
t
g
n
i
d
n
i
f

n
o
i
t
a
c
o
l

e
l
y
t
s
e
f
i
l

k
s
a
t

s
e
t
a
b
e
d

n
o
i
t
a
c
u
d
e

,
s
c
i
t
i
l
o
p

s
e
m
a
g

,
s
c
i
t
i
l
o
p

e
m
a
g
g
n
i
y
a
l

p
-
e
l
o
r

s
n
o
i
t
a
s
r
e
v
n
o
c

l
a
n
o
i
t
o
m
e

t
s
i
r
u
o
t

s
e
i
r
i
u
q
n
i

y
r
a
r
b
i
l

s
g
n
i
t
e
e

m

i
s
c

i

s
u
p
r
o
c
d
n
u
o
r
a
g
n
i
k
l
a

w

e
h
t

)
3
1
0
2

,
.
l
a

t
e
n
a
n
n
e
r
b

(

)
7
0
0
2

,
.
l
a

t
e

e
i
w
o
c
-
s
a
l
g
u
o
d

(

s
e
t
a
b
e
d
d
e
r
a
u
q
s
e
c
n
e
g
i
l
l
e
t
n
i

e
s
a
b
a
t
a
d
e
v
i
s
a
u
s
r
e
p
n
e
e
r
g

s
u
p
r
o
c
k
s
a
t
p
a
m
c
r
c
h

)
1
9
9
1

,
.
l
a

t
e
n
o
s
r
e
d
n
a

(

)
6
1
0
2

,
.
l
a

t
e

g
n
a
h
z
(

n
e
k
o
p
s

)
0
0
0
2

l
a
n
o
i
s
s
e
f
o
r
p
f
o

s
u
p
r
o
c
e
h
t

,

w
o
l
r
a
b

(
h
s
i
l
g
n
e
n
a
c
i
r
e
m
a

e
s
a
b
a
t
a
d
y
r
c
i
m
m
b
o
n
h
a
m

i

)
0
1
0
2

,

n
a
j
n
a
r
a
t
t
i
h
c
d
n
a

g
n
u
h

(

s
u
p
r
o
c

f
l
o
w
p
a
d

i

i

e
h
t

)
1
1
0
2

,
.
l
a

t
e

n
u
s
(

)
4
1
0
2

,
r
a
h
c
a
s
d
n
a
u
a
e
n
n
o
s
s
a
p
(

)
0
1
0
2

,
.
l
a

t
e
n
w
o
e
k
c
m

(

a
r
o
p
r
o
c
5
c
t
s
d
/
4
c
t
s
d

)
6
1
0
2

,

5
1
0
2

,
.
l
a

t
e
m
k

i

(

s
u
p
r
o
c
e
u
g
o
l
a
i
d

i
u
q
o
l

s
u
p
r
o
c
e
n
a
m
e
s

i

)
4
0
0
2

,
.
l
a

t
e

g
r
e
b
i
r
h
s
(

s
u
p
r
o
c
a
d
r
m

t
h
g
i
e
r
f
d
a
o
r
l
i
a
r

g
n
i
n
n
a
l

p
e
t
u
o
r

t
n
e
m
t
n
i
o
p
p
a

g
n
i
l
u
d
e
h
c
s

s
u
p
r
o
c
s
e
u
g
o
l
a
i
d
3
9
s
n
a
r
t

i

)
5
9
9
1

,

n
e
l
l

a
d
n
a

n
a
m
e
e
h

(

)
0
0
0
2

,
.
l
a

t
e

r
e
g
r
u
b

(

s
u
p
r
o
c

l
i
b
o
m
b
r
e
v

15

#

l
a
t
o
t

s
e
u
g
o
l
a
i
d

f
o

s
c
i
p
o
t

e
m
a
n

h
c
e
e
p
s
h
s
i
l
g
n
e
f
o
e
t
a
r

e
g
a
r
e
v
a

e
h
t
n
o
d
e
s
a
b
s
e
t
a
m

i
t
s
e

e
r
a

s
r
e
b
m
u
n
)
*
(
d
e
r
r
a
t
s

.
)
l
m
t
h
.
y
t
i
l
a
u
q
/
l
a
i
r
o
t
u
t
/
d
o
r
p
e
c
i
o
v
/
s
l
a
i
r
o
t
u
t
/
s
v
c
n
/
g
r
o
.
s
v
c
n
.
w
w
w
(

h
c
e
e
p
s
d
n
a

e
c
i
o
v

r
o
f

r
e
t
n
e
c

l
a
n
o
i
t
a
n
e
h
t

m
o
r
f

.
s
t
e
s
a
t
a
d
e
u
g
o
l
a
i
d
n
e
k
o
p
s
d
e
n
i
a
r
t
s
n
o
c
n
a
m
u
h
-
n
a
m
u
h

:
2

e
l
b
a
t

.

o
g
a

y
r
u
t
n
e
c

a
m
o
r
f

e
d
i
s
y
r
t
n
u
o
c

e
h
t

f
o

e
r
o
l
k
l
o
f

e
h
t

d
n
a
k
r
o
w

,
s
e
i
l
i

m
a
f

,
s
e
i
r
o
m
e
m

r
i
e
h
t

t
u
o
b
a

g
n
i
k
l
a
t

e
v
o
b
a

r
o

0
6
d
e
g
a

e
l
p
o
e
p
f
o

e
u
g
o
l
a
i
d

s
r
h
0
6

k
0
0
8

4
1
3

s
c
i
p
o
t

l
a
u
s
a
c

.
a
n
i
l
o
r
a
c
h
t
r
o
n

,

y
t
n
u
o
c
g
r
u
b
n
e
l
k
c
e

m

f
o

s
t
n
e
d
i
s
e
r

e
h
t

f
o

e
v
i
t
a
t
n
e
s
e
r
p
e
r

s
w
e
i
v
r
e
t
n
i
d
n
a

s
n
o
i
t
a
s
r
e
v
n
o
c

,
s
e
v
i
t
a
r
r
a
n

*
s
r
h
2

k
0
2

5
9

s
c
i
p
o
t

l
a
u
s
a
c

.

n
o
i
t
i
s
i
u
q
c
a

e
g
a
u
g
n
a
l

d
n
o
c
e
s

d
n
a

e
h
t

r
o
f
d
e
z
i
n
a
g
r
o

e
s
a
b
a
t
a
d

l
a
n
o
i
t
a
n
r
e
t
n
i

t
s
r
   
f
o

y
d
u
t
s

*
s
r
h
0
0
0

,

1

m
0
1

k
1
1

d
e
t
c
i
r
t
s
e
r
n
u

t
n
e
m
n
r
e
v
o
g

r
o

s
s
e
n
i
s
u
b
l
a
m
r
o
f

m
o
r
f

,
s
t
x
e
t
n
o
c

y
n
a
m
s
e
u
g
o
l
a
i
d
h
s
i
t
i
r

b

s
c
i
p
o
t

d
e
   
i
c
e
p
s
-
e
r
p
n
o
s
n
o
i
t
a
s
r
e
v
n
o
c

e
n
o
h
p
e
l
e
t

.
s
n
i
-
e
n
o
h
p

d
n
a

s
w
o
h
s

o
i
d
a
r

o
t

s
g
n
i
t
e
e
m

n
o
i
t
p
i
r
c
s
e
d

l
a
t
o
t

h
t
g
n
e
l

*
s
r
h
0
0
3

*
s
r
h
0
0
0

,

1

.
s
d
n
e
i
r
f

e
s
o
l
c

r
o
s
r
e
b
m
e
m
y
l
i

m
a
f
n
e
e
w
t
e
b
s
n
o
i
t
a
s
r
e
v
n
o
c

e
n
o
h
p
e
l
e
t

s
r
h
0
6

.
t
n
e
c
c
a

n
r
e
h
t
u
o
s
a

h
t
i

w
s
n
a
c
i
r
e
m
a
n
e
e
w
t
e
b
s
n
o
i
t
a
s
r
e
v
n
o
c

e
n
o
h
p
e
l
e
t

s
r
h
0
2

m
3

m
0
1

*
k
0
4
5

*
k
0
8
1

s
a

h
c
u
s

,
s
t
x
e
t
n
o
c

l
a
m
r
o
f
n
i

f
o
y
t
e
i
r
a
v
e
d
i
w
m
o
r
f

s
e
u
g
o
l
a
i
d
h
s
i
t
i
r

b

*
s
r
h
0
5
5

m
5

.
c
t
e

,
s
t
n
a
r
u
a
t
s
e
r

,
s
n
o
l
a
s

r
i
a
h

e
l
p
o
e
p

f
o

p
u
o
r
g
a

n
e
e
w
t
e
b
n
o
i
t
c
a
r
e
t
n
i

l
a
r
u
t
a
n

f
o

s
r
u
o
h

l
a
r
e
v
e
s

s
r
h
8

*
k
0
7

,
s
n
o
i
t
a
s
r
e
v
n
o
c

l
a
r
u
t
a
n

d
e
t
p
i
r
c
s
n
u
h
t
i

w
e
s
a
b
a
t
a
d

l
a
u
s
i
v
-
o
i
d
u
a

n
i
m
0
5
1

*
k
0
2

c
i
l
b
u
p

d
n
a

,
e
n
o
h
p
e
l
e
t

,
e
c
a
f
-
o
t
-
e
c
a
f

f
o
n
o
i
t
c
e
l
e
s

*
s
r
h
0
8

.

n
i
a
t
i
r

b
m
o
r
f

e
u
g
o
l
a
i
d
n
o
i
s
s
u
c
s
i
d

.
s
n
o
i
t
a
t
o
n
n
a

l
a
u
s
i
v

g
n
i
d
u
l
c
n
i

o
e
d
i
v
d
3
h
t
i

w
b
d
c
c
e
h
t

f
o

n
o
i
s
r
e
v
a

n
i
m
7
1

*
k
5

.

2

k
0
0
8

.
s
g
n
i
d
r
o
c
e
r

g
n
i
t
e
e
m
e
c
a
f
-
o
t
-
e
c
a
f

s
r
h
0
0
1

*
k
0
0
9

.

y
l
t
e
r
c
e
s

d
e
d
r
o
c
e
r

e
r
e
w
s
n
o
i
t
a
s
r
e
v
n
o
c

.

3
9
9
1
n
i
d
e
d
r
o
c
e
r

k
l
a
t

e
g
a
n
e
e
t

s
u
o
e
n
a
t
n
o
p
s

s
r
h
5
5

k
0
0
5

#

l
a
t
o
t

s
d
r
o
w

f
o

#

l
a
t
o
t

s
e
u
g
o
l
a
i
d

f
o

s
c
i
p
o
t

e
m
a
n

0
0
4

,

2

4
5
8

s
c
i
p
o
t

s
c
i
p
o
t

l
a
u
s
a
c

l
a
u
s
a
c

)
2
9
9
1

,
.
l
a

t
e
y
e
r
f
d
o
g

(

d
r
a
o
b
h
c
t
i

w
s

)

c
n
b

(

s
u
p
r
o
c

l
a
n
o
i
t
a
n
h
s
i
t
i
r

b

0
2
1

0
6

0
0
1

   

2

5
7
1

0
3

7
1

0
8
2

s
c
i
p
o
t

l
a
u
s
a
c

d
e
t
c
i
r
t
s
e
r
n
u

d
e
t
c
i
r
t
s
e
r
n
u

s
g
n
i
t
e
e

m

s
c
i
p
o
t

l
a
u
s
a
c

s
c
i
p
o
t

l
a
u
s
a
c

d
e
t
c
i
r
t
s
e
r
n
u

s
c
i
p
o
t

l
a
u
s
a
c

h
s
i
l
g
n
e
n
a
c
i
r
e
m
a
e
m
o
h
l
l
a
c

)
7
9
9
1

,
.
l
a

t
e

n
a
v
a
n
a
c

(

h
c
e
e
p
s

h
s
i
l
g
n
e
n
a
c
i
r
e
m
a
d
n
e
i
r
f
l
l
a
c

)
6
9
9
1

,

n
e
l
r
e
p
p
i
z
d
n
a

n
a
v
a
n
a
c

(

n
o
d
n
o
l
f
o

s
u
p
r
o
c
n
e
g
r
e
b
e
h
t

t
c
e
l
a
i
d
n
r
e
h
t
u
o
s
-
n
o
n

)
5
9
9
1

,

m
  o
r
t
s
n
e
t
s
d
n
a
d
u
r
e
l
s
a
h

(

m
a
h
g
n
i
t
t
o
n
d
n
a

e
g
d
i
r
b
m
a
c
e
h
t

h
s
i
l
g
n
e
n
i

e
s
r
u
o
c
s
i
d

f
o

s
u
p
r
o
c

e
g
a
u
g
n
a
l
e
g
a
n
e
e
t

)
8
9
9
1

,

y
h
t
r
a
c
c
m

(

)
2
9
9
1

,
h
c
e
e
l
(

d
e
t
c
i
r
t
s
e
r
n
u

s
u
p
r
o
c
n
o
i
t
a
s
r
e
v
n
o
c

l
a
d
o
m

i
t
l
u
m
4
6
d

)
5
1
0
2

,
.
l
a

t
e

r
e
t
n
e
v
e
d
n
a
v

(

)
b
d
c
c
d
4
(

e
s
a
b
a
t
a
d
n
o
i
t
a
s
r
e
v
n
o
c

f
f
i
d
r
a
c
d
4

e
s
a
b
a
t
a
d
n
o
i
t
a
s
r
e
v
n
o
c

f
f
i
d
r
a
c

)
3
1
0
2

,
.
l
a

t
e

y
e
r
b
u
a

(

)
b
d
c
c

(

h
s
i
l
g
n
e
n
e
k
o
p
s
y
a
d

-
t
n
e
s
e
r
p

f
o

s
u
p
r
o
c
c
i
n
o
r
h
c
a
i
d
e
h
t

e
h
t

f
o

s
u
p
r
o
c
n
e
k
o
p
s
e
h
t

)
6
0
0
2

,
s
i
l
l
a

w
d
n
a

s
t
r
a
a

(

s
t
c
e
l
a
i
d
h
s
i
l
g
n
e
f
o

)
9
9
9
1

,
t
t
o
c
s
d
n
a

y
e
v
r
u
s

e
r
a
e
b

(

a
t
a
d
e
g
a
u
g
n
a
l
d
l
i
h
c
e
h
t

m
e
t
s
y
s
e
g
n
a
h
c
x
e

)
5
8
9
1

,

w
o
n
s
d
n
a
y
e
n
n
i
h
w

c
a

m

(

d
n
a

e
v
i
t
a
r
r
a
n
e
t
t
o
l
r
a
h
c
e
h
t

)

c
c
n
c

(
n
o
i
t
c
e
l
l
o
c
n
o
i
t
a
s
r
e
v
n
o
c

)
4
0
0
2

,
e
d
i
d
n
a

n
e
p
p
e
r

(

s
u
p
r
o
c
g
n
i
t
e
e

m

i

m
a

)
7
0
0
2

,
.
l
a

t
e

s
l
a
n
e
r

(

)
3
1
0
2

,
.
l
a

t
e

l
e
t
r
e
o

(

16

h
c
e
e
p
s
h
s
i
l
g
n
e
f
o
e
t
a
r
e
g
a
r
e
v
a
e
h
t
n
o
d
e
s
a
b
s
e
t
a
m

i
t
s
e
e
r
a
s
r
e
b
m
u
n
)
*
(
d
e
r
r
a
t
s

)
l
m
t
h
.
y
t
i
l
a
u
q
/
l
a
i
r
o
t
u
t
/
d
o
r
p
e
c
i
o
v
/
s
l
a
i
r
o
t
u
t
/
s
v
c
n
/
g
r
o
.
s
v
c
n
.
w
w
w
(

h
c
e
e
p
s
d
n
a

e
c
i
o
v

r
o
f

r
e
t
n
e
c

l
a
n
o
i
t
a
n
e
h
t

m
o
r
f

.
s
t
e
s
a
t
a
d
e
u
g
o
l
a
i
d
n
e
k
o
p
s

s
u
o
e
n
a
t
n
o
p
s
n
a
m
u
h
-
n
a
m
u
h

:
3

e
l
b
a
t

.
)
s
m
l
   
n
a
c
i
r
e
m
a
/
h
s
i
t
i
r

b
d
e
x
i
m
0
0
5
d
n
a

s
m
l
   
n
a
c
i
r
e
m
a
0
0
0
1
(

d
e
t
a
t
o
n
n
a

,
s
t
p
i
r
c
s
m
l
   
m
o
r
f

s
n
o
i
t
a
s
r
e
v
n
o
c

t
r
o
h
s

e
m
o
c

o
t

d
e
r
e
t
l
   
e
r
a

h
c
i
h
w
s
e
c
n
a
r
e
t
t
u

f
o

s
e
l
p
i
r
t

.
a
t
a
d
a
t
e
m

r
e
t
c
a
r
a
h
c

h
t
i

w

*
m
9

*
m
2

7
1
6

6
8
7

,

1

s
t
p
i
r
c
s

f
o
s
t
e
s
b
u
s
o
w
t

*
m
6
1

0
0
5

,

1

e
m
o
c

o
t

d
e
r
e
t
l
   
e
r
a

h
c
i
h
w
s
e
c
n
a
r
e
t
t
u

f
o

s
e
l
p
i
r
t

m
3
1

.
s
m
l
   
n
a
c
i
r
e
m
a

f
o

s
t
p
i
r
c
s

e
i
v
o
m

m
6

3
5
7

4
1
6

.
s
e
l
p
i
r
t

-

-

x
y
x
m
o
r
f

d
n
a

)
y
r
o
e
h
t
g
n
a
b
g
i
b

(

y
d
e
m
o
c

a
m
o
r
f

s
t
p
i
r
c
s
v
t

*
k
0
0
6

.
s
e
p
y
t
e
h
c
r
a

r
e
t
c
a
r
a
h
c

d
n
a

s
e
r
u
t
c
u
r
t
s

c
i
t
s
i
u
g
n
i
l

r
o
f

d
e
t
a
t
o
n
n
a

,

b
d
s
m

i

m
o
r
f

s
t
p
i
r
c
s

m
6
9

.

.

w
o
h
s

)
s
e
n
o
r
h
t
f
o
e
m
a
g

(

a
m
a
r
d

1
9
1

2
6
8

m
o
r
f

s
r
i
a
p

e
s
n
o
p
s
e
r
-
n
o
i
t
c
a
r
e
t
n
i
d
e
n
g
i
l

a

m
0
2

4
8
1

,

6

.
s
e
l
t
i
t
b
u
s

e
i
v
o
m

.

d
e
n
g
i
l
a
-
r
e
k
a
e
p
s

t
o
n
e
r
a

h
c
i
h
w
s
e
l
t
i
t
b
u
s

e
i
v
o
m

b
1

7
0
9
7
0
2

,

.
s
a
r
e
p
o
p
a
o
s

n
a
c
i
r
e
m
a

f
o
s
t
p
i
r
c
s
n
a
r
t

m
0
0
1

0
0
0

,

2
2

.
s
e
l
p
i
r
t

-

-

x
y
x
m
o
r
f

k
2
3
1

k
5
4
2

   

k
3
6
2

k
0
2
2

k
7
8

   

m
2

.

1

   

k
0
1

k
1
5
1

m
5
3

.

3

   

m
6
3

.
s
g
n
i
d
e
e
c
o
r
p

l
a
i
r
t

t
r
u
o
c

s
a

l
l
e
w
s
a

)
0
6
7
1
   
0
6
5
1
(

m
o
r
f

s
k
r
o
w

l
a
n
o
i
t
c
   
d
e
t
p
i
r
c
s

s
u
o
i
r
a
v

m
2
1

.

7
7
1

   

k
4
6
7

k
6
3
7

*
m
1

k
5
0
3

k
3
7
1

*
m
0
1

*
k
0
6

k
4
6
6

m
7

.

6

*
m
0
4
1

   

n
o
i
t
p
i
r
c
s
e
d

#

l
a
t
o
t

s
d
r
o
w

f
o

#

l
a
t
o
t

s
k
r
o
w

f
o

#

l
a
t
o
t

#

l
a
t
o
t

s
e
u
g
o
l
a
i
d

f
o

s
e
c
n
a
r
e
t
t
u

f
o

s
e
u
g
o
l
a
i
d

e
i
v
o
m

s
e
u
g
o
l
a
i
d

e
i
v
o
m

e
i
v
o
m

s
t
p
i
r
c
s

e
i
v
o
m

s
e
u
g
o
l
a
i
d

s
e
u
g
o
l
a
i
d

w
o
h
s
v
t

s
t
p
i
r
c
s

w
o
h
s
v
t

e
i
v
o
m

s
t
p
i
r
c
s

e
i
v
o
m

s
t
p
i
r
c
s

e
i
v
o
m

s
e
l
t
i
t
b
u
s

s
e
l
t
i
t
b
u
s

e
i
v
o
m

s
c
i
p
o
t

s
g
n
i
d
e
e
c
o
r
p

l
a
i
r
t
&

s
k
r
o
w
n
e
t
t
i
r

w

)
1
1
0
2

,
e
e
l
d
n
a

l
i
z
i

m
-
u
c
s
e
l
u
c
i
n
-
u
c
s
e
n
a
d

(

s
u
p
r
o
c
e
u
g
o
l
a
i
d
-
e
i
v
o
m

l
l
e
n
r
o
c

s
u
p
r
o
c

t
p
i
r
c
s
e
i
v
o
m
d
e
r
e
t
l
i
f

s
e
i
r
e
s
e
n
i
l
n
o
s
t
p
i
r
c
s
m

l
i
f

)
6
1
0
2

,
.
l
a

t
e

n
a
b
r
e
s
(

)
2
1
0
2

,
s
h
c
n
a
b

(

s
e
l
p
i
r
t
-
e
i
v
o
m

i

c
d
-
e
i
v
o
m

e
m
a
n

)
a
2
1
0
2

,
.
l
a

t
e

r
e
k
l
a

w

(

s
u
p
r
o
c

m

l
i

f
m
o
r
f

e
l
y
t

s
r
e
t
c
a
r
a
h
c

)
3
1
0
2

,
r
u
e
h
o
c
d
n
a

a
x
i
e
m
a

(

s
u
p
r
o
c
e
l
t
b
u
s

s
u
p
r
o
c

)
0
6
7
1
   
0
6
5
1
(

d
e
c

)
6
0
0
2

,
r
e
k
l
a

w
d
n
a

  o
t
y
k

(

)
2
1
0
2

,

n
n
a
m
e
d
e
i
t
(

s
e
l
t
i
t
b
u
s
n
e
p
o

)
b
2
1
0
2

,
s
e
i
v
a
d

(

s
u
p
r
o
c

a
r
e
p
o
p
a
o
s
n
a
c
i
r
e
m
a

)
b
4
1
0
2

,
.
l
a

t
e

o
i
n

(

)
4
1
0
2

,
.
l
a

t
e

y
o
r

(

s
u
p
r
o
c
d
v
t

17

   

.
s
t
e
s
a
t
a
d
e
s
e
h
t
n
i
d
e
t
a
r
a
p
e
s
y
l
t
i
c
i
l
p
x
e

e
b
t
o
n
y
a
m

r
e
p
s
e
u
g
o
l
a
i
d
f
o
r
e
b
m
u
n
e
g
a
r
e
v
a
n
o
d
e
s
a
b
s
e
t
a
m

i
t
s
e

s
e
u
g
o
l
a
i
d

.
s
u
p
r
o
c

e
h
t
n
i

s
k
r
o
w

r
o
s
t
p
i
r
c
s

f
o
r
e
b
m
u
n
e
h
t
d
n
a

)
2
1
0
2

,
s
h
c
n
a
b

(

e
i
v
o
m

e
t
a
c
i
d
n
i

)

(
h
t
i

w
d
e
t
o
n
e
d
s
e
i
t
i
t
n
a
u
q

.
s
t
e
s
a
t
a
d
e
u
g
o
l
a
i
d
d
e
t
p
i
r
c
s
n
a
m
u
h
-
n
a
m
u
h

.
)
s
e
t
u
n
i
m
6
3
(

e
m

i
t
n
u
r

w
o
h
s
v
t
e
g
a
r
e
v
a
o
t

)
s
e
t
u
n
i
m
2
1
1
(

e
m

i
t
n
u
r

m
l
   
e
g
a
r
e
v
a

f
o
o
i
t
a
r

e
h
t
n
o
d
e
s
a
b
d
e
t
s
u
j
d
a

e
r
e
w
s
t
e
s
a
t
a
d
w
o
h
s
v
t

d
e
s
a
b
d
e
t
a
m

i
t
s
e

e
r
a

s
e
i
t
i
t
n
a
u
q
)
*
(
d
e
r
r
a
t
s
(

.
)
s
e
c
a
f
r
e
t
n
i
/
m
o
c
.
b
d
m
i
.
w
w
w
/
/
:
p
t
t
h
(

e
s
a
b
a
t
a
d
d
b
m

i

e
h
t

m
o
r
f
d
e
p
a
r
c
s

s
a
w
a
t
a
d
s
i
h
t

i
r
e
m
a
t

e
h
t

m
o
r
f

d
e
v
i
r
e
d

s
e
t
a
m

i
t
s
e

.
s
w
o
h
s
v
t

d
n
a

s

m
   

l

f
o

s
h
t
g
n
e
l

e
g
a
r
e
v
a

e
h
t

d
n
a

,

m
   

l

r
e
p

s
e
c
n
a
r
e
t
t
u

d
n
a

s
d
r
o
w

f
o

r
e
b
m
u
n

e
g
a
r
e
v
a

e
h
t

n
o

:
4

e
l
b
a
t

.
)
l
m
t
h
.
s
t
n
u
o
c
d
r
o
w
/
t
a
m
r
o
f
/
m
o
c
.
i
r
e
m
a
t
.
w
w
w
/
/
:
p
t
t
h
(

s
r
e
t
i
r

w

r
o
f

e
d
i
u
g

.
s
m
o
o
r

t
a
h
c

e
n
i
l
n
o

c
   
i
c
e
p
s
-
e
g
a
m
o
r
f

s
t
s
o
p

r
e
t
t
i

w
t
m
o
r
f

d
e
t
c
a
r
t
x
e

s
e
i
l
p
e
r
d
n
a

s
t
e
e
w
t

n
o
i
t
p
i
r
c
s
e
d

r
e
t
t
i

w
t
m
o
r
f

d
e
t
c
a
r
t
x
e

s
e
l
p
i
r
t

-

a
b
a

-

#
l
a
t
o
t

s
d
r
o
w

f
o

m
0
0
1

   

m
5
2
1

   

k
5
6

o
w

t
n
e
e
w
t
e
b
d
e
t
c
e
l
l
o
c

s
e
g
a
s
s
e
m
s
m
s

2
*
8
6
6
0
8
5

,

s
g
n
i
t
s
o
p
m
u
r
o
f

t
e
n
e
s
u

b
7

s
e
u
g
o
l
a
i
d

   

5
1

#

l
a
t
o
t

f
o

#

.

g
v
a

s
n
r
u
t

f
o

4
0
7

d
e
t
c
i
r
t
s
e
r
n
u

s
c
i
p
o
t

e
p
y
t

t
a
h
c

d
e
t
c
i
r
t
s
e
r
n
u

g
o
l
b
o
r
c
i

m

d
e
t
c
i
r
t
s
e
r
n
u

g
o
l
b
o
r
c
i

m

)
7
0
0
2

,
l
l
e
t
r
a

m
d
n
a

h
t
y
s
r
o
f
(

s
u
p
r
o
c

t
a
h
c
s
p
n

s
u
p
r
o
c
e
l
p
i
r
t
r
e
t
t
i

w
t

)
b
5
1
0
2

,
.
l
a

t
e

i
n
o
d
r
o
s
(

)
0
1
0
2

,
.
l
a

t
e

r
e
t
t
i

r

(

s
u
p
r
o
c

r
e
t
t
i

w
t

e
m
a
n

d
e
t
c
i
r
t
s
e
r
n
u

g
o
l
b
o
r
c
i

m

s
u
p
r
o
c

)
9
0
0
2

,

y
r
u
b
t
s
e

w
d
n
a

t
e
n
e
s
u

l
u
o
a
h
s
(

d
e
t
c
i
r
t
s
e
r
n
u

s
e
g
a
s
s
e
m
s
m
s

s
u
p
r
o
c
s
m
s
s
u
n

e
p
y
t

t
a
h
w
d
e
t
a
t
o
n
n
a

.
s
n
o
i
t
a
s
r
e
v
n
o
c
m
u
r
o
f

e
t
a
b
e
d
e
t
a
e
r
c

.
t
n
e
m
e
e
r
g
a
s
i
d

r
o

)
e
s
a
r
h
p
a
r
a
p

.

g

.
e
(

t
n
e
m
e
e
r
g
a

f
o

.
s
d
a
e
r
h
t

m
u
r
o
f

s
n
o
i
s
s
u
c
s
i
d
a
i
d
e
p
i
k
i
w
d
n
a

l
a
n
r
u
o
j
e
v
i
l

.

d
e
t
a
t
o
n
n
a

l
e
v
e
l

d
n
a

e
p
y
t

t
n
e
m
e
e
r
g
a

s
e
d
u
l
c
n
i

.
s
m
e
t
s
y
s

e
u
g
o
l
a
i
d

n
e
v
i
r
d
-
l
a
o
g

r
o
f

.
s
e
l
p
i
r
t

e
g
d
e
l
w
o
n
k

s
a

a
t
a
d
a
t
e
m
e
i
v
o
m

.
)
d
e
t
c
a
r
t
x
e

s
e
u
g
o
l
a
i
d
o
n
(

s
g
o
l

m
o
r
f

d
e
p
a
r
c
s
m
a
e
r
t
s

t
a
h
c

c
r

i

.
s
c
i
p
o
t

w
e
i
v
r
e
t
n
i

d
n
a

,
l
a
c
i
t
i
l
o
p

,
l
a
r
e
n
e
g
t
u
o
b
a

s
n
o
i
t
a
s
r
e
v
n
o
c

.
s
n
o
i
t
i
s
o
p

l
a
r
o
m

r
o
l
a
c
i
t
i
l
o
p

.

c
r

i
n
o
m
a
e
r
t
s

t
a
h
c
u
t
n
u
b
u

m
o
r
f

d
e
t
c
a
r
t
x
e

s
e
u
g
o
l
a
i
d

c
   
i
c
e
p
s

t
u
o
b
a

s
e
t
a
b
e
d

e
s
u
b
a

c
i
t
s
e
m
o
d

r
e
h
t
i
e
m
o
r
f

s
t
s
o
p

t
i
d
d
e
r

.
t
i
d
d
e
r
s
s
o
r
c
a

s
t
n
e
m
m
o
c
b
7
1

.

.
s
i
s
y
l
a
n
a

g
n
i
m

i
t

h
t
i

w

,
s
r
e
s
u

(cid:52)

s
r
e
y
a
l
p
n
e
e
w
t
e
b

s
n
o
i
t
a
s
r
e
v
n
o
c

   
.
n
a
t
a
c

f
o
s
r
e
l
t
t
e
s
   

e
m
a
g

e
h
t

n
i

s
r
e
y
a
l
p
n
e
e
w
t
e
b

s
n
o
i
t
a
s
r
e
v
n
o
c

.
t
a
h
c

l
a
r
e
n
e
g

r
o

,
s
t
i
d
d
e
r
b
u
s

   
.
d
l
r
o
w
s
d
r
a
c

   

g
n
i
y
a
l
p

   

m
3
0
1
-
m
9
1

3
3
1

,

1
2

3
5

.

7
1

m
3

.

1

2
3
2

,

4

   

0
6
8
7
4

k
3

   

2

3

7
8
6

8
1

   

   

k
2
8
2

k
0
1
1

m
4

.

1

m
3
7

k
8
5

m
0
0
1

2
*
b
2

m
5
8
1

1
2

6
6
2

,

1

2
2
8

k
0
1

k
1
1

4
1

k
0
3
9

   

5
6
6
0
1

(cid:72)

m
1

.

3

5
9

1

.

8
3

2

2

5
4

.

5
3

0
2
5

1
7

.

7

g
n
i
t
a
r
e
p
o
u
t
n
u
b
u

m
e
t
s
y
s

6

.

1
8
3
3

g
n
i
t
a
r
e
p
o
u
t
n
u
b
u

3

.

3

m
e
t
s
y
s

s
e
i
v
o
m

n
o
i
t
a
d
n
e
m
m
o
c
e
r

&
a
q

,
t
a
h
c

d
e
t
c
i
r
t
s
e
r
n
u

p
l
e
h

e
s
u
b
a

s

m
r
e
t

e
m
a
g

s

m
r
e
t

e
m
a
g

d
e
t
c
i
r
t
s
e
r
n
u

d
e
t
c
i
r
t
s
e
r
n
u

s
k
s
a
t

l
a
i
c
o
s

s
c
i
t
i
l
o
p

m
u
r
o
f

m
u
r
o
f

t
a
h
c

t
a
h
c

t
a
h
c

)
5
1
0
2

,

n
w
o
e
k
c
m
d
n
a

s
r
e
t
a
b
e
d
e
t
a
e
r
c
y
b

t
n
e
m
e
e
r
g
a

l
a
h
t
n
e
s
o
r

(

)
2
1
0
2

,
.
l
a

t
e

s
a
e
r
d
n
a

(

s
u
p
r
o
c

t
n
e
m
u
g
r
a

)
b
2
1
0
2

,
.
l
a

t
e

t
e
n
r
e
t
n
i

r
e
k
l
a

w

(

s
u
p
r
o
c
e
u
g
o
l
a
i
d
u
t
n
u
b
u

)
0
1
0
2

,
.
l
a

t
e

h
k
i
a
h
s
(

)
3
1
0
2

,
a
h
a
d
n
a

s
u
h
t
u

(

t
e
s
a
t
a
d
g
o
l
a
i
d
e
i
v
o
m

)
5
1
0
2

,
.
l
a

t
e

e
g
d
o
d

(

)
a
5
1
0
2

,
.
l
a

t
e

e
w
o
l
(

s
u
p
r
o
c

t
a
h
c
u
t
n
u
b
u

s
u
p
r
o
c
c
p
m

m
u
r
o
f

m
u
r
o
f

t
a
h
c

t
a
h
c

s
u
p
r
o
c
e
s
u
b
a
c
i
t
s
e
m
o
d

t
i
d
d
e
r

)
5
1
0
2

,
.
l
a

t
e
g
n
i
d
a
r
h
c
s
(

)
2
1
0
2

,
.
l
a

t
e

s
o
n
e
t
n
a
f
a

(

n
a
t
a
c

f
o

s
r
e
l
t
t
e
s

)
2
1
0
2

,
.
l
a

t
e

i
l
a
l
a
j
d

(

s
u
p
r
o
c
s
d
r
a
c

)
3
1
0
2

,

n
a
k
d
n
a

n
e
h
c

(

   

t
i
d
d
e
r

m
u
r
o
f

s
e
g
a
p
k
l
a
t
a
i
d
e
p
i
k
i
w
n
i

t
n
e
m
e
e
r
g
a

18

_
t
i
d
d
e
r
_
e
l
b
a
l
i
a
v
a
_
y
l
c
i
l
b
u
p
_
y
r
e
v
e
_
e
v
a
h
_
i
/
7
g
l
x
b
3
/
s
t
n
e
m
m
o
c
/
s
t
e
s
a
t
a
d
/
r
/
m
o
c
.
t
i
d
d
e
r
.
w
w
w
/
/
:
s
p
t
t
h

)

   

(

e
c
n
e
u
q
e
s

a

e
b
t
s
u
m
d
r
o
w
a

.
e
.
i
(

s
e
c
a
p
s
n
o
d
e
s
a
b
s
t
n
u
o
c
d
r
o
w
g
n
i
s
u
d
e
t
u
p
m
o
c

e
r
a

s
e
i
t
i
t
n
a
u
q
)
*
(
d
e
r
r
a
t

s

.
s
t
e
s
a
t
a
d
e
u
g
o
l
a
i
d
n
e
t
t
i
r

w
n
a
m
u
h
-
n
a
m
u
h

s
e
m

i
t
e
m
o
s

e
r
a

s
d
r
o
w
h
s
i
l
g
n
e
r
e
p
o
r
p

,
a
r
o
p
r
o
c

s
m
s

d
n
a
c
r

i

s
a

h
c
u
s

,
a
r
o
p
r
o
c

n
i
a
t
r
e
c

r
o
f

d
e
t
a
m

i
t
s
e

e
c
n
a
r
e
t
t
u
r
e
p
s
d
r
o
w
e
g
a
r
e
v
a
g
n
i
s
u
d
e
t
u
p
m
o
c

s
d
n
u
o
b
r
e
p
p
u
d
n
a

r
e
w
o
l

s
e
t
a
c
i
d
n
i

)

(cid:52)

t
u
b

(

,
)
e
c
a
p
s

a

y
b

d
e
w
o
l
l
o
f

d
n
a

d
e
d
e
c
e
r
p

s
r
e
t
c
a
r
a
h
c

f
o

e
l
g
n
a
i
r
t

.
e
g
a
s
u
g
n
a
l
s
o
t

e
u
d
r
e
h
t
e
g
o
t
d
e
t
a
n
e
t
a
c
n
o
c

m
1
2

.

t
a
h
t

e
t
o
n

.
s
u
p
r
o
c

e
h
t

f
o

t
r
a
p

h
s
i
l
g
n
e

e
h
t

n
o

y
l
n
o

d
e
s
a
b

s
e
t
a
m

i
t
s
e

s
e
t
a
c
i
d
n
i

)
2
(

e
r
a
u
q
s

.
)
5
1
0
2
(

g
n
i
d
a
r
h
c
s

s
u
p
r
o
c

t
i
d
d
e
r

r
a
l
i

m

i
s

a

n
o

d
e
d
r
o
c
e
r

f
o

s
k
c
o
l
b

s
u
o
u
g
i
t
n
o
c

e
r
a

e
h
t

s
a

s
n
r
u
t

e
g
a
r
e
v
a

e
h
t

e
t
a
l
u
c
l
a
c

d
n
a

y
b

d
e
t
a
c
i
d
n
i

s
p
u
o
r
g
s
w
e
n

s
g
o
l
a
i
d

.
s
r
i
a
p
a
q
d
e
t
a
l
u
m

i
s

f
o
m
r
o
f

e
h
t

n
i

e
r
a

)

(

t
e
s
a
t
a
d

g
o
l
a
i
d
e
i
v
o
m

e
h
t

m
o
r
f

s
e
u
g
o
l
a
i
d

f
o

r
e
b
m
u
n

l
a
t
o
t

e
h
t

e
t
o
n

e
w

,
t
e
n
e
s
u

f
o

e
s
a
c

e
h
t

n
i

.
t
a
h
c

t
n
a
p
i
c
i
t
r
a
p
-
i
t
l
u
m
a

n
i

n
o
i
t
a
s
r
e
v
n
o
c

l
l
e
w
s
a

s
n
e
k
o
t
o
t

s
r
e
f
e
r
d
n
a

e
z
i
s

r
a
l
i

m

i
s

f
o
t
e
s
a
t
a
d
r
e
t
t
i

w
t
a
n
o
d
e
s
a
b
e
t
a
m

i
t
s
e
n
a

s
e
t
a
c
i
d
n
i

)

.
p
u
o
r
g
s
w
e
n
r
e
p
d
e
t
c
e
l
l
o
c

s
t
s
o
p
f
o
r
e
b
m
u
n
e
g
a
r
e
v
a

   

(

(cid:72)

   

(

:
o
t

s
r
e
f
e
r

)

.
s
d
r
o
w
s
a

/
t
n
e
m
m
o
c

:
5

e
l
b
a
t

4.1.3 other
the dialog mathematical proof dataset (wolska et al., 2004) is a wizard-of-oz dataset in-
volving an automated tutoring system that attempts to advise students on proving mathematical
theorems. this is done using a hinting algorithm that provides clues when students come up with an
incorrect answer. at only 66 dialogues, the dataset is very small, and consists of a conglomeration
of text-based interactions with the system, as well as think-aloud audio and video footage recorded
by the users as they interacted with the system. the latter was transcribed and annotated with simple
speech acts such as    signaling emotions    or    self-addressing   .

the match corpus (georgila et al., 2010) is a small corpus of 447 dialogues based on a
wizard-of-oz experiment, which collected 50 young and old adults interacting with spoken dialogue
systems. these conversations were annotated semi-automatically with dialogue acts and    informa-
tion state update    (isu) representations of dialogue context. the corpus also contains information
about the users    cognitive abilities, with the motivation of modeling how the elderly interact with
dialogue systems.

4.2 human-human spoken corpora
naturally, there is much more data available for conversations between humans than conversations
between humans and machines. thus, we break down this category further, into spoken dialogues
(this section) and written dialogues (section 4.3). the distinction between spoken and written dia-
logues is important, since the distribution of utterances changes dramatically according to the nature
of the interaction. as discussed in subsection 3.1, spoken dialogues tend to be more colloquial and
generally well-formed as the user speaks in train-of-thought manner; they also tend to use shorter
words and phrases. conversely, in written communication, users have the ability to re   ect on what
they are writing before they send a message. written dialogues can also contain spelling errors or
abbreviations, though, which are generally not transcribed in spoken dialogues.

4.2.1 spontaneous spoken corpora
we    rst introduce datasets in which the topics of conversation are either casual, or not pre-speci   ed
in any way. we refer to these corpora as spontaneous, as we believe they most closely mimic
spontaneous and unplanned spoken interactions between humans.

perhaps one of the most in   uential spoken corpora is the switchboard dataset (godfrey et al.,
1992). this dataset consists of approximately 2,500 dialogues from phone calls, along with word-
by-word transcriptions with about 500 total speakers. a computer-driven robot operator system
introduced a topic for discussion between two participants, and recorded the resulting conversation.
about 70 casual topics were provided, of which about 50 were frequently used. the corpus was
originally designed for training and testing various speech processing algorithms; however, it has
since been used for a wide variety of other tasks, including the modeling of dialogue acts such as
   statement   ,    question   , and    agreement    (stolcke et al., 2000).

another important dataset is the british national corpus (bnc) (leech, 1992), which contains
approximately 10 million words of dialogue. these were collected in a variety of contexts ranging
from formal business or government meetings, to radio shows and phone-ins. although most of
the conversations are spoken in nature, some of them are also written. bnc covers a large number
of sources, and was designed to represent a wide cross-section of british english from the late
twentieth century. the corpus also includes part-of-speech (pos) tagging for every word. the vast

19

array of settings and topics covered by this corpus renders it very useful as a general-purpose spoken
dialogue dataset.

other datasets have been collected for the analysis of spoken english over the telephone. the
callhome american english speech corpus (canavan et al., 1997) consists of 120 such
conversations totalling about 60 hours, mostly between family members or close friends. similarly,
the callfriend american english-non-southern dialect corpus (canavan and zipperlen,
1996) consists of 60 telephone conversations lasting 5-30 minutes each between english speakers in
north america without a southern accent. it is annotated with speaker information such as sex, age,
and education. the goal of the project was to support the development of language identi   cation
technologies, yet, there are no distinguishing features in either of these corpora in terms of the topics
of conversation.

an attempt to capture exclusively teenage spoken language was made in the bergen corpus
of london teenager language (colt) (haslerud and stenstr  om, 1995). conversations were
recorded surreptitiously by student    recruits   , with a sony walkman and a lapel microphone, in
order to obtain a better representation of teenager interactions    in-the-wild   . this dataset has been
used to identify trends in language evolution in teenagers (stenstr  om et al., 2002).

the cambridge and nottingham corpus of discourse in english (cancode) (mccarthy,
1998) is a subset of the cambridge international corpus, containing about 5 million words collected
from recordings made throughout the islands of britain and ireland. it was constructed by cam-
bridge university press and the university of nottingham using dialogue data on general topics
between 1995 and 2000. it focuses on interpersonal communication in a range of social contexts,
varying from hair salons, to post of   ces, to restaurants. this has been used, for example, to study
language awareness in relation to spoken texts and their cultural contexts (carter, 1998). in the
dataset, the relationships between speakers (e.g. roommates, strangers) is labeled and the interac-
tion type is provided (e.g. professional, intimate).

other works have attempted to record the physical elements of conversations between humans.
to this end, a small corpus entitled d64 multimodal conversational corpus (oertel et al., 2013)
was collected, incorporating data from 7 video cameras, and the registration of 3-d head, torso,
and arm motion using an optitrack system. signi   cant effort was made to make the data collection
process as non-intrusive   and thus, naturalistic   as possible. annotations were made to attempt to
quantify overall group excitement and pairwise social distance between participants.

a similar attempt to incorporate id161 features was made in the ami meeting cor-
pus (renals et al., 2007), where cameras, a vga data projector capture, whiteboard capture, and
digital pen capture, were all used in addition to speech recordings for various meeting scenarios.
as with the d64 corpus, the ami meeting corpus is a small dataset of multi-participant chats, that
has not been disentangled into strict dialogue. the dataset has often been used for analysis of the
dynamics of various corporate and academic meeting scenarios.

in a similar vein, the cardiff conversation database (ccdb) (aubrey et al., 2013) is an audio-
visual database containing unscripted natural conversations between pairs of people. the original
dataset consisted of 30    ve minute conversations, 7 of which were fully annotated with transcrip-
tions and behavioural annotations such as speaker activity, facial expressions, head motions, and
smiles. the content of the conversation is an unconstrained discussion on topics such as movies.
while the original dataset featured 2d visual feeds, an updated version with 3d video has also been
derived, called the 4d cardiff conversation database (4d ccdb) (vandeventer et al., 2015).

20

this version contains 17 one-minute conversations from 4 participants on similarly un-constrained
topics.

the diachronic corpus of present-day spoken english (dcpse) (aarts and wallis, 2006) is
a parsed corpus of spoken english made up of two separate datasets. it contains more than 400,000
words from the ice-gb corpus (collected in the early 1990s) and 400,000 words from the london-
lund corpus (collected in the late 1960s-early 1980s). ice-gb refers to the british component of
the international corpus of english (greenbaum and nelson, 1996; greenbaum, 1996) and contains
both spoken and written dialogues from english adults who have completed secondary education.
the dataset was selected to provide a representative sample of british english. the london-lund
corpus (svartvik, 1990) consists exclusively of spoken british conversations, both dialogues and
monologues. it contains a selection of face-to-face, telephone, and public discussion dialogues; the
latter refers to dialogues that are heard by an audience that does not participate in the dialogue, in-
cluding interviews and panel discussions that have been broadcast. the orthographic transcriptions
of the datasets are normalised and annotated according to the same criteria; ice-gb was used as a
gold standard for the parsing of dcpse.

the spoken corpus of the survey of english dialects (beare and scott, 1999) consists of
1000 recordings, with about 0.8 million total words, collected from 1948-1961 in order to document
various existing english dialects. people aged 60 and over were recruited, being most likely to speak
the traditional    uncontaminated    dialects of their area and encouraged to talk about their memories,
families, work, and their countryside folklore.

the child language data exchange system (childes) (macwhinney and snow, 1985) is a
database organized for the study of    rst and second id146. the database contains 10
million english words and approximately the same number of non-english words. it also contains
transcripts, with occasional audio and video recordings of data collected from children and adults
learning both    rst and second languages, although the english transcripts are mostly from children.
this corpus could be leveraged in order to build automated teaching assistants.

the expanded charlotte narrative and conversation collection (cncc), a subset of the    rst
release of the american national corpus (reppen and ide, 2004), contains 95 narratives, conver-
sations and interviews representative of the residents of mecklenburg county, north carolina and
its surrounding communities. the purpose of the cncc was to create a corpus of conversation and
conversational narration in a    new south    city at the beginning of the 21st century, that could be
used as a resource for linguistic analysis. it was originally released as one of several collections
in the new south voices corpus, which otherwise contained mostly oral histories. information on
speaker age and gender in the cncc is included in the header for each transcript.

4.2.2 constrained spoken corpora

next, we discuss domains in which conversations only occur about a particular topic, or intend to
solve a speci   c task. not only is the topic of the conversation speci   ed beforehand, but participants
are discouraged from deviating off-topic. as a result, these corpora are slightly less general than
their spontaneous counterparts; however, they may be useful for building goal-oriented dialogue
systems. as discussed in subsection 3.3, this may also make the conversations less natural. we can
further subdivide this category into the types of topics they cover: path-   nding or planning tasks,
persuasion tasks or debates, q&a or information retrieval tasks, and miscellaneous topics.

21

collaborative path-finding or planning tasks several corpora focus on task planning or path-
   nding through the collaboration of two interlocutors. in these corpora typically one person acts as
the decision maker and the other acts as the observer.

a well-known example of such a dataset is the hcrc map task corpus (anderson et al.,
1991), that consists of unscripted, task-oriented dialogues that have been digitally recorded and
transcribed. the corpus uses the map task (brown et al., 1984), where participants must collab-
orate verbally to reproduce a route on one of the participant   s map on the map of another partic-
ipant. the corpus is fairly small, but it controls for the familiarity between speakers, eye contact
between speakers, matching between landmarks on the participants    maps, opportunities for con-
trastive stress, and phonological characteristics of landmark names. by adding these controls, the
dataset attempts to focus on solely the dialogue and human speech involved in the planning process.
the walking around corpus (brennan et al., 2013) consists of 36 dialogues between people
communicating over mobile telephone. the dialogues have two parts:    rst, a    stationary partner   
is asked to direct a    mobile partner    to    nd 18 destinations on a medium-sized university campus.
the stationary partner is equipped with a map marked with the target destinations accompanied by
photos of the locations, while the mobile partner is given a gps navigation system and a camera to
take photos. in the second part, the participants are asked to interact in-person in order to duplicate
the photos taken by the mobile partner. the goal of the dataset is to provide a testbed for natural
lexical entrainment, and to be used as a resource for pedestrian navigation applications.

the trains 93 dialogues corpus (heeman and allen, 1995) consists of recordings of two
interlocutors interacting to solve various planning tasks for scheduling train routes and arranging
railroad freight. one user acts the role of a planning assistant system and the other user acts as
the coordinator. this was not done in a wizard-of-oz fashion, and as such is not considered a
human-machine corpus. 34 different interlocutors were asked to complete 20 different tasks such
as:    determine the maximum number of boxcars of oranges that you could get to bath by 7 am
tomorrow morning. it is now 12 midnight.    the person playing the role of the planning assistant was
provided with access to information that is needed to solve the task. also included in the dataset
is the information available to both users, the length of dialogue, and the speaker and    system   
interlocutor identities.

the verbmobil corpus (burger et al., 2000) is a multilingual corpus consisting of english,
german, and japanese dialogues collected for the purposes of training and testing the verbmobil
project system. the system was a designed for speech-to-speech machine translation tasks. dia-
logues were recorded in a variety of conditions and settings with room microphones, telephones,
or close microphones, and were subsequently transcribed. users were tasked with planning and
scheduling an appointment throughout the course of the dialogue. note that while there have been
several versions of the verbmobil corpora released, we refer to the entire collection here as described
in (burger et al., 2000). dialogue acts were annotated in a subset of the corpus (1,505 mixed dia-
logues in german, english and japanese). 76,210 acts were annotated with 32 possible categories
of dialogue acts alexandersson et al. (2000)4.

persuasion and debates another theme recurring among constrained spoken corpora is the ap-
pearance of persuasion or debate tasks. these can involve general debates on a topic or tasking
a speci   c interlocutor to try to convince another interlocutor of some opinion or topic. generally,

4. note, this information and further facts about the verbmobil project and corpus can be found here: http:

//verbmobil.dfki.de/facts.html

22

these datasets record the outcome of how convinced the audience is of the argument at the end of
the dialogue or debate.

the green persuasive dataset (douglas-cowie et al., 2007) was recorded in 2007 to provide
data for the humaine project, whose goal is to develop interfaces that can register and respond
to emotion. in the dataset, a persuader with strong pro-environmental (   pro-green   ) feelings tries to
convince persuadees to consider adopting more green lifestyles; these interactions are in the form of
dialogues. it contains 8 long dialogues, totalling about 30 minutes each. since the persuadees often
either disagree or agree strongly with the persuaders points, this would be good corpus for studying
social signs of (dis)-agreement between two people.

the mahnob mimicry database (sun et al., 2011) contains 11 hours of recordings, split
over 54 sessions between 60 people engaged either in a socio-political discussion or negotiating a
tenancy agreement. this dataset consists of a set of fully synchronised audio-visual recordings of
natural dyadic (one-on-one) interactions. it is one of several dialogue corpora that provide multi-
modal data for analyzing human behaviour during conversations. such corpora often consist of
auditory, visual, and written transcriptions of the dialogues. here, only audio-visual recordings are
provided. the purpose of the dataset was to analyze mimicry (i.e. when one participant mimics the
verbal and nonverbal expressions of their counterpart). the authors provide some benchmark video
classi   cation models to this effect.

the intelligence squared debate dataset (zhang et al., 2016) covers the    intelligence squared   
oxford-style debates taking place between 2006 and 2015. the topics of the debates vary across
the dataset, but are constrained within the context of each debate. speakers are labeled and the full
transcript of the debate is provided. furthermore, the outcome of the debate is provided (how many
of the audience members were for the given proposal or against, before and after the debate).

qa or information retrieval there are several corpora which feature direct question and an-
swering sessions. these may involve general qa, such as in a press conference, or more task-
speci   c lines of questioning, as to retrieve a speci   c set of information.

the corpus of professional spoken american english (cpsae) (barlow, 2000) was con-
structed using a selection of transcripts of interactions occurring in professional settings. the corpus
contains two million words involving over 400 speakers, recorded between 1994-1998. the cpase
has two main components. the    rst is a collection of transcripts (0.9 million words) of white house
press conferences, which contains almost exclusively question and answer sessions, with some pol-
icy statements by politicians. the second component consists of transcripts (1.1 million words) of
faculty meetings and committee meetings related to national tests that involve statements, discus-
sions, and questions. the creation of the corpus was motivated by the desire to understand and
model more formal uses of the english language.

as previously mentioned, the dialog state tracking challenge (dstc) consists of a series of
datasets evaluated using a    state tracking    or    slot    lling    metric. while the    rst 3 installments of
this challenge had conversations between a human participant and a computer, dstc4 (kim et al.,
2015) contains dialogues between humans. in particular, this dataset has 35 conversations with 21
hours of interactions between tourists and tour guides over skype, discussing information on hotels,
   ights, and car rentals. due to the small size of the dataset, researchers were encouraged to use
id21 from other datasets in the dstc in order to improve state tracking performance.
this same training set is used for dstc5 (kim et al., 2016) as well. however, the goal of dstc5

23

is to study multi-lingual speech-act prediction, and therefore it combines the dstc4 dialogues plus
a set of equivalent chinese dialogs; evaluation is done on a holdout set of chinese dialogues.
miscellaneous lastly, there are several corpora which do not fall into any of the aforementioned
categories, involving a range of tasks and situations.

the idiap wolf corpus (hung and chittaranjan, 2010) is an audio-visual corpus containing
natural conversational data of volunteers who took part in an adversarial role-playing game called
   werewolf   . four groups of 8-12 people were recorded using headset microphones and synchro-
nised video cameras, resulting in over 7 hours of conversational data. the novelty of this dataset is
that the roles of other players are unknown to game participants, and some of the roles are decep-
tive in nature. thus, there is a signi   cant amount of lying that occurs during the game. although
speci   c instances of lying are not annotated, each speaker is labeled with their role in the game. in
a dialogue setting, this could be useful for analyzing the differences in language when deception is
being used.

the semaine corpus (mckeown et al., 2010) consists of 100    emotionally coloured    con-
versations. participants held conversations with an operator who adopted various roles designed to
evoke emotional reactions. these conversations were recorded with synchronous video and audio
devices. importantly, the operators    responses were stock phrases that were independent of the con-
tent of the user   s utterances, and only dependent on the user   s emotional state. this corpus motivates
building dialogue systems with affective and emotional intelligence abilities, since the corpus does
not exhibit the natural language understanding that normally occurs between human interlocutors.
the loqui human-human dialogue corpus (passonneau and sachar, 2014) consists of an-
notated transcriptions of telephone interactions between patrons and librarians at new york city   s
andrew heiskell braille & talking book library in 2006. it stands out as it has annotated dis-
cussion topics, question-answer pair links (adjacency pairs), dialogue acts, and frames (discourse
units).

similarly, the the icsi meeting recorder dialog act (mrda) corpus (shriberg et al., 2004)
has annotated dialogue acts, question-answer pair links (adjacency pairs), and dialogue hot spots5.
it consists of transcribed recordings of 75 icsi meetings on several classes of topics including: the
icsi meeting recorder project itself, automatic id103, natural language processing and
neural theories of language, and discussions with the annotators for the project.

4.2.3 scripted corpora
a    nal category of spoken dialogue consists of conversations that have been pre-scripted for the
purpose of being spoken later. we refer to datasets containing such conversations as    scripted cor-
pora   . as discussed in subsection 3.4, these datasets are distinct from spontaneous human-human
conversations, as they inevitably contain fewer       ller    words and expressions that are common in
spoken dialogue. however, they should not be confused with human-human written dialogues, as
they are intended to sound like natural spoken conversations when read aloud by the participants.
furthermore, these scripted dialogues are required to be dramatic, as they are generally sourced
from movies or tv shows.

there exist multiple scripted corpora based on movies and tv series. these can be sub-divided
into two categories: corpora that provide the actual scripts (i.e. the movie script or tv series script)
where each utterance is tagged with the appropriate speaker, and those that only contain subtitles

5. for more information on dialogue hot spots and how they relate to dialogue acts, see (wrede and shriberg, 2003).

24

and consecutive utterances are not divided or labeled in any way. it is always preferable to have the
speaker labels, but there is signi   cantly more unlabeled subtitle data available, and both sources of
information can be leveraged to build a dialogue system.

the movie dic corpus (banchs, 2012) is an example of the former case   it contains about
130,000 dialogues and 6 million words from movie scripts extracted from the internet movie script
data collection6, carefully selected to cover a wide range of genres. these dialogues also come
with context descriptions, as written in the script. one derivation based on this corpus is the movie
triples dataset (serban et al., 2016). there is also the american film scripts corpus and film
scripts online corpus which form the film scripts online series corpus, which can be pur-
chased 7. the latter consists of a mix of british and american    lm scripts, while the former consists
of solely american    lms.

the majority of these datasets consist mostly of raw scripts, which are not guaranteed to portray
conversations between only two people. the dataset collected by nio et al. (2014b), which we refer
to as the filtered movie script corpus, takes over 1 million utterance-response pairs from web-
based script resources and    lters them down to 86,000 such pairs. the    ltering method limits the
extracted utterances to x-y-x triples, where x is spoken by the same actor and each of the utterance
share some semantic similarity. these triples are then decomposed into x-y and y-x pairs. such
   ltering largely removes conversations with more than two speakers, which could be useful in some
applications. particularly, the    ltering method helps to retain semantic context in the dialogue and
keeps a back-and-forth conversational    ow that is desired in training many dialogue systems.

the cornell movie-dialogue corpus (danescu-niculescu-mizil and lee, 2011) also has short
conversations extracted from movie scripts. the distinguishing feature of this dataset is the amount
of metadata available for each conversation: this includes movie metadata such as genre, release
year, and imdb rating, as well as character metadata such as gender and position on movie credits.
although this corpus contains 220,000 dialogue excerpts, it only contains 300,000 utterances; thus,
many of the excerpts consist of single utterances.

the corpus of american soap operas (davies, 2012b) contains 100 million words in more
than 22,000 transcripts of ten american tv-series soap operas from 2001 and 2012. because it is
based on soap operas it is qualitatively different from the movie dic corpus, which contains movies
in the action and horror genres. the corpus was collected to provide insights into colloquial amer-
ican speech, as the vocabulary usage is quite different from the british national corpus (davies,
2012a). unfortunately, this corpus does not come with speaker labels.

another corpus consisting of dialogues from tv shows is the tvd corpus (roy et al., 2014).
this dataset consists of 191 movie transcripts from the comedy show the big bang theory, and
the drama show game of thrones, along with crowd-sourced text descriptions (brief episode sum-
maries, longer episode outlines) and various types of metadata (speakers, shots, scenes). text align-
ment algorithms are used to link descriptions and metadata to the appropriate sections of each script.
for example, one might align an event description with all the utterances associated with that event
in order to develop algorithms for locating speci   c events from raw dialogue, such as    person x
tries to convince person y   .

some work has been done in order to analyze character style from movie scripts. this is aided by
a dataset collected by walker et al. (2012a) that we refer to as the character style from film cor-
pus. this corpus was collected from the imsdb archive, and is annotated for linguistic structures

6. http://www.imsdb.com
7. http://alexanderstreet.com/products/film-scripts-online-series

25

and character archetypes. features, such as the sentiment behind the utterances, are automatically
extracted and used to derive models of the characters in order to generate new utterances similar
in style to those spoken by the character. thus, this dataset could be useful for building dialogue
personalization models.

there are two primary movie subtitle datasets: the opensubtitles (tiedemann, 2012) and the
subtle corpus (ameixa and coheur, 2013). both corpora are based on the opensubtitles web-
site.8 the opensubtitles dataset is a giant collection of movie subtitles, containing over 1 billion
words, whereas subtle corpus has been pre-processed in order to extract interaction-response pairs
that can help dialogue systems deal with out-of-domain (ood) interactions.

the corpus of english dialogues 1560-1760 (ced) (kyt  o and walker, 2006) compiles di-
alogues from the mid-16th century until the mid-18th century. the sources vary from real trial
transcripts to    ction dialogues. due to the scripted nature of    ctional dialogues and the fact that the
majority of the corpus consists of    ctional dialogue, we classify it here as such. the corpus is com-
posed as follows: trial proceedings (285,660 words), witness depositions (172,940 words), drama
comedy works (238,590 words), didactic works (236,640 words), prose    ction (223,890 words),
and miscellaneous (25,970 words).

4.3 human-human written corpora

we proceed to survey corpora of conversations between humans in written form. as before, we
sub-divide this section into spontaneous and constrained corpora, depending on whether there are
restrictions on the topic of conversation. however, we make a further distinction between forum,
micro-blogging, and chat corpora.

forum corpora consist of conversations on forum-based websites such as reddit9 where users
can make posts, and other users can make comments or replies to said post. in some cases, com-
ments can be nested inde   nitely, as users make replies to previous replies. utterances in forum
corpora tend to be longer, and there is no restriction on the number of participants in a discussion.
on the other hand, conversations on micro-blogging websites such as twitter10 tend to have very
short utterances as there is an upper bound on the number of characters permitted in each message.
as a result, these tend to exhibit highly colloquial language with many abbreviations. the identi-
fying feature of chat corpora is that the conversations take place in real-time between users. thus,
these conversations share more similarities with spoken dialogue between humans, such as common
grounding phenomena.

4.3.1 spontaneous written corpora

we begin with written corpora where the topic of conversation is not pre-speci   ed. such is the case
for the nps internet chatroom conversations corpus (forsyth and martell, 2007), which con-
sists of 10,567 english utterances gathered from age-speci   c chat rooms of various online chat ser-
vices from october and november of 2006. each utterance was annotated with part-of-speech and
dialogue act information; the correctness of this was veri   ed manually. the nps internet chatroom
conversations corpus was one of the    rst corpora of computer-mediated communication (cmc),

8. http://www.opensubtitles.org
9. http://www.reddit.com
10. http://www.twitter.com

26

and it was intended for various nlp applications such as conversation thread topic detection, author
pro   ling, entity identi   cation, and social network analysis.

several corpora of spontaneous micro-blogging conversations have been collected, such as the
twitter corpus from ritter et al. (2010), which contains 1.3 million post-reply pairs extracted from
twitter. the corpus was originally constructed to aid in the production of unsupervised approaches
to modeling dialogue acts. larger twitter corpora have been collected. the twitter triples cor-
pus (sordoni et al., 2015b) is one such example, with a described original dataset of 127 million
context-message-response triples, but only a small labeled subset of this corpus has been released.
speci   cally, the released labeled subset contains 4,232 pairs that scored an average of greater than
4 on the likert scale by crowdsourced evaluators for quality of the response to the context-message
pair. similarly, large micro-blogging corpora such as the sina weibo corpus (shang et al., 2015),
which contains 4.5 million post-reply pairs, have been collected; however, the authors have not yet
been made publicly available. we do not include the sina weibo corpus (and its derivatives) in the
tables in this section, as they are not primarily in english.

the usenet corpus (shaoul and westbury, 2009) is a gigantic collection of public usenet
postings11 containing over 7 billion words from october 2005 to january 2011. usenet was a
distributed discussion system established in 1980 where participants could post articles to one of
47,860    newsgroup    categories. it is seen as the precursor to many current internet forums. the
corpus derived from these posts has been used for research in collaborative    ltering (konstan et al.,
1997) and role detection (fisher et al., 2006).

the nus sms corpus (chen and kan, 2013) consists of conversations carried out over mobile
phone sms messages between two users. while the original purpose of the dataset was to improve
predictive text entry when mobile phones still mapped multiple letters to a single number, aided by
video and timing analysis of users entering their messages it could equally be used for analysis of
informal dialogue. unfortunately, the corpus does not consist of dialogues, but rather single sms
messages. sms messages are similar in style to twitter, in that they use many abbreviations and
acronyms.

currently, one of the most popular forum-based websites is reddit12 where users can create
discussions and post comments in various sub-forums called    subreddits   . each subreddit addresses
its own particular topic. over 1.7 billion of these comments have been collected in the reddit cor-
pus.13 each comment is labeled with the author, score (rating from other users), and position in the
comment tree; the position is important as it determines which comment is being replied to. al-
though researchers have not yet investigated dialogue problems using this reddit discussion corpus,
the sheer size of the dataset renders it an interesting candidate for id21. additionally,
researchers have used smaller collections of reddit discussions for broad discourse classi   cation.
(schrading et al., 2015).

some more curated versions of the reddit dataset have been collected. the reddit domestic
abuse corpus (schrading et al., 2015) consists of reddit posts and comments taken from either
subreddits speci   c to domestic abuse, or from subreddits representing casual conversations, advice,
and general anxiety or anger. the motivation is to build classi   ers that can detect occurrences of
domestic abuse in other areas, which could provide insights into the prevalence and consequences

11. http://www.usenet.net
12. http://www.reddit.com
13. https://www.reddit.com/r/datasets/comments/3bxlg7/i_have_every_publicly_

available_reddit_comment/

27

of these situations. these conversations have been pre-processed with lower-casing, lemmatizing,
and removal of stopwords, and semantic role labels are provided.

4.3.2 constrained written corpora

there are also several written corpora where users are limited in terms of topics of conversation.
for example, the settlers of catan corpus (afantenos et al., 2012) contains logs of 40 games of
   settlers of catan   , with about 80,000 total labeled utterances. the game is played with up to 4
players, and is predicated on trading certain goods between players. the goal of the game is to
be the    rst player to achieve a pre-speci   ed number of points. therefore, the game is adversarial
in nature, and can be used to analyze situations of strategic conversation where the agents have
diverging motives.

another corpus that deals with game playing is the cards corpus (djalali et al., 2012), which
consists of 1,266 transcripts of conversations between players playing a game in the    cards world   .
this world is a simple 2-d environment where players collaborate to collect cards. the goal of the
game is to collect six cards of a particular suit (cards in the environment are only visible to a player
when they are near the location of that player), or to determine that this goal is impossible in the
environment. the catch is that each player can only hold 3 cards, thus players must collaborate in
order to achieve the goal. further, each player   s location is hidden to the other player, and there are
a    xed number of non-chatting moves. thus, players must use the chat to formulate a plan, rather
than exhaustively exploring the environment themselves. the dataset has been further annotated by
potts (2012) to collect all locative question-answer pairs (i.e. all questions of the form    where are
you?   ).

the agreement by create debaters corpus (rosenthal and mckeown, 2015), the agree-
ment in wikipedia talk pages corpus (andreas et al., 2012) and the internet argument corpus
(abbott et al., 2016) all cover dialogs with annotations measuring levels of agreement or disagree-
ment in responses to posts in various media. the agreement by create debaters corpus and the
agreement in wikipedia talk pages corpus both are formatted in the same way. post-reply pairs
are annotated with whether they are in agreement or disagreement, as well as the type of agreement
they are in if applicable (e.g. id141). the difference between the two corpora is the source:
the former is collected from create debate forums and the latter from a mix of wikipedia discus-
sion pages and livejournal postings. the internet argument corpus (iac) (walker et al., 2012b)
is a forum-based corpus with 390,000 posts on 11,000 discussion topics. each topic is controversial
in nature, including subjects such as evolution, gay marriage and climate change; users participate
by sharing their opinions on one of these topics. posts-reply pairs have been labeled as being either
in agreement or disagreement, and sarcasm ratings are given to each post.

another source of constrained text-based corpora are chat-room environments. such a set-up
forms the basis of the mpc corpus (shaikh et al., 2010), which consists of 14 multi-party dialogue
sessions of approximately 90 minutes each. in some cases, discussion topics were constrained to
be about certain political stances, or mock committees for choosing job candidates. an interest-
ing feature is that different participants are given different roles   leader, disruptor, and consensus
builder   with only a general outline of their goals in the conversation. thus, this dataset could
be used to model social phenomena such as agenda control, in   uence, and leadership in on-line
interactions.

28

the largest written corpus with a constrained topic is the recently released ubuntu dialogue
corpus (lowe et al., 2015a), which has almost 1 million dialogues of 3 turns or more, and 100
it is related to the former ubuntu chat corpus (uthus and aha, 2013). both
million words.
corpora were scraped from the ubuntu irc channel logs.14 on this channel, users can log in and
ask a question about a problem they are having with ubuntu; these questions are answered by other
users. although the chat room allows everyone to chat with each other in a multi-party setting,
the ubuntu dialogue corpus uses a series of heuristics to disentangle it into dyadic dialogue. the
technical nature and size of this corpus lends itself particularly well to applications in technical
support.

other corpora have been extracted from irc chat logs. the irc corpus (elsner and charniak,
2008) contains approximately 50 hours of chat, with an estimated 20,000 utterances from the linux
channel on irc, complete with the posting times. therefore, this dataset consists of similarly
technical conversations to the ubuntu corpus, with the occasional social chat. the purpose of
this dataset was to investigate approaches for conversation disentanglement; given a multi-party
chat room, one attempts to recover the individual conversations of which it is composed. for this
purpose, there are approximately 1,500 utterances with annotated ground-truth conversations.

more recent efforts have combined traditional conversational corpora with id53
and recommendation datasets in order to facilitate the construction of goal-driven dialogue systems.
such is the case for the movie dialog dataset (dodge et al., 2015). there are four tasks that the
authors propose as a prerequisite for a working dialogue system: id53, recommenda-
tion, id53 with recommendation, and casual conversation. the movie dialog dataset
consists of four sub-datasets used for training models to complete these tasks: a qa dataset from the
open movie database (omdb)15 of 116k examples with accompanying movie and actor metadata
in the form of knowledge triples; a recommendation dataset from movielens16 with 110k users
and 1m questions; a combined recommendation and qa dataset with 1m conversations of 6 turns
each; and a discussion dataset from reddit   s movie subreddit. the former is evaluated using recall
metrics in a manner similar to lowe et al. (2015a). it should be noted that, other than the reddit
dataset, the dialogues in the sub-datasets are simulated qa pairs, where each response corresponds
to a list of entities from the knowledge base.

5. discussion

we conclude by discussing a number of general issues related to the development and evaluation of
data-driven dialogue systems. we also discuss alternative sources of information, user personaliza-
tion, and automatic evaluation methods.

5.1 challenges of learning from large datasets

recently, several large-scale dialogue datasets have been proposed in order to train data-driven
dialogue systems; the twitter corpus (ritter et al., 2010) and the ubuntu dialogue corpus (lowe
et al., 2015a) are two examples. in this section, we discuss the bene   ts and drawbacks of these
datasets based on our experience using them for building data-driven models. unlike the previous

14. http://irclogs.ubuntu.com
15. http://en.omdb.org
16. http://movielens.org

29

section, we now focus explicitly on aspects of high relevance for using these datasets for learning
dialogue strategies.

5.1.1 the twitter corpus

the twitter corpus consists of a series of conversations extracted from tweets. while the dataset is
large and general-purpose, the micro-blogging nature of the source material leads to several draw-
backs for building conversational dialogue agents. however, some of these drawbacks do not apply
if the end goal is to build an agent that interacts with users on the twitter platform.

the twitter corpus has an enormous amount of typos, slang, and abbreviations. due to the
140-character limit, tweets are often very short and compressed. in addition, users frequently use
twitter-speci   c devices such as hashtags. unless one is building a dialogue agent speci   cally for
twitter, it is often not desirable to have a chatbot use hashtags and excessive abbreviations as it
is not re   ective of how humans converse in other environments. this also results in a signi   cant
increase in the word vocabulary required for dialogue systems trained at the word level. as such,
it is not surprising that character-level models have shown promising results on twitter (dhingra
et al., 2016).

twitter conversations often contain various kinds of verbal role-playing and imaginative actions
similar to stage directions in theater plays (e.g. instead of writing    goodbye   , a user might write
   *waves goodbye and leaves*   ). these conversations are very different from the majority of text-
based chats. therefore, dialogue models trained on this dataset are often able to provide interesting
and accurate responses to contexts involving role-playing and imaginative actions (serban et al.,
2017b).

another challenge posed by twitter is that twitter conversations often refer to recent public
events outside the conversation.
in order to learn effective responses for such conversations, a
dialogue agent must infer the news event under discussion by referencing some form of external
knowledge base. this would appear to be a particularly dif   cult task.

5.1.2 the ubuntu dialogue corpus

the ubuntu dialogue corpus is one of the largest, publicly available datasets containing technical
support dialogues. due to the commercial importance of such systems, the dataset has attracted
signi   cant attention.17 thus, the ubuntu dialogue corpus presents the opportunity for anyone to
train large-scale data-driven technical support dialogue systems.

despite this, there are several problems when training data-driven dialogue models on the
ubuntu dialogue corpus due to the nature of the data. first, since the corpus comes from a multi-
party irc channel, it needs to be disentangled into separate dialogues. this disentanglement process
is noisy, and errors inevitably arise. the most frequent error is when a missing utterance in the di-
alogue is not picked up by the extraction procedure (e.g. an utterance from the original multi-party
chat was not added to the disentangled dialogue). as a result, for a substantial amount of conver-
sations, it is dif   cult to follow the topic. in particular, this means that some of the next utterance
classi   cation (nuc) examples, where models must select the correct next response from a list of
candidates, are either dif   cult or impossible for models to predict.

17. most of the largest technical support datasets are based on commercial technical support channels, which are propri-

etary and never released to the public for privacy reasons.

30

another problem arises from the lack of annotations and labels. since users try to solve their
technical problems, it is perhaps best to build models under a goal-driven dialogue framework,
where a dialogue system has to maximize the id203 that it will solve the user   s problem at the
end of the conversation. however, there are no reward labels available. thus, it is dif   cult to model
the dataset in a goal-driven dialogue framework. future work may alleviate this by constructing
automatic methods of determining whether a user in a particular conversation solved their problem.
a particular challenge of the ubuntu dialogue corpus is the large number of out-of-vocabulary
words, including many technical words related to the ubuntu operating system, such as commands,
software packages, websites, etc. since these words occur rarely in the dataset, it is dif   cult to
learn their meaning directly from the dataset     for example, it is dif   cult to obtain meaningful
distributed, real-valued vector representations for neural network-based dialogue models. this is
further exacerbated by the large number of users who use different nomenclature, acronyms, and
speaking styles, and the many typos in the dataset. thus, the linguistic diversity of the corpus is
large.

a    nal challenge of the dataset is the necessity for additional knowledge related to ubuntu in
order to accurately generate or predict the next response in a conversation. we hypothesize that
this knowledge is crucial for a system trained on the ubuntu dialogue corpus to be effective in
practice, as often solutions to technical problems change over time as new versions of the operating
system become available. thus, an effective dialogue system must learn to combine up-to-date
technical information with an understanding of natural language dialogue in order to solve the users   
problems. we will discuss the use of external knowledge in more detail in section 5.5.

while these challenges make it dif   cult to build data-driven dialogue systems, it also presents
an important research opportunity. current data-driven dialogue systems perform rather poorly in
terms of generating utterances that are coherent and on-topic (serban et al., 2017a). as such, there
is signi   cant room for improvement on these models.

5.2 id21 between datasets

while it is not always feasible to obtain large corpora for every new application, the use of other
related datasets can effectively bootstrap the learning process. in several branches of machine learn-
ing, and in particular in deep learning, the use of related datasets in pre-training the model is an
effective method of scaling up to complex environments (erhan et al., 2010; kumar et al., 2015).

to build open-domain dialogue systems, it is arguably necessary to move beyond domain-
speci   c datasets. instead, like humans, dialogue systems may have to be trained on multiple data
sources for solving multiple tasks. to leverage statistical ef   ciency, it may be necessary to    rst use
unsupervised learning   as opposed to supervised learning or of   ine id23, which
typically only provide a sparse scalar feedback signal for each phrase or sequence of phrases   and
then    ne-tune models based on human feedback. researchers have already proposed various ways
of applying id21 to build data-driven dialogue systems, ranging from learning separate
sub-components of the dialogue system (e.g. intent and dialogue act classi   cation) to learning the
entire dialogue system (e.g. in an unsupervised or id23 framework) using transfer
learning (fabbrizio et al., 2004; forgues et al., 2014; serban and pineau, 2015; serban et al., 2016;
lowe et al., 2015a; vandyke et al., 2015; wen et al., 2016; ga  si  c et al., 2016; mo et al., 2016;
genevay and laroche, 2016; chen et al., 2016)

31

5.3 topic-oriented & goal-driven datasets

tables 1   5 list the topics of available datasets. several of the human-human datasets are denoted as
having casual or unrestricted topics. in contrast, most human-machine datasets focus on speci   c,
narrow topics. it is useful to keep this distinction between restricted and unrestricted topics in mind,
as goal-driven dialogue systems     which typically have a well-de   ned measure of performance
related to task completion     are usually developed in the former setting. in some cases, the line
between these two types of datasets blurs. for example, in the case of conversations occurring
between players of an online game (afantenos et al., 2012), the outcome of the game is determined
by how participants play in the game environment, not by their conversation. in this case, some
conversations may have a direct impact on a player   s performance in the game, some conversations
may be related to the game but irrelevant to the goal (e.g. commentary on past events) and some
conversations may be completly unrelated to the game.

5.4 incorporating longer memories

recently, signi   cant progress has been made towards incorporating a form of external memory
into various neural-network architectures for sequence modeling. models such as memory net-
works (weston et al., 2015; sukhbaatar et al., 2015) and id63s (ntm) (graves
et al., 2014) store some part of their input in a memory, which is then reasoned over in order to
perform a variety of sequence to sequence tasks. these vary from simple problems, such as se-
quence copying, to more complex problems, such as id53 and machine translation.
although none of these models are explicitly designed to address dialogue problems, the extension
by kumar et al. (2015) to dynamic memory networks speci   cally differentiates between episodic
and semantic memory. in this case, the episodic memory is the same as the memory used in the
traditional memory networks paper that is extracted from the input, while the semantic memory
refers to knowledge sources that are    xed for all inputs. the model is shown to work for a variety of
nlp tasks, and it is not dif   cult to envision an application to dialogue utterance generation where
the semantic memory is the desired external knowledge source.

5.5 incorporating external knowledge

another interesting research direction is the incorporation of external knowledge sources in order to
inform the response to be generated. using external information is of great importance to dialogues
systems, particularly in the goal-driven setting. even non-goal-driven dialogue systems designed
to simply entertain the user could bene   t from leveraging external information, such as current
news articles or movie reviews, in order to better converse about real-world events. this may
be particularly useful in data-sparse domains, where there is not enough dialogue training data to
reliably learn a response that is appropriate for each input utterance, or in domains that evolve
quickly over time.

5.5.1 structured external knowledge

in traditional goal-driven dialogue systems (levin and pieraccini, 1997), where the goal is to provide
information to the user, there is already extensive use of external knowledge sources. for example,
in the let   s go! dialogue system (raux et al., 2005), the user requests information about various bus
arrival and departure times. thus, a critical input to the model is the actual bus schedule, which is

32

used in order to generate the system   s utterances. another example is the dialogue system described
by n  oth et al. (2004), which helps users    nd movie information by utilizing movie showtimes from
different cinemas. such examples are abundant both in the literature and in practice. although these
models make use of external knowledge, the knowledge sources in these cases are highly structured
and are only used to place hard constraints on the possible states of an utterance to be generated.
they are essentially contained in id208 or structured ontologies, and are only used to
provide a deterministic mapping from the dialogue states extracted from an input user utterance to
the dialogue system state or the generated response.

complementary to domain-speci   c databases and ontologies are the general natural language
processing databases and tools. these include lexical databases such as id138 (miller, 1995),
which contains lexical relationships between words for over a hundred thousand words, verbnet
(schuler, 2005) which contains lexical relations between verbs, and framenet (ruppenhofer et al.,
2006), which contains    word senses    for over ten thousand words along with examples of each
word sense. in addition, there exist several natural language processing tools such as part of speech
taggers, word category classi   ers, id27 models, id39 models, co-
reference resolution models, id14 models, semantic similarity models and sen-
timent analysis models (manning and sch  utze, 1999; jurafsky and martin, 2008; mikolov et al.,
2013; gurevych and strube, 2004; lin and walker, 2011b) that may be used by the natural lan-
guage interpreter to extract meaning from human utterances. since these tools are typically built
upon texts and annotations created by humans, using them inside a dialogue system can be inter-
preted as a form of structured id21, where the relationships or labels learned from the
original natural language processing corpus provide additional information to the dialogue system
and improve generalization of the system.

5.5.2 unstructured external knowledge

complementary sources of information can be found in unstructured knowledge sources, such
as online encyclopedias (wikipedia (denoyer and gallinari, 2007)) as well as domain-speci   c
sources (lowe et al., 2015b).
it is beyond the scope of this paper to review all possible ways
that these unstructured knowledge sources have or could be used in conjunction with a data-driven
dialogue system. however, we note that this is likely to be a fruitful research area.

5.6 personalized dialogue agents

when conversing, humans often adapt to their interlocutor to facilitate understanding, and thus
improve conversational ef   ciency and satisfaction. attaining human-level performance with dia-
logue agents may well require personalization, i.e. models that are aware and capable of adapting
to their intelocutor. such capabilities could increase the effectiveness and naturalness of generated
dialogues (lucas et al., 2009; su et al., 2013). we see personalization of dialogue systems as an
important task, which so far has not received much attention. there has been initial efforts on user-
speci   c models which could be adapted to work in combination with the dialogue models presented
in this survey (lucas et al., 2009; lin and walker, 2011a; pargellis et al., 2004). there has also been
interesting work on character modeling in movies (walker et al., 2011; li et al., 2016; mo et al.,
2016). there is signi   cant potential to learn user models as part of dialogue models. the large
datasets presented in this paper, some of which provide multiple dialogues per user, may enable the
development of such models.

33

5.7 id74

one of the most challenging aspects of constructing dialogue systems lies in their evaluation. while
the end goal is to deploy the dialogue system in an application setting and receive real human feed-
back, getting to this stage is time consuming and expensive. often it is also necessary to optimize
performance on a pseudo-performance metric prior to release. this is particularly true if a dialogue
model has many hyper-parameters to be optimized   it is infeasible to run user experiments for every
parameter setting in a grid search. although id104 platforms, such as amazon mechanical
turk, can be used for some user testing (jurc  cek et al., 2011), evaluations using paid subjects can
also lead to biased results (young et al., 2013). ideally, we would have some automated metrics for
calculating a score for each model, and only involve human evaluators once the best model has been
chosen with reasonable con   dence.

the evaluation problem also arises for non-goal-driven dialogue systems. here, researchers
have focused mainly on the output of the response generation module. evaluation of such non-goal-
driven dialogue systems can be traced back to the turing test (turing, 1950), where human judges
communicate with both computer programs and other humans over a chat terminal without knowing
each other   s true identity. the goal of the judges was to identify the humans and computer programs
under the assumption that a program indistinguishable from a real human being must be intelligent.
however, this setup has been criticized extensively with numerous researchers proposing alterna-
tive evaluation procedures (cohen, 2005). more recently, researchers have turned to analyzing the
collected dialogues produced after they are    nished (galley et al., 2015; pietquin and hastie, 2013;
shawar and atwell, 2007a; schatzmann et al., 2005).

even when human evaluators are available, it is often dif   cult to choose a set of informative
and consistent criteria that can be used to judge an utterance generated by a dialogue system. for
example, one might ask the evaluator to rate the utterance on vague notions such as    appropriateness   
and    naturalness   , or to try to differentiate between utterances generated by the system and those
generated by actual humans (vinyals and le, 2015). schatzmann et al. (2005) suggest two aspects
that need to be evaluated for all response generation systems (as well as user simulation models): 1)
if the model can generate human-like output, and 2) if the model can reproduce the variety of user
behaviour found in corpus. but we lack a de   nitive framework for such evaluations.

we complete this discussion by summarizing different approaches to the automatic evaluation

problem as they relate to these objectives.

5.7.1 automatic id74 for goal-driven dialogue systems

user evaluation of goal-driven dialogue systems typically focuses on goal-related performance cri-
teria, such as goal completion rate, dialogue length, and user satisfaction (walker et al., 1997;
schatzmann et al., 2005). these were originally evaluated by human users interacting with the
dialogue system, but more recently researchers have also begun to use third-party annotators for
evaluating recorded dialogues (yang et al., 2010). due to their simplicity, the vast majority of hand-
crafted task-oriented dialogue systems have been solely evaluated in this way. however, when using
machine learning algorithms to train on large-scale corpora, automatic optimization criteria are re-
quired. the challenge with evaluating goal-driven dialogue systems without human intervention is
that the process necessarily requires multiple steps   it is dif   cult to determine if a task has been
solved from a single utterance-response pair from a conversation. thus, simulated data is often gen-
erated by a user simulator (eckert et al., 1997; schatzmann et al., 2007; jung et al., 2009; georgila

34

et al., 2006; pietquin and hastie, 2013). given a suf   ciently accurate user simulation model, an
interaction between the dialogue system and the user can be simulated from which it is possible
to deduce the desired metrics, such as goal completion rate. signi   cant effort has been made to
render the simulated data as realistic as possible, by modeling user intentions. evaluation of such
simulation methods has already been conducted (schatzmann et al., 2005). however, generating
realistic user simulation models remains an open problem.

5.7.2 automatic id74 for non-goal-driven dialogue systems

evaluation of non-goal-driven dialogue systems, whether by automatic means or user studies, re-
mains a dif   cult challenge.

word overlap metrics. one approach is to borrow id74 from other nlp tasks
such as machine translation, which uses id7 (papineni et al., 2002) and meteor (banerjee and
lavie, 2005) scores. these metrics have been used to compare responses generated by a learned
dialogue strategy to the actual next utterance in the conversation, conditioned on a dialogue context
(sordoni et al., 2015b). while id7 scores have been shown to correlate with human judgements
for machine translation (papineni et al., 2002), their effectiveness for automatically assessing di-
alogue response generation is unclear. there are several issues to consider: given the context of
a conversation, there often exists a large number of possible responses that       t    into the dialogue.
thus, the response generated by a dialogue system could be entirely reasonable, yet it may have no
words in common with the actual next utterance. in this case, the id7 score would be very low,
but would not accurately re   ect the strength of the model. indeed, even humans who are tasked with
predicting the next utterance of a conversation achieve relatively low id7 scores (sordoni et al.,
2015b). although the meteor metric takes into account synonyms and morphological variants
of words in the candidate response, it still suffers from the aforementioned problems. in a sense,
these measurements only satisfy one direction of schatzmann   s criteria: high id7 and meteor
scores imply that the model is generating human-like output, but the model may still not reproduce
the variety of user behaviour found in corpus. furthermore, such metrics will only accurately re-
   ect the performance of the dialogue system if given a large number of candidate responses for each
given context.

next utterance classi   cation. alternatively, one can narrow the number of possible responses
to a small, pre-de   ned list, and ask the model to select the most appropriate response from this
list. the list includes the actual next response of the conversation (the desired prediction), and the
other entries (false positives) are sampled from elsewhere in the corpus (lowe et al., 2016, 2015a).
this next utterance classi   cation (nuc) task is derived from the recall and precision metrics for
information-retrieval-based approaches. there are several attractive properties of this metric: it
is easy to interpret, and the dif   culty can be adjusted by changing the number of false responses.
however, there are drawbacks. in particular, since the other candidate answers are sampled from
elsewhere in the corpus, there is a chance that these also represent reasonable responses given the
context. this can be alleviated to some extent by reporting recall@k measures, i.e. whether the
correct response is found in the k responses with the highest rankings according to the model.
although current models evaluated using nuc are trained explicitly to maximize the performance
on this metric by minimizing the cross-id178 between context-response pairs (lowe et al., 2015a;
kadlec et al., 2015), the metric could also be used to evaluate a probabilistic generative model
trained to output full utterances.

35

word perplexity. another metric proposed to evaluate probabilistic language models (bengio
et al., 2003; mikolov et al., 2010) that has seen signi   cant recent use for evaluating end-to-end
dialogue systems is word perplexity (pietquin and hastie, 2013; serban et al., 2016). perplexity ex-
plicitly measures the id203 that the model will generate the ground truth next utterance given
some context of the conversation. this is particularly appealing for dialogue, as the distribution over
words in the next utterance can be highly multi-modal (i.e. many possible responses). a re-weighted
perplexity metric has also been proposed where stop-words, punctuation, and end-of-utterance to-
kens are removed before evaluating to focus on the semantic content of the phrase (serban et al.,
2016). both word perplexity, as well as utterance-level recall and precision outlined above, satisfy
schatzmann   s evaluation criteria, since scoring high on these would require the model to produce
human-like output and to reproduce most types of conversations in the corpus.

response diversity. recent non-goal-driven dialogue systems based on neural networks have
had problems generating diverse responses (serban et al., 2016). (li et al., 2015) recently intro-
duced two new metrics, distinct-1 and distinct-2, which respectively measure the number of distinct
unigrams and bigrams of the generated responses. although these fail to satisfy either of schatz-
mann   s criteria, they may still be useful in combination with other metrics, such as id7, nuc or
word perplexity.

6. conclusion

there is strong evidence that over the next few years, dialogue research will quickly move towards
large-scale data-driven model approaches. in particular, as is the case for other language-related
applications such as id103, machine translation and information retrieval, these ap-
proaches will likely come in the form of end-to-end trainable systems. this paper provides an
extensive survey of currently available datasets suitable for research, development, and evaluation
of such data-driven dialogue systems.

in addition to presenting the datasets, we provide a detailed discussion of several of the is-
sues related to the use of datasets in dialogue system research. several potential directions are
highlighted, such as id21 and incorporation of external knowledge, which may lead to
scalable solutions for end-to-end training of conversational agents.

acknowledgements

the authors gratefully acknowledge    nancial support by the samsung advanced institute of tech-
nology (sait), the natural sciences and engineering research council of canada (nserc), the
canada research chairs, the canadian institute for advanced research (cifar) and compute
canada. early versions of the manuscript bene   ted greatly from the proofreading of melanie
lyman-abramovitch, and later versions were extensively revised by genevieve fried and nico-
las angelard-gontier. the authors also thank nissan pow, michael noseworthy, chia-wei liu,
gabriel forgues, alessandro sordoni, yoshua bengio and aaron courville for helpful discussions.

references
b. aarts and s. a. wallis. the diachronic corpus of present-day spoken english (dcpse), 2006.
r. abbott, b. ecker, p. anand, and m. walker. internet argument corpus 2.0: an sql schema for dialogic social media

and the corpora to go with it. in language resources and evaluation conference, lrec2016, 2016.

36

s. afantenos, n. asher, f. benamara, a. cadilhac, c  edric d  egremont, p. denis, m. guhe, s. keizer, a. lascarides,
o. lemon, et al. developing a corpus of strategic conversation in the settlers of catan. in seinedial 2012-the 16th
workshop on the semantics and pragmatics of dialogue, 2012.

y. al-onaizan, u. germann, u. hermjakob, k. knight, p. koehn, d. m., and k. yamada. translating with scarce

resources. in aaai, 2000.

j. alexandersson, r. engel, m. kipp, s. koch, u. k  ussner, n. reithinger, and m. stede. modeling negotiation dialogs.

in verbmobil: foundations of speech-to-speech translation, pages 441   451. springer, 2000.

d. ameixa and l. coheur. from subtitles to human interactions: introducing the subtle corpus. technical report, tech.

rep., 2013.

d. ameixa, luisa coheur, p. fialho, and p. quaresma. luke, i am your father: dealing with out-of-domain requests by

using movies subtitles. in intelligent virtual agents, pages 13   21, 2014.

a. h. anderson, m. bader, e. g. bard, e. boyle, g. doherty, s. garrod, s. isard, j. kowtko, j. mcallister, j. miller, et al.

the hcrc map task corpus. language and speech, 34(4):351   366, 1991.

j. andreas, s. rosenthal, and k. mckeown. annotating agreement and disagreement in threaded discussion. in lrec,

pages 818   822. citeseer, 2012.

l. e. asri, j. he, and k. suleman. a sequence-to-sequence model for user simulation in spoken dialogue systems. arxiv

preprint arxiv:1607.00070, 2016.

a. j. aubrey, d. marshall, p. l. rosin, j. vandeventer, d. w. cunningham, and c. wallraven. cardiff conversation
database (ccdb): a database of natural dyadic conversations. in id161 and pattern recognition workshops
(cvprw), ieee conference on, pages 277   282, 2013.

h. aust, m. oerder, f. seide, and v. steinbiss. the philips automatic train timetable information system. speech

communication, 17(3):249   262, 1995.

a. aw, m. zhang, j. xiao, and j. su. a phrase-based statistical model for sms text id172. in proceedings of the

coling, pages 33   40, 2006.

r. e. banchs. movie-dic: a movie dialogue corpus for research and development. in proceedings of the 50th annual

meeting of the association for computational linguistics: short papers, 2012.

r. e. banchs and h. li. iris: a chat-oriented dialogue system based on the vector space model. in proceedings of the

acl 2012 system demonstrations, 2012.

s. banerjee and a. lavie. meteor: an automatic metric for mt evaluation with improved correlation with human
judgments. in proceedings of the acl workshop on intrinsic and extrinsic evaluation measures for machine translation
and/or summarization, 2005.

m. barlow. corpus of spoken, professional american-english, 2000.
j. beare and b. scott. the spoken corpus of the survey of english dialects: language variation and oral history.

in

proceedings of allc/ach, 1999.

y. bengio, r. ducharme, p. vincent, and c. janvin. a neural probabilistic language model. the journal of machine

learning research, 3:1137   1155, 2003.

y. bengio, i. goodfellow, and a. courville. deep learning. an mit press book in preparation. draft chapters available

at http://www. iro. umontreal. ca/ bengioy/dlbook, 2014.

c. bennett and a. i rudnicky. the carnegie mellon communicator corpus, 2002.
d. biber and e. finegan. an initial typology of english text types. corpus linguistics ii: new studies in the analysis and

exploitation of computer corpora, pages 19   46, 1986.

d. biber and e. finegan. diachronic relations among speech-based and written registers in english. variation in english:

multi-dimensional studies, pages 66   83, 2001.

s. bird, s. browning, r. moore, and m. russell. dialogue move recognition using topic spotting techniques. in spoken

dialogue systems-theories and applications, 1995.

a. w. black, s. burger, a. conkie, h. hastie, s. keizer, o. lemon, n. merigaud, g. parent, g. schubiner, b. thomson,
in special interest group on

et al. spoken dialog challenge 2010: comparison of live and control test results.
discourse and dialogue (sigdial), 2011.

d. bohus and a. i rudnicky. sorry, i didnt catch that!

in recent trends in discourse and dialogue, pages 123   154.

springer, 2008.

s. e. brennan, k. s. schuhmann, and k. m. batres. entrainment on the move and in the lab: the walking around corpus.

in proceedings of the 35th annual conference of the cognitive science society, 2013.

g. brown, a. anderson, r. shillcock, and g. yule. teaching talk. cambridge: cup, 1984.
s. burger, k. weilhammer, f. schiel, and h. g. tillmann. verbmobil data collection and annotation.

in verbmobil:

foundations of speech-to-speech translation, pages 537   549. springer, 2000.

37

j. e. cahn and s. e. brennan. a psychological model of grounding and repair in dialog.

in aaai symposium on

psychological models of communication in collaborative systems, 1999.

a. canavan and g. zipperlen. callfriend american english-non-southern dialect. linguistic data consortium, 10:1, 1996.
a. canavan, d. graff, and g. zipperlen. callhome american english speech. linguistic data consortium, 1997.
s. k. card, t. p. moran, and a. newell. the psychology of human-computer interaction. l. erlbaum associates inc.,

hillsdale, nj, usa, 1983. isbn 0898592437.

r. carter. orders of reality: cancode, communication, and culture. elt journal, 52(1):43   56, 1998.
r. carter and m. mccarthy. cambridge grammar of english: a comprehensive guide; spoken and written english

grammar and usage. ernst klett sprachen, 2006.

tanya l. chartrand and j. a. bargh. the chameleon effect: the perception   behavior link and social interaction. journal

of personality and social psychology, 76(6):893, 1999.

t. chen and m. kan. creating a live, public short message service corpus: the nus sms corpus. language resources and

evaluation, 47(2):299   335, 2013.

y.-n. chen, d. hakkani-t  ur, and x. he. zero-shot learning of intent embeddings for expansion by convolutional deep
structured semantic models. in acoustics, speech and signal processing (icassp), 2016 ieee international confer-
ence on, pages 6045   6049. ieee, 2016.

a. clark. pre-processing very noisy text. in proc. of workshop on shallow processing of large corpora, pages 12   22,

2003.

h. h. clark and s. e. brennan. grounding in communication. perspectives on socially shared cognition, 13:127   149,

1991.

p. r. cohen. if not turing   s test, then what? ai magazine, 26(4):61, 2005.
k. m. colby. modeling a paranoid mind. behavioral and brain sciences, 4:515   534, 1981.
r. m. cooper. the control of eye    xation by the meaning of spoken language: a new methodology for the real-time

investigation of speech perception, memory, and language processing. cognitive psychology, 6(1):84   107, 1974.

n. cristianini and j. shawe-taylor. an introduction to support vector machines: and other kernel-based learning

methods. cambridge university press, 2000.

h. cuay  ahuitl, s. renals, o. lemon, and h. shimodaira. human-computer dialogue simulation using hidden markov

models. in automatic id103 and understanding, 2005 ieee workshop on, pages 290   295, 2005.

h. cuay  ahuitl, s. keizer, and o. lemon. strategic dialogue management via deep id23. arxiv preprint

arxiv:1511.08099, 2015.

c. danescu-niculescu-mizil and l. lee. chameleons in imagined conversations: a new approach to understanding
coordination of linguistic style in dialogs. in proceedings of the workshop on cognitive modeling and computational
linguistics, acl, 2011.

l. daubigney, m. geist, s. chandramohan, and o. pietquin. a comprehensive id23 framework for

dialogue management optimization. ieee journal of selected topics in signal processing, 6(8):891   902, 2012.

m. davies. comparing the corpus of american soap operas, coca, and the bnc, 2012a.
m. davies. corpus of american soap operas, 2012b.
i. de kok, d. heylen, and l. morency. speaker-adaptive multimodal prediction model for listener responses. in proceed-

ings of the 15th acm on international conference on multimodal interaction, 2013.

l. deng and x. li. machine learning paradigms for id103: an overview. audio, speech, and language

processing, ieee transactions on, 21(5):1060   1089, 2013.

l. denoyer and p. gallinari. the wikipedia xml corpus.

in comparative evaluation of xml information retrieval

systems, pages 12   19. springer, 2007.

b. dhingra, z. zhou, d. fitzpatrick, m. muehl, and w. cohen. tweet2vec: character-based distributed representations

for social media. arxiv preprint arxiv:1605.03481, 2016.

a. djalali, s. lauer, and c. potts. corpus evidence for preference-driven interpretation. in logic, language and meaning,

pages 150   159. springer, 2012.

j. dodge, a. gane, x. zhang, a. bordes, s. chopra, a. miller, a. szlam, and j. weston. evaluating prerequisite qualities

for learning end-to-end id71. arxiv preprint arxiv:1511.06931, 2015.

s. dose. flipping the script: a corpus of american television series (cats) for corpus-based language learning and

teaching. corpus linguistics and variation in english: focus on non-native englishes, 2013.

e. douglas-cowie, r. cowie, i. sneddon, c. cox, o. lowry, m. mcrorie, j. martin, l. devillers, s. abrilian, a. batliner,
et al. the humaine database: addressing the collection and annotation of naturalistic and induced emotional data. in
affective computing and intelligent interaction, pages 488   500. springer, 2007.

38

w. eckert, e. levin, and r. pieraccini. user modeling for spoken dialogue system evaluation. in automatic speech

recognition and understanding, 1997. proceedings., 1997 ieee workshop on, pages 80   87, 1997.

l. el asri, h. schulz, s. sharma, j. zumer, j. harris, e. fine, r. mehrotra, and k. suleman. frames: acorpus
for adding memory to goal-oriented dialogue systems. preprint on webpage at http://www.maluuba.com/
publications/, 2017.

m. elsner and e. charniak. you talking to me? a corpus and algorithm for conversation disentanglement. in association

for computational linguistics (acl), 2008.

d. erhan, y. bengio, a. courville, pierre-a. manzagol, and p. vincent. why does unsupervised pre-training help deep

learning? journal of machine learning research, 11, 2010.

g. di fabbrizio, g. tur, and d. hakkani-tr. id64 spoken id71 with data reuse. in special interest

group on discourse and dialogue (sigdial), 2004.

m. fatemi, l. e. asri, h. schulz, j. he, and k. suleman. policy networks with two-stage training for dialogue systems.

in special interest group on discourse and dialogue (sigdial), 2016.

d. fisher, m. smith, and h. t welser. you are who you talk to: detecting roles in usenet newsgroups. in proceedings of
the 39th annual hawaii international conference on system sciences (hicss   06), volume 3, pages 59b   59b, 2006.
in corpus linguistics,

p. forchini. spontaneity reloaded: american face-to-face and movie conversation compared.

2009.

p. forchini. movie language revisited. evidence from multi-dimensional analysis and corpora. peter lang, 2012.
g. forgues, j. pineau, j. larchev  eque, and r. tremblay. id64 id71 with id27s. in work-
shop on modern machine learning and natural language processing, advances in neural information processing
systems (nips), 2014.

e. n. forsyth and c. h. martell. lexical and discourse analysis of online chat dialog. in international conference on

semantic computing (icsc)., pages 19   26, 2007.

m. frampton and o. lemon. recent research advances in id23 in spoken dialogue systems. the

knowledge engineering review, 24(04):375   408, 2009.

m. galley, c. brockett, a. sordoni, y. ji, m. auli, c. quirk, m. mitchell, j. gao, and b. dolan. deltaid7: a dis-
criminative metric for generation tasks with intrinsically diverse targets. in proceedings of the 53rd annual meeting
of the association for computational linguistics and the 7th international joint conference on natural language
processing of the asian federation of natural language processing, acl, pages 445   450, 2015.

m. ga  si  c, f. jur  c      cek, s. keizer, f. mairesse, b. thomson, k. yu, and s. young. gaussian processes for fast policy
optimisation of pomdp-based dialogue managers. in proceedings of the 11th annual meeting of the special interest
group on discourse and dialogue, pages 201   204. association for computational linguistics, 2010.

m. ga  si  c, f. jur  c      cek, b. thomson, k. yu, and s. young. on-line policy optimisation of spoken dialogue systems via live
interaction with human subjects. in ieee workshop on automatic id103 and understanding (asru),
pages 312   317. ieee, 2011.

m. ga  si  c, m. henderson, b. thomson, p. tsiakoulis, and s. young. policy optimisation of pomdp-based dialogue systems
without state space compression. in spoken language technology workshop (slt), 2012 ieee, pages 31   36. ieee,
2012.

m. gasic, c. breslin, m. henderson, d. kim, m. szummer, b. thomson, p. tsiakoulis, and s. young. on-line pol-
icy optimisation of bayesian spoken dialogue systems via human interaction. in ieee international conference on
acoustics, speech and signal processing, pages 8367   8371, 2013.

m. ga  si  c, n. mrk  si  c, l. m. rojas-barahona, p.-h. su, s. ultes, d. vandyke, t.-h. wen, and s. young. dialogue manager

id20 using gaussian process id23. computer speech & language, 2016.

a. genevay and r. laroche. id21 for user adaptation in spoken dialogue systems. in proceedings of the 2016
international conference on autonomous agents & multiagent systems, pages 975   983. international foundation for
autonomous agents and multiagent systems, 2016.

k. georgila, j. henderson, and o. lemon. user simulation for spoken dialogue systems: learning and evaluation. in

proceedings of interspeech, 2006.

k. georgila, m. wolters, j. d. moore, and r. h. logie. the match corpus: a corpus of older and younger users

interactions with spoken dialogue systems. language resources and evaluation, 44(3):221   261, 2010.

j. gibson and a. d. pick. perception of another person   s looking behavior. the american journal of psychology, 76(3):

386   394, 1963.

j. j godfrey, e. c holliman, and j mcdaniel. switchboard: telephone speech corpus for research and development.

in international conference on acoustics, speech, and signal processing (icassp-92), 1992.

39

i. goodfellow, a. courville, and y. bengio. deep learning. book in preparation for mit press, 2015. url http:

//goodfeli.github.io/dlbook/.

j. t. goodman. a bit of progress in id38 extended version. machine learning and applied statistics

group microsoft research. technical report, msr-tr-2001-72, 2001.

c. goodwin. conversational organization: interaction between speakers and hearers. new york: academic press,

1981.

a. l. gorin, g. riccardi, and j. h. wright. how may i help you? speech communication, 23(1):113   127, 1997.
a. graves. sequence transduction with recurrent neural networks. in proceedings of the 29th international conference

on machine learning (icml), representation learning workshop, 2012.

a. graves, g. wayne, and i. danihelka. id63s. arxiv preprint arxiv:1410.5401, 2014.
s. greenbaum. comparing english worldwide: the international corpus of english. clarendon press, 1996.
s. greenbaum and g nelson. the international corpus of english (ice) project. world englishes, 15(1):3   15, 1996.
c. g  ulc  ehre, o. firat, k. xu, k. cho, l. barrault, h. lin, f. bougares, h. schwenk, and y. bengio. on using monolingual

corpora in id4. corr, abs/1503.03535, 2015.

i. gurevych and m. strube. semantic similarity applied to spoken dialogue summarization. in proceedings of the 20th

international conference on computational linguistics, 2004.

v. haslerud and a. stenstr  om. the bergen corpus of london teenager language (colt). spoken english on computer.

transcription, mark-up and application. london: longman, pages 235   242, 1995.

p. a. heeman and j. f. allen. the trains 93 dialogues. technical report, dtic document, 1995.
c. t. hemphill, j. j. godfrey, and g. r. doddington. the atis spoken language systems pilot corpus. in proceedings of

the darpa speech and natural language workshop, pages 96   101, 1990.

m. henderson, b. thomson, and s. young. deep neural network approach for the dialog state tracking challenge. in

special interest group on discourse and dialogue (sigdial), 2013.

m. henderson, b. thomson, and j. williams. dialog state tracking challenge 2 & 3, 2014a.
m. henderson, b. thomson, and j. williams. the second dialog state tracking challenge. in special interest group on

discourse and dialogue (sigdial), 2014b.

m. henderson, b. thomson, and s. young. word-based dialog state tracking with recurrent neural networks. in 15th

special interest group on discourse and dialogue (sigdial), page 292, 2014c.

g. hinton, l. deng, d. yu, g. e. dahl, a. mohamed, n. jaitly, a. senior, v. vanhoucke, p. nguyen, t.a n. sainath, et al.
deep neural networks for acoustic modeling in id103: the shared views of four research groups. signal
processing magazine, ieee, 29(6):82   97, 2012.

t. hiraoka, g. neubig, k. yoshino, t. toda, and s. nakamura. active learning for example-based id71. in

proc intl workshop on spoken id71, saariselka, finland, 2016.

h. hung and g. chittaranjan. the idiap wolf corpus: exploring group behaviour in a competitive role-playing game. in

proceedings of the international conference on multimedia, pages 879   882, 2010.

j. l. hutchens and m. d. alder. introducing megahal. in proceedings of the joint conferences on new methods in

language processing and computational natural language learning, 1998.

arne j. and nils d. talking to a computer is not like talking to your best friend. in proceedings of the    rst scandinivian

conference on arti   cial intelligence, 1988.

s. jung, c. lee, k. kim, m. jeong, and g. g. lee. data-driven user simulation for automated evaluation of spoken dialog

systems. computer speech & language, 23(4):479   509, 2009.

d. jurafsky and j. h. martin. speech and language processing, 2nd edition. prentice hall, 2008.
f. jurc  cek, s. keizer, m. ga  sic, f. mairesse, b. thomson, k. yu, and s. young. real user evaluation of spoken dialogue

systems using amazon mechanical turk. in proceedings of interspeech, volume 11, 2011.

f. jur  c      cek, b. thomson, and s. young. id23 for parameter estimation in statistical spoken dialogue

systems. computer speech & language, 26(3):168   192, 2012.

r. kadlec, m. schmid, and j. kleindienst. improved deep learning baselines for ubuntu corpus dialogs. neural informa-

tion processing systems workshop on machine learning for spoken language understanding, 2015.

m. kaufmann and j. kalita. syntactic id172 of twitter messages. in international conference on natural language

processing, kharagpur, india, 2010.

s. kim, l. f. dharo, r. e. banchs, j. williams, and m. henderson. dialog state tracking challenge 4, 2015.
s. kim, l. f. dharo, r. e. banchs, j. d. williams, m. henderson, and k. yoshino. the    fth dialog state tracking

challenge. in ieee spoken language technology workshop (slt), 2016.

d. koller and n. friedman. probabilistic id114: principles and techniques. mit press, 2009.

40

j. a konstan, b. n. miller, d. maltz, j. l. herlocker, l. r. gordon, and j. riedl. grouplens: applying collaborative

   ltering to usenet news. communications of the acm, 40(3):77   87, 1997.

a. kumar, o. irsoy, j. su, j. bradbury, r. english, b. pierce, p. ondruska, i. gulrajani, and r. socher. ask me anything:

dynamic memory networks for natural language processing. neural information processing systems (nips), 2015.

m. kyt  o and t. walker. guide to a corpus of english dialogues 1560-1760. acta universitatis upsaliensis, 2006.
i. langkilde and k. knight. generation that exploits corpus-based statistical knowledge. in proceedings of the 36th an-
nual meeting of the association for computational linguistics and 17th international conference on computational
linguistics-volume 1, pages 704   710. association for computational linguistics, 1998.

g. leech. 100 million words of english: the british national corpus (bnc). language research, 28(1):1   13, 1992.
e. levin and r. pieraccini. a stochastic model of computer-human interaction for learning dialogue strategies.

in

eurospeech, volume 97, pages 1883   1886, 1997.

e. levin, r. pieraccini, and w. eckert. learning dialogue strategies within the markov decision process framework. in
automatic id103 and understanding, 1997. proceedings., 1997 ieee workshop on, pages 72   79. ieee,
1997.

j. li, m. galley, c. brockett, j. gao, and b. dolan. a diversity-promoting objective function for neural conversation

models. arxiv preprint arxiv:1510.03055, 2015.

j. li, m. galley, c. brockett, j. gao, and bill d. a persona-based neural conversation model. in acl, pages 994   1003,

2016.

g. lin and m. walker. all the world   s a stage: learning character models from    lm. in aaai conference on arti   cial

intelligence and interactive digital entertainment, 2011a.

g. i. lin and m. a. walker. all the world   s a stage: learning character models from    lm. in aiide, 2011b.
c. lord and m. haith. the perception of eye contact. attention, perception, & psychophysics, 16(3):413   416, 1974.
r. lowe, n. pow, i. serban, and j. pineau. the ubuntu dialogue corpus: a large dataset for research in unstructured

multi-turn dialogue systems. in special interest group on discourse and dialogue (sigdial), 2015a.

r. lowe, n. pow, i. v. serban, l. charlin, and j. pineau. incorporating unstructured textual knowledge sources into neural
dialogue systems. neural information processing systems workshop on machine learning for spoken language
understanding, 2015b.

r. lowe, i. v. serban, m. noseworthy, l. charlin, and j. pineau. on the evaluation of dialogue systems with next

utterance classi   cation. in special interest group on discourse and dialogue (sigdial), 2016.

j. m. lucas, f. feid56dez, j. salazar, j. ferreiros, and r. san segundo. managing speaker identity and user pro   les in a

spoken dialogue system. in procesamiento del lenguaje natural, number 43 in 1, pages 77   84, 2009.

b. macwhinney and c. snow. the child language data exchange system. journal of child language, 12(02):271   295,

1985.

f. mairesse and s. young. stochastic language generation in dialogue using factored language models. computational

linguistics, 2014.

f. mairesse, m. ga  si  c, f. jur  c      cek, s. keizer, b. thomson, k. yu, and s. young. phrase-based statistical language
generation using id114 and active learning. in proceedings of the 48th annual meeting of the association
for computational linguistics, pages 1552   1561. association for computational linguistics, 2010.

c. d. manning and h. sch  utze. foundations of statistical natural language processing. mit press, 1999.
m. mccarthy. spoken language and applied linguistics. ernst klett sprachen, 1998.
s. mcglashan, n. fraser, n. gilbert, e. bilange, p. heisterkamp, and n. youd. dialogue management for telephone
information systems. in proceedings of the third conference on applied natural language processing, pages 245   246.
association for computational linguistics, 1992.

g. mckeown, m. f valstar, r. cowie, and m. pantic. the semaine corpus of emotionally coloured character interac-

tions. in multimedia and expo (icme), 2010 ieee international conference on, pages 1079   1084, 2010.

t. mikolov, m. kara     at, l. burget, j. cernock`y, and sanjeev khudanpur. recurrent neural network based language

model. in 11th proceedings of interspeech, pages 1045   1048, 2010.

t. mikolov, i. sutskever, k. chen, g. s. corrado, and j. dean. distributed representations of words and phrases and their

compositionality. in advances in neural information processing systems, pages 3111   3119, 2013.

g. a. miller. id138: a lexical database for english. communications of the acm, 38(11):39   41, 1995.
x. a. miro, s. bozonnet, n. evans, c. fredouille, g. friedland, and o. vinyals. speaker diarization: a review of recent

research. audio, speech, and language processing, ieee transactions on, 20(2):356   370, 2012.

k. mo, s. li, y. zhang, j. li, and q. yang. personalizing a dialogue system with id21. arxiv preprint

arxiv:1610.02891, 2016.

s. mohan and j. laird. learning goal-oriented hierarchical tasks from situated interactive instruction. in aaai, 2014.

41

t. nguyen, m. rosenberg, x. song, j. gao, s. tiwary, r. majumder, and l. deng. ms marco: a human generated

id17 dataset. arxiv preprint arxiv:1611.09268, 2016.

l. nio, s. sakti, g. neubig, t. toda, m. adriani, and sa. nakamura. developing non-goal dialog system based on
in natural interaction with robots, knowbots and smartphones, pages 355   361.

examples of drama television.
springer, 2014a.

l nio, s. sakti, g. neubig, t. toda, and s. nakamura. conversation dialog corpora from television and movie scripts. in
17th oriental chapter of the international committee for the co-ordination and standardization of speech databases
and assessment techniques (cocosda), pages 1   4, 2014b.

e. n  oth, a. horndasch, f. gallwitz, and j. haas. experiences with commercial telephone-based dialogue systems. it   

information technology (vormals it+ ti), 46(6/2004):315   321, 2004.

c. oertel, f. cummins, j. edlund, p. wagner, and n. campbell. d64: a corpus of richly recorded conversational

interaction. journal on multimodal user interfaces, 7(1-2):19   28, 2013.

a. h. oh and a. i. rudnicky. stochastic language generation for spoken dialogue systems. in conference of the north
american chapter of the association for computational linguistics (naacl 2000), workshop on conversational
systems, volume 3, pages 27   32. association for computational linguistics, 2000.

t. paek. id23 for spoken dialogue systems: comparing strengths and weaknesses for practical deploy-

ment. in proc. dialog-on-dialog workshop, interspeech, 2006.

k. papineni, s. roukos, t ward, and w zhu. id7: a method for automatic evaluation of machine translation.

in

proceedings of the 40th annual meeting on association for computational linguistics (acl), 2002.

a. n. pargellis, h-k. j. kuo, and c. lee. an automatic dialogue generation platform for personalized dialogue applica-

tions. speech communication, 42(3-4):329   351, 2004. doi: 10.1016/j.specom.2003.10.003.

r. passonneau and e. sachar. loqui human-human dialogue corpus (transcriptions and annotations), 2014.
d. perez-marin and i. pascual-nieto. conversational agents and natural language interaction: techniques and effective

practices. igi global, 2011.

s. petrik. wizard of oz experiments on speech dialogue systems. phd thesis, technischen universitat graz, 2004.
r. pieraccini, d. suendermann, k. dayanidhi, and j. liscombe. are we there yet? research in commercial spoken dialog

systems. in text, speech and dialogue, pages 3   13, 2009.

o. pietquin. a framework for unsupervised learning of dialogue strategies. presses universit  e catholique de louvain,

2004.

o. pietquin. a probabilistic description of man-machine spoken communication. in multimedia and expo, 2005. icme

2005. ieee international conference on, pages 410   413, 2005.

o. pietquin. learning to ground in spoken dialogue systems. in acoustics, speech and signal processing, 2007. icassp

2007. ieee international conference on, volume 4, pages iv   165, 2007.

o pietquin and t. dutoit. a probabilistic framework for dialog simulation and optimal strategy learning. ieee transac-

tions on audio, speech, and language processing, 14(2):589   599, 2006.

o. pietquin and h. hastie. a survey on metrics for the evaluation of user simulations. the knowledge engineering review,

28(01):59   73, 2013.

b. piot, m. geist, and o. pietquin. imitation learning applied to embodied conversational agents. in 4th workshop on

machine learning for interactive systems (mlis 2015), volume 43, 2015.

s. png and j. pineau. bayesian id23 for pomdp-based dialogue systems. in ieee international con-

ference on acoustics, speech and signal processing (icassp), pages 2156   2159, 2011.

c. potts. goal-driven answers in the cards dialogue corpus. in proceedings of the 30th west coast conference on formal

linguistics, pages 1   20, 2012.

a. ratnaparkhi. trainable approaches to surface id86 and their application to conversational

id71. computer speech & language, 16(3):435   455, 2002.

a. raux, b. langner, d. bohus, a. w. black, and m. eskenazi. lets go public! taking a spoken dialog system to the real

world. in proceedings of interspeech. citeseer, 2005.

n. reithinger and m. klesen. dialogue act classi   cation using language models. in eurospeech, 1997.
h. ren, w. xu, y. zhang, and y. yan. dialog state tracking using conditional random    elds. in special interest group

on discourse and dialogue (sigdial), 2013.

s. renals, t. hain, and h. bourlard. recognition and understanding of meetings the ami and amida projects. in ieee

workshop on automatic id103 & understanding (asru), 2007.

r. reppen and n. ide. the american national corpus overall goals and the    rst release. journal of english linguistics,

32(2):105   113, 2004.

42

j. rickel and w. l. johnson. animated agents for procedural training in virtual reality: perception, cognition, and motor

control. applied arti   cial intelligence, 13(4-5):343   382, 1999.

v. rieser and o. lemon. id86 as planning under uncertainty for spoken dialogue systems. in

empirical methods in id86, pages 105   120. springer, 2010.

a. ritter, c. cherry, and b. dolan. unsupervised modeling of twitter conversations. in north american chapter of the

association for computational linguistics (naacl 2010), 2010.

a. ritter, c. cherry, and w. b. dolan. data-driven response generation in social media. in proceedings of the conference

on empirical methods in natural language processing, 2011.

s. rosenthal and k. mckeown. i couldnt agree more: the role of conversational structure in agreement and disagreement

detection in online discussions. in special interest group on discourse and dialogue (sigdial), page 168, 2015.

s. rosset and s. petel. the ritel corpus-an annotated human-machine open-domain id53 spoken dialog

corpus. in the international conference on language resources and evaluation (lrec), 2006.

s. rossignol, o. pietquin, and m. ianotto. training a bn-based user model for dialogue simulation with missing data. in

proceedings of the international joint conference on natural language processing, pages 598   604, 2011.

a. roy, c. guinaudeau, h. bredin, and c. barras. tvd: a reproducible and multiply aligned tv series dataset. in the

international conference on language resources and evaluation (lrec), volume 2, 2014.

j. ruppenhofer, m. ellsworth, m. r.l. petruck, c. r. johnson, and j. scheffczyk. framenet ii: extended theory and

practice. international computer science institute, 2006. distributed with the framenet data.

j. schatzmann and s. young. the hidden agenda user simulation model.

ieee transactions on audio, speech, and

language processing, 17(4):733   747, 2009.

j. schatzmann, k. georgila, and s. young. quantitative evaluation of user simulation techniques for spoken dialogue

systems. in special interest group on discourse and dialogue (sigdial), 2005.

j. schatzmann, k. weilhammer, m. stuttle, and s. young. a survey of statistical user simulation techniques for
reinforcement-learning of dialogue management strategies. the knowledge engineering review, 21(02):97   126,
2006.

j. schatzmann, b. thomson, k. weilhammer, . ye, and s. young. agenda-based user simulation for id64 a
pomdp dialogue system. in human language technologies 2007: the conference of the north american chapter of
the association for computational linguistics; companion volume, short papers, pages 149   152, 2007.

j. n. schrading. analyzing domestic abuse using natural language processing on social media data. master   s thesis,

rochester institute of technology, 2015. http://scholarworks.rit.edu/theses.

n. schrading, c. o. alm, r. ptucha, and c. m. homan. an analysis of domestic a.se discourse on reddit. in empirical

methods in natural language processing (emnlp), 2015.

k. k. schuler. verbnet: a broad-coverage, comprehensive verb lexicon. phd thesis, university of pennsylvania, 2005.

paper aai3179808.

i. v. serban. maximum likelihood learning and id136 in conditional random    elds. bachelor   s thesis, university of

copenhagen, denmark, 2012. http://www.blueanalysis.com/thesis/thesis.pdf.

i. v. serban and j. pineau. text-based speaker identi   cation for multi-participant open-domain dialogue systems. neural

information processing systems workshop on machine learning for spoken language understanding, 2015.

i. v. serban, a. sordoni, y. bengio, a. courville, and j. pineau. building end-to-end dialogue systems using genera-

tive hierarchical neural networks. in aaai, 2016. in press.

i. v. serban, t. klinger, g. tesauro, k. talamadupula, b. zhou, y. bengio, and a. courville. multiresolution recurrent

neural networks: an application to dialogue response generation. in aaai conference, 2017a.

i. v. serban, a. sordoni, r. lowe, l. charlin, j. pineau, a. courville, and y. bengio. a hierarchical latent variable

encoder-decoder model for generating dialogues. in aaai conference, 2017b.

s. shaikh, t. strzalkowski, g. a. broadwell, j. stromer-galley, s. m. taylor, and n. webb. mpc: a multi-party chat
corpus for modeling social phenomena in discourse. in the international conference on language resources and
evaluation (lrec), 2010.

l. shang, z. lu, and h. li. neural responding machine for short-text conversation. arxiv preprint arxiv:1503.02364,

2015.

c. shaoul and c. westbury. a usenet corpus (2005-2009), 2009.
s. sharma, j. he, k. suleman, h. schulz, and p. bachman. id86 in dialogue using lexicalized and

delexicalized data. arxiv preprint arxiv:1606.03632, 2016.

b. a. shawar and e. atwell. different measurements metrics to evaluate a chatbot system.

in proceedings of the

workshop on bridging the gap: academic and industrial research in dialog technologies, pages 89   96, 2007a.

b. a. shawar and eric atwell. chatbots: are they really useful? in ldv forum, volume 22, pages 29   49, 2007b.

43

e. shriberg, r. dhillon, s. bhagat, j. ang, and h. carvey. the icsi meeting recorder dialog act (mrda) corpus. technical

report, dtic document, 2004.

a. simpson and n. m eraser. black box and glass box evaluation of the sundial system. in third european conference

on speech communication and technology, 1993.

s. singh, d. litman, m. kearns, and m. walker. optimizing dialogue management with id23: experi-

ments with the njfun system. journal of arti   cial intelligence research, pages 105   133, 2002.

s. p. singh, m. j. kearns, d. j. litman, and m. a. walker. id23 for spoken dialogue systems. in

neural information processing systems, 1999.

a. sordoni, y. bengio, h. vahabi, c. lioma, j. g. simonsen, and j. nie. a hierarchical recurrent encoder-decoder for
generative context-aware query suggestion. in proceedings of the 24th acm international conference on information
and knowledge management (cikm 2015), 2015a.

a. sordoni, m. galley, m. auli, c. brockett, y. ji, m. mitchell, j. nie, j. gao, and b. dolan. a neural network approach
in conference of the north american chapter of the

to context-sensitive generation of conversational responses.
association for computational linguistics (naacl-hlt 2015), 2015b.

a. stenstr  om, g. andersen, and i. k. hasund. trends in teenage talk: corpus compilation, analysis and    ndings,

volume 8. j. benjamins, 2002.

a. stent, r. prasad, and m. walker. trainable sentence planning for complex information presentation in spoken dialog
systems. in proceedings of the 42nd annual meeting on association for computational linguistics, page 79. association
for computational linguistics, 2004.

a. stolcke, k. ries, n. coccaro, e. shriberg, r. bates, d. jurafsky, p. taylor, r. martin, c. van ess-dykema, and
m. meteer. dialogue act modeling for automatic tagging and recognition of conversational speech. computational
linguistics, 26(3):339   373, 2000.

p.-h. su, y.-b. wang, t.-h. yu, and l.-s. lee. a dialogue game framework with personalized training using reinforce-
ment learning for computer-assisted language learning. in 2013 ieee international conference on acoustics, speech
and signal processing, pages 8213   8217. ieee, 2013.

p.-h. su, d. vandyke, m. gasic, d. kim, n. mrksic, t.-h. wen, and s. young. learning from real users: rating dialogue

success with neural networks for id23 in spoken dialogue systems. in interspeech, 2015.

p.-h. su, m. gasic, n. mrksic, l. rojas-barahona, s. ultes, d. vandyke, t.-h. wen, and s. young. continuously learning

neural dialogue management. arxiv preprint arxiv:1606.02689, 2016.

s. sukhbaatar, a. szlam, j. weston, and r. fergus. end-to-end memory networks. in neural information processing

systems (nips), 2015.

x. sun, j. lichtenauer, m. valstar, a. nijholt, and m. pantic. a multimodal database for mimicry analysis. in affective

computing and intelligent interaction, pages 367   376. springer, 2011.

j. svartvik. the london-lund corpus of spoken english: description and research. number 82 in 1. lund university

press, 1990.

b. thomson and s. young. bayesian update of dialogue state: a pomdp framework for spoken dialogue systems.

computer speech & language, 24(4):562   588, 2010.

j. tiedemann. parallel data, tools and interfaces in opus. in the international conference on language resources and

evaluation (lrec), 2012.

s. e. tranter, d. reynolds, et al. an overview of automatic speaker diarization systems. audio, speech, and language

processing, ieee transactions on, 14(5):1557   1565, 2006.

d. traum and j. rickel. embodied agents for multi-party dialogue in immersive virtual worlds. in proceedings of the    rst

international joint conference on autonomous agents and multiagent systems: part 2, pages 766   773. acm, 2002.

a. m. turing. computing machinery and intelligence. mind, pages 433   460, 1950.
d. c uthus and d. w aha. the ubuntu chat corpus for multiparticipant chat analysis.

in aaai spring symposium:

analyzing microtext, 2013.

j. vandeventer, a. j. aubrey, p. l. rosin, and d. marshall. 4d cardiff conversation database (4d ccdb): a 4d database
in proceedings of the 1st joint conference on facial analysis, animation and

of natural, dyadic conversations.
auditory-visual speech processing (faavsp 2015), 2015.

d. vandyke, p.-h. su, m. gasic, n. mrksic, t.-h. wen, and s. young. multi-domain dialogue success classi   ers for
policy training. in automatic id103 and understanding (asru), 2015 ieee workshop on, pages 763   
770. ieee, 2015.

o. vinyals and q. le. a neural conversational model. arxiv preprint arxiv:1506.05869, 2015.

44

m. a. walker, d. j. litman, c. a. kamm, and a. abella. paradise: a framework for evaluating spoken dialogue agents.
in proceedings of the eighth conference on european chapter of the association for computational linguistics, pages
271   280, 1997.

m. a. walker, o. c. rambow, and m. rogati. training a sentence planner for spoken dialogue using boosting. computer

speech & language, 16(3):409   433, 2002.

m. a. walker, r. grant, j. sawyer, g. i. lin, n. wardrip-fruin, and m. buell. perceived or not perceived: film character

models for expressive id86. in icids, pages 109   121, 2011.

m. a walker, g. i. lin, and j. sawyer. an annotated corpus of    lm dialogue for learning and characterizing character

style. in the international conference on language resources and evaluation (lrec), pages 1373   1378, 2012a.

m. a walker, j. e. f. tree, p. anand, r. abbott, and j. king. a corpus for research on deliberation and debate. in the

international conference on language resources and evaluation (lrec), pages 812   817, 2012b.

z. wang and o. lemon. a simple and generic belief tracking mechanism for the dialog state tracking challenge: on the

believability of observed information. in special interest group on discourse and dialogue (sigdial), 2013.

s. webb. a corpus driven study of the potential for vocabulary learning through watching movies. international journal

of corpus linguistics, 15(4):497   519, 2010.

j. weizenbaum. elizaa computer program for the study of natural language communication between man and machine.

communications of the acm, 9(1):36   45, 1966.

t. wen, m. ga  sic, d. kim, n. mrk  sic, p. su, d. vandyke, and s. young. stochastic language generation in dialogue using
recurrent neural networks with convolutional sentence reranking. special interest group on discourse and dialogue
(sigdial), 2015.

t.-h. wen, m. gasic, n. mrksic, l. m. rojas-barahona, p.-h. su, d. vandyke, and s. young. multi-domain neural
in conference of the north american chapter of the

network language generation for spoken dialogue systems.
association for computational linguistics (naacl-hlt 2016), 2016.

j. weston. dialog-based language learning. arxiv preprint arxiv:1604.06045, 2016.
j. weston, s. chopra, and a. bordes. memory networks.

in international conference on learning representations

(iclr), 2015.

j. williams, a. raux, d. ramachandran, and a. black. the dialog state tracking challenge. in special interest group on

discourse and dialogue (sigdial), 2013.

j. d. williams and s. young. partially observable id100 for spoken id71. computer

speech & language, 21(2):393   422, 2007.

j. d. williams and g. zweig. end-to-end lstm-based dialog control optimized with supervised and id23.

arxiv preprint arxiv:1606.01269, 2016.

m. wolska, q. b. vo, d. tsovaltzi, i. kruijff-korbayov  a, e. karagjosova, h. horacek, a. fiedler, and c. benzm  uller. an
annotated corpus of tutorial dialogs on mathematical theorem proving. in the international conference on language
resources and evaluation (lrec), 2004.

b. wrede and e. shriberg. relationship between dialogue acts and hot spots in meetings. in automatic speech recogni-

tion and understanding, 2003. asru   03. 2003 ieee workshop on, pages 180   185. ieee, 2003.

yi yang, wen-tau yih, and christopher meek. wikiqa: a challenge dataset for open-domain id53. in

emnlp, pages 2013   2018. citeseer, 2015.

z. yang, b. li, y. zhu, i. king, g. levow, and h. meng. collection of user judgments on spoken dialog system with

id104. in spoken language technology workshop (slt), 2010 ieee, pages 277   282, 2010.

s. young, m. gasic, b. thomson, and j. d. williams. pomdp-based statistical spoken id71: a review.

proceedings of the ieee, 101(5):1160   1179, 2013.

s. j. young. probabilistic methods in spoken   dialogue systems. philosophical transactions of the royal society of

london. series a: mathematical, physical and engineering sciences, 358(1769), 2000.

j. zhang, r. kumar, s. ravi, and c. danescu-niculescu-mizil. conversational    ow in oxford-style debates. in confer-

ence of the north american chapter of the association for computational linguistics (naacl-hlt 2016), 2016.

45

appendix a. learning from dialogue corpora

in this appendix section, we review some existing computational architectures suitable for learning
dialogue strategies directly from data. the goal is not to provide full technical details on the methods
available to achieve this     though we provide appropriate citations for the interested reader     but
rather to illustrate concretely how the datasets described above can, and have, been used in different
dialogue learning efforts. as such, we limit this review to a small set of existing work.

a.1 data pre-processing

before applying machine learning methods to a dialogue corpus, it is common practice to perform
some form of pre-processing. the aim of pre-processing is to standardize a dataset with minimal
loss of information. this can reduce data scarcity, and eventually make it easier for models to learn
from the dataset. in natural language processing, it is commonly acknowledged that pre-processing
can have a signi   cant effect on the results of the natural language processing system   the same
observation holds for dialogue. although the speci   c procedure for pre-processing is task- and
data-dependent, in this section we highlight a few common approaches, in order to give a general
idea of where pre-processing can be effective for dialogue systems.

pre-processing is often used to remove anomalies in the data. for text-based corpora, this can
include removing acronyms, slang, misspellings and phonemicization (e.g. where words are written
according to their pronunciation instead of their correct spelling). for some models, such as the
generative dialogue models discussed later, id121 (e.g. de   ning the smallest unit of input) is
also critical. in datasets collected from mobile text, forum, microblog and chat-based settings, it
is common to observe a signi   cant number of acronyms, abbreviations, and phonemicizations that
are speci   c to the topic and userbase (clark, 2003). although there is no widely accepted standard
for handling such occurrences, many nlp systems incorporate some form of pre-processing to
normalize these entries (kaufmann and kalita, 2010; aw et al., 2006; clark, 2003). for example,
there are look-up tables, such as the irc beginner list18, which can be used to translate the most
common acronyms and slang into standard english. another common strategy is to use id30
and lemmatization to replace many words with a single item (e.g. walking and walker both replaced
by walk). of course, depending on the task at hand and the corpus size, an option is also to leave
the acronyms and phonemicized words as they are.

in our experience, almost all dialogue datasets contain some amount of spelling errors. by
correcting these, we expect to reduce data sparsity. this can be done by using automatic spelling
correctors. however, it is important to inspect their effectiveness. for example, for movie scripts,
serban et al. (2016) found that automatic spelling correctors introduced more spelling errors than
they corrected, and a better strategy was to use wikipedia   s most commonly misspelled words19
to lookup and replace potential spelling errors. transcribed spoken language corpora often include
many non-words in their transcriptions (e.g. uh, oh). depending on whether or not these provide
additional information to the dialogue system, researchers may also want to remove these words by
using automatic spelling correctors.

18. http://www.ircbeginner.com/ircinfo/abbreviations.html
19. https://en.wikipedia.org/wiki/commonly_misspelled_english_words

46

a.2 segmenting speakers and conversations

some dialogue corpora, such as those based on movie subtitles, come without explicit speaker
segmentation. however, it is often possible to estimate the speaker segmentation, which is useful
to build a model of a given speaker   as compared to a model of the conversation as a whole. for
text-based corpora, serban and pineau (2015) have recently proposed the use of recurrent neural
networks to estimate turn-taking and speaker labels in movie scripts with promising results.

in the id103 literature, this is the subtask of speaker diarisation (miro et al., 2012;
tranter et al., 2006). when the audio stream of the speech is available, the segmentation is quite
accurate with classi   cation error rates as low as 5%.

a strategy sometimes used for segmentation of spoken dialogues is based on labelling a small
subset of the corpus, known as the gold corpus, and training a speci   c segmentation model based on
this. the remaining corpus is then segmented iteratively according to the segmentation model, after
which the gold corpus is expanded with the most con   dent segmentations and the segmentation
model is retrained. this process is sometimes known as embedded training, and is widely used in
other id103 tasks (jurafsky and martin, 2008). it appears to work well in practice, but
has the disadvantage that the interpretation of the label can drift. naturally, this approach can be
applied to text dialogues as well in a straightforward manner.

in certain corpora, such as those based on chat channels or extracted from movie subtitles, many
conversations occur in sequence. in some cases, there are no labels partitioning the beginning and
end of separate conversations. similarly, certain corpora with multiple speakers, such as corpora
based on chat channels, contain several conversations occurring in parallel (e.g. simultaneously)
but do not contain any segmentation separating these conversations. this makes it hard to learn a
meaningful model from such conversations, because they do not represent consistent speakers or
coherent semantic topics.

to leverage such data towards learning individual conversations, researchers have proposed
methods to automatically estimate segmentations of conversations (lowe et al., 2015a; nio et al.,
2014a). former solutions were mostly based on hand-crafted rules and seemed to work well upon
manual inspection. for chat forums, one solution involves thresholding the beginning and end of
conversations based on time (e.g. delay of more than x minutes between utterances), and eliminat-
ing speakers from the conversation unless they are referred to explicitly by other speakers (lowe
et al., 2015a). more advanced techniques involve maximum-id178 classi   ers, which leverage
the content of the utterances in addition to the discourse structure and timing information (elsner
and charniak, 2008). for movie scripts, researchers have proposed the use of simple information-
retrieval similarity measures, such as cosine similarity, to identify conversations (nio et al., 2014a).
based on the their performance on estimating turn-taking and speaker labels, recurrent neural net-
works also hold promise for segmenting conversations (serban and pineau, 2015).

a.3 discriminative model architectures

as discussed in subsection 2.3, discriminative models aim to predict certain labels or annotations
manually associated with a portion of a dialogue. for example, a discriminative model might be
trained to predict the intent of a person in a dialogue, or the topic, or a speci   c piece of information.

47

in the following subsections, we discuss research directions where discriminative models have
been developed to solve dialogue-related tasks.20 this is primarily meant to review and contrast the
work from a data-driven learning perspective.

a.3.1 dialogue act classification and dialogue topic spotting

here we consider the simple task known as dialogue act classi   cation (or dialogue move recogni-
tion). in this task, the goal is to classify a user utterance, independent of the rest of the conversation,
as one out of k dialogue acts: p (a | u ), where a is the discrete variable representing the dialogue
act and u is the user   s utterance. this falls under the general umbrella of text classi   cation tasks,
though its application is speci   c to dialogue. like the dialogue state tracker model, a dialogue
act classi   cation model could be plugged into a dialogue system as an additional natural language
understanding component.

early approaches for this task focused on using id165 models for classi   cation (reithinger
and klesen, 1997; bird et al., 1995). for example, reithinger et al. assumed that each dialogue act
is generated by its own language model. they trained an id165 language model on the utterances
of each dialogue act, p  (u|a), and afterwards use bayes    rule to assign the id203 of a new
dialogue act p  (a|u ) to be proportional to the id203 of generating the utterance under the
language model p  (u|a).

however, a major problem with this approach is the lack of datasets with annotated dialogue
acts. more recent work by forgues et al. (2014) acknowledged this problem, and tried to overcome
the data scarcity issue by leveraging id27s learned from other, larger text corpora. they
created an utterance-level representation by combining the id27s of each word, for
example, by summing the id27s or taking the maximum w.r.t. each dimension. these
utterance-level representations, together with word counts, were then given as inputs to a linear
classi   er to classify the dialogue acts. thus, forgues et al. showed that by leveraging another,
substantially larger, corpus they were able to improve performance on their original task.

this makes the work on dialogue act classi   cation very appealing from a data-driven perspec-
tive. first, it seems that the accuracy can be improved by leveraging alternative data sources. sec-
ond, unlike the dialogue state tracking models, dialogue act classi   cation models typically involve
relatively little feature hand-crafting thus suggesting that data-driven approaches may be more pow-
erful for these tasks.

a.3.2 dialogue state tracking

the core task of the dstc (williams et al., 2013) adds more complexity by focusing on tracking
the state of a conversation. this is framed as a classi   cation problem: for every time step t of
the dialogue, the model is given the current input to the dialogue state tracker (including asr
and slu outputs) together with external knowledge sources (e.g. bus timetables). the required
output is a id203 distribution over a set of nt prede   ned hypotheses, in addition to the rest
hypothesis (which represents the id203 that none of the previous nt hypotheses are correct).
the goal is to match the distribution over hypotheses as closely as possible to the real annotated

20. it is important to note that although discriminative models have been favored to model supervised problems in the
dialogue-system literature, in principle generative models (p (x, y )) instead of discriminative models (p (y |x))
could be used.

48

data. by providing an open dataset with accurate labels, it has been possible for researchers to
perform rigourous comparative evaluations of different classi   cation models for dialogue systems.
models for the dstc include both statistical approaches and hand-crafted systems. an example
of the latter is the system proposed in wang and lemon (2013), which relies on having access to a
marginal con   dence score pt(u, s, v) for a user dialogue u(s = v) with slot s and value v given by
a subsystem at time t. the marginal con   dence score gives a heuristic estimate of the id203 of
a slot taking a particular value. the model must then aggregate all these estimates and con   dence
scores to compute probabilities for each hypothesis.

in this model, the slu component may for example give the marginal con   dence score (in-
form(data.day=today)=0.9) in the bus scheduling dstc, meaning that it believes with high con   -
dence (0.9) that the user has requested information for the current day. this marginal con   dence
score is used to update the belief state of the system bt(s, v) at time t using a set of hand-crafted
updates to the id203 distribution over hypotheses. from a data-driven learning perspective,
this approach does not make ef   cient use of the dataset, but instead relies heavily on the accuracy
of the hand-crafted tracker outputs.

more sophisticated models for the dstc take a dynamic bayesian approach by modeling the
latent dialogue state and observed tracker outputs in a directed graphical model (thomson and
young, 2010). these models are sometimes called generative state tracking models, though they
are still discriminative in nature as they only attempt to model the state of the dialogue and not
the words and speech acts in each dialogue. for simplicity we drop the index i in the following
equations. similar to before, let xt be the observed tracker outputs at time t. let st be the dialogue
state at time t, which represents the state of the world including, for example, the user actions (e.g.
de   ned by slot-value pairs) and system actions (e.g. number of times a piece of information has
been requested). for the dstc, the state st must represent the true current slot-value pair at time
t. let rt be the reward observed at time t, and let at be the action taken by the dialogue system
at time t. this general framework, also known as a partially-observable markov decision process
(pomdp) then de   nes the graphical model:

p  (xt, st, rt|at, st   1) = p  (xt|st, at)p  (st|st   1, at)p  (rt|st, at),

(3)

where at is assumed to be a deterministic variable of the dialogue history. this variable is given in
the dstc, because it comes from the policy used to interact with the humans when gathering the
datasets. this approach is attractive from a data-driven learning perspective, because it models the
uncertainty (e.g. noise and ambiguity) inherent in all variables of interest. thus, we might expect
such a model to be more robust in real applications.

now, since all variables are observed in this task, and since the goal is to determine st given the

other variables, we are only interested in:

p  (st|xt, rt, at)     p  (xt|st, at)p  (st|st   1, at)p  (rt|st, at),

(4)

which can then be normalized appropriately since st is a discrete stochastic variable. however, due
to the temporal dependency between st and st   1, the complexity of the model is similar to a hidden
markov model, and thus both learning and id136 become intractable when the state, observation
and action spaces are too large. indeed, as noted by young et al. (2013), the number of states,
actions and observations can easily reach 1010 con   gurations in some dialogue systems. thus, it is
necessary to make simplifying assumptions on the distribution p  (st|xt, rt, at) and to approximate

49

the learning and id136 procedures (young et al., 2013). with appropriate structural assumptions
and approximations, these models perform well compared to baseline systems on the dstc (black
et al., 2011).

non-bayesian data-driven models have also been proposed. these models are sometimes called
discriminative state tracking models, because they do not assume a generation process for the tracker
outputs, xt or for any other variables, but instead only condition on them. for example, henderson
et al. (2013) proposed to use a feed-forward neural network. at each time step t, they extracted
a set of features and then concatenate a window of w feature vectors together. these are given
as input to the neural network, which outputs the id203 of each hypothesis from the set of
hypotheses. by learning a discriminative model and using a window over the last time steps, they
do not face the intractability issues of dynamic id110s. instead, their system can be
trained with id119 methods. this approach could eventually scale to large datasets,
and is therefore very attractive for data-driven learning. however, unlike the dynamic bayesian
approaches, these models do not represent id203 distributions over variables apart from the
state of the dialogue. without id203 distributions, it is not clear how to de   ne a con   dence
interval over the predictions. thus the models might not provide adequate information to determine
when to seek con   rmation or clari   cation following unclear statements.

researchers have also investigated the use of conditional random    elds (crfs) for state tracking
(ren et al., 2013). this class of models also falls under the umbrella of discriminative state tracking
models; however, they are able to take into account temporal dependencies within dialogues by
modeling a complete joint distribution over states:

fi(sc, xc),

(5)

p  (s|x)    (cid:89)

(cid:89)

c   c

i

p  (s|x)    (cid:89)

(cid:89)

where c is the set of factors, i.e. sets of state and tracker variables across time, sc is the set of states
associated with factor c, xc is the set of observations associated with factor c, and {fi}i is a set of
functions parametrized by parameters   . there exist certain functions fi, for which exact id136
is tractable and learning the parameters    is ef   cient (koller and friedman, 2009; serban, 2012).
for example, ren et al. (2013) propose a set of factors which create a linear dependency structure
between the dialogue states while conditioning on all the observed tracker outputs:

fi(st   1, st, st+1, x).

(6)

t

i

this creates a dependency between all dialogue states, forcing them be coherent with each other.
this should be contrasted to the feed-forward neural network approach, which does not enforce any
sort of consistency between different predicted dialogue states. the cfr models can be trained with
id119 to optimize the exact log-likelihood, but exact id136 is typically intractable.
therefore, an approximate id136 procedure, such as loopy belief propagation, is necessary to
approximate the posterior distribution over states st.

in summary, there exist different approaches to building discriminative learning architectures
for dialogue. while they are fairly straightforward to evaluate and often form a crucial component
for real-world dialogue systems, by themselves they only offer a limited view of what we ultimately
want to accomplish with dialogue models. they often require labeled data, which is often dif   cult
to acquire on a large scale (except in the case of answer re-ranking) and require manual feature
selection, which reduces their potential effectiveness. since each model is trained independently

50

of the other models and components with which it interacts in the complete dialogue system, one
cannot give guarantees on the performance of the    nal dialogue system by evaluating the individual
models alone. thus, we desire models that are capable of producing id203 distributions over
all possible responses instead of over all annotated labels   in other words, models that can actually
generate new responses by selecting the highest id203 next utterance. this is the subject of
the next section.

a.4 response generation models

both the response re-ranking approach and the generative response model approach have allowed
for the use of large-scale unannotated dialogue corpora for training dialogue systems. we therefore
close this section by discussing these classes of approaches

in general, approaches which aim to generate responses have the potential to learn semantically
more powerful representations of dialogues compared to models trained for dialogue state tracking
or dialogue act classi   cation tasks: the concepts they are able to represent are limited only by the
content of the dataset, unlike the dialogue state tracking or dialogue act classi   cation models which
are limited by the annotation scheme used (e.g. the set of possible slot-value pairs pre-speci   ed for
the dstc).

a.4.1 re-ranking response models

researchers have recently turned their attention to the problem of building models that produce
answers by re-ranking a set of candidate answers, and outputting the one with the highest rank
or id203. while the task may seem arti   cial, the main advantage is that it allows the use of
completely un-annotated datasets. unlike dialogue state tracking, this task does not require datasets
where experts have labeled every utterance and system response. this task only requires knowing
the sequence of utterances, which can be extracted automatically from transcribed conversations.

banchs and li (2012) construct an information retrieval system based on movie scripts using the
vector space model. their system searches through a database of movie scripts to    nd a dialogue
similar to the current dialogue with the user, and then emits the response from the closest dialogue
in the database. similarly, ameixa et al. (2014) also use an information retrieval system, but based
on movie subtitles instead of movie scripts. they show that their system gives sensible responses
to questions, and that id64 an existing dialogue system from movie subtitles improves an-
swering out-of-domain questions. both approaches assume that the responses given in the movie
scripts and movie subtitle corpora are appropriate. such information retrieval systems consist of a
relatively small set of manually tuned parameters. for this reason, they do not require (annotated)
labels and can therefore take advantage of raw data (in this case movie scripts and movie subtitles).
however, these systems are effectively nearest-neighbor methods. they do not learn rich represen-
tations from dialogues which can be used, for example, to generalize to previously unseen situations.
furthermore, it is unclear how to transform such models into full dialogue agents. they are not ro-
bust and it is not clear how to maintain the dialogue state. contrary to search engines, which present
an entire page of results, the dialogue system is only allowed to give a single response to the user.

(lowe et al., 2015a) also propose a re-ranking approach using the ubuntu dialogue corpus.
the authors propose an af   nity model between a context c (e.g.    ve consecutive utterances in a
conversation) and a potential reply r. given a context-reply pair the model compares the output
of a context-speci   c lstm against that of a response-speci   c lstm neural network and outputs

51

whether or not the response is correct for the given context. the model maximizes the likelihood of
a correct context-response pair:

p  (true response | ci, ri)ici (ri)(1     p  (true response | ci, ri))1   ici (ri)

(7)

(cid:88)

i

max

  

where    stands for the set of all model parameters and ici(  ) denotes a function that returns 1 when
ri is the correct response to ci and 0 otherwise. learning in the model uses stochastic gradient
descent. as is typical with neural network architectures, this learning procedure scales to large
datasets. given a context, the trained model can be used to pick an appropriate answer from a set of
potential answers. this model assumes that the responses given in the corpus are appropriate (i.e.,
this model does not generate novel responses). however, unlike the above information retrieval
systems, this model is not provided with a similarity metric as in the vector space model, but instead
must learn the semantic relevance of a response to a context. this approach is more attractive from
a data-driven learning perspective because it uses the dataset more ef   ciently and avoids costly hand
tuning of parameters.

a.4.2 full generative response models

generative dialogue response strategies are designed to automatically produce utterances by com-
posing text (see section 2.4). a straightforward way to de   ne the set of dialogue system actions is
by considering them as sequences of words which form utterances. sordoni et al. (2015b) and ser-
ban et al. (2016) both use this approach. they assume that both the user and the system utterances
can be represented by the same generative distribution:

t(cid:89)
t(cid:89)

t=1

n(cid:89)

p  (ut | u<t)

p  (u1, . . . , ut ) =

=

p  (wt,n | wt,<n, u<t),

(8)

(9)

t=1

n=1

where the dialogue consists of t utterances u1, . . . , ut and wt,n is the nth token in utterance t. the
variable u<t indicates the sequence of utterances which preceed ut and similarly for wt,<n. further,
the id203 of the    rst utterance is de   ned as p (u1|u<1) = p (u1), and the    rst word of each
utterance only conditions on the previous utterance, i.e. wt,<1 is    null   . tokens can be words, as
well as speech and dialogue acts. the set of tokens depends on the particular application domain,
but in general the set must be able to represent all desirable system actions. in particular, the set
must contain an end-of-utterance token to allow the model to express turn-taking. this approach
is similar to id38. for differentiable models, training is based on maximum log-
likelihood using stochastic id119 methods. as discussed in subsection 2.4, these models
project words and dialogue histories onto an euclidian space. furthermore, when trained on text
only, they can be thought of as unsupervised machine learning models.
sordoni et al. (2015b) use the above approach to generate responses for posts on twitter. specif-
ically, p  (um | u<m) is given by a recurrent neural network which generates a response word-by-
word based on eq. (9). the model learns its parameters using stochastic id119 on a corpus
of twitter messages. the authors then combine their generative model with a machine translation

52

system and demonstrate that the hybrid system outperforms a state-of-the-art machine translation
system (ritter et al., 2011).

serban et al. (2016) extend the above model to generate responses for movie subtitles and movie
scripts. speci   cally, serban et al. (2016) adapt a hierarchical recurrent neural network (sordoni
et al., 2015a), which they argue is able to represent the common ground between the dialogue
interlocutors. they also propose to add speech and dialogue acts to the vocabulary of the model to
make the interaction with the system more natural. however, since the model is used in a standalone
manner, i.e., without combining it with a machine translation system, the majority of the generated
responses are highly generic (e.g. i   m sorry or i don   t know). the authors conclude that this is a
limitation of all neural network-based generative models for dialogue (e.g., (serban et al., 2016;
sordoni et al., 2015b; vinyals and le, 2015)). the problem appears to lie in the distribution of
words in the dialogue utterances, which primarily consist of pronouns, punctuation tokens and a few
common verbs but rarely nouns, verbs and adjectives. when trained on a such a skewed distribution,
the models do not learn to represent the semantic content of dialogues very well. this issue is
exacerbated by the fact that dialogue is inherently ambiguous and multi-modal, which makes it
more likely for the model to fall back on a generic response. as a workaround, li et al. (2015)
increase response diversity by changing the objective function at generation time to also maximize
the mutual information between the context, i.e. the previous utterances, and the response utterance.
however, it is not clear what impact this arti   cial diversity has on the effectiveness or naturalness
of the dialogue system. it is possible that the issue may require larger corpora to learn semantic
representations of dialogue, more context (e.g. longer conversations, user pro   les and task-speci   c
corpora) and multi-modal interfaces to reduce uncertainty. further research is needed to resolve this
question.

wen et al. (2015) train a neural network to generate natural language responses for a closed-
dialogue domain. they use amazon mechanical turk21 to collect a dataset of dialogue acts and
utterance pairs. they then train recurrent neural networks to generate a single utterance as in eq.
(9), but condition on the speci   ed dialogue act:

p  (u|a) =

p  (wn | w<n, a),

(10)

n

where a is the dialogue act represented by a discrete variable, u is the generated utterance given a
and wn is the nth word in the utterance. based on a hybrid approach combining different recurrent
neural networks for answer generation and convolutional neural networks for re-ranking answers,
they are able to generate diverse utterances representing the dialogue acts in their datasets.

similar to the models which re-rank answers, generative models may be used as complete di-
alogue systems or as response generation components of other dialogue systems. however, unlike
the models which re-rank answers, the word-by-word generative models can generate entirely new
utterances never seen before in the training set. further, in certain models such as those cited above,
response generation scales irrespective of dataset size.

a.5 user simulation models
in the absence of large datasets, some researchers have turned to building user simulation models
(sometimes referred to as    user models   ) to train dialogue strategies. user simulation models aim

21. http://www.mturk.com

53

(cid:89)

to produce natural, varied and consistent interactions from a    xed corpus, as stated by pietquin
and hastie (2013, p. 2):    an ef   cient user simulation should not only reproduce the statistical
distribution of dialogue acts measured in the data but should also reproduce complete dialogue
structures.    as such, they model the id155 of the user utterances given previous
user and system utterances:

p  (uuser

t

|uuser
<t , usystem

<t

),

(11)

where    are the model parameters, uuser
utterance (or action) respectively at time t. similarly, uuser
and system utterances that precede uuser

and usystem

and usystem

t

t

t

t

, respectively.

are the user utterance (or action) and the system
indicate the sequence of user

<t and usystem

<t

there are two main differences between user simulation models and the generative response
models discussed in subsection a.4.2. first, user simulation models never model the distribution
over system utterances, but instead only model the conditional distribution over user utterances
given previous user and system utterances. second, user simulation models usually model dia-
logue acts as opposed to word tokens. since a single dialogue act may represent many different
utterances, the models generalize well across paraphrases. however, training such user simulation
models requires access to a dialogue corpus with annotated dialogue acts, and limits their applica-
tion to training dialogue systems which work on the same set of dialogue acts. for spoken dialogue
systems, user simulation models are usually combined with a model over id103 errors
based on the automatic id103 system but, for simplicity, we omit this aspect in our
analysis.

researchers initially experimented with id165-based user simulation models (eckert et al.,

1997; georgila et al., 2006), which are de   ned as:

p  (uuser

t

|usystem
t   1

, uuser

t   2, . . . , usystem

t   n   1) =   uuser

t

,usystem

t   1 ,uuser

t   2,...,usystem
t   n   1

,

where n is an even integer, and    is an n-dimensional tensor (table) which satis   es:

(cid:88)

uuser
t

  uuser

t

,usystem

t   1 ,uuser

t   2,...,usystem
t   n   1

= 1.

(12)

(13)

t

,usystem

t   1 ,uuser

t   2,...,usystem
t   n   1

these models are trained either to maximize the log-likelihood of the observations by setting
equal to (a constant times) the number of occurrences of each correspond-
  uuser
ing id165 , or on a related objective function which encourages smoothness and therefore reduces
data sparsity for larger n   s (goodman, 2001). even with smoothing, n has to be kept small and
these models are therefore unable to maintain the history and goals of the user over several utter-
ances (schatzmann et al., 2005). consequently, the goal of the user changes over time, which has a
detrimental effect on the performance of the dialogue system trained using the user simulator.

several solutions have been proposed to solve the problem of maintaining the history of the

dialogue. pietquin (2004) propose to condition the id165 model on the user   s goal:

p  (uuser

t

|usystem
t   1

, uuser

t   2, . . . , usystem

t   n   1, g),

(14)

where g is the goal of the user de   ned as a set of slot-value pairs. unfortunately, not only must
the goal lie within a set of hand-crafted slot-value pairs, but its distribution when simulating must

54

also be de   ned by experts. using a more data-driven approach, georgila et al. (2006) propose to
condition the id165 model on additional features:

p  (uuser

t

|usystem
t   1

, uuser

t   2, . . . , usystem

t   n   1, f (uuser

<t , usystem

<t

)),

(15)

<t

<t , usystem

where f (uuser
) is a function mapping all previous user and system utterances to a low-
dimensional vector that summarizes the previous interactions between the user and the system (e.g.
slot-value pairs that the user has provided the system up to time t). now,    can be learned using
maximum log-likelihood with stochastic id119.

more sophisticated probabilistic models have been proposed based on directed graphical mod-
els, such as id48 and input-output id48 (cuay  ahuitl et al.,
2005), and undirected id114, such as conditional random    elds based on linear chains
(jung et al., 2009). inspired by pietquin (2005), pietquin (2007) and rossignol et al. (2011) propose
the following directed graphical model:

p  (uuser

t

|uuser
<t , usystem

<t

) =

p  (uuser

t

|gt, kt, uuser

<t , usystem

<t

)p  (gt|kt)p  (kt|k<t, uuser

<t , usystem

<t

)

(16)

(cid:88)

gt,kt

where gt is a discrete random variable representing the user   s goal at time t (e.g. a set of slot-value
pairs), and kt is another discrete random variable representing the user   s knowledge at time t (e.g. a
set of slot-value pairs). this model allows the user to change goals during the dialogue, which would
be the case, for example, if the user is noti   ed by the dialogue system that the original goal cannot
be accomplished. the dependency on previous user and system utterances for uuser
and kt may be
limited to a small number of previous turns as well as a set of hand-crafted features computed on
these utterances. for example, the id155:

t

p  (uuser

t

|gt, kt, uuser

<t , usystem

<t

),

(17)

t

may be approximated by an id165 model with additional features as in georgila et al. (2006).
generating user utterances can be done in a straightforward manner by using ancestral sampling:
   rst, sample kt given k<t and the previous user and system utterances; then, sample gt given kt;
and    nally, sample uuser
given gt, kt and the previous user and system utterances. the model can
be trained using maximum log-likelihood. if all variables are observed, i.e. gt and kt have been
given by human annotators, then the maximum-likelihood parameters can be found similarly to n-
gram models by counting the co-occurrences of variables. if some variables are missing, they can
be estimated using the id83, since the dependencies form a
linear chain. rossignol et al. (2011) also propose to regularize the model by assuming a dirichlet
distribution prior over the parameters, which is straightforward to combine with the em algorithm.
user simulation models are particularly useful in the development of dialogue systems based on
id23 methods (singh et al., 2002; schatzmann et al., 2006; pietquin and dutoit,
2006; frampton and lemon, 2009; jur  c      cek et al., 2012; png and pineau, 2011; young et al., 2013).
furthermore, many user simulation models, such as those trainable with stochastic id119
or co-occurrence statistics, are able to scale to large corpora. in the light of the increasing availability
of large dialogue corpora, there are ample opportunities for building novel user simulation models,
which aim to better represent real user behavior, and in turn for training dialogue systems, which aim
to solve more general and more dif   cult tasks. despite their similarities, research on user simulation

55

models and full generative models has progressed independently of each other so far. therefore, it
also seems likely that there is fruitful work to be done in transferring and merging ideas between
these two areas.

56

