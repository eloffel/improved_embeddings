   iframe: [1]//www.googletagmanager.com/ns.html?id=gtm-tp26bh

   iframe: [2]//www.googletagmanager.com/ns.html?id=gtm-mqqmgf

   advertisement

     * [3]plos.org
     * [4]create account
     * [5]sign in

[6]plos medicine

     * browse
          + [7]current issue
          + [8]journal archive
          + [9]special issues
          + [10]collections
          + [11]find and read articles
     * publish
          + submissions
               o [12]getting started
               o [13]presubmission inquiries
               o [14]submission guidelines
               o [15]figures
               o [16]tables
               o [17]supporting information
               o [18]latex
               o [19]other article types
               o [20]revising your manuscript
               o [21]submit now
          + policies
               o [22]best practices in research reporting
               o [23]human subjects research
               o [24]animal research
               o [25]competing interests
               o [26]disclosure of funding sources
               o [27]licenses and copyright
               o [28]data availability
               o [29]materials and software sharing
               o [30]ethical publishing practice
               o [31]authorship
               o [32]downloads and translations
          + manuscript review and publication
               o [33]editorial and peer review process
               o [34]guidelines for reviewers
               o [35]accepted manuscripts
               o [36]corrections and retractions
               o [37]comments
               o [38]article-level metrics

submit your manuscript
       plos medicine publishes research and commentary of general interest
       with clear implications for patient care, public policy or clinical
       research agendas.
       [39]get started
     * about
          + [40]why publish with plos medicine?
          + [41]journal information
          + [42]staff editors
          + [43]editorial board
          + [44]publishing information
          + [45]publication fees
          + [46]press and media
          + [47]resources
          + [48]contact
     *

       search

       search
       ____________________ (button)

       [49]advanced search

     * loading metrics

   open access

   essay

   [50]essay essays are opinion pieces on a topic of broad interest to a
   general medical audience.

   [51]see all article types   

why most published research findings are false

     * john p. a. ioannidis

why most published research findings are false

     * john p. a. ioannidis

   plos
   x
     * published: august 30, 2005
     * [52]https://doi.org/10.1371/journal.pmed.0020124

     * [53]article
     * [54]authors
     * [55]metrics
     * [56]comments
     * [57]media coverage

     * [58]reader comments (37)
     * [59]media coverage
     * [60]figures

figures

   table 1
   figure 1
   table 2
   figure 2
   table 3
   table 4

abstract

summary

   there is increasing concern that most current published research
   findings are false. the id203 that a research claim is true may
   depend on study power and bias, the number of other studies on the same
   question, and, importantly, the ratio of true to no relationships among
   the relationships probed in each scientific field. in this framework, a
   research finding is less likely to be true when the studies conducted
   in a field are smaller; when effect sizes are smaller; when there is a
   greater number and lesser preselection of tested relationships; where
   there is greater flexibility in designs, definitions, outcomes, and
   analytical modes; when there is greater financial and other interest
   and prejudice; and when more teams are involved in a scientific field
   in chase of statistical significance. simulations show that for most
   study designs and settings, it is more likely for a research claim to
   be false than true. moreover, for many current scientific fields,
   claimed research findings may often be simply accurate measures of the
   prevailing bias. in this essay, i discuss the implications of these
   problems for the conduct and interpretation of research.

   citation: ioannidis jpa (2005) why most published research findings are
   false. plos med 2(8): e124.
   https://doi.org/10.1371/journal.pmed.0020124

   published: august 30, 2005

   copyright:    2005 john p. a. ioannidis. this is an open-access article
   distributed under the terms of the creative commons attribution
   license, which permits unrestricted use, distribution, and reproduction
   in any medium, provided the original work is properly cited.

   competing interests: the author has declared that no competing
   interests exist.

   abbreviation: ppv, positive predictive value

   published research findings are sometimes refuted by subsequent
   evidence, with ensuing confusion and disappointment. refutation and
   controversy is seen across the range of research designs, from clinical
   trials and traditional epidemiological studies [[61]1   3] to the most
   modern molecular research [[62]4,[63]5]. there is increasing concern
   that in modern research, false findings may be the majority or even the
   vast majority of published research claims [[64]6   8]. however, this
   should not be surprising. it can be proven that most claimed research
   findings are false. here i will examine the key factors that influence
   this problem and some corollaries thereof.

modeling the framework for false positive findings

   several methodologists have pointed out [[65]9   11] that the high rate
   of nonreplication (lack of confirmation) of research discoveries is a
   consequence of the convenient, yet ill-founded strategy of claiming
   conclusive research findings solely on the basis of a single study
   assessed by formal statistical significance, typically for a p-value
   less than 0.05. research is not most appropriately represented and
   summarized by p-values, but, unfortunately, there is a widespread
   notion that medical research articles should be interpreted based only
   on p-values. research findings are defined here as any relationship
   reaching formal statistical significance, e.g., effective
   interventions, informative predictors, risk factors, or associations.
      negative    research is also very useful.    negative    is actually a
   misnomer, and the misinterpretation is widespread. however, here we
   will target relationships that investigators claim exist, rather than
   null findings.

     it can be proven that most claimed research findings are false

   as has been shown previously, the id203 that a research finding
   is indeed true depends on the prior id203 of it being true
   (before doing the study), the statistical power of the study, and the
   level of statistical significance [[66]10,[67]11]. consider a 2    2
   table in which research findings are compared against the gold standard
   of true relationships in a scientific field. in a research field both
   true and false hypotheses can be made about the presence of
   relationships. let r be the ratio of the number of    true relationships   
   to    no relationships    among those tested in the field. r is
   characteristic of the field and can vary a lot depending on whether the
   field targets highly likely relationships or searches for only one or a
   few true relationships among thousands and millions of hypotheses that
   may be postulated. let us also consider, for computational simplicity,
   circumscribed fields where either there is only one true relationship
   (among many that can be hypothesized) or the power is similar to find
   any of the several existing true relationships. the pre-study
   id203 of a relationship being true is r/(r + 1). the id203
   of a study finding a true relationship reflects the power 1 -    (one
   minus the type ii error rate). the id203 of claiming a
   relationship when none truly exists reflects the type i error rate,   .
   assuming that c relationships are being probed in the field, the
   expected values of the 2    2 table are given in [68]table 1. after a
   research finding has been claimed based on achieving formal statistical
   significance, the post-study id203 that it is true is the
   positive predictive value, ppv. the ppv is also the complementary
   id203 of what wacholder et al. have called the false positive
   report id203 [[69]10]. according to the 2    2 table, one gets ppv
   = (1 -   )r/(r -   r +   ). a research finding is thus more likely true
   than false if (1 -   )r >   . since usually the vast majority of
   investigators depend on a = 0.05, this means that a research finding is
   more likely true than false if (1 -   )r > 0.05.
   [70]thumbnail
   download:
     * [71]ppt
       [72]powerpoint slide
     * [73]png
       [74]larger image
     * [75]tiff
       [76]original image

   table 1. research findings and true relationships

   [77]https://doi.org/10.1371/journal.pmed.0020124.t001

   what is less well appreciated is that bias and the extent of repeated
   independent testing by different teams of investigators around the
   globe may further distort this picture and may lead to even smaller
   probabilities of the research findings being indeed true. we will try
   to model these two factors in the context of similar 2    2 tables.

bias

   first, let us define bias as the combination of various design, data,
   analysis, and presentation factors that tend to produce research
   findings when they should not be produced. let u be the proportion of
   probed analyses that would not have been    research findings,    but
   nevertheless end up presented and reported as such, because of bias.
   bias should not be confused with chance variability that causes some
   findings to be false by chance even though the study design, data,
   analysis, and presentation are perfect. bias can entail manipulation in
   the analysis or reporting of findings. selective or distorted reporting
   is a typical form of such bias. we may assume that u does not depend on
   whether a true relationship exists or not. this is not an unreasonable
   assumption, since typically it is impossible to know which
   relationships are indeed true. in the presence of bias ([78]table 2),
   one gets ppv = ([1 -   ]r + u  r)/(r +          r + u     u   + u  r), and ppv
   decreases with increasing u, unless 1              , i.e., 1            0.05 for
   most situations. thus, with increasing bias, the chances that a
   research finding is true diminish considerably. this is shown for
   different levels of power and for different pre-study odds in
   [79]figure 1. conversely, true research findings may occasionally be
   annulled because of reverse bias. for example, with large measurement
   errors relationships are lost in noise [[80]12], or investigators use
   data inefficiently or fail to notice statistically significant
   relationships, or there may be conflicts of interest that tend to
      bury    significant findings [[81]13]. there is no good large-scale
   empirical evidence on how frequently such reverse bias may occur across
   diverse research fields. however, it is probably fair to say that
   reverse bias is not as common. moreover measurement errors and
   inefficient use of data are probably becoming less frequent problems,
   since measurement error has decreased with technological advances in
   the molecular era and investigators are becoming increasingly
   sophisticated about their data. regardless, reverse bias may be modeled
   in the same way as bias above. also reverse bias should not be confused
   with chance variability that may lead to missing a true relationship
   because of chance.
   [82]thumbnail
   download:
     * [83]ppt
       [84]powerpoint slide
     * [85]png
       [86]larger image
     * [87]tiff
       [88]original image

   figure 1. ppv (id203 that a research finding is true) as a
   function of the pre-study odds for various levels of bias, u

   panels correspond to power of 0.20, 0.50, and 0.80.

   [89]https://doi.org/10.1371/journal.pmed.0020124.g001
   [90]thumbnail
   download:
     * [91]ppt
       [92]powerpoint slide
     * [93]png
       [94]larger image
     * [95]tiff
       [96]original image

   table 2. research findings and true relationships in the presence of
   bias

   [97]https://doi.org/10.1371/journal.pmed.0020124.t002

testing by several independent teams

   several independent teams may be addressing the same sets of research
   questions. as research efforts are globalized, it is practically the
   rule that several research teams, often dozens of them, may probe the
   same or similar questions. unfortunately, in some areas, the prevailing
   mentality until now has been to focus on isolated discoveries by single
   teams and interpret research experiments in isolation. an increasing
   number of questions have at least one study claiming a research
   finding, and this receives unilateral attention. the id203 that
   at least one study, among several done on the same question, claims a
   statistically significant research finding is easy to estimate. for n
   independent studies of equal power, the 2    2 table is shown in
   [98]table 3: ppv = r(1       ^n)/(r + 1     [1       ]^n     r  ^n) (not
   considering bias). with increasing number of independent studies, ppv
   tends to decrease, unless 1 -    < a, i.e., typically 1        < 0.05. this
   is shown for different levels of power and for different pre-study odds
   in [99]figure 2. for n studies of different power, the term   ^n is
   replaced by the product of the terms   [i] for i = 1 to n, but
   id136s are similar.
   [100]thumbnail
   download:
     * [101]ppt
       [102]powerpoint slide
     * [103]png
       [104]larger image
     * [105]tiff
       [106]original image

   figure 2. ppv (id203 that a research finding is true) as a
   function of the pre-study odds for various numbers of conducted
   studies, n

   panels correspond to power of 0.20, 0.50, and 0.80.

   [107]https://doi.org/10.1371/journal.pmed.0020124.g002
   [108]thumbnail
   download:
     * [109]ppt
       [110]powerpoint slide
     * [111]png
       [112]larger image
     * [113]tiff
       [114]original image

   table 3. research findings and true relationships in the presence of
   multiple studies

   [115]https://doi.org/10.1371/journal.pmed.0020124.t003

corollaries

   a practical example is shown in [116]box 1. based on the above
   considerations, one may deduce several interesting corollaries about
   the id203 that a research finding is indeed true.

box 1. an example: science at low pre-study odds

   let us assume that a team of investigators performs a whole genome
   association study to test whether any of 100,000 gene polymorphisms are
   associated with susceptibility to schizophrenia. based on what we know
   about the extent of heritability of the disease, it is reasonable to
   expect that probably around ten gene polymorphisms among those tested
   would be truly associated with schizophrenia, with relatively similar
   odds ratios around 1.3 for the ten or so polymorphisms and with a
   fairly similar power to identify any of them. then r = 10/100,000 =
   10^   4, and the pre-study id203 for any polymorphism to be
   associated with schizophrenia is also r/(r + 1) = 10^   4. let us also
   suppose that the study has 60% power to find an association with an
   odds ratio of 1.3 at    = 0.05. then it can be estimated that if a
   statistically significant association is found with the p-value barely
   crossing the 0.05 threshold, the post-study id203 that this is
   true increases about 12-fold compared with the pre-study id203,
   but it is still only 12    10^   4.

   now let us suppose that the investigators manipulate their design,
   analyses, and reporting so as to make more relationships cross the p =
   0.05 threshold even though this would not have been crossed with a
   perfectly adhered to design and analysis and with perfect comprehensive
   reporting of the results, strictly according to the original study
   plan. such manipulation could be done, for example, with serendipitous
   inclusion or exclusion of certain patients or controls, post hoc
   subgroup analyses, investigation of genetic contrasts that were not
   originally specified, changes in the disease or control definitions,
   and various combinations of selective or distorted reporting of the
   results. commercially available    data mining    packages actually are
   proud of their ability to yield statistically significant results
   through data dredging. in the presence of bias with u = 0.10, the
   post-study id203 that a research finding is true is only 4.4   
   10^   4. furthermore, even in the absence of any bias, when ten
   independent research teams perform similar experiments around the
   world, if one of them finds a formally statistically significant
   association, the id203 that the research finding is true is only
   1.5    10^   4, hardly any higher than the id203 we had before any
   of this extensive research was undertaken!

   corollary 1: the smaller the studies conducted in a scientific field,
   the less likely the research findings are to be true. small sample size
   means smaller power and, for all functions above, the ppv for a true
   research finding decreases as power decreases towards 1        = 0.05.
   thus, other factors being equal, research findings are more likely true
   in scientific fields that undertake large studies, such as randomized
   controlled trials in cardiology (several thousand subjects randomized)
   [[117]14] than in scientific fields with small studies, such as most
   research of molecular predictors (sample sizes 100-fold smaller)
   [[118]15].

   corollary 2: the smaller the effect sizes in a scientific field, the
   less likely the research findings are to be true. power is also related
   to the effect size. thus research findings are more likely true in
   scientific fields with large effects, such as the impact of smoking on
   cancer or cardiovascular disease (relative risks 3   20), than in
   scientific fields where postulated effects are small, such as genetic
   risk factors for multigenetic diseases (relative risks 1.1   1.5)
   [[119]7]. modern epidemiology is increasingly obliged to target smaller
   effect sizes [[120]16]. consequently, the proportion of true research
   findings is expected to decrease. in the same line of thinking, if the
   true effect sizes are very small in a scientific field, this field is
   likely to be plagued by almost ubiquitous false positive claims. for
   example, if the majority of true genetic or nutritional determinants of
   complex diseases confer relative risks less than 1.05, genetic or
   nutritional epidemiology would be largely utopian endeavors.

   corollary 3: the greater the number and the lesser the selection of
   tested relationships in a scientific field, the less likely the
   research findings are to be true. as shown above, the post-study
   id203 that a finding is true (ppv) depends a lot on the pre-study
   odds (r). thus, research findings are more likely true in confirmatory
   designs, such as large phase iii randomized controlled trials, or
   meta-analyses thereof, than in hypothesis-generating experiments.
   fields considered highly informative and creative given the wealth of
   the assembled and tested information, such as microarrays and other
   high-throughput discovery-oriented research [[121]4,[122]8,[123]17],
   should have extremely low ppv.

   corollary 4: the greater the flexibility in designs, definitions,
   outcomes, and analytical modes in a scientific field, the less likely
   the research findings are to be true. flexibility increases the
   potential for transforming what would be    negative    results into
      positive    results, i.e., bias, u. for several research designs, e.g.,
   randomized controlled trials [[124]18   20] or meta-analyses
   [[125]21,[126]22], there have been efforts to standardize their conduct
   and reporting. adherence to common standards is likely to increase the
   proportion of true findings. the same applies to outcomes. true
   findings may be more common when outcomes are unequivocal and
   universally agreed (e.g., death) rather than when multifarious outcomes
   are devised (e.g., scales for schizophrenia outcomes) [[127]23].
   similarly, fields that use commonly agreed, stereotyped analytical
   methods (e.g., kaplan-meier plots and the log-rank test) [[128]24] may
   yield a larger proportion of true findings than fields where analytical
   methods are still under experimentation (e.g., artificial intelligence
   methods) and only    best    results are reported. regardless, even in the
   most stringent research designs, bias seems to be a major problem. for
   example, there is strong evidence that selective outcome reporting,
   with manipulation of the outcomes and analyses reported, is a common
   problem even for randomized trails [[129]25]. simply abolishing
   selective publication would not make this problem go away.

   corollary 5: the greater the financial and other interests and
   prejudices in a scientific field, the less likely the research findings
   are to be true. conflicts of interest and prejudice may increase bias,
   u. conflicts of interest are very common in biomedical research
   [[130]26], and typically they are inadequately and sparsely reported
   [[131]26,[132]27]. prejudice may not necessarily have financial roots.
   scientists in a given field may be prejudiced purely because of their
   belief in a scientific theory or commitment to their own findings. many
   otherwise seemingly independent, university-based studies may be
   conducted for no other reason than to give physicians and researchers
   qualifications for promotion or tenure. such nonfinancial conflicts may
   also lead to distorted reported results and interpretations.
   prestigious investigators may suppress via the peer review process the
   appearance and dissemination of findings that refute their findings,
   thus condemning their field to perpetuate false dogma. empirical
   evidence on expert opinion shows that it is extremely unreliable
   [[133]28].

   corollary 6: the hotter a scientific field (with more scientific teams
   involved), the less likely the research findings are to be true. this
   seemingly paradoxical corollary follows because, as stated above, the
   ppv of isolated findings decreases when many teams of investigators are
   involved in the same field. this may explain why we occasionally see
   major excitement followed rapidly by severe disappointments in fields
   that draw wide attention. with many teams working on the same field and
   with massive experimental data being produced, timing is of the essence
   in beating competition. thus, each team may prioritize on pursuing and
   disseminating its most impressive    positive    results.    negative   
   results may become attractive for dissemination only if some other team
   has found a    positive    association on the same question. in that case,
   it may be attractive to refute a claim made in some prestigious
   journal. the term proteus phenomenon has been coined to describe this
   phenomenon of rapidly alternating extreme research claims and extremely
   opposite refutations [[134]29]. empirical evidence suggests that this
   sequence of extreme opposites is very common in molecular genetics
   [[135]29].

   these corollaries consider each factor separately, but these factors
   often influence each other. for example, investigators working in
   fields where true effect sizes are perceived to be small may be more
   likely to perform large studies than investigators working in fields
   where true effect sizes are perceived to be large. or prejudice may
   prevail in a hot scientific field, further undermining the predictive
   value of its research findings. highly prejudiced stakeholders may even
   create a barrier that aborts efforts at obtaining and disseminating
   opposing results. conversely, the fact that a field is hot or has
   strong invested interests may sometimes promote larger studies and
   improved standards of research, enhancing the predictive value of its
   research findings. or massive discovery-oriented testing may result in
   such a large yield of significant relationships that investigators have
   enough to report and search further and thus refrain from data dredging
   and manipulation.

most research findings are false for most research designs and for most
fields

   in the described framework, a ppv exceeding 50% is quite difficult to
   get. [136]table 4 provides the results of simulations using the
   formulas developed for the influence of power, ratio of true to
   non-true relationships, and bias, for various types of situations that
   may be characteristic of specific study designs and settings. a finding
   from a well-conducted, adequately powered randomized controlled trial
   starting with a 50% pre-study chance that the intervention is effective
   is eventually true about 85% of the time. a fairly similar performance
   is expected of a confirmatory meta-analysis of good-quality randomized
   trials: potential bias probably increases, but power and pre-test
   chances are higher compared to a single randomized trial. conversely, a
   meta-analytic finding from inconclusive studies where pooling is used
   to    correct    the low power of single studies, is probably false if r    
   1:3. research findings from underpowered, early-phase clinical trials
   would be true about one in four times, or even less frequently if bias
   is present. epidemiological studies of an exploratory nature perform
   even worse, especially when underpowered, but even well-powered
   epidemiological studies may have only a one in five chance being true,
   if r = 1:10. finally, in discovery-oriented research with massive
   testing, where tested relationships exceed true ones 1,000-fold (e.g.,
   30,000 genes tested, of which 30 may be the true culprits)
   [[137]30,[138]31], ppv for each claimed relationship is extremely low,
   even with considerable standardization of laboratory and statistical
   methods, outcomes, and reporting thereof to minimize bias.
   [139]thumbnail
   download:
     * [140]ppt
       [141]powerpoint slide
     * [142]png
       [143]larger image
     * [144]tiff
       [145]original image

   table 4. ppv of research findings for various combinations of power (1
   -   ), ratio of true to not-true relationships (r), and bias (u)

   [146]https://doi.org/10.1371/journal.pmed.0020124.t004

claimed research findings may often be simply accurate measures of the
prevailing bias

   as shown, the majority of modern biomedical research is operating in
   areas with very low pre- and post-study id203 for true findings.
   let us suppose that in a research field there are no true findings at
   all to be discovered. history of science teaches us that scientific
   endeavor has often in the past wasted effort in fields with absolutely
   no yield of true scientific information, at least based on our current
   understanding. in such a    null field,    one would ideally expect all
   observed effect sizes to vary by chance around the null in the absence
   of bias. the extent that observed findings deviate from what is
   expected by chance alone would be simply a pure measure of the
   prevailing bias.

   for example, let us suppose that no nutrients or dietary patterns are
   actually important determinants for the risk of developing a specific
   tumor. let us also suppose that the scientific literature has examined
   60 nutrients and claims all of them to be related to the risk of
   developing this tumor with relative risks in the range of 1.2 to 1.4
   for the comparison of the upper to lower intake tertiles. then the
   claimed effect sizes are simply measuring nothing else but the net bias
   that has been involved in the generation of this scientific literature.
   claimed effect sizes are in fact the most accurate estimates of the net
   bias. it even follows that between    null fields,    the fields that claim
   stronger effects (often with accompanying claims of medical or public
   health importance) are simply those that have sustained the worst
   biases.

   for fields with very low ppv, the few true relationships would not
   distort this overall picture much. even if a few relationships are
   true, the shape of the distribution of the observed effects would still
   yield a clear measure of the biases involved in the field. this concept
   totally reverses the way we view scientific results. traditionally,
   investigators have viewed large and highly significant effects with
   excitement, as signs of important discoveries. too large and too highly
   significant effects may actually be more likely to be signs of large
   bias in most fields of modern research. they should lead investigators
   to careful critical thinking about what might have gone wrong with
   their data, analyses, and results.

   of course, investigators working in any field are likely to resist
   accepting that the whole field in which they have spent their careers
   is a    null field.    however, other lines of evidence, or advances in
   technology and experimentation, may lead eventually to the dismantling
   of a scientific field. obtaining measures of the net bias in one field
   may also be useful for obtaining insight into what might be the range
   of bias operating in other fields where similar analytical methods,
   technologies, and conflicts may be operating.

how can we improve the situation?

   is it unavoidable that most research findings are false, or can we
   improve the situation? a major problem is that it is impossible to know
   with 100% certainty what the truth is in any research question. in this
   regard, the pure    gold    standard is unattainable. however, there are
   several approaches to improve the post-study id203.

   better powered evidence, e.g., large studies or low-bias meta-analyses,
   may help, as it comes closer to the unknown    gold    standard. however,
   large studies may still have biases and these should be acknowledged
   and avoided. moreover, large-scale evidence is impossible to obtain for
   all of the millions and trillions of research questions posed in
   current research. large-scale evidence should be targeted for research
   questions where the pre-study id203 is already considerably high,
   so that a significant research finding will lead to a post-test
   id203 that would be considered quite definitive. large-scale
   evidence is also particularly indicated when it can test major concepts
   rather than narrow, specific questions. a negative finding can then
   refute not only a specific proposed claim, but a whole field or
   considerable portion thereof. selecting the performance of large-scale
   studies based on narrow-minded criteria, such as the marketing
   promotion of a specific drug, is largely wasted research. moreover, one
   should be cautious that extremely large studies may be more likely to
   find a formally statistical significant difference for a trivial effect
   that is not really meaningfully different from the null [[147]32   34].

   second, most research questions are addressed by many teams, and it is
   misleading to emphasize the statistically significant findings of any
   single team. what matters is the totality of the evidence. diminishing
   bias through enhanced research standards and curtailing of prejudices
   may also help. however, this may require a change in scientific
   mentality that might be difficult to achieve. in some research designs,
   efforts may also be more successful with upfront registration of
   studies, e.g., randomized trials [[148]35]. registration would pose a
   challenge for hypothesis-generating research. some kind of registration
   or networking of data collections or investigators within fields may be
   more feasible than registration of each and every hypothesis-generating
   experiment. regardless, even if we do not see a great deal of progress
   with registration of studies in other fields, the principles of
   developing and adhering to a protocol could be more widely borrowed
   from randomized controlled trials.

   finally, instead of chasing statistical significance, we should improve
   our understanding of the range of r values   the pre-study odds   where
   research efforts operate [[149]10]. before running an experiment,
   investigators should consider what they believe the chances are that
   they are testing a true rather than a non-true relationship. speculated
   high r values may sometimes then be ascertained. as described above,
   whenever ethically acceptable, large studies with minimal bias should
   be performed on research findings that are considered relatively
   established, to see how often they are indeed confirmed. i suspect
   several established    classics    will fail the test [[150]36].

   nevertheless, most new discoveries will continue to stem from
   hypothesis-generating research with low or very low pre-study odds. we
   should then acknowledge that statistical significance testing in the
   report of a single study gives only a partial picture, without knowing
   how much testing has been done outside the report and in the relevant
   field at large. despite a large statistical literature for multiple
   testing corrections [[151]37], usually it is impossible to decipher how
   much data dredging by the reporting authors or other research teams has
   preceded a reported research finding. even if determining this were
   feasible, this would not inform us about the pre-study odds. thus, it
   is unavoidable that one should make approximate assumptions on how many
   relationships are expected to be true among those probed across the
   relevant research fields and research designs. the wider field may
   yield some guidance for estimating this id203 for the isolated
   research project. experiences from biases detected in other neighboring
   fields would also be useful to draw upon. even though these assumptions
   would be considerably subjective, they would still be very useful in
   interpreting research claims and putting them in context.

references

    1. 1. ioannidis jp, haidich ab, lau j (2001) any casualties in the
       clash of randomised and observational evidence? bmj 322: 879   880.
          + [152]view article
          + [153]google scholar
    2. 2. lawlor da, davey smith g, kundu d, bruckdorfer kr, ebrahim s
       (2004) those confounded vitamins: what can we learn from the
       differences between observational versus randomised trial evidence?
       lancet 363: 1724   1727.
          + [154]view article
          + [155]google scholar
    3. 3. vandenbroucke jp (2004) when are observational studies as
       credible as randomised trials? lancet 363: 1728   1731.
          + [156]view article
          + [157]google scholar
    4. 4. michiels s, koscielny s, hill c (2005) prediction of cancer
       outcome with microarrays: a multiple random validation strategy.
       lancet 365: 488   492.
          + [158]view article
          + [159]google scholar
    5. 5. ioannidis jpa, ntzani ee, trikalinos ta, contopoulos-ioannidis
       dg (2001) replication validity of genetic association studies. nat
       genet 29: 306   309.
          + [160]view article
          + [161]google scholar
    6. 6. colhoun hm, mckeigue pm, davey smith g (2003) problems of
       reporting genetic associations with complex outcomes. lancet 361:
       865   872.
          + [162]view article
          + [163]google scholar
    7. 7. ioannidis jp (2003) genetic associations: false or true? trends
       mol med 9: 135   138.
          + [164]view article
          + [165]google scholar
    8. 8. ioannidis jpa (2005) microarrays and molecular research: noise
       discovery? lancet 365: 454   455.
          + [166]view article
          + [167]google scholar
    9. 9. sterne ja, davey smith g (2001) sifting the evidence   what's
       wrong with significance tests. bmj 322: 226   231.
          + [168]view article
          + [169]google scholar
   10. 10. wacholder s, chanock s, garcia-closas m, elghormli l, rothman n
       (2004) assessing the id203 that a positive report is false:
       an approach for molecular epidemiology studies. j natl cancer inst
       96: 434   442.
          + [170]view article
          + [171]google scholar
   11. 11. risch nj (2000) searching for genetic determinants in the new
       millennium. nature 405: 847   856.
          + [172]view article
          + [173]google scholar
   12. 12. kelsey jl, whittemore as, evans as, thompson wd (1996) methods
       in observational epidemiology, 2nd ed. new york: oxford u press.
       432 p.
   13. 13. topol ej (2004) failing the public health   rofecoxib, merck, and
       the fda. n engl j med 351: 1707   1709.
          + [174]view article
          + [175]google scholar
   14. 14. yusuf s, collins r, peto r (1984) why do we need some large,
       simple randomized trials? stat med 3: 409   422.
          + [176]view article
          + [177]google scholar
   15. 15. altman dg, royston p (2000) what do we mean by validating a
       prognostic model? stat med 19: 453   473.
          + [178]view article
          + [179]google scholar
   16. 16. taubes g (1995) epidemiology faces its limits. science 269:
       164   169.
          + [180]view article
          + [181]google scholar
   17. 17. golub tr, slonim dk, tamayo p, huard c, gaasenbeek m, et al.
       (1999) molecular classification of cancer: class discovery and
       class prediction by gene expression monitoring. science 286:
       531   537.
          + [182]view article
          + [183]google scholar
   18. 18. moher d, schulz kf, altman dg (2001) the consort statement:
       revised recommendations for improving the quality of reports of
       parallel-group randomised trials. lancet 357: 1191   1194.
          + [184]view article
          + [185]google scholar
   19. 19. ioannidis jp, evans sj, gotzsche pc, o'neill rt, altman dg, et
       al. (2004) better reporting of harms in randomized trials: an
       extension of the consort statement. ann intern med 141: 781   788.
          + [186]view article
          + [187]google scholar
   20. 20. international conference on harmonisation e9 expert working
       group (1999) ich harmonised tripartite guideline. statistical
       principles for clinical trials. stat med 18: 1905   1942.
          + [188]view article
          + [189]google scholar
   21. 21. moher d, cook dj, eastwood s, olkin i, rennie d, et al. (1999)
       improving the quality of reports of meta-analyses of randomised
       controlled trials: the quorom statement. quality of reporting of
       meta-analyses. lancet 354: 1896   1900.
          + [190]view article
          + [191]google scholar
   22. 22. stroup df, berlin ja, morton sc, olkin i, williamson gd, et al.
       (2000) meta-analysis of observational studies in epidemiology: a
       proposal for reporting. meta-analysis of observational studies in
       epidemiology (moose) group. jama 283: 2008   2012.
          + [192]view article
          + [193]google scholar
   23. 23. marshall m, lockwood a, bradley c, adams c, joy c, et al.
       (2000) unpublished rating scales: a major source of bias in
       randomised controlled trials of treatments for schizophrenia. br j
       psychiatry 176: 249   252.
          + [194]view article
          + [195]google scholar
   24. 24. altman dg, goodman sn (1994) transfer of technology from
       statistical journals to the biomedical literature. past trends and
       future predictions. jama 272: 129   132.
          + [196]view article
          + [197]google scholar
   25. 25. chan aw, hrobjartsson a, haahr mt, gotzsche pc, altman dg
       (2004) empirical evidence for selective reporting of outcomes in
       randomized trials: comparison of protocols to published articles.
       jama 291: 2457   2465.
          + [198]view article
          + [199]google scholar
   26. 26. krimsky s, rothenberg ls, stott p, kyle g (1998) scientific
       journals and their authors' financial interests: a pilot study.
       psychother psychosom 67: 194   201.
          + [200]view article
          + [201]google scholar
   27. 27. papanikolaou gn, baltogianni ms, contopoulos-ioannidis dg,
       haidich ab, giannakakis ia, et al. (2001) reporting of conflicts of
       interest in guidelines of preventive and therapeutic interventions.
       bmc med res methodol 1: 3.
          + [202]view article
          + [203]google scholar
   28. 28. antman em, lau j, kupelnick b, mosteller f, chalmers tc (1992)
       a comparison of results of meta-analyses of randomized control
       trials and recommendations of clinical experts. treatments for
       myocardial infarction. jama 268: 240   248.
          + [204]view article
          + [205]google scholar
   29. 29. ioannidis jp, trikalinos ta (2005) early extreme contradictory
       estimates may appear in published research: the proteus phenomenon
       in molecular genetics research and randomized trials. j clin
       epidemiol 58: 543   549.
          + [206]view article
          + [207]google scholar
   30. 30. ntzani ee, ioannidis jp (2003) predictive ability of dna
       microarrays for cancer outcomes and correlates: an empirical
       assessment. lancet 362: 1439   1444.
          + [208]view article
          + [209]google scholar
   31. 31. ransohoff df (2004) rules of evidence for cancer
       molecular-marker discovery and validation. nat rev cancer 4:
       309   314.
          + [210]view article
          + [211]google scholar
   32. 32. lindley dv (1957) a statistical paradox. biometrika 44:
       187   192.
          + [212]view article
          + [213]google scholar
   33. 33. bartlett ms (1957) a comment on d.v. lindley's statistical
       paradox. biometrika 44: 533   534.
          + [214]view article
          + [215]google scholar
   34. 34. senn sj (2001) two cheers for p-values. j epidemiol biostat 6:
       193   204.
          + [216]view article
          + [217]google scholar
   35. 35. de angelis c, drazen jm, frizelle fa, haug c, hoey j, et al.
       (2004) clinical trial registration: a statement from the
       international committee of medical journal editors. n engl j med
       351: 1250   1251.
          + [218]view article
          + [219]google scholar
   36. 36. ioannidis jpa (2005) contradicted and initially stronger
       effects in highly cited clinical research. jama 294: 218   228.
          + [220]view article
          + [221]google scholar
   37. 37. hsueh hm, chen jj, kodell rl (2003) comparison of methods for
       estimating the number of true null hypotheses in multiplicity
       testing. j biopharm stat 13: 675   689.
          + [222]view article
          + [223]google scholar

   [224]download pdf

     * [225]citation
     * [226]xml

   print
     * [227]print article
     * [228]ezreprint

   share
     * [229]reddit reddit
     * [230]google+ google+
     * [231]facebook facebook
     * [232]linkedin linkedin
     * [233]citeulike citeulike
     * [234]mendeley mendeley
     * [235]pubchase pubchase
     * [236]twitter twitter
     * [237]email email

       [crossmark_bw_horizontal.svg]

related plos articles

     * [238]why current publication practices may distort science
     * [239]why most published research findings are false: author's reply
       to goodman and greenland
     * [240]why most published research findings are false: problems in
       the analysis
     * [241]most published research findings are false   but a little
       replication goes a long way
     * [242]when should potentially false research findings be considered
       acceptable?
     * [243]power, reliability, and heterogeneous results
     * [244]author's reply
     * [245]the clinical interpretation of research
     * [246]truth, id203, and frameworks
     * [247]minimizing mistakes and embracing uncertainty

included in the following collection

     * [248]meta-research: methods

   advertisement

subject areas

   ?

   for more information about plos subject areas, click [249]here.
   we want your feedback. do these subject areas make sense for this
   article? click the target next to the incorrect subject area and let us
   know. thanks for your help!
     * [250]research design
       is the subject area "research design" applicable to this article?
       (button) yes (flagno) no
       thanks for your feedback.
     * [251]randomized controlled trials
       is the subject area "randomized controlled trials" applicable to
       this article? (button) yes (flagno) no
       thanks for your feedback.
     * [252]genetic epidemiology
       is the subject area "genetic epidemiology" applicable to this
       article? (button) yes (flagno) no
       thanks for your feedback.
     * [253]genetics of disease
       is the subject area "genetics of disease" applicable to this
       article? (button) yes (flagno) no
       thanks for your feedback.
     * [254]meta-analysis
       is the subject area "meta-analysis" applicable to this article?
       (button) yes (flagno) no
       thanks for your feedback.
     * [255]schizophrenia
       is the subject area "schizophrenia" applicable to this article?
       (button) yes (flagno) no
       thanks for your feedback.
     * [256]clinical research design
       is the subject area "clinical research design" applicable to this
       article? (button) yes (flagno) no
       thanks for your feedback.
     * [257]finance
       is the subject area "finance" applicable to this article? (button)
       yes (flagno) no
       thanks for your feedback.

archived tweets

   load more
   [258]view all tweets

     * [259]publications
     * [260]plos biology
     * [261]plos medicine
     * [262]plos computational biology
     * [263]plos genetics
     * [264]plos pathogens
     * [265]plos one
     * [266]plos neglected tropical diseases

     * [267]home
     * [268]blogs
     * [269]collections
     * [270]give feedback
     * [271]lockss

     * [272]privacy policy
     * [273]terms of use
     * [274]advertise
     * [275]media inquiries
     * [276]contact

   plos is a nonprofit 501(c)(3) corporation, #c2354500, based in san
   francisco, california, us
   plos

references

   1. https://www.googletagmanager.com/ns.html?id=gtm-tp26bh
   2. https://www.googletagmanager.com/ns.html?id=gtm-mqqmgf
   3. https://www.plos.org/
   4. https://community.plos.org/registration/new
   5. https://journals.plos.org/plosmedicine/user/secure/login?page=/plosmedicine/article?id=10.1371/journal.pmed.0020124
   6. https://journals.plos.org/plosmedicine/.
   7. https://journals.plos.org/plosmedicine/issue
   8. https://journals.plos.org/plosmedicine/volume
   9. https://collections.plos.org/s/plos-medicine-special-issues
  10. https://journals.plos.org/plosmedicine/s/collections
  11. https://journals.plos.org/plosmedicine/s/find-and-read-articles
  12. https://journals.plos.org/plosmedicine/s/getting-started
  13. https://journals.plos.org/plosmedicine/s/presubmission-inquiries
  14. https://journals.plos.org/plosmedicine/s/submission-guidelines
  15. https://journals.plos.org/plosmedicine/s/figures
  16. https://journals.plos.org/plosmedicine/s/tables
  17. https://journals.plos.org/plosmedicine/s/supporting-information
  18. https://journals.plos.org/plosmedicine/s/latex
  19. https://journals.plos.org/plosmedicine/s/other-article-types
  20. https://journals.plos.org/plosmedicine/s/revising-your-manuscript
  21. https://journals.plos.org/plosmedicine/s/submit-now
  22. https://journals.plos.org/plosmedicine/s/best-practices-in-research-reporting
  23. https://journals.plos.org/plosmedicine/s/human-subjects-research
  24. https://journals.plos.org/plosmedicine/s/animal-research
  25. https://journals.plos.org/plosmedicine/s/competing-interests
  26. https://journals.plos.org/plosmedicine/s/disclosure-of-funding-sources
  27. https://journals.plos.org/plosmedicine/s/licenses-and-copyright
  28. https://journals.plos.org/plosmedicine/s/data-availability
  29. https://journals.plos.org/plosmedicine/s/materials-and-software-sharing
  30. https://journals.plos.org/plosmedicine/s/ethical-publishing-practice
  31. https://journals.plos.org/plosmedicine/s/authorship
  32. https://journals.plos.org/plosmedicine/s/downloads-and-translations
  33. https://journals.plos.org/plosmedicine/s/editorial-and-peer-review-process
  34. https://journals.plos.org/plosmedicine/s/reviewer-guidelines
  35. https://journals.plos.org/plosmedicine/s/accepted-manuscripts
  36. https://journals.plos.org/plosmedicine/s/corrections-and-retractions
  37. https://journals.plos.org/plosmedicine/s/comments
  38. https://journals.plos.org/plosmedicine/s/article-level-metrics
  39. https://journals.plos.org/plosmedicine/s/submit-now
  40. https://journals.plos.org/plosmedicine/s/why-publish-with-plos-medicine
  41. https://journals.plos.org/plosmedicine/s/journal-information
  42. https://journals.plos.org/plosmedicine/s/staff-editors
  43. https://journals.plos.org/plosmedicine/s/editorial-board
  44. https://journals.plos.org/plosmedicine/s/publishing-information
  45. https://journals.plos.org/plosmedicine/s/publication-fees
  46. https://journals.plos.org/plosmedicine/s/press-and-media
  47. https://journals.plos.org/plosmedicine/s/resources
  48. https://journals.plos.org/plosmedicine/s/contact
  49. https://journals.plos.org/plosmedicine/search
  50. https://journals.plos.org/plosmedicine/s/other-article-types#essay
  51. https://journals.plos.org/plosmedicine/s/other-article-types
  52. https://doi.org/10.1371/journal.pmed.0020124
  53. https://journals.plos.org/plosmedicine/article?id=10.1371/journal.pmed.0020124
  54. https://journals.plos.org/plosmedicine/article/authors?id=10.1371/journal.pmed.0020124
  55. https://journals.plos.org/plosmedicine/article/metrics?id=10.1371/journal.pmed.0020124
  56. https://journals.plos.org/plosmedicine/article/comments?id=10.1371/journal.pmed.0020124
  57. https://journals.plos.org/plosmedicine/article/related?id=10.1371/journal.pmed.0020124
  58. https://journals.plos.org/plosmedicine/article/comments?id=10.1371/journal.pmed.0020124
  59. https://journals.plos.org/plosmedicine/article/related?id=10.1371/journal.pmed.0020124
  60. https://journals.plos.org/plosmedicine/article?id=10.1371/journal.pmed.0020124
  61. https://journals.plos.org/plosmedicine/article?id=10.1371/journal.pmed.0020124#pmed-0020124-b1
  62. https://journals.plos.org/plosmedicine/article?id=10.1371/journal.pmed.0020124#pmed-0020124-b4
  63. https://journals.plos.org/plosmedicine/article?id=10.1371/journal.pmed.0020124#pmed-0020124-b5
  64. https://journals.plos.org/plosmedicine/article?id=10.1371/journal.pmed.0020124#pmed-0020124-b6
  65. https://journals.plos.org/plosmedicine/article?id=10.1371/journal.pmed.0020124#pmed-0020124-b9
  66. https://journals.plos.org/plosmedicine/article?id=10.1371/journal.pmed.0020124#pmed-0020124-b10
  67. https://journals.plos.org/plosmedicine/article?id=10.1371/journal.pmed.0020124#pmed-0020124-b11
  68. https://journals.plos.org/plosmedicine/article?id=10.1371/journal.pmed.0020124#pmed-0020124-t001
  69. https://journals.plos.org/plosmedicine/article?id=10.1371/journal.pmed.0020124#pmed-0020124-b10
  70. https://journals.plos.org/plosmedicine/article/figure/image?size=medium&id=info:doi/10.1371/journal.pmed.0020124.t001
  71. https://journals.plos.org/plosmedicine/article/figure/powerpoint?id=info:doi/10.1371/journal.pmed.0020124.t001
  72. https://journals.plos.org/plosmedicine/article/figure/powerpoint?id=info:doi/10.1371/journal.pmed.0020124.t001
  73. https://journals.plos.org/plosmedicine/article/figure/image?download&size=large&id=info:doi/10.1371/journal.pmed.0020124.t001
  74. https://journals.plos.org/plosmedicine/article/figure/image?download&size=large&id=info:doi/10.1371/journal.pmed.0020124.t001
  75. https://journals.plos.org/plosmedicine/article/figure/image?download&size=original&id=info:doi/10.1371/journal.pmed.0020124.t001
  76. https://journals.plos.org/plosmedicine/article/figure/image?download&size=original&id=info:doi/10.1371/journal.pmed.0020124.t001
  77. https://doi.org/10.1371/journal.pmed.0020124.t001
  78. https://journals.plos.org/plosmedicine/article?id=10.1371/journal.pmed.0020124#pmed-0020124-t002
  79. https://journals.plos.org/plosmedicine/article?id=10.1371/journal.pmed.0020124#pmed-0020124-g001
  80. https://journals.plos.org/plosmedicine/article?id=10.1371/journal.pmed.0020124#pmed-0020124-b12
  81. https://journals.plos.org/plosmedicine/article?id=10.1371/journal.pmed.0020124#pmed-0020124-b13
  82. https://journals.plos.org/plosmedicine/article/figure/image?size=medium&id=info:doi/10.1371/journal.pmed.0020124.g001
  83. https://journals.plos.org/plosmedicine/article/figure/powerpoint?id=info:doi/10.1371/journal.pmed.0020124.g001
  84. https://journals.plos.org/plosmedicine/article/figure/powerpoint?id=info:doi/10.1371/journal.pmed.0020124.g001
  85. https://journals.plos.org/plosmedicine/article/figure/image?download&size=large&id=info:doi/10.1371/journal.pmed.0020124.g001
  86. https://journals.plos.org/plosmedicine/article/figure/image?download&size=large&id=info:doi/10.1371/journal.pmed.0020124.g001
  87. https://journals.plos.org/plosmedicine/article/figure/image?download&size=original&id=info:doi/10.1371/journal.pmed.0020124.g001
  88. https://journals.plos.org/plosmedicine/article/figure/image?download&size=original&id=info:doi/10.1371/journal.pmed.0020124.g001
  89. https://doi.org/10.1371/journal.pmed.0020124.g001
  90. https://journals.plos.org/plosmedicine/article/figure/image?size=medium&id=info:doi/10.1371/journal.pmed.0020124.t002
  91. https://journals.plos.org/plosmedicine/article/figure/powerpoint?id=info:doi/10.1371/journal.pmed.0020124.t002
  92. https://journals.plos.org/plosmedicine/article/figure/powerpoint?id=info:doi/10.1371/journal.pmed.0020124.t002
  93. https://journals.plos.org/plosmedicine/article/figure/image?download&size=large&id=info:doi/10.1371/journal.pmed.0020124.t002
  94. https://journals.plos.org/plosmedicine/article/figure/image?download&size=large&id=info:doi/10.1371/journal.pmed.0020124.t002
  95. https://journals.plos.org/plosmedicine/article/figure/image?download&size=original&id=info:doi/10.1371/journal.pmed.0020124.t002
  96. https://journals.plos.org/plosmedicine/article/figure/image?download&size=original&id=info:doi/10.1371/journal.pmed.0020124.t002
  97. https://doi.org/10.1371/journal.pmed.0020124.t002
  98. https://journals.plos.org/plosmedicine/article?id=10.1371/journal.pmed.0020124#pmed-0020124-t003
  99. https://journals.plos.org/plosmedicine/article?id=10.1371/journal.pmed.0020124#pmed-0020124-g002
 100. https://journals.plos.org/plosmedicine/article/figure/image?size=medium&id=info:doi/10.1371/journal.pmed.0020124.g002
 101. https://journals.plos.org/plosmedicine/article/figure/powerpoint?id=info:doi/10.1371/journal.pmed.0020124.g002
 102. https://journals.plos.org/plosmedicine/article/figure/powerpoint?id=info:doi/10.1371/journal.pmed.0020124.g002
 103. https://journals.plos.org/plosmedicine/article/figure/image?download&size=large&id=info:doi/10.1371/journal.pmed.0020124.g002
 104. https://journals.plos.org/plosmedicine/article/figure/image?download&size=large&id=info:doi/10.1371/journal.pmed.0020124.g002
 105. https://journals.plos.org/plosmedicine/article/figure/image?download&size=original&id=info:doi/10.1371/journal.pmed.0020124.g002
 106. https://journals.plos.org/plosmedicine/article/figure/image?download&size=original&id=info:doi/10.1371/journal.pmed.0020124.g002
 107. https://doi.org/10.1371/journal.pmed.0020124.g002
 108. https://journals.plos.org/plosmedicine/article/figure/image?size=medium&id=info:doi/10.1371/journal.pmed.0020124.t003
 109. https://journals.plos.org/plosmedicine/article/figure/powerpoint?id=info:doi/10.1371/journal.pmed.0020124.t003
 110. https://journals.plos.org/plosmedicine/article/figure/powerpoint?id=info:doi/10.1371/journal.pmed.0020124.t003
 111. https://journals.plos.org/plosmedicine/article/figure/image?download&size=large&id=info:doi/10.1371/journal.pmed.0020124.t003
 112. https://journals.plos.org/plosmedicine/article/figure/image?download&size=large&id=info:doi/10.1371/journal.pmed.0020124.t003
 113. https://journals.plos.org/plosmedicine/article/figure/image?download&size=original&id=info:doi/10.1371/journal.pmed.0020124.t003
 114. https://journals.plos.org/plosmedicine/article/figure/image?download&size=original&id=info:doi/10.1371/journal.pmed.0020124.t003
 115. https://doi.org/10.1371/journal.pmed.0020124.t003
 116. https://journals.plos.org/plosmedicine/article?id=10.1371/journal.pmed.0020124#box1
 117. https://journals.plos.org/plosmedicine/article?id=10.1371/journal.pmed.0020124#pmed-0020124-b14
 118. https://journals.plos.org/plosmedicine/article?id=10.1371/journal.pmed.0020124#pmed-0020124-b15
 119. https://journals.plos.org/plosmedicine/article?id=10.1371/journal.pmed.0020124#pmed-0020124-b7
 120. https://journals.plos.org/plosmedicine/article?id=10.1371/journal.pmed.0020124#pmed-0020124-b16
 121. https://journals.plos.org/plosmedicine/article?id=10.1371/journal.pmed.0020124#pmed-0020124-b4
 122. https://journals.plos.org/plosmedicine/article?id=10.1371/journal.pmed.0020124#pmed-0020124-b8
 123. https://journals.plos.org/plosmedicine/article?id=10.1371/journal.pmed.0020124#pmed-0020124-b17
 124. https://journals.plos.org/plosmedicine/article?id=10.1371/journal.pmed.0020124#pmed-0020124-b18
 125. https://journals.plos.org/plosmedicine/article?id=10.1371/journal.pmed.0020124#pmed-0020124-b21
 126. https://journals.plos.org/plosmedicine/article?id=10.1371/journal.pmed.0020124#pmed-0020124-b22
 127. https://journals.plos.org/plosmedicine/article?id=10.1371/journal.pmed.0020124#pmed-0020124-b23
 128. https://journals.plos.org/plosmedicine/article?id=10.1371/journal.pmed.0020124#pmed-0020124-b24
 129. https://journals.plos.org/plosmedicine/article?id=10.1371/journal.pmed.0020124#pmed-0020124-b25
 130. https://journals.plos.org/plosmedicine/article?id=10.1371/journal.pmed.0020124#pmed-0020124-b26
 131. https://journals.plos.org/plosmedicine/article?id=10.1371/journal.pmed.0020124#pmed-0020124-b26
 132. https://journals.plos.org/plosmedicine/article?id=10.1371/journal.pmed.0020124#pmed-0020124-b27
 133. https://journals.plos.org/plosmedicine/article?id=10.1371/journal.pmed.0020124#pmed-0020124-b28
 134. https://journals.plos.org/plosmedicine/article?id=10.1371/journal.pmed.0020124#pmed-0020124-b29
 135. https://journals.plos.org/plosmedicine/article?id=10.1371/journal.pmed.0020124#pmed-0020124-b29
 136. https://journals.plos.org/plosmedicine/article?id=10.1371/journal.pmed.0020124#pmed-0020124-t004
 137. https://journals.plos.org/plosmedicine/article?id=10.1371/journal.pmed.0020124#pmed-0020124-b30
 138. https://journals.plos.org/plosmedicine/article?id=10.1371/journal.pmed.0020124#pmed-0020124-b31
 139. https://journals.plos.org/plosmedicine/article/figure/image?size=medium&id=info:doi/10.1371/journal.pmed.0020124.t004
 140. https://journals.plos.org/plosmedicine/article/figure/powerpoint?id=info:doi/10.1371/journal.pmed.0020124.t004
 141. https://journals.plos.org/plosmedicine/article/figure/powerpoint?id=info:doi/10.1371/journal.pmed.0020124.t004
 142. https://journals.plos.org/plosmedicine/article/figure/image?download&size=large&id=info:doi/10.1371/journal.pmed.0020124.t004
 143. https://journals.plos.org/plosmedicine/article/figure/image?download&size=large&id=info:doi/10.1371/journal.pmed.0020124.t004
 144. https://journals.plos.org/plosmedicine/article/figure/image?download&size=original&id=info:doi/10.1371/journal.pmed.0020124.t004
 145. https://journals.plos.org/plosmedicine/article/figure/image?download&size=original&id=info:doi/10.1371/journal.pmed.0020124.t004
 146. https://doi.org/10.1371/journal.pmed.0020124.t004
 147. https://journals.plos.org/plosmedicine/article?id=10.1371/journal.pmed.0020124#pmed-0020124-b32
 148. https://journals.plos.org/plosmedicine/article?id=10.1371/journal.pmed.0020124#pmed-0020124-b35
 149. https://journals.plos.org/plosmedicine/article?id=10.1371/journal.pmed.0020124#pmed-0020124-b10
 150. https://journals.plos.org/plosmedicine/article?id=10.1371/journal.pmed.0020124#pmed-0020124-b36
 151. https://journals.plos.org/plosmedicine/article?id=10.1371/journal.pmed.0020124#pmed-0020124-b37
 152. https://journals.plos.org/plosmedicine/article?id=10.1371/journal.pmed.0020124
 153. http://scholar.google.com/scholar?q=any+casualties+in+the+clash+of+randomised+and+observational+evidence?+ioannidis+2001
 154. https://journals.plos.org/plosmedicine/article?id=10.1371/journal.pmed.0020124
 155. http://scholar.google.com/scholar?q=those+confounded+vitamins:+what+can+we+learn+from+the+differences+between+observational+versus+randomised+trial+evidence?+lawlor+2004
 156. https://journals.plos.org/plosmedicine/article?id=10.1371/journal.pmed.0020124
 157. http://scholar.google.com/scholar?q=when+are+observational+studies+as+credible+as+randomised+trials?+vandenbroucke+2004
 158. https://journals.plos.org/plosmedicine/article?id=10.1371/journal.pmed.0020124
 159. http://scholar.google.com/scholar?q=prediction+of+cancer+outcome+with+microarrays:+a+multiple+random+validation+strategy.+michiels+2005
 160. https://journals.plos.org/plosmedicine/article?id=10.1371/journal.pmed.0020124
 161. http://scholar.google.com/scholar?q=replication+validity+of+genetic+association+studies.+ioannidis+2001
 162. https://journals.plos.org/plosmedicine/article?id=10.1371/journal.pmed.0020124
 163. http://scholar.google.com/scholar?q=problems+of+reporting+genetic+associations+with+complex+outcomes.+colhoun+2003
 164. https://journals.plos.org/plosmedicine/article?id=10.1371/journal.pmed.0020124
 165. http://scholar.google.com/scholar?q=genetic+associations:+false+or+true?+ioannidis+2003
 166. https://journals.plos.org/plosmedicine/article?id=10.1371/journal.pmed.0020124
 167. http://scholar.google.com/scholar?q=microarrays+and+molecular+research:+noise+discovery?+ioannidis+2005
 168. https://journals.plos.org/plosmedicine/article?id=10.1371/journal.pmed.0020124
 169. http://scholar.google.com/scholar?q=sifting+the+evidence   what&apos;s+wrong+with+significance+tests.+sterne+2001
 170. https://journals.plos.org/plosmedicine/article?id=10.1371/journal.pmed.0020124
 171. http://scholar.google.com/scholar?q=assessing+the+id203+that+a+positive+report+is+false:+an+approach+for+molecular+epidemiology+studies.+wacholder+2004
 172. https://journals.plos.org/plosmedicine/article?id=10.1371/journal.pmed.0020124
 173. http://scholar.google.com/scholar?q=searching+for+genetic+determinants+in+the+new+millennium.+risch+2000
 174. https://journals.plos.org/plosmedicine/article?id=10.1371/journal.pmed.0020124
 175. http://scholar.google.com/scholar?q=failing+the+public+health   rofecoxib,+merck,+and+the+fda.+topol+2004
 176. https://journals.plos.org/plosmedicine/article?id=10.1371/journal.pmed.0020124
 177. http://scholar.google.com/scholar?q=why+do+we+need+some+large,+simple+randomized+trials?+yusuf+1984
 178. https://journals.plos.org/plosmedicine/article?id=10.1371/journal.pmed.0020124
 179. http://scholar.google.com/scholar?q=what+do+we+mean+by+validating+a+prognostic+model?+altman+2000
 180. https://journals.plos.org/plosmedicine/article?id=10.1371/journal.pmed.0020124
 181. http://scholar.google.com/scholar?q=epidemiology+faces+its+limits.+taubes+1995
 182. https://journals.plos.org/plosmedicine/article?id=10.1371/journal.pmed.0020124
 183. http://scholar.google.com/scholar?q=molecular+classification+of+cancer:+class+discovery+and+class+prediction+by+gene+expression+monitoring.+golub+1999
 184. https://journals.plos.org/plosmedicine/article?id=10.1371/journal.pmed.0020124
 185. http://scholar.google.com/scholar?q=the+consort+statement:+revised+recommendations+for+improving+the+quality+of+reports+of+parallel-group+randomised+trials.+moher+2001
 186. https://journals.plos.org/plosmedicine/article?id=10.1371/journal.pmed.0020124
 187. http://scholar.google.com/scholar?q=better+reporting+of+harms+in+randomized+trials:+an+extension+of+the+consort+statement.+ioannidis+2004
 188. https://journals.plos.org/plosmedicine/article?id=10.1371/journal.pmed.0020124
 189. http://scholar.google.com/scholar?q=ich+harmonised+tripartite+guideline.+statistical+principles+for+clinical+trials.++1999
 190. https://journals.plos.org/plosmedicine/article?id=10.1371/journal.pmed.0020124
 191. http://scholar.google.com/scholar?q=improving+the+quality+of+reports+of+meta-analyses+of+randomised+controlled+trials:+the+quorom+statement.+quality+of+reporting+of+meta-analyses.+moher+1999
 192. https://journals.plos.org/plosmedicine/article?id=10.1371/journal.pmed.0020124
 193. http://scholar.google.com/scholar?q=meta-analysis+of+observational+studies+in+epidemiology:+a+proposal+for+reporting.+meta-analysis+of+observational+studies+in+epidemiology+(moose)+group.+stroup+2000
 194. https://journals.plos.org/plosmedicine/article?id=10.1371/journal.pmed.0020124
 195. http://scholar.google.com/scholar?q=unpublished+rating+scales:+a+major+source+of+bias+in+randomised+controlled+trials+of+treatments+for+schizophrenia.+marshall+2000
 196. https://journals.plos.org/plosmedicine/article?id=10.1371/journal.pmed.0020124
 197. http://scholar.google.com/scholar?q=transfer+of+technology+from+statistical+journals+to+the+biomedical+literature.+past+trends+and+future+predictions.+altman+1994
 198. https://journals.plos.org/plosmedicine/article?id=10.1371/journal.pmed.0020124
 199. http://scholar.google.com/scholar?q=empirical+evidence+for+selective+reporting+of+outcomes+in+randomized+trials:+comparison+of+protocols+to+published+articles.+chan+2004
 200. https://journals.plos.org/plosmedicine/article?id=10.1371/journal.pmed.0020124
 201. http://scholar.google.com/scholar?q=scientific+journals+and+their+authors&apos;+financial+interests:+a+pilot+study.+krimsky+1998
 202. https://journals.plos.org/plosmedicine/article?id=10.1371/journal.pmed.0020124
 203. http://scholar.google.com/scholar?q=reporting+of+conflicts+of+interest+in+guidelines+of+preventive+and+therapeutic+interventions.+papanikolaou+2001
 204. https://journals.plos.org/plosmedicine/article?id=10.1371/journal.pmed.0020124
 205. http://scholar.google.com/scholar?q=a+comparison+of+results+of+meta-analyses+of+randomized+control+trials+and+recommendations+of+clinical+experts.+treatments+for+myocardial+infarction.+antman+1992
 206. https://journals.plos.org/plosmedicine/article?id=10.1371/journal.pmed.0020124
 207. http://scholar.google.com/scholar?q=early+extreme+contradictory+estimates+may+appear+in+published+research:+the+proteus+phenomenon+in+molecular+genetics+research+and+randomized+trials.+ioannidis+2005
 208. https://journals.plos.org/plosmedicine/article?id=10.1371/journal.pmed.0020124
 209. http://scholar.google.com/scholar?q=predictive+ability+of+dna+microarrays+for+cancer+outcomes+and+correlates:+an+empirical+assessment.+ntzani+2003
 210. https://journals.plos.org/plosmedicine/article?id=10.1371/journal.pmed.0020124
 211. http://scholar.google.com/scholar?q=rules+of+evidence+for+cancer+molecular-marker+discovery+and+validation.+ransohoff+2004
 212. https://journals.plos.org/plosmedicine/article?id=10.1371/journal.pmed.0020124
 213. http://scholar.google.com/scholar?q=a+statistical+paradox.+lindley+1957
 214. https://journals.plos.org/plosmedicine/article?id=10.1371/journal.pmed.0020124
 215. http://scholar.google.com/scholar?q=a+comment+on+d.v.+lindley&apos;s+statistical+paradox.+bartlett+1957
 216. https://journals.plos.org/plosmedicine/article?id=10.1371/journal.pmed.0020124
 217. http://scholar.google.com/scholar?q=two+cheers+for+p-values.+senn+2001
 218. https://journals.plos.org/plosmedicine/article?id=10.1371/journal.pmed.0020124
 219. http://scholar.google.com/scholar?q=clinical+trial+registration:+a+statement+from+the+international+committee+of+medical+journal+editors.+de+angelis+2004
 220. https://journals.plos.org/plosmedicine/article?id=10.1371/journal.pmed.0020124
 221. http://scholar.google.com/scholar?q=contradicted+and+initially+stronger+effects+in+highly+cited+clinical+research.+ioannidis+2005
 222. https://journals.plos.org/plosmedicine/article?id=10.1371/journal.pmed.0020124
 223. http://scholar.google.com/scholar?q=comparison+of+methods+for+estimating+the+number+of+true+null+hypotheses+in+multiplicity+testing.+hsueh+2003
 224. https://journals.plos.org/plosmedicine/article/file?id=10.1371/journal.pmed.0020124&type=printable
 225. https://journals.plos.org/plosmedicine/article/citation?id=10.1371/journal.pmed.0020124
 226. https://journals.plos.org/plosmedicine/article/file?id=10.1371/journal.pmed.0020124&type=manuscript
 227. https://journals.plos.org/plosmedicine/article?id=10.1371/journal.pmed.0020124
 228. https://www.odysseypress.com/onlinehost/reprint_order.php?type=a&page=0&journal=2&doi=10.1371/journal.pmed.0020124&volume=&issue=&title=why most published research findings are false&author_name=john p. a. ioannidis&start_page=1
 229. https://www.reddit.com/submit?url=http://dx.plos.org/10.1371/journal.pmed.0020124
 230. https://plus.google.com/share?url=http://dx.plos.org/10.1371/journal.pmed.0020124
 231. https://www.facebook.com/share.php?u=http://dx.plos.org/10.1371/journal.pmed.0020124&t=why most published research findings are false
 232. https://www.linkedin.com/sharearticle?url=http://dx.plos.org/10.1371/journal.pmed.0020124&title=why most published research findings are false&summary=checkout this article i found at plos
 233. http://www.citeulike.org/posturl?url=http://dx.plos.org/10.1371/journal.pmed.0020124&title=why most published research findings are false
 234. https://www.mendeley.com/import/?url=http://dx.plos.org/10.1371/journal.pmed.0020124
 235. https://www.pubchase.com/library?add_aid=10.1371/journal.pmed.0020124&source=plos
 236. https://twitter.com/intent/tweet?url=http://dx.plos.org/10.1371/journal.pmed.0020124&text=#plosmedicine: why most published research findings are false
 237. https://journals.plos.org/plosmedicine/article/email?id=10.1371/journal.pmed.0020124
 238. https://journals.plos.org/plosmedicine/article?id=10.1371/journal.pmed.0050201
 239. https://journals.plos.org/plosmedicine/article?id=10.1371/journal.pmed.0040215
 240. https://journals.plos.org/plosmedicine/article?id=10.1371/journal.pmed.0040168
 241. https://journals.plos.org/plosmedicine/article?id=10.1371/journal.pmed.0040028
 242. https://journals.plos.org/plosmedicine/article?id=10.1371/journal.pmed.0040026
 243. https://journals.plos.org/plosmedicine/article?id=10.1371/journal.pmed.0020386
 244. https://journals.plos.org/plosmedicine/article?id=10.1371/journal.pmed.0020398
 245. https://journals.plos.org/plosmedicine/article?id=10.1371/journal.pmed.0020395
 246. https://journals.plos.org/plosmedicine/article?id=10.1371/journal.pmed.0020361
 247. https://journals.plos.org/plosmedicine/article?id=10.1371/journal.pmed.0020272
 248. https://collections.plos.org/meta-research-methods
 249. https://github.com/plos/plos-thesaurus/blob/develop/readme.md
 250. https://journals.plos.org/plosmedicine/search?filtersubjects=research+design&filterjournals=plosmedicine&q=
 251. https://journals.plos.org/plosmedicine/search?filtersubjects=randomized+controlled+trials&filterjournals=plosmedicine&q=
 252. https://journals.plos.org/plosmedicine/search?filtersubjects=genetic+epidemiology&filterjournals=plosmedicine&q=
 253. https://journals.plos.org/plosmedicine/search?filtersubjects=genetics+of+disease&filterjournals=plosmedicine&q=
 254. https://journals.plos.org/plosmedicine/search?filtersubjects=meta-analysis&filterjournals=plosmedicine&q=
 255. https://journals.plos.org/plosmedicine/search?filtersubjects=schizophrenia&filterjournals=plosmedicine&q=
 256. https://journals.plos.org/plosmedicine/search?filtersubjects=clinical+research+design&filterjournals=plosmedicine&q=
 257. https://journals.plos.org/plosmedicine/search?filtersubjects=finance&filterjournals=plosmedicine&q=
 258. https://alm.plos.org/works/doi.org/10.1371/journal.pmed.0020124?source_id=twitter
 259. https://www.plos.org/publications/journals/
 260. https://journals.plos.org/plosbiology/
 261. https://journals.plos.org/plosmedicine/
 262. https://journals.plos.org/ploscompbiol/
 263. https://journals.plos.org/plosgenetics/
 264. https://journals.plos.org/plospathogens/
 265. https://journals.plos.org/plosone/
 266. https://journals.plos.org/plosntds/
 267. https://www.plos.org/
 268. https://blogs.plos.org/
 269. https://collections.plos.org/
 270. https://journals.plos.org/plosmedicine/feedback
 271. https://journals.plos.org/plosmedicine/lockss-manifest
 272. https://www.plos.org/privacy-policy
 273. https://www.plos.org/terms-of-use
 274. https://www.plos.org/advertise/
 275. https://www.plos.org/media-inquiries
 276. https://www.plos.org/contact
