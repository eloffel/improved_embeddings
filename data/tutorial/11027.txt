   #[1]alternate [2]alternate

   warning: the ncbi web site requires javascript to function. [3]more...
     * [4]ncbi ncbi logo
     * [5]skip to main content
     * [6]skip to navigation
     * [7]resources
     * [8]how to
     * [9]about ncbi accesskeys

   [10]my ncbi[11]sign in to ncbi[12]sign out

[13]pmc

   [14]us national library of medicine
   [15]national institutes of health
   search database[pmc_____________________]
   search term
   ____________________
   (button) search
     * [16]advanced
     * [17]journal list
     * [18]help

     * [19]journal list
     * [20]amia annu symp proc
     * [21]v.2008; 2008
     * pmc2656101

   [22]logo of procamia
   amia annu symp proc. 2008; 2008: 222-226.
   published online 2008.
   pmcid: pmc2656101
   pmid: [23]18999029

models for predicting and explaining citation count of biomedical articles

   [24]lawrence d. fu, m.s.^1 and [25]constantin aliferis, m.d., ph.d.^1

lawrence d. fu

   ^1vanderbilt university, nashville, tn
   find articles by [26]lawrence d. fu

constantin aliferis

   ^1vanderbilt university, nashville, tn
   find articles by [27]constantin aliferis
   [28]author information [29]copyright and license information
   [30]disclaimer
   ^1vanderbilt university, nashville, tn
   [31]copyright [copyright]2008 amia - all rights reserved.
   this is an open access article: verbatim copying and redistribution of
   this article are permitted in all media for any purpose
   this article has been [32]cited by other articles in pmc.

abstract

   the single most important bibliometric criterion for judging the impact
   of biomedical papers and their authors' work is the number of citations
   received which is commonly referred to as "citation count". this metric
   however is unavailable until several years after publication time. in
   the present work, we build computer models that accurately predict
   citation counts of biomedical publications within a deep horizon of ten
   years using only predictive information available at publication time.
   our experiments show that it is indeed feasible to accurately predict
   future citation counts with a mixture of content-based and bibliometric
   features using machine learning methods. the models pave the way for
   practical prediction of the long-term impact of publication, and their
   statistical analysis provides greater insight into citation behavior.

introduction

   a commonly accepted metric for evaluating the impact and quality of an
   article is the citation count which is the number of citations received
   by this article within a pre-specified time horizon [[33]1]. the main
   limitation of citation count is its unavailability before this horizon
   expires (typically several years after publication). this delay renders
   citation counts primarily useful for historical assessment of the
   scientific contribution and impact of papers. another limitation of
   citation count is that it is a subjective measure [[34]1].

   automatic prediction of citation counts would provide a powerful new
   method for evaluating articles while alleviating many difficulties
   associated with the explosive growth of the biomedical literature.
   faster identification of promising articles could accelerate research
   and dissemination of new knowledge. accurate models for citation count
   prediction would also improve our understanding of the factors that
   influence citations.

   predicting and understanding article citation counts is however a very
   hard problem both on theoretical grounds and on the basis of several
   decades of related empirical work. in fact, the bulk of the literature
   concerning citation counts relates to understanding the motivating
   factors for article citations rather than predicting them. for an
   excellent survey, see [[35]1].

   from a theoretical point of view, it has been found that citation
   prediction is difficult because of the nature and dynamics of citations
   [[36]2, [37]3]. citations are a noisy, indirect quality measure, and
   accumulation rates vary unpredictably between articles. breakthrough
   papers can stop receiving citations after review articles replace them
   or the subject matter becomes common knowledge [[38]2]. predictions
   based on current data assume that citation behavior will not change in
   the future, and this assumption may be violated in fast-paced research
   fields such as biomedicine. another difficulty in making accurate
   predictions is the sparseness of a citation network [[39]3]. fitting a
   reliable statistical model is difficult since the number of links is
   small compared to the number of nodes, and negative cases (i.e.,
   non-connected nodes) grow much more rapidly than positive cases (i.e.,
   connected nodes) [[40]4].

   from an empirical perspective, previous research has predicted
   long-term citation counts based on citations accumulated shortly after
   publication. in the knowledge discovery and data mining cup competition
   of 2003 [[41]5], research groups predicted the evolution of the number
   of citations received by a set of 441 well-cited articles in
   high-energy physics during successive three month periods. in other
   work, castillo et al. [[42]6] used id75 and citation count
   after 6 months to predict citation count after 30 months. they
   incorporated author-related information (i.e., the number of previous
   citations, publications, and coauthors for an author) to improve
   predictions. the resulting model had a correlation coefficient of 0.81
   between the true number of citations received and predicted values for
   1500 articles from citeseer, a database of computer science articles.

   a recent report by lokker [[43]7] is closest to the aims of our work.
   it presents a regression model to predict citation counts in a time
   horizon of two years based on information available within three weeks
   of publication. it uses characteristics of an article that are either
   structural (e.g., whether it contains a structured abstract) or a
   result of manual systematic review criteria. this model has modest
   predictivity and explanatory power (0.76 area under the receiver
   operating characteristic curve and 60% explained variation).

   in our work, we hypothesize that we can achieve much greater
   predictivity and a deeper prediction horizon (ten years instead of two)
   compared to prior efforts by including in the model the full content
   terms of the medline abstract and mesh keywords as well as bibliometric
   information about the authors, journals, and institutions. furthermore,
   we only use information available at publication time. as a corollary
   to the above model-building effort, we also study factors that
   correlate strongly and potentially determine the chances of an article
   being cited by many subsequent articles.

methods

predictive features and response variables

   [44]table 1 lists the input features used to construct a learning
   corpus for predictive modeling. the number of articles or citations for
   first and last authors was counted for 10 years prior to publication.
   publication type indicates if a paper was identified as an article or
   review by the bibliometric database which was the web of science (wos)
   of the institute of scientific information (isi) [[45]8]. the academic
   ranking of world universities (arwu) [[46]9] was used as the measure of
   quality for first author's institution. number of institutions refers
   to unique home institutions for all authors. all other variables are
   self-explanatory.

table 1

   list of features included in each learning model
   feature complete model content model biblio. model i.f. model
   article title x x
   article abstract x x
   mesh terms x x
   number of articles for first author x x
   number of citations for first author x x
   number of articles for last author x x
   number of citations for last author x x
   publication type x x
   number of authors x x
   number of institutions x x
   journal impact factor x x x
   quality of first author's institution x x
   [47]open in a separate window

   the response variable is defined by a set of citation thresholds to
   determine if an article is labeled positive or negative. for a given
   threshold, a positive label means that an article received at least
   that number of citations within 10 years of publication. thresholds
   were chosen (before analysis) to be 20, 50, 100, and 500 citations. in
   the space of topics covered by the corpus (see next subsection), papers
   with at least 20, 50, 100, and 500 citations within 10 years can be
   interpreted to be at least: mildly influential, relatively influential,
   influential, and extremely influential respectively.

   predictions were made for a binary response variable rather than a
   continuous one in the present analysis primarily because error metrics
   for discrete values are easier to interpret than continuous ones.
   continuous id168s such as mean square error or percent
   variation explained are more difficult to interpret in terms of
   practical significance.

corpus construction

   we built a corpus for model training and evaluation by specifying a set
   of topics, journals, and dates. eight topics were chosen from internal
   medicine as defined by the mesh vocabulary: cardiology, endocrinology,
   gastroenterology, hematology, medical oncology, nephrology, pulmonary
   disease, and rheumatology. an article was operationally considered
   relevant to a topic if its medline record contained one of the eight
   mesh terms, a related topic from the "see also" field of the mesh
   record, or a term from a sub-tree of one of these terms
   ([48]http://www.nlm.nih.gov/mesh/). for example, an article was
   cardiology-related if it contained the mesh heading "cardiology", a
   related term like "cardiovascular diseases", or a term from a sub-tree.

   articles were included from six journals: american journal of medicine,
   annals of internal medicine, british medical journal, journal of the
   american medical association, lancet, and new england journal of
   medicine. the journals were selected to include popular journals with a
   broad range of impact factors. the corpus contained articles published
   between 1991 and 1994 to allow collection of citation data for a 10
   year period after publication of the most recent articles. the window
   length was chosen so that citation rates would have sufficient time to
   become relatively stable.

   pubmed was queried for all desired articles, and additional information
   was downloaded from the bibliometric database, the isi web of science
   (wos) [[49]8]. documents were excluded if bibliometric data was
   unavailable, and the final corpus contained 3788 documents. the
   complete model consisted of 20005 total features, and information was
   downloaded in may 2007. positive-to-negative class ratios for each
   threshold were as follows: 2705/1083 for threshold 20, 1858/1930 for
   threshold 50, 1136/2652 for threshold 100, and 100/3688 for threshold
   500 citations.

id194

   articles were formatted for learning by text preprocessing and term
   weighting. the title, abstract, and mesh terms were extracted from
   medline records. pubmed stop words
   ([50]http://www.ncbi.nlm.nih.gov/books/bv.fcgi?rid=helppubmed.table.pub
   medhelp.t43) were removed from the title and abstract. multiple forms
   of the same word were eliminated with the porter id30 algorithm
   [[51]10] to reduce the dimensionality of the input space. terms were
   weighted using log frequency with redundancy which considers term
   frequency in a document and the corpus [[52]11, [53]12]. each weight
   was a value between 0 and 1. in the end, the corpus was represented as
   a matrix where rows corresponded to documents and columns represented
   terms. bibliometric features were also scaled linearly between 0 and 1.

learning method

   support vector machine (id166) models were used as the learning
   algorithm. they are a supervised learning method where a kernel
   function maps the input space to a higher-dimensional feature space,
   and a hyperplane is calculated to separate the classes of data. the
   optimal hyperplane is the solution to a constrained quadratic
   optimization problem. id166 models are usually sparse since the solution
   depends on the support vectors or points closest to the hyperplane
   [[54]13]. id166s are well suited for representing text which typically
   involves high-dimensional data. prior research has demonstrated that
   they perform well in categorizing text and identifying high-quality
   articles [[55]11, [56]12].

model selection and error estimation

   we performed 5-fold nested cross validation and optimized parameters
   for cost and degree in the inner loop while the outer loop produced an
   unbiased estimate of model predictivity. the set of costs was [.1, .2,
   .4, .7, .9, 1, 5, 10, 20], and the set of degrees was [1, 2, 3, 4, 5,
   8]. performance was measured by area under the receiver operating
   characteristic curve (auc). auc was chosen instead of accuracy since
   auc is not dependent on the ratio of positive and negative cases.
   recall that an auc of 0.5 describes a random classifier, auc of ~.75 a
   mediocre classifier, auc of ~0.85 a very good classifier, and auc > 0.9
   an excellent classifier (while an auc of 1 denotes perfect
   classification).

analysis of influential features

   after fitting the complete models (i.e., with all features) and
   estimating their performance, we identified the most influential
   features using two types of analysis. first, we trained three
   reduced-feature models for each threshold based only on the content,
   bibliometric data, or impact factor. [57]table 1 shows the features
   included in each model. performance of these models revealed whether
   one type of feature was more important than the others.

   a second feature-specific analysis was performed as follows: we reduced
   the total number of features by selecting only features in the markov
   blanket of the response variable (i.e., number of citations received).
   the markov blanket is the smallest set of features conditioned on which
   all remaining features are independent of the response variable. thus
   it excludes both irrelevant and redundant variables without
   compromising predictivity, and it provably results in maximum variable
   compression under broad distributional assumptions [[58]14]. the
   specific algorithm used was semi-interleaved hiton-pc without symmetry
   correction which is an instance of the generalized local learning class
   of algorithms [[59]14]. before proceeding, we verified that the reduced
   feature set indeed predicts citation counts as well as the original
   model. after this variable selection and verification step, logistic
   regression analysis was employed to estimate for each feature the
   magnitude of its effect and statistical significance on predicting
   citation counts while controlling for all other features in the lr
   model. notice that the raw id166 weights, or recursive feature
   elimination (rfe) weights in the polynomial id166 case, cannot be used
   for the same purpose. id166s do not control for the effect of all other
   variables on the weight of each feature in the id166 model contrary to
   id28. instead id166s "spread" weights to otherwise
   conditionally independent features in order to implicitly model a
   smoother decision function.

implementation details

   corpus construction and feature weighting were implemented in custom
   python scripts. for text-based features, the scripts constructed pubmed
   queries, retrieved desired articles, downloaded medline records, and
   preprocessed text. for bibliometric features, the wos database was
   queried with the title, author, and journal of each article. if a match
   was found, a user session was simulated by navigating through the
   website and extracting desired information about the document and
   authors.

   the remainder of the code was written in matlab. libid166 was used to
   train id166 models, and it included a matlab interface [[60]15]. scripts
   were written to perform cross-validation and estimate performance. a
   custom matlab implementation for hiton was used as well as the logistic
   regression implementation of the matlab statistics toolbox.

results

overall predictivity

   [61]figure 1 shows the performance of four different types of models:
   the complete model with all features, models with only content
   features, models with only bibliometric features, and models with only
   the impact factor. the complete model accurately predicted whether a
   publication received a given number of citations for each citation
   threshold. auc values range from 0.857 to 0.918 depending on threshold.
   an external file that holds a picture, illustration, etc. object name
   is amia-0222-s2008f1.jpg
   [62]open in a separate window
   [63]figure 1

   performance for models based on all features, content, bibliometric
   features, and impact factor

testing for overfitting

   in response to the unexpectedly high level of achieved predictivity, we
   performed an additional analysis to verify that the results were
   generalizable (i.e., not overfitted). the analysis borrowed from
   state-of-the-art analysis of high-throughput data by randomly
   reshuffling citation counts followed and rebuilding all models on the
   reshuffled data [[64]16] exactly as was done for non-shuffled data.
   this procedure yielded auc estimates of 0.5 since reshuffling
   eliminated the predictive association of the features to the outcome.
   this result verified that our original analysis was not overfitted.

predictivity by feature type

   after establishing that model performance was not due to overfitted
   analysis, we focused our attention on estimating predictivity when
   learning was performed on subsets of the features. as shown in
   [65]figure 1, the consistent trend in all thresholds was: auc(complete
   model) [greater-than-or-equal] auc(content only features)
   [greater-than-or-equal] auc(bibliometric only features)
   [greater-than-or-equal] auc(impact factor only). the impact factor
   model had the lowest predictivity for all thresholds. this predictivity
   was much lower than that of the complete model (differences in aucs
   range from 0.065 to 0.154). the results in [66]figure 1 also show that
   both content and bibliometric features had individually high
   predictivity. auc was maximized only when combining all types of
   predictive features.

analysis of individual features

   as explained in the methods section, markov blanket induction was used
   to select only non-redundant and relevant features, and logistic
   regression was used to estimate feature importance and statistical
   significance of the selected features. the original set of 20,005
   features was reduced to 169, 125, 132, and 138 features for thresholds
   20, 50, 100, and 500 respectively. [67]table 2 shows the top 10 ranked
   features according to absolute values of regression coefficients for
   citation thresholds 50 and 100. a full-length journal version of the
   present work will provide the full results.

table 2

   top 10 features sorted by absolute value of regression coefficients for
   thresholds of 50 (left) and 100 (right) citations.
             feature            reg. coeff p-value std. error
           splenectomi           +/-3.406   0.006    1.243
   journal impact factor [wos]    3.342     0.000    0.164
   last author citations [wos]    3.147     0.001    0.914
          ciprofloxacin          +/-2.858   0.019    1.223
    anemia, sickle cell [mesh]   +/-2.760   0.000    0.681
       rural health [mesh]       +/-2.668   0.015    1.097
              brain               2.574     0.000    0.635
          history [mesh]         +/-2.442   0.046    1.227
   zidovudine:therap. use[mesh]   2.424     0.030    1.114
       death, sudden [mesh]      +/-2.329   0.014    0.948
   first author citations [wos]   5.753     0.000    1.469
     smoking:mortality [mesh]     4.224     0.018    1.785
              offset              3.347     0.007    1.232
   journal impact factor [wos]    3.320     0.000    0.180
   last author citations [wos]    3.023     0.001    0.872
       birth weight [mesh]        2.954     0.000    0.770
      pilot projects [mesh]      +/-2.912   0.013    1.173
   autoantibodies:blood [mesh]    2.783     0.001    0.810
      family practice [mesh]     +/-2.746   0.016    1.140
          person [title]          2.576     0.002    0.828
   [68]open in a separate window

   recall that a positive unit change in a regression coefficient [beta]
   for a feature corresponds to e^[beta] increase in the odds of exceeding
   the citation count threshold for which the model is built. for example,
   "first author citations" had the largest coefficient of 5.753 for
   citation threshold 100. this value indicates that an article with the
   greatest number of first author citations was about 315 times (e ^5.753
   [approximate] 315) more likely to receive 100 citations than an article
   with no first author citations (notice that a one-unit change for
   interval-based features corresponds to a difference between the largest
   and smallest values since interval variables were scaled in the [0,1]
   range).

   the feature-specific analysis points to several important conclusions:
   (a) certain "hot" topics were associated with high citation rates
   (e.g., smoking:mortality [mesh] was 68 times more likely to exceed 100
   citations when controlling for other factors); (b) other topics or
   types of practice indicated smaller citation id203 (e.g.,
   splenectomi* and family practice were about 33 and 17 times less likely
   to receive 50 and 100 citations); (c) citation history of first and
   last author played a significant role in citation rates by increasing
   the chances of exceeding 100 and 50 citations by 315 and 23 times when
   comparing the best and worst citation histories; (d) for each
   threshold, different sets of content features were selected (and ranked
   differently in the top positions) which indicates that the importance
   of content changed for different levels of citation impact. on the
   other hand, bibliometric features and impact factor were predictive and
   always had large positive effects for all thresholds studied.

discussion

   our experiments show that article citations can be predicted accurately
   for several distinct levels of citation performance even in a deep time
   horizon and with information strictly available at publication time.

   in constructing the corpus, we hypothesized that information about the
   publication history of first and last author as well as the home
   institution of the first author would be highly predictive for citation
   counts. furthermore, another reason why these analyses were successful
   compared to previous approaches is that newer developments in
   classifier technology allowed the routine use of all content terms in
   article titles, abstracts, and mesh terms without adversely affecting
   predictivity with this high dimensionality. it is important to note
   that the use of content terms limits our method to journals indexed by
   pubmed.

   our modeling is very different from that of lokker [[69]7] both in
   design and results. specifically, we attempted and achieved a
   prediction that spans a longer time horizon. we started with a very
   large predictive feature space and utilized machine learning and
   feature selection algorithms to identify predictive patterns while
   narrowing down the required features. our starting features differed
   substantially since we relied on content and bibliometric information
   whereas [[70]7] used article-specific structural and systematic review
   criteria. the models produced in this work achieved predictivity that
   exceeded the predictivity of [[71]7] by about 0.10 to 0.16 auc
   depending on the model. notably, the reported predictivity of the model
   in [[72]7] of auc 0.76 should be no better (as evidenced in our
   experiments with different feature sets) than a single relatively weak
   variable: the impact factor, which was not used in their models. note
   that one cannot conclusively compare results for the two studies
   because of the differences in chosen journals and time horizons.
   because the two studies were independently conducted during roughly the
   same period,^[73]1 we did not have access to the set of features chosen
   or the corpus used in the study of [[74]7] in order to perform a
   head-to-head comparison with the methods herein. this is clearly an
   area of interesting future research.

   in conclusion, the results of the present work pave the way for
   practical models to predict future citations without requiring
   citations to slowly build over time. such models have the potential to
   render citation counts a more practical tool for evaluating long-term
   impact of recent work and their authors instead of waiting for years as
   is current practice. avoiding excessive reliance on less accurate
   heuristics such as impact factor is another advantage. finally,
   analysis of the relative importance of various input variables for
   citation counts suggests that several factors may causatively influence
   or even bias citation practices, and this is an important direction for
   our future work.

acknowledgments

   the authors thank drs. cindy gadd, nunzia giuse, lily wang, and daniel
   masys for their helpful comments.

footnotes

   ^1r.brian haynes, personal communication, november 2007

references

   1. bornmann l, daniel h. what do citation counts measure? a review of
   studies on citing behavior. journal of documentation. 2007 [[75]google
   scholar]
   2. feitelson d, yovel u. predictive ranking of computer scientists
   using citeseer data. journal of documentation. 2004;60(1):44-61.
   [[76]google scholar]
   3. getoor l. link mining: a new data mining challenge. sigkdd
   explorations. 2003;5(1):84-89. [[77]google scholar]
   4. rattigan m, jensen d. the case for anomalous link discovery. sigkdd
   explorations. 2003;5(1):41-47. [[78]google scholar]
   5. gehrke j, ginsparg p, kleinberg j. overview of the 2003 kdd cup.
   sigkdd explorations. 2003;5(2):149-151. [[79]google scholar]
   6. castillo c, donato d, gionis a. estimating the number of citations
   using author reputation. proceedings of string processing and
   information retrieval (spire) 2007:107-117. [[80]google scholar]
   7. lokker c, mckibbon ka, mckinlay rj, et al. prediction of citation
   counts for clinical articles at two years using data available within
   three weeks of publication: retrospective cohort study. bmj. 2008.
   [81]http://www.bmj.com/cgi/content/abstract/bmj.39482.526713.bev1
   [[82]pmc free article] [[83]pubmed]
   8. isi web of science: thomson scientific
   [84]http://www.isiknowledge.com (accessed mar 2008).
   9. academic ranking of world universities: shanghai jiao tong
   university [85]http://ed.sjtu.edu.cn/anking2006.htm (accessed mar
   2008).
   10. porter m. an algorithm for suffix stripping. program.
   1980;14:130-137. [[86]google scholar]
   11. aphinyanaphongs y, tsamardinos i, statnikov a, et al. text
   categorization models for high-quality article retrieval in internal
   medicine. jamia. 2005;12(2):207-216. [[87]pmc free article]
   [[88]pubmed] [[89]google scholar]
   12. leopold e, kindermann j. text categorization with support vector
   machines. machine learning. 2002;46:423-444. [[90]google scholar]
   13. muller k, mika s, ratsch g, et al. an introduction to kernel-based
   learning algorithms. ieee trans. on neural networks.
   2001;12(2):181-201. [[91]pubmed] [[92]google scholar]
   14. aliferis c, statnikov a, tsamardinos i, et al. local causal and
   markov blanket induction for causal discovery and feature selection for
   classification. submitted to jmlr. 2008 [[93]google scholar]
   15. libid166 -- a library for support vector machines. chang c, lin c.
   [94]http://www.csie.ntu.edu.tw/~cjlin/libid166/ (accessed mar 2008).
   16. aliferis c, statnikov a, tsamardinos i. challenges in the analysis
   of mass-throughput data. cancer informatics. 2006;2:133-162. [[95]pmc
   free article] [[96]pubmed] [[97]google scholar]
     __________________________________________________________________

   articles from amia annual symposium proceedings are provided here
   courtesy of american medical informatics association

formats:

     * article |
     * [98]pubreader |
     * [99]epub (beta) |
     * [100]pdf (142k) |
     * [101]citation

share

     * [102]share on facebook facebook
     * [103]share on twitter twitter
     * [104]share on google plus google+

   [105]support center [106]support center
   external link. please review our [107]privacy policy.
   [108]nlm
   [109]nih
   [110]dhhs
   [111]usa.gov

   [112]national center for biotechnology information, [113]u.s. national
   library of medicine 8600 rockville pike, bethesda md, 20894 usa
   [114]policies and guidelines | [115]contact

   statistics

references

   visible links
   1. https://www.ncbi.nlm.nih.gov/pmc/articles/pmc2656101/epub/
   2. https://www.ncbi.nlm.nih.gov/pmc/articles/pmc2656101/pdf/amia-0222-s2008.pdf
   3. https://www.ncbi.nlm.nih.gov/guide/browsers/#enablejs
   4. https://www.ncbi.nlm.nih.gov/
   5. https://www.ncbi.nlm.nih.gov/pmc/articles/pmc2656101/#maincontent
   6. https://www.ncbi.nlm.nih.gov/pmc/articles/pmc2656101/#navcontent
   7. https://www.ncbi.nlm.nih.gov/static/header_footer_ajax/submenu/#resources
   8. https://www.ncbi.nlm.nih.gov/static/header_footer_ajax/submenu/#howto
   9. https://www.ncbi.nlm.nih.gov/guide/browsers/#accesskeys
  10. https://www.ncbi.nlm.nih.gov/myncbi/
  11. https://www.ncbi.nlm.nih.gov/account/
  12. https://www.ncbi.nlm.nih.gov/account/signout/
  13. https://www.ncbi.nlm.nih.gov/pmc/
  14. https://www.nlm.nih.gov/
  15. https://www.nih.gov/
  16. https://www.ncbi.nlm.nih.gov/pmc/advanced/
  17. https://www.ncbi.nlm.nih.gov/pmc/journals/
  18. https://www.ncbi.nlm.nih.gov/books/nbk3825/
  19. https://www.ncbi.nlm.nih.gov/pmc/journals/
  20. https://www.ncbi.nlm.nih.gov/pmc/journals/362/
  21. https://www.ncbi.nlm.nih.gov/pmc/issues/177327/
  22. lynximgmap:https://www.ncbi.nlm.nih.gov/pmc/articles/pmc2656101/#logo-imagemap
  23. https://www.ncbi.nlm.nih.gov/pubmed/18999029
  24. https://www.ncbi.nlm.nih.gov/pubmed/?term=fu ld[author]&cauthor=true&cauthor_uid=18999029
  25. https://www.ncbi.nlm.nih.gov/pubmed/?term=aliferis c[author]&cauthor=true&cauthor_uid=18999029
  26. https://www.ncbi.nlm.nih.gov/pubmed/?term=fu ld[author]&cauthor=true&cauthor_uid=18999029
  27. https://www.ncbi.nlm.nih.gov/pubmed/?term=aliferis c[author]&cauthor=true&cauthor_uid=18999029
  28. https://www.ncbi.nlm.nih.gov/pmc/articles/pmc2656101/
  29. https://www.ncbi.nlm.nih.gov/pmc/articles/pmc2656101/
  30. https://www.ncbi.nlm.nih.gov/pmc/about/disclaimer/
  31. https://www.ncbi.nlm.nih.gov/pmc/about/copyright/
  32. https://www.ncbi.nlm.nih.gov/pmc/articles/pmc2656101/citedby/
  33. https://www.ncbi.nlm.nih.gov/pmc/articles/pmc2656101/#b1-amia-0222-s2008
  34. https://www.ncbi.nlm.nih.gov/pmc/articles/pmc2656101/#b1-amia-0222-s2008
  35. https://www.ncbi.nlm.nih.gov/pmc/articles/pmc2656101/#b1-amia-0222-s2008
  36. https://www.ncbi.nlm.nih.gov/pmc/articles/pmc2656101/#b2-amia-0222-s2008
  37. https://www.ncbi.nlm.nih.gov/pmc/articles/pmc2656101/#b3-amia-0222-s2008
  38. https://www.ncbi.nlm.nih.gov/pmc/articles/pmc2656101/#b2-amia-0222-s2008
  39. https://www.ncbi.nlm.nih.gov/pmc/articles/pmc2656101/#b3-amia-0222-s2008
  40. https://www.ncbi.nlm.nih.gov/pmc/articles/pmc2656101/#b4-amia-0222-s2008
  41. https://www.ncbi.nlm.nih.gov/pmc/articles/pmc2656101/#b5-amia-0222-s2008
  42. https://www.ncbi.nlm.nih.gov/pmc/articles/pmc2656101/#b6-amia-0222-s2008
  43. https://www.ncbi.nlm.nih.gov/pmc/articles/pmc2656101/#b7-amia-0222-s2008
  44. https://www.ncbi.nlm.nih.gov/pmc/articles/pmc2656101/table/t1-amia-0222-s2008/
  45. https://www.ncbi.nlm.nih.gov/pmc/articles/pmc2656101/#b8-amia-0222-s2008
  46. https://www.ncbi.nlm.nih.gov/pmc/articles/pmc2656101/#b9-amia-0222-s2008
  47. https://www.ncbi.nlm.nih.gov/pmc/articles/pmc2656101/table/t1-amia-0222-s2008/?report=objectonly
  48. http://www.nlm.nih.gov/mesh/
  49. https://www.ncbi.nlm.nih.gov/pmc/articles/pmc2656101/#b8-amia-0222-s2008
  50. http://www.ncbi.nlm.nih.gov/books/bv.fcgi?rid=helppubmed.table.pubmedhelp.t43
  51. https://www.ncbi.nlm.nih.gov/pmc/articles/pmc2656101/#b10-amia-0222-s2008
  52. https://www.ncbi.nlm.nih.gov/pmc/articles/pmc2656101/#b11-amia-0222-s2008
  53. https://www.ncbi.nlm.nih.gov/pmc/articles/pmc2656101/#b12-amia-0222-s2008
  54. https://www.ncbi.nlm.nih.gov/pmc/articles/pmc2656101/#b13-amia-0222-s2008
  55. https://www.ncbi.nlm.nih.gov/pmc/articles/pmc2656101/#b11-amia-0222-s2008
  56. https://www.ncbi.nlm.nih.gov/pmc/articles/pmc2656101/#b12-amia-0222-s2008
  57. https://www.ncbi.nlm.nih.gov/pmc/articles/pmc2656101/table/t1-amia-0222-s2008/
  58. https://www.ncbi.nlm.nih.gov/pmc/articles/pmc2656101/#b14-amia-0222-s2008
  59. https://www.ncbi.nlm.nih.gov/pmc/articles/pmc2656101/#b14-amia-0222-s2008
  60. https://www.ncbi.nlm.nih.gov/pmc/articles/pmc2656101/#b15-amia-0222-s2008
  61. https://www.ncbi.nlm.nih.gov/pmc/articles/pmc2656101/figure/f1-amia-0222-s2008/
  62. https://www.ncbi.nlm.nih.gov/pmc/articles/pmc2656101/figure/f1-amia-0222-s2008/?report=objectonly
  63. https://www.ncbi.nlm.nih.gov/pmc/articles/pmc2656101/figure/f1-amia-0222-s2008/
  64. https://www.ncbi.nlm.nih.gov/pmc/articles/pmc2656101/#b16-amia-0222-s2008
  65. https://www.ncbi.nlm.nih.gov/pmc/articles/pmc2656101/figure/f1-amia-0222-s2008/
  66. https://www.ncbi.nlm.nih.gov/pmc/articles/pmc2656101/figure/f1-amia-0222-s2008/
  67. https://www.ncbi.nlm.nih.gov/pmc/articles/pmc2656101/table/t2-amia-0222-s2008/
  68. https://www.ncbi.nlm.nih.gov/pmc/articles/pmc2656101/table/t2-amia-0222-s2008/?report=objectonly
  69. https://www.ncbi.nlm.nih.gov/pmc/articles/pmc2656101/#b7-amia-0222-s2008
  70. https://www.ncbi.nlm.nih.gov/pmc/articles/pmc2656101/#b7-amia-0222-s2008
  71. https://www.ncbi.nlm.nih.gov/pmc/articles/pmc2656101/#b7-amia-0222-s2008
  72. https://www.ncbi.nlm.nih.gov/pmc/articles/pmc2656101/#b7-amia-0222-s2008
  73. https://www.ncbi.nlm.nih.gov/pmc/articles/pmc2656101/#fn1-amia-0222-s2008
  74. https://www.ncbi.nlm.nih.gov/pmc/articles/pmc2656101/#b7-amia-0222-s2008
  75. https://scholar.google.com/scholar_lookup?journal=journal+of+documentation&title=what+do+citation+counts+measure?+a+review+of+studies+on+citing+behavior&author=l+bornmann&author=h+daniel&publication_year=2007&
  76. https://scholar.google.com/scholar_lookup?journal=journal+of+documentation&title=predictive+ranking+of+computer+scientists+using+citeseer+data&author=d+feitelson&author=u+yovel&volume=60&issue=1&publication_year=2004&pages=44-61&
  77. https://scholar.google.com/scholar_lookup?journal=sigkdd+explorations&title=link+mining:+a+new+data+mining+challenge&author=l+getoor&volume=5&issue=1&publication_year=2003&pages=84-89&
  78. https://scholar.google.com/scholar_lookup?journal=sigkdd+explorations&title=the+case+for+anomalous+link+discovery&author=m+rattigan&author=d+jensen&volume=5&issue=1&publication_year=2003&pages=41-47&
  79. https://scholar.google.com/scholar_lookup?journal=sigkdd+explorations&title=overview+of+the+2003+kdd+cup&author=j+gehrke&author=p+ginsparg&author=j+kleinberg&volume=5&issue=2&publication_year=2003&pages=149-151&
  80. https://scholar.google.com/scholar_lookup?journal=proceedings+of+string+processing+and+information+retrieval+(spire)&title=estimating+the+number+of+citations+using+author+reputation&author=c+castillo&author=d+donato&author=a+gionis&publication_year=2007&pages=107-117&
  81. http://www.bmj.com/cgi/content/abstract/bmj.39482.526713.bev1
  82. https://www.ncbi.nlm.nih.gov/pmc/articles/pmc2270947/
  83. https://www.ncbi.nlm.nih.gov/pubmed/18292132
  84. http://www.isiknowledge.com/
  85. http://ed.sjtu.edu.cn/anking2006.htm
  86. https://scholar.google.com/scholar_lookup?journal=program&title=an+algorithm+for+suffix+stripping&author=m+porter&volume=14&publication_year=1980&pages=130-137&
  87. https://www.ncbi.nlm.nih.gov/pmc/articles/pmc551552/
  88. https://www.ncbi.nlm.nih.gov/pubmed/15561789
  89. https://scholar.google.com/scholar_lookup?journal=jamia&title=text+categorization+models+for+high-quality+article+retrieval+in+internal+medicine&author=y+aphinyanaphongs&author=i+tsamardinos&author=a+statnikov&volume=12&issue=2&publication_year=2005&pages=207-216&pmid=15561789&
  90. https://scholar.google.com/scholar_lookup?journal=machine+learning&title=text+categorization+with+support+vector+machines&author=e+leopold&author=j+kindermann&volume=46&publication_year=2002&pages=423-444&
  91. https://www.ncbi.nlm.nih.gov/pubmed/18244377
  92. https://scholar.google.com/scholar_lookup?journal=ieee+trans.+on+neural+networks&title=an+introduction+to+kernel-based+learning+algorithms&author=k+muller&author=s+mika&author=g+ratsch&volume=12&issue=2&publication_year=2001&pages=181-201&
  93. https://scholar.google.com/scholar_lookup?journal=submitted+to+jmlr&title=local+causal+and+markov+blanket+induction+for+causal+discovery+and+feature+selection+for+classification&author=c+aliferis&author=a+statnikov&author=i+tsamardinos&publication_year=2008&
  94. http://www.csie.ntu.edu.tw/~cjlin/libid166/
  95. https://www.ncbi.nlm.nih.gov/pmc/articles/pmc2675497/
  96. https://www.ncbi.nlm.nih.gov/pubmed/19458765
  97. https://scholar.google.com/scholar_lookup?journal=cancer+informatics&title=challenges+in+the+analysis+of+mass-throughput+data&author=c+aliferis&author=a+statnikov&author=i+tsamardinos&volume=2&publication_year=2006&pages=133-162&pmid=19458765&
  98. https://www.ncbi.nlm.nih.gov/pmc/articles/pmc2656101/?report=reader
  99. https://www.ncbi.nlm.nih.gov/pmc/articles/pmc2656101/epub/
 100. https://www.ncbi.nlm.nih.gov/pmc/articles/pmc2656101/pdf/amia-0222-s2008.pdf
 101. https://www.ncbi.nlm.nih.gov/pmc/articles/pmc2656101/
 102. https://www.facebook.com/sharer/sharer.php?u=https://www.ncbi.nlm.nih.gov/pmc/articles/pmc2656101/
 103. https://twitter.com/intent/tweet?url=https://www.ncbi.nlm.nih.gov/pmc/articles/pmc2656101/&text=models for predicting and explaining citation count of biomedical articles
 104. https://plus.google.com/share?url=https://www.ncbi.nlm.nih.gov/pmc/articles/pmc2656101/
 105. https://www.ncbi.nlm.nih.gov/pmc/articles/pmc2656101/
 106. https://support.ncbi.nlm.nih.gov/ics/support/kblist.asp?time=2019-04-05t16:14:51-04:00&snapshot=/projects/pmc/pmcviewer@4.46&host=portal106&ncbi_phid=ce8de3abca7b43d10000000002450167&ncbi_session=ce8de3abca7b73a1_0581sid&from=https://www.ncbi.nlm.nih.gov/pmc/articles/pmc2656101/&db=pmc&folderid=132&ncbi_app=pmc&page=literature&style=classic&deptid=28049
 107. https://www.nlm.nih.gov/privacy.html
 108. https://www.nlm.nih.gov/
 109. https://www.nih.gov/
 110. https://www.hhs.gov/
 111. https://www.usa.gov/
 112. https://www.ncbi.nlm.nih.gov/
 113. https://www.nlm.nih.gov/
 114. https://www.ncbi.nlm.nih.gov/home/about/policies.shtml
 115. https://www.ncbi.nlm.nih.gov/home/about/contact.shtml

   hidden links:
 117. https://www.ncbi.nlm.nih.gov/account/settings/
 118. https://www.ncbi.nlm.nih.gov/pmc/articles/pmc2656101/figure/f1-amia-0222-s2008/
 119. https://www.ncbi.nlm.nih.gov/core/lw/2.0/html/tileshop_pmc/tileshop_pmc_inline.html?title=click%20on%20image%20to%20zoom&p=pmc3&id=2656101_amia-0222-s2008f1.jpg

[usemap]
https://www.ncbi.nlm.nih.gov/pmc/articles/pmc2656101/#logo-imagemap
   1. http://proceedings.amia.org/
