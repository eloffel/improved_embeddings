learning to search for dependencies

kai-wei chang1, he he2, hal daum  e iii2, john langford3

1 university of illinois urbana-champaign, il

2 university of maryland, college park, md

kchang10@illinois.edu
{hhe,hal}@cs.umd.edu

3 john langford microsoft research, new york, ny

5
1
0
2

 

y
a
m
7

 

 
 
]
l
c
.
s
c
[
 
 

2
v
5
1
6
5
0

.

3
0
5
1
:
v
i
x
r
a

jcl@microsoft.com

abstract

we demonstrate that a dependency parser
can be built using a credit assignment
compiler which removes the burden of
worrying about low-level machine learn-
ing details from the parser implemen-
tation. the result
is a simple parser
which robustly applies to many languages
that provides similar statistical and com-
putational performance with best-to-date
transition-based parsing approaches, while
avoiding various downsides including ran-
domization, extra feature requirements,
and custom learning algorithms.
introduction

1
transition-based dependency parsers have a long
history, in which many aspects of their construc-
tion have been studied: transition systems (nivre,
2003; nivre, 2004), feature engineering (koo et
al., 2008), neural-network predictors (chen and
manning, 2014) and the importance of training
against a    dynamic oracle    (kuhlmann et al.,
2011; goldberg and nivre, 2013). in this paper we
focus on an understudied aspect of building depen-
dency parsers: the role of getting the underlying
machine learning technology    right   . in contrast
to previous approaches which use heuristic learn-
ing strategies, we demonstrate that we can easily
build a highly robust dependency parser with a
   compiler    that automatically translates a simple
speci   cation of id33 and labeled
data into machine learning updates.

an issue with complex prediction problems is
credit assignment: when something goes wrong
do you blame the    rst, second, or third prediction?
existing systems commonly take two strategies:

1. the system may ignore the possibility that a
previous prediction may have been wrong. or
ignore that different errors may have differ-
ent costs (consequences). or that train-time

prediction may differ from the test-time pre-
diction. these and other issues lead to sta-
tistical inconsistency: when features are not
rich enough for perfect prediction the ma-
chine learning may converge suboptimally.

2. the system may use hand crafted credit-
assignment heuristics to cope with errors the
underlying algorithm makes and the long-
term outcomes of decisions.

here, we show instead that a learning to search
(daum  e iii et al., 2014) can automati-
compiler
cally handle credit assignment using known tech-
niques (daum  e iii et al., 2009; ross et al., 2011;
ross and bagnell, 2014; chang et al., 2015) when
applied to id33. dependency pars-
ing is more complex than previous applications of
the compiler and may also be of interest for other
similarly complex nlp problems as it frees de-
signers to worry about concerns other than low-
level machine learning.

the advantage here is the combination of cor-

rectness and simplicity via removal of concerns:

1. the system automatically employs a cost
sensitive learning algorithm instead of a
multiclass learning algorithm, ensuring the
model learns to avoid compounding errors.

2. the system automatically    rolls in    with the
learned policy and    rolls out    the dynamic or-
acle insuring competition with the oracle.

3. advanced machine learning techniques or
optimization strategies are enabled with
command-line    ags with no additional imple-
mentation overhead, such as neural networks
or    fancy    online learning.

4. the implementation is future-friendly: future

compilers may yield a better parser.

5. train/test asynchrony bugs are removed. es-
sentially, you only write the test-time    de-
coder    and the oracle.

6. the implementation is simple: this one is

about 300 lines of c++ code.

algorithm 1 runtagger(words)
1: output     []
2: for n = 1 to len(words) do
ref     words[n].true label
3:
output[n]     predict(words[i], ref, output[:n-1])
4:
5: end for
6: loss(# output[n] (cid:54)= words[n].true label)
7: return output

experiments on standard english penn tree-
bank and nine other languages from conll-x
show that the compiled parser is competitive with
recent published results (e.g., an average labeled
accuracy of 81.7 over 10 languages, versus 80.3
for (goldberg and nivre, 2013)).

altogether, this system provides a strong simple
baseline for future research on dependency pars-
ing, and demonstrates that the compiler approach
to solving complex prediction problems may be of
broader interest.

2 learning to search

learning to search is a family of approaches for
solving id170 tasks. this family in-
cludes a number of speci   c algorithms including
the incremental structured id88 (collins and
roark, 2004; huang et al., 2012), searn (daum  e
iii et al., 2009), dagger (ross et al., 2011),
aggrevate (ross and bagnell, 2014), and oth-
ers (daum  e iii and marcu, 2005; xu and fern,
2007; xu et al., 2007; ratliff et al., 2007; syed and
schapire, 2011; doppa et al., 2012; doppa et al.,
2014). learning to search approaches solve struc-
tured prediction problems by (1) decomposing the
production of the structured output in terms of an
explicit search space (states, actions, etc.); and (2)
learning hypotheses that control a policy that takes
actions in this search space.

in this work we build on recent theoretical and
implementational advances in learning to search
that make development of novel structured predic-
tion frameworks easy and ef   cient using    imper-
ative learning to search    (daum  e iii et al., 2014).
in this framework, an application developer needs
to write (a) a    decoder    for the target structured
prediction task (e.g., id33), (b) an
annotation in the decoder that computes losses on
the training data, and (c) a reference policy on the
training data that returns at any prediction point
a    suggestion    as to a good action to take at that
state1.

1some papers in the past make an implicit or explicit as-

figure 1: a search space implicitly de   ned by an
imperative program. the system begins at the start
state s and chooses the middle among three ac-
tions by the rollin policy twice. at state r it con-
siders both the chosen action (middle) and both
one-step deviations from that action (top and bot-
tom). each of these deviations is completed using
the rollout policy until an end state is reached, at
which point the loss is collected. here, we learn
that deviating to the top action (instead of middle)
at state r decreases the loss by 0.2.

algorithm 1 shows the code one must write for
a part of speech tagger (or generic sequence la-
beler) under hamming loss. the only annotation
in this code aside from the calls to the library func-
tion predict are the computation of an reference
(an oracle reference is trivial under hamming loss)
and the computation of the total sequence loss at
the end of the function. note that in this example,
the prediction of the tag for the nth word depends
explicitly on the predictions of all previous words!
the machine learning question that arises is
how to learn a good predict function given
just this information. the    imperative learning to
search    answer (daum  e iii et al., 2014) is es-
sentially to run the runtagger function many
times,    trying out    different versions of predict
in order to learn one that yields low loss. the
challenge is how to do this ef   ciently. the general
strategy is, for some number of epochs, and for
each example (x, y) in the training data, to do the

sumption that this reference policy is an oracle policy: for ev-
ery state, it always chooses the best action (assuming it gets
to make all future decisions as well).

sreeerollinrollout  one-stepdeviationsloss=.2loss=0loss=.8following:

2. many times:

1. execute runtagger on x with some rollin
policy to obtain a search trajectory (sequence
of action a) and loss (cid:96)0
(a) choose some time step t     |a|
t (cid:54)= at
(b) choose an alternative action a(cid:48)
(c) execute runtagger on x, with pre-
dict return a1:t   1 initially, then a(cid:48)
t, then
acting according to a rollout policy to ob-
tain a new loss (cid:96)t,a(cid:48)

t

(d) compare the overall losses (cid:96)0 and (cid:96)t,a(cid:48)
to construct a classi   cation/regression
example that demonstrates how much
better or worse a(cid:48)
t is than at in this con-
text

t

3. update the learned policy
figure 1 shows a schematic of the search space
implicitly de   ned by an imperative program. by
executing this program three times (in this exam-
ple), we are able to explore three different trajec-
tories and compute their losses. these trajectories
are de   ned by the rollin policy (what determines
the initial trajectory), the position of one-step devi-
ations (here, state r), and the rollout policy (which
completes the trajectory after a deviation).

by varying the rollin policy, the rollout pol-
icy and the manner in which classi   cation/regres-
sion examples are created, this general frame-
work can mimic algorithms like searn, dag-
ger and aggrevate. for instance, dagger
uses rollin=learned policy2 and rollout=reference,
while searn uses rollin=rollout=stochastic mix-
ture of learned and reference policies.

3 id33 by learning to

search

learning to search provides a natural framework
for implementing a transition-based dependency
parser. a transition-based dependency parser takes
a sequence of actions and parses a sentence from
left to right by maintaining a stack s, a buffer b,
and a set of dependency arcs a. the stack main-
tains partial parses, the buffer stores the words to
be parsed, and a keeps the arcs that have been
generated so far. the con   guration of the parser
at each stage can be de   ned by a triple (s, b, a).
for the ease of notation, we use wp to represent the

2technically, dagger rolls in with a mixture which is al-
most always instantiated to be    reference    for the    rst epoch
and    learned    for subsequent epochs.

algorithm 2 trans(s, b, a, action)
1: let wp be the leftmost element in b
2: if action = shift then
3:
4:
5: else if action= reduce-left then
6:
7:
8: else if action = reduce-right then
9:
10:
11: end if
12: return s, b, a

s.push(wp)
remove wp from b
top     s.pop()
a     a    (wp,top)
top     s.pop()
a     a    (s.top(), top)

leftmost word in the buffer and use s1 and s2 to de-
note the top and the second top words in the stack.
a dependency arc (wh, wm) is a directed edge that
indicates word wh is the parent of word wm. when
the parser terminates, the arcs in a form a projec-
tive dependency tree. we assume that each word
only has one parent in the derived dependency
parse tree, and use a[wm] to denote the parent of
word wm. for labeled id33, we fur-
ther assign a tag to each arc representing the de-
pendency type between the head and the modi   er.
for simplicity, we assume an unlabeled parser in
the following description. the extension from an
unlabeled parser to a labeled parser is straightfor-
ward, and is discussed at the end of this section.

we consider an arc-hybrid transition sys-
tem (kuhlmann et al., 2011)3. in the initial con-
   guration, the buffer b contains all the words in
the sentence, a dummy root node is pushed in the
stack s, and the set of arcs a is empty. the root
node cannot be popped out at anytime during pars-
ing. the system then takes a sequence of actions
until the buffer is empty and the stack contains
only the root node (i.e., |b| = 0 and s = {root}).
when the process terminates, a parse tree is de-
rived. at each state, the system can take one of the
following actions:

1. shift: push wp to s and move p to the next

word. (valid when |b| > 0).

2. reduce-left: add an arc (wp, s1) to a and

pop s1. (valid when |b| > 0 and |s| > 1).

3. reduce-right: add an arc (s2, s1) to a and

pop s1. (valid when |s| > 1).

3the learning to search framework is also suitable for
other transition-based id33 systems, such as
arc-eager (nivre, 2003) or arc-standard (nivre, 2004) transi-
tion systems.

action

shift
reduce-left
shift
reduce-left
shift
shift
shift
reduce-right
reduce-right
reduce-right

[root flying] [planes can be dangerous]
[root] [planes can be dangerous]

con   guration
stack buffer
arcs
[root] [flying planes can be dangerous] {}
{}
{(planes, flying)}
{(planes, flying)}
{(planes, flying), (can, planes)}
{(planes, flying), (can, planes)}
{(planes, flying), (can, planes)}
{(planes, flying), (can, planes)}
{(planes, flying), (can, planes), (be, dangerous)}
{(planes, flying), (can, planes), (be, dangerous), (can, be)}
{(planes, flying), (can, planes), (be, dangerous), (can, be), (root, can)}

[root planes] [can be dangerous]
[root] [can be dangerous]

[root can] [be dangerous]

[root can be] [dangerous]

[root can be dangerous] []
[root can be] []
[root can] []
[root] []

root

flying

planes

can

be

dangerous

root

flying

parse tree derived by the above parser

can

planes
gold parse tree

be

dangerous

figure 2: an illustrative example of an arc-hybrid transition parser. the above table show the actions
taken and the intermediate con   gurations generated by a parser. the parse tree derived by the parser is
in the bottom left, and the gold parse tree is the bottom right. the distance between these two trees is 2.

algorithm 3 runparser(sentence)
1: stack s     {root}
2: buffer b     [words in sentence]
3: arcs a        
4: while b (cid:54)=     or |s| > 1 do

validacts     getvalidactions(s, b)
5:
features     getfeat(s, b, a)
6:
ref     getgoldaction(s, b)
7:
action     predict(features, ref, validacts)
8:
s, b, a     trans(s, b, a, action)
9:
10: end while
11: loss(a[w] (cid:54)= a   [w],    w     sentence)
12: return output

algorithm 2 shows the execution of these actions
during parsing, and figure 2 demonstrates an ex-
ample of transition-based id33.

we can de   ne a search space for dependency
parser such that each state represents one con   g-
uration during the parsing. the start state is asso-
ciated with the initial con   guration, and the end
states are associated with the con   gurations that
|b| = 0 and s = {root}. the loss of each end
state is de   ned by the distance between the derived
parse tree and the gold parse tree. the above tran-
sition actions de   ne how to move from one search
state to the other. in the following, we describe our
implementation details.
implementation as mentioned in section 2, to
implement a parser using the learning to search
framework, we need to provide a decoder, a loss
function and reference policy. thanks to recent
work (goldberg and nivre, 2013), we know how
to compute a    dynamic oracle    reference policy
that is optimal. the loss can be measured by how

many parents are different between the derived
parse tree and the gold annotated parse tree. al-
gorithm 3 shows the pseudo-code of a decoder for
a unlabeled dependency parser. we discuss each
subcomponent below.

    getvalidaction returns a set of valid ac-
tions that can be taken based on the current
con   guration.

    getfeat extracts features based on the cur-
rent con   guration. the features depend on
the top few words in the stack and leftmost
few words in the buffer as well as their as-
sociated part-of-speech tags. we list our fea-
ture templates in table 1. all features are
generated dynamically because con   guration
changes during parsing.

    getgoldaction implements the dynamic
oracle described in (goldberg and nivre,
2013). the dynamic oracle returns the opti-
mal action in any state that leads to the reach-
able end state with the minimal loss.

    predict is a library call implemented in
the learning to search system. given training
samples, the learning to search system can
learn the policy automatically. therefore, in
the test phase, this function returns the pre-
dicted action leading to an end state with
small structured loss.

    trans function implements the hybrid-arc
transition system. based on the predicted ac-

tion and labels, it updates the parser   s con   g-
uration, and move the agent to the next search
state.

    id168 is used to measure the dis-
tance between the predicted output and the
gold annotation. here, we simply used the
number of words for which the parent is
wrong as the loss. the loss has no effect in
the test phase.

the above decoder implements an unlabeled
parser. to build a labeled parser, when the transi-
tion action is reduce-left or reduce-right,
we call the predict function again to predict
the dependency type of the arc. the loss in the
labled dependnecy parser can be measured by

(cid:80)

loss(wi), where

wi

               2 a[wi] (cid:54)= a   [wi]

1 a[wi] = a   [wi], l[wi] (cid:54)= l   [wi]
0 otherwise.

loss(wi) =

(1)
a[wi] and a   [wi] are the parent of wi in the de-
rived parse tree and gold parse tree, respectively,
l[wi] is the label assign to the arc (a[wi], wi).
we observe that this simple id168 performs
well empirically.

we implemented our parser based on an open-
source library supporting learning to search. the
implementation requires about 300 lines of c++
code. the reduction of implementation effort
comes from two-folds. first, in the learning to
search framework, there is no need to implement
a learning algorithm. once the decoding function
is de   ned, the system is able to learn the best
   predict    function from training data. second,
l2s provides a uni   ed framework, which allows
the library to serve common functions for ease of
implementation. for example, quadratic and cubic
feature generating functions and a feature hashing
mechanism are provided by the library. the uni-
   ed framework also allows a user to experiment
with different base learners and hyper-parameters
using command line arguments without modifying
the code.
base learner as mentioned in section 2, the
learning to search framework reduces structured
prediction to cost-sensitive multi-class classi   ca-
tion, which can be further reduced to regression.
this reduction framework allows us to employ

unigram features
s1, s2, s3, b1, b2, b3, l1(s1), l2(s1),
r1(s1), r1(s2), l1(b1), l2(b1), l1(s2)
bigram features
s1s1, s2s2, s3s3, b1b1, b2b2, b3b3, s1b1,
s1s2, b1b2
trigram features
s1s2s3 , s1b1b2, s1s2b1, s1b1b3,
b1b2b3 , s1r1(s1)r1(s2), s1l2(s1)l2(b1),
b1l1(b1)l2(b1), s1s2l1(b1), s1b1l1(s1),
s1b1l1(s2), s1b1l1(b1)

table 1: features used in our id33
system. si represents the i-th top element in the
stack s. bi is the i-th leftmost word in the buffer
b. li(w) and ri(w) are the i-th leftmost child and
rightmost child of the word w. for each feature
template, we includes the surface string and the as-
sociated part-of-speech (pos) tag as features. for
ri(w) and li(w), we also include arc labels as
features. a feature hashing technique (weinberger
et al., 2009) is employed to provide a fast feature
lookup.

parser
l2s
dyna
snn

transition
arc-hybrid
arc-hybrid
arc-standard

base learner reference
dynamic
dynamic

id88

nn

nn

static

table 2: parser settings.

well-studied binary and multi-class classi   cation
methods as the base learner. we analyze the value
of using more powerful base learners in the exper-
iment section.

4 experimental results

while most work compares with maltparser or
mstparser, which are indeed weak baselines, we
compare with two recent strong baselines: the
greedy transition-based parser with dynamic or-
acle (goldberg and nivre, 2013) and the stan-
ford neural network parser (chen and manning,
2014). we evaluate on a wide range of different
languages, and show that our parser achieves com-
parable or better results on all languages, with sig-
ni   cantly less engineering.

parser

ar

bu

ch

da

du

en

ja

po

sl

sw

avg

l2s
dyna
snn

77.59
77.89
67.37   

90.64
89.54
88.05

90.46
89.41
87.31

88.03
87.37
82.98

78.06
74.63
75.34

92.30
91.84
90.20

90.89
92.72
89.45

89.77
85.82
83.19   

81.28
77.14
63.60   

89.12
87.85
85.70

86.81
85.42
81.32   

uas

l2s
dyna
snn

66.44
66.33
51.72   

85.07
84.73
84.01

86.43
85.14
82.72

81.36
82.30
77.44

73.55
70.26
71.96

91.09
90.81
89.10

89.53
90.91
87.37

84.68
82.00
77.88   

72.48
68.65
51.08   

82.81
82.21
80.09

81.34
80.33
75.34   

las

table 3: uas and las on ptb and conll-x. the average score over all languages is shown in the
last column. the best scores for each language is bolded. snn makes assumptions about the structure of
languages and hence obtains substantially worse performance on languages with multi-root trees (marked
with    ). excluding these languages, snn achieves 85.6 (uas) and 81.8 (las) in average, while l2s
achieves 88.5 and 84.3.

4.1 datasets
we conduct experiments on the english penn
treebank (ptb) (marcus et al., 1993) and the
conll-x (buchholz and marsi, 2006) datasets
for 9 other languages,
including arabic, bul-
garian, chinese, danish, dutch, japanese, por-
tuguese, slovene and swedish. for ptb, we con-
vert the constituency trees to dependencies by the
head rules of yamada and matsumoto (2006). we
follow the standard split: sections 2 to 21 for train-
ing, section 22 for development and section 23
for testing. the pos tags in the evaluation data is
assigned by the stanford pos tagger (toutanova
et al., 2003), which has an accuracy of 97.2% on
the ptb test set. for conll-x, we use the given
train/test splits and reserve the last 10% of train-
ing data for development if needed. the gold pos
tags given in the conll-x datasets are used.

4.2 setup and parameters
for l2s, the rollin policy is a mixture of the
current (learned) policy and the reference (dy-
namic oracle) policy. the id203 of executing
the reference policy decreases over each round.
speci   cally, we set it to be 1     (1       )t, where
t is the number of rounds and    is set to 10   5 in
all experiments. it has been shown (ross and bag-
nell, 2014; chang et al., 2015) that when the ref-
erence policy is optimal, it is preferable to roll out
with the reference. therefore, we roll out with the
dynamic oracle (goldberg and nivre, 2013).

our base learner is a simple neural network with
one hidden layer. the hidden layer size is 5 and

we do not use word or pos tag embeddings. we
   nd the follow-the-regularized-leader-proximal
(ftrl) online learning algorithm particularly ef-
fective with learning the neural network and sim-
ply use default hyperparameters.

we compare with the recent transition-based
parser with dynamic oracles (dyna) (goldberg
and nivre, 2013), and the stanford neural network
parser (snn) (chen and manning, 2014). settings
of the three parsers are shown in table 2.

for dyna, we use the software provided by
the authors online4. our initial experiments show
that its performance is the best using the arc hy-
brid system with exploration parameters k = 1,
p = 1, thus we use this setting for all experiments.
the best model evaluated on the development set
among 5 runs with different random seeds are cho-
sen for testing.

for snn, we use the latest stanford parser.5
since all other parsers do not use external re-
sources, we do not provide pretrained word em-
beddings and initialize randomly. we use the same
parameter values as suggested in (chen and man-
ning, 2014), which are also the default settings of
the software. the best model over 20000 iterations
evaluated on the development set is used for test-
ing.6

in addition, we compare with the redshift7

4available at https://bitbucket.org/yoavgo/

tacl2013dynamicoracles

5available

at

http://nlp.stanford.edu/

software/nndep.shtml

6enabled by -saveintermediate.
7available at https://github.com/syllog1sm/

base leaner

sgd
sgd+
nn
nn+ftrl
multiclass

dev

test

uas
89.34
91.0
92.02
92.27
91.7

las uas
89.34
88.03
91.0
89.5
90.78
91.97
92.30
91.04
90.6
91.3

las
87.89
89.6
90.84
91.09
90.2

table 4: performance of different base learning al-
gorithms with the l2s parser on ptb corpus.

parser on ptb. for fair comparison, we only use
its basic features (excluding features based on the
brown cluster). we use the default parameters,
which runs a id125 with width 8. in our ex-
periments, the redshift parser has uas 92.10 and
las 90.83 on the ptb test set.

4.3 results
we report unlabeled attachment scores (uas) and
labeled attachment scores (las) in table 3. punc-
tuation is excluded in all evaluations. our parser
achieves up to 4% improvement on both uas and
las. compared with dyna, our parser has the
same transition system and oracle but more pow-
erful base learners to choose from. compared with
snn, we use much fewer hidden units and param-
eters to tune.
the value of strong base learners. l2s allows
us to leverage well studied classi   cation meth-
ods. we show the performance when training with
base learners using the following update rules. un-
less stated otherwise all the base learners are cost-
sensitive multiclass classi   ers.

1. sgd: stochastic id119 updates.
2. sgd+: improved update rule using an adap-
tive metric (duchi et al., 2011; mcmahan
and streeter, 2010), importance invariant up-
dates (karampatziakis and langford, 2011),
and normalized updates (ross et al., 2013).

3. nn: a single-hidden-layer neural network

with 5 hidden nodes.

4. nn + ftrl: a neural network learner with
follow-the-regularized-leader
id173
(the base learner in the above experiments).
5. multiclass: a multiclass classi   er using
nn+ftrl update rules. the gold label is
given by the dynamic oracle.

the results in table 4 show that using a strong

redshift

base leaner

uas
uni-gram
80.41
uni- + bi-gram 90.73
all features
92.27

dev

test

las uas
80.97
78.01
91.08
89.46
91.04
92.30

las
78.65
89.81
91.09

table 5: the contribution of bi-gram and tri-gram
features. results are evaluated on the dev and the
test set of ptb.

base learner and taking care of low-level learning
details (i.e., using cost-sensitive multiclass classi-
   er) can improve the performance.

finally, figure 5 shows the performance of dif-
ferent feature templates. using a comprehensive
set of features leads to a better dependency parser.

5 related work

training a transition-based dependency parser can
be viewed as an imitation learning problem. how-
ever, most early works focus on decoding or fea-
ture engineering instead of the core learning al-
gorithm. for a long time, averaged id88 is
the default learner for id33. gold-
berg and nivre (2013)    rst proposed dynamic or-
acles under the framework of imitation learning.
their approach is essentially a special case of our
algorithm: the base learner is a multi-class percep-
tron, and no rollout is executed to assign cost to
actions. in this work, we combine dynamic ora-
cles into learning and explore the search space in
a more principled way by learning to search: by
cost-sensitive classi   cation, we evaluate the end
result of each non-optimal action instead of treat-
ing them as equally bad.

there are a number of works that use the
l2s approach to solve various other structured
prediction problems, for example, sequence la-
beling (doppa et al., 2014), coreference resolu-
tion (ma et al., 204), graph-based dependency
parsing (he et al., 2013). however, these works
can be considered as a special setting under our
uni   ed learning framework, e.g., with a custom
action set or different rollin/rollout methods.

to our knowledge, this is the    rst work that
develops a general programming interface for de-
pendency parsing, or more broadly, for structured
prediction. our system bears some resemblance
to probabilistic programming language (e.g., (mc-
callum et al., 2009; gordon et al., 2014)), how-

ever, instead of relying on a new programming lan-
guage, ours is implemented in c++ and python,
thus is easily accessible.
6 conclusion and discussion
we have described a simple transition-based de-
pendency parser based on the learning to search
framework. we show that it is now much eas-
ier to implement a high-performance dependency
parser. furthermore, we provide a wide range of
advanced optimization methods to choose from
during training. experimental results show that we
consistently achieve better performance across 10
languages. an interesting direction for future work
is to extend the current system beyond greedy
search. in addition, there is a large room for speed-
ing up training time by smartly choosing where to
rollout.

references
sabine buchholz and erwin marsi. 2006. conll-x
shared task on multilingual id33. in
proceedings of the tenth conference on computa-
tional natural language learning, pages 149   164.
association for computational linguistics.

kai-wei chang, akshay krishnamurthy, alekh agar-
2015.
teacher.

wal, hal daum  e iii, and john langford.
learning to search better
than your
arxiv:1502.02206.

danqi chen and christopher manning. 2014. a fast
and accurate dependency parser using neural net-
in proceedings of the conference on em-
works.
pirical methods in natural language processing
(emnlp), pages 740   750.

michael collins and brian roark. 2004. incremental
parsing with the id88 algorithm. in proceed-
ings of the conference of the association for com-
putational linguistics (acl).

hal daum  e iii and daniel marcu. 2005. learning
as search optimization: approximate large margin
in proceedings
methods for id170.
of the international conference on machine learn-
ing (icml).

hal daum  e iii, john langford, and daniel marcu.
2009. search-based id170. machine
learning journal.

hal daum  e iii, john langford, and st  ephane ross.
2014. ef   cient programmable learning to search.
arxiv:1406.1837.

janardhan rao doppa, alan fern, and prasad tade-
palli. 2014. hc-search: a learning framework for
search-based id170. journal of arti-
   cial intelligence research (jair), 50.

john c. duchi, elad hazan, and yoram singer. 2011.
adaptive subgradient methods for online learning
journal of machine
and stochastic optimization.
learning research, 12:2121   2159.

yoav goldberg and joakim nivre. 2013. training
deterministic parsers with non-deterministic oracles.
transactions of the acl, 1.

andrew d. gordon, thomas a. henzinger, aditya v.
nori, and sriram k. rajamani. 2014. probabilistic
in proceedings of the on future of
programming.
software engineering.

he he, hal daum  e iii, and jason eisner. 2013. dy-
namic feature selection for id33. in
proceedings of the conference on empirical meth-
ods in natural language processing (emnlp).

liang huang, suphan fayong, and yang guo. 2012.
structured id88 with inexact search. in pro-
ceedings of the conference of the north american
chapter of the association for computational lin-
guistics (naacl).

nikos karampatziakis and john langford. 2011. on-
line importance weight aware updates. in uai 2011,
proceedings of the twenty-seventh conference on
uncertainty in arti   cial intelligence, barcelona,
spain, july 14-17, 2011, pages 392   399.

terry koo, xavier carreras, and michael collins.
2008. simple semi-supervised id33.
in proceedings of the conference of the association
for computational linguistics (acl).

marco kuhlmann, carlos g  omez-rodr    guez, and gior-
gio satta. 2011. id145 algorithms
in pro-
for transition-based dependency parsers.
ceedings of the 49th annual meeting of the asso-
ciation for computational linguistics: human lan-
guage technologies-volume 1, pages 673   682. as-
sociation for computational linguistics.

chao ma, janardhan rao doppa, j walker orr,
prashanth mannem, xiaoli fern, tom dietterich,
and prasad tadepalli. 204. prune-and-score: learn-
ing for greedy coreference resolution. in proceed-
ings of the conference on empirical methods in nat-
ural language processing (emnlp).

m.p. marcus, m.a. marcinkiewicz, and b. santorini.
1993. building a large annotated corpus of en-
glish: the id32. computational linguis-
tics, 19(2):330.

janardhan rao doppa, alan fern, and prasad tade-
palli. 2012. output space search for structured pre-
diction. in proceedings of the international confer-
ence on machine learning (icml).

andrew mccallum, karl schultz, and sameer singh.
2009. factorie: probabilistic programming via im-
in advances in
peratively de   ned factor graphs.
neural information processing systems (nips).

h. brendan mcmahan and matthew j. streeter. 2010.
adaptive bound optimization for online convex op-
timization. in colt 2010 - the 23rd conference on
learning theory, haifa, israel, june 27-29, 2010,
pages 244   256.

joakim nivre. 2003. an ef   cient algorithm for projec-
tive id33. in international workshop
on parsing technologies (iwpt), pages 149   160.

joakim nivre. 2004.

incrementality in deterministic
in proceedings of the work-
id33.
shop on incremental parsing: bringing engineering
and cognition together.

nathan ratliff, david bradley, j. andrew bagnell, and
joel chestnutt. 2007. boosting structured predic-
in advances in neural
tion for imitation learning.
information processing systems (nips).

st  ephane ross and j. andrew bagnell. 2014. rein-
forcement and imitation learning via interactive no-
regret learning. arxiv:1406.5979.

st  ephane ross, geoff j. gordon, and j. andrew bag-
nell. 2011. a reduction of imitation learning and
id170 to no-regret online learning. in
proceedings of the workshop on arti   cial intelli-
gence and statistics (ai-stats).

st  ephane ross, paul mineiro, and john langford.
2013. normalized online learning. in proceedings
of the twenty-ninth conference on uncertainty in
arti   cial intelligence, bellevue, wa, usa, august
11-15, 2013.

umar syed and robert e. schapire. 2011. a reduc-
tion from apprenticeship learning to classi   cation.
in advances in neural information processing sys-
tems (nips).

kristina toutanova, dan klein, christopher d. man-
ning, and yoram singer. 2003. feature-rich part-of-
speech tagging with a cyclic dependency network.
in proceedings of the conference of the north amer-
ican chapter of the association for computational
linguistics (naacl).

kilian weinberger, anirban dasbupta, john langford,
alex smola, and josh attenberg. 2009. feature
hashing for large scale multitask learning. in pro-
ceedings of the international conference on ma-
chine learning (icml).

yuehua xu and alan fern. 2007. on learning linear
ranking functions for id125. in icml, pages
1047   1054.

yuehua xu, alan fern, and sung wook yoon. 2007.
discriminative learning of beam-search heuristics
for planning. in ijcai, pages 2041   2046.

hiroyasu yamada and yuji matsumoto. 2006. statis-
tical dependency analysis with support vector ma-
chines. in international workshop on parsing tech-
nologies (iwpt).

function
setup
getvalidactions
getfeat
getgoldaction
trans
runparser
total

number of lines

90
17
86
41
28
40
331

table 6: number of code lines of our de-
pendency parser implementation. the    setup   
contains class constructor, destructor, and han-
dlers for the learning to search framework.

dependency parser
l2s (ours)
stanford
redshift
(goldberg and nivre, 2013)
malt parser

number of lines

   300
   3k
   2k
   4k
   10k

table 7: number of lines of dependency parser
implementations.

we implemented our dependency parser at vowpal wabbit (http://hunch.net/  vw/), a ma-
chine learning system supporting online learning, hashing, reductions, and l2s. table 6 shows the num-
ber of code lines for each function in our implementation, and table 7 shows the number of lines of
other popular id33 systems. redshift and goldberg and nivre (2013) are implemented
in python. stanford and malt parser are in java. our implementation is in c++. c++ is usually more
lengthy than python and is competitive to java. the code is readable and contains proper comments as
shown below.

1 #include "search_dep_parser.h"

#include "gd.h"

3 #include "cost_sensitive.h"

5 #define val_namespace 100 // valency and distance feature space

#define offset_const 344429

7

9

11

13

15

17

19

21

23

25

27

29

31

33

35

37

39

41

43

45

namespace depparsertask

{

search::search_task task = { "dep_parser", run, initialize, finish, setup

, nullptr};

}

struct task_data {

example *ex;
size_t root_label, num_label;
v_array<uint32_t> valid_actions, valid_labels, action_loss, gold_heads, gold_tags, stack, heads, tags,

temp;

v_array<uint32_t> children[6]; // [0]:num_left_arcs, [1]:num_right_arcs; [2]: leftmost_arc, [3]:

second_leftmost_arc, [4]:rightmost_arc, [5]: second_rightmost_arc

example * ec_buf[13];

};

namespace depparsertask {
using namespace search;

void initialize(search::search& srn, size_t& num_actions, po::variables_map& vm) {

task_data *data = new task_data();
data->action_loss.resize(4,true);
data->ex = null;
srn.set_num_learners(3);
srn.set_task_data<task_data>(data);
po::options_description dparser_opts("dependency parser options");
dparser_opts.add_options()

("root_label", po::value<size_t>(&(data->root_label))->default_value(8), "ensure that there is only

one root in each sentence")

("num_label", po::value<size_t>(&(data->num_label))->default_value(12), "number of arc labels");

srn.add_program_options(vm, dparser_opts);

for(size_t i=1; i<=data->num_label;i++)

if(i!=data->root_label)

data->valid_labels.push_back(i);

data->ex = alloc_examples(sizeof(polylabel), 1);
data->ex->indices.push_back(val_namespace);
for(size_t i=1; i<14; i++)

data->ex->indices.push_back((unsigned char)i+   a   );

data->ex->indices.push_back(constant_namespace);

vw& all = srn.get_vw_pointer_unsafe();

const char* pair[] = {"bc", "be", "bb", "cc", "dd", "ee", "ff", "gg", "ef", "bh", "bj", "el", "db", "dc"
, "dd", "de", "df", "dg", "dd"};
const char* triple[] = {"efg", "bef", "bce", "bcd", "bel", "elm", "bhi", "bcc", "bje", "bhe", "bjk", "
beh", "ben", "bej"};

vector<string> newpairs(pair, pair+19);
vector<string> newtriples(triple, triple+14);
all.pairs.swap(newpairs);
all.triples.swap(newtriples);

srn.set_options(auto_condition_features | no_caching);
srn.set_label_parser( cost_sensitive::cs_label, [](polylabel&l) -> bool { return l.cs.costs.size() == 0;

});

}

void finish(search::search& srn) {

task_data *data = srn.get_task_data<task_data>();
data->valid_actions.delete_v();
data->valid_labels.delete_v();
data->gold_heads.delete_v();
data->gold_tags.delete_v();
data->stack.delete_v();
data->heads.delete_v();
data->tags.delete_v();
data->temp.delete_v();
data->action_loss.delete_v();
dealloc_example(cost_sensitive::cs_label.delete_label, *data->ex);
free(data->ex);
for (size_t i=0; i<6; i++) data->children[i].delete_v();
delete data;

}

void inline add_feature(example *ex,

uint32_t idx, unsigned

char ns, size_t mask, uint32_t multiplier){

feature f = {1.0f, (idx * multiplier) & (uint32_t)mask};
ex->atomics[(int)ns].push_back(f);

}

void inline reset_ex(example *ex){

ex->num_features = 0;
ex->total_sum_feat_sq = 0;
for(unsigned char *ns = ex->indices.begin; ns!=ex->indices.end; ns++){

ex->sum_feat_sq[(int)*ns] = 0;
ex->atomics[(int)*ns].erase();

}

}

// arc-hybrid system.
uint32_t transition_hybrid(search::search& srn, uint32_t a_id, uint32_t idx, uint32_t t_id) {

task_data *data = srn.get_task_data<task_data>();
v_array<uint32_t> &heads=data->heads, &stack=data->stack, &gold_heads=data->gold_heads, &gold_tags=data
->gold_tags, &tags = data->tags;
v_array<uint32_t> *children = data->children;
switch(a_id) {

case 1:

//shift

stack.push_back(idx);
return idx+1;

case 2:

//right

heads[stack.last()] = stack[stack.size()-2];
children[5][stack[stack.size()-2]]=children[4][stack[stack.size()-2]];
children[4][stack[stack.size()-2]]=stack.last();
children[1][stack[stack.size()-2]]++;
tags[stack.last()] = t_id;
srn.loss(gold_heads[stack.last()] != heads[stack.last()]?2:(gold_tags[stack.last()] != t_id)?1:0);
stack.pop();
return idx;

case 3:

//left

heads[stack.last()] = idx;
children[3][idx]=children[2][idx];
children[2][idx]=stack.last();
children[0][idx]++;
tags[stack.last()] = t_id;
srn.loss(gold_heads[stack.last()] != heads[stack.last()]?2:(gold_tags[stack.last()] != t_id)?1:0);
stack.pop();
return idx;

}
return idx;

}

void extract_features(search::search& srn, uint32_t idx,

vector<example*> &ec) {

vw& all = srn.get_vw_pointer_unsafe();
task_data *data = srn.get_task_data<task_data>();
reset_ex(data->ex);
size_t mask = srn.get_mask();
uint32_t multiplier = all.wpp << all.reg.stride_shift;
v_array<uint32_t> &stack = data->stack, &tags = data->tags, *children = data->children, &temp=data->temp
;
example **ec_buf = data->ec_buf;
example &ex = *(data->ex);

add_feature(&ex, (uint32_t) constant, constant_namespace, mask, multiplier);
size_t n = ec.size();

47

49

51

53

55

57

59

61

63

65

67

69

71

73

75

77

79

81

83

85

87

89

91

93

95

97

99

101

103

105

107

109

111

113

115

117

119

121

123

125

127

129

131

133

135

137

139

141

143

145

147

149

151

153

155

157

159

161

163

165

167

169

171

173

175

177

179

181

183

185

187

189

191

193

195

197

199

201

203

205

207

209

for(size_t i=0; i<13; i++)

ec_buf[i] = nullptr;

// feature based on the top three examples in stack ec_buf[0]: s1, ec_buf[1]: s2, ec_buf[2]: s3
for(size_t i=0; i<3; i++)

ec_buf[i] = (stack.size()>i && *(stack.end-(i+1))!=0) ? ec[*(stack.end-(i+1))-1] : 0;

// features based on examples in string buffer ec_buf[3]: b1, ec_buf[4]: b2, ec_buf[5]: b3
for(size_t i=3; i<6; i++)

ec_buf[i] = (idx+(i-3)-1 < n) ? ec[idx+i-3-1] : 0;

// features based on the leftmost and the rightmost children of the top element stack ec_buf[6]: sl1,
ec_buf[7]: sl2, ec_buf[8]: sr1, ec_buf[9]: sr2;
for(size_t i=6; i<10; i++) {

if (!stack.empty() && stack.last() != 0&& children[i-4][stack.last()]!=0)

ec_buf[i] = ec[children[i-4][stack.last()]-1];

}

// features based on leftmost children of the top element in bufer ec_buf[10]: bl1, ec_buf[11]: bl2
for(size_t i=10; i<12; i++)

ec_buf[i] = (idx <=n && children[i-8][idx]!=0)? ec[children[i-8][idx]-1] : 0;

ec_buf[12] = (stack.size()>1 && *(stack.end-2)!=0 && children[2][*(stack.end-2)]!=0)? ec[children[2][*(
stack.end-2)]-1]:0;

// unigram features
uint64_t v0;
for(size_t i=0; i<13; i++) {

for (unsigned char* fs = ec[0]->indices.begin; fs != ec[0]->indices.end; fs++) {

if(*fs == constant_namespace) // ignore constant_namespace

continue;

uint32_t additional_offset = (uint32_t)(i*offset_const);
if(!ec_buf[i]){

for(size_t k=0; k<ec[0]->atomics[*fs].size(); k++) {

v0 = affix_constant*((*fs+1)*quadratic_constant + k);
add_feature(&ex, (uint32_t) v0 + additional_offset, (unsigned char)((i+1)+   a   ), mask, multiplier

);

}

}
else {

for(size_t k=0; k<ec_buf[i]->atomics[*fs].size(); k++) {

v0 = (ec_buf[i]->atomics[*fs][k].weight_index / multiplier);
add_feature(&ex, (uint32_t) v0 + additional_offset, (unsigned char)((i+1)+   a   ), mask, multiplier

}

}

);

}

}

// other features
temp.resize(10,true);
temp[0] = stack.empty()? 0: (idx >n? 1: 2+min(5, idx - stack.last()));
temp[1] = stack.empty()? 1: 1+min(5, children[0][stack.last()]);
temp[2] = stack.empty()? 1: 1+min(5, children[1][stack.last()]);
temp[3] = idx>n? 1: 1+min(5 , children[0][idx]);
for(size_t i=4; i<8; i++)

temp[i] = (!stack.empty() && children[i-2][stack.last()]!=0)?tags[children[i-2][stack.last()]]:15;

for(size_t i=8; i<10; i++)

temp[i] = (idx <=n && children[i-6][idx]!=0)? tags[children[i-6][idx]] : 15;

size_t additional_offset = val_namespace*offset_const;
for(int j=0; j< 10;j++) {

additional_offset += j* 1023;
add_feature(&ex, temp[j]+ additional_offset , val_namespace, mask, multiplier);

}

size_t count=0;
for (unsigned char* ns = data->ex->indices.begin; ns != data->ex->indices.end; ns++) {

data->ex->sum_feat_sq[(int)*ns] = (float) data->ex->atomics[(int)*ns].size();
count+= data->ex->atomics[(int)*ns].size();

}
for (vector<string>::iterator i = all.pairs.begin(); i != all.pairs.end();i++)

count += data->ex->atomics[(int)(*i)[0]].size()* data->ex->atomics[(int)(*i)[1]].size();

for (vector<string>::iterator i = all.triples.begin(); i != all.triples.end();i++)

count += data->ex->atomics[(int)(*i)[0]].size()*data->ex->atomics[(int)(*i)[1]].size()*data->ex->

atomics[(int)(*i)[2]].size();
data->ex->num_features = count;
data->ex->total_sum_feat_sq = (float) count;

}

void get_valid_actions(v_array<uint32_t> & valid_action, uint32_t idx, uint32_t n, uint32_t stack_depth,

uint32_t state) {
valid_action.erase();
if(idx<=n) // shift

valid_action.push_back(1);
if(stack_depth >=2) // right
valid_action.push_back(2);

211

213

215

217

219

221

223

225

227

229

231

233

235

237

239

241

243

245

247

249

251

253

255

257

259

261

263

265

267

269

271

273

275

277

279

281

283

285

287

289

291

293

if(stack_depth >=1 && state!=0 && idx<=n) // left

valid_action.push_back(3);

}

bool is_valid(uint32_t action, v_array<uint32_t> valid_actions) {

for(size_t i=0; i< valid_actions.size(); i++)

if(valid_actions[i] == action)

return true;

return false;

}

size_t get_gold_actions(search::search &srn, uint32_t idx, uint32_t n){

task_data *data = srn.get_task_data<task_data>();
v_array<uint32_t> &action_loss = data->action_loss, &stack = data->stack, &gold_heads=data->gold_heads,
&valid_actions=data->valid_actions;

if (is_valid(1,valid_actions) &&( stack.empty() || gold_heads[idx] == stack.last()))

return 1;

if (is_valid(3,valid_actions) && gold_heads[stack.last()] == idx)

return 3;

for(size_t i = 1; i<= 3; i++)

action_loss[i] = (is_valid(i,valid_actions))?0:100;

for(uint32_t i = 0; i<stack.size()-1; i++)

if(idx <=n && (gold_heads[stack[i]] == idx || gold_heads[idx] == stack[i]))

action_loss[1] += 1;

if(stack.size()>0 && gold_heads[stack.last()] == idx)

action_loss[1] += 1;

for(uint32_t i = idx+1; i<=n; i++)

if(gold_heads[i] == stack.last()|| gold_heads[stack.last()] == i)

action_loss[3] +=1;

if(stack.size()>0

&& idx <=n && gold_heads[idx] == stack.last())

action_loss[3] +=1;

if(stack.size()>=2 && gold_heads[stack.last()] == stack[stack.size()-2])

action_loss[3] += 1;

if(gold_heads[stack.last()] >=idx)

action_loss[2] +=1;

for(uint32_t i = idx; i<=n; i++)

if(gold_heads[i] == stack.last())

action_loss[2] +=1;

// return the best action
size_t best_action = 1;
for(size_t i=1; i<=3; i++)

if(action_loss[i] <= action_loss[best_action])

best_action= i;
return best_action;

}

void setup(search::search& srn, vector<example*>& ec) {

task_data *data = srn.get_task_data<task_data>();
v_array<uint32_t> &gold_heads=data->gold_heads, &heads=data->heads, &gold_tags=data->gold_tags, &tags=
data->tags;
uint32_t n = (uint32_t) ec.size();
heads.resize(n+1, true);
tags.resize(n+1, true);
gold_heads.erase();
gold_heads.push_back(0);
gold_tags.erase();
gold_tags.push_back(0);
for (size_t i=0; i<n; i++) {

v_array<cost_sensitive::wclass>& costs = ec[i]->l.cs.costs;
uint32_t head = (costs.size() == 0) ? 0 : costs[0].class_index;
uint32_t tag
if (tag > data->num_label) {

= (costs.size() <= 1) ? data->root_label : costs[1].class_index;

cerr << "invalid label " << tag << " which is > num actions=" << data->num_label << endl;
throw exception();

}
gold_heads.push_back(head);
gold_tags.push_back(tag);
heads[i+1] = 0;
tags[i+1] = -1;

}

for(size_t i=0; i<6; i++)

data->children[i].resize(n+1, true);

}

void run(search::search& srn, vector<example*>& ec) {

task_data *data = srn.get_task_data<task_data>();
v_array<uint32_t> &stack=data->stack, &gold_heads=data->gold_heads, &valid_actions=data->valid_actions,
&heads=data->heads, &gold_tags=data->gold_tags, &tags=data->tags, &valid_labels=data->valid_labels;
uint32_t n = (uint32_t) ec.size();

295

297

299

301

303

305

307

309

311

313

315

317

319

321

323

325

327

329

}

331 }

stack.erase();
stack.push_back((data->root_label==0)?0:1);
for(size_t i=0; i<6; i++)

for(size_t j=0; j<n+1; j++)
data->children[i][j] = 0;

int count=1;
uint32_t idx = ((data->root_label==0)?1:2);
while(stack.size()>1 || idx <= n){

if(srn.predictneedsexample())

extract_features(srn, idx, ec);

get_valid_actions(valid_actions, idx, n, (uint32_t) stack.size(), stack.size()>0?stack.last():0);
uint32_t gold_action = get_gold_actions(srn, idx, n);

// predict the next action {shift, reduce_left, reduce_right}
count = 2*idx + 1;
uint32_t a_id= search::predictor(srn, (ptag) count).set_input(*(data->ex)).set_oracle(gold_action).
set_allowed(valid_actions).set_condition_range(count-1, srn.get_history_length(),    p   ).set_learner_id
(0).predict();

count++;

uint32_t t_id = 0;
if(a_id ==2 || a_id == 3){

uint32_t gold_label = gold_tags[stack.last()];
t_id= search::predictor(srn, (ptag) count).set_input(*(data->ex)).set_oracle(gold_label).set_allowed

(valid_labels).set_condition_range(count-1, srn.get_history_length(),    p   ).set_learner_id(a_id-1).
predict();

}
count++;
idx = transition_hybrid(srn, a_id, idx, t_id);

}

heads[stack.last()] = 0;
tags[stack.last()] = data->root_label;
srn.loss((gold_heads[stack.last()] != heads[stack.last()]));
if (srn.output().good())

for(size_t i=1; i<=n; i++)

srn.output() << (heads[i])<<":"<<tags[i] << endl;

