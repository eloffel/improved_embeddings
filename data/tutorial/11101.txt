connotation frames: a data-driven investigation

hannah rashkin

sameer singh

yejin choi

computer science & engineering

university of washington

{hrashkin, sameer, yejin}@cs.washington.edu

6
1
0
2

 

g
u
a
2
2

 

 
 
]
l
c
.
s
c
[
 
 

3
v
9
3
7
2
0

.

6
0
5
1
:
v
i
x
r
a

abstract

through a particular choice of a predicate
(e.g.,    x violated y   ), a writer can subtly
connote a range of implied sentiments and
presupposed facts about the entities x and
y: (1) writer   s perspective: projecting x
as an    antagonist    and y as a    victim   , (2)
entities    perspective: y probably dislikes
x, (3) effect: something bad happened to y,
(4) value: y is something valuable, and (5)
mental state: y is distressed by the event.
we introduce connotation frames as a rep-
resentation formalism to organize these
rich dimensions of connotation using typed
relations. first, we investigate the fea-
sibility of obtaining connotative labels
through id104 experiments. we
then present models for predicting the con-
notation frames of verb predicates based
on their distributional word representations
and the interplay between different types
of connotative relations. empirical results
con   rm that connotation frames can be in-
duced from various data sources that re   ect
how people use language and give rise to
the connotative meanings. we conclude
with analytical results that show the poten-
tial use of connotation frames for analyzing
subtle biases in online news media.
introduction

1
people commonly express their opinions through
subtle and nuanced language (thomas et al., 2006;
somasundaran and wiebe, 2010). often, through
seemingly objective statements, the writer can in-
   uence the readers    judgments toward an event and
their participants. even by choosing a particular
predicate, the writer can indicate rich connotative
information about the entities that interact through

figure 1: an example connotation frame of    violate    as a
set of typed relations: perspective p(x     y), effect e(x),
value v(x), and mental state s(x).

the predicate. speci   cally, through a simple state-
ment such as    x violated y   , the writer can convey:
(1) writer   s perspective: the writer is projecting
x as an    antagonist    and y as a    victim   , elic-
iting negative perspective from readers toward
x (i.e., blaming x) and positive perspective
toward y (supportive or sympathetic to y).

(2) entities    perspective: y most likely feels neg-
atively toward x as a result of being violated.

(3) effect: something bad happened to y.
(4) value: y is something valuable, since it does
not make sense to violate something worthless.
in other words, the writer is presupposing y   s
positive value as a fact.

(5) mental state: y is most likely unhappy about

the outcome.1

1to be more precise, y is most likely in a negative mental

state assuming it is an entity that can have a mental state.

writer:    agent violates theme.   writer+=+reader==agentthemep(w!agent)p(w!theme)p(agent!theme)e(agent)e(theme)v(theme)v(agent)e(theme)s(agent)s(agent)e(agent)perspective: the writer is  sympathetic  towards the themeperspective:  the writer portrays the agent as being antagonisticvalue: the theme must be valuable+effect: the agent is not really affected by the violationstate: the theme will be unhappystate: the agent feels indifferenteffect: the theme has been hurtvalue: not clear if agent is valuable                  subset of typed relations

verb
suffer

guard

p(w     agent) = +
p(w     theme) =    
p(agent     theme) =    
p(w     agent) = +
p(w     theme) = +
p(agent     theme) = +

uphold p(w     theme) = +

p(agent     theme) = +

e(agent) =    
v(agent) = +
s(agent) =    
e(theme) = +
v(theme) = +
s(theme) = +
e(theme) = +
v(theme) = +

example sentences
the story begins in illinois in 1987, when a 17-
year-old girl suffered a botched abortion.

l/r
r

in august, marshals guarded 25 clinics in 18
cities.

a hearing is scheduled to make a decision on
whether to uphold the clinic   s suspension.

l

r

table 1: example typed relations (perspective p(x     y), effect e(x), value v(x), and mental state s(x)), where w denotes
the writer. not all typed relations are shown due to space constraints. the example sentences demonstrate the usage of the
predicates in left [l] or right [r] leaning news sources.

even though the writer might not explicitly state
any of the interpretations [1-5] above, the readers
will be able interpret these intentions as a part of
their comprehension. in this paper, we present an
empirical study of how to represent and induce the
connotative interpretations that can be drawn from
a verb predicate, as illustrated above.

we introduce connotation frames as a represen-
tation framework to organize the rich dimensions
of the implied sentiment and presupposed facts.
figure 1 shows an example of a connotation frame
for the predicate violate. we de   ne four different
typed relations: p(x     y) for perspective of x
towards y, e(x) for effect on x, v(x) for value of
x, and s(x) for mental state of x. these relation-
ships can all be either positive (+), neutral (=), or
negative (-).

our work is the    rst study to investigate frames
as a representation formalism for connotative
meanings. this contrasts with previous com-
putational studies and resource development for
frame semantics, where the primary focus was al-
most exclusively on denotational meanings of lan-
guage (baker et al., 1998; palmer et al., 2005). our
formalism draws inspirations from the earlier work
of frame semantics, however, in that we investi-
gate the connection between a word and the related
world knowledge associated with the word (fill-
more, 1976), which is essential for the readers to
interpret many layers of the implied sentiment and
presupposed value judgments.

we also build upon the extensive amount of lit-
erature in id31 (pang and lee, 2008;
liu and zhang, 2012), especially the recent emerg-
ing efforts on implied id31 (feng
et al., 2013; greene and resnik, 2009), entity-
entity sentiment id136 (wiebe and deng, 2014),
opinion role induction (wiegand and ruppenhofer,
2015), and effect analysis (choi and wiebe, 2014).

however, our work is the    rst to organize aspects of
the connotative information into coherent frames.
more concretely, our contributions are threefold:
(1) a new formalism, model, and annotated dataset
for studying the connotation frames from large-
scale natural language data and statistics, (2) data-
driven insights into the dynamics among different
typed relations within each frame, and (3) an ana-
lytic study to show the potential use of connotation
frames for analyzing subtle biases in journalism.
the rest of the paper is organized as follows: in
  2, we provide the de   nitions and data-driven in-
sights for connotation frames. in   3, we introduce
models for inducing the connotation frames, fol-
lowed by empirical results, annotation studies, and
analysis on news media in   4. we discuss related
work in   5 and conclude in   6.
2 connotation frame
given a predicate v, we de   ne a connotation frame
f(v) as a collection of typed relations and their po-
larity assignments: (i) perspective p v(xi     xj):
whether the predicate v implies directed sentiment
from the entity xi to the entity xj, (ii) value v v(xi):
whether xi is presupposed to be valuable by the
predicate v, (iii) effect e v(xi): whether the event
denoted by the predicate v is good or bad for the
entity xi, and (iv) mental state s v(xi): the likely
mental state of the entity xi as a result of the event.
we assume that each typed relation can have one of
the three connotative polarities     {+,   , =}, i.e.,
positive, negative, or neutral. our goal in this paper
is to focus on the general connotation of the predi-
cate considered out of context. we leave contextual
interpretation of connotation as future work.

table 1 shows examples of connotation frame
relations for the verbs suffer, guard, and uphold,
along with example sentences. for instance, for the
verb suffer, the writer is likely to have a positive

verb

accuse

attack

criticize

x   s role p(w       )
agent
theme
agent
theme
agent
theme

-
+
-
+
-
+

left-leaning sources

right-leaning sources

putin, progressives, limbaugh, gingrich

of   cial, rival, administration, leader

mccain, trump, limbaugh
gingrich, obama, policy

activist, u.s., protestor, chavez
romney, iran, gingrich, regime
obama, campaign, biden, israel

citizen, zimmerman

ugandans, rival, romney, tyson
obama, allen, cameron, congress

britain, passage, obama, maddow
pelosi, romey, gop, republicans

table 2: media bias in connotation frames: obama, for example, is portrayed as someone who attacks or criticizes others by
the right-leaning sources, whereas the left-leaning sources portray obama as the victim of harsh acts like    attack    and    criticize   .

perspective towards the agent (e.g., being support-
ive or sympathetic toward the    17-year-old girl    in
the example shown on the right) and a negative
perspective towards the theme (e.g., being negative
towards    botched abortion   ).

2.1 data-driven motivation
since the meaning of language is ultimately contex-
tual, the exact connotation will vary depending on
the context of each utterance. nonetheless, there
still are common shifts or biases in the connota-
tive polarities, as we found from two data-driven
analyses.

first, we looked at words from the subjectivity
lexicon (wilson et al., 2005) that are used in the
argument positions of a small selection of predi-
cates in google syntactic id165s (goldberg and
orwant, 2013). for this analysis, we assumed that
the agent is the word in the subject position while
the theme is the word in the object position. we
found 64% of the words in the agent role of suffer
are positive, and 94% of the words in the theme
role are negative, which is consistent with the po-
larities of the writer   s perspective towards these
arguments, as shown in table 1. for guard, 57%
of the agents and 76% of the themes are positive,
and in the case of uphold, 56% of the agents and
72% of the themes are positive.

we also investigated how media bias can po-
tentially be analyzed through connotation frames.
from the stream corpus 2014 dataset (kba, 2014),
we selected all articles from news outlets with
known political biases,2 and compared how they
use polarised words such as    accuse   ,    attack   , and
   criticize    differently in light of p(w     agent)
and p(w     theme) relations of the connota-
tion frames. table 2 shows interesting contrasts.
obama, for example, is frequently portrayed as
2the articles come from 30 news sources indicated by
others as exhibiting liberal or conservative leanings (mitchell
et al., 2014; center for media and democracy, 2013; center
for media and democracy, 2012; hwc library, 2011)

someone who attacks or criticizes others accord-
ing to the right-leaning sources, whereas the left-
leaning sources portray obama as the victim of
harsh acts like    attack    or    criticize   .3 further-
more, by knowing the perspective relationships
p(w     xi) associated with a predicate, we can
make predictions about how the left-leaning and
right-leaning sources feel about speci   c people or
issues. for example, because left-leaning sources
frequently use mccain, trump, and limbaugh in
the agent position of attack, we might predict that
these sources have a negative sentiment towards
these entities.

2.2 dynamics between typed relations
given a predicate, the polarity assignments of typed
relations are interdependent. for example, if the
writer feels positively towards the agent but nega-
tively towards the theme, then it is likely that the
agent and the theme do not feel positively towards
each other. this insight is related to that of wiebe
and deng (2014), but differs in that the polarities
are predicate-speci   c and do not rely on knowledge
of prior sentiment towards the arguments, them-
selves. this and other possible interdependencies
are summarized in table 3. these interdependen-
cies serve as general guidelines of what properties
we expect to depend on one another, especially in
the case where the polarities are non-neutral. we
will promote these internal consistencies in our
factor graph model (  3) as soft constraints.
there also exist other interdependencies that we
will use to simplify our task. first, the directed
sentiments between the agent and the theme are
likely to be reciprocal, or at least do not directly
con   ict with + and     simultaneously. this intu-
ition follows from a notion of balance derived by
social theory (heider, 1946). therefore, we assume

3that is, even if someone truly deserves criticism from
obama, left-learning sources would choose slightly different
wordings to avoid a potentially harsh portrayal of obama.

perspective triad: if argument xi is positive towards xj, and xj is positive towards xk, then we expect xi is also
positive towards xk. similar dynamics hold for the negative case.

pw   xi =    (pw   xj     pxi   xj )

perspective     effect: if a predicate has a positive effect on one argument, then we expect that the interaction
between the arguments was positive. similar dynamics hold for the negative case.

exi = pxj   xi

perspective     value: if argument xi is presupposed as valuable, then we expect that the writer also views xi
positively. similar dynamics hold for the negative case.

vxi = pw   xi

effect     mental state: if the predicate has a positive effect on an argument xi, then we expect that xi will gain a
positive mental state. similar dynamics hold for the negative case.

sxi = exi

table 3: potential dynamics among typed relations: we propose models that parameterize these dynamics using log-linear
models (frame-level model in   3).

3 modeling connotation frames

our task is essentially that of lexicon induc-
tion (akkaya et al., 2009; feng et al., 2013) in that
we want to induce the connotation frames of previ-
ously unseen verbs. for each verb predicate, we in-
fer a connotation frame composed of 9 relationship
aspects that represent: perspective {p(w     t),
p(w     a), p(a     t)}, effect {e(t), e(a)}, value
{v(t), v(a)}, and mental state {s(t), s(a)} po-
larities, where w, a, t denote the writer, the agent,
and the theme, respectively.

we propose two models: an aspect-level model
that makes the prediction for each typed relation
independently based on the distributional represen-
tation of the context in which the predicate com-
monly appears (  3.1), and a frame-level model that
makes the prediction over the connotation frame
collectively in consideration of the dynamics be-
tween typed relations (  3.2).
3.1 aspect-level
our aspect-level model predicts labels for each of
these typed relations separately. as input, we use
the 300-dimensional dependency-based word em-
beddings from levy and goldberg (2014). for each
aspect, there is a separate maxent (maximum en-
tropy) classi   er used to predict the label of that as-
pect on a given word-embedding, which is treated
as a 300 dimensional input vector to the classi-
   er. the maxent classi   ers learn their weights
using lbfgs on the training data examples with
re-weighting of samples to maximize for the best
average f1 score.

3.2 frame-level
next we present a factor graph model (figure 2)
of the connotation frames that parameterizes the
dynamics between typed relations. speci   cally,

figure 2: a factor graph for predicting the polarities of the
typed relations that de   ne a connotation frame for a given
verb predicate. the factor graph also includes unary factors
(  emb), which we left out for brevity.

that p(xi     xj) = p(xj     xi) = p(xi     xj),
and we only measure for these binary relationships
going in one direction. in addition, we assume the
predicted4 perspective from the reader r to an ar-
gument, p(r     x), is likely to be the same as the
implied perspective from the writer w to the same
argument, p(w     x). so, we only try to learn the
perspective of the writer. lifting these assumptions
will be future work.

for simplicity, our work only explores verb pred-
icates and focuses on the polarities involving the
agent and the theme roles, which we will refer to
as a and t. we will assume that these roles are
correlated to the subject and object positions.

4surely different readers can and will form varying opin-
ions after reading the same text. here we concern with the
most likely perspective of the general audience, as a result of
reading the text.

nodemeaningperspective of writer towards the agenteffect on the agentvalue of the agentmental state of the agentfor each verb predicate, the factor graph contains
9 nodes representing the different aspects of the
connotation frame involving the writer (w), the
agent (a), and the theme (t). all these variables
take polarity values from the set {   , =, +}.
we de   ne yi := {pwt,pwa,pat,et,ea,vt,va,
st,sa} as the set of relational aspects for the ith
verb predicate. the factor graph for yi, is illus-
trated in figure 2, and we describe the factor po-
tentials,   , in detail in the rest of this section. the
id203 of an assignment of polarities to the
nodes in yi is:

p (yi)       pv(pwa,va)   pv(pwt,vt)
  pe(pat,ea)   pe(pat,et)
  es(ea,sa)   es(et,st)
  pt(pwt,pwa,pat)

(cid:89)

y   yi

  emb(y)

embedding factors we include unary factors on
all nodes to represent the results of the aspect-level
classi   er. incorporating this knowledge as factors,
as opposed to    xing the variables as observed, af-
fords us the    exibility of representing noise in the
labels as soft evidence. the potential function   emb
is a log-linear function of a feature vector f, which
is a one-hot feature vector representing the polarity
of a node (+,   ,or =). for example, with the node
representing the value of the theme (vt):

  emb(vt) = e  vt  f (vt)

the potential   emb is de   ned similarly for the re-
maining eight nodes.

weights    are learned in a piecewise likelihood
manner (sutton and mccallum, 2009) for each fac-
tor independently using stochastic id119
(sgd) over the training data.
interdependency factors we include interde-
pendency factors to promote the properties de   ned
by the dynamics between relations (  2.2). the po-
tentials for perspective triad, perspective-value,
perspective-effect, and effect-state relationships
(  pt,   pv,   pe,   es respectively) are all de   ned
using log-linear functions of one-hot feature vec-
tors that encode the combination of polarities of
the neighboring nodes. thus the potential   pt is:
  pt (pwt,pwa,pat) = e  p t   f (pwt,pwa,pat)

and we de   ne the potentials for   pv,   pe, and   es
for nodes pertaining to the agent as:

  pv (pwa,va) = e  p v,a  f (pwa,va)

  pe(pat,ea) = e  p e,a  f (pat,ea)
  es(ea,sa) = e  es,a  f (ea,sa)

  v   f (x)    
(cid:88)

and we de   ne the potentials for the theme nodes
similarly. as with the unary seed factors, weights
   are learned using sgd over training data.
belief propagation we use belief propagation
to induce the connotation frames of previously un-
seen verbs. in the belief propagation algorithm,
messages are iteratively passed between the nodes
to their neighboring factors. each message   , con-
taining a scalar for each value x     {   , =, +}, is
de   ned from each node v to a neighboring factor f
as follows:

(cid:89)

  f      v(x)

f      n (v)\a

and from each factor a to a neighboring node v as:

  f   v    

(cid:48)
  (x

)

  v      f (x

(cid:48)
v   )

x(cid:48),x(cid:48)

v=x

v      n (f )\v

(cid:89)

our factor graph does not contain any loops, so we
are able to perform exact id136 by choosing a
root node and performing message passing from
the leaves to the root and back to the leaves. at
the conclusion of message passing, the id203
of a speci   c polarity associated with node v being

equal to x is proportional to(cid:81)

f   n (v)   f   v(x).

4 experiments
we    rst describe crowd-sourced annotations (  4.1),
then present the empirical results of predicting con-
notation frames (  4.2), and conclude with qualita-
tive analysis of a large corpus (  4.3).
4.1 data and id104
in order to understand how humans interpret conno-
tation frames, we designed an amazon mechanical
turk (amt) annotation study. we gathered a set of
transitive verbs commonly used in the new york
times corpus (sandhaus, 2008), selecting the 2400
verbs that are used more than 200 times in the cor-
pus. of these, amt workers annotated the 1000
most frequently used verbs.
annotation design in a pilot annotation exper-
iment, we found that annotators have dif   culty
thinking about subtle connotative polarities when
shown predicates without any context. therefore,
we designed the amt task to provide a generic
context as follows. we    rst split each verb predi-
cate into 5 separate tasks that each gave workers a

different generic sentence using the verb. to cre-
ate generic sentences, we used google syntactic
id165s (goldberg and orwant, 2013) to come
up with a frequently seen subject-verb-object tu-
ple which served as a simple three-word sentence
with generic arguments.5 for each of the 5 sen-
tences, we asked 3 annotators to answer questions
like    how do you think the agent feels about the
event described in this sentence?    in total, each
verb has 15 annotations aggregated over 5 different
generic sentences containing the verb.

in order to help the annotators, some of the ques-
tions also allowed annotators to choose sentiment
using additional classes for    positive or neutral   
or    negative or neutral    for when they were less
con   dent but still felt like a sentiment might ex-
ist. when taking inter-annotator agreement, we
count    positive or neutral    as agreeing with either
   positive    or    neutral    classes.
annotator agreement table 4 shows agreements
and data statistics. the non-con   icting (nc) agree-
ment only counts opposite polarities as disagree-
ment.6 from this study, we can see that non-expert
annotators are able to see these sort of relationships
based on their understanding of how language is
used. from the nc agreement, we see that annota-
tors do not frequently choose completely opposite
polarities, indicating that even when they disagree,
their disagreements are based on the degree of con-
notations rather than the polarity itself. the average
krippendorff alpha for all of the questions posed
to the workers is 0.25, indicating stronger than ran-
dom agreement. considering the subtlety of the
implicit sentiments that we are asking them to anno-
tate, it is reasonable that some annotators will pick
up on more nuances than others. overall, the per-
cent agreement is encouraging that the connotative
relationships are visible to human annotators.
aggregating annotations we aggregated over
crowdsourced labels (   fteen annotations per verb)
to create a polarity label for each aspect of a verb.7
final distributions of the aggregated labels are
included in the right-hand columns of table 4. no-

5because google syntactic id165s only provide depen-
dency types and do not provide semantic roles, we approxi-
mate the agent and theme as the subject and the object respec-
tively.

6annotators were asked yes/no questions related to value,

so this does not have a corresponding nc agreement score.
7 we take the average to obtain scalar value be-
tween [   1., 1.] for each aspect of a verb   s connotation frame.
for simplicity, we cutoff the ranges of negative, neutral
and positive polarities as [   1,   0.25), [   0.25, 0.25] and
(0.25, 1], respectively.

aspect

p(w     t)
p(w     a)
p(a     t)

e(t)
e(a)
v(t)
v(a)
s(t)
s(a)

% agreement
strict
nc
95.6
75.6
95.5
76.1
91.9
70.4
52.3
94.6
53.5
96.5
65.2
71.9
79.9
70.4

98.0
92.5

-
-

distribution
% +
% -
4.6
36.6
7.9
47.1
5.0
45.8
50.3
20.24
4.7
45.1
2.7
78.64
1.4
90.32
14.5
12.8
50.72
8.6

table 4: label statistics: % agreement refers to pairwise
inter-annotator agreement. the strict agreement counts agree-
ment over 3 classes (   positive or neutral    was counted as
agreeing with either + or neutral), while non-con   icting (nc)
agreement also allows agreements between neutral and -/+ (no
direct con   icts). distribution shows the    nal class distribution
of -/+ labels created by averaging annotations.

tably, the distributions are skewed toward positive
and neutral labels. the most skewed connotation
frame aspect is the value v(x) which tends to be
positive, especially for the agent argument. this
makes some intuitive sense since, as the agent ac-
tively causes the predicate event to occur, they most
likely have some intrinsic potential to be valuable.
an example of a verb where the agent was labelled
with negative value is    contaminate   . in the most
generic case, the writer is using    contaminate    to
frame the agent as being worthless (and even harm-
ful) with regards to the other event participants. for
example, in the sentence    his touch contaminated
the food,    it is clear that the writer presupposes    his
touch    to be of negative value in how it impacts the
rest of the event.

4.2 connotation frame prediction
using the crowdsourced labels, we randomly di-
vide the annotated verbs into training, dev, and
held-out test sets of equal size (300 verbs each).
for evaluation we measure average accuracy and
f1 score of induced labels for the 9 different conno-
tation frame relationship types for which we have
annotations: p(w     t), p(w     a), p(a     t),
v(t), v(a), e(t), e(a), s(t), and s(a), where w
refers to the writer, a to the agent, and t to the
theme.
baselines to show the non-trivial challenge of
learning connotation frames, we include a simple
majority-class baselines. the majority classi-
   er assigns each of the 9 relationships the label
of the majority of that relationship type found in
the training data. some of these relationships (in

particular, the value of agent/theme) have skewed
distributions, so we expect this classi   er to achieve
a much higher accuracy than random but a much
lower overall f1 score.

additionally, we add a graph prop baseline
that is comparable to algorithms like graph prop-
agation or label propagation which are often used
for (sentiment) lexicon induction (velikovich et al.,
2010a). we use a factor graph with nodes repre-
senting the polarity of each typed relation for each
verb. binary factors connect nodes representing
a particular type of relation for two similar verbs
(e.g. p(w     t) for verbs persuade and convince).
these binary factors have hand-tuned potentials
that are proportional to the cosine similarity of the
verbs    embeddings, encouraging similar verbs to
have the same polarity for the various relational
aspects. we use words in the training data as the
seed set and use loopy belief propagation to propa-
gate polarities from known nodes to the unknown
relationships.

finally, we use a 3-nearest neighbor base-
line that labels relationships for a verb based on
the predicate   s 300-dimensional id27
representation, using the same embeddings as in
our aspect-level. 3-nearest neighbor labels
each verb using the polarities of the three closest
verbs found in the training set. the most similar
verbs are determined using the cosine similarity
between id27s.
results as shown in table 5, aspect-level and
frame-level models consistently outperform all
three baselines     majority, 3-nn, graph
prop in the development set across the different
types of relationships. in particular, the improved
f1 scores show that these models are able to per-
form better across all three classes of labels even
in the most skewed cases. the frame-level model
also frequently improves the f1 scores of the la-
bels from what they were in the aspect-level model.
the summarized comparison of the classi   ers    per-
formance test set is shown in table 6. as with
the development set, aspect-level and frame-level
are both able to outperform the baselines. fur-
thermore, the frame-level formulation is able to
make improvement over the results of the aspect-
level classi   cation, indicating that the modelling of
inter-dependencies between relationships did help
correct some of the mistakes made.

one point of interest about the frame-level re-
sults is whether the learned weights over the consis-

(a)   p(a   t)

(b)   p t , p(w     t):    

(c)   p t , p(w     t): = (d)   p t , p(w     t): +

figure 3: learned weights,   , of embedding factor for
the perspective of agent to theme (3a) and the weights the
perspective triad (pt) factor (3b-3d). lighter shades are for
weights that are more positive, whereas dark blue is more
negative.

tency factors match our initial intuitions about inter-
dependencies between relationships. the weights
learned in our algorithm do tell us something in-
teresting about the degree to which these inter-
dependencies are actually found in our data.

we show the heat maps for some of the learned
weights in figure 3. in 3a, we show the weights of
one of the embedding factors, and how the node   s
polarities are more strongly weighted when they
match the aspect-level output. in the rest of the
   gure, we show the weights for the other per-
spective relationships when p(w     t) is nega-
tive (3b), neutral (3c), and positive (3d), respec-
tively. based on the expected interdependencies,
when p(w     t) :    , the model should favor
p(w     a) (cid:54)= p(a     t) and when p(w     t) : +,
the model should favor p(w     a) = p(a     t).
our model does, in fact, learn a similar trend, with
slightly higher weights along these two diagonals in
the maps 3b and 3d. interestingly, when p(w     t)
is neutral, weights slightly prefer for the other two
perspectives to resemble one another, but with high-
est weights being when other perspectives are also
neutral.

4.3 analysis of a large news corpus
using the connotation frame, we present measured
implied sentiment in online journalism.

data from the stream corpus (kba, 2014),
we select 70 million news articles. we extract
subject-verb-object relations for this subset us-

aspect

p(w     t)

p(w     a)

p(a     t)

e(t)

e(a)

v(t)

v(a)

s(t)

s(a)

algorithm
majority
graph prop
3-nn
aspect-level
frame-level
majority
graph prop
3-nn
aspect-level
frame-level
majority
graph prop
3-nn
aspect-level
frame-level
majority
graph prop
3-nn
aspect-level
frame-level
majority
graph prop
3-nn
aspect-level
frame-level
majority
graph prop
3-nn
aspect-level
frame-level
majority
graph prop
3-nn
aspect-level
frame-level
majority
graph prop
3-nn
aspect-level
frame-level
majority
graph prop
3-nn
aspect-level
frame-level

acc.

avg f1

56.52
59.53
62.88
67.56
67.56
49.83
52.84
55.18
60.54
61.87
49.83
52.17
56.52
63.21
63.88
48.83
54.85
55.18
64.21
65.22
49.83
52.17
54.85
62.54
63.88
79.60
71.91
76.25
75.92
76.25
89.30
84.62
85.62
87.96
87.96
71.91
69.90
72.91
81.61
81.61
50.84
48.83
54.85
61.54
61.54

24.07
50.20
47.93
56.18
56.18
22.17
42.93
45.88
60.72
63.07
22.17
46.57
52.94
61.70
62.56
21.87
51.40
51.53
63.63
64.67
22.17
35.56
42.63
53.82
56.81
29.55
35.10
39.09
45.45
48.13
31.45
38.82
38.45
48.06
48.06
27.89
55.57
59.26
72.85
72.85
22.47
35.40
45.51
53.88
53.88

table 5: detailed breakdown of results on the de-
velopment set using accuracy and average f1 over
the three class labels (+,-,=).

algorithm
graph prop
3-nn
aspect-level
frame-level

acc. avg f1
41.46
58.81
63.71
47.30
53.17
67.93
68.26
53.50

table 6: performance on the test set. results are
averaged over the different aspects.

figure 4: average sentiment of democrats and republicans
(as agents) to selected nouns (as their themes), aggregated
over a large corpus using the learned lexicon (  4.2). the
line indicates identical sentiments, i.e. republicans are more
positive towards the nouns that are above the line.

ing the direct dependencies between noun phrases
and verbs as identi   ed by the bbn serif system,
obtaining 1.2 billion unique tuples of the form
(url,subject,verb,object,count). we also extract tu-
ples from news articles from the annotated english
gigaword corpus (napoles et al., 2012), which
contains nearly 10 million articles, resulting in an
additional 120 million unique tuples.
estimating entity polarities using connotation
frames, we can also measure entity-to-entity sen-
timent at a large scale. figure 4, for example,
presents the polarity of entities    democrats    and
   republicans    towards a selected set of nouns, by
computing the average estimated p(a     t) polar-
ity (using our frame-level output) over triples where
one of these entities appears as part of the phrase
in the agent role (e.g.    democrats    or    republican
party   ). apart from nouns that both entities are pos-
itive (   business   ,    constitution   ) or negative (   the
allegations   ,   veto threat   ) towards, we can also
see interesting examples in which democrats feel
more positively (below the line:    nancy pelosi   ,
   unions   ,    gun control   , etc.) and ones where re-
publicans feel more positive (   the pipeline   ,    gop
leadership   ,    budget cuts   , etc.). also, both enti-
ties are neutral towards    idea    and    the proposal   ,
which probably owes to the fact that ideas or pro-
posals can be good or bad for either entity depend-
ing on the context.

1.00.50.00.51.0democrat1.00.50.00.51.0republicanlawsuitsfundingbudget dealtax proposalabortionelephantmccainnancy pelosidelaying tacticsbacklashbiasmitt romneynrathe proposaljudicial nomineesstate departmentbill clintontheir principlesaidbig businessobamacaremarketrenominationgay marriagetraditionhealth care billbusinessthe pipelinetax cutsprinciplessmall businessesveto threatboehnerthe dream actgeorge w. bushideabusinessesbudget proposaltax increasespropositionspalinbarack obamathe allegationsenvironmentconstitutionkerrytax dealjobs billsmedicaregop leadershiphealthfloor voteunionsbudget cutsgun control5 related work
most prior work on sentiment lexicons focused on
the overall polarity of words without taking into
account their semantic arguments (wilson et al.,
2005; baccianella et al., 2010; wiebe et al., 2005;
velikovich et al., 2010b; kaji and kitsuregawa,
2007; kamps et al., 2004; takamura et al., 2005;
adreevskaia and bergler, 2006). several recent
studies began exploring more speci   c and nuanced
aspects of sentiment such as connotation (feng et
al., 2013), good and bad effects (choi and wiebe,
2014), and evoked sentiment (mohammad and tur-
ney, 2010). drawing inspirations from them, we
present connotation frames as a unifying represen-
tation framework to encode the rich dimensions of
implied sentiment, presupposed value judgements,
and effect evaluation, and propose a factor graph
formulation that captures the interplay among dif-
ferent types of connotation relations.

goyal et al. (2010a; 2010b) investigated how
characters (protagonists, villains, victims) in chil-
dren   s stories are affected by certain predicates,
which is related to the effect relations studied in this
work. while klenner et al. (2014) similarly investi-
gated the relation between the polarity of the verbs
and arguments, our work introduces new perspec-
tive types and proposes a uni   ed representation and
id136 model. wiegand and ruppenhofer (2015)
also looked at perspective-based relationships in-
duced by verb predicates with a focus on opinion
roles. building on this concept, our framework
also incorporates information about the perspec-
tives    polarities as well as information about other
typed relations. there have been growing interests
for modeling framing (greene and resnik, 2009;
hasan and ng, 2013), biased language (recasens
et al., 2013) and ideology detection (yano et al.,
2010). all these tasks are relatively less studied,
and we hope our connotation frame lexicon will be
useful for them.

sentiment id136 rules have been explored
by the recent work of wiebe and deng (2014)
and deng and wiebe (2014). the focus of their
work was on general id136 rules that are not
predicate-speci   c. in contrast, our work focuses
on the notion that connotative polarities can be de-
termined directly from the predicate, rather than
partial knowledge of the arguments or the context
in which it is being used.
in brief, we make a
novel conceptual connection between inferred sen-
timents and frame semantics, organized as conno-

tation frames, and present a uni   ed model that inte-
grates different aspects of the connotation frames.
finally, in a broader sense, what we study as
connotation frames draws a connection to schema
and script theory (schank and abelson, 1975). un-
like prior work that focused on directly observable
actions (chambers and jurafsky, 2009; frermann
et al., 2014; bethard et al., 2008), we focus on
implied sentiments that are framed by predicate
verbs.

6 conclusion
in this paper, we presented a novel system of
connotative frames that de   ne a set of implied
sentiment and presupposed facts for a predicate.
our work also empirically explores different meth-
ods of inducing and modelling these connotation
frames, incorporating the interplay between rela-
tions within frames. our work suggests new re-
search avenues on learning connotation frames,
and their applications to deeper understanding of
social and political discourse. all the learned
connotation frames and annotations are available
at http://homes.cs.washington.edu/
  hrashkin/connframe.html.
acknowledgements
we thank the anonymous reviewers for many in-
sightful comments. we also thank members of
uw nlp for discussions and support. this mate-
rial is based upon work supported by the national
science foundation graduate research fellowship
program under grant no. dge-1256082, in part
by nsf grants iis-1408287, iis-1524371, and gifts
by google and facebook.

references
alina adreevskaia and sabine bergler. 2006. mining
id138 for fuzzy sentiment: sentiment tag extrac-
in 11th conference of
tion from id138 glosses.
the european chapter of the association for com-
putational linguistics, pages 209   216.

cem akkaya, janyce wiebe, and rada mihalcea. 2009.
in pro-
subjectivity id51.
ceedings of the 2009 conference on empirical meth-
ods in natural language processing, volume 2,
pages 190   199.

stefano baccianella, andrea esuli, and fabrizio sebas-
tiani. 2010. sentiid138 3.0: an enhanced lexi-
cal resource for id31 and opinion min-
in proceedings of the seventh conference on
ing.

international language resources and evaluation
(lrec   10).

collin f baker, charles j fillmore, and john b lowe.
in proceed-
1998. the berkeley framenet project.
ings of the 17th international conference on compu-
tational linguistics, volume 1, pages 86   90.

steven bethard, william j corvey, sara klingenstein,
2008. building a corpus
and james h martin.
in proceedings of
of temporal-causal structure.
the sixth international conference on language re-
sources and evaluation (lrec   08).

center

for media

and democracy.
conservative

sourcewatch:
http://www.sourcewatch.org/index.
php/conservative_news_outlets.

news

2012.
outlets.

center

for media

and democracy.
liberal news outlets.

sourcewatch:
//www.sourcewatch.org/index.php/
liberal_news_outlets.

2013.
http:

nathanael chambers and dan jurafsky. 2009. unsu-
pervised learning of narrative schemas and their par-
ticipants. in proceedings of the joint conference of
the 47th annual meeting of the acl and the 4th in-
ternational joint conference on natural language
processing of the afnlp, volume 2 of acl    09,
pages 602   610.

yoonjung choi and janyce wiebe.

+/-
effectid138: sense-level lexicon acquisition for
opinion id136. in proceedings of the 2014 con-
ference on empirical methods in natural language
processing (emnlp), pages 1181   1191. associa-
tion for computational linguistics, october.

2014.

lingjia deng and janyce wiebe. 2014. sentiment
in pro-
propagation via implicature constraints.
ceedings of the conference of the european chap-
ter of the association for computational linguistics
(eacl).

song feng, jun seok kang, polina kuznetsova, and
yejin choi. 2013. connotation lexicon: a dash
of sentiment beneath the surface meaning. in pro-
ceedings of the 51st annual meeting of the asso-
ciation for computational linguistics (acl), vol-
ume 1, pages 1774   1784. association for compu-
tational linguistics.

charles j. fillmore. 1976. frame semantics and the
in in annals of the new york
nature of language.
academy of sciences: conference on the origin and
development of language and speech, volume 280,
pages 2032.

lea frermann, ivan titov, and manfred pinkal. 2014.
a hierarchical bayesian model for unsupervised in-
duction of script knowledge. in proceedings of the
conference of the european chapter of the associa-
tion for computational linguistics.

yoav goldberg and jon orwant. 2013. a dataset of
syntactic-ngrams over time from a very large corpus
in second joint conference on
of english books.
lexical and computational semantics (*sem), vol-
ume 1, pages 241   247, june.

amit goyal, ellen riloff, and hal daum  e, iii. 2010a.
automatically producing plot unit representations
for narrative text. in proceedings of the 2010 con-
ference on empirical methods in natural language
processing, proceedings of the 2010 conference on
empirical methods in natural language processing
(emnlp), pages 77   86.

amit goyal, ellen riloff, hal daum  e iii, and nathan
gilbert. 2010b. toward plot units: automatic affect
state analysis. in proceedings of hlt/naacl work-
shop on computational approaches to analysis and
generation of emotion in text (caet).

stephan greene and philip resnik. 2009. more than
words: syntactic packaging and implicit sentiment.
in proceedings of human language technologies:
the 2009 annual conference of the north american
chapter of the association for computational lin-
guistics, pages 503   511.

kazi saidul hasan and vincent ng. 2013. frame se-
mantics for stance classi   cation. proceedings of the
seventeenth conference on computational natural
language learning (conll), pages 124   132.

fritz heider. 1946. attitudes and cognitive organiza-

tion. the journal of psychology, 21(1):107   112.

hwc library. 2011. consider the source: a resource
guide to liberal, conservative, and nonpartisan
periodicals.
www.ccc.edu/colleges/
washington/departments/documents/
periodicalspov.pdf.
librarians in january 2011.

compiled by hwc

nobuhiro kaji and masaru kitsuregawa. 2007. build-
ing lexicon for id31 from massive col-
in proceedings of the
lection of html documents.
2007 joint conference on empirical methods in nat-
ural language processing and computational nat-
ural language learning (emnlp-conll), pages
1075   1083.

jaap kamps, maarten marx, robert j mokken, and
maarten de rijke. 2004. using id138 to mea-
in pro-
sure semantic orientations of adjectives.
ceedings of the fourth international conference on
language resources and evaluation(lrec   04), vol-
ume 4, pages 1115   1118.

trec kba.

2014. knowledge base accelera-
tion stream corpus. http://trec-kba.org/
kba-stream-corpus-2014.shtml.

manfred klenner, michael amsler, and nora hollen-
stein. 2014. verb polarity frames: a new resource
and its application in target-speci   c polarity classi-
   cation. in proceedings of konvens 2014, pages
106   115.

omer levy and yoav goldberg. 2014. dependency-
in proceedings of the
based id27s.
52nd annual meeting of the association for compu-
tational linguistics (acl), pages 302   308.

bing liu and lei zhang. 2012. a survey of opinion
mining and id31. in mining text data,
pages 415   463. springer.

amy mitchell,

jeffrey

gottfried,
and katerina eva matsa.

polarization

kiley,
political
www.journalism.org/2014/10/21/
political-polarization-media-habits/.
produced by pew research center in october, 2014.

& media

jocelyn
2014.
habits.

saif m mohammad and peter d turney. 2010. emo-
tions evoked by common words and phrases: using
mechanical turk to create an emotion lexicon.
in
proceedings of the naacl hlt 2010 workshop on
computational approaches to analysis and gener-
ation of emotion in text, pages 26   34. association
for computational linguistics.

courtney napoles, matthew gorid113y, and benjamin
in pro-
van durme. 2012. annotated gigaword.
ceedings of the joint workshop on automatic knowl-
edge base construction and web-scale knowledge
extraction, pages 95   100. association for computa-
tional linguistics.

martha palmer, daniel gildea, and paul kingsbury.
2005. the proposition bank: an annotated cor-
pus of semantic roles. computational linguistics,
31(1):71   106.

bo pang and lillian lee. 2008. opinion mining and
id31. foundations and trends in infor-
mation retrieval, 2(1-2):1   135.

marta recasens, cristian danescu-niculescu-mizil,
and dan jurafsky. 2013. linguistic models for an-
alyzing and detecting biased language. in proceed-
ings of the 51st annual meeting of the association
for computational linguistics (acl), pages 1650   
1659.

evan sandhaus. 2008. the new york times annotated
corpus. linguistic data consortium, philadelphia,
6(12):e26752.

roger c schank and robert p abelson. 1975. scripts,

plans, and knowledge. yale university.

swapna somasundaran and janyce wiebe. 2010. rec-
ognizing stances in ideological on-line debates. in
proceedings of the naacl hlt 2010 workshop on
computational approaches to analysis and genera-
tion of emotion in text, pages 116   124. association
for computational linguistics.

charles sutton and andrew mccallum. 2009. piece-
wise training for id170. machine
learning, 77(2):165   194.

hiroya takamura, takashi inui, and manabu okumura.
2005. extracting semantic orientations of words
in proceedings of 43rd annual
using spin model.
meeting of the association for computational lin-
guistics (acl).

matt thomas, bo pang, and lillian lee. 2006. get out
the vote: determining support or opposition from
congressional    oor-debate transcripts. in proceed-
ings of the 2006 conference on empirical methods
in natural language processing (emnlp), pages
327   335.

leonid velikovich, sasha blair-goldensohn, kerry
hannan, and ryan mcdonald. 2010a. the viabil-
ity of web-derived polarity lexicons. in human lan-
guage technologies: the 2010 annual conference
of the north american chapter of the association
for computational linguistics, hlt    10, pages 777   
785, stroudsburg, pa, usa. association for compu-
tational linguistics.

leonid velikovich, sasha blair-goldensohn, kerry
hannan, and ryan mcdonald. 2010b. the viabil-
ity of web-derived polarity lexicons. in human lan-
guage technologies: the 2010 annual conference
of the north american chapter of the association
for computational linguistics, hlt    10, pages 777   
785.

janyce wiebe and lingjia deng. 2014. an account of

opinion implicatures. corr, abs/1404.6491.

janyce wiebe, theresa wilson, and claire cardie.
2005. annotating expressions of opinions and emo-
tions in language. language resources and evalua-
tion, 39(2-3):165   210.

michael wiegand and josef ruppenhofer. 2015. opin-
ion holder and target extraction based on the in-
duction of verbal categories. proceedings of the
2015 conference on computational natural lan-
guage learning (conll), page 215.

theresa wilson, janyce wiebe, and paul hoffmann.
2005. recognizing contextual polarity in phrase-
level id31. in proceedings of the con-
ference on human language technology and empiri-
cal methods in natural language processing, pages
347   354.

tae yano, philip resnik, and noah a. smith. 2010.
shedding (a thousand points of) light on biased lan-
in proceedings of the naacl hlt 2010
guage.
workshop on creating speech and language data
with amazon   s mechanical turk, csldamt    10,
pages 152   158.

