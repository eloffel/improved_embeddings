proceedings of the 53rd annual meeting of the association for computational linguistics
and the 7th international joint conference on natural language processing, pages 53   62,

beijing, china, july 26-31, 2015. c(cid:13)2015 association for computational linguistics

53

textto3dscenegenerationwithrichlexicalgroundingangelchang   ,willmonroe   ,manolissavva,christopherpottsandchristopherd.manningstanforduniversity,stanford,ca94305{angelx,wmonroe4,msavva}@cs.stanford.edu,{cgpotts,manning}@stanford.eduabstracttheabilitytomapdescriptionsofscenesto3dgeometricrepresentationshasmanyapplicationsinareassuchasart,educa-tion,androbotics.however,priorworkonthetextto3dscenegenerationtaskhasusedmanuallyspeci   edobjectcate-goriesandlanguagethatidenti   esthem.weintroduceadatasetof3dscenesan-notatedwithnaturallanguagedescriptionsandlearnfromthisdatahowtogroundtex-tualdescriptionstophysicalobjects.ourmethodsuccessfullygroundsavarietyoflexicaltermstoconcretereferents,andweshowquantitativelythatourmethodim-proves3dscenegenerationoverprevi-ousworkusingpurelyrule-basedmeth-ods.weevaluatethe   delityandplau-sibilityof3dscenesgeneratedwithourgroundingapproachthroughhumanjudg-ments.toeaseevaluationonthistask,wealsointroduceanautomatedmetricthatstronglycorrelateswithhumanjudgments.1introductionweexaminethetaskoftextto3dscenegener-ation.theabilitytomapdescriptionsofscenesto3dgeometricrepresentationshasawidevari-etyofapplications;manycreativeindustriesuse3dscenes.roboticsapplicationsneedtointerpretcommandsreferringtoreal-worldenvironments,andtheabilitytovisualizescenariosgivenhigh-leveldescriptionsisofgreatpracticaluseineduca-tionaltools.unfortunately,3dscenedesignuserinterfacesareprohibitivelycomplexfornoviceusers.priorworkhasshownthetaskremainschal-lengingandtimeintensivefornon-experts,evenwithsimpli   edinterfaces(savvaetal.,2014).   the   rsttwoauthorsarelistedinalphabeticalorder.{...l-shaped room with walls that have 2 tones of gray...,a dark room with a pool table...}{...a multicolored table in the middle of the room ,...four red and white chairs and a colorful table, ...}figure1:welearnhowtogroundreferencessuchas   l-shapedroom   to3dmodelsinapairedcor-pusof3dscenesandnaturallanguagedescrip-tions.sentencefragmentsinboldwereidenti   edashigh-weightedreferencestotheshownobjects.languageoffersaconvenientwayfordesignerstoexpresstheircreativegoals.systemsthatcaninterpretnaturaldescriptionstobuildavisualrep-resentationallownon-expertstovisuallyexpresstheirthoughtswithlanguage,aswasdemonstratedbywordseye,apioneeringworkintextto3dscenegeneration(coyneandsproat,2001).wordseyeandotherpriorworkinthisarea(severskyandyin,2006;changetal.,2014)usedmanuallychosenmappingsbetweenlan-guageandobjectsinscenes.toourknowledge,wepresentthe   rst3dscenegenerationapproachthatlearnsfromdatahowtomaptextualtermstoobjects.first,wecollectadatasetof3dscenesalongwithtextualdescriptionsbypeople,whichwecontributetothecommunity.wethentrainaclassi   eronascenediscriminationtaskandextracthigh-weightfeaturesthatgroundlexicaltermsto3dmodels.weintegrateourlearnedlexicalgroundingswitharule-basedscenegener-ationapproach,andweshowthroughahuman-judgmentevaluationthatthecombinationoutper-formsbothapproachesinisolation.finally,weintroduceascenesimilaritymetricthatcorrelateswithhumanjudgments.54

 there is a desk and there is a notepad on the desk. there is a pen next to the notepad. scene templateinput texton(o0,o1)3d sceneo0roomon(o1,o2)parsingo0     category:room, modelid:420o1     category:desk, modelid:132o2     category:notepad, modelid:343o3     category:pen, modelid:144on(o1,o3)next_to(o3,o2)o1desko3peno2notepadgenerationfigure2:illustrationofthetextto3dscenegenerationpipeline.theinputistextdescribingascene(left),whichweparseintoanabstractscenetemplaterepresentationcapturingobjectsandrelations(mid-dle).thescenetemplateisthenusedtogenerateaconcrete3dscenevisualizingtheinputdescription(right).the3dsceneisconstructedbyretrievingandarrangingappropriate3dmodels.2taskdescriptioninthetextto3dscenegenerationtask,theinputisanaturallanguagedescription,andtheoutputisa3drepresentationofaplausiblescenethat   tsthedescriptionandcanbeviewedandrenderedfrommultipleperspectives.moreprecisely,givenanutterancexasinput,theoutputisasceney:anarrangementof3dmodelsrepresentingobjectsatspeci   edpositionsandorientationsinspace.inthispaper,wefocusonthesubproblemoflexicalgroundingoftextualtermsto3dmodelref-erents(i.e.,choosing3dmodelsthatrepresentob-jectsreferredtobytermsintheinpututterancex).weemployanintermediatescenetemplaterepre-sentationparsedfromtheinputtexttocapturethephysicalobjectspresentinasceneandconstraintsbetweenthem.thisrepresentationisthenusedtogeneratea3dscene(figure2).ana    veapproachtoscenegenerationmightusekeywordsearchtoretrieve3dmodels.how-ever,suchanapproachisunlikelytogeneralizewellinthatitfailstocaptureimportantobjectat-tributesandspatialrelations.inorderforthegen-eratedscenetoaccuratelyre   ecttheinputdescrip-tion,adeepunderstandingoflanguagedescrib-ingenvironmentsisnecessary.manychallengingsubproblemsneedtobetackled:physicalobjectmentiondetection,estimationofobjectattributessuchassize,extractionofspatialconstraints,andplacementofobjectsatappropriaterelativeposi-tionsandorientations.thesubproblemoflexicalgroundingto3dmodelshasalargedimpactonthequalityofgeneratedscenes,aslaterstagesofscenegenerationrelyonhavingacorrectlychosensetofobjectstoarrange.anotherchallengeisthatmuchcommonknowl-edgeaboutthephysicalpropertiesofobjectsandthestructureofenvironmentsisrarelymentionedinnaturallanguage(e.g.,thatmosttablesaresup-portedonthe   oorandinanuprightorienta-tion).unfortunately,common3drepresentationsofobjectsandscenesusedincomputergraph-icsspecifyonlygeometryandappearance,andrarelyincludesuchinformation.priorworkintextto3dscenegenerationfocusedoncollectingmanualannotationsofobjectpropertiesandrela-tions(rouhizadehetal.,2011;coyneetal.,2012),whichareusedtodriverule-basedgenerationsys-tems.regrettably,thetaskofscenegenerationhasnotyetbene   tedfromrecentrelatedworkinnlp.3relatedworkthereismuchpriorworkinimageretrievalgiventextualqueries;arecentoverviewisprovidedbysiddiquieetal.(2011).theimageretrievaltaskbearssomesimilaritytoourtaskinsofaras3dsceneretrievalisanapproachthatcanapprox-imate3dscenegeneration.however,therearefundamentaldifferencesbe-tween2dimagesand3dscenes.generationinimagespacehaspredominantlyfocusedoncom-positionofsimple2dclipartelements,asexem-pli   edrecentlybyzitnicketal.(2013).thetaskofcomposing3dscenespresentsamuchhigher-dimensionalsearchspaceofscenecon   gurationswhere   ndingplausibleanddesirablecon   gura-tionsisdif   cult.unlikepriorworkinclipartgen-erationwhichusesasmallpre-speci   edsetofob-jects,wegroundtoalargedatabaseofobjectsthatcanoccurinvariousindoorenvironments:124903dmodelsfromroughly270categories.55

there is a table and there are four chairs. there are four plates and there are four sandwiches.there is a chair and a table.there is a bed and there is anightstand next to the bed.    dinning room with four plates, four chairs, and four sandwiches    dark room with two small windows. a rectangular table seating four is in the middle of the room with plates set. there is a set of two gray double doors on another wall.    i see a rectangular table in the center of the room. there are 4 chairs around the table and 4 plates on the table    there is a chair and a circular table in the middle of a floral print room.    a corner widow room with a a table and chair sitting to the east side.    there's a dresser in the corner of the room, and a yellow table with a brown wooden chair.    there is a bed with three pillows and a bedside table next to it.    the room appears to be a bedroom. a blue bed and white nightstand are pushed against the furthest wall. a window is on the left side.    a dark bedroom with a queen bed with blue comforter and three pillows. there is a night stand. one wall is decorated with a large design and another wall has three large windows.figure3:scenescreatedbyparticipantsfromseeddescriptionsentences(top).additionaldescriptionsprovidedbyotherparticipantsfromthecreatedscene(bottom).ourdatasetcontainsaround19scenesperseedsentence,foratotalof1129scenes.scenesexhibitvariationinthespeci   cobjectschosenandtheirplacement.eachsceneisdescribedby3or4otherpeople,foratotalof4358descriptions.3.1texttoscenesystemspioneeringworkontheshrdlusystem(wino-grad,1972)demonstratedlinguisticmanipulationofobjectsin3dscenes.however,thedis-coursedomainwasrestrictedtoamicro-worldwithsimplegeometricshapestosimplifyparsingandgroundingofnaturallanguageinput.morere-cently,prototypetextto3dscenegenerationsys-temshavebeenbuiltforbroaderdomains,mostnotablythewordseyesystem(coyneandsproat,2001)andlaterworkbyseverskyandyin(2006).changetal.(2014)showeditispossibletolearnspatialpriorsforobjectsandrelationsdirectlyfrom3dscenedata.thesesystemsusemanuallyde   nedmappingsbetweenlanguageandtheirrepresentationofthephysicalworld.thispreventsgeneralizationtomorecomplexobjectdescriptions,variationsinwordchoiceandspelling,andotherlanguages.italsoforcesuserstouseunnaturallanguagetoex-presstheirintent(e.g.,thetableistwofeettothesouthofthewindow).weproposereducingrelianceonmanuallex-iconsbylearningtomapdescriptionstoobjectsfromacorpusof3dscenesandassociatedtextualdescriptions.whilewe   ndthatlexicalknowledgealoneisnotsuf   cienttogeneratehigh-qualityscenes,alearnedapproachtolexicalgroundingcanbeusedincombinationwitharule-basedsys-temforhandlingcompositionalknowledge,result-inginbetterscenesthaneithercomponentalone.3.2relatedtaskspriorworkhasgeneratedsentencesthatdescribe2dimages(farhadietal.,2010;kulkarnietal.,2011;karpathyetal.,2014)andreferringexpres-sionsforspeci   cobjectsinimages(fitzgeraldetal.,2013;kazemzadehetal.,2014).how-ever,generatingscenesiscurrentlyoutofreachforpurelyimage-basedapproaches.3dscenerep-resentationsserveasanintermediatelevelofstruc-turebetweenrawimagepixelsandsimplermicro-cosms(e.g.,gridandblockworlds).thislevelofstructureisamenabletothegenerationtaskbutstillrealisticenoughtopresentavarietyofchal-lengesassociatedwithnaturalscenes.arelatedlineofworkfocusesongroundingreferringexpressionstoreferentsin3dworldswithsimplecoloredgeometricshapes(gorniakandroy,2004;gorniakandroy,2005).morere-centworkgroundstexttoobjectattributessuchascolorandshapeinimages(matuszeketal.,2012;krishnamurthyandkollar,2013).gollandetal.(2010)groundspatialrelationshiplanguagein3dscenes(e.g.,totheleftof,behind)bylearningfrompairwiseobjectrelationsprovidedbycrowd-workers.incontrast,wegroundgeneraldescrip-tionstoawidevarietyofpossibleobjects.theobjectsinourscenesrepresentabroaderspaceofpossiblereferentsthanthe   rsttwolinesofwork.unlikethelatterwork,ourdescriptionsarepro-videdasunrestrictedfree-formtext,ratherthan   llinginspeci   ctemplatesofobjectreferencesand   xedspatialrelationships.56

4datasetweintroduceanewdatasetof1128scenesand4284free-formnaturallanguagedescriptionsofthesescenes.1tocreatethistrainingset,weusedasimpleonlinescenedesigninterfacethatallowsuserstoassemblescenesusingavailable3dmodelsofcommonhouseholdobjects(eachmodelisannotatedwithacategorylabelandhasauniqueid).weusedasetof60seedsentencesdescribingsimplecon   gurationsofinteriorscenesaspromptsandaskedworkersontheamazonmechanicalturkid104platformtocre-atescenescorrespondingtotheseseeddescrip-tions.toobtainmorevarieddescriptionsforeachscene,weaskedotherworkerstodescribeeachscene.figure3showsexamplesofseeddescrip-tionsentences,3dscenescreatedbypeoplegiventhosedescriptions,andnewdescriptionsprovidedbyothersviewingthecreatedscenes.wemanuallyexaminedarandomsubsetofthedescriptions(approximately10%)toelimi-natespamandunacceptablypoordescriptions.whenweidenti   edanunacceptabledescription,wealsoexaminedallotherdescriptionsbythesameworker,asmostpoordescriptionscamefromasmallnumberofworkers.fromoursample,weestimatethatlessthan3%ofdescriptionswerespamorunacceptablyincoherent.tore   ectnat-uraluse,weretainedminortypographicalandgrammaticalerrors.despitethesmallsetofseedsentences,theturker-providedscenesexhibitmuchvarietyinthespeci   cobjectsusedandtheirplacementswithinthescene.over600distinct3dmodelsappearinatleastonescene,andmorethan40%ofnon-roomobjectsarerotatedfromtheirdefaultorienta-tion,despitethefactthatthisrequiresanextrama-nipulationinthescene-buildinginterface.thede-scriptionscollectedforthesescenesaresimilarlydiverseandusuallydiffersubstantiallyinlengthandcontentfromtheseedsentences.25modeltocreateamodelforgeneratingscenetemplatesfromtext,wetrainaclassi   ertolearnlexical1availableathttp://nlp.stanford.edu/data/text2scene.shtml.2mean26.2words,sd17.4;versusmean16.6,sd7.2fortheseedsentences.ifoneconsidersseedsentencestobethe   reference,   themacro-averagedid7score(papinenietal.,2002)oftheturkerdescriptionsis12.0.groundings.wethencombineourlearnedlexi-calgroundingswitharule-basedscenegenerationmodel.thelearnedgroundingsallowustoselectbettermodels,whiletherule-basedmodelofferssimplecompositionalityforhandlingcoreferenceandrelationshipsbetweenobjects.5.1learninglexicalgroundingstolearnlexicalmappingsfromexamples,wetrainaclassi   eronarelatedgroundingtaskandex-tracttheweightsoflexicalfeaturesforuseinscenegeneration.thisclassi   erlearnsfroma   discrim-ination   versionofourscenedataset,inwhichthesceneineachscene   descriptionpairishid-denamongfourotherdistractorscenessampleduniformlyatrandom.thetrainingobjectiveistomaximizethel2-regularizedloglikelihoodofthisscenediscriminationdatasetunderaone-vs.-alllogisticregressionmodel,usingeachtruesceneandeachdistractorsceneasoneexample(withtrue/distractorastheoutputlabel).thelearnedmodelusesbinary-valuedfea-turesindicatingtheco-occurrenceofaunigramorbigramandanobjectcategoryormodelid.forexample,featuresextractedfromthescene-descriptionpairshowninfigure2wouldincludethetuples(desk,modelid:132)and(thenotepad,category:notepad).toevaluateourlearnedmodel   sperformanceatdiscriminatingscenes,independentlyofitsuseinscenegeneration,wesplitoursceneanddescrip-tioncorpus(augmentedwithdistractorscenes)randomlyintotrain,development,andtestpor-tions70%-15%-15%byscene.usingonlymodelidfeatures,theclassi   erachievesadiscrimina-tionaccuracyof0.715onthetestset;addingfea-turesthatuseobjectcategoriesaswellasmodelidsimprovesaccuracyto0.833.5.2rule-basedmodelweusetherule-basedparsingcomponentde-scribedinchangetal.(2014).thissystemin-corporatesknowledgethatisimportantforscenegenerationandnotaddressedbyourlearnedmodel(e.g.,spatialrelationshipsandcoreference).insection5.3,wedescribehowweuseourlearnedmodeltoaugmentthismodel.thisrule-basedapproachisathree-stagepro-cessusingestablishednlpsystems:1)theinputtextissplitintomultiplesentencesandparsedus-ingthestanfordcorenlppipeline(manninget57

red cupround yellow tablegreen roomblack toptan love seatblack bedopen windowfigure4:someexamplesextractedfromthetop20highest-weightfeaturesinourlearnedmodel:lexicaltermsfromthedescriptionsinourscenecorpusaregroundedto3dmodelswithinthescenecorpus.al.,2014).headwordsofnounphrasesareiden-ti   edascandidateobjectcategories,   lteredusingid138(miller,1995)toonlyincludephysicalobjects.2)referencestothesameobjectarecol-lapsedusingthestanfordcoreferencesystem.3)propertiesareattachedtoeachobjectbyextract-ingotheradjectivesandnounsinthenounphrase.thesepropertiesarelaterusedtoquerythe3dmodeldatabase.weusethesamemodeldatabaseaschangetal.(2014)andalsoextractspatialrelationsbetweenobjectsusingthesamesetofdependencypatterns.5.3combinedmodeltherule-basedparsingmodelislimitedinitsabil-itytochooseappropriate3dmodels.weintegrateourlearnedlexicalgroundingswiththismodeltobuildanimprovedscenegenerationsystem.identifyingobjectcategoriesusingtherule-basedmodel,weextractallnounphrasesaspo-tentialobjects.foreachnounphrasep,weextractfeatures{  i}andcomputethescoreofacategorycbeingdescribedbythenounphraseasthesumofthefeatureweightsfromthelearnedmodelinsection5.1:score(c|p)=     i     (p)  (i,c),where  (i,c)istheweightforassociatingfeature  iwithcategoryc.fromcategorieswithascorehigherthantc=0.5,weselectthebest-scoringcategoryastherepresentativeforthenounphrase.ifnocategory   sscoreexceedstc,weusetheheadofthenounphrasefortheobjectcategory.3dmodelselectionforeachobjectmentiondetectedinthedescription,weusethefeatureweightsfromthelearnedmodeltoselectaspeci   cobjecttoaddtothescene.afterusingdependencyrulestoextractspatialrelationshipsanddescrip-tivetermsassociatedwiththeobject,wecomputethescoreofa3dmodelmgiventhecategorycandtextcategorytextcategorychairchairroundroundtablelamplamplaptoplaptopcouchcouchfruitbowlvasevaseroundtableroundtablesofacouchlaptopcomputerbedbedbookshelfbookcasetable1:topgroundingsoflexicaltermsinourdatasettocategoriesof3dmodelsinthescenes.asetofdescriptivetermsdusingasimilarsumoffeatureweights.astherule-basedsystemmaynotaccuratelyidentifythecorrectsetoftermsd,weaugmentthescorewithasumoffeatureweightsovertheentireinputdescriptionx:m=argmaxm   {c}  d     i     (d)  (i,m)+  x     i     (x)  (i,m)fortheresultsshownhere,  d=0.75and  x=0.25.weselectthebest-scoring3dmodelwithpositivescore.ifnomodelhaspositivescore,weassumetheobjectmentionwasspuriousandomittheobject.6learnedlexicalgroundingsbyextractinghigh-weightfeaturesfromourlearnedmodel,wecanvisualizespeci   cmodelstowhichlexicaltermsaregrounded(seefigure4).thesefeaturescorrespondtohighfrequencytext   3dmodelpairswithinthescenecorpus.table1showssomeofthetoplearnedlexicalground-ingstomodeldatabasecategories.weareabletorecovermanysimpleidentitymappingswith-outusinglexicalsimilarityfeatures,andwecap-tureseverallexicalvariants(e.g.,sofaforcouch).afewerroneousmappingsre   ectcommonco-occurrences;forexample,fruitismappedtobowlduetofruittypicallybeingobservedinbowlsinourdataset.58

descriptionin between the doors and the window, there is a black couch with red cushions, two white pillows, and one black pillow. in front of the couch, there is a wooden coffee table with a glass top and two newspapers. next to the table, facing the couch, is a wooden folding chair.randomrulelearnedcomboa round table is in the center of the room with four chairs around the table. there is a double window facing west. a door is on the east side of the room.there is a desk and a computer.seed sentence:mturk sentences:figure5:qualitativecomparisonofgeneratedscenesforthreeinputdescriptions(oneseedandtwomturk),usingthefourdifferentmethods:random,learned,rule,combo.7experimentalresultsweconductahumanjudgmentexperimenttocomparethequalityofgeneratedscenesusingtheapproacheswepresentedandbaselinemethods.toevaluatewhetherlexicalgroundingimprovesscenegeneration,weneedamethodtoarrangethechosenmodelsinto3dscenes.since3dscenelayoutisnotafocusofourwork,weuseanap-proachbasedonpriorworkin3dscenesynthesisandtexttoscenegeneration(fisheretal.,2012;changetal.,2014),simpli   edbyusingsamplingratherthanahillclimbingstrategy.conditionswecompare   veconditions:{random,learned,rule,combo,human}.therandomconditionrepresentsabaselinewhichsynthesizesascenewithrandomly-selectedmodels,whilehumanrepresentsscenescreatedbypeople.thelearnedconditiontakesourlearnedlexicalgroundings,picksthefour3mostlikelyobjects,andgeneratesascenebasedonthem.theruleandcomboconditionsusescenesgeneratedbytherule-basedapproachandthecombinedmodel,respectively.descriptionsweconsidertwosetsofinputde-scriptions:{seeds,mturk}.theseedsdescrip-tionsare50oftheinitialseedsentencesfromwhichworkerswereaskedtocreatescenes.theseseedsentencesweresimple(e.g.,thereisadesk3theaveragenumberofobjectsinasceneinourhuman-builtdatasetwas3.9.andachair,thereisaplateonatable)anddidnothavemodi   ersdescribingtheobjects.themturkdescriptionsaremuchmoredescriptiveandexhibitawidervarietyinlanguage(includingmis-spellingsandungrammaticalconstructs).ourhy-pothesiswasthattherule-basedsystemwouldper-formwellonthesimpleseedsdescriptions,butitwouldbeinsuf   cientforhandlingthecomplexi-tiesofthemorevariedmturkdescriptions.forthesemorenaturaldescriptions,weexpectedourcombinationmodeltoperformbetter.ourexperi-mentalresultscon   rmthishypothesis.7.1qualitativeevaluationfigure5showsaqualitativecomparisonof3dscenesgeneratedfromexampleinputdescriptionsusingeachofthefourmethods.inthetoprow,therule-basedapproachselectsacpuchassisforcomputer,whilecomboandlearnedselectamoreiconicmonitor.inthebottomrow,therule-basedapproachselectstwonewspapersandplacesthemonthe   oor,whilethecombinedapproachcor-rectlyselectsacoffeetablewithtwonewspapersonit.thelearnedmodelislimitedtofourobjectsanddoesnothaveanotionofobjectidentity,soitoftenduplicatesobjects.7.2humanevaluationweperformedanexperimentinwhichpeopleratedthedegreetowhichscenesmatchthetex-tualdescriptionsfromwhichtheyweregenerated.59

figure6:screenshotoftheuiforratingscene-descriptionmatch.suchratingsareanaturalwaytoevaluatehowwellourapproachcangeneratescenesfromtext:inpracticaluse,apersonwouldprovideaninputdescriptionandthenjudgethesuitabilityofthere-sultingscenes.forthemturkdescriptions,werandomlysampled100descriptionsfromthede-velopmentsplitofourdataset.procedureduringtheexperiment,eachpartici-pantwasshown30pairsofscenedescriptionsandgenerated3dscenesdrawnrandomlyfromall   veconditions.allparticipantsprovided30responseseachforatotalof5040scene-descriptionratings.participantswereaskedtoratehowwellthegen-eratedscenematchedtheinputdescriptionona7-pointlikertscale,with1indicatingapoormatchand7averygoodone(seefigure6).inasep-aratetaskwiththesameexperimentalprocedure,weaskedotherparticipantstoratetheoverallplau-sibilityofeachgeneratedscenewithoutarefer-encedescription.thisplausibilityratingmeasureswhetheramethodcangenerateplausiblescenesirrespectiveofthedegreetowhichtheinputde-scriptionismatched.weusedamazonmechan-icalturktorecruit168participantsforratingthematchofscenestodescriptionsand63participantsforratingsceneplausibility.designtheexperimentfollowedawithin-subjectsfactorialdesign.thedependentmeasurewasthelikertrating.sinceper-participantandper-scenevarianceontheratingisnotaccountedforbyastandardanova,weuseamixedeffectsmodelwhichcanaccountforboth   xedeffectsandrandomeffectstodeterminethestatisticalsigni   -methodseedsmturkrandom2.03(1.88   2.18)1.68(1.57   1.79)learned3.51(3.23   3.77)2.61(2.40   2.84)rule5.44(5.26   5.61)3.15(2.91   3.40)combo5.23(4.96   5.44)3.73(3.48   3.95)human6.06(5.90   6.19)5.87(5.74   6.00)table2:averagescene-descriptionmatchratingsacrosssentencetypesandmethods(95%c.i.).canceofourresults.4wetreattheparticipantandthespeci   csceneasrandomeffectsofvaryingin-tercept,andthemethodconditionasthe   xedef-fect.resultstherewasasigni   canteffectofthemethodconditiononthescene-descriptionmatchrating:  2(4,n=5040)=1378.2,p<0.001.table2summarizestheaveragescene-descriptionmatchratingsand95%con   denceintervalsforallsentencetype   conditionpairs.allpairwisedifferencesbetweenratingsweresigni   cantun-derwilcoxonrank-sumtestswiththebonferroni-holmcorrection(p<0.05).thesceneplausibilityratings,whichwereobtainedindependentofde-scriptions,indicatedthattheonlysigni   cantdif-ferenceinplausibilitywasbetweenscenescre-atedbypeople(human)andalltheothercondi-tions.weseethatforthesimpleseedsentencesboththerule-basedandcombinedmodelapproachthequalityofhuman-createdscenes.however,allmethodshavesigni   cantlylowerratingsforthemorecomplexmturksentences.inthismorechallengingscenario,thecombinedmodelisclos-esttothemanuallycreatedscenesandsigni   -cantlyoutperformsbothrule-basedandlearnedmodelsinisolation.7.3erroranalysisfigure7showssomecommonerrorcasesinoursystem.thetopleftscenewasgeneratedwiththerule-basedmethod,thetoprightwiththelearnedmethod,andthebottomtwowiththecombinedapproach.atthetopleft,thereisanerroneousselectionofconcreteobjectcategory(woodlogs)forthefourwoodchairsreferenceintheinputdescription,duetoanincorrectheadidenti   ca-tion.attopright,thelearnedmodelidenti   esthe4weusedthelme4rpackageandoptimized   twithmaximumlog-likelihood(baayenetal.,2008).wereportsigni   canceresultsusingthelikelihood-ratio(lr)test.60

figure7:commonscenegenerationerrors.fromtopleftclockwise:woodtableandfourwoodchairsinthecenteroftheroom;thereisablackandbrowndeskwithatablelampand   owers;thereisawhitedesk,ablackchair,andalampinthecorneroftheroom;thereinthemiddleisatable,onthetableisacup.presenceofbrowndeskandlampbuterroneouslypickstwodesksandtwolamps(sincewealwayspickthetopfourobjects).thesceneonthebot-tomrightdoesnotobeytheexpressedspatialcon-straints(inthecorneroftheroom)sinceoursys-temdoesnotunderstandthegroundingofroomcornerandthatthetoprightsideisnotagood   tduetothedoor.inthebottoid113ft,incorrectcoref-erenceresolutionresultsintwotablesforthereinthemiddleisatable,onthetableisacup.7.4scenesimilaritymetricweintroduceanautomatedmetricforscoringscenesgivenascenetemplaterepresentation,thealignedscenetemplatesimilarity(asts).givenaone-to-onealignmentabetweenthenodesofascenetemplateandtheobjectsinascene,letthealignmentpenaltyj(a)bethesumofthenumberofunalignednodesinthescenetemplateandthenumberofunalignedobjectsinthescene.forthealignednodes,wecomputeasimilarityscorespernodepair(n,n   )wheres(n,n   )=1ifthemodelidmatches,s(n,n   )=0.5ifonlythecategorymatchesand0otherwise.wede   netheastsofascenewithrespecttoascenetemplatetobethemaximumalignmentmethodhumanastsrandom1.680.08learned2.610.23rule3.150.32combo3.730.44table3:averagehumanratings(outof7)andalignedscenetemplatesimilarityscores.scoreoverallsuchalignments:asts(s,z)=maxa   (n,n   )   as(n,n   )j(a)+|a|.withthisde   nition,wecompareaverageastsscoresforeachmethodagainstaveragehumanrat-ings(table3).wetestthecorrelationoftheastsmetricagainsthumanratingsusingpearson   srandkendall   srankcorrelationcoef   cientr  .we   ndthatastsandhumanratingsarestronglycor-related(r=0.70,r  =0.49,p<0.001).thissuggestsastsscorescouldbeusedtotrainandalgorithmicallyevaluatescenegenerationsystemsthatmapdescriptionstoscenetemplates.8futureworkmanyerrorcasesinourgeneratedscenesresultedfromnotinterpretingspatialrelations.anobvi-ousimprovementwouldbetoexpandourlearnedlexicalgroundingapproachtoincludespatialrela-tions.thiswouldhelpwithspatiallanguagethatisnothandledbytherule-basedsystem   sdepen-dencypatterns(e.g.,around,between,ontheeastside).oneapproachwouldbetoaddspatialcon-straintstothede   nitionofourscenesimilarityscoreandusethisimprovedmetricintrainingasemanticparsertogeneratescenetemplates.tochooseobjects,ourcurrentsystemusesinformationobtainedfromlanguage   objectco-occurrencesandsparsemanually-annotatedcate-gorylabels;anotherpromisingavenueforachiev-ingbetterlexicalgroundingistopropagatecate-gorylabelsusinggeometricandimagefeaturestolearnthecategoriesofunlabeledobjects.novelcategoriescanalsobeextractedfromturkerde-scriptions.thesenewlabelscouldbeusedtoim-provetheannotationsinour3dmodeldatabase,enablingawiderrangeofobjecttypestobeusedinscenegeneration.61

ourapproachlearnsobjectreferenceswithoutusinglexicalsimilarityfeaturesoramanually-assembledlexicon.thus,weexpectthatourmethodforlexicalgroundingcanfacilitatede-velopmentoftext-to-scenesystemsinotherlan-guages.however,additionaldatacollectionandexperimentsarenecessarytocon   rmthisandidentifychallengesspeci   ctootherlanguages.thenecessityofhandlingomittedinformationsuggeststhatamodelincorporatingamoreso-phisticatedtheoryofpragmaticid136couldbebene   cial.anotherimportantproblemnotad-dressedhereistheroleofcontextanddiscourseininterpretingscenedescriptions.forexample,severalofourcollecteddescriptionsincludelan-guageimaginingembodiedpresenceinthescene(e.g.,thewoodentableistoyourright,ifyou   reenteringtheroomfromthedoors).9conclusionpriorworkin3dscenegenerationreliesonpurelyrule-basedmethodstomapobjectreferencestoconcrete3dobjects.weintroduceadatasetof3dscenesannotatedwithnaturallanguagedescrip-tionswhichwebelievewillbeofgreatinteresttotheresearchcommunity.usingthiscorpusofscenesanddescriptions,wepresentanapproachthatlearnsfromdatahowtogroundtextualde-scriptionstoobjects.toevaluatehowourgroundingapproachim-pactsgeneratedscenequality,wecollecthumanjudgmentsofgeneratedscenes.inaddition,wepresentametricforautomaticallycomparinggen-eratedscenetemplatestoscenes,andweshowthatitcorrelatesstronglywithhumanjudgments.wedemonstratethatrichlexicalgroundingcanbelearneddirectlyfromanunalignedcorpusof3dscenesandnaturallanguagedescriptions,andthatourmodelcansuccessfullygroundlexicaltermstoconcretereferents,improvingscenegen-erationoverbaselinesadaptedfrompriorwork.acknowledgmentswethankkatherinebreedenforvaluablefeed-back.theauthorsgratefullyacknowledgethesup-portofthedefenseadvancedresearchprojectsagency(darpa)deepexplorationandfilter-ingoftext(deft)programunderairforcere-searchlaboratory(afrl)contractno.fa8750-13-2-0040,thenationalsciencefoundationun-dergrantno.iis1159679,thedepartmentofthenavy,of   ceofnavalresearch,undergrantno.n00014-10-1-0109,andthestanfordgrad-uatefellowshipfund.anyopinions,   ndings,andconclusionsorrecommendationsexpressedinthismaterialarethoseoftheauthorsanddonotnecessarilyre   ecttheviewsofthenationalsci-encefoundation,theof   ceofnavalresearch,darpa,afrl,ortheusgovernment.referencesr.h.baayen,d.j.davidson,andd.m.bates.2008.mixed-effectsmodelingwithcrossedrandomeffectsforsubjectsanditems.journalofmemoryandlan-guage,59(4):390   412.angelx.chang,manolissavva,andchristopherd.manning.2014.learningspatialknowledgefortextto3dscenegeneration.inproceedingsofempiricalmethodsinnaturallanguageprocessing(emnlp).bobcoyneandrichardsproat.2001.wordseye:anautomatictext-to-sceneconversionsystem.inpro-ceedingsofthe28thannualconferenceoncom-putergraphicsandinteractivetechniques.bobcoyne,alexanderklapheke,masoudrouhizadeh,richardsproat,anddanielbauer.2012.annotationtoolsandknowledgerepresen-tationforatext-to-scenesystem.proceedingsofcoling2012:technicalpapers.alifarhadi,mohsenhejrati,mohammadaminsadeghi,peteryoung,cyrusrashtchian,juliahockenmaier,anddavidforsyth.2010.everypic-turetellsastory:generatingsentencesfromimages.incomputervision   eccv2010.matthewfisher,danielritchie,manolissavva,thomasfunkhouser,andpathanrahan.2012.example-basedsynthesisof3dobjectarrange-ments.acmtransactionsongraphics(tog),31(6):135.nicholasfitzgerald,yoavartzi,andlukezettle-moyer.2013.learningdistributionsoverlogicalformsforreferringexpressiongeneration.inpro-ceedingsofempiricalmethodsinnaturallanguageprocessing(emnlp).davegolland,percyliang,anddanklein.2010.agame-theoreticapproachtogeneratingspatialde-scriptions.inproceedingsofempiricalmethodsinnaturallanguageprocessing(emnlp).petergorniakanddebroy.2004.groundedsemanticcompositionforvisualscenes.journalofarti   cialintelligenceresearch(jair),21(1):429   470.petergorniakanddebroy.2005.probabilisticgroundingofsituatedspeechusingplanrecognitionandreferenceresolution.inproceedingsofthe7thinternationalconferenceonmultimodalinterfaces.62

andrejkarpathy,armandjoulin,andlifei-fei.2014.deepfragmentembeddingsforbidirectionalimagesentencemapping.inadvancesinneuralinforma-tionprocessingsystems.saharkazemzadeh,vicenteordonez,markmatten,andtamaral.berg.2014.referitgame:refer-ringtoobjectsinphotographsofnaturalscenes.inproceedingsofempiricalmethodsinnaturallan-guageprocessing(emnlp).jayantkrishnamurthyandthomaskollar.2013.jointlylearningtoparseandperceive:connectingnaturallanguagetothephysicalworld.transac-tionsoftheassociationforcomputationallinguis-tics,1:193   206.girishkulkarni,visruthpremraj,sagnikdhar,simingli,yejinchoi,alexanderc.berg,andtamaral.berg.2011.babytalk:understandingandgener-atingsimpleimagedescriptions.inieeeconfer-enceoncomputervisionandpatternrecognition(cvpr).christopherd.manning,mihaisurdeanu,johnbauer,jennyfinkel,stevenj.bethard,anddavidmc-closky.2014.thestanfordcorenlpnaturallan-guageprocessingtoolkit.inproceedingsofthe52ndannualmeetingoftheassociationforcom-putationallinguistics:systemdemonstrations.cynthiamatuszek,nicholasfitzgerald,lukezettle-moyer,liefengbo,anddieterfox.2012.ajointmodeloflanguageandperceptionforgroundedat-tributelearning.ininternationalconferenceonma-chinelearning(icml).georgea.miller.1995.id138:alexicaldatabaseforenglish.communicationsoftheacm,38(11):39   41.kishorepapineni,salimroukos,toddward,andwei-jingzhu.2002.id7:amethodforautomaticevaluationofmachinetranslation.inproceedingsofthe40thannualmeetingoftheassociationforcomputationallinguistics.masoudrouhizadeh,margitbowler,richardsproat,andbobcoyne.2011.collectingsemanticdatabymechanicalturkforthelexicalknowledgeresourceofatext-to-picturegeneratingsystem.inproceed-ingsoftheninthinternationalconferenceoncom-putationalsemantics.manolissavva,angelx.chang,gilbertbernstein,christopherd.manning,andpathanrahan.2014.onbeingtherightscale:sizinglargecollectionsof3dmodels.insiggraphasia2014workshoponindoorsceneunderstanding:wheregraphicsmeetsvision.leem.severskyandlijunyin.2006.real-timeau-tomatic3dscenegenerationfromnaturallanguagevoiceandtextdescriptions.inproceedingsofthe14thannualacminternationalconferenceonmul-timedia.behjatsiddiquie,rog  erioschmidtferis,andlarrys.davis.2011.imagerankingandretrievalbasedonmulti-attributequeries.inieeeconferenceoncomputervisionandpatternrecognition(cvpr).terrywinograd.1972.understandingnaturallan-guage.cognitivepsychology,3(1):1   191.c.lawrencezitnick,deviparikh,andlucyvander-wende.2013.learningthevisualinterpretationofsentences.inieeeinternationalconferenceoncomputervision(iccv).