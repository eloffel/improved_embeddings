5
1
0
2

 

y
a
m
0
1

 

 
 
]
l
c
.
s
c
[
 
 

1
v
5
2
4
2
0

.

5
0
5
1
:
v
i
x
r
a

fast rhetorical structure theory discourse parsing

michael heilman

educational testing service

princeton, nj, usa

mheilman@ets.org

kenji sagae

institute for creative technologies
university of southern california

los angeles, ca, usa
sagae@ict.usc.edu

1 introduction

in recent years, there has been a variety of research
on discourse parsing, particularly rst discourse
parsing (feng and hirst, 2014; li et al., 2014b; ji
and eisenstein, 2014; joty and moschitti, 2014; li et
al., 2014a). most of the recent work on rst parsing
has focused on implementing new types of features
or learning algorithms in order to improve accuracy,
with relatively little focus on ef   ciency, robustness,
or practical use. also, most implementations are not
widely available.

here, we describe an rst segmentation and pars-
ing system that adapts models and feature sets from
various previous work, as described below. its ac-
curacy is near state-of-the-art, and it was developed
to be fast, robust, and practical. for example, it can
process short documents such as news articles or es-
says in less than a second.

the system is written in python and is
https://github.

publicly
com/educationaltestingservice/
discourse-parsing.

available

at

2 tasks and data

we address two tasks in this work: discourse seg-
mentation and discourse parsing. discourse seg-
mentation is the task of taking a sequence of word
and punctuation tokens as input and identifying
boundaries where new discourse units begin. dis-
course parsing is the task of taking a sequence of dis-
course units and identifying relationships between
them. in our case, the set of these relationships form
a tree.

for both, we follow the conventions encoded in
the rst discourse treebank (carlson et al., 2002).
here, we give a brief overview of the corpus. see
carlson et al. (2001) for more information.

the treebank uses a representation where dis-
course is represented as a tree, with labels on nodes
indicating relationships between siblings. most rst
relationships have a nucleus, expressing the core
content, and a satellite that contributes additional
information to the nucleus. probably the simplest
example is the    attribution    relationship: attributed
(e.g., quoted) text is labeled as the nucleus, and text
indicating the source of the attributed text is labeled
as the satellite, with an    attribution    subcategoriza-
tion.

the leaves of the rst trees are    elementary dis-
course units    (edus), which are contiguous spans
of tokens roughly similar to indepedent clauses.
most branching in rst trees is binary, with one
satellite and one nucleus, though there are some rela-
tions that have multiple nuclei and no satellite (e.g.,
lists).

the rst corpus consists of a training set of 347
documents and a test set of 38 documents. the texts
in the rst treebank are a subset of those in the penn
treebank (marcus et al., 1993). for this reason,
we retrained the syntactic parser used in our sys-
tem, zpar (zhang and clark, 2011), on the subset
of the id32 wsj sections 2 to 21 texts not
present in the rst treebank.

for development of the system, we split the train-
ing set into a smaller subset for model estimation
and a development validation set similar in size (n =
40) to the rst treebank test set.

3 discourse segmenter description

in this section, we describe and evaluate the dis-
course segmentation component of the system. our
discourse segmenter is essentially a reimplementa-
tion of the baseline system from xuan bach et al.
(2012). we do not implement their reranked model,
which is more complex to implement and probably
less ef   cient, and we use the zpar parser (zhang and
clark, 2011) for automatic syntactic parsing.

3.1 segmenter model and features
following xuan bach et al. (2012), we model rst
as a tagging problem. speci   cally, for each token
in a sentence, the system predicts whether that to-
ken is the beginning of a new edu or the contin-
uation of an edu. for this task, we use a condi-
tional random    eld (lafferty et al., 2001) model with
   2 id173, using the crf++ implementation
(https://crfpp.googlecode.com). also,
we assume that a new sentence always starts a new
edu, regardless of the crf output.

the crf uses simple word and pos features as
well as syntactic features. the word and pos fea-
tures are as follows (note that by    word   , we mean
word or punctuation token):

    the lowercased form of the current word

    the part-of-speech (pos) of the current word

the syntactic features are based on automatic
parses from zpar (using a retrained model as dis-
cussed in   2). for each of the following nodes in
the syntactic tree, there are two features, one for the
nonterminal symbol and the head word (e.g.,    vp,
said   ), and one for the nonterminal symbol and the
head pos (e.g.,    vp, vbd   ). note that these fea-
tures will not be used for the last token in a sentence
since there is no subsequent token.

    np: the    rst common ancestor of the current

token and the subsequent word

    the subtree of np that contains the current word
    the subtree of np that contains the subsequent

word

    the parent of np
    the right sibling of np

crfseg
bach-etal-2012 (base)
bach-etal-2012 (reranking)
our system
human agreement

p
91.0
91.4
91.5
90.2
98.5

r
87.2
90.1
90.4
83.5
98.2

f1
89.0
90.7
91.0
86.7
98.3

table 1: discourse segmentation performance in terms
of percentages precision (   p   ), recall (   r   ), and f1 score
(   f1   ) for the    b-edu    tag.

all of these features are extracted for the current
word, the previous 2 words, and next 2 words in the
sentence.

3.2 segmenter evaluation
following xuan bach et al. (2012), we evaluate
segmentation performance using the gold standard
edus from the rst treebank test set, using the f1
score for the tag indicating the beginning of a new
edu (   b-edu   ). since new sentences always be-
gin new edus, we exclude the    rst tag in the output
(always    b-edu   ) for each sentence. we    rst tuned
the crf id173 parameter using grid search
on the split of the training set used for development
evaluations, using a grid of powers of 2 ranging from
1/64 to 64.

the results are shown in table 1. for compari-
son, we include previous results, including human-
human agreement, reported by xuan bach et al.
(2012), using syntax from the stanford parser (klein
and manning, 2003a) (it is not clear from the paper
what parsing model was used). the    crfseg    re-
sults are for the system from hernault et al. (2010).
we are uncertain as to the cause for the observed
differences in performance, though we hypothesize
that the differences are at least partially due to dif-
ferences in syntactic parsing, which is a key step in
feature computation.

4 discourse parser description

in this section, we describe our rst parser.
it
borrows extensively from previous work, especially
sagae (2009).1

1note that we do not include sagae (2009) in our evaluations
since only within-sentence parsing performance was reported in
that paper.

4.1 shift-reduce approach

    the previous action (e.g.,    binary reduce to

following sagae (2009) and ji and eisenstein
(2014), we use an    arc standard    shift-reduce ap-
proach to rst discourse parsing.

4.2 parsing model

the parser maintains two primary data structures:
a queue containing the edus in the document that
have not been processed yet, and a stack of rst
subtrees that will eventually be combined to form
a complete tree.

initially,

the stack is empty and all edus are
placed in the queue. until a complete tree is found
or no actions can be performed, the parser iteratively
chooses to perform shift or reduce actions. the shift
action creates a new subtree for the next edu on the
queue.

reduce actions create new subtrees from the sub-
trees on the top of the stack. there are multiple types
reduce actions. first, there are unary or binary ver-
sions of reduce actions, depending on whether the
top 1 or 2 items on the stack will be included as
children in the subtree to be created. second, there
are versions for each of the nonterminal labels (e.g.,
   satellite:attribution   ).

following previous work, we collapse the full set
of rst relations to 18 labels. additionally, we bina-
rize trees as described by sagae and lavie (2005).

following sagae (2009) and ji and eisenstein
(2014), we treat the problem of selecting the best
parsing action given the current parsing state (i.e.,
the stack and queue) as a classi   cation problem.
we use multi-class id28 with an    1
penalty, as implemented in the scikit-learn package,
to estimate our classi   er.

the parser supports id125 and k-best pars-
ing, though we use simple greedy parsing (i.e., we
set the beam size and k to 1) for the experiments
described here.

4.3 parsing features

to select the next shift or reduce action, the pars-
ing model considers a variety of lexical, syntactic,
and positional features adapted from various previ-
ous work on rst discourse parsing, such as that of
sagae (2009) and the systems we compare to in   5.
the features are as follows:

satellite:attribution   )

    the nonterminal symbols of the nth subtree on
the stack (n = 0, 1, 2), and their combinations
    the nonterminal symbols of the children of the

nth subtree on the stack (n = 0, 1, 2)

    the lowercased words (and pos tags) for the
tokens in the head edu for the nth subtree on
the stack (n = 0, 1) and the    rst edu on the
queue

    whether, for pairs of the top 3 stack subtrees
and the 1st queue item, the distance (in edu
indices) between the edu head is greater than
n (n = 1, 2, 3, 4)

    whether, for pairs of the top 3 stack subtrees
and the 1st queue item, the head edus are in
the same sentence

    for the head edus of top 3 stack subtrees and
the 1st queue item, the syntactic head word
(lowercased), head pos, and the nonterminal
symbol of the highest node in the subtree

    syntactic dominance features between pairs of
the top 3 stack items and 1st queue item, similar
to (soricut and marcu, 2003)

    for each of the    rst 3 stack items or 1st queue
item, whether that item starts a new paragraph

5 parsing experiments

following (marcu, 2000, pp. 143   144) and other re-
cent work, we evaluate our system according to the
f1 score over labeled and unlabeled spans of dis-
course units in the rst treebank test set. this eval-
uation is analogous to the evalb bracket scoring
program commonly used for constituency parsing
(http://nlp.cs.nyu.edu/evalb/).
for
comparison with previous results, we use gold stan-
dard discourse segmentations (but automatic syntac-
tic parses from zpar).

we report f1 scores for agreement with the gold
standard on unlabeled edu spans (   span   ), spans
labeled only with nuclearity (   nuclearity   ), and fully
labeled spans that include relation information (   re-
lation   ).

we    rst tuned the    1 id173 parameter us-
ing grid search on the split of the training set used

syntax

stanford

zpar (retrained)

our system
li et al. (2014a)
joty et al. (2013)
charniak (retrained)
joty and moschitti (2014) charniak (retrained)
feng and hirst (2014)
li et al. (2014b)
ji and eisenstein (2014)
human agreement

id32

stanford

malt

   

span nuclearity
83.5
84.0
82.5

68.1
70.8
68.4

   

85.7
82.9
81.6
88.7

   

71.0
73.0
71.0
77.7

relation

55.1
58.6
55.7
57.3
58.2
60.6
61.8
65.8

table 2: test set discourse parsing performance in terms of f1 scores (%), using gold standard discourse segmentation.
   syntax    indicates the source of pos tags and syntactic parse trees:    stanford    refers to the stanford parser (klein
and manning, 2003b),    malt    refers to nivre and marsi (2007), and    charniak    refers to charniak (2000).

syntax

our system zpar (retrained)
our system

ptb

span nuclearity
83.5
84.7

69.3
71.2

relation

57.4
59.4

table 3: development set discourse parsing performance in terms of f1 scores (%), using gold standard discourse
segmentation.    syntax    indicates the source of pos tags and syntactic parse trees.

for development evaluations, using a grid of powers
of 2 ranging from 1/16 to 16. we selected the set-
ting that led to the highest f1 score for fully labeled
spans (i.e., relation f1).

we compare to recently reported results from ji
and eisenstein (2014) (their dplp general +features
model), feng and hirst (2014), li et al. (2014b),
joty and moschitti (2014), li et al. (2014a), and joty
and moschitti (2014).2 the results are shown in ta-
ble 2. the human agreement statistics were origi-
nally reported by ji and eisenstein (2014). for each
system, the table indicates the source of pos tags
and syntactic parse trees (   id32    means
that gold standard id32 trees and tags
were used).

we observe that our system is relatively close to
the others in terms of f1 scores. we hypothesize that
the differences in performance are at least partially
due to differences in syntactic parsing.

2joty and moschitti (2014) and joty and moschitti (2014) do
not explicitly state the source of syntactic parsers, but we infer
from joty et al. (2012) that the charniak (2000) parser was used,
with a model trained on a subset of the id32 that did
not include the rst treebank test set.

5.1 the effect of automatic syntax parsing
in order to show the effect of using automatic pars-
ing, we report performance on the development set
(  2), using either gold standard syntax trees from the
id32 or the automatic syntax trees from
our retrained zpar model (  2) for computing fea-
tures. the f1 scores are shown in table 3 (note that
we are reporting results using the optimal settings
from grid search on the development set).

it appears that the performance difference be-
tween using automatic rather than gold standard syn-
tax is about 1 to 2 points of f1 score.

5.2 parsing speed
in this section, we evaluate the speed of the parser.
most previous papers on rst parsing do not re-
port runtime experiments, and most systems are not
widely available or easy to replicate.

our parser uses a id132 algorithm
that has a worst-case runtime that is linear in the
number of edus. for comparison, li et al. (2014b)
employ a quadratic time maximum spanning tree
parsing approach. the approach from joty et al.
(2013) also uses a polynominal runtime algorithm.
other linear time parsers have been developed
(feng and hirst, 2014; ji and eisenstein, 2014).
however, feature computation can also be a per-

formance bottleneck. feng and hirst (2014) report
an average parsing time of 10.71 seconds for rst
treebank test set documents (and 5.52 seconds for a
variant) on a system with    four duo-core 3.0 ghz
processors   , not including time for preprocessing
or discourse segmentation. in contrast, our system
takes less than half a second per test set document
on average (mean = 0.40, s.d. = 0.40, min. = 0.02,
max. = 1.85 seconds) on a 2013 macbook pro with
an i7-4850hq cpu at 2.30 ghz. of course, these
performance measurements are not completely com-
parable since they were run on different hardware.
the preprocessing (zpar) and segmentation (  3.1)
steps are also similarly fast.

6 conclusion

in this paper, we have presented a fast shift-
reduce rst discourse segmenter and parser. the
parser achieves near state-of-the-art accuracy and
processes id32 documents in less than
a second, which is about an order of magnitude
faster than recent results reported by feng and hirst
(2014).

acknowledgments

we would like to thank dan blanchard, xinhao
wang, and keelan evanini for feedback about the
paper. we would also like to thank dan blanchard,
diane napolitano, nitin madnani, aoife cahill,
chong min lee, michael flor, and keisuke sak-
aguchi for initial help with and feedback about the
implementation.

references

lynn carlson, daniel marcu, and mary ellen okurowski.
2001. building a discourse-tagged corpus in the
framework of rhetorical structure theory. in proceed-
ings of the second sigdial workshop on discourse
and dialogue - volume 16, sigdial    01, pages 1   10,
stroudsburg, pa, usa. association for computational
linguistics.

lynn carlson, daniel marcu, and mary ellen okurowski,
rst discourse treebank ldc2002t07.

2002.
philadelphia.

eugene charniak. 2000. a maximum-id178-inspired
parser. 1st meeting of the north american chapter of
the association for computational linguistics.

vanessa wei feng and graeme hirst. 2014. a linear-
time bottom-up discourse parser with constraints and
post-editing. in proceedings of the 52nd annual meet-
ing of the association for computational linguistics
(volume 1: long papers), pages 511   521, baltimore,
maryland, june. association for computational lin-
guistics.

hugo hernault, danushka bollegala, and mitsuru
ishizuka. 2010. a sequential model for discourse seg-
mentation.
in proceedings of the 11th international
conference on computational linguistics and intel-
ligent text processing, cicling   10, pages 315   326,
berlin, heidelberg. springer-verlag.

yangfeng ji and jacob eisenstein. 2014. representation
learning for text-level discourse parsing. in proceed-
ings of the 52nd annual meeting of the association for
computational linguistics (volume 1: long papers),
pages 13   24, baltimore, maryland, june. association
for computational linguistics.

sha   q joty and alessandro moschitti. 2014. discrimi-
native reranking of discourse parses using tree kernels.
in proceedings of the 2014 conference on empirical
methods in natural language processing (emnlp),
pages 2049   2060, doha, qatar, october. association
for computational linguistics.

sha   q joty, giuseppe carenini, and raymond ng. 2012.
a novel discriminative framework for sentence-level
discourse analysis. in proceedings of the 2012 joint
conference on empirical methods in natural lan-
guage processing and computational natural lan-
guage learning, pages 904   915, jeju island, korea,
july. association for computational linguistics.

sha   q joty, giuseppe carenini, raymond ng, and
yashar mehdad. 2013. combining intra- and multi-
sentential rhetorical parsing for document-level dis-
course analysis.
in proceedings of the 51st annual
meeting of the association for computational linguis-
tics (volume 1: long papers), pages 486   496, so   a,
bulgaria, august. association for computational lin-
guistics.

dan klein and christopher d. manning. 2003a. accu-
rate unlexicalized parsing. in proceedings of the 41st
annual meeting of the association for computational
linguistics, pages 423   430, sapporo, japan, july. as-
sociation for computational linguistics.

dan klein and christopher d manning. 2003b. fast
exact id136 with a factored model for natural lan-
guage parsing. in s. becker, s. thrun, and k. ober-
mayer, editors, advances in neural information pro-
cessing systems 15, pages 3   10. mit press.

john lafferty, andrew mccallum, and fernando c. n.
pereira. 2001. conditional random    elds: probabilis-
tic models for segmenting and labeling sequence data.
in proceedings of the 18th international conference

on machine learning 2001 (icml 2001), pages 282   
289.

jiwei li, rumeng li, and eduard hovy. 2014a. recur-
sive deep models for discourse parsing. in proceed-
ings of the 2014 conference on empirical methods in
natural language processing (emnlp), pages 2061   
2069, doha, qatar, october. association for compu-
tational linguistics.

sujian li, liang wang, ziqiang cao, and wenjie li.
2014b. text-level discourse id33. in
proceedings of the 52nd annual meeting of the associ-
ation for computational linguistics (volume 1: long
papers), pages 25   35, baltimore, maryland, june. as-
sociation for computational linguistics.

daniel marcu. 2000. the theory and practice of dis-

course parsing and summarization. mit press.

mitchell p. marcus, mary ann marcinkiewicz, and beat-
rice santorini. 1993. building a large annotated cor-
pus of english: the id32. computational
linguistics, 19(2):313   330.

j. hall j. nilsson a. chanev g. eryigit s. kbler s. mari-
nov nivre, j. and e. marsi. 2007. maltparser: a
language-independent system for data-driven depen-
dency parsing. 13(2):95   135.

kenji sagae and alon lavie. 2005. a classi   er-based
in proceed-
parser with linear run-time complexity.
ings of the ninth international workshop on pars-
ing technology, pages 125   132, vancouver, british
columbia, october. association for computational
linguistics.

kenji sagae. 2009. analysis of discourse structure with
syntactic dependencies and data-driven shift-reduce
parsing. in proceedings of the 11th international con-
ference on parsing technologies (iwpt   09), pages
81   84, paris, france, october. association for com-
putational linguistics.

radu soricut and daniel marcu. 2003. sentence level
discourse parsing using syntactic and lexical informa-
tion.
in proceedings of the 2003 conference of the
north american chapter of the association for com-
putational linguistics on human language technol-
ogy - volume 1, naacl    03, pages 149   156, strouds-
burg, pa, usa. association for computational lin-
guistics.

ngo xuan bach, nguyen le minh, and akira shimazu.
2012. a reranking model for discourse segmentation
using subtree features. in proceedings of the 13th an-
nual meeting of the special interest group on dis-
course and dialogue, pages 160   168, seoul, south
korea, july. association for computational linguis-
tics.

yue zhang and stephen clark. 2011. syntactic process-
ing using the generalized id88 and id125.
computational linguistics, 37(1).

