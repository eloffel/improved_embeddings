freshman or fresher? quantifying the geographic variation of language in

online social media

vivek kulkarni and bryan perozzi and steven skiena

stony brook university

department of computer science, usa

{vvkulkarni,bperozzi,skiena@cs.stonybrook.edu}

6
1
0
2

 
r
a

m
7

 

 
 
]
l
c
.
s
c
[
 
 

2
v
6
8
7
6
0

.

0
1
5
1
:
v
i
x
r
a

abstract

in this paper we present a new computational technique to
detect and analyze statistically signi   cant geographic varia-
tion in language. while previous approaches have primarily
focused on lexical variation between regions, our method iden-
ti   es words that demonstrate semantic and syntactic variation
as well. our meta-analysis approach captures statistical prop-
erties of word usage across geographical regions and uses
statistical methods to identify signi   cant changes speci   c to
regions.
we extend recently developed techniques for neural language
models to learn word representations which capture differing
semantics across geographical regions. in order to quantify
this variation and ensure robust detection of true regional
differences, we formulate a null model to determine whether
observed changes are statistically signi   cant. our method
is the    rst such approach to explicitly account for random
variation due to chance while detecting regional variation in
word meaning.
to validate our model, we study and analyze two different
massive online data sets: millions of tweets from twitter
spanning not only four different countries but also    fty states,
as well as millions of phrases contained in the google book
ngrams. our analysis reveals interesting facets of language
change at multiple scales of geographic resolution     from
neighboring states to distant continents.
finally, using our model, we propose a measure of semantic
distance between languages. our analysis of british and amer-
ican english over a period of 100 years reveals that semantic
variation between these dialects is shrinking.

1

introduction

detecting and analyzing regional variation in language is
central to the    eld of socio-variational linguistics and di-
alectology (eg. [25, 31, 40, 41]). since online content is an
agglomeration of material originating from all over the world,
language on the internet demonstrates geographic variation.
the abundance of geo-tagged online text enables a study of
geographic linguistic variation at scales that are unattainable
using classical methods like surveys and questionnaires.

characterizing and detecting such variation is challenging
since it takes different forms: lexical, syntactic and semantic.
most existing work has focused on detecting lexical variation

copyright    2016this is the authors draft of the work.
personal use. not for redistribution.

it is posted here for your

figure 1: the latent semantic space captured by our method
(geodist) reveals geographic variation between language speakers.
in the majority of the english speaking world (e.g. us, uk, and
canada) a test is primarily used to refer to an exam, while in
india a test indicates a lengthy cricket match which is played over
   ve consecutive days.

prevalent in geographic regions [4, 13, 15, 16]. however,
regional linguistic variation is not limited to lexical variation.
in this paper we address this gap. our method, geodist,
is the    rst computational approach for tracking and detecting
statistically signi   cant linguistic shifts of words across geo-
graphical regions. geodist detects syntactic and semantic
variation in word usage across regions, in addition to purely
lexical differences. geodist builds on recently introduced
neural language models that learn word representations (word
embeddings), extending them to capture region-speci   c se-
mantics. since observed regional variation could be due to
chance, geodist explicitly introduces a null model to ensure
detection of only statistically signi   cant differences between
regions.

figure 1 presents a visualization of the semantic variation
captured by geodist for the word test between the united
states, the united kingdoms, canada, and india.
in the
majority of english speaking countries, test almost always
means an exam, but in india (where cricket is a popular
sport) test almost always refers to a lengthy form of cricket
match. one might argue that simple baseline methods like
(analyzing part of speech) might be suf   cient to identify
regional variation. however because these methods capture
different modalities, they detect different types of changes as

test.ininningsmatchfinalperiodcrickettest.usexamquizmidtermmathalgebratest.uktest.ca(a) part of speech distribution for schedule (syntactic)

(b) latent semantic space captured by geodist method.

figure 2: the word schedule differs in its semantic usage between us and uk english which geodist (see figure 2b) detects. while
schedule in the usa refers to a    scheduling time   , in the uk schedule also has the meaning of an    addendum to a text   . however the
syntactic method (see figure 2a) does not detect this semantic change since schedule is dominantly used as a noun (nn) in both uk and
the usa.

we illustrate in figure 2.

we use our method in two novel ways. first, we evaluate
our methods on several large datasets at multiple geographic
resolutions. we investigate linguistic variation across twit-
ter at multiple scales: (a) between four english speaking
countries and (b) between    fty states in usa. we also inves-
tigate regional variation in the google books ngram corpus
data. our methods detect a variety of changes including re-
gional dialectical variations, region speci   c usages, words
incorporated due to code mixing and differing semantics.

second, we apply our method to analyze distances be-
tween language dialects. in order to do this, we propose a
measure of semantic distance between languages. our anal-
ysis of british and american english over a period of 100
years reveals that semantic variation between these dialects is
shrinking potentially due to cultural mixing and globalization
(see figure 3).

speci   cally, our contributions are as follows:

    models and methods: we present our new method
geodist which extends recently proposed neural lan-
guage models to capture semantic differences between
regions (section 3.2). geodist is a new statistical method
that explicitly incorporates a null model to ascertain statis-
tical signi   cance of observed semantic changes.

    multi-resolution analysis: we apply our method on
multiple domains (books and tweets) across geographic
scales (states and countries). our analysis of these large
corpora (containing billions of words) reveals interesting
facets of language change at multiple scales of geographic
resolution     from neighboring states to distant continents
(section 5).

    semantic distance: we propose a new measure of seman-
tic distance between languages which we use to charac-
terize distances between various dialects of english and
analyze their convergent and divergent patterns over time
(section 6).

figure 3: semantic distance between uk english and us english
at different time periods from 1900-2005. the two countries are be-
coming closer to one another driven by globalization and invention
of mass communication technologies like radio, television, and the
internet.

2 problem de   nition

we seek to quantify shift in word meaning (usage) across
different geographic regions. speci   cally, we are given a
corpus c that spans r regions where cr corresponds to the
corpus speci   c to region r. we denote the vocabulary of the
corpus by v. we want to detect words in v that have region
speci   c semantics (not including trivial instances of words
exclusively used in one region). for each region r, we capture
statistical properties of a word w   s usage in that region. given
a pair of regions (ri, rj), we then reduce the problem of
detecting words that are used differently across these regions
to an outlier detection problem using the statistical properties
captured.

in summary, we answer the following questions:

1. in which regions does the word usage drastically differ

nnnnpvbcdjj0.00.10.20.30.40.50.60.70.80.9pr(posjschedule)ukusschedule.usregularovertimeyearlypayroll401schedule.ukpursuantarticleprovisionssubpartappendix190019201940196019802000time2.02.53.03.54.04.55.0semt(uk;us)radiointernettvuk-usnull modelfigure 4: frequency usage of different words in english uk and
english us. note that touchdown, an american football term is
much more frequent in the us than in uk. words like carers and
licences are used more in the uk than in the us. carers are
known as caregivers in the us and licences is spelled as
licenses in the us.

figure 5: part of speech tag id203 distribution of the words
which differ in syntactic usage between uk and us. observe that
remit is predominantly used a verb (vb) in the us but as a com-
mon noun (nn) in the uk.

2. how statistically signi   cant is the difference observed

3. given two regions, how close are their corresponding di-

from other regions?

across regions?

alects semantically?

3 methods

in this section we discuss methods to model regional word
usage.

3.1 baseline methods
frequency method. one standard method to detect which
words vary across geographical regions is to track their fre-
quency of usage. formally, we track the change in id203
of a word across regions as described in [24]. to characterize
the difference in frequency usage of w between a region pair
(ri, rj), we compute the ratio score(w) = pri (w)
prj (w) where
pri(w) is the id203 of w occurring in region ri. an
example of the information we capture by tracking word
frequencies over regions is shown in figure 4. observe that
touchdown (an american football term) is used much more
frequently in the us than in uk. while this naive method is
easy to implement and identi   es words which differ in their
usage patterns, one limitation is an overemphasis on rare
words. furthermore frequency based methods overlook the
fact that word usage or meaning changes are not exclusively
associated with a change in frequency.

syntactic method. a method to capture syntactic varia-
tion in word usage through time was proposed by [24]. along
similar lines, we can capture regional syntactic variation of
words. the word lift is a striking example of such varia-
tion: in the us, lift is dominantly used as a verb (in the
sense:    to lift an object   ), whereas in the uk lift also
refers to an elevator, thus predominantly used as a common
noun. given a word w and a pair of regions (ri, rj) we
adapt the method outlined in [24] and compute the jennsen-

shannon divergence between the part of speech distributions
for word w corresponding to the regions.

figure 5 shows the part of speech distribution for a few
words that differ in syntactic usage between the us and uk.
in the us, remit is used primarily as a verb (as in    to remit
a payment   ). however in the uk, remit can refer    to an
area of activity over which a particular person or group has
authority, control or in   uence    (used as    a remit to report
on medical services   )1. the word curb is used mostly as a
noun (as    i should put a curb on my drinking habits.   ) in the
uk but it is used dominantly as a verb in the us (as in    we
must curb the rebellion.   ).

whereas the syntactic method captures a deeper variation
than the frequency methods, it is important to observe that
semantic changes in word usage are not limited to syntactic
variation as we illustrated before in figure 2.

3.2 distributional method: geodist
as we noted in the previous section, linguistic variation is
not restricted only to syntactic variation. in order to detect
subtle semantic changes, we need to infer cues based on the
contextual usage of a word. to do so, we use distributional
methods which learn a latent semantic space that maps each
word w     v to a continuous vector space rd.

we differentiate ourselves from the closest related work
to our method [5], by explicitly accounting for random vari-
ation between regions, and proposing a method to detect
statistically signi   cant changes.
learning region speci   c id27s given a cor-
pus c with r regions, we seek to learn a region speci   c word
embedding   r : v,cr (cid:55)    rd using a neural language model.
for each word w     v the neural language model learns:
1. a global embedding   main(w) for the word ignoring all

region speci   c cues.

2. a differential embedding   r(w) that encodes differences

from the global embedding speci   c to region r.

1http://www.oxfordlearnersdictionaries.com/us/

definition/english/remit_1

minibartouchdowncarerslicences10-910-810-710-610-510-4pr(w)ukusremitukremituscurbukcurbuswadukwadus0.00.20.40.60.81.0pr(tag)nnvbvbpother(cid:107)u(cid:107)2(cid:107)v(cid:107)2

regional

between

embed-
distance computation
dings after
learning id27s
each
v, we then compute the distance
   
word w
of
as
score(w) = cosinedistance(  ri(w),   rj (w)) where
cosinedistance(u, v) is de   ned by 1     ut v

a word between any two regions

(ri, rj)

for

.

figure 6 illustrates the information captured by our
geodist method as a two dimensional projection of the
latent semantic space learned, for the word theatre. in the
us, the british spelling theatre is typically used only to re-
fer to the performing arts. observe how the word theatre
in the us is close to other subjects of study: sciences,
literature, anthropology, but theatre as used
in uk is close to places showcasing performances (like
opera, studio, etc). we emphasize that these regional
differences detected by geodist are inherently semantic, the
result of a level of language understanding unattainable by
methods which focus solely on lexical variation [17].

3.3 statistical signi   cance of changes
in this section, we outline our method to quantify whether an
observed change given by score(w) is signi   cant. when
one is operating on an entire population (or in the absence of
stochastic processes), one fairly standard method to identify
outliers is the z-value test [1] (obtained by standardizing the
raw scores) and marking samples whose z-value exceeds a
threshold    (typically set to the 95th percentile) as outliers.
however since in our method, score(w) could vary due
random stochastic processes (even possibly pure chance),
whether an observed score is signi   cant or not depends on
two factors: (a) the magnitude of the observed score (effect
size) and (b) id203 of obtaining a score more extreme
than the observed score, even in the absence of a true effect.
speci   cally, given a word w with a score e(w) =
score(w) between regions (ri, rj) we ask the question:
   what is the chance of observing e(w) or a more extreme
value assuming the absence of an effect?   

first our method explicitly models the scenario when there
is no effect, which we term as the null model. next we char-
acterize the distribution of scores under the null model. our
method then compares the observed score with this distribu-
tion of scores to ascertain the signi   cance of the observed
score. the details of our method are described in algorithm
1 and below.

we simulate the null model by observing that under the
null model, the labels of the text are exchangeable. therefore,
we generate a corpus c(cid:48) by a random assignment of the labels
(regions) of the given corpus c. we then learn a model using
c(cid:48) and estimate score(w) under this model. by repeating
this procedure b times we estimate the distribution of scores
for each word under the null model (lines 1 to 10).

after we estimate the distribution of scores we then com-
pute the 100  % con   dence interval on score(w) under the
null model. thus for each word w, we specify two measures:
(a) observed effect size and (b) 100  % con   dence interval
(we typically set    = 0.95) corresponding to the null distribu-
tion (lines 16-17). when the observed effect is not contained
in the con   dence interval obtained for the null distribution,

figure 6: semantic    eld of theatre as captured by geodist
method between the uk and us. theatre is a    eld of study in
the us while in the uk it primarily associated with opera or a club.

the region speci   c embedding   r(w) is computed as:
  r(w) =   main(w) +   r(w). before training, the global
id27s are randomly initialized while the differ-
ential id27s are initialized to 0. during each
training step, the model is presented with a set of words w
and the region r they are drawn from. given a word wi, the
context words are the words appearing to the left or right of
wi within a window of size m. we de   ne the set of active
regions a = {r, main} where main is a placeholder lo-
cation corresponding to the global embedding and is always
included in the set of active regions. the training objective
then is to maximize the id203 of words appearing in the
context of word wi conditioned on the active set of regions
a. speci   cally, we model the id203 of a context word
wj given wi as:

pr(wj | wi) =

(cid:80)
where wi is de   ned as wi = (cid:80)

wk   v

exp (wt

j wi)
exp (wt

k wi)

(1)

  a(wi).

a   a

during training, we iterate over each word occurrence in c
to minimize the negative log-likelihood of the context words.
our objective function j is thus given by:

    log pr(wj | wi)

(2)

(cid:88)

i+m(cid:88)

wi   c

j=i   m
j!=i

j =

when |v| is large, it is computationally expensive to com-
pute the id172 factor in equation 1 exactly. there-
fore, we approximate this id203 by using hierarchical
soft-max [32, 34] which reduces the cost of computing the
id172 factor from o(|v|) to o(log |v|). we opti-
mize the model parameters using stochastic id119
[8], as   t(wi) =   t(wi)           j
     t(wi) where    is the learning
rate. we calculate the derivatives using the back-propagation
algorithm [38]. we set    = 0.025, context window size m to
10 and size of the id27 d to be 200 unless stated
otherwise.

theatre.usliteraturesciencessymbolismexplorationsanthropologytheatre.ukpalacecluboperaabbeystudiocinema(a) observed score for hand

(b) observed score for buffalo

figure 7: the observed scores computed by geodist (in
) for buffalo and hand when analyzing regional differences between new
york and usa overall. the histogram shows the distribution of scores under the null model. the 98% con   dence intervals of the score under
null model are shown in
. the observed score for hand lies well within the con   dence interval and hence is not a statistically signi   cant
change. in contrast, the score for buffalo is far outside the con   dence interval for the null distribution indicating a statistically signi   cant
change.
the effect is statistically signi   cant at the 1        signi   cance
level.

algorithm 1 scoresignificance (c, b,   )
input: c: corpus of text with r regions, b: number of

even though p-values have been traditionally used to report
signi   cance, recently researchers have argued against their
use as p-values themselves do not indicate what the observed
effect size was and hence even very small effects can be
deemed statistically signi   cant [14, 39]. in contrast, reporting
effect sizes and con   dence intervals enables us to factor in
the magnitude of effect size while interpreting signi   cance.
in a nutshell therefore, we deem a change observed for w as
statistically signi   cant when:
1. the effect size exceeds a threshold    which ensures the
effect size is large enough. one typically standardizes
the effect size and typically sets    to the 95th percentile
(which is usually around 3).

2. it is rare to observe this effect as a result of pure chance.
this is captured by our comparison to the null model and
the con   dence intervals computed.
figure 7 illustrates this for two words: hand and
buffalo. observe that for hand, the observed score is
smaller than the higher con   dence interval, indicating that
hand has not changed signi   cantly. in contrast buffalo
which is used differently in new york (since buffalo refers
to a place in new york) has a score well above the higher
con   dence interval under the null model.

as we will also see in section 5, the incorporation of
the null model and obtaining con   dence estimates enables
our method to ef   caciously tease out effects arising due to
random chance from statistically signi   cant effects.

bootstrap samples,   : con   dence interval threshold

output: e: computed effect sizes for each word w, ci:

computed con   dence intervals for each word w
// estimate the null distribution.
1: bs         {corpora from the null distribution}.
nullscores(w) {store the scores for w under null
model.}
2: repeat
3:

permute the labels assigned to text of c uniformly at
bs     bs     c(cid:48)
learn a model n using c(cid:48) as the text.
for w     v do

random to obtain corpus c(cid:48)

compute score(w) using n.
append score(w) to nullscores(w)

4:
5:
6:
7:
8:
9:

end for

10: until |bs| = b

// estimate the actual observed effect and compute con   -
dence intervals.
11: learn a model m using c as the text.
12: for w     v do

13:
14:
15:
16:
17:

compute score(w) using m.
e(w)     score(w)
sort the scores in nullscores(w).
hci(w)     100   percentile in nullscores(w)
lci(w)     100(1       )
in
ci(w)     (lci(w), hci(w))

percentile

nullscores(w)

18:
19: end for
20: return e, ci

4 datasets

here we outline the details of two online datasets that we con-
sider - tweets from various geographic locations on twitter
and google books ngram corpus.

the google books ngram corpus the google books
ngram corpus corpus [27] contains frequencies of short
phrases of text (ngrams) which were taken from books span-
ning eight languages over    ve centuries. while these ngrams
vary in size from 1     5, we use the 5-grams in our experi-

0.140.150.160.170.180.190.200.210.220.23score(hand)0.000.020.040.060.080.100.120.140.16id203scoreobservedcinull0.000.050.100.150.200.250.300.35score(buffalo)0.000.020.040.060.080.100.12id203scoreobservedcinullments. speci   cally we use the google books ngram corpus
corpora for american english and british english and use
a random sample of 30 million ngrams for our experiments.
here, we show a sample of 5-grams along with their region:

    drive a coach and horses (uk)
    years as a football coach (us)

we obtained the pos distribution of each word in the

above corpora using google syntactic ngrams[18, 26].

twitter data this dataset consists of a sample of tweets
spanning 24 months starting from september 2011 to october
2013. each tweet includes the tweet id, tweet and the
geo-location if available. we partition these tweets by their
location in two ways:
1. states in the usa: we consider tweets originating in the
united states and group the tweets by the state in the
united states they originated from. the joint corpus con-
sists of 7 million tweets.

2. countries: we consider 11 million tweets originating
from usa, uk, india (in) and australia (au) and partition
the tweets among these four countries.
some sample tweet text is shown below:

    someone come to golden with us!

(ca)

    taking the subway with the kids

...(ny)

in order to obtain part of speech tags, for the tweets we

use the tweetnlp pos tagger[36].

5 results and analysis

in this section, we apply our methods to various data sets
described above to identify words that are used differently
across various geographic regions. we describe the results of
our experiments below.
5.1 geographical variation analysis
table 1 shows words which are detected by the frequency
method. note that zucchini is used rarely in the uk
because a zucchini is referred to as a courgette in
the uk. yet another example is the word freshman which
refers to a student in their    rst year at college in the us.
however in the uk a freshman is known as a fresher.
the frequency method also detects terms that are speci   c
to regional cultures like touchdown, an american football
term and hence used very frequently in the us.

as we noted in section 3.1, the syntactic method detects
words which differ in their syntactic roles. table 2 shows
words like lift, cuddle which are used as verbs in the us
but predominantly as nouns in the uk. in particular lift
in the uk also refers to an elevator. while in the usa, the
word cracking is typically used as a verb (as in    the ice is
cracking   ), in the uk cracking is also used as an adjective
and means    stunningly beautiful   . the frequency method in

contrast would not be able to detect such syntactic variation
since it focuses only on usage counts and not on syntax.

in tables 3a and 3b we show several words identi   ed by
our geodist method. while theatre refers primarily
to a building (where events are held) in the uk, in the us
theatre also refers primarily to the study of the performing
arts. the word extract is yet another example: extract
in the us refers to food extracts but is used primarily as a
verb in the uk. while in the us, the word test almost
always refers to an exam, in india test has an additional
meaning of a cricket match that is typically played over    ve
days. an example usage of this meaning is    we are going to
see the test match between india and australia    or the    the
test was drawn.   . we reiterate here that the geodist method
picks up on    ner distributional cues that the syntactic or the
frequency method cannot detect. to illustrate this, observe
that theatre is still used predominantly as a noun in both
uk and the usa, but they differ in semantics which the
syntactic method fails to detect.

another clear pattern that emerges are    code-mixed
words   , which are regional language words that are incor-
porated into the variant of english (yet still retaining the
meaning in the regional language). examples of such words
include main and hum which in india also mean    i    and
   we    respectively in addition to their standard meanings. in
indian english, one can use main as    the main job is done   
as well as    main free at noon. what about you?   . in the
second sentence main refers to    i    and means    i am free at
noon. what about you?   .

furthermore, we demonstrate that our method is capable
of detecting changes in word meaning (usage) at    ner scales
(within states in a country). table 4 shows a sample of the
words in states of the usa which differ in semantic usage
markedly from their overall semantics globally across the
country.

note that the usage of buffalo signi   cantly differs in
new york as compared to the rest of the usa. buffalo
typically would refer to an animal in the rest of usa, but
it refers to a place named buffalo in new york. the word
queens is yet another example where people in new york
almost always refer to it as a place.

other clear trends evident are words that are typically asso-
ciated with states. examples of such words include golden,
space and twins. the word golden in california almost
always refers to the golden gate bridge and space in wash-
ington refers to the space needle. while twins in the rest
of the country is dominantly associated with twin babies (or
twin brothers), in the state of minnesota, twins also refers
to the state   s baseball team minnesota twins.

table 4 also illustrates the signi   cance of incorporating the
null model to detect which changes are signi   cant. observe
how incorporating the null model renders several observed
changes as being not signi   cant thus highlighting statistically
signi   cant changes. without incorporating the null model,
one would erroneously conclude that hand has different
semantic usage in several states. however on incorporating
the null model, we notice that these are very likely due to
random chance thus enabling us to reject this as signifying a
true change.

word

us/uk     explanation

s zucchini

2.3
2.4
2.5

   zucchinis    are known as    courgettes    in uk
   touchdown    is a term in american football
   bartender    is a very recent addition to the pub language in uk.

k
o
o
b

s
t
e
e
w
t

touchdown
bartender

word
freshman
hmu

maccas
wickets
heaps

us/uk     explanation

2.7
2.5
us/au    
   3.3
   2.9
   2.7

   freshman    are referred to as    freshers    in the uk
hit me up a slang which is popular in usa

mcdonald   s in australia is called maccas
wickets is a term in cricket, a popular game in australia
australian colloquial for    alot   

table 1: examples of words detected by the frequency method on google book ngrams and twitter. (    is difference in log probabilities
between countries). a positive value indicates the word is more probable in the us than the other region. a negative value indicates the word
is more probable in the other region than the us.

word
s remit

k
o
o
b

oracle
wad

sort
lift
ring
cracking
cuddle
dear

kisses
claim

s
t
e
e
w
t

js
0.173

0.149
0.143

0.224
0.220
0.200
0.181
0.148
0.137

0.320
0.109

us usage
remit the loan

oracle the company
a wad of cotton

he   s not a bad sort
lift the bag
ring on my    nger
the ice is cracking
let her cuddle the baby (verb)
dear relatives
us usage
hugs and kisses (as a noun)
he made an insurance claim (noun)

uk usage
the jury investigated issues within its remit
(an assigned area).
a person who is omniscient
wad the paper towel and throw it! (used as
   to compress   )
sort it out
i am stuck in the lift (elevator)
give him a ring (call)
the girl is cracking (beautiful)
come here and give me a cuddle (noun)
something is dear (expensive)
au usage
he kisses them (verb)
i claim ... (almost always used as a verb)

table 2: examples of words detected by the syntactic method on google book ngrams and twitter. (js is jennsen shannon divergence)

word
theatre
schedule
forms
extract
leisure
extensive

store
facility

effect size

0.6067
0.5153
0.595
0.400
0.535
0.487

ci(null)

(0.004,0.007)
(0.032,0.050)
(0.015, 0.026)
(0.023, 0.045)
(0.012, 0.024)
(0.015, 0.027)

us usage
great love for the theatre
back to your regular schedule
out the application forms
vanilla and almond extract
culture and leisure (a topic)
view our extensive catalog list

0.423
0.378

(0.02, 0.04)
(0.035, 0.055) mental health,term care facility

trips to the grocery store

uk usage
in a large theatre
a schedule to the agreement
range of literary forms (styles)
extract from a sermon
as a leisure activity
possessed an extensive knowledge
(as in impressive)
store of gold (used as a container)
set up a manufacturing facility (a
unit)

(a) google book ngrams: differences between english usage in the united states and united kingdoms

word
high
hum
main
ring
test
stand

effect size

0.820
0.740
0.691
0.718
0.572
0.589

us usage
i am in high school
more than hum and talk
your main attraction

ci(null)
(0.02,0.03)
(0.03, 0.04)
(0.048, 0.074)
(0.054, 0.093) my belly piercing ring
(0.03, 0.061)
(0.046, 0.07)
(b) twitter: differences between english usage in the united states and india

in usage
by pass the high way (as a road)
hum busy hain (hinglish)
main cool hoon (i am cool)
on the ring road (a circular road)
we won the test
wait at the bus stand

i failed the test
i can   t stand stupid people

table 3: examples of statistically signi   cant geographic variation of language detected by our method, geodist, between english usage in the
united states and english usage in the united kingdoms (a) and india (b). (ci - the 98% con   dence intervals under the null model)

word

distances

naive distances

nullmodel

geodist(our method)

buffalo

twins

space

golden

hand

table 4: sample set of words which differ in meaning (semantics) in different states of the usa. note how incorporating the null model
highlights only statistically signi   cant changes. observe how our method geodist correctly detects no change in hand.

these examples demonstrate the capability of our method
to detect wide variety of variation across different scales
of geography spanning regional differences to code-mixed
words.

6 semantic distance

in this section we investigate the following question: are
british and american english converging or diverging over
time semantically?

in order to measure semantic distance between languages
through time, we propose a measure of semantic distance be-
tween two variants of the language at a given point t. specif-
ically, at a given time t, we are given a corpus c and a pair
of regions (ri, rj). using our method (see section 3.2) we
compute the standardized distance zt(w) for each word w
between the regions at time point t. then, we construct the

intersection of the set of words w that have been deemed
to have changed signi   cantly at each time point t. we do
this so that (a) we focus on only the words that were sig-
ni   cantly different between the language dialects at time
point t and (b) the words identi   ed as different are stable
across time, allowing us to track the usage of the same set
of divergent words over time. our measure of the seman-
tic distance between the two language dialects at time t is
then semt(ri, rj) = 1|w|
w   w zt(w), the mean of the
distances of words in w.

(cid:80)

in our experiment, we considered the google books
ngram corpus for uk english and us english within a
time span of 1900     2005 using a window of 5 years. we
computed the semantic distance between these dialects as
described above, which we present in figure 3. we clearly
observe a trend showing both british and american english

to identify semantic changes in word meaning (usage) not
limited to lexical variation. the work that is most closely
related to ours is that of bamman, dyer, and smith [5]. they
propose a method to obtain geographically situated word
embeddings and evaluate them on a semantic similarity task
that seeks to identify words accounting for geographical lo-
cation. their evaluation typically focuses on named entities
that are speci   c to geographic regions. our work differs in
several aspects: unlike their work which does not explic-
itly seek to identify which words vary in semantics across
regions, we propose methods to detect and identify which
words vary across regions. while our work builds on their
work to learn region speci   c id27s, we differ-
entiate our work by proposing an appropriate null model,
quantifying the change and assessing its signi   cance. fur-
thermore our work is unique in the fact that we evaluate our
method comprehensively on multiple web-scale datasets at
different scales (both at a country level and state level).

measures of semantic distance have been developed for
units of language (words, concepts etc) which [33] provide
an excellent survey. cooper [12] study the problem of mea-
suring semantic distance between languages, by attempting
to capture the relative dif   culty of translating various pairs
of languages using bi-lingual dictionaries. different from
their work, we measure semantic distance between language
dialects in an unsupervised manner (using id27s)
and also analyze convergence patterns of language dialects
over time.
id27s the concept of using distributed rep-
resentations to learn a mapping from symbolic data to contin-
uous space dates back to hinton [21]. in a landmark paper,
bengio et al. [6] proposed a neural language model to learn
id27s and demonstrated that they outperform tra-
ditional id165 based models. mikolov et al. [29] proposed
skipgram models for learning id27s and demon-
strated that they capture    ne grained structures and linguistic
regularities [28, 30]. also [37] induce language networks
over id27s to reveal rich but varied community
structure. finally these embeddings have been demonstrated
to be useful features for several nlp tasks [2, 3, 10, 11].

8 conclusions

in this work, we proposed a new method to detect linguistic
change across geographic regions. our method explicitly ac-
counts for random variation, quantifying not only the change
but also its signi   cance. this allows for more precise detec-
tion than previous methods.

we comprehensively evaluate our method on large datasets
at different levels of granularity     from states in a country to
countries spread across continents. our methods are capable
of detecting a rich set of changes attributed to word seman-
tics, syntax, and code-mixing. using our method, we are able
to characterize the semantic distances between dialectical
variants over time. speci   cally, we are able to observe the
semantic convergence between british and american english
over time, potentially an effect of globalization. this promis-
ing (although preliminary) result points to exciting research
directions for future work.

figure 8: usage of acts in uk converges to the usage in us over
time.

are converging. figure 8 shows one such word acts, where
the usage in the uk starts converging to the usage in the us.
before the 1950   s, acts in british english was primarily
used as a legal term (with ordinances, enactments, laws etc).
american english on the other hand used acts to refer to
actions (as in acts of vandalism, acts of sabotage). however
in the 1960   s british english started adopting the american
usage.

we hypothesize that this effect is observed due to global-
ization (the invention of radio, tv and the internet), but leave
a rigorous investigation of this phenomenon to future work.
while our measure of semantic distance between lan-
guages does not capture lexical variation, introduction of
new words etc, our work opens the door for future research to
design better metrics for measuring semantic distances while
also accounting for other forms of variation.

7 related work

most of the related work can be organized into two areas: (a)
socio-variational linguistics (b) id27s

socio-variational linguistics a large body of work studies
how language varies according to geography and time [4, 5,
15, 17, 19, 22   24].

while previous work like [7, 9, 20, 22, 23] focus on tem-
poral analysis of language variation, our work centers on
methods to detect and analyze linguistic variation according
to geography. a majority of these works also either restrict
themselves to two time periods or do not outline methods to
detect when changes are signi   cant. recently [24] proposed
methods to detect statistically signi   cant linguistic change
over time that hinge on timeseries analysis. since their meth-
ods explicitly model word evolution as a time series, their
methods cannot be trivially applied to detect geographical
variation.

several works on geographic variation [4, 13, 15, 35] focus
on lexical variation. bamman and others [4] study lexical
variation in social media like twitter based on gender iden-
tity. eisenstein et al. [15] describe a latent variable model to
capture geographic lexical variation. eisenstein et al. [16]
outline a model to capture diffusion of lexical variation in
social media. different from these studies, our work seeks

190019201940196019802000time0123456distanceuk-usnull model[23] kim, y.; chiu, y.-i.; hanaki, k.; hegde, d.; and petrov, s.
2014. temporal analysis of language through neural language
models. in acl.

[24] kulkarni, v.; al-rfou, r.; perozzi, b.; and skiena, s. 2015.
statistically signi   cant detection of linguistic change. in www.
[25] labov, w. 1980. locating language in time and space / edited

by william labov. academic press new york.

[26] lin, y.; michel, j.-b.; aiden, e. l.; et al. 2012. syntactic
annotations for the google books ngram corpus. in proceedings
of the acl 2012 system demonstrations.

[27] michel, j.-b., et al. 2011. quantitative analysis of culture
using millions of digitized books. science 331(6014):176   182.
[28] mikolov, t., et al. 2013. linguistic regularities in continuous

space word representations. in proceedings of naacl-hlt.

[29] mikolov, t.; chen, k.; corrado, g.; and dean, j. 2013a. ef   -
cient estimation of word representations in vector space. arxiv
preprint arxiv:1301.3781.

[30] mikolov, t.; sutskever, i.; chen, k.; corrado, g. s.; and dean,
j. 2013b. distributed representations of words and phrases and
their compositionality. in nips.

[31] milroy, j. 1992. linguistic variation and change: on the

historical sociolinguistics of english. b. blackwell.

[32] mnih, a., and hinton, g. e. 2009. a scalable hierarchical

distributed language model. nips.

[33] mohammad, s. m., and hirst, g. 2012. distributional
arxiv preprint

measures of semantic distance: a survey.
arxiv:1203.1858.

[34] morin, f., and bengio, y. 2005. hierarchical probabilistic neu-
ral network language model. in proceedings of the international
workshop on arti   cial intelligence and statistics.

[35] o   connor, b.; eisenstein, j.; xing, e. p.; and smith, n. a.
2010. discovering demographic language variation. in proc. of
nips workshop on machine learning for social computing.

[36] owoputi, o.; o   connor, b.; et al. 2013. improved part-of-
speech tagging for online conversational text with word clusters.
association for computational linguistics.

[37] perozzi, b.; al-rfou, r.; et al. 2014. inducing language net-
works from continuous space word representations. in complex
networks v.

[38] rumelhart, d. e.; hinton, g. e.; and williams, r. j. 2002.
learning representations by back-propagating errors. cognitive
modeling 1:213.

[39] sullivan, g. m., and feinn, r. 2012. using effect size-or
why the p value is not enough. journal of graduate medical
education.

[40] tagliamonte, s. a. 2006. analysing sociolinguistic variation.

cambridge university press.

[41] wolfram, w., and schilling-estes, n. 2005. american english:

dialects and variation, volume 20. wiley-blackwell.

acknowledgments

we thank david bamman for sharing the code for training situated
id27s. we thank yingtao tian for valuable comments.

references

[1] aggarwal, c. c. 2013. outlier analysis. springer science &

business media.

[2] al-rfou, r.; kulkarni, v.; perozzi, b.; and skiena, s. 2015.
polyglot-ner: massive multilingual id39. in
sdm.

[3] al-rfou, r.; perozzi, b.; and skiena, s. 2013. polyglot: dis-
tributed word representations for multilingual nlp. in proceed-
ings of the seventeenth conference on computational natural
language learning.

[4] bamman, d., et al. 2014. gender identity and lexical variation

in social media. journal of sociolinguistics.

[5] bamman, d.; dyer, c.; and smith, n. a. 2014. distributed
representations of geographically situated language. proceedings
of the 52nd annual meeting of the association for computational
linguistics (volume 2: short papers) 828   834.

[6] bengio, y.; schwenk, h.; senecal, j.-s.; morin, f.; and gau-
in

vain, j.-l. 2006. neural probabilistic language models.
innovations in machine learning.

[7] berners-lee, t.; hendler, j.; lassila, o.; et al. 2001. the

semantic web. scienti   c american.

[8] bottou, l. 1991. stochastic gradient learning in neural net-

works. in proceedings of neuro-n    mes 91.

[9] brigadir, i.; greene, d.; and cunningham, p. 2015. analyzing
discourse communities with distributional semantic models. in
acm web science 2015 conference. acm.

[10] chen, y.; perozzi, b.; al-rfou, r.; and skiena, s. 2013.
the expressive power of id27s. arxiv preprint
arxiv:1301.3226.

[11] collobert, r.; weston,

j.; bottou, l.; karlen, m.;
kavukcuoglu, k.; and kuksa, p. 2011. natural language pro-
cessing (almost) from scratch. jmlr.

[12] cooper, m. c. 2008. measuring the semantic distance between
languages from a statistical analysis of bilingual dictionaries*.
journal of quantitative linguistics.

[13] doyle, g. 2014. mapping dialectal variation by querying

social media. in eacl.

[14] du prel, j.-b.; hommel, g.; r  ohrig, b.; and blettner, m. 2009.
con   dence interval or p-value?: part 4 of a series on evaluation
of scienti   c publications. deutsches   arzteblatt international.

[15] eisenstein, j.; o   connor, b.; smith, n. a.; and xing, e. p.
2010. a latent variable model for geographic lexical variation.
in emnlp.

[16] eisenstein, j.; o   connor, b.; smith, n. a.; and xing, e. p.
2014. diffusion of lexical change in social media. plos one.
[17] eisenstein, j.; smith, n. a.; et al. 2011. discovering sociolin-

guistic associations with structured sparsity. in in acl-hlt.

[18] goldberg, y., and orwant, j. 2013. a dataset of syntactic-
ngrams over time from a very large corpus of english books. in
*sem.

[19] gonc  alves, b., and s  anchez, d. 2014. id104 dialect

characterization through twitter.

[20] gulordava, k., and baroni, m. 2011. a distributional similar-
ity approach to the detection of semantic change in the google
books ngram corpus. in gems.

[21] hinton, g. e. 1986. learning distributed representations of
concepts. in proceedings of the eighth annual conference of the
cognitive science society.

[22] kenter, t.; wevers, m.; huijnen, p.; et al. 2015. ad hoc

monitoring of vocabulary shifts over time. in cikm. acm.

