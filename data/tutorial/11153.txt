6
1
0
2

 
r
p
a
6

 

 
 
]
l
c
.
s
c
[
 
 

2
v
4
4
5
7
0

.

8
0
5
1
:
v
i
x
r
a

computational sociolinguistics: a survey

dong nguyen
university of twente

carolyn p. ros  
carnegie mellon university

a. seza do   gru  z
tilburg university/
netherlands institute for advanced
study in the humanities and social
sciences (nias)

franciska de jong
university of twente/
erasmus university rotterdam

language is a social phenomenon and variation is inherent to its social nature. recently, there
has been a surge of interest within the computational linguistics (cl) community in the social
dimension of language. in this article we present a survey of the emerging    eld of    computational
sociolinguistics    that re   ects this increased interest. we aim to provide a comprehensive overview
of cl research on sociolinguistic themes, featuring topics such as the relation between language
and social identity, language use in social interaction and multilingual communication. more-
over, we demonstrate the potential for synergy between the research communities involved, by
showing how the large-scale data-driven methods that are widely used in cl can complement
existing sociolinguistic studies, and how sociolinguistics can inform and challenge the methods
and assumptions employed in cl studies. we hope to convey the possible bene   ts of a closer
collaboration between the two communities and conclude with a discussion of open challenges.

1. introduction

science has experienced a paradigm shift along with the increasing availability of large
amounts of digital research data (hey, tansley, and tolle 2009). in addition to the
traditional focus on the description of natural phenomena, theory development and
computational science, data-driven exploration and discovery have become a dominant
ingredient of many methodological frameworks. in line with these developments, the
   eld of computational linguistics (cl) has also evolved.

human communication occurs in both verbal and nonverbal form. research on
computational linguistics has primarily focused on capturing the informational di-
mension of language and the structure of verbal information transfer. in the words
of krishnan and eisenstein (2015), computational linguistics has made great progress
in modeling language   s informational dimension, but with a few notable exceptions,
computation has had little to contribute to our understanding of language   s social
dimension. the recent increase in interest of computational linguists to study language
in social contexts is partly driven by the ever increasing availability of social media data.
data from social media platforms provide a strong incentive for innovation in the cl
research agenda and the surge in relevant data opens up methodological possibilities
for studying text as social data. textual resources, like many other language resources,
can be seen as a data type that is signaling all kinds of social phenomena. this is
related to the fact that language is one of the instruments by which people construct

computational linguistics

to appear

their online identity and manage their social network. there are challenges as well.
for example, social media language is more colloquial and contains more linguistic
variation, such as the use of slang and dialects, than the language in datasets that have
been commonly used in cl research (e.g., scienti   c articles, newswire text and the wall
street journal) (eisenstein 2013b). however, an even greater challenge is that the relation
between social variables and language is typically    uid and tenuous, while the cl    eld
commonly focuses on the level of literal meaning and language structure, which is more
stable.

the tenuous connection between social variables and language arises because of
the symbolic nature of the relation between them. with the language chosen a social
identity is signaled, which may buy a speaker1 something in terms of footing within a
conversation, or in other words: for speakers there is room for choice in how to use
their linguistic repertoire in order to achieve social goals. this freedom of choice is
often referred to as the agency of speakers and the linguistic symbols chosen can be
thought of as a form of social currency. speakers may thus make use of speci   c words
or stylistic elements to represent themselves in a certain way. however, because of this
agency, social variables cease to have an essential connection with language use. it may
be the case, for example, that on average female speakers display certain characteris-
tics in their language more frequently than their male counterparts. nevertheless, in
speci   c circumstances, females may choose to de-emphasize their identity as females
by modulating their language usage to sound more male. thus, while this exception
serves to highlight rather than challenge the commonly accepted symbolic association
between gender and language, it nevertheless means that it is less feasible to predict
how a female will sound in a randomly selected context.

speaker agency also enables creative violations of conventional language patterns.
just as with any violation of expectations, these creative violations communicate indi-
rect meanings. as these violations become conventionalized, they may be one vehicle
towards language change. thus, agency plays a role in explaining the variation in
and dynamic nature of language practices, both within individual speakers and across
speakers. this variation is manifested at various levels of expression     the choice of
lexical elements, phonological variants, semantic alternatives and grammatical patterns
    and plays a central role in the phenomenon of linguistic change. the audience,
demographic variables (e.g., gender, age), and speaker goals are among the factors
that in   uence how variation is exhibited in speci   c contexts. agency thus increases
the intricate complexity of language that must be captured in order to achieve a social
interpretation of language.

sociolinguistics investigates the reciprocal in   uence of society and language on
each other. sociolinguists traditionally work with spoken data using qualitative and
quantitative approaches. surveys and ethnographic research have been the main meth-
ods of data collection (eckert 1989; milroy and milroy 1985; milroy and gordon 2003;
tagliamonte 2006; trudgill 1974; weinreich, labov, and herzog 1968). the datasets
used are often selected and/or constructed to facilitate controlled statistical analyses
and insightful observations. however, the resulting datasets are often small in size
compared to the standards adopted by the cl community. the massive volumes of data
that have become available from sources such as social media platforms have provided
the opportunity to investigate language variation more broadly. the opportunity for

1 we use the term    speaker    for an individual who has produced a message, either as spoken word or in

textual format. when discussing particular social media sites, we may refer to    users    as well.

2

nguyen et al.

computational sociolinguistics: a survey

the    eld of sociolinguistics is to identify questions that this massive but messy data
would enable them to answer. sociolinguists must then also select an appropriate
methodology. however, typical methods used within sociolinguistics would require
sampling the data down. if they take up the challenge to instead analyze the data in
its massive form, they may    nd themselves open to partnerships in which they may
consider approaches more typical in the    eld of cl.

as more and more researchers in the    eld of cl seek to interpret language from a
social perspective, an increased awareness of insights from the    eld of sociolinguistics
could inspire modeling re   nements and potentially lead to performance gains. re-
cently, various studies (hovy 2015; stoop and van den bosch 2014; volkova, wilson,
and yarowsky 2013) have demonstrated that existing nlp tools can be improved by
accounting for linguistic variation due to social factors, and hovy and s  gaard (2015)
have drawn attention to the fact that biases in frequently used corpora, such as the
wall street journal, cause nlp tools to perform better on texts written by older people.
the rich repertoire of theory and practice developed by sociolinguists could impact the
   eld of cl also in more fundamental ways. the boundaries of communities are often
not as clear-cut as they may seem and the impact of agency has not been suf   ciently
taken into account in many computational studies. for example, an understanding of
linguistic agency can explain why and when there might be more or less of a problem
when making id136s about people based on their linguistic choices. this issue is
discussed in depth in some recent computational work related to gender, speci   cally
bamman, eisenstein, and schnoebelen (2014) and nguyen et al. (2014) who provide a
critical re   ection on the operationalization of gender in cl studies.

the increasing interest in analyzing and modeling the social dimension of language
within cl encourages collaboration between sociolinguistics and cl in various ways.
however, the potential for synergy between the two    elds has not been explored
systematically so far (eisenstein 2013b) and to date there is no overview of the common
and complementary aspects of the two    elds. this article aims to present an integrated
overview of research published in the two communities and to describe the state-of-
the-art in the emerging multidisciplinary    eld that could be labeled as    computational
sociolinguistics   . the envisaged audiences are cl researchers interested in sociolinguis-
tics and sociolinguists interested in computational approaches to study language use.
we hope to demonstrate that there is enough substance to warrant the recognition of
   computational sociolinguistics    as an autonomous yet multidisciplinary research area.
furthermore, we hope to convey that this is the moment to develop a research agenda
for the scholarly community that maintains links with both sociolinguistics and compu-
tational linguistics.

in the remaining part of this section, we discuss the rationale and scope of our
survey in more detail as well as the potential impact of integrating the social dimen-
sions of language use in the development of practical nlp applications. in section 2
we discuss methods for computational sociolinguistics, in which we re   ect on methods
used in sociolinguistics and computational linguistics. in section 3, language and social
identity construction, we discuss how speakers use language to shape perception of their
identity and focus on computational approaches to model language variation based on
gender, age and geographical location. in section 4 on language and social interaction,
we move from individual speakers to pairs, groups and communities and discuss the
role of language in shaping personal relationships, the use of style-shifting, and the
adoption of norms and language change in communities. in section 5 we discuss multi-
lingualism and social interaction, in which we present an overview of tools for processing
multilingual communication, such as parsers and language identi   cation systems. we

3

computational linguistics

to appear

will also discuss approaches for analyzing patterns in multilingual communication
from a computational perspective. in section 6 we conclude with a summary of major
challenges within this emerging    eld.

1.1 rationale for a survey of computational sociolinguistics

the increased interest in studying a social phenomenon such as language use from a
data-driven or computational perspective exempli   es a more general trend in scholarly
agendas. the study of social phenomena through computational methods is commonly
referred to as    computational social science    (lazer et al. 2009). the increasing interest
of social scientists in computational methods can be regarded as illustrating the general
increase of attention for cross-disciplinary research perspectives.    multidisciplinary   ,
   interdisciplinary   ,    cross-disciplinary    and    transdisciplinary    are among the labels used
to mark the shift from monodisciplinary research formats to models of collaboration
that embrace diversity in the selection of data and methodological frameworks. how-
ever, in spite of various attempts to harmonize terminology, the adoption of such labels
is often poorly supported by de   nitions and they tend to be used interchangeably. the
objectives of research rooted in multiple disciplines often include the ambition to resolve
real world or complex problems, to provide different perspectives on a problem, or to
create cross-cutting research questions, to name a few (choi and pak 2006).

the emergence of research agendas for (aspects of) computational sociolinguistics
   ts in this trend. we will use the term computational sociolinguistics for the emerging
research    eld that integrates aspects of sociolinguistics and computer science in study-
ing the relation between language and society from a computational perspective. this
survey article aims to show the potential of leveraging massive amounts of data to study
social dynamics in language use by combining advances in computational linguistics
and machine learning with foundational concepts and insights from sociolinguistics.
our goals for establishing computational sociolinguistics as an independent research
area include the development of tools to support sociolinguists, the establishment of
new statistical methods for the modeling and analysis of data that contains linguistic
content as well as information on the social context, and the development or re   nement
of nlp tools based on sociolinguistic insights.

1.2 scope of discussion

given the breadth of this    eld, we will limit the scope of this survey as follows. first
of all, the coverage of sociolinguistics topics will be selective and primarily determined
by the work within computational linguistics that touches on sociolinguistic topics. for
readers with a wish for a more complete overview of sociolinguistics, we recommend
the introductory readings by bell (2013), holmes (2013) and meyerhoff (2011).

the availability of social media and other online language data in computer-
mediated formats is one of the primary driving factors for the emergence of compu-
tational sociolinguistics. a relevant research area is therefore the study of computer-
mediated communication (cmc) (herring 1996). considering the strong focus on
speech data within sociolinguistics, there is much potential for computational ap-
proaches to be applied to spoken language as well. moreover, the increased availability
of recordings of spontaneous speech and transcribed speech has inspired a revival in
the study of the social dimensions of spoken language (jain et al. 2012), as well as in the
analysis of the relation between the verbal and the nonverbal layers in spoken dialogues
(truong et al. 2014). as online data increasingly becomes multimodal, for example

4

nguyen et al.

computational sociolinguistics: a survey

with the popularity of vlogs (video blogs), we expect the use of spoken word data
for computational sociolinguistics to increase. furthermore, we expect that multimodal
analysis, a topic that has been the focus of attention in the    eld of human-computer
interaction for many years, will also receive attention in computational sociolinguistics.
in the study of communication in pairs and groups, the individual contributions are
often analyzed in context. therefore, much of the work on language use in settings with
multiple speakers draws from foundations in discourse analysis (de fina, schiffrin, and
bamberg 2006; hyland 2004; martin and white 2005; schegloff 2007), pragmatics (such
as speech act theory (austin 1975; searle 1969)), rhetorical structure theory (mann and
thompson 1988; taboada and mann 2006) and social psychology (giles and coupland
1991; postmes, spears, and lea 2000; richards 2006). for studies within the scope of
computational sociolinguistics that build upon these    elds the link with the founda-
tional frameworks will be indicated. another relevant    eld is computational stylometry
(daelemans 2013; holmes 1998; stamatatos 2009), which focuses on computational
models of writing style for various tasks such as plagiarism detection, author pro   ling
and authorship attribution. here we limit our discussion to publications on topics such
as the link between style and social variables.

1.3 nlp applications

besides yielding new insights into language use in social contexts, research in compu-
tational sociolinguistics could potentially also impact the development of applications
for the processing of textual social media and other content. for example, user pro   ling
tools might bene   t from research on automatically detecting the gender (burger et al.
2011), age (nguyen et al. 2013), geographical location (eisenstein et al. 2010) or af   li-
ations of users (piergallini et al. 2014) based on an analysis of their linguistic choices.
the cases for which the interpretation of the language used could bene   t most from
using variables such as age and gender are usually also the ones for which it is most
dif   cult to automatically detect those variables. nevertheless, in spite of this kind of
challenge, there are some published proofs of concept that suggest potential value in
advancing past the typical assumption of homogeneity of language use embodied in
current nlp tools. for example, incorporating how language use varies across social
groups has improved word prediction systems (stoop and van den bosch 2014), al-
gorithms for cyberbullying detection (dadvar et al. 2012) and sentiment-analysis tools
(hovy 2015; volkova, wilson, and yarowsky 2013). hovy and s  gaard (2015) show
that pos taggers trained on well-known corpora such as the english id32
perform better on texts written by older authors. they draw attention to the fact that
texts in various frequently used corpora are from a biased sample of authors in terms
of demographic factors. furthermore, many nlp tools currently assume that the input
consists of monolingual text, but this assumption does not hold in all domains. for
example, social media users may employ multiple language varieties, even within a
single message. to be able to automatically process these texts, nlp tools that are able
to deal with multilingual texts are needed (solorio and liu 2008b).

2. methods for computational sociolinguistics

as discussed, one important goal of this article is to stimulate collaboration between
the    elds of sociolinguistics in particular and social science research related to commu-
nication at large on the one hand, and computational linguistics on the other hand. by
addressing the relationship with methods from both sociolinguistics and the social sci-

5

computational linguistics

to appear

ences in general we are able to underline two expectations. first of all, we are convinced
that sociolinguistics and related    elds can help the    eld of computational linguistics to
build richer models that are more effective for the tasks they are or could be used for.
second, the time seems right for the cl community to contribute to sociolinguistics
and the social sciences, not only by developing and adjusting tools for sociolinguists,
but also by re   ning the theoretical models within sociolinguistics using computational
approaches and contributing to the understanding of the social dynamics in natural
language. in this section, we highlight challenges that re   ect the current state of the
   eld of computational linguistics. in part these challenges relate to the fact that in the
   eld of language technologies at large, the methodologies of social science research are
usually not valued, and therefore also not taught. there is a lack of familiarity with
methods that could easily be adopted if understood and accepted. however, there are
promising examples of bridge building that are already occurring in related    elds such
as learning analytics. more speci   cally, in the emerging area of discourse analytics there
are demonstrations of how these practices could eventually be observed within the
language technologies community as well (ros   in press; ros   and tovares 2015; ros  
et al. 2008).

at the outset of multidisciplinary collaboration, it is necessary to understand differ-
ences in goals and values between communities, as these differences strongly in   uence
what counts as a contribution within each    eld, which in turn in   uences what it would
mean for the    elds to contribute to one another. towards that end, we    rst discuss
the related but distinct notions of reliability and validity, as well as the differing roles
these notions have played in each    eld (section 2.1). this will help lay a foundation for
exploring differences in values and perspectives between    elds. here, it will be most
convenient to begin with quantitative approaches in the social sciences as a frame of
reference. in section 2.2 we discuss contrasting notions of theory and empiricism as well
as the relationship between the two, as that will play an important and complementary
role in addressing the concern over differing values. in section 2.3 we broaden the scope
to the spectrum of research approaches within the social sciences, including strong
quantitative and strong qualitative approaches, and the relationship between cl and
the social disciplines involved. this will help to further specify the concrete challenges
that must be overcome in order for a meaningful exchange between communities to take
place. in section 2.4 we illustrate how these issues come together in the role of data, as
the collection, sampling, and preparation of data are of central importance to the work
in both    elds.

2.1 validation of modeling approaches

the core of much research in the    eld of computational linguistics, in the past decade
especially, is the development of new methods for computational modeling, such as
probabilistic id114 and deep learning within a neural network approach.
these novel methods are valued both for the creativity that guided the speci   cation
of novel model structures and the corresponding requirement for new methods of
id136 as well as the achievement of predictive accuracy on tasks for which there is
some notion of a correct answer.

development of new modeling frameworks is part of the research production cycle
both within sociolinguistics (and the social sciences in general) and the cl community,
and there is a lot of overlap with respect to the types of methods used. for example,
id28 is widely employed by variationist sociolinguists using a program
called varbrul (tagliamonte 2006). similarly, id28 is widely used in the

6

nguyen et al.

computational sociolinguistics: a survey

cl community, especially in combination with id173 methods when dealing
with thousands of variables, for example for age prediction (nguyen et al. 2013). as
another example, latent variable modeling approaches (koller and friedman 2009) have
grown in prominence within the cl community for id84, manag-
ing heterogeneity in terms of multiple domains or multiple tasks (zhang, ghahramani,
and yang 2008), and approximation of semantics (blei, ng, and jordan 2003; grif   ths
and steyvers 2004). similarly, it has grown in prominence within the quantitative
branches of the social sciences for modeling causality (glymour et al. 1987), managing
heterogeneity in terms of group effects and subpopulations (collins and lanza 2010),
and time series modeling (rabe-hesketh and skrondal 2012; rabe-hesketh, skrondal,
and pickles 2004).

the differences in reasons for the application of similar techniques are indicative of
differences in values. while in cl there is a value placed on creativity and predictive
accuracy, within the social sciences, the related notions of validity and reliability under-
line the values placed on conceptual contributions to the    eld. validity is primarily a
measure of the extent to which a research design isolates a particular issue from con-
founds so that questions can receive clear answers. this typically requires creativity, and
frequently research designs for isolating issues effectively are acknowledged for this
creativity in much the same way a novel graphical model would be acknowledged for
the elegance of its mathematical formulation. reliability, on the other hand, is primarily
a measure of the reproducibility of a result and might seem to be a distinct notion from
predictive accuracy. however, the connection is apparent when one considers that a
common notion of reliability is the extent to which two human coders would arrive at
the same judgment on a set of data points, whereas predictive accuracy is the extent to
which a model would arrive at the same judgment on a set of data points as a set of
judgements decided ahead of time by one or more humans.

while at some deep level there is much in common between the goals and values of
the two communities, the differences in values signi   ed by the emphasis on creativity
and predictive accuracy on the one side and reliability and validity on the other side
nevertheless poses challenges for mutual exchange. validity is a multi-faceted notion,
and it is important to properly distinguish it from the related notion of reliability. if
one considers shooting arrows at a target, one can consider reliability to be a measure
of how much convergence is achieved in location of impact of multiple arrows. on
the other hand, validity is the extent to which the point of convergence centers on
the target. reproducibility of results is highly valued in both    elds, which requires
reliability wherever human judgment is involved, such as in the production of a gold
standard (carletta 1996; di eugenio and glass 2004). however, before techniques from
cl will be adopted by social science researchers, standards of validation from the social
sciences will likely need to be addressed (krippendorff 2013). we will see that this
notion requires more than the related notion of creativity as appreciated within the    eld
of cl.

one aspect that is germane to the notion of validity that goes beyond pure creativity
is the extent to which the essence that some construct actually captures corresponds to
the intended quantity. this aspect of validity is referred to as face validity. for exam-
ple, the face validity of a id31 tool could be tested as follows. first, an
automatic measure of sentiment would be applied to a text corpus. then, texts would
be sorted by the resulting sentiment scores and the data points from the end points
and middle compared with one another. are there consistent and clear distinctions
in sentiment between beginning, middle, and end? is sentiment the main thing that
is captured in the contrast, or is something different really going on? while the cl

7

computational linguistics

to appear

community has frequently upheld high standards of reliability, it is rare to    nd work
that deeply questions whether the models are measuring the right thing. nevertheless,
this deep questioning is core to high quality work in the social sciences, and without it,
the work may appear weak.

another important notion is construct validity, or the extent to which the experi-
mental design manages extraneous variance effectively. if the design fails to do so,
it affects the interpretability of the result. this notion applies when we interpret the
learned weights of features in our models to make statements about language use.
when not controlling for confounding variables, the feature weights are misleading and
valid interpretation is not possible. for example, many studies on gender prediction
(see section 3) ignore extraneous variables such as age, while gender and age are
known to interact with each other highly. where confounds may not have been properly
eliminated in an investigation, again the results may appear weak regardless of the
numbers associated with the measure of predictive accuracy.

another important methodological idea is triangulation. simply put, it is the idea
that if you look at the same object through different lenses, each of which is designed
to accentuate and suppress different kinds of details, you get more information than
if you looked through just one, analogous to the value obtained through the use of
ensemble methods like id112. triangulation is thus an important way of strengthening
research    ndings in the social sciences by leveraging multiple views simultaneously
rather than just using one in addressing a question. id31 can again
be used for illustration purposes. consider a blog corpus for which the age of each
individual blogger is available. let   s assume that a model for predicting age allocated
high weights to some sentiment-related words. this may be considered as evidence
that the model is consistent with previous    ndings that older people use more words
that express a positive sentiment. another method could measure sentiment for each
blog individually. if the measured sentiment would correlate with the age of bloggers
across the corpus, the two methods for investigating the connection between age and
sentiment would tell the same story and the con   dence in the validity of the story would
increase. this type of con   rming evidence is referred to as an indication of convergent
validity.

another form of triangulation is where distinctions known to exist are con   rmed.
for this example, assume that a particular model for predicting political af   liation
placed high weights on some sentiment-related words in a corpus related to issues for
which those af   liated with one political perspective would take a different stance than
those af   liated with another perspective, and this af   liation is known for all data points.
the experimenters may conclude that this evidence is consistent with previous    ndings
suggesting that voters express more positive sentiment towards political stances they
are in favor of. if this is true, then if the model is applied to a corpus where both parties
agree on a stance, the measure of sentiment should become irrelevant. assuming the
difference in the role of sentiment between the corpora is consistent with what is ex-
pected, the interpretation is strengthened. this is referred to as divergent validity since
an expected difference in relationship is con   rmed. seeking convergent and divergent
validity is a mark of high quality work in the social sciences, but it is rare in evaluations
in the    eld of cl, and without it, again, the results may appear weak from a social
science perspective. in order for methods from cl to be acceptable for use within the
social sciences, these perceived weaknesses must be addressed.

8

nguyen et al.

computational sociolinguistics: a survey

2.2 theory versus empiricism

above we discussed the importance placed on validity within the social sciences that
stems from the goal of isolating an issue in order to answer questions. in order to clarify
why that is important, it is necessary to discuss the value placed on theory versus
empiricism.

within the cl community, a paradigm shift took place after the middle of the 1990s.
initially, approaches that combined symbolic and statistical methods were of interest
(klavans and resnik 1996). but with the focus on very large corpora and new frame-
works for large-scale statistical modeling, symbolic- and knowledge-driven methods
have been largely left aside, though the presence of linguistics as an active force can
still be seen in some areas of computational linguistics, such as tree banking. along
with older symbolic methods that required carefully crafted grammars and lexicons,
the concept of knowledge source has become strongly associated with the notion of
theory, which is consistent with the philosophical notion of linguistic theory advocated
by chomskyan linguistics and other formal linguistic theories (backofen and smolka
1993; green 1992; schneider, dowdall, and rinaldi 2004; wintner 2002). as knowledge-
based methods have to a large extent been replaced with statistical models, a grounding
in linguistic theory has become less and less valued. a desire to replace theory with
empiricism dominated the zeitgeist and drove progress within the    eld. currently, the
term theory seems to be associated with old and outdated approaches. it often has a
negative connotation in contrast to the positive reception of empiricism, and contem-
porary modeling approaches are believed to have a greater ability to offer insights into
language than symbolic modeling frameworks.

in contrast, in the social sciences the value of a contribution is measured in terms
of the extent to which it contributes towards theory. theories may begin with human
originated ideas. but these notions are only treated as valuable if they are con   rmed
through empirical methods. as these methods are applied, theoretical models gain
empirical support. findings are rati   ed and then accumulated. therefore, theories
become storehouses for knowledge obtained through empirical methods. atheoretical
empiricism is not attractive within the social sciences where the primary value is on
building theory and engaging theory in the interpretation of models.

as cl seeks to contribute to sociolinguistics and the social sciences, this divide
of values must be addressed in order to avoid the    elds talking at cross purposes.
to stimulate collaboration between    elds, it is important to not only focus on task
performance, but also to integrate existing theories into the computational models and
use these models to re   ne or develop new theories.

2.3 quantitative versus qualitative approaches

the social sciences have both strong qualitative and quantitative branches. similarly,
sociolinguistics has branches in qualitative research (e.g., interactional sociolinguis-
tics) and quantitative research (variationist sociolinguistics). from a methodological
perspective, most computational sociolinguistics work has a strong resemblance with
quantitative and therefore variationist sociolinguistics, which has a strong focus on
statistical analysis to uncover the distribution of sociolinguistic variables (tagliamonte
2006). so far we have mostly re   ected on methods used in cl and their commonality
with the methods used in the quantitative branches in sociolinguistics and the social
sciences, but the time is right for a greater focus on how qualitative methods may also
be of use. some thoughts about what that might look like can be found in the work of

9

computational linguistics

to appear

ros   and tovares (2015), who explore the productive tension between the two branches
as it relates to interaction analysis. the    eld of computational linguistics could bene   t
from exploring this tension to a greater degree in its own work, for example by taking a
deeper look at data through human eyes as part of the validation of constructed models.
the tension between qualitative and quantitative branches can be illustrated with
the extent to which the agency of speakers is taken into account. as explained in the
introduction, linguistic agency refers to the freedom of speakers to make choices about
how they present themselves in interaction. a contrasting notion is the extent to which
social structures in   uence the linguistic choices speakers make. regardless of research
tradition, it is acknowledged that speakers both have agency and are simultaneously
in   uenced by social structures. the question is which is emphasized in the research
approach. quantitative researchers believe that the most important variance is captured
by representation of the social structure. they recognize that this is a simpli   cation, but
the value placed on quanti   cation for the purpose of identifying causal connections
between variables makes the sacri   ce of accuracy worth it. in the    eld of cl, this
valuing is analogous to the well-known saying that all models are wrong, but some
are nevertheless useful. on the other side are researchers committed to the idea that
the most important and interesting aspects of language use are the ones that violate
norms in order for the speaker to achieve a goal. these researchers may doubt that the
bulk of choices made by speakers can be accounted for by social structures. we see the
balance and tension between the ideas of language re   ecting established social struc-
tures and language arising from speaker agency within current trends in variationist
sociolinguistics. much of that work focused on the ways in which language variation
can be accounted for by reference to social structures (bell 2013). on the other hand,
more recently the agency of speakers is playing a more central role as well in variationist
sociolinguistics (eckert 2012).

while in cl qualitative research is sometimes dismissed as being quantitative work
that lacks rigor, one could argue that high quality qualitative research has a separate
notion of rigor and depth that is all its own (morrow and brown 1994). an impor-
tant role for qualitative research is to challenge the operationalizations constructed by
quantitative researchers. to achieve the adoption of cl methods and models by social
science researchers, the challenges from the qualitative branches of the social sciences
will become something to consider carefully.

as computational linguistics shares more values with variationist sociolinguistics,
many studies within computational sociolinguistics also focus on the in   uence of social
structures. for example, work on predicting social variables such as gender (section 3)
is built on the idea that gender determines the language use of speakers. however,
such research ignores the agency of speakers: speakers use language to construct their
identity and thus not everyone might write in a way that re   ects their biological sex.
moving forward, it would make sense for researchers in computational sociolinguistics
to re   ect on the dominant role of social structures over agency. some work in cl
has already begun to acknowledge the agency of speakers when interpreting    ndings
(bamman, eisenstein, and schnoebelen 2014; nguyen et al. 2014).

one way of conceptualizing the contrast between the usage of computational mod-
els in the two    elds is to reconsider the trade-off between maximizing interpretabil-
ity     typical of the social sciences and sociolinguistics    , and maximizing predic-
tive accuracy, typical of cl. both    elds place a premium on rigor in evaluation and
generalization of results across datasets. to maintain a certain standard of rigor, the
cl community has produced practices for standardization of metrics, sampling, and
avoidance of over   tting or overestimation of performance through careful separation of

10

nguyen et al.

computational sociolinguistics: a survey

training and testing data at all stages of model development. within the social sciences,
the striving for rigor has also produced statistical machinery for analysis, but most of
all it has resulted in an elaborate process for validation of such modeling approaches
and practices for careful application and interpretation of the results.

one consequence of the focus on interpretability within the social sciences is that
models tend to be kept small and simple in terms of the number of parameters, fre-
quently no more than 10, or at least no more than 100. because the models are kept
simple, they can be estimated on smaller datasets, as long as sampling is done carefully
and extraneous variance is controlled. in the cl community, it is more typical for mod-
els to include tens of thousands of parameters or more. for such large models, massive
corpora are needed to prevent over   tting. as a result, research in the cl community is
frequently driven by the availability of large corpora, which explains the large number
of recent papers on data from the web, such as twitter and wikipedia. because of this
difference in scale, a major focus on parallelization and approximate id136 has been
an important focus of work in cl (heskes, albers, and kappen 2002), whereas interest
in such methods has only recently grown within the social sciences.

2.4 spotlight on corpora and other data

data collection is a fundamental step in the research cycle for researchers in both
sociolinguistics and computational linguistics. here we will re   ect on the differences
in the practices and traditions within both    elds and on the emerging use of online
data. in the subsequent sections of this survey, there will be dedicated subsections about
the data sources used in the speci   c studies relevant to the discussed themes (e.g., on
identity construction).

traditionally, sociolinguists have been interested in datasets that capture informal
speech (also referred to as the    vernacular   ), i.e., the kind of language used when speakers
are not paying attention (tagliamonte 2006). a variety of methods have been used to
collect data, including observation, surveys and interviews (mallinson, childs, and
herk 2013; tagliamonte 2006). the sociolinguistic datasets are carefully prepared to
enable in-depth analyses of how a speech community operates, carefully observing
standards of reliability and validity as discussed previously. inevitably, these data
collection methods are labor-intensive and time-consuming. the resulting datasets are
often small in comparison to the ones used within computational linguistics. the small
sizes of these datasets made the work in sociolinguistics of limited interest to the    eld
of cl.

the tide began to turn with the rise of computer mediated communication (cmc).
herring (2007) de   nes cmc as    predominantly text-based human-human interaction me-
diated by networked computers or mobile telephony   . the content generated in cmc, and
in particular when generated on social media platforms, is a rich and easy to access
source of large amounts of informal language coming together with information about
the context (e.g., the users, social network structure, the time or geolocation at which
it was generated) that can be used for the study of language in social contexts on a
large scale. examples include microblogs (eisenstein et al. 2014; kooti et al. 2012), web
forums (garley and hockenmaier 2012; nguyen and ros   2011) and online review
sites (danescu-niculescu-mizil et al. 2013b; hovy, johannsen, and s  gaard 2015). for
example, based on data from twitter (a popular microblogging site) dialectal variation
has been mapped using a fraction of the time, costs and effort that was needed in
traditional studies (doyle 2014). however, data from cmc is not always easy to collect.
as an example, while text messaging (sms) is widely used, collecting sms data has

11

computational linguistics

to appear

been dif   cult due to both technical and privacy concerns. the sms4science project
(d  rscheid and stark 2011) aims to overcome these dif   culties by asking people to
donate their messages, collaborating with the service providers for the collection of the
messages, and applying anonymization to ensure privacy.

a complicating issue in data collection in sociolinguistics is that participants might
adjust their language use towards the expectations of the data collector. this phe-
nomenon is known as the    observer   s paradox   , a term    rst coined by labov (1972): "the
aim of linguistic research in the community must be to    nd out how people talk when they are
not being systematically observed; yet we can only obtain these data by systematic observation".
in social media, the observer   s paradox could potentially be argued to have lost much
of its strength, making it a promising resource to complement traditional data collection
methods. while a convenient source of data, the use of social media data does introduce
new challenges that must be addressed regardless of    eld, and this offers a convenient
beginning to a potential exchange between    elds.

first, social media users are usually not representative of the general population
(mislove et al. 2011; nguyen et al. 2013). a better understanding of the demographics
could aid the interpretation of    ndings, but often little is known about the users. collect-
ing demographic information requires signi   cant effort, or might not even be possible
in some cases due to ethical concerns. furthermore, in many cases the complete data is
not fully accessible through an api, requiring researchers to apply a sampling strategy
(e.g., randomly, by topic, time, individuals/groups, phenomenon (androutsopoulos
2013; herring 2004)). sampling may introduce additional biases or remove important
contextual information. these problems are even more of a concern when datasets
are reused for secondary analysis by other researchers whose purposes might be very
different from those who performed the sampling.

social media data also introduces new units of analysis (such as messages and
threads) that do not correspond entirely with traditional analysis units (such as sen-
tences and turns) (androutsopoulos 2013). this raises the question about valid applica-
tion of    ndings from prior work. another complicating factor is that in social media the
target audience of a message is often not explicitly indicated, i.e., multiple audiences
(e.g., friends, colleagues) are collapsed into a single context (marwick and boyd 2011).
some studies have therefore treated the use of hashtags and user mentions as proxies for
the target audience (nguyen, trieschnigg, and cornips 2015; pavalanathan and eisen-
stein 2015a). furthermore, while historically the    eld of sociolinguistics started with a
major focus on phonological variation, e.g., labov (1966), the use of social media data
has led to a higher focus on lexical variation in computational sociolinguistics. however,
there are concerns that a focus on lexical variation without regard to other aspects may
threaten the validity of conclusions. phonology does impact social media orthography
at both the word level and structural level (eisenstein 2013a), suggesting that studies on
phonological variation could inform studies based on social media text data and vice
versa. for example, eisenstein (2013a) found that consonant cluster reduction (e.g., just
vs. jus) in twitter is in   uenced by the phonological context, in particular, reduction was
less likely when the word was followed by a segment that began with a vowel.

there are practical concerns as well. first, while both access and content have
often been conceptualized as either public or private, in reality this distinction is not
as absolute, for example, a user might discuss a private topic on a public social media
site. in view of the related privacy issues, bolander and locher (2014) argue for more
awareness regarding the ethical implications of research using social media data.

automatically processing social media data is more dif   cult compared to various
other types of data that have been used within computational linguistics. many de-

12

nguyen et al.

computational sociolinguistics: a survey

veloped tools (e.g., parsers, named entity recognizers) do not work well due to the
informal nature of many social media texts. while the dominant response has been
to focus on text id172 and id20, eisenstein (2013b) argues that
doing so is throwing away meaningful variation. for example, building on work on text
id172, gouws et al. (2011) showed how various transformations (e.g., dropping
the last character of a word) vary across different user groups on twitter. as another
example, brody and diakopoulos (2011)    nd that lengthening of words (e.g., cooooll) is
often applied to subjective words. they build on this observation to detect sentiment-
bearing words. the tension between normalizing and preserving the variation in text
also arises in the processing and analysis of historical texts (see piotrowski (2012) for an
overview), which also contain many spelling variations. in this domain, id172
is often applied as well to facilitate the use of tools such as parsers. however, some
approaches    rst normalize the text, but then replace the modernized word forms with
the original word forms to retain the original text. another issue with social media data
is that many social media studies have so far focused primarily on one data source. a
comparison of the online data sources in terms of language use has only been done in a
few studies (baldwin et al. 2013; hu, talamadupula, and kambhampati 2013).

another up and coming promising resource for studying language from a social
perspective is id104. so far, id104 is mostly used to obtain large
numbers of annotations, e.g., snow et al. (2008). however,    crowds    can also be used
for large-scale perception studies, i.e., to study how non-linguists interpret messages
and identify social characteristics of speakers (clopper 2013), and for the collection of
linguistic data, such as the use of variants of linguistic variables. within sociolinguistics,
surveys have been one of the instruments to collect data and id104 is an
emerging alternative to traditional methods for collecting survey data.

id104 has already been used to obtain perception data for sociolinguistic
research, for example, to study how english utterances are perceived differently across
language communities (makatchev and simmons 2011) and to obtain native-likeness
ratings of speech samples (wieling et al. 2014). for some studies, games have been
developed to collect data. nguyen et al. (2014) studied how twitter users are perceived
based on their tweets by asking players to guess the gender and age based on displayed
tweets. leemann et al. (2016) developed a mobile app that predicted the user   s location
based on a 16-question survey. by also collecting user feedback on the predictions, the
authors compared their data with the linguistic atlas of german-speaking switzerland,
which was collected about 70 years before the id104 study. the mismatches
between the atlas data and self-reported data from the mobile app were seen to suggest
linguistic change in progress.

id104 also introduces challenges. for example, the data collection method
is less controlled and additional effort for quality control is often needed. even more
problematic is that usually little is known is about the workers, such as the communities
they are part of. for example, wieling et al. (2014) recruited participants using e-
mail, social media and blogs, which resulted in a sample that was likely to be biased
towards linguistically interested people. however, they did not expect that the possible
bias in the data in   uenced the    ndings much. another concern is that participants
in id104 studies might modulate their answers towards what they think is
expected, especially when there is a monetary compensation. in the social sciences in
general, id104 is also increasingly used for survey research. behrend et al.
(2011) compared the data collected using id104 with data collected from a tra-
ditional psychology participant pool (undergraduates) in the context of organizational
psychology research and concluded that id104 is a potentially viable resource

13

computational linguistics

to appear

to collect data for this research area. while thus promising, the number of studies so
far using id104 for sociolinguistic research is small and more research needs
to be done to study the strengths and weaknesses of this data collection method for
sociolinguistic research.

3. language and social identity

we now turn to discussing computational approaches for modeling language variation
related to social identity. speakers use language to construct their social identity (bu-
choltz and hall 2005). being involved in communicative exchange can be functional for
the transfer of information, but at the same it functions as a staged performance in which
users select speci   c codes (e.g., language, dialect, style) that shape their communication
(wardhaugh 2011). consciously or unconsciously speakers adjust their performance to
the speci   c social context and to the impression they intend to make on their audience.
each speaker has a personal linguistic repertoire to draw linguistic elements or codes
from. selecting from the repertoire is partially subject to    identity work   , a term referring
to the range of activities that individuals engage in to create, present, and sustain
personal identities that are congruent with and supportive of the self-concept (snow
and anderson 1987).

language is one of the instruments that speakers use in shaping their identities,
but there are limitations (e.g., physical or genetic constraints) to the variation that
can be achieved. for example, somebody with a smoker   s voice may not be able to
speak with a smooth voice but many individual characteristics still leave room for
variation. although traditionally attributed an absolute status, personal features (e.g.,
age and gender) are increasingly considered social rather than biological variables.
within sociolinguistics, a major thrust of research is to uncover the relation between
social variables (e.g., gender, age, ethnicity, status) and language use (eckert 1997;
eckert and mcconnell-ginet 2013; holmes and meyerhoff 2003; wagner 2012). the
concept of sociolects, or social dialects, is similar to the concept of regional dialects.
while regional dialects are language varieties based on geography, sociolects are based
on social groups, e.g., different groups according to social class (with labels such as
   working class    and    middle class   ), or according to gender or age. a study by guy (2013)
suggests that the cohesion between variables (e.g., nominal agreement, denasalization)
to form sociolects is weaker than usually assumed. the unique use of language by
an individual is an idiolect, and this concept is in particular relevant for authorship
attribution (e.g., grieve (2007)).

recognizing that language use can reveal social patterns, many studies in computa-
tional linguistics have focused on automatically inferring social variables from text. this
task can be seen as a form of automatic metadata detection that can provide information
on author features. the growing interest in trend analysis tools is one of the drivers for
the interest in the development and re   nement of algorithms for this type of metadata
detection. however, tasks such as gender and age prediction do not only appeal to
researchers and developers of trend mining tools. various public demos have been able
to attract the attention of the general public (e.g., tweetgenie2 (nguyen, trieschnigg,
and meder 2014) and gender guesser3), which can be attributed to a widespread
interest in the entertaining dimension of the linguistic dimension of identity work. the

2 http://www.tweetgenie.nl
3 http://www.hackerfactor.com/genderguesser.php

14

nguyen et al.

computational sociolinguistics: a survey

automatic prediction of individual features such as age and gender based on only text
is a nontrivial task. studies that have compared the performance of humans with that
of automatic systems for gender and age prediction based on text alone found that
automatic systems perform better than humans (burger et al. 2011; nguyen et al. 2013).
a system based on aggregating guesses from a large number of people still predicted
gender incorrectly for 16% of the twitter users (nguyen et al. 2014). while most studies
use a supervised learning approach, a recent study by ardehaly and culotta (2015)
explored a lightly supervised approach using soft constraints. they combined unlabeled
geotagged twitter data with soft constraints, like the proportion of people below or
above 25 years in a county according to census data, to train their classi   ers.

within computational linguistics, linguistic variation according to gender, age and
geographical location have received the most attention, compared to other variables
such as ethnicity (ardehaly and culotta 2015; pennacchiotti and popescu 2011; rao
et al. 2011) and social class. labels for variables like social class are more dif   cult to
obtain and use because they are rarely made explicit in online user pro   les that are
publically available. only recently this direction has been explored, with occupation as
a proxy for variables like social class. occupation labels for twitter users have been
extracted from their pro   le description (preo  tiuc-pietro, lampos, and aletras 2015;
preo  tiuc-pietro et al. 2015; sloan et al. 2015). preo  tiuc-pietro et al. (2015) then mapped
the derived occupations to income and sloan et al. (2015) mapped the occupations to
social class categories. however, these studies were limited to users with self-reported
occupations in their pro   les.

many studies have focused on individual social variables, but these variables are
not independent. for example, there are indications that linguistic features that are used
more by males increase in frequency with age as well (argamon et al. 2007). as another
example, some studies have suggested that language variation across gender tends to
be stronger among younger people and to fade away with older ages (barbieri 2008).
eckert (1997) notes that the age considered appropriate for cultural events often differs
for males and females (e.g., getting married), which in   uences the interaction between
gender and age. the interaction between these variables is further complicated by the
fact that in many uncontrolled settings the gender distribution may not be equal for
different age ranges (as observed in blogs (burger and henderson 2006) and twitter
(nguyen et al. 2013)). therefore, failing to control for gender while studying age (and
vice versa) can lead to misinterpretation of the    ndings.

in this section an overview will be presented of computational studies of language
variation related to social identity. this section will    rst focus on the datasets that have
been used to investigate social identity and language variation in computational lin-
guistics (subsection 3.1). after surveying computational studies on language variation
according to gender (subsection 3.2), age (subsection 3.3) and location (subsection 3.4),
we conclude with a discussion of how various nlp tasks, such as sentiment detection,
can be improved by accounting for language variation related to the social identity of
speakers (subsection 3.5).

3.1 data sources

early computational studies on social identity and language use were based on formal
texts, such as the british national corpus (argamon et al. 2003; koppel, argamon,
and shimoni 2002), or datasets collected from controlled settings, such as recorded
conversations (singh 2001) and telephone conversations (boulis and ostendorf 2005;
garera and yarowsky 2009; van durme 2012) where protocols were used to coordinate

15

computational linguistics

to appear

the conversations (such as the topic). with the advent of social media, a shift is observed
towards more informal texts collected from uncontrolled settings. much of the initial
work in this domain focused on blogs. the blog authorship corpus (schler et al. 2006),
collected in 2004 from blogger.com, has been used in various studies on gender and
age (argamon et al. 2007; gianfortoni, adamson, and ros   2011; goswami, sarkar, and
rustagi 2009; nguyen, smith, and ros   2011; sap et al. 2014). others have created their
own blog corpus from various sources including livejournal and xanga (burger and
henderson 2006; mukherjee and liu 2010; nowson and oberlander 2006; rosenthal
and mckeown 2011; sarawgi, gajulapalli, and choi 2011; yan and yan 2006).

more recent studies are focusing on twitter data, which contains richer interactions
in comparison to blogs. burger et al. (2011) created a large corpus by following links
to blogs that contained author information provided by the authors themselves. the
dataset has been used in various subsequent studies (bergsma and van durme 2013;
van durme 2012; volkova, wilson, and yarowsky 2013). others created their own
twitter dataset (eisenstein, smith, and xing 2011; kokkos and tzouramanis 2014; liao
et al. 2014; rao et al. 2010; zamal, liu, and ruths 2012). while early studies focused on
english, recent studies have used twitter data written in other languages as well, like
dutch (nguyen et al. 2013), spanish and russian (volkova, wilson, and yarowsky 2013),
and japanese, indonesian, turkish, and french (ciot, sonderegger, and ruths 2013).
besides blogs and twitter, other web sources have been explored, including linkedin
(kokkos and tzouramanis 2014), imdb (otterbacher 2010), youtube (filippova 2012),
e-mails (corney et al. 2002), a belgian social network site (peersman, daelemans, and
vaerenbergh 2011) and facebook (rao et al. 2011; sap et al. 2014; schwartz et al. 2013).
two aspects can be distinguished that are often involved in the process of creating

datasets to study the relation between social variables and language use.

labeling. datasets derived from uncontrolled settings such as social media often lack
explicit information regarding the identity of users, such as their gender, age or location.
researchers have used different strategies to acquire adequate labels:

r

user-provided information. many researchers utilize information provided
by the social media users themselves, for example based on explicit    elds
in user pro   les (burger et al. 2011; schler et al. 2006; yan and yan 2006), or
by searching for speci   c patterns such as birthday announcements (zamal,
liu, and ruths 2012). while this information is probably highly accurate,
such information is often only available for a small set of users, e.g., for
age, 0.75% of the users in twitter (liao et al. 2014) and 55% in blogs
(burger and henderson 2006). locations of users have been derived based
on geotagged messages (eisenstein et al. 2010) or locations in user pro   les
(mubarak and darwish 2014).

r manual annotation. another option is manual annotation based on personal

information revealed in the text, pro   le information, and public
information on other social media sites (ciot, sonderegger, and ruths
2013; nguyen et al. 2013). in the manual annotation scenario, a random set
of authors is annotated. however, the required effort is much higher
resulting in smaller datasets and biases of the annotators themselves might
in   uence the annotation process. furthermore, for some users not enough
information may be available to even manually assign labels.

16

nguyen et al.

computational sociolinguistics: a survey

r

exploiting names. some labels can be automatically extracted based on the
name of a person. for example, gender information for names can be
derived from census information from the us social security
administration (bamman, eisenstein, and schnoebelen 2014; prabhakaran,
reid, and rambow 2014), or from facebook data (fink, kopecky, and
morawski 2012). however, people who use names that are more common
for a different gender will be incorrectly labeled in these cases. in some
languages, such as russian, the morphology of the names can also be used
to predict the most likely gender labels (volkova, wilson, and yarowsky
2013). however, people who do not provide their names, or have
uncommon names, will remain unlabeled. in addition, acquiring labels
this way has not been well studied yet for other languages and cultures
and for other types of labels (such as geographical location or age).

sample selection. in many cases, it is necessary to limit the study to a sample of persons.
sometimes the selected sample is directly related to the way labels are obtained, for
example by only including people who explicitly list their gender or age in their social
media pro   le (burger et al. 2011), who have a gender-speci   c    rst name (bamman,
eisenstein, and schnoebelen 2014), or who have geotagged tweets (eisenstein et al.
2010). restricting the sample, e.g., by only including geotagged tweets, could poten-
tially lead to biased datasets. pavalanathan and eisenstein (2015b) compared geotagged
tweets with tweets written by users with self-reported locations in their pro   le. they
found that geotagged tweets are more often written by women and younger peo-
ple. furthermore, geotagged tweets contain more geographically speci   c non-standard
words. another approach is random sampling, or as random as possible due to restric-
tions of targeting a speci   c language (nguyen et al. 2013). however, in these cases the
labels may not be readily available. this increases the annotation effort and in some
cases it may not even be possible to obtain reliable labels. focused sampling is used
as well, for example by starting with social media accounts related to gender-speci   c
behavior (e.g., male/female hygiene products, sororities) (rao et al. 2010). however,
such an approach has the danger of creating biased datasets, which could in   uence the
prediction performance (cohen and ruths 2013).

3.2 gender

the study of gender and language variation has received much attention in sociolin-
guistics (eckert and mcconnell-ginet 2013; holmes and meyerhoff 2003). various stud-
ies have highlighted gender differences. according to tannen (1990), women engage
more in    rapport    talk, focusing on establishing connections, while men engage more
in    report    talk, focusing on exchanging information. similarly, according to holmes
(1995), in women   s communication the social function of language is more salient,
while in men   s communication the referential function (conveying information) tends
to be dominant. argamon et al. (2003) make a distinction between involvedness (more
associated with women) and informational (more associated with men). however, with
the increasing view that speakers use language to construct their identity, such general-
izations have also been met with criticism. many of these studies rely on small sample
sizes and ignore other variables (such as ethnicity, social class) and the many similarities
between genders. such generalizations contribute to stereotypes and the view of gender
as an inherent property.

17

computational linguistics

to appear

3.2.1 modeling gender. within computational linguistics, researchers have focused
primarily on automatic gender classi   cation based on text. gender is then treated as
a binary variable based on biological characteristics, resulting in a binary classi   cation
task. a variety of machine learning methods have been explored, including id166s
(boulis and ostendorf 2005; ciot, sonderegger, and ruths 2013; corney et al. 2002;
fink, kopecky, and morawski 2012; gianfortoni, adamson, and ros   2011; mukherjee
and liu 2010; nowson and oberlander 2006; peersman, daelemans, and vaerenbergh
2011; rao et al. 2010; zamal, liu, and ruths 2012), id28 (bergsma and
van durme 2013; otterbacher 2010), naive bayes (goswami, sarkar, and rustagi 2009;
mukherjee and liu 2010; yan and yan 2006) and the winnow algorithm (burger et
al. 2011; schler et al. 2006). however, treating gender as a binary variable based on
biological characteristics assumes that gender is    xed and is something people have,
instead of something people do (butler 1990), i.e., such a setup neglects the agency of
speakers. many sociolinguists, together with scholars from the social sciences in general,
view gender as a social construct, emphasizing that gendered behavior is a result of
social conventions rather than inherent biological characteristics.

3.2.2 features and patterns. rather than focusing on the underlying machine learning
models, most studies have focused on developing predictive features. token-level and
character-level unigrams and id165s have been explored in various studies (bamman,
eisenstein, and schnoebelen 2014; burger et al. 2011; fink, kopecky, and morawski 2012;
sarawgi, gajulapalli, and choi 2011; yan and yan 2006). sarawgi, gajulapalli, and choi
(2011) found character-level language models to be more robust than token-level lan-
guage models. grouping words by meaningful classes could improve the interpretation
and possibly the performance of models. linguistic inquiry and word count (liwc,
pennebaker, francis, and booth (2001)) is a dictionary-based word counting program
originally developed for the english language. it also has versions for other languages,
such as dutch (zijlstra et al. 2005). liwc has been used in experiments on twitter
data (fink, kopecky, and morawski 2012) and blogs (nowson and oberlander 2006;
schler et al. 2006). however, models based on liwc alone tend to perform worse than
unigram/ngram models (fink, kopecky, and morawski 2012; nowson and oberlander
2006). by analyzing the developed features, studies have shown that males tend to
use more numbers (bamman, eisenstein, and schnoebelen 2014), technology words
(bamman, eisenstein, and schnoebelen 2014) and urls (schler et al. 2006; nguyen et al.
2013), while females use more terms referring to family and relationship issues (boulis
and ostendorf 2005). a discussion of the in   uence of genre and domain on gender
differences is provided later in this section.

various features based on grammatical structure have been explored, including
features capturing individual pos frequencies (argamon et al. 2003; otterbacher 2010)
as well as pos patterns (argamon et al. 2003, 2009; bamman, eisenstein, and schnoe-
belen 2014; schler et al. 2006). males tend to use more prepositions (argamon et al.
2007, 2009; otterbacher 2010; schler et al. 2006) and more articles (argamon et al. 2007;
nowson and oberlander 2006; otterbacher 2010; schler et al. 2006; schwartz et al. 2013),
however bamman, eisenstein, and schnoebelen (2014) did not    nd these differences
to be signi   cant in their twitter study. females tend to use more pronouns (argamon
et al. 2003, 2007, 2009; bamman, eisenstein, and schnoebelen 2014; otterbacher 2010;
schler et al. 2006; schwartz et al. 2013), in particular    rst person singular (nguyen et al.
2013; otterbacher 2010; schwartz et al. 2013). a measure introduced by heylighen and
dewaele (2002) to measure formality based on the frequencies of different word classes
has been used in experiments on blogs (mukherjee and liu 2010; nowson, oberlander,

18

nguyen et al.

computational sociolinguistics: a survey

and gill 2005). sarawgi, gajulapalli, and choi (2011) experimented with probabilistic
context-free grammars (pid18s) by adopting the approach proposed by raghavan,
kovashka, and mooney (2010) for authorship attribution. they trained pid18 parsers
for each gender and computed the likelihood of test documents for each gender-speci   c
pid18 parser to make the prediction. bergsma, post, and yarowsky (2012) experimented
with three types of syntax features and found features based on single-level context-
free-grammar (id18) rules (e.g., np    prp) to be the most effective. in some languages
such as french, the gender of nouns (including the speaker) is often marked in the
syntax. for example, a male would write    je suis all     , while a female would write    je suis
all  e    (   i went   ). by detecting such    je suis    constructions, ciot, sonderegger, and ruths
(2013) improved performance of gender classi   cation in french.

stylistic features have been widely explored as well. studies have reported that
males tend to use longer words, sentences and texts (goswami, sarkar, and rustagi
2009; otterbacher 2010; singh 2001), and more swear words (boulis and ostendorf
2005; schwartz et al. 2013). females use more emotion words (bamman, eisenstein,
and schnoebelen 2014; nowson and oberlander 2006; schwartz et al. 2013), emoticons
(bamman, eisenstein, and schnoebelen 2014; gianfortoni, adamson, and ros   2011;
rao et al. 2010; volkova, wilson, and yarowsky 2013), and typical social media words
such as omg and lol (bamman, eisenstein, and schnoebelen 2014; schler et al. 2006).

groups can be characterized by their attributes, for example females tend to have
maiden names. bergsma and van durme (2013) used such distinguishing attributes,
extracted from common nouns for males and females (e.g., granny, waitress), to improve
classi   cation performance. features based on    rst names have also been explored.
although not revealing much about language use itself, they can improve prediction
performance (bergsma and van durme 2013; burger et al. 2011; rao et al. 2011).

genre. so far, not many studies have analyzed the in   uence of genre and domain (lee
2001) on language use, but a better understanding will aid the interpretation of observed
language variation patterns. using data from the british national corpus, argamon et
al. (2003) found a strong correlation between characteristics of male and non-   ction
writing and likewise, between female and    ction writing. based on this observation,
they trained separate prediction models for    ction and non-   ction (koppel, argamon,
and shimoni 2002). building on these    ndings, herring and paolillo (2006) investigated
whether gender differences would still be observed when controlling for genre in blogs.
they did not    nd a signi   cant relation between gender and linguistic features that were
identi   ed to be associated with gender in previous literature, however the study was
based on a relatively small sample. similarly, gianfortoni, adamson, and ros   (2011)
revisited the task of gender prediction on the blog authorship corpus. after controlling
for occupation, features that previously were found to be predictive for gender on that
corpus were not effective anymore.

studies focusing on gender prediction have tested the generalizability of gender
prediction models by training and testing on different datasets. although models tend
to perform worse when tested on a different dataset than the one used for training,
studies have shown that prediction performance is still higher than random, suggesting
that there are indeed gender-speci   c patterns of language variation that go beyond
genre and domain (sap et al. 2014; sarawgi, gajulapalli, and choi 2011). gianfortoni,
adamson, and ros   (2011) proposed the use of    stretchy patterns   ,    exible sequences of
categories, to model stylistic variation and to improve generalizability across domains.

19

computational linguistics

to appear

social interaction. most computational studies on gender-speci   c patterns in language
use have studied speakers in isolation. as the conversational partner4 and social net-
work in   uence the language use of speakers, several studies have extended their focus
by also considering contextual factors. for example, this led to the    nding that speakers
use more gender-speci   c language in same-gender conversations (boulis and ostendorf
2005). on the fisher and switchboard corpus (telephone conversations), classi   ers
dependent on the gender of the conversation partner improve performance (garera
and yarowsky 2009). however, exploiting the social network of speakers on twitter
has been less effective so far. features derived from the friends of twitter users did
not improve gender classi   cation (but it was effective for age) (zamal, liu, and ruths
2012). likewise, bamman, eisenstein, and schnoebelen (2014) found that social network
information of twitter users did not improve gender classi   cation when enough text
was available.

not all computational studies on gender in interaction contexts have focused on
gender classi   cation itself. some have used gender as a variable when studying other
phenomena. in a study on language and power, prabhakaran, reid, and rambow (2014)
showed how the gender composition of a group in   uenced how power is manifested
in the enron corpus, a large collection of emails from enron employees (described
in more detail in section 4.1). in a study on language change in online communities,
hemphill and otterbacher (2012) found that females write more like men over time in
the imdb community (a movie review site), which they explain by men receiving more
prestige in the community. jurafsky, ranganath, and mcfarland (2009) automatically
classi   ed speakers according to interactional style (awkward, friendly, or    irtatious)
using various types of features, including lexical features based on liwc (pennebaker,
francis, and booth 2001), prosodic, and discourse features. differences, as well as
commonalities, were observed between genders, and incorporating features from both
speakers improved classi   cation performance.

3.2.3 interpretation of findings. as mentioned before, most computational approaches
adopt a simplistic view of gender as an inherent property based on biological char-
acteristics. only recently, the computational linguistics community has noticed the
limitations of this simplistic view by acknowledging the agency of speakers. two of
these studies based their argumentation on an analysis of the social networks of the
users. automatic gender predictions on youtube data correlated more strongly with
the dominant gender in a user   s network than the user-reported gender (filippova
2012). likewise, in experiments by bamman, eisenstein, and schnoebelen (2014), incor-
rectly labeled twitter users also had fewer same-gender connections. in addition, they
identi   ed clusters of users who used linguistic markers that con   icted with general
population-level    ndings. another study was based on data collected from an online
game (nguyen et al. 2014). thousands of players guessed the age and gender of twitter
users based on their tweets, and the results revealed that many twitter users do not
tweet in a gender-stereotypical way.

thus, language is inherently social and while certain language features are on
average used more by males or females, individual speakers may diverge from the
stereotypical images that tend to be highlighted by many studies. in addition, gender is
shaped differently depending on the culture and language, and thus presenting gender

4 an individual who participates in a conversation, sometimes also referred to as interlocutor or addressee

20

nguyen et al.

computational sociolinguistics: a survey

as a universal social variable can be misleading. furthermore, linguistic variation within
speakers of the same gender holds true as well.

3.3 age

aging is a universal phenomenon and understanding the relation between language
and age can provide interesting insights in many ways. an individual at a speci   c time
represents both a place in history as well as a life stage (eckert 1997), and thus observed
patterns can generate new insights into language change as well as how individuals
change their language use as they move through life. within computational linguistics,
fewer studies have focused on language variation according to age compared to studies
focusing on gender, possibly because obtaining age labels requires more effort than
gender labels (e.g., the gender of people can often be derived from their names; cf.
section 3.1). most of these studies have focused on absolute chronological age, although
age can also be seen as a social variable like gender.

sociolinguistic studies have found that adolescents use the most non-standard
forms, because at a young age the group pressure to not conform to established societal
conventions is the largest (eckert 1997; holmes 2013). in contrast, adults are found to
use the most standard language, because for them social advancement matters and they
use standard language to be taken seriously (bell 2013; eckert 1997). these insights can
explain why predicting the ages of older people is harder, e.g., distinguishing between
a 15- and a 20-year old person based on their language use is easier than distinguishing
between a 40- and a 45-year old person (nguyen et al. 2013, 2014). thus, age is an
important variable to consider, especially when we consider processes relevant for
language evolution, since the degree of language innovation varies by age (labov 2001).

3.3.1 modeling age. a fundamental question is how to model age, and so far researchers
have not reached a consensus yet. eckert (1997) distinguishes between chronological age
(number of years since birth), biological age (physical maturity) and social age (based
on life events). speakers are often grouped according to their age, because the amount
of data is in many cases not suf   cient to make more    ne-grained distinctions (eckert
1997). most studies consider chronological age and group speakers based on age spans
(barbieri 2008; labov 1966; trudgill 1974). however, chronological age can be mislead-
ing since persons with the same chronological age may have had very different life
experiences. another approach is to group speakers according to    shared experiences of
time   , such as high school students (eckert 1997).

within computational linguistics the most common approach is to model age-
speci   c language use based on the chronological age of speakers. an exception is
nguyen et al. (2013) who explored classi   cation into life stages. however, even when
focusing on chronological age, the task can be framed in different ways as well.
chronological age prediction has mostly been approached as a classi   cation problem, by
modeling the chronological age as a categorical variable. based on this task formulation,
various classical machine learning models have been used, such as id166s (peersman,
daelemans, and vaerenbergh 2011; rao et al. 2010), id28 (nguyen et al.
2013; rosenthal and mckeown 2011) and naive bayes (tam and martell 2009).

the boundaries used for discretizing age have varied depending on the dataset and
experimental setup. experiments on the blog authorship corpus (schler et al. 2006) used
categories based on the following age spans: 13-17, 23-27, and 33-47, removing the age
ranges in between to simplify the task. rangel et al. (2013) adopted this approach in the
author pro   ling task at pan 2013. the following year, the dif   culty of the task at pan

21

computational linguistics

to appear

2014 was increased by considering the more    ne-grained categories of 18-24, 25-34, 35-
49, 50-64 and 65+ (rangel et al. 2014). zamal, liu, and ruths (2012) classi   ed twitter
users into 18-23 and 25-30. other studies explored boundaries at 30 (rao et al. 2010), at
20 and 40 (nguyen et al. 2013), at 40 (garera and yarowsky 2009) and at 18 (burger and
henderson 2006).

in several studies experiments have been done by varying the classi   cation bound-
aries. peersman, daelemans, and vaerenbergh (2011) experimented with binary classi-
   cation and boundaries at 16, 18 and 25. tam and martell (2009) experimented with
classifying teens versus 20s, 30s, 40s, 50s and adults. not surprisingly, in both studies
a higher performance was obtained when using larger age gaps (e.g., teens versus
40s/50s) than when using smaller age gaps (e.g., teens versus 20s/30s) (peersman,
daelemans, and vaerenbergh 2011; tam and martell 2009). rosenthal and mckeown
(2011) explored a range of splits to study differences in performance when predicting
the birth year of blog authors. they related their    ndings to pre- and post social media
generations.

for many applications, modeling age as a categorical variable might be suf   cient.
however, it does have several limitations. first, selecting age boundaries has proven to
be dif   cult. it is not always clear which categories are meaningful. secondly, researchers
have used different categories depending on the age distribution of their dataset, which
makes it dif   cult to make comparisons across datasets.

motivated by such limitations, recent studies have modeled age as a continuous
variable, removing the need to de   ne age categories. framing age prediction as a
regression task, a frequently used method has been id75 (nguyen, smith,
and ros   2011; nguyen et al. 2013; sap et al. 2014; schwartz et al. 2013). liao et al. (2014)
experimented with a latent variable model that jointly models age and topics. in their
model, age-speci   c topics obtain low standard deviations of age, while more general
topics obtain high standard deviations. another approach that would remove the need
to de   ne age categories is the unsupervised induction of age categories. analyzing the
discovered age groups could shed more light on the relation between language use and
age, but we are not aware of existing research in this area.

3.3.2 features and patterns. the majority of studies on age prediction have focused on
identifying predictive features. while some features tend to be effective across domains,
others are domain-speci   c (nguyen, smith, and ros   2011). features that characterize
male speech have been found to also increase with age (argamon et al. 2007), thus
simply said, males tend to sound older than they are.

unigrams alone already perform well (nguyen, smith, and ros   2011; nguyen et al.
2013; peersman, daelemans, and vaerenbergh 2011). features based on part of speech
are effective as well. for example, younger people tend to use more    rst and second
person singular pronouns (e.g., i, you), while older people more often use    rst person
plural pronouns (e.g., we) (barbieri 2008; nguyen et al. 2013; rosenthal and mckeown
2011). older people also use more prepositions (argamon et al. 2009; nguyen et al.
2013), determiners (argamon et al. 2009; nguyen, smith, and ros   2011) and articles
(schwartz et al. 2013). most of these studies focused on english and therefore some of
these    ndings might not be applicable to other languages. for example, the effectiveness
of pronoun-related features should also be studied in pro-drop languages (e.g., turkish
and spanish).

various studies have found that younger people use less standard language. they
use more alphabetical lengthening (e.g., niiiice) (nguyen et al. 2013; rao et al. 2010),
more contractions without apostrophes (e.g., dont) (argamon et al. 2009), more internet

22

nguyen et al.

computational sociolinguistics: a survey

acronyms (e.g., lol) (rosenthal and mckeown 2011), more slang (barbieri 2008; rosen-
thal and mckeown 2011), more swear words (barbieri 2008; nguyen, smith, and ros  
2011), and more capitalized words (e.g., haha) (nguyen et al. 2013; rosenthal and
mckeown 2011). speci   c words such as like are also highly associated with younger ages
(barbieri 2008; nguyen, smith, and ros   2011). younger people also use more features
that indicate stance and emotional involvement (barbieri 2008), such as intensi   ers
(barbieri 2008; nguyen et al. 2013) and emoticons (rosenthal and mckeown 2011).
younger people also use shorter words and sentences and write shorter tweets (burger
and henderson 2006; nguyen et al. 2013; rosenthal and mckeown 2011).

3.3.3 interpretation of findings. age prediction experiments are usually done on
datasets collected at a speci   c point in time. based on such datasets, language use is
modeled and compared between users with different ages. features that are found to
be predictive or that correlate highly with age are used to highlight how differently
   younger    and    older    people talk or write. however, the observed differences in lan-
guage use based on such datasets could be explained in multiple ways. linguistic
variation can occur as an individual moves through life (age grading). in that case the
same trend is observed for individuals at different time periods. linguistic variation can
also be a result of changes in the community itself as it moves through time (generational
change) (bell 2013; sankoff 2006). for example, suppose we observe that younger twitter
users include more smileys in their tweets. this could indicate that smiley usage is
higher at younger ages, but that when twitter users grow older they decrease their
usage of smileys. however, this could also indicate a difference in smiley usage between
generations (i.e., the generation of the current younger twitter users use more smileys
compared to the generation of the older twitter users). this also points to the relation
between synchronic variation and diachronic change. synchronic variation is variation
across different speakers or speech communities at a particular point in time, while
diachronic change is accumulation of synchronic variation in time and frequency. to
have a better understanding of change, we need to understand the spread of variation
across time and frequency. as is the case for gender, age can be considered a social
variable and thus when only modeling chronological age, we are ignoring the agency
of speakers and that speakers follow different trajectories in their lives.

3.4 location

regional variation has been extensively studied in sociolinguistics and related areas
such as dialectology (chambers and trudgill 1998) and dialectometry (wieling and ner-
bonne 2015). the use of certain words, grammatical constructions, or the pronunciation
of a word, can often reveal where a speaker is from. for example,    yinz    (a form of the
second-person pronoun) is mostly used around pittsburgh, which can be observed on
twitter as well (eisenstein 2015). dialectology traditionally focuses on the geographical
distribution of individual or small sets of linguistic variables (chambers and trudgill
1998). a typical approach involves identifying and plotting isoglosses, lines that divide
maps into regions where speci   c values of the variable predominate. the next step
involves identifying bundles of isoglosses, often followed by the identi   cation of dialect
regions. while these steps have usually been done manually, computational approaches
have recently been explored as well. for example, grieve, speelman, and geeraerts
(2011) demonstrated how methods from spatial analysis can be used for automating
such an analysis.

23

computational linguistics

to appear

the study of regional variation has been heavily in   uenced by new statistical
approaches, such as from computational linguistics, machine learning and spatial anal-
ysis. a separate branch has also emerged, referred to as dialectometry (wieling and
nerbonne 2015). in contrast to dialectology, which focuses on individual linguistic
variables, dialectometry involves aggregating linguistic variables to examine linguistic
differences between regions. nerbonne (2009) argues that studies that focus on individ-
ual variables are sensitive to noise and that therefore aggregating linguistic variables
will result in more reliable signals. this aggregation step has led to the introduction of
various statistical methods, including id91, id84 techniques
and regression approaches (heeringa and nerbonne 2013; nerbonne and wieling 2015;
wieling and nerbonne 2010). recently, researchers within dialectometry have explored
the automatic identi   cation of characteristic features of dialect regions (wieling and
nerbonne 2010), a task which aligns more closely with the approaches taken by dialec-
tologists.

while the datasets typically used in dialectology and dialectometry studies are
still small compared to datasets used in computational linguistics, similar statistical
methods have been explored. this has created a promising starting point for closer
collaboration with computational linguistics.

3.4.1 modeling geographical variation. within cl, we    nd two lines of work on
computationally modeling geographical variation.

supervised. the    rst approach starts with documents labeled according to their dialect,
which can be seen as a supervised learning approach. most studies taking this approach
focus on automatic dialect identi   cation, which is a variation of automatic language
identi   cation, a well-studied research topic within the    eld of computational linguistics
(baldwin and lui 2010; hughes et al. 2006). while some have considered automatic lan-
guage identi   cation a solved problem (mcnamee 2005), still many outstanding issues
exist (hughes et al. 2006), including the identi   cation of dialects and closely related
languages (zampieri et al. 2014, 2015). in studies on automatic dialect identi   cation,
various dialects have been explored, including arabic (darwish, sajjad, and mubarak
2014; elfardy and diab 2013; huang 2015; zaidan and callison-burch 2013), turkish
(do   gru  z and nakov 2014), swiss german (scherrer and rambow 2010) and dutch
(trieschnigg et al. 2012) dialects.

unsupervised. an alternative approach is to start with location-tagged data to automati-
cally identify dialect regions. while the models are given labels indicating the locations
of speakers, the dialect labels themselves are not observed. in the context of modeling
dialects, we consider it an unsupervised approach (although it can be considered a
supervised approach when the task is framed as a location prediction task). the majority
of the work in this area has used twitter data, because it contains    ne-grained location
information in the form of gps data for tweets or user-provided locations in user
pro   les.

much of the research that starts with location-tagged data is done with the aim
of automatically predicting the location of speakers. the setup is thus similar to the
setup for the other tasks that we have surveyed in this section (e.g., gender and age
prediction). eisenstein et al. (2010) developed a topic model to identify geographically
coherent linguistic regions and words that are highly associated with these regions. the
model was tested by predicting the locations of twitter users based on their tweets.
while the topic of text-based location prediction has received increasing attention (han,

24

nguyen et al.

computational sociolinguistics: a survey

cook, and baldwin 2012; wing and baldridge 2011), using these models for the discov-
ery of new sociolinguistic patterns is an option that has not been fully explored yet,
since most studies primarily focus on prediction performance.

various approaches have been explored to model the location of speakers, an aspect
that is essential in many of the studies that start with location-tagged data. in wing and
baldridge (2011), locations are modeled using geodesic grids, but these grids do not
always correspond to administrative or language boundaries. users can also be grouped
based on cities (han, cook, and baldwin 2012), but such an approach is not suitable for
users in rural areas or when the focus is on more    ne-grained geographical variation
(e.g., within a city). eisenstein et al. (2010) model regions using gaussian distributions,
but only focus on the united states and thus more research is needed to investigate the
suitability of this approach when considering other countries or larger regions.

3.4.2 features and patterns. word and character id165 models have been frequently
used in dialect identi   cation (king, radev, and abney 2014; trieschnigg et al. 2012;
zaidan and callison-burch 2013). similarly, many text-based location prediction sys-
tems make use of unigram word features (eisenstein et al. 2010; han, cook, and baldwin
2012; wing and baldridge 2011).

features inspired by sociolinguistics could potentially improve performance. dar-
wish, sajjad, and mubarak (2014) showed that for identifying arabic dialects a better
classi   cation performance could be obtained by incorporating known lexical, mor-
phological and phonological differences in their model. scherrer and rambow (2010)
also found that using linguistic knowledge improves over an id165 approach. their
method is based on a linguistic atlas for the extraction of lexical, morphological and
phonetic rules and the likelihood of these forms across german-speaking switzerland.
do   gru  z and nakov (2014) explored the use of light verb constructions to distinguish
between two turkish dialects.

to support the discovery of new sociolinguistic patterns and to improve prediction
performance, several studies have focused on automatically identifying characteristic
features of dialects. han, cook, and baldwin (2012) explored various feature selection
methods to improve location prediction. the selected features may re   ect dialectal
variation but this was not the focus of the study. the method by proki  c,     ltekin,
and nerbonne (2012) was based on in-group and out-group comparisons using data
in which linguistic varieties were already grouped (e.g., based on id91). peirs-
man, geeraerts, and speelman (2010) compared frequency-based measures, such as
chi-square and log-likelihood tests, with distributional methods. automatic methods
may identify many features that vary geographically such as topic words and named
entities, and an open challenge is to separate this type of variation from the more
sociolinguistically interesting variations. for example, the observation that the word
   beach    is used more often near coastal areas or that    times square    is used more often in
new york is not interesting from the perspective of a sociolinguist.

making use of location-tagged data, several studies have focused on analyzing
patterns of regional variation. doyle (2014) analyzed the geographical distribution of
dialectal variants (e.g., the use of double modals like    might could   ) based on twitter data,
and compared it with traditional sociolinguistic data collection methods. starting with
a query-based approach, he uses baseline queries (e.g.,    i   ) for estimating a conditional
distribution of data given metadata. his approach achieved high correlations with data
from sociolinguistic studies. j  rgensen, hovy, and s  gaard (2015) studied the use of
three phonological features of african american vernacular english using manually
selected word pairs. the occurrence of the features was correlated with location data

25

computational linguistics

to appear

(longitude and latitude) as well as demographic information obtained from the us
census bureau. while these approaches start with attested dialect variants, automatic
discovery of unknown variation patterns could potentially lead to even more inter-
esting results. to study how a word   s meaning varies geographically, bamman, dyer,
and smith (2014) extended the skip gram model by mikolov et al. (2013) by adding
contextual variables that represent states from the us. the model then learns a global
embedding matrix and additional matrices for each context (e.g., state) to capture the
variation of a word   s meaning.

the increasing availability of longitudinal data has made it possible to study the
spreading of linguistic innovations geographically and over time on a large scale. a
study by eisenstein et al. (2014) based on tweets in the united states indicates that
linguistic innovations spread through demographically similar areas, in particular with
regard to race.

3.4.3 interpretation of findings. labeling texts by dialect presumes that there are clear
boundaries between dialects. however, it is not easy to make absolute distinctions
between language varieties (e.g., languages, dialects). chambers and trudgill (1998)
illustrate this with the example of traveling from village to village in a rural area.
speakers from villages at larger distances have more dif   culty understanding each
other compared to villages that are closer to each other, but there is no clear-cut distance
at which speakers are no longer mutually intelligible. a computational approach was
taken by heeringa and nerbonne (2001) to shed more light on this puzzling example.
besides linguistic differences, boundaries between language varieties are often in   u-
enced by other factors such as political boundaries (chambers and trudgill 1998).
therefore, deciding on the appropriate labels to describe linguistic communication
across different groups of speakers (in terms of language, dialect, minority language,
regional variety, etc.) is an on-going issue of debate. the arbitrariness of the distinction
between a language and dialect is captured with the popular expression "a language is
a dialect with an army and navy" (bright 1997). methods that do not presume clear dialect
boundaries are therefore a promising alternative. however, such methods then rely on
location-tagged data, which is usually only available for a portion of the data.

3.5 text classi   cation informed by identity information

so far, we have focused on automatically predicting the variables themselves (e.g.,
gender, age, location) but linguistic variation related to the identity of speakers can
also be used to improve various other nlp tasks. dadvar et al. (2012) trained gender-
speci   c classi   ers to detect instances of cyberbullying, noticing that language used by
harassers varies by gender. to improve the prediction performance of detecting the
power direction between participants in emails, prabhakaran, reid, and rambow (2014)
incorporated the gender of participants in e-mail conversations and the overall    gender
environment    as features in their model. volkova, wilson, and yarowsky (2013) studied
gender differences in the use of subjective language on twitter. representing gender as
a binary feature was not effective, but the use of features based on gender-dependent
sentiment terms improved subjectivity and polarity classi   cation. hovy (2015) found
that training gender- or age-speci   c id27s improved tasks such as senti-
ment analysis and topic classi   cation.

26

nguyen et al.

computational sociolinguistics: a survey

4. language and social interaction

the previous section explored computational approaches to the study of identity con-
struction through language. we discussed variables such as gender, age and geograph-
ical location, thereby mostly focusing on the in   uence of social structures on language
use. however, as we also pointed out in the previous section, speaker agency enables
violations of conventional language patterns. speakers do not act in isolation, but they
are part of pairs, groups and communities. social interaction contexts produce the
opportunity for variation due to agency. in response to the particulars of these social
settings and encounters (e.g., the addressee or audience, topic, and social goals of the
speakers), there is thus much variation within individual speakers. the variation that is
related to the context of interaction will be the focus of this section.

we start this section with a discussion of data sources for large-scale analyses of
language use in pairs, groups and communities (section 4.1). next, we discuss com-
putational approaches to studying how language re   ects and shapes footing within
social relationships (section 4.2). much of this work has revolved around the role of
language in power dynamics by studying how speakers use language to maintain
and change power relations (fairclough 1989). we will continue with a discussion on
style-shifting (i.e., the use of different styles by a single speaker) in section 4.3. we
will discuss two prominent frameworks within sociolinguistics, audience design (bell
1984) and communication accommodation theory (giles, coupland, and coupland
1991), and discuss how these frameworks have been studied within the computational
linguistics community. finally, we will move our focus to the community level and
discuss computational studies on how members adapt their language to conform to
or sometimes diverge from community norms. one might speculate about how these
micro-level processes might eventually become conventional, and therefore consider
how these processes may lead to language change over time (section 4.4).

4.1 data sources

many of the types of data that are relevant for the investigation of concepts of social
identity, are also relevant for work on communication dynamics in pairs, groups and
communities. the availability of detailed interaction recordings in online data has
driven and enabled much of the work on this topic within computational linguistics.
a variety of online discussion forums have been analyzed, including online cancer
support communities (nguyen and ros   2011; wang, reitter, and yen 2014), a street
gang forum (piergallini et al. 2014), and more recently discussion forums in massive
open online courses (moocs) (wen, yang, and ros   2014b, 2014a). review sites, such
as tripadvisor (michael and otterbacher 2014), imdb (hemphill and otterbacher 2012)
and beer review communities (danescu-niculescu-mizil et al. 2013b), have also been
used in studies on language in online communities.

the enron email corpus is another frequently used data source. the enron corpus
is a large email corpus with messages from enron employees, which was made public
during the legal investigation of the enron corporation. the corpus has been used in
various studies, for example, investigations related to email classi   cation (klimt and
yang 2004) and structure of communication networks (diesner and carley 2005). in
particular, in studies on language and social dynamics, the enron email corpus has
featured in analyses of power relationships (diehl, namata, and getoor 2007; gilbert
2012; prabhakaran, rambow, and diab 2012b; prabhakaran, reid, and rambow 2014),
since enron   s organizational structure is known and can be integrated in studies on

27

computational linguistics

to appear

hierarchical power structures connected with quantitative capacity theories of power.
such theories treat power as a stable characteristic that inheres in a person. an example
theory within this space is resource dependency theory (pfeffer and salancik 1978).

for studies that involve more dynamic notions of power (e.g., identifying indi-
viduals who are pursuing power), other resources have also been explored, includ-
ing wikipedia talk pages (bender et al. 2011; bracewell, tomlinson, and wang 2012;
danescu-niculescu-mizil et al. 2012; swayamdipta and rambow 2012), transcripts of
political debates (prabhakaran, john, and seligmann 2013; prabhakaran, arora, and
rambow 2014) and transcripts of supreme court arguments (danescu-niculescu-mizil
et al. 2012).

4.2 shaping social relationships

language is not only a means to exchange information but language also contributes
to the performance of action within interaction. language serves simultaneously as a
re   ection of the relative positioning of speakers to their conversation partners as well
as actions that accompany those positions (ribeiro 2006). sometimes distributions of
these actions can be considered to cohere to such a degree that they can be thought of
as de   ning conversational roles (yang, wen, and ros   2015). at a conceptual level, this
work draws heavily from a foundation in linguistic pragmatics (grice 1975; levinson
1983) as well as sociological theories of discourse (gee 2011; tannen 1993), which
each provide a complementary view. concepts related to expectations or norms that
provide the foundation for claiming such positions may similarly be described either
from a philosophical perspective or a sociological one (postmes, spears, and lea 2000).
in viewing interaction as providing a context in which information and action may
   ow towards the accomplishment of social goals, speakers position themselves and
others as sources or recipients of such information and action (martin and rose 2003).
when performatives, i.e., speech acts used to perform an action, break norms related
to social positions, they have implications for relational constructs such as politeness
(brown and levinson 1987), which codi   es rhetorical strategies for acknowledging and
managing relational expectations while seeking to accomplish extra-relational goals. in
the remaining part of this section, we focus on computational studies within this theme.
we    rst discuss the general topic of automatic extraction of social relationships from
text, and then focus on power and politeness.

automatic extraction of social relationships. recognizing that language use may reveal
cues about social relationships, studies within cl have explored the automatic extrac-
tion of different types of social relationships based on text. one distinction that has
been made is between weak ties (e.g., acquaintances) and strong ties (e.g., family and
close friends) (granovetter 1973). gilbert and karahalios (2009) explored how different
types of information (including messages posted) can be used to predict tie strength on
facebook. in this study, the predictions were done for ties within a selected sample. bak,
kim, and oh (2012) studied differences in self-disclosure on twitter between strong and
weak ties using automatically identi   ed topics. twitter users disclose more personal
information to strong ties, but they show more positive sentiment towards weak ties,
which may be explained by social norms regarding    rst-time acquaintances on twitter.
other studies have automatically extracted social relationships from more extensive
datasets, enabling analyses of the extracted network structures. these studies have
focused on extracting signed social networks, i.e., networks with positive and negative
edges, for example based on positive and negative af   nity between individuals or

28

nguyen et al.

computational sociolinguistics: a survey

formal and informal relationships. work within this area has drawn from structural
balance theory (heider 1946), which captures intuitions such as that when two indi-
viduals have a mutual friend, they are likely to be friends as well, and from status
theory (leskovec, huttenlocher, and kleinberg 2010), which involves edges that are
directed and re   ect status differences. hassan, abu-jbara, and radev (2012) developed
a machine learning classi   er to extract signed social networks and found that the
extracted network structure mostly agreed with structural balance theory. krishnan
and eisenstein (2015) proposed an unsupervised model for extracting signed social
networks, which they used to extract formal and informal relations in a movie-script
corpus. furthermore, their model also induced the social function of address terms
(e.g., dude). to infer edge signs in a social network, west et al. (2014) formulated an
optimization problem that combined two objectives, capturing the extent to which
the inferred signs agreed with the predictions of a id31 model, and the
extent to which the resulting triangles corresponded with status and structural balance
theory.

power. work on power relations draws from social psychological concepts of relative
power in social situations (guinote and vescio 2010), in particular aspects of relative
power that operate at the level of individuals in relation to speci   c others within groups
or communities. relative power may be thought of as operating in terms of horizon-
tal positioning or vertical positioning: horizontal positioning relates to closeness and
related constructs such as positive regard, trust and commitment, while vertical posi-
tioning relates to authority and related constructs such as approval and respect among
individuals within communities. within the areas of linguistics and computational
linguistics, investigations have focused on how speakers use language to maintain
and change power relations (fairclough 1989). operationalization and computational
modeling of these two dimensions has important applications in the    eld of learning
sciences (howley, may   eld, and ros   2013).

within computational linguistics, much of the work related to analysis of power
as it is re   ected through language has focused on automatically identifying power
relationships from text. though some of the literature cited above is referenced in this
work, the engagement between communities has remained so far at a simple level.
fine-grained distinctions between families of theories of power, and subtleties about
the relationship between power and language are frequently glossed over. one way in
which this is visible is in the extent to which the locus of meaning is treated as though it
is in the text itself rather than an emergent property of the interaction between speakers.
though some references to external power structures and transient power relationships
are mentioned, much room remains for deeper re   ection on the connection between
power and language.

research in the computational linguistics community related to these issues is
normally centered around classi   cation tasks. earlier studies have focused on hierar-
chical power relations based on the organizational structure, thereby frequently making
use of the enron corpus. bramsen et al. (2011) extracted messages between pairs of
participants and developed a machine learning classi   er to automatically determine
whether the messages of an author were upspeak (directed towards a person of higher
status) or downspeak (directed towards a person of lower status). with a slightly
different formulation of the task, gilbert (2012) used id28 to classify power
relationships in the enron corpus and identi   ed the most predictive phrases. besides
formulating the task as a classi   cation task, ranking approaches have been explored
as well (diehl, namata, and getoor 2007; nguyen et al. 2014; prabhakaran, john, and

29

computational linguistics

to appear

seligmann 2013). for example, prabhakaran, john, and seligmann (2013) predicted the
ranking of participants in political debates according to their relative poll standings.

studies based on external power structures, such as the organizational structure of
a company, treat power relations as static. recent studies have adopted more dynamic
notions of power. for example, prabhakaran, rambow, and diab (2012b) discuss a
setting with an employee in a human resources department who interacts with an
of   ce manager. the hr employee has power over the of   ce manager when the situation
is about enforcing a hr policy, but the power relation will be reversed when the topic
is allocation of new of   ce space. in their study using the enron corpus, they compared
manual annotations of situational power with the organization hierarchy and found
that these were not well aligned. other studies have focused on a more dynamic view of
power as arising through asymmetries with respect to needed resources or other goals,
as characterized in consent-based theories of power such as exchange theory (guinote
and vescio 2010). this would include such investigations as identifying persons who are
pursuing power (bracewell, tomlinson, and wang 2012; swayamdipta and rambow
2012) and detecting in   uencers (biran et al. 2012; huffaker 2010; nguyen et al. 2014;
quercia et al. 2011). this could also include studying how language use changes when
users change their status in online communities (danescu-niculescu-mizil et al. 2012).
depending on the conceptualization of power and the used dataset, labels for the
relations or roles of individuals have been collected in different ways, such as based on
the organizational structure of enron (bramsen et al. 2011; gilbert 2012), the number
of followers in twitter (danescu-niculescu-mizil, gamon, and dumais 2011), standings
in state and national polls to study power in political debates (prabhakaran, john, and
seligmann 2013), admins and non-admins in wikipedia (bender et al. 2011; danescu-
niculescu-mizil et al. 2012), and manual annotation (biran et al. 2012; nguyen et al.
2014; prabhakaran and rambow 2013).

many computational approaches within this sphere build on a foundation from
pragmatics related to speech act theory (austin 1975; searle 1969), which has most
commonly been represented in what are typically referred to as conversation, dialog
or social acts (bender et al. 2011; ferschke, gurevych, and chebotar 2012). such cat-
egories can also be combined into sequences (bracewell, tomlinson, and wang 2012).
other specialized representations are also used, such as features related to turn taking
style (prabhakaran, john, and seligmann 2013; swayamdipta and rambow 2012), topic
control (nguyen et al. 2014; prabhakaran, arora, and rambow 2014; strzalkowski et al.
2012), and    overt displays of power   , which prabhakaran, rambow, and diab (2012a)
de   ne as utterances that constrain the addressee   s actions beyond what the underlying
dialog act imposes.

politeness. polite behavior contributes to maintaining social harmony and avoiding
social con   ict (holmes 2013). automatic classi   ers to detect politeness have been de-
veloped to study politeness strategies on a large scale. according to politeness theory
by brown and levinson (1987), three social factors in   uence linguistically polite be-
havior: social distance, relative power, and ranking of the imposition (i.e., cost of the
request). drawing from this theory, peterson, hohensee, and xia (2011) performed a
study on the enron corpus by training classi   ers to automatically detect formality and
requests. emails that contained requests or that were sent to people of higher ranks
indeed tended to be more formal. according to politeness theory, speakers with greater
power than their addressees are expected to be less polite (brown and levinson 1987).
danescu-niculescu-mizil et al. (2013a) developed a politeness classi   er and found
that in wikipedia polite editors were more likely to achieve higher status, but once

30

nguyen et al.

computational sociolinguistics: a survey

promoted, they indeed became less polite. in stackexchange, a site with an explicit
reputation system, users with a higher reputation were less polite than users with a
lower reputation. their study also revealed new interactions between politeness mark-
ings (e.g.,    please   ) and morphosyntactic context.

4.3 style shifting

according to labov (1972), there are no single-style speakers since speakers may switch
between styles (style-shifting) depending on their communication partners (e.g., ad-
dressee   s age, gender and social background). besides the addressee, other factors such
as the topic (e.g., politics vs. religion) or the context (e.g., a courtroom vs. family dinner)
can contribute to style shifting. in early studies, labov stated that "styles can be arranged
along a single dimension, measured by the amount of attention paid to speech" (labov 1972),
which thus views style shifting as mainly something responsive. the work by labov
on style has been highly in   uential, but not everyone agreed with his explanation for
different speech styles. we will discuss two theories (communication accommodation
theory and audience design) that have received much attention in both sociolinguistics
and computational linguistics and that focus on the role of audiences and addressees
on style. even more recent theories are emphasizing the agency of speakers as they
employ different styles to represent themselves in a certain way or initiate a change in
the situation. besides switching between styles, multilingual speakers may also switch
between languages or dialects. this is discussed in more depth in section 5.

communication accommodation theory. communication accommodation theory (cat)
(giles, taylor, and bourhis 1973; giles, coupland, and coupland 1991; soliz and giles
2014) seeks to explain why speakers accommodate5 to each other during conversa-
tions. speakers can shift their behavior to become more similar (convergence) or more
different (divergence) to their conversation partners. convergence reduces the social
distance between speakers and converging speakers are often viewed as more favorable
and cooperative. cat has been developed in the 1970s and has its roots in the    eld
of social psychology. while cat has been studied extensively in controlled settings,
e.g., gonzales, hancock, and pennebaker (2010), only recently studies have been per-
formed in uncontrolled settings such as twitter conversations (danescu-niculescu-
mizil, gamon, and dumais 2011), online forums (jones et al. 2014), wikipedia talk pages
and supreme court arguments (danescu-niculescu-mizil et al. 2012), and even movie
scripts (danescu-niculescu-mizil and lee 2011).

speakers accommodate to each other on a variety of dimensions, ranging from pitch
and gestures, to the words that are used. within computational linguistics, researchers
have focused on measuring linguistic accommodation. liwc has frequently been em-
ployed in these studies to capture stylistic accommodation, for example as re   ected
in the use of pronouns (danescu-niculescu-mizil and lee 2011; danescu-niculescu-
mizil, gamon, and dumais 2011; jones et al. 2014; niederhoffer and pennebaker 2002).
speakers do not necessarily converge on all dimensions (giles, coupland, and cou-
pland 1991), which has also been observed on twitter (danescu-niculescu-mizil, ga-
mon, and dumais 2011). although earlier studies used correlations of speci   c features
between participants, on turn-level or overall conversation-level (levitan, gravano, and

5 the phenomenon of adapting to the conversation partner has also been known as    alignment   ,

   coordination    and    entrainment   .

31

computational linguistics

to appear

hirschberg 2011; niederhoffer and pennebaker 2002; scissors et al. 2009), these correla-
tions fail to capture the temporal aspect of accommodation. the measure developed
by danescu-niculescu-mizil, gamon, and dumais (2011) is based on the increase in
id203 of a response containing a certain stylistic dimension given that the original
message contains that speci   c stylistic dimension. wang, reitter, and yen (2014) used
a measure based on repetition of words (or syntactic structures) between target and
prime posts. jones et al. (2014) proposed a measure that takes into account that speakers
differ in their tendency to accommodate to others. similarly, jain et al. (2012) used a
dynamic bayesian model to induce latent style states that group related style choices
together in a way that re   ects relevant styles within a corpus. they also introduce
global accommodation states that provide more context in identi   cation of style shifts
in interactions that extend for more than a couple of turns.

social roles and orientations taken up by speakers in   uence how conversations play
out over time and computational approaches to measure accommodation have been
used to study power dynamics (danescu-niculescu-mizil, gamon, and dumais 2011;
danescu-niculescu-mizil et al. 2012; jones et al. 2014). in a study on power dynamics
in wikipedia talk pages and supreme court debates, danescu-niculescu-mizil et al.
(2012) found that people with a lower status accommodated more than people with
a higher status. in addition, users accommodated less once they became an admin in
wikipedia. using the same wikipedia data, noble and fern  ndez (2015) found that
users accommodated more towards users that occupied a more central position, based
on eigenvector and betweenness centrality, in the social network. furthermore, whether
a user was an admin did not had a signi   cant effect on the amount of coordination
that highly central users received. from a different angle, gweon et al. (2013) studied
transactive exchange in debate contexts. transactivity is a property of an assertion that
requires that it displays reasoning (e.g., a causal mechanism) and refers to or integrates
an idea expressed earlier in the discussion. in this context, high concentrations of
transactivity re   ect a balance of power in a discussion. in their data, higher levels of
speech style accommodation were correlated with higher levels of transactivity.

audience design. in a classical study set in new zealand, allan bell found that news-
readers used different styles depending on which radio station they were talking for,
even when they were reporting the same news on the same day. bell   s audience design
framework (bell 1984) explains style shifting as a response to audiences and shares
similarities with cat. one of the differences with cat is that different types of au-
diences are de   ned from the perspective of the speaker (ranging from addressee to
eavesdropper) and thus can also be applied to settings in which there is only a one-
way interaction (such as broadcasting). social media provides an interesting setting to
study how audiences in   uence style. in many social media platforms, such as twitter
or facebook, multiple audiences (e.g., friends, colleagues) are collapsed into a single
context. users of such platforms often imagine an audience when writing messages and
they may target messages to different audiences (marwick and boyd 2011).

twitter has been the focus of several recent large-scale studies on audience design.
in a study on how audiences in   uence the use of minority languages on twitter,
nguyen, trieschnigg, and cornips (2015) showed how characteristics of the audience
in   uence language choice on twitter by analyzing tweets from multilingual users in
the netherlands using automatic language identi   cation. tweets directed to larger
audiences were more often written in dutch, while within conversations users often
switched to the minority language. in another study on audience on twitter, bam-
man and smith (2015) showed that incorporating features of the audience improved

32

nguyen et al.

computational sociolinguistics: a survey

sarcasm detection. furthermore, their results suggested that users tend to use the
hashtag #sarcasm when they are less familiar with their audience. pavalanathan and
eisenstein (2015a) studied two types of non-standard lexical variables: those strongly
associated with speci   c geographical regions of the united states and variables that
were frequently used in twitter but considered non-standard in other media. the use
of non-standard lexical variables was higher in messages with user mentions, which are
usually intended for smaller audiences, and lower in messages with hashtags, which are
usually intended for larger audiences. furthermore, non-standard lexical variables were
more often used in tweets addressed to individuals from the same metropolitan area.
using a different data source, michael and otterbacher (2014) showed that reviewers on
the tripadvisor site adjust their style to the style of preceding reviews. moreover, the
extent to which reviewers are in   uenced correlates with attributes such as experience
of the reviewer and their sentiment towards the reviewed attraction.

4.4 community dynamics

as we just discussed, people adapt their language use towards their conversation part-
ner. within communities, norms emerge over time through interaction between mem-
bers, such as the use of slang words and domain-speci   c jargon (danescu-niculescu-
mizil et al. 2013b; nguyen and ros   2011), or conventions for indicating retweets in
twitter (kooti et al. 2012). community members employ such markers to signal their
af   liation. in an online gangs forum, for example, graf   ti style features were used to
signal group af   liation (piergallini et al. 2014). to become a core member of a commu-
nity, members adopt such community norms. as a result, often a change in behavior
can be observed when someone joins a community. multiple studies have reported that
members of online communities decrease their use of    rst person singular pronouns
(e.g.,    i   ) over time and increase their use of    rst person plural pronouns (e.g.,    we   ) (cas-
sell and tversky 2005; danescu-niculescu-mizil et al. 2013b; nguyen and ros   2011),
suggesting a stronger focus on the community. depending on the frequency of use and
social factors, local accommodation effects could in   uence how languages change in
the long term (labov 1994, 2001). fine-grained, large-scale analyses of language change
are dif   cult in of   ine settings, but the emergence of online communities has enabled
computational approaches for analyzing language change within communities.

early investigations of this topic were based on data from non-public communities,
such as email exchanges between students during a course (postmes, spears, and lea
2000) and data from the junior summit    98, an online community where children from
across the world discussed global issues (cassell and tversky 2005; huffaker et al. 2006).
in these communities, members joined at the same time. furthermore, the studies were
based on data spanning only several months.

more recent studies have used data from public, online communities, such as
online forums and review sites. data from these communities typically span longer
time periods (e.g., multiple years). members join these communities intermittently and
thus, when new users join, community norms have already been established. nguyen
and ros   (2011) analyzed an online breast cancer community, in which long-time
members used forum-speci   c jargon, highly informal style, and showed familiarity
and emotional involvement with other members. time periods were represented by
the distribution of high frequency words and measures such as kullback-leibler diver-
gence were used to study how language changed over time. members who joined the
community showed increasing conformity to community norms during the    rst year of
their participation. based on these observations, a model was developed to determine

33

computational linguistics

to appear

membership duration. hemphill and otterbacher (2012) also studied how members
adopt community norms over time but focused speci   cally on gender differences. they
studied changes in the use of various characteristics, such as hedging, word/sentence
complexity and vocabulary richness, in imdb (the internet movie database), a commu-
nity in which males tend to receive higher prestige than females.

not only members change their behavior over time as they participate in a com-
munity, communities themselves are also constantly evolving. kershaw, rowe, and
stacey (2016) identi   ed and analyzed word innovations in twitter and reddit based
on variation in frequency, form and meaning. they performed their analyses on a
global level, i.e., the whole dataset, and on a community level, based on applying a
community detection algorithm to the reddit data and grouping the geotagged tweets
by geopolitical units.

language change on both member-level and community-level was analyzed by
danescu-niculescu-mizil et al. (2013b) in two beer review communities. language
models were created based on monthly snapshots to capture the linguistic state of a
community over time. cross-id178 was then used to measure how much a certain
post deviated from a language model. members in these communities turned out
to follow a two-stage lifecycle: they    rst align with the language of the community
(innovative learning phase), however at some point they stop adapting their language
(conservative phase). the point at which members enter the conservative phase turned
out to be dependent on how long a user would end up staying in the community.

these studies illustrate the potential of using large amounts of online data to study
language change in communities in a quantitative manner. however, in such analyses
biases in the data should be considered carefully, especially when the dynamics and
content of the data are not understood fully. for example, pechenick, danforth, and
dodds (2015) call into question the    ndings on linguistic change based on the google
books corpus, due to its bias towards scienti   c publications. furthermore, they point
out that proli   c authors in the dataset can in   uence the    ndings as well.

5. multilingualism and social interaction

languages evolve due to the interaction of speakers within and outside their speech
communities. within sociolinguistics, multilingual speakers and speech communities
have been studied widely with respect to the contexts and conditions of language
mixing and/or switching across languages. we use the term    multilingual speaker   
for someone who has a repertoire of various languages and/or dialects and who may
mix them depending on contextual factors like occasion (e.g., home vs. work) and
conversation partners (e.g., family vs. formal encounters). this section is dedicated to
computational approaches for analyzing multilingual communication in relation to the
social and linguistic contexts. we    rst start with a brief introduction into multilingual
communication from a sociolinguistic point of view. later, we expand the discussion to
include the analysis of multilingual communication using computational approaches.

human mobility is one of the main reasons for interaction among speakers of
different languages. weinreich (1953) was one of the    rst to explain why and how
languages come into contact and evolve under each other   s in   uence in a system-
atic manner. sociolinguists (auer 1988; gumperz 1982; myers-scotton 2002; poplack,
sankoff, and miller 1988) have studied various aspects of language contact and mixing
across different contact settings.

language mixing and code-switching are used interchangeably and there is not
always a consensus on the terminology. according to gumperz (1982), language mixing

34

nguyen et al.

computational sociolinguistics: a survey

refers to the mixing of languages within the same text or conversation. wei (1998)
describes language alternations at or above the clause level and calls it code-mixing.
romaine (1995) differentiates between inter-sentential (i.e., across sentences) and intra-
sentential (i.e., within the same sentence) switches. poplack, sankoff, and miller (1988)
refer to complete languages shifts of individual users as code-switching.

language mixing spans across a continuum ranging from occasional switches (e.g.,
words or    xed multi-word expressions) to more structural ones (e.g., morphological,
syntactic borrowings). the duration and intensity of interaction between speakers of
contact languages in   uence the types of switches. when the frequency of switched
words increases in use, they may get established in the speech community and become
borrowed/loan words (e.g., hip hop-related anglicisms in a german hip hop forum
(garley and hockenmaier 2012)).

earlier studies on language mixing were mostly based on multilingual spoken
data collected in controlled or naturalistic settings (auer 1988; myers-scotton 1995).
nowadays, the wide-spread use of internet in multilingual populations provides ample
opportunities for large-scale and in-depth analyses of mixed language use in online
media (danet and herring 2007; hinnenkamp 2008; hinrichs 2006; paolillo 2001; tsaliki
2003). still most of these studies focus on qualitative analyses of multilingual online
communication with limited data in terms of size and duration.

the rest of this section presents a discussion of data sources for studying multilin-
gual communication on a large scale (section 5.1). consequently, we discuss research on
adapting various nlp tools to process mixed-language texts (section 5.2). we conclude
this section with a discussion of studies that analyze, or even try to predict, the use of
multiple languages in multilingual communication (section 5.3).

5.1 data sources

in sociolinguistics, conversational data is usually collected by the researchers them-
selves, either among small groups of speakers at different times (do   gru  z and backus
2007, 2009) or from the same group of speakers longitudinally (milroy and milroy
1978; trudgill 2003). the manual transcription and annotation of data is time-intensive
and costly. multilingual data from online environments is usually extracted in small
volumes and for short periods. automatic analysis of this type of data has been dif   cult
for most languages, especially when resources or technical support are lacking.

within computational linguistics, there is a growing interest in the automatic pro-
cessing of mixed-language texts. lui, lau, and baldwin (2014) and yamaguchi and
tanaka-ishii (2012) studied automatic language identi   cation in mixed-language doc-
uments from wikipedia by arti   cially concatenating texts from monolingual sources
into multilingual documents. however, such approaches lead to arti   cial language
boundaries. more recently, social media (such as facebook (vyas et al. 2014), twitter (ju-
rgens, dimitrov, and ruths 2014; peng, wang, and dredze 2014; solorio et al. 2014) and
online forums (nguyen and do   gru  z 2013)) provide large volumes of data for analyzing
multilingual communication in social interaction. transcriptions of conversations have
been explored by solorio and liu (2008b), however their data was limited to three
speakers. language pairs that have been studied for multilingual communication in-
clude english-hindi (vyas et al. 2014), spanish-english (peng, wang, and dredze 2014;
solorio and liu 2008a, 2008b), turkish-dutch (nguyen and do   gru  z 2013), mandarin-
english (adel, vu, and schultz 2013; peng, wang, and dredze 2014), and french-english
(jurgens, dimitrov, and ruths 2014). besides being a valuable resource for studies on
multilingual social interaction, multilingual texts in social media have also been used to

35

computational linguistics

to appear

improve general purpose machine translation systems (huang and yates 2014; ling et
al. 2013).

processing and analyzing mixed-language data often requires identi   cation of lan-
guages at the word level. language identi   cation is a well-researched problem in cl
and we discussed it in the context of dialect identi   cation in section 3.4.1. here, we
discuss language identi   cation for mixed-language texts. several datasets are publicly
available to stimulate research on language identi   cation in mixed-language texts,
including data from the shared task on language identi   cation in code-switched
data (solorio et al. 2014) covering four different language pairs on twitter, romanized
algerian arabic and french texts from the comments section of an online algerian
newspaper (cotterell et al. 2014), turkish-dutch forum posts (nguyen and do   gru  z
2013) and web documents in different languages (king and abney 2013).

annotation on a    ne-grained level such as individual words has introduced new
challenges in the construction of datasets. more    ne-grained annotations require more
effort and sometimes the segments are so short that they can no longer be clearly
attributed to a particular language. for example, annotating the language of named
entities remains a challenge in mixed-language texts. named entities have been labeled
according to the context (king and abney 2013), ignored in the evaluation (elfardy and
diab 2012b; nguyen and do   gru  z 2013) or treated as a separate category (elfardy and
diab 2012a; solorio et al. 2014). annotation at sentence-level is also challenging. for
example, zaidan and callison-burch (2013) annotated a large corpus for arabic dialect
identi   cation using id104. their analysis indicated that many annotators over-
identify their native dialect (i.e., they were biased towards labeling texts as written
in their own dialect). elfardy and diab (2012a) presented guidelines to annotate texts
written in dialectal variants of arabic and modern standard arabic on a word level.

5.2 nlp tools for multilingual data

most of the current nlp tools, such as parsers, are developed for texts written in a
single language. therefore, such tools are not optimized for processing texts containing
multiple languages. in this section, we discuss the development of nlp tools that
speci   cally aim to support the processing of multilingual texts. we start with research
on automatic language identi   cation, which is an important step in the preprocessing
pipeline of many language-speci   c analysis tasks. mixed-language documents have
introduced new challenges to this task. we then continue with a discussion of work
on various other nlp tools (e.g., parsers, id96).

automatic language identi   cation. automatic language identi   cation is often the    rst
step for systems that process mixed-language texts (vyas et al. 2014). furthermore,
it supports large-scale analyses of patterns in multilingual communication (jurgens,
dimitrov, and ruths 2014; kim et al. 2014; papalexakis, nguyen, and do   gru  z 2014).
most of the earlier research on automatic language identi   cation focused on document-
level identi   cation of a single language (baldwin and lui 2010). to handle mixed-
language texts, more    ne-grained approaches have been explored, ranging from lan-
guage identi   cation at the sentence (elfardy and diab 2013; zaidan and callison-burch
2013; zampieri et al. 2014) and word level (elfardy and diab 2012b; king and abney
2013; nguyen and do   gru  z 2013; solorio et al. 2014; voss et al. 2014), approaches for
text segmentation (yamaguchi and tanaka-ishii 2012), and estimating the proportion
of the various languages used within documents (lui, lau, and baldwin 2014; prager
1999). depending on the application, different approaches may be suitable, but studies

36

nguyen et al.

computational sociolinguistics: a survey

that analyze patterns in multilingual communication have mostly focused on word-
level identi   cation (nguyen and do   gru  z 2013; solorio et al. 2014). off-the-shelf tools
developed for language identi   cation at the document-level (e.g., the textcat program
(cavnar and trenkle 1994)) are not effective for word-level identi   cation (alex 2005;
nguyen and do   gru  z 2013). language models (elfardy and diab 2012b; nguyen and
do   gru  z 2013) and dictionaries (alex 2005; elfardy and diab 2012b; nguyen and
do   gru  z 2013), which are also commonly used in automatic language identi   cation at
the document level, have been explored. furthermore, the context around the words has
been exploited using id49 to improve performance on language
identi   cation at the word level (king and abney 2013; nguyen and do   gru  z 2013).

parsing. early studies on language mixing within computational linguistics focused
on developing grammars to model language mixing (e.g., joshi (1982)). however, the
models developed in these early studies were not tested on empirical data. the more
recently developed systems have been validated on large, real-world data. solorio and
liu (2008b) explored various strategies to combine monolingual taggers to parse mixed-
language texts. the best performance was obtained by including the output of the
monolingual parsers as features in a machine learning algorithm. vyas et al. (2014)
studied the impact of different preprocessing steps on id52 of english-hindi
data collected from facebook. language identi   cation and id68 were the
major challenges that impacted pos performance.

language and topic models. language models have been developed to improve speech
recognition for mixed-language speech, by adding pos and language information to the
language models (adel, vu, and schultz 2013) or by incorporating syntactic inversion
constraints (li and fung 2012). peng, wang, and dredze (2014) developed a topic model
that infers language-speci   c topic distributions based on mixed-language text. the main
challenge for their model was aligning the inferred topics across languages.

5.3 analysis and prediction of multilingual communication

according to thomason (2001), gardner-chloros and edwards (2004), and bhatt and
bolonyai (2011), social factors (e.g., attitudes and motives of the speakers, social and
political context) are as important as linguistic factors in multilingual settings. large-
scale analysis of social factors in multilingual communication has only recently been
possible with the availability of automatic language identi   cation tools.

twitter is frequently used as a resource for such studies. focusing on language
choice at the user level, researchers have extracted network structures, based on follow-
ers and followees (eleta and golbeck 2014; kim et al. 2014), or mentions and retweets
(hale 2014), and analyzed the relation between the composition of such networks and
the language choices of users. users tweeting in multiple languages are often found to
function as a bridge between communities tweeting in one language. besides analyzing
language choice at the user level, there is also an interest in the language choices for
individual tweets. jurgens, dimitrov, and ruths (2014) studied tweets written in one
language but containing hashtags in another language. automatic language identi   -
cation was used to identify the languages of the tweets. however, as they note, some
tweets were written in another language because they were automatically generated by
applications rather than being a conscious choice of the user. nguyen, trieschnigg, and
cornips (2015) studied users in the netherlands who tweeted in a minority language
(limburgish or frisian) as well as in dutch. most tweets were written in dutch, but

37

computational linguistics

to appear

during conversations users often switched to the minority language (i.e., limburgish
or frisian). mocanu et al. (2013) analyzed the geographic distribution of languages in
multilingual regions and cities (such as new york and montreal) using twitter.

in addition to the analysis of patterns in multilingual communication, several
studies have explored the automatic prediction of language switches. the task may
seem similar to automatic language identi   cation, yet there are differences between the
two tasks. rather than determining the language of an utterance, it involves predicting
whether the language of the next utterance is the same without having access to the next
utterance itself. solorio and liu (2008a) were the    rst to predict whether a speaker will
switch to another language in english-spanish bilingual spoken conversations based
on lexical and syntactic features. the approach was evaluated using standard ma-
chine learning metrics as well as human evaluators who rated the naturalness/human-
likeness of the sentences the system generated. papalexakis, nguyen, and do   gru  z
(2014) predicted when multilingual users switch between languages in a turkish-dutch
online forum using various features, including features based on multi-word units and
emoticons.

6. research agenda

computational sociolinguistics is an emerging multidisciplinary    eld. closer collab-
oration between sociolinguists and computational linguists could be bene   cial to re-
searchers from both    elds. in this article, we have outlined some challenges related
to differences in data and methods that must be addressed in order for synergy to
be effective. in this section, we summarize the main challenges for advancing the
   eld of computational sociolinguistics. these fall under three main headings, namely,
expanding the scope of inquiry of the    eld, adapting methods to increase compatibility,
and offering tools.

6.1 expanding the scope of inquiry

the    eld of computational linguistics has begun to investigate issues that overlap with
those of the    eld of sociolinguistics. the emerging availability of data that is of interest
to both communities is an important factor, but in order for real synergy to come out
of this, additional angles in the research agendas and tuning of the methodological
frameworks in the respective communities would be needed.

going beyond lexical and stylistic variation. many studies within cl focus on lexical
variation (e.g., section 3 on social identity), possibly driven by the focus on prediction
tasks. stylistic variation has also received attention. several of the discussed studies
focus on variation in the usage of functional categories. for example, they zoom in
on the usage of determiners, prepositions and pronouns for studying linguistic style
accommodation (in section 4.3). others employ measures such as average word and
sentence length (e.g., in section 3). advances in the area of stylometry (stamatatos 2009)
could inspire the exploration of more    ne-grained features to capture style. besides
lexical and stylistic variation, linguistic variation also occurs on many other levels.
some computational studies have focused on phonological (eisenstein 2013a; jain et
al. 2012; j  rgensen, hovy, and s  gaard 2015) and syntactic (doyle 2014; gianfortoni,
adamson, and ros   2011; johannsen, hovy, and s  gaard 2015; wiersma, nerbonne, and
lauttamus 2010) variation, but so far the number of studies is limited. in combination

38

nguyen et al.

computational sociolinguistics: a survey

with the surge in availability of relevant data, these examples suggest that there seems
to be ample opportunities for an extended scope.

extending focus to other social variables. a large body of work exists on the modeling
of gender, age and regional variation (cf. section 3). other variables, like social class
(labov 1966), have barely received any attention so far within computational sociolin-
guistics. although it is more dif   cult to obtain labels for some social variables, they are
essential for a richer understanding of language variation and more robust analyses.

going beyond english and monolingual data. the world is multilingual and multicultural,
but english has received much more attention within computational sociolinguistics
than other languages. there is a need for research to validate the generalizability of    nd-
ings based on english data for other languages (danet and herring 2007). furthermore,
most studies within computational linguistics generally assume that texts are written in
one language. however, these assumptions may not hold, especially in social media. a
single user may use multiple languages, sometimes even within a syntactic unit, while
most nlp tools are not optimized to process such texts. tools that are able to process
mixed-language texts will support the analysis of such data and shed more light on the
social and linguistic factors involved in multilingual communication.

from monomodal to multimodal data. another recommendable shift in scope would be a
stronger focus on multimedia data. video and audio recordings with a speech track
encapsulate a form of language in which the verbal and nonverbal dimensions of
human communication are available in an integrated manner and they represent a rich
source for the study of social behavior. among the so-called paralinguistic aspects for
which detection models and evaluation frameworks exist are age, gender and affect
(schuller et al. 2010). the increasing volumes of recordings of spoken dialogue and
aligned transcriptions, e.g., in oral history collections (boyd 2013; de jong et al. 2014),
meeting recording archives (janin et al. 2003), and video blogs (biel et al. 2013), can
add new angles to the investigation of sociolinguistic variation. in particular, the study
of the interaction between (transcribed) speech, non-speech (laughter, sighs, etc.), facial
expression and gestures is a promising area for capturing and predicting social variables
as well as the related affective layers.

6.2 adapting methodological frameworks to increase compatibility

to make use of the rich repertoire of theory and practice from sociolinguistics and to
contribute to it, we have to appreciate the methodologies that underlie sociolinguistic
research, e.g., the rules of engagement for joining into the ongoing scienti   c discourse.
however, as we have highlighted in the methodology discussion earlier in the article,
the differences in values between the communities can be perceived as a divide. while
the cl community has experienced a history in which theory and empiricism are treated
as the extreme ends of a spectrum, in the social sciences there is no such dichotomy,
and empiricism contributes substantially to theory. moving forward, research within
computational sociolinguistics should build on and seek to partner in extending ex-
isting sociolinguistic theories and insights. this requires placing a strong focus on the
interpretability of the developed models. the feasibility of such a shift in attention can
be seen when observing successes of applied computational sociolinguistics work that
has been adopted in other    elds like health communication (may   eld et al. 2014) and
education (ros   et al. 2008).

39

computational linguistics

to appear

controlling for multiple variables. sociolinguistic studies typically control for multiple
social variables (e.g., gender, age, social class, ethnicity). however, many studies in
computational sociolinguistics focus on individual variables (e.g., only gender, or only
age), which can be explained by the focus on social media data. the uncontrolled nature
of social media makes it challenging to obtain data about the social backgrounds of the
speakers and to understand the various biases that such datasets might have. the result
is that models are frequently confounded, which results in low interpretability as well
as limited justi   cation for generalization to other domains.

on the other hand, much work in the cl community has focused on structured
modeling approaches that take a step towards addressing these issues (joshi et al. 2012,
2013). these approaches are very similar to the hierarchical modeling approaches used
in sociolinguistic research to control for multiple sources of variation and thus avoid
misattributing weight to extraneous variables. a stronger partnership within the    eld
of cl between researchers interested in computational sociolinguistics and researchers
interested in multi-domain learning would be valuable for addressing some of the limi-
tations mentioned above. in this regard, inferring demographic variables automatically
(see section 3) may also help, since predicted demographic variables could be used in
structuring the models. another approach is the use of census data when location data
is already available. for example, eisenstein et al. (2014) studied lexical change in social
media by using census data to obtain demographic information for the geographical
locations. they justi   ed their approach by assuming that lexical change is in   uenced
by the demographics of the population in these locations, and not necessarily by the
demographics of the particular twitter users in these locations.

developing models that generalize across domains. many of the studies within the area
of computational sociolinguistics have focused on a single domain. however, domain
effects can in   uence the    ndings, such as which features are predictive for gender
(e.g., herring and paolillo (2006)). studies considering multiple domains enable distin-
guishing variables that work differently in different contexts, and therefore improve the
interpretation of the    ndings. recently, several studies within the area of computational
sociolinguistics have performed experiments across domains (sap et al. 2014; sarawgi,
gajulapalli, and choi 2011) and explored the effectiveness of id20 ap-
proaches (nguyen, smith, and ros   2011; piergallini et al. 2014). another approach
involves reconsidering the features used in an attempt to include more features with
a deep connection with the predicted variable of interest. for example, gianfortoni,
adamson, and ros   (2011) show that features such as id165s, usually reported to be
predictive for gender classi   cation, did not perform well after controlling for occupation
in a blog corpus, but pattern-based features inspired by    ndings related to gender-based
language practices did.

using sociolinguistics and the social sciences as a source of inspiration for methodological
re   ection. going forward, we need to appreciate where our work stands along an impor-
tant continuum that represents a fundamental tension in the social sciences: qualitative
approaches that seek to preserve the complexity of the phenomena of interest, versus
quantitative approaches that discretize (but thereby also simplify) the phenomena to
achieve more generalizability. for computational linguistics, a primarily quantitative
   eld, work from research areas with a less strong or less exclusive focus on quan-
titative measures, such as sociolinguistics and the social sciences, could serve as a
source of inspiration for methodological re   ection. in this survey, we have questioned
the operationalizations of the concepts of gender (section 3.2), age (section 3.3) and

40

nguyen et al.

computational sociolinguistics: a survey

language variety (section 3.4) as discrete and static categories, based on insights from
sociolinguistics. more critical re   ection on such operationalizations could lead to a
deeper insight into the limitations of the developed models and the incorrect predictions
that they sometimes make.

6.3 tuning nlp tools to requirements of sociolinguistics research

as a    nal important direction, we should consider what would be required for nlp
tools to be supportive for sociolinguistic work.

developing models that can guide users of data analysis systems in taking next steps. so-
ciolinguists are primarily interested in new insights about language use. in contrast,
much of the work within cl is centered around highly speci   c analysis tasks that are
isolated from scenarios of use, and the focus on the obtained performance    gures for
such tasks is fairly dominant. as manning (2015) mentions: "[..], there has been an over-
focus on numbers, on beating the state of the art". only for few analysis methods, validation
of the outcomes has been pursued (e.g., have we measured the right thing?) in view of
the potential for integration of the models outside lab-like environments. furthermore
many of the models developed within cl make use of thousands of features. as a result,
their value for practical data exploration tasks is therefore often limited. sparse models,
such as used in eisenstein, smith, and xing (2011), that identify small sets of predictive
features would be more suited for exploratory analysis. however, when the focus is on
interpretability of the models, we must consider that the resulting average prediction
performance of interpretable models may be lower (piergallini et al. 2014).

developing pre-processing tools to support the analysis of language variation. the perfor-
mance of many developed nlp tools is lower on informal text. for example, pos
taggers perform less well on texts written by certain user groups (e.g., younger people
(hovy and s  gaard 2015)) or on texts in certain language varieties (e.g., african amer-
ican vernacular english (j  rgensen, hovy, and s  gaard 2015)). one of the approaches
to improve the performance of tools has been to normalize the texts, but as eisenstein
(2013b) argues, doing so is removing the variation that is central to the study of sociolin-
guistics. to support deeper sociolinguistic analyses and to go beyond shallow features,
we thus need pre-processing tools, such as pos taggers, that are able to handle the
variation found in informal texts and that are not biased towards certain social groups.

7. conclusion

while the computational linguistics    eld has historically emphasized interpretation and
manipulation of the propositional content of language, another valid perspective on
language is that it is a dynamic, social entity. while some aspects of language viewed
from a social perspective are predictable, and thus behave much like other aspects more
commonly the target of inquiry in the    eld, we must acknowledge that linguistic agency
is a big part of how language is used to construct social identities, to build and maintain
social relationships, and even to de   ne the boundaries of communities. the increasing
research on social media data has contributed to the insight that text can be considered
as a data source that captures multiple aspects and layers of human and social behavior.
the recent focus on text as social data and the emergence of computational social science
are likely to increase the interest within the computational linguistics community on
sociolinguistic topics. in this article, we have de   ned and set out a research agenda

41

computational linguistics

to appear

for the emerging    eld of    computational sociolinguistics   . we have aimed to provide a
comprehensive overview of studies published within the    eld of cl that touch upon
sociolinguistic themes in order to provide an overview of what has been accomplished
so far and where there is room for growth. in particular, we have endeavored to
illustrate how the large-scale data-driven methods of our community can complement
existing sociolinguistic studies, but also how sociolinguistics can inform and challenge
our methods and assumptions.

acknowledgments
thanks to mari  t theune, dirk hovy and
marcos zampieri for helpful comments on
the draft. thanks also to the anonymous
reviewers for their valuable and detailed
feedback. this work was funded in part
through nsf grant aci-1443068 and arl
grant w911nf-11-2-0042. the    rst author
was supported by the netherlands
organization for scienti   c research (nwo)
grant 640.005.002 (catch project fact).
the second author was supported by the
digital humanities research grant from
tilburg university and a fellowship from the
netherlands institute of advanced study in
humanities and social sciences.

references
adel, heike, ngoc thang vu, and tanja

schultz. 2013. combination of recurrent
neural networks and factored language
models for code-switching language
modeling. in proceedings of the 51st annual
meeting of the association for computational
linguistics (volume 2: short papers), pages
206   211, so   a, bulgaria.

alex, beatrice. 2005. an unsupervised

system for identifying english inclusions
in german text. in proceedings of the acl
student research workshop, pages 133   138,
ann arbor, michigan.

androutsopoulos, jannis. 2013. online data
collection. in christine mallinson, becky
childs, and gerard van herk, editors, data
collection in sociolinguistics: methods and
applications. routledge.

ardehaly, ehsan mohammady and aron

culotta. 2015. inferring latent attributes of
twitter users with label id173. in
proceedings of the 2015 conference of the
north american chapter of the association for
computational linguistics: human language
technologies, pages 185   195, denver,
colorado.

argamon, shlomo, moshe koppel, jonathan

fine, and anat rachel shimoni. 2003.
gender, genre, and writing style in formal
written texts. text, 23(3):321   346.

42

argamon, shlomo, moshe koppel, james w.

pennebaker, and jonathan schler. 2007.
mining the blogosphere: age, gender and
the varieties of self-expression. first
monday, 12(9).

argamon, shlomo, moshe koppel, james w.

pennebaker, and jonathan schler. 2009.
automatically pro   ling the author of an
anonymous text. communications of the
acm, 52(2):119   123.

auer, peter. 1988. a conversation analytic

approach to code-switching and transfer.
in monica heller, editor, codeswitching:
anthropological and sociolinguistic
perspectives. berlin: mouton de gruyter,
pages 187   213.

austin, john langshaw. 1975. how to do

things with words. oxford university press.

backofen, rolf and gert smolka. 1993. a

complete and recursive feature theory. in
proceedings of the 31st annual meeting of the
association for computational linguistics,
pages 193   200, columbus, ohio.

bak, jinyeong, suin kim, and alice oh. 2012.
self-disclosure and relationship strength in
twitter conversations. in proceedings of the
50th annual meeting of the association for
computational linguistics (volume 2: short
papers), pages 60   64, jeju island, korea.
association for computational linguistics.

baldwin, timothy, paul cook, marco lui,
andrew mackinlay, and li wang. 2013.
how noisy social media text, how diffrnt
social media sources? in proceedings of the
sixth international joint conference on
natural language processing, pages
356   364, nagoya, japan.

baldwin, timothy and marco lui. 2010.

language identi   cation: the long and the
short of the matter. in proceedings of the
2010 annual conference of the north
american chapter of the association for
computational linguistics, pages 229   237,
los angeles, california.

bamman, david, chris dyer, and noah a.

smith. 2014. distributed representations of
geographically situated language. in
proceedings of the 52nd annual meeting of the
association for computational linguistics
(volume 2: short papers), pages 828   834,

nguyen et al.

computational sociolinguistics: a survey

baltimore, maryland.

bamman, david, jacob eisenstein, and tyler

schnoebelen. 2014. gender identity and
lexical variation in social media. journal of
sociolinguistics, 18(2):135   160.

2012. detecting in   uencers in written
online conversations. in proceedings of the
2012 workshop on language in social media
(lsm 2012), pages 37   45, montreal,
canada.

bamman, david and noah a. smith. 2015.

blei, david m., andrew y. ng, and michael i.

contextualized sarcasm detection on
twitter. in proceedings of the ninth
international aaai conference on web and
social media, pages 574   577, oxford, uk.

barbieri, federica. 2008. patterns of

age-based linguistic variation in american
english. journal of sociolinguistics,
12(1):58   88.

jordan. 2003. id44.
journal of machine learning research,
3:993   1022.

bolander, brook and miriam a. locher. 2014.

doing sociolinguistic research on
computer-mediated data: a review of four
methodological issues. discourse, context
& media, 3(0):14     26.

behrend, tara s., david j. sharek, adam w.

boulis, constantinos and mari ostendorf.

meade, and eric n. wiebe. 2011. the
viability of id104 for survey
research. behavior research methods,
43(3):800   813.

bell, allan. 1984. language style as audience
design. language in society, 13(2):145   204.

bell, allan. 2013. the guidebook to

sociolinguistics. john wiley & sons.

bender, emily m., jonathan t. morgan,

meghan oxley, mark zachry, brian
hutchinson, alex marin, bin zhang, and
mari ostendorf. 2011. annotating social
acts: authority claims and alignment
moves in wikipedia talk pages. in
proceedings of the workshop on language in
social media (lsm 2011), pages 48   57.
portland, oregon.

bergsma, shane, matt post, and david

yarowsky. 2012. stylometric analysis of
scienti   c articles. in proceedings of the 2012
conference of the north american chapter of
the association for computational linguistics:
human language technologies, pages
327   337, montreal, canada.

bergsma, shane and benjamin van durme.
2013. using conceptual class attributes to
characterize social media users. in
proceedings of the 51st annual meeting of the
association for computational linguistics
(volume 1: long papers), pages 710   720,
so   a, bulgaria.

bhatt, rakesh m. and agnes bolonyai. 2011.
code-switching and the optimal grammar
of bilingual language use. bilingualism:
language and cognition, 14(04):522   546.

biel, joan-isaac, vagia tsiminaki, john dines,

and daniel gatica-perez. 2013. hi
youtube!: personality impressions and
verbal content in social video. in
proceedings of the 15th acm on international
conference on multimodal interaction, pages
119   126, sydney, australia.

biran, or, sara rosenthal, jacob andreas,

kathleen mckeown, and owen rambow.

2005. a quantitative analysis of lexical
differences between genders in telephone
conversations. in proceedings of the 43rd
annual meeting of the association for
computational linguistics (acl   05), pages
435   442, ann arbor, michigan.

boyd, doug. 2013. special issue: oral history
in the digital age, volume 40. oral history
review.

bracewell, david b., marc tomlinson, and

hui wang. 2012. a motif approach for
identifying pursuits of power in social
discourse. in 2012 ieee sixth international
conference on semantic computing, pages
1   8, palermo, italy.

bramsen, philip, martha escobar-molano,

ami patel, and rafael alonso. 2011.
extracting social power relationships from
natural language. in proceedings of the 49th
annual meeting of the association for
computational linguistics: human language
technologies, pages 773   782, portland,
oregon, usa.

bright, william. 1997. notes. language in

society, 26(03):469   470.

brody, samuel and nicholas diakopoulos.

2011.
cooooooooooooooollllllllllllll!!!!!!!!!!!!!!
using word lengthening to detect
sentiment in microblogs. in proceedings of
the 2011 conference on empirical methods in
natural language processing, pages
562   570, edinburgh, scotland, uk.

brown, penelope and stephen c. levinson.

1987. politeness: some universals in language
usage, volume 4 of studies in interactional
sociolinguistics. cambridge university
press.

bucholtz, mary and kira hall. 2005. identity
and interaction: a sociocultural linguistic
approach. discourse studies, 7(4-5):585   614.

burger, john d., john henderson, george

kim, and guido zarrella. 2011.
discriminating gender on twitter. in

43

computational linguistics

to appear

proceedings of the 2011 conference on
empirical methods in natural language
processing, pages 1301   1309, edinburgh,
scotland, uk.

burger, john d. and john c. henderson.

2006. an exploration of observable
features related to blogger age. in aaai
spring symposium: computational
approaches to analyzing weblogs, pages
15   20, menlo park, california.

butler, judith. 1990. gender trouble: feminism

and the subversion of identity. routledge.

gender-preferential id111 of e-mail
discourse. in proceedings of the 18th annual
computer security applications conference
(acsac    02), pages 282   289, las vegas,
nevada.

cotterell, ryan, adithya renduchintala,

naomi saphra, and chris callison-burch.
2014. an algerian arabic-french
code-switched corpus. in lrec-2014
workshop on free/open-source arabic
corpora and corpora processing tools,
reykjavik, iceland.

carletta, jean. 1996. assessing agreement on

dadvar, maral, franciska m. g. de jong,

classi   cation tasks: the kappa statistic.
computational linguistics, 22(2):249   254.

cassell, justine and dona tversky. 2005. the

language of online intercultural
community formation. journal of
computer-mediated communication, 10(2).

roeland ordelman, and dolf trieschnigg.
2012. improved cyberbullying detection
using gender information. in proceedings of
the twelfth dutch-belgian information
retrieval workshop (dir 2012), pages 23   25,
ghent, belgium.

cavnar, william b. and john m. trenkle.

daelemans, walter. 2013. explanation in

1994. id165-based text categorization. in
proceedings of sdair-94, 3rd annual
symposium on document analysis and
information retrieval, pages 161   175, las
vegas, us.

chambers, jack k. and peter trudgill. 1998.
dialectology. cambridge university press.

choi, bernard c. k. and anita w. p. pak.

2006. multidisciplinarity,
interdisciplinarity and transdisciplinarity
in health research, services, education and
policy: 1. de   nitions, objectives, and
evidence of effectiveness. clin invest med,
29(6):351   364.

ciot, morgane, morgan sonderegger, and
derek ruths. 2013. gender id136 of
twitter users in non-english contexts. in
proceedings of the 2013 conference on
empirical methods in natural language
processing, pages 1136   1145, seattle,
washington, usa.

clopper, cynthia g. 2013. experiments. in
christine mallinson, becky childs, and
gerard van herk, editors, data collection
in sociolinguistics: methods and applications.
routledge.

cohen, raviv and derek ruths. 2013.

classifying political orientation on twitter:
it   s not easy! in proceedings of the seventh
international aaai conference on weblogs
and social media, pages 91   99, cambridge,
massachusetts, usa.

collins, linda m. and stephanie t. lanza.

2010. latent class and latent transition
analysis: with applications in the social,
behavioral, and health sciences. john wiley &
sons.

corney, malcolm, olivier de vel, alison

anderson, and george mohay. 2002.

44

computational stylometry. in proceedings of
the 14th international conference on
computational linguistics and intelligent text
processing (cicling   13) - volume 2, pages
451   462, samos, greece.

danescu-niculescu-mizil, cristian, michael

gamon, and susan dumais. 2011. mark
my words! linguistic style
accommodation in social media. in
proceedings of the 20th international
conference on world wide web, pages
745   754, hyderabad, india.

danescu-niculescu-mizil, cristian and

lillian lee. 2011. chameleons in imagined
conversations: a new approach to
understanding coordination of linguistic
style in dialogs. in proceedings of the 2nd
workshop on cognitive modeling and
computational linguistics, pages 76   87,
portland, oregon, usa.

danescu-niculescu-mizil, cristian, lillian

lee, bo pang, and jon kleinberg. 2012.
echoes of power: language effects and
power differences in social interaction. in
proceedings of the 21st international
conference on world wide web, pages
699   708, lyon, france.

danescu-niculescu-mizil, cristian, moritz
sudhof, dan jurafsky, jure leskovec, and
christopher potts. 2013a. a computational
approach to politeness with application to
social factors. in proceedings of the 51st
annual meeting of the association for
computational linguistics (volume 1: long
papers), pages 250   259, so   a, bulgaria.

danescu-niculescu-mizil, cristian, robert

west, dan jurafsky, jure leskovec, and
christopher potts. 2013b. no country for
old members: user lifecycle and linguistic

nguyen et al.

computational sociolinguistics: a survey

change in online communities. in
proceedings of the 22nd international
conference on world wide web (www    13),
pages 307   318, rio de janeiro, brazil.

danet, brenda and susan c. herring, editors.

2007. the multilingual internet: language,
culture, and communication online. oxford
university press.

darwish, kareem, hassan sajjad, and

hamdy mubarak. 2014. veri   ably effective
arabic dialect identi   cation. in proceedings
of the 2014 conference on empirical methods
in natural language processing (emnlp),
pages 1465   1468, doha, qatar.

de fina, anna, deborah schiffrin, and

michael bamberg, editors. 2006. discourse
and identity. cambridge university press.
de jong, franciska, arjan van hessen, tanja
petrovic, and stef scagliola. 2014. croatian
memories: speech, meaning and emotions
in a collection of interviews on experiences
of war and trauma. in proceedings of the
ninth international conference on language
resources and evaluation (lrec   14), pages
26   31, reykjavik, iceland.

di eugenio, barbara and michael glass.

2004. the kappa statistic: a second look.
computational linguistics, 30(1):95   101.

diehl, christopher p., galileo namata, and

lise getoor. 2007. relationship
identi   cation for social network discovery.
in proceedings of the twenty-second aaai
conference on arti   cial intelligence, pages
546   552, vancouver, british columbia,
canada.

diesner, jana and kathleen m carley. 2005.
exploration of communication networks
from the enron email corpus. in
proceedings of siam international conference
on data mining: workshop on link analysis,
counterterrorism and security, pages 3    14,
newport beach, ca, usa.

do   gru  z, a. seza and ad backus. 2007.

postverbal elements in immigrant turkish:
evidence of change? international journal of
bilingualism, 11(2):185   220.

do   gru  z, a. seza and ad backus. 2009.

innovative constructions in dutch turkish:
an assessment of ongoing contact-induced
change. bilingualism: language and
cognition, 12(01):41   63.

do   gru  z, a. seza and preslav nakov. 2014.
predicting dialect variation in immigrant
contexts using light verb constructions. in
proceedings of the 2014 conference on
empirical methods in natural language
processing (emnlp), pages 1391   1395,
doha, qatar.

doyle, gabriel. 2014. mapping dialectal
variation by querying social media. in
proceedings of the 14th conference of the
european chapter of the association for
computational linguistics, pages 98   106,
gothenburg, sweden.

d  rscheid, christa and elisabeth stark, 2011.

digital discourse. language in the new
media, chapter sms4science: an
international corpus-based texting project
and the speci   c challenges for
multilingual switzerland. oxford: oxford
university press.

eckert, penelope. 1989. jocks and burnouts:

social categories and identity in the high
school. teachers college press.
eckert, penelope. 1997. age as a

sociolinguistic variable. in florian
coulmas, editor, the handbook of
sociolinguistics. blackwell publishers.
eckert, penelope. 2012. three waves of

variation study: the emergence of meaning
in the study of sociolinguistic variation.
annual review of anthropology, 41:87   100.

eckert, penelope and sally mcconnell-ginet.

2013. language and gender. cambridge
university press.

eisenstein, jacob. 2013a. phonological factors

in social media writing. in proceedings of
the workshop on language analysis in social
media (lasm 2013), pages 11   19, atlanta,
georgia.

eisenstein, jacob. 2013b. what to do about

bad language on the internet. in
proceedings of the 2013 conference of the
north american chapter of the association for
computational linguistics: human language
technologies, pages 359   369, atlanta,
georgia.

eisenstein, jacob. 2015. written dialect

variation in online social media. in charles
boberg, john nerbonne, and dom watt,
editors, handbook of dialectology. wiley.

eisenstein, jacob, brendan o   connor,

noah a. smith, and eric p. xing. 2010. a
latent variable model for geographic
lexical variation. in proceedings of the 2010
conference on empirical methods in natural
language processing, pages 1277   1287,
cambridge, ma.

eisenstein, jacob, brendan o   connor,

noah a. smith, and eric p. xing. 2014.
diffusion of lexical change in social media.
plos one, 9(11):e113114, 11.

eisenstein, jacob, noah a. smith, and eric p.

xing. 2011. discovering sociolinguistic
associations with structured sparsity. in
proceedings of the 49th annual meeting of the
association for computational linguistics:

45

computational linguistics

to appear

human language technologies-volume 1,
pages 1365   1374, portland, oregon, usa.

eleta, irene and jennifer golbeck. 2014.

multilingual use of twitter: social
networks at the language frontier.
computers in human behavior, 41:424     432.

elfardy, heba and mona diab. 2012a.

simpli   ed guidelines for the creation of
large scale dialectal arabic annotations. in
proceedings of the eighth international
conference on language resources and
evaluation (lrec-2012), istanbul, turkey.
elfardy, heba and mona diab. 2012b. token

level identi   cation of linguistic code
switching. in proceedings of coling 2012:
posters, pages 287   296, mumbai, india.

elfardy, heba and mona diab. 2013.

sentence level dialect identi   cation in
arabic. in proceedings of the 51st annual
meeting of the association for computational
linguistics (volume 2: short papers), pages
456   461, so   a, bulgaria.

fairclough, norman. 1989. language and

power. london: longman.

ferschke, oliver, iryna gurevych, and

yevgen chebotar. 2012. behind the article:
recognizing dialog acts in wikipedia talk
pages. in proceedings of the 13th conference
of the european chapter of the association for
computational linguistics, pages 777   786,
avignon, france.

filippova, katja. 2012. user demographics

and language in an implicit social
network. in proceedings of the 2012 joint
conference on empirical methods in natural
language processing and computational
natural language learning, pages
1478   1488, jeju island, korea.

fink, clay, jonathon kopecky, and maksym

morawski. 2012. inferring gender from the
content of tweets: a region speci   c
example. in proceedings of the sixth
international aaai conference on weblogs
and social media, pages 459   462, dublin,
ireland.

gardner-chloros, penelope and malcolm

edwards. 2004. assumptions behind
grammatical approaches to
code-switching: when the blueprint is a
red herring. transactions of the philological
society, 102(1):103   129.

garera, nikesh and david yarowsky. 2009.
modeling latent biographic attributes in
conversational genres. in proceedings of the
joint conference of the 47th annual meeting
of the acl and the 4th international joint
conference on natural language processing of
the afnlp, pages 710   718, suntec,
singapore.

46

garley, matt and julia hockenmaier. 2012.

beefmoves: dissemination, diversity, and
dynamics of english borrowings in a
german hip hop forum. in proceedings of
the 50th annual meeting of the association for
computational linguistics (volume 2: short
papers), pages 135   139, jeju island, korea.

gee, james paul. 2011. an introduction to

discourse analysis: theory and method. new
york: routledge, third edition.

gianfortoni, philip, david adamson, and

carolyn p. ros  . 2011. modeling of stylistic
variation in social media with stretchy
patterns. in proceedings of the first workshop
on algorithms and resources for modelling of
dialects and language varieties, pages
49   59, edinburgh, scotland.

gilbert, eric. 2012. phrases that signal

workplace hierarchy. in proceedings of the
acm 2012 conference on computer
supported cooperative work, cscw    12,
pages 1037   1046, seattle, washington,
usa.

gilbert, eric and karrie karahalios. 2009.

predicting tie strength with social media.
in proceedings of the sigchi conference on
human factors in computing systems, pages
211   220, boston, massachusetts, usa.

giles, howard and nikolas coupland. 1991.

language: contexts and consequences.
mapping social psychology series.
brooks/cole publishing company.

giles, howard, nikolas coupland, and

justine coupland. 1991. accommodation
theory: communication, context, and
consequence. in howard giles, justine
coupland, and nikolas coupland, editors,
contexts of accommodation. cambridge
university press, pages 1   68.

giles, howard, donald m. taylor, and

richard bourhis. 1973. towards a theory of
interpersonal accommodation through
language: some canadian data. language
in society, 2(2):177   192.

glymour, clark, richard scheines, peter

spirtes, and kevin kelly. 1987. discovering
causal structure: arti   cial intelligence,
philosophy of science, and statistical modeling.
academic press.

gonzales, amy l., jeffrey t. hancock, and

james w. pennebaker. 2010. language
style matching as a predictor of social
dynamics in small groups. communication
research, 37(1):3   19.

goswami, sumit, sudeshna sarkar, and

mayur rustagi. 2009. stylometric analysis
of bloggers    age and gender. in proceedings
of the third international icwsm conference,
pages 214   217, san jose, california.

nguyen et al.

computational sociolinguistics: a survey

gouws, stephan, donald metzler, congxing

cai, and eduard hovy. 2011. contextual
bearing on linguistic variation in social
media. in proceedings of the workshop on
language in social media (lsm 2011), pages
20   29, portland, oregon.

granovetter, mark s. 1973. the strength of
weak ties. american journal of sociology,
78(6):1360   1380.

green, neil. 1992. meaning-text theory:

linguistics, id69, and
implications. machine translation,
7(3):195   198.

grice, h. paul. 1975. logic and conversation,

syntax and semantics, volume 3. academic
press.

grieve, jack. 2007. quantitative authorship
attribution: an evaluation of techniques.
literary and linguistic computing,
22(3):251   270.

grieve, jack, dirk speelman, and dirk

geeraerts. 2011. a statistical method for
the identi   cation and aggregation of
regional linguistic variation. language
variation and change, 23:193   221.

modeling positive and negative relations
among participants. in proceedings of the
2012 joint conference on empirical methods
in natural language processing and
computational natural language learning,
pages 59   70, jeju island, korea.

heeringa, wilbert and john nerbonne. 2001.

dialect areas and dialect continua.
language variation and change,
13(03):375   400.

heeringa, wilbert and john nerbonne, 2013.

language and space. an international
handbook of linguistic variation, volume iii:
dutch, chapter dialectometry. de gruyter
mouton.

heider, fritz. 1946. attitudes and cognitive

organization. the journal of psychology:
interdisciplinary and applied, 21(1):107   112.

hemphill, libby and jahna otterbacher.

2012. learning the lingo?: gender, prestige
and linguistic adaptation in review
communities. in proceedings of the acm
2012 conference on computer supported
cooperative work, pages 305   314, seattle,
washington, usa.

grif   ths, thomas l. and mark steyvers.

herring, susan c., editor. 1996.

2004. finding scienti   c topics. proceedings
of the national academy of sciences,
101(suppl 1):5228   5235.

guinote, ana and theresa k. vescio, editors.

2010. the social psychology of power. the
guilford press.

gumperz, john j. 1982. discourse strategies.

cambridge university press.

guy, gregory r. 2013. the cognitive

coherence of sociolects: how do speakers
handle multiple sociolinguistic variables?
journal of pragmatics, 52:63     71.

gweon, gahgene, mahaveer jain, john

mcdonough, bhiksha raj, and carolyn p.
ros  . 2013. measuring prevalence of
other-oriented transactive contributions
using an automated measure of speech
style accommodation. international journal
of computer-supported collaborative
learning, 8(2):245   265.

computer-mediated communication:
linguistic, social, and cross-cultural
perspectives, volume 39 of pragmatics &
beyond new series. john benjamins
publishing.

herring, susan c. 2004. computer-mediated

discourse analysis: an approach to
researching online behavior. in sasha
barab, rob kling, and james h. gray,
editors, designing for virtual communities
in the service of learning. new york:
cambridge university press, pages 338    
376.

herring, susan c. 2007. a faceted

classi   cation scheme for
computer-mediated discourse.
language@internet, 4(1).

herring, susan c. and john c. paolillo. 2006.

gender and genre variation in weblogs.
journal of sociolinguistics, 10(4):439   459.

hale, scott a. 2014. global connectivity and

heskes, tom, kees albers, and bert kappen.

multilinguals in the twitter network. in
proceedings of the 32nd annual acm
conference on human factors in computing
systems, pages 833   842, toronto, canada.
han, bo, paul cook, and timothy baldwin.

2012. geolocation prediction in social
media data by    nding location indicative
words. in proceedings of coling 2012,
pages 1045   1062, mumbai, india.

2002. approximate id136 and
constrained optimization. in proceedings of
the nineteenth conference on uncertainty in
arti   cial intelligence, pages 313   320,
acapulco, mexico.

hey, tony, stewart tansley, and kristin tolle,

editors. 2009. the fourth paradigm:
data-intensive scienti   c discovery. microsoft
research.

hassan, ahmed, amjad abu-jbara, and

heylighen, francis and jean-marc dewaele.

dragomir radev. 2012. detecting
subgroups in online discussions by

2002. variation in the contextuality of
language: an empirical measure.

47

computational linguistics

to appear

foundations of science, 7(3):293   340.

hinnenkamp, volker. 2008. deutsch, doyc or
doitsch? chatters as languagers   the case
of a german   turkish chat room.
international journal of multilingualism,
5(3):253   275.

hinrichs, lars. 2006. codeswitching on the

web: english and jamaican creole in e-mail
communication. john benjamins publishing
company.

holmes, david i. 1998. the evolution of
stylometry in humanities scholarship.
literary and linguistic computing,
13(3):111   117.

holmes, janet. 1995. women, men and

politeness. routledge.

holmes, janet. 2013. an introduction to

sociolinguistics. routledge.

holmes, janet and miriam meyerhoff,

editors. 2003. the handbook of language and
gender. wiley-blackwell.

hovy, dirk. 2015. demographic factors

improve classi   cation performance. in
proceedings of the 53rd annual meeting of the
association for computational linguistics and
the 7th international joint conference on
natural language processing (volume 1: long
papers), pages 752   762, beijing, china.

portugal.

huang, fei and alexander yates. 2014.

improving word alignment using
linguistic code switching data. in
proceedings of the 14th conference of the
european chapter of the association for
computational linguistics, pages 1   9,
gothenburg, sweden.

huffaker, david. 2010. dimensions of

leadership and social in   uence in online
communities. human communication
research, 36(4):593   617.

huffaker, david, joseph jorgensen, francisco
iacobelli, paul tepper, and justine cassell.
2006. computational measures for
language similarity across time in online
communities. in proceedings of the
hlt-naacl 2006 workshop on analyzing
conversations in text and speech, pages
15   22, new york city, new york.

hughes, baden, timothy baldwin, steven

bird, jeremy nicholson, and andrew
mackinlay. 2006. reconsidering language
identi   cation for written language
resources. in proceedings of the fifth
international conference on language
resources and evaluation (lrec   06), pages
485   488, genoa, italy.

hovy, dirk, anders johannsen, and anders

hyland, ken. 2004. disciplinary discourses:

s  gaard. 2015. user review sites as a
resource for large-scale sociolinguistic
studies. in proceedings of the 24th
international conference on world wide web
(www    15), pages 452   461, florence, italy.

hovy, dirk and anders s  gaard. 2015.
tagging performance correlates with
author age. in proceedings of the 53rd
annual meeting of the association for
computational linguistics and the 7th
international joint conference on natural
language processing (volume 2: short
papers), pages 483   488, beijing, china.

howley, iris, elijah may   eld, and carolyn p.

ros  , 2013. the international handbook of
collaborative learning, chapter linguistic
analysis methods for studying small
groups. routledge.

hu, yuheng, kartik talamadupula, and
subbarao kambhampati. 2013. dude,
srsly?: the surprisingly formal nature of
twitter   s language. in proceedings of the
seventh international aaai conference on
weblogs and social media, pages 244   253,
boston, massachusetts usa.

huang, fei. 2015. improved arabic dialect
classi   cation with social media data. in
proceedings of the 2015 conference on
empirical methods in natural language
processing, pages 2118   2126, lisbon,

48

social interactions in academic writing. the
university of michigan press.

jain, mahaveer, john mcdonough, gahgene
gweon, bhiksha raj, and carolyn p. ros  .
2012. an unsupervised dynamic bayesian
network approach to measuring speech
style accommodation. in proceedings of the
13th conference of the european chapter of the
association for computational linguistics,
pages 787   797, avignon, france.

janin, adam, don baron, jane edwards, dan

ellis, david gelbart, nelson morgan,
barbara peskin, thilo pfau, elizabeth
shriberg, andreas stolcke, and chuck
wooters. 2003. the icsi meeting corpus. in
proceedings of 2013 ieee international
conference on acoustics, speech, and signal
processing (icassp    03), pages 364   367,
hong kong.

johannsen, anders, dirk hovy, and anders

s  gaard. 2015. cross-lingual syntactic
variation over age and gender. in
proceedings of the nineteenth conference on
computational natural language learning,
pages 103   112, beijing, china.

jones, simon, rachel cotterill, nigel

dewdney, kate muir, and adam joinson.
2014. finding zelig in text: a measure for
normalising linguistic accommodation. in
proceedings of coling 2014, the 25th

nguyen et al.

computational sociolinguistics: a survey

international conference on computational
linguistics: technical papers, pages 455   465,
dublin, ireland.

j  rgensen, anna, dirk hovy, and anders

s  gaard. 2015. challenges of studying and
processing dialects in social media. in
proceedings of the acl 2015 workshop on
noisy user-generated text, pages 9   18,
beijing, china.

joshi, aravind k. 1982. processing of

sentences with intra-sentential
code-switching. in coling 1982: proceedings
of the ninth international conference on
computational linguistics, pages 145   150,
prague, czechoslovakia.

joshi, mahesh, william w. cohen, mark

dredze, and carolyn p. ros  . 2012.
multi-domain learning: when do domains
matter? in proceedings of the 2012 joint
conference on empirical methods in natural
language processing and computational
natural language learning, pages
1302   1312, jeju island.

documents using weakly supervised
methods. in proceedings of the 2013
conference of the north american chapter of
the association for computational linguistics:
human language technologies, pages
1110   1119, atlanta, georgia.

king, ben, dragomir radev, and steven
abney. 2014. experiments in sentence
language identi   cation with groups of
similar languages. in proceedings of the first
workshop on applying nlp tools to similar
languages, varieties and dialects, pages
146   154, dublin, ireland.

klavans, judith l. and philip resnik, editors.
1996. the balancing act: combining symbolic
and statistical approaches to language. mit
press.

klimt, bryan and yiming yang. 2004. the
enron corpus: a new dataset for email
classi   cation research. in proceedings of the
15th european conference on machine
learning (ecml 2004), pages 217   226, pisa,
italy.

joshi, mahesh, mark dredze, william w.

kokkos, athanasios and theodoros

cohen, and carolyn p. ros  . 2013. what   s
in a domain? multi-domain learning for
multi-attribute data. in proceedings of
naacl-hlt 2013, pages 685   690, atlanta,
georgia.

jurafsky, dan, rajesh ranganath, and dan

mcfarland. 2009. extracting social
meaning: identifying interactional style in
spoken conversation. in proceedings of
human language technologies: the 2009
annual conference of the north american
chapter of the association for computational
linguistics, pages 638   646, boulder,
colorado.

tzouramanis. 2014. a robust gender
id136 model for online social networks
and its application to linkedin and
twitter. first monday, 19(9).

koller, daphne and nir friedman. 2009.

probabilistic id114: principles and
techniques. mit press.

kooti, farshad, haeryun yang, meeyoung

cha, krishna gummadi, and winter
mason. 2012. the emergence of
conventions in online social networks. in
proceedings of the sixth international aaai
conference on weblogs and social media,
pages 194   201, dublin, ireland.

jurgens, david, stefan dimitrov, and derek

koppel, moshe, shlomo argamon, and

ruths. 2014. twitter users #codeswitch
hashtags! #moltoimportante #wow. in
proceedings of the first workshop on
computational approaches to code switching,
pages 51   61, doha, qatar.

kershaw, daniel, matthew rowe, and

patrick stacey. 2016. towards modelling
language innovation acceptance in online
social networks. in proceedings of the ninth
acm international conference on web search
and data mining, pages 553   562, san
francisco, ca, usa.

kim, suin, ingmar weber, li wei, and alice

oh. 2014. sociolinguistic analysis of
twitter in multilingual societies. in
proceedings of the 25th acm conference on
hypertext and social media, pages 243   248,
santiago, chile.

king, ben and steven abney. 2013. labeling
the languages of words in mixed-language

anat rachel shimoni. 2002. automatically
categorizing written texts by author
gender. literary and linguistic computing,
17(4):401   412.

krippendorff, klaus, 2013. content analysis:
an introduction to its methodology, chapter
validity. sage publications.

krishnan, vinodh and jacob eisenstein. 2015.

   you   re mr. lebowski, i   m the dude   :
inducing address term formality in signed
social networks. in proceedings of the 2015
conference of the north american chapter of
the association for computational linguistics:
human language technologies, pages
1616   1626, denver, colorado.

labov, william. 1966. the social strati   cation of
english in new york city. washington, d.c.:
center for applied linguistics.

labov, william. 1972. sociolinguistic patterns.
philadelphia: university of pennsylvania

49

computational linguistics

to appear

press.

labov, william. 1994. principles of linguistic

change, volume i, internal factors.
wiley-blackwell.

labov, william. 2001. principles of linguistic

change, volume ii, social factors.
wiley-blackwell.

lazer, david, alex sandy pentland, lada

adamic, sinan aral, albert laszlo
barabasi, devon brewer, nicholas
christakis, noshir contractor, james
fowler, myron gutmann, tony jebara,
gary king, michael macy, deb roy, and
marshall van alstyne. 2009. life in the
network: the coming age of computational
social science. science, 323(5915):721   723.
lee, david y.w. 2001. genres, registers, text
types, domains and styles: clarifying the
concepts and navigating a path through
the bnc jungle. language learning &
technology, 5(3):37   72.

leemann, adrian, marie-jos   kolly, ross

purves, david britain, and elvira glaser.
2016. id104 language change
with smartphone applications. plos one,
11(1).

leskovec, jure, daniel huttenlocher, and jon
kleinberg. 2010. signed networks in social
media. in proceedings of the sigchi
conference on human factors in computing
systems, pages 1361   1370, atlanta, ga,
usa.

levinson, stephen c. 1983. pragmatics.

cambridge university press.

levitan, rivka, agustin gravano, and julia
hirschberg. 2011. entrainment in speech
preceding backchannels. in proceedings of
the 49th annual meeting of the association for
computational linguistics: human language
technologies, pages 113   117, portland,
oregon, usa.

li, ying and pascale fung. 2012. code-switch
language model with inversion constraints
for mixed language id103. in
proceedings of coling 2012: technical
papers, pages 1671   1680, mumbai, india.

liao, lizi, jing jiang, ying ding, heyan

huang, and ee-peng lim. 2014. lifetime
lexical variation in social media. in
proceedings of the twenty-eighth aaai
conference on arti   cial intelligence, pages
1643   1649, qu  bec city, qu  bec, canada.
ling, wang, guang xiang, chris dyer, alan

black, and isabel trancoso. 2013.
microblogs as parallel corpora. in
proceedings of the 51st annual meeting of the
association for computational linguistics
(volume 1: long papers), pages 176   186,
so   a, bulgaria.

50

lui, marco, jey han lau, and timothy

baldwin. 2014. automatic detection and
language identi   cation of multilingual
documents. transactions of the association
for computational linguistics, 2(1):27   40.

makatchev, maxim and reid simmons. 2011.
perception of personality and naturalness
through dialogues by native speakers of
american english and arabic. in
proceedings of the sigdial 2011 conference,
pages 286   293, portland, oregon.

mallinson, christine, becky childs, and
gerard van herk, editors. 2013. data
collection in sociolinguistics: methods and
applications. routledge.

mann, william c. and sandra a. thompson.
1988. rhetorical structure theory: toward a
functional theory of text organization. text,
8(3):243   281.

manning, christopher d. 2015.

computational linguistics and deep
learning. computational linguistics,
41(4):701   707.

martin, james r. and david rose. 2003.

working with discourse: meaning beyond the
clause. continuum.

martin, james r. and peter r. r. white. 2005.

the language of evaluation: appraisal in
english. palgrave macmillan.

marwick, alice e. and danah boyd. 2011. i

tweet honestly, i tweet passionately:
twitter users, context collapse, and the
imagined audience. new media & society,
13(1):114   133.

may   eld, elijah, m. barton laws, ira b .

wilson, and carolyn p. ros  . 2014.
automating annotation of
information-giving for analysis of clinical
conversation. journal of the american
medical informatics association,
21(1):122   128.

mcnamee, paul. 2005. language

identi   cation: a solved problem suitable
for undergraduate instruction. journal of
computing sciences in colleges, 20(3):94   101.

meyerhoff, miriam. 2011. introducing

sociolinguistics. routledge.

michael, loizos and jahna otterbacher. 2014.
write like i write: herding in the language
of online reviews. in proceedings of the
eighth international aaai conference on
weblogs and social media, pages 356   365,
ann arbor, michigan, usa.

mikolov, tomas, kai chen, greg corrado,

and jeffrey dean. 2013. ef   cient estimation
of word representations in vector space. in
proceedings of iclr workshop.

milroy, james and lesley milroy, 1978.

belfast: change and variation in an urban

nguyen et al.

computational sociolinguistics: a survey

vernacular, pages 19   36.

milroy, james and lesley milroy. 1985.

linguistic change, social network and
speaker innovation. journal of linguistics,
21(2):339   384.

milroy, lesley and matthew gordon. 2003.
sociolinguistics: method and interpretation.
wiley-blackwell.

mislove, alan, sune lehmann, yong-yeol
ahn, jukka-pekka onnela, and j. niels
rosenquist. 2011. understanding the
demographics of twitter users. in
proceedings of the fifth international aaai
conference on weblogs and social media,
pages 554   557, barcelona, catalonia,
spain.

mocanu, delia, andrea baronchelli, nicola
perra, bruno gon  alves, qian zhang, and
alessandro vespignani. 2013. the twitter
of babel: mapping world languages
through microblogging platforms. plos
one, 8(4):e61981.

morrow, raymond a. and david d. brown,

1994. contemporary social theory: critical
theory and methodology, chapter
deconstructing the conventional
discourse of methodology: quantitative
versus qualitative methods. sage
publications.

mubarak, hamdy and kareem darwish.

2014. using twitter to collect a
multi-dialectal corpus of arabic. in
proceedings of the emnlp 2014 workshop on
arabic natural language processing (anlp),
pages 1   7, doha, qatar.

mukherjee, arjun and bing liu. 2010.

improving gender classi   cation of blog
authors. in proceedings of the 2010 conference
on empirical methods in natural language
processing, pages 207   217, cambridge,
ma.

myers-scotton, carol. 1995. social motivations

for codeswitching: evidence from africa.
oxford: clarendon.

myers-scotton, carol. 2002. contact
linguistics: bilingual encounters and
grammatical outcomes. oxford: oxford
university press.

nerbonne, john. 2009. data-driven

dialectology. language and linguistics
compass, 3(1):175   198.

nerbonne, john and martijn wieling. 2015.

statistics for aggregate variationist
analyses. in charles boberg, john
nerbonne, and dominic watt, editors,
handbook of dialectology. boston: wiley.

nguyen, dong and a. seza do   gru  z. 2013.

word level language identi   cation in
online multilingual communication. in

proceedings of the 2013 conference on
empirical methods in natural language
processing, pages 857   862, seattle,
washington, usa.

nguyen, dong, rilana gravel, dolf

trieschnigg, and theo meder. 2013.    how
old do you think i am?" a study of
language and age in twitter. in proceedings
of the seventh international aaai conference
on weblogs and social media, pages 439   448,
boston, massachusetts, usa.

nguyen, dong and carolyn p. ros  . 2011.

language use as a re   ection of
socialization in online communities. in
proceedings of the workshop on language in
social media (lsm 2011), pages 76   85,
portland, oregon.

nguyen, dong, noah a. smith, and
carolyn p. ros  . 2011. author age
prediction from text using linear
regression. in proceedings of the 5th
acl-hlt workshop on language technology
for cultural heritage, social sciences, and
humanities, pages 115   123, portland,
oregon.

nguyen, dong, dolf trieschnigg, and leonie

cornips. 2015. audience and the use of
minority languages on twitter. in
proceedings of the ninth international aaai
conference on web and social media, pages
666   669, oxford, united kingdom.

nguyen, dong, dolf trieschnigg, a. seza

do   gru  z, rilana gravel, mari  t theune,
theo meder, and franciska de jong. 2014.
why gender and age prediction from
tweets is hard: lessons from a
id104 experiment. in proceedings
of coling 2014, the 25th international
conference on computational linguistics:
technical papers, pages 1950   1961, dublin,
ireland.

nguyen, dong, dolf trieschnigg, and theo
meder. 2014. tweetgenie: development,
evaluation, and lessons learned. in
proceedings of coling 2014, the 25th
international conference on computational
linguistics: system demonstrations, pages
62   66, dublin, ireland.

nguyen, viet-an, jordan boyd-graber,

philip resnik, deborah a. cai, jennifer e.
midberry, and yuanxin wang. 2014.
modeling topic control to detect in   uence
in conversations using nonparametric
topic models. machine learning,
95(3):381   421.

niederhoffer, kate g. and james w.
pennebaker. 2002. linguistic style
matching in social interaction. journal of
language and social psychology,

51

computational linguistics

to appear

21(4):337   360.

glasgow, uk.

noble, bill and raquel fern  ndez. 2015.

peirsman, yves, dirk geeraerts, and dirk

centre stage: how social network position
shapes linguistic coordination. in
proceedings of the 6th workshop on cognitive
modeling and computational linguistics,
pages 29   38, denver, colorado.

nowson, scott and jon oberlander. 2006. the
identity of bloggers: openness and gender
in personal weblogs. in aaai spring
symposium: computational approaches to
analyzing weblogs, pages 163   167, palo
alto, california.

nowson, scott, jon oberlander, and

alastair j. gill. 2005. weblogs, genres and
individual differences. in proceedings of the
27th annual conference of the cognitive
science society, pages 1666   1671, stresa,
italy.

otterbacher, jahna. 2010. inferring gender of
movie reviewers: exploiting writing style,
content and metadata. in proceedings of the
19th acm international conference on
information and knowledge management,
pages 369   378, toronto, on, canada.

paolillo, john c. 2001. language variation on

internet relay chat: a social network
approach. journal of sociolinguistics,
5(2):180   213.

papalexakis, evangelos e., dong nguyen,

and a. seza do   gru  z. 2014. predicting
code-switching in multilingual
communication for immigrant
communities. in proceedings of the first
workshop on computational approaches to
code switching, pages 42   50, doha, qatar.

pavalanathan, umashanthi and jacob

eisenstein. 2015a. audience-modulated
variation in online social media. american
speech, 90(2):187   213.

pavalanathan, umashanthi and jacob

eisenstein. 2015b. confounds and
consequences in geotagged twitter data.
in proceedings of the 2015 conference on
empirical methods in natural language
processing, pages 2138   2148, lisbon,
portugal.

pechenick, eitan adam, christopher m.

danforth, and peter sheridan dodds. 2015.
characterizing the google books corpus:
strong limits to id136s of socio-cultural
and linguistic evolution. plos one,
10(10):1   24.

peersman, claudia, walter daelemans, and
leona van vaerenbergh. 2011. predicting
age and gender in online social networks.
in proceedings of the 3rd international
workshop on search and mining user-generated
contents (smuc    11), pages 37   44,

52

speelman. 2010. the automatic
identi   cation of lexical variation between
language varieties. natural language
engineering, 16(04):469   491.

peng, nanyun, yiming wang, and mark

dredze. 2014. learning polylingual topic
models from code-switched social media
documents. in proceedings of the 52nd
annual meeting of the association for
computational linguistics (volume 2: short
papers), pages 674   679, baltimore,
maryland.

pennacchiotti, marco and ana-maria
popescu. 2011. a machine learning
approach to twitter user classi   cation. in
proceedings of the fifth international aaai
conference on weblogs and social media,
pages 281   288, barcelona, spain.

pennebaker, james w., martha e. francis,

and roger j. booth. 2001. linguistic
inquiry and word count: liwc 2001.
mahwah, nj: lawrence erlbaum.

peterson, kelly, matt hohensee, and fei xia.
2011. email formality in the workplace: a
case study on the enron corpus. in
proceedings of the workshop on language in
social media (lsm 2011), pages 86   95,
portland, oregon.

pfeffer, jeffrey and gerald r. salancik. 1978.

the external control of organizations: a
resource dependence perspective. new york:
harper & row.

piergallini, mario, seza a. do   gru  z, phani
gadde, david adamson, and carolyn p.
ros  . 2014. modeling the use of graf   ti
style features to signal social relations
within a multi-domain learning paradigm.
in proceedings of the 14th conference of the
european chapter of the association for
computational linguistics, pages 107   115,
gothenburg, sweden.

piotrowski, michael. 2012. natural language

processing for historical texts. synthesis
lectures on human language technologies.

poplack, shana, david sankoff, and

christopher miller. 1988. the social
correlates and linguistic processes of
lexical borrowing and assimilation.
linguistics, 26(1):47   104.

postmes, tom, russell spears, and martin

lea. 2000. the formation of group norms
in computer-mediated communication.
human communication research,
26(3):341   371.

prabhakaran, vinodkumar, ashima arora,

and owen rambow. 2014. staying on
topic: an indicator of power in political

nguyen et al.

computational sociolinguistics: a survey

debates. in proceedings of the 2014
conference on empirical methods in natural
language processing (emnlp), pages
1481   1486, doha, qatar.

prabhakaran, vinodkumar, ajita john, and
dor  e d. seligmann. 2013. who had the
upper hand? ranking participants of
interactions based on their relative power.
in proceedings of the sixth international joint
conference on natural language processing,
pages 365   373, nagoya, japan.

prabhakaran, vinodkumar and owen

rambow. 2013. written dialog and social
power: manifestations of different types of
power in dialog behavior. in proceedings of
the sixth international joint conference on
natural language processing, pages
216   224, nagoya, japan.

prabhakaran, vinodkumar, owen rambow,

and mona diab. 2012a. predicting overt
display of power in written dialogs. in
proceedings of the 2012 conference of the
north american chapter of the association for
computational linguistics: human language
technologies, pages 518   522, montr  al,
canada.

prabhakaran, vinodkumar, owen rambow,
and mona diab. 2012b. who   s (really) the
boss? perception of situational power in
written interactions. in proceedings of
coling 2012, pages 2259   2274, mumbai,
india.

prabhakaran, vinodkumar, emily e. reid,

and owen rambow. 2014. gender and
power: how gender and gender
environment affect manifestations of
power. in proceedings of the 2014 conference
on empirical methods in natural language
processing (emnlp), pages 1965   1976,
doha, qatar.

prager, john m. 1999. linguini: language

identi   cation for multilingual documents.
in proceedings of the 32nd annual hawaii
international conference on systems sciences,
maui, hi, usa.

preo  tiuc-pietro, daniel, vasileios lampos,

and nikolaos aletras. 2015. an analysis of
the user occupational class through twitter
content. in proceedings of the 53rd annual
meeting of the association for computational
linguistics and the 7th international joint
conference on natural language processing
(volume 1: long papers), pages 1754   1764,
beijing, china.

preo  tiuc-pietro, daniel, svitlana volkova,
vasileios lampos, yoram bachrach, and
nikolaos aletras. 2015. studying user
income through language, behaviour and
affect in social media. plos one, 10(9).

proki  c, jelena,   a   gr       ltekin, and john

nerbonne. 2012. detecting shibboleths. in
proceedings of the eacl 2012 joint workshop
of lingvis & unclh, pages 72   80,
avignon, france.

quercia, daniele, jonathan ellis, licia capra,

and jon crowcroft. 2011. in the mood for
being in   uential on twitter. in proceedings
of the 3rd ieee international conference on
social computing, pages 307     314, boston,
ma.

rabe-hesketh, sophia and anders skrondal.

2012. multilevel and longitudinal modeling
using stata. stata press.

rabe-hesketh, sophia, anders skrondal, and
andrew pickles. 2004. gllamm manual.
u.c. berkeley division of biostatistics
working paper series, paper 160.

raghavan, sindhu, adriana kovashka, and

raymond mooney. 2010. authorship
attribution using probabilistic context-free
grammars. in proceedings of the acl 2010
conference short papers, pages 38   42,
uppsala, sweden.

rangel, francisco, paolo rosso, irina

chugur, martin potthast, martin
trenkmann, benno stein, ben verhoeven,
and walter daelemans. 2014. overview of
the 2nd author pro   ling task at pan 2014.
in clef 2014 evaluation labs and workshop
    working notes papers.

rangel, francisco, paolo rosso, moshe

koppel, efstathios stamatatos, and
giacomo inches. 2013. overview of the
author pro   ling task at pan 2013. notebook
papers of clef.

rao, delip, michael j. paul, clayton fink,

david yarowsky, timothy oates, and glen
coppersmith. 2011. hierarchical bayesian
models for latent attribute detection in
social media. in proceedings of the fifth
international aaai conference on weblogs
and social media, pages 598   601, barcelona,
spain.

rao, delip, david yarowsky, abhishek
shreevats, and manaswi gupta. 2010.
classifying latent user attributes in
twitter. in proceedings of the 2nd
international workshop on search and mining
user-generated contents (smuc    10), pages
37   44, toronto , on, canada.

ribeiro, branca telles. 2006. footing,

positioning, voice. are we talking about the
same things? in anna de fina, deborah
schiffrin, and michael bamberg, editors,
discourse and identity. cambridge
university press, pages 48   82.

richards, keith. 2006. language and

professional identity: aspects of collaborative

53

computational linguistics

to appear

interaction. palgrave macmillan.

romaine, suzanne. 1995. bilingualism (2nd
edition). malden, ma: blackwell publishers.

ros  , carolyn p., in press. international

handbook of the learning sciences, chapter
learning analytics in the learning
sciences. taylor & francis.

ros  , carolyn p. and alla tovares, 2015.

socializing intelligence through academic
talk and dialogue, chapter what
sociolinguistics and machine learning have
to say to one another about interaction
analysis. washington, dc: american
educational research association.

ros  , carolyn p., yi-chia wang, yue cui,

jaime arguello, karsten stegmann, armin
weinberger, and frank fischer. 2008.
analyzing collaborative learning processes
automatically: exploiting the advances of
computational linguistics in
computer-supported collaborative
learning. international journal of
computer-supported collaborative learning,
3(3):237   271.

2010 conference on empirical methods in
natural language processing, pages
1151   1161, cambridge, ma.

schler, jonathan, moshe koppel, shlomo

argamon, and james w. pennebaker. 2006.
effects of age and gender on blogging. in
proceedings of aaai spring symposium on
computational approaches to analyzing
weblogs, pages 199   205, menlo park,
california.

schneider, gerold, james dowdall, and fabio

rinaldi. 2004. a robust and hybrid
deep-linguistic theory applied to
large-scale parsing. in proceedings of the 3rd
workshop on robust methods in analysis of
natural language data (romand 2004),
pages 14   23, geneva, switzerland.

schuller, bj  rn, stefan steidl, anton batliner,

felix burkhardt, laurence devillers,
christian m  ller, and shrikanth
narayanan. 2010. the interspeech
2010 paralinguistic challenge. in
interspeech, pages 2794   2797,
makuhari, chiba, japan.

rosenthal, sara and kathleen mckeown.

schwartz, h. andrew, johannes c.

2011. age prediction in blogs: a study of
style, content, and online behavior in pre-
and post-social media generations. in
proceedings of the 49th annual meeting of the
association for computational linguistics:
human language technologies, pages
763   772, portland, oregon.

sankoff, gillian, 2006. encyclopedia of

language and linguistics, chapter age:
apparent time and real time. amsterdam:
elsevier.

sap, maarten, gregory park, johannes

eichstaedt, margaret kern, david stillwell,
michal kosinski, lyle ungar, and
andrew hansen schwartz. 2014.
developing age and gender predictive
lexica over social media. in proceedings of
the 2014 conference on empirical methods in
natural language processing (emnlp),
pages 1146   1151, doha, qatar.

sarawgi, ruchita, kailash gajulapalli, and

yejin choi. 2011. gender attribution:
tracing stylometric evidence beyond topic
and genre. in proceedings of the fifteenth
conference on computational natural
language learning, pages 78   86, portland,
oregon, usa.

schegloff, emanuel a. 2007. sequence

organization in interaction: a primer in
conversation analysis, volume 1.
cambridge university press.

scherrer, yves and owen rambow. 2010.
word-based dialect identi   cation with
georeferenced rules. in proceedings of the

54

eichstaedt, margaret l. kern, lukasz
dziurzynski, stephanie m. ramones,
megha agrawal, achal shah, michal
kosinski, david stillwell, martin e. p.
seligman, and lyle h. ungar. 2013.
personality, gender, and age in the
language of social media: the
open-vocabulary approach. plos one,
8(9):e73791.

scissors, lauren e., alastair j. gill, kathleen

geraghty, and darren gergle. 2009. in
cmc we trust: the role of similarity. in
proceedings of the sigchi conference on
human factors in computing systems (chi
   09), pages 527   536, boston, ma, usa.

searle, john r. 1969. speech acts: an essay in

the philosophy of language. cambridge:
cambridge university press.

singh, sameer. 2001. a pilot study on gender

differences in conversational speech on
lexical richness measures. literary and
linguistic computing, 16(3):251   264.

sloan, luke, jeffrey morgan, pete burnap,

and matthew williams. 2015. who tweets?
deriving the demographic characteristics
of age, occupation and social class from
twitter user meta-data. plos one, 10(3).
snow, david a. and leon anderson. 1987.
identity work among the homeless: the
verbal construction and avowal of
personal identities. american journal of
sociology, 92(6):1336   1371.

snow, rion, brendan o   connor, daniel

jurafsky, and andrew y. ng. 2008. cheap

nguyen et al.

computational sociolinguistics: a survey

and fast   but is it good?: evaluating
non-expert annotations for natural
language tasks. in proceedings of the 2008
conference on empirical methods in natural
language processing, pages 254   263,
honolulu, hawaii.

soliz, jordan and howard giles. 2014.
relational and identity processes in
communication: a contextual and
meta-analytical review of communication
accommodation theory. in elisia l.
cohen, editor, communication yearbook 38.
routledge.

solorio, thamar, elizabeth blair, suraj

maharjan, steven bethard, mona diab,
mahmoud ghoneim, abdelati hawwari,
fahad alghamdi, julia hirschberg, alison
chang, and pascale fung. 2014. overview
for the    rst shared task on language
identi   cation in code-switched data. in
proceedings of the first workshop on
computational approaches to code switching,
pages 62   72, doha, qatar.

solorio, thamar and yang liu. 2008a.

learning to predict code-switching points.
in proceedings of the 2008 conference on
empirical methods in natural language
processing, pages 973   981, honolulu,
hawaii.

solorio, thamar and yang liu. 2008b.

part-of-speech tagging for english-spanish
code-switched text. in proceedings of the
2008 conference on empirical methods in
natural language processing, pages
1051   1060, honolulu, hawaii.

stamatatos, efstathios. 2009. a survey of

modern authorship attribution methods.
journal of the american society for
information science and technology,
60(3):538   556.

stoop, wessel and antal van den bosch.
2014. using idiolects and sociolects to
improve word prediction. in proceedings of
the 14th conference of the european chapter of
the association for computational linguistics,
pages 318   327, gothenburg, sweden.

strzalkowski, tomek, samira shaikh, ting

liu, george aaron broadwell, jenny
stromer-galley, sarah taylor, umit boz,
veena ravishankar, and xiaoai ren. 2012.
modeling leadership and in   uence in
multi-party online discourse. in
proceedings of coling 2012, pages
2535   2552, mumbai, india.

swayamdipta, swabha and owen rambow.

2012. the pursuit of power and its
manifestation in written dialog. in
proceedings of 2012 ieee sixth international
conference on semantic computing (icsc),

pages 22   29, palermo, italy.

taboada, maite and william c. mann. 2006.

applications of rhetorical structure
theory. discourse studies, 8(4):567   588.

tagliamonte, sali a. 2006. analysing
sociolinguistic variation. cambridge
university press.

tam, jenny and craig h. martell. 2009. age

detection in chat. in icsc    09. ieee
international conference on semantic
computing, pages 33   39, berkeley, ca.

tannen, deborah. 1990. you just don   t

understand: women and men in conversation.
ballantine books.

tannen, deborah. 1993. framing in discourse.

oxford university press.

thomason, sarah g. 2001. language contact:

an introduction. edinburgh: edinburgh
university press.

trieschnigg, dolf, djoerd hiemstra, mari  t
theune, franciska jong, and theo meder.
2012. an exploration of language
identi   cation techniques for the dutch
folktale database. in proceedings of the
workshop on adaptation of language
resources and tools for processing cultural
heritage, pages 47   51, istanbul, turkey.

trudgill, peter. 1974. the social differentiation

of english in norwich. cambridge:
cambridge university press.

trudgill, peter. 2003. the norfolk dialect.

norfolk origins 7. poppyland publishing.
truong, khiet p., gerben j. westerhof, sanne
m. a. lamers, and franciska de jong. 2014.
towards modeling expressed emotions in
oral history interviews: using verbal and
nonverbal signals to track personal
narratives. literary and linguistic
computing, 29(4):621   636.

tsaliki, liza. 2003. globalization and

hybridity: the construction of greekness
on the internet. in karim haiderali karim,
editor, the media of diaspora. routledge.

van durme, benjamin. 2012. streaming
analysis of discourse participants. in
proceedings of the 2012 joint conference on
empirical methods in natural language
processing and computational natural
language learning, pages 48   58, jeju
island, korea.

volkova, svitlana, theresa wilson, and

david yarowsky. 2013. exploring
demographic language variations to
improve multilingual id31
in social media. in proceedings of the 2013
conference on empirical methods in natural
language processing, pages 1815   1827,
seattle, washington, usa.

55

computational linguistics

to appear

voss, clare, stephen tratz, jamal laoudi, and
douglas briesch. 2014. finding romanized
arabic dialect in code-mixed tweets. in
proceedings of the ninth international
conference on language resources and
evaluation (lrec-2014), pages 2249   2253,
reykjavik, iceland.

vyas, yogarshi, spandana gella, jatin

sharma, kalika bali, and monojit
choudhury. 2014. id52 of
english-hindi code-mixed social media
content. in proceedings of the 2014
conference on empirical methods in natural
language processing (emnlp), pages
974   979, doha, qatar.

wagner, suzanne e. 2012. age grading in

sociolinguistic theory. language and
linguistics compass, 6(6):371   382.

wang, yafei, david reitter, and john yen.

2014. linguistic adaptation in conversation
threads: analyzing alignment in online
health communities. in proceedings of the
2014 acl workshop on cognitive modeling
and computational linguistics, pages 55   62,
baltimore, maryland, usa.

wardhaugh, ronald. 2011. an introduction to

sociolinguistics. wiley-blackwell.

wei, li. 1998. the    why    and    how    questions

in the analysis of conversational
codeswitching. in peter auer, editor,
codeswitching in conversation: language,
interaction and identity. london: routledge,
pages 156   176.

weinreich, uriel. 1953. languages in contact.

   ndings and problems. new york,
linguistic circle of new york.

weinreich, uriel, william labov, and
marvin i. herzog. 1968. empirical
foundations for a theory of language
change. in winfred p. lehmann and yakov
malkiel, editors, directions for historical
linguistics: a symposium. austin:
university of texas press, pages 95   188.
wen, miaomiao, diyi yang, and carolyn p.

ros  . 2014a. linguistic re   ections of
student engagement in massive open
online courses. in proceedings of the eighth
international aaai conference on weblogs
and social media, pages 525   534, ann
arbor, michigan, usa.

person-to-person id31.
transactions of the association of
computational linguistics     volume 2, issue
1, pages 297   310.

wieling, martijn, jelke bloem, kaitlin

mignella, mona timmermeister, and john
nerbonne. 2014. measuring foreign accent
strength in english. language dynamics and
change, 4(2):253   269.

wieling, martijn and john nerbonne. 2010.

hierarchical spectral partitioning of
bipartite graphs to cluster dialects and
identify distinguishing features. in
proceedings of textgraphs-5 - 2010 workshop
on graph-based methods for natural language
processing, pages 33   41, uppsala, sweden.

wieling, martijn and john nerbonne. 2015.

advances in dialectometry. annual review
of linguistics, 1(1):243   264.

wiersma, wybo, john nerbonne, and timo

lauttamus. 2010. automatically extracting
typical syntactic differences from corpora.
literary and linguistic computing,
26(1):107   124.

wing, benjamin p. and jason baldridge. 2011.

simple supervised document geolocation
with geodesic grids. in proceedings of the
49th annual meeting of the association for
computational linguistics: human language
technologies, pages 955   964, portland,
oregon, usa.

wintner, shuly. 2002. formal language

theory for natural language processing. in
proceedings of the acl-02 workshop on
effective tools and methodologies for teaching
natural language processing and
computational linguistics, pages 71   76,
philadelphia, pa.

yamaguchi, hiroshi and kumiko

tanaka-ishii. 2012. text segmentation by
language using minimum description
length. in proceedings of the 50th annual
meeting of the association for computational
linguistics (volume 1: long papers), pages
969   978, jeju island, korea.

yan, xiang and ling yan. 2006. gender

classi   cation of weblog authors. in aaai
spring symposium: computational
approaches to analyzing weblogs, pages
228   230, palo alto, california.

wen, miaomiao, diyi yang, and carolyn p.

yang, diyi, miaomiao wen, and carolyn p.

ros  . 2014b. id31 in mooc
discussion forums: what does it tell us? in
proceedings of the 7th international
conference on educational data mining,
pages 130   137, london, uk.

west, robert, hristo s. paskov, jure

leskovec, and christopher potts. 2014.
exploiting social network structure for

ros  . 2015. weakly supervised role
identi   cation in teamwork interactions. in
proceedings of the 53rd annual meeting of the
association for computational linguistics and
the 7th international joint conference on
natural language processing (volume 1: long
papers), pages 1671   1680, beijing, china.

56

nguyen et al.

computational sociolinguistics: a survey

zaidan, omar f. and chris callison-burch.

2013. arabic dialect identi   cation.
computational linguistics, 40(1):171   202.
zamal, faiyaz al, wendy liu, and derek

ruths. 2012. homophily and latent
attribute id136: inferring latent
attributes of twitter users from neighbors.
in proceedings of the sixth international
aaai conference on weblogs and social
media, pages 387   390, dublin, ireland.

zampieri, marcos, liling tan, nikola

ljube  i  c, and j  rg tiedemann. 2014. a
report on the dsl shared task 2014. in
proceedings of the first workshop on applying
nlp tools to similar languages, varieties and
dialects, pages 58   67, dublin, ireland.

zampieri, marcos, liling tan, nikola

ljube  i  c, j  rg tiedemann, and preslav
nakov. 2015. overview of the dsl shared
task 2015. in proceedings of the joint
workshop on language technology for closely
related languages, varieties and dialects,
pages 1   9, hissar, bulgaria.

zhang, jian, zoubin ghahramani, and

yiming yang. 2008. flexible latent variable
models for id72. machine
learning, 73(3):221   242.

zijlstra, hanna, henri  t van middendorp,
tanja van meerveld, and rinie geenen.
2005. validiteit van de nederlandse versie
van de linguistic inquiry and word count
(liwc). netherlands journal of psychology,
60(3):55   63.

57

58

