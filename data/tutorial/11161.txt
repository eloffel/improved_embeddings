6
1
0
2

 
r
a

m
6

 

 
 
]
l
c
.
s
c
[
 
 

2
v
1
1
6
3
0

.

9
0
5
1
:
v
i
x
r
a

a parallel corpus of translationese

ella rabinovich, shuly wintner, and ofek luis lewinsohn

1 e. rabinovich, s. wintner

department of computer science, university of haifa.

ellarabi@csweb.haifa.ac.il,

shuly@cs.haifa.ac.il

2 o.l. lewinsohn

department of computational linguistics, universit  at des saarlandes.

o.l.lewinsohn@gmail.com

abstract. we describe a set of bilingual english   french and english   german
parallel corpora in which the direction of translation is accurately and reliably
annotated. the corpora are diverse, consisting of parliamentary proceedings, lit-
erary works, transcriptions of ted talks and political commentary. they will
be instrumental for research of translationese and its applications to (human and
machine) translation; speci   cally, they can be used for the task of translationese
identi   cation, a research direction that enjoys a growing interest in recent years.
to validate the quality and reliability of the corpora, we replicated previous re-
sults of supervised and unsupervised identi   cation of translationese, and further
extended the experiments to additional datasets and languages.

1 introduction

research in all areas of language and linguistics is stimulated by the unprecedented
availability of data. in particular, large text corpora are essential for research of the
unique properties of translationese: the sub-language of translated texts (in any given
language) that is presumably distinctly different from the language of texts originally
written in the same language. indeed, contemporary research in translation studies is
prominently dominated by corpus-based approach [1   9]. most studies of translationese
utilize monolingual comparable corpora, i.e. corpora where translations from multiple
languages into a single language are compared with texts written originally in the target
language.

the unique characteristics of translated language have been traditionally classi   ed
into two categories: properties that stem from the interference of the source language
[10], and universal traits elicited from the translation process itself, regardless of the
speci   c source and target language-pair [1, 11]. computational investigation of trans-
lated texts has been a proli   c    eld of recent research, laying out an empirical foundation
for the theoretically-motivated hypotheses on the characteristics of translationese. more
speci   cally, identi   cation of translated texts by means of automatic classi   cation shed
much light on the manifestation of translation universals and interference phenomena
in translation [12   20].

along the way it was suggested that the unique properties of translationese should
be studied in a parallel setting, i.e., in context of the corresponding source language: the

original language the text was produced in. in particular, several studies hypothesized
that certain phenomena traditionally attributed to translation universals (i.e., source-
language independent) are, in fact, derivatives of the linguistic characteristics of the
speci   c language-pair, subject to translation. [21] investigated the phenomenon of omit-
ting the optional    that    in reporting english verbs, such as    he claimed [that] they left
the room   , highlighting correlation of this behavior to the linguistic conventions in the
source language. [22] raised similar arguments regarding explicitation in translation
(e.g., excessive usage of cohesive devices): he claimed that this phenomenon should
only be studied by comparative analysis of translation and its original counterpart.

parallel setting can also facilitate the task of automatic identi   cation of transla-
tionese. [14] were the    rst to employ bilingual text properties for identi   cation of the
direction of translated parallel texts. they took advantage of sentence pairs translated
in both directions for training a supervised classi   er to identify translationese using
word- and (part-of-speech) pos-ngrams as features. [23] used pos mtu (minimal
translation unit) ngrams and id48 distortion properties extracted from bilingual par-
allel english-french europarl and hansard texts. consecutively, they carried out series
of experiments on sentence-level identi   cation of translationese using brown clusters
[24] mtus on the hansard corpus [25].

a good corpus for research into the properties of translationese, should ideally sat-

isfy the following desiderata:
diversity the corpus should ideally re   ect diverse genres, registers, authors, modality
(written vs. spoken) etc.
parallelism the corpus should include both the source and its translation, so that fea-
tures that are revealed in the translation can be traced back to their origins in the source.
multilinguality having translations from several source languages to the same target
language facilitates a closer inspection of properties that are language-pair-speci   c vs.
more    universal    features of translationese [1, 26, 27, 22].
uniformity whatever processing is done on the texts, it must be done uniformly. this
includes sentence boundary detection, id121, sentence- and word-alignment, pos
tagging, etc.
availability finally, corpora that are used for research must be publicly available so
that other researchers have the opportunity to replicate and corroborate research results.
in this work we describe a set of cross-domain, parallel, uniform, english-french
and english-german corpora that were compiled speci   cally for research on trans-
lationese3. the corpora are diverse, consisting of parliamentary proceedings, literary
works, transcriptions of ted talks and political commentary. we rigorously evaluate
all datasets by series of supervised and unsupervised experiments; sensitivity analysis
further implies applicability of these methodologies to data-meager scenarios. these
datasets will be instrumental for research of translationese and its manifestations; they
will also facilitate accurate identi   cation of translationese at small text units by ex-
ploitation of bilingual text properties.

3 all

corpora

are

available

at

http://cl.haifa.ac.il/projects/

translationese/index.shtml

we detail the structure of the corpus in section 2, explain how it was processed in
section 3, and evaluate it by extending some state-of-the-art supervised and unsuper-
vised experiments in section 4. we conclude with suggestions for future extensions.

2 corpus structure

our corpus of translationese consists of    ve sub-corpora: europarl, canadian hansard,
literature, ted and political commentary.4 all are parallel corpora, with accurate an-
notation indicating the direction of the translation. the datasets are uniformly pre-
processed, represented, and organized. all corpora were further    ltered to contain solely
one-to-one sentence-alignments, which are more useful for the smt research. tables 1
and 2 report some statistical data on the corpus (after id121).

table 1. english-french corpus statistics

# of sentences

# of tokens

# of types

corpus original en original fr total original en original fr original en original fr
73k
eur
han
196k
lit
66k
17k
ted

10,542k
1,379k 6,616k 132,232k 147,463k
2,898k
239k

217k
5,237k
35k
7k

98k 133k
4k
12k

61k
193k
52k
14k

2,875k
217k

130k 347k

9,572k

table 2. english-german corpus statistics

# of sentences

# of tokens

# of types

corpus original en original de total original en original de original en original de
170k
eur
lit
104k
pol
44k

155k 380k
48k 93k
9k 18k

10,067k
2,666k
421k

10,550k
2,854k
443k

225k
45k
8k

63k
56k
26k

2.1 europarl

the europarl sub-corpus is extracted from the collection of the proceedings of the euro-
pean parliament, dating back to 1996, originally collected by [28]. the original corpus5
is organized as several language-pairs, each with multiple sentence-aligned    les. we
mainly used the english-french and english-german segments, but resorted to other
segments as we presently explain. we focus below on the way we generated the english-
french sub-corpus; its english-german counterpart was obtained in a similar way.

4 we use    eur   ,    han   ,    lit   ,    ted    and    pol    to denote the    ve corpora hereafter.
5 the original europarl is available from http://www.statmt.org/europarl/

europarl is probably the most popular parallel corpus in natural language process-
ing, and it was indeed used for many of the translationese tasks surveyed in section 1.
unfortunately, it is a very problematic corpus. first, it consists of transcriptions of spo-
ken utterances that are edited (by the speakers) after they are transcribed; only then
are they translated. consequently, there are signi   cant discrepancies between the actual
speeches and their    verbatim    transcriptions [29]. second, while    members of the eu-
ropean parliament have the right to use any of the eu   s [24] of   cial languages when
speaking in parliament   ,6 many of them prefer to speak in english, which is often not
their native language.7

mainly due to its multilingual nature, however, europarl has been used extensively
in smt [30] and in cross-lingual research [31]. it has even been adapted speci   cally for
research in translation studies: [32] compiled a customized version of europarl, where
the direction of translation is indicated. they used meta-data from the corpus, and in
particular the    language    tag, to identify the original language in which each sentence
was spoken, and removed sentence pairs for which this information was missing. a
similar strategy was used by [33] and [34]. however, relying on the    language    tag
in europarl parallel text for identi   cation of translation direction could be potentially
   awed. next we detail the procedure of reliable extraction of speaker details, including
the original language of each sentence.

the europarl corpus is a collection of several monolingual (parallel) corpora: the
original text was uttered in one language and then translated to several other languages.
in each sub-corpus, each paragraph is annotated with meta-information, in particular,
the original language in which the paragraph was uttered. unfortunately, the meta-
information pertaining to the original language of europarl utterances is frequently
missing. furthermore, in some cases this information is inconsistent: different lan-
guages are indicated as the original languages of (various translations of) the same
paragraph (in the various sub-corpora). additionally, the europarl corpus includes sev-
eral bilingual sub-corpora that are generated from the original and the translated texts,
and are already sentence-aligned. these bilingual corpora include only raw sentence
pairs, with no meta-information.

to minimize the risk of erroneous information, we processed the europarl corpus
as follows. first, we propagated the meta-information from the monolingual texts to the
bilingual sub-corpora: each sentence pair was thus annotated with the original language
in which it was uttered. we repeated this process    ve times, using as the source of meta-
information the original monolingual corpora in    ve languages: english, french, ger-
man, italian, and spanish (note that not all monolingual corpora are identical: some are
much larger than others). for the same reason, not all the english-french sentence pairs
in our bilingual corpus are re   ected in all    ve monolingual corpora, and therefore some
sentence pairs have less than    ve annotations of the original language. we restricted
the bilingual corpus to only those sentence pairs that had    ve annotations. then, we    l-
tered out all sentence pairs whose annotations were inconsistent (about 0.5%). we also

6 http://europa.eu/about-eu/facts-figures/administration/index_

en.htm

7 http://www.theguardian.com/education/datablog/2014/may/21/
european-parliament-english-language-official-debates-data

removed comments (about 0.5% as well), typically written in parentheses (things like
   applause   ,    continuation of the previous session   , etc.) as a result, we are con   dent
that the speaker information (and in particular, the original language of utterances) in
the    ltered corpus is highly accurate.

2.2 the canadian hansard

the hansard corpus is a parallel corpus consisting of transcriptions of the canadian par-
liament in (canadian) english and french from 2001   2009. we used a version that was
annotated with the original language of each parallel sentence. this corpus most likely
suffers from similar problems as the europarl corpus discussed above; indeed, [35], who
investigated the british hansard parliamentary transcripts, found that    the transcripts
omit performance characteristics of spoken language, such as incomplete utterances or
hesitations, as well as any type of extrafactual, contextual talk    and that    transcribers
and editors also alter speakers    lexical and grammatical choices towards more conser-
vative and formal variants.    still, this is the largest available source of english   french
sentence pairs. in addition to parliament members    speech, the original hansard corpus
contains metadata. various annotations were used to discriminate different line types,
including the date of the session, the name of the speaker, etc. we    ltered out all seg-
ments except those referring to speech: in total, about 15% of the corpus line-pairs were
thus eliminated.

2.3 literary classics

our english   french literary corpus consists of classics written and translated in the
18th   20th centuries by english and french writers. most of the raw material is avail-
able from the gutenberg project8 and farkastranslations.9 the english-german lit-
erature corpus was generated in a similar way: we used material from the guten-
berg project, wikisource,10 and a few more books. both english   french and english   
german datasets contain a metadata    le with details about the books: title, year of
publication, translator name and year of translation.

identi   cation of translationese in literary text by means of classi   cation is consid-
ered a more challenging task [36, 37] than classifying more    technical    translations,
such as parliament proceedings. translators of literature typically bene   t from freedom
and fewer constraints, rendering the translated text more similar to original writing.
additionally, our literature span almost three centuries and comprises works from wide
range of genres     traits that overshadow the subtle characteristics of translationese [15,
38, 39, 19]. under this circumstances, we obtain very high accuracy with supervised
classi   cation on this corpus, and moderate, yet reasonable results with unsupervised
id91 (see section 4.3).

8 http://www.gutenberg.org
9 http://farkastranslations.com/
10 http://en.wikisource.org/

2.4 ted talks

our ted corpus is based on the subtitles of the ted talks delivered in english and
translations to english of tedx talks originally given in french11. we used the ted
api12 to extract subtitles of talks delivered in english, and youtube api for tedx talks
originally given in french.

the quality of translation in this corpus is very high: not only are translators as-
sumed to be competent, but the common practice is that each translation passes through
a review before being published. this corpus consists of talks delivered orally, but we
assume that they were meticulously prepared, so the language is not spontaneous but
rather planned. compared to the other sub-corpora, the ted dataset has some unique
characteristics that stem from the following reasons: (i) its size is relatively small; (ii) it
exhibits stylistic disparity between the original and translated texts (the former contains
more    oral    markers of a spoken language, while the latter is a written translation); and
(iii) ted talks are not transcribed but are rather subtitled, so they undergo some edit-
ing and rephrasing. the vast majority of ted talks are publicly available online, which
makes this corpus easily extendable for future research.

2.5 political news and commentary

this corpus contains articles, commentary and analysis on world affairs and interna-
tional relations. english articles and their translations to german were collected from
project syndicate.13 this is a non-pro   t organization that primarily relies on contri-
butions from newspapers in developed countries. it provides original commentaries
by people who are shaping the world   s economics, politics, science and culture. we
collected articles categorized as word affairs from this project, originally written by
english authors and translated to german. original german commentaries and their
translations to english were collected from the diplomatics magazine,14 speci   cally,
from its international relations section.

3 processing

the original europarl corpora are already sentence-aligned, using an implementation
of the gale and church sentence-alignment algorithm [40]. since the alignment was
done for one source paragraph at a time (typically consisting of few sentences), its
quality is very high. the same also holds for the hansard corpus, so we used the original
alignments for both sub-corpora. we then    ltered out any alignments that were not one-
to-one; this resulted in a loss of about 3% of the alignments in europarl, and only 2%
in hansard.

11 tedx are ted-like events not restricted to speci   c language. we could not    nd suf   cient

amount of tedx german talks translated to english.

12 http://developer.ted.com/
13 http://www.project-syndicate.org/
14 http://www.diplomatisches-magazin.de/

the literary sub-corpus required more careful attention. books that were acquired
from farkastranslations.com were available pre-aligned at the chapter- and
paragraph-level; we therefore sentence-aligned them, one paragraph at a time, using a
python implementation [41] of the gale and church algorithm. for the remainder of the
books, we    rst extracted chapters by (manually) identifying characteristic chapter titles
(e.g., roman numerals, explicit    chapter n   ). paragraph boundaries within a chapter
are typically marked by a double newline in gutenberg transcripts, and we used this
pattern to break chapters into paragraphs. due to the fact that the gale-church algorithm
only utilizes text length for alignment, it can be easily re   ned for aligning other logical
units, e.g., paragraphs [40]. finally, we aligned sentences within paragraphs using the
same algorithm.

the genre of the literature sub-corpus is very different (presumably due to trans-
lators taking greater liberty), hence restricting the dataset to include only one-to-one
sentence-alignments resulted in loss of above 10% of each book.

sentence-alignment of subtitles of ted talks originally delivered in french (and
translated to english) involved synchronization of subtitle frames. a typical frame in a
subtitles (.srt)    le contains frame start and end time (including milliseconds), as well as
frame text:

frame sequential number
18
frame start and end time
00:00:47,497 --> 00:00:50,813
cet engagement, je pense que j   ai fait le choix frame text

first, we re-organized the subtitles    le to contain (longer) frames that start and end
on a sentence boundary; we achieved this by concatenating frames until a sentence ter-
mination punctuation symbol is reached. this procedure was conducted on both french
subtitles and their corresponding english translations. then, we aligned the english   
french parallel    les at paragraph-level by alternated concatenation of paragraphs until
synchronization of frame end time (up to a    threshold that was    xed to 500 millisec-
onds) on the english and french sides. the paragraph-alignment procedure pseudo-
code is detailed in algorithm 1.

we further aligned the paragraph-aligned ted and tedx corpora at the sentence-
level using the same sentence-alignment procedure [40]. ted talks tend to vary greatly
in terms of sentence alignments (one-to-one, one-to-many, many-to-one, many-to-many).
on average, approximately 10% of the alignments are not one-to-one; those were    l-
tered out as well.

4 evaluation

to validate the quality of the corpus we replicated the experiments of [18], who con-
ducted a thorough exploration of supervised classi   cation of translationese, using dozens
of feature types. while [18] only used the europarl corpus (in its original format)
and worked on english translated from french, we extended the experiments to all

algorithm 1 ted subtitles paragraph-alignment algorithm

comment: l paragraphs and r paragraphs are (not necessarily equal length) arrays of text
paragraphs for alignment, from the left and right sides, respectively
   = 500 milliseconds
subtitles paragraph alignment(1,1)
procedure subtitles paragraph alignment(l count,r count)

    threshold controlling the allowed delta in aligned frames    end time
    initial invocation assuming the arrays start from 1

if (l count > l paragraphs.length) and (r count > r paragraphs.length) then

return

end if
if (l count > l paragraphs.length) then

output r paragraphs[r count:r paragraphs.length]     remainder of the right side
return

end if
if (r count > r paragraphs.length) then

output l paragraphs[l count:l paragraphs.length]
return

    remainder of the left side

end if
l current = l paragraphs[l count].f rame content
l f rame end = l paragraphs[l count].f rame end
r current = r paragraphs[r count].f rame content
r f rame end = r paragraphs[r count].f rame end
while (|l f rame end     r f rame end| >    and (l count < l paragraphs.length)

and (r count < r paragraphs.length)) do
if (l f rame end > r f rame end) then

    advance on the right side

r count += 1; r current += r paragraphs[r count].f rame content
r f rame end = r paragraphs[r count].f rame end

else

    advance on the left side

l count += 1; l current += l paragraphs[l count].f rame content
l f rame end = l paragraphs[l count].f rame end

end if
end while
output    aligned paragraph pair:   , l current, r current
subtitles paragraph alignment(l count+1,r count+1)

end procedure

    recursive invocation

the datasets described above, including also english translated from german, as well
as french and german translations from english. we show that in-domain classi   ca-
tion (with ten-fold cross-validation evaluation) yields excellent results. moreover, very
good results are obtained using unsupervised classi   cation, implying robustness of this
methodology and its applicability to various domains and languages.

4.1 preprocessing and tools

the (tokenized) datasets were split into chunks of approximately 2000 tokens, respect-
ing sentence boundaries and preserving punctuation. we assume that translationese fea-
tures are present in the texts or speeches across author, genre or native language, thus

we allow some chunks to contain linguistic information from two or more different
speakers simultaneously. the frequency-based features are normalized by the number
of tokens in each chunk. for id52, we employ the stanford implementation
along with its models for english, french and german [42].

we use platt   s sequential minimal optimization algorithm [43] to train a support
vector machine classi   er with the default linear kernel, an implementation freely avail-
able in weka [44]. in all classi   cation experiments we use (the maximal) equal number
of chunks from each class: original (o) and translated (t).

4.2 features

the    rst feature set we utilized for classi   cation tasks comprises function words (fw),
probably the most popular choice ever since [45] used it successfully for the federal-
ist papers. function words proved to be suitable features for multiple reasons:(i) they
abstract away from contents and are therefore less biased by topic; (ii) their frequency
is so high that by and large they are assumed to be selected unconsciously by authors;
(iii) although not easily interpretable, they are assumed to re   ect grammar, and there-
fore facilitate the study of how structures are carried over from one language to another.
we used the list of above 400 english function words provided in [15], and similar
number of french and german function words.15

a more informative way to represent (admittedly shallow) syntax is to use part-of-
speech (pos) trigrams. triplets such as pp (personal pronoun) + vhz (verb    have   ,
3rd person sing. present) + vbn (verb    be   , past participle) re   ect a complex tense
form, represented distinctively across languages. in europarl, for example, this triplet
is highly frequent in translations from finnish and danish and much rarer in translations
from portuguese and greek.

we also used positional token frequency [46]. the feature is de   ned as counts of
words occupying the    rst, second, third, penultimate and last positions in a sentence.
the motivation behind this feature is that sentences open and close differently across
languages, and it should be expected that these opening and closing devices will be
transferred from the source if they do not violate the grammaticality of the target lan-
guage. positional tokens were previously used for translationese identi   cation [18] and
for native language detection [47].

finally, we experimented with contextual function words. contextual fw are a vari-
ation of pos trigrams where a trigram can be anchored by speci   c function words:
these are consecutive triplets hw1,w2,w3i where at least two of the elements are func-
tion words, and at most one is a pos tag.

pos-trigrams, positional tokens and contextual-fw-trigrams are calculated as de-
tailed in [18], but we only considered the 1000 most frequent feature values extracted
from each dataset.

15 the list of french and german fw was downloaded from https://code.google.com/

archive/p/stop-words/.

4.3 results

supervised identi   cation of translationese we begin with supervised identi   cation
of translated text using features detailed in section 4.216; table 3 reports the results.
total number of chunks used for classi   cation is reported per dataset, where we used
the maximum available amount of data (up to 1000 chunks).

table 3. ten-fold supervised cross-validation classi   cation (rounded) accuracy of english,
french and german translationese; the best result in each column is boldfaced.

en(o)+fr   en en(o)+de   en fr(o)+en   fr de(o)+en   de
feature / corpus eur han lit ted eur lit pol eur han lit ted eur lit pol
90
total # of chunks 1k 1k 400 40
96
fw
90
99
100
93
97
pos. tokens
94
98
pos-trigrams
99
contextual fw 94
90
90

1k 1k 400 40
96
93
96
96
94
95
96
98

1k 650 100
100
96
99
93
100
97
92
98

1k 600
96
99
98
92
98
93
94
83

99
96
98
93

95
93
94
89

99
96
99
98

93
95
95
94

94
98
88
95

in line with previous works, the classi   cation results are very high, yielding near-
perfect accuracy with all feature types across all datasets. close inspection of highly
discriminative feature values sheds interesting light on the realization of unique char-
acteristics of translationese across languages and domains; we leave this discussion for
another venue.

supervised classi   cation methods, however, suffer from two main drawbacks:

(i) they inherently depend on data annotated with the translation direction, and (ii) they
may not be generalized to unseen (related or unrelated) domains. indeed, series of works
on supervised identi   cation of translationese reveal that classi   cation accuracy dramat-
ically deteriorates when classi   er is evaluated out-of-domain (i.e., trained and tested on
texts drawn from different corpora): [15, 38, 39, 19] demonstrated signi   cant drop in the
accuracy of classi   cation when one of the parameters (genre, source language, modal-
ity) was changed. these shortcomings undermine the usability of supervised methods
for translationese identi   cation in a typical real-life scenario, where no labelled in-
domain data are available.

unsupervised identi   cation of translationese to overcome the domain- and labeled-
data-dependence of supervised classi   cation we experiment in this section with un-
supervised methods. we adopt the approach detailed in [19], who demonstrated high
accuracy identifying english translationese by id91 methodology.

table 4 demonstrates the results; the reported numbers re   ect average accuracy over
30 experiments (the only difference being a random choice of the initial conditions).17
europarl and hansard systematically obtain very high accuracy with all feature types

16 feature combinations yield similar, occasionally slightly better, results; we refrain from pro-

viding full analysis in this paper.

17 standard deviation in most experiments was close to 0.

(with a single exception of fw for french hansard), implying uniform distribution of
other linguistic aspects (authorship, topic, modality, epoch etc.) in these sub-corpora,
thus facilitating the unsupervised procedure of id91, since the text translation sta-
tus dominates other dimensions.

table 4. id91 (rounded) accuracy of english, french and german translationese; the best
result in each column is boldfaced.

en(o)+fr   en en(o)+de   en fr(o)+en   fr de(o)+en   de
feature / corpus eur han lit ted eur lit pol eur han lit ted eur lit pol
90
total # of chunks 1k 1k 400 40
89
92
98
fw
99
pos. tokens
67
87
97
pos-trigrams
61
99
contextual fw 87
89
70

1k 1k 400 40
95
91
97
83
95
85
98
96

1k 650 100
100
95
99
80
100
94
98
88

1k 600
68
96
68
94
68
95
64
95

70
64
67
67

91
95
94
96

77
55
71
78

71
86
79
91

72
80
60
72

a notably high accuracy is obtained on the small ted corpus, which implies the
applicability of the id91 methodology to data-meager scenarios. the exceptionally
high accuracy achieved by unsupervised procedure on the politics dataset (both english
and german, across all feature types) may indicate existence of additional artifacts (e.g.,
subtle topical differences) that tease apart o from t, thus boosting the classi   cation
procedure. we leave this investigation for the future work.

we explain the lower precision achieved on the literature corpus by its unique char-
acter: translators of literary works enjoy more freedom, rendering the translated texts
more similar to original writing. yet, id91 with fw systematically yields a rea-
sonable accuracy for the literature datasets as well. we therefore, conclude that fw
comprise one of the best-performing and most-reliable features for the task of unsuper-
vised identi   cation of translationese.

sensitivity analysis next we tested (supervised and unsupervised) classi   ers    sensi-
tivity by varying the number of chunks that are subject to classi   cation. we used fw
(one of the best performing, content-independent features) in these experiments. we
excluded ted and politics datasets from these experiments due to their small size;
the results for the literature corpus are limited by the amount of available data in this
dataset. figures 1 and 2 report supervised and unsupervised classi   cation accuracy as
function of number of chunks used for this task.

supervised classi   cation accuracy remains stable when the number of chunks used
for classi   cation decreases. evidently, as few as 200 (100 on each side) chunks are suf-
   cient for excellent classi   cation in most cases. id91 results demonstrate similar
pattern: the vast majority of datasets preserve perfectly stable performance when the
number of chunks decreases. a single exception is hansard french (o + t from en-
glish), that exhibits results with considerable variance; we attribute these    uctuations to
the random choice of samples, subject for id91.

)

%

(

y
c
a
r
u
c
c
a
n
o
i
t
a
c
   

i
s
s
a
l
c

100

90

85

200

400

600

800

1

000

,

1

200

,

eur en   de

eur fr   en

han fr   en

lit en   de

lit fr   en

eur de   en

eur en   fr

han en   fr

lit de   en

lit en   fr

1

600

,

2

000

,

fig. 1. supervised classi   cation accuracy as function of number of chunks using function words.

total number of chunks

)

%

(

y
c
a
r
u
c
c
a
g
n
i
r
e
t
s
u
l
c

100

90

80

70

60

50

eur en   de

eur fr   en

han fr   en

lit en   de

lit fr   en

eur de   en

eur en   fr

han en   fr

lit de   en

lit en   fr

200

400

600

800

1,000

1,200

1,600

2,000

total number of chunks

fig. 2. id91 accuracy as function of number of chunks using function words.

unsupervised classi   cation is inherently sensitive procedure, thus the stable accu-
racy obtained by the majority of sub-corpora implies high reliability and applicability
of the id91 procedure to scenarios where only little data are available.

5 conclusion

we present diverse parallel bilingual english-french and english-german corpora with
accurate indication of the translation direction. to evaluate the quality of the corpus,
we carried out series of experiments across all sub-corpora, using both supervised and
unsupervised methodologies and various feature types. this is the    rst work (to the best
of our knowledge) employing unsupervised classi   cation across multiple languages and
diverse registers, and the encouraging results stress the applicability of this methodol-
ogy, leveraging further research in this    eld.

it has been shown in a series of works [14, 48   50, 33, 51] that awareness to trans-
lationese has a positive effect on the quality of smt. parallel resources presented in
this work enable exploitation of bilingual information for the task of identi   cation of
translationese. more precisely, the datasets that we compiled can be used for the task of
identifying the translation direction of parallel texts; task that enjoys growing interest
in recent years [23, 25].

the potential value of this work leaves much room for further exploratory and prac-
tical activities. our future plans include extending this set of corpora to additional do-
mains and languages, as well as exploitation of bilingual information for highly accurate
identi   cation of translationese at small text units, eventually, at the sentence level.

acknowledgments

this research was supported by a grant from the israeli ministry of science and tech-
nology. we are grateful to noam ordan for much advice and encouragement. we also
thank sergiu nisioi for helpful suggestions. we are grateful to philipp koehn for mak-
ing the europarl corpus available; to cyril goutte, george foster and pierre isabelle for
providing us with an annotated version of the hansard corpus; to franc  ois yvon and
andr  as farkas18 for contributing their literary corpora; and to the ted otp team for
sharing ted talks and their translations. we thank also raphael salkie for sharing his
diverse english-german corpus.

18 http://farkastranslations.com

references

1. baker, m.: corpus linguistics and translation studies: implications and applications.

in
baker, m., francis, g., tognini-bonelli, e., eds.: text and technology: in honour of john
sinclair. john benjamins, amsterdam (1993) 233   252

2. baker, m.: corpora in translation studies: an overview and some suggestions for future

research. target 7 (1995) 223   243

3. baker, m.: corpus-based translation studies: the challenges that lie ahead. in mona baker,
g.f., tognini-bonelli, e., eds.: terminology, lsp and translation. studies in language engi-
neering in honour of juan c. sager. john benjamins, amsterdam (1996) 175   186

4. al-shabab, o.s.: interpretation and the language of translation: creativity and conventions

in translation. janus, edinburgh (1996)

5. laviosa, s.: core patterns of lexical use in a comparable corpus of english lexical prose.

meta 43 (1998) 557   570

6. laviosa, s.: corpus-based translation studies: theory,    ndings, applications. approaches to

translation studies. rodopi (2002)

7. olohan, m.: introducing corpora in translation studies. routledge (2004)
8. becher, v.: when and why do translators add connectives? target 23 (2011) 26   47
9. zanettin, f.: corpus methods for descriptive translation studies. procedia     social and be-
havioral sciences 95 (2013) 20   32 corpus resources for descriptive and applied studies.
current challenges and future directions: selected papers from the 5th international con-
ference on corpus linguistics (cilc2013).

10. gellerstam, m.: translationese in swedish novels translated from english. in wollin, l.,
lindquist, h., eds.: translation studies in scandinavia. cwk gleerup, lund (1986) 88   95
john benjamins, amsterdam /

11. toury, g.: descriptive translation studies and beyond.

philadelphia (1995)

12. baroni, m., bernardini, s.: a new approach to the study of translationese: machine-learning
the difference between original and translated text. literary and linguistic computing 21
(2006) 259   274

13. van halteren, h.: source language markers in europarl translations. in scott, d., uszko-
reit, h., eds.: coling 2008, 22nd international conference on computational linguistics,
proceedings of the conference, 18-22 august 2008, manchester, uk. (2008) 937   944

14. kurokawa, d., goutte, c., isabelle, p.: automatic detection of translated text and its impact

on machine translation. in: proceedings of mt-summit xii. (2009) 81   88

15. koppel, m., ordan, n.: translationese and its dialects. in: proceedings of the 49th annual
meeting of the association for computational linguistics: human language technologies,
portland, oregon, usa, association for computational linguistics (2011) 1318   1326

16. ilisei, i., inkpen, d., pastor, g.c., mitkov, r.: identi   cation of translationese: a machine
learning approach. in gelbukh, a.f., ed.: proceedings of cicling-2010: 11th international
conference on computational linguistics and intelligent text processing. volume 6008 of
lecture notes in computer science., springer (2010) 503   511

17. ilisei, i., inkpen, d.: translationese traits in romanian newspapers: a machine learning

approach. international journal of computational linguistics and applications 2 (2011)

18. volansky, v., ordan, n., wintner, s.: on the features of translationese. digital scholarship

in the humanities 30 (2015) 98   118

19. rabinovich, e., wintner, s.: unsupervised identi   cation of translationese. transactions of

the association for computational linguistics 3 (2015) 419   432

20. nisioi, s.: unsupervised classi   cation of translated texts.

in biemann, c., handschuh,
s., freitas, a., meziane, f., m  etais, e., eds.: natural language processing and information

systems: proceedings of the 20th international conference on applications of natural lan-
guage to information systems, nldb. volume 9103 of lecture notes in computer science.,
springer (2015) 323   334

21. pym, a.: on toury   s laws of how translators translate. in pym, a., shlesinger, m., simeoni,
d., eds.: beyond descriptive translation studies: investigations in homage to gideon toury.
benjamins translation library: est subseries. john benjamins (2008) 311   328

22. becher, v.: abandoning the notion of    translation-inherent    explicitation: against a dogma

of translation studies. across languages and cultures 11 (2010) 1   28

23. eetemadi, s., toutanova, k.: asymmetric features of human generated translation. in: pro-
ceedings of the 2014 conference on empirical methods in natural language processing
(emnlp), association for computational linguistics (2014) 159   164

24. brown, p.f., desouza, p.v., mercer, r.l., pietra, v.j.d., lai, j.c.: class-based id165 mod-

els of natural language. computational linguistics 18 (1992) 467   479

25. eetemadi, s., toutanova, k.: detecting translation direction: a cross-domain study.

in:
naacl student research workshop, acl association for computational linguistics
(2015)

26. house, j.: beyond intervention: universals in translation? trans-kom 1 (2008) 6   19
27. laviosa, s.: universals. in baker, m., saldanha, g., eds.: routledge encyclopedia of trans-

lation studies, 2nd edition. routledge (taylor and francis), new york (2008) 288   292

28. koehn, p.: europarl: a parallel corpus for id151. mt summit (2005)
29. cucchi, c.: dialogic features in eu non-native parliamentary debates. review of the air

force academy 11 (2012) 5   14

30. koehn, p., birch, a., steinberger, r.: 462 machine translation systems for europe.

in:

proceedings of the twelfth machine translation summit. (2009) 65   72

31. cartoni, b., zufferey, s., meyer, t.: using the europarl corpus for cross-linguistic research.

belgian journal of linguistics 27 (2013) 23     42

32. islam, z., mehler, a.: customization of the europarl corpus for translation studies.

in:
proceedings of the eight international conference on language resources and evaluation
(lrec   12), european language resources association (elra) (2012)

33. lembersky, g., ordan, n., wintner, s.: language models for machine translation: original

vs. translated texts. computational linguistics 38 (2012) 799   825

34. cartoni, b., meyer, t.: extracting directional and comparable corpora from a multilingual
corpus for translation studies. in: proceedings 8th international conference on language re-
sources and evaluation (lrec), european language resources association (elra) (2012)
2132   2137

35. mollin, s.: the hansard hazard: gauging the accuracy of british parliamentary transcripts.

corpora 2 (2007) 187   210

36. lynch, g., vogel, c.: towards the automatic detection of the source language of a literary
translation. in: proceedings of coling 2012, the 24th international conference on com-
putational linguistics: posters. (2012) 775   784

37. avner, e.a.: identifying hebrew translationese using machine learning techniques. diplo-

marbeit, university of potsdam (2013)

38. popescu, m.: studying translationese at the character level. in angelova, g., bontcheva, k.,

mitkov, r., nicolov, n., eds.: proceedings of ranlp-2011. (2011) 634   639

39. avner, e.a., ordan, n., wintner, s.: identifying translationese at the word and sub-word

level. digital scholarship in the humanities (forthcoming)

40. gale, w.a., church, k.w.: a program for aligning sentences in bilingual corpora. compu-

tational linguistics 19 (1993) 75   102

41. tan, l., bond, f.: ntu-mc toolkit: annotating a linguistically diverse corpus.

in: pro-
ceedings of 25th international conference on computational linguistics (coling 2014).
(2014)

42. manning, c.d., surdeanu, m., bauer, j., finkel, j., bethard, s.j., mcclosky, d.: the stan-
ford corenlp natural language processing toolkit. in: proceedings of 52nd annual meeting
of the association for computational linguistics: system demonstrations, baltimore, mary-
land, association for computational linguistics (2014) 55   60

43. keerthi, s., shevade, s., bhattacharyya, c., murthy, k.: improvements to platt   s smo algo-

rithm for id166 classi   er design. neural computation 13 (2001) 637   649

44. hall, m., frank, e., holmes, g., pfahringer, b., reutemann, p., witten, i.h.: the weka

data mining software: an update. sigkdd explorations 11 (2009) 10   18

45. mosteller, f., wallace, d.l.: id136 in an authorship problem: a comparative study of
discrimination methods applied to the authorship of the disputed federalist papers. journal
of the american statistical association 58 (1963) 275   309

46. grieve, j.: quantitative authorship attribution: an evaluation of techniques. literary and

linguistic computing 22 (2007) 251   270

47. nisioi, s.: feature analysis for native language identi   cation. in gelbukh, a.f., ed.: pro-
ceedings of the 16th international conference on computational linguistics and intelligent
text processing (cicling 2015). lecture notes in computer science, springer (2015)

48. lembersky, g., ordan, n., wintner, s.: adapting translation models to translationese im-
proves smt. in: proceedings of the 13th conference of the european chapter of the as-
sociation for computational linguistics, avignon, france, association for computational
linguistics (2012) 255   265

49. lembersky, g., ordan, n., wintner, s.: improving id151 by adapting

translation models to translationese. computational linguistics 39 (2013) 999   1023

50. lembersky, g., ordan, n., wintner, s.: language models for machine translation: original
vs. translated texts. in: proceedings of the 2011 conference on empirical methods in natural
language processing, edinburgh, scotland, uk, association for computational linguistics
(2011) 363   374

51. twitto-shmuel, n., ordan, n., wintner, s.: id151 with automatic

identi   cation of translationese. in: proceedings of wmt-2015. (2015)

