description of the odin event extraction framework and

rule language

marco a. valenzuela-esc  arcega gus hahn-powell mihai surdeanu

computational language understanding (clu) lab

university of arizona, tucson, az, usa

{marcov,hahnpowell,msurdeanu}@email.arizona.edu

last revised: september 28, 2015

version 1.0 (see changes)

abstract

this document describes the odin framework, which is a domain-independent platform for
developing rule-based event extraction models. odin aims to be powerful (the rule language
allows the modeling of complex syntactic structures) and robust (to recover from syntactic parsing
errors, syntactic patterns can be freely mixed with surface, token-based patterns), while remaining
simple (some domain grammars can be up and running in minutes), and fast (odin processes over
100 sentences/second in a real-world domain with over 200 rules). here we include a thorough
de   nition of the odin rule language, together with a description of the odin api in the scala
language, which allows one to apply these rules to arbitrary texts.

5
1
0
2

 

p
e
s
4
2

 

 
 
]
l
c
.
s
c
[
 
 

1
v
3
1
5
7
0

.

9
0
5
1
:
v
i
x
r
a

1

3

3

4

6
6
6
6
7
7
8
9
9
9
10
10
10
12
12
13
16
17
18
18
19
19
19
20

21
22
22
22

23

24

contents
1 changes

2 introduction

3 a walkthrough example

4 rules

.

.

.

.

.

.

.

.
.

.
.

.
.

. .

.
4.2 rules
4.3 token patterns .

4.1 a gentle introduction to yaml . . . . . . . . . . . . . . . . . . . . . . . . . . .
4.1.1 yaml lists
. . . . . . . . . . . . . . . . . . . . . . . . . . . . .
4.1.2 yaml associative arrays . . . . . . . . . . . . . . . . . . . . . . . . . .
. .
4.1.3 yaml strings
. . . . . . . . . . . . . . . . . . . . . . . . . . . . .
.
.
. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
.
. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
.
.
.
. . . . . . . . . . . . . . . . . . . . . . . . . . . . .
4.3.1 token constraints
. . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
4.3.2
string matchers .
4.3.3 exact string matchers
. . . . . . . . . . . . . . . . . . . . . . . . . . . .
4.3.4 regex string matchers . . . . . . . . . . . . . . . . . . . . . . . . . . . .
4.3.5 named arguments .
. . . . . . . . . . . . . . . . . . . . . . . . . . . . .
4.3.6 token pattern operations . . . . . . . . . . . . . . . . . . . . . . . . . . .
4.3.7 zero-width assertions
. . . . . . . . . . . . . . . . . . . . . . . . . . . .
4.3.8 output
. .
. . . . . . . . . . . . . . . . . . . . . . . . . . . . .
. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
4.4.1 named arguments for dependency patterns . . . . . . . . . . . . . . . . .
4.4.2 quanti   ers for dependency patterns . . . . . . . . . . . . . . . . . . . . .
4.4.3 zero-width assertions
. . . . . . . . . . . . . . . . . . . . . . . . . . . .
. .
. . . . . . . . . . . . . . . . . . . . . . . . . . . . .
4.4.4 output
.
. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
4.5 building a grammar
. . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
.
4.5.1 master file .
. .
. . . . . . . . . . . . . . . . . . . . . . . . . . . . .
4.5.2 taxonomy .
4.5.3 variables and templates . . . . . . . . . . . . . . . . . . . . . . . . . . .

.
4.4 dependency patterns .

.
.
.
.

.
.
.
.

.
.

.

.

.

.

.

5 mentions, or the output of rules

5.1 textboundmention .
.
5.2 relationmention .
5.3 eventmention .
.
.

.

.
.
.

.
.
.

. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .

6 advanced: customizing rule output with actions

7 putting it together: the odin api

2

1 changes

1.0: initial release.

2 introduction

rule-based information extraction (ie) has long enjoyed wide adoption throughout industry, though
it has remained largely ignored in academia, in favor of machine learning (ml) methods [chiticariu
et al., 2013]. however, rule-based systems have several advantages over pure ml systems, includ-
ing: (a) the rules are interpretable and thus suitable for rapid development and domain transfer; and
(b) humans and machines can contribute to the same model. why then have such systems failed to
hold the attention of the academic community? one argument raised by chiticariu et al. is that, de-
spite notable efforts [appelt and onyshkevych, 1998, levy and andrew, 2006, hunter et al., 2008,
cunningham et al., 2011, chang and manning, 2014], there is not a standard language for this task,
or a    standard way to express rules   , which raises the entry cost for new rule-based systems.

odin (open domain informer) aims to address this issue with a novel event extraction (ee)
language and framework. the design of odin followed the simplicity principles promoted by other
natural language processing toolkits, such as stanford   s corenlp, which aim to    avoid over-design   ,
   do one thing well   , and have a user    up and running in ten minutes or less    [manning et al., 2014].
for example, consider a domain that tracks people   s movement, as reported in the news. one may
want to quickly write a domain grammar that captures events with the following arguments: (a)
the subject of the verb    move    (and its synonyms) only if it has been identi   ed as a person by a
named entity recognizer (ner), (b) the indirect object of the same verb that is dominated by the
preposition    from    as the origin location, and (c) an indirect object dominated by the preposition
   to    as the destination. odin captures such event patterns (and more) using a single declarative rule.

in particular, odin is:

simple: taking advantage of a syntactic dependency (sd) representation [de marneffe and man-
ning, 2008], our ee language has a simple, declarative syntax for the extraction of n-ary events,
which captures single or multi-word event predicates with lexical and morphological constraints,
and event arguments with (generally) simple syntactic patterns and semantic constraints.

powerful: despite its simplicity, our ee framework can capture complex constructs when neces-
sary, such as: (a) recursive events1, and (b) complex id157 over syntactic patterns for
event arguments. inspired by stanford   s semgrex2, we have extended a standard regular expression
language to describe patterns over directed graphs3, e.g., we introduce new < and > operators to
specify the direction of edge traversal in the dependency graph. finally, we allow for (c) optional
arguments and multiple arguments with the same name.

robust: to recover from unavoidable syntactic errors, sd patterns (such as the ones shown in the
next section) can be can be freely mixed with token-based surface patterns, using a language inspired
by the allen institute of arti   cial intelligence   s tagger4. these patterns match against information
extracted in our text processing pipeline5 , namely a token   s part of speech, lemmatized form, named
entity label, and the immediate incoming and outgoing edges in the sd graph.

fast: our ee runtime is fast because the odin runtime uses event trigger phrases (e.g.,    move    for
a moving event), which are captured with lexico-morphological patterns, as shallow    lters to reduce
the search space for pattern matching. that is, only when event triggers are detected is the matching
of more complex syntactic patterns for arguments attempted. this guarantees quick executions. for

1events that take other events as arguments. see the walkthrough example in the next section.
2nlp.stanford.edu/software/tregex.shtml
3we currently use stanford syntactic dependencies, but any other graph derived from text could be used. for example,

one could use a graph that models semantic roles or id15.

4https://github.com/allenai/taggers
5https://github.com/sistanlp/processors

3

the phosphorylation of mek by ras inhibits the ubiquitination of tgf.

figure 1: a sentence containing three events in the biomedical domain: a phosphorylation,
ubiquitination, and a negative regulation between the two. the text in bold marks biochemical
named entities previously identi   ed by a ner.

example, in a real-world biochemical domain, odin processes an average of 110 sentences/second6
with a grammar of 211 rules on a laptop with an i7 cpu and 16gb of ram.

this document is organized as follows. section 3 introduces the odin rule language with a sim-
ple walkthrough example. section 4 describes the complete rule language. the remaining sections
introduce the programmatic aspects of odin. section 5 describes odin mentions, which are scala7
objects that store the output of rules. section 6 describes programmatic ways to customize the out-
put of rules, by attaching custom scala code to rules. an important note here is that odin constructs
these mentions automatically, so adding custom actions is completely optional and their addition
should be reserved for complex phenomena that are not easily implemented with rules, e.g., coref-
erence resolution. lastly, section 7 puts it all together, by introducing the odin scala api, i.e., how
to instantiate and execute a domain grammar programatically.

3 a walkthrough example

lets use the sentence in figure 1 as a simple walkthrough example for an odin grammar in the
biomedical domain. this particular sentence contains three protein named entities, previously found
by a ner8, and we would like to build a grammar that    nds three molecular events: two simple
events that operate directly on the entities mentioned in the text, that is the phosphorylation of mek
by ras, and the ubiquitination of tgf9.

conceptually, odin follows the same strategy introduced by fastus more than 20 years ago ap-
pelt et al. [1993]: it applies a cascade of grammars, where each grammar builds on the output pro-
duced by the previous one. this is illustrated in the grammar listed in example 1, which lists all the
rules necessary to capture the events of interest from figure 1. the different rules capture multiple
phenomena:
ner promotes the output of the external ner, i.e., the ne labels in iob notation10, to odin   s men-
tion objects, and assigns them the arbitrary label protein. note that mention labels are a
domain-dependent choice, and, thus, they are the responsibility of the domain developer. the
implement this rule we used a simple surface, or token, pattern.

phospho matches a phosphorylation event, which is anchored around a nominal trigger,    phophory-

lation   , and has two arguments: a mandatory theme, which is syntactically attached to the
trigger verb through the preposition    of   , and an optional (note the ? character) cause,
attached to the trigger through the preposition    by   . both arguments must be protein men-
tion. in general, we call events that take only entity mentions as arguments simple events. the
resulting event mention is assigned the phosphorylation and event labels (any number

6after the initial text processing pipeline that includes syntactic parsing.
7odin is implemented in the scala language. however, because scala runs on the standard java virtual machine (jvm),

it plays well with other jvm languages, most notably java.

8although here we focus on event extraction, odin can also be used to write rules that extract entities. we largely ignore

these type of rules here because event extraction is much more challenging and exciting.

9it is not extremely important in this context, but, in the biomedical domain, a phosphorylation event adds a phosphate
group to the corresponding protein, which alters the activity of the protein. similarly, ubiquitination adds ubiquitin, a regu-
latory protein, to the corresponding substrate protein. finally we have a more complex event that takes these two events as
arguments (phosphorylation inhibits ubiquitination). detecting and linking these kinds of interactions, or   events   , deepens
our understanding of cancer signaling pathways.

10the iob or bio notation is a common representation,    rst proposed in ramshaw and marcus [1995], used to capture
sequences of words that form named entity mentions. please see http://www.cnts.ua.ac.be/conll2003/ner/
for more examples and details.

4

[entity="b-protein"][entity="i-protein"]*

1 - name: ner
2

label: protein
type: token
pattern: |

6
7 - name: phospho
8

label: [phosphorylation, event]
pattern: |

trigger = phosphorylation
theme: protein = prep_of
cause: protein? = prep_by

13
14 - name: ubiq
15

label: [ubiquitination, event]
pattern: |

trigger = ubiquitination
theme: protein = prep_of
cause: protein? = prep_by

20
21 - name: negreg
22

label: negative_regulation
pattern: |

3

4

5

9

10

11

12

16

17

18

19

23

24

25

26

trigger = [lemma=inhibit & tag=/  v/]
theme: event = dobj
cause: event = nsubj

example 1: rules that capture the events listed in figure 1.

of labels     1 can be assigned through a rule). by assigning multiple labels to a mention, a
domain developer essentially implements a de facto domain taxonomy. for example, in this
example, we arbitrarily decide that an is-a relation exists between labels from left to right.
that is, the phosphorylation event is a type of event. in section 4.5.2 we discuss how
to use formally-de   ned taxonomies in odin.

ubiq matches another simple event, this time around a ubiquitination. clearly, there is a lot of
redundancy between these last two rules. we will discuss later how to avoid this through rule
templates.

negreg matches the speci   ed trigger for a negative regulation, and then uses syntactic patterns
to    nd the arguments, theme and cause, which, this time, must be event mentions. this
rule will of course match only after the mentions for the simple events introduced above are
constructed. we call these type of events, which take other events as arguments, recursive
events.

explicit priorities can be assigned to rules to control the order and extent of their execution. it is
important to note that these priorities are not mandatory. if they are not speci   ed, odin attempts
to match all rules, which imposes an implicit execution. that is, phospho and ubiq can only
match after ner is executed, because they require entity mentions as arguments. similarly, negreg
matches only after the simple event mentions are constructed.

once the domain grammar is de   ned, the hard work is done. these rules are fed into an
extractorengine scala object that applies them on free text and returns the extracted men-
tions, as summarized in example 2.

of course, this simple example does not cover all of odin   s features. in the following sections
you will learn the different features that can be used to make more general, permissive, or restrictive
rules using our declarative language. for advanced users, we will also demonstrate how to write
custom code that can be attached to rules, also known as    actions   , which can be used to transform
the extracted mentions in ways that are not supported by the language, so that you can create complex
systems that better adapt to your needs.

5

1 val rules = "... text containing a domain grammar ..."
2 // this engine applies the rules on free text and constructs output mentions
3 val ee = extractorengine(rules)
4 // instantiate a processor, for id39 and syntactic analysis
5 val proc = new bionlpprocessor
6 // annotate text, producing a document with pos, ner, and syntactic annotations
7 val text = "... example text ..."
8 val doc = proc.annotate(text)
9 // and, lastly, apply the domain grammar on this document
10 val mentions = ee.extractfrom(doc)

example 2: a simple scala api example. here we used bionlpprocessor, a processor
tuned for texts in the biomedical domain, for pos, ner, and syntactic analysis. we offer open-
domain processors as well, such as corenlpprocessor.

4 rules

as the previous example illustrated, the fundamental building block of an odin grammar is a rule.
rules de   ne either surface patterns, which are    at patterns over sequences of words, such as ner in
the example (formally de   ned in section 4.3), or patterns over the underlying syntactic structure of
a sentence described using relational dependencies, such as phospho, ubiq, or negreg (de   ned in
section 4.4).

all odin rules are written in yaml ben-kiki et al. [2005]. however, it is not necessary to be a
yaml expert to use odin, as we only use a small and simple yaml subset to write rules. a brief
explanation of the required yaml features is given in section 4.1.

once you are comfortable writing rules, it is time to construct a complete domain grammar. in
the simplest instance, a complete grammar is a single    le containing some rules (similar to exam-
ple 1). while this is suf   cient for simple domains, when tackling more complex domains it may
become necessary to organize rules into several    les and recycle sets of prototypical rules to cover
related events by altering sub-pattern variables. we describe all these situations in section 4.5.

4.1 a gentle introduction to yaml
odin rules are written using a small yaml ben-kiki et al. [2005] subset. in particular, we only use
lists, associative arrays, and strings, which are brie   y summarized below. for more details (although
you should not need them), please read the yaml manual ben-kiki et al. [2005].

4.1.1 yaml lists

yaml supports two different ways of specifying lists. the recommended one for odin requires each
list item to appear in a line by itself, and it is denoted by prepending a dash and a space before the
actual element. elements of the same list must have the same level of indentation. as an example, a
list of fruits in yaml notation is provided in example 3.

1 - apple
2 - banana
3 - orange
4 - watermelon

example 3: example yaml list

4.1.2 yaml associative arrays

yaml supports two different syntaxes for associative arrays. the recommended one for odin is the
one in which each key-value pair appears in its own line, and all key-value pairs have the same level

6

of indentation. each key must be followed by colon. an example of a yaml associative array is
provided in example 4.

1 first_name: homer
2 last_name: simpson
3 address: 742 evergreen terrace
4 town: springfield

example 4: example yaml associative array

4.1.3 yaml strings

many rule components are encoded using single-line strings, as we have seen in the previous ex-
amples. there is one exception: the rule   s pattern    eld (as described in sections 4.3 and 4.4).
patterns can be complex and it is a good idea to break them into several lines. yaml supports
multi-line strings using the vertical bar character (e.g. |) to partition a key-value pair. when this is
used, the string begins in the next line and it is delimited by its indentation. an example of a yaml
multi-line string is shown in example 5.

1 var1: single-line string
2 var2: |
3

4

this is a multi-line string
this is still part of the same string
because of its indentation

5
6 var3: another single-line string

example 5: example yaml associative array with one multi-line string value

as shown, yaml strings don   t have to be quoted. this is a nice feature that allows one to write
shorter and cleaner rules. however, there is one exception that you should be aware of: strings that
start with a yaml indicator character must be quoted. indicator characters have special semantics
and must be quoted if they should be interpreted as part of a string. these are all the valid yaml
indicator characters:

- ? : , [ ] { } # & * ! | >     " % @    

as you can probably tell, these are not characters that occur frequently in practice. usually names
and labels are composed of alphanumeric characters and the occasional underscore, so, most of the
time, you can get away without quoting strings.

4.2 rules
odin rules are represented simply as yaml associative arrays, using the    elds shown in table 1.

7

field
name
label

description
the rule   s name (must be unique)
the label or list of labels to assign to the mentions found by this
rule

default
must be provided
must be provided

action

priority the iterations in which this rule should be applied. note that the
odin runtime system continuously applies the given grammar
on a given sentence until no new rule matches (this allows gram-
mars that use recursive events, such as the one in example 1
to work). each of these distinct runs is called an    iteration   ,
and they are all numbered starting from 1. through priorities,
a developer can specify in which iteration(s) the corresponding
rule should run. specifying priorities is not required, but it may
have an impact on run time, by optimizing which rule should
be applied when. a priority can be exact (denoted by a single
number), a range (two numbers separated by a dash), an in   nite
range (a number followed by a plus +), or a list of priorities (a
comma separated list of numbers surrounded by square brackets.
the custom code (or    action   ) to call for the matched mentions.
as discussed in section 6, specifying an action is not required.
the default action does the most widely used job, i.e., keep-
ing track of what was matched.
include the output of this rule in the output results?
what type of rule is this: surface rule (token) or syntax-based
(dependency)?
as discussed in section 4.3, each token contains multiple pieces
of information, e.g., the actual word (word), its lemma, or its
part-of-speech (pos) tag (tag). this parameter indicates which
of these    elds to be matched against implicitly, i.e., when the
token pattern is a simple string. currently, the only valid values
are word and tag.
either a token or a dependency pattern, as speci   ed in type,
that describes how to match mentions.

keep
type

pattern

unit

1+

default

true
dependency

word

must be provided

table 1: an overview of the    elds of odin rules.

clearly, the most important part of a rule, is the pattern    eld. in section 4.3 we describe
how to implement surface, or    token   , patterns. these are useful for simple sequences, or when
syntax is not to be trusted. in section 4.4 we introduce the bread-and-butter of odin: syntactic, or
   dependency   , patterns. note that both types of patterns use some of the same constructs: string
matchers (i.e., objects that can match a string), and token constraints (i.e., objects that impose com-
plex conditions on individual tokens to be matched). we will introduce these for token patterns, and
reuse them for dependency patterns.

4.3 token patterns
a common task in information extraction is extracting structured information from text. structured
information may refer to different kinds of things, from item enumerations to complex event men-
tions. one way to extract this kind of mentions from text is by the use of surface patterns that allow
us to match sequences of tokens that usually signal the presence of the information we are interested
in.

surface patterns are available in odin through the use of    token    patterns. odin   s token patterns
can match continuous and discontinuous token sequences by applying linguistic constraints on each

8

token (section 4.3.1), imposing structure (section 4.3.5), generalized through the use of operators
(section 4.3.6), and drawing on context (section 4.3.7). in this section we will describe each of these
features that make token patterns ef   cient and easy to use for the different information extraction
tasks that are encountered by practitioners.

4.3.1 token constraints

remember that, in the simplest case, a token (or word) can be matched in odin simply by specifying
a string. for example, to match the phosphorylation trigger in example 1, all we had to do was write
phosphorylation (quotes are optional). but, of course, odin can do a lot more when matching
individual words. this is where token constraints become useful. a token constraint is a boolean
expression surrounded by square brackets that can be used to impose more complex conditions when
matching a token.

each token has multiple    elds that can be matched:

description
field
the actual token.
word
the lemma form of the token
lemma
the part-of-speech (pos) tag assigned to the token
tag
incoming relations from the dependency graph for the token
incoming
outgoing outgoing relations from the dependency graph for the token
chunk

the shallow constituent type (ex. np, vp) immediately con-
taining the token
the ner label of the token
the label of any mention(s) (i.e., rule output) that contains the
token.

entity
mention

table 2: an overview of the attributes that may be speci   ed in a token constraint.

a token    eld is matched by writing the    eld name, followed by the equals character and a string
matcher. (e.g. word=dog matches the word    dog   , tag=/  v/ matches any token with a part-of-
speech that starts with    v   , entity="b-person" matches any token that is the beginning of a
person named entity). expressions can be combined using the common boolean operators: and &,
or |, not !. parentheses are also available for grouping the boolean expressions.

note: if the square brackets that delimit the token constraint are left empty, i.e., [], the expres-

sion will match any token.

4.3.2 string matchers

a string matcher is an object that matches a string. matching strings is the most common opera-
tion in odin, being heavily used both in token and dependency patterns. this is because all token
   elds (described in table 2) have string values that are matched using string matchers. addition-
ally, dependency patterns (described in section 4.4) match incoming and outgoing dependencies by
matching the name of the dependency using the same string matchers.

strings can be matched exactly or using id157. both options are described next.

4.3.3 exact string matchers

an exact string matcher is denoted using a string literal, which is a single- or double-quote delimited
string. the escape character is the backslash (e.g., \). if the string is a valid java identi   er, the quotes
can be omitted. for example, word=dog matches the word    dog   .

9

4.3.4 regex string matchers
a regex string matcher is denoted by a slash delimited java regular expression.11 a slash can be
escaped using a backslash. this is the only escaping done by odin to id157, everything
else is handled by the java regular expression engine. for example, tag=/  v/ matches any token
with a part-of-speech that starts with    v   .

4.3.5 named arguments

token patterns support two types of named arguments: those constructed    on-the-   y    from an arbi-
trary sequence of tokens or those that point to existing mentions.

capturing a sequence of tokens and assigning a label to the span for later use can be performed
using the (?<identifier> pattern) notation, where identifier is the argument name
and pattern is the token pattern whose result should be captured and associated with the argument
name. capturing several sequences or mentions with the same name is supported as well as nested
captures (i.e., arguments de   ned inside other arguments).

bonnie and clyde robbed the bank.

1

(?<robber> bonnie) and (?<robber> clyde) robbed []*? (?<location> bank)

example 6: an example of a token pattern with a repeated argument using a subpattern-style
named argument.

while powerful, these subpattern-style named arguments can quickly clutter a rule, especially
when the pattern is nontrivial. consider the (?<robber>) pattern in example 6. a broad-
coverage rule for detecting a robber could be quite complex. a better strategy might be to generalize
this pattern as a rule designed to identify any person. since this rule provides the context of a robbery
event, it would be suf   cient to simply specify that the span of text being labelled robber is a mention
of a person. we can do this quite easily with odin.

a previously matched mention can be included in a token pattern using the @ operator followed
by a stringmatcher that should match a mention label. this will consume all the tokens that
are part of the matched mention. if the mention should be captured in one of the named groups then
the notation is @identifier:stringmatcher where the identi   er is the group name and the
string matcher should match the mention label.

bonnie and clyde robbed the bank.

1

@robber:person and @robber:person robbed []*? @location:location

example 7: an example of a token pattern with a repeated argument using an mention-based
named argument. this assumes that other rules built the person and location mentions,
possibly from the output of a ner.

4.3.6 token pattern operations

the most fundamental token pattern operations are concatenation and alternation. concatenating
two patterns is achieved by writing one pattern after the other. alternation is achieved by separating
the two patterns using the alternation operator (e.g., |). this is analogous to a boolean or.

parentheses can be used to group such expressions. as is usual, parentheses take precedence
over the alternation operator. table 3 shows some simple examples of operator and parenthesis
usage.

11see http://docs.oracle.com/javase/8/docs/api/java/util/regex/pattern.html

10

pattern
fat rats | mice
fat (rats | mice)

description
matches fat rats or mice
matches fat rats or fat mice

table 3: example of parentheses usage to change operator precedence.

odin also supports several types of quanti   ers (see table 4 for details). the ?, * and + post   x
quanti   ers are used to match a pattern zero or one times, zero or more times, and one or more times
respectively. these are greedy quanti   ers, and can be turned lazy by appending a question mark
(e.g., ??, *?, +?). figure 2 illustrates the difference between greedy and lazy quanti   ers.

a b c d e f c

pattern match
[]+ c
[]+? c

a b c d e f c
a b c

figure 2: comparison of greedy (default behavior) and lazy (?) quanti   ers.

ranged repetitions can be speci   ed by appending {n,m} to a pattern, which means that the
pattern should repeat at least n times and at most m. if n is omitted (e.g., {,m}) then the pattern
must repeat zero to m times. if m is omitted (e.g., {n,}) then the pattern must repeat at least n
times. ranges are greedy, and can be turned lazy by appending a question mark (e.g., {n,m}?,
{,m}?, {n,}?) for an exact number of repetitions the {n} suf   x is provided. since this is an
exact repetition there are no greedy/lazy variations.

table 4 summarizes this set of quanti   ers.

symbol description
?

*
+
{n}
{n,m}

{,m}

{n,}

the quanti   ed pattern is optional.
repeat the quanti   ed pattern zero or more times.
repeat the quanti   ed pattern one or more times.
exact repetition. repeat the quanti   ed pattern n times.
ranged repetition. repeat the quanti   ed pattern between
n and m times, where n < m.
open start ranged repetition. repeat the quanti   ed pat-
tern between 0 and m times, where m > 0.
open end ranged repetition. repeat the quanti   ed pattern
at least n times, where n > 0.

lazy form
??
*?
+?

{n,m}?

{,m}?

{n,}?

table 4: an overview of the quanti   ers supported by odin   s token patterns.

quanti   ers apply either to a single token constraint or to a group of token constraints. groups
are speci   ed by using parentheses. an example of a token pattern that uses quanti   ers is shown on
example 8. this example also shows that one can use mention captures in the quanti   ed groups (the
number argument), and that the captured mentions can share the same name. this is useful for the
extraction of enumerations of unknown length.

11

the numbers 4, 8, 15, 16, 23 and 42 frequently recurred in lost.

1 # first, find numbers by inspecting the pos tag.
2 # note that this is not the only way to check for a number,
3 # there are other options, such as [word=/\d+/]
4 - name: numbers
label: number
5
priority: 1
type: token
pattern: |
[tag=cd]

6

7

8

9

10
11 # second, match comma separated lists of numbers optionally followed
12 # by the word    and    and a final number.
13 - name: list
14

label: listofnumbers
priority: 2
type: token
pattern: |

15

16

17

18

@num:number ("," @num:number)+ (and @num:number)?

example 8: example showcasing quanti   ers and mention captures.

4.3.7 zero-width assertions

zero-width assertions allow one to verify whether or not a pattern is present without including it in
the matched result. odin supports the following zero-width assertions:

symbol
  
$
(?=...)
(?!...)

description
beginning of sentence
end of sentence
postive lookahead
negative lookahead

(?<=...) positive lookbehind

(?<!...) negative lookbehind

limitation

the length of the lookbehind assertion matches must be
known at compile time. this restricts the patterns
supported by lookbehinds to token constraints and the
exact range quanti   er (e.g., {n}). parentheses are
supported.

table 5: an overview of the zero-width assertions supported by odin. these patterns do not
consume tokens, but are useful to match patterns preceding/following the expression of interest.

4.3.8 output

the output of any odin rule is called a    mention   , and they are actual instances of a mention scala
class, or one of its subclasses (see section 5).

the inclusion of named captures in a token pattern affects the type of mention that is produced.
in general, the result of applying a token pattern successfully is usually a textboundmention
(see section 5). however, if the token pattern includes named captures, then the result is a relationmention,
which is essentially a collection of named captures, or    arguments    (but without a predicate, or    trig-
ger   , which is typical of event mentions!). in other words, relation mentions are not dependent on
a particular predicate. if one of the named captures has the name    trigger    (case insensitive), then
odin assumes that this pattern de   nes an event, and the result is an event mention (an instance of
the eventmention class). examples 9 and 10 show two simple patterns that produce an event
mention and a relation mention, respectively.

12

3

4

5

6

7

8

3

4

5

6

oscar lives in a trash can.

1 - name: event_mention_out
2

label: livesin
priority: 2
type: token
pattern: |

(?<resident>oscar)
(?<trigger>[lemma=live])
in [tag=dt]? (?<location>[tag=/  n/]+)

example 9: an example of a token pattern rule that produces an event mention through the
speci   cation of a trigger.

dr. frankenstein spends a lot of time in the graveyard.

1 - name: relation_mention_out
2

label: personwithtitle
priority: 2
type: token
pattern: |

(?<title>[word=/(?i)  mr?s|dr|prof/]) @person:person

example 10: an example of a token pattern rule that produces a relation mention. this rule has
named arguments, but does not specify a trigger. for brevity, we assume that person mentions
have already been identi   ed.

4.4 dependency patterns
while token patterns are quite powerful, they are, of course, not too robust to syntactic variation.
writing patterns over syntactic structure produces generalizations with broader coverage that do not
sacri   ce precision. consider the sentences in figure 3:

noam danced at midnight with the leprechaun.

noam, in full view of the three-legged robot, danced at dawn
with the leprechaun.

noam danced under the moonlight at midnight with the
leprechaun.

his friends watched in awe while noam danced the forbidden jig
with the leprechaun at midnight.

figure 3: these sentences show some of the in   nite syntactic variation describing a dance be-
tween two entities.

13

figure 4: the relational-dependency parse for the sentences in figure 3.

while it requires several token-pattern rules to precisely capture the syntactic variation shown
in figure 3, all of these variants can be covered with a single rule using a dependency pattern (see
example 11).
1 - name: dancers_1
2

label: dance
priority: 2
pattern: |

3

4

5

6

7

trigger = [lemma=dance]
dancer:entity = nsubj
partner:entity = dobj? prep_with

example 11: a dependency rule that expects two arguments: (1) a nominal subject and (2) the
head word complements of a    with    prepositional phrase off of the lemmatized trigger, dance; (2)
may be preceded by an optional hop through a direct object (dobj) relation. note the optional
hop through a direct object (dobj). parsers often struggle with prepositional attachment, so we
have added an optional dobj in this rule to be robust to such errors.

figure 5: the structured output of the rule in example 11.

formally, a dependency pattern describes a traversal over a syntactic dependency graph. again,
we currently use stanford dependencies de marneffe and manning [2008] in odin, but odin is
independent of the representation used. odin   s dependency patterns are composed of several    elds.
to boot, dependency patterns de   ning event rules require a    trigger    that must be set to a token
pattern (see previous section). this token pattern describes a valid predicate for the event of interest.
the rest of the    elds are event arguments de   ned through a syntactic path from the trigger to some
mention (entity or event) that was previously matched by another rule. the path is composed of
hops and optional    lters. the hops are edges in the syntactic dependency graph; the    lters are token
constraints on the nodes (tokens) in the graph.
hops can be incoming or outgoing. an outgoing hop follows the direction of the edge from
head    dependent; an incoming hop goes against the direction of the edge, leading from de-
pendent    head. for example, the dependency    jumped           fonzie    is outgoing (   jumped    is
the head), but it is considered incoming when traversed in the other direction:    fonzie           jumped   .

14

figure 6: a simple sentence with its corresponding dependency parse tree.

1

2

3

4

pattern: |

trigger = [lemma=jump]
entity:noun = nsubj
obstacle:noun = prep_over

example 12: a simple, two-argument dependency pattern composed solely of outgoing hops,
which matches the    jumping    event above. we are assuming that a different rule created a noun
mention for every nn*.

an outgoing dependency is matched using the > operator followed by a string matcher, which
operates on the label of the corresponding dependency, e.g., >nsubj. because most patterns use
outgoing hops, (i.e. head    dependent), the > operator is implicit and can therefore be omitted.
an incoming relation (i.e. dependent    head) is matched using a required < operator followed
by a string matcher. >> is a wildcard operator that can be used to match any outgoing dependency.
<< is a wildcard operator that can be used to match any incoming dependency.

importantly, restrictions may be imposed on the nodes (i.e., tokens) visited when following
dependencies, using the usual token constraints. example 13 illustrates such constraints on both the
robber (using the pos tag) and the property (using the actual word).

gonzo stole her chicken.

gonzo stole her heart.

1 - name: np
2

label: noun
priority: 1
type: token
unit: tag
pattern: |

/  n/

8
9 - name: steal-1
10

label: steal
priority: 2
pattern: |

3

4

5

6

7

11

12

13

14

15

trigger = [lemma=steal]
robber:noun = nsubj [tag=nnp] # we are only interested in proper nouns
property:noun = dobj [!word=heart] # let   s keep the romance out of it.

example 13: while these two sentences are syntactically identical, only one pertains to theft of
tangible goods. we are assuming that a different rule created a noun mention for every nn*.

just as in token patterns, dependency patterns can include parentheses and the alternation oper-
ator |. for example, the pattern nsubj|agent matches an outgoing dependency whose label is
either nsubj or agent.

15

4.4.1 named arguments for dependency patterns

clearly, naming event arguments is important (e.g., one may want to keep track who is the agent
and who is the patient in a robbery event). we probably already observed that odin has a simple
syntax for this: a path to an argument begins with name:label = path, where label is the
the label of an existing mention. the path must lead to a token that is a part of a mention
with the speci   ed label. argument names are required and unique, i.e., you can   t have two different
patterns with the same name. but the same pattern may match multiple mentions! if, for example,
an argument with the name    theme    matched three different entities, then three event mentions will
be generated, each with one entity as the theme. if the given path to the theme fails to match any
mention, then no event mentions will be created.

at times one may need to make an argument optional or allow for more than one argument
with the same name in a single event mention. this can be achieved through the use of argument
quanti   ers. arguments can be made optional with the ? operator. the + operator is used to indicate
that a single event mention with all matches should be created. the * is similar to + but also makes
the argument optional. if the exact number of arguments with the same name is known, it can be
speci   ed using the exact repetition quanti   er {k}. in cases of exact repetitions, the cartesian product
will be applied to the mentions matching the given path. if k mentions are asked for in a path
p and n are found to match p, then j event mentions will be produced, where j is the binomial
coef   cient shown in equation 4.4.1. a few rules using these argument quanti   ers are shown in
examples 14, 15, & 16.

(cid:18)n

(cid:19)

k

=

n!

k!(n     k)!

(1)

cities like london, paris, tokyo, and beijing.

figure 7: the sentence used by the rules shown in examples 14, 15, & 16. we are assuming that
a different rule created a location mention for every location ne.

1 - name: cities-1
2

label: cities
priority: 2
pattern: |

3

4

5

6

7

1

2

3

trigger = [lemma=city]
# produces 4 eventmentions each with 1 city
city:location = prep_like

example 14: an example of a complete dependency pattern rule without an argument quanti   er.

mention cities
1
2
3
4

london
paris
tokyo
beijing

table 6: the four mentions produced by the dependency pattern shown in example 14.

trigger = [lemma=city]
# produces 1 eventmention with 4 cities
city:location+ = prep_like

example 15: an example of a dependency pattern with a + argument quanti   er. its output is
shown in table 7.

16

mention cities
1

london, paris, tokyo, beijing

table 7: the single mention produced by the rule shown in example 15.

1

2

3

trigger = [lemma=city]
# produces 6 eventmentions each with 2 cities
city:location{2} = prep_like

example 16: an example of a dependency pattern with a {k} quanti   ers on event arguments.
the scattering effect of the {k} quanti   er is shown in table 8.

mention cities
1
2
3
4
5
6

london, paris
london, tokyo
london, beijing
paris, tokyo
paris, beijing
tokyo, beijing

table 8: the six mentions produced by the rule shown in example 16.

4.4.2 quanti   ers for dependency patterns

in addition of the above quanti   ers on event arguments, odin supports quanti   ers inside the actual
dependency patterns. they are shown in table 9.

the ?, * and + post   x quanti   ers are used to match a pattern zero or one times, zero or more
times, and one or more times respectively. there is no notion of greedy/lazy dependency patterns.

ranged repetitions can be speci   ed by appending {m,n} to a pattern, and means that the pattern
should repeat at least m times and at most n. if m is omitted (e.g., {,n}) then the pattern must
repeat zero to n times. if n is omitted (e.g., {m,}) then the pattern must repeat at least m times.
there is no notion of greedy/lazy dependency patterns. for an exact number of repetitions the {n}
suf   x is provided.
for example, the pattern /prep/+ matches a sequence of 1 or more outgoing dependencies
whose labels contain prep. the pattern dobj* /prep/{,3} matches 0 or more dobj depen-
dencies, followed by up to 3 outgoing dependencies that contain prep.

symbol description
?

*
+
{n}
{n,m}

{,m}

{n,}

the quanti   ed pattern is optional.
repeat the quanti   ed pattern zero or more times.
repeat the quanti   ed pattern one or more times.
exact repetition. repeat the quanti   ed pattern n times.
ranged repetition. repeat the quanti   ed pattern between
n and m times, where n < m.
open start ranged repetition. repeat the quanti   ed pat-
tern between 0 and m times, where m > 0.
open end ranged repetition. repeat the quanti   ed pattern
at least n times, where n > 0.

table 9: an overview of the quanti   ers supported by odin   s dependency patterns.

17

4.4.3 zero-width assertions

for dependency patterns, there no lookbehind or lookahead assertions, only lookaround assertions.
the lookaround syntax is (?= pattern) for positive assertions and (?!
pattern) for neg-
ative assertions. example 17 shows an example of a positive lookaround in action.

dennis crashed his mom   s car.

dennis crashed his car.

1 - name: np
2

label: noun
priority: 1
type: token
unit: tag
pattern: |

/  n/

8
9 - name: accident-1
10

label: accident
priority: 2
pattern: |

3

4

5

6

7

11

12

13

14

15

16

3

4

5

6

7

trigger = [lemma=crash]
agent:noun = nsubj [tag=nnp] # we are only interested in proper nouns
# only match if this is mom   s car
vehicle:noun = dobj (?= poss [lemma=mom]) [lemma=car]

example 17: sometimes ownership matters. perhaps we want to know whether or not dennis
should be grounded for crashing a car. did dennis crash his mother   s car? a positive lookaround
is needed for this.

4.4.4 output

the result of applying a dependency pattern successfully is usually an event mention. if a trigger is
not speci   ed, a relation mention is produced (see figures 18 & 19 for details).

oscar lives in a trash can.

1 - name: dep_event_mention_out
2

label: livesin
priority: 2
pattern: |

trigger = [lemma=live]
resident:person = nsubj
location:location prep_in

example 18: an example of a dependency pattern rule that produces an event mention through
the speci   cation of a trigger.

18

dr. frankenstein spends a lot of time in the graveyard.

1 - name: sometitle-1
2

label: title
priority: 1
type: token
pattern: |

[word=/(?i)  mr?s|dr|prof/]

7
8 - name: dep_relation_mention_out
9

label: personwithtitle
priority: 2
pattern: |

3

4

5

6

10

11

12

13

person:person
title:title = nn

example 19: an example of a dependency pattern rule that produces a relation mention. this
rule has named arguments, but does not specify a trigger. when the trigger    eld is omitted in
a dependency pattern, the    rst    eld given should specify a named argument using the mention
retrieval syntax (argname:mentionlabel). all subsequent dependency patterns used by
the other arguments are anchored on this    rst argument.

4.5 building a grammar
by now, we hope you are somewhat con   dent that you can write odin rules. of course, the next step
is to put them together into a complete grammar. this can be very simple: minimally, all you have
to do is to store them all into a single    le which is then loaded into an odin engine (see section 7).
if you care a lot about ef   ciency, you can tune your grammar by assigning priorities to rules. for
example, rules that match entities should be executed before (i.e., have a lower priority) than rules
that match events where these entities serve as arguments. (but again, this is not needed: odin takes
care of pipelining rules internally.)

but some domain grammars are more complicated than a simple sequence of rules. you may
have event labels that are so complex that you would prefer to store them in a taxonomy. some event
types have almost exactly the same syntactic representations as others, so you would like to reuse
some rules. odin supports all these issues. we describe them next.

4.5.1 master file

the master    le is a grammar   s entry point, or the    le is passed to the odin runtime engine. as
mentioned, for simple grammars, this    le can be simply a collection of rules. for more complicated
scenarios, this    le must contain a required rules section, and two optional sections: taxonomy
and vars. let us describe these sections next.

4.5.2 taxonomy

the taxonomy is a forest (meaning a collection of trees) of labels that, if speci   ed, is used by odin
as the hierarchy for mention labels. an example taxonomy is shown in example 20.

19

1 # a tree hierarchy can be used to define the taxonomy
2 - organism:
3

- prokaryotic:

4

5

6

7

8

9

10

11

12

13

- archaebacteria
- eubacteria

- eukaryotic:

- unicellular:

- protista

- multicellular:
- autotrophic:

- plantae

- heterotrophic:

- fungi
- animalia

14
15 # we want to include robots in our taxonomy
16 # but they are not organisms, what can we do?
17 # fortunately, multiple trees are supported
18 - robot

example 20: example taxonomy

if a taxonomy is provided, then all the labels used by the rules must be declared in the taxonomy.
this is obviously useful for catching typos. more importantly, the taxonomy hierarchy is used to
robustly match mentions in subsequent rules. for example, if a rule creates an entity mention with
the label animalia from the taxonomy in example 20, this mention will be matched as argument
in a subsequent rule, which requires that argument to be of label multicellular. this is because
animalia is a hyponym of multicellular, i.e., it is directly derived from it.

if the value of taxonomy is a single string, then it will be interpreted as a    le name and the
taxonomy will be read from that    le. it should be noted that the taxonomy may only be speci   ed in
the master    le, whether included directly or provided through an import (see example 21).

1 # the taxonomy file should contain only the contents of the taxonomy (without the

taxonomy: section name)

2 taxonomy: path/to/taxonomy.yml

example 21: an example of a taxonomy import.

4.5.3 variables and templates

it is very common that similar events share the same syntactic structure. for example, in the biomed-
ical domain, all the biochemical reactions (there are between 10 and 20 of these) share the same
structure. for example,    a phosphorylates b    is similar to    a ubiquitinates b   , with the exception
of the predicate:    phosphorylates    vs.    ubiquitinates   . in such situations, we would like to reuse
these syntactic structures between events (so we do not write the same rules 10   20 times). odin
supports these through the use of variables and rule templates, where rule templates are simply rules
that use variables. for example, one could write a single rule template for the above example, where
the trigger constraints are encoded using a variable.

in general, variables can be declared as a yaml mapping, and they can be substituted in rules
using the ${variablename} notation (see examples 22 & 23). furthermore, wherever a rule
can be speci   ed, you can also import a    le, through the import command, and its optional vars
parameter. this gives one a further opportunity to instantiate variables. example 22 shows the
import command in action.

20

1 # global variables
2 vars:
3

mytrigger: "eat"

4
5 rules:
6

# import rules from file
# if variables are used in the imported file,
# they will be retrieved from the global vars
- import: path/to/template.yml

7

8

9

10

11

12

13

14

15

16

17

18

19

20

21

22

# import rules from file
# mytrigger is overridden for this import
- import: path/to/template.yml

vars:

mytrigger: "sell"

# rules and imports can live together in harmony :)
- name: somedude

label: person
type: token
pattern: |

[entity=   b-person   ] [entity=   i-person   ]*

example 22: an example of a master    le that uses import statements and demonstrates variable
precedence. note that variables can be instantiated in three different places: (a) in the template
   le itself, (b) when the import command is used, or (c) at the top of the master    le. the
precedence is: (b) > (c) > (a). for this particular example, it means that the value chosen for
the mytrigger variable is    eat    for the    rst import (line 9) and    sell    for the second import
(line 13).

1 vars:
2

# these variables are superseded by those in the master file
mytrigger: "buy"
mymentionlabel: "food"

3

4

5
6 rules:
7

- name: example_rule

8

9

10

11

12

13

14

label: event
type: token
priority: 1
pattern: |

@person:person # match a person
(?<trigger> [lemma=${mytrigger}]) # trigger comes from provided variable
[tag="dt"]? @object:${mymentionlabel} # retrieve mention with given label

example 23: the template.yml    le imported in example 22.

5 mentions, or the output of rules

as hinted before in this document, each rule produces a mention object when it successfully
matches some text. these objects are nothing magical: we simply use them to store everything that
the rule contains, and the corresponding text matched. table 10 summarizes the    elds of the mention
object.

21

field
labels
tokeninterval the open interval token span from the    rst word to the    nal word

description
the sequence of labels to associate with a mention.

startoffset

endoffset

sentence
document

arguments

foundby

+1.
the character index in the original text at which the mention
begins.
the character index in the original text at which the mention
ends +1.
the sentence index of this mention.
the document (composed of annotated sentences) from which
this mention originates.
a map from argument name (a string) to a sequence of men-
tions.
the name of the rule that    found    this mention.

table 10: an overview of the most important    elds of the mention class.

sometimes, actual code is best at explaining things. we highly encourage the reader to take
a look at the code implementing mention and its subclasses12. note that some the information
stored in mentions, e.g., the token interval of the mention, refer to data structures produced by our
preprocessing code, such as sentence and document. again, reading through the code is the
best way to learn about these13.

5.1 textboundmention
the mention class is subclassed by several other classes. the simplest is textboundmention.
a textboundmention is created when the output of a rule is a    at structure, i.e., a contiguous se-
quence of tokens in a sentence. more formally, a textboundmention will have a tokeninterval,
but its arguments map will be empty. these mentions are usually used to represent entities or
event triggers.

5.2 relationmention
a relationmention encodes n-ary relations between its arguments. all the arguments are
named (based on the argument names speci   ed in the matched rule), and are stored in the arguments
map. importantly, several arguments may have the same name! this is extremely useful when one
needs to capture in a rule enumerations of several valid arguments with the same role (for example,
a food argument may capture multiple foods consumed at a dinner).

5.3 eventmention
an eventmention is similar to a relationmention, with just one additional feature: it has
a textboundmention that represents the trigger of the event. in other words, the arguments
map contains an additional argument, labeled trigger, which stores the event   s predicate. note:
an event must have exactly one trigger.

12https://github.com/clulab/processors/blob/master/src/main/scala/edu/arizona/

sista/odin/mention.scala

13https://github.com/clulab/processors/blob/master/src/main/scala/edu/arizona/

sista/processors/document.scala

22

6 advanced: customizing rule output with actions

note: you are welcome to skip this section. we expect only a small numbers of users, who need
deep customization of odin, to    nd this section necessary.

as described in the previous section, odin rules produce mentions, which store all the relevant
information generated during the match. this is suf   cient for most common usages of odin, but
sometimes this information requires some changes. for example, one could use coreference reso-
lution to replace event arguments that are pronouns with their nominal antecedents, as indicated by
the coreference resolution component. this is not easily done though rules, and this is when actions
become necessary.

actions are scala methods (implemented by the domain developer!)

that can be applied by
odin   s runtime engine to the resulting mentions after matching the rule. an action has the type
signature shown in example 24.

1 def action(mentions: seq[mention], state: state): seq[mention]

example 24: signature of action methods.

a rule will    rst try to apply its pattern to a sentence. any matches will be sent to the correspond-
ing action as a mention sequence. if an action is not explicitly named, the default identity action
will be used, which returns its input mentions unmodi   ed (i.e. the input   s identity).actions receive
as input parameters this mention sequence and also the runtime engine   s state.

the state object (second parameter) provides read-only access to all the mentions previously
created by odin in the current document. this information may be useful to implement global
decisions, e.g., coreference resolution across the entire document.

actions must return a mention sequence that will be added to the state at the end of the
current iteration by the runtime engine. for example, the simplest possible action would return
the mentions it received as the    rst input parameter. example 25 shows an only slightly more
complicated action that removes any mention containing the text    fox   .

1 def action(mentions: seq[mention], state: state): seq[mention] = {
2
3 }

mentions.filter(_.text contains "fox")

example 25: an example of an action that removes any mention containing the text    fox   .

note that, in addition to attaching actions to individual rules, actions can also be called glob-
ally at the end of each iteration by the runtime engine. this means that the extractor engine (see
example 26) must receive this global action as a parameter during its construction.

1 // the simplest instantiation where no actions are specified.
2 // here the matches produced by a our rules are returned unmodified.
3 val eenoactions = extractorengine(rules)
4 // myactions is an object containing the implementation of any actions
5 // named in the rules
6 val eewithactions = extractorengine(rules, myactions)
7 // here we specify both an actions object and a global action
8 val eewithactionsandglobal = extractorengine(rules, myactions, myglobalaction)
9 // we can also choose to specify only a global action
10 val eewithglobalonly = extractorengine(rules, globalaction = myglobalaction)

example 26: the extractorengine may be instantiated in several ways.

23

global actions have the same signature, but, in this context, the mentions parameter contains
all mentions found in this iteration of the engine. any mentions produced by rule-local actions will
only make it into the state iff they pass successfully through the global actions. by default, the
global action returns its input unmodi   ed (i.e. the input   s identity).

7 putting it together: the odin api

in the previous sections we learned how to write token and dependency patterns using the odin
information extraction framework. in this section, we will go through the set up of a complete system
using odin to extract marriage events from free text. in example 27, we de   ne a minimal grammar
which we assume to be saved to the current working directory in a    le named marriage.yml.

1 - name: ner-person-or-pronouns
2

label: person
priority: 1
type: token
pattern: |

# this pattern uses the output of an ner system to
# create a person mention
[entity=person]+

|

# we will also consider some pronouns to be person mentions
[lemma=/  he|she|they/]

12
13 - name: ner-date
14

label: [date]
priority: 1
type: token
pattern: |

[entity=date]+

19
20 - name: ner-loc
21

label: location
priority: 1
type: token
pattern: |

3

4

5

6

7

8

9

10

11

15

16

17

18

22

23

24

25

30

31

32

33

34

35

36

37

38

[entity=location]+

26
27 # optional location and date
28 - name: marry-syntax-1
29

label: marriage
priority: 2
example: "he married jane last june in hawaii."
type: dependency
pattern: |

# avoid negative examples by checking for "neg" relation
trigger = [lemma=marry & !outgoing=neg]
spouse:person+ = (<xcomp? /  nsubj/ | dobj) conj_and?
date:date? = /prep_(on|in|at)/+ | tmod
location:location* = prep_on? /prep_(in|at)/+

example 27: an example of a small set of rules designed to capture a marriage event and its
participants. the rules that run in priority 1 make use of the output of an ner system to capture
mentions for person, location, and date. according to the rule    marriage-syntax-1   , a
marriage event requires at least one spouse and may optionally have a date and location.

we can now use our marriage.yml event grammar to extract mentions from free text. exam-
ple 28 shows a simple scala program to do just this. we instantiate a corenlpprocessor which
uses stanford   s corenlp to parse and annotate the provided text with the attributes required by
odin (see table 2 for a list of the relevant attributes). this annotated text is stored in a document

24

which is then passed to odin through the eventengine.extractfrom() method. finally we
collect the marriage mentions found by odin and display them using the mention.json()
method, which converts the mention into a json representation. a portion of this output is shown
in example 29.

1 import edu.arizona.sista.odin._
2 import edu.arizona.sista.processors.corenlp.corenlpprocessor
3
4 object simpleexample extends app {
5

// two example sentences
val text = """|john and alice got married in vegas last march.

|caesar and cleopatra never married.
|i think they got married.
|zarbon and frederick will marry next summer.
|she and burt finally got married.
|simon and samantha got married in tucson on march 12, 2010 at the desert museum.
|""".stripmargin

// read rules from general-rules.yml file in resources
val source = io.source.fromfile("marriage.yml"))
val rules = source.mkstring
source.close()

// create a simple engine without custom actions
val extractor = extractorengine(rules)

// annotate the sentences
val proc = new corenlpprocessor
val doc = proc.annotate(text)

// extract mentions from annotated document
val mentions = extractor

.extractfrom(doc)
// only keep the marriage mentions
.filter(_ matches "marriage")

// display the mentions
mentions.foreach{ m => println(m.json(pretty=true)) }

6

7

8

9

10

11

12

13

14

15

16

17

18

19

20

21

22

23

24

25

26

27

28

29

30

31

32

33

34
35 }

example 28: a simple scala program using the marriage.yml rules shown in example 27.
these rules do not call any custom actions. for an explanation of how to link rules to custom
actions, please refer to section 6.

1 {
2

3

4

5

6

7

8

9

10

11

12

13

14

15

16

17

18

19

"type":"event",
"labels":["marriage"],
"sentence":5,
"foundby":"marry-syntax-1",
"trigger":{

"type":"textbound",
"tokeninterval":[4,5],
"characteroffsets":[212,219],
"labels":["marriage"],
"sentence":5,
"foundby":"marry-syntax-1"

},
"arguments":{
"spouse":[{

"type":"textbound",
"tokeninterval":[0,1],
"characteroffsets":[189,194],
"labels":["person"],

25

"sentence":5,
"foundby":"ner-person-or-pronouns"

},{

"type":"textbound",
"tokeninterval":[2,3],
"characteroffsets":[199,207],
"labels":["person"],
"sentence":5,
"foundby":"ner-person-or-pronouns"

}],
"date":[{

"type":"textbound",
"tokeninterval":[8,12],
"characteroffsets":[233,247],
"labels":["date"],
"sentence":5,
"foundby":"ner-date"

}],
"location":[{

"type":"textbound",
"tokeninterval":[6,7],
"characteroffsets":[223,229],
"labels":["location"],
"sentence":5,
"foundby":"ner-loc"

},{

"type":"textbound",
"tokeninterval":[14,16],
"characteroffsets":[255,268],
"labels":["location"],
"sentence":5,
"foundby":"ner-loc"

}]

20

21

22

23

24

25

26

27

28

29

30

31

32

33

34

35

36

37

38

39

40

41

42

43

44

45

46

47

48

49

50

51

52

}

53
54 }

example 29: an example of one of the captured marriage mentions outputted as json. the
   characteroffsets       eld corresponds to the original text provided in example 28).

an example of a complete project including details on how to specify odin   s dependencies is avail-
able here:

https://github.com/clulab/odin-examples

readers seeking a starting point for their own projects can refer to the code in the linked repository
which contains working examples covering both simple and complex scenarios.

26

references
douglas e appelt and boyan onyshkevych. the common pattern speci   cation language. in proc.

of the tipster workshop, pages 23   30, 1998.

douglas e. appelt, jerry r. hobbs, john bear, david israel, and mabry tyson. fastus: a    nite-state
in proceedings of the international

processor for information extraction from real-world text.
conferences on arti   cial intelligence (ijcai), 1993.

oren ben-kiki, clark evans, and brian ingerson. yaml ain   t markup language (yaml) version 1.1.

yaml. org, tech. rep, 2005.

angel x. chang and christopher d. manning. tokensregex: de   ning cascaded id157

over tokens. technical report cstr 2014-02, computer science, stanford, 2014.

laura chiticariu, yunyao li, and frederick r reiss. rule-based information extraction is dead!

long live rule-based information extraction systems! in proc. of emnlp, 2013.

hamish cunningham, diana maynard, kalina bontcheva, valentin tablan, niraj aswani, ian
roberts, genevieve gorrell, adam funk, angus roberts, danica damljanovic, thomas heitz,
mark a. greenwood, horacio saggion, johann petrak, yaoyong li, and wim peters. developing
language processing components with gate (version 6). university of shef   eld, 2011.

marie-catherine de marneffe and christopher d. manning. the stanford typed dependencies rep-
resentation. in proc. of coling workshop on cross-framework and cross-domain parser eval-
uation, 2008.

lawrence hunter, zhiyong lu, james firby, william a baumgartner, helen l johnson, philip v
ogren, and k bretonnel cohen. opendmap: an open source, ontology-driven concept analysis
engine, with applications to capturing knowledge regarding protein transport, protein interactions
and cell-type-speci   c gene expression. bmc bioinformatics, 9(1):78, 2008.

roger levy and galen andrew. tregex and tsurgeon: tools for querying and manipulating tree data

structures. in proc. of lrec, 2006.

c. d. manning, m. surdeanu, j. bauer, j. finkel, s. j. bethard, and d. mcclosky. the stanford

corenlp natural language processing toolkit. in proc. of acl, 2014.

lance a ramshaw and mitchell p marcus. text chunking using transformation-based learning.

arxiv preprint cmp-lg/9505040, 1995.

27

