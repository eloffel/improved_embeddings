we are humor beings: understanding and predicting visual humor

arjun chandrasekaran1 ashwin k. vijayakumar1

stanislaw antol1 mohit bansal2

dhruv batra1 c. lawrence zitnick3 devi parikh1
1virginia tech
3facebook ai research

2tti-chicago

1{carjun, ashwinkv, santol, dbatra, parikh}@vt.edu 2mbansal@ttic.edu 3zitnick@fb.com

6
1
0
2

 

y
a
m
5

 

 
 
]

v
c
.
s
c
[
 
 

4
v
7
0
4
4
0

.

2
1
5
1
:
v
i
x
r
a

abstract

humor is an integral part of human lives. despite be-
ing tremendously impactful, it is perhaps surprising that we
do not have a detailed understanding of humor yet. as in-
teractions between humans and ai systems increase, it is
imperative that these systems are taught to understand sub-
tleties of human expressions such as humor. in this work,
we are interested in the question     what content in a scene
causes it to be funny? as a    rst step towards understanding
visual humor, we analyze the humor manifested in abstract
scenes and design computational models for them. we col-
lect two datasets of abstract scenes that facilitate the study
of humor at both the scene-level and the object-level. we
analyze the funny scenes and explore the different types of
humor depicted in them via human studies. we model two
tasks that we believe demonstrate an understanding of some
aspects of visual humor. the tasks involve predicting the
funniness of a scene and altering the funniness of a scene.
we show that our models perform well quantitatively, and
qualitatively through human studies. our datasets are pub-
licly available.

1. introduction

an adult laughs 18 times a day [28] on average. a
good sense of humor is related to communication com-
petence [14, 15], helps raise an individual   s social status
[47], popularity [19, 29], and helps attract compatible mates
[8, 10, 39]. humor in the workplace improves camaraderie
and helps workers cope with daily stresses [42] and loneli-
ness [56]. fmri [44] studies of the brain reveal that humor
activates the components of the brain that are involved in
reward processing [57]. this probably explains why we ac-
tively seek to experience and create humor [36].

despite the tremendous impact that humor has on our
lives, the lack of a rigorous de   nition of humor has hin-
dered humor-related research in the past [4, 50]. while ver-
bal humor is better understood today [45, 48], visual humor
remains unexplored. as vision and ai researchers we are
interested in the following question     what content in an
image causes it to be funny? our work takes a step in the

(a) funny scene: raccoons
are drunk at a picnic.

(b) funny scene: dogs feast
while the girl sits in a pet bed.

(c) funny scene: rats steal
food while the cats are asleep.

(d) funny object replaced
(unfunny) counterpart: rats
in (c) are replaced by food.

figure 1: (a), (b) are selected funny scenes in the abstract
visual humor dataset. (c) is an originally funny scene in the
funny object replaced dataset. the objects contributing to
humor in (c) are replaced by a human with other objects, to
create an unfunny counterpart.
direction of building computational models for visual hu-
mor. computational visual humor is useful for a number
of applications: to create better photo editing tools, smart
cameras that pick the right moment to take a (funny) pic-
ture, recommendation tools that rate funny pictures higher
(say, to post on social media), video summarization tools
that summarize only the funny frames, automatically gener-
ating funny scenes for entertainment, identifying and cater-
ing to personalized humor, etc. as ai systems interact more
with humans, it is vital that they understand subtleties of hu-
man emotions and expressions. in that sense, being able to
identify humor can contribute to their common sense.

understanding visual humor is fraught with challenges
such as having to detect all objects in the scene, ob-
serving the interactions between objects, and understand-
ing context, which are currently unsolved problems.
in
this work, we argue that, by using scenes made from cli-
part [1, 2, 17, 25, 26, 54, 61, 62], we can study visual humor
without having to wait for these detailed recognition prob-

lems to be solved. abstract scenes are inherently densely
annotated (e.g. all objects and their locations are known),
and so enable us to learn    ne-grained semantics of a scene
that causes it to be funny.
in this paper, we collect two
datasets of abstract scenes that facilitate the study of humor
at both the scene-level (fig. 1a, fig. 1b) and the object-level
(fig. 1c, fig. 1d). we propose a model that predicts how
funny a scene is using semantic visual features of the scene
such as occurrence of objects, and their relative locations.
we also build computational models for a particular source
of humor, i.e., humor due to the presence of objects in an
unusual context. this source of humor is explained by the
incongruity theory of humor which states that a playful vi-
olation of the subjective expectations of a perceiver causes
humor [31]. e.g., fig. 1b is funny because our expectation
is that people eat at tables and dogs sit in pet beds and this is
violated when we see the roles of people and dogs swapped.
the scene-level abstract visual humor (avh) dataset
contains funny scenes (fig. 1a, fig. 1b) and unfunny scenes
with human ratings for funniness of each scene. using the
ground truth rating, we demonstrate that we can reliably
predict a funniness score for a given scene. the object-level
funny object replaced (for) dataset contains scenes that
are originally funny (fig. 1c) and their unfunny counterparts
(fig. 1d). the unfunny counterparts are created by humans
by replacing objects that contribute to humor such that the
scene is not funny anymore. the ground truth of replaced
objects is used to train models to alter the funniness of a
scene     to make a funny scene unfunny and vice versa. our
models outperform natural baselines and ablated versions
of our system in quantitative evaluation. they also demon-
strate good qualitative performance via human studies.

our main contributions are as follows:

1. we collect two abstract scene datasets consisting of
scenes created by humans which are publicly available.
i. the scene-level abstract visual humor (avh)
dataset consists of funny and unfunny abstract
scenes (sec. 3.2). each scene also contains a brief
explanation of the humor in the scene.

ii. the object-level funny object replaced (for)
dataset consists of funny scenes and their corre-
sponding unfunny counterparts resulting from ob-
ject replacement (sec. 3.3).

2. we analyze the different sources of humor

tech-
niques depicted in the avh dataset via human studies
(sec. 3.2).

3. we learn distributed representations for each object cat-
egory which encode the context in which an object natu-
rally appears, i.e., in an unfunny setting. (sec. 4.1).

4. we model two tasks to demonstrate an understanding of

visual humor:

i. predicting how funny a given scene is (sec. 5.1).
ii. automatically altering the funniness of a given

scene (sec. 5.2).

to the best of our knowledge, this is the    rst work that
deals with understanding and building computational mod-
els for visual humor.
2. related work
humor theories. humor has been a topic of study since
the time of plato [41], aristotle [3] and bharata [5]. over
the years, philosophical studies and psychological research
have sought to explain why we laugh. there are three the-
ories of humor [59] that are popular in contemporary aca-
demic literature. according to the incongruity theory, a per-
ceiver encounters an incongruity when expectations about
the stimulus are violated [27]. the two stage model of hu-
mor [52] further states that the process of discarding prior
assumptions and reinterpreting the incongruity in a new
context (resolution) is crucial to the comprehension of hu-
mor. superiority theory suggests that the misfortunes of
others which re   ects our own superiority is a source of hu-
mor [38]. according to the relief theory, humor is the re-
lease of pent-up tension or mental energy. feelings of hos-
tility, aggression, or sexuality that are expressed bypassing
any societal norms are said to be enjoyed [18].

previous attempts to characterize the stimuli that induce
humor have mostly dealt with linguistic or verbal humor
[31] e.g., script-based semantic theory of humor [48] and
its revised version, the general theory of verbal humor [45].
computational models of humor. a number of compu-
tational models are developed to recognize language-based
humor e.g., one-liners [33], sarcasm [11] and knock-knock
jokes [53]. other work in this area includes exploring fea-
tures of humorous texts that help detection of humor [32],
and identifying the set of words or phrases in a sentence that
could contribute to humor [60].

some computational humor models that generate verbal
humor are jape [7] which is a pun-based riddle generating
program, hahacronym [51] which is an automatic funny
acronym generator, and an unsupervised model that pro-
duces    i like my x like i like my y, z    jokes [40]. while the
above works investigate detection and generation of verbal
humor, in this work we deal purely with visual humor.

recent works predict the best text to go along with a
given (presumably funny) raw image such as a meme [55]
in addition, radev et al. [43] develop
or a cartoon [49].
unsupervised methods to rank funniness of captions for a
cartoon. they also analyze the characteristics of the funni-
est captions. unlike our work, these works do not predict
whether a scene is funny or which components of the scene
contribute to the humor.

buijzen and valkenburg [9] analyze humorous commer-
cials to develop and investigate a typology of humor. our
contributions are different as we study the sources of humor
in static images, as opposed to audiovisual media. to the
best of our knowledge, ours is the    rst work to study visual
humor in a computational framework.

human perception of images. a number of works inves-
tigate the intrinsic characteristics of an image that in   uence
human perception e.g., memorability [23], popularity [24],
visual interestingness [20], and virality [13]. in this work,
we study what content in a scene causes people to perceive
it as funny, and explore a method of altering the funniness
of a scene.
learning from visual abstraction. visual abstractions
have been used to explore high-level semantic scene under-
standing tasks like identifying visual features that are se-
mantically important [61, 63], learning mappings between
visual features and text [62], learning visually grounded
id27s [25], modeling    ne-grained interactions
between pairs of people [2], and learning (temporal and
static) common sense [17, 26, 54].
in this work, we use
abstract scenes to understand the semantics in a scene that
cause humor, a problem that has not been studied before.

3. datasets

we introduce two new abstract scenes datasets     the ab-
stract visual humor (avh) dataset (sec. 3.2) and the funny
object replaced (for) dataset (sec. 3.3) using the inter-
faces described in sec. 3.1. the avh dataset (sec. 3.2) con-
sists of both funny and unfunny scenes along with funniness
ratings. the for dataset (sec. 3.3) consists of funny scenes
and their altered unfunny counterparts. both the datasets are
made publicly available on the project webpage.
3.1. abstract scenes interface

abstract scenes enable researchers to explore high-level
semantics of a scene without waiting for low-level recogni-
tion tasks to be solved. we use the clipart interface1 devel-
oped by antol et al. [1] which allows for indoor and outdoor
scenes to be created. the clipart vocabulary consists of 20
deformable human models, 31 animals in various poses, and
around 100 objects that are found in indoor (e.g., chair, ta-
ble, sofa,    replace, notebook, painting) and outdoor (e.g.,
sun, cloud, tree, grill, camp   re, slide) scenes. the human
models span different genders, races, and ages with 8 dif-
ferent expressions. they have limbs that are adjustable to
allow for continuous pose variations. this combined with
the large vocabulary of objects result in diverse scenes with
rich semantics. fig. 1 (top row) shows scenes that amt
workers created using this abstract scenes interface and vo-
cabulary. additional details, example scenes, and a sample
of clipart objects are available on the project webpage.
3.2. abstract visual humor (avh) dataset

this dataset consists of funny and unfunny scenes cre-
ated by amt workers, facilitating the study of visual humor
at the scene level.

1www.github.com/vt-vision-lab/abstract_scenes_

v002

collecting funny scenes. we collect 3.2k scenes via
amt by asking workers to create funny scenes that are
meaningful, realistic, and that other people would also con-
sider funny. this is to encourage workers to refrain from
creating scenes with inside jokes or catering to a very per-
sonalized form of humor. a screenshot of the interface used
to collect the data is available on the project webpage. we
provide a random subset of the clipart vocabulary to each
worker out of which at least 6 clipart objects are to be used
to create a scene. in addition, we also ask the worker to
give a brief description of why the scene is funny in a short
phrase or sentence. we    nd that this encourages workers
to be more thoughtful and detailed regarding the scene they
create. note that this is different from providing a caption
to an image since this is a simple explanation of what the
worker had in mind while creating the scene. mining this
data may be useful to better understand visual humor. how-
ever, in this work we focus on the harder task of understand-
ing purely visual humor and do not use these explanations.
we also use an equal number (3.2k) of abstract scenes
from [1] which are realistic, everyday scenes. we expect
most of these scenes to be mundane (i.e., not funny).
labeling scene funniness. anyone who has tried to be
funny knows that humor is a subjective notion. a well-
intending worker may create a scene that other people do
not    nd very funny. we obtain funniness ratings for each
scene in the dataset from 10 different workers on amt who
do not see the creator   s explanation of funniness. the rat-
ings are on a scale of 1 to 5, where 1 is not funny and 5 is ex-
tremely funny. we de   ne the funniness score fi of a scene
i, as the average of the 10 ratings for the scene. we found
10 ratings to be suf   cient for good inter-human agreement.
further analysis is provided on the project webpage.

by plotting a distribution of these scores, we determine
the optimal threshold that best separates scenes that were
intended to be funny (i.e., workers were speci   cally asked
to create a funny scene) and other scenes (i.e., everyday
scenes from [1], where workers were not asked to cre-
ate funny scenes). we label all scenes that have a fi (cid:62)
threshold as funny and all scenes with a lower fi as un-
funny. this re-labeling results in 522 unintentionally funny
scenes (i.e., scenes from [1], which were determined to be
funny), and 682 unintentionally unfunny scenes (i.e., well-
intentioned worker outputs which were deemed not funny
by the crowd).

in total, this dataset contains 6,400 scenes (3,028 funny
scenes and 3,372 unfunny scenes). we randomly split these
scenes into train, val, and test sets having 60%, 20%, and
20% of the scenes, respectively. we refer to this dataset as
the avh dataset.
humor techniques.
to better understand the different
sources of humor in our dataset, we collect human annota-
tions of the different techniques are used to depict humor
in each scene. we create a list of humor techniques that

(a) 0.1

(b) 1.5

(c) 4.0

(d) 4.0

figure 2: spectrum of scenes (left to right) in ascending order of funniness score, fi (sec. 3.2) as rated by amt workers.
motivation behind this is to get a precise signal of which ob-
are motivated by existing humor theories, based on patterns
jects in the scene contribute to humor and what they can be
that we observe in funny scenes, and the audio-visual humor
typology by buijzen et al. [9]: person doing something un-
replaced with to reduce/eliminate humor, while keeping the
usual, animal doing something unusual, clownish behavior
underlying structure of the scene the same. we ask work-
(i.e., goo   ness), too many objects, somebody getting hurt,
ers to replace an object with another object that is as similar
somebody getting scared and somebody getting angry.
as possible to the    rst object and keep the scene realistic.
this helps us understand    ne-grained semantics that causes
a speci   c object category to contribute to humor. there
could be other ways to manipulate humor, e.g., by adding,
removing, or moving objects in a scene, etc. but in our work
we employ only the technique of replacing objects. we    nd
that this technique is very effective in altering the funniness
of a scene. our interface did not allow people to add, re-
move, or move the objects in the scene. a screenshot of
the interface used to collect this dataset is available on the
project webpage.

we choose a subset of 200 funny scenes from the avh
dataset. we show each of these scenes to 10 different amt
workers and ask them to choose all the humor techniques
that are depicted. our options also included none of the
above reasons, which also prompted workers to brie   y ex-
plain what other unlisted technique depicted in the scene
made it funny. however, we observe that this option was
rarely used by workers. this may indicate that most of our
scenes can be explained well by one of the listed humor
techniques. fig. 3 shows the top voted images correspond-
ing to the 4 most popular techniques of humor. we    nd
that the techniques that involve animate objects     animal
doing something unusual and person doing something un-
usual are voted higher than any other technique by a large
margin. for 75% of the scenes, at least 3 out of 10 workers
picked one of these two techniques. we observe that this
unusualness or incongruity is generally caused by objects
occurring in an unusual context in the scene.

for each of the 3,028 funny scenes in the avh dataset,
we collect object-replaced scenes from 5 different workers
resulting in 15,140 unfunny counterpart scenes. as a san-
ity check, we collect funniness ratings (via amt) for 750
unfunny counterpart scenes. we observe that they indeed
have an average fi of 1.10, which is smaller than that of
their corresponding original funny scenes (whose average
fi is 2.66). fig. 4 shows two pairs of funny scenes and
their object-replaced unfunny counterparts. we refer to this
dataset as the for dataset.

given the task posed to workers (altering a funny scene
to make it unfunny), it is natural to use this dataset to train a
model to reduce the humor in a scene. however, this dataset
can also be used to train    ipped models that can increase the
humor in a scene as shown in sec. 5.2.3.

4. approach

we propose and model two tasks that we believe demon-

strate an understanding of some aspects of visual humor:
1. predicting how funny a given scene is.
2. altering the funniness of a scene.
the models that perform the above tasks are described in
sec. 4.2 and sec. 4.3, respectively. the features used in the
models are described    rst (sec. 4.1).
4.1. features

abstract scenes are trivially densely annotated which we
use to compute rich semantic features. recall that our in-
terface allows two types of scenes (indoor and outdoor) and

introducing or eliminating incongruities can alter the
funniness of a scene. an elderly person kicking a football
while simultaneously skateboarding (fig. 4, bottom) is in-
congruous and hence considered funny. however, when the
person is replaced by a young girl, this is is not incongruous
and hence not funny. such incongruities that can alter the
funniness of a scene serves as our motivation to collect the
funny object replaced dataset which we describe next.

3.3. funny object replaced (for) dataset

replacing objects in a scene is a technique to manipulate
incongruities (and hence funniness) in a scene. for instance,
we can change funny interactions (which are unexpected by
our common sense) to interactions that are normal accord-
ing to our mental model of the world. we use this technique
to collect a dataset which consists of funny scenes and their
altered unfunny counterparts. this enables the study of hu-
mor in a scene at the object-level.

we show funny scenes from the avh dataset and ask
amt workers to make the least number of replacements in
the scene to render the originally funny scene unfunny. the

figure 3: top voted scenes by humor technique (sec. 3.2). from left to right: animal doing something unusual, person doing
something unusual, somebody getting hurt, and somebody getting scared.

2. scene-level features
(a) cardinality (150-d) is a bag-of-words representation
that indicates the number of instances of each object cate-
gory that are present in the scene.
(b) location (300-d) is a vector of the horizontal and verti-
cal coordinates of every object in the scene. when multiple
instances of an object category are present, we consider lo-
cation of the instance closest to the center of the scene.
(c) scene embedding (150-d) is the sum of object embed-
dings of all objects present in the scene.
4.2. predicting funniness score

we train a support vector regressor (svr) that predicts
the funniness score, fi for a given scene i. the model
regresses to the fi computed from ratings given by amt
workers (described in sec. 3.2) on scenes from the avh
dataset (sec. 3.2). we train the svr on the scene-level fea-
tures (described in sec. 4.1) and perform an ablation study.
4.3. altering funniness of a scene

we learn models to alter the funniness of a scene     from
funny to unfunny and vice versa. our two-stage pipeline
involves:
1. detecting objects that contribute to humor.
2. identifying suitable replacement objects from 1. to make
the scene unfunny (or funny), while keeping it realistic.
detecting humor. we train a multi-layer id88
(mlp) on scenes from the for dataset to make a binary
prediction on each object instance in the scene     whether
it should be replaced to alter the funniness of a scene or
not. the input is a 300-d vector formed by concatenating
object embedding and local embedding features. the mlp
has two hidden layers comprising of 300 and 100 units re-
spectively, to which relu activation is applied. the    nal
layer has 2 neurons and is used to perform binary classi   -
cation (replace or not) using cross-id178 loss. we train
the model using sgd with a base learning rate of 0.01 and
momentum of 0.9. we also trained a model with skip-
connections that considers the predictions made on other
objects when making a prediction on a given object. how-
ever, this did not result in signi   cant performance gains.
altering humor. we train an mlp to perform a 150-way
classi   cation to predict potential replacer objects (from the

figure 4: funny scenes (left) and one among the 5 corre-
sponding object-replaced unfunny counterparts (right) from
the for dataset (see sec. 3.3). for each funny scene, we
collect an unfunny counterpart from a different worker.

our vocabulary consists of 150 object categories. we com-
pute both scene-level and instance-level features.
1. instance-level features
(a) object embedding (150-d) is a distributed represen-
tation that captures the context in which an object cate-
gory usually occurs. we learn this representation using a
id97-style continuous bag-of-words model [35]. the
model tries to predict the presence of an object category in
the scene, given the context provided by other instances of
objects in the scene. speci   cally, in a scene, given 5 (ran-
domly chosen) instances, the model tries to predict the ob-
ject category of the 6th instance. we train the single-layer
(150-d) neural network [34] with multiple 6-item subsets of
instances from each scene. the network is trained using
stochastic id119 (sgd) with a momentum of
0.9. we use 11k scenes (that were not intended to be funny)
from the dataset collected in [1] to train the model. thus, we
learn representations of objects occurring in natural contexts
which are not funny. a visualization of the object embed-
dings is available on the project webpage.
(b) local embedding (150-d) for each instantiation of an
object in the scene, we compute a weighted sum of object
embeddings of all the other instances in the scene. the
weight of every other instance is its inverse square-root
distance w.r.t. the instance under consideration.

clipart vocabulary), given an object predicted to be replaced
in a scene. the model   s input is a 300-d vector formed by
concatenating local embedding and object embedding fea-
tures. the classi   er has 3 hidden layers of 300 units each,
with relu non-linearities. the output layer has 150 units
over which we compute soft-max loss. we train the model
using sgd with a base learning rate of 0.1, momentum of
0.9, and a dropout ratio of 0.5. the label for an instance is
the index of the replacer object category used by the worker.
due to the large diversity of viable replacer objects that can
alter humor in a scene, we also analyze the top-5 predictions
of this model. we train two models     one on funny scenes,
and another on their unfunny counterparts from the for
dataset. thus, we learn models to alter the funniness in a
scene in one direction     funny to unfunny or vice versa. al-
though we could train the pipeline end-to-end, we train each
stage separately so that we can evaluate them separately and
isolate their errors (for better interpretability).

5. results

we discuss the performance of our models in the two

visual humor tasks of:

1. predicting how funny a given scene is (sec. 5.1)
2. altering funniness of a scene (sec. 5.2).

we discuss the quantitative results of our model in altering
an unfunny scene to make it funny in sec. 5.2.2), and the
vice versa in sec. 5.2.3. in sec. 5.3, we report qualitative
results through human studies.

5.1. predicting funniness score

this section presents performance of the svr (sec. 4.2)

that predicts the funniness score fi of a scene.
metric. we use average relative error to quantify our
model   s performance computed as follows:

n(cid:88)

1
n

|p redicted fi     ground t ruth fi|

i=1

ground t ruth fi

(1)

where n is the number of test scenes and fi is the funniness
score for the test scene i.
baseline: the baseline model always predicts the average
funniness score of the training scenes.
model. as shown in table 1, we observe that our model
trained using combinations of different scene-level features
(described in sec. 4.1) performs better than the baseline
model. we see that location features perform slightly bet-
ter than cardinality. this makes sense because location
features also have occurrence information. the embedding
does not have location information and hence does worse.
due to some redundancy (all features have occurrence in-
formation), combining them does not improve performance.

features
avg. prediction baseline
embedding
cardinality
location
embedding + cardinality + location

avg. rel. err.
0.3151
0.2516
0.2450
0.2400
0.2400

table 1: performance of different feature combinations in
predicting funniness score fi of a scene.

5.2. altering funniness of a scene

we discuss the performance in the tasks of identifying
objects in a scene that contribute to humor (sec. 4.2) and
replacing those objects with other objects to reduce (or in-
crease) humor (sec. 4.3).
5.2.1 predicting objects to be replaced

we train this model to detect objects instances that are funny
in the scene. it makes a binary prediction whether each in-
stance should be replaced or not.
metric. along with na    ve accuracy (% of correct predic-
tions, i.e., acc.), we also report average class-wise accuracy
(i.e., avg. cl. acc.) to determine the performance of our
model for this task. as the data is skewed, with the major-
ity class being not-replace, we require our model to perform
well both class-wise and as a whole.
baselines:
1. priors. we always predict that an instance should not
be replaced. we also compute a stronger baseline that
replaces an object if it is replaced at least t% of the time
in training data. t was set to 20 based on the validation
set.

2. anomaly detection. from the scene embedding, we
subtract the object embedding of the object under con-
sideration. we then compute the cosine similarity of the
resultant scene embedding with the object embedding.
objects with the least similarity with the scene are the
anomalous objects in the scene. this is similar to    nd-
ing the odd-one-out given a group of words [34]. objects
that have a cosine similarity less than a threshold t with
the scene are predicted as anomalous objects and are re-
placed. a modi   cation to this baseline is to replace k
objects that are least similar to the scene. based on per-
formance on the validation set, t and k are determined
to be 0.8 and 4, respectively.

model. table 2 compares the performance of our model
with the baselines described above. we observe that the
baseline based on priors performs better than anomaly de-
tection. this is perhaps not surprising because the prior-
based baseline, while na    ve, is    supervised    in the sense
that it relies on statistics from the training dataset of which
objects tend to get replaced. on the other hand, anomaly
detection is completely unsupervised since it only captures
the context of objects in normal scenes. our approach per-

method
priors (do not replace)
priors (object   s tendency to be replaced)
anomaly detection (threshold distance)
anomaly detection (top-k objects)
our model

avg. cl. acc. acc.
50% % 79.86%
73.13 % 71.5%
62.16 % 58.30%
63.01 % 64.31%
74.45% 74.74%

table 2: performance of predicting whether an object
should be replaced or not, for the task of altering a funny
scene to make it unfunny. as the data is skewed with the
majority class being    not-replace   , we require our model to
perform well both class-wise and as a whole.

forms better than the baseline approaches in identifying ob-
jects that contribute to humor.

on average, we observe that our model replaces 3.67 ob-
jects for a given image as compared to an average of 2.54
objects replaced in the ground truth. this bias to replace
more objects ensures that a given scene becomes signi   -
cantly less funny than the original scene. we observe that
the model learns that in general, animate objects like hu-
mans and animals are potentially stronger sources of humor
compared to inanimate objects. it is interesting to note that
the model also learns    ne-grained detail, e.g., to replace
older people playing outdoors (which may be considered
funny) with younger people (fig. 5, top row).

5.2.2 making a scene unfunny
given that an object is predicted to be replaced in the scene,
the model has to also predict a suitable replacer object. in
this section, we discuss the performance of the model in
predicting these replacer objects. this model is trained and
evaluated using ground truth annotations of objects that are
replaced by humans in a scene. this helps us isolate per-
formance between predicting which objects to replace and
predicting suitable replacers .
metric. in order to evaluate the performance of the model
on the task of replacing funny objects in the scene to make
it unfunny, we use the top-5 metric (similar to id163
[46]), i.e., if any of our 5 most con   dent predictions match
the ground truth, we consider that as a correct prediction.
baselines:
1. priors. every object is replaced by one of its 5 most

frequent replacers in the training set.

2. anomaly detection. we subtract the embedding of the
object that is to be replaced from the scene embedding.
the 5 objects from the clipart vocabulary that are most
similar (in the embedding space) to this resultant scene
embedding are the ones that contextually       t in   .

model. we observe that the performance trend in table 3 is
similar to that observed in the previous section (sec. 5.2.1),
i.e., our model performs better than priors, which performs
better than anomaly detection. by qualitative inspection, we

method
priors (top 5 gt replacers)
anomaly detection (object that       ts    into scene)
our model

top-5 accuracy
24.53%
7.69%
29.65%

table 3: performance of predicting which object to replace
with, for the task of altering a funny scene to make it un-
funny.

figure 5: fully automatic result of altering an input funny
scene (left) into an unfunny scene (right).

   nd that our top prediction is intelligent, but lazy. it elimi-
nates humor in most scenes by choosing to replace objects
contributing to humor with other objects that blend well into
the background. by relegating an object to the background,
it is rendered inactive and hence, cannot be contribute to hu-
mor in the scene. for e.g., the top prediction is frequently
   plant    in indoor scenes and    butter   y    in outdoor scenes.
the 2nd prediction is both intelligent and creative. it ef-
fectively reduces humor while also ensuring diversity of re-
placer objects. subsequent predictions from the model tend
to be less meaningful. qualitatively, we    nd the 2nd most
con   dent prediction to be the best compromise.
full pipeline. fig. 5 shows qualitative results from our full
pipeline (predicting objects to replace and predicting their
replacers) using the 2nd predictions made by our model.

5.2.3 making a scene funny

we train our full pipeline model used in sec. 5.2.2 on scenes
from the for dataset to perform the task of altering an un-
funny scene to make it funny. some qualitative results are
shown in fig. 6.

5.3. human evaluation

we conducted two human studies to evaluate our full

pipeline:
1. absolute: we ask 10 workers to rate the funniness of
the scene predicted by our model on a scale of 1-5. we
then compare this with the fi of the input funny scene.

afford us    suspension of reality   . unlike real images, the
content depicted in an abstract scene is benign. thus, peo-
ple are likely to    nd the depiction more funny [30]. in our
everyday lives, we come across a signi   cant amount of hu-
morous content in the form of comics and cartoons to which
our computational models of humor are directly applicable.
they can also be applied to learn semantics that can extend
to photorealistic images as demonstrated by antol et al. [2].
recognizing funniness involves violation of our mental
model of how the world    ought to be    [31]. in verbal hu-
mor, the    rst few lines of the joke (set-up) build up the world
model and the last line (punch line) goes against it. it is un-
clear what forms our mental model when we look at images.
is it our priors about the world around us formed from our
past experiences? is it because we attend to different re-
gions of the image when we look at it and gradually build
an expectation of what to see in the rest of the image? these
are some interesting questions regarding visual humor that
remain unanswered.
7. conclusion

in this work, we take a step towards understanding and
predicting visual humor. we collect two datasets of abstract
scenes which enable the study of humor at different lev-
els of granularity. we train a model to predict the funni-
ness score of a given scene. we also explore the different
sources of humor depicted in the funny scenes via human
studies. we train models using incongruity-based humor to
alter a scene   s funniness. the models learn that in general,
animate objects like humans and animals contribute more
to humor compared to inanimate objects. our model out-
performs a strong anomaly detection baseline, demonstrat-
ing that detecting humor involves something more than just
anomaly detection. in human studies of the task of making
an originally funny scene unfunny, humans    nd our model   s
output to be less funny 95% of the time.
in the task of
making a normal scene funny, our evaluation can be inter-
preted as a turing test of sorts. scenes made funny by our
model were found to be funnier 28% of the time when com-
pared with the original funny scenes created by workers.
note that our model would match humans at 50%. we hope
that addressing the problem of studying visual humor using
abstract scenes and the two datasets that are made public
would stimulate further research in this new direction.
acknowledgements. we thank the anonymous reviewers
for their valuable comments and suggestions. this work
was supported in part by the paul g. allen family foun-
dation via an award to d.p. db was partially supported
by the national science foundation career award, the
army research of   ce yip award, and an of   ce of naval
research grant n00014-14-1-0679. the views and conclu-
sions contained herein are those of the authors and should
not be interpreted as necessarily representing the of   cial
policies or endorsements, either expressed or implied, of the

figure 6: fully automatic result of altering an input unfunny
scene (left) into a funny scene (right).

2. relative: we show 5 workers the input scene and the
predicted scene (in random order) and ask them to indi-
cate which scene is funnier.

funny to unfunny. as expected, the output scenes from
our model are less funny than the input funny scenes on
average. the average fi of the input funny test scenes is
2.69. this is 1.05 points higher than the output unfunny
scenes whose average fi is 1.64. unsurprisingly, in relative
evaluation, workers    nd our output scenes to be less funny
than the input funny scenes 95% of the time.
unfunny to funny. during absolute evaluation, we    nd that
the average fi of scenes made funny by our model is 2.14.
this is a relatively high score, considering that the average
fi score of the corresponding originally funny scenes that
were created by workers is 2.69. interestingly, the relative
evaluation can be perceived as a turing test of sorts, where
we show workers the model   s output funny scene and the
original funny scene created by workers. 28% of the time,
workers picked the model   s scenes to be funnier.
6. discussion

humor is a subtle and complex human behavior.

it
has many forms ranging from slapstick which has a sim-
ple physical nature, to satire which is nuanced and requires
an understanding of social context [58]. understanding the
entire spectrum of humor is a challenging task. it demands
perception of    ne-grained differences between seemingly
similar scenarios. e.g., a teenager falling off his skateboard
(such as in america   s funniest home videos2) could be
considered funny but an old person falling down the stairs is
typically horrifying. due to these challenges some people
even consider computational humor to be an    ai-complete   
problem [6, 22].

while understanding    ne-grained semantics is impor-
tant, it is interesting to note that there exists a qualitative
difference in the way humor is perceived in abstract and real
scenes. since abstract scenes are not photorealistic, they

2www.afv.com

u.s. government or any sponsor. we thank xinlei chen for
his work on earlier versions of the clipart interface.

overview of appendix

in the following appendix we provide:
i. inter-human agreement on funniness ratings in the ab-

stract visual humor (avh) dataset.

ii. details of the model architecture used to learn object

embeddings and visualizations of its embeddings.

iii. a sample of objects from the abstract scenes vocabu-

lary.

iv. examples of scenes from our datasets.
v. analysis of occurrences of different object types in

scenes from our datasets.

vi. the user interfaces used to collect scenes for the avh

and funny object replaced (for) datasets.

appendix i: inter-human agreement

in this section, we describe our experiment to determine
inter-human agreement in funniness ratings of scenes. the
abstract visual humor (avh) dataset contains 3,028 funny
scenes and 3,372 unfunny scenes that were created by ama-
zon mechanical turk (amt) workers. the funniness of
each scene in the dataset is rated by 10 different workers on
a scale of 1-5. we de   ne the funniness score of a scene,
as the average of all ratings for a scene. in this section, we
investigate the extent to which people agree regarding the
funniness of a scene.

perception of an image differs from one person to an-
other. moran et al. [37] treat humor appreciation by people
as a personality characteristic. we investigate to what extent
people agree how funny each scene in our dataset is. we
split the votes we received for each scene into two groups,
keeping each individual worker   s ratings in the same group
to the extent possible. we compute the funniness score of
each scene across workers in each group. we compute pear-
son   s correlation between the two groups. fig. 7 shows
a plot of pearson   s correlation (y-axis) vs. the number of
workers (x-axis). we can see that inter-human agreement
increases as we increase the number of workers in a group
and that the trend is gradually saturating. this indicates that
ratings from 10 workers is suf   cient to compute a reliable
funniness score.

we observed that the standard deviation among ratings
from 10 different workers for funny scenes is 1.09, and for
unfunny scenes is 0.73. i.e., people agree more on scenes
that are clearly not funny than on ones that are funny, match-
ing our intuition that humor is subjective, while the lack
thereof is not.

appendix ii: object embeddings

in this section, we describe our model that learns embed-
dings for clipart objects and present visualizations of these

figure 7: inter-human agreement (y-axis) as we collect fun-
niness ratings from more workers (x-axis). we see can see
that by 10 ratings, we are starting to saturate with high
agreement, indicating that 10 ratings is suf   cient for a re-
liable funniness score.

embeddings. we learn distributed representations for each
object category in the abstract scenes vocabulary using a
id97-style continuous bag-of-words model [35]. dur-
ing training, subsets of 6 objects are sampled from all of the
objects present in a scene and the model tries to predict one
of the objects, given the other 5. each object is assigned
a 150-d vector, which is randomly initialized. the vectors
corresponding to the 5 context objects are projected to an
embedding space via a single layer whose parameters are
shared between the 5 objects. this (randomly initialized)
layer consists of 150 hidden units without a non-linearity af-
ter it. the sum of these 5 object projections is used to com-
pute a softmax over the 150 classes in the object vocabulary.
using the correct label (i.e., the object category of the 6th
object), the cross-id178 loss is computed and backpropa-
gated to learn all network parameters. the model is trained
using stochastic id119 with a base learning rate
of 0.0001 and a momentum update of 0.9. the learning rate
was reduced by a factor of two after each epoch. a diagram
of the model can be seen in fig. 9.

the context provided by the 5 objects ensures that the
representations learnt re   ect the relationships between ob-
jects. i.e., objects that are semantically related tend to have
similar representations. we learn the    normal    embeddings
(i.e., the object embedding instance-level features from the
main paper) from 11k scenes collected by antol et al. [1].
as these scenes were not intended to be humorous, the rela-
tionships captured in the embeddings are the ones that occur
naturally in the abstract scenes world.

fig. 8 (left) is a id167 [12] visualization of the    nor-
mal    embeddings for the 75 most frequent objects in un-
funny scenes. in fig. 8 (right), we also visualize    humor   
embeddings, which were not used as features but provide us
with insights. these are learnt from the 3,028 funny scenes

figure 8: left. visualization of    normal    object embeddings of 75 most frequent objects in unfunny scenes. we see that
closely placed objects have semantically similar meanings. right. visualization of    humor    embeddings of 75 most frequent
objects in funny scenes. we see that objects that are close in the    humor    embedding space may be semantically very
different.

   dog    and    wine glass    are placed together at coordinates
(0, 0). these are placed far apart (at opposite ends) in the
   normal    embedding. however, in the    humor    embedding,
these two categories are extremely close to each other; even
closer than semantically similar categories like two breeds
of dogs. we hypothesize that this because our dataset con-
tains funny scenes consisting of dogs with wine glasses,
e.g., fig. 11b. it is interesting to note that    background   
objects that do not contribute to humor in a scene are also
placed together. for example,    chair   ,    couch   , and    win-
dow    are placed together in the    humor    embedding as well
(coordinates (4, 5)).

the understanding of semantically similar object cate-
gories that can occur in a context, represented by the    nor-
mal    embeddings, can be interpreted as a person   s mental
model of the world. the    humor    embeddings capture de-
viations or incongruities from this    normal    view that might
cause humor.

appendix iii: abstract scenes vocabulary

the abstract scenes interface developed by antol et
al. [1] consists of 20    deformable    humans, 31 animals in
different poses, and about 100 objects that can be found
in indoor scenes (e.g., couch, picture, doll, door, window,
plant,    replace) or outdoor scenes (e.g., tree, pond, sun,
clouds, bench, bike, camp   re, grill, skateboard). in addi-
tion to the 8 different expressions available for humans,

figure 9: the continuous bag-of-words model used to ob-
tain the object embeddings.

in the avh dataset.

we observe that the    normal    embeddings encode a no-
tion for which object categories occur in similar contexts.
we also observe that closely placed objects in the    normal   
embedding space have semantically similar meanings. for
instance, humans are clustered together around coordinates
(10, -7). interestingly,    dog    and    puppy    (coordinates (10,
-5)) are placed together and furniture like    chair   ,    book-
shelf   ,    armchair   , etc. are placed together (coordinates
(10, 5)). this follows from the distributional hypothesis,
which states that words which occur in the similar contexts
tend to have similar meanings [16, 21].
in contrast, in the    humor    embeddings, visualized in fig. 8
(right), we see that objects that are close in the embedding
space may be semantically very different. for instance,

figure 10: a subset of clipart objects from the abstract scenes vocabulary.

(a) 1.3

(b) 2.8

(c) 3.2

(d) 4.4

(e) 1.1

(f) 2.7

(g) 3.5

(h) 4.1

figure 11: spectrum of scenes from our avh dataset that are arranged in ascending order of funniness score (shown in the
sub-caption)

the ability to vary the pose of a human at a    ne-grained
level enables these abstract scenes to effectively capture
the semantics of a scene. the large clipart vocabulary (of
which only a fraction is shown to a worker during creation
of a scene) ensures diversity in the scenes being depicted.
a subset of objects from our abstract scenes vocabulary is
shown in fig. 10.

appendix iv: example scenes

in this section, we present examples of scenes that were
created using the abstract scenes interface. fig. 11, depicts
a spectrum of scenes from the avh dataset in ascending or-
der of funniness score. these scenes were created by amt
workers using the interface presented in fig. 15.

fig. 12 shows originally funny scenes (left) and their

unfunny counterparts (right) from the for dataset. amt
workers created the counterparts by replacing as few
objects in the originally funny scene such that the resulting
scene is not funny anymore. a screenshot of the interface
that was used to create the unfunny counterparts is shown
in fig. 16.

appendix v: object type occurrences

in this section, we    rst analyze the occurrence of each
object type in funny and unfunny scenes. we then ana-
lyze the most commonly cooccurring object types in funny
scenes as compared to unfunny scenes.
distribution of object types. we analyze the distribu-
tion of object types in funny and unfunny scenes across all
scenes in our dataset. we compute the frequency of appear-
ance of each object type in funny and unfunny scenes. we

figure 13: top 100 object pairs that have the highest prob-
abilities of cooccurring in a funny scene. please note that
repeated entries for an object type (e.g.,    dog   ), correspond
to slightly different versions (e.g., breeds) of the same ob-
ject type.

cooccurrence matrices     f and u, corresponding to funny
scenes and unfunny scenes, respectively. each element
in f and u corresponds to the count of the cooccurrence
of a pair of objects across all funny and unfunny scenes,
respectively. to enable the study of types of cooccurrences
that contribute to humor, we compute the id203 of a
scene being funny, given that a pair of objects cooccur in
f
the scene as
f+u, which is shown in fig. 13 for the top 100
probable combinations that exist in a funny scene. please
note that repeated entries for an object type (e.g.,    dog   ),
correspond to slightly different versions (e.g., breeds) of
the same object type. an interesting set of object pairs that
are present in funny scenes are    rat    appearing alongside
   kitten   ,    cat   ,    stool   , and    dog   . another interesting
set of combinations is    raccoon    cooccurring with    bee   ,
   hamburger   ,    basket   , and    wine glass   . we observe that
this matrix captures interesting and unusual combinations
of objects that appear together frequently in funny scenes.

appendix vi: user interfaces

in this section, we present the user interfaces that were
used to collect data from amt. fig. 15 shows a screenshot
of the user interface that we used to collect funny scenes.
objects in the clipart library (on the right in the screenshot)
can be dragged on to any part of the empty canvas shown in
the    gure. the pose,    ip (i.e., lateral orientation), and size

figure 12: some example originally funny scenes (left) and
their object-replaced unfunny counterparts (right) from the
for dataset.

use this to compute the id203 of a scene being funny,
given that an object is present in the scene, which is shown
in blue in fig. 14. since we have more unfunny scenes than
funny scenes, we use normalized counts.

we observe that the humans that most appear in funny
scenes are elderly people. this is probably because a
number of scenes in our dataset depict old men behaving
unexpectedly, e.g., dancing or playing in the park as shown
in fig. 11c, which is funny. interestingly, we also observe
that in general, animals appear more frequently in funny
scenes. animals like    mouse   ,    rat   ,    raccoon    and    bee   
appear in funny scenes signi   cantly more than they do in
unfunny scenes. other objects having a strong bias towards
appearing in funny scenes include    wine bottle   ,    pen   ,
   scissors   ,    tape   ,    game    and    beehive   . thus, we see
that certain object types have a tendency to appear in funny
scenes. a possible reason for this is that these objects are
involved in funny interactions, or are intrinsically funny,
and hence contribute to humor in these scenes.
funny cooccurrence matrix. we populate two object

of all objects can be changed once they are placed in the
scene. in the case of humans, one of 8 expressions must be
chosen (initially humans have blank faces) and    ne-grained
pose adjustments are required.

fig. 16 shows the interface that we used to collect
   object-replaced    scenes for our for dataset. we showed
workers an originally funny scene and asked them to replace
objects in that scene so that the scene is not funny anymore.
on clicking an object in the original scene, the object gets
highlighted in green. a replacer object can then be cho-
sen from the clipart library (displayed on the right in the
screenshot). objects that are replaced in the original scene
show up in the empty canvas below. at any point, to undo
a replacement, a user can click on the object in the below
canvas and the corresponding object will be placed at its
original position in the scene. the interface does not allow
for the movement or the removal of objects.

figure 14: id203 of scene being funny, given object.

figure 15: user interface used to create the funny scenes in the avh dataset.

figure 16: user interface to replace objects for the for dataset.

references
[1] s. antol, a. agrawal, j. lu, m. mitchell, d. batra, c. l. zitnick, and
d. parikh. vqa: visual id53. in iccv, 2015. 1, 3,
5, 9, 10

[2] s. antol, c. l. zitnick, and d. parikh. zero-shot learning via visual
abstraction. in european conference on id161, eccv,
2014. 1, 3, 8

[3] aristotle and r. mckeon. the basic works of aristotle. modern

library, 2001. 2

[4] s. attardo. linguistic theories of humor. walter de gruyter, 1994. 1
[5] bharata-muni and m. ghosh. natya shastra (with english transla-

tions). 1951. 2

[6] k. binsted, b. bergen, d. o   mara, s. coulson, a. nijholt, o. stock,
c. strapparava, g. ritchie, r. manurung, and h. pain. computa-
tional humor. ieee intelligent systems, 2006. 8

[7] k. binsted and g. ritchie. computational rules for generating pun-
ning riddles. humor: international journal of humor research,
1997. 2

[8] e. r. bressler, r. a. martin, and s. balshine. production and appre-
ciation of humor as sexually selected traits. evolution and human
behavior, 2006. 1

[9] m. buijzen and p. m. valkenburg. developing a typology of humor

in audiovisual media. media psychology, 2004. 2, 4

[10] d. m. buss. the evolution of human intrasexual competition: tactics
of mate attraction. journal of personality and social psychology,
1988. 1

[11] d. davidov, o. tsur, and a. rappoport. semi-supervised recogni-
tion of sarcastic sentences in twitter and amazon. in conference on
computational natural language learning, 2010. 2

[12] l. v. der maaten and g. hinton. visualizing data using id167. jour-

nal of machine learning research, 2008. 9

[13] a. deza and d. parikh. understanding image virality. in ieee con-
ference on id161 and pattern recognition, cvpr, 2015.
3

[14] r. l. duran. communicative adaptability: a measure of social com-

municative competence. communication quarterly, 1983. 1

[15] r. l. duran. communicative adaptability: a review of conceptual-

ization and measurement. communication quarterly, 1992. 1

[16] j. r. firth. a synopsis of linguistic theory. blackwell, 1957. 10
[17] d. f. fouhey and c. l. zitnick. predicting object dynamics in scenes.
in ieee conference on id161 and pattern recognition,
cvpr, 2014. 1, 3

[18] s. freud. the joke and its relation to the unconscious. penguin,

2003. 2

[19] j. d. goodchilds, j. goldstein, and p. mcghee. on being titty:
causes, correlates, and consequences. the psychology of humor:
theoretical perspectives and empirical issues, 1972. 1

[20] m. gygli, h. grabner, h. riemenschneider, f. nater, and l. gool.
the interestingness of images. in proceedings of the ieee interna-
tional conference on id161, 2013. 3

[21] z. s. harris. distributional structure. word, 10 (2-3): 146   162.
reprinted in fodor, j. a and katz, jj (eds.), readings in the philosophy
of language, 1954. 10

[22] m. m. hurley, d. c. dennett, and r. b. adams. inside jokes: using

humor to reverse-engineer the mind. mit press, 2011. 8

[23] p. isola, d. parikh, a. torralba, and a. oliva. understanding the

intrinsic memorability of images. in nips, 2011. 3

[24] a. khosla, a. das sarma, and r. hamid. what makes an image
popular? in international conference on world wide web, 2014. 3
[25] s. kottur, r. vedantam, j. m. moura, and d. parikh. visual id97
(vis-w2v): learning visually grounded id27s using ab-
stract scenes. 2015. 1, 3

[26] x. lin and d. parikh. don   t just listen, use your imagination: lever-
aging visual common sense for non-visual tasks. in ieee conference
on id161 and pattern recognition, cvpr, 2015. 1, 3

[27] a. mahapatra and j. srivastava. incongruity versus incongruity res-
in proceedings of the 2013 international conference on

olution.
social computing, 2013. 2

[28] r. a. martin and n. a. kuiper. daily occurrence of laughter: re-
lationships with age, gender, and type a personality. humor, 1999.
1

[29] p. e. mcghee. chapter 5: the contribution of humor to children   s
social development. journal of children in contemporary society,
1989. 1

[30] a. p. mcgraw and c. warren. benign violations making immoral

behavior funny. psychological science, 2010. 8

[31] r. mihalcea. the multidisciplinary facets of research on humour. in
international workshop on fuzzy logic and applications, 2007. 2, 8
[32] r. mihalcea and s. pulman. characterizing humour: an exploration
of features in humorous texts. computational linguistics and intel-
ligent text processing, 2007. 2

[33] r. mihalcea and c. strapparava. making computers laugh: investi-

gations in automatic humor recognition. in emnlp, 2005. 2

[34] t. mikolov, k. chen, g. corrado, and j. dean. ef   cient esti-
arxiv preprint

mation of word representations in vector space.
arxiv:1301.3781, 2013. 5, 6

[35] t. mikolov, i. sutskever, k. chen, g. s. corrado, and j. dean. dis-
tributed representations of words and phrases and their composition-
ality. in advances in neural information processing systems, 2013.
5, 9

[36] d. mobbs, m. d. greicius, e. abdel-azim, v. menon, and a. l.
reiss. humor modulates the mesolimbic reward centers. neuron,
2003. 1

[37] j. m. moran, m. rain, e. page-gould, and r. a. mar. do i amuse
you? asymmetric predictors for humor appreciation and humor pro-
duction. journal of research in personality, 2014. 9

[38] m. p. mulder and a. nijholt. humor research: state of the art.
university of twente, centre for telematics and information tech-
nology, 2002. 2

[39] b. i. murstein and r. g. brust. humor and interpersonal attraction.

journal of personality assessment, 1985. 1

[40] s. petrovic and d. matthews. unsupervised joke generation from big

data. in acl, 2013. 2

[41] plato, e. hamilton, and h. cairns. the collected dialogues of plato,

including the letters. pantheon books, 1961. 2

[42] b. plester. healthy humour: using humour to cope at work. new

zealand journal of social sciences online, 2009. 1

[43] d. radev, a. stent, j. tetreault, a. pappu, a. iliakopoulou, a. chan-
freau, p. de juan, j. vallmitjana, a. jaimes, and r. jha. humor in
collective discourse: unsupervised funniness detection in the new
yorker cartoon caption contest. arxiv preprint arxiv:1506.08126,
2015. 2

[44] p. rinck. magnetic resonance in medicine. the basic textbook of the

european magnetic resonance forum. 8th edition; 2014. 1

[45] w. ruch, s. attardo, and v. raskin. toward an empirical veri   cation
of the general theory of verbal humor. humor: international journal
of humor research, 1993. 1, 2

[46] o. russakovsky, j. deng, h. su, j. krause, s. satheesh, s. ma,
id163
international journal of

z. huang, a. karpathy, a. khosla, m. bernstein, et al.
large scale visual recognition challenge.
id161, 2015. 7

[47] p. salovey, a. j. rothman, j. b. detweiler, and w. t. steward. emo-

tional states and physical health. american psychologist, 2000. 1

[48] a. salvatore and v. raskin. script rheory revisited: joke similar-
ity and joke representation model. humor-international journal of
humor research, 1991. 1, 2

[49] d. shahaf, e. horvitz, and r. mankoff.

humorous cartoon captions.
on knowledge discovery and data mining, 2015. 2

inside jokes: identifying
in sigkdd international conference

[50] g. sinicropi. la struttura della parodia    avvero: bradamante in arli.

strumenti critici torino, 1981. 1

[51] o. stock and c. strapparava. hahacronym: a computational hu-

mor system. in acl, 2005. 2

[52] j. m. suls. a two-stage model for the appreciation of jokes and
cartoons: an information-processing analysis. the psychology of
humor: theoretical perspectives and empirical issues, 1972. 2

[53] j. taylor and l. mazlack. computationally recognizing wordplay in

jokes. proceedings of cogsci, 2004. 2

[54] r. vedantam, x. lin, t. batra, c. l. zitnick, and d. parikh. learning

common sense through visual abstraction. in iccv, 2015. 1, 3

[55] w. y. wang and m. wen. i can has cheezburger? a nonparanormal
approach to combining textual and visual information for predicting
and generating popular meme descriptions. in naacl, 2015. 2

[56] m. b. wanzer, m. booth-butter   eld, and s. booth-butter   eld. are
funny people popular? an examination of humor orientation, loneli-
ness, and social attraction. communication quarterly, 1996. 1

[57] k. k. watson, b. j. matthews, and j. m. allman. brain activation
during sight gags and language-dependent humor. cerebral cortex,
2007. 1

[58] wikipedia. humor, november 2015. 8
[59] wikipedia. theories of humor, april 2016. 2
[60] d. yang, a. lavie, c. dyer, and e. hovy. humor recognition and

humor anchor extraction. 2015. 2

[61] c. l. zitnick and d. parikh. bringing semantics into focus using
visual abstraction. in ieee conference on id161 and pat-
tern recognition, cvpr, 2013. 1, 3

[62] c. l. zitnick, d. parikh, and l. vanderwende. learning the visual

interpretation of sentences. in iccv, 2013. 1, 3

[63] c. l. zitnick, r. vedantam, and d. parikh. adopting abstract images

for semantic scene understanding. pami, 2014. 3

