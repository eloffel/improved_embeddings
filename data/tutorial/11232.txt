id53 via integer programming over semi-structured knowledge
daniel khashabi   , tushar khot   , ashish sabharwal   , peter clark   , oren etzioni   , dan roth   

   university of illinois at urbana-champaign, il, u.s.a.

{khashab2,danr}@illinois.edu

   allen institute for arti   cial intelligence (ai2), seattle, wa, u.s.a.

{tushark,ashishs,peterc,orene}@allenai.org

6
1
0
2

 
r
p
a
0
2

 

 
 
]
i

a
.
s
c
[
 
 

1
v
6
7
0
6
0

.

4
0
6
1
:
v
i
x
r
a

abstract

answering science questions posed in natural lan-
guage is an important ai challenge. answering
such questions often requires non-trivial id136
and knowledge that goes beyond factoid retrieval.
yet, most systems for this task are based on rela-
tively shallow information retrieval (ir) and statis-
tical correlation techniques operating on large un-
structured corpora. we propose a structured in-
ference system for this task, formulated as an in-
teger linear program (ilp), that answers natural
language questions using a semi-structured knowl-
edge base derived from text, including questions
requiring multi-step id136 and a combination
of multiple facts. on a dataset of real, unseen
science questions, our system signi   cantly outper-
forms (+14%) the best previous attempt at struc-
tured reasoning for this task, which used markov
logic networks (mlns).
it also improves upon
a previous ilp formulation by 17.7%. when com-
bined with unstructured id136 methods, the ilp
system signi   cantly boosts overall performance
(+10%). finally, we show our approach is substan-
tially more robust to a simple answer perturbation
compared to statistical correlation methods.

1 introduction
answering questions posed in natural language is a funda-
mental ai task, with a large number of impressive qa sys-
tems built over the years. today   s internet search engines,
for instance, can successfully retrieve factoid style answers
to many natural language queries by ef   ciently searching the
web. information retrieval (ir) systems work under the as-
sumption that answers to many questions of interest are of-
ten explicitly stated somewhere [kwok et al., 2001], and all
one needs, in principle, is access to a suf   ciently large cor-
pus. similarly, statistical correlation based methods, such as
those using pointwise mutual information or pmi [church
and hanks, 1989], work under the assumption that many
questions can be answered by looking for words that tend to
co-occur with the question words in a large corpus.

while both of these approaches help identify correct an-
swers, they are not suitable for questions requiring reasoning,

figure 1: tableilp searches for the best support graph
(chains of reasoning) connecting the question to an answer,
in this case june. constraints on the graph de   ne what con-
stitutes valid support and how to score it (section 3.3).

such as chaining together multiple facts in order to arrive at a
conclusion. arguably, such reasoning is a cornerstone of hu-
man intelligence, and is a key ability evaluated by standard-
ized science exams given to students. for example, consider
a question from the ny regents 4th grade science test:

in new york state, the longest period of daylight oc-
curs during which month?
(a) june (b) march (c)
december (d) september

we would like a qa system that, even if the answer is not ex-
plicitly stated in a document, can combine basic scienti   c and
geographic facts to answer the question, e.g., new york is in
the north hemisphere; the longest day occurs during the sum-
mer solstice; and the summer solstice in the north hemisphere
occurs in june (hence the answer is june). figure 1 illustrates
how our system approaches this, with the highlighted support
graph representing its line of reasoning.

further, we would like the system to be robust under simple
perturbations, such as changing new york to new zealand
(in the southern hemisphere) or changing an incorrect answer
option to an irrelevant word such as    last    that happens to
have high co-occurrence with the question text.

to this end, we propose a structured reasoning system,
called tableilp, that operates over a semi-structured knowl-
edge base derived from text and answers questions by chain-
ing multiple pieces of information and combining parallel

q: in new york state, the longest  period of daylight occurs during which month?          subdivision country new york state usa california usa rio de janeiro brazil         orbital event day duration night duration summer solstice long short winter solstice short long    .    .     (a) december (b) june (c) march (d) september country hemisphere united states northern canada northern  brazil southern     ..      hemisphere orbital event month north summer solstice june north winter solstice december south summer solstice december south winter solstice june       semi-structured knowledge  evidence.1 the knowledge base consists of tables, each of
which is a collection of instances of an n-ary relation de   ned
over natural language phrases. e.g., as illustrated in figure 1,
a simple table with schema (country, hemisphere) might con-
tain the instance (united states, northern) while a ternary
table with schema (hemisphere, orbital event, month) might
contain (north, summer solstice, june). tableilp treats lex-
ical constituents of the question q, as well as cells of poten-
tially relevant tables t , as nodes in a large graph gq,t , and
attempts to    nd a subgraph g of gq,t that    best    supports
an answer option. the notion of best support is captured via
a number of structural and semantic constraints and prefer-
ences, which are conveniently expressed in the integer linear
programming (ilp) formalism. we then use an off-the-shelf
ilp optimization engine called scip [achterberg, 2009] to
determine the best supported answer for q.

following a recently proposed ai challenge [clark, 2015],
we evaluate tableilp on unseen elementary-school science
questions from standardized tests. speci   cally, we consider
a challenge set [clark et al., 2016] consisting of all non-
diagram multiple choice questions from 6 years of ny re-
gents 4th grade science exams. in contrast to a state-of-the-
art structured id136 method [khot et al., 2015] for this
task, which used markov logic networks (mlns) [richard-
son and domingos, 2006], tableilp achieves a signi   cantly
(+14% absolute) higher test score. this suggests that a
combination of a rich and    ne-grained constraint language,
namely ilp, even with a publicly available solver is more ef-
fective in practice than various mln formulations of the task.
further, while the scalability of the mln formulations was
limited to very few (typically one or two) selected science
rules at a time, our approach easily scales to hundreds of rel-
evant scienti   c facts. it also complements the kind of ques-
tions amenable to ir and pmi techniques, as is evidenced
by the fact that a combination (trained using simple logis-
tic regression [clark et al., 2016]) of tableilp with ir and
pmi results in a signi   cant (+10% absolute) boost in the score
compared to ir alone.

our ablation study suggests that combining facts from mul-
tiple tables or multiple rows within a table plays an important
role in tableilp   s performance. we also show that tableilp
bene   ts from the table structure, by comparing it with an ir
system using the same knowledge (the table rows) but ex-
pressed as simple sentences; tableilp scores signi   cantly
(+10%) higher. finally, we demonstrate that our approach
is robust to a simple perturbation of incorrect answer options:
while the simple perturbation results in a relative drop of 20%
and 33% in the performance of ir and pmi methods, respec-
tively, it affects tableilp   s performance by only 12%.

2 related work
clark et al. [2016] proposed an ensemble approach for
the science qa task, demonstrating the effectiveness of a
combination of information retrieval, statistical association,

1a preliminary version of our ilp model was used in the en-
semble solver of clark et al. [2016]. we build upon this earlier ilp
formulation, providing further details and incorporating additional
syntactic and semantic constraints that improve the score by 17.7%.

rule-based reasoning, and an ilp solver operating on semi-
structured knowledge. our ilp system extends their model
with additional constraints and preferences (e.g., semantic re-
lation matching), substantially improving qa performance.

a number of systems have been developed for answering
factoid questions with short answers (e.g.,    what is the cap-
ital of france?   ) using document collections or databases
(e.g., freebase [bollacker et al., 2008], nell [carlson et al.,
2010]), for example [brill et al., 2002; fader et al., 2014;
ferrucci et al., 2010; ko et al., 2007; yih et al., 2014;
yao and van durme, 2014; zou et al., 2014]. however,
many science questions have answers that are not explic-
itly stated in text, and instead require combining informa-
tion together. conversely, while there are ai systems for
formal scienti   c reasoning (e.g., [gunning et al., 2010;
novak, 1977]), they require questions to be posed in logic or
restricted english. our goal here is a system that operates be-
tween these two extremes, able to combine information while
still operating with natural language.

the task of recognizing id123 (rte) [da-
gan et al., 2010; dagan et al., 2013] is also closely related,
as qa can be cast as entailment (does corpus entail ques-
tion+answer? [bentivogli et al., 2008]). however, rte has
primarily focused on the task of linguistic equivalence, and
has not addressed questions where some form of scienti   c
reasoning is required. recent work on natural logic [angeli
and manning, 2014; maccartney, 2009] has extended rte to
account for the logical structure within language. our work
can be seen as going one step further, to add a layer of struc-
tured reasoning on top of this; in fact, we use an rte engine
as a basic subroutine for comparing individual table cells in
our ilp formulation.

ilp based discrete optimization has been successful in sev-
eral nlp tasks [roth and yih, 2004; chang et al., 2010;
berant et al., 2010; srikumar and roth, 2011; goldwasser
and roth, 2011]. while our ilp formulation also operates on
natural language text, our focus is on the use of a speci   c
semi-structured table representation for qa. cohen [2000]
studied tables with natural language text requiring soft match-
ing, with a focus on ef   ciently computing the top few candi-
dates given a database query. in contrast, our system, given
a natural language question, (implicitly) seeks to generate a
query that produces the most supported answer.

3 qa as subgraph optimization
we begin with our id99 formalism, fol-
lowed by our treatment of qa as an optimal subgraph selec-
tion problem over such knowledge, and then brie   y describe
our ilp model for subgraph selection.
3.1 semi-structured knowledge as tables
we use semi-structured knowledge represented in the form
of n-ary predicates over natural language text [clark et al.,
2016]. formally, a k-column table in the knowledge base is a
predicate r(x1, x2, . . . , xk) over strings, where each string is
a (typically short) natural language phrase. the column head-
ers capture the table schema, akin to a relational database.
each row in the table corresponds to an instance of this pred-

icate. for example, a simple country-hemisphere table repre-
sents the binary predicate rctry-hems(c, h) with instances such
as (australia, southern) and (canada, northern). since ta-
ble content is speci   ed in natural language, the same entity
is often represented differently in different tables, posing an
additional id136 challenge.

although techniques for constructing this knowledge base
are outside the scope of this paper, we brie   y mention them.
tables were constructed using a mixture of manual and semi-
automatic techniques. first, the table schemas were manu-
ally de   ned based on the syllabus, study guides, and train-
ing questions. tables were then populated both manually
and semi-automatically using ike [dalvi et al., 2016], a
table-building tool that performs interactive, bootstrapped
id36 over a corpus of science text.
in ad-
dition, to augment these tables with the broad knowledge
present in study guides that doesn   t always    t the manu-
ally de   ned table schemas, we ran an open ie [banko et
al., 2007] pattern-based subject-verb-object (svo) extractor
from clark et al. [2014] over several science texts to populate
three-column open ie tables. methods for further automating
table construction are under development.
3.2 qa as a search for desirable support graphs
we treat id53 as the task of pairing the ques-
tion with an answer such that this pair has the best support in
the knowledge base, measured in terms of the strength of a
   support graph    de   ned as follows.
given a multiple choice question q and tables t , we can
de   ne a labeled undirected graph gq,t over nodes v and
edges e as follows. we    rst split q into lexical constituents
(e.g., non-stopword tokens, or chunks) q = {q(cid:96)} and an-
swer options a = {am}. for each table ti, we consider
its cells t = {tijk} as well as column headers h = {hik}.
the nodes of gq,t are then v = q     a     t     h. for pre-
sentation purposes, we will equate a graph node with the
lexical entity it represents (such as a table cell or a ques-
tion constituent). the undirected edges of gq,t are e =
((q     a)    (t     h))     (t    t)     (h    h) excluding edges
both whose endpoints are within a single table.

informally, an edge denotes (soft) equality between a ques-
tion or answer node and a table node, or between two table
nodes. to account for lexical variability (e.g., that tool and in-
strument are essentially equivalent) and generalization (e.g.,
that a dog is an animal), we replace string equality with a
phrase-level entailment or similarity function w : e     [0, 1]
that labels each edge e     e with an associated score w(e).
we use entailment scores (directional) from q to t     h and
from t     h to a, and similarity scores (symmetric) between
two nodes in t.2 in the special case of column headers across
two tables, the score is (manually) set to either 0 or 1, indi-
cating whether this corresponds to a meaningful join.

2in our evaluations, w for entailment is a simple id138-based
[miller, 1995] function that computes the best word-to-word align-
ment between phrases, scores these alignments using id138   s
hypernym and synonym relations normalized using relevant word-
sense frequency, and returns the weighted sum of the scores. w for
similarity is the maximum of the entailment score in both directions.
alternative de   nitions for these functions may also be used.

element

description

ti
hik
tijk
rij
(cid:96)ik
q(cid:96)
am

table i
header of the k-th column of i-th table
cell in row j and column k of i-th table
row j of i-th table
column k of i-th table
(cid:96)-th lexical constituent of the question q
m-th answer option

table 1: notation for the ilp formulation.

intuitively, we would like the support graph for an answer
option to be connected, and to include nodes from the ques-
tion, the answer option, and at least one table. since each
table row represents a coherent piece of information but cells
within a row do not have any edges in gq,t (the same holds
also for cells and the corresponding column headers), we use
the notion of an augmented subgraph to capture the underly-
ing table structure. let g = (v, e) be a subgraph of gq,t .
the augmented subgraph g+ is formed by adding to g edges
(v1, v2) such that v1 and v2 are in v and they correspond to
either the same row (possibly the header row) of a table in t
or to a cell and the corresponding column header.
de   nition 1. a support graph g = g(q, t, am) for a ques-
tion q, tables t , and an answer option am is a subgraph
(v, e) of gq,t with the following basic properties:
1. v     a = {am}, v     q (cid:54)=   , v     t (cid:54)=   ;
2. w(e) > 0 for all e     e;
3. if e     e     (t    t) then there exists a corresponding

e(cid:48)     e     (h    h) involving the same columns; and

4. the augmented subgraph g+ is connected.
a support graph thus connects the question constituents to
a unique answer option through table cells and (optionally)
table headers corresponding to the aligned cells. a given
question and tables give rise to a large number of possible
support graphs, and the role of the id136 process will be
to choose the    best    one under a notion of desirable support
graphs developed next. we do this through a number of addi-
tional structural and semantic properties; the more properties
the support graph satis   es, the more desirable it is.
3.3
we model the above support graph search for qa as an ilp
optimization problem, i.e., as maximizing a linear objective
function over a    nite set of variables, subject to a set of linear
inequality constraints. a summary of the model is given be-
low. 3 we note that the ilp objective and constraints aren   t
tied to the particular domain of evaluation; they represent
general properties that capture what constitutes a well sup-
ported answer for a given question.

ilp formulation

table 1 summarizes the notation for various elements of the
problem, such as tijk for cell (j, k) of table i. all core vari-
ables in the ilp model are binary, i.e., have domain {0, 1}.
for each element, the model has a unary variable capturing
whether this element is part of the support graph g, i.e., it is

3details of the ilp model may be found in the appendix.

basic pairwise activity variables

y (tijk, tij(cid:48)k(cid:48) )
y (tijk, q(cid:96))
y (hik, q(cid:96))
y (tijk, am)
y (hik, am)
y ((cid:96)ik, am)
y (ti, am)
y ((cid:96)ik, (cid:96)ik(cid:48) )

cell to cell
cell to question constituent
header to question constituent
cell to answer option
header to answer option
column to answer option
table to answer option
column to column relation
high-level unary variables

x (ti)
x (rij)
x ((cid:96)ik)
x (hik)
x (q(cid:96))
x (am)

active table
active row
active column
active column header
active question constituent
active answer option

table 2: variables used for de   ning the optimization problem
for tableilp solver. all variables have domain {0, 1}.

   active   . for instance, row rij is active if at least one cell in
row j of table i is in g. the model also has pairwise    align-
ment    variables, capturing edges of gq,t . the alignment
variable for an edge e in gq,t is associated with the corre-
sponding weight w(e), and captures whether e is included in
g. to improve ef   ciency, we create a pairwise variable for
e only if w(e) is larger than a certain threshold. these unary
and pairwise variables are then used to de   ne various types
of constraints and preferences, as discussed next.

to make the de   nitions clearer, we introduce all basic vari-
ables used in our optimization in table 2, and will use them
later to de   ne constraints explicitly. we use the notation x (.)
to refer to a unary variable parameterized by a single element
of the optimization, and y (., .) to refer to a pairwise variable
parameterized by a pair of elements. unary variables repre-
sent the presence of a speci   c element as a node in the support
graph g. for example x (ti) = 1 if and only if the table ti
is active in g. similarly, y (tijk, q(cid:96)) = 1 if and only if the
corresponding edge is present in g, which we alternatively
refer to as an alignment between cell (j, k) of table i and the
(cid:96)-th constituent of the question.

as previously mentioned, in practice we do not create
all possible pairwise variables. instead we choose the pairs
alignment score w(e) exceeds a pre-set threshold. for ex-
ample, we create y (tijk, ti(cid:48)j(cid:48)k(cid:48)) only if w(tijk, ti(cid:48)j(cid:48)k(cid:48))    
mincellcellalignment.4

the objective function is a weighted linear sum over all
variables instantiated for a given id53 prob-
lem.5 a small set of auxiliary variables is de   ned for lin-
earizing complicated constraints.

constraints are a signi   cant part of our model, used for
imposing the desired behavior on the support graph. due to
lack of space, we discuss only a representative subset here.6

some constraints relate variables to each other. for exam-
ple, unary variables are de   ned through constraints that relate
them to the corresponding pairwise variables. for instance,
for active row variable x (rij), we ensure that it is 1 if and
only if at least one cell in row j is active:

x (rij)     y (tijk,   ) ,    (tijk,   )     rij,   i, j, k,

where rij is collection of pairwise variables with one end in
row j of table i.

in the remainder of this section, we outline some of the
important characteristics we expect in our model, and provide
details of a few illustrative constraints.
basic lookup
consider the following question:

which characteristic helps a fox    nd food? (a) sense of
smell (b) thick fur (c) long tail (d) pointed teeth

in order to answer such lookup-style questions, we generally
seek a row with the highest aggregate alignment to question
constituents. we achieve this by incorporating the question-
table alignment variables with the alignment scores, w(e), as
coef   cients and the active question constituents variable with
a constant coef   cient in the objective function. since any ad-
ditional question-table edge with a positive entailment score
(even to irrelevant tables) in the support graph would result in
an increase in the score, we disallow tables with alignments
only to the question (or only to a choice) and add a small
penalty for every table used in order to reduce noise in the
support graph. we also limit the maximum number of align-
ments of a question constituent and table cells, in order to
prevent one constituent or cell from having a large in   uence
on the objective function and thereby the solution:

y (   , q(cid:96))     maxalignmentsperqcons,   l

(cid:88)

(   ,q(cid:96))   ql

where ql is the set of all pairwise variables with one end in
the question constituent (cid:96).
parallel evidence
for certain questions, evidence needs to be combined from
multiple rows of a table. for example,

sleet, rain, snow, and hail are forms of (a) erosion (b)
evaporation (c) groundwater (d) precipitation

to answer this question, we need to combine evidence
from multiple table entries from the weather terms table,
(term, type), namely (sleet, precipitation), (rain, precipita-
tion), (snow, precipitation), and (hail, precipitation). to
achieve this, we allow multiple active rows in the support
graph. similar to the basic constraints, we limit the maxi-
mum number of active rows per table and add a penalty for
every active row to ensure only relevant rows are considered

for reasoning:(cid:88)

x (rij)     maxrowspertable,   i

4an exhaustive list of the minimum alignment thresholds for cre-

ating pairwise variables is in table 10 in the appendix.

5the complete list of weights for unary and pairwise variables is

included in table 9 in the appendix.

6the complete list of the constraints is explained in table 13 in

j

to encourage only coherent parallel evidence within a sin-
gle table, we limit our support graph to always use the same
the appendix.

columns across multiple rows within a table, i.e., every ac-
tive row has the active cells corresponding to the same set of
columns.

evidence chaining
questions requiring chaining of evidence from multiple ta-
bles, such as the example in figure 1, are typically the most
challenging in this domain. chaining can be viewed as per-
forming a join between two tables. we introduce alignments
between cells across columns in pairs of tables to allow for
chaining of evidence. to help minimize potential noise in-
troduced by chaining irrelevant facts, we add a penalty for
every inter-table alignment and also rely on the 0/1 weights
of header-to-header edges to ensure only semantically mean-
ingful table joins are considered.

semantic relation matching
our constraints so far have only looked at the content of the
table cells, or the structure of the support graph, without ex-
plicitly considering the semantics of the table schema. by
using alignments between the question and column headers
(i.e., type information), we exploit the table schema to prefer
alignments to columns relevant to the    topic    of the question.
in particular, for questions of the form    which x . . .   , we pre-
fer answers that directly entail x or are connected to cells that
entail x. however, this is not suf   cient for questions such as:

what is one way to change water from a liquid to a
solid? (a) decrease the temperature (b) increase the
temperature (c) decrease the mass (d) increase the
mass

even if we select the correct table, say rchange-init-   n(c, i, f )
that describes the initial and    nal states for a phase change
event, both choice (a) and choice (b) would have the exact
same score in the presence of table rows (increase tempera-
ture, solid, liquid) and (decrease temperature, liquid, solid).
the table, however, does have the initial vs.    nal state struc-
ture. to capture this semantic structure, we annotate pairs of
columns within certain tables with the semantic relationship
present between them. in this example, we would annotate
the phase change table with the relations: changefrom(c, i),
changeto(c, f ), and fromto(i, f ).

given such semantic relations for table schemas, we can
now impose a preference towards question-table alignments
that respect these relations. we associate each semantic rela-
tion with a set of linguistic patterns describing how it might
be expressed in natural language. tableilp then uses these
patterns to spot possible mentions of the relations in the
question q. we then add the soft constraint that for every
pair of active columns in a table (with an annotated seman-
tic relation) aligned to a pair of question constituents, there
should be a valid expression of that relation in q between
those constituents. in our example, we would match the re-
lation fromto(liquid, solid) in the table to    liquid to a solid   
in the question via the pattern    x to a y    associated with
fromto(x,y), and thereby prefer aligning with the correct
row (decrease temperature, liquid, solid).

4 evaluation
we compare our approach to three existing methods, demon-
strating that it outperforms the best previous structured ap-
proach [khot et al., 2015] and produces a statistically signif-
icant improvement when used in combination with ir-based
methods [clark et al., 2016]. for evaluations, we use a 2-core
2.5 ghz amazon ec2 linux machine with 16 gb ram.
question set. we use the same question set as clark et
al. [2016], which consists of all non-diagram multiple-choice
questions from 12 years of the ny regents 4th grade science
exams.7 the set is split into 108 development questions and
129 hidden test questions based on the year they appeared in
(6 years each). all numbers reported below are for the hidden
test set, except for question perturbation experiments which
relied on the 108 development questions.

test scores are reported as percentages. for each question,
a solver gets a score of 1 if it chooses the correct answer and
1/k if it reports a k-way tie that includes the correct answer.
on the 129 test questions, a score difference of 9% (or 7%) is
statistically signi   cant at the 95% (or 90%, resp.) con   dence
interval based on the binomial exact test [howell, 2012].
corpora. we work with three knowledge corpora:
1. web corpus: this corpus contains 5    1010 tokens (280
gb of plain text) extracted from web pages.
it was
collected by charles clarke at the university of water-
loo, and has been used previously by turney [2013] and
clark et al. [2016]. we use it here to compute statistical
co-occurrence values for the pmi solver.

2. sentence corpus [clark et al., 2016]: this includes sen-
tences from the web corpus above, as well as around
80,000 sentences from various domain-targeted sources
for elementary science: a regents study guide, ck12
textbooks (www.ck12.org), and web sentences with sim-
ilar content as the course material.

3. table corpus (cf. section 3.1): this includes 65 tables
totaling around 5,000 rows, designed based on the de-
velopment set and study guides, as well as 4 open ie-
style [banko et al., 2007] automatically generated tables
totaling around 2,600 rows.8

4.1 solvers

tableilp (our approach). given a question q, we select the
top 7 tables from the table corpus using the the standard
tf-idf score of q with tables treated as bag-of-words doc-
uments. for each selected table, we choose the 20 rows that
overlap with q the most. this    ltering improves ef   ciency
and reduces noise. we then generate an ilp and solve it us-
ing the open source scip engine [achterberg, 2009], return-
ing the active answer option am from the optimal solution. to
check for ties, we disable am, re-solve the ilp, and compare
the score of the second-best answer, if any, with that of am.

7these are the only publicly available state-level science exams.

http://www.nysedregents.org/grade4/science/home.html

8table corpus and the ilp model are available at allenai.org.

mln solver (structured id136 baseline). we consider
the current state-of-the-art structured reasoning method de-
veloped for this speci   c task by khot et al. [2015]. we com-
pare against their best performing system, namely praline,
which uses markov logic networks [richardson and domin-
gos, 2006] to (a) align lexical elements of the question with
probabilistic    rst-order science rules and (b) to control infer-
ence. we use the entire set of 47,000 science rules from their
original work, which were also derived from same domain-
targeted sources as the ones used in our sentence corpus.
ir solver (information retrieval baseline). we use the ir
baseline by clark et al. [2016], which selects the answer op-
tion that has the best matching sentence in a corpus. specif-
ically, for each answer option ai, the ir solver sends q + ai
as a query to a search engine (we use lucene) on the sen-
tence corpus, and returns the search engine   s score for the
top retrieved sentence s, where s must have at least one non-
stopword overlap with q, and at least one with ai. the option
with the highest lucene score is returned as the answer.
pmi solver (statistical co-occurrence baseline). we use the
pmi-based approach by clark et al. [2016], which selects the
answer option that most frequently co-occurs with the ques-
tion words in a corpus. speci   cally, it extracts unigrams,
bigrams, trigrams, and skip-bigrams from the question and
each answer option. for a pair (x, y) of id165s, their point-
wise mutual information (pmi) [church and hanks, 1989] in
the corpus is de   ned as log p(x,y)
p(x)p(y) where p(x, y) is the co-
occurrence frequency of x and y (within some window) in
the corpus. the solver returns the answer option that has the
largest average pmi in the web corpus, calculated over all
pairs of question id165s and answer option id165s.
4.2 results
we    rst compare the accuracy of our approach against the
previous structured (mln-based) reasoning solver. we also
compare against ir(tables), an ir solver using table rows
expressed as sentences, thus embodying an unstructured ap-
proach operating on the same knowledge as tableilp.

solver
mln
ir(tables)
tableilp

test score (%)

47.5
51.2
61.5

table 3: tableilp signi   cantly outperforms both the prior
mln reasoner, and ir using identical knowledge as tableilp

as table 3 shows, among the two structured id136 ap-
proaches, tableilp outperforms the mln baseline by 14%.
the preliminary ilp system reported by clark et al. [2016]
achieves only a score of 43.8% on this question set. fur-
ther, given the same semi-structured knowledge (i.e., the ta-
ble corpus), tableilp is substantially (+10%) better at ex-
ploiting the structure than the ir(tables) baseline, which, as
mentioned above, uses the same data expressed as sentences.
complementary strengths
while their overall score is similar, tableilp and ir-based
methods clearly approach qa very differently. to assess

whether tableilp adds any new capabilities, we considered
the 50 (out of 129) questions incorrectly answered by pmi
solver (ignoring tied scores). on these unseen but arguably
more dif   cult questions, tableilp answered 27 questions
correctly, achieving a score of 54% compared to the random
chance of 25% for 4-way multiple-choice questions. results
with ir solver were similar: tableilp scored 24.75 on the 52
questions incorrectly answered by ir (i.e., 47.6% accuracy).

solver
ir
pmi
tableilp
tableilp + ir
tableilp + pmi
tableilp + ir+ pmi

test score (%)

58.5
60.7
61.5
66.1
67.6
69.0

table 4: solver combination results

this analysis highlights the complementary strengths of
these solvers. following clark et al. [2016], we create an
ensemble of tableilp, ir, and pmi solvers, combining their
answer predictions using a simple id28 model
trained on the development set. this model uses 4 features
derived from each solver   s score for each answer option, and
11 features derived from tableilp   s support graphs. 9 table
4 shows the results, with the    nal combination at 69% repre-
senting a signi   cant improvement over individual solvers.
ilp solution properties
table 5 summarizes various ilp and support graph statistics
for tableilp, averaged across all test questions.

the optimization model has around 50 high-level con-
straints, which result, on average, in around 4000 inequalities
over 1000 variables. model creation, which includes comput-
ing pairwise entailment scores using id138, takes 1.9 sec-
onds on average per question, and the resulting ilp is solved
by the scip engine in 2.1 seconds (total for all four options),
using around 1,300 lp iterations for each option.10 thus,
tableilp takes only 4 seconds to answer a question using
multiple rows across multiple tables (typically 140 rows in
total), as compared to 17 seconds needed by the mln solver
for reasoning with four rules (one per answer option).

category

ilp complexity

knowledge use

timing stats

quantity
#variables
#constraints
#lp iterations
#rows
#tables
model creation
solving the ilp

average
1043.8
4417.8
1348.9

2.3
1.3

1.9 sec
2.1 sec

table 5: tableilp statistics averaged across questions

while the    nal support graph on this question set relies
mostly on a single table to answer the question, it generally

9details of the 11 features may be found in the appendix b.
10commercial ilp solvers (e.g., cplex, gurobi) are much faster

than the open-source scip solver we used for evaluations.

combines information from more than two rows (2.3 on av-
erage) for reasoning. this suggests parallel evidence is more
frequently used on this dataset than evidence chaining.
4.3 ablation study
to quantify the importance of various components of our sys-
tem, we performed several ablation experiments, summarized
in table 6 and described next.

solver

test score (%)

tableilp

no multiple row id136
no relation matching
no open ie tables
no lexical entailment

61.5
51.0
55.6
52.3
50.5

table 6: ablation results for tableilp

no multiple row id136: we modify the ilp constraints
to limit id136 to a single row (and hence a single table),
thereby disallowing parallel evidence and evidence chaining
(section 3.3). this drops the performance by 10.5%, high-
lighting the importance of being able to combine evidence
from multiple rows (which would correspond to multiple sen-
tences in a corpus) from one or more tables.
no relation matching: to assess the importance of consid-
ering the semantics of the table, we remove the requirement
of matching the semantic relation present between columns
of a table with its lexicalization in the question (section 3.3).
the 6% drop indicates tableilp relies strongly on the table
semantics to ensure creating meaningful inferential chains.
no open ie tables: to evaluate the impact of relatively un-
structured knowledge from a large corpus, we removed the
tables containing open ie extractions (section 3.2). the 9%
drop in the score shows that this knowledge is important and
tableilp is able to exploit it even though it has a very simple
triple structure. this opens up the possibility of extending our
approach to triples extracted from larger knowledge bases.
no lexical entailment: finally, we test the effect of chang-
ing the alignment metric w (section 3.2) from id138 based
scores to a simple asymmetric word-overlap measured as
. relying on just word-matching re-
score(t, h) =
sults in an 11% drop, which is consistent with our knowledge
often being de   ned in terms of generalities.
4.4 question perturbation
one desirable property of qa systems is robustness to simple
variations of a question, especially when a variation would
make the question arguably easier for humans.

|t   h|
|h|

to assess this, we consider a simple, automated way to
perturb each 4-way multiple-choice question: (1) query mi-
crosoft   s bing search engine (www.bing.com) with the ques-
tion text and obtain the text snippet of the top 2,000 hits; (2)
create a list of strings by chunking and tokenizing the results;
(3) remove stop words and special characters, as well as any
words (or their lemma) appearing in the question; (4) sort the
remaining strings based on their frequency; and (5) replace

the three incorrect answer options in the question with the
most frequently occurring strings, thereby generating a new
question. for instance:

in new york state, the longest period of daylight
occurs during which month? (a) eastern (b) june
(c) history (d) years

as in this example, the perturbations (italicized) are often not
even of the correct    type   , typically making them much easier
for humans. they, however, still remain dif   cult for solvers.

solver
ir
pmi
tableilp

original
score (%)

% drop with perturbation
absolute

relative

70.7
73.6
85.0

13.8
24.4
10.5

19.5
33.2
12.3

table 7: drop in solver scores (on the development set, rather
than the hidden test set) when questions are perturbed

for each of the 108 development questions, we generate
10 new perturbed questions, using the 30 most frequently oc-
curring words in step (5) above. while this approach can in-
troduce new answer options that should be considered correct
as well, only 3% of the questions in a random sample exhib-
ited this behavior. table 7 shows the performance of various
solvers on the resulting 1,080 perturbed questions. as one
might expect, the pmi approach suffers the most at a 33%
relative drop. tableilp   s score drops as well (since answer
type matching isn   t perfect), but only by 12%, attesting to its
higher resilience to simple question variation.

5 conclusion
answering real science questions is a challenging task
because they are posed in natural language, require extensive
domain knowledge, and often require combining multiple
facts together. we presented tableilp, a system that can
answer such questions, using a semi-structured knowledge
base. we treat qa as a subgraph selection problem and then
formulate this as an ilp optimization. most importantly, this
formulation allows multiple, semi-formally expressed facts
to be combined to answer questions, a capability outside
the scope of ir-based qa systems. in our experiments, this
approach signi   cantly outperforms both the previous best
attempt at structured reasoning for this task, and an ir engine
provided with the same knowledge.
it also signi   cantly
boosts performance when combined with unstructured meth-
ods (ir and pmi). these results suggest that the approach
is both viable and promising for natural language question
answering.

acknowledgments
d.k. is in part supported by ai2 and google. the au-
thors would like to thank christos christodoulopoulos, su-
jay jauhar, sam skjonsberg, and the aristo team at ai2 for
invaluable discussions and insights.

[ferrucci et al., 2010] d. ferrucci, e. brown,

j. chu-carroll,
j. fan, d. gondek, a. a. kalyanpur, a. lally, j. w. murdock,
e. nyberg, j. prager, et al. building watson: an overview of the
deepqa project. ai magazine, 31(3):59   79, 2010.

[goldwasser and roth, 2011] d. goldwasser and d. roth. learn-

ing from natural instructions. in ijcai, 2011.

[gunning et al., 2010] d. gunning, v. chaudhri, p. clark,
k. barker, j. chaw, and m. greaves. project halo update -
progress toward digital aristotle. ai magazine, 31(3), 2010.

[howell, 2012] d. howell.
cengage learning, 2012.

statistical methods for psychology.

[khot et al., 2015] t. khot, n. balasubramanian, e. gribkoff,
a. sabharwal, p. clark, and o. etzioni. exploring markov logic
networks for id53. in 2015 emnlp, lisbon, por-
tugal, sep 2015.

[ko et al., 2007] j. ko, e. nyberg, and l. si. a probabilistic graph-
in

ical model for joint answer ranking in id53.
proceedings of sigir, pg. 343   350, 2007.

[kwok et al., 2001] c. c. t. kwok, o. etzioni, and d. s. weld.

scaling id53 to the web. in www, 2001.

[maccartney, 2009] b. maccartney. natural language id136.

phd thesis, 2009.

[miller, 1995] g. miller. id138: a lexical database for english.

communications of the acm, 38(11):39   41, 1995.

[novak, 1977] g. novak. representations of knowledge in a pro-

gram for solving physics problems. in ijcai-77, 1977.

[richardson and domingos, 2006] m. richardson and p. domin-
gos. markov logic networks. machine learning, 62(1   2):107   
136, 2006.

[roth and yih, 2004] d. roth and w. yih. a id135
in

formulation for global id136 in natural language tasks.
conll, pg. 1   8. acl, 2004.

[srikumar and roth, 2011] v. srikumar and d. roth. a joint model
for extended id14. in emnlp, edinburgh, scot-
land, 2011.

[turney, 2013] p. d. turney. id65 beyond
words: supervised learning of analogy and paraphrase. tacl,
1:353   366, 2013.

[yao and van durme, 2014] x. yao and b. van durme. informa-
tion extraction over structured data: id53 with
freebase. in 52nd acl, 2014.

[yih et al., 2014] w. yih, x. he, and c. meek. id29
for single-relation id53. in acl (2), pg. 643   648,
2014.

[zou et al., 2014] l. zou, r. huang, h. wang, j. x. yu, w. he,
and d. zhao. natural language id53 over rdf: a
graph data driven approach. in sigmod, pg. 313   324, 2014.

references
[achterberg, 2009] t. achterberg. scip: solving constraint integer

programs. math. prog. computation, 1(1):1   41, 2009.

[angeli and manning, 2014] g. angeli and c. d. manning. natu-
ralli: natural logic id136 for common sense reasoning. in
emnlp, 2014.

[banko et al., 2007] m. banko, m. j. cafarella, s. soderland,
m. broadhead, and o. etzioni. id10 from
the web. in ijcai, 2007.

[bentivogli et al., 2008] l. bentivogli, p. clark, i. dagan, and
d. giampiccolo. the sixth pascal recognizing id123
challenge. in tac, 2008.

[berant et al., 2010] j. berant, i. dagan, and j. goldberger. global
learning of focused entailment graphs. in acl, pg. 1220   1229,
2010.

[bollacker et al., 2008] k. d. bollacker, c. evans, p. paritosh,
t. sturge, and j. taylor. freebase: a collaboratively created graph
database for structuring human knowledge. in sigmod, 2008.
[brill et al., 2002] e. brill, s. dumais, and m. banko. an analysis
of the askmsr question-answering system. in proceedings of
emnlp, pg. 257   264, 2002.

[carlson et al., 2010] a. carlson, j. betteridge, b. kisiel, b. set-
tles, e. r. h. jr., and t. m. mitchell. toward an architecture for
never-ending language learning. in aaai, 2010.

[chang et al., 2010] m.-w. chang, d. goldwasser, d. roth, and
v. srikumar. discriminative learning over constrained latent rep-
resentations. in 2010 naacl, pg. 429   437, 2010.

[church and hanks, 1989] k. w. church and p. hanks. word as-
sociation norms, mutual information and id69. in 27th
acl, pg. 76   83, 1989.

[clark et al., 2014] p. clark, n. balasubramanian, s. bhaktha-
vatsalam, k. humphreys, j. kinkead, a. sabharwal, and
o. tafjord. automatic construction of id136-supporting
in 4th akbc workshop, montreal, canada,
knowledge bases.
dec 2014.

[clark et al., 2016] p. clark, o. etzioni, t. khot, a. sabharwal,
o. tafjord, p. turney, and d. khashabi. combining retrieval,
statistics, and id136 to answer elementary science questions.
in 30th aaai, 2016.

[clark, 2015] p. clark. elementary school science and math tests
as a driver for ai: take the aristo challenge! in 29th aaai/iaai,
pg. 4019   4021, austin, tx, 2015.

[cohen, 2000] w. w. cohen. data integration using similarity joins
and a word-based information representation language. acm
transactions on information systems, 18(3):288   321, 2000.
[dagan et al., 2010] i. dagan, b. dolan, b. magnini,

and
d. roth. recognizing id123: rational, evalua-
tion and approaches   erratum. natural language engineering,
16(01):105   105, 2010.

[dagan et al., 2013] i. dagan, d. roth, m. sammons, and f. m.
zanzotto. recognizing id123: models and appli-
cations. synthesis lectures on human language technologies,
6(4):1   220, 2013.

[dalvi et al., 2016] b. dalvi, s. bhakthavatsalam, and p. clark.
ike - an interactive tool for knowledge extraction. in 5th akbc
workshop, 2016.

[fader et al., 2014] a. fader, l. zettlemoyer, and o. etzioni. open
id53 over curated and extracted knowledge bases.
in proceedings of sigkdd, pg. 1156   1165, 2014.

a appendix: ilp model for tableilp
as it is widely known an ilp can be written as the following:
(1)
(2)
(3)
we    rst introduce the basic variables, and de   ne the full de   -
nition of the ilp program: de   ne the weights in the objective
function (w in equation 1), and the constraints (a and b in
equation 2).

maximize
subject to
and

wtx
ax     b,
x     zn,

variables: we start with a brief overview of the basic
variables and how they are combined into high level variables.
table 8 summarizes our notation to refer to various ele-
ments of the problem, such as tijk for cell (j, k) of table i, as
de   ned in section 3. we de   ne variables over each element
by overloading x (.) or y (., .) notation which refer to a binary
variable on elements or their pair, respectively. table 2 con-
tains the complete list of basic variables in the model, all of
which are binary. the pairwise variables are de   ned between
pairs of elements; e.g., y (tijk, q(cid:96)) takes value 1 if and only if
the corresponding edge is present in the support graph. simi-
larly, if a node corresponding to an element of the problem is
present in the support graph, we will refer to that element as
being active.

reference description

i
j
k
l
m
x (.)
y (., .)

index over tables
index over table rows
index over table columns
index over lexical constituents of question
index over answer options
a unary variable
a pairwise variable

table 8: notation for the ilp formulation.

in practice we do not create pairwise variables for all pos-
sible pairs of elements; instead we create pairwise variables
for edges that have an entailment score exceeding a threshold.
for example we create the pairwise variables y (tijk, ti(cid:48)j(cid:48)k(cid:48))
only if w(tijk, ti(cid:48)j(cid:48)k(cid:48))     mincellcellalignment. an
exhaustive list of the minimum alignment thresholds for cre-
ating pairwise variables is in table 10.

table 2 also includes some high level unary variables,
which help conveniently impose structural constraints on the
support graph g we seek. an example is the active row vari-
able x (ti) which should take value 1 if and only if at least a
cell in row j of table i.

objective function: any of the binary variables de   ned
in our problem are included in the    nal weighted linear ob-
jective function. the weights of the variables in the objective
the vector w in equation 1) are set according
function (i.e.
to table 9. in addition to the current set of variables, we in-
troduce auxiliary variables for certain constraints. de   ning
auxiliary variables is a common trick for linearizing more in-
tricate constraints at the cost of having more variables.

constraints: constraints are signi   cant part of our model
in imposing the desirable behaviors for the support graph (cf.
section 3.1).

the complete list of the constraints is explained in ta-
ble 13. while groups of constraints are de   ned for different
purposes, it is hard to partition them into disjoint sets of con-
straints. here we give examples of some important constraint
groups.

active variable constraints: an important group of con-
straints relate variables to each other. the unary variables
are de   ned through constraints that relate them to the basic
pairwise variables. for example, active row variable x (ti)
should be active if and only if any cell in row j is active.
(constraint 15, table 13).

correctness constraints: a simple, but important set of
constraints force the basic correctness principles on the    -
nal answer. for example g should contain exactly one an-
swer option which is expressed by constraint 27, table 13.
another example is that, g should contain at least a certain
number of constituents in the question, which is modeled by
constraint 30, table 13.

sparsity constraints: another group of constraint induce
simplicity (sparsity) in the output. for example g should
use at most a certain number of knowledge base tables (con-
straint 28, table 13), since letting the id136 use any table
could lead to unreasonably long, and likely error-prone, an-
swer chains.

b appendix: features in solver combination
to combine the predictions from all the solvers, we learn a
id28 model [clark et al., 2016] that returns a
id203 for an answer option, ai, being correct based on
the following features.

solver-independent features: given the solver scores sj
for all the answer options j, we generate the following set of
features for the answer option ai, for each of the solvers:

1. score = si

2. normalized score = si(cid:80)

j sj
3. softmax score = exp(si)
4. best option, set to 1 if this is the top-scoring option =

j exp(sj )

(cid:80)

i(si = max sj)

tableilp-speci   c features: given the proof graph re-
turned for an option, we generate the following 11 features
apart from the solver-independent features:

1. average alignment score for question constituents
2. minimum alignment score for question constituents
3. number of active question constituents
4. fraction of active question constituents
5. average alignment scores for question choice
6. sum of alignment scores for question choice
7. number of active table cells
8. average alignment scores across all the edges
9. minimum alignment scores across all the edges
10. log of number of variables in the ilp
11. log of number of constraints in the ilp

pairwise variables

unary variables

y (tijk, ti(cid:48)j(cid:48)k(cid:48) )
y (tijk, am)
x (ti)
x (tijk)

1

w(tijk, am)

1.0
0.0

y (tijk, tij(cid:48)k(cid:48) ) w(tijk, tij(cid:48)k(cid:48) )     0.1
y (hik, am)
x (rij)
x (q(cid:96))

w(hik, am)

-1.0
0.3

y (tijk, q(cid:96)) w(q(cid:96), tijk)

y (hik, q(cid:96)) w(q(cid:96), hik)

x ((cid:96)ik)

1.0

x (hik)

0.3

table 9: the weights of the variables in our objective function. in each column, the weight of the variable is mentioned on its
right side. the variables that are not mentioned here are set to have zero weight.

mincellcellalignment
mintitletitlealignment
mincellqchoiceconsalignment
minactivecellaggralignment

0.6 mincellqconsalignment
0.0 mincellqchoicealignment
0.4 mincellqchoiceconsalignment
0.1 minactivetitleaggralignment

0.1 mintitleqconsalignment
0.2 mintitleqchoicealignment
0.4 mintitleqchoiceconsalignment
0.1

table 10: minimum thresholds used in creating pairwise variables.

maxtablestochain
whichtermmulboost
rowusagepenalty
maxalignmentspercell
emptyrelationmatchcoeff
minactiveqcons
minactivecellsperrow

qconscoalignmaxdist
minalignmentwhichterm
intertablealignmentpenalty
relationmatchcoeff

4
1
1
2
0.0 norelationmatchcoeff
1
2

maxactivecolumnchoicealignments

taid7sagepenalty

4 whichtermspan
0.6
0.1 maxalignmentsperqcons
0.2
-5 maxrowspertable
1

relationmatchcoeff

maxactivechoicecolumnvars

0.1
0.2
0.4

2
3
2
0.2
4
2

table 11: some of the important constants and their values in our model.

collection of basic variables connected to header column k
of table i:

collection of basic variables connected to cell j, k of table
i:

collection of basic variables connected to column k of
table i

collection of basic variables connected to row j of table i:

collection of non-choice basic variables connected to row
j of table i:
collection of non-question basic variables connected to
row j of table i:

collection of basic variables connected to table i:

collection of non-choice basic variables connected to table
i:
collection of basic variables connected to question
constituent q(cid:96):
collection of basic variables connected to option m
collection of basic variables in column k of table i
connected to option m:

hik = {(hik, q(cid:96));   l}     {(hik, am);   m}

eijk =(cid:8)(tijk, tij(cid:48)k(cid:48) );   i

(cid:48)

(cid:48)

, j

, k

(cid:48)(cid:9)     {(tijk, am);   m}     {(tijk, q(cid:96));   l}

(4)

cik = hik    

eijk

(cid:33)

(cid:32)(cid:91)
(cid:91)

j

rij =

lij =(cid:8)(tijk, tij(cid:48)k(cid:48) );   k, i
kij =(cid:8)(tijk, tij(cid:48)k(cid:48) );   k, i

(cid:48)

(cid:48)

eijk

(cid:48)(cid:9)     {(tijk, q(cid:96));   k, l}
(cid:48)(cid:9)     {(tijk, am);   k, m}

, k

k

(cid:48)

, j
(cid:48)

(cid:91)
ni = {(hik, q(cid:96));   l}   (cid:8)(tijk, tij(cid:48)k(cid:48) );   j, k, i

, j
ti =

, k
cik

k

(10)

(cid:48)(cid:9)   {(tijk, q(cid:96));   j, k, l}

(cid:48)

(cid:48)

, j

, k

ql = {(tijk, q(cid:96));   i, j, k}     {(hik, q(cid:96));   i, k}
om = {(tijk, am);   i, j, k}     {(hik, am);   i, k}

mi,k,m = {(tijk, am);   j}     {(hik, am)}

table 12: all the sets useful in de   nitions of the constraints in table 13.

if any cell in row j of table i is active, the row should be active.

if the row j of table i is active, at least one cell in that row must be active
as well.
column j header should be active if any of the basic variables with one
end in this column header are active.
if the header of column j variable is active, at least one basic variable with
one end in the end in the header
column k is active if at least one of the basic variables with one end in this
column are active.

(cid:88)
(cid:88)

x (rij)     y (tijk, e) ,   (tijk, e)     rij,   i, j, k
y (tijk, e)     x (rij) ,   i, j

(tijk,e)   rij

x (hik)     y (hik, e) ,   (hik, e)     hik,   i, k
y (hik, e)     x (hik) ,   i

(hik,e)   hik

x ((cid:96)ik)     y (tijk, e) ,   (tijk, e)     cik,   i, k

(5)

(6)

(7)

(8)

(9)

(11)
(12)

(13)

(14)

(15)

(16)

(17)

(18)

(19)

if the column k is active, at least one of the basic variables with one end in
this column should be active.
if a basic variable with one end in table i is active, the table variable is
active.
if the table i is active, at least one of the basic variables with one end in the
table should be active.
if any of the basic variables with one end in option am are on, the option
should be active as well.
if the question option am is active, there is at least one active basic element
connected to it
if any of the basic variables with one end in the constituent q(cid:96), the
constituent must be active.
if the constituent q(cid:96) is active, at least one basic variable connected to it
must be active.

choose only a single option.

there is an upper-bound on the number of active tables; this is to limit the
solver and reduce the chance of using spurious tables.

the number of active rows in each table is upper-bounded.

the number of active constituents in each question is lower-bounded.
clearly we need to use the question de   nition in order to answer a
question.

a cell is active if and only if the sum of coef   cients of all external
alignment to it is at least a minimum speci   ed value

a title is active if and only if the sum of coef   cients of all external
alignment to it is at least a minimum speci   ed value

if a column is active, at least one of its cells must be active as well.

at most a certain number of columns can be active for a single option

if a column is active for a choice, the table is active too.

if a table is active for a choice, there must exist an active column for
choice.

if a table is active for a choice, there must be some non-choice alignment.

(20)

(21)

(22)

(23)

(24)

(25)

(26)

(27)

(28)

(29)

(30)

(31)

(32)

(33)

y (tijk, e)     x (hik) ,   i, k

(tijk,e)   cik
y (tijk, e)     x (ti) ,   (tijk, e)     ti,   i

y (t, e)     x (ti) ,   i

x (am)     y (x, am) ,   (e, am)     om

y (x, a)     x (am)

(cid:88)
(cid:88)
(cid:88)
(cid:88)

(t,e)   ti

(e,a)   om

x (q(cid:96))     y (e, q(cid:96)) ,   (e, q(cid:96))     ql

y (e, q(cid:96))     x (q(cid:96))

(e,q(cid:96))   ql
x (am)     1,

x (am)     1

(cid:88)

m

x (ti)     maxtablestochain

x (rij)     maxrowspertable,   i

x (q(cid:96))     minactiveqcons

m

(cid:88)
(cid:88)
(cid:88)
(cid:88)

j

i

l

(cid:88)

y (tijk, e)     x (tijk)

(tijk,e)   ei,j,k
   minactivecellaggralignment,   i, j, k

y (tijk, e)     x (tijk)

(e)   hi,k
   minactivetitleaggralignment,   i, k

(cid:88)

x (tijk)     x ((cid:96)ik) ,   i, k

(cid:88)

(cid:88)

k

j

y ((cid:96)ik, am)     maxactivechoicecolumn,

   i, m (34)

x ((cid:96)ik)     x (ti) ,   i, k
x ((cid:96)ik) ,   i

x (ti)    (cid:88)
y (ti, am)     (cid:88)

y(cid:0)e, e

k

(cid:48)(cid:1) ,   i, m

(e,e(cid:48))   ni

(35)

(36)

(37)

answer should be present in at most a certain number of tables

y (ti, am)     maxactivetablechoicealignmets,
   i, m (38)

if a cell in a column, or its header is aligned with a question option, the
column is active for question option as well.

if a column is active for an option, there must exist an alignment to header
or cell in the column.

y (tijk, am)     y ((cid:96)ik, am) ,

y ((cid:96)ik, am)     (cid:88)

(tijk,am)   oi,k,m

   i, k, m,   (tijk, am)     mi,k,m (39)

y (tijk, am) ,   i, m (40)

at most a certain number of columns may be active for question option
in a table.

if a column is active for a choice, the table is active for an option as
well.
if the table is active for an option, at least one column is active for a
choice

create an auxiliary variable x (whichtermisactive) with objective
weight 1.5 and activate it, if there a    which    term in the question.

create an auxiliary variable x (whichtermisaligned) with objective
weight 1.5. add a boost if at least one of the table cells/title aligning to
the choice happens to have a good alignment
({w(., .) > minalignmentwhichterm}) with the    which    terms,
i.e. whichtermspan constituents after    which   .

a question constituent may not align to more than a certain number of
cells

disallow aligning a cell to two question constituents if they are too far
apart; in other words add the following constraint if the two
constituents q(cid:96) and q(cid:96)(cid:48) are more than qconscoalignmaxdist
apart from each other:
for any two two question constraints that are not more than
qconscoalignmaxdist apart create an auxiliary binary variable
x (cellproximityboost) and set its weight in the objective function to
be 1/(l     l(cid:48) + 1), where l and l(cid:48) are the indices of the two question
constituents. with this we boost objective score if a cell aligns to two
question constituents that are within a few words of each other
if a relation match is active, both the columns for the relation must be
active

if a column is active, a relation match connecting to the column must
be active

if a relation match is active, the column cannot align to the question in
an invalid position

if a row is active, at least a certain number of its cells must be active

if row is active, it must have non-choice alignments.

if row is active, it must have non-question alignments

if two rows of a table are active, the corresponding active cell variables
across the two rows must match; in other words, the two rows must
have identical activity signature

if two rows are active, then at least one active column in which they
differ (in tokenized form) must also be active; otherwise the two rows
would be identical in the proof graph.

l

(cid:88)
(cid:88)
(cid:88)

i

(e,q(cid:96))   ql

(cid:88)

(e1,e2)   ti

(cid:88)

k

y ((cid:96)ik, am)    

maxactivechoicecolumnvars,   i, m (41)

y (ti, am)    (cid:88)

y ((cid:96)ik, am)     y (ti, am) ,   i, k, m
y ((cid:96)ik, am) ,   i, m

k

1{q(cid:96) =    which   }     x (whichtermisactive)

(42)

(43)

(44)

y (e1, e2)     x (whichtermisaligned)

(45)

y (e, q(cid:96))     maxalignmentsperqcons

(46)

y (tijk, q(cid:96)) + y (tijk, q(cid:96)(cid:48) )     1,   l, l

(cid:48)

, i, j, k

(47)

x (cellproximityboost)     y (tijk, q(cid:96)) ,

x (cellproximityboost)     y (tijk, q(cid:96)(cid:48) ) ,   i, j, k

(48)

x ((cid:96)ik)    (cid:88)

r ((cid:96)ik, (cid:96)ik(cid:48) , q(cid:96), q(cid:96)(cid:48) )     x ((cid:96)ik) , r ((cid:96)ik, (cid:96)ik(cid:48) , q(cid:96), q(cid:96)(cid:48) )     x ((cid:96)ik(cid:48) )
(49)
(r ((cid:96)ik, (cid:96)ik(cid:48) , q(cid:96), q(cid:96)(cid:48) ) + r ((cid:96)ik(cid:48) , (cid:96)ik, q(cid:96), q(cid:96)(cid:48) )),   k
(50)

k(cid:48)

r ((cid:96)ik, (cid:96)ik(cid:48) , q(cid:96), q(cid:96)(cid:48) )     1     y (tijk,   q(cid:96)) ,

where   q(cid:96)     q(cid:96) and tijk     (cid:96)ik

(51)

x (tijk)     minactivecellsperrow    x (rij) ,   i, j
(52)

x (rij)     (cid:88)
x (rij)     (cid:88)

(n,n(cid:48))   lij

(n,n(cid:48))   kij

y (n, n)

y (n, n)

(cid:88)

k

x (rij) + x (rij(cid:48) ) + x (tijk)

(cid:88)

    x (tij(cid:48)k(cid:48) )     2,   i, j, j

, k, k
x ((cid:96)ik)     x (rij)     x (rij(cid:48) )        1

(cid:48)

(53)

(54)

(cid:48)

(55)

(56)

tijk(cid:54)=tijk(cid:48)

(cid:88)

j,k,j(cid:48),k(cid:48)

if a table is active and another table is also active, at least one
inter-table active variable must be active;

x (ti) + x (ti(cid:48) ) +

y (tijk, ti(cid:48)j(cid:48)k(cid:48) )     1,   i, i

(cid:48)

(57)

table 13: the set of all constraints used in our ilp formulation. the set of variables and are de   ned in table 2. more intuition
about constraints is included in section 3. the sets used in the de   nition of the constraints are de   ned in table 12.

