5
1
0
2

 

y
a
m
7
2

 

 
 
]
l
c
.
s
c
[
 
 

7
v
5
3
3
5

.

2
1
4
1
:
v
i
x
r
a

accepted as a workshop contribution at iclr 2015

ensemble of generative and discriminative
techniques for id31 of movie
reviews

gr  egoire mesnil
university of montr  eal
university of rouen

tomas mikolov & marc   aurelio ranzato
facebook arti   cial intelligence research

yoshua bengio
university of montr  eal

abstract

id31 is a common task in natural language processing that aims to
detect polarity of a text document (typically a consumer review). in the simplest
settings, we discriminate only between positive and negative sentiment, turning
the task into a standard binary classi   cation problem. we compare several ma-
chine learning approaches to this problem, and combine them to achieve a new
state of the art. we show how to use for this task the standard generative lan-
guage models, which are slightly complementary to the state of the art techniques.
we achieve strong results on a well-known dataset of imdb movie reviews. our
results are easily reproducible, as we publish also the code needed to repeat the
experiments. this should simplify further advance of the state of the art, as other
researchers can combine their techniques with ours with little effort.

1

introduction

id31 is among the most popular, simple and useful tasks in natural language process-
ing. it aims at predicting the attitude of text, typically a sentence or a review. for instance, movies
or restaurant are often rated with a certain number of stars, which indicate the degree to which the
reviewer was satis   ed.

this task is often considered as one of the simplest in nlp because basic machine learning tech-
niques can yield strong baselines (wang & manning, 2012), often beating much more intricate ap-
proaches (socher et al., 2011). in the simplest settings, this task can be seen as a binary classi   cation
between positive and negative sentiment.

however, there are several challenges towards achieving the best possible accuracy. it is not obvious
how to represent variable length documents beyond simple bag of words approaches that lose word
order information. one can use advanced machine learning techniques such as recurrent neural net-
works and their variations (mikolov et al., 2010; socher et al., 2011), however it is not clear if these
provide any signi   cant gain over simple bag-of-words and bag-of-ngram techniques (pang & lee,
2008; wang & manning, 2012).

in this work, we compared several different approaches and realized, without much surprise, that
model combination performs better than any individual technique. the ensemble best bene   ts from
models that are complementary, thus having diverse set of techniques is desirable. the vast major-
ity of models proposed in the literature are discriminative in nature, as their parameters are tuned
for the classi   cation task directly.
in this work, we boost the performance of the ensemble by
considering a generative language model. to this end, we train two language models, one on the
positive reviews and one on the negative ones, and use the likelihood ratio of these two models

1

accepted as a workshop contribution at iclr 2015

evaluated on the test data as an additional feature. for example, we assume that a positive re-
view will have higher likelihood to be generated by a model that was trained on a large set of
positive reviews, and lower likelihood given the negative model. in this paper, we constrained our
work to binary classi   cation where we trained two generative models, positive and negative. one
could consider a higher number of classes since this approach scales linearily with the number of
models to be train, i.e. one for each class. the large pool of diverse models is a) simple to im-
plement (in line with previous work by wang and manning (wang & manning, 2012)) and b) it
yields state of the art performance on one of the largest publicly available benchmarks of movie
reviews, the stanford imdb dataset of reviews. code to reproduce our experiments is available at
https://github.com/mesnilgr/iclr15.

2 description of the models

in this section we describe in detail the approaches we considered in our study. the novelty of
this paper consists in combining both generative and discriminative models together for sentiment
prediciton.

2.1 generative model

a generative model de   nes a distribution over the input. by training a generative model for each
class, we can then use bayes rule to predict which class a test sample belongs to. more formally,
given a dataset of pairs {x(i), y(i)}i=1,...,n where x(i) is the i-th document in the training set, y(i)    
{   1, +1} is the corresponding label and n is the number of training samples, we train two models:
p+(x|y = +1) for {x(i) subject to y(i) = +1} and p   (x|y =    1) for {x subject to y =    1}.
then, given an input x at test time we compute the ratio (derived from bayes rule): r = p+(x|y =
+1)/p   (x|y =    1)    p(y = +1)/p(y =    1). if r > 1, then x is assigned to the positive class,
otherwise to the negative class.

is the k-th word in the i-th document.

we have a few different choices of distribution we can choose from. the most common one is the
id165, a count-based non-parametric method to compute p(x(i)
k   n +1), where
x(i)
in order to compute the likelihood of a document,
we use the markov assumption and simply multiply the id165 probabilities over all words in the
document: p(x(i)) = qk
k   n +1). as mentioned before, we train one
id165 language model using the positive documents and one model using the negative ones.

k   2, . . . , x(i)

k   2, . . . , x(i)

k=1 p(x(i)

k   1, x(i)

k   1, x(i)

k |x(i)

k |x(i)

k

in our experiments, we used srilm toolkit (stolcke et al., 2002) to train the id165 language mod-
els using modi   ed kneser-ney smoothing (kneser & ney, 1995). furthermore, as both language
models are trained on different datasets, there is a mismatch between vocabularies: some words can
appear only in one of the training sets. this can be a problem during scoring, as the test data contain
novel words that were not seen in at least one of the training datasets. to avoid this problem, it is
needed to add penalty during scoring for each out of vocabulary word.

id165s are a very simple data-driven way to build language models. however, they suffer from
both data sparsity and large memory requirement. since the number of word combinations grows
exponentially with the length of the context, there is always little data to accurately estimate proba-
bilities for higher order id165s.

in contrast with id165s languages models, recurrent neural networks (id56s) (mikolov et al.,
2010) are parametric models that can address these issues. the inner architecture of the id56s
gives them potentially in   nite context window, allowing them to perform smoother predictions.
we know that in practice, the context window is limited due to exploding and vanishing gradients
(pascanu et al., 2012). still, id56s outperform signi   cantly id165s and are the state of the art for
statistical id38. a review of these techniques is beyond the scope of this short paper
and we point the reader to (mikolov, 2012) for a more in depth discussion on this topic.

both when using id165s and id56s, we compute the id203 of the test document belonging to
the positive and negative class via bayes    rule. these scores are then averaged in the ensemble with
other models, as explained in section 2.4.

2

accepted as a workshop contribution at iclr 2015

table 1: performance of id166 with wang & manning (2012) rescaling for different id165s

input features
unigrams
unigrams+bigrams
unigrams+bigrams+trigrams

accuracy
88.61%
91.56%
91.87%

2.2 linear classification of weighted id165 features

among purely discriminative methods, the most popular choice is a linear classi   er on top of a bag-
of-word representation of the document. the input representation is usually a tf-idf weighted word
counts of the document. in order to preserve local ordering of the words, a better representation
would consider also the position-independent id165 counts of the document (bag-of-id165s).

in our ensemble, we used a supervised reweighing of the counts as in the naive bayes support vector
machine (nb-id166) approach (wang & manning, 2012). this approach computes a log-ratio vector
between the average word counts extracted from positive documents and the average word counts
extracted from negative documents. the input to the id28 classi   er corresponds to the
log-ratio vector multiplied by the binary pattern for each word in the document vector. note that
the logictic regression can be replaced by a linear id166. our implementation1 slightly improved the
performance reported in (wang & manning, 2012) by adding tri-grams (improvement of +0.6%),
as shown in table 1.

2.3 sentence vectors

recently, (le & mikolov, 2014) proposed an unsupervised method to learn distributed represen-
tations of words and paragraphs. the key idea is to learn a compact representation of a word or
paragraph by predicting nearby words in a    xed context window. this captures co-occurence statis-
tics and it learns embeddings of words and paragraphs that capture rich semantics. synonym words
and similar paragraphs often are surrounded by similar context, and therefore, they will be mapped
into nearby feature vectors (and vice versa).

such embeddings can then be used to represent a new document (for instance, by averaging the
representations of the paragraphs that constitute the document) via a    xed size feature vector. the
authors then use such a document descriptor as input to a one hidden layer neural network for
sentiment discrimination.

2.4 model ensemble

in this work, we combine the log id203 scores of the above mentioned models via linear inter-
polation. more formally, we de   ne the overall id203 score as the weighted geometric mean of
baseline models: p(y = +1|x) = q pk(y = +1|x)  k , with   k > 0.
we    nd the best setting of weights via brute force grid search, quantizing the coef   cient values in the
interval [0, 1] at increments of 0.1. the search is evaluated on a validation set to avoid over   tting.
we do not focus on a smarter way to    nd the    since we consider only 3 models in our approach
and we consider it out of the scope of this paper. using more models would make the use of such
method prohibitive. for a larger number of models, one might want to consider random search of
the    coef   cients or even bayesian approaches as these techniques will give better running time
performance.

3 results

in this section we report results on one of the largest publicly available id31 datasets,
the imdb dataset of movie reviews. the dataset consists of 50, 000 movie reviews which are cat-
egorized as being either positive or negative. we use 25, 000 reviews for training and the rest for

1https://github.com/mesnilgr/nbid166

3

accepted as a workshop contribution at iclr 2015

table 2: performance of individual models

accuracy
single methods
id165
86.5%
id56-lm
86.6%
sentence vectors
88.73%
nb-id166 trigram 91.87%

table 3: performance of different model combinations

ensemble
id56-lm + nb id166 trigram
id56-lm + sentence vectors
sentence vectors + nb-id166 trigrams
all
state of the art

accuracy
92.13%
90.4%
92.39%
92.57%
91.22%

testing, using the same protocol proposed by (maas et al., 2011). all experiments can be reproduced
using the code available at https://github.com/mesnilgr/iclr15.

table 2 reports the results of each individual model. we have found that generative models per-
formed the worst, with id56s slightly better than id165s. the most competitive method is the
method based on reweighed bag-of-words (wang & manning, 2012) 2. favoring simplicity and
reproducibility of our performance, all results reported in this paper were produced by a linear clas-
si   er.

finally, table 3 reports the results of combining the previous models into an ensemble. when we
interpolate the scores of id56, sentence vectors and nb-id166, we achieve a new state-of-the-art
performance of 92.57%, to be compared to 91.22% reported by (wang & manning, 2012). notice
that our implementation of the sentence vectors method (le & mikolov, 2014) alone yielded only
88.73% (a difference of     4%). in order to measure the contribution of each model to the    nal en-
semble classi   er, we remove one model at a time from the ensemble. we observe that the removal of
the generative model affects the least the ensemble performance. overall, all three models contribute
to the success of the overall ensemble, suggesting that these three models pick up complimentary
features useful for discrimination. in table 4, we show test reviews misclassi   ed by single models
but classi   ed accurately by the ensemble.

4 conclusion

we have proposed a very simple yet powerful ensemble system for id31. we combine
three rather complementary and conceptually different baseline models: one based on a generative
approach (language models), one based on continuous representations of sentences and one based
on a clever reweighing of tf-idf bag-of-word representation of the document. each such model
contributes to the success of the overall system, achieving the new state of the art performance on
the challenging imdb movie review dataset. code to reproduce our experiments is available at:
https://github.com/mesnilgr/iclr15. we hope researchers will take advantage of our
code to include their new results into our ensemble and focus on improving the state of the art for
id31.

references
kneser, reinhard and ney, hermann. improved backing-off for m-gram id38. in
acoustics, speech, and signal processing, 1995. icassp-95., 1995 international conference on,

2in our experiments, to match the results from (le & mikolov, 2014), we followed the suggestion by quoc
le to use hierarchical softmax instead of negative sampling. however, this produces the 92.6% accuracy result
only when the training and test data are not shuf   ed. thus, we consider this result to be invalid.

4

accepted as a workshop contribution at iclr 2015

table 4: reviews misclassi   ed by single models but classi   ed accurately by the ensemble

model

nb-id166

id56-lm

sentence vector

sentences
(positive) a really realistic , sensible movie by ramgopal verma . no stupidity like
songs as in other hindi movies . class acting by nana patekar . much similarities to
real    encounters    .
(negative) leslie nielson is a very talented actor , who made a huge mistake by doing
this    lm . it doesn   t even come close to being funny . the best word to describe
it is stupid !
(positive) this is a good    lm . this is very funny . yet after this    lm there
were no good ernest    lms !
(negative) a real hoot , unintentionally . sidney portier   s character
is so sweet and lovable you want to smack him . nothing about this movie rings true .
and it   s boring to boot .
(positive) this movie is based on the novel island of dr . moreau by
version by john frankenheimer .
(negative) if it wasn   t for the terri   c music , i would not hesitate to give this
cinematic underachievement 2/10 . but the music actually makes me like certain
passages , and so i give it 5/10 .

volume 1, pp. 181   184. ieee, 1995.

le, quoc v. and mikolov, tomas. distributed representations of sentences and documents.

international conference on machine learning, 2014.

in

maas, andrew l., daly, raymond e., pham, peter t., huang, dan, ng, andrew y., and potts,
christopher. learning word vectors for id31. in proceedings of the annual meet-
ing of the association for computational linguistics. association for computational linguistics,
2011.

mikolov, tom  a  s. statistical language models based on neural networks. phd thesis, 2012.

mikolov, tomas, kara     at, martin, burget, lukas, cernock`y, jan, and khudanpur, sanjeev. recur-

rent neural network based language model. in interspeech, pp. 1045   1048, 2010.

pang, bo and lee, lillian. opinion mining and id31. foundations and trends in

information retrieval, 2(1-2):1   135, 2008.

pascanu, razvan, mikolov, tomas, and bengio, yoshua. on the dif   culty of training recurrent

neural networks. arxiv preprint arxiv:1211.5063, 2012.

socher, richard, pennington, jeffrey, huang, eric, ng, andrew, and manning, christopher d. semi-
supervised recursive autoencoders for predicting sentiment distributions. conference on empiri-
cal methods in natural language processing, 2011.

stolcke, andreas et al. srilm-an extensible id38 toolkit. in interspeech, 2002.

wang, sida and manning, christopher d. baselines and bigrams: simple, good sentiment and topic
classi   cation. in proceedings of the 50th annual meeting of the association for computational
linguistics: short papers-volume 2, pp. 90   94. association for computational linguistics, 2012.

5

