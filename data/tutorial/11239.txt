from id27s to item recommendation

makbule gulcin ozsoy

department of computer engineering

middle east technical university

ankara, turkey

email: makbule.ozsoy@ceng.metu.edu.tr

6
1
0
2

 

n
u
j
 

5
1

 
 
]

g
l
.
s
c
[
 
 

3
v
6
5
3
1
0

.

1
0
6
1
:
v
i
x
r
a

abstract   social network platforms can use the data produced
by their users to serve them better. one of the services these
platforms provide is recommendation service. recommendation
systems can predict the future preferences of users using their
past preferences. in the id126s literature there
are various techniques, such as neighborhood based methods,
machine-learning based methods and matrix-factorization based
methods. in this work, a set of well known methods from natural
language processing domain, namely id97, is applied to
id126s domain. unlike previous works that
use id97 for recommendation, this work uses non-textual
features, the check-ins, and it recommends venues to visit/check-
in to the target users. for the experiments, a foursquare check-
in dataset is used. the results show that use of continuous
vector space representations of items modeled by techniques of
id97 is promising for making recommendations.

keywords   id126s, location based social
networks, id27, id97, skip-gram technique,
cbow technique

i.

introduction

social

network

platforms

(e.g. twitter, facebook,
foursquare) have many active users who produce vast amount
of
information by interacting with each other and with
items/services the platform provide. for example, up to april
2016, 320 million monthly active users use twitter, more than
50 million users use foursquare and 1.04 billion daily active
users use facebook. these platforms are able to archive and
use the produced information to better serve their users. one
of the services that most of the social network platforms
provide is recommendation service.

id126s predict the future preferences
of users    based on their previous interactions with the items.
for example, information on previous check-ins of users can
be used to make recommendations on future check-ins. the
vast amount of information produced by the users is used
by several different methods to make recommendations, e.g.
neighborhood based methods, machine-learning based methods
and matrix-factorization based methods. recently, matrix fac-
torization (mf) methods gained more attention by researchers,
as these methods can ef   ciently deal with large datasets by
using low-rank approximation of input data [15].

similar to id105 methods, id27
methods learn low-dimensional vector space representation of
input elements. they are used to learn linguistic regularities
and semantic information from large text datasets and they
are gaining more attention especially in natural
language
processing and id111    elds [19]. in this work, we aim

to recommend next venues to visit/check-in by adopting skip-
gram and continuous bag of words (cbow) id27
techniques proposed in id97 framework [18].

ef   ciency of using text processing techniques in recom-
mendation systems is already exempli   ed in some of the pre-
vious works in the literature ([6], [23], [19]). [6] is one of the
state-of-the-art methods for venue recommendation on loca-
tion based social networks (lbsns) and employs a language
model based method. [23] aims to make recommendation to
users about which blog to follow. it uses id97 to model a
word based feature, i.e. tags. [19] employs three different word
embedding techniques, one of which is id97, to make
recommendation on movielens and dbbook datasets. it uses
textual data collected from wikipedia about the items. unlike
the previous works that use id97 for recommendation, in
this work a non-textual feature, namely the past check-ins of
the users, is used to make recommendations.

the aim of this work is to apply a set of well known meth-
ods from natural language processing domain, namely meth-
ods from id97 framework, to id126s
domain and show that the performance is comparable to well-
known methods in id126s. the contributions
of this work are as follow:

   

    methods from natural language processing domain,
id97   s skip-gram and continuous bag of words
(cbow) techniques, are employed to make recom-
mendations on location based social networks (lb-
sns).
several different techniques inspired from well-known
recommendation methods, namely content based and
collaborative    ltering based methods, are combined
with id97   s techniques.
unlike the previous works that use id97 for
recommendation ([23], [19]), a non-textual feature,
namely the past check-ins of the users, is used to make
recommendations.
for the evaluation a foursquare check-in dataset,
which is already used in previous works ([6], [20])
is employed. also comparisons to methods from the
id126s literature are presented.

   

   

the rest of the paper is structured as follows: information
on the related work is given in the section ii. id97
and the proposed methods are explained in the section iii.
the experimental results and the comparisons are given in the
section iv. the paper is concluded in the section v.

ii. related work

id126s make recommendation of items
by estimating the preferences of users ([16], [24]). in the
literature there are three base recommendation approaches:
content based, collaborative    ltering and hybrid approaches.
content based approach uses features of items and users,
calculates their similarities and use these similarities to make
recommendations. collaborative    ltering approach uses past
preferences of users to decide which items to recommend.
hybrid methods combine these approaches to make recom-
mendations.

beside the above-mentioned methods, there are various
methods to make recommendation, e.g. by neighborhood
based methods, machine-learning based methods and matrix-
factorization based methods. recently, the id105
based methods gained more attention of recommendation sys-
tems researchers. these methods use low-rank approximation
of input data and can handle large volume of data [15]. in
[9], it is stated that id105 can represent the
items and the users as vectors, where high correlation between
vectors leads to recommendation. also, in the same work
it is stated that these methods have good scalability, high
accuracy and    exibility. some example works that use the
id105 for recommendation belong to sarwar et
al. [22], ma et al. [14], zheng et al. [27], liu et al. [13], yu
et al. [26], cheng et al. [5] and lian et al. [12]. among these
works [27] and [5] have similar purpose as ours and they make
location/activity recommendations to the target users. however
none of these methods employ id97 for this purpose.

similar to id105 methods, id27
methods from natural language processing    eld learn low-
dimensional vector space representation of input elements. the
id27s learn linguistic regularities and semantic
information from the input text datasets and represent the the
meaning of the words by a vector representation ([19], [3]). in
[3] it is stated that id27s can be learned by latent
semantic analysis (lsa), topic models and matrix factoriza-
tion techniques. techniques de   ned in id97 [18], namely
skip-gram and cbow, are commonly used in the literature to
represent the word vectors.

some of the recommendation methods ([23], [19]) use
techniques from id97 to represent their text based fea-
tures. [23] aims to make recommendation to users about
which tumblr blogs to follow. in that work inductive matrix
completion (imc) method is used for recommendation. that
method uses side features (i.e. likes, re-blogs and tags) as well
as past preferences of users. it does not directly use techniques
from natural language processing, but employ id97 to
compute vector representation of tags; which are word based
features. [19] empirically evaluates three id27
techniques, namely id45, random index-
ing and id97, to make recommendation. they evaluate
their proposed method on movielens and dbbook datasets.
they mapped the items in the datasets to textual contents using
wikipedia and used the textual contents for making recommen-
dation. another recommendation method that uses techniques
from natural language processing is socio-historical method
proposed in [6]. it is one of the state-of-the-art methods for
venue recommendation on lbsns. observing the similarities
in id111 and social network datasets, it employs language

fig. 1: id97 techniques

models approach from natural language processing to make
venue recommendations. it models either users    historical
preferences or their social interactions or both together.

techniques in id97 are generally considered as deep
learning technique. there are few other methods that employ
deep learning to make recommendations, e.g. [21], [7] and
[25]. [21] uses restricted id82s (rbm   s) to
make movie recommendations. it models correlation among
item ratings. [7] extends [21] by modelling both user-user and
item-item correlations. [25] proposes a hierarchical bayesian
model that learns models on both content information on items
and past preferences of users.

in this work, id97   s skip-gram and cbow techniques
are employed to recommend check-in locations to the target
users. unlike the previous works that use id97 for
recommendation ([23], [19]), a non-textual features, namely
the past check-ins of the users, is used.

iii. recommendation using multiple data

sources

the aim in this work is to list the top-k venues/locations
(e.g. restaurant, cafe) that the target user will visit/check-in
in the future. for this purpose techniques from id97
toolbox, namely skip-gram and cbow, are used. in this
section, a brief information on the techniques in id97
toolbox and explanation on how they are used for venue
recommendation is presented.

id97 is a group of models which is introduced by
mikolov et al. ([18], [17]). it contains two different tech-
niques, namely skip-gram and cbow, which produce word
embeddings, i.e. distributed word representations. the word
embeddings represent the words in a low dimensional contin-
uous space and carry the semantic and syntactic information of
words [11]. while the cbow technique uses the words around
the current word to predict the current word, the skip-gram
technique does the vice-versa, such that it uses the current
word to predict the words around the current word (figure 1).
in both of the techniques, bag-of-words representation is used,
i.e. order of the words in the input does not affect the result.
we used both of the techniques to model the data and to make
recommendations.

the proposed recommendation method is composed of the
following steps: first the input data is modeled using the
techniques from id97. then the output model is used
to execute the recommendation process.

in this work, inspiring from [10], the item lists are used
together with the users as the input to id97 techniques,
i.e. not only list of items, but list of user and the items preferred
by this user is given as input to the id97 techniques. as
a result, the continuous vector representation of the items and
the users are obtained, separately. these vector representations
can be used to decide on which item is more similar to other
item or which user is contextually closer to which items. these
vectors and their similarities are used in the next step of our
recommendation method.

in the figure 3, the output of skip-gram technique on the
input data given in the figure 2 is presented. to be able to plot
the    gure, the output continuous vector representation dimen-
sion is set to two. in the figure 3a, the output for sentence-
word data is shown. according to this    gure, the relations
among words and sentences are captured. for example, in
the    gure the word    walked    is closer (more related) to the
sentence s0 and the word    went    is closer to the sentence s2;
these words are seen only in these sentences. another example
is the words    man    and    his    which are represented at the same
position on the    gure. this indicates that the technique is able
to capture the relation between these words. in the figure
3b the output for user-item data is shown. from the    gure
relations among users and items can be observed. for example,
in the    gure    loc7    is represented closer to    u2    (user2); in the
input data    loc7    is visited only by    user2   . another example
is related to relations among locations; in the    gure    loc0   
and    loc2    are closer to each other and in the input data these
locations are always visited together.

b. recommendation using continuous vector representation

the output of id97 techniques provide the continuous
representation of the items and users in vector space where
similar vectors are located closer to each other. in this report
three different recommendation techniques that use the contin-
uous vector representation of items and users are proposed:

recommendation by k-nearest items (kni): the k-
nearest
items (kni) approach is inspired from traditional
content-based    ltering recommendation method. in content-
based    ltering method, features or tags that describe users
and the items are used. for the recommendation the similarity
between the target user and the items are calculated and the
items that are more similar to the target user are listed as
the recommendation. in kni approach, instead of description
of users and items,
the continuous vector representations
calculated in the previous step are used. for this purpose, the
cosine similarity between the target user and item vectors are
calculated and the most similar k items to the target user are
found. the collected top-k items are recommended to the target
user. for example, given the vectors presented in the figure 3,
assume that we want to make two location recommendations
to the user u0. the most similar location vectors to the user
vector belong to    loc1    and    loc2   , so these locations are
recommended to the target user.

recommendation by n-nearest users (nn):

in recom-
mendation by n-nearest users (nn) approach, the traditional
user-based collaborative    ltering method is applied on the
continuous vector representations modeled in the previous step.
in traditional user-based collaborative    ltering,    rst the most

(a) sentence-word data

(b) user-item data

fig. 2: example data for text processing and recommendation
systems

a. modeling the data using the techniques from id97

we used the id97 techniques implemented in the
gensim toolbox 1. this implementation accepts a list of sen-
tences which are themselves are a list of words. these words
are used to create the internal dictionary which holds the
words and their frequencies. afterwards the model is trained
using the input data and the dictionary. the output of the
technique is continuous vector representation of words, which
can be used as features by different applications [1]. during
the training various parameters can be tuned which affects the
performance, in terms of time and quality. the details on how
the parameters are tuned and the effects of different values are
presented in the evaluation section.

there are several similarities between the id97 tech-
niques and the recommendation process: first, the input data
used in id97 techniques is actually similar to what is
used in the recommendation process. in the recommendation
process a list of items that the user preferred/rated in the
past are used and these lists can be divided into individual
items. in other words, the sentences used in id97 can
be mapped into past preferences of users in recommenda-
tion process and the words in id97 to individual items
used in recommendation process. second, the purpose of the
id97 techniques and the recommendation process are
similar. id97 model aims to predict the words based
on the observed words, which can be mapped to predicting
the items to be recommended based on already preferred/used
items.

in the figure 2, the similarity of data used in text pro-
cessing and id126s are presented. on the
left side of the    gure, three sentences are presented together
with the vocabulary list (dictionary). similarly on the right
side of the    gure three users and their past preferences on
locations that they have checked in are presented. similar to
sentence-word example, given in the    gure 2a, it is possible
to create a list of locations (venues). both of the examples can
be represented as a vector. the vectors on the left present the
existence of words in the related sentences and the vectors on
the right show if the related user visited the locations (venues)
or not.

1https://radimrehurek.com/gensim/models/id97.html

(a) sentence-word data

(b) user-item data

fig. 3: continuous vector representation of the example data for text processing and id126s

in nn approach,    rst

similar users (neighbors) to the target user are selected, and
then the items that are previously preferred by the neighbors
are recommended to the target user. similar to the traditional
approach,
the top-n neighbors are
decided using the similarity among the user vector represen-
tations. then the items that are previously used/preferred by
the top-n neighbors are collected. summing up the votes of
neighbors, the top-k items to recommend are decided. for
example, using the previously presented example in the figure
2, assume that we want to make two location recommendations
to the user u0 by using a single neighbor. according to
continuous vector representations (the figure 3), the most
similar user of user0 is user1(u1) and it is selected as the
neighbor. two of the locations previously visited by user1,
namely    loc0   ,    loc4   ,    loc2   ,    loc3   ,    loc5   ,    loc6   , are
chosen (randomly) and are recommended to the target user
(u0).

recommendation by n-nearest users and k-nearest
items (kiu): this approach is a combination of the previous
two approaches. in this approach,    rst, the top-n neighbors are
found by using the vector representation of the users. then
the top-k items that are most similar to the combination of
target user and the neighbors are found by using the vector
representations calculated in the    rst step. the collected top-
k items are recommended to the target user. for example,
assume that we want to make two location recommendations
to the user u0 by using a single neighbor. as explained in
the previous method, the selected neighbor is u1 based on the
continuous vector similarity. the two most similar location
vectors to the user0   s and user1   s vector belong to    loc2    and
   loc0   . these two locations are recommended to the target
user, u0, by the kiu method.

iv. evaluation

in this work, the aim is to recommend k-many check-in
venues to each user based on their past check-ins. for this
purpose the checkin2011 dataset [6] is used. the original

dataset 2 is collected from foursquare web-site in between
january 2011 - december 2011 and contains 11326 users,
187218 locations, 1385223 check-ins and 47164 friendship
links. however, in [20] the researchers used a subset of this
dataset by using the check-ins made in january as the training
set and check-ins made in february as the test set, and named it
as checkinsjan. the checkinsjan dataset contains 8308 users,
49521 locations and 86375 check-ins. in this work, the same
sub-dataset, checkinsjan dataset, is used for the experiments.
the performance of the methods is measured by preci-
sion@k, ndcg, hitrate and prediction coverage metrics. while
giving the evaluation results, for each user the performance
metrics are calculated separately and then their averages are
presented.

precision@k measures the relevance of items on the output
list. the ndcg (normalized discounted cumulative gain) metric
decides the relevance of the listed items depending on their
rank. since these metrics are well-known in the literature and
because of the limited space, we did not present how these
metrics are calculated in this work. hitrate measures the ratio
of user who are given at least one true recommendation. in the
equation 1, m is one of the users, m is the total set of users,
|m| is the size of the users and hitratem indicates if there
is a hit for the target user m or not. hitratem is equal to 1.0
if there is at least one true recommendation for that user and
0.0 otherwise.

hitrate =

m   m hitratem

|m|

(1)

prediction coverage measures the ratio of the users who are
given any recommendation, independent from being relevant or
not. some of the recommendation methods, e.g. collaborative
   ltering, may not be able to make any recommendation to some
of the users who have not got any preference history or who

2http://www.public.asu.edu/ hgao16/dataset.html

(cid:80)

have unique tastes. for example, in checkinsjan dataset, the
user81 visited ten venues which are never visited by any other
user. making recommendation to these kind of users, known
as cold-start users in the literature, is a challenging task. in the
id126s literature, some of the methods may
loose coverage in order to increase the accuracy [4]. [8] states
that coverage and accuracy should be analyzed together.

the methods presented in this report use two parameters:
number of neighbors (n) and output list size (k). in [20] it is
decided that best performing values are n = 30 and k = 10 for
the checkinsjan dataset. in this work, the values are directly
used for the experiments. the upper-bound of the methods
based on the decided parameters are also presented in [20]:
the upper-bound for precision metric is found as 0.489 and
for the rest of the metrics they are found as 1.0.

several different settings are evaluated when the input
data is modeled using skip-gram and cbow techniques. the
parameters used during the training affects the performance
in terms of time and quality [2]. these parameters are based
on the gensim toolbox implementation. in this work only the
parameters that are set to a different value than the default
are detailed; for the rest of the parameters one can refer to
gensim web-page. the details of the parameters and how they
are tuned are as follows:

   

    min word count: the technique ignores the items
whose frequency is less than min word count pa-
rameter. its default value is 5. in natural language
processing, the items (words) that are seen only few
times can be considered as garbage or typo, however
in the id126s the data is very sparse
and having items that are observed only few times
is normal. in order not to lose any item that is not
used frequently,this parameter is set to 1 during the
experiments.
size: size parameter represents the dimension of the
feature vectors and its default value is 100. in [2]
it
is stated that bigger size value can lead more
accurate model, but requires more data. the suggested
values for size parameter is in tens to hundreds
[2]. in our experiments this parameter is referred as
f eature count(f ) and is set to different values in
the range of [10, 100] with 10 increments.
window: window parameter assigns the maximum
distance between the current and the predicted words
and its default value is 5. [2] states that it should
be large enough to capture the semantic relationships
among words. in our experiments this parameter is
referred as context count(c) and is set to different
values in the range of [5, 20] with 5 increments.
however, during the experiments we observed that
cbow does not provide good performance results
when small window size is used. for cbow we
preferred to set the window size to the maximum
length of input vectors.
iter: iter parameter represents the number of itera-
tions on the input data and its default value is 1. in
our experiments it is referred as epoch count(e) and
is set to different values in the range of [5, 25] with 5
increments.

   

   

fig. 4: the time needed to model the input data and make
recommendation

while iterating on the different ranges of one parame-
ter, the other parameters are    xed to a constant value. for
example while iterating on f eature count,
the values of
context count and epoch count are    xed. the constant val-
ues for the parameters are set to: f eature count(f ) = 100,
epoch count(e) = 25, context count(c) = 20 for skip-
gram and context count(c) = 683 for cbow (the maxi-
mum length of input vector is 683 for checkinsjan dataset).

in this work, three different recommendation techniques
that use the models trained by id97 techniques are
proposed. these techniques are    recommendation by k-nearest
items (kni)   ,    recommendation by n-nearest users (nn)   
and    recommendation by n-nearest users and k-nearest items
(kiu)   . the time spent to train the model by skip-gram or
cbow techniques and to make recommendation to all target
users are presented on the figure 4. the presented time
results are calculated by taking the average of time spent
when combinations of f eature count, context count and
epoch count values are used. according to the figure 4, train-
ing the model using the skip-gram technique spends less time
than cbow technique. skip-gram technique spends about 50
seconds for training while cbow spends about 150 seconds
on the average. among the proposed recommendation methods
kni method spends less time than other methods. this can be
the result of the fact that this method directly uses the output of
the model created by id97 techniques without any further
computations, such as    nding neighbors. on the average kni
method spends less than 50 seconds to make recommendation
to all target users, while both nn and kiu methods spend
around 1500 seconds. these results indicate that the proposed
methods spend less than 0.20 seconds for each target user in
the recommendation step.

the figures 5a, 5b and 5c show the the recommendation
performance of the proposed methods which use continuous
vectors produced by skip-gram technique. for all of the meth-
ods, increasing the f eature count, i.e. the size of the vector
representation, improves the performance. the effect of the
increase for this parameter is less obvious as it is set to higher
values than 50. when context count(c) = 5 the model is
not able to capture the semantic similarity among the items
and users. after setting this parameter to c = 10 and higher,
it performs better. for both context count and epoch count,
increase of the parameters slightly improves the performance.
similar observations can be made when cbow is used as the
   rst step to produce the continuous vector representations of

the input data (the figures 5d, 5e and 5f).

according to figures 5a-5f, the comparison of the perfor-
mance of the recommendation techniques indicates that the
best performing method is kni, followed by kiu. both of
these methods use the vector representations of the items and
their similarities to the target users. both kni and kiu uses
similarity to item vectors, however kiu additionally uses the
neighbors of the target users, which are decided by user vector
similarities. compared to kni, the use of neighbors in kiu
does not provide high performance gain. this may indicate
that use of user vector similarities for checkinsjan dataset is
not effective. this may root from the fact that the users could
not be differentiated in the vector space ef   ciently since the
number of users in the dataset is not very high, i.e. only 8307
users.

comparison of the techniques that use cbow to the
techniques that use skip-gram shows that using the continuous
vectors produced by skip-gram technique performs slightly
better than using the ones produced by cbow. this can
be related to the characteristics of the input data. in the
checkinsjan dataset the check-ins in the prede   ned window
do not necessarily related except they are visited by the same
user. for example, the check-ins may be done in different time
of the day (e.g. morning, evening), but still listed in sequence;
such that the related user did not visit any other venue in
between. this may lead to poorer performance, as cbow
uses window-sized data listed in sequence to decide on the
relevance of the items (venues).

in the table i, the proposed kni, nn and kiu methods
are compared to the methods in the literature. the    rst method
from the recommendation literature is traditional collaborative
   ltering method (cf-c) which uses the past preferences of
the users and their similarities. we implemented this method to
observe its performance. the second method is random, which
randomly chooses k-many items (venues) to recommend. we
run random method 10 times and presented the average of the
results.

the third and fourth methods use id105;
the third one is svd based recommendation, proposed by
sarwar et al. [22] and the fourth one ccd++ algorithm, is
proposed by yu et al. [26]. in the original ccd++ method,
rating prediction of missing items are calculated, such that the
method predicts the ratings of unseen items and recommends
the items that have the highest predicted score. however, the
problem proposed in this work does not aim to predict rating
but aim to rank items. to solve this problem using ccd++,
we adopted ideas from svd based recommendation method
[22] to ccd++ algorithm [26]. in both of the methods, the
input user-item matrix is decomposed into other matrices one
of which represents the user-latent features relations (u). after
reducing the dimension of the u matrix (ut), recommendation
is made by calculating the similarities among users-latent
feature vectors, choosing the most similar users (neighbors)
to the target user and listing the items which are previously
used (e.g. venues that are previously visited) by the neighbors
as recommendation. we used libpmf and sparsesvd libraries
for id105 and implemented the rest of the method
ourselves.

the    fth and sixth methods are from [6], which uses a lan-

table i: comparison of methods

method

precision

kni(skip-gram)
nn(skip-gram)
kiu(skip-gram)
kni(cbow)
nn(cbow)
kiu(cbow)

cf-c
random

svd
ccd++
gao-h
gao-sh
mo-cfih
mo-ch

0.119
0.070
0.112
0.112
0.062
0.102
0.114
0.0001
0.058
0.073
0.174
0.167
0.105
0.112

ndcg
0.169
0.117
0.161
0.165
0.100
0.150
0.242
0.0001
0.104
0.121
0.299
0.295
0.218
0.227

hitrate
0.618
0.450
0.599
0.586
0.401
0.555
0.621
0.001
0.392
0.461
0.696
0.721
0.596
0.616

coverage

1.000
1.000
1.000
1.000
1.000
1.000
0.955
1.000
1.000
1.000
0.952
0.992
0.999
0.996

guage model based method from natural language processing
literature for recommendation. the method can combine past
preferences and social ties of users. two versions of the meth-
ods are proposed; one of which uses only the past preferences
of the users (gao-h) and the other uses the combination of
past preferences and social ties (gao-sh). we directly used the
provided code in the authors    web-page. the last two methods
are from [20], which are based on multi-objective optimization
technique and combines past preferences of the users with
other features, such as users    hometowns, friendship relations
and their in   uence on each other. the methods are abbreviated
as mo-ch when it uses past check-ins and hometowns of the
users and mo-cfih when it uses all of the above-mentioned
features. for the experiments of mo based methods, the code
provided by the authors is used.

in the table i    rst group of methods are the ones that
are proposed in this paper, the second group are the ones
that use a single feature (the past check-ins of the users) and
the last group are the methods that combine multiple features
to make recommendation. among the proposed methods, the
best performing method is kni which uses continuous vector
representation modeled by skip-gram technique. nn performs
poorer than the others, which indicates that recommending
items that are only used by neighbors is not able to capture
the preference of the target user, and use of item similarity
to the target user is more promising. the random method   s
poor performance show that making venue recommendation
on checkinsjan dataset is challenging, since there are many
items to recommend, e.g. nearly 50000 venues.

the nn, cf, svd-based and ccd++ methods have similar
steps: finding neighbors and recommending venues that are
visited by neighbors. interestingly,
learn
low-dimensional vector space representation of the input data
(nn, svd-based and ccd++) are worse than the method that
directly use user similarity (cf). this may be result of the
sparsity of the checkinsjan data, such that nn, svd-based
and ccd++ methods are not able to model the user relations
as well as modeling the user-item and item-item relations.

the methods that

among the listed methods, the best performing methods
are gao-h and gao-sh, which use language model technique
from natural language processing. this result shows that use of
methods from natural language processing can be effective for
making recommendations. even though gao-h and gao-sh
are better at accuracy related metrics, they are not able to make

(a) performance results of kni (skip-gram)

(b) performance results of nn (skip-gram)

(c) performance results of kiu (skip-gram)

(d) performance results of kni (cbow)

(e) performance results of nn (cbow)

(f) performance results of kiu (cbow)

fig. 5: performance results of the proposed methods

predictions for some of the users. for example, having 0.952
prediction coverage ratio, gao-h cannot make recommenda-
tion to about 350 of the users. some of the methods in the liter-
ature may not make any recommendation to more challenging
users, such as users who have not got any preference history
or who have unique tastes. making recommendation to these
challenging users may lead to reduced accuracy results, since
it is harder to make true recommendations for them. in terms
of prediction coverage, the methods proposed in this paper
and id105 methods are the better than the others.
overall, results show that use of id97 techniques produce
comparable performance to the methods in the literature and
they are promising for making recommendations.

v. conclusion

id126s predict the future preferences of
users based on their previous interactions with the items. in
the literature, there are many different techniques to make
recommendations, e.g. neighborhood based, machine-learning
based and matrix-factorization based methods. in this work,
we employed id97   s skip-gram and cbow techniques
to make next check-in venue (location) recommendations on
location based social networks (lbsns). we proposed sev-
eral different techniques that combines id97 techniques
and the well-known recommendation methods, namely content
based and collaborative    ltering based methods. unlike the
previous works that use id97 for recommendation ([23],
[19]), we used a non-textual feature, namely the past check-ins

of the users, to make recommendations. for the evaluation a
foursquare check-in dataset, which is already used in previous
works ([6], [20]) is employed. also comparisons to methods
from the id126s literature are presented. the
results show that use of techniques from natural language
processing is effective and use of id97 techniques is
promising for making recommendations.

in the future, more experiments will be done using the
other datasets used in the recommendation literature to observe
the effectiveness of the proposed methods. also, we will
integrate multiple features while using continuous vector space
representations, as previous works showed that combining
multiple features increases the recommendation performance.

references

   id97,    https://code.google.com/p/id97/.
   id97tutorial,    http://rare-technologies.com/id97-tutorial/.

[1]
[2]
[3] s. arora, y. li, y. liang, t. ma, and a. risteski,    id93 on
context spaces: towards an explanation of the mysteries of semantic
id27s,    corr, vol. abs/1502.03520, 2015.

[4] a. bellog    n, i. cantador, f. d    ez, p. castells, and e. chavarriaga,
   an empirical comparison of social, collaborative    ltering, and hybrid
recommenders,    acm tist, vol. 4, no. 1, p. 14, 2013.

[5] c. cheng, h. yang, m. r. lyu, and i. king,    where you like to
go next: successive point-of-interest recommendation,    in ijcai 2013,
proceedings of the 23rd international joint conference on arti   cial
intelligence, beijing, china, august 3-9, 2013, 2013.

[23] d. shin, s. cetintas, and k. lee,    recommending tumblr blogs to
follow with inductive matrix completion,    in poster proceedings of the
8th acm conference on recommender systems, recsys 2014, foster
city, silicon valley, ca, usa, october 6-10, 2014, 2014.

[24] m. tavakolifard and k. c. almeroth,    social computing: an intersection
of recommender systems, trust/reputation systems, and social networks,   
ieee network, vol. 26, no. 4, pp. 53   58, 2012.

[25] h. wang, n. wang, and d. yeung,    collaborative deep learning for

recommender systems,    corr, vol. abs/1409.2944, 2014.

[26] h.-f. yu, c.-j. hsieh, s. si, and i. s. dhillon,    scalable coordinate
descent approaches to parallel id105 for recommender
systems,    in ieee international conference of data mining, 2012.

[27] v. w. zheng, y. zheng, x. xie, and q. yang,    collaborative location
and activity recommendations with gps history data,    in proceedings
of the 19th international conference on world wide web, www 2010,
raleigh, north carolina, usa, april 26-30, 2010, 2010, pp. 1029   1038.

[6] h. gao, j. tang, and h. liu,    exploring social-historical

ties on
location-based social networks,    in proceedings of the sixth interna-
tional conference on weblogs and social media, dublin, ireland, june
4-7, 2012, 2012.

[7] k. georgiev and p. nakov,    a non-iid framework for collaborative
   ltering with restricted id82s,    in proceedings of the 30th
international conference on machine learning, icml 2013, atlanta,
ga, usa, 16-21 june 2013, 2013, pp. 1148   1156.
j. l. herlocker, j. a. konstan, l. g. terveen, and j. riedl,    evaluating
collaborative    ltering recommender systems,    acm trans. inf. syst.,
vol. 22, no. 1, pp. 5   53, 2004.

[8]

[9] y. koren, r. m. bell, and c. volinsky,    id105 techniques
for recommender systems,    ieee computer, vol. 42, no. 8, pp. 30   37,
2009.

[10] q. v. le and t. mikolov,    distributed representations of sentences and
documents,    in proceedings of the 31th international conference on
machine learning, icml 2014, beijing, china, 21-26 june 2014, 2014,
pp. 1188   1196.

[11] y. li, l. xu, f. tian, l. jiang, x. zhong, and e. chen,    word
embedding revisited: a new representation learning and explicit matrix
factorization perspective,    in proceedings of the twenty-fourth interna-
tional joint conference on arti   cial intelligence, ijcai 2015, buenos
aires, argentina, july 25-31, 2015, 2015, pp. 3650   3656.

[12] d. lian, c. zhao, x. xie, g. sun, e. chen, and y. rui,    geomf: joint
geographical modeling and id105 for point-of-interest
recommendation,    in the 20th acm sigkdd international conference
on knowledge discovery and data mining, kdd    14, new york, ny,
usa - august 24 - 27, 2014, 2014, pp. 831   840.

[13] x. liu and k. aberer,    soco: a social network aided context-aware
recommender system,    in 22nd international world wide web confer-
ence, www    13, rio de janeiro, brazil, may 13-17, 2013, 2013, pp.
781   802.

[14] h. ma, h. yang, m. r. lyu, and i. king,    sorec: social recommendation
using probabilistic id105,    in proceedings of the 17th
acm conference on information and knowledge management, cikm
2008, napa valley, california, usa, october 26-30, 2008, 2008, pp.
931   940.

[15] h. ma, d. zhou, c. liu, m. r. lyu, and i. king,    recommender
systems with social id173,    in proceedings of the forth in-
ternational conference on web search and web data mining, wsdm
2011, hong kong, china, february 9-12, 2011, 2011, pp. 287   296.

[16] p. massa and p. avesani,    trust-aware recommender systems,    in
proceedings of the 2007 acm conference on recommender systems,
recsys 2007, minneapolis, mn, usa, october 19-20, 2007, 2007, pp.
17   24.

[17] t. mikolov, k. chen, g. corrado, and j. dean,    ef   cient estimation of
word representations in vector space,    corr, vol. abs/1301.3781, 2013.
[18] t. mikolov, i. sutskever, k. chen, g. s. corrado, and j. dean,
   distributed representations of words and phrases and their compo-
sitionality,    in advances in neural information processing systems 26:
27th annual conference on neural information processing systems
2013. proceedings of a meeting held december 5-8, 2013, lake tahoe,
nevada, united states., 2013, pp. 3111   3119.

[19] c. musto, g. semeraro, m. de gemmis, and p. lops,    word embed-
ding techniques for content-based recommender systems: an empirical
evaluation,    in poster proceedings of
the 9th acm conference on
recommender systems, recsys 2015, vienna, austria, september 16,
2015., 2015.

[20] m. g. ozsoy, f. polat, and r. alhajj,    multi-objective optimization
based location and social network aware recommendation,    in 10th
ieee international conference on collaborative computing: network-
ing, applications and worksharing, collaboratecom 2014, miami,
florida, usa, october 22-25, 2014, 2014, pp. 233   242.

[21] r. salakhutdinov, a. mnih, and g. e. hinton,    restricted boltzmann
machines for collaborative    ltering,    in machine learning, proceedings
of the twenty-fourth international conference (icml 2007), corvallis,
oregon, usa, june 20-24, 2007, 2007, pp. 791   798.

[22] b. m. sarwar, g. karypis, j. a. konstan, and j. t. riedl,    application
of id84 in recommender systems: a case study,    in
webkdd workshop at the acm sigkkd, 2000.

