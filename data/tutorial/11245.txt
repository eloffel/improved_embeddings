6
1
0
2

 
l
u
j
 

2
2

 
 
]
l
c
.
s
c
[
 
 

2
v
0
7
3
7
0

.

4
0
6
1
:
v
i
x
r
a

parsing argumentation structures in
persuasive essays

christian stab   
technische universit  t darmstadt

iryna gurevych      
technische universit  t darmstadt and
german institute for educational
research

in this article, we present a novel approach for parsing argumentation structures. we identify
argument components using sequence labeling at the token level and apply a new joint model
for detecting argumentation structures. the proposed model globally optimizes argument com-
ponent types and argumentative relations using integer id135. we show that our
model considerably improves the performance of base classi   ers and signi   cantly outperforms
challenging heuristic baselines. moreover, we introduce a novel corpus of persuasive essays
annotated with argumentation structures. we show that our annotation scheme and annotation
guidelines successfully guide human annotators to substantial agreement. this corpus and the
annotation guidelines are freely available for ensuring reproducibility and to encourage future
research in computational argumentation.1

1. introduction

argumentation is a verbal activity which aims at increasing or decreasing the accept-
ability of a controversial standpoint (van eemeren, grootendorst, and snoeck henke-
mans 1996, p. 5). it is a routine which is omnipresent in our daily verbal communication
and thinking. well-reasoned arguments are not only important for decision making and
learning but also play a crucial role in drawing widely-accepted conclusions.

computational argumentation is a recent research    eld in computational linguistics
that focuses on the analysis of arguments in natural language texts. novel methods
have broad application potential in various areas like legal decision support (mochales-
palau and moens 2009), information retrieval (carstens and toni 2015), policy mak-
ing (sardianos et al. 2015), and debating technologies (levy et al. 2014; rinott et al.
2015). recently, computational argumentation has been receiving increased attention in
computer-assisted writing (song et al. 2014; stab and gurevych 2014b) since it allows the
creation of writing support systems that provide feedback about written arguments.

argumentation structures are closely related to discourse structures such as de   ned
by rhetorical structure theory (rst) (mann and thompson 1987), penn discourse treebank
(pdtb) (prasad et al. 2008), or segmented discourse representation theory (sdrt) (asher
and lascarides 2003). the internal structure of an argument consists of several argument

universit  t darmstadt

    ubiquitous knowledge processing lab (ukp-tuda), department of computer science, technische
       ubiquitous knowledge processing lab (ukp-tuda), department of computer science, technische
universit  t darmstadt and ubiquitous knowledge processing lab (ukp-dipf), german institute for
educational research

1 www.ukp.tu-darmstadt.de/data/argumentation-mining

   2016 association for computational linguistics

computational linguistics

volume ?, number ?

components. it includes a claim and one or more premises (govier 2010). the claim is
a controversial statement and the central component of an argument, while premises
are reasons for justifying (or refuting) the claim. moreover, arguments have directed
argumentative relations, describing the relationships one component has with another.
each such relation indicates that the source component is either a justi   cation for or a
refutation of the target component.

the identi   cation of argumentation structures involves several subtasks like sepa-
rating argumentative from non-argumentative text units (moens et al. 2007; florou et
al. 2013), classifying argument components into claims and premises (mochales-palau
and moens 2011; rooney, wang, and browne 2012; stab and gurevych 2014b), and
identifying argumentative relations (mochales-palau and moens 2009; peldszus 2014;
stab and gurevych 2014b). however, an approach which covers all subtasks is still
missing. furthermore, most approaches operate locally and do not optimize the global
argumentation structure. recently, peldszus and stede (2015) proposed an approach
based on minimum spanning trees (mst) which jointly models argumentation structures.
however, it links all argument components in a single tree structure. consequently,
it is not capable of separating several arguments and recognizing unlinked argument
components (e.g. unsupported claims). in addition to the lack of end-to-end approaches
for parsing argumentation structures, there are relatively few corpora annotated with
argumentation structures at the discourse-level. apart from our previous corpus (stab
and gurevych 2014a), the few existing corpora lack non-argumentative text units (peld-
szus 2014), contain text genres different from our target domain (kirschner, eckle-
kohler, and gurevych 2015), or the reliability is unknown (reed et al. 2008).

our primary motivation for this work is to create argument analysis methods
for argumentative writing support systems and to achieve a better understanding
of argumentation structures. therefore, our    rst research question is whether human
annotators can reliably identify argumentation structures in persuasive essays and
if it is possible to create annotated data of high quality. the second research ques-
tion addresses the automatic recognition of argumentation structure. we investigate
if, and how accurately, argumentation structures can be identi   ed by computational
techniques. the contributions of this article are the following:

   

   

   

an annotation scheme for modeling argumentation structures derived from
argumentation theory. our annotation scheme models the argumentation
structure of a document as a connected tree.
a novel corpus of 402 persuasive essays annotated with discourse-level
argumentation structures. we show that human annotators can apply our
annotation scheme to persuasive essays with substantial agreement.
an end-to-end argumentation structure parser which identi   es argument
components at the token level and globally optimizes component types
and argumentative relations.

the remainder of this article is structured as follows: in section 2, we review related
work in computational argumentation and discuss the difference to traditional dis-
course analysis. in section 3, we derive our annotation scheme from argumentation
theory. section 4 presents the results of an annotation study and the corpus creation.
in section 5, we introduce the argumentation structure parser. we show that our model
considerably improves the performance of base classi   ers and signi   cantly outperforms
challenging heuristic baselines. we conclude the article with a discussion in section 6.

2

stab and gurevych

parsing argumentation structures

2. related work

existing work in computational argumentation addresses a variety of different tasks.
these include, for example, approaches for identifying reasoning type (feng and hirst
2011), argumentation style (oraby et al. 2015), the stance of the author (somasundaran
and wiebe 2009; hasan and ng 2014), the acceptability of arguments (cabrio and villata
2012), and appropriate support types (park and cardie 2014). most relevant to our
work, however, are approaches on argument mining that focus on the identi   cation of
argumentation structures in natural language texts. we categorize related approaches
into the following three subtasks:

   

   

   

component identi   cation focuses on the separation of argumentative from
non-argumentative text units and the identi   cation of argument
component boundaries.
component classi   cation addresses the function of argument components. it
aims at classifying argument components into different types such as
claims and premises.
structure identi   cation focuses on linking arguments or argument
components. its objective is to recognize different types of argumentative
relations such as support or attack relations.

2.1 component identi   cation

moens et al. (2007) identi   ed argumentative sentences in various types of text such as
newspapers, parliamentary records and online discussions. they experimented with
various different features and achieved an accuracy of .738 with word pairs, text statis-
tics, verbs and keyword features. florou et al. (2013) classi   ed text segments as argu-
mentative or non-argumentative using discourse markers and several features extracted
from the tense and mood of verbs. they report an f1 score of .764. levy et al. (2014) pro-
posed a pipeline including three consecutive steps for identifying context-dependent
claims in wikipedia articles. their    rst component detects topic-relevant sentences
including a claim. the second component detects the boundaries of each claim. the
third component ranks the identi   ed claims for identifying the most relevant claims
for the given topic. goudas et al. (2014) presented a two-step approach for identifying
argument components and their boundaries in social media texts. first, they classi   ed
each sentence as argumentative or non-argumentative and achieved an accuracy of .774.
second, they segmented each argumentative sentence using a conditional random    eld
(crf). their best model achieved an accuracy of .424.

2.2 component classi   cation

the objective of the component classi   cation task is to identify the type of argument
components. kwon et al. (2007) proposed two consecutive steps for identifying differ-
ent types of claims in online comments. first, they classi   ed sentences as claims and
obtained an f1 score of .55 with a boosting algorithm. second, they classi   ed each
claim as either support, oppose or propose. their best model achieved an f1 score
of .67. rooney, wang, and browne (2012) applied kernel methods for classifying text
units as either claims, premises or non-argumentative. they obtained an accuracy of
.65. mochales-palau and moens (2011) classi   ed sentences in legal decisions as claim

3

computational linguistics

volume ?, number ?

or premise. they achieved an f1 score of .741 for claims and .681 for premises using a
support vector machine (id166) with domain-dependent key phrases, text statistics, verbs,
and the tense of the sentence. in our previous work, we used a multiclass id166 for la-
beling text units of student essays as major claim, claim, premise, or non-argumentative
(stab and gurevych 2014b). we obtained an accuracy of .773 using structural, lexical,
syntactic, indicator and contextual features. recently, nguyen and litman (2015) found
that argument and domain words from unlabeled data increases accuracy to .79 using
the same corpus, and lippi and torroni (2015) achieved promising results using partial
tree kernels for identifying sentences containing a claim.

2.3 structure identi   cation

approaches on structure identi   cation can be divided into macro-level approaches and
micro-level approaches. macro-level approaches such as presented by cabrio and vil-
lata (2012), ghosh et al. (2014), or boltu  i  c and   najder (2014) address relations between
complete arguments and ignore the microstructure of arguments. more relevant to our
work, however, are micro-level approaches, which focus on relations between argument
components. mochales-palau and moens (2009) introduced one of the    rst approaches
for identifying the microstructure of arguments. their approach is based on a manually
created context-free grammar (id18) and recognizes argument structures as trees. how-
ever, it is tailored to legal argumentation and does not recognize implicit argumentative
relations, i.e. relations which are not indicated by discourse markers. in previous work,
we de   ned the task as the binary classi   cation of ordered argument component pairs
(stab and gurevych 2014b). we classi   ed each pair as support or not-linked using an
id166 with structural, lexical, syntactic and indicator features. our best model achieved
an f1 score of .722. however, the approach recognizes argumentative relations locally
and does not consider contextual information. peldszus (2014) modeled the targets of
argumentative relations along with additional information in a single tagset. his tagset
includes, for instance, several labels denoting if an argument component at position
n is argumentatively related to preceding argument components n     1, n     2, etc. or
following argument components n + 1, n + 2, etc. although his approach achieved a
promising accuracy of .48, it is only applicable to short texts. peldszus and stede (2015)
presented the    rst approach which globally optimizes argumentative relations. they
jointly modeled several aspects of argumentation structures using an mst model and
achieved an f1 score of .720. they found that the function (support or attack) and the
role (opponent and proponent) of argument components are the most useful dimen-
sions for improving the identi   cation of argumentative relations. their corpus, how-
ever, is arti   cially created and includes a comparatively high proportion of opposing
argument components (cf. section 2.4). therefore, it is unclear whether the results can
be reproduced with real data. moreover, their approach links all argument components
in a single tree structure. thus, it is not capable of separating several arguments and
recognizing unlinked components.

2.4 existing corpora annotated with argumentation structures

existing corpora in computational argumentation cover numerous aspects of argumen-
tation analysis. there are, for instance, corpora which address argumentation strength
(persing and ng 2015), factual knowledge (beigman klebanov and higgins 2012),
various properties of arguments (walker et al. 2012), argumentative relations between
complete arguments at the macro-level (cabrio and villata 2014; boltu  i  c and   najder

4

stab and gurevych

parsing argumentation structures

2014), different types of argument components (mochales-palau and ieven 2009; kwon
et al. 2007; habernal and gurevych 2016), and argumentation structures over several
documents (aharoni et al. 2014). however, corpora annotated with argumentation
structures at the level of discourse are still rare.

one prominent resource is araucariadb (reed et al. 2008). it includes heterogenous
text types such as newspaper editorials, parliamentary records, judicial summaries and
online discussions. it also includes annotations for the reasoning type and implicit argu-
ment components, which were added by the annotators during the analysis. however,
the reliability of the annotations is unknown.

kirschner, eckle-kohler, and gurevych (2015) annotated argumentation structures
in introduction and discussion sections of 24 german scienti   c articles. their annotation
scheme includes four argumentative relations (support, attack, detail and sequence).
however, the corpus does not include annotations for argument component types.

peldszus and stede (2015) created a small corpus of 112 german microtexts with
controlled linguistic and rhetoric complexity. each document includes a single argu-
ment and does not include more than    ve argument components. their annotation
scheme models supporting and attacking relations as well as additional information like
proponent and opponent. they obtained an inter-annotator agreement (iaa) of    = .83
with three expert annotators. recently, they translated the corpus to english resulting
in the    rst parallel corpus for computational argumentation. however, the corpus does
not include non-argumentative text units. therefore, the corpus is only of limited use
for training end-to-end argumentation structure parsers. due to the employed writing
guidelines (peldszus and stede 2013, p. 197), it also exhibits an unusually high propor-
tion of attack relations. in particular, 97 of the 112 arguments (86.6%) include at least
one attack relation.

table 1
existing corpora annotated with argumentation structures at the discourse-level (#doc = number
of documents; #comp = number of argument components; noarg = presence of non-argumen-
tative text units; *recent releases do not include non-argumentative text units).

source

(reed et al. 2008)

(stab and gurevych 2014a)
(peldszus and stede 2015)

(kirschner et al. 2015)

genre
various

student essays

microtexts

scienti   c articles

#doc
~700
90
112
24

#comp
~2,000
1,552
576

~2,700

noarg
yes*
yes
no
yes

granularity

clause
clause
clause
sentence

iaa

unknown
  u = .72
   = .83
   = .43

in previous work, we created a corpus of 90 persuasive essays, which we selected
randomly from essayforum.com (stab and gurevych 2014a). we annotated the cor-
pus in two consecutive steps: first, we identi   ed argument components at the clause
level and obtained an inter-annotator agreement of   u = .72 between three annotators.
second, we annotated argumentative support and attack relations between argument
components and achieved an inter-annotator agreement of    = .8. in contrast to the
microtext corpus from peldszus, the corpus includes non-argumentative text units and
exhibits a more realistic proportion of argumentative attack relations since the essays
were not written in a controlled experiment. apart from this corpus, we are only aware
of one additional study on argumentation structures in persuasive essays. botley (2014)
analyzed 10 essays using argument diagramming for studying differences in argumen-
tation strategies. unfortunately, the corpus is too small for computational purposes and
the reliability of the annotations is unknown. table 1 provides an overview of existing
corpora annotated with argumentation structures at the discourse-level.

5

computational linguistics

volume ?, number ?

2.5 discourse analysis

the identi   cation of argumentation structures is closely related to discourse analysis.
similar to the identi   cation of argumentation structures, discourse analysis aims at
identifying elementary discourse units and discourse relations between them. existing
approaches on discourse analysis mainly differ in the employed discourse theory. rst
(mann and thompson 1987), for instance, models discourse structures as trees by
iteratively linking adjacent discourse units (feng and hirst 2014; hernault et al. 2010)
while approaches based on pdtb (prasad et al. 2008) identify more shallow structures
by linking two adjacent sentences or clauses (lin, ng, and kan 2014). whereas rst
and pdtb are limited to discourse relations between adjacent discourse units, sdrt
(asher and lascarides 2003) also allows long distance relations (afantenos and asher
2014; afantenos et al. 2015). however, similar to argumentation structure parsing the
main challenge of discourse analysis is to identify implicit discourse relations (braud
and denis 2014, p. 1694).

marcu and echihabi (2002) proposed one of the    rst approaches for identifying
implicit discourse relations. in order to collect large amounts of training data, they ex-
ploited several discourse markers like    because    or    but   . after removing the discourse
markers, they found that word pair features are useful for identifying implicit discourse
relations. pitler, louis, and nenkova (2009) proposed an approach for identifying four
implicit types of discourse relations in the pdtb and achieved f1 scores between .22 and
.76. they found that using features tailored to each individual relation leads to the best
results. lin, kan, and ng (2009) showed that production rules collected from parse trees
yield good results and louis et al. (2010) found that features based on named entities
do not perform as well as lexical features.

approaches to discourse analysis usually aim at identifying various different types
of discourse relations. however, only a subset of these relations is relevant for argu-
mentation structure parsing. for example, peldszus and stede (2013) proposed support,
attack and counter-attack relations for modeling argumentation structures, whereas our
work focuses on support and attack relations. this difference is also illustrated by the
work of biran and rambow (2011). they selected a subset of 12 relations from the rst
discourse treebank (carlson, marcu, and okurowski 2001) and argue that only a subset of
rst relations is relevant for identifying justi   cations.

3. argumentation: theoretical background

the study of argumentation is a comprehensive and interdisciplinary research    eld. it
involves philosophy, communication science, logic, linguistics, psychology, and com-
puter science. the    rst approaches to studying argumentation date back to the an-
cient greek sophists and evolved in the 6th and 5th centuries b.c. (van eemeren,
grootendorst, and snoeck henkemans 1996). in particular, the in   uential works of
aristotle on traditional logic, rhetoric, and dialectics set an important milestone and are
a cornerstone of modern argumentation theory. due to the diversity of the    eld, there
are numerous proposals for modeling argumentation. bentahar, moulin, and b  langer
(2010) categorize argumentation models into three types: (i) monological models, (ii)
dialogical models, and (iii) rhetorical models. monological models address the internal
microstructure of arguments. they focus on the function of argument components,
the links between them, and the reasoning type. most monological models stem from
the    eld of informal logic and focus on arguments as product (johnson 2000; o   keefe
1977). on the other hand, dialogical models focus on the process of argumentation and

6

stab and gurevych

parsing argumentation structures

ignore the microstructure of arguments. they model the external macrostructure and
address relations between arguments in dialogical communications. finally, rhetorical
models consider neither the micro- nor the macrostructure but rather the way arguments
are used as a means of persuasion. they consider the audience   s perception and aim
at studying rhetorical schemes that are successful in practice. in this article, we focus
on the monological perspective which is well-suited for developing computational
methods (peldszus and stede 2013; lippi and torroni 2016).

3.1 argument diagramming

the laying out of argument structure is a widely used method in informal logic (copi
and cohen 1990; govier 2010). this technique, referred to as argument diagramming,
aims at transferring natural language arguments into a structured representation for
evaluating them in subsequent analysis steps (henkemans 2000, p. 447). although
argumentation theorists consider argument diagramming a manual activity, the dia-
gramming conventions also serve as a good foundation for developing novel argument
mining models (peldszus and stede 2013). an argument diagram is a node-link diagram

figure 1
microstructures of arguments: nodes are argument components and links represent
argumentative relations. nodes at the bottom are the claims of the arguments.

whereby each node represents an argument component, i.e. a statement represented in
natural language and each link represents a directed argumentative relation indicating
that the source component is a justi   cation (or refutation) of the target component. for
example, figure 1 shows some common argument structures. a basic argument includes
a claim supported by a single premise. it can be considered the minimal form an ar-
gument can take. a convergent argument comprises two premises that support the claim
individually; an argument is serial if it includes a reasoning chain and divergent if a single
premise supports several claims (beardsley 1950). complementarily, thomas (1973)
de   ned linked arguments (figure 1e). like convergent arguments, a linked argument
includes two premises. however, neither of the two premises independently supports
the claim. the premises are only relevant to the claim in conjunction. more complex
arguments can combine any of these elementary structures illustrated in figure 1.

on closer inspection, however, there are several ambiguities when applying argu-
ment diagramming to real texts: first, the distinction between convergent and linked
structures is often ambiguous in real argumentation structures (henkemans 2000; free-
man 2011). second, it is unclear if the argumentation structure is a graph or a tree. third,
the argumentative type of argument components is ambiguous in serial structures. we
discuss each of these questions in the following sections.

3.1.1 distinguishing between linked and convergent arguments. the question if an
argumentation model needs to distinguish between linked and convergent arguments is

7

computational linguistics

volume ?, number ?

still debated in argumentation theory (van eemeren, grootendorst, and snoeck henke-
mans 1996; freeman 2011; yanal 1991; conway 1991). from a perspective based on
traditional logic, linked arguments indicate deductive reasoning and convergent argu-
ments represent inductive reasoning (henkemans 2000, p. 453). however, freeman (2011,
p. 91ff.) showed that the traditional de   nition of linked arguments is frequently am-
biguous in everyday discourse. yanal (1991) argues that the distinction is equivalent
to separating several arguments and conway (1991) argues that linked structures can
simply be omitted for modeling single arguments. from a computational perspective,
the identi   cation of linked arguments is equivalent to    nding groups of premises or
classifying the reasoning type of an argument as either deductive or inductive. accord-
ingly, it is not necessary to distinguish linked and convergent arguments during the
identi   cation of argumentation structures since this task can be solved in subsequent
analysis steps.

3.1.2 argumentation structures as trees. de   ning argumentation structures as trees
implies the exclusion of divergent arguments, to allow only one target for each premise
and to neglect cycles. from a theoretical perspective, divergent structures are equivalent
to several arguments (one for each claim) (freeman 2011, p. 16). as a result of this
treatment, a great many of theoretical textbooks neglect divergent structures (henke-
mans 2000; reed and rowe 2004) and also most computational approaches consider
arguments as trees (mochales-palau and moens 2009; cohen 1987; peldszus 2014).
however, there is little empirical evidence regarding the structure of arguments. we are
only aware of one study which showed that 5.26% of the arguments in political speeches
(which can be assumed to exhibit complex argumentation structures) are divergent.

essay writing usually follows a    claim-oriented    procedure (whitaker 2009; shiach
2009; perutz 2010; kemper and sebranek 2004). starting with the formulation of the
standpoint on the topic, authors collect claims in support (or opposition) of their view.
subsequently, they collect premises that support or attack their claims. the following
example illustrates this procedure. a major claim on abortion, for instance, is    abortion
should be illegal   ; a supporting claim could be    abortion is ethically wrong    and the
associated premises    unborn babies are considered human beings    and    killing human beings
is wrong   . due to this common writing procedure, divergent and circular structures are
rather unlikely in persuasive essays. therefore, we assume that modeling the argumen-
tation structure of essays as a tree is a reasonable decision.

3.1.3 argumentation structures and argument component types. assigning argu-
mentative types to the components of an argument is unambiguous if the argumen-
tation structure is shallow. it is, for instance, obvious that an argument component
c1 is a premise and argument component c2 is a claim, if c1 supports c2 in a basic
argument (cf. figure 1). however, if the tree structure is deeper, i.e. exhibits serial
structures, assigning argumentative types becomes ambiguous. essentially, there are
three different approaches for assigning argumentative types to argument components.
first, according to beardsley (1950) a serial argument includes one argument component
which is both a claim and a premise. therefore, the inner argument component bears
two different argumentative types (multi-label approach). second, govier (2010, p. 24)
distinguishes between    main claim    and    subclaim   . similarly, damer (2009, p. 17)
distinguishes between    premise    and    subpremise    for labeling argument components
in serial structures. both approaches de   ne speci   c labels for each level in the argu-
mentation structure (level approach). third, cohen (1987) considers only the root node of
an argumentation tree as a claim and the following nodes in the structure as premises

8

stab and gurevych

parsing argumentation structures

(   one-claim    approach). in order to de   ne an argumentation model for persuasive essays,
we propose a hybrid approach that combines the level approach and the    one-claim   
approach.

3.2 argumentation structures in persuasive essays

we model the argumentation structure of persuasive essays as a connected tree struc-
ture. we use a level approach for modeling the    rst level of the tree and a    one-claim   
approach for representing the structure of each individual argument. accordingly, we
model the    rst level of the tree with two different argument component types and the
structure of individual arguments with argumentative relations.

the major claim is the root node of the argumentation structure and represents the
author   s standpoint on the topic. it is an opinionated statement that is usually stated
in the introduction and restated in the conclusion of the essay. the individual body
paragraphs of an essay include the actual arguments. they either support or attack the
author   s standpoint expressed in the major claim. each argument consists of a claim and
several premises. in order to differentiate between supporting and attacking arguments,
each claim has a stance attribute that can take the values    for    or    against   .

we model the structure of each argument with a    one-claim    approach. the claim
constitutes the central component of each argument. the premises are the reasons of
the argument. the actual structure of an argument comprises directed argumentative
support and attack relations, which link a premise either to a claim or to another premise
(serial arguments). each premise p has one outgoing relation, i.e. there is a relation that
has p as source component, and none or several incoming relations, i.e. there can be a
relation with p as target component. a claim can exhibit several incoming relations but
no outgoing relation. the ambiguous function of inner premises in serial arguments is
implicitly modeled by the structure of the argument. the inner premise exhibits one
outgoing relation and at least one incoming relation. finally, the stance of each premise
is indicated by the type of its outgoing relation (support or attack).

the following example illustrates the argumentation structure of a persuasive es-
say.2 the introduction of an essay describes the controversial topic and usually includes
the major claim:

ever since researchers at the roslin institute in edinburgh cloned an adult sheep, there
has been an ongoing debate about whether cloning technology is morally and ethically
right or not. some people argue for and others against and there is still no agreement
whether cloning technology should be permitted. however, as far as i   m concerned,
[cloning is an important technology for humankind]m ajorclaim1 since [it would
be very useful for developing novel cures]claim1.

the    rst two sentences introduce the topic and do not include argumentative content.
the third sentence contains the major claim (boldfaced) and a claim which supports
the major claim (underlined). the following body paragraphs of the essay include
arguments which either support or attack the major claim. for example, the following
body paragraph includes one argument that supports the positive standpoint of the
author on cloning:

2 the example essay was written by the authors to illustrate all phenomena of argumentation structures in

persuasive essays.

9

computational linguistics

volume ?, number ?

::::::

cloned ::::::

first, [cloning will be bene   cial for many people who are in need of organ trans-
tissue ::of
plants]claim2. [::::::
raised ::::
patients]p remise1 since [ :::they:::can:::be :::::
patient]p remise2.
process]p remise3. usually, [ :it::is ::::very::::rare ::to :::   nd:::an
in addition, [ :it :::::::
healing:::::::
appropriate:::::
organ:::::
required::::::
organs
::the:::::::

donor]p remise4 and [ ::by :::::
shortened :::::::::::

organs::::will::::::match ::::::::
from::::::

waiting::::time:::can:::be ::::::::

stem ::::cells ::of :::the ::::::

tremendously]p remise5.

perfectly ::to:::the::::::

order ::to ::::raise:::::::

shortens:::the::::::

group::::and::::::

cloning::in:::::

using ::::::

blood :::::

cloned ::::

:::::::::

the    rst sentence contains the claim of the argument, which is supported by    ve
premises in the following three sentences (wavy underlined). the second sentence
includes two premises, of which premise1 supports claim2 and premises2 supports
premise1. premise3 in the third sentence supports claim2. the fourth sentence includes
premise4 and premise5. both support premise3. the next paragraph illustrates a body
paragraph with two arguments:

scientists :::use ::::::

animals::as::::::models::in:::::

second, [::::::::
diseases]p remise6
and therefore [cloning animals enables novel developments in science]claim3. further-
more, [ ::::::
related]p remise7. [ ::::even
children]p remise8. consequently, [cloning can help families to
same :::sex ::::::
get children]claim4.

children::::that:::are::::::::::

couples :::can:::::have :::::::

couples::::can ::::have :::::::

genetically ::::::

infertile:::::::

human:::::::

order::to::::

about::::::

learn:::::

::::

the initial sentence includes the    rst argument, which consists of premise6 and claim3.
the following three sentences include the second argument. premise7 and premise8
both support claim4 in the last sentence. both arguments cover different aspects (de-
velopment in science and cloning humans) which both support the author   s standpoint
on cloning. this example illustrates that knowing argumentative relations is important
for separating several arguments in a paragraph. the example also shows that argument
components frequently exhibit preceding text units that are not relevant to the argument
but helpful for recognizing the argument component type. for example, preceding dis-
course connectors like    therefore   ,    consequently   , or    thus    can signal a subsequent
claim. discourse markers like    because   ,    since   , or    furthermore    could indicate a
premises. we refer to these text units as preceding tokens. the third body paragraph
illustrates a contra argument and argumentative attack relations:

could:::be:::::used ::to::::::::::

admittedly, [cloning could be misused for military purposes]claim5. for example,
obedient :::::::
[ :it :::::
soldiers
::::with :::::::::::
ethical ::::::
values :::are
internationally::::::
misused:::for
cloning::::will:::be :::::::
militant:::::::::

abilities]p remise9. however, because [:::::moral::::and ::::::

shared]p remise10, [::it ::is ::::very:::::::

extraordinary:::::::

unlikely::::that:::::::

objectives]p remise11.

manipulate:::::::

genes ::in::::::

create::::::::

order ::to::::::

human::::::

::::::::::::

::::::

the paragraph begins with claim5, which attacks the stance of the author. it is supported
by premise9 in the second sentence. the third sentence includes two premises, both of
which defend the stance of the author. premise11 is an attack of claim5 and premise10
supports premise11. the last paragraph (conclusion) restates the major claim and sum-
marizes the main aspects of the essay:

to sum up, although [permitting cloning might bear some risks like misuse for mil-
itary purposes]claim6, i strongly believe that [this technology is bene   cial to
humanity]m ajorclaim2. it is likely that [this technology bears some important cures
which will significantly improve life conditions]claim7.

the conclusion of the essay starts with an attacking claim followed by the restatement of
the major claim. the last sentence includes another claim that summarizes the most im-

10

stab and gurevych

parsing argumentation structures

portant points of the author   s argumentation. figure 2 shows the entire argumentation
structure of the example essay.

figure 2
argumentation structure of the example essay. arrows indicate argumentative relations.
arrowheads denote argumentative support relations and circleheads attack relations. dashed
lines indicate relations that are encoded in the stance attributes of claims.    p    denotes premises.

4. corpus creation

the motivation for creating a new corpus is threefold: first, our previous corpus is
relatively small. we believe that more data will improve the accuracy of our compu-
tational models. second, we ensure the reproducibility of the annotation study and
validate our previous results. third, we improved our annotation guidelines. we added
more precise rules for segmenting argument components and a detailed description of
common essay structures. we expect that our novel annotation guidelines will guide
annotators towards adequate agreement without collaborative training sessions. our
annotation guidelines comprise 31 pages and include the following three steps:

1.

2.

3.

topic and stance identi   cation: we found in our previous annotation study
that knowing the topic and stance of an essay improves inter-annotator
agreement (stab and gurevych 2014a). for this reason, we ask the
annotators to read the entire essay before starting with the annotation task.
annotation of argument components: annotators mark major claims, claims
and premises. they annotate the boundaries of argument components and
determine the stance attribute of claims.
linking premises with argumentative relations: the annotators identify the
structure of arguments by linking each premise to a claim or another
premise with argumentative support or attack relations.

three non-native speakers with excellent english pro   ciency participated in our anno-
tation study. one of the three annotators already participated in our previous study
(expert annotator). the two other annotators learned the task by independently reading
the annotation guidelines. we used the brat rapid annotation tool (stenetorp et al. 2012).
it provides a graphical web interface for marking text units and linking them.

11

computational linguistics

volume ?, number ?

4.1 data

we randomly selected 402 english essays from essayforum.com. this online forum is
an active community which provides correction and feedback about different texts such
as research papers, essays, or poetry. for example, students post their essays in order to
receive feedback about their writing skills while preparing for standardized language
tests. we manually reviewed each essay and selected only those with a suf   ciently
detailed description of the writing prompt. the corpus includes 7,116 sentences with
147,271 tokens.

4.2 inter-annotator agreement

all three annotators independently annotated a random subset of 80 essays. the re-
maining 322 essays were annotated by the expert annotator. we evaluate the inter-
annotator agreement of the argument component annotations using two different strate-
gies: first, we evaluate if the annotators agree on the presence of argument compo-
nents in sentences using observed agreement and fleiss       (fleiss 1971). we consider
each sentence as a markable and evaluate the presence of each argument component
type t     {m ajorclaim, claim, p remise} in a sentence individually. accordingly, the
number of markables for each argument component type t corresponds to the number of
sentences n = 1,441, the number of annotations per markable equals with the number
of annotators n = 3, and the number of categories is k = 2 (   t    or    not t   ). evaluating
the agreement at the sentence level is an approximation of the actual agreement since
the boundaries of argument components can differ from sentence boundaries and a
sentence can include several argument components.3 therefore, for the second eval-
uation strategy, we employ krippendorff   s   u (krippendorff 2004) which considers
the differences in the component boundaries at the token level. thus, it allows for
assessing the reliability of our annotation study more accurately. for determining the
inter-annotator agreement, we use dkpro agreement whose implementations of inter-
annotator agreement measures are well-tested with various examples from literature
(meyer et al. 2014).

table 2
inter-annotator agreement of argument components.

component type

majorclaim

claim
premise

observed agreement

97.9%
88.9%
91.6%

fleiss      

.877
.635
.833

  u
.810
.524
.824

table 2 shows the inter-annotator agreement of each argument component type.
the agreement is best for major claims. the iaa scores of 97.9% and    = .877 indicate
that annotators reliably identify major claims in persuasive essays. in addition, the
unitized alpha measure of   u = .810 shows that there are only few disagreements about
the boundaries of major claims. the results also indicate good agreement for premises
(   = .833 and   u = .824). we obtain the lowest agreement of    = .635 for claims which

3 in our evaluation set of 80 essays the annotators identi   ed in 4.3% of the sentences several argument

components of different types. thus, evaluating the reliability of argument components at the sentence
level is a good approximation of the inter-annotator agreement.

12

stab and gurevych

parsing argumentation structures

shows that the identi   cation of claims is more complex than identifying major claims
and premises. the joint unitized measure for all argument components is   u = .767,
and thus the agreement improved by .043 compared to our previous study (stab and
gurevych 2014b). therefore, we conclude that human annotators can reliably annotate
argument components in persuasive essays.

for determining the agreement of the stance attribute, we follow the same method-
ology as for the sentence level agreement described above, but we consider each sen-
tence containing a claim as    for    or    against    according to its stance attribute and all
sentences without a claim as    none   . consequently, the agreement of claims constitutes
the upper bound for the stance attribute. we obtain an agreement of 88.5% and    = .623
which is slightly below the agreement scores of claims (cf. table 2). therefore, human
annotators can reliably differentiate between supporting and attacking claims.

we determined the markables for evaluating the agreement of argumentative rela-
tions by pairing all argument components in the same paragraph. for each paragraph
with argument components c1, ..., cn, we consider each pair p = (ci, cj) with 1     i, j     n
and i (cid:54)= j as markable. thus, the set of all markables corresponds to all argument
component pairs that can be annotated according to our guidelines. the number of
argument component pairs is n = 4,922, the number of ratings per markable is n = 3,
and the number of categories k = 2.

table 3
inter-annotator of argumentative relations.

relation type

support
attack

observed agreement

.923
.996

fleiss      

.708
.737

table 3 shows the inter-annotator agreement of argumentative relations. we obtain
for both argumentative support and attack relations   -scores above .7 which allows
tentative conclusions (krippendorff 2004). on average the annotators marked only
0.9% of the 4,922 pairs as argumentative attack relations and 18.4% as argumentative
support relations. although the agreement is usually much lower if a category is rare
(artstein and poesio 2008, p. 573), the annotators agree more on argumentative attack
relations. this indicates that the identi   cation of argumentative attack relations is a
simpler task than identifying argumentative support relations. the agreement scores for
argumentative relations are approximately .10 lower compared to our previous study.
this difference can be attributed to the fact that we did not explicitly annotate relations
between claims and major claims which are easy to annotate due to the known types of
argument components (cf. section 3.2).

4.3 analysis of human disagreement

for analyzing the disagreements between the annotators, we determined confusion
id203 matrices (cpm) (cinkov  , holub, and kr     2012). compared to traditional
confusion matrices, a cpm also allows to analyze confusion if more than two annotators
are involved in an annotation study. a cpm includes conditional probabilities that an
annotator assigns a category in the column given that another annotator selected the
category in the row. table 4 shows the cpm of argument component annotations. it
shows that the highest confusion is between claims and premises. we observed that
one annotator frequently did not split sentences including a claim. for instance, the

13

computational linguistics

volume ?, number ?

table 4
confusion id203 matrix of argument component annotations (   noarg    indicates sentences
without argumentative content).
majorclaim

premise

majorclaim
claim
premise
noarg

.771
.036
.002
.059

claim
.077
.517
.131
.126

.010
.307
.841
.054

noarg
.142
.141
.026
.761

annotator labeled the entire sentence as a claim although it includes an additional
premise. this type of error also explains the lower unitized alpha score compared to the
sentence level agreements in table 2. furthermore, we found that concessions before
claims were frequently not annotated as an attacking premise. for example, annotators
often did not split sentences similar to the following example:

although [ ::in ::::some:::::
convenience of technology outweighs its drawbacks]claim.

technology::::::makes:::::::

cases:::::::::

people   s:::life:::::more ::::::::::

complicated]premise, [the

the distinction between major claims and claims exhibits less confusion. this may
be due to the fact that major claims are relatively easy to locate in essays since they occur
usually in introductions or conclusions whereas claims can occur anywhere in the essay.

table 5
confusion id203 matrix of argumentative relation annotations (   not-linked    indicates
argument component pairs which are not argumentatively related).

support
attack
not-linked

support

.605
.107
.086

attack
.006
.587
.004

not-linked

.389
.307
.910

table 5 shows the cpm of argumentative relations. there is little confusion between
argumentative support and attack relations. the cpm also shows that the highest con-
fusion is between argumentative relations (support and attack) and unlinked pairs. this
can be attributed to the identi   cation of the correct targets of premises. in particular, we
observed that agreement on the targets decreases if a paragraph includes several claims
or serial argument structures.

4.4 creation of the final corpus

we created a partial gold standard of the essays annotated by all annotators. we use this
partial gold standard of 80 essays as our test data (20%) and the remaining 322 essays
annotated by the expert annotator as our training data (80%). the creation of our gold
standard test data consists of the following two steps:    rst, we merge the annotation
of all argument components. thus, each annotator annotates argumentative relations
based on the same argument components. second, we merge the argumentative rela-
tions to compile our    nal gold standard test data. since the argument component types
are strongly related - the selection of the premises, for instance, depends on the selected
claim(s) in a paragraph - we did not merge the annotations using majority voting as in

14

stab and gurevych

parsing argumentation structures

our previous study. instead, we discussed the disagreements in several meetings with
all annotators for resolving the disagreements.

4.5 corpus statistics

table 6 shows an overview of the size of the corpus. it contains 6,089 argument com-
ponents, 751 major claims, 1,506 claims, and 3,832 premises. such a large proportion of
claims compared to premises is common in argumentative texts since writers tend to
provide several reasons for ensuring a robust standpoint (mochales-palau and moens
2011).

table 6
statistics of the    nal corpus.

e
z
i
s

.

p
m
o
c

.

g
r
a

sentences
tokens
paragraphs
arg. components
majorclaims
claims
premises
claims (for)
claims (against)

. support

l
e
r

attack

all

7,116

147,271

1,833
6,089
751
1,506
3,832
1,228
278
3,613
219

avg. per essay

standard deviation

18
366

5
15
2
4
10
3
1
9
1

4.2
62.9
0.6
3.9
0.5
1.2
3.4
1.3
0.8
3.3
0.9

the proportion of non-argumentative text amounts to 47,474 tokens (32.2%) and
1,631 sentences (22.9%). the number of sentences with several argument components
is 583 of which 302 include several components with different types (e.g. a claim fol-
lowed by premise). therefore, the identi   cation of argument components requires the
separation of argumentative from non-argumentative text units and the recognition of
component boundaries at the token level. the proportion of paragraphs with unlinked
argument components (e.g. unsupported claims without incoming relations) is 421
(23%). thus, methods that link all argument components in a paragraph are only of
limited use for identifying the argumentation structures in our corpus.

in total, the corpus includes 1,130 arguments, i.e. claims supported by at least one
premise. only 140 of them have an attack relation. thus, the proportion of arguments
with attack relations is considerably lower than in the microtext corpus from peldszus
and stede (2015). most of the arguments are convergent, i.e. the depth of the argument
is one. the number of arguments with serial structure is 236 (20.9%).

5. approach

our approach for parsing argumentation structures consists of    ve consecutive sub-
tasks depicted in figure 3. the identi   cation model separates argumentative from non-
argumentative text units and recognizes the boundaries of argument components. the
next three models constitute a joint model for recognizing the argumentation structure.
we train two base classi   ers. the argument component classi   cation model labels each
argument component as major claim, claim or premise while the argumentative relation
identi   cation model recognizes if two argument components are argumentatively linked
or not. the tree generation model globally optimizes the results of the two base classi   ers

15

computational linguistics

volume ?, number ?

figure 3
architecture of the argumentation structure parser

for    nding a tree (or several ones) in each paragraph. finally, the stance recognition model
differentiates between support and attack relations.

for preprocessing, we use several models from the dkpro framework (eckart de
castilho and gurevych 2014). we identify tokens and sentence boundaries using the
languagetool segmenter4 and identify paragraphs by checking for line breaks. we
lemmatize each token using the mate tools lemmatizer (bohnet et al. 2013) and apply
the stanford part-of-speech (pos) tagger (toutanova et al. 2003), constituent and depen-
dency parsers (klein and manning 2003), and sentiment analyzer (socher et al. 2013).
we use a discourse parser from lin, ng, and kan (2014) for recognizing pdtb-style dis-
course relations. we employ the dkpro tc text classi   cation framework (daxenberger
et al. 2014) for feature extraction and experimentation.

in the following sections, we describe each model in detail. for    nding the best-
performing models, we conduct model selection on our training data using 5-fold cross-
validation. then, we conduct model assessment on our test data. we determine the
evaluation scores of each cross-validation experiment by accumulating the confusion
matrices of each fold into one confusion matrix, which has been shown to be the less
biased method for evaluating cross-validation experiments (forman and scholz 2010).
we employ macro-averaging as described by sokolova and lapalme (2009) and report
macro precision (p), macro recall (r) and macro f1 scores (f1). we use mcnemar test
(mcnemar 1947) with p = .05 for signi   cance testing. compared to other tests, it does
not make as many assumptions about the distribution in the data (japkowicz and shah
2014). furthermore, this test compares the outcomes of two classi   ers to the gold stan-
dard and does not require several trials. thus, it allows for assessing the differences of
the models in both of our evaluation scenarios (model selection and model assessment).
the remainder of this section is structured as follows: in the following section, we
introduce the baselines and the upper bound for each task. in section 5.2, we present the
identi   cation model that detects argument components and their boundaries. in section
5.3, we propose a new joint model for identifying argumentation structures. in section
5.4, we introduce our stance recognition model. in section 5.5, we report the results of
the model assessment on our test data and on the microtext corpus from peldszus and
stede (2015). we present the results of the error analysis in section 5.6. we evaluate the
identi   cation model independently and use the gold standard argument components
for evaluating the remaining models.

4 www.languagetool.org

16

stab and gurevych

parsing argumentation structures

5.1 baselines and upper bound

for evaluating our models, we use two different types of baselines: first, we employ
majority baselines which label each instance with the majority class. table a1 in the
appendix shows the class distribution in our training data and test data for each task.

second, we use heuristic baselines, which are motivated by the common structure of
persuasive essays (whitaker 2009; perutz 2010). the heuristic baseline of the identi   ca-
tion task exploits sentence boundaries. it selects all sentences as argument components
except the    rst two and the last sentence of an essay.5 the heuristic baseline of the
classi   cation task labels the    rst argument component in each body paragraph as
claim and all remaining components in body paragraphs as premise. the last argument
component in the introduction and the    rst argument component in the conclusion are
classi   ed as major claim and all remaining argument components in the introduction
and conclusion are labeled as claim. the heuristic baseline for the relation identi   cation
classi   es an argument component pair as linked if the target is the    rst component of a
body paragraph. we expect that this baseline will yield good results because 62% of all
body paragraphs in our corpus start with a claim. the heuristic baseline of the stance
recognition classi   es each argument component in the second last paragraph as attack.
the motivation for this baseline stems from essay writing guidelines which recommend
including opposing arguments in the second last paragraph.

we determine the human upper bound for each task by averaging the evaluation

scores of all three annotator pairs on our test data.

5.2 identifying argument components

we consider the identi   cation of argument components as a sequence labeling task at
the token level. we encode the argument components using an iob-tagset (ramshaw
and marcus 1995) and consider an entire essay as a single sequence. accordingly, we
label the    rst token of each argument component as    arg-b   , the tokens covered by an
argument component as    arg-i   , and non-argumentative tokens as    o   . as a learner,
we use a crf (lafferty, mccallum, and pereira 2001) with averaged id88 training
method (collins 2002). since a crf considers contextual information, the model is
particularly suited for sequence labeling tasks (goudas et al. 2014, p. 292). for each
token, we extract the following features (table 7):

structural features capture the position of the token. we expect that these features
are effective for    ltering non-argumentative text units since the introductions and con-
clusions of essays include few argumentatively relevant content. the punctuation fea-
tures indicate if the token is a punctuation and if the token is adjacent to a punctuation.
syntactic features consist of the token   s pos as well as features extracted from
the lowest common ancestor (lca) of the current token ti and its adjacent tokens in
where
the constituent parse tree. first, we de   ne lcapreceding(ti) =
|lcap ath(u, v)| is the length of the path from u to the lca of u and v, and depth the depth
|lcap ath(ti,ti+1)|
of the constituent parse tree. second, we de   ne lcaf ollowing(ti) =
,
which considers the current token ti and its following token ti+1.6 additionally, we
add the constituent types of both lowest common ancestors to our feature set.

|lcap ath(ti,ti   1)|

depth

depth

5 full stops at the end of a sentence are all classi   ed as non-argumentative.
6 we set lcapreceding =    1 if ti is the    rst token in its covering sentence and lcaf ollowing =    1 if ti is

the last token in its covering sentence.

17

computational linguistics

volume ?, number ?

table 7
features used for argument component identi   cation (*indicates genre-dependent features)

group

feature

token position

structural

punctuation

position of covering sentence
part-of-speech
lowest
(lca)
lca types

common ancestor

syntactic

lexsyn

lexico-syntactic

prob

id203

description
token present in introduction or conclusion*; token is    rst
or last token in sentence; relative and absolute token posi-
tion in document, paragraph and sentence
token precedes or follows any punctuation, full stop,
comma and semicolon; token is any punctuation or full
stop
absolute and relative position of the token   s covering sen-
tence in the document and paragraph
the token   s part-of-speech
normalized length of the path to the lca with the follow-
ing and preceding token in the parse tree
the two constituent types of the lca of the current token
and its preceding and following token
combination of lexical and syntactic features as described
by soricut and marcu (2003)
id155 of the current token being the be-
ginning of a component given its preceding tokens

lexico-syntactic features have been shown to be effective for segmenting elemen-
tary discourse units (hernault et al. 2010). we adopt the features introduced by soricut
and marcu (2003). we use lexical head projection rules (collins 2003) implemented
in the stanford tool suite to lexicalize the constituent parse tree. for each token t, we
extract its uppermost node n in the parse tree with the lexical head t and de   ne a lexico-
syntactic feature as the combination of t and the constituent type of n. we also consider
the child node of n in the path to t and its right sibling, and combine their lexical heads
and constituent types as described by soricut and marcu (2003).

the id203 feature is the id155 of the current token ti being
the beginning of an argument component (   arg-b   ) given its preceding tokens. we
maximize the id203 for preceding tokens of a length up to n = 3:

p (ti =    arg-b   |ti   n, ..., ti   1)

argmax
n   {1,2,3}

to estimate these probabilities, we divide the number of times the preceding tokens
ti   n, ..., ti   1 with 1     n     3 precede a token ti labeled as    arg-b    by the total number of
occurrences of the preceding tokens in our training data.

5.2.1 results of argument component identi   cation. the results of model selection
show that using all features performs best. table b1 in the appendix shows the detailed
results of the feature analysis. table 8 shows the results of the model assessment on the
test data. the heuristic baseline achieves a macro f1 score of .642 and outperforms the
majority baseline by .383. it achieves an f1 score of .677 for non-argumentative tokens
(   o   ) and .867 for argumentative tokens (   arg-i   ). thus, the heuristic baseline effec-
tively separates argumentative from non-argumentative text units. however, it achieves
a low f1 score of .364 for identifying the beginning of argument components (   arg-
b   ). since it does not split sentences, it recognizes 145 fewer argument components
compared to the number of gold standard components in the test data.

the crf model with all features signi   cantly outperforms the heuristic baseline
(table 8). it achieves a macro f1 score of .867. compared to the heuristic baseline, it

18

stab and gurevych

parsing argumentation structures

table 8
model assessment of argument component identi   cation (    = signi   cant improvement over
baseline heuristic)

human upper bound
baseline majority
baseline heuristic
crf all features    

f1
.886
.259
.642
.867

p
.887
.212
.664
.873

r
.885
.333
.621
.861

f1 arg-b

.821

0

.364
.809

f1 arg-i

.941
.778
.867
.934

f1 o
.892

0

.677
.857

performs considerably better in identifying the beginning of argument components. it
also performs better for separating argumentative from non-argumentative text units. in
addition, the number of identi   ed argument components differs only slightly from the
number of gold standard components in our test data. it identi   es 1,272 argument com-
ponents, whereas the number of gold standard components in our test data amounts to
1,266. the human upper bound yields a macro f1 score of .886 for identifying argument
components. the macro f1 score of our model is only .019 less. therefore, our model
achieves 97.9% of human performance.

5.2.2 error analysis. for identifying the most frequent errors of our model, we manually
investigated the predicted argument components. the most frequent errors are false
positives of    arg-i   . the model classi   es 1,548 out of 9,403 non-argumentative tokens
(   o   ) as argumentative (   arg-i   ). the reason for these errors is threefold: first, the
model frequently labels non-argumentative sentences in the conclusion of an essay as
argumentative. these sentences are, for instance, non-argumentative recommendations
for future actions or summarizations of the essay topic. second, the model does not cor-
rectly recognize non-argumentative sentences in body paragraphs. it wrongly identi   es
argument components in 13 out of the 15 non-argumentative body paragraph sentences
in our test data. the reason for these errors may be attributed to the high class imbalance
in our training data. third, the model tends to annotate lengthy non-argumentative
preceding tokens as argumentative. for instance, it labels subordinate clauses preceding
the actual argument component as argumentative in sentences similar to    in addition
to the reasons mentioned above, [actual    arg-b   ] ...    (underlined text units represent the
annotations of our model).

the second most frequent cause of errors are misclassi   ed beginnings of argument
components. the model classi   es 137 of the 1,266 beginning tokens as    arg-i   . the
model, for instance, fails to identify the correct beginning in sentences like    hence,
from this case we are capable of stating that [actual    arg-b   ] ...     or    apart from the reason
i mentioned above, another equally important aspect is that [actual    arg-b   ] ...   . these exam-
ples also explain the false negatives of non-argumentative tokens which are wrongly
classi   ed as    arg-b   .

5.3 recognizing argumentation structures

the identi   cation of argumentation structures involves the classi   cation of argument
component types and the identi   cation of argumentative relations. both argumentative
types and argumentative relations share mutual information (stab and gurevych 2014b,
p. 54). for instance, if an argument component is classi   ed as claim, it is less likely to
exhibit outgoing relations and more likely to have incoming relations. on the other

19

computational linguistics

volume ?, number ?

hand, an argument component with an outgoing relation and few incoming relations is
more likely to be a premise. therefore, we propose a joint model which combines both
types of information for    nding the optimal structure. we train two local base classi   ers.
one classi   er recognizes the type of argument components, and another identi   es
argumentative relations between argument components. for both models, we use an
id166 (cortes and vapnik 1995) with a polynomial kernel implemented in the weka
machine learning framework (hall et al. 2009). the motivation for selecting this learner
stems from the results of our previous work, in which we found that id166s outperform
several other learners in both tasks (stab and gurevych 2014b, p. 51). we globally
optimize the outcomes of both classi   ers in order to    nd the optimal argumentation
structure using integer id135.

5.3.1 classifying argument components. we consider the classi   cation of argument
component types as multiclass classi   cation and label each argument component as
   major claim   ,    claim    or    premise   . we experiment with the following feature groups:
lexical features consist of binary lemmatized unigrams and the 2k most frequent
dependency word pairs. we extract the unigrams from the component and its preceding
tokens to ensure that discourse markers are included in the features.

structural features capture the position of the component in the document and
token statistics (table 9). since major claims occur frequently in introductions or conclu-
sions, we expect that these features are valuable for differentiating component types.

indicator features are based on four categories of lexical indicators that we manu-
ally extracted from 30 additional essays. forward indicators such as    therefore   ,    thus   ,
or    consequently    signal that the component following the indicator is a result of
preceding argument components. backward indicators indicate that the component fol-
lowing the indicator supports a preceding component. examples of this category are
   in addition   ,    because   , or    additionally   . thesis indicators such as    in my opinion   
or    i believe that    indicate major claims. rebuttal indicators signal attacking premises
or contra arguments. examples are    although   ,    admittedly   , or    but   . the complete
lists of all four categories are provided in table c1 in the appendix. we de   ne for each
category a binary feature that indicates if an indicator of a category is present in the
component or its preceding tokens. an additional binary feature indicates if    rst-person
indicators are present in the argument component or its preceding tokens (table 9). we
assume that    rst-person indicators are informative for identifying major claims.

contextual features capture the context of an argument component. we de   ne
eight binary features set to true if a forward, backward, rebuttal or thesis indicator
precedes or follows the current component in its covering paragraph. additionally,
we count the number of noun and verb phrases of the argument component that are
also present in the introduction or conclusion of the essay. these features are motivated
by the observation that claims frequently restate entities or phrases of the essay topic.
furthermore, we add four binary features indicating if the current component shares a
noun or verb phrase with the introduction or conclusion.

syntactic features consist of the pos distribution of the argument component, the
number of subclauses in the covering sentence, the depth of the constituent parse tree of
the covering sentence, the tense of the main verb of the component, and a binary feature
that indicates whether a modal verb is present in the component.
the id203 features are the conditional probabilities of the current component
being assigned the type t     {m ajorclaim, claim, p remise} given the sequence of
tokens p directly preceding the component. to estimate p (t|p), we divide the number of

20

stab and gurevych

parsing argumentation structures

times the preceding tokens p appear before a component tagged as t by the total number
of occurrences of p in our training data.

discourse features are based on the output of the pdtb-style discourse parser
from lin, ng, and kan (2014). each binary feature is a triple combining the follow-
ing information: (1) the type of the relation that overlaps with the current argument
component, (2) whether the current argument component overlaps with the    rst or
second elementary discourse unit of a relation, and (3) if the discourse relation is implicit
or explicit. for instance, the feature    contrast_imp_arg1    indicates that the current
component overlaps with the    rst discourse unit of an implicit contrast relation. the
use of these features is motivated by the    ndings of cabrio, tonelli, and villata (2013).
by analyzing several example arguments, they hypothesized that general discourse
relations could be informative for identifying argument components.

table 9
features of the argument component classi   cation model (*indicates genre-dependent features)

group

lexical

structural

indicators

contextual

syntactic

id203

feature
unigrams
dependency tuples

token statistics

component position

type indicators

first-person indicators

type indicators in context

shared phrases*
subclauses
depth of parse tree
tense of main verb
modal verbs
pos distribution
type id203

discourse

discourse triples

embedding combined id27s

description
binary and lemmatized unigrams of the component and its
preceding tokens
lemmatized dependency tuples (2k most frequent)
number of tokens of component, covering paragraph and
covering sentence; number of tokens preceding and follow-
ing the component in its sentence; ratio of component and
sentence tokens
component is    rst or last in paragraph; component present
in introduction or conclusion*; relative position in para-
graph; number of preceding and following components in
paragraph
forward, backward, thesis or rebuttal indicators present in
the component or its preceding tokens
   i   ,    me   ,    my   ,    mine   , or    myself    present in compo-
nent or its preceding tokens
forward, backward, thesis or rebuttal indicators preceding
or following the component in its paragraph
shared noun phrases or verb phrases with the introduction
or conclusion (number and binary)
number of subclauses in the covering sentence
depth of the parse tree of the covering sentence
tense of the main verb of the component
modal verbs present in the component
pos distribution of the component
id155 of the component being a major
claim, claim or premise given its preceding tokens
pdtb-discourse relations overlapping with the current
component
sum of the word vectors of each word of the component
and its preceding tokens

embedding features are based on id27s trained on a part of the google
news data set (mikolov et al. 2013). we sum the vectors of each word of an argument
component and its preceding tokens and add it to our feature set. in contrast to common
bag-of-words representations, embedding features have a continuous feature space that
helped to achieve better results in several nlp tasks (socher et al. 2013).

by experimenting with individual features and several feature combinations, we
found that a combination of all features yields the best results. the results of the model
selection can be found in table b2 in the appendix.

21

computational linguistics

volume ?, number ?

5.3.2 identifying argumentative relations. the relation identi   cation model classi   es
ordered pairs of argument components as    linked    or    not-linked   . in this analysis
step, we consider both argumentative support and attack relations as    linked   . for each
paragraph with argument components c1, ..., cn, we consider p = (ci, cj) with i (cid:54)= j and
1     i, j     n as an argument component pair. an argument component pair is    linked   
if our corpus contains an argumentative relation with ci as source component and cj as
target component. the class distribution is skewed towards    not-linked    pairs (table
a1). we experiment with the following features:

lexical features are binary lemmatized unigrams of the source and target compo-
nent and their preceding tokens. we limit the number of unigrams for both source and
target component to the 500 most frequent words in our training data.

syntactic features include binary pos features of the source and target component
and the 500 most frequent production rules extracted from the parse tree of the source
and target component as described in our previous work (stab and gurevych 2014b).

structural features consist of the number of tokens in the source and target com-
ponent, statistics on the components of the covering paragraph of the current pair, and
position features (table 10).

indicator features are based on the forward, backward, thesis and rebuttal indica-
tors introduced in section 5.3.1. we extract binary features from the source and target
component and the context of the current pair (table 10). we assume that these features
are helpful for modeling the direction of argumentative relations and the context of the
current component pair.

discourse features are extracted from the source and target component of each
component pair as described in section 5.3.1. although pdtb-style discourse relations
are limited to adjacent relations, we expect that the types of general discourse relations
can be helpful for identifying argumentative relations. we also experimented with
features capturing pdtb relations between the target and source component. however,
those were not effective for capturing argumentative relations.

pmi features are based on the assumption that particular words indicate incoming
or outgoing relations. for instance, tokens like    therefore   ,    thus   , or    hence    can
signal incoming relations, whereas tokens such as    because   ,    since   , or    furthermore   
may indicate outgoing relations. to capture this information, we use pointwise mutual
information (pmi) which has been successfully used for measuring word associations
(turney 2002; church and hanks 1990). however, instead of determining the pmi of two
words, we estimate the pmi between a lemmatized token t and the direction of a relation
d = {incoming, outgoing} as p m i(t, d) = log p(t,d)
p(t) p(d). here, p(t, d) is the id203 that
token t occurs in an argument component with either incoming or outgoing relations.
the ratio between p(t, d) and p(t) p(d) indicates the dependence between a token and
the direction of a relation. we estimate p m i(t, d) for each token in our training data.
we extract the ratio of tokens positively and negatively associated with incoming or
outgoing relations for both source and target component. additionally, we extract four
binary features which indicate if any token of the components has a positive or negative
association with either incoming or outgoing relations.

shared noun features (shno) indicate if the source and target component share a
noun. we also add the number of shared nouns to our feature set. these features are
motivated by the fact that premises and claims in classical syllogisms share the same
subjects (govier 2010, p. 199).

for selecting the best performing model, we conducted feature ablation tests and
experimented with individual features. the results show that none of the feature groups

22

stab and gurevych

parsing argumentation structures

table 10
features used for argumentative relation identi   cation (*indicates genre-dependent features)

group

lexical

feature

unigrams

syntactic

structural

indicator

discourse

part-of-speech
production rules
token statistics
component statistics

position features

indicator source/target
indicators between
indicators context
discourse triples

pmi

pointwise mutual information

shno

shared nouns

description
binary lemmatized unigrams of the source and target
components including preceding tokens (500 most fre-
quent)
binary pos features of source and target components
production rules extracted from the constituent parse tree
(500 most frequent)
number of tokens of source and target
number of components between source and target; num-
ber of components in covering paragraph
source and target present in same sentence; target present
before source; source and target are    rst or last component
in paragraph; pair present in introduction or conclusion*
indicator type present in source or target
indicator type present between source or target
indicator type follows or precedes source or target in the
covering paragraph of the pair
binary discourse triples of source and target
ratio of tokens positively or negatively associated with
incoming or outgoing relations; presence of words nega-
tively or positively associated with incoming or outgoing
relations
shared nouns between source and target components
(number and binary)

is informative when used individually. we achieved the best performance by removing
lexical features from our feature set (detailed results of the model selection can be found
in table b3 in the appendix).

5.3.3 jointly modeling argumentative relations and argument component types.
both base classi   ers identify argument component types and argumentative relations
locally. consequently, the results may not be globally consistent. for instance, the
relation identi   cation model does not link 37.1% of all premises in our model selection
experiments. therefore, we propose a joint model that globally optimizes the outcomes
of the two base classi   ers. we formalize this task as an integer id135
(ilp) problem. given a paragraph including n argument components7, we de   ne the
following objective function

n(cid:88)

n(cid:88)

i=1

j=1

argmax

x

wijxij

(1)

with variables xij     {0, 1} indicating an argumentative relation from argument compo-
nent i to argument component j.8 each coef   cient wij     r is a weight of a relation. it is
determined by incorporating the outcomes of the two base classi   ers. for ensuring that

7 we consider only claims and premises in our joint model since argumentative relations between claims

and major claims are modeled with a level approach (cf. section 3.2).

8 we use the lpsolve framework (http://lpsolve.sourceforge.net) and set each variable in the objective

function to    binary mode    for ensuring the upper bound of 1.

23

computational linguistics

volume ?, number ?

the resulting structure is a tree, we de   ne the following constraints:

n(cid:88)
n(cid:88)

j=1

   i :

n(cid:88)

xij     1

xij     n     1

i=1

j=1

   i : xii = 0

(2)

(3)

(4)

equation ?? prevents an argument component i from having more than one outgoing
relation. equation ?? ensures that a paragraph includes at least one root node, i.e. a node
without outgoing relation. equation ?? prevents an argumentative relation from having
the same source and target component.
for preventing cycles, we adopt the approach described by k  bler et al. (2008, p.
92). we add the auxiliary variables bij     {0, 1} to our objective function (??) where bij =
1 if there is a directed path from argument component i to argument component j. the
following constraints tie the auxiliary variables bij to the variables xij:

   i   j : xij     bij     1

   i   j   k : bik     bij     bjk        1

   i : bii = 0

(5)

(6)

(7)

the    rst constraint ensures that there is a path from i to j represented in variable bij
if there is a direct relation between the argument components i and j. the second
constraint covers all paths of length greater than 1 in a transitive way. it states that
if there is a path from argument component i to argument component j (bij = 1) and
another path from argument component j to argument component k (bjk = 1) then
there is also a path from argument component i to argument component k. thus, it
iteratively covers paths of length l + 1 by having covered paths of length l. the third
constraint prevents cycles by preventing all directed paths starting and ending with the
same argument component.
having de   ned the ilp model, we consolidate the results of the two base classi   ers.
we consider this task by determining the weight matrix w     rn  n that includes the
coef   cients wij     w of our objective function. the weight matrix w can be considered
an adjacency matrix. the greater a weight of a particular relation is, the higher the
likelihood that the relation appears in the optimal structure found by the ilp-solver.
first, we incorporate the results of the relation identi   cation model. its result can be
considered as an adjacency matrix r     {0, 1}n  n. for each pair of argument components
(i, j) with 1     i, j     n, each rij     r is 1 if the relation identi   cation model predicts an
argumentative relation from argument component i (source) to argument component j
(target), or 0 if the model does not predict an argumentative relation.

second, we derive a claim score (cs) for each argument component i from the pre-

dicted relations in r:

csi =

relini     relouti + n     1

rel + n     1

(8)

24

stab and gurevych

parsing argumentation structures

k=1

here, relini =(cid:80)n
ment component i, relouti =(cid:80)n
tions of argument component i and rel =(cid:80)n

k=1 rki[i (cid:54)= k] is the number of predicted incoming relations of argu-
(cid:80)n
l=1 ril[i (cid:54)= l] is the number of predicted outgoing rela-
l=1 rkl[k (cid:54)= l] is the total number of
relations predicted in the current paragraph. the claim score csi is greater for argument
components with many incoming relations and few outgoing relations. it becomes
smaller for argument components with fewer incoming relations and more outgoing
relations. by normalizing the score with the total number of predicted relations and
argument components, it also accounts for contextual information in the current para-
graph and prevents overly optimistic scores. for example, if all predicted relations point
to argument component i which has no outgoing relations, csi is exactly 1. on the other
hand, if there is an argument component j with no incoming and one outgoing relation
in a paragraph with 4 argument components and 3 predicted relations in r, csj is 1
3.
since it is more likely that a relation links an argument component which has a lower
claim score to an argument component with a higher claim score, we determine the
weight for each argumentative relation as:

crij = csj     csi

(9)

by adding the claim score csj of the target component j, we assign a higher weight to
relations pointing to argument components which are likely to be a claim. by subtract-
ing the claim score csi of the source component i, we assign smaller weights to relations
outgoing argument components with larger claim score.

third, we incorporate the argument component types predicted by the classi   cation
model. we assign a higher score to the weight wij if the target component j is predicted
as claim since it is more likely that argumentative relations point to claims. accordingly,
we set cij = 1 if argument component j is labeled as claim and cij = 0 if argument
component j is labeled as premise.

finally, we combine all three scores to estimate the weights of the objective function:

wij =   rrij +   crcrij +   ccij

(10)

each    represents a hyperparameter of the ilp model. in our model selection exper-
iments, we found that   r = 1
4 yields the best performance. more
detailed results of the model selection are provided in table b4 in the appendix.

2 and   cr =   c = 1

after applying the ilp model, we adapt the argumentative relations and argument
types according to the results of the ilp-solver. we revise each relation according to
the determined xij scores, set the type of all components without outgoing relation to
   claim   , and set the type of all remaining components to    premise   .

5.4 classifying support and attack relations

the stance recognition model differentiates between argumentative support and attack
relations. we model this task as binary classi   cation and classify each claim and premise
as    support    or    attack   . the stance of each premise is encoded in the type of its
outgoing relation, whereas the stance of each claim is encoded in its stance attribute.
we use an id166 and the following features (table 11)9:

9 for    nding the best learner, we compared na  ve bayes (john and langley 1995), id79s

(breiman 2001), multinomial id28 (le cessie and van houwelingen 1992), c4.5 decision

25

computational linguistics

volume ?, number ?

lexical features are binary lemmatized unigram features of the argument compo-

nent and its preceding tokens.

sentiment features are based on the subjectivity lexicon from wilson, wiebe, and
hoffmann (2005) and the    ve sentiment scores produced by the stanford sentiment
analyzer (socher et al. 2013).

syntactic features consist of the pos distribution of the component and production

rules (stab and gurevych 2014b).

token statistics (table 11).

structural features capture the position of the component in the paragraph and

discourse features are discourse triples as described in section 5.3.1. we expect
that these features will be helpful for identifying attacking components since the pdtb
includes contrast and concession relations.

embedding features are the embedding features described in section 5.3.1.

table 11
features used for stance recognition

group
lexical

feature
unigrams

sentiment

syntactic

structural

discourse

subjectivity clues

sentiment scores
pos distribution
production rules

token statistics

component statistics
component position
discourse triples

embedding combined id27s

5.5 evaluation

description
binary and lemmatized unigrams of the component and its
preceding token
presence of negative words; number of negative, positive,
and neutral words; number of positive words subtracted
by the number of negative words
five sentiment scores of covering sentence (stanford senti-
ment analyzer)
pos distribution of the component
production rules extracted from the constituent parse tree
number of tokens of covering sentence; number of pre-
ceding and following tokens in covering sentence; ratio of
component and sentence tokens
number of components in paragraph; number of preceding
and following components in paragraph
relative position of the argument component in paragraph
pdtb discourse relations overlapping with the current
component
sum of the word vectors of each word of the component
and its preceding tokens

the upper part of table 12 shows the f1 scores of the classi   cation, relation identi   ca-
tion, and stance recognition tasks using our test data. the heuristic baselines outperform
the majority baselines in all three tasks by a considerable margin. they achieve an
average macro f1 score of .674, which con   rms our assumption that argumentation
structures in persuasive essays can be identi   ed with simple heuristic rules (section
5.1).

our base classi   ers for component classi   cation and relation identi   cation both
improve the macro f1 scores of the heuristic baselines. the component classi   cation
model achieves a macro f1 score of .794. compared to the heuristic baseline, the model
yields slightly worse results for claims and premises but improves the identi   cation

trees (quinlan 1993) and id166 (cortes and vapnik 1995) and found that an id166 considerably
outperforms all other classi   ers.

26

stab and gurevych

parsing argumentation structures

of major claims by .132. however, the difference between the component classi   cation
model and the heuristic baseline is not statistically signi   cant. on the other hand, the
relation identi   cation model signi   cantly improves the result of the heuristic baseline,
achieving a macro f1 score of .717. additionally, the stance recognition model signi   -
cantly outperforms the heuristic baseline by .118 macro f1 score. it yields an f1 score of
.947 for supporting components and .413 for attacking component.

table 12
f1 scores of model assessment. the upper part shows the results on the test data of the
persuasive essay corpus, while the lower part shows the results on the microtext corpus from
peldszus and stede (2015) (    = signi   cant improvement over baseline heuristic;     = signi   cant
improvement over base classi   er).

human upper bound
baseline majority
baseline heuristic
base classi   er
ilp joint model

      

simple
best eg
mp+p
base classi   er
ilp joint model

f1

.868
.260
.759
.794
.826

.817
.869
.831
.830
.857

components
f1 mc f1 cl f1 pr

relations
f1 noli f1 li

f1

stance recognition
f1

f1 sup f1 att avg f1

model assessment on persuasive essays
.754

.924
.780
.899
.879
.903

.854
.455
.700
.717
.751

   
   

.954
.910
.901
.917
.918

0

.620
.611
.682

model assessment on microtexts

-
-
-

-
-
-

.712
.770

.937
.943

.663
.693
.720
.650
.683

-
-
-

.841
.881

.755

0

.499
.508
.585

.478
.502
.546
.446
.486

.926

0

.759
.891
.891

-
-
-
-
-

   
   

.844
.478
.562
.680
.680

.671
.710
.514
.745
.745

.975
.957
.776
.947
.947

-
-
-

.703

0

.201
.413
.413

-
-
-

.855
.855

.628
.628

.855
.398
.674
.730
.752

.717
.757
.688
.742
.762

the ilp joint model signi   cantly outperforms the heuristic baselines for component
classi   cation and relation identi   cation. additionally, it signi   cantly outperforms the
base classi   er for component classi   cation. however, it does not yield a signi   cant
improvement over the base classi   er for relation identi   cation despite that the ilp joint
model improves the base classi   er for relation identi   cation by .034 macro f1 score. the
results show that the identi   cation of claims and linked component pairs bene   t most
from the joint model. compared to the base classi   ers, the ilp joint model improves the
f1 score of claims by .071 and the f1 score of linked component pairs by .077.

the human upper bound yields macro f1 scores of .868 for component classi   ca-
tion, .854 for relation identi   cation, and .844 for stance recognition. the ilp joint model
achieves almost human performance for classifying argument components. its f1 score
is only .042 lower compared to human upper bound. regarding relation identi   cation
and stance recognition, the f1 scores of our model are .103 and .164 less than human
performance. thus, our model achieves 95.2% human performance for component
identi   cation, 87.9% for relation identi   cation, and 80.5% for stance recognition.

in order to verify the effectiveness of our approach, we also evaluated the ilp
joint model on the english microtext corpus (cf. setion 2.4). for ensuring the compa-
rability to previous results, we used the same data splitting and the repeated cross-
validation setup described by peldszus and stede (2015). since the microtext corpus
does not include major claims, we removed the major claim label from our component
classi   cation model for this evaluation task. furthermore, it was necessary to adapt
several features of the base classi   ers since the microtext corpus does not include non-
argumentative text units. therefore, we did not consider preceding tokens for lexical,
indicator and embedding features and removed the id203 feature of the compo-

27

computational linguistics

volume ?, number ?

nent classi   cation model. additionally, we removed all genre-dependent features of
both base classi   ers.

the    rst three rows of the lower part in table 12 show the results reported by
peldszus and stede (2015) on the english microtext corpus. the simple model indicates
their local base classi   ers, best eg is their best model for component classi   cation, and
mp+p is their best model for relation identi   cation. on average our base classi   ers
outperform the base classi   ers from peldszus and stede (2015) by .025. only their rela-
tion identi   cation model yields a better macro f1 score compared to our base classi   er.
their best eg model outperforms our model with respect to component classi   cation
and relation identi   cation but yields a lower score for stance recognition. their mp+p
model outperforms the relation identi   cation of our model, but yields lower results
for component classi   cation and stance recognition compared to our ilp joint model.
this difference can be attributed to the additional information about the function and
role attribute incorporated in their joint models (cf. section 2.3). they showed that both
have a bene   cial effect on the component classi   cation and relation identi   cation in
their corpus (peldszus and stede 2015, figure 3). however, the role attribute is a unique
feature of their corpus and the arguments in their corpus exhibit an unusually high
proportion of attack relations (cf. section 2.4). in particular, 86.6% of their arguments
include attack relations, whereas the proportion of arguments with attack relations
in our corpus amounts to only 12.4%. this proportion may even be lower in other
text genres because essay writing guidelines encourage students to include opposing
arguments in their writing. therefore, we assume that incorporating function and role
attributes will not be bene   cial using our corpus.

the evaluation results show that our ilp joint model simultaneously improves the

performance of component classi   cation and relation identi   cation on both corpora.

5.6 error analysis

in order to analyze frequent errors of the ilp joint model, we investigated the predicted
argumentation structures in our test data. the confusion matrix of the component
classi   cation task (table 13) shows that the highest confusion is between claims and
premises. the model classi   es 74 actual premises as claims and 82 claims as premises.
by manually investigating these errors, we found that the model tends to label in-
ner premises in serial structures as claims and wrongly identi   es claims in sentences
containing two premises. regarding the relation identi   cation, we observed that the

table 13
confusion matrix of the ilp joint model of component classi   cation on our test data

l majorclaim

a
u
t
c
a

claim
premise

majorclaim

139
20
0

predictions

claim

12
202
74

premise

2
82
735

model tends to identify argumentation structures which are more shallow than the
structures in our gold standard. the model correctly identi   es only 34.7% of the 98
serial arguments in our test data. this can be attributed to the    claim-centered    weight
calculation in our objective function. in particular, the predicted relations in matrix r
are the only information about serial arguments, whereas the other two scores (c and cr)
assign higher weights to relations pointing to claims.

28

stab and gurevych

parsing argumentation structures

in order to determine if the ilp joint model correctly models the relationship be-
tween component types and argumentative relations, we arti   cially improved the pre-
dictions of both base classi   ers as suggested by peldszus and stede (2015). the dashed
lines in figure 4 show the performance of the arti   cially improved base classi   ers.
continuous lines show the resulting performance of the ilp joint model. figures 4a+b

(a) improve types

(b) improve relations

(c) improve both

figure 4
in   uence of improving the base classi   ers (x-axis shows the proportion of improved predictions
and y-axis the macro f1 score).

show the effect of improving the component classi   cation and relation identi   cation. it
shows that correct predictions of one base classi   er are not maintained after applying
the ilp model if the other base classi   er exhibits less accurate predictions. in particular,
less accurate argumentative relations have a more detrimental effect on the component
types (figure 4a) than less accurate component types do on the outcomes of the relation
identi   cation (figure 4b). thus, it is more reasonable to focus on improving relation
identi   cation than component classi   cation in future work.

figure 4c depicts the effect of improving both base classi   ers, which illustrates that
the ilp joint model improves the component types more effectively than argumentative
relations. figure 4c also shows that the ilp joint model improves both tasks if the base
classi   ers are improved. therefore, we conclude that the ilp joint model successfully
captures the natural relationship between argument component types and argumenta-
tive relations.

6. discussion

our argumentation structure parser includes several consecutive steps. consequently,
potential errors of the upstream models can negatively in   uence the results of the
downstream models. for example, errors of the identi   cation model can result in    awed
argumentation structures if argumentatively relevant text units are not recognized or
non-argumentative text units are identi   ed as relevant. however, our identi   cation
model yields good accuracy and an   u of .958 for identifying argument components.
therefore, it is unlikely that identi   cation errors will signi   cantly in   uence the outcome
of the upstream models when applied to persuasive essays. however, as demonstrated
by levy et al. (2014) and goudas et al. (2014), the identi   cation of argument components
is more complex in other text genres than it is in persuasive essays. another potential
issue of the pipeline architecture is that wrongly classi   ed major claims will decrease the
accuracy of the model due to the fact that those are not integrated in the joint modeling

29

010203040506070bothmerged	
   types	
   macro	
   f10.7730.7960.8180.840.8630.8850.9090.932ilp	
   relations	
   macro	
   f10.7520.7810.8080.8380.8660.8910.9140.94ilp	
   types	
   macro	
   f10.8230.8430.8630.8840.9060.9220.940.955merged	
   relations	
   macro	
   f10.7360.7640.7920.820.8510.8720.8980.926relationsilp	
   relations	
   macro	
   f10.7520.7730.7950.8170.8410.8650.890.914ilp	
   types	
   macro	
   f10.8230.8310.8390.8480.8570.8670.8790.887merged	
   relations	
   macro	
   f10.7360.7650.7930.820.8470.8730.8990.924typesmerged	
   types	
   macro	
   f10.7730.7970.820.840.8640.8880.9090.931ilp	
   relations	
   macro	
   f10.7520.7590.7660.7720.7810.7880.7930.8ilp	
   types	
   macro	
   f10.8230.8350.8490.860.8730.8860.8970.9080.7	
   0.75	
   0.8	
   0.85	
   0.9	
   0.95	
   1	
   0	
   10	
   20	
   30	
   40	
   50	
   60	
   70	
   80	
   90	
   100	
   improved	
   comp.	
   types	
   component	
   types	
   argumentative	
   relations	
   improved	
   arg.	
   relations	
   0102030bothmerged	
   types	
   macro	
   f10.7730.7960.8180.84ilp	
   relations	
   macro	
   f10.7520.7810.8080.838ilp	
   types	
   macro	
   f10.8230.8430.8630.884merged	
   relations	
   macro	
   f10.7360.7640.7920.82relationsilp	
   relations	
   macro	
   f10.7520.7730.7950.817ilp	
   types	
   macro	
   f10.8230.8310.8390.848merged	
   relations	
   macro	
   f10.7360.7650.7930.82typesmerged	
   types	
   macro	
   f10.7730.7970.820.84ilp	
   relations	
   macro	
   f10.7520.7590.7660.772ilp	
   types	
   macro	
   f10.8230.8350.8490.860.7	
   0.75	
   0.8	
   0.85	
   0.9	
   0.95	
   1	
   0	
   10	
   20	
   30	
   40	
   50	
   60	
   70	
   80	
   90	
   100	
   imptypes	
   ilptypes	
   ilprelation	
   0102030bothmerged	
   types	
   macro	
   f10.7730.7960.8180.84ilp	
   relations	
   macro	
   f10.7520.7810.8080.838ilp	
   types	
   macro	
   f10.8230.8430.8630.884merged	
   relations	
   macro	
   f10.7360.7640.7920.82relationsilp	
   relations	
   macro	
   f10.7520.7730.7950.817ilp	
   types	
   macro	
   f10.8230.8310.8390.848merged	
   relations	
   macro	
   f10.7360.7650.7930.82typesmerged	
   types	
   macro	
   f10.7730.7970.820.84ilp	
   relations	
   macro	
   f10.7520.7590.7660.772ilp	
   types	
   macro	
   f10.8230.8350.8490.860.7	
   0.75	
   0.8	
   0.85	
   0.9	
   0.95	
   1	
   0	
   10	
   20	
   30	
   40	
   50	
   60	
   70	
   80	
   90	
   100	
   ilptypes	
   ilprelation	
   imprelations	
   0102030bothmerged	
   types	
   macro	
   f10.7730.7960.8180.84ilp	
   relations	
   macro	
   f10.7520.7810.8080.838ilp	
   types	
   macro	
   f10.8230.8430.8630.884merged	
   relations	
   macro	
   f10.7360.7640.7920.82relationsilp	
   relations	
   macro	
   f10.7520.7730.7950.817ilp	
   types	
   macro	
   f10.8230.8310.8390.848merged	
   relations	
   macro	
   f10.7360.7650.7930.82typesmerged	
   types	
   macro	
   f10.7730.7970.820.84ilp	
   relations	
   macro	
   f10.7520.7590.7660.772ilp	
   types	
   macro	
   f10.8230.8350.8490.860.7	
   0.75	
   0.8	
   0.85	
   0.9	
   0.95	
   1	
   0	
   10	
   20	
   30	
   40	
   50	
   60	
   70	
   80	
   90	
   100	
   imptypes	
   ilptypes	
   ilprelation	
   imprelations	
   computational linguistics

volume ?, number ?

approach. for this reason, it is worthwhile to experiment in future work with structured
machine learning methods which incorporate several tasks in a single model (moens
2013).

in this work, we have demonstrated that our annotation scheme can be reliably
applied to persuasive essays. however, persuasive essays exhibit a common structure
and so it may be more challenging to apply the annotation scheme to text genres with
less explicit argumentation structures such as social media data, product reviews or
dialogical debates. nevertheless, we believe that our annotation scheme can be success-
fully applied to other text genres with minor adaptations. although other text genres
may not include major claims, previous work has already demonstrated that claims and
premises can be reliably annotated in legal cases (mochales-palau and moens 2011),
written dialogs (biran and rambow 2011) and even over multiple wikipedia articles
(aharoni et al. 2014). additionally, it is unknown if our tree assumption generalizes to
other text genres. although most previous work considered argumentation structures as
trees, other text genres may include divergent arguments and even cyclic argumentation
structures.

although our approach shows promising results, it is still unknown if the identi   ed
argumentation structures can be used to provide adequate feedback about argumenta-
tion. however, the identi   ed argumentation structures enable various kinds of feedback
about argumentation. for instance, it facilitates the automatic recommendation of more
meaningful and comprehensible argumentation structure. particularly, the extracted
structure can be used to prevent multiple reasoning directions in a single argument (e.g.
both forward and backward reasoning), which may result in a more comprehensible
structure of arguments. it could be also used to highlight unsupported claims and then
prompt the author for reasons supporting or attacking it (e.g. premises related to the
claim). additionally, the identi   ed argumentation structure facilitates the recommen-
dation of additional discourse markers in order to make the arguments more coherent
or can be used to encourage authors to discuss opposing views. finally, the visualization
of the identi   ed argumentation structure could stimulate self re   ection and plausibility
checking. however,    nding adequate feedback types and investigating their effect on
the argumentation skills of students requires the integration of the models in writing
environments and extensive long term user studies in future work.

7. conclusion

in this paper, we presented an end-to-end approach for parsing argumentation struc-
tures in persuasive essays. previous approaches suffer from several limitations: existing
approaches either focus only on particular subtasks of argumentation structure parsing
or rely on manually created rules. consequently, previous approaches are only of lim-
ited use for parsing argumentation structures in real application scenarios. to the best
of our knowledge, the presented work is the    rst approach which covers all required
subtasks for identifying the global argumentation structure of documents. we showed
that jointly modeling argumentation structures simultaneously improves the results
of component classi   cation and relation identi   cation. additionally, we introduced a
novel annotation scheme and a new corpus of persuasive essays annotated with argu-
mentation structures which represents the largest resource of its kind. both the corpus
and the annotation guidelines are freely available in order to ensure reproducibility and
for fostering future research in computational argumentation.

30

stab and gurevych

parsing argumentation structures

appendix a: class distributions

table a1 shows the class distributions of the training and test data of the persuasive
essay corpus for each analysis step.

table a1
class distributions in training data and test data

class

arg-b
arg-i

o

majorclaim

claim
premise

not-linked

linked

support
attack

component classi   cation

training data
identi   cation
4,823 (4.1%)
75,053 (63.6%)
38,071 (32.3%)

598 (12.4%)
1,202 (24.9%)
3,023 (62.7%)

relation identi   cation

14,227 (82.5%)
3,023 (17.5%)

stance recognition

3,820 (90.4%)

405 (9.6%)

test data

1,266 (4.3%)
18,655 (63.6%)
9,403 (32.1%)

153 (12.1%)
304 (24.0%)
809 (63.9%)

4,113 (83.5%)
809 (16.5%)

1,021 (91.7%)

92 (8.3%)

appendix b: detailed results of model selections

the following tables show the model selection results for all    ve tasks using 5-fold cross-
validation on our training data. table b1 shows the results of using individual feature
groups for the argument component identi   cation task. lexico-syntactic features per-
form best for identifying argument components, and they perform particularly well for
recognizing the beginning of argument components (   arg-b   ). the second best features
are structural features. they yield the best f1 score for separating argumentative from
non-argumentative text units (   o   ). syntactic features are useful for identifying the

table b1
argument component identi   cation (    = signi   cant improvement over baseline heuristic)
f1 o

f1 arg-b

f1 arg-i

baseline majority
baseline heuristic
crf only structural    
crf only syntactic    
crf only lexsyn    
crf only id203
crf w/o genre-dependent    
crf all features    

f1
.259
.628
.748
.730
.762
.605
.847
.849

p
.212
.647
.757
.752
.780
.698
.851
.853

r
.333
.610
.740
.710
.744
.534
.844
.846

0

.350
.542
.638
.714
.520
.778
.777

.778
.869
.906
.868
.873
.806
.925
.927

0

.660
.789
.601
.620
.217
.835
.842

beginning of argument components. the id203 feature yields the lowest score.
nevertheless, we observe a signi   cant decrease of .028 f1 score of    arg-b    when eval-
uating the system without the id203 feature. we obtain the best results by using
all features. since persuasive essays exhibit a particular paragraph structure which may
not be present in other text genres (e.g. user-generated web discourse), we also evaluate
the model without genre-dependent features (cf. table 7). this yields a macro f1 score
of .847 which is only .002 less compared to the model with all features.

31

computational linguistics

volume ?, number ?

table b2 shows the model selection results of the classi   cation model. structural
features are the only features which signi   cantly outperform the heuristic baseline
when used individually. they are the most effective features for identifying major
claims. the second-best features for identifying claims are discourse features. with
this knowledge, we can con   rm the assumption that general discourse relations are
useful for component classi   cation (cf. section 5.3.1). however, embedding features do

table b2
argument component classi   cation (    = signi   cant improvement over baseline heuristic)

baseline majority
baseline heuristic
id166 only lexical
id166 only structural    
id166 only contextual
id166 only indicators
id166 only syntactic
id166 only id203
id166 only discourse
id166 only embeddings
id166 all w/o prob & emb    
id166 w/o genre-dependent
id166 all features    

f1
.257
.724
.591
.746
.601
.508
.387
.561
.521
.588
.771
.742
.773

p
.209
.724
.603
.726
.603
.596
.371
.715
.563
.620
.771
.745
.774

r
.333
.723
.580
.767
.600
.443
.405
.462
.484
.560
.772
.739
.771

f1 majorclaim

0

.740
.591
.803
.656
.415
.313
.448
.016
.560
.855
.819
.865

f1 claim

0

.560
.405
.551
.248
.098

0

.002
.538
.355
.596
.560
.592

f1 premise

.771
.870
.772
.870
.836
.799
.783
.792
.786
.815
.863
.847
.861

not perform as well as lexical features. they yield lower f1 scores for major claims
and claims. contextual features are effective for identifying major claims since they
implicitly capture if an argument component is present in the introduction or conclusion
(cf. section 5.3.1). indicator features are most effective for identifying major claims but
contribute only slightly to the identi   cation of claims. syntactic features are predictive
of major claims and premises but are not effective for recognizing claims. the prob-
ability features are not informative for identifying claims, probably because forward
indicators may also signal inner premises in serial structures. omitting id203 and
embedding features yields the best accuracy. however, we select the best performing
system by means of the macro f1 score which is more appropriate for imbalanced data
sets. accordingly, we select the model which uses all features (table b2).

the model selection results for relation identi   cation are shown in table b3. we
report the results of feature ablation tests since none of the feature groups yields remark-
able results when used individually. we also found that removing any of the feature

table b3
argumentative relation identi   cation (    = signi   cant improvement over baseline heuristic;     =
signi   cant difference compared to id166 all features)

baseline majority
baseline heuristic
id166 all w/o lexical    
id166 all w/o syntactic    
id166 all w/o structural    
id166 all w/o indicators    
id166 all w/o discourse    
id166 all w/o pmi    
id166 all w/o shno    
id166 w/o genre-dependent    
id166 all features    

f1
.455
.660
.736
.729
.715
.719
.732
.720
.733
.722
.733

p
.418
.657
.762
.764
.740
.743
.755
.745
.756
.750
.756

r
.500
.664
.711
.697
.692
.697
.709
.697
.712
.700
.711

f1 not-linked

.910
.885
.917
.917
.911
.912
.915
.912
.915
.913
.915

32

f1 linked

0

.436
.547
.526
.511
.520
.540
.521
.545
.520
.544

stab and gurevych

parsing argumentation structures

groups does not yield a signi   cant difference compared to the model with all features.
structural features are the most effective features for identifying relations. the second-
and third-most effective feature groups are indicator and pmi features. both syntactic
and discourse features yield a slight improvement when combining them with other
features. removing the shared noun features does not yield a difference in accuracy or
macro f1 score although we observe a decrease of .002 macro f1 score when removing
them from our best performing model. we achieve the best results by removing lexical
features from the feature set.

table b4 shows the model selection results of the ilp joint model. base+heuristic
shows the result of applying the baseline to all paragraphs in which the base classi   ers
identify neither claims nor argumentative relations. the heuristic baseline is triggered
in 31 paragraphs which results in 3.3% more trees identi   ed compared to the base
classi   ers. however, the difference between base+heuristic and the base classi   ers is
not statistically signi   cant. for this reason, we can attribute any further improvements
to the joint modeling approach. moreover, table b4 shows selected results of the hyper-

table b4
joint modeling approach (    = signi   cant improvement over base heuristic;     = signi   cant
improvement over base classi   er; cl   pr = number of claims converted to premises; pr   cl =
number of premises converted to claims; trees = percentage of correctly identi   ed trees)

parameter
f1
  r   cr   c
.724
-
-
   
.773
-
-
   
.776
-
-
0    
.765
1
0        .809
1
2
1    
.740
0
3        .822
1
3
2        .817
1
4
4        .823
1
2

-
-
-
0
1
2
0
1
3
1
4
1
4

1

1

1

   
   
   

components
f1
f1 mc f1 cl f1 pr
.660
.870
.740
.865
.736
.861
.865
.739
.861
.865
.732
.761
.875        .759
.865
.865
.666
.777
.865
.751
.903
.865
.738
.898
.865
.904
.752

.560
.592
.601
.591
.677
.549
.699
.687
.701

   
   
   

-
-
31

statistics

relations
f1 noli f1 li cl   pr pr   cl trees
100%
20.9%
24.2%
100%
100%
100%
100%
100%
100%

.885
.917
.917
.918
.919
.894
.913
.908
.913

.436
.547
.555
.530
.598
.434
.590
.569
.591

-
-
0
206
299
229
294
264
297

1,144
571
818
280
250
283

base heuristic
base classi   er
base+heuristic
ilp-na  ve
ilp-relation
ilp-claim
ilp-equal
ilp-same
ilp-balanced

parameter tuning of the ilp joint model. using only predicted relations in the ilp-na  ve
model does not yield an improvement over the base classi   ers. ilp-relation uses only
information from the relation identi   cation base classi   er. it signi   cantly outperforms
both base classi   ers but converts a large number of premises to claims. the ilp-claim
model uses only the outcomes of the argument component base classi   er and improves
neither component classi   cation nor relation identi   cation. all three models identify a
relatively high proportion of claims compared to the number of claims in our training
data. the reason for this is that many weights in w are 0. combining the results of
both base classi   ers yields a considerably more balanced proportion of component type
conversions. all three models (ilp-equal, ilp-same, and ilp-balanced) signi   cantly
outperform the base classi   er for component classi   cation. we identify the best per-
forming system by means of the average macro f1 score for both tasks. accordingly, we
select ilp-balanced as our best performing ilp joint model.

table b5 shows the model selection results for the stance recognition model. using
sentiment, structural and embedding features individually does not yield an improve-
ment over the majority baseline. however, lexical, syntactic and discourse features yield
a signi   cant improvement over the heuristic baseline when used individually. although
lexical features perform best individually, there is no signi   cant difference when remov-

33

computational linguistics

volume ?, number ?

ing them from the feature set. since omitting any of the feature groups yields a lower
macro f1 score, we select the model with all features as the best performing model.

table b5
stance recognition (    = signi   cant improvement over baseline heuristic;     = signi   cant difference
compared to id166 all features)

baseline majority
baseline heuristic
id166 only lexical    
id166 only syntactic    
id166 only discourse    
id166 all w/o lexical    
id166 all w/o syntactic       
id166 all w/o sentiment    
id166 all w/o structural    
id166 all w/o discourse       
id166 all w/o embeddings    
id166 all features    

f1
.475
.521
.663
.649
.630
.696
.687
.699
.698
.675
.692
.702

p
.452
.511
.677
.725
.746
.719
.691
.710
.710
.685
.703
.714

r
.500
.530
.650
.587
.546
.657
.684
.688
.686
.666
.682
.690

f1 support

.950
.767
.941
.950
.951
.948
.941
.945
.946
.941
.944
.946

f1 attack

0

.173
.383
.283
.169
.439
.433
.451
.449
.408
.439
.456

appendix c: indicators

table c1 shows all of the lexical indicators we extracted from 30 persuasive essays. the
lists include 22 forward indicators, 33 backward indicators, 48 thesis indicators and 10
rebuttal indicators.

table c1
list of lexical indicators

indicators
   as a result   ,    as the consequence   ,    because   ,    clearly   ,    consequently   ,    consid-
ering this subject   ,    furthermore   ,    hence   ,    leading to the consequence   ,    so   ,    so   ,
   taking account on this fact   ,    that is the reason why   ,    the reason is that   ,    therefore   ,
   therefore   ,    this means that   ,    this shows that   ,    this will result   ,    thus   ,    thus   ,
   thus, it is clearly seen that   ,    thus, it is seen   ,    thus, the example shows   
   additionally   ,    as a matter of fact   ,    because   ,    besides   ,    due to   ,    finally   ,    first
of all   ,    firstly   ,    for example   ,    for example   ,    for instance   ,    for instance   ,    fur-
thermore   ,    has proved it   ,    in addition   ,    in addition to this   ,    in the    rst place   ,    is
due to the fact that   ,    it should also be noted   ,    moreover   ,    on one hand   ,    on the
one hand   ,    on the other hand   ,    one of the main reasons   ,    secondly   ,    similarly   ,
   since   ,    since   ,    so   ,    the reason   ,    to begin with   ,    to offer an instance   ,    what is
more   
   all in all   ,    all things considered   ,    as far as i am concerned   ,    based on some
reasons   ,    by analyzing both the views   ,    considering both the previous fact   ,    finally   ,
   for the reasons mentioned above   ,    from explanation above   ,    from this point of
view   ,    i agree that   ,    i agree with   ,    i agree with the statement that   ,    i believe   ,    i
believe that   ,    i do not agree with this statement   ,    i    rmly believe that   ,    i highly
advocate that   ,    i highly recommend   ,    i strongly believe that   ,    i think that   ,    i think
the view is   ,    i totally agree   ,    i totally agree to this opinion   ,    i would have to argue
that   ,    i would reaf   rm my position that   ,    in conclusion   ,    in conclusion   ,    in my
opinion   ,    in my opinion   ,    in my personal point of view   ,    in my point of view   ,
   in my point of view   ,    in summary   ,    in the light of the facts outlined above   ,    it
can be said that   ,    it is clear that   ,    it seems to me that   ,    my deep conviction   ,    my
sentiments   ,    overall   ,    personally   ,    the above explanations and example shows that   ,
   this, however   ,    to conclude   ,    to my way of thinking   ,    to sum up   ,    ultimately   
   admittedly   ,    although   ,    although   ,    besides these advantages   ,    but   ,    but   ,    even
though   ,    even though   ,    however   ,    otherwise   

category
forward (24)

backward (33)

thesis (48)

rebuttal (10)

34

stab and gurevych

parsing argumentation structures

acknowledgments
this work has been supported by the
volkswagen foundation as part of the
lichtenberg-professorship program under
grant no. i/82806 and by the german
federal ministry of education and research
(bmbf) as a part of the software campus
project aws under grant no. 01|s12054. we
would like to thank the anonymous
reviewers for their valuable feedback, can
diehl, ilya kuznetsov, todd shore and
anshul tak for their valuable contributions,
and andreas peldszus for providing details
about his corpus.

references
[afantenos and asher2014]afantenos,

stergos and nicholas asher. 2014.
counter-argumentation and discourse: a
case study. in proceedings of the workshop on
frontiers and connections between
argumentation theory and natural language
processing, pages 11   16, bertinoro, italy.
[afantenos et al.2015]afantenos, stergos,
eric kow, nicholas asher, and j  r  my
perret. 2015. discourse parsing for
multi-party chat dialogues. in proceedings
of the 2015 conference on empirical methods
in natural language processing, pages
928   937, lisbon, portugal.

[aharoni et al.2014]aharoni, ehud, anatoly

polnarov, tamar lavee, daniel
hershcovich, ran levy, ruty rinott, dan
gutfreund, and noam slonim. 2014. a
benchmark dataset for automatic detection
of claims and evidence in the context of
controversial topics. in proceedings of the
first workshop on argumentation mining,
pages 64   68, baltimore, md, usa.

[artstein and poesio2008]artstein, ron and

massimo poesio. 2008. inter-coder
agreement for computational linguistics.
computational linguistics, 34(4):555   596.

[asher and lascarides2003]asher, nicholas

and alex lascarides. 2003. logics of
conversation. cambridge university press,
cambridge.

[beardsley1950]beardsley, monroe c. 1950.

practical logic. prentice-hall.

[beigman klebanov and higgins2012]

beigman klebanov, beata and derrick
higgins. 2012. measuring the use of
factual information in test-taker essays. in
proceedings of the seventh workshop on
building educational applications using
nlp, pages 63   72, montreal, quebec,
canada.

[bentahar, moulin, and b  langer2010]

bentahar, jamal, bernard moulin, and
micheline b  langer. 2010. a taxonomy of
argumentation models used for
id99. arti   cial
intelligence review, 33(3):211   259.

[biran and rambow2011]biran, or and

owen rambow. 2011. identifying
justi   cations in written dialogs by
classifying text as argumentative.
international journal of semantic computing,
05(04):363   381.

[bohnet et al.2013]bohnet, bernd, joakim

nivre, igor boguslavsky, rich  rd farkas,
filip ginter, and jan haji  c. 2013. joint
morphological and syntactic analysis for
richly in   ected languages. transactions of
the association for computational linguistics,
1:415   428.

[boltu  i  c and   najder2014]boltu  i  c, filip and

jan   najder. 2014. back up your stance:
recognizing arguments in online
discussions. in proceedings of the first
workshop on argumentation mining, pages
49   58, baltimore, ma, usa.

[botley2014]botley, simon philip. 2014.

argument structure in learner writing: a
corpus-based analysis using argument
mapping. kajian malaysia, 32(1):45   77.
[braud and denis2014]braud, chlo   and

pascal denis. 2014. combining natural and
arti   cial examples to improve implicit
discourse relation identi   cation. in
proceedings of coling 2014, the 25th
international conference on computational
linguistics: technical papers, pages
1694   1705, dublin, ireland.

[breiman2001]breiman, leo. 2001. random

forests. machine learning, 45(1):5   32.

[cabrio, tonelli, and villata2013]cabrio,
elena, sara tonelli, and serena villata.
2013. from discourse analysis to
argumentation schemes and back:
relations and differences. in computational
logic in multi-agent systems, volume 8143
of lecture notes in computer science.
springer berlin heidelberg, pages 1   17.
[cabrio and villata2012]cabrio, elena and

serena villata. 2012. natural language
arguments: a combined approach. in
proceedings of the 20th european conference
on arti   cial intelligence, ecai    12, pages
205   210, montpellier, france.

[cabrio and villata2014]cabrio, elena and

serena villata. 2014. node: a benchmark
of natural language arguments. in
proceedings of comma, pages 449   450.

35

computational linguistics

volume ?, number ?

[carlson, marcu, and okurowski2001]

carlson, lynn, daniel marcu, and
mary ellen okurowski. 2001. building a
discourse-tagged corpus in the framework
of rhetorical structure theory. in proceedings
of the second sigdial workshop on discourse
and dialogue - volume 16, sigdial    01,
pages 1   10, aalborg, denmark.

[carstens and toni2015]carstens, lucas and

francesca toni. 2015. towards relation
based argumentation mining. in
proceedings of the 2nd workshop on
argumentation mining, pages 29   34,
denver, co, usa.

[church and hanks1990]church,

kenneth ward and patrick hanks. 1990.
word association norms, mutual
information, and id69.
computational linguistics, 16(1):22   29.
[cinkov  , holub, and kr    2012]cinkov  ,
silvie, martin holub, and vincent kr    .
2012. managing uncertainty in semantic
tagging. in proceedings of the 13th
conference of the european chapter of the
association for computational linguistics,
eacl    12, pages 840   850, avignon, france.

[cohen1987]cohen, robin. 1987. analyzing
the structure of argumentative discourse.
computational linguistics, 13(1-2):11   24.

[collins2002]collins, michael. 2002.

discriminative training methods for
id48: theory and
experiments with id88 algorithms.
in proceedings of the acl-02 conference on
empirical methods in natural language
processing - volume 10, emnlp    02, pages
1   8, pennsylvania, pa, usa.

[collins2003]collins, michael. 2003.

head-driven statistical models for natural
language parsing. computational
linguistics, 29(4):589   637.

[conway1991]conway, david a. 1991. on
the distinction between convergent and
linked arguments. informal logic,
13:145   158.

[copi and cohen1990]copi, irving m. and
carl cohen. 1990. introduction to logic.
macmillan publishing company, 8th
edition.

[cortes and vapnik1995]cortes, corinna and

vladimir vapnik. 1995. support-vector
networks. machine learning, 20(3):273   297.

[damer2009]damer, t. edward. 2009.

attacking faulty reasoning: a practical
guide to fallacy-free reasoning. wadsworth
cengage learning, 6th edition.

[daxenberger et al.2014]daxenberger,

johannes, oliver ferschke, iryna
gurevych, and torsten zesch. 2014. dkpro

36

tc: a java-based framework for
supervised learning experiments on
textual data. in proceedings of the 52nd
annual meeting of the association for
computational linguistics. system
demonstrations, pages 61   66, baltimore,
md, usa.

[eckart de castilho and gurevych2014]
eckart de castilho, richard and iryna
gurevych. 2014. a broad-coverage
collection of portable nlp components for
building shareable analysis pipelines. in
nancy ide and jens grivolla, editors,
proceedings of the workshop on open
infrastructures and analysis frameworks for
hlt (oiaf4hlt) at coling 2014, pages
1   11, dublin, ireland.

[feng and hirst2011]feng, vanessa wei and
graeme hirst. 2011. classifying arguments
by scheme. in proceedings of the 49th annual
meeting of the association for computational
linguistics: human language technologies -
volume 1, hlt    11, pages 987   996,
portland, or, usa.

[feng and hirst2014]feng, vanessa wei and

graeme hirst. 2014. a linear-time
bottom-up discourse parser with
constraints and post-editing. in proceedings
of the 52nd annual meeting of the association
for computational linguistics (volume 1:
long papers), pages 511   521, baltimore,
ma, usa.

[fleiss1971]fleiss, joseph l. 1971. measuring

nominal scale agreement among many
raters. psychological bulletin, 76(5):378   382.

[florou et al.2013]florou, eirini, stasinos

konstantopoulos, antonis koukourikos,
and pythagoras karampiperis. 2013.
argument extraction for supporting public
policy formulation. in proceedings of the 7th
workshop on language technology for
cultural heritage, social sciences, and
humanities, pages 49   54, so   a, bulgaria.
[forman and scholz2010]forman, george

and martin scholz. 2010. apples-to-apples
in cross-validation studies: pitfalls in
classi   er performance measurement.
sigkdd explor. newsl., 12(1):49   57.
[freeman2011]freeman, james b. 2011.
argument structure: representation and
theory, volume 18 of argumentation
library. springer.

[ghosh et al.2014]ghosh, debanjan,

smaranda muresan, nina wacholder,
mark aakhus, and matthew mitsui. 2014.
analyzing argumentative discourse units
in online interactions. in proceedings of the
first workshop on argumentation mining,
pages 39   48, baltimore, ma, usa.

stab and gurevych

parsing argumentation structures

[goudas et al.2014]goudas, theodosis,

christos louizos, georgios petasis, and
vangelis karkaletsis. 2014. argument
extraction from news, blogs, and social
media. in arti   cial intelligence: methods and
applications, volume 8445 of lecture notes
in computer science. springer international
publishing, pages 287   299.

[govier2010]govier, trudy. 2010. a practical
study of argument. wadsworth, cengage
learning, 7th edition.

[habernal and gurevych2016]habernal, ivan
and iryna gurevych. 2016. argumentation
mining in user-generated web discourse.
computational linguistics, in press.

[hall et al.2009]hall, mark, eibe frank,

geoffrey holmes, bernhard pfahringer,
peter reutemann, and ian h. witten. 2009.
the weka data mining software: an
update. sigkdd explor. newsl.,
11(1):10   18.

[hasan and ng2014]hasan, kazi saidul and
vincent ng. 2014. why are you taking this
stance? identifying and classifying reasons
in ideological debates. in proceedings of the
2014 conference on empirical methods in
natural language processing (emnlp),
pages 751   762, doha, qatar.

[henkemans2000]henkemans, a.

francisca snoeck. 2000. state-of-the-art:
the structure of argumentation.
argumentation, 14(4):447   473.

[hernault et al.2010]hernault, hugo, helmut

prendinger, david a. duverle, and
mitsuru ishizuka. 2010. hilda: a discourse
parser using support vector machine
classi   cation. dialogue and discourse,
1(3):1   33.

[japkowicz and shah2014]japkowicz,

nathalie and mohak shah. 2014. evaluating
learning algorithms: a classi   cation
perspective. cambridge university press.

[john and langley1995]john, george h. and
pat langley. 1995. estimating continuous
distributions in bayesian classi   ers. in
eleventh conference on uncertainty in
arti   cial intelligence, pages 338   345,
montreal, quebec, canada.

[johnson2000]johnson, ralph h. 2000.

manifest rationality. lawrence erlbaum.
[kemper and sebranek2004]kemper, dave

and pat sebranek. 2004. inside writing:
persuasive essays. great source education
group.

[kirschner, eckle-kohler, and gurevych2015]

kirschner, christian, judith eckle-kohler,
and iryna gurevych. 2015. linking the
thoughts: analysis of argumentation
structures in scienti   c publications. in

proceedings of the 2nd workshop on
argumentation mining, pages 1   11, denver,
co, usa.

[klein and manning2003]klein, dan and

christopher d. manning. 2003. accurate
unlexicalized parsing. in proceedings of the
41st annual meeting on association for
computational linguistics - volume 1, acl
   03, pages 423   430, sapporo, japan.

[krippendorff2004]krippendorff, klaus.

2004. measuring the reliability of
qualitative text analysis data. quality &
quantity, 38(6):787   800.

[k  bler et al.2008]k  bler, sandra, ryan

mcdonald, joakim nivre, and graeme
hirst. 2008. id33. morgan
and claypool publishers.

[kwon et al.2007]kwon, namhee, liang

zhou, eduard hovy, and stuart w.
shulman. 2007. identifying and classifying
subjective claims. in proceedings of the 8th
annual international conference on digital
government research: bridging disciplines &
domains, pages 76   81, philadelphia, pa,
usa.

[lafferty, mccallum, and pereira2001]

lafferty, john d., andrew mccallum, and
fernando c. n. pereira. 2001. conditional
random    elds: probabilistic models for
segmenting and labeling sequence data. in
proceedings of the eighteenth international
conference on machine learning, icml    01,
pages 282   289, san francisco, ca, usa.

[le cessie and van houwelingen1992]

le cessie, s. and j.c. van houwelingen.
1992. ridge estimators in logistic
regression. applied statistics, 41(1):191   201.

[levy et al.2014]levy, ran, yonatan bilu,

daniel hershcovich, ehud aharoni, and
noam slonim. 2014. context dependent
claim detection. in proceedings of the 25th
international conference on computational
linguistics (coling 2014), pages
1489   1500, dublin, ireland.

[lin, kan, and ng2009]lin, ziheng, min-yen
kan, and hwee tou ng. 2009. recognizing
implicit discourse relations in the penn
discourse treebank. in proceedings of the
2009 conference on empirical methods in
natural language processing: volume 1,
emnlp    09, pages 343   351, suntec,
singapore.

[lin, ng, and kan2014]lin, ziheng,

hwee tou ng, and min-yen kan. 2014. a
pdtb-styled end-to-end discourse parser.
natural language engineering,
20(2):151   184.

[lippi and torroni2015]lippi, marco and

paolo torroni. 2015. context-independent

37

computational linguistics

volume ?, number ?

claim detection for argument mining. in
proceedings of the twenty-fourth
international joint conference on arti   cial
intelligence (ijcai 2015), pages 185   191,
buenos aires, argentina.

[lippi and torroni2016]lippi, marco and

paolo torroni. 2016. argumentation
mining: state of the art and emerging
trends. acm transactions on internet
technology, 16(2):10:1   10:25.

[louis et al.2010]louis, annie, aravind

joshi, rashmi prasad, and ani nenkova.
2010. using entity features to classify
implicit discourse relations. in proceedings
of the 11th annual meeting of the special
interest group on discourse and dialogue,
sigdial    10, pages 59   62, stroudsburg,
pa, usa.

[mann and thompson1987]mann,

william c. and sandra a. thompson.
1987. rhetorical structure theory: a theory
of text organization. technical report
isi/rs-87-190, information sciences
institute.

[marcu and echihabi2002]marcu, daniel and

abdessamad echihabi. 2002. an
unsupervised approach to recognizing
discourse relations. in proceedings of the
40th annual meeting on association for
computational linguistics, acl    02, pages
368   375.

[mcnemar1947]mcnemar, quinn. 1947.

note on the sampling error of the
difference between correlated proportions
or percentages. psychometrika,
12(2):153   157.

[meyer et al.2014]meyer, christian m.,

margot mieskes, christian stab, and iryna
gurevych. 2014. dkpro agreement: an
open-source java library for measuring
inter-rater agreement. in proceedings of the
25th international conference on
computational linguistics: system
demonstrations (coling), pages 105   109,
dublin, ireland.

[mikolov et al.2013]mikolov, tomas, ilya

sutskever, kai chen, greg s corrado, and
jeff dean. 2013. distributed
representations of words and phrases and
their compositionality. in advances in
neural information processing systems 26.
curran associates, inc., pages 3111   3119.

[mochales-palau and ieven2009]

mochales-palau, raquel and aagje ieven.
2009. creating an argumentation corpus:
do theories apply to real arguments?: a
case study on the legal argumentation of
the echr. in proceedings of the 12th
international conference on arti   cial

38

intelligence and law (icail    09), pages
21   30, barcelona, spain.

[mochales-palau and moens2009]

mochales-palau, raquel and
marie-francine moens. 2009.
argumentation mining: the detection,
classi   cation and structure of arguments in
text. in proceedings of the 12th international
conference on arti   cial intelligence and law,
icail    09, pages 98   107, barcelona, spain.

[mochales-palau and moens2011]

mochales-palau, raquel and
marie-francine moens. 2011.
argumentation mining. arti   cial
intelligence and law, 19(1):1   22.

[moens2013]moens, marie-francine. 2013.

argumentation mining: where are we
now, where do we want to be and how do
we get there? in post-proceedings of the
forum for information retrieval evaluation
(fire 2013), pages 4   6, new delhi, india.

[moens et al.2007]moens, marie-francine,
erik boiy, raquel mochales palau, and
chris reed. 2007. automatic detection of
arguments in legal texts. in proceedings of
the 11th international conference on arti   cial
intelligence and law, icail    07, pages
225   230, stanford, ca, usa.

[nguyen and litman2015]nguyen, huy and
diane litman. 2015. extracting argument
and domain words for identifying
argument components in texts. in
proceedings of the 2nd workshop on
argumentation mining, pages 22   28,
denver, co, usa.

[o   keefe1977]o   keefe, daniel j. 1977. two

concepts of argument. journal of the
american forensic assiciation, 13(3):121   128.
[oraby et al.2015]oraby, shereen, lena reed,

ryan compton, ellen riloff, marilyn
walker, and steve whittaker. 2015. and
that   s a fact: distinguishing factual and
emotional argumentation in online
dialogue. in proceedings of the 2nd workshop
on argumentation mining, pages 116   126,
denver, co, usa.

[park and cardie2014]park, joonsuk and

claire cardie. 2014. identifying
appropriate support for propositions in
online user comments. in proceedings of the
first workshop on argumentation mining,
pages 29   38, baltimore, ma, usa.

[peldszus2014]peldszus, andreas. 2014.
towards segment-based recognition of
argumentation structure in short texts. in
proceedings of the first workshop on
argumentation mining, pages 88   97,
baltimore, ma, usa.

stab and gurevych

parsing argumentation structures

[peldszus and stede2013]peldszus, andreas
and manfred stede. 2013. from argument
diagrams to argumentation mining in
texts: a survey. international journal of
cognitive informatics and natural intelligence
(ijcini), 7(1):1   31.

[peldszus and stede2015]peldszus, andreas
and manfred stede. 2015. joint prediction
in mst-style discourse parsing for
argumentation mining. in conference on
empirical methods in natural language
processing (emnlp 2015), page (to appear),
lisbon, portugal.

[persing and ng2015]persing, isaac and
vincent ng. 2015. modeling argument
strength in student essays. in proceedings of
the 53rd annual meeting of the association
for computational linguistics and the 7th
international joint conference on natural
language processing (volume 1: long
papers), pages 543   552, beijing, china.

[perutz2010]perutz, vivien. 2010. a helpful
guide to essay writing! student services,
anglia ruskin university.

[pitler, louis, and nenkova2009]pitler,

emily, annie louis, and ani nenkova.
2009. automatic sense prediction for
implicit discourse relations in text. in
proceedings of the joint conference of the 47th
annual meeting of the acl and the 4th
international joint conference on natural
language processing of the afnlp, pages
683   691, suntec, singapore.

[prasad et al.2008]prasad, rashmi, nikhil

dinesh, alan lee, eleni miltsakaki, livio
robaldo, aravind joshi, and bonnie
webber. 2008. the penn discourse
treebank 2.0. in proceedings of the sixth
international conference on language
resources and evaluation (lrec   08),
marrakech, morocco.

[quinlan1993]quinlan, ross. 1993. c4.5:
programs for machine learning. morgan
kaufmann publishers.

[ramshaw and marcus1995]ramshaw,

lance a. and mitchell p. marcus. 1995.
text chunking using transformation-based
learning. in proceedings of the 3rd acl
workshop on very large corpora, pages
82   94, cambridge, ma, usa.

[reed et al.2008]reed, chris, raquel
mochales-palau, glenn rowe, and
marie-francine moens. 2008. language
resources for studying argument. in
proceedings of the sixth international
conference on language resources and
evaluation, lrec    08, pages 2613   2618,
marrakech, morocco.

[reed and rowe2004]reed, chris and glenn

rowe. 2004. araucaria: software for
argument analysis, diagramming and
representation. international journal on
arti   cial intelligence tools, 14(4):961   980.

[rinott et al.2015]rinott, ruty, lena dankin,

carlos alzate perez, mitesh m. khapra,
ehud aharoni, and noam slonim. 2015.
show me your evidence - an automatic
method for context dependent evidence
detection. in proceedings of the 2015
conference on empirical methods in natural
language processing, emnlp    15, pages
440   450, lisbon, portugal.

[rooney, wang, and browne2012]rooney,

niall, hui wang, and fiona browne. 2012.
applying kernel methods to
argumentation mining. in proceedings of the
twenty-fifth international florida arti   cial
intelligence research society conference,
flairs    12, pages 272   275, marco island,
fl, usa.

[sardianos et al.2015]sardianos, christos,

ioannis manousos katakis, georgios
petasis, and vangelis karkaletsis. 2015.
argument extraction from news. in
proceedings of the 2nd workshop on
argumentation mining, pages 56   66,
denver, co, usa.

[shiach2009]shiach, don. 2009. how to write

essays. how to books ltd, 2nd edition.

[socher et al.2013]socher, richard, alex

perelygin, jean wu, jason chuang,
christopher d. manning, andrew y. ng,
and christopher potts. 2013. recursive
deep models for semantic compositionality
over a sentiment treebank. in proceedings of
the 2013 conference on empirical methods in
natural language processing, pages
1631   1642, seattle, wa, usa.

[sokolova and lapalme2009]sokolova,

marina and guy lapalme. 2009. a
systematic analysis of performance
measures for classi   cation tasks.
information processing & management,
45(4):427   437.

[somasundaran and wiebe2009]

somasundaran, swapna and janyce wiebe.
2009. recognizing stances in online
debates. in proceedings of the 47th annual
meeting of the acl and the 4th ijcnlp of the
afnlp, acl    09, pages 226   234, suntec,
singapore.

[song et al.2014]song, yi, michael heilman,
beata beigman klebanov, and paul deane.
2014. applying argumentation schemes
for essay scoring. in proceedings of the first
workshop on argumentation mining, pages
69   78, baltimore, ma, usa.

39

computational linguistics

volume ?, number ?

[soricut and marcu2003]soricut, radu and

[walker et al.2012]walker, marilyn, jean fox

tree, pranav anand, rob abbott, and
joseph king. 2012. a corpus for research
on deliberation and debate. in proceedings
of the eight international conference on
language resources and evaluation
(lrec   12), istanbul, turkey.

[whitaker2009]whitaker, anne. 2009.

academic writing guide 2010: a step-by-step
guide to writing academic papers. city
university of seattle.

[wilson, wiebe, and hoffmann2005]wilson,

theresa, janyce wiebe, and paul
hoffmann. 2005. recognizing contextual
polarity in phrase-level id31.
in proceedings of the conference on human
language technology and empirical methods
in natural language processing, hlt    05,
pages 347   354, vancouver, british
columbia, canada.

[yanal1991]yanal, robert j. 1991. dependent

and independent reasons. informal logic,
13(3):137   144.

daniel marcu. 2003. sentence level
discourse parsing using syntactic and
lexical information. in proceedings of the
2003 conference of the north american
chapter of the association for computational
linguistics on human language technology -
volume 1, naacl    03, pages 149   156,
edmonton, canada.

[stab and gurevych2014a]stab, christian
and iryna gurevych. 2014a. annotating
argument components and relations in
persuasive essays. in proceedings of the 25th
international conference on computational
linguistics (coling 2014), pages
1501   1510, dublin, ireland, august.

[stab and gurevych2014b]stab, christian
and iryna gurevych. 2014b. identifying
argumentative discourse structures in
persuasive essays. in conference on
empirical methods in natural language
processing (emnlp 2014), pages 46   56,
doha, qatar.

[stenetorp et al.2012]stenetorp, pontus,
sampo pyysalo, goran topi  c, tomoko
ohta, sophia ananiadou, and jun   ichi
tsujii. 2012. brat: a web-based tool for
nlp-assisted text annotation. in proceedings
of the demonstrations at the 13th conference
of the european chapter of the association for
computational linguistics, eacl    12, pages
102   107, avignon, france.

[thomas1973]thomas, stephen n. 1973.
practical reasoning in natural language.
prentice-hall.

[toutanova et al.2003]toutanova, kristina,
dan klein, christopher d. manning, and
yoram singer. 2003. feature-rich
part-of-speech tagging with a cyclic
dependency network. in proceedings of the
2003 conference of the north american
chapter of the association for computational
linguistics on human language technology,
naacl    03, pages 173   180, edmonton,
canada.

[turney2002]turney, peter d. 2002. thumbs

up or thumbs down?: semantic orientation
applied to unsupervised classi   cation of
reviews. in proceedings of the 40th annual
meeting on association for computational
linguistics, acl    02, pages 417   424,
philadelphia, pennsylvania.

van eemeren, frans h., rob grootendorst,
and francisca snoeck henkemans. 1996.
fundamentals of argumentation theory: a
handbook of historical backgrounds and
contemporary developments. routledge,
taylor & francis group.

40

[van eemeren, grootendorst, and snoeck henkemans1996]

