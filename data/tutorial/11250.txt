learning global features for coreference resolution

sam wiseman and alexander m. rush and stuart m. shieber

school of engineering and applied sciences

harvard university

cambridge, ma, usa

{swiseman,srush,shieber}@seas.harvard.edu

6
1
0
2

 
r
p
a
1
1

 

 
 
]
l
c
.
s
c
[
 
 

1
v
5
3
0
3
0

.

4
0
6
1
:
v
i
x
r
a

abstract

there is compelling evidence that corefer-
ence prediction would bene   t from modeling
global information about entity-clusters. yet,
state-of-the-art performance can be achieved
with systems treating each mention prediction
independently, which we attribute to the inher-
ent dif   culty of crafting informative cluster-
level features. we instead propose to use re-
current neural networks (id56s) to learn la-
tent, global representations of entity clusters
directly from their mentions. we show that
such representations are especially useful for
the prediction of pronominal mentions, and
can be incorporated into an end-to-end coref-
erence system that outperforms the state of the
art without requiring any additional search.

introduction

1
while structured, non-local coreference models
would seem to hold promise for avoiding many com-
mon coreference errors (as discussed further in sec-
tion 3), the results of employing such models in
practice are decidedly mixed, and state-of-the-art
results can be obtained using a completely local,
mention-ranking system.

in this work, we posit that global context is indeed
necessary for further improvements in coreference
resolution, but argue that informative cluster, rather
than mention, level features are very dif   cult to de-
vise, limiting their effectiveness. accordingly, we
instead propose to learn representations of mention
clusters by embedding them sequentially using a re-
current neural network (shown in section 4). our
model has no manually de   ned cluster features, but

instead learns a global representation from the indi-
vidual mentions present in each cluster. we incor-
porate these representations into a mention-ranking
style coreference system.

the entire model, including the recurrent neu-
ral network and the mention-ranking sub-system, is
trained end-to-end on the coreference task. we train
the model as a local classi   er with    xed context (that
is, as a history-based model). as such, unlike several
recent approaches, which may require complicated
id136 during training, we are able to train our
model in much the same way as a vanilla mention-
ranking model.

experiments compare the use of learned global
features to several strong baseline systems for coref-
erence resolution. we demonstrate that the learned
global representations capture important underlying
information that can help resolve dif   cult pronom-
inal mentions, which remain a persistent source of
errors for modern coreference systems (durrett and
klein, 2013; kummerfeld and klein, 2013; wise-
man et al., 2015; martschat and strube, 2015). our
   nal system improves over 0.8 points in conll
score over the current state of the art, and the im-
provement is statistically signi   cant on all three
conll metrics.

2 background and notation

coreference resolution is fundamentally a id91
task. given a sequence (xn)n
n=1 of (intra-document)
mentions     that is, syntactic units that can refer or be
referred to     coreference resolution involves parti-
tioning (xn) into a sequence of clusters (x (m))m
m=1
such that all the mentions in any particular cluster

x (m) refer to the same underlying entity. since the
mentions within a particular cluster may be ordered
linearly by their appearance in the document,1 we
will use the notation x (m)
to refer to the j   th men-
j
tion in the m   th cluster.

one strategy to avoid the computational

a valid id91 places each mention in exactly
one cluster, and so we may represent a id91
with a vector z    {1, . . . , m}n , where zn = m iff
xn is a member of x (m). coreference systems at-
tempt to    nd the best id91 z        z under some
scoring function, with z the set of valid id91s.
in-
tractability associated with predicting an entire clus-
tering z is to instead predict a single antecedent for
each mention xn; because xn may not be anaphoric
(and therefore have no antecedents), a    dummy    an-
tecedent   may also be predicted. the aforemen-
tioned strategy is adopted by    mention-ranking    sys-
tems (denis and baldridge, 2008; rahman and ng,
2009; durrett and klein, 2013), which, formally,
predict an antecedent   y    y(xn) for each mention
xn, where y(xn) ={1, . . . , n    1,  }. through tran-
sitivity, these decisions induce a id91 over the
document.

mention-ranking systems make their antecedent
predictions with a local scoring function f (xn, y)
de   ned for any mention xn and any antecedent
y    y(xn). while such a scoring function clearly
ignores much structural information, the mention-
ranking approach has been attractive for at least two
reasons. first, id136 is relatively simple and ef-
   cient, requiring only a left-to-right pass through a
document   s mentions during which a mention   s an-
tecedents (as well as  ) are scored and the highest
scoring antecedent is predicted. second, from a lin-
guistic modeling perspective, mention-ranking mod-
els learn a scoring function that requires a mention
xn to be compatible with only one of its coreferent
antecedents. this contrasts with mention-pair mod-
els (e.g., bengtson and roth (2008)), which score
all pairs of mentions in a cluster, as well as with cer-
tain cluster-based models (see discussion in culotta
et al. (2007)). modeling each mention as having
a single antecedent is particularly advantageous for
pronominal mentions, which we might like to model

1we assume nested mentions are ordered by their syntactic

heads.

as linking to a single nominal or proper antecedent,
for example, but not necessarily to all other corefer-
ent mentions.

accordingly, in this paper we attempt to maintain
the inferential simplicity and modeling bene   ts of
mention ranking, while allowing the model to utilize
global, structural information relating to z in mak-
ing its predictions. we therefore investigate objec-
tive functions of the form

f (xn, yn) + g(xn, yn, z1:n   1)

,

n(cid:88)

n=1

arg max
y1,...,yn

where g is a global function that, in making pre-
dictions for xn, may examine (features of) the clus-
tering z1:n   1 induced by the antecedent predictions
made through yn   1.
3 the role of global features
here we motivate the use of global features for
coreference resolution by focusing on the issues that
may arise when resolving pronominal mentions in
a purely local way. see clark and manning (2015)
and stoyanov and eisner (2012) for more general
motivation for using global models.

3.1 pronoun problems
recent empirical work has shown that the resolu-
tion of pronominal mentions accounts for a substan-
tial percentage of the total errors made by modern
mention-ranking systems. wiseman et al. (2015)
show that on the conll 2012 english development
set, almost 59% of mention-ranking precision errors
and almost 24% of recall errors involve pronominal
mentions. martschat and strube (2015) found a sim-
ilar pattern in their comparison of mention-ranking,
mention-pair, and latent-tree models.

to see why pronouns can be so problematic, con-
sider the following passage from the    broadcast
conversation    portion of the conll development
set (bc/msnbc/0000/018); below, we enclose men-
tions in brackets and give the same subscript to co-
clustered mentions. (this example is also shown in
figure 2.)

da: um and [i]1 think that is what   s - go
ahead [linda]2.
lw: well and uh thanks goes to [you]1 and to
[the media]3 to help [us]4...so [our]4 hat is off
to all of [you]5 as well.

this example is typical of broadcast conversation,
and it is dif   cult because local systems learn to my-
opically link pronouns such as [you]5 to other in-
stances of the same pronoun that are close by, such
as [you]1. while this is often a reasonable strategy,
in this case predicting [you]1 to be an antecedent of
[you]5 would result in the prediction of an incoher-
ent cluster, since [you]1 is coreferent with the singu-
lar [i]1, and [you]5, as part of the phrase    all of you,   
is evidently plural. thus, while there is enough in-
formation in the text to correctly predict [you]5, do-
ing so crucially depends on having access to the his-
tory of predictions made so far, and it is precisely
this access to history that local models lack.

more empirically, there are non-local statistical
regularities involving pronouns we might hope mod-
els could exploit. for instance, in the conll train-
ing data over 70% of pleonastic    it    instances and
over 74% of pleonastic    you    instances follow (re-
spectively) previous pleonastic    it    and    you    in-
stances. similarly, over 78% of referential    i    in-
stances and over 68% of referential    he    instances
corefer with previous    i    and    he    instances, respec-
tively.

accordingly, we might expect non-local models
with access to global features to perform signi   -
cantly better. however, models incorporating non-
local features have a rather mixed track record. for
instance, bj  orkelund and kuhn (2014) found that
cluster-level features improved their results, whereas
martschat and strube (2015) found that they did not.
clark and manning (2015) found that incorporating
cluster-level features beyond those involving the pre-
computed mention-pair and mention-ranking prob-
abilities that form the basis of their agglomerative
id91 coreference system did not improve per-
formance. furthermore, among recent, state-of-the-
art systems, mention-ranking systems (which are
completely local) perform at least as well as their
more structured counterparts (durrett and klein,
2014; clark and manning, 2015; wiseman et al.,
2015; peng et al., 2015).

issues with global features

3.2
we believe a major reason for the relative inef-
fectiveness of global features in coreference prob-
lems is that, as noted by clark and manning (2015),
cluster-level features can be hard to de   ne. specif-

ically, it is dif   cult to de   ne discrete,    xed-length
features on clusters, which can be of variable size
(or shape). as a result, global coreference features
tend to be either too coarse or too sparse. thus, early
attempts at de   ning cluster-level features simply ap-
plied the coarse quanti   er predicates all, none, most
to the mention-level features de   ned on the men-
tions (or pairs of mentions) in a cluster (culotta et
al., 2007; rahman and ng, 2011). for example, a
cluster would have the feature    most-female=true    if
more than half the mentions (or pairs of mentions)
in the cluster have a    female=true    feature.

on the other extreme, bj  orkelund and kuhn
(2014) de   ne certain cluster-level features by con-
catenating the mention-level features of a cluster   s
constituent mentions in order of the mentions    ap-
pearance in the document. for example, if a clus-
ter consists, in order, of the mentions (the president,
he, he), they would de   ne a cluster-level    type    fea-
ture    c-p-p=true   , which indicates that the cluster is
composed, in order, of a common noun, a pronoun,
and a pronoun. while very expressive, these con-
catenated features are often quite sparse, since clus-
ters encountered during training can be of any size.

4 learning global features

to circumvent the aforementioned issues with de   n-
ing global features, we propose to learn cluster-level
feature representations implicitly, by identifying the
state of a (partial) cluster with the hidden state of
an id56 that has consumed the sequence of men-
tions composing the (partial) cluster. before pro-
viding technical details, we provide some prelimi-
nary evidence that such learned representations cap-
ture important contextual information by display-
ing in figure 1 the learned    nal states of all clus-
ters in the conll development set, projected using
id167 (van der maaten and hinton, 2012). each
point in the visualization represents the learned fea-
tures for an entity cluster and the head words of
mentions are shown for representative points. note
that the model learns to roughly separate clusters by
simple distinctions such as predominant type (nom-
inal, proper, pronominal) and number (it, they, etc),
but also captures more subtle relationships such as
grouping geographic terms and long strings of pro-
nouns.

der). we therefore propose to embed the state(s) of
x (m) by running an id56 over the cluster in order.
in order to run an id56 over the mentions we need
an embedding function hc to map a mention to a real
vector. first, following wiseman et al. (2015) de   ne
  a(xn) : x     {0, 1}f as a standard set of local in-
dicator features on a mention, such as its head word,
its gender, and so on. (we elaborate on features be-
low.) we then use a non-linear feature embedding
hc to map a mention xn to a vector-space represen-
tation. in particular, we de   ne

hc(xn) (cid:44) tanh(w c   a(xn) + bc)

,

where w c and bc are parameters of the embedding.
we will refer to the j   th hidden state of the id56
, and we obtain it ac-

corresponding to x (m) as h(m)
cording to the following formula
j     id56(hc(x (m)
h(m)

j

j

), h(m)

j   1;   )

,

again assuming that h(m)
0 = 0. thus, we will ef-
fectively run an id56 over each (sequence of men-
tions corresponding to a) cluster x (m) in the docu-
ment, and thereby generate a hidden state h(m)
cor-
responding to each step of each cluster in the docu-
ment. concretely, this can be implemented by main-
taining m id56s     one for each cluster     that all
share the parameters   . the process is illustrated in
the top portion of figure 2.

j

5 coreference with global features
we now describe how the id56 de   ned above is
used within an end-to-end coreference system.

5.1 full model and training
recall that our id136 objective is to maximize
the score of both a local mention ranking term as
well as a global term based on the current clusters:

arg max
y1,...,yn

f (xn, yn) + g(xn, yn, z1:n   1)

we begin by de   ning the local model f (xn, y)
with the two layer neural network of wiseman et
al. (2015), which has a specialization for the non-
anaphoric case, as follows:

(cid:40)

ut(cid:104) ha(xn)

hp(xn,y)

(cid:105)

vtha(xn) + v0

f (xn, y) (cid:44)

+ u0

if y (cid:54)=  
if y =  

.

n(cid:88)

n=1

figure 1: id167 visualization of learned entity repre-
sentations on the conll development set. each point
shows a gold cluster of size > 1. yellow, red, and pur-
ple points represent predominantly common noun, proper
noun, and pronoun clusters, respectively. captions show
head words of representative clusters    mentions.

4.1 recurrent neural networks
a recurrent neural network is a parameterized non-
linear function id56 that recursively maps an in-
put sequence of vectors to a sequence of hidden
states. let (mj)j
j=1 be a sequence of j input vec-
tors mj     rd, and let h0 = 0. applying an id56 to
any such sequence yields

hj     id56(mj, hj   1;   )

,

where    is the set of parameters for the model, which
are shared over time.

there are several varieties of id56, but by far
the most commonly used in natural-language pro-
cessing is the long short-term memory network
(lstm) (hochreiter and schmidhuber, 1997), par-
ticularly for id38 (e.g., zaremba et al.
(2014)) and machine translation (e.g., sutskever et
al. (2014)), and we use lstms in all experiments.

4.2 id56s for cluster features
our main contribution will be to utilize id56s to
produce feature representations of entity clusters
which will provide the basis of the global term g.
recall that we view a cluster x (m) as a sequence of
mentions (x (m)
j=1 (ordered in linear document or-
)j

j

da: um and [i]1 think that is what   s - go ahead [linda]2.
lw: well and thanks goes to [you]1 and to [the media]3 to help [us]4...so [our]4 hat is off to all of [you]5...

x (1)

h(1)
1

[i]

h(1)
2

[you]

x (2)
h(2)
1

[linda]

x (3)
h(3)
1

[the media]

x (4)

h(4)
1

[us]

h(4)
2

[our]

[i], h(1)
2

[linda], h(2)
1

[you], h(1)
2

[the media], h(3)
1

[us], h(4)
2

[our], h(4)
2

xn = [you]  , na(xn)

figure 2: full id56 example for handling the mention xn = [you]. there are currently four entity clusters in scope
x (1), x (2), x (3), x (4) based on unseen previous decisions (y). each cluster has a corresponding id56 state, two
of which (h(1) and h(4)) have processed multiple mentions (with x (1) notably including a singular mention [i]). at
the bottom, we show the complete mention-ranking process. each previous mention is considered as an antecedent,
and the global term considers the antecedent clusters    current hidden state. selecting   is treated with a special case
na(xn).

above, u and v are the parameters of the model,
and ha and hp are learned feature embeddings of
the local mention context and the pairwise af   nity
between a mention and an antecedent, respectively.
these feature embeddings are de   ned similarly to
hc, as

ha(xn) (cid:44) tanh(w a   a(xn) + ba)

hp(xn, y) (cid:44) tanh(w p   p(xn, y) + bp)

,

where   a (mentioned above) and   p are    raw    (that
is, unconjoined) features on the context of xn and
on the pairwise af   nity between mentions xn and
antecedent y, respectively (wiseman et al., 2015).
note that ha and hc use the same raw features; only
their weights differ.

we now specify our global scoring function g
based on the history of previous decisions. de   ne
h(m)
<n as the hidden state of cluster m before a de-
cision is made for xn     that is, h(m)
<n is the state of
cluster m   s id56 after it has consumed all mentions
in the cluster preceding xn. we de   ne g as

g(xn, y,z1:n   1) (cid:44)

hc(xn)th(zy)
<n
na(xn)

if y (cid:54)=  
if y =  

,

where na gives a score for assigning   based on
a non-linear function of all of the current hidden
states:

(cid:40)

(cid:16)

(cid:104)   a(xn)
(cid:80)m

m=1 h(m)

<n

(cid:105)

(cid:17)

see figure 2 for a diagram. the intuition behind
the    rst case in g is that in considering whether y
is a good antecedent for xn, we add a term to the
score that examines how well xn matches with the
mentions already in x (zy); this matching score is ex-
pressed via a dot-product.2 in the second case, when
predicting that xn is non-anaphoric, we add the na
term to the score, which examines the (sum of) the
current states h(m)
<n of all clusters. this information
is useful both because it allows the non-anaphoric
score to incorporate information about potential an-
tecedents, and because the occurrence of certain
singleton-clusters often predicts the occurrence of
future singleton-clusters, as noted in section 3.

the whole system is trained end-to-end on coref-
erence using id26. for a given training
document, let z(o) be the oracle mapping from men-
tion to cluster, which induces an oracle id91.
while at training time we do have oracle clusters, we
do not have oracle antecedents (y)n
n=1, so following
past work we treat the oracle antecedent as latent (yu
and joachims, 2009; fernandes et al., 2012; chang
et al., 2013; durrett and klein, 2013). we train with
the following slack-rescaled, margin objective:

na(xn) = qt tanh

w s

+ bs

.

2we also experimented with other non-linear functions, but

dot-products performed best.

n(cid:88)

n=1

max
  y   y(xn)

   (xn,   y)(1 + f (xn,   y) + g(xn,   y, z(o))

where the latent antecedent y(cid:96)

    f (xn, y(cid:96)

n)     g(xn, y(cid:96)
n is de   ned as

n, z(o))),

(cid:44)

y(cid:96)
n

arg max
y   y(xn):z(o)

y =z(o)
n

f (xn, y) + g(xn, y, z(o))

if xn is anaphoric, and is   otherwise. the term
   (xn,   y) gives different weight
to different er-
ror types. we use a     with 3 different weights
(  1,   2,   3) for    false link    (fl),    false new    (fn),
and    wrong link    (wl) mistakes (durrett and klein,
2013), which correspond to predicting an antecedent
when non-anaphoric,   when anaphoric, and the
wrong antecedent, respectively.

j

note that in training we use the oracle clusters
z(o). since these are known a priori, we can pre-
compute all the hidden states h(m)
in a document,
which makes training quite simple and ef   cient.
this approach contrasts in particular with the work
of bj  orkelund and kuhn (2014)     who also incor-
porate global information in mention-ranking     in
that they train against latent trees, which are not an-
notated and must be searched for during training. on
the other hand, training on oracle clusters leads to a
mismatch between training and test, which can hurt
performance.

5.2 search
when moving from a strictly local objective to one
with global features, the test-time search problem
becomes intractable. the local objective requires
o(n2) time, whereas the full id91 problem is
np-hard. past work with global features has used
integer id135 solvers for exact search
(chang et al., 2013; peng et al., 2015), or beam
search with (delayed) early update training for an
approximate solution (bj  orkelund and kuhn, 2014).
in contrast, we simply use greedy search at test time,
which also requires o(n2) time.3 the full algorithm

algorithm 1 greedy search with global id56s
1: procedure greedycluster(x1, . . . , xn )
2:

initialize clusters x (1) . . . as empty lists, hidden states
h(0), . . . as 0 vectors in rd, z as map from mention to
cluster, and cluster counter m     0

f (xn, y) + g(xn, y, z1:n   1)

3:
4:

5:
6:
7:
8:
9:
10:
11:
12:

for n = 2 . . . n do
        arg max
y
y   y(xn)
m     zy   
if y    =   then
m     m + 1
m     m

append xn to x (m)
zn     m
h(m)     id56(hc(xn), h(m))

return x (1), . . . , x (m )

is shown in algorithm 1. the greedy search algo-
rithm is identical to a simple mention-ranking sys-
tem, with the exception of line 11, which updates
the current id56 representation based on the previ-
ous decision that was made, and line 4, which then
uses this cluster representation as part of scoring.

6 experiments
6.1 methods
we run experiments on the conll 2012 english
shared task (pradhan et al., 2012). the task uses
the ontonotes corpus (hovy et al., 2006), consist-
ing of 3,493 documents in various domains and for-
mats. we use the experimental split provided in the
shared task. for all experiments, we use the berke-
ley coreference system (durrett and klein, 2013)
for mention extraction and to compute features   a
and   p.
features we use the raw basic+ feature sets de-
scribed by wiseman et al. (2015), with the following
modi   cations:

    we remove all features from   p that concate-
nate a feature of the antecedent with a feature of
the current mention, such as bi-head features.
    we add true-cased head features, a current
speaker indicator feature, and a 2-character

3while id125 is a natural way to decrease search er-
ror at test time, it may fail to help if training involves a local
margin objective (as in our case), since scores need not be cali-
brated across local decisions. we accordingly attempted to train
various locally normalized versions of our model, but found that

they underperformed. we also experimented with training ap-
proaches and model variants that expose the model to its own
predictions (daum  e iii et al., 2009; ross et al., 2011; bengio et
al., 2015), but found that these yielded a negligible performance
improvement.

system

b&k (2014)
m&s (2015)
c&m (2015)
peng et al. (2015)
wiseman et al. (2015)
this work

muc

r

p

74.30
76.72
76.12

-

76.23
77.49

67.46
68.13
69.38

-

69.31
69.75

b3
r

p

62.71
66.12
65.64

-

66.07
66.83

54.96
54.22
56.01

-

55.83
56.95

ceafe

r

p

59.40
59.47
59.44

-

59.41
62.14

52.27
52.33
52.98

-

54.88
53.85

f1
58.58
59.58
60.44
60.50
60.52
61.50

f1
55.61
55.67
56.02
56.37
57.05
57.70

conll
61.63
62.47
63.02
63.03
63.39
64.21

f1
70.72
72.17
72.59
72.22
72.60
73.42

table 1: results on conll 2012 english test set. we compare against recent state of the art systems, including (in
order) bjorkelund and kuhn (2014), martschat and strube (2015), clark and manning (2015), peng et al. (2015), and
wiseman et al. (2015). f1 gains are signi   cant (p < 0.05 under the bootstrap resample test (koehn, 2004)) compared
with wiseman et al. (2015) for all metrics.

genre (out of {bc,bn,mz,nw,pt,tc,wb}) indica-
tor to   p and   a.

    we add features indicating if a mention has a
substring overlap with the current speaker (  p
and   a), and if an antecedent has a substring
overlap with a speaker distinct from the current
mention   s speaker (  p).

    we add a single centered, rescaled document
position feature to each mention when learning
hc. we calculate a mention xn   s rescaled doc-
ument position as 2n   n   1
n   1

.

these modi   cations result in there being approx-
imately 14k distinct features in   a and approxi-
mately 28k distinct features in   p, which is far
fewer features than has been typical in past work.

for training, we use document-size minibatches,
which allows for ef   cient pre-computation of id56
states, and we minimize the loss described in sec-
tion 5 with adagrad (duchi et al., 2011) (after
clipping lstm gradients to lie (elementwise) in
(   10, 10)). we    nd that the initial learning rate cho-
sen for adagrad has a signi   cant impact on results,
and we choose learning rates for each layer out of
{0.1, 0.02, 0.01, 0.002, 0.001}.
in experiments, we set ha(xn), hc(xn), and h(m)
to be     r200, and hp(xn, y)    r700. we use a
single-layer lstm (without    peep-hole    connec-
tions), as implemented in the element-id56 li-
brary (l  eonard et al., 2015). for id173,
we apply dropout (srivastava et al., 2014) with a
rate of 0.4 before applying the linear weights u,
and we also apply dropout with a rate of 0.3 to the
lstm states before forming the dot-product scores.

muc
73.06
mr
avg, oh
73.30
id56, gh 73.63
id56, oh 74.26

b3
62.66
63.06
63.23
63.89

ceafe conll
58.98
64.90
65.07
58.85
65.47
59.56
59.54
65.90

table 2: f1 scores of models described in text on conll
2012 development set. rows in grey highlight models
using oracle history.

following wiseman et al. (2015) we use the cost-
weights    = (cid:104)0.5, 1.2, 1(cid:105) in de   ning    , and we
use their pre-training scheme as well. for    nal re-
sults, we train on both training and development por-
tions of the conll data. scoring uses the of   cial
conll 2012 script (pradhan et al., 2014; luo et al.,
2014). code for our system is available at https:
//github.com/swiseman/nn_coref. the
system makes use of a gpu for training, and trains
in about two hours.

6.2 results
in table 1 we present our main results on the conll
english test set, and compare with other recent state-
of-the-art systems. we see a statistically signi   cant
improvement of over 0.8 conll points over the pre-
vious state of the art, and the highest f1 scores to
date on all three conll metrics.

we now consider in more detail the impact of
global features and id56s on performance. for these
experiments, we report muc, b3, and ceafe f1-
scores in table 2 as well as errors broken down
by mention type and by whether the mention is
anaphoric or not in table 3. table 3 further parti-
tions errors into fl, fn, and wl categories, which

non-anaphoric (fl)

nom. hm nom. no hm

mr
avg, oh
id56, gh
id56, oh
# mentions

1061
1983
1914
1913
9.0k

1130
1140
1125
1130
22.2k

pron.
1075
1011
1893
1842
3.1k

anaphoric (fn + wl)

4.7k

pron.

533+796
578+744
664+727
611+686

666+56
641+60
648+57
648+52
1.0k

nom. hm nom. no hm
665+326
781+300
767+303
750+289

model
mr
avg, oh
id56, gh
id56, oh
# mentions
table 3: number of    false link    (fl) errors on non-
anaphoric mentions (top) and number of    false new    (fn)
and    wrong link    (wl) errors on anaphoric mentions
(bottom) on conll 2012 development set. mentions
are categorized as nominal or proper with (previous) head
match (nom. hm), nominal or proper with no head match
(nom. no hm), and pronominal. models are described
in the text, and rows in grey highlight models using oracle
history.

7.3k

are de   ned in section 5.1. we typically think of fl
and wl as representing precision errors, and fn as
representing recall errors.

our experiments consider several different set-
tings.
first, we consider an oracle setting
(   id56, oh    in tables), in which the model receives
z(o)
1:n   1, the oracle partial id91 of all mentions
preceding xn in the document, and is therefore not
forced to rely on its own past predictions when pre-
dicting xn. this provides us with an upper bound on
the performance achievable with our model. next,
we consider the performance of the model under
a greedy id136 strategy (id56, gh), as in al-
gorithm 1. finally, for baselines we consider the
mention-ranking system (mr) of wiseman et al.
(2015) using our updated feature-set, as well as a
non-local baseline with oracle history (avg, oh),
which averages the representations hc(xj) for all
xj     x (m), rather than feed them through an id56;
errors are still backpropagated through the hc repre-
sentations during learning.

in table 3 we see that the id56 improves per-
formance overall, with the most dramatic improve-

figure 3: cluster predictions of greedy id56 model; co-
clustered mentions are of the same color, and intensity of
mention xj corresponds to hc(xn)th(i)
<k, where k = j+1,
i     {1, 2}, and xn =    his.    see text for full description.

ments on non-anaphoric pronouns, though errors are
also decreased signi   cantly for non-anaphoric nom-
inal and proper mentions that follow at least one
mention with the same head. while wl errors also
decrease for both these mention-categories under the
id56 model, fn errors increase.
importantly, the
id56 performance is signi   cantly better than that
of the avg baseline, which barely improves over
mention-ranking, even with oracle history. this sug-
gests that modeling the sequence of mentions in a
cluster is advantageous. we also note that while
id56 performance degrades in both precision and
recall when moving from the oracle history upper-
bound to a greedy setting, we are still able to recover
a signi   cant portion of the possible performance im-
provement.

6.3 qualitative analysis
in this section we consider in detail the impact of the
g term in the id56 scoring function on the two error
categories that improve most under the id56 model
(as shown in table 3), namely, pronominal wl errors
and pronominal fl errors. we consider an example
from the conll development set in each category
on which the baseline mr model makes an error but
the greedy id56 model does not.

the example in figure 3 involves the resolution
of the ambiguous pronoun    his,    which is brack-
eted and in bold in the    gure. whereas the baseline
mr model incorrectly predicts    his    to corefer with
the closest gender-consistent antecedent    justin       
thus making a wl error     the greedy id56 model

figure 4: magnitudes of gradients of na score applied
to bold    it   s    with respect to    nal mention in three pre-
ceding clusters. see text for full description.

correctly predicts    his    to corefer with    mr. kaye   
in the previous sentence.
(note that    the of   cial   
also refers to mr. kaye). to get a sense of the greedy
id56 model   s decision-making on this example, we
color the mentions the greedy id56 model has pre-
dicted to corefer with    mr. kaye    in green, and the
mentions it has predicted to corefer with    justin    in
blue. (note that the model incorrectly predicts the
initial    i    mentions to corefer with    justin.   ) let-
ting x (1) refer to the blue cluster, x (2) refer to the
green cluster, and xn refer to the ambiguous mention
   his,    we further shade each mention xj in x (1) so
that its intensity corresponds to hc(xn)th(1)
<k, where
k = j + 1; mentions in x (2) are shaded analogously.
thus, the shading shows how highly g scores the
compatibility between    his    and a cluster x (i) as
each of x (i)   s mentions is added. we see that when
the initial    justin    mentions are added to x (1) the
g-score is relatively high. however, after    the com-
pany    is correctly predicted to corefer with    justin,   
the score of x (1) drops, since companies are gener-
ally not coreferent with pronouns like    his.   

figure 4 shows an example (consisting of a tele-
phone conversation between    a    and    b   ) in which
the bracketed pronoun    it   s    is being used pleonas-
tically. whereas the baseline mr model predicts
   it   s    to corefer with a previous    it        thus mak-
ing a fl error     the greedy id56 model does not. in
figure 4 the    nal mention in three preceding clusters
is shaded so its intensity corresponds to the magni-
tude of the gradient of the na term in g with re-
spect to that mention. this visualization resembles
the    saliency    technique of li et al. (2016), and it at-
tempts to gives a sense of the contribution of a (pre-
ceding) cluster in the calculation of the na score.

we see that the potential antecedent    s-bahn   
has a large gradient, but also that the initial, obvi-
ously pleonastic use of    it   s    has a large gradient,

which may suggest that earlier, easier predictions of
pleonasm can inform subsequent predictions.

7 related work

in addition to the related work noted throughout,
we add supplementary references here. unstruc-
tured approaches to coreference typically divide into
mention-pair models, which classify (nearly) every
pair of mentions in a document as coreferent or
not (soon et al., 2001; ng and cardie, 2002; bengt-
son and roth, 2008), and mention-ranking models,
which select a single antecedent for each anaphoric
mention (denis and baldridge, 2008; rahman and
ng, 2009; durrett and klein, 2013; chang et al.,
2013; wiseman et al., 2015). structured approaches
typically divide between those that induce a clus-
tering of mentions (mccallum and wellner, 2003;
culotta et al., 2007; poon and domingos, 2008;
haghighi and klein, 2010; stoyanov and eisner,
2012; cai and strube, 2010), and, more recently,
those that learn a latent tree of mentions (fernandes
et al., 2012; bj  orkelund and kuhn, 2014; martschat
and strube, 2015).

there have also been structured approaches that
merge the mention-ranking and mention-pair ideas
in some way. for instance, rahman and ng (2011)
rank clusters rather than mentions; clark and man-
ning (2015) use the output of both mention-ranking
and mention pair systems to learn a id91.

the application of id56s to modeling (the trajec-
tory of) the state of a cluster is apparently novel,
though it bears some similarity to the recent work
of dyer et al. (2015), who use lstms to embed the
state of a transition based parser   s stack.

8 conclusion

we have presented a simple, state of the art approach
to incorporating global information in an end-to-end
coreference system, which obviates the need to de-
   ne global features, and moreover allows for simple
(greedy) id136. future work will examine im-
proving recall, and more sophisticated approaches
to global training.

acknowledgments

we gratefully acknowledge the support of a google
research award.

references
[bengio et al.2015] samy bengio,

oriol vinyals,
navdeep jaitly, and noam shazeer. 2015. scheduled
sampling for sequence prediction with recurrent
neural networks. in advances in neural information
processing systems, pages 1171   1179.

[bengtson and roth2008] eric bengtson and dan roth.
2008. understanding the value of features for coref-
erence resolution. in proceedings of the 2008 con-
ference on empirical methods in natural language
processing, pages 294   303. association for compu-
tational linguistics.

[bj  orkelund and kuhn2014] anders bj  orkelund

and
jonas kuhn. 2014. learning structured id88s
for coreference resolution with latent antecedents
and non-local features. acl, baltimore, md, usa,
june.

[cai and strube2010] jie cai and michael strube. 2010.
end-to-end coreference resolution via hypergraph par-
titioning. in 23rd international conference on com-
putational linguistics (coling), pages 143   151.

[chang et al.2013] kai-wei chang, rajhans samdani,
and dan roth. 2013. a constrained latent variable
model for coreference resolution. in proceedings of
the 2013 conference on empirical methods in natural
language processing, pages 601   612.

[clark and manning2015] kevin clark and christo-
pher d. manning. 2015. entity-centric coreference
in proceedings
resolution with model stacking.
of the 53rd annual meeting of the association for
computational linguistics (acl), pages 1405   1415.
[culotta et al.2007] aron culotta, michael wick, robert
hall, and andrew mccallum. 2007. first-order prob-
in hu-
abilistic models for coreference resolution.
man language technology conference of the north
american chapter of the association of computa-
tional linguistics (naacl hlt).

[daum  e iii et al.2009] hal daum  e iii, john langford,
and daniel marcu. 2009. search-based structured pre-
diction. machine learning, 75(3):297   325.

[denis and baldridge2008] pascal denis

jason
baldridge. 2008. specialized models and ranking
in proceedings of the
for coreference resolution.
2008 conference on empirical methods in natural
language processing, pages 660   669. association
for computational linguistics.

and

[duchi et al.2011] john duchi, elad hazan, and yoram
singer. 2011. adaptive subgradient methods for on-
line learning and stochastic optimization. the jour-
nal of machine learning research, 12:2121   2159.

[durrett and klein2013] greg durrett and dan klein.
2013. easy victories and uphill battles in corefer-
ence resolution. in proceedings of the 2013 confer-

ence on empirical methods in natural language pro-
cessing, pages 1971   1982.

[durrett and klein2014] greg durrett and dan klein.
2014. a joint model for entity analysis: coreference,
typing, and linking. transactions of the association
for computational linguistics, 2:477   490.

[dyer et al.2015] chris dyer, miguel ballesteros, wang
ling, austin matthews, and noah a. smith. 2015.
transition-based id33 with stack long
in proceedings of the 53rd an-
short-term memory.
nual meeting of the association for computational
linguistics (acl), pages 334   343.

[fernandes et al.2012] eraldo

rezende

fernandes,
c    cero nogueira dos santos, and ruy luiz milidi  u.
2012.
latent structure id88 with feature
induction for unrestricted coreference resolution.
in joint conference on emnlp and conll-shared
task, pages 41   48. association for computational
linguistics.

[haghighi and klein2010] aria haghighi and dan klein.
2010. coreference resolution in a modular, entity-
in the 2010 annual conference of
centered model.
the north american chapter of the association for
computational linguistics, pages 385   393. associa-
tion for computational linguistics.

[hochreiter and schmidhuber1997] sepp hochreiter and
j  urgen schmidhuber. 1997. long short-term memory.
neural comput., 9:1735   1780.

[hovy et al.2006] eduard hovy, mitchell marcus, martha
palmer, lance ramshaw, and ralph weischedel.
2006. ontonotes: the 90% solution. in proceedings
of the human language technology conference of the
naacl, companion volume: short papers, pages 57   
60. association for computational linguistics.

[koehn2004] philipp koehn. 2004. statistical signi   -
cance tests for machine translation evaluation.
in
proceedings of the 2004 conference on empirical
methods in natural language processing, pages 388   
395. citeseer.

[kummerfeld and klein2013] jonathan k. kummerfeld
and dan klein. 2013. error-driven analysis of chal-
lenges in coreference resolution. in proceedings of
the 2013 conference on empirical methods in natural
language processing, seattle, wa, usa, october.

[l  eonard et al.2015] nicholas l  eonard, yand waghmare,
id56:
arxiv preprint

sagar ad wang, and jin-hwa kim.
recurrent library for torch.
arxiv:1511.07889.

2015.

[li et al.2016] jiwei li, xinlei chen, eduard hovy, and
dan jurafsky. 2016. visualizing and understanding
neural models in nlp. in naacl hlt.

[luo et al.2014] xiaoqiang luo, sameer pradhan, marta
recasens, and eduard hovy. 2014. an extension of

[ross et al.2011] st  ephane ross, geoffrey j. gordon, and
drew bagnell. 2011. a reduction of imitation learn-
ing and id170 to no-regret online learn-
in proceedings of the fourteenth international
ing.
conference on arti   cial intelligence and statistics,
pages 627   635.

[soon et al.2001] wee meng soon, hwee tou ng, and
daniel chung yong lim. 2001. a machine learning
approach to coreference resolution of noun phrases.
computational linguistics, 27(4):521   544.

[srivastava et al.2014] nitish srivastava, geoffrey hin-
ton, alex krizhevsky, ilya sutskever, and ruslan
salakhutdinov. 2014. dropout: a simple way to pre-
vent neural networks from over   tting. the journal of
machine learning research, 15(1):1929   1958.

[stoyanov and eisner2012] veselin stoyanov and jason
eisner. 2012. easy-   rst coreference resolution. in
coling, pages 2519   2534. citeseer.

[sutskever et al.2014] ilya sutskever, oriol vinyals, and
quoc vv le. 2014. sequence to sequence learning
with neural networks. in advances in neural informa-
tion processing systems (nips), pages 3104   3112.

[van der maaten and hinton2012] laurens

der
maaten and geoffrey e. hinton. 2012. visualizing
non-metric similarities in multiple maps. machine
learning, 87(1):33   55.

van

[wiseman et al.2015] sam wiseman, alexander m. rush,
stuart m. shieber, and jason weston. 2015. learning
anaphoricity and antecedent ranking features for coref-
erence resolution. in proceedings of the 53rd annual
meeting of the association for computational linguis-
tics (acl), pages 1416   1426.

[yu and joachims2009] chun-nam john yu and thorsten
joachims. 2009. learning structural id166s with la-
tent variables. in proceedings of the 26th annual in-
ternational conference on machine learning, pages
1169   1176. acm.

[zaremba et al.2014] wojciech zaremba, ilya sutskever,
and oriol vinyals. 2014. recurrent neural network
id173. corr, abs/1409.2329.

blanc to system mentions. proceedings of acl,
baltimore, maryland, june.

[martschat and strube2015] sebastian martschat

and
michael strube. 2015. latent structures for corefer-
ence resolution. tacl, 3:405   418.

[martschat et al.2015] sebastian martschat,

thierry
g  ockel, and michael strube. 2015. analyzing and
in naacl
visualizing coreference resolution errors.
hlt, pages 6   10.

[mccallum and wellner2003] andrew mccallum and
ben wellner.
2003. toward conditional models
of identity uncertainty with application to proper
noun coreference. advances in neural information
processing systems 17.

[ng and cardie2002] vincent ng and claire cardie.
2002.
identifying anaphoric and non-anaphoric
noun phrases to improve coreference resolution. in
proceedings of the 19th international conference on
computational linguistics-volume 1, pages 1   7. asso-
ciation for computational linguistics.

[peng et al.2015] haoruo peng, kai-wei chang, and dan
roth. 2015. a joint framework for coreference reso-
lution and mention head detection. in proceedings of
the 19th conference on computational natural lan-
guage learning (conll), pages 12   21.

[poon and domingos2008] hoifung poon and pedro m.
domingos. 2008. joint unsupervised coreference res-
in 2008 conference on
olution with markov logic.
empirical methods in natural language processing
(emnlp), pages 650   659.

[pradhan et al.2012] sameer pradhan, alessandro mos-
chitti, nianwen xue, olga uryupina, and yuchen
zhang. 2012. conll-2012 shared task: modeling
multilingual unrestricted coreference in ontonotes.
in joint conference on emnlp and conll-shared
task, pages 1   40. association for computational lin-
guistics.

[pradhan et al.2014] sameer pradhan, xiaoqiang luo,
marta recasens, eduard hovy, vincent ng, and
michael strube. 2014. scoring coreference partitions
of predicted mentions: a reference implementation.
in proceedings of the association for computational
linguistics.

[rahman and ng2009] altaf rahman and vincent ng.
2009. supervised models for coreference resolution.
in proceedings of the 2009 conference on empirical
methods in natural language processing: volume 2-
volume 2, pages 968   977. association for computa-
tional linguistics.

[rahman and ng2011] altaf rahman and vincent ng.
2011. narrowing the modeling gap: a cluster-ranking
approach to coreference resolution. j. artif. intell. res.
(jair), 40:469   521.

