7
1
0
2

 

b
e
f
8
1

 

 
 
]
l
c
.
s
c
[
 
 

4
v
6
2
1
2
0

.

6
0
6
1
:
v
i
x
r
a

supervised syntax-based alignment between english sentences

and id15 graphs

chenhui chu1 and sadao kurohashi2
1japan science and technology agency

2graduate school of informatics, kyoto university
chu@pa.jst.jp, kuro@i.kyoto-u.ac.jp

abstract

as alignment links are not given between english
sentences and id15
(amr) graphs in the amr annotation, automatic
alignment becomes indispensable for training an
amr parser. previous studies formalize it as a
string-to-string problem and solve it in an unsu-
pervised way, which suffers from data sparseness
due to the small size of training data for english-
amr alignment. in this paper, we formalize it as
a syntax-based alignment problem and solve it in
a supervised manner based on syntax trees, which
can address the data sparseness problem by gener-
alizing english-amr tokens to syntax tags. ex-
periments verify the effectiveness of the proposed
method not only for english-amr alignment, but
also for amr parsing.

1 introduction
id15 (amr) is a sentence level
semantic annotation, which is represented in a rooted,
directed, and edge-labeled graph [banarescu et al., 2013].
nodes of a graph are concepts (e.g.,    possible    in figure 1),
while edges are labeled with semantic roles (e.g.,    :arg4    in
figure 1). amr concepts consist of predicate senses, named
entities, and lemmas of english tokens. amr roles consist of
core semantic roles from the propbank [palmer et al., 2005]
and    ne-grained semantic roles de   ned speci   cally for amr.
as amr annotation has no explicit alignment with the to-
kens in the english sentence, automatic alignment becomes a
requirement for training amr parsers [flanigan et al., 2014;
wang et al., 2015; werling et al., 2015; artzi et al., 2015;
pust et al., 2015; zhou et al., 2016; misra and artzi, 2016;
peng et al., 2017].

the alignment problem between english sentences and
amr graphs is not trivial. there are two reasons. firstly,
the problem itself is complicated. concepts do not always
have a direct matching among the english tokens in a given
sentence. for example, in figure 1 the english token    could   
is represented as the concept    possible,    and aligning them
is not easy. it becomes more dif   cult in the english token-
to-role alignment case. for example, in figure 1, we should
align the english token    to    to the role    :arg4.    secondly,

!"#$%&   ()$*&$!"$+$,-$"$*"((&.$
$
/0$1$0&##23(454,$
$$$$$$!"#$%&   $/*$1$*&6-,547$
$$$$$$$$$$$$!()*+$/8$1$892.*$
$$$$$$$$$$$$$$$$$$!()*,-#.$/07$1$0:2%46-,$
$$$$$$$$$$$$$$$$$$$$$$$$!()*+$/*;$1$*"#54-$
$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$!/0%   1$/<7$1$2#30$4-/0%   5167!/0%   1$,54=$
$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$!0   &1$/*>$1$*"((&.54?@@@@@$
$$$$$$$$$$$$!"#$%54a$/b7$1$$#   41%86-/0%   5167!/0%   1$,-54>$
$$$$$$$$$$$$$$$$$$!0   &1$/)7$1$)&((":54;@@@@!

figure 1: an example of english-amr alignment (amr
concepts are underlined, amr roles are in bold,    e denotes
alignment and the numbers after    e are english token in-
dices).

the training data for english-amr alignment is very small.
the biggest publicly available data set only contains 13,050
english-amr pairs, which is signi   cantly smaller than con-
ventional alignment settings in machine translation (mt).

[flanigan et al., 2014] is the    rst study of english-amr
alignment, which proposes a rule-based method. the lim-
it cannot ben-
itation of the rule-based method is that
e   t from more annotation of english-amr pairs.
a
data driven alignment method also has been proposed
[pourdamghani et al., 2014]. they formalize the string-to-
graph alignment problem as a string-to-string problem by
linearizing the amr graph. then they apply the conven-
tional unsupervised string-to-string alignment models (i.e.,
ibm models [brown et al., 1993]) for this problem. how-
ever, this method signi   cantly suffers from data sparseness
due to the small size of training data.

in the

effectiveness

using syntax trees in a supervised manner has shown
its
alignment problem in mt
[riesa et al., 2011]. motivated by this,
in this paper,
we formalize the english-amr graph alignment problem as
a syntax-based alignment problem. we then apply the super-
vised syntax-based alignment model [riesa et al., 2011] for
this. our proposed method generalizes pure english-amr
tokens to syntax tags, which can address the data sparseness
problem of the previous study [pourdamghani et al., 2014].

experiments conducted on the benchmark dataset show
that our proposed method outperforms the unsupervised
alignment model of [pourdamghani et al., 2014] by 1.7%
absolute f-score on alignment accuracy, although it
is
trained on only 100 english-amr pairs that are annotated
with gold alignments. using the alignments by our pro-
posed method instead of the unsupervised alignments for
a state-of-the-art amr parser [pust et al., 2015] improves
the parsing accuracy of 0.4% absolute smatch f-score
[cai and knight, 2013].

have

been

criteria,

alignment

and their

alignment methods

2 related work
corre-
three different
proposed
sponding
[flanigan et al., 2014;
pourdamghani et al., 2014;
[flanigan et al., 2014] is the most
werling et al., 2015].
prior work of english-amr alignment. they proposed an
alignment criterion that aligns a span of english tokens
to an amr graph concept fragment. this means that in
figure 1, e.g., the english token    gas    should be aligned
to the graph fragment    (t / thing :arg2-of (p2 / price-01
:amr1 (g4 / gas.    their criterion, however, does not align
[flanigan et al., 2014] proposed a
amr roles explicitly.
rule-based method for this type of alignment.
in contrast,
[pourdamghani et al., 2014] proposed an alignment crite-
rion that not only aligns amr concepts but also roles to
english tokens explicitly.
in addition, in their criterion,
each concept and role is aligned to at most one english
token, but each english token can be aligned to many
concepts/roles. an example of the alignment criterion of
[pourdamghani et al., 2014] is shown in figure 1. they pro-
posed an unsupervised string-to-string alignment model for
this. [werling et al., 2015] essentially adopted the alignment
criterion of [pourdamghani et al., 2014], except that they
forced every amr concept aligns to some english tokens.
they proposed a boolean id135 method for
this. note that the accuracies of these studies were reported
on different golden alignment data, and thus they are not
directly comparable. we adopt
the alignment criterion
of [pourdamghani et al., 2014], and directly compare the
alignment accuracy with their method.

for amr parsing, [flanigan et al., 2014] is also the most
prior work. they proposed a graph based parsing method
that    nds a maximum spanning and connected subgraph via
id170 for amr parsing. their parser is pub-
licly available as the jamr parser.1
[werling et al., 2015]
extended the study of [flanigan et al., 2014] by propos-
ing generative actions for subgraph derivation based on
[zhou et al., 2016] extended
their alignment criterion.
the study of [flanigan et al., 2014] by proposing a beam
[wang et al., 2015] proposed a tran-
search algorithm.
sition based method that    rst parses english sentences
to dependency trees and then transforms the dependency
their parser is publicly avail-
trees to amr graphs.
able as the camr parser.2
[artzi et al., 2015] proposed
using the id35
for

(id35)

1http://github.com/j   anigan/jamr
2https://github.com/c-amr/camr

note that

[misra and artzi, 2016] developed the
amr parsing.
id35 amr parsing method of [artzi et al., 2015] based
[flanigan et al., 2014;
on neural networks.
wang et al., 2015; artzi et al., 2015;
zhou et al., 2016;
misra and artzi, 2016] adopted the alignment criterion and
method of [flanigan et al., 2014]. [pust et al., 2015] treated
amr parsing as a string-to-tree, syntax-based mt problem.
after transforming english sentences to trees, they further
convert the trees to amr graphs. their parser is publicly
available as the isi amr parser.3 seqence-to-seqence based
amr parsing also has been proposed [peng et al., 2017],
however it suffers from data sparseness due to the small
both [pust et al., 2015]
size of amr training data.
and [peng et al., 2017] adopted the alignment criterion
and method of [pourdamghani et al., 2014].
note that
[werling et al., 2015; zhou et al., 2016;
the parsers of
peng et al., 2017] are not publicly available. we apply the
alignments by our proposed method to the isi amr parser
[pust et al., 2015], and also compare the parsing performance
with the other publicly available parsers (i.e., jamr and
camr).

3 baseline alignment method
the baseline method that we compare to is the isi align-
ment [pourdamghani et al., 2014]. the isi alignment method
formalizes the english-amr graph alignment problem as a
string-to-string alignment problem, by linearizing an amr
graph to a string.
it includes three steps: preprocessing,
string-to-string alignment, and postprocessing.

3.1 preprocessing

    linearize the amr using a depth-   rst traversal. for ex-
ample, the amr graph in figure 1 will be linearized to
   possible :domain go-01 :arg1 thing :arg2-of price-
01 :arg1 gas :quant volume-quantity :quant 1 :unit gal-
lon :arg4 monetary-quantity :quant 10 :unit dollar.   

    remove the tokens that are rarely aligned, to improve
the precision with a small sacri   ce of recall. on the en-
glish side, this removes stop words, such as articles    a   ,
   an   ,    the   ; on the amr side, this removes special con-
cepts, and roles, such as    :arg0   ,    :quant   ,    :op1    that do
not usually align, quotes, and sense tags. after this step,
the english sentence in figure 1 becomes    gas could
go to $ 10 gallon   ; the amr is transferred to    possi-
ble :domain go thing :arg2-of price gas 1 gallon :arg4 10
dollar   .

    lowercase and stem both sides to the    rst four letters.
this is necessary to address the sparseness of the train-
ing data, which is very small compared to the size of the
training data for conventional word alignment of mt.
this converts english to    gas coul go to $ 10 gall   , and
amr to    poss :domain go thin :arg2-of pric gas 1 gall
:arg4 10 doll    in figure 1.

3.2 string-to-string alignment
as the preprocessing step has converted the english-
amr graph alignment problem to a string-to-string align-

3http://www.isi.edu/   pust/amrparser.tar.gz

ment problem,
the widely used ibm alignment models
[brown et al., 1993] that are based on token sequences can
be applied. to further improve the alignment accuracy,
[pourdamghani et al., 2014] also proposed a symmetrization
constraint that encourages agreement of the parameter learn-
ing in two directions for the ibm models.

3.3 postprocessing
the string-to-string alignments are    nally projected back to
the original english sentence and the amr graph to obtain
english-amr graph alignments. this can be done easily by
memorizing the corresponding token positions before and af-
ter the preprocessing.

4 proposed alignment method
we use the same pipeline as [pourdamghani et al., 2014],
however, we formalize it as a constituency tree based align-
ment problem, and apply the hierarchical alignment model
of [riesa et al., 2011]. this method has been proposed for
conventional word alignment of mt, however, it has not been
used for english-amr graph alignment.

4.1 constituency trees for english and amr
constituency trees for english can be obtained via a conven-
tional syntactic parser. in this study, we parse original english
sentences with the berkeley parser4 [petrov and klein, 2007].
we process obtained constituency trees by discarding the stop
words, and replacing the leaf tokens with their stems. an ex-
ample of the    nal tree is shown in figure 2.

for amr, we convert amrs to constituency trees using
the method proposed in [pust et al., 2015] with the following
steps:

    arbitrarily disconnect multiple parents from each node.
    propagate the edge labels (roles) to leaves, and add pre-

terminals x.

    restructure the tree with role labels as intermediates.

we do not apply the reordering steps, because they requires
alignments. for more details of these steps, please refer to
[pust et al., 2015]. we used the amr to syntax tree conver-
sion code provided by [pust et al., 2015] for the above con-
version.

we then process the converted amr trees by discarding
special concepts and roles that are rarely aligned, and replac-
ing leaf tokens with their stems. note that the converted amr
trees usually are not isomorphic to the english trees. for ex-
ample,    could    is the grandchild of the root in the english
tree, while in the converted amr tree    possible    is the direct
child of the root.

4.2 hierarchical alignment on constituency trees
figure 2 shows an overview of the application of the hierar-
chical alignment model [riesa et al., 2011] to our problem.
the model hierarchically searches for the k-best alignment
by constructing partial alignments over a target constituency
tree,5 in a bottom-up manner (from leaf nodes to the root).

4https://github.com/slavpetrov/berkeleyparser
5the source side could be either a constituency tree or a token

sequence.

$"**!

!"#$%!
&   !

()**!

$"**!

!"#$%!
&   !

()**!

$"**!

!"#$%!
&   !

()**!

$"**!

!"#$%!
&   !

()**!

$"**!

!"#$%!
&   !

()**!

figure 2: proposed alignment method (each black square
represents a partial alignment; each gray square represents
an alignment link in an alignment matrix).

each node in the tree has partial alignments, which are sorted
by alignment scores. a partial alignment for a node is an
alignment matrix of amr tokens or null, covered by the
node, and it is represented as a black square. we only keep
a beam size of k for partial alignments for each node,6 to re-
duce the computational cost. for example, in figure 2 the
beam size k = 4. firstly, 4-best partial alignments are gener-
ated for all the leaf nodes. these partial alignments are then
linearly combined to generate partial alignments for the non-
terminals in the constituency tree. for example, the partial
alignments of the leaf node    $    and    10    are combined to
generate 4-best partial alignments for the node    np   . we hi-
erarchically perform this process until we reach the root node.
one important merit of this model is that it is a discrimi-
native model that can incorporate various features including
local and non-local features. local features are the ones that
can be factored among the local productions in a tree, and
otherwise they are non-local features. local features include
source syntactic, target syntactic, source-target joint syntac-
tic, translation rule and same token features. non-local fea-
tures include lexical translation probabilities, and third party
alignment features.

the score of a partial alignment is a linear combination of
these features by their weights. the weights of the features
are learnt against a set of pairs with gold alignments, using the
online averaged id88 algorithm [collins, 2002]. the
learning objective is de   ned as:

  y = arg max
y   y (xi)

l(yi, y) + w    h(y)

(1)

where xi is a token sequence pair and their parse trees; yi
is the gold alignment for xi; y (xi) denotes all the possible
alignment outputs for xi; w is a weight vector; h(y) is a vec-
tor of feature values; l(yi, y) is a id168 to measure
how bad it would be to guess y instead of yi, which is de   ned

6we used a beam size of 128 in our experiments.

# pairs
# amr tokens
# amr roles
# english tokens

original split

train
10,311
364k
177k
213k

our split

dev
1,368
48.9k
23.7k
28.8k

test
1,371
51.0k
24.8k
29.5k

# pairs
# amr tokens
# amr roles
# english tokens

train
10,311+200
370k
180k
217k

dev
1,368-100
45.1k
21.9k
26.5k

test
1,371-100
48.6k
23.6k
27.8k

table 1: statistics of the amr corpus for amr parsing.

# pairs
# amr tokens

# amr roles

# english tokens

train
100
3.0k
(54.7%)
1.5k
(23.5%)
2.0k
(74.9%)

dev
50
1.5k
(51.6%)
0.7k
(21.0%)
0.9k
(75.8%)

test
50
1.6k
(52.2%)
0.8k
(21.6%)
1.1k
(75.4%)

table 2: statistics of the gold alignment data (the numbers
in parentheses are the percentages of the tokens aligned in the
gold alignment data).

as:

l(yi, y) = 1     f1(yi, y)

(2)
where f1(yi, y) is a f-score. w is updated at each iteration
as:

w = w + h(yi)     h(  y)

(3)

we stop the update of w when a prede   ned iteration number
has been reached. after the learning of a set of w at each itera-
tion, we select the w that achieves the best f-score on a devel-
opment set for decoding. for more details of the features and
the learning algorithm, please refer to [riesa et al., 2011].

5 experiments
we conducted both alignment and amr parsing experiments,
to verify the effectiveness of our proposed alignment method.

5.1 settings
the data used in our experiments was the linguistic data
consortium amr corpus release 1.0 (ldc2014t12), con-
sisting of 13,050 amr/english sentence pairs.7 the statis-
tics of the original split in the amr corpus for training,
development, and testing amr parsers are shown in upper
part of table 1. among which, 100 development8 and 100
testing9 pairs were manually annotated with gold alignments
[pourdamghani et al., 2014]. as these 200 pairs were used
for training and testing (and tuning for our proposed align-
ment model) alignment models in our study, we moved them

7https://catalog.ldc.upenn.edu/ldc2014t12
8http://www.isi.edu/natural-language/mt/dev-gold.txt
9http://www.isi.edu/natural-language/mt/test-gold.txt

type

concept

role

concept
+role

method
isi
proposed
upper bound
isi
proposed
upper bound
isi
proposed
upper bound

f-score
precision recall
96.2% 85.6%
90.6%
97.1% 87.8% 92.2%   
97.0%
99.7% 94.4%
69.1% 43.9%
53.7%
69.7% 47.6% 56.6%   
95.4% 66.1%
78.1%
92.0% 77.1%
83.9%
92.7% 79.6% 85.6%   
99.0% 88.6%
93.5%

table 3: alignment results (   proposed    shows the best re-
sults among the different syntax usages,    upper bound is   
the upper bound after removing stop words in english and
rarely aligned concepts, roles in amr,           indicates that the
f-score is signi   cantly better than    isi    at p < 0.01).

to the training data for our amr parsing experiments. the
statistics of our split of the amr corpus for amr parsing is
shown in lower part of table 1. we further mixed these 200
pairs with gold alignments pair by pair, and split them into
100, 50, 50 for training, tuning, and testing, respectively in
our alignment experiments. table 2 shows the statistics of
the gold alignment data.

our

for

alignment,

baseline method

compared
the

we
proposed
alignment method with
of
[pourdamghani et al., 2014]. for the baseline method, we
ran the publicly available toolkit isi aligner10 on the training
data of our split in table 1. the isi aligner is an implementa-
tion of the method described in [pourdamghani et al., 2014].
for our proposed method, we trained and tuned the align-
ment model on the 100 training and 50 development pairs,
respectively, with the open source supervised alignment
toolkit nile11 [riesa et al., 2011]. as the third party align-
ment feature for nile, we used the trained isi alignments.
lexical translation probabilities were generated from the
isi alignments on the training data of our split in table 1.
alignment results were reported on the 50 testing pairs. in
addition, we compared different ways of using syntax trees
for our proposed method:

    amr(string)-en(tree): use amr strings as the source

side, and english trees as the target side.

    amr(tree)-en(tree): use converted amr trees as the

source side, and english trees as the target side.

    en(tree)-amr(tree): use english trees as the source

side, and converted amr trees as the target side.

    grow-diag-   nal-and (1): a symmetrization of the align-
ment results of amr(string)-en(tree) and en(tree)-
amr(tree) with the grow-diag-   nal-and heuristic
[och and ney, 2003], which is commonly used in mt.

    grow-diag-   nal-and (2): a symmetrization of the
alignment results of amr(tree)-en(tree) and en(tree)-
amr(tree) with the grow-diag-   nal-and heuristic
[och and ney, 2003].

for amr parsing, we compared the parsing performance
of the state-of-the-art amr parser [pust et al., 2015] using

10http://www.isi.edu/ damghani/papers/aligner.zip
11https://github.com/neubig/nile

type

method

precision

recall

f-score

concept

role

amr(string)-en(tree)
amr(tree)-en(tree)
en(tree)-amr(tree)
grow-diag-   nal-and (1)
grow-diag-   nal-and (2)
amr(string)-en(tree)
amr(tree)-en(tree)
en(tree)-amr(tree)
grow-diag-   nal-and (1)
grow-diag-   nal-and (2)
amr(string)-en(tree)

concept amr(tree)-en(tree)
+role
en(tree)-amr(tree)
grow-diag-   nal-and (1)
grow-diag-   nal-and (2)

91.6%
96.1% 87.5%
91.4%
95.9% 87.2%
94.7% 88.0%
91.3%
94.7% 88.6% 91.6%
97.1% 87.8%
92.2%
55.9%
78.8% 43.3%
77.3% 43.3%
55.5%
61.7% 48.6%
54.4%
67.8% 50.2% 57.7%
56.6%
69.7% 47.6%
85.5%
93.8% 78.5%
93.4% 78.3%
85.2%
88.8% 80.0%
84.2%
90.2% 80.8% 85.2%
92.7% 79.6%
85.6%

table 4: syntax usage comparison results for our proposed
method.

either the baseline isi alignments or our proposed alignments,
respectively. we trained the baseline alignment model us-
ing the same method described above. alignments for the
parsing training data are available once we trained the base-
line alignment model. for our proposed alignment method,
we trained the alignment model with the best syntax usage
and further applied the trained model on the parsing train-
ing data for obtaining alignments. in addition, we compared
with the performance of other public available amr parsers
[flanigan et al., 2014; wang et al., 2015] that use alignments
with different annotation criteria from ours, by running their
parsers with default settings. all amr parsing experiments
were conducted on our split of the amr corpus in table 1.

5.2 alignment results
table 3 shows the alignment results. we report the align-
ment accuracies for the concept, role and both types of to-
kens, respectively. the signi   cance tests were performed us-
ing the id64 method [zhang et al., 2004]. we can
see that our proposed method outperforms the isi alignment
for all the alignment types. however, there is still a gap be-
tween it and the upper bound, especially for role alignment.
although they are not directly comparable, the concept pre-
cision 97.1% and f-score 92.2% obtained by our proposed
method are also signi   cantly higher than the concept preci-
sion 83.2% reported in [werling et al., 2015] and the concept
f-score 90% reported in [flanigan et al., 2014], respectively.
table 4 shows the results of using syntax trees in differ-
ent ways for the proposed method. amr(tree)-english(tree)
performs slightly worse than amr(string)-english(tree), due
to the bad isomorphism between converted amr trees and
english trees. using converted amr trees as the target
side seems to be a bad idea for the precision, but it is
helpful for improving the recall. the reason for this is
that english-to-amr is a one-to-many alignment problem,
while en(tree)-amr(tree) could produce many-to-one align-
ments for english-to-amr due to the peculiarities of nile,
which decreases the precision but improves the recall. the
grow-diag-   nal-and heuristic leverages both the high preci-
sion of amr(tree)-en(tree) and the high recall of en(tree)-
amr(tree), and thus further improves the f-score; it also

676!

8"),)9#-!

!"##$%&   $&()*+&&
,"#-   ./)$&0$-&1)2-&
3#22)4%&)$25&   $&1)2-!

figure 3: an alignment comparison example of better con-
cept recall.

improves the role f-score by using the grow-diag-   nal-and
heuristic for amr(string)-en(tree) and en(tree)-amr(tree).
to further understand the reason for the alignment im-
provement, we investigated many alignment examples. we
found that the main reason for the alignment improvement
is the generalization of pure english-amr tokens to syntax
tags, which addresses the data sparseness problem. figure
3 shows an alignment example of better concept recall by
our proposed method. comparing the isi alignment and our
proposed method, we can see that our proposed method suc-
cessfully aligns the amr concept    7100(000)    to the english
tokens    71    and    mill(ion),    while the isi alignment fails.
   7100(000)    is not aligned to    mill(ion),    due to the sparse-
ness of the training data. with the help of syntax information,
both    7100(000)    and    mill(ion)    are generalized to cardinal
numbers    aquant    and    qp (cd),    respectively. as cardinal
numbers co-occur many times in the training data, our pro-
posed method learns a big positive weight, which success-
fully aligns them.

figure 4 shows an alignment example of better role re-
call by our proposed method. we can see that our proposed
method successfully aligns the amr role token    :topic    to
the english token    with,    while the isi alignment fails. this
is again improved by the syntax information. as    :topic    and
   with    do not co-occur in the training data, it is very dif   -
cult for the isi alignment model to align them. our proposed
method generalizes them to    ctopic    and    in,    respectively.
for which, a positive alignment weight has been learnt, which
makes them being aligned.

figure 5 shows an alignment example of concept precision
comparing the baseline with our proposed method. although
the isi alignment incorrectly aligns the amr concept token
   thin(g)    to the english token    how,    our proposed method
does not align them. because    thin(g)    and    how    co-occurs
several times in the training data, the isi alignment gives it
a high translation id203 and aligns it. our proposed

method
[pust et al., 2015] (isi)
[pust et al., 2015] (proposed)
[pust et al., 2015] (isi) w/ rules
[flanigan et al., 2014]
[wang et al., 2015]
[zhou et al., 2016]

our split original split
65.4%
n/a
67.1%
58.2%
63.0%
66.0%

64.7%
65.1%
n/a
59.0%
61.3%
n/a

table 5: smatch f-scores for amr parsing.

also list the parsing accuracies on the original split reported
in [pust et al., 2015; flanigan et al., 2014; wang et al., 2015;
zhou et al., 2016] in the    original split    column of table
5.13    [pust et al., 2015] (isi)    and    [pust et al., 2015] (pro-
posed)    denote the parsers using different alignment mod-
els.    [pust et al., 2015] (isi) w/ rules    denotes a system that
further used rule-based alignments,    which is not a compari-
son object in our study. note that we cannot report the per-
formance of    [pust et al., 2015] (proposed)    on the original
split, because our proposed alignment method requires the
200 pairs in the development and testing sets of the original
split for training and tuning the alignment model.

parsing

evaluated

using
as

accuracies were

the
smatch f-score [cai and knight, 2013].
reported
[cai and knight, 2013],
the smatch f-score of human
inter-annotator is in the 79-83 range. we can that see on both
our and the original split, [pust et al., 2015] outperforms
the other studies. on our split, the improved alignments
by our proposed method also lead to a 0.4% smatch f-
score improvement for amr parsing with the parser of
[pust et al., 2015]. the performance of    [pust et al., 2015]
(isi)    differs on    our split    and    original split.    the reason
for this is twofold: firstly,    original split    uses 100 more
pairs for tuning the parser; secondly, the 100 testing pairs
moved from the testing data of the original split might
be more dif   cult for parsing, which is consistent with the
parsing performance of [wang et al., 2015].

ghg!

i"),)7#-!

6+   7&   $80*90/)$&4   *+&.   *5&2   :   $1&*"925&(0;#7&<#&=&&
>(&?&(0;#@ab&
&&&&&&%cd!a&>   &?&   $80*90/)$&
&&&&&&&&&&&&%*),   .&>2&?&2   :#@ab&
&&&&&&&&&&&&&&&&&&%2).0/)$&>.&?&.   *5ee&
&&&&&&&&&&&&%<)-&>*&?&*+   7ee&
&&&&&&%cd!b&>   f&?&   e&
&&&&&&%<)-&>*f&?&*"9#ee!

!"#

!"##$%&   $&()*+&&
,"#-   ./)$&0$-&1)2-&
3#22)4%&)$25&   $&1)2-!

figure 4: an alignment comparison example of better role
recall.

!"#$%&   ()*+$!$,-$./00".%1$)"$2%%0$3"4.%.$
"5$   $678$   (4%$*")$9.$:%+"51$-%$;$
$
</$7$/51%4.)   51=>6$
$$?@ab>$9$
$$?@ab6$<)$7$)395c$
$$$$$$$$$$?-   55%4="d$<2$7$2%%0=>6$
$$$$$$$$$$$$$$$$$$$$$$$?@ab>$<9$7$"e$
$$$$$$$$$$$$$$$$$$$$$$$?@ab6$<3$7$3"4.%e$
$$$$$$$$$$$$$$$$$$$$$$$?*"(   f"5$<*$7$*")$
$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$?-"1$<   $7$   4%   =g/   5f)+$
$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$?/59)$<   h$7$   (4%e$
$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$?g/   5)$>;hiee$
$$$$$$$$$$$$$$$$$$$$$$$?@abh="d$<.$7$./00".%=>h$
$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$?@ab6$9ee$
$$$$$$$$$$?-"1$<%$7$%&   ()ee$
$$?0"*   49)+$=e!

jkj!

l4"0".%1!

b4%%5?$95$:")3$$
04%19(f"5$   51$c"*1$
m*/%?$"5*+$95$04%19(f"5$$

figure 5: an alignment comparison example of concept pre-
cision.

method also looks at the syntax information of    thin(g)    and
   how,    which are    sstatement    and    whnp (wrb),    respec-
tively. because this syntax pair rarely co-occurs in the train-
ing data, the learnt weight is negative, which prevents this in-
correct alignment. however, the proposed method incorrectly
aligns the two    i    tokens in amr and english. this hap-
pens because of two reasons: firstly, the correct alignment
   :arg1 i    has been removed in the preprocessing; secondly,
nile has a feature that tends to align same tokens.

5.3 amr parsing results
the amr parsing results are shown in table 5, where
   our split    denotes the performance for different parsers
on our data split of the amr corpus.12 for reference, we

12as the parsers of

[werling et al., 2015; zhou et al., 2016;
peng et al., 2017] are not publicly available, we could not report the
performance of their parser on our data split. we were not able to
run the parsers of [artzi et al., 2015; misra and artzi, 2016] on our
split.

6 conclusion
the alignment between english sentences and amr graphs is
necessary for amr parsing. we improved the alignment ac-
curacy with a supervised syntax-based alignment method. we
showed the effectiveness of the supervised method on both
alignment and amr parsing, even when only a very small
training data set is available (i.e., 100 pairs).

as future work,    rstly, we plan to increase the number of
amr/english sentence pairs with gold alignments for train-
ing a more accurate alignment model. secondly, we plan to
improve the alignment accuracy for roles. semantic role la-
beling [gildea and jurafsky, 2000] for the english sentences

13 note that [flanigan et al., 2014] did not report the result on
this dataset in their paper. [pust et al., 2015] reported the parsing
performance of the parser of [flanigan et al., 2014] on this dataset,
which we listed here. as [werling et al., 2015; artzi et al., 2015;
misra and artzi, 2016] only reported the parsing performance
(62.2%, 66.2%, and 66.0% smatch f-score, respectively) on the
newswire section of the original split, [peng et al., 2017] reported
their performance (52% smatch f-score) on a slighly larger dataset
(ldc2015e86), we do not list their scores in table 5.

and using the obtained roles for alignment may be a solution
for this.

acknowledgments
we are very appreciated to mr. michael pust for providing
the amr to constituency tree conversion code and helping
conduct the amr parsing experiments on his parser. we
also thank mr. yevgeniy puzikov very much for helping con-
duct the amr parsing experiments on the jamr and camr
parsers.

references
[artzi et al., 2015] yoav artzi, kenton lee, and luke zettle-
moyer. broad-coverage id35 id29 with amr. in
proceedings of the 2015 conference on empirical meth-
ods in natural language processing, pages 1699   1710,
lisbon, portugal, september 2015.

[banarescu et al., 2013] laura banarescu, claire bonial,
shu cai, madalina georgescu, kira grif   tt, ulf herm-
jakob, kevin knight, philipp koehn, martha palmer, and
nathan schneider. id15 for
sembanking. in proceedings of the 7th linguistic annota-
tion workshop and interoperability with discourse, pages
178   186, so   a, bulgaria, august 2013.

f.

[brown et al., 1993] peter

brown,

stephen a.
della pietra, vincent j. della pietra, and robert l.
mercer. the mathematics of statistical machine transla-
tion: parameter estimation. computational linguistics,
19(2):263   312, 1993.

[cai and knight, 2013] shu cai and kevin knight. smatch:
an evaluation metric for semantic feature structures.
in
proceedings of the 51st annual meeting of the association
for computational linguistics (volume 2: short papers),
pages 748   752, so   a, bulgaria, august 2013.

[collins, 2002] michael collins. discriminative training
methods for id48: theory and experi-
ments with id88 algorithms. in proceedings of the
2002 conference on empirical methods in natural lan-
guage processing, pages 1   8, july 2002.

[flanigan et al., 2014] jeffrey flanigan, sam thomson,
jaime carbonell, chris dyer, and noah a. smith. a dis-
criminative graph-based parser for the abstract meaning
representation. in proceedings of the 52nd annual meet-
ing of the association for computational linguistics (vol-
ume 1: long papers), pages 1426   1436, baltimore, mary-
land, june 2014.

[gildea and jurafsky, 2000] daniel gildea and daniel juraf-
sky. automatic labeling of semantic roles. in proceedings
of the 38th annual meeting of the association for compu-
tational linguistics, pages 512   520, hong kong, october
2000.

[misra and artzi, 2016] dipendra kumar misra and yoav
artzi. neural shift-reduce id35 id29. in pro-
ceedings of the 2016 conference on empirical methods in
natural language processing, pages 1775   1786, austin,
texas, november 2016.

[och and ney, 2003] franz josef och and hermann ney.
a systematic comparison of various statistical alignment
models. computational linguistics, 29(1):19   51, 2003.

[palmer et al., 2005] martha palmer, daniel gildea, and
paul kingsbury. the proposition bank: an annotated cor-
pus of semantic roles. comput. linguist., 31(1):71   106,
march 2005.

[peng et al., 2017] xiaochang peng, chuan wang, daniel
gildea, and nianwen xue. addressing the data sparsity
issue in neural amr parsing. in proceedings of the 15 th
european chapter of the association for computational
linguistics, valencia, spain, april 2017.

[petrov and klein, 2007] slav petrov and dan klein.

im-
proved id136 for unlexicalized parsing. in human lan-
guage technologies 2007: the conference of the north
american chapter of the association for computational
linguistics; proceedings of the main conference, pages
404   411, rochester, new york, april 2007.

[pourdamghani et al., 2014] nima pourdamghani, yang
gao, ulf hermjakob, and kevin knight. aligning english
strings with id15 graphs.
in proceedings of the 2014 conference on empirical
methods in natural language processing (emnlp),
pages 425   429, doha, qatar, october 2014.

[pust et al., 2015] michael pust, ulf hermjakob, kevin
knight, daniel marcu, and jonathan may. parsing english
into id15 using syntax-based
machine translation. in proceedings of the 2015 confer-
ence on empirical methods in natural language process-
ing, pages 1143   1154, lisbon, portugal, september 2015.
[riesa et al., 2011] jason riesa, ann irvine, and daniel
marcu. feature-rich language-independent syntax-based
alignment for id151. in proceed-
ings of the 2011 conference on empirical methods in
natural language processing, pages 497   507, edinburgh,
scotland, uk., july 2011.

[wang et al., 2015] chuan wang, nianwen xue, and sameer
pradhan. boosting transition-based amr parsing with re-
   ned actions and auxiliary analyzers. in proceedings of
the 53rd annual meeting of the association for computa-
tional linguistics and the 7th international joint confer-
ence on natural language processing (volume 2: short
papers), pages 857   862, beijing, china, july 2015.

[werling et al., 2015] keenon werling, gabor angeli, and
christopher d. manning. robust subgraph generation im-
proves id15 parsing.
in pro-
ceedings of the 53rd annual meeting of the association for
computational linguistics and the 7th international joint
conference on natural language processing (volume 1:
long papers), pages 982   991, beijing, china, july 2015.
[zhang et al., 2004] ying zhang, stephan vogel, and alex
waibel. interpreting id7/nist scores: how much improve-
ment do we need to have a better system? in proceedings
of the fourth international conference on language re-
sources and evaluation (lrec-2004), lisbon, portugal,
may 2004. acl anthology identi   er: l04-1489.

[zhou et al., 2016] junsheng zhou, feiyu xu, hans uszkor-
eit, weiguang qu, ran li, and yanhui gu. amr parsing
with an incremental joint model.
in proceedings of the
2016 conference on empirical methods in natural lan-
guage processing, pages 680   689, austin, texas, novem-
ber 2016.

