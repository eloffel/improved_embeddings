inducing domain-speci   c sentiment lexicons from unlabeled corpora

william l. hamilton, kevin clark, jure leskovec, dan jurafsky

department of computer science, stanford university, stanford ca, 94305

wleif,kevclark,jure,jurafsky@stanford.edu

6
1
0
2

 

p
e
s
4
2

 

 
 
]
l
c
.
s
c
[
 
 

2
v
0
2
8
2
0

.

6
0
6
1
:
v
i
x
r
a

abstract

a word   s sentiment depends on the domain in
which it is used. computational social science
research thus requires sentiment lexicons that
are speci   c to the domains being studied. we
combine domain-speci   c id27s
with a label propagation framework to in-
duce accurate domain-speci   c sentiment lex-
icons using small sets of seed words, achiev-
ing state-of-the-art performance competitive
with approaches that rely on hand-curated re-
sources. using our framework we perform
two large-scale empirical studies to quantify
the extent to which sentiment varies across
time and between communities. we induce
and release historical sentiment lexicons for
150 years of english and community-speci   c
sentiment lexicons for 250 online communi-
ties from the social media forum reddit. the
historical lexicons show that more than 5%
of sentiment-bearing (non-neutral) english
words completely switched polarity during the
last 150 years, and the community-speci   c
lexicons highlight how sentiment varies dras-
tically between different communities.

introduction

1
inducing domain-speci   c sentiment lexicons is cru-
cial to computational social science (css) research.
sentiment lexicons allow us to analyze key subjec-
tive properties of texts like opinions and attitudes
(taboada et al., 2011). but lexical sentiment is
hugely in   uenced by context. the word soft has a
very different sentiment in an online sports commu-
nity than it does in one dedicated to toy animals (fig-
ure 1). terri   c once had a highly negative conno-

figure 1: the sentiment of soft in different online commu-
nities. sentiment values computed using sentprop (section
3) on comments from reddit communities illustrate how sen-
timent depends on social context. bootstrap-sampled standard
deviations provide a measure of con   dence with the scores.

tation; now it is essentially synonymous with good
(figure 2). without domain-speci   c lexicons, social
scienti   c analyses can be misled by sentiment as-
signments biased towards domain-general contexts,
neglecting factors like genre, community-speci   c
vernacular, or demographic variation (deng et al.,
2014; hovy, 2015; yang and eisenstein, 2015).

using experts or id104 to construct
domain-speci   c sentiment
lexicons is expensive
and often time-consuming (mohammad and turney,
2010; fast et al., 2016), and is especially prob-
lematic when non-standard language (as in histori-
cal documents or obscure social media forums) pre-
vents annotators from understanding the sociolin-
guistic context of the data.

web-scale sentiment lexicons can be automat-
ically induced for large socially-diffuse domains,
such as the internet-at-large (velikovich et al., 2010)
or all of twitter (tang et al., 2014). however, to
study sentiment in domain-speci   c cases      nancial
documents, historical texts, or tight-knit social me-

r/sportsr/mylittlepony   6   4   20246sentimentofsoftdia forums   such generic lexicons may be inaccu-
rate, and even introduce harmful biases (loughran
and mcdonald, 2011).1 researchers need a princi-
pled and accurate framework for inducing lexicons
that are speci   c to their domain of study.

to meet these needs, we introduce sentprop, a
framework to learn accurate sentiment lexicons from
small sets of seed words and domain-speci   c cor-
pora. sentprop combines the well-known method
of label propagation with advances in word em-
beddings, and unlike previous approaches, is de-
signed to be accurate even when using modestly-
sized domain-speci   c corpora (   107 tokens). our
framework also provides con   dence scores along
with the learned lexicons, which allows researchers
to quantify uncertainty in a principled manner.

the key contributions of this work are:

1. a simple state-of-the-art sentiment induction al-
gorithm, combining high-quality word vector
embeddings with a label propagation approach.

2. a novel bootstrap-sampling framework for infer-
ring con   dence scores with the sentiment values.
3. two large-scale studies that reveal how sentiment

depends on both social and historical context.
(a) we induce community-speci   c sentiment
lexicons for the largest 250    subreddit    commu-
nities on the social-media forum reddit, reveal-
ing substantial variation in word sentiment be-
tween communities.
(b) we induce historical sentiment lexicons for
150 years of english, revealing that >5% of
words switched polarity during this time.

to the best of our knowledge, this is the    rst work
to systematically analyze the domain-dependency of
sentiment at a large-scale, across hundreds of years
and hundreds of user-de   ned online communities.

all of the inferred lexicons along with code for
sentprop and all methods evaluated are made
available in the socialsent package released with
this paper.2 the socialsent package provides a
benchmark toolkit for inducing sentiment lexicons,
including implementations of previously published
algorithms (velikovich et al., 2010; rothe et al.,
2016), which are not otherwise publicly available.

1

http://brandsavant.com/brandsavant/

the-hidden-bias-of-social-media-sentiment-analysis

2http://nlp.stanford.edu/projects/socialsent

figure 2: the sentiment of terri   c changed from negative to
positive over the last 150 years. sentiment values and boot-
strapped con   dences were computed using sentprop on his-
torical data (see section 6).

2 related work

our work builds upon a wealth of previous research
on inducing sentiment lexicons, along two threads:
corpus-based approaches use seed words and
patterns in unlabeled corpora to induce domain-
speci   c lexicons. these patterns may rely on syn-
tactic structures (hatzivassiloglou and mckeown,
1997; jijkoun et al., 2010; rooth et al., 1999; the-
len and riloff, 2002; widdows and dorow, 2002),
which can be domain-speci   c and brittle (e.g., in
social media lacking usual grammatical structures).
other models rely on general co-occurrence (igo
and riloff, 2009; riloff and shepherd, 1997; tur-
ney and littman, 2003). often corpus-based meth-
ods exploit distant-supervision signals (e.g., review
scores, emoticons) speci   c to certain domains (as-
ghar et al., 2015; blair-goldensohn et al., 2008;
bravo-marquez et al., 2015; choi and cardie, 2009;
severyn and moschitti, 2015; speriosu et al., 2011;
tang et al., 2014). an effective corpus-based ap-
proach that does not require distant-supervision   
which we adapt here   is to construct lexical graphs
using word co-occurrences and then to perform
some form of label propagation over these graphs
(huang et al., 2014; velikovich et al., 2010). re-
cent work has also learned transformations of word-
vector representations in order to induce sentiment
lexicons (rothe et al., 2016). fast et al. (2016) com-
bine word vectors with id104 to produce
domain-independent topic lexicons.

dictionary-based approaches use hand-curated
lexical
(fellbaum,
1998)   in order to propagate sentiment from seed

resources   usually id138

domain
standard
english
finance

twitter

positive seed words
good, lovely, excellent, fortunate, pleasant,
delightful, perfect, loved, love, happy
successful, excellent, pro   t, bene   cial, im-
proving, improved, success, gains, positive
love, loved, loves, awesome, nice, amazing,
best, fantastic, correct, happy

negative seed words
bad, horrible, poor, unfortunate, unpleasant,
disgusting, evil, hated, hate, unhappy
negligent, loss, volatile, wrong, losses, dam-
ages, bad, litigation, failure, down, negative
hate, hated, hates,
worst, horrible, wrong, sad

terrible, nasty, awful,

table 1: seed words. the seed words were manually selected to be context insensitive (without knowledge of the test lexicons).

labels (esuli and sebastiani, 2006; hu and liu,
2004; kamps et al., 2004; rao and ravichandran,
2009; san vicente et al., 2014; takamura et al.,
2005; tai and kao, 2013). there is an implicit con-
sensus that dictionary-based approaches will gener-
ate higher-quality lexicons, due to their use of these
clean, hand-curated resources; however, they are not
applicable in domains lacking such a resource (e.g.,
most historical texts).

most previous work seeks to enrich or enlarge ex-
isting lexicons (qiu et al., 2009; san vicente et al.,
2014; velikovich et al., 2010), emphasizing recall
over precision. this recall-oriented approach is mo-
tivated by the need for massive polarity lexicons in
tasks like web-advertising (velikovich et al., 2010).
in contrast to these previous efforts, the goal of this
work is to induce high-quality lexicons that are ac-
curate to a speci   c social context.

algorithmically, our approach is inspired by ve-
likovich et al. (2010). we extend velikovich
et al. (2010) by incorporating high-quality word
vector embeddings, a new graph construction ap-
proach, an alternative label propagation algorithm,
and a id64 method to obtain con   dence
values. together these improvements, especially
the high-quality word vectors, allow our corpus-
based method to even outperform the state-of-the-art
dictionary-based approach.
3 framework
our framework, sentprop, is designed to meet
four key desiderata:
1. resource-light: accurate performance without

massive corpora or hand-curated resources.

2. interpretable:

seed sets of
   paradigm    words to maintain interpretabil-
ity and avoid ambiguity in sentiment values.

small

uses

3. robust: bootstrap-sampled standard deviations

provide a measure of con   dence.

4. out-of-the-box: does not rely on signals that are

speci   c to only certain domains.
sentprop involves two steps: constructing a
lexical graph from unlabeled corpora and propagat-
ing sentiment labels over this graph.

3.1 constructing a lexical graph
lexical graphs are constructed from distributional
id27s learned on unlabeled corpora.

distributional id27s

the    rst step in our approach is to build high-
quality semantic representations for words using a
vector space model (vsm). we embed each word
wi     v as a vector wi that captures information
about its co-occurrence statistics with other words
(landauer and dumais, 1997; turney and pantel,
2010). this vsm approach has a long history in
nlp and has been highly successful in recent appli-
cations (see levy et al., 2015 for a survey).

when recreating known lexicons, we used a num-

ber of publicly available embeddings (section 4).

in the cases where we learned embeddings our-
selves, we employed an svd-based method to con-
struct the word-vectors. first, we construct a matrix

(cid:18)   p(wi, wj)
(cid:19)
mp p m i     r|v|  |v| with entries given by

(cid:26)

mp p m i

i,j

= max

log

(cid:27)

, 0

,

(1)

  p(w)  p(wj)

where   p denotes smoothed empirical probabilities of
word (co-)occurrences within    xed-size sliding win-
dows of text.3 mp p m i
is equal to a smoothed vari-
ant of the positive pointwise mutual information be-
tween words wi and wj (levy et al., 2015). next,
we compute mp p m i = u  v(cid:62), the truncated sin-
gular value decomposition of mp p m i. the vector

i,j

3we use contexts of size four on each side and context-

distribution smoothing with c = 0.75 (levy et al., 2015).

figure 3: visual summary of the sentprop algorithm.

embedding for word wi is then given by

wsvd

i = (u)i .

where d is a matrix with the column sums of e on
the diagonal. next, using t we iteratively update p
until numerical convergence:

(2)

excluding the singular value weights,   , has been
shown known to dramatically improve embedding
quality (turney and pantel, 2010; bullinaria and
levy, 2012). following standard practices, we learn
embeddings of dimension 300.

we found that this svd-based method signif-
icantly outperformed id97 (mikolov et al.,
2013) and glove (pennington et al., 2014) on pre-
liminary experiments with the domain-speci   c data
we used (see section 4).
de   ning the graph edges

given a set of id27s, a weighted lex-
ical graph is constructed by connecting each word
with its nearest k neighbors within the semantic
space (according to cosine-similarity). the weights
of the edges are set as

ei,j = arccos

   

.

(3)

3.2 propagating polarities from a seed set
once a weighted lexical graph is constructed, we
propagate sentiment labels over this graph using a
random walk method (zhou et al., 2004). a word   s
polarity score for a seed set is proportional to the
id203 of a random walk from the seed set hit-
ting that word (figure 3).

let p     r|v| be a vector of word-sentiment
scores constructed using seed set s (e.g., ten nega-
tive words); p is initialized to have 1|v| in all entries.
and let e be the matrix of edge weights given by
equation (3). first, we construct a symmetric tran-
sition matrix from e by computing t = d
2 ,

1
2 ed

1

(cid:18)

(cid:19)

(cid:62)wj
wi
(cid:107)wi(cid:107)(cid:107)wj(cid:107)

p(t+1) =   tp(t) + (1       )s,

(4)

where s is a vector with values set to 1|s| in the en-
tries corresponding to the seed set s and zeros else-
where. the    term controls the extent to which the
algorithm favors local consistency (similar labels for
neighbors) vs. global consistency (correct labels on
seed words), with lower   s emphasizing the latter.

to obtain a    nal polarity score for a word wi,
we run the walk using both positive and negative
seed sets, obtaining positive (pp (wi)) and nega-
tive (pn (wi)) label scores. we then combine these
values into a positive-polarity score as   pp (wi) =
pp (wi)+pn (wi) and standardize the    nal scores to
have zero mean and unit variance (within a corpus).

pp (wi)

3.3 sentprop variants
many variants of the random walk approach and re-
lated label propagation techniques exist in the lit-
erature (san vicente et al., 2014; velikovich et al.,
2010; zhou et al., 2004; zhu and ghahramani, 2002;
zhu et al., 2003). for example, there are differ-
ences in how to normalize the transition matrix in
the id93 (zhou et al., 2004) and variants
of label propagation, e.g. where the labeled seeds
are clamped to the correct values (zhu and ghahra-
mani, 2002) or where only shortest-paths through
the graph are used for propagation (velikovich et al.,
2010).

we experimented with a number of these ap-
proaches and found little difference in their perfor-
mance. we opted to use the random walk method
because it had a slight edge in terms of performance

a. run id93 from seed words.b. assign polarity scores based on frequency of random walk visits.lovehatedespiseadoreloathdislikelike   ndappreciateacknowledgesee+++idolizerelishabhornotice---execratedisapproveuncoverlovehatedespiseadoreloathdislikelike   ndappreciateacknowledgesee+++idolizerelishabhornotice---execratedisapproveuncover----------+++++++++in preliminary experiments4 and because it pro-
duces well-behaved distributions over label scores,
whereas zhu and ghahramani (2002)   s method and
its variants produce extremely peaked distributions.
we do note report in detail on all the label propa-
gation variants here, but the socialsent package
contains a full suite of these methods.

3.4 bootstrap-sampling for robustness
propagated sentiment scores are inevitably in   u-
enced by the seed set, and it is important for re-
searchers to know the extent to which polarity values
are simply the result of corpus artifacts that are cor-
related with these seeds words. we address this issue
by using a bootstrap-sampling approach to obtain
con   dence regions over our sentiment scores. we
bootstrap by running our propagation over b ran-
dom equally-sized subsets of the positive and neg-
ative seed sets. computing the standard deviation
of the bootstrap-sampled polarity scores provides a
measure of con   dence and allows the researcher to
evaluate the robustness of the assigned polarities.
we set b = 50 and used 7 words per random subset
(full seed sets are size 10; see table 1).

4 recreating known lexicons

we validate our approach by recreating known sen-
timent lexicons in the three domains: standard en-
glish, twitter, and finance. table 1 lists the seed
words used in each domain.

standard english: to facilitate comparison with
previous work, we focus on the well-known general
inquirer lexicon (stone et al., 1966). we also use the
continuous valence (i.e., polarity) scores collected
by warriner et al. (2013) in order to evaluate the
   ne-grained performance of our framework. we test
our framework   s performance using two different
embeddings: off-the-shelf google news embeddings
constructed from 1011 tokens5 and embeddings we
constructed from the 2000s decade of the corpus of
historical american english (coha), which con-
tains    2    107 words in each decade, from 1850
to 2000 (davies, 2010). the coha corpus allows
us to test how the algorithms deal with this smaller

4>2% improvement across metrics on the standard and his-

torical english datasets described in section 4.

5https://code.google.com/p/id97/

historical corpus, which is important since we will
use the coha corpus to infer historical sentiment
lexicons (section 6).

twitter: numerous works attempt

finance: previous work found that general pur-
pose sentiment lexicons performed very poorly on
   nancial text (loughran and mcdonald, 2011), so
a    nance-speci   c sentiment lexicon (containing bi-
nary labels) was hand-constructed for this domain
(ibid.). to test against this lexicon, we constructed
embeddings using a dataset of    2  107 tokens from
   nancial 8k documents (lee et al., 2014).
to induce
twitter-speci   c sentiment lexicons using supervised
approaches and features unique to that domain (e.g.,
follower graphs; speriosu et al., 2011). here, we
emphasize that we can induce an accurate lexicon
using a simple domain-independent and resource-
light approach, with the implication that lexicons
can easily be induced for related social media
domains without resorting to complex supervised
frameworks. we evaluate our approach using the
test set from the 2015 semeval task 10e competition
(rosenthal et al., 2015), and we use the embeddings
constructed by rothe et al. (2016).6

4.1 baselines and state-of-the-art comparisons
we compare sentprop against standard baselines
and state-of-the-art approaches. the pmi base-
line of turney and littman (2003) computes the
pointwise mutual information between the seeds and
the targets without using propagation. the base-
line method of velikovich et al. (2010) is simi-
lar to our method but uses an alternative propa-
gation approach and raw co-occurrence vectors in-
stead of learned embeddings. both these methods
require raw corpora, so they function as baselines
in cases where we do not use off-the-shelf embed-
dings. we also compare against densifier, a state-
of-the-art method that learns orthogonal transforma-
tions of word vectors instead of propagating labels
(rothe et al., 2016). lastly, on standard english we
compare against a state-of-the-art id138-based
method, which performs label propagation over a
id138-derived graph (san vicente et al., 2014).
several variant baselines, all of which sentprop

6the of   cial semeval task 10e involved fully-supervised

learning, so we do not use their evaluation setup.

method
sentprop
densifier
id138
majority

auc ternary f1
90.6
93.3
89.5

58.6
62.1
58.7
24.8

   

  
0.44
0.50
0.34

   

method
sentprop
densifier
sentiment140
majority

auc ternary f1
86.0
90.1
86.2

60.1
59.4
57.7
24.9

   

  
0.50
0.57
0.51

   

(a) corpus methods outperform id138 on standard
english. using word-vector embeddings learned on a mas-
sive corpus (1011 tokens), we see that both corpus-based
methods outperform the id138-based approach overall.

(b) corpus approaches are competitive with a distantly
supervised method on twitter. using twitter embeddings
learned from    109 tokens, we see that the semi-supervised
corpus approaches using small seed sets perform very well.

method
sentprop
densifier
pmi
velikovich et al. (2010)
majority

auc ternary f1
91.6
80.2
86.1
81.6

63.1
50.3
49.8
51.1
23.6

   

method
sentprop
densifier
pmi
velikovich et al. (2010)
majority

auc ternary f1
83.8
77.4
70.6
52.7

53.0
46.6
41.9
32.9
24.3

   

  
0.28
0.19
0.16
0.01

   

(c) sentprop performs best with domain-speci   c    nance
embeddings. using embeddings learned from    nancial cor-
pus (   2   107 tokens) , sentprop signi   cantly outperforms
the other methods.

(d) sentprop performs well on standard english even
with 1000x reduction in corpus size. sentprop maintains
strong performance even when using embeddings learned
from the 2000s decade of coha (only 2       107 tokens).

table 2: results on recreating known lexicons.

outperforms, are omitted for brevity (e.g., using
word-vector cosines in place of pmi in turney and
littman (2003)   s framework). code for all these
variants is available in the socialsent package.

4.2 evaluation setup
we evaluate the approaches according to (i) their
binary classi   cation accuracy (ignoring the neutral
class, as is common in previous work), (ii) ternary
classi   cation performance (positive vs. neutral vs.
negative)7, and (iii) kendall    rank-correlation with
continuous human-annotated polarity scores.

for all methods in the ternary-classi   cation con-
dition, we use the class-mass id172 method
(zhu et al., 2003) to label words as positive, neutral,
or negative. this method assumes knowledge of the
label distribution   i.e., how many positive/negative
vs. neutral words there are   and simply assigns la-
bels to best match this distribution.

4.3 evaluation results
tables 2a-2d summarize the performance of our
framework along with baselines and other state-of-

7only gi contains words explicitly marked neutral, so for
ternary evaluations in twitter and finance we sample neutral
words from gi to match its neutral-vs-not distribution.

the-art approaches. our framework signi   cantly
outperforms the baselines on all tasks, outperforms a
state-of-the-art approach that uses id138 on stan-
dard english (table 2a), and is competitive with
sentiment140 on twitter (table 2b), a distantly-
supervised approach that uses signals from emoti-
cons (mohammad and turney, 2010). densifier
also performs extremely well, outperforming sent-
prop when off-the-shelf embeddings are used (ta-
bles 2a and 2b). however, sentprop signi   cantly
outperforms all other approaches when using the
domain-speci   c embeddings (tables 2c and 2d).

overall our results show that sentprop    a rel-
atively simple method, which combines high-quality
word vectors embeddings with standard label prop-
agation     can perform at a state-of-the-art level,
even performing competitively with methods rely-
ing on hand-curated lexical graphs. unlike previous
published approaches, sentprop is able to main-
tain high accuracy even when modest-sized domain-
speci   c corpora are used. in cases where very large
corpora are available and where there is an abun-
dance of training data, densifier performs ex-
tremely well, since it was designed for this sort of
setting (rothe et al., 2016).

we found that the baseline method of velikovich
et al. (2010), which our method is closely related
to, performed relatively poorly with these domain-
speci   c corpora. this indicates that using high-
quality word-vector embeddings can have a drastic
impact on performance. however, it is worth noting
that velikovich et al. (2010)   s method was designed
for high recall with massive corpora, so its poor per-
formance in our regime is not surprising.

lastly, we found that the choice of embedding
method could have a drastic impact.
prelimi-
nary experiments on the coha data showed that
using id97 sgns vectors (with default set-
tings) instead of our svd-based embeddings led to
a >40% performance drop for sentprop across
all measures and a >10% performance drop for
densifier.
it is possible that certain settings of
id97 could perform better, but previous work
has shown that svd-based methods have superior
results on smaller datasets and rare-word similarity
tasks (levy et al., 2015; hamilton et al., 2016), so
this result is not surprising.

5

inducing community-speci   c lexicons

as a    rst large-scale study, we investigate how sen-
timent depends on the social context in which a
word is used.
it is well known that there is sub-
stantial sociolinguistic variation between different
communities, whether these communities are de-
   ned geographically (trudgill, 1974) or via under-
lying sociocultural differences (labov, 2006). how-
ever, no previous work has systematically investi-
gated community-speci   c variation in word senti-
ment at a large scale. yang and eisenstein (2015)
exploit social network structure in twitter to infer
a small number (1-10) of communities and analyzed
sentiment variation via a supervised framework. our
analysis extends this line of work by analyzing the
sentiment across hundreds of user-de   ned commu-
nities using only unlabeled corpora and a small set
of    paradigm    seed words (the twitter seed words
outlined in table 1).

in our study, we induced sentiment lexicons for
the top-250 (by comment-count) subreddits from the
social media forum reddit.8 we used all the 2014
comment data to induce the lexicons, with words

8subreddits are user-created topic-speci   c forums.

lower cased and comments from bots and deleted
users removed.9 sentiment was induced for the top-
5000 non-stop words in each subreddit (again, by
comment-frequency).

5.1 examining the lexicons
analysis of the learned lexicons reveals the ex-
tent
to which sentiment can differ across com-
munities. figure 4 highlights some words with
opposing sentiment
in
r/twoxchromosomes (r/twox), a community
dedicated to female perspectives and gender issues,
the words crazy and insane have negative polarity,
which is not true in the r/sports community, and,
vice-versa, words like soft are positive in r/twox
but negative in r/sports.

in two communities:

to get a sense of how much sentiment differs
across communities in general, we selected a ran-
dom subset of 1000 community pairs and examined
the correlation in their sentiment values for highly
sentiment-bearing words (figure 5). we see that the
distribution is noticeably skewed, with many com-
munity pairs having highly uncorrelated sentiment
values. the 1000 random pairs were selected such
that each member of the pair overlapped in at least
half of their top-5000 word vocabulary. we then
computed the correlation between the sentiments in
these community-pairs. since sentiment is noisy and
relatively uninteresting for neutral words, we com-
pute   25%, the kendall-   correlation over the top-
25% most sentiment bearing words shared between
the two communities.

analysis of individual pairs reveals some inter-
esting insights about sentiment and inter-community
dynamics. for example, we found that the sentiment
correlation between r/twox and r/theredpill
(  25% = 0.58), two communities that hold con-
   icting views and often attack each other10, was
actually higher than the sentiment correlation be-
tween r/twox and r/sports (  25% = 0.41), two
communities that are entirely unrelated. this re-
sult suggests that con   icting communities may have

https://archive.org/details/2015_reddit_comments_corpus

9
10this con   ict is well-known on reddit; for example, both
communities mention each others    names along with fuck-based
profanity in the same comment far more than one would expect
by chance (  2
1 > 6.8, p < 0.01 for both). r/theredpill is
dedicated to male empowerment.

figure 4: word sentiment differs drastically between a community dedicated to sports (r/sports) and one dedicated to
female perspectives and gender issues (r/twox). words like soft and animal have positive sentiment in r/twox but negative
sentiment in r/sports, while the opposite holds for words like crazy and insane.

historical text (piotrowski, 2012) which are inform-
ing diachronic linguistics (hamilton et al., 2016),
the digital humanities (muralidharan and hearst,
2012), and history (hendrickx et al., 2011).

our work is inspired by the only previous work
on automatically inducing historical sentiment lexi-
cons, cook and stevenson (2010); they use the pmi
method and a full modern sentiment lexicon as their
seed set, which relies on the assumption that all
these words have not changed in sentiment. in con-
trast, in addition to our different algorithm, we use a
small seed set of words that were manually selected
based on having strong and stable sentiment over the
last 150 years (table 1; con   rmed via historical en-
tries in the oxford english dictionary).

6.1 examining the lexicons
we constructed lexicons from coha, since it was
carefully constructed to be genre balanced (e.g.,
compared to the google id165s; pechenick et al.,
2015). we built lexicons for all adjectives with
counts above 100 in a given decade and also for the
top-5000 non-stop words within each year. in both
these cases we found that >5% of sentiment-bearing
(positive/negative) words completely switched po-
larity during this 150-year time-period and >25%
of all words changed their sentiment label (includ-
ing switches to/from neutral).11 the prevalence of

11we de   ned the thresholds for polar vs. neutral using the
class-mass id172 method and compared scores aver-

figure 5: there is a long tail of communities with very dif-
ferent word sentiments. some communities have very similar
sentiment (e.g., r/sports and r/hockey), while other com-
munity pairs differ drastically (e.g., r/sports and r/twox).

more similar sentiment in their language compared
to communities that are entirely unrelated.

6

inducing diachronic sentiment lexicons

sentiment also depends on the historical time-period
in which a word is used. to investigate this depen-
dency, we use our framework to analyze how word
polarities have shifted over the last 150 years. the
phenomena of amelioration (words becoming more
positive) and pejoration (words becoming more neg-
ative) are well-discussed in the linguistic literature
(traugott and dasher, 2001); however, no compre-
hensive polarity lexicons exist for historical data
(cook and stevenson, 2010). such lexicons are cru-
cial to the growing body of work on nlp analyses of

0.10.20.30.40.50.60.70.8community-communitysentimentcorrelation(  25%)0123456count(a) lean becomes more positive. lean underwent amelioration,
becoming more similar to muscular and less similar to weak.

(b) pathetic becomes more negative. pathetic underwent pejo-
ration, becoming similar to weak and less similar to passionate.

figure 6: examples of amelioration and pejoration.

full polarity switches highlights the importance of
historical sentiment lexicons for work on diachronic
linguistics and cultural change.

figure 6a shows an example amelioration de-
the word lean lost its neg-
tected by this method:
ative connotations associated with    weakness    and
instead became positively associated with concepts
like    muscularity    and       tness   . figure 6b shows
an example pejoration, where pathetic, which used
to be more synonymous with passionate, gained
stronger negative associations with the concepts
of    weakness    and    inadequacy    (simpson et al.,
1989).
in both these cases, semantic similarities
computed using our learned historical word vectors
were used to contextualize the shifts.

some other well-known examples of sentiment
changes captured by our framework include the se-
mantic bleaching of sorry, which shifted from nega-
tive and serious (   he was in a sorry state   ) to uses
as a neutral discourse marker (   sorry about that   )
and worldly, which used to have negative conno-
tations related to materialism and religious impu-
rity (   sinful worldly pursuits   ) but now is frequently
used to indicate sophistication (   a cultured, worldly
woman   ) (simpson et al., 1989). our hope is that
the full lexicons released with this work will spur
further examinations of such historical shifts in sen-
timent, while also facilitating css applications that
require sentiment ratings for historical text.

7 conclusion

sentprop allows researchers to easily induce ro-
bust and accurate sentiment lexicons that are rel-
aged over 1850-1880 to those averaged over 1970-2000.

evant to their particular domain of study. such
lexicons are crucial to css research, as evidenced
by our two studies showing that sentiment depends
strongly on both social and historical context.

our methodological comparisons show that sim-
ply combining label propagation with high-quality
word vector embeddings can achieve state-of-the-
art performance competitive with methods that rely
on hand-curated dictionaries, and the code pack-
age released with this work contains a full bench-
mark toolkit for this area, including implementations
of several variants of sentprop. we hope these
tools will facilitate future quantitative studies on the
domain-dependency of sentiment.

of course,

the sentiment lexicons induced by
sentprop are not perfect, which is re   ected in the
uncertainty associated with our bootstrap-sampled
estimates. however, we believe that these user-
constructed, domain-speci   c lexicons, which quan-
tify uncertainty, provide a more principled founda-
tion for css research compared to domain-general
sentiment lexicons that contain unknown biases.
in the future our method could also be integrated
with supervised domain-adaption (e.g.,yang and
eisenstein, 2015) to further improve these domain-
speci   c results.

acknowledgements

the authors thank p. liang for his helpful com-
ments. this research has been supported in part
by nsf cns-1010921, iis-1149837, iis-1514268
nih bd2k, aro muri, darpa xdata, darpa
simplex, stanford data science initiative, sap
stanford graduate fellowship, nserc pgs-d,
boeing, lightspeed, and volkswagen.

references
[asghar et al.2015] muhammad zubair asghar, au-
rangzeb khan, shakeel ahmad, imran ali khan,
and fazal masud kundi. 2015. a uni   ed frame-
work for creating domain dependent polarity lex-
icons from user generated reviews. plos one,
10(10):e0140204, october.

[blair-goldensohn et al.2008] sasha blair-goldensohn,
kerry hannan, ryan mcdonald, tyler neylon,
george a. reis, and jeff reynar. 2008. building a
sentiment summarizer for local service reviews.
in
www workshop on nlp in the information explosion
era.

[bravo-marquez et al.2015] felipe bravo-marquez, eibe
frank, and bernhard pfahringer. 2015. from unla-
belled tweets to twitter-speci   c opinion words.
in
sigir.

[bullinaria and levy2012] john a. bullinaria

and
joseph p. levy. 2012. extracting semantic represen-
tations from word co-occurrence statistics: stop-lists,
id30, and svd. behavior research methods,
44(3):890   907, september.

[choi and cardie2009] yejin choi and claire cardie.
2009. adapting a polarity lexicon using integer lin-
ear programming for domain-speci   c sentiment clas-
si   cation. in emnlp.

[cook and stevenson2010] paul cook

and suzanne
stevenson. 2010. automatically identifying changes
in the semantic orientation of words. in lrec.

[davies2010] mark davies. 2010. the corpus of histor-
ical american english: 400 million words, 1810-2009.
http://corpus.byu.edu/coha/.

[deng et al.2014] lingjia deng, janyce wiebe, and yoon-
jung choi. 2014. joint id136 and disambiguation
of implicit sentiments via implicature constraints. in
coling.

[esuli and sebastiani2006] andrea esuli and fabrizio se-
bastiani. 2006. sentiid138: a publicly available
lexical resource for opinion mining. in lrec.

[fast et al.2016] ethan fast, binbin chen, and michael s.
bernstein. 2016. empath: understanding topic sig-
nals in large-scale text. in chi.

[fellbaum1998] christiane fellbaum. 1998. id138.

wiley online library.

[hamilton et al.2016] william l. hamilton,

jure
leskovec, and dan jurafsky.
2016. diachronic
id27s reveal statistical laws of seman-
tic change. in acl.

[hatzivassiloglou and mckeown1997] vasileios hatzi-
1997.
in

vassiloglou and kathleen r. mckeown.
predicting the semantic orientation of adjectives.
eacl.

[hendrickx et al.2011] iris hendrickx, michel gnreux,
and rita marquilhas. 2011. automatic pragmatic
in language
text segmentation of historical letters.
technology for cultural heritage, pages 135   153.
springer.

[hovy2015] dirk hovy. 2015. demographic factors im-

prove classi   cation performance. in acl.

[hu and liu2004] minqing hu and bing liu. 2004. min-

ing and summarizing customer reviews. in kdd.

[huang et al.2014] sheng huang, zhendong niu, and
chongyang shi.
2014. automatic construction
of domain-speci   c sentiment lexicon based on con-
strained label propagation. knowledge-based sys-
tems, 56:191   200.

[igo and riloff2009] sean p. igo and ellen riloff. 2009.
corpus-based semantic lexicon induction with web-
based corroboration. in acl workshop on unsuper-
vised and minimally supervised learning of lexical
semantics.

[jijkoun et al.2010] valentin jijkoun, maarten de rijke,
and wouter weerkamp. 2010. generating focused
topic-speci   c sentiment lexicons. in acl.

[kamps et al.2004] jaap kamps, m. j. marx, robert j.
mokken, and m. de rijke. 2004. using id138 to
measure semantic orientations of adjectives. in lrec.
[labov2006] william labov. 2006. the social strati   ca-
tion of english in new york city. cambridge univer-
sity press.

[landauer and dumais1997] thomas k. landauer and
susan t. dumais. 1997. a solution to plato   s prob-
lem: the latent semantic analysis theory of acquisi-
tion, induction, and representation of knowledge. psy-
chol. rev., 104(2):211.

[lee et al.2014] heeyoung lee, mihai surdeanu, bill
maccartney, and dan jurafsky. 2014. on the impor-
tance of text analysis for stock price prediction. in
lrec.

[levy et al.2015] omer levy, yoav goldberg, and ido
dagan. 2015. improving distributional similarity with
lessons learned from id27s. trans. assoc.
comput. ling., 3.

[loughran and mcdonald2011] tim loughran and bill
mcdonald. 2011. when is a liability not a liability?
textual analysis, dictionaries, and 10-ks. the journal
of finance, 66(1):35   65.

[mikolov et al.2013] tomas mikolov, ilya sutskever, kai
chen, greg s. corrado, and jeff dean. 2013. dis-
tributed representations of words and phrases and their
compositionality. in nips.

[mohammad and turney2010] saif m. mohammad and
peter d. turney. 2010. emotions evoked by common
words and phrases: using mechanical turk to create
an emotion lexicon. in naacl.

[muralidharan and hearst2012] aditi muralidharan and
marti a hearst. 2012. supporting exploratory text
analysis in literature study. literary and linguistic
computing.

[pechenick et al.2015] eitan adam pechenick, christo-
pher m. danforth, and peter sheridan dodds. 2015.
characterizing the google books corpus: strong lim-
its to id136s of socio-cultural and linguistic evolu-
tion. plos one, 10(10).

[pennington et al.2014] jeffrey

richard
socher, and christopher d. manning. 2014. glove:
global vectors for word representation. in emnlp.

pennington,

[piotrowski2012] michael piotrowski. 2012. natural lan-
guage processing for historical texts. synthesis lec-
tures on human language technologies, 5(2):1   157.
[qiu et al.2009] guang qiu, bing liu, jiajun bu, and
chun chen. 2009. expanding domain sentiment
lexicon through double propagation. in ijcai.

[rao and ravichandran2009] delip rao and deepak
ravichandran. 2009. semi-supervised polarity lexi-
con induction. in eacl.

[riloff and shepherd1997] ellen riloff and jessica shep-
herd. 1997. a corpus-based approach for building
semantic lexicons. arxiv preprint cmp-lg/9706013.

[rooth et al.1999] mats rooth, stefan riezler, detlef
in-
prescher, glenn carroll, and franz beil. 1999.
ducing a semantically annotated lexicon via em-based
id91. in acl.

[rosenthal et al.2015] sara rosenthal, preslav nakov,
svetlana kiritchenko, saif m. mohammad, alan rit-
ter, and veselin stoyanov. 2015. semeval-2015 task
10: id31 in twitter. semeval-2015.

[rothe et al.2016] sascha rothe, sebastian ebert, and
hinrich schutze. 2016. ultradense id27s
by orthogonal transformation. in naacl-hlt.

[san vicente et al.2014] inaki san vicente, rodrigo
agerri, german rigau, and donostia-san sebastin.
2014.
simple, robust and (almost) unsupervised
generation of polarity lexicons for multiple lan-
guages. in eacl.

[severyn and moschitti2015] aliaksei

alessandro moschitti.
learning of sentiment lexicons. in naacl-hlt.

and
2015. on the automatic

severyn

[simpson et al.1989] john andrew simpson, edmund sc
weiner, et al. 1989. the oxford english dictionary,
volume 2. clarendon press oxford, oxford, uk.

[speriosu et al.2011] michael speriosu, nikita sudan, sid
upadhyay, and jason baldridge. 2011. twitter po-
larity classi   cation with label propagation over lexical
in acl workshop on
links and the follower graph.
unsupervised learning in nlp.

[stone et al.1966] philip j stone, dexter c dunphy, and
marshall s smith. 1966. the general inquirer: a
computer approach to content analysis.

[taboada et al.2011] maite taboada, julian brooke, mi-
lan to   loski, kimberly voll, and manfred stede.
2011. lexicon-based methods for id31.
comput. ling., 37(2):267   307.

[tai and kao2013] yen-jen tai and hung-yu kao. 2013.
automatic domain-speci   c sentiment lexicon genera-
tion with label propagation. in proceedings of inter-
national conference on information integration and
web-based applications & services, page 53. acm.

[takamura et al.2005] hiroya takamura, takashi inui,
and manabu okumura. 2005. extracting semantic ori-
entations of words using spin model. in acl.

[tang et al.2014] duyu tang, furu wei, bing qin, ming
zhou, and ting liu. 2014. building large-scale
twitter-speci   c sentiment lexicon: a representation
learning approach. in coling.

[thelen and riloff2002] michael thelen and ellen riloff.
2002. a id64 method for learning semantic
lexicons using extraction pattern contexts. in emnlp.
[traugott and dasher2001] elizabeth closs traugott and
2001. regularity in semantic
richard b dasher.
change. cambridge university press, cambridge,
uk.

[trudgill1974] peter trudgill. 1974. linguistic change
and diffusion: description and explanation in soci-
olinguistic dialect geography. language in society,
3(2):215   246.

[turney and littman2003] peter

and
michael l. littman.
2003. measuring praise
and criticism: id136 of semantic orientation from
association. acm trans. inf. sys., 21(4):315   346.

turney

d.

[turney and pantel2010] peter d. turney and patrick
pantel.
2010. from frequency to meaning: vec-
tor space models of semantics. j. artif. intell. res.,
37(1):141   188.

[velikovich et al.2010] leonid velikovich, sasha blair-
goldensohn, kerry hannan, and ryan mcdonald.
2010. the viability of web-derived polarity lexicons.
in naacl-hlt.

[warriner et al.2013] amy beth warriner, victor kuper-
man, and marc brysbaert. 2013. norms of valence,
arousal, and dominance for 13,915 english lemmas.
behavior research methods, 45(4):1191   1207.

[widdows and dorow2002] dominic widdows and beate
dorow. 2002. a graph model for unsupervised lexical
acquisition. in coling.

[yang and eisenstein2015] yi yang and jacob eisenstein.
2015. putting things in context: community-speci   c
embedding projections for id31. arxiv
preprint arxiv:1511.06052.

[zhou et al.2004] dengyong zhou, olivier bousquet,
thomas navin lal, jason weston, and bernhard
scholkopf. 2004. learning with local and global con-
sistency. in nips.

[zhu and ghahramani2002] xiaojin zhu and zoubin
ghahramani. 2002. learning from labeled and un-
labeled data with label propagation. technical report.
[zhu et al.2003] xiaojin zhu, zoubin ghahramani, john
lafferty, and others. 2003. semi-supervised learn-
ing using gaussian    elds and id94. in
icml.

