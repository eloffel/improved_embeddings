hyperlex: a large-scale evaluation of graded
lexical entailment

ivan vuli  c   
ltl, university of cambridge

daniela gerz   
ltl, university of cambridge

douwe kiela      
facebook ai research

anna korhonen   
ltl, university of cambridge

felix hill   
google deepmind

7
1
0
2

 

y
a
m
0
1

 

 
 
]
l
c
.
s
c
[
 
 

2
v
7
1
1
2
0

.

8
0
6
1
:
v
i
x
r
a

we introduce hyperlex - a dataset and evaluation resource that quanti   es the extent of of the semantic
category membership, that is, type-of relation also known as hyponymy-hypernymy or lexical entailment
(le) relation between 2,616 concept pairs. cognitive psychology research has established that typicality
and category/class membership are computed in human semantic memory as a gradual rather than
binary relation. nevertheless, most nlp research, and existing large-scale invetories of concept category
membership (id138, dbpedia, etc.) treat category membership and le as binary. to address this, we
asked hundreds of native english speakers to indicate typicality and strength of category membership
between a diverse range of concept pairs on a id104 platform. our results con   rm that category
membership and le are indeed more gradual than binary. we then compare these human judgements
with the predictions of automatic systems, which reveals a huge gap between human performance and
state-of-the-art le, distributional and representation learning models, and substantial differences between
the models themselves. we discuss a pathway for improving semantic models to overcome this discrepancy,
and indicate future application areas for improved graded le systems.

1. introduction

most native speakers of english, in almost all contexts and situations, would agree that dogs, cows,
or cats are animals, and that tables or pencils are not. however, for certain concepts, membership
of the animal category is less clear-cut. whether lexical concepts such as dinosaur, human being
or amoeba are considered animals seems to depend on the context in which such concepts are
described, the perspective of the speaker or listener and even the formal scienti   c knowledge of
the interlocutors. despite this indeterminacy, when communicating, humans intuitively reason
about such relations between concepts and categories (quillian 1967; collins and quillian 1969).
indeed, the ability to quickly perform id136 over such networks and arrive at coherent
id99s is crucial for human language understanding.

the princeton id138 lexical database (miller 1995; fellbaum 1998) is perhaps the best
known attempt to formally represent such a semantic network. in id138, concepts are

    language technology lab (ltl), department of theoretical and applied linguistics, university of cambridge, 9
west road, cb3 9dp cambridge, uk. e-mail: {iv250|dsg40|alk23}@cam.ac.uk
       facebook ai research, 770 broadway, ny 10003, new york city, ny, usa. e-mail: dkiela@fb.com
    google deepmind, 7 pancras square, london nc14ag, uk. e-mail: felixhill@google.com

organised in a hierarchical fashion, in an attempt to replicate observed aspects of human semantic
memory (collins and quillian 1972; beckwith et al. 1991). one of the fundamental relations
between concepts in id138 is the so-called type-of or hypernymy-hyponymy relation that
exists between category concepts such as animal and their constituent members such as cat or dog.
the type-of relation is particularly important in language understanding because it underlines
the lexical entailment (le) relation. simply put, an instantiation of a member concept such as
a cat entails the existence of an animal. this lexical entailment in turns governs many cases of
phrasal and sentential entailment: if we know that a cat is in the garden, we can quickly and
intuitively conclude that an animal is in the garden too.1

because of this fundamental connection to language understanding, the automatic detection
and modelling of lexical entailment has been an area of much focus in natural language
processing (bos and markert 2005; dagan, glickman, and magnini 2006; baroni et al. 2012;
beltagy et al. 2013, inter alia). the ability to effectively detect and model both lexical and phrasal
entailment in a human-like way may be critical for numerous related applications such as
id53, information retrieval, information extraction, and text summarisation and
generation (androutsopoulos and malakasiotis 2010). for instance, in order to answer a question
such as    which mammal has a strong bite?   , a question-answering system has to know that a jaguar
or a grizzly bear are types of mammals, while a crocodile or a piranha are not.

although inspired to some extent by theories of human semantic memory, large-scale inven-
tories of semantic concepts, such as id138, typically make many simplifying assumptions,
particularly regarding the nature of the type-of relation, and consequently the effect of le. in
id138, for instance, all semantic relations are represented in a binary way (i.e., concept x
entails y ) rather than gradual (e.g., x entails y to a certain degree). however, since at least the
pioneering experiments of prototypes (rosch 1973, 1975), it has been known that, for a given
semantic category, certain member concepts are consistently understood as more central to the
category than others (even when controlling for clearly confounding factors such as frequency)
(coleman and kay 1981; medin, altom, and murphy 1984; lakoff 1990; hampton 2007). in other
words, id138 and similar resources fail to capture the fact that category membership is a
gradual semantic phenomenon. this limitation of id138 also characterises much of the le
research in nlp, as we discuss later in sect. 3.

to address these limitations, the present work is concerned with graded lexical entailment: the
degree of the le relation between two concepts on a continuous scale. thanks to the availability
of id104 technology, we conduct a variant of the seminal behavioural data collection by
rosch (1973), but on a massive scale. to do so, we introduce the idea of graded or soft le, and
design a human rating task for (x, y ) concept pairs based on the following question: to what
degree is x a type of y?. we arrive at a data set with 2,616 concept pairs, each rated by at least
10 human raters, scored by the degree to which they exhibit typicality and semantic category
membership and, equivalently, le. using this dataset, hyperlex,2 we investigate two questions:

r

(q1) do we observe the same effects of typicality, graded membership and graded
lexical entailment in human judgements as observed by rosch? do humans
intuitively distinguish between central and non-central members of a
category/class? do humans distinguish between full and partial membership in a
class as discussed by kamp and partee (1995)?

1 due to dual and inconsistent use in prior work, in this work we use the term lexical entailment (le) in its stricter

de   nition: it refers precisely to the taxonomical hyponymy-hypernymy relation, also known as type-of, or is-a
relation. more details on the distinction between taxonomical and substitutable le are provided in sect. 2.

2 hyperlex is available online at: http://people.ds.cam.ac.uk/iv250/hyperlex.html

2

r

vuli  c et al.

hyperlex: a large-scale evaluation of graded lexical entailment

(q2) is the current le modeling and representation methodology as applied in nlp
research and technology suf   cient to accurately capture graded lexical entailment
automatically? what is the gap between current automatic systems and human
performance in the graded le task?

the article is structured as follows. we de   ne and discuss graded le in sect. 2. in sect. 3, we
survey benchmarking resources from the literature that pertain to semantic category membership,
le identi   cation or evaluation, and motivate the need for a new, more expressive resource. in
sect. 4, we describe the design and development of hyperlex, and outline the various semantic
dimensions (such as pos usage, hypernmy levels and concreteness levels) along which these
concept pairs are designed to vary.

this allows us to address q1 in sect. 5, where we present a series of qualitative analyses of
the data gathered and collated into hyperlex. high inter-annotator agreement scores (pairwise
and mean spearman   s    correlations around 0.85 on the entire dataset, similar correlations on
noun and verb subsets) indicate that participants found it unproblematic to rate consistently
the graded le relation for the full range of concepts. these analyses reveal that the data in
hyperlex enhances, rather than contradicts or undermines the information in id138, in the
sense that hypernymy-hyponymy pairs receive highest average ratings in hyperlex compared
to all other id138 relations. we also show that participants are able to capture the implicit
asymmetry of the graded le relation by examining ratings of (x, y ) and reversed (y, x) pairs.
most importantly, our analysis shows that the effects of typicality, vagueness, and gradual
nature of le are indeed captured in human judgements. for instance, graded le scores indicate
that humans rate concepts such as to talk or to speak as more typical instances of the class to
communicate than concepts such as to touch, or to pray.

in sect. 6 we then turn our attention to q2: we evaluate the performance of a wide range of
le detection or measurement approaches. this review covers: (i) distributional models relying
on the distributional inclusion hypothesis (geffet and dagan 2005; lenci and benotto 2012) and
semantic generality computations (santus et al. 2014), (ii) multi-modal approaches (kiela et
al. 2015), (iii) id138-based approaches (pedersen, patwardhan, and michelizzi 2004), (iv) a
selection of state-of-the-art recent id27s, some optimised for similarity on semantic
similarity data sets (mikolov et al. 2013b; levy and goldberg 2014; wieting et al. 2015, inter
alia), others developed to better capture the asymmetric le relation (vilnis and mccallum 2015;
vendrov et al. 2016). due to its size, and unlike other word pair scoring data sets such as siid113x-
999 or wordsim-353, in hyperlex we provide standard train/dev/test splits (both random and
lexical (levy et al. 2015; shwartz, goldberg, and dagan 2016)) so that hyperlex can be used
for supervised learning. we therefore evaluate several prominent supervised le architectures
(baroni et al. 2012; weeds et al. 2014; roller, erk, and boleda 2014, inter alia). although we
observe interesting differences in the models, our    ndings indicate clearly that none of the
currently available models or approaches accurately model the relation of graded le re   ected in
human subjects. this study therefore calls for new paradigms and solutions capable of capturing
the gradual nature of semantic relations such as hypernymy in hierarchical semantic networks.
in section 8, we turn to the future and discuss potential applications of the graded le concept
and hyperlex. we conclude in section 9 by summarising the key aspects of our contribution.
hyperlex offers robust, data-driven insight into how humans perceive the concepts of typicality
and graded membership within the graded le relation. we hope that this will in turn incentivise
research into language technology that both re   ects human semantic memory more faithfully
and interprets and models linguistic entailment more effectively.

3

(a) animal

(b) sport

(c) to move

figure 1
toy examples illustrating the    typicality    or centrality of various class instances x of the y classes (a)
animal, (b) sport, (c) (to) move.

2. graded lexical entailment

note on terminology. due to dual and inconsistent use in prior work, in this work we use the term
lexical entailment (le) in its stricter de   nition. it refers precisely to the taxonomical hyponymy-
hypernymy relation, also known as is-a, or type-of relation (hearst 1992; weeds, weir, and
mccarthy 2004; snow, jurafsky, and ng 2004; pantel and pennacchiotti 2006; do and roth 2010,
inter alia), e.g., snake is a type-of animal, computer is a type-of machine.

this is different from the de   nition used in (zhitomirsky-geffet and dagan 2009; kotlerman
et al. 2010; turney and mohammad 2015) as substitutable lexical entailment: this relation holds for
a pair of words (x, y ) if a possible meaning of one word (i.e., x) entails a meaning of the other,
and the entailing word can substitute the entailed one in some typical contexts. this de   nition
is looser and more general than the type-of de   nition, as it also encompasses other lexical
relations such as synonymy, metonymy, meronymy, etc.3

de   nitions. the classical de   nition of ungraded lexical entailment is as follows: given a concept
word pair (x, y ), y is a hypernym of x if and only if x is a type of y , or equivalently every x
is a y .4 on the other hand, graded lexical entailment de   nes the strength of the lexical entailment
relation between the two concepts. given the concept pair (x, y ) and the entailment strength s,
the triplet (x, y, s) de   nes to what degree y is a hypernym of x (i.e., to what degree x is a type of
y ), where the degree is quanti   ed by s, e.g., to what degree snake is a type-of animal.

it may be observed as approximate or soft entailment, a weaker form of the classical
entailment variant (esteva et al. 2012; bankova et al. 2016). by imposing a threshold thr on
s, all graded relations may be straightforwardly converted to discrete ungraded decisions.

(proto)typicality, graded membership, and graded le. the graded le relation as described by the
intuitive question    to what degree is x a type of y?    encompasses two distinct phenomena
described in cognitive science research (cf. (hampton 2007)). first, it can be seen as the measure
of typicality in graded cognitive categorisation (rosch 1973, 1975; medin, altom, and murphy
1984; lakoff 1990), where some instances of a category are more central than others, as illustrated

3 for instance, turney and mohammad (2015) argue that in the sentences jane dropped the glass and jane dropped

something fragile, the concept glass should entail fragile.

4 other variants of the same de   nition replace type-of with kind-of or instance-of.

4

catdogcowcalfyakdinosaursnakesnailduckostrichmongoosegandercrabhumanbasketballsoccerfootballrugbyhandballtennisbadmintonsquashchessboxingjudobaseballsoftballcricketwrestlingracquetballwalkruncrawljogsprintjumphopdriftamblecreepdragsaunterwhisktowspeedtrotvuli  c et al.

hyperlex: a large-scale evaluation of graded lexical entailment

in fig. 1(a)-fig. 1(c). it measures to what degree some class instance x is a prototypical example
of class/concept y . for instance, when humans are asked to give an example instance of the
concept sport, it turns out that football and basketball are more frequently cited than wrestling,
chess, softball, or racquetball. another viewpoint stresses that    prototypes serve as reference points
for the categorisation of not-so-clear instances    (taylor 2003). osherson and smith (1997) make
further developments to the theory of (proto)typicality by recognising that there exist concepts
   that lack prototypes while possessing degrees of exempli   cation   . they list the famous example
of the concept building without a clear prototype; however, people tend to agree that most banks
are more typical buildings than, say, barns or pile dwellings.

second, the graded le relation also arises when one asks about the applicability of concepts
to objects: the boundaries between a category and its instances are much more often fuzzy and
vague than it is unambiguous and clear-cut (kamp and partee 1995). in other words, the graded
membership (often termed vagueness) measures the graded applicability of a concept to different
instances, e.g., it is not clear to what extent different objects in our surroundings (e.g., tables,
pavements, washing machines, stairs, benches) could be considered members of the category chair
despite the fact that such objects can be used as    objects on which one can sit   .

the notions of typicality and graded membership are not limited to concrete or nominal
concepts, as similar gradience effects are detected for more complex and abstract concepts (e.g.,
   to what degree is thesis an instance/type of statement?   ) (coleman and kay 1981), or action
verbs (pulman 1983) and adjectives (dirven and taylor 1986).

in short, graded membership or vagueness quanti   es    whether or not and to what degree
an instance falls within a conceptual category    , while typicality re   ects    how representative an
exemplar is of a category    (hampton 2007). the subtle distinction between the two is discussed
and debated at length from the philosophical and psychological perspective (osherson and
smith 1981; kamp and partee 1995; osherson and smith 1997; hampton 2006, 2007; blutner,
pothos, and bruza 2013; decock and douven 2014). in our id104 study with non-expert
workers, we have deliberately avoided any explicit differentiation between the two phenomena
captured by the same intuitive    to-what-degree    question, reducing the complexity of the study
design and allowing for their free variance in the collected data in terms of their quantity and
representative concept pairs. in addition, the distinction is often not evident for verb concepts.
we leave further developments with respect to the two related phenomena of typicality and
vagueness for future work, and refer the interested reader to the aforementioned literature.

relation to relational similarity. a strand of related research on relational similarity (turney 2006;
jurgens et al. 2012) also attempts to assign the score s to a pair of concepts (x, y ). note that there
exists a fundamental difference between relational similarity and graded lexical entailment. in the
latter, s refers to the degree of the le relation in the (x, y ) pair, that is, to the levels of typicality
and graded membership of the instance x for the class y , while the former quanti   es the
typicality of the pair (x, y ) for some    xed lexical relation class r (bejar, chaf   n, and embretson
1991; vylomova et al. 2016), e.g., to what degree the pair (snake, animal) re   ects a typical le
relation or a typical synonymy relation.5

graded le vs. semantic similarity. a plethora of current evaluations in nlp and representation
learning almost exclusively focus on semantic similarity and relatedness. semantic similarity
as quanti   ed by e.g. siid113x-999 or simverb-3500 (gerz et al. 2016) may be rede   ned as graded
synonymy relation. the graded scores there, in fact, refer to the strength of the synonymy relation

5 for instance, given the lexical relation classi   cation scheme of bejar et al. (1991), le or class-inclusion is only one

of the 10 high-level relation classes.

5

between any pair of concepts (x, y ). one could say that semantic similarity aims to answer the
question to what degree x and y are similar.6 therefore, an analogy between previously annotated
semantic similarity data sets and our objective to construct a graded le data set may be utilised
to introduce the graded le task and facilitate the construction of hyperlex.

3. design motivation

3.1 lexical entailment evaluations in nlp

since the work in nlp and human language understanding focuses on the ungraded version
of the le relation, we brie   y survey main ungraded le evaluation protocols in sect. 3.1.1,
followed by an overview of benchmarking le evaluation sets in sect. 3.1.2. we show that none
of the existing evaluation protocols coupled with existing evaluation sets enables a satisfactory
evaluation of the capability of statistical models to capture graded le. as opposed to existing
evaluation sets, by collecting human judgements through a id104 study our new
hyperlex evaluation set also enables qualitative linguistic analysis on how humans perceive
and rate graded lexical entailment.

3.1.1 evaluation protocols. evaluation protocols for the lexical entailment or type-of relation in
nlp, based on the classical de   nition of ungraded le, may be roughly clustered as follows:

(i) entailment directionality. given two words (x, y ) that are known to stand in a lexical
entailment relation, the system has to predict the relation directionality, that is, which word is the
hypernym and which word is the hyponym. more formally, the following mapping is de   ned by
the directionality function fdir:

fdir : (x, y )     {   1, 1}

(1)

fdir simply maps to 1 when y is the hypernym, and to    1 otherwise.
(ii) entailment detection. the system has to predict whether there exists a lexical entailment relation
between two words, or the words stand in some other relation, e.g., synonymy, meronymy-
holonymy, causality, no relation, see (hendrickx et al. 2010; jurgens et al. 2012; vylomova et al.
2016) for a more detailed overview of lexical relations. the following mapping is de   ned by the
detection function fdet:

fdet simply maps to 1 when (x, y ) stand in a lexical entailment relation, irrespective to the actual
directionality of the relation, and to 0 otherwise.

fdet : (x, y )     {0, 1}

(2)

(iii) entailment detection and directionality. this recently proposed evaluation protocol (weeds et
al. 2014; kiela et al. 2015) combines (i) and (ii). the system    rst has to detect whether there exists
a lexical entailment relation between two words (x, y ), and then, if the relation holds, it has to

6 from the siid113x-999 guidelines:    two words are syonymys if they have very similar meanings. synonyms represent

the same type or category (...) you are asked to compare word pairs and to rate how similar they are...    synonymy
and le capture different aspects of meaning regarding semantic hierarchies/taxonomies: e.g., while the pair (mouse,
rat) receives a score of 7.78 in siid113x-999 (on the scale 0-10), the same pair has a graded le score of 2.22 in hyperlex.

6

vuli  c et al.

hyperlex: a large-scale evaluation of graded lexical entailment

predict its directionality, i.e., the correct hypernym. the following mapping is de   ned by the
joint detection and directionality function fdet+dir:

fdet+dir : (x, y )     {   1, 0, 1}

(3)

fdet+dir maps to 1 when (x, y ) stand in a lexical entailment relation and y is the hypernym, to
   1 if x is the hypernym, and to 0 if x and y stand in some other lexical relation or no relation.
standard modeling approaches. these decisions are typically based on the distributional inclusion
hypothesis (geffet and dagan 2005) or a measure of lexical generality (herbelot and ganesalingam
2013). the intuition supporting the former is that the class (i.e., extension) denoted by a hyponym
is included in the class denoted by the hypernym, and therefore hyponyms are expected to occur
in a subset of the contexts of their hypernyms. the intuition supporting the latter hints that
typical characteristics constituting the intension (i.e., concept) expressed by a hypernym (e.g.,
move or eat for the concept word animal) are semantically more general than the characteristics
forming the intension7 of its hyponyms (e.g., bark or has tail for the concept word dog). in other
words, superordinate concepts such as animal or appliance are semantically less informative than
their hyponyms (murphy 2003), which is also re   ected in less speci   c contexts for hypernyms.
unsupervised (distributional) models of lexical entailment were instigated by the early work
of hearst (1992) on prototypicality patterns (e.g., the pattern    x such as y    indicates that y
is a hyponym of x). the current unsupervised models typically replace the symmetric cosine
similarity measure which works well for semantic similarity computations (bullinaria and levy
2007; mikolov et al. 2013a) with an asymmetric similarity measure optimised for entailment
(weeds, weir, and mccarthy 2004; clarke 2009; kotlerman et al. 2010; lenci and benotto 2012;
herbelot and ganesalingam 2013; santus et al. 2014).

supervised models, on the other hand, attempt to learn the asymmetric operator from a
training set, differing mostly in the feature selection to represent each candidate pair of words
(baroni et al. 2012; fu et al. 2014; rimell 2014; weeds et al. 2014; roller, erk, and boleda 2014;
fu et al. 2015; shwartz, goldberg, and dagan 2016; roller and erk 2016).8 an overview of the
supervised techniques also discussing their main shortcomings is provided by levy et al. (2015),
while a thorough discussion of differences between unsupervised and supervised entailment
models is provided by turney and mohammad (2015).

why is hyperlex different?. in short, regardless of the chosen methodology, the evaluation
protocols (directionality or detection) may be straightforwardly translated into binary decision
problems: (1) distinguishing between hypernyms and hyponyms, (2) distinguishing between
lexical entailment and other relations.

hyperlex, on the other hand, targets a different type of evaluation. the graded entailment

function fgraded de   nes the following mapping:

fgraded : (x, y )     r+

0

(4)

fgraded outputs the strength of the lexical entailment relation s     r+
0 .
by adopting the graded le paradigm, hyperlex thus measures the degree of lexical
entailment between words x and y constituting the order-sensitive pair (x, y ). from another

7 the terms intension and extension assume classical intensional and extensional de   nitions of a concept, e.g., (van

benthem and ter meulen 1996; baronett 2012).
8 typical choices are feature vector concatenation ( (cid:126)x     (cid:126)y ), difference ((cid:126)y     (cid:126)x), or element-wise multiplication
( (cid:126)x (cid:12) (cid:126)y ) where (cid:126)x and (cid:126)y are feature vectors of concepts x and y.

7

variant

bless

wbless

bibless

pair

(cat, animal)
(cat, animal)
(cat, monkey)
(animal, cat)
(cat, animal)
(cat, monkey)
(animal, cat)

annotation

1
1
0
0
1
0
-1

table 1
example pairs from bless dataset variants.

perspective, it measures the typicality and graded membership of the instance x for the
class/category y . from the relational similarity viewpoint (turney 2006; jurgens et al. 2012;
zhila et al. 2013), it also measures the prototypicality of the pair (x, y ) for the le relation.

3.1.2 evaluation sets.

bless. introduced by baroni and lenci (2011), the original bless evaluation set includes 200
concrete english nouns as target concepts (i.e., x-s from the pairs (x, y )), equally divided
between animate and inanimate entities. 175 concepts were extracted from the mcrae feature
norms dataset (mcrae et al. 2005), while the remaining 25 were selected manually by the authors.
these concepts were then paired to 8,625 different relatums (i.e., y -s) yielding a total of 26,554
(x, y ) pairs, where 14,440 contain a meaningful lexical relation and 12,154 are paired randomly.
the lexical relations represented in bless are lexical entailment, co-hyponymy, meronymy,
attribute, event, and random/no relation.

the use of its hyponymy-hypernymy/le subset of 1,337 (x, y ) pairs is then twofold. first,
for directionality evaluations (santus et al. 2014; kiela et al. 2015), only the le subset is used.
note that original bless data is always presented with the hyponym    rst, so gold annotations
are implicitly provided here. second, for detection evaluations (santus et al. 2014; roller, erk,
and boleda 2014; levy et al. 2015), the pairs from the le subset are taken as positive pairs, while
all the remaining pairs are considered negative pairs. that way, the evaluation data effectively
measures a model   s ability to predict the positive le relation. another evaluation dataset based
on bless was introduced by santus et al. (2015). following the standard annotation scheme, it
comprises 7,429 noun pairs in total, and 1,880 pairs le pairs in particular, covering a wider range
of relations than bless (i.e., the dataset now includes synonymy and antonymy pairs).

adaptations of the original bless evaluation set were proposed recently. first, relying on its
le subset, weeds et al. (2014) created another dataset called wbless (kiela et al. 2015) consisting
of 1,976 concept pairs in total. only (x, y ) pairs where y is the hypernym are annotated as
positive examples. it also contains reversed le pairs (i.e., x is the hypernym), cohyponymy
pairs, meronymy-holonymy pairs and randomly matched nouns balanced across different lexical
relations, all are annotated as negative examples. due to its construction, wbless is used solely
for experiments on le detection. weeds et al. (2014) created another dataset in a similar fashion,
consisting of 5,835 noun pairs, targeting co-hyponymy detection.

for the combined detection and directionality evaluation, a variant evaluation set called
bibless was proposed (kiela et al. 2015). it is built on wbless, but now explicitly distinguishes
direction in le pairs. examples of concept pairs in all bless variants can be found in tab. 1. a
majority of alternative ungraded le evaluation sets brie   y discussed here have a structure very
similar to bless and its variants.

8

vuli  c et al.

hyperlex: a large-scale evaluation of graded lexical entailment

resource

id138
wikidata
dbpedia
yago

relation

instance hypernym, hypernym
subclass of, instance of
type
subclass of

table 2
indicators of le/hypernymy relation in structured semantic resources.

kotlerman et al. (2010). based on the original dataset of (zhitomirsky-geffet and dagan 2009),
this evaluation set (kotlerman et al. 2010) contains 3,772 word pairs in total. the structure is
similar to bless: 1,068 pairs are labeled as positive examples (i.e., 1 or entails iff x entails y ),
and 2,704 labeled as negative examples, including the reversed positive pairs. the assignment of
binary labels is described in detail by (zhitomirsky-geffet and dagan 2009). the class sizes are
not balanced, and due to its design, although each pair is unique, 30 high-frequent nouns occur
in each pair in the dataset. note that this dataset has been annotated according to the broader
de   nition of substitutable le, see sect. 2.

baroni et al. (2012). the n1 (cid:15) n2 evaluation set contains 2,770 nominal concept pairs, with 1,385
pairs labeled as positive examples (i.e., 1 or entails) (baroni et al. 2012). the remaining 1,385
pairs labeled as negatives were created by inverting the positive pairs and randomly matching
concepts from the positive pairs. the pairs and annotations were extracted automatically from
id138 and then validated manually by the authors, e.g., the abstract concepts with a large
number of hyponyms such as entity or object were removed from the pool of concepts).

levy et al. (2014). a similar dataset for the standard le evaluation may be extracted from manually
annotated entailment graphs of subject-verb-object tuples (i.e., propositions) (levy, dagan, and
goldberger 2014): noun les were extracted from entailing tuples that were identical except for
one of the arguments, thus propagating the proposition-level entailment to the word level. this
data set was built for the medical domain and adopts the looser de   nition of substitutable le.

custom evaluation sets. a plethora of relevant work on ungraded le do not rely on established
evaluation resources, but simply extract ad-hoc le evaluation data using distant supervision
from readily available semantic resources and knowledge bases such as id138 (miller 1995),
dbpedia (auer et al. 2007), (tanon et al. 2016), yago (suchanek, kasneci, and weikum 2007), or
dictionaries (gheorghita and pierrel 2012). although plenty of the custom evaluation sets are
available online, there is a clear tendency to construct a new custom dataset in every subsequent
paper which uses the same evaluation protocol for ungraded le.

a standard practice (snow, jurafsky, and ng 2004, 2006; bordes et al. 2011; riedel et al. 2013;
socher et al. 2013; weeds et al. 2014; vendrov et al. 2016; shwartz, goldberg, and dagan 2016,
inter alia) is to extract positive and negative pairs by coupling concepts that are directly related
in at least one of the resources. only pairs standing in an unambiguous hypernymy/le relation,
according to the set of indicators from tab. 2, are annotated as positive examples (i.e., again 1
or entailing, tab. 1) (shwartz et al. 2015). all other pairs standing in other relations are taken as
negative instances. using related rather than random concept pairs as negative instances enables
detection experiments. we adopt a similar construction principle regarding wide coverage of
different lexical relations in hyperlex. this decision will support a variety of interesting analyses
related to graded le and other relations.

9

jurgens et al. (2012). finally, the evaluation resource most similar in spirit to hyperlex is the
dataset of jurgens et al. (2012) (https://sites.google.com/site/semeval2012task2/) created for measuring
degrees of relational similarity. it contains 3,218 word pairs labelled with 79 types of lexical
relations from the bejar et al.   s (1991) relation classi   cation scheme.

the dataset was constructed using two phases of id104. first, for each of the
79 subcategories, human subjects were shown paradigmatic examples of word pairs in the
given subcategory. they were then asked to generate more pairs of the same semantic relation
type. second, for each of the 79 subcategories, other subjects were shown word pairs that were
generated in the    rst phase, and they were asked to rate the pairs according to their degree of
prototypicality for the given semantic relation type. this is different from hyperlex where all
word pairs, regardless of their actual relation, were scored according to the degree of lexical
entailment between them.

the bejar et al.   s hierarchical classi   cation system contains ten high-level categories, with
   ve to ten subcategories each. only one high-level category, class-inclusion refers to the
true relation of ungraded le or hypernymy-hyponymy, and the scores in the data set do not
re   ect graded le. the data set aims at a wide coverage of different    ne-grained relations: it
comprises a small sample of manually generated instances (e.g., the number of distinct pairs for
the class-inclusion class is 200) for each relation scored according to their prototypicality
only for that particular relation. for more details concerning the construction of the evaluation
set, we refer the reader to the original work. also, for details on how to convert the dataset to an
evaluation resource for substitutable le, we refer the reader to (turney and mohammad 2015).

hyperlex: a short summary of motivation. the usefulness of these evaluation sets is evident from
their wide usage in the le literature over recent years: they helped to guide the development
of semantic research focussed on taxonomical relations. however, none of the evaluation sets
contains graded le ratings. therefore, hyperlex may be considered as a more informative data
collection: it enables a new evaluation protocol focussed on gradience of the type-of relation
rooted in cognitive science (hampton 2007). as discussed in sect. 2, graded annotations from
hyperlex may be easily converted to ungraded annotations: hyperlex may also be used in
the standard format of previous le evaluation sets (see tab. 1) for detection and directionality
evaluation protocols (see later in sect. 7.2).

second, a typical way to evaluate word representation quality at present is by judging the
similarity of representations assigned to similar words. the most popular semantic similarity
evaluation sets such as siid113x-999 or simverb-3500 consist of word pairs with similarity ratings
produced by human annotators. hyperlex is the    rst resource that can be used for the intrinsic
evaluation (schnabel et al. 2015; faruqui et al. 2016) of le-based vector space models (vendrov et
al. 2016), see later in sect. 6.6. encouraged by high inter annotator agreement scores and evident
large gaps between the human and system performance (see sect. 7), we believe that hyperlex
will guide the development of a new generation of representation-learning architectures that
induce hypernymy/le-specialised word representations, as opposed to nowadays ubiquitous
word representations targeting exclusively semantic similarity and/or relatedness (see later the
discussion in sect. 7.4 and sect. 8).

finally, hyperlex provides a wide coverage of different semantic phenomena related to
le: graded membership vs typicality (see sect. 2), entailment depths, concreteness levels, word
classes (nouns and verbs), word pairs standing in other lexical relations, etc. besides its primary
purpose as an evaluation set, such a large-scale and diverse crowdsourced semantic resource
(2,616 pairs in total!) enables novel linguistic and cognitive science analyses regarding human
typicality and vagueness judgments, as well as taxonomic relationships (discussed in sect. 5).

10

vuli  c et al.

hyperlex: a large-scale evaluation of graded lexical entailment

pair

chemistry / science
motorcycle / vehicle
pistol / weapon
to ponder / to think
to scribble / to write
gate / door
thesis / statement
to overwhelm / to defeat
shore / beach
vehicle / motorcycle
enemy / crocodile
ear / head

hyperlex le rating

10.0
9.85
9.62
9.40
8.18
6.53
6.17
4.75
3.33
1.09
0.33
0.00

table 3
example word pairs from hyperlex. the order of words in each pair is    xed, e.g., the pair chemistry /
science should be read as    is chemistry a type of science?   

4. the hyperlex data set

construction criteria. hill, reichart, and korhonen (2015) argue that comprehensive high-quality
evaluation resources have to satisfy the following three criteria:
(c1) representative: the resource covers the full range of concepts occurring in natural language.
(c2) clearly de   ned: a clear understanding is needed of what exactly the gold standard measures,
that is, the data set has to precisely de   ne the annotated relation, e.g., relatedness as with
wordsim-353, similarity as with siid113x-999, or in this case graded lexical entailment.
(c3) consistent and reliable: untrained native speakers must be able to quantify the target relation
consistently relying on simple instructions.

the choice of word pairs and construction of the evaluation set were steered by the
requirements. the criterion c1 was satis   ed by sampling a suf   cient number of pairs from
the university of southern florida (usf) norms data set (nelson, mcevoy, and schreiber 2004).
as shown in prior work (hill, reichart, and korhonen 2015), the usf data set provides an
excellent range of different semantic relations (e.g., synonyms vs hypernyms vs meronyms vs
cohyponyms) and semantic phenomena (e.g., it contains concrete vs abstract word pairs, noun
pairs vs verb pairs). this, in turn, guarantees a wide coverage of distinct semantic phenomena in
hyperlex. we discuss usf and the choice of concept words in more detail in sect. 4.1.

c2-c3 were satis   ed in hyperlex by providing clear and precise annotation guidelines
which accurately outline the lexical entailment relation and its graded variant in terms of the
synonymous de   nition based on the type-of relationship (fromkin, rodman, and hyams
2013) for average native speakers of english without any linguistic background. we discuss the
annotation guidelines and questionnaire structure in sect. 4.3 and sect. 4.4.

final output. the hyperlex evaluation set contains noun pairs (2,163 pairs) and verb pairs (453
pairs) annotated for the strength of the lexical entailment relation between the words in each
pair. since the le relation is asymmetric and the score always quanti   es to what degree x is a
type of y , pairs (x, y ) and (y, x) are considered distinct pairs. each concept pair is rated by at
least 10 human raters. the rating scale goes from 0 (no type-of relationship at all) to 10 (perfect
type-of relationship). several examples from hyperlex are provided in tab. 3.

in its 2,616 word pairs, hyperlex contains 1,843 distinct noun types and 392 distinct verb
types. in comparison, siid113x-999 as the standard crowdsourced evaluation benchmark for
representation learning architectures focused on the synonymy relation contains 751 distinct
nouns and 170 verbs in its 999 word pairs. in another comparison, the le benchmark bless

11

(see sect. 3.1.2) contains relations where one of the words in each pair comes from the set of 200
distinct concrete noun types.

4.1 choice of concepts

sources: usf and id138. to ensure a wide coverage of a variety semantic phenomena (c1), the
choice of candidate pairs is steered by two standard semantic resources available online: (1) the
usf norms data set9 (nelson, mcevoy, and schreiber 2004), and (2) id13810 (miller 1995).

usf was used as the primary source of concept pairs. it is a large database of free association
data collected for english, generated by presenting human subjects with one of 5, 000 cue
concepts and asking them to write the    rst word coming to mind that is associated with that
concept. each cue concept c was normed in this way by over 10 participants, resulting in a set of
associates a for each cue, for a total of over 72, 000 (c, a) pairs. for each such pair, the proportion
of participants who produced associate a when presented with cue c can be used as a proxy for
the strength of association between the two words.

the norming process guarantees that two words in a pair have a degree of semantic
association which correlates well with semantic relatedness re   ected in different lexical relations
between words in the pairs. inspecting the pairs manually revealed a good range of semantic
relationship values represented, e.g., there were examples of ungraded le pairs (car / vehicle,
biology / science), cohyponym pairs (peach / pear), synonyms or near-synonyms (foe / enemy),
meronym-holonym pairs (heel / boot), and antonym pairs (peace / war). usf also covers different
pos categories: nouns (winter / summer), verbs (to elect / to select), and adjectives (white / gray), at
the same time spanning word pairs at different levels of concreteness (panther / cat vs wave / motion
vs hobby / interest). the rich annotations of the usf data (e.g., concreteness scores, association
strength) can be combined with graded le scores to yield additional analyses and insight.

id138 was used to automatically assign a    ne-grained lexical relation to each pair in the
pool of candidates, which helped to guide the sampling process to ensure a wide coverage of
word pairs standing in a variety of lexical relations (shwartz, goldberg, and dagan 2016).

lexical relations. to guarantee the coverage of a wide range of semantic phenomena, we have
conditioned the cohort/pool used for sampling on the lexical relation between the words in
each pair. as mentioned above, the information was extracted from id138. we consider the
following lexical relations in hyperlex:
(1) hyp-n: (x, y ) pairs where x is a hyponym of y according to id138. n denotes the path
length between the two concepts in the id138 hierarchy, e.g., the pair cathedral / building is
assigned the hyp-3 relation. due to unavailability of a suf   cient number of pairs for longer
paths, we have grouped all pairs with the path length     4 into a single relation class hyp   4.
it was shown that pairs that are separated by fewer levels in the id138 hierarchy are both
more strongly associated and rated as more similar (hill, reichart, and korhonen 2015). this
   ne-grained division over different le levels will enable analyses based on the semantic distance
in a concept hierarchy.
(2) rhyp-n: the same as hyp-n, now with the order reversed: x is now a hypernym of y .
such pairs were included to investigate the inherent asymmetry of the type-of relation and how
human subjects perceive it.

9 http://w3.usf.edu/freeassociation/
10 https://id138.princeton.edu/

12

vuli  c et al.

hyperlex: a large-scale evaluation of graded lexical entailment

(3) cohyp: x and y are two instances of the same implicit category, that is, they share a hypernym
(e.g., dog and elephant are instances of the category animal). for simplicity, we retain only (x, y )
pairs that share a direct hypernym.
(4) mero: it denotes the part-whole relation, where x always refer to the meronym (i.e., part),
and y to the holonym (i.e., whole):    nger / hand, letter / alphabet. by its de   nition, this relation is
observed only between nominal concepts.
(5) syn: x and y are synonyms and near-synonyms, e.g., movement / motion, attorney / lawyer. in
case of polysemous concepts, at least one sense has to be synonymous with a meaning of the
other concept, e.g., author / writer.
(6) ant: x and y are antonyms, e.g., beginning / end, day / night, to unite / to divide.
(7) no-rel: x and y do not stand in any lexical relation, including the ones not present in
hyperlex (e.g., causal relations, space-time relations), and are also not semantically related. this
relation speci   es that there is no apparent semantic connection between the two concepts at all,
e.g., chimney / swan, nun / softball.

pos category. hyperlex includes subsets of pairs from two principle meaning-bearing pos
categories: nouns and verbs.11 this decision will enable    ner-grained analyses based on the two
main pos categories. it is further supported by recent research in id65
showcasing that different word classes (e.g., nouns vs verbs) require different modeling
approaches and distributional information to reach per-class peak performances (schwartz,
reichart, and rappoport 2015). in addition, we expect verbs to have fuzzier category borders
due to their high variability and polysemy, increased abstractness, and a wide range of syntactic-
semantic behaviour (jackendoff 1972; levin 1993; gerz et al. 2016).

pools of candidate concept pairs. the initial pools for sampling were selected as follows. first,
we extracted all possible noun pairs (n / n) and verb pairs (v / v) from usf based on the
associated pos tags available as part of usf annotations. concept pairs of other and mixed
pos (e.g., puzzle / solve, meet / acquaintance) were excluded from the pool of candidate pairs.12 to
ensure that semantic association between concepts in a pair is not accidental, we then discarded
all such usf pairs that had been generated by two or fewer participants in the original usf
experiments.13 we also excluded all concept pairs containing a multi-word expression (e.g., put
down / insult, stress / heart attack), pairs containing a named entity (e.g., europe / continent), and
pairs containing a potentially offensive concept (e.g., weed / pot, heroin / drug).14

all remaining concept pairs were then assigned a lexical relation according to id138. in
case of duplicate (x, y ) and (y, x) pairs, only one variant (i.e., (x, y )) was retained. in addition,
all rhyp-n pairs at this stage were reversed into hyp-n pairs. all no-rel pairs from usf were
also discarded at this stage to prevent the inclusion of semantically related pairs in the no-rel
subset of hyperlex.

in the    nal step, all remaining pairs were divided into per-relation pools of candidate noun
and verb pairs for each represented relation: hyp-n, cohyp, mero, syn, ant. two additional
pools were created for rhyp-n and no-rel after the sampling process.

11 we have decided to leave out adjectives: they are represented in usf to a lesser extent than nouns and verbs, and it is

thus not possible to sample large enough subsets of adjectives pairs across different lexical relations and lexical
entailment levels, i.e., only syn and ant adjective pairs are available in usf.

12 pos categories are generally considered to re   ect very broad ontological classes (fellbaum 1998). we thus felt it

would be very dif   cult, or even counter-intuitive, for annotators to rate mixed pos pairs.

13 the numbers are available as part of usf annotations.
14 note that the pairs with the same concept without any offensive connotation were included in the pools, e.g., weed /

grass, weed / plant, or ecstasy / feeling.

13

figure 2
a total number of noun and verb pairs in hyperlex representing different    ne-grained semantic relations
extracted from id138.

4.2 sampling procedure

the candidate pairs were then sampled from the respective per-relation pools. the    nal
number of pairs per each relation and pos category was in   uenced by: (1) the number of
candidates in each pool (therefore, hyperlex contains signi   cantly more noun pairs), (2) the
focus on le (therefore, hyperlex contains more hyp-n pairs at different le levels), (3) the wide
coverage of most prominent lexical relations (therefore, each lexical relation is represented by a
suf   cient number of pairs), and (4) logistic reasons (we were unable to rate all candidates in a
id104 study and had to sample a representative subset of candidates for each relation
and pos category in the    rst place).

step 1: initial sampling. first, pairs for lexical relations hyp-n, cohyp, mero, syn, and ant
were sampled from their respective pools. id138, although arguably the best choice for our
purpose, is not entirely reliable as a gold standard resource with occasional inconsistencies
and debatable precision regarding the way lexical relations have been encoded: e.g., silly is a
hyponym of child according to id138. therefore, all sampled pairs were manually checked
by the authors plus two native english speakers in several iterations. only such sampled pairs
where the majority of human checkers agreed on the lexical relation were retained. if a pair was
discarded, another substitute pair was randomly sampled if available, and again veri   ed against
human judgements.

step 2: reverse and no-rel pairs. before the next step, the pool for rhyp-n was generated by
simply reversing the order of concepts in all previously sampled (x, y ) hyp-n pairs. the pool for
no-rel was generated by pairing up the concepts from the pairs extracted in step 1 at random
using the cartesian product. from these random parings, we excluded those that coincidentally
occurred elsewhere in usf (and therefore had a degree of association), as well as those that
were assigned any lexical relation according to id138. from the remaining pairs, we accepted
only those in which both concepts had been subject to the usf norming procedure, ensuring
that these non-usf pairs were indeed unassociated rather than simply not normed. rhyp-n
and no-rel were then sampled from these two pools, followed by another manual check. the
rhyp-n pairs will be used to test the asymmetry of human and system judgements (see later in
tab. 7 and tab. 8), which is immanent to the le relation.

14

vuli  c et al.

hyperlex: a large-scale evaluation of graded lexical entailment

(a) page 1

(b) page 2(a)

figure 3
page 1 and page 2(a) of hyperlex annotation guidelines.

fig. 2 shows the exact numbers of noun and verb pairs across different lexical relations
represented in hyperlex. the    nal set of 2,616 distinct word pairs15 was then annotated in a
id104 study (sect. 4.3 and sect. 4.4).

4.3 question design and guidelines

here, we show and detail the exact annotation guidelines followed by the participants in the
id104 study. in order to accurately outline the lexical entailment relation to average
native speakers of english without any linguistic background, we have deliberately eschewed the
usage of any expert linguistic terminology in the annotation guidelines, and have also avoided
addressing the subtle differences between typicality and vagueness (sect. 2). for instance, the
terms such as hyponymy/hypernymy, lexical entailment, prototypicality, or taxonomy were never
explicitly de   ned using any precise linguistic formalism.

(page 1). we have adopted a simpler and more intuitive de   nition of lexical entailment instead,
based on the type-of relationship between words in question (fromkin, rodman, and hyams
2013), illustrated by a set of typical examples in the guidelines (see fig. 3(a)).

(page 2). following that, a clear distinction was made between words standing in a broader
relationship of semantic relatedness and words standing in an actual type-of relation (see fig. 3(b)).
we have included typical examples of related words without any entailment relation, including
meronymy pairs (tyre / car), cohyponymy pairs (plant / animal), and antonymy pairs (white / black),
and pairs in other lexical relations (e.g., shore / sea). since hyperlex also contains verbs, we have
also provided several examples for a type-of relation between verbs (see again fig. 3(b)).

potential polysemy issues have been addressed by stating (using intuitive examples) that
two words stand in a type-of relation if any of their senses stand in a type-of relation. however, we
acknowledge that this de   nition is vague, and the actual disambiguation process was left to
the annotators and their intuition as native speakers. a similar context-free rating was used in

15 the    nal number was obtained after randomly discarding a small number of pairs for each relation in order to
distribute the pairs of both pos categories into tranches of equal size in the id104 study, see sect. 4.4.

15

(a) page 2(b)

(b) page 3

figure 4
page 2(b) and page 3 of hyperlex annotation guidelines.

the construction of other word pair scoring datasets such as siid113x-999 (hill, reichart, and
korhonen 2015) or wordsim-353 (finkelstein et al. 2002).16 in the next step, we have explicitly
stressed that the type-of relation is asymmetric (see fig. 4(a)).

(page 3). the    nal page explains the main idea behind graded lexical entailment, graded
membership and prototypical class instances according to the theories from cognitive science
(rosch 1973, 1975; lakoff 1990; hampton 2007; divjak and arppe 2013) by providing another
illustrative set of examples (see fig. 4(b)). the main goals of the study were then quickly
summarised in the    nal paragraph, and the annotators were reminded to think in terms of the
type-of relationship throughout the study.

4.4 questionnaire structure and participants

we employ the proli   c academic (pa) id104 platform,17 an online marketplace very
similar to amazon mechanical turk and to crowdflower. while pa was used to recruit
participants, the actual questionnaire was hosted on qualtrics.18 unlike other id104
platforms, pa collects and stores detailed demographic information from the participants upfront.
this information was used to carefully select the pool of eligible participants. we restricted the
pool to native english speakers with a 90% approval rate (maximum rate on pa), of age 18-50,
born and currently residing in the united states or the united kingdom.

immediately after the guidelines, similar to the siid113x-999 questionnaire, a quali   cation
question is posed to the participant to test whether she/he understood the guidelines and is

16 determining the set of exact senses for a given concept, and then the set of contexts that represent those senses,
introduces a high degree of subjectivity into the design process. furthermore, in the infrequent case that some
concept x in a pair (x, y ) is genuinely (etymologically) polysemous, y can provide suf   cient context to
disambiguate x (hill, reichart, and korhonen 2015; leviant and reichart 2015).

17 https://proli   c.ac/ (we chose pa for logistic reasons.)
18 https://www.qualtrics.com/

16

vuli  c et al.

hyperlex: a large-scale evaluation of graded lexical entailment

(a) quali   cation question

(b) survey structure

figure 5
(a) quali   cation question. the correct answer is    is goose a type of animal?       (b) a group of noun pairs
to be rated by moving the sliders. the rating slider was initially at position 0, and it was possible to
attribute a rating of 0, although it was necessary to have actively moved the slider to that position to
proceed to the next page. the    rst pair is repeated from the previous page, while the last pair will be
repeated on the next page.

allowed to proceed with the questionnaire. the question is: fig. 5(a). in the case of an incorrect
answer, the study terminates for the participant without collecting any ratings.

in case of a correct answer, the participant begins rating pairs by moving a slider, as shown
in fig. 5(b). having a slider attached to the question    is x a type of y?    implicitly translates the
posed question to the question    to what degree is x a type of y?    (sect. 2). the pairs are presented
to the participant in groups of six or seven. as with siid113x-999, this group size was chosen
because the (relative) rating of a set of pairs implicitly requires pairwise comparisons between
all pairs in that set. therefore, larger groups would have signi   cantly increased the cognitive
load on the annotators. since concept pairs were presented to raters in batches de   ned according
to pos, another advantage of grouping was the clear break (submitting a set of ratings and
moving to the next page) between the tasks of rating noun and verb pairs. for better inter-group
calibration, from the second group onward the last pair of the previous group became the    rst
pair of the present group. the participants were then asked to re-assign the rating previously
attributed to the    rst pair before rating the remaining new items (fig. 5(b)).

it is also worth stressing that we have decided to retain the type-of structure of each question
explicitly for all word pairs so that raters are constantly reminded of the targeted lexical relation,
i.e., all (x, y ) word pairs are rated according to the question    is x a type of y?   , as shown in
fig. 5(b). for verbs, we have decided to use the in   nitive form in each question, e.g.,    is to run
a type of to move?   

following a standard practice in crowdsourced word pair scoring studies (finkelstein et
al. 2002; luong, socher, and manning 2013; hill, reichart, and korhonen 2015), each of the
2,616 concept pairs has to be assigned at least 10 ratings from 10 different accepted annotators.
we collected ratings from more than 600 annotators in total. to distribute the workload, we

17

benchmark

wordsim (353)
(finkelstein et al. 2002)
ws-sim (203)
(agirre et al. 2009)
siid113x (999)
(hill, reichart, and korhonen 2015)

hyperlex (2616)
hyperlex: nouns (2163)
hyperlex: verbs (453)

iaa-1

iaa-2

0.611

0.667

0.673

0.854
0.854
0.855

0.756

0.651

0.778

0.864
0.864
0.862

table 4
a comparison of hyperlex iaa with several prominent crowdsourced semantic similarity/relatedness
evaluation benchmarks that also provide scores for word pairs. numbers in parentheses refer to the total
number of word pairs in each evaluation set.

divided the 2,616 pairs into 45 tranches, with 79 pairs each: 50 are unique to one tranche, while
20 manually chosen pairs are in all tranches to ensure consistency: the use of such consistency
pairs enabled control for possible systematic differences between annotators and tranches, which
could detected by variation on this set of 20 pairs shared across all tranches. the remaining
9 are duplicate pairs displayed to the same participant multiple times to detect inconsistent
annotations. the number of noun and verb pairs is the same across all tranches (64/79 and 15/79
respectively). each annotator was asked to rate the pairs in a single tranche only. participants took
10 minutes on average to complete one tranche, including the time spent reading the guidelines
and answering the quali   cation question.

4.5 post-processing

85% of total exclusions occurred due to crowdsourcers answering the quali   cation question
incorrectly: we did not collect any ratings from such workers. in the post-processing stage, we
additionally excluded ratings of annotators who (a) did not give equal ratings to duplicate pairs;
(b) showed suspicious rating patterns (e.g., randomly alternating between two ratings, using one
single rating throughout the study, or assigning random ratings to pairs from the consistency set).
the    nal acceptance rate was 85.7% (if we also count the workers who answered the quali   cation
question incorrectly for the total number of assignments) and 97.5% (with such workers excluded
from the counts). we then calculated the average of all ratings from the accepted raters (     10 )
for each word pair. the score was    nally scaled linearly from the 0-6 to the 0-10 interval as in
(hill, reichart, and korhonen 2015).

5. analysis

inter-annotator agreement. we report two different inter-annotator agreement (iaa) measures.
iaa-1 (pairwise) computes the average pairwise spearman   s    correlation between any two
raters. this is a common choice in previous data collection in id65 (pad  ,
pad  , and erk 2007; reisinger and mooney 2010a; silberer and lapata 2014; hill, reichart, and
korhonen 2015).

a complementary measure would smooth individual annotator effects. for this aim, our
iaa-2 (mean) measure compares the average correlation of a human rater with the average of
all the other raters. it arguably serves as better    upper bound    than iaa-1 for the performance
of automatic systems. hyperlex obtains    = 0.854 (iaa-1) and    = 0.864 (iaa-2), a very good

18

vuli  c et al.

hyperlex: a large-scale evaluation of graded lexical entailment

hyp-1
0.850
0.866

hyp-2
0.844
0.847

hyp-3
0.859
0.872

hyp   4 cohyp mero
0.856
0.848
0.851
0.876

0.857
0.875

syn
0.860
0.883

ant
0.858
0.858

no-rel
0.854
0.859

rhyp-1
0.855
0.845

rhyp-2
0.842
0.850

rhyp-3
0.868
0.846

rhyp   4
0.856
0.859

iaa-1
iaa-2

table 5
inter-annotator agreements, measured by average pairwise spearman   s    correlation over different
   ne-grained semantic relations extracted from id138.

type-of
cat
monkey
cow
bat
mink
snake
snail
mongoose
dinosaur
crab
plant

animal

10.0
10.0
10.0
9.52
9.17
8.75
8.62
8.33
8.20
7.27
0.13

sandwich
pizza
rice
hamburger
mushroom
pastry
clam
snack
oregano
rabbit
dinner

food

10.0
10.0
10.0
9.75
9.07
8.83
8.20
7.78
5.97
5.83
4.85

rose
cactus
   ower
lily
weed
orchid
ivy
tree
clove
turnip
fungus

plant

9.75
9.58
9.45
9.40
9.23
9.08
9.00
8.63
8.47
8.05
4.75

basketball
hockey
volleyball
soccer
baseball
softball
cricket
racquetball
wrestling
recreation
-

sport

10.0
10.0
10.0
9.87
9.75
9.55
9.37
9.03
8.85
2.46
-

person

vehicle

girl
customer
clerk
citizen
nomad
poet
guest
mayor
publisher
climber
idol

9.85
9.08
8.97
8.63
8.63
7.78
7.22
6.67
6.03
5.00
4.28

car
limousine
motorcycle
van
automobile
tractor
truck
caravan
buggy
bicycle
vessel

10.0
10.0
9.85
9.75
9.58
9.37
9.23
8.33
8.20
8.00
6.38

table 6
graded le scores for instances of several prominent taxonomical categories/classes represented in
hyperlex (i.e., the categories are the word y in each (x, y, s) graded le triplet).

agreement compared to other prominent crowdsourced benchmarks for semantic evaluation
which also used word pair scoring (see tab. 4).19 we also report iaas over different groups of
pairs according to the relation extracted from id138 in tab. 5.

we acknowledge the fact that the grading process at places requires speci   c world-
knowledge (e.g., to what degree is snake a type of reptile?, to what degree is tomato a
type of fruit?), or is simply subjective and demographically biased (e.g., to what degree is to
pray a type of to communicate?), which needs principled qualitative analyses. however,
the hyperlex inter-rater agreement scores suggest that participants were able to understand
the characterisation of graded lexical entailment presented in the instructions and to apply it to
concepts of various types (e.g. nouns vs verbs, concrete vs abstract concepts, different lexical
relations from id138) consistently.

typicality in human judgements. in the    rst qualitative analysis, we aim to investigate the
straightforward question: are some concepts really more (proto)typical of semantically broader
higher-level classes? several examples of prominent high-level taxonomical categories along
with le scores are shown in tab. 6. we might draw several preliminary insights based on the
presented lists. there is an evident prototyping effect present in human judgements: concepts
such as cat, monkey or cow are more typical instances of the class animal than the more peculiar
instances such as mongoose or snail according to hyperlex annotators. instances of the class sport
also seem to be sorted accordingly, as higher scores are assigned to arguably more prototypical
sports such as basketball, volleyball or soccer, and less protypical sports such as racquetball or
wrestling are assigned lower scores.

nonetheless, the majority of hyp-n pairs (x, animal) or (x, sport), where x is a hyponym
of animal/sport according to wn, are indeed assigned reasonably high graded le scores. it

19 note that the iaas are not computed on the entire data set, but are in fact computed per tranche, as one worker

annotated only one tranche. exactly the same iaa computation was used previously by hill et al. (2015).

19

all
7.86
8.10
8.16
8.33
3.54
3.14
6.83
1.47
0.85
4.75
4.19
3.07
2.85

hyp-1
hyp-2
hyp-3
hyp   4
cohyp
mero
syn
ant
no-rel
rhyp-1
rhyp-2
rhyp-3
rhyp   4

nouns
7.99
8.31
8.39
8.62
3.29
3.14
6.69
1.57
0.64
4.17
3.44
2.72
2.54

verbs
7.49
7.08
6.55
5.12
4.76
-
7.66
1.25
1.48
6.45
6.15
4.47
4.11

table 7
average hyperlex scores across all pairs, and noun and verb pairs representing    ner-grained semantic
relations extracted from id138.

suggests that humans are able to: (1) judge the le relation consistently and decide that a concept
indeed stands in a type-of relation with another concept, and (2) grade the le relation by
assigning more strength to more prototypical class instances. similar patterns are visible with
other class instances from tab. 6, as well as with other prominent nominal classes (e.g., bird,
appliance, science). we also observe the same effect with verbs, e.g., (drift, move, 8.58), (hustle, move,
7.67), (tow, move, 7.37), (wag, move, 6.80), (unload, move, 6.22).

we have also analysed if the effects of graded membership/vagueness (see the discussion
in sect. 2) are also captured in the ratings, and our preliminary qualitative analysis suggests so.
for instance, an interesting example quanti   es the graded membership in the class group: (gang,
group, 9.25), (legion, group, 7.67), (conference, group, 6.80), (squad, group, 8.33), (caravan, group, 5.00),
(grove, group, 3.58), (herd, group, 9.23), (fraternity, group, 8.72), (staff, group, 6.28).

hypernymy/le levels. graded le scores in hyperlex averaged for each id138 relation are
provided in tab. 7. note that the le level is extracted as the shortest direct path between two
concept words in the id138 taxonomy, where x-s in each (x, y ) pair always refer to the less
general concept (i.e., hyponym). the scores suggest several important observations.

graded le scores for nouns increase with the increase of the le level (i.e., wn path length)
between the concepts. a longer wn path implies a clear difference in semantic generality between
nominal concepts which seems to be positively correlated with the degree of the le relation
and ease of human judgement. a similar    nding in directionality and detection experiments on
bless and its variants was reported by kiela et al. (2015). they demonstrate that their model is
less accurate on concepts with short paths (i.e., the lowest results are reported for wn hyp-1
pairs from bless), and the performance increases with the increase of the wn path length. the
tendency is explained by the lower difference in generality between concepts with short paths,
which may be dif   cult to discern for a statistical model. the results from tab. 7 show that human
raters also display a similar tendency when rating nominal pairs.

another factor underlying the observed scores might be the link between hyperlex and
the source usf norms. since usf contains free association norms, one might assume that more
prototypical instances are generated more frequently as responses to cue words in the original
usf experiments. this, in turn, re   ects in their greater presence in hyperlex, especially for
concept pairs with longer wn distances.

further, nominal concepts higher in the wn hierarchy typically refer to semantically very
broad but well-de   ned categories such as animal, food, vehicle, or appliance (see again tab. 6).

20

vuli  c et al.

hyperlex: a large-scale evaluation of graded lexical entailment

hyp-1 vs rhyp-1 (89%)
pair
(computer, machine)
(road, highway)
(dictator, ruler)
(truce, peace)
(remorse, repentance)
(disagreement, con   ict)
(navigator, explorer)
(ring, jewelry)
(solution, mixture)
(spinach, vegetable)
(surgeon, doctor)
(hint, suggestion)

scr

rscr

9.83
9.67
9.87
8.00
7.63
8.78
6.80
10.0
6.52
10.0
8.63
8.75

2.43
4.30
6.22
6.38
3.50
8.67
7.63
2.78
7.37
0.55
4.05
7.03

hyp-2 vs rhyp-2 (95%)
pair
(gravity, force)
(professional, expert)
(therapy, treatment)
(encyclopedia, book)
(empathy, feeling)
(shovel, tool)
(fraud, deception)
(bed, furniture)
(verdict, judgment)
(reader, person)
(vision, perception)
(daughter, child)

scr

rscr

9.50
6.37
9.17
8.93
8.85
9.70
9.52
9.75
9.67
7.43
3.82
9.37

3.58
6.03
4.10
2.22
2.42
2.57
8.17
2.63
7.57
3.33
6.25
2.78

hyp-3 vs rhyp-3 (96%)
pair
(   ask, container)
(elbow, joint)
(nylon, material)
(choir, group)
(beer, beverage)
(reptile, animal)
(parent, ancestor)
(note, message)
(oven, appliance)
(king, leader)
(hobby, activity)
(prism, shape)

scr

rscr

9.37
7.18
9.75
8.72
9.25
9.87
7.00
9.00
9.83
8.67
7.12
7.50

1.83
1.07
1.42
2.43
0.67
1.17
6.17
6.07
1.33
4.55
6.83
2.70

table 8
a selection of scored (x, y ) word pairs from hyperlex holding the hyp-1, hyp-2, and hyp-3 relation
according to id138 along with the hyperlex score for the actual (x, y ) pair (scr) and the hyperlex
score for the reversed (y, x) pair (i.e., rhyp-n relations): rscr. the reported percentages on top refer to the
ratio of (x, y ) pairs for each relation where scr > rscr.

semantically more speci   c instances of such concepts are easier to judge as true hyponyms
(using the ungraded le terminology), which also re   ects in higher le ratings for such instances.
however, gradience effects are clearly visible even for pairs with longer wn distances (tab. 6).
the behaviour with respect to the le level is reversed for verbs: the average scores decrease
over increasing le levels. we may attribute this effect to a higher level of abstractness and
ambiguity present in verb concepts higher in the wn hierarchy id30 from a fundamental
cognitive difference: gentner (2006) showed that children    nd verb concepts harder to learn than
noun concepts, and markman and wisniewski (1997) present evidence that different cognitive
operations are used when comparing two nouns or two verbs .for instance, it is intuitive to
assume that human subjects    nd it easier to grade instances of the class animal than instances of
verb classes such as to get, to set or to think.

le directionality. another immediate analysis investigates whether the inherent asymmetry of
the type-of relation is captured by the human annotations in hyperlex. several illustrative
example pairs and their reverse pairs split across different le levels are shown in tab. 8. two
important conclusions may be drawn from the analysis.

first, human raters are able to capture the asymmetry as the strong majority of hyp-n pairs
is rated higher than their rhyp-n counterparts: 94% of all hyp-n pairs for which exists the
rhyp-n counterpart are assigned a higher rating. second, the ability to clearly detect the correct
le direction seems to increase with the increase of semantic distance in id138: (1) we notice
decreasing average scores for the rhyp-n relation as n increases (see tab. 7), (2) we notice a
higher proportion of hyp-n concept pairs scoring higher than their rhyp-n counterparts as n
increases (see tab. 8). there are evident dif   culties to decide on the entailment direction with
several pairs (e.g., navigator / explorer, solution / mixture, disagreement / con   ict), especially for the
taxonomically closer hyp-1 pairs, a    nding aligned with prior work on le directionality (rimell
2014; kiela et al. 2015).

other lexical relations. another look into tab. 7, where graded le scores are averaged across each
wn-based lexical relation, indicates the expected order of all other lexical relations sorted by
the average per-relation scores (i.e., syn > cohyp > mero > ant > no-rel). no-rel and ant
pairs have the lowest graded le scores by a large margin, as expected. no-rel pairs are expected
to have completely non-overlapping semantic    elds, which facilitates human judgement. with

21

g1
979

# pairs

g2
259

g3
883

g4
344

table 9
a total number of concept pairs in each of the four coarse-grained groups based on the concepts   
concreteness ratings: both concepts are concrete (usf concreteness rating     4)     g1; both abstract     g2;
one concrete and one abstract concept with a difference in concreteness     1     g3 or > 1     g4. rhyp-n
pairs are not counted.

antonyms, the graded le question may be implicitly reformulated as to what degree is x a type of
  x? (e.g., winner / loser, to depart / to arrive), which intuitively should result in low graded le
scores: the hyperlex ratings con   rm the intuition.
low scores for cohyp pairs in comparison to hyp-n pairs indicate that the annotators are
able to effectively distinguish between the two related but different well-de   ned taxonomical
relations (i.e., hyp-n vs cohyp). high scores for syn pairs are also aligned with our expectations
and agree with intuitions from prior work on ungraded le (rei and briscoe 2014). in a slightly
simpli   ed view, given that two synonyms may be observed as two different utterances of the
same semantic concept x, the graded le question may be rephrased as to what degree is x a type
of x?. one might say that syn could be seen as a special case: the degenerate taxonomical hyp-0
relation. such an implicit reformulation of the posed question naturally results in higher scores
for syn pairs on average.

concreteness. differences in human and computational concept learning and representation
have been attributed to the effects of concreteness, the extent to which a concept has a directly
perceptible physical referent (paivio 1991; hill, korhonen, and bentz 2014). since the main focus
of this work is not on the distinction between abstract and concrete concepts, we have not
explicitly controlled for the balanced amount of concrete/abstract pairs in hyperlex. however,
since the source usf dataset provides concreteness scores, we believe that hyperlex will also
enable various additional analyses regarding this dimension in future work.

here, we report the number of pairs in four different groups based on concreteness ratings
of two concepts in each pair. the four groups are as follows: (g1) both concepts are concrete
(usf concreteness rating     4); (g2) both concepts are abstract (usf rating < 4), (g3) one concept
is considered concrete and another abstract, with their difference in ratings     1, (g4) one concept
is considered concrete and another abstract, with their difference in ratings > 1.
the statistics regarding hyperlex pairs divided into groups g1     g4 is presented in tab. 9.
rhyp-n pairs are not counted as they are simply reversed hyp-n pairs present in hyperlex.
concept pairs where at least one concreteness rating is missing in the usf data are also not
taken into account. although hyperlex contains more concrete pairs overall, there is also a
large sample of highly abstract pairs and mixed pairs. for instance, hyperlex contains 125
highly abstract concept pairs, with both concepts scoring     3 in concreteness, e.g., misery /
sorrow, hypothesis / idea, competence / ability, or religion / belief. this preliminary coarse-grained
analysis already hints that hyperlex provides a good representation of concepts across the entire
concreteness scale. this will also facilitate further analyses related to concept concreteness and
its in   uence on the automatic construction of semantic taxonomies.

data splits: random and lexical. a common problem in scored/graded word pair datasets is the
lack of a standard split to development and test sets (faruqui et al. 2016). custom splits, e.g.,
10-fold cross-validation make results incomparable with others. further, due to their limited
size, they also do not support supervised learning, and do not provide splits into training,

22

vuli  c et al.

hyperlex: a large-scale evaluation of graded lexical entailment

split
hyperlex-all
random split
train
dev
test
lexical split
train
dev
test

rating intervals
all
2616 (2163 + 453)

[0, 2 >

[2, 4 >

[4, 6 >

[6, 8 >

[8, 10]

604 (504 + 100)

350 (304 + 46)

307 (243 + 64)

515 (364 + 151)

840 (748 + 92)

1831 (1514 + 317)
130 (108 + 22)
655 (541 + 114)

423 (353 + 70)
30 (25 + 5)
151 (126 + 25)

1133 (982 + 151)
85 (71 + 14)
269 (198 + 71)

253 (220 + 33)
20 (18 + 2)
65 (52 + 13)

245 (213 + 32)
17 (15 + 2)
88 (76 + 12)

140 (122 + 18)
13 (11 + 2)
37 (29 + 8)

215 (170 + 45)
15 (13 + 2)
77 (60 + 17)

129 (109 + 20)
11 (8 + 3)
41 (31 + 10)

361 (255 + 106)
26 (18 + 8)
128 (91 + 37)

195 (148 + 47)
17 (10 + 7)
63 (37 + 26)

587 (523 + 64)
42 (37 + 5)
211 (188 + 23)

416 (383 + 33)
24 (24 + 0)
63 (49 + 14)

table 10
hyperlex data splits: basic statistics. the number of pairs is always provided in the following format
#overall (#n + #v), where #n and #v denote the number of noun and verb pairs respectively. the columns
represent groups/buckets of word pairs according to their le scores.

development, and test data. the lack of standard splits in such word pair datasets stems mostly
from small size and poor coverage     issues which we have solved with hyperlex.

we provide two standard data splits into train, dev, and test data: random and lexical. in
the random split, 70% of all pairs were reserved for training, 5% for development, and 25% for
testing. the subsets were selected by random sampling, but controlling for a broad coverage in
terms of similarity ranges, i.e., non-similar and highly similar pairs, as well as pairs of medium
similarity are represented. some statistics are available in tab. 10. a manual inspection of the
subsets revealed that a good range of lexical relations is represented in the subsets.

the lexical split, advocated in (levy et al. 2015; shwartz, goldberg, and dagan 2016),
prevents the effect of    lexical memorisation   : supervised distributional lexical id136 models
tend to learn an independent property of a single concept in the pair instead of learning a relation
between the two concepts.20 to prevent such behaviour, we split hyperlex into a train and test
set with zero lexical overlap. we tried to retain roughly the same 70%/25%/5% ratio in the lexical
split. note that the lexical split discards all    cross-set    training-test concept pairs. therefore, the
number of instances in each subset is lower than with the random split. statistics are again given
in tab. 10.

we believe that the provided standardised hyperlex data splits will enable easy and direct
comparisons of various le modeling architectures in unsupervised and supervised settings.
following arguments from prior work, we hold that it is important to provide both data set splits,
as they can provide additional possibility to assess differences between models. it is true that
training a model on a lexically split dataset may result in a more general model (levy et al. 2015),
which is able to better reason over pairs consisting of two unseen concepts during id136.
however, shwartz, goldberg, and dagan (2016) argue that a random split emulates a more
typical    real-life    reasoning scenario, where id136 involves an unseen concept pair (x, y ), in
which x and/or y have already been observed separately. models trained on a random split
may introduce the model with a concept   s    prior belief    of being a frequent hypernym or a
hyponym. this information can be effectively exploited during id136.

20 for instance, if the training set contains concept pairs (dog / animal), (cow, animal), and (cat, animal), all assigned very
high le scores or annotated as positive examples in case of ungraded le evaluation, the algorithm may learn that
animal is a prototypical hypernym, assigning any new (x, animal) pair a very high score, regardless of the actual
relation between x and animal; additional analyses provided in sect. 7.3.

23

6. evaluation setup and models

evaluation setup. we compare the performance of prominent models and frameworks focused on
modeling lexical entailment on our new hyperlex evaluation set now measuring the strength
of the lexical entailment relation. due to the evident similarity of the graded evaluation with
standard protocols in the semantic similarity (i.e., synonymy detection) literature (finkelstein et
al. 2002; agirre et al. 2009; hill, reichart, and korhonen 2015; schwartz, reichart, and rappoport
2015, inter alia), we adopt the same evaluation setup. each evaluated model assigns a score to
each pair of words measuring the strength of lexical entailment relation between them.21

as in prior work on intrinsic semantic evaluations with word pair scoring evaluation sets,
e.g., (hill, reichart, and korhonen 2015; levy, goldberg, and dagan 2015) as well as on measuring
relational similarity (jurgens et al. 2012), all reported scores are spearman   s    correlations between
the ranks derived from the scores of the evaluated models and the human scores provided in
hyperlex. in this work, we evaluate off-the-shelf unsupervised models and insightful baselines
on the entire hyperlex. we also report on preliminary experiments exploiting provided data
splits for supervised learning.

6.1 directional entailment measures

note that all directional entailment measures (dems) available in the literature have    pre-
embedding    origins and assume traditional count-based vector spaces (turney and pantel 2010;
baroni, dinu, and kruszewski 2014) based on counting word-to-word corpus co-occurrence.
distributional features are typically words co-occurring with the target word in a chosen context
(e.g., a window of neighbouring words, a sentence, a document, a dependency-based context).
this collection of models is grounded on variations of the distributional inclusion hypothesis
(geffet and dagan 2005): if x is a semantically narrower term than y , then a signi   cant number
of salient distributional features of x are included in the feature vector of y as well. we closely
follow the work from lenci and benotto (2012) in the presentation. let f eatx denote the set
of distributional features f t for a concept word x, and let wx (f t) refer to the weight of the
feature f t for x. the most common choices for the weighting function in traditional count-based
distributional models are positive variants of pointwise mutual information (pmi) (bullinaria
and levy 2007) and local mutual information (lmi) (evert 2008).

weedsprec (dem1). this dem quanti   es the weighted inclusion of the features of a concept word
x within the features of a concept word y (weeds and weir 2003; weeds, weir, and mccarthy
2004; kotlerman et al. 2010):

(cid:80)

(cid:80)

dem1(x, y ) =

wx (f t)

f t   f eatx   f eaty

f t   f eatx

wx (f t)

(5)

weedssim (dem2). it computes the geometrical average of weedsprec (dem1) or some other
asymmetric measure (e.g., apinc from kotlerman et al. (2010)) and the symmetric similarity
sim(x, y ) between x and y , typically measured by cosine (weeds, weir, and mccarthy 2004),
or the lin measure (lin 1998) as in the balapinc measure of kotlerman et al. (2010):

21 note that, unlike with similarity scores, the score now refers to an asymmetric relation id30 from the question

   is x a type of y    for the word pair (x, y ). therefore, the scores for two reverse pairs (x, y ) and (y, x) should be
different, see also tab. 8.

24

vuli  c et al.

hyperlex: a large-scale evaluation of graded lexical entailment

(6)

(7)

(8)

dem2(x, y ) = dem1(x, y )    sim(x, y )

clarkede (dem3). a close variation of dem1 was proposed by clarke (2009):

(cid:80)

(cid:80)

dem3(x, y ) =

f t   f eatx   f eaty

min(wx (f t), wy (f t))

f t   f eatx

wx (f t)

invcl (dem4). a variation of dem3 was introduced by lenci and benotto (2012). it takes into
account both the inclusion of context features of x in context features of y and non-inclusion of
features of y in features of x.22

dem4(x, y ) =(cid:112)dem3(x, y )    (1     dem3(y, x))

6.2 generality measures

another related view towards the type-of relation is as follows. given two semantically related
words, a key aspect of detecting lexical entailment is the generality of the hypernym compared to
the hyponym. for example, bird is more general than eagle, having a broader intension and a larger
extension. this property has led to the introduction of lexical entailment measures that compare
the id178/semantic content of distributional word representations, under the assumption that
a more general term has a higher-id178 distribution (herbelot and ganesalingam 2013; rimell
2014; santus et al. 2014). from this group we show the results with the slqs (santus et al. 2014)
model demonstrating the best performance in prior work.

slqs. it is an id178-based measure which actually quanti   es the speci   city/generality level
of related terms. first, the top n most associated context features (i.e., typically context words as
in the original work of santus et al. (2014)) are identi   ed (e.g., using positive pmi or lmi); for
each identi   ed context feature cn, its id178 h(cn) is de   ned as:

h(cn) =    

p (f ti|cn) log2 p (f ti|c)

(9)

where f ti, i = 1, . . . , n is the i-th context feature, and p (f ti|cn) is computed as the ratio of the
co-occurrence frequency (cn, f ti) and the total frequency of cn. for each concept word x, it
is possible to compute its median id178 ex over the n most associated context features. a
higher value ex implies a higher semantic generality of the concept word x. the initial slqs
measure called slqs-basic is then de   ned as:

slqs(x, y ) = 1    

ex
ey

(10)

this measure may be directly used in standard ungraded le directionality experiments since
slqs(x, y ) > 0 implies that x is a type of y (see tab. 1). another variant of slqs called slqs-
sim is tailored to le detection experiments: it resembles the dem2 measure from eq. (6), the
only difference is that, since slqs can now produce negative scores, all such scores are set to 0.

22 e.g., if animal is a hypernym of crocodile, one expects that (i) a number of context features of crocodile are also features
of animal, and (ii) that a number of context features of animal are not context features of crocodile. as a semantically
broader concept, animal is also found in contexts in which also occur animals other than crocodiles.

25

n(cid:88)

i=1

6.3 visual generality measures

kiela et al. (2015) showed that such generality-based measures for ungraded le need not be
linguistic in nature, and proposed a series of visual and multi-modal models for le directionality
and detection. we brie   y outline the two best performing ones in their experiments.

deselaers and ferrari (2011) previously showed that sets of images corresponding to terms at
higher levels in the id138 hierarchy have greater visual variability than those at lower levels.
they exploit this tendency using sets of images associated with each concept word as returned
by google   s image search. the intuition is that the set of images returned for the broader concept
animal will consist of pictures of different kinds of animals, that is, exhibiting greater visual
variability and lesser concept speci   city; on the other hand, the set of images for bird will consist
of pictures of different birds, while the set for owl will mostly consist only of images of owls.

the generality of a set of n images for each concept x is then computed. the    rst model
relies on the image dispersion measure (kiela et al. 2014). it is the average pairwise cosine distance
between all image representations23 {         ix,1, . . . ,         ix,n} for x:

id(x) =

2

n(n     1)

j<k   n

1     cos(         ix,j,         ix,k)

(11)

another similar measure instead of calculating the pairwise distance calculates the distance to
the centroid         x of {         ix,1, . . . ,         ix,n}:

cent(x) =

1
n

1     cos(         ix,j,        x )

(12)

(cid:88)

(cid:88)

1   j   n

final model. the following formula summarises the visual model for ungraded le directionality
and detection which we also test in graded evaluations:

(cid:26) 1     f (x)+  

f (y )

0

s  (x, y ) =

if cos( (cid:126)x, (cid:126)y )       
otherwise

(13)

f is one of the functions for image generality given by eq. (11) and eq. (12). the model relying on
eq. (11) is called vis-id, while the other is called vis-cent.    is a tunable threshold which sets a
minimum difference in generality for le identi   cation, driven by the idea that non-le pairs also
have non-identical generality scores. to avoid false positives where one word is more general
but the pair is not semantically related, a second threshold    is used, which sets f to zero if the
two concepts have low cosine similarity. finally, (cid:126)x and (cid:126)y are representations of concept words
used to compute their semantic similarity, e.g., (turney and pantel 2010; kiela and bottou 2014).

6.4 concept frequency ratio

concept word frequency ratio (fr) is used as a proxy for lexical generality and it is a surprisingly
competitive baseline in the standard (binary) le evaluation protocols (see sect. 3.1.1 and later
sect. 7.2) (weeds, weir, and mccarthy 2004; santus et al. 2014; kiela et al. 2015, inter alia). the

23 as is common practice in multi-modal semantics, each image representation is obtained by extracting the

4096-dimensional pre-softmax layer from a forward pass in a convolutional neural network (id98) (krizhevsky,
sutskever, and hinton 2012; simonyan and zisserman 2015) that has been trained on the id163 classi   cation task
using caffe (jia et al. 2014; russakovsky et al. 2015).

26

vuli  c et al.

hyperlex: a large-scale evaluation of graded lexical entailment

fr model also relies on eq. (13), the only difference is that f (x) = f req(x), where f req(x) is a
simple word frequency count obtained from a large corpus.

6.5 id138-based similarity measures

a variant of eq. (13) may also be used with any standard id138-based similarity measure to
quantify the degree of type-of relation:

s(x, y ) = fw n (x, y )

(14)

where fw n (x, y ) returns a similarity score based on the id138 path between two concepts.
we use three different standard measures for fw n resulting in three variant wn-based models:
(1) wn-basic: fw n returns a score denoting how similar two concepts are, based on the shortest
path that connects the concepts in the wn taxonomy.
(2) wn-lch: leacock-chodorow similarity function (1998) returns a score denoting how similar
two concepts are, based on their shortest connecting path (as above) and the maximum depth of
the taxonomy in which the concepts occur. the score is then     log(path/2    depth), where path is
the shortest connecting path length and depth the taxonomy depth.
(3) wn-wup: wu-palmer similarity function (wu and palmer 1994; pedersen, patwardhan, and
michelizzi 2004) returns a score denoting how similar two concepts are, based on the depth of
the two concepts in the taxonomy and that of their most speci   c ancestor node.

note that all three wn-based similarity measures are not well-suited for graded le
experiments by their design: e.g., they will rank direct co-hyponyms as more similar than
distant hypernymy-hyponymy pairs.

6.6 order embeddings

following trends in semantic similarity (or graded synonymy computations, see sect. 2 again)
vendrov et al. (2016) have recently demonstrated that it is possible to construct a vector space or
id27 model that specialises in the lexical entailment relation, rather than in the more
popular similarity/syonymy relation. the model is then applied in a variety of tasks including
ungraded le detection and directionality.

the order embedding model exploits the partial order structure of a visual-semantic
hierarchy (see fig. 6) by learning a mapping which is not distance-preserving but order-
preserving between the visual-semantic hierarchy and a partial order over the embedding space.
it learns a mapping from a partially ordered set (u,(cid:22)u ) into a partially ordered embedding
space (v,(cid:22)v ): the ordering of a pair in u is then based on the ordering in the embedding space.
the chosen embedding space is the reversed product order on rn
+ , de   ned by the conjunction of
total orders on each coordinate:

n(cid:94)

i=1

(cid:126)x (cid:22) (cid:126)y

iff

xi     yi

(15)

for all vectors (cid:126)x and (cid:126)y with nonnegative coordinates, where the vectors (cid:126)x and (cid:126)y are order
embeddings of concept words x and y .24 with a slight abuse of notation, xi refers to the i-th
coordinate of vector (cid:126)x, the same for yi. the ordering criterion, however, is too restrictive to

24 smaller coordinates imply higher position in the partial order. the origin is then the top element of the order,

representing the most general concept.

27

figure 6
a slice of the visual-semantic hierarchy. the toy example taken from vendrov et al. (2016), inspired by the
resource of young et al. (2014).

impose as a hard constraint. therefore, an approximate order-embedding is sought: a mapping
which violates the order-embedding condition, imposed as a soft constraint, as little as possible.
in particular, the penalty l for an ordered pair ( (cid:126)x, (cid:126)y ) of points/vectors in rn

+ is de   ned as:

l( (cid:126)x, (cid:126)y ) = || max(0, (cid:126)y     (cid:126)x)||2

(16)

l( (cid:126)x, (cid:126)y ) = 0 implies that x (cid:22) y according to the reversed product order. if the order is not
satis   ed, the penalty is positive. the model requires a set of positive pairs p p (i.e., true le pairs)
and a set of negative pairs n p for training. finally, to learn an approximate mapping to an order
embedding space, a max-margin loss is used, which encourages positive examples to have zero
penalty, and negative examples to have penalty greater than a margin   :

(cid:88)

(cid:88)

l( (cid:126)x, (cid:126)y ) +

max(0,        l( (cid:126)x(cid:48), (cid:126)y (cid:48)))

(17)

(x,y )   p p

(x(cid:48),y (cid:48))   n p

positive and negative examples are task-dependent. for the standard ungraded le evaluations,
positive pairs for the training set p p are extracted from the id138 hierarchy. the set n p is
obtained by arti   cially constructing    corrupted    pairs (socher et al. 2013), that is, by replacing
one of the two concepts from positive examples with a randomly selected concept. this model is
called orderemb.

graded le with order embeddings. order embeddings are trained for the binary le detection task,
but not explicitly for the graded le task. to measure how much one such off-the-shelf order
embedding model captures le on the continuous scale, we test three different distance measures:
(1) orderemb-cos: a standard cosine similarity is used on vector representations.
(2) orderemb-distall: the sum of the absolute distance between all coordinates of the vectors
(cid:126)x and (cid:126)y is used as a distance function:

(cid:88)

distall( (cid:126)x, (cid:126)y ) =

|yi     xi|,

(18)

28

i

vuli  c et al.

hyperlex: a large-scale evaluation of graded lexical entailment

this measure is based on the training penalty de   ned by eq. (16). the idea is that for order
embeddings the space is sorted based on the degree of hypernymy/hyponymy violation in each
dimension: the absolute coordinate distance may be used as an indicator of the le strength.
(3) orderemb-distpos: this variant extends the distall distance by only adding up those
coordinates ful   lling the criterion de   ned in the reversed product order in eq. (15):

(cid:40)

(cid:88)

distp os( (cid:126)x, (cid:126)y ) =

|yi     xi|,
0,

if xi     yi
otherwise

(19)

6.7 standard (   similarity   ) embeddings

i

a majority of other id27 models available in the literature target the symmetric
relation of semantic relatedness and similarity, and the strength of the similarity relation is
modeled by a symmetric similarity measure such as cosine.

it was shown that human subjects often consider    closer    le pairs quite semantically similar
(geffet and dagan 2005; agirre et al. 2009; hill, reichart, and korhonen 2015).25 for instance,
pairs (assignment, task) or (author, creator) are judged as strong le pairs (with average scores 9.33
and 9.30 in hyperlex respectively), they are assigned the labels hyp-1 and hyp-2 according to
id138 respectively, and are also considered semantically very similar (their siid113x-999 scores
are 8.70 and 8.02). in another example, the id138 syn pairs (foe, enemy) and (summit, peak)
have graded le scores of 9.72 and 9.58 in hyperlex. the rationale behind these experiments
is then to test to what extent these symmetric models are capable of quantifying the degree of
lexical entailment, and to what degree these two relations are interlinked.

we test the following benchmarking semantic similarity models: (1) unsupervised models
that learn from distributional information in text, including the skip-gram negative-sampling
model (sgns) (mikolov et al. 2013b) with various contexts (bow = bag of words; deps
= dependency contexts) as described by levy and goldberg (2014); (2) models that rely on
linguistic hand-crafted resources or curated knowledge bases. here, we rely on models using
currently holding the peak scores in word similarity tasks: sparse binary vectors built from
linguistic resources (non-distributional, (faruqui and dyer 2015)), vectors    ne-tuned
to a paraphrase database (paragram, (wieting et al. 2015)) further re   ned using linguistic
constraints (paragram+cf, (mrk  i  c et al. 2016)). since these models are not the main focus of
this work, the reader is referred to the relevant literature for detailed descriptions.

6.8 gaussian embeddings

an alternative approach to learning id27s was proposed by vilnis and mccallum
(2015). they represent words as gaussian densities rather than points in the embedding space.
each concept x is represented as a multivariate k-dimensional gaussian parameterised as
n (  x ,   x ), where   x is a k-dimensional vector of means, and   x in the most general case is a
k    k covariance matrix.26
word types are embedded into soft regions in space: the intersection of these regions could
be straightforwardly used to compute the degree of lexical entailment. this allows a natural
representation of hierarchies using e.g. the asymmetric kullback-leibler (kl) divergence. kl

25    closeness    or hypernymy level for (x, y ) may be measured by the shortest wn path connecting x and y .
26 vilnis and mccallum (2015) use a simpli   cation where   x is represented as a k-dimensional vector (so-called

diagonal gaussian embeddings) or a scalar (spherical embeddings).

29

divergence between gaussian id203 distributions is straightforward to calculate, naturally
asymmetric, and has a geometric interpretation as an inclusion between families of ellipses.

to train the model, they de   ne an energy function that returns a similarity-like measure
of the two probabilities. it is possible to train the model to better capture    standard semantic
similarity    (see sect. 6.7) by using expected likelihood (el) as the energy function. on the other
hand, kl divergence is a natural energy function for representing entailment between concepts    
a low kl divergence from x to y indicates that we can encode y easily as x, implying that y
entails x. this can be interpreted as a soft form of inclusion between the level sets of ellipsoids
generated by the two gaussians     if there is a relatively high expected log-likelihood ratio
(negative kl), then most of the mass of y lies inside x.

we refer the reader to the original work (vilnis and mccallum 2015; he et al. 2015) for a more
detailed description of the idea and actual low-level modelling steps. we evaluate two variants
of the model on the graded le task following (vilnis and mccallum 2015): (i) word2gauss-
el-cos and word2gauss-el-kl use el in training, but the former uses cosine between
vectors of means as a (symmetric) measure of similarity between concepts, and the latter relies
on the (asymmetric) kl divergence between full gaussians; (ii) word2gauss-kl-cos and
word2gauss-kl-kl use kl divergence as the energy function.

7. results and discussion

7.1 training data and parameters

since we evaluate a plethora of heterogeneous models and architectures on the graded le task,
we    rst provide a quick overview of their training setup regarding training data, their parameter
settings and other modeling choices.

dems and slqs. directional entailment measures dem1-dem4 and both slqs variants (i.e.,
slqs-basic and slqs-sim) are based on the cleaned, tokenised and lowercased polyglot
wikipedia (al-rfou, perozzi, and skiena 2013). we have used two setups for the induction
of word representations, the only difference being that in setup 1 context/feature vectors are
extracted from the polyglot wiki directly based on bigram co-occurrence counts, while in setup 2,
these vectors are extracted from the typedm tensor (baroni and lenci 2010) as in the original
work of lenci and benotto (2012).27 both setups use the positive lmi weighting calculated on
syntactic co-occurrence links between each word and its context word (gulordava and baroni
, where c(w) is the unigram count in the
2011): lm i(w1, w2) = c(w1, w2)     log2
polyglot wiki for the word w, c(w1, w2) is the dependency based co-occurrence count of the
two tokens w1 and w2., i.e. (w1, (dep_rel, w2)), and t otal is the number of all such tuples. the
polyglot wiki was parsed with universal dependencies (nivre et al. 2015) as in the work of
vuli  c and korhonen (2016).28 the context vocabulary (i.e., words w2) is restricted to the 10k
most frequent words in the polyglot wiki. the same two setups were used for the slqs model.
we also use frequency counts collected from the polyglot wiki for the frequency ratio model.
id138-based similarity measures rely on the latest id138 3.1 release.

c(w1,w2)   t otal

c(w1)c(w2)

27 typedm is a variant of the distributional memory (dm) framework, where distributional info is represented as a set
of weighted word-link-word tuples (cid:104)(cid:104)w1, l, w2(cid:105),   (cid:105) where w1 and w2 are word tokens, l is a syntactic co-occurrence
link between the words (e.g. a typed dependency link), and    is a weight assigned to the tuple (e.g., lmi or pmi).
28 we have also experimented with the typedm scores directly and negative lmi values. we do not report these results

as they are signi   cantly lower than the reported results obtained by the other two setups.

30

vuli  c et al.

hyperlex: a large-scale evaluation of graded lexical entailment

id27s. we use 300-dimensional pre-trained order embeddings of vendrov et al. (2016)
available online.29 for the detailed description of the training procedure, we refer the reader to the
original paper. gaussian embeddings are trained on the polyglot wiki with the vocabulary of the
top 200k most frequent single words. we train 300-dimensional representations using the online
tool and default settings suggested by vilnis and mccallum (2015):30 spherical embeddings
trained for 200 epochs on a max-margin objective with margin set to 2.

we also use pre-trained standard    semantic similarity    id27s available online
from various sources. 300-dimensional sgns-bow/deps vectors are also trained on the
polyglot wiki: these are the same vectors from (levy and goldberg 2014).31 300-dimensional
paragram vectors are the same as in (wieting et al. 2015)32, while their extension using a
retro   tting procedure (paragram+cf) has been made available by mrk  i  c et al. (2016).33 sparse
non-distributional vectors of faruqui and dyer (2015) are also available online.34

7.2 results

due to a wide variety of models and a large space of results used in this work, it is not feasible
to present all results at once or provide detailed analyses across all potential dimensions of
comparison. therefore, we have decided to make a gradual selection of the most interesting
experiments and results, and stress (what we consider to be) the most important aspects of the
hyperlex evaluation set and modeling architectures in our comparisons.

experiment i: ungraded le approaches. in the    rst batch of experiments, we evaluate a series of
state-of-the-art traditional le modelling aproaches in the graded le task on the entire hyperlex
evaluation set. the models are described in sect. 6.1-sect. 6.5. a summary of the results is
provided in tab. 11. comparing model scores with the inter-annotator agreements suggests
that the graded le task, although well-de   ned and understandable by average native speakers,
poses a challenge for current ungraded le models. the absolute difference in scores between
human and system performance indicates that there is vast room for improvement in future
work. the gap also illustrates the increased dif   culty of the graded le task compared to previous
ungraded le evaluations (see also exp. iv). for instance, the best unsupervised le directionality
and detection models from tab. 11 reach up over 70% and up to 90% in precision scores (santus
et al. 2014; kiela et al. 2015, inter alia) on bless and other datasets discussed in sect. 3.1.2.

previous work on ungraded le evaluation also detected that frequency is a surprisingly
competitive baseline in le detection/directionality experiments (herbelot and ganesalingam
2013; weeds et al. 2014; kiela et al. 2015). this    nding stems from an assumption that the
informativeness of a concept decreases and generality increases as frequency of the concept
increases (resnik 1995). although the assumption is a rather big simpli   cation (herbelot and
ganesalingam 2013), the results based on simple frequency scores in this work further suggest
that the fr model may be used as a very competitive baseline in the graded le task.

the results also reveal that visual approaches are competitive to purely textual distributional
ones. in tab. 11, we have set the parameters according to (kiela et al. 2015). varying the   
parameter leads to even better results, e.g., the vis-id model scores    = 0.229 and vis-cent

29 https://github.com/ivendrov/order-embedding
30 https://github.com/seomoz/word2gauss
31 https://levyomer.wordpress.com/2014/04/25/dependency-based-word-embeddings/
32 http://ttic.uchicago.edu/~wieting/
33 https://github.com/nmrksic/counter-   tting
34 https://github.com/mfaruqui/non-distributional

31

model
fr (   = 0.02,    = 0.25)
fr (   = 0,    = 0)
dem1
dem2
dem3
dem4
slqs-basic
slqs-sim
wn-basic
wn-lch
wn-wup
vis-id (   = 0.02,    = 0)
vis-cent (   = 0.02,    = 0)

iaa-1
iaa-2

setup 1
0.279
0.268
0.162
0.171
0.150
0.153
0.225
0.228
0.207
0.214
0.234
0.203
0.209

0.854
0.864

setup 2
0.240
0.265
0.162
0.180
0.150
0.153
0.221
0.226
0.207
0.214
0.234
0.203
0.209

0.854
0.864

table 11
results in the graded le task over all hyperlex concept pairs obtained by the sets of most prominent le
models available in the literature (see sect. 6.1-sect. 6.5). setup 1 and setup 2 refer to different training
setups for dems and slqs. all results are spearman   s    correlation scores. iaa    scores are provided to
quantify the upper bound for the graded le task.

scores    = 0.228 with    = 1. this    nding supports recent trends in multi-modal semantics and
calls for more expressive multi-modal le models as discussed previously by kiela et al. (2015).
to our own surprise, the fr model was the strongest model in this    rst comparison, while
directional measures fall short of all other approaches, although prior work suggested that they
are tailored to capture the le relation in particular. as we do not observe any major difference
between two setups for dems and slqs, all subsequent experiments use setup 1. the observed
strong correlation between frequency and graded le supports the intuition that prototypical
class instances will be more often cited in text, and therefore simply more frequent.

even wn-based measures do not lead to huge improvements over dems and fall short of
fr. since id138 lacks annotations pertinent to the idea of graded le, such simple wn-based
measures cannot quantify the actual le degree. the inclusion of the basic    semantic relatedness
detector    (as controlled by the parameter   ) does not lead to any signi   cant improvements (e.g.,
as evident from the comparison of slqs-sim vs. slqs-basic, or dem2 vs. dem1).

in summary, the large gap between human and system performances along with the fr
superiority over more sophisticated le approaches from prior work unambiguously calls for the
next generation of distributional models tailored for graded lexical entailment in particular.

experiment ii: id27s. in the next experiment, we evaluate a series of state-of-the-
art id27 architectures, covering order embeddings (sect. 6.6), standard semantic
similarity embeddings optimised on siid113x-999 and related word similarity tasks (sect. 6.7),
and gaussian embeddings (sect. 6.8). a summary of the results is provided in tab. 12. the scores
again reveal the large gap between the system performance and human ability to consistently
judge the graded le relation. the scores on average are similar to or even lower than scores
obtained in exp. i. one trivial reason behind the failure is as follows: id27s typically
apply the cosine similarity in the euclidean space to measure the distance between x and y .
in practice, this leads to the symmetry: dist(x, y ) = dist(y, x) for each pair (x, y ), which is
an undesired model behaviour for graded le in practice, as corroborated by our analysis of

32

vuli  c et al.

hyperlex: a large-scale evaluation of graded lexical entailment

model
fr (   = 0.02,    = 0.25)
fr (   = 0,    = 0)
sgns-bow (win=2)
sgns-deps
non-distributional
paragram
paragram+cf
orderemb-cos
orderemb-distall
orderemb-distpos
word2gauss-el-cos
word2gauss-el-kl
word2gauss-kl-cos
word2gauss-kl-kl
iaa-1
iaa-2

all
0.279
0.268
0.167
0.205
0.158
0.243
0.320
0.156
0.180
0.191
0.192
0.206
0.190
0.201
0.854
0.864

nouns
0.283
0.283
0.148
0.182
0.115
0.200
0.267
0.162
0.180
0.195
0.171
0.192
0.179
0.189
0.854
0.864

verbs
0.239
0.091
0.289
0.352
0.543
0.492
0.629
0.005
0.130
0.120
0.207
0.209
0.160
0.172
0.855
0.862

table 12
results (spearman   s    correlation scores) in the graded le task on hyperlex using a selection of
state-of-the-art pre-trained id27 models (see sect. 6.6-sect. 6.8). all id27s,
excluding sparse non-distributional vectors, are 300-dimensional.

asymmetry in human judgements (see tab. 7 and tab. 8). this    nding again calls for a new
methodology capable of tackling the asymmetry of the graded le problem in future work.

dependency-based contexts (sgns-deps) seem to have a slight edge over ordinary bag-
of-words contexts (sgns-bow) which agrees with    ndings from prior work on ungraded le
(roller and erk 2016; shwartz, santus, and schlechtweg 2017). we observe no clear advantage
with orderemb and word2gauss, two id27 models tailored for capturing the
hierarchical le relation naturally in their training objective. we notice slight but encouraging
improvements with orderemb when resorting to more sophisticated distance metrics, e.g.,
moving from the symmetric straightforward cos measure to distpos with orderemb, or
using kl instead of cos with word2gauss.

as discussed in sect. 6.6, the off-the-shelf orderemb model was trained for the binary
ungraded le detection task: its expressiveness for graded le thus remains limited. one line
of future work might utilise the orderemb framework with a true graded le objective, and
investigate new orderemb-style representation models fully adapted to the graded le setting.

lexical entailment and similarity. hill, reichart, and korhonen (2015) report that there is strong
correlation between hyp-n word pairs and semantic similarity as judged by human raters. for
instance, given the same [0, 10] continuous rating scale in siid113x-999, the average similarity
score in siid113x-999 for siid113x-999 hyp-1 pairs is 6.62, it is 6.19 for hyp-2 pairs, and 5.70
for hyp-3 and hyp-4. in fact, the only group scoring higher than hyp-n pairs in siid113x-999
are syn pairs with the average score of 7.70. therefore, we also evaluate state-of-the-art word
embedding models obtaining peak scores on siid113x-999, some of them even obtaining scores
above the siid113x-999 iaa-1. the rationale is to test whether hyperlex really captures the
   ne-grained and subtle notion of graded lexical entailment, or the hyperlex annotations were
largely driven by decisions at the broader level of semantic similarity.

another look into tab. 12 indicates an evident link between the le relation and semantic
similarity. positive correlation scores for all models reveal that pairs with high graded le scores
naturally imply some degree of semantic similarity, e.g., author / creator. however, the scores with

33

figure 7
results on the intersection subset of 111 concept pairs annotated both in siid113x-999 (for similarity) and in
hyperlex (for graded le).

similarity-specialised models are much lower than the human performance in the graded le task,
which suggests that they cannot capture intricacies of the task accurately. more importantly, there
is a dramatic drop in performance when evaluating exactly the same models in the semantic
similarity task (i.e., graded synonymy) on siid113x-999 vs. the graded le task on hyperlex.
for instance, two best performing id27 models on siid113x-999 are paragram
and paragram+cf reaching spearman   s    correlation of 0.685 and 0.742, respectively, with
siid113x-999 iaa-1 = 0.673, iaa-2 = 0.778. at the same time, the two models score 0.243 and 0.320
on hyperlex respectively, where the increase in scores for paragram+cf may be attributed to
its explicit control of antonyms through dictionary-based constraints.

a similar decrease in scores is observed with other models in our comparisons, e.g., sgns-
bow falls from 0.415 on siid113x-999 to 0.167 on hyperlex. to further examine this effect, we
have performed a simple experiment using only the intersection of the two evaluation sets
comprising 111 word pairs in total (91 nouns and 20 verbs) for evaluation. the results of selected
embedding models on the 111 pairs are shown in fig. 7. it is evident that all state-of-the-art word
embedding models are signi   cantly better at capturing semantic similarity.

in summary, the analysis of results with distributed representation models on siid113x-999
and hyperlex suggests that the human understanding of the graded le relation is not con   ated
with semantic similarity. human scores assigned to word pairs in both siid113x-999 and hyperlex
re   ect truly the nature of the annotated relation: semantic similarity in case of siid113x-999 and
graded lexical entailment in case of hyperlex.

experiment iii: nouns vs. verbs. in the next experiment, given the theoretical likelihood of variation
in model performance across pos categories mentioned in sect. 4.1, we assess the differences in
results on noun (n) and verb (v) subsets of hyperlex. the results of    traditional    le models
(exp. i) are provided in tab. 13. tab. 12 shows results of id27 models. iaa scores
on both pos subsets are very similar and reasonably high, implying that human raters did not
   nd it more dif   cult to rate verb pairs. however, we observe differences in performance over the
two pos-based hyperlex subsets. first, dems obtain much lower scores on the verb subset. it
may be attributed to a larger variability of context features for verbs, which also affects the pure
distributional models relying on the distributional inclusion hypothesis. wn-based approaches,
relying on an external curated knowledge base, do not show the same pattern, with comparable
results over pairs of both word classes. visual models also score better on nouns, which may

34

sgns-bowsgns-depsnon-distributionalparagramparagram+cfrepresentationmodel   0.20.00.20.40.60.8spearman  intersection:siid113x-999intersection:hyperlexvuli  c et al.

hyperlex: a large-scale evaluation of graded lexical entailment

model
fr (   = 0.02,    = 0.25)
fr (   = 0,    = 0)
dem1
dem2
dem3
dem4
slqs-basic
slqs-sim

wn-basic
wn-lch
wn-wup
vis-id (   = 1,    = 0)
vis-cent (   = 1,    = 0)

iaa-1
iaa-2

nouns
0.283
0.283
0.180
0.170
0.164
0.167
0.224
0.229

0.240
0.214
0.214
0.253
0.252

0.854
0.864

verbs
0.239
0.091
0.018
0.047
0.108
0.109
0.247
0.232

0.263
0.260
0.269
0.137
0.132

0.855
0.862

table 13
results in the graded le task over all hyperlex noun and verb pairs separately. all dem and slqs model
variants are using setup 1.

again be explained by the increased level of abstractness when dealing with verbs. this, in turn,
leads to a greater visual variability and incoherence in visual concept representations.

for id27 models, we notice that scores for the v subset are signi   cantly higher
than for the n subset. to isolate the in   uence of test set size, we have also repeated experiments
with random subsets of the n subset, equal to the v subset in size (453 pairs). we observe the
same trend even with such smaller n test sets, leading to a conclusion that difference in results
stems from the fundamental difference in how humans perceive nouns and verbs. human raters
seem to associate the le relation with similarity more frequently in case of verbs, and they do it
consistently (based on the iaa scores). we speculate that it is indeed easier for humans to think
in terms of semantic taxonomies when dealing with real-world entities (e.g., concrete nouns),
than with more abstract events and actions, as expressed by verbs. another reason could be that,
when humans make judgements over verb semantics, syntactic features become more important
and implicitly in   uence the judgements. this effect is supported by the research on automatic
acquisition of verb semantics, in which syntactic features have proven particularly important
(kipper et al. 2008; korhonen 2010, inter alia).

we leave the underlying causes at the level of speculation. a deeper exploration here
is beyond the scope of this work, but this preliminary analysis already highlights how the
principal word classes integrated in hyperlex are pertinent to a range of questions concerning
distributional, lexical, and cognitive semantics.

experiment iv: ungraded vs. graded le. we also analyse the usefulness of hyperlex as a data set
for ungraded le evaluations and study the differences between graded le and one ungraded
le task: hypernymy/le directionality (see sect. 3.1.1). first, we have converted a subset of
hyperlex into a data set for le directionality experiments similar to bless by retaining only
hyp-n pairs from hyperlex (as indicated by id138) with the graded le score     7.0. the
subset contains 940 (x, y ) pairs in total (of which 121 pairs are verb pairs), where y in each
pair may be seen as the hypernym. following that, we run a selection of ungraded le models
from sect. 6 tailored to capture directionality, and compare the scores of the same models in the
graded le task on this hyperlex subset containing    true hypernymy-hyponymy    pairs.

35

model
fr (   = 0,    = 0)
dem1
dem2
dem3
dem4
slqs-basic
slqs-sim
orderemb

directionality
all
0.760
0.700
0.700
0.696
0.696
0.747
0.749
0.578

nouns
0.778
0.696
0.696
0.684
0.684
0.734
0.734
0.578

verbs
0.636
0.726
0.726
0.777
0.777
0.835
0.851
0.571

graded le
all
0.089
-0.072
-0.070
0.036
0.036
0.088
0.163
0.048

nouns
0.104
-0.102
-0.050
0.063
0.064
0.121
0.126
0.068

verbs
0.032
-0.071
-0.042
0.115
0.110
-0.036
-0.012
0.029

table 14
results in the ungraded le directionality task (precision) using a subset of 940 hyperlex pairs converted
to the ungraded directionality data set. graded le results (spearman   s    correlation) on the same subset
are also provided for comparison purposes, using the best model con   gurations from tab. 11 and tab. 12.

the frequency baseline considers the more frequent concept as the hypernym in the pair.
for dem 1-dem 4 models (sect. 6.1), the prediction of directionality is based on the asymmetry
of the measure: if demi(x, y ) > demi(y, x), it means that the inclusion of the features of x
within the features of y is higher than the reverse, which in turn implies that y is the hypernym
in the pair. further, slqs(x, y ) > 0 implies that y is a semantically more general concept and
is therefore the hypernym (see sect. 6.2).35 with orderemb, smaller coordinates mean higher
position in the partial order: we compute and compare distp os( (cid:126)x, (cid:126)y ) and distp os((cid:126)y , (cid:126)x) scores
to    nd the hypernym. the results provided as binary precision scores are summarised in tab. 14.
they reveal that frequency is a strong indicator of directionality, but further improvements,
especially for verbs, may be achieved by resorting to asymmetric and generality measures. the
reasonably high scores observed in our ungraded directionality experiments are also reported
for the detection task in prior work (shwartz, santus, and schlechtweg 2017). the graded le
results on the hyperlex subset are prominently lower than the results with the same models on
the entire hyperlex: this shows that    ne-grained differences in human ratings in the high end of
the graded le spectrum are even more dif   cult to capture with current statistical models.

the main message conveyed by the results from tab. 14 is that the output from the models
built for ungraded le indeed cannot be used as an estimate of graded le. in other words, the
relative id178 or the measure of distributional inclusion between two concepts can be used
to reliably detect which concept is the hypernym in the directionality task, or to distinguish
between le and other relations in the detection task, but it leads to a poor global estimate of the
le strength for graded le experiments.

7.3 supervised settings: regression models

we also conduct preliminary experiments in supervised settings, relying on the random and
lexical splits of hyperlex introduced in sect. 5 (see tab. 10). we experiment with several
well-known supervised models from the literature: they typically represent concept pairs as
a combination of each concept   s embedding vector: concatenation (cid:126)x     (cid:126)y (baroni et al. 2012),
difference (cid:126)y     (cid:126)x (roller, erk, and boleda 2014; weeds et al. 2014; fu et al. 2014), or element-wise

35 following the same idea, also discussed in (lazaridou, pham, and baroni 2015; kiela et al. 2015), a concept with a

higher id27 standard deviation or embedding id178 could be considered semantically more general
and therefore the hypernym. however, we do not report the scores with id27s as they were only slightly
better than the random baseline with the precision of 0.5.

36

vuli  c et al.

hyperlex: a large-scale evaluation of graded lexical entailment

model
fr (   = 0.02,    = 0.25)
dem1
dem2
dem3
dem4
slqs-sim
wn-basic
wn-wup
vis-id (   = 1,    = 0)
vis-cent (   = 1,    = 0)

iaa-1
iaa-2

random
0.299
0.212
0.220
0.142
0.145
0.223
0.189
0.212
0.203
0.207

0.849
0.862

lexical
0.199
0.188
0.142
0.177
0.178
0.179
0.255
0.261
0.201
0.209

0.846
0.857

table 15
results on the two test sets of hyperlex splits with a selection of unsupervised le models. lower scoring
model variants are not shown.

multiplication (cid:126)x (cid:12) (cid:126)y (levy et al. 2015). based on state-of-the-art id27s such as
sgns-bow or paragram, these methods are easy to apply, and show very good results in
ungraded le tasks (baroni et al. 2012; weeds et al. 2014; roller, erk, and boleda 2014). using
two standardised hyperlex splits, the experimental setup is as follows: we learn a regression
model on the training set, optimise parameters (if any) on dev, and test the model   s prediction
power on test. we experiment with two id75 models: (1) standard ordinary least
squares (ols), and (2) ridge regression or tikhonov regularisation (ridge) (myers 1990).

ridge regression is a variant of least squares regression in which a regularisation term is
added to the training objective to favour solutions with certain properties. the regularisation
term is the euclidian l2-norm of the inferred vector of regression coef   cients. this term ensures
that the regression favors lower coef   cients and a smoother solution function, which should
provide better generalisation performance than simple ols id75. the ridge objective
is to minimise the following:

||(cid:126)aq     (cid:126)s||2

2 + ||  (cid:126)a||2

2

(20)

where (cid:126)a is the vector of regression coef   cients, q is a matrix of feature representations for each
concept pair (x, y ) obtained using concatenation, difference, or element-wise multiplication. (cid:126)s is
the vector of graded le strengths for each concept pair, and    is some suitably chosen tikhonov
matrix. we rely on the most common choice: it is a multiple of the identity matrix    =   i.

the effect of regularisation is thus varied via the    hyperparameter, which is optimised on

the dev set. setting    = 0 reduces the model to the unregularised ols solution.

results. following related work, we rely on the selection of state-of-the-art id27
models to provide feature vectors (cid:126)x and (cid:126)y . the results of a variety of tested regression models
are summarised in fig. 8(a) (random split) and fig. 8(b) (lexical split). as another reference point,
we also report results with several unsupervised models on the two smaller test sets in tab. 15.
the iaa scores from tab. 15 again indicate that there is    rm agreement between annotators
for the two test sets, and that automatic systems still display a large gap to the human
performance. the scores on the smaller test sets follow similar patterns as on the entire hyperlex.
we see a slight increase of performance for similarity-specialised models (e.g., wn-based models
or paragram+cf) on the lexical split. we attribute this increase to the larger percentage of verb

37

(a) random split

(b) lexical split

figure 8
spearman   s    correlation scores using two different hyperlex data splits: (a) random and (b) lexical (see
sect. 5). two id75 models are used: ordinary least squares (ols) and ridge regression (ridge),
both trained on the training subset of each split, and tested on the test subset. three typical feature
transformations from prior work on le detection/directionality in supervised settings have been tested:
feature vector difference ((cid:126)y     (cid:126)x), element-wise multiplication ( (cid:126)x (cid:12) (cid:126)y ), concatenation ( (cid:126)x     (cid:126)y ). we also
report baseline    correlation scores obtained by simply computing cos( (cid:126)x, (cid:126)y ) on each test subset directly,
without any model learning (unsupervised). performance ceilings are 0.849 (iaa-1), 0.862 (iaa-2) for the
random split, 0.846 (iaa-1), 0.857 (iaa-2) for the lexical split.

pairs in the lexical test set, shown to be better modelled with similarity-oriented embeddings in
the graded le task. verb pairs constitute 17.3% of the entire random test set, the same percentage
as in the entire hyperlex, while the number is 26.4% for the lexical test set.

we reassess that supervised distributional methods indeed perform worse on a lexical split
(levy et al. 2015; shwartz, goldberg, and dagan 2016). besides operating with a smaller training

38

sgns-bowsgns-depsparagram+cforderembrepresentationmodel0.00.10.20.30.40.50.6spearman   s  ~y   ~x(ols)~y   ~x(ridge)~x(cid:12)~y(ols)~x(cid:12)~y(ridge)~x   ~y(ols)~x   ~y(ridge)unsupervisedsgns-bowsgns-depsparagram+cforderembrepresentationmodel0.00.10.20.30.40.5spearman   s  ~y   ~x(ols)~y   ~x(ridge)~x(cid:12)~y(ols)~x(cid:12)~y(ridge)~x   ~y(ols)~x   ~y(ridge)unsupervisedvuli  c et al.

hyperlex: a large-scale evaluation of graded lexical entailment

concept pair
(plant, animal)
(mammal, animal)
(animal, mammal)
(rib, animal)
(reader, person)
(foot, plant)
(fungus, plant)
(dismiss, go)
(dinner, food)

hyperlex
0.13
10.0
1.25
0.35
7.43
0.42
4.75
3.97
4.85

ols
6.95
7.14
6.61
6.94
7.47
7.86
7.94
4.22
9.36

ridge
7.39
7.43
4.99
7.08
6.97
6.05
7.51
4.29
8.63

table 16
the effects of lexical memorisation on the output of regression models when dealing with typical
hypernymy concepts higher in the taxonomy (e.g., animal, plant): hyperlex denotes the score assigned to
the pair by humans in hyperlex, while ols and ridge refer to the predicted output of the two tested
regression models. we use sgns-deps embeddings with concatenation ( (cid:126)x     (cid:126)y , see fig. 8), while similar
trends are observed with other sets of vectors and feature transformations.

set in a lexical split, the    nding is also explained by the effect of lexical memorisation with a
random split: if high scores are systematically assigned to training pairs (x1, animal) or (x2,
appliance), the model will simply memorise that each pair (y1, animal) or (y2, appliance) should
be assigned a high score during id136. the impact of lexical memorisation is illustrated by
tab. 16 using a sample of concept pairs containing    prototypical hypernyms    (roller and erk
2016) such as animal: the regression models assign high scores even to clear negatives such as
(plant, animal). however, the effect of lexical memorisation also partially explains the improved
performance of all regression models over unsupervised baselines for a random split, as many
(xt, animal) pairs are indeed assigned high scores in the test set.

on the other hand, we also notice that almost all ols regression models and a large number
of ridge models in a lexical split cannot beat unsupervised model variants without any model
learning. this suggests that the current state-of-the-art methodology in supervised settings
is indeed limited in such scenarios and cannot learn satisfying generalisations regarding the
type-of relation between words in training pairs. we suspect that another reason behind strong
results with the semantically specialised paragram+cf model in the unsupervised setting
for the lexical split is the larger percentage of verbs in the lexical test set as well as explicit
handling of antonymy, as mentioned earlier. the model explicitly penalises antonyms through
dictionary-based constraints (i.e., pushes them away from each other in the vector space), a
property which is desired both for semantic similarity and graded le (see the low scores for the
ant relation in tab. 7).

the variation in results across the tested supervised model variants also indicates that the
performance of a regression model is strongly dependent on the actual choice of the underlying
representation model, feature transformation, as well as the chosen regression algorithm. first,
the results on a random split reveal that the best unsupervised representation model does not
necessarily yield the best supervised model, e.g., higher results are observed with sgns-deps
than with paragram in that setting. orderemb is by far the weakest model in our comparison.
second, there is no clear winner in the comparison of three different feature representations.
while vector difference ((cid:126)y     (cid:126)x) and concatenation ((cid:126)y     (cid:126)x) seem to yield higher scores overall
for a majority of models, element-wise multiplication obtains highest scores overall in a lexical
split with paragram and paragram+cf. the variation clearly suggests that supervised
models have to be carefully tuned in order to perform effectively on the graded le task.

finally, consistent improvements of ridge over ols across all splits, models, and feature
transformations reveal that the choice of a regression model matters. this preliminary analysis
advocates the use of more sophisticated learning algorithms in future work. another path of

39

research work could investigate how to exploit more training data from resources other than
hyperlex to yield improved graded le models.

7.4 further discussion: specialising semantic spaces

following the growing interest in word representation learning, this work also touches upon
the ideas of vector/semantic space specialisation: a desirable property of representation models
is their ability to steer their output vector spaces according to explicit linguistic and dictionary
knowledge (yu and dredze 2014; wieting et al. 2015; faruqui et al. 2015; astudillo et al. 2015;
liu et al. 2015; mrk  i  c et al. 2016; vuli  c et al. 2017, inter alia). previous work showed that it is
possible to build vector spaces specialised for capturing different lexical relations, e.g., antonymy
(yih, zweig, and platt 2012; ono, miwa, and sasaki 2015), or distinguishing between similarity
and relatedness (kiela, hill, and clark 2015). yet, it is to be seen how to build a representation
model specialised for the graded le relation. an analogy with (graded) semantic similarity
is appropriate here: it was recently demonstrated that vector space models specialising for
similarity and scoring high on siid113x-999 and simverb-3500 are able to boost performance of
statistical systems in language understanding tasks such as dialogue state tracking (mrk  i  c et al.
2016, 2017; vuli  c et al. 2017). along the same line, we assume that the speci   cation of what the
degree of le means for each individual pair may also boost performance of statistical end-to-end
systems in another language understanding task in future work: natural language id136
(bowman et al. 2015; parikh et al. 2016; agi  c and schluter 2017).

owing to their adaptability and versatility, we believe that representation architectures
inspired by neural networks, e.g., (mrk  i  c et al. 2016; vendrov et al. 2016), are a promising avenue
for future modeling work on graded lexical entailment in both unsupervised and supervised
settings, despite their low performance on the graded le task at present.

8. application areas: a quick overview

the proposed data set should have an immediate impact in the cognitive science research,
providing means to analyse the effects of typicality and gradience in concept representations
(hampton 2007; decock and douven 2014). besides this, a variety of other research domains share
interest in taxonomic relations, automatic methods for their extraction from text, completion of
rich knowledge bases, etc. here, we provide a quick overview of such application areas for the
graded lexical entailment framework and the hyperlex data set.

natural language processing. as discussed in depth in sect. 3, lexical entailment is an important
linguistic task in its own right (rimell 2014). graded le introduces a new challenge and a
new evaluation protocol for data-driven distributional le models. in current binary evaluation
protocols targeting ungraded le detection and directionality, even simple methods modeling
lexical generality are able to yield very accurate predictions. however, our preliminary analysis
in sect. 7.2 demonstrates their fundamental limitations for graded lexical entailment.

in addition to the use of hyperlex as a new evaluation set, we believe that the introduction
of graded le will have implications on how the distributional hypothesis (harris 1954) is
exploited in distributional models targeting taxonomic relations in particular (rubinstein et
al. 2015; shwartz, goldberg, and dagan 2016; roller and erk 2016, inter alia). further, a tight
connection of le with the broader phrase-/sentence-level task of recognising lexical entailment
(rte) (dagan, glickman, and magnini 2006; dagan et al. 2013) should lead to further implications
for text generation (biran and mckeown 2013), metaphor detection (mohler et al. 2013), question
answering (sacaleanu et al. 2008), id141 (androutsopoulos and malakasiotis 2010), etc.

40

vuli  c et al.

hyperlex: a large-scale evaluation of graded lexical entailment

representation learning. the previous work on representation learning has mostly focused on
the relations of semantic similarity and relatedness, as evidenced by the surge in interest in
evaluation of id27s on datasets such as siid113x-999, wordsim-353, men (bruni,
tran, and baroni 2014), rare words (luong, socher, and manning 2013), etc. this strong focus
towards similarity and relatedness means that other fundamental semantic relations such as
lexical entailment have been largely overlooked in the representation learning literature. notable
exceptions building id27s for le have appeared only recently (see the work of
vendrov et al. (2016) and a short overview in sect. 7.4), but a comprehensive evaluation resource
for intrinsic evaluation of such le embeddings is still missing. there is a pressing need to improve,
broaden, and introduce new evaluation protocols and datasets for representation learning
architectures (schnabel et al. 2015; tsvetkov et al. 2015; yaghoobzadeh and sch  tze 2016; faruqui
et al. 2016; batchkarov et al. 2016, inter alia).36 we believe that one immediate application of
hyperlex is its use as a comprehensive, wide-coverage large evaluation set for representation-
learning architectures focused on the fundamental type-of taxonomic relation.

data mining: extending knowledge bases. ontologies and knowledge bases such as id138, yago,
or dbpedia are useful resources in a variety of applications such as text generation, question
answering, information retrieval, or for simply providing structured knowledge to users. since
they typically suffer from incompleteness and a lack of reasoning capability, a strand of research
(snow, jurafsky, and ng 2004; suchanek, kasneci, and weikum 2007; bordes et al. 2011; socher et
al. 2013; lin et al. 2015) attempts to extend existing knowledge bases using patterns or classi   ers
applied to large text corpora. one of the fundamental relations in all knowledge bases is the
type-of/instance-of/is-a le relation (see tab. 2 in sect. 3.1.2). hyperlex may be again used
straightforwardly as a wide-coverage evaluation set for such knowledge base extension models:
it provides an opportunity to evaluate statistical models that tackle the problem of graded le.

cognitive science. inspired by theories of prototypicality and graded membership, hyperlex
is a repository of human graded le scores which could be exploited in cognitive linguistics
research (taylor 2003) and other applications in cognitive science (g  rdenfors 2004; hampton
2007). for instance, reasoning over lexical entailment is related to analogical transfer: transferring
information from the past experience (the source domain) to the new situation (the target domain)
(gentner 1983; holyoak 2012), e.g., seeing an unknown animate object called wampimunk or
huhblub which resembles a dog, one is likely to conclude that such huhblubs are to a large extent
types of animals, although de   nitely not prototypical instances such as dogs.

information search. graded le may    nd application in relational web search (cafarella, banko,
and etzioni 2006; kato et al. 2009; kopliku, pinel-sauvagnat, and boughanem 2011). a user of a
relational search engine might pose the query:    list all animals with four legs    or    list manners of
slow movement.    a system aware of the degree of le would be better suited to relational search
than a simple discrete classi   er: the relational engine could rank the output list so that more
prototypical instances are cited    rst (e.g., dogs, cats or elephants before huhblubs or wampimunks).
this has a direct analogy with how standard search engines rank documents or web pages in
descending order of relevance to the user   s query. further, taxonomy keyword search (song et al.

36 the need for    nding better evaluation protocols for representation learning models is further exempli   ed by the

initiative focused on designing better evaluation protocols for semantic representation models (repeval):
https://sites.google.com/site/repevalacl16/
https://repeval2017.github.io/

41

2011; liu et al. 2012; wu et al. 2012) is another prominent problem in information search and
retrieval where such knowledge of lexical entailment relations may be particularly useful.

beyond the horizon: multi-modal modeling. from a high-level perspective, autonomous arti   cial
agents will need to jointly model vision and language in order to parse the visual world and
communicate with people. lexical entailment, id123, and image captioning can be
seen as special cases of a partial order over uni   ed visual-semantic hierarchies (deselaers and
ferrari 2011; vendrov et al. 2016), see also fig. 6 again. for instance, image captions may be seen
as abstractions of images, and they can be expressed at various levels in the hierarchy. the same
image may be abstracted as, e.g., a boy and a girl walking their dog, people walking their dog, people
walking, a boy, a girl, and a dog, children with a dog, children with an animal, etc. lexical entailment
might prove helpful in research on e.g. image captioning (hodosh, young, and hockenmaier
2013; socher et al. 2014; bernardi et al. 2016) or cross-modal information retrieval (pereira et al.
2014) based on such visual-semantic hierarchies, but it is yet to be seen whether the knowledge
of gradience and prototypicality may contribute to image captioning systems.

image generality is closely linked to semantic generality as is evident from recent work
(deselaers and ferrari 2011; kiela et al. 2015). the data set could also be very useful in evaluating
models that ground language in the physical world (silberer and lapata 2012, 2014; bruni, tran,
and baroni 2014, inter alia). future work might also investigate attaching graded le scores to
large hierarchical image databases such as id163 (deng et al. 2009; russakovsky et al. 2015).

9. conclusion

while the ultimate test of semantic models is their usefulness in downstream applications, the
research community is still in need of wide-coverage comprehensive gold standard resources for
intrinsic evaluation (camacho-collados, pilehvar, and navigli 2015; schnabel et al. 2015; tsvetkov
et al. 2015; hashimoto, alvarez-melis, and jaakkola 2016; gladkova and drozd 2016, inter alia).
such resources can measure the general quality of the representations learned by semantic
models, prior to their integration in end-to-end systems. we have presented hyperlex, a large
wide-coverage gold standard resource for the evaluation of semantic representations targeting
the lexical relation of graded lexical entailment (le) also known as hypernymy-hyponymy or
type-of relation, a relation which is fundamental in construction and understanding of concept
hierarchies, that is, semantic taxonomies. given that the problem of concept category membership
is central to many cognitive science problems focused on semantic representation, we believe
that hyperlex will also    nd its use in this domain.

the development of hyperlex was principally inspired and motivated by several factors.
first, unlike prior work on lexical entailment in nlp, it focuses on the relation of graded or
soft lexical entailment at a continuous scale: the relation quanti   es the strength of the type-of
relation between concepts rather than simply making a binary decision as with the ungraded
le variant surveyed in sect. 3. graded le is    rmly grounded in cognitive linguistic theory
of class prototypes (rosch 1973, 1975) and graded membership (hampton 2007), stating that
some concepts are more central to a broader category/class than others (prototypicality) or that
some concepts are only within the category to some extent (graded membership). for instance,
basketball is more frequently cited as a prototypical sport than chess or wrestling. one purpose
of hyperlex is to examine the effects of prototypicality and graded membership in human
judgements, as well as to provide a large repository (i.e., hyperlex contains 2,616 word pairs in
total) of concept pairs annotated for graded lexical entailment. a variety of analyses in sect. 5
show that the effects are indeed prominent.

42

vuli  c et al.

hyperlex: a large-scale evaluation of graded lexical entailment

second, while existing gold standards measure the ability of models to capture similarity
or relatedness, hyperlex is the    rst crowdsourced data set with the relation of (graded) lexical
entailment as its primary target. as such, it will serve as an invaluable evaluation resource for
representation learning architectures tailored for the principal lexical relation, which has plenty
of potential applications as indicated in sect. 8. analysis of the hyperlex ratings from more than
600 annotators, native english speakers, showed that subjects can consistently quantify graded
le, and distinguish it from a broader notion of similarity/relatedness and other prominent
lexical relations (e.g., cohyponymy, meronymy, antonymy) based on simple non-expert intuitive
instructions. this is supported by high inter-annotator agreement scores on the entire data set, as
well as on different subsets of hyperlex (e.g., pos categories, id138 relations).

third, as we wanted hyperlex to be wide-coverage and representative, the construction
process guaranteed that the data set covers concept pairs of different pos categories (nouns
and verbs), at different levels of concreteness, and concept pairs standing in different relations
according to id138. the size and coverage of hyperlex makes it possible to compare the
strengths and weaknesses of various representation models via statistically robust analyses on
speci   c word classes, and investigate human judgements in relation to such different properties.
the size of hyperlex also enables supervised learning, for which we provide two standard
data set splits (levy et al. 2015; shwartz, goldberg, and dagan 2016) into training, test, and
development subsets.

to dissect the key properties of hyperlex, we conducted a spectrum of experiments and
evaluations with most prominent state-of-the-art classes of lexical entailment and embedding
models available in the literature. one clear conclusion is that current lexical entailment models
optimised for the ungraded le variant perform very poorly in general. there is clear room under
the inter-rating ceiling to guide the development of the next generation of distributional models:
the low performance can be partially mitigated by focusing models on the graded le variant,
and developing new and more expressive architectures for le in future work. even analyses
with a selection of prominent supervised le models reveal the huge gap between the human and
system performance in the graded le task. future work thus needs to    nd a way to conceptualise
and encode the graded le idea into distributional models to tackle the task effectively. despite
their poor performance at present, we believe that a promising step in that direction are neural
net inspired approaches to le proposed recently (vilnis and mccallum 2015; vendrov et al.
2016), mostly due to their conceptual distinction from other distributional modeling approaches
complemented with their modeling adaptability and    exibility. in addition, in order to model
hierarchical semantic knowledge more accurately, in future work we may require algorithms that
are better suited to fast learning from few examples (lake et al. 2011), and have some    exibility
with respect to sense-level distinctions (reisinger and mooney 2010b; neelakantan et al. 2014;
jauhar, dyer, and hovy 2015;   uster, titov, and van noord 2016).

despite the abundance of reported experiments and analyses in this work, we have only
scratched the surface in terms of the possible analyses with hyperlex and use of such models
as components of broader phrase- and sentence-level id123 systems, as well as in
other applications, as quickly surveyed in sect. 8. beyond the preliminary conclusions from these
initial analyses, we believe that the bene   t of hyperlex will become evident as researchers use it
to probe the relationship between architectures, algorithms and representation quality for a wide
range of concepts. a better understanding of how to represent the full diversity of concepts (with
le grades attached) in hierarchical semantic networks should in turn yield improved methods
for encoding and interpreting the hierarchical semantic knowledge which constitutes much of
the important information in language.

43

acknowledgments

this work is supported by the erc consolidator grant (no 648909). dk and fh performed their
work while they were still at the university of cambridge.

references
agi  c,   eljko and natalie schluter. 2017. baselines and test data for cross-lingual id136. corr,

abs/1704.05347.

agirre, eneko, enrique alfonseca, keith b. hall, jana kravalova, marius pasca, and aitor soroa. 2009. a
study on similarity and relatedness using distributional and id138-based approaches. in proceedings
of naacl-hlt, pages 19   27.

al-rfou, rami, bryan perozzi, and steven skiena. 2013. polyglot: distributed word representations for

multilingual nlp. in proceedings of conll, pages 183   192.

androutsopoulos, ion and prodromos malakasiotis. 2010. a survey of id141 and id123

methods. journal of arti   cial intelligence research, 38:135   187.

astudillo, ram  n, silvio amir, wang ling, mario silva, and isabel trancoso. 2015. learning word

representations from scarce and noisy data with embedding subspaces. in proceedings of acl, pages
1074   1084.

auer, s  ren, christian bizer, georgi kobilarov, jens lehmann, richard cyganiak, and zachary g. ives.

2007. dbpedia: a nucleus for a web of open data. in proceedings of the semantic web conference (iswc),
pages 722   735.

bankova, desislava, bob coecke, martha lewis, and daniel marsden. 2016. graded entailment for

compositional id65. corr, abs/1601.04908.

baronett, stan. 2012. logic, 3rd edition.
baroni, marco, raffaella bernardi, ngoc-quynh do, and chung-chieh shan. 2012. entailment above the

word level in id65. in proceedings of eacl, pages 23   32.

baroni, marco, georgiana dinu, and germ  n kruszewski. 2014. don   t count, predict! a systematic

comparison of context-counting vs. context-predicting semantic vectors. in proceedings of acl, pages
238   247.

baroni, marco and alessandro lenci. 2010. distributional memory: a general framework for corpus-based

semantics. computational linguistics, 36(4):673   721.

baroni, marco and alessandro lenci. 2011. how we blessed distributional semantic evaluation. in
proceedings of the workshop on geometrical models of natural language semantics (gems), pages 1   10.

batchkarov, miroslav, thomas kober, jeremy ref   n, julie weeds, and david weir. 2016. a critique of word
similarity as a method for evaluating distributional semantic models. in proceedings of repeval, pages
7   12.

beckwith, richard, christiane fellbaum, derek gross, and george a. miller. 1991. id138: a lexical

database organized on psycholinguistic principles. lexical acquisition: exploiting on-line resources to build a
lexicon, pages 211   231.

bejar, isaac i., roger chaf   n, and susan embretson. 1991. cognitive and psychometric analysis of analogical

problem solving.

beltagy, islam, cuong chau, gemma boleda, dan garrette, katrin erk, and raymond mooney. 2013.

montague meets markov: deep semantics with probabilistic logical form. in proceedings of *sem, pages
11   21.

bernardi, raffaella, ruket cakici, desmond elliott, aykut erdem, erkut erdem, nazli ikizler-cinbis, frank

keller, adrian muscat, and barbara plank. 2016. automatic description generation from images: a
survey of models, datasets, and evaluation measures. journal of arti   cial intelligence research, 55:409   442.

biran, or and kathleen mckeown. 2013. classifying taxonomic relations between pairs of wikipedia

articles. in proceedings of ijcnlp, pages 788   794.

blutner, reinhard, emmanuel m. pothos, and peter bruza. 2013. a quantum id203 perspective on

borderline vagueness. topics in cognitive science, 5(4):711   736.

bordes, antoine, jason weston, ronan collobert, and yoshua bengio. 2011. learning structured

embeddings of knowledge bases. in proceedings of aaai, pages 301   306.

bos, johan and katja markert. 2005. recognising id123 with logical id136. in proceedings of

emnlp, pages 628   635.

bowman, samuel r., gabor angeli, christopher potts, and christopher d. manning. 2015. a large

annotated corpus for learning natural language id136. in proceedings of emnlp, pages 632   642.

44

vuli  c et al.

hyperlex: a large-scale evaluation of graded lexical entailment

bruni, elia, nam-khanh tran, and marco baroni. 2014. multimodal id65. journal of

arti   cial intelligence research, 49:1   47.

bullinaria, john a. and joseph p. levy. 2007. extracting semantic representations from word co-occurrence

statistics: a computational study. behavior research methods, 39(3):510   526.

cafarella, michael j., michele banko, and oren etzioni. 2006. relational web search. in proceedings of www.
camacho-collados, jos  , mohammad taher pilehvar, and roberto navigli. 2015. a framework for the

construction of monolingual and cross-lingual word similarity datasets. in proceedings of acl, pages 1   7.
clarke, daoud. 2009. context-theoretic semantics for natural language: an overview. in proceedings of the

workshop on geometrical models of natural language semantics (gems), pages 112   119.

coleman, linda and paul kay. 1981. prototype semantics: the english word lie. language, 57(1):26   44.
collins, allan m. and ross m. quillian. 1969. retrieval time from semantic memory. journal of verbal

learning and verbal behavior, 8(2):240   247.

collins, allan m. and ross m. quillian. 1972. experiments on semantic memory and language

comprehension. cognition in learning and memory.

dagan, ido, oren glickman, and bernardo magnini. 2006. the pascal recognising id123

challenge. in machine learning challenges. pages 177   190.

dagan, ido, dan roth, mark sammons, and fabio massimo zanzotto. 2013. recognizing id123:

models and applications. synthesis lectures on human language technologies, 6(4):1   220.
decock, lieven and igor douven. 2014. what is graded membership? no  s, 48(4):653   682.
deng, jia, wei dong, richard socher, li-jia li, kai li, and fei-fei li. 2009. id163: a large-scale

hierarchical image database. in proceedings of cvpr, pages 248   255.

deselaers, thomas and vittorio ferrari. 2011. visual and semantic similarity in id163. in proceedings of

cvpr, pages 1777   1784.

dirven, ren   and john taylor. 1986. the conceptualisation of vertical space in english: the case of tall.
divjak, dagmar and antti arppe. 2013. extracting prototypes from exemplars: what can corpus data tell us

about concept representation? cognitive linguistics, 24(2):221   274.

do, quang and dan roth. 2010. constraints based taxonomic relation classi   cation. in proceedings of

emnlp, pages 1099   1109.

esteva, francesc, llu  s godo, ricardo o. rodr  guez, and thomas vetterlein. 2012. logics for approximate

and strong entailments. fuzzy sets and systems, 197:59   70.

evert, stefan. 2008. corpora and collocations. corpus linguistics, 2:223   233.
faruqui, manaal, jesse dodge, sujay kumar jauhar, chris dyer, eduard hovy, and noah a. smith. 2015.

retro   tting word vectors to semantic lexicons. in proceedings of naacl-hlt, pages 1606   1615.

faruqui, manaal and chris dyer. 2015. non-distributional word vector representations. in proceedings of

acl, pages 464   469.

faruqui, manaal, yulia tsvetkov, pushpendre rastogi, and chris dyer. 2016. problems with evaluation of

id27s using word similarity tasks. in proceedings of repeval, pages 30   35.

fellbaum, christiane. 1998. id138.
finkelstein, lev, evgeniy gabrilovich, yossi matias, ehud rivlin, zach solan, gadi wolfman, and eytan

ruppin. 2002. placing search in context: the concept revisited. acm transactions on information systems,
20(1):116   131.

fromkin, victoria, robert rodman, and nina hyams. 2013. an introduction to language, 10th edition.
fu, ruiji, jiang guo, bing qin, wanxiang che, haifeng wang, and ting liu. 2014. learning semantic

hierarchies via id27s. in proceedings of acl, pages 1199   1209.

fu, ruiji, jiang guo, bing qin, wanxiang che, haifeng wang, and ting liu. 2015. learning semantic

hierarchies: a continuous vector space approach. ieee/acm transactions on audio, speech & language
processing, 23(3):461   471.

g  rdenfors, peter. 2004. conceptual spaces: the geometry of thought.
geffet, maayan and ido dagan. 2005. the distributional inclusion hypotheses and lexical entailment. in

proceedings of acl, pages 107   114.

gentner, dedre. 1983. structure-mapping: a theoretical framework for analogy. cognitive science,

7(2):155   170.

544   564.

gentner, dedre. 2006. why verbs are hard to learn. action meets word: how children learn verbs, pages

gerz, daniela, ivan vuli  c, felix hill, roi reichart, and anna korhonen. 2016. simverb-3500: a large-scale

evaluation set of verb similarity. in proceedings of emnlp, pages 2173   2182.

gheorghita, inga and jean-marie pierrel. 2012. towards a methodology for automatic identi   cation of

hypernyms in the de   nitions of large-scale dictionary. in proceedings of lrec, pages 2614   2618.

45

gladkova, anna and aleksandr drozd. 2016. intrinsic evaluations of id27s: what can we do

better? in proceedings of repeval, pages 36   42.

gulordava, kristina and marco baroni. 2011. a distributional similarity approach to the detection of

semantic change in the google books ngram corpus. in proceedings of the gems workshop on geometrical
models of natural language semantics, pages 67   71.

hampton, james a. 2006. concepts as prototypes. psychology of learning and motivation, 46:79   113.
hampton, james a. 2007. typicality, graded membership, and vagueness. cognitive science, 31(3):355   384.
harris, zellig s. 1954. distributional structure. word, 10(2-3):146   162.
hashimoto, tatsunori b., david alvarez-melis, and tommi s. jaakkola. 2016. id27s as metric

recovery in semantic spaces. transactions of the acl, 4:273   286.

he, shizhu, kang liu, guoliang ji, and jun zhao. 2015. learning to represent id13s with

gaussian embedding. in proceedings of cikm, pages 623   632.

hearst, marti a. 1992. automatic acquisition of hyponyms from large text corpora. in proceedings of

coling, pages 539   545.

hendrickx, iris, su nam kim, zornitsa kozareva, preslav nakov, diarmuid    s  aghdha, sebastian pad  ,

marco pennacchiotti, lorenza romano, and stan szpakowicz. 2010. semeval-2010 task 8: multi-way
classi   cation of semantic relations between pairs of nominals. in proceedings of semeval, pages 33   38.
herbelot, aur  lie and mohan ganesalingam. 2013. measuring semantic content in distributional vectors. in

proceedings of acl, pages 440   445.

hill, felix, anna korhonen, and christian bentz. 2014. a quantitative empirical analysis of the

abstract/concrete distinction. cognitive science, 38(1):162   177.

hill, felix, roi reichart, and anna korhonen. 2015. siid113x-999: evaluating semantic models with

(genuine) similarity estimation. computational linguistics, 41(4):665   695.

hodosh, micah, peter young, and julia hockenmaier. 2013. framing image description as a ranking task:

data, models and id74. journal of arti   cial intelligence research, 47:853   899.

holyoak, keith j. 2012. analogy and relational reasoning. the oxford handbook of thinking and reasoning,

pages 234   259.

jackendoff, ray s. 1972. semantic interpretation in generative grammar.
jauhar, sujay kumar, chris dyer, and eduard hovy. 2015. ontologically grounded multi-sense

representation learning for semantic vector space models. in proceedings of naacl-hlt, pages 683   693.

jia, yangqing, evan shelhamer, jeff donahue, sergey karayev, jonathan long, ross b. girshick, sergio

guadarrama, and trevor darrell. 2014. caffe: convolutional architecture for fast feature embedding. in
proceedings of acm multimedia, pages 675   678.

jurgens, david, saif mohammad, peter turney, and keith holyoak. 2012. semeval-2012 task 2: measuring

degrees of relational similarity. in proceedings of semeval, pages 356   364.

kamp, hans and barbara partee. 1995. prototype theory and compositionality. cognition, 57(2):129   191.
kato, makoto p., hiroaki ohshima, satoshi oyama, and katsumi tanaka. 2009. query by analogical
example: relational search using web search engine indices. in proceedings of cikm, pages 27   36.

kiela, douwe and l  on bottou. 2014. learning image embeddings using convolutional neural networks for

improved multi-modal semantics. in proceedings of emnlp, pages 36   45.

kiela, douwe, felix hill, and stephen clark. 2015. specializing id27s for similarity or

relatedness. in proceedings of emnlp, pages 2044   2048.

kiela, douwe, felix hill, anna korhonen, and stephen clark. 2014. improving multi-modal representations

using image dispersion: why less is sometimes more. in proceedings of acl, pages 835   841.

kiela, douwe, laura rimell, ivan vuli  c, and stephen clark. 2015. exploiting image generality for lexical

entailment detection. in proceedings of acl, pages 119   124.

kipper, karin, anna korhonen, neville ryant, and martha palmer. 2008. a large-scale classi   cation of

english verbs. language resources and evaluation, 42(1):21   40.

kopliku, arlind, karen pinel-sauvagnat, and mohand boughanem. 2011. retrieving attributes using web

tables. in proceedings of jcdl, pages 397   398.

korhonen, anna. 2010. automatic lexical classi   cation: bridging research and practice. philosophical

transactions of the royal society of london a: mathematical, physical and engineering sciences,
368(1924):3621   3632.

kotlerman, lili, ido dagan, idan szpektor, and maayan zhitomirsky-geffet. 2010. directional

distributional similarity for lexical id136. natural language engineering, 16(4):359   389.

krizhevsky, alex, ilya sutskever, and geoffrey e. hinton. 2012. id163 classi   cation with deep

convolutional neural networks. in proceedings of nips, pages 1106   1114.

lake, brenden m., ruslan salakhutdinov, jason gross, and joshua b. tenenbaum. 2011. one shot learning

of simple visual concepts. in proceedings of cogsci, pages 2568   2573.

46

vuli  c et al.

hyperlex: a large-scale evaluation of graded lexical entailment

lakoff, george. 1990. women, fire, and dangerous things: what categories reveal about the mind.
lazaridou, angeliki, nghia the pham, and marco baroni. 2015. combining language and vision with a

multimodal skip-gram model. in proceedings of naacl-hlt, pages 153   163.

leacock, claudia and martin chodorow. 1998. combining local context and id138 similarity for word

sense identi   cation. id138: an electronic lexical database, 49(2):265   283.

lenci, alessandro and giulia benotto. 2012. identifying hypernyms in distributional semantic spaces. in

proceedings of *sem, pages 75   79.

leviant, ira and roi reichart. 2015. separated by an un-common language: towards judgment language

informed vector space modeling. corr, abs/1508.00106.

levin, beth. 1993. english verb classes and alternation, a preliminary investigation.
levy, omer, ido dagan, and jacob goldberger. 2014. focused entailment graphs for open ie propositions.

in proceedings of conll, pages 87   97.

levy, omer and yoav goldberg. 2014. dependency-based id27s. in proceedings of acl, pages

levy, omer, yoav goldberg, and ido dagan. 2015. improving distributional similarity with lessons learned

from id27s. transactions of the acl, 3:211   225.

levy, omer, steffen remus, chris biemann, and ido dagan. 2015. do supervised distributional methods

really learn lexical id136 relations? in proceedings of naacl-hlt, pages 970   976.

lin, dekang. 1998. automatic retrieval and id91 of similar words. in proceedings of acl, pages

302   308.

768   774.

lin, yankai, zhiyuan liu, maosong sun, yang liu, and xuan zhu. 2015. learning entity and relation

embeddings for id13 completion. in proceedings of aaai, pages 2181   2187.

liu, quan, hui jiang, si wei, zhen-hua ling, and yu hu. 2015. learning semantic id27s based

on ordinal knowledge constraints. in proceedings of acl, pages 1501   1511.

liu, xueqing, yangqiu song, shixia liu, and haixun wang. 2012. automatic taxonomy construction from

keywords. in proceedings of kdd, pages 1433   1441.

luong, thang, richard socher, and christopher manning. 2013. better word representations with recursive

neural networks for morphology. in proceedings of conll, pages 104   113.

markman, arthur b and edward j wisniewski. 1997. similar and different: the differentiation of basic-level

categories. journal of experimental psychology: learning, memory, and cognition, 23(1).

mcrae, ken, george s. cree, mark s. seidenberg, and chris mcnorgan. 2005. semantic feature production

norms for a large set of living and nonliving things. behavior research methods, 37(4):547   559.

medin, douglas l., mark w. altom, and timothy d. murphy. 1984. given versus induced category

representations: use of prototype and exemplar information in classi   cation. journal of experimental
psychology, 10(3):333   352.

mikolov, tomas, kai chen, gregory s. corrado, and jeffrey dean. 2013a. ef   cient estimation of word

representations in vector space. in proceedings of iclr: workshop papers.

mikolov, tomas, ilya sutskever, kai chen, gregory s. corrado, and jeffrey dean. 2013b. distributed
representations of words and phrases and their compositionality. in proceedings of the 27th annual
conference on advances in neural information processing systems (nips), pages 3111   3119.

miller, george a. 1995. id138: a lexical database for english. communications of the acm, 38(11):39   41.
mohler, michael, david bracewell, marc tomlinson, and david hinote. 2013. semantic signatures for

example-based linguistic metaphor detection. in proceedings of the first workshop on metaphor in nlp,
pages 27   35.

mrk  i  c, nikola, diarmuid    s  aghdha, blaise thomson, milica ga  i  c, lina maria rojas-barahona, pei-hao

su, david vandyke, tsung-hsien wen, and steve j. young. 2016. counter-   tting word vectors to
linguistic constraints. in proceedings of naacl-hlt.

mrk  i  c, nikola, diarmuid    s  aghdha, tsung-hsien wen, blaise thomson, and steve j. young. 2017.

neural belief tracker: data-driven dialogue state tracking. in proceedings of acl.

murphy, lynne m. 2003. semantic relations and the lexicon: antonymy, synonymy and other paradigms.
myers, raymond h. 1990. classical and modern regression with applications (volume 2).
neelakantan, arvind, jeevan shankar, alexandre passos, and andrew mccallum. 2014. ef   cient

non-parametric estimation of multiple embeddings per word in vector space. in proceedings of emnlp,
pages 1059   1069.

nelson, douglas l., cathy l. mcevoy, and thomas a. schreiber. 2004. the university of south florida free

association, rhyme, and word fragment norms. behavior research methods, 36(3):402   407.

nivre et al., joakim. 2015. universal dependencies 1.2. lindat/clarin digital library at institute of

formal and applied linguistics, charles university in prague.

47

ono, masataka, makoto miwa, and yutaka sasaki. 2015. id27-based antonym detection using

thesauri and distributional information. in proceedings of naacl-hlt, pages 984   989.

osherson, daniel n. and edward e. smith. 1981. on the adequacy of prototype theory as a theory of

concepts. cognition, 9(1):35   58.

osherson, daniel n. and edward e. smith. 1997. on typicality and vagueness. cognition, 64(2):189   206.
pad  , sebastian, ulrike pad  , and katrin erk. 2007. flexible, corpus-based modelling of human plausibility

judgements. in proceedings of emnlp-conll, pages 400   409.

paivio, allan. 1991. dual coding theory: retrospect and current status. canadian journal of psychology,

45(3):255.

pantel, patrick and marco pennacchiotti. 2006. espresso: leveraging generic patterns for automatically

harvesting semantic relations. in proceedings of acl, pages 113   120.

parikh, ankur, oscar t  ckstr  m, dipanjan das, and jakob uszkoreit. 2016. a decomposable attention

model for natural language id136. in proceedings of emnlp, pages 2249   2255.

pedersen, ted, siddharth patwardhan, and jason michelizzi. 2004. id138::similarity - measuring the

relatedness of oncepts. in proceedings of aaai, pages 1024   1025.

pereira, jose costa, emanuele coviello, gabriel doyle, nikhil rasiwasia, gert r. g. lanckriet, roger levy,

and nuno vasconcelos. 2014. on the role of correlation and abstraction in cross-modal multimedia
retrieval. ieee transactions on pattern analysis and machine intelligence, 36(3):521   535.

pulman, stephan guy. 1983. word meaning and belief.
quillian, ross m. 1967. word concepts: a theory and simulation of some basic semantic capabilities.

rei, marek and ted briscoe. 2014. looking for hyponyms in vector space. in proceedings of conll, pages

reisinger, joseph and raymond j. mooney. 2010a. a mixture model with sharing for lexical semantics. in

behavioral science, 12(5):410   430.

68   77.

proceedings of emnlp, pages 1173   1182.

reisinger, joseph and raymond j. mooney. 2010b. multi-prototype vector-space models of word meaning.

in proceedings of naacl-hlt, pages 109   117.

resnik, philip. 1995. using information content to evaluate semantic similarity in a taxonomy. in

proceedings of ijcai, pages 448   453.

riedel, sebastian, limin yao, andrew mccallum, and benjamin m. marlin. 2013. id36 with

id105 and universal schemas. in proceedings of naacl-hlt, pages 74   84.

rimell, laura. 2014. distributional lexical entailment by topic coherence. in proceedings of eacl, pages

511   519.

roller, stephen and katrin erk. 2016. relations such as hypernymy: identifying and exploiting hearst
patterns in distributional vectors for lexical entailment. in proceedings of emnlp, pages 2163   2172.

roller, stephen, katrin erk, and gemma boleda. 2014. inclusive yet selective: supervised distributional

hypernymy detection. in proceedings of coling, pages 1025   1036.

rosch, eleanor h. 1973. natural categories. cognitive psychology, 4(3):328   350.
rosch, eleanor h. 1975. cognitive representations of semantic categories. journal of experimental psychology,

104(3):192   233.

rubinstein, dana, ef    levi, roy schwartz, and ari rappoport. 2015. how well do distributional models

capture different types of semantic knowledge? in proceedings of acl, pages 726   730.

russakovsky, olga, jia deng, hao su, jonathan krause, sanjeev satheesh, sean ma, zhiheng huang,

andrej karpathy, aditya khosla, michael s. bernstein, alexander c. berg, and fei-fei li. 2015. id163
large scale visual recognition challenge. international journal of id161, 115(3):211   252.

sacaleanu, bogdan, constantin orasan, christian spurk, shiyan ou, oscar ferrandez, milen kouylekov,

and matteo negri. 2008. entailment-based id53 for structured data. in proceedings of
coling, pages 173   176.

santus, enrico, alessandro lenci, qin lu, and sabine schulte im walde. 2014. chasing hypernyms in

vector spaces with id178. in proceedings of eacl, pages 38   42.

santus, enrico, frances yung, alessandro lenci, and chu-ren huang. 2015. evalution 1.0: an evolving
semantic dataset for training and evaluation of distributional semantic models. in proceedings of the 4th
workshop on linked data in linguistics: resources and applications, pages 64   69.

schnabel, tobias, igor labutov, david m. mimno, and thorsten joachims. 2015. evaluation methods for

unsupervised id27s. in proceedings of emnlp, pages 298   307.

schwartz, roy, roi reichart, and ari rappoport. 2015. symmetric pattern based id27s for

improved word similarity prediction. in proceedings of conll, pages 258   267.

shwartz, vered, yoav goldberg, and ido dagan. 2016. improving hypernymy detection with an integrated

path-based and distributional method. in proceedings of acl, pages 2389   2398.

48

vuli  c et al.

hyperlex: a large-scale evaluation of graded lexical entailment

shwartz, vered, omer levy, ido dagan, and jacob goldberger. 2015. learning to exploit structured

resources for lexical id136. in proceedings of conll, pages 175   184.

shwartz, vered, enrico santus, and dominik schlechtweg. 2017. hypernyms under siege:

linguistically-motivated artillery for hypernymy detection. in proceedings of eacl, pages 65   75.

silberer, carina and mirella lapata. 2012. grounded models of semantic representation. in proceedings of

silberer, carina and mirella lapata. 2014. learning grounded meaning representations with autoencoders.

simonyan, karen and andrew zisserman. 2015. very deep convolutional networks for large-scale image

emnlp, pages 1423   1433.

in proceedings of acl, pages 721   732.

recognition. in proceedings of iclr.

snow, rion, daniel jurafsky, and andrew y. ng. 2004. learning syntactic patterns for automatic hypernym

discovery. in proceedings of nips, pages 1297   1304.

snow, rion, daniel jurafsky, and andrew y. ng. 2006. semantic taxonomy induction from heterogenous

evidence. in proceedings of acl, pages 801   808.

socher, richard, danqi chen, christopher d. manning, and andrew y. ng. 2013. reasoning with neural

tensor networks for knowledge base completion. in proceedings of nips, pages 926   934.

socher, richard, andrej karpathy, quoc v. le, christopher d. manning, and andrew y. ng. 2014.

grounded id152 for    nding and describing images with sentences. transactions of the
acl, 2:207   218.

song, yangqiu, haixun wang, zhongyuan wang, hongsong li, and weizhu chen. 2011. short text
conceptualization using a probabilistic knowledgebase. in proceedings of aaai, pages 2330   2336.

suchanek, fabian m., gjergji kasneci, and gerhard weikum. 2007. yago: a core of semantic knowledge. in

proceedings of www, pages 697   706.

tanon, thomas pellissier, denny vrande  ci  c, sebastian schaffert, thomas steiner, and lydia pintscher. 2016.

from freebase to wikidata: the great migration. in proceedings of www, pages 1419   1428.

taylor, john r. 2003. linguistic categorization.
tsvetkov, yulia, manaal faruqui, wang ling, guillaume lample, and chris dyer. 2015. evaluation of word

vector representations by subspace alignment. in proceedings of emnlp, pages 2049   2054.

turney, peter d. 2006. similarity of semantic relations. computational linguistics, 32(3):379   416.
turney, peter d. and saif m. mohammad. 2015. experiments with three approaches to recognizing lexical

entailment. natural language engineering, 21(3):437   476.

turney, peter d. and patrick pantel. 2010. from frequency to meaning: vector space models of semantics.

journal of arti   cial intelligence research, 37:141   188.

van benthem, johan and alice ter meulen. 1996. handbook of logic and language.
vendrov, ivan, ryan kiros, sanja fidler, and raquel urtasun. 2016. order-embeddings of images and

language. in proceedings of iclr.

iclr.

vilnis, luke and andrew mccallum. 2015. word representations via gaussian embedding. in proceedings of

  uster, simon, ivan titov, and gertjan van noord. 2016. bilingual learning of multi-sense embeddings with

discrete autoencoders. in proceedings of naacl-hlt, pages 1346   1356.

vuli  c, ivan and anna korhonen. 2016. is    universal syntax    universally useful for learning distributed

word representations? in proceedings of acl.

vuli  c, ivan, nikola mrk  i  c, roi reichart, diarmuid    s  aghdha, steve young, and anna korhonen. 2017.
morph-   tting: fine-tuning word vector spaces with simple language-speci   c rules. in proceedings of acl.
vylomova, ekaterina, laura rimell, trevor cohn, and timothy baldwin. 2016. take and took, gaggle and

goose, book and read: evaluating the utility of vector differences for lexical relation learning. in
proceedings of acl.

weeds, julie, daoud clarke, jeremy ref   n, david weir, and bill keller. 2014. learning to distinguish

hypernyms and co-hyponyms. in proceedings of coling, pages 2249   2259.

weeds, julie and david weir. 2003. a general framework for distributional similarity. in proceedings of

emnlp, pages 81   88.

weeds, julie, david weir, and diana mccarthy. 2004. characterising measures of lexical distributional

similarity. in proceedings of coling, pages 1015   1021.

wieting, john, mohit bansal, kevin gimpel, and karen livescu. 2015. from paraphrase database to

compositional paraphrase model and back. transactions of the acl, 3:345   358.

wu, wentao, hongsong li, haixun wang, and kenny q. zhu. 2012. probase: a probabilistic taxonomy for

text understanding. in proceedings of sigmod, pages 481   492.

wu, zhibiao and martha palmer. 1994. verb semantics and lexical selection. in proceedings of acl, pages

133   138.

49

yaghoobzadeh, yadollah and hinrich sch  tze. 2016. intrinsic subspace evaluation of id27

representations. in proceedings of acl, pages 236   246.

yih, scott wen-tau, geoffrey zweig, and john c. platt. 2012. polarity inducing latent semantic analysis. in

proceedings of emnlp, pages 1212   1222.

young, peter, alice lai, micah hodosh, and julia hockenmaier. 2014. from image descriptions to visual
denotations: new similarity metrics for semantic id136 over event descriptions. transactions of the
acl, 2:67   78.

yu, mo and mark dredze. 2014. improving lexical embeddings with semantic knowledge. in proceedings of

acl, pages 545   550.

zhila, alisa, wen-tau yih, christopher meek, geoffrey zweig, and tomas mikolov. 2013. combining

heterogeneous models for measuring relational similarity. in proceedings of naacl-hlt, pages
1000   1009.

zhitomirsky-geffet, maayan and ido dagan. 2009. id64 distributional feature vector quality.

computational linguistics, 35(3):435   461.

50

