6
1
0
2

 
r
p
a
1
1

 

 
 
]
l
c
.
s
c
[
 
 

1
v
4
1
1
3
0

.

4
0
6
1
:
v
i
x
r
a

conversational flow in oxford-style debates

justine zhang,1 ravi kumar,2 sujith ravi,2 cristian danescu-niculescu-mizil1

1cornell university, 2google

jz727@cornell.edu, ravi.k53@gmail.com,

ravi.sujith@gmail.com, cristian@cs.cornell.edu

abstract

public debates are a common platform for pre-
senting and juxtaposing diverging views on
important issues. in this work we propose a
methodology for tracking how ideas    ow be-
tween participants throughout a debate. we
use this approach in a case study of oxford-
style debates   a competitive format where the
winner is determined by audience votes   and
show how the outcome of a debate depends
on aspects of conversational    ow. in particu-
lar, we    nd that winners tend to make better
use of a debate   s interactive component than
losers, by actively pursuing their opponents   
points rather than promoting their own ideas
over the course of the conversation.

introduction

1
public debates are a common platform for present-
ing and juxtaposing diverging viewpoints as op-
posed to monologues where speakers are limited
to expressing their own beliefs, debates allow for
participants to interactively attack their opponents   
points while defending their own. the resulting    ow
of ideas is a key feature of this conversation genre.
in this work we introduce a computational frame-
work for characterizing debates in terms of conver-
sational    ow. this framework captures two main de-
bating strategies   promoting one   s own points and
attacking the opponents    points   and tracks their
relative usage throughout the debate. by applying
this methodology to a setting where debate winners
are known, we show that conversational    ow pat-
terns are predictive of which debater is more likely
to persuade an audience.

case study: oxford-style debates. oxford-style
debates provide a setting that is particularly conve-
nient for studying the effects of conversational    ow.
in this competitive debate format, two teams argue
for or against a preset motion in order to persuade
a live audience to take their position. the audience
votes before and after the debate, and the winning
team is the one that sways more of the audience to-
wards its view. this setup allows us to focus on the
effects of conversational    ow since it disentangles
them from the audience   s prior leaning.1

the debate format involves an opening statement
from the two sides, which presents an overview of
their arguments before the discussion begins. this
allows us to easily identify talking points held by
the participants prior to the interaction, and con-
sider them separately from points introduced spon-
taneously to serve the discussion.

this work is taking steps towards better model-
ing of conversational dynamics, by: (i) introducing
a debate dataset with rich metadata (section 2), (ii)
proposing a framework for tracking the    ow of ideas
(section 3), and (iii) showing its effectiveness in a
predictive setting (section 4).

2 debate dataset: intelligence squared

in this study we use transcripts and results of
oxford-style debates from the public debate series
   intelligence squared debates    (iq2 for short).2
these debates are recorded live, and contain mo-
tions covering a diversity of topics ranging from for-

1other potential confounding factors are mitigated by the

tight format and topic enforced by the debate   s moderator.

2http://www.intelligencesquaredus.org

eign policy issues to the bene   ts of organic food.
each debate consists of two opposing teams   one
for the motion and one against   of two or three ex-
perts in the topic of the particular motion, along with
a moderator. each debate follows the oxford-style
format and consists of three rounds. in the introduc-
tion, each debater is given 7 minutes to lay out their
main points. during the discussion, debaters take
questions from the moderator and audience, and re-
spond to attacks from the other team. this round
lasts around 30 minutes and is highly interactive;
teams frequently engage in direct conversation with
each other. finally, in the conclusion, each debater
is given 2 minutes to make    nal remarks.

our dataset consists of the transcripts of all de-
bates held by iq2 in the us from september 2006
up to september 2015; in total, there are 108 de-
bates.3 each debate is quite extensive: on average,
12801 words are uttered in 117 turns by members of
either side per debate.4
winning side labels. we follow iq2   s criteria for
deciding who wins a debate, as follows. before the
debate, the live audience votes on whether they are
for, against, or undecided on the motion. a sec-
ond round of voting occurs after the debate. a side
wins the debate if the difference between the per-
centage of votes they receive post- and pre-debate
(the    delta   ) is greater than that of the other side   s.
often the debates are quite tight: for 30% of the de-
bates, the difference between the winning and losing
sides    deltas is less than 10%.
audience feedback. we check that the voting re-
sults are meaningful by verifying that audience reac-
tions to the debaters are related to debate outcome.
using laughter and applause received by each side
in each round5 as markers of positive reactions, we
note that differences in audience reception of the two
sides emerge over the course of the debate. while
both sides get similar levels of reaction during the
introduction, winning teams tend to receive more
laughter during the discussion (p < 0.001)6 and
more applause during the conclusion (p = 0.05).

3we omitted one debate due to pdf parsing errors.
4the processed data is available at http://www.cs.

cornell.edu/  cristian/debates/.

5laughter and applause are indicated in the transcripts.
6unless otherwise indicated, all reported p-values are calcu-

lated using the wilcoxon signed-rank test.

example debate. we will use a debate over the mo-
tion    millennials don   t stand a chance    (henceforth
millennials) as a running example.7 the for side
won the debate with a delta of 20% of the votes,
compared to the against side which only gained 5%.

3 modeling idea flow
promoting one   s own points and addressing the op-
ponent   s points are two primary debating strategies.
here we introduce a methodology to identify these
strategies, and use it to investigate their usage and
effect on a debate   s outcome.8
identifying talking points. we    rst focus on ideas
which form the basis of a side   s stance on the mo-
tion. we identify such talking points by consider-
ing words whose frequency of usage differs signif-
icantly between the two teams during the introduc-
tion, before any interaction takes place. to    nd these
words, we use the method introduced by monroe et
al. (2008) in the context of u.s. senate speeches.
in particular, we estimate the divergence between
the two sides    word-usage in the introduction, where
word-usage is modeled as multinomial distributions
smoothed with a uniform dirichlet prior, and diver-
gence is given by log-odds ratio. the most discrim-
inating words are those with the highest and lowest
z-scores of divergence estimates. for a side x, we
de   ne the set of talking points wx to be the k words
with the highest or lowest z-scores.9 we distinguish
between x   s own talking points wx, and the oppos-
ing talking points wy belonging to its opponent y .
these are examples of talking points for the    mil-
lennials    debate:

side
for
against

talking points

debt, boomer, college, reality

economy, volunteer, home, engage

the    ow of talking points. a side can either pro-
mote its own talking points, address its opponent   s
points, or steer away from these initially salient

7http://www.intelligencesquaredus.

org/debates/past-debates/item/
1019-millennials-dont-stand-a-chance

8in the subsequent discussion, we treat all utterances of a
particular side as coming from a single speaker and defer mod-
eling interactions within teams to future work.

9in order to focus on concepts central to the sides    argu-
ments, we discard stopwords, perform id30 on the text,
and take k = 20. we set these parameters by examining one
subsequently discarded debate.

talking point
introduction

discussion

volunteer

boomer

against: [millennials] volunteer more than any
generation. 73 percent of millennials volunteered for
a nonpro   t in 2012. and the percentage of [students]
believing that it   s [...]
important to help people in
need is [at the highest level] in 40 years.
for: i   d make the argument [that] volunteering [is
done] for exntrinsic [sic] reasons. so, it   s done for
college applications, or it   s done because it   s a re-
quirement in high school.

[referring to college completion rate]

for:
the
boomer generation is now [at] 32 percent. [millen-
nials] are currently at [...] 33 percent. so this notion
that [millennials] have more education at this point in
time than anybody else is not actually true.
for: it stinks to be young, having gone through what
your generation [referring to millennials] has gone
through. but keep in mind that [...] have gone through
the same.

table 1: example talking points used throughout the    millennials    debate. each talking point belongs to the
side uttering the    rst excerpt, taken from the introduction; the second excerpt is from the discussion section.
in the    rst example, the for side addresses the opposing talking point volunteer during the discussion; in the
second example the for side refers to their own talking point boomer and recalls it later in the discussion.

does the change in focus translate to any strategic
advantages? figure 1 suggests this is the case: the
drop in self-coverage is slightly larger for the side
that eventually wins the debate (p = 0.08). the
drop in the sum of self- and opponent-coverage is
also larger for winning teams, suggesting that they
are more likely to steer away from discussing any
talking points from either side (p = 0.05).
identifying discussion points. having seen that
debaters can bene   t by shifting away from talking
points that were salient during the introduction, we
now examine the ideas that spontaneously arise to
serve the discussion. we model such discussion
points as words introduced to the debate during the
discussion by a debater and adopted by his oppo-
nents at least twice.10 this allows us to focus on
words that become relevant to the conversation; only
3% of all newly introduced words qualify, amount-
ing to about 10 discussion points per debate.
the    ow of discussion points. the adoption of dis-
cussion points plays an important role in persuad-
ing the audience: during the discussion, eventual
winners adopt more discussion points introduced by
their opponents than eventual losers (p < 0.01).
two possible strategic interpretations emerge. from
a topic control angle (nguyen et al., 2014), perhaps
losers are more successful at imposing their discus-
sion points to gain control of the discussion. this
view appears counterintuitive given work linking
topic control to in   uence in other settings (planalp
and tracy, 1980; rienks et al., 2006).

10ignoring single repetitions discards simple echoing of

words used by the previous speaker.

figure 1: the start of the debate   s interactive stage
triggers a drop in self-coverage (> 0, indicated by
leftmost two bars) and a rise in opponent-coverage
(< 0, indicated by rightmost bars), with eventual
winners showing a more pronounced drop in self-
coverage (comparing the two bars on the left).

ideas altogether. we quantify the use of these strate-
gies by comparing the airtime debaters devote to
talking points. for a side x, let the self-coverage
fr(x, x) be the fraction of content words uttered
by x in round r that are among their own talking
points wx; and the opponent-coverage fr(x, y ) be
the fraction of its content words covering opposing
talking points wy .

not surprisingly, we    nd that self-coverage
dominates during the discussion (fdisc(x, x) >
fdisc(x, y ), p < 0.001). however, this does not
mean debaters are simply giving monologues and
ignoring each other: the effect of the interaction is
re   ected in a sharp drop in self-coverage and a rise
in opponent-coverage once the discussion round be-
gins. respectively, fdisc(x, x) < fintro(x, x)
and fdisc(x, y ) > fintro(x, y ), both p < 0.001.
examples of self- and opponent-coverage of two
talking points in the    millennials    debate from the
introduction and discussion are given in table 1.

against: i would say [millennials] are effectively
moving towards goals [...]
it might seem like imma-
turity if you don   t actually talk to millennials and look
at the statistics.
for:    actually, the numbers are showing [...] that it   s
worsening [...] same statistics, dreadful statistics.
against: [...] there   s a incredible [sic] advantage that
millennials have when it comes to social media [...] be-
cause we have an understanding of that landscape as
digital natives [...]
for: generation x [...] is also known as the digital
generation. the companies [...] that make you digital
natives were all founded by [...] people in generation x.
it   s simply inaccurate every time somebody says that
the millennial generation is the only generation [...]

table 2: example discussion points introduced by
the against side in the    millennials    debate. for
each point, the    rst excerpt is the context in which
the point was    rst mentioned by the against side in
the discussion, and the second excerpt shows the for
side challenging the point later on.

an alternative interpretation could be that winners
are more active than losers in contesting their oppo-
nents    points, a strategy that might play out favor-
ably to the audience. a post-hoc manual examina-
tion supports this interpretation: 78% of the valid
discussion points are picked up by the opposing side
in order to be challenged;11 this strategy is exem-
pli   ed in table 2. overall, these observations tying
the    ow of discussion points to the debate   s outcome
suggest that winners are more successful at using the
interaction to engage with their opponents    ideas.

4 predictive power

we evaluate the predictive power of our    ow fea-
tures in a binary classi   cation setting:
predict
whether the for or against side wins the debate.12
this is a challenging task even for humans, thus the
dramatic reveal at the end of each iq2 debate that
partly explains the popularity of the show. our goal

11three annotators (including one author) informally anno-
tated a random sample of 50 discussion points in the context of
all dialogue excerpts where the point was used. according to a
majority vote, in 26 cases the opponents challenged the point,
in 7 cases the point was supported, 4 cases were unclear, and
in 13 cases the annotators deemed the discussion point invalid.
we discuss the last category in section 6.

12the task is balanced: after removing three debates ending

in a tie, we have 52 debates won by for and 53 by against.

here is limited to understanding which of the    ow
features that we developed carry predictive power.
conversation    ow features. we use all conversa-
tional features discussed above. for each side x we
include fdisc(x, x), fdisc(x, y ), and their sum.
we also use the drop in self-coverage given by sub-
tracting corresponding values for fintro(  ,  ), and the
number of discussion points adopted by each side.
we call these the flow features.
baseline features. to discard the possibility that
our results are simply explained by debater ver-
bosity, we use the number of words uttered and num-
ber of turns taken by each side (length) as baselines.
we also compare to a unigram baseline (bow).
audience features. we use the counts of applause
and laughter received by each side (described in sec-
tion 2) as rough indicators of how well the audience
can foresee a debate   s outcome.

prediction accuracy is evaluated using a leave-
one-out (loo) approach. we use logistic regres-
sion; model parameters for each loo train-test split
are selected via 3-fold cross-validation on the train-
ing set. to    nd particularly predictive    ow features,
we also try using univariate feature selection on the
   ow features before the model is    tted in each split;
we refer to this setting as flow*.13

we    nd that conversation    ow features obtain the
best accuracy among all listed feature types (flow:
63%; flow*: 65%), performing signi   cantly higher
than a 50% random baseline (binomial test p <
0.05), and comparable to audience features (60%).
in contrast, the length and bow baselines do not
perform better than chance. we note that flow fea-
tures perform competitively despite being the only
ones that do not factor in the concluding round.

the features selected most often in the flow* task
are: the number of discussion points adopted (with
positive regression coef   cients), the recall of talk-
ing points during the discussion round (negative co-
ef   cients), and the drop in usage of own talking
points from introduction to discussion (positive co-
ef   cients). the relative importance of these features,
which focus on the interaction between teams, sug-
gests that audiences tend to favor debating strategies
which emphasize the discussion.

13we optimize the regularizer ((cid:96)1 or (cid:96)2), and the value of the
id173 parameter c (between 10   5 and 105). for flow*
we also optimize the number of features selected.

5 further related work

previous work on conversational structure has pro-
posed approaches to model dialogue acts (samuel et
al., 1998; ritter et al., 2010; ferschke et al., 2012)
or disentangle interleaved conversations (elsner and
charniak, 2010; elsner and charniak, 2011). other
research has considered the problem of detecting
conversation-level traits such as the presence of dis-
agreements (allen et al., 2014; wang and cardie,
2014) or the likelihood of relation dissolution (nic-
ulae et al., 2015). at the participant level, several
studies present approaches to identify ideological
stances (somasundaran and wiebe, 2010; rosenthal
and mckeown, 2015), using features based on par-
ticipant interactions (thomas et al., 2006; sridhar
et al., 2015), or extracting words and reasons char-
acterizing a stance (monroe et al., 2008; nguyen
et al., 2010; hasan and ng, 2014). in our setting,
both the stances and the turn structure of a debate
are known, allowing us to instead focus on the de-
bate   s outcome.

existing research on argumentation strategies has
largely focused on exploiting the structure of mono-
logic arguments (mochales and moens, 2011), like
those of persuasive essays (feng and hirst, 2011;
stab and gurevych, 2014). in addition, tan et al.
(2016) has examined the effectiveness of arguments
in the context of a forum where people invite oth-
ers to challenge their opinions.we complement this
line of work by looking at the relative persuasiveness
of participants in extended conversations as they ex-
change arguments over multiple turns.

previous studies of in   uence in extended con-
versations have largely dealt with the political do-
main, examining moderated but relatively unstruc-
tured settings such as talk shows or presidential
debates, and suggesting features like topic control
(nguyen et al., 2014),
linguistic style matching
(romero et al., 2015) and turn-taking (prabhakaran
et al., 2013). with persuasion in mind, our work ex-
tends these studies to explore a new dynamic, the
   ow of ideas between speakers, in a highly struc-
tured setting that controls for confounding factors.

6 limitations and future work

this study opens several avenues for future research.
one could explore more complex representations of

talking points and discussion points, for instance
using topic models or id27s. further-
more, augmenting the    ow of content in a conversa-
tion with the speakers    linguistic choices could bet-
ter capture their intentions. in addition, it would be
interesting to study the interplay between our con-
versational    ow features and relatively monologic
features that consider the argumentative and rhetor-
ical traits of each side separately. more explicitly
comparing and contrasting monologic and interac-
tive dynamics could lead to better models of con-
versations. such approaches could also help clar-
ify some of the intuitions about conversations ex-
plored in this work, particularly that engaging in di-
alogue carries different strategic implications from
self-promotion.

our focus in this paper is on capturing and under-
standing conversational    ow. we hence make some
simplifying assumptions that could be re   ned in fu-
ture work. for instance, by using a basic unigram-
based de   nition of discussion points, we do not ac-
count for the context or semantic sense in which
these points occur.
in particular, our annotators
found that a signi   cant proportion of the discussion
points under our de   nition actually referred to dif-
fering ideas in the various contexts in which they
appeared. we expect that improving our retrieval
model will also improve the robustness of our idea
   ow analysis. a better model of discussion points
could also provide more insight into the role of these
points in persuading the audience.

while oxford-style debates are a particularly con-
venient setting for studying the effects of conversa-
tional    ow, our dataset is limited in terms of size. it
would be worthwhile to examine the    ow features
we developed in the context of settings with richer
incentives beyond persuading an audience, such as
in the semi-cooperative environment of wikipedia
talk pages. finally, our methodology could point
to applications in areas such as education and co-
operative work, where it is key to establish the link
between conversation features and an interlocutor   s
ability to convey their point (niculae and danescu-
niculescu-mizil, 2016).
acknowledgements. we thank the reviewers and v.
niculae for their helpful comments, and i. arawjo
and d. sedra for annotations. this work was sup-
ported in part by a google faculty research award.

alan ritter, colin cherry, and bill dolan. 2010. un-
supervised modeling of twitter conversations. in pro-
ceedings of naacl.

daniel m romero, roderick i swaab, brian uzzi, and
adam d galinsky. 2015. mimicry is presidential:
linguistic style matching in presidential debates and
improved polling numbers. personality and social
psychology bulletin, 41(10):1311   1319.
sara rosenthal and kathleen mckeown.

i
couldn   t agree more: the role of conversational struc-
ture in agreement and disagreement detection in online
discussions. in proceedings of sigdial.

2015.

ken samuel, sandra carberry, and k. vijay-shanker.
1998. dialogue act tagging with transformation-based
learning. in proceedings of acl.

swapna somasundaran and janyce wiebe. 2010. rec-
ognizing stances in ideological on-line debates.
in
proceedings of the naacl hlt 2010 workshop on
computational approaches to analysis and genera-
tion of emotion in text.

dhanya sridhar, james foulds, bert huang, lise getoor,
and marilyn walker. 2015. joint models of disagree-
ment and stance in online debate. in proceedings of
acl.

christian stab and iryna gurevych. 2014. identifying
argumentative discourse structures in persuasive es-
says. in proceedings of emnlp.

chenhao tan, vlad niculae, cristian danescu-
niculescu-mizil, and lillian lee. 2016. winning
arguments:
interaction dynamics and persuasion
strategies in good-faith online discussions.
in
proceedings of www.

matt thomas, bo pang, and lillian lee. 2006. get out
the vote: determining support or opposition from con-
gressional    oor-debate transcripts. in proceedings of
emnlp.

lu wang and claire cardie. 2014. a piece of my mind:
a id31 approach for online dispute de-
tection. in proceedings of acl.

references
kelsey allen, giuseppe carenini, and raymond t ng.
2014. detecting disagreement in conversations using
in proceed-
pseudo-monologic rhetorical structure.
ings of emnlp.

micha elsner and eugene charniak. 2010. disentan-
gling chat. computational linguistics, 36(3):389   
409.

micha elsner and eugene charniak. 2011. disentan-
gling chat with local coherence models. in proceed-
ings of acl.

vanessa wei feng and graeme hirst. 2011. classifying

arguments by scheme. in proceedings of acl.

oliver ferschke, iryna gurevych, and yevgen chebotar.
2012. behind the article: recognizing dialog acts in
wikipedia talk pages. in proceedings of eacl.

kazi saidul hasan and vincent ng. 2014. why are you
taking this stance? identifying and classifying reasons
in ideological debates. in proceedings of emnlp.

raquel mochales and marie-francine moens. 2011. ar-
gumentation mining. arti   cial intelligence and law,
19(1):1   22.

burt l. monroe, michael p. colaresi, and kevin m.
quinn. 2008. fightin   words: lexical feature selec-
tion and evaluation for identifying the content of polit-
ical con   ict. political analysis, 16(4):372   403.

dong nguyen, elijah may   eld, and carolyn p ros  e.
2010. an analysis of perspectives in interactive set-
tings. in proceedings of the kdd 2010 workshop on
social media analytics.

viet-an nguyen, jordan boyd-graber, philip resnik,
deborah a cai, jennifer e midberry, and yuanxin
wang. 2014. modeling topic control to detect in   u-
ence in conversations using nonparametric topic mod-
els. machine learning, 95(3):381   421.

vlad niculae and cristian danescu-niculescu-mizil.
2016. conversational markers of constructive discus-
sions. in proceedings of naacl.

vlad niculae, srijan kumar, jordan boyd-graber, and
cristian danescu-niculescu-mizil. 2015. linguistic
harbingers of betrayal: a case study on an online strat-
egy game. in proceedings of acl.

sally planalp and karen tracy. 1980. not to change the
subject but: a cognitive approach to the management
of conversation. communication yearbook, 4:680   
690.

vinodkumar prabhakaran, ajita john, and dor  ee d.
seligmann. 2013. who had the upper hand? rank-
ing participants of interactions based on their relative
power. in proceedings of ijcnlp.

rutger rienks, dong zhang, daniel gatica-perez, and
wilfried post. 2006. detection and application of in-
   uence rankings in small group meetings. in proceed-
ings of icmi.

