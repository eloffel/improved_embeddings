foundations and trends r(cid:1) in
databases
vol. 1, no. 3 (2007) 261   377
c(cid:1) 2008 s. sarawagi
doi: 10.1561/1500000003

information extraction

sunita sarawagi

indian institute of technology, cse, mumbai 400076, india,
sunita@iitb.ac.in

abstract

the automatic extraction of information from unstructured sources has
opened up new avenues for querying, organizing, and analyzing data
by drawing upon the clean semantics of structured databases and the
abundance of unstructured data. the    eld of information extraction
has its genesis in the natural language processing community where the
primary impetus came from competitions centered around the recog-
nition of named entities like people names and organization from news
articles. as society became more data oriented with easy online access
to both structured and unstructured data, new applications of struc-
ture extraction came around. now, there is interest in converting our
personal desktops to structured databases, the knowledge in scien-
ti   c publications to structured records, and harnessing the internet for
structured fact    nding queries. consequently, there are many di   erent
communities of researchers bringing in techniques from machine learn-
ing, databases, information retrieval, and computational linguistics for
various aspects of the information extraction problem.

this review is a survey of information extraction research of over
two decades from these diverse communities. we create a taxonomy
of the    eld along various dimensions derived from the nature of the

extraction task, the techniques used for extraction, the variety of input
resources exploited, and the type of output produced. we elaborate on
rule-based and statistical methods for entity and relationship extrac-
tion. in each case we highlight the di   erent kinds of models for cap-
turing the diversity of clues driving the recognition process and the
algorithms for training and e   ciently deploying the models. we survey
techniques for optimizing the various steps in an information extraction
pipeline, adapting to dynamic data, integrating with existing entities
and handling uncertainty in the extraction process.

1

introduction

information extraction refers to the automatic extraction of struc-
tured information such as entities, relationships between entities, and
attributes describing entities from unstructured sources. this enables
much richer forms of queries on the abundant unstructured sources
than possible with keyword searches alone. when structured and
unstructured data co-exist, information extraction makes it possible
to integrate the two types of sources and pose queries spanning them.
the extraction of structure from noisy, unstructured sources is a
challenging task, that has engaged a veritable community of researchers
for over two decades now. with roots in the natural language process-
ing (nlp) community, the topic of structure extraction now engages
many di   erent communities spanning machine learning, information
retrieval, database, web, and document analysis. early extraction tasks
were concentrated around the identi   cation of named entities, like
people and company names and relationship among them from nat-
ural
language text. the scope of this research was strongly in   u-
enced by two competitions, the message understanding conference
(muc) [57, 100, 198] and automatic content extraction (ace) [1, 159]
program. the advent of the internet considerably increased the extent
and diversity of applications depending on various forms of information

263

264 introduction

extraction. applications such as comparison shopping, and other
automatic portal creation applications, lead to a frenzy of research
and commercial activity on the topic. as society became more data
oriented with easy online access to both structured and unstructured
data, new applications of structure extraction came around.

to address the needs of these diverse applications, the techniques
of structure extraction have evolved considerably over the last
two decades. early systems were rule-based with manually coded
rules [10, 127, 181]. as manual coding of rules became tedious,
algorithms for automatically learning rules from examples were
developed [7, 43, 60, 195]. as extraction systems were targeted on
more noisy unstructured sources, rules were found to be too brittle.
then came the age of statistical learning, where in parallel two kinds
of techniques were deployed: generative models based on hidden
markov models [3, 20, 25, 189] and conditional models based on
maximum id178 [26, 118, 135, 143, 177]. both were superseded
by global conditional models, popularly called conditional random
fields [125]. as the scope of extraction systems widened to require
a more holistic analysis of a document   s structure, techniques from
grammar construction [191, 213] were developed. in spite of this
journey of varied techniques, there is no clear winner. rule-based
methods [72, 113, 141, 190] and statistical methods [32, 72, 146, 220]
continue to be used in parallel depending on the nature of the extrac-
tion task. there also exist hybrid models [42, 59, 70, 89, 140, 173] that
attempt to reap the bene   ts of both statistical and rule-based methods.

1.1 applications

structure extraction is useful in a diverse set of applications. we list a
representative subset of these, categorized along whether the applica-
tions are enterprise, personal, scienti   c, or web-oriented.

1.1.1 enterprise applications
news tracking: a classical application of information extraction,
which has spurred a lot of the early research in the nlp commu-
nity, is automatically tracking speci   c event types from news sources.

1.1 applications

265

the popular muc [57, 100, 198] and ace [1] competitions are based
on the extraction of structured entities like people and company
names, and relations such as    is-ceo-of    between them. other pop-
ular tasks are: tracking disease outbreaks [99], and terrorist events
from news sources. consequently there are several research publica-
tions [71, 98, 209] and many research prototypes [10, 73, 99, 181] that
target extraction of named entities and their relationship from news
articles. two recent applications of information extraction on news
articles are: the automatic creation of multimedia news by integrat-
ing video and pictures of entities and events annotated in the news
articles,1 and hyperlinking news articles to background information on
people, locations, and companies.2
customer care: any customer-oriented enterprise collects many
forms of unstructured data from customer interaction; for e   ective
management these have to be closely integrated with the enterprise   s
own structured databases and business ontologies. this has given rise
to many interesting extraction problems such as the identi   cation of
product names and product attributes from customer emails, linking of
customer emails to a speci   c transaction in a sales database [19, 44], the
extraction of merchant name and addresses from sales invoices [226],
the extraction of repair records from insurance claim forms [168],
the extraction of customer moods from phone conversation tran-
scripts [112], and the extraction of product attribute value pairs from
textual product descriptions [97].
data cleaning: an essential step in all data warehouse cleaning pro-
cesses is converting addresses that are stored as    at strings into their
structured forms such as road name, city, and state. large customer-
oriented organizations like banks, telephone companies, and universities
store millions of addresses. in the original form, these addresses have
little explicit structure. often for the same person, there are di   erent
address records stored in di   erent databases. during warehouse con-
struction, it is necessary to put all these addresses in a standard canon-
ical format where all the di   erent    elds are identi   ed and duplicates

1 http://spotlight.reuters.com/.
2 http://www.linkedfacts.com.

266 introduction

removed. an address record broken into its structured    elds not only
enables better querying, it also provides a more robust way of doing
deduplication and householding     a process that identi   es all addresses
belonging to the same household [3, 8, 25, 187].
classi   ed ads: classi   ed ads and other listings such as restau-
rant lists is another domain with implicit structure that when
exposed can be invaluable for querying. many researchers have speci   -
cally targeted such record-oriented data in their extraction research
[150, 156, 157, 195].

1.1.2 personal information management

personal information management (pim) systems seek to organize per-
sonal data like documents, emails, projects and people in a structured
inter-linked format [41, 46, 74]. the success of such systems will depend
on being able to automatically extract structure from existing predom-
inantly    le-based unstructured sources. thus, for example we should
be able to automatically extract from a powerpoint    le, the author
of a talk and link the person to the presenter of a talk announced
in an email. emails, in particular, have served as testbeds for many
extraction tasks such as locating mentions of people names and phone
numbers [113, 152], and inferring request types in service centers [63].

1.1.3 scienti   c applications

the recent rise of the    eld of bio-informatics has broadened the scope
of earlier extractions from named entities, to biological objects such as
proteins and genes. a central problem is extracting from paper reposito-
ries such as pubmed, protein names, and their interaction [22, 32, 166].
since the form of entities like gene and protein names is very di   erent
from classical named entities like people and companies, this task has
helped to broaden the techniques used for extraction.

1.1.4 web oriented applications

citation databases: many citation databases on the web have been
created through elaborate structure extraction steps from sources

1.1 applications

267

ranging from conference web sites to individual home pages. popular
amongst these are citeseer [126], google scholar3 and cora [144]. the
creation of such databases requires structure extraction at many di   er-
ent levels starting from navigating web sites for locating pages contain-
ing publication records, extracting individual publication records from
a html page, extracting title, authors, and references from paper
pdfs, and segmenting citation strings into individual authors, title,
venue, and year    elds. the resulting structured database provides sig-
ni   cant value added in terms of allowing forward references, and aggre-
gate statistics such as author-level citation counts.

opinion databases: there are innumerable web sites storing unmod-
erated opinions about a range of topics, including products, books,
movies, people, and music. many of the opinions are in free text form
hidden behind blogs, newsgroup posts, review sites, and so on. the
value of these reviews can be greatly enhanced if organized along struc-
tured    elds. for example, for products it might be useful to    nd out for
each feature of the product, the prevalent polarity of opinion [131, 167].
see [160] for a recent survey.

community websites: another example of the creation of struc-
tured databases from web documents is community web sites such as
dblife [78] and rexa4 that tracks information about researchers, con-
ferences, talks, projects, and events relevant to a speci   c community.
the creation of such structured databases requires many extraction
steps: locating talk announcements from department pages, extracting
names of speakers and titles from them [189], extracting structured
records about a conference from a website [111], and so on.

comparison shopping: there is much interest in creating comparison
shopping web sites that automatically crawl merchant web sites to
   nd products and their prices which can then be used for comparison
shopping [87]. as web technologies evolved, most large merchant web
sites started getting hidden behind forms and scripting languages. con-
sequently, the focus has shifted to crawling and extracting information

3 http://www.scholar.google.com.
4 http://rexa.info.

268 introduction

from form-based web sites [104]. the extraction of information from
form-based web sites is an active research area not covered in this
survey.

ad placement on webpages: suppose a web site wants to place adver-
tisements of a product next to the text that both mentions the prod-
uct and expresses a positive opinion about it. both of these subtasks:
extracting mentions of products and the type of opinion expressed on
the product are examples of information extraction tasks that can facil-
itate the burgeoning internet ad placement industry [29].

structured web searches: finally, a grand challenge problem for infor-
mation extraction is allowing structured search queries involving enti-
ties and their relationships on the world wide web. keyword searches
are adequate for getting information about entities, which are typi-
cally nouns or noun phrases. they fail on queries that are looking
for relationships between entities [45]. for example, if one wants to
retrieve documents containing text of the form    company x acquired
company y   , then keywords alone are extremely inadequate. the only
obvious keyword is    acquired   , and one has to work hard to introduce
related words like    corp    etc. to get the required documents. research
prototypes for answering such kinds of queries are only starting to
appear [39, 196, 197].

1.2 organization of the survey

given the broad scope of the topic, the diversity of communities
involved and the long history, compiling an exhaustive survey on struc-
ture extraction is a daunting task. fortunately, there are many short
surveys on information extraction from di   erent communities that can
be used to supplement what is missed here [71, 98, 104, 139, 142, 153,
154, 178, 209, 212].

we provide a taxonomy of the    eld by categorizing along di   erent
dimensions and alongside scope out what is covered in this survey.
we layout the    eld of information extraction along the following    ve
dimensions.

1.3 types of structure extracted

269

(1) the type of structure extracted (entities, relationships, lists,

tables, attributes, etc.).

(2) the type of unstructured source (short strings or documents,

templatized or open-ended).

(3) the type of input resources available for extraction (struc-
tured databases, labeled unstructured data, linguistic tags,
etc.).

(4) the method used for extraction (rule-based or statistical,

manually coded or trained from examples).

(5) the output of extraction (annotated unstructured text, or a

database).

these are discussed in sections 1.3 through 1.7.

1.3 types of structure extracted

we categorize the type of structure extracted from an unstructured
source into four types: entities, relationships between entities, adjec-
tives describing entities, and higher-order structures such as tables and
lists.

1.3.1 entities

entities are typically noun phrases and comprise of one to a few tokens
in the unstructured text. the most popular form of entities is named
entities like names of persons, locations, and companies as popular-
ized in the muc [57, 100], ace [1, 159], and conll [206] compe-
titions. id39 was    rst introduced in the sixth
muc [100] and consisted of three subtasks: proper names and acronyms
of persons, locations, and organizations (enamex), absolute tem-
poral terms (timex) and monetary and other numeric expressions
(numex). now the term entities is expanded to also include gener-
ics like disease names, protein names, paper titles, and journal names.
the ace competition for entity relationship extraction from natural
language text lists more than 100 di   erent entity types.

figures 1.1 and 1.2 present examples of entity extractions: fig-
ure 1.1 shows the classical ie task of extracting person, organization,

270 introduction

fig. 1.1 traditionally named entity and relationship extraction from plain text (in this case
a news article). the extracted entities are bold-faced with the entity type surrounding it.

fig. 1.2 text segmentation as an example of entity extraction from address records.

and location entities from news articles; figure 1.2 shows an example
where entity extraction can be treated as a problem of segmenting a
text record into structured entities. in this case an address string is
segmented so as to identify six structured entities. more examples of
segmentation of addresses coming from diverse geographical locations
appear in table 1.1.

we cover techniques for entity extraction in sections 2 and 3.

1.3.2 relationships

relationships are de   ned over two or more entities related in a pre-
de   ned way. examples are    is employee of    relationship between a
person and an organization,    is acquired by    relationship between pairs
of companies,    location of outbreak    relationship between a disease

1.3 types of structure extracted

271

table 1.1 sample addresses from di   erent countries. the    rst line shows the unformatted
address and the second line shows the address broken into its elements.

#

address text [segmented address]

0 m. j. muller, 71, route de longwy l-4750 petange

1

2

3

[recipient: m. j. muller] [house#: 71]
[street: route de longwy] [zip: l-4750] [city:petange]
viale europa, 22 00144-roma rm
[street: viale europa] [house#: 22] [city: roma]
[province: rm] [zip: 00144-]
7d-brijdham bangur nagar goregaon (w) bombay 400 090
[house#: 7d-] [building: brijdham]
[colony: bangur nagar] [area: goregaon (w)]
[city: bombay] [zip: 400 090]
18100 new hamshire ave. silver spring, md 20861
[house#: 18100], [street: new hamshire ave.],
[city: silver spring,], [state: md], [zip: 20861]

and a location, and    is price of    relationship between a product name
and a currency amount on a web-page. figure 1.1 shows instances of
the extraction of two relationships from a news article. the extrac-
tion of relationships di   ers from the extraction of entities in one sig-
ni   cant way. whereas entities refer to a sequence of words in the
source and can be expressed as annotations on the source, relation-
ships are not annotations on a subset of words. instead they express
the associations between two separate text snippets representing the
entities.

the extraction of multi-way relationships is often referred to as
record extraction. a popular subtype of record extraction is event
extraction. for example, for an event such as a disease outbreak we
extract a multi-way relationship involving the    disease name   ,    loca-
tion of the outbreak   ,    number of people a   ected   ,    number of people
killed   , and    date of outbreak.    some record extraction tasks are trivial
because the unstructured string implies a    xed set of relationships. for
example, for addresses, the relation    is located in    is implied between
an extracted street name and city name.

in section 4, we cover techniques for relationship extraction con-

centrating mostly on binary relationships.

another form of multi-way relationship popular in the natural
language community is id14 [124], where given a

272 introduction

predicate in a sentence, the goal is to identify various semantic argu-
ments of the predicate. for example, given a predicate accept in the
sentence    he accepted the manuscript from his dying father with trem-
bling hands    the extraction task is to    nd the role-sets of the predicate
consisting of the    acceptor   ,    thing accepted   , and    accepted-from   .
we will not cover id14 in this survey, and refer the
reader to [124] to know more about this topic.

1.3.3 adjectives describing entities

in many applications we need to associate a given entity with the value
of an adjective describing the entity. the value of this adjective typi-
cally needs to be derived by combining soft clues spread over many
di   erent words around the entity. for example, given an entity type,
say restaurants, or music bands, we need to extract parts of a blog
or web-page that presents a critique of entities of such type. then, we
would like to infer if the critique is positive or negative. this is also
called opinion extraction and is now a topic of active research interest
in many di   erent communities. we will not cover this topic in this
survey but instead refer the reader to [160] for a current and exhaustive
survey.

1.3.4 structures such as lists, tables, and ontologies

the scope of extraction systems has now expanded to include the
extraction of not such atomic entities and    at records but also richer
structures such as tables, lists, and trees from various types of docu-
ments. for example, [109, 134, 164] addresses the identi   cation of tables
from documents, [62, 85, 156] considers the extraction of elements of
a list, and [130] considers the extraction of ontologies. we will not be
able to cover this topic in the survey to contain its scope and volume.
on the topic of table extraction there is an extensive research liter-
ature spanning many di   erent communities, including the document
analysis [84, 109, 134, 222], information retrieval [164], web [62, 96],
database [36, 165], and machine learning [164, 216] communities. a sur-
vey can be found in [84].

1.4 types of unstructured sources

273

1.4 types of unstructured sources

we classify the type of unstructured source along two dimensions: the
basic unit of granularity on which an extractor is run, and the hetero-
geneity in style and format across unstructured documents.

1.4.1 granularity of extraction

record or sentences: the most popular form of extraction is from
small text snippets that are either unstructured records like addresses,
citations and classi   ed ads [3, 25, 151, 163, 195] or sentences extracted
from a natural language paragraph [1, 26, 57, 100, 159, 206]. in the case
of unstructured records, the data can be treated as a set of structured
   elds concatenated together, possibly with a limited reordering of the
   elds. thus, each word is a part of such structured    eld and during
extraction we just need to segment the text at the entity boundaries.
in contrast, in sentences there are many words that do not form part
of any entity of interest.
paragraphs and documents: many other extraction tasks make it nec-
essary to consider the context of multiple sentences or an entire docu-
ment for meaningful extractions. popular examples include extractions
of events from news articles [57, 100], extraction of part number and
problem description from emails in help centers, extraction of a struc-
tured resume from a word    le, extraction of title, location and timing
of a talk from talk announcements [189] and the extraction of paper
headers and citations from a scienti   c publication [163].

the techniques proposed in this survey mostly assume the    rst kind
of source. typically, for extracting information from longer units the
main challenge is designing e   cient techniques for    ltering only the
relevant portion of a long document. currently, this is handled through
hand-coded heuristics, so there is nothing speci   cally to cover in a
survey on the handling of longer units.

1.4.2 heterogeneity of unstructured sources

an important concern that has a huge impact on the complexity
and accuracy of an extractor is how much homogeneity is there in

274 introduction

the format and style of the unstructured documents. we categorize
them as:

machine generated pages: on the easy end of the spectrum we
have highly templatized machine generated pages. a popular source
in this space is html documents dynamically generated via database
backed sites. the extractors for such documents are popularly known
as wrappers. these have been extensively studied in many commu-
nities [11, 184, 16, 17, 67, 103, 106, 123, 133, 149, 156], where the
main challenge is how to automatically    gure out the layout of a
page with little or no human input by exploiting mostly the reg-
ularity of html tags present in the page. in this survey we will
not be able to do justice to the extensive literature on web wrapper
development.

partially structured domain speci   c sources: the most studied set-
ting for information extraction is where the input source is from within
a well-de   ned scope, say news articles [1, 57, 100, 159, 206], or clas-
si   ed ads [151, 195], or citations [25, 163], or resumes. in all these
examples, there is an informal style that is roughly followed so that it
is possible to develop a decent extraction model given enough labeled
data, but there is lot more variety from one input to another than in
machine generated pages. most of the techniques in this survey are for
such input sources.

open ended sources: recently [14, 37, 86, 192], there is interest in
extracting instances of relationships and entities from open domains
such as the web where there is little that can be expected in terms of
homogeneity or consistency. in such situations, one important factor is
to exploit the redundancy of the extracted information across many dif-
ferent sources. we discuss extractions from such sources in the context
of relationship extraction in section 4.2.

1.5

input resources for extraction

the basic speci   cation of an extraction task includes just the types
of structures to be extracted and the unstructured sources from which

1.5 input resources for extraction

275

it should be extracted. in practice, there are several additional input
resources that are available to aid the extraction.

1.5.1 structured databases

existing structured databases of known entities and relationships are
a valuable resource to improve extraction accuracy. typically, there
are several such databases available during extraction. in many appli-
cations unstructured data needs to be integrated with structured
databases on an ongoing basis so that at the time of extraction a large
database is available. consider the example of portals like dblife, cite-
seer, and google scholar. in addition to their own operational database
of extracted publications, they can also exploit external databases such
as the acm digital library or dblp. other examples include the use
of a sales transactions database and product database for extracting
   elds like customer id and product name in a customer email; the use
of a contact database to extract authoring information from    les in a
personal information management system; the use of a postal database
to identify entities in address records.

1.5.2 labeled unstructured text

many extraction systems are seeded via labeled unstructured text. the
collection of labeled unstructured text requires tedious labeling e   ort.
however, this e   ort is not totally avoidable because even when an
extraction system is manually coded, a ground truth is necessary for
evaluating its accuracy. a labeled unstructured source is signi   cantly
more valuable than a structured database because it provides contex-
tual information about an entity and also because the form in which
an entity appears in the unstructured data is often a very noisy form
of its occurrence in the database.

we will discuss how labeled data is used for learning entity extrac-
tion models in sections 2.3 and 3.4 and for relationship extraction in
section 4.1. in section 4.2, we show how to learn a model using only a
structured database and a large corpus of unlabeled corpus. we discuss
how structured databases are used in conjunction with labeled data in
sections 2 and 3.

276 introduction

1.5.3 preprocessing libraries for unstructured text

many extraction systems crucially depend on preprocessing libraries
that enrich it with linguistic or layout information that serve as valuable
anchors for structure recognition.

natural language text: natural language documents are often ana-
lyzed by a deep pipeline of preprocessing libraries, including,

    sentence analyzer and tokenizer that identi   es the bound-
aries of sentences in a document and decomposes each sen-
tence into tokens. tokens are obtained by splitting a sentence
along a prede   ned set of delimiters like spaces, commas, and
dots. a token is typically a word or a digit, or a punctuation.
    part of speech tagger that assigns to each word a grammati-
cal category coming from a    xed set. the set of tags includes
the conventional part of speech such as noun, verb, adjective,
adverb, article, conjunct, and pronoun; but is often consid-
erably more detailed to capture many subtypes of the basic
types. examples of well-known tag sets are the brown tag
set which has 179 total tags, and the id32 tag set
that has 45 tags [137]. an example of pos tags attached to
a sentence appears below:

the/dt university/nnp of/in helsinki/nnp
hosts/vbz icml/nnp this/dt year/nn

    parser that groups words in a sentence into prominent phrase
types such as noun phrases, prepositional phrases, and verb
phrases. a id18 is typically used to identify
the structure of a sentence in terms of its constituent phrase
types. the output of parsing is a parse tree that groups
words into syntactic phrases. an example of a parse tree
appears in figure 4.1. parse trees are useful in entity extrac-
tion because typically named entities are noun phrases. in
relationship extraction they are useful because they provide
valuable linkages between verbs and their arguments as we
will see in section 4.1.

1.5 input resources for extraction

277

    dependency analyzer that identi   es the words in a sentence
that form arguments of other words in the sentence. for
example, in the sentence    apple is located in cupertino   , the
word    apple    and    cupertino    are dependent on the word
   located   . in particular, they respectively form the subject
and object argument of the word    located   . the output of
a dependency analyzer is a graph where the nodes are the
words and the directed edges are used to connect a word to
words that depend on it. an example of a dependency graph
appears in figure 4.2. the edges could be typed to indicate
the type of dependency, but even untyped edges are useful
for relationship extraction as we will see in section 4.

many of the above preprocessing steps are expensive. the shift is
now for selective preprocessing of only parts of the text. many shal-
low extractions are possible without subjecting a sentence to the full
preprocessing pipeline. also, some of these preprocessing steps, exam-
ple parsing, are often erroneous. the extraction system needs to be
robust to errors in the preprocessing steps to avoid cascading of errors.
this problem is particularly severe on ill-formed sentences of the kind
found in emails and speech transcripts.

gate [72] and uima [91] are two examples of frameworks that
provide support for such preprocessing pipelines. many nlp libraries
are also freely available for download such as ibm   s languageware,5
libraries from the stanford nlp group,6 and several others listed under
the opennlp e   ort.7

formatted text: for formatted text such as a pdf document and a
web-page, there is often a need for understanding the overall structure
and layout of the source before entity extraction. two popular prepro-
cessing steps on formatted documents are, extracting items in a list-like
environment and creating hierarchies of rectangular regions comprising
logical units of content. much work exists in this area in the document

5 http://www.alphaworks.ibm.com/tech/lrw.
6 http://nlp.stanford.edu/software/.
7 http://opennlp.sourceforge.net/.

278 introduction

analysis community [139] and elsewhere [40, 85, 157, 191]. we will not
discuss these in this survey.

1.6 methods of extraction

we categorize the method used for information extraction along two
dimensions: hand-coded or learning-based and rule-based or statistical.

1.6.1 hand-coded or learning-based

a hand-coded system requires human experts to de   ne rules or regular
expressions or program snippets for performing the extraction. that
person needs to be a domain expert and a programmer, and possess
descent linguistic understanding to be able to develop robust extrac-
tion rules. in contrast, learning-based systems require manually labeled
unstructured examples to train machine learning models of extraction.
even in the learning-based systems, domain expertise is needed in iden-
tifying and labeling examples that will be representative of the actual
deployment setting. it is also necessary to possess an understanding of
machine learning to be able to choose between various model alterna-
tives and also to de   ne features that will be robust on unseen data.
the nature of the extraction task and the amount of noise in the
unstructured data should be used to decide between a hand-coded and a
learning-based system. an interesting commentary that quantitatively
and qualitatively compares the two sides can be found in [127].

1.6.2 rule-based or statistical

rule-based extraction methods are driven by hard predicates, whereas
statistical methods make decisions based on a weighted sum of pred-
icate    rings. rule-based methods are easier to interpret and develop,
whereas statistical methods are more robust to noise in the unstruc-
tured data. therefore, rule-based systems are more useful in closed
domains where human involvement is both essential and available. in
open-ended domains like fact extraction from speech transcripts, or
opinion extraction from blogs, the soft logic of statistical methods is
more appropriate. we will present both rule-based techniques for entity

1.7 output of extraction systems

279

extraction in section 2 and statistical techniques for entity and rela-
tionship extraction in sections 3 and 4, respectively.

1.7 output of extraction systems

there are two primary modes in which an extraction system is
deployed. first, where the goal is to identify all mentions of the struc-
tured information in the unstructured text. second, where the goal is
to populate a database of structured entities. in this case, the end user
does not care about the unstructured text after the structured entities
are extracted from it. the core extraction techniques remain the same
irrespective of the form of the output. therefore, in the rest of the sur-
vey we will assume the    rst form of output. only for a few types of
open ended extractions where redundancy is used to improve the reli-
ability of extractions stored in a database is the distinction important.
we brie   y cover this scenario in sections 4.2 and 5.4.3.

1.8 challenges

large scale deployments of information extraction models raises many
challenges of accuracy, performance, maintainability, and usability that
we elaborate on next.

1.8.1 accuracy

the foremost challenge facing the research community, in spite of more
than two decades of research in the    eld, is designing models that
achieve high accuracy of extraction. we list some of the factors that
contribute to the di   culty of achieving high accuracy in extraction
tasks.

diversity of clues: the inherent complexity of the recognition task
makes it crucial to combine evidence from a diverse set of clues, each of
which could individually be very weak. even the simplest and the most
well-explored of tasks, id39, depends on a myriad
set of clues including orthographic property of the words, their part
of speech, similarity with an existing database of entities, presence of
speci   c signature words and so on. optimally combining these di   erent

280 introduction

modalities of clues presents a nontrivial modeling challenge. this is
evidenced by the huge research literature for this task alone over the
past two decades. we will encounter many of these in the next three
sections of the survey. however, the problem is far from solved for all
the di   erent types of extraction tasks that we mentioned in section 1.3.
di   culty of detecting missed extractions: the accuracy of extraction
comprises of two components: precision, that measures the percent of
extracted entries that are correct, and recall, that measures the percent
of actual entities that were extracted correctly. in many cases, precision
is high because it is easy to manually detect mistakes in extractions
and then tune the models until those mistakes disappear. the bigger
challenge is achieving high recall, because without extensive labeled
data it is not even possible to detect what was missed in the large mass
of unstructured information.
increased complexity of the structures extracted: new tasks requiring
the extraction of increasingly complex kinds of entities keep getting
de   ned. of the recent additions, it is not entirely clear how to extract
longer entities such as the parts within running text of a blog where
a restaurant is mentioned and critiqued. one of the challenges in such
tasks is that the boundary of the entity is not clearly de   ned.

1.8.2 running time

real-life deployment of extraction techniques in the context of an oper-
ational system raises many practical performance challenges. these
arise at many di   erent levels. first, we need mechanisms to e   ciently
   lter the right subset of documents that are likely to contain the struc-
tured information of interest. second, we need to    nd means of e   -
ciently zooming into the (typically small) portion of the document that
contains the relevant information. finally, we need to worry about the
many expensive processing steps that the selected portion might need to
go through. for example, while existing database of structured entries
are invaluable for information extraction, they also raise performance
challenges. the order in which we search for parts of a compound entity
or relationship can have a big in   uence on running time. these and
other performance issues are discussed in section 5.1.

1.8 challenges

281

1.8.3 other systems issues

dynamically changing sources: extraction models take time and
e   ort to build and tune to speci   c unstructured sources. when these
sources change, a challenge to any system that operates continuously
on that source is detecting the change and adapting the model auto-
matically to the change. we elaborate on this topic in section 5.2.

data integration: although in this survey we will concentrate pri-
marily on information extraction, extraction goes hand in hand with
the integration of the extracted information with pre-existing datasets
and with information already extracted. many researchers have also
attempted to jointly solve the extraction and integration problem with
the hope that it will provide higher accuracy than performing each of
these steps directly. we elaborate further in section 5.3.

extraction errors:
it is impossible to guarantee perfect extraction
accuracy in real-life deployment settings even with the latest extrac-
tion tools. the problem is more severe when the sources are extremely
heterogeneous, making it impossible to hand tune any extraction tool
to perfection. one method of surmounting the problem of extraction
errors is to require that each extracted entity be attached with con   -
dence scores that correlate with the id203 that the extracted enti-
ties are correct. normally, even this is a hard goal to achieve. another
challenging issue is how to represent such results in a database that
captures the imprecision of extraction, while being easy to store and
query. in section 5.4, we review techniques for managing errors that
arise in the extraction process.

section layout

the rest of the survey is organized as follows. in section 2, we cover
rule-based techniques for entity extraction. in section 3, we present
an overview of statistical methods for entity extraction. in section 4,
we cover statistical and rule-based techniques for relationship extrac-
tion. in section 5, we discuss work on handling various performance
and systems issues associated with creating an operational extraction
system.

2

entity extraction: rule-based methods

many real-life extraction tasks can be conveniently handled through a
collection of rules, which are either hand-coded or learnt from examples.
early information extraction systems were all rule-based [10, 72, 141,
181] and they continue to be researched and engineered [60, 113, 154,
190, 209] to meet the challenges of real world extraction systems. rules
are particularly useful when the task is controlled and well-behaved like
the extraction of phone numbers and zip codes from emails, or when
creating wrappers for machine generated web-pages. also, rule-based
systems are faster and more easily amenable to optimizations [179, 190].
a typical rule-based system consists of two parts: a collection of
rules, and a set of policies to control the    rings of multiple rules. in
section 2.1, we present the basic form of rules and in section 2.2, we
present rule-consolidation policies. rules are either manually coded, or
learnt from example labeled sources. in section 2.3, we will present
algorithms for learning rules.

2.1 form and representation of rules
rule-based systems have a long history of usage and many di   er-
ent rule representation formats have evolved over the years. these

282

2.1 form and representation of rules

283

include the common pattern speci   cation language (cspl) [10]
and its derivatives like jape [72], pattern items and lists as in
rapier [43], id157 as in whisk [195], sql expressions
as in avatar [113, 179], and datalog expressions as in dblife [190]. we
describe rules in a generic manner that captures the core functionality
of most of these languages.
a basic rule is of the form:    contextual pattern     action   . a
contextual pattern consists of one or more labeled patterns capturing
various properties of one or more entities and the context in which
they appear in the text. a labeled pattern consists of a pattern that is
roughly a regular expression de   ned over features of tokens in the text
and an optional label. the features can be just about any property of
the token or the context or the document in which the token appears.
we list examples of typical features in section 2.1.1. the optional label
is used to refer to the matching tokens in the rule action.

the action part of the rule is used to denote various kinds of
tagging actions: assigning an entity label to a sequence of tokens,
inserting the start or the end of an entity tag at a position, or assigning
multiple entity tags. we elaborate on these in sections 2.1.2, 2.1.3,
and 2.1.4, respectively.

most rule-based systems are cascaded; rules are applied in multiple
phases where each phase associates an input document with an anno-
tation that serves as input features to the next phase. for example, an
extractor for contact addresses of people is created out of two phases of
rule annotators: the    rst phase labels tokens with entity labels like peo-
ple names, geographic locations like road names, city names, and email
addresses. the second phase locates address blocks with the output of
the    rst phase as additional features.

2.1.1 features of tokens

a token in a sentence is typically associated with a bag of features
obtained via one or more of the following criteria:

    the string representing the token.
    orthography type of the token that can take values of the

284 entity extraction: rule-based methods

form capitalized word, smallcase word, mixed case word,
number, special symbol, space, punctuation, and so on.
    the part of speech of the token.
    the list of dictionaries in which the token appears. often
this can be further re   ned to indicate if the token matches
the start, end, or middle word of a dictionary. for example, a
token like    new    that matches the    rst word of a dictionary
of city names will be associated with a feature,    dictionary-
lookup = start of city.   
    annotations attached by earlier processing steps.

2.1.2 rules to identify a single entity

rules for recognizing a single full entity consists of three types of
patterns:

    an optional pattern capturing the context before the start
of an entity.
    a pattern matching the tokens in the entity.
    an optional pattern for capturing the context after the end
of the entity.

an example of a pattern for identifying person names of the form
   dr. yair weiss    consisting of a title token as listed in a dictionary
of titles (containing entries like:    prof   ,    dr   ,    mr   ), a dot, and two
capitalized words is

({dictionarylookup = titles} {string =    .   } {orthography type =
capitalized word}{2})     person names.

each condition within the curly braces is a condition on a token
followed with an optional number indicating the repetition count of
tokens.

an example of a rule for marking all numbers following words    by   

and    in    as the year entity is

({string=   by   |string=   in   }) ({orthography type = number }):y    
year=:y.

2.1 form and representation of rules

285

there are two patterns in this rule: the    rst one for capturing the
context of the occurrence of the year entity and the second one for
capturing the properties of tokens forming the    year       eld.

another example for    nding company names of the form    the xyz

corp.    or    abc ltd.    is given by

({string=   the   }?
{orthography
capitalized}
{orthography type = capitalized word, dictionarytype =
company end})     company name.

type = all

the    rst term allows the    the    to be optional, the second term matches
all capitalized abbreviations, and the last term matches all capitalized
words that form the last word of any entry in a dictionary of company
names. in figure 2.1, we give a subset of the more than dozen rules
for identifying company names in gate, a popular entity recognition
system [72].

2.1.3 rules to mark entity boundaries

for some entity types, in particular long entities like book titles, it is
more e   cient to de   ne separate rules to mark the start and end of
an entity boundary. these are    red independently and all tokens in
between two start and end markers are called as the entity. viewed
another way, each rule essentially leads to the insertion of a single
sgml tag in the text where the tag can be either a begin tag or an
end tag. separate consolidation policies are designed to handle incon-
sistencies like two begin entity markers before an end entity marker.
an example of a rule to insert a (cid:2)journal(cid:3) tag to mark the start of a
journal name in a citation record is

({string=   to   }
{string=   in   }):jstart
({orthography type = capitalized word}{2-5})     insert (cid:2)journal(cid:3)
after:jstart.

{string=   appear   }

many successful rule-based extraction systems are based on
such rules, including (lp)2 [60], stalker [156], rapier [43], and
wein [121, 123].

286 entity extraction: rule-based methods

fig. 2.1 a subset of rules for identifying company names paraphrased from the named
entity recognizer in gate.

2.1.4 rules for multiple entities

some rules take the form of id157 with multiple slots, each
representing a di   erent entity so that this rule results in the recogni-
tion of multiple entities simultaneously. these rules are more useful for
record oriented data. for example, the whisk [195] rule-based system
has been targeted for extraction from structured records such as med-
ical records, equipment maintenance logs, and classi   ed ads. this rule
rephrased from [195] extracts two entities, the number of bedrooms and
rent, from an apartment rental ad.

({orthography type = digit}):bedrooms ({string =   br   }) ({}*)
({string =   $   }) ({orthography type = number}):price     number
of bedrooms = :bedroom, rent =: price

2.2 organizing collection of rules

287

2.1.5 alternative forms of rules

many state-of-the-art rule-based systems allow arbitrary programs
written in procedural languages such as java and c++ in place of
both the pattern and action part of the rule. for example, gate [72]
supports java programs in place of its custom rule scripting language
called jape in the action of a rule. this is a powerful capability because
it allows the action part of the rule to access the di   erent features that
were used in the pattern part of the rule and use those to insert new
   elds for the annotated string. for example, the action part could lead
to the insertion of the standardized form of a string from a dictionary.
these new    elds could serve as additional features for a later rule in
the pipeline. similarly, in the prolog-based declarative formulations of
[190] any procedural code can be substituted as a pattern matcher for
any subset of entity types.

2.2 organizing collection of rules

a typical rule-based system consists of a very large collection of rules,
and often for the same action multiple rules are used to cover di   er-
ent kinds of inputs. each    ring of a rule identi   es a span of text to be
called a particular entity or entity sub-type. it is possible that the spans
demarcated by di   erent rules overlap and lead to con   icting actions.
thus, an important component of a rule engine is how to organize the
rules and control the order in which they are applied so as to elimi-
nate con   icts, or resolve them when they arise. this component forms
one the most nonstandardized and custom-tuned part of a rule-based
system, often involving many heuristics and special case handling. we
present an overview of the common practices.

2.2.1 unordered rules with custom policies to

resolve con   icts

a popular strategy is to treat rules as an unordered collection of dis-
juncts. each rule    res independently of the other. a con   ict arises when
two di   erent overlapping text spans are covered by two di   erent rules.

288 entity extraction: rule-based methods

special policies are coded to resolve such con   icts. some examples of
such policies are

    prefer rules that mark larger spans of text as an entity type.
for example in gate [72] one strategy for resolving con   icts
is to favor the rule matching a longer span. in case of a tie,
a rule with a higher priority is selected.
    merge the spans of text that overlap. this rule only applies
when the action part of the two rules is the same. if not,
some other policy is needed to resolve the con   ict. this is
one of the strategies that a user can opt for in the ie system
described in [113, 179].

this laissez faire method of organizing rules is popular because it allows
a user more    exibility in de   ning rules without worrying too much
about overlap with existing rules.

2.2.2 rules arranged as an ordered set

another popular strategy is to de   ne a complete priority order on all
the rules and when a pair of rules con   ict, arbitrate in favor of the
one with a higher priority [141]. in learning based systems such rule
priorities are    xed by some function of the precision and coverage of
the rule on the training data. a common practice is to order rules in
decreasing order of precision of the rule on the training data.

an advantage of de   ning a complete order over rules is that a later
rule can be de   ned on the actions of earlier rules. this is particularly
useful for    xing the error of unmatched tags in rules where actions
correspond to an insertion of either a start or an end tag of an entity
type. an example of two such rules, is shown below where the second
rule of lower priority inserts the (cid:2)/journal(cid:3) on the results of a earlier
rule for inserting a (cid:2)journal(cid:3) tag.

r1: ({string =    to   } {string =    appear   } {string =    in   } ):jstart
({orthography type = capitalized word}{2-5})     insert (cid:2)journal(cid:3)
after :jstart.
r2: {tag = (cid:2)journal(cid:3)}({orthography type = word}+):jend {string
=    vol   }    insert (cid:2)/journal(cid:3) after :jend.

2.3 rule learning algorithms

289

(lp)2 is an example of a rule learning algorithm that follows this strat-
egy. (lp)2    rst uses high precision rules to independently recognize
either the start or the end boundary of an entity and then handles the
unmatched cases through rules de   ned on the inserted boundary and
other possibly low con   dence features of tokens.

2.2.3 rule consolidation via finite state machines

both of the above forms of rules can be equivalently expressed as a
deterministic    nite state automata. but, the user at the time of de   ning
the rules is shielded from the details of forming the uni   ed automata.
sometimes, the user might want to exercise direct control by explicitly
de   ning the full automata to control the exact sequence of    rings of
rules. softmealy [106] is one such approach where each entity is rep-
resented as a node in an fst. the nodes are connected via directed
edges. each edge is associated with a rule on the input tokens that
must be satis   ed for the edge to be taken. thus, every rule    ring has
to correspond to a path in the fst and as long as there is a unique
path from the start to a sink state for each sequence of tokens, there
is no ambiguity about the order of rule    rings. however, for increasing
recall softmealy does allow multiple rules to apply at a node. it then
depends on a hand-coded set of policy decisions to arbitrate between
them.

2.3 rule learning algorithms

we now address the question of how rules are formulated in the    rst
place. a typical entity extraction system depends on a large    nely tuned
set of rules. often these rules are manually coded by a domain expert.
however in many cases, rules can be learnt automatically from labeled
examples of entities in unstructured text. in this section, we discuss
algorithms commonly used for inducing rules from labeled examples.

we concentrate on learning an unordered disjunction of rules as in
section 2.2.1. we are given several examples of unstructured documents
d = x1, . . . ,xn , where all occurrences of entities in the examples are
marked correctly. we call this the training set. our goal is to learn a

290 entity extraction: rule-based methods

(cid:2)(r) of them. the ratio of the sizes of s

set of rules r1, . . . , rk such that the action part of each rule is one of
three action types described in sections 2.1.2 through 2.1.4. the body
of each rule r will match a fraction s(r) of the data segments in the
n training documents. we call this fraction the coverage of r. of all
segments r covers, the action speci   ed by r will be correct only for a
(cid:2)(r) and s(r) is the
subset s
precision of the rule. in rule learning, our goal is to cover all segments
that contain an annotation by one or more rules and to ensure that
the precision of each rule is high. ultimately, the set of rules have
to provide good recall and precision on new documents. therefore, a
trivial solution that covers each entity in d by its own very speci   c
rule is useless even if this rule set has 100% coverage and precision.
to ensure generalizability, rule-learning algorithms attempt to de   ne
the smallest set of rules that cover the maximum number of training
cases with high precision. however,    nding such a size optimal rule set
is intractable. so, existing rule-learning algorithms follow a greedy hill
climbing strategy for learning one rule at a time under the following
general framework.

(1) rset = set of rules, initially empty.
(2) while there exists an entity x     d not covered by any rule

in rset

(a) form new rules around x.

(b) add new rules to rset.

(3) post process rules to prune away redundant rules.

the main challenge in the above framework is in    guring out how
to create a new rule that has high overall coverage (and therefore gen-
eralizes), is nonredundant given rules already existing in rset, and has
high precision. several strategies and heuristics have been proposed for
this. they broadly fall under two classes: bottom-up [42, 43, 60], or,
top-down [170, 195]. in bottom-up a speci   c rule is generalized, and in
top-down a general rule is specialized as elaborated next. in practice,
the details of rule-learning algorithms are much more involved and we
will present only an outline of the main steps.

2.3 rule learning algorithms

291

2.3.1 bottom-up rule formation

in bottom-up rule learning the starting rule is a very speci   c rule cover-
ing just the speci   c instance. this rule has minimal coverage, but 100%
precision, and is guaranteed to be nonredundant because it is grown
from an instance that is not covered by the existing rule set. this rule is
gradually made more general so that the coverage increases with a pos-
sible loss of precision. there are many variants on the details of how
to explore the space of possible generalizations and how to trade-o   
coverage with precision. we describe (lp)2 a successful rule-learning
algorithm speci   cally developed for learning entity extraction rules [60].
(lp)2 follows the rule format of section 2.1.3 where rule actions cor-
respond to an insertion of either a start or an end marker for each entity
type. rules are learnt independently for each action. when inducing
rules for an action, examples that contain the action are positive exam-
ples; the rest are negative examples. for each tag type t , the follow-
ing steps are repeatedly applied until there are no uncovered positive
examples:

(1) creation of a seed rule from an uncovered instance.
(2) generalizations of the seed rule.
(3) removal of instances that are covered by the new rules.

creation of seed rule: a seed rule is created from a positive instance
x not already covered by the existing rules. a seed rule is just the
snippet of w tokens to the left and right of t in x giving rise to a very
speci   c rule of the form: xi   w        xi   1xi       xi+w     t , where t appears
in position i of x.

consider the sentence in figure 1.1 and let t =<per> and w = 2.
an example seed rule that will lead to the insertion of t before position
i is

({string =    according   } {string =    to   }):pstart {string =
   robert   } {string =    callahan   }     insert (cid:2)per(cid:3) at :pstart

an interesting variant for the creation of seed rules is used in
rapier [42] another popular rule-learning algorithm. in rapier a seed

292 entity extraction: rule-based methods

rule is created from a pair of instances instead of a single instance. this
ensures that each selected rule minimally has a coverage of two.
generalizing seed rules: the seed rule is generalized by either drop-
ping a token or replacing the token by a more general feature of the
token.

here are some examples of generalizations of the seed rule above:
    ({string =    according   }
{string =    to   }):pstart
{orthography type =    capitalized word   } {orthography
type =    capitalized word   }     insert (cid:2)per(cid:3) after :pstart
    ({dictionarylookup = person}):pb ({dictionarylookup =
person})     insert (cid:2)per(cid:3) before :pb

the    rst rule is a result of two generalizations, where the third and
fourth terms are replaced from their speci   c string forms to their
orthography type. the second rule generalizes by dropping the    rst two
terms and generalizing the last two terms by whether they appear in a
dictionary of people names. clearly, the set of possible generalizations
is exponential in the number of tokens in the seed rule. hence, heuristics
like greedily selecting the best single step of generalization is followed
to reduce the search space. finally, there is a user-speci   ed cap of k on
the maximum number of generalizations that are retained starting from
a single seed rule. typically, the top-k rules are selected sequentially in
decreasing order of precision over the uncovered instances. but (lp)2
also allows a number of other selection strategies based on a combina-
tion of multiple measures of quality of rules, including its precision, its
overall coverage, and coverage of instances not covered by other rules.

2.3.2 top-down rule formation

a well-known rule learning algorithm is foil (for first order induc-
tion logic) [170] that has been extensively used in many applications
of inductive learning, and also in information extraction [7]. another
top-down rule learning algorithm is whisk [195]. (lp)2 also has a
more e   cient variant of its basic algorithm above that is top-down.

in a top-down algorithm, the starting rule covers all possible
instances, which means it has 100% coverage and poor precision. the

2.3 rule learning algorithms

293

starting rule is specialized in various ways to get a set of rules with high
precision. each specialization step ensures coverage of the starting seed
instance. we describe the top-down rule specialization method in (lp)2
that follows an apriori-style [6] search of the increasingly specialized
rules. let r0 be the most specialized seed rule consisting of conditions
at 2w positions that is used in bottom-up learning as described in the
previous section. the top-down method starts from rules that gener-
alize r0 at only one of the 2w positions. this set is specialized to get
a collection of rules such that the coverage of each rule is at least s, a
user provided threshold. an outline of the algorithm is given below:
(1) r1 = set of level 1 rules that impose a condition on exactly

one of the 2w positions and have coverage at least s.

(2) for level l = 2 to 2w

(a) rl = rules formed by intersecting two rules from
rl   1 that agree on l     2 conditions and di   er on
only one. this step is exactly like the join step in the
apriori algorithm.

(b) prune away rules from rl with coverage less than s.

the above process will result in a set of rules, each of which cover r0
and have coverage at least s. the set k of the most precise of these
rules are selected. a computational bene   t of the above method is that
the coverage of a new rule can be easily computed by intersecting the
list of instances that each of the parent rule covers.

interactive methods for rule induction:
in practice, a purely auto-
mated data-driven method for rule induction cannot be adequate due to
the limited availability of labeled data. the most successful rule-based
systems have to provide a hybrid of automated and manual methods.
first, the labeled data can be used to    nd a set of seed rules. then, the
user interacts with the system to modify or tune the rules or to provide
more labeled examples. often, this is a highly iterative process. an
important requirement for the success of such a system is fast support
for assessing the impact of a rule modi   cation on the available labeled
and unlabeled data. see [116] for a description of one such system that

294 entity extraction: rule-based methods

deploys a customized inverted index on the documents to assess the
impact of each rule change.

summary

in this section, we presented an overview of rule-based methods to
entity extraction. we showed how rule-based systems provide a con-
venient method of de   ning extraction patterns spanning over various
properties of the tokens and the context in which it resides. one key
advantage of a rule-based system is that it is easy for a human being
to interpret, develop, and augment the set of rules. one important
component of a rule-based method is the strategy followed to resolve
con   icts; many di   erent strategies have evolved over the years but one
of the most popular of these is ordering rules by priorities. most sys-
tems allow the domain expert to choose a strategy from a set of sev-
eral prede   ned strategies. rules are typically hand-coded by a domain
expert but many systems also support automatic learning of rules from
examples. we presented two well-known algorithms for rule-learning.

further readings

optimizing the execution of a rule-based extractor: most rule-based
systems are based on regular grammars that can be compiled as a
deterministic    nite state automata (dfa) for the purposes of e   cient
processing. this implies that a single pass over the input document
can be used to    nd all possible rule    rings. each input token results in
a transition from one state to another based on properties applied on
the features attached to the token. however, there are many issues in
optimizing such executions further. troussov et al. [207] show how to
exploit the di   erence in the relative popularity of the states of the dfa
to optimize a rule-execution engine. another signi   cant advancement
in rule execution engines is to apply techniques from relational database
query optimization to e   cient rule execution [179, 190]. we revisit this
topic in section 5.1.

untyped entities: typically, in entity extraction, the type of entities
come from a small closed class, that is known in advance. when one is

2.3 rule learning algorithms

295

trying to build a knowledge base from open sources, such as the web, it
may not be possible to de   ne the set of entity types in advance. in such
cases it makes sense to    rst extract all plausible entities using generic
patterns for entity recognition and later    gure out the type of the
entity [81, 193]. for example, downey et al. [81] exploit capitalization
patterns of a text string and its repeated occurrences on the web to
   nd such untyped entities from webpages.

3

entity extraction: statistical methods

statistical methods of entity extraction convert the extraction task
to a problem of designing a decomposition of the unstructured text
and then labeling various parts of the decomposition, either jointly or
independently.

the most common form of decomposition is into a sequence of
tokens obtained by splitting an unstructured text along a prede   ned
set of delimiters (like spaces, commas, and dots). in the labeling phase,
each token is then assigned an entity label or an entity subpart label
as elaborated in section 3.1. once the tokens are labeled, entities are
marked as consecutive tokens with the same entity label. we call these
token-level methods since they assign label to each token in a sequence
of tokens and discuss these in section 3.1.

a second form of decomposition is into word chunks. a common
method of creating text chunks is via natural language parsing tech-
niques [137] that identify noun chunks in a sentence. during label-
ing, instead of assigning labels to tokens, we assign labels to chunks.
this method is e   ective for well-formed natural language sentences. it
fails when the unstructured source does not comprise of well formed
sentences, for example, addresses and classi   ed ads. a more general

296

3.1 token-level models

297

method of handling multi-word entities is to treat extraction as a seg-
mentation problem where each segment is an entity. we call these
segment-level methods and discuss them in section 3.2.

sometimes, decompositions based on tokens or segments, fail to
exploit the global structure in a source document. in such cases,
context-free grammars driven by production rules, are more e   ective.
we discuss these in section 3.3.

we discuss algorithms for training and deploying these models in

sections 3.4 and 3.5, respectively.
we use the following notation in this section. we denote the given
unstructured input as x and its tokens as x1       xn, where n is the num-
ber of tokens in string. the set of entity types we want to extract from
x is denoted as e.

3.1 token-level models

this is the most prevalent of statistical extraction methods on plain
text data. the unstructured text is treated as a sequence of tokens
and the extraction problem is to assign an entity label to each token.
figure 3.1 shows two example sequences of eleven and nine words each.
we denote the sequence of tokens as x = x1       xn. at the time of extrac-
tion each xi has to be classi   ed into one of a set y of labels. this gives
rise to a tag sequence y = y1       yn.
the set of labels y comprise of the set of entity types e and a special
label    other    for tokens that do not belong to any of the entity types.
for example, for segmenting an address record into its constituent

fig. 3.1 id121 of two sentences into sequence of tokens.

298 entity extraction: statistical methods
   elds we use y ={houseno, street, city, state, zip, country, other}.
since entities typically comprise of multiple tokens, it is customary
to decompose each entity label as    entity begin   ,    entity end   , and
   entity continue.    this is popularly known as the bceo (where
b=begin c=continue e=end o=other) encoding. another popular
encoding is bio that decomposes an entity label into    entity begin   ,
and    entity inside.    we will use y to denote the union of all these dis-
tinct labels and m to denote the size of y. for example, in the second
sentence the correct label for the nine tokens in the bceo encoding is:
author begin, author end, other, author begin, author end, other,
title begin, title continue, title end.

token labeling can be thought of as a generalization of classi   ca-
tion where instead of assigning a label to each token, we assign labels
to a sequence of tokens. features form the basis of this classi   cation
process. we present an overview of typical entity extraction features in
section 3.1.1. we then present models for predicting the label sequence
given the features of a token sequence.

3.1.1 features

a typical extraction task depends on a diverse set of clues capturing
various properties of the token and the context in which it lies. each
of these can be thought of as a function f : (x, y, i) (cid:5)    r that takes as
argument the sequence x, the token position i, and the label y that
we propose to assign xi, and returns a real-value capturing properties
of the ith token and tokens in its neighborhood when it is assigned
label y. typical features are    red for the ith token xi, for each token
in a window of w elements around xi, and for concatenation of words
in the window.

we list common families of token properties used in typical extrac-
tion tasks. we will soon see that the feature framework provides a
convenient mechanism for capturing a wide variety of clues that are
needed to recognize entities in noisy unstructured sources.

word features: the surface word itself is often a very strong clue
for the label it should be assigned. two examples of token features at

3.1 token-level models

299

position 2 of the second sequence x in figure 3.1 is

f1(y,x, i) = [[xi equals    fagin   ]]    [[y = author]]
f2(y,x, i) = [[xi+1 equals    and   ]]    [[y = author]],
where [[p ]] = 1 when predicate p is true and 0 otherwise.

orthographic features: many valuable features for entity extraction
are derived from various orthographic properties of the words, viz,
its capitalization pattern, the presence of special symbols and alpha-
numeric generalization of the characters in the token.

two examples of orthographic features are

f3(y,x, i) = [[xi matches initial dot]]    [[y = author]]
f4(y,x, i) = [[xixi+1 matches initial dot capsword ]]

  [[y = author]].

feature f3    res when a token xi is an initial followed by a dot, and
it is being labeled author. for the second sentence in figure 3.1 this
   res at position 1 and 4 and for the    rst at position 10. feature f4    res
when a token xi is labeled author and xi is a dotted initial and the
word following it is a capitalized word. this feature    res at the same
positions as f3.
dictionary lookup features: as mentioned in section 1.5.1, there is
often a database of entities available at the time of extraction. match
with words in a dictionary is a powerful clue for entity extraction. this
can be expressed in terms of features as follows:

f5(y,x, i) = [[xi in person dictionary]]    [[y = author]]
f6(y,x, i) = [[xi in city list]]    [[y = state]].

3.1.2 models for labeling tokens

a number of di   erent models have been proposed for assigning labels
to the sequence of tokens in a sentence. an easy model is to inde-
pendently assign the label yi of each token xi using features derived
from the token xi and its neighbors in x. any existing classi   er such
as a logistic classi   er or a support vector machine (id166) can be used

300 entity extraction: statistical methods

to classify each token to the entity type it belongs. however, in typi-
cal extraction tasks the labels of adjacent tokens are seldom indepen-
dent of each other. in the example in figure 3.1, it might be di   cult
to classify    last    as being a word from a book title. however, when
the word to the left and right of it is labeled a book title, it makes
sense to label    last    as a book title too. this has led to a number
of di   erent models for capturing the dependency between the labels
of adjacent words. the simplest of these is the ordered classi   cation
method that assigns labels to words in a    xed left to right order where
the label of a word is allowed to depend on the label of the word to
its left [200, 79]. other popular choices were id48
(id48s) [3, 20, 25, 171, 189] and maximum id178 taggers [26, 177]
also called maximum id178 markov models (memm) [143] and con-
ditional markov models (cmm) [118, 135]. the state-of-the-art method
for assigning labels to token sequences is id49
(crfs) [125]. crfs provide a powerful and    exible mechanism for
exploiting arbitrary feature sets along with dependency in the labels of
neighboring words. empirically, they have been found to be superior
to all the earlier proposed methods for sequence labeling. we elaborate
on crfs next.

id49: a conditional random field (crf)
models a single joint distribution pr(y|x) over the predicted labels
y = y1       yn of the tokens of x. the tractability of the joint distribution
is ensured by using a markov random    eld [119] to express the condi-
tional independencies that hold between elements yi of y. in typical
extraction tasks, a chain is adequate for capturing label dependencies.
this implies that the label yi of the ith token is directly in   uenced only
by the labels of tokens that are adjacent to it. in other words, once the
label yi   1 is    xed, label yi   2 has no in   uence on label yi.

the dependency between the labels of adjacent tokens is captured
by a scoring function   (yi   1, yi,x, i) between nodes yi   1 and yi. this
score is de   ned in terms of weighted functions of features as follows:

  (yi   1, yi,x, i) = e

k=1 wkfk(yi,x,i,yi   1) = e

(cid:1)k

w  f(yi,x,i,yi   1).

(3.1)

n(cid:1)

i=1

with these per-edge scores, the conditional distribution of a label

3.2 segment-level models

301

sequence y given a token x is given as

pr(y|x,w) =

1

z(x)

  (yi   1, yi,x, i) =

1
z(x) e

(cid:1)n
i=1 w  f(yi,x,i,yi   1).

(cid:2)

(3.2)
(cid:2)n
w  f(x,y),
the term z(x) is a normalizing constant and is equal to
i=1 f(yi,x, i, yi   1) the sum of the feature vector over
where f(x,y) =
all token positions of the sequence. some subset of these features can
be simpli   ed further to depend only on the current state and are inde-
pendent of the previous state. we will refer these as state features
and denote these by f(yi,x, i) when we want to make the distinction
explicit. the term transition features refers to the remaining features
that are not independent of the previous label.

y e

given m labels and a sequence x of length n, there can be o(mn)
possible labeling of x. this exponential complexity is cut down to
o(nm2) by the famous id145-based viterbi algorithm
that is described in section 3.5.1. the training algorithm is more
involved and we discuss these in section 3.4.

3.2 segment-level models

in segment-level methods, the output is a sequence of segments, with
each segment de   ning an entity, rather than a sequence of labels as in
earlier token-level models. more formally, a segmentation s of an input
sequence of length n is a sequence of segments s1       sp such that the
last segment ends at n, the    rst segment starts at 1, and segment sj+1
begins right after segment sj ends. each segment sj consists of a start
position lj, an end position uj, and a label yj     y. in figure 3.2, we
show an ideal segmentation of the second sentence in figure 3.1. the
segmentation identi   es three entities: two authors and one title.

fig. 3.2 segmentation of a sentence.

302 entity extraction: statistical methods

in a segment-level model, features are de   ned over segments com-
prising of multiple tokens forming an entire entity string. this allows
for the use of more powerful features than token-level models because
features can now capture joint properties over all the tokens forming
part of an entity. like in the case of sequence models, the label of a
segment depends on the label of the previous segment and the proper-
ties of the tokens comprising this segment. thus a feature for segment
sj = (yj, lj, uj) is of the form f(yj, yj   1,x, lj, uj).

we present examples of segment level features that cannot be
expressed in the earlier token-based models. note that in a segment-
level model, one would include token-level features in addition to the
segment-level features. for example, it is often useful to de   ne token-
level features tied to the start and ending words of a segment.

3.2.1 entity-level features

similarity to an entity in the database: most entities consist of multi-
ple tokens. in sequence models, it is not possible to de   ne a feature that
measures the similarity of an entity to the entire entity in a database.
for example, if we have a database of company names, and a segment
of our input s matches one of the entries entirely, then this gives a
strong clue to mark the segment as a company name. in a sequence
model, we cannot enforce arbitrary segment of text to take the same
label. thus, we can de   ne a segment-level feature of the form:

f(yi, yi   1,x,3,5) = [[x3x4x5 appears in a list of journals]]

  [[yi = journal]].

in general, since unstructured data is noisy instead of de   ning
boolean features that measure exact match, it is more useful to de   ne
real-valued features that quantify the similarity between them [65]. for
example, the feature below captures the maximum tf-idf similarity
between the text span x3x4x5 and an entry in a list of journal names.

f(yi, yi   1,x,3,5) = max

tf-idf-similarity(x3x4x5, j)

j   journals
  [[yi = journal]].

3.3 grammar-based models

303

length of the entity segment: another useful segment-level feature
is its length as this helps capture typical length distributions of the
entity. thus, one can de   ne features of the form that will be    red on
all segments of length    ve when they are labeled as title
f(yi, yi   1,x, l, u) = [[u     l = 5]]    [[yi = title]].

3.2.2 global segmentation models

as in sequence models, it is possible to de   ne a id203 distribution
over di   erent segmentation of an input x as follows:

(3.3)

w  f(x,s),

pr(s|x,w) =

where w is a weight vector

1
z(x) e
(cid:2)|s|
(cid:2)
for
feature vector
f(x,s) =
w  f(x,s(cid:2)) is the id172
j=1 f(yj,x, lj, uj, yj   1), and z(x) =
s(cid:2) e
term.
during id136, the goal is to    nd a segmentation s = s1       sp of
the input sequence x = x1       xn such that w  f(x,s) is maximized. it is
possible to    nd the best segmentation e   ciently using dynamic pro-
gramming as we show later in section 3.5.2.

f,

3.3 grammar-based models

some entity extraction systems require a better interpretation of the
structure of the source, than is possible with segmentation models [202,
213]. for example, we expect author names in a single citation to be
formatted similarly; either all author    rst names are initialized, or all
of them are in full. such a global structure cannot be exploited in any
of the earlier models that can only capture dependency in the labels of
adjacent words.

a grammar-based model uses a set of production rules, like in
context-free grammars of programming language, to express the global
structure of the entity. the productions are de   ned over terminals,
which in this case are tokens in the unstructured source, and non-
terminals that include entity labels and other additional meta-labels
to capture the grouping amongst subset of labels. for example, to cap-
ture the style homogeneity amongst author names in a citation we can

304 entity extraction: statistical methods

de   ne a set of production rules which along with a scoring model that
we will de   ne shortly will achieve the desired e   ect.

r: s     authorslf | authorsfl
r0: authorslf     namelf separator authorslf
r1: authorsfl     namefl separator authorsfl
r2: authorsfl     namefl
r3: authorslf     namelf
r4: namelf separator     namelf punctuation
r5: namefl separator     namefl punctuation
r6: namelf     lastname first middle
r7: namefl     first middle lastname

the output of the extraction process is a parse tree. unlike in program-
ming languages, there can be many valid parses for a token sequence.
each output tree is assigned a score that decomposes over the produc-
tions in the parse tree. early methods of assigning scores were based
on a generative model where each nonterminal has a multinomial prob-
ability distribution over production rules where it is the head. more
recently, analogously to the shift from id48s to discriminative learners
like crfs, grammars are also scored discriminatively. each production
of the form: r     r1r2 is scored as follows:

s(r) = s(r1) + s(r2) + w  f(r, r1, r2,x, l1, r1, r2),

(3.4)

where (l1, r1) and (r1 + 1, r2) are the text spans in x that r1 and r2
cover, respectively. the score of a node depends on the production used
at the node and the text spans that its children r1 and r2 cover. it does
not depend on the subtree underneath r1 and r2. in the base case we
have terminal nodes whose score calculated as w  f(r,x, l, r) indicates
the score of assigning label r to the tokens between l and r. we show
an example to illustrate the scoring of a grammar-based model such as
the above. consider a string    peter haas, george john    of    ve tokens.
one of the many possible parses of the string is

r0    r4 r3
r4    r6 x3
r3     r6

3.4 training algorithms

305

r6    x1x2
r6    x4x5
the total score of this tree w  f(r0, r4, r3,x,1,3,5) + w  f(r4, r6,
punctuation,x,1,2,3) + w  f(r3, r6,   ,x,1,2,2) + w  f(r6,x,1,2) + w.
f(r6,x,3,4). in this method of scoring, any arbitrary set of features
can be used to capture the a   nities between tokens and their labels.
for example, we can use any of the features described in section 3.1.1
to score labeling tokens    george john    as a name where the last name
appears    rst.

the above method of scoring makes it possible to    nd the highest
scoring parse tree in polynomial time. we present the id136 algo-
rithm in section 3.5. grammar-based models, although more expres-
sive, are not as popular as the other methods because of the high cost
of    nding an optimal parse tree.

3.4 training algorithms

we now discuss training algorithms that apply to the di   erent feature-
based models introduced in sections 3.1 through 3.3.

this section and the next, which cover the details of training and
id136, can be involved for someone not already familiar with similar
machine learning topics. we refer the reader to this text book [119] for
a gentler introduction.
the model outputs a y for which the score s(y) = w  f(x,y)
is maximum where f(x,y)
is a feature vector de   ned jointly
over the output y and input x. models di   er in the form of
the output y and the feature vector. for sequence models, y
refers
segment-level models y is
a segmentation of x,
for grammar-based models y is a parse
tree.
let d = {(x(cid:1),y(cid:1))}n

(cid:1)=1 denote the labeled training set. broadly there

to a sequence of

labels,

for

are two types of methods for training:

(1) likelihood-based training discussed in section 3.4.1.
(2) max-margin training discussed in section 3.4.2.

306 entity extraction: statistical methods

3.4.1 likelihood trainer
this method is applicable when w  f(x,y) is used to impose a proba-
bility distribution on the output y as follows:
w  f(x,y)

(3.5)
w  f(x,y). the goal during training is to choose a
where z(x) =
weight vector w such that id203 of the correct output as given in
the training data is maximized. let l(w) denote the log of the proba-
bility of the training data when the weight vector is w. we can write
it as:

pr(y|x) =

1
z(x) e

(cid:2)

y e

l(w) =

log pr(y(cid:1)|x(cid:1),w) =

(w    f(x(cid:1),y(cid:1))     log zw(x(cid:1))).

(cid:3)

(cid:3)

(cid:1)

(cid:1)

c

routinely, a term such as    ||w||2
is added to prevent over   tting by
penalizing large swings in the parameter values. this term has the e   ect
of performing a soft form of feature selection. ideally, we would like to
maximize accuracy while using the smallest number of features. since
this leads to a di   cult discrete optimization problem we instead use
||w||2 weighted by a user-provided constant 1/c. the training objective
can then be expresssed as

(w    f(x(cid:1),y(cid:1))     log zw(x(cid:1)))     ||w||2/c.

(cid:3)

(cid:1)

maxw

the above equation is concave in w, and can thus be maximized by
gradient ascent type of methods that iteratively move toward the opti-
mum w. at each iteration they require the computation of the gradient
   l(w) of the objective which can be calculated as:

(cid:3)
(cid:3)

(cid:1)

   l(w) =

=

(cid:2)
y(cid:2) f(y(cid:2)

f(x(cid:1),y(cid:1))    

,x(cid:1))ew  f(x(cid:1),y(cid:2))
zw(x(cid:1))

    2w/c

f(x(cid:1),y(cid:1))     epr(y(cid:2)|w,x(cid:1))f(x(cid:1),y

(cid:2)

)     2w/c.

(cid:1)

the    rst term is easy to compute. however, the second term that
involves a summation over exponentially many outputs y(cid:2) require spe-
cial algorithms that exploit the decomposability of the feature vector.

3.4 training algorithms

307

we will show how these are computed in section 3.5 where we discuss
id136 algorithms.

the overall training algorithm appears in figure 3.1. the running
time of the algorithm is o(in n(m2 + k)), where i is the total number
of iterations. this basic algorithm has been improved substantially and
now there are many faster variants like semi-id77s [132, 136]
and stochastic gradient methods [27, 214].

algorithm 3.1. train(d = {(x(cid:1),y(cid:1))}n
1. output:
||w||2/c

w = argmax

(cid:1)=1, f : f1       fk)

(cid:2)n
(cid:1)=1(w    f(x(cid:1),y(cid:1))     log zw(x(cid:1)))    

2. initialize w0 = 0
3. for t = 1      maxiters do
for (cid:3) = 1       n do
4.
(cid:2)
gk,(cid:1) = fk(x(cid:1),y(cid:1))     epr(y(cid:2)|w,x(cid:1))fk(x(cid:1),y(cid:2)) k = 1       k
5.
(cid:1) gk,(cid:1) k = 1       k
gk =
6.
k +   t(gk     2wt   1
k = wt   1
wt
7.
rate)
8. exit if ||g||     zero

k /c) k = 1       k (  t = learning

3.4.2 max-margin training

max-margin trainers [201, 208] are an extension of support vector
machines for training structured models. they are more generally appli-
cable because they require only the computation of the output with
the highest score. in contrast, for likelihood trainers it is necessary to
compute the expected value of features, which is sometimes di   cult.
the goal during max-margin training is to    nd a w such that the
score w  f(x(cid:1),y(cid:1)) of the correct labeling y(cid:1) has a margin of at least
err(y,y(cid:1)) more than the score of a labeling y, where err(y,y(cid:1)) is a
user-provided error function that indicates the penalty of outputting
y when the correct label is y(cid:1). an example of an error function is the
hamming error that measures the number of tokens where the label is
incorrect. the max-margin objective can be formulated as a constrained

308 entity extraction: statistical methods

optimization problem as follows:

n(cid:3)

min
w,  

  (cid:1) +

||w||2

1
2

(cid:1)=1

c
s.t. w  f(x(cid:1),y(cid:1))     err(y,y(cid:1)) + w  f(x(cid:1),y)       (cid:1)    y (cid:10)= y(cid:1), (cid:3) : 1       n
(3.6)

  (cid:1)     0 (cid:3) : 1       n

the variables   (cid:1) capture the gap between the desired margin and the
margin achieved by the current values of w. the training objective
is to minimize this gap. the above program is convex in w,   , so a
local minima is the global minima. but the number of constraints is
exponential in the length of each sequence. clearly, any method that
explicitly enumerates these constraints cannot be practical. a cutting
plane algorithm is used to    nd the best w iteratively. a sketch of the
algorithm appears in figure 3.2.
algorithm 3.2. train(d = {(x(cid:1),y(cid:1))}n
(cid:1)=1, f : f1       fk), c
(cid:2)n
1. output: w = argmin 1
(cid:1)=1 maxy(err(y,y(cid:1))+
w  f(x(cid:1),y)     w  f(x(cid:1),y(cid:1)))
2
2. initialize w0 = 0, active constraints = empty.
3. for t = 1      maxiters do
4.
5.
6.
7.
8.
9. exit if no new constraint added.

  y = argmaxy(err(y,y(cid:1)) + w    f(x(cid:1),y))
if w  f(x(cid:1),y(cid:1)) < err(  y,y(cid:1)) + w  f(x(cid:1),   y)       (cid:1)       then

add (x(cid:1),   y) to the set of constraints.
w,    = solve qp with active constraints.

for (cid:3) = 1       n do

||w||2 + c

the two time consuming steps in the above algorithms are
    step 5 that    nds the most violating constraint. to solve this
e   ciently, the err(., .) function is assumed to be decompos-
able, in the same manner as the features themselves. a typ-
ical decomposable err function is the hamming error, which
just counts the number of positions in y and y(cid:1) that are
di   erent.

3.5 id136 algorithms

309

    step 8 that solves the constrained quadratic program to    nd
the new values of the variables. many methods are avail-
able to solve this e   ciently. a popular method is to solve a
dual of the program that turns out to be simpler than the
primal [208]. recently, other methods have been proposed
including stochastic online methods [24], and extra-gradient
methods [203].

3.5

id136 algorithms

we encountered two kinds of id136 queries when training and
deploying the di   erent models.

scoring (map)

    highest
w  f(x,y).
    expected feature values: find
pr(y|x) = 1

w  f(x,y).

z(x) e

labeling: find y    = argmaxy
(cid:2)
y f(x,y)pr(y|x), where

the key to solving both these e   ciently, in spite of the exponential
number of possible values of y, is that the feature vector f(x,y) decom-
poses over    ner substructures in y. this enables us to design a dynamic
programming algorithm based on the following general principle. let
s1 and s2 be a disjoint decomposition of the entire output s that is,
s = s1     s2 and s1     s2 =   . let s3     s1 be the smallest part of s1
such that all features spanning s1 and s2 involve only the subset in s3.
that is, there are no features involving a label in s2 and a label from
s1     s3.

we can    nd the map score v(s) over s recursively as:
) + v(s2|s3 = y
(cid:2)
).

v(s1|s3 = y

v(s) =

max

(cid:2)

(3.7)

label y(cid:2) of s3

as long as the number of possible labelings of the common part s3
is small, this equation will be e   cient. the same principle holds for
   nding the expected values.

sections 3.5.1, 3.5.2, and 3.5.3 elaborate on map labeling for
the special cases of sequential labeling, segmentation, and parsing,
respectively. section 3.5.4 elaborates on computing expected features
values for sequence models.

310 entity extraction: statistical methods

3.5.1 map for sequential labeling

(cid:2)|x|

in sequence labeling the feature vector decomposes over labels of adja-
f(yi,x, i, yi   1). let v(i|y) denote
cent positions, that is, f(x,y) =
the best score of the sequence from 1 to i with the ith position labeled y.
we can express its value using id145 as follows:

i

(cid:4)
maxy(cid:2) v(i     1, y
0

v(i|y) =

(cid:2)) + w    f(y,x, i, y

(cid:2))

(3.8)
the best label then corresponds to the path traced by maxy v(n|y),
where n is the length of x. the running time of this algorithm is
o(nm2), where m is the number of labels. this is well-known as the
viterbi algorithm.

if i > 0
if i = 0.

3.5.2 map for segmentations

in segmentation tasks, y denotes a segmentation of x. let y = s1 . . . sp,
where each sj = (tj, uj, yj) with tj = segment start position, uj =
segment end position, and yj = segment label. the feature vector
(cid:2)p
decomposes over segments and the label of its previous segment as
j=1 f(x, sj, yj   1). let v(i|y) denote the best score of seg-
f(x,y) =
      
mentations ending at i with label y.
(cid:1)|y
   maxy(cid:1) maxi(cid:1)=i   l      i   1 v(i
v(i|y) =

if i > 0
if i = 0
if i < 0,
where l is the size of the largest segment. the best segmentation
then corresponds to the path traced by maxy v(n|y). this runs in time
o(nlm2).

(cid:1)) + w    f(x, y, i

(cid:1) + 1, i, y

0
      

(cid:1))

in entity extraction, segmentation models use a mix of token-level
and segment-level features with the former comprising a much larger
fraction of the total feature set. in such cases it is possible to make
id136 over segmentation models comparable to that over sequence
models as shown in [186].

3.5.3 map for parse trees

in this case, the output y denotes a parse tree. each internal node j
of the tree denotes a rule rj and the span of text (tj, uj) on which it

3.5 id136 algorithms

311

applies. the feature vector f(x,y) decomposes over the nodes in tree
y and spans of its immediate children. we assume trees are binary
(cid:2)
for simplicity and denote the children of rj as rj1 and rj2. thus,
node j   y f(x, rj, rj1, rj2, tj, uj, uj1), where uj1 denotes the
f(x,y) =
ending position of the    rst child of the node. let v(i, j|y) denote the
score of the best tree rooted at nonterminal y over text span (i, j).

v(i, j|y) =

         
w  f(x, y, i, j)
if y is terminal
      
maxi<i(cid:2)<j maxr(cid:2):y(cid:5)   r1r2 v(i, i
(cid:2) + 1, j|r2) + w  f(x, r

+v(i

(cid:2)|r1)
(cid:2)

(cid:2))
, r1, r2, i, j, i

the best tree is maxy v(1, n, y), where y goes over all possible non-
(cid:2) denotes the total
terminals. the running time is o(n3m
number of nonterminals and terminals.

(cid:2)), where m

3.5.4 expected features values for sequential labelings

w  f(x,y).
consider    rst the simpler problem of computing z(x) =
again, we exploit the decomposability of f(x,y) to de   ne a dynamic
(cid:2)
program over partial solutions. let   (i, y) denote the value of
y(cid:2)   yi:y ew  f(x,y(cid:2)), where yi:y denotes all label sequences from 1 to i
with the ith position labeled y. for i > 0, this can be expressed recur-
sively as

y e

(cid:2)

  (i     1, y

(cid:2)

)ew  f(y,x,i,y(cid:2))

(cid:3)
  (i, y) =
y(cid:2)   y
(cid:2)
y   (n, y).

with the base cases de   ned as   (0, y) = 1. the value of zw(x) can then
be written as zw(x) =
(cid:2)
a similar approach can be used to compute the expectation
(cid:2)
y(cid:2) f(x,y(cid:2))ew  f(x,y(cid:2)). for the kth component of f, let   k(i, y) be the
y(cid:2)   yi:y fk(x,y(cid:2))ew  f(x,y(cid:2)), restricted to the part of
value of the sum
the label ending at position i. the following recursion can then be used
(cid:3)
to compute   k(i, y):
y(cid:2)   y

(  k(i     1, y

w  f(y,x,i,y(cid:2)).

  k(i, y) =

))e

(cid:2)

(cid:2)

) +   (i     1, y
(cid:2)
)fk(y,x, i, y
(cid:2)
y   k(n, y).

finally, we let epr(y(cid:2)|w)fk(x,y(cid:2)) = 1
zw(x)

312 entity extraction: statistical methods

the space requirements here can be reduced from km + nm to k +
nm, where k is the number of features, by using a backward recursion
(cid:2)
to computing an appropriate set of   (i, y) values de   ned, analogously
y(cid:2)   bi:y ew  f(y(cid:2),x), where bi:y denotes all
to the    terms, as   (i, y) =
(cid:3)
label sequences from i + 1 to n with the ith position labeled y.
y(cid:2)   y

)ew  f(y(cid:2),x,i+1,y).

  (i + 1, y

  (i, y) =

(cid:2)

now, the expected value of a feature fk can be computed more

e(fk(y,x, i, y

(cid:2)

)) =   (i     1, y

(cid:2)

w  f(y,x,i,y(cid:2))  (i, y).
)e

simply as:

summary

in this section, we studied models for entity extraction using statis-
tical models. there is a long history behind the development of such
models and many di   erent models have been proposed over the years.
the most prominent of these are maximum id178 taggers or condi-
tional markov models (cmms), id48 (id48s), and
id49 (crfs). crfs are now established as the
state-of-the-art methods and have shown clear advantages over cmms
and id48s both theoretically and empirically [118, 163] because of
the ease with which diverse set of clues can be exploited as features.
there are many existing implementations of crfs [92, 146, 185] that
can be easily customized by modifying only the feature set. segment-
level models and the grammar-based models provide all the    exibility
of crfs and more, but they are not as popular because of the increased
overheads of id136 and training.

further readings

the topic of statistical learning for information extraction is relatively
new and there continues to be much active research on many di   erent
aspects that we have not covered in this section. we present a brief
overview of some of these.
active learning: the accuracy of a statistical model crucially depends
on    nding adequate amount of labeled data for training the model

3.5 id136 algorithms

313

parameters. since collecting training data often requires painstaking
manual e   ort, there has been much work on reducing this e   ort. active
learning is one technique for reducing labeling e   ort that is used with a
limited labeled and a large unlabeled pool of instances. the labeled set
forms the training data for an initial preliminary classi   er. the active
learner seeks out from the unlabeled pool those instances which when
labeled will help strengthen the classi   er at the fastest possible rate.
this is an important conceptual problem in machine learning and there
is much ongoing work on developing theoretically sound methods for
active learning [12, 13, 66, 76, 95]. speci   cally, for information extrac-
tion studies [68, 155, 169, 205] have shown that active learning can
signi   cantly reduce the number of examples that need to be manually
labeled.

id64 from structured data: another practical method of
addressing the problem of limited training data is to bootstrap models
from existing structured entities, which are often readily available. this
requires very careful handling, particularly when unstructured labeled
is available along with structured databases. when there is only struc-
tured data at one   s disposable, the technique proposed in [3] would be
useful. methods of training with a mix of structured and unstructured
data for id48s are discussed in [189], for crfs are discussed in [138],
and for rule-based systems are discussed in [99].

id21 and id20: statistical learning tech-
niques crucially depend on the training data being representative
of the distribution on which the trained model
is deployed. this
assumption often does not hold when extraction systems get deployed
on a large scale. a topic of much recent interest now is domain
adaptation [23, 108, 188] where labeled data from some domain is used
to train a model that maximizes accuracy in a target domain for which
we only have unlabeled data available. another related variant is trans-
fer learning [9, 52, 77, 129] where the goal is to use training data from
a related domain, along with training data from the target domain, to
train the target classi   er. a popular technique is to use the classi   er in
the related domain to de   ne a prior [9, 52, 129] for the classi   er trained
using the in-domain data.

314 entity extraction: statistical methods

collective id136: most information extraction (ie) models are
based on sequential models that capture the dependency between labels
of words. recently, several researchers [31, 93, 101, 120, 199] have
reported increased accuracy of collectively labeling repeated words
within a document or across multiple documents. in the corresponding
graphical model this leads to additional edges between non-adjacent
positions that share a word.

4

relationship extraction

in many extraction tasks, there is an explicit need to relate the
extracted entities because the unstructured source is not naturally par-
titioned into records. for example, it is not just enough to    nd occur-
rences of company names and people names in a news article but also
to identify if there is a    is acquired by    relationship between pairs of
companies, or, a    is appointed ceo of    relationship between a person
and company, or    is employee of    relationship between a person and
an organization. figure 1.1 shows instances of the extraction of two
relationships from a news article.

the problem of relationship extraction has been studied extensively
on natural language text, including news articles [1], scienti   c publica-
tions [166], blogs, emails [113], and sources like wikipedia [196, 197]
and the general web [4, 14]. as in entity extraction, much of the impe-
tus to relationship extraction research was provided by the various
competitions: starting with the muc competitions [57, 100], and later
the ace task [1] and the biocreative ii protein   protein interac-
tion tasks [22, 209]. for example, the ace task de   nes    ve top-level
relations:    located at   ,    near   ,    part   ,    role   , and    social    over pairs
from    ve top-level entity types    person   ,    organization   ,    facility   ,
   location   , and,    geo-political entity.    the    located at    relation relates

315

316 relationship extraction

   person    or    organization    with    location   . the    role    relation links
a    person    to an    organization   , and so on. in the bio-medical litera-
ture three kinds of relationship extractions are common: gene-disease
relations, protein   protein interaction, and subcellular id173s.
the naga knowledge base [196, 197] comprises of 26 relationships
such as isa, borninyear, establishedinyear, haswonprize, locatedin,
politicianof, actedin, discoveredinyear, discoveredby, and iscitizenof
extracted from sources such as wikipedia.

in this section, we concentrate on the extraction of binary rela-
tionships, although in general relationships can be multi-way involving
three or more entities. two popular examples of multi-way relation-
ships are: event extraction and id14 [124]. another
term for multi-way relationship extraction is record extraction. we will
present a brief overview of techniques for multiway relations at the end
of this section.

the binary relationship extraction problem can be posed at three
di   erent levels. the    rst case is where entities are preidenti   ed in the
unstructured text, and for a given    xed pair of entities we need to    nd
out the type of relationship that exists between the pair. the second
case is when we are given a relationship type r and an entity name
e, and our goal is to extract the entities with which e has relation-
ship r. the third case is where the unstructured corpus is large and
open-ended like the web where we cannot assume that entity pairs
are marked. given a    xed relationship type r, our goal is to extract all
instances of entity pairs that have relationship r between them through
appropriate    ltering and recognition techniques. most of the early work
in relationship extraction has been on the    rst case and we review the
main ideas that have emerged in section 4.1. in section 4.2, we present
techniques for relationship extraction in the third case. this is a more
recent topic that has emerged in the context of building knowledge
bases from open domains like the web.

4.1 predicting the relationship between a given

entity pair

given a    xed set r of relationship types each involving a pair of entity
types, our goal is to identify all occurrences of the relationships in r

4.1 predicting the relationship between a given entity pair

317

in an input natural language document where all entities have been
marked. typically, in relationship extraction from natural language
text it is assumed that the two argument entities are within a close
proximity of each other, or are part of the same sentence. so, the basic
recognition problem is as follows: given a text snippet x and two marked
entities e1 and e2 in x, identify if there is any of the relationships y
between e1 and e2. the set y indicates all relationship types r and
a special member    other    for the case when none of the relationships
applies to this entity pair.

this prediction problem is simpler than the one that arises in entity
extraction because here we only need to make a scalar prediction,
instead of a vector of predictions. however, relationship extraction is
considered a harder problem than entity extraction because relating
two entity words in a sentence requires a skillful combination of local
and nonlocal noisy clues from diverse syntactic and semantic structures
in a sentence. we review the most common types of resources that are
useful for relationship extractions.

surface tokens: the tokens around and in-between the two enti-
ties often hold strong clues for relationship extraction. for example,
a    is situated    relationship between a company entity and a location
entity is strongly indicated by the presence of unigram token    located   
and bigram token    located in    between the two entities, as in
(cid:2)company(cid:3) kosmix (cid:2)/company(cid:3) is located in the
(cid:2)location(cid:3) bay area (cid:2)/location(cid:3).

similarly, an    outbreak    relationship between a disease and location is
strongly indicated by the presence of words like    epidemic   .

the centers for disease control and prevention, which
is in the front line of the world   s response to the deadly
(cid:2)disease(cid:3) ebola (cid:2)/disease(cid:3) epidemic in (cid:2)location(cid:3) zaire
(cid:2)/location(cid:3).

often, a token is generalized or stemmed to its morphological root. for
example,    located    is stemmed to    locate.   

318 relationship extraction

part of speech tags: part of speech (pos) tags play a more central
role in relationship extraction than in entity extraction. verbs in a
sentence are key to de   ning the relationship between entities, that are
typically nouns or noun phrases. for example, in the sentence,
(cid:2)location(cid:3) the university of helsinki (cid:2)/location(cid:3) hosts
(cid:2)conference(cid:3) icml (cid:2)/conference(cid:3) this year.

more reliable extraction of the    held in    relationship between confer-
ences and locations is possible if the word    hosts    is tagged as a verb
(vbz) instead of a noun as shown below.

the/dt
hosts/vbz icml/nnp this/dt year/nn.

university/nnp

of/in

helsinki/nnp

syntactic parse tree structure: a parse tree groups words in a sen-
tence into prominent phrase types such as noun phrases, prepositional
phrases and verb phrases, and thus is signi   cantly more valuable than
pos tags in understanding the relationship between the entities in a
sentence. for example, in the sentence

(cid:2)location(cid:3) haifa (cid:2)/location(cid:3), located 53 miles from
(cid:2)location(cid:3) tel aviv (cid:2)/location(cid:3) will host (cid:2)conference(cid:3)
icml (cid:2)/conference(cid:3) in 2010.

   tel aviv, icml    is likely to be preferred over    haifa, icml    as an
instance of the    held in    relationship based on its relative proximity to
icml. but consider the parse tree of the sentence in figure 4.1. this
tree brings    icml    closer to    haifa    than    tel aviv    because    haifa   
is the head of the noun phrase    haifa, located 53 miles from tel aviv   
which forms the subject of the verb phrase    will host icml in 2010.   

dependency graph: full parse trees are expensive to create. a depen-
dency graph that links each word to the words that depend on it,
is often found to be just as adequate as a parse tree. for example,
for the sentence above the dependency graph is shown in figure 4.2.
in the graph it is clear that the verb    host    is linked to by both

4.1 predicting the relationship between a given entity pair

319

fig. 4.1 parse tree of a sentence.

fig. 4.2 dependency parse of a sentence.

   haifa    a location entity and    icml    a conference entity. this
directly establishes a close connection between them. in contrast,
the path between icml and tel aviv goes through    haifa    and
   located.   
we next present methods that use the above clues in di   erent ways
for classifying an input (x, e1, e2) into one of the y classes. assume we
2, ri) : i = 1       n,
are given n training examples of the form (xi, ei
where ri     y denotes the relationship that exists between entities ei
and ei

2 in the sentence xi.

the main challenge is handling the diversity of structural forms
that the di   erent inputs represent. for example, the tokens and part
of speech tags form a sequence, the parse information is a tree, and the
dependency structure is a graph. further, there could be errors in any
of the input clues since the linguistic libraries used for these tasks are
not perfect. while redundancy provides robustness to errors, too much
redundancy brings in noise and increases running time.

1, ei

1

320 relationship extraction

the methods used for relationship extraction can be categorized

into one of three main types:

    feature-based methods that extract a    at set of features from
the input and then invoke an o    the shelf classi   er like a
decision tree or a id166. (section 4.1.1)
    kernel-based methods that design special kernels to capture
the similarity between structures such as trees and graphs.
(section 4.1.2)
    rule-based methods that create propositional and    rst order
rules over structures around the two entities. we refer the
reader to [7, 147, 113, 190] for examples of various rule-
based relationship extraction systems. many of the issues in
using rule-based system for relationship extraction are sim-
ilar to the ones that arise in entity extraction covered in
section 2.

4.1.1 feature-based methods

a diverse set of methods have been used to convert the extraction clues
in structures such as sequences, trees, and graphs to a    at set of features
for use by conventional classi   ers. jiang and zhai in [114] present a
systematic method of designing such features, while also capturing most
of the earlier proposed methods of feature-based relationship extraction
[115, 196].

let x denote the input sentence where xi denotes the word at posi-
tion i and e1, e2 denote the segments in x corresponding to the two
entities whose relationship we wish to predict. for simplicity assume
that e1 and e2 consist of single words each. each word xi is associated
with a set of properties p1       pk much like the features used in entity
extraction. examples of such properties include the string form of xi,
the orthographic type of xi, the class of xi in a given ontology, entity
label of xi, and the pos tag of xi.

the    rst set of

features are obtained by taking all possible
conjunctions of the properties of the two tokens representing the two

4.1 predicting the relationship between a given entity pair

321

entities e1 and e2. examples of such features are:

[[entity label of e1 = person, entity label of e2 =
location]].
[[string e1 =    einstein    and orthography type of e2 =
4-digits]].

the    rst feature could be useful for the    resides in    relationship when
the    rst entity in the sentence is a person and the second marked entity
is a location. the second feature that could be useful for the    born   
relationship when the string at e1 is    einstein    and e2 consists of four
digits.

next, we present how to extract features from the structural inputs
that captures the relationships among the words in the sentence. we
have three kinds of inputs: sequences, parse trees, and dependency
graphs. to unify the feature generation step from these inputs, we view
each of them as a graph where the nodes are words, and in the case
of parse trees also the nonterminals such as nnp, vp, etc. each word
node is associated with the set of k properties p1, . . . , pk. in addition
there is a special    ag attached to each node that takes four possible
values: 1 when it subsumes e1, 2 when it subsumes e2,    both    when
it subsumes both, and    none    when it subsumes neither. features are
derived from properties of individual nodes, pairs of nodes connected
by an edge, or triplets of nodes connected by at least two edges, and
for each combination of values of the    ag attached to the nodes. we
explain this with examples from the sentence x with e1 = haifa and
e2 = icml.

(cid:2)location(cid:3) haifa (cid:2)/location(cid:3), located 53 miles from
(cid:2)location(cid:3) tel aviv (cid:2)/location(cid:3) will host (cid:2)conference(cid:3)
icml (cid:2)/conference(cid:3) in 2010.

features from word sequence: we    rst give examples of features for
the sequence graph formed out of the ten words between e1 and e2. in
this case, the only edges are between adjacent words. each node has k
properties and one of three possible    ag values (1, 2, none). example

322 relationship extraction

unigram features are

[[string =   host   ,    ag =   none   ]]
[[part of speech = verb,    ag =    none   ]].

example bigram features are:

[[strings =    (host, icml)   ,    ags =    (none,2)   , type =

   sequence   ]]

[[part of speech = (verb,noun)    ag =    (none,2)   , type

=    sequence   ]]

[[(string =    host   , part of speech = noun),    ag =

   (none,2)   , type =    sequence   ]].

example trigram features are:

host,

[[strings =    (will,
   (none,none,2)   , type =    sequence   ]]
[[part of
   (none,none,2)   , type =    sequence   ]].

speech = (modi   er, verb,noun)    ag =

icml)   ,

   ags =

using this template we can easily calculate the maximum number of
(cid:2)k
features of each type. let d(pi) denote the number of possible values
i=1 d(pi) denote the sum of the
that property i can take and let d =
sizes of all properties. then the number of unigram features is 3d, the
bigram features is 32d2, and the trigram features is 33d3. in practice,
the number of features is much smaller because during training only
the combination of properties present in at least one training instance
are included.
features from dependency graph: next, consider the dependency
graph in figure 4.2. since the set of nodes is the same as in sequences,
we do not need to generate any more unigram features. the edges in
the graph gives rise to many new bigram and trigram features. here
are some examples:

[[(entity label = location, part of speech = verb),    ag
=    (1, none)   , type =    dependency   ]].

4.1 predicting the relationship between a given entity pair

323
this feature    res on node pair    (haifa, host)    connected as    host    
haifa    in the dependency graph. a useful trigram feature that we get
out of the dependency graph is

[[(pos = (noun,verb,noun),    ag =    (1,none,2)   , type =
   dependency   ]].

this feature    res on the nodes    (haifa, host, icml)    because of the
edge pattern:    haifa     host     icml.   
features from parse trees: the node set in parse trees consists of the
word nodes at the leaf and the internal nodes. this gives rise to new
unigram features of the form:

[[node =    vp   ,    ag =    2   ]].

also, some of the internal nodes that subsume both the entity nodes e1
and e2 can now have a    ag value of    both   . for example, in figure 4.1,
the    s    node subsumes both the entities and is associated with a    ag
of    both.    in addition, using the parent to child edges in the parse tree
we can de   ne bigram and trigram features as in the case of dependency
graphs.

jiang and zhai [114] report that on eight relationship extraction
tasks on the ace corpus, the accuracy obtained with these simple fea-
tures derived from unigram, bigram, and trigram units of input graphs
is competitive with other methods that interpret the structure more
globally.

4.1.2 kernel-based methods

kernels provide a natural alternative to classi   cation using graphs
because then, instead of worrying about how to convert each graph into
a    at set of features, one just needs to encode the similarity between
the two graphs as a id81. feature-based methods give rise
to a very high dimensional decision space, whereas a suitable kernel in
conjunction with a sparse trainer like id166 can signi   cantly reduce the
e   ective dimensionality of the space. all that is needed is to de   ne over
(cid:2)) that roughly captures
pairs of instances, a id81 k(x, x

324 relationship extraction

(cid:2). then, any method
the similarity between two structures x and x
like a support vector machine (id166) classi   er can be used to predict
the relationship type as follows:

an id166 associates each training instance i and relationship type r
2, ri) :
2). given a new instance

with a weight   ir. recall our training data is of the form (xi, ei
i = 1, . . . , n. we use xi to denote (xi, ei
x = (x, e1, e2) the predicted relationship type   r is de   ned as:

1, ei

1, ei

n(cid:3)

i=1

  r = argmax

r   y

  irk(xi, x).

the values of   ir are estimated during training. details of training are
not relevant to our discussion here and can be found in [208]. we discuss
instead how to de   ne meaningful id81s over the various kinds
of structural inputs to a relationship extraction task.

many id81s that apply either to parse trees or the depen-
dency graph [33, 69, 215, 223, 224, 225] or a composition of the two
have been proposed. of these, kernels over dependency graphs are
most popular. we describe a shortest path based kernel on dependency
(cid:2) represent the
graphs that has been proposed in [33]. let t and t
dependency trees of two di   erent training instances x = (x, e1, e2) and
(cid:2)) is de   ned
(cid:2) = (x(cid:2)
x
as follows. let the unique shortest path connecting the entities (e1, e2)
(cid:2). along each node of the path we have asso-
in t be p and in t
ciated a set of properties of type p1, . . . , pk as described in the previous
section on feature-based methods. two nodes are considered similar if
the value of many of these k properties are common. the node simi-
larities are used to de   ne the id81 as follows:

(cid:2)
2), respectively. the id81 k(x, x

(cid:2) be p

(cid:2)
1, e

, e

(cid:1)|p|

k=1 commonproperties(pk, p (cid:2)

k) otherwise,

if p, p (cid:2) have di   erent lengths

(4.1)

(cid:4)

0
  

k(p, p

(cid:2)

) =

(cid:2)
where commonproperties(pk, p
k) measures the number of properties
(cid:2), respectively.
common between the kth node along the paths p and p
thus, the kernel value is high when the length of the shortest path
between the two entities is the same in both sentences and the nodes
along the path share many common properties.

4.2 extracting entity pairs given a relationship type

325

a shortcoming of the above kernel is that it assigns zero similarity
to paths of di   erent lengths. a more thorough method of capturing
the similarity between two paths is to use convolution kernels, de   ned
originally for strings but later generalized to trees. a follow-up work in
[224] reports slightly better performance with using convolution kernels
on parse trees. kernels have also been proposed to combine the sim-
ilarity along di   erent kinds of input clues including sequences, parse
trees, and dependency graphs [224].

4.2 extracting entity pairs given a relationship type

in the previous section, our task was predicting the type of relationship
between two marked entities in an input text. an alternative scenario
is where we are given one or more relationship types, and our goal is
to    nd all occurrences of those relationships in a corpus [2, 4, 14, 30,
182, 192, 211]. most work in this area has been on open document
collections such as the web, where one cannot assume that the entities
are already marked. typically, there is no labeled unstructured data
for training unlike what we assumed in the previous section. instead,
the seeding of these systems is done by specifying for each relationship
type r the following kinds of inputs

    the types of the entity pair that form the argument of r.
the type of the entity is often speci   ed at a high level, for
example, if the entity argument is a proper or a common noun
or a numeric such as year or currency. more speci   c types
like    person name    and    company names    make sense only
if they are accompanied by patterns that be used to recognize
them in the unstructured text.
    a seed database s of pairs of entities that exhibit the rela-
tionships. in rare cases, negative examples of entity pairs that
do not satisfy the relationship are also given.
    sometimes, a seed set of manually coded patterns are also
available. this is particularly easy for generic relationship
types such as hypernym relationship (parrot is a bird), or
part-of or meronym relationship (steering wheel is a part of
a car). for example, for extracting hypernym relationships,

326 relationship extraction

hearst et al. [105], propose patterns of the form:    (cid:2)noun(cid:3)
such as (cid:2)list of noun phrases(cid:3).   

there are three steps to solving the problem of relationship extrac-
tion starting from the above input. we are given a corpus d, set of
relationship types r1, . . . , rk, entity types tr1, tr2 forming arguments
of relationship type r, and a seed set s of examples of the form
(ei1, ei2, ri) 1     i     n indicating that ei1 has relationship ri with
ei2. optionally, some of these might be marked as negative examples.
an example of the seed input for two relationship types:    isphdad-
visorof    and    acquired    appears below. the entity type arguments
for the    rst relationship is    (person, person)    and the second is
   (company, company)   .

e2

e1
donald knuth andrei broder
alon halevy
je    ullman
alon halevy
google
google
microsoft

anhai doan
surajit chaudhari
dan suciu
you tube
yahoo!
powerset

r

polarity

isphdadvisorof
isphdadvisorof
isphdadvisorof
isphdadvisorof
acquired
acquired
acquired

+
+
+
   
+
   
+

the    rst step is to use the given seed database s of entity pairs to
learn extraction patterns m. the second step is to use a subset of the
patterns to create from the unstructured corpus d candidate triplets
(ei, ej, rij) indicating that entity ei has relationship rij with entity
ej. a    nal validation step is to select only a subset of these candidates
as true entity-relationship triplets based on additional statistical tests.
we elaborate on each of these steps next.

4.2.1 learn patterns from seed triples

for each relationship type r we are given several entity pairs (e1, e2)
indicating that e1 and e2 are related by relationship r. optionally, an
example might be marked as being a negative example for that triplet.
there is an implicit assumption in this task that a given entity pair

4.2 extracting entity pairs given a relationship type

327

cannot be in more than one relationship with each other. therefore, all
entity pairs of a relationship r can serve as negative examples for rela-
(cid:2). a special case is when there is only one
tionship of a di   erent type r
relationship type and there are no negative examples for that type. we
do not consider this case and refer the reader to [211] for a customized
method of extracting high frequency patterns using only positive seed
examples of one relationship type.

the learning of patterns proceeds in three steps that we elaborate

next.
query corpus to find sentences containing an entity pair: the    rst
step in learning the patterns, is to query the corpus to    nd text snip-
pets containing both the entities. typically, a query of the form    e1
near e2    is posed for each example triple of the form (e1, e2, r). for
example, the seed database above would give rise to seven queries of
the form    donald knuth near andrei broder   ,    alon halevy near
anhai doan   , and so on. the near predicate can be made more spe-
ci   c so as to retrieve only documents where the distance is less than
a user-provided threshold [30, 211]. most systems only consider text
snippets that form a complete sentence. this yields for each entity pair
(e1, e2) a bag of sentences s1, s2, . . . , sn such that both entities appear
in the sentence. lightweight linguistic processing on the sentence is
used to    lter away sentences where e1 and e2 do not match the stated
entity types tr1, tr2 of relationship r.
filter sentences supporting the relationship: not all sentences con-
taining the entity pair necessarily support the relationship type. for
example, if we start with a seed triple (donald knuth, andrei broder,
isphdadvisorof) and get two sentences:

broder completed his doctoral thesis under the super-
vision of donald knuth
the invited speakers for the conference are a. broder,
r. karp, and d. knuth.

then, only the    rst sentence is a positive example of the relationship.
automatic    ltering of positive sentences is challenging because there is
no labeled data to go by. banko et al. [14] propose a simple heuristic

328 relationship extraction

for    ltering based on dependency trees. they propose to    rst perform
a dependency parse of the sentence and retain only those sentences as
positive examples where the length of the dependency links between
the occurrences of e1 and e2 in the sentence is no more than a certain
length. this will not always work. in the two sentences above, the
   and    in the second sentence makes    knuth    directly connected to
   broder   .

learn patterns from entity pairs and sentences: now the learning
problem reduces to that of section 4.1 where we have labeled data in
the form of a set of sentences with marked entity pairs and a named
relationship type between the pair. we can then formulate it as a stan-
dard classi   cation problem where given an entity pair marked in a
sentence, we need to predict the relationship between the two entities.
there are two practical problems to training a model by treating each
sentence as an independent training example.

first, in spite of the    ltering there is no guarantee that all sen-
tences are indeed positive examples for the relationship of interest. to
address this problem, bunescu and mooney [30] explored the possibility
of casting this as a multi-instance learning problem. in multi-instance
learning, each positive example is associated with a bag of instances
where at least one of them is guaranteed to be positive but it is not
known which one. however, they obtained better results by treating
each sentence as an independent training instance and invoking a high
performing classi   er such as an id166.

a second di   erence from the setup in section 4.1 is that typically for
each entity pair, say (alon halevy, anhai doan) many sentences will
contain that pair of entities. when the set of seed pairs in the database
is small, the classi   er might include features that are speci   c to par-
ticular entity pairs. for example, words like    schema   ,    integration   
might surface as signi   cant features because they appear in many posi-
tive sentences corresponding to alon halevy, anhai doan, isphdadvi-
sorof. but, these features do not generalize for the    isphdadvisorof   
relationship prediction task. bunescu and mooney [30] propose to solve
this problem by down-weighting terms that have a strong correlation
with the words in the entity pair.

4.2 extracting entity pairs given a relationship type

329

4.2.2 extract candidate entity pairs

now we get to the actual task of    nding all entity pairs in the corpus d
that support the given relationship types. let m denote the relation-
ship extraction model learnt in the previous section. this model takes
as input a sentence x and two entities in it e1 and e2 and predicts the
relationship type between e1 and e2. so, a straightforward method
to    nd all entities in d is to make a sequential pass over d, for each
sentence    nd if it contains two entities of types tr1 and tr2 for each
relationship type r, and if yes, invoke model m to get the right predic-
tion. this approach would work for small to medium sized collections
such as wikipedia, or if an enterprise like a large search engine chooses
to integrate relationship extraction as a part of its processing pipeline
of during o   ine crawling.

when a sequential scan is not feasible but an index on the corpus
exists, it makes sense to retrieve only relevant sentences based on key-
word search patterns, and apply m on the fetched subset. the problem
of    nding the sequence of queries so as to provide the right tradeo    of
cost, recall, and precision raises interesting research challenges partic-
ularly in webscale corpora with all its attendant noise and redundancy.
existing methods are of two types.

pattern-based: the    rst type depend on a set of manually coded
phrase patterns that match sentences which contain the relation-
ships. for example, is   a   e relationships where e is an entity type are
extracted by phrase searches of the form    e such as   ,    or other e   ,
   such e as   ,    e like    and so on [86, 105, 211]. hearst et al. [105]    rst
proposed patterns of the form:    (cid:2)noun(cid:3) such as (cid:2)list of noun phrases(cid:3).   
these patterns have since been enriched and deployed in projects like
knowitall project [86] for extracting instances of a given type from
the web. for part-of relationships, patterns like    y   s x    and    x of the
y    have been proposed in [18]. similarly, it is easy for a human expert
to provide patterns of the form    phd under supervision   ,    phd near
advisor    for collecting instances of    isphdadvisorof    relationship.

keyword-based: the second type depend on keyword matches to
perform subject-level    ltering of documents. for example,    lters

330 relationship extraction

on keywords    vaccine    and    cure    are used to subset documents
containing disease outbreaks in [99]. this raises questions about select-
ing the right sequence of words to ensure that the result of each suc-
cessive query provides the largest set of relevant documents containing
entities not already present in the database. agichtein and gravano
[2, 5] give an iterative solution to the problem. the basic premise of
the method is that documents that contain relevant entities are implic-
itly linked by shared keywords. therefore, by starting from a seed set
of entities, it is possible to fetch, using keyword searches alone, all
documents that contain relevant relationships. the problem is broadly
applicable even for generic information retrieval queries. flake et al.
[94] and others in the ir community have addressed the problem of
generating a sequence of keywords based on a user   s feedback on rele-
vant and irrelevant documents. the main di   erence with the ir setting
is in the notion of relevance of a document. in extraction, relevance is
de   ned based on whether an entity was found in a newly fetched page.
in ir, relevance is judged by a user providing feedback.

4.2.3 validate extracted relationships

the lack of proper training data often results in high error rates in
extractions of the previous step. many systems deploy an additional
validation phase that depends on more expensive aggregate statistics
on the entire corpus to prune away candidates with low support. for
large corpora such as the web, the same relationship instance will be
extracted from many di   erent sentences, typically coming from many
independent sources. the number of occurrences of a relationship can
therefore be used to derive a id203 that the given extraction is
correct as proposed in [82]. we elaborate on how such probabilities
are calculated in section 5.4.3. even when a particular relationship
instance is rare, the contextual pattern in which it occurs is likely
to be frequent and these can be exploited to extract only high con-
   dence relationships [83]. an alternative method is proposed in [182]
based on the observation that a major cause of error in relationship
extraction is errors in marking the boundaries of entities. they cor-
rect this error under the premise that the entity with the correct

4.2 extracting entity pairs given a relationship type

331

boundary will be signi   cantly more frequent than either its subset or
superset.

summary

in this section, we covered the problem of relationship extraction under
two settings. the    rst setting is where we needed to classify the types
of relationships that exist between entities that are already marked
in an unstructured text. we presented feature-based and kernel-based
methods for combining clues from diverse structures such as the word
sequence, parse tree, and dependency graph for the classi   cation task.
for this part, we assumed that the training data consists of a document
collection with labeled relationship types between entity pairs. the
second setting is where we needed to    nd entity pairs in a corpus that
exhibit a given set of relationship types. in this setting, we do not
have labeled unstructured data, just a seed database of entity pairs
exhibiting the relationships. we discussed a number of techniques for
creating a relationship extraction model by id64 from such
seed databases. we then discussed how a pre-existing index can be
used to    lter only relevant subsets likely to exhibit the relationship.

in spite of the extensive research on the topic, relationship extrac-
tion is by no means a solved problem. the accuracy values still range in
the neighborhood of 50%   70% even in closed benchmark datasets such
as ace. in open domains like the web the state-of-the-art systems still
involve a lot of special case handling that cannot easily be described as
principled, portable approaches.

further readings

in this section, we concentrated on the extraction of binary relationship.
a natural extension is to the extraction of records involving multi-way
relationships. record extraction is signi   cantly more complicated since
binary relations are assumed to be at sentence level, whereas multi-
way relationships span sentences. on natural language text this makes
it necessary to perform cross sentence analysis involving co-reference
resolution and discourse analysis. we refer the reader to [148, 218] for
existing work on this topic.

332 relationship extraction

we assumed here that the set of relationship types is known in
advance. as extractions systems start getting deployed in more open-
ended settings, for example, the web and wikipedia, it is not possi-
ble to de   ne the set of relationships in advance. instead, a part of
the extraction process is automatically discovering relevant relation-
ship types. early work on automatic relationship discovery appears in
[14, 39, 192, 211].

5

management of information extraction systems

in the previous sections we presented a number of di   erent models and
algorithms for various kinds of extraction tasks. real-life deployment
of these extraction techniques in the context of an operational system
raises many practical engineering, performance, and usability issues:
how scalable are these techniques? how to integrate the structures
extracted with existing data? since extractions are not guaranteed to be
error-free, how does the storage and querying model adapt to erroneous
sources? as the unstructured source evolves, how does the extraction
model detect the change and adapt to it?

we devote this section to addressing these issues. we    rst discuss
performance-related issues in section 5.1 which includes topics like the
design and use of indices to    lter relevant unstructured sources, e   -
cient lookup of large structured databases during entity extraction and
optimization of extraction pipelines.

next, in section 5.2 we discuss issues related to handling dynam-
ically changing unstructured sources. we discuss techniques for
optimizing the incremental process of extraction, detecting when data
drift causes extractors to fail, and repairing extractors to work with
the modi   ed data.

333

334 management of information extraction systems

in section 5.3, we discuss issues related to the integration of
extracted entities with existing entities in the database and with
repeated occurrences of that entity in the unstructured source. this
is a challenging problem that has been extensively researched under
various names like deduplication, coreference resolution, record linkage
and so on.

in section 5.4, we review techniques for managing errors that arise
in the extraction process. there is much interest in the management
of imprecise data, however the imprecision of information extraction
models raises its own set of challenges. it is not obvious how to assign
numerical con   dence values with each extraction and choose an e   cient
imprecise data model for storing extraction results.

5.1 performance optimization

while many extraction systems have been in operation both com-
mercially and as research prototypes, published research addressing
the various performance aspects of extraction is only starting to
appear.

extraction systems can be deployed in two modes. in one mode
the unstructured source is naturally available, for example in closed
systems like a data warehouse or a complaint processing center. in
the second mode, the unstructured source is open-ended and large,
like the web, and a part of the extraction process is also selecting the
relevant subset of documents. typically, in the    rst mode the user is
interested in annotating all occurrences of the entities/relationships
in the unstructured source, whereas in the second mode, the user   s
interest is in creating a repository of structured entities. therefore, only
documents that are likely to contain new entities need to be processed.
we consider optimizations that have been proposed for making such
selections e   cient in section 5.1.1.

this is followed by a phase of within document    ltering where we
zoom to the right sections of the document. for example, in a citation
system it is necessary to design quick tests to locate the paper headers
and reference sections of papers. existing solutions here are domain-
speci   c, and we do not have anything general-purpose to discuss.

5.1 performance optimization

335

finally, on selected subset of documents the extractors are deployed.
most extraction algorithms scale linearly with the length of the input.
even so, there is a need to optimize their performance because the
pre-processing and feature generation steps tend to be expensive. exist-
ing pattern-based extraction systems are almost always cpu-bound;
i/o    gures only when    nding matches to existing database of enti-
ties. both rule-based and statistical methods depend on features of the
text for recognizing entities and relationships. features have varying
costs of evaluations. some of these, for example if a word is capital-
ized, are cheap to evaluate, whereas others, for example that check
whether a span has a large match to a database of entities, are expen-
sive. in section 5.1.2, we present techniques for e   ciently evaluating
such expensive matches on large databases. in section 5.1.3, we present
optimizations that apply during extractions that depend on a mixture
of cheap and expensive features.

5.1.1 document selection strategies

when the source is really large, there is no alternative to manually
restricting the set through a list of addresses or address domains.
for example, dblife [78] uses a listing of urls pointing to database
researchers    homepages, conference web sites, and mailing lists like
dbworld. when such manual subsetting is not possible, there is a
need for additional levels of pruning and two solutions have been
proposed. the    rst one, applicable only for hyperlinked sources is
to perform some form of focused crawling [47]. the second option
is exploiting pre-existing indices on the unstructured source to fetch
only the documents of interest. this raises issues on how to search
the index and how to design appropriate indices for extraction that
we discuss in the later part of this section. even after a document
is fetched, the cost of running the full-   edged extraction algorithm
on the entire document is often expensive. it might be possible to
design more sophisticated tests, such as a statistical whole-document
classi   er as a second-level    lter of relevance [2].

in general, there is an interesting trade o    between recall and time
among these three options of selecting documents: focused crawling,

336 management of information extraction systems

searching via keywords, and    ltering documents after fetching them
using a classi   er. this is captured as an optimization problem in [110].
one of the contributions of the work is providing a detailed estimation
procedure for recall and running time of various options.

index search techniques: depending on the richness of the index,
queries can be of two types: standard ir-style keyword queries and
pattern queries for entity-level    ltering.

the keyword mode of access is typically used to perform only a
crude subject-level    ltering of documents. for example,    lters on key-
words    vaccine    and    cure    are used to subset documents containing
disease outbreaks in [99]. more discussion of this topic appears in the
context of relationship extraction in section 4.2.2.

pattern queries o   er a    ner grained    ltering of only the entities of
interest from the corpus. as we saw in earlier sections, entity recogni-
tion is more often driven by patterns capturing orthographic proper-
ties of text than keywords. for example, to retrieve mentions of person
names in an indexed document collection, it is not possible to depend
on keyword queries alone. regular expression queries such as    [mr.| dr.
| mrs.] initial dot capitalized word    could be more useful. similarly,
the pattern query    thomas w+ edison    will be more useful to extract
the middle name of thomas edison instead of the ir query    thomas
near edison.    specialized indices and search algorithms are needed
to support pattern-level queries, particularly if they are to support
character-level pattern queries such as    <a href=.*   mp3>   .

some strategies for searching an inverted index with regular expres-
sions are proposed in [58, 172]. an interesting challenge is deploying an
index to retrieve entities for statistical models. an example of such an
index for extracting entity names using patterns involving various fea-
tures like part of speech tags, or orthographic patterns appears in [37].

index design for e   cient extraction: the use of indices in    ltering
for information extraction, raises many engineering questions, which
have not been su   ciently addressed. in general, the index should pro-
vide e   cient support for proximity queries, regular expression patterns,
and allow e   cient storage of tags like pos, phrase tags, common
entity tags like person and company names, and tags from standard

5.1 performance optimization

337

[38],

ontologies such as id138 [180]. cafarella and etzioni
for
example, suggest that the standard inverted index for keyword searches
be augmented to neighborhood tag information along with each (doc-
ument, position) entry in an inverted list. while this makes it e   -
cient to answer queries of the form    cities such as np   , the storage
overhead is huge. chakrabarti et al. [48] discuss how to e   ciently
search an index where the query contains tags coming from a hier-
archy. it also addresses workload-driven strategies for selecting the
subset of tags in a hierarchy that should be directly indexed, instead
of being computed at query time by oring inverted lists of tags
below it.

in order to e   ciently support queries involving id157
at the level of characters, it will be necessary to go beyond existing
word-level inverted indices. two options are su   x trees and q-gram
indices. su   x trees are the classical solution for pattern search queries
but they are too space intensive, and are not a scalable option for
large amounts of data. inverted indices are the de facto choice for large
scale keyword searches. one option to support character-level searches
on inverted indices it to index q-grams, and possibly variable length
q-grams as explored in [117].

5.1.2 e   cient querying of entity databases for extraction

as we discussed in sections 2 and 3, a valuable feature to an entity
extraction system is the degree of similarity of a candidate entity to an
existing entity database. for example, for extracting book titles from
blogs, a very strong clue is provided by a close match with a book
title in a database of published books. however, in order to be able to
use these features we have to    nd the similarity of each possible text
span in the unstructured source to the database of entities. this is an
expensive operation that needs to be optimized separately from other
generic pattern matching operations [49, 179, 190]. since extraction
decisions depend on a diverse set of patterns, only one of which could
be the degree of match with an existing database, in general one needs
to    nd match values for each possible span in an input document. also,
it is meaningless to look for exact match between an input unstructured

338 management of information extraction systems

source and an entity database given that slight mismatch in forms is
inevitable in real-data.

we formalize the problem as follows: we are given an input token
sequence x and a large database of entities d. our goal is to    nd
each possible segment in x whose similarity to an entry in d is greater
than a threshold  . we call this the batch-top-k search problem. we
concentrate on the tf   idf similarity score, which has been found to
be highly e   ective in text searches. the tf   idf similarity between
two text records r1 and r2 is de   ned as follows:

tf   idf(r1, r2) =

(5.1)

(cid:3)
t   r1   r2
(cid:2)
v
t(cid:2)   r v (cid:2)(t(cid:2), r)2

v (t, r1)v (t, r2)
(cid:2)(t, r)

v (t, r) =
(cid:2)

v

(t, r) = log(tf(t, r) + 1)log(idf(t)).

in the above, the idf term makes the weight of a token inversely
proportional to its frequency in the database and the tf term makes it
proportional to its frequency in the record. intuitively, this assigns low
scores to frequent tokens (stop-tokens) and high scores to rare tokens.
the basic top-k search problem with the tf   idf similarity mea-
sure is extensively researched [51, 88, 204, 219] in the information
retrieval and database literature. thus, a simple mechanism of solv-
ing our batch-top-k problem is to invoke the basic top-k algorithm
for each segment in the input sequence. however, since segments have
overlapping tokens there is scope for signi   cant gains by batching their
computations. the state-of-the-art top-k algorithms are highly opti-
mized to balance the number of tidlist1 fetches with record fetches
via lower and upper bound score estimates. utilizing these optimiza-
tions along with e   ectively sharing the partial and    nal results of one
sub-query in the evaluation of another is a challenging problem. chan-
del et al. [49] present an algorithm for optimizing such evaluations
and report signi   cant runtime reductions by designing special purpose
index lookups for entity extraction tasks.

1 tidlist refers to list of tuple-ids containing a given token. this is analogous to document-id
list in an inverted-word index used in ir applications.

5.1 performance optimization

339

5.1.3 optimizations for patterns of variable cost

patterns that depend only on the surface properties of a text span are
cheaper than patterns that require external resources like match with
a database, or expensive operations like inferring the part of speech
of tokens in the span. in rule-based systems where a rule contains a
conjunction of such patterns, it is possible to use tricks from expensive
predicate evaluation in relational systems to reorder predicates based
on the selectivity and cost estimates of each pattern as suggested in
[179, 190].

in statistical systems where hard predicates are missing, the steps
required to minimize the evaluations of expensive patterns are more
involved. consider entity extraction based on a log-linear model where
the score of assigning a particular entity label to a text span is a
weighted sum of features of the span, a subset of which are expen-
sive. chandel et al. [49] show how to minimize the exact evaluations of
the expensive features by exploiting cheap upper and lower bounds on
the values of the expensive features.

in general, both for rule-based and statistical systems an interest-
ing, unexplored problem is to design rules or models which explicitly
account for the cost of evaluating features. the goal during training
then becomes not just accuracy, but also cost minimization during
model deployment. many techniques exist for cost-based learning in
the ml literature [80, 210, 221], but these have not been deployed on
extraction models.

5.1.4 optimization frameworks: relational style

recently, relational engine style frameworks have been proposed for
optimizing the evaluation of rule-based systems for entity and relation-
ship extraction [179, 190]. in rule-based systems, a typical extraction
consists of the following operations:

    predicates that can be evaluated independently on text
spans.
    predicates on text spans that depend on expensive database
lookups.

340 management of information extraction systems

    predicates that involve two text spans. typically, these are
proximity predicates that control the gap between text spans
that form di   erent attributes of a single entity. for example,
the title and abstract of a paper should not be separated by
more than 10 words.

these operations can be cast as select and join predicates of varying
costs operating over document streams. the order of evaluation of these
predicates could have a big impact on running time. for example, the
last operation could be viewed as a join over two streams of text spans:
the    rst that extracts titles and the second that extracts abstracts.
there are three options for evaluating it:    nd title spans    rst and then
check if there is an abstract within 10 words to the right,    nd abstracts
   rst and check if there is a title 10 words to the left, or independently
   nd all title and abstract spans and join to retain pairs that satisfy the
distance constraint. the selection of the right order can be cast as a
relational plan selection problem when proper statistics of selectivity
and running time is attached with each predicate as shown in [179, 190].

5.2 handling change

in an operational setting where extractors are deployed repeatedly on
changing sources, there is a scope for improving performance by reusing
work from previous extractions on the same page. we discuss the lim-
ited work that exists on this topic in section 5.2.1. a related issue
with dynamic data is detecting when an extraction model, trained or
manually tuned, no longer works on newly evolved pages. this issue
has been addressed in the context of generating wrappers for web
pages [56, 122, 128, 176]. in section 5.2.2, we discuss one represen-
tative work in this area [128].

5.2.1

incremental extractions on changing sources

an easy optimization, with clear scope for performance boost, is to
run the extractor only on the changed portions of a page, instead of
the entire page. the success of this optimization rests on being able to
e   ciently detect the regions of the page that have remained unchanged.
this is a well-explored problem and there are standard tools like unix

5.2 handling change

341

di    for    at documents. formatted documents like web pages which fol-
low hierarchical layouts present somewhat di   erent issues. these have
been explored in the context of fragment-level caching in [174, 175].
specially for extraction, chen et al. [53] evaluate the option of detect-
ing regions of change using unix di    and su   x trees. their results
show that both these options are comparable in reducing running time
beyond running the extractor afresh.

5.2.2 detecting when extractors fail on evolving data

we discuss the method proposed in [128] on detecting when a set of
pages have changed enough to cause an extractor to return incorrect
results. the problem is challenging because we need to detect when the
extractor fails even though the content of the source keeps changing. for
example, consider an extractor for locating product names and price
from an auctioning web site. the only change that we are interested
in    agging is when the pattern used for extracting product names and
price changes, not in any change of the content or layout of the page.
let s be a set of documents on which an extractor e is known to
(cid:2) be the new version of the
produce correct structured data d. let s
(cid:2) might not contain necessarily the same set of pages as
documents. s
s, as some pages might have been deleted, and new pages might be
(cid:2) be the data extracted by applying e on s
added. let d
the    rst step is to derive from d a set of data characteristics f
that capture certain key generalizable properties of the data. with
(cid:2). the
the change from s to s
extractor e is declared to be wrong when f and f(cid:2) di   er drastically.
we    rst describe how to calculate generalizable characteristics of a
(cid:2) represent entities
dataset so that we can detect if two datasets d and d
of the same type in spite of di   erences in their content. next, we will
describe how to quantify such di   erences.

(cid:2), recalculate the characteristics f(cid:2) of d

(cid:2).

de   ning characteristic patterns: the main challenge in capturing a
set of characteristics of d is that at the time we capture these charac-
teristics we do not have any other reference dataset that could be used
as a negative example. most pattern learning algorithms require both
positive and negative examples. in the absence of negative examples,

342 management of information extraction systems

one idea for ensuring generalizability is to ensure that the chosen data
characteristics apply to a large number of instances in the dataset d.
the algorithm, dataprog proposed in [128] captures data characteris-
tics as a set of patterns where a pattern is selected only if its frequency
is statistically signi   cant vis-a-vis frequencies of subsets of the pattern.
another design decision in dataprog to avoid choosing very speci   c
patterns is to de   ne patterns over either the beginning or the end of
the data records, instead of the entire record.

we repeat the toy example from [128] to illustrate the kind of pat-
terns that dataprog    nds. the dataset d is the list of the following
   ve street addresses:

4676 admiralty way
10924 pico boulevard
512 oak street
2431 main street
5257 adams boulevard

and the two patterns that comprise the characterizing set f of d are:

p1: number uppercaseword boulevard
p2: number uppercaseword street

the patterns p1 and p2 jointly cover four of the    ve addresses above.
we do not include a pattern such as    number uppercaseword way   
because that would cover too few addresses in this set and possibly
would not generalize.

the algorithm for    nding such patterns follows a top-down pattern
growth procedure and we refer the reader to the paper [128] for its
details.
detecting signi   cant change: let p1       pm be m characteristic pat-
terns discovered in the previous section. let fi be the total count of
(cid:2)
i be the count in the modi   ed version
each pattern i in (d, s) and f
(cid:2)
i is said to be statistically
(d
(cid:2)
(cid:2)) obtained
di   erent from fi, if the expected values e
i of counts in (d
(cid:2)
i . the expected value
by extrapolated from fi, di   ers a lot from f
(cid:2)
(cid:2) and n is the size of s. the check
i = fi
e

(cid:2)). the distribution represented by f

(cid:2) is the size of s

n(cid:2)
n , where n

, s

, s

(cid:2)

(cid:2)

5.3 integration of extracted information 343

(cid:2)
of whether e
i is di   erent enough from f
statistic

m(cid:3)

i=1

(f

i     e
(cid:2)
(cid:2)
i)2
(cid:2)
e
i

(cid:2)
i

.

is performed using the   2

(5.2)

the above statistic is reliable only when the m patterns are inde-
pendent of each other. it is observed in [128] that patterns derived
from both the start and end parts of data performed worse than those
derived from just the starting parts of data because of high correlation
among the two pattern types. also [128] proposes a number of other
(cid:2)
user-de   ned simple aggregate features derived from the pages s and s
instead of restricting to the extracted datasets d and d

(cid:2).

5.3

integration of extracted information

as entities and relationships are extracted from the unstructured
source, they need to be integrated with existing databases and with
repeated mentions of the same information in the unstructured source.
the main challenge in this task is deciding if two strings refer to the
same entity in spite of the many noisy variants in which it appears
in the unstructured source. this problem is variously called dedupli-
cation, coreference resolution, record linkage and so on and has been
extensively studied in many di   erent communities [8, 21, 61, 64, 90,
145, 187, 217].

when data integration is performed on automatically extracted
information, a number of design alternatives arise. ideally, extraction of
all repeated mentions should be done simultaneously and jointly with
integration with existing sources. however, this increases complexity
and running time. existing methods of data integration in the context
of extraction can be categorized under three scenarios depending on
the sequence in which the di   erent tasks are scheduled.

5.3.1 decoupled extractions and integration

in this case each extraction decision is taken independently of any sub-
sequent data integration steps and independent of the extraction of
other repeated mentions. the task during integration is to decide if

344 management of information extraction systems

a given extracted record is the same as any of the existing database
entries, or if it is a new record. this is a basic de-duplication problem
that is solved by reducing to a binary classi   cation problem as follows:
the classi   er takes as input a pair of records and outputs a binary
decision of whether the records in the pair are duplicates of each other
or not. the input features to the classi   er are string similarity functions
such as cosine similarity, id153, jaccard similarity, and soundex.
some of these similarity functions could be domain dependent. for
example, for comparing page numbers in scienti   c publications, a user
could de   ne a special purpose similarity function that makes    408   11   
look similar to    pp. 408   411.    the classi   er could be either a set of
manually de   ned rules on the similarity functions or an automatically
trained classi   er such as a id166 or a decision tree. an example of a
decision tree created on similarity functions de   ned over various    elds
of citation records appears in figure 5.1.

the integration of an extracted record r happens as follows. for each
entry e in the existing database d, we apply the above classi   er on the
pair (r, e) and get a    yes/no    verdict on whether r is a duplicate of e. if
the answer is no for all entries, r is inserted as a new entry. otherwise, it
is integrated with the best matching entry e. this sequential process can
be sped up considerably through index lookups for e   ciently    nding

yeardifference > 1

non-duplicate

non duplicate

titleisnull < 1

pagematch     0.5

authoreditdist     0.8

all-ngrams     0.48

authortitlengrams     0.4

duplicate

duplicate

duplicate

non-duplicate

duplicate

fig. 5.1 an example decision tree for resolving if two citation records are duplicates of each
other or not. each internal node is a similarity function on one or more attributes of the
record.

5.3 integration of extracted information 345

only likely matches. for example, an inverted index on the entries in
the database d can be used to e   ciently retrieve only those records
that contain more than a threshold number of common words with
the extracted record r. word-based indices may not be adequate when
spelling mistakes are common and the text records are short. in such
cases, an index on the sliding window of q-grams in the text is more
useful. in general, a hybrid of the two approaches might yield the best
results as proposed in [51].

5.3.2 decoupled extraction and collective integration

typically when the same entry is extracted from multiple locations,
more accurate integration is possible if all mentions are collectively
grouped into entities instead of integrating one entry at a time. as an
example, consider three records extracted in the order r1, r2, r3.

r1. alistair maclean
r2. a mclean
r3. alistair mclean

before seeing r3, it is unlikely that r1 will be classi   ed as a duplicate
of r2 because the last names of r1 and r2 do not match exactly and
the    rst name is abbreviated. however, after seeing r3, r2 and r1 start
looking similar because of the transitivity of the duplicate-of relation.
this insight is used to cast the collective integration of multiple records
as a graph partitioning problem as follows:

the nodes of the graph are the records. an edge is drawn between
record pairs ei and ej weighted with a score wij. the sign of the score
denotes if the pair is likely to be a duplicate or a nonduplicate, and
the magnitude denotes the con   dence in this outcome. all pairs with
no edges between them are assumed to be connected with a large
negative weight. such scores can be obtained through a number of
means: hand tuned weighted combination of the similarity between
the record pairs, log id203 of the con   dence value of a binary
probabilistic classi   er such as a id28, scores from a binary
id166 classi   er, and so on.

346 management of information extraction systems

in joint deduplication, the goal is to harden the scores to consistent
0/1 labels on all edges. a label assignment is consistent if it satis   es
the transitivity of the is-duplicate-of relation. that is, if the output
label on the edge between ei, ej is 1 and between ej, ek is 1, then the
output on ei, ek also has to be 1. such an output can also be thought
of as a disjoint partitioning of the nodes of the graph such that each
partition denotes a distinct entity. all the edges within a partition are
ones and across partitions are zeros. our goal is to generate a consis-
tent edge label assignment that minimizes the scores of the positive
edges across partitions and negative edges within partitions. this is
called the correlation id91 (cc) problem in [15]. as an example,
consider figure 5.2 which shows a toy weighted graph, the inconsis-
tent solution obtained by independently classifying each pair, and the
optimal consistent solution. however, for general graphs    nding such
optimal solutions is np-hard. charikar et al. [50] provide a linear pro-
gramming (lp) formulation of a relaxed version of the problem. such
lp based approaches are not likely to be practical because for each of
the cubic triples (ei, ej, ek) of records, the lp requires a constraint to
enforce transitivity. a practical alternative is to depend on well-known
id91 algorithms, such as bottom-up agglomerative, or top-down
divisive where the criteria for each greedy step is modi   ed to be the
reduction of the correlation id91 objective as shown in [54].

a

-2

0.5

1

0.33

-0.5

c 

e

0.7

0.8

b

d

f

a

b

d

a

b

d

c

e

c

e

f

f

fig. 5.2 an example of correlation id91. the leftmost    gure is the starting weighted
graphs. the middle graph shows an inconsistent partitioning obtained by retaining only the
positive edges. the rightmost graph is the optimal consistent partitioning.

5.3 integration of extracted information 347

collective multi-attribute
information
extracted spans multiple columns, instead of a single column, collec-
tive integration can have even a greater impact. consider the four
citation records below (from [161]).

integration: when

the

id title
b1 record linkage using crfs
b2 record linkage using crfs
b3 learning boolean formulas
b4 learning of boolean expressions william johnson

author
linda stewart
linda stewart
bill johnson

venue
kdd-2003
9th sigkdd
kdd-2003
9th sigkdd

the similarity between b1 and b2 could be easy to establish
because of the high similarity of the title and author    elds. this in
turn forces the venues    kdd-2003   ,    9th sigkdd    to be called
duplicates even though intrinsic textual similarity is not too high.
these same venue names are shared between b3 and b4 and now it
might be easy to call b3 and b4 duplicates in spite of not such high
textual similarity between the author and title    elds. in fact, such an
iterative scheme can be shown to provably converge to the optimal
decisions about pairs being duplicates of each other. alternately, the
best pairwise labeling of attributes and record pairs being duplicates
or not can be found e   ciently using a minimum cut-based algorithm
as discussed in [194]. however, the optimal pairwise decisions may not
satisfy transitivity. so, a second step is needed to convert the pairwise
decisions obtained here to consistent decisions that correspond to an
entity-level partitioning of the data.

5.3.3 coupled extraction and integration

when extraction is performed in the presence of a large database
of existing entities, we already discussed how to improve extraction
accuracy by adding features such as the maximum similarity of a
text segment to the existing entities. when our goal is also to resolve
which of the existing entities is the same as the entity extracted, a
question that arises is if performing the two steps jointly instead of
independently can improve accuracy. we believe that there is little to
be gained out of joint extraction and integration when the database

348 management of information extraction systems

is not guaranteed to be complete, and when we are extracting single
entities at a time. in contrast, when extracting records or multi-way
relationships consisting of multiple entity subtypes, it is possible to
boost accuracy by coupling the two steps. consider, an example string:
   in his foreword to transaction processing concepts and tech-

niques, bruce lindsay   

suppose we have an existing books database consisting of the fol-

lowing three tables:

    book names where one of the entries is    transaction pro-
cessing: concepts and techniques.   
    people names consisting of entries
like    a. reuters   ,
   j. gray   ,    b. lindsay   ,    d knuth   , and so on.
    authors table linking the book titles with the people who
wrote them.

if we try to independently extract and integrate, it is quite likely
that the string    transaction processing: concepts and techniques   
will be extracted as a book title because of the strong similarity to the
entry in the booknames table. similarly,    bruce lindsay    is likely to
be extracted as the author because the string    bruce lindsay    matches
an entry in the people names tables and because of its placement next
to the string marked as book title. after the extraction, when we try
to integrate the results with the database entries we will fail because of
inconsistency with the existing author names in the database. in con-
trast, combined extraction and integration will avoid the error during
extraction itself. however, modifying the id136 algorithms used for
extraction to handle such database imposed constraints raises new chal-
lenges. we refer the readers to [151, 217], and [138] for three di   erent
mechanisms in which such constraints are handled.

5.4

imprecision of extraction

errors in extractions are inevitable, particularly in open domain
unstructured sources where it is impossible to foresee all di   erent
patterns of noise. in many cases users of automatically extracted
databases have come to live with erroneous outputs. for example, users

5.4 imprecision of extraction

349

of automatically curated citation databases such as the google scholar
and citeseer, are aware that a bibtex entry on these sites is to be
trusted less than that obtained from manually curated web sites such
as the acm digital library. the automatically extracted databases still
serve their role in terms of providing a more comprehensive, but by no
means error-free, list of forward citations.

as the scope of extraction based systems expands to business crit-
ical situations, there is increasing research interest in more formally
capturing the errors of extraction as an imprecise data model so that
the answers of queries can be associated with correctness indicators.
many imprecise data models are being actively explored in the database
research community. a top-level characterization is based on whether
imprecision is represented quantitatively as a id203 distribution,
or not. in the probabilistic approach each possible world has a proba-
bility value associated with it, whereas in a nonprobabilistic approach
there is a hard notion of whether a particular combination of values
is possible. such constraints are often provided as logical predicates
attached to rows, columns, or entire tables in the database. we will
consider the probabilistic approach for the rest of the discussion.

we concentrate on the problem of how to populate a probabilistic
database so as to faithfully represent the uncertainty of extraction. we
consider only simple models based on row and column uncertainties
because the cost of query processing on more complicated probabilistic
models could get prohibitively high. we give an overview of existing
work under three di   erent scenarios.

5.4.1 con   dence values for single extractions

consider the simplest setting where we are performing independent
extractions of some structured entity, say list of protein names, or
book titles. we can represent the imprecision of this extraction in one
of two possible ways. the    rst is to associate each extracted information
with a id203 value. the second method extends the    rst approach
to output multiple possible extractions instead of a single extraction.
for a given source string, the sum of the id203 of the di   erent
possibilities is one. for example, the output of an extraction of book

350 management of information extraction systems

titles from sentences could look like this:

id title
1
1
1
2
2

last theorem
fermat   s last theorem
the fermat   s last theorem
   transaction processing: concepts and techniques   
transaction processing

pr
0.5
0.3
0.2
0.95
0.05

the above example shows that the    rst option of keeping only the
highest scoring extraction would miss the second correct extraction
from the    rst source.

surprisingly, it is very di   cult to get such id203 estimates
from typical extraction models. the reason is that the id203 val-
ues convey more than just vague notions of correctness. there is a
speci   c interpretation of the id203 estimates with regard to what
they tell us about the correctness of the results. suppose, we have
a ground truth database using which we can    nd out which of the
extractions are correct and which are wrong. if the id203 esti-
mates are sound, then we expect that roughly p fraction of the entries
marked with probabilities between p       and p +   are correct. many
well-known entity recognition methods such as rules, id90,
statistical classi   ers such as id166s, and naive bayes classi   ers, while
adequate for outputting a single most preferred entity, fail badly when
used to associate con   dence values with their outputs.

a study that compared di   erent classi   ers on the goodness of the
con   dence scores that they output is reported in [158]. a useful visual
tool to measure the soundness of the probabilities output by a classi   er
is a reliability plot. the x-axis of a reliability plot are binned probabili-
ties output by a classi   er and the y -axis is the fraction of test instances
in that id203 bin whose predictions are correct. two examples
of reliability plots for extractions using a crf-based extractor (sec-
tion 3.1.2) are shown in figure 5.3. the closer the bin heights are to the
45 degree line, the better calibrated are the id203 estimates of the
classi   er. the study concluded that popular methods such as decision
tree classi   ers, naive bayes classi   ers, and, id166s provide really poor

n
o

i
t

t

a
n
e
m
g
e
s
 
p
o

t
 
f

i

 

o
n
o
s
c
e
r
p

i

1

0.8

0.6

0.4

0.2

0

0

0.4

0.2
0.8
id203 of top segmentation

0.6

1

5.4 imprecision of extraction

351

1

0.8

0.6

0.4

0.2

0

0

0.4

0.2
0.8
id203 of top segmentation

0.6

1

n
o

i
t

t

a
n
e
m
g
e
s
 
p
o

t
 
f

i

 

o
n
o
s
c
e
r
p

i

fig. 5.3 reliability plots for two datasets. the diagonal line denotes the ideal ending points
of the bars.

id203 values. in contrast, classi   ers like id28s and
neural networks provide very sound estimates. crfs are a generaliza-
tion of id28 classi   ers, and id48s are a generalization of
naive bayes classi   ers. so, we expect similar conclusions to hold for the
relative performance of these two entity extraction models.

it is easy to extend sequence models like crfs to return a set of
k highest id203 extractions instead of a single most likely extrac-
tion. we only need to change the viterbi algorithm discussed in sec-
tion 3.5.1 to maintain top-k highest scoring solution at each position.
uncertainty management in rule-based models is more di   cult than
for statistical models that are rooted in probabilistic modeling to start
with. many rule-learning systems associate each rule with a precision
value that indicates for all    rings of the rule condition, the fraction
of cases where the action associated with the rule is correct. however,
there is little principled work on obtaining sound probabilities when an
extraction is due to the combined application of many rules, or when
the    rings of multiple rules overlap. even for a single rule, obtaining
con   dence estimates is not easy as evidenced by the poor performance
of decision tree classi   ers in the evaluation conducted in [158].

5.4.2 multi-attribute extractions

we now consider the case where we are extracting multiple attributes of
an entity from a single source string. examples include the extraction of
   elds like house number, area, city, and zipcode from address strings

352 management of information extraction systems

and the extraction of model name, make, number of doors and price
from car sales ads. unlike in the previous case we cannot assume that
the di   erent attributes extracted are independent of each other.

assume that the results of these extractions are stored as multiple
columns of a single database table. a simple extension of the previous
multi-row imprecision model is to maintain with each row a id203
value exactly as in the single column case. an example for the case of
address strings is given below where we show four possible extractions
of the    elds of an address from the string    52-a goregaon west mumbai
400 076.    again, these four rows together provide a more informative
summary of the imprecision in the data than possible with the highest
id203 row alone.

city

id house no area
1
1
1
1

52
52-a
52-a
52

goregaon west mumbai
goregaon
goregaon west mumbai
goregaon

west mumbai

west mumbai

pincode prob
400 062
400 062
400 062
400 062

0.1
0.2
0.5
0.2

however, for multi-attribute data, another possible method of rep-
resenting uncertainty is through a id203 distribution attached to
each column. an example is shown below:

id house no
1

52 (0.3)
52-a (0.7)

area
goregaon
west (0.6)
goregaon (0.4)

city

mumbai (0.6)
west mumbai
(0.4)

pincode

400 062
(1.0)

in the above, each column stores a distribution of the possible values
that it can take. the id203 of any speci   c combination of values
is obtained by multiplying the id203 of the corresponding values
from each column. this representation is more compact than explicitly
storing the id203 for each possible combination at the row-level.
however, a downside of the method is that it may not faithfully capture
the probabilities of the original extraction output. [102] proposes a
hybrid method of keeping both row and column level distributions and
an example is shown below.

5.4 imprecision of extraction

353

id house no
52 (0.167)
1
52-a (0.833)
52 (0.5)
52-a (0.5)

1

city

mumbai (1.0)

area
goregaon
west (1.0)
goregaon (1.0) west

mumbai (1.0)

pincode
400 062
(1.0)
400 062
(1.0)

prob
0.6

0.4

the creation of such imprecise models is however not easy. for the
speci   c case of a crf model, [102] presents algorithms for obtaining
the best model for each unstructured source. since the details of the
steps are speci   c to crfs we do not present the method here. an inter-
esting future work is creating such hybrid models from other baseline
extraction models.

5.4.3 multiple redundant extractions

when the same information is extracted from multiple sources, there is
a need to reason about the resultant uncertainty out of a data integra-
tion phase following an extraction phase. consider the simple case of
extracting single attribute entities from multiple independent sources.
also, for the sake of simplicity, assume that each extraction generates
a single most likely output with a id203 denoting its con   dence.
as an example, consider the table of extractions below:

id title
1
2
3
4
5
6
7
8
9

last theorem
   transaction processing: concepts and techniques   
transaction processing
fermat   s last theorem
the fermat   s last theorem
transaction processing: concepts and techniques
transaction processing concepts and techniques
fermat   s last theorem
fermat   s last theorem

pr
0.5
0.95
0.4
0.3
0.5
1.0
1.0
0.9
0.8

there are two kinds of uncertainties in the above table: first is the
single source extraction uncertainty indicated by the probabilities in

354 management of information extraction systems

each row. second, we have co-reference uncertainty between every pair
of strings of whether they refer to the same entity or not (not quanti   ed
in the table). including both these sources of uncertainties into a single
uncertainty value is a challenging problem. existing work addresses one
of the following two settings:

(1) assume only extraction uncertainty and ignore co-reference
uncertainty by assuming that an exact method exists for
resolving if two strings are the same.

(2) assume there is only co-reference uncertainty and each string

has no uncertainty attached to it referring to an entity.

we will discuss only the    rst kind of uncertainty and refer the reader
to [145, 162] for uncertainty models for the second setting. we present
three di   erent methods of combining evidence from multiple extrac-
tions into a single uncertainty value.

the noisy-or model: consider the case where for a given extracted
string x we have n repetitions, and the probabilities attached with the
n extractions are p1, . . . , pn. our goal is to convert this into a single
id203 value p of x being a correct instance of the entity type y.
one simple approach is to assume that each extraction is an indepen-
dent event. then the id203 that x is of type y is equal to the
id203 that at least one of the extractions is correct. this is called
the noisy-or model and is given by

p = 1     n(cid:1)

(1     pi).

(5.3)

i=1

thus, in our example table, the id203 that the string    fermat   s
last theorem    that appears thrice with id203 0.8, 0.9, and 0.3 is
a book title is calculated as 1     0.2    0.1    0.7 = 0.986     a very high
id203 indeed.

a shortcoming of the noisy-or model is that the assumption that
di   erent extractions are independent of each other often does not hold
in practice. to see an extreme case where the noisy-or model can give
nonintuitive results, consider the case where we have 100 extractions of
a string each with a con   dence of 0.1. the combined id203 in this

5.4 imprecision of extraction

355

case is very close to 1, but if all 100 extractions were due to the same
incorrect pattern then it is quite likely that the pattern is wrong given
the individual con   dence value of 0.1. the soft-or function is another
proposed method that chooses the overall precision as the maximum of
any of the existing precision.

p = nmax
i=1

pi.

(5.4)

in this example, soft-or will return a con   dence of 0.1. however, it
seems rather pessimistic to stick to a con   dence value of 0.1 given 100
occurrences of the string.

we next discuss more sophisticated models that reward repetitions
without assuming independence. these models assume that there are
multiple patterns that can generate an entity. let m1, . . . , mk denote
these patterns. for example, in a rule learning system the patterns
could correspond to the di   erent rules whose action lead to the extrac-
tion of an entity of a given type y. each extraction is associated with
the pattern that generated it. thus, for a given string x we can calculate
counts n1, . . . , nk of the number of times x was extracted using pattern
m1, . . . , mk, respectively. for this part, we ignore the con   dence val-
ues attached with individual extractions. our goal is to use the counts
n1, . . . nk to estimate for a given string x the id203 that it is
indeed an instance of type y. that is, we want, pr(x     y|n1, . . . , nk).
two category of methods have been proposed for this. we    rst
present an easy to implement method applicable for the case where
we have labeled data. later we present a more complicated generative
method that does not necessarily require labeled data.
id155 models from labeled data: this approach
based on labeled data does not make any assumption about the inde-
pendence of the di   erent patterns. instead, it directly learns the condi-
tional id203 pr(y|n1, . . . , nk) using well-known methods such as
logistic classi   ers as follows:

pr(y|n1, . . . , nk) =

(5.5)
the parameters w1       wk, b are estimated using labeled data in an o   ine
training phase.

1 + exp(

(cid:2)k
1
i=1 wini + b)

356 management of information extraction systems

generative models for unlabeled data: the second method taken
from [82] is more involved and can be skipped on    rst reading.

consider the case of    rst a single pattern m1. let n1j denote the
(cid:2)
total number of times string xj is extracted using m1. therefore, the
j n1j = n1.
total number of times pattern m1    red over all strings is
assume we have a distribution function for each class y, pr(f|y) that
gives the id203 that x appears in fraction f of the total cases n1.
we can then use bayes rule to estimate pr(y|n1j) as
pr(y|n1j) =

(cid:2)
f c(n1, n1j)f n1j (1     f)n1   n1j pr(f|y)pr(y)
(cid:2)
f c(n1, n1j)f n1j (1     f)n1   n1j pr(f|y)pr(y) .

(cid:2)

y=0,1

(5.6)

in the above equation, the outer summation goes over all possible values
f of the id203 of getting x from pattern m1. the unknown terms
in the above are pr(f|y) and pr(y). before we discuss how these are
estimated, let us generalize to the case of multiple patterns.

a straightforward generalization is to assume that we have a joint
distribution over the full space of the fractional occurrence of each
string in each pattern. thus, if we had a full distribution pr(f1       fk|y)
we could generalize the above equation to estimate the joint distribution
pr(y|n1j        nkj) as:
(cid:9)k
(cid:2)
(cid:9)k
nij
i=1 c(ni, nij)f
i
nij
i=1 c(ni, nij)f
i

(1     fi)ni   nij pr(f1       fk|y)pr(y)

(1     fi)ni   nij pr(f1       fk|y)pr(y)
(5.7)

(cid:2)

(cid:2)

f1,...,fk

f1,...,fk

y=0,1

.

however, it is di   cult to estimate the joint distribution. downey
et al. [82] simpli   es the space in the following way. for the case when
y = 1, create a discrete distribution as follows. assume there are c dis-
tinct strings of type y numbered arbitrarily from 1 to c. the jth string
has id203 fij in pattern i and is given by a zip   an distribution as:

fij = pi

   zc(cid:2)
j
k k   zc

,

where pi is a user-provided term denoting the precision of pattern mi,
zc is a parameter that is estimated.

5.4 imprecision of extraction

357

similarly, for the case of y = 0, that is all the wrong strings, assume
there are a total e of them and a di   erent parameter ze. using this we
get a di   erent set of e fractions calculated for di   erent values of j as

gij = (1     pi)

   ze(cid:2)
j
k k   ze

.

with these values calculated, the joint id203 is calculated as
follows: pr(v1       vk|y = 1) = 1
c if there exists an index j for which vi =
fij. if no such index exists the id203 is zero. pr(v1       vk|y = 0) =
1
e if for each pattern i, we have an index position ki such that vi =
giki. note for the case of y = 1 we assume that the probabilities are
correlated in the sense that there exists a shared ordering of the strings
across the di   erent patterns. this captures the intuition that strings
which have high id203 of occurrence in one pattern will also have
high id203 of occurrence in another. in contrast, for the case of
y = 0 we do not make any such assumption. the values of zc, ze,
c, and e are calculated using an expectation minimization procedure
where the hidden variable denotes if a particular string is an instance
of y or not.

5.4.4 other techniques for managing extraction errors

there are many other dimensions to the handling of imprecision in
extraction systems that we have not discussed here. one important
issue is querying the results of uncertain extractions. the approach in
this discussion have been to represent extraction uncertainty in terms
of generic imprecision models, and then leverage on the active research
on e   cient querying of uncertain data [28, 55, 75, 183] for getting
probabilistic answers. however, since automatically extracted data is
most popular in decision support systems, models and algorithms for
answering multidimensional aggregate queries on such imprecise data
is a popular research problem on its own right. we refer the reader to
[34, 35] for existing work in this direction. another practical solution to
the problem of uncertain extractions is to provide provenance support
in databases created out of the results of extractions. this can enable
a user to track down erroneous results or missed extractions as shown
in [107]. other issues that we have not discussed here are: modeling

358 management of information extraction systems

the reliability of the unstructured source, capturing the dependence
of current extraction on the outputs of previous imprecise extractions,
and managing uncertainties with evolving data.

overall, existing methods for the management of imprecision in
information extraction is still at a preliminary stage. substantially more
experience is needed before we understand imprecision in a way that we
can create reliable models that are useful without being unmanageably
complex.

6

concluding remarks

many applications depend on the automatic extraction of structure
from unstructured data for better means of querying, organizing, and
analyzing data connecting the structured and unstructured world.
starting from research in the natural language community on basic
id39 systems, the topic now engages a verita-
ble community of researchers spanning machine learning, databases,
web, and information retrieval. a lot of work now exists on various
aspects of the information extraction problem including core statisti-
cal and rule-based models, frameworks and architectures for managing
the extraction pipelines, performance optimization, uncertainty man-
agement, and so on.

in the    rst part of the survey, we concentrated on core models for
the extraction of entities and relationships via rule-based and statis-
tical models. we presented di   erent forms of rules for entity extrac-
tion and for resolving con   icts when multiple rules    re on overlapping
tokens. most often rule-based systems are manually coded but there
also exist e   cient methods for learning rules from labeled data. when
labeled data is available, such rule-learning algorithms provide a valu-
able starting set of rules for manual tuning later. statistical methods

359

360 concluding remarks

are more useful when the input sources are noisy so that hard predi-
cates of rule-based extractors hurt. we described conditional random
fields, a state-of-the-art method for entity recognition that imposes a
joint distribution over the sequence of entity labels assigned to a given
sequence of tokens. although the details of training and id136 on
statistical models are somewhat involved for someone outside the    eld
of statistical machine learning, the models are easy to deploy and cus-
tomize due to their fairly nonrestrictive feature based framework.

on the topic of relationship extraction we considered two scenarios:
one where entities are already annotated in the corpus and our goal is
to classify the type of relationship that exists between a given entity
pair, and second where for a given relationship type we need to retrieve
all instances of entity pairs from an un-annotated corpus given only a
seed set of pairs that exhibit that relationship. for the    rst problem, we
presented di   erent methods of combining clues from intervening words
and their properties, parse trees, and dependency graphs to perform
the classi   cation. the solution for the second problem builds upon
the    rst and the two additional challenges: training models based on
only a seed database, and designing    lter queries to retrieve only the
relevant portions of a large corpus. we discussed existing methods for
solving these problems, but compared to entity extraction, the problem
of relationship extraction from open domains is still at a preliminary
stage of exploration. more extensive study from a larger community of
researchers is needed to get consensus on sound ideas that generalize.
we then discussed existing work on a number of practical issues
like performance optimization, dynamic data management, uncertainty
handling, and data integration.

in spite of more than two decades of research on designing models
for extraction, accuracy continues to be of prime concern. while for
basic named entities, it is possible to achieve close to 90% accuracy
with state-of-the-art extraction models, for relationship extraction the
accuracy is in the neighborhood of 70% even in restricted domains such
as news articles. more complex types of extractions such as, extraction
of long entities, soft attributes of entities, and higher order structures,
are only starting to be explored. although there are many existing sys-
tems that use information extraction in a core way, published research

361

literature providing principled solutions to many of the practical issues
arising in the management of extraction systems are only starting
to appear. the time is ripe now for lot more exciting and useful
work in practical large-scale deployments of information extraction
systems.

acknowledgments

i am indebted to many people for making this survey possible. first,
i would like to thank surajit chaudhuri for getting me to take a break
from research and spend time on the survey instead. i thank the anony-
mous reviewers and anhai doan for su   ering through my hurriedly
drafted    rst version and helping me produce a signi   cantly improved
   nal version. ganesh ramakrishnan helped me with the rule-learning
section by providing important references and helping me maintain bal-
ance with the statistical methods. soumen chakrabarti deserves thanks
for encouraging me to stay focused on completing the survey.

my life as a researcher during this period was supported by grants

from microsoft research and ibm, and iit bombay, my employer.

362

references

[1] 2004. ace. annotation guidelines for entity detection and tracking.
[2] e. agichtein,    extracting relations from large text collections,    phd thesis,

columbia university, 2005.

[3] e. agichtein and v. ganti,    mining reference tables for automatic text
segmentation,    in proceedings of the tenth acm sigkdd international
conference on knowledge discovery and data mining, seattle, usa,
2004.

[4] e. agichtein and l. gravano,    snowball: extracting relations from large plain-
text collections,    in proceedings of the 5th acm international conference on
digital libraries, 2000.

[5] e. agichtein and l. gravano,    querying text databases for e   cient informa-

tion extraction,    in icde, 2003.

[6] r. agrawal, h. mannila, r. srikant, h. toivonen, and a. i. verkamo,    fast
discovery of association rules,    in advances in knowledge discovery and data
mining, (u. m. fayyad, g. piatetsky-shapiro, p. smyth, and r. uthurusamy,
eds.), ch. 12, pp. 307   328, aaai/mit press, 1996.

[7] j. aitken,    learning information extraction rules: an inductive logic program-
ming approach,    in proceedings of the 15th european conference on arti   cial
intelligence, pp. 355   359, 2002.

[8] r. ananthakrishna, s. chaudhuri, and v. ganti,    eliminating fuzzy duplicates
in data warehouses,    in international conference on very large databases
(vldb), 2002.

[9] r. ando and t. zhang,    a framework for learning predictive structures from
multiple tasks and unlabeled data,    journal of machine learning research,
vol. 6, pp. 1817   1853, 2005.

363

364 references

[10] d. e. appelt, j. r. hobbs, j. bear, d. j. israel, and m. tyson,    fastus:
a    nite-state processor for information extraction from real-world text,    in
ijcai, pp. 1172   1178, 1993.

[11] a. arasu, h. garcia-molina, and s. university,    extracting structured data
from web pages,    in sigmod    03: proceedings of the 2003 acm sigmod
international conference on management of data, pp. 337   348, 2003.

[12] s. argamon-engelson and i. dagan,    committee-based sample selection for
probabilistic classi   ers,    journal of arti   cial intelligence research, vol. 11,
pp. 335   360, 1999.

[13] m.-f. balcan, a. beygelzimer, and j. langford,    agnostic active learning,   

in icml, pp. 65   72, 2006.

[14] m. banko, m. j. cafarella, s. soderland, m. broadhead, and o. etzioni,    open

information extraction from the web,    in ijcai, pp. 2670   2676, 2007.

[15] n. bansal, a. blum, and s. chawla,    correlation id91,    in focs    02:
proceedings of the 43rd symposium on foundations of computer science,
usa, washington, dc: ieee computer society, 2002.

[16] g. barish, y.-s. chen, d. dipasquo, c. a. knoblock, s. minton, i. muslea, and
c. shahabi,    theaterloc: using information integration technology to rapidly
build virtual applications,    in international conference on data engineering
(icde), pp. 681   682, 2000.

[17] r. baumgartner, s. flesca, and g. gottlob,    visual web information extrac-
tion with lixto,    in vldb    01: proceedings of the 27th international con-
ference on very large data bases, pp. 119   128, usa, san francisco, ca:
morgan kaufmann publishers inc, 2001.

[18] m. berland and e. charniak,    finding parts in very large corpora,    in pro-
ceedings of the 37th annual meeting of the association for computational
linguistics on computational linguistics, pp. 57   64, 1999.

[19] m. bhide, a. gupta, r. gupta, p. roy, m. k. mohania, and z. ichhaporia,
   liptus: associating structured and unstructured information in a banking
environment,    in sigmod conference, pp. 915   924, 2007.

[20] d. m. bikel, s. miller, r. schwartz, and r. weischedel,    nymble: a high-
performance learning name-   nder,    in proceedings of anlp-97, pp. 194   201,
1997.

[21] m. bilenko, r. mooney, w. cohen, p. ravikumar, and s. fienberg,    adaptive
name-matching in information integration,    ieee intelligent systems, 2003.
[22] 2006. biocreative     critical assessment for information extraction in biology.

http://biocreative.sourceforge.net/.

[23] j. blitzer, r. mcdonald, and f. pereira,    id20 with structural
correspondence learning,    in proceedings of the empirical methods in natural
language processing (emnlp), 2006.

[24] a. bordes, l. bottou, p. gallinari, and j. weston,    solving multiclass support

vector machines with larank,    in icml, pp. 89   96, 2007.

[25] v. r. borkar, k. deshmukh, and s. sarawagi,    automatic text segmenta-
tion for extracting structured records,    in proceedings of acm sigmod
international conference on management of data, santa barabara, usa,
2001.

references

365

[26] a. borthwick, j. sterling, e. agichtein, and r. grishman,    exploiting diverse
knowledge sources via maximum id178 in id39,    in sixth
workshop on very large corpora new brunswick, new jersey, association for
computational linguistics, 1998.

[27] l. bottou,    stochastic learning,    in advanced lectures on machine learning,
number lnai 3176 in lecture notes in arti   cial intelligence, (o. bousquet
and u. von luxburg, eds.), pp. 146   168, springer verlag, 2004.

[28] j. boulos, n. dalvi, b. mandhani, s. mathur, c. re, and d. suciu,    mystiq:
a system for    nding more answers by using probabilities,    in acm sigmod,
2005.

[29] a. z. broder, m. fontoura, v. josifovski, and l. riedel,    a semantic approach

to contextual advertising,    in sigir, pp. 559   566, 2007.

[30] r. bunescu and r. mooney,    learning to extract relations from the web using
minimal supervision,    in proceedings of the 45th annual meeting of the asso-
ciation of computational linguistics, pp. 576   583, june 2007.

[31] r. bunescu and r. j. mooney,    collective information extraction with
the 42nd annual meet-
the association for computational linguistics, pp. 439   446,

relational markov networks,    in proceedings of
ing of
2004.

[32] r. c. bunescu, r. ge, r. j. kate, e. m. marcotte, r. j. mooney, a. k.
ramani, and y. w. wong,    comparative experiments on learning informa-
tion extractors for proteins and their interactions,    arti   cial intelligence in
medicine, vol. 33, pp. 139   155, 2005.

[33] r. c. bunescu and r. j. mooney,    a shortest path dependency kernel for
id36,    in hlt    05: proceedings of the conference on human
language technology and empirical methods in natural language processing,
pp. 724   731, usa, morristown, nj: association for computational linguis-
tics, 2005.

[34] d. burdick, p. m. deshpande, t. s. jayram, r. ramakrishnan, and
s. vaithyanathan,    olap over uncertain and imprecise data,    in proceedings
of the 31st international conference on very large data bases, pp. 970   981,
vldb endowment, 2005.

[35] d. burdick, a. doan, r. ramakrishnan, and s. vaithyanathan,    olap over

imprecise data with domain constraints,    in vldb, pp. 39   50, 2007.

[36] m. cafarella, n. khoussainova, d. wang, e. wu, y. zhang, and a. halevy,

   uncovering the relational web,    in webdb, 2008.

[37] m. j. cafarella, d. downey, s. soderland, and o. etzioni,    knowitnow: fast,
scalable information extraction from the web,    in conference on human lan-
guage technologies (hlt/emnlp), 2005.

[38] m. j. cafarella and o. etzioni,    a search engine for natural language appli-

cations,    in www, pp. 442   452, 2005.

[39] m. j. cafarella, c. re, d. suciu, and o. etzioni,    structured querying of web

text data: a technical challenge,    in cidr, pp. 225   234, 2007.

[40] d. cai, shipengyu, ji-rongwen, and w.-y. ma,    vips: a vision based
page segmentation algorithm,    technical report msr-tr-2003-79, microsoft,
2004.

366 references

[41] y. cai, x. l. dong, a. y. halevy, j. m. liu, and j. madhavan,    personal
information management with semex,    in sigmod conference, pp. 921   923,
2005.

[42] m. cali    and r. mooney, bottom-up relational learning of pattern matching

rules for information extraction, 2003.

[43] m. e. cali    and r. j. mooney,    relational learning of pattern-match rules for
information extraction,    in proceedings of the sixteenth national conference
on arti   cial intelligence (aaai-99), pp. 328   334, july 1999.

[44] v. t. chakaravarthy, h. gupta, p. roy, and m. k. mohania,    e   ciently link-
ing text documents with relevant structured information,    in vldb, pp. 667   
678, 2006.

[45] s. chakrabarti, mining the web: discovering knowledge from hypertext data.

morgan-kau   man, 2002.

[46] s. chakrabarti, j. mirchandani, and a. nandi,    spin: searching personal infor-

mation networks,    in sigir, p. 674, 2005.

[47] s. chakrabarti, k. punera, and m. subramanyam,    accelerated focused crawl-
ing through online relevance feedback,    in www, hawaii, acm, may 2002.
[48] s. chakrabarti, k. puniyani, and s. das,    optimizing scoring functions and
indexes for proximity search in type-annotated corpora,    in www, pp. 717   
726, 2006.

[49] a. chandel, p. nagesh, and s. sarawagi,    e   cient batch top-k search for
dictionary-based entity recognition,    in proceedings of the 22nd ieee inter-
national conference on data engineering (icde), 2006.

[50] m. charikar, v. guruswami, and a. wirth,    id91 with qualitative infor-
mation,    journal of computer and systems sciences, vol. 71, pp. 360   383,
2005.

[51] s. chaudhuri, k. ganjam, v. ganti, and r. motwani,    robust and e   cient

fuzzy match for online data cleaning,    in sigmod, 2003.

[52] chelba and acero,    adaptation of maximum id178 capitalizer: little data

can help a lot,    in emnlp, 2004.

[53] f. chen, a. doan, j. yang, and r. ramakrishnan,    e   cient information

extraction over evolving text data,    in icde, 2008.

[54] d. cheng, r. kannan, s. vempala, and g. wang,    a divide-and-merge
methodology for id91,    acm transactions on database systems, vol. 31,
pp. 1499   1525, 2006.

[55] r. cheng, d. v. kalashnikov, and s. prabhakar,    evaluating probabilistic
queries over imprecise data,    in sigmod    03: proceedings of the 2003 acm
sigmod international conference on management of data, pp. 551   562,
usa, new york, ny: acm press, 2003.

[56] b. chidlovskii, b. roustant, and m. brette,    documentum eci self-repairing
wrappers: performance analysis,    in sigmod    06: proceedings of the 2006
acm sigmod international conference on management of data, pp. 708   
717, usa, new york, ny: acm, 2006.

[57] 1998. n. a. chinchor, overview of muc-7/met-2.
[58] j. cho and s. rajagopalan,    a fast regular expression indexing engine,    in

icde, pp. 419   430, 2002.

references

367

[59] y. choi, c. cardie, e. rilo   , and s. patwardhan,    identifying sources
of opinions with conditional random    elds and extraction patterns,    in
hlt/emnlp, 2005.

[60] f. ciravegna,    adaptive information extraction from text by rule induction
and generalisation,    in proceedings of the 17th international joint conference
on arti   cial intelligence (ijcai2001), 2001.

[61] w. cohen and j. richman,    learning to match and cluster entity names,    in
acm sigir    01 workshop on mathematical/formal methods in information
retrieval, 2001.

[62] w. w. cohen, m. hurst, and l. s. jensen,    a    exible learning system for
wrapping tables and lists in html documents,    in proceedings of the 11th world
wide web conference (www2002), 2002.

[63] w. w. cohen, e. minkov, and a. tomasic,    learning to understand web site

update requests,    in ijcai, pp. 1028   1033, 2005.

[64] w. w. cohen, p. ravikumar, and s. e. fienberg,    a comparison of string
distance metrics for name-matching tasks,    in proceedings of the ijcai-2003
workshop on information integration on the web (iiweb-03), 2003.
(to
appear).

[65] w. w. cohen and s. sarawagi,    exploiting dictionaries in named entity
extraction: combining semi-markov extraction processes and data integration
methods,    in proceedings of the tenth acm sigkdd international confer-
ence on knowledge discovery and data mining, 2004.

[66] d. a. cohn, z. ghahramani, and m. i. jordan,    active learning with sta-
tistical models,    in advances in neural information processing systems,
(g. tesauro, d. touretzky, and t. leen, eds.), pp. 705   712, the mit press,
1995.

[67] v. crescenzi, g. mecca, p. merialdo, and p. missier,    an automatic data
grabber for large web sites,    in vldb   2004: proceedings of the thirtieth inter-
national conference on very large data bases, pp. 1321   1324, 2004.

[68] a. culotta, t. t. kristjansson, a. mccallum, and p. a. viola,    corrective
feedback and persistent learning for information extraction,    arti   cial intel-
ligence, vol. 170, nos. 14   15, pp. 1101   1122, 2006.

[69] a. culotta and j. sorensen,    dependency tree kernels for relation extrac-
tion,    in proceedings of the 42nd meeting of the association for computational
linguistics (acl   04), main volume, pp. 423   429, barcelona, spain, july
2004.

[70] c. cumby and d. roth,    feature extraction languages for propositionalzed
relational learning,    in working notes of the ijcai-2003 workshop on learn-
ing statistical models from relational data (srl-2003), (l. getoor and
d. jensen, eds.), pp. 24   31, acapulco, mexico, august 11, 2003.

[71] h. cunningham,    information extraction, automatic,    encyclopedia of lan-

guage and linguistics, 2005. second ed.

[72] h. cunningham, d. maynard, k. bontcheva, and v. tablan,    gate: a frame-
work and graphical development environment for robust nlp tools and appli-
cations,    in proceedings of the 40th anniversary meeting of the association
for computational linguistics, 2002.

368 references

[73] h. cunningham, d. maynard, k. bontcheva, and v. tablan,    gate: a
framework and graphical development environment for robust nlp tools and
applications,    in proceedings of the 40th anniversary meeting of the associa-
tion for computational linguistics (acl   02), philadelphia, 2002.

[74] e. cutrell and s. t. dumais,    exploring personal information,    communica-

tions on acm, vol. 49, pp. 50   51, 2006.

[75] n. n. dalvi and d. suciu,    e   cient query evaluation on probabilistic

databases,    in vldb, pp. 864   875, 2004.

[76] s. dasgupta,    coarse sample complexity bounds for active learning,    in nips,

2005.

[77] h. daum  e iii,    frustratingly easy id20,    in conference of the
association for computational linguistics (acl), prague, czech republic,
2007.

[78] p. derose, w. shen, f. c. 0002, y. lee, d. burdick, a. doan, and r. ramakr-
ishnan,    dblife: a community information management platform for the
database research community (demo),    in cidr, pp. 169   172, 2007.

[79] t. dietterich,    machine learning for sequential data: a review,    in structural,
syntactic and statistical pattern recognition; lecture notes in computer sci-
ence, (t. caelli, ed.), vol. 2396, pp. 15   30, springer-verlag, 2002.

[80] p. domingos,    metacost: a general method for making classi   ers cost-
sensitive,    in proceedings of the fifth international conference on knowledge
discovery and data mining (kdd-99), 1999.

[81] d. downey, m. broadhead, and o. etzioni,    locating complex named entities

in web text,    in ijcai, pp. 2733   2739, 2007.

[82] d. downey, o. etzioni, and s. soderland,    a probabilistic model of redun-

dancy in information extraction,    in ijcai, 2005.

[83] d. downey, s. schoenmackers, and o. etzioni,    sparse information extraction:

unsupervised language models to the rescue,    in acl, 2007.

[84] d. w. embley, m. hurst, d. p. lopresti, and g. nagy,    table-processing

paradigms: a research survey,    ijdar, vol. 8, nos. 2   3, pp. 66   86, 2006.

[85] d. w. embley, y. s. jiang, and y.-k. ng,    record-boundary discovery in
web documents,    in sigmod 1999, proceedings acm sigmod international
conference on management of data, june 1   3, 1999, pp. 467   478, philade-
phia, pennsylvania, usa, 1999.

[86] o. etzioni, m. cafarella, d. downey, s. kok, a.-m. popescu, t. shaked,
s. soderland, d. s. weld, and a. yates,    web-scale information extraction in
knowitall: (preliminary results),    in www, pp. 100   110, 2004.

[87] o. etzioni, b. doorenbos, and d. weld,    a scalable comparison shopping
agent for the world-wide web,    in proceedings of the international conference
on autonomous agents, 1997.

[88] r. fagin, a. lotem, and m. naor,    optimal aggregation algorithms for mid-
dleware,    journal of computer and system sciences, vol. 66, nos. 614, 656,
september 2001.

[89] r. feldman, b. rosenfeld, and m. fresko,    teg-a hybrid approach to infor-
mation extraction,    knowledge and information systems, vol. 9, pp. 1   18,
2006.

references

369

[90] i. p. fellegi and a. b. sunter,    a theory for record linkage,    journal of the

american statistical society, vol. 64, pp. 1183   1210, 1969.

[91] d. ferrucci and a. lally,    uima: an architectural approach to unstructured
information processing in the corporate research environment,    natural lan-
guage engineering, vol. 10, nos. 3   4, pp. 327   348, 2004.

[92] j. r. finkel, t. grenager, and c. manning,    incorporating non-local informa-
tion into information extraction systems by id150,    in proceedings
of the 43nd annual meeting of the association for computational linguistics
(acl 2005), 2005.

[93] j. r. finkel, t. grenager, and c. d. manning,    incorporating non-local infor-
mation into information extraction systems by id150,    in acl, 2005.
[94] g. w. flake, e. j. glover, s. lawrence, and c. l. giles,    extracting query

modi   cations from nonlinear id166s,    in www, pp. 317   324, 2002.

[95] y. freund, h. s. seung, e. shamir, and n. tishby,    selective sampling using
the query by committee algorithm,    machine learning, vol. 28, nos. 2   3,
pp. 133   168, 1997.

[96] w. gatterbauer, p. bohunsky, m. herzog, b. kr  upl, and b. pollak,    towards
domain-independent information extraction from web tables,    in www    07:
proceedings of the 16th international conference on world wide web, pp. 71   
80, acm, 2007.

[97] r. ghani, k. probst, y. liu, m. krema, and a. fano,    id111 for product
attribute extraction,    sigkdd explorations newsletter, vol. 8, pp. 41   48,
2006.

[98] r. grishman,    information extraction: techniques and challenges,    in scie,

1997.

[99] r. grishman, s. huttunen, and r. yangarber,    information extraction for
enhanced access to disease outbreak reports,    journal of biomedical infor-
matics, vol. 35, pp. 236   246, 2002.

[100] r. grishman and b. sundheim,    message understanding conference-6: a brief
history,    in proceedings of the 16th conference on computational linguistics,
pp. 466   471, usa, morristown, nj: association for computational linguis-
tics, 1996.

[101] r. gupta, a. a. diwan, and s. sarawagi,    e   cient id136 with cardinality-
based clique potentials,    in proceedings of the 24th international conference
on machine learning (icml), usa, 2007.

[102] r. gupta and s. sarawagi,    curating probabilistic databases from information
extraction models,    in proceedings of the 32nd international conference on
very large databases (vldb), 2006.

[103] j. hammer, h. garcia-molina, j. cho, r. aranha, and a. crespo,    extract-
ing semistructure information from the web,    in workshop on mangement of
semistructured data, 1997.

[104] b. he, m. patel, z. zhang, and k. c.-c. chang,    accessing the deep web,   

communications on acm, vol. 50, pp. 94   101, 2007.

[105] m. a. hearst,    automatic acquisition of hyponyms from large text corpora,   
in proceedings of the 14th conference on computational linguistics, pp. 539   
545, 1992.

370 references

[106] c.-n. hsu and m.-t. dung,    generating    nite-state transducers for semistruc-
tured data extraction from the web,    information systems special issue on
semistructured data, vol. 23, 1998.

[107] j. huang, t. chen, a. doan, and j. naughton, on the provenance of non-

answers to queries over extracted data.

[108] j. huang, a. smola, a. gretton, k. borgwardt, and b. sch  olkopf,    correcting
sample selection bias by unlabeled data,    in advances in neural information
processing systems 20, cambridge, ma: mit press, 2007.

[109] m. hurst,    the interpretation of tables in texts,    phd thesis, university of
edinburgh, school of cognitive science, informatics, university of edinburgh,
2000.

[110] p. g. ipeirotis, e. agichtein, p. jain, and l. gravano,    towards a query
optimizer for text-centric tasks,    acm transactions on database systems,
vol. 32, 2007.

[111] n. ireson, f. ciravegna, m. e. cali   , d. freitag, n. kushmerick, and
a. lavelli,    evaluating machine learning for information extraction,    in
icml, pp. 345   352, 2005.

[112] m. jansche and s. p. abney,    information extraction from voicemail tran-
scripts,    in emnlp    02: proceedings of the acl-02 conference on empirical
methods in natural language processing, pp. 320   327, usa, morristown, nj:
association for computational linguistics, 2002.

[113] t. s. jayram, r. krishnamurthy, s. raghavan, s. vaithyanathan, and h. zhu,
   avatar information extraction system,    ieee data engineering bulletin,
vol. 29, pp. 40   48, 2006.

[114] j. jiang and c. zhai,    a systematic exploration of the feature space for rela-
tion extraction,    in human language technologies 2007: the conference of
the north american chapter of the association for computational linguistics;
proceedings of the main conference, pp. 113   120, 2007.

[115] n. kambhatla,    combining lexical, syntactic and semantic features with max-
imum id178 models for information extraction,    in the companion volume
to the proceedings of 42st annual meeting of the association for computa-
tional linguistics, pp. 178   181, barcelona, spain: association for computa-
tional linguistics, july 2004.

[116] s. khaitan, g. ramakrishnan, s. joshi, and a. chalamalla,    rad: a scalable

framework for annotator development,    in icde, pp. 1624   1627, 2008.

[117] m.-s. kim, k.-y. whang, j.-g. lee, and m.-j. lee,    id165/2l: a space
and time e   cient two-level id165 inverted index structure,    in vldb    05:
proceedings of the 31st international conference on very large data bases,
pp. 325   336, 2005.

[118] d. klein and c. d. manning,    conditional structure versus conditional estima-
tion in nlp models,    in workshop on empirical methods in natural language
processing (emnlp), 2002.

[119] d. koller and n. friedman,    structured probabilistic models,    under prepa-

ration, 2007.

[120] v. krishnan and c. d. manning,    an e   ective two-stage model for exploiting
non-local dependencies in id39,    in acl-coling, 2006.

references

371

[121] n. kushmerick,    wrapper induction for information extraction,    phd thesis,

university of washington, 1997.

[122] n. kushmerick,

   regression testing

for wrapper maintenance,   

in

aaai/iaai, pp. 74   79, 1999.

[123] n. kushmerick, d. weld, and r. doorenbos,    wrapper induction for informa-

tion extraction,    in proceedings of ijcai, 1997.

[124] s. r. labeling 2008. http://www.lsi.upc.es/ srlconll/refs.html.
[125] j. la   erty, a. mccallum, and f. pereira,    conditional random    elds: proba-
bilistic models for segmenting and labeling sequence data,    in proceedings of
the international conference on machine learning (icml-2001), williams,
ma, 2001.

[126] s. lawrence, c. l. giles, and k. bollacker,    digital libraries and autonomous

citation indexing,    ieee computer, vol. 32, pp. 67   71, 1999.

[127] w. lehnert, j. mccarthy, s. soderland, e. rilo   , c. cardie, j. peterson,
f. feng, c. dolan, and s. goldman,    umass/hughes: description of the cir-
cus system used for tipster text,    in proceedings of a workshop on held at
fredericksburg, virginia, pp. 241   256, usa, morristown, nj: association for
computational linguistics, 1993.

[128] k. lerman, s. minton, and c. a. knoblock,    wrapper maintenance:
a machine learning approach,    journal of arti   cial intellgence research
(jair), vol. 18, pp. 149   181, 2003.

[129] x. li and j. bilmes,    a bayesian divergence prior for classi   er adaptation,   
eleventh international conference on arti   cial intelligence and statistics
(aistats-2007), 2007.

[130] y. li and k. bontcheva,    hierarchical, id88-like learning for ontology-
based information extraction,    in www    07: proceedings of the 16th inter-
national conference on world wide web, pp. 777   786, acm, 2007.

[131] b. liu, m. hu, and j. cheng,    opinion observer: analyzing and comparing
opinions on the web,    in www    05: proceedings of the 14th international
conference on world wide web, pp. 342   351, 2005.

[132] d. c. liu and j. nocedal,    on the limited memory bfgs method for large-scale

optimization,    mathematic programming, vol. 45, pp. 503   528, 1989.

[133] l. liu, c. pu, and w. han,    xwrap: an xml-enabled wrapper construction
system for web information sources,    in international conference on data
engineering (icde), pp. 611   621, 2000.

[134] y. liu, k. bai, p. mitra, and c. l. giles,    tableseer: automatic table meta-
data extraction and searching in digital libraries,    in jcdl    07: proceedings
of the 2007 conference on digital libraries, pp. 91   100, usa, new york, ny:
acm, 2007.

[135] r. malouf,    markov models for language-independent named entity recogni-
tion,    in proceedings of the sixth conference on natural language learning
(conll-2002), 2002.

[136] r. malouf,    a comparison of algorithms for maximum id178 parameter esti-
mation,    in proceedings of the sixth conference on natural language learning
(conll-2002), pp. 49   55, 2002.

[137] c. d. manning and h. sch  utze, foundations of statistical natural language

processing. cambridge, ma: the mit press, 1999.

372 references

[138] i. mansuri and s. sarawagi,    a system for integrating unstructured data into
id208,    in proceedings of the 22nd ieee international confer-
ence on data engineering (icde), 2006.

[139] s. mao, a. rosenfeld, and t. kanungo,    document structure analysis algo-
rithms: a literature survey,    document recognition and retrieval x, vol. 5010,
pp. 197   207, 2003.

[140] b. marthi, b. milch, and s. russell,    first-order probabilistic models
for information extraction,    in working notes of the ijcai-2003 work-
shop on learning statistical models from relational data (srl-2003),
(l. getoor and d. jensen, eds.), pp. 71   78, acapulco, mexico, august 11
2003.

[141] d. maynard, v. tablan, c. ursu, h. cunningham, and y. wilks,    named
entity recognition from diverse text types,    recent advances in natural lan-
guage processing 2001 conference, tzigov chark, bulgaria, 2001.

[142] a. mccallum,    information extraction: distilling structured data from

unstructured text,    acm queue, vol. 3, pp. 48   57, 2005.

[143] a. mccallum, d. freitag, and f. pereira,    maximum id178 markov models
for information extraction and segmentation,    in proceedings of the interna-
tional conference on machine learning (icml-2000), pp. 591   598, palo alto,
ca, 2000.

[144] a. mccallum, k. nigam, j. reed, j. rennie, and k. seymore, cora: computer

science research paper search engine, http://cora.whizbang.com/, 2000.

[145] a. mccallum and b. wellner,    toward conditional models of identity uncer-
tainty with application to proper noun coreference,    in proceedings of the
ijcai-2003 workshop on information integration on the web, pp. 79   86,
acapulco, mexico, august 2003.

[146] a. k. mccallum, mallet: a machine learning for language toolkit.

http://mallet.cs.umass.edu, 2002.

[147] d. mcdonald, h. chen, h. su, and b. marshall,    extracting gene pathway
relations using a hybrid grammar: the arizona relation parser,    bioinformat-
ics, vol. 20, pp. 3370   3378, 2004.

[148] r. mcdonald, k. crammer, and f. pereira,    flexible text segmentation with

structured multilabel classi   cation,    in hlt/emnlp, 2005.

[149] g. mecca, p. merialdo, and p. atzeni,    araneus in the era of xml,    in
ieee data engineering bullettin, special issue on xml, ieee, september
1999.

[150] m. michelson and c. a. knoblock,    semantic annotation of unstructured and
ungrammatical text,    in proceedings of the 19th international joint confer-
ence on arti   cial intelligence (ijcai), pp. 1091   1098, 2005.

[151] m. michelson and c. a. knoblock,    creating relational data from unstruc-
tured and ungrammatical data sources,    journal of arti   cial intelligence
research (jair), vol. 31, pp. 543   590, 2008.

[152] e. minkov, r. c. wang, and w. w. cohen,    extracting personal names from
email: applying id39 to informal text,    in hlt/emnlp,
2005.

[153] r. j. mooney and r. c. bunescu,    mining knowledge from text using infor-

mation extraction,    sigkdd explorations, vol. 7, pp. 3   10, 2005.

references

373

[154] i. muslea,    extraction patterns for information extraction tasks: a survey,   
in the aaai-99 workshop on machine learning for information extraction,
1999.

[155] i. muslea, s. minton, and c. knoblock,    selective sampling with redundant
views,    in proceedings of the fifteenth national conference on arti   cial intel-
ligence, aaai-2000, pp. 621   626, 2000.

[156] i. muslea, s. minton, and c. a. knoblock,    a hierarchical approach to
wrapper induction,    in proceedings of the third international conference on
autonomous agents, seattle, wa, 1999.

[157] i. muslea, s. minton, and c. a. knoblock,    hierarchical wrapper induction
for semistructured information sources,    autonomous agents and multi-agent
systems, vol. 4, nos. 1/2, pp. 93   114, 2001.

[158] a. niculescu-mizil and r. caruana,    predicting good probabilities with super-

vised learning,    in icml, 2005.

[159] nist. automatic content extraction (ace) program. 1998   present.
[160] b. pang and l. lee,    opinion mining and id31,    foundations

and trends in information retrieval, vol. 2, nos. 1   2, pp. 1   135, 2008.

[161] parag and p. domingos,    multi-relational record linkage,    in proceedings of
3rd workshop on multi-relational data mining at acm sigkdd, seattle,
wa, august 2004.

[162] h. pasula, b. marthi, b. milch, s. russell, and i. shpitser,    identity uncer-
tainty and citation matching,    in advances in neural processing systems 15,
vancouver, british columbia: mit press, 2002.

[163] f. peng and a. mccallum,    accurate information extraction from research
papers using conditional random    elds,    in hlt-naacl, pp. 329   336, 2004.
[164] d. pinto, a. mccallum, x. wei, and w. b. croft,    table extraction using con-
ditional random    elds,    in sigir    03: proceedings of the 26th annual interna-
tional acm sigir conference on research and development in informaion
retrieval, pp. 235   242, usa, new york, ny: acm, 2003.

[165] a. pivk, p. cimiano, y. sure, m. gams, v. rajkovi  c, and r. studer,    trans-
forming arbitrary tables into logical form with tartar,    data knowledge engi-
neering, vol. 60, pp. 567   595, 2007.

[166] c. plake, t. schiemann, m. pankalla, j. hakenberg, and u. leser,    alibaba:

pubmed as a graph,    bioinformatics, vol. 22, pp. 2444   2445, 2006.

[167] a.-m. popescu and o. etzioni,    extracting product features and opinions
from reviews,    in hlt    05: proceedings of the conference on human language
technology and empirical methods in natural language processing, pp. 339   
346, 2005.

[168] f. popowich,    using id111 and natural language processing for health
care claims processing,    sigkdd explorartion newsletter, vol. 7, pp. 59   66,
2005.

[169] k. probst and r. ghani,    towards    interactive    active learning in multi-view

feature sets for information extraction,    in ecml, pp. 683   690, 2007.

[170] j. r. quinlan,    learning logical de   nitions from examples,    machine learn-

ing, vol. 5, 1990.

[171] l. rabiner,    a tutorial on id48 and selected applications

in id103,    in proceedings of the ieee, vol. 77, 1989.

374 references

[172] g. ramakrishnan, s. balakrishnan, and s. joshi,    entity annotation based

on inverse index operations,    in emnlp, 2006.

[173] g. ramakrishnan, s. joshi, s. balakrishnan, and a. srinivasan,    using ilp to
construct features for information extraction from semi-structured text,    in
ilp, 2007.

[174] l. ramaswamy, a. iyengar, l. liu, and f. douglis,    automatic fragment
detection in dynamic web pages and its impact on caching,    ieee transac-
tions on knowledge and data engineering, vol. 17, pp. 859   874, 2005.

[175] l. ramaswamy, a. iyengar, l. liu, and f. douglis,    automatic detection
of fragments in dynamically generated web pages,    in www, pp. 443   454,
2004.

[176] j. raposo, a. pan, m.   alvarez, and n.   angel vira,    automatic wrapper main-
tenance for semi-structured web sources using results from previous queries,   
in sac    05: proceedings of the 2005 acm symposium on applied computing,
pp. 654   659, acm, 2005.

[177] a. ratnaparkhi,    learning to parse natural language with maximum id178

models,    machine learning, vol. 34, 1999.

[178] l. reeve and h. han,    survey of semantic annotation platforms,    in sac    05:
proceedings of the 2005 acm symposium on applied computing, pp. 1634   
1638, usa, new york, ny: acm, 2005.

[179] f. reiss, s. raghavan, r. krishnamurthy, h. zhu, and s. vaithyanathan,    an

algebraic approach to rule-based information extraction,    in icde, 2008.

[180] p. resnik and a. elkiss,    the linguist   s search engine: an overview (demon-

stration),    in acl, 2005.

[181] e. rilo   ,    automatically constructing a dictionary for information extraction

tasks,    in aaai, pp. 811   816, 1993.

[182] b. rosenfeld and r. feldman,    using corpus statistics on entities to improve
semi-supervised id36 from the web,    in proceedings of the 45th
annual meeting of the association of computational linguistics, pp. 600   607,
june 2007.

[183] r. ross, v. s. subrahmanian, and j. grant,    aggregate operators in proba-

bilistic databases,    journal of acm, vol. 52, pp. 54   101, 2005.

[184] a. sahuguet and f. azavant,    building light-weight wrappers for legacy web
data-sources using w4f,    in international conference on very large databases
(vldb), 1999.

[185] s. sarawagi, the crf project: a java implementation.

http://crf.

sourceforge.net, 2004.

[186] s. sarawagi,    e   cient id136 on sequence segmentation models,    in pro-
ceedings of the 23rd international conference on machine learning (icml),
pittsburgh, pa, usa, 2006.

[187] s. sarawagi and a. bhamidipaty,    interactive deduplication using active learn-
ing,    in proceedings of the eighth acm sigkdd international conference on
knowledge discovery and data mining(kdd-2002), edmonton, canada, july
2002.

[188] s. satpal and s. sarawagi,    id20 of id155

models via feature subsetting,    in ecml/pkdd, 2007.

references

375

[189] k. seymore, a. mccallum, and r. rosenfeld,    learning hidden markov
model structure for information extraction,    in papers from the aaai-
99 workshop on machine learning for information extraction, pp. 37   42,
1999.

[190] w. shen, a. doan, j. f. naughton, and r. ramakrishnan,    declarative infor-
mation extraction using datalog with embedded extraction predicates,    in
vldb, pp. 1033   1044, 2007.

[191] m. shilman, p. liang, and p. viola,    learning non-generative grammatical

models for document analysis,    iccv, vol. 2, pp. 962   969, 2005.

[192] y. shinyama and s. sekine,    preemptive information extraction using unre-

stricted relation discovery,    in hlt-naacl, 2006.

[193] j. f. silva, z. kozareva, v. noncheva, and g. p. lopes,    extracting named
entities. a statistical approach,    in proceedings of the xime confrence sur
le traitement des langues naturelles     taln, 19   22 avril, fez, marroco,
(b. bel and i. merlien, eds.), pp. 347   351, atala     association pour le
traitement automatique des langues, 04, 2004.

[194] p. singla and p. domingos,    entity resolution with markov logic,    in icdm,

pp. 572   582, 2006.

[195] s. soderland,    learning information extraction rules for semi-structured and

free text,    machine learning, vol. 34, 1999.

[196] f. m. suchanek, g. ifrim, and g. weikum,    combining linguistic and sta-
tistical analysis to extract relations from web documents,    in kdd    06: pro-
ceedings of the 12th acm sigkdd international conference on knowledge
discovery and data mining, pp. 712   717, 2006.

[197] f. m. suchanek, g. kasneci, and g. weikum,    yago: a core of semantic
knowledge,    in www    07: proceedings of the 16th international conference
on world wide web, pp. 697   706, 2007.

[198] b. m. sundheim,    overview of the third message understanding evaluation
and conference,    in proceedings of the third message understanding confer-
ence (muc-3), pp. 3   16, san diego, ca, 1991.

[199] c. sutton and a. mccallum,    collective segmentation and labeling of distant
entities in information extraction,    technical report tr # 04-49, univer-
sity of massachusetts presented at icml workshop on statistical relational
learning and its connections to other fields, july 2004.

[200] k. takeuchi and n. collier,    use of support vector machines in extended
id39,    in the 6th conference on natural language learn-
ing (conll), 2002.

[201] b. taskar,    learning id170 models: a large margin approach,   

phd thesis, stanford university, 2004.

[202] b. taskar, d. klein, m. collins, d. koller, and c. manning,    max-margin

parsing,    in emnlp, july 2004.

[203] b. taskar, s. lacoste-julien, and m. i. jordan,    id170,
dual extragradient and bregman projections,    journal on machine learning
research, vol. 7, pp. 1627   1653, 2006.

[204] m. theobald, g. weikum, and r. schenkel,    top-k query evaluation with

probabilistic guarantees,    in vldb, pp. 648   659, 2004.

376 references

[205] c. a. thompson, m. e. cali   , and r. j. mooney,    active learning for nat-
ural language parsing and information extraction,    in proceedings of 16th
international conference on machine learning, pp. 406   414, morgan kauf-
mann, san francisco, ca, 1999.

[206] e. f. tjong kim sang and f. d. meulder,    introduction to the conll-2003
shared task: language-independent id39,    in seventh
conference on natural language learning (conll-03), (w. daelemans and
m. osborne, eds.), pp. 142   147, edmonton, alberta, canada: association for
computational linguistics, may 31   june 1, 2003. (in association with hlt-
naacl, 2003).

[207] a. troussov, b. o   donovan, s. koskenniemi, and n. glushnev,    per-node
optimization of    nite-state mechanisms for natural language processing,    in
cicling, pp. 221   224, 2003.

[208] i. tsochantaridis, t. joachims, t. hofmann, and y. altun,    large mar-
gin methods for structured and interdependent output variables,    journal of
machine learning research (jmlr), vol. 6, pp. 1453   1484, september 2005.
[209] j. turmo, a. ageno, and n. catal`a,    adaptive information extraction,    acm

computer services, vol. 38, p. 4, 2006.

[210] p. d. turney,    cost-sensitive classi   cation: empirical evaluation of a hybrid
genetic decision tree induction algorithm,    journal of arti   cial intelligence
research, pp. 369   409, 1995.

[211] p. d. turney,    expressing implicit semantic relations without supervision,   

in acl, 2006.

[212] v. s. uren, p. cimiano, j. iria, s. handschuh, m. vargas-vera, e. motta,
and f. ciravegna,    semantic annotation for knowledge management: require-
ments and a survey of the state of the art,    journal of web semantics, vol. 4,
pp. 14   28, 2006.

[213] p. viola and m. narasimhan,    learning to extract information from semi-
structured text using a discriminative id18,    in sigir    05:
proceedings of the 28th annual international acm sigir conference on
research and development in information retrieval, pp. 330   337, usa, new
york, ny: acm, 2005.

[214] s. v. n. vishwanathan, n. n. schraudolph, m. w. schmidt, and k. p. murphy,
   accelerated training of conditional random    elds with stochastic gradient
methods,    in icml, pp. 969   976, 2006.

[215] m. wang,    a re-examination of dependency path kernels for relation extrac-

tion,    in proceedings of ijcnlp, 2008.

[216] y. wang and j. hu,    a machine learning based approach for table detection
on the web,    in www    02: proceedings of the 11th international conference
on world wide web, pp. 242   250, acm, 2002.

[217] b. wellner, a. mccallum, f. peng, and m. hay,    an integrated, conditional
model of information extraction and coreference with application to cita-
tion matching,    in conference on uncertainty in arti   cial intelligence (uai),
2004.

[218] m. wick, a. culotta, and a. mccallum,    learning    eld compatibilities
to extract database records from unstructured text,    in proceedings of the

references

377

2006 conference on empirical methods in natural language processing,
pp. 603   611, sydney, australia: association for computational lingistics, july
2006.

[219] i. h. witten, a. mo   at, and t. c. bell, managing gigabytes: compressing
and indexing documents and images. morgan kaufmann publishing, san
francisco, 1999.

[220] f. wu and d. s. weld,    autonomously semantifying wikipedia,    in cikm,

pp. 41   50, 2007.

[221] b. zadrozny and c. elkan,    learning and making decisions when costs and
probabilities are both unknown,    in proceedings of the seventh international
conference on knowledge discovery and data mining (kdd), 2001.

[222] r. zanibbi, d. blostein, and r. cordy,    a survey of table recognition: mod-
els, observations, transformations, and id136s,    international journal on
document analysis and recognition, vol. 7, pp. 1   16, 2004.

[223] d. zelenko, c. aone, and a. richardella,    kernel methods for relation extrac-

tion,    journal of machine learning research, vol. 3, pp. 1083   1106, 2003.

[224] m. zhang, j. zhang, j. su, and g. zhou,    a composite kernel to extract rela-
tions between entities with both    at and structured features,    in proceedings
of the 21st international conference on computational linguistics and 44th
annual meeting of the association for computational linguistics, pp. 825   
832, sydney, australia: association for computational linguistics, july 2006.
[225] s. zhao and r. grishman,    extracting relations with integrated information
using kernel methods,    in acl    05: proceedings of the 43rd annual meeting
on association for computational linguistics, pp. 419   426, 2005.

[226] g. zhu, t. j. bethea, and v. krishna,    extracting relevant named entities

for automated expense reimbursement,    in kdd, pp. 1004   1012, 2007.

