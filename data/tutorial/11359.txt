open-vocabulary id29

with both distributional statistics and formal knowledge

matt gardner and jayant krishnamurthy

allen institute for arti   cial intelligence

seattle, washington, usa

6
1
0
2

 

v
o
n
8
2

 

 
 
]
l
c
.
s
c
[
 
 

2
v
2
4
5
3
0

.

7
0
6
1
:
v
i
x
r
a

{mattg,jayantk}@allenai.org

abstract

traditional semantic parsers map language onto composi-
tional, executable queries in a    xed schema. this map-
ping allows them to effectively leverage the information con-
tained in large, formal knowledge bases (kbs, e.g., freebase)
to answer questions, but it is also fundamentally limiting   
these semantic parsers can only assign meaning to language
that falls within the kb   s manually-produced schema. re-
cently proposed methods for open vocabulary semantic pars-
ing overcome this limitation by learning execution models
for arbitrary language, essentially using a text corpus as a
kind of knowledge base. however, all prior approaches to
open vocabulary id29 replace a formal kb with
textual information, making no use of the kb in their mod-
els. we show how to combine the disparate representations
used by these two approaches, presenting for the    rst time a
semantic parser that (1) produces compositional, executable
representations of language, (2) can successfully leverage the
information contained in both a formal kb and a large cor-
pus, and (3) is not limited to the schema of the underly-
ing kb. we demonstrate signi   cantly improved performance
over state-of-the-art baselines on an open-domain natural lan-
guage id53 task.

1 introduction

base

knowledge

the task of mapping a phrase
id29 is
in natural
language onto a formal query in some
   xed schema, which can then be executed against
(kb)
a
(zelle and mooney 1996;
zettlemoyer and collins 2005).
example,
the united
the phrase
states?   
the
query
  (x)./government/president of(x, usa), which, when
executed against freebase (bollacker et al. 2008), returns
barack obama. by mapping phrases to executable state-
ments, semantic parsers can leverage large, curated sources
of knowledge to answer questions (berant et al. 2013).

for
the president of
onto

be mapped

   who is

might

this bene   t comes with an inherent limitation, however   
semantic parsers can only produce executable statements
within their manually-produced schema. there is no query
against freebase that can answer questions like    who are the
democratic front-runners in the us election?   , as freebase

copyright c(cid:13) 2017, association for the advancement of arti   cial
intelligence (www.aaai.org). all rights reserved.

in these methods,

to overcome this limitation,

does not encode information about front-runners. semantic
parsers trained for freebase fail on these kinds of questions.
recent work has pro-
posed methods for open vocabulary id29,
which replace a formal kb with a probabilistic database
learned from a text corpus.
lan-
guage is mapped onto queries with predicates derived
directly from the text
itself (lewis and steedman 2013;
krishnamurthy and mitchell 2015). for instance, the ques-
tion above might be mapped to   (x).president of(x, usa).
this query is not executable against any kb, however, and
so open vocabulary semantic parsers must learn execution
models for the predicates found in the text. they do this with
a distributional approach similar to id27 meth-
ods, giving them broad coverage, but lacking access to the
large, curated kbs available to traditional semantic parsers.
prior work in id29, then, has either had direct
access to the information in a knowledge base, or broad cov-
erage over all of natural language using the information in a
large corpus, but not both.

in this work, we show how to combine these two
approaches by incorporating kb information into open
vocabulary id29 models. our key insight
is that formal kb queries can be converted into fea-
tures that can be added to the learned execution mod-
els of open vocabulary semantic parsers. this conver-
sion allows open vocabulary models to use the kb fact
/government/president of(barackobama, usa) when
scoring president of(barackobama, usa), without requir-
ing the model to map the language onto a single formal state-
ment. crucially, this featurization also allows the model to
use these kb facts even when they only provide partial in-
formation about the language being modeled. for example,
knowing that an entity is a politician is very helpful in-
formation for deciding whether that entity is a front-runner.
our approach, outlined in figure 1, effectively learns the
meaning of a word as a distributional vector plus a weighted
combination of freebase queries, a considerably more ex-
pressive representation than those used by prior work.

while this combination is the main contribution of our
work, we also present some small improvements that allow
open vocabulary id29 models to make better use
of kb information when it is available: improving the logi-
cal forms generated by the semantic parser, and employing a

   

   
   

   

   

input text
italian architect

candidate entities
palladio
obama
        

   
   

      

      

category models:

predicate parameters for architect:
  :
  :

[.2, -.6, . . . ]
type:architect     .52
type:designer     .32
nationality:italy     .20
        

entity parameters for palladio:
  :
  :

[.15, -.8, . . . ]
type:architect     1
nationality:italy     1
        

logical form
  x.architect(x)     architect n/n(italy, x)

id203 that entity is in denotation
p(architect(palladio))    p(architect n/n(italy, palladio)) = 0.79
p(architect(obama))    p(architect n/n(italy, obama)) = 0.01
        

   
   

relation models:

predicate parameters for architect n/n:
  :
  :

[-.9, .1, . . . ]
/person/nationality-1     .29
/structure/architect     .11
/person/ethnicity-1     .05
        

entity pair parameters for (italy, palladio):

  :
  :

[-.8, .2, . . . ]
/person/nationality-1     1
/structure/architect     0
        

p(architect(palladio)) =   (  t    +   t   )

p(architect n/n(italy, palladio)) =   (  t    +   t   )

   

   
   

figure 1: overview of the components of our model. given an input text, we use a id35 parser and an entity linker to produce
a logical form with predicates derived from the text (shown in italics). for each predicate, we learn a distributional vector   , as
well as weights    associated with a set of selected freebase queries. for each entity and entity pair, we learn a distributional
vector   , and we extract a binary feature vector    from freebase, indicating whether each entity or entity pair is in the set
returned by the selected freebase queries. these models are combined to assign probabilities to candidate entities.

simple technique from related work for generating candidate
entities from the kb.

we demonstrate our approach on the task of answering
open-domain    ll-in-the-blank natural language questions.
by giving open vocabulary semantic parsers direct access
to kb information, we improve mean average precision on
this task by over 120%.

2 open vocabulary id29

in this section, we brie   y describe the current state-of-the-
art model for open vocabulary id29, introduced
by krishnamurthy and mitchell (2015). instead of mapping
text to freebase queries, as done by a traditional semantic
parser, their method parses text to a surface logical form
with predicates derived directly from the words in the text
(see figure 1). next, a distribution over denotations for each
predicate is learned using a id105 approach
similar to that of riedel et al. (2013). this distribution is
concisely represented using a probabilistic database, which
also enables ef   cient probabilistic execution of logical form
queries.

the id105 has two sets of parameters: each
category or relation has a learned k-dimensional embedding
  , and each entity or entity pair has a learned k-dimensional
embedding   . the id203 assigned to a category in-
stance c(e) or relation instance r(e1, e2) is given by:

p(c(e)) =   (  t
p(r(e1, e2)) =   (  t

c   e)
r   (e1 ,e2))

the id203 of a predicate instance is the sigmoided
inner product of the corresponding predicate and entity em-

beddings. predicates with nearby embeddings will have sim-
ilar distributions over the entities in their denotation. the pa-
rameters    and    are learned using a query ranking objective
that optimizes them to rank entities observed in the denota-
tion of a logical form above unobserved entities. given the
trained predicate and entity parameters, the system is capa-
ble of ef   ciently computing the marginal id203 that an
entity is an element of a logical form   s denotation using ap-
proximate id136 algorithms for probabilistic databases.
the model presented in this section is purely distribu-
tional, with predicate and entity models that draw only on
co-occurrence information found in a corpus. in the follow-
ing sections, we show how to augment this model with in-
formation contained in large, curated kbs such as freebase.

3 converting freebase queries to features

our key insight is that the executable queries used by tra-
ditional semantic parsers can be converted into features that
provide kb information to the execution models of open vo-
cabulary semantic parsers. here we show how this is done.
traditional semantic parsers map words onto distributions
over executable queries, select one to execute, and return
sets of entities or entity pairs from a kb as a result. instead
of executing a single query, we can simply execute all possi-
ble queries and use an entity   s (or entity pair   s) membership
in each set as a feature in our predicate models.

there are two problems with this approach: (1) the set of
all possible queries is intractably large, so we need a mech-
anism similar to a semantic parser   s lexicon to select a small
set of queries for each word; and (2) executing hundreds or
thousands of queries at runtime for each predicate and entity

palladio

nationality

t
y
p
e

d

e

s

i

g

n

e

d

in

l o c a t e d

italy

t
y
p
e

architect

country

villa capra

features between palladio and italy:
hnationalityi
hdesigned   located ini
features for palladio:
hnationalityi
hnationalityi:italy
htypei:architect
hdesigned   located ini
hdesigned   located ini:italy

figure 2: a subset of the freebase graph, and some example
extracted features. the actual freebase relations and entity
identi   ers used are modi   ed here to aid readability.

is not computationally tractable. to solve these problems,
we use a graph-based technique called subgraph feature ex-
traction (sfe) (gardner and mitchell 2015).

3.1 subgraph feature extraction
sfe is a technique for generating feature matrices over node
pairs in graphs with labeled edges. when the graph cor-
responds to a formal kb such as freebase, the features
generated by sfe are isomorphic to statements in the kb
schema (gardner 2015). this means that we can use sfe
to generate a feature vector for each entity (or entity pair)
which succinctly captures the set of all statements1 in whose
denotations the entity (or entity pair) appears. using this
feature vector as part of the semantic parser   s entity models
solves problem (2) above, and performing feature selection
for each predicate solves problem (1).

some example features extracted by sfe are shown in
figure 2. for entity pairs, these features include the se-
quence of edges (or paths) connecting the nodes correspond-
ing to the entity pair. for entities, these features include
the set of paths connected to the node, optionally includ-
ing the node at the end of the path. note the correspon-
dence between these features and freebase queries:
the
path hdesigned   located ini can be executed as a query
against freebase, returning a set of (architect, location) en-
tity pairs, where the architect designed a structure in the lo-
cation. (palladio, italy) is one such entity pair, so this
pair has a feature value of 1 for this query.

3.2 feature selection
the feature vectors produced by sfe contain tens of mil-
lions of possible formal statements. out of these tens of

1in a restricted class, which contains horn clauses and a few

other things; see gardner (2015) for more details.

millions of formal statements, only a handful represent rele-
vant freebase queries for any particular predicate. we there-
fore select a small number of statements to consider for each
learned predicate in the open vocabulary semantic parser.

we select features by    rst summing the entity and en-
tity pair feature vectors seen with each predicate in the
training data. for example, the phrase    italian architect
andrea palladio    is considered a positive training exam-
ple for the predicate instances architect(palladio) and
architect n/n(italy, palladio). we add the feature vec-
tors for palladio and (italy, palladio) to the feature
counts for the predicates architect and architect n/n, re-
spectively. this gives a set of counts count(  ), count(f ),
and count(       f ), for each predicate    and feature f . the
features are then ranked by pmi for each predicate by com-
puting
count(  )count(f ) . after removing low-frequency fea-
tures, we pick the k = 100 features with the highest pmi
values for each predicate to use in our model.

count(     f )

4 combined predicate models

here we present our approach to incorporating kb infor-
mation into open vocabulary semantic parsers. having de-
scribed how we use sfe to generate features corresponding
to statements in a formal schema, adding these features to
the models described in section 2 is straightforward.

we saw in section 2 that open vocabulary semantic
parsers learn distributional vectors for each category, rela-
tion, entity and entity pair. we augment these vectors with
the feature vectors described in section 3. each category
and relation receives a weight    for each selected freebase
query, and each entity and entity pair has an associated fea-
ture vector   . the truth id203 of a category instance
c(e) or relation instance r(e1, e2) is thus given by:

p(c(e)) =   (  t
p(r(e1, e2)) =   (  t

c   c(e))

c   e +   t
r   (e1,e2) +   t

r   r(e1, e2))

in these equations,    and    are learned predicate and en-
tity embeddings, as described in section 2. the second term
in the sum represents our new features and their learned
weights.   c(e) and   r(e1, e2) are sfe feature vectors for
each entity and entity pair; a different set of features is cho-
sen for each predicate c and r, as described in section 3.2.
  c and   r are learned weights for these features.

in our model, there are now three sets of parameters to
be learned:
(1)   , low-dimensional distributional vectors
trained for each predicate; (2)   , low-dimensional distribu-
tional vectors trained for each entity and entity pair; and (3)
  , weights associated with the selected formal sfe features
for each predicate. all of these parameters are optimized
jointly, using the same method described in section 2.

note here that each sfe feature corresponds to a query
over the formal schema, de   ning a set of entities (or entity
pairs). the associated feature weight measures the likeli-
hood that an entity in this set is also in the denotation of the
surface predicate. our models include many such features
for each surface predicate, effectively mapping each surface
predicate onto a weighted combination of freebase queries.

5 making full use of kb information

in addition to improving predicate models, as just described,
adding kb information to open vocabulary semantic parsers
suggests two other simple improvements: (1) using more
speci   c logical forms, and (2) generating candidate entities
from the kb.

5.1 logical form generation

krishnamurthy and mitchell (2015) generate logical forms
from natural language statements by computing a syntac-
tic id35 parse, then applying a collection of rules to pro-
duce logical forms. however, their logical form analy-
ses do not model noun-mediated relations well. for ex-
ample, given the phrase    italian architect andrea palla-
dio,    their system   s logical form would include the relation
n/n(italy, palladio). here, the n/n predicate represents
a generic noun modi   er relation; however, this relation is
too vague for the predicate model to accurately learn its de-
notation. a similar problem occurs with prepositions and
possessives, e.g., it is similarly hard to learn the denotation
of the predicate of.

our system improves the analysis of noun-mediated re-
lations by simply including the noun in the predicate
name.
in the architect example above, our system pro-
duces the relation architect n/n.
it does this by con-
catenating all intervening noun modi   ers between two en-
tity mentions and including them in the predicate name;
for example,    illinois attorney general lisa madigan    pro-
duces the predicate attorney general n/n. we similarly
improve the analyses of prepositions and possessives to
include the head noun. for example,    barack obama,
president of the u.s.    produces the predicate instance
president of(barack obama, u.s.), and    rome, italy   s
capital    produces the predicate    s capital. this process gen-
erates more speci   c predicates that more closely align with
the kb facts that we make available to the predicate models.

5.2 candidate entity generation

a key bene   t of our predicate models is that they are able to
assign scores to entity pairs that were never seen in the train-
ing data. distributional models have no learned vectors for
these entity pairs and therefore assume p(r(e1, e2)) = 0 for
unseen entity pairs (e1, e2). this limits the recall of these
models when applied to id53, as entity pairs
will not have been observed for many correct, but rare en-
tity answers. in contrast, because our models have access to
a large kb, the formal component of the model can always
give a score to any entity pair in the kb. this allows our
model to considerably improve id53 perfor-
mance on rare entities.

it would be computationally intractable to consider all
freebase entities as answers to queries, and so we use a sim-
ple candidate entity generation technique to consider only a
small set of likely entities for a given query. we    rst    nd all
entities in the query, and consider as candidates any entity
that has either been seen at training time with a query entity

or is directly connected to a query entity in freebase.2 this
candidate entity generation is common practice for recent
id53 models over freebase (yih et al. 2015),
though, for the reasons stated above, it has not been used
previously in open vocabulary id29 models.

6 evaluation

we evaluate our open-vocabulary semantic parser on a    ll-
in-the-blank natural language query task. each test example
is a natural language phrase containing at least two free-
base entities, one of which is held out. the system must
propose a ranked list of freebase entities to    ll in the blank
left by the held out entity, and the predicted entities are then
judged manually for correctness. we compare our proposed
models, which combine distributional and formal elements,
with a purely distributional baseline from prior work. all of
the data and code used in these experiments is available at
http://github.com/allenai/open vocab semparse.

6.1 data
much recent work on id29 has been evaluated
using the webquestions dataset (berant et al. 2013). this
dataset is not suitable for evaluating our model because it
was    ltered to only questions that are mappable to free-
base queries.
in contrast, our focus is on language that
is not directly mappable to freebase. we thus use the
dataset introduced by krishnamurthy and mitchell (2015),
which consists of the clueweb09 web corpus3 along
with google   s facc entity linking of that corpus to
freebase (gabrilovich, ringgaard, and subramanya 2013).
for training data, 3 million webpages from this corpus
were processed with a id35 parser to produce logical
forms (krishnamurthy and mitchell 2014). this produced
2.1m predicate instances involving 142k entity pairs and
184k entities. after removing infrequently-seen predicates
(seen fewer than 6 times), there were 25k categories and 4.2k
relations.

we also used the test set created by krishnamurthy and
mitchell, which contains 220 queries generated in the same
fashion as the training data from a separate section of
clueweb. however, as they did not release a development
set with their data, we used this set as a development set.
for a    nal evaluation, we generated another, similar test set
from a different held out section of clueweb, in the same
fashion as done by krishnamurthy and mitchell. this    nal
test set contains 307 queries.

6.2 models
we compare three models in our experiments: (1) the dis-
tributional model of krishnamurthy and mitchell, described
in section 2, which is the current state-of-the-art method for
open vocabulary id29; (2) a formal model (new
to this work), where the distributional parameters    and    in
section 4 are    xed at zero; and (3) the combined model de-
scribed in section 4 (also new to this work). in each of these

2or connected by a mediator node, which is how freebase rep-

resents relations with more than two arguments.
3http://www.lemuproject.org/clueweb09.php

model

k&m   s lfs our lfs delta

model

map w-map mrr

distributional (k&m 2015)
formal
combined

.269
.231
.313

.284
.276
.335

+.015
+.045
+.022

distributional (k&m 2015)
with freebase candidates

relative improvement

.163
.229

40%

.163
.275

69%

.288
.312

8%

table 1: improvement in mean average precision when us-
ing our logical forms on the development set.

table 2: improvement to the distributional model when us-
ing our candidate entity generation.

models, we used vectors of size 300 for all embeddings. ex-
cept where noted, all experiments use our modi   ed logical
forms (section 5.1) and our entity proposal mechanism (sec-
tion 5.2). we do not compare against any traditional seman-
tic parsers, as more than half of the questions in our dataset
are not answerable by freebase queries, and so are out of
scope for those parsers (krishnamurthy and mitchell 2015).

6.3 methodology
given a    ll-in-the-blank query such as    italian architect
   , each system produces a ranked list of 100 candidate
entities. to compare the output of the systems, we fol-
low a pooled evaluation protocol commonly used in rela-
tion extraction and information retrieval (west et al. 2014;
riedel et al. 2013). we take the top 30 predictions from
each system and manually annotate whether they are cor-
rect, and use those annotations to compute the average pre-
cision (ap) and reciprocal rank (rr) of each system on the
query. average precision is de   ned as 1
k=1 prec(k)   
correct(k), where prec(k) is the precision at rank k,
correct(k) is an indicator function for whether the kth an-
swer is correct, and m is number of returned answers (up to
100 in this evaluation). ap is equivalent to calculating the
area under a precision-recall curve. reciprocal rank is com-
puted by    rst    nding the rank r of the    rst correct prediction
made by a system. reciprocal rank is then 1
r , ranging from
1 (if the    rst prediction is correct) to 0 (if there is no cor-
rect answer returned). in the tables below we report mean
average precision (map) and mean reciprocal rank (mrr),
averaged over all of the queries in the test set. we also re-
port a weighted version of map, where the ap of each query
is scaled by the number of annotated correct answers to the
query (shown as w-map in the tables for space considera-
tions).

m pm

6.4 results
we    rst show the effect of the new logical forms introduced
in section 5.1. as can be seen in table 1, with our improved
logical forms, all models are better able to capture the se-
mantics of language. this improvement is most pronounced
in the formal models, which have more capacity to get spe-
ci   c features from freebase with the new logical forms. as
our logical forms give all models better performance, the re-
maining experiments we present all use these logical forms.
we next show the improvement gained by using the sim-
ple candidate entity generation outlined in section 5.2. by
simply appending the list of connected entities in freebase to
the end of the rankings returned by the distributional model,
map improves by 40% (see table 2). the connectedness of

model

map w-map mrr

distributional (k&m 2015)
formal
combined

relative improvement

.284
.276
.335

18%

.371
.469
.477

29%

.379
.334
.429

13%

table 3: development set results for our    ll-in-the-blank
task. the combined model signi   cantly improves map over
prior work.

an entity pair in freebase is very informative, especially for
rare entities that are not seen together during training.

table 3 shows a comparison between the id29
models on the development set. as can be seen, the com-
bined model signi   cantly improves performance over prior
work, giving a relative gain in weighted map of 29%.

table 4 shows that these improvements are consistent on
the    nal test set, as well. the performance improvement
seen by the combined model is actually larger on this set,
with gains on our metrics ranging from 50% to 87%.

on both of these datasets, the difference in map between
the combined model and the distributional model is statis-
tically signi   cant (by a paired permutation test, p < 0.05).
the differences between the combined model and the formal
model, and between the formal model and the distributional
model, are not statistically signi   cant, as each method has
certain kinds of queries that it performs well on. only the
combined model is able to consistently outperform the dis-
tributional model on all kinds of queries.

model

map w-map mrr

distributional (k&m 2015)
formal
combined

relative improvement

.229
.355
.370

62%

.275
.495
.513

87%

.312
.419
.469

50%

table 4: final test results set for our    ll-in-the-blank task.
the combined model improves over prior work by 50   87%
on our metrics. these improvements over the baseline are
after the baseline has been improved by the methods devel-
oped in this paper, shown in table 1 and table 2. the cu-
mulative effect of the methods presented in this work is an
improvement of over 120% in map.

6.5 discussion
our model tends to outperform the distributional model on
queries containing predicates with exact or partial corre-
lates in freebase. for example, our model obtains nearly
perfect average precision on the queries    french newspa-
per
,    both of which
can be exactly expressed in freebase. the top features
for newspaper(x) all indicate that x has type newspaper in
freebase, and the top features for newspaper n/n(x, y) indi-
cate that y is a newspaper, and that x is either the circulation
area of y or the language of y.

    and    israeli prime minister

   ,    the united states,

the model also performs well on queries with par-
tial freebase correlates, such as    microsoft head honcho
   s closest ally   , and    patriots
linebacker
,    although with somewhat lower average pre-
cision. the high weight features in these cases tend to pro-
vide useful hints, even though there is no direct correlate;
for example, the model learns that    honchos    are people,
and that they tend to be ceos and    lm producers.

there are also some areas where our model can be im-
proved. first, in some cases, the edge sequence features
used by the model are not expressive enough to identify the
correct relation in freebase. an example of this problem
is the    linebacker    example above, where the features for
linebacker n/n can capture which athletes play for which
teams, but not the positions of those athletes. second, our
model can under-perform on predicates with no close map-
ping to freebase. an example where this problem occurs is
the query    
is a nasa mission.    third, there remains
room to further improve the logical forms produced by
the semantic parser, speci   cally for multi-word expressions.
one problem occurs with multi-word noun modi   ers, e.g.,
   vice president al gore    is mapped to vice(al gore)    
president(al gore). another problem is that there is no
back-off with multi-word relations. for example, the pred-
icate head honcho n/n was never seen in the training data,
so it is replaced with unknown; however, it would be better
to replace it with honcho n/n, which was seen in the train-
ing data. finally, although using connected entities in free-
base as additional candidates during id136 is helpful, it
often over- or under-generates candidates. a more tailored,
per-query search process could improve performance.

7 related work

a

is

to

on

kb

answer

literature

extensive
parsers

an
semantic

build-
there
questions
ing
(zettlemoyer and collins 2005;
against
berant et al. 2013;
krishnamurthy and mitchell 2012;
li et al. 2015). some of this work has used surface (or
ungrounded) logical forms as an intermediate represen-
tation,
to our work (kwiatkowski et al. 2013;
reddy, lapata, and steedman 2014;
yih et al. 2015;
reddy et al. 2016). the main difference between our work
and these techniques is that they map surface logical forms
to a single executable freebase query, while we learn
execution models for the surface logical forms directly,
using a weighted combination of freebase queries as part of
the model. none of these prior works can assign meaning

similar

to language that is not directly representable in the kb
schema.

choi, kwiatkowski and zettlemoyer (2015) presented
an information extraction system that performs a semantic
parse of open-domain text, recognizing when a predicate
cannot be mapped to freebase. however, while they recog-
nize when a predicate is not mappable to freebase, they do
not attempt to learn execution models for those predicates,
nor can they answer questions using those predicates.

yao and van durme (2014) and dong et al. (2015) pro-
posed id53 models that use similar features
to those used in this work. however, they did not produce
semantic parses of language, instead using methods that are
non-compositional and do not permit complex queries.

in

and

relations

finally, learning probabilistic databases in an open vocab-
ulary semantic parser has a strong connection with kb com-
in addition to sfe (gardner and mitchell 2015),
pletion.
our work draws on work on embedding the
en-
a kb (riedel et al. 2013;
tities
nickel, tresp, and kriegel 2011;
bordes et al. 2013;
nickel, jiang, and tresp 2014;
toutanova et al. 2015),
as well as work on graph-based methods for reasoning
with kbs
(lao and cohen 2010; gardner et al. 2014;
neelakantan, roth, and mccallum 2015;
bornea and barker 2015). our combination of embed-
ding methods with graph-based methods in this paper is
suggestive of how one could combine the two in methods
for kb completion. initial work exploring this direction has
already been done by toutanova and chen (2015).

8 conclusion

prior work in id29 has either leveraged large
knowledge bases to answer questions, or used distributional
techniques to gain broad coverage over all of natural lan-
guage. in this paper, we have shown how to gain both of
these bene   ts by converting the queries generated by tradi-
tional semantic parsers into features which are then used in
open vocabulary id29 models. we presented a
technique to do this conversion in a way that is scalable us-
ing graph-based feature extraction methods. our combined
model achieved relative gains of over 50% in mean average
precision and mean reciprocal rank versus a purely distribu-
tional approach. we also introduced a better mapping from
surface text to logical forms, and a simple method for using
a kb to    nd candidate entities during id136. taken to-
gether, the methods introduced in this paper improved mean
average precision on our task from .163 to .370, a 127% rel-
ative improvement over prior work.

this work suggests a new direction for semantic pars-
ing research. existing semantic parsers map language to a
single kb query, an approach that successfully leverages a
kb   s predicate instances, but is fundamentally limited by
its schema. in contrast, our approach maps language to a
weighted combination of queries plus a distributional com-
ponent; this approach is capable of representing a much
broader class of concepts while still using the kb when
it is helpful. furthermore, it is capable of using the kb
even when the meaning of the language cannot be exactly

represented by a kb predicate, which is a common occur-
rence. we believe that this kind of approach could signif-
icantly expand the applicability of id29 tech-
niques to more complex domains where the assumptions of
traditional techniques are too limiting. we are actively ex-
ploring applying these techniques to science question an-
swering (clark, harrison, and balasubramanian 2013), for
example, where existing kbs provide only partial coverage
of the questions.

references

[berant et al. 2013] berant, j.; chou, a.; frostig, r.; and liang, p.
2013. id29 on freebase from question-answer pairs.
in emnlp, 1533   1544.

[bollacker et al. 2008] bollacker, k.; evans, c.; paritosh, p.;
sturge, t.; and taylor, j. 2008. freebase: a collaboratively created
graph database for structuring human knowledge. in proceedings
of sigmod.

[bordes et al. 2013] bordes, a.; usunier, n.; garcia-duran, a.;
weston, j.; and yakhnenko, o. 2013. translating embeddings for
modeling multi-relational data. in advances in neural information
processing systems, 2787   2795.

[bornea and barker 2015] bornea, m., and barker, k. 2015. re-
lational path mining in structured knowledge.
in proceedings of
the 8th international conference on knowledge capture, k-cap
2015, 14:1   14:7. new york, ny, usa: acm.

[choi, kwiatkowski, and zettlemoyer 2015] choi,

e.;
kwiatkowski, t.; and zettlemoyer, l. 2015. scalable semantic
parsing with partial ontologies. in proceedings of acl.

[clark, harrison, and balasubramanian 2013] clark, p.; harrison,
p.; and balasubramanian, n. 2013. a study of the knowledge
base requirements for passing an elementary science test. in pro-
ceedings of the 2013 workshop on automated knowledge base con-
struction, 37   42. acm.

[dong et al. 2015] dong, l.; wei, f.; zhou, m.; and xu, k. 2015.
id53 over freebase with multi-column convolu-
tional neural networks. in acl.

[gabrilovich, ringgaard, and subramanya 2013] gabrilovich, e.;
ringgaard, m.; and subramanya, a. 2013. facc1: freebase an-
notation of clueweb corpora, version 1 (release date 2013-06-26,
format version 1, correction level 0). note: http://lemurproject.
org/clueweb09/facc1/cited by 5.

[gardner and mitchell 2015] gardner, m., and mitchell, t. 2015.
ef   cient and expressive knowledge base completion using sub-
graph feature extraction. in proceedings of emnlp. association
for computational linguistics.

[gardner et al. 2014] gardner, m.; talukdar, p.; krishnamurthy, j.;
and mitchell, t. 2014.
incorporating vector space similarity in
random walk id136 over knowledge bases. in proceedings of
emnlp. association for computational linguistics.

[gardner 2015] gardner, m. 2015. reading and reasoning with
id13s. ph.d. dissertation, carnegie mellon univer-
sity.

[krishnamurthy and mitchell 2012] krishnamurthy,

and
mitchell, t. m. 2012. weakly supervised training of semantic
parsers. in proceedings of the 2012 joint conference on empirical
methods in natural language processing and computational nat-
ural language learning, 754   765. association for computational
linguistics.

j.,

[krishnamurthy and mitchell 2014] krishnamurthy,

and
mitchell, t. m. 2014. joint syntactic and id29 with
id35.
in proceedings of the 52nd
annual meeting of the association for computational linguistics
(acl).

j.,

[krishnamurthy and mitchell 2015] krishnamurthy,

and
mitchell, t. m. 2015. learning a id152 for
freebase with an open predicate vocabulary. transactions of the
association for computational linguistics 3:257   270.

j.,

[kwiatkowski et al. 2013] kwiatkowski, t.; choi, e.; artzi, y.; and
zettlemoyer, l. 2013. scaling semantic parsers with on-the-   y on-
tology matching. in proceedings of the 2013 conference on em-
pirical methods in natural language processing. citeseer.

[lao and cohen 2010] lao, n., and cohen, w. w. 2010. fast query
execution for retrieval models based on path-constrained random
walks.
in proceedings of the 16th acm sigkdd international
conference on knowledge discovery and data mining, 881   888.
acm.

[lewis and steedman 2013] lewis, m., and steedman, m. 2013.
combined distributional and logical semantics. tacl 1:179   192.
[li et al. 2015] li, j.; zhu, m.; lu, w.; and zhou, g. 2015. im-
proving id29 with enriched synchronous context-free
grammar. in emnlp.

[neelakantan, roth, and mccallum 2015] neelakantan, a.; roth,
b.; and mccallum, a. 2015. compositional vector space mod-
els for knowledge base completion. in acl 2015. association for
computational linguistics.

[nickel, jiang, and tresp 2014] nickel, m.; jiang, x.; and tresp,
v. 2014. reducing the rank in relational factorization models by
including observable patterns. in advances in neural information
processing systems, 1179   1187.

[nickel, tresp, and kriegel 2011] nickel, m.; tresp, v.;

and
kriegel, h.-p. 2011. a three-way model for collective learning
on multi-relational data. in proceedings of the 28th international
conference on machine learning (icml-11), 809   816.

[reddy et al. 2016] reddy, s.; t  ackstr  om, o.; collins, m.;
kwiatkowski, t.; das, d.; steedman, m.; and lapata, m. 2016.
transforming dependency structures to logical forms for semantic
parsing. tacl 4:127   140.

[reddy, lapata, and steedman 2014] reddy, s.; lapata, m.; and
large-scale id29 without

steedman, m.
question-answer pairs. tacl 2:377   392.

2014.

[riedel et al. 2013] riedel, s.; yao, l.; mccallum, a.; and marlin,
b. m. 2013. id36 with id105 and
universal schemas. in proceedings of naacl-hlt.

[toutanova and chen 2015] toutanova, k., and chen, d. 2015. ob-
served versus latent features for knowledge base and text id136.
in acl workshop on on continuous vector space models and their
compositionality.

[toutanova et al. 2015] toutanova, k.; chen, d.; pantel, p.; poon,
h.; choudhury, p.; and gamon, m. 2015. representing text for
joint embedding of text and knowledge bases. in emnlp.

[west et al. 2014] west, r.; gabrilovich, e.; murphy, k.; sun, s.;
gupta, r.; and lin, d. 2014. knowledge base completion via
search-based id53. in www.

[yao and durme 2014] yao, x., and durme, b. v. 2014.

infor-
mation extraction over structured data: id53 with
freebase. in acl.

[yih et al. 2015] yih, w.; chang, m.-w.; he, x.; and gao, j. 2015.
id29 via staged query graph generation: question an-
swering with knowledge base. in acl.

[zelle and mooney 1996] zelle, j. m., and mooney, r. j. 1996.
learning to parse database queries using inductive logic program-
ming. in aaai.

[zettlemoyer and collins 2005] zettlemoyer, l. s., and collins, m.
2005. learning to map sentences to logical form: structured clas-
si   cation with probabilistic categorial grammars. in uai.

