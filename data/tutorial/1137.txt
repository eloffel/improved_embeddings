syntax-based id151

philip williams and philipp koehn

29 october 2014

- introduction
- rule extraction

part i
part ii
part iii - decoding
part iv - extensions

syntax-based id151

1

what do we mean by syntax-based smt?

       syntax-based    is a very inclusive term. it refers to a large family of approaches:
    hiero, syntax-directed mt, syntax-augmented mt, syntacti   ed phrase-
based mt, tree-to-string, string-to-dependency, dependency treelet-based,
soft syntax, fuzzy tree-to-tree, tree-based, . . .

    we mean that the translation model uses a tree-based representation of

language.

    we don   t count syntax-based preordering or syntactic lms.

    we will focus on four widely-used approaches:

1. hierarchical phrase-based
2. tree-to-string

3. string-to-tree
4. tree-to-tree

syntax-based id151

why use syntax?

    many translation problems can be best explained by pointing to syntax

    reordering, e.g., verb movement in german   english translation
    long distance agreement (e.g., subject-verb) in output

    encourage grammatically coherent output
    important step towards more linguistically motivated models (semantics)
    state-of-the art for some language pairs

    chinese-english (nist 2008)
    english-german (wmt 2012)
    german-english (wmt 2013)

syntax-based id151

2

3

id151

given a source string, s,    nd the target string, t   , with the highest
id203 according to a distribution p(t|s):

t    = arg maxt p(t|s)

1. model a id203 distribution p(t|s)
2. learn the parameters for the model

3. find or approximate the highest id203 string t   

syntax-based id151

id151

1. model a id203 distribution p(t|s)

    how is syntax used in modelling?
2. learn the parameters for the model

    what are the parameters of a syntax-based model?
3. find or approximate the highest id203 string t   

    how do we decode with a syntax-based model?

syntax-based id151

4

5

modelling p(t|s)

    most smt models use och and ney   s (2002) log-linear formulation:

p(t|s) =

exp   pm
pt0 exp   pm

m=1  mhm(t, s)   
m=1  mhm(t0, s)   

h1, . . . , hm are real-valued functions and  1, . . . ,  m are real-valued constants

    denominator can be ignored during search:

t    = arg max

t

p(t|s)

= arg max

t

mxm=1

 mhm(t, s)

syntax-based id151

6

modelling p(t|s)

t    = arg max

t

mxm=1

 mhm(t, s)

(1)

    in word-based models, s and t are modelled as sequences of words.
    in phrase-based models, s and t are modelled as sequences of phrases.
    so what about syntax-based models?

syntax-based id151

7

hierarchical phrase-based mt

like phrase pairs. . .

f  r

britische skandale

ist

dieser

nicht besonders

schl  pfrig

.

as

british political scandals

go , this one

is

not particularly

juicy

.

but with nesting:

f  r britische skandale

ist dieser

nicht besonders

schl  pfrig 

.

as                                               go

british political scandals

 , this one is not particularly

juicy

.

syntax-based id151

hierarchical phrase-based mt

hierarchical phrase pairs:

ist dieser nicht besonders

schl  pfrig 

 , this one is not particularly

juicy

are modelled using synchronous context-free grammar (sid18):

x ! ist dieser x1 | , this one is x1
x ! nicht besonders x1 | not particularly x1
x ! schl  upfrig | juicy

syntax-based id151

8

9

hierarchical phrase-based mt

deshalb             die

sei

werbung

                          und
unzutreffend

irref  hrend

therefore the advertisement

was

                        and
unfounded

misleading

rules can include up to two non-terminals:

x ! deshalb x1 die x2 | therefore the x2 x1
x ! x1 und x2 | x1 and x2

glue rules concatenate hierarchical phrases:

s ! x1 | x1
s ! s1 x2 | s1 x2

syntax-based id151

10

hierarchical phrase-based mt

    synchronous context-free grammar:

    rewrite rules of the form ha, bi ! h   ,  ,   i
    a and b are source and target non-terminals, respectively
        and   are strings of terminals and non-terminals for the source and target

sides, respectively.

        is a one-to-one correspondence between source and target non-terminals.

    hiero grammars are a special case of sid18:
    one non-terminal type, x, on source side
    two non-terminal types, x and s, on target side
    various restrictions on rule form (see chiang (2007))

syntax-based id151

11

sid18 derivation

s1 | s1

    derivation starts with pair of linked s symbols.

syntax-based id151

12

sid18 derivation

s1 | s1

) s2 x3 | s2 x3

    s ! s1 x2 | s1 x2

(glue rule)

syntax-based id151

13

sid18 derivation

s1 | s1

) s2 x3 | s2 x3
) s2 x4 und x5 | s2 x4 and x5

    x ! x1 und x2 | x1 and x2

syntax-based id151

14

sid18 derivation

s1 | s1

) s2 x3 | s2 x3
) s2 x4 und x5 | s2 x4 and x5
) s2 unzutre   end und x5 | s2 unfounded and x5

    x ! unzutre   end | unfounded

syntax-based id151

15

sid18 derivation

s1 | s1

) s2 x3 | s2 x3
) s2 x4 und x5 | s2 x4 and x5
) s2 unzutre   end und x5 | s2 unfounded and x5
) s2 unzutre   end und irref  uhrend | s2 unfounded and misleading

    x ! irref  uhrend | misleading

syntax-based id151

16

sid18 derivation

s1 | s1

) s2 x3 | s2 x3
) s2 x4 und x5 | s2 x4 and x5
) s2 unzutre   end und x5 | s2 unfounded and x5
) s2 unzutre   end und irref  uhrend | s2 unfounded and misleading
) x6 unzutre   end und irref  uhrend | x6 unfounded and misleading

    s ! x1 | x1

(glue rule)

syntax-based id151

17

sid18 derivation

s1 | s1

) s2 x3 | s2 x3
) s2 x4 und x5 | s2 x4 and x5
) s2 unzutre   end und x5 | s2 unfounded and x5
) s2 unzutre   end und irref  uhrend | s2 unfounded and misleading
) x6 unzutre   end und irref  uhrend | x6 unfounded and misleading
) deshalb x7 die x8 unzutre   end und irref  uhrend

| therefore the x8 x7 unfounded and misleading

    x ! deshalb x1 die x2 | therefore the x2 x1

(non-terminal reordering)

syntax-based id151

18

sid18 derivation

s1 | s1

) s2 x3 | s2 x3
) s2 x4 und x5 | s2 x4 and x5
) s2 unzutre   end und x5 | s2 unfounded and x5
) s2 unzutre   end und irref  uhrend | s2 unfounded and misleading
) x6 unzutre   end und irref  uhrend | x6 unfounded and misleading
) deshalb x7 die x8 unzutre   end und irref  uhrend

| therefore the x8 x7 unfounded and misleading

) deshalb sei die x8 unzutre   end und irref  uhrend

| therefore the x8 was unfounded and misleading

    x ! sei | was

syntax-based id151

19

sid18 derivation

s1 | s1

) s2 x3 | s2 x3
) s2 x4 und x5 | s2 x4 and x5
) s2 unzutre   end und x5 | s2 unfounded and x5
) s2 unzutre   end und irref  uhrend | s2 unfounded and misleading
) x6 unzutre   end und irref  uhrend | x6 unfounded and misleading
) deshalb x7 die x8 unzutre   end und irref  uhrend

| therefore the x8 x7 unfounded and misleading

) deshalb sei die x8 unzutre   end und irref  uhrend

| therefore the x8 was unfounded and misleading

) deshalb sei die werbung unzutre   end und irref  uhrend

| therefore the advertisement was unfounded and misleading

    x ! werbung | advertisement

syntax-based id151

20

hierarchical phrase-based mt

    we can now de   ne the search in terms of sid18 derivations

t    = arg max

 mhm(t, s)

= arg max

 mhm(t, s, d)

t

mxm=1
mxm=1
t xd

d 2 d, the set of synchronous derivations with source s and yield t.

    in practice, approximated with search for single-best derivation:

d    = arg max

d

mxm=1

 mhm(t, s, d)

syntax-based id151

(1)

(2)

(3)

21

hierarchical phrase-based mt

    search for single-best derivation:

    rule-local feature functions allow decomposition of derivation scores:

 mhm(t, s, d)

d

d    = arg max

mxm=1
hm(d) =xri
d 0@ 1 log plm(d) +xri

hm(ri)

mxm=2

 mhm(ri)1a

    but id165 language model can   t be decomposed this way. . .

d    = arg max

syntax-based id151

(3)

(4)

22

hierarchical phrase-based mt

    summary so far:

    generalizes concept of phrase pair to allow nested phrases
    formalized using sid18
    no use of linguistic annotation: syntactic in a purely formal sense
    model uses standard smt log-linear formulation
    search over derivations

    later:

    rule extraction and scoring
    decoding (search for best derivation)
    k-best extraction

syntax-based id151

23

tree-to-string

hierarchical phrase pairs but with embedded tree fragments on the source side:

s-top

pp-mo

vafin

np-sb

ap-pd

appr

adja

nn

f  r

britische

skandale

ist

pds

dieser

avp-ng

adjd

ptkneg

adv

schl  pfrig

nicht

besonders

                                                               ,  this  one  is
as british political                       go

scandals

not particularly

juicy

each source subphrase is a complete subtree.

syntax-based id151

24

tree-to-string

formalized using synchronous tree-substitution grammar (stsg):

pp-mo

appr

adja

nn

f  r

britische

skandale

as british political                       go

scandals

pp-mp
adja
britische

appr
f  r

nn

skandale

nn1

as british x1 go

scandals

syntax-based id151

25

tree-to-string

    synchronous tree substitution grammar (stsg):

    grammar rules have the form h   ,  ,   i
        is a tree with source terminal and non-terminal leaves
      is a string1 of target terminals and non-terminals
        is a one-to-one correspondence between source and target non-terminals.

    unlike hiero:

    linguistic-annotation (on source-side)
    no limit to number of substitution sites (non-terminals)
    no reordering limit during decoding

1technically, a 1-level tree formed by adding x as the root and the symbols from   as children.

syntax-based id151

26

tree-to-string

    derivation involves synchronous rewrites (like sid18)
    tree fragments required to match input parse tree.

    motivation: tree provides context for rule selection (   syntax-directed   )

    e cient decoding algorithms available: source tree constrains rule options
    search for single-best derivation:

d    = arg max

d 0@ 1 log plm(d) +xri

mxm=2

 mhm(ri)1a

where source-side of d must match input tree

syntax-based id151

27

string-to-tree

hierarchical phrase pairs but with embedded tree fragments on the target side:

                                                 ist  dieser
f  r britische skandale

nicht besonders

schl  pfrig

s

,

,

np

dt
this

nn
one

vbz
is

vp

rb
not

adjp

rb

particularly

jj
juicy

in

sbar

np

jj

jj

s

nns

as

british

political

scandals

vp

vbp
go

each target subphrase is a complete subtree.

syntax-based id151

28

string-to-tree

formalized using stsg:

f  r britische skandale

sbar

np

jj

jj

s

nns

in

as

british

political

scandals

vp

vbp
go

sbar

in
as

s

np1

f  r x1

vp
vbp
go

britische skandale

jj

np
jj

nns

british

political

scandals

or sid18:

sbar ! f  ur x1 | as np1 go

np ! britische skandale | british political scandals

syntax-based id151

29

string-to-tree

    derivation is a rewriting process, like hierachical phrase-based and tree-to-string

    rewrites only allowed if target labels match at substitution sites

    internal tree structure not used in derivation (hence frequent use of sid18)

    motivation: constraints provided by target syntax lead to more    uent output

    later:

    rule extraction and scoring
    decoding (hiero will be special case of s2t)
    k-best extraction (likewise)

syntax-based id151

30

tree-to-tree

hierarchical phrase pairs but with embedded tree fragments on both sides:

pp-mo

appr

adja

nn

f  r

britische

skandale

in

sbar

np

jj

jj

s

nns

as

british

political

scandals

vp

vbp

go

formalized using stsg

syntax-based id151

31

tree-to-tree

di   erences in source and target syntactic structure increasingly important

pp-mo

appr

adja

nn

f  r

britische

skandale

in

sbar

np

jj

jj

s

nns

as

british

political

scandals

vp

vbp

go

can be di   erences in treebank annotation style or simply di   erences in language
choice

syntax-based id151

32

summary so far

    we have introduced four models:

model formalism
hiero
t2s
s2t
t2t

source syntax target syntax
sid18
n
stsg
y
stsg or sid18 n
stsg
y

n
n
y
y

input
string
tree
string
tree

    next:

    rule extraction

syntax-based id151

33

- introduction
- rule extraction

part i
part ii
part iii - decoding
part iv - extensions

syntax-based id151

34

learning synchronous grammars

    extracting rules from a word-aligned parallel corpus

    first: hierarchical phrase-based model

    only one non-terminal symbol x
    no linguistic syntax, just a formally syntactic model

    then: synchronous phrase structure model

    non-terminals for words and phrases: np, vp, pp, adj, ...
    corpus must also be parsed with syntactic parser

syntax-based id151

35

extracting phrase translation rules

n
e
d
n
e
h
c
e
r
p
s
t
n
e

n
e
g
n
u
k
r
e
m
n
a

i

n
e
g
d
n
  
h
s
u
a

e
d
r
e
w

n
e
n
h

i

h
c
i

e
d

i

shall be = werde

i

shall

be

passing

on

to

you

some

comments

syntax-based id151

36

extracting phrase translation rules

n
e
d
n
e
h
c
e
r
p
s
t

n
e

n
e
g
n
u
k
r
e
m
n
a

i

n
e
g
d
n
  
h
s
u
a

e
d
r
e
w

n
e
n
h

i

h
c
i

e
d

i

i

shall

be

passing

on

to

you

some

comments

some comments = 
die entsprechenden anmerkungen

syntax-based id151

37

extracting phrase translation rules

n
e
d
n
e
h
c
e
r
p
s
t
n
e

n
e
g
n
u
k
r
e
m
n
a

i

n
e
g
d
n
  
h
s
u
a

e
d
r
e
w

n
e
n
h

i

h
c
i

e
d

i

i

shall

be

passing

on

to

you

some

comments

werde ihnen die entsprechenden 
anmerkungen aush  ndigen
   =   shall be passing on to you 
         some comments

syntax-based id151

38

extracting hierarchical phrase translation rules

n
e
d
n
e
h
c
e
r
p
s
t

n
e

n
e
g
n
u
k
r
e
m
n
a

i

n
e
g
d
n
  
h
s
u
a

e
d
r
e
w

n
e
n
h

i

e
d

i

h
c
i

subtracting
subphrase

werde x aush  ndigen
= shall be passing on x

i

shall

be

passing

on

to

you

some

comments

syntax-based id151

39

formal de   nition

    recall: consistent phrase pairs

(  e,   f ) consistent with a ,

8ei 2   e : (ei, fj) 2 a ! fj 2   f
and 8fj 2   f : (ei, fj) 2 a ! ei 2   e
and 9ei 2   e, fj 2   f : (ei, fj) 2 a

    let p be the set of all extracted phrase pairs (  e,   f )

syntax-based id151

40

formal de   nition

    extend recursively:

if (  e,   f ) 2 p and (  esub,   fsub) 2 p
and   e =   epre +   esub +   epost
and   f =   fpre +   fsub +   fpost
and   e 6=   esub and   f 6=   fsub

add (epre + x + epost, fpre + x + fpost) to p

(note: any of epre, epost, fpre, or fpost may be empty)

    set of hierarchical phrase pairs is the closure under this extension mechanism

syntax-based id151

41

comments

    removal of multiple sub-phrases leads to rules with multiple non-terminals,

such as:

y ! x1 x2 | x2 of x1

    typical restrictions to limit complexity [chiang, 2005]

    at most 2 nonterminal symbols
    at least 1 but at most 5 words per language
    span at most 15 words (counting gaps)

syntax-based id151

42

learning syntactic translation rules

s

vp

vp

i

n
f
a
v
 
 
 
e
d
r
e
w

r
e
p
p
 
 
 
n
e
n
h
i

r
e
p
p
 
 
 
h
c
i

t
r
a
 
 
 
e
d

i

np

j
d
a
 
 
 
.
r
p
s
t
n
e

n
n
 
 
 
.

m
n
a

i

n
f
v
v
 
 
 
.
d
n
  
h
s
u
a

s

vp

vp

vp

prp   i

md   shall

vb   be

vbg    passing

rp   on

to   to

prp   you

dt   some

pp

nns   comments

np

pro

ihnen

= pp

to

prp

to

you

syntax-based id151

43

constraints on syntactic rules

    same word alignment constraints as id187
    hierarchical: rule can cover any span

, syntactic rules must cover constituents in the tree

    hierarchical: gaps may cover any span

, gaps must cover constituents in the tree

    much fewer rules are extracted (all things being equal)

syntax-based id151

44

impossible rules

s

vp

vp

i

n
f
a
v
 
 
 
e
d
r
e
w

r
e
p
p
 
 
 
n
e
n
h
i

r
e
p
p
 
 
 
h
c
i

t
r
a
 
 
 
e
d

i

np

j
d
a
 
 
 
.
r
p
s
t
n
e

n
n
 
 
 
.

m
n
a

i

n
f
v
v
 
 
 
.
d
n
  
h
s
u
a

english span not a constituent
no rule extracted

s

vp

vp

vp

prp   i

md   shall

vb   be

vbg    passing

rp   on

to   to

prp   you

dt   some

pp

nns   comments

np

syntax-based id151

45

rules with context

s

vp

vp

i

n
f
a
v
 
 
 
e
d
r
e
w

r
e
p
p
 
 
 
n
e
n
h
i

r
e
p
p
 
 
 
h
c
i

t
r
a
 
 
 
e
d

i

np

j
d
a
 
 
 
.
r
p
s
t
n
e

n
n
 
 
 
.

m
n
a

i

n
f
v
v
 
 
 
.
d
n
  
h
s
u
a

s

vp

vp

vp

prp   i

md   shall

vb   be

vbg    passing

rp   on

to   to

prp   you

dt   some

pp

nns   comments

np

rule with this phrase pair
requires syntactic context

vp

vp

vafin

vp

md

vp

werde

=

shall

vb

vp

be

syntax-based id151

46

too many rules extractable

    huge number of rules can be extracted

(every alignable node may or may not be part of a rule ! exponential number of rules)

    need to limit which rules to extract

    option 1: similar restriction as for hierarchical model

(maximum span size, maximum number of terminals and non-terminals, etc.)

    option 2: only extract minimal rules (   ghkm    rules)

syntax-based id151

47

minimal rules

s

vp

vp

prp

md

vb

vbg

rp

i

shall

be passing on

vp

to

to

pp

np

prp

dt

nns

you some comments

ich werde

ihnen die

entsprechenden anmerkungen aush  ndigen

extract: set of smallest rules required to explain the sentence pair

syntax-based id151

48

lexical rule

s

vp

vp

prp

md

vb

vbg

rp

i

shall

be passing on

vp

to

to

pp

np

prp

dt

nns

you some comments

ich werde

ihnen die

entsprechenden anmerkungen aush  ndigen

extracted rule: prp ! ich | i

syntax-based id151

49

lexical rule

s

vp

vp

prp

md

vb

vbg

rp

i

shall

be passing on

vp

to

to

pp

np

prp

dt

nns

you some comments

ich werde

ihnen die

entsprechenden anmerkungen aush  ndigen

extracted rule: prp ! ihnen | you

syntax-based id151

50

lexical rule

s

vp

vp

prp

md

vb

vbg

rp

i

shall

be passing on

vp

to

to

pp

np

prp

dt

nns

you some comments

ich werde

ihnen die

entsprechenden anmerkungen aush  ndigen

extracted rule: dt ! die | some

syntax-based id151

51

lexical rule

s

vp

vp

prp

md

vb

vbg

rp

i

shall

be passing on

vp

to

to

pp

np

prp

dt

nns

you some comments

ich werde

ihnen die

entsprechenden anmerkungen aush  ndigen

extracted rule: nns ! anmerkungen | comments

syntax-based id151

52

insertion rule

s

vp

vp

prp

md

vb

vbg

rp

i

shall

be passing on

vp

to

to

pp

np

prp

dt

nns

you some comments

ich werde

ihnen die

entsprechenden anmerkungen aush  ndigen

extracted rule: pp ! x | to prp

syntax-based id151

53

non-lexical rule

s

vp

vp

prp

md

vb

vbg

rp

i

shall

be passing on

vp

to

to

pp

np

prp

dt

nns

you some comments

ich werde

ihnen die

entsprechenden anmerkungen aush  ndigen

extracted rule: np ! x1 x2 | dt1 nns2

syntax-based id151

54

lexical rule with syntactic context

s

vp

vp

prp

md

vb

vbg

rp

i

shall

be passing on

vp

to

to

pp

np

prp

dt

nns

you some comments

ich werde

ihnen die

entsprechenden anmerkungen aush  ndigen

extracted rule: vp ! x1 x2 aush  andigen | passing on pp1 np2

syntax-based id151

55

lexical rule with syntactic context

s

vp

vp

prp

md

vb

vbg

rp

i

shall

be passing on

vp

to

to

pp

np

prp

dt

nns

you some comments

ich werde

ihnen die

entsprechenden anmerkungen aush  ndigen

extracted rule: vp ! werde x | shall be vp (ignoring internal structure)

syntax-based id151

56

non-lexical rule

s

vp

vp

prp

md

vb

vbg

rp

i

shall

be passing on

vp

to

to

pp

np

prp

dt

nns

you some comments

ich werde

ihnen die

entsprechenden anmerkungen aush  ndigen

extracted rule: s ! x1 x2 | prp1 vp2

done     note: one rule per alignable constituent

syntax-based id151

57

unaligned source words

s

vp

vp

prp

md

vb

vbg

rp

i

shall

be passing on

vp

to

to

pp

np

prp

dt

nns

you some comments

ich werde

ihnen die

entsprechenden anmerkungen aush  ndigen

attach to neighboring words or higher nodes ! additional rules

syntax-based id151

58

too few phrasal rules?

    lexical rules will be 1-to-1 mappings (unless word alignment requires otherwise)

    but: phrasal rules very bene   cial in phrase-based models

    solutions

    combine rules that contain a maximum number of symbols

(as in id187, recall:    option 1   )

    compose minimal rules to cover a maximum number of non-leaf nodes

syntax-based id151

59

composed rules

x1 x2 =

np

dt1

nns1

entsprechenden anmerkungen =

nns

comments

    current rules

die =

dt
some

    composed rule

die entsprechenden anmerkungen =

np

dt
some

nns

comments

(1 non-leaf node: np)

syntax-based id151

60

composed rules

    minimal rule:

3 non-leaf nodes:
vp, pp, np

x1 x2 aush  andigen =
prp

passing

vp
prp
on

pp1

np2

    composed rule:
3 non-leaf nodes:
vp, pp and np

ihnen x1 aush  andigen =
prp

passing

vp

prp
on

pp

np1

to
to

prp
you

syntax-based id151

61

relaxing tree constraints

    impossible rule

x

werde

= md
shall

vb
be

    create new non-terminal label: md+vb

) new rule

x

werde

= md+vb
vb
be

md
shall

syntax-based id151

62

zollmann venugopal relaxation

    if span consists of two constituents , join them: x+y
    if span conststs of three constituents, join them: x+y+z
    if span covers constituents with the same parent x and include

    every but the    rst child y, label as x\y
    every but the last child y, label as x/y

    for all other cases, label as fail

) more rules can be extracted, but number of non-terminals blows up

syntax-based id151

63

special problem: flat structures

    flat structures severely limit rule extraction

np

dt
the

nnp
israeli

nnp
prime

nnp

nnp

minister

sharon

    can only extract rules for individual words or entire phrase

syntax-based id151

64

relaxation by tree binarization

dt
the

np

nnp
israeli

np

nnp
prime

np

np

nnp

nnp

minister

sharon

more rules can be extracted

left-binarization or right-binarization?

syntax-based id151

65

scoring translation rules

    extract all rules from corpus
    score based on counts

    joint rule id203: p(lhs, rhsf, rhse)
    rule application id203: p(rhsf, rhse|lhs)
    direct translation id203: p(rhse|rhsf, lhs)
    noisy channel translation id203: p(rhsf|rhse, lhs)

    lexical translation id203: qei2rhse p(ei|rhsf, a)

syntax-based id151

66

- introduction
- rule extraction

part i
part ii
part iii - decoding
part iv - extensions

syntax-based id151

67

outline

1. hiero/s2t decoding (sid18 with string input)
    viterbi decoding with local features (-lm)
    k-best extraction
    lm integration (cube pruning)
    the s2t algorithm, as implemented in moses

2. t2s decoding (stsg with tree input)

    vanilla t2s: non-directional, cube pruning

3. t2t decoding (stsg with tree input)

    included for completeness     better alternatives explored later

syntax-based id151

68

viterbi s2t decoding (-lm)

objective

find the highest-scoring synchronous derivation d   

input

s1 s2 . . . sn

grammar

r1
r2
r3
. . .
r|g|

c1 !    1 |  1
c2 !    2 |  2
c3 !    3 |  3
c|g| !    |g|

|  |g|

w1
w2
w3

w|g|

    ci,    i and  i are lhs, source rhs, target rhs of rule ri, respectively.
    wi is weight of rule ri (weighted product of rule-local feature functions).
    |g| is the number of rules in the grammar g.

syntax-based id151

69

viterbi s2t decoding (-lm)

objective

find the highest-scoring synchronous derivation d   

solution

1. project grammar

project weighted sid18 to weighted id18
f : g ! g0 (many-to-one rule mapping)

2. parse

find viterbi parse of sentence wrt g0

3. translate

produce synchronous tree pair by applying inverse
projection f0

syntax-based id151

70

example

input

jemand mu  te josef k. verleumdet haben
someone must josef k. slandered have

grammar

np ! josef k. | josef k.

) r1:
) r2: vbn ! verleumdet | slandered
) r3: vbn ! verleumdet | defamed
) r4:
) r5:
) r6:
) r7:

vp ! mu  te x1 x2 haben | must have vbn2 np1
s ! jemand x1 | someone vp1
s ! jemand mu  te x1 x2 haben | someone must have vbn2 np1
s ! jemand mu  te x1 x2 haben | np1 must have been vbn1 by someone

(six derivations in total)

syntax-based id151

0.90
0.40
0.20
0.10
0.60
0.80
0.05

71

example

input

jemand mu  te josef k. verleumdet haben
someone must josef k. slandered have

grammar

np ! josef k. | josef k.

) r1:
) r2: vbn ! verleumdet | slandered
) r3: vbn ! verleumdet | defamed
) r4:
) r5:
) r6:
) r7:

vp ! mu  te x1 x2 haben | must have vbn2 np1
s ! jemand x1 | someone vp1
s ! jemand mu  te x1 x2 haben | someone must have vbn2 np1
s ! jemand mu  te x1 x2 haben | np1 must have been vbn1 by someone

source

x

target

s

derivation 1

jemand

x

someone

vp

mu  te

x

x

haben

must

have

vbn

np

josef

k.

verleumdet

slandered

josef

k.

syntax-based id151

example

input

jemand mu  te josef k. verleumdet haben
someone must josef k. slandered have

grammar

np ! josef k. | josef k.

) r1:
) r2: vbn ! verleumdet | slandered
) r3: vbn ! verleumdet | defamed
) r4:
) r5:
) r6:
) r7:

vp ! mu  te x1 x2 haben | must have vbn2 np1
s ! jemand x1 | someone vp1
s ! jemand mu  te x1 x2 haben | someone must have vbn2 np1
s ! jemand mu  te x1 x2 haben | np1 must have been vbn1 by someone

source

x

target

s

derivation 2

jemand

x

someone

vp

mu  te

x

x

haben

must

have

vbn

np

josef

k.

verleumdet

defamed

josef

k.

syntax-based id151

0.90
0.40
0.20
0.10
0.60
0.80
0.05

72

0.90
0.40
0.20
0.10
0.60
0.80
0.05

73

example

input

jemand mu  te josef k. verleumdet haben
someone must josef k. slandered have

grammar

np ! josef k. | josef k.

) r1:
) r2: vbn ! verleumdet | slandered
) r3: vbn ! verleumdet | defamed
) r4:
) r5:
) r6:
) r7:

vp ! mu  te x1 x2 haben | must have vbn2 np1
s ! jemand x1 | someone vp1
s ! jemand mu  te x1 x2 haben | someone must have vbn2 np1
s ! jemand mu  te x1 x2 haben | np1 must have been vbn1 by someone

source

target

x

s

derivation 3

jemand

mu  te

x

x

haben

someone

must

have

vbn

np

josef

k.

verleumdet

slandered

josef

k.

syntax-based id151

example

input

jemand mu  te josef k. verleumdet haben
someone must josef k. slandered have

grammar

np ! josef k. | josef k.

) r1:
) r2: vbn ! verleumdet | slandered
) r3: vbn ! verleumdet | defamed
) r4:
) r5:
) r6:
) r7:

vp ! mu  te x1 x2 haben | must have vbn2 np1
s ! jemand x1 | someone vp1
s ! jemand mu  te x1 x2 haben | someone must have vbn2 np1
s ! jemand mu  te x1 x2 haben | np1 must have been vbn1 by someone

source

target

x

s

derivation 4

jemand

mu  te

x

x

haben

someone

must

have

vbn

np

josef

k.

verleumdet

defamed

josef

k.

syntax-based id151

0.90
0.40
0.20
0.10
0.60
0.80
0.05

74

0.90
0.40
0.20
0.10
0.60
0.80
0.05

75

example

input

jemand mu  te josef k. verleumdet haben
someone must josef k. slandered have

grammar

np ! josef k. | josef k.

) r1:
) r2: vbn ! verleumdet | slandered
) r3: vbn ! verleumdet | defamed
) r4:
) r5:
) r6:
) r7:

vp ! mu  te x1 x2 haben | must have vbn2 np1
s ! jemand x1 | someone vp1
s ! jemand mu  te x1 x2 haben | someone must have vbn2 np1
s ! jemand mu  te x1 x2 haben | np1 must have been vbn1 by someone

source

target

x

s

derivation 5

jemand

mu  te

x

x

haben

np

must

have

been

vbn

by

someone

josef

k.

verleumdet

josef

k.

slandered

syntax-based id151

example

input

jemand mu  te josef k. verleumdet haben
someone must josef k. slandered have

grammar

np ! josef k. | josef k.

) r1:
) r2: vbn ! verleumdet | slandered
) r3: vbn ! verleumdet | defamed
) r4:
) r5:
) r6:
) r7:

vp ! mu  te x1 x2 haben | must have vbn2 np1
s ! jemand x1 | someone vp1
s ! jemand mu  te x1 x2 haben | someone must have vbn2 np1
s ! jemand mu  te x1 x2 haben | np1 must have been vbn1 by someone

source

target

x

s

derivation 6

jemand

mu  te

x

x

haben

np

must

have

been

vbn

by

someone

josef

k.

verleumdet

josef

k.

defamed

syntax-based id151

0.90
0.40
0.20
0.10
0.60
0.80
0.05

76

0.90
0.40
0.20
0.10
0.60
0.80
0.05

77

step 1: project grammar to id18

np ! josef k. | josef k.

) r1:
) r2: vbn ! verleumdet | slandered
) r3: vbn ! verleumdet | defamed
) r4:
) r5:
) r6:
) r7:

vp ! mu  te x1 x2 haben | must have vbn2 np1
s ! jemand x1 | someone vp1
s ! jemand mu  te x1 x2 haben | someone must have vbn2 np1
s ! jemand mu  te x1 x2 haben | np1 must have been vbn1 by someone

np ! josef k.
) q1:
) q2: vbn ! verleumdet
vp ! mu  te np vbn haben
) q3:
s ! jemand vp
) q4:
) q5:
s ! jemand mu  te np vbn haben

0.90
0.40
0.20
0.10
0.60
0.80
0.05

0.90
0.40
0.10
0.60
0.80

g

g0

    g is original synchronous grammar, g0 is monolingual projection

syntax-based id151

78

step 1: project grammar to id18

g

g0

np ! josef k. | josef k.

) r1:
) r2: vbn ! verleumdet | slandered
) r3: vbn ! verleumdet | defamed
) r4:
) r5:
) r6:
) r7:

vp ! mu  te x1 x2 haben | must have vbn2 np1
s ! jemand x1 | someone vp1
s ! jemand mu  te x1 x2 haben | someone must have vbn2 np1
s ! jemand mu  te x1 x2 haben | np1 must have been vbn1 by someone

np ! josef k.
) q1:
) q2: vbn ! verleumdet
vp ! mu  te np vbn haben
) q3:
s ! jemand vp
) q4:
s ! jemand mu  te np vbn haben
) q5:

0.90
0.40
0.20
0.10
0.60
0.80
0.05

0.90
0.40
0.10
0.60
0.80

    projected rule gets lhs and source rhs (but with target non-terminal labels)

syntax-based id151

79

step 1: project grammar to id18

np ! josef k. | josef k.

) r1:
) r2: vbn ! verleumdet | slandered
) r3: vbn ! verleumdet | defamed
) r4:
) r5:
) r6:
) r7:

vp ! mu  te x1 x2 haben | must have vbn2 np1
s ! jemand x1 | someone vp1
s ! jemand mu  te x1 x2 haben | someone must have vbn2 np1
s ! jemand mu  te x1 x2 haben | np1 must have been vbn1 by someone

np ! josef k.
) q1:
) q2: vbn ! verleumdet
vp ! mu  te np vbn haben
) q3:
s ! jemand vp
) q4:
) q5:
s ! jemand mu  te np vbn haben

0.90
0.40
0.20
0.10
0.60
0.80
0.05

0.90
0.40
0.10
0.60
0.80

g

g0

    many-to-one: weight of projected rule is the best from set of projecting rules

syntax-based id151

80

step 1: project grammar to id18

g

g0

np ! josef k. | josef k.

) r1:
) r2: vbn ! verleumdet | slandered
) r3: vbn ! verleumdet | defamed
) r4:
) r5:
) r6:
) r7:

vp ! mu  te x1 x2 haben | must have vbn2 np1
s ! jemand x1 | someone vp1
s ! jemand mu  te x1 x2 haben | someone must have vbn2 np1
s ! jemand mu  te x1 x2 haben | np1 must have been vbn1 by someone

np ! josef k.
) q1:
) q2: vbn ! verleumdet
vp ! mu  te np vbn haben
) q3:
s ! jemand vp
) q4:
s ! jemand mu  te np vbn haben
) q5:

0.90
0.40
0.20
0.10
0.60
0.80
0.05

0.90
0.40
0.10
0.60
0.80

    target non-terminal labels projected to monolingual rule (in source order)

syntax-based id151

81

step 1: project grammar to id18

np ! josef k. | josef k.

) r1:
) r2: vbn ! verleumdet | slandered
) r3: vbn ! verleumdet | defamed
) r4:
) r5:
) r6:
) r7:

vp ! mu  te x1 x2 haben | must have vbn2 np1
s ! jemand x1 | someone vp1
s ! jemand mu  te x1 x2 haben | someone must have vbn2 np1
s ! jemand mu  te x1 x2 haben | np1 must have been vbn1 by someone

np ! josef k.
) q1:
) q2: vbn ! verleumdet
vp ! mu  te np vbn haben
) q3:
s ! jemand vp
) q4:
) q5:
s ! jemand mu  te np vbn haben

0.90
0.40
0.20
0.10
0.60
0.80
0.05

0.90
0.40
0.10
0.60
0.80

g

g0

    and so on. . .

syntax-based id151

82

step 1: project grammar to id18

g

np ! josef k. | josef k.

) r1:
) r2: vbn ! verleumdet | slandered
) r3: vbn ! verleumdet | defamed
) r4:
) r5:
) r6:
) r7:

vp ! mu  te x1 x2 haben | must have vbn2 np1
s ! jemand x1 | someone vp1
s ! jemand mu  te x1 x2 haben | someone must have vbn2 np1
s ! jemand mu  te x1 x2 haben | np1 must have been vbn1 by someone

g0

np ! josef k.
) q1:
) q2: vbn ! verleumdet
vp ! mu  te np vbn haben
) q3:
s ! jemand vp
) q4:
) q5:
s ! jemand mu  te np vbn haben
    and so on.

0.90
0.40
0.20
0.10
0.60
0.80
0.05

0.90
0.40
0.10
0.60
0.80

syntax-based id151

83

step 2: find viterbi parse

input 
sentence

g'

binarize

g''

cyk

flatten

input 
sentence

g'

cyk+ / earley

    standard weighted parsing algorithms.
    binarization can be explicit (like cyk) or implicit (like earley / cyk+)

syntax-based id151

84

step 3: reconstruct synchronous derivation

1-best parse tree

source-side parse tree

s

jemand

mu  te

np

vbn

haben

josef 

k.

verleumdet

syntax-based id151

85

step 3: reconstruct synchronous derivation

1-best parse tree

source-side parse tree

s

x

jemand

mu  te

np

vbn

haben

jemand

mu  te

x

x

haben

josef 

k.

verleumdet

josef 

k.

verleumdet

    source-side: replace non-terminals with xs

syntax-based id151

86

step 3: reconstruct synchronous derivation

1-best parse tree

source-side parse tree

s

jemand

mu  te

np

vbn

haben

josef 

k.

verleumdet

    target-side: invert grammar projection

syntax-based id151

87

step 3: reconstruct synchronous derivation

1-best parse tree

source-side parse tree

s

jemand

mu  te

np

vbn

haben

josef 

k.

verleumdet

np

josef  k.

    target-side: invert grammar projection
np ! josef k. | josef k.

syntax-based id151

88

step 3: reconstruct synchronous derivation

1-best parse tree

source-side parse tree

s

jemand

mu  te

np

vbn

haben

josef 

k.

verleumdet

np

vbn

josef 

k.

slandered

    target-side: invert grammar projection (multiple rules? pick highest-scoring)
vbn ! verleumdet | slandered
vbn ! verleumdet | defamed

0.4
0.2

syntax-based id151

89

step 3: reconstruct synchronous derivation

1-best parse tree

source-side parse tree

s

s

jemand

mu  te

np

vbn

haben

someone

must have

vbn

np

josef 

k.

verleumdet

slandered

josef 

k.

    target-side: invert grammar projection (multiple rules? pick highest-scoring)
s ! jemand mu  te x1 x2 haben | someone must have vbn2 np1
0.80
s ! jemand mu  te x1 x2 haben | np1 must have been vbn2 by someone
0.05

syntax-based id151

90

k-best extraction

objective

find the k-best synchronous derivations d1, d2, . . . dk

well. . .

1. 1-best derivation is 1-best monolingual parse tree with best set of translations

2. 2-best and 3-best derivations are (in some order):

(a) 1-best monolingual parse tree with second best set of translations, and
(b) 2-best monolingual parse tree with best translations

3. 4-best derivation is one of. . .

syntax-based id151

91

k-best extraction

objective

find the k-best synchronous derivations d1, d2, . . . dk

well. . .

1. 1-best derivation is 1-best monolingual parse tree with best set of translations

2. 2-best and 3-best derivations are (in some order):

(a) 1-best monolingual parse tree with second best set of translations, and
(b) 2-best monolingual parse tree with best translations

3. 4-best derivation is one of. . .

we know part of the solution: how to get the k-best monolingual
derivations (huang and chiang, 2005)

syntax-based id151

92

digression: parsing and hypergraphs

s

s

jemand

mu  te

np

vbn

haben

jemand

vp

josef

k.

verleumdet

mu  te

np

vbn

haben

josef

k.

verleumdet

q5

s1,6

q4

jemand

mu  te

np3,4

q1
josef

k.

vp2,6

q3

vbn5,5
q2
verleumdet

haben

syntax-based id151

93

digression: parsing and hypergraphs

q5

s1,6

q4

jemand

mu  te

np3,4

q1
josef

k.

vp2,6

q3

vbn5,5
q2
verleumdet

haben

    generalization of a graph: hyperedges connect two sets of vertices
    terminology: vertices and hyperedges (nodes and arcs)
    a parse forest can be represented by a rooted, connected, labelled, directed,

acyclic hypergraph (klein and manning, 2001)

    vertices represent parsing states; hyperedges represent rule applications

syntax-based id151

94

monolingual k-best extraction

huang and chiang (2005) provide e cient algorithms for k-best extraction.

objective

extract the k-best monolingual derivations d1, d2, . . . dk from a
weighted parse forest

outline
(alg. 3)

1. the 1-best subderivation for every vertex (and its

incoming hyperedges) is known from the outset

2. given the i-best derivation, the next best candidate
along the same hyperedge is identical except for a
substitution at a single incoming vertex

3. at the top vertex, generates candidates by recursively

asking predecessors for next best subderivations.

4. maintain priority queue of candidates at each vertex

syntax-based id151

95

synchronous k-best extraction

replace hyperedges according to f0 (invert grammar projection)

q5

s1,6

q4

jemand

mu  te

np3,4

q1
josef

k.

vp2,6

q3

vbn5,5
q2
verleumdet

r6

s1,6

r5

r7

r4

vp2,6

haben

jemand

mu  te

np3,4

vbn5,5

haben

r1
josef

r2

r3

k.

verleumdet

    the standard k-best extraction algorithm now gives the k-best synchronous

derivations.

    the second hypergraph is sometimes called a    translation hypergraph   .
    we   ll call the    rst the    parse forest hypergraph    or the    parse hypergraph.   

syntax-based id151

96

s2t decoding (lm-) summary

objective

find the k-best synchronous derivations d1, d2, . . . dk

solution

1. project grammar

project weighted sid18 to unweighted id18
f : g ! g0 (many-to-one)

2. parse

build parse hypergraph wrt g0

3. invert projection

expand hypergraph by replacing hyperedges according to f0

4. extract derivations

extract k-best derivations using huang and chiang   s (2005)
algorithm

syntax-based id151

97

lm integration

without lm

k-best derivation is k-best path through translation
hypergraph

optimal
substructure

vbn4,4

r2 0.40

r3 0.20

verleumdet

global

if
best
path
includes vbn4,4
then
best path must include
hyperedge labelled r2

syntax-based id151

98

lm integration

consider the two paths that include the hyperedge labelled r6:

s1,6

r6 ???

jemand

mu  te

np3,4

vbn5,5

haben

r1
josef

r2 ???

r3 ???

k.

verleumdet

what   s the best path through this hypergraph? for bi-gram lm we need to
compute:

have slandered josef

have defamed josef

p(have | hsi)     p(slandered | have)     p(josef | slandered)     . . .
p(have | hsi)     p(defamed | have)     p(josef | defamed)     . . .

syntax-based id151

99

state splitting?

restore optimal substructure property by splitting states:

s1,6, someone...k.

r6

0.80 + c3

r6

0.80 + c4

jemand

mu  te

np3,4, josef k.
r1
josef

k.

vbn5,5,slandered

vbn5,5,defamed

haben

r2

0.40 + c1

verleumdet

r3

0.20 + c2

    vertex labels include    rst and last words of translation.
    hyperedges labelled with weights that incorporate lm costs.
    k-best derivation is k-best path.

syntax-based id151

100

state splitting?

objective

find the k-best synchronous derivations d1, d2, . . . dk

potential
solution

1. project grammar

project weighted sid18 to weighted id18 f : g ! g0
build parse hypergraph wrt g0

2. parse

3. invert projection + split states

expand hypergraph by replacing hyperedges according
to f0. during replacement, split states and add
lm costs

4. extract derivations

extract k-best derivations (huang and chiang, 2005)

syntax-based id151

101

state splitting?

s1,6,someone ... k.

r6 + c0

jemand

mu  te

np3,4,josef k.

vbn5,5,slandered

haben

s1,6
q5 

s1,6,someone ... k.

r6 + c1

jemand

mu  te

np3,4

vbn5,5

haben

jemand

mu  te

np3,4,josef k.

vbn5,5,defamed

haben

s1,6,josef ... someone
r7 + c2

jemand

mu  te

np3,4,josef k.

vbn5,5,slandered

haben

np3,4

    pick a search vertex for    
 
    pick a search vertex for    
 
    pick a synchronous rule from the set f0(q5) = {r6, r7} (i.e. pick a target-side)
the full set is generated by taking the cartesian product of these three sets.

from the set {    
 
 
 
 
from the set {    
 
 

 
}
 
,    
 
 
 

 
}
 

np5,5,slandered

np5,5,defamed

np3,4,josef k.

vbn5,5

syntax-based id151

102

the search hypergraph is too large. . .

the parse hypergraph has o(n3) space constraints (assuming certain grammar
properties. . . )

with a m-gram lm the search hypergraph is much larger:
hyperedges

vertices

o(n2|c|)

parse
search o(n2|c||t|2(m 1)) o(n3|g||t|2a(m 1))

o(n3|g|)

c is the set of target non-terminals n is the input sentence length
t is the set of target-side terminals m is the order of the lm
a is the maximum rule arity

syntax-based id151

103

heuristic search

    in practice, only part of the search hypergraph can be explored.
    during search, a partial search hypergraph is generated in topological order.
    three main strategies for reducing search space:

parse forest pruning avoid splitting some parse forest hyperedges by pre-

pruning the forest (methods can be exact or inexact).

heuristic best-   rst splitting e.g. cube pruning. use a splitting algorithm

that    nds expanded hyperedges in approximately best-   rst order.

id125 bin vertices according to source word span and category. keep

only the highest-scoring vertices for use later in the search.

syntax-based id151

104

strategy 1: parse forest pruning

    if parse forest is constructed in full prior to search then dead-ends can be

pruned away.

    state splitting can be restricted to a small subset of promising hyperedges.

    moses ranks hyperedges according to -lm rule cost plus sums of incoming

+lm vertex costs.

    monolingual

charniak and johnson (2005)).

forest pruning methods (inside-outside estimates,

see e.g.

(forest pruning methods haven   t been widely explored in the mt literature.)

syntax-based id151

105

strategy 2: heuristic best-first state splitting

    for every hyperedge in the parse hypergraph,
corresponding hyperedges in the search hypergraph.

there can be very many

s1,6,someone ... k.

r6 + c0

jemand

mu  te

np3,4,josef k.

vbn5,5,slandered

haben

s1,6
q5 

s1,6,someone ... k.

r6 + c1

jemand

mu  te

np3,4

vbn5,5

haben

jemand

mu  te

np3,4,josef k.

vbn5,5,defamed

haben

s1,6,josef ... someone
r7 + c2

jemand

mu  te

np3,4,josef k.

vbn5,5,slandered

haben

    cube pruning (chiang, 2007) is most widely-used approximate algorithm but

see hea   eld et al. (2013) for a faster alternative.

syntax-based id151

106

cube pruning

i

t
s
n
o
g
a

t

o
r
p
 
r
u
o
2

 

.

3

.

k

 
f

e
s
o
j
5

 

.

1

f

e
s
o
j
6
2

.

 

.

 

k
7
1

.

slandered 1.0
defamed 1.3
 maligned 2.2
libelled 2.6

arrange all the choices in a    cube   

(here: a square, generally an orthotope, also called a hyperrectangle)

syntax-based id151

107

create the first hyperedge

i

t
s
n
o
g
a
t
o
r
p
 
r
u
o
2

 

.

k

 
f
e
s
o
j
5

 

.

f
e
s
o
j
6

 

.

k
7

 

.

1

.

2

.

3

1

2.1
2.1

slandered 1.0
defamed 1.3
 maligned 2.2
libelled 2.6

    hyperedges created in cube: (0,0)

syntax-based id151

108

   pop    hyperedge

i

t
s
n
o
g
a

t

o
r
p
 
r
u
o
2
3

.

 

.

k

 
f

e
s
o
j
5
1

.

 

f

e
s
o
j
6
2

.

 

.

k
7

 

.

1

2.1

slandered 1.0
defamed 1.3
 maligned 2.2
libelled 2.6

    hyperedges created in cube:    
    hyperedges popped: (0,0)

syntax-based id151

109

create neighboring hyperedges

i

t
s
n
o
g
a
t
o
r
p
 
r
u
o
2

 

f
e
s
o
j
6

 

.

2

.

3

.

k

 
f
e
s
o
j
5

 

.

k
7

 

.

1

2.5

.

1

2.1
2.7

slandered 1.0
defamed 1.3
 maligned 2.2
libelled 2.6

    hyperedges created in cube: (0,1), (1,0)
    hyperedges popped: (0,0)

syntax-based id151

110

pop best hyperedge

i

t
s
n
o
g
a

t

o
r
p
 
r
u
o
2
3

.

 

.

k

 
f

e
s
o
j
5

 

f

e
s
o
j
6
2

.

 

.

k
7

 

.

1

2.5

.

1

2.1
2.7

slandered 1.0
defamed 1.3
 maligned 2.2
libelled 2.6

    hyperedges created in cube: (0,1)
    hyperedges popped: (0,0), (1,0)

syntax-based id151

111

create neighboring hyperedges

i

t
s
n
o
g
a
t
o
r
p
 
r
u
o
2

 

.

3

.

k

 
f
e
s
o
j
5

 

.

k
7

 

.

1

.

1

f
e
s
o
j
6

 

.

2

3.1

2.5
2.1
2.7 2.4

slandered 1.0
defamed 1.3
 maligned 2.2
libelled 2.6

    hyperedges created in cube: (0,1), (1,1), (2,0)
    hyperedges popped: (0,0), (1,0)

syntax-based id151

112

more of the same

i

t
s
n
o
g
a

t

o
r
p
 
r
u
o
2

 

.

3

.

k

 
f

e
s
o
j
5

 

.

k
7

 

.

1

.

1

f

e
s
o
j
6
2

.

 

slandered 1.0
defamed 1.3
 maligned 2.2
libelled 2.6

2.5
2.1
2.7 2.4

3.1
3.0

3.8

    hyperedges created in cube: (0,1), (1,2), (2,1), (2,0)
    hyperedges popped: (0,0), (1,0), (1,1)

syntax-based id151

113

queue of cubes

    many parse hyperedges for any given span
    each of them will have a cube
    we can create a queue of cubes
) always pop o    the most promising hyperedge, regardless of cube

    may have separate queues for di   erent target constituent labels

syntax-based id151

114

strategy 3: id125

    bin vertices according to source word span

and category.

    keep only the highest-scoring vertices for use

later in the search.

s1,6

s1,6,someone ... k.

s1,6,josef ... someone

s1,6,josef. ... somebody

...

syntax-based id151

115

putting it all together: the s2t decoding

algorithm in moses

objective

find the k-best synchronous derivations d1, d2, . . . dk

outline

1. project grammar

project weighted sid18 to weighted id18 f : g ! g0

2. interleaved parse + search

span-by-span, build parse hypergraph wrt g0 and build
partial search hypergraph

3. extract derivations

extract k-best derivations (huang and chiang, 2005)

syntax-based id151

116

decoding: components

s1,6

vp2,6

np3,4

jemand

mu  te

josef

k.

vbn5,5
verleumdet

haben

    vertices of the parse hypergraph are stored in a chart (includes input sentence)
    hyperedges are enumerated but not stored in chart
    terminology: pchart, pvertex, phyperedge

syntax-based id151

117

decoding: components

span

[1,6]

parser

partially-   lled

pchart

vp2,6

np3,4

jemand

mu  te

josef

k.

vbn5,5
verleumdet haben

phyperedges

for span

s1,6
q5 

jemand

mu  te

np3,4

vbn5,5

haben

s1,6
q4 

jemand

vp2,6

    parser generates phyperedges for given span of pchart
    parser has access to partially-completed pchart
    for now, the parser is a black-box component but we   ll return to parsing. . .

syntax-based id151

118

decoding: components

..
..
..

...
..
...
..
..
..

...
..
...
..
..
..

...
..
...

...
..
...
..
..
..

...
..
...

...
..
...

..
..
..

..
..
..

...
..
...

..
..
..
...
..
...
..
..
..

...
..
...

..
..
..
...
..
...

..
..
..

...
..
...

..
..
..

..
..
..

...
..
...
..
..
..

...
..
...

..
..
..

...
..
...

..
..
..

..
..
..

...
..
...

..
..
..

...
..
...

...
..
...

..
..
..

..
..
..

...
..
...
..
..
..

..
..
...

..
..
...

..
..
..

..
..
...

s

sbar

...

s1,6,someone ... k.

sbar1,6,that ... k.

s1,6,josef ... someone

sbar1,6,someone ... k.

s1,6,josef. ... somebody

sbar1,6,josef ... someone

...

...

    vertices of the search hypergraph are stored in a chart (includes input sentence)
    vertices are stored in stacks (one per span + category), which are sorted
    hyperedges are stored (unlike in pchart)
    terminology: schart, svertex, shyperedge

syntax-based id151

119

decoding: components

s1,6
q5 

jemand

mu  te

np3,4

vbn5,5

haben

i

t
s
n
o
g
a
t
o
r
p
 
r
u
o
2

 

.

3

.

k

 
f
e
s
o
j
5

 

.

1

f
e
s
o
j
6
2

.

 

.

 

k
7
1

.

slandered 1.0
defamed 1.3
 maligned 2.2
libelled 2.6

2.5
2.1
2.7 2.4

3.1
3.0

3.8

s1,6,someone ... k.

r6 + c0

jemand

mu  te

np3,4,josef k.

vbn5,5,slandered

haben

s1,6,someone ... k.

r6 + c1

jemand

mu  te

np3,4,josef k.

vbn5,5,defamed

haben

s1,6,josef ... someone
r7 + c2

jemand

mu  te

np3,4,josef k.

vbn5,5,slandered

haben

    cube pruning algorithm (or similar) produces shyperedges from phyperedges
    a single svertex can be produced multiple times so must check for this

(   recombination   )

syntax-based id151

120

the moses s2t decoding algorithm

initialize pchart and schart by adding vertices for input words

1:
2: for each span (in parser-de   ned order) do
3:

p-hyperedges = forestprune(parser.enumeratehyperedges(span, p-chart), s-chart)
for all p-hyperedges do

4:

5:

6:

7:

8:

9:

10:

11:

12:

13:

14:

15:

16:

create a cube for it
create    rst s-hyperedge in cube
place cube in queue

end for
for speci   ed number of pops do

pop o    best s-hyperedge of any cube in queue
add it to a category-speci   c bu   er
create its neighbors

end for
for category do

recombine s-hyperedges from bu   er and move into s-chart stack
sort stack

end for

17:
18: end for

syntax-based id151

121

parsing for s2t decoding

span

[1,6]

parser

partially-   lled

pchart

vp2,6

np3,4

jemand

mu  te

josef

k.

vbn5,5
verleumdet haben

phyperedges

for span

s1,6
q5 

jemand

mu  te

np3,4

vbn5,5

haben

s1,6
q4 

jemand

vp2,6

    parser   s job is to enumerate phyperedges, span-by-span.
    parser has access to partially-   lled pchart.

syntax-based id151

122

parsing for s2t decoding

    can we just use cyk / cyk+ / earley?

    all require binarization (implicit or explicit).
    wasn   t a problem for viterbi -lm case.

    idea 1 binarize g0

    binary normal forms exist for monolingual id18 grammars.
    but we still need to know the synchronous rules for +lm search.

    idea 2 binarize g before projection to id18

    binarization impossible for some sid18 rules with rank   4
    not necessarily a problem: non-binarizable cases are rare in word-aligned

translation data (zhang et al., 2006)

    but tricky in practice: how do we weight rules? and what about grammar

in   ation?

syntax-based id151

123

how to avoid binarization

    hopkins and langmead (2010) de   ne a grammar property called scope:

pattern
a b c d e
a     c     e
a         d e
    b c d e

scope
0
0
1
1

pattern
a             e
    b c d    
        c d    
                   

scope
2
2
3
6

    they prove that a sentence of length n can be parsed with a scope k grammar

in o(nk) chart updates without binarization.

    they demonstrate empirically that reducing a ghkm grammar to scope-3 by
pruning does not harm translation quality compared to synchronous binarization
(and pruning is much simpler).

    chung et al. (2011) perform similar comparison and achieve same result.

syntax-based id151

124

specialized parsing algorithms

    cyk+ and earley are popular choices for s2t decoding.
    but storing large numbers of dotted rules is problematic in practice (chung et
al. 2011    nd scope-3 slower than binarized grammar with earley parser, which
they attribute to dotted rule storage).

    several parsing algorithms have been designed speci   cally for synchronous
translation grammars: denero et al. (2009), hopkins and langmead (2010),
sennrich (2014).

    we use sennrich (2014)   s recursive variant of cyk+:

    good performance on wmt-scale task: fast, low-memory overhead
    simpler than cyk+ and alternatives
    no dotted rule storage

syntax-based id151

125

parsing for s2t decoding (moses-style)

l e u m d e t
josef

d
n
a
m
je

v e r

k .

   te

u

m

v

p

np
vbn

haben

mu  te

np

vbn

h

a

b

e

n

    projected grammar g0 is represented as a trie (sometimes called a pre   x tree)
    edges are labelled with terminals and non-terminals
    labels along path (from root) represent pre   x of rule rhs
    vertices in black are associated with group of rules from g (sub-grouped by

rule lhs)

syntax-based id151

126

parsing for s2t decoding - example

partially-   lled

pchart

vp2,6

np3,4

jemand

mu  te

josef

k.

vbn5,5
verleumdet

haben

l e u m d e t
josef

d
n
a
m
je

v e r

k .

   te

u

m

v

p

np
vbn

haben

mu  te

np

vbn

h

a

b

e

n

    sennrich (2014)   s parsing algorithm visits cells in right-to-left, depth-   rst order.
    we consider situation where all of pchart    lled except for left-most diagonal.
    recall that pvertices are stored, but phyperedges are not.

syntax-based id151

127

parsing for s2t decoding - example

partially-   lled

pchart

vp2,6

np3,4

jemand

mu  te

josef

k.

vbn5,5
verleumdet

haben

l e u m d e t
josef

d
n
a
m
je

v e r

k .

   te

u

m

v

p

np
vbn

haben

mu  te

np

vbn

h

a

b

e

n

    tail pre   x: []
    recursion level: 0

syntax-based id151

128

parsing for s2t decoding - example

l e u m d e t
josef

d
n
a
m
je

v e r

k .

   te

u

m

v

p

np
vbn

haben

mu  te

np

vbn

h

a

b

e

n

partially-   lled

pchart

vp2,6

np3,4

jemand

mu  te

josef

k.

vbn5,5
verleumdet

haben

    tail pre   x: []
    recursion level: 0
    look for edge labelled    jemand    at root node

syntax-based id151

129

parsing for s2t decoding - example

partially-   lled

pchart

vp2,6

np3,4

jemand

mu  te

josef

k.

vbn5,5
verleumdet

haben

l e u m d e t
josef

d
n
a
m
je

v e r

k .

   te

u

m

v

p

np
vbn

haben

mu  te

np

vbn

h

a

b

e

n

    tail pre   x: [jemand1,1]
    recursion level: 0
    look for edge labelled    jemand    at root node - found

syntax-based id151

130

parsing for s2t decoding - example

l e u m d e t
josef

d
n
a
m
je

v e r

k .

   te

u

m

v

p

np
vbn

haben

mu  te

np

vbn

h

a

b

e

n

partially-   lled

pchart

vp2,6

np3,4

jemand

mu  te

josef

k.

vbn5,5
verleumdet

haben

    tail pre   x: [jemand1,1]
    recursion level: 0
    check for rules at current node - none

syntax-based id151

131

parsing for s2t decoding - example

partially-   lled

pchart

vp2,6

np3,4

jemand

mu  te

josef

k.

vbn5,5
verleumdet

haben

l e u m d e t
josef

d
n
a
m
je

v e r

k .

   te

u

m

v

p

np
vbn

haben

mu  te

np

vbn

h

a

b

e

n

    tail pre   x: [jemand1,1]
    recursion level: 0
    now visit each cell along previous diagonal (recursive step)

syntax-based id151

132

parsing for s2t decoding - example

partially-   lled

pchart

vp2,6

np3,4

jemand

mu  te

josef

k.

vbn5,5
verleumdet

haben

l e u m d e t
josef

d
n
a
m
je

v e r

k .

   te

u

m

v

p

np
vbn

haben

mu  te

np

vbn

h

a

b

e

n

    tail pre   x: [jemand1,1]
    recursion level: 1
    look for edge labelled    mu  te    at current node

syntax-based id151

133

parsing for s2t decoding - example

partially-   lled

pchart

vp2,6

np3,4

jemand

mu  te

josef

k.

vbn5,5
verleumdet

haben

l e u m d e t
josef

d
n
a
m
je

v e r

k .

   te

u

m

v

p

np
vbn

haben

mu  te

np

vbn

h

a

b

e

n

    tail pre   x: [jemand1,1, mu  te2,2]
    recursion level: 1
    look for edge labelled    mu  te    at current node - found

syntax-based id151

134

parsing for s2t decoding - example

l e u m d e t
josef

d
n
a
m
je

v e r

k .

   te

u

m

v

p

np
vbn

haben

mu  te

np

vbn

h

a

b

e

n

partially-   lled

pchart

vp2,6

np3,4

jemand

mu  te

josef

k.

vbn5,5
verleumdet

haben

    tail pre   x: [jemand1,1, mu  te2,2]
    recursion level: 1
    now visit each cell along previous diagonal

syntax-based id151

135

parsing for s2t decoding - example

partially-   lled

pchart

vp2,6

np3,4

jemand

mu  te

josef

k.

vbn5,5
verleumdet

haben

l e u m d e t
josef

d
n
a
m
je

v e r

k .

   te

u

m

v

p

np
vbn

haben

mu  te

np

vbn

h

a

b

e

n

    tail pre   x: [jemand1,1, mu  te2,2]
    recursion level: 2
    look for edge labelled    josef    at current node

syntax-based id151

136

parsing for s2t decoding - example

partially-   lled

pchart

vp2,6

np3,4

jemand

mu  te

josef

k.

vbn5,5
verleumdet

haben

l e u m d e t
josef

d
n
a
m
je

v e r

k .

   te

u

m

v

p

np
vbn

haben

mu  te

np

vbn

h

a

b

e

n

    tail pre   x: [jemand1,1, mu  te2,2]
    recursion level: 2
    look for edge labelled    josef    at current node - not found

syntax-based id151

137

parsing for s2t decoding - example

l e u m d e t
josef

d
n
a
m
je

v e r

k .

   te

u

m

v

p

np
vbn

haben

mu  te

np

vbn

h

a

b

e

n

partially-   lled

pchart

vp2,6

np3,4

jemand

mu  te

josef

k.

vbn5,5
verleumdet

haben

    tail pre   x: [jemand1,1, mu  te2,2]
    recursion level: 2
    look for edge labelled    np    at current node

syntax-based id151

138

parsing for s2t decoding - example

partially-   lled

pchart

vp2,6

np3,4

jemand

mu  te

josef

k.

vbn5,5
verleumdet

haben

l e u m d e t
josef

d
n
a
m
je

v e r

k .

   te

u

m

v

p

np
vbn

haben

mu  te

np

vbn

h

a

b

e

n

    tail pre   x: [jemand1,1, mu  te2,2, np3,4]
    recursion level: 2
    look for edge labelled    np    at current node - found

syntax-based id151

139

parsing for s2t decoding - example

l e u m d e t
josef

d
n
a
m
je

v e r

k .

   te

u

m

v

p

np
vbn

haben

mu  te

np

vbn

h

a

b

e

n

partially-   lled

pchart

vp2,6

np3,4

jemand

mu  te

josef

k.

vbn5,5
verleumdet

haben

    tail pre   x: [jemand1,1, mu  te2,2, np3,4]
    recursion level: 3
    and so on. . .

syntax-based id151

140

parsing for s2t decoding - example

partially-   lled

pchart

vp2,6

np3,4

jemand

mu  te

josef

k.

vbn5,5
verleumdet

haben

l e u m d e t
josef

d
n
a
m
je

v e r

k .

   te

u

m

v

p

np
vbn

haben

mu  te

np

vbn

h

a

b

e

n

    tail pre   x: [jemand1,1, mu  te2,2, np3,4, vbn5,5]
    recursion level: 3
    and so on. . .

syntax-based id151

141

parsing for s2t decoding - example

partially-   lled

pchart

vp2,6

np3,4

jemand

mu  te

josef

k.

vbn5,5
verleumdet

haben

l e u m d e t
josef

d
n
a
m
je

v e r

k .

   te

u

m

v

p

np
vbn

haben

mu  te

np

vbn

h

a

b

e

n

    tail pre   x: [jemand1,1, mu  te2,2, np3,4, vbn5,5, haben6,6]
    recursion level: 4
    and so on. . .

syntax-based id151

142

parsing for s2t decoding - example

partially-   lled

pchart

vp2,6

np3,4

jemand

mu  te

josef

k.

vbn5,5
verleumdet

haben

l e u m d e t
josef

d
n
a
m
je

v e r

k .

   te

u

m

v

p

np
vbn

haben

mu  te

np

vbn

h

a

b

e

n

    tail pre   x: [jemand1,1, mu  te2,2, np3,4, vbn5,5, haben6,6]
    recursion level: 4
    at this point we add a pvertex for each lhs from trie node   s rule group

syntax-based id151

143

parsing for s2t decoding - example

partially-   lled

pchart

s1,6

vp2,6

np3,4

jemand

mu  te

josef

k.

vbn5,5
verleumdet

haben

l e u m d e t
josef

d
n
a
m
je

v e r

k .

   te

u

m

v

p

np
vbn

haben

mu  te

np

vbn

h

a

b

e

n

    tail pre   x: [jemand1,1, mu  te2,2, np3,4, vbn5,5, haben6,6]
    recursion level: 4
    at this point we add a pvertex for each lhs from trie node   s rule group

syntax-based id151

144

parsing for s2t decoding - example

partially-   lled

pchart

s1,6

vp2,6

np3,4

jemand

mu  te

josef

k.

vbn5,5
verleumdet

haben

l e u m d e t
josef

d
n
a
m
je

v e r

k .

   te

u

m

v

p

np
vbn

haben

mu  te

np

vbn

h

a

b

e

n

    tail pre   x: [jemand1,1, mu  te2,2, np3,4, vbn5,5, haben6,6]
    recursion level: 4
    together the pvertex and tail pre   x constitute a complete phyperedge.

syntax-based id151

145

parsing for s2t decoding - example

partially-   lled

pchart

s1,6

vp2,6

np3,4

jemand

mu  te

josef

k.

vbn5,5
verleumdet

haben

l e u m d e t
josef

d
n
a
m
je

v e r

k .

   te

u

m

v

p

np
vbn

haben

mu  te

np

vbn

h

a

b

e

n

    tail pre   x: [jemand1,1, mu  te2,2, np3,4, vbn5,5, haben6,6]
    recursion level: 4
    reached end of sentence, so now the recursion stack unwinds

syntax-based id151

146

parsing for s2t decoding - example

partially-   lled

pchart

s1,6

vp2,6

np3,4

jemand

mu  te

josef

k.

vbn5,5
verleumdet

haben

l e u m d e t
josef

d
n
a
m
je

v e r

k .

   te

u

m

v

p

np
vbn

haben

mu  te

np

vbn

h

a

b

e

n

    tail pre   x: [jemand1,1, mu  te2,2, np3,4, vbn5,5]
    recursion level: 3
    the recursion stack unwinds. . .

syntax-based id151

147

parsing for s2t decoding - example

l e u m d e t
josef

d
n
a
m
je

v e r

k .

   te

u

m

v

p

np
vbn

haben

mu  te

np

vbn

h

a

b

e

n

partially-   lled

pchart

s1,6

vp2,6

np3,4

jemand

mu  te

josef

k.

vbn5,5
verleumdet

haben

    tail pre   x: [jemand1,1, mu  te2,2, np3,4]
    recursion level: 2
    the recursion stack unwinds. . .

syntax-based id151

148

parsing for s2t decoding - example

partially-   lled

pchart

s1,6

vp2,6

np3,4

jemand

mu  te

josef

k.

vbn5,5
verleumdet

haben

l e u m d e t
josef

d
n
a
m
je

v e r

k .

   te

u

m

v

p

np
vbn

haben

mu  te

np

vbn

h

a

b

e

n

    tail pre   x: [jemand1,1, mu  te2,2]
    recursion level: 1
    the parser continues trying to extend the tail. . .

syntax-based id151

149

parsing for s2t decoding - example

partially-   lled

pchart

s1,6

vp2,6

np3,4

jemand

mu  te

josef

k.

vbn5,5
verleumdet

haben

l e u m d e t
josef

d
n
a
m
je

v e r

k .

   te

u

m

v

p

np
vbn

haben

mu  te

np

vbn

h

a

b

e

n

    tail pre   x: [jemand1,1]
    recursion level: 1
    the parser continues trying to extend the tail. . .

syntax-based id151

150

parsing for s2t decoding - example

partially-   lled

pchart

s1,6

vp2,6

np3,4

jemand

mu  te

josef

k.

vbn5,5
verleumdet

haben

l e u m d e t
josef

d
n
a
m
je

v e r

k .

   te

u

m

v

p

np
vbn

haben

mu  te

np

vbn

h

a

b

e

n

    tail pre   x: [jemand1,1, vp2,6]
    recursion level: 1
    pvertex s1,6 has already been added, but new tail means new phyperedge

syntax-based id151

151

decoding performance in practice

)
s
d
n
o
c
e
s
(

i

e
m
t
g
n
d
o
c
e
d

i

max span 25 (exp 1.4)
no span limit (exp 2.4)

250

200

150

100

50

0

0

10

20

40

30
50
sentence length

60

70

80

    s2t moses system trained using all english-german data from wmt14
    span limit can be used to reduce decoding time (limit is typically 10-15 for

hiero; can be higher or unlimited for s2t)

syntax-based id151

152

string-to-tree decoding - summary

    input sentence is a string.
    decoding algorithm based on monolingual parsing.
    hiero decoding is special-case of s2t decoding.
    to integrate a m-gram lm, the parse forest hypergraph is expanded to a

(much-larger) search hypergraph.

    heavy pruning is required in practice.

syntax-based id151

153

tree-to-string decoding

syntax-based id151

154

reminder

    translation rules are stsg rules with source-side syntax

pp-mp
adja
britische

appr
f  r

nn1

as british x1 go

    input is parse tree

top

s-top

pp-mo

vafin

np-sb

ap-pd

appr

adja

nn

ist

pds

nicht besonders schl  upfrig

f  ur

britische

skandale

dieser

punc.

.

syntax-based id151

155

outline

objective

find the k-best synchronous derivations d1, d2, . . . dk

outline

1. project grammar

project weighted stsg to unweighted tsg f : g !
g0

2. match rules

find rules from g0 that match input tree, record in
match hypergraph

3. search

in post-order traversal of match hypergraph, build
partial search hypergraph

4. extract derivations

extract k-best derivations (huang and chiang, 2005)

syntax-based id151

156

step 1: project grammar

r1
np-sb
pis

jemand

r2
np-sb1

s-top
vmfin
mu  te

vp-oc

vp-oc

np-da1

vvpp2

vainf
haben

s-top
vmfin
mu  te

vp-oc

vp-oc

np-da2

vvpp3

r3
np-sb1

s-top
vmfin
mu  te

vp-oc

vp-oc

np-da2

vvpp3

vainf
haben

vainf
haben

someone must have x2 x1

0.53

x1 must have x3 x2

0.61

x2 must have been x3 by x1

0.03

q1
np-sb
pis

jemand

s-top
vmfin
mu  te

vp-oc

vp-oc

np-da

vvpp

vainf
haben

q2
np-sb

s-top
vmfin
mu  te

vp-oc

vp-oc

np-da

vvpp

vainf
haben

    take source-side of rule, ignore weights.

syntax-based id151

157

step 2: match rules, build match hypergraph

np-sb
pis

jemand

s-top

vmfin
mu  te

vp-oc

vp-oc

vvpp

verleumdet

np-da
ne
josef

ne
k.

vainf
haben

    look for rules that match input tree

syntax-based id151

158

step 2: match rules, build match hypergraph

np-sb
pis

jemand

s-top

vmfin
mu  te

vp-oc

vp-oc

vvpp

verleumdet

np-da
ne
josef

ne
k.

vainf
haben

q1

np-sb
pis

jemand

s-top
vmfin
mu  te

vp-oc

vp-oc

np-da

vvpp

vainf
haben

s-top1,4

q1

mu  te

np-da3,4

vvpp5,5

haben

jemand

    for each matching rule, add hyperedge to match hypergraph

syntax-based id151

159

step 2: match rules, build match hypergraph

np-sb
pis

jemand

s-top

vmfin
mu  te

vp-oc

vp-oc

vvpp

verleumdet

np-da
ne
josef

ne
k.

vainf
haben

q2

np-sb

s-top
vmfin
mu  te

vp-oc

vp-oc

np-da

vvpp

vainf
haben

s-top1,4

q1

q2 

mu  te

np-da3,4

vvpp5,5

haben

np-sb1,1
q3
jemand

    match hypergraph encodes forest of possible derivation trees from g0

syntax-based id151

160

step 3: build partial search hypergraph

q1

s-top1,4

jemand

mu  te

np-da3,4

vvpp5,5

haben

d
e
r
e
d
n
a
s
 

l

n
e
e
b
 
2
.
3

d
e
r
e
d
n
a
s
 
5
.
1

l

d
e
m
a

f

e
d
 
7
.
1

d
e
n
g

i
l

a
m

 
6
.
2

2.1

2.7

3.1

3.0

2.5

2.4

3.8

josef k. 1.0
k. 1.3
 he 2.2
and josef k. 2.6

r1

s-top1,4,someone ... k.

jemand
r1

mu  te

np-da3,4,josef k.

vvpp5,5,slandered

haben

s-top1,4,someone,k.

jemand

mu  te

np-da3,4, k.

vvpp5,5,defamed

haben

r4

s-top1,4,josef...someone

jemand

mu  te

np-da3,4, josef k.

vvpp5,5,slandered

haben

    cube pruning algorithm produces shyperedges from mhyperedges
    translations not necessarily constituents (unlike s2t)

syntax-based id151

161

step 3: build partial search hypergraph

np-da3,4

np-da3,4,josef k.

np-da3,4,k.

np-da3,4,he

...

s-top1,6

s1,6,someone ... k.

s1,6,josef ... someone

s1,6,k. ... someone

...

    vertices are stored in stacks, one per input tree node

syntax-based id151

162

the t2s decoding algorithm

1: build match hypergraph by matching grammar rules to input tree
2: for each m-vertex (post-order) do
3:

for all incoming m-hyperedges do

4:

5:

6:

7:

8:

9:

10:

11:

12:

13:

create a cube for it
create    rst s-hyperedge in cube
place cube in queue

end for
for speci   ed number of pops do

pop o    best s-hyperedge of any cube in queue
add it to a bu   er
create its neighbors

end for
recombine s-hyperedges from bu   er and move into stack
sort and prune stack

14:
15: end for

syntax-based id151

163

rule matching by dfa intersection

    rules are encoded as dfas. scheme here is from matthews et al. (2014)
    input tree encoded in same way.
    standard dfa intersection algorithm produces rule match hypergraph.

q1

np-sb
pis

jemand

q2

np-sb

s-top
vmfin
mu  te

vp-oc

vp-oc

np-da

vvpp

vainf
haben

s-top
vmfin
mu  te

vp-oc

vp-oc

np-da

vvpp

vainf
haben

s-top

np-sb

n p-s b

np-sb'

vmfin

vmfin

!

pis'

!

t

e
  
u
m

!

vp-oc2

vp-oc

vp-oc1

vp-oc

vmfin'

np-sb

p
s

i

pis

np-da'

v
v
p
p

jemand

np-da

vvpp'

!

vp-oc2' vainf

vainf

haben

!

s-top'

!

vp-oc1'

syntax-based id151

164

tree-to-string decoding - summary

    input sentence is a parse tree.
    tree constrains rule choice: much smaller search space than s2t
    decoding algorithm based on rule matching with lm integration.
    lm integration identical to s2t.

syntax-based id151

165

a sketch of tree-to-tree decoding

    stsg with tree input.
    t2t decoding is combination of s2t and t2s:

    search state expanded to include target-side category
    rule matching used to select rules; further constrained by target categories
    multiple category-speci   c stacks per input tree node
    lm integration identical to s2t / t2s.

    exact t2t not widely used in practice due to syntactic divergence.

syntax-based id151

166

- introduction
- rule extraction

part i
part ii
part iii - decoding
part iv - extensions

syntax-based id151

167

   fuzzy    syntax

    in a nutshell: move syntax out of grammar and into feature functions

    syntax becomes a soft constraint
    motivated by syntactic divergence problem in tree-to-tree model

pp-mo

appr

adja

nn

f  r

britische

skandale

in

sbar

np

jj

jj

s

nns

as

british

political

scandals

vp

vbp

go

       learning to translate with source and target syntax    (chiang, 2010)

    zhang et al (2011) use fuzzy syntax on source-side of string-to-tree model

and explore alternative feature functions

syntax-based id151

168

   fuzzy    syntax

    parse trees on both sides of training data
    uses hiero rule extraction but with samt-style labelling

pp-mo

appr

adja

nn

f  r

britische

skandale

in

sbar

np

jj

jj

s

nns

as

british

political

scandals

vp

vbp

go

two left-hand side non-terminals

adja+nn | np

britische skandale | british political scandals  

pp-mo | sbar

f  r adja+nn1 | as np1 go  

+ used for adjacent consituents

    only most frequent labelling kept (one-to-one correspondence with hiero rules)

r1
r2

adja+nn | np
pp-mo | sbar

britische skandale | british political scandals  
f  r adja+nn1 | as np1 go  

q1
q2

x
x

britische skandale | british political scandals  
f  r x1 | as x1 go  

syntax-based id151

169

   fuzzy    syntax

    rule labels not used during parsing but retrieved for search
adja+nn | np
1,2,british ... scandals
r1

x1,2

q1 

britische

skandale

britische

skandale

    feature functions score substitutions

    e.g.

if a np is rewritten as a adja+nn on source side then the feature

substs

np!adja+nn    res

    tens of thousands of features
    outperforms exact tree-to-tree (0.4 id7 on zh-en; 1.5 id7 on ar-en)

syntax-based id151

170

forest-to-string

    translation quality of t2s model depends on accuracy of 1-best (or k-best)

parse tree(s) for input sentences

    forest-to-string extends t2s by using (pruned) parse forest as input

vp2,7

vbd2,2

purchased

np3,7

np3,4

pp5,7

dt3,3

nn4,4

in5,5

np6,7

a

house

with

dt6,6

nn7,7

four

rooms

    algorithm is identical to t2s except for rule matching step
       forest-based translation    (mi et al., 2008)

syntax-based id151

171

forest-to-string

    using forest gives better speed-quality trade-o    than using k-best trees

(figure taken from mi et al., 2008)

syntax-based id151

172

tree transformation

    adapting training data for syntax-based mt is active area of research (tree

binarization, label coarsening / re   nement, word alignment edits)

       transforming trees to improve syntactic convergence    (burkett and klein,

2012) proposes tree restructuring method to improve rule extraction:

syntax-based id151

173

(figure taken from burkett and klein, 2012)

tree transformation

    de   nes six classes of transformation

    error-based learning method using ghkm frontier node count as metric
    sequence of transformations learned from subset of training data then applied

to full corpus

    gain of 0.9 id7 over baseline on chinese to english; outperforms simple left

and right binarization

syntax-based id151

174

dependency

a di   erent view on syntax

sid18 phrase structure

syntactic dependency grammar

s

np

vp

np

dt
the

nn
dog

v

chews

dt
a

nn
bone

det

subj

the

dog

chews

obj

det
a

bone

syntax-based id151

175

phrase structure is not enough

s

np

vp

np

dt
the

v

nn
bone chews

dt
a

nn
dog

det

subj

the

bone chews

obj

det
a

dog

syntactically well-formed

semantically implausible

syntax-based id151

176

dependency in sid18

    add head word to constituents

s(chews)

vp(chews)

np(bone)
dt
nn
bone chews
the

v

np(dog)
dt
nn
a
dog

    add mapping of head words to rules

vp(w1) ! v(w1) np(w2)

requires identi   cation of head child

syntax-based id151

177

semantic plausibility

s(chews)

vp(chews)

np(bone)
dt
nn
bone chews
the

v

np(dog)
dt
nn
a
dog

score each lexical relationship

    rule: vp(chews) ! v(chews) np(dogs)

    feature: vp(chews)!v-head(chews) ok
    feature: vp(chews)!np(dog) bad
    rule: s(chews) ! np(bone) vp(chews)
    feature: s(chews)!np(bone) bad
    feature: s(chews)!v-head(chews) ok

syntax-based id151

178

informed by source

    languages with case marking

    di   erent word order
    same dependency relationships

det

obj

den knochen

bone

fri  t
chews

subj

det
der hund
dog

    give preference to translations that preserve dependency relationships

det

subj

the

dog

chews

obj

det
a

bone

syntax-based id151

179

verb frames

s(chews)

vp(chews)

np(bone)
dt
nn
bone chews
the

v

np(dog)
dt
nn
a
dog

    check if full verb frame is properly    lled
    intransitive / transitive / ditransitive
    not just binary relationships
    appropriate type of subjects / objects

    however: tracking verb frame is not trivial

syntax-based id151

180

towards semantics

    di   erent syntax     same verb-noun semantic relationships

    the bone is chewed by the dog.
    the dog chews the bone.
    the bone, the dog chews.
    a dog chewed a bone.

    even more abstract representations

e.g., id15 (amr):

(c / chew-01

:arg0 (d / dog)
:arg1 (b / bone))

    generation of these types of representation open research problem

syntax-based id151

181

string-to-dependency: shen et al. (2008)

    hiero rules but with unlabelled dependencies on target side
    target-side allowed one head to which    oating dependencies can attach

r1

r2

r3

r4

x

x

x

x

x1    og nach x2  

|  

x1

   ew

to

x2

fixed

   og nach x1  

|  

   ew

to

x1

fixed

nach x1

|  

to

x2

floating (left)

   og nach

|  

   ew

to

ill-formed

       a new string-to-dependency machine translation algorithm with a target

dependency language model    (shen et al., 2008)

syntax-based id151

182

string-to-dependency

    decoding algorithm modi   ed to combine dependency structures.
    restriction to well-formed rules reduces grammar size from 140m to 26m rules

(no signi   cant e   ect on translation quality).

    gains of 1.2 id7 on zh-en from addition of dependency lm (markov model

over dependency heads).

syntax-based id151

183

references

    parsing and hypergraphs

dan klein and christopher manning. iwpt 2001.

    what   s in a translation rule?

michel galley, mark hopkins, kevin knight, and daniel marcu. hlt-naacl 2004.

    a hierarchical phrase-based model for id151

david chiang. acl 2005.

    better k-best parsing

liang huang and david chiang. iwpt 2005.

    syntax augmented machine translation via chart parsing

andreas zollmann and ashish venugopal. wmt 2006.
    synchronous binarization for machine translation

hao zhang, liang huang, daniel gildea, and kevin knight. naacl 2006.

    hierarchical phrase-based translation

david chiang. computational linguistics 2007.

syntax-based id151

184

references

    a new string-to-dependency machine translation algorithm with a target dependency

language model
libin shen, jinxi xu, and ralph weischedel. acl 2008.

    forest-based translation

haitao mi, liang huang, and qun liu. acl 2008.

    e cient parsing for transducer grammars

john denero, mohit bansal, adam pauls, and dan klein. naacl 2009.

    sid18 decoding without binarization

mark hopkins and greg langmead. emnlp 2010.

    learning to translate with source and target syntax

david chiang, acl 2010.

    issues concerning decoding with synchronous context-free grammar

tagyoung chung, licheng fang, and daniel gildea. acl 2011.

    transforming trees to improve syntactic convergence

david burkett and dan klein. emnlp 2012.

syntax-based id151

185

references

    grouping language model boundary words to speed k-best extraction from hypergraphs

kenneth hea   eld, philipp koehn, and alon lavie. naacl 2013.

    tree transduction tools for cdec

austin matthews, paul baltescu, phil blunsom, alon lavie, chris dyer. pbml vol 102.
(2014)

    a cyk+ variant for sid18 decoding without a dot chart

rico sennrich. ssst 2014.

syntax-based id151

186

