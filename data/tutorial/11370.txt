the parallel meaning bank: towards a multilingual corpus of

translations annotated with compositional meaning representations

lasha abzianidze1, johannes bjerva1, kilian evang1, hessel haagsma1,
rik van noord1, pierre ludmann2, duc-duy nguyen3 and johan bos1

1clcg, university of groningen, the netherlands

2   ecole normale sup  erieure de cachan, france

{l.abzianidze,j.bjerva,k.evang}@rug.nl

{hessel.haagsma,r.i.k.van.noord,johan.bos}@rug.nl

3university of trento, italy

7
1
0
2

 

b
e
f
3
1

 

 
 
]
l
c
.
s
c
[
 
 

1
v
4
6
9
3
0

.

2
0
7
1
:
v
i
x
r
a

pierre.ludmann@ens-cachan.fr

ducduy.nguyen@studenti.unitn.it

abstract

the parallel meaning bank is a cor-
pus of translations annotated with shared,
formal meaning representations compris-
ing over 11 million words divided over
four languages (english, german, ital-
ian, and dutch). our approach is based
on cross-lingual projection: automatically
produced (and manually corrected) se-
mantic annotations for english sentences
are mapped onto their word-aligned trans-
lations, assuming that the translations are
meaning-preserving. the semantic anno-
tation consists of    ve main steps: (i) seg-
mentation of the text in sentences and lexi-
cal items; (ii) syntactic parsing with com-
binatory categorial grammar; (iii) uni-
versal semantic tagging; (iv) symboliza-
tion; and (v) compositional semantic anal-
ysis based on discourse representation
theory. these steps are performed us-
ing statistical models trained in a semi-
supervised manner. the employed annota-
tion models are all language-neutral. our
   rst results are promising.
introduction

1
there is no reason to believe that the ingredi-
ents of a meaning representation for one language
should be different from that for another language.
hence, a meaning-preserving translation from a
sentence to another language should, arguably,
have equivalent meaning representations. hence,
given a parallel corpus with at least one language
for which one can automatically generate mean-
ing representations with suf   cient accuracy, indi-
rectly one also produces meaning representations

for aligned sentences in other languages. the aim
of this paper is to present a method that imple-
ments this idea in practice, by building a paral-
lel corpus with shared formal meaning representa-
tions, that is, the parallel meaning bank (pmb).

recently, several semantic resources   corpora
of texts annotated with meanings   have been de-
veloped to stimulate and evaluate semantic pars-
ing. usually, such resources are manually or semi-
automatically created, and this process is expen-
sive since it requires training of and annotation
by human annotators. the amr banks of ab-
stract meaning representations for english (ba-
narescu et al., 2013) or chinese and czech (xue
et al., 2014) sentences, for instance, are the result
of manual annotation efforts. another example is
the development of the groningen meaning bank
(bos et al., 2017), a corpus of english texts an-
notated with formal, compositional meaning rep-
resentations, which took advantage of existing se-
mantic parsing tools, combining them with human
corrections.

in this paper we propose a method for pro-
ducing meaning banks for several languages (en-
glish, dutch, german and italian), by taking ad-
vantage of translations. on the conceptual level
we follow the approach of the groningen mean-
ing bank project (basile et al., 2012), and use
some of the tools developed in it. the main rea-
son for this choice is that we are not only inter-
ested in the    nal meaning of a sentence, but also
in how it is derived   the id152.
these derivations, based on combinatory catego-
rial grammar (id35, steedman, 2001), give us the
means to project semantic information from one
sentence to its translated counterpart.

the goal of the pmb is threefold. first, it will

figure 1: annotation pipeline of the pmb. manual corrections can be added at each annotation layer.

serve as a test bed for cross-lingual compositional
semantics, enabling systematic studies of the chal-
lenges arising from loose translations and differ-
ent semantic granularities. the second goal is to
produce data for building semantic parsers for lan-
guages other than english. this, in turn, will help
with the third, long-term goal, which concerns the
process of translation itself. human translators
purposely change meaning in translation to yield
better translations (langeveld, 1986). the third
goal is thus to develop methods to automatically
detect such shifts in meaning.

2 languages and corpora

the foundation of the pmb is a large set of raw,
parallel texts. ideally, each text has a parallel ver-
sion in every language of the meaning bank, but in
practice, having a version for the pivot language
(here: english) and one other language is suf   -
cient for our purposes. another criterion for selec-
tion is that freely distributable texts are preferable
over texts which are under copyright and require
(paid) licensing.

besides english we chose two other germanic
languages, dutch and german, because they are
similar to english. we also include one romance
language, italian,
in order to test whether our
method works for languages which are typologi-
cally more different from english.

the texts in the pmb are sourced from twelve
different corpora from a wide range of gen-
res, including, among others: tatoeba1, news-
commentary (via opus, tiedemann, 2012), rec-
ognizing id123 (giampiccolo et al.,
2007), sherlock holmes stories2, and the bible
(christodouloupoulos and steedman, 2015).

these corpora are divided over 100 parts in a
balanced way. initially, two of these parts, 00 and

1https://tatoeba.org
2http://gutenberg.org,

http://etc.usf.

edu/lit2go, http://gutenberg.spiegel.de

10, are selected to be the gold standard (and thus
will be manually annotated). this ensures that the
gold standard represents the full range of genres.
the resulting corpus contains over 11.3 million
tokens, divided into 285,154 documents. all of
them have an english version. 72% have a german
version, 14% a dutch one and 42% an italian one.
9% have german and dutch, 6% have dutch and
italian and 18% have italian and german. 5% exist
in all four languages.

3 automatic annotation pipeline

our goal is    rst to richly annotate the english cor-
pus, with annotations ranging from segmentation
to deep semantics, and then project these annota-
tions to the other languages via alignment. the an-
notation consists of several layers, each of which
will be presented in detail below. figure 1 gives
an overview of the pipeline while figure 2 shows
the annotation example.

3.1 segmentation

text segmentation involves word and sentence
boundary detection. multiword expressions that
represent constituents are treated as single tokens.
closed compound words that have a semantically
transparent structure are decomposed. for exam-
ple, impossible is decomposed into im and possi-
ble while las vegas and 2 pm are analysed as a
single token. in this way we aim to assign    atomic   
meanings to tokens and avoid redundant lexical se-
mantics. segmentation follows an iob-annotation
scheme on the level of characters, with four labels:
beginning of sentence, beginning of word, inside a
word, and outside a word. we use the same sta-
tistical tokenizer, elephant (evang et al., 2013),
for all four languages, but with language-speci   c
models.

s\np
kam

came
eps
come
s\np

np
er

he
pro
male
np

    px

  p.d
=

x
male(x)

((s\np )\(s\np ))/np

um

n

f  unf uhr

(s\np )\(s\np )

zur  uck

back
ist
back

(s\np )\(s\np )

at
rel
at

((s\np )\(s\np ))/np

  gp.g(  x.d
=

; pe)

  v gp.v g(  x.d
=

; px)

  gvhp.v h(  x.g(  y.d
=

; px))

e t1 t2
come(e)
t heme(e, x)
t ime(e, t2)
now(t1)

t2 < t1

s\np

s
m anner(x, s)
back(s)

<

s\np

s

   
dis   

np/n

; (px; qx)

  pq.d
=
x

5 o   clock

clo
17 : 00

n

  x.d
=

at(x, y)

(s\np )\(s\np )

time(x)
value(x, 17 : 00)
>

np

>

<
<

x y e s t1 t2

come(e)
now(t1)

t ime(e, t2)

t heme(e, x) m anner(e, s)

t2 < t1

male(x)

back(s)

at(e, y)
time(y)
value(y, 17 : 00)

figure 2: document 00/3178: projection of the annotation from english to german. the source sentence
is annotated, in this order, with semtags, symbols, id35 categories and lexical semantics. the drs for
the whole sentence is obtained compositionally from the lexical drss.

3.2 syntactic analysis
we use id35-based derivations for syntactic anal-
ysis. the transparent syntax-semantic interface
of id35 makes the derivations suitable for wide-
coverage id152 (bos et al.,
2004).
id35 is also a lexicalised theory of
grammar, which makes cross-lingual projection
of grammatical information from source to target
sentence more convenient (see section 4).

the version of id35 that we employ differs
from standard id35: in order to facilitate the cross-
lingual projection process and retain composition-
ality, type-changing rules of a id35 parser are
explicated by inserting (unprojected) empty ele-
ments which have their own semantics (see the to-
ken     in figure 2).

for parsing, we use easyid35 (lewis and
steedman, 2014), which was chosen because it
is accurate, does not require part-of-speech anno-
tation (which would require different annotation
schemes for each language) and is easily adaptable
to our modi   ed grammar formalism.

3.3 universal semantic tagging
to facilitate the organization of a wide-coverage
semantic lexicon for cross-lingual semantic analy-
ses, we develop a universal semantic tagset. the
semantic tags (semtags, for short) are language-
neutral, generalise over part-of-speech and named
entity classes, and also add more speci   c infor-
mation when needed from a semantic perspective.

given a id35 category of a token, we specify a
general schema for its lexical semantics by tagging
the token with a semtag.

currently the tagset comprises 80 different    ne-
grained semtags divided into 13 coarse-grained
classes (bjerva et al., 2016). we do not list all
possible semtags here, but give some examples in-
stead. for instance, the semtag not marks nega-
tion triggers, e.g., not, no, without and af   xes, e.g.,
im- in impossible; the semtag pos is assigned to
possibility modals, e.g., might, perhaps and can.
rol identi   es roles and professions, e.g., boxer
and semanticist, while con is for concepts like ta-
ble and wheel. distinguishing roles from concepts
is crucial to get accurate semantic behaviour. 3

we use the semantic tagger based on deep resid-
ual networks. it works directly on the words as in-
put, and therefore requires no additional language-
speci   c features. the    rst results on semantic tag-
ging, with an accuracy of 83.6%, are reported by
bjerva et al. (2016).

3.4 symbolization
the meaning representations that we use contain
logical symbols and non-logical symbols. the lat-
ter are based on the words mentioned in the input
text. we refer to this process as symbolization. it
combines lemmatization with id172, and

3roles are mostly consistent with each other while con-
cepts are not. for instance, an entity can be a boxer and a
semanticist at the same time but not a wheel and a table.

performs some lexical disambiguation as well. for
example, male is the symbol of the pronouns he
and himself, europe of the adjective european,
and 14 : 00 for the time expression 2 pm. a sym-
bol together with a id35 category and a semtag
are suf   cient to determine the lexical semantics
of a token (see figure 2). some function words
do not need symbols since their semantics are ex-
pressed with logical symbols, e.g., auxiliary verbs,
conjunctions, and most determiners.

notice that the employed symbols are not as
radical and verbalized as the concepts in amrs,
e.g., the symbol of opinion is opinion rather than
opine. first, using deep forms as symbols often
makes it dif   cult to recover the original and se-
mantically related forms, e.g., if opinion had the
symbol opine, then it would be dif   cult to re-
cover opinion and its semantic relation with idea.
second, alignment of translations does not al-
ways work well with deep forms, e.g., opinion can
be translated as parere in italian and mening in
dutch, but it is unnatural to align their symbols to
opine. after all, having such alignments would
make it dif   cult to judge good and bad transla-
tions, which is one of the goals of the pmb.

the symbolizer could either be implemented
as a rule-based system with multiple modules, or
as a system that learns the required transforma-
tions from examples. the advantage of the lat-
ter is that it is more robust to typos and other
spelling variants without manual engineering. to
evaluate the feasibility of this approach, we built a
character-based sequence-to-sequence model with
deep recurrent neural networks, which uses words,
semtags, and additional data from existing knowl-
edge sources, such as id138 (fellbaum, 1998),
wikipedia, and unece codes for trade4, to do
symbolization. we are currently investigating how
the performance of machine learning-based sym-
bolizer compares to a rule-based one incorporating
the lemmatizer morpha (minnen et al., 2001).

3.5 semantic interpretation
discourse representation theory (drt, kamp
and reyle, 1993), is the semantic formalism that
is used as a semantic representation in the pmb. it
is a well-studied theory from a linguistic seman-
tic viewpoint and suitable for compositional se-
mantics.5 expressions in drt, called discourse
4http://unece.org/cefact/codesfortrade
5in particular, we employ projective drt (venhuizen,
2015)   an extension of drt that accounts for presupposi-

representation structures (drss), have a recur-
sive structure and are usually depicted as boxes.
an upper part of a drs contains a set of referents
while the lower part lists a conjunction of atomic
or compound conditions over these referents (see
an example of a drs in the bottom of figure 2).

boxer (bos, 2015), a system that employs
  -calculus to construct drss in a compositional
way, is used to derive meaning representations
of the documents. however,
the original ver-
sion of boxer is tailored to the english language.
we have adapted boxer to work with the univer-
sal semtags rather than english-speci   c part-of-
speech tags. boxer also assigns verbnet/lirics
thematic roles (bonial et al., 2011) to verbs so
that the lexical semantics of verbs include the cor-
responding thematic predicates (see came in fig-
ure 2).

hence an input to boxer is a id35 derivation
where all tokens are decorated with semtags and
symbols. this information is enough for boxer to
assign a lexical drs to each token and produce a
drs for the entire sentence in a compositional and
language-neutral way (see figure 2).

4 cross-lingual projection

the initial annotation for dutch, german and ital-
ian is bootstrapped via word alignments. each
non-english text is automatically word-aligned
with its english counterpart, and non-english
words initially receive semtags, id35 categories
and symbols based on those of their english coun-
terparts (see figure 2).

id35 slashes are    ipped as needed, and 2:1
alignments are handled through functional com-
position. then, the id35 derivations and drss
can be obtained by applying id35   s combinatory
rules in such a way that the same drs as for the
english sentence results (evang and bos, 2016;
evang, 2016).

if the alignment is incorrect, it can be corrected
manually (see section 5). the idea behind this
way of id64 is to exploit the advanced
state-of-the-art of nlp for english, and to encour-
age parallelism between the syntactic and seman-
tic analyses of different languages.

to facilitate cross-lingual projection, alignment
has to be done at two levels: sentences and words.
sentence alignment is initially done with a simple

tions, anaphora and conventional implicatures in a general-
ized way.

one-to-one heuristic, with each english sentence
aligned to a non-english sentence in order, to be
corrected manually. subsequently, we automati-
cally align words in the aligned sentences using
giza++ (och and ney, 2003).

although we use existing tools for the initial an-
notation of english and projection as the initial an-
notation of non-english documents, our aim is to
train new language-neutral models. training new
models on just the automatic annotation will not
yield better performance than the combination of
existing tools and projection. however, we im-
prove these models constantly by adding manual
corrections to the initial automatic annotation, and
retraining them. in addition, this approach lets us
adapt to revisions of the annotation guidelines.
5 adding bits of wisdom
for each annotation layer, manual corrections can
be applied to any of the four languages. these an-
notations are called bits of wisdom (bows, fol-
lowing basile et al. (2012)), and they overrule
the annotations of the models if they are in con-
   ict. based on the bows, we distinguish three
disjoint classes of annotation layers: gold standard
(manually checked), silver standard (including at
least one bow) and bronze standard (no bows).
table 1 shows how these classes are distributed
across languages and documents.

layer

tokens

semtags
symbols

en
de
it
nl

lang gold
6,810
4,757
2,843
945
316
313

en

en

silver bronze
275,796
2,548
198,776
736
384
117,792
528
38,942
267,359
17,479
1,177
283,664

table 1: number of gold, silver and bronze doc-
uments per layer and language, as of 13-02-2017.

in addition to adding bows in general, we also
use annotations to improve the models in a more
targeted way, by focusing on annotation con   icts.
annotation con   icts arise when a certain annota-
tion layer for a document has manually checked
and marked    gold   . when the automatic annota-
tion of such a layer changes, e.g., after retraining a
model, new annotation errors might be introduced,
and these are marked as annotation con   icts. the

annotation con   icts are then slated for resolution
by an expert annotator. this has two main ben-
e   ts: it concentrates human annotation efforts on
dif   cult cases, for which the models    judgements
are still in    ux, so that the bits of wisdom can steer
the model more effectively.
in addition, by en-
forcing con   icts to be re-judged by a human, we
have a chance to correct human errors and incon-
sistencies, and, if necessary, improve the annota-
tion guidelines.

6 conclusion
our ultimate goal is to provide accurate, language-
neutral natural language analysis tools.
in the
pipeline that we presented in this paper, we
have laid the foundation to reach this goal. for
every task in the pipeline   id121, pars-
ing, semantic tagging, symbolization, semantic
interpretation   we have a single component that
uses a language-speci   c model. we proposed new
language-neutral tagging schemes to reach this
goal (e.g., for id121 and semantic tagging)
and adapted existing formalisms (making id35
more general by introducing lexical categories for
empty elements).

our    rst results for dutch show that our method
is promising (evang and bos, 2016), but we still
need to assess how much manual effort is involved
in other languages, such as german and italian.
we will also explore the idea of combining id35
parsing with semantic role labelling, following
lewis et al. (2015), and whether we can derive
word senses in a data-driven fashion (kilgarriff,
1997) rather than using id138. furthermore,
we will assess whether our cross-lingual projec-
tion method yields accurate tools with time and
annotation costs lower than would be needed when
starting from scratch for a single language.

the annotated data of the pmb is now publicly
accessible through a web interface.6 stable re-
leases will be made available for download peri-
odically.

acknowledgements
this work was funded by the nwo-vici grant
   lost in translation     found in meaning    (288-
89-003). the tesla k40 gpu used for this re-
search was donated by the nvidia corporation.
we also wish to thank the two anonymous review-
ers for their comments.

6http://pmb.let.rug.nl

references
laura banarescu, claire bonial, shu cai, madalina
georgescu, kira grif   tt, ulf hermjakob, kevin
knight, philipp koehn, martha palmer, and nathan
schneider. 2013. id15
for sembanking. in proceedings of the 7th linguis-
tic annotation workshop and interoperability with
discourse, pages 178   186, so   a, bulgaria.

2012.

valerio basile, johan bos, kilian evang, and noortje
a platform for collabora-
venhuizen.
in proceedings of the
tive semantic annotation.
demonstrations at the 13th conference of the euro-
pean chapter of the association for computational
linguistics (eacl 2012), pages 92   96, avignon,
france.

johannes bjerva, barbara plank, and johan bos. 2016.
semantic tagging with deep residual networks.
in
proceedings of coling 2016, the 26th interna-
tional conference on computational linguistics:
technical papers, pages 3531   3541, osaka, japan.

claire bonial, william j. corvey, martha palmer,
volha petukhova, and harry bunt. 2011. a hierar-
chical uni   cation of lirics and verbnet semantic
roles. in proceedings of the 5th ieee international
conference on semantic computing (icsc 2011),
pages 483   489.

johan bos, stephen clark, mark steedman, james r.
curran, and julia hockenmaier.
2004. wide-
coverage semantic representations from a id35
in proceedings of the 20th international
parser.
conference on computational linguistics (coling
2004), pages 1240   1246, geneva, switzerland.

johan bos, valerio basile, kilian evang, noortje ven-
huizen, and johannes bjerva. 2017. the gronin-
gen meaning bank. in nancy ide and james puste-
jovsky, editors, handbook of linguistic annotation.
springer netherlands.

johan bos. 2015. open-domain id29 with
boxer. in be  ata megyesi, editor, proceedings of the
20th nordic conference of computational linguis-
tics (nodalida 2015), pages 301   304.

christos christodouloupoulos and mark steedman.
2015. a massively parallel corpus:
the bible in
100 languages. language resources and evalua-
tion, 49(2):375   395.

kilian evang and johan bos. 2016. cross-lingual
learning of an open-domain semantic parser. in pro-
ceedings of coling 2016, the 26th international
conference on computational linguistics: techni-
cal papers, pages 579   588, osaka, japan.

kilian evang, valerio basile, grzegorz chrupa  a, and
johan bos. 2013. elephant: sequence labeling for
word and sentence segmentation. in proceedings of
the 2013 conference on empirical methods in nat-
ural language processing (emnlp), pages 1422   
1426, seattle, washington, usa.

kilian evang. 2016. cross-lingual id29
with categorial grammars. ph.d. thesis, university
of groningen.

christiane fellbaum, editor. 1998. id138. an elec-
tronic lexical database. the mit press, cam-
bridge, ma., usa.

danilo giampiccolo, bernardo magnini, ido dagan,
and bill dolan. 2007. the third pascal recog-
in proceed-
nizing id123 challenge.
ings of the acl-pascal workshop on textual en-
tailment and id141, pages 1   9.

hans kamp and uwe reyle. 1993. from discourse
to logic; an introduction to modeltheoretic seman-
tics of natural language, formal logic and drt.
kluwer, dordrecht.

adam kilgarriff.

   i don   t believe in word
senses   . computers and the humanities, 31(2):91   
113.

1997.

arthur langeveld. 1986. vertalen wat er staat. syn-

these, de arbeiderspers.

mike lewis and mark steedman. 2014. a* id35
parsing with a supertag-factored model. in proceed-
ings of the 2014 conference on empirical methods
in natural language processing (emnlp), pages
990   1000, doha, qatar.

mike lewis, luheng he, and luke zettlemoyer. 2015.
joint a* id35 parsing and semantic role label-
in proceedings of the 2015 conference on
ing.
empirical methods in natural language processing
(emnlp), pages 1444   1454.

guido minnen, john carroll, and darren pearce. 2001.
applied morphological processing of english. nat-
ural language engineering, 7(3):207   223.

franz josef och and hermann ney. 2003. a sys-
tematic comparison of various statistical alignment
models. computational linguistics, 29(1):19   51.

mark steedman. 2001. the syntactic process. the

mit press, cambridge, ma., usa.

j  org tiedemann. 2012. parallel data, tools and in-
terfaces in opus. in proceedings of the eight in-
ternational conference on language resources and
evaluation (lrec 2012), pages 2214   2218, istan-
bul, turkey.

noortje joost venhuizen. 2015. projection in dis-
course: a data-driven formal semantic analysis.
ph.d. thesis, university of groningen.

nianwen xue, ondrej bojar, jan hajic, martha palmer,
zdenka uresova, and xiuhong zhang. 2014. not
an interlingua, but close: comparison of english
in proceedings of
amrs to chinese and czech.
the ninth international conference on language re-
sources and evaluation (lrec 2014), volume 14,
pages 1765   1772.

