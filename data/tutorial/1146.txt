semantic similarity frontiers: 
 from concepts to documents

david jurgens

stanford university

mohammad taher pilehvar

sapienza university of rome

erc grant 259234


semantic similarity   s 

key question: 

 how similar are two 

linguistic items?

how similar are two sentences?

the boss    red the worker 

the boss    red the employee

the supervisor let the employee go

the supervisor reprimanded the 

worker

the boss promoted the worker


how similar are two sentences?

the boss    red the worker 

the boss    red the employee

the supervisor let the employee go

the supervisor reprimanded the 

worker

the boss promoted the worker


how similar are two sentences?

the boss    red the worker 

the boss    red the employee

very similar 

the supervisor let the employee go

very similar

the supervisor reprimanded the 

somewhat 

worker

   similar

the boss promoted the worker

related





don   t we already have 

 solutions for semantic similarity?

lots of work on all types of text 

and concept input

allison and dix (1986)

gus   eld (1997)

wise (1996)

keselj et al. (2003)

50+ approaches from 

semeval 

2012, 2013, 2014

sussna (1993, 1997)
wu and palmer (1994)

resnik (1995)

jiang and conrath (1997)

lin (1998)

hirst and st-onge (1998)

leacock and chodorow (1998)

salton and mcgill (1983)

patwardan (2003)

landauer et al. (1998)

banerjee and pederson (2003)

turney (2007)

gabrilovich and markovitch (2007)

we refer to these as 
linguistic levels

ramage et al. (2009)

yeh et al. (2009)

radinsky et al. (2011)

sentence 


 


    word 


           sense


lots of work on all types of text 

and concept input

not	
   to	
   men(on	
   	
   
word	
   embeddings...	
   

allison and dix (1986)

gus   eld (1997)

wise (1996)

keselj et al. (2003)

50+ approaches from 

semeval 

2012, 2013, 2014

sussna (1993, 1997)
wu and palmer (1994)

resnik (1995)

jiang and conrath (1997)

lin (1998)

hirst and st-onge (1998)

leacock and chodorow (1998)

salton and mcgill (1983)

patwardan (2003)

landauer et al. (1998)

banerjee and pederson (2003)

turney (2007)

gabrilovich and markovitch (2007)

we refer to these as 
linguistic levels

ramage et al. (2009)

yeh et al. (2009)

radinsky et al. (2011)

sentence 


 


    word 


           sense


why do we have so many 

similarity methods?!
      new resources or machine learning 
methods become available
      ~20 embeddings papers at emnlp alone
      new datasets reveal weaknesses in 
plication-speci   c similarity functions


why do we have so many 

similarity methods?!
      new resources or machine learning 
methods become available
      ~20 embeddings papers at emnlp alone
      new datasets reveal weaknesses in 
previous methods
      soa is a moving target

      need to adapt for new types of input or 
domains
      microtext, biomedical, multilingual
      application-speci   c similarity functions


why do we have so many 

similarity methods?!
      new resources or machine learning 
methods become available
      ~20 embeddings papers at emnlp alone
      new datasets reveal weaknesses in 
previous methods
      soa is a moving target

      need to adapt for new types of input or 
domains
      microtext, biomedical, multilingual
      application-speci   c similarity functions


why do we have so many 

similarity methods?!
      new resources or machine learning 
methods become available
      ~20 embeddings papers at emnlp alone
      new datasets reveal weaknesses in 
previous methods
      soa is a moving target

      need to adapt for new types of input or 
domains
      microtext, biomedical, multilingual
      application-speci   c similarity functions


do we still need more methods?
      semantic similarity itself is not an end-task, 
but rather a component
      applications can select the similarity method 
that yields the best performance. 

      performance on new benchmarks is still not 
satisfactory
      low hanging similarity fruit is solved, but many 
challenging cases still remain


tutorial objectives

       make sense of current semantic similarity 
state of the art!
      formulate tasks and required resources
      standard and state-of-the-art algorithms
      current id74 
       provide practical knowledge

      what open source tools and data are available 
      what are the current open problems 

       target audience: we assume no knowledge of 
any machine learning or lexical semantics
      stop us to ask questions at any time!



tutorial objectives

       make sense of current semantic similarity 
state of the art!
      formulate tasks and required resources
      standard and state-of-the-art algorithms
      current id74 
       provide practical knowledge

      what open source tools and data are available 
      what are the current open problems 

       target audience: we assume no knowledge of 
any machine learning or lexical semantics
      stop us to ask questions at any time!



tutorial objectives

       make sense of current semantic similarity 
state of the art!
      formulate tasks and required resources
      standard and state-of-the-art algorithms
      current id74 
       provide practical knowledge

      what open source tools and data are available 
      what are the current open problems 

       target audience: we assume no knowledge of 
any machine learning or lexical semantics
      stop us to ask questions at any time!



tutorial non-objectives

       provide gory details of methodologies

      we focus more on the landscape and knowing 
which methods matter
      but feel free to ask questions on details if 
interested! 

       covering all work on a similarity task

      course materials provide an extended bibliography
      we focus on the most exciting ideas (to us)

you should leave feeling comfortable knowing 

what papers to read next, why, and roughly 

what they   re about!


quick outline of the morning
      foundations in semantic similarity
      concepts, terminology, and examples
      state of the art overviews

      similarity when comparing concepts, words, 
phrases, sentences, paragraphs, or documents
      cross-level semantic similarity

      open source tools and resources
      current challenges and future work

quick outline of the morning
      foundations in semantic similarity
      concepts, terminology, and examples
      state of the art overviews

      similarity when comparing concepts, words, 
phrases, sentences, paragraphs, or documents
      cross-level semantic similarity

      open source tools and resources
      current challenges and future work

coffee break happens in here! 
10:30 - 11:00

foundations

semantic similarity can be 

de   ned on many linguistic levels
       word senses (concepts)
       words
       phrases
       sentences
       paragraphs
       documents

for the most part, different 

algorithms are used for each kind of 

item being compared.

similarity is graded

car vs. automobile -> 1.0
car vs. vehicle -> 0.6
car vs. tire -> 0.2
car vs. street -> 0.1

similarity has psychological 

quirks

      nontransitive
      cuba vs. jamaica
      cuba vs. china
      jamaica vs. china 

      asymmetric

      north korea vs. china
      china vs. north korea
these are ignored by nearly all approaches, 
but see gawron (2014)


similarity vs. relatedness

similarity is a speci   c type of relatedness

       similarity: synonyms and hyponyms/hyperonyms, and 

siblings are highly similar
       doctor vs. surgeon, bike vs. bicycle

       related: topically related or based on any other 

semantic relation
       heart vs. surgeon, tyre vs. car




relational similarity

       the degree of correspondence between two 

relations:
      
      


 linux     grep

 windows        ndstr

      
      


 france     paris

- rome

 italy

       semeval-2012 task 2: measuring degrees 

of relational similarity (jurgens et al)

desiderata for a  

semantic similarity method 

      consistently interpretable similarity scores 
with explanations of why similar 

      works well for different types of text 
 (news, web, social media,    ) 

      applicable to multiple linguistic types 
 (words, phrases sentences) 





typically, two main resources for 

measuring similarity

massive corpora of 

text documents

typically, two main resources for 

measuring similarity

massive corpora of 

text documents

semantic resources 
and knowledge bases

many methods represent semantics 
using a vector space model (vsm)

vector spaces provide a machine-interpretable 

or mathematical format

pizza

restaurant

bank



vector space models

       simple representation based on id202
       easy comparison of different items based on a 

continuous scale of similarity

       supported by studies in cognitive science
       flexible way of adjusting the degree of 

complication through setting the number of 
dimensions




vector space models

explicit
       individual dimensions denote speci   c linguistic 
       usually higher in dimension
       the vector is interpretable

items, e.g., words

continuous
       dimensions do not correspond to explicit 

concepts

       usually lower in dimension




vector space models

vector comparison techniques

kullback   leibler (kl) divergence

jensen   shannon (js) divergence






vector space models

vector comparison techniques

cosine distance








vector space models

vector comparison techniques

tanimoto similarity (1957)








vector space models
rank-based vector comparison techniques

rank-biased overlap (rbo)

the set of overlapping 
dimensions between the 

top-d elements

a parameter that 

determines the relative 
importance of the top 

elements.








vector space models
rank-based vector comparison techniques

weighted overlap






semantic similarity: 

state of the art

many approaches incorporate 
techniques from more speci   c 

linguistic levels

start here and 
work our way to 
bigger ideas!

      word senses (concepts)
      words
      phrases
      sentences
      paragraphs
      documents

semantic similarity

between word senses

concepts vs. senses

a id138 synset (concept):

the middle of the day

noon, twelve noon
 high noon, midday
 noonday, noontide

(noon#n#1)	
   



applications - general

       lowest (most    ne-grained) level of semantic 

similarity: can be extended to applications 
that require higher levels of similarity

mt evaluation, paraphrases recognition, textual 

entailment, information retrieval, id53, 

text summarization, lexical substitution or 

simpli   cation, id183



applications - speci   c

wsd

install the updated application
-   
software application?
-    application for a job?
-    practical usage?

        coarsening 


       


  alignment








sense similarity techniques

       tied to sense inventories

       graph distance-based

       id138-based
       thesauri-based
       dictionary-based


       explicit sense representation

       simple gloss-based
       random walk-based
       distributional

       not tied to sense inventories




sense similarity techniques

tied to sense inventories: graph distance

id138 as a graph

sense similarity techniques

tied to sense inventories: id138 graph distance

sense similarity techniques

tied to sense inventories: id138 graph distance

len(c1,c2)

sense similarity techniques

tied to sense inventories: id138 graph distance

dept(c1)

sense similarity techniques

tied to sense inventories: id138 graph distance

lso(c1,c2)

sense similarity techniques

tied to sense inventories: id138 graph distance

conventional id138-based techniques

survey: budanitsky and hirst (2006)

       id138 structure only

hirst and st-onge (1998)
sussna   s depth-relative scaling (1993, 1997)
wu and palmer (1994)
leacock and chodorow   s (1998)

       combined with statistics from corpora

jiang and conrath   s measure (1997)
resnik (1995)
lin   s measure (1998)





sense similarity techniques

tied to sense inventories: thesauri-based

roget   s thesaurus: morris and hirst (1991), jarmasz and szpakowicz (2003)

sense similarity techniques

tied to sense inventories: dictionary-based

longman dictionary (ldoce): kozima and furugori (1993),  kozima and ito (1997)
-    constructs a semantic network from a subset of the 

dictionary, 2851 nodes, called paradigme

-    computes similarity by spreading the activation in the 

network






sense similarity techniques

tied to sense inventories

explicit semantic representation

sense similarity techniques

tied to sense inventories: explicit semantic representation

simple gloss-based: exploiting id138   s content

 application#n#2 -- 

a verbal or written request for assistance or employment or admission to a school

application#n#4 -- 

a program that gives a computer instructions that provide the user with tools to accomplish a 
task

example:

meerkat ma   a - kashyap et al (2014)
@ semeval-2014 task-3: clss





sense similarity techniques

tied to sense inventories: explicit semantic representation

id93 on semantic networks
the personalized id95 algorithm
semantic similarity: pilehvar et al (2013)
wsd: agirre et al (cl 2014)

sense similarity techniques

tied to sense inventories: explicit semantic representation

distributional
sensembed - id97 sense embeddings
iacobacci et al (2015)

+	
   


sense similarity techniques

tied to sense inventories: explicit semantic representation

distributional
nasari and muffin - camacho-collados et al (2015) 


sense similarity techniques

tied to sense inventories: explicit semantic representation

distributional
chen et al (emnlp 2014)

joint word sense representation and disambiguation

       learn word representations (id97 skip-gram)
       use them for sense representation (average gloss)
       automatically disambiguate large amounts of text
       modify the objective of skip-gram to learn sense 

representations










sense similarity techniques

tied to sense inventories: explicit semantic representation

distributional
rothe and schutze (acl 2015)

extends id27s (id97) to embeddings of other data types: 
id138 synsets and word senses

       constructs an auto-encoder
       learns these representations based on id138 constraints 
(word/synset is the summation of its lexemes + wn relations)







sense similarity techniques

not tied to sense inventories


also called 

multi-prototype or topic-based representations

usually based on id91



















sense similarity techniques

not tied to sense inventories

reisinger and mooney (2010)

sense similarity techniques

not tied to sense inventories

reisinger and mooney (2010)

measuring similarity - isolated words:


sense similarity techniques

not tied to sense inventories

reisinger and mooney (2010)

measuring similarity - words in contexts:

likelihood	
   of	
   the	
   cluster	
   given	
   the	
   
context	
   


sense similarity techniques

not tied to sense inventories

huang et al (2012)
-    learns id27s with local and global objectives
-    then clusters the contexts of a word and learns multi-prototype 

representations



sense similarity techniques

not tied to sense inventories

neelakantan et al (emnlp 2014)

multi-sense skip-gram (mssg) model


(   xed number of senses)
sense discrimination and learning embeddings are 
performed jointly

by disambiguating a word using current parameters

non-parametric mssg model

(varying number of senses per word)

different in the sense discrimination phase
online non-parametric id91









sense similarity techniques

not tied to sense inventories

sasa - sense-aware semantic analysis
wu and giles (aaai 2015)



sense similarity techniques

not tied to sense inventories

topical id27s - liu et al (aaai 2015)

different senses of a word can overlap


-> soft id91

uses lda to learn representations for <word,topic> pairs



sense similarity

evaluation benchmarks

       word similarity

and all other word-level applications

       sense merging
       id51 
       stanford's contextual word similarities 
       cross level semantic similarity

(scws)


(more details to follow)





word similarity

word similarity is a lot like sense 

similarity

he went to the atm to deposit the money.

she goes to the bank to withdraw cash.



word similarity is a lot like sense 
similarity     except for ambiguity

he went to the atm to deposit the money.

she goes to the bank to withdraw cash.

she goes to the shore near the silt deposit.





word similarity is a lot like sense 
similarity     except for ambiguity

he went to the atm to deposit the money.

she goes to the bank to withdraw cash.

she goes to the shore near the silt deposit.

most approaches measure similarity 

completely out of context.





word similarity lets you easily build 
to larger linguistic level   s similarities

the boy sailed the boat over the ocean.

the girl navigate the sailboat across the sea.


many applications bene   t from 
having word representations that 

encode similarity or having effective 

word similarity functions.

       text classi   cation (baker and mccallum, 1998) 
       document classi   cation (sebastinani et al, 2002)
       id53 (tellex et al, 2003)
       ir (sanderson, 1994), manning et al (2008)
       id123 (baroni, 2014 - sick)
       id39 (turian et al, 2010, passos et al, 2014)
       id33 (bansal et al, 2014)
       chunking (turian et al, 2010, dhillon and ungar, 2011)
       paraphrase detection (socher et al, 2011)

ideal references for comparing 

impact of new approaches

most approaches evaluate on similarity 

benchmarks, rather than tasks

numeric word-pair similarity tests
      rubenstein & goodenough, 1965 (rg)
      wordsim-353 (finkelstein et al., 2001)
      rare words (luong et al., 2013)
      men (bruni et al., 2012)
      radinsky et al., (2010)

word choice tests
      toefl, esl, reader   s digest


toefl synonymy 
recognition

rg-65 judgement

correlation

stanford rare word (rw)
judgement correlation

dispossess
entrapping
ruralist
acoustical
quieten 


deprive 

 6.83

capture 
 8.00

          advocate 
 0.67

 0.14

           9.38


remedy 


          hush

what if we know nothing 

(about the words)?

you shall know a word by the 

company it keeps

-- firth (1957)

learning semantic 

representations from text

1) corpus

learning semantic 

representations from text

1) corpus

2) preprocessing

learning semantic 

representations from text

1) corpus

2) preprocessing

3) id84

learning semantic 

representations from text

1) corpus

2) preprocessing

3) id84

4) post processing

three typical setups: term-term, term-

context or term-document matrix

...	
   

term-     i	
   

.
.
.
	
   

cells record the number of times... 

term j occurs in the context 
window of term i.

three typical setups: term-term, term-

context or term-document matrix

...	
   

...	
   

term-     i	
   

.
.
.
	
   

term-     i	
   

.
.
.
	
   

cells record the number of times... 

term j occurs in the context 
window of term i.

term i occurs in a context window
       w-     2,	
   w-     1,	
   w,	
   w1,	
   w2	
   
      

	
   or analogously, with 
dependencies

three typical setups: term-term, term-

context or term-document matrix

...	
   

...	
   

...	
   

cells record the number of times... 

term j occurs in the context 
window of term i.

term i occurs in a context window
       w-     2,	
   w-     1,	
   w,	
   w1,	
   w2	
   
      

	
   or analogously, with 
dependencies

term i occurs in document j.

term-     i	
   

.
.
.
	
   

term-     i	
   

.
.
.
	
   

term-     i	
   

.
.
.
	
   

raw word co-occurrence is rarely 
satisfactory as a representation
      all words are treated as equally informative

      the, big, metallic, biophosphorescence 

      vector length is proportional to vocabulary 
size
      eventually issues with computation and space  

      infrequent words have overly-sparse 
vectors



standard approach: reduce the 

dimensionality using the 

singular value decomposition (svd)

standard approach: reduce the 

dimensionality using the 

singular value decomposition (svd)

typically, u *    is used as the vector space.

state of the art: reduce dimensionality 

with neural embeddings (id97)

also known as 

id97

more a software system than an algorithm
      training methods
      negative sampling
      hierarchical softmax

      context representations

      continuous bag of words (cbow)
      skip grams

(mikolov	
   et	
   al.,	
   2013a,b,c)	
   


id97: a neural look

each	
   word	
   is	
   represented	
   as	
   a	
   

k-     dimensional	
   vector	
   

w0	
   

hidden layer 
weight matrix

c-     2	
   

c-     1	
   

c1	
   

c2	
   

(mikolov	
   et	
   al.,	
   2013a,b,c)	
   

id97: a neural look

each	
   word	
   is	
   represented	
   as	
   a	
   

k-     dimensional	
   vector	
   

w0	
   

hidden layer 
weight matrix

c-     2	
   

c-     1	
   

c1	
   

c2	
   

the	
   system	
   is	
   trained	
   to	
   predict	
   the	
   representa(ons	
   for	
   

context	
   words	
   before	
   and	
   a@er	
   

(mikolov	
   et	
   al.,	
   2013a,b,c)	
   

id97: a neural look

each	
   word	
   is	
   represented	
   as	
   a	
   

k-     dimensional	
   vector	
   

w0	
   

hidden layer 
weight matrix

for	
   nega(ve	
   sampling,	
   replace	
   w0	
   
with	
   a	
   random	
   word   s	
   vector	
   and	
   

penalize.	
   

c-     2	
   

c-     1	
   

c1	
   

c2	
   

the	
   system	
   is	
   trained	
   to	
   predict	
   the	
   representa(ons	
   for	
   

context	
   words	
   before	
   and	
   a@er	
   

(mikolov	
   et	
   al.,	
   2013a,b,c)	
   

id97     implicitly 

factorizing pmi-weighted 

word-context matrix

key implication: id97 is building upon 

existing techniques by using a new decomposition

(levy	
   and	
   goldberg,	
   2014)	
   

huge gains from using embeddings!

rg
 wordsim
 men

toefl

pmi+svd

id97

.70

.83

.70

.78

.72

.80

.76

.86

performance improvement over svd-based 

methods is consistent across many tasks*

(baroni	
   et	
   al.,	
   2014)	
   

could we get better performance 

with syntactic contexts?

australian scientist discovers star with telescope

(levy	
   and	
   goldberg,	
   2014)	
   

could we get better performance 

with syntactic contexts?

australian scientist discovers star with telescope

nsubj

prep_with

dobj

australian scientist discovers star with telescope

(levy	
   and	
   goldberg,	
   2014)	
   

dependency-based embeddings 
capture functional information

no quantitative results on standard benchmarks

(levy	
   and	
   goldberg,	
   2014)	
   

glove: capture the ratio of co-

occurrence probabilities 

id97:

w  ct  = pmi(w, c)     log k

glove:

w  ct    bw    bc = log(#(w, c))

key insight: the context vector provides insight into 

so a word representation is w + c 

(mikolov	
   et	
   al.,	
   2013;	
   pennington	
   et	
   al.,	
   2014;	
   levy	
   and	
   goldberg,	
   2015)	
   

glove had initially impressive 
performance at word similarity

mc
 rg

scws
 rare words

svd 

.727

.751

id97

.652

.697

glove

.727

.778

.565

.581

.529

.370

.372

.381

(pennington	
   et	
   al.,	
   2014)	
   

however under equivalent tuning, 

id97 performs better

men

word
sim

rad. et al.
(2011)

rare 
words

siid113x

ppmi

pmi+svd

id97

glove

.755

.793

.793

.725

.745

.778

.774

.729

.686

.666

.693

.632

.462

.514

.470

.403

.393

.432

.438

.398

(levy	
   and	
   goldberg,	
   2015)	
   

regular embeddings still 

con   ate meanings

incorporating senses* seems to 

improve performance

scws

rg

men

siid113x

id97

.657

gaussian embeddings 
(vilnis and mccallum, 2015)

twi (liu et al. 2015)

.681

.694

.710

.707

.713

.311

.322

but results vary based on test setup

scws

rg

men

siid113x

id97

.657

gaussian embeddings 
(vilnis and mccallum, 2015)

twi (liu et al. 2015)

.681

.694

.710

.707

.713

.311

.322

scws
 wordsim
 men

siid113x

pmi+svd

id97

.581

.793

.793

.778

.774

.432

.438

many other sense-based embeddings 

never evaluate on similarity

(pennington	
   et	
   al.,	
   2014;	
   
	
   levy	
   and	
   goldberg,	
   2015)	
   

results suggest that more 

dimensions in word vectors can 

compensate for con   ating meanings

ner

semantic relatedness

sentiment

word-embeddings (50 dims)

.852

sense-embeddings (50 dims)

.854

.748

.762

word-embeddings (100 
dims)

.867

.770

.747

.750

.763

(li	
   and	
   jurafsky,	
   2015)	
   

learning-approach recap

      nothing magic in the representation

      similar to svd with pmi-weighted matrix 

      id97 state of the art for most use cases
      but dependency-based relations may be useful 
in some circumstances
      also, one of the fastest to train 

      sense-aware representations have a yet to 
show a clear bene   t



what if we already know 

something about the words?

the structure of id138, wikipedia, 

and other knowledge bases can be 
used to measure word similarity

great for when you need a 

similarity value

not as great when you need a 
representation to use, unless 

you create one

wikipedia links create a knowledge 

graph with edges between related pages

ideal for path-based measures of similarity 

and for id93!

wikirelate: apply id138 
measures on wikipedia   s graph

best results with leacock & codorow   s method: 
-log( path_length(page1, page2) / max_depth)

l&c (wikipedia)

rg

.41

mc

.54

wordsim-353

.48

(leacock	
   and	
   chodorow,	
   1998;	
   strube	
   and	
   ponzero,	
   2006)	
   

wikirelate: apply id138 
measures on wikipedia   s graph

best results with leacock & codorow   s method: 
-log( path_length(page1, page2) / max_depth)

l&c (wikipedia)

l&c (id138)

rg

.41

.82

mc

.54

.86

wordsim-353

.48

.34

large amount of noise in wikipedia   s graph creates issues for 
similarity-speci   c calculations.   i.e,. dif   cult to tell edges and 
nodes are important.

(leacock	
   and	
   chodorow,	
   1998;	
   strube	
   and	
   ponzero,	
   2006)	
   

idea: identify important pages in 

wikipedia using personalized id95
       given a page p,    nd all wiki-linked pages to p 
and initialize the ppr vector to these pages
      optionally prune (a) pages with spaces in the name 
and (b) pages account for fewer than x% of the links 

       run ppr and compare vectors

(agirre	
   et	
   al.,	
   2009)	
   


idea: identify important pages in 

wikipedia using personalized id95
       given a page p,    nd all wiki-linked pages to p 
and initialize the ppr vector to these pages
      optionally prune (a) pages with spaces in the name 
and (b) pages account for fewer than x% of the links 

       run ppr and compare vectors

ppr

wikirelate

mc

.60

.54

wordsim-353

.45

.48

(agirre	
   et	
   al.,	
   2009)	
   


idea: identify important pages in 

wikipedia using personalized id95
       given a page p,    nd all wiki-linked pages to p 
and initialize the ppr vector to these pages
      optionally prune (a) pages with spaces in the name 
and (b) pages account for fewer than x% of the links 

       run ppr and compare vectors

ppr

wikirelate

esa

mc

.60

.54

wordsim-353

.45

.48

.75

.72
(agirre	
   et	
   al.,	
   2009;	
   gabrilovich	
   and	
   markovitch,	
   2007)	
   


(still) state of the art for wikipedia: 

explicit semantic analysis

consider each wikipedia article as a concept

{c1, c2, c3,     cn} where n is the number of articles 
in wikipedia

gabrilovich	
   and	
   markovitch	
   (2007)	
   









articles for tomcat

explicit semantic analysis (esa)

for a given word (e.g., equipment) calculate an 
inverted index entry to all the n documents: 


explicit semantic analysis (esa)

for a given word (e.g., equipment) calculate an 
inverted index entry to all the n documents: 

 

{c1, c2, c3,     cn} 

tool

0.073	
   

camping

electronic test equipment

0.002	
   

0.018	
   

explicit semantic analysis (esa)

for a given word (e.g., equipment) calculate an 
inverted index entry to all the n documents: 

 

{c1, c2, c3,     cn} 

tool

camping

electronic test equipment

<	
   

0.073	
   

,	
   

0.002	
   

,	
       	
   

,	
   

0.018	
   

>	
   

explicit semantic analysis (esa)

for a given word (e.g., equipment) calculate an 
inverted index entry to all the n documents: 

 

{c1, c2, c3,     cn} 

tool

camping

electronic test equipment

<	
   

0.073	
   

,	
   

0.002	
   

,	
       	
   

,	
   

0.018	
   

>	
   

vector for equipment

we use machine learning techniques to build a semantic
interpreter that maps fragments of natural language text into
a weighted sequence of wikipedia concepts ordered by their
relevance to the input. this way, input texts are represented
as weighted vectors of concepts, called interpretation vectors.
the meaning of a text fragment is thus interpreted in terms
of its af   nity with a host of wikipedia concepts. comput-
ing semantic relatedness of texts then amounts to comparing
their vectors in the space de   ned by the concepts, for exam-
ple, using the cosine metric [zobel and moffat, 1998]. our
semantic analysis is explicit in the sense that we manipulate
manifest concepts grounded in human cognition, rather than

observe that input texts are given in the same form as
wikipedia articles, that is, as plain text. therefore, we can use
conventional text classi   cation algorithms [sebastiani, 2002]
to rank the concepts represented by these articles according
to their relevance to the given text fragment. it is this key ob-
servation that allows us to use encyclopedia directly, without
the need for deep language understanding or pre-cataloged

esa pipeline

b uilding semantic i nterpreter

b uilding weighted
inverted index

w ikipedia

using semantic i nterpreter

semantic
i nter pr eter

t ext1

t ext2

word1

wordi

wordn

weighted list
of concepts
(= wikipedia
articles)

w eighted

inver ted index

v ector
compar ison

r elatedness
estimation

weighted
vector of
wikipedia
concepts

(gabrilovich	
   and	
   markovitch,	
   2007)	
   

wikipedia
concepts

esa (example)

figure 1: semantic interpreter

#
1
2
3
4
5
6
7
8
9
10

input:    equipment   
tool
digital equipment corporation
military technology and equipment
camping
engineering vehicle
weapon
original equipment manufacturer
french army
electronic test equipment
distance measuring equipment

input:    investor   
investment
angel investor
stock trader
mutual fund
margin (   nance)
modern portfolio theory
equity investment
exchange-traded fund
hedge fund
ponzi scheme

table 1: first ten concepts in sample interpretation vectors.

(gabrilovich	
   and	
   markovitch,	
   2007)	
   

esa: text modeling

	
   	
   

tfidf weight of word i 
in the text 

inverted index for word i 

wiktionary provides links with 

more semantic structure 

wiktionary provides links with 

more semantic structure 

ideal for path-based 

measures of similarity and 

for id93!

id93 are still useful if you 
use a semantically structured resource

adw w/ wiktionary (pilehvar and navigli, 2015)

adw w/ id138 (pilehvar et al. 2013)

ppr w/ id138 (hughes and ramage, 2007)

ppr w/ id138 (agirre et al., 2009)

esa (gabrilovich and markovitch, 2007)

rg

.920

.868

.838

.830

.749

wikirelate (strube and ponzetto, 2006)

r = 0.53

word vectors don   t need to be 

learned either!

idea: create binary vectors of whether a word 

satis   es a set properties from knowledge 
bases

      id138: is hypernym of x
      framenet: evokes frame x
      sentiment: evokes emotion or sentiment
      ~172k features total

optionally compress vectors using an svd

(faruqui	
   and	
   dyer,	
   2015)	
   



word vectors don   t need to be 

distributional either!

id97

glove

lsa

ling (full)

ling (with svd)

rg

.728

.766

.770

.778

.670

siid113x
 wordsim-353

.436

.369

.496

.566

.576

.656

.605

.673

.446

.454

signi   cant gains in similarity just by encoding 

knowledge bases in a vector format

(faruqui	
   and	
   dyer,	
   2015)	
   

word vectors don   t need to be 

distributional either!

id97

glove

lsa

ling (full)

ling (with svd)

adw

rg

.728

.766

.770

.778

.670

.868

siid113x
 wordsim-353

.436

.369

.496

.566

.576

.656

.605

.673

.446

.454

there may still be better ways to encode knowledge though

(pilehvar	
   et	
   al.,	
   2013;	
   faruqui	
   and	
   dyer,	
   2015)	
   

what if we knew something 

but still wanted to learn?

idea: modify vectors learning (or 
representations) to match desired 

properties of knowledge bases 

impose constraints such as
      sim(word, synonym) > sim(word, antonym)
      similarity is greater when concepts are more 
categorically related (e.g., using hypernyms)

constraints could be added during learning or 

could be used to retro   t already-learned 
vectors

(iacobacci	
   et	
   al.,	
   2015;	
   liu	
   et	
   al.,	
   2015;	
   faruqui	
   et	
   al,	
   2015)	
   


idea: modify vectors learning (or 
representations) to match desired 

properties of knowledge bases 

where is knowledge 
added?

rg

toefl
 wordsim-353

id97

n/a

.728

83.75

.709

li et al., (2015)

learning

87.5

.727

faruqui et al., (2015)

representation

iacobacci et al., (2015)

similarity func.

100

.778

.871

.700

.779

signi   cant opportunities to add knowledge at different stages, 
with the ability to tune the representation or how it is used for a 

speci   c task

(iacobacci	
   et	
   al.,	
   2015;	
   liu	
   et	
   al.	
   2015;	
   faruqui	
   et	
   al,	
   2015)	
   

phrase similarity 

compositionality

moving from words to phrases, sentences, 

and larger pieces of texts

how would we compare...

   the usual morning cup of joe   
   drip coffee with freshly-ground arabica beans   

how would we compare...

   the usual morning cup of joe   
   drip coffee with freshly-ground arabica beans   

   must do our utmost   

   must make every effort   

how would we compare...

   the usual morning cup of joe   
   drip coffee with freshly-ground arabica beans   

   must do our utmost   

   must make every effort   

measuring the similarity of the phrases requires understanding 

each item as a whole.

we need compositionality!

initial idea: compose from existing 

word representations

combining individual words    vectors

simple average:

weighted average:

including one or more
distributional neighbors:

multiplicative:

combined multiplication
and addition:

better at distinguishing

high and low

semantic similarity

mitchell and lapata (2008) 


combine words by taking syntax into account
-   

integrates lexical information with selectional 
preferences

-    computes the meaning of a word a in the context 

of the word b (disambiguates the meaning of a 
word in the context of another)

erk and pado (2008) 


combine words by taking syntax into 
account

erk and pado (2008) 

moving beyond element-wise 

composition

simple average:        zi = uj + vk 

adjectives as matrices:   zi = ujvk 
       learn each adjective   s u by comparing vectors when adjective is 

and isn   t present.  

composition as matrices: zi = auj + bvk 
       estimating a and b is a regression problem with multiple dependent 

variables.   use a dictionary to    nd training pairs (u, v, z)! 

(baroni and zamparelli, 2010; guevara, 2010) 



moving beyond element-wise 

composition

simple average:        zi = uj + vk 

adjectives as matrices:   zi = ujvk 
       learn each adjective   s u by comparing vectors when adjective is 

and isn   t present.  

composition as matrices: zi = auj + bvk 
       estimating a and b is a regression problem with multiple dependent 

variables.   use a dictionary to    nd training pairs (u, v, z)! 

(baroni and zamparelli, 2010; guevara, 2010; zanzotto et al., 2010) 



moving beyond element-wise 

composition

simple average:        zi = uj + vk 

adjectives as matrices:   zi = ujvk 
       learn each adjective   s u by comparing vectors when adjective is 

and isn   t present.  

key insight: composition is 
decoupled from word type!

composition as matrices: zi = auj + bvk 
       estimating a and b is a regression problem with multiple dependent 

variables.   use a dictionary to    nd training pairs (u, v, z)! 

(baroni and zamparelli, 2010; guevara, 2010; zanzotto et al., 2010) 



learn phrase representations directly 
during embedding!

directly learns id97 representations for 
phrases
-   
-   

first detects phrases in the training corpus by using a simple 
frequency-based approach
treating these phrases as single tokens, obtains phrase-speci   c 
representations

incapable of handling syntactic dependencies or 

related phrasal constructions

mikolov	
   et	
   al	
   (2013)	
   

compose with a recursive neural net

note:	
   requires	
   data	
   be	
   parsable.	
   

(socher	
   et	
   al.,	
   2012)	
   

compose with a recursive neural net

matrix captures the compositional 
aspects of the word

note:	
   requires	
   data	
   be	
   parsable.	
   

(socher	
   et	
   al.,	
   2012)	
   

compose with a recursive neural net

not	
   ideal	
   performance	
   in	
   composi(onality-     speci   c	
   tasks	
   (blacoe	
   
and	
   lapata,	
   2012;	
   hashimoto	
   et	
   al.,	
   2014)	
   -     -     	
   partly	
   because	
   the	
   
model	
   isn   t	
   trained	
   for	
   composi(onality!	
   

(socher	
   et	
   al.,	
   2012)	
   

idea: design an id56 with a cost 
function based on good paraphrase
      create a paraphrase ranking corpus from 
ppdb (ganitkevitch et al., 2013) 

      modify the id56 from socher et al. (2014) 
so that the id168 penalizes similar 
representations of bad paraphrase 
examples 

      initialize with id97, but tune the 
vectors

(wie^ng	
   et	
   al.,	
   2015)	
   




idea: design an id56 with a cost 
function based on good paraphrase

id97

additive

paragram

additive

paragram

id56

hashimoto et al. (2014)

mitchell and lapata (2010)

m&l bigrams

m&l 

paraphrase

annotated 

ppdb 

.39

.42

.47

.47

.44

.36

.46

.52

.41

-

.20

.32

.40

-

-

a supervised id56 provides signi   cant bene   ts 
over representing phrases using vector addition.

(wie^ng	
   et	
   al.,	
   2015)	
   

sentence similarity

sentence similarity is one of the 

most active areas

many applications bene   t:
      id141
      id123
      machine translation
      id53

easy to build models using combinations of 

string similarity and word-semantics similarity!


semantic textual similarity

       2012 (a pilot): 35 teams 88 runs
       2013 (+typed): 34 teams 89 runs
       2014 (multilingual): 


english 15 teams 38 runs

spanish 9 teams 22 runs

       2015 (+pilot on interpretability):


english 29 teams 74 runs

spanish 7 teams 16 runs

interpretable sts 7 teams 29 runs

       2016 (interpretable sts)


semantic textual similarity

iaa statistics:

    hdl: 79.4%
    onwn: 67.2%
    deft-forum: 58.6%
    deft-news: 70.7%
    images: 83.6%
    tweets-news: 74.4%


sentence similarity techniques

basic idea: average vectors of the words in a 

sentence

<	
   	
   	
   	
   	
   	
   	
   >	
   

<	
   	
   	
   	
   	
   	
   	
   >	
    <	
   	
   	
   	
   	
   	
   	
   >	
   
indonesia	
   passenger	
   plane	
   wreckage	
   located	
   in	
   remote	
   papua	
   

<	
   	
   	
   	
   	
   	
   	
   >	
    <	
   	
   	
   	
   	
   	
   	
   >	
   

<	
   	
   	
   	
   	
   	
   	
   >	
   

<	
   	
   	
   	
   	
   	
   	
   >	
    <	
   	
   	
   	
   	
   	
   	
   >	
   <	
   	
   	
   	
   	
   	
   	
   >	
   <	
   	
   	
   	
   	
   	
   	
   >	
    <	
   	
   	
   	
   	
   	
   	
   >	
    <	
   	
   	
   	
   	
   	
   	
   >	
   <	
   	
   	
   	
   	
   	
   	
   >	
   
indonesia	
   plane	
   debris	
   found	
   in	
   remote	
   papua	
   area	
   






sentence similarity techniques

alignment

aggregate the similarities of the closest pairs 
of words: corley and mihalcea (2005)

indonesia	
   passenger	
   plane	
   wreckage	
   located	
   in	
   remote	
   papua	
   

indonesia	
   plane	
   debris	
   found	
   in	
   remote	
   papua	
   area	
   






sentence similarity techniques

simple string-based similarity

v      
 substring overlap

he is talking on a phone
he talks on a telephone





sentence similarity techniques

simple string-based similarity

he is talking on a phone
he talks on a telephone

v      id165 overlap (character and word)

<begin>	
   he	
   is	
   
he	
   is	
   talking	
   
is	
   talking	
   on	
   
talking	
   on	
   phone	
   
on	
   phone	
   <end>	
   
	
   

<begin>	
   he	
   talks	
   
talks	
   on	
   a	
   
on	
   a	
   telephone	
   
a	
   telephone	
   <end>	
   
	
   





sentence similarity techniques

simple string-based similarity

he is talking on a phone
he talks on a telephone

v      id165 overlap (character and word)

<b>he-     	
   
he-     	
   
e-     i	
   
-     is	
   
is-     	
   
s-     t	
   
   	
   

<b>he-     	
   
he-     	
   
e-     t	
   
-     ta	
   
tal	
   
alk	
   
   	
   





sentence similarity techniques

usually feature-based regression models

e.g., ukp (best system in sts-12)

string-based similarity: character id165, gst, etc.

semantic similarity: id138-based approaches, esa, etc.

other features: pos id165, smt, etc.










most sts systems are multi-feature 

regressors

       sts-2012
       resources and tools 
used by the systems 
(from the task   s paper)

most sts systems are multi-feature 

regressors

       sts-2013
       resources and tools 
used by the systems 
(from the task   s paper)

most sts systems are multi-feature 

regressors

       sts-2013 resources and tools used by 

the systems

       id138 
       monolingual corpora 
       wikipedia 
       dictionaries
       multilingual corpora
       opinion and id31 
       lists and tables of paraphrases

sentence similarity techniques

soft cardinality


jimenez et al (2010)

uses only surface text information, a stop-word 
remover, and a stemmer 

ranked 3rd in sts-12





sentence similarity techniques

monolingual alignment


sultan et al (2014): best system in sts-14 and -15 

dls@cu

the similarity score is computed as a function of the proportions of 
aligned content words in the two input sentences.











sentence similarity techniques: 

skip-thought vectors

embedding a sentence with unsupervised training

given a sentence, predict the 
previous and following sentences

senti-1

senti

senti+1

hidden layer

input layer

senti

sentence similarity techniques: 

skip-thought vectors

embedding a sentence with unsupervised training

given a sentence, predict the 
previous and following sentences

senti-1

senti

senti+1

sequential embedding 
of the words

hidden layer

input layer

senti

senti = (w1, w2, w3, w4, w5,     wn)

sentence similarity techniques: 

skip-thought vectors

embedding a sentence with unsupervised training

given a sentence, predict the 
previous and following sentences

msr paraphrase 
detection (mse)

sick semantic 
relatedness (f1)

senti+1

skip-thought vecs

0.2561 

sequential embedding 
of the words

0.2532

state of the art

83.0

84.1

senti-1

senti

hidden layer

input layer

senti

not state of the art,  
but high performance on 
a wide variety of tasks

kiros	
   et	
   al.	
   (2015)	
   

coffee break

30 minutes

paragraph similarity

paragraphs represent large 

thematic, topical units -- more than 

just a sequence of sentence

the lisbon region is the wealthiest region in portugal and it is 

well above the european union's gdp per capita average     it 
produces 45% of the portuguese gdp. lisbon's economy is 
based primarily on the tertiary sector. most of the headquarters 
of multinationals operating in portugal are concentrated in the 
grande lisboa subregion, specially in the oeiras municipality. 
the lisbon metropolitan area is heavily industrialized, 
especially the south bank of the tagus river (rio tejo). 

little evaluation directly on 

paragraph similarity

      often used as the unit of text for 
applications
      plagiarism detection
      summarization
      essay grading
      scienti   c abstracts
      document chunking


simplest idea: model paragraphs as 

a bag of words (bow)

paragraph bow representations run into all 
the same issues as with words
      huge dimensionality makes them 
cumbersome
      ignores word semantics

paragraphs also include word ordering and 

sentence ordering
      the topic sentence can matter!


current state of the art: doc2vec

tackles two problems with bag-of-word and id96 

approaches:

-    they lose the ordering of the words 
-    they ignore semantics of the words

base	
   model	
   is	
   a	
   
predic(on	
   task	
   to	
   
predict	
   the	
   next	
   word	
   
in	
   a	
   sequence	
   

le	
   and	
   mikolov	
   (2014)	
   



current state of the art: doc2vec

-    incorporate paragraph structure explicitly 

by adding a paragraph vector to the 
predictive model
-    every paragraph is mapped to a unique vector
-    a paragraph is thought of as another word that remembers what is 

missing from the current context

le	
   and	
   mikolov	
   (2014)	
   


document similarity

early document similarity techniques 

used vector space models

id45 (lsi, aka lsa) 

developed by deerwester (1988) to address 
already-discussed issues with vsms.

id96: viewing document 

contents as a mixture of topics

image	
   credit:	
   steyvers	
   and	
   gri   ths	
   (2007)	
   

id96: viewing document 

contents as a mixture of topics

image	
   credit:	
   steyvers	
   and	
   gri   ths	
   (2007)	
   

id96: viewing document 

contents as a mixture of topics

image	
   credit:	
   blei	
   (2012)	
   

document similarity techniques
id44

blei	
   et	
   al	
   (2003)	
   



key points for using topic distributions 

as id194s

      selecting the number of topics
      identify relationships between topics
      moving beyond token-topic 
assignments

how many topics should you use?

let a hierarchical dirichlet process (hdp) 

model decide for you.

(teh	
   et	
   al.,	
   2005;	
   fourtassi	
   and	
   dupoux,	
   2013)	
   

introducing structure into the topics

li and mccallum (2006)

adams et al. (2010)

blei et al. (2003)

kim et al. (2012)

topic allocations 
per document

hierarchical topic organizations can potentially yield 
more informative id194s

image	
   credit:	
   kim	
   et	
   al.	
   (2012)	
   

incorporating multi-word 

expressions into topics

      pre-process the corpus to glob mwes 
together, e.g.,    white house    -> white_house
      not feasible for domain-speci   c mwes 




incorporating multi-word 

expressions into topics

      pre-process the corpus to glob mwes 
together, e.g.,    white house    -> white_house
      not feasible for domain-speci   c mwes 

      learn the mwes on the    y by looking at 
topic-assignment sequences
      turbotopics (blei and lafferty, 2009)




turbotopics example phrases

blei	
   and	
   la   erty	
   (2009)	
   

incorporating multi-word 

expressions into topics

      pre-process the corpus to glob mwes 
together, e.g.,    white house    -> white_house
      not feasible for domain-speci   c mwes 

      learn the mwes on the    y by looking at 
topic-assignment sequences
      turbotopics (blei and lafferty, 2009) 

      learn the mwes during id96

      most scalable approach is top-min (el-kishky 
et al., 2014)





topmine example phrases

el-     kishky	
   et	
   al.	
   (2014)	
   

documents can contain much more 

than just text

lots of work on structured document similarity

adding knowledge to the document 

representation

entities that can be linked in a 
document become connected to 
wikipedia   s semantic network

image credit: http://www.emapsproject.com/blog/archives/1572

schuhmacher	
   and	
   ponzero	
   (2014)	
   

adding knowledge to the document 

representation

the edges in the graph between 
linked entities de   ne how similar 
the documents are

image credit: http://www.emapsproject.com/blog/archives/1572

schuhmacher	
   and	
   ponzero	
   (2014)	
   

other recent works have tried an lsa-like 

approach with new id84s
       non-negative id105 

 (xu et al., 2003) 

       concept factorization 

 (xu and gong, 2004) 

       locally-consistent concept factorization 

(cai et al. 2011)
       non-linear id84
main issues are computational complexity and 

representational opaqueness



cross-level semantic 

similarity

semantic similarity

mostly focused on similar types of lexical items

paragraph level	
   

sentence level	
   

word level	
   

sense level	
   

semantic similarity

what if we have different types of inputs?

paragraph level	
   

sentence level	
   

word level	
   

sense level	
   

clss: cross-level semantic 

similarity

a new type of similarity task

clss: cross-level semantic 

similarity

       multiple types of comparison
      
       push towards computing the similarity of anything

incorporate multiple genres of text

clss: comparison types

paragraph to sentence

paragraph

sentence

phrase

word

sense

clss: comparison types

paragraph to sentence

sentence to phrase

the 30-year-old woman has had no contact with the outside world.

30-year-old female recluse

paragraph

sentence

phrase

word

sense

clss: comparison types

paragraph to sentence

sentence to phrase

phrase to word

a large, expensive house

mansion

paragraph

sentence

phrase

word

sense

clss: comparison types

paragraph to sentence

sentence to phrase

phrase to word

word to sense

mansion 
driver
vehicle
1 
n	
   

(a conveyance that 
transports people or 

objects)

paragraph

sentence

phrase

word

sense

task data
4000	
   pairs	
   in	
   total	
   

500 pairs per type

500 pairs per type

paragraph to sentence

paragraph to sentence

sentence to phrase

sentence to phrase

phrase to word

word to sense

training set

 
 

phrase to word

word to sense

test set

task data

a wide range of domains and text styles

paragraph to sentence

paragraph to sentence

sentence to phrase

phrase to word

newswire

travel

newswire

travel

id53

id53

scienti   c

metaphoric

review

scienti   c

slang

idiomatic

newswire

slang

idiomatic

lexicographic

descriptive

search



                              pairs

word to sense

   regular   

   central   vs.  essential#a#1

   tyre   vs.  automobile#n#1

word not in id138

   zombify    vs. resurrect#v#3

   drank    vs. opiate#n#1

sense not in id138

   red    vs. communist#a#1

   shiraz    vs. grape#n#1

rating scale

4 -- nearly  identical

3 -- similar, but not identical

2 -- related but not similar

1 -- on the same topic, but not closely related

0 -- completely unrelated

comparison baselines

       longest common substring (lcs)

the quick brown fox

the brown fox was quick 

       greedy string tiling (gst)

the quick brown fox

the brown foxes was quick 

number of participants

sentence-phrase 
word-sense 

paragraph-sentence 
phrase-word 
35 
30 
25 
20 
15 
10 
5 
0 

38 systems total from 19 teams

top 5 systems and baselines

correlation, max 1.0 

max 4.0 

gold 
lcs baseline 
gst baseline 
semantiklue run1 
unal-nlp run2 
ecnu run1 
simcompass run1 
meerkat mafia pw* 

0 

1 
3 
overall performance 

2 

4 

paragraph-sentence 

sentence-phrase 

top 5 systems and baselines

correlation, max 1.0

max 4.0

gold 
lcs baseline 
gst baseline 
semantiklue run1 
unal-nlp run2 
ecnu run1 
simcompass run1 
meerkat mafia pw* 

0 

1 
3 
overall performance 

2 

4 

paragraph-sentence 

sentence-phrase 

where do the baselines stand?

25 systems > lcs 

lcs baseline 
gst baseline 
semantiklue run1 
unal-nlp run2 
ecnu run1 
simcompass run1 
meerkat mafia pw* 

0 

0.75 
paragraph-sentence 

2.25 

1.5 
sentence-phrase 

3 

where do the baselines stand?

25 systems > lcs 

7 systems > gst 

lcs baseline 
gst baseline 
semantiklue run1 
unal-nlp run2 
ecnu run1 
simcompass run1 
meerkat mafia pw* 

0 

0.75 
paragraph-sentence 

2.25 

1.5 
sentence-phrase 

3 

simcompass - banea et al (2014)

highest overall performance among all competing systems.

multi-feature regression model:

-    knowledge-based

-    different id138-based measures

-    corpus-based

-    deep learning id27s, skip-gram (mikolov et al, 

2013)

other novel features: 

-    transform texts to a sets of topic centroids; then check for closest 

topics






encu - zhu and lan (2014)

among the top three systems

multi-feature regression model:

-    string-based
-    knowledge-based

-    different id138-based measures

-    corpus-based
-    syntactic-based

-    lsa

other novel features:

using metrics for machine translation evaluation for semantic 
similarity, e.g., ter, meteor, id7, etc.






unal-nlp - jimenez et al (2014)

third best system overall

utilizes only a set of simple string-similarity features based on soft 

cardinality (jimenez et al, 2010).

unal-nlp run1, ranked 5th, is unsupervised: mirroring the potential for 
unsupervised semantic similarity measured seen in the recent work of 
sultan et al (2014, 2015).






correlation per genre 
paragraph-to-sentence

correlation per genre 
paragraph-to-sentence

correlation per genre 
paragraph-to-sentence

correlation per genre 

phrase-to-word

what makes the task dif   cult?

handling oov words 

and novel usages

how often do draik eggs come in merifoods in meridell?

frequency of draik eggs in merifoods

hard feelings

grudge

id138 alone is too limited

include multiple dictionaries or  

use distributional methods

lcs baseline 
gst baseline 
semantiklue run1 
unal-nlp run2 
ecnu run1 
simcompass run1 
meerkat mafia pw* 

0 

0.75 
paragraph-sentence 

2.25 

1.5 
sentence-phrase 

3 

dealing with social media text

can i watch 4od bbc iplayer etc with 10gb useage allowence?

online television streaming for bbc

can d internet companies see which websyts ive bin visiting?

internet provider's knowledge of my actions



fables

a groom used to spend whole days in 

currycombing and rubbing down his horse, 
but at the same time stole his oats and sold 

them for his own pro   t.    alas!    said the 

horse,    if you really wish me to be in good 
condition, you should groom me less, and 

feed me more.   

horses need food to look their best.



fables in real world

the fields medals are regarded as 

mathematics' nobel prize, and are awarded 
every four years. all the previous 52 winners 

of the fields have been men since its 

inception in 1936.

mathematics is a male-dominated research 

area.


open source tools for 

semantic similarity

sense
word
phrase
sentence
para/doc

tools

id138::similarity

- word and sense similarity (ted pederson) 

       in perl 

       also available in java, by hideki shima 

ws4j: http://code.google.com/p/ws4j/

       many common id138 similarity measures

lin (1998)

leacock & chodorow (1998)
jiang & conrath (1997)

      
      
       resnik (1995)
      
       hirst & st-onge (1998)
       wu & palmer (1994)
       the extended gloss overlap measure by banerjee and pedersen 
       two measures based on context vectors by patwardhan (2003).

(2002)


sense
word
phrase
sentence
para/doc

tools

align, disambiguate and walk: adw (acl 2013)

-    multi-level similarity 

-     from word senses to texts
-    all inputs have comparable representations 

- implicit id51  

- publicly available in java

https://github.com/pilehvar/adw





sense
word
phrase
sentence
para/doc

tools

align, disambiguate and walk: adw

online demo at 

http://lcl.uniroma1.it/adw/


sense
word
phrase
sentence
para/doc

tools
dkprosimilarity

https://github.com/dkpro/dkpro-similarity

-    open source framework for text similarity, java
-    best system semeval sts-12 task
-    several similarity measures, including:

algorithms.lexical

greedystringtiling, levenshtein, ngrambased, ...

algorithms.lsr

based on id138 or wikipedia

algorithms.style

functionwordfrequency, mtld, typetokenratio

algorithms.vsm

vector-space models, e.g. esa

algorithms.wikipedia

special wikipedia measures, e.g., 
wikipedialinkmeasure









sense
word
phrase
sentence
para/doc

tools
takelab

http://takelab.fer.hr/sts/

-    open source framework for text similarity, python
-    among the top    ve in sts-12
-    several similarity measures, including:

lexical

id138-based measures from nltk

knowledge-based

greedystringtiling, levenshtein, ngrambased, etc

corpus-based

latent semantic analysis

syntactic

other

syntactic role similarity, syntactic dependency similarity

normalized differences, number overlap, etc.









sense
word
phrase
sentence
para/doc

tools
s-space package

https://github.com/fozziethebeat/s-space

-    open source framework for word distributions
-    written in java
-    support for common weighting (e.g., pmi) and 
id105s (e.g,. svd)
-    implements many common algorithms in a 
single interface
-    lsa, id97, coals, glove, random 
-    integrated pre-processing support using 
stanford corenlp

indexing








sense
word
phrase
sentence
para/doc

tools
dissect

http://clic.cimec.unitn.it/composes/toolkit/

-    open source framework for word distributions
-    written in python
-    support for common weighting (e.g., pmi) and 

id105s (e.g,. svd)

-    designed around compositionality 

-    easy to build representation for larger phrases









sense
word
phrase
sentence
para/doc

tools
gensim

https://radimrehurek.com/gensim/

-    originally written for high-performance lsa 
-    now includes support for many kinds of id96 and 

id97
-    usually where new algorithms get    rst 

implemented 

-    fast and written in python











sense
word
phrase
sentence
para/doc

tools
id97

https://code.google.com/p/id97/

-    tomas mikolov (in c)
-    ef   cient implementation of the continuous bag-of-words 

and skip-gram architectures for word representation
-    dependency-based version available from omer levy
-    also available in 

-    https://bitbucket.org/yoavgo/id97f 

http://deeplearning4j.org/id97.html

-    java: dl4j, deep learning 4 java
-    spark mlib: https://spark.apache.org/docs/latest/mllib-feature-
-    python: as a part of gensim 

extraction.html#id97

http://radimrehurek.com/2013/09/deep-learning-with-id97-and-
gensim/











sense
word
phrase
sentence
para/doc

tools
glove: global vectors for word representation

http://nlp.stanford.edu/projects/glove/

-    written by jeffrey pennington, richard socher,  

christopher d. manning (in c) as an alternative to 
id97

-    ef   cient implementation, with pre-trained vectors 

-    also available in 

available
-    java: dl4j, deep learning 4 java

http://deeplearning4j.org/id97.html











tools
doc2vec

sense
word
phrase
sentence
para/doc
-   
-    ef   cient implementation of the continuous bag-of-words 

implemented in python as a part of gensim

https://radimrehurek.com/gensim/models/doc2vec.html

and skip-gram architectures for paragraph-level 
representations












sense
word
phrase
sentence
para/doc

tools
nltk

http://www.nltk.org/

-    a large nlp package with support for many kinds of 

operations on text 

-   

integrated with id138 with easy support for most 
sense- and word-similarity measures 

-    written in python











sense
word
phrase
sentence
para/doc

tools
spacy

http://spacy.io/

-    a large nlp package with support for many kinds of 

operations on text
-    fast pos taggers, parsers, with state of the art-level performance 

-    built in support for representing words with  

dependency-based id97 vectors (levy and goldberg, 2014) 

-    written in python











sense
word
phrase
sentence
para/doc

tools
mallet - machine learning for language toolkit
-    a software package for building all kinds of probabilistic 

http://mallet.cs.umass.edu/

models from text

-    scalable and fast support for lda and the hierarchical 

pachinko allocation model 

-    written in java











sense
word
phrase
sentence
para/doc

tools
other id96 software

       huge list of id96 software 

available at
http://www.cs.columbia.edu/~blei/topicmodeling_software.html
      


with an active mailing list too

       highlights include:
-    lda in c (fast!)
-    hdp in c
-    turbotopics in python












sense
word
phrase
sentence
para/doc

resources
out of vocabulary or rare words

       medial subject headings (mesh)

https://www.nlm.nih.gov/mesh/ 

       wiktionary

      

      

      

      

      

      

https://www.wiktionary.org 

       wordnik:    world's biggest online english dictionary   

https://www.wordnik.com/ 

       collaborative international dictionary of english 

http://gcide.gnu.org.ua/ 

       moby thesaurus ii 

http://goo.gl/fzrrcf 

       the free on-line dictionary of computing 

http://foldoc.org/ 


sense
word
phrase
sentence
para/doc

resources
crown

https://github.com/davidjurgens/crown

-    extension of id138 with new synsets 

and lexicalizations
-    2x the size of id138
-    slang, archaic forms, idioms, technical words,      

-    released as stand-off dictionaries, so 
compatible with all id138 libraries
-    nltk, id138::similarity




sense
word
phrase
sentence
para/doc

resources
babelnet

http://babelnet.org/

-    combination of many resources into a single 

representation
-    id138, wikipedia, wiktionary

-    can be combined with babelfy to 
disambiguate text to sense level

-    support for cross-lingual mapping of 

concepts across 271 languages

-    written in java, but has rest api as well


pre-trained word vectors

       id97 
       https://code.google.com/p/id97/
       https://github.com/3top/id97-api
       baroni and lenci, distributional memory
       http://clic.cimec.unitn.it/dm/
       glove
       http://nlp.stanford.edu/projects/glove/
       faruqui and dyer (acl 2014) 
       http://wordvectors.org/
       huang et al (2012), multiple word prototypes
       http://www-nlp.stanford.edu/~ehhuang/wordrep.zip

      

levy and goldberg (2014), dependency-based id27s
       https://levyomer.wordpress.com/2014/04/25/dependency-based-word-embeddings/ 


open problems in semantic 

similarity

open problem: irregular 

language

can i watch 4od bbc iplayer etc with 10gb useage allowence?

online television streaming for bbc

can d internet companies see which websyts ive bin visiting?

internet provider's knowledge of my actions









open problem: multi-word 

expressions (mwes)

-    most approaches either ignore mwes or 
recognize those from    xed lists of mwes
-    problematic unless lemmatizing
-    even more problematic with syntactic 
rearrangement 

we need to sort out the problem
we need to sort the problem out




open problem: multi-word 

expressions (mwes)

-   new semeval-2016 task on super-sense 
tagging seems like a promising direction for 
addressing this

example from the task   s website

open problem: cross-language 

similarity

-   bene   cial for machine translation 
evaluation or even applications like 
plagiarism detection
-    recent benchmarks by camacho-collados et 
al. (2015) and leviant and reichart (2015)
cross-lingual datasets constructed based on rg-65 (fr, 
de, en, fa, es, and pt) and ws353 (en, de, it, and ru)

hrp://lcl.uniroma1.it/similarity-     datasets/	
   
hrp://technion.ac.il/~irakr/mul^lingualvsmdata.html	
   



open problem: syntax

-   syntax matters
-       man bites dog   
-       dog bites man   
-       pitbull bites man   

vector addition would fail 

in these cases

-    compositionality can help here but more analysis is 
needed
-    recent sick benchmark designed to explicit test for 
compositional ability (marelli et al., 2014)
-    possible solution with abstract meaning 
representations (amrs)
-    check out semeval-2016   s task!



open problem: punctuations!

a woman without her man is nothing.

a woman: without her, man is nothing.


open problem: variable-sized 

input

the 30-year-old woman has had "no 
contact with the outside world.   

30-year-old female 
recluse

prius
a fuel-ef   cient hybrid car
an automobile powered by both an internal combustion 
engine and an electric motor, reducing its dependence on 
fossil fuels

requires smarter compositionality












open problem: ambiguity

-   multiple interpretations can wreak havoc 
when text is limited

the boss    red his worker.

an employee was 
terminated 
from work by his boss.

a worker was shot
by his boss.


open problem: ambiguity

-   alignment-based disambiguation of adw

-   wsd is a solution, but is still a long way off

babelfy	
   






open problem: subjectivity vs. objectivity

as of 2012, there are  2.1 million hybrids on u.s. roads.

 

?	
   

?	
   

hybrid cars are getting quite popular in u.s.

us hybrid vehicle market share grew by 41% in 2012.


open problem: uncovered 

words

       words might not have been covered in the 

corpus or by the lexicon;

       for instance, some id138 oov words:

       prequel#n
      
fanbase#n
       screenshot#n
       bookmark#v
       programmatic#a
       broadband#n
       and many more regular terms

       photoshop#v
       space_cadet#n
       homewrecker#n
       and many more slang terms





open problem: evaluation

      many evaluation tasks make it easy to pick-
and-choose which results to report
       20+ choices for word similarity!
       what exactly is state of the art? 

      similarity itself is not an end-task, yet most 
approaches are only tested on sts 
benchmarks, not in any application.
      no easily-pluggable application-based tests


semantic similarity frontiers: from

concepts to documents

david jurgens 
jurgens@stanford.edu 
stanford university

mohammad taher pilehvar
pilehvar@di.uniroma1.it 
sapienza university of rome

slides, bibliography, extended reading list, 
and all other materials available at
http://tiny.cc/similarity-tutorial 

erc grant 259234





bonus: must-see similarity papers at emnlp!

       j. li and d. jurafsky: do multi-sense embeddings improve 

natural language understanding?

       h. he et al: multi-perspective sentence similarity modeling with 

convolutional neural networks

       d. kiela et al: specializing id27s for similarity or 

relatedness

       j. wieting and d. roth: latent variable regression for text similarity 

and id123

       sergienya and schutze: learning better embeddings for rare words 

using distributional representations

       a. gupta et al: distributional vectors encode referential attributes



