recent advances in id33

tutorial, eacl, april 27th, 2014

ryan mcdonald1

joakim nivre2

1google inc., usa/uk

e-mail: ryanmcd@google.com

2uppsala university, sweden

e-mail: joakim.nivre@lingfil.uu.se

recent advances in id33

1(42)

introduction

introduction

(cid:73) pre-2008

(cid:73) what we will brie   y cover in    rst quarter of tutorial
(cid:73) textbook: id33 [k  ubler et al. 2009]
(cid:73) esslli 2007:

http://www.ryanmcd.com/courses/esslli2007/

(cid:73) acl 2006:

http://stp.lingfil.uu.se/~nivre/docs/aclslides.pdf

(cid:73) post-2008

(cid:73) what we will mainly cover today
(cid:73) naacl 2010:

http://naaclhlt2010.isi.edu/tutorials/t7.html

recent advances in id33

2(42)

overview of the tutorial

introduction

(cid:73) introduction to id33 (joakim)

(cid:73) formulation, de   nitions, evaluation, etc.
(cid:73) graph-based and transition-based parsing
(cid:73) contrastive error analysis

(cid:73) graph-based parsing post-2008 (ryan)
(cid:73) transition-based parsing post-2008 (joakim)
(cid:73) summary and    nal thoughts (ryan)

recent advances in id33

3(42)

introduction

introduction: outline

(cid:73) dependency syntax:

(cid:73) basic concepts
(cid:73) terminology and notation
(cid:73) dependency graphs
(cid:73) data-driven id33

(cid:73) paradigms:

(cid:73) graph-based parsing
(cid:73) transition-based parsing
(cid:73) alternatives (brief)

(cid:73) contrastive error analysis [mcdonald and nivre 2007]

recent advances in id33

4(42)

dependency syntax

dependency syntax

(cid:73) the basic idea:

(cid:73) syntactic structure consists of lexical items, linked by binary

asymmetric relations called dependencies.

(cid:73) in the words of lucien tesni`ere [tesni`ere 1959]:

(cid:73) la phrase est un ensemble organis  e dont les   el  ements constituants
sont les mots. [1.2] tout mot qui fait partie d   une phrase cesse par
lui-m  eme d     etre isol  e comme dans le dictionnaire. entre lui et ses
voisins, l   esprit aper  coit des connexions, dont l   ensemble forme la
charpente de la phrase. [1.3] les connexions structurales   etablissent
entre les mots des rapports de d  ependance. chaque connexion unit
en principe un terme sup  erieur `a un terme inf  erieur. [2.1] le terme
sup  erieur re  coit le nom de r  egissant. le terme inf  erieur re  coit le
nom de subordonn  e. ainsi dans la phrase alfred parle [. . . ], parle
est le r  egissant et alfred le subordonn  e. [2.2]

recent advances in id33

5(42)

dependency syntax

dependency syntax

(cid:73) the basic idea:

(cid:73) syntactic structure consists of lexical items, linked by binary

asymmetric relations called dependencies.

(cid:73) in the words of lucien tesni`ere [tesni`ere 1959]:

(cid:73) the sentence is an organized whole, the constituent elements of

which are words. [1.2] every word that belongs to a sentence ceases
by itself to be isolated as in the dictionary. between the word and
its neighbors, the mind perceives connections, the totality of which
forms the structure of the sentence. [1.3] the structural
connections establish dependency relations between the words. each
connection in principle unites a superior term and an inferior term.
[2.1] the superior term receives the name governor. the inferior
term receives the name subordinate. thus, in the sentence alfred
parle [. . . ], parle is the governor and alfred the subordinate. [2.2]

recent advances in id33

5(42)

dependency structure

dependency syntax

economic news had little e   ect
noun

noun verb

adj

adj

on    nancial markets .
.
prep

noun

adj

recent advances in id33

6(42)

dependency structure

dependency syntax

economic news had little e   ect
noun

noun verb

adj

adj

on    nancial markets .
.
prep

noun

adj

recent advances in id33

6(42)

dependency structure

dependency syntax

economic news had little e   ect
noun

noun verb

adj

adj

on    nancial markets .
.
prep

noun

adj

recent advances in id33

6(42)

dependency structure

dependency syntax

economic news had little e   ect
noun

noun verb

adj

adj

on    nancial markets .
.
prep

noun

adj

recent advances in id33

6(42)

dependency structure

dependency syntax

economic news had little e   ect
noun

noun verb

adj

adj

on    nancial markets .
.
prep

noun

adj

recent advances in id33

6(42)

dependency structure

dependency syntax

economic news had little e   ect
noun

noun verb

adj

adj

on    nancial markets .
.
prep

noun

adj

recent advances in id33

6(42)

dependency structure

dependency syntax

dobj

amod
amod

nsubj

amod

prep

p

pobj

amod

economic news had little e   ect
noun

noun verb

adj

adj

on    nancial markets .
.
prep

noun

adj

recent advances in id33

6(42)

terminology

dependency syntax

superior
head
governor
regent
...

inferior
dependent
modi   er
subordinate
...

recent advances in id33

7(42)

terminology

dependency syntax

superior
head
governor
regent
...

inferior
dependent
modi   er
subordinate
...

recent advances in id33

7(42)

phrase structure

dependency syntax

 

 

 

 

 

 

q

q

q

q

s
  
qq
q
vp
hh
 
np
hh
pp
hh
 
np
  
hh
jj

 
in

 

q

 

"""""

 
np
hh
  
nn
jj

 

q

nns

q

q

q
pu

 

 

 

 

 
np
hh
  
jj
nn

 

 
vbd

economic

news

had

little

e   ect

on

   nancial

markets

.

recent advances in id33

8(42)

comparison

dependency syntax

(cid:73) dependency structures explicitly represent
(cid:73) head-dependent relations (directed arcs),
(cid:73) functional categories (arc labels),
(cid:73) possibly some structural categories (parts-of-speech).

(cid:73) phrase structures explicitly represent

(cid:73) phrases (nonterminal nodes),
(cid:73) structural categories (nonterminal labels),
(cid:73) possibly some functional categories (grammatical functions).

(cid:73) hybrid representations may combine all elements.

recent advances in id33

9(42)

some theoretical frameworks

dependency syntax

(cid:73) word grammar (wg) [hudson 1984, hudson 1990, hudson 2007]
(cid:73) functional generative description (fgd) [sgall et al. 1986]
(cid:73) dependency uni   cation grammar (dug)

[hellwig 1986, hellwig 2003]

(cid:73) meaning-text theory (mtt) [mel     cuk 1988, mili  cevi  c 2006]
(cid:73) (weighted) constraint dependency grammar ([w]cdg)

[maruyama 1990, menzel and schr  oder 1998, schr  oder 2002]

(cid:73) functional dependency grammar (fdg)

[tapanainen and j  arvinen 1997, j  arvinen and tapanainen 1998]

(cid:73) topological/extensible dependency grammar ([t/x]dg)

[duchier and debusmann 2001, debusmann et al. 2004]

recent advances in id33

10(42)

dependency syntax

some theoretical issues

(cid:73) dependency structure su   cient as well as necessary?
(cid:73) mono-stratal or multi-stratal syntactic representations?
(cid:73) what is the nature of lexical elements (nodes)?

(cid:73) morphemes?
(cid:73) word forms?
(cid:73) multi-word units?

(cid:73) what is the nature of dependency types (arc labels)?

(cid:73) grammatical functions?
(cid:73) semantic roles?

(cid:73) what are the criteria for identifying heads and dependents?
(cid:73) what are the formal properties of dependency structures?

recent advances in id33

11(42)

dependency syntax

some theoretical issues

(cid:73) dependency structure su   cient as well as necessary?
(cid:73) mono-stratal or multi-stratal syntactic representations?
(cid:73) what is the nature of lexical elements (nodes)?

(cid:73) morphemes?
(cid:73) word forms?
(cid:73) multi-word units?

(cid:73) what is the nature of dependency types (arc labels)?

(cid:73) grammatical functions?
(cid:73) semantic roles?

(cid:73) what are the criteria for identifying heads and dependents?
(cid:73) what are the formal properties of dependency structures?

more at: http://www.ryanmcd.com/courses/esslli2007/

recent advances in id33

11(42)

dependency graphs

dependency syntax

(cid:73) a dependency structure can be de   ned as a directed graph g ,

consisting of

(cid:73) a set v of nodes (vertices),
(cid:73) a set a of arcs (directed edges),
(cid:73) a linear precedence order < on v (word order).

(cid:73) labeled graphs:

(cid:73) nodes in v are labeled with word forms (and annotation).
(cid:73) arcs in a are labeled with dependency types:

(cid:73) l = {l1, . . . , l|l|} is the set of permissible arc labels.
(cid:73) every arc in a is a triple (i, j, k), representing a dependency

from wi to wj with label lk .

recent advances in id33

12(42)

dependency graph notation

dependency syntax

(cid:73) for a dependency graph g = (v , a)
(cid:73) with label set l = {l1, . . . , l|l|}
(cid:73) i     j        k : (i, j, k)     a
(cid:73) i     j     i     j     j     i
(cid:73) i        j     i = j        i(cid:48) : i     i(cid:48), i(cid:48)        j
(cid:73) i        j     i = j        i(cid:48) : i     i(cid:48), i(cid:48)        j

recent advances in id33

13(42)

formal conditions on dependency graphs

dependency syntax

(cid:73) g is (weakly) connected:

(cid:73) if i, j     v , i        j.

(cid:73) g is acyclic:

(cid:73) if i     j, then not j        i.

(cid:73) g obeys the single-head constraint:

(cid:73) if i     j, then not i(cid:48)     j, for any i(cid:48) (cid:54)= i.

(cid:73) g is projective:

(cid:73) if i     j, then i        i(cid:48), for any i(cid:48) such that i < i(cid:48) < j or j < i(cid:48) < i.

recent advances in id33

14(42)

connectedness, acyclicity and single-head

dependency syntax

(cid:73) intuitions:

(cid:73) syntactic structure is complete (connectedness).
(cid:73) syntactic structure is hierarchical (acyclicity).
(cid:73) every word has at most one syntactic head (single-head).

(cid:73) connectedness can be enforced by adding a special root node.

dobj

pmod

amod

nsubj

amod

prep

amod

root economic news had little e   ect on    nancial markets .
.
root

noun verb adj

noun prep

noun

adj

adj

recent advances in id33

15(42)

connectedness, acyclicity and single-head

dependency syntax

(cid:73) intuitions:

(cid:73) syntactic structure is complete (connectedness).
(cid:73) syntactic structure is hierarchical (acyclicity).
(cid:73) every word has at most one syntactic head (single-head).

(cid:73) connectedness can be enforced by adding a special root node.

p

root

dobj

pmod

amod

nsubj

amod

prep

amod

root economic news had little e   ect on    nancial markets .
.
root

noun verb adj

noun prep

noun

adj

adj

recent advances in id33

15(42)

dependency syntax

projectivity

(cid:73) most theoretical frameworks do not assume projectivity.
(cid:73) non-projective structures are needed to account for

(cid:73) long-distance dependencies,
(cid:73) free word order.

p

pobj

root

aux

prep

dobj

amod

nsubj

amod

root what did economic news have little e   ect on ?
noun prep .
root pron

noun verb

verb

adj

adj

recent advances in id33

16(42)

id33

(cid:73) the problem:

id33

(cid:73) input: sentence x = w0, w1, . . . , wn with w0 = root
(cid:73) output: dependency graph g = (v , a) for x where:

(cid:73) v = {0, 1, . . . , n} is the vertex set,
(cid:73) a is the arc set, i.e., (i, j, k)     a represents a dependency

from wi to wj with label lk     l

(cid:73) two main approaches:

(cid:73) grammar-based parsing

(cid:73) context-free dependency grammar
(cid:73) lexicalized context-free grammars
(cid:73) constraint dependency grammar

(cid:73) data-driven parsing

(cid:73) graph-based models
(cid:73) transition-based models
(cid:73) easy-   rst parsing
(cid:73) hybrids: grammar+data-driven, ensembles, etc.

recent advances in id33

17(42)

data-driven id33

id33

(cid:73) need to de   ne a function f : x     g

(cid:73) from sentences x     x to valid dependency graphs g     g
(cid:73) most common approach is to learn from training data t ,

(cid:73) where t = {(x1, g1), (x2, g2), . . . , (xn, gn)},
(cid:73) and (xi , gi ) are labeled sentence and dependency graph pairs

that make up the treebank.

(cid:73) supervised learning: fully annotated training examples
(cid:73) semi-supervised learning: annotated data plus constraints and

features drawn from unlabeled resources

(cid:73) id61: constraints drawn from

ontologies, structural and lexical resources

(cid:73) unsupervised learning: learning only from unlabeled data

recent advances in id33

18(42)

id74

id33

(cid:73) standard setup:

(cid:73) test set e = {(x1, g1), (x2, g2), . . . , (xn, gn)}
(cid:73) parser predictions p = {(x1, g(cid:48)
(cid:73) evaluation on the word (arc) level:

1), (x2, g(cid:48)

2), . . . , (xn, g(cid:48)

n)}

(cid:73) labeled attachment score (las) = head and label
(cid:73) unlabeled attachment score (uas) = head
(cid:73) label accuracy (la) = label

(cid:73) evaluation on the sentence (graph) level:

(cid:73) exact match (labeled or unlabeled) = complete graph

(cid:73) nb: id74 may or may not include punctuation

recent advances in id33

19(42)

graph-based parsing (pre-2008)

graph-based parsing

(cid:73) basic idea:

(cid:73) de   ne a space of candidate dependency graphs for a sentence.
(cid:73) learning: induce a model for scoring an entire dependency

graph for a sentence.

(cid:73) parsing: find the highest-scoring dependency graph, given the

induced model.

(cid:73) characteristics:

(cid:73) global training of a model for optimal dependency graphs
(cid:73) exhaustive search/id136

recent advances in id33

20(42)

graph-based parsing

graph-based parsing

(cid:73) for input sentence x de   ne a graph gx = (vx , ax ), where

(cid:73) vx = {0, 1, . . . , n}
(cid:73) ax = {(i, j, k)| i, j     v and lk     l}

(cid:73) key observation:

(cid:73) valid dependency trees for x = directed spanning trees of gx
(cid:73) score of dependency tree t factors by subgraphs g1, . . . , gm:

(cid:73) s(t ) =(cid:80)m

i=1 s(gi )

(cid:73) learning:

(cid:73) id136:

(cid:73) scoring function s(gi ) for subgraphs gi     g

(cid:73) search for maximum spanning tree t     of gx given s(gi )

recent advances in id33

21(42)

parameterizing graph-based parsing

graph-based parsing

(cid:73) first-order (arc-factored) model:

(cid:73) s(t = (v , a)) =(cid:80)

(i,j,k)   a s(i, j, k)

(cid:73) exact id136 in o(n2) time for non-projective trees using

the chu-liu-edmonds algorithm [mcdonald et al. 2005b]

recent advances in id33

22(42)

johnsawmaryroot91020930011330johnsawmaryroot103030parameterizing graph-based parsing

graph-based parsing

(cid:73) higher-order models [mcdonald and pereira 2006, carreras 2007]:

(cid:73) subgraphs gi involving a (small) number of arcs
(cid:73) intractable in non-projective case [mcdonald and satta 2007]
(cid:73) exact id136 in o(n3) time for projective trees with

second-order model using eisner   s algorithm [eisner 1996]

(cid:73) e   cient parsing requires that scores factor by small subgraphs

recent advances in id33

23(42)

learning graph-based models

graph-based parsing

(cid:73) typical scoring function:

(cid:73) s(gi ) = w    f(gi )

where

(cid:73) f(gi ) = high-dimensional feature vector over subgraphs
(cid:73) w = weight vector [wj = weight of feature fj (gi )]

(cid:73) structured learning [mcdonald et al. 2005a]:

(cid:73) learn weights that maximize the score of the correct
dependency tree for every sentence in the training set

(cid:73) learning is global (trees), but features are local (subgraphs)

recent advances in id33

24(42)

transition-based parsing (pre-2008)

transition-based parsing

(cid:73) basic idea:

(cid:73) de   ne a transition system (state machine) for mapping a

sentence to its dependency graph.

(cid:73) learning: induce a model for predicting the next state

transition, given the transition history.

(cid:73) parsing: construct the optimal transition sequence, given the

induced model.

(cid:73) characteristics:

(cid:73) local training of a model for optimal transitions
(cid:73) greedy search/id136

recent advances in id33

25(42)

transition-based parsing

transition-based parsing (pre-2008)

(cid:73) a transition system for id33 de   nes

(cid:73) a set c of parser con   gurations
(cid:73) a set t of transitions, each a function t : c     c
(cid:73) initial con   guration and terminal con   gurations for sentence x

(cid:73) key idea:

(cid:73) valid dependency trees for s de   ned by terminating transition

sequences c0,m = t1(c0), . . . , tm(cm   1)

(cid:73) score of c0,m factors by con   g-transition pairs (ci   1, ti ):

(cid:73) s(c0,m) =(cid:80)m

i=1 s(ci   1, ti )

(cid:73) learning:

(cid:73) id136:

(cid:73) scoring function s(ci   1, ti ) for ti (ci   1)     c0,m

(cid:73) search for highest scoring sequence c   

0,m given s(ci   1, ti )

recent advances in id33

26(42)

example: arc-eager projective parsing

transition-based parsing

con   guration:

initial:

terminal:

shift:

reduce:

right-arc(k):

left-arc(k):

[s = stack, b = bu   er, a = arcs]

(s, b, a)
([ ], [0, 1, . . . , n],{ })
(s, [ ], a)
(s, i|b, a)     (s|i, b, a)
(s|i, b, a)     (s, b, a)
(s|i, j|b, a)     (s|i|j, b, a     {(i, j, k)})
(s|i, j|b, a)     (s, j|b, a     {(j, i, k)})

h(i, a)

  h(i, a)     i (cid:54)= 0

recent advances in id33

27(42)

id136 for transition-based parsing

transition-based parsing

(cid:73) exact id136 intractable for standard transition systems
(cid:73) standard approach:

(cid:73) greedy (pseudo-deterministic) id136

[yamada and matsumoto 2003, nivre et al. 2004]

(cid:73) complexity given by upper bound on transition sequence length

(cid:73) transition systems:

(cid:73) projective o(n) [yamada and matsumoto 2003, nivre 2003]
(cid:73) limited non-projective o(n) [attardi 2006, nivre 2007]
(cid:73) unrestricted non-projective o(n2) [covington 2001, nivre 2008]

(cid:73) e   cient parsing requires approximate id136

recent advances in id33

28(42)

learning for transition-based parsing

transition-based parsing

(cid:73) typical scoring function:

(cid:73) s(c, t) = w    f(c, t)

where

(cid:73) f(c, t) = feature vector over con   guration c and transition t
(cid:73) w = weight vector [wj = weight of feature fj (c, t)]

(cid:73) simple classi   cation problem:

(cid:73) learn weights that maximize the score of the correct transition

out of every con   guration in the training set

(cid:73) con   gurations represent derivation history, including partially

built dependency tree

(cid:73) learning is local, but features are global

recent advances in id33

29(42)

conll 2006

mcdonald & nivre (2007)

(cid:73) conll 2006: shared task on id33

(cid:73) evaluation of 13 di   erent languages

(cid:73) top 2 systems statistically identical: one graph-based

(mstparser) and the other transition-based (maltparser)

(cid:73) question: do the systems learn the same things?

recent advances in id33

30(42)

mstparser and maltparser

mcdonald & nivre (2007)

mstparser maltparser

arabic
bulgarian
chinese
czech
danish
dutch
german
japanese
portuguese
slovene
spanish
swedish
turkish
overall

66.91
87.57
85.90
80.18
84.79
79.19
87.34
90.71
86.82
73.44
82.25
82.55
63.19
80.83

66.71
87.41
86.92
78.42
84.77
78.59
85.82
91.65
87.60
70.30
81.29
84.58
65.68
80.75

recent advances in id33

31(42)

mcdonald & nivre (2007)

comparing the models

(cid:73) id136:

(cid:73) exhaustive (mstparser)
(cid:73) greedy (maltparser)

(cid:73) training:

(cid:73) global structure learning (mstparser)
(cid:73) local decision learning (maltparser)

(cid:73) features:

(cid:73) local features (mstparser)
(cid:73) rich decision history (maltparser)

(cid:73) fundamental trade-o   :

(cid:73) global learning and id136 vs. rich feature space

recent advances in id33

32(42)

error analysis [mcdonald and nivre 2007]

mcdonald & nivre (2007)

(cid:73) aim:

(cid:73) relate parsing errors to linguistic and structural properties of

the input and predicted/gold standard dependency graphs

(cid:73) three types of factors:

(cid:73) length factors: sentence length, dependency length
(cid:73) graph factors: tree depth, branching factor, non-projectivity
(cid:73) linguistic factors: part of speech, dependency type

(cid:73) statistics:

(cid:73) labeled accuracy, precision and recall
(cid:73) computed over the test sets for all 13 languages

recent advances in id33

33(42)

sentence length

mcdonald & nivre (2007)

(cid:73) maltparser is more accurate than mstparser for short

sentences (1   10 words) but its performance degrades more
with increasing sentence length.

recent advances in id33

34(42)

102030405050+sentence length (bins of size 10)0.70.720.740.760.780.80.820.84dependency accuracymstparsermaltparserdependency length

mcdonald & nivre (2007)

(cid:73) maltparser is more precise than mstparser for short

dependencies (1   3 words) but its performance degrades
drastically with increasing dependency length (> 10 words).

(cid:73) mstparser has more or less constant precision for

dependencies longer than 3 words.

(cid:73) recall is very similar across systems.

recent advances in id33

35(42)

051015202530dependency length0.30.40.50.60.70.80.9dependency precisionmstparsermaltparser051015202530dependency length0.30.40.50.60.70.80.9dependency recallmstparsermaltparsertree depth (distance to root)

mcdonald & nivre (2007)

(cid:73) mstparser is much more precise than maltparser for

dependents of the root and has roughly constant precision for
depth > 1, while maltparser   s precision improves with
increasing depth (up to 7 arcs).

(cid:73) recall is very similar across systems.

recent advances in id33

36(42)

246810distance to root0.740.760.780.80.820.840.860.880.9dependency precisionmstparsermaltparser246810distance to root0.760.780.80.820.840.860.88dependency recallmstparsermaltparserdegrees of non-projectivity

mcdonald & nivre (2007)

(cid:73) degree of a dependency arc (i, j, k) = the number of words

in the span min(i, j), . . . , max(i, j) that are not descendants of
i and have their head outside the span.

(cid:73) maltparser has slightly higher precision, and mstparser

slightly higher recall, for non-projective arcs (degree > 0).

(cid:73) no system predicts arcs with a higher degree than 2.

recent advances in id33

37(42)

0 1 2+non-projective arc degree00.20.40.60.8dependency precisionmstparsermaltparser0 1 2+non-projective arc degree00.20.40.60.81dependency recallmstparsermaltparserpart of speech

mcdonald & nivre (2007)

(cid:73) mstparser is more accurate for verbs, adjectives, adverbs,

adpositions, and conjunctions.

(cid:73) maltparser is more accurate for nouns and pronouns.

recent advances in id33

38(42)

60.0%65.0%70.0%75.0%80.0%85.0%90.0%95.0%verbnounpronadjadvadposconjpart of speech (pos)labeled attachment score (las)mstparsermaltparserdependency type: root, subject, object

mcdonald & nivre (2007)

(cid:73) mstparser has higher precision (and recall) for roots.
(cid:73) mstparser has higher recall (and precision) for subjects.

recent advances in id33

39(42)

65.0%70.0%75.0%80.0%85.0%90.0%95.0%rootsubjobjdependency type (dep)dependency precisionmstparsermaltparser72.0%74.0%76.0%78.0%80.0%82.0%84.0%86.0%88.0%90.0%rootsubjobjdependency type (dep)dependency recallmstparsermaltparserdiscussion

mcdonald & nivre (2007)

(cid:73) many of the results are indicative of the fundamental

trade-o   : global learning/id136 versus rich features.

(cid:73) global id136 improves decisions for long sentences and

those near the top of graphs.

(cid:73) rich features improve decisions for short sentences and those

near the leaves of the graphs.

(cid:73) id33 post-2008:

(cid:73) how do we use this to improve parser performance?

recent advances in id33

40(42)

voting and stacking

mcdonald & nivre (2007)

(cid:73) early improvements were based on system combination
(cid:73) voting:

(cid:73) let parsers vote for heads [zeman and   zabokrtsk  y 2005]
(cid:73) use mst algorithm for tree constraint [sagae and lavie 2006]

(cid:73) stacking:

(cid:73) use the output of one parser as features for the other

[nivre and mcdonald 2008, torres martins et al. 2008]

(cid:73) focus today:

(cid:73) recent work evolving the approaches themselves
(cid:73) richer feature representations in graph-based parsing
(cid:73) improved learning and id136 in transition-based parsing

recent advances in id33

41(42)

summary

conclusion

(cid:73) dependency syntax     basic concepts
(cid:73) id33     graph-based and transition-based
(cid:73) empirical trade-o   s present way forward

recent advances in id33

42(42)

references and further reading

references and further reading
(cid:73) giuseppe attardi. 2006. experiments with a multilanguage non-projective

dependency parser. in proceedings of the 10th conference on computational
natural language learning (conll), pages 166   170.

(cid:73) xavier carreras. 2007. experiments with a higher-order projective dependency

parser. in proceedings of the joint conference on empirical methods in natural
language processing and computational natural language learning
(emnlp-conll), pages 957   961.

(cid:73) michael a. covington. 2001. a fundamental algorithm for id33. in

proceedings of the 39th annual acm southeast conference, pages 95   102.

(cid:73) ralph debusmann, denys duchier, and geert-jan m. kruij   . 2004. extensible
dependency grammar: a new methodology. in proceedings of the workshop on
recent advances in dependency grammar, pages 78   85.

(cid:73) denys duchier and ralph debusmann. 2001. topological dependency trees: a

constraint-based account of linear precedence. in proceedings of the 39th annual
meeting of the association for computational linguistics (acl), pages 180   187.
(cid:73) jason m. eisner. 1996. three new probabilistic models for id33: an
exploration. in proceedings of the 16th international conference on computational
linguistics (coling), pages 340   345.

recent advances in id33

42(42)

references and further reading

(cid:73) peter hellwig. 1986. dependency uni   cation grammar. in proceedings of the 11th
international conference on computational linguistics (coling), pages 195   198.
(cid:73) peter hellwig. 2003. dependency uni   cation grammar. in vilmos agel, ludwig m.
eichinger, hans-werner eroms, peter hellwig, hans j  urgen heringer, and hening
lobin, editors, dependency and valency, pages 593   635. walter de gruyter.

(cid:73) richard a. hudson. 1984. word grammar. blackwell.
(cid:73) richard a. hudson. 1990. english word grammar. blackwell.
(cid:73) richard hudson. 2007. language networks. the new word grammar. oxford

university press.

(cid:73) timo j  arvinen and pasi tapanainen. 1998. towards an implementable dependency

grammar. in sylvain kahane and alain polgu`ere, editors, proceedings of the
workshop on processing of dependency-based grammars, pages 1   10.

(cid:73) sandra k  ubler, joakim nivre, and ryan mcdonald. 2009. id33.

morgan & claypool publishers.

(cid:73) hiroshi maruyama. 1990. structural disambiguation with constraint propagation. in
proceedings of the 28th meeting of the association for computational linguistics
(acl), pages 31   38.

(cid:73) ryan mcdonald and joakim nivre. 2007. characterizing the errors of data-driven
id33 models. in proceedings of the join conference on empirical

recent advances in id33

42(42)

references and further reading

methods in natural language processing and the conference on computational
natural language learning (emnlp-conll).

(cid:73) ryan mcdonald and fernando pereira. 2006. online learning of approximate
id33 algorithms. in proceedings of the 11th conference of the
european chapter of the association for computational linguistics (eacl), pages
81   88.

(cid:73) ryan mcdonald and giorgio satta. 2007. on the complexity of non-projective

data-driven id33. in proceedings of the 10th international
conference on parsing technologies (iwpt), pages 122   131.

(cid:73) ryan mcdonald, koby crammer, and fernando pereira. 2005a. online

large-margin training of dependency parsers. in proceedings of the 43rd annual
meeting of the association for computational linguistics (acl), pages 91   98.

(cid:73) ryan mcdonald, fernando pereira, kiril ribarov, and jan haji  c. 2005b.

non-projective id33 using spanning tree algorithms. in proceedings
of the human language technology conference and the conference on empirical
methods in natural language processing (hlt/emnlp), pages 523   530.

(cid:73) igor mel     cuk. 1988. dependency syntax: theory and practice. state university of

new york press.

(cid:73) wolfgang menzel and ingo schr  oder. 1998. decision procedures for dependency
parsing using graded constraints. in sylvain kahane and alain polgu`ere, editors,

recent advances in id33

42(42)

references and further reading

proceedings of the workshop on processing of dependency-based grammars,
pages 78   87.

(cid:73) jasmina mili  cevi  c. 2006. a short guide to the meaning-text theory. journal of

koralex, 8:187   233.

(cid:73) joakim nivre and ryan mcdonald. 2008. integrating graph-based and

transition-based dependency parsers. in proceedings of the 46th annual meeting of
the association for computational linguistics (acl), pages 950   958.

(cid:73) joakim nivre, johan hall, and jens nilsson. 2004. memory-based dependency

parsing. in hwee tou ng and ellen rilo   , editors, proceedings of the 8th
conference on computational natural language learning (conll), pages 49   56.
(cid:73) joakim nivre. 2003. an e   cient algorithm for projective id33. in

gertjan van noord, editor, proceedings of the 8th international workshop on
parsing technologies (iwpt), pages 149   160.

(cid:73) joakim nivre. 2007. incremental non-projective id33. in

proceedings of human language technologies: the annual conference of the
north american chapter of the association for computational linguistics
(naacl-hlt), pages 396   403.

(cid:73) joakim nivre. 2008. algorithms for deterministic incremental id33.

computational linguistics, 34:513   553.

recent advances in id33

42(42)

references and further reading

(cid:73) kenji sagae and alon lavie. 2006. parser combination by reparsing. in proceedings

of the human language technology conference of the naacl, companion
volume: short papers, pages 129   132.

(cid:73) ingo schr  oder. 2002. natural language parsing with graded constraints. ph.d.

thesis, hamburg university.

(cid:73) petr sgall, eva haji  cov  a, and jarmila panevov  a. 1986. the meaning of the

sentence in its pragmatic aspects. reidel.

(cid:73) pasi tapanainen and timo j  arvinen. 1997. a non-projective dependency parser. in
proceedings of the 5th conference on applied natural language processing, pages
64   71.

(cid:73) lucien tesni`ere. 1959.   el  ements de syntaxe structurale. editions klincksieck.
(cid:73) andr  e filipe torres martins, dipanjan das, noah a. smith, and eric p. xing.

2008. stacking dependency parsers. in proceedings of the conference on empirical
methods in natural language processing, pages 157   166.

(cid:73) hiroyasu yamada and yuji matsumoto. 2003. statistical dependency analysis with

support vector machines. in gertjan van noord, editor, proceedings of the 8th
international workshop on parsing technologies (iwpt), pages 195   206.

recent advances in id33

42(42)

(cid:73) daniel zeman and zden  ek   zabokrtsk  y. 2005. improving parsing accuracy by

combining diverse dependency parsers. in proceedings of the ninth international
workshop on parsing technology, pages 171   178.

references and further reading

recent advances in id33

42(42)

