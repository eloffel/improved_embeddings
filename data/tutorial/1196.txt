recent advances in id33

tutorial, eacl, april 27th, 2014

ryan mcdonald1

joakim nivre2

1google inc., usa/uk

e-mail: ryanmcd@google.com

2uppsala university, sweden

e-mail: joakim.nivre@lingfil.uu.se

recent advances in id33

1(58)

overview of the tutorial

introduction

(cid:73) introduction to id33 (joakim)
(cid:73) graph-based parsing post-2008 (ryan)
(cid:73) transition-based parsing post-2008 (joakim)
(cid:73) summary and    nal thoughts (ryan)

recent advances in id33

2(58)

introduction

graph-based id33

recent advances in id33

3(58)

johnsawmaryroot91020930011330johnsawmaryroot103030introduction

overview

(cid:73) projective parsing

(cid:73) exact parsing via chart parsing
(cid:73) approximations

(cid:73) structure/features cascades
(cid:73) cube-pruning

(cid:73) non-projective

(cid:73) np-completeness
(cid:73) exact parsing

(cid:73) mst algorithms
(cid:73) integer id135

(cid:73) approximations

(cid:73) approximate id136
(cid:73) mildly non-projective structures

recent advances in id33

4(58)

graph-based parsing

graph-based parsing

(cid:73) for input sentence x de   ne a graph gx = (vx , ax ), where

(cid:73) vx = {0, 1, . . . , n}
(cid:73) ax = {(i, j, k)| i, j     v and j (cid:54)= 0 and lk     l}

recent advances in id33

5(58)

graph-based parsing

graph-based parsing

(cid:73) for input sentence x de   ne a graph gx = (vx , ax ), where

(cid:73) vx = {0, 1, . . . , n}
(cid:73) ax = {(i, j, k)| i, j     v and j (cid:54)= 0 and lk     l}

(cid:73) valid dependency trees for x equivalent to directed spanning

trees t of gx rooted at x0

recent advances in id33

5(58)

graph-based parsing

graph-based parsing

(cid:73) for input sentence x de   ne a graph gx = (vx , ax ), where

(cid:73) vx = {0, 1, . . . , n}
(cid:73) ax = {(i, j, k)| i, j     v and j (cid:54)= 0 and lk     l}

(cid:73) valid dependency trees for x equivalent to directed spanning

(cid:73) score of dependency tree t factors by subgraphs g1, . . . , gm:

trees t of gx rooted at x0

(cid:73) s(t ) =(cid:80)m

c=1 s(gc )

(cid:73) each gc need not be a subtree

recent advances in id33

5(58)

graph-based parsing

graph-based parsing

(cid:73) for input sentence x de   ne a graph gx = (vx , ax ), where

(cid:73) vx = {0, 1, . . . , n}
(cid:73) ax = {(i, j, k)| i, j     v and j (cid:54)= 0 and lk     l}

(cid:73) valid dependency trees for x equivalent to directed spanning

(cid:73) score of dependency tree t factors by subgraphs g1, . . . , gm:

trees t of gx rooted at x0

(cid:73) s(t ) =(cid:80)m

c=1 s(gc )

(cid:73) each gc need not be a subtree

(cid:73) learning: scoring function s(gc ) for subgraphs gc     g

recent advances in id33

5(58)

graph-based parsing

graph-based parsing

(cid:73) for input sentence x de   ne a graph gx = (vx , ax ), where

(cid:73) vx = {0, 1, . . . , n}
(cid:73) ax = {(i, j, k)| i, j     v and j (cid:54)= 0 and lk     l}

(cid:73) valid dependency trees for x equivalent to directed spanning

(cid:73) score of dependency tree t factors by subgraphs g1, . . . , gm:

trees t of gx rooted at x0

(cid:73) s(t ) =(cid:80)m

c=1 s(gc )

(cid:73) each gc need not be a subtree

(cid:73) learning: scoring function s(gc ) for subgraphs gc     g
(cid:73) id136: search for maximum spanning tree t     of gx

t     = argmax
t   gx

s(t ) = argmax

t   gx

s(gc )

m(cid:88)

c=1

recent advances in id33

5(58)

learning

graph-based parsing

(cid:73) we will assume scoring function is a linear classi   er

(cid:73) s(t ) =(cid:80)m

c=1 s(gc ) =(cid:80)m

c=1 w    f(gc )

recent advances in id33

6(58)

learning

graph-based parsing

(cid:73) we will assume scoring function is a linear classi   er

(cid:73) s(t ) =(cid:80)m

c=1 s(gc ) =(cid:80)m

c=1 w    f(gc )

(cid:73) f     rn is a feature representation of the subgraph gc

recent advances in id33

6(58)

learning

graph-based parsing

(cid:73) we will assume scoring function is a linear classi   er

(cid:73) s(t ) =(cid:80)m

c=1 s(gc ) =(cid:80)m

c=1 w    f(gc )

(cid:73) f     rn is a feature representation of the subgraph gc
(cid:73) w     rn is a corresponding parameter vector

recent advances in id33

6(58)

learning

graph-based parsing

(cid:73) we will assume scoring function is a linear classi   er

(cid:73) s(t ) =(cid:80)m

c=1 s(gc ) =(cid:80)m

c=1 w    f(gc )

(cid:73) f     rn is a feature representation of the subgraph gc
(cid:73) w     rn is a corresponding parameter vector

(cid:73) we will assume that learning is solved

(cid:73) linear scoring plus id136 allows us to use id88,

mira, etc. to    nd suitable w

(cid:73) this is not whole story ...

recent advances in id33

6(58)

parameterizing graph-based parsing

first-order projective parsing

first-order (arc-factored) model

(cid:73) scored subgraph gc is a single arc (i, j, k)
(i,j,k)   t s(i, j, k)

c=1 s(gc ) =(cid:80)

(cid:73) s(t ) =(cid:80)m
(cid:73) s(t ) =(cid:80)

(cid:73) often we drop k, since it is rarely structurally relevant

(i,j)   t s(i, j)
(cid:73) s(i, j) = maxk s(i, j, k)

recent advances in id33

7(58)

johnsawmaryroot91020930011330johnsawmaryroot103030parameterizing graph-based parsing

first-order projective parsing

first-order (arc-factored) model

(cid:73) scored subgraph gc is a single arc (i, j, k)
(i,j,k)   t s(i, j, k)

c=1 s(gc ) =(cid:80)

(cid:73) s(t ) =(cid:80)m
(cid:73) s(t ) =(cid:80)

(cid:73) often we drop k, since it is rarely structurally relevant

(i,j)   t s(i, j)
(cid:73) s(i, j) = maxk s(i, j, k)

(cid:73) this search is global: consider all possible trees

recent advances in id33

7(58)

johnsawmaryroot91020930011330johnsawmaryroot103030first-order projective parsing

eisner algorithm
[eisner 1996]

first-order projective parsing

recent advances in id33

8(58)

root      john          saw         mary30s(saw     mary) = 30s(saw     john) = 30300 + 30 = 300 + 30 = 3030 + 10 = 40s(root     saw) = 10000000040 + 30 = 70root      john          saw         marychart items either:1) create a new dependency2) absorb left/right subtreeeach chart item store two indexes:1) left boundary2) right boundaryall operations require3 indexes: o(n3)123feature scope

(cid:73) f     rn is a feature representation of the subgraph gc

first-order projective parsing

recent advances in id33

9(58)

first-order projective parsing

feature scope

(cid:73) f     rn is a feature representation of the subgraph gc
(cid:73) for    rst-order models, gc is an arc

(cid:73) i.e., gc = (i, j) for a head i and modi   er j

recent advances in id33

9(58)

first-order projective parsing

feature scope

(cid:73) f     rn is a feature representation of the subgraph gc
(cid:73) for    rst-order models, gc is an arc

(cid:73) i.e., gc = (i, j) for a head i and modi   er j

(cid:73) this inherently limits features to a local scope

recent advances in id33

9(58)

feature scope

first-order projective parsing

(cid:73) f     rn is a feature representation of the subgraph gc
(cid:73) for    rst-order models, gc is an arc

(cid:73) i.e., gc = (i, j) for a head i and modi   er j

(cid:73) this inherently limits features to a local scope

(cid:73) for arc (had, e   ect) below, can have features over properties

of arc and context within sentence

dobj

pmod

amod

nsubj

amod

prep

amod

economic news had little e   ect on    nancial markets

adj

noun verb

adj

noun prep

adj

noun

recent advances in id33

9(58)

feature scope

first-order projective parsing

(cid:73) f     rn is a feature representation of the subgraph gc
(cid:73) for    rst-order models, gc is an arc

(cid:73) i.e., gc = (i, j) for a head i and modi   er j

(cid:73) this inherently limits features to a local scope

(cid:73) for arc (had, e   ect) below, cannot have features over multiple

arcs (siblings, grandparents), valency, etc.

valency=2

dobj

pmod

amod

nsubj

amod

prep

amod

economic news had little e   ect on    nancial markets

adj

noun verb

adj

noun prep

adj

noun

recent advances in id33

9(58)

first-order projective parsing

graph-based parsing trade-o   
[mcdonald and nivre 2007]

(cid:73) learning and id136 are global

(cid:73) decoding guaranteed to    nd highest scoring tree
(cid:73) training algorithms use global structure learning

recent advances in id33

10(58)

first-order projective parsing

graph-based parsing trade-o   
[mcdonald and nivre 2007]

(cid:73) learning and id136 are global

(cid:73) decoding guaranteed to    nd highest scoring tree
(cid:73) training algorithms use global structure learning

(cid:73) but this is only possible with local feature factorizations

(cid:73) must limit context statistical model can look at
(cid:73) results in bad    easy    decisions

(cid:73) e.g., first-order models often predict two subjects
(cid:73) no parameter exists to discourage this

nsubj

nsubj

acomp

john smith was
noun
verb

noun

tall
adj

recent advances in id33

10(58)

first-order projective parsing

graph-based parsing trade-o   
[mcdonald and nivre 2007]

(cid:73) learning and id136 are global

(cid:73) decoding guaranteed to    nd highest scoring tree
(cid:73) training algorithms use global structure learning

(cid:73) but this is only possible with local feature factorizations

(cid:73) must limit context statistical model can look at
(cid:73) results in bad    easy    decisions

(cid:73) e.g., first-order models often predict two subjects
(cid:73) no parameter exists to discourage this

the major question in graph-based parsing has been how to

increase scope of features to larger subgraphs, without making

id136 intractable.

recent advances in id33

10(58)

exact higher-order projective parsing

higher-order parsing

(cid:73) two main dimensions of higher-order features

(cid:73) vertical: e.g.,    remain    is the grandparent of    emeritus   
(cid:73) horizontal: e.g.,    remain    is    rst child of    will   

recent advances in id33

11(58)

exact higher-order projective parsing

higher-order projective parsing

(cid:73) easy     just modify the chart
(cid:73) usually asymptotic increase with each order modeled
(cid:73) but we have a bag of tricks that help

recent advances in id33

12(58)

exact higher-order projective parsing

2nd-order horizontal projective parsing

(cid:73) score factors by pairs of horizontally adjacent arcs
(cid:73) often called sibling dependencies
(cid:73) s(i, j, j(cid:48)) is the score of creating adjacent arcs xi     xj and

xi     xj(cid:48)

(cid:88)

(i,j):(i,j(cid:48))   a

s(i, j, j(cid:48))

s(t ) =

= . . . + s(i0, i1, i2) + s(i0, i2, i3) + . . . + s(i0, ij   1, ij ) +

s(i0, ij+1, ij+2) + . . . + s(i0, im   1, im) + . . .

recent advances in id33

13(58)

2nd-order horizontal projective parsing

(cid:73) add a sibling chart item to get to o(n3)

exact higher-order projective parsing

recent advances in id33

14(58)

ijjj   jijj   ij   jj   is(i, j, j   )exact higher-order projective parsing

higher-order projective parsing

(cid:73) people played this game since 2006

(cid:73) mcdonald and pereira [2006] (2nd-order sibling)
(cid:73) carreras [2007] (2nd-order sibling and grandparent)
(cid:73) koo and collins [2010] (3rd-order grand-sibling and tri-sibling)
(cid:73) ma and zhao [2012] (4th-order grand-tri-sibling+)

recent advances in id33

15(58)

hmhmsgmhhorizontal contextvertical context* from koo et al. 2010 presentationhmss   gmhs11232o(n3)o(n3)o(n4)o(n4)o(n4)hmss   o(n5)gthird-order parsing [koo and collins 2010]

(cid:73) dynamic program grand-sibling component:

exact higher-order projective parsing

recent advances in id33

16(58)

exact higher-order projective parsing

approximate higher-order projective parsing

(cid:73) can be done via chart augmentation
(cid:73) but there are drawbacks

(cid:73) o(n4), o(n5), . . . is just too slow
(cid:73) every type of higher order feature requires specialized chart

items and combination rules

recent advances in id33

17(58)

exact higher-order projective parsing

approximate higher-order projective parsing

(cid:73) can be done via chart augmentation
(cid:73) but there are drawbacks

(cid:73) o(n4), o(n5), . . . is just too slow
(cid:73) every type of higher order feature requires specialized chart

items and combination rules

(cid:73) led to research on approximations

(cid:73) bohnet [2010]: feature hashing, parallelization
(cid:73) koo and collins [2010]:    rst-order marginal probabilities
(cid:73) bergsma and cherry [2010]: classi   er arc    ltering
(cid:73) cascades

(cid:73) rush and petrov [2012]: id170 cascades
(cid:73) he et al. [2013]: dynamic feature selection

(cid:73) zhang and mcdonald [2012], zhang et al. [2013]: cube-pruning

recent advances in id33

17(58)

approximate higher-order projective parsing

id170 cascades
[rush and petrov 2012]

(cid:73) lower-order models prune space for higher order models

(cid:73) weiss et al. [2010]: train level n w.r.t. to level n + 1
(cid:73) vine-parsing allows linear    rst stage [dreyer et al. 2006]
(cid:73) 100x+ faster than unpruned 3rd-order model with small

accuracy loss (93.3   93.1) [rush and petrov 2012]

recent advances in id33

18(58)

dynamic feature selection [he et al. 2013]

approximate higher-order projective parsing

(cid:73) observation: feature computations dominate parsing time
(cid:73) incrementally increase size and scope of features

(cid:73) multiple    rst-order models with di   erent feature sizes

(cid:73) prune away low con   dence options
(cid:73) compared to id170 cascades:

(cid:73) empirically, about 50% slower, but . . .
(cid:73) . . . results in smaller accuracy drops

recent advances in id33

19(58)

approximate higher-order projective parsing

cube pruning
[zhang and mcdonald 2012, zhang et al. 2013]

(cid:73) keep eisner o(n3) as back bone
(cid:73) use chart item k-best lists to score higher order features

(cid:73) always o(n3) asymptotically
(cid:73) no specialized chart parsing algorithms

recent advances in id33

20(58)

i0i1i2i0i1i2i0i1i2i3i4i5i3i4i5i3i4i5i0     i5s(i0     i5     i4)s(i0     i5     i3)example:grandparent featuresprojective parsing summary

projective parsing summary

(cid:73) can augment chart (dynamic program) to increase scope of

features

(cid:73) but comes at complexity cost

(cid:73) solution: use pruning approximations

en-uas zh-uas

1st order exact
2nd order exact
3rd order exact   
4th order exact   
struct. pred. casc.   

cube-pruning(cid:63)

91.8
92.4
93.0
93.4
93.1
93.5

84.4
86.6
86.8
87.4

   

87.9

   [koo and collins 2010],    [ma and zhao 2012],    [rush and petrov 2012], (cid:63)[zhang et al. 2013]

cube-pruning is 2x slower than id170 cascades and 5x faster than third-order

recent advances in id33

21(58)

non-projective parsing

non-projective parsing

(cid:73) first-order (arc-factored) parsing

(cid:73) mcdonald et al. [2005]: equivalent to maximum spanning tree

(mst) problem

(cid:73) for directed graphs, also called arboresence problem
(cid:73) o(n2) parsing [chu and liu 1965, edmonds 1967]
(cid:73) greedy algorithm, not id145

p

pobj

root

aux

prep

dobj

amod

nsubj

amod

root what did economic news have little e   ect on ?
noun prep .
root

noun verb

verb

adj

adj

adj

recent advances in id33

22(58)

higher-order non-projective parsing

non-projective parsing

(cid:73) mcdonald and satta [2007]:
(cid:73) parsing is np-hard for all

higher-order features

(cid:73) horizontal, vertical, valency, etc.
(cid:73) even seemingly simple arc features like    is this the only

modi   er    result in intractability

recent advances in id33

23(58)

higher-order non-projective parsing

non-projective parsing

(cid:73) projective parsing

(cid:73) exact parsing via chart parsing
(cid:73) approximations

(cid:73) structure/features cascades
(cid:73) cube-pruning

(cid:73) non-projective

(cid:73) np-completeness
(cid:73) exact parsing

(cid:73) mst algorithms
(cid:73) integer id135

(cid:73) approximations

(cid:73) approximate id136
(cid:73) mildly non-projective structures

recent advances in id33

24(58)

higher-order non-projective parsing

non-projective parsing

(cid:73) projective parsing

(cid:73) exact parsing via chart parsing
(cid:73) approximations

(cid:73) structure/features cascades
(cid:73) cube-pruning

(cid:73) non-projective

(cid:73) np-completeness
(cid:73) exact parsing

(cid:73) mst algorithms
(cid:73) integer id135

(cid:73) approximations

(cid:73) approximate id136
(cid:73) mildly non-projective structures

recent advances in id33

24(58)

higher-order non-projective parsing

non-projective parsing

(cid:73) projective parsing

(cid:73) exact parsing via chart parsing
(cid:73) approximations

(cid:73) structure/features cascades
(cid:73) cube-pruning

(cid:73) non-projective

(cid:73) np-completeness
(cid:73) exact parsing

(cid:73) mst algorithms
(cid:73) integer id135

(cid:73) approximations

(cid:73) approximate id136
(cid:73) mildly non-projective structures

recent advances in id33

24(58)

exact non-projective parsing

integer id135 (ilp)

(cid:73) for a sentence x = x1 . . . xn and dependency graph g , let:

(cid:73)   ij = 1 i        (i, j)     g , for i, j     {1, . . . , n}
(cid:73)   ij = 0 otherwise

recent advances in id33

25(58)

exact non-projective parsing

integer id135 (ilp)

(cid:73) for a sentence x = x1 . . . xn and dependency graph g , let:

(cid:73)   ij = 1 i        (i, j)     g , for i, j     {1, . . . , n}
(cid:73)   ij = 0 otherwise

(cid:73) for example, for x and g

root

dobj

pmod

amod

nsubj

amod

prep

amod

root0 economic1 news2 had3
noun verb
root

adj

little4 e   ect5
adj

noun prep

on6    nancial7 markets8

adj

noun

(cid:73)   03,   31,   35,   21,   54,   56,   68,   87 equal 1
(cid:73) all other   ij = 0

recent advances in id33

25(58)

exact non-projective parsing

integer id135 (ilp)

(cid:73) for a sentence x = x1 . . . xn and dependency graph g , let:

(cid:73)   ij = 1 i        (i, j)     g , for i, j     {1, . . . , n}
(cid:73)   ij = 0 otherwise

(cid:73) for example, for x and g

root

dobj

pmod

amod

nsubj

amod

prep

amod

root0 economic1 news2 had3
noun verb
root

adj

little4 e   ect5
adj

noun prep

on6    nancial7 markets8

adj

noun

(cid:73)   03,   31,   35,   21,   54,   56,   68,   87 equal 1
(cid:73) all other   ij = 0
(cid:73) let      be the set of all   ij

recent advances in id33

25(58)

integer id135 (ilp)

(cid:73) ilp: linear objective function with linear constraints

exact non-projective parsing

recent advances in id33

26(58)

integer id135 (ilp)

exact non-projective parsing

(cid:73) ilp: linear objective function with linear constraints
(cid:73) first-order id136:

(cid:88)

  ij        

     = argmax

    

  ij s(i, j)

recent advances in id33

26(58)

integer id135 (ilp)

exact non-projective parsing

(cid:73) ilp: linear objective function with linear constraints
(cid:73) first-order id136:

(cid:88)

  ij        

     = argmax

    

  ij s(i, j)

subject to:

2) one head per word:     j     {1, . . . , n}, (cid:80)

1) single root:   i0 = 0

i   ij = 1

recent advances in id33

26(58)

integer id135 (ilp)

exact non-projective parsing

(cid:73) ilp: linear objective function with linear constraints
(cid:73) first-order id136:

(cid:88)

  ij        

     = argmax

    

  ij s(i, j)

subject to:

2) one head per word:     j     {1, . . . , n}, (cid:80)

1) single root:   i0 = 0

i   ij = 1

(cid:73) but this permits cycles!

root

dobj

pmod

amod

nsubj

amod

prep

amod

root0 economic1 news2 had3
noun verb
root

adj

little4 e   ect5
adj

noun prep

on6    nancial7 markets8

adj

noun

recent advances in id33

26(58)

exact non-projective parsing

integer id135 (ilp)

(cid:73) getting rid of cycles

(cid:73) cycle constraints: constraints exponential in size (worst case)

[riedel and clarke 2006]

(cid:73) auxiliary path variables, constraint cubic in size

[k  ubler et al. 2009]

(cid:73) arc    ow variables   , constraints quadratic in size

[martins et al. 2009]

recent advances in id33

27(58)

root0saw2john1mary3311exact non-projective parsing

integer id135 (ilp)

(cid:73) getting rid of cycles

(cid:73) cycle constraints: constraints exponential in size (worst case)

[riedel and clarke 2006]

(cid:73) auxiliary path variables, constraint cubic in size

[k  ubler et al. 2009]

(cid:73) arc    ow variables   , constraints quadratic in size

[martins et al. 2009]

root emits n    ow: (cid:80)
flow-in minus    ow-out is 1: (cid:80)

j   0j = n

flow is positive i    arc is included:   ij     n  ij

i,k   ij       jk = 1

recent advances in id33

27(58)

root0saw2john1mary3311integer id135 (ilp)

exact non-projective parsing

(cid:73) martins et al. [2009]    rst-order id136:

(cid:88)

  ij        

     = argmax

    

  ij s(i, j)

subject to:

1) single root:   i0 = 0

2) one head per word:     j     {1, . . . , n}, (cid:80)
3) root emits n    ow: (cid:80)
4) flow-in minus    ow-out is 1: (cid:80)

j   0j = n

5) flow is positive i    arc is included:   ij     n  ij

i,k   ij       jk = 1

i   ij = 1

recent advances in id33

28(58)

integer id135 (ilp)

exact non-projective parsing

(cid:73) martins et al. [2009]    rst-order id136:

(cid:88)

  ij        

     = argmax

    

  ij s(i, j)

subject to:

1) single root:   i0 = 0

2) one head per word:     j     {1, . . . , n}, (cid:80)
3) root emits n    ow: (cid:80)
4) flow-in minus    ow-out is 1: (cid:80)

j   0j = n

5) flow is positive i    arc is included:   ij     n  ij

i,k   ij       jk = 1

i   ij = 1

martins et al. [2010]: multi-commodity    ow formulation, with cubic

sized constraints, makes the lp relaxation tight.

recent advances in id33

28(58)

integer id135 (ilp)

exact non-projective parsing

(cid:73) ilp id136 is in general intractable

(cid:73) so why do we bother?

recent advances in id33

29(58)

integer id135 (ilp)

exact non-projective parsing

(cid:73) ilp id136 is in general intractable

(cid:73) so why do we bother?

(cid:73) there are very e   cient o   -the-shelf optimizers, e.g., cplex

recent advances in id33

29(58)

integer id135 (ilp)

exact non-projective parsing

(cid:73) ilp id136 is in general intractable

(cid:73) so why do we bother?

(cid:73) there are very e   cient o   -the-shelf optimizers, e.g., cplex
(cid:73) can easily be expanded

(cid:73) adding arc labels
(cid:73) adding grammar rules, e.g.,    at most one subject per verb   
(cid:73) higher-order parsing

recent advances in id33

29(58)

integer id135 (ilp)

exact non-projective parsing

(cid:73) higher-order example: grandparent features (g     h     m)
(cid:73) let   ijk = 1 i    (i, j), (j, k)     g , 0 otherwise
(cid:73) let s(i, j, k) be the grandparent dependency score

(cid:88)

  ij        

(cid:88)

  ijk        

  ij s(i, j) +

  ijk s(i, j, k)

    ,      = argmax

    ,     

subject to:

1) single root:   i0 = 0
. . .
6) grandparent consistency:

  ijk       ij ,   ijk       jk ,   ijk       ij +   jk     1

recent advances in id33

30(58)

approximate non-projective parsing

approximate higher-order non-projective parsing

(cid:73) ilp: as constraint set grows, search slows
(cid:73) higher order parsing: asymptotic increase in constraint set size
(cid:73) alternative: branch and bound [qian and liu 2013]

recent advances in id33

31(58)

approximate non-projective parsing

approximate higher-order non-projective parsing

(cid:73) ilp: as constraint set grows, search slows
(cid:73) higher order parsing: asymptotic increase in constraint set size
(cid:73) alternative: branch and bound [qian and liu 2013]

(cid:73) approximations (some return optimal in practice)

(cid:73) approximate id136: t     = argmax t   gx s(t )
(cid:73) post-processing [mcdonald and pereira 2006],

[hall and nov  ak 2005], [hall 2007]

(cid:73) id209
(cid:73) belief propagation [smith and eisner 2008]
(cid:73) lp relaxations [riedel et al. 2012]
(cid:73) sampling [nakagawa 2007]

(cid:73) approximate search space: t     = argmaxt   gx s(t )

(cid:73) mildly non-projective structures

recent advances in id33

31(58)

approximate higher-order non-projective parsing

id209

(cid:73) consider second-order horizontal scoring s(i, j, j(cid:48))
(cid:73) let mi = {mk = j |     j s.t. (i, j)     t and mk > mk   1}
(cid:73) i.e., mi is the ordered set of modi   er indexes for arcs with

head xi in a tree t

root

dobj

pmod

amod

nsubj

amod

prep

amod

root0 economic1 news2 had3
noun verb
root

adj

little4 e   ect5
adj

noun prep

on6    nancial7 markets8

adj

noun

(cid:73) e.g. m3 = {2, 5} and m5 = {4, 6}

recent advances in id33

32(58)

id209

approximate higher-order non-projective parsing

(cid:73) we can re-write the second-order sibling score of a tree as

(cid:88)

s(t ) =

(i,j):(i,j(cid:48))   t

n(cid:88)

|mi|(cid:88)

i=0

k=2

s(i, j, j(cid:48)) =

s(i, mk   1, mk )

(cid:73) (i, j) : (i, j(cid:48))     t means arcs (i, j) and (i, j(cid:48)) are adjacent in t
(cid:73) i.e., for each word, we can sum over the second-order modi   er

scores, independently of the other words

recent advances in id33

33(58)

approximate higher-order non-projective parsing

id209

(cid:88)

(i,j):(i,j(cid:48))   gx

s(t ) =

s(i, j, j(cid:48)) =

n(cid:88)

|mi|(cid:88)

i=0

k=2

s(i, mk   1, mk )

(cid:73) koo et al. [2010] point out that inner sum can be solved with a

semi-markov viterbi algorithm in o(n2)

(cid:73) for head word xi , let si [j] be the score of the best sequence of

modi   ers for i with right-most modi   er xj

si [j] = maxk<j s(i, k, j) + si [k]

(cid:73) there are o(n) cells to    ll each takes o(n) due to the max
(cid:73) find highest si [j] for each i and follow back-pointers

recent advances in id33

34(58)

approximate higher-order non-projective parsing

id209

(cid:73) for each head word xi , compute si [j]     o(n3)!

root

root what did economic news have little e   ect on

amod

root what did economic news have little e   ect on

aux

nsubj

dobjprep

root what did economic news have little e   ect on

amod

root what did economic news have little e   ect on

pobj

root what did economic news have little e   ect on

recent advances in id33

35(58)

approximate higher-order non-projective parsing

id209

(cid:73) for each head word xi , compute si [j]     o(n3)!

root

root what did economic news have little e   ect on

amod

root what did economic news have little e   ect on

aux

nsubj

dobjprep

root what did economic news have little e   ect on

amod

root what did economic news have little e   ect on

pobj

root what did economic news have little e   ect on

put it together

root

aux
amod

pobj

nsubj

dobjprep
amod

root what did economic news have little e   ect on

recent advances in id33

35(58)

approximate higher-order non-projective parsing

id209

(cid:73) why does this not work? no tree constraint!

root

root what did economic news have little e   ect on

amod

root what did economic news have little e   ect on

aux

nsubj

dobj [

root what did economic news have little e   ect on

amod

[

root what did economic news have little e   ect on

prep

root what did economic news have little e   ect on

put it together

root

aux
amod

pobj

nsubj

dobjprep
amod

prep

root what did economic news have little e   ect on

recent advances in id33

36(58)

id209

approximate higher-order non-projective parsing

(cid:73) first-order o(n2) model with tree constraint exists

(cid:73) mst algorithm [chu and liu 1965, edmonds 1967]

(cid:73) second-order o(n3) model without tree constraint exists

(cid:73) the o(n3) sibling decoding algorithm

recent advances in id33

37(58)

id209

approximate higher-order non-projective parsing

(cid:73) first-order o(n2) model with tree constraint exists

(cid:73) mst algorithm [chu and liu 1965, edmonds 1967]

(cid:73) second-order o(n3) model without tree constraint exists

(cid:73) the o(n3) sibling decoding algorithm

(cid:73) id209 [koo et al. 2010]
(cid:73) add components for each feature

(cid:73) independently calculate each e   ciently
(cid:73) tie together with agreement (disagreement) constraints

(penalties)

(cid:73) sub-id119 of lagrangian relaxation

[held and karp 1971, komodakis et al. 2007, komodakis et al. 2011]

(cid:73) dual decomp in nlp [rush et al. 2010, collins and rush 2011]

recent advances in id33

37(58)

approximate higher-order non-projective parsing

id209

(cid:73) for a sentence x = x1 . . . xn, let:

recent advances in id33

38(58)

id209

approximate higher-order non-projective parsing

(cid:73) for a sentence x = x1 . . . xn, let:

(cid:73) s1o(t ) be the    rst-order score of a tree t

(cid:73) t1o = argmaxt   gx s1o(t )

recent advances in id33

38(58)

id209

approximate higher-order non-projective parsing

(cid:73) for a sentence x = x1 . . . xn, let:

(cid:73) s1o(t ) be the    rst-order score of a tree t

(cid:73) s2o(g ) be the second-order sibling score of a graph g

(cid:73) t1o = argmaxt   gx s1o(t )

(cid:73) g2o = argmaxg   gx s2o(g )

recent advances in id33

38(58)

id209

approximate higher-order non-projective parsing

(cid:73) for a sentence x = x1 . . . xn, let:

(cid:73) s1o(t ) be the    rst-order score of a tree t

(cid:73) t1o = argmaxt   gx s1o(t )

(cid:73) s2o(g ) be the second-order sibling score of a graph g

(cid:73) g2o = argmaxg   gx s2o(g )

(cid:73) de   ne structural variables

(cid:73) t1o(i, j) = 1 if (i, j)     t1o, 0 otherwise
(cid:73) g2o(i, j) = 1 if (i, j)     g2o, 0 otherwise

recent advances in id33

38(58)

id209

approximate higher-order non-projective parsing

(cid:73) for a sentence x = x1 . . . xn, let:

(cid:73) s1o(t ) be the    rst-order score of a tree t

(cid:73) t1o = argmaxt   gx s1o(t )

(cid:73) s2o(g ) be the second-order sibling score of a graph g

(cid:73) g2o = argmaxg   gx s2o(g )

(cid:73) de   ne structural variables

(cid:73) t1o(i, j) = 1 if (i, j)     t1o, 0 otherwise
(cid:73) g2o(i, j) = 1 if (i, j)     g2o, 0 otherwise

(cid:73) what we really want to    nd is

t = argmax

t   gx

s1o(t ) + sso(t )

(cid:73) i.e., the tree that has highest score under    rst and second

order models

recent advances in id33

38(58)

id209

approximate higher-order non-projective parsing

(cid:73) for a sentence x = x1 . . . xn, let:

(cid:73) s1o(t ) be the    rst-order score of a tree t

(cid:73) t1o = argmaxt   gx s1o(t )

(cid:73) s2o(g ) be the second-order sibling score of a graph g

(cid:73) g2o = argmaxg   gx s2o(g )

(cid:73) de   ne structural variables

(cid:73) t1o(i, j) = 1 if (i, j)     t1o, 0 otherwise
(cid:73) g2o(i, j) = 1 if (i, j)     g2o, 0 otherwise

(cid:73) this is equivalent to:

(t , g ) = argmax
t   gx ,g   gx

s1o(t ) + sso(g )

s.t. t1o(i, j) = g2o(i, j),     i, j     n

recent advances in id33

38(58)

id209

approximate higher-order non-projective parsing

(t , g ) = argmax
t   gx ,g   gx

s1o(t ) + sso(g ), s.t. t1o(i, j) = g2o(i, j)

algorithm sketch

recent advances in id33

39(58)

id209

approximate higher-order non-projective parsing

(t , g ) = argmax
t   gx ,g   gx

s1o(t ) + sso(g ), s.t. t1o(i, j) = g2o(i, j)

algorithm sketch

for k = 1 to k

recent advances in id33

39(58)

id209

approximate higher-order non-projective parsing

(t , g ) = argmax
t   gx ,g   gx

s1o(t ) + sso(g ), s.t. t1o(i, j) = g2o(i, j)

algorithm sketch

for k = 1 to k
1. t1o = argmaxt   gx s1o(t )     p //    rst-order decoding

recent advances in id33

39(58)

id209

approximate higher-order non-projective parsing

(t , g ) = argmax
t   gx ,g   gx

s1o(t ) + sso(g ), s.t. t1o(i, j) = g2o(i, j)

algorithm sketch

for k = 1 to k
1. t1o = argmaxt   gx s1o(t )     p //    rst-order decoding
2. g2o = argmaxg   gx s2o(t ) + p // second-order decoding

recent advances in id33

39(58)

id209

approximate higher-order non-projective parsing

(t , g ) = argmax
t   gx ,g   gx

s1o(t ) + sso(g ), s.t. t1o(i, j) = g2o(i, j)

algorithm sketch

for k = 1 to k
1. t1o = argmaxt   gx s1o(t )     p //    rst-order decoding
2. g2o = argmaxg   gx s2o(t ) + p // second-order decoding
3. if t1o(i, j) = g2o(i, j),     i, j, return t1o

recent advances in id33

39(58)

id209

approximate higher-order non-projective parsing

(t , g ) = argmax
t   gx ,g   gx

s1o(t ) + sso(g ), s.t. t1o(i, j) = g2o(i, j)

algorithm sketch

for k = 1 to k
1. t1o = argmaxt   gx s1o(t )     p //    rst-order decoding
2. g2o = argmaxg   gx s2o(t ) + p // second-order decoding
3. if t1o(i, j) = g2o(i, j),     i, j, return t1o
4. else update penalties p and go to 1

recent advances in id33

39(58)

id209

approximate higher-order non-projective parsing

(t , g ) = argmax
t   gx ,g   gx

s1o(t ) + sso(g ), s.t. t1o(i, j) = g2o(i, j)

algorithm sketch

for k = 1 to k
1. t1o = argmaxt   gx s1o(t )     p //    rst-order decoding
2. g2o = argmaxg   gx s2o(t ) + p // second-order decoding
3. if t1o(i, j) = g2o(i, j),     i, j, return t1o
4. else update penalties p and go to 1

if k is reached, return t1o from last iteration

recent advances in id33

39(58)

id209

approximate higher-order non-projective parsing

(t , g ) = argmax
t   gx ,g   gx

s1o(t ) + sso(g ), s.t. t1o(i, j) = g2o(i, j)

algorithm sketch

for k = 1 to k
1. t1o = argmaxt   gx s1o(t )     p //    rst-order decoding
2. g2o = argmaxg   gx s2o(t ) + p // second-order decoding
3. if t1o(i, j) = g2o(i, j),     i, j, return t1o
4. else update penalties p and go to 1

what are the penalties p?

recent advances in id33

39(58)

approximate higher-order non-projective parsing

id209

(cid:73) let p(i, j) = t1o(i, j)     g2o(i, j)
(cid:73) p is the set of all penalties p(i, j)

recent advances in id33

40(58)

id209

approximate higher-order non-projective parsing

(cid:73) let p(i, j) = t1o(i, j)     g2o(i, j)
(cid:73) p is the set of all penalties p(i, j)
(cid:73) we rewrite the decoding objectives as:

s1o(t )    (cid:88)
(cid:88)

i,j

s2o(g ) +

i,j

p(i, j)    t1o(i, j)

p(i, j)    g2o(i, j)

t1o = argmax

t   gx

g2o = argmax

g   gx

(cid:73) i.e., reward trees/graphs that agree with other model

recent advances in id33

40(58)

id209

approximate higher-order non-projective parsing

(cid:73) let p(i, j) = t1o(i, j)     g2o(i, j)
(cid:73) p is the set of all penalties p(i, j)
(cid:73) we rewrite the decoding objectives as:

s1o(t )    (cid:88)
(cid:88)

i,j

s2o(g ) +

i,j

p(i, j)    t1o(i, j)

p(i, j)    g2o(i, j)

t1o = argmax

t   gx

g2o = argmax

g   gx

(cid:73) i.e., reward trees/graphs that agree with other model
(cid:73) since t1o and g2o are arc-factored indicator variables, we can

easily include in decoding

(cid:73) e.g., s(i, j) = s(i, j)     p(i, j) for    rst-order model

recent advances in id33

40(58)

approximate higher-order non-projective parsing

id209     1-iter example

first-order

root

pobj

aux

amod

nsubj

dobjprep
amod

root0 what1 d  economic3 news4 have5

little6 e   ect7 on8

second-order sibling

root

aux
amod

pobj

nsubj

dobjprep
amod

prep

root0 what1 d  economic3 news4 have5

little6 e   ect7 on8

penalties: p(5, 3) = 1, p(4, 3) =    1, p(7, 8) =    1
   rst-order: s1o(5, 3)    = 1, s1o(4, 3) += 1, s1o(7, 8) += 1

second-order: s2o(5,   , 3) += 1, s2o(4,   , 3)    = 1, s2o(7,   , 8)    = 1

*indicates any sibling, even null if it is    rst left/right modi   er.

recent advances in id33

41(58)

id209

approximate higher-order non-projective parsing

goal : (t , g ) = argmax
t   gx ,g   gx

s1o(t )+sso(g ), s.t. t1o(i, j) = g2o(i, j)

for k = 1 to k

1. t1o = argmaxt   gx s1o (t )     p //    rst-order decoding
2. g2o = argmaxg   gx s2o (t ) + p // second-order decoding
3.

if t1o (i, j) = g2o (i, j),     i, j, return t1o

4. else update penalties p and go to 1

(cid:73) penalties push scores towards agreement
(cid:73) this optimization is sub-id119 on the lagrangian

relaxation formulation [komodakis et al. 2007]

      s1o (t )    (cid:88)

i,j

l(p) = argmax
t   gx ,g   gx

p(i, j)    t1o (i, j)

       +

      sso (g ) +

      

p(i, j)    g2o (i, j)

(cid:88)

i,j

(cid:73) theorem: if for any k, line 3 holds, then decoding is optimal

recent advances in id33

42(58)

approximate higher-order non-projective parsing

id209

(cid:73) collins and rush [2011] has easy to follow proofs
(cid:73) koo et al. [2010]: grandparents, grand-sibling, tri-siblings
(cid:73) martins et al. [2011, 2013]

(cid:73) extensions to arbitrary siblings, head bigrams
(cid:73) alternating direction method of multipliers (admm)

(cid:73) adds penalty to the average solution from previous iterations
(cid:73) speeds up id136 by factor of 2     10

independent solutions

1st order
2nd order
3rd order

uas
90.52
91.85
92.41

[martins et al. 2013]

recent advances in id33

43(58)

approximate higher-order non-projective parsing

mildly non-projective structures

(cid:73) dual decomp., belief propagation, branch and bound, etc.

(cid:73) approximates search over space of entire trees
(cid:73) t = argmax t   gx s(t )

recent advances in id33

44(58)

mildly non-projective structures

approximate higher-order non-projective parsing

(cid:73) dual decomp., belief propagation, branch and bound, etc.

(cid:73) approximates search over space of entire trees
(cid:73) t = argmax t   gx s(t )

(cid:73) another approach is to approximate search space

(cid:73) t = argmaxt   gx s(t )
(cid:73) de   ne restricted search space gx :

1. allow e   cient decoding
2. still cover all linguistically plausible structures

(cid:73) such restrictions called mildly non-projective structures

recent advances in id33

44(58)

mildly non-projective structures

approximate higher-order non-projective parsing

(cid:73) dual decomp., belief propagation, branch and bound, etc.

(cid:73) approximates search over space of entire trees
(cid:73) t = argmax t   gx s(t )

(cid:73) another approach is to approximate search space

(cid:73) t = argmaxt   gx s(t )
(cid:73) de   ne restricted search space gx :

1. allow e   cient decoding
2. still cover all linguistically plausible structures

(cid:73) such restrictions called mildly non-projective structures

(cid:73) do we really care about scoring such structures?

aux
aux

aux

aux

aux

aux

aux

aux

aux

aux

aux

aux

aux

aux aux
aux

0 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16

recent advances in id33

44(58)

approximate higher-order non-projective parsing

mildly non-projective structures

(cid:73) consider the sentence:

(cid:73) eisner   s algorithm gets stuck

(cid:73) can   t complete right subtree rooted at    arrived   

recent advances in id33

45(58)

root      what           do           you         think        arrivedmildly non-projective structures
(cid:73) but, we can add new chart items and rules

approximate higher-order non-projective parsing

recent advances in id33

46(58)

o(n4)1234neither head   what    has no headroot     what           do           you         think        arrivedmildly non-projective structures

approximate higher-order non-projective parsing

(cid:73) that solves that sentence, but not this one

aux

aux

aux

aux

aux
aux

aux

aux

aux

root yesterday , what do you think arrived ?

(cid:73) try it!

recent advances in id33

47(58)

mildly non-projective structures

approximate higher-order non-projective parsing

(cid:73) that solves that sentence, but not this one

aux

aux

aux

aux

aux
aux

aux

aux

aux

root yesterday , what do you think arrived ?

(cid:73) try it!

(cid:73) want a general solution that:
1. has large empirical coverage
2. can characterize coverage by structural/linguistic properties

recent advances in id33

47(58)

mildly non-projective structures

approximate higher-order non-projective parsing

(cid:73) well-nested block-degree 2 [bodirsky et al. 2005]

(cid:73) ltag-like algorithms: o(n7)    [g  omez-rodr    guez et al. 2011]
(cid:73) + 1-inherit: o(n6) [pitler et al. 2012]

(cid:73) empirical coverage identical to well-nested block-degree 2

(cid:73) + head-split: o(n6) [satta and kuhlmann 2013]

(cid:73) empirical coverage similar to well-nested block-degree 2
(cid:73) + head-split + 1-inherit: o(n5) [satta and kuhlmann 2013]

(cid:73) gap minding trees: o(n5) [pitler et al. 2012]
(cid:73) 1-endpoint-crossing: o(n4) [pitler et al. 2013]

   all run-times are for    rst-order parsing

recent advances in id33

48(58)

1-endpoint-crossing [pitler et al. 2013]

approximate higher-order non-projective parsing

(cid:73) an arc a, is 1-endpoint-crossing i    all arcs a(cid:48) that cross a

have a common endpoint p

(cid:73) an endpoint p is either a head or a modi   er in an arc
(cid:73) e.g., (arrived, what) is crossed by (root,think) and (think,?),

both have endpoint    think   

aux

aux
aux

aux

aux

aux

root what do you think arrived ?

recent advances in id33

49(58)

1-endpoint-crossing

approximate higher-order non-projective parsing

(cid:73) 1-endpoint-crossings have good empirical coverage
(cid:73) on conll-x data sets [buchholz and marsi 2006]

class

projective

well-nested block-degree 2

gap-minding

1-endpoint-crossing

[pitler et al. 2013]

tree coverage

80.8
98.4
95.1
98.5

macro average over arabic, czech, danish, dutch, portuguese

recent advances in id33

50(58)

approximate higher-order non-projective parsing

1-endpoint-crossing

(cid:73) can we design an algorithm that parses all and only

1-endpoint-crossing trees?

(cid:73) pitler et al. [2013] provides the solution

recent advances in id33

51(58)

ijinterval representing a contiguous sub-tree from i to jonly edges with endpoint at left may cross exterior point pbothneitheronly edges with endpoint at right may cross exterior point pijijijijppppapproximate higher-order non-projective parsing

1-endpoint-crossing

(cid:73) can we design an algorithm that parses all and only

1-endpoint-crossing trees?

(cid:73) pitler et al. [2013] provides the solution
(cid:73) pitler   s algorithm works by de   ning 5 types of intervals

recent advances in id33

51(58)

ijinterval representing a contiguous sub-tree from i to jonly edges with endpoint at left may cross exterior point pbothneitheronly edges with endpoint at right may cross exterior point pijijijijppppapproximate higher-order non-projective parsing

1-endpoint-crossing

(cid:73) can we design an algorithm that parses all and only

1-endpoint-crossing trees?

(cid:73) pitler et al. [2013] provides the solution
(cid:73) pitler   s algorithm works by de   ning 5 types of intervals

(cid:73) location of exterior point, direction of arcs, etc, controlled via

variables, similar to eisner [1996] projective formulation

recent advances in id33

51(58)

ijinterval representing a contiguous sub-tree from i to jonly edges with endpoint at left may cross exterior point pbothneitheronly edges with endpoint at right may cross exterior point pijijijijppppapproximate higher-order non-projective parsing

1-endpoint-crossing

(cid:73) pitler et al. [2013]
de   nes operations
on intervals

(cid:73) o(n4) algorithm

parses exactly
1-endpoint-crossing
trees

(cid:73) intuition    

recent advances in id33

52(58)

ijikjlkllkiljilo(n4)1-endpoint-crossing

approximate higher-order non-projective parsing

(cid:73) 1-endpoint-crossings have good empirical coverage . . .
(cid:73) . . . and low run-time
(cid:73) on conll-x data sets [buchholz and marsi 2006]

class

projective

well-nested block-degree 2

gap-minding

1-endpoint-crossing

tree coverage run-time

80.8
98.4
95.1
98.5

o(n3)
o(n7)
o(n5)
o(n4)

[pitler et al. 2013]

macro average over arabic, czech, danish, dutch, portuguese

recent advances in id33

53(58)

1-endpoint-crossing

approximate higher-order non-projective parsing

(cid:73) can be linguistically motivated [pitler et al. 2013]
(cid:73) cross-serial verb constructions [shieber 1985]

aux

nsubj

amod
prep

amod

root

der mer

em hans

es huus h  alfed aastriiche

(cid:73) phrase-impenetrability condition (pic) [chomsky 1998]

(cid:73) only head and edge words of phrase accessible to sentence
(cid:73) long-distance elements leave chain of traces at clause edges
(cid:73) pitler et al. [2013] conjecture: pic implies 1-endpoint-crossing

recent advances in id33

54(58)

1-endpoint-crossing

approximate higher-order non-projective parsing

(cid:73) so what? mst algorithm does arc-factored parsing in o(n2)
(cid:73) but, mst algorithm is greedy = hard to augment
(cid:73) dynamic prog. = easy augmentation for higher-order features

(cid:73) e.g., higher-order projective parsing

recent advances in id33

55(58)

1-endpoint-crossing

approximate higher-order non-projective parsing

(cid:73) so what? mst algorithm does arc-factored parsing in o(n2)
(cid:73) but, mst algorithm is greedy = hard to augment
(cid:73) dynamic prog. = easy augmentation for higher-order features

(cid:73) e.g., higher-order projective parsing

(cid:73) pitler [2014]: 1-endpoint-crossing + third-order

(cid:73) merge of pitler et al. [2013] and koo and collins [2010]
(cid:73) searches 1-endpoint-crossing trees
(cid:73) scores higher-order features when no crossing arc present
(cid:73) o(n4)     identical to third-order projective!
(cid:73) signi   cant improvements in accuracy

recent advances in id33

55(58)

mildly non-projective structures

approximate higher-order non-projective parsing

(cid:73) summary

(cid:73) de   ne restricted space of non-projective trees
(cid:73) de   ne id145 algorithms that parse them
(cid:73) 1-endpoint-crossings: o(n4) third-order parsing

(cid:73) next steps

(cid:73) combine with pruning: cascades or cube-pruning
(cid:73) add structural restrictions to ilps, dual decomp., etc.

(cid:73) structural constraints could lead to improved id136

recent advances in id33

56(58)

summary

conclusion

(cid:73) graph-based parsing:

(cid:73) expanding feature scope with new id136 techniques
(cid:73) maintain global search and learning properties with minimal

approximations

(cid:73) recent advances in synergy:

(cid:73) pruning: id170 cascades and cube-pruning
(cid:73) exact non-projective parsing via ilp
(cid:73) id209 and other approximate search methods
(cid:73) mildly non-projective structures

recent advances in id33

57(58)

references and further reading

references and further reading
(cid:73) shane bergsma and colin cherry. 2010. fast and accurate arc    ltering for
id33. in proceedings of the 23rd international conference on
computational linguistics (coling), pages 53   61.

(cid:73) manuel bodirsky, marco kuhlmann, and mathias m  ohl. 2005. well-nested
drawings as models of syntactic structure. in tenth conference on formal
grammar and ninth meeting on mathematics of language.

(cid:73) bernd bohnet. 2010. very high accuracy and fast id33 is not a

contradiction. in proceedings of the 23rd international conference on
computational linguistics, pages 89   97. association for computational linguistics.

(cid:73) sabine buchholz and erwin marsi. 2006. conll-x shared task on multilingual
id33. in proceedings of the tenth conference on computational
natural language learning, pages 149   164.

(cid:73) xavier carreras. 2007. experiments with a higher-order projective dependency

parser. in proceedings of the joint conference on empirical methods in natural
language processing and computational natural language learning
(emnlp-conll), pages 957   961.

(cid:73) noam chomsky. 1998. minimalist inquiries: the framework. mit working papers

in linguistics, mit, department of linguistics.

recent advances in id33

57(58)

references and further reading

(cid:73) y. j. chu and t. j. liu. 1965. on the shortest arborescence of a directed graph.

science sinica, 14:1396   1400.

(cid:73) michael collins and alexander m rush. 2011. id209 for natural

language processing. in tutorial abstracts of acl 2011, page 6, portland, oregon,
usa, june. association for computational linguistics.

(cid:73) markus dreyer, david a smith, and noah a smith. 2006. vine parsing and
minimum risk reranking for speed and precision. in proceedings of the tenth
conference on computational natural language learning, pages 201   205.
association for computational linguistics.

(cid:73) j. edmonds. 1967. optimum branchings. journal of research of the national

bureau of standards, 71b:233   240.

(cid:73) jason m. eisner. 1996. three new probabilistic models for id33: an
exploration. in proceedings of the 16th international conference on computational
linguistics (coling), pages 340   345.

(cid:73) carlos g  omez-rodr    guez, john carroll, and david weir. 2011. id33

schemata and mildly non-projective id33. computational
linguistics, 37(3):541   586.

(cid:73) keith hall and v  aclav nov  ak. 2005. corrective modeling for non-projective
id33. in proceedings of the ninth international workshop on
parsing technology, pages 42   52. association for computational linguistics.

recent advances in id33

57(58)

references and further reading

(cid:73) keith hall. 2007. k-best spanning tree parsing. in proceedings of the association

for computational linguistics (acl).

(cid:73) he he, hal daum  e iii, and jason eisner. 2013. dynamic feature selection for
id33. in proceedings of empirical methods in natural language
processing (emnlp).

(cid:73) michael held and richard m karp. 1971. the traveling-salesman problem and

minimum spanning trees: part ii. mathematical programming, 1(1):6   25.

(cid:73) nikos komodakis, nikos paragios, and georgios tziritas. 2007. mrf optimization

via id209: message-passing revisited. in id161, 2007.
iccv 2007. ieee 11th international conference on, pages 1   8. ieee.

(cid:73) nikos komodakis, nikos paragios, and georgios tziritas. 2011. mrf energy

minimization and beyond via id209. pattern analysis and machine
intelligence, ieee transactions on, 33(3):531   552.

(cid:73) terry koo and michael collins. 2010. e   cient third-order dependency parsers. in

proceedings of the 48th annual meeting of the association for computational
linguistics, pages 1   11. association for computational linguistics.

(cid:73) terry koo, alexander m rush, michael collins, tommi jaakkola, and david

sontag. 2010. id209 for parsing with non-projective head automata.
in proceedings of the 2010 conference on empirical methods in natural language
processing, pages 1288   1298. association for computational linguistics.

recent advances in id33

57(58)

references and further reading

(cid:73) sandra k  ubler, joakim nivre, and ryan mcdonald. 2009. id33.

morgan & claypool publishers.

(cid:73) xuezhe ma and hai zhao. 2012. fourth-order id33. in proceedings

of the conference on computational linguistics (coling), pages 785   796.

(cid:73) andr  e ft martins, noah a smith, and eric p xing. 2009. concise integer linear
programming formulations for id33. in proceedings of the joint
conference of the 47th annual meeting of the acl and the 4th international joint
conference on natural language processing of the afnlp: volume 1-volume 1,
pages 342   350. association for computational linguistics.

(cid:73) andr  e ft martins, noah a smith, eric p xing, pedro mq aguiar, and m  ario at
figueiredo. 2010. turbo parsers: id33 by approximate variational
id136. in proceedings of the 2010 conference on empirical methods in natural
language processing, pages 34   44. association for computational linguistics.

(cid:73) andr  e ft martins, noah a smith, pedro mq aguiar, and m  ario at figueiredo.
2011. id209 with many overlapping components. in proceedings of
the conference on empirical methods in natural language processing, pages
238   249. association for computational linguistics.

(cid:73) andr  e ft martins, miguel b almeida, and noah a smith. 2013. turning on the

turbo: fast third-order non-projective turbo parsers. in proceedings of the
association for computational linguistics.

recent advances in id33

57(58)

references and further reading

(cid:73) ryan mcdonald and joakim nivre. 2007. characterizing the errors of data-driven
id33 models. in proceedings of the join conference on empirical
methods in natural language processing and the conference on computational
natural language learning (emnlp-conll).

(cid:73) ryan mcdonald and fernando pereira. 2006. online learning of approximate
id33 algorithms. in proceedings of the 11th conference of the
european chapter of the association for computational linguistics (eacl), pages
81   88.

(cid:73) ryan mcdonald and giorgio satta. 2007. on the complexity of non-projective

data-driven id33. in proceedings of the 10th international
conference on parsing technologies (iwpt), pages 122   131.

(cid:73) ryan mcdonald, fernando pereira, kiril ribarov, and jan haji  c. 2005.

non-projective id33 using spanning tree algorithms. in proceedings
of the human language technology conference and the conference on empirical
methods in natural language processing (hlt/emnlp), pages 523   530.

(cid:73) tetsuji nakagawa. 2007. multilingual id33 using global features. in

emnlp-conll, pages 952   956.

(cid:73) emily pitler, sampath kannan, and mitchell marcus. 2012. id145

for higher order parsing of gap-minding trees. in proceedings of the 2012 joint
conference on empirical methods in natural language processing and

recent advances in id33

57(58)

references and further reading

computational natural language learning, pages 478   488. association for
computational linguistics.

(cid:73) emily pitler, sampath kannan, and mitchell marcus. 2013. finding optimal
1-endpoint-crossing trees. transactions of the association for computational
linguistics (tacl).

(cid:73) emily pitler. 2014. a crossing-sensitive third-order factorization for dependency
parsing. transactions of the association for computational linguistics (tacl).

(cid:73) xian qian and yang liu. 2013. branch and bound algorithm for dependency

parsing with non-local features. transactions of the association for computational
linguistics (tacl), 1:37   48.

(cid:73) sebastian riedel and james clarke. 2006. incremental integer id135
for non-projective id33. in proceedings of the 2006 conference on
empirical methods in natural language processing, pages 129   137. association
for computational linguistics.

(cid:73) sebastian riedel, david smith, and andrew mccallum. 2012. parse, price and cut:
delayed column and row generation for graph based parsers. in proceedings of the
2012 joint conference on empirical methods in natural language processing and
computational natural language learning, pages 732   743. association for
computational linguistics.

recent advances in id33

57(58)

references and further reading

(cid:73) alexander m rush and slav petrov. 2012. vine pruning for e   cient multi-pass

id33. in proceedings of the 2012 conference of the north american
chapter of the association for computational linguistics: human language
technologies, pages 498   507. association for computational linguistics.

(cid:73) alexander m rush, david sontag, michael collins, and tommi jaakkola. 2010. on

id209 and id135 relaxations for natural language
processing. in proceedings of the 2010 conference on empirical methods in natural
language processing, pages 1   11. association for computational linguistics.

(cid:73) giorgio satta and marco kuhlmann. 2013. e   cient parsing for head-split

dependency trees. transactions of the association for computational linguistics,
1(july):267   278.

(cid:73) stuart shieber. 1985. evidence against the context-freeness of natural language.

linguistics and philosophy.

(cid:73) david a smith and jason eisner. 2008. id33 by belief propagation.

in proceedings of the conference on empirical methods in natural language
processing, pages 145   156. association for computational linguistics.

(cid:73) david weiss, benjamin sapp, and ben taskar. 2010. sidestepping intractable

id136 with structured ensemble cascades. in proceesings of neural information
processing systems (nips).

recent advances in id33

57(58)

references and further reading

(cid:73) hao zhang and ryan mcdonald. 2012. generalized higher-order dependency
parsing with cube pruning. in proceedings of the 2012 joint conference on
empirical methods in natural language processing and computational natural
language learning, pages 320   331. association for computational linguistics.
(cid:73) liang zhang, huang, kai zhao, and ryan mcdonald. 2013. online learning for

inexact hypergraph search. in proceedings of empirical methods in natural
language processing.

recent advances in id33

57(58)

