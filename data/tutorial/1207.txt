spectral learning
part i

geoff gordon
http://www.cs.cmu.edu/~ggordon/
machine learning department
carnegie mellon university

http://www.cs.cmu.edu/~ggordon/spectral-learning/

what is spectral learning?
machine learning is hard:    tting a good model = optimization with lots of local optima (e.g., learning id48s 

is provably at least as hard as factoring big numbers)
in some cases, by setting up the problem another way, we can avoid the difficult optimization entirely -- 

different set of tradeoffs (e.g., give up learning the factoring id48, but make it a lot easier to learn other useful 
id48s)

what is spectral learning good for?  we   ll look at some examples...

replace it with a spectral problem (= based on matrix eigenvalues/vectors)

the  fsu and the  ibu  w e r e  employed t o  protect the 
no&&.  they  could  not  be  used  on  an  operational 
airplane  without  predetermining  the  control  laws  i n  
the  ibu.  this action  would  negate  the  need  for  the 

(without  flutter  suppression)  flutter boundary.  the 
flutter  points  are  sham  as  solid  circles.  the 
adaptive wing-   utter suppression
f l u t m   mode  was  antisymmetric  and  the  flutter 
shown  on  figwe  6,  as apen 
frequency  was  8.6  hz. 
are  the  wind  tunnel  conditions  that  w e r e  
spt+s, 
several 
achieved  with 
different parameters sets. 

parameter  sets 

the  afss  engaged,  with 
airspeed (mach)
i o  
1

mach number 
6 
1

8 
1

i 
1

3 

5 

1

1

1

j 

i 
1

three 

f o r   a l l  

turing  the  wind  tunnel  demonstration,  several 
parameters i n  the afss  algorithm w e r e  varied.  for  an 
    high speeds can 
operational  aircraft  the  prameter  set  would  be 
fixed.  the  purpose of  varying  the parameters during 
excite aircraft 
the  demonstration  was  t o  determine  the parameter  set 
that produced  the best  afss  performance and the  best 
wing resonances
s t o r e  
common  parameter  set 
    spectral lti 
the  number  of  time  increments  in the data window 
was  varied.  tests were  conduded  with  data windows 
system id adapts 
containing  400,  800,  1600,  and 2000 tine  incretnents 
which  correspond t o  4,  8,  16,  and 20 seconds of  data, 
online: use last 1s 
of    ight data to 
two  sets of  the  q  and r  weighting  matrices  in 
the  control  algorithm,  defined  by equations  (15)  and 
id, derive lqg 
controller, repeat
the  feedback  signal  could  be  multiplied  by  a 
feedback  coefficient  (gain).  feedback  coefficients 
of  0.5,  0.75,  1.0,  and 2.0 were tested. 

2 
1

5.00 

3.50 

0
q
/
q
 
e
r
u
s
9 __ 
s
' ref 
e
r
p
 
c
m
a
n
y
d

i

3.00 

2.50 

2  00 

1.50 

1 00 
.90 
.bo 
.70 

.60 

3 0  

.40 

adaptive    utter 

suppression

   utter boundary 
before suppression

! i  
1

1 1  
1

i 1  
1

 

speed of sound

]
0
9
9
1
 
c
d
c
, 
g
n
d
o
b
 
&

l

i

 
r
e

l
l

a
h
, 
t
e
b
u
o
e
p
[

l

.30 

laws  are  mre  effective 

figure  6  s t o r e   configuration  3 3  

in 
suppressing  flutter than others.  an  attempt  was  mde 
t o  implement  a  rationale  for deciding  whether  a  new 
contml  law  should  replace  the  current control  law  or 
be  discarded.  a  s f l   (signal  t o   noise)  ratio  was 
camputed.  the  s/n  ratio  was  defined  as the  square 
mt  of  the  quotient  of  the measured  sensor  respnse 
the  difference 
response  and  the 
predicted  sensor  response  averaged  over  a  data 
window.  when  the  s/n  ratio for any  of  the three afss 
sensors  exceded  a  preset 
the  updatd 
otherwise,  it  was 
implemented. 
discarded.  the  threshold  sett-  was  tested over  a 
range  f r m   0  to  6.  when  the  threshold  is  set  t o  
zero, every  updated  control  law was  implemented. 

geoff gordon   icml tutorial   july, 2012
resonances depend on conditions   e.g., external fuel tanks attached at hard points   so, they can   t easily be 
prior  t o  testing  the  m s ,  a  bcl was  acquind. 
eliminated at design time
with  the k!l  waged,  the model was  tested to a speed 
plot from wind tunnel tests w/ full-span wing model   intended to simulate 1990s-era    ghter jet   typical    utter 
that  was  30  percent  above  the  unaugmented  flutter 
frequency 8.6hz
lmxday.  subsequently,  the wind  tunnel  was  rduced 
ibu  was 
t o  a  pomt  belaw  the  flutter boundary. 
plot shows tests w/ one wing con   guration   not all tests moved the    utter boundary this much, and achievable 
disengaged and the thresholds for the sensors used  in 
the  square  of 
speed varied widely depending on con   guration (e.g., one con   guration went from mach 0.95 (before suppression) 
the  fsu w e r e   set.  then  the  wind  tunnel  speed  was 
to 1.05 (after))
sensor 
increase2  to  confirm that  the  fsu  would  engage  the 
ibu as the flutter b0urkh-y was  approached. 
sensing was with 3 pairs of accelerometers placed on wing
for  each  parameter  set,  the  wind  -ne1  was 
control was by actuating aircraft    aperons (wing surfaces) on top of input from pilot   100hz updates
increased until  the wind  tunnel  objective was  reached 
or the fsu engaged  the ieu, whichever occurred f i r s t .  
old-school: learning implemented on a vax 11/750
a  pass was  defined  as a  test  of  the afss from  belaw 
the  f l u t t e r  boundary t o  the maximum tested condition 
===
and a  retum t o  below  the  flutter boundary.  s a w  52 
dynamic pressure = kinetic energy of a    xed volume of air hitting the wing
passes w e r e   conducted  for store configuration  33. 

threshold 

2

a  dead  band  could  be  placed  in  the  feedback 
the  feedback  signal  was  zero  unless  it 
exceeded  the  dead  band  expressed  in  degrees  of 
ccummndeed  flaperon  deflection.  the  afss was  tested 
with  the dead band set a t  0",  _+0.05", and 20.1'. 

the  size  of  the  i n i t i a l   number  of  id113s  that 
were  collected  after a  store drop  for the purpose  of 
cxmputing  the  initial  control  law  wuld  be varied. 
hawever,  this prameter  was  set  a t   100  (1 sec  of 
data)  throughout  the wind  tunnel  demonstration. 
the  best  cammon  parameter  set  for  a l l   three 
store  configurations  consisted  of  800  samples in the 
the  weighting 
matrices,  0.5  feedback  coefficient,  zero s/n  ratio, 

[q]=l  and  i+l 

for 

wind  tunnel tests 

an 

a c t u a t o r  

f a i l u r e   was 

simulated  by 
deactivating  the  left  flaperon  actuator  while  the 
afss  was  suppressing  flutter  a t   a  point  30  percent 
above  the  unauqtented  flutter  velocity.  me  afss 
continu&  t o  maintain control. 
above  the unaucpxted  flutter speed  the afss was 
disengaged  t o   allow  the  flutter  mtion  t o   increase 
until  the  fsu  engaged  the  ibu  while  movies  w e r e  
for  several  parameter sets the  wind  tunnel 
taken. 
was  reduced rapidly  and the m s  mintained control. 
ten sbndated store drops w e r e  conducted and only one 
caused the fsu t o  erigage  the ibu. 
store confiquration  73 

intuition: bottleneck

data about past
(many samples)

predict

t

e
a
t
s

data about future
(many samples)

compress

expand

bottleneck

can    nd best rank-k bottleneck via matrix 

factorization (cid:15482) spectral method

geoff gordon   icml tutorial   july, 2012
for id173, don   t just want a state: want a low-d (hopefully minimal) one
so, select k (linear combinations of) predictions which explain as much variance in future as possible

3

video textures

(train from a short video, then simulate learned model)

fountain

steam grate

observation = raw pixels (vector of reals over time)

[siddiqi, boots & gordon, 2007; 

geoff gordon   icml tutorial   july, 2012
both this example and the last one: learned model is a linear time invariant (lti) system (aka kalman    lter)
spectral algorithms for lti systems have been known for decades   but recently it was discovered that we can use 
spectral algorithms to learn more-interesting models

4

doretto & soatto 2006]

video textures, redux

original

kalman filter

psr

both models: 10 latent dimensions

geoff gordon   icml tutorial   july, 2012
reason for failure of kalman: gaussian is log-concave.  so, if two images are likely, their *average* is at least as 
likely.
so: we need a *nonlinear*    lter

5

learning to parse

[cohen, stratos, collins, foster & ungar, acl 2012]

s

np-sbj

vp

pp

np

np

i saw the man with the telescope

    treebanks commonly 
used to train parsers
    but manual tags typically 
don   t make    ne-enough 
distinctions to enable 
local decisions by parser
    e.g., helps to label nps 
with gender, number, 
mass/count, animate/
inanimate, human/
nonhuman,    

geoff gordon   icml tutorial   july, 2012
6
parse is from id32, omitting annotation of ambiguity -- could have been (np (np the man) (pp with the 
telescope))
the extra labels would help parsing, but they   re not available   could we simulate them?

learning to parse

[cohen, stratos, collins, foster & ungar, acl 2012]

s
, z1

np-sbj

, z2

vp

, z3

pp

, z5

np

, z4

np

, z6

i saw the man with the telescope

    re   ne manual tags w/ 
learned latent variables
    each latent depends on 
neighboring tags and 
latents
    learn to    ll in latents by 
trying to explain training 
parses
    spectral method leads 
to low-d latents

geoff gordon   icml tutorial   july, 2012
7
intuition: to determine latent at each node, predict (features of) inside context from outside context, and vice versa
advantages of spectral: very fast to train (can handle bigger data sets); no need to think of a smart initialization to 
defeat local optima; can bene   t from arbitrary smart features computed from inside and outside contexts
but so far, smart initialization of em to    nd id113 still gets best    nal parsing accuracy

id44

  : overall topic frequencies
dirichlet(  )

  d: topic frequencies in document d 

multinomial(  d)
zwd: topic for word w of doc d

multinomial(  (zwd))

   
   
   

identity of word w of doc d

words
docs

[blei, ng and jordan, jmlr 2003]
[anandkumar et al., arxiv 2012]

  (z): word 
distribution for 

topic z

lda: famous example of not 
knowing when mcmc converges
spectral: single global optimum

geoff gordon   icml tutorial   july, 2012
but, practical implementation of spectral method still in progress

8

structure from motion

]
2
9
9
1
, 
e
d
a
n
a
k
&

 

 
i
s
a
m
o
t
[

geoff gordon   icml tutorial   july, 2012
measurement matrix = 2d image positions of tracked features over time

9

red lines indicate ground truth data and blue lines indicate reconstructed data.

structure from motion

nonrigid 

version: learn a 
model of how 
shape changes 

over time

10

[akter, sheikh, khan & kanade, tpami 2011]

(b)

geoff gordon   icml tutorial   july, 2012
grey line: recovered
black dots: ground truth

fig. 8. structure recovery for multiple walk dataset containing 8 people with different walking styles. (a) shows
the recovered structure (gray circles) and ground truth (black dots) for one frame. (b) shows the recovered 3d
trajectories (gray solid line) and ground truth trajectories (black dotted line) of some points of a walk in the dataset.
it also shows the recovered structure for the starting and ending frame.

draft

the problems: id136 & learning

observed

hidden

geoff gordon   icml tutorial   july, 2012
some structure of mrf or factor graph
some nodes always hidden
some nodes always or usually observed in training data (but perhaps not in test)
variables may be discrete, continuous, mixed; structure may vary from example to example (so long as there are 
common pieces)

11

the data

many replicates of 

our network

geoff gordon   icml tutorial   july, 2012
either: repeated observations of same graph, or   

12

the data

    or many common substructures 

carved out of one big network

geoff gordon   icml tutorial   july, 2012
... repeated structure in one or a few big graphs 
need repetition one way or the other so that we have a chance to learn something
could also have a similar sliding window for trees

13

the data

test time: some vars observed 

in training set are missing

geoff gordon   icml tutorial   july, 2012
for simplicity of notation, assume for now repeated observations of same graph

14

exact solutions

    id136: belief propagation
    problem: exponential in treewidth (base = arity)
    continuous vars: exponential in diameter too
    learning: maximum likelihood
    e.g., id119 or em
    problem: id136 is a subtask
    problem: lots of local optima

geoff gordon   icml tutorial   july, 2012
id136 is (very!) hard in general
learning is (very very!) hard in general
any hope of computationally efficient learning and id136?  yes, w/ (surprisingly weak) assumptions, using 
id106

15

key ideas for spectral learning

    spectral bottleneck

    predictive state

[a bunch of control theorists in    80s;
van overschee & de moor, automatica, 1993]

[littman, sutton, singh, nips 2001]

    observable representation of model

[jaeger, neural computation, 1999]

geoff gordon   icml tutorial   july, 2012
already seen bottleneck idea
predictive state: next
observable rep   n: later


expresses model in terms of predictive state and direct observables

16

predictive state

use a vector of 
predictions of 
(features of) 

observables as state

geoff gordon   icml tutorial   july, 2012
e.g., in movie, predicted future pixels
e.g., in parse tree, predicted nonterminals on opposite side of current nonterminal
here, we need predictions of pixels from at least two frames (to capture both position and direction of pendulum).
predictions are e(features of future observations).  predictive state can represent uncertainty: e.g., uncertain 
position leads to average image of pendulum in various positions.  (this smeared-out image doesn   t mean that 
we will ever see the pendulum in multiple states at once, only that we are uncertain where it will be.)
why do we want a predictive state?  easier to interpret, easier to learn.  e.g., if learning algorithm wants an 
unbiased estimate of current state, all it has to do is wait and see what the future looks like.
in some cases we know a good set of features to predict (examples include id48, kalman, characteristic rkhs); if 
not, we guess feature space (typical ml feature engineering problem)

17

predictive state: minimal example

2
3
1
3
0

1
4
0
3
4
0

p(st | st   1) =          
p(ot | st   1) =     1
ot =     2

          = t
1     = o
8     w
    e([  (ot+1)       (ot+k)] | st) = wst with w invertible

0
2
3
1
3
1
0

2
3
1
3

0
7

2
1
2

3
1
3

geoff gordon   icml tutorial   july, 2012
here we derive a predictive state for a simple id48 (exact numbers don   t matter)
transition matrix t, observation matrix o
given state s, current expected observation is os
next state is ts, so next expected observation is ots, etc.
pick w to be any 3 linearly independent rows of o, ot, ott, ottt, etc.
note: may not be able to get an invertible w under non-observability: e.g., 2 distinct hidden states w/ identical 
transitions and observations.  but in this case we can pick a representative of each equivalence class of states, and 
use the corresponding pseudoinverse.

18

start simple

x

yy

xx x, . . .)

p(y | x) = n (  yx     1
id136: normal equations
learning: estimate   xx 
and   xy from data

p(x, y) = n (0,   )

  =       xx   xy
  yx   yy    

19

geoff gordon   icml tutorial   july, 2012
2d gaussian case; training data has (x,y), while test data has x and we need to predict y
normal equations give bayes rule update for e(y | x)
learning is just estimating covariances (= id75)

another simple case

p(y | x) = p(x, y)/p(x)

x

y

p(x,y)

 

0
0
0
1
0
0
1
0
0
0
0
0
0
0
x    y

x

 

y

0.035
0.03
0.025
0.02
0.015
0.01
0.005

geoff gordon   icml tutorial   july, 2012
small number of discrete outcomes: p(x,y) speci   ed by a id203 table, can implement bayes rule exactly by 
iterating over table

20

id136

  xx

  xy

0
0
1
0
0
0
0
1
0
0
0
0
0
0
x    y

0 0 0 0
0 0 0 0
0 0 0 0
0 1 0 0
0 0 0 0
0 0 0 0
0 0 0 0

0
0
0
0
0
0
0

0
0
0
0
0
0
0

                              

0
0
0
0
0
0
0

                              

  xx = e(xx   )

  xy = e(xy   )

[  xx]ii = p(x = ei)
p(x) = x     xxx

[  xy]ij = p(x = ei, y = ej)
p(x, y) = x     xyy

geoff gordon   icml tutorial   july, 2012
to connect to gaussian case, let   s look at covariances
can write everything needed for bayes rule in terms of   xx and   xy

21

===

id136

  xx

d

  xy

p(y = ej | x = ei) = p(x = ei, y = ej)/p(x = ei)

= [   xy]ij/[  xx]ii

0
0
1
0
0
0
0
1
0
0
0
0
0
0
x    y

p(y | x) = x        1

xx   xyy

bayes rule: matrix version

geoff gordon   icml tutorial   july, 2012

22

learning

  xx

  xy

0
0
1
0
0
0
0
1
0
0
0
0
0
0
x    y

    xy =

    xx =

1
t

1
t

t   t=1
t   t=1

xty   t

xtx   t

  p(y | x) = x           1
empirical matrix 

xx

    xyy

bayes rule
(consistent)

geoff gordon   icml tutorial   july, 2012
these are same formulas as for gaussian case
optional: can regularize   xx by adding a ridge term   i (and possibly rescaling to maintain sum=1)

23

slightly more complicated graph

x

s

y

x, y, s discrete

u

0
1
0
0
0
0
0

0
0
0
1
0
0
0
0
1
0
x    y    s

p(x, y, s) =

qxs(x, s)qys(y, s)

1
  

qxs(x, s)qys(y, s)

1
  

p(x, y) =   s

vt

=   xy

uik =

1
  

qxs(ei, ek)

vjk = qys(ej, ek)

  xx

geoff gordon   icml tutorial   july, 2012
start to work our way up in graph complexity: suppose a latent variable z separates x from y
then something interesting happens:   xy is low rank
just as before,   xx is diagonal

24

id136 and learning

p(y = ej | x = ei) = [   xy]ij/[  xx]ii

xx   xyy

p(y | x) = x        1
xty   t    
t   t=1

t

    xy = rankk    1
t   t=1

    xx =

1
t

xtx   t

id136 by 

normal equations

learning: project 

empirical covariance 

onto rank k

geoff gordon   icml tutorial   july, 2012
the learned rule is exact if k     rank(true   xy), but clearly we can still use it as an approximation if not

25

so what do we do w/ a real graph?

x1

l

s1

r

s3

x2

x3

s2

m

x4

x5

x6

s4

s5

goal: bayes    lter

given belief p(s2 | x12): dist   n over a cut, given left context

update recursively: get belief p(s3 | x123)

geoff gordon   icml tutorial   july, 2012

26

bayes    lter

x1

x2

x3

x4

x5

x6

s1

s2

s3

s4

s5

    extend: p(s2, x3, s3 |    ) = p(s2 |    ) p(s3, x3 | s2)
    marginalize: drop s2 to get p(x3, s3 |    )
    condition: p(s3 |    ) = p(x3, s3 |    ) / p(x3 |    )

geoff gordon   icml tutorial   july, 2012
we   ll show how to do each of these steps efficiently; the result will look like repeated application of the matrix 
bayes rule.  (and as above this result is exact if we use a big enough rank, or approximate if we pick a smaller 
rank.)

27

so what do we do w/ a real graph?

x1

x2

x3

x4

x5

x6

x3, x4, x5, x6
vt
p(x) =   12,3456

x1, x2

u

x

s

y

geoff gordon   icml tutorial   july, 2012
if we group variables, we get right back to x-s-y case
write p(x) as a matrix: it is covariance of x12 vs x3456.  each row is an event x12 = something; each column is an 
event x3456 = something.
this matrix is low-rank (by same argument above)
so, if we have ut * x12, that   s enough to compute p(x) for any value of x matching x12 -- we don   t need the actual 
value of x12 
similarly, can compute p(x3456 | x12) by normalizing this slice of p(x)
problem: can   t actually write down a table as big as p(x3456) -- much less p(x123456)
so what do we do?

28

cutting down on storage

basis q3456

x3, x4, x5, x6

x3456 = [0,5,2,3]

x12 = [5,1]

x1, x2

p(x12, 
x3456 = 
q3456)

p(x) =   12,3456

geoff gordon   icml tutorial   july, 2012
say rank is 5
then we can    nd 5 linearly independent columns (a basis for the column space) -- each column gives 
probabilities of all settings of x12 for one setting of x3456
and we can reconstruct any other column as a linear combination of this basis
now we can work with the (much smaller) matrix which has only the basis columns, and we   ll be able to 
reconstruct any other desired column as needed
e.g., our belief will be represented as a prediction of probabilities for the events corresponding to basis columns 
-- this is our predictive state

29

it works for rows too

q3456

q12

p(x12 = 
p(x) =   12,3456
q12, x3456 
= q3456)

geoff gordon   icml tutorial   july, 2012
same idea works for rows, so we only need a small square submatrix of   

30

numerical example

2
1

,

x

1,1
1,2
1,3
2,1
2,2
2,3
3,1
3,2
3,3

1,1 1,2 1,3 2,1 2,2 2,3 3,1 3,2 3,3

x3,4

this matrix     has rank 2

x1

x2

x3

x4

   

since this variable has arity 2

geoff gordon   icml tutorial   july, 2012

31

numerical example

t

e
s
 

e
r
o
c

1,3
3,1

1,2 3,2
core set

t

e
s
 

e
r
o
c

1,2

3,2

1,1 1,2 1,3 2,1 2,2 2,3 3,1 3,2 3,3

x3,4

    rt = regress from b to p(core, :) 

    b = basis subset of p

2
1

,

x

1,1
1,2
1,3
2,1
2,2
2,3
3,1
3,2
3,3

1,3 3,1
core set
    l = regress from b to p(:, core) 

p = lbrt

geoff gordon   icml tutorial   july, 2012
we   ve represented the entire distribution p as the product of these 3 matrices -- many fewer parameters
if you   ve heard psr terminology    core events    and    indicative events   , these are other names for a basis set
note: common caxis, except b, which is factor of 500 larger

32

ambiguity

b
s

rt

s-1

l
lb

    all these factorizations are equivalent
    each corresponds to a linear transform of 
the basis
    instead of p(basis event), e(basis statistic)

   x1,x2

p(x1, x2)f (x1, x2)

33

geoff gordon   icml tutorial   july, 2012
we can rearrange factorization:
l b rt
(lb) rt
(lb) s s-1 rt

learning and id136

2
1

,

x

1,1
1,2
1,3
2,1
2,2
2,3
3,1
3,2
3,3

1,2 3,2
core set

l

t

e
s
 
e
r
o
c

1,3

3,1

t

e
s
 

e
r
o
c

1,2
3,2

1,3 3,1
core set

b

1,1 1,2 1,3 2,1 2,2 2,3 3,1 3,2 3,3

x3,4
r

learn l and r by svd

if desired, learn b by counting co-

occurrences of core events, adjust l and r

id136 by usual formula:

p(x3,4 | x1,2) = x   12     1

12,12  12,34x34

geoff gordon   icml tutorial   july, 2012
in reality, though, for big sets of variables,   xy will be too big to write down

34

features

  t

  12,34

  

          xy   = rankk    1

t

  t     t    

t   t=1

  

x1,2 x1+x2
1, 1
1, 2
1, 3
2, 1
2, 2
2, 3
3, 1
3, 2
3, 3

2
3
4
3
4
5
4
5
6

x2    
   
1
   
2
   
3
   
1
   
2
   
3
   
1
   
2
   
3

geoff gordon   icml tutorial   july, 2012
35
so, de   ne features of x12 and x34 -- call them phi and psi, and suppose there are    k of them on each side -- each 
feature is a linear combination of indicators for events
compute empirical covariance of features, and project onto rank k
big advantage: we never need to represent a pdf over domain of x or y, which can be huge -- instead work only 
with shorter feature vectors
big advantage #2:    xes a numerical/statistical problem.  if each core event has small id203 (the usual case, 
since it   s a conjunction of settings for many variables), then it might take a lot of data to estimate the core 
submatrix, and it might be ill-conditioned to reconstruct other event probabilities from the core events.  but as 
long as features are not (nearly) perfectly correlated, projecting feature covariance onto rank k is well-
conditioned.
problem: can   t do this with   xx (it   s not low-rank)
solution: we   ll use bayes    lter to condition on observed variables one at a time, instead of all at once

ok, we can work with groups

x1

x2

x3

x4

x5

x6

x3, x4, x5, x6
vt

x1, x2

u

x

s

y

geoff gordon   icml tutorial   july, 2012
so now we   ve shown how to work efficiently with this grouping

36

do it again

x3, x4, x5

q456

x1, x2, x3

p(x)=  123,456

(cid:15482)

p(x123, 
x456 = 
q456)

geoff gordon   icml tutorial   july, 2012
we can also regroup variables, and    nd a basis set for x345
or, if desired, a transformed basis (not just a subset of atomic events)

x

z

y

37

bayes    lter
p(q | c)    

p(q    | c   )    

context c

context c   

q     q
q        q   

p(q | c) = 

vector of p(q | c)

xq    = (x, then q   ): e.g., if 
q    is x456 = (4, 2, 7), then 
5q    is x3456 = (5, 4, 2, 7)

geoff gordon   icml tutorial   july, 2012
we are given a belief over a core set: p(q | context c) -- this is a short vector -- length 5 in our example
given an observation x3 = x, we need to update: p(q    | c   ) where c    = (context c, observation x)
marginalize: not really clear where this is happening since latents are never explicitly represented

38

bayes    lter

p(q | c) = 

vector of p(q | c)

xq    = (x, then q   ): e.g., if q    is 
x456 = (4, 2, 7), then 5q    is 

x3456 = (5, 4, 2, 7)

p(q | c)    

p(q    | c   )    

context c

context c   

   q        q   ,     symbols x,    mxq        rk,
p (xq    | c) = m   xq   p (q | c)
p (x | c) = m   x p (q | c)

geoff gordon   icml tutorial   july, 2012
extend: by assumption, for any qj    in q   , p(x, qj    | context c) is a linear function of p(q | c)
in symbols, p(xq    | c) = mx p(q | c) for some matrix mx
again by assumption, p(x | c) = mx p(q | c) for some vector mx

39

bayes    lter

p(q | c) = 

vector of p(q | c)

xq    = (x, then q   ): e.g., if q    is 
x456 = (4, 2, 7), then 5q    is 

x3456 = (5, 4, 2, 7)

p(q | c)    

p(q    | c   )    

context c

context c   

p (q    | c   ) = p (q    | c, x)

= p (xq    | c) / p (x | c)
= m   xq   p (q | c) / m   x p (q | c)
p (q    | c   ) = mx(nxp (q | c))   1p (q | c)

= (covar of x, q    | c)(covar of x | c)   1p (q | c)

40

geoff gordon   icml tutorial   july, 2012
condition: bayes rule: p(qj | c, x) = p(x, qj | c) / p(x | c)
or, all at once: p(q | c   ) = mx p(q | c) / mx p(q | c)

does it work?

s
n
o
i
t
i
s
n
a
r
t

s
n
o
i
t
a
v
r
e
s
b
o

    simple id48: 5 states, 7 observations
    n=300 thru n=900k

geoff gordon   icml tutorial   july, 2012

xt

yt

41

does it work?

model

true

)
3
o
 
,
2
o
 
,
1
o
(
p

r
r
e
 
s
b
a
 
n
a
e
m

geoff gordon   icml tutorial   july, 2012
in heat maps,
   rst observation: major blocks
2nd: up&down within block
3rd: across rows

)

m
r
o

f
i

i

n
u
 
t
c
d
e
r
p
=
0
0
1
(

100

10(cid:239)1

10(cid:239)2

 

 

run 1
run 2
run 3
c/sqrt(n)

103

104
training data

105

42

discussion

    impossibility   learning dfa in poly time = 
breaking crypto primitives [kearns & valiant 89]
    so, clearly, we can   t always be statistically ef   cient
    but, see mcdonald [11], hkz [09], us [09]: 

convergence depends on mixing rate

    nonlinearity   bayes    lter update is highly 
nonlinear in state (matrix inverse), even though we 
use a id75 to identify the model
    this is essential for expressiveness (e.g., clock)
    in   nite memory horizon   even if we learn from 
a    nite window
geoff gordon   icml tutorial   july, 2012
there are data sets from which it would be possible to learn a good dynamical system (using arbitrary 
computational power) where we learn little or nothing
failure mode: we need exponentially more data than would be possible with arbitrary computational power   
contrast breaking rsa by factoring vs. by building a table of (plaintext, cyphertext) pairs
any proof of efficiency would need to use some parameter such as beta-mixing which excludes    bad    id48s

43

summary so far

    we can write bayes rule updates in terms of 
covariances
    often, they are low rank
    we can learn them from data
    we can chain bayes rule updates together to 
make a bayes    lter
    lots of cool applications of this simple idea

geoff gordon   icml tutorial   july, 2012

44

