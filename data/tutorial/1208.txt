humor detection

classi cation approaches

miriam k  shammer

course: computational approaches to creative language

universit  t des saarlandes

june 29, 2010

introduction
classi cation approaches
evaluation
conclusion

humor detection/humor recognition

automatically decide whether a document (e.g. text, paragraph,
sentence etc.) is humorous or not.

challenging task

what is humor?

most commonly: what makes people laugh is humorous.
many de nitions and theories of humor (philosophy, linguistics,
psychology)
here: verbally expressed humor; subclass: jokes

sense of humor varies from person to person.

humor recognition is not an easy task for humans.

2/ 34

introduction
classi cation approaches
evaluation
conclusion

motivation

humor is an essential element of all verbal communication.

natural language systems should be able to handle humor.

improve user-friendliness
improve human-computer interaction
develop better intelligent systems
improve second language learning

information retrieval: discard unnecessary or irrelevant
information

search for unintended humor in serious text, i.e. diplomatic
note, presidential speech

3/ 34

introduction
classi cation approaches
evaluation
conclusion

approaches

classi cation techniques

learning to laugh (automatically): computational models for
humor recognition
mihalcea, r. and strapparava, c. (2006)

identi cation of  knock-knock  jokes, heuristics based on
the particular joke structure

computationally recognizing wordplay in jokes
taylor, j. m. and mazlack, l. j. (2004)

ontological semantics

computational detection of humor: a dream or a nightmare?
taylor, j. m. (2009)

4/ 34

introduction
classi cation approaches
evaluation
conclusion

outline

1

introduction

2 classi cation approaches

3 evaluation

4 conclusion

5/ 34

introduction
classi cation approaches
evaluation
conclusion

data sets
a. classi cation using heuristics
b. text classi cation
c. combination

outline

1

introduction

2 classi cation approaches

3 evaluation

4 conclusion

6/ 34

introduction
classi cation approaches
evaluation
conclusion

data sets
a. classi cation using heuristics
b. text classi cation
c. combination

overall idea

hypothesis: automatic classi cation techniques represent a viable
approach to distinguish between humorous and non-humorous text.

1 labels: humorous vs. non-humorous
2 de ne features:

a. humor-speci c stylistic features (heuristics)
b. content-based features
c. combined stylistic and content-based features

3 use labeled data to train a classi er:

a. decision tree
b. naive bayes and id166
c. stacked machine learning framework

4 use the classi er to label the test data and evaluate

7/ 34

introduction
classi cation approaches
evaluation
conclusion

data sets
a. classi cation using heuristics
b. text classi cation
c. combination

restrictions on the type of humor

one-liner

take my advice; i don't use it anyway.

 [...] a short sentence with comic e ects and an interesting
linguistic structure [...] 

simple syntax

deliberate use of rhetoric devices (alliteration, rhyme etc.)

frequent use of creative language constructions to attract the
readers' attention

humor in general: too ambitious

humor-producing features are present in this one and only
sentence.

8/ 34

introduction
classi cation approaches
evaluation
conclusion

data sets
a. classi cation using heuristics
b. text classi cation
c. combination

outline

1

introduction

2 classi cation approaches

data sets
a. classi cation using heuristics
b. text classi cation
c. combination

3 evaluation

experimental results
discussion

4 conclusion

9/ 34

introduction
classi cation approaches
evaluation
conclusion

data sets
a. classi cation using heuristics
b. text classi cation
c. combination

humorous data

web-based id64 process
[mihalcea and strapparava, 2005]
    16.000 one-liners for the experiments

i get enough exercise just pushing my luck.

beauty is in the eye of the beer holder.

take my advice; i don't use it anyway.

10/ 34

introduction
classi cation approaches
evaluation
conclusion

data sets
a. classi cation using heuristics
b. text classi cation
c. combination

non-humorous data

four collections of 16.000 sentences from di erent sources

reuters/bnc/proverbs/omcs

similar in structure and composition to the one-liners, but
di erent in their comic e ect

average length of 10-15 words

    enforce the classi ers to identify humor-speci c features

11/ 34

introduction
classi cation approaches
evaluation
conclusion

data sets
a. classi cation using heuristics
b. text classi cation
c. combination

non-humorous data contd.

reuters titles
from articles published in the reuters newswire

short sentences with simple syntax

phrased to catch the readers' attention

oil prices slip as refiners shop for bargains.

12/ 34

introduction
classi cation approaches
evaluation
conclusion

data sets
a. classi cation using heuristics
b. text classi cation
c. combination

non-humorous data contd.

reuters titles
from articles published in the reuters newswire

short sentences with simple syntax

phrased to catch the readers' attention

oil prices slip as refiners shop for bargains.

bnc
sentences from the british national corpus

no added creativity

the train arrives three minutes early.

12/ 34

introduction
classi cation approaches
evaluation
conclusion

data sets
a. classi cation using heuristics
b. text classi cation
c. combination

non-humorous data contd.

proverbs
from an online proverb collection

condensed sayings

some one-liners reproduce proverbs with a comic e ect.

beauty is in the eye of the beholder.

13/ 34

introduction
classi cation approaches
evaluation
conclusion

data sets
a. classi cation using heuristics
b. text classi cation
c. combination

non-humorous data contd.

proverbs
from an online proverb collection

condensed sayings

some one-liners reproduce proverbs with a comic e ect.

beauty is in the eye of the beholder.

omcs
commonsense assertions in english

simple single sentences

jokes often break commonsense understandings.

a file is used for keeping documents.

13/ 34

introduction
classi cation approaches
evaluation
conclusion

data sets
a. classi cation using heuristics
b. text classi cation
c. combination

outline

1

introduction

2 classi cation approaches

data sets
a. classi cation using heuristics
b. text classi cation
c. combination

3 evaluation

experimental results
discussion

4 conclusion

14/ 34

introduction
classi cation approaches
evaluation
conclusion

data sets
a. classi cation using heuristics
b. text classi cation
c. combination

stylistic features

linguistic theories of humor have suggested stylistic features that
characterize humorous text.

signi cant and feasible to implement:

alliteration

antonymy

adult slang

15/ 34

introduction
classi cation approaches
evaluation
conclusion

data sets
a. classi cation using heuristics
b. text classi cation
c. combination

stylistic features: alliteration

structural and phonetic properties of jokes are at least as
important as their content.

one-liners often rely on attention-catching sounds, enforced
through alliteration and word repetition.

veni, vidi, visa: i came, i saw, i did a little shopping.

identify and count the alliteration chains in each example in
the data set.

automatically achieved with a pronunciation dictionary, a
longest string matching device and a stopword list of
functional words.

16/ 34

introduction
classi cation approaches
evaluation
conclusion

data sets
a. classi cation using heuristics
b. text classi cation
c. combination

stylistic features: antonymy

humor often relies on some form of incongruity, opposition or
contradiction.

always try to be modest and be proud of it.

identify the presence of antonyms in a sentence.

antonymy relation (and similar-to relation for adjectives) of
id138.

problem of coverage: antonymy feature cannot always be
identi ed.

17/ 34

introduction
classi cation approaches
evaluation
conclusion

data sets
a. classi cation using heuristics
b. text classi cation
c. combination

stylistic features: adult slang

humor based on adult slang (= sexual-oriented lexicon) is
popular.

the sex was so good that even the neighbors had a cigarette.

extract the synsets labeled with the domain sexuality from
id138.

check for the presence of these words in each sentence and
annotate them accordingly.

problem of coverage: adult slang feature cannot always be
identi ed.

18/ 34

introduction
classi cation approaches
evaluation
conclusion

data sets
a. classi cation using heuristics
b. text classi cation
c. combination

classi cation using heuristics

numerical features that act as heuristics
parameters to learn: threshold indicating the minimum value
admitted for a sentence to be classi ed as humorous (or
non-humorous).

19/ 34

introduction
classi cation approaches
evaluation
conclusion

data sets
a. classi cation using heuristics
b. text classi cation
c. combination

classi cation using heuristics

numerical features that act as heuristics
parameters to learn: threshold indicating the minimum value
admitted for a sentence to be classi ed as humorous (or
non-humorous).
    decision tree

figure: a sample decision tree

19/ 34

introduction
classi cation approaches
evaluation
conclusion

data sets
a. classi cation using heuristics
b. text classi cation
c. combination

outline

1

introduction

2 classi cation approaches

data sets
a. classi cation using heuristics
b. text classi cation
c. combination

3 evaluation

experimental results
discussion

4 conclusion

20/ 34

introduction
classi cation approaches
evaluation
conclusion

data sets
a. classi cation using heuristics
b. text classi cation
c. combination

content-based features

formulation of the humor recognition task as a traditional text
classi cation problem.
    the sentences themselves represent feature vectors encoding
term presence or absence.

classi ers: naive bayes and id166

21/ 34

introduction
classi cation approaches
evaluation
conclusion

data sets
a. classi cation using heuristics
b. text classi cation
c. combination

outline

1

introduction

2 classi cation approaches

data sets
a. classi cation using heuristics
b. text classi cation
c. combination

3 evaluation

experimental results
discussion

4 conclusion

22/ 34

introduction
classi cation approaches
evaluation
conclusion

data sets
a. classi cation using heuristics
b. text classi cation
c. combination

combining stylistic with content features

jointly exploit stylistic and content features for humor
recognition
stacked learner:

1 apply the text classi er
2 join the output of the text classi er with the stylistic features
3 feed the newly created vector to a machine learning tool

23/ 34

introduction
classi cation approaches
evaluation
conclusion

experimental results
discussion

outline

1

introduction

2 classi cation approaches

data sets
a. classi cation using heuristics
b. text classi cation
c. combination

3 evaluation

experimental results
discussion

4 conclusion

24/ 34

introduction
classi cation approaches
evaluation
conclusion

experimental results
discussion

a. classi cation using heuristics

humor recognition accuracy

using alliteration, antonymy and adult slang

25/ 34

introduction
classi cation approaches
evaluation
conclusion

experimental results
discussion

a. classi cation using heuristics

humor recognition accuracy

using alliteration, antonymy and adult slang

training on 1.000 examples, evaluation on the remaining 15.000
examples
proverbs and one-liners have the most similar style.
reuters titles and one-liners have the most di erent style.

alliteration feature: the most useful indicator of humor

25/ 34

introduction
classi cation approaches
evaluation
conclusion

experimental results
discussion

b. text classi cation

humor recognition accuracy using content-based features

one-liners

naive bayes
id166

bnc

reuters
96.67% 73.22%
96.09% 77.51%

proverbs
84.81%
84.48%

omcs
82.39%
81.86%

26/ 34

introduction
classi cation approaches
evaluation
conclusion

experimental results
discussion

b. text classi cation

humor recognition accuracy using content-based features

one-liners

naive bayes
id166
stylistic f.

bnc

reuters
96.67% 73.22%
96.09% 77.51%
76.73% 60.63%

proverbs
84.81%
84.48%
53.71%

omcs
82.39%
81.86%
56.16%

26/ 34

introduction
classi cation approaches
evaluation
conclusion

experimental results
discussion

b. text classi cation

humor recognition accuracy using content-based features

one-liners

naive bayes
id166
stylistic f.

bnc

reuters
96.67% 73.22%
96.09% 77.51%
76.73% 60.63%

proverbs
84.81%
84.48%
53.71%

omcs
82.39%
81.86%
56.16%

again: reuters titles seem to be the most di erent from one-liners.

bnc sentences represent the most similar data set.
    joke content tends to be similar to regular text.
interesting: proverbs and one-liners seem to deal with di erent
topics (despite their stylistic similarity)

26/ 34

introduction
classi cation approaches
evaluation
conclusion

experimental results
discussion

c. combination

humor recognition accuracy

using content-based and stylistic features

combination

reuters
96.95% 79.15%

bnc

proverbs
84.82%

omcs
82.37%

one-liners

27/ 34

introduction
classi cation approaches
evaluation
conclusion

experimental results
discussion

c. combination

humor recognition accuracy

using content-based and stylistic features

one-liners

combination
text classif.
stylistic feat.

bnc

reuters
96.95% 79.15%
96.67% 77.51%
76.73% 60.63%

proverbs
84.82%
84.81%
53.71%

omcs
82.37%
82.39%
56.16%

no improvement for one-liners/proverbs and one-liners/omcs
    not surprising (see  rst experiment)

27/ 34

introduction
classi cation approaches
evaluation
conclusion

experimental results
discussion

discussion

results prove that automatic classi cation techniques
represent a viable approach for the task of humor recognition.

good performance using stylistic and content-based features.

initial intuition: one-liners are most similar to other creative
text (e.g. reuters titles or proverbs)

but: it is more di cult to distinguish humor from regular text
(e.g. bnc sentences)
still: signi cant improvement over the baseline with the
combined classi er

28/ 34

introduction
classi cation approaches
evaluation
conclusion

experimental results
discussion

discussion contd.

learning curve for humor recognition

using text classi cation (reuters & bnc)

similar-shaped curves for the other negative data sets

steep ascent: humorous and non-humorous texts are well-distinguishable

plateau: more data is not likely to improve the quality of humor detection

29/ 34

introduction
classi cation approaches
evaluation
conclusion

experimental results
discussion

discussion contd.

additional experiments and results:

1 experiment using sentences drawn randomly from the four
non-humorous collections
    results similar to the results with one-liners/bnc before

2 experiment using uneven class distributions:

75% non-humorous/25% humorous
    still improvement over the baseline

30/ 34

introduction
classi cation approaches
evaluation
conclusion

experimental results
discussion

discussion contd.

sources of humor in cases where the stylistic and
content-based features failed (manual inspection):
irony, ambiguity, incongruity, idiomatic expressions,
commonsense knowledge

semantic classes of the most discriminative content-based
features (useful for humor generation):
human-centric vocabulary, negation, negative polarity,
professional communities, human  weakness 

31/ 34

introduction
classi cation approaches
evaluation
conclusion

outline

1

introduction

2 classi cation approaches

data sets
a. classi cation using heuristics
b. text classi cation
c. combination

3 evaluation

experimental results
discussion

4 conclusion

32/ 34

introduction
classi cation approaches
evaluation
conclusion

conclusion

a conclusion is simply the place where you got tired of thinking.

(anonymous one-liner, from [mihalcea and strapparava, 2006])

automatic classi cation techniques can be successfully applied
to the humor recognition task.

more training data is not likely to improve the performance
    identi cation of more sophisticated humor-speci c features

but:

can this approach generalize from one-liners to humor in
general?

how would it be used in the mentioned applications?

33/ 34

introduction
classi cation approaches
evaluation
conclusion

references

mihalcea, r. and strapparava, c. (2005).
id64 for fun: web-based construction of large data sets for
humor recognition.
proceedings of the workshop on negotiation, behaviour and language.

mihalcea, r. and strapparava, c. (2006).
learning to laugh (automatically): computational models for humor
recognition.
computational intelligence, 22(2).

taylor, j. m. (2009).
computational detection of humor: a dream or a nightmare?
international conference on web intelligence and intelligent agent
technology - workshops.

taylor, j. m. and mazlack, l. j. (2004).
computationally recognizing wordplay in jokes.
proceedings of cognitive science conference, pages 2166 2171.

34/ 34

