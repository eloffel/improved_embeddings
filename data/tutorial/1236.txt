1

sample space and
id203

contents

.

.

.

.

.

.

.
.

.
.
.

.
.
.

.
.
.

.
.
.

.
.
1.1. sets .
.
.
1.2. probabilistic models .
.
1.3. id155 .
.
1.4. total id203 theorem and bayes    rule
.
.
1.5. independence .
.
1.6. counting
.
.
.
1.7. summary and discussion
.
.

problems .

.
.
.
.

.
.
.
.

.
.
.
.

.
.
.
.

.
.
.
.

.
.
.
.

.
.
.

.
.
.

.
.

.
.

.
.

.
.

.

.

.

.

.

.

.

.
.
.

.
.
.
.

.
.
.
.
.
.
.
.

.
.
.
.
.
.
.
.

.
.
.
.
.
.
.
.

.
.
.
.
.
.
.
.

.
.
.
.
.
.
.
.

.
.
.
.
.
.
.
.

.
.
.
.
.
.
.
.

. p. 3
.
.
. p. 6
. p. 18
. p. 28
. p. 34
. p. 44
. p. 51
. p. 53

1

2

sample space and id203

chap. 1

   id203    is a very useful concept, but can be interpreted in a number of
ways. as an illustration, consider the following.

a patient is admitted to the hospital and a potentially life-saving drug is
administered. the following dialog takes place between the nurse and a
concerned relative.
relative: nurse, what is the id203 that the drug will work?
nurse: i hope it works, we   ll know tomorrow.
relative: yes, but what is the id203 that it will?
nurse: each case is di   erent, we have to wait.
relative: but let   s see, out of a hundred patients that are treated under
similar conditions, how many times would you expect it to work?
nurse (somewhat annoyed): i told you, every person is di   erent, for some
it works, for some it doesn   t.
relative (insisting): then tell me, if you had to bet whether it will work
or not, which side of the bet would you take?
nurse (cheering up for a moment): i   d bet it will work.
relative (somewhat relieved): ok, now, would you be willing to lose two
dollars if it doesn   t work, and gain one dollar if it does?
nurse (exasperated): what a sick thought! you are wasting my time!

in this conversation, the relative attempts to use the concept of id203
to discuss an uncertain situation. the nurse   s initial response indicates that the
meaning of    id203    is not uniformly shared or understood, and the relative
tries to make it more concrete. the    rst approach is to de   ne id203 in
terms of frequency of occurrence, as a percentage of successes in a moderately
large number of similar situations. such an interpretation is often natural. for
example, when we say that a perfectly manufactured coin lands on heads    with
id203 50%,    we typically mean    roughly half of the time.    but the nurse
may not be entirely wrong in refusing to discuss in such terms. what if this
was an experimental drug that was administered for the very    rst time in this
hospital or in the nurse   s experience?

while there are many situations involving uncertainty in which the fre-
quency interpretation is appropriate, there are other situations in which it is
not. consider, for example, a scholar who asserts that the iliad and the odyssey
were composed by the same person, with id203 90%. such an assertion
conveys some information, but not in terms of frequencies, since the subject is
a one-time event. rather, it is an expression of the scholar   s subjective be-
lief. one might think that subjective beliefs are not interesting, at least from a
mathematical or scienti   c point of view. on the other hand, people often have
to make choices in the presence of uncertainty, and a systematic way of making
use of their beliefs is a prerequisite for successful, or at least consistent, decision
making.

sec. 1.1

sets

3

in fact, the choices and actions of a rational person, can reveal a lot about
the inner-held subjective probabilities, even if the person does not make conscious
use of probabilistic reasoning. indeed, the last part of the earlier dialog was an
attempt to infer the nurse   s beliefs in an indirect manner. since the nurse was
willing to accept a one-for-one bet that the drug would work, we may infer
that the id203 of success was judged to be at least 50%. and had the
nurse accepted the last proposed bet (two-for-one), that would have indicated a
success id203 of at least 2/3.

rather than dwelling further into philosophical issues about the appropri-
ateness of probabilistic reasoning, we will simply take it as a given that the theory
of id203 is useful in a broad variety of contexts, including some where the
assumed probabilities only re   ect subjective beliefs. there is a large body of
successful applications in science, engineering, medicine, management, etc., and
on the basis of this empirical evidence, id203 theory is an extremely useful
tool.

our main objective in this book is to develop the art of describing un-
certainty in terms of probabilistic models, as well as the skill of probabilistic
reasoning. the    rst step, which is the subject of this chapter, is to describe
the generic structure of such models, and their basic properties. the models we
consider assign probabilities to collections (sets) of possible outcomes. for this
reason, we must begin with a short review of set theory.

1.1 sets

id203 makes extensive use of set operations, so let us introduce at the
outset the relevant notation and terminology.
a set is a collection of objects, which are the elements of the set. if s is
a set and x is an element of s, we write x     s. if x is not an element of s, we
write x /    s. a set can have no elements, in which case it is called the empty
set, denoted by   .

sets can be speci   ed in a variety of ways. if s contains a    nite number of

elements, say x1, x2, . . . , xn, we write it as a list of the elements, in braces:

s = {x1, x2, . . . , xn}.

for example, the set of possible outcomes of a die roll is {1, 2, 3, 4, 5, 6}, and the
set of possible outcomes of a coin toss is {h, t}, where h stands for    heads   
and t stands for    tails.   

if s contains in   nitely many elements x1, x2, . . ., which can be enumerated
in a list (so that there are as many elements as there are positive integers) we
write

s = {x1, x2, . . .},

and we say that s is countably in   nite. for example, the set of even integers
can be written as {0, 2,   2, 4,   4, . . .}, and is countably in   nite.

4

sample space and id203

chap. 1

alternatively, we can consider the set of all x that have a certain property

p , and denote it by

{x| x satis   es p}.

(the symbol    |    is to be read as    such that.   ) for example, the set of even
integers can be written as {k | k/2 is integer}. similarly, the set of all scalars x
in the interval [0, 1] can be written as {x| 0     x     1}. note that the elements x
of the latter set take a continuous range of values, and cannot be written down
in a list (a proof is sketched in the end-of-chapter problems); such a set is said
to be uncountable.
if every element of a set s is also an element of a set t , we say that s
is a subset of t , and we write s     t or t     s. if s     t and t     s, the
two sets are equal, and we write s = t . it is also expedient to introduce a
universal set, denoted by   , which contains all objects that could conceivably
be of interest in a particular context. having speci   ed the context in terms of a
universal set   , we only consider sets s that are subsets of   .

set operations
the complement of a set s, with respect to the universe   , is the set {x    
  | x /    s} of all elements of    that do not belong to s, and is denoted by sc.
note that   c =   .
the union of two sets s and t is the set of all elements that belong to s
or t (or both), and is denoted by s     t . the intersection of two sets s and t
is the set of all elements that belong to both s and t , and is denoted by s     t .
thus,

s     t = {x| x     s or x     t},

and

s     t = {x| x     s and x     t}.

in some cases, we will have to consider the union or the intersection of several,
even in   nitely many sets, de   ned in the obvious way. for example, if for every
positive integer n, we are given a set sn, then

   (cid:2)

n=1

sn = s1     s2            = {x| x     sn for some n},
   (cid:3)

sn = s1     s2            = {x| x     sn for all n}.

and

n=1

two sets are said to be disjoint if their intersection is empty. more generally,
several sets are said to be disjoint if no two of them have a common element. a
collection of sets is said to be a partition of a set s if the sets in the collection
are disjoint and their union is s.

sec. 1.1

sets

5

if x and y are two objects, we use (x, y) to denote the ordered pair of x
and y. the set of scalars (real numbers) is denoted by (cid:8); the set of pairs (or
triplets) of scalars, i.e., the two-dimensional plane (or three-dimensional space,
respectively) is denoted by (cid:8)2 (or (cid:8)3, respectively).

sets and the associated operations are easy to visualize in terms of venn

diagrams, as illustrated in fig. 1.1.

  

t

  

s

s

(a)

t

(d)

  

  

t

u

s

(b)

(e)

s

t

  

  

s

u

t

s

(c)

t

(f )

figure 1.2: examples of venn diagrams. (a) the shaded region is s     t . (b)
the shaded region is s     t . (c) the shaded region is s     t c. (d) here, t     s.
the shaded region is the complement of s. (e) the sets s, t , and u are disjoint.
(f) the sets s, t , and u form a partition of the set   .

the algebra of sets

set operations have several properties, which are elementary consequences of the
de   nitions. some examples are:

s     t = t     s,

s     (t     u) = (s     t )     (s     u),

s     (t     u) = (s     t )     u,
s     (t     u) = (s     t )     (s     u),

(sc)c = s,
s        =   ,

(cid:5)

c

(cid:4)(cid:2)

n

(cid:3)

n

state that

two particularly useful properties are given by de morgan   s laws which

sn

=

sc
n,

sn

=

sc
n.

to establish the    rst law, suppose that x     (   nsn)c. then, x /       nsn, which
implies that for every n, we have x /    sn. thus, x belongs to the complement

n

n

s     sc =   ,
s        = s.
(cid:5)
(cid:2)

c

(cid:4)(cid:3)

6

sample space and id203

chap. 1

of every sn, and x        nsc
n. the converse
inclusion is established by reversing the above argument, and the    rst law follows.
the argument for the second law is similar.

n. this shows that (   nsn)c        nsc

1.2 probabilistic models

a probabilistic model is a mathematical description of an uncertain situation.
it must be in accordance with a fundamental framework that we discuss in this
section. its two main ingredients are listed below and are visualized in fig. 1.2.

elements of a probabilistic model

experiment.

    the sample space   , which is the set of all possible outcomes of an
    the id203 law, which assigns to a set a of possible outcomes
(also called an event) a nonnegative number p(a) (called the proba-
bility of a) that encodes our knowledge or belief about the collective
   likelihood    of the elements of a. the id203 law must satisfy
certain properties to be introduced shortly.

experiment

event b

event a

sample space

(set of possible outcomes)

id203

law

p(b)

p(a)

a

b

events

figure 1.2: the main ingredients of a probabilistic model.

sample spaces and events

every probabilistic model involves an underlying process, called the experi-
ment, that will produce exactly one out of several possible outcomes. the set
of all possible outcomes is called the sample space of the experiment, and is
denoted by   . a subset of the sample space, that is, a collection of possible

sec. 1.2

probabilistic models

7

outcomes, is called an event.    there is no restriction on what constitutes an
experiment. for example, it could be a single toss of a coin, or three tosses,
or an in   nite sequence of tosses. however, it is important to note that in our
formulation of a probabilistic model, there is only one experiment. so, three
tosses of a coin constitute a single experiment, rather than three experiments.

the sample space of an experiment may consist of a    nite or an in   nite
number of possible outcomes. finite sample spaces are conceptually and math-
ematically simpler. still, sample spaces with an in   nite number of elements are
quite common. for an example, consider throwing a dart on a square target and
viewing the point of impact as the outcome.

choosing an appropriate sample space

regardless of their number, di   erent elements of the sample space should be
distinct and mutually exclusive so that when the experiment is carried out,
there is a unique outcome. for example, the sample space associated with the
roll of a die cannot contain    1 or 3    as a possible outcome and also    1 or 4   
as another possible outcome, because we would not be able to assign a unique
outcome when the roll is a 1.

a given physical situation may be modeled in several di   erent ways, de-
pending on the kind of questions that we are interested in. generally, the sample
space chosen for a probabilistic model must be collectively exhaustive, in the
sense that no matter what happens in the experiment, we always obtain an out-
come that has been included in the sample space. in addition, the sample space
should have enough detail to distinguish between all outcomes of interest to the
modeler, while avoiding irrelevant details.

example 1.1. consider two alternative games, both involving ten successive coin
tosses:

game 1: we receive $1 each time a head comes up.

game 2: we receive $1 for every coin toss, up to and including the    rst time
a head comes up. then, we receive $2 for every coin toss, up to the second
time a head comes up. more generally, the dollar amount per toss is doubled
each time a head comes up.

    any collection of possible outcomes, including the entire sample space    and
its complement, the empty set   , may qualify as an event. strictly speaking, however,
some sets have to be excluded. in particular, when dealing with probabilistic models
involving an uncountably in   nite sample space, there are certain unusual subsets for
which one cannot associate meaningful probabilities. this is an intricate technical issue,
involving the mathematics of measure theory. fortunately, such pathological subsets
do not arise in the problems considered in this text or in practice, and the issue can be
safely ignored.

8

sample space and id203

chap. 1

in game 1, it is only the total number of heads in the ten-toss sequence that mat-
ters, while in game 2, the order of heads and tails is also important. thus, in
a probabilistic model for game 1, we can work with a sample space consisting of
eleven possible outcomes, namely, 0, 1, . . . , 10. in game 2, a    ner grain description
of the experiment is called for, and it is more appropriate to let the sample space
consist of every possible ten-long sequence of heads and tails.

sequential models

many experiments have an inherently sequential character, such as for example
tossing a coin three times, or observing the value of a stock on    ve successive
days, or receiving eight successive digits at a communication receiver. it is then
often useful to describe the experiment and the associated sample space by means
of a tree-based sequential description, as in fig. 1.3.

4

3
2nd roll

2

1

1

sample space 
for a pair of rolls

2

3
1st roll

4

tree-based sequential
description

1,1
1,2
1,3
1,4

leaves

root

1

2

3

4

figure 1.3: two equivalent descriptions of the sample space of an experiment
involving two rolls of a 4-sided die. the possible outcomes are all the ordered pairs
of the form (i, j), where i is the result of the    rst roll, and j is the result of the
second. these outcomes can be arranged in a 2-dimensional grid as in the    gure
on the left, or they can be described by the tree on the right, which re   ects the
sequential character of the experiment. here, each possible outcome corresponds
to a leaf of the tree and is associated with the unique path from the root to
that leaf. the shaded area on the left is the event {(1, 4), (2, 4), (3, 4), (4, 4)}
that the result of the second roll is 4. that same event can be described by the
set of leaves highlighted on the right. note also that every node of the tree can
be identi   ed with an event, namely, the set of all leaves downstream from that
node. for example, the node labeled by a 1 can be identi   ed with the event
{(1, 1), (1, 2), (1, 3), (1, 4)} that the result of the    rst roll is 1.

id203 laws

suppose we have settled on the sample space    associated with an experiment.
then, to complete the probabilistic model, we must introduce a id203

sec. 1.2

probabilistic models

9

law. intuitively, this speci   es the    likelihood    of any outcome, or of any set of
possible outcomes (an event, as we have called it earlier). more precisely, the
id203 law assigns to every event a, a number p(a), called the id203
of a, satisfying the following axioms.

id203 axioms

1. (nonnegativity) p(a)     0, for every event a.
2. (additivity) if a and b are two disjoint events, then the id203

of their union satis   es

p(a     b) = p(a) + p(b).

more generally, if the sample space has an in   nite number of elements
and a1, a2, . . . is a sequence of disjoint events, then the id203 of
their union satis   es

p(a1     a2           ) = p(a1) + p(a2) +        .

3. (id172) the id203 of the entire sample space    is

equal to 1, that is, p(  ) = 1.

in order to visualize a id203 law, consider a unit of mass which is
   spread    over the sample space. then, p(a) is simply the total mass that was
assigned collectively to the elements of a. in terms of this analogy, the additivity
axiom becomes quite intuitive: the total mass in a sequence of disjoint events is
the sum of their individual masses.

a more concrete interpretation of probabilities is in terms of relative fre-
quencies: a statement such as p(a) = 2/3 often represents a belief that event a
will occur in about two thirds out of a large number of repetitions of the exper-
iment. such an interpretation, though not always appropriate, can sometimes
facilitate our intuitive understanding. it will be revisited in chapter 5, in our
study of limit theorems.

there are many natural properties of a id203 law, which have not been
included in the above axioms for the simple reason that they can be derived
from them. for example, note that the id172 and additivity axioms
imply that

1 = p(  ) = p(         ) = p(  ) + p(  ) = 1 + p(  ),

and this shows that the id203 of the empty event is 0:

p(  ) = 0.

10

sample space and id203

chap. 1

as another example, consider three disjoint events a1, a2, and a3. we can use
the additivity axiom for two disjoint events repeatedly, to obtain

p(a1     a2     a3) = p

(cid:6)

(cid:7)
a1     (a2     a3)
= p(a1) + p(a2     a3)
= p(a1) + p(a2) + p(a3).

proceeding similarly, we obtain that the id203 of the union of    nitely many
disjoint events is always equal to the sum of the probabilities of these events.
more such properties will be considered shortly.

discrete models

here is an illustration of how to construct a id203 law starting from some
common sense assumptions about a model.

example 1.2. consider an experiment involving a single coin toss. there are two
possible outcomes, heads (h) and tails (t ). the sample space is    = {h, t}, and
the events are

if the coin is fair, i.e., if we believe that heads and tails are    equally likely,    we
should assign equal probabilities to the two possible outcomes and specify that
p({h}) = p({t}) = 0.5. the additivity axiom implies that

(cid:6)

p

{h, t}, {h}, {t},   .
(cid:6)
(cid:7)
{h, t}
(cid:6)
(cid:6)

(cid:7)
{h}

= p

(cid:6)

+ p

(cid:7)
{h}

(cid:7)
{t}
(cid:7)
{t}

= 0.5,

p

= 1,

which is consistent with the id172 axiom. thus, the id203 law is given
by

= 1,

p

= 0.5,

p(  ) = 0,

(cid:6)

(cid:7)
{h, t}

p

and satis   es all three axioms.

consider another experiment involving three coin tosses. the outcome will

now be a 3-long string of heads or tails. the sample space is

   = {hhh, hht, ht h, ht t, t hh, t ht, t t h, t t t}.

we assume that each possible outcome has the same id203 of 1/8. let us
construct a id203 law that satis   es the three axioms. consider, as an example,
the event

(cid:6)

a = {exactly 2 heads occur} = {hht, ht h, t hh}.
(cid:6)

(cid:7)
{hht, ht h, t hh}

(cid:7)
{ht h}

= p

(cid:6)

(cid:6)

+ p

+ p

(cid:7)
{t hh}

using additivity, the id203 of a is the sum of the probabilities of its elements:

p

(cid:7)
{hht}
1
1
8
8

+

+

=

=

1
8
3
8

.

sec. 1.2

probabilistic models

11

similarly, the id203 of any event is equal to 1/8 times the number of possible
outcomes contained in the event. this de   nes a id203 law that satis   es the
three axioms.

by using the additivity axiom and by generalizing the reasoning in the

preceding example, we reach the following conclusion.

discrete id203 law
if the sample space consists of a    nite number of possible outcomes, then the
id203 law is speci   ed by the probabilities of the events that consist of
a single element. in particular, the id203 of any event {s1, s2, . . . , sn}
is the sum of the probabilities of its elements:

(cid:6){s1, s2, . . . , sn}(cid:7)

p

= p(s1) + p(s2) +        + p(sn).

note that we are using here the simpler notation p(si) to denote the prob-
ability of the event {si}, instead of the more precise p({si}). this convention
will be used throughout the remainder of the book.

in the special case where the probabilities p(s1), . . . , p(sn) are all the same
(by necessity equal to 1/n, in view of the id172 axiom), we obtain the
following.

discrete uniform id203 law
if the sample space consists of n possible outcomes which are equally likely
(i.e., all single-element events have the same id203), then the proba-
bility of any event a is given by

p(a) =

number of elements of a

n

.

let us provide a few more examples of sample spaces and id203 laws.

example 1.3. consider the experiment of rolling a pair of 4-sided dice (cf. fig.
1.4). we assume the dice are fair, and we interpret this assumption to mean that
each of the sixteen possible outcomes [pairs (i, j), with i, j = 1, 2, 3, 4], has the same
id203 of 1/16. to calculate the id203 of an event, we must count the
number of elements of the event and divide by 16 (the total number of possible

12

sample space and id203

chap. 1

outcomes). here are some event probabilities calculated in this way:

p

(cid:7)
(cid:6)
(cid:7)
(cid:6)
{the sum of the rolls is even}
(cid:7)
(cid:6)
{the sum of the rolls is odd}
(cid:7)
{the    rst roll is equal to the second}
(cid:7)
p
{the    rst roll is larger than the second}
{at least one roll is equal to 4}

(cid:6)

p

p

(cid:6)

p

= 8/16 = 1/2,

= 8/16 = 1/2,

= 4/16 = 1/4,

= 6/16 = 3/8,

= 7/16.

sample space for a
pair of rolls

2

3
1st roll

4

4

3
2nd roll

2

1

1

event = {at least one roll is a 4}
id203 = 7/16

event = {the first roll is equal to the second}
id203 = 4/16

figure 1.4: various events in the experiment of rolling a pair of 4-sided dice,
and their probabilities, calculated according to the discrete uniform law.

continuous models

probabilistic models with continuous sample spaces di   er from their discrete
counterparts in that the probabilities of the single-element events may not be
su   cient to characterize the id203 law. this is illustrated in the following
examples, which also indicate how to generalize the uniform id203 law to
the case of a continuous sample space.

example 1.4. a wheel of fortune is continuously calibrated from 0 to 1, so the
possible outcomes of an experiment consisting of a single spin are the numbers in
the interval    = [0, 1]. assuming a fair wheel, it is appropriate to consider all
outcomes equally likely, but what is the id203 of the event consisting of a
single element? it cannot be positive, because then, using the additivity axiom, it
would follow that events with a su   ciently large number of elements would have

sec. 1.2

probabilistic models

13

id203 larger than 1. therefore, the id203 of any event that consists of a
single element must be 0.
in this example, it makes sense to assign id203 b     a to any subinter-
val [a, b] of [0, 1], and to calculate the id203 of a more complicated set by
evaluating its    length.   
this assignment satis   es the three id203 axioms and
quali   es as a legitimate id203 law.

   

example 1.5. romeo and juliet have a date at a given time, and each will arrive
at the meeting place with a delay between 0 and 1 hour, with all pairs of delays
being equally likely. the    rst to arrive will wait for 15 minutes and will leave if the
other has not yet arrived. what is the id203 that they will meet?

let us use as sample space the unit square, whose elements are the possible
pairs of delays for the two of them. our interpretation of    equally likely    pairs of
delays is to let the id203 of a subset of    be equal to its area. this id203
law satis   es the three id203 axioms. the event that romeo and juliet will
meet is the shaded region in fig. 1.5, and its id203 is calculated to be 7/16.

y

1

1/4

m

0

1/4

1

x

figure 1.5: the event m that romeo and juliet will arrive within 15 minutes
of each other (cf. example 1.5) is

(cid:8)

m =

(x, y)

(cid:9)(cid:9) |x     y|     1/4, 0     x     1, 0     y     1
(cid:11)

(cid:10)

,

and is shaded in the    gure. the area of m is 1 minus the area of the two unshaded
triangles, or 1     (3/4)    (3/4) = 7/16. thus, the id203 of meeting is 7/16.

    the    length    of a subset s of [0, 1] is the integral

dt, which is de   ned, for
   nice    sets s, in the usual calculus sense. for unusual sets, this integral may not be
well de   ned mathematically, but such issues belong to a more advanced treatment of
the subject. incidentally, the legitimacy of using length as a id203 law hinges on
the fact that the unit interval has an uncountably in   nite number of elements. indeed,
if the unit interval had a countable number of elements, with each element having
zero id203, the additivity axiom would imply that the whole interval has zero
id203, which would contradict the id172 axiom.

s

14

sample space and id203

chap. 1

properties of id203 laws

id203 laws have a number of properties, which can be deduced from the
axioms. some of them are summarized below.

some properties of id203 laws
consider a id203 law, and let a, b, and c be events.
(a) if a     b, then p(a)     p(b).
(b) p(a     b) = p(a) + p(b)     p(a     b).
(c) p(a     b)     p(a) + p(b).
(d) p(a     b     c) = p(a) + p(ac     b) + p(ac     bc     c).

these properties, and other similar ones, can be visualized and veri   ed
graphically using venn diagrams, as in fig. 1.6. note that property (c) can be
generalized as follows:

p(a1     a2                an)     n(cid:12)

p(ai).

i=1

to see this, we apply property (c) to the sets a1 and a2                an, to obtain

p(a1     a2                an)     p(a1) + p(a2                an).

we also apply property (c) to the sets a2 and a3                an, to obtain

p(a2                an)     p(a2) + p(a3                an).

we continue similarly, and    nally add.

models and reality

the framework of id203 theory can be used to analyze uncertainty in a
wide variety of physical contexts. typically, this involves two distinct stages.

(a) in the    rst stage, we construct a probabilistic model, by specifying a prob-
ability law on a suitably de   ned sample space. there are no hard rules to
guide this step, other than the requirement that the id203 law con-
form to the three axioms. reasonable people may disagree on which model
best represents reality. in many cases, one may even want to use a some-
what    incorrect    model, if it is simpler than the    correct    one or allows for
tractable calculations. this is consistent with common practice in science

sec. 1.2

probabilistic models

15

and engineering, where the choice of a model often involves a tradeo    be-
tween accuracy, simplicity, and tractability. sometimes, a model is chosen
on the basis of historical data or past outcomes of similar experiments,
using statistical id136 methods, which will be discussed in chapters 8
and 9.

bua

buac

a

b

a

b

(a)

(b)

a

b

ac

u

bc

u c

c

buac

(c)

figure 1.6: visualization and veri   cation of various properties of id203
if a     b, then b is the union of the two disjoint
laws using venn diagrams.
events a and ac     b; see diagram (a). therefore, by the additivity axiom, we
have

p(b) = p(a) + p(ac     b)     p(a),

where the inequality follows from the nonnegativity axiom, and veri   es prop-
erty (a).
from diagram (b), we can express the events a     b and b as unions of

disjoint events:

a     b = a     (ac     b),

b = (a     b)     (ac     b).

using the additivity axiom, we have
p(a     b) = p(a) + p(ac     b),

p(b) = p(a     b) + p(ac     b).

subtracting the second equality from the    rst and rearranging terms, we obtain
p(a    b) = p(a) + p(b)     p(a    b), verifying property (b). using also the fact
p(a     b)     0 (the nonnegativity axiom), we obtain p(a     b)     p(a) + p(b),
verifying property (c).
from diagram (c), we see that the event a     b     c can be expressed as a

union of three disjoint events:

a     b     c = a     (ac     b)     (ac     bc     c),

so property (d) follows as a consequence of the additivity axiom.

16

sample space and id203

chap. 1

(b) in the second stage, we work within a fully speci   ed probabilistic model and
derive the probabilities of certain events, or deduce some interesting prop-
erties. while the    rst stage entails the often open-ended task of connecting
the real world with mathematics, the second one is tightly regulated by the
rules of ordinary logic and the axioms of id203. di   culties may arise
in the latter if some required calculations are complex, or if a id203
law is speci   ed in an indirect fashion. even so, there is no room for ambi-
guity: all conceivable questions have precise answers and it is only a matter
of developing the skill to arrive at them.
id203 theory is full of    paradoxes    in which di   erent calculation
methods seem to give di   erent answers to the same question. invariably though,
these apparent inconsistencies turn out to re   ect poorly speci   ed or ambiguous
probabilistic models. an example, bertrand   s paradox, is shown in fig. 1.7.

v

chord 
at angle   

  

midpoint 
of ab

a

.
.
.b

c

chord through c

(a)

(b)

figure 1.7: this example, presented by l. f. bertrand in 1889, illustrates the
need to specify unambiguously a probabilistic model. consider a circle and an
equilateral triangle inscribed in the circle. what is the id203 that the length
of a randomly chosen chord of the circle is greater than the side of the triangle?
the answer here depends on the precise meaning of    randomly chosen.    the two
methods illustrated in parts (a) and (b) of the    gure lead to contradictory results.
in (a), we take a radius of the circle, such as ab, and we choose a point
c on that radius, with all points being equally likely. we then draw the chord
through c that is orthogonal to ab. from elementary geometry, ab intersects
the triangle at the midpoint of ab, so the id203 that the length of the chord
is greater than the side is 1/2.

in (b), we take a point on the circle, such as the vertex v , we draw the
tangent to the circle through v , and we draw a line through v that forms a random
angle    with the tangent, with all angles being equally likely. we consider the
chord obtained by the intersection of this line with the circle. from elementary
geometry, the length of the chord is greater than the side of the triangle if    is
between   /3 and 2  /3. since    takes values between 0 and   , the id203
that the length of the chord is greater than the side is 1/3.

sec. 1.2

probabilistic models

17

a brief history of id203

    b.c.e. games of chance were popular in ancient greece and rome, but
no scienti   c development of the subject took place, possibly because the
number system used by the greeks did not facilitate algebraic calculations.
the development of id203 based on sound scienti   c analysis had to
await the development of the modern arithmetic system by the hindus and
the arabs in the second half of the    rst millennium, as well as the    ood of
scienti   c ideas generated by the renaissance.

    16th century. girolamo cardano, a colorful and controversial italian
mathematician, publishes the    rst book describing correct methods for cal-
culating probabilities in games of chance involving dice and cards.

    17th century. a correspondence between fermat and pascal touches upon
several interesting id203 questions, and motivates further study in the
   eld.

    18th century. jacob bernoulli studies repeated coin tossing and introduces
the    rst law of large numbers, which lays a foundation for linking theoreti-
cal id203 concepts and empirical fact. several mathematicians, such as
daniel bernoulli, leibnitz, bayes, and lagrange, make important contribu-
tions to id203 theory and its use in analyzing real-world phenomena.
de moivre introduces the normal distribution and proves the    rst form of
the central limit theorem.

    19th century. laplace publishes an in   uential book that establishes the
importance of id203 as a quantitative    eld and contains many original
contributions, including a more general version of the central limit theo-
rem. legendre and gauss apply id203 to astronomical predictions,
using the method of least squares, thus pointing the way to a vast range of
applications. poisson publishes an in   uential book with many original con-
tributions, including the poisson distribution. chebyshev, and his students
markov and lyapunov, study limit theorems and raise the standards of
mathematical rigor in the    eld. throughout this period, id203 theory
is largely viewed as a natural science, its primary goal being the explanation
of physical phenomena. consistently with this goal, probabilities are mainly
interpreted as limits of relative frequencies in the context of repeatable ex-
periments.

    20th century. relative frequency is abandoned as the conceptual foun-
dation of id203 theory in favor of a now universally used axiomatic
system, introduced by kolmogorov. similar to other branches of mathe-
matics, the development of id203 theory from the axioms relies only
on logical correctness, regardless of its relevance to physical phenomena.
nonetheless, id203 theory is used pervasively in science and engineer-
ing because of its ability to describe and interpret most types of uncertain
phenomena in the real world.

18

sample space and id203

chap. 1

1.3 id155

id155 provides us with a way to reason about the outcome
of an experiment, based on partial information. here are some examples of
situations we have in mind:

(a) in an experiment involving two successive rolls of a die, you are told that

the sum of the two rolls is 9. how likely is it that the    rst roll was a 6?

(b) in a word guessing game, the    rst letter of the word is a    t   . what is the

likelihood that the second letter is an    h   ?

(c) how likely is it that a person has a certain disease given that a medical

test was negative?

(d) a spot shows up on a radar screen. how likely is it to correspond to an

aircraft?
in more precise terms, given an experiment, a corresponding sample space,
and a id203 law, suppose that we know that the outcome is within some
given event b. we wish to quantify the likelihood that the outcome also belongs
to some other given event a. we thus seek to construct a new id203 law,
which takes into account the available knowledge: a id203 law that for
any event a, speci   es the id155 of a given b, denoted by
p(a| b).
we would like the conditional probabilities p(a| b) of di   erent events a
to constitute a legitimate id203 law, which satis   es the id203 axioms.
the conditional probabilities should also be consistent with our intuition in im-
portant special cases, e.g., when all possible outcomes of the experiment are
equally likely. for example, suppose that all six possible outcomes of a fair die
roll are equally likely. if we are told that the outcome is even, we are left with
only three possible outcomes, namely, 2, 4, and 6. these three outcomes were
equally likely to start with, and so they should remain equally likely given the
additional knowledge that the outcome was even. thus, it is reasonable to let

p(the outcome is 6| the outcome is even) =

1
3 .

this argument suggests that an appropriate de   nition of id155
when all outcomes are equally likely, is given by

p(a| b) =

number of elements of a     b
number of elements of b

.

generalizing the argument, we introduce the following de   nition of condi-

tional id203:

p(a| b) =

p(a     b)
p(b)

,

sec. 1.3

id155

19

where we assume that p(b) > 0; the id155 is unde   ned if the
conditioning event has zero id203. in words, out of the total id203 of
the elements of b, p(a| b) is the fraction that is assigned to possible outcomes
that also belong to a.

conditional probabilities specify a id203 law
for a    xed event b, it can be veri   ed that the conditional probabilities p(a| b)
form a legitimate id203 law that satis   es the three axioms. indeed, non-
negativity is clear. furthermore,

p(  | b) =

p(       b)
p(b)

=

p(b)
p(b)

= 1,

and the id172 axiom is also satis   ed. to verify the additivity axiom, we
write for any two disjoint events a1 and a2,

(cid:6)

(cid:7)

p(a1     a2 | b) =

p

(a1     a2)     b

p(b)

=

=

p(b)

p((a1     b)     (a2     b))
p(a1     b) + p(a2     b)
p(a1     b)
p(a2     b)

p(b)

+

p(b)

=
p(b)
= p(a1 | b) + p(a2 | b),

where for the third equality, we used the fact that a1     b and a2     b are
disjoint sets, and the additivity axiom for the (unconditional) id203 law.
the argument for a countable collection of disjoint sets is similar.

since conditional probabilities constitute a legitimate id203 law, all
general properties of id203 laws remain valid. for example, a fact such as
p(a     c)     p(a) + p(c) translates to the new fact

p(a     c | b)     p(a| b) + p(c | b).

let us also note that since we have p(b | b) = p(b)/p(b) = 1, all of the con-
ditional id203 is concentrated on b. thus, we might as well discard all
possible outcomes outside b and treat the conditional probabilities as a proba-
bility law de   ned on the new universe b.

let us summarize the conclusions reached so far.

20

sample space and id203

chap. 1

properties of id155

    the id155 of an event a, given an event b with

p(b) > 0, is de   ned by

p(a| b) =

p(a     b)
p(b)

,

and speci   es a new (conditional) id203 law on the same sample
space   . in particular, all properties of id203 laws remain valid
for id155 laws.
    conditional probabilities can also be viewed as a id203 law on a
new universe b, because all of the id155 is concen-
trated on b.

    if the possible outcomes are    nitely many and equally likely, then

p(a| b) =

number of elements of a     b
number of elements of b

.

example 1.6. we toss a fair coin three successive times. we wish to    nd the
id155 p(a| b) when a and b are the events

a = {more heads than tails come up},

b = {1st toss is a head}.

the sample space consists of eight sequences,

   = {hhh, hht, ht h, ht t, t hh, t ht, t t h, t t t},

which we assume to be equally likely. the event b consists of the four elements
hhh, hht, ht h, ht t , so its id203 is

p(b) =

4
8

.

the event a     b consists of the three elements hhh, hht, ht h, so its proba-
bility is

p(a     b) =
thus, the id155 p(a| b) is
p(a     b)
p(b)

p(a| b) =

3
8

.

=

3/8
4/8

=

3
4

.

because all possible outcomes are equally likely here, we can also compute p(a| b)
using a shortcut. we can bypass the calculation of p(b) and p(a    b), and simply

sec. 1.3

id155

21

divide the number of elements shared by a and b (which is 3) with the number of
elements of b (which is 4), to obtain the same result 3/4.

example 1.7. a fair 4-sided die is rolled twice and we assume that all sixteen
possible outcomes are equally likely. let x and y be the result of the 1st and the
2nd roll, respectively. we wish to determine the id155 p(a| b),
where

(cid:10)

(cid:8)

(cid:10)

(cid:8)

a =

max(x, y ) = m

,

b =

min(x, y ) = 2

,

and m takes each of the values 1, 2, 3, 4.
as in the preceding example, we can    rst determine the probabilities p(a   b)
and p(b) by counting the number of elements of a     b and b, respectively, and
dividing by 16. alternatively, we can directly divide the number of elements of
a     b with the number of elements of b; see fig. 1.8.

2nd roll y

4

3

2

1

all outcomes equally likely
id203 = 1/16

b

4

1

3
2
1st roll x

figure 1.8: sample space of an experiment involving two rolls of a 4-sided die.
(cf. example 1.7). the conditioning event b = {min(x, y ) = 2} consists of the
5-element shaded set. the set a = {max(x, y ) = m} shares with b two elements
if m = 3 or m = 4, one element if m = 2, and no element if m = 1. thus, we have

(cid:6)

{max(x, y ) = m}

p

(cid:13)

(cid:7)

(cid:9)(cid:9) b

=

2/5,

1/5,
0,

if m = 3 or m = 4,

if m = 2,
if m = 1.

example 1.8. a conservative design team, call it c, and an innovative design
team, call it n, are asked to separately design a new product within a month. from
past experience we know that:

(a) the id203 that team c is successful is 2/3.

(b) the id203 that team n is successful is 1/2.

(c) the id203 that at least one team is successful is 3/4.

22

sample space and id203

chap. 1

assuming that exactly one successful design is produced, what is the id203
that it was designed by team n?

there are four possible outcomes here, corresponding to the four combinations

of success and failure of the two teams:

ss: both succeed,
sf : c succeeds, n fails,

f f : both fail,
f s: c fails, n succeeds.

we were given that the probabilities of these outcomes satisfy

p(ss) + p(sf ) =

2
3

, p(ss) + p(f s) =

1
2

, p(ss) + p(sf ) + p(f s) =

3
4

.

from these relations, together with the id172 equation

p(ss) + p(sf ) + p(f s) + p(f f ) = 1,

we can obtain the probabilities of individual outcomes:

p(ss) =

5
12

,

p(sf ) =

1
4

,

p(f s) =

1
12

,

p(f f ) =

1
4

.

the desired id155 is

(cid:6)

p

f s

(cid:9)(cid:9) {sf, f s}
(cid:7)

1
12

+

1
12

=

1
4

=

1
4

.

using id155 for modeling

when constructing probabilistic models for experiments that have a sequential
character, it is often natural and convenient to    rst specify conditional prob-
abilities and then use them to determine unconditional probabilities. the rule
p(a   b) = p(b)p(a| b), which is a restatement of the de   nition of conditional
id203, is often helpful in this process.

example 1.9. radar detection. if an aircraft is present in a certain area, a
radar detects it and generates an alarm signal with id203 0.99. if an aircraft is
not present, the radar generates a (false) alarm, with id203 0.10. we assume
that an aircraft is present with id203 0.05. what is the id203 of no
aircraft presence and a false alarm? what is the id203 of aircraft presence
and no detection?

a sequential representation of the experiment is appropriate here, as shown

in fig. 1.9. let a and b be the events

a = {an aircraft is present},
b = {the radar generates an alarm},

sec. 1.3

id155

23

and consider also their complements

ac = {an aircraft is not present},
bc = {the radar does not generate an alarm}.

the given probabilities are recorded along the corresponding branches of the tree de-
scribing the sample space, as shown in fig. 1.9. each possible outcome corresponds
to a leaf of the tree, and its id203 is equal to the product of the probabilities
associated with the branches in a path from the root to the corresponding leaf. the
desired probabilities are
p(not present, false alarm) = p(ac     b) = p(ac)p(b | ac) = 0.95    0.10 = 0.095,
p(present, no detection) = p(a     bc) = p(a)p(bc | a) = 0.05    0.01 = 0.0005.

aircraft present

p(a) = 0.05

9

p ( b | a ) =  0 . 9

missed detection

p(bc| a) = 0.01

0

) =  0 . 1

false alarm

p(ac) = 0.95

c

p ( b | a

aircraft not present

p(

bc| ac

) = 0.90

figure 1.9: sequential description of the experiment for the radar detection
problem in example 1.9.

extending the preceding example, we have a general rule for calculating
various probabilities in conjunction with a tree-based sequential description of
an experiment. in particular:

(a) we set up the tree so that an event of interest is associated with a leaf.
we view the occurrence of the event as a sequence of steps, namely, the
traversals of the branches along the path from the root to the leaf.

(b) we record the conditional probabilities associated with the branches of the

tree.

(c) we obtain the id203 of a leaf by multiplying the probabilities recorded

along the corresponding path of the tree.

24

sample space and id203

chap. 1

in mathematical terms, we are dealing with an event a which occurs if and
only if each one of several events a1, . . . , an has occurred, i.e., a = a1     a2    
           an. the occurrence of a is viewed as an occurrence of a1, followed by the
occurrence of a2, then of a3, etc., and it is visualized as a path with n branches,
corresponding to the events a1, . . . , an. the id203 of a is given by the
following rule (see also fig. 1.10).

multiplication rule
assuming that all of the conditioning events have positive id203, we
have

p

i=1 ai

= p(a1)p(a2 | a1)p(a3 | a1     a2)       p

an |    n   1

i=1 ai

(cid:6)    n

(cid:7)

(cid:7)

.

(cid:6)

(cid:6)    n

p

i=1 ai

(cid:7)

the multiplication rule can be veri   ed by writing

= p(a1)    p(a1     a2)

p(a1)

   p(a1     a2     a3)
p(a1     a2)

(cid:6)    n
(cid:6)    n   1

i=1 ai
i=1 ai

(cid:7)
(cid:7) ,

       p
p

event a1  

    a2     a3

event a1  

    a2        
    
. . .
 

 an

a1

p(a1)

a2

a3

p(a2 |a1)

p(a3 |a1  

    a2)

. . .

an   1

an
    a2        
    
. . .
 

p(an |a1  

 an   1)

figure 1.10: visualization of the multiplication rule. the intersection event

a = a1     a2                  an is associated with a particular path on a tree that

describes the experiment. we associate the branches of this path with the events
a1, . . . , an, and we record next to the branches the corresponding conditional
probabilities.

the    nal node of the path corresponds to the intersection event a, and
its id203 is obtained by multiplying the conditional probabilities recorded
along the branches of the path

p(a1     a2                  an) = p(a1)p(a2 | a1)          p(an | a1     a2                  an   1).

note that any intermediate node along the path also corresponds to some inter-
section event and its id203 is obtained by multiplying the corresponding

conditional probabilities up to that node. for example, the event a1     a2     a3

corresponds to the node shown in the    gure, and its id203 is

p(a1     a2     a3) = p(a1)p(a2 | a1)p(a3 | a1     a2).

sec. 1.3

id155

25

and by using the de   nition of id155 to rewrite the right-hand
side above as

p(a1)p(a2 | a1)p(a3 | a1     a2)       p

an |    n   1

i=1 ai

(cid:6)

(cid:7)

.

for the case of just two events, a1 and a2, the multiplication rule is simply the
de   nition of id155.

example 1.10. three cards are drawn from an ordinary 52-card deck without
replacement (drawn cards are not placed back in the deck). we wish to    nd the
id203 that none of the three cards is a heart. we assume that at each step,
each one of the remaining cards is equally likely to be picked. by symmetry, this
implies that every triplet of cards is equally likely to be drawn. a cumbersome
approach, which we will not use, is to count the number of all card triplets that
do not include a heart, and divide it with the number of all possible card triplets.
instead, we use a sequential description of the experiment in conjunction with the
multiplication rule (cf. fig. 1.11).

de   ne the events

ai = {the ith card is not a heart},

i = 1, 2, 3.

we will calculate p(a1     a2     a3), the id203 that none of the three cards is

a heart, using the multiplication rule

p(a1     a2     a3) = p(a1)p(a2 | a1)p(a3 | a1     a2).

we have

p(a1) =

39
52

,

since there are 39 cards that are not hearts in the 52-card deck. given that the
   rst card is not a heart, we are left with 51 cards, 38 of which are not hearts, and

p(a2 | a1) =

38
51

.

finally, given that the    rst two cards drawn are not hearts, there are 37 cards which
are not hearts in the remaining 50-card deck, and

p(a3 | a1     a2) =

37
50

.

these probabilities are recorded along the corresponding branches of the tree de-
scribing the sample space, as shown in fig. 1.11. the desired id203 is now
obtained by multiplying the probabilities recorded along the corresponding path of
the tree:

p(a1     a2     a3) =

39
52

   38
51

   37
50

.

26

sample space and id203

chap. 1

not a heart

37/50

not a heart

38/51

heart

13/50

not a heart

39/52

heart

13/51

heart

13/52

figure 1.11: sequential description
of the experiment in the 3-card se-
lection problem of example 1.10.

note that once the probabilities are recorded along the tree, the id203

of several other events can be similarly calculated. for example,

p(1st is not a heart and 2nd is a heart) =

p(1st and 2nd are not hearts, and 3rd is a heart) =

39
52

39
52

   13
51
   38
51

,
   13
50

.

example 1.11. a class consisting of 4 graduate and 12 undergraduate students
is randomly divided into 4 groups of 4. what is the id203 that each group
includes a graduate student? we interpret    randomly    to mean that given the
assignment of some students to certain slots, any of the remaining students is equally
likely to be assigned to any of the remaining slots. we then calculate the desired
id203 using the multiplication rule, based on the sequential description shown
in fig. 1.12. let us denote the four graduate students by 1, 2, 3, 4, and consider
the events

a1 = {students 1 and 2 are in di   erent groups},
a2 = {students 1, 2, and 3 are in di   erent groups},
a3 = {students 1, 2, 3, and 4 are in di   erent groups}.

we will calculate p(a3) using the multiplication rule:

p(a3) = p(a1     a2     a3) = p(a1)p(a2 | a1)p(a3 | a1     a2).

we have

p(a1) =

12
15

,

since there are 12 student slots in groups other than the one of student 1, and there
are 15 student slots overall, excluding student 1. similarly,

p(a2 | a1) =

8
14

,

sec. 1.3

id155

27

students 1, 2, 3, & 4 are
in different groups 

4/13

students 1, 2, & 3 are
in different groups 

8/14

students 1 & 2 are
in different groups 

12/15

figure 1.12: sequential descrip-
tion of the experiment in the stu-
dent problem of example 1.11.

since there are 8 student slots in groups other than those of students 1 and 2, and
there are 14 student slots, excluding students 1 and 2. also,

p(a3 | a1     a2) =

4
13

,

since there are 4 student slots in groups other than those of students 1, 2, and 3,
and there are 13 student slots, excluding students 1, 2, and 3. thus, the desired
id203 is

12
15

   8
14

   4
13

,

and is obtained by multiplying the conditional probabilities along the corresponding
path of the tree in fig. 1.12.

example 1.12. the monty hall problem. this is a much discussed puzzle,
based on an old american game show. you are told that a prize is equally likely to
be found behind any one of three closed doors in front of you. you point to one of
the doors. a friend opens for you one of the remaining two doors, after making sure
that the prize is not behind it. at this point, you can stick to your initial choice,
or switch to the other unopened door. you win the prize if it lies behind your    nal
choice of a door. consider the following strategies:

(a) stick to your initial choice.

(b) switch to the other unopened door.

(c) you    rst point to door 1. if door 2 is opened, you do not switch. if door 3 is

opened, you switch.

which is the best strategy? to answer the question, let us calculate the id203
of winning under each of the three strategies.

under the strategy of no switching, your initial choice will determine whether
you win or not, and the id203 of winning is 1/3. this is because the prize is
equally likely to be behind each door.

under the strategy of switching, if the prize is behind the initially chosen
door (id203 1/3), you do not win. if it is not (id203 2/3), and given that

28

sample space and id203

chap. 1

another door without a prize has been opened for you, you will get to the winning
door once you switch. thus, the id203 of winning is now 2/3, so (b) is a better
strategy than (a).

consider now strategy (c). under this strategy, there is insu   cient informa-
tion for determining the id203 of winning. the answer depends on the way
that your friend chooses which door to open. let us consider two possibilities.

suppose that if the prize is behind door 1, your friend always chooses to open
door 2. (if the prize is behind door 2 or 3, your friend has no choice.) if the prize
is behind door 1, your friend opens door 2, you do not switch, and you win. if the
prize is behind door 2, your friend opens door 3, you switch, and you win. if the
prize is behind door 3, your friend opens door 2, you do not switch, and you lose.
thus, the id203 of winning is 2/3, so strategy (c) in this case is as good as
strategy (b).

suppose now that if the prize is behind door 1, your friend is equally likely to
open either door 2 or 3. if the prize is behind door 1 (id203 1/3), and if your
friend opens door 2 (id203 1/2), you do not switch and you win (id203
1/6). but if your friend opens door 3, you switch and you lose. if the prize is behind
door 2, your friend opens door 3, you switch, and you win (id203 1/3). if the
prize is behind door 3, your friend opens door 2, you do not switch and you lose.
thus, the id203 of winning is 1/6 + 1/3 = 1/2, so strategy (c) in this case is
inferior to strategy (b).

1.4 total id203 theorem and bayes    rule

in this section, we explore some applications of id155. we start
with the following theorem, which is often useful for computing the probabilities
of various events, using a    divide-and-conquer    approach.

total id203 theorem
let a1, . . . , an be disjoint events that form a partition of the sample space
(each possible outcome is included in exactly one of the events a1, . . . , an)
and assume that p(ai) > 0, for all i. then, for any event b, we have

p(b) = p(a1     b) +        + p(an     b)

= p(a1)p(b | a1) +        + p(an)p(b | an).

the theorem is visualized and proved in fig. 1.13. intuitively, we are par-
titioning the sample space into a number of scenarios (events) ai. then, the
id203 that b occurs is a weighted average of its id155
under each scenario, where each scenario is weighted according to its (uncondi-
tional) id203. one of the uses of the theorem is to compute the id203
of various events b for which the conditional probabilities p(b | ai) are known or

sec. 1.4

total id203 theorem and bayes    rule

29

easy to derive. the key is to choose appropriately the partition a1, . . . , an, and
this choice is often suggested by the problem structure. here are some examples.

a1

b

a2

a3

a1

a2

a3

    b

a1  

    b

a2  

    b

a3  

b

bc

b

bc

b

bc

figure 1.13: visualization and veri   cation of the total id203 theorem. the
events a1, . . . , an form a partition of the sample space, so the event b can be
decomposed into the disjoint union of its intersections ai     b with the sets ai,

i.e.,

b = (a1     b)                  (an     b).

using the additivity axiom, it follows that

p(b) = p(a1     b) +          + p(an     b).

since, by the de   nition of id155, we have

p(ai     b) = p(ai)p(b | ai),

the preceding equality yields

p(b) = p(a1)p(b | a1) +          + p(an)p(b | an).

for an alternative view, consider an equivalent sequential model, as shown

on the right. the id203 of the leaf ai     b is the product p(ai)p(b | ai) of

the probabilities along the path leading to that leaf. the event b consists of the
three highlighted leaves and p(b) is obtained by adding their probabilities.

example 1.13. you enter a chess tournament where your id203 of winning
a game is 0.3 against half the players (call them type 1), 0.4 against a quarter of
the players (call them type 2), and 0.5 against the remaining quarter of the players
(call them type 3). you play a game against a randomly chosen opponent. what
is the id203 of winning?

let ai be the event of playing with an opponent of type i. we have

p(a1) = 0.5,

p(a2) = 0.25,

p(a3) = 0.25.

also, let b be the event of winning. we have

p(b | a1) = 0.3,

p(b | a2) = 0.4,

p(b | a3) = 0.5.

30

sample space and id203

chap. 1

thus, by the total id203 theorem, the id203 of winning is

p(b) = p(a1)p(b | a1) + p(a2)p(b | a2) + p(a3)p(b | a3)

= 0.5    0.3 + 0.25    0.4 + 0.25    0.5
= 0.375.

example 1.14. you roll a fair four-sided die. if the result is 1 or 2, you roll once
more but otherwise, you stop. what is the id203 that the sum total of your
rolls is at least 4?

let ai be the event that the result of    rst roll is i, and note that p(ai) = 1/4
for each i. let b be the event that the sum total is at least 4. given the event a1,
the sum total will be at least 4 if the second roll results in 3 or 4, which happens
with id203 1/2. similarly, given the event a2, the sum total will be at least
4 if the second roll results in 2, 3, or 4, which happens with id203 3/4. also,
given the event a3, you stop and the sum total remains below 4. therefore,
p(b | a4) = 1.

p(b | a3) = 0,

p(b | a2) =

p(b | a1) =

,

,

1
2

3
4

by the total id203 theorem,

p(b) =

   1
2

1
4

+

   3
4

1
4

+

1
4

   0 +

1
4

   1 =

9
16

.

the total id203 theorem can be applied repeatedly to calculate proba-
bilities in experiments that have a sequential character, as shown in the following
example.

example 1.15. alice is taking a id203 class and at the end of each week
she can be either up-to-date or she may have fallen behind. if she is up-to-date in
a given week, the id203 that she will be up-to-date (or behind) in the next
week is 0.8 (or 0.2, respectively). if she is behind in a given week, the id203
that she will be up-to-date (or behind) in the next week is 0.4 (or 0.6, respectively).
alice is (by default) up-to-date when she starts the class. what is the id203
that she is up-to-date after three weeks?

let ui and bi be the events that alice is up-to-date or behind, respectively,
after i weeks. according to the total id203 theorem, the desired id203
p(u3) is given by

p(u3) = p(u2)p(u3 | u2) + p(b2)p(u3 | b2) = p(u2)    0.8 + p(b2)    0.4.

the probabilities p(u2) and p(b2) can also be calculated using the total id203
theorem:

p(u2) = p(u1)p(u2 | u1) + p(b1)p(u2 | b1) = p(u1)    0.8 + p(b1)    0.4,
p(b2) = p(u1)p(b2 | u1) + p(b1)p(b2 | b1) = p(u1)    0.2 + p(b1)    0.6.

sec. 1.4

total id203 theorem and bayes    rule

31

finally, since alice starts her class up-to-date, we have

p(u1) = 0.8,

p(b1) = 0.2.

we can now combine the preceding three equations to obtain

p(u2) = 0.8    0.8 + 0.2    0.4 = 0.72,

p(b2) = 0.8    0.2 + 0.2    0.6 = 0.28,

and by using the above probabilities in the formula for p(u3):

p(u3) = 0.72    0.8 + 0.28    0.4 = 0.688.

note that we could have calculated the desired id203 p(u3) by con-
structing a tree description of the experiment, then calculating the id203 of
every element of u3 using the multiplication rule on the tree, and adding. however,
there are cases where the calculation based on the total id203 theorem is more
convenient. for example, suppose we are interested in the id203 p(u20) that
alice is up-to-date after 20 weeks. calculating this id203 using the multipli-
cation rule is very cumbersome, because the tree representing the experiment is 20
stages deep and has 220 leaves. on the other hand, with a computer, a sequential
calculation using the total id203 formulas

p(ui+1) = p(ui)    0.8 + p(bi)    0.4,

p(bi+1) = p(ui)    0.2 + p(bi)    0.6,

and the initial conditions p(u1) = 0.8, p(b1) = 0.2, is very simple.

id136 and bayes    rule

the total id203 theorem is often used in conjunction with the following
celebrated theorem, which relates conditional probabilities of the form p(a | b)
to conditional probabilities of the form p(b | a), in which the order of the con-
ditioning is reversed.

bayes    rule

let a1, a2, . . . , an be disjoint events that form a partition of the sample
space, and assume that p(ai) > 0, for all i. then, for any event b such
that p(b) > 0, we have

p(ai | b) =

p(ai)p(b | ai)

p(b)

=

p(ai)p(b | ai)

p(a1)p(b | a1) +          + p(an)p(b | an)

.

32

sample space and id203

chap. 1

cause 1:
malignant tumor

cause 3:
other

a1

effect:
shade  observed

b

a2

a3

cause 2:
nonmalignant
tumor

a1

a2

a3

    b

a1  

    b

a2  

    b

a3  

b

bc

b

bc

b

bc

figure 1.14: an example of the id136 context that is implicit in bayes   
rule. we observe a shade in a person   s x-ray (this is event b, the    e   ect   ) and
we want to estimate the likelihood of three mutually exclusive and collectively
exhaustive potential causes: cause 1 (event a1) is that there is a malignant tumor,
cause 2 (event a2) is that there is a nonmalignant tumor, and cause 3 (event
a3) corresponds to reasons other than a tumor. we assume that we know the
probabilities p(ai) and p(b | ai), i = 1, 2, 3. given that we see a shade (event

b occurs), bayes    rule gives the posterior probabilities of the various causes as

p(ai | b) =

p(a1)p(b | a1) + p(a2)p(b | a2) + p(a3)p(b | a3)

p(ai)p(b | ai)

,

i = 1, 2, 3.

for an alternative view, consider an equivalent sequential model, as shown

on the right. the id203 p(a1 | b) of a malignant tumor is the id203
of the    rst highlighted leaf, which is p(a1     b), divided by the total id203

of the highlighted leaves, which is p(b).

to verify bayes    rule, note that by the de   nition of id155,

we have

p(ai     b) = p(ai)p(b | ai) = p(ai | b)p(b).

this yields the    rst equality. the second equality follows from the    rst by using
the total id203 theorem to rewrite p(b).

bayes    rule is often used for id136. there are a number of    causes   
that may result in a certain    e   ect.    we observe the e   ect, and we wish to infer
the cause. the events a1, . . . , an are associated with the causes and the event b
represents the e   ect. the id203 p(b | ai) that the e   ect will be observed
when the cause ai is present amounts to a probabilistic model of the cause-e   ect
relation (cf. fig. 1.14). given that the e   ect b has been observed, we wish to
evaluate the id203 p(ai | b) that the cause ai is present. we refer to
p(ai | b) as the posterior id203 of event ai given the information, to
be distinguished from p(ai), which we call the prior id203.

sec. 1.4

total id203 theorem and bayes    rule

33

example 1.16. let us return to the radar detection problem of example 1.9 and
fig. 1.9. let

a = {an aircraft is present},
b = {the radar generates an alarm}.

we are given that

p(a) = 0.05,

p(b | a) = 0.99,

p(b | ac) = 0.1.

applying bayes    rule, with a1 = a and a2 = ac, we obtain

p(aircraft present| alarm) = p(a| b)

p(a)p(b | a)

p(b)

=

=

p(a)p(b | a)

p(a)p(b | a) + p(ac)p(b | ac)
0.05    0.99 + 0.95    0.1

0.05    0.99

=
    0.3426.

example 1.17. let us return to the chess problem of example 1.13. here, ai is
the event of getting an opponent of type i, and

p(a1) = 0.5,

p(a2) = 0.25,

p(a3) = 0.25.

also, b is the event of winning, and

p(b | a1) = 0.3,

p(b | a2) = 0.4,

p(b | a3) = 0.5.

suppose that you win. what is the id203 p(a1 | b) that you had an opponent

of type 1?

using bayes    rule, we have

p(a1 | b) =

=

p(a1)p(b | a1)

p(a1)p(b | a1) + p(a2)p(b | a2) + p(a3)p(b | a3)
0.5    0.3 + 0.25    0.4 + 0.25    0.5

0.5    0.3

= 0.4.

example 1.18. the false-positive puzzle. a test for a certain rare disease is
assumed to be correct 95% of the time: if a person has the disease, the test results
are positive with id203 0.95, and if the person does not have the disease,
the test results are negative with id203 0.95. a random person drawn from

34

sample space and id203

chap. 1

a certain population has id203 0.001 of having the disease. given that the
person just tested positive, what is the id203 of having the disease?
test results are positive, the desired id203, p(a| b), is

if a is the event that the person has the disease, and b is the event that the

p(a| b) =

=

p(a)p(b | a)

p(a)p(b | a) + p(ac)p(b | ac)
0.001    0.95 + 0.999    0.05

0.001    0.95

= 0.0187.

note that even though the test was assumed to be fairly accurate, a person who has
tested positive is still very unlikely (less than 2%) to have the disease. according
to the economist (february 20th, 1999), 80% of those questioned at a leading
american hospital substantially missed the correct answer to a question of this
type; most of them thought that the id203 that the person has the disease
is 0.95!

1.5 independence

we have introduced the id155 p(a| b) to capture the partial
information that event b provides about event a. an interesting and important
special case arises when the occurrence of b provides no such information and
does not alter the id203 that a has occurred, i.e.,

p(a| b) = p(a).

when the above equality holds, we say that a is independent of b. note that
by the de   nition p(a| b) = p(a     b)/p(b), this is equivalent to

p(a     b) = p(a)p(b).

we adopt this latter relation as the de   nition of independence because it can be
used even when p(b) = 0, in which case p(a| b) is unde   ned. the symmetry
of this relation also implies that independence is a symmetric property; that is,
if a is independent of b, then b is independent of a, and we can unambiguously
say that a and b are independent events.

independence is often easy to grasp intuitively. for example, if the occur-
rence of two events is governed by distinct and noninteracting physical processes,
such events will turn out to be independent. on the other hand, independence
is not easily visualized in terms of the sample space. a common    rst thought
is that two events are independent if they are disjoint, but in fact the oppo-
site is true: two disjoint events a and b with p(a) > 0 and p(b) > 0 are
never independent, since their intersection a    b is empty and has id203 0.

sec. 1.5

independence

35

for example, an event a and its complement ac are not independent [unless
p(a) = 0 or p(a) = 1], since knowledge that a has occurred provides precise
information about whether ac has occurred.

example 1.19. consider an experiment involving two successive rolls of a 4-sided
die in which all 16 possible outcomes are equally likely and have id203 1/16.

(a) are the events

ai = {1st roll results in i},

bj = {2nd roll results in j},

independent? we have

(cid:6)
p(ai     bj) = p

the outcome of the two rolls is (i, j)

=

(cid:7)

1
16

,

p(ai) =

p(bj) =

number of elements of ai

total number of possible outcomes

number of elements of bj

total number of possible outcomes

=

=

4
16

4
16

,

.

we observe that p(ai     bj) = p(ai)p(bj), and the independence of ai and
bj is veri   ed. thus, our choice of the discrete uniform id203 law implies
the independence of the two rolls.

(b) are the events

b = {sum of the two rolls is a 5},

a = {1st roll is a 1},
(cid:6)
p(a     b) = p

independent? the answer here is not quite obvious. we have

the result of the two rolls is (1,4)

(cid:7)

=

1
16

,

and also

p(a) =

number of elements of a

total number of possible outcomes

=

4
16

.

the event b consists of the outcomes (1,4), (2,3), (3,2), and (4,1), and

p(b) =

number of elements of b

total number of possible outcomes

=

4
16

.

thus, we see that p(a     b) = p(a)p(b), and the events a and b are
independent.

(c) are the events

a = {maximum of the two rolls is 2}, b = {minimum of the two rolls is 2},

36

sample space and id203

chap. 1

independent? intuitively, the answer is    no    because the minimum of the
two rolls conveys some information about the maximum. for example, if the
minimum is 2, the maximum cannot be 1. more precisely, to verify that a
and b are not independent, we calculate

(cid:6)
p(a     b) = p

the result of the two rolls is (2,2)

=

(cid:7)

1
16

,

and also

p(a) =

p(b) =

number of elements of a

total number of possible outcomes

number of elements of b

total number of possible outcomes

=

=

3
16

,

5
16

.

we have p(a)p(b) = 15/(16)2, so that p(a     b) (cid:4)= p(a)p(b), and a and
b are not independent.

we    nally note that, as mentioned earlier, if a and b are independent, the
occurrence of b does not provide any new information on the id203 of a
occurring. it is then intuitive that the non-occurrence of b should also provide
no information on the id203 of a. indeed, it can be veri   ed that if a and
b are independent, the same holds true for a and bc (see the end-of-chapter
problems).

conditional independence

we noted earlier that the conditional probabilities of events, conditioned on
a particular event, form a legitimate id203 law. we can thus talk about
independence of various events with respect to this conditional law. in particular,
given an event c, the events a and b are called conditionally independent
if

p(a     b | c) = p(a| c)p(b | c).

to derive an alternative characterization of conditional independence, we use the
de   nition of the id155 and the multiplication rule, to write

p(a     b | c) =

p(a     b     c)

p(c)

p(c)p(b | c)p(a| b     c)

=
= p(b | c)p(a| b     c).

p(c)

we now compare the preceding two expressions, and after eliminating the com-
mon factor p(b | c), assumed nonzero, we see that conditional independence is
the same as the condition

p(a| b     c) = p(a| c).

sec. 1.5

independence

37

in words, this relation states that if c is known to have occurred, the additional
knowledge that b also occurred does not change the id203 of a.

interestingly, independence of two events a and b with respect to the
unid155 law, does not imply conditional independence, and
vice versa, as illustrated by the next two examples.

example 1.20. consider two independent fair coin tosses, in which all four possible
outcomes are equally likely. let

h1 = {1st toss is a head},
h2 = {2nd toss is a head},
d = {the two tosses have di   erent results}.

the events h1 and h2 are (unconditionally) independent. but

p(h1 | d) =

p(h2 | d) =

,

p(h1     h2 | d) = 0,

,

1
2

1
2

so that p(h1     h2 | d) (cid:4)= p(h1 | d)p(h2 | d), and h1, h2 are not conditionally

independent.
this example can be generalized. for any probabilistic model, let a and b be
independent events, and let c be an event such that p(c) > 0, p(a| c) > 0, and
p(b | c) > 0, while a     b     c is empty. then, a and b cannot be conditionally
independent (given c) since p(a     b | c) = 0 while p(a| c) p(b | c) > 0.

example 1.21. there are two coins, a blue and a red one. we choose one of
the two at random, each being chosen with id203 1/2, and proceed with two
independent tosses. the coins are biased: with the blue coin, the id203 of
heads in any given toss is 0.99, whereas for the red coin it is 0.01.

let b be the event that the blue coin was selected. let also hi be the event
that the ith toss resulted in heads. given the choice of a coin, the events h1 and
h2 are independent, because of our assumption of independent tosses. thus,

p(h1     h2 | b) = p(h1 | b)p(h2 | b) = 0.99    0.99.

on the other hand, the events h1 and h2 are not independent. intuitively, if we
are told that the    rst toss resulted in heads, this leads us to suspect that the blue
coin was selected, in which case, we expect the second toss to also result in heads.
mathematically, we use the total id203 theorem to obtain
   0.99 +

p(h1) = p(b)p(h1 | b) + p(bc)p(h1 | bc) =

   0.01 =

,

1
2

1
2

1
2

as should be expected from symmetry considerations. similarly, we have p(h2) =
1/2. now notice that

p(h1     h2) = p(b)p(h1     h2 | b) + p(bc)p(h1     h2 | bc)

=

1
2

   0.99    0.99 +

   0.01    0.01     1
2

.

1
2

38

sample space and id203

chap. 1

thus, p(h1     h2) (cid:4)= p(h1)p(h2), and the events h1 and h2 are dependent, even

though they are conditionally independent given b.

we now summarize.

independence

    two events a and b are said to be independent if

p(a     b) = p(a)p(b).

if in addition, p(b) > 0, independence is equivalent to the condition

p(a| b) = p(a).

    if a and b are independent, so are a and bc.
    two events a and b are said to be conditionally independent,

given another event c with p(c) > 0, if

p(a     b | c) = p(a| c)p(b | c).

if in addition, p(b     c) > 0, conditional independence is equivalent
to the condition

p(a| b     c) = p(a| c).

    independence does not imply conditional independence, and vice versa.

independence of a collection of events

the de   nition of independence can be extended to multiple events.

de   nition of independence of several events
we say that the events a1, a2, . . . , an are independent if

(cid:4)(cid:3)

(cid:5)

ai

=

p

i   s

(cid:14)

i   s

p(ai),

for every subset s of {1, 2, . . . , n}.

sec. 1.5

independence

39

for the case of three events, a1, a2, and a3, independence amounts to

satisfying the four conditions

p(a1     a2) = p(a1) p(a2),
p(a1     a3) = p(a1) p(a3),
p(a2     a3) = p(a2) p(a3),

p(a1     a2     a3) = p(a1) p(a2) p(a3).

the    rst three conditions simply assert that any two events are independent,
a property known as pairwise independence. but the fourth condition is
also important and does not follow from the    rst three. conversely, the fourth
condition does not imply the    rst three; see the two examples that follow.

example 1.22. pairwise independence does not imply independence.
consider two independent fair coin tosses, and the following events:

h1 = {1st toss is a head},
h2 = {2nd toss is a head},
d = {the two tosses have di   erent results}.

the events h1 and h2 are independent, by de   nition. to see that h1 and d are
independent, we note that

p(d | h1) =

p(h1     d)

p(h1)

=

1/4
1/2

=

1
2

= p(d).

similarly, h2 and d are independent. on the other hand, we have

p(h1     h2     d) = 0 (cid:4)=

   1
2

   1
2

1
2

= p(h1)p(h2)p(d),

and these three events are not independent.

example 1.23. the equality p(a1     a2     a3) = p(a1) p(a2) p(a3) is not

enough for independence. consider two independent rolls of a fair six-sided
die, and the following events:

a = {1st roll is 1, 2, or 3},
b = {1st roll is 3, 4, or 5},
c = {the sum of the two rolls is 9}.

we have

p(a     b) =
p(a     c) =
p(b     c) =

(cid:4)=
1
2
(cid:4)=
(cid:4)=

   1
2
   4
36
   4
36

1
2

1
2

1
6

1
36

1
12

= p(a)p(b),

= p(a)p(c),

= p(b)p(c).

40

sample space and id203

chap. 1

thus the three events a, b, and c are not independent, and indeed no two of these
events are independent. on the other hand, we have

p(a     b     c) =

1
36

=

   1
2

   4
36

1
2

= p(a)p(b)p(c).

the intuition behind the independence of a collection of events is anal-
ogous to the case of two events.
independence means that the occurrence or
non-occurrence of any number of the events from that collection carries no
information on the remaining events or their complements. for example, if the
events a1, a2, a3, a4 are independent, one obtains relations such as

or

p(a1     a2 | a3     a4) = p(a1     a2)
p(a1     ac
    a4) = p(a1     ac
2);
2
see the end-of-chapter problems.

| ac

3

reliability

in probabilistic models of complex systems involving several components, it is
often convenient to assume that the behaviors of the components are uncoupled
(independent). this typically simpli   es the calculations and the analysis, as
illustrated in the following example.

example 1.24. network connectivity. a computer network connects two
nodes a and b through intermediate nodes c, d, e, f, as shown in fig. 1.15(a).
for every pair of directly connected nodes, say i and j, there is a given id203
pij that the link from i to j is up. we assume that link failures are independent
of each other. what is the id203 that there is a path connecting a and b in
which all links are up?

a

0.9

0.75

c

d

0.8

0.95

e

f

0.9

0.85

b

0.95

1

2

3

series connection

1

2

3

(a)

parallel connection

(b)

figure 1.15: (a) network for example 1.24. the number next to each link
indicates the id203 that the link is up. (b) series and parallel connections
of three components in a reliability problem.

sec. 1.5

independence

41

this is a typical problem of assessing the reliability of a system consisting of
components that can fail independently. such a system can often be divided into
subsystems, where each subsystem consists in turn of several components that are
connected either in series or in parallel; see fig. 1.15(b).

let a subsystem consist of components 1, 2, . . . , m, and let pi be the prob-
ability that component i is up (   succeeds   ). then, a series subsystem succeeds
if all of its components are up, so its id203 of success is the product of the
probabilities of success of the corresponding components, i.e.,

p(series subsystem succeeds) = p1p2        pm.

a parallel subsystem succeeds if any one of its components succeeds, so its prob-
ability of failure is the product of the probabilities of failure of the corresponding
components, i.e.,

p(parallel subsystem succeeds) = 1     p(parallel subsystem fails)
= 1     (1     p1)(1     p2)       (1     pm).

returning now to the network of fig. 1.15(a), we can calculate the probabil-
ity of success (a path from a to b is available) sequentially, using the preceding
formulas, and starting from the end. let us use the notation x     y to denote the
event that there is a (possibly indirect) connection from node x to node y . then,
p(c     b) = 1    

(cid:7)
1     p(c     f and f     b)

(cid:6)

(cid:7)(cid:6)
1     p(c     e and e     b)
= 1     (1     pcepeb)(1     pcf pf b)
= 1     (1     0.8    0.9)(1     0.95    0.85)
= 0.946,

p(a     c and c     b) = p(a     c)p(c     b) = 0.9    0.946 = 0.851,
p(a     d and d     b) = p(a     d)p(d     b) = 0.75    0.95 = 0.712,

and    nally we obtain the desired id203
p(a     b) = 1    

(cid:7)(cid:6)
1     p(a     c and c     b)

(cid:6)

(cid:7)
1     p(a     d and d     b)

= 1     (1     0.851)(1     0.712)
= 0.957.

independent trials and the binomial probabilities

if an experiment involves a sequence of independent but identical stages, we say
that we have a sequence of independent trials. in the special case where there
are only two possible results at each stage, we say that we have a sequence of
independent bernoulli trials. the two possible results can be anything, e.g.,
   it rains    or    it doesn   t rain,    but we will often think in terms of coin tosses and
refer to the two results as    heads    (h) and    tails    (t ).

42

sample space and id203

chap. 1

consider an experiment that consists of n independent tosses of a coin, in
which the id203 of heads is p, where p is some number between 0 and 1. in
this context, independence means that the events a1, a2, . . . , an are indepen-
dent, where ai = {ith toss is a head}.

we can visualize independent bernoulli trials by means of a sequential
description, as shown in fig. 1.16 for the case where n = 3. the conditional
id203 of any toss being a head, conditioned on the results of any preced-
ing tosses is p, because of independence. thus, by multiplying the conditional
probabilities along the corresponding path of the tree, we see that any particular
outcome (3-long sequence of heads and tails) that involves k heads and 3     k
tails has id203 pk(1     p)3   k. this formula extends to the case of a general
number n of tosses. we obtain that the id203 of any particular n-long
sequence that contains k heads and n     k tails is pk(1     p)n   k, for all k from 0
to n.

p

h

p

1     p

1     p

p

t

1     p

p

hh

hhh

prob = p3

1     p

p

1     p

p

1     p

p

1     p

hh t

prob = p2(1     p)

h t h

prob = p2(1     p)

h t t

prob = p(1     p)2

t h h

prob = p2(1     p)

t h t

t th

prob = p(1     p)2

prob = p(1     p)2

t t t

prob = (1     p)3

h t

th

t t

figure 1.16: sequential description of an experiment involving three indepen-
dent tosses of a coin. along the branches of the tree, we record the corresponding
conditional probabilities, and by the multiplication rule, the id203 of ob-
taining a particular 3-toss sequence is calculated by multiplying the probabilities
recorded along the corresponding path of the tree.

let us now consider the id203

p(k) = p(k heads come up in an n-toss sequence),

which will play an important role later. we showed above that the id203
of any given sequence that contains k heads is pk(1     p)n   k, so we have

(cid:15)

(cid:16)

n
k

p(k) =

pk(1     p)n   k,

sec. 1.5

independence

43

where we use the notation

(cid:15)

(cid:16)

n
k

(cid:6)

(cid:7)

= number of distinct n-toss sequences that contain k heads.

the numbers
(read as    n choose k   ) are known as the binomial coe   -
cients, while the probabilities p(k) are known as the binomial probabilities.
using a counting argument, to be given in section 1.6, we can show that

n
k

(cid:15)

(cid:16)

n
k

=

n!

k! (n     k)! ,

k = 0, 1, . . . , n,

where for any positive integer i we have

i! = 1    2       (i     1)    i,

and, by convention, 0! = 1. an alternative veri   cation is sketched in the end-of-
chapter problems. note that the binomial probabilities p(k) must add to 1, thus
showing the binomial formula

(cid:15)

n(cid:12)

(cid:16)

n
k

k=0

pk(1     p)n   k = 1.

example 1.25. grade of service. an internet service provider has installed c
modems to serve the needs of a population of n dialup customers. it is estimated
that at a given time, each customer will need a connection with id203 p,
independent of the others. what is the id203 that there are more customers
needing a connection than there are modems?

here we are interested in the id203 that more than c customers simul-

taneously need a connection. it is equal to

n(cid:12)
(cid:15)
(cid:16)

k=c+1

p(k),

where

p(k) =

n
k

pk(1     p)n   k

are the binomial probabilities. for instance, if n = 100, p = 0.1, and c = 15, the
id203 of interest turns out to be 0.0399.

this example is typical of problems of sizing a facility to serve the needs
of a homogeneous population, consisting of independently acting customers. the
problem is to select the facility size to guarantee a certain id203 (sometimes
called grade of service) that no user is left unserved.

44

sample space and id203

chap. 1

1.6 counting

the calculation of probabilities often involves counting the number of outcomes
in various events. we have already seen two contexts where such counting arises.
(a) when the sample space    has a    nite number of equally likely outcomes,
so that the discrete uniform id203 law applies. then, the id203
of any event a is given by

p(a) =

number of elements of a
number of elements of    ,

and involves counting the elements of a and of   .

(b) when we want to calculate the id203 of an event a with a    nite
number of equally likely outcomes, each of which has an already known
id203 p. then the id203 of a is given by

p(a) = p    (number of elements of a),

and involves counting the number of elements of a. an example of this type
is the calculation of the id203 of k heads in n coin tosses (the binomial
probabilities). we saw in the preceding section that the id203 of each
distinct sequence involving k heads is easily obtained, but the calculation
of the number of all such sequences, to be presented shortly, requires some
thought.
while counting is in principle straightforward, it is frequently challenging;
the art of counting constitutes a large portion of the    eld of combinatorics. in
this section, we present the basic principle of counting and apply it to a number
of situations that are often encountered in probabilistic models.

the counting principle

the counting principle is based on a divide-and-conquer approach, whereby the
counting is broken down into stages through the use of a tree. for example,
consider an experiment that consists of two consecutive stages. the possible
results of the    rst stage are a1, a2, . . . , am; the possible results of the second
stage are b1, b2, . . . , bn. then, the possible results of the two-stage experiment
are all possible ordered pairs (ai, bj), i = 1, . . . , m, j = 1, . . . , n. note that the
number of such ordered pairs is equal to mn. this observation can be generalized
as follows (see also fig. 1.17).

sec. 1.6

counting

45

. . . . . . 
. . . 

. . . 
. . . . . . 
. . . . . . 

leaves

n1
choices

n2

n3

n4

choices choices choices

stage1

stage2 stage3 stage4

figure 1.17: illustration of the basic counting principle. the counting is carried
out in r stages (r = 4 in the    gure). the    rst stage has n1 possible results. for
every possible result at the    rst i     1 stages, there are ni possible results at the
ith stage. the number of leaves is n1n2          nr. this is the desired count.

the counting principle

consider a process that consists of r stages. suppose that:

(a) there are n1 possible results at the    rst stage.

(b) for every possible result at the    rst stage, there are n2 possible results

at the second stage.

(c) more generally, for any sequence of possible results at the    rst i     1

stages, there are ni possible results at the ith stage.

then, the total number of possible results of the r-stage process is

n1n2          nr.

example 1.26. the number of telephone numbers. a local telephone
number is a 7-digit sequence, but the    rst digit has to be di   erent from 0 or 1.
how many distinct telephone numbers are there? we can visualize the choice of a
sequence as a sequential process, where we select one digit at a time. we have a
total of 7 stages, and a choice of one out of 10 elements at each stage, except for

46

sample space and id203

chap. 1

the    rst stage where we only have 8 choices. therefore, the answer is

(cid:20)
(cid:17)
8    10    10       10

(cid:18)(cid:19)

= 8    106.

6 times

example 1.27. the number of subsets of an n-element set. consider

an n-element set {s1, s2, . . . , sn}. how many subsets does it have (including itself

and the empty set)? we can visualize the choice of a subset as a sequential process
where we examine one element at a time and decide whether to include it in the set
or not. we have a total of n stages, and a binary choice at each stage. therefore
the number of subsets is

(cid:17) (cid:18)(cid:19) (cid:20)
2    2       2

= 2n.

n times

it should be noted that the counting principle remains valid even if each
   rst-stage result leads to a di   erent set of potential second-stage results, etc. the
only requirement is that the number of possible second-stage results is constant,
regardless of the    rst-stage result.

in what follows, we will focus primarily on two types of counting arguments
that involve the selection of k objects out of a collection of n objects. if the order
of selection matters, the selection is called a permutation, and otherwise, it is
called a combination. we will then discuss a more general type of counting,
involving a partition of a collection of n objects into multiple subsets.

k-permutations
we start with n distinct objects, and let k be some positive integer, with k     n.
we wish to count the number of di   erent ways that we can pick k out of these
n objects and arrange them in a sequence, i.e., the number of distinct k-object
sequences. we can choose any of the n objects to be the    rst one. having chosen
the    rst, there are only n     1 possible choices for the second; given the choice of
the    rst two, there only remain n     2 available objects for the third stage, etc.
when we are ready to select the last (the kth) object, we have already chosen
k     1 objects, which leaves us with n     (k     1) choices for the last one. by the
counting principle, the number of possible sequences, called k-permutations,
is

n(n     1)       (n     k + 1) = n(n     1)       (n     k + 1)(n     k)       2    1

(n     k)       2    1

=

n!

(n     k)! .

in the special case where k = n, the number of possible sequences, simply called
permutations, is

n(n     1)(n     2)       2    1 = n!.

(let k = n in the formula for the number of k-permutations, and recall the
convention 0! = 1.)

sec. 1.6

counting

47

example 1.28. let us count the number of words that consist of four distinct
letters. this is the problem of counting the number of 4-permutations of the 26
letters in the alphabet. the desired number is

n!

(n     k)!

=

26!
22!

= 26    25    24    23 = 358, 800.

the count for permutations can be combined with the counting principle

to solve more complicated counting problems.

example 1.29. you have n1 classical music cds, n2 rock music cds, and n3
country music cds. in how many di   erent ways can you arrange them so that the
cds of the same type are contiguous?

we break down the problem in two stages, where we    rst select the order of
the cd types, and then the order of the cds of each type. there are 3! ordered se-
quences of the types of cds (such as classical/rock/country, rock/country/classical,
etc.), and there are n1! (or n2!, or n3!) permutations of the classical (or rock, or
country, respectively) cds. thus for each of the 3! cd type sequences, there are
n1! n2! n3! arrangements of cds, and the desired total number is 3! n1! n2! n3!.

suppose now that you o   er to give ki out of the ni cds of each type i to a
friend, where ki < ni, i = 1, 2, 3. what is the number of all possible arrangements
of the cds that you are left with? the solution is similar, except that the number of
(ni     ki)-permutations of cds of type i replaces ni! in the estimate, so the number

of possible arrangements is

3!    n1!
k1!

   n2!
k2!

   n3!
k3!

.

combinations

there are n people and we are interested in forming a committee of k. how
many di   erent committees are possible? more abstractly, this is the same as the
problem of counting the number of k-element subsets of a given n-element set.
notice that forming a combination is di   erent than forming a k-permutation,
because in a combination there is no ordering of the selected elements.
for example, whereas the 2-permutations of the letters a, b, c, and d are

ab, ba, ac, ca, ad, da, bc, cb, bd, db, cd, dc,

the combinations of two out of these four letters are

ab, ac, ad, bc, bd, cd.

in the preceding example, the combinations are obtained from the per-
mutations by grouping together    duplicates   ; for example, ab and ba are not

48

sample space and id203

chap. 1

viewed as distinct, and are both associated with the combination ab. this rea-
soning can be generalized: each combination is associated with k!    duplicate   
k-permutations, so the number n!/(n     k)! of k-permutations is equal to the
number of combinations times k!. hence, the number of possible combinations,
is equal to

n!

k! (n     k)! .

(cid:6)

(cid:7)

n
k

let us now relate the above expression to the binomial coe   cient, which
and was de   ned in the preceding section as the number of
was denoted by
n-toss sequences with k heads. we note that specifying an n-toss sequence with
k heads is the same as selecting k elements (those that correspond to heads) out
of the n-element set of tosses, i.e., a combination of k out of n objects. hence,
the binomial coe   cient is also given by the same formula and we have

(cid:15)

(cid:16)

n
k

=

n!

k! (n     k)! .

example 1.30. the number of combinations of two out of the four letters a, b,
c, and d is found by letting n = 4 and k = 2. it is

(cid:15)

(cid:16)

4
2

=

4!
2! 2!

= 6,

consistent with the listing given earlier.

it is worth observing that counting arguments sometimes lead to formulas
that are rather di   cult to derive algebraically. one example is the binomial
formula

(cid:15)

(cid:16)

n(cid:12)

k=0

n
k

pk(1     p)n   k = 1,
(cid:15)
n(cid:12)

(cid:16)

n
k

= 2n,

k=0

discussed in section 1.5. in the special case where p = 1/2, this formula becomes

and admits the following simple interpretation. since
is the number of k-
element subsets of a given n-element subset, the sum over k of
counts the
number of subsets of all possible cardinalities. it is therefore equal to the number
of all subsets of an n-element set, which is 2n.

n
k

n
k

(cid:6)

(cid:7)

(cid:6)

(cid:7)

example 1.31. consider a group of n persons, and clubs that consist of a special
person from the group (the club leader) and a number (possibly zero) of additional

sec. 1.6

counting

49

club members. let us count the number of possible clubs of this type in two di   erent
ways, thereby obtaining an algebraic identity.
there are n choices for club leader. once the leader is chosen, we are left
with a set of n     1 available persons, and we are free to choose any of the 2n   1
subsets. thus the number of possible clubs is n2n   1.

alternatively, for    xed k, we can form a k-person club by    rst selecting k out
of the n available persons [there are
choices]. we can then select one of the
members to be the leader (there are k choices). by adding over all possible club
sizes k, we obtain the number of possible clubs as
, thereby showing the
identity

n
k=1 k

(cid:21)

n
k

n
k

(cid:6)

(cid:7)

(cid:7)

(cid:6)
(cid:16)

(cid:15)

n(cid:12)

k

n
k

= n2n   1.

partitions

k=1

recall that a combination is a choice of k elements out of an n-element set
without regard to order. thus, a combination can be viewed as a partition of
the set in two: one part contains k elements and the other contains the remaining
n     k. we now generalize by considering partitions into more than two subsets.
we are given an n-element set and nonnegative integers n1, n2, . . . , nr,
whose sum is equal to n. we consider partitions of the set into r disjoint subsets,
with the ith subset containing exactly ni elements. let us count in how many
ways this can be done.
ways of forming the
   rst subset. having formed the    rst subset, we are left with n     n1 elements.
(cid:6)
we need to choose n2 of them in order to form the second subset, and we have
n   n1
choices, etc. using the counting principle for this r-stage process, the
n2
total number of choices is
n     n1
n2

we form the subsets one at a time. we have

n     n1                nr   1

n     n1     n2

(cid:16)(cid:15)

(cid:16)(cid:15)

(cid:15)

(cid:16)

(cid:15)

(cid:16)

n
n1

      

(cid:7)

(cid:6)

(cid:7)

n
n1

n3

nr

,

which is equal to

n!

n1! (n     n1)!

  

(n     n1)!

n2! (n     n1     n2)!

      

(n     n1                nr   1)!

(n     n1                nr   1     nr)! nr! .

we note that several terms cancel and we are left with

this is called the multinomial coe   cient and is usually denoted by

n!

n1! n2!       nr! .
(cid:16)

(cid:15)

n

n1, n2, . . . , nr

.

50

sample space and id203

chap. 1

example 1.32. anagrams. how many di   erent words (letter sequences) can be
obtained by rearranging the letters in the word tattoo? there are six positions
to be    lled by the available letters. each rearrangement corresponds to a partition
of the set of the six positions into a group of size 3 (the positions that get the letter
t), a group of size 1 (the position that gets the letter a), and a group of size 2 (the
positions that get the letter o). thus, the desired number is

6!

1! 2! 3!

=

1    2    3    4    5    6
1    1    2    1    2    3

= 60.

it is instructive to derive this answer using an alternative argument. (this
argument can also be used to rederive the multinomial coe   cient formula; see
the end-of-chapter problems.) let us write tattoo in the form t1at2t3o1o2
pretending for a moment that we are dealing with 6 distinguishable objects. these
6 objects can be rearranged in 6! di   erent ways. however, any of the 3! possible
permutations of t1, t2, and t3, as well as any of the 2! possible permutations of
o1 and o2, lead to the same word. thus, when the subscripts are removed, there
are only 6!/(3! 2!) di   erent words.

example 1.33. a class consisting of 4 graduate and 12 undergraduate students
is randomly divided into four groups of 4. what is the id203 that each group
includes a graduate student? this is the same as example 1.11 in section 1.3, but
we will now obtain the answer using a counting argument.

we    rst determine the nature of the sample space. a typical outcome is a
particular way of partitioning the 16 students into four groups of 4. we take the
term    randomly    to mean that every possible partition is equally likely, so that the
id203 question can be reduced to one of counting.

according to our earlier discussion, there are

(cid:15)

(cid:16)

16

4, 4, 4, 4

=

16!

4! 4! 4! 4!

di   erent partitions, and this is the size of the sample space.

let us now focus on the event that each group contains a graduate student.

generating an outcome with this property can be accomplished in two stages:

(a) take the four graduate students and distribute them to the four groups; there
are four choices for the group of the    rst graduate student, three choices for
the second, two for the third. thus, there is a total of 4! choices for this stage.

(b) take the remaining 12 undergraduate students and distribute them to the

four groups (3 students in each). this can be done in

(cid:15)

(cid:16)

12

3, 3, 3, 3

=

12!

3! 3! 3! 3!

di   erent ways.

by the counting principle, the event of interest can occur in

4! 12!

3! 3! 3! 3!

sec. 1.7

summary and discussion

51

di   erent ways. the id203 of this event is

4! 12!

3! 3! 3! 3!

16!

4! 4! 4! 4!

.

after some cancellations, we    nd that this is equal to

12    8    4
15    14    13

,

consistent with the answer obtained in example 1.11.

here is a summary of all the counting results we have developed.

summary of counting results

    permutations of n objects: n!.
(cid:16)
(cid:15)
    k-permutations of n objects: n!/(n     k)!.
    combinations of k out of n objects:
n
k
(cid:16)
    partitions of n objects into r groups, with the ith group having ni
objects:

k! (n     k)! .

(cid:15)

n!

=

n

n1, n2, . . . , nr

n!

=

n1! n2!       nr! .

1.7 summary and discussion

a id203 problem can usually be broken down into a few basic steps:

(a) the description of the sample space, that is, the set of possible outcomes

of a given experiment.

(b) the (possibly indirect) speci   cation of the id203 law (the id203

of each event).

(c) the calculation of probabilities and conditional probabilities of various

events of interest.

the probabilities of events must satisfy the nonnegativity, additivity, and nor-
malization axioms. in the important special case where the set of possible out-
comes is    nite, one can just specify the id203 of each outcome and obtain
the id203 of any event by adding the probabilities of the elements of the
event.

52

sample space and id203

chap. 1

given a id203 law, we are often interested in conditional probabilities,
which allow us to reason based on partial information about the outcome of
the experiment. we can view conditional probabilities as id203 laws of a
special type, under which only outcomes contained in the conditioning event can
have positive id155. conditional probabilities can be derived
from the (unconditional) id203 law using the de   nition p(a| b) = p(a    
b)/p(b). however, the reverse process is often convenient, that is,    rst specify
some conditional probabilities that are natural for the real situation that we wish
to model, and then use them to derive the (unconditional) id203 law.

we have illustrated through examples three methods for calculating prob-

abilities:

(a) the counting method. this method applies to the case where the num-
ber of possible outcomes is    nite, and all outcomes are equally likely. to
calculate the id203 of an event, we count the number of elements of
the event and divide by the number of elements of the sample space.

(b) the sequential method. this method applies when the experiment has a
sequential character, and suitable conditional probabilities are speci   ed or
calculated along the branches of the corresponding tree (perhaps using the
counting method). the probabilities of various events are then obtained
by multiplying conditional probabilities along the corresponding paths of
the tree, using the multiplication rule.
(c) the divide-and-conquer method. here, the probabilities p(b) of vari-
ous events b are obtained from conditional probabilities p(b | ai), where
the ai are suitable events that form a partition of the sample space and
have known probabilities p(ai). the probabilities p(b) are then obtained
by using the total id203 theorem.
finally, we have focused on a few side topics that reinforce our main themes.
we have discussed the use of bayes    rule in id136, which is an important
application context. we have also discussed some basic principles of counting
and combinatorics, which are helpful in applying the counting method.

problems

53

p r o b l e m s

section 1.1. sets

problem 1. consider rolling a six-sided die. let a be the set of outcomes where the
roll is an even number. let b be the set of outcomes where the roll is greater than 3.
calculate and compare the sets on both sides of de morgan   s laws
= ac     bc.

(a     b)c = ac     bc,

a     b

(cid:6)

(cid:7)

c

problem 2. let a and b be two sets.

(a) show that

ac = (ac     b)     (ac     bc),

bc = (a     bc)     (ac     bc).

(b) show that

(a     b)c = (ac     b)     (ac     bc)     (a     bc).

(c) consider rolling a fair six-sided die. let a be the set of outcomes where the roll
is an odd number. let b be the set of outcomes where the roll is less than 4.
calculate the sets on both sides of the equality in part (b), and verify that the
equality holds.

problem 3.* prove the identity
      
n=1 bn

a    

(cid:6)

(cid:7)

=       

n=1(a     bn).

solution.

if x belongs to the set on the left, there are two possibilities. either x     a,
in which case x belongs to all of the sets a     bn, and therefore belongs to the set on
the right. alternatively, x belongs to all of the sets bn in which case, it belongs to all
of the sets a     bn, and therefore again belongs to the set on the right.
conversely, if x belongs to the set on the right, then it belongs to a     bn for all

n. if x belongs to a, then it belongs to the set on the left. otherwise, x must belong
to every set bn and again belongs to the set on the left.
problem 4.* cantor   s diagonalization argument. show that the unit interval
[0, 1] is uncountable, i.e., its elements cannot be arranged in a sequence.

solution. any number x in [0, 1] can be represented in terms of its decimal expansion,
e.g., 1/3 = 0.3333      . note that most numbers have a unique decimal expansion,
but there are a few exceptions. for example, 1/2 can be represented as 0.5000       or
as 0.49999      . it can be shown that this is the only kind of exception, i.e., decimal
expansions that end with an in   nite string of zeroes or an in   nite string of nines.

54

sample space and id203

chap. 1

suppose, to obtain a contradiction, that the elements of [0, 1] can be arranged
in a sequence x1, x2, x3, . . ., so that every element of [0, 1] appears in the sequence.
consider the decimal expansion of xn:

xn = 0.a1

na2

na3
n

       ,

n belongs to {0, 1, . . . , 9}. consider now a number y constructed as

where each digit ai
follows. the nth digit of y can be 1 or 2, and is chosen so that it is di   erent from the
nth digit of xn. note that y has a unique decimal expansion since it does not end with
an in   nite sequence of zeroes or nines. the number y di   ers from each xn, since it has
a di   erent nth digit. therefore, the sequence x1, x2, . . . does not exhaust the elements
of [0, 1], contrary to what was assumed. the contradiction establishes that the set [0, 1]
is uncountable.

section 1.2. probabilistic models

problem 5. out of the students in a class, 60% are geniuses, 70% love chocolate,
and 40% fall into both categories. determine the id203 that a randomly selected
student is neither a genius nor a chocolate lover.

problem 6. a six-sided die is loaded in a way that each even face is twice as likely
as each odd face. all even faces are equally likely, as are all odd faces. construct a
probabilistic model for a single roll of this die and    nd the id203 that the outcome
is less than 4.

problem 7. a four-sided die is rolled repeatedly, until the    rst time (if ever) that an
even number is obtained. what is the sample space for this experiment?

problem 8. you enter a special kind of chess tournament, in which you play one game
with each of three opponents, but you get to choose the order in which you play your
opponents, knowing the id203 of a win against each. you win the tournament if
you win two games in a row, and you want to maximize the id203 of winning.
show that it is optimal to play the weakest opponent second, and that the order of
playing the other two opponents does not matter.

problem 9. a partition of the sample space    is a collection of disjoint events

s1, . . . , sn such that    =    n

i=1si.

(a) show that for any event a, we have

n(cid:12)

p(a) =

p(a     si).
(cid:6)
p(a) = p(a     b) + p(a     c) + p

i=1

(b) use part (a) to show that for any events a, b, and c, we have

a     bc     c c)     p(a     b     c).

problem 10. show the formula

(cid:6)

(cid:7)
(a     bc)     (ac     b)

p

= p(a) + p(b)     2p(a     b),

problems

55

which gives the id203 that exactly one of the events a and b will occur. [compare
with the formula p(a     b) = p(a) + p(b)     p(a     b), which gives the id203
that at least one of the events a and b will occur.]

problem 11.* bonferroni   s inequality.

(a) prove that for any two events a and b, we have

p(a     b)     p(a) + p(b)     1.

(b) generalize to the case of n events a1, a2, . . . , an, by showing that

p(a1     a2                an)     p(a1) + p(a2) +        + p(an)     (n     1).

solution. we have p(a     b) = p(a) + p(b)     p(a     b) and p(a     b)     1, which
implies part (a). for part (b), we use de morgan   s law to obtain

(cid:6)

(cid:7)

1     p(a1                an) = p
= p(ac
(cid:6)
(cid:6)
1
    p(ac
=
= n     p(a1)                p(an).

(a1                an)c
               ac
(cid:7)
n)
1) +        + p(ac
n)
1     p(a1)
+        +

(cid:7)
1     p(an)

problem 12.* the inclusion-exclusion formula. show the following generaliza-
tions of the formula

p(a     b) = p(a) + p(b)     p(a     b).

(a) let a, b, and c be events. then,

i   s1

k=1ak) =

(cid:12)

(cid:12)

p(ai)    
(cid:12)

p(a   b   c) = p(a)+p(b)+p(c)   p(a   b)   p(b   c)   p(a   c)+p(a   b   c).
(b) let a1, a2, . . . , an be events. let s1 = {i| 1     i     n}, s2 = {(i1, i2)| 1     i1 <
i2     n}, and more generally, let sm be the set of all m-tuples (i1, . . . , im) of
indices that satisfy 1     i1 < i2 <        < im     n. then,
    ai2 )
p (   n
    ai3 )            + (   1)n   1p (   n

p(ai1
    ai2
(cid:6)
solution.
(a     b)     c = (a     c)     (b     c). we have
(cid:6)
p(a     b     c) = p(a     b) + p(c)     p
= p(a     b) + p(c)     p
= p(a     b) + p(c)     p(a     c)     p(b     c) + p(a     b     c)
= p(a) + p(b)     p(a     b) + p(c)     p(a     c)     p(b     c)

k=1ak) .
(a) we use the formulas p(x     y ) = p(x) + p(y )     p(x     y ) and

(cid:7)
(a     b)     c
(a     c)     (b     c)

(i1,i2,i3)   s3

(i1,i2)   s2

p(ai1

(cid:7)

+

= p(a) + p(b) + p(c)     p(a     b)     p(b     c)     p(a     c)

+ p(a     b     c)

+ p(a     b     c).

56

sample space and id203

chap. 1

(b) use induction and verify the main induction step by emulating the derivation of
part (a). for a di   erent approach, see the problems at the end of chapter 2.
problem 13.* continuity property of probabilities.

(a) let a1, a2, . . . be an in   nite sequence of events, which is    monotonically increas-
ing,    meaning that an     an+1 for every n. let a =       
n=1an. show that
p(a) = limn       p(an). hint: express the event a as a union of countably
many disjoint sets.
(b) suppose now that the events are    monotonically decreasing,    i.e., an+1     an
n=1an. show that p(a) = limn       p(an). hint: apply

for every n. let a =       
the result of part (a) to the complements of the events.

(c) consider a probabilistic model whose sample space is the real line. show that

(cid:6)

(cid:7)
[0,   )

(cid:6)

(cid:7)

(cid:6)

(cid:7)
[n,   )

= 0.

solution.
disjoint, and we have    n
to obtain

,

p

and

[0, n]

= lim

n       p

lim
n       p
(a) let b1 = a1 and, for n     2, bn = an     ac
   (cid:12)

k=1bk = an, and       

n(cid:12)

n   1. the events bn are
k=1bk = a. we apply the additivity axiom

p(a) =

p(bk) = lim
n      

k=1

k=1

p(bk) = lim

n       p(   n

k=1bk) = lim

n       p(an).

(b) let cn = ac
cn are increasing. furthermore, c = ac = (      
the result from part (a) for the sequence cn, we obtain

n and c = ac. since an+1     an, we obtain cn     cn+1, and the events
n=1cn. using

n=1ac

n=1an)c =       
(cid:6)

n =       
(cid:7)
1     p(an)

,

n       p(cn) = lim
n      

1     p(a) = p(ac) = p(c) = lim

from which we conclude that p(a) = limn       p(an).
(c) for the    rst equality, use the result from part (a) with an = [0, n] and a = [0,   ).
for the second, use the result from part (b) with an = [n,   ) and a =       
n=1an =   .

section 1.3. id155

problem 14. we roll two fair 6-sided dice. each one of the 36 possible outcomes is
assumed to be equally likely.

(a) find the id203 that doubles are rolled.

(b) given that the roll results in a sum of 4 or less,    nd the id155

that doubles are rolled.

(c) find the id203 that at least one die roll is a 6.

(d) given that the two dice land on di   erent numbers,    nd the id155

that at least one die roll is a 6.

problem 15. a coin is tossed twice. alice claims that the event of two heads is at
least as likely if we know that the    rst toss is a head than if we know that at least one

problems

57

of the tosses is a head. is she right? does it make a di   erence if the coin is fair or
unfair? how can we generalize alice   s reasoning?

problem 16. we are given three coins: one has heads in both faces, the second has
tails in both faces, and the third has a head in one face and a tail in the other. we
choose a coin at random, toss it, and the result is heads. what is the id203 that
the opposite face is tails?

problem 17. a batch of one hundred items is inspected by testing four randomly
selected items.
if one of the four is defective, the batch is rejected. what is the
id203 that the batch is accepted if it contains    ve defectives?
problem 18. let a and b be events. show that p(a     b | b) = p(a| b), assuming
that p(b) > 0.

section 1.4. total id203 theorem and bayes    rule

problem 19. alice searches for her term paper in her    ling cabinet, which has several
drawers. she knows that she left her term paper in drawer j with id203 pj > 0.
the drawers are so messy that even if she correctly guesses that the term paper is in
drawer i, the id203 that she    nds it is only di. alice searches in a particular
drawer, say drawer i, but the search is unsuccessful. conditioned on this event, show
that the id203 that her paper is in drawer j, is given by

pj

1     pidi

,

if j (cid:4)= i,

pi(1     di)
1     pidi

,

if j = i.

problem 20. how an inferior player with a superior strategy can gain an
advantage. boris is about to play a two-game chess match with an opponent, and
wants to    nd the strategy that maximizes his winning chances. each game ends with
either a win by one of the players, or a draw. if the score is tied at the end of the two
games, the match goes into sudden-death mode, and the players continue to play until
the    rst time one of them wins a game (and the match). boris has two playing styles,
timid and bold, and he can choose one of the two at will in each game, no matter what
style he chose in previous games. with timid play, he draws with id203 pd > 0,
and he loses with id203 1     pd. with bold play, he wins with id203 pw, and
he loses with id203 1     pw. boris will always play bold during sudden death, but

may switch style between games 1 and 2.

(a) find the id203 that boris wins the match for each of the following strategies:

(i) play bold in both games 1 and 2.
(ii) play timid in both games 1 and 2.
(iii) play timid whenever he is ahead in the score, and play bold otherwise.

(b) assume that pw < 1/2, so boris is the worse player, regardless of the playing
style he adopts. show that with the strategy in (iii) above, and depending on
the values of pw and pd, boris may have a better than a 50-50 chance to win the
match. how do you explain this advantage?

problem 21. two players take turns removing a ball from a jar that initially contains
m white and n black balls. the    rst player to remove a white ball wins. develop a

58

sample space and id203

chap. 1

recursive formula that allows the convenient computation of the id203 that the
starting player wins.

problem 22. each of k jars contains m white and n black balls. a ball is randomly
chosen from jar 1 and transferred to jar 2, then a ball is randomly chosen from jar 2
and transferred to jar 3, etc. finally, a ball is randomly chosen from jar k. show that
the id203 that the last ball is white is the same as the id203 that the    rst
ball is white, i.e., it is m/(m + n).

problem 23. we have two jars, each initially containing an equal number of balls.
we perform four successive ball exchanges. in each exchange, we pick simultaneously
and at random a ball from each jar and move it to the other jar. what is the id203
that at the end of the four exchanges all the balls will be in the jar where they started?

problem 24. the prisoner   s dilemma. the release of two out of three prisoners
has been announced, but their identity is kept secret. one of the prisoners considers
asking a friendly guard to tell him who is the prisoner other than himself that will be
released, but hesitates based on the following rationale: at the prisoner   s present state
of knowledge, the id203 of being released is 2/3, but after he knows the answer,
the id203 of being released will become 1/2, since there will be two prisoners
(including himself) whose fate is unknown and exactly one of the two will be released.
what is wrong with this line of reasoning?

problem 25. a two-envelopes puzzle. you are handed two envelopes, and you
know that each contains a positive integer dollar amount and that the two amounts are
di   erent. the values of these two amounts are modeled as constants that are unknown.
without knowing what the amounts are, you select at random one of the two envelopes,
and after looking at the amount inside, you may switch envelopes if you wish. a friend
claims that the following strategy will increase above 1/2 your id203 of ending
up with the envelope with the larger amount: toss a coin repeatedly, let x be equal to
1/2 plus the number of tosses required to obtain heads for the    rst time, and switch
if the amount in the envelope you selected is less than the value of x. is your friend
correct?

problem 26. the paradox of induction. consider a statement whose truth is
unknown. if we see many examples that are compatible with it, we are tempted to
view the statement as more probable. such reasoning is often referred to as induc-
tive id136 (in a philosophical, rather than mathematical sense). consider now the
statement that    all cows are white.    an equivalent statement is that    everything that
is not white is not a cow.    we then observe several black crows. our observations are
clearly compatible with the statement, but do they make the hypothesis    all cows are
white    more likely?

to analyze such a situation, we consider a probabilistic model. let us assume
that there are two possible states of the world, which we model as complementary
events:

a : all cows are white,
ac : 50% of all cows are white.

let p be the prior id203 p(a) that all cows are white. we make an observation
of a cow or a crow, with id203 q and 1     q, respectively, independent of whether

problems

59

event a occurs or not. assume that 0 < p < 1, 0 < q < 1, and that all crows are black.
(a) given the event b = {a black crow was observed}, what is p(a| b)?
(b) given the event c = {a white cow was observed}, what is p(a| c)?

problem 27. alice and bob have 2n + 1 coins, each coin with id203 of heads
equal to 1/2. bob tosses n+1 coins, while alice tosses the remaining n coins. assuming
independent coin tosses, show that the id203 that after all coins have been tossed,
bob will have gotten more heads than alice is 1/2.

problem 28.* conditional version of the total id203 theorem. let
c1, . . . , cn be disjoint events that form a partition of the state space. let also a and
b be events such that p(b     ci) > 0 for all i. show that

solution. we have

p(a| b) =

n(cid:12)

i=1

p(a     b) =
(cid:7)

(cid:6)

p(ci | b)p(a| b     ci).
n(cid:12)
(cid:7)

(cid:6)

(a     b)     ci

,

p

i=1

and by using the multiplication rule,

(a     b)     ci

= p(b)p(ci | b)p(a| b     ci).

p(

combining these two equations, dividing by p(b), and using the formula p(a| b) =
p(a     b)/p(b), we obtain the desired result.
problem 29.* let a and b be events with p(a) > 0 and p(b) > 0. we say that
an event b suggests an event a if p(a| b) > p(a), and does not suggest event a if
p(a| b) < p(a).
(a) show that b suggests a if and only if a suggests b.

(b) assume that p(bc) > 0. show that b suggests a if and only if bc does not

suggest a.

(c) we know that a treasure is located in one of two places, with probabilities    and
1      , respectively, where 0 <    < 1. we search the    rst place and if the treasure
is there, we    nd it with id203 p > 0. show that the event of not    nding the
treasure in the    rst place suggests that the treasure is in the second place.

(a) we have p(a| b) = p(a     b)/p(b), so b suggests a if and only if

solution.
p(a     b) > p(a)p(b), which is equivalent to a suggesting b, by symmetry.
(b) since p(b) + p(bc) = 1, we have

p(b)p(a) + p(bc)p(a) = p(a) = p(b)p(a| b) + p(bc)p(a| bc),

which implies that

(cid:6)

(cid:7)
p(a)     p(a| bc)

(cid:6)

= p(b)

(cid:7)
p(a| b)     p(a)

.

p(bc)

60
chap. 1
thus, p(a| b) > p(a) (b suggests a) if and only if p(a) > p(a| bc) (bc does not
suggest a).

sample space and id203

(c) let a and b be the events

a = {the treasure is in the second place},
b = {we don   t    nd the treasure in the    rst place}.

using the total id203 theorem, we have

p(b) = p(ac)p(b | ac) + p(a)p(b | a) =   (1     p) + (1       ),

so

p(a| b) =

p(a     b)
p(b)

=

1       

  (1     p) + (1       )

1       
1       p

=

> 1        = p(a).

it follows that event b suggests event a.

section 1.5. independence

problem 30. a hunter has two hunting dogs. one day, on the trail of some animal,
the hunter comes to a place where the road diverges into two paths. he knows that
each dog, independent of the other, will choose the correct path with id203 p.
the hunter decides to let each dog choose a path, and if they agree, take that one, and
if they disagree, to randomly pick a path. is his strategy better than just letting one
of the two dogs decide on a path?

problem 31. communication through a noisy channel. a source transmits a
message (a string of symbols) through a noisy communication channel. each symbol is
0 or 1 with id203 p and 1     p, respectively, and is received incorrectly with prob-
ability  0 and  1, respectively (see fig. 1.18). errors in di   erent symbol transmissions
are independent.

 0

 1

  
0
  
1

1       
0

1       
1

 0

 1

figure 1.18: error probabilities in a binary communication channel.

(a) what is the id203 that the kth symbol is received correctly?

(b) what is the id203 that the string of symbols 1011 is received correctly?

(c) in an e   ort to improve reliability, each symbol is transmitted three times and
in other words, a 0 (or 1) is

the received string is decoded by majority rule.

problems

61

transmitted as 000 (or 111, respectively), and it is decoded at the receiver as a 0
(or 1) if and only if the received three-symbol string contains at least two 0s (or
1s, respectively). what is the id203 that a 0 is correctly decoded?

(d) for what values of  0 is there an improvement in the id203 of correct de-

coding of a 0 when the scheme of part (c) is used?

(e) suppose that the scheme of part (c) is used. what is the id203 that a

symbol was 0 given that the received string is 101?

problem 32. the king   s sibling. the king has only one sibling. what is the proba-
bility that the sibling is male? assume that every birth results in a boy with id203
1/2, independent of other births. be careful to state any additional assumptions you
have to make in order to arrive at an answer.

problem 33. using a biased coin to make an unbiased decision. alice and bob
want to choose between the opera and the movies by tossing a fair coin. unfortunately,
the only available coin is biased (though the bias is not known exactly). how can they
use the biased coin to make a decision so that either option (opera or the movies) is
equally likely to be chosen?

problem 34. an electrical system consists of identical components, each of which
is operational with id203 p, independent of other components. the components
are connected in three subsystems, as shown in fig. 1.19. the system is operational
if there is a path that starts at point a, ends at point b, and consists of operational
components. what is the id203 of this happening?

1

a

2

3

b

figure 1.19: a system of identical components that consists of the three sub-
systems 1, 2, and 3. the system is operational if there is a path that starts at
point a, ends at point b, and consists of operational components.

problem 35. reliability of a k-out-of-n system. a system consists of n identical
components, each of which is operational with id203 p, independent of other
components. the system is operational if at least k out of the n components are
operational. what is the id203 that the system is operational?

problem 36. a power utility can supply electricity to a city from n di   erent power
plants. power plant i fails with id203 pi, independent of the others.

62

sample space and id203

chap. 1

(a) suppose that any one plant can produce enough electricity to supply the entire

city. what is the id203 that the city will experience a black-out?

(b) suppose that two power plants are necessary to keep the city from a black-out.

find the id203 that the city will experience a black-out.

problem 37. a cellular phone system services a population of n1    voice users    (those
who occasionally need a voice connection) and n2    data users    (those who occasionally
need a data connection). we estimate that at a given time, each user will need to be
connected to the system with id203 p1 (for voice users) or p2 (for data users),
independent of other users. the data rate for a voice user is r1 bits/sec and for a data
user is r2 bits/sec. the cellular system has a total capacity of c bits/sec. what is the
id203 that more users want to use the system than the system can accommodate?

problem 38. the problem of points. telis and wendy play a round of golf (18
holes) for a $10 stake, and their probabilities of winning on any one hole are p and
1     p, respectively, independent of their results in other holes. at the end of 10 holes,
with the score 4 to 6 in favor of wendy, telis receives an urgent call and has to report
back to work. they decide to split the stake in proportion to their probabilities of
winning had they completed the round, as follows. if pt and pw are the conditional
probabilities that telis and wendy, respectively, are ahead in the score after 18 holes
given the 4-6 score after 10 holes, then telis should get a fraction pt /(pt + pw ) of the
stake, and wendy should get the remaining pw /(pt + pw ). how much money should
telis get? note: this is an example of the, so-called, problem of points, which played
an important historical role in the development of id203 theory. the problem
was posed by chevalier de m  er  e in the 17th century to pascal, who introduced the
idea that the stake of an interrupted game should be divided in proportion to the
players    conditional probabilities of winning given the state of the game at the time of
interruption. pascal worked out some special cases and through a correspondence with
fermat, stimulated much thinking and several id203-related investigations.

problem 39. a particular class has had a history of low attendance. the annoyed
professor decides that she will not lecture unless at least k of the n students enrolled
in the class are present. each student will independently show up with id203
pg if the weather is good, and with id203 pb if the weather is bad. given the
id203 of bad weather on a given day, obtain an expression for the id203 that
the professor will teach her class on that day.

problem 40. consider a coin that comes up heads with id203 p and tails with

id203 1    p. let qn be the id203 that after n independent tosses, there have
been an even number of heads. derive a recursion that relates qn to qn   1, and solve
this recursion to establish the formula

(cid:6)

(cid:7)

1 + (1     2p)n

/2.

qn =

problem 41. consider a game show with an in   nite pool of contestants, where
at each round i, contestant i obtains a number by spinning a continuously calibrated
wheel. the contestant with the smallest number thus far survives. successive wheel
spins are independent and we assume that there are no ties. let n be the round at
which contestant 1 is eliminated. for any positive integer n,    nd p(n = n).

problems

63

problem 42.* gambler   s ruin. a gambler makes a sequence of independent bets.
in each bet, he wins $1 with id203 p, and loses $1 with id203 1    p. initially,
the gambler has $k, and plays until he either accumulates $n or has no money left.
what is the id203 that the gambler will end up with $n?

solution. let us denote by a the event that he ends up with $n, and by f the event
that he wins the    rst bet. denote also by wk the id203 of event a, if he starts
with $k. we apply the total id203 theorem to obtain

wk = p(a| f )p(f ) + p(a| f c)p(f c) = pp(a| f ) + qp(a| f c),

0 < k < n,

where q = 1    p. by the independence of past and future bets, having won the    rst bet
is the same as if he were just starting now but with $(k+1), so that p(a| f ) = wk+1
and similarly p(a| f c) = wk   1. thus, we have wk = pwk+1 + qwk   1, which can be

written as

wk+1     wk = r(wk     wk   1),

0 < k < n,

where r = q/p. we will solve for wk in terms of p and q using iteration, and the
boundary values w0 = 0 and wn = 1.

we have wk+1     wk = rk(w1     w0), and since w0 = 0,
wk+1 = wk + rkw1 = wk   1 + rk   1w1 + rkw1 = w1 + rw1 +        + rkw1.

the sum in the right-hand side can be calculated separately for the two cases where
r = 1 (or p = q) and r (cid:4)= 1 (or p (cid:4)= q). we have

(cid:13)

wk =

w1,

1     rk
1     r
kw1,

1     rn ,
1
n

         
       1     r
         
       1     rk

1     rn ,
k
n

,

,

if p (cid:4)= q,
if p = q.

if p = q,

if p (cid:4)= q,

if p = q.

since wn = 1, we can solve for w1 and therefore for wk:
if p (cid:4)= q,

so that

w1 =

wk =

problem 43.* let a and b be independent events. use the de   nition of indepen-
dence to prove the following:

(a) the events a and bc are independent.

(b) the events ac and bc are independent.
solution. (a) the event a is the union of the disjoint events a    bc and a    b. using
the additivity axiom and the independence of a and b, we obtain

p(a) = p(a     b) + p(a     bc) = p(a)p(b) + p(a     bc).

64

it follows that

(cid:6)
p(a     bc) = p(a)

so a and bc are independent.

(cid:7)
1     p(b)

= p(a)p(bc),

sample space and id203

chap. 1

(b) apply the result of part (a) twice:    rst on a and b, then on bc and a.
problem 44.* let a, b, and c be independent events, with p(c) > 0. prove that
a and b are conditionally independent given c.

solution. we have

p(a     b | c) =

p(a     b     c)

p(c)

=

p(a)p(b)p(c)

p(c)

= p(a)p(b)
= p(a| c)p(b | c),

so a and b are conditionally independent given c. in the preceding calculation, the
   rst equality uses the de   nition of conditional probabilities; the second uses the as-
sumed independence; the fourth uses the independence of a from c, and of b from c.
problem 45.* assume that the events a1, a2, a3, a4 are independent and that
p(a3     a4) > 0. show that

p(a1     a2 | a3     a4) = p(a1     a2).

solution. we have

p(a1 | a3     a4) =

p(a1     a3     a4)

p(a3     a4)

=

p(a1)p(a3)p(a4)

p(a3)p(a4)

= p(a1).

we similarly obtain p(a2 | a3     a4) = p(a2) and p(a1     a2 | a3     a4) = p(a1     a2),

and    nally,

p(a1     a2 | a3     a4) = p(a1 | a3     a4) + p(a2 | a3     a4)     p(a1     a2 | a3     a4)

= p(a1) + p(a2)     p(a1     a2)
= p(a1     a2).

problem 46.* laplace   s rule of succession. consider m + 1 boxes with the kth
box containing k red balls and m     k white balls, where k ranges from 0 to m. we
choose a box at random (all boxes are equally likely) and then choose a ball at random
from that box, n successive times (the ball drawn is replaced each time, and a new ball
is selected independently). suppose a red ball was drawn each of the n times. what
is the id203 that if we draw a ball one more time it will be red? estimate this
id203 for large m.

solution. we want to    nd the id155 p(e | rn), where e is the event
of a red ball drawn at time n + 1, and rn is the event of a red ball drawn each of the n
preceding times. intuitively, the consistent draw of a red ball indicates that a box with

problems

65

a high percentage of red balls was chosen, so we expect that p(e | rn) is closer to 1

than to 0. in fact, laplace used this example to calculate the id203 that the sun
will rise tomorrow given that it has risen for the preceding 5,000 years. (it is not clear
how serious laplace was about this calculation, but the story is part of the folklore of
id203 theory.)

we have

p(e | rn) =

and by using the total id203 theorem, we obtain

,

p(e     rn)
p(rn)
(cid:27)n
(cid:26)
(cid:27)n+1
(cid:26)

m(cid:12)

k
m

=

k=0

(cid:28)

m(cid:12)

(cid:26)

k=0

(cid:27)n

,

k
m

1

m + 1

.

p(rn) =

k=0

p(kth box chosen)

p(e     rn) = p(rn+1) =

1

m + 1

k
m

m(cid:12)

(cid:27)n    

m(cid:12)

(cid:26)

k=0

k
m

for large m, we can view p(rn) as a piecewise constant approximation to an integral:

1

(m + 1)mn

0

m

xndx =

1

(m + 1)mn

   mn+1
n + 1

    1

n + 1

.

p(rn) =

1

m + 1

similarly,

so that

p(e     rn) = p(rn+1)     1

n + 2

,

p(e | rn)     n + 1

n + 2

.

thus, for large m, drawing a red ball one more time is almost certain when n is large.
problem 47.* binomial coe   cient formula and the pascal triangle.

(a) use the de   nition of

as the number of distinct n-toss sequences with k
heads, to derive the recursion suggested by the so called pascal triangle, given in
fig. 1.20.

(b) use the recursion derived in part (a) and induction, to establish the formula

(cid:6)

(cid:7)

n
k

(cid:15)

(cid:16)

n
k

=

n!

k! (n     k)!

.

(a) note that n-toss sequences that contain k heads (for 0 < k < n) can be

solution.
obtained in two ways:
(1) by starting with an (n    1)-toss sequence that contains k heads and adding a tail

(cid:6)

(cid:7)

at the end. there are

di   erent sequences of this type.

(2) by starting with an (n     1)-toss sequence that contains k     1 heads and adding

n   1
k

a head at the end. there are

di   erent sequences of this type.

(cid:6)

(cid:7)

n   1
k   1

66

sample space and id203

chap. 1

0
( )
0

1
( )
0

1
( )
1

2
( )
0

2
( )
1

2
( )
2

3
( )
0

3
( )
1

3
( )
2

3
( )
3

1

1

1

1

2

1

1

3

3

1

4
( )
0

4
( )
1

4
( )
2

4
( )
3

4
( )
4

1

4

6

4

1

.  .  .  .  .  .  .  .

.  .  .  .  .  .  .  .

(cid:6)

(cid:7)

figure 1.20: sequential calculation method of the binomial coe   cients using the
pascal triangle. each term
in the triangular array on the left is computed
and placed in the triangular array on the right by adding its two neighbors in the
row above it (except for the boundary terms with k = 0 or k = n, which are equal
to 1).

n
k

thus,

(cid:15)

(cid:16)

n
k

=

(cid:15)

(cid:16)
n     1
k     1

      
   

(cid:15)

(cid:16)
n     1
k

+

if k = 1, 2, . . . , n     1,

,

1,

if k = 0, n.

this is the formula corresponding to the pascal triangle calculation, given in fig. 1.20.

(b) we now use the recursion from part (a), to demonstrate the formula

(cid:15)

(cid:16)

(cid:7)
(cid:6)
= 1, so for n = 1 the
by induction on n. indeed, we have from the de   nition
above formula is seen to hold as long as we use the convention 0! = 1. if the formula
holds for each index up to n     1, we have for k = 1, 2, . . . , n     1,

k! (n     k)!

(cid:6)

(cid:7)

n
k

n!

=

=

1
0

1
1

,

(cid:15)

(cid:16)

n
k

=

=

=

=

(cid:15)

(cid:16)
n     1
k     1

(cid:15)

(cid:16)
n     1
+
k
(n     1)!

(k     1)! (n     1     k + 1)!
n     k
  
  
k
n
n

n!

+

k! (n     k)!
n!

k! (n     k)!

,

+

(n     1)!

k! (n     1     k)!
n!

k! (n     k)!

and the induction is complete.
problem 48.* the borel-cantelli lemma. consider an in   nite sequence of trials.
the id203 of success at the ith trial is some positive number pi. let n be the

problems

67

event that there is no success, and let i be the event that there is an in   nite number
of successes.

(cid:21)   
i=1 pi =    . show that

(a) assume that the trials are independent and that

p(n ) = 0 and p(i) = 1.

(b) assume that

(cid:21)   
i=1 pi <    . show that p(i) = 0.

solution. (a) the event n is a subset of the event that there were no successes in the
   rst n trials, so that

p(n )     n(cid:14)

(1     pi).

taking logarithms,

log p(n )     n(cid:12)

i=1

log(1     pi)     n(cid:12)

(   pi).

i=1

i=1

taking the limit as n tends to in   nity, we obtain log p(n ) =       , or p(n ) = 0.

let now ln be the event that there is a    nite number of successes and that the
last success occurs at the nth trial. we use the already established result p(n ) = 0,
and apply it to the sequence of trials after trial n, to obtain p(ln) = 0. the event i c
(   nite number of successes) is the union of the disjoint events ln, n     1, and n , so

   (cid:12)

p(i c) = p(n ) +

p(ln) = 0,

n=1

that

and p(i) = 1.

(b) let si be the event that the ith trial is a success. fix some number n and for every
i > n, let fi be the event that the    rst success after time n occurs at time i. note
that fi     si. finally, let an be the event that there is at least one success after time
n. note that i     an, because an in   nite number of successes implies that there are
successes subsequent to time n. furthermore, the event an is the union of the disjoint
events fi, i > n. therefore,

(cid:4)    (cid:2)

(cid:5)

   (cid:12)

   (cid:12)

p(i)     p(an) = p

fi

=

p(fi)    

p(si) =

i=n+1

i=n+1

i=n+1

we take the limit of both sides as n        . because of the assumption
the right-hand side converges to zero. this implies that p(i) = 0.

section 1.6. counting

   (cid:12)
(cid:21)   
i=1 pi <    ,

pi.

i=n+1

problem 49. de m  er  e   s puzzle. a six-sided die is rolled three times independently.
which is more likely: a sum of 11 or a sum of 12? (this question was posed by the
french nobleman de m  er  e to his friend pascal in the 17th century.)

problem 50. the birthday problem. consider n people who are attending a
party. we assume that every person has an equal id203 of being born on any day

68

sample space and id203

chap. 1

during the year, independent of everyone else, and ignore the additional complication
presented by leap years (i.e., assume that nobody is born on february 29). what is
the id203 that each person has a distinct birthday?

problem 51. an urn contains m red and n white balls.

(a) we draw two balls randomly and simultaneously. describe the sample space and
calculate the id203 that the selected balls are of di   erent color, by using
two approaches: a counting approach based on the discrete uniform law, and a
sequential approach based on the multiplication rule.

(b) we roll a fair 3-sided die whose faces are labeled 1,2,3, and if k comes up, we
remove k balls from the urn at random and put them aside. describe the sample
space and calculate the id203 that all of the balls drawn are red, using a
divide-and-conquer approach and the total id203 theorem.

problem 52. we deal from a well-shu   ed 52-card deck. calculate the id203
that the 13th card is the    rst king to be dealt.

problem 53. ninety students, including joe and jane, are to be split into three
classes of equal size, and this is to be done at random. what is the id203 that
joe and jane end up in the same class?

problem 54. twenty distinct cars park in the same parking lot every day. ten of
these cars are us-made, while the other ten are foreign-made. the parking lot has
exactly twenty spaces, all in a row, so the cars park side by side. however, the drivers
have varying schedules, so the position any car might take on a certain day is random.

(a) in how many di   erent ways can the cars line up?

(b) what is the id203 that on a given day, the cars will park in such a way
that they alternate (no two us-made are adjacent and no two foreign-made are
adjacent)?

problem 55. eight rooks are placed in distinct squares of an 8    8 chessboard, with
all possible placements being equally likely. find the id203 that all the rooks are
safe from one another, i.e., that there is no row or column with more than one rook.

problem 56. an academic department o   ers 8 lower level courses: {l1, l2, . . . , l8}
and 10 higher level courses: {h1, h2, . . . , h10}. a valid curriculum consists of 4 lower

level courses, and 3 higher level courses.

(a) how many di   erent curricula are possible?

(b) suppose that {h1, . . . , h5} have l1 as a prerequisite, and {h6, . . . h10} have l2
and l3 as prerequisites, i.e., any curricula which involve, say, one of {h1, . . . , h5}
must also include l1. how many di   erent curricula are there?

problem 57. how many 6-word sentences can be made using each of the 26 letters
of the alphabet exactly once? a word is de   ned as a nonempty (possibly jibberish)
sequence of letters.

problems

69

problem 58. we draw the top 7 cards from a well-shu   ed standard 52-card deck.
find the id203 that:

(a) the 7 cards include exactly 3 aces.

(b) the 7 cards include exactly 2 kings.

(c) the id203 that the 7 cards include exactly 3 aces, or exactly 2 kings, or

both.

problem 59. a parking lot contains 100 cars, k of which happen to be lemons. we
select m of these cars at random and take them for a test drive. find the id203
that n of the cars tested turn out to be lemons.

problem 60. a well-shu   ed 52-card deck is dealt to 4 players. find the id203
that each of the players gets an ace.

n
k

m
i

(cid:7)

(cid:6)
(cid:7)
(cid:15)

problem 61.* hypergeometric probabilities. an urn contains n balls, out of
which m are red. we select k of the balls at random, without replacement (i.e., selected
balls are not put back into the urn before the next selection). what is the id203
that i of the selected balls are red?

(cid:6)
solution. the sample space consists of the
di   erent ways that we can select k out
(cid:6)
(cid:7)
of the available balls. for the event of interest to occur, we have to select i out of the
ways, and also select k    i out of the n    m balls
(cid:16)(cid:15)
m red balls, which can be done in
n   m
k   i
ways. therefore, the desired id203
that are not red, which can be done in
is
n     m
(cid:15)
(cid:16)
k     i
n
k

for i     0 satisfying i     m, i     k, and k     i     n     m. for all other i, the id203 is
zero.
problem 62.* correcting the number of permutations for indistinguishable
objects. when permuting n objects, some of which are indistinguishable, di   erent
permutations may lead to indistinguishable object sequences, so the number of distin-
guishable object sequences is less than n!. for example, there are six permutations of
the letters a, b, and c:

(cid:16)

m
i

,

abc, acb, bac, bca, cab, cba,

but only three distinguishable sequences that can be formed using the letters a, d,
and d:

add, dad, dda.

(a) suppose that k out of the n objects are indistinguishable. show that the number

of distinguishable object sequences is n!/k!.

(b) suppose that we have r types of indistinguishable objects, and for each i, ki

objects of type i. show that the number of distinguishable object sequences is

n!

k1! k2!       kr!

.

70

sample space and id203

chap. 1

solution.
(a) each one of the n! permutations corresponds to k! duplicates which are
obtained by permuting the k indistinguishable objects. thus, the n! permutations can
be grouped into n!/k! groups of k! indistinguishable permutations that result in the
same object sequence. therefore, the number of distinguishable object sequences is
n!/k!. for example, the three letters a, d, and d give the 3! = 6 permutations

add, add, dad, dda, dad, dda,

obtained by replacing b and c by d in the permutations of a, b, and c given earlier.
however, these 6 permutations can be divided into the n!/k! = 3!/2! = 3 groups

{add, add}, {dad, dad}, {dda, dda},

each having k! = 2! = 2 indistinguishable permutations.

(b) one solution is to extend the argument in (a) above: for each object type i, there are
ki! indistinguishable permutations of the ki objects. hence, each permutation belongs
to a group of k1! k2!       kr! indistinguishable permutations, all of which yield the same

object sequence.

an alternative argument goes as follows. choosing a distinguishable object se-
quence is the same as starting with n slots and for each i, choosing the ki slots to be
occupied by objects of type i. this is the same as partitioning the set {1, . . . , n} into
groups of size k1, . . . , kr, and the number of such partitions is given by the multinomial
coe   cient.

