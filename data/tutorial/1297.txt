   #[1]meta [2]meta [3]meta [4]meta [5]meta [6]meta [7]rss - etoc alert
   for synthesis lectures on id161 [8]rss - cited articles

   morgan & claypool publishers logo
   hello. [9]sign in to personalize your visit. new user? [10]register
   now.
     * [11]home
     * [12]synthesis
          + [13]subject areas
          + [14]recent & forthcoming titles
          + [15]complete collections
          + [16]institutional pricing
          + [17]about
     * [18]colloquium
          + [19]subject areas
          + [20]recent & forthcoming titles
          + [21]complete collections
          + [22]institutional pricing
          + [23]about
     * [24]search
          + [25]simple search
          + [26]advanced search
          + [27]help
     * [28]profile
          + [29]series
          + [30]sign up for e-alerts
          + [31]account info
     * [32]author
     * [33]help
     * [34]about
          + [35]synthesis
          + [36]colloquium
          + [37]morgan & claypool publishers
          + [38]contact
     * [39]bookstore

     quick search: ____________________ within: [this issue_] go

   [singlepixel.gif]

computational methods for integrating vision and language

[40]synthesis lectures on id161

   april 2016, 227 pages,
   ([41]https://doi.org/10.2200/s00705ed1v01y201602cov007)
   kobus barnard   
   university of arizona

   abstract

   "this is clearly the most comprehensive and thoughtful compendium of
   knowledge on language/vision integration out there, and i'm sure it
   will be a valuable resources to many researchers and instructors." -
   sven dickinson, series editor (university of toronto)

   modeling data from visual and linguistic modalities together creates
   opportunities for better understanding of both, and supports many
   useful applications. examples of dual visual-linguistic data includes
   images with keywords, video with narrative, and figures in documents.
   we consider two key task-driven themes: translating from one modality
   to another (e.g., inferring annotations for images) and understanding
   the data using all modalities, where one modality can help disambiguate
   information in another. the multiple modalities can either be
   essentially semantically redundant (e.g., keywords provided by a person
   looking at the image), or largely complementary (e.g., meta data such
   as the camera used). redundancy and complementarity are two endpoints
   of a scale, and we observe that good performance on translation
   requires some redundancy, and that joint id136 is most useful where
   some information is complementary.

   computational methods discussed are broadly organized into ones for
   simple keywords, ones going beyond keywords toward natural language,
   and ones considering sequential aspects of natural language. methods
   for keywords are further organized based on localization of semantics,
   going from words about the scene taken as whole, to words that apply to
   specific parts of the scene, to relationships between parts. methods
   going beyond keywords are organized by the linguistic roles that are
   learned, exploited, or generated. these include proper nouns,
   adjectives, spatial and comparative prepositions, and verbs. more
   recent developments in dealing with sequential structure include
   automated captioning of scenes and video, alignment of video and text,
   and automated answering of questions about scenes depicted in images.

   table of contents: acknowledgments / figure credits / introduction /
   the semantics of images and associated text / sources of data for
   linking visual and linguistic information / extracting and representing
   visual information / text and speech processing / modeling images and
   keywords / beyond simple nouns / sequential structure / bibliography /
   author's biography

                  [42]pdf (6477 kb) [43]pdf plus (3024 kb)


   [44]home  > [45]series home  > abstract
   [cover.jpg]
   [46]prev. lecture | next lecture
   [47]view/print pdf (6477 kb)
   [48]view pdf plus (3024 kb)
   [49]add to favorites
   [50]email to a friend
   [51][xml.gif] toc alert | [52]citation alert [53]what is rss?
   quick links
       [54]purchase print or personal ebook
       alert me when:
   [55]new articles cite this article
       [56]download to citation manager
       related articles found in:
   [57]morgan & claypool
       [58]view most downloaded articles
   quick search
   [morgan & claypool] for
   author:
   [ ] kobus barnard
   keywords:
   [ ]
   vision
   [ ]
   language
   [ ]
   loosely labeled data
   [ ]
   correspondence ambiguity
   [ ]
   auto-annotation
   [ ]
   region labeling
   [ ]
   multimodal translation
   [ ]
   cross-modal disambiguation
   [ ]
   image captioning
   [ ]
   video captioning
   [ ]
   affective visual attributes
   [ ]
   aligning visual and linguistic data
   [ ]
   auto-illustration
   [ ]
   visual id53
   _______________
   search
   [singlepixel.gif]
   [59]home | [60]synthesis | [61]search | [62]profile | [63]access |
   [64]author | [65]help | [66]about
   technology partner - [67]atypon systems, inc.
   [68][crmemberlogo.gif] [69][atyponlogo.gif]

references

   visible links
   1. https://doi.org/10.2200/s00705ed1v01y201602cov007
   2. https://doi.org/10.2200/s00705ed1v01y201602cov007
   3. https://doi.org/10.2200/s00705ed1v01y201602cov007
   4. https://doi.org/10.2200/s00705ed1v01y201602cov007
   5. https://doi.org/10.2200/s00705ed1v01y201602cov007
   6. https://doi.org/10.2200/s00705ed1v01y201602cov007
   7. https://www.morganclaypool.com/action/showfeed?ui=0&mi=658t8x&ai=zr&jc=cov&type=etoc&feed=rss
   8. https://www.morganclaypool.com/action/showfeed?ui=0&mi=658t8x&ai=2g3&doi=10.2200/s00705ed1v01y201602cov007&type=citrack&feed=rss
   9. https://www.morganclaypool.com/action/showlogin?uri=/doi/abs/10.2200/s00705ed1v01y201602cov007
  10. https://www.morganclaypool.com/action/registration
  11. https://www.morganclaypool.com/
  12. https://www.morganclaypool.com/page/synthesis
  13. https://www.morganclaypool.com/page/browselbs.jsp
  14. https://www.morganclaypool.com/page/forthcomingsynthesislectures
  15. https://www.morganclaypool.com/page/coll_one
  16. https://www.morganclaypool.com/page/pricing
  17. https://www.morganclaypool.com/page/aboutsynthesis.jsp
  18. https://www.morganclaypool.com/page/lsindex
  19. https://www.morganclaypool.com/page/browsecbs
  20. https://www.morganclaypool.com/page/forthcomingcolloquium
  21. https://www.morganclaypool.com/page/colloquium_one
  22. https://www.morganclaypool.com/page/mcls_pricing
  23. https://www.morganclaypool.com/page/colloquium
  24. https://www.morganclaypool.com/search/simple
  25. https://www.morganclaypool.com/search/simple
  26. https://www.morganclaypool.com/search/advanced
  27. https://www.morganclaypool.com/help?context=search
  28. https://www.morganclaypool.com/doi/abs/10.2200/s00705ed1v01y201602cov007
  29. https://www.morganclaypool.com/action/showpreferences?menutab=journals&type=favorite&type=subscribed
  30. https://www.morganclaypool.com/action/showpreferences?menutab=alerts
  31. https://www.morganclaypool.com/action/showpreferences?menutab=accountinfo
  32. https://www.morganclaypool.com/page/authors.jsp
  33. https://www.morganclaypool.com/help?context=main
  34. https://www.morganclaypool.com/doi/abs/10.2200/s00705ed1v01y201602cov007
  35. https://www.morganclaypool.com/page/aboutsynthesis.jsp
  36. https://www.morganclaypool.com/page/colloquium
  37. https://www.morganclaypool.com/page/aboutmcp.jsp
  38. https://www.morganclaypool.com/feedback/show
  39. https://www.morganclaypoolpublishers.com/
  40. https://www.morganclaypool.com/toc/cov/6/1
  41. https://doi.org/10.2200/s00705ed1v01y201602cov007
  42. https://www.morganclaypool.com/doi/pdf/10.2200/s00705ed1v01y201602cov007
  43. https://www.morganclaypool.com/doi/pdfplus/10.2200/s00705ed1v01y201602cov007
  44. https://www.morganclaypool.com/
  45. https://www.morganclaypool.com/toc/cov/6/1
  46. https://www.morganclaypool.com/doi/abs/10.2200/s00713ed1v01y201603cov008
  47. https://www.morganclaypool.com/doi/pdf/10.2200/s00705ed1v01y201602cov007
  48. https://www.morganclaypool.com/doi/pdfplus/10.2200/s00705ed1v01y201602cov007
  49. https://www.morganclaypool.com/personalize/addfavoritepublication?doi=10.2200/s00705ed1v01y201602cov007
  50. https://www.morganclaypool.com/action/showmailpage?href=/doi/abs/10.2200/s00705ed1v01y201602cov007&title=computational+methods+for+integrating+vision+and+language&doi=10.2200/s00705ed1v01y201602cov007
  51. https://www.morganclaypool.com/action/showfeed?ui=0&mi=658t8x&ai=zr&jc=cov&type=etoc&feed=rss
  52. https://www.morganclaypool.com/action/showfeed?ui=0&mi=658t8x&ai=2g3&doi=10.2200/s00705ed1v01y201602cov007&type=citrack&feed=rss
  53. https://www.morganclaypool.com/help?context=rss
  54. https://morganclaypoolpublishers.com/
  55. https://www.morganclaypool.com/action/addcitationalert?doi=10.2200/s00705ed1v01y201602cov007
  56. https://www.morganclaypool.com/action/showcitformats?doi=10.2200/s00705ed1v01y201602cov007
  57. https://www.morganclaypool.com/action/dosearch?target=related&doi=10.2200/s00705ed1v01y201602cov007
  58. https://www.morganclaypool.com/action/showmostreadarticles?journalcode=cov
  59. https://www.morganclaypool.com/
  60. https://www.morganclaypool.com/page/synthesis.jsp
  61. https://www.morganclaypool.com/search/advanced
  62. https://www.morganclaypool.com/action/showpreferences
  63. https://www.morganclaypool.com/page/access.jsp
  64. https://www.morganclaypool.com/page/authors.jsp
  65. https://www.morganclaypool.com/help?context=main#_top
  66. https://www.morganclaypool.com/feedback/show
  67. http://www.atypon.com/
  68. http://www.crossref.org/
  69. http://www.atypon.com/

   hidden links:
  71. https://www.morganclaypool.com/doi/pdf/10.1046/9999-9999.99999
