practical neural 
networks for nlp 

(part 1)

chris dyer, yoav goldberg, graham neubig

https://github.com/clab/dynet_tutorial_examples

november 1, 2016

emnlp

neural nets and language

    tension: language and neural nets 

    language is discrete and structured 

    sequences, trees, graphs 

    neural nets represent things with continuous vectors 

    poor    native support    for structure 

    the big challenge is writing code that translates between the 

{discrete-structured, continuous} regimes 

    this tutorial is about one framework that lets you use the power of 

neural nets without abandoning familiar nlp algorithms

outline

    part 1

    computation graphs and their construction 

    neural nets in dynet 

    recurrent neural networks 

    minibatching 

    adding new differentiable functions

outline

    part 2: case studies

    tagging with bidirectional id56s 

    transition-based id33 

    id170 meets deep learning

computation graphs

deep learning   s lingua franca

expression:
y = x>ax + b    x + c
graph:

a node is a {tensor, matrix, vector, scalar} value

x

an edge represents a function argument   
expression:
(and also an data dependency). they are just   
y = x>ax + b    x + c
pointers to nodes.
a node with an incoming edge is a function of 
graph:
that edge   s tail node.
a node knows how to compute its value and the 
value of its derivative w.r.t each argument (edge) 
times a derivative of an arbitrary input       .
@f
@f (u)

f (u) = u>

@f (u)

@u

@f
@f (u)

=    @f

@f (u)   >

x

expression:
y = x>ax + b    x + c
graph:

functions can be nullary, unary,   
binary,     n-ary. often they are unary or binary.

f (u, v) = uv

f (u) = u>

a

x

expression:
y = x>ax + b    x + c
graph:

f (m, v) = mv

f (u, v) = uv

f (u) = u>

a

x

computation graphs are directed and acyclic (in dynet)

expression:
y = x>ax + b    x + c
graph:

f (m, v) = mv

f (x, a) = x>ax

f (u, v) = uv

f (u) = u>

a

x

x

a

@f (x, a)

@x

@f (x, a)

@a

= (a> + a)x

= xx>

expression:
y = x>ax + b    x + c
graph:

f (x1, x2, x3) =xi

xi

f (m, v) = mv

f (u, v) = uv

f (u) = u>

f (u, v) = u    v

a

x

b

c

expression:
y = x>ax + b    x + c
graph:

f (x1, x2, x3) =xi

y

xi

f (m, v) = mv

f (u, v) = uv

f (u) = u>

f (u, v) = u    v

a

x

b

c

variable names are just labelings of nodes.

algorithms

    graph construction
    forward propagation

    loop over nodes in topological order 

    compute the value of the node given its inputs 

    given my inputs, make a prediction (or compute an    error    with respect to a    target 

output   ) 

    backward propagation

    loop over the nodes in reverse topological order starting with a    nal goal node 

    compute derivatives of    nal goal node value with respect to each edge   s tail 

node 

    how does the output change if i make a small change to the inputs?

forward propagation

graph:

f (x1, x2, x3) =xi

xi

f (m, v) = mv

f (u, v) = uv

f (u) = u>

f (u, v) = u    v

a

x

b

c

forward propagation

graph:

f (x1, x2, x3) =xi

xi

f (m, v) = mv

f (u, v) = uv

f (u) = u>

f (u, v) = u    v

a

x

b

c

forward propagation

graph:

f (x1, x2, x3) =xi

xi

f (m, v) = mv

f (u, v) = uv

f (u) = u>

f (u, v) = u    v

a

x

b

c

forward propagation

graph:

f (x1, x2, x3) =xi

xi

f (m, v) = mv

f (u, v) = uv

f (u) = u>
x>

a

f (u, v) = u    v

x

b

c

forward propagation

graph:

f (x1, x2, x3) =xi

xi

f (m, v) = mv

f (u, v) = uv
x>a

f (u) = u>
x>

a

f (u, v) = u    v

x

b

c

forward propagation

graph:

f (x1, x2, x3) =xi

xi

f (m, v) = mv

f (u, v) = uv
x>a

f (u) = u>
x>

f (u, v) = u    v

b    x

a

x

b

c

forward propagation

graph:

f (x1, x2, x3) =xi

xi

f (m, v) = mv
x>ax

f (u, v) = uv
x>a

f (u) = u>
x>

f (u, v) = u    v

b    x

a

x

b

c

forward propagation

graph:

f (x1, x2, x3) =xi
xi
x>ax + b    x + c

f (m, v) = mv
x>ax

f (u, v) = uv
x>a

f (u) = u>
x>

f (u, v) = u    v

b    x

a

x

b

c

the mlp

h = tanh(wx + b)
y = vh + a

f (u, v) = u + v

f (m, v) = mv

a

f (u) = tanh(u) v

h

b

f (u, v) = u + v

f (m, v) = mv

w

x

constructing graphs

two software models

    static declaration

    phase 1: de   ne an architecture   

(maybe with some primitive    ow control like loops and 
conditionals) 

    phase 2: run a bunch of data through it to train the 

model and/or make predictions 

    dynamic declaration

    graph is de   ned implicitly (e.g., using operator 

overloading) as the forward computation is executed 

hierarchical structure

words

sentences

s

vp

vp

np

pp

alice

gave a message

to bob

phrases

documents

this film was completely unbelievable.
the characters were wooden and the plot was absurd.
that being said, i liked it.

static declaration

    pros

    of   ine optimization/scheduling of graphs is powerful 

    limits on operations mean better hardware support 

    cons

    structured data (even simple stuff like sequences), even variable-

sized data, is ugly  

    you effectively learn a new programming language (   the graph 

language   ) and you write programs in that language to process data. 

    examples: torch, theano, tensorflow

dynamic declaration

    pros

    library is less invasive 
    the forward computation is written in your favorite programming 

language with all its features, using your favorite algorithms 

    interleave construction and evaluation of the graph 

    cons

    little time for graph optimization 

    if the graph is static, effort can be wasted 

    examples: chainer, most automatic differentiation libraries, dynet

dynamic structure?

    hierarchical structures exist in language 

    we might want to let the network re   ect that hierarchy 

    hierarchical structure is easiest to process with 

traditional    ow-control mechanisms in your favorite 
languages 

    combinatorial algorithms (e.g., id145) 

    exploit independencies to compute over a large 

space of operations tractably

why dynet?

    the state of the world before dynet/id98 

    ad libraries are fast and good, but don   t have support for deep learning 
must-haves (gpus, optimization algorithms, primitives for implementing 
id56s, etc.) 

    deep learning toolkits don   t support dynamic graphs well 

    dynet is a hybrid between a generic autodiff library and a deep learning toolkit 

    it has the    exibility of a good ad library 

    it has most obligatory dl primitives 

    (although the emphasis is dynamic operation, it can run perfectly well in    static 

mode   . it   s quite fast too! but if you   re happy with that, probably stick to 
tensorflow/theano/torch.)

why dynet?

    the state of the world before dynet/id98 

    ad libraries are fast and good, but don   t have support for deep learning 
must-haves (gpus, optimization algorithms, primitives for implementing 
id56s, etc.) 

    deep learning toolkits don   t support dynamic graphs well 

    dynet is a hybrid between a generic autodiff library and a deep learning toolkit 

    it has the    exibility of a good ad library 

    it has most obligatory dl primitives 

    (although the emphasis is dynamic operation, it can run perfectly well in    static 

mode   . it   s quite fast too! but if you   re happy with that, probably stick to 
tensorflow/theano/torch.)

how does it work?

    c++ backend based on eigen 

    eigen also powers tensorflow 

    custom (   quirky   ) memory management 

    you probably don   t need to ever think about this, 

but a few well-hidden assumptions make the 
graph construction and execution very fast. 

    thin python wrapper on c++ api

neural networks in 

dynet

the major players

    computation graph 

    expressions (~ nodes in the graph) 

    parameters 

    model 

    a collection of parameters 

    trainer

computation graph 
and expressions

import dynet as dy 
dy.renew_cg() # create a new computation graph 
v1 = dy.inputvector([1,2,3,4]) 
v2 = dy.inputvector([5,6,7,8]) 
# v1 and v2 are expressions 
v3 = v1 + v2 
v4 = v3 * 2 
v5 = v1 + 1 
v6 = dy.concatenate([v1,v2,v3,v5]) 
print v6            
print v6.npvalue() 

computation graph 
and expressions

import dynet as dy 
dy.renew_cg() # create a new computation graph 
v1 = dy.inputvector([1,2,3,4]) 
v2 = dy.inputvector([5,6,7,8]) 
# v1 and v2 are expressions 
v3 = v1 + v2 
v4 = v3 * 2 
v5 = v1 + 1 
v6 = dy.concatenate([v1,v2,v3,v5]) 
print v6            
print v6.npvalue() 

expression 5/1

computation graph 
and expressions

import dynet as dy 
dy.renew_cg() # create a new computation graph 
v1 = dy.inputvector([1,2,3,4]) 
v2 = dy.inputvector([5,6,7,8]) 
# v1 and v2 are expressions 
v3 = v1 + v2 
v4 = v3 * 2 
v5 = v1 + 1 
v6 = dy.concatenate([v1,v2,v3,v5]) 
print v6            
print v6.npvalue() 

array([  1.,   2.,   3.,   4.,   2.,   4.,   6.,   8.,   4.,   8.,  12.,  16.])

computation graph 
and expressions

    create basic expressions. 
    combine them using operations. 
    expressions represent symbolic computations. 
    use:   
.value()   
.npvalue()    
.scalar_value()   
.vec_value()   
.forward()    
           to perform actual computation.

model and parameters

    parameters are the things that we optimize over 

(vectors, matrices). 

    model is a collection of parameters. 
    parameters out-live the computation graph.

model and parameters

model = dy.model() 
pw = model.add_parameters((20,4)) 
pb = model.add_parameters(20) 

dy.renew_cg() 
x = dy.inputvector([1,2,3,4]) 
w = dy.parameter(pw) # convert params to expression 
b = dy.parameter(pb) # and add to the graph 
y = w * x + b 

parameter initialization

model = dy.model() 
pw = model.add_parameters((4,4)) 
pw2 = model.add_parameters((4,4), init=dy.glorotinitializer()) 
pw3 = model.add_parameters((4,4), init=dy.normalinitializer(0,1)) 
pw4 = model.parameters_from_numpu(np.eye(4)) 

trainers and backdrop

    initialize a trainer with a given model. 
    compute gradients by calling expr.backward() 

from a scalar node. 

    call trainer.update() to update the model 

parameters using the gradients.

trainers and backdrop

model = dy.model() 
trainer = dy.simplesgdtrainer(model) 
p_v = model.add_parameters(10) 
for i in xrange(10): 
    dy.renew_cg() 
    v = dy.parameter(p_v) 
    v2 = dy.dot_product(v,v) 
    v2.forward()  
    v2.backward()  # compute gradients 
    trainer.update()

trainers and backdrop

  dy.simplesgdtrainer(model,...) 
  dy.momentumsgdtrainer(model,...) 
  dy.adagradtrainer(model,...) 
  dy.adadeltatrainer(model,...) 
  dy.adamtrainer(model,...) 

model = dy.model() 
trainer = dy.simplesgdtrainer(model) 
p_v = model.add_parameters(10) 
for i in xrange(10): 
    dy.renew_cg() 
    v = dy.parameter(p_v) 
    v2 = dy.dot_product(v,v) 
    v2.forward()  
    v2.backward()  # compute gradients 
    trainer.update()

training with dynet

    create model, add parameters, create trainer. 

    for each training example: 

    create computation graph for the loss 

    run forward (compute the loss) 

    run backward (compute the gradients) 

    update parameters

multi-layer id88s

limitations of linear models: the xor problem
the hypothesis class of linear (and log-linear) models is severely restricted. for example,
it cannot represent the xor function, de   ned as:

    model form:

    data:

example: mlp for xor

xor(0, 0) = 0

xor(1, 0) = 1

xor(0, 1) = 1

xor(1, 1) = 0

x

y

  y =  (v    tanh(ux + b))

    loss:

` =(  log   y

  log(1     y)

y = 1
y = 0

that is, there is no parameterization w 2 r2, b 2 r such that:

(0, 0)    w + b < 0

import dynet as dy 
import random 
data =[ ([0,1],0), 
        ([1,0],0), 
        ([0,0],1), 
        ([1,1],1) ] 

  y =  (v    tanh(ux + b))

model = dy.model() 
pu = model.add_parameters((4,2)) 
pb = model.add_parameters(4) 
pv = model.add_parameters(4) 
trainer = dy.simplesgdtrainer(model) 
closs = 0.0 
for iter in xrange(1000): 
    random.shuffle(data) 
    for x,y in data: 
   

.... 

  y =  (v    tanh(ux + b))

for iter in xrange(1000): 
for x,y in data: 
   # create graph for computing loss 
   dy.renew_cg() 
   u = dy.parameter(pu) 
   b = dy.parameter(pb) 
   v = dy.parameter(pv) 
   x = dy.inputvector(x) 
   # predict 
   yhat = dy.logistic(dy.dot_product(v,dy.tanh(u*x+b))) 
   # loss 
   if y == 0: 
      loss = -dy.log(1 - yhat) 
   elif y == 1: 
      loss = -dy.log(yhat) 
             
   closs += loss.scalar_value() # forward 
   loss.backward()   
   trainer.update() 
         

` =(  log   y

  log(1     y)

y = 1
y = 0

  y =  (v    tanh(ux + b))

for iter in xrange(1000): 
for x,y in data: 
   # create graph for computing loss 
   dy.renew_cg() 
   u = dy.parameter(pu) 
   b = dy.parameter(pb) 
   v = dy.parameter(pv) 
   x = dy.inputvector(x) 
   # predict 
   yhat = dy.logistic(dy.dot_product(v,dy.tanh(u*x+b))) 
   # loss 
   if y == 0: 
      loss = -dy.log(1 - yhat) 
   elif y == 1: 
      loss = -dy.log(yhat) 
             
   closs += loss.scalar_value() # forward 
   loss.backward()   
   trainer.update() 
         

  y =  (v    tanh(ux + b))

for iter in xrange(1000): 
for x,y in data: 
   # create graph for computing loss 
   dy.renew_cg() 
   u = dy.parameter(pu) 
   b = dy.parameter(pb) 
   v = dy.parameter(pv) 
   x = dy.inputvector(x) 
   # predict 
   yhat = dy.logistic(dy.dot_product(v,dy.tanh(u*x+b))) 
   # loss 
   if y == 0: 
      loss = -dy.log(1 - yhat) 
   elif y == 1: 
      loss = -dy.log(yhat) 
             
   closs += loss.scalar_value() # forward 
   loss.backward()   
   trainer.update() 
         

  y =  (v    tanh(ux + b))

for iter in xrange(1000): 
for x,y in data: 
   # create graph for computing loss 
   dy.renew_cg() 
   u = dy.parameter(pu) 
   b = dy.parameter(pb) 
   v = dy.parameter(pv) 
   x = dy.inputvector(x) 
   # predict 
   yhat = dy.logistic(dy.dot_product(v,dy.tanh(u*x+b))) 
   # loss 
   if y == 0: 
      loss = -dy.log(1 - yhat) 
   elif y == 1: 
      loss = -dy.log(yhat) 
             
   closs += loss.scalar_value() # forward 
   loss.backward()   
   trainer.update() 
         

` =(  log   y

  log(1     y)

y = 1
y = 0

  y =  (v    tanh(ux + b))

for iter in xrange(1000): 
for x,y in data: 
   # create graph for computing loss 
   dy.renew_cg() 
   u = dy.parameter(pu) 
   b = dy.parameter(pb) 
   v = dy.parameter(pv) 
   x = dy.inputvector(x) 
   # predict 
   yhat = dy.logistic(dy.dot_product(v,dy.tanh(u*x+b))) 
   # loss 
   if y == 0: 
      loss = -dy.log(1 - yhat) 
   elif y == 1: 
      loss = -dy.log(yhat) 
             
   closs += loss.scalar_value() # forward 
   loss.backward()   
   trainer.update() 
         

` =(  log   y

  log(1     y)

y = 1
y = 0

  y =  (v    tanh(ux + b))

for iter in xrange(1000): 
for x,y in data: 
   # create graph for computing loss 
   dy.renew_cg() 
   u = dy.parameter(pu) 
   b = dy.parameter(pb) 
   v = dy.parameter(pv) 
   x = dy.inputvector(x) 
   # predict 
   yhat = dy.logistic(dy.dot_product(v,dy.tanh(u*x+b))) 
   # loss 
   if y == 0: 
      loss = -dy.log(1 - yhat) 
   elif y == 1: 
      loss = -dy.log(yhat) 
             
   closs += loss.scalar_value() # forward 
   loss.backward()   
if iter > 0 and iter % 100 == 0:  
   trainer.update() 
        print "iter:",iter,"loss:", closs/400 
         
        closs = 0

` =(  log   y

  log(1     y)

y = 1
y = 0

for iter in xrange(1000): 
for x,y in data: 
   # create graph for computing loss 
   dy.renew_cg() 
   u = dy.parameter(pu) 
   b = dy.parameter(pb) 
   v = dy.parameter(pv) 
   x = dy.inputvector(x) 
   # predict 
   yhat = dy.logistic(dy.dot_product(v,dy.tanh(u*x+b))) 
   # loss 
   if y == 0: 
      loss = -dy.log(1 - yhat) 
   elif y == 1: 
      loss = -dy.log(yhat) 
             
   closs += loss.scalar_value() # forward 
   loss.backward()   
   trainer.update() 
         

lets organize the code a bit

for iter in xrange(1000): 
for x,y in data: 
   # create graph for computing loss 
   dy.renew_cg() 
   u = dy.parameter(pu) 
   b = dy.parameter(pb) 
   v = dy.parameter(pv) 
   x = dy.inputvector(x) 
   # predict 
   yhat = dy.logistic(dy.dot_product(v,dy.tanh(u*x+b))) 
   # loss 
   if y == 0: 
      loss = -dy.log(1 - yhat) 
   elif y == 1: 
      loss = -dy.log(yhat) 
             
   closs += loss.scalar_value() # forward 
   loss.backward()   
   trainer.update() 
         

lets organize the code a bit

for iter in xrange(1000): 
for x,y in data: 
   # create graph for computing loss 
   dy.renew_cg() 
   u = dy.parameter(pu) 
x = dy.inputvector(x) 
   b = dy.parameter(pb) 
# predict 
   v = dy.parameter(pv) 
yhat = predict(x) 
   x = dy.inputvector(x) 
# loss 
   # predict 
loss = compute_loss(yhat, y)  
   yhat = dy.logistic(dy.dot_product(v,dy.tanh(u*x+b))) 
         
   # loss 
 closs += loss.scalar_value() # forward 
   if y == 0: 
 loss.backward()   
      loss = -dy.log(1 - yhat) 
 trainer.update() 
   elif y == 1: 
      loss = -dy.log(yhat) 
             
   closs += loss.scalar_value() # forward 
   loss.backward()   
   trainer.update() 
         

for iter in xrange(1000): 
for x,y in data: 
   # create graph for computing loss 
   dy.renew_cg() 
   u = dy.parameter(pu) 
x = dy.inputvector(x) 
   b = dy.parameter(pb) 
# predict 
   v = dy.parameter(pv) 
yhat = predict(x) 
   x = dy.inputvector(x) 
# loss 
   # predict 
loss = compute_loss(yhat, y)  
   yhat = dy.logistic(dy.dot_product(v,dy.tanh(u*x+b))) 
         
   # loss 
 closs += loss.scalar_value() # forward 
   if y == 0: 
 loss.backward()   
      loss = -dy.log(1 - yhat) 
 trainer.update() 
   elif y == 1: 
      loss = -dy.log(yhat) 
def predict(expr): 
             
    u = dy.parameter(pu) 
   closs += loss.scalar_value() # forward 
    b = dy.parameter(pb) 
   loss.backward()   
    v = dy.parameter(pv) 
   trainer.update() 
    y = dy.logistic(dy.dot_product(v,dy.tanh(u*expr+b))) 
         
    return y

  y =  (v    tanh(ux + b))

for iter in xrange(1000): 
for x,y in data: 
   # create graph for computing loss 
   dy.renew_cg() 
   u = dy.parameter(pu) 
x = dy.inputvector(x) 
   b = dy.parameter(pb) 
# predict 
   v = dy.parameter(pv) 
yhat = predict(x) 
   x = dy.inputvector(x) 
# loss 
   # predict 
loss = compute_loss(yhat, y)  
   yhat = dy.logistic(dy.dot_product(v,dy.tanh(u*x+b))) 
         
   # loss 
 closs += loss.scalar_value() # forward 
   if y == 0: 
 loss.backward()   
      loss = -dy.log(1 - yhat) 
 trainer.update() 
   elif y == 1: 
      loss = -dy.log(yhat) 
def compute_loss(expr, y): 
             
    if y == 0: 
   closs += loss.scalar_value() # forward 
        return -dy.log(1 - expr) 
   loss.backward()   
    elif y == 1: 
   trainer.update() 
        return -dy.log(expr) 
         

` =(  log   y

  log(1     y)

y = 1
y = 0

key points

    create computation graph for each example. 

    graph is built by composing expressions. 

    functions that take expressions and return 

expressions de   ne graph components.

id27s and 

lookupparameters
    in nlp, it is very common to use feature 

embeddings. 

    each feature is represented as a d-dim vector. 

    these are then summed or concatenated to form 

an input vector. 

    the embeddings can be pre-trained. 

    they are usually trained with the model.

"feature embeddings"

    each feature is assigned a vector. 

    the input is a combination of feature vectors. 
    the feature vectors are parameters of the model   
and are trained jointly with the rest of the network. 

    representation learning: similar features will 

receive similar vectors.

"feature embeddings"

figure 1: sparse vs. dense feature representations. two encodings of the informa-

id27s and 

lookupparameters

    in dynet, embeddings are implemented using   

lookupparameters.

vocab_size = 10000 
emb_dim = 200 
e = model.add_lookup_parameters((vocab_size, emb_dim)) 

id27s and 

lookupparameters

    in dynet, embeddings are implemented using   

lookupparameters.

vocab_size = 10000 
emb_dim = 200 
e = model.add_lookup_parameters((vocab_size, emb_dim)) 

dy.renew_cg() 
x = dy.lookup(e, 5) 
# or 
x = e[5] 
# x is an expression 

deep unordered composition rivals syntactic methods

for text classi   cation

mohit iyyer,1 varun manjunatha,1 jordan boyd-graber,2 hal daum  e iii1

1university of maryland, department of computer science and umiacs

2university of colorado, department of computer science

{miyyer,varunm,hal}@umiacs.umd.edu, jordan.boyd.graber@colorado.edu

"document averaging networks" 
abstract

many existing deep learning models for
natural language processing tasks focus on
learning the compositionality of their in-
puts, which requires many expensive com-
putations. we present a simple deep neural

text classi   cation

results have shown that syntactic functions outper-
form unordered functions on many tasks (socher
et al., 2013b; kalchbrenner and blunsom, 2013).
however, there is a tradeoff: syntactic functions
require more training time than unordered compo-
sition functions and are prohibitively expensive in

scores of labels

sof tmax(   )

g2(w2    + b2)

g1(w1    + b1)

cbow (   )

w1, ..., wn

scores of labels

sof tmax(   )

cbow (   )

w1, ..., wn

"neural bag of words"

"deep averaging network"

cbow (w1, . . . , wn) =

e[wi]

nxi=1

lets define this network

scores of labels

sof tmax(   )

g2(w2    + b2)

g1(w1    + b1)

cbow (   )

w1, ..., wn

scores of labels

sof tmax(   )

cbow (   )

w1, ..., wn

"neural bag of words"

"deep averaging network"

g1 = g2 = tanh

cbow (w1, . . . , wn) =

e[wi]

nxi=1

pw1 = model.add_parameters((hid, edim)) 
pb1 = model.add_parameters(hid) 
pw2 = model.add_parameters((nout, hid)) 
pb2 = model.add_parameters(nout) 
e = model.add_lookup_parameters((v, edim)) 

scores of labels

sof tmax(   )

cbow (   )

w1, ..., wn

scores of labels

sof tmax(   )

g2(w2    + b2)

g1(w1    + b1)

cbow (   )

w1, ..., wn

"neural bag of words"

"deep averaging network"

g1 = g2 = tanh

cbow (w1, . . . , wn) =

e[wi]

nxi=1

pw1 = model.add_parameters((hid, edim)) 
pb1 = model.add_parameters(hid) 
pw2 = model.add_parameters((nout, hid)) 
pb2 = model.add_parameters(nout) 
e = model.add_lookup_parameters((v, edim)) 

scores of labels

sof tmax(   )

cbow (   )

w1, ..., wn

scores of labels

sof tmax(   )

g2(w2    + b2)

g1(w1    + b1)

cbow (   )

w1, ..., wn

"neural bag of words"

"deep averaging network"

for (doc, label) in data: 
    dy.renew_cg() 
    probs = predict_labels(doc)

def predict_labels(doc): 
    x = encode_doc(doc) 
    h = layer1(x) 
    y = layer2(h) 
    return dy.softmax(y)

def layer1(x): 
    w = dy.parameter(pw1) 
    b = dy.parameter(pb1) 
    return dy.tanh(w*x+b) 
def layer2(x): 
    w = dy.parameter(pw2) 
    b = dy.parameter(pb2) 
    return dy.tanh(w*x+b) 

scores of labels

sof tmax(   )

g2(w2    + b2)

g1(w1    + b1)

cbow (   )

w1, ..., wn

"deep averaging network"

scores of labels

sof tmax(   )

cbow (   )

w1, ..., wn

"neural bag of words"

for (doc, label) in data: 
    dy.renew_cg() 
    probs = predict_labels(doc)

def predict_labels(doc): 
    x = encode_doc(doc) 
    h = layer1(x) 
    y = layer2(h) 
    return dy.softmax(y)

def layer1(x): 
    w = dy.parameter(pw1) 
    b = dy.parameter(pb1) 
    return dy.tanh(w*x+b) 
def layer2(x): 
    w = dy.parameter(pw2) 
    b = dy.parameter(pb2) 
    return dy.tanh(w*x+b) 

scores of labels

sof tmax(   )

g2(w2    + b2)

g1(w1    + b1)

cbow (   )

w1, ..., wn

"deep averaging network"

scores of labels

sof tmax(   )

cbow (   )

w1, ..., wn

"neural bag of words"

for (doc, label) in data: 
    dy.renew_cg() 
    probs = predict_labels(doc)

def predict_labels(doc): 
    x = encode_doc(doc) 
    h = layer1(x) 
    y = layer2(h) 
    return dy.softmax(y)

def layer1(x): 
    w = dy.parameter(pw1) 
    b = dy.parameter(pb1) 
    return dy.tanh(w*x+b) 
def layer2(x): 
    w = dy.parameter(pw2) 
    b = dy.parameter(pb2) 
    return dy.tanh(w*x+b) 

scores of labels

sof tmax(   )

g2(w2    + b2)

g1(w1    + b1)

cbow (   )

w1, ..., wn

"deep averaging network"

scores of labels

sof tmax(   )

cbow (   )

w1, ..., wn

"neural bag of words"

for (doc, label) in data: 
    dy.renew_cg() 
    probs = predict_labels(doc)

def predict_labels(doc): 
    x = encode_doc(doc) 
    h = layer1(x) 
    y = layer2(h) 
    return dy.softmax(y)

def layer1(x): 
    w = dy.parameter(pw1) 
    b = dy.parameter(pb1) 
    return dy.tanh(w*x+b) 
def layer2(x): 
    w = dy.parameter(pw2) 
    b = dy.parameter(pb2) 
    return dy.tanh(w*x+b) 

scores of labels

sof tmax(   )

g2(w2    + b2)

g1(w1    + b1)

cbow (   )

w1, ..., wn

"deep averaging network"

scores of labels

sof tmax(   )

cbow (   )

w1, ..., wn

"neural bag of words"

for (doc, label) in data: 
    dy.renew_cg() 
    probs = predict_labels(doc)

scores of labels

def predict_labels(doc): 
    x = encode_doc(doc) 
    h = layer1(x) 
    y = layer2(h) 
    return dy.softmax(y)
def encode_doc(doc): 
sof tmax(   )
    doc = [w2i[w] for w in doc] 
    embs = [e[idx] for idx in doc] 
cbow (   )
    return dy.esum(embs) 
def layer1(x): 
    w = dy.parameter(pw1) 
    b = dy.parameter(pb1) 
    return dy.tanh(w*x+b) 
def layer2(x): 
    w = dy.parameter(pw2) 
    b = dy.parameter(pb2) 
    return dy.tanh(w*x+b) 

w1, ..., wn

"neural bag of words"

scores of labels

sof tmax(   )

g2(w2    + b2)

g1(w1    + b1)

cbow (   )

w1, ..., wn

"deep averaging network"

for (doc, label) in data: 
    dy.renew_cg() 
    probs = predict_labels(doc)

scores of labels

def predict_labels(doc): 
    x = encode_doc(doc) 
    h = layer1(x) 
    y = layer2(h) 
    return dy.softmax(y)
def encode_doc(doc): 
sof tmax(   )
    doc = [w2i[w] for w in doc] 
    embs = [e[idx] for idx in doc] 
cbow (   )
    return dy.esum(embs) 
def layer1(x): 
    w = dy.parameter(pw1) 
    b = dy.parameter(pb1) 
    return dy.tanh(w*x+b) 
def layer2(x): 
    w = dy.parameter(pw2) 
    b = dy.parameter(pb2) 
    return dy.tanh(w*x+b) 

w1, ..., wn

"neural bag of words"

scores of labels

sof tmax(   )

g2(w2    + b2)

g1(w1    + b1)

cbow (   )

w1, ..., wn

"deep averaging network"

for (doc, label) in data: 
for (doc, label) in data: 
    dy.renew_cg() 
    dy.renew_cg() 
    probs = predict_labels(doc)
    probs = predict_labels(doc) 
    loss = do_loss(probs,label) 
    loss.forward() 
    loss.backward() 
    trainer.update()

def predict_labels(doc): 
    x = encode_doc(doc) 
    h = layer1(x) 
    y = layer2(h) 
    return dy.softmax(y)

scores of labels

def do_loss(probs, label): 
    label = l2i[label] 
    return -dy.log(dy.pick(probs,label))

cbow (   )

w1, ..., wn

sof tmax(   )

scores of labels

sof tmax(   )

g2(w2    + b2)

g1(w1    + b1)

cbow (   )

w1, ..., wn

"neural bag of words"

"deep averaging network"

for (doc, label) in data: 
for (doc, label) in data: 
    dy.renew_cg() 
    dy.renew_cg() 
    probs = predict_labels(doc)
    probs = predict_labels(doc) 
    loss = do_loss(probs,label) 
    loss.forward() 
    loss.backward() 
    trainer.update()

def predict_labels(doc): 
    x = encode_doc(doc) 
    h = layer1(x) 
    y = layer2(h) 
    return dy.softmax(y)

scores of labels

sof tmax(   )

g2(w2    + b2)

g1(w1    + b1)

cbow (   )

w1, ..., wn

scores of labels

sof tmax(   )

cbow (   )

w1, ..., wn

"neural bag of words"

"deep averaging network"

def classify(doc): 
    dy.renew_cg() 
    probs = predict_labels(doc) 
    vals = probs.npvalue() 
    return i2l[np.argmax(vals)] 

tf/idf?

def encode_doc(doc): 
    doc = [w2i[w] for w in doc] 
    embs = [e[idx] for idx in doc] 
    return dy.esum(embs) 

def encode_doc(doc): 
    weights = [tfidf(w) for w in doc] 
    doc = [w2i[w] for w in doc] 
    embs = [e[idx]*w for w,idx in zip(weights,doc)] 
    return dy.esum(embs) 

encapsulation with classes

class mlp(object): 
    def __init__(self, model, in_dim, hid_dim, out_dim, non_lin=dy.tanh): 
        self._w1 = model.add_parameters((hid_dim, in_dim)) 
        self._b1 = model.add_parameters(hid_dim) 
        self._w2 = model.add_parameters((out_dim, hid_dim)) 
        self._b2 = model.add_parameters(out_dim) 
        self.non_lin = non_lin 
         
    def __call__(self, in_expr): 
        w1 = dy.parameter(self._w1) 
        w2 = dy.parameter(self._w2) 
        b1 = dy.parameter(self._b1) 
        b2 = dy.parameter(self._b2) 
        g = self.non_lin 
        return w2*g(w1*in_expr + b1)+b2 

x = dy.inputvector(range(10)) 
mlp = mlp(model, 10, 100, 2, dy.tanh) 
y = mlp(v) 

summary

    computation graph 

    expressions (~ nodes in the graph) 

    parameters, lookupparameters 

    model (a collection of parameters) 

    trainers 
    create a graph for each example, then   

compute loss, backdrop, update.

outline

    part 1

    computation graphs and their construction 

    neural nets in dynet 

    recurrent neural networks 

    minibatching 

    adding new differentiable functions

recurrent neural networks

    nlp is full of sequential data 

    words in sentences 

    characters in words 

    sentences in discourse 

        

    how do we represent an arbitrarily long history?

    we will train neural networks to build a representation of these 

arbitrarily big sequences

recurrent neural networks

    nlp is full of sequential data 

    words in sentences 

    characters in words 

    sentences in discourse 

        

    how do we represent an arbitrarily long history?

    we will train neural networks to build a representation of these 

arbitrarily big sequences

recurrent neural networks
feed-forward nn
h = g(vx + c)
  y = wh + b

  y

h

x

recurrent neural networks
feed-forward nn
h = g(vx + c)
  y = wh + b

ht = g(vxt + uht 1 + c)
  yt = wht + b

recurrent nn

  y

h

x

  yt

ht

xt

recurrent neural networks
ht = g(vxt + uht 1 + c)
  yt = wht + b

how do we train the id56   s parameters?

  y1

h1

x1

h0

  y2

h2

x2

  y3

h3

x3

  y4

h4

x4

recurrent neural networks
ht = g(vxt + uht 1 + c)
  yt = wht + b

f

y1

cost1

  y1

h1

x1

h0

y2

cost2

  y2

h2

x2

y3

cost3

  y3

h3

x3

y4

cost4

  y4

h4

x4

recurrent neural networks

f

    the unrolled graph is a well-formed (dag) 
computation graph   we can run backprop 

    parameters are tied across time, derivatives are 

aggregated across all time steps  

    this is historically called    id26 

through time    (bptt)

parameter tying

ht = g(vxt + uht 1 + c)
  yt = wht + b

f

y1

cost1

  y1

h1

x1

h0

u

y2

cost2

  y2

h2

x2

y3

cost3

  y3

h3

x3

y4

cost4

  y4

h4

x4

parameter tying

  y2

h2

x2

  y3

h3

x3

  y4

h4

x4

  y1

h1

x1

h0

u

@f
@u

=

4xt=1

@ht
@u

@f
@ht

what else can we do?

ht = g(vxt + uht 1 + c)
  yt = wht + b

y1

cost1

  y1

h1

x1

h0

y2

cost2

  y2

h2

x2

f

y4

cost4

  y4

h4

x4

y3

cost3

  y3

h3

x3

   read and summarize   

ht = g(vxt + uht 1 + c)
  y = wh|x| + b
summarize a sequence into a single vector.   
(for prediction, translation, etc.)

h1

x1

h0

h2

x2

h3

x3

y

f

  y

h4

x4

example: language model

the 
a 
and 
cat 
dog 
horse 
runs 
says 
walked 
walks 
walking 
pig 
lisbon 
sardines 
   

h

softmax

u = wh + b

pi =

exp uipj exp uj

h 2 rd
|v | = 100, 000

example: language model

the 
a 
and 
cat 
dog 
horse 
runs 
says 
walked 
walks 
walking 
pig 
lisbon 
sardines 
   

h

softmax

u = wh + b

pi =

exp uipj exp uj

h 2 rd
|v | = 100, 000

p(e) =p(e1)   

p(e2 | e1)   
p(e3 | e1, e2)   
p(e4 | e1, e2, e3)   
      

 istories are sequences of words   
h

example: language model
p(tom | hsi)

   p(likes | hsi, tom)

   p(beer | hsi, tom, likes)

   p(h/si | hsi, tom, likes, beer)

beer

</s>

   

   

tom

   

  p1

likes

   

softmax

softmax

softmax

softmax

h2

x2

h3

x3

h4

x4

h0

h1

x1

<s>

language model training

tom

   

  p1

likes

   

beer

   

</s>

   

softmax

softmax

softmax

softmax

h2

x2

h3

x3

h4

x4

h0

h1

x1

<s>

language model training

likes

cost2

f

</s>

cost4

beer

cost3

softmax

softmax

softmax

softmax

h2

x2

h3

x3

h4

x4

tom

cost1

{log loss/   
cross id178

  p1

h0

h1

x1

<s>

alternative id56s

    long short-term memories (lstms; hochreiter and 

schmidthuber, 1997) 

    id149 (grus; cho et al., 2014) 

    all follow the basic paradigm of    take input, update 

state   

recurrent neural networks 

in dynet

    based on    *builder    class (*=simpleid56/lstm)
    add parameters to model (once):
# lstm (layers=1, input=64, hidden=128, model) 
id56 = dy.lstmbuilder(1, 64, 128, model)
    add parameters to cg and get initial state (per sentence):
s = id56.initial_state()
    update state and access (per input word/character):
s = s.add_input(x_t) 
h_t = s.output()

id56lm example: 

parameter initialization

# lookup parameters for id27s 
words_lookup = model.add_lookup_parameters((nwords, 64)) 
# word-level lstm (layers=1, input=64, hidden=128, model) 
id56 = dy.lstmbuilder(1, 64, 128, model) 
# softmax weights/biases on top of lstm outputs 
w_sm = model.add_parameters((nwords, 128)) 
b_sm = model.add_parameters(nwords) 

id56lm example: 
sentence initialization

# build the language model graph 
def calc_lm_loss(wids): 
    dy.renew_cg() 
    # parameters -> expressions 
    w_exp = dy.parameter(w_sm) 
    b_exp = dy.parameter(b_sm) 
    # add parameters to cg and get state 
    f_init = id56.initial_state() 
    # get the word vectors for each word id 
    wembs = [words_lookup[wid] for wid in wids] 
    # start the id56 by inputting "<s>" 
    s = f_init.add_input(wembs[-1]) 

   

id56lm example: 

loss calculation and state update

   

    # process each word id and embedding 
    losses = [] 
    for wid, we in zip(wids, wembs): 

        # calculate and save the softmax loss 
        score = w_exp * s.output() + b_exp 
        loss = dy.pickneglogsoftmax(score, wid) 
        losses.append(loss) 

        # update the id56 state with the input 
        s = s.add_input(we)  
     
    # return the sum of all losses 
    return dy.esum(losses)

mini-batching

implementation details: 

minibatching

    minibatching: group together multiple similar operations 
    modern hardware 

    pretty fast for elementwise operations 

    very fast for matrix-id127 
    has overhead for every operation (esp. gpus) 

    neural networks consist of 

    lots of elementwise operations 
    lots of matrix-vector products

minibatching

single-instance id56

ht = g(vxt + uht 1 + c)
  yt = wht + b

minibatch id56

z

x1

}|

x1

{

x1

x1

ht = g(vxt + uht 1 + c)
  yt = wht + b
we batch across instances,   
not across time.

anything wrong here?

minibatching sequences

    how do we handle sequences of different lengths?

this     is   an          example  </s>
</s>
this     is   another  </s>

calculate   
loss

1   
1 

1   
1 

1   
1 

1   
1 

1   
0 

pad

mask

sum to sentence loss

mini-batching in dynet

    dynet has special minibatch operations for lookup 

and id168s, everything else automatic 

    you need to: 

    group sentences into a mini batch (optionally, for 

ef   ciency group sentences by length) 

    select the    t   th word in each sentence, and send 

them to the lookup and id168s

function changes

wid = 5 
wemb = words_lookup[wid] 
loss = dy.pickneglogsoftmax(score, wid)

wids = [5, 2, 1, 3] 
wemb = dy.lookup_batch(words_lookup, wids) 
loss = dy.pickneglogsoftmax_batch(score, wids)

implementing functions

standard functions

addmv, af   ne_transform, average, average_cols, binary_log_loss, 
block_dropout, cdiv, colwise_add, concatenate, concatenate_cols, 
const_lookup, const_parameter, contract3d_1d, contract3d_1d_1d, 
conv1d_narrow, conv1d_wide, cube, cwise_multiply, dot_product, 
dropout, erf, exp,    lter1d_narrow, fold_rows, hinge, huber_distance, 
input, inverse, kmax_pooling, kmh_ngram, l1_distance, lgamma, 
log, log_softmax, logdet, logistic, logsumexp, lookup, max, min, 
nobackprop, noise, operator*, operator+, operator-, operator/, 
pairwise_rank_loss, parameter, pick, pickneglogsoftmax, pickrange, 
poisson_loss, pow, rectify, reshape, select_cols, select_rows, 
softmax, softsign, sparsemax, sparsemax_loss, sqrt, square, 
squared_distance, squared_norm, sum, sum_batches, sum_cols, 
tanh, trace_of_product, transpose, zeroes

what if i can   t find my 

    e.g. geometric mean   

function?
y = sqrt(x_0 * x_1)

    option 1: connect multiple functions together 
    option 2: implement forward and backward 
functions directly   
    c++ implementation w/ python bindings

implementing forward

    backend based on eigen operations
geom(x0, x1) := px0     x1

nodes.cc
template<class mydevice> 
void geometricmean::forward_dev_impl(const mydevice & dev, 
                                     const vector<const tensor*>& xs, 
                                     tensor& fx) const { 
  fx.tvec().device(*dev.edevice) =    
        (xs[0]->tvec() * xs[1]->tvec()).sqrt(); 
}

dev: which device     cpu/gpu 
xs: input values 
fx: output value

implementing backward

    calculate gradient for all args @geom(x0, x1)

@x0

=

x1

2     geom(x0, x1)

nodes.cc

template<class mydevice> 
void geometricmean::backward_dev_impl(const mydevice & dev, 
                             const vector<const tensor*>& xs, 
                             const tensor& fx, 
                             const tensor& dedf, 
                             unsigned i, 
                             tensor& dedxi) const { 
  dedxi.tvec().device(*dev.edevice) +=  
                        xs[i==1?0:1] * fx.inv() / 2 * dedf; 
}

dev: which device, cpu/gpu 
xs: input values 
fx: output value

dedf: derivative of loss w.r.t f    
i: index of input to consider 
dedxi: derivative of loss w.r.t. x[i]

other functions to 

implement

    nodes.h: class de   nition 
    nodes-common.cc: dimension check and function name 
    expr.h/expr.cc: interface to expressions 
    dynet.pxd/dynet.pyx: python wrappers

gradient checking

    things go wrong in implementation (forgot a    2    or 

a    -   ) 

    luckily, we can check forward/backward 

consistency automatically 

    idea: small steps (h) approximate gradient

@f (x)
@x    

f (x + h)   f (x   h)

2h

uses backward

only forward

    easy in dynet: use gradcheck(cg) function

questions/coffee time!

