   #[1]github [2]recent commits to awesome-deep-learning-papers:master

   [3]skip to content

   (button)

     * why github?
       [4]features    
          + [5]code review
          + [6]project management
          + [7]integrations
          + [8]actions
          + [9]team management
          + [10]social coding
          + [11]documentation
          + [12]code hosting
          + [13]customer stories    
          + [14]security    
     * [15]enterprise
     * explore
          + [16]explore github    

learn & contribute
          + [17]topics
          + [18]collections
          + [19]trending
          + [20]learning lab
          + [21]open source guides

connect with others
          + [22]events
          + [23]community forum
          + [24]github education
     * [25]marketplace
     * pricing
       [26]plans    
          + [27]compare plans
          + [28]contact sales
          + [29]nonprofit    
          + [30]education    

   ____________________
     * in this repository all github    
       jump to    

     * no suggested jump to results

     * in this repository all github    
       jump to    
     * in this repository all github    
       jump to    

   [31]sign in [32]sign up

     * [33]watch [34]1,963
     * [35]star [36]18,384
     * [37]fork [38]3,476

[39]terryum/[40]awesome-deep-learning-papers

   [41]code [42]issues 12 [43]pull requests 16 [44]projects 0 [45]insights
   (button) dismiss

join github today

   github is home to over 31 million developers working together to host
   and review code, manage projects, and build software together.
   [46]sign up
   the most cited deep learning papers
   [47]deep-learning [48]deep-neural-networks [49]machine-learning
     * [50]168 commits
     * [51]1 branch
     * [52]0 releases
     * [53]30 contributors

    1. [54]tex 85.7%
    2. [55]python 14.3%

   (button) tex python
   branch: master (button) new pull request
   [56]find file
   clone or download

clone with https

   use git or checkout with svn using the web url.
   https://github.com/t
   [57]download zip

downloading...

   want to be notified of new releases in
   terryum/awesome-deep-learning-papers?
   [58]sign in [59]sign up

launching github desktop...

   if nothing happens, [60]download github desktop and try again.

   (button) go back

launching github desktop...

   if nothing happens, [61]download github desktop and try again.

   (button) go back

launching xcode...

   if nothing happens, [62]download xcode and try again.

   (button) go back

launching visual studio...

   if nothing happens, [63]download the github extension for visual studio
   and try again.

   (button) go back
   [64]@terryum
   [65]terryum [66]update readme.md
   latest commit [67]1a0a9df oct 19, 2018
   [68]permalink
   type name latest commit message commit time
   failed to load latest commit information.
   [69].gitignore [70]added .gitignore with papers directory feb 26, 2017
   [71]contributing.md
   [72]readme.md
   [73]readingnotes.md
   [74]fetch_papers.py
   [75]get_authors.py
   [76]top100papers.bib [77]add "training very deep networks" to bib may
   8, 2017

readme.md

awesome - most cited deep learning papers

   [78]awesome

   [notice] this list is not being maintained anymore because of the
   overwhelming amount of deep learning papers published every day since
   2017.

   a curated list of the most cited deep learning papers (2012-2016)

   we believe that there exist classic deep learning papers which are
   worth reading regardless of their application domain. rather than
   providing overwhelming amount of papers, we would like to provide a
   curated list of the awesome deep learning papers which are considered
   as must-reads in certain research domains.

background

   before this list, there exist other awesome deep learning lists, for
   example, [79]deep vision and [80]awesome recurrent neural networks.
   also, after this list comes out, another awesome list for deep learning
   beginners, called [81]deep learning papers reading roadmap, has been
   created and loved by many deep learning researchers.

   although the roadmap list includes lots of important deep learning
   papers, it feels overwhelming for me to read them all. as i mentioned
   in the introduction, i believe that seminal works can give us lessons
   regardless of their application domain. thus, i would like to introduce
   top 100 deep learning papers here as a good starting point of
   overviewing deep learning researches.

   to get the news for newly released papers everyday, follow my
   [82]twitter or [83]facebook page!

awesome list criteria

    1. a list of top 100 deep learning papers published from 2012 to 2016
       is suggested.
    2. if a paper is added to the list, another paper (usually from *more
       papers from 2016" section) should be removed to keep top 100
       papers. (thus, removing papers is also important contributions as
       well as adding papers)
    3. papers that are important, but failed to be included in the list,
       will be listed in more than top 100 section.
    4. please refer to new papers and old papers sections for the papers
       published in recent 6 months or before 2012.

   (citation criteria)
     * < 6 months : new papers (by discussion)
     * 2016 : +60 citations or "more papers from 2016"
     * 2015 : +200 citations
     * 2014 : +400 citations
     * 2013 : +600 citations
     * 2012 : +800 citations
     * ~2012 : old papers (by discussion)

   please note that we prefer seminal deep learning papers that can be
   applied to various researches rather than application papers. for that
   reason, some papers that meet the criteria may not be accepted while
   others can be. it depends on the impact of the paper, applicability to
   other researches scarcity of the research domain, and so on.

   we need your contributions!

   if you have any suggestions (missing papers, new papers, key
   researchers or typos), please feel free to edit and pull a request.
   (please read the [84]contributing guide for further instructions,
   though just letting me know the title of papers can also be a big
   contribution to us.)

   (update) you can download all top-100 papers with [85]this and collect
   all authors' names with [86]this. also, [87]bib file for all top-100
   papers are available. thanks, doodhwala, [88]sven and [89]grepinsight!
     * can anyone contribute the code for obtaining the statistics of the
       authors of top-100 papers?

contents

     * [90]understanding / generalization / transfer
     * [91]optimization / training techniques
     * [92]unsupervised / generative models
     * [93]convolutional network models
     * [94]image segmentation / id164
     * [95]image / video / etc
     * [96]natural language processing / id56s
     * [97]speech / other domain
     * [98]id23 / robotics
     * [99]more papers from 2016

   (more than top 100)
     * [100]new papers : less than 6 months
     * [101]old papers : before 2012
     * [102]hw / sw / dataset : technical reports
     * [103]book / survey / review
     * [104]video lectures / tutorials / blogs
     * [105]appendix: more than top 100 : more papers not in the list
     __________________________________________________________________

understanding / generalization / transfer

     * distilling the knowledge in a neural network (2015), g. hinton et
       al. [106][pdf]
     * deep neural networks are easily fooled: high confidence predictions
       for unrecognizable images (2015), a. nguyen et al. [107][pdf]
     * how transferable are features in deep neural networks? (2014), j.
       yosinski et al. [108][pdf]
     * id98 features off-the-shelf: an astounding baseline for recognition
       (2014), a. razavian et al. [109][pdf]
     * learning and transferring mid-level image representations using
       convolutional neural networks (2014), m. oquab et al. [110][pdf]
     * visualizing and understanding convolutional networks (2014), m.
       zeiler and r. fergus [111][pdf]
     * decaf: a deep convolutional activation feature for generic visual
       recognition (2014), j. donahue et al. [112][pdf]

optimization / training techniques

     * training very deep networks (2015), r. srivastava et al. [113][pdf]
     * batch id172: accelerating deep network training by reducing
       internal covariate shift (2015), s. loffe and c. szegedy [114][pdf]
     * delving deep into rectifiers: surpassing human-level performance on
       id163 classification (2015), k. he et al. [115][pdf]
     * dropout: a simple way to prevent neural networks from overfitting
       (2014), n. srivastava et al. [116][pdf]
     * adam: a method for stochastic optimization (2014), d. kingma and j.
       ba [117][pdf]
     * improving neural networks by preventing co-adaptation of feature
       detectors (2012), g. hinton et al. [118][pdf]
     * random search for hyper-parameter optimization (2012) j. bergstra
       and y. bengio [119][pdf]

unsupervised / generative models

     * pixel recurrent neural networks (2016), a. oord et al. [120][pdf]
     * improved techniques for training gans (2016), t. salimans et al.
       [121][pdf]
     * unsupervised representation learning with deep convolutional
       id3 (2015), a. radford et al.
       [122][pdf]
     * draw: a recurrent neural network for image generation (2015), k.
       gregor et al. [123][pdf]
     * generative adversarial nets (2014), i. goodfellow et al. [124][pdf]
     * auto-encoding id58 (2013), d. kingma and m. welling
       [125][pdf]
     * building high-level features using large scale unsupervised
       learning (2013), q. le et al. [126][pdf]

convolutional neural network models

     * rethinking the inception architecture for id161 (2016),
       c. szegedy et al. [127][pdf]
     * inception-v4, inception-resnet and the impact of residual
       connections on learning (2016), c. szegedy et al. [128][pdf]
     * identity mappings in deep residual networks (2016), k. he et al.
       [129][pdf]
     * deep residual learning for image recognition (2016), k. he et al.
       [130][pdf]
     * spatial transformer network (2015), m. jaderberg et al., [131][pdf]
     * going deeper with convolutions (2015), c. szegedy et al. [132][pdf]
     * very deep convolutional networks for large-scale image recognition
       (2014), k. simonyan and a. zisserman [133][pdf]
     * return of the devil in the details: delving deep into convolutional
       nets (2014), k. chatfield et al. [134][pdf]
     * overfeat: integrated recognition, localization and detection using
       convolutional networks (2013), p. sermanet et al. [135][pdf]
     * maxout networks (2013), i. goodfellow et al. [136][pdf]
     * network in network (2013), m. lin et al. [137][pdf]
     * id163 classification with deep convolutional neural networks
       (2012), a. krizhevsky et al. [138][pdf]

image: segmentation / id164

     * you only look once: unified, real-time id164 (2016), j.
       redmon et al. [139][pdf]
     * fully convolutional networks for semantic segmentation (2015), j.
       long et al. [140][pdf]
     * faster r-id98: towards real-time id164 with region
       proposal networks (2015), s. ren et al. [141][pdf]
     * fast r-id98 (2015), r. girshick [142][pdf]
     * rich feature hierarchies for accurate id164 and semantic
       segmentation (2014), r. girshick et al. [143][pdf]
     * spatial pyramid pooling in deep convolutional networks for visual
       recognition (2014), k. he et al. [144][pdf]
     * semantic image segmentation with deep convolutional nets and fully
       connected crfs, l. chen et al. [145][pdf]
     * learning hierarchical features for scene labeling (2013), c.
       farabet et al. [146][pdf]

image / video / etc

     * image super-resolution using deep convolutional networks (2016), c.
       dong et al. [147][pdf]
     * a neural algorithm of artistic style (2015), l. gatys et al.
       [148][pdf]
     * deep visual-semantic alignments for generating image descriptions
       (2015), a. karpathy and l. fei-fei [149][pdf]
     * show, attend and tell: neural image id134 with visual
       attention (2015), k. xu et al. [150][pdf]
     * show and tell: a neural image caption generator (2015), o. vinyals
       et al. [151][pdf]
     * long-term recurrent convolutional networks for visual recognition
       and description (2015), j. donahue et al. [152][pdf]
     * vqa: visual id53 (2015), s. antol et al. [153][pdf]
     * deepface: closing the gap to human-level performance in face
       verification (2014), y. taigman et al. [154][pdf]:
     * large-scale video classification with convolutional neural networks
       (2014), a. karpathy et al. [155][pdf]
     * two-stream convolutional networks for action recognition in videos
       (2014), k. simonyan et al. [156][pdf]
     * 3d convolutional neural networks for human action recognition
       (2013), s. ji et al. [157][pdf]

natural language processing / id56s

     * neural architectures for id39 (2016), g. lample
       et al. [158][pdf]
     * exploring the limits of id38 (2016), r. jozefowicz et
       al. [159][pdf]
     * teaching machines to read and comprehend (2015), k. hermann et al.
       [160][pdf]
     * effective approaches to attention-based id4
       (2015), m. luong et al. [161][pdf]
     * id49 as recurrent neural networks (2015), s.
       zheng and s. jayasumana. [162][pdf]
     * memory networks (2014), j. weston et al. [163][pdf]
     * id63s (2014), a. graves et al. [164][pdf]
     * id4 by jointly learning to align and
       translate (2014), d. bahdanau et al. [165][pdf]
     * sequence to sequence learning with neural networks (2014), i.
       sutskever et al. [166][pdf]
     * learning phrase representations using id56 encoder-decoder for
       id151 (2014), k. cho et al. [167][pdf]
     * a convolutional neural network for modeling sentences (2014), n.
       kalchbrenner et al. [168][pdf]
     * convolutional neural networks for sentence classification (2014),
       y. kim [169][pdf]
     * glove: global vectors for word representation (2014), j. pennington
       et al. [170][pdf]
     * distributed representations of sentences and documents (2014), q.
       le and t. mikolov [171][pdf]
     * distributed representations of words and phrases and their
       compositionality (2013), t. mikolov et al. [172][pdf]
     * efficient estimation of word representations in vector space
       (2013), t. mikolov et al. [173][pdf]
     * recursive deep models for semantic compositionality over a
       sentiment treebank (2013), r. socher et al. [174][pdf]
     * generating sequences with recurrent neural networks (2013), a.
       graves. [175][pdf]

speech / other domain

     * end-to-end attention-based large vocabulary id103
       (2016), d. bahdanau et al. [176][pdf]
     * deep speech 2: end-to-end id103 in english and
       mandarin (2015), d. amodei et al. [177][pdf]
     * id103 with deep recurrent neural networks (2013), a.
       graves [178][pdf]
     * deep neural networks for acoustic modeling in id103:
       the shared views of four research groups (2012), g. hinton et al.
       [179][pdf]
     * context-dependent pre-trained deep neural networks for
       large-vocabulary id103 (2012) g. dahl et al.
       [180][pdf]
     * acoustic modeling using id50 (2012), a. mohamed et
       al. [181][pdf]

id23 / robotics

     * end-to-end training of deep visuomotor policies (2016), s. levine
       et al. [182][pdf]
     * learning hand-eye coordination for robotic grasping with deep
       learning and large-scale data collection (2016), s. levine et al.
       [183][pdf]
     * asynchronous methods for deep id23 (2016), v.
       mnih et al. [184][pdf]
     * deep id23 with double id24 (2016), h.
       hasselt et al. [185][pdf]
     * mastering the game of go with deep neural networks and tree search
       (2016), d. silver et al. [186][pdf]
     * continuous control with deep id23 (2015), t.
       lillicrap et al. [187][pdf]
     * human-level control through deep id23 (2015), v.
       mnih et al. [188][pdf]
     * deep learning for detecting robotic grasps (2015), i. lenz et al.
       [189][pdf]
     * playing atari with deep id23 (2013), v. mnih et
       al. [190][pdf])

more papers from 2016

     * layer id172 (2016), j. ba et al. [191][pdf]
     * learning to learn by id119 by id119 (2016),
       m. andrychowicz et al. [192][pdf]
     * domain-adversarial training of neural networks (2016), y. ganin et
       al. [193][pdf]
     * wavenet: a generative model for raw audio (2016), a. oord et al.
       [194][pdf] [195][web]
     * colorful image colorization (2016), r. zhang et al. [196][pdf]
     * generative visual manipulation on the natural image manifold
       (2016), j. zhu et al. [197][pdf]
     * texture networks: feed-forward synthesis of textures and stylized
       images (2016), d ulyanov et al. [198][pdf]
     * ssd: single shot multibox detector (2016), w. liu et al. [199][pdf]
     * squeezenet: alexnet-level accuracy with 50x fewer parameters and<
       1mb model size (2016), f. iandola et al. [200][pdf]
     * eie: efficient id136 engine on compressed deep neural network
       (2016), s. han et al. [201][pdf]
     * binarized neural networks: training deep neural networks with
       weights and activations constrained to+ 1 or-1 (2016), m.
       courbariaux et al. [202][pdf]
     * dynamic memory networks for visual and textual id53
       (2016), c. xiong et al. [203][pdf]
     * stacked attention networks for image id53 (2016), z.
       yang et al. [204][pdf]
     * hybrid computing using a neural network with dynamic external
       memory (2016), a. graves et al. [205][pdf]
     * google's id4 system: bridging the gap
       between human and machine translation (2016), y. wu et al.
       [206][pdf]
     __________________________________________________________________

new papers

   newly published papers (< 6 months) which are worth reading
     * mobilenets: efficient convolutional neural networks for mobile
       vision applications (2017), andrew g. howard et al. [207][pdf]
     * convolutional sequence to sequence learning (2017), jonas gehring
       et al. [208][pdf]
     * a knowledge-grounded neural conversation model (2017), marjan
       ghazvininejad et al. [209][pdf]
     * accurate, large minibatch sgd:training id163 in 1 hour (2017),
       priya goyal et al. [210][pdf]
     * tacotron: towards end-to-end id133 (2017), y. wang et
       al. [211][pdf]
     * deep photo style transfer (2017), f. luan et al. [212][pdf]
     * evolution strategies as a scalable alternative to reinforcement
       learning (2017), t. salimans et al. [213][pdf]
     * deformable convolutional networks (2017), j. dai et al. [214][pdf]
     * mask r-id98 (2017), k. he et al. [215][pdf]
     * learning to discover cross-domain relations with generative
       adversarial networks (2017), t. kim et al. [216][pdf]
     * deep voice: real-time neural text-to-speech (2017), s. arik et al.,
       [217][pdf]
     * pixelnet: representation of the pixels, by the pixels, and for the
       pixels (2017), a. bansal et al. [218][pdf]
     * batch reid172: towards reducing minibatch dependence in
       batch-normalized models (2017), s. ioffe. [219][pdf]
     * wasserstein gan (2017), m. arjovsky et al. [220][pdf]
     * understanding deep learning requires rethinking generalization
       (2017), c. zhang et al. [221][pdf]
     * least squares id3 (2016), x. mao et al.
       [222][pdf]

old papers

   classic papers published before 2012
     * an analysis of single-layer networks in unsupervised feature
       learning (2011), a. coates et al. [223][pdf]
     * deep sparse rectifier neural networks (2011), x. glorot et al.
       [224][pdf]
     * natural language processing (almost) from scratch (2011), r.
       collobert et al. [225][pdf]
     * recurrent neural network based language model (2010), t. mikolov et
       al. [226][pdf]
     * stacked denoising autoencoders: learning useful representations in
       a deep network with a local denoising criterion (2010), p. vincent
       et al. [227][pdf]
     * learning mid-level features for recognition (2010), y. boureau
       [228][pdf]
     * a practical guide to training restricted id82s (2010),
       g. hinton [229][pdf]
     * understanding the difficulty of training deep feedforward neural
       networks (2010), x. glorot and y. bengio [230][pdf]
     * why does unsupervised pre-training help deep learning (2010), d.
       erhan et al. [231][pdf]
     * learning deep architectures for ai (2009), y. bengio. [232][pdf]
     * convolutional id50 for scalable unsupervised
       learning of hierarchical representations (2009), h. lee et al.
       [233][pdf]
     * greedy layer-wise training of deep networks (2007), y. bengio et
       al. [234][pdf]
     * reducing the dimensionality of data with neural networks, g. hinton
       and r. salakhutdinov. [235][pdf]
     * a fast learning algorithm for deep belief nets (2006), g. hinton et
       al. [236][pdf]
     * gradient-based learning applied to document recognition (1998), y.
       lecun et al. [237][pdf]
     * long short-term memory (1997), s. hochreiter and j. schmidhuber.
       [238][pdf]

hw / sw / dataset

     * squad: 100,000+ questions for machine comprehension of text (2016),
       rajpurkar et al. [239][pdf]
     * openai gym (2016), g. brockman et al. [240][pdf]
     * tensorflow: large-scale machine learning on heterogeneous
       distributed systems (2016), m. abadi et al. [241][pdf]
     * theano: a python framework for fast computation of mathematical
       expressions, r. al-rfou et al.
     * torch7: a matlab-like environment for machine learning, r.
       collobert et al. [242][pdf]
     * matconvnet: convolutional neural networks for matlab (2015), a.
       vedaldi and k. lenc [243][pdf]
     * id163 large scale visual recognition challenge (2015), o.
       russakovsky et al. [244][pdf]
     * caffe: convolutional architecture for fast feature embedding
       (2014), y. jia et al. [245][pdf]

book / survey / review

     * on the origin of deep learning (2017), h. wang and bhiksha raj.
       [246][pdf]
     * deep id23: an overview (2017), y. li, [247][pdf]
     * id4 and sequence-to-sequence models(2017): a
       tutorial, g. neubig. [248][pdf]
     * neural network and deep learning (book, jan 2017), michael nielsen.
       [249][html]
     * deep learning (book, 2016), goodfellow et al. [250][html]
     * lstm: a search space odyssey (2016), k. greff et al. [251][pdf]
     * tutorial on id5 (2016), c. doersch. [252][pdf]
     * deep learning (2015), y. lecun, y. bengio and g. hinton [253][pdf]
     * deep learning in neural networks: an overview (2015), j.
       schmidhuber [254][pdf]
     * representation learning: a review and new perspectives (2013), y.
       bengio et al. [255][pdf]

video lectures / tutorials / blogs

   (lectures)
     * cs231n, convolutional neural networks for visual recognition,
       stanford university [256][web]
     * cs224d, deep learning for natural language processing, stanford
       university [257][web]
     * oxford deep nlp 2017, deep learning for natural language
       processing, university of oxford [258][web]

   (tutorials)
     * nips 2016 tutorials, long beach [259][web]
     * icml 2016 tutorials, new york city [260][web]
     * iclr 2016 videos, san juan [261][web]
     * deep learning summer school 2016, montreal [262][web]
     * bay area deep learning school 2016, stanford [263][web]

   (blogs)
     * openai [264][web]
     * distill [265][web]
     * andrej karpathy blog [266][web]
     * colah's blog [267][web]
     * wildml [268][web]
     * fastml [269][web]
     * themorningpaper [270][web]

appendix: more than top 100

   (2016)
     * a character-level decoder without explicit segmentation for neural
       machine translation (2016), j. chung et al. [271][pdf]
     * dermatologist-level classification of skin cancer with deep neural
       networks (2017), a. esteva et al. [272][html]
     * weakly supervised object localization with multi-fold multiple
       instance learning (2017), r. gokberk et al. [273][pdf]
     * brain tumor segmentation with deep neural networks (2017), m.
       havaei et al. [274][pdf]
     * professor forcing: a new algorithm for training recurrent networks
       (2016), a. lamb et al. [275][pdf]
     * adversarially learned id136 (2016), v. dumoulin et al.
       [276][web][277][pdf]
     * understanding convolutional neural networks (2016), j. koushik
       [278][pdf]
     * taking the human out of the loop: a review of bayesian optimization
       (2016), b. shahriari et al. [279][pdf]
     * adaptive computation time for recurrent neural networks (2016), a.
       graves [280][pdf]
     * densely connected convolutional networks (2016), g. huang et al.
       [281][pdf]
     * region-based convolutional networks for accurate id164
       and segmentation (2016), r. girshick et al.
     * continuous deep id24 with model-based acceleration (2016), s.
       gu et al. [282][pdf]
     * a thorough examination of the id98/daily mail reading comprehension
       task (2016), d. chen et al. [283][pdf]
     * achieving open vocabulary id4 with hybrid
       word-character models, m. luong and c. manning. [284][pdf]
     * very deep convolutional networks for natural language processing
       (2016), a. conneau et al. [285][pdf]
     * bag of tricks for efficient text classification (2016), a. joulin
       et al. [286][pdf]
     * efficient piecewise training of deep structured models for semantic
       segmentation (2016), g. lin et al. [287][pdf]
     * learning to compose neural networks for id53 (2016),
       j. andreas et al. [288][pdf]
     * perceptual losses for real-time style transfer and super-resolution
       (2016), j. johnson et al. [289][pdf]
     * reading text in the wild with convolutional neural networks (2016),
       m. jaderberg et al. [290][pdf]
     * what makes for effective detection proposals? (2016), j. hosang et
       al. [291][pdf]
     * inside-outside net: detecting objects in context with skip pooling
       and recurrent neural networks (2016), s. bell et al. [292][pdf].
     * instance-aware semantic segmentation via multi-task network
       cascades (2016), j. dai et al. [293][pdf]
     * conditional image generation with pixelid98 decoders (2016), a. van
       den oord et al. [294][pdf]
     * deep networks with stochastic depth (2016), g. huang et al.,
       [295][pdf]
     * consistency and fluctuations for stochastic gradient langevin
       dynamics (2016), yee whye teh et al. [296][pdf]

   (2015)
     * ask your neurons: a neural-based approach to answering questions
       about images (2015), m. malinowski et al. [297][pdf]
     * exploring models and data for image id53 (2015), m.
       ren et al. [298][pdf]
     * are you talking to a machine? dataset and methods for multilingual
       image question (2015), h. gao et al. [299][pdf]
     * mind's eye: a recurrent visual representation for image caption
       generation (2015), x. chen and c. zitnick. [300][pdf]
     * from captions to visual concepts and back (2015), h. fang et al.
       [301][pdf].
     * towards ai-complete id53: a set of prerequisite toy
       tasks (2015), j. weston et al. [302][pdf]
     * ask me anything: dynamic memory networks for natural language
       processing (2015), a. kumar et al. [303][pdf]
     * unsupervised learning of video representations using lstms (2015),
       n. srivastava et al. [304][pdf]
     * deep compression: compressing deep neural networks with pruning,
       trained quantization and huffman coding (2015), s. han et al.
       [305][pdf]
     * improved semantic representations from tree-structured long
       short-term memory networks (2015), k. tai et al. [306][pdf]
     * character-aware neural language models (2015), y. kim et al.
       [307][pdf]
     * grammar as a foreign language (2015), o. vinyals et al. [308][pdf]
     * trust region policy optimization (2015), j. schulman et al.
       [309][pdf]
     * beyond short snippents: deep networks for video classification
       (2015) [310][pdf]
     * learning deconvolution network for semantic segmentation (2015), h.
       noh et al. [311][pdf]
     * learning spatiotemporal features with 3d convolutional networks
       (2015), d. tran et al. [312][pdf]
     * understanding neural networks through deep visualization (2015), j.
       yosinski et al. [313][pdf]
     * an empirical exploration of recurrent network architectures (2015),
       r. jozefowicz et al. [314][pdf]
     * deep generative image models using a    laplacian pyramid of
       adversarial networks (2015), e.denton et al. [315][pdf]
     * gated feedback recurrent neural networks (2015), j. chung et al.
       [316][pdf]
     * fast and accurate deep network learning by exponential linear units
       (elus) (2015), d. clevert et al. [317][pdf]
     * id193 (2015), o. vinyals et al. [318][pdf]
     * visualizing and understanding recurrent networks (2015), a.
       karpathy et al. [319][pdf]
     * attention-based models for id103 (2015), j. chorowski
       et al. [320][pdf]
     * end-to-end memory networks (2015), s. sukbaatar et al. [321][pdf]
     * describing videos by exploiting temporal structure (2015), l. yao
       et al. [322][pdf]
     * a neural conversational model (2015), o. vinyals and q. le.
       [323][pdf]
     * improving distributional similarity with lessons learned from word
       embeddings, o. levy et al. [[pdf]]
       ([324]https://www.transacl.org/ojs/index.php/tacl/article/download/
       570/124)
     * transition-based id33 with stack long short-term
       memory (2015), c. dyer et al. [325][pdf]
     * improved transition-based parsing by modeling characters instead of
       words with lstms (2015), m. ballesteros et al. [326][pdf]
     * finding function in form: compositional character models for open
       vocabulary word representation (2015), w. ling et al. [327][pdf]

   (~2014)
     * deeppose: human pose estimation via deep neural networks (2014), a.
       toshev and c. szegedy [328][pdf]
     * learning a deep convolutional network for image super-resolution
       (2014, c. dong et al. [329][pdf]
     * recurrent models of visual attention (2014), v. mnih et al.
       [330][pdf]
     * empirical evaluation of gated recurrent neural networks on sequence
       modeling (2014), j. chung et al. [331][pdf]
     * addressing the rare word problem in id4
       (2014), m. luong et al. [332][pdf]
     * on the properties of id4: encoder-decoder
       approaches (2014), k. cho et. al.
     * recurrent neural network id173 (2014), w. zaremba et al.
       [333][pdf]
     * intriguing properties of neural networks (2014), c. szegedy et al.
       [334][pdf]
     * towards end-to-end id103 with recurrent neural
       networks (2014), a. graves and n. jaitly. [335][pdf]
     * scalable id164 using deep neural networks (2014), d.
       erhan et al. [336][pdf]
     * on the importance of initialization and momentum in deep learning
       (2013), i. sutskever et al. [337][pdf]
     * id173 of neural networks using dropconnect (2013), l. wan
       et al. [338][pdf]
     * learning hierarchical features for scene labeling (2013), c.
       farabet et al. [339][pdf]
     * linguistic regularities in continuous space word representations
       (2013), t. mikolov et al. [340][pdf]
     * large scale distributed deep networks (2012), j. dean et al.
       [341][pdf]
     * a fast and accurate dependency parser using neural networks. chen
       and manning. [342][pdf]

acknowledgement

   thank you for all your contributions. please make sure to read the
   [343]contributing guide before you make a pull request.

license

   [344]cc0

   to the extent possible under law, [345]terry t. um has waived all
   copyright and related or neighboring rights to this work.

     *    2019 github, inc.
     * [346]terms
     * [347]privacy
     * [348]security
     * [349]status
     * [350]help

     * [351]contact github
     * [352]pricing
     * [353]api
     * [354]training
     * [355]blog
     * [356]about

   (button) you can   t perform that action at this time.

   you signed in with another tab or window. [357]reload to refresh your
   session. you signed out in another tab or window. [358]reload to
   refresh your session.

   (button)

references

   visible links
   1. https://github.com/opensearch.xml
   2. https://github.com/terryum/awesome-deep-learning-papers/commits/master.atom
   3. https://github.com/terryum/awesome-deep-learning-papers#start-of-content
   4. https://github.com/features
   5. https://github.com/features/code-review/
   6. https://github.com/features/project-management/
   7. https://github.com/features/integrations
   8. https://github.com/features/actions
   9. https://github.com/features#team-management
  10. https://github.com/features#social-coding
  11. https://github.com/features#documentation
  12. https://github.com/features#code-hosting
  13. https://github.com/customer-stories
  14. https://github.com/security
  15. https://github.com/enterprise
  16. https://github.com/explore
  17. https://github.com/topics
  18. https://github.com/collections
  19. https://github.com/trending
  20. https://lab.github.com/
  21. https://opensource.guide/
  22. https://github.com/events
  23. https://github.community/
  24. https://education.github.com/
  25. https://github.com/marketplace
  26. https://github.com/pricing
  27. https://github.com/pricing#feature-comparison
  28. https://enterprise.github.com/contact
  29. https://github.com/nonprofit
  30. https://education.github.com/
  31. https://github.com/login?return_to=/terryum/awesome-deep-learning-papers
  32. https://github.com/join
  33. https://github.com/login?return_to=/terryum/awesome-deep-learning-papers
  34. https://github.com/terryum/awesome-deep-learning-papers/watchers
  35. https://github.com/login?return_to=/terryum/awesome-deep-learning-papers
  36. https://github.com/terryum/awesome-deep-learning-papers/stargazers
  37. https://github.com/login?return_to=/terryum/awesome-deep-learning-papers
  38. https://github.com/terryum/awesome-deep-learning-papers/network/members
  39. https://github.com/terryum
  40. https://github.com/terryum/awesome-deep-learning-papers
  41. https://github.com/terryum/awesome-deep-learning-papers
  42. https://github.com/terryum/awesome-deep-learning-papers/issues
  43. https://github.com/terryum/awesome-deep-learning-papers/pulls
  44. https://github.com/terryum/awesome-deep-learning-papers/projects
  45. https://github.com/terryum/awesome-deep-learning-papers/pulse
  46. https://github.com/join?source=prompt-code
  47. https://github.com/topics/deep-learning
  48. https://github.com/topics/deep-neural-networks
  49. https://github.com/topics/machine-learning
  50. https://github.com/terryum/awesome-deep-learning-papers/commits/master
  51. https://github.com/terryum/awesome-deep-learning-papers/branches
  52. https://github.com/terryum/awesome-deep-learning-papers/releases
  53. https://github.com/terryum/awesome-deep-learning-papers/graphs/contributors
  54. https://github.com/terryum/awesome-deep-learning-papers/search?l=tex
  55. https://github.com/terryum/awesome-deep-learning-papers/search?l=python
  56. https://github.com/terryum/awesome-deep-learning-papers/find/master
  57. https://github.com/terryum/awesome-deep-learning-papers/archive/master.zip
  58. https://github.com/login?return_to=https://github.com/terryum/awesome-deep-learning-papers
  59. https://github.com/join?return_to=/terryum/awesome-deep-learning-papers
  60. https://desktop.github.com/
  61. https://desktop.github.com/
  62. https://developer.apple.com/xcode/
  63. https://visualstudio.github.com/
  64. https://github.com/terryum
  65. https://github.com/terryum/awesome-deep-learning-papers/commits?author=terryum
  66. https://github.com/terryum/awesome-deep-learning-papers/commit/1a0a9dfb1ee27f74a1ab47ed1273694ec4778ae7
  67. https://github.com/terryum/awesome-deep-learning-papers/commit/1a0a9dfb1ee27f74a1ab47ed1273694ec4778ae7
  68. https://github.com/terryum/awesome-deep-learning-papers/tree/1a0a9dfb1ee27f74a1ab47ed1273694ec4778ae7
  69. https://github.com/terryum/awesome-deep-learning-papers/blob/master/.gitignore
  70. https://github.com/terryum/awesome-deep-learning-papers/commit/c7fa34e52908f93db9b743c0bbb2d7a03cb8e824
  71. https://github.com/terryum/awesome-deep-learning-papers/blob/master/contributing.md
  72. https://github.com/terryum/awesome-deep-learning-papers/blob/master/readme.md
  73. https://github.com/terryum/awesome-deep-learning-papers/blob/master/readingnotes.md
  74. https://github.com/terryum/awesome-deep-learning-papers/blob/master/fetch_papers.py
  75. https://github.com/terryum/awesome-deep-learning-papers/blob/master/get_authors.py
  76. https://github.com/terryum/awesome-deep-learning-papers/blob/master/top100papers.bib
  77. https://github.com/terryum/awesome-deep-learning-papers/commit/2400bbef05c40cfc52ee8064614a81fd602ffb21
  78. https://github.com/sindresorhus/awesome
  79. https://github.com/kjw0612/awesome-deep-vision
  80. https://github.com/kjw0612/awesome-id56
  81. https://github.com/songrotek/deep-learning-papers-reading-roadmap
  82. https://twitter.com/terryum_ml
  83. https://www.facebook.com/terryum.io/
  84. https://github.com/terryum/awesome-deep-learning-papers/blob/master/contributing.md
  85. https://github.com/terryum/awesome-deep-learning-papers/blob/master/fetch_papers.py
  86. https://github.com/terryum/awesome-deep-learning-papers/blob/master/get_authors.py
  87. https://github.com/terryum/awesome-deep-learning-papers/blob/master/top100papers.bib
  88. https://github.com/sunshinemyson
  89. https://github.com/grepinsight
  90. https://github.com/terryum/awesome-deep-learning-papers#understanding--generalization--transfer
  91. https://github.com/terryum/awesome-deep-learning-papers#optimization--training-techniques
  92. https://github.com/terryum/awesome-deep-learning-papers#unsupervised--generative-models
  93. https://github.com/terryum/awesome-deep-learning-papers#convolutional-neural-network-models
  94. https://github.com/terryum/awesome-deep-learning-papers#image-segmentation--object-detection
  95. https://github.com/terryum/awesome-deep-learning-papers#image--video--etc
  96. https://github.com/terryum/awesome-deep-learning-papers#natural-language-processing--id56s
  97. https://github.com/terryum/awesome-deep-learning-papers#speech--other-domain
  98. https://github.com/terryum/awesome-deep-learning-papers#reinforcement-learning--robotics
  99. https://github.com/terryum/awesome-deep-learning-papers#more-papers-from-2016
 100. https://github.com/terryum/awesome-deep-learning-papers#new-papers
 101. https://github.com/terryum/awesome-deep-learning-papers#old-papers
 102. https://github.com/terryum/awesome-deep-learning-papers#hw--sw--dataset
 103. https://github.com/terryum/awesome-deep-learning-papers#book--survey--review
 104. https://github.com/terryum/awesome-deep-learning-papers#video-lectures--tutorials--blogs
 105. https://github.com/terryum/awesome-deep-learning-papers#appendix-more-than-top-100
 106. http://arxiv.org/pdf/1503.02531
 107. http://arxiv.org/pdf/1412.1897
 108. http://papers.nips.cc/paper/5347-how-transferable-are-features-in-deep-neural-networks.pdf
 109. http://www.cv-foundation.org//openaccess/content_cvpr_workshops_2014/w15/papers/razavian_id98_features_off-the-shelf_2014_cvpr_paper.pdf
 110. http://www.cv-foundation.org/openaccess/content_cvpr_2014/papers/oquab_learning_and_transferring_2014_cvpr_paper.pdf
 111. http://arxiv.org/pdf/1311.2901
 112. http://arxiv.org/pdf/1310.1531
 113. http://papers.nips.cc/paper/5850-training-very-deep-networks.pdf
 114. http://arxiv.org/pdf/1502.03167
 115. http://www.cv-foundation.org/openaccess/content_iccv_2015/papers/he_delving_deep_into_iccv_2015_paper.pdf
 116. http://jmlr.org/papers/volume15/srivastava14a/srivastava14a.pdf
 117. http://arxiv.org/pdf/1412.6980
 118. http://arxiv.org/pdf/1207.0580.pdf
 119. http://www.jmlr.org/papers/volume13/bergstra12a/bergstra12a
 120. http://arxiv.org/pdf/1601.06759v2.pdf
 121. http://papers.nips.cc/paper/6125-improved-techniques-for-training-gans.pdf
 122. https://arxiv.org/pdf/1511.06434v2
 123. http://arxiv.org/pdf/1502.04623
 124. http://papers.nips.cc/paper/5423-generative-adversarial-nets.pdf
 125. http://arxiv.org/pdf/1312.6114
 126. http://arxiv.org/pdf/1112.6209
 127. http://www.cv-foundation.org/openaccess/content_cvpr_2016/papers/szegedy_rethinking_the_inception_cvpr_2016_paper.pdf
 128. http://arxiv.org/pdf/1602.07261
 129. https://arxiv.org/pdf/1603.05027v2.pdf
 130. http://arxiv.org/pdf/1512.03385
 131. http://papers.nips.cc/paper/5854-spatial-transformer-networks.pdf
 132. http://www.cv-foundation.org/openaccess/content_cvpr_2015/papers/szegedy_going_deeper_with_2015_cvpr_paper.pdf
 133. http://arxiv.org/pdf/1409.1556
 134. http://arxiv.org/pdf/1405.3531
 135. http://arxiv.org/pdf/1312.6229
 136. http://arxiv.org/pdf/1302.4389v4
 137. http://arxiv.org/pdf/1312.4400
 138. http://papers.nips.cc/paper/4824-id163-classification-with-deep-convolutional-neural-networks.pdf
 139. http://www.cv-foundation.org/openaccess/content_cvpr_2016/papers/redmon_you_only_look_cvpr_2016_paper.pdf
 140. http://www.cv-foundation.org/openaccess/content_cvpr_2015/papers/long_fully_convolutional_networks_2015_cvpr_paper.pdf
 141. http://papers.nips.cc/paper/5638-faster-r-id98-towards-real-time-object-detection-with-region-proposal-networks.pdf
 142. http://www.cv-foundation.org/openaccess/content_iccv_2015/papers/girshick_fast_r-id98_iccv_2015_paper.pdf
 143. http://www.cv-foundation.org/openaccess/content_cvpr_2014/papers/girshick_rich_feature_hierarchies_2014_cvpr_paper.pdf
 144. http://arxiv.org/pdf/1406.4729
 145. https://arxiv.org/pdf/1412.7062
 146. https://hal-enpc.archives-ouvertes.fr/docs/00/74/20/77/pdf/farabet-pami-13.pdf
 147. https://arxiv.org/pdf/1501.00092v3.pdf
 148. https://arxiv.org/pdf/1508.06576
 149. http://www.cv-foundation.org/openaccess/content_cvpr_2015/papers/karpathy_deep_visual-semantic_alignments_2015_cvpr_paper.pdf
 150. http://arxiv.org/pdf/1502.03044
 151. http://www.cv-foundation.org/openaccess/content_cvpr_2015/papers/vinyals_show_and_tell_2015_cvpr_paper.pdf
 152. http://www.cv-foundation.org/openaccess/content_cvpr_2015/papers/donahue_long-term_recurrent_convolutional_2015_cvpr_paper.pdf
 153. http://www.cv-foundation.org/openaccess/content_iccv_2015/papers/antol_vqa_visual_question_iccv_2015_paper.pdf
 154. http://www.cv-foundation.org/openaccess/content_cvpr_2014/papers/taigman_deepface_closing_the_2014_cvpr_paper.pdf
 155. http://vision.stanford.edu/pdf/karpathy14.pdf
 156. http://papers.nips.cc/paper/5353-two-stream-convolutional-networks-for-action-recognition-in-videos.pdf
 157. http://machinelearning.wustl.edu/mlpapers/paper_files/icml2010_jixyy10.pdf
 158. http://aclweb.org/anthology/n/n16/n16-1030.pdf
 159. http://arxiv.org/pdf/1602.02410
 160. http://papers.nips.cc/paper/5945-teaching-machines-to-read-and-comprehend.pdf
 161. https://arxiv.org/pdf/1508.04025
 162. http://www.cv-foundation.org/openaccess/content_iccv_2015/papers/zheng_conditional_random_fields_iccv_2015_paper.pdf
 163. https://arxiv.org/pdf/1410.3916
 164. https://arxiv.org/pdf/1410.5401
 165. http://arxiv.org/pdf/1409.0473
 166. http://papers.nips.cc/paper/5346-sequence-to-sequence-learning-with-neural-networks.pdf
 167. http://arxiv.org/pdf/1406.1078
 168. http://arxiv.org/pdf/1404.2188v1
 169. http://arxiv.org/pdf/1408.5882
 170. http://anthology.aclweb.org/d/d14/d14-1162.pdf
 171. http://arxiv.org/pdf/1405.4053
 172. http://papers.nips.cc/paper/5021-distributed-representations-of-words-and-phrases-and-their-compositionality.pdf
 173. http://arxiv.org/pdf/1301.3781
 174. http://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.383.1327&rep=rep1&type=pdf
 175. https://arxiv.org/pdf/1308.0850
 176. https://arxiv.org/pdf/1508.04395
 177. https://arxiv.org/pdf/1512.02595
 178. http://arxiv.org/pdf/1303.5778.pdf
 179. http://www.cs.toronto.edu/~asamir/papers/spm_dnn_12.pdf
 180. http://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.337.7548&rep=rep1&type=pdf
 181. http://www.cs.toronto.edu/~asamir/papers/speechdbn_jrnl.pdf
 182. http://www.jmlr.org/papers/volume17/15-522/source/15-522.pdf
 183. https://arxiv.org/pdf/1603.02199
 184. http://www.jmlr.org/proceedings/papers/v48/mniha16.pdf
 185. https://arxiv.org/pdf/1509.06461.pdf
 186. http://www.nature.com/nature/journal/v529/n7587/full/nature16961.html
 187. https://arxiv.org/pdf/1509.02971
 188. http://www.davidqiu.com:8888/research/nature14236.pdf
 189. http://www.cs.cornell.edu/~asaxena/papers/lenz_lee_saxena_deep_learning_grasping_ijrr2014.pdf
 190. http://arxiv.org/pdf/1312.5602.pdf
 191. https://arxiv.org/pdf/1607.06450v1.pdf
 192. http://arxiv.org/pdf/1606.04474v1
 193. http://www.jmlr.org/papers/volume17/15-239/source/15-239.pdf
 194. https://arxiv.org/pdf/1609.03499v2
 195. https://deepmind.com/blog/wavenet-generative-model-raw-audio/
 196. https://arxiv.org/pdf/1603.08511
 197. https://arxiv.org/pdf/1609.03552
 198. http://www.jmlr.org/proceedings/papers/v48/ulyanov16.pdf
 199. https://arxiv.org/pdf/1512.02325
 200. http://arxiv.org/pdf/1602.07360
 201. http://arxiv.org/pdf/1602.01528
 202. https://arxiv.org/pdf/1602.02830
 203. http://www.jmlr.org/proceedings/papers/v48/xiong16.pdf
 204. http://www.cv-foundation.org/openaccess/content_cvpr_2016/papers/yang_stacked_attention_networks_cvpr_2016_paper.pdf
 205. https://www.gwern.net/docs/2016-graves.pdf
 206. https://arxiv.org/pdf/1609.08144
 207. https://arxiv.org/pdf/1704.04861.pdf
 208. https://arxiv.org/pdf/1705.03122
 209. https://arxiv.org/pdf/1702.01932
 210. https://research.fb.com/wp-content/uploads/2017/06/id1631kin1h3.pdf
 211. https://arxiv.org/pdf/1703.10135.pdf
 212. http://arxiv.org/pdf/1703.07511v1.pdf
 213. http://arxiv.org/pdf/1703.03864v1.pdf
 214. http://arxiv.org/pdf/1703.06211v2.pdf
 215. https://128.84.21.199/pdf/1703.06870
 216. http://arxiv.org/pdf/1703.05192v1.pdf
 217. http://arxiv.org/pdf/1702.07825v2.pdf
 218. http://arxiv.org/pdf/1702.06506v1.pdf
 219. https://arxiv.org/abs/1702.03275
 220. https://arxiv.org/pdf/1701.07875v1
 221. https://arxiv.org/pdf/1611.03530
 222. https://arxiv.org/abs/1611.04076v2
 223. http://machinelearning.wustl.edu/mlpapers/paper_files/aistats2011_coatesnl11.pdf
 224. http://machinelearning.wustl.edu/mlpapers/paper_files/aistats2011_glorotbb11.pdf
 225. http://arxiv.org/pdf/1103.0398
 226. http://www.fit.vutbr.cz/research/groups/speech/servite/2010/id56lm_mikolov.pdf
 227. http://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.297.3484&rep=rep1&type=pdf
 228. http://ece.duke.edu/~lcarin/boureau-cvpr-10.pdf
 229. http://www.csri.utoronto.ca/~hinton/absps/guidetr.pdf
 230. http://machinelearning.wustl.edu/mlpapers/paper_files/aistats2010_glorotb10.pdf
 231. http://machinelearning.wustl.edu/mlpapers/paper_files/aistats2010_erhancbv10.pdf
 232. http://sanghv.com/download/soft/machine learning, artificial intelligence, mathematics ebooks/ml/learning deep architectures for ai (2009).pdf
 233. http://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.149.802&rep=rep1&type=pdf
 234. http://machinelearning.wustl.edu/mlpapers/paper_files/nips2006_739.pdf
 235. http://homes.mpimf-heidelberg.mpg.de/~mhelmsta/pdf/2006 hinton salakhudtkinov science.pdf
 236. http://nuyoo.utm.mx/~jjf/rna/a8 a fast learning algorithm for deep belief nets.pdf
 237. http://yann.lecun.com/exdb/publis/pdf/lecun-01a.pdf
 238. http://www.mitpressjournals.org/doi/pdfplus/10.1162/neco.1997.9.8.1735
 239. https://arxiv.org/pdf/1606.05250.pdf
 240. https://arxiv.org/pdf/1606.01540
 241. http://arxiv.org/pdf/1603.04467
 242. https://ronan.collobert.com/pub/matos/2011_torch7_nipsw.pdf
 243. http://arxiv.org/pdf/1412.4564
 244. http://arxiv.org/pdf/1409.0575
 245. http://arxiv.org/pdf/1408.5093
 246. https://arxiv.org/pdf/1702.07800
 247. http://arxiv.org/pdf/1701.07274v2.pdf
 248. http://arxiv.org/pdf/1703.01619v1.pdf
 249. http://neuralnetworksanddeeplearning.com/index.html
 250. http://www.deeplearningbook.org/
 251. https://arxiv.org/pdf/1503.04069.pdf?utm_content=buffereddc5&utm_medium=social&utm_source=plus.google.com&utm_campaign=buffer
 252. https://arxiv.org/pdf/1606.05908
 253. https://www.cs.toronto.edu/~hinton/absps/naturedeepreview.pdf
 254. http://arxiv.org/pdf/1404.7828
 255. http://arxiv.org/pdf/1206.5538
 256. http://cs231n.stanford.edu/
 257. http://cs224d.stanford.edu/
 258. https://github.com/oxford-cs-deepnlp-2017/lectures
 259. https://nips.cc/conferences/2016/schedule?type=tutorial
 260. http://techtalks.tv/icml/2016/tutorials/
 261. http://videolectures.net/iclr2016_san_juan/
 262. http://videolectures.net/deeplearning2016_montreal/
 263. https://www.bayareadlschool.org/
 264. https://www.openai.com/
 265. http://distill.pub/
 266. http://karpathy.github.io/
 267. http://colah.github.io/
 268. http://www.wildml.com/
 269. http://www.fastml.com/
 270. https://blog.acolyer.org/
 271. https://arxiv.org/pdf/1603.06147
 272. http://www.nature.com/nature/journal/v542/n7639/full/nature21056.html
 273. https://arxiv.org/pdf/1503.00949
 274. https://arxiv.org/pdf/1505.03540
 275. https://arxiv.org/pdf/1610.09038
 276. https://ishmaelbelghazi.github.io/ali/
 277. https://arxiv.org/pdf/1606.00704v1
 278. https://arxiv.org/pdf/1605.09081v1
 279. https://www.cs.ox.ac.uk/people/nando.defreitas/publications/bayesoptloop.pdf
 280. http://arxiv.org/pdf/1603.08983
 281. https://arxiv.org/pdf/1608.06993v1
 282. http://www.jmlr.org/proceedings/papers/v48/gu16.pdf
 283. https://arxiv.org/pdf/1606.02858
 284. https://arxiv.org/pdf/1604.00788
 285. https://arxiv.org/pdf/1606.01781
 286. https://arxiv.org/pdf/1607.01759
 287. http://www.cv-foundation.org/openaccess/content_cvpr_2016/papers/lin_efficient_piecewise_training_cvpr_2016_paper.pdf
 288. https://arxiv.org/pdf/1601.01705
 289. https://arxiv.org/pdf/1603.08155
 290. http://arxiv.org/pdf/1412.1842
 291. https://arxiv.org/pdf/1502.05082
 292. http://www.cv-foundation.org/openaccess/content_cvpr_2016/papers/bell_inside-outside_net_detecting_cvpr_2016_paper.pdf
 293. http://www.cv-foundation.org/openaccess/content_cvpr_2016/papers/dai_instance-aware_semantic_segmentation_cvpr_2016_paper.pdf
 294. http://papers.nips.cc/paper/6527-tree-structured-reinforcement-learning-for-sequential-object-localization.pdf
 295. https://arxiv.org/pdf/1603.09382
 296. http://www.jmlr.org/papers/volume17/teh16a/teh16a.pdf
 297. http://www.cv-foundation.org/openaccess/content_iccv_2015/papers/malinowski_ask_your_neurons_iccv_2015_paper.pdf
 298. http://papers.nips.cc/paper/5640-stochastic-variational-id136-for-hidden-markov-models.pdf
 299. http://papers.nips.cc/paper/5641-are-you-talking-to-a-machine-dataset-and-methods-for-multilingual-image-question.pdf
 300. http://www.cv-foundation.org/openaccess/content_cvpr_2015/papers/chen_minds_eye_a_2015_cvpr_paper.pdf
 301. http://www.cv-foundation.org/openaccess/content_cvpr_2015/papers/fang_from_captions_to_2015_cvpr_paper.pdf
 302. http://arxiv.org/pdf/1502.05698
 303. http://arxiv.org/pdf/1506.07285
 304. http://www.jmlr.org/proceedings/papers/v37/srivastava15.pdf
 305. https://arxiv.org/pdf/1510.00149
 306. https://arxiv.org/pdf/1503.00075
 307. https://arxiv.org/pdf/1508.06615
 308. http://papers.nips.cc/paper/5635-grammar-as-a-foreign-language.pdf
 309. http://www.jmlr.org/proceedings/papers/v37/schulman15.pdf
 310. http://www.cv-foundation.org/openaccess/content_cvpr_2015/papers/ng_beyond_short_snippets_2015_cvpr_paper.pdf
 311. https://arxiv.org/pdf/1505.04366v1
 312. http://www.cv-foundation.org/openaccess/content_iccv_2015/papers/tran_learning_spatiotemporal_features_iccv_2015_paper.pdf
 313. https://arxiv.org/pdf/1506.06579
 314. http://www.jmlr.org/proceedings/papers/v37/jozefowicz15.pdf
 315. http://papers.nips.cc/paper/5773-deep-generative-image-models-using-a-laplacian-pyramid-of-adversarial-networks.pdf
 316. http://www.jmlr.org/proceedings/papers/v37/chung15.pdf
 317. https://arxiv.org/pdf/1511.07289.pdf\nhttp://arxiv.org/abs/1511.07289\nhttp://arxiv.org/abs/1511.07289
 318. http://papers.nips.cc/paper/5866-pointer-networks.pdf
 319. https://arxiv.org/pdf/1506.02078
 320. http://papers.nips.cc/paper/5847-attention-based-models-for-speech-recognition.pdf
 321. http://papers.nips.cc/paper/5846-end-to-end-memory-networks.pdf
 322. http://www.cv-foundation.org/openaccess/content_iccv_2015/papers/yao_describing_videos_by_iccv_2015_paper.pdf
 323. https://arxiv.org/pdf/1506.05869.pdf
 324. https://www.transacl.org/ojs/index.php/tacl/article/download/570/124
 325. http://aclweb.org/anthology/p/p15/p15-1033.pdf
 326. http://aclweb.org/anthology/d/d15/d15-1041.pdf
 327. http://aclweb.org/anthology/d/d15/d15-1176.pdf
 328. http://www.cv-foundation.org/openaccess/content_cvpr_2014/papers/toshev_deeppose_human_pose_2014_cvpr_paper.pdf
 329. https://www.researchgate.net/profile/chen_change_loy/publication/264552416_lecture_notes_in_computer_science/links/53e583e50cf25d674e9c280e.pdf
 330. http://arxiv.org/pdf/1406.6247.pdf
 331. https://arxiv.org/pdf/1412.3555
 332. https://arxiv.org/pdf/1410.8206
 333. http://arxiv.org/pdf/1409.2329
 334. https://arxiv.org/pdf/1312.6199.pdf
 335. http://www.jmlr.org/proceedings/papers/v32/graves14.pdf
 336. http://www.cv-foundation.org/openaccess/content_cvpr_2014/papers/erhan_scalable_object_detection_2014_cvpr_paper.pdf
 337. http://machinelearning.wustl.edu/mlpapers/paper_files/icml2013_sutskever13.pdf
 338. http://machinelearning.wustl.edu/mlpapers/paper_files/icml2013_wan13.pdf
 339. https://hal-enpc.archives-ouvertes.fr/docs/00/74/20/77/pdf/farabet-pami-13.pdf
 340. http://www.aclweb.org/anthology/n13-1#page=784
 341. http://papers.nips.cc/paper/4687-large-scale-distributed-deep-networks.pdf
 342. http://cs.stanford.edu/people/danqi/papers/emnlp2014.pdf
 343. https://github.com/terryum/awesome-deep-learning-papers/blob/master/contributing.md
 344. https://creativecommons.org/publicdomain/zero/1.0/
 345. https://www.facebook.com/terryum.io/
 346. https://github.com/site/terms
 347. https://github.com/site/privacy
 348. https://github.com/security
 349. https://githubstatus.com/
 350. https://help.github.com/
 351. https://github.com/contact
 352. https://github.com/pricing
 353. https://developer.github.com/
 354. https://training.github.com/
 355. https://github.blog/
 356. https://github.com/about
 357. https://github.com/terryum/awesome-deep-learning-papers
 358. https://github.com/terryum/awesome-deep-learning-papers

   hidden links:
 360. https://github.com/
 361. https://github.com/terryum/awesome-deep-learning-papers
 362. https://github.com/terryum/awesome-deep-learning-papers
 363. https://github.com/terryum/awesome-deep-learning-papers
 364. https://help.github.com/articles/which-remote-url-should-i-use
 365. https://github.com/terryum/awesome-deep-learning-papers#awesome---most-cited-deep-learning-papers
 366. https://github.com/terryum/awesome-deep-learning-papers#background
 367. https://github.com/terryum/awesome-deep-learning-papers#awesome-list-criteria
 368. https://github.com/terryum/awesome-deep-learning-papers#contents
 369. https://github.com/terryum/awesome-deep-learning-papers#understanding--generalization--transfer
 370. https://github.com/terryum/awesome-deep-learning-papers#optimization--training-techniques
 371. https://github.com/terryum/awesome-deep-learning-papers#unsupervised--generative-models
 372. https://github.com/terryum/awesome-deep-learning-papers#convolutional-neural-network-models
 373. https://github.com/terryum/awesome-deep-learning-papers#image-segmentation--object-detection
 374. https://github.com/terryum/awesome-deep-learning-papers#image--video--etc
 375. https://github.com/terryum/awesome-deep-learning-papers#natural-language-processing--id56s
 376. https://github.com/terryum/awesome-deep-learning-papers#speech--other-domain
 377. https://github.com/terryum/awesome-deep-learning-papers#reinforcement-learning--robotics
 378. https://github.com/terryum/awesome-deep-learning-papers#more-papers-from-2016
 379. https://github.com/terryum/awesome-deep-learning-papers#new-papers
 380. https://github.com/terryum/awesome-deep-learning-papers#old-papers
 381. https://github.com/terryum/awesome-deep-learning-papers#hw--sw--dataset
 382. https://github.com/terryum/awesome-deep-learning-papers#book--survey--review
 383. https://github.com/terryum/awesome-deep-learning-papers#video-lectures--tutorials--blogs
 384. https://github.com/terryum/awesome-deep-learning-papers#appendix-more-than-top-100
 385. https://github.com/terryum/awesome-deep-learning-papers#acknowledgement
 386. https://github.com/terryum/awesome-deep-learning-papers#license
 387. https://github.com/
