generative adversarial 

networks (gans)

ian goodfellow, openai research scientist 

nips 2016 tutorial 
barcelona, 2016-12-4

generative modeling

    density estimation 

    sample generation

training examples

model samples

(goodfellow 2016)

roadmap

    why study generative modeling? 

    how do generative models work? how do gans compare to 

others? 

    how do gans work? 

    tips and tricks 

    research frontiers 

    combining gans with other methods

(goodfellow 2016)

why study generative models?

    excellent test of our ability to use high-dimensional, 

complicated id203 distributions 

    simulate possible futures for planning or simulated rl 

    missing data 

    semi-supervised learning 

    multi-modal outputs 

    realistic generation tasks

(goodfellow 2016)

chapter 15. representation learning

next video frame prediction

ground truth

mse

adversarial

figure 15.6: predictive generative networks provide an example of the importance of
learning which features are salient. in this example, the predictive generative network
has been trained to predict the appearance of a 3-d model of a human head at a speci   c
viewing angle. (left)ground truth. this is the correct image, that the network should
emit. (center)image produced by a predictive generative network trained with mean
squared error alone. because the ears do not cause an extreme di   erence in brightness
(goodfellow 2016)
compared to the neighboring skin, they were not su   ciently salient for the model to learn

(lotter et al 2016)

single image super-resolution

(ledig et al 2016)

(goodfellow 2016)

igan

youtube

(zhu et al 2016)

(goodfellow 2016)

introspective adversarial 

networks

youtube

(brock et al 2016)

(goodfellow 2016)

phillip isola

jun-yan zhu

tinghui zhou

alexei a. efros

image to image translation

berkeley ai research (bair) laboratory

university of california, berkeley

{isola,junyanz,tinghuiz,efros}@eecs.berkeley.edu

figure 13: example results of our method on day!night, compared to ground truth.

labels to street scene

input
labels to facade

ground truth

output

bw to color

input

input

aerial to map

output

input

output

day to night

input

output

edges to photo

input

output

input

output

input

output

figure 1: many problems in image processing, graphics, and vision involve translating an input image into a corresponding output image.
these problems are often treated with application-speci   c algorithms, even though the setting is always the same: map pixels to pixels.
conditional adversarial nets are a general-purpose solution that appears to work well on a wide variety of these problems. here we show
results of the method on several. in each case we use the same architecture and objective, and simply train on different data.

figure 14: example results of our method on automatically detected edges!handbags, compared to ground truth.

(isola et al 2016)

(goodfellow 2016)

abstract

may be expressed in either english or french, a scene may

roadmap

    why study generative modeling? 

    how do generative models work? how do gans compare to 

others? 

    how do gans work? 

    tips and tricks 

    research frontiers 

    combining gans with other methods

(goodfellow 2016)

maximum likelihood

brief article

the author

       = arg max

   

ex   pdata log pmodel(x |    )

(goodfellow 2016)

taxonomy of generative models

   

maximum likelihood

direct
gan

explicit density

implicit density

tractable density
-fully visible belief nets 
 -nade 
 -made 
 -pixelid56 
-change of variables 
models (nonlinear ica)

approximate density

markov chain

gsn

variational

markov chain

variational autoencoder

id82

(goodfellow 2016)

the author

maximum likelihood

fully visible belief nets

       = arg max

    explicit formula based on chain 

fully-visible belief net
rule: 
pmodel(x) = pmodel(x1)

   

(frey et al, 1996)

ex   pdata log pmodel(x |    )
nyi=2

pmodel(xi | x1, . . . , xi 1)

    disadvantages: 

    o(n) sample generation cost 

    generation not controlled by a 

latent code

pixelid98 elephants 
(van den ord et al 2016)

(goodfellow 2016)

wavenet

amazing quality 

sample generation slow 

two minutes to synthesize 

one second of audio

(goodfellow 2016)

fully-visible belief net

change of variables

nyi=2

pmodel(x) = pmodel(x1)

change of variables
pmodel(xi | x1, . . . , xi 1)
y = g(x) ) px(x) = py(g(x))    det    @g(x)
@x        

e.g. nonlinear ica (hyv  rinen 1999)
disadvantages: 
- transformation must be 

invertible 

- latent dimension must 
match visible dimension

64x64 id163 samples 
real nvp (dinh et al 2016)

(goodfellow 2016)

nyi=2

change of variables

variational bound

y = g(x) ) px(x) = py(g(x))    det    @g(x)
@x        
variational autoencoder

(kingma and welling 2013, rezende et al 2014)

log p(x)   log p(x)   dkl (q(z)kp(z | x))

zz

xx

=ez   q log p(x, z) + h(q)
disadvantages: 
-not asymptotically 
consistent unless q is 
perfect 
-samples tend to have lower 
quality

cifar-10 samples 
(kingma et al 2016)

(goodfellow 2016)

y = g(x) ) px(x) = py(g(x))    det    @g(x)
@x        
log p(x)   log p(x)   dkl (q(z)kp(z | x))
id82s

=ez   q log p(x, z) + h(q)

id82s

p(x) =

exp ( e(x, z))

1
z

z =xx xz

exp ( e(x, z))

    partition function is intractable 

    may be estimated with markov chain methods 

    generating samples requires markov chains too

(goodfellow 2016)

gans

    use a latent code 

    asymptotically consistent (unlike variational 

methods) 

    no markov chains needed 

    often regarded as producing the best samples 

    no good way to quantify this

(goodfellow 2016)

roadmap

    why study generative modeling? 

    how do generative models work? how do gans compare to 

others? 

    how do gans work? 

    tips and tricks 

    research frontiers 

    combining gans with other methods

(goodfellow 2016)

adversarial nets framework

d(x) tries to be 

near 1

di   erentiable 
function d

d tries to make 
d(g(z)) near 0,
g tries to make 
d(g(z)) near 1

d

x sampled from 

data

x sampled from 

model

di   erentiable 
function g

input noise z

(goodfellow 2016)

exp ( e(x, z))

z =xx xz

generator network

x = g(z;    (g))

zz

xx

-must be di   erentiable 
- no invertibility requirement 
- trainable for any size of z 
- some guarantees require z to have higher 

- can make x conditionally gaussian given z but 

dimension than x 

need not do so

(goodfellow 2016)

training procedure

    use sgd-like algorithm of choice (adam) on two 

minibatches simultaneously: 

    a minibatch of training examples 

    a minibatch of generated samples 

    optional: run k steps of one player for every step of 

the other player.

(goodfellow 2016)

generator equation

z =xx xz

exp ( e(x, z))
minimax game

x = g(z;    (g))

1
2ex   pdata log d(x)  

j (d) =  
j (g) =  j (d)

1
2ez log (1   d (g(z)))

-equilibrium is a saddle point of the discriminator loss 
-resembles jensen-shannon divergence 
-generator minimizes the log-id203 of the discriminator 
being correct

(goodfellow 2016)

generator equation

exp ( e(x, z))

z =xx xz
exercise 1

x = g(z;    (g))

1
2ex   pdata log d(x)  

j (d) =  
j (g) =  j (d)
    what is the solution to d(x) in terms of pdata and 

1
2ez log (1   d (g(z)))

pgenerator? 

    what assumptions are needed to obtain this 

solution?

(goodfellow 2016)

solution

    assume both densities are nonzero everywhere 

    if not, some input values x are never trained, so 
some values of d(x) have undetermined behavior. 

    solve for where the functional derivatives are zero:

 

 d(x)

j (d) = 0

(goodfellow 2016)

p(x) =xh

long as g changes slowly enough. this strategy is analogous to the way that sml/pcd [31, 29]
training maintains samples from a markov chain from one learning step to the next in order to avoid
burning in a markov chain as part of the inner loop of learning. the procedure is formally presented
in algorithm 1.
in practice, equation 1 may not provide suf   cient gradient for g to learn well. early in learning,
when g is poor, d can reject samples with high con   dence because they are clearly different from
the training data. in this case, log(1   d(g(z))) saturates. rather than training g to minimize
log(1   d(g(z))) we can train g to maximize log d(g(z)). this objective function results in the
same    xed point of the dynamics of g and d but provides much stronger gradients early in learning.

discriminator strategy

optimal d(x) for any pdata(x) and pmodel(x) is always

p(x | h)p(h)

pdata(x)

d(x) =

pdata(x) + pmodel(x)

discriminator

estimating this ratio 

using supervised learning is 

the key approximation 
mechanism used by gans

(a)

(b)

data 
model 

distribution

. . .

x

z

1

(c)

(d)

(goodfellow 2016)

j (d) =  
j (g) =  j (d)

1
2ex   pdata log d(x)  

1
2ez log (1   d (g(z)))

non-saturating game

non-saturating

1
2ez log (1   d (g(z)))

1
2ex   pdata log d(x)  
1
2ez log d (g(z))

j (d) =  
j (g) =  
-equilibrium no longer describable with a single loss 
-generator maximizes the log-id203 of the discriminator 
being mistaken 
-heuristically motivated; generator can still learn even when 
discriminator successfully rejects all generator samples

1

(goodfellow 2016)

dcgan architecture

most    deconvs    are batch normalized

(radford et al 2015)

(goodfellow 2016)

dcgans for lsun bedrooms

(radford et al 2015)

(goodfellow 2016)

chapter 15. representation learning

vector space arithmetic

-

+

=

man 

with glasses

man

woman

woman with glasses

figure 15.9: a generative model has learned a distributed representation that disentangles
the concept of gender from the concept of wearing glasses. if we begin with the repre-
sentation of the concept of a man with glasses, then subtract the vector representing the
concept of a man without glasses, and    nally add the vector representing the concept
of a woman without glasses, we obtain the vector representing the concept of a woman
with glasses. the generative model correctly decodes all of these representation vectors to

(radford et al, 2015)

(goodfellow 2016)

is the divergence important?

maximum likelihood

reverse kl

figure 3.6: the kl divergence is asymmetric. suppose we have a distribution p(x) and
wish to approximate it with another distribution q(x). we have the choice of minimizing
either dkl(pkq) or dkl(qkp). we illustrate the e   ect of this choice using a mixture of
two gaussians for p, and a single gaussian for q. the choice of which direction of the

(goodfellow et al 2016)

(goodfellow 2016)

xid203densityq   =argminqdkl(p q)p(x)q   (x)xid203densityq   =argminqdkl(q p)p(x)q   (x)modifying gans to do 
maximum likelihood

the author

maximum likelihood non-saturating

j (d) =  
j (g) =  

1
2ex   pdata log d(x)  
2ez exp   1 (d (g(z))) 
1

1
2ez log (1   d (g(z)))

when discriminator is optimal, the generator 
gradient matches that of maximum likelihood

(   on distinguishability criteria for estimating generative 

models   , goodfellow 2014, pg 5)

(goodfellow 2016)

reducing gans to rl

    generator makes a sample 

    discriminator evaluates a sample 

    generator   s cost (negative reward) is a function of d(g(z)) 

    note that generator   s cost does not include the data, x 

    generator   s cost is always monotonically decreasing in d(g(z)) 

    di   erent divergences change the location of the cost   s fastest 

decrease

(goodfellow 2016)

comparison of generator losses

)
g
(
j

5

0

 5

 10

 15

 20

0.0

minimax
non-saturating heuristic
maximum likelihood cost

0.2

0.4

0.6

0.8

1.0

d(g(z))

(goodfellow 2014)

(goodfellow 2016)

loss does not seem to explain 
why gan samples are sharp

kl

reverse 

kl

(nowozin et al 2016)

kl samples from lsun

takeaway:  the approximation strategy 

matters more than the loss

(goodfellow 2016)

comparison to nce, id113

v (g, d) = epdata log d(x) + epgenerator (log (1   d(x)))

nce 

(gutmann and 
hyv  rinen 2010)

id113

d(x) =

pmodel(x)

pmodel(x) + pgenerator(x)

gan

neural 
network

learn pmodel

learn pgenerator

d

goal

g update rule none (g is 

   xed)

copy pmodel 
parameters

gradient 
descent on v

d update rule

gradient ascent on v

(   on distinguishability criteria      , goodfellow 2014)

(goodfellow 2016)

roadmap

    why study generative modeling? 

    how do generative models work? how do gans compare to 

others? 

    how do gans work? 

    tips and tricks 

    research frontiers 

    combining gans with other methods

(goodfellow 2016)

labels improve subjective 

sample quality

    learning a conditional model p(y|x) often gives much 
better samples from all classes than learning p(x) does 
(denton et al 2015) 

    even just learning p(x,y) makes samples from p(x) look 
much better to a human observer (salimans et al 2016) 

    note: this de   nes three categories of models (no labels, 

trained with labels, generating condition on labels) 
that should not be compared directly to each other

(goodfellow 2016)

one-sided label smoothing

    default discriminator cost: 

cross_id178(1., discriminator(data)) 

+ cross_id178(0., discriminator(samples))

    one-sided label smoothed cost (salimans et al 

2016):

cross_id178(.9, discriminator(data)) 

+ cross_id178(0., discriminator(samples))

(goodfellow 2016)

do not smooth negative labels
cross_id178(1.-alpha, discriminator(data)) 
+ cross_id178(beta, discriminator(samples))

reinforces current generator behavior

d(x) =

(1      )pdata(x) +  pmodel(x)

pdata(x) + pmodel(x)

(goodfellow 2016)

bene   ts of label smoothing

    good regularizer (szegedy et al 2015) 

    does not reduce classi   cation accuracy, only con   dence 

    bene   ts speci   c to gans: 

    prevents discriminator from giving very large 

gradient signal to generator 

    prevents extrapolating to encourage extreme samples

(goodfellow 2016)

batch norm

    given inputs x={x(1), x(2), .., x(m)} 

    compute mean and standard deviation of features of x 

    normalize features (subtract mean, divide by standard deviation) 

    id172 operation is part of the graph 

    id26 computes the gradient through the 

id172 

    this avoids wasting time repeatedly learning to undo the 

id172

(goodfellow 2016)

batch norm in g can cause 
strong intra-batch correlation

(goodfellow 2016)

reference batch norm

    fix a reference batch r={r(1), r(2), .., r(m)} 
    given new inputs x={x(1), x(2), .., x(m)} 

    compute mean and standard deviation of features of r 

    note that though r does not change, the feature values change 

when the parameters change 

    normalize the features of x using the mean and standard deviation 

from r 

    every x(i) is always treated the same, regardless of which other 

examples appear in the minibatch

(goodfellow 2016)

virtual batch norm

    reference batch norm can over   t to the reference batch. a partial solution 

is virtual batch norm 

    fix a reference batch r={r(1), r(2), .., r(m)} 
    given new inputs x={x(1), x(2), .., x(m)} 
    for each x(i) in x: 

    construct a virtual batch v containing both x(i) and all of r 

    compute mean and standard deviation of features of v 
    normalize the features of x(i) using the mean and standard deviation 

from v

(goodfellow 2016)

balancing g and d

    usually the discriminator    wins    

    this is a good thing   the theoretical justi   cations are based on 

assuming d is perfect 

    usually d is bigger and deeper than g 

    sometimes run d more often than g. mixed results. 

    do not try to limit d to avoid making it    too smart    

    use non-saturating cost 

    use label smoothing

(goodfellow 2016)

roadmap

    why study generative modeling? 

    how do generative models work? how do gans compare to 

others? 

    how do gans work? 

    tips and tricks 

    research frontiers 

    combining gans with other methods

(goodfellow 2016)

non-convergence

    optimization algorithms often approach a saddle 

point or local minimum rather than a global 
minimum 

    game solving algorithms may not approach an 

equilibrium at all

(goodfellow 2016)

exercise 2

    for scalar x and y, consider the value function: 

    does this game have an equilibrium? where is it? 

v (x, y) = xy

    consider the learning dynamics of simultaneous 
id119 with in   nitesimal learning rate 
(continuous time). solve for the trajectory followed 
by these dynamics.

@x
@t
@y
@t

@
=  
@x
@
=
@y

v (x(t), y(t))

v (x(t), y(t))

(goodfellow 2016)

solution

this is the canonical example of 
a saddle point. 

there is an equilibrium, at 
x = 0, y = 0.

(goodfellow 2016)

solution

    the gradient dynamics are: 

@x
@t
@y
@t

=  y(t)
= x(t)

    di   erentiating the second equation, we obtain: 

@2y
@t2 =

@x
@t

=  y(t)

    we recognize that y(t) must be a sinusoid

(goodfellow 2016)

solution

    the dynamics are a circular orbit:

x(t) = x(0) cos(t)   y(0) sin(t)
y(t) = x(0) sin(t) + y(0) cos(t)

discrete time 
id119 

can spiral 

outward for large 

step sizes

(goodfellow 2016)

non-convergence in gans

    exploiting convexity in function space, gan training is theoretically 

guaranteed to converge if we can modify the density functions directly, 
but: 

    instead, we modify g (sample generation function) and d (density 

ratio), not densities 

    we represent g and d as highly non-convex parametric functions 

       oscillation   : can train for a very long time, generating very many 

di   erent categories of samples, without clearly generating better samples 

    mode collapse: most severe form of non-convergence

(goodfellow 2016)

mode collapse

min
g

max

d

v (g, d) 6= max

d

min
g

v (g, d)

    d in inner loop: convergence to correct distribution 

under review as a conference paper at iclr 2017

    g in inner loop: place all mass on most likely point

figure 1: unrolling the discriminator stabilizes gan training on a toy 2d mixture of gaussians
dataset. columns show a heatmap of the generator distribution after increasing numbers of training
steps. the    nal column shows the data distribution. the top row shows training for a gan with
(metz et al 2016)
10 unrolling steps. its generator quickly spreads out and converges to the target distribution. the
bottom row shows standard gan training. the generator rotates through the modes of the data

figure 1: unrolling the discriminator stabilizes gan training on a toy 2d mixture of gaussians

(goodfellow 2016)

reverse kl loss does not 
explain mode collapse

    other gan losses also yield mode collapse 

    reverse kl loss prefers to    t as many modes as the 
model can represent and no more; it does not prefer 
fewer modes in general  

    gans often seem to collapse to far fewer modes 

than the model can represent

(goodfellow 2016)

generative adversarial text to image synthesis

scott reed, zeynep akata, xinchen yan, lajanugen logeswaran

2 max planck institute for informatics, saarbr  ucken, germany (mpi-inf.mpg.de)

mode collapse causes low 

reedscot1, akata2, xcyan1, llajan1
schiele2,honglak1

output diversity

figure 1. examples of generated images from text descriptions.
left: captions are from zero-shot (held out) categories, unseen
text. right: captions are from the training set.

(reed et al 2016)

properties of attribute representations are attractive, at-
tributes are also cumbersome to obtain as they may require
domain-speci   c knowledge.
in comparison, natural lan-
guage offers a general and    exible interface for describing

(reed et al, submitted to 

iclr 2017)

(goodfellow 2016)

this small bird has a pink breast and crown, and black primaries and secondaries.the flower has petals that are bright pinkish purple with white stigmathis magnificent fellow is almost all black with a red crest, and white cheek patch.this white and yellow flower have thin white petals and a round yellow stamenminibatch features

    add minibatch features that classify each example 
by comparing it to other members of the minibatch 
(salimans et al 2016) 

    nearest-neighbor style features detect if a minibatch 

contains samples that are too similar to each other

(goodfellow 2016)

minibatch gan on cifar

training data

samples

(salimans et al 2016)

(goodfellow 2016)

minibatch gan on id163

(salimans et al 2016)

(goodfellow 2016)

cherry-picked results

(goodfellow 2016)

problems with counting

(goodfellow 2016)

problems with perspective

(goodfellow 2016)

problems with global 

structure

(goodfellow 2016)

this one is real

(goodfellow 2016)

unrolled gans

under review as a conference paper at iclr 2017

under review as a conference paper at iclr 2017

    backprop through k updates of the discriminator to 

prevent mode collapse:

(metz et al 2016)

figure 1: unrolling the discriminator stabilizes gan training on a toy 2d mixture of gaussians
dataset. columns show a heatmap of the generator distribution after increasing numbers of training
steps. the    nal column shows the data distribution. the top row shows training for a gan with
10 unrolling steps. its generator quickly spreads out and converges to the target distribution. the
figure 1: unrolling the discriminator stabilizes gan training on a toy 2d mixture of gaussians
bottom row shows standard gan training. the generator rotates through the modes of the data
dataset. columns show a heatmap of the generator distribution after increasing numbers of training
distribution. it never converges to a    xed distribution, and only ever assigns signi   cant mass to a
steps. the    nal column shows the data distribution. the top row shows training for a gan with
single data mode at once.
10 unrolling steps. its generator quickly spreads out and converges to the target distribution. the

(goodfellow 2016)

evaluation

    there is not any single compelling way to evaluate a generative 

model 

    models with good likelihood can produce bad samples 

    models with good samples can have bad likelihood 

    there is not a good way to quantify how good samples are 

    for gans, it is also hard to even estimate the likelihood 

    see    a note on the evaluation of generative models,    theis et al 

2015, for a good overview

(goodfellow 2016)

discrete outputs

    g must be di   erentiable 

    cannot be di   erentiable if output is discrete 

    possible workarounds: 

    reinforce (williams 1992) 

    concrete distribution (maddison et al 2016) or gumbel-

softmax (jang et al 2016) 

    learn distribution over continuous embeddings, decode to 

discrete

(goodfellow 2016)

supervised discriminator

real

fake

real cat

real 
dog

fake

hidden 
units

input

hidden 
units

input

(odena 2016, salimans et al 2016)

(goodfellow 2016)

(left fig. 3). by using minibatch discrimination
instead (section 3.2) we can improve their visual quality. on mturk, annotators were able to dis-
tinguish samples in 52.4% of cases (2000 votes total), where 50% would be obtained by random
guessing. similarly, researchers in our institution were not able to    nd any artifacts that would al-
low them to distinguish samples. however, semi-supervised learning with minibatch discrimination
does not produce as good a classi   er as does feature matching.

semi-supervised classi   cation 

mnist (permutation invariant)

model

number of incorrectly predicted test examples

dgn [21]

virtual adversarial [22]

catgan [14]

skip deep generative model [23]

ladder network [24]

auxiliary deep generative model [23]

our model

ensemble of 10 of our models

for a given number of labeled samples

20

50

1677    452
1134    445

221    136
142    96

100

212

333    14
191    10
132    7
106    37
96    2
93    6.5
86    5.6

200

90    4.2
81    4.3

table 1: number of incorrectly classi   ed test examples for the semi-supervised setting on permuta-
tion invariant mnist. results are averaged over 10 seeds.

6.2 cifar-10

model

(salimans et al 2016)

test error rate for

(goodfellow 2016)

ladder network [24]

auxiliary deep generative model [23]

our model

ensemble of 10 of our models

table 1: number of incorrectly classi   ed test examples for the semi-supervised setting on permuta-
tion invariant mnist. results are averaged over 10 seeds.

semi-supervised classi   cation 

1677    452
1134    445

221    136
142    96

90    4.2
81    4.3

132    7
106    37
96    2
93    6.5
86    5.6

6.2 cifar-10

cifar-10

model

test error rate for

a given number of labeled samples

2000

4000

8000

1000

ladder network [24]

catgan [14]
our model

ensemble of 10 of our models

21.83  2.01
19.22  0.54

19.61  2.09
17.25  0.66

20.40  0.47
19.58  0.46
18.63  2.32
15.59  0.47

17.72  1.82
14.87  0.89
svhn

table 2: test error on semi-supervised cifar-10. results are averaged over 10 splits of data.

cifar-10 is a small, well studied dataset of 32     32 natural images. we use this data set to study
semi-supervised learning, as well as to examine the visual quality of samples that can be achieved.
for the discriminator in our gan we use a 9 layer deep convolutional network with dropout and
weight id172. the generator is a 4 layer deep id98 with batch id172. table 2
summarizes our results on the semi-supervised learning task.
our model

auxiliary deep generative model [23]

skip deep generative model [23]

virtual adversarial [22]

36.02  0.10

24.63
22.86

dgn [21]

1000

500

percentage of incorrectly predicted test examples

for a given number of labeled samples

2000

model

18.44    4.8

6.16    0.58

16.61  0.24
8.11    1.3
5.88    1.0

378
379
380
381
382
383
384
385
386

ensemble of 10 of our models

6
(salimans et al 2016)
figure 5: (left) error rate on svhn. (right) samples from the generator for svhn.

(goodfellow 2016)

learning interpretable latent codes / 
controlling the generation process

infogan (chen et al 2016)

(goodfellow 2016)

rl connections

    gans interpreted as actor-critic (pfau and vinyals 

2016) 

    gans as inverse id23 (finn et al 

2016) 

    gans for imitation learning (ho and ermon 2016)

(goodfellow 2016)

finding equilibria in games

    simultaneous sgd on two players costs may not 

converge to a nash equilibrium 

    in    nite spaces,    ctitious play provides a better 

algorithm 

    what to do in continuous spaces? 

    unrolling is an expensive solution; is there a 

cheap one?

(goodfellow 2016)

other games in ai

    board games (checkers, chess, go, etc.) 

    robust optimization / robust control 

    for security/safety, e.g. resisting adversarial examples 

    domain-adversarial learning for id20 

    adversarial privacy 

    guided cost learning 

       

(goodfellow 2016)

exercise 3

    in this exercise, we will derive the maximum likelihood cost for 

gans. 

    we want to solve for f(x), a cost function to be applied to every 

sample from the generator: 

    show the following:  

j (g) = ex   pg f (x)

@
@   

j (g) = ex   pg f (x)

@
@   

log pg(x)

    what should f(x) be?

(goodfellow 2016)

solution
j (g) = ex   pg f (x)

@
@   

@
@   

log pg(x)

    to show that 

    expand the expectation to an integral 

    assume that leibniz   s rule may be used 

@

@   z pg(x)f (x)dx

@
@    ex   pg f (x) =
z f (x)

@
@   
    use the identity

pg(x)dx

@
@   

pg(x) = pg(x)

@
@   

log pg(x)

(goodfellow 2016)

solution
j (g) = ex   pg f (x)

@
@   

@
@   

log pg(x)

    we now know  

    the kl gradient is 

 ex   pdata

@
@   

log pg(x)

    we can do an importance sampling trick 

f (x) =  

pdata(x)
pg(x)

    note that we must copy the density pg or the 

derivatives will double-count

(goodfellow 2016)

solution

    we want 

f (x) =  

pdata(x)
pg(x)

    we know that  

d(x) =  (a(x)) =

    by algebra

f (x) =   exp(a(x))

pdata(x)

pdata(x) + pg(x)

(goodfellow 2016)

roadmap

    why study generative modeling? 

    how do generative models work? how do gans 

compare to others? 

    how do gans work? 

    tips and tricks 

    combining gans with other methods

(goodfellow 2016)

plug and play generative 

models

    new state of the art generative model (nguyen et al 

2016) released days before nips 

    generates 227x227 realistic images from all 

id163 classes 

    combines adversarial training, moment matching, 

denoising autoencoders, and langevin sampling

(goodfellow 2016)

university of wyoming
anh.ng8@gmail.com

geometric intelligence

montreal institute for learning algorithms

jason@geometric.ai

yoshua.umontreal@gmail.com

alexey dosovitskiy
university of freiburg

dosovits@cs.uni-freiburg.de

jeff clune

ppgn samples

jeffclune@uwyo.edu

university of wyoming

abstract

generating high-resolution, photo-realistic images has
been a long-standing goal in machine learning. recently,
nguyen et al. [36] showed one interesting way to synthesize
novel images by performing gradient ascent in the latent
space of a generator network to maximize the activations
of one or multiple neurons in a separate classi   er network.
in this paper we extend this method by introducing an addi-
tional prior on the latent code, improving both sample qual-
ity and sample diversity, leading to a state-of-the-art gen-
erative model that produces high quality images at higher
resolutions (227     227) than previous generative models,
and does so for all 1000 id163 categories. in addition,
we provide a uni   ed probabilistic interpretation of related
activation maximization methods and call the general class
of models    plug and play generative networks.    ppgns
are composed of 1) a generator network g that is capable
of drawing a wide range of image types and 2) a replace-
able    condition    network c that tells the generator what
to draw. we demonstrate the generation of images condi-
tioned on a class (when c is an id163 or mit places
classi   cation network) and also conditioned on a caption
(when c is an image captioning network). our method also
improves the state of the art of multifaceted feature visual-

(nguyen et al 2016)

figure 1: images synthetically generated by plug and play
generative networks at high-resolution (227x227) for four
id163 classes. not only are many images nearly photo-

(goodfellow 2016)

ppgn for caption to image

(nguyen et al 2016)

figure 5: images synthesized to match a user description.
a ppgn containing the image captioning model from [8]

(goodfellow 2016)

basic idea

    langevin sampling repeatedly adds noise and 

gradient of log p(x,y) to generate samples (markov 
chain) 

    denoising autoencoders estimate the required 

gradient 

    use a special denoising autoencoder that has been 
trained with multiple losses, including a gan loss, 
to obtain best results

(goodfellow 2016)

sampling without class 

gradient

(nguyen et al 2016)

(goodfellow 2016)

gan loss is a key ingredient

(a) real images

(b) joint ppgn-h (limg + lh1 + lh + lgan )

(a) real images

(b) joint ppgn-h (limg + lh1 + lh + lgan )

(c) lgan removed (limg + lh1 + lh)

reconstruction 

by ppgn

raw data

reconstruction 

by ppgn 
without gan

images from nguyen et al 2016 

first observed by dosovitskiy et al 2016

(goodfellow 2016)

conclusion

    gans are generative models that use supervised learning to 

approximate an intractable cost function 

    gans can simulate many cost functions, including the one 

used for maximum likelihood 

    finding nash equilibria in high-dimensional, continuous, non-

convex games is an important open research problem 

    gans are a key ingredient of ppgns, which are able to 
generate compelling high resolution samples from diverse 
image classes

(goodfellow 2016)

