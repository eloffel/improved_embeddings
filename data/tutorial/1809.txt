scien-   c	compu-ng	with	python	
aus-n,	texas	   	july	11-17,	2016	

machine	learning		
	
				

with	

scikit

sebastian raschka & andreas mueller!

links!

tutorial material on github:!

https://github.com/amueller/scipy-2016-sklearn!

contact info:!

sebastian raschka!
      mail@sebastianraschka.com!
      http://sebastianraschka.com!
      @rasbt!

andreas mueller!
      t3kcit+website@gmail.com!
      http://amueller.github.io!
      @amuellerml!

sebastian raschka & andreas mueller!

2!

tutorial setup i!

a) fork the repository (if you haven   t done so, yet):!

b) sync an older fork:!

$ git remote add upstream https://github.com/amueller/scipy-2016-sklearn.git 
$ git fetch upstream 
$ git checkout master merge upstream/master 

sebastian raschka & andreas mueller!

3!

tutorial setup ii!

jupyter notebook check_env.ipynb 

python fetch_data.py    ~456	mb!!!	

sebastian raschka & andreas mueller!

4!

our agenda!

     morning session: 8:00 am - 12:00 pm (room 

105)!

     afternoon session: 1:30 pm - 5:30 pm (room 

105)!

sebastian raschka & andreas mueller!

5!

morning session!

8:00	am	-	12:00	pm	

01 introduction to machine learning with sample applications!
02 scienti   c computing tools for python: numpy, scipy, and matplotlib!
03 data formats, preparation, and representation!
04 supervised learning: training and test data!
05 supervised learning: estimators for classi   cation!
06 supervised learning: estimators for regression analysis!
07 unsupervised learning: unsupervised transformers!
08 unsupervised learning: id91!
09 the scikit-learn estimator interface!
10 preparing a real-world dataset (titanic)!
11 working with text data via the bag-of-words model!
12 application: sms spam classi   cation!

sebastian raschka & andreas mueller!

6!

afternoon session! 1:30	pm	-	5:30	pm		

13 cross-validation!
14 model complexity and grid search for adjusting hyperparameters!
15 scikit-learn pipelines!
16 supervised learning: performance metrics for classi   cation!
17 supervised learning: linear models!
18 supervised learning: support vector machines!
19 supervised learning: id90 and id79s, ensemble methods!
20 supervised learning: feature selection!
21 unsupervised learning: hierarchical and density-based id91 algorithms!
22 unsupervised learning: non-linear id84!
23 supervised learning: out-of-core learning!

sebastian raschka & andreas mueller!

7!

morning session!

8:00	am	-	12:00	pm	

01 introduction to machine learning with sample applications
02 scienti   c computing tools for python: numpy, scipy, and matplotlib!
03 data formats, preparation, and representation!
04 supervised learning: training and test data!
05 supervised learning: estimators for classi   cation!
06 supervised learning: estimators for regression analysis!
07 unsupervised learning: unsupervised transformers!
08 unsupervised learning: id91!
09 the scikit-learn estimator interface!
10 preparing a real-world dataset (titanic)!
11 working with text data via the bag-of-words model!
12 application: sms spam classi   cation!

sebastian raschka & andreas mueller!

s!

8!

what is machine learning?!

inputs 

(observations)!

   traditional    programming!

programmer!

program!

computer!

outputs!

machine learning is the    eld of study that gives computers the ability to 
learn without being explicitly programmed.!
-- arthur samuel (1959)!

inputs 

(observations)!

outputs!

machine learning!

computer!

program!

sebastian raschka & andreas mueller!

9!

examples of machine learning!

hjps://   ic.kr/p/5blw6g	[cc	by	2.0]	

hjp://commons.wikimedia.org/wiki/
file:american_book_company_1916._lejer_envelope-2.jpg#
   lelinks	[public	domain]		

hjp://commons.wikimedia.org/wiki/
file:nexlix_logo.svg	[public	domain]	

and many, many more    !

by	steve	jurvetson	[cc	by	2.0]	

sebastian raschka & andreas mueller!

10!

3 types of learning!

supervised!

unsupervised!

reinforcement!

      learning from 
labeled data!
      e.g., spam 
classi   cation!

      discover structure in 
unlabeled data!
      e.g., document 

id91!

      learning by    doing    with 
      e.g., chess computer!

delayed reward!

sebastian raschka & andreas mueller!

11!

supervised learning!

supervised!

classi   cation!

regression!

?!

y=12.5!

?!

x=0.8!

sebastian raschka & andreas mueller!

12!

unsupervised learning!

unsupervised!

id91!

compression!

sebastian raschka & andreas mueller!

13!

flower classi   cation!

iris-setosa!

iris-versicolor!

iris-setosa!

sebastian raschka & andreas mueller!

14!

data representation!

instances (samples, observations)

iris

https://archive.ics.uci.edu/ml/datasets/iris

sepal_length
5.1
4.9
   
6.4
   
5.9

1
2
   
50
   
150

sepal_width
3.5
3.0
   
3.2
   
3.0

petal_length
1.4
1.4
   
4.5
   
5.1

petal_width
0.2
0.2
   
1.5
   
1.8

class
setosa
setosa
   
veriscolor
   
virginica

features (attributes, dimensions)

classes (targets)

sebastian raschka & andreas mueller!

15!

morning session!

8:00	am	-	12:00	pm	

01 introduction to machine learning with sample applications!
02 scienti   c computing tools for python: numpy, scipy, and matplotlib
03 data formats, preparation, and representation!
04 supervised learning: training and test data!
05 supervised learning: estimators for classi   cation!
06 supervised learning: estimators for regression analysis!
07 unsupervised learning: unsupervised transformers!
08 unsupervised learning: id91!
09 the scikit-learn estimator interface!
10 preparing a real-world dataset (titanic)!
11 working with text data via the bag-of-words model!
12 application: sms spam classi   cation!

sebastian raschka & andreas mueller!

s!

16!

!
jupyter notebooks!

sebastian raschka & andreas mueller!

17!

numpy arrays!

contiguous data buffer of values!

      build around a c array with pointers to a 
      id202 functions!
      fancy indexing!
         !

>>>	import	numpy	
>>>	ary	=	numpy.array([7,	8,	9,	10,	11])	
>>>	ary[[2,	4]]	
array([	9,	11])	
>>>	lst	=	list([7,	8,	9,	10,	11])	
>>>	lst[2,	4]]	
>>>	lst[[2,	4]]	
traceback	(most	recent	call	last):	
		file	"<stdin>",	line	1,	in	<module>	
typeerror:	list	indices	must	be		
integers	or	slices,	not	list	

image	source:	   why	python	is	slow:	looking	under	the	hood   	by	jake	vanderplas	
hjp://jakevdp.github.io/blog/2014/05/09/why-python-is-slow/	

sebastian raschka & andreas mueller!

18!

scipy sparse matrices!

list of lists (lil) example!

>>> from scipy import sparse 
>>> mtx = sparse.lil_matrix([[0, 1, 2, 0],  
...                          [3, 0, 1, 0],  
...                          [1, 0, 0, 1]]) 
>>> print(mtx) 
  (0, 1)  1 
  (0, 2)  2 
  (1, 0)  3 
  (1, 2)  1 
  (2, 0)  1 
  (2, 3)  1 
>>> print(mtx.toarray())  
[[0 1 2 0] 
 [3 0 1 0] 
 [1 0 0 1]] 

sebastian raschka & andreas mueller!

19!

matplotlib!

>>> import matplotlib.pyplot as plt 
>>> import numpy as np 
>>> 
>>> mu, sigma = 200, 25 
>>> x = mu + sigma*np.random.randn(10000) 
>>> plt.hist(x, 20, normed=1,  
...         histtype='stepfilled',  
...         facecolor='b',  
...         alpha=0.75) 
>>> plt.show() 

sebastian raschka & andreas mueller!

20!

morning session!

8:00	am	-	12:00	pm	

01 introduction to machine learning with sample applications!
02 scienti   c computing tools for python: numpy, scipy, and matplotlib!
03 data formats, preparation, and representation
04 supervised learning: training and test data!
05 supervised learning: estimators for classi   cation!
06 supervised learning: estimators for regression analysis!
07 unsupervised learning: unsupervised transformers!
08 unsupervised learning: id91!
09 the scikit-learn estimator interface!
10 preparing a real-world dataset (titanic)!
11 working with text data via the bag-of-words model!
12 application: sms spam classi   cation!

sebastian raschka & andreas mueller!

s!

21!

iris-setosa!

iris!

iris-versicolor!

iris-setosa!

sebastian raschka & andreas mueller!

22!

digits!

sebastian raschka & andreas mueller!

23!

generating synthetic data!

from sklearn.datasets import make_    

sebastian raschka & andreas mueller!

24!

morning session!

8:00	am	-	12:00	pm	

01 introduction to machine learning with sample applications!
02 scienti   c computing tools for python: numpy, scipy, and matplotlib!
03 data formats, preparation, and representation!
04 supervised learning: training and test data
05 supervised learning: estimators for classi   cation!
06 supervised learning: estimators for regression analysis!
07 unsupervised learning: unsupervised transformers!
08 unsupervised learning: id91!
09 the scikit-learn estimator interface!
10 preparing a real-world dataset (titanic)!
11 working with text data via the bag-of-words model!
12 application: sms spam classi   cation!

sebastian raschka & andreas mueller!

a!

25!

training & test data!

all data!

training data!

typically:!
      75% : 25%!
      2/3 : 1/3!

test data!

sebastian raschka & andreas mueller!

26!

strati   cation!

non-strati   ed split:!

     
     

training set     38 x setosa, 28 x versicolor, 34 x virginica!
test set     12 x setosa, 22 x versicolor, 16 x virginica!

sebastian raschka & andreas mueller!

27!

k-nearest neighbors!

k=5!

image source: https://github.com/rasbt/python-machine-learning-
book/blob/master/code/ch03/images/03_20.png!

sebastian raschka & andreas mueller!

28!

morning session!

8:00	am	-	12:00	pm	

01 introduction to machine learning with sample applications!
02 scienti   c computing tools for python: numpy, scipy, and matplotlib!
03 data formats, preparation, and representation!
04 supervised learning: training and test data!
05 supervised learning: estimators for classi   cation
06 supervised learning: estimators for regression analysis!
07 unsupervised learning: unsupervised transformers!
08 unsupervised learning: id91!
09 the scikit-learn estimator interface!
10 preparing a real-world dataset (titanic)!
11 working with text data via the bag-of-words model!
12 application: sms spam classi   cation!

sebastian raschka & andreas mueller!

a!

29!

supervised work   ow!

training data

training labels

model

training

training!

test data

prediction

test labels

evaluation

generalization!

generalization

      fit model on all data after 

evaluation!

sebastian raschka & andreas mueller!

30!

supervised work   ow!

estimator.fit(x_train, y_train) 

training data

training labels

model

training

training!

estimator.predict(x_test) 

test data

prediction

test labels

evaluation

generalization

generalization!

estimator.score(x_test, y_test) 

sebastian raschka & andreas mueller!

31!

morning session!

8:00	am	-	12:00	pm	

01 introduction to machine learning with sample applications!
02 scienti   c computing tools for python: numpy, scipy, and matplotlib!
03 data formats, preparation, and representation!
04 supervised learning: training and test data!
05 supervised learning: estimators for classi   cation!
06 supervised learning: estimators for regression analysis
07 unsupervised learning: unsupervised transformers!
08 unsupervised learning: id91!
09 the scikit-learn estimator interface!
10 preparing a real-world dataset (titanic)!
11 working with text data via the bag-of-words model!
12 application: sms spam classi   cation!

sebastian raschka & andreas mueller!

a!

32!

id75!

y =coef_[0]*x[0] + intercept_   

	

)
e
l
b
a
i
r
a
v
 
t
e
g
r
a
t
(
 
y

x[0] (feature variable)	

sebastian raschka & andreas mueller!

33!

morning session!

8:00	am	-	12:00	pm	

01 introduction to machine learning with sample applications!
02 scienti   c computing tools for python: numpy, scipy, and matplotlib!
03 data formats, preparation, and representation!
04 supervised learning: training and test data!
05 supervised learning: estimators for classi   cation!
06 supervised learning: estimators for regression analysis!
07 unsupervised learning: unsupervised transformers
08 unsupervised learning: id91!
09 the scikit-learn estimator interface!
10 preparing a real-world dataset (titanic)!
11 working with text data via the bag-of-words model!
12 application: sms spam classi   cation!

sebastian raschka & andreas mueller!

s!

34!

unsupervised transformers!

training data

model

test data

new view

       transformer.fit(x_train) 
       x_train_transf = transformer.transform(x_train) 
       x_test_transf  = transformer.transform(x_test) 
 

sebastian raschka & andreas mueller!

35!

feature scaling!

standardization!

min-max scaling!
(   id172   )!

sebastian raschka & andreas mueller!

36!

principal component analysis!

pc1!

pc2!

x2!

x1!

sebastian raschka & andreas mueller!

37!

pca for id84!

sebastian raschka & andreas mueller!

38!

morning session!

8:00	am	-	12:00	pm	

01 introduction to machine learning with sample applications!
02 scienti   c computing tools for python: numpy, scipy, and matplotlib!
03 data formats, preparation, and representation!
04 supervised learning: training and test data!
05 supervised learning: estimators for classi   cation!
06 supervised learning: estimators for regression analysis!
07 unsupervised learning: unsupervised transformers!
08 unsupervised learning: id91
09 the scikit-learn estimator interface!
10 preparing a real-world dataset (titanic)!
11 working with text data via the bag-of-words model!
12 application: sms spam classi   cation!

sebastian raschka & andreas mueller!

s!

39!

id116 id91!

sebastian raschka & andreas mueller!

40!

id116 id91!

sebastian raschka & andreas mueller!

41!

morning session!

8:00	am	-	12:00	pm	

01 introduction to machine learning with sample applications!
02 scienti   c computing tools for python: numpy, scipy, and matplotlib!
03 data formats, preparation, and representation!
04 supervised learning: training and test data!
05 supervised learning: estimators for classi   cation!
06 supervised learning: estimators for regression analysis!
07 unsupervised learning: unsupervised transformers!
08 unsupervised learning: id91!
09 the scikit-learn estimator interface
10 preparing a real-world dataset (titanic)!
11 working with text data via the bag-of-words model!
12 application: sms spam classi   cation!

sebastian raschka & andreas mueller!

a!

42!

scikit-learn api!

sebastian raschka & andreas mueller!

43!

morning session!

8:00	am	-	12:00	pm	

01 introduction to machine learning with sample applications!
02 scienti   c computing tools for python: numpy, scipy, and matplotlib!
03 data formats, preparation, and representation!
04 supervised learning: training and test data!
05 supervised learning: estimators for classi   cation!
06 supervised learning: estimators for regression analysis!
07 unsupervised learning: unsupervised transformers!
08 unsupervised learning: id91!
09 the scikit-learn estimator interface!
10 preparing a real-world dataset (titanic)
11 working with text data via the bag-of-words model!
12 application: sms spam classi   cation!

sebastian raschka & andreas mueller!

a!

44!

continuous & categorical features!

con-nuous	

e.g., sepal width in cm!

[3.4, 4.7    ]!

categorical	

nominal	

ordinal	

e.g., colors!

[red, green, blue,    ]!

e.g., ratings!

[satis   ed, neutral, unsatis   ed]!

sebastian raschka & andreas mueller!

45!

case study - titanic survival!

sebastian raschka & andreas mueller!

46!

morning session!

8:00	am	-	12:00	pm	

01 introduction to machine learning with sample applications!
02 scienti   c computing tools for python: numpy, scipy, and matplotlib!
03 data formats, preparation, and representation!
04 supervised learning: training and test data!
05 supervised learning: estimators for classi   cation!
06 supervised learning: estimators for regression analysis!
07 unsupervised learning: unsupervised transformers!
08 unsupervised learning: id91!
09 the scikit-learn estimator interface!
10 preparing a real-world dataset (titanic)!
11 working with text data via the bag-of-words model
12 application: sms spam classi   cation!

sebastian raschka & andreas mueller!

a!

47!

bag of words!

    d1:    each state has its own laws.   !
    d2:    every country has its own culture.   !

v ={each:1, state:1, has:2, its:2, own:2, !
       laws: 1, every: 1, country: 1, culture: 1} !

sebastian raschka & andreas mueller!

48!

!
!
morning session!

8:00	am	-	12:00	pm	

01 introduction to machine learning with sample applications!
02 scienti   c computing tools for python: numpy, scipy, and matplotlib!
03 data formats, preparation, and representation!
04 supervised learning: training and test data!
05 supervised learning: estimators for classi   cation!
06 supervised learning: estimators for regression analysis!
07 unsupervised learning: unsupervised transformers!
08 unsupervised learning: id91!
09 the scikit-learn estimator interface!
10 preparing a real-world dataset (titanic)!
11 working with text data via the bag-of-words model!
12 application: sms spam classi   cation

sebastian raschka & andreas mueller!

a!

49!

preprocessing & classi   cation  overview!

sebastian raschka & andreas mueller!

50!

afternoon session! 1:30	pm	-	5:30	pm		

13 cross-validation
14 model complexity and grid search for adjusting hyperparameters!
15 scikit-learn pipelines!
16 supervised learning: performance metrics for classi   cation!
17 supervised learning: linear models!
18 supervised learning: support vector machines!
19 supervised learning: id90 and id79s, ensemble methods!
20 supervised learning: feature selection!
21 unsupervised learning: hierarchical and density-based id91 algorithms!
22 unsupervised learning: non-linear id84!
23 supervised learning: out-of-core learning!

sebastian raschka & andreas mueller!

s!

51!

holdout evaluation i!

data

labels

training data

training labels

test data

test labels

training data

training labels

hyperparameter 

values
learning 
algorithm

model

test data

sebastian raschka & andreas mueller!

52!

prediction

1

2

3

2

3

4

training labels

holdout evaluation ii!

learning 
algorithm

test data

model

prediction

test labels

performance

data

labels

hyperparameter 

values
learning 
algorithm

final 
model

this work by sebastian raschka is licensed under a 
creative commons attribution 4.0 international license.

sebastian raschka & andreas mueller!

53!

holdout validation i!

data

labels

training data

training labels

validation  

data

validation  
labels

test  
data
test  
labels

hyperparameter  

values

training data

training labels

hyperparameter  

values

learning  
algorithm

hyperparameter  

values

model

model

model

1

2

validation  

data

sebastian raschka & andreas mueller!

prediction

54!

model

validation  

performance

holdout validation ii!

hyperparameter  

model

values

validation  

data

model

validation  

data

model

validation  

data

model

prediction

validation  
labels

prediction

validation  
labels

prediction

validation  
labels

training data

training labels

validation  

data

validation  
labels

3

4

performance

hyperparameter  

best 

values

performance

best 
model

performance

best  

hyperparameter  

values
learning  
algorithm

model

sebastian raschka & andreas mueller!

55!

holdout validation iii!

5

6

test data

model

prediction

test labels

performance

best  

hyperparameter  

values
learning  
algorithm

final 
model

data

labels

this work by sebastian raschka is licensed under a  
creative commons attribution 4.0 international license. 

sebastian raschka & andreas mueller!

56!

k-fold cross-validation!

validation  

fold

training  

fold

performance

1

performance

2

performance

3

performance

4

performance

5

performance  
10    10
=

1 

i=1

performancei

validation  
fold data

model

prediction

validation  
fold labels

performance

l

)
s
d
o
f
-
k

(
 
s
n
o

i
t

a
r
e

t
i
 

k

1st

2nd

3rd

4th

5th

training fold data

training fold labels

 hyperparameter  

values
learning  
algorithm

model

this work by sebastian raschka is licensed under a  
creative commons attribution 4.0 international license. 

sebastian raschka & andreas mueller!

57!

k-fold cross-validation pipeline i!

1

2

3

data

labels

training data

training labels

test data

test labels

hyperparameter  

values

training data

training labels

hyperparameter  

values

learning  
algorithm

hyperparameter  

values

model

model

model

sebastian raschka & andreas mueller!

hyperparameter  

58!

best  

values
learning  

model

training data

training labels

k-fold cross-validation pipeline ii!

hyperparameter  

model

values

3

4

5

training data

training labels

best  

hyperparameter  

values
learning  
algorithm

test data

model

prediction

test labels

performance

data

labels

best  

hyperparameter  

values
learning  
algorithm

model

final 
model

sebastian raschka & andreas mueller!

59!

this work by sebastian raschka is licensed under a  
creative commons attribution 4.0 international license. 

nested cv!

outer  

validation fold

outer 

training fold

1st

2nd

3rd

4th

5th

p
o
o
l
 
r
e
t
u
o

performance

1

performance

2

performance

3

performance

4

performance

5

best  
learning 
algorithm

performance  
10    10
=

1 

i=1

performancei

p
o
o
l

 
r
e
n
n

i

performance

5,1

performance

5, 2

inner 

training fold

inner 

validation fold

this work by sebastian raschka is licensed under a  
creative commons attribution 4.0 international license. 

performance  

1 

2     2

j=1

performance5,j

hyperparameter  

best  

values

sebastian raschka & andreas mueller!

60!

afternoon session! 1:30	pm	-	5:30	pm		

13 cross-validation!
14 model complexity and grid search for adjusting hyperparameters
15 scikit-learn pipelines!
16 supervised learning: performance metrics for classi   cation!
17 supervised learning: linear models!
18 supervised learning: support vector machines!
19 supervised learning: id90 and id79s, ensemble methods!
20 supervised learning: feature selection!
21 unsupervised learning: hierarchical and density-based id91 algorithms!
22 unsupervised learning: non-linear id84!
23 supervised learning: out-of-core learning!

sebastian raschka & andreas mueller!

s!

61!

learning curves!

image	source:	hjps://github.com/rasbt/python-machine-
learning-book/blob/master/code/ch06/images/06_04.png	

sebastian raschka & andreas mueller!

62!

model complexity!

sebastian raschka & andreas mueller!

63!

t

r
e
e
m
a
r
a
p
c

 

grid search!

gamma parameter!

source:	hjp://scikit-learn.org/stable/auto_examples/id166/plot_rbf_parameters.html	

sebastian raschka & andreas mueller!

64!

!
afternoon session! 1:30	pm	-	5:30	pm		

13 cross-validation!
14 model complexity and grid search for adjusting hyperparameters!
15 scikit-learn pipelines
16 supervised learning: performance metrics for classi   cation!
17 supervised learning: linear models!
18 supervised learning: support vector machines!
19 supervised learning: id90 and id79s, ensemble methods!
20 supervised learning: feature selection!
21 unsupervised learning: hierarchical and density-based id91 algorithms!
22 unsupervised learning: non-linear id84!
23 supervised learning: out-of-core learning!

sebastian raschka & andreas mueller!

a!

65!

pipelines!

pipe = make_pipeline(t1(), t2(), classi   er())

t1

t2

classi   er

pipe.   t(x, y)

y

x

t1.   t(x, y)

t1.transform(x)

t1

x1

y

t2.   t(x1, y)

t2

t2.transform(x1) x2

pipe.predict(x')
x'

t1.transform(x') x'1 t2.transform(x'1) x'2

y

classi   er.   t(x2, y)

classi   er

classi   er.predict(x'2)

y'

sebastian raschka & andreas mueller!

66!

pipelines & cross validation!

training labels

training data

feature
extraction

scaling

feature
selection

model

cross validation

sebastian raschka & andreas mueller!

67!

afternoon session! 1:30	pm	-	5:30	pm		

13 cross-validation!
14 model complexity and grid search for adjusting hyperparameters!
15 scikit-learn pipelines!
16 supervised learning: performance metrics for classi   cation
17 supervised learning: linear models!
18 supervised learning: support vector machines!
19 supervised learning: id90 and id79s, ensemble methods!
20 supervised learning: feature selection!
21 unsupervised learning: hierarchical and density-based id91 algorithms!
22 unsupervised learning: non-linear id84!
23 supervised learning: out-of-core learning!

sebastian raschka & andreas mueller!

a!

68!

confusion matrix!

sebastian raschka & andreas mueller!

69!

classi   cation metrics i!

sebastian raschka & andreas mueller!

70!

classi   cation metrics ii!

sebastian raschka & andreas mueller!

71!

classi   cation metrics iii!

sebastian raschka & andreas mueller!

72!

receiver operator characteristic!

image	source:	hjp://scikit-learn.org/stable/_images/plot_roc_001.png	

sebastian raschka & andreas mueller!

73!

multi-class!

sebastian raschka & andreas mueller!

74!

afternoon session! 1:30	pm	-	5:30	pm		

13 cross-validation!
14 model complexity and grid search for adjusting hyperparameters!
15 scikit-learn pipelines!
16 supervised learning: performance metrics for classi   cation!
17 supervised learning: linear models
18 supervised learning: support vector machines!
19 supervised learning: id90 and id79s, ensemble methods!
20 supervised learning: feature selection!
21 unsupervised learning: hierarchical and density-based id91 algorithms!
22 unsupervised learning: non-linear id84!
23 supervised learning: out-of-core learning!

sebastian raschka & andreas mueller!

a!

75!

linear models for regression!

y_pred =   x_test[0] * coef_[0] + ...  
         + x_test[n_features-1] * coef_[n_features-1]  
         + intercept_ 

y	

slope (=  y/  x)!

x[0]	

sebastian raschka & andreas mueller!

76!

afternoon session! 1:30	pm	-	5:30	pm		

13 cross-validation!
14 model complexity and grid search for adjusting hyperparameters!
15 scikit-learn pipelines!
16 supervised learning: performance metrics for classi   cation!
17 supervised learning: linear models!
18 supervised learning: support vector machines
19 supervised learning: id90 and id79s, ensemble methods!
20 supervised learning: feature selection!
21 unsupervised learning: hierarchical and density-based id91 algorithms!
22 unsupervised learning: non-linear id84!
23 supervised learning: out-of-core learning!

sebastian raschka & andreas mueller!

a!

77!

support vector machines!

image	source:	hjps://github.com/rasbt/python-machine-learning-
book/blob/master/code/ch03/images/03_07.png	

sebastian raschka & andreas mueller!

78!

kernel trick!

hjps://github.com/rasbt/python-machine-learning-book/blob/
master/code/ch03/images/03_11.png	

sebastian raschka & andreas mueller!

79!

afternoon session! 1:30	pm	-	5:30	pm		

13 cross-validation!
14 model complexity and grid search for adjusting hyperparameters!
15 scikit-learn pipelines!
16 supervised learning: performance metrics for classi   cation!
17 supervised learning: linear models!
18 supervised learning: support vector machines!
19 supervised learning: id90 and id79s, ensemble methods
20 supervised learning: feature selection!
21 unsupervised learning: hierarchical and density-based id91 algorithms!
22 unsupervised learning: non-linear id84!
23 supervised learning: out-of-core learning!

s!

sebastian raschka & andreas mueller!

80!

id90!

sebastian raschka & andreas mueller!

81!

classi   cation w. continuous features!

sebastian raschka & andreas mueller!

82!

impurity measures!

sebastian raschka & andreas mueller!

83!

ensemble methods!

id112	

boos-ng	

random	
forests	

sebastian raschka & andreas mueller!

84!

afternoon session! 1:30	pm	-	5:30	pm		

13 cross-validation!
14 model complexity and grid search for adjusting hyperparameters!
15 scikit-learn pipelines!
16 supervised learning: performance metrics for classi   cation!
17 supervised learning: linear models!
18 supervised learning: support vector machines!
19 supervised learning: id90 and id79s, ensemble methods!
20 supervised learning: feature selection
21 unsupervised learning: hierarchical and density-based id91 algorithms!
22 unsupervised learning: non-linear id84!
23 supervised learning: out-of-core learning!

sebastian raschka & andreas mueller!

s!

85!

id84!

dimensionality	reduc-on	

feature	selec-on	

feature	extrac-on	

sebastian raschka & andreas mueller!

86!

afternoon session! 1:30	pm	-	5:30	pm		

13 cross-validation!
14 model complexity and grid search for adjusting hyperparameters!
15 scikit-learn pipelines!
16 supervised learning: performance metrics for classi   cation!
17 supervised learning: linear models!
18 supervised learning: support vector machines!
19 supervised learning: id90 and id79s, ensemble methods!
20 supervised learning: feature selection!
21 unsupervised learning: hierarchical and density-based id91 algorithms
22 unsupervised learning: non-linear id84!
23 supervised learning: out-of-core learning!

s!

sebastian raschka & andreas mueller!

87!

hierarchical id91!

hjps://en.wikipedia.org/wiki/hierarchical_id91#/media/
file:hierarchical_id91_simple_diagram.svg	[cc	by-sa	3.0]	

sebastian raschka & andreas mueller!

88!

dbscan!

sebastian raschka & andreas mueller!

89!

afternoon session! 1:30	pm	-	5:30	pm		

13 cross-validation!
14 model complexity and grid search for adjusting hyperparameters!
15 scikit-learn pipelines!
16 supervised learning: performance metrics for classi   cation!
17 supervised learning: linear models!
18 supervised learning: support vector machines!
19 supervised learning: id90 and id79s, ensemble methods!
20 supervised learning: feature selection!
21 unsupervised learning: hierarchical and density-based id91 algorithms!
22 unsupervised learning: non-linear id84
23 supervised learning: out-of-core learning!

sebastian raschka & andreas mueller!

s!

90!

pca!

2d!

1d!

?!

sebastian raschka & andreas mueller!

91!

pca!

2d!

1d!

sebastian raschka & andreas mueller!

92!

kernel pca!

2d!

1d!

sebastian raschka & andreas mueller!

93!

afternoon session! 1:30	pm	-	5:30	pm		

13 cross-validation!
14 model complexity and grid search for adjusting hyperparameters!
15 scikit-learn pipelines!
16 supervised learning: performance metrics for classi   cation!
17 supervised learning: linear models!
18 supervised learning: support vector machines!
19 supervised learning: id90 and id79s, ensemble methods!
20 supervised learning: feature selection!
21 unsupervised learning: hierarchical and density-based id91 algorithms!
22 unsupervised learning: non-linear id84!
23 supervised learning: out-of-core learning

sebastian raschka & andreas mueller!

s!

94!

