translation quality estimation tutorial

hands-on quest++

carolina scarton and lucia specia

july 12, 2016

abstract

in this tutorial we present quest++ , an open source framework for
pipelined translation quality estimation. quest++ is the newest ver-
sion of quest, including several improvements into the core code and the
support to word and document-level feature extraction and machine learn-
ing. this framework has two modules: a feature extractor module and
a machine learning module. with the two modules it is possible to
build a full quality estimation system, that predicts the quality of unseen
data.

contents

1 introduction

2 quest++ : an open source framework for translation quality

estimation
2.1 feature extractor module . . . . . . . . . . . . . . . . . . . . . .
including a feature . . . . . . . . . . . . . . . . . . . . . .
2.2 machine learning module . . . . . . . . . . . . . . . . . . . . . .
2.2.1 adding a new algorithm . . . . . . . . . . . . . . . . . . .

2.1.1

3 license

4 citation

1

introduction

1

3
4
8
13
14

16

16

quality estimation (qe) of machine translation (mt) have become increas-
ingly popular over the last decade. with the goal of providing a prediction on
the quality of a machine translated text, qe systems have the potential to make
mt more useful in a number of scenarios, for example, improving post-editing
e   ciency by    ltering out segments which would require more e   ort or time to
correct than to translate from scratch [specia, 2011], selecting high quality seg-
ments [soricut and echihabi, 2010], selecting a translation from either an mt
system or a translation memory [he et al., 2010], selecting the best translation
from multiple mt systems [shah and specia, 2014], and highlighting words or
phrases that need revision [bach et al., 2011].

1

sentence-level qe is addressed as a supervised machine learning task using
a variety of algorithms to induce models from examples of sentence translations
annotated with quality labels (e.g. 1-5 likert scores). this level has been cov-
ered in shared tasks organised by the workshop on statistical machine transla-
tion (wmt) annually since 2012 [callison-burch et al., 2012, bojar et al., 2013,
bojar et al., 2014, bojar et al., 2015]. while standard algorithms can be used
to build prediction models, key to this task is work of feature engineering.
two open source feature extraction toolkits are available for that: asiya1
[gon`alez et al., 2012] and quest2 [specia et al., 2013]. the latter has been
used as the o   cial baseline for the wmt shared tasks and extended by a num-
ber of participants, leading to improved results over the years.

qe

word-level

[blatz et al., 2004,

ue   ng and ney, 2005,
it is seemingly
luong et al., 2014] has recently received more attention.
a more challenging task where a quality label
is to be produced for each
target word. an additional challenge is the acquisition of sizable training sets
signi   cant e   orts have been made (including three years of shared task at
wmt), showing an increase on researches in word-level qe from last year.
an application that can bene   t from word-level qe is spotting errors (wrong
words) in a post-editing/revision scenario.

document-level qe has received much less attention than the other two lev-
els. this task consists in predicting a single label for entire documents, be it
an absolute score [scarton and specia, 2014] or a relative ranking of transla-
tions by one or more mt systems [soricut and echihabi, 2010] (being useful for
gisting purposes, where post-editing is not an option). the    rst shared-task
on document-level qe was organised last year in wmt15. although feature
engineering is the focus of this tutorial, it is worth mentioning that one impor-
tant research question in document-level qe is to de   ne ideal quality labels for
documents [scarton et al., 2015].

more recently, phrase-level qe has also been explored [blain et al., 2016,
logacheva and specia, 2015]. the idea is to move from word-level and instead
of predicting the quality of single words, the quality of segments of words are
predicted. this is a very promising level with applications on improving post-
editing, building automatic post-editing systems and including information on
decoders. phrase-level qe is being addressed for the    rst time in wmt16
shared task.3

quest++ 4 is a signi   cantly refactored and expanded version of quest.
feature extraction modules for both word and document-level qe were added
and sequence-labelling learning algorithms for word-level qe were made avail-
able. quest++ can be easily extended with new features at any textual level.
in this tutorial we present the two modules of quest++ : feature
extractor (implemented in java) and machine learning (implemented in
python) modules. in section 2 both modules are presented. section 2.1 con-
tains details of the feature extractor module, including how to build and run
the system, how to add a new feature and how to extract the results. sec-
tion 2.2 presents the machine learning module, showing how to use the python
scripts and how to include a new scikit-learn [pedregosa et al., 2011] algorithm

1http://nlp.lsi.upc.edu/asiya/
2http://www.quest.dcs.shef.ac.uk/
3http://www.statmt.org/wmt16/quality-estimation-task.html
4https://github.com/ghpaetzold/questplusplus

2

in the code. sections 3 and 4 contain the licence agreement and how to cite
quest++ , respectively.

2 quest++ : an open source framework for

translation quality estimation

in this section the basic functionalities of quest++ are shown. quest++ en-
compass a number of improvements and new functionalities over its previous
version. the main changes are listed below:

    refactoring of the core code of feature extractor module -

changes included:

    cleaning unused code in the main class.

    creating processorfactory classes in order to instantiate processors
classes that are required by features (now, only processors that are
required are instantiated).

    creating missingresourcesgenerator classes in order to generate
missing resources (such as language model (lm) whenever it is pos-
sible).

    implementing word and document-level features.
    including a id49 (crf) algorithm (by using crf-

suite) for word-level prediction.

    changing the con   guration    le format.

previous developers of quest can note the improvements in quest++ ,
making the code cleaner and easier to understand. users are bene   ted with a
more understandable con   guration    le format, better documentation and elim-
ination of unused dependencies.

in this section, we present how to use quest++ , how to build it and how

to add a new feature.

download

for developers, quest++ can be downloaded from github5 using the following
command:

git clone https://github.com/ghpaetzold/questplusplus.git

for users, a stable version of quest++ is available at:

http://www.quest.dcs.shef.ac.uk

5http://github.com

3

system requirements

    java 86

    netbeans 8.17 or
    apache ant (>= 1.9.3)8

    python 2.7.69 (or above -only 2.7 stable distributions)

    scipy and numpy (scipy >=0.9 and numpy >=1.6.1)10
    scikit-learn (version 0.15.2)11
    pyyaml12
    crfsuite13 (for word-level model only)

please note: for linux, the feature extractor module should work with

both openjdk and oracle versions (java-8-oracle14 recommended)

on ubuntu, it   s easier to install oracle distribution:

sudo apt-get install oracle-java8-installer

(check

http://ubuntuhandbook.org/index.php/2014/02/
install-oracle-java-6-7-or-8-ubuntu-14-04/ if you don   t    nd that
version)

netbeans has issues to build on linux. get ant instead to build through

command line:

sudo apt-get install ant

2.1 feature extractor module

the feature extractor module is implemented in java, as in the    rst version
of the framework. this module encompass over 150 implemented features for
sentence-level, 40 features for word-level and 70 features for document-level.
this tutorial will cover baseline features only, although some information about
advanced features is provided.

dependencies - tools

the dependencies for sentence and document-level baseline are:

    perl 515 (or above)
6http://www.oracle.com/technetwork/java/javase/downloads/

jdk8-downloads-2133151.html

7https://netbeans.org/downloads/
8http://ant.apache.org/bindownload.cgi)
9https://www.python.org/downloads/
10http://www.scipy.org/install.html
11https://pypi.python.org/pypi/scikit-learn/0.15.2
12http://pyyaml.org/
13http://www.chokkan.org/software/crfsuite/
14http://www.oracle.com/technetwork/java/javase/downloads/

jdk8-downloads-2133151.html

15https://www.perl.org/get.html

4

    srilm16
    tokenizer (available at lang_resources folder - from moses toolkit17)
    truecaser (available at lang_resources folder - from moses toolkit)

word-level features require the following libraries: some of the libraries
required to compile and run the code are included in the lib directory in the
root directory of the distribution. the java libraries should be included there
when possible. however, there are two libraries that were not included into the
lib directory due their size (used for word-level features only):

    stanford core nlp 3.5.1 models18 (stanford-corenlp-3.5.1-models.jar

only)

    stanford core nlp spanish models19

advanced features (sentence and document-level) require the following tools:
    treetagger20
    berkeley parser21

dependencies - resources

the resources required for sentence and document-level baseline features are:

    corpus for source language
    corpus for target language
    lm for source language
    lm for target language
    ngram counts    le for source language
    ngram counts    le for target language
    truecase model for source language
    truecase model for target language
    giza lex    le

for word-level the resources required are:
    corpus for source language
    corpus for target language
16http://www.speech.sri.com/projects/srilm/manpages/
17http://www.statmt.org/moses/
18http://nlp.stanford.edu/software/stanford-corenlp-full-2015-01-29.zip
19http://nlp.stanford.edu/software/stanford-spanish-corenlp-2015-01-08-models.

jar

20http://www.cis.uni-muenchen.de/\%7eschmid/tools/treetagger/
21https://github.com/slavpetrov/berkeleyparser

5

    lm for source language
    lm for target language
    ngram counts    le for source language
    ngram counts    le for target language
    pos ngram counts    le for source language
    pos ngram counts    le for target language
    corpus com pos information for source language
    corpus com pos information for target language
    reference translations in the target language
    stop words list of the source language
    translation probabilities of the source language
    universal id138 plugin22 (unzip this    le inside the lang_resources

folder)

examples of these resources are provided in the lang_resources folder.
resources for several languages can be downloaded from http://www.statmt.
org/wmt15/quality-estimation-task.html. advanced features may require
speci   c data (please read the documentation of the speci   c features).

input    les

for word and sentence levels, the input    les contain one sentence per line. for
document level, the input    les contain paths to documents (one document per
line). both source and target    les should have the same number of lines.

an alignment    le should also be provided for word-level feature extraction.
this    le is generated by fast align23 tool. alternatively, we can provide the
path for the fast align tool on the con   guration    le and quest++ will generate
the missing resource.

output    le

the output    le contain the features extracted separated by tab. word-level fea-
tures output are features templates for crf algorithm. sentence and document-
level features are real values separated by tab.

22http://resources.mpi-inf.mpg.de/yago-naga/uwn/uwn.zip
23https://github.com/clab/fast_align

6

con   guration    le

con   guration    le is a structured    le (extension .properties) that contains infor-
mation about the language pairs, featureset and paths to resources and tools.
an example of information about language pairs, featureset and source resource
is showed below:

sourcelang.default
targetlang.default
output
input
resourcespath
featureconfig

= spanish
= english
= output/test
= input/test

= ./lang_resources
= config/features/features_blackbox_17.xml

! resources for source:
source.corpus = ./lang_resources/english/europarl-nc.en
source.lm
source.truecase.model = ./lang_resources/english/truecase-model.en
source.postagger
source.ngram
source.tokenizer.lang

= ./lang_resources/english/english_lm.lm

= en

= /export/tools/tree-tagger/cmd/tree-tagger-english

= ./lang_resources/english/ngram-counts.europarl-nc.en.proc

for running sentence and document-level baseline features, you need to

change the path to srilm folder in your system:

tools.ngram.path

= /export/tools/srilm/bin/i686-m64/

for word-level features, paths to srilm, fast align and universal id138

plugin should be changed accordingly:

tools.fast_align.path
tools.ngram.path
tools.universalid138.path = ./lang_resources/uwn/

= /export/tools/srilm/bin/i686-m64/

= /export/tools/fast-align

feature con   guration    le

this is an xml    le containing the features that should be extracted. the path
to this    le is provided in the con   guration    le in the featureconfig parameter.
an example of this    le is presented below:

<?xml version="1.0" encoding="utf-8" standalone="no"?>
<features>

<feature class="shef.mt.features.impl.bb.feature1001"

description="number of tokens in the source sentence" index="1001"/>

<feature class="shef.mt.features.impl.bb.feature1002"

description="number of tokens in the target sentence" index="1002"/>

<feature class="shef.mt.features.impl.bb.feature1006"

description="average source token length" index="1006"/>

</features>

if this    le is used, three features will be extracted by the feature extractor

module.

7

build

we recommend the use of netbeans (version 8.1)24. alternatively, you can
use apache ant (>= 1.9.3):

ant "-dplatforms.jdk_1.8.home=/usr/lib/jvm/java-8-<<version>>"

the ant command will create all classes needed to use quest++ and a

quest++.jar    le.

basic usage

the following commands run quest++ for word, sentence and document-level
feature extraction, respectively (including data examples).

word-level:

java -cp quest++.jar:lib/* shef.mt.wordlevelfeatureextractor

-lang english spanish
-input input/source.word-level.en input/target.word-level.es
-alignments lang_resources/alignments/alignments.word-level.out
-config config/config.word-level.properties

sentence-level:

java -cp quest++.jar shef.mt.sentencelevelfeatureextractor

-tok -case true
-lang english spanish
-input input/source.sent-level.en input/target.sent-level.es
-config config/config.sentence-level.properties

document-level:

java -cp quest++.jar shef.mt.doclevelfeatureextractor

-tok -case true
-lang english spanish
-input input/source.sent-level.en input/target.sent-level.es
-config config/config.sentence-level.properties

omitting -tok option, the system will not tokenise the input. the option

-case can be true, lower or none.

2.1.1 including a feature

the following example provides basic steps to include a new feature at
quest++ . the example includes a feature at the sentence-level feature ex-
tractor. similarly, features for word and document levels can be added.

let   s include a feature that counts the number of complex words in a source
sentence and average it by the number of total words in the sentece. the source
language will be english and the target spanish.

24https://netbeans.org/downloads/

8

resources the    rst thing required is a resource, a list of simple words in
english. our task will be to count how many words are out of this list. a list
of simple words in english can be downloaded from:

https://www.dropbox.com/s/vc2vbzs1w2yptni/list_simple_words?dl=0

download the list and place it at lang_resources/english folder.

processors since our feature requires a resource, the second step is to create
a processor that will read and store the data from the resource. processor
classes are placed in the package shef.mt.tools (folder src/shef/mt/tools).
these classes are useful because they guarantee the modularity of the code.
features do not contain read and store operations and more than one feature
can require the same processor (without the need of implementing the same
code twice). moreover, the processors are instantiated only once for all features
that use them. processors extends the resourceprocessor class and imple-
ments the method processnextsentence (or processnextdocument). this
method is responsible to send information from the processor to the sentence
being evaluated. in order to read our list of simple words, let   s create a class
called complexwordsprocessor.java in the package shef.mt.tools (folder
src/shef/mt/tools). this class should contain the code:

package shef.mt.tools;

import java.io.bufferedreader;
import java.io.filenotfoundexception;
import java.io.filereader;
import java.io.ioexception;
import java.util.arraylist;
import java.util.logging.level;
import java.util.logging.logger;
import shef.mt.features.util.doc;
import shef.mt.features.util.sentence;

public class complexwordsprocessor
extends resourceprocessor {

private arraylist<string> simplewords;

public complexwordsprocessor(string path) {

//create hash of words:
this.simplewords = new arraylist<>();

//read and store words from file:
try {

bufferedreader reader =

new bufferedreader(new filereader(path));

while(reader.ready()){

string word = reader.readline().trim();
this.simplewords.add(word);

}

} catch (filenotfoundexception ex) {

9

logger.getlogger(stopwordsprocessor.class.getname())

.log(level.severe, null, ex);

} catch (ioexception ex) {
logger.getlogger(stopwordsprocessor.class.getname())

.log(level.severe, null, ex);

}

}

@override
public void processnextsentence(sentence s) {

s.setvalue("simplewords", this.simplewords);

}

@override
public void processnextdocument(doc source) {

throw new unsupportedoperationexception("not supported yet.");

}

}

this

code assumes

a word per
sentencelevelprocessofactory.java.

line.

it will
this

receive a valid path for a    le with
class

instantiated by the

class will be

feature once we have create all processors required for the feature, the next
step is to implement the feature itself. features classes are placed in the
shef.mt.features.impl package (src/shef/mt/features/impl folder) and
they are named following a numerical order to group features (e.g. feature1001
and feature1002 are from the same group). these classes implements each
feature, by using the resources provided by the processors.
it extends the
feature class and implement the method run that extracts the feature and set
the feature value for the sentece.25 let   s create a class called feature7001.java
in the shef.mt.features.impl.bb package (src/shef/mt/features/impl/bb
folder). this class should contain a code similar to:

package shef.mt.features.impl.bb;

import java.util.arraylist;
import shef.mt.features.impl.feature;
import shef.mt.features.util.sentence;

public class feature7001 extends feature {

public feature7001(){

this.setindex(7001);
this.setdescription("complex word count of source sentence");
this.addresource("source.simplewords");

}

@override

25for word and document levels, the classes are wordlevelfeature and doclevelfeature,

respectively.

10

public void run(sentence source, sentence target) {

arraylist<string> simplewords =

(arraylist<string>) source.getvalue("simplewords");

string[] tokens = source.gettokens();
int complexwords = 0;
for (string token:tokens){

if (!simplewords.contains(token)){

complexwords+=1;

}

}
//defining value for the feature
this.setvalue(((float) complexwords)/tokens.length);

}

}

this class is assuming that the resource source.simplewords was provide

in the con   guration    le.

feature con   guration    le a feature con   guration    le is a xml con-
taining the featureset that will be extracted. these    les are saved at the
config/features folder. in order to run our new feature, let   s create a fea-
ture con   guration    le called features_complex_words.xml. this    le should
contain:

<feature class="shef.mt.features.impl.bb.feature7001"

description="number of complex words in the source sentence"
index="7001"/>

con   guration    le the con   guration    le contains paths to the resources and
tools that are used by quest++ . these    les are in the config folder and have
the extension .properties in order to provide the path of the list of complex
words, we can include a line in the con   guration    le. this line should contain the
name of the resource (that we gave in the feature    le - source.simplewords).
also, the featureconfig parameter should be changed to point to the new
feature con   guration    le.

featureconfig = config/features/features_complex_words.xml
source.simplewords = ./lang_resources/english/list_simple_words

sentencelevelprocessofactory this class is responsible for linking instan-
tiated all required processors. it will search in the feature set provide for the
dependencies (resource or tools) required and it will instantiated the proces-
sors accordingly. this class is the link between the features requirements, the
resource and tools paths in the con   guration    le and the processors. in its con-
structor there are if blocks checking for feature requirements. if a constructor
is required it is instantiated in a get method and added to the list of processors
that will run for each sentence. the structure of this class is as follow:

//constructor
public sentencelevelprocessorfactory(featureextractor fe) {

//setup initial instance of resourceprocessor matrix:

11

this.resourceprocessors = null;

//setup feature extractor:
this.fe = fe;

//get required resources:
hashset<string> requirements =

fe.getfeaturemanager().getrequiredresources();

//allocate source and target processor vectors:
arraylist<resourceprocessor> sourceprocessors =

new arraylist<resourceprocessor>();

arraylist<resourceprocessor> targetprocessors =

new arraylist<resourceprocessor>();

[if blocks checking for feature requirements]

//transform array lists in vectors:
resourceprocessor[] sourceprocessorvector =

new resourceprocessor[sourceprocessors.size()];

resourceprocessor[] targetprocessorvector =

new resourceprocessor[targetprocessors.size()];

sourceprocessorvector =

(resourceprocessor[]) sourceprocessors.toarray(sourceprocessorvector);

targetprocessorvector =

(resourceprocessor[]) targetprocessors.toarray(targetprocessorvector);

//return vectors:
this.resourceprocessors =

new resourceprocessor[][]{sourceprocessorvector, targetprocessorvector};

}

[get processor methods]

in order to implement our new feature, the following if block should be

added to the code.

if (requirements.contains("source.simplewords")){

complexwordsprocessor complexwordsprocessor =

this.getcomplexwordsprocessor();

sourceprocessors.add(complexwordsprocessor);

}

the method getcomplexwordsprocessor() should also be implemented:

private complexwordsprocessor getcomplexwordsprocessor() {

//register resource:
resourcemanager.registerresource("source.simplewords");

//get paths to stop word lists:
string path = this.fe.getresourcemanager().getproperty("source.simplewords");

12

//generate processors:
complexwordsprocessor processor = new complexwordsprocessor(path);

//return processors:
return processor;

}

build and run either build the system again using netbeans or using
apache ant. just run using the sentence-level basic usage line.

2.2 machine learning module

the machine learning module is implemented in python and is located in the
folder learning of quest++ distribution. this module has support to several
algorithms from the scikit-learn toolkit and an implementation of crf from
crfsuite. support to gaussian process (using gpy toolkit) needs update. this
tutorial presents how to run and how to add a new algorithm from scikit-learn
to the module.

dependencies and instalation

the program itself does not require any installation step, it is just a matter of
running it provided that all the system requirements for python are installed.

running

note: following commands are based on the assumption that all    les are under
learning directory. the program takes only one input parameter, the con   gu-
ration    le. for example:

python src/learn_model.py config/svr.id18

please note that the    le svr.id18 can be replaced by any other con   guration

   le for di   erent algorithms.

for building crf models for word-level qe, use:

python src/learn_model_crf.py config/crf.id18

con   guration    le

the con   guration uses the yaml format. its layout is quite straightforward. it
is formed by key and value pairs that map directly to dictionaries (in python)
or hash tables with string keys. one example is as follows:

learning:

method: lassolars
parameters:

alpha: 1.0
max_iter: 500
normalize: true

13

fit_intercept: true
fit_path: true
verbose: false

each keyword followed by a : represents an entry in a hash. in this example,
the dictionary contains an entry learning that points to another dictionary
with two entries method and parameters. the values of each entry can be lists,
dictionaries or primitive values like    oats, integers, booleans or strings. please
note that each level in the example above is indented with 4 spaces.

for more information about the yaml format please refer to http://www.

yaml.org/ .

the con   guration    le is composed of three main parts:

input and generic

options, feature selection, and learning.

input comprises the following four parameters:

x_train: data/features/wmt2012_qe_baseline/training.qe.baseline.tsv
y_train: data/features/wmt2012_qe_baseline/training.effort
x_test: data/features/wmt2012_qe_baseline/test.qe.baseline.tsv
y_test: data/features/wmt2012_qe_baseline/test.effort

the    rst two are the paths to the    les containing the features for the training
set and the responses for the training set, respectively. the last two options refer
to the test dataset features and response values, respectively.

the format of the feature    les is any format that uses a character to separate
the columns. the default is the tabulator char (tab) as this is the default format
generated by the features extractor module.

two other options are available:

scale: true
separator:    \t   

scale applies scikit-learn   s scale() function to remove the mean and divide
by the unit standard deviation for each feature. this function is applied to the
concatenation of the training and test sets. more information about the scale
function implemented by scikit-learn can be found at http://scikit-learn.
org/dev/modules/generated/sklearn.preprocessing.scale.html.

separator sets the character used to delimit the columns in the input    les.
for crf algorithm a parameter related to the folder or the crfsuite also

need to be set:

crfsuite: <<path-to-crfsuite>>

con   guration    les for some of the implemented algorithms are available in

the con   g directory.

2.2.1 adding a new algorithm

let   s add a new algorithm from scikit-learn toolkit. in order to do this, we need
to change the    le learn_model.py (in the folder src). this    le instantiates
and run all scikit-learn algorithms already implemented in the module. not
only regression and classi   cation is supported, but also di   erent algorithms for
feature selection and several evaluation scores are already implemented.

14

the method that we need to change is called set_learning_method. in this
method the scikit-learn algorithm is de   ned and all the parameters are passed.
part of this method is presented below:

def set_learning_method(config, x_train, y_train):

estimator = none

learning_id18 = config.get("learning", none)
if learning_id18:

p = learning_id18.get("parameters", none)
o = learning_id18.get("optimize", none)
scorers = \
set_scorer_functions(learning_id18.get("scorer", [   mae   ,    rmse   ]))

method_name = learning_id18.get("method", none)
if method_name == "svr":

if o:

tune_params = set_optimization_params(o)
estimator = optimize_model(svr(), x_train, y_train,

tune_params,
scorers,
o.get("cv", 5),
o.get("verbose", true),
o.get("n_jobs", 1))

elif p:

estimator = svr(c=p.get("c", 10),

epsilon=p.get(   epsilon   , 0.01),
kernel=p.get(   kernel   ,    rbf   ),
degree=p.get(   degree   , 3),
gamma=p.get(   gamma   , 0.0034),
tol=p.get(   tol   , 1e-3),
verbose=false)

else:

estimator = svr()

it is possible to observe in the code that according to the o (optimise) and
p (   xed parameters) options, the algorithm svr is called di   erently. this
parameters come from the con   guration    le.

to include the linear ridge algorithm from scikit-learn we need to add the

following code:

if method_name == "ridge":

if o:

tune_params = set_optimization_params(o)
estimator = optimize_model(linear_model.ridge(), x_train, y_train,

tune_params,

scorers,
o.get("cv", 5),
o.get("verbose", true),
o.get("n_jobs", 1))

15

elif p:

estimator = linear_model.ridge(alpha =0.5)

else:

estimator = linear_model.ridge()

also the following line should be add to the top of the learn_model.py    le:

from sklearn import linear_model

the next step is to create a con   guration    le for the new algorithm. let   s
create a    le called ridge.id18 inside the config folder. this    le should follow
the yaml format, containing:

x_train: data/features/wmt2012_qe_baseline/training.qe.baseline.tsv
y_train: data/features/wmt2012_qe_baseline/training.effort
x_test: data/features/wmt2012_qe_baseline/test.qe.baseline.tsv
y_test: data/features/wmt2012_qe_baseline/test.effort

scale: true
separator: "\t"

learning:

method: ridge
optimize:

alpha: [0.1, 0.2, 0.3, 0.4, 0.5]

scorer: [mae, rmse]
parameters:

alpha: 0.5

note that the parameter that should be optimised is alpha.
run the system with the command line:

python src/learn_model.py config/ridge.id18

3 license

the license for the java code and any python and shell scripts developed here
is the very permissive bsd license26. for pre-existing code and resources, e.g.,
scikit-learn, srilm and stanford parser, please check their websites.

4 citation

lucia specia, gustavo henrique paetzold and carolina scarton (2015): multi-
level translation quality prediction with quest++. in proceedings of acl-
ijcnlp 2015 system demonstrations, denver, co, pp. 118-125.27

26http://en.wikipedia.org/wiki/bsd_licenses
27http://aclweb.org/anthology/n/n15/n15-2016.pdf

16

acknowledgements

this particular release of quest++ was made possible through the expert28
(eu marie curie itn no. 317471) project and funding from eamt29. we also
thank to quest30 (pascal noe), qtlaunchpad31, qt2132 projects that funded
previous versions of quest.

references

[bach et al., 2011] bach, n., huang, f., and al-onaizan, y. (2011). goodness:

a method for measuring mt con   dence. in acl11.

[blain et al., 2016] blain, f., logacheva, v., and specia, l. (2016). phrase level

segmentation and labelling of machine translation errors. in lrec 2016.

[blatz et al., 2004] blatz, j., fitzgerald, e., foster, g., gandrabur, s., goutte,
c., kulesza, a., sanchis, a., and ue   ng, n. (2004). con   dence estimation
for machine translation. in coling04.

[bojar et al., 2013] bojar, o., buck, c., callison-burch, c., federmann, c.,
haddow, b., koehn, p., monz, c., post, m., soricut, r., and specia, l.
(2013). findings of the 2013 workshop on smt. in wmt13.

[bojar et al., 2014] bojar, o., buck, c., federmann, c., haddow, b., koehn,
p., leveling, j., monz, c., pecina, p., post, m., saint-amand, h., soricut,
r., specia, l., and tamchyna, a. (2014). findings of the 2014 workshop on
smt. in wmt14.

[bojar et al., 2015] bojar, o., chatterjee, r., federmann, c., haddow, b.,
huck, m., hockamp, c., koehn, p., logacheva, v., monz, c., negri, m.,
post, m., scarton, c., specia, l., and turchi, m. (2015). findings of the
2015 workshop on smt. in wmt15.

[callison-burch et al., 2012] callison-burch, c., koehn, p., monz, c., post, m.,
soricut, r., and specia, l. (2012). findings of the 2012 workshop on smt.
in wmt12.

[gon`alez et al., 2012] gon`alez, m., gim  enez, j., and m`arquez, l. (2012). a

graphical interface for mt evaluation and error analysis. in acl12.

[he et al., 2010] he, y., ma, y., van genabith, j., and way, a. (2010). bridging

smt and tm with translation recommendation. in acl10.

[logacheva and specia, 2015] logacheva, v. and specia, l. (2015). phrase-level

quality estimation for machine translation. in iwslt 2015.

[luong et al., 2014] luong, n. q., besacier, l., and lecouteux, b. (2014). lig

system for word level qe task. in wmt14.

28http://expert-itn.eu/
29http://www.eamt.org/
30http://staffwww.dcs.shef.ac.uk/people/l.specia/projects/quest.html
31http://www.qt21.eu/launchpad/
32http://www.qt21.eu//

17

[pedregosa et al., 2011] pedregosa, f., varoquaux, g., gramfort, a., michel,
v., thirion, b., grisel, o., blondel, m., prettenhofer, p., weiss, r., dubourg,
v., vanderplas, j., passos, a., cournapeau, d., brucher, m., perrot, m., and
duchesnay, e. (2011). scikit-learn: machine learning in python. journal of
machine learning research, 12:2825   2830.

[scarton and specia, 2014] scarton, c. and specia, l. (2014). document-level
translation quality estimation: exploring discourse and pseudo-references. in
eamt14.

[scarton et al., 2015] scarton, c., zampieri, m., vela, m., van genabith, j.,
and specia, l. (2015). searching for context: a study on document-level
labels for translation quality estimation. in eamt15.

[shah and specia, 2014] shah, k. and specia, l. (2014). quality estimation for

translation selection. in eamt14.

[soricut and echihabi, 2010] soricut, r. and echihabi, a. (2010). trustrank:

inducing trust in automatic translations via ranking. in acl10.

[specia, 2011] specia, l. (2011). exploiting objective annotations for measuring

translation post-editing e   ort. in eamt11.

[specia et al., 2013] specia, l., shah, k., de souza, j. g. c., and cohn, t.

(2013). quest - a translation quality estimation framework. in acl13.

[ue   ng and ney, 2005] ue   ng, n. and ney, h. (2005). word-level con   dence
estimation for machine translation using phrase-based translation models. in
hlt/emnlp.

18

