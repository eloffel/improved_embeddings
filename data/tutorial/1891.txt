   #[1]github [2]recent commits to skip-thoughts:master

   [3]skip to content

   (button)

     * why github?
       [4]features    
          + [5]code review
          + [6]project management
          + [7]integrations
          + [8]actions
          + [9]team management
          + [10]social coding
          + [11]documentation
          + [12]code hosting
          + [13]customer stories    
          + [14]security    
     * [15]enterprise
     * explore
          + [16]explore github    

learn & contribute
          + [17]topics
          + [18]collections
          + [19]trending
          + [20]learning lab
          + [21]open source guides

connect with others
          + [22]events
          + [23]community forum
          + [24]github education
     * [25]marketplace
     * pricing
       [26]plans    
          + [27]compare plans
          + [28]contact sales
          + [29]nonprofit    
          + [30]education    

   ____________________
     * in this repository all github    
       jump to    

     * no suggested jump to results

     * in this repository all github    
       jump to    
     * in this repository all github    
       jump to    

   [31]sign in [32]sign up

     * [33]watch [34]112
     * [35]star [36]1,813
     * [37]fork [38]491

[39]ryankiros/[40]skip-thoughts

   [41]code [42]issues 59 [43]pull requests 12 [44]projects 0 [45]insights
   (button) dismiss

join github today

   github is home to over 31 million developers working together to host
   and review code, manage projects, and build software together.
   [46]sign up
   sent2vec encoder and training code from the paper "skip-thought
   vectors"
     * [47]25 commits
     * [48]1 branch
     * [49]0 releases
     * [50]fetching contributors

    1. [51]python 100.0%

   (button) python
   branch: master (button) new pull request
   [52]find file
   clone or download

clone with https

   use git or checkout with svn using the web url.
   https://github.com/r
   [53]download zip

downloading...

   want to be notified of new releases in ryankiros/skip-thoughts?
   [54]sign in [55]sign up

launching github desktop...

   if nothing happens, [56]download github desktop and try again.

   (button) go back

launching github desktop...

   if nothing happens, [57]download github desktop and try again.

   (button) go back

launching xcode...

   if nothing happens, [58]download xcode and try again.

   (button) go back

launching visual studio...

   if nothing happens, [59]download the github extension for visual studio
   and try again.

   (button) go back
   [60]@ryankiros
   [61]ryankiros [62]merge pull request [63]#43 [64]from cshallue/refactor
   (button)    
minor refactor for compatibility with tensorflow

   latest commit [65]6661cad mar 10, 2017
   [66]permalink
   type name latest commit message commit time
   failed to load latest commit information.
   [67]decoding [68]bug in id125 nov 3, 2015
   [69]training [70]update readme.md oct 31, 2015
   [71].gitignore
   [72]readme.md [73]minor refactor for compatibility with tensorflow mar
   8, 2017
   [74]__init__.py [75]minor refactor for compatibility with tensorflow
   mar 8, 2017
   [76]dataset_handler.py
   [77]eval_classification.py [78]minor refactor for compatibility with
   tensorflow mar 8, 2017
   [79]eval_msrp.py [80]minor refactor for compatibility with tensorflow
   mar 8, 2017
   [81]eval_rank.py [82]minor refactor for compatibility with tensorflow
   mar 8, 2017
   [83]eval_sick.py
   [84]eval_trec.py [85]minor refactor for compatibility with tensorflow
   mar 8, 2017
   [86]nbid166.py
   [87]skipthoughts.py

readme.md

skip-thoughts

   sent2vec encoder and training code from the paper [88]skip-thought
   vectors.

dependencies

   this code is written in python. to use it you will need:
     * python 2.7
     * theano 0.7
     * a recent version of [89]numpy and [90]scipy
     * [91]scikit-learn
     * [92]nltk 3
     * [93]keras (for semantic-relatedness experiments only)
     * [94]gensim (for vocabulary expansion when training new models)

getting started

   you will first need to download the model files and id27s.
   the embedding files (utable and btable) are quite large (>2gb) so make
   sure there is enough space available. the encoder vocabulary can be
   found in dictionary.txt.
wget http://www.cs.toronto.edu/~rkiros/models/dictionary.txt
wget http://www.cs.toronto.edu/~rkiros/models/utable.npy
wget http://www.cs.toronto.edu/~rkiros/models/btable.npy
wget http://www.cs.toronto.edu/~rkiros/models/uni_skip.npz
wget http://www.cs.toronto.edu/~rkiros/models/uni_skip.npz.pkl
wget http://www.cs.toronto.edu/~rkiros/models/bi_skip.npz
wget http://www.cs.toronto.edu/~rkiros/models/bi_skip.npz.pkl

   note to toronto users: you should be able to run the code as is from
   any machine, without having to download.

   once these are downloaded, open skipthoughts.py and set the paths to
   the above files (path_to_models and path_to_tables). now you are ready
   to go. make sure to set the theano_flags device if you want to use cpu
   or gpu.

   open up ipython and run the following:
import skipthoughts
model = skipthoughts.load_model()
encoder = skipthoughts.encoder(model)

   now suppose you have a list of sentences x, where each entry is a
   string that you would like to encode. to get vectors, just run the
   following:
vectors = encoder.encode(x)

   vectors is a numpy array with as many rows as the length of x, and each
   row is 4800 dimensional (combine-skip model, from the paper). the first
   2400 dimensions is the uni-skip model, and the last 2400 is the bi-skip
   model. we highly recommend using the combine-skip vectors, as they are
   almost universally the best performing in the paper experiments.

   as the vectors are being computed, it will print some numbers. the code
   works by extracting vectors in batches of sentences that have the same
   length - so the number corresponds to the current length being
   processed. if you want to turn this off, set verbose=false when calling
   encode.

   the rest of the document will describe how to run the experiments from
   the paper. for these, create a folder called 'data' to store each of
   the datasets.

trec question-type classification

   download the dataset from
   [95]http://cogcomp.cs.illinois.edu/data/qa/qc/ (train_5500.label and
   trec_10.label) and put these into the data directory. to obtain the
   test set result using the best chosen hyperparameter from cv, run the
   following:
import eval_trec
eval_trec.evaluate(encoder, evalcv=false, evaltest=true)

   this should give you a result of 92.2%, as in the paper. alternatively,
   you can set evalcv=true to do 10-fold cross-validation on the training
   set. it should find the same hyperparameter and report the same
   accuracy as above.

image-sentence ranking

   the file eval_rank.py is used for the coco image-sentence ranking
   experiments. to use this, you need to prepare 3 lists: one each for
   training, development and testing. each list should consist of 3
   entries. the first entry is a list of sentences, the second entry is a
   numpy array of image features for the corresponding sentences (e.g.
   oxfordnet/vgg) and the third entry is a numpy array of skip-thought
   vectors for the corresponding sentences.

   to train a model, open eval_rank.py and set the hyperparameters as
   desired in the trainer function. then simply run:
import eval_rank
eval_rank.trainer(train, dev)

   where train and dev are the lists you created. the model will train for
   the maximum numbers of epochs specified and periodically compute ranks
   on the development set. if the ranks improve, it will save the model.
   after training is done, you can evaluate a saved model by calling the
   evaluate function:
eval_rank.evaluate(dev, saveto, evaluate=true)

   this will load a saved model from the 'saveto' path and evaluate on the
   development set (alternatively, past the test list instead to evaluate
   on the test set).

   pre-computed coco features will be made available at a later date, once
   i find a suitable place to host them. note that this ranking code is
   generic, it can be applied with other tasks but you may need to modify
   the evaluation code accordingly.

semantic-relatedness

   download the semeval 2014 task 1 (sick) dataset from
   [96]http://alt.qcri.org/semeval2014/task1/index.php?id=data-and-tools
   (training data, trial data and test data with annotations) and put
   these into the data directory. then run the following:
import eval_sick
eval_sick.evaluate(encoder, evaltest=true)

   this will train a model using the trial dataset to early stop on
   pearson correlation. after stopping, it will evaluate the result on the
   test set. it should output the following results:
test pearson: 0.858463714763
test spearman: 0.791613731617
test mse: 0.26871638445

   for this experiment, you will need to have keras installed in order for
   it to work.

paraphrase detection

   download the microsoft research paraphrase corpus and put it in the
   data directory. there should be two files, msr_paraphrase_train.txt and
   msr_paraphrase_test.txt. to obtain the test set result using the best
   chosen hyperparameter from cv, run the following:
import eval_msrp
eval_msrp.evaluate(encoder, evalcv=false, evaltest=true, use_feats=true)

   this will evaluate on the test set using the best chosen hyperparamter
   from cv. i get the following results:
test accuracy: 0.75768115942
test f1: 0.829526916803

   alternatively, turning on evalcv will perform 10-fold cv on the
   training set, and should output the same result after.

binary classification benchmarks

   the file eval_classification.py is used for evaluation on the binary
   classification tasks (mr, cr, subj and mpqa). you can download cr and
   mpqa from [97]http://nlp.stanford.edu/~sidaw/home/projects:nbid166 and mr
   and subj from
   [98]https://www.cs.cornell.edu/people/pabo/movie-review-data/ (sentence
   polarity dataset, subjectivity dataset). included is a function for
   nested cross-validation, since it is standard practice to report
   10-fold cv on these datasets. here is sample usage:
import eval_classification
eval_classification.eval_nested_kfold(encoder, 'subj', use_nb=false)

   this will apply nested cv on the subj dataset without nb features. the
   dataset names above can be substituted in place of subj.

a note about the eos (end-of-sentence) token

   by default the eos token is not used when encoding, even though it was
   used in training. we found that this results in slightly better
   performance across all tasks, assuming the sentences end with proper
   puctuation. if this is not the case, we highly recommend using the eos
   token (which can be applied with use_eos=true in the encode function).
   for example, the semantic-relatedness sentences have been stripped of
   periods, so we used the eos token in those experiments. if ever in
   doubt, consider it as an extra hyperparameter.

bookcorpus data

   the pre-processed dataset we used for training our model is now
   available [99]here.

reference

   if you found this code useful, please cite the following paper:

   ryan kiros, yukun zhu, ruslan salakhutdinov, richard s. zemel, antonio
   torralba, raquel urtasun, and sanja fidler. "skip-thought vectors."
   arxiv preprint arxiv:1506.06726 (2015).
@article{kiros2015skip,
  title={skip-thought vectors},
  author={kiros, ryan and zhu, yukun and salakhutdinov, ruslan and zemel, richar
d s and torralba, antonio and urtasun, raquel and fidler, sanja},
  journal={arxiv preprint arxiv:1506.06726},
  year={2015}
}

   if you use the bookcorpus data in your work, please also cite:

   yukun zhu, ryan kiros, richard zemel, ruslan salakhutdinov, raquel
   urtasun, antonio torralba, sanja fidler. "aligning books and movies:
   towards story-like visual explanations by watching movies and reading
   books." arxiv preprint arxiv:1506.06724 (2015).
@article{zhu2015aligning,
    title={aligning books and movies: towards story-like visual explanations by
watching movies and reading books},
    author={zhu, yukun and kiros, ryan and zemel, richard and salakhutdinov, rus
lan and urtasun, raquel and torralba, antonio and fidler, sanja},
    journal={arxiv preprint arxiv:1506.06724},
    year={2015}
}

license

   [100]apache license 2.0

     *    2019 github, inc.
     * [101]terms
     * [102]privacy
     * [103]security
     * [104]status
     * [105]help

     * [106]contact github
     * [107]pricing
     * [108]api
     * [109]training
     * [110]blog
     * [111]about

   (button) you can   t perform that action at this time.

   you signed in with another tab or window. [112]reload to refresh your
   session. you signed out in another tab or window. [113]reload to
   refresh your session.

   (button)

references

   visible links
   1. https://github.com/opensearch.xml
   2. https://github.com/ryankiros/skip-thoughts/commits/master.atom
   3. https://github.com/ryankiros/skip-thoughts#start-of-content
   4. https://github.com/features
   5. https://github.com/features/code-review/
   6. https://github.com/features/project-management/
   7. https://github.com/features/integrations
   8. https://github.com/features/actions
   9. https://github.com/features#team-management
  10. https://github.com/features#social-coding
  11. https://github.com/features#documentation
  12. https://github.com/features#code-hosting
  13. https://github.com/customer-stories
  14. https://github.com/security
  15. https://github.com/enterprise
  16. https://github.com/explore
  17. https://github.com/topics
  18. https://github.com/collections
  19. https://github.com/trending
  20. https://lab.github.com/
  21. https://opensource.guide/
  22. https://github.com/events
  23. https://github.community/
  24. https://education.github.com/
  25. https://github.com/marketplace
  26. https://github.com/pricing
  27. https://github.com/pricing#feature-comparison
  28. https://enterprise.github.com/contact
  29. https://github.com/nonprofit
  30. https://education.github.com/
  31. https://github.com/login?return_to=/ryankiros/skip-thoughts
  32. https://github.com/join
  33. https://github.com/login?return_to=/ryankiros/skip-thoughts
  34. https://github.com/ryankiros/skip-thoughts/watchers
  35. https://github.com/login?return_to=/ryankiros/skip-thoughts
  36. https://github.com/ryankiros/skip-thoughts/stargazers
  37. https://github.com/login?return_to=/ryankiros/skip-thoughts
  38. https://github.com/ryankiros/skip-thoughts/network/members
  39. https://github.com/ryankiros
  40. https://github.com/ryankiros/skip-thoughts
  41. https://github.com/ryankiros/skip-thoughts
  42. https://github.com/ryankiros/skip-thoughts/issues
  43. https://github.com/ryankiros/skip-thoughts/pulls
  44. https://github.com/ryankiros/skip-thoughts/projects
  45. https://github.com/ryankiros/skip-thoughts/pulse
  46. https://github.com/join?source=prompt-code
  47. https://github.com/ryankiros/skip-thoughts/commits/master
  48. https://github.com/ryankiros/skip-thoughts/branches
  49. https://github.com/ryankiros/skip-thoughts/releases
  50. https://github.com/ryankiros/skip-thoughts/graphs/contributors
  51. https://github.com/ryankiros/skip-thoughts/search?l=python
  52. https://github.com/ryankiros/skip-thoughts/find/master
  53. https://github.com/ryankiros/skip-thoughts/archive/master.zip
  54. https://github.com/login?return_to=https://github.com/ryankiros/skip-thoughts
  55. https://github.com/join?return_to=/ryankiros/skip-thoughts
  56. https://desktop.github.com/
  57. https://desktop.github.com/
  58. https://developer.apple.com/xcode/
  59. https://visualstudio.github.com/
  60. https://github.com/ryankiros
  61. https://github.com/ryankiros/skip-thoughts/commits?author=ryankiros
  62. https://github.com/ryankiros/skip-thoughts/commit/6661cad40664b6c251cac1dad779986eb332c26a
  63. https://github.com/ryankiros/skip-thoughts/pull/43
  64. https://github.com/ryankiros/skip-thoughts/commit/6661cad40664b6c251cac1dad779986eb332c26a
  65. https://github.com/ryankiros/skip-thoughts/commit/6661cad40664b6c251cac1dad779986eb332c26a
  66. https://github.com/ryankiros/skip-thoughts/tree/6661cad40664b6c251cac1dad779986eb332c26a
  67. https://github.com/ryankiros/skip-thoughts/tree/master/decoding
  68. https://github.com/ryankiros/skip-thoughts/commit/a69ae64fbdaa025c11b6979dc5a8f8ce5cd77aca
  69. https://github.com/ryankiros/skip-thoughts/tree/master/training
  70. https://github.com/ryankiros/skip-thoughts/commit/4782989f320687e7fb1996071dd1cc011337829f
  71. https://github.com/ryankiros/skip-thoughts/blob/master/.gitignore
  72. https://github.com/ryankiros/skip-thoughts/blob/master/readme.md
  73. https://github.com/ryankiros/skip-thoughts/commit/cbee88259b8f09d69ba6da5f31f7be14bf1dd193
  74. https://github.com/ryankiros/skip-thoughts/blob/master/__init__.py
  75. https://github.com/ryankiros/skip-thoughts/commit/cbee88259b8f09d69ba6da5f31f7be14bf1dd193
  76. https://github.com/ryankiros/skip-thoughts/blob/master/dataset_handler.py
  77. https://github.com/ryankiros/skip-thoughts/blob/master/eval_classification.py
  78. https://github.com/ryankiros/skip-thoughts/commit/cbee88259b8f09d69ba6da5f31f7be14bf1dd193
  79. https://github.com/ryankiros/skip-thoughts/blob/master/eval_msrp.py
  80. https://github.com/ryankiros/skip-thoughts/commit/cbee88259b8f09d69ba6da5f31f7be14bf1dd193
  81. https://github.com/ryankiros/skip-thoughts/blob/master/eval_rank.py
  82. https://github.com/ryankiros/skip-thoughts/commit/cbee88259b8f09d69ba6da5f31f7be14bf1dd193
  83. https://github.com/ryankiros/skip-thoughts/blob/master/eval_sick.py
  84. https://github.com/ryankiros/skip-thoughts/blob/master/eval_trec.py
  85. https://github.com/ryankiros/skip-thoughts/commit/cbee88259b8f09d69ba6da5f31f7be14bf1dd193
  86. https://github.com/ryankiros/skip-thoughts/blob/master/nbid166.py
  87. https://github.com/ryankiros/skip-thoughts/blob/master/skipthoughts.py
  88. http://arxiv.org/abs/1506.06726
  89. http://www.numpy.org/
  90. http://www.scipy.org/
  91. http://scikit-learn.org/stable/index.html
  92. http://www.nltk.org/
  93. https://github.com/fchollet/keras
  94. https://radimrehurek.com/gensim/
  95. http://cogcomp.cs.illinois.edu/data/qa/qc/
  96. http://alt.qcri.org/semeval2014/task1/index.php?id=data-and-tools
  97. http://nlp.stanford.edu/~sidaw/home/projects:nbid166
  98. https://www.cs.cornell.edu/people/pabo/movie-review-data/
  99. http://www.cs.toronto.edu/~mbweb/
 100. http://www.apache.org/licenses/license-2.0
 101. https://github.com/site/terms
 102. https://github.com/site/privacy
 103. https://github.com/security
 104. https://githubstatus.com/
 105. https://help.github.com/
 106. https://github.com/contact
 107. https://github.com/pricing
 108. https://developer.github.com/
 109. https://training.github.com/
 110. https://github.blog/
 111. https://github.com/about
 112. https://github.com/ryankiros/skip-thoughts
 113. https://github.com/ryankiros/skip-thoughts

   hidden links:
 115. https://github.com/
 116. https://github.com/ryankiros/skip-thoughts
 117. https://github.com/ryankiros/skip-thoughts
 118. https://github.com/ryankiros/skip-thoughts
 119. https://help.github.com/articles/which-remote-url-should-i-use
 120. https://github.com/ryankiros/skip-thoughts#skip-thoughts
 121. https://github.com/ryankiros/skip-thoughts#dependencies
 122. https://github.com/ryankiros/skip-thoughts#getting-started
 123. https://github.com/ryankiros/skip-thoughts#trec-question-type-classification
 124. https://github.com/ryankiros/skip-thoughts#image-sentence-ranking
 125. https://github.com/ryankiros/skip-thoughts#semantic-relatedness
 126. https://github.com/ryankiros/skip-thoughts#paraphrase-detection
 127. https://github.com/ryankiros/skip-thoughts#binary-classification-benchmarks
 128. https://github.com/ryankiros/skip-thoughts#a-note-about-the-eos-end-of-sentence-token
 129. https://github.com/ryankiros/skip-thoughts#bookcorpus-data
 130. https://github.com/ryankiros/skip-thoughts#reference
 131. https://github.com/ryankiros/skip-thoughts#license
 132. https://github.com/
