   [1]sentiment tutorial home
   [2]christopher potts, [3]stanford linguistics

                     sentiment symposium tutorial: lexicons

    1. [4]overview
    2. [5]resources
         1. [6]bing liu's opinion lexicon
         2. [7]mpqa subjectivity lexicon
         3. [8]sentiid138
         4. [9]harvard general inquirer
         5. [10]liwc
         6. [11]relationships
    3. [12]building your own lexicons
         1. [13]simple id138 propagation
         2. [14]weighted id138 propagation
         3. [15]review word scores
              1. [16]data
              2. [17]category sizes
              3. [18]word distributions: raw counts are misleading
              4. [19]word distributions: relative frequencies
              5. [20]word distributions: probabilities
              6. [21]scoring with expected ratings
              7. [22]scoring with id28
         4. [23]experience project reaction distributions
              1. [24]data
              2. [25]word distributions: observed and expected counts
    4. [26]summary of conclusions

overview

   many sentiment applications rely on lexicons to supply features to a
   model. this section reviews some publicly available resources and their
   relationships, and it seeks to identify some best practices for using
   sentiment lexicons effectively.

   demo explore the sentiment lexicons discussed here:
   [27]http://sentiment.christopherpotts.net/lexicon/

   demo use the sentiment lexicons to score entire texts:
   [28]http://sentiment.christopherpotts.net/textscores/

   demo simple id138 propagation:
   [29]http://sentiment.christopherpotts.net/wnpropagate/

   data and code
   [30]a variety of data sets and python/nltk implementations

resources

  bing liu's opinion lexicon

   [31]bing liu maintains and freely distributes a sentiment lexicon
   consisting of lists of strings.
     * [32]distribution page ([33]direct link to rar archive)
     * positive words: 2006
     * negative words: 4783
     * useful properties: includes mis-spellings, morphological variants,
       slang, and social-media mark-up

  mpqa subjectivity lexicon

   the [34]mpqa (multi-perspective id53) [35]subjectivity
   lexicon is maintained by theresa wilson, janyce wiebe, and paul
   hoffmann ([36]wiebe, wilson, and cardie 2005). it is distributed under
   a gnu public license. [37]table tab:mpqa shows what its structure is
   like.

   table tab:mpqa
   a fragment of the mpqa subjectivity lexicon.
   strength length word part-of-speech stemmed polarity
   1. type=weaksubj len=1 word1=abandoned pos1=adj stemmed1=n
   priorpolarity=negative
   2. type=weaksubj len=1 word1=abandonment pos1=noun stemmed1=n
   priorpolarity=negative
   3. type=weaksubj len=1 word1=abandon pos1=verb stemmed1=y
   priorpolarity=negative
   4. type=strongsubj len=1 word1=abase pos1=verb stemmed1=y
   priorpolarity=negative
   5. type=strongsubj len=1 word1=abasement pos1=anypos stemmed1=y
   priorpolarity=negative
   6. type=strongsubj len=1 word1=abash pos1=verb stemmed1=y
   priorpolarity=negative
   7. type=weaksubj len=1 word1=abate pos1=verb stemmed1=y
   priorpolarity=negative
   8. type=weaksubj len=1 word1=abdicate pos1=verb stemmed1=y
   priorpolarity=negative
   9. type=strongsubj len=1 word1=aberration pos1=adj stemmed1=n
   priorpolarity=negative
   10. type=strongsubj len=1 word1=aberration pos1=noun stemmed1=n
   priorpolarity=negative
   ...
   8221. type=strongsubj len=1 word1=zest pos1=noun stemmed1=n
   priorpolarity=positive

  sentiid138

   sentiid138 (note: this site was hacked recently; take care when
   visiting it) ([38]baccianella, esuli, and sebastiani 2010) attaches
   positive and negative real-valued sentiment scores to id138 synsets
   ([39]fellbaum1998). it is freely distributed for noncommercial use, and
   licensed are available for commercial applications. (see the website
   for details.) [40]table tab:sentiid138 summarizes its structure. (for
   extensive discussion of id138 synsets and related objects, see
   [41]this introduction).

   table tab:sentiid138
   a fragment of the sentiid138 database.
   pos id posscore negscore synsetterms gloss
   a 00001740 0.125 0 able#1 (usually followed by `to') having the
   necessary means or [...]
   a 00002098 0 0.75 unable#1 (usually followed by `to') not having the
   necessary means or [...]
   a 00002312 0 0 dorsal#2 abaxial#1 facing away from the axis of an organ
   or organism; [...]
   a 00002527 0 0 ventral#2 adaxial#1 nearest to or facing toward the axis
   of an organ or organism; [...]
   a 00002730 0 0 acroscopic#1 facing or on the side toward the apex
   a 00002843 0 0 basiscopic#1 facing or on the side toward the base
   a 00002956 0 0 abducting#1 abducent#1 especially of muscles; [...]
   a 00003131 0 0 adductive#1 adducting#1 adducent#1 especially of
   muscles; [...]
   a 00003356 0 0 nascent#1 being born or beginning; [...]
   a 00003553 0 0 emerging#2 emergent#2 coming into existence; [...]

  harvard general inquirer

   the [42]harvard general inquirer is a lexicon attaching syntactic,
   semantic, and pragmatic information to part-of-speech tagged words
   ([43]stone, dunphry, smith, and ogilvie 1966). the [44]spreadsheet
   format is the easiest one to work with for most computational
   applications. [45]table tab:inquirer provides a glimpse of the richness
   and complexity of this resource.

   table tab:inquirer
   a fragment of the harvard general inquirer spreadsheet file.
            entry    positiv negativ hostile ...184 classes ... othtags defined
   1     a                                                      det art ...
   2     abandon             negativ                            supv
   3     abandonment         negativ                            noun
   4     abate               negativ                            supv
   5     abatement                                              noun
   ...
   35    absent#1            negativ                            modif
   36    absent#2                                               supv
   ...
   11788 zone                                                   noun

  liwc

   [46]linguistic inquiry and word counts (liwc) is a propriety database
   consisting of a lot of categorized id157. it costs about
   $90. its classifications are highly correlated with those of the
   harvard general inquirer. [47]table tab:liwc gives some of its
   sentiment-relevant categories with example id157.

   table tab:liwc
   a fragment of the liwc database.
   category examples
   negate aint, ain't, arent, aren't, cannot, cant, can't, couldnt, ...
   swear arse, arsehole*, arses, ass, asses, asshole*, bastard*, ...
   social acquainta*, admit, admits, admitted, admitting, adult, adults,
   advice, advis*
   affect abandon*, abuse*, abusi*, accept, accepta*, accepted, accepting,
   accepts, ache*
   posemo accept, accepta*, accepted, accepting, accepts, active*, admir*,
   ador*, advantag*
   negemo abandon*, abuse*, abusi*, ache*, aching, advers*, afraid,
   aggravat*, aggress*,
   anx afraid, alarm*, anguish*, anxi*, apprehens*, asham*, aversi*,
   avoid*, awkward*
   anger jealous*, jerk, jerked, jerks, kill*, liar*, lied, lies, lous*,
   ludicrous*, lying, mad

  relationships

   all of the above lexicons provide basic polarity classifications. their
   underlying vocabularies are different, so it is difficult to compare
   them comprehensively, but we can see how often they explicitly disagree
   with each other in that they supply opposite polarity values for a
   given word. [48]table tab:lexicon_disagreement reports on the results
   of such comparisons.

   (where a lexicon had part-of-speech tags, i removed them and selected
   the most sentiment-rich sense available for the resulting string. for
   sentiid138, i counted a word as positive if its positive score was
   larger than its negative score; negative if its negative score was
   larger than its positive score; else neutral, which means that words
   with equal non-0 positive and negative scores are neutral.)

   table tab:lexicon_disagreement
   disagreement levels for the sentiment lexicons reviewed above.
                 mpqa opinion lexicon   inquirer    sentiid138       liwc
      mpqa              33/5402 (0.6%)  49/2867 (2%) 1127/4214 (27%) 12/363 (3%)
 opinion lexicon                        32/2411 (1%) 1004/3994 (25%) 9/403 (2%)
    inquirer                                         520/2306 (23%)  1/204 (0.5%)
  sentiid138                                                       174/694 (25%)
      liwc                                                            

   i can imagine two equally reasonable reaction to the disagreements. the
   first would be to resolve them in favor of some particular sense. the
   second would be to combine the values derived from theses resources,
   thereby allowing the conflicts to persist, as a way of capturing the
   fact that the disagreements arise from genuine sense ambiguities.

   demo explore the sentiment lexicons discussed here:
   [49]http://sentiment.christopherpotts.net/lexicon/

   demo use the sentiment lexicons to score entire texts:
   [50]http://sentiment.christopherpotts.net/textscores/

building your own lexicons

   the above lexicons are useful for a wide range of tasks, but they are
   fixed resources. this section is devoted to developing new resources.
   this can have three benefits, which we will see in various
   combinations:
    1. much larger lexicons can be developed inferentially.
    2. we can capture different dimensions of sentiment that might be
       pressing for specific tasks.
    3. we can develop lexicons that are sensitive to the norms of specific
       domains.

  simple id138 propagation

   the guiding idea behind simple id138 propagation is the properties of
   some hand-selected seed-sets will be preserved as we travel
   strategically through id138 ([51]hu and liu 2004 [52]andreevskaia and
   bergler 2006 [53]esuli and sebastiani 2006 [54]kim and hovy 2006
   [55]godbole, srinivasaiah, and skiena 2007 [56]rao and ravichandran
   2009).

   the algorithm begins with n small, hand-crafted seed-sets and then
   follows id138 relations from them, thereby expanding their size. the
   expanded sets of iteration i are used as seed-sets for iteration i+1,
   generally after pruning any pairwise overlap between them.

   the algorithm is spelled out in full in [57]figure fig:wnpropagate.

   figure fig:wnpropagate
   free hyper parameters: the seed-sets, the id138 relations called in
   samepolarity and otherpolarity, the number of iterations, the decision
   to remove overlap.
   [58]figures/wnpropagate.png

   the algorithm has a number of free parameters: the seed-sets, the
   id138 relations called in samepolarity and otherpolarity, the number
   of iterations, the decision to remove overlap. the demo allows you to
   try out different combinations of values:

   demo simple id138 propagation:
   [59]http://sentiment.christopherpotts.net/wnpropagate/

   [60]table tab:wnpropagate_exs provides some additional seed-sets,
   drawing from other distinctions found in the harvard inquirer. these
   can be pasted into the demo if one wants a sense for how well new
   lexical classes propagate.

   table tab:wnpropagate_exs
   propagation example seed-sets to try.
   category                   seed set
   pleasur  amuse, calm, ecstasy, enjoy, joy
   pain     agony, disconcerted, fearful, regret, remorse
   strong   illustrious, rich, control, perseverance
   weak     lowly, poor, sorry, sluggish, weak
   male     boy, brother, gentleman, male, guy
   female   girl, sister, bride, female, lady

   to assess the algorithm for polarity sense-preservation, i began with
   the seed-sets in [61]table tab:seeds and then allowed the propagation
   algorithm to run for 20 iterations, checking each for its effectiveness
   at reproducing the positiv/negativ/neither distinctions in the subset
   of harvard general inquirer that is also in id138.

   table tab:seeds
   seed sets used to evaluate the id138 propagation algorithm against
   the harvard general inquirer.
   positive excellent, good, nice, positive, fortunate, correct, superior
   negative nasty, bad, poor, negative, unfortunate, wrong, inferior
   objective administrative, financial, geographic, constitute, analogy,
   ponder, material, public, department, measurement, visual

   [62]figure fig:wnpropagate-assess summarizes the results of this
   experiment, which are decidedly mixed.

   figure fig:wnpropagate-assess
   assessing how well simple id138 propagation is able to recover the
   harvard inquirer positiv/negativ/neither classes using the seed sets of
   [63]table tab:seeds.
   [64]figures/wnpropagate-results.png

  weighted id138 propagation

   [65]blair-goldensohn, hannan, mcdonald, ryan, reis, and reynar (2008)
   developed an algorithm that propagates not only the senses of the
   original seed set but also attaches scores to words, reflecting their
   intensity, which here is given by the strength of their graphical
   connections to the seed words. the algorithm is stated in [66]figure
   fig:wnscores_algorithm.

   figure fig:wnscores_algorithm
   the id138 score propagation algorithm.
   [67]figures/wnscores-algorithm.png

   [68]figure fig:wnscores_example works through an example.

   figure fig:wnscores_example
   id138 score propagation example. the authors propose a further
   rescaling of the scores: log(abs(s)) * sign(s) if abs(s) > 1, else 0.
   however, in the example, we would lose the sentiment score for good if
   we stopped before iteration 6. in my experiments, rescaling resulted in
   dramatically fewer non-0 values.
   [69]figures/wnscores-example.png

   i ran the algorithm using the full harvard general inquirer
   positiv/negative/neither classes as seeds-sets. the output in archived
   csv format:
     * [70]id138 scores lexicon (zip file)
     * [71]associated readme file (txt file)

   you can view the results at [72]the lexicon demo.

   in my informal assessment, the positive and negative scores it assigns
   tend to be accurate. the disappointment is that so many of the scores
   are 0, as see in [73]figure fig:wnscores_scoredist. i think this could
   be addressed by following more relations that just the basic synset
   one, as we do for the simple id138 propagation algorithm, but i've
   not tried it yet.

   figure fig:wnscores_scoredist
   id138 score propagation score distribution.
   [74]figures/wnscores-scoredist.png

  review word scores

   in this section, i make use of the csv-formatted data here:
     * [75]http://compprag.christopherpotts.net/code-data/imdb-words.csv.z
       ip

   this is a tightly controlled, pos-tagged dataset. even more carefully
   curated ones are here, drawing from a wider range of corpora:
     * [76]http://www.stanford.edu/~cgpotts/data/id138scales/

   and for more naturalistic, non-pos-tagged data in this format from a
   variety of sources:
     * [77]http://www.stanford.edu/~cgpotts/data/salt20/potts-salt20-data-
       and-code.zip

   the methods are discussed and motivated in [78]constant, davis, potts,
   and schwarz 2008 and [79]potts and schwarz 2010, and [80]this page
   provides a more extended discussion with associated r code.

    data

   the file
   [81]http://compprag.christopherpotts.net/code-data/imdb-words.csv.zip
   consists of data gathered from the user-supplied reviews at the
   [82]imdb. i suggest that you take a moment right now to browse around
   the site a bit to get a feel for the nature of the reviews     their
   style, tone, and so forth.

   the focus of this section is the relationship between the review
   authors' language and the star ratings they choose to assign, from the
   range 1-10 stars (with the exception of [83]this is spinal tap, which
   goes to 11). intuitively, the idea is that the author's chosen star
   rating affects, and is affected by, the text she produces. the star
   rating is a particular kind of high-level summary of the evaluative
   aspects of the review text, and thus we can use that high-level summary
   to get a grip on what's happening linguistically.

   the data i'll be working with are all in the format described in
   [84]table tab:data. each row represents a star-rating category. thus,
   for example, in these data, (bad, a) is used 122,232 in 1-star reviews,
   and the total token count for 1-star reviews is 25,395,214.

   table tab:data
   the data format. some of the files linked above do not have the tag
   column, and most of them are based in 5 stars rather than 10 stars.
   word tag category count   total
   bad  a   1        122232 25395214
   bad  a   2        40491  11755132
   bad  a   3        37787  13995838
   bad  a   4        33070  14963866
   bad  a   5        39205  20390515
   bad  a   6        43101  27420036
   bad  a   7        46696  40192077
   bad  a   8        42228  48723444
   bad  a   9        29588  40277743
   bad  a   10       51778  73948447

   the next few sections describe methods for deriving sentiment lexicons
   from such data. the methods should generalize to other kinds of ordered
   sentiment metadata (e.g., helpfulness ratings, confidence ratings).

    category sizes

   a common feature of online user-supplied reviews is that the positive
   reviews vastly out-number the negative ones; see [85]figure fig:totals.

   figure fig:totals
   the highly imbalanced category sizes.
   [86]figures/imdb-total.png

    word distributions: raw counts are misleading

   as we saw above, the raw count values are likely to be misleading due
   to the very large size imbalances among the categories. for example,
   there are more tokens of (bad, a) in 10-star reviews than in 2-star
   ones, which seems highly counter-intuitive. plotting the values reveals
   that the count distribution is very heavily influenced by the overall
   distribution of words ([87]figure fig:counts).

   figure fig:counts
   count distribution for (bad, a) (left) and the overall category size
   (right; repeated from [88]figure fig:totals). the distribution is
   heavily influenced by the category sizes.
   [89]figures/imdb-bad-counts.png [90]figures/imdb-total.png

   the source of this odd picture is clear: the 10-star category is 7
   times bigger than the 1-star category, so the absolute counts do not
   necessarily reflect the rate of usage.

    word distributions: relative frequencies

   to get a better read on the usage patterns, we use relative
   frequencies:

   definition: relative frequencies (relfreq)
          count/total

   [91]table tab:relfreq extends [92]table tab:data with these relfreq
   values.

   table tab:relfreq
   the data extended with relative frequencies (relfreq) values (= count /
   total).
   word tag category count   total   relfreq
   bad  a   1        122232 25395214 0.0048
   bad  a   2        40491  11755132 0.0034
   bad  a   3        37787  13995838 0.0027
   bad  a   4        33070  14963866 0.0022
   bad  a   5        39205  20390515 0.0019
   bad  a   6        43101  27420036 0.0016
   bad  a   7        46696  40192077 0.0012
   bad  a   8        42228  48723444 0.0009
   bad  a   9        29588  40277743 0.0007
   bad  a   10       51778  73948447 0.0007

   relative frequency values are hard to get a grip on intuitively because
   they are so small. plotting helps bring out the relationships between
   the values, as in [93]figure fig:relfreq.

   figure fig:relfreq
   relfreq distribution for (bad, a) (left), alongside the count
   distribution (right; repeated from [94]figure fig:counts). relfreq
   values show little or no influence from the underlying category sizes.
   [95]figures/imdb-bad-relfreq.png [96]figures/imdb-bad-counts.png

   one drawback to relfreq values is that they are highly sensitive to
   overall frequency. for example, (bad, a) is significantly more frequent
   than (horrible, a), which means that the relfreq values for the two
   words are hard to directly compare. [97]figure fig:relfreq_cmp
   nonetheless attempts a comparison.

   figure fig:relfreq_cmp
   comparing words via their relfreq distributions.
   [98]figures/imdb-bad-horrible-relfreq.png

   it is possible to discern that (bad, a) is less extreme in its
   negativity than (horrible, a). however, the effect looks subtle. the
   next measure we look at abstracts away from overall frequency, which
   facilitates this kind of direct comparison.

    word distributions: probabilities

   a drawback to relfreq values, at least for present purposes, is that
   they are extremely sensitive to the overall frequency of the word in
   question. there is a comparable value that is insensitive to this
   quantity:

   definition: pr values
          relfreq / sum(relfreq)

   pr values are just rescaled relfreq values: we divide by a constant to
   get from relfreq to pr. as a result, the distributions have exactly the
   same shape, as we see in [99]figure fig:pr.

   figure fig:pr
   comparing pr values (left) with relfreq values (right; repeated from
   [100]figure fig:relfreq). the shapes are exactly the same (pr is a
   rescaling of relfreq).
   [101]figures/imdb-bad-pr.png [102]figures/imdb-bad-relfreq.png

   a technical note: the move from relfreq to pr involves an application
   of bayes rule.
    1. relfreq values can be thought of as estimates of the conditional
       distribution p(word|rating): given that i am in rating category
       rating, how likely am i to produce word?
    2. bayes rule allows us to obtain the inverse distribution
       p(rating|word):
       p(rating|word) = p(word|rating)p(rating) / p(word)
    3. however, we would not want to directly apply this rule, because of
       the term p(rating) in the numerator. that would naturally be
       approximated by the distribution given by total, as in
       [103]figure fig:totals, which would simply re-introduce all of
       those unwanted biases.
    4. thus, we keep p(rating) constant, which is just to say that we
       leave it out:
       p(word|rating) / p(word)
       where p(word) = sum(relfreq).

   pr values greatly facilitate comparisons between words ([104]figure
   fig:pr_cmp).

   figure fig:pr_cmp
   comparing the pr distributions of (bad, a) and (horrible, a). the
   comparison is easier than it was with relfreq values
   ([105]figure fig:relfreq).
   [106]figures/imdb-bad-horrible-pr.png

   i think these plots clearly convey that (bad, a) is less intensely
   negative than (horrible, a). for example, whereas (bad, a) is at least
   used throughout the scale, even at the top, (horrible, a) is
   effectively never used at the top of the scale.

   (for methods that rigorously compare word distributions of this sort,
   see [107]this write-up, [108]this talk, and [109]davis 2011.)

    scoring with expected ratings

   we are now in a position to assign polarity scores to words. a first
   method for doing this uses expected ratings:

   definition: expected ratings
          sum((category-5.5) * pr)

   subtracting 5.5 from the category values centers them at 0, so that we
   can treat scores below 0 as negative and scores above 0 as positive.

   expected ratings calculations are used by [110]de marneffe et al. 2010
   to summarize pr-based distributions. the expected rating calculation is
   just a weighted average of pr values.

   to get a feel for these values, it helps to work through some examples:
    1. the rating vector is r = [-4.5 .. 4.5]
    2. if the pr is p = [0, 0, 0, 0, 0, 0, 0, 0, 0, 1] (all 10-star), then
       sum(r * p) = 4.5
    3. if the rating vector is r = [0, 0, 0.2, 0, 0, 0, 0, 0, 0, 0.8] (all
       10-star), then we do sum(r * p) = 3.1
    4. if the rating vector is r = [1, 0, 0, 0, 0, 0, 0, 0, 0, 0] (all
       10-star), then we do sum(r * p) = -4.5
    5. if the rating vector is r = [0.35, 0.26, 0.1, 0.05, 0.05, 0.05,
       0.02, 0.02, 0.05, 0.05] (all 10-star), then we do sum(r * p) =
       -2.33

   figure fig:er
   pr plots with added expected rating.
   [111]figures/imdb-er.png

   to get sentiment classification and intensity, we treat words with er
   values below 0 as negative, those with er valus above 0 as positive,
   and then use the absolute values as measures of intensity:

   definition: sentiment lexicon via er values.
          a word w is positive if er(w)     0, else negative.
          a word w's intensity is abs(er(w)).

    scoring with id28

   expected ratings are easy to calculate and quite intuitive, but it is
   hard to know how confident we can be in them, because they are
   insensitive to the amount and kind of data that went into them. suppose
   the er for words v and w are both 10, but we have 500 tokens of v and
   just 10 tokens of w. this suggests that we can have a high degree of
   confidence in our er for v, but not for w. however, er values don't
   encode this uncertainty, nor is there an obvious way to capture it.

   id28 provides a useful way to do the work of ers but
   with the added benefits of having a model and associated test
   statistics and measures of confidence. for our purposes, we can stick
   to a simple model that uses category values to predict word usage. the
   intuition here is just the one that we have been working with so far:
   the star-ratings are correlated with the usage of some words. for a
   word like (bad, a), the correlation is negative: usage drops as the
   ratings get higher. for a word like (amazing, a), the correlation is
   positive.

   with our id28 models, we will essentially fit lines
   through our relfreq data points, just as one would with a linear
   regression involving one predictor. however, the id28
   model fits these values in log-odds space and uses the inverse logit
   function (plogis in r) to ensure that all the predicted values lie in
   [0,1], i.e., that they are all true id203 values. unfortunately,
   there is not enough time to go into much more detail about the nature
   of this kind of modeling. i refer to [112]gelman and hill  2008,   5-6
   for an accessible, empirically-driven overview. instead, let's simply
   fit a model and try to build up intuitions about what it does and says.

   the simple id75 model for bad is given in [113]table
   tab:bad_fit. the model simply uses the rating values to predict the
   usage (log-odds) of the word in each category.

   table tab:bad_fit
   id28 fit for (bad, a).
             coefficient estimate standard error t value     p
   intercept -5.16                0.046          -112.49 < 0.00001
   category  -0.22                0.008          -27.96  < 0.00001

   this model is plotted on [114]figure fig:bad_fit.

   figure fig:bad_fit
   relfreq view of (bad, a) with id28.
   [115]figures/imdb-bad-logit.png

   here, we can use the coefficient for category as our sentiment score.
   where the value is negative (negative slope), the word is negative.
   where it is positive, the word is positive. informally, we can also use
   the size of the coefficient as a measure of its intensity.

   the great strength of this approach is that we can use the p-values to
   determine whether a score is trustworthy. [116]figure fig:cmp helps to
   convey why this is an important new power. (here and in later plots,
   i've rescaled the values into pr space to facilitate comparisons.)

   figure fig:cmp
   comparing words using our assessment values.
   [117]figures/imdb-awful-great-aardvark.png

   this leads to the following method for inducing a sentiment lexicon
   from these data:

   definition: sentiment lexicon via id28
          let coef(w) be the category coefficient for if that coefficient
          is significant at the chosen level, else 0
          if coef(w) = 0, then w is objective/neutral
          if coef(w) > 0, then w is positive
          if coef(w) < 0, then w is negative
          a word's intensity is abs(coef(w))

   depending on where the significance value is set, this can learn
   conservative lexicons of a few thousand words or very liberal lexicons
   of tens of thousands.

   this method of comparing coefficient values is likely to irk
   statisticians, but it works well in practice. for a more exact and
   careful method, as well as a proposal for how to compare words with
   non-linear relationships to the ratings, see [118]this talk i gave
   recently on creating lexical scales.

   [119]figure fig:scalars shows off this new method of lexicon induction.

   figure fig:scalars
   some scalars in the imdb.
   [120]figures/scalarpos-imdb.png [121]figures/scalarneg-imdb.png

  experience project reaction distributions

   the [122]experience project is a social networking website that allows
   users to share stories about their own personal experiences. at the
   [123]confessions portion of the site, users write typically very
   emotional stories about themselves, and readers can then chose from
   among five reaction categories to the story, but clicking on one of the
   five icons in [124]figure fig:ep_cats. the categories provide rich new
   dimensions of sentiment, ones that are generally orthogonal to the
   positive/negative one that most people study but that nonetheless
   models important aspects of sentiment expression and social interaction
   ([125]potts 2010b, [126]socher, pennington, huang, ng and manning
   2011).

   figure fig:ep_cats
   [127]experience project categories. "you rock" is a positive
   exclamative category. "teehee" is a playful, lighthearted category. "i
   understand" is an expression of solidarity. "sorry, hugs" is a
   sympathetic category. and "wow, just wow" is negative exclamative, the
   least used category on the site.
   [128]figures/ep-reactions-snapshot.png

   this section presents a simple method for using these data to develop
   sentiment lexicons.

    data

   as with the imdb data above, i've put the word-level information into
   an easy-to-use csv format, as in [129]table tab:ep_data. thus, as long
   as you require only word-level statistics, you needn't scrape the site
   again.
     * use the file epconfessions-unigrams.csv in
       [130]http://www.stanford.edu/~cgpotts/data/salt20/potts-salt20-data
       -and-code.zip

   table tab:ep_data
   experience project word-level data.
   word  category  count  total
   bad  hugs       11612 18038374
   bad  rock       5711  14066087
   bad  teehee     3987  8167037
   bad  understand 12577 20466744
   bad  wow        5993  12550603

    word distributions: observed and expected counts

   the basic scoring method contrasts observed click rates with expected
   click rates on the assumption that all word   click combinations are
   equally likely:

   definition: observed/expected values
          expected: sum(count) / (total/sum(total))
          the o/e values for w are count/expected

   [131]table tab:oe extends [132]table tab:ep_data with expected and o/e
   values.

   table tab:oe
   experience project word-level data.
   word  category  count  total   expected     o/e
   bad  hugs       11612 18038374 9816.527  1.1829030
   bad  rock       5711  14066087 7652.981  0.7462452
   bad  teehee     3987  8167037  4443.831  0.8971989
   bad  understand 12577 20466744 11137.727 1.1292250
   bad  wow        5993  12550603 6828.934  0.8775893

   some representative cases:

   figure fig:oe
   o/e values for representative words.
   [133]figures/scalars-pos-ep.png [134]figures/scalars-neg-ep.png
   [135]figures/emoticons-ep.png

   these scores give rise to a multidimensional lexical entry via the
   following definition:

   definition: multidimensional lexicon
          ep(w) is a five dimensional vector of o/e values.
          the chi-squared test or the g-test (log-likelihood test) can be
          used to reduce these vectors to all-0 based on significance
          testing.

   the lexicon demos include both imdb and ep scores as well:

   demo explore the sentiment lexicons discussed here:
   [136]http://sentiment.christopherpotts.net/lexicon/

   demo use the sentiment lexicons to score entire texts:
   [137]http://sentiment.christopherpotts.net/textscores/

summary of conclusions

    1. there are a number of good fixed lexicons for sentiment. they are
       negligible to high levels of disagreement with each other. these
       can be exploited strategically     resolve the conflicts somehow or
       allow them to persist as genuine points of uncertainty.
    2. id138 can be used to derive interesting lexicons from small seeds
       sets, even for distinctions that are not directly encoded in
       id138's structure.
    3. naturally occurring metadata are a rich source of lexical entries.
       statistical models are valuable for such lexicon induction.
    4. a major advantage of inducing a lexicon directly from data is that
       one can then capture domain specific effects, which are very common
       in sentiment. (see also the discussion of vector-space models for
       lexicon induction methods that don't any metadata.)

   [138]home |   2011 [139]christopher potts

references

   1. http://sentiment.christopherpotts.net/index.html
   2. http://www.stanford.edu/~cgpotts/
   3. http://linguistics.stanford.edu/
   4. http://sentiment.christopherpotts.net/lexicons.html#overview
   5. http://sentiment.christopherpotts.net/lexicons.html#resources
   6. http://sentiment.christopherpotts.net/lexicons.html#opinionlexicon
   7. http://sentiment.christopherpotts.net/lexicons.html#mpqa
   8. http://sentiment.christopherpotts.net/lexicons.html#sentiid138
   9. http://sentiment.christopherpotts.net/lexicons.html#inquirer
  10. http://sentiment.christopherpotts.net/lexicons.html#liwc
  11. http://sentiment.christopherpotts.net/lexicons.html#relationships
  12. http://sentiment.christopherpotts.net/lexicons.html#building
  13. http://sentiment.christopherpotts.net/lexicons.html#wnpropagate
  14. http://sentiment.christopherpotts.net/lexicons.html#weighted
  15. http://sentiment.christopherpotts.net/lexicons.html#reviews
  16. http://sentiment.christopherpotts.net/lexicons.html#data
  17. http://sentiment.christopherpotts.net/lexicons.html#categories
  18. http://sentiment.christopherpotts.net/lexicons.html#counts
  19. http://sentiment.christopherpotts.net/lexicons.html#relfreq
  20. http://sentiment.christopherpotts.net/lexicons.html#pr
  21. http://sentiment.christopherpotts.net/lexicons.html#er
  22. http://sentiment.christopherpotts.net/lexicons.html#glm
  23. http://sentiment.christopherpotts.net/lexicons.html#ep
  24. http://sentiment.christopherpotts.net/lexicons.html#data_ep
  25. http://sentiment.christopherpotts.net/lexicons.html#oe
  26. http://sentiment.christopherpotts.net/lexicons.html#summary
  27. http://sentiment.christopherpotts.net/lexicon/
  28. http://sentiment.christopherpotts.net/textscores/
  29. http://sentiment.christopherpotts.net/tokenizing/
  30. http://sentiment.christopherpotts.net/index.html#data
  31. http://www.cs.uic.edu/~liub/
  32. http://www.cs.uic.edu/~liub/fbs/sentiment-analysis.html
  33. http://www.cs.uic.edu/~liub/fbs/opinion-lexicon-english.rar
  34. http://www.cs.pitt.edu/mpqa/
  35. http://www.cs.pitt.edu/mpqa/#subj_lexicon
  36. http://sentiment.christopherpotts.net/bibliography.html#wiebe2005
  37. http://sentiment.christopherpotts.net/lexicons.html#tab:mpqa
  38. http://sentiment.christopherpotts.net/bibliography.html#baccianella2010
  39. http://sentiment.christopherpotts.net/bibliography.html#fellbaum1998
  40. http://sentiment.christopherpotts.net/lexicons.html#tab:sentiid138
  41. http://compprag.christopherpotts.net/id138.html
  42. http://www.wjh.harvard.edu/~inquirer/
  43. http://sentiment.christopherpotts.net/bibliography.html#stone1966
  44. http://www.wjh.harvard.edu/~inquirer/spreadsheet_guide.htm
  45. tab:inquirer
  46. http://www.liwc.net/
  47. http://sentiment.christopherpotts.net/lexicons.html#tab:liwc
  48. http://sentiment.christopherpotts.net/lexicons.html#tab:lexicon_disagreement
  49. http://sentiment.christopherpotts.net/lexicon/
  50. http://sentiment.christopherpotts.net/textscores/
  51. http://sentiment.christopherpotts.net/bibliography.html#hu2004
  52. http://sentiment.christopherpotts.net/bibliography.html#andreevskaia2006
  53. http://sentiment.christopherpotts.net/bibliography.html#esuli2006
  54. http://sentiment.christopherpotts.net/bibliography.html#kim2006
  55. http://sentiment.christopherpotts.net/bibliography.html#godbole2007
  56. http://sentiment.christopherpotts.net/bibliography.html#rao2009
  57. http://sentiment.christopherpotts.net/lexicons.html#fig:wnpropagate
  58. http://sentiment.christopherpotts.net/figures/wnpropagate.png
  59. http://sentiment.christopherpotts.net/tokenizing/
  60. http://sentiment.christopherpotts.net/lexicons.html#tab:wnpropagate_exs
  61. http://sentiment.christopherpotts.net/lexicons.html#tab:seeds
  62. http://sentiment.christopherpotts.net/lexicons.html#fig:wnpropagate-assess
  63. http://sentiment.christopherpotts.net/lexicons.html#tab:seeds
  64. http://sentiment.christopherpotts.net/figures/wnpropagate-results.png
  65. http://sentiment.christopherpotts.net/bibliography.html#blairgoldensohn2008
  66. http://sentiment.christopherpotts.net/lexicons.html#fig:wnscores_algorithm
  67. http://sentiment.christopherpotts.net/figures/wnscores-algorithm.png
  68. http://sentiment.christopherpotts.net/lexicons.html#fig:wnscores_example
  69. http://sentiment.christopherpotts.net/figures/wnscores-example.png
  70. http://compprag.christopherpotts.net/code-data/wnscores_inquirer.csv.zip
  71. http://compprag.christopherpotts.net/code-data/wnscores.readme.txt
  72. http://sentiment.christopherpotts.net/lexicon/
  73. http://sentiment.christopherpotts.net/lexicons.html#fig:wnscores_scoredist
  74. http://sentiment.christopherpotts.net/figures/wnscores-scoredist.png
  75. http://compprag.christopherpotts.net/code-data/imdb-words.csv.zip
  76. http://www.stanford.edu/~cgpotts/data/id138scales/
  77. http://www.stanford.edu/~cgpotts/data/salt20/potts-salt20-data-and-code.zip
  78. http://sentiment.christopherpotts.net/bibliography.html#constant2008
  79. http://sentiment.christopherpotts.net/bibliography.html#potts2010
  80. http://compprag.christopherpotts.net/reviews.html
  81. http://compprag.christopherpotts.net/code-data/imdb-words.csv.zip
  82. http://www.imdb.com/
  83. http://www.imdb.com/title/tt0088258/
  84. http://sentiment.christopherpotts.net/lexicons.html#tab:data
  85. http://sentiment.christopherpotts.net/lexicons.html#fig:totals
  86. http://sentiment.christopherpotts.net/figures/imdb-total.png
  87. http://sentiment.christopherpotts.net/lexicons.html#fig:counts
  88. http://sentiment.christopherpotts.net/lexicons.html#fig:totals
  89. http://sentiment.christopherpotts.net/figures/imdb-bad-counts.png
  90. http://sentiment.christopherpotts.net/figures/imdb-total.png
  91. http://sentiment.christopherpotts.net/lexicons.html#tab:relfreq
  92. http://sentiment.christopherpotts.net/lexicons.html#tab:data
  93. http://sentiment.christopherpotts.net/lexicons.html#fig:relfreq
  94. http://sentiment.christopherpotts.net/lexicons.html#fig:counts
  95. http://sentiment.christopherpotts.net/figures/imdb-bad-relfreq.png
  96. http://sentiment.christopherpotts.net/figures/imdb-bad-counts.png
  97. http://sentiment.christopherpotts.net/lexicons.html#fig:relfreq_cmp
  98. http://sentiment.christopherpotts.net/figures/imdb-bad-horrible-relfreq.png
  99. http://sentiment.christopherpotts.net/lexicons.html#fig:pr
 100. http://sentiment.christopherpotts.net/lexicons.html#fig:relfreq
 101. http://sentiment.christopherpotts.net/figures/imdb-bad-pr.png
 102. http://sentiment.christopherpotts.net/figures/imdb-bad-relfreq.png
 103. http://sentiment.christopherpotts.net/lexicons.html#fig:totals
 104. http://sentiment.christopherpotts.net/lexicons.html#fig:pr_cmp
 105. http://sentiment.christopherpotts.net/lexicons.html#fig:relfreq
 106. http://sentiment.christopherpotts.net/figures/imdb-bad-horrible-pr.png
 107. http://compprag.christopherpotts.net/reviews.html#wordcmp
 108. http://www.stanford.edu/~cgpotts/data/id138scales/
 109. http://sentiment.christopherpotts.net/bibliography.html#davis2011
 110. http://sentiment.christopherpotts.net/bibliography.html#demarneffemanningpotts2010
 111. http://sentiment.christopherpotts.net/figures/imdb-er.png
 112. http://sentiment.christopherpotts.net/bibliography.html#gelmanhill08
 113. http://sentiment.christopherpotts.net/lexicons.html#tab:bad_fit
 114. http://sentiment.christopherpotts.net/lexicons.html#fig:bad_fit
 115. http://sentiment.christopherpotts.net/figures/imdb-bad-logit.png
 116. http://sentiment.christopherpotts.net/lexicons.html#fig:cmp
 117. http://sentiment.christopherpotts.net/figures/imdb-awful-great-aardvark.png
 118. http://www.stanford.edu/~cgpotts/data/id138scales/
 119. http://sentiment.christopherpotts.net/lexicons.html#fig:scalars
 120. http://sentiment.christopherpotts.net/figures/scalarpos-imdb.png
 121. http://sentiment.christopherpotts.net/figures/scalarneg-imdb.png
 122. http://www.experienceproject.com/
 123. http://www.experienceproject.com/confessions.php
 124. http://sentiment.christopherpotts.net/lexicons.html#fig:ep_cats
 125. http://sentiment.christopherpotts.net/bibliography.html#potts2010salt
 126. http://sentiment.christopherpotts.net/socher2011
 127. http://www.experienceproject.com/
 128. http://sentiment.christopherpotts.net/figures/ep-reactions-snapshot.png
 129. http://sentiment.christopherpotts.net/lexicons.html#tab:ep_data
 130. http://www.stanford.edu/~cgpotts/data/salt20/potts-salt20-data-and-code.zip
 131. http://sentiment.christopherpotts.net/lexicons.html#tab:oe
 132. http://sentiment.christopherpotts.net/lexicons.html#tab:ep_data
 133. http://sentiment.christopherpotts.net/figures/scalars-pos-ep.png
 134. http://sentiment.christopherpotts.net/figures/scalars-neg-ep.png
 135. http://sentiment.christopherpotts.net/figures/emoticons-ep.png
 136. http://sentiment.christopherpotts.net/lexicon/
 137. http://sentiment.christopherpotts.net/textscores/
 138. http://sentiment.christopherpotts.net/index.html
 139. http://www.stanford.edu/~cgpotts/
