   #[1]tensorflow

   (button)
   [2]tensorflow
     *

   [3]install [4]learn
     * [5]introduction
       new to tensorflow?
     * [6]tensorflow
       the core open source ml library
     * [7]for javascript
       tensorflow.js for ml using javascript
     * [8]for mobile & iot
       tensorflow lite for mobile and embedded devices
     * [9]for production
       tensorflow extended for end-to-end ml components
     * [10]swift for tensorflow (in beta)

   [11]api
     * api r1
     * [12]r1.13 (stable)
     * [13]r1.12
     * [14]r1.11
     * [15]r1.10
     * [16]r1.9
     * [17]more   

     * api r2
     * [18]r2.0 (preview)

   [19]resources
     * [20]models & datasets
       pre-trained models and datasets built by google and the community
     * [21]tools
       ecosystem of tools to help you use tensorflow
     * [22]libraries & extensions
       libraries and extensions built on tensorflow

   [23]community [24]why tensorflow
     * [25]about
     * [26]case studies

   ____________________
   (button)
   (button)
   [27]github
     * [28]tensorflow core

   [29]overview [30]tutorials [31]guide [32]tf 2.0 alpha

   (button)
     * [33]install
     * [34]learn
          + more
          + [35]overview
          + [36]tutorials
          + [37]guide
          + [38]tf 2.0 alpha
     * [39]api
          + more
     * [40]resources
          + more
     * [41]community
     * [42]why tensorflow
          + more
     * [43]github

     * [44]get started with tensorflow
     * learn and use ml
          + [45]overview
          + [46]basic classification
          + [47]text classification
          + [48]regression
          + [49]overfitting and underfitting
          + [50]save and restore models
     * research and experimentation
          + [51]overview
          + [52]eager execution
          + [53]automatic differentiation
          + [54]custom training: basics
          + [55]custom layers
          + [56]custom training: walkthrough
     * ml at production scale
          + [57]linear model with estimators
          + [58]wide and deep learning
          + [59]boosted trees
          + [60]boosted trees model understanding
          + [61]build a id98 using estimators
     * generative models
          + [62]translation with attention
          + [63]image captioning
          + [64]dcgan
          + [65]vae
     * images
          + [66]image recognition
          + [67]pix2pix
          + [68]neural style transfer
          + [69]image segmentation
          + [70]advanced id98
     * sequences
          + [71]text generation with an id56
          + [72]recurrent neural network
          + [73]drawing classification
          + [74]simple audio recognition
          + [75]id4
     * load data
          + [76]load images
          + [77]tfrecords and tf.example
     * data representation
          + [78]vector representations of words
          + [79]kernel methods
          + [80]large-scale linear models
          + [81]unicode
     * non-ml
          + [82]mandelbrot set
          + [83]partial differential equations

     * [84]introduction
     * [85]tensorflow
     * [86]for javascript
     * [87]for mobile & iot
     * [88]for production
     * [89]swift for tensorflow (in beta)

     * api r1
     * [90]r1.13 (stable)
     * [91]r1.12
     * [92]r1.11
     * [93]r1.10
     * [94]r1.9
     * [95]more   
     * api r2
     * [96]r2.0 (preview)

     * [97]models & datasets
     * [98]tools
     * [99]libraries & extensions

     * [100]about
     * [101]case studies

   watch talks from the 2019 tensorflow dev summit [102]watch now
     * [103]tensorflow
     * [104]learn
     * [105]tensorflow core
     * [106]tutorials

hub with keras

   [107][tf_logo_32px.png] view on tensorflow.org
   [108][colab_logo_32px.png] run in google colab
   [109][github-mark-32px.png] view source on github

   [110]tensorflow hub is a way to share pretrained model components. see
   the [111]tensorflow module hub for a searchable listing of pre-trained
   models.

   this tutorial demonstrates:
    1. how to use tensorflow hub with [112]tf.keras.
    2. how to do image classification using tensorflow hub.
    3. how to do simple id21.

setup

imports

!pip install -q tensorflow_hub

from __future__ import absolute_import, division, print_function

import matplotlib.pylab as plt

import tensorflow as tf
import tensorflow_hub as hub

from tensorflow.keras import layers

tf.version

'1.13.0-rc2'

dataset

   for this example we'll use the tensorflow flowers dataset:
data_root = tf.keras.utils.get_file(
  'flower_photos','https://storage.googleapis.com/download.tensorflow.org/exampl
e_images/flower_photos.tgz',
   untar=true)

downloading data from https://storage.googleapis.com/download.tensorflow.org/exa
mple_images/flower_photos.tgz
228818944/228813984 [==============================] - 3s 0us/step

   the simplest way to load this data into our model is using
   tf.keras.preprocessing.image.imagedatagenerator:

   all of tensorflow hub's image modules expect float inputs in the [0, 1]
   range. use the imagedatagenerator's rescale parameter to achieve this.

   the image size will be handles later.
image_generator = tf.keras.preprocessing.image.imagedatagenerator(rescale=1/255)
image_data = image_generator.flow_from_directory(str(data_root))

found 3670 images belonging to 5 classes.

   the resulting object is an iterator that returns image_batch,
   label_batch pairs.
for image_batch,label_batch in image_data:
  print("image batch shape: ", image_batch.shape)
  print("labe batch shape: ", label_batch.shape)
  break

image batch shape:  (32, 256, 256, 3)
labe batch shape:  (32, 5)

an id163 classifier

download the classifier

   use hub.module to load a mobilenet, and [113]tf.keras.layers.lambda to
   wrap it up as a keras layer.

   any [114]image classifier url from tfhub.dev will work here.
classifier_url = "https://tfhub.dev/google/id163/mobilenet_v2_100_224/classif
ication/2" #@param {type:"string"}

def classifier(x):
  classifier_module = hub.module(classifier_url)
  return classifier_module(x)

image_size = hub.get_expected_image_size(hub.module(classifier_url))

info:tensorflow:using /tmp/tfhub_modules to cache modules.
info:tensorflow:downloading tf-hub module 'https://tfhub.dev/google/id163/mob
ilenet_v2_100_224/classification/2'.
info:tensorflow:downloaded https://tfhub.dev/google/id163/mobilenet_v2_100_22
4/classification/2, total size: 15.28mb
info:tensorflow:downloaded tf-hub module 'https://tfhub.dev/google/id163/mobi
lenet_v2_100_224/classification/2'.
warning:tensorflow:from /usr/local/lib/python3.5/dist-packages/tensorflow/python
/ops/control_flow_ops.py:3632: colocate_with (from tensorflow.python.framework.o
ps) is deprecated and will be removed in a future version.
instructions for updating:
colocations handled automatically by placer.

classifier_layer = layers.lambda(classifier, input_shape = image_size+[3])
classifier_model = tf.keras.sequential([classifier_layer])
classifier_model.summary()

info:tensorflow:saver not created because there are no variables in the graph to
 restore
_________________________________________________________________
layer (type)                 output shape              param #
=================================================================
lambda (lambda)              (none, 1001)              0
=================================================================
total params: 0
trainable params: 0
non-trainable params: 0
_________________________________________________________________

   rebuild the data generator, with the output size set to match what's
   expected by the module.
image_data = image_generator.flow_from_directory(str(data_root), target_size=ima
ge_size)
for image_batch,label_batch in image_data:
  print("image batch shape: ", image_batch.shape)
  print("labe batch shape: ", label_batch.shape)
  break

found 3670 images belonging to 5 classes.
image batch shape:  (32, 224, 224, 3)
labe batch shape:  (32, 5)

   when using keras, tfhub modules need to be manually initialized.
import tensorflow.keras.backend as k
sess = k.get_session()
init = tf.global_variables_initializer()

sess.run(init)

run it on a single image

   download a single image to try the model on.
import numpy as np
import pil.image as image

grace_hopper = tf.keras.utils.get_file('image.jpg','https://storage.googleapis.c
om/download.tensorflow.org/example_images/grace_hopper.jpg')
grace_hopper = image.open(grace_hopper).resize(image_size)
grace_hopper

downloading data from https://storage.googleapis.com/download.tensorflow.org/exa
mple_images/grace_hopper.jpg
65536/61306 [================================] - 0s 0us/step

   png
grace_hopper = np.array(grace_hopper)/255.0
grace_hopper.shape

(224, 224, 3)

   add a batch dimension, and pass the image to the model.
result = classifier_model.predict(grace_hopper[np.newaxis, ...])
result.shape

(1, 1001)

   the result is a 1001 element vector of logits, rating the id203
   of each class for the image.

   so the top class id can be found with argmax:
predicted_class = np.argmax(result[0], axis=-1)
predicted_class

653

decode the predictions

   we have the predicted class id, fetch the id163 labels, and decode
   the predictions
labels_path = tf.keras.utils.get_file('id163labels.txt','https://storage.goog
leapis.com/download.tensorflow.org/data/id163labels.txt')
id163_labels = np.array(open(labels_path).read().splitlines())

downloading data from https://storage.googleapis.com/download.tensorflow.org/dat
a/id163labels.txt
16384/10484 [==============================================] - 0s 0us/step

plt.imshow(grace_hopper)
plt.axis('off')
predicted_class_name = id163_labels[predicted_class]
_ = plt.title("prediction: " + predicted_class_name)

   png

run it on a batch of images

   now run the classifier on the image batch.
result_batch = classifier_model.predict(image_batch)

labels_batch = id163_labels[np.argmax(result_batch, axis=-1)]
labels_batch

array(['mask', 'cardoon', 'daisy', 'rapeseed', 'paper towel',
       'coral reef', 'bee', 'daisy', 'cardoon', 'picket fence',
       'shower curtain', 'parachute', 'bee', 'hip', 'daisy', 'bee', 'hip',
       'daisy', 'daisy', 'coral reef', 'clog', 'daisy', 'daisy',
       'picket fence', 'daisy', 'hermit crab', 'daisy', 'cardoon',
       'rapeseed', 'pot', 'quill', 'umbrella'], dtype='<u30')

   now check how these predictions line up with the images:
plt.figure(figsize=(10,9))
for n in range(30):
  plt.subplot(6,5,n+1)
  plt.imshow(image_batch[n])
  plt.title(labels_batch[n])
  plt.axis('off')
_ = plt.suptitle("id163 predictions")

   png

   see the license.txt file for image attributions.

   the results are far from perfect, but reasonable considering that these
   are not the classes the model was trained for (except "daisy").

simple id21

   using tfhub it is simple to retrain the top layer of the model to
   recognize the classes in our dataset.

download the headless model

   tensorflow hub also distributes models without the top classification
   layer. these can be used to easily do id21.

   any [115]image feature vector url from tfhub.dev will work here.
feature_extractor_url = "https://tfhub.dev/google/id163/mobilenet_v2_100_224/
feature_vector/2" #@param {type:"string"}

   create the module, and check the expected image size:
def feature_extractor(x):
  feature_extractor_module = hub.module(feature_extractor_url)
  return feature_extractor_module(x)

image_size = hub.get_expected_image_size(hub.module(feature_extractor_url))

info:tensorflow:downloading tf-hub module 'https://tfhub.dev/google/id163/mob
ilenet_v2_100_224/feature_vector/2'.
info:tensorflow:downloaded https://tfhub.dev/google/id163/mobilenet_v2_100_22
4/feature_vector/2, total size: 10.35mb
info:tensorflow:downloaded tf-hub module 'https://tfhub.dev/google/id163/mobi
lenet_v2_100_224/feature_vector/2'.

   ensure the data generator is generating images of the expected size:
image_data = image_generator.flow_from_directory(str(data_root), target_size=ima
ge_size)
for image_batch,label_batch in image_data:
  print("image batch shape: ", image_batch.shape)
  print("labe batch shape: ", label_batch.shape)
  break

found 3670 images belonging to 5 classes.
image batch shape:  (32, 224, 224, 3)
labe batch shape:  (32, 5)

   wrap the module in a keras layer.
features_extractor_layer = layers.lambda(feature_extractor, input_shape=image_si
ze+[3])

   freeze the variables in the feature extractor layer, so that the
   training only modifies the new classifier layer.
features_extractor_layer.trainable = false

attach a classification head

   now wrap the hub layer in a [116]tf.keras.sequential model, and add a
   new classification layer.
model = tf.keras.sequential([
  features_extractor_layer,
  layers.dense(image_data.num_classes, activation='softmax')
])
model.summary()

info:tensorflow:saver not created because there are no variables in the graph to
 restore
_________________________________________________________________
layer (type)                 output shape              param #
=================================================================
lambda_1 (lambda)            (none, 1280)              0
_________________________________________________________________
dense (dense)                (none, 5)                 6405
=================================================================
total params: 6,405
trainable params: 6,405
non-trainable params: 0
_________________________________________________________________

   initialize the tfhub module.
init = tf.global_variables_initializer()
sess.run(init)

   test run a single batch, to see that the result comes back with the
   expected shape.
result = model.predict(image_batch)
result.shape

(32, 5)

train the model

   use compile to configure the training process:
model.compile(
  optimizer=tf.train.adamoptimizer(),
  loss='categorical_crossid178',
  metrics=['accuracy'])

   now use the .fit method to train the model.

   to keep this example short train just a single epoch. to visualize the
   training progress during that epoch, use a custom callback to log the
   loss and accuract of each batch.
class collectbatchstats(tf.keras.callbacks.callback):
  def __init__(self):
    self.batch_losses = []
    self.batch_acc = []

  def on_batch_end(self, batch, logs=none):
    self.batch_losses.append(logs['loss'])
    self.batch_acc.append(logs['acc'])

steps_per_epoch = image_data.samples//image_data.batch_size
batch_stats = collectbatchstats()
model.fit((item for item in image_data), epochs=1,
                    steps_per_epoch=steps_per_epoch,
                    callbacks = [batch_stats])

warning:tensorflow:from /usr/local/lib/python3.5/dist-packages/tensorflow/python
/ops/math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is depreca
ted and will be removed in a future version.
instructions for updating:
use tf.cast instead.
114/114 [==============================] - 38s 337ms/step - loss: 0.6716 - acc:
0.7543

<tensorflow.python.keras.callbacks.history at 0x7f93e2241828>

   now after, even just a few training iterations, we can already see that
   the model is making progress on the task.
plt.figure()
plt.ylabel("loss")
plt.xlabel("training steps")
plt.ylim([0,2])
plt.plot(batch_stats.batch_losses)

plt.figure()
plt.ylabel("accuracy")
plt.xlabel("training steps")
plt.ylim([0,1])
plt.plot(batch_stats.batch_acc)

[<matplotlib.lines.line2d at 0x7f93e19ea160>]

   png

   png

check the predictions

   to redo the plot from before, first get the ordered list of class
   names:
label_names = sorted(image_data.class_indices.items(), key=lambda pair:pair[1])
label_names = np.array([key.title() for key, value in label_names])
label_names

array(['daisy', 'dandelion', 'roses', 'sunflowers', 'tulips'],
      dtype='<u10')

   run the image batch through the model and comvert the indices to class
   names.
result_batch = model.predict(image_batch)

labels_batch = label_names[np.argmax(result_batch, axis=-1)]
labels_batch

array(['dandelion', 'dandelion', 'roses', 'roses', 'daisy', 'roses',
       'dandelion', 'dandelion', 'roses', 'daisy', 'tulips', 'daisy',
       'daisy', 'dandelion', 'daisy', 'dandelion', 'daisy', 'daisy',
       'dandelion', 'sunflowers', 'daisy', 'tulips', 'tulips', 'daisy',
       'sunflowers', 'sunflowers', 'sunflowers', 'sunflowers', 'tulips',
       'roses', 'tulips', 'tulips'], dtype='<u10')

   plot the result
plt.figure(figsize=(10,9))
for n in range(30):
  plt.subplot(6,5,n+1)
  plt.imshow(image_batch[n])
  plt.title(labels_batch[n])
  plt.axis('off')
_ = plt.suptitle("model predictions")

   png

export your model

   now that you've trained the model, export it as a saved model:
export_path = tf.contrib.saved_model.save_keras_model(model, "./saved_models")
export_path


warning: the tensorflow contrib module will not be included in tensorflow 2.0.
for more information, please see:
  * https://github.com/tensorflow/community/blob/master/rfcs/20180907-contrib-su
nset.md
  * https://github.com/tensorflow/addons
if you depend on functionality not listed there, please file an issue.

warning:tensorflow:from /usr/local/lib/python3.5/dist-packages/tensorflow/python
/keras/engine/network.py:1436: update_checkpoint_state (from tensorflow.python.t
raining.checkpoint_management) is deprecated and will be removed in a future ver
sion.
instructions for updating:
use tf.train.checkpointmanager to manage checkpoints rather than manually editin
g the checkpoint proto.
info:tensorflow:saver not created because there are no variables in the graph to
 restore
warning:tensorflow:from /usr/local/lib/python3.5/dist-packages/tensorflow/python
/saved_model/signature_def_utils_impl.py:257: build_tensor_info (from tensorflow
.python.saved_model.utils_impl) is deprecated and will be removed in a future ve
rsion.
instructions for updating:
this function will only be available through the v1 compatibility library as tf.
compat.v1.saved_model.utils.build_tensor_info or tf.compat.v1.saved_model.build_
tensor_info.
info:tensorflow:signatures included in export for train: ['train']
info:tensorflow:signatures included in export for regress: none
info:tensorflow:signatures included in export for classify: none
info:tensorflow:signatures included in export for predict: none
info:tensorflow:signatures included in export for eval: none
warning:tensorflow:export includes no default signature!
info:tensorflow:no assets to save.
info:tensorflow:no assets to write.
info:tensorflow:saver not created because there are no variables in the graph to
 restore
info:tensorflow:signatures included in export for train: none
info:tensorflow:signatures included in export for regress: none
info:tensorflow:signatures included in export for classify: none
info:tensorflow:signatures included in export for predict: none
info:tensorflow:signatures included in export for eval: ['eval']
warning:tensorflow:export includes no default signature!
info:tensorflow:no assets to save.
info:tensorflow:no assets to write.
info:tensorflow:saver not created because there are no variables in the graph to
 restore
info:tensorflow:signatures included in export for train: none
info:tensorflow:signatures included in export for regress: none
info:tensorflow:signatures included in export for classify: none
info:tensorflow:signatures included in export for predict: ['serving_default']
info:tensorflow:signatures included in export for eval: none
info:tensorflow:no assets to save.
info:tensorflow:no assets to write.
info:tensorflow:savedmodel written to: ./saved_models/1550962723/saved_model.pb

b'./saved_models/1550962723'

   this saved model can loaded for id136 later, or converted to
   [117]tflite or [118]tfjs.

   except as otherwise noted, the content of this page is licensed under
   the [119]creative commons attribution 3.0 license, and code samples are
   licensed under the [120]apache 2.0 license. for details, see the
   [121]google developers site policies. java is a registered trademark of
   oracle and/or its affiliates.

     * stay connected
          + [122]blog
          + [123]github
          + [124]twitter
          + [125]youtube
     * support
          + [126]issue tracker
          + [127]release notes
          + [128]stack overflow
          + [129]brand guidelines

     * [130]terms
     * [131]privacy

   [english_____]

references

   visible links
   1. https://www.tensorflow.org/s/opensearch.xml
   2. https://www.tensorflow.org/
   3. https://www.tensorflow.org/install
   4. https://www.tensorflow.org/learn
   5. https://www.tensorflow.org/learn
   6. https://www.tensorflow.org/overview
   7. https://www.tensorflow.org/js
   8. https://www.tensorflow.org/lite
   9. https://www.tensorflow.org/tfx
  10. https://www.tensorflow.org/swift
  11. https://www.tensorflow.org/api_docs/python/tf
  12. https://www.tensorflow.org/api_docs/python/tf
  13. https://www.tensorflow.org/versions/r1.12/api_docs/python/tf
  14. https://www.tensorflow.org/versions/r1.11/api_docs/python/tf
  15. https://www.tensorflow.org/versions/r1.10/api_docs/python/tf
  16. https://www.tensorflow.org/versions/r1.9/api_docs/python/tf
  17. https://www.tensorflow.org/versions
  18. https://www.tensorflow.org/versions/r2.0/api_docs/python/tf
  19. https://www.tensorflow.org/resources/models-datasets
  20. https://www.tensorflow.org/resources/models-datasets
  21. https://www.tensorflow.org/resources/tools
  22. https://www.tensorflow.org/resources/libraries-extensions
  23. https://www.tensorflow.org/community
  24. https://www.tensorflow.org/about
  25. https://www.tensorflow.org/about
  26. https://www.tensorflow.org/about/case-studies
  27. https://github.com/tensorflow
  28. https://www.tensorflow.org/overview
  29. https://www.tensorflow.org/overview
  30. https://www.tensorflow.org/tutorials
  31. https://www.tensorflow.org/guide
  32. https://www.tensorflow.org/alpha
  33. https://www.tensorflow.org/install
  34. https://www.tensorflow.org/learn
  35. https://www.tensorflow.org/overview
  36. https://www.tensorflow.org/tutorials
  37. https://www.tensorflow.org/guide
  38. https://www.tensorflow.org/alpha
  39. https://www.tensorflow.org/api_docs/python/tf
  40. https://www.tensorflow.org/resources/models-datasets
  41. https://www.tensorflow.org/community
  42. https://www.tensorflow.org/about
  43. https://github.com/tensorflow
  44. https://www.tensorflow.org/tutorials
  45. https://www.tensorflow.org/tutorials/keras
  46. https://www.tensorflow.org/tutorials/keras/basic_classification
  47. https://www.tensorflow.org/tutorials/keras/basic_text_classification
  48. https://www.tensorflow.org/tutorials/keras/basic_regression
  49. https://www.tensorflow.org/tutorials/keras/overfit_and_underfit
  50. https://www.tensorflow.org/tutorials/keras/save_and_restore_models
  51. https://www.tensorflow.org/tutorials/eager
  52. https://www.tensorflow.org/tutorials/eager/eager_basics
  53. https://www.tensorflow.org/tutorials/eager/automatic_differentiation
  54. https://www.tensorflow.org/tutorials/eager/custom_training
  55. https://www.tensorflow.org/tutorials/eager/custom_layers
  56. https://www.tensorflow.org/tutorials/eager/custom_training_walkthrough
  57. https://www.tensorflow.org/tutorials/estimators/linear
  58. https://github.com/tensorflow/models/tree/master/official/wide_deep
  59. https://www.tensorflow.org/tutorials/estimators/boosted_trees
  60. https://www.tensorflow.org/tutorials/estimators/boosted_trees_model_understanding
  61. https://www.tensorflow.org/tutorials/estimators/id98
  62. https://github.com/tensorflow/tensorflow/blob/r1.13/tensorflow/contrib/eager/python/examples/id4_with_attention/id4_with_attention.ipynb
  63. https://github.com/tensorflow/tensorflow/blob/r1.13/tensorflow/contrib/eager/python/examples/generative_examples/image_captioning_with_attention.ipynb
  64. https://github.com/tensorflow/tensorflow/blob/r1.13/tensorflow/contrib/eager/python/examples/generative_examples/dcgan.ipynb
  65. https://github.com/tensorflow/tensorflow/blob/r1.13/tensorflow/contrib/eager/python/examples/generative_examples/cvae.ipynb
  66. https://www.tensorflow.org/tutorials/images/hub_with_keras
  67. https://github.com/tensorflow/tensorflow/blob/r1.13/tensorflow/contrib/eager/python/examples/pix2pix/pix2pix_eager.ipynb
  68. https://github.com/tensorflow/models/blob/master/research/nst_blogpost/4_neural_style_transfer_with_eager_execution.ipynb
  69. https://github.com/tensorflow/models/blob/master/samples/outreach/blogs/segmentation_blogpost/image_segmentation.ipynb
  70. https://www.tensorflow.org/tutorials/images/deep_id98
  71. https://www.tensorflow.org/tutorials/sequences/text_generation
  72. https://www.tensorflow.org/tutorials/sequences/recurrent
  73. https://www.tensorflow.org/tutorials/sequences/recurrent_quickdraw
  74. https://www.tensorflow.org/tutorials/sequences/audio_recognition
  75. https://github.com/tensorflow/id4
  76. https://www.tensorflow.org/tutorials/load_data/images
  77. https://www.tensorflow.org/tutorials/load_data/tf_records
  78. https://www.tensorflow.org/tutorials/representation/id97
  79. https://www.tensorflow.org/tutorials/representation/kernel_methods
  80. https://www.tensorflow.org/tutorials/representation/linear
  81. https://www.tensorflow.org/tutorials/representation/unicode
  82. https://www.tensorflow.org/tutorials/non-ml/mandelbrot
  83. https://www.tensorflow.org/tutorials/non-ml/pdes
  84. https://www.tensorflow.org/learn
  85. https://www.tensorflow.org/overview
  86. https://www.tensorflow.org/js
  87. https://www.tensorflow.org/lite
  88. https://www.tensorflow.org/tfx
  89. https://www.tensorflow.org/swift
  90. https://www.tensorflow.org/api_docs/python/tf
  91. https://www.tensorflow.org/versions/r1.12/api_docs/python/tf
  92. https://www.tensorflow.org/versions/r1.11/api_docs/python/tf
  93. https://www.tensorflow.org/versions/r1.10/api_docs/python/tf
  94. https://www.tensorflow.org/versions/r1.9/api_docs/python/tf
  95. https://www.tensorflow.org/versions
  96. https://www.tensorflow.org/versions/r2.0/api_docs/python/tf
  97. https://www.tensorflow.org/resources/models-datasets
  98. https://www.tensorflow.org/resources/tools
  99. https://www.tensorflow.org/resources/libraries-extensions
 100. https://www.tensorflow.org/about
 101. https://www.tensorflow.org/about/case-studies
 102. https://www.youtube.com/playlist?list=plqy2h8rroyvzouyi26khmksjbedn3squb
 103. https://www.tensorflow.org/
 104. https://www.tensorflow.org/learn
 105. https://www.tensorflow.org/overview
 106. https://www.tensorflow.org/tutorials
 107. https://www.tensorflow.org/tutorials/images/hub_with_keras
 108. https://colab.research.google.com/github/tensorflow/docs/blob/master/site/en/tutorials/images/hub_with_keras.ipynb
 109. https://github.com/tensorflow/docs/blob/master/site/en/tutorials/images/hub_with_keras.ipynb
 110. http://tensorflow.org/hub
 111. https://tfhub.dev/
 112. https://www.tensorflow.org/api_docs/python/tf/keras
 113. https://www.tensorflow.org/api_docs/python/tf/keras/layers/lambda
 114. https://tfhub.dev/s?module-type=image-classification
 115. https://tfhub.dev/s?module-type=image-feature-vector
 116. https://www.tensorflow.org/api_docs/python/tf/keras/models/sequential
 117. https://www.tensorflow.org/lite/convert/
 118. https://github.com/tensorflow/tfjs-converter
 119. https://creativecommons.org/licenses/by/3.0/
 120. https://www.apache.org/licenses/license-2.0
 121. https://developers.google.com/site-policies
 122. https://medium.com/tensorflow
 123. https://github.com/tensorflow/
 124. https://twitter.com/tensorflow
 125. https://youtube.com/tensorflow
 126. https://github.com/tensorflow/tensorflow/issues
 127. https://github.com/tensorflow/tensorflow/blob/master/release.md
 128. https://stackoverflow.com/questions/tagged/tensorflow
 129. https://www.tensorflow.org/extras/tensorflow_brand_guidelines.pdf
 130. https://policies.google.com/terms
 131. https://policies.google.com/privacy

   hidden links:
 133. https://www.tensorflow.org/tutorials/images/hub_with_keras
 134. https://www.tensorflow.org/tutorials/images/hub_with_keras
 135. https://www.tensorflow.org/tutorials/images/hub_with_keras
 136. https://www.tensorflow.org/tutorials/images/hub_with_keras
