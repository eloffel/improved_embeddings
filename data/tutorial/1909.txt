   #[1]analytics vidhya    feed [2]analytics vidhya    comments feed
   [3]analytics vidhya    an introduction to implementing neural networks
   using tensorflow comments feed [4]alternate [5]alternate

   iframe: [6]//googletagmanager.com/ns.html?id=gtm-mpsm42v

   [7]new certified ai & ml blackbelt program (beginner to master) -
   enroll today @ launch offer (coupon: blackbelt10)

   (button) search______________
     * [8]learn
          + [9]blog archive
               o [10]machine learning
               o [11]deep learning
               o [12]career
               o [13]stories
          + [14]datahack radio
          + [15]infographics
          + [16]training
          + [17]learning paths
               o [18]sas business analyst
               o [19]learn data science on r
               o [20]data science in python
               o [21]data science in weka
               o [22]data visualization with tableau
               o [23]data visualization with qlikview
               o [24]interactive data stories with d3.js
          + [25]glossary
     * [26]engage
          + [27]discuss
          + [28]events
          + [29]datahack summit 2018
          + [30]datahack summit 2017
          + [31]student datafest
          + [32]write for us
     * [33]compete
          + [34]hackathons
     * [35]get hired
          + [36]jobs
     * [37]courses
          + [38]id161 using deep learning
          + [39]natural language processing using python
          + [40]introduction to data science
          + [41]microsoft excel
          + [42]more courses
     * [43]contact

     *
     *
     *
     *

     * [44]home
     * [45]blog archive
     * [46]trainings
     * [47]discuss
     * [48]datahack
     * [49]jobs
     * [50]corporate

     *

   [51]analytics vidhya - learn everything about analytics

learn everything about analytics

   [52][black-belt-2.gif]
   [53][black-belt-2.gif]
   [54][black-belt-2.gif]
   (button) search______________

   [55]analytics vidhya - learn everything about analytics
     * [56]learn
          + [57]blog archive
               o [58]machine learning
               o [59]deep learning
               o [60]career
               o [61]stories
          + [62]datahack radio
          + [63]infographics
          + [64]training
          + [65]learning paths
               o [66]sas business analyst
               o [67]learn data science on r
               o [68]data science in python
               o [69]data science in weka
               o [70]data visualization with tableau
               o [71]data visualization with qlikview
               o [72]interactive data stories with d3.js
          + [73]glossary
     * [74]engage
          + [75]discuss
          + [76]events
          + [77]datahack summit 2018
          + [78]datahack summit 2017
          + [79]student datafest
          + [80]write for us
     * [81]compete
          + [82]hackathons
     * [83]get hired
          + [84]jobs
     * [85]courses
          + [86]id161 using deep learning
          + [87]natural language processing using python
          + [88]introduction to data science
          + [89]microsoft excel
          + [90]more courses
     * [91]contact

   [92]home [93]machine learning [94]an introduction to implementing
   neural networks using tensorflow

   [95]machine learning[96]python

an introduction to implementing neural networks using tensorflow

   [97]faizan shaikh, october 3, 2016

introduction

   if you have been following data science / machine learning, you just
   can   t miss the buzz around deep learning and neural
   networks. organizations are looking for people with deep learning
   skills wherever they can. from running competitions to open sourcing
   projects and paying big bonuses, people are trying every possible thing
   to tap into this limited pool of talent. self driving engineers are
   being hunted by the big guns in automobile industry, as the industry
   stands on the brink of biggest disruption it faced in last few decades!

   if you are excited by the prospects deep learning has to offer, but
   have not started your journey yet     i am here to enable it. starting
   with this article, i will write a series of articles on deep learning
   covering the popular deep learning libraries and their hands-on
   implementation.

   in this article, i will introduce tensorflow to you. after reading this
   article you will be able to understand application of neural networks
   and use tensorflow to solve a real life problem. this article will
   require you to know the basics of neural networks and have familiarity
   with programming. although the code in this article is in python, i
   have focused on the concepts and stayed as language-agnostic as
   possible.

   let   s get started!

   [98]tensorflow

table of contents

     * when to apply neural nets?
     * general way to solve problems with neural networks
     * understanding image data and popular libraries to solve it
     * what is tensorflow?
     * a typical    flow    of tensorflow
     * implementing mlp in tensorflow
     * limitations of tensorflow
     * tensorflow vs. other libraries
     * where to go from here?


when to apply neural networks ?

   neural networks have been in the spotlight for quite some time now. for
   a more detailed explanation on neural network and deep
   learning [99]read here. its    deeper    versions are making tremendous
   breakthroughs in many fields such as image recognition, speech and
   natural language processing etc.

   the main question that arises is when to and when not to apply neural
   networks? this field is like a gold mine right now, with many
   discoveries uncovered everyday. and to be a part of this    gold rush   ,
   you have to keep a few things in mind:
     * firstly, neural networks require clear and informative data (and
       mostly big data) to train. try to imagine neural networks as a
       child. it first observes how its parent walks. then it tries to
       walk on its own, and with its every step, the child learns how to
       perform a particular task. it may fall a few times, but after few
       unsuccessful attempts, it learns how to walk. if you don   t let it
       walk, it might not ever learn how to walk. the more exposure you
       can provide to the child, the better it is.
     * it is prudent to use neural networks for complex problems such as
       image processing. neural nets belong to a class of algorithms
       called representation learning algorithms. these algorithms break
       down complex problems into simpler form so that they become
       understandable (or    representable   ). think of it as chewing food
       before you gulp. this would be harder for traditional
       (non-representation learning) algorithms.
     * when you have appropriate type of neural network to solve the
       problem. each problem has its own twists. so the data decides the
       way you solve the problem. for example, if the problem is of
       sequence generation, recurrent neural networks are more suitable.
       whereas, if it is image related problem, you would probably be
       better of taking convolutional neural networks for a change.
     * last but not the least, hardware requirements are essential for
       running a deep neural network model. neural nets were    discovered   
       long ago, but they are shining in the recent years for the main
       reason that computational resources are better and more powerful.
       if you want to solve a real life problem with these networks, get
       ready to buy some high-end hardware!


general way to solve problems with neural networks

   neural networks is a special type of machine learning (ml) algorithm.
   so as every ml algorithm, it follows the usual ml workflow of data
   preprocessing, model building and model evaluation. for the sake of
   conciseness, i have listed out a to do list of how to approach a neural
   network problem.
     * check if it is a problem where neural network gives you uplift over
       traditional algorithms (refer to the checklist in the section
       above)
     * do a survey of which neural network architecture is most suitable
       for the required problem
     * define neural network architecture through which ever language /
       library you choose.
     * convert data to right format and divide it in batches
     * pre-process the data according to your needs
     * augment data to increase size and make better trained models
     * feed batches to neural network
     * train and monitor changes in training and validation data sets
     * test your model, and save it for future use

   for this article, i will be focusing on image data. so let us
   understand that first before we delve into tensorflow.


understanding image data and popular libraries to solve it

   images are mostly arranged as 3-d arrays, with the dimensions referring
   to height, width and color channel. for example, if you take a
   screenshot of your pc at this moment, it would be first convert into a
   3-d array and then compress it     .jpeg    or    .png    file formats.

   while these images are pretty easy to understand to a human, a computer
   has a hard time to understand them. this phenomenon is called    semantic
   gap   . our brain can look at the image and understand the complete
   picture in a few seconds. on the other hand, computer sees image as
   just an array of numbers. so the problem is how to we explain this
   image to the machine?

   in early days, people tried to break down the image into
      understandable    format for the machine like a    template   . for example,
   a face always has a specific structure which is somewhat preserved in
   every human, such as the position of eyes, nose or the shape of our
   face. but this method would be tedious, because when the number of
   objects to recognise would increase, the    templates    would not hold.

   fast forward to 2012, a deep neural network architecture won the
   id163 challenge, a prestigious challenge to recognise objects from
   natural scenes. it continued to reign its sovereignty in all the
   upcoming id163 challenges, thus proving the usefulness to solve
   image problems.

   so which library / language do people normally use to solve image
   recognition problems? one [100]recent survey i did that most of the
   popular deep learning libraries have interface for python, followed by
   lua, java and matlab. the most popular libraries, to name a few, are:
     * [101]caffe
     * [102]deeplearning4j
     * [103]tensorflow
     * [104]theano
     * [105]torch

   now, that  you understand how an image is stored and which are the
   common libraries used, let us look at what tensorflow has to offer.


what is tensorflow?

   lets start with the official definition,

        tensorflow is an open source software library for numerical
     computation using dataflow graphs. nodes in the graph represents
     mathematical operations, while graph edges represent
     multi-dimensional data arrays (aka tensors) communicated between
     them. the flexible architecture allows you to deploy computation to
     one or more cpus or gpus in a desktop, server, or mobile device with
     a single api.   

   [106]tensors_flowing [107]tensors_flowing

   if that sounds a bit scary     don   t worry. here is my simple definition
       look at tensorflow as nothing but numpy with a twist. if you have
   worked on numpy before, understanding tensorflow will be a piece of
   cake! a major difference between numpy and tensorflow is that
   tensorflow follows a lazy programming paradigm. it first builds a graph
   of all the operation to be done, and then when a    session    is called,
   it    runs    the graph. it   s built to be scalable, by changing internal
   data representation to tensors (aka multi-dimensional arrays). building
   a computational graph can be considered as the main ingredient of
   tensorflow. to know more about mathematical constitution of a
   computational graph, read [108]this article.

   it   s easy to classify tensorflow as a neural network library, but it   s
   not just that. yes, it was designed to be a powerful neural network
   library. but it has the power to do much more than that. you can build
   other machine learning algorithms on it such as id90 or
   k-nearest neighbors. you can literally do everything you normally would
   do in numpy! it   s aptly called    numpy on steroids   

   the advantages of using tensorflow are:
     * it has an intuitive construct, because as the name suggests it has
          flow of tensors   . you can easily visualize each and every part of
       the graph.
     * easily train on cpu/gpu for distributed computing
     * platform flexibility. you can run the models wherever you want,
       whether it is on mobile, server or pc.


a typical    flow    of tensorflow

   every library has its own    implementation details   , i.e. a way to write
   which follows its coding paradigm. for example, when implementing
   scikit-learn, you first create object of the desired algorithm, then
   build a model on train and get predictions on test set, something like
   this:
# define hyperparamters of ml algorithm
clf = id166.svc(gamma=0.001, c=100.)
# train
clf.fit(x, y)
# test
clf.predict(x_test)

   as i said earlier, tensorflow follows a lazy approach. the usual
   workflow of running a program in tensorflow is as follows:
     * build a computational graph, this can be any mathematical operation
       tensorflow supports.
     * initialize variables, to compile the variables defined previously
     * create session, this is where the magic starts!
     * run graph in session, the compiled graph is passed to the session,
       which starts its execution.
     * close session, shutdown the session.


   few terminologies used in tensoflow;
     *
placeholder: a way to feed data into the graphs
     *
feed_dict: a dictionary to pass numeric values to computational graph

   lets write a small program to add two numbers!
# import tensorflow
import tensorflow as tf

# build computational graph
a = tf.placeholder(tf.int16)
b = tf.placeholder(tf.int16)

addition = tf.add(a, b)

# initialize variables
init = tf.initialize_all_variables()

# create session and run the graph
with tf.session() as sess:
    sess.run(init)
    print "addition: %i" % sess.run(addition, feed_dict={a: 2, b: 3})

# close session
sess.close()


implementing neural network in tensorflow

   note: we could have used a different neural network architecture to
   solve this problem, but for the sake of simplicity, we settle on feed
   forward multilayer id88 with an in depth implementation.

   let us remember what we learned about neural networks first.

   a typical implementation of neural network would be as follows:
     * define neural network architecture to be compiled
     * transfer data to your model
     * under the hood, the data is first divided into batches, so that it
       can be ingested. the batches are first preprocessed, augmented and
       then fed into neural network for training
     * the model then gets trained incrementally
     * display the accuracy for a specific number of timesteps
     * after training save the model for future use
     * test the model on a new data and check how it performs

   here we solve our deep learning practice problem     [109]identify the
   digits.  let   s for a moment take a look at our problem statement.

   our problem is an image recognition, to identify digits from a given 28
   x 28 image. we have a subset of images for training and the rest for
   testing our model. so first, download the train and test files. the
   dataset contains a zipped file of all the images in the dataset and
   both the train.csv and test.csv have the name of corresponding train
   and test images. any additional features are not provided in the
   datasets, just the raw images are provided in    .png    format.

   as you know we will use tensorflow to make a neural network model. so
   you should first install tensorflow in your system. refer the[110]
   official installation guide for installation, as per your system
   specifications.

   we will follow the template as described above. create a jupyter
   notebook with python 2.7 kernel and follow the steps below.
     * let   s import all the required modules

%pylab inline

import os
import numpy as np
import pandas as pd
from scipy.misc import imread
from sklearn.metrics import accuracy_score
import tensorflow as tf
     * let   s set a seed value, so that we can control our models
       randomness

# to stop potential randomness
seed = 128
rng = np.random.randomstate(seed)
     * the first step is to set directory paths, for safekeeping!

root_dir = os.path.abspath('../..')
data_dir = os.path.join(root_dir, 'data')
sub_dir = os.path.join(root_dir, 'sub')

# check for existence
os.path.exists(root_dir)
os.path.exists(data_dir)
os.path.exists(sub_dir)
     * now let us read our datasets. these are in .csv formats, and have a
       filename along with the appropriate labels

train = pd.read_csv(os.path.join(data_dir, 'train', 'train.csv'))
test = pd.read_csv(os.path.join(data_dir, 'test.csv'))

sample_submission = pd.read_csv(os.path.join(data_dir, 'sample_submission.csv'))

train.head()

     filename label
   0 0.png    4
   1 1.png    9
   2 2.png    1
   3 3.png    7
   4 4.png    3
     * let us see what our data looks like! we read our image and display
       it.

img_name = rng.choice(train.filename)
filepath = os.path.join(data_dir, 'train', 'images', 'train', img_name)

img = imread(filepath, flatten=true)

pylab.imshow(img, cmap='gray')
pylab.axis('off')
pylab.show()

   [111]3

   the above image is represented as numpy array, as seen below

   [112]one


     * for easier data manipulation, let   s store all our images as numpy
       arrays

temp = []
for img_name in train.filename:
    image_path = os.path.join(data_dir, 'train', 'images', 'train', img_name)
    img = imread(image_path, flatten=true)
    img = img.astype('float32')
    temp.append(img)

train_x = np.stack(temp)

temp = []
for img_name in test.filename:
    image_path = os.path.join(data_dir, 'train', 'images', 'test', img_name)
    img = imread(image_path, flatten=true)
    img = img.astype('float32')
    temp.append(img)

test_x = np.stack(temp)
     * as this is a typical ml problem, to test the proper functioning of
       our model we create a validation set. let   s take a split size of
       70:30 for train set vs validation set

split_size = int(train_x.shape[0]*0.7)

train_x, val_x = train_x[:split_size], train_x[split_size:]
train_y, val_y = train.label.values[:split_size], train.label.values[split_size:
]
     * now we define some helper functions, which we use later on, in our
       programs

def dense_to_one_hot(labels_dense, num_classes=10):
    """convert class labels from scalars to one-hot vectors"""
    num_labels = labels_dense.shape[0]
    index_offset = np.arange(num_labels) * num_classes
    labels_one_hot = np.zeros((num_labels, num_classes))
    labels_one_hot.flat[index_offset + labels_dense.ravel()] = 1

    return labels_one_hot

def preproc(unclean_batch_x):
    """convert values to range 0-1"""
    temp_batch = unclean_batch_x / unclean_batch_x.max()

    return temp_batch

def batch_creator(batch_size, dataset_length, dataset_name):
    """create batch with random samples and return appropriate format"""
    batch_mask = rng.choice(dataset_length, batch_size)

    batch_x = eval(dataset_name + '_x')[[batch_mask]].reshape(-1, input_num_unit
s)
    batch_x = preproc(batch_x)

    if dataset_name == 'train':
        batch_y = eval(dataset_name).ix[batch_mask, 'label'].values
        batch_y = dense_to_one_hot(batch_y)

    return batch_x, batch_y
     * now comes the main part! let us define our neural network
       architecture. we define a neural network with 3 layers;  input,
       hidden and output. the number of neurons in input and output are
       fixed, as the input is our 28 x 28 image and the output is a 10 x 1
       vector representing the class. we take 500 neurons in the hidden
       layer. this number can vary according to your need. we also
       assign values to remaining variables. read the [113]article on
       fundamentals of neural network to know more in depth of how it
       works.

### set all variables

# number of neurons in each layer
input_num_units = 28*28
hidden_num_units = 500
output_num_units = 10

# define placeholders
x = tf.placeholder(tf.float32, [none, input_num_units])
y = tf.placeholder(tf.float32, [none, output_num_units])

# set remaining variables
epochs = 5
batch_size = 128
learning_rate = 0.01

### define weights and biases of the neural network (refer [114]this article if
you don't understand the terminologies)

weights = {
    'hidden': tf.variable(tf.random_normal([input_num_units, hidden_num_units],
seed=seed)),
    'output': tf.variable(tf.random_normal([hidden_num_units, output_num_units],
 seed=seed))
}

biases = {
    'hidden': tf.variable(tf.random_normal([hidden_num_units], seed=seed)),
    'output': tf.variable(tf.random_normal([output_num_units], seed=seed))
}
     * now create our neural networks computational graph

hidden_layer = tf.add(tf.matmul(x, weights['hidden']), biases['hidden'])
hidden_layer = tf.nn.relu(hidden_layer)

output_layer = tf.matmul(hidden_layer, weights['output']) + biases['output']
     * also, we need to define cost of our neural network

cost = tf.reduce_mean(tf.nn.softmax_cross_id178_with_logits(output_layer, y))
     * and set the optimizer, i.e. our backpropogation algorithm. here we
       use [115]adam, which is an efficient variant of id119
       algorithm. there are a number of other optimizers available in
       tensorflow (refer [116]here)

optimizer = tf.train.adamoptimizer(learning_rate=learning_rate).minimize(cost)
     * after defining our neural network architecture, let   s initialize
       all the variables

init = tf.initialize_all_variables()
     * now let us create a session, and run our neural network in the
       session. we also validate our models accuracy on validation set
       that we created

with tf.session() as sess:
    # create initialized variables
    sess.run(init)

    ### for each epoch, do:
    ###   for each batch, do:
    ###     create pre-processed batch
    ###     run optimizer by feeding batch
    ###     find cost and reiterate to minimize

    for epoch in range(epochs):
        avg_cost = 0
        total_batch = int(train.shape[0]/batch_size)
        for i in range(total_batch):
            batch_x, batch_y = batch_creator(batch_size, train_x.shape[0], 'trai
n')
            _, c = sess.run([optimizer, cost], feed_dict = {x: batch_x, y: batch
_y})

            avg_cost += c / total_batch

        print "epoch:", (epoch+1), "cost =", "{:.5f}".format(avg_cost)

    print "\ntraining complete!"


    # find predictions on val set
    pred_temp = tf.equal(tf.argmax(output_layer, 1), tf.argmax(y, 1))
    accuracy = tf.reduce_mean(tf.cast(pred_temp, "float"))
    print "validation accuracy:", accuracy.eval({x: val_x.reshape(-1, input_num_
units), y: dense_to_one_hot(val_y)})

    predict = tf.argmax(output_layer, 1)
    pred = predict.eval({x: test_x.reshape(-1, input_num_units)})

   this will be the output of the above code
epoch: 1 cost = 8.93566
epoch: 2 cost = 1.82103
epoch: 3 cost = 0.98648
epoch: 4 cost = 0.57141
epoch: 5 cost = 0.44550

training complete!
validation accuracy: 0.952823
     * to test our model with our own eyes, let   s visualize its
       predictions

img_name = rng.choice(test.filename)
filepath = os.path.join(data_dir, 'train', 'images', 'test', img_name)

img = imread(filepath, flatten=true)

test_index = int(img_name.split('.')[0]) - 49000

print "prediction is: ", pred[test_index]

pylab.imshow(img, cmap='gray')
pylab.axis('off')
pylab.show()



prediction is:  8
[117] 8
     * we see that our model performance is pretty good! now let   s create
       a submission

sample_submission.filename = test.filename

 sample_submission.label = pred

sample_submission.to_csv(os.path.join(sub_dir, 'sub01.csv'), index=false)

   and done! we just created our own trained neural network!


limitations of tensorflow

     * even though tensorflow is powerful, it   s still a low level library.
       for example, it can be considered as a machine level language. but
       for most of the purpose, you need modularity and high level
       interface such as keras
     * it   s still in development, so much more awesomeness to come!
     * it depends on your hardware specs, the more the merrier
     * still not an api for many languages.
     * there are still many things yet to be included in tensorflow, such
       as opencl support.

   most of the above mentioned are in the sights of tensorflow developers.
   they have made a roadmap for specifying how the library should be
   developed in the future.


tensorflow vs. other libraries

   tensorflow is built on similar principles as theano and torch of using
   mathematical computational graphs. but with the additional support of
   distributed computing, tensorflow comes out to be better at solving
   complex problems. also deployment of tensorflow models is already
   supported which makes it easier to use for industrial purposes, giving
   a fight to commercial libraries such as deeplearning4j, h2o and turi.
   tensorflow has apis for python, c++ and matlab. there   s also a recent
   surge for support for other languages such as ruby and r. so,
   tensorflow is trying to have a universal language support.


where to go from here?

   so you saw how to build a simple neural network with tensorflow. this
   code is meant for people to understand how to get started implementing
   tensorflow, so take it with a pinch of salt. remember that to solve
   more complex real life problems, you have to tweak the code a little
   bit.

   many of the above functions can be abstracted to give a seaid113ss
   end-to-end workflow. if you have worked with scikit-learn, you might
   know how a high level library abstracts    under the hood   
   implementations to give end-users a more easier interface. although
   tensorflow has most of the implementations already abstracted, high
   level libraries are emerging such as tf-slim and tflearn.


useful resources

     * [118]tensorflow official repository
     * rajat monga (tensorflow technical lead) [119]   tensorflow for
       everyone    video
     * [120]a curated list of dedicated resources


end notes

   i hope you found this article helpful. now, it   s time for you to
   practice and read as much as you can. good luck! if you follow a
   different approach / package / library to get started with neural
   networks, i   d love to interact with you in comments. if you have any
   more suggestions, drop in your comments below. and to gain expertise in
   working in neural network don   t forget to try out our deep learning
   practice problem     [121]identify the digits.

you can test your skills and knowledge. check out [122]live competitions and
compete with best data scientists from all over the world.

   you can also read this article on analytics vidhya's android app
   [123]get it on google play

share this:

     * [124]click to share on linkedin (opens in new window)
     * [125]click to share on facebook (opens in new window)
     * [126]click to share on twitter (opens in new window)
     * [127]click to share on pocket (opens in new window)
     * [128]click to share on reddit (opens in new window)
     *

like this:

   like loading...

related articles

   [ins: :ins]

   tags : [129]id158, [130]id158s,
   [131]deep learning, [132]google tensorflow, [133]guide on neurall
   networks, [134]neural networks, [135]neural networks using tensorflow,
   [136]tensorflow
   next article

using pyspark to perform transformations and actions on rdd

   previous article

most active data scientists, free books, notebooks & tutorials on github

[137]faizan shaikh

   faizan is a data science enthusiast and a deep learning rookie. a
   recent comp. sc. undergrad, he aims to utilize his skills to push the
   boundaries of ai research.
     *
     *

   this article is quite old and you might not get a prompt response from
   the author. we request you to post this comment on analytics vidhya's
   [138]discussion portal to get your queries resolved

81 comments

     * jerry says:
       [139]october 3, 2016 at 5:00 pm
       hi faizan, i   m new to deep learning and really appreciate your
       effort for sharing this article. i   ve downloaded the mnist dataset
       you used in this tutorial. there are 4 .gz files only, so i can   t
       understand that how to have the train.csv, test.csv and
       sample_submission.csv. please help advise me more, thanks.
       [140]reply
          + faizan shaikh says:
            [141]october 3, 2016 at 5:17 pm
            hi jerry! thanks for reading the article. this article is
            released as a solution to our practice problem    identify the
            digits   . so the datasets (train.csv, test.csv) belong to that
            ([142]https://datahack.analyticsvidhya.com/contest/practice-pr
            oblem-identify-the-digits/). download the datasets from there.
            thanks!
            [143]reply
               o jerry says:
                 [144]october 5, 2016 at 4:26 am
                 hi faizen! again thanks a lot for this article. it is
                 very useful for us beginners to move the first step
                 toward learning dl.
                 [145]reply
                    # faizan shaikh says:
                      [146]october 5, 2016 at 7:06 am
                      my pleasure. stay tuned for more!
                      [147]reply
     * pmitra says:
       [148]october 20, 2016 at 9:28 pm
       hi   
       i am having problem in reading train and test csv files. i am
       unable to program it properly. i have the files located at
       e:\av\tensorflow\test.csv and i want the above code to read this
       path. how do i set the path in the code above.
       please help.
       [149]reply
          + faizan shaikh says:
            [150]october 21, 2016 at 9:25 am
            hello pmitra,
            there are three main directory paths to specified in the code,
            * root_dir : this is the main directory in which all your
            codes and datasets are situated
            * data_dir : this is where your csv files and images are
            * sub_dir : this is where the submission you create are stored
            the structure would look similar to this:
            root_dir
            |
            |      data_dir
            |      |
            |      |      train
            |      |      |
            |      |      |      
            |      |      test.csv
            |      sub_dir
            there are checks provided in the code to check whether you
            have loaded the correct paths.
            having said that, the code provided is for your ease, and you
            could easily modify it for your purposes. for example, you
            could set directory paths as:
            root_dir =    e:\av\tensorflow   
            data_dir =    e:\av\tensorflow\data   
            sub_dir =    e:\av\tensorflow\sub   
            if you have any more problems, feel free to ask!
            [151]reply
               o pmitra says:
                 [152]october 22, 2016 at 2:50 pm
                 hi,
                 thanks for reading my post and replying but that
                 unfortunately did not help. i still get an error    file
                 does not exist    while running the above code.
                 i don   t know how to correct this..
                 my code:
                 train =
                 pd.read_csv(   e:\analytics_vidya\tflow\train\train.csv   )
                 test = pd.read_csv(   e:\analytics_vidya\tflow\test.csv   )
                 the csv files does exist but still i am unable to get
                 them pulled in the code. moreover, to add a point i am
                 using windows 7 docker to run tensorflow using ipython
                 notebook for python 2.7.
                 please help and suggest so that i can run my code
                 successfully.
                 thanks and regards.
                 [153]reply
                    # faizan shaikh says:
                      [154]october 22, 2016 at 3:16 pm
                      hello pmitra,
                      if you   re setting your directories correctly, you
                      don   t need to change any code below. did your sanity
                      checks pass?
                      # check for existence
                      print os.path.exists(root_dir)
                      print os.path.exists(data_dir)
                      print os.path.exists(sub_dir)
                      ps: if you still have difficulties, mail me
                      personally at faizankshaikh at gmail
                      [155]reply
                         @ pmitra says:
                           [156]october 23, 2016 at 12:28 pm
                           hi,
                           thank you again.
                           i have dropped you an email with my code files.
                           i have been trying various ways to run the
                           practice problem but am not able to do the same
                           at ease on docker installation of tf.
                           kindly, assist me to modify the code with an
                           workaround.
                           regards,
                           paushali
                           [157]reply
                              - faizan shaikh says:
                                [158]october 23, 2016 at 12:33 pm
                                ok. let me check
                                [159]reply
     * cosma damiano de angelis says:
       [160]november 2, 2016 at 5:13 pm
       hi fazan, thanks for the really good tutorial. i   m usually work
       with r and weka and i am very interested to have a better knowledge
       of tensorflow.
       i   ve had only the need to change two lines in your code to make it
       works for me:
       from:
       index_offset = numpy.arange(num_labels) * num_classes
       labels_one_hot = numpy.zeros((num_labels, num_classes))
       to
       index_offset = np.arange(num_labels) * num_classes
       labels_one_hot = np.zeros((num_labels, num_classes))
       thanks again
       mino
       [161]reply
          + faizan shaikh says:
            [162]november 3, 2016 at 7:13 am
            updated the code. thanks for notifying!
            [163]reply
     * [164]paramanand sahu says:
       [165]december 5, 2016 at 11:29 am
       train csv file zip is giving error .
       kindly check the file plz.
       error msg    error occured while loading the zip   
       [166]https://datahack.analyticsvidhya.com/contest/practice-problem-
       identify-the-digits/media/train_file/train_hi6augp.zip
       [167]reply
          + faizan shaikh says:
            [168]december 5, 2016 at 1:06 pm
            hi sahu, the download works fine for me. could you redownload
            and try again?
            [169]reply
               o vp says:
                 [170]april 22, 2017 at 1:58 am
                 so stupid question but how do we unzip train*.zip on
                 mac?! i am having some issues!
                 [171]reply
                    # faizan shaikh says:
                      [172]april 22, 2017 at 7:39 am
                      maybe this would help you
                      [173]https://www.lifewire.com/how-to-zip-and-unzip-f
                      iles-and-folders-on-a-mac-2260188
                      [174]reply
     * [175]paramanand sahu says:
       [176]december 6, 2016 at 8:49 am
       gui interface of ubuntu was unable to extract the file so i use cli
       and solved it.
       method 1
       but my problem did not end here.
       %pylab inline is causing error and its showing unresolved reference
       in my case.
       i have created tensor flow virtual environment for running this
       code but its not resolving.
       method 2
       i tried to run the code with ipython and all the dependencies
       installed but here error is occurring at while checking
       directories.
       please guide me regarding it.
       [177]reply
          + faizan shaikh says:
            [178]december 6, 2016 at 9:24 am
            the code is designed to be run on an ipython notebook. running
            magic functions (for example %pylab inline) would not work on
            cli.
            for issues with checking directories, refer the comments
            above.
            [179]reply
               o [180]paramanand sahu says:
                 [181]december 6, 2016 at 11:02 am
                 after debugging somehow i managed to run the code but i
                 am getting this error even after doing all steps
                 correctly.
                 attributeerror traceback (most recent call last)
                 in ()
                 26 pred_temp = tf.equal(tf.argmax(output_layer, 1),
                 tf.argmax(y, 1))
                 27 accuracy = tf.reduce_mean(tf.cast(pred_temp,    float   ))
                    > 28 print    validation accuracy:   , accuracy.eval({x:
                 val_x.reshape(-1, 784), y:
                 dense_to_one_hot(val_y.values)})
                 29
                 30 predict = tf.argmax(output_layer, 1)
                 attributeerror:    numpy.ndarray    object has no attribute
                    values   
                 [182]reply
               o faizan shaikh says:
                 [183]december 6, 2016 at 11:26 am
                 thanks for notifying, i have updated the same.
                 [184]reply
     * sumit says:
       [185]january 10, 2017 at 11:42 am
       hi faizan,
       it was great article. got a so much help and i am new in deep
       learning.
       i have a problem with    preproc    method. why do we need this method
       and why the value of seed and batch_size is 128. it will be great
       help for getting an answer.
       thanks.
       [186]reply
          + faizan shaikh says:
            [187]january 10, 2017 at 12:01 pm
            hey sumit, i   m glad you like it.
            the    preproc    method in simple words, is a id174
            step in which we do standardization (explained in detail here
            [188]https://www.analyticsvidhya.com/blog/2016/07/practical-gu
            ide-data-preprocessing-python-scikit-learn/) if you preprocess
            the data before sending it to the network, it helps in
            training (i.e. neural network converges faster)
            for batch_size and seed value, they can be set as per your
            choice. in fact, i would suggest you to try changing the
            values to see what happens.
            let me know if you need more help
            [189]reply
     * sumit says:
       [190]january 10, 2017 at 1:46 pm
       predict = tf.argmax(output_layer, 1)
       pred = predict.eval({x: test.reshape(-1, 784)})
           cannot evaluate tensor using `eval()`: no default session is
       registered. use `with sess.as_default()` or pass an explicit
       session to `eval(session=sess)`   
       why this error is showing?
       [191]reply
          + faizan shaikh says:
            [192]january 10, 2017 at 1:49 pm
            have you kept the code in the same level of indentation?
            with tf.session() as sess:
            (indent)    
            (indent)    
            (indent)    
            (indent) predict = tf.argmax(output_layer, 1)
            (indent) pred = predict.eval({x: test_x.reshape(-1, 784)})
            [193]reply
               o sumit says:
                 [194]january 10, 2017 at 1:57 pm
                 yes,
                 i exactly did it with this single session.
                 [195]reply
                    # faizan shaikh says:
                      [196]january 10, 2017 at 2:02 pm
                      can you try downloading this notebook and running it
                      on your end? let me know if it still does not work
                      [197]https://github.com/analyticsvidhya/identify_the
                      _digits/blob/master/tensorflow/notebooks/simple_neur
                      al_network.ipynb
                      [198]reply
                         @ sumit says:
                           [199]january 10, 2017 at 2:11 pm
                           sure, i will try it. and definitely notify you.
                           [200]reply
     * anand says:
       [201]january 11, 2017 at 11:38 am
       hi faizan,
       nice article! a stupid question perhaps: i see that you save the
       prediction results in submission.csv. is there a way to save the
       trained network itself (as a config perhaps) so i can use it for
       subsequent runs without having to retrain the network ?
       thanks!
       [202]reply
          + faizan shaikh says:
            [203]january 11, 2017 at 2:10 pm
            thanks anand.
            actually that   s a good question. the answer is yes, you can
            save all the individual weights and biases of a neural network
            in tensorflow. there   s a function included called
            train.saver() which does exactly this for you. refer here
            ([204]https://www.tensorflow.org/api_docs/python/state_ops/sav
            ing_and_restoring_variables)
            [205]reply
     *                                says:
       [206]january 23, 2017 at 9:55 am
       dear sir,
       thanks for your guide,
       i have tried to modify the code by myself in order to input a
       matrix that have a different size,
       and it turns out that this part of the code is not functioning:
       print    validation accuracy:   , accuracy.eval({x: val_x.reshape(-1,
       841), y:dense_to_one_hot(val_y)})
       with the error message
       valueerror: cannot feed value of shape (60, 841) for tensor
       u   placeholder_1:0   , which has shape    (?, 200)   
       at the moment, i feel that i don   t understand how this
       accuracy.eval works, can you please explain more about it? thank
       you.
       [207]reply
          + faizan shaikh says:
            [208]january 23, 2017 at 11:14 am
            hey!
            its great that you   ve tried to modify the code to meet your
            needs. could you specify which parts you changed? there might
            be something you   ve left that   s causing the problem. (ps:
            posting your code here [209]http://nbviewer.jupyter.org/ would
            be a good choice.)
            anyways, so i would describe    eval    method similar to    run   
            method. viz to compile a computational graph and pass values
            through it. here accuracy.eval passes our input feed val_x and
            val_y through the    accuracy    graph (specified as
            >>> accuracy = tf.reduce_mean(tf.cast(pred_temp,    float   ))
            ). the main difference between run and eval is that run is a
            lazy evaluation method, whereas eval does it as soon as it is
            called.
            hope it helps. if there   s anything you would like to clarify,
            feel free to comment here
            [210]reply
               o                                says:
                 [211]january 23, 2017 at 11:34 am
                 here is the code i am using at the moment
                 [212]https://docs.google.com/document/d/1jga0cxack48xkt8r
                 al75cuw3vuqj2p843eobmjdc4tc/edit?usp=sharing
                 what i am doing is feeding the network with a molecular
                 structure (29*29 matrix) and try to relate it with the
                 band gap (homo-lumo gap)
                 i am sorry that i con   t post it on the jupyter as this is
                 part of my final year project as an undergraduate
                 studying material science, but i am new to both
                 programming and machine learning   
                 [213]reply
                    # faizan shaikh says:
                      [214]january 23, 2017 at 1:58 pm
                      i went through your code and i would suggest you a
                      few things.
                      * the number    784    which i had mentioned in the code
                      (as you might have guessed correctly) is the
                      flattened input dimensions of matrix. (i.e. 28 *
                      28). there was a line in the code which you have
                      modified to (.reshape(-1, 9999) which might not be
                      correct. with your feedback i have changed the code
                      in article to input_num_units
                      * the problem you are trying to solve is to predict
                      a continuous variable, and not fixed classes. hence
                      it is a regression problem and not a classification
                      problem for which the code is originally designed
                      for. so you would have to change a few more things
                      in the code. i would leave this in your hands as a
                      learning exercise. if you need any help in that, do
                      post it here or in the discussion portal
                      ([215]https://discuss.analyticsvidhya.com/)
                      good luck!
                      [216]reply
                         @                                says:
                           [217]january 23, 2017 at 4:11 pm
                           thank you sir.
                           i will try this by myself first tomorrow     
                           thanks again.
                           [218]reply
                         @                                says:
                           [219]january 24, 2017 at 5:07 am
                           i have tried to rewrite the code into
                           autoencoder to fit the regression purpose
                           [220]https://docs.google.com/document/d/1jga0cx
                           ack48xkt8ral75cuw3vuqj2p843eobmjdc4tc/edit?usp=
                           sharing
                           but in line 66 which is this line
                           _, c = sess.run([optimizer, cost],
                           feed_dict={x: batch_xs,y: batch_ys})
                           this error message pop out
                           typeerror: the value of a feed cannot be a
                           tf.tensor object. acceptable feed values
                           include python scalars, strings, lists, or
                           numpy ndarrays.
                           from what i known, tensorflow don   t accept
                           tensor for feed_dict, but i don   t known how
                           should i change my code   
                           any help is appreciated. thank you   
                           [221]reply
                              - faizan shaikh says:
                                [222]january 24, 2017 at 7:00 pm
                                the message you got should probably give
                                you a hint. tf.train.batch is meant to
                                return a    tensor    object, but a feed_dict
                                does not allow an uninitialized object
                                (such as tensor) as input.
                                you should probably refer the above code
                                for creating batches, as you can just
                                define your own function easily.
                                let me know if the problem persists. and
                                remember to post at least the first five
                                rows of your data, because i may be making
                                wild guesses without it!
                                [223]reply
                                   =                                says:
                                     [224]january 31, 2017 at 1:15 pm
                                     dear sir,
                                     the problem of mine still exist.
                                     this is the code that i am using
                                     [225]https://docs.google.com/document
                                     /d/1jga0cxack48xkt8ral75cuw3vuqj2p843
                                     eobmjdc4tc/edit?usp=sharing
                                     this is the dataset that i am using
                                     [226]https://drive.google.com/file/d/
                                     0b9bramtid-xtbev3sddudejczza/view?usp
                                     =sharing
                                     when i try to run the code, this
                                     error message pop out
                                     valueerror: cannot feed value of
                                     shape (140, 29, 29) for tensor
                                     u   placeholder:0   , which has shape
                                        (?, 841)   
                                     at line 87
                                     _, c = sess.run([optimizer, cost],
                                     feed_dict={x: train_x, y: train_y})
                                     i still cannot solve the problem    any
                                     help is great   
                                     thank you very much.
                                     [227]reply
                                   * faizan shaikh says:
                                     [228]february 2, 2017 at 6:50 am
                                     things are getting a bit cluttered
                                     here. i   ll transfer this thread to
                                     the discussion portal.
                                     edit: here is the link
                                     [229]https://discuss.analyticsvidhya.
                                     com/t/problem-in-tensorflow-cannot-fe
                                     ed-value-of-shape-140-29-29-for-tenso
                                     r-u-placeholder-0-which-has-shape-841
                                     /15043?u=jalfaizy
     * igor says:
       [230]january 26, 2017 at 6:07 pm
       hi faizan,
       really good guide.
       but i try to execute the code with some changes:
       i.e: resize the images to 28*28 :
       temp = []
       with open(   train.csv   ) as trainfile:
       readcsv = csv.reader(trainfile, delimiter=   ,   )
       for row in readcsv:
       if (row[0] !=    filename    and row[1] !=    label    ):
       image_path = os.path.join(data_dir +    /    + row[1], row[0])
       img = imread(image_path, flatten=true)
       img.resize(size, refcheck=false)
       img = img.astype(   float32   )
       temp.append(img)
       train_x = np.stack(temp)
       and changed the num of classes to be 50 (as the letters and the
       signs i have to recognize).
       i changed also this:
       input_num_units = 28*28
       hidden_num_units = 500
       output_num_units = 50
       epochs = 5
       batch_size = 60
       learning_rate = 0.01
       and every time i run the code the accuracy is 0.
       could you help me with that ?      do you have an idea why?
       and another qouestion is what is the meaning of seed ?
       thank you in advance
       [231]reply
          + faizan shaikh says:
            [232]february 2, 2017 at 6:58 am
            hi igor,
            make sure are vectorizing your output (aka train_y). in the
            article, the function    dense_to_one_hot    does this for you
            [233]reply
     * trantrunghieu says:
       [234]february 23, 2017 at 9:27 am
       hi fizan,
       i applied your code into my dataset. my train set has 112 images
       and 8 labels. size of image is 128*128. and i only train with
       single layer (not use multilayer as your above code). my problem as
       below
       epoch: 1 cost = 0.00000
       epoch: 2 cost = 0.00000
       epoch: 3 cost = 0.00000
       epoch: 4 cost = 0.00000
       epoch: 5 cost = 0.00000
       my code:
       from collections import counter
       import os
       import numpy as np
       import pandas as pd
       from scipy.misc import imread
       import tensorflow as tf
       import cv2
       seed = 128
       rng = np.random.randomstate(seed)
       root_dir =    /home/trantrunghieu/lv   
       train = pd.read_csv(os.path.join(root_dir,   train   ,    train.csv   ))
       test = pd.read_csv(os.path.join(root_dir,   test   ,   test.csv   ))
       # sample_submission = pd.read_csv(os.path.join(data_dir,
          sample_submission.csv   ))
       train.head()
       temp = []
       for img_name in train.filename:
       image_path = os.path.join(root_dir,    train   , img_name)
       img = imread(image_path)
       img = img.astype(   float32   )
       img = tf.reshape(img,[-1])
       temp.append(img)
       train_x = np.stack(temp)
       for img_name in test.filename:
       image_path = os.path.join(root_dir,    test   , img_name)
       img = imread(image_path)
       img = img.astype(   float32   )
       img = tf.reshape(img,[-1])
       temp.append(img)
       test_x = np.stack(temp)
       # take a split size of 70:30 for train set vs validation set
       split_size = int(train_x.shape[0]*0.7)
       train_y = train.label.values[0:]
       # train_x, val_x = train_x[:split_size], train_x[split_size:]
       # train_y, val_y = train.label.values[:split_size],
       train.label.values[split_size:]
       print(train_y)
       print (counter(train_y))
       # define some function
       def dense_to_one_hot(labels_dense, num_classes=8):
                convert class labels from scalars to one-hot vectors         
       num_labels = labels_dense.shape[0]
       index_offset = np.arange(num_labels) * num_classes
       labels_one_hot = np.zeros((num_labels, num_classes))
       labels_one_hot.flat[index_offset + labels_dense.ravel()] = 1
       return labels_one_hot
       def preproc(unclean_batch_x):
                convert values to range 0-1         
       temp_batch = unclean_batch_x / unclean_batch_x.max()
       return temp_batch
       def batch_creator(batch_size, dataset_length, dataset_name):
                create batch with random samples and return appropriate
       format         
       batch_mask = rng.choice(dataset_length, batch_size)
       batch_x = eval(dataset_name +    _x   )[[batch_mask]].reshape(-1,
       input_num_units)
       batch_x = preproc(batch_x)
       if dataset_name ==    train   :
       batch_y = eval(dataset_name).ix[batch_mask,    label   ].values
       batch_y = dense_to_one_hot(batch_y)
       return batch_x, batch_y
       input_num_units = 128*128
       output_num_units = 8
       # define placeholders
       # placeholder of image
       x = tf.placeholder(tf.float32, [none, input_num_units])
       # placeholder of label
       y = tf.placeholder(tf.float32, [none, output_num_units])
       # set remaining variables
       epochs = 5
       batch_size = 128
       learning_rate = 0.01
       # create the model
       # weight
       w = tf.variable(tf.zeros([input_num_units, output_num_units]))
       # bias
       b = tf.variable(tf.zeros([output_num_units]))
       output_layer = tf.matmul(x, w) + b
       cost =
       tf.reduce_mean(tf.nn.softmax_cross_id178_with_logits(output_layer
       , y))
       optimizer =
       tf.train.adamoptimizer(learning_rate=learning_rate).minimize(cost)
       init = tf.global_variables_initializer()
       with tf.session() as sess:
       # create initialized variables
       sess.run(init)
       for epoch in range(epochs):
       avg_cost = 0
       total_batch = int(train.shape[0]/batch_size)
       for i in range(total_batch):
       batch_x, batch_y = batch_creator(batch_size, train_x.shape[0],
          train   )
       _, c = sess.run([optimizer, cost], feed_dict = {x: batch_x, y:
       batch_y})
       avg_cost += c / total_batch
       # if epoch % 200 ==0:
       print    epoch:   , (epoch+1),    cost =   ,    {:.5f}   .format(avg_cost)
       print    \ntraining complete!   
       could you help me with this problem? and how is batch_size value
       assigned? is it dependent anything?
       thank you in advance
       [235]reply
     * trantrunghieu1 says:
       [236]february 23, 2017 at 9:49 am
       i fixed above problem. cause is that my dataset length is 112 less
       than batch_size is 128. so total_batch is always 0. but, when i
       change batch_size to a number less than dataset length( such as 8),
       a new error appeard as below:
       traceback (most recent call last):
       file    draw_shape.py   , line 124, in
       batch_x, batch_y = batch_creator(batch_size, train_x.shape[0],
          train   )
       file    draw_shape.py   , line 71, in batch_creator
       batch_x = eval(dataset_name +    _x   )[[batch_mask]].reshape(-1,
       input_num_units)
       valueerror: total size of new array must be unchanged
       please help me to fix this prolem.
       [237]reply
          + faizan shaikh says:
            [238]february 23, 2017 at 10:50 am
            hey can you print the shape of batch_mask variable and check
            if its not zero?
            [239]reply
               o trantrunghieu says:
                 [240]february 23, 2017 at 12:24 pm
                 i printed batch_mask variable. and the result is below:
                 (   batch_mask:    , array([ 82, 83, 101, 82, 10, 34, 84, 57,
                 21, 75, 16, 48, 55, 47, 69, 42, 9, 0, 44, 27, 22, 51, 1,
                 42, 99, 70, 16, 30, 7, 79, 79, 20, 42, 103, 40, 72, 22,
                 71, 60, 36, 19, 39, 56, 20, 45, 23, 43, 70, 45, 20, 20,
                 10, 106, 63, 48, 89, 12, 110, 67, 111, 19, 23, 89, 40,
                 111, 4, 42, 86, 44, 15, 21, 84, 44, 17, 64, 68, 23, 89,
                 70, 10, 29, 3, 67, 108, 87, 110, 35, 29, 34, 23, 87, 4,
                 34, 29, 16, 103, 76, 23, 107, 69, 5, 9, 33, 29, 13, 103,
                 40, 4, 38, 87, 19, 102, 27, 84, 13, 101, 100, 65, 32, 44,
                 61, 46, 83, 39, 74, 31, 0, 86]))
                 0
                 epoch: 1 cost = 0.00000
                 0
                 epoch: 2 cost = 0.00000
                 0
                 epoch: 3 cost = 0.00000
                 0
                 epoch: 4 cost = 0.00000
                 0
                 epoch: 5 cost = 0.00000
                 how do i have to check and fix it?
                 [241]reply
     * ashish says:
       [242]march 2, 2017 at 5:57 am
       i use tensorflow for the review and rating and get only 60%
       accuracy.i have a data of size 5000 and vary hidden layer
       from100-1000 and iteration 10000-100000.so how can i improve the
       accuracy with this data ??
       [243]reply
          + faizan shaikh says:
            [244]may 24, 2017 at 9:00 am
            you can try using a better architecture than mlp, for example,
            you can use id56 if the review data is textual sentences. i
            have discussed some of these tweaks in this article:
            [245]https://www.analyticsvidhya.com/blog/2016/10/tutorial-opt
            imizing-neural-networks-using-keras-with-image-recognition-cas
            e-study/
            [246]reply
     * y says:
       [247]march 4, 2017 at 6:42 pm
       1. why biases don   t have their own weights?
       2.
       hidden_layer = tf.add(tf.matmul(x, weights[   hidden   ]),
       biases[   hidden   ])
       output_layer = tf.matmul(hidden_layer, weights[   output   ]) +
       biases[   output   ]
       is there any difference between tf.add and +?
       thanks
       [248]reply
          + faizan shaikh says:
            [249]may 24, 2017 at 8:58 am
            1. bias have been defined separately from weights. you can
            refer the code
            2. even when you use    +    operator, it is converted to    tf.add   
            which is a more optimized function. so for all practical
            purposes, they are the same
            [250]reply
     * m amer says:
       [251]april 1, 2017 at 6:45 pm
       a.a!
       thank you for this helpful material.
       i was working on this project and i found the following error
       invalidargumenterror: logits and labels must be same size:
       logits_size=[512,10] labels_size=[128,10]
       [[node: softmaxcrossid178withlogits_2 =
       softmaxcrossid178withlogits[t=dt_float,
       _device=   /job:localhost/replica:0/task:0/cpu:0   ](reshape_6,
       reshape_7)]]
       during handling of the above exception, another exception occurred:
       invalidargumenterror traceback (most recent call last)
       in ()
       14 for i in range(total_batch):
       15 batch_x, batch_y = batch_creator(batch_size, train_x.shape[0],
          train   )
          > 16 _, c = sess.run([optimizer, cost], feed_dict = {x: batch_x,
       y: batch_y})
       17
       18 avg_cost += c / total_batch
       i tried my best(apply different google solutions) to solve it but
       it still remain. i will be grateful if you help me to solve it. :
       [252]reply
          + faizan shaikh says:
            [253]may 24, 2017 at 9:03 am
            check if the length of input (batch_x) you are passing is the
            same as length of output (batch_y)
            [254]reply
     * deepak says:
       [255]april 18, 2017 at 7:04 pm
       hi faizan,
       i am currently working on image dataset. eg. train dataset has
       multiple sub folders like automobiles, flowers, bikes and each
       folders having 100 images of different size. labels are given as
       subfloders name. how do i read these images in python from each
       folders and create single training set. as i read online we need to
       resize all images into same size to input in tensorflow. i am using
       windows machine so not be able to use opencv3 also.
       please help me out.
       [256]reply
          + faizan shaikh says:
            [257]may 24, 2017 at 9:02 am
            hi deepak. you can use keras for this purpose, as it directly
            reads subfolders and assigns classes with respect to it
            [258]reply
     * [259]tushar says:
       [260]may 30, 2017 at 3:18 pm
       hi faizan,
       great post. a quick question , i was going through the nn network
       from various materials and it got me a bit confused. why are we not
       using an relu activation in the output layer ?
       i did try implement it and my cost stopped reducing after a point
       leading to poor accuracy(clearly it is incorrect). can you sum up
       or point me in a direction where i can better understand this.
       [261]reply
          + faizan shaikh says:
            [262]june 15, 2017 at 7:29 pm
            in the output layer, your aim is to predict classes (if its a
            classification problem) or to predict continuous values (if
            its a regression problem). so you would use an appropriate
            activation function. in a classification problem, you
            generally use sigmoid or softmax function, whereas in
            regression you use a linear function
            [263]reply
     * atana says:
       [264]june 8, 2017 at 11:12 am
       hello faizan,can u please give a clear picture of what you are
       doing in the batch_creator function.
       batch_y = eval(dataset_name).ix[batch_mask,    label   ].values
       what is the .ix here and what is    label   ?
       since i am trying use this code for training my own dataset,it will
       be useful for me to know this function.
       thank you.
       [265]reply
          + faizan shaikh says:
            [266]july 8, 2017 at 5:19 pm
            hi atana, .ix is a pandas function
            ([267]http://pandas.pydata.org/pandas-docs/version/0.19.2/gene
            rated/pandas.dataframe.ix.html) and    label    represents the
            label column that is that target variable. here i am simply
            trying to extract the respective targets for the batches
            [268]reply
     * m2gr8 says:
       [269]june 9, 2017 at 4:12 pm
       faizan,
       can you explain what this part of code is performing, i had
       encountered an error    logits and labels must be same size:
       logits_size=[118,3] labels_size=[128,3]   .
       i tracked where was my tensor variable size going incorrect and it
       was below code which dint calculated expected batch size as per the
       specified inputs.
       batch_x = eval(dataset_name +    _x   )[[batch_mask]].reshape(-1,
       (input_num_units))
       some below debug variables size :    
       batch_mask: 128
       dataset_name: train
       input_num_units: 9216
       batch_x: (118, 9216)
       unclean_batch_x: (118, 9216)
       unclean_batch_x max: 160.0
       batch_y: (128, 3)
       [270]reply
          + faizan shaikh says:
            [271]june 15, 2017 at 7:23 pm
            the number of elements in batch_x and batch_y should match. in
            your problem, one is 128 and the other 118. both should be the
            same
            [272]reply
     * sayak paul says:
       [273]june 18, 2017 at 12:17 pm
       that was a very informative post as i am just getting started with
       tf.
       it would be very much appreciated if you elaborate this line of
       code:
       filepath = os.path.join(data_dir,    train   ,    images   ,    train   ,
       img_name)
       [274]reply
          + faizan shaikh says:
            [275]july 8, 2017 at 5:21 pm
            hi sayak, here i am defining the file path. so instead of
            directly setting it as    e:\workspace\train\images       , i am
            writing a more generalized code by using python   s    os    library
            [276]reply
     * sayak paul says:
       [277]june 18, 2017 at 1:08 pm
       getting the following error after running the code for assigning
       the cost:
                                                                                  
       valueerror traceback (most recent call last)
       in ()
          -> 1 cost =
       tf.reduce_mean(tf.nn.softmax_cross_id178_with_logits(output_layer
       , y))
       2 optimizer =
       tf.train.adamoptimizer(learning_rate=learning_rate).minimize(cost)
       3
       4 init = tf.initialize_all_variables()
       /home/sayak/anaconda3/envs/py27/lib/python2.7/site-packages/tensorf
       low/python/ops/nn_ops.pyc in
       softmax_cross_id178_with_logits(_sentinel, labels, logits, dim,
       name)
       1605          
       1606 _ensure_xent_args(   softmax_cross_id178_with_logits   ,
       _sentinel,
       -> 1607 labels, logits)
       1608
       1609 # todo(pcmurray) raise an error when the labels do not sum to
       1. note: this
       /home/sayak/anaconda3/envs/py27/lib/python2.7/site-packages/tensorf
       low/python/ops/nn_ops.pyc in _ensure_xent_args(name, sentinel,
       labels, logits)
       1560 if sentinel is not none:
       1561 raise valueerror(   only call `%s` with    
       -> 1562    named arguments (labels=   , logits=   ,    )    % name)
       1563 if labels is none or logits is none:
       1564 raise valueerror(   both labels and logits must be provided.   )
       valueerror: only call `softmax_cross_id178_with_logits` with
       named arguments (labels=   , logits=   ,    )
       [278]reply
          + faizan shaikh says:
            [279]july 8, 2017 at 5:37 pm
            hi, write this code line instead:
            cost =
            tf.reduce_mean(tf.nn.softmax_cross_id178_with_logits(logits=
            output_layer, labels=y))
            [280]reply
     * kishore says:
       [281]july 27, 2017 at 2:49 pm
       hi
       this blog is very useful for me.
       and which type neural network it is, i mean it id98 or id56.
       regards,
       kishore
       [282]reply
          + faizan shaikh says:
            [283]august 17, 2017 at 5:08 pm
            hi, its a simple neural network; a multi layer id88
            [284]reply
     * vicky shi says:
       [285]august 3, 2017 at 11:46 pm
       hi faizan,
       thank you for the article. it is really practical. my problem is i
       can   t download the data from the practice problem page. i clicked
       data on the left, but it does nothing.
       thank you
       [286]reply
          + vicky shi says:
            [287]august 4, 2017 at 1:31 am
            problem fixed. thank you.
            [288]reply
               o faizan shaikh says:
                 [289]august 17, 2017 at 5:05 pm
                 glad it worked out.
                 [290]reply
     * vijay gupta says:
       [291]september 28, 2017 at 3:26 pm
       hi faizan,
       recently i started learning, about deep learning, neural network
       and possible way to accelerate all computation through gpu, and i
       went through lots of ieee paper and then i come across this blog
       and i must appreciate that this is the only place (being beginner)
       where i found all required information presented very cleanly right
       from start, till character prediction.
       great work!!
       [292]reply
          + faizan shaikh says:
            [293]october 13, 2017 at 12:13 pm
            thanks vijay
            [294]reply
               o vijay says:
                 [295]november 7, 2017 at 6:23 pm
                 hi faizan,
                 i am able to run this code with minimal modification fine
                 on cpu side. for performance evaluation i tried to port
                 same code to gpu but couldn   t succeed. could you
                 provide/point me some direction or document that i could
                 refer to get some help here?
                 thanks! in anticipation.
                 thanks,
                 vijay.
                 [296]reply
                    # faizan shaikh says:
                      [297]november 16, 2017 at 6:07 pm
                      you can check out the official documentation for
                      this
                      [298]reply
     * e says:
       [299]october 9, 2017 at 8:29 pm
       can anyone tell why this code is not producing poper output
       import tensorflow as tf
       x=tf.placeholder(tf.float32,shape=[none,1])
       y_=tf.placeholder(tf.float32,shape=[none,1])
       w=tf.variable(tf.zeros([1,1]))
       b=tf.variable(tf.zeros([1]))
       y=tf.matmul(x,w)+b
       init=tf.global_variables_initializer()
       cross_id178=tf.nn.softmax_cross_id178_with_logits(labels=y_,log
       its=y)
       train_step=tf.train.gradientdescentoptimizer(0.6).minimize(cross_en
       tropy)
       sess=tf.interactivesession()
       sess.run(init)
       for e in range(100):
       sess.run([train_step,cross_id178],feed_dict={x:[[1],[2]],y_:[[1],
       [2]]})
       print(sess.run([w,b]))
       correct_prediction=tf.equal(tf.arg_max(y,1),tf.arg_max(y_,1))
       accuracy=tf.reduce_mean(tf.cast(correct_prediction,tf.float32))
       print(accuracy.eval(feed_dict={x:[[2]], y_: [[6]]}))
       sess.close()
       [300]reply
          + faizan shaikh says:
            [301]october 13, 2017 at 12:15 pm
            hi,
            assuming there   s no syntax errors/indentation errors; what
            error does the code show?
            [302]reply
     * muhammad sohail khan says:
       [303]october 13, 2017 at 12:03 am
       i face this problem, i don   t know why other people did not face it.
       temp = []
       for img_name in test.filename:
       image_path = os.path.join(data_dir,    train   ,    images   ,    test   ,
       img_name)
       img = imread(image_path, flatten=true)
       img = img.astype(   float32   )
       temp.append(img)
       test_x = np.stack(temp)
       error output
       attributeerror traceback (most recent call last)
       in ()
       9
       10 temp = []
          > 11 for img_name in test.filename:
       12 image_path = os.path.join(data_dir,    train   ,    images   ,    test   ,
       img_name)
       13 img = imread(image_path, flatten=true)
       ~\anaconda3\envs\tensorflow\lib\site-packages\pandas\core\generic.p
       y in __getattr__(self, name)
       3079 if name in self._info_axis:
       3080 return self[name]
       -> 3081 return object.__getattribute__(self, name)
       3082
       3083 def __setattr__(self, name, value):
       attributeerror:    dataframe    object has no attribute    filename   
       i checked the test.csv file and there is no filename field. i may
       have wrong test.csv file, can you please mention me the correct
       file to download.
       thanks
       [304]reply
          + faizan shaikh says:
            [305]october 13, 2017 at 12:19 pm
            hi sohail,
            you can find the dataset here:
            [306]https://datahack.analyticsvidhya.com/contest/practice-pro
            blem-identify-the-digits/
            [307]reply
               o sohailkhan says:
                 [308]october 13, 2017 at 1:46 pm
                 thanks faizan for the quick reply.
                 i have downloaded the training data from the above zip
                 file you provided in the comments to someone and that   s
                 fine according to the above coding which contains the
                 filename field and we can loop through that train.csv
                 file, but as for as the test.csv file is concerned it
                 does not contain filename field and in the above code, we
                 are going to loop through the file to store it in python
                 array for which i am getting an error. i have gone
                 through the link you provided but i am getting strange
                 kind of data set and i am unable to get test.csv file, if
                 kindly you can provide me the test.csv file will be
                 thankful.
                 [309]reply
                    # faizan shaikh says:
                      [310]november 16, 2017 at 6:16 pm
                      maybe the dataset that you downloaded might be
                      corrupted. please check the dataset again
                      [311]reply
     * noufal says:
       [312]december 7, 2017 at 11:07 am
       hello sir,
       i am rewriting this code to train another set of data which is
       image dataset of 20,000. but the image size varying in every image
       so i am unable to create the training and test set. can you please
       suggest a solution.
       [313]reply
          + faizan shaikh says:
            [314]december 7, 2017 at 2:03 pm
            hey     you can force all the images to be of the same size
            using scipy   s misc package
            [315]reply
     * dxf says:
       [316]march 26, 2018 at 5:10 pm
       hi ! the datasets (train.csv, test.csv) belong to that
       ([317]https://datahack.analyticsvidhya.com/contest/practice-problem
       -identify-the-digits/) can not to be download .how can i get it ? .
       thanks!
       [318]reply
          + faizan shaikh says:
            [319]march 27, 2018 at 4:12 pm
            hi     you would have to register to the hackathon to access the
            dataset
            [320]reply

   [ins: :ins]

top analytics vidhya users

   rank                  name                  points
   1    [1.jpg?date=2019-04-05] [321]srk       3924
   2    [2.jpg?date=2019-04-05] [322]mark12    3510
   3    [3.jpg?date=2019-04-05] [323]nilabha   3261
   4    [4.jpg?date=2019-04-05] [324]nitish007 3237
   5    [5.jpg?date=2019-04-05] [325]tezdhar   3082
   [326]more user rankings
   [ins: :ins]
   [ins: :ins]

popular posts

     * [327]24 ultimate data science projects to boost your knowledge and
       skills (& can be accessed freely)
     * [328]understanding support vector machine algorithm from examples
       (along with code)
     * [329]essentials of machine learning algorithms (with python and r
       codes)
     * [330]a complete tutorial to learn data science with python from
       scratch
     * [331]7 types of regression techniques you should know!
     * [332]6 easy steps to learn naive bayes algorithm (with codes in
       python and r)
     * [333]a simple introduction to anova (with applications in excel)
     * [334]stock prices prediction using machine learning and deep
       learning techniques (with python codes)

   [ins: :ins]

recent posts

   [335]top 5 machine learning github repositories and reddit discussions
   from march 2019

[336]top 5 machine learning github repositories and reddit discussions from
march 2019

   april 4, 2019

   [337]id161 tutorial: a step-by-step introduction to image
   segmentation techniques (part 1)

[338]id161 tutorial: a step-by-step introduction to image
segmentation techniques (part 1)

   april 1, 2019

   [339]nuts and bolts of id23: introduction to temporal
   difference (td) learning

[340]nuts and bolts of id23: introduction to temporal
difference (td) learning

   march 28, 2019

   [341]16 opencv functions to start your id161 journey (with
   python code)

[342]16 opencv functions to start your id161 journey (with python
code)

   march 25, 2019

   [343][ds-finhack.jpg]

   [344][hikeathon.png]

   [av-white.d14465ee4af2.png]

analytics vidhya

     * [345]about us
     * [346]our team
     * [347]career
     * [348]contact us
     * [349]write for us

   [350]about us
   [351]   
   [352]our team
   [353]   
   [354]careers
   [355]   
   [356]contact us

data scientists

     * [357]blog
     * [358]hackathon
     * [359]discussions
     * [360]apply jobs
     * [361]leaderboard

companies

     * [362]post jobs
     * [363]trainings
     * [364]hiring hackathons
     * [365]advertising
     * [366]reach us

   don't have an account? [367]sign up here.

join our community :

   [368]46336 [369]followers
   [370]20220 [371]followers
   [372]followers
   [373]7513 [374]followers
   ____________________ >

      copyright 2013-2019 analytics vidhya.
     * [375]privacy policy
     * [376]terms of use
     * [377]refund policy

   don't have an account? [378]sign up here

   iframe: [379]likes-master

   %d bloggers like this:

   [loading.gif]
   ____________________

   ____________________

   ____________________
   [button input] (not implemented)_________________

   download resource

join the nextgen data science ecosystem

     * learn: get access to some of the best courses on data science
       created by us
     * engage: interact with thousands of data science professionals
       across the globe!
     * compete: compete in our hackathons and win exciting prizes
     * get hired: get information of jobs in data science community and
       build your profile

   [380](button) join now

   subscribe!

   iframe: [381]likes-master

   %d bloggers like this:

   [loading.gif]
   ____________________

   ____________________

   ____________________
   [button input] (not implemented)_________________

   download resource

join the nextgen data science ecosystem

     * learn: get access to some of the best courses on data science
       created by us
     * engage: interact with thousands of data science professionals
       across the globe!
     * compete: compete in our hackathons and win exciting prizes
     * get hired: get information of jobs in data science community and
       build your profile

   [382](button) join now

   subscribe!

references

   visible links
   1. https://www.analyticsvidhya.com/feed/
   2. https://www.analyticsvidhya.com/comments/feed/
   3. https://www.analyticsvidhya.com/blog/2016/10/an-introduction-to-implementing-neural-networks-using-tensorflow/feed/
   4. https://www.analyticsvidhya.com/wp-json/oembed/1.0/embed?url=https://www.analyticsvidhya.com/blog/2016/10/an-introduction-to-implementing-neural-networks-using-tensorflow/
   5. https://www.analyticsvidhya.com/wp-json/oembed/1.0/embed?url=https://www.analyticsvidhya.com/blog/2016/10/an-introduction-to-implementing-neural-networks-using-tensorflow/&format=xml
   6. https://googletagmanager.com/ns.html?id=gtm-mpsm42v
   7. https://courses.analyticsvidhya.com/bundles/ai-blackbelt-beginner-to-master?utm_source=blog&utm_medium=flashstrip
   8. https://www.analyticsvidhya.com/blog/2016/10/an-introduction-to-implementing-neural-networks-using-tensorflow/
   9. https://www.analyticsvidhya.com/blog-archive/
  10. https://www.analyticsvidhya.com/blog/category/machine-learning/
  11. https://www.analyticsvidhya.com/blog/category/deep-learning/
  12. https://www.analyticsvidhya.com/blog/category/career/
  13. https://www.analyticsvidhya.com/blog/category/stories/
  14. https://www.analyticsvidhya.com/blog/category/podcast/
  15. https://www.analyticsvidhya.com/blog/category/infographics/
  16. https://courses.analyticsvidhya.com/?utm_source=home_blog_navbar
  17. https://www.analyticsvidhya.com/learning-paths-data-science-business-analytics-business-intelligence-big-data/
  18. https://www.analyticsvidhya.com/learning-paths-data-science-business-analytics-business-intelligence-big-data/learning-path-business-analyst-sas/
  19. https://www.analyticsvidhya.com/learning-paths-data-science-business-analytics-business-intelligence-big-data/learning-path-r-data-science/
  20. https://www.analyticsvidhya.com/learning-paths-data-science-business-analytics-business-intelligence-big-data/learning-path-data-science-python/
  21. https://www.analyticsvidhya.com/learning-paths-data-science-business-analytics-business-intelligence-big-data/weka-gui-learn-machine-learning/
  22. https://www.analyticsvidhya.com/learning-paths-data-science-business-analytics-business-intelligence-big-data/tableau-learning-path/
  23. https://www.analyticsvidhya.com/learning-paths-data-science-business-analytics-business-intelligence-big-data/qlikview-learning-path/
  24. https://www.analyticsvidhya.com/learning-paths-data-science-business-analytics-business-intelligence-big-data/newbie-d3-js-expert-complete-path-create-interactive-visualization-d3-js/
  25. https://www.analyticsvidhya.com/glossary-of-common-statistics-and-machine-learning-terms/
  26. https://www.analyticsvidhya.com/blog/2016/10/an-introduction-to-implementing-neural-networks-using-tensorflow/
  27. https://discuss.analyticsvidhya.com/
  28. https://www.analyticsvidhya.com/blog/category/events/
  29. https://www.analyticsvidhya.com/datahack-summit-2018/
  30. https://www.analyticsvidhya.com/datahacksummit/
  31. https://www.analyticsvidhya.com/student-datafest-2018/?utm_source=homepage_menu
  32. http://www.analyticsvidhya.com/about-me/write/
  33. https://www.analyticsvidhya.com/blog/2016/10/an-introduction-to-implementing-neural-networks-using-tensorflow/
  34. https://datahack.analyticsvidhya.com/contest/all
  35. https://www.analyticsvidhya.com/blog/2016/10/an-introduction-to-implementing-neural-networks-using-tensorflow/
  36. https://www.analyticsvidhya.com/jobs/
  37. https://courses.analyticsvidhya.com/
  38. https://courses.analyticsvidhya.com/courses/computer-vision-using-deep-learning/?utm_source=blog-navbar&utm_medium=web
  39. https://courses.analyticsvidhya.com/courses/natural-language-processing-nlp/?utm_source=blog-navbar&utm_medium=web
  40. https://courses.analyticsvidhya.com/courses/introduction-to-data-science-2/?utm_source=blog-navbar&utm_medium=web
  41. https://courses.analyticsvidhya.com/courses/microsoft-excel-beginners-to-advanced/?utm_source=blog-navbar&utm_medium=web
  42. https://courses.analyticsvidhya.com/collections/?utm_source=blog-navbar&utm_medium=web
  43. https://www.analyticsvidhya.com/contact/
  44. https://www.analyticsvidhya.com/
  45. https://www.analyticsvidhya.com/blog-archive/
  46. https://courses.analyticsvidhya.com/?utm_source=home_blog_navbar
  47. https://discuss.analyticsvidhya.com/
  48. https://datahack.analyticsvidhya.com/
  49. https://www.analyticsvidhya.com/jobs/
  50. https://www.analyticsvidhya.com/corporate/
  51. https://www.analyticsvidhya.com/blog/
  52. https://courses.analyticsvidhya.com/bundles/ai-blackbelt-beginner-to-master?utm_source=avtopbanner&utm_medium=display
  53. https://courses.analyticsvidhya.com/bundles/ai-blackbelt-beginner-to-master?utm_source=avtopbanner&utm_medium=display
  54. https://courses.analyticsvidhya.com/bundles/ai-blackbelt-beginner-to-master?utm_source=avtopbanner&utm_medium=display
  55. https://www.analyticsvidhya.com/blog/
  56. https://www.analyticsvidhya.com/blog/2016/10/an-introduction-to-implementing-neural-networks-using-tensorflow/
  57. https://www.analyticsvidhya.com/blog-archive/
  58. https://www.analyticsvidhya.com/blog/category/machine-learning/
  59. https://www.analyticsvidhya.com/blog/category/deep-learning/
  60. https://www.analyticsvidhya.com/blog/category/career/
  61. https://www.analyticsvidhya.com/blog/category/stories/
  62. https://www.analyticsvidhya.com/blog/category/podcast/
  63. https://www.analyticsvidhya.com/blog/category/infographics/
  64. https://courses.analyticsvidhya.com/?utm_source=home_blog_navbar
  65. https://www.analyticsvidhya.com/learning-paths-data-science-business-analytics-business-intelligence-big-data/
  66. https://www.analyticsvidhya.com/learning-paths-data-science-business-analytics-business-intelligence-big-data/learning-path-business-analyst-sas/
  67. https://www.analyticsvidhya.com/learning-paths-data-science-business-analytics-business-intelligence-big-data/learning-path-r-data-science/
  68. https://www.analyticsvidhya.com/learning-paths-data-science-business-analytics-business-intelligence-big-data/learning-path-data-science-python/
  69. https://www.analyticsvidhya.com/learning-paths-data-science-business-analytics-business-intelligence-big-data/weka-gui-learn-machine-learning/
  70. https://www.analyticsvidhya.com/learning-paths-data-science-business-analytics-business-intelligence-big-data/tableau-learning-path/
  71. https://www.analyticsvidhya.com/learning-paths-data-science-business-analytics-business-intelligence-big-data/qlikview-learning-path/
  72. https://www.analyticsvidhya.com/learning-paths-data-science-business-analytics-business-intelligence-big-data/newbie-d3-js-expert-complete-path-create-interactive-visualization-d3-js/
  73. https://www.analyticsvidhya.com/glossary-of-common-statistics-and-machine-learning-terms/
  74. https://www.analyticsvidhya.com/blog/2016/10/an-introduction-to-implementing-neural-networks-using-tensorflow/
  75. https://discuss.analyticsvidhya.com/
  76. https://www.analyticsvidhya.com/blog/category/events/
  77. https://www.analyticsvidhya.com/datahack-summit-2018/
  78. https://www.analyticsvidhya.com/datahacksummit/
  79. https://www.analyticsvidhya.com/student-datafest-2018/?utm_source=homepage_menu
  80. http://www.analyticsvidhya.com/about-me/write/
  81. https://www.analyticsvidhya.com/blog/2016/10/an-introduction-to-implementing-neural-networks-using-tensorflow/
  82. https://datahack.analyticsvidhya.com/contest/all
  83. https://www.analyticsvidhya.com/blog/2016/10/an-introduction-to-implementing-neural-networks-using-tensorflow/
  84. https://www.analyticsvidhya.com/jobs/
  85. https://courses.analyticsvidhya.com/
  86. https://courses.analyticsvidhya.com/courses/computer-vision-using-deep-learning/?utm_source=blog-navbar&utm_medium=web
  87. https://courses.analyticsvidhya.com/courses/natural-language-processing-nlp/?utm_source=blog-navbar&utm_medium=web
  88. https://courses.analyticsvidhya.com/courses/introduction-to-data-science-2/?utm_source=blog-navbar&utm_medium=web
  89. https://courses.analyticsvidhya.com/courses/microsoft-excel-beginners-to-advanced/?utm_source=blog-navbar&utm_medium=web
  90. https://courses.analyticsvidhya.com/collections/?utm_source=blog-navbar&utm_medium=web
  91. https://www.analyticsvidhya.com/contact/
  92. https://www.analyticsvidhya.com/
  93. https://www.analyticsvidhya.com/blog/category/machine-learning/
  94. https://www.analyticsvidhya.com/blog/2016/10/an-introduction-to-implementing-neural-networks-using-tensorflow/
  95. https://www.analyticsvidhya.com/blog/category/machine-learning/
  96. https://www.analyticsvidhya.com/blog/category/python-2/
  97. https://www.analyticsvidhya.com/blog/author/jalfaizy/
  98. https://www.analyticsvidhya.com/wp-content/uploads/2016/10/maxresdefault-1.jpg
  99. https://www.analyticsvidhya.com/blog/2016/08/evolution-core-concepts-deep-learning-neural-networks/
 100. https://www.analyticsvidhya.com/blog/2016/08/deep-learning-path/
 101. http://caffe.berkeleyvision.org/
 102. http://deeplearning4j.org/
 103. https://www.tensorflow.org/
 104. http://www.deeplearning.net/software/theano
 105. http://torch.ch/
 106. https://www.analyticsvidhya.com/wp-content/uploads/2016/10/tensors_flowing.gif
 107. https://www.analyticsvidhya.com/wp-content/uploads/2016/10/tensors_flowing-3.gif
 108. http://colah.github.io/posts/2015-08-backprop/
 109. https://datahack.analyticsvidhya.com/contest/practice-problem-identify-the-digits/
 110. https://github.com/tensorflow/tensorflow/blob/master/tensorflow/g3doc/get_started/os_setup.md
 111. https://www.analyticsvidhya.com/wp-content/uploads/2016/10/3.png
 112. https://www.analyticsvidhya.com/wp-content/uploads/2016/10/one.png
 113. https://www.analyticsvidhya.com/blog/2016/03/introduction-deep-learning-fundamentals-neural-networks/
 114. https://www.analyticsvidhya.com/blog/2016/03/introduction-deep-learning-fundamentals-neural-networks/
 115. https://arxiv.org/abs/1412.6980
 116. https://www.tensorflow.org/versions/r0.11/api_docs/python/train.html#optimizers
 117. https://www.analyticsvidhya.com/wp-content/uploads/2016/10/8.png
 118. https://github.com/tensorflow/tensorflow
 119. https://youtu.be/wmw8bbb_eie
 120. https://github.com/jtoy/awesome-tensorflow/#github-projects
 121. https://datahack.analyticsvidhya.com/contest/practice-problem-identify-the-digits/
 122. http://datahack.analyticsvidhya.com/contest/all
 123. https://play.google.com/store/apps/details?id=com.analyticsvidhya.android&utm_source=blog_article&utm_campaign=blog&pcampaignid=mkt-other-global-all-co-prtnr-py-partbadge-mar2515-1
 124. https://www.analyticsvidhya.com/blog/2016/10/an-introduction-to-implementing-neural-networks-using-tensorflow/?share=linkedin
 125. https://www.analyticsvidhya.com/blog/2016/10/an-introduction-to-implementing-neural-networks-using-tensorflow/?share=facebook
 126. https://www.analyticsvidhya.com/blog/2016/10/an-introduction-to-implementing-neural-networks-using-tensorflow/?share=twitter
 127. https://www.analyticsvidhya.com/blog/2016/10/an-introduction-to-implementing-neural-networks-using-tensorflow/?share=pocket
 128. https://www.analyticsvidhya.com/blog/2016/10/an-introduction-to-implementing-neural-networks-using-tensorflow/?share=reddit
 129. https://www.analyticsvidhya.com/blog/tag/artificial-neural-network/
 130. https://www.analyticsvidhya.com/blog/tag/artificial-neural-networks/
 131. https://www.analyticsvidhya.com/blog/tag/deep-learning/
 132. https://www.analyticsvidhya.com/blog/tag/google-tensorflow/
 133. https://www.analyticsvidhya.com/blog/tag/guide-on-neurall-networks/
 134. https://www.analyticsvidhya.com/blog/tag/neural-networks/
 135. https://www.analyticsvidhya.com/blog/tag/neural-networks-using-tensorflow/
 136. https://www.analyticsvidhya.com/blog/tag/tensorflow/
 137. https://www.analyticsvidhya.com/blog/author/jalfaizy/
 138. https://discuss.analyticsvidhya.com/
 139. https://www.analyticsvidhya.com/blog/2016/10/an-introduction-to-implementing-neural-networks-using-tensorflow/#comment-116727
 140. https://www.analyticsvidhya.com/blog/2016/10/an-introduction-to-implementing-neural-networks-using-tensorflow/#comment-116727
 141. https://www.analyticsvidhya.com/blog/2016/10/an-introduction-to-implementing-neural-networks-using-tensorflow/#comment-116728
 142. https://datahack.analyticsvidhya.com/contest/practice-problem-identify-the-digits/
 143. https://www.analyticsvidhya.com/blog/2016/10/an-introduction-to-implementing-neural-networks-using-tensorflow/#comment-116728
 144. https://www.analyticsvidhya.com/blog/2016/10/an-introduction-to-implementing-neural-networks-using-tensorflow/#comment-116803
 145. https://www.analyticsvidhya.com/blog/2016/10/an-introduction-to-implementing-neural-networks-using-tensorflow/#comment-116803
 146. https://www.analyticsvidhya.com/blog/2016/10/an-introduction-to-implementing-neural-networks-using-tensorflow/#comment-116808
 147. https://www.analyticsvidhya.com/blog/2016/10/an-introduction-to-implementing-neural-networks-using-tensorflow/#comment-116808
 148. https://www.analyticsvidhya.com/blog/2016/10/an-introduction-to-implementing-neural-networks-using-tensorflow/#comment-117353
 149. https://www.analyticsvidhya.com/blog/2016/10/an-introduction-to-implementing-neural-networks-using-tensorflow/#comment-117353
 150. https://www.analyticsvidhya.com/blog/2016/10/an-introduction-to-implementing-neural-networks-using-tensorflow/#comment-117371
 151. https://www.analyticsvidhya.com/blog/2016/10/an-introduction-to-implementing-neural-networks-using-tensorflow/#comment-117371
 152. https://www.analyticsvidhya.com/blog/2016/10/an-introduction-to-implementing-neural-networks-using-tensorflow/#comment-117413
 153. https://www.analyticsvidhya.com/blog/2016/10/an-introduction-to-implementing-neural-networks-using-tensorflow/#comment-117413
 154. https://www.analyticsvidhya.com/blog/2016/10/an-introduction-to-implementing-neural-networks-using-tensorflow/#comment-117415
 155. https://www.analyticsvidhya.com/blog/2016/10/an-introduction-to-implementing-neural-networks-using-tensorflow/#comment-117415
 156. https://www.analyticsvidhya.com/blog/2016/10/an-introduction-to-implementing-neural-networks-using-tensorflow/#comment-117439
 157. https://www.analyticsvidhya.com/blog/2016/10/an-introduction-to-implementing-neural-networks-using-tensorflow/#comment-117439
 158. https://www.analyticsvidhya.com/blog/2016/10/an-introduction-to-implementing-neural-networks-using-tensorflow/#comment-117440
 159. https://www.analyticsvidhya.com/blog/2016/10/an-introduction-to-implementing-neural-networks-using-tensorflow/#comment-117440
 160. https://www.analyticsvidhya.com/blog/2016/10/an-introduction-to-implementing-neural-networks-using-tensorflow/#comment-117840
 161. https://www.analyticsvidhya.com/blog/2016/10/an-introduction-to-implementing-neural-networks-using-tensorflow/#comment-117840
 162. https://www.analyticsvidhya.com/blog/2016/10/an-introduction-to-implementing-neural-networks-using-tensorflow/#comment-117863
 163. https://www.analyticsvidhya.com/blog/2016/10/an-introduction-to-implementing-neural-networks-using-tensorflow/#comment-117863
 164. http://www.digifledged.com/
 165. https://www.analyticsvidhya.com/blog/2016/10/an-introduction-to-implementing-neural-networks-using-tensorflow/#comment-119218
 166. https://datahack.analyticsvidhya.com/contest/practice-problem-identify-the-digits/media/train_file/train_hi6augp.zip
 167. https://www.analyticsvidhya.com/blog/2016/10/an-introduction-to-implementing-neural-networks-using-tensorflow/#comment-119218
 168. https://www.analyticsvidhya.com/blog/2016/10/an-introduction-to-implementing-neural-networks-using-tensorflow/#comment-119222
 169. https://www.analyticsvidhya.com/blog/2016/10/an-introduction-to-implementing-neural-networks-using-tensorflow/#comment-119222
 170. https://www.analyticsvidhya.com/blog/2016/10/an-introduction-to-implementing-neural-networks-using-tensorflow/#comment-127362
 171. https://www.analyticsvidhya.com/blog/2016/10/an-introduction-to-implementing-neural-networks-using-tensorflow/#comment-127362
 172. https://www.analyticsvidhya.com/blog/2016/10/an-introduction-to-implementing-neural-networks-using-tensorflow/#comment-127377
 173. https://www.lifewire.com/how-to-zip-and-unzip-files-and-folders-on-a-mac-2260188
 174. https://www.analyticsvidhya.com/blog/2016/10/an-introduction-to-implementing-neural-networks-using-tensorflow/#comment-127377
 175. http://www.digifledged.com/
 176. https://www.analyticsvidhya.com/blog/2016/10/an-introduction-to-implementing-neural-networks-using-tensorflow/#comment-119280
 177. https://www.analyticsvidhya.com/blog/2016/10/an-introduction-to-implementing-neural-networks-using-tensorflow/#comment-119280
 178. https://www.analyticsvidhya.com/blog/2016/10/an-introduction-to-implementing-neural-networks-using-tensorflow/#comment-119284
 179. https://www.analyticsvidhya.com/blog/2016/10/an-introduction-to-implementing-neural-networks-using-tensorflow/#comment-119284
 180. http://www.digifledged.com/
 181. https://www.analyticsvidhya.com/blog/2016/10/an-introduction-to-implementing-neural-networks-using-tensorflow/#comment-119289
 182. https://www.analyticsvidhya.com/blog/2016/10/an-introduction-to-implementing-neural-networks-using-tensorflow/#comment-119289
 183. https://www.analyticsvidhya.com/blog/2016/10/an-introduction-to-implementing-neural-networks-using-tensorflow/#comment-119293
 184. https://www.analyticsvidhya.com/blog/2016/10/an-introduction-to-implementing-neural-networks-using-tensorflow/#comment-119293
 185. https://www.analyticsvidhya.com/blog/2016/10/an-introduction-to-implementing-neural-networks-using-tensorflow/#comment-120810
 186. https://www.analyticsvidhya.com/blog/2016/10/an-introduction-to-implementing-neural-networks-using-tensorflow/#comment-120810
 187. https://www.analyticsvidhya.com/blog/2016/10/an-introduction-to-implementing-neural-networks-using-tensorflow/#comment-120812
 188. https://www.analyticsvidhya.com/blog/2016/07/practical-guide-data-preprocessing-python-scikit-learn/
 189. https://www.analyticsvidhya.com/blog/2016/10/an-introduction-to-implementing-neural-networks-using-tensorflow/#comment-120812
 190. https://www.analyticsvidhya.com/blog/2016/10/an-introduction-to-implementing-neural-networks-using-tensorflow/#comment-120817
 191. https://www.analyticsvidhya.com/blog/2016/10/an-introduction-to-implementing-neural-networks-using-tensorflow/#comment-120817
 192. https://www.analyticsvidhya.com/blog/2016/10/an-introduction-to-implementing-neural-networks-using-tensorflow/#comment-120818
 193. https://www.analyticsvidhya.com/blog/2016/10/an-introduction-to-implementing-neural-networks-using-tensorflow/#comment-120818
 194. https://www.analyticsvidhya.com/blog/2016/10/an-introduction-to-implementing-neural-networks-using-tensorflow/#comment-120820
 195. https://www.analyticsvidhya.com/blog/2016/10/an-introduction-to-implementing-neural-networks-using-tensorflow/#comment-120820
 196. https://www.analyticsvidhya.com/blog/2016/10/an-introduction-to-implementing-neural-networks-using-tensorflow/#comment-120821
 197. https://github.com/analyticsvidhya/identify_the_digits/blob/master/tensorflow/notebooks/simple_neural_network.ipynb
 198. https://www.analyticsvidhya.com/blog/2016/10/an-introduction-to-implementing-neural-networks-using-tensorflow/#comment-120821
 199. https://www.analyticsvidhya.com/blog/2016/10/an-introduction-to-implementing-neural-networks-using-tensorflow/#comment-120822
 200. https://www.analyticsvidhya.com/blog/2016/10/an-introduction-to-implementing-neural-networks-using-tensorflow/#comment-120822
 201. https://www.analyticsvidhya.com/blog/2016/10/an-introduction-to-implementing-neural-networks-using-tensorflow/#comment-120872
 202. https://www.analyticsvidhya.com/blog/2016/10/an-introduction-to-implementing-neural-networks-using-tensorflow/#comment-120872
 203. https://www.analyticsvidhya.com/blog/2016/10/an-introduction-to-implementing-neural-networks-using-tensorflow/#comment-120878
 204. https://www.tensorflow.org/api_docs/python/state_ops/saving_and_restoring_variables
 205. https://www.analyticsvidhya.com/blog/2016/10/an-introduction-to-implementing-neural-networks-using-tensorflow/#comment-120878
 206. https://www.analyticsvidhya.com/blog/2016/10/an-introduction-to-implementing-neural-networks-using-tensorflow/#comment-121460
 207. https://www.analyticsvidhya.com/blog/2016/10/an-introduction-to-implementing-neural-networks-using-tensorflow/#comment-121460
 208. https://www.analyticsvidhya.com/blog/2016/10/an-introduction-to-implementing-neural-networks-using-tensorflow/#comment-121464
 209. http://nbviewer.jupyter.org/
 210. https://www.analyticsvidhya.com/blog/2016/10/an-introduction-to-implementing-neural-networks-using-tensorflow/#comment-121464
 211. https://www.analyticsvidhya.com/blog/2016/10/an-introduction-to-implementing-neural-networks-using-tensorflow/#comment-121465
 212. https://docs.google.com/document/d/1jga0cxack48xkt8ral75cuw3vuqj2p843eobmjdc4tc/edit?usp=sharing
 213. https://www.analyticsvidhya.com/blog/2016/10/an-introduction-to-implementing-neural-networks-using-tensorflow/#comment-121465
 214. https://www.analyticsvidhya.com/blog/2016/10/an-introduction-to-implementing-neural-networks-using-tensorflow/#comment-121473
 215. https://discuss.analyticsvidhya.com/
 216. https://www.analyticsvidhya.com/blog/2016/10/an-introduction-to-implementing-neural-networks-using-tensorflow/#comment-121473
 217. https://www.analyticsvidhya.com/blog/2016/10/an-introduction-to-implementing-neural-networks-using-tensorflow/#comment-121477
 218. https://www.analyticsvidhya.com/blog/2016/10/an-introduction-to-implementing-neural-networks-using-tensorflow/#comment-121477
 219. https://www.analyticsvidhya.com/blog/2016/10/an-introduction-to-implementing-neural-networks-using-tensorflow/#comment-121500
 220. https://docs.google.com/document/d/1jga0cxack48xkt8ral75cuw3vuqj2p843eobmjdc4tc/edit?usp=sharing
 221. https://www.analyticsvidhya.com/blog/2016/10/an-introduction-to-implementing-neural-networks-using-tensorflow/#comment-121500
 222. https://www.analyticsvidhya.com/blog/2016/10/an-introduction-to-implementing-neural-networks-using-tensorflow/#comment-121551
 223. https://www.analyticsvidhya.com/blog/2016/10/an-introduction-to-implementing-neural-networks-using-tensorflow/#comment-121551
 224. https://www.analyticsvidhya.com/blog/2016/10/an-introduction-to-implementing-neural-networks-using-tensorflow/#comment-121910
 225. https://docs.google.com/document/d/1jga0cxack48xkt8ral75cuw3vuqj2p843eobmjdc4tc/edit?usp=sharing
 226. https://drive.google.com/file/d/0b9bramtid-xtbev3sddudejczza/view?usp=sharing
 227. https://www.analyticsvidhya.com/blog/2016/10/an-introduction-to-implementing-neural-networks-using-tensorflow/#comment-121910
 228. https://www.analyticsvidhya.com/blog/2016/10/an-introduction-to-implementing-neural-networks-using-tensorflow/#comment-122015
 229. https://discuss.analyticsvidhya.com/t/problem-in-tensorflow-cannot-feed-value-of-shape-140-29-29-for-tensor-u-placeholder-0-which-has-shape-841/15043?u=jalfaizy
 230. https://www.analyticsvidhya.com/blog/2016/10/an-introduction-to-implementing-neural-networks-using-tensorflow/#comment-121672
 231. https://www.analyticsvidhya.com/blog/2016/10/an-introduction-to-implementing-neural-networks-using-tensorflow/#comment-121672
 232. https://www.analyticsvidhya.com/blog/2016/10/an-introduction-to-implementing-neural-networks-using-tensorflow/#comment-122017
 233. https://www.analyticsvidhya.com/blog/2016/10/an-introduction-to-implementing-neural-networks-using-tensorflow/#comment-122017
 234. https://www.analyticsvidhya.com/blog/2016/10/an-introduction-to-implementing-neural-networks-using-tensorflow/#comment-123167
 235. https://www.analyticsvidhya.com/blog/2016/10/an-introduction-to-implementing-neural-networks-using-tensorflow/#comment-123167
 236. https://www.analyticsvidhya.com/blog/2016/10/an-introduction-to-implementing-neural-networks-using-tensorflow/#comment-123168
 237. https://www.analyticsvidhya.com/blog/2016/10/an-introduction-to-implementing-neural-networks-using-tensorflow/#comment-123168
 238. https://www.analyticsvidhya.com/blog/2016/10/an-introduction-to-implementing-neural-networks-using-tensorflow/#comment-123173
 239. https://www.analyticsvidhya.com/blog/2016/10/an-introduction-to-implementing-neural-networks-using-tensorflow/#comment-123173
 240. https://www.analyticsvidhya.com/blog/2016/10/an-introduction-to-implementing-neural-networks-using-tensorflow/#comment-123179
 241. https://www.analyticsvidhya.com/blog/2016/10/an-introduction-to-implementing-neural-networks-using-tensorflow/#comment-123179
 242. https://www.analyticsvidhya.com/blog/2016/10/an-introduction-to-implementing-neural-networks-using-tensorflow/#comment-123546
 243. https://www.analyticsvidhya.com/blog/2016/10/an-introduction-to-implementing-neural-networks-using-tensorflow/#comment-123546
 244. https://www.analyticsvidhya.com/blog/2016/10/an-introduction-to-implementing-neural-networks-using-tensorflow/#comment-129115
 245. https://www.analyticsvidhya.com/blog/2016/10/tutorial-optimizing-neural-networks-using-keras-with-image-recognition-case-study/
 246. https://www.analyticsvidhya.com/blog/2016/10/an-introduction-to-implementing-neural-networks-using-tensorflow/#comment-129115
 247. https://www.analyticsvidhya.com/blog/2016/10/an-introduction-to-implementing-neural-networks-using-tensorflow/#comment-123891
 248. https://www.analyticsvidhya.com/blog/2016/10/an-introduction-to-implementing-neural-networks-using-tensorflow/#comment-123891
 249. https://www.analyticsvidhya.com/blog/2016/10/an-introduction-to-implementing-neural-networks-using-tensorflow/#comment-129114
 250. https://www.analyticsvidhya.com/blog/2016/10/an-introduction-to-implementing-neural-networks-using-tensorflow/#comment-129114
 251. https://www.analyticsvidhya.com/blog/2016/10/an-introduction-to-implementing-neural-networks-using-tensorflow/#comment-125990
 252. https://www.analyticsvidhya.com/blog/2016/10/an-introduction-to-implementing-neural-networks-using-tensorflow/#comment-125990
 253. https://www.analyticsvidhya.com/blog/2016/10/an-introduction-to-implementing-neural-networks-using-tensorflow/#comment-129117
 254. https://www.analyticsvidhya.com/blog/2016/10/an-introduction-to-implementing-neural-networks-using-tensorflow/#comment-129117
 255. https://www.analyticsvidhya.com/blog/2016/10/an-introduction-to-implementing-neural-networks-using-tensorflow/#comment-127104
 256. https://www.analyticsvidhya.com/blog/2016/10/an-introduction-to-implementing-neural-networks-using-tensorflow/#comment-127104
 257. https://www.analyticsvidhya.com/blog/2016/10/an-introduction-to-implementing-neural-networks-using-tensorflow/#comment-129116
 258. https://www.analyticsvidhya.com/blog/2016/10/an-introduction-to-implementing-neural-networks-using-tensorflow/#comment-129116
 259. http://none/
 260. https://www.analyticsvidhya.com/blog/2016/10/an-introduction-to-implementing-neural-networks-using-tensorflow/#comment-129466
 261. https://www.analyticsvidhya.com/blog/2016/10/an-introduction-to-implementing-neural-networks-using-tensorflow/#comment-129466
 262. https://www.analyticsvidhya.com/blog/2016/10/an-introduction-to-implementing-neural-networks-using-tensorflow/#comment-130549
 263. https://www.analyticsvidhya.com/blog/2016/10/an-introduction-to-implementing-neural-networks-using-tensorflow/#comment-130549
 264. https://www.analyticsvidhya.com/blog/2016/10/an-introduction-to-implementing-neural-networks-using-tensorflow/#comment-129999
 265. https://www.analyticsvidhya.com/blog/2016/10/an-introduction-to-implementing-neural-networks-using-tensorflow/#comment-129999
 266. https://www.analyticsvidhya.com/blog/2016/10/an-introduction-to-implementing-neural-networks-using-tensorflow/#comment-131708
 267. http://pandas.pydata.org/pandas-docs/version/0.19.2/generated/pandas.dataframe.ix.html
 268. https://www.analyticsvidhya.com/blog/2016/10/an-introduction-to-implementing-neural-networks-using-tensorflow/#comment-131708
 269. https://www.analyticsvidhya.com/blog/2016/10/an-introduction-to-implementing-neural-networks-using-tensorflow/#comment-130127
 270. https://www.analyticsvidhya.com/blog/2016/10/an-introduction-to-implementing-neural-networks-using-tensorflow/#comment-130127
 271. https://www.analyticsvidhya.com/blog/2016/10/an-introduction-to-implementing-neural-networks-using-tensorflow/#comment-130548
 272. https://www.analyticsvidhya.com/blog/2016/10/an-introduction-to-implementing-neural-networks-using-tensorflow/#comment-130548
 273. https://www.analyticsvidhya.com/blog/2016/10/an-introduction-to-implementing-neural-networks-using-tensorflow/#comment-130668
 274. https://www.analyticsvidhya.com/blog/2016/10/an-introduction-to-implementing-neural-networks-using-tensorflow/#comment-130668
 275. https://www.analyticsvidhya.com/blog/2016/10/an-introduction-to-implementing-neural-networks-using-tensorflow/#comment-131709
 276. https://www.analyticsvidhya.com/blog/2016/10/an-introduction-to-implementing-neural-networks-using-tensorflow/#comment-131709
 277. https://www.analyticsvidhya.com/blog/2016/10/an-introduction-to-implementing-neural-networks-using-tensorflow/#comment-130669
 278. https://www.analyticsvidhya.com/blog/2016/10/an-introduction-to-implementing-neural-networks-using-tensorflow/#comment-130669
 279. https://www.analyticsvidhya.com/blog/2016/10/an-introduction-to-implementing-neural-networks-using-tensorflow/#comment-131710
 280. https://www.analyticsvidhya.com/blog/2016/10/an-introduction-to-implementing-neural-networks-using-tensorflow/#comment-131710
 281. https://www.analyticsvidhya.com/blog/2016/10/an-introduction-to-implementing-neural-networks-using-tensorflow/#comment-133009
 282. https://www.analyticsvidhya.com/blog/2016/10/an-introduction-to-implementing-neural-networks-using-tensorflow/#comment-133009
 283. https://www.analyticsvidhya.com/blog/2016/10/an-introduction-to-implementing-neural-networks-using-tensorflow/#comment-134524
 284. https://www.analyticsvidhya.com/blog/2016/10/an-introduction-to-implementing-neural-networks-using-tensorflow/#comment-134524
 285. https://www.analyticsvidhya.com/blog/2016/10/an-introduction-to-implementing-neural-networks-using-tensorflow/#comment-133624
 286. https://www.analyticsvidhya.com/blog/2016/10/an-introduction-to-implementing-neural-networks-using-tensorflow/#comment-133624
 287. https://www.analyticsvidhya.com/blog/2016/10/an-introduction-to-implementing-neural-networks-using-tensorflow/#comment-133631
 288. https://www.analyticsvidhya.com/blog/2016/10/an-introduction-to-implementing-neural-networks-using-tensorflow/#comment-133631
 289. https://www.analyticsvidhya.com/blog/2016/10/an-introduction-to-implementing-neural-networks-using-tensorflow/#comment-134523
 290. https://www.analyticsvidhya.com/blog/2016/10/an-introduction-to-implementing-neural-networks-using-tensorflow/#comment-134523
 291. https://www.analyticsvidhya.com/blog/2016/10/an-introduction-to-implementing-neural-networks-using-tensorflow/#comment-138226
 292. https://www.analyticsvidhya.com/blog/2016/10/an-introduction-to-implementing-neural-networks-using-tensorflow/#comment-138226
 293. https://www.analyticsvidhya.com/blog/2016/10/an-introduction-to-implementing-neural-networks-using-tensorflow/#comment-139460
 294. https://www.analyticsvidhya.com/blog/2016/10/an-introduction-to-implementing-neural-networks-using-tensorflow/#comment-139460
 295. https://www.analyticsvidhya.com/blog/2016/10/an-introduction-to-implementing-neural-networks-using-tensorflow/#comment-142585
 296. https://www.analyticsvidhya.com/blog/2016/10/an-introduction-to-implementing-neural-networks-using-tensorflow/#comment-142585
 297. https://www.analyticsvidhya.com/blog/2016/10/an-introduction-to-implementing-neural-networks-using-tensorflow/#comment-144018
 298. https://www.analyticsvidhya.com/blog/2016/10/an-introduction-to-implementing-neural-networks-using-tensorflow/#comment-144018
 299. https://www.analyticsvidhya.com/blog/2016/10/an-introduction-to-implementing-neural-networks-using-tensorflow/#comment-139143
 300. https://www.analyticsvidhya.com/blog/2016/10/an-introduction-to-implementing-neural-networks-using-tensorflow/#comment-139143
 301. https://www.analyticsvidhya.com/blog/2016/10/an-introduction-to-implementing-neural-networks-using-tensorflow/#comment-139462
 302. https://www.analyticsvidhya.com/blog/2016/10/an-introduction-to-implementing-neural-networks-using-tensorflow/#comment-139462
 303. https://www.analyticsvidhya.com/blog/2016/10/an-introduction-to-implementing-neural-networks-using-tensorflow/#comment-139425
 304. https://www.analyticsvidhya.com/blog/2016/10/an-introduction-to-implementing-neural-networks-using-tensorflow/#comment-139425
 305. https://www.analyticsvidhya.com/blog/2016/10/an-introduction-to-implementing-neural-networks-using-tensorflow/#comment-139463
 306. https://datahack.analyticsvidhya.com/contest/practice-problem-identify-the-digits/
 307. https://www.analyticsvidhya.com/blog/2016/10/an-introduction-to-implementing-neural-networks-using-tensorflow/#comment-139463
 308. https://www.analyticsvidhya.com/blog/2016/10/an-introduction-to-implementing-neural-networks-using-tensorflow/#comment-139469
 309. https://www.analyticsvidhya.com/blog/2016/10/an-introduction-to-implementing-neural-networks-using-tensorflow/#comment-139469
 310. https://www.analyticsvidhya.com/blog/2016/10/an-introduction-to-implementing-neural-networks-using-tensorflow/#comment-144019
 311. https://www.analyticsvidhya.com/blog/2016/10/an-introduction-to-implementing-neural-networks-using-tensorflow/#comment-144019
 312. https://www.analyticsvidhya.com/blog/2016/10/an-introduction-to-implementing-neural-networks-using-tensorflow/#comment-146591
 313. https://www.analyticsvidhya.com/blog/2016/10/an-introduction-to-implementing-neural-networks-using-tensorflow/#comment-146591
 314. https://www.analyticsvidhya.com/blog/2016/10/an-introduction-to-implementing-neural-networks-using-tensorflow/#comment-146613
 315. https://www.analyticsvidhya.com/blog/2016/10/an-introduction-to-implementing-neural-networks-using-tensorflow/#comment-146613
 316. https://www.analyticsvidhya.com/blog/2016/10/an-introduction-to-implementing-neural-networks-using-tensorflow/#comment-152189
 317. https://datahack.analyticsvidhya.com/contest/practice-problem-identify-the-digits/
 318. https://www.analyticsvidhya.com/blog/2016/10/an-introduction-to-implementing-neural-networks-using-tensorflow/#comment-152189
 319. https://www.analyticsvidhya.com/blog/2016/10/an-introduction-to-implementing-neural-networks-using-tensorflow/#comment-152205
 320. https://www.analyticsvidhya.com/blog/2016/10/an-introduction-to-implementing-neural-networks-using-tensorflow/#comment-152205
 321. https://datahack.analyticsvidhya.com/user/profile/srk
 322. https://datahack.analyticsvidhya.com/user/profile/mark12
 323. https://datahack.analyticsvidhya.com/user/profile/nilabha
 324. https://datahack.analyticsvidhya.com/user/profile/nitish007
 325. https://datahack.analyticsvidhya.com/user/profile/tezdhar
 326. https://datahack.analyticsvidhya.com/top-competitor/?utm_source=blog-navbar&utm_medium=web
 327. https://www.analyticsvidhya.com/blog/2018/05/24-ultimate-data-science-projects-to-boost-your-knowledge-and-skills/
 328. https://www.analyticsvidhya.com/blog/2017/09/understaing-support-vector-machine-example-code/
 329. https://www.analyticsvidhya.com/blog/2017/09/common-machine-learning-algorithms/
 330. https://www.analyticsvidhya.com/blog/2016/01/complete-tutorial-learn-data-science-python-scratch-2/
 331. https://www.analyticsvidhya.com/blog/2015/08/comprehensive-guide-regression/
 332. https://www.analyticsvidhya.com/blog/2017/09/naive-bayes-explained/
 333. https://www.analyticsvidhya.com/blog/2018/01/anova-analysis-of-variance/
 334. https://www.analyticsvidhya.com/blog/2018/10/predicting-stock-price-machine-learningnd-deep-learning-techniques-python/
 335. https://www.analyticsvidhya.com/blog/2019/04/top-5-machine-learning-github-reddit/
 336. https://www.analyticsvidhya.com/blog/2019/04/top-5-machine-learning-github-reddit/
 337. https://www.analyticsvidhya.com/blog/2019/04/introduction-image-segmentation-techniques-python/
 338. https://www.analyticsvidhya.com/blog/2019/04/introduction-image-segmentation-techniques-python/
 339. https://www.analyticsvidhya.com/blog/2019/03/reinforcement-learning-temporal-difference-learning/
 340. https://www.analyticsvidhya.com/blog/2019/03/reinforcement-learning-temporal-difference-learning/
 341. https://www.analyticsvidhya.com/blog/2019/03/opencv-functions-computer-vision-python/
 342. https://www.analyticsvidhya.com/blog/2019/03/opencv-functions-computer-vision-python/
 343. https://datahack.analyticsvidhya.com/contest/ltfs-datascience-finhack-an-online-hackathon/?utm_source=sticky_banner1&utm_medium=display
 344. https://datahack.analyticsvidhya.com/contest/hikeathon/?utm_source=sticky_banner2&utm_medium=display
 345. http://www.analyticsvidhya.com/about-me/
 346. https://www.analyticsvidhya.com/about-me/team/
 347. https://www.analyticsvidhya.com/career-analytics-vidhya/
 348. https://www.analyticsvidhya.com/contact/
 349. https://www.analyticsvidhya.com/about-me/write/
 350. http://www.analyticsvidhya.com/about-me/
 351. https://www.analyticsvidhya.com/about-me/team/
 352. https://www.analyticsvidhya.com/about-me/team/
 353. https://www.analyticsvidhya.com/about-me/team/
 354. https://www.analyticsvidhya.com/career-analytics-vidhya/
 355. https://www.analyticsvidhya.com/about-me/team/
 356. https://www.analyticsvidhya.com/contact/
 357. https://www.analyticsvidhya.com/blog
 358. https://datahack.analyticsvidhya.com/
 359. https://discuss.analyticsvidhya.com/
 360. https://www.analyticsvidhya.com/jobs/
 361. https://datahack.analyticsvidhya.com/users/
 362. https://www.analyticsvidhya.com/corporate/
 363. https://trainings.analyticsvidhya.com/
 364. https://datahack.analyticsvidhya.com/
 365. https://www.analyticsvidhya.com/contact/
 366. https://www.analyticsvidhya.com/contact/
 367. https://datahack.analyticsvidhya.com/signup/
 368. https://www.facebook.com/analyticsvidhya/
 369. https://www.facebook.com/analyticsvidhya/
 370. https://twitter.com/analyticsvidhya
 371. https://twitter.com/analyticsvidhya
 372. https://plus.google.com/+analyticsvidhya
 373. https://in.linkedin.com/company/analytics-vidhya
 374. https://in.linkedin.com/company/analytics-vidhya
 375. https://www.analyticsvidhya.com/privacy-policy/
 376. https://www.analyticsvidhya.com/terms/
 377. https://www.analyticsvidhya.com/refund-policy/
 378. https://id.analyticsvidhya.com/accounts/signup/
 379. https://widgets.wp.com/likes/master.html?ver=201914#ver=201914
 380. https://id.analyticsvidhya.com/accounts/login/?next=https://www.analyticsvidhya.com/blog/&utm_source=blog-subscribe&utm_medium=web
 381. https://widgets.wp.com/likes/master.html?ver=201914#ver=201914
 382. https://id.analyticsvidhya.com/accounts/login/?next=https://www.analyticsvidhya.com/blog/&utm_source=blog-subscribe&utm_medium=web

   hidden links:
 384. https://www.facebook.com/analyticsvidhya
 385. https://twitter.com/analyticsvidhya
 386. https://plus.google.com/+analyticsvidhya/posts
 387. https://in.linkedin.com/company/analytics-vidhya
 388. https://www.analyticsvidhya.com/blog/2016/10/using-pyspark-to-perform-transformations-and-actions-on-rdd/
 389. https://www.analyticsvidhya.com/blog/2016/09/most-active-data-scientists-free-books-notebooks-tutorials-on-github/
 390. https://www.analyticsvidhya.com/blog/author/jalfaizy/
 391. https://www.linkedin.com/in/faizankshaikh
 392. http://github.com/faizankshaikh
 393. http://www.edvancer.in/certified-data-scientist-with-python-course?utm_source=av&utm_medium=avads&utm_campaign=avadsnonfc&utm_content=pythonavad
 394. https://www.facebook.com/analyticsvidhya/
 395. https://twitter.com/analyticsvidhya
 396. https://plus.google.com/+analyticsvidhya
 397. https://plus.google.com/+analyticsvidhya
 398. https://in.linkedin.com/company/analytics-vidhya
 399. https://www.addtoany.com/add_to/facebook?linkurl=https%3a%2f%2fwww.analyticsvidhya.com%2fblog%2f2016%2f10%2fan-introduction-to-implementing-neural-networks-using-tensorflow%2f&linkname=an%20introduction%20to%20implementing%20neural%20networks%20using%20tensorflow
 400. https://www.addtoany.com/add_to/twitter?linkurl=https%3a%2f%2fwww.analyticsvidhya.com%2fblog%2f2016%2f10%2fan-introduction-to-implementing-neural-networks-using-tensorflow%2f&linkname=an%20introduction%20to%20implementing%20neural%20networks%20using%20tensorflow
 401. https://www.addtoany.com/add_to/linkedin?linkurl=https%3a%2f%2fwww.analyticsvidhya.com%2fblog%2f2016%2f10%2fan-introduction-to-implementing-neural-networks-using-tensorflow%2f&linkname=an%20introduction%20to%20implementing%20neural%20networks%20using%20tensorflow
 402. https://www.addtoany.com/add_to/flipboard?linkurl=https%3a%2f%2fwww.analyticsvidhya.com%2fblog%2f2016%2f10%2fan-introduction-to-implementing-neural-networks-using-tensorflow%2f&linkname=an%20introduction%20to%20implementing%20neural%20networks%20using%20tensorflow
 403. https://www.addtoany.com/add_to/whatsapp?linkurl=https%3a%2f%2fwww.analyticsvidhya.com%2fblog%2f2016%2f10%2fan-introduction-to-implementing-neural-networks-using-tensorflow%2f&linkname=an%20introduction%20to%20implementing%20neural%20networks%20using%20tensorflow
 404. https://www.addtoany.com/add_to/facebook?linkurl=https%3a%2f%2fwww.analyticsvidhya.com%2fblog%2f2016%2f10%2fan-introduction-to-implementing-neural-networks-using-tensorflow%2f&linkname=an%20introduction%20to%20implementing%20neural%20networks%20using%20tensorflow
 405. https://www.addtoany.com/add_to/twitter?linkurl=https%3a%2f%2fwww.analyticsvidhya.com%2fblog%2f2016%2f10%2fan-introduction-to-implementing-neural-networks-using-tensorflow%2f&linkname=an%20introduction%20to%20implementing%20neural%20networks%20using%20tensorflow
 406. https://www.addtoany.com/add_to/linkedin?linkurl=https%3a%2f%2fwww.analyticsvidhya.com%2fblog%2f2016%2f10%2fan-introduction-to-implementing-neural-networks-using-tensorflow%2f&linkname=an%20introduction%20to%20implementing%20neural%20networks%20using%20tensorflow
 407. https://www.addtoany.com/add_to/flipboard?linkurl=https%3a%2f%2fwww.analyticsvidhya.com%2fblog%2f2016%2f10%2fan-introduction-to-implementing-neural-networks-using-tensorflow%2f&linkname=an%20introduction%20to%20implementing%20neural%20networks%20using%20tensorflow
 408. https://www.addtoany.com/add_to/whatsapp?linkurl=https%3a%2f%2fwww.analyticsvidhya.com%2fblog%2f2016%2f10%2fan-introduction-to-implementing-neural-networks-using-tensorflow%2f&linkname=an%20introduction%20to%20implementing%20neural%20networks%20using%20tensorflow
 409. javascript:void(0);
 410. javascript:void(0);
 411. https://www.addtoany.com/add_to/facebook?linkurl=https%3a%2f%2fwww.analyticsvidhya.com%2fblog%2f2016%2f10%2fan-introduction-to-implementing-neural-networks-using-tensorflow%2f&linkname=an%20introduction%20to%20implementing%20neural%20networks%20using%20tensorflow
 412. https://www.addtoany.com/add_to/twitter?linkurl=https%3a%2f%2fwww.analyticsvidhya.com%2fblog%2f2016%2f10%2fan-introduction-to-implementing-neural-networks-using-tensorflow%2f&linkname=an%20introduction%20to%20implementing%20neural%20networks%20using%20tensorflow
 413. https://www.addtoany.com/add_to/linkedin?linkurl=https%3a%2f%2fwww.analyticsvidhya.com%2fblog%2f2016%2f10%2fan-introduction-to-implementing-neural-networks-using-tensorflow%2f&linkname=an%20introduction%20to%20implementing%20neural%20networks%20using%20tensorflow
 414. https://www.addtoany.com/add_to/flipboard?linkurl=https%3a%2f%2fwww.analyticsvidhya.com%2fblog%2f2016%2f10%2fan-introduction-to-implementing-neural-networks-using-tensorflow%2f&linkname=an%20introduction%20to%20implementing%20neural%20networks%20using%20tensorflow
 415. https://www.addtoany.com/add_to/whatsapp?linkurl=https%3a%2f%2fwww.analyticsvidhya.com%2fblog%2f2016%2f10%2fan-introduction-to-implementing-neural-networks-using-tensorflow%2f&linkname=an%20introduction%20to%20implementing%20neural%20networks%20using%20tensorflow
 416. https://www.addtoany.com/add_to/facebook?linkurl=https%3a%2f%2fwww.analyticsvidhya.com%2fblog%2f2016%2f10%2fan-introduction-to-implementing-neural-networks-using-tensorflow%2f&linkname=an%20introduction%20to%20implementing%20neural%20networks%20using%20tensorflow
 417. https://www.addtoany.com/add_to/twitter?linkurl=https%3a%2f%2fwww.analyticsvidhya.com%2fblog%2f2016%2f10%2fan-introduction-to-implementing-neural-networks-using-tensorflow%2f&linkname=an%20introduction%20to%20implementing%20neural%20networks%20using%20tensorflow
 418. https://www.addtoany.com/add_to/linkedin?linkurl=https%3a%2f%2fwww.analyticsvidhya.com%2fblog%2f2016%2f10%2fan-introduction-to-implementing-neural-networks-using-tensorflow%2f&linkname=an%20introduction%20to%20implementing%20neural%20networks%20using%20tensorflow
 419. https://www.addtoany.com/add_to/flipboard?linkurl=https%3a%2f%2fwww.analyticsvidhya.com%2fblog%2f2016%2f10%2fan-introduction-to-implementing-neural-networks-using-tensorflow%2f&linkname=an%20introduction%20to%20implementing%20neural%20networks%20using%20tensorflow
 420. https://www.addtoany.com/add_to/whatsapp?linkurl=https%3a%2f%2fwww.analyticsvidhya.com%2fblog%2f2016%2f10%2fan-introduction-to-implementing-neural-networks-using-tensorflow%2f&linkname=an%20introduction%20to%20implementing%20neural%20networks%20using%20tensorflow
 421. javascript:void(0);
 422. javascript:void(0);
