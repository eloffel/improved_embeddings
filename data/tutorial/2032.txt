nlp 

introduction to nlp

probabilities (1/2) 

probabilities in nlp 

       very important for language processing
       example in id103:
       example in machine translation:

          recognize speech    vs    wreck a nice beach   

          l   avocat general   :    the attorney general    vs.    the general 

avocado   

       example in information retrieval:

       if a document includes three occurrences of    stir    and one of 
       probabilities make it possible to combine evidence from 

   rice   , what is the id203 that it is a recipe

multiple sources in a systematic way

probabilities 

       predicting how likely it is that something will happen

       e.g., throwing a coin

       id203 theory
       experiment (trial)
       possible outcomes
       heads or tails
       sample spaces
temperature)

       events

          is the certain event 
           is the impossible event
       event space - all possible events

       discrete (number of occurrences of    rice   ) or continuous (e.g., 

sample space 

       random experiment: an experiment with uncertain 

outcome
       e.g., flipping a coin, picking a word from text

       sample space: all possible outcomes, e.g., 

       tossing 2 fair coins,    ={hh, ht, th, tt}

events 

       event: a subspace of the sample space
       e      , e happens iff outcome is in e, e.g., 

       e={hh} (all heads) 
       e={hh,tt} (same face)
       impossible event (   )
       certain event (  )
       p(  )=1 (outcome always in   )
       p(a    b)=p(a)+p(b), if (a   b)=     (e.g., a=same face, 

       id203 of event : 0     p(e)    1, s.t.

b=different face)

example: toss a die 

       p(1) = p(2) = p(3) = p(4) = p(5) = p(6) = 1/6

       sample space:    = {1,2,3,4,5,6}
       fair die:
       unfair die: p(1) = 0.3, p(2) = 0.2, ...
       n-dimensional die:
       example in modeling text:

          = {1, 2, 3, 4,    , n}
       toss a die to decide which word to write in the next position
          = {cat, dog, tiger,    }

example: flip a coin 

          : {head, tail}
       fair coin: 
       p(h) = 0.5, p(t) = 0.5
       unfair coin, e.g.:
       p(h) = 0.3, p(t) = 0.7
       flipping two fair coins:
       example in modeling text:

       sample space: {hh, ht, th, tt}
       flip a coin to decide whether or not to include a word in a 
       sample space = {appear, absence}

document

probabilities 

       probabilities
       numbers between 0 and 1
       id203 distribution
       distributes a id203 mass of 1 throughout the 

sample space   .

       example: 

       a fair coin is tossed three times. 
       what is the id203 of 3 heads?
       what is the id203 of 2 heads?

meaning of probabilities 

       frequentist

       subjective

       i threw the coin 10 times and it turned up heads 5 
times

       i am willing to bet 50 cents on heads

probabilities 

joint id203: p(a   b), also written as p(a, b)
      
       id155: p(b|a)=p(a   b)/p(a)
       p(a   b) = p(a)p(b|a) = p(b)p(a|b)
       so, p(a|b) = p(b|a)p(a)/p(b) (bayes    rule)
       for independent events, p(a   b) = p(a)p(b), so p(a|b)=p(a)
       p(b) = p(b   s) = p(b, a1) +     + p(b, an) (why?)
       so, p(ai|b) = p(b|ai)p(ai)/p(b)
                      = p(b|ai)p(ai)/[p(b|a1)p(a1)+   +p(b|an)p(an)] 
       this allows us to compute p(ai|b) based on p(b|ai)
                      

       total id203: if a1,    , an form a partition of s, then

properties of probabilities 

       p(   ) = 0 
       p(certain event)=1
       p(x)     p(y), if x     y
       p(x     y) = p(x) + p(y), if x     y=   

id155 

       prior and posterior id203
       id155

p(a|b) =  

p(a     b) 
p(b)  

   

a 

b 

a   b 

id155 

       six-sided fair die

       p(d even)=?
       p(d>=4)=?
       p(d even|d>=4)=?
       p(d odd|d>=4)=?
       multiple conditions

       p(d odd|d>=4, d<=5)=?

answers 

       six-sided fair die
       p(d even)=3/6=1/2
       p(d>=4)=3/6=1/2
       p(d even|d>=4)=2/3
       p(d odd|d>=4)=1/3
       multiple conditions

       p(d odd|d>=4, d<=5)=1/2

nlp 

