nlp

introduction to nlp

bayes    theorem

bayes    theorem

    formula for joint id203

    p(a,b) = p(b|a)p(a)
    p(a,b) = p(a|b)p(b)

    therefore
    bayes    theorem is used to calculate p(a|b) 

    p(b|a)=p(a|b)p(b)/p(a)
given p(b|a)

example

    diagnostic test
    test accuracy

    p(positive |   disease) = 0.05               false 
positive
    p(negative | disease) = 0.05                false 
negative
    so p(positive | disease) = 1-0.05 = 0.95
    same for p(negative |   disease)
    in general the rates of false positives and false 
negatives are different

example

    diagnostic test with errors

p(a|b)

a=test

positive

negative

b=disease

yes
no

0.95
0.05

0.05
0.95

example

    what is p(disease | positive)?
    p(disease|positive) = 
p(positive|disease)*p(disease)/p(positive)
    p(  disease|positive) = p(positive| 
  disease)*p(  disease)/p(positive)
    p(disease|positive)/p(  disease|positive) = ?

    we don   t really care about p(positive)
    as long as it is not zero, we can divide by it on both sides

example

    p(disease|positive) / p(  disease|positive) = 

(p(positive|disease) x p(disease))/(p(positive|  disease) x 
p(  disease))

    so p(  disease) = 0.999
0.999)  =0.019

    suppose p(disease) = 0.001  
    p(disease|positive) / p(  disease|positive) = (0.95 x 0.001)/(0.05 x 
    p(disease|positive) + p(  disease|positive) = 1
    p(disease|positive)     0.02
    p(disease) is called the prior id203
    p(disease|positive) is called the posterior id203
   

in this example the posterior is 20 times larger than the prior

example

    p(well)=0.9, p(cold)=0.05, p(allergy)=0.05

    p(sneeze|well)=0.1
    p(sneeze|cold)=0.9
    p(sneeze|allergy)=0.9
    p(cough|well)=0.1
    p(cough|cold)=0.8
    p(cough|allergy)=0.7
    p(fever|well)=0.01
    p(fever|cold)=0.7
    p(fever|allergy)=0.4

example from ray mooney

example (cont   d)

    features: sneeze, cough, no fever
    p(well|e)=(.9) * (.1)(.1)(.99) / p(e)=0.0089/p(e)
    p(cold|e)=(.05) * (.9)(.8)(.3) / p(e)=0.01/p(e)
    p(allergy|e)=(.05) * (.9)(.7)(.6) / p(e)=0.019/p(e)
    p(e) = 0.0089+0.01+0.019=0.379
    p(well|e)=.23
    p(cold|e)=.26
    p(allergy|e)=.50

bayes    theorem

hypothesis space: h={h1 ,    , hn}
)
(
ep

ehp

hphep

=

)

(

(

)

(

|

|

i

i

evidence: e

)

i

in text classification: h: class space; e: data (features)

if we want to pick the most likely hypothesis h*,  we can drop p(e)

posterior id203 of hi
  

ehp

)

(

|

i

prior id203 of hi

i

|

(

()

hphep
i
likelihood of data/evidence
if hi is true

)

[slide from qiaozhu mei]

getting to statistics ...
    we are flipping an unfair coin, but p(head)=? 
(parameter estimation)
    if we see the results of a huge number of random 

experiments, then 
heads
count
(
)
count
flips
(
)

head

(  
p

=

)

=

count

(

count
(
heads
)

heads
+

)
count

tails
(

)

    but, what if we only see a small sample (e.g., 2)? is this 
estimate still reliable? we flip twice and got two tails, does it 
mean p(head) = 0?
in general, statistics has to do with drawing conclusions 
on the whole population based on observations of a 
sample (data)

   

[slide from qiaozhu mei]

parameter estimation

    general setting:

random experiment
on the parameter q
about the value of q?

    given a (hypothesized & probabilistic) model that governs the 
    the model gives a id203 of any data p(d|q) that depends 
    now, given actual sample data x={x1,   ,xn},  what can we say 
intuitively, take your best guess of q --    best    means 
   
   best explaining/fitting the data   
    generally an optimization problem

[slide from qiaozhu mei]

maximum likelihood vs. bayesian
    id113

       best    means    data likelihood reaches maximum   

  
q

arg
    problem: small sample
    bayesian estimation

=

max
q

xp

(

)
|
q

and explaining data well

       best    means being consistent with our    prior    knowledge 
    problem: how to define the prior?
arg

|
)(
qq

xp

arg

(
|
q

  
q

x

p

p

=

=

(

)

)

max
q

max
q

[slide from qiaozhu mei]

illustration of bayesian estimation

posterior:
p(q|x)  p(x|q)p(q)

prior: p(q)

likelihood:
p(x|q)
x=(x1,   ,xn)

q

qa: prior mode 

q: posterior mode 

qml: ml estimate

[slide from qiaozhu mei]

example: an unfair die

   

    what if you toss the die 1000 times, 

it   s more likely to get a 6 and less likely to get a 1
    p(6) > p(1)
    how likely?
and observe    6    501 times, 
   1    108 times?
    p(6) = 501/1000 = 0.501
    p(1) = 108/1000 = 0.108
    as simple as counting, but principled     maximum likelihood 

estimate

[slide from qiaozhu mei]

what if the die has more faces?
    suitable to represent documents
    every face corresponds to a word in vocabulary
    the author tosses a die 
    apparently, an unfair die

to write a word

[slide from qiaozhu mei]

maximum likelihood estimate

data: a document d with counts c(w1),    , c(wn), and length |d|
model: multinomial distribution m with parameters {p(wi)} 
likelihood: p(d|m)
maximum likelihood estimator: m=argmax m p(d|m)

wp

(

i

)

=

)

wc
(
i
d

problem: a document is short

if c(wi) = 0, does this mean p(wi) = 0? 

[slide from qiaozhu mei]

optional: if you want to know how 

we get it   

data: a document d with counts c(w1),    , c(wn), and length |d|
model: multinomial distribution m with parameters {p(wi)} 
likelihood: p(d|m)
maximum likelihood estimator: m=argmax m p(d|m)
=  

where
,
q
i

p w
i

p d m

iq

q
i

q
i

c w
i

c w
i

1

d

(

)

(

)

n

n

n

|

(

)

(

)

  
=  =   
  

|
|
)... (

c w c w
(
n

1

)

  

i

1
=

i

1
=

l d m
(

|

)

=

log (

p d m

|

)

=

c w
(
i

) log

q
i

c w
(
i

) log

-

q l q
i

+

i

(

  

n

i

1
=

1)

n

  
i
)

1
=

0
+ =  =
-

l

q
i

)

c w
(
i
l

l d m
'

(

|

)

=

'

=

c w
l
(
  
i
q q
  
i
  

since

n

i

i

1
=

q l

=-

=

1,

i

n

  

1
=

=-
i

c w
(
i

)

|

d

|

so

,

q =

i

p w
i

(

)

=

)

c w
(
i
d
|
|

we   ll tune p(wi) to maximize l(d|m)
use lagrange multiplier approach

set partial derivatives to zero

  

1
=

  
  
  
  

i
n

i

1
=

ml estimate

[slide from qiaozhu mei]

nlp

