nlp

introduction to nlp

statistical id52

id52 methods

    rule-based
    stochastic

    id48 (generative)
    maximum id178 mm (discriminative)

    transformation-based

id48-based id52
    find tag sequence that maximizes the 

id203 formula
    p(word|tag) * p(tag|previous n tags) 
    a bigram-based id48 tagger chooses the 
tag ti for word wi that is most probable 
given the previous tag ti-1 and the current 
word wi:
    ti = argmaxj p(tj|ti-1,wi)
    ti = argmaxj p(tj|ti-1)p(wi|tj) : id48 equation for a 
single tag

id48 tagging

    t = argmax p(t|w)
    where t=t1,t2,   ,tn
    by bayes    theorem
    p(t|w) = p(t)p(w|t)/p(w)
    thus we are attempting to choose the sequence 
of tags that maximizes the right hand side of 
the equation
    p(w) can be ignored
    p(t) is called the prior, p(w|t) is called the likelihood.

id48 tagging

    complete formula

    p(t)p(w|t) =   p(wi|w1t1   wi-1ti-1ti)p(ti|t1   ti-2ti-1)
    simplification 1: 
    p(w|t) =   p(wi|ti)
    simplification 2: 
    p(t)=   p(ti|ti-1)
    t = argmax p(t|w) = argmax   p(wi|ti) p(ti|ti-1)

    bigram approximation

maximum likelihood estimates

    transitions
    emissions

p(nn|jj) = c(jj,nn)/c(jj)=22301/89401 = .249

p(this|dt) = c(dt,this)/c(dt)=7037/103687 = .068

example

    the/dt rich/jj like/vbp to/to travel/vb ./.

example

dt

the

dt

the

nn

rich

nn

rich

vbp

like

vbp

like

to

to

to

to

nn

travel

vb

travel

.

.

.

.

evaluating taggers

    data set

    training set
    development set
    test set
    tagging accuracy
    how many tags right
    results
    baseline is very high     90% for english
    trigram id48 about 95% total accuracy, 55% on unknown words
    highest accuracy around 97% on ptb trained on 800,000 words
    upper bound 97-98% 

   
    noise (e.g., errors and inconsistencies in the data, e.g., nn vs jj)

(50-85% on unknown words; 50% for trigrams)

notes on pos

    lower performance

    new domains
    new languages
    distributional id91

    morphology matters! also availability of training data

    combine statistics about semantically related words
    example: names of companies
    example: days of the week
    example: animals

notes on pos

    http://www.natcorp.ox.ac.uk/

    british national corpus
    tagset sizes
    dealing with unknown words

    ptb 45, brown 85, universal 12, twitter 25

    look at features like twodigitnum, allcaps, initcaps, 

containsdigitandslash (bikel et al. 1999)

brown id91

    words with similar vector representations are 

clustered together, in an agglomerative 
(recursive) way
    for example,    monday   ,    tuesday   , etc. may form 
a new vector    day of the week   
    published by brown et al. [1992]

example

friday monday thursday wednesday tuesday saturday sunday weekends sundays
people guys folks fellows ceos chaps doubters commies unfortunates blokes
down backwards ashore sideways southward northward overboard aloft downwards adrift
water gas coal liquid acid sand carbon steam shale iron
great big vast sudden mere sheer gigantic lifelong scant colossal
american indian european japanese german african catholic israeli italian arab
mother wife father son husband brother daughter sister boss uncle
machine device controller processor cpu printer spindle subsystem compiler plotter
john george james bob robert paul william jim david mike
feet miles pounds degrees inches barrels tons acres meters bytes
had hadn't hath would've could've should've must've might've
that tha theat
head body hands eyes voice arm seat eye hair mouth

example

   

program only cares about spaces .

input:
    this is one document . it has two sentences but the 
    here is another document . it also has two sentences .
    and here is a third document with one sentence .
    this document is short .
    the dog ran in the park .
    the cat was chased by the dog .
    the dog chased the cat .

[code by michael heilman: https://github.com/mheilman/tan-id91]

.       
the     
is      
document
dog     
it      
one     
sentences
chased  
two     
has     
here    
this    
cat     
and     
sentence
ran     
in      
spaces  
another 
cares   
also    
only    
program 
was     
park    
but     
short   
with    
by      
a       
about   
third   

1011    
011    
110     
1110    
000     
101001  
11111   
1010111 
00111   
1010100 
1010110 
111101  
1000    
0010    
11110010
11110011
01011
0100
10101011011
1010001
101010111
1010000
10101011010
10101011001
001100
01010
10101011000
1001
111100001
001101
111100000
10101010
11110001

9
7
4
4
3
2
2
2
2
2
2
2
2
2
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1

[code by michael heilman]

external link

   

jason eisner   s awesome interactive spreadsheet 
about learning id48s
    http://cs.jhu.edu/~jason/papers/#eisner-2002-tnlp
    http://cs.jhu.edu/~jason/papers/eisner.id48.xls

introduction to nlp

transformation-based learning

transformation based learning
idea: change some labels given specific input 
   
patterns
    [brill 1995]
    example
    p(nn|sleep) = .9
    p(vb|sleep) = .1
    change nn to vb when the previous tag is to
    types of rules:
    the preceding (following) word is tagged z
    the word two before (after) is tagged z
    one of the two preceding (following) words is tagged z
    one of the three preceding (following) words is tagged z
    the preceding word is tagged z and the following word is 

tagged w

transformation based tagger

transformation based tagger

unknown words

nlp

