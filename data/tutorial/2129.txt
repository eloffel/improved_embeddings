nlp

introduction to nlp

feature selection

feature selection: the c2 test

    for a term t:

it
0
k00
k10

1
k01
k11

c

0
1

    c=class, it = feature
    testing for independence: p(c=0,it=0) should be equal 

to p(c=0) p(it=0)
p(c=0) = (k00+k01)/n
p(c=1) = 1-p(c=0) = (k10+k11)/n
p(it=0) = (k00+k10)/n
p(it=1) = 1-p(it=0) = (k01+k11)/n

feature selection: the c2 test

2

  

=

(

kkn
11
00
k
k
)(
+

2

kk
)
-
10
01
k
k
)(
+
11

(

k
11

+

+
    high values of c2 indicate lower belief in 

k
)(
10

k
10

01

00

01

independence.
in practice, compute c2 for all words and pick the 
top kamong them.

k

00

)

   

mutual information

    measures amount of information

    x = word; y = class

yxmi

(

,

)

    =

x

y

yxp

,(

log)

)
ypxp
)(

yxp
,(
)(

then mi=0

    if the distribution is the same as the background distribution, 
    documents are assumed to be generated 
according to the multinomial model

nlp

