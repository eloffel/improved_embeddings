nlp 

introduction to nlp

evaluation of classification 

evaluation of text classification 

       average over classes

       microaveraging 
       macroaveraging 
       uses pooled table

well-known datasets 

       20 newsgroups
       reuters-21578
reuters21578/ 

       http://qwone.com/~jason/20newsgroups/ 
       http://www.daviddlewis.com/resources/testcollections/
       cats: grain, acquisitions, corn, crude, wheat, trade   
       http://www-2.cs.cmu.edu/~webkb/ 
       course, student, faculty, staff, project, dept, other
       http://www.daviddlewis.com/resources/testcollections/rcv1/
       larger reuters corpus

       webkb

       rcv1

the 2-by-2 contingency table 

relevant 

not relevant 

selected 
not selected 

tp 
fn 

fp 
tn 

precision and recall 

       precision: % of selected items that are correct   

recall: % of correct items that are selected

relevant 

not relevant 

selected 
not selected 

tp 
fn 

fp 
tn 

pick a card    

a combined measure: f 

       a combined measure that assesses the p/r tradeoff is f 

measure (weighted harmonic mean):
pr
)1
+
rp
+

(
  
  

f

=

=

2

2

1
1(
   +

  

1
p

1)
  
r

       the harmonic mean is a very conservative average; see iir 
       people usually use balanced f1 measure

   8.3
         i.e., with    = 1 (that is,    =   ):   

     f = 2pr/(p+r)

classic reuters-21578 data set  
       most	
   (over)used	
   data	
   set,	
   21,578	
   docs	
   (each	
   90	
   types,	
   200	
   toknens)	
   
       9603	
   training,	
   3299	
   test	
   ar@cles	
   (modapte/lewis	
   split)	
   
       118	
   categories	
   

       an	
   ar@cle	
   can	
   be	
   in	
   more	
   than	
   one	
   category	
   
       learn	
   118	
   binary	
   category	
   dis@nc@ons	
   

       average	
   document	
   (with	
   at	
   least	
   one	
   category)	
   has	
   1.24	
   classes	
   
       only	
   about	
   10	
   out	
   of	
   118	
   categories	
   are	
   large	
   

common categories 
(#train, #test) 

       earn (2877, 1087)  
       acquisitions (1650, 179) 
       money-fx (538, 179) 
       grain (433, 149) 
       crude (389, 189) 

       trade (369,119) 
       interest (347, 131) 
       ship (197, 89) 
       wheat (212, 71) 
       corn (182, 56) 

confusion matrix c 

docs in test set  assigned 

       for each pair of classes <c1,c2> how many 

documents from c1 were incorrectly assigned to c2?
       c3,2: 90 wheat documents incorrectly assigned to poultry
assigned 
trade 
0 
0 
0 
7 
5 
10 

assigned 
poultry 
1 
1 
90 
0 
1 
0 

assigned 
wheat 
13 
0 
0 
0 
2 
2 

assigned 
coffee 
0 
0 
1 
34 
13 
14 

assigned 
interest 
1 
0 
0 
3 
26 
5 

uk 
95 
0 
10 
0 
- 
0 

true uk 
true poultry 
true wheat 
true coffee 
true interest 
true trade 

10 

micro- vs. macro-averaging 

       if	
   we	
   have	
   more	
   than	
   one	
   class,	
   how	
   do	
   we	
   combine	
   
mul@ple	
   performance	
   measures	
   into	
   one	
   quan@ty?	
   
       macroaveraging:	
   compute	
   performance	
   for	
   each	
   
       microaveraging:	
   collect	
   decisions	
   for	
   all	
   classes,	
   

class,	
   then	
   average.	
   

compute	
   con@ngency	
   table,	
   evaluate.	
   

which classifier works the 

best? 
       id166 gives the best performance
       discriminative approaches tend to be more 
effective than generative approaches, but in 
general, the difference between different classifiers 
is not so significant as that between different 
feature extraction methods
       need to consider other factors (e.g., efficiency, 
interpretability)

nlp 

