   #[1]algobeans    feed [2]algobeans    comments feed [3]algobeans    topic
   modeling with lda introduction comments feed [4]automated biography for
   a nation [5]k-nearest neighbor (knn) tutorial: anomaly detection
   [6]alternate [7]alternate [8]algobeans [9]wordpress.com

   [10]skip to content

[11]algobeans

layman tutorials in analytics

   (button) menu
     * [12]home
     * [13]about
     * [14]all posts
     * [15]subscribe

id96 with lda introduction

   [16]june 21, 2015september 23, 2016

   suppose you have the following set of sentences:
     * i eat fish and vegetables.
     * fish are pets.
     * my kitten eats fish.

   id44 (lda) is a technique that automatically
   discovers topics that these documents contain.

   given the above sentences, lda might classify the red words under the
   topic f, which we might label as    food   . similarly, blue words might be
   classified under a separate topic p, which we might label as    pets   .
   lda defines each topic as a bag of words, and you have to label the
   topics as you deem fit.

   there are 2 benefits from lda defining topics on a word-level:

   1) we can infer the content spread of each sentence by a word count:

   sentence 1: 100% topic f
   sentence 2: 100% topic p
   sentence 3: 33% topic p and 67% topic f

   2) we can derive the proportions that each word constitutes in given
   topics. for example, topic f might comprise words in the following
   proportions: 40% eat, 40% fish, 20% vegetables,    

   lda achieves the above results in 3 steps.

   to illustrate these steps, imagine that you are now discovering topics
   in documents instead of sentences. imagine you have 2 documents with
   the following words:

   lda1

   step 1
   you tell the algorithm how many topics you think there are. you can
   either use an informed estimate (e.g. results from a previous
   analysis), or simply trial-and-error. in trying different estimates,
   you may pick the one that generates topics to your desired level of
   interpretability, or the one yielding the highest statistical certainty
   (i.e. log likelihood). in our example above, the number of topics might
   be inferred just by eyeballing the documents.

   step 2
   the algorithm will assign every word to a temporary topic. topic
   assignments are temporary as they will be updated in step 3. temporary
   topics are assigned to each word in a semi-random manner (according to
   a dirichlet distribution, to be exact). this also means that if a word
   appears twice, each word may be assigned to different topics. note that
   in analyzing actual documents, function words (e.g.    the   ,    and   ,    my   )
   are removed and not assigned to any topics.

   step 3 (iterative)
   the algorithm will check and update topic assignments, looping through
   each word in every document. for each word, its topic assignment is
   updated based on two criteria:
     * how prevalent is that word across topics?
     * how prevalent are topics in the document?

   to understand how these two criteria work, imagine that we are now
   checking the topic assignment for the word    fish    in doc y:

   lda2
     * how prevalent is that word across topics? since    fish    words across
       both documents comprise nearly half of remaining topic f words but
       0% of remaining topic p words, a    fish    word picked at random would
       more likely be about topic f.

   lda3
     * how prevalent are topics in the document? since the words in doc y
       are assigned to topic f and topic p in a 50-50 ratio, the remaining
          fish    word seems equally likely to be about either topic.

   lda4

   weighing conclusions from the two criteria, we would assign the    fish   
   word of doc y to topic f. doc y might then be a document on what to
   feed kittens.

   the process of checking topic assignment is repeated for each word in
   every document, cycling through the entire collection of documents
   multiple times. this iterative updating is the key feature of lda that
   generates a final solution with coherent topics.

   example applications of id96:
   [17]generating an automated biography for a country with news articles

   did you learn something useful today? we would be glad to inform you
   when we have new tutorials, so that your learning continues!

   sign up below to get bite-sized tutorials delivered to your inbox:


   [18]free data science tutorials

   copyright    2015-present algobeans.com. all rights reserved. be a cool
   bean.


share this:

     * [19]click to share on facebook (opens in new window)
     * [20]click to share on linkedin (opens in new window)
     * [21]click to share on twitter (opens in new window)
     * [22]click to share on reddit (opens in new window)
     * [23]click to email this to a friend (opens in new window)
     *

like this:

   like loading...

related

   posted in: [24]tutorial | tagged: [25]layman, [26]lda, [27]machine
   learning, [28]text analysis, [29]id96, [30]tutorial

post navigation

   [31] automated biography for a nation
   [32]k-nearest neighbor (knn) tutorial: anomaly detection

19 thoughts on    id96 with lda introduction   

    1.
   [33]ahmad harmain (@h4rm41n_) says:
       [34]may 17, 2018 at 12:18 am
       [35]reply
       very helpful, thanks.
       [36]likeliked by [37]1 person
    2.
   sneha says:
       [38]february 6, 2018 at 4:51 pm
       [39]reply
       can you please explain with an example from 1st iteration to last
       iteration in more detailed way   
       [40]likelike
    3.
   mohamed elhosany says:
       [41]january 20, 2018 at 9:23 am
       [42]reply
       i am so happy and thank god for being here and read your post,
       still the best that i have read ever.
       [43]likelike
    4.
   mostafa says:
       [44]november 20, 2017 at 10:06 pm
       [45]reply
       sorry i am a newbie in the area of id96, i would ask you
       , is there any possibility to define the topics in beforehand?
       for instance to have some topics, named as soccer, tennis, etc.
       [46]likelike
    5. pingback: [47]capstone project #1: mining medical data     enterprise
       analytics
    6. pingback: [48]id96 with lda introduction | open data
       science
    7.
   sunil chinnamgari says:
       [49]february 27, 2017 at 12:46 am
       [50]reply
       good one annalyn. next time, i need to teach a group of students
       about this topic. i am going to use your example. i am sure they
       will understand the topic better than doing it with all math!     
       by the way, i know you have written a book recently compiling all
       the topics in a non-math way. is there a way the book be made
       available free for educational purposes. i see it is on sale on
       amazon.
       [51]likelike
    8.
   allen says:
       [52]october 18, 2016 at 3:41 am
       [53]reply
       hi annalyn,
       thanks for the explanation on this topic.
       for the example on how prevalent is that word across topics, since
       each word in the 2 documents is assigned to a random topic, how
       come the 3    fish    words happen to be assigned to the same topic f?
       thanks
       [54]likelike
          +
        [55]annalyn ng says:
            [56]october 18, 2016 at 9:05 am
            [57]reply
            hi allen, you   re most welcome. the assignment of the 3    fish   
            words was made all to be f for the ease of explanation. you
            can also view the assignments as occurring in the later stages
            of iteration, where topics are assigned more accurately. you
            are right that at the beginning, topics would be assigned more
            randomly     or according to a dirichlet distribution to be
            exact.
            [58]likelike
               o
             allen qin says:
                 [59]october 18, 2016 at 10:55 am
                 [60]reply
                 thanks for your reply annalyn. it makes sense now. though
                 i have another question now.
                 suppose by chance, in the first iteration, the majority
                 of    fish    words are assigned to the p topic, how can lda
                 correct the error over time? to me lda feels very
                 different from other ml algorithms where there is an cost
                 function to measure the correctness of your model at
                 every iteration. so for lda, how do we know if the
                 current iteration is better than the previous one?
                 thanks, allen
                 [61]likeliked by [62]1 person
                    #
                  [63]annalyn ng says:
                      [64]october 19, 2016 at 7:29 pm
                      [65]reply
                      allen, good question! to prevent these errors in the
                      first place, lda requires us to set initial
                      parameters that determine topic assignments. these
                      parameters are called alpha and beta. in a symmetric
                      dirichlet distribution, high alpha means that all
                      your documents contain most topics (as opposed to
                      documents containing a few or just a single topic).
                      high beta means that all your topics contain most of
                      the words in your corpus. lda works towards
                      optimizing topic assignments based on these
                      parameters through the iterative process.
                      [66]likeliked by [67]1 person
                         @
                       allen says:
                           [68]october 21, 2016 at 3:40 am
                           [69]reply
                           thanks annalyn. really appreciate your prompt
                           reply. i kind of get your point and will dig
                           into the details of the lda implementation to
                           understand how it works exactly. thanks. allen
                           [70]likelike
    9. pingback: [71]spark     lda : a complete example of id91
       algorithm for topic discovery. | knoldus
   10.
   ted says:
       [72]august 16, 2016 at 1:50 am
       [73]reply
       thanks, annalyn.
       i learned something from you.
       [74]likeliked by [75]1 person
          +
        [76]annalyn ng says:
            [77]august 16, 2016 at 11:59 pm
            [78]reply
            you   re most welcome ted.
            [79]likelike
   11.
   [80]ahsaas chawla says:
       [81]april 1, 2016 at 7:10 pm
       [82]reply
       very crisp and simple, for a layman. thanks annalyn!
       [83]likelike
          +
        [84]annalyn ng says:
            [85]april 1, 2016 at 7:12 pm
            [86]reply
            thanks ahsaas, glad you found it useful.
            [87]likelike
   12.
   james says:
       [88]august 20, 2015 at 7:34 pm
       [89]reply
       very helpful artical annalyn. thanks for posting.
       [90]likelike
          +
        annalyn ng says:
            [91]august 20, 2015 at 7:53 pm
            [92]reply
            glad you found it helpful, james.
            [93]likelike

leave a reply [94]cancel reply

   enter your comment here...

   ____________________________________________________________
   ____________________________________________________________
   ____________________________________________________________
   ____________________________________________________________

   fill in your details below or click an icon to log in:
     *
     *
     *
     *
     *

   [95]gravatar
   email (required) (address never made public)
   ____________________
   name (required)
   ____________________
   website
   ____________________
   wordpress.com logo

   you are commenting using your wordpress.com account. ( [96]log out /
   [97]change )
   google photo

   you are commenting using your google account. ( [98]log out /
   [99]change )
   twitter picture

   you are commenting using your twitter account. ( [100]log out /
   [101]change )
   facebook photo

   you are commenting using your facebook account. ( [102]log out /
   [103]change )
   [104]cancel

   connecting to %s

   [ ] notify me of new comments via email.

   [ ] notify me of new posts via email.

   post comment

   search for: ____________________ search

wanna learn data science?

   get intuitive explanations focusing on core concepts with no math.
   discover applications and pitfalls in concise 1500-word chapters.

   [105]free data science tutorials

   to see what you've missed so far, check out our tutorial compilation in
   our brand new book:

   [106]numsense algobeans

                  [107]top kdnuggets blogger for april 2017

follow us

     * [108]facebook
     * [109]twitter
     * [110]rss
     * [111]github

about algobeans

   algobeans is the brainchild of two data science enthusiasts, annalyn
   (university of cambridge) and kenneth (stanford university). we noticed
   that while data science is increasingly used to improve workplace
   decisions, many people know little about the field. hence, we created
   algobeans so that everyone and anyone can learn - be it an aspiring
   student or enterprising business professional. each tutorial covers the
   important functions and assumptions of a data science technique,
   without any math or jargon. we also illustrate these techniques with
   real-world data and examples.

wanna learn data science?

   get intuitive explanations focusing on core concepts with no math.
   discover applications and pitfalls in concise 1500-word posts delivered
   to your inbox.

   [112]free data science tutorials

   [tr?id=1258053584302511&amp;ev=pageview&amp;noscript=1]

   copyright    2015-present algobeans.com.
   all rights reserved. be a cool bean.

     * [113]facebook
     * [114]twitter
     * [115]rss
     * [116]github


   ____________________________________________________________
   ____________________________________________________________
   ____________________________________________________________
   ____________________________________________________________
   post to
   [117]cancel reblog post

   send to email address ____________________ your name
   ____________________ your email address ____________________
   _________________________
   loading send email [118]cancel
   post was not sent - check your email addresses!
   email check failed, please try again
   sorry, your blog cannot share posts by email.

   iframe: [119]likes-master

   %d bloggers like this:

references

   visible links
   1. https://algobeans.com/feed/
   2. https://algobeans.com/comments/feed/
   3. https://algobeans.com/2015/06/21/laymans-explanation-of-topic-modeling-with-lda-2/feed/
   4. https://algobeans.com/2015/06/04/automated-biography/
   5. https://algobeans.com/2015/06/22/anomaly-detection-with-predictive-algorithms/
   6. https://public-api.wordpress.com/oembed/?format=json&url=https://algobeans.com/2015/06/21/laymans-explanation-of-topic-modeling-with-lda-2/&for=wpcom-auto-discovery
   7. https://public-api.wordpress.com/oembed/?format=xml&url=https://algobeans.com/2015/06/21/laymans-explanation-of-topic-modeling-with-lda-2/&for=wpcom-auto-discovery
   8. https://algobeans.com/osd.xml
   9. https://s1.wp.com/opensearch.xml
  10. https://algobeans.com/2015/06/21/laymans-explanation-of-topic-modeling-with-lda-2/#content
  11. https://algobeans.com/
  12. https://algobeans.com/
  13. https://algobeans.com/about/
  14. https://algobeans.com/all-posts/
  15. https://algobeans.com/subscribe/
  16. https://algobeans.com/2015/06/21/laymans-explanation-of-topic-modeling-with-lda-2/
  17. https://algobeans.com/2015/06/04/automated-biography/
  18. http://eepurl.com/cbvfy1
  19. https://algobeans.com/2015/06/21/laymans-explanation-of-topic-modeling-with-lda-2/?share=facebook
  20. https://algobeans.com/2015/06/21/laymans-explanation-of-topic-modeling-with-lda-2/?share=linkedin
  21. https://algobeans.com/2015/06/21/laymans-explanation-of-topic-modeling-with-lda-2/?share=twitter
  22. https://algobeans.com/2015/06/21/laymans-explanation-of-topic-modeling-with-lda-2/?share=reddit
  23. https://algobeans.com/2015/06/21/laymans-explanation-of-topic-modeling-with-lda-2/?share=email
  24. https://algobeans.com/category/tutorial/
  25. https://algobeans.com/tag/layman/
  26. https://algobeans.com/tag/lda/
  27. https://algobeans.com/tag/machine-learning/
  28. https://algobeans.com/tag/text-analysis/
  29. https://algobeans.com/tag/topic-modeling/
  30. https://algobeans.com/tag/tutorial/
  31. https://algobeans.com/2015/06/04/automated-biography/
  32. https://algobeans.com/2015/06/22/anomaly-detection-with-predictive-algorithms/
  33. http://twitter.com/h4rm41n_
  34. https://algobeans.com/2015/06/21/laymans-explanation-of-topic-modeling-with-lda-2/#comment-705
  35. https://algobeans.com/2015/06/21/laymans-explanation-of-topic-modeling-with-lda-2/?replytocom=705#respond
  36. https://algobeans.com/2015/06/21/laymans-explanation-of-topic-modeling-with-lda-2/?like_comment=705&_wpnonce=8d201a23d5
  37. https://algobeans.com/2015/06/21/laymans-explanation-of-topic-modeling-with-lda-2/
  38. https://algobeans.com/2015/06/21/laymans-explanation-of-topic-modeling-with-lda-2/#comment-613
  39. https://algobeans.com/2015/06/21/laymans-explanation-of-topic-modeling-with-lda-2/?replytocom=613#respond
  40. https://algobeans.com/2015/06/21/laymans-explanation-of-topic-modeling-with-lda-2/?like_comment=613&_wpnonce=07c56f1b3d
  41. https://algobeans.com/2015/06/21/laymans-explanation-of-topic-modeling-with-lda-2/#comment-609
  42. https://algobeans.com/2015/06/21/laymans-explanation-of-topic-modeling-with-lda-2/?replytocom=609#respond
  43. https://algobeans.com/2015/06/21/laymans-explanation-of-topic-modeling-with-lda-2/?like_comment=609&_wpnonce=9efd500c00
  44. https://algobeans.com/2015/06/21/laymans-explanation-of-topic-modeling-with-lda-2/#comment-572
  45. https://algobeans.com/2015/06/21/laymans-explanation-of-topic-modeling-with-lda-2/?replytocom=572#respond
  46. https://algobeans.com/2015/06/21/laymans-explanation-of-topic-modeling-with-lda-2/?like_comment=572&_wpnonce=1e768e314f
  47. https://cis450asu.wordpress.com/2017/06/29/capstone-project-1-mining-medical-data/
  48. https://opendatascience.com/blog/topic-modeling-with-lda-introduction/
  49. https://algobeans.com/2015/06/21/laymans-explanation-of-topic-modeling-with-lda-2/#comment-270
  50. https://algobeans.com/2015/06/21/laymans-explanation-of-topic-modeling-with-lda-2/?replytocom=270#respond
  51. https://algobeans.com/2015/06/21/laymans-explanation-of-topic-modeling-with-lda-2/?like_comment=270&_wpnonce=8d20053105
  52. https://algobeans.com/2015/06/21/laymans-explanation-of-topic-modeling-with-lda-2/#comment-179
  53. https://algobeans.com/2015/06/21/laymans-explanation-of-topic-modeling-with-lda-2/?replytocom=179#respond
  54. https://algobeans.com/2015/06/21/laymans-explanation-of-topic-modeling-with-lda-2/?like_comment=179&_wpnonce=0e4a50e3b4
  55. http://algobeans.com/
  56. https://algobeans.com/2015/06/21/laymans-explanation-of-topic-modeling-with-lda-2/#comment-180
  57. https://algobeans.com/2015/06/21/laymans-explanation-of-topic-modeling-with-lda-2/?replytocom=180#respond
  58. https://algobeans.com/2015/06/21/laymans-explanation-of-topic-modeling-with-lda-2/?like_comment=180&_wpnonce=9dcbf519c0
  59. https://algobeans.com/2015/06/21/laymans-explanation-of-topic-modeling-with-lda-2/#comment-181
  60. https://algobeans.com/2015/06/21/laymans-explanation-of-topic-modeling-with-lda-2/?replytocom=181#respond
  61. https://algobeans.com/2015/06/21/laymans-explanation-of-topic-modeling-with-lda-2/?like_comment=181&_wpnonce=ea5fd71738
  62. https://algobeans.com/2015/06/21/laymans-explanation-of-topic-modeling-with-lda-2/
  63. http://algobeans.com/
  64. https://algobeans.com/2015/06/21/laymans-explanation-of-topic-modeling-with-lda-2/#comment-183
  65. https://algobeans.com/2015/06/21/laymans-explanation-of-topic-modeling-with-lda-2/?replytocom=183#respond
  66. https://algobeans.com/2015/06/21/laymans-explanation-of-topic-modeling-with-lda-2/?like_comment=183&_wpnonce=741b7a804d
  67. https://algobeans.com/2015/06/21/laymans-explanation-of-topic-modeling-with-lda-2/
  68. https://algobeans.com/2015/06/21/laymans-explanation-of-topic-modeling-with-lda-2/#comment-186
  69. https://algobeans.com/2015/06/21/laymans-explanation-of-topic-modeling-with-lda-2/?replytocom=186#respond
  70. https://algobeans.com/2015/06/21/laymans-explanation-of-topic-modeling-with-lda-2/?like_comment=186&_wpnonce=43714228cb
  71. http://blog.knoldus.com/2016/10/08/spark-lda-id91/
  72. https://algobeans.com/2015/06/21/laymans-explanation-of-topic-modeling-with-lda-2/#comment-129
  73. https://algobeans.com/2015/06/21/laymans-explanation-of-topic-modeling-with-lda-2/?replytocom=129#respond
  74. https://algobeans.com/2015/06/21/laymans-explanation-of-topic-modeling-with-lda-2/?like_comment=129&_wpnonce=91a3de2e25
  75. https://algobeans.com/2015/06/21/laymans-explanation-of-topic-modeling-with-lda-2/
  76. http://algobeans.com/
  77. https://algobeans.com/2015/06/21/laymans-explanation-of-topic-modeling-with-lda-2/#comment-130
  78. https://algobeans.com/2015/06/21/laymans-explanation-of-topic-modeling-with-lda-2/?replytocom=130#respond
  79. https://algobeans.com/2015/06/21/laymans-explanation-of-topic-modeling-with-lda-2/?like_comment=130&_wpnonce=3963d72e41
  80. https://plus.google.com/105511034096161541396
  81. https://algobeans.com/2015/06/21/laymans-explanation-of-topic-modeling-with-lda-2/#comment-30
  82. https://algobeans.com/2015/06/21/laymans-explanation-of-topic-modeling-with-lda-2/?replytocom=30#respond
  83. https://algobeans.com/2015/06/21/laymans-explanation-of-topic-modeling-with-lda-2/?like_comment=30&_wpnonce=35ba368dfa
  84. http://annalyn-ng.com/
  85. https://algobeans.com/2015/06/21/laymans-explanation-of-topic-modeling-with-lda-2/#comment-31
  86. https://algobeans.com/2015/06/21/laymans-explanation-of-topic-modeling-with-lda-2/?replytocom=31#respond
  87. https://algobeans.com/2015/06/21/laymans-explanation-of-topic-modeling-with-lda-2/?like_comment=31&_wpnonce=cfa2812326
  88. https://algobeans.com/2015/06/21/laymans-explanation-of-topic-modeling-with-lda-2/#comment-11
  89. https://algobeans.com/2015/06/21/laymans-explanation-of-topic-modeling-with-lda-2/?replytocom=11#respond
  90. https://algobeans.com/2015/06/21/laymans-explanation-of-topic-modeling-with-lda-2/?like_comment=11&_wpnonce=b415ae19f8
  91. https://algobeans.com/2015/06/21/laymans-explanation-of-topic-modeling-with-lda-2/#comment-12
  92. https://algobeans.com/2015/06/21/laymans-explanation-of-topic-modeling-with-lda-2/?replytocom=12#respond
  93. https://algobeans.com/2015/06/21/laymans-explanation-of-topic-modeling-with-lda-2/?like_comment=12&_wpnonce=230919657b
  94. https://algobeans.com/2015/06/21/laymans-explanation-of-topic-modeling-with-lda-2/#respond
  95. https://gravatar.com/site/signup/
  96. javascript:highlandercomments.doexternallogout( 'wordpress' );
  97. https://algobeans.com/2015/06/21/laymans-explanation-of-topic-modeling-with-lda-2/
  98. javascript:highlandercomments.doexternallogout( 'googleplus' );
  99. https://algobeans.com/2015/06/21/laymans-explanation-of-topic-modeling-with-lda-2/
 100. javascript:highlandercomments.doexternallogout( 'twitter' );
 101. https://algobeans.com/2015/06/21/laymans-explanation-of-topic-modeling-with-lda-2/
 102. javascript:highlandercomments.doexternallogout( 'facebook' );
 103. https://algobeans.com/2015/06/21/laymans-explanation-of-topic-modeling-with-lda-2/
 104. javascript:highlandercomments.cancelexternalwindow();
 105. http://eepurl.com/cbvfy1
 106. http://getbook.at/numsense
 107. http://www.kdnuggets.com/2017/04/data-science-layman-no-math-added.html
 108. https://www.facebook.com/algobeans/
 109. https://twitter.com/algobeans
 110. https://algobeans.com/feed
 111. https://github.com/algobeans/numsense
 112. http://eepurl.com/cbvfy1
 113. https://www.facebook.com/algobeans/
 114. https://twitter.com/algobeans
 115. https://algobeans.com/feed
 116. https://github.com/algobeans/numsense
 117. https://algobeans.com/2015/06/21/laymans-explanation-of-topic-modeling-with-lda-2/
 118. https://algobeans.com/2015/06/21/laymans-explanation-of-topic-modeling-with-lda-2/#cancel
 119. https://widgets.wp.com/likes/master.html?ver=20190321#ver=20190321

   hidden links:
 121. https://algobeans.com/2015/06/21/laymans-explanation-of-topic-modeling-with-lda-2/#comment-form-guest
 122. https://algobeans.com/2015/06/21/laymans-explanation-of-topic-modeling-with-lda-2/#comment-form-load-service:wordpress.com
 123. https://algobeans.com/2015/06/21/laymans-explanation-of-topic-modeling-with-lda-2/#comment-form-load-service:twitter
 124. https://algobeans.com/2015/06/21/laymans-explanation-of-topic-modeling-with-lda-2/#comment-form-load-service:facebook
