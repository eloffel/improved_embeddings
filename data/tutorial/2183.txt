   #[1]edwin chen's blog atom feed [2]edwin chen's blog rss feed

[3]introduction to id44

introduction

   suppose you have the following set of sentences:
     * i like to eat broccoli and bananas.
     * i ate a banana and spinach smoothie for breakfast.
     * chinchillas and kittens are cute.
     * my sister adopted a kitten yesterday.
     * look at this cute hamster munching on a piece of broccoli.

   what is id44? it   s a way of automatically
   discovering topics that these sentences contain. for example, given
   these sentences and asked for 2 topics, lda might produce something
   like
     * sentences 1 and 2: 100% topic a
     * sentences 3 and 4: 100% topic b
     * sentence 5: 60% topic a, 40% topic b
     * topic a: 30% broccoli, 15% bananas, 10% breakfast, 10% munching,    
       (at which point, you could interpret topic a to be about food)
     * topic b: 20% chinchillas, 20% kittens, 20% cute, 15% hamster,     (at
       which point, you could interpret topic b to be about cute animals)

   the question, of course, is: how does lda perform this discovery?

lda model

   in more detail, lda represents documents as mixtures of topics that
   spit out words with certain probabilities. it assumes that documents
   are produced in the following fashion: when writing each document, you
     * decide on the number of words n the document will have (say,
       according to a poisson distribution).
     * choose a topic mixture for the document (according to a dirichlet
       distribution over a fixed set of k topics). for example, assuming
       that we have the two food and cute animal topics above, you might
       choose the document to consist of 1/3 food and 2/3 cute animals.
     * generate each word w_i in the document by:
          + first picking a topic (according to the multinomial
            distribution that you sampled above; for example, you might
            pick the food topic with 1/3 id203 and the cute animals
            topic with 2/3 id203).
          + using the topic to generate the word itself (according to the
            topic   s multinomial distribution). for example, if we selected
            the food topic, we might generate the word    broccoli    with 30%
            id203,    bananas    with 15% id203, and so on.

   assuming this generative model for a collection of documents, lda then
   tries to backtrack from the documents to find a set of topics that are
   likely to have generated the collection.

example

   let   s make an example. according to the above process, when generating
   some particular document d, you might
     * pick 5 to be the number of words in d.
     * decide that d will be 1/2 about food and 1/2 about cute animals.
     * pick the first word to come from the food topic, which then gives
       you the word    broccoli   .
     * pick the second word to come from the cute animals topic, which
       gives you    panda   .
     * pick the third word to come from the cute animals topic, giving you
          adorable   .
     * pick the fourth word to come from the food topic, giving you
          cherries   .
     * pick the fifth word to come from the food topic, giving you
          eating   .

   so the document generated under the lda model will be    broccoli panda
   adorable cherries eating    (note that lda is a bag-of-words model).

learning

   so now suppose you have a set of documents. you   ve chosen some fixed
   number of k topics to discover, and want to use lda to learn the topic
   representation of each document and the words associated to each topic.
   how do you do this? one way (known as collapsed id150) is the
   following:
     * go through each document, and randomly assign each word in the
       document to one of the k topics.
     * notice that this random assignment already gives you both topic
       representations of all the documents and word distributions of all
       the topics (albeit not very good ones).
     * so to improve on them, for each document d   
          + go through each word w in d   
               o and for each topic t, compute two things: 1) p(topic t |
                 document d) = the proportion of words in document d that
                 are currently assigned to topic t, and 2) p(word w |
                 topic t) = the proportion of assignments to topic t over
                 all documents that come from this word w. reassign w a
                 new topic, where we choose topic t with id203
                 p(topic t | document d) * p(word w | topic t) (according
                 to our generative model, this is essentially the
                 id203 that topic t generated word w, so it makes
                 sense that we resample the current word   s topic with this
                 id203). (also, i   m glossing over a couple of things
                 here, in particular the use of priors/pseudocounts in
                 these probabilities.)
               o in other words, in this step, we   re assuming that all
                 topic assignments except for the current word in question
                 are correct, and then updating the assignment of the
                 current word using our model of how documents are
                 generated.
     * after repeating the previous step a large number of times, you   ll
       eventually reach a roughly steady state where your assignments are
       pretty good. so use these assignments to estimate the topic
       mixtures of each document (by counting the proportion of words
       assigned to each topic within that document) and the words
       associated to each topic (by counting the proportion of words
       assigned to each topic overall).

layman   s explanation

   in case the discussion above was a little eye-glazing, here   s another
   way to look at lda in a different domain.

   suppose you   ve just moved to a new city. you   re a hipster and an anime
   fan, so you want to know where the other hipsters and anime geeks tend
   to hang out. of course, as a hipster, you know you can   t just ask, so
   what do you do?

   here   s the scenario: you scope out a bunch of different establishments
   (documents) across town, making note of the people (words) hanging out
   in each of them (e.g., alice hangs out at the mall and at the park, bob
   hangs out at the movie theater and the park, and so on). crucially, you
   don   t know the typical interest groups (topics) of each establishment,
   nor do you know the different interests of each person.

   so you pick some number k of categories to learn (i.e., you want to
   learn the k most important kinds of categories people fall into), and
   start by making a guess as to why you see people where you do. for
   example, you initially guess that alice is at the mall because people
   with interests in x like to hang out there; when you see her at the
   park, you guess it   s because her friends with interests in y like to
   hang out there; when you see bob at the movie theater, you randomly
   guess it   s because the z people in this city really like to watch
   movies; and so on.

   of course, your random guesses are very likely to be incorrect (they   re
   random guesses, after all!), so you want to improve on them. one way of
   doing so is to:
     * pick a place and a person (e.g., alice at the mall).
     * why is alice likely to be at the mall? probably because other
       people at the mall with the same interests sent her a message
       telling her to come.
     * in other words, the more people with interests in x there are at
       the mall and the stronger alice is associated with interest x (at
       all the other places she goes to), the more likely it is that alice
       is at the mall because of interest x.
     * so make a new guess as to why alice is at the mall, choosing an
       interest with some id203 according to how likely you think it
       is.

   go through each place and person over and over again. your guesses keep
   getting better and better (after all, if you notice that lots of geeks
   hang out at the bookstore, and you suspect that alice is pretty geeky
   herself, then it   s a good bet that alice is at the bookstore because
   her geek friends told her to go there; and now that you have a better
   idea of why alice is probably at the bookstore, you can use this
   knowledge in turn to improve your guesses as to why everyone else is
   where they are), and eventually you can stop updating. then take a
   snapshot (or multiple snapshots) of your guesses, and use it to get all
   the information you want:
     * for each category, you can count the people assigned to that
       category to figure out what people have this particular interest.
       by looking at the people themselves, you can interpret the category
       as well (e.g., if category x contains lots of tall people wearing
       jerseys and carrying around basketballs, you might interpret x as
       the    basketball players    group).
     * for each place p and interest category c, you can compute the
       proportions of people at p because of c (under the current set of
       assignments), and these give you a representation of p. for
       example, you might learn that the people who hang out at barnes &
       noble consist of 10% hipsters, 50% anime fans, 10% jocks, and 30%
       college students.

real-world example

   finally, i applied lda to a set of sarah palin   s emails a little while
   ago (see [4]here for the blog post, or [5]here for an app that allows
   you to browse through the emails by the lda-learned categories), so
   let   s give a brief recap. here are some of the topics that the
   algorithm learned:
     * trig/family/inspiration: family, web, mail, god, son, from,
       congratulations, children, life, child, down, trig, baby, birth,
       love, you, syndrome, very, special, bless, old, husband, years,
       thank, best,    
     * wildlife/bp corrosion: game, fish, moose, wildlife, hunting, bears,
       polar, bear, subsistence, management, area, board, hunt, wolves,
       control, department, year, use, wolf, habitat, hunters, caribou,
       program, denby, fishing,    
     * energy/fuel/oil/mining: energy, fuel, costs, oil, alaskans, prices,
       cost, nome, now, high, being, home, public, power, mine, crisis,
       price, resource, need, community, fairbanks, rebate, use, mining,
       villages,    
     * gas: gas, oil, pipeline, agia, project, natural, north, producers,
       companies, tax, company, energy, development, slope, production,
       resources, line, gasline, transcanada, said, billion, plan,
       administration, million, industry,    
     * education/waste: school, waste, education, students, schools,
       million, read, email, market, policy, student, year, high, news,
       states, program, first, report, business, management, bulletin,
       information, reports, 2008, quarter,    
     * presidential campaign/elections: mail, web, from, thank, you, box,
       mccain, sarah, very, good, great, john, hope, president, sincerely,
       wasilla, work, keep, make, add, family, republican, support, doing,
       p.o,    

   here   s an example of an email which fell 99% into the
   trig/family/inspiration category (particularly representative words are
   highlighted in blue):

   [6]trig email

   and here   s an excerpt from an email which fell 10% into the
   presidential campaign/election category (in red) and 90% into the
   wildlife/bp corrosion category (in green):

   [7]wildlife-presidency email

   [8]edwin chen

   ai, stats, data science, human computation.

   math/cs/linguistics at mit, id103 at msr, quant trading at
   clarium, ads at twitter, data science at dropbox, stats/ml at google.
   [9]quora
   [10]twitter
   [11]github
   [12]linkedin
   [13]email

recent posts

   [14]exploring lstms
   [15]moving beyond ctr: better recommendations through human evaluation
   [16]propensity modeling, causal id136, and discovering drivers of
   growth
   [17]product insights for airbnb
   [18]improving twitter search with real-time human computation
   [19]edge prediction in a social graph: my solution to facebook's user
   recommendation contest on kaggle
   [20]soda vs. pop with twitter
   [21]infinite mixture models with nonparametric bayes and the dirichlet
   process
   [22]instant interactive visualization with d3 + ggplot2
   [23]movie recommendations and more via mapreduce and scalding
   [24]quick introduction to ggplot2
   [25]introduction to id49
   [26]winning the netflix prize: a summary
   [27]stuff harvard people like
   [28]information transmission in a social network: dissecting the spread
   of a quora post


    proudly powered by [29]pelican, which takes great advantage of
    [30]python.

references

   1. http://blog.echen.me/feeds/all.atom.xml
   2. http://blog.echen.me/feeds/all.rss.xml
   3. http://blog.echen.me/2011/08/22/introduction-to-latent-dirichlet-allocation/
   4. http://blog.echen.me/2011/06/27/topic-modeling-the-sarah-palin-emails/
   5. http://sarah-palin.heroku.com/
   6. http://dl.dropbox.com/u/10506/blog/palin-browser/trig-email.png
   7. http://dl.dropbox.com/u/10506/blog/palin-browser/wildlife-presidency-email.png
   8. http://blog.echen.me/
   9. https://quora.com/edwin-chen-1
  10. https://twitter.com/echen
  11. https://github.com/echen
  12. https://www.linkedin.com/in/edwinchen1
  13. mailto:hello[  ]echen.me
  14. http://blog.echen.me/2017/05/30/exploring-lstms/
  15. http://blog.echen.me/2014/10/07/moving-beyond-ctr-better-recommendations-through-human-evaluation/
  16. http://blog.echen.me/2014/08/15/propensity-modeling-causal-id136-and-discovering-drivers-of-growth/
  17. http://blog.echen.me/2014/08/14/product-insights-for-airbnb/
  18. http://blog.echen.me/2013/01/08/improving-twitter-search-with-real-time-human-computation
  19. http://blog.echen.me/2012/07/31/edge-prediction-in-a-social-graph-my-solution-to-facebooks-user-recommendation-contest-on-kaggle/
  20. http://blog.echen.me/2012/07/06/soda-vs-pop-with-twitter/
  21. http://blog.echen.me/2012/03/20/infinite-mixture-models-with-nonparametric-bayes-and-the-dirichlet-process/
  22. http://blog.echen.me/2012/03/05/instant-interactive-visualization-with-d3-and-ggplot2/
  23. http://blog.echen.me/2012/02/09/movie-recommendations-and-more-via-mapreduce-and-scalding/
  24. http://blog.echen.me/2012/01/17/quick-introduction-to-ggplot2/
  25. http://blog.echen.me/2012/01/03/introduction-to-conditional-random-fields/
  26. http://blog.echen.me/2011/10/24/winning-the-netflix-prize-a-summary/
  27. http://blog.echen.me/2011/09/29/stuff-harvard-people-like/
  28. http://blog.echen.me/2011/09/07/information-transmission-in-a-social-network-dissecting-the-spread-of-a-quora-post/
  29. http://getpelican.com/
  30. http://python.org/
