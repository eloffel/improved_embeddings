   #[1]github [2]recent commits to berkeley-doc-summarizer:master

   [3]skip to content

   (button)

     * why github?
       [4]features    
          + [5]code review
          + [6]project management
          + [7]integrations
          + [8]actions
          + [9]team management
          + [10]social coding
          + [11]documentation
          + [12]code hosting
          + [13]customer stories    
          + [14]security    
     * [15]enterprise
     * explore
          + [16]explore github    

learn & contribute
          + [17]topics
          + [18]collections
          + [19]trending
          + [20]learning lab
          + [21]open source guides

connect with others
          + [22]events
          + [23]community forum
          + [24]github education
     * [25]marketplace
     * pricing
       [26]plans    
          + [27]compare plans
          + [28]contact sales
          + [29]nonprofit    
          + [30]education    

   ____________________
     * in this repository all github    
       jump to    

     * no suggested jump to results

     * in this repository all github    
       jump to    
     * in this repository all github    
       jump to    

   [31]sign in [32]sign up

     * [33]watch [34]28
     * [35]star [36]663
     * [37]fork [38]53

[39]gregdurrett/[40]berkeley-doc-summarizer

   [41]code [42]issues 5 [43]pull requests 0 [44]projects 0 [45]insights
   (button) dismiss

join github today

   github is home to over 31 million developers working together to host
   and review code, manage projects, and build software together.
   [46]sign up
   the berkeley document summarizer is a learning-based, single-document
   summarization system that extracts source document content, exploits
   syntactic information to compress it, and uses coreference constraints
   to ensure clarity.
     * [47]15 commits
     * [48]1 branch
     * [49]0 releases
     * [50]fetching contributors
     * [51]gpl-3.0

    1. [52]scala 65.4%
    2. [53]perl 21.2%
    3. [54]java 13.0%
    4. [55]shell 0.4%

   (button) scala perl java shell
   branch: master (button) new pull request
   [56]find file
   clone or download

clone with https

   use git or checkout with svn using the web url.
   https://github.com/g
   [57]download zip

downloading...

   want to be notified of new releases in
   gregdurrett/berkeley-doc-summarizer?
   [58]sign in [59]sign up

launching github desktop...

   if nothing happens, [60]download github desktop and try again.

   (button) go back

launching github desktop...

   if nothing happens, [61]download github desktop and try again.

   (button) go back

launching xcode...

   if nothing happens, [62]download xcode and try again.

   (button) go back

launching visual studio...

   if nothing happens, [63]download the github extension for visual studio
   and try again.

   (button) go back
   fetching latest commit   
   cannot retrieve the latest commit at this time.
   [64]permalink
   type name latest commit message commit time
   failed to load latest commit information.
   [65]lib
   [66]project
   [67]id8/id8
   [68]src/main/scala
   [69]test
   [70]license
   [71]readme.md
   [72]acl2016_nyt50_eval_doc_list.txt
   [73]berkeley-doc-summarizer-assembly-1.jar
   [74]build.sbt
   [75]run-glpk-test.sh
   [76]run-summarizer.sh

readme.md

berkeley-doc-summarizer

   the berkeley document summarizer is a learning-based single-document
   summarization system. it compresses source document text based on
   constraints from constituency parses and rst discourse parses.
   moreover, it can improve summary clarity by reexpressing pronouns whose
   antecedents would otherwise be deleted or unclear.

   note: if all you're interested in is the new york times dataset, you do
   not need to do most of the setup and preprocessing below. instead, use
   the pre-built .jar and run the commands in the "new york times dataset"
   section under "training" below.

preamble

   the berkeley document summarizer is described in:

   "learning-based single-document summarization with compression and
   anaphoricity constraints" greg durrett, taylor berg-kirkpatrick, and
   dan klein. acl 2016.

   see [77]http://www.eecs.berkeley.edu/~gdurrett/ for papers and bibtex.

   questions? bugs? email me at [78]gdurrett@eecs.berkeley.edu

license

   copyright (c) 2013-2016 greg durrett. all rights reserved.

   this program is free software: you can redistribute it and/or modify it
   under the terms of the gnu general public license as published by the
   free software foundation, either version 3 of the license, or (at your
   option) any later version.

   this program is distributed in the hope that it will be useful, but
   without any warranty; without even the implied warranty of
   merchantability or fitness for a particular purpose. see the gnu
   general public license for more details.

   you should have received a copy of the gnu general public license along
   with this program. if not, see [79]http://www.gnu.org/licenses/

setup

models and data

   models are not included in github due to their large size. download the
   latest models from
   [80]http://nlp.cs.berkeley.edu/projects/summarizer.shtml. these are
   necessary for both training the system (you need the edu segmenter,
   discourse parser, and coreference model) as well as running it (you
   need the edu segmenter, discourse parser, and summarization model,
   which contains the coreference model). all of these are expected in the
   models/ subdirectory.

   we also require [81]number and gender data produced by shane bergsma
   and dekang lin in in "id64 path-based pronoun resolution".
   download this, untar/gzip it, and put it at data/gender.data (default
   path the system expects it to be at).

glpk

   for solving ilps, our system relies on glpk, specifically [82]glpk for
   java. for os x, the easiest way to install glpk is with [83]homebrew.
   on linux, you should run sudo apt-get install glpk-utils libglpk-dev
   libglpk-java.

   both the libglpk-java and java native interface (jni) libraries need to
   be in your java library path (see below for how to test this); these
   libraries allow java to interact with the native glpk code.
   additionally, when running the system, you must have
   glpk-java-1.1.0.jar on the build path; this is included in the lib
   directory and bundled with the distributed jar, and will continue to be
   included automatically if you build with sbt.

   you can test whether the system can call glpk successfully with with
   run-glpk-test.sh, which tries to solve a small ilp defined in
   edu.berkeley.nlp.summ.glpktest. the script attempts to augment the
   library path with /usr/local/lib/jni, which is sometimes where the jni
   library is located on os x. if this script reports an error, you may
   need to augment the java library path with the location of either the
   jni or the libglpk_java libraries as follows:
-djava.library.path="<current library path>:<location of additional library>"

building from source

   the easiest way to build is with sbt:
   [84]https://github.com/harrah/xsbt/wiki/getting-started-setup

   then run
sbt assembly

   which will compile everything and build a runnable jar.

   you can also import it into eclipse and use the scala ide plug-in for
   eclipse [85]http://scala-ide.org

running the system

   the two most useful main classes are edu.berkeley.nlp.summ.main and
   edu.berkeley.nlp.summ.summarizer. the former is a more involved harness
   for training and evaluating the system on the new york times corpus
   (see below for how to acquire this corpus), and the latter simply takes
   a trained model and runs it. both files contain descriptions of their
   functionality and command-line arguments.

   an example run on new data is included in run-summarizer.sh. the main
   prerequisite for running the summarizer on new data is having that data
   preprocessed in the conll format with constituency parses, ner, and
   coreference. for a system that does this, see the [86]berkeley entity
   resolution system. the test/ directory already contains a few such
   files.

   the summarizer then does additional processing with edu segmentation
   and discourse parsing. these use the models that are by default located
   in models/edusegmenter.ser.gz and models/discoursedep.ser.gz. you can
   control these with command-line switches.

   the system is distributed with several pre-trained variants:
     * summarizer-extractive.ser.gz: a sentence-extractive summarizer
     * summarizer-extractive-compressive.ser.gz: an extractive-compressive
       summarizer
     * summarizer-full.ser.gz: an extractive-compressive summarizer with
       the ability to rewrite pronouns and additional coreference features
       and constraints

training

new york times dataset

   the primary corpus we use for training and evaluation is the new york
   times annotated corpus (sandhaus, 2007), ldc2008t19. we distribute our
   preprocessing as standoff annotations which replace words with (line,
   char start, char end) triples, except for some cases where words are
   included manually (e.g. when id121 makes our data
   non-recoverable from the original file). a few scattered tokens are
   included explicitly, plus roughly 1% of files that our system couldn't
   find a suitable alignment for.

   to prepare the dataset, first you need to extract all the xml files
   from 2003-2007 and flatten them into a single directory. not all files
   have summaries, so not all of these will be used. next, run
mkdir train_corefner
java -xmx3g -cp <jarpath> edu.berkeley.nlp.summ.preprocess.standoffannotationhan
dler \
  -inputdir train_corefner_standoff/ -rawxmldir <path_to_flattened_nyt_xmls> -ou
tputdir train_corefner/

   this will take the train standoff annotation files and reconstitute the
   real files using the xml data, writing to the output directory. use
   eval instead of train to reconstitute the test set.

   to reconstitute abstracts, run:
java -xmx3g -cp <jarpath> edu.berkeley.nlp.summ.preprocess.standoffannotationhan
dler \
  -inputdir train_abstracts_standoff/ -rawxmldir <path_to_flattened_nyt_xmls> -o
utputdir train_abstracts/ \
  -tagname "abstract"

   and similarly swap out for eval appropriately.

id8 scorer

   we bundle the system with a version of the id8 scorer that will be
   called during execution. id8-gillick.sh hardcodes command-line
   arguments used in this work and in hirao et al. (2013)'s work. the
   system expects this in the id8/id8/ directory under the execution
   directory, along with the appropriate data files (which we've also
   bundled with this release).

   see edu.berkeley.nlp.summ.id8computer.evaluateid8nontok for a
   method you can use to evaluate id8 in a manner consistent with our
   evaluation.

training the system

   to train the full system, run:
java -xmx80g -cp <jarpath> -djava.library.path=<library path>:/usr/local/lib/jni
 edu.berkeley.nlp.summ.main \
  -traindocspath <path_to_train_conll_docs> -trainabstractspath <path_to_train_s
ummaries> \
  -evaldocspath <path_to_eval_conll_docs> -evalabstractspath <path_to_eval_summa
ries> -abstractsareconll \
  -modelpath "models/trained-model.ser.gz" -corefmodelpath "models/coref-onto.se
r.gz" \
  -printsummaries -printsummariesforturk \

   where <jarpath>, <library path>, and the data paths are instantiated
   accordingly. the system requires a lot of memory due to caching 25,000
   training documents with annotations.

   to train the sentence extractive version of the system, add:
-dopronounreplacement false -usefragilepronouns false -norst

   to train the extractive-compressive version, add:
-dopronounreplacement false -usefragilepronouns false

   the results you get using this command should be:
     * extractive: id8-1 recall: 38.6 / id8-2 recall: 23.3
     * extractive-compressive: id8-1 recall: 42.2 / id8-2 recall: 26.1
     * full: id8-1 recall: 41.9 / id8-2 recall: 25.7

   (results are slightly different from those in the paper due to minor
   changes for this release.)

     *    2019 github, inc.
     * [87]terms
     * [88]privacy
     * [89]security
     * [90]status
     * [91]help

     * [92]contact github
     * [93]pricing
     * [94]api
     * [95]training
     * [96]blog
     * [97]about

   (button) you can   t perform that action at this time.

   you signed in with another tab or window. [98]reload to refresh your
   session. you signed out in another tab or window. [99]reload to refresh
   your session.

   (button)

references

   visible links
   1. https://github.com/opensearch.xml
   2. https://github.com/gregdurrett/berkeley-doc-summarizer/commits/master.atom
   3. https://github.com/gregdurrett/berkeley-doc-summarizer#start-of-content
   4. https://github.com/features
   5. https://github.com/features/code-review/
   6. https://github.com/features/project-management/
   7. https://github.com/features/integrations
   8. https://github.com/features/actions
   9. https://github.com/features#team-management
  10. https://github.com/features#social-coding
  11. https://github.com/features#documentation
  12. https://github.com/features#code-hosting
  13. https://github.com/customer-stories
  14. https://github.com/security
  15. https://github.com/enterprise
  16. https://github.com/explore
  17. https://github.com/topics
  18. https://github.com/collections
  19. https://github.com/trending
  20. https://lab.github.com/
  21. https://opensource.guide/
  22. https://github.com/events
  23. https://github.community/
  24. https://education.github.com/
  25. https://github.com/marketplace
  26. https://github.com/pricing
  27. https://github.com/pricing#feature-comparison
  28. https://enterprise.github.com/contact
  29. https://github.com/nonprofit
  30. https://education.github.com/
  31. https://github.com/login?return_to=/gregdurrett/berkeley-doc-summarizer
  32. https://github.com/join
  33. https://github.com/login?return_to=/gregdurrett/berkeley-doc-summarizer
  34. https://github.com/gregdurrett/berkeley-doc-summarizer/watchers
  35. https://github.com/login?return_to=/gregdurrett/berkeley-doc-summarizer
  36. https://github.com/gregdurrett/berkeley-doc-summarizer/stargazers
  37. https://github.com/login?return_to=/gregdurrett/berkeley-doc-summarizer
  38. https://github.com/gregdurrett/berkeley-doc-summarizer/network/members
  39. https://github.com/gregdurrett
  40. https://github.com/gregdurrett/berkeley-doc-summarizer
  41. https://github.com/gregdurrett/berkeley-doc-summarizer
  42. https://github.com/gregdurrett/berkeley-doc-summarizer/issues
  43. https://github.com/gregdurrett/berkeley-doc-summarizer/pulls
  44. https://github.com/gregdurrett/berkeley-doc-summarizer/projects
  45. https://github.com/gregdurrett/berkeley-doc-summarizer/pulse
  46. https://github.com/join?source=prompt-code
  47. https://github.com/gregdurrett/berkeley-doc-summarizer/commits/master
  48. https://github.com/gregdurrett/berkeley-doc-summarizer/branches
  49. https://github.com/gregdurrett/berkeley-doc-summarizer/releases
  50. https://github.com/gregdurrett/berkeley-doc-summarizer/graphs/contributors
  51. https://github.com/gregdurrett/berkeley-doc-summarizer/blob/master/license
  52. https://github.com/gregdurrett/berkeley-doc-summarizer/search?l=scala
  53. https://github.com/gregdurrett/berkeley-doc-summarizer/search?l=perl
  54. https://github.com/gregdurrett/berkeley-doc-summarizer/search?l=java
  55. https://github.com/gregdurrett/berkeley-doc-summarizer/search?l=shell
  56. https://github.com/gregdurrett/berkeley-doc-summarizer/find/master
  57. https://github.com/gregdurrett/berkeley-doc-summarizer/archive/master.zip
  58. https://github.com/login?return_to=https://github.com/gregdurrett/berkeley-doc-summarizer
  59. https://github.com/join?return_to=/gregdurrett/berkeley-doc-summarizer
  60. https://desktop.github.com/
  61. https://desktop.github.com/
  62. https://developer.apple.com/xcode/
  63. https://visualstudio.github.com/
  64. https://github.com/gregdurrett/berkeley-doc-summarizer/tree/3c32487b7419e8b76a5ec2e5233de7c75ca93fa8
  65. https://github.com/gregdurrett/berkeley-doc-summarizer/tree/master/lib
  66. https://github.com/gregdurrett/berkeley-doc-summarizer/tree/master/project
  67. https://github.com/gregdurrett/berkeley-doc-summarizer/tree/master/id8/id8
  68. https://github.com/gregdurrett/berkeley-doc-summarizer/tree/master/src/main/scala
  69. https://github.com/gregdurrett/berkeley-doc-summarizer/tree/master/test
  70. https://github.com/gregdurrett/berkeley-doc-summarizer/blob/master/license
  71. https://github.com/gregdurrett/berkeley-doc-summarizer/blob/master/readme.md
  72. https://github.com/gregdurrett/berkeley-doc-summarizer/blob/master/acl2016_nyt50_eval_doc_list.txt
  73. https://github.com/gregdurrett/berkeley-doc-summarizer/blob/master/berkeley-doc-summarizer-assembly-1.jar
  74. https://github.com/gregdurrett/berkeley-doc-summarizer/blob/master/build.sbt
  75. https://github.com/gregdurrett/berkeley-doc-summarizer/blob/master/run-glpk-test.sh
  76. https://github.com/gregdurrett/berkeley-doc-summarizer/blob/master/run-summarizer.sh
  77. http://www.eecs.berkeley.edu/~gdurrett/
  78. mailto:gdurrett@eecs.berkeley.edu
  79. http://www.gnu.org/licenses/
  80. http://nlp.cs.berkeley.edu/projects/summarizer.shtml
  81. http://www.cs.utexas.edu/~gdurrett/data/gender.data.tgz
  82. http://glpk-java.sourceforge.net/
  83. http://brew.sh/
  84. https://github.com/harrah/xsbt/wiki/getting-started-setup
  85. http://scala-ide.org/
  86. https://github.com/gregdurrett/berkeley-entity
  87. https://github.com/site/terms
  88. https://github.com/site/privacy
  89. https://github.com/security
  90. https://githubstatus.com/
  91. https://help.github.com/
  92. https://github.com/contact
  93. https://github.com/pricing
  94. https://developer.github.com/
  95. https://training.github.com/
  96. https://github.blog/
  97. https://github.com/about
  98. https://github.com/gregdurrett/berkeley-doc-summarizer
  99. https://github.com/gregdurrett/berkeley-doc-summarizer

   hidden links:
 101. https://github.com/
 102. https://github.com/gregdurrett/berkeley-doc-summarizer
 103. https://github.com/gregdurrett/berkeley-doc-summarizer
 104. https://github.com/gregdurrett/berkeley-doc-summarizer
 105. https://help.github.com/articles/which-remote-url-should-i-use
 106. https://github.com/gregdurrett/berkeley-doc-summarizer#berkeley-doc-summarizer
 107. https://github.com/gregdurrett/berkeley-doc-summarizer#preamble
 108. https://github.com/gregdurrett/berkeley-doc-summarizer#license
 109. https://github.com/gregdurrett/berkeley-doc-summarizer#setup
 110. https://github.com/gregdurrett/berkeley-doc-summarizer#models-and-data
 111. https://github.com/gregdurrett/berkeley-doc-summarizer#glpk
 112. https://github.com/gregdurrett/berkeley-doc-summarizer#building-from-source
 113. https://github.com/gregdurrett/berkeley-doc-summarizer#running-the-system
 114. https://github.com/gregdurrett/berkeley-doc-summarizer#training
 115. https://github.com/gregdurrett/berkeley-doc-summarizer#new-york-times-dataset
 116. https://github.com/gregdurrett/berkeley-doc-summarizer#id8-scorer
 117. https://github.com/gregdurrett/berkeley-doc-summarizer#training-the-system
 118. https://github.com/
