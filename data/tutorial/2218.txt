   #[1]the keras blog atom feed

                               [2]the keras blog

   [3]keras is a deep learning library for python, that is simple,
   modular, and extensible.

     * [4]archives
     * [5]github
     * [6]documentation
     * [7]google group

          [8]running jupyter notebooks on gpu on aws: a starter guide

   tue 21 march 2017


    by [9]francois chollet

   in [10]tutorials.

   this is a step by step guide to start running deep learning jupyter
   notebooks on an aws gpu instance, while editing the notebooks from
   anywhere, in your browser. this is the perfect setup for deep learning
   research if you do not have a gpu on your local machine.

what are jupyter notebooks? why run jupyter notebooks on aws gpus?

   a jupyter notebook is a web app that allows you to write and annotate
   python code interactively. it's a great way to experiment, do research,
   and share what you are working on. [11]here's what a notebook looks
   like.

   a lot of deep learning applications are very computationally intensive,
   and would take hours or even days when running on a laptop's cpu cores.
   running on gpu can speed up training and id136 by a considerable
   factor (often 5x to 10x, when going from a modern cpu to a single
   modern gpu). however, you may not have access to a gpu on your local
   machine. running jupyter notebooks on aws gives you the same experience
   as running on your local machine, while allowing you to leverage one or
   several gpus on aws. and you only pay for what you use, which can
   compare favorably versus investing in your own gpu(s) if you only use
   deep learning occasionally.

why would i not want to use jupyter on aws for deep learning?

   aws gpu instances can quickly become expensive. the one we suggest
   using costs $0.90 per hour. this is fine for occasional use, but if you
   are going to run experiments for several hours per day every day, then
   you are better off building your own deep learning machine, featuring a
   titan x or gtx 1080 ti.

before you start

   note:
     * you will need an active aws account.
     * some familiarity with aws ec2 will help, but isn't mandatory.

   it will take 5 to 10 minutes to get set up.
     __________________________________________________________________

step-by-step guide

1 - navigate to [12]the ec2 control panel and follow the "launch instance"
link.

   ec2 control panel

2 - select the official aws deep learning ubuntu ami.

   to find it, select "aws marketplace" and search for "deep learning" in
   the search box.

   ec2 ami marketplace

   scroll down until you find the ami named "deep learning ami ubuntu
   version" (pictured below). select this ami.

   deep learning ami

3 - select the p2.xlarge instance.

   this instance type provides access to a single gpu and costs $0.90 per
   hour of usage (as of march 2017). click "configure instance details".

   the p2.xlarge instance

4 - configure instance details

   you can keep the default configuration for the steps "configure
   instance", "add storage", "add tags". but we will customize the step
   "configure security group".

   create a custom tcp rule to allow port 8888.

   this rule can either be allowed for your current public ip (e.g. that
   of your laptop), or for any ip (e.g. 0.0.0.0/0) if the former is not
   possible. note that if you do allow port 8888 for any ip, then
   literally anyone will be able to listen to that port on your instance
   (which is where we will be running our ipython notebooks). we will add
   password protection to the notebooks to migitate the risk of random
   strangers modifying them, but that may be pretty weak protection. if at
   all possible, you should really consider restricting the access to a
   specific ip. however, if your ip address changes constantly, then that
   is not a very pratical choice. if you are going to leave access open to
   any ip, then remember not to leave any sensitive data on the instance.

   configure a new security group

   at the end of the launch process, you will be asked if you want to
   create new connection keys or if you want to reuse existing keys. if
   you have never use ec2 before, simply create new keys and download
   them.

5 - launch your instance and connect to it.

   to connect to your instance, select it on the ec2 control panel, click
   the "connect" button, and follow the instructions provided, e.g.:

   connect instructions

   note that it may take a just minutes until the instance is fully booted
   up. if you can't connect at first, wait a bit and retry.

6 - set up ssl certificates

   once you are logged into the instance via ssh, create a ssl directory
   at the root of the instance and cd to it (not mandatory, but cleaner).
mkdir ssl
cd ssl

   create a new ssl certificate using openssl:
sudo openssl req -x509 -nodes -days 365 -newkey rsa:1024 -keyout "cert.key" -out
 "cert.pem" -batch

   when done, you will have created two files in the current ssl
   directory: cert.key and cert.pem.

6 - configure jupyter

   before we start using jupyter, we need to touch-up its default
   configuration. first, we will need to generate a new jupyter config
   file (still on the remote instance):
jupyter notebook --generate-config

   optionally, you can generate a jupyter password for your notebooks.
   since your instance may be configured to be accessible from any ip
   (depending on the choice you made when configuring the security group),
   it is better to restrict access to jupyter via a password. to generate
   a password, open an ipython shell (command ipython) and run:
from ipython.lib import passwd
passwd()
exit

   the passwd() command will ask you to enter and verify a password, and
   when that is done, is will display the hash of your password. copy that
   hash, we will need it soon. it looks something like:
   "sha1:b592a9cf2ec6:b99edb2fd3d0727e336185a0b0eab561aa533a43" (that's
   the hash of "password", which is not a password you should be using).

   next, use vi (or your favorite available text editor) to edit the
   config file:
vi ~/.jupyter/jupyter_notebook_config.py

   it's a python file where all line are commented-out.

   you need to insert the following lines of python code (e.g. at the
   start of the file):
c = get_config()  # get the config object
c.notebookapp.certfile = u'/home/ubuntu/ssl/cert.pem' # path to the certificate
we generated
c.notebookapp.keyfile = u'/home/ubuntu/ssl/cert.key' # path to the certificate k
ey we generated
c.ipkernelapp.pylab = 'inline'  # in-line figure when using matplotlib
c.notebookapp.ip = '*'  # serve the notebooks locally
c.notebookapp.open_browser = false  # do not open a browser window by default wh
en using notebooks
c.notebookapp.password = 'sha1:b592a9cf2ec6:b99edb2fd3d0727e336185a0b0eab561aa53
3a43'  # this is the password hash that we generated earlier.

   in case you are not a vi person, remember that you need to press i to
   start inserting content, and when you are done, you can hit esc then
   :wq and finally enter to quit vi while saving your changes (:wq stands
   for write-quit).

7 - update keras

   you are almost ready to start using jupyter. but first, make sure to
   update keras. albeit there is a version of keras pre-installed on the
   ami, it may not necessarily be up to date. on the remote instance, run:

   .install keras [source,cs]
     __________________________________________________________________

sudo pip install keras --upgrade

   in case you plan on using python 3, you should also update keras using
   pip3:

   .updating keras for python 3 [source,cs]
     __________________________________________________________________

sudo pip3 install keras --upgrade

   in case there is any existing keras configuration file on the instance
   (this should not be the case, but the ami may have changed since we
   wrote this guide), you should delete it, just in case. keras will
   recreate a standard configuration file when it is launched for the
   first time.

   if the code snippet below returns an error saying that the file does
   not exist, then you can just ignore it.

   .cleaning up the keras config file [source,cs]
     __________________________________________________________________

rm ~/.keras/keras.json

8 - set up local port forwarding

   in a shell on your local machine (not the remote instance), start
   fowarding your local port 443 (the https port) to port 8888 of the
   remote instance. this is done using the syntax:
sudo ssh -i awskeys.pem -l local_port:local_machine:remote_port remote_machine

   in our case this becomes:
sudo ssh -i awskeys.pem -l 443:127.0.0.1:8888 ubuntu@ec2-54-147-126-214.compute-
1.amazonaws.com

9 - start using jupyter from your local browser

   first, on the remote instance, create the folder where you will save
   your notebooks:
mkdir notebooks
cd notebooks

   start jupyter notebook by running this command inside the folder you
   create, on the remote instance:
jupyter notebook

   then, in your local browser, navigate to the local address which we are
   fowarding to the remote notebook process, https://127.0.0.1. make sure
   that you use https in the address, otherwise you will get an ssl error.

   you should see a safety warning:

   safety warning

   this warning is simply due to the fact that the ssl certificate we
   generated isn't verified by any trusted authority (obviously: we just
   generated our own). click "advanced" and proceed to navigate, which is
   safe.

   you should then be prompted to enter your jupyter password. you will
   then arrive to the jupyter dashboard.

   dashboard

   click "new -> notebook" to get started. you can use the python version
   of your choice.

   create a new notebook

   all set!


    powered by [13]pelican, which takes great advantages of [14]python.

references

   1. https://blog.keras.io/
   2. https://blog.keras.io/index.html
   3. https://github.com/fchollet/keras
   4. https://blog.keras.io/
   5. https://github.com/fchollet/keras
   6. http://keras.io/
   7. https://groups.google.com/forum/#!forum/keras-users
   8. https://blog.keras.io/running-jupyter-notebooks-on-gpu-on-aws-a-starter-guide.html
   9. https://twitter.com/fchollet
  10. https://blog.keras.io/category/tutorials.html
  11. https://github.com/leriomaggio/deep-learning-keras-tensorflow/blob/master/1.3 introduction - keras.ipynb
  12. https://console.aws.amazon.com/ec2/v2/
  13. http://alexis.notmyidea.org/pelican/
  14. http://python.org/
