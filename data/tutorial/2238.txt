   #[1]analytics vidhya    feed [2]analytics vidhya    comments feed
   [3]analytics vidhya    tutorial     data science at command line with r &
   python (scikit learn) comments feed [4]alternate [5]alternate

   iframe: [6]//googletagmanager.com/ns.html?id=gtm-mpsm42v

   [7]new certified ai & ml blackbelt program (beginner to master) -
   enroll today @ launch offer (coupon: blackbelt10)

   (button) search______________
     * [8]learn
          + [9]blog archive
               o [10]machine learning
               o [11]deep learning
               o [12]career
               o [13]stories
          + [14]datahack radio
          + [15]infographics
          + [16]training
          + [17]learning paths
               o [18]sas business analyst
               o [19]learn data science on r
               o [20]data science in python
               o [21]data science in weka
               o [22]data visualization with tableau
               o [23]data visualization with qlikview
               o [24]interactive data stories with d3.js
          + [25]glossary
     * [26]engage
          + [27]discuss
          + [28]events
          + [29]datahack summit 2018
          + [30]datahack summit 2017
          + [31]student datafest
          + [32]write for us
     * [33]compete
          + [34]hackathons
     * [35]get hired
          + [36]jobs
     * [37]courses
          + [38]id161 using deep learning
          + [39]natural language processing using python
          + [40]introduction to data science
          + [41]microsoft excel
          + [42]more courses
     * [43]contact

     *
     *
     *
     *

     * [44]home
     * [45]blog archive
     * [46]trainings
     * [47]discuss
     * [48]datahack
     * [49]jobs
     * [50]corporate

     *

   [51]analytics vidhya - learn everything about analytics

learn everything about analytics

   [52][black-belt-2.gif]
   [53][black-belt-2.gif]
   [54][black-belt-2.gif]
   (button) search______________

   [55]analytics vidhya - learn everything about analytics
     * [56]learn
          + [57]blog archive
               o [58]machine learning
               o [59]deep learning
               o [60]career
               o [61]stories
          + [62]datahack radio
          + [63]infographics
          + [64]training
          + [65]learning paths
               o [66]sas business analyst
               o [67]learn data science on r
               o [68]data science in python
               o [69]data science in weka
               o [70]data visualization with tableau
               o [71]data visualization with qlikview
               o [72]interactive data stories with d3.js
          + [73]glossary
     * [74]engage
          + [75]discuss
          + [76]events
          + [77]datahack summit 2018
          + [78]datahack summit 2017
          + [79]student datafest
          + [80]write for us
     * [81]compete
          + [82]hackathons
     * [83]get hired
          + [84]jobs
     * [85]courses
          + [86]id161 using deep learning
          + [87]natural language processing using python
          + [88]introduction to data science
          + [89]microsoft excel
          + [90]more courses
     * [91]contact

   [92]home [93]machine learning [94]tutorial     data science at command
   line with r & python (scikit learn)

   [95]machine learning[96]python[97]r

tutorial     data science at command line with r & python (scikit learn)

   [98]guest blog, august 1, 2016

introduction

   the thought of doing data science at command line may possibly cause
   you to wonder, what new devilry is that?

   as if, it weren   t enough that, an aspiring data scientist has to keep
   up with learning, python / r / spark / scala / julia and what not just
   to stay abreast, that someone   s adding one more to that stack?

   worry not, it   s not something new (a part of it is new though) but
   something that   s already existed for a while and with a bit of fresh
   perspective might just become a quintessential part of your
   data-science-workflow.

   my inspiration to write this article derived from a book data science
   at the command line by jeroen janssens. since then, i   ve been reading
   up and applying things i learnt by using it in my workflow.

   i hope, by demonstrating some quick hands-on examples in this article,
   i can whet your appetite for more command line goodness and hopefully
   you   ll get brand new skill-set in your arsenal. i   ve explained every
   bit of code to help you understand command line faster.

   note: for modeling purpose, i   ve used id75, id79
   and gradient boosting algorithm.

   tutorial on data science at command line with r & scikit learn


table of contents

     * why data science at command line?
          + data science is osemn
     * required installations
     * part 1 : obtain | scrub | explore data
          + practice problem     black friday
     * part 2 : visualize     using r on command line
     * part 3 : model with scikit-learn on command line
     * summary
     * end notes:
          + general
          + about awk & sed


why data science @ the command line?

   given that data science is such a multi-disciplinary field, we have
   folks from wide variety of professional background and skills; one of
   the most common ones being some experience using the unix command line,
   even if it be for basic actions like cp / grep / cat / wc / head / tail
   / awk */ sed* / bash*.

   the command line has existed for a long time and can be found on any
   unix based os. even, microsoft windows has now come out with a bash
   shell. so, it becomes pretty appealing to have one system to carry out
   data science tasks.

   taking the ideas from the unix philosophy, of text being the input
   /output most command produce and that a unix command performing one
   type of action and doing it well; piping these commands together, we
   can augment these in our data science workflows.

   unix pipes allow us to pass on the output of one command as input for
   the next one. have a look at the gnu [99]site to see the various free
   and robust tools developed by the os community     quite interesting to
   have a wide-array of tools at your disposal to carry out tasks. lastly,
   command line tasks can be automated and operated in parallel thereby
   making it quick and efficient.

   in the age of big data and iot, the appeal for command line tools still
   persists. imagine, instead of moving around large amounts of data, you
   could analyse it, visualise it, and get a feel for it directly from the
   command line!

   does it mean, that we should do away with r / python or others and do
   everything on the command line? perhaps not, rather just use the right
   tool at the right time in the right context and use the command line to
   supplement r / python / other tools.

   a popular taxonomy of data science describes it as osemn (pronounced:
   awesome)

   [100]article2

   (dragon due of [101]got finale still fresh in my mind)
     * o: obtain, data from various sources
     * s:  scrub, perform data wrangling
     * e:  explore
     * m: model
     * n:   interpret

   in practice, osemn tends to be a cyclical process as opposed to a
   purely linear one. in this article, we shall only be covering the osem
   parts of the osemn acronym.


required installations

   before we can get started, let   s ensure we have everything required to
   work on command line:

   packages & commands
    1. all: the easiest way to get along doing hands on exercises is to
       use the virtual machine (vm) created by jeroen janssen ([102]here)
       with all tools pre-installed. also, you can find the code on
       jeroen   s git [103]here or buy the book (i don   t get anything out of
       this).

    2. linux & osx: if you are confident about command line, most packages
       can be easily installed on linux / mac based machines using pip
       install or apt-get or brew (mac osx). some of them require special
       package managers like npm to be installed and some (such as awk,
       sed, cat, head, tail, grep, nl etc.) are already pre-installed on
       linux / mac machines. it should essentially be a
       one-time installation. i personally prefer to install them once and
       be done with it. jeroen   s [104]book list all the commands used in
       the appendix and ways to install them in bit more detail than what
       i have.

   to carry out the exercises, you   ll mostly need datamash, csvkit, and
   skll     which can be installed as follows,
     * pip install datamash
          + datamash documentation [105]here.
     * pip install csvkit
          + csvkit documentation [106]here.
     * rio & header are available on jeroen   s git [107]here. you   ll need
       to extend your unix path so the bash shell knows where to look for
       the command. [108]here is how you can extend your unix path.
     * pip install skll
     * if using python 2.7, pip install configparser futures logutils

   not the most important right away,
     * pip install cowsay (for the dragon-image)
     * pip install imagemagick or brew install imagemagick (mac only)

   windows:  you   ll need the same packages as in linux / osx section. it   s
   just you might have to put more effort to install it.
     * windows 10 now comes with the functionality to install a bash
       shell. below are the links to microsoft   s website, explaining how
       to use bash shell. i haven   t used it personally, so can   t comment
       on how straightforward it is to install packages there.
          + [109]link1 and [110]link2
     * for other windows versions: use [111]cygwin and try to install the
       packages.
     * as a last resort, you can use the    free tier    from amazon aws. more
       info [112]here. just pick up any linux instance ubuntu or open
       suse, install the same packages as above and get going.

   once you   ve installed the tools, and need help, you can use the unix
   command man command-name or command-name --help on the command line to
   get further help or our good friend google is always there!


part 1: obtain | scrub | explore data

   we   ll use the data set from[113] black friday practice problem. feel
   free to work together on your command line as we go through the
   examples     just make sure, you have installed all the packages and
   refer to end notes if you get stuck.

   after you   ve downloaded the file from link above, unzip it in a folder
   and rename the extracted csv file as  bftrain.csv. ensure that you
   change your present working directory to the folder where you   ve
   downloaded & extracted the csv file.

   use the    cd    command to change directory

   let   s look at some of the most common tasks to be performed with a new
   data set. we   ll now check out the dimension of this data set using 2
   methods (you can use any):

   > cat bftrain.csv | awk -f, ' end {print " #rows = " nr, " # columns =
   " nf}   
   output: #rows = 550069  # columns = 12 #method 1

   > cat bftrain.csv | datamash    t, check
   output: 550069 lines, 12 fields  #method 2

   we know the file is comma separated and the first row is a header. in
   method 1, awk is used to count the #rows and #columns and display it in
   a nice format. just for fun, prefix the command, time to both the
   methods above to compare the 2 methods, like this:

   > time cat bftrain.csv | datamash    t, check

   let   s perform basic steps of data exploration now:

   1. columns: now, we   ll check for available columns in the data set:

   > head    n 1 bftrain.csv | tr    ,       \n    | nl
   output
   1  user_id
   2  product_id
   3  gender
   4  age
   5  occupation
   6  city_category
   7  stay_in_current_city_years
   8  marital_status
   9  product_category_1
   10 product_category_2
   11 product_category_3
   12 purchase

   in the command above, we just took the first row of the file and used
   tr to transform the commas (remember, it   s a csv file) to a new-line
   separator. nl is used to print line numbers.


   2. rows: check first few rows of the data

   > head    n 5 bftrain.csv | csvlook

   in this command, we used the regular head command to select top 5 rows
   and pipe it to command csvlook to present it in a nice tabular format.

   in case you   re having difficulty viewing the output on your command
   line, try the following to view a section of the data at a time.
   let   s display first 5 columns of the file:

   > head bftrain.csv | csvcut    c 1-5 | csvlook

   now, displaying the remaining columns:

   > head bftrain.csv | csvcut    c 6- | csvlook


   3. value counts: let   s dive deeper into the variables. let   s see how
   many male / female respondents exist in the data.

   > cat bftrain.csv | datamash -t, -s -h -g 3 count 3 | csvlook

   the cat command just pips in the file. then, using datamash, we ask to
   group by the 3rd column (gender) and do a count on the same. the
   datamash [114]documentation explains all the various options used.

   tip: in case your data has too many columns, it might be a good idea to
   use csvcut to just select the columns you need and use it for further
   processing.

   exercise: try answering the following questions:-
    1. how many people live in the different cities?
    2. can you find all the unique occupations? (hint: use command
          unique   )


   4. groupby stats: is there a difference in the purchase amount by
   gender?

   there are many ways to answer this. we can use something everyone
   would be very familiar with i.e. sql     yes we can write sql queries
   directly on the command line to query a csv file.

   > cat bftrain.csv | csvsql --query "select gender,avg(purchase),
   min(purchase), max(purchase) from stdin group by 1" | csvlook


   5. crosstabs: how are men / women distributed by age group?

   > cat bftrain.csv | datamash -t, -s -h crosstab 4,3 | csvlook


   6. scrub data: just for argument   s sake, assume that we have to remove
   the    +    sign from the observations of    age    column. we can do it as
   follows:

   > cat bftrain.csv | sed    s/+//g    > newfile.csv

   here, we use sed to remove the    +    sign in the age column.


   7. na / nulls: how do we find out if the data contains nas?

   > csvstat bftrain.csv --nulls

   here, we call upon csvstat and pass the argument --nulls to get a
   true/false style output per column.

   exercise: pass the following arguments one-at-a-time to csvstat to get
   other useful info about the data    min,    max ,    median,    unique

   hopefully by now, you might have realized that command line can be
   pretty handy and fast while working on a data set. however, until
   here we   ve just scratched the surface by doing exploratory work so far.
   to drive the point home, just reflect on the point that we did all of
   the things above, without actually loading the data (in memory as in r
   or python). pretty cool eh?


   8. different data formats

   perhaps you   ve noticed that until now, we   ve only used data in nicely
   formatted csv or txt files. but, surely in the age of big data and iot
   that   s not all what command line can handle, can it? let   s look at some
   available options:

   1. in2csv

   it   s part of the csvkit command line utility. it   s a really awesome
   command line tool that can handle csv, geojson, json, ndjson, xls,
   xlsx, and dbase dbf.

   2. convert xlsx to csv

   > curl -l -o
   https://github.com/onyxfish/csvkit/raw/master/examples/realdata/ne_1033
   _data.xlsx > ne_1033_data.xlsx

   > in2csv ne_1033_data.xlsx > ne_1033_data.csv

   in here, we   ve simply used curl to download the excel file and save it.
   then, we used in2csv to convert excel to a csv file of same name.

   3. json to csv

   utility tools such as in2csv and jq allow us to handle json and other
   data formats.

   4. databases

   again csvkit comes to the rescue here, providing a tool sql2csv that
   allows us to query on several different databases (e.g. oracle, mysql,
   and postgres etc.).


part 2: visualize     using r on the command line

   how cool would it be if we could leverage our r knowledge, scripts
   directly on the command line?

   as you might have guessed by now, there exists a solution for this too.
   jeroen (the author of data science at command line) has created many
   handy tools, and one of them is rio. it   s an acronym for r input/
   output. rio is essentially a wrapper function around r that allows us
   to use r commands on the command line.

   let   s get cracking!

   #summary stats
   > cat bftrain.csv | rio    e    summary(df$purchase)   

   #calculating correlation between age and purchase amount
   > cat bftrain.csv | csvcut    c age,purchase | cut    d    -       f 2 | sed
      s/+//g    | rio    f cor | csvlook

   let   s understand how it works. here, we select the columns age,
   purchase using csvcut. since, age is presented as a range of values
   like 0-17, 26-35 etc., we use cut to select the upper limit of the age
   range (think of it as using substring to select a specific portion of a
   text).

   next, we remove the    +    sign from the age column using sed. finally, we
   make a call to rio to check correlation between the 2 columns and
   present it nicely using csvlook.


   data visualisation:  let   s use another data set now. we   ll refer to the
   [115]uci irvine website and download    abalone    dataset. this data set
   is about predicting the age of abalone (oyster like sea-creature) from
   physical measurements. the target column in the data is rings.

   #getting actual data
   > curl
   http://archive.ics.uci.edu/ml/machine-learning-databases/abalone/abalon
   e.data > abalone.csv

   #getting data description
   > curl
   http://archive.ics.uci.edu/ml/machine-learning-databases/abalone/abalon
   e.names > abalonenames.txt

   #view sample data
   > head abalone.csv | csvlook

   #create a scatterplot
   > cat abalone.csv | csvcut    c rings,diameter,sex | rio    ge
      g+geom_point(aes(diameter,rings,color=factor(sex)))    | display

   let   s understand how the above code works!

   as usual, we take the input data file, select the columns we need.
   then, we call rio and the r-code to create a scatter plot colour coded
   by sex (m / f) and save it to a file. the code to create r-graphs is
   that of ggplot2.

   if you are unable to see the image , just change the command above as:

   > cat abalone.csv | csvcut    c rings,diameter,sex | rio    ge
      g+geom_point(aes(diameter,rings,color=factor(sex)))    > abascatter.jpeg

   this will redirect the output graph as a jpeg file into your current
   working directory. this is how it would look like:[116] article 3

   #boxplot
   > cat abalone.csv | csvcut    c rings,sex | rio    ge
      g+geom_boxplot(aes(sex, rings))    > ababoxp.jpeg

   we used ggplot to produce a boxplot and divert it as a jpeg file in
   your current working directory.


part 3: modeling with scikit-learn on the command line

   now we come to the final and perhaps the most interesting part of
   modeling data on the command line with scikit-learn. let   s continue
   with the abalone data set used above.

   we can extract the column names from the abalonenames.txt file as:

   > tail    n +89 abalonenames.txt | awk    nr<10{print $1}    | tr    \n       ,    |
   sed    s/,//9   
   output: sex,length,diameter,height,whole,shucked,viscera,shell,rings

   let   s see what we just did.
     * here, i filtered the description file. then, i used awk to select 9
       rows and printed them on the same line separated by commas using
       tr. later, i viewed the abalonenames.txt file in a text editor (for
       e.g. notepad++) to get the line #89.
     * of course, we could have just copied the column names from the text
       file directly but i just wanted to show how we could do it
       automatically on the command line. we do this because in this case,
       data file doesn   t have headers.

   we need to do some groundwork before we can start modelling. the steps
   are as follows,
    1. add the column names to the data file.
    2. add an id column (for e.g. 1,2,3   ) at the start of the data file to
       easily identify the predictions later.
    3. create a config file to set the parameters for the model.

   let   s do it.

   1. add the column names to the data file.

   now, we   ll extract the column names from the abalonenames.txt and store
   it in a separate file abalonecn.txt

   > tail    n +89 abalonenames.txt | awk    nr<10{print $1}    | tr    \n       ,    |
   sed    s/,//9    > abalonecn.txt

   > cat abalone.csv | header    e    cat abalonecn.txt    > abalone_2.csv

   in the command above, i used sed to remove the 9^th comma. then,
   i piped in the abalone.csv file and called upon the command header
   which is allowed us to header to a standard output / file. the
   abalonecn.txt is then passed on to it and the output is directed to a
   new file called abalone_2.csv.


   2. add an id column at the start of the features.csv file

   > mkdir train | cat abalone_2.csv | nl    s, -w1    v0 | sed    1s/0,/id,    >
   ./train/features.csv

   let   s see what we did:
     * we created a new directory called folder, piped in the
       abalone_2.csv file, invoked the nl command as we used earlier to
       add numbers starting count at 0 and separated by a comma.
     * finally, we called upon sed to only replace 0 in the header row
       with id, and save the file as features.csv under the train
       directory.


   3. creating a config file

   we   ll now create a config file which contains the model configurations.
   you can create it using any text editor; just remember to save it as
      predict-rings.id18   . it   s contents should be:

   [general]
   experiment_name = abalone
   task = cross_validate
   [input]
   train_location = train
   featuresets = [["features.csv"]]
   learners =
   ["linearregression","gradientboostingregressor","randomforestregressor"
   ]
   label_col = rings
   [tuning]
   grid_search = false
   feature_scaling = both
   objective = r2
   [output]
   log = output
   results = output
   predictions = output

   let   s understand it as well. here we call the experiment, abalone. we
   used 10-fold cross-validation and 3 modeling techniques (linear
   regression, gradient boosting, id79). the target column is
   specified under, label_col as rings. more info about creating id18 files
   for run_experiment can be found [117]here.

   now that the groundwork is done, we can call start modeling.

   > run_experiment    l predict-rings.id18

   in this command, we call upon the run_experiment command to run the
   config file and start modeling. be patient, this command might take
   time to run.

   once modeling is done, the results can be found under the    output   
   directory (created in the directory folder, where the command
   run_experiment was run from).

   there are 4 types of files produced per modeling technique (for the 3
   techniques we used here, we end up with 12 files). files being (.log,
   .results, .results.json, .predictions) and a summary file (with suffix
   _summary) containing information about each fold. we can get the model
   summary as follows:

   > cat ./output/abalone_summary.tsv | csvsql    query    select
   learner_name, pearson from stdin where fold = 'average' order by
   pearson desc" | csvlook   
   learner_name              pearson
   randomforestregressor     0.744
   gradientboostingregressor 0.734
   linearregressor           0.726

   let   s understand it now:
     * first, we call upon abalone_summary.tsv file. using sql, we
       generated a summary of results. we see that id79 gives the
       best result in this case. the pearson score indicates the
       correlation between the true ranking (of the rings) and the
       predicted values.
     * we didn   t perform any feature engineering as this was just an
       exercise to show how we can model from the command line from the
       scikit learn.


end notes

   general
     * in case you find yourself using a set of commands in your workflow
       quite regularly, you can put them together in a bash script and
       reuse them time and again!
     * it   s even possible to call bash command from ipython. here   s an
       [118]article describing it in detail.

   about awk / sed
     * perhaps may or may not have heard / used them before. this blog
       wasn   t meant as a class towards awk & sed programming but just as a
       key point, remember,
          + awk excels are line and column level processing of files,
            whereas,
          + sed (stream editor) excels at character level manipulation.
            sed commands tend to follow the general structure,

   sed   s/old/new where old is what you want to replace and new is what you
   will replace it with. essentially old and new are id157.

   this brings us to the end of this article. we   ve covered quite some
   ground     going through the already familiar data science tasks (getting
   data directly from the source, summarizing it, understanding it,
   plotting it, finally modeling it) and using a different way to approach
   them.

   i hope you enjoyed working on data at command line (probably for the
   first time) and feel encouraged to explore it further. it can seem a
   bit daunting at first to remember the various options, tool names but
   it   s only a matter of little practice. in the world of fancy guis, a
   classical command line does still hold a certain allure for me.

   my personal goal is to get proficient using command line tools more as
   part of my workflow and combine it with vowpal wabbit (read more
   [119]here), which is an [120]open source fast [121]out-of-core learning
   system library and program.

about author sandeep karkhanis

   sandeep karkhanis ([122]@sskarkhanis) is passionate about numbers. he
   has worked in few industries mainly insurance, banking and telcos. he
   is currently working as a data scientist in london. he strives to learn
   new ways of doing things. his primary goal is to use his data science
   skills for social causes and make human lives better. you can connect
   with sandeep at [123][email protected]


you can test your skills and knowledge. check out [124]live competitions and
compete with best data scientists from all over the world.

   you can also read this article on analytics vidhya's android app
   [125]get it on google play

share this:

     * [126]click to share on linkedin (opens in new window)
     * [127]click to share on facebook (opens in new window)
     * [128]click to share on twitter (opens in new window)
     * [129]click to share on pocket (opens in new window)
     * [130]click to share on reddit (opens in new window)
     *

like this:

   like loading...

related articles

   [ins: :ins]

   tags : [131]command line, [132]command line tools, [133]data
   exploration, [134]data science at command line, [135]data
   visualization, [136]feature engineering, [137]gradient boosting,
   [138]linear regressor, [139]machine learning, [140]pip install,
   [141]python, [142]id79, [143]scikit-learn, [144]scrub data
   next article

the evolution and core concepts of deep learning & neural networks

   previous article

making predictions on test data after principal component analysis in r

[145]guest blog

   this article is quite old and you might not get a prompt response from
   the author. we request you to post this comment on analytics vidhya's
   [146]discussion portal to get your queries resolved

   [ins: :ins]

top analytics vidhya users

   rank                  name                  points
   1    [1.jpg?date=2019-04-05] [147]srk       3924
   2    [2.jpg?date=2019-04-05] [148]mark12    3510
   3    [3.jpg?date=2019-04-05] [149]nilabha   3261
   4    [4.jpg?date=2019-04-05] [150]nitish007 3237
   5    [5.jpg?date=2019-04-05] [151]tezdhar   3082
   [152]more user rankings
   [ins: :ins]
   [ins: :ins]

popular posts

     * [153]24 ultimate data science projects to boost your knowledge and
       skills (& can be accessed freely)
     * [154]understanding support vector machine algorithm from examples
       (along with code)
     * [155]essentials of machine learning algorithms (with python and r
       codes)
     * [156]a complete tutorial to learn data science with python from
       scratch
     * [157]7 types of regression techniques you should know!
     * [158]6 easy steps to learn naive bayes algorithm (with codes in
       python and r)
     * [159]a simple introduction to anova (with applications in excel)
     * [160]stock prices prediction using machine learning and deep
       learning techniques (with python codes)

   [ins: :ins]

recent posts

   [161]top 5 machine learning github repositories and reddit discussions
   from march 2019

[162]top 5 machine learning github repositories and reddit discussions from
march 2019

   april 4, 2019

   [163]id161 tutorial: a step-by-step introduction to image
   segmentation techniques (part 1)

[164]id161 tutorial: a step-by-step introduction to image
segmentation techniques (part 1)

   april 1, 2019

   [165]nuts and bolts of id23: introduction to temporal
   difference (td) learning

[166]nuts and bolts of id23: introduction to temporal
difference (td) learning

   march 28, 2019

   [167]16 opencv functions to start your id161 journey (with
   python code)

[168]16 opencv functions to start your id161 journey (with python
code)

   march 25, 2019

   [169][ds-finhack.jpg]

   [170][hikeathon.png]

   [av-white.d14465ee4af2.png]

analytics vidhya

     * [171]about us
     * [172]our team
     * [173]career
     * [174]contact us
     * [175]write for us

   [176]about us
   [177]   
   [178]our team
   [179]   
   [180]careers
   [181]   
   [182]contact us

data scientists

     * [183]blog
     * [184]hackathon
     * [185]discussions
     * [186]apply jobs
     * [187]leaderboard

companies

     * [188]post jobs
     * [189]trainings
     * [190]hiring hackathons
     * [191]advertising
     * [192]reach us

   don't have an account? [193]sign up here.

join our community :

   [194]46336 [195]followers
   [196]20224 [197]followers
   [198]followers
   [199]7513 [200]followers
   ____________________ >

      copyright 2013-2019 analytics vidhya.
     * [201]privacy policy
     * [202]terms of use
     * [203]refund policy

   don't have an account? [204]sign up here

   iframe: [205]likes-master

   %d bloggers like this:

   [loading.gif]
   ____________________

   ____________________

   ____________________
   [button input] (not implemented)_________________

   download resource

join the nextgen data science ecosystem

     * learn: get access to some of the best courses on data science
       created by us
     * engage: interact with thousands of data science professionals
       across the globe!
     * compete: compete in our hackathons and win exciting prizes
     * get hired: get information of jobs in data science community and
       build your profile

   [206](button) join now

   subscribe!

   iframe: [207]likes-master

   %d bloggers like this:

   [loading.gif]
   ____________________

   ____________________

   ____________________
   [button input] (not implemented)_________________

   download resource

join the nextgen data science ecosystem

     * learn: get access to some of the best courses on data science
       created by us
     * engage: interact with thousands of data science professionals
       across the globe!
     * compete: compete in our hackathons and win exciting prizes
     * get hired: get information of jobs in data science community and
       build your profile

   [208](button) join now

   subscribe!

references

   visible links
   1. https://www.analyticsvidhya.com/feed/
   2. https://www.analyticsvidhya.com/comments/feed/
   3. https://www.analyticsvidhya.com/blog/2016/08/tutorial-data-science-command-line-scikit-learn/feed/
   4. https://www.analyticsvidhya.com/wp-json/oembed/1.0/embed?url=https://www.analyticsvidhya.com/blog/2016/08/tutorial-data-science-command-line-scikit-learn/
   5. https://www.analyticsvidhya.com/wp-json/oembed/1.0/embed?url=https://www.analyticsvidhya.com/blog/2016/08/tutorial-data-science-command-line-scikit-learn/&format=xml
   6. https://googletagmanager.com/ns.html?id=gtm-mpsm42v
   7. https://courses.analyticsvidhya.com/bundles/ai-blackbelt-beginner-to-master?utm_source=blog&utm_medium=flashstrip
   8. https://www.analyticsvidhya.com/blog/2016/08/tutorial-data-science-command-line-scikit-learn/
   9. https://www.analyticsvidhya.com/blog-archive/
  10. https://www.analyticsvidhya.com/blog/category/machine-learning/
  11. https://www.analyticsvidhya.com/blog/category/deep-learning/
  12. https://www.analyticsvidhya.com/blog/category/career/
  13. https://www.analyticsvidhya.com/blog/category/stories/
  14. https://www.analyticsvidhya.com/blog/category/podcast/
  15. https://www.analyticsvidhya.com/blog/category/infographics/
  16. https://courses.analyticsvidhya.com/?utm_source=home_blog_navbar
  17. https://www.analyticsvidhya.com/learning-paths-data-science-business-analytics-business-intelligence-big-data/
  18. https://www.analyticsvidhya.com/learning-paths-data-science-business-analytics-business-intelligence-big-data/learning-path-business-analyst-sas/
  19. https://www.analyticsvidhya.com/learning-paths-data-science-business-analytics-business-intelligence-big-data/learning-path-r-data-science/
  20. https://www.analyticsvidhya.com/learning-paths-data-science-business-analytics-business-intelligence-big-data/learning-path-data-science-python/
  21. https://www.analyticsvidhya.com/learning-paths-data-science-business-analytics-business-intelligence-big-data/weka-gui-learn-machine-learning/
  22. https://www.analyticsvidhya.com/learning-paths-data-science-business-analytics-business-intelligence-big-data/tableau-learning-path/
  23. https://www.analyticsvidhya.com/learning-paths-data-science-business-analytics-business-intelligence-big-data/qlikview-learning-path/
  24. https://www.analyticsvidhya.com/learning-paths-data-science-business-analytics-business-intelligence-big-data/newbie-d3-js-expert-complete-path-create-interactive-visualization-d3-js/
  25. https://www.analyticsvidhya.com/glossary-of-common-statistics-and-machine-learning-terms/
  26. https://www.analyticsvidhya.com/blog/2016/08/tutorial-data-science-command-line-scikit-learn/
  27. https://discuss.analyticsvidhya.com/
  28. https://www.analyticsvidhya.com/blog/category/events/
  29. https://www.analyticsvidhya.com/datahack-summit-2018/
  30. https://www.analyticsvidhya.com/datahacksummit/
  31. https://www.analyticsvidhya.com/student-datafest-2018/?utm_source=homepage_menu
  32. http://www.analyticsvidhya.com/about-me/write/
  33. https://www.analyticsvidhya.com/blog/2016/08/tutorial-data-science-command-line-scikit-learn/
  34. https://datahack.analyticsvidhya.com/contest/all
  35. https://www.analyticsvidhya.com/blog/2016/08/tutorial-data-science-command-line-scikit-learn/
  36. https://www.analyticsvidhya.com/jobs/
  37. https://courses.analyticsvidhya.com/
  38. https://courses.analyticsvidhya.com/courses/computer-vision-using-deep-learning/?utm_source=blog-navbar&utm_medium=web
  39. https://courses.analyticsvidhya.com/courses/natural-language-processing-nlp/?utm_source=blog-navbar&utm_medium=web
  40. https://courses.analyticsvidhya.com/courses/introduction-to-data-science-2/?utm_source=blog-navbar&utm_medium=web
  41. https://courses.analyticsvidhya.com/courses/microsoft-excel-beginners-to-advanced/?utm_source=blog-navbar&utm_medium=web
  42. https://courses.analyticsvidhya.com/collections/?utm_source=blog-navbar&utm_medium=web
  43. https://www.analyticsvidhya.com/contact/
  44. https://www.analyticsvidhya.com/
  45. https://www.analyticsvidhya.com/blog-archive/
  46. https://courses.analyticsvidhya.com/?utm_source=home_blog_navbar
  47. https://discuss.analyticsvidhya.com/
  48. https://datahack.analyticsvidhya.com/
  49. https://www.analyticsvidhya.com/jobs/
  50. https://www.analyticsvidhya.com/corporate/
  51. https://www.analyticsvidhya.com/blog/
  52. https://courses.analyticsvidhya.com/bundles/ai-blackbelt-beginner-to-master?utm_source=avtopbanner&utm_medium=display
  53. https://courses.analyticsvidhya.com/bundles/ai-blackbelt-beginner-to-master?utm_source=avtopbanner&utm_medium=display
  54. https://courses.analyticsvidhya.com/bundles/ai-blackbelt-beginner-to-master?utm_source=avtopbanner&utm_medium=display
  55. https://www.analyticsvidhya.com/blog/
  56. https://www.analyticsvidhya.com/blog/2016/08/tutorial-data-science-command-line-scikit-learn/
  57. https://www.analyticsvidhya.com/blog-archive/
  58. https://www.analyticsvidhya.com/blog/category/machine-learning/
  59. https://www.analyticsvidhya.com/blog/category/deep-learning/
  60. https://www.analyticsvidhya.com/blog/category/career/
  61. https://www.analyticsvidhya.com/blog/category/stories/
  62. https://www.analyticsvidhya.com/blog/category/podcast/
  63. https://www.analyticsvidhya.com/blog/category/infographics/
  64. https://courses.analyticsvidhya.com/?utm_source=home_blog_navbar
  65. https://www.analyticsvidhya.com/learning-paths-data-science-business-analytics-business-intelligence-big-data/
  66. https://www.analyticsvidhya.com/learning-paths-data-science-business-analytics-business-intelligence-big-data/learning-path-business-analyst-sas/
  67. https://www.analyticsvidhya.com/learning-paths-data-science-business-analytics-business-intelligence-big-data/learning-path-r-data-science/
  68. https://www.analyticsvidhya.com/learning-paths-data-science-business-analytics-business-intelligence-big-data/learning-path-data-science-python/
  69. https://www.analyticsvidhya.com/learning-paths-data-science-business-analytics-business-intelligence-big-data/weka-gui-learn-machine-learning/
  70. https://www.analyticsvidhya.com/learning-paths-data-science-business-analytics-business-intelligence-big-data/tableau-learning-path/
  71. https://www.analyticsvidhya.com/learning-paths-data-science-business-analytics-business-intelligence-big-data/qlikview-learning-path/
  72. https://www.analyticsvidhya.com/learning-paths-data-science-business-analytics-business-intelligence-big-data/newbie-d3-js-expert-complete-path-create-interactive-visualization-d3-js/
  73. https://www.analyticsvidhya.com/glossary-of-common-statistics-and-machine-learning-terms/
  74. https://www.analyticsvidhya.com/blog/2016/08/tutorial-data-science-command-line-scikit-learn/
  75. https://discuss.analyticsvidhya.com/
  76. https://www.analyticsvidhya.com/blog/category/events/
  77. https://www.analyticsvidhya.com/datahack-summit-2018/
  78. https://www.analyticsvidhya.com/datahacksummit/
  79. https://www.analyticsvidhya.com/student-datafest-2018/?utm_source=homepage_menu
  80. http://www.analyticsvidhya.com/about-me/write/
  81. https://www.analyticsvidhya.com/blog/2016/08/tutorial-data-science-command-line-scikit-learn/
  82. https://datahack.analyticsvidhya.com/contest/all
  83. https://www.analyticsvidhya.com/blog/2016/08/tutorial-data-science-command-line-scikit-learn/
  84. https://www.analyticsvidhya.com/jobs/
  85. https://courses.analyticsvidhya.com/
  86. https://courses.analyticsvidhya.com/courses/computer-vision-using-deep-learning/?utm_source=blog-navbar&utm_medium=web
  87. https://courses.analyticsvidhya.com/courses/natural-language-processing-nlp/?utm_source=blog-navbar&utm_medium=web
  88. https://courses.analyticsvidhya.com/courses/introduction-to-data-science-2/?utm_source=blog-navbar&utm_medium=web
  89. https://courses.analyticsvidhya.com/courses/microsoft-excel-beginners-to-advanced/?utm_source=blog-navbar&utm_medium=web
  90. https://courses.analyticsvidhya.com/collections/?utm_source=blog-navbar&utm_medium=web
  91. https://www.analyticsvidhya.com/contact/
  92. https://www.analyticsvidhya.com/
  93. https://www.analyticsvidhya.com/blog/category/machine-learning/
  94. https://www.analyticsvidhya.com/blog/2016/08/tutorial-data-science-command-line-scikit-learn/
  95. https://www.analyticsvidhya.com/blog/category/machine-learning/
  96. https://www.analyticsvidhya.com/blog/category/python-2/
  97. https://www.analyticsvidhya.com/blog/category/r/
  98. https://www.analyticsvidhya.com/blog/author/guest-blog/
  99. https://www.gnu.org/software/software.html
 100. https://www.analyticsvidhya.com/wp-content/uploads/2016/07/article2.png
 101. http://www.usatoday.com/story/life/entertainthis/2016/06/26/game-of-thrones-recap-season-6-episode-10-the-winds-of-winter-season-finale/86418364/
 102. http://datasciencetoolbox.org/
 103. https://github.com/jeroenjanssens/data-science-at-the-command-line/tree/master/tools
 104. https://www.amazon.com/data-science-command-line-time-tested/dp/1491947853
 105. https://www.gnu.org/software/datamash/
 106. https://csvkit.readthedocs.io/en/0.9.1/tutorial.html
 107. https://github.com/jeroenjanssens/data-science-at-the-command-line/tree/master/tools
 108. https://www.google.co.uk/?client=firefox-b#q=how+to+extend+unix+path&safe=active&gfe_rd=cr
 109. https://blogs.windows.com/buildingapps/2016/03/30/run-bash-on-ubuntu-on-windows/
 110. https://blogs.msdn.microsoft.com/commandline/2016/04/06/bash-on-ubuntu-on-windows-download-now-3/
 111. https://www.cygwin.com/
 112. https://aws.amazon.com/free/
 113. http://datahack.analyticsvidhya.com/contest/black-friday
 114. https://www.gnu.org/software/datamash/manual/datamash.html
 115. https://archive.ics.uci.edu/ml/datasets.html
 116. https://www.analyticsvidhya.com/wp-content/uploads/2016/07/article-3.png
 117. http://skll.readthedocs.io/en/latest/run_experiment.html
 118. https://www.safaribooksonline.com/blog/2014/02/12/using-shell-commands-effectively-ipython/
 119. http://hunch.net/~vw/
 120. https://en.wikipedia.org/wiki/open_source
 121. https://en.wikipedia.org/wiki/out-of-core_algorithm
 122. https://twitter.com/sskarkhanis
 123. https://www.analyticsvidhya.com/cdn-cgi/l/email-protection#7912180b12111817100a260a18171d1c1c093911160d14181015571a1614
 124. http://datahack.analyticsvidhya.com/contest/all
 125. https://play.google.com/store/apps/details?id=com.analyticsvidhya.android&utm_source=blog_article&utm_campaign=blog&pcampaignid=mkt-other-global-all-co-prtnr-py-partbadge-mar2515-1
 126. https://www.analyticsvidhya.com/blog/2016/08/tutorial-data-science-command-line-scikit-learn/?share=linkedin
 127. https://www.analyticsvidhya.com/blog/2016/08/tutorial-data-science-command-line-scikit-learn/?share=facebook
 128. https://www.analyticsvidhya.com/blog/2016/08/tutorial-data-science-command-line-scikit-learn/?share=twitter
 129. https://www.analyticsvidhya.com/blog/2016/08/tutorial-data-science-command-line-scikit-learn/?share=pocket
 130. https://www.analyticsvidhya.com/blog/2016/08/tutorial-data-science-command-line-scikit-learn/?share=reddit
 131. https://www.analyticsvidhya.com/blog/tag/command-line/
 132. https://www.analyticsvidhya.com/blog/tag/command-line-tools/
 133. https://www.analyticsvidhya.com/blog/tag/data-exploration/
 134. https://www.analyticsvidhya.com/blog/tag/data-science-at-command-line/
 135. https://www.analyticsvidhya.com/blog/tag/data-visualization/
 136. https://www.analyticsvidhya.com/blog/tag/feature-engineering/
 137. https://www.analyticsvidhya.com/blog/tag/gradient-boosting/
 138. https://www.analyticsvidhya.com/blog/tag/linear-regressor/
 139. https://www.analyticsvidhya.com/blog/tag/machine-learning/
 140. https://www.analyticsvidhya.com/blog/tag/pip-install/
 141. https://www.analyticsvidhya.com/blog/tag/python/
 142. https://www.analyticsvidhya.com/blog/tag/random-forest/
 143. https://www.analyticsvidhya.com/blog/tag/scikit-learn/
 144. https://www.analyticsvidhya.com/blog/tag/scrub-data/
 145. https://www.analyticsvidhya.com/blog/author/guest-blog/
 146. https://discuss.analyticsvidhya.com/
 147. https://datahack.analyticsvidhya.com/user/profile/srk
 148. https://datahack.analyticsvidhya.com/user/profile/mark12
 149. https://datahack.analyticsvidhya.com/user/profile/nilabha
 150. https://datahack.analyticsvidhya.com/user/profile/nitish007
 151. https://datahack.analyticsvidhya.com/user/profile/tezdhar
 152. https://datahack.analyticsvidhya.com/top-competitor/?utm_source=blog-navbar&utm_medium=web
 153. https://www.analyticsvidhya.com/blog/2018/05/24-ultimate-data-science-projects-to-boost-your-knowledge-and-skills/
 154. https://www.analyticsvidhya.com/blog/2017/09/understaing-support-vector-machine-example-code/
 155. https://www.analyticsvidhya.com/blog/2017/09/common-machine-learning-algorithms/
 156. https://www.analyticsvidhya.com/blog/2016/01/complete-tutorial-learn-data-science-python-scratch-2/
 157. https://www.analyticsvidhya.com/blog/2015/08/comprehensive-guide-regression/
 158. https://www.analyticsvidhya.com/blog/2017/09/naive-bayes-explained/
 159. https://www.analyticsvidhya.com/blog/2018/01/anova-analysis-of-variance/
 160. https://www.analyticsvidhya.com/blog/2018/10/predicting-stock-price-machine-learningnd-deep-learning-techniques-python/
 161. https://www.analyticsvidhya.com/blog/2019/04/top-5-machine-learning-github-reddit/
 162. https://www.analyticsvidhya.com/blog/2019/04/top-5-machine-learning-github-reddit/
 163. https://www.analyticsvidhya.com/blog/2019/04/introduction-image-segmentation-techniques-python/
 164. https://www.analyticsvidhya.com/blog/2019/04/introduction-image-segmentation-techniques-python/
 165. https://www.analyticsvidhya.com/blog/2019/03/reinforcement-learning-temporal-difference-learning/
 166. https://www.analyticsvidhya.com/blog/2019/03/reinforcement-learning-temporal-difference-learning/
 167. https://www.analyticsvidhya.com/blog/2019/03/opencv-functions-computer-vision-python/
 168. https://www.analyticsvidhya.com/blog/2019/03/opencv-functions-computer-vision-python/
 169. https://datahack.analyticsvidhya.com/contest/ltfs-datascience-finhack-an-online-hackathon/?utm_source=sticky_banner1&utm_medium=display
 170. https://datahack.analyticsvidhya.com/contest/hikeathon/?utm_source=sticky_banner2&utm_medium=display
 171. http://www.analyticsvidhya.com/about-me/
 172. https://www.analyticsvidhya.com/about-me/team/
 173. https://www.analyticsvidhya.com/career-analytics-vidhya/
 174. https://www.analyticsvidhya.com/contact/
 175. https://www.analyticsvidhya.com/about-me/write/
 176. http://www.analyticsvidhya.com/about-me/
 177. https://www.analyticsvidhya.com/about-me/team/
 178. https://www.analyticsvidhya.com/about-me/team/
 179. https://www.analyticsvidhya.com/about-me/team/
 180. https://www.analyticsvidhya.com/career-analytics-vidhya/
 181. https://www.analyticsvidhya.com/about-me/team/
 182. https://www.analyticsvidhya.com/contact/
 183. https://www.analyticsvidhya.com/blog
 184. https://datahack.analyticsvidhya.com/
 185. https://discuss.analyticsvidhya.com/
 186. https://www.analyticsvidhya.com/jobs/
 187. https://datahack.analyticsvidhya.com/users/
 188. https://www.analyticsvidhya.com/corporate/
 189. https://trainings.analyticsvidhya.com/
 190. https://datahack.analyticsvidhya.com/
 191. https://www.analyticsvidhya.com/contact/
 192. https://www.analyticsvidhya.com/contact/
 193. https://datahack.analyticsvidhya.com/signup/
 194. https://www.facebook.com/analyticsvidhya/
 195. https://www.facebook.com/analyticsvidhya/
 196. https://twitter.com/analyticsvidhya
 197. https://twitter.com/analyticsvidhya
 198. https://plus.google.com/+analyticsvidhya
 199. https://in.linkedin.com/company/analytics-vidhya
 200. https://in.linkedin.com/company/analytics-vidhya
 201. https://www.analyticsvidhya.com/privacy-policy/
 202. https://www.analyticsvidhya.com/terms/
 203. https://www.analyticsvidhya.com/refund-policy/
 204. https://id.analyticsvidhya.com/accounts/signup/
 205. https://widgets.wp.com/likes/master.html?ver=201914#ver=201914
 206. https://id.analyticsvidhya.com/accounts/login/?next=https://www.analyticsvidhya.com/blog/&utm_source=blog-subscribe&utm_medium=web
 207. https://widgets.wp.com/likes/master.html?ver=201914#ver=201914
 208. https://id.analyticsvidhya.com/accounts/login/?next=https://www.analyticsvidhya.com/blog/&utm_source=blog-subscribe&utm_medium=web

   hidden links:
 210. https://www.facebook.com/analyticsvidhya
 211. https://twitter.com/analyticsvidhya
 212. https://plus.google.com/+analyticsvidhya/posts
 213. https://in.linkedin.com/company/analytics-vidhya
 214. https://www.analyticsvidhya.com/blog/2016/08/evolution-core-concepts-deep-learning-neural-networks/
 215. https://www.analyticsvidhya.com/blog/2016/07/making-predictions-test-data-principal-component-analysis/
 216. https://www.analyticsvidhya.com/blog/author/guest-blog/
 217. http://www.edvancer.in/certified-data-scientist-with-python-course?utm_source=av&utm_medium=avads&utm_campaign=avadsnonfc&utm_content=pythonavad
 218. https://www.facebook.com/analyticsvidhya/
 219. https://twitter.com/analyticsvidhya
 220. https://plus.google.com/+analyticsvidhya
 221. https://plus.google.com/+analyticsvidhya
 222. https://in.linkedin.com/company/analytics-vidhya
 223. https://www.addtoany.com/add_to/facebook?linkurl=https%3a%2f%2fwww.analyticsvidhya.com%2fblog%2f2016%2f08%2ftutorial-data-science-command-line-scikit-learn%2f&linkname=tutorial%20-%20data%20science%20at%20command%20line%20with%20r%20%26amp%3b%20python%20%28scikit%20learn%29
 224. https://www.addtoany.com/add_to/twitter?linkurl=https%3a%2f%2fwww.analyticsvidhya.com%2fblog%2f2016%2f08%2ftutorial-data-science-command-line-scikit-learn%2f&linkname=tutorial%20-%20data%20science%20at%20command%20line%20with%20r%20%26amp%3b%20python%20%28scikit%20learn%29
 225. https://www.addtoany.com/add_to/linkedin?linkurl=https%3a%2f%2fwww.analyticsvidhya.com%2fblog%2f2016%2f08%2ftutorial-data-science-command-line-scikit-learn%2f&linkname=tutorial%20-%20data%20science%20at%20command%20line%20with%20r%20%26amp%3b%20python%20%28scikit%20learn%29
 226. https://www.addtoany.com/add_to/flipboard?linkurl=https%3a%2f%2fwww.analyticsvidhya.com%2fblog%2f2016%2f08%2ftutorial-data-science-command-line-scikit-learn%2f&linkname=tutorial%20-%20data%20science%20at%20command%20line%20with%20r%20%26amp%3b%20python%20%28scikit%20learn%29
 227. https://www.addtoany.com/add_to/whatsapp?linkurl=https%3a%2f%2fwww.analyticsvidhya.com%2fblog%2f2016%2f08%2ftutorial-data-science-command-line-scikit-learn%2f&linkname=tutorial%20-%20data%20science%20at%20command%20line%20with%20r%20%26amp%3b%20python%20%28scikit%20learn%29
 228. https://www.addtoany.com/add_to/facebook?linkurl=https%3a%2f%2fwww.analyticsvidhya.com%2fblog%2f2016%2f08%2ftutorial-data-science-command-line-scikit-learn%2f&linkname=tutorial%20-%20data%20science%20at%20command%20line%20with%20r%20%26amp%3b%20python%20%28scikit%20learn%29
 229. https://www.addtoany.com/add_to/twitter?linkurl=https%3a%2f%2fwww.analyticsvidhya.com%2fblog%2f2016%2f08%2ftutorial-data-science-command-line-scikit-learn%2f&linkname=tutorial%20-%20data%20science%20at%20command%20line%20with%20r%20%26amp%3b%20python%20%28scikit%20learn%29
 230. https://www.addtoany.com/add_to/linkedin?linkurl=https%3a%2f%2fwww.analyticsvidhya.com%2fblog%2f2016%2f08%2ftutorial-data-science-command-line-scikit-learn%2f&linkname=tutorial%20-%20data%20science%20at%20command%20line%20with%20r%20%26amp%3b%20python%20%28scikit%20learn%29
 231. https://www.addtoany.com/add_to/flipboard?linkurl=https%3a%2f%2fwww.analyticsvidhya.com%2fblog%2f2016%2f08%2ftutorial-data-science-command-line-scikit-learn%2f&linkname=tutorial%20-%20data%20science%20at%20command%20line%20with%20r%20%26amp%3b%20python%20%28scikit%20learn%29
 232. https://www.addtoany.com/add_to/whatsapp?linkurl=https%3a%2f%2fwww.analyticsvidhya.com%2fblog%2f2016%2f08%2ftutorial-data-science-command-line-scikit-learn%2f&linkname=tutorial%20-%20data%20science%20at%20command%20line%20with%20r%20%26amp%3b%20python%20%28scikit%20learn%29
 233. javascript:void(0);
 234. javascript:void(0);
 235. https://www.addtoany.com/add_to/facebook?linkurl=https%3a%2f%2fwww.analyticsvidhya.com%2fblog%2f2016%2f08%2ftutorial-data-science-command-line-scikit-learn%2f&linkname=tutorial%20-%20data%20science%20at%20command%20line%20with%20r%20%26amp%3b%20python%20%28scikit%20learn%29
 236. https://www.addtoany.com/add_to/twitter?linkurl=https%3a%2f%2fwww.analyticsvidhya.com%2fblog%2f2016%2f08%2ftutorial-data-science-command-line-scikit-learn%2f&linkname=tutorial%20-%20data%20science%20at%20command%20line%20with%20r%20%26amp%3b%20python%20%28scikit%20learn%29
 237. https://www.addtoany.com/add_to/linkedin?linkurl=https%3a%2f%2fwww.analyticsvidhya.com%2fblog%2f2016%2f08%2ftutorial-data-science-command-line-scikit-learn%2f&linkname=tutorial%20-%20data%20science%20at%20command%20line%20with%20r%20%26amp%3b%20python%20%28scikit%20learn%29
 238. https://www.addtoany.com/add_to/flipboard?linkurl=https%3a%2f%2fwww.analyticsvidhya.com%2fblog%2f2016%2f08%2ftutorial-data-science-command-line-scikit-learn%2f&linkname=tutorial%20-%20data%20science%20at%20command%20line%20with%20r%20%26amp%3b%20python%20%28scikit%20learn%29
 239. https://www.addtoany.com/add_to/whatsapp?linkurl=https%3a%2f%2fwww.analyticsvidhya.com%2fblog%2f2016%2f08%2ftutorial-data-science-command-line-scikit-learn%2f&linkname=tutorial%20-%20data%20science%20at%20command%20line%20with%20r%20%26amp%3b%20python%20%28scikit%20learn%29
 240. https://www.addtoany.com/add_to/facebook?linkurl=https%3a%2f%2fwww.analyticsvidhya.com%2fblog%2f2016%2f08%2ftutorial-data-science-command-line-scikit-learn%2f&linkname=tutorial%20-%20data%20science%20at%20command%20line%20with%20r%20%26amp%3b%20python%20%28scikit%20learn%29
 241. https://www.addtoany.com/add_to/twitter?linkurl=https%3a%2f%2fwww.analyticsvidhya.com%2fblog%2f2016%2f08%2ftutorial-data-science-command-line-scikit-learn%2f&linkname=tutorial%20-%20data%20science%20at%20command%20line%20with%20r%20%26amp%3b%20python%20%28scikit%20learn%29
 242. https://www.addtoany.com/add_to/linkedin?linkurl=https%3a%2f%2fwww.analyticsvidhya.com%2fblog%2f2016%2f08%2ftutorial-data-science-command-line-scikit-learn%2f&linkname=tutorial%20-%20data%20science%20at%20command%20line%20with%20r%20%26amp%3b%20python%20%28scikit%20learn%29
 243. https://www.addtoany.com/add_to/flipboard?linkurl=https%3a%2f%2fwww.analyticsvidhya.com%2fblog%2f2016%2f08%2ftutorial-data-science-command-line-scikit-learn%2f&linkname=tutorial%20-%20data%20science%20at%20command%20line%20with%20r%20%26amp%3b%20python%20%28scikit%20learn%29
 244. https://www.addtoany.com/add_to/whatsapp?linkurl=https%3a%2f%2fwww.analyticsvidhya.com%2fblog%2f2016%2f08%2ftutorial-data-science-command-line-scikit-learn%2f&linkname=tutorial%20-%20data%20science%20at%20command%20line%20with%20r%20%26amp%3b%20python%20%28scikit%20learn%29
 245. javascript:void(0);
 246. javascript:void(0);
