   [1][mainlogowhitethick.jpg]
     * search
     * ____________________
     * [2]home
     * [3]+=1
     * [4]support the content
     * [5]community
     * [6]log in
     * [7]sign up

     * ____________________
     * [8]home
     * [9]+=1
     * [10]support the content
     * [11]community
     * [12]log in
     * [13]sign up

   [mainid166image.png]

intro to machine learning with scikit learn and python

   while a lot of people like to make it sound really complex, machine
   learning is quite simple at its core and can be best envisioned as
   machine classification. machine learning shines when the number of
   dimensions exceeds what we can graphically represent, but here's a nice
   2d representation of machine learning with two features:
   [machine-learning-support-vector-machine-linear-svc-example-with-python
   -and-sklearn.png] the above image is taken from part 11 of this series,
   where we show an extremely basic example of how a support vector
   machine (id166) works. this particular example and the specific estimator
   that we will be using is linear svc. if that means nothing to you now,
   that is perfectly okay. the above image is taken by feeding through
   data sets of x,y coordinates like:

     [1,2],
     [5,8],
     [1.5,1.8],
     [8,8],
     [1,0.6],
     [9,11]

   as you can see, this data set has some larger pairs, and some smaller
   pairs. what an id166 is going to do is help you find the perfect dividing
   line between the data. we can then take it a step further, and ask the
   id166 to predict which "group" a coordinate like [0.8,0.92] would belong
   to.

   with features (think of these as dimensions) as 2d or 3d, it is really
   quite simple to visualize and for us humans to just look at the graph
   and do some basic id91. machine learning, however, can be used to
   analyze, say, 100 features (100 dimensions). try that yourself with 5
   billion samples.

   iframe:
   [14]https://www.youtube.com/embed/urtz2jkcgbc?list=plqvvvaa0qudd0flggph
   kcej-9jp-qdzz3

   this series is concerned with machine learning in a hands-on and
   practical manner, using the python programming language and the
   scikit-learn module (sklearn).

   our example used here is to analyze fundamental characteristics of
   publicly-traded companies (stocks), comparing these fundamentals to the
   stock's market value performance over time. our goal is to see if we
   can use machine learning to identify good stocks with solid
   fundamentals that matter so we can invest in them.

   i will try to cover more machine learning examples in the future, as
   each machine learning algorithm is fairly specific to the "type" of
   problem you might have. a support vector machine (id166) is great for
   some tasks, but very poor for others. there are many other machine
   learning algorithms to learn about, and there is a lot more to learn
   about machine learning in general. we're going to be taken only a small
   slice of the pie per machine learning algorithm that we use.

   machine learning, for the most part, is not actual learning at all,
   though a lot of people in the media generally fear-monger with that as
   the premise.

   with machine learning, we can perform a lot of amazing tasks and give
   the appearance, or probably better put: "the illusion" of intelligence,
   but it's not really intelligence as we know it. the real question,
   however, is if that matters in the end? if the end-result is the same,
   and achieved in a far more efficient manner, then what does it matter
   how the conclusion was reached?

   there are many applications where this form of computing is superior to
   human intelligence. properly weighing and analyzing all aspects is
   simply done better with less bias, and far quicker, by computers.

   there are two main categories of machine learning:

     supervised learning
     unsupervised learning.

   within supervised learning, we have classification and regression.
   remember earlier when i said machine learning is really just machine
   classification? it still is, but there's also a specific form of
   machine learning called classification.

   so, supervised learning is where we, the scientist, supervise and
   sometimes sort of guide the learning process. we might say what some of
   the data is, and leave some to question.

   within supervised learning, we have classification, which is where we
   already have the classifications done. an example here would be the
   image recognition tutorial we did, where you have a set of numbers, and
   you have an unknown that you want to fit into one of your pre-defined
   categories.

   then we have regression, still under supervised learning, which is
   maybe better called induction or something like that, where we have
   certain known variables of the data in question, and then, using past
   sample or historical data, we can make predictions on the unknown.

   an example here would be what facebook does to you when it guesses
   where you live. given your network and the people you have the closest
   ties to and communicate with, and where they are from, facebook can
   then guess that you too are from that location.

   another example would be if we sample a million people, then find an
   unknown person who has blonde hair and pale skin. we're curious what
   color eyes that they have. our regression algorithm will probably
   suggest our new person has blue or grey eyes, based on the previous
   samples.

   now, immediately red flags should probably go off here. for you
   philosophy majors out there, you knew there was a problem immediately
   when we used inductive reasoning. for the rest of you, the problem is
   we're making predictions here, using the weaker form of reasoning.

   all that said, humans have owed quite a bit of their evolution to their
   ability to do inductive reasoning. it is not all bad, but people do
   like to use inductive reasoning and regression analysis for things like
   trading stocks. the problem is this reasoning follows history and makes
   predictions to the future. as we know and hear many times over and
   over, history is not a representation of future.

   i do not want to spend too much time here, but i would like to lastly
   point out, with induction, computers are better at it than humans. when
   it comes to inductive reasoning, humans have the tendency to miss-judge
   and incorrectly weigh various attributes. they generally have a lot
   more bias, and other statistical flaws that particularly plague
   inductive reasoning. computers do not have these issues, and they can
   perform this reasoning on a far larger data set at an astronomically
   faster pace than us.

   unsupervised learning is where we create the learning algorithm, then
   we just throw a ton of data at the computer and we let the computer
   make sense of it.

   the basics of unsupervised learning is to just throw a massive data set
   at the machine, and the machine, you guessed it, classifies, or groups,
   the data. this is why the terms can be confusing. just remember that
   all machine learning is machine classification, and the specific
   version of machine learning called classification is where we're just
   pre-defining categories, forcing the machine to choose one.

   the last major terms i would like to have us cover here before we get
   our feet wet are testing and training

   when we "train" the machine, this is where we give data which is
   pre-classified. so again, with the image recognition series, we trained
   our machine by giving it examples of 0s through 9s.

   when we test this algo, we use new, unclassified data to the machine,
   but we know the proper classification. generally, you feed the data
   through to test it, then you run the correct answers through the
   machine and see how many the machine got right and wrong.

   as you may soon find, actually acquiring the data necessary for
   training and testing is the most challenging part. for me and
   sentdex.com, which does id31 of text, i was able to use
   movie and product reviews scraped offline as my training and testing
   sets. the reviews come with rankings, so i could train and test the
   machine on massive data-sets that were personally ranked by the
   reviewer themselves.

   i made this picture long ago, but i find it still applies to machine
   learning:
   [machinelearning.png]

   while i think machine learning is actually more complicated than that,
   most people are likely to read about machine learning and think it is
   incredibly complicated both in programming and mathematically, thus
   being scared off.

   while machine learning algorithms are actually incredibly long and
   complex, you will almost never need to write your own, except just for
   fun or just to see if you can.

   in almost all production cases, you wouldn't want to write your own,
   nor should you. you will want to use a peer-reviewed, highly efficient,
   and highly tested algorithm. for most major cases, there will be a very
   effective algorithm available for you. because of this, it's actually
   not necessary for you to learn about all of the inner workings of
   machine learning to be successful with it.

   you can think of this much like how you probably treat your car, your
   computer, or your cell phone. you can get a lot of utility out of these
   things, yet you probably actually know very little about all of the
   intricacies of them.

   machine learning is the same way. it's best to understand some of the
   major parameters, like "learning rate," as well as what machine
   learning is actually doing for you, that way you can figure how how
   best to apply machine learning to a problem. this is why i find
   visualizing some examples before moving into impossible dimensions is a
   great idea.

   of course, you may find that you're curious about the inner-workings,
   and i would encourage you to feed your curiosity. the algorithms are
   truly fascinating, and it will certainly improve your efficacy the more
   you understand the algorithms that you intend to employ.

   the focus of this course is to actually apply a machine learning
   algorithm to a problem. if that sounds like something you'd like to do,
   head to the next tutorial.

   [15]there exists 2 quiz/question(s) for this tutorial. (button) sign up
   to +=1 for access to these, video downloads, and no ads.

   the next tutorial: [16](button) simple support vector machine (id166)
   example with character recognition
   [paperspace-1.png]
     * intro to machine learning with scikit learn and python
     * simple support vector machine (id166) example with character
       recognition
       [17](button) go
     * our method and where we will be getting our data
       [18](button) go
     * parsing data
       [19](button) go
     * more parsing
       [20](button) go
     * structuring data with pandas
       [21](button) go
     * getting more data and meshing data sets
       [22](button) go
     * labeling of data part 1
       [23](button) go
     * labeling data part 2
       [24](button) go
     * finally finishing up the labeling
       [25](button) go
     * linear svc machine learning id166 example with python
       [26](button) go
     * getting more features from our data
       [27](button) go
     * linear svc machine learning and testing our data
       [28](button) go
     * scaling, normalizing, and machine learning with many features
       [29](button) go
     * shuffling our data to solve a learning issue
       [30](button) go
     * using quandl for more data
       [31](button) go
     * improving our analysis with a more accurate measure of performance
       in relation to fundamentals
       [32](button) go
     * learning and testing our machine learning algorithm
       [33](button) go
     * more testing, this time including n/a data
       [34](button) go
     * back-testing the strategy
       [35](button) go
     * pulling current data from yahoo
       [36](button) go
     * building our new data-set
       [37](button) go
     * searching for investment suggestions
       [38](button) go
     * raising investment requirement standards
       [39](button) go
     * testing raised standards
       [40](button) go
     * streamlining the changing of standards
       [41](button) go

you've reached the end!

   contact: harrison@pythonprogramming.net.
     * [42]support this website!
     * [43]hire me
     * [44]facebook
     * [45]twitter
     * [46]google+

legal stuff:

     * [47]terms and conditions
     * [48]privacy policy

   [49]

   programming is a superpower.

      over 9000! pythonprogramming.net

references

   visible links
   1. https://pythonprogramming.net/
   2. https://pythonprogramming.net/
   3. https://pythonprogramming.net/+=1/
   4. https://pythonprogramming.net/support/
   5. https://goo.gl/7zgavq
   6. https://pythonprogramming.net/login/
   7. https://pythonprogramming.net/register/
   8. https://pythonprogramming.net/
   9. https://pythonprogramming.net/+=1/
  10. https://pythonprogramming.net/support/
  11. https://goo.gl/7zgavq
  12. https://pythonprogramming.net/login/
  13. https://pythonprogramming.net/register/
  14. https://www.youtube.com/embed/urtz2jkcgbc?list=plqvvvaa0qudd0flggphkcej-9jp-qdzz3
  15. https://pythonprogramming.net/+=1/
  16. https://pythonprogramming.net/support-vector-machine-id166-example-tutorial-scikit-learn-python/?completed=/machine-learning-python-sklearn-intro/
  17. https://pythonprogramming.net/support-vector-machine-id166-example-tutorial-scikit-learn-python/
  18. https://pythonprogramming.net/data-acquisition-machine-learning/
  19. https://pythonprogramming.net/getting-data-machine-learning/
  20. https://pythonprogramming.net/parsing-data-website-machine-learning/
  21. https://pythonprogramming.net/using-pandas-structure-process-data/
  22. https://pythonprogramming.net/getting-data-sp-500-index-value-comparison/
  23. https://pythonprogramming.net/labeling-data-machine-learning/
  24. https://pythonprogramming.net/labeling-data-machine-learning-part-2/
  25. https://pythonprogramming.net/label-data-machine-learning/
  26. https://pythonprogramming.net/linear-svc-example-scikit-learn-id166-python/
  27. https://pythonprogramming.net/collecting-features-machine-learning/
  28. https://pythonprogramming.net/linear-svc-machine-learning-testing-data/
  29. https://pythonprogramming.net/preprocessing-machine-learning/
  30. https://pythonprogramming.net/shuffling-data-learning/
  31. https://pythonprogramming.net/using-quandl-data/
  32. https://pythonprogramming.net/improving-analysis-machine-learning/
  33. https://pythonprogramming.net/learning-and-testing-id166/
  34. https://pythonprogramming.net/machine-learning-testing-with-na/
  35. https://pythonprogramming.net/back-testing-machine-learning-investing-strategy/
  36. https://pythonprogramming.net/current-yahoo-data-for-machine-learning/
  37. https://pythonprogramming.net/building-yahoo-data-machine-learning/
  38. https://pythonprogramming.net/investment-suggestions-machine-learning/
  39. https://pythonprogramming.net/raising-investment-suggestion-requirements/
  40. https://pythonprogramming.net/machine-learning-testing-new-algo/
  41. https://pythonprogramming.net/streamlining-changing-machine-learning/
  42. https://pythonprogramming.net/support-donate/
  43. https://pythonprogramming.net/consulting/
  44. https://www.facebook.com/pythonprogramming.net/
  45. https://twitter.com/sentdex
  46. https://plus.google.com/+sentdex
  47. https://pythonprogramming.net/about/tos/
  48. https://pythonprogramming.net/about/privacy-policy/
  49. https://xkcd.com/353/

   hidden links:
  51. https://pythonprogramming.net/machine-learning-python-sklearn-intro/
  52. https://bit.ly/2frosrq?a=15&t=/machine-learning-python-sklearn-intro/
  53. https://bit.ly/2frosrq?a=15&t=/machine-learning-python-sklearn-intro/
