   #[1]facebook research    feed [2]facebook research    comments feed
   [3]facebook research    fasttext comments feed [4]alternate [5]alternate

   [6]skip to content

   iframe: [7]https://www.googletagmanager.com/ns.html?id=gtm-wspss3d

   [8]facebook research
   search ____________________ (button) submit
   [9]toggle search (button)

     * [10]research areas (button) show dropdown menu
          + [11]ar/vr
          + [12]connectivity
          + [13]computational photography & intelligent cameras
          + [14]id161
          + [15]data science
          + [16]economics & computation
          + [17]facebook ai research
          + [18]human computer interaction & ux
          + [19]machine learning
          + [20]natural language processing & speech
          + [21]security & privacy
          + [22]systems & networking
     * [23]publications
     * [24]people
     * [25]academic programs (button) show dropdown menu
          + [26]facebook fellowship program
          + [27]research awards
          + [28]research collaborations
          + [29]research award recipients
          + [30]visiting researchers and postdocs
     * [31]downloads & projects
     * [32]careers
     * [33]blog

   search ____________________ (button) submit
   [34]close search

   august 18, 2016

fasttext

   by: [35]piotr bojanowski, [36]edouard grave, [37]armand joulin,
   [38]tomas mikolov

faster, better text classification!

   understanding the meaning of words that roll off your tongue as you
   talk, or your fingertips as you tap out posts is one of the biggest
   technical challenges facing artificial intelligence researchers. but it
   is an essential need. automatic text processing forms a key part of the
   day-to-day interaction with your computer; it   s a critical component of
   everything from web search and content ranking to spam filtering, and
   when it works well, it   s completely invisible to you. with the growing
   amount of online data, there is a need for more flexible tools to
   better understand the content of very large datasets, in order to
   provide more accurate classification results.

   to address this need, the [39]facebook ai research (fair) lab is
   open-sourcing [40]fasttext, a library designed to help build scalable
   solutions for text representation and classification. our ongoing
   commitment to collaboration and sharing with the community extends
   beyond just delivering code. we know it   s important to share our
   learnings to advance the field, so have also [41]published[42] our
   research relating to fasttext.

   fasttext combines some of the most successful concepts introduced by
   the natural language processing and machine learning communities in the
   last few decades. these include representing sentences with bag of
   words and bag of id165s, as well as using subword information, and
   sharing information across classes through a hidden representation. we
   also employ a hierachical softmax that takes advantage of the
   unbalanced distribution of the classes to speed up computation. these
   different concepts are being used for two different tasks: efficient
   text classification and learning word vector representations.

efficient learning for text classification

   deep neural networks have recently become very popular for text
   processing. while these models achieve very good performance in limited
   laboratory practice, they can be slow to train and test, which limits
   their use on very large datasets.

   fasttext helps solve this problem. to be efficient on datasets with
   very large number of categories, it uses a hierarchical classifier
   instead of a flat structure, in which the different categories are
   organized in a tree (think binary tree instead of list). this reduces
   the time complexities of training and testing text classifiers from
   linear to logarithmic with respect to the number of classes. fasttext
   also exploits the fact that classes are imbalanced (some classes
   appearing more often than other) by using the huffman algorithm to
   build the tree used to represent categories. the depth in the tree of
   very frequent categories is therefore smaller than for infrequent ones,
   leading to further computational efficiency.

   fasttext also represents a text by a low dimensional vector, which is
   obtained by summing vectors corresponding to the words appearing in the
   text. in fasttext, a low dimensional vector is associated to each word
   of the vocabulary. this hidden representation is shared across all
   classifiers for different categories, allowing information about words
   learned for one category to be used by other categories. these kind of
   representations, called bag of words, ignore word order. in fasttext we
   also use vectors to represent word ngrams to take into account local
   word order, which is important for many text classification problems.

   our experiments show that fasttext is often on par with deep learning
   classifiers in terms of accuracy, and many orders of magnitude faster
   for training and evaluation. with fasttext, we were often able to cut
   training times from several days to just a few seconds, and achieve
   state-of-the-art performance on many standard problems, such as
   id31 or tag prediction.

   post00048_image0002
   comparison between fasttext and deep learning-based methods.

a dedicated tool

   text classification is very important in the commercial world; spam or
   clickbait filtering being perhaps the most ubiquitous example. there
   are tools that design models for general classification problems (such
   as vowpal wabbit or libid166), but fasttext is exclusively dedicated to
   text classification. this allows it to be quickly trained on extremely
   large datasets. we have seen results of models trained on more than 1
   billion words in less than 10 minutes using a standard multicore cpu.
   fasttext can also classify a half-million sentences among more than
   300,000 categories in less than five minutes.

works on many languages

   besides text classification, fasttext can also be used to learn vector
   representations of words. it has been designed to work on a variety of
   languages, including english, german, spanish, french, and czech, by
   taking advantage of the languages morphological structure. it uses a
   simple yet effective way of incorporating subword information that
   turns out to work very well for morphologically rich languages like
   czech, demonstrating that carefully designed character ngram features
   are strong source of information to enrich the word representations.
   fasttext can achieve significantly better performance than the popular
   [43]id97 tool, or other state-of-the-art morphological word
   representations.

   post00048_image0003
   comparison between fasttext and state-of-the-art word representations
   for different languages.

   we hope the introduction of fasttext helps the community build better,
   more scalable solutions for text representation and classification.
   delivered as an open-source library, we believe fasttext is a valuable
   addition to the research and engineering communities, which will
   ultimately help us all design better applications and further advances
   in language understanding.
   areas: [44]facebook ai research facebook ai research

related content

   [45]

   blog

open-sourcing pytorch-biggraph for faster embeddings of extremely large
graphs

   april 2, 2019
   [46]

   blog

turing award presented to yann lecun, geoffrey hinton and yoshua bengio

   march 27, 2019
   [47]

   blog

q&a with facebook ai residents tatiana likhomanenko and siddharth karamcheti

   march 15, 2019
   [48]

   blog

facebook ai researchers share perspectives on diversity on international
women   s day

   march 8, 2019

   iframe:
   [49]https://www.facebook.com/plugins/page.php?href=https%3a%2f%2fwww.fa
   cebook.com%2facademics&tabs&width=340&height=70&small_header=true&adapt
   _container_width=true&hide_cover=true&show_facepile=false&appid

     * [50]rss feed
     * [51]about
     * [52]careers
     * [53]privacy
     * [54]cookies
     * [55]terms
     * [56]help

   facebook    2019

   to help personalize content, tailor and measure ads, and provide a
   safer experience, we use cookies. by clicking or navigating the site,
   you agree to allow our collection of information on and off facebook
   through cookies. learn more, including about available controls:
   [57]cookies policy

references

   1. https://research.fb.com/feed/
   2. https://research.fb.com/comments/feed/
   3. https://research.fb.com/fasttext/feed/
   4. https://research.fb.com/wp-json/oembed/1.0/embed?url=https://research.fb.com/fasttext/
   5. https://research.fb.com/wp-json/oembed/1.0/embed?url=https://research.fb.com/fasttext/&format=xml
   6. https://research.fb.com/fasttext/#content
   7. https://www.googletagmanager.com/ns.html?id=gtm-wspss3d
   8. https://research.fb.com/
   9. javascript:void(0)
  10. https://research.fb.com/research-areas/
  11. https://research.fb.com/category/augmented-reality-virtual-reality/
  12. https://research.fb.com/category/connectivity/
  13. https://research.fb.com/category/computational-photography-and-intelligent-cameras/
  14. https://research.fb.com/category/computer-vision/
  15. https://research.fb.com/category/data-science/
  16. https://research.fb.com/category/economics-and-computation/
  17. https://research.fb.com/category/facebook-ai-research
  18. https://research.fb.com/category/human-computer-interaction-and-ux/
  19. https://research.fb.com/category/machine-learning/
  20. https://research.fb.com/category/natural-language-processing-and-speech/
  21. https://research.fb.com/category/security-and-privacy/
  22. https://research.fb.com/category/systems-and-networking/
  23. https://research.fb.com/publications/
  24. https://research.fb.com/people/
  25. https://research.fb.com/programs/
  26. https://research.fb.com/programs/fellowship/
  27. https://research.fb.com/programs/research-awards/
  28. https://research.fb.com/programs/research-collaborations/
  29. https://research.fb.com/programs/faculty-awards
  30. https://research.fb.com/programs/post-docs-and-sabbaticals/
  31. https://research.fb.com/downloads/
  32. https://research.fb.com/careers/
  33. https://research.fb.com/blog/
  34. javascript:void(0)
  35. https://research.fb.com/people/bojanowski-piotr/
  36. https://research.fb.com/people/grave-edouard/
  37. https://research.fb.com/people/joulin-armand/
  38. https://research.fb.com/people/mikolov-tomas/
  39. https://research.fb.com/category/facebook-ai-research-fair/
  40. https://github.com/facebookresearch/fasttext
  41. http://arxiv.org/abs/1607.04606
  42. http://arxiv.org/abs/1607.01759
  43. https://code.google.com/archive/p/id97/
  44. https://research.fb.com/category/facebook-ai-research/
  45. https://ai.facebook.com/blog/open-sourcing-pytorch-biggraph-for-faster-embeddings-of-extremely-large-graphs/
  46. https://research.fb.com/turing-award-presented-to-yann-lecun-geoffrey-hinton-and-yoshua-bengio/
  47. https://research.fb.com/qa-with-facebook-ai-residents-tatiana-likhomanenko-and-siddharth-karamcheti/
  48. https://research.fb.com/facebook-ai-researchers-share-perspectives-on-diversity-on-international-womens-day/
  49. https://www.facebook.com/plugins/page.php?href=https://www.facebook.com/academics&tabs&width=340&height=70&small_header=true&adapt_container_width=true&hide_cover=true&show_facepile=false&appid
  50. https://research.fb.com/feed/
  51. https://www.facebook.com/facebook
  52. https://www.facebook.com/careers/university/
  53. https://www.facebook.com/about/privacy
  54. https://www.facebook.com/help/cookies
  55. https://www.facebook.com/policies
  56. https://www.facebook.com/help
  57. https://www.facebook.com/policies/cookies/
