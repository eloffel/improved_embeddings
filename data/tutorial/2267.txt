    #[1]nvidia developer blog    feed [2]nvidia developer blog    comments
   feed [3]nvidia developer blog    introduction to neural machine
   translation with gpus (part 3) comments feed [4]alternate [5]alternate

   [6]nvidia accelerated computing [7]developer
     * ____________________
       [ ] search nvidia developer
     * [8]join
     * [9]login

   ____________________
   [ ] search nvidia developer

[10]nvidia developer blog

main menu

   [11]skip to primary content
   [12]skip to secondary content
   [13]developer news
   [14]subscribe
   [15]follow us
   [16]nvidiaaidev
   [17]nvidiahpcdev
   [18]nvidiagamedev
   [19]nvidiaembedded
   [20]nvidiadrive
   [21]nvidiadesign

   (button) toggle navigation

   topics
     * [22]accelerated computing
     * [23]artificial intelligence
     * [24]autonomous vehicles
     * [25]design & visualization
     * [26]features
     * [27]game development
     * [28]robotics
     * [29]smart cities
     * [30]virtual reality

   [31]accelerated computing
   [32]artificial intelligence
   [33]autonomous vehicles
   [34]design & visualization
   [35]features
   [36]game development
   [37]robotics
   [38]smart cities
   [39]virtual reality

   [40]artificial intelligence


introduction to id4 with gpus (part 3)

   by [41]kyunghyun cho | [42]july 26, 2015
   tags: [43]deep learning, [44]machine learning, [45]machine translation,
   [46]natural language processing, [47]natural language understanding,
   [48]neural networks, [49]theano

     note: this is the final part of a detailed three-part series on
     machine translation with neural networks by kyunghyun cho. you may
     enjoy [50]part 1 and [51]part 2.

   in the [52]previous post in this series, i introduced a simple
   encoder-decoder model for machine translation. this simple
   encoder-decoder model is excellent at english-french translation.
   however, in this post i will briefly discuss the weakness of this
   simple approach, and describe a recently proposed way of incorporating
   a soft attention mechanism to overcome the weakness and significantly
   improve the translation quality.

   furthermore, i will present some more recent works that utilize this
   id4 approach to go beyond machine translation of
   text, such as image id134 and video description
   generation. i   ll finish the blog series with a brief discussion of
   future research directions and a pointer to the open source code
   implementing these id4 models.

the trouble with simple encoder-decoder architectures

   in the encoder-decoder architecture, the encoder compresses the input
   sequence as a fixed-size vector from which the decoder needs to
   generate a full translation. in other words, the fixed-size vector,
   which i   ll call a context vector, must contain every single detail of
   the source sentence. intuitively, this means that the true function
   approximated by the encoder has to be extremely nonlinear and
   complicated. furthermore, the dimensionality of the context vector must
   be large enough that a sentence of any length can be compressed.

   in my paper    [53]on the properties of id4:
   encoder-decoder approaches    presented at [54]ssst-8, my coauthors and i
   empirically confirmed that translation quality dramatically degrades as
   the length of the source sentence increases when the encoder-decoder
   model size is small. together with a much better result from
   [55]sutskever et al. (2014), using the same type of encoder-decoder
   architecture, this suggests that the representational power of the
   encoder needed to be large, which often means that the model must be
   large, in order to cope with long sentences (see figure 1).
   figure 1: dramatic drop of performance w.r.t. the length of sentence
   with a small encoder-decoder model. figure 1: dramatic drop of
   performance w.r.t. the length of sentence with a small encoder-decoder
   model.

   of course, a larger model implies higher computation and memory
   requirements. the use of advanced gpus, such as nvidia titan x, indeed
   helps with computation, but not with memory (at least not yet). the
   size of onboard memory is often limited to several gigabytes, and this
   imposes a serious limitation on the size of the model. (note: it   s
   possible to overcome this issue by using multiple gpus while
   distributing a single model across those gpus, as shown by
   [56]sutskever et al. (2014). however, let   s assume for now that we have
   access to a single machine with a single gpu due to space, power and
   other physical constraints.)

   then, the question is    can we do better than the simple encoder-decoder
   based model?   

soft attention mechanism for id4

   the biggest issue with the simple encoder-decoder architecture is that
   a sentence of any length needs to be compressed into a fixed-size
   vector. this is a rather peculiar approach when you consider how
   computers typically handle compression tasks. when you zip a file, the
   length of the resulting compressed file is roughly proportional to the
   length of the original file. (this is not quite true: the compressed
   size is proportional to the amount of information in the original file,
   not its length. however, for the sake of argument, let us assume that
   the length of the original file closely reflects the amount of
   information in the file.)

   continuing with an analogy to digital computers, let   s store the whole
   sentence not as a fixed-size vector, but as a memory that contains as
   many banks as there are source words. this is done by using a so-called
   bidirectional recurrent neural network (biid56) which consists of a
   forward [57]recurrent neural network (id56) and a separate backward id56.
   as the names suggest, the forward and backward id56   s read the source
   sentence in forward and backward directions, respectively.

   now, let   s call the hidden states from the forward id56
   \overrightarrow{h}_j    s and those from the backward id56
   \overleftarrow{h}_j    s. as we discussed [58]in the first post of this
   series, an id56 summarizes a sequence by reading one symbol at a time.
   this means that \overrightarrow{h}_j of the forward id56 summarizes the
   source sentence up to the j -th word beginning from the first word, and
   \overleftarrow{h}_j of the backward id56 up to the j -th word beginning
   from the last word. in other words, \overrightarrow{h}_j and
   \overleftarrow{h}_j together summarize the whole input sentence. see
   figure 2 for an illustration.
   figure 2. id182 for encoding a source
   sentence. figure 2. id182 for
   encoding a source sentence.

   this summary at the position of each word, however, is not the perfect
   summary of the whole input sentence. due to its sequential nature, a
   recurrent neural network tends to remember recent symbols better. in
   other words, the further away an input symbol is from j , the less
   likely the id56   s hidden state, either \overleftarrow{h}_j or
   \overleftarrow{h}_j , remembers it perfectly. the annotation vector,
   which we use to refer to the concatenation of \overleftarrow{h}_j or
   \overleftarrow{h}_j , represents the current word w_j best.

   this is definitely not an agreed convention, but personally, because of
   this reason, i understand the annotation vector as a context-dependent
   word representation. furthermore, we can consider this set of
   context-dependent word representations as a mechanism by which we store
   the source sentence as a variable-length representation, as opposed to
   the fixed-length, fixed-dimensional summary from the simple
   encoder-decoder model.

   with this variable-length representation of a source sentence, the
   decoder now needs to be able to selectively focus on one or more of the
   context-dependent word representations, or the annotation vectors, for
   each target word. so, which annotation vector should the decoder focus
   on each time?

   let   s imagine you   re translating the given source sentence, and you
   have written the first i-1 target words ( y_1, y_2, \ldots, y_{i-1} )
   and are about to decide which target word you want to write as the i
   -th target word. in this case, how do you decide which source word(s)
   you will translate this time?

   a typical translator looks at each source word x_j (or its
   context-dependent representation h_j ), considers it together with the
   already translated words ( y_1, y_2, \ldots, y_{t-1} ) and decides
   whether the source word x_j has been translated (equivalently, how
   (ir)relevant the source word x_j is for the next target word). it
   repeats this process for every word in the source sentence.
   figure 3. attention mechanism takes into consideration what has been
   translated and one of the source words. figure 3. attention mechanism
   takes into consideration what has been translated and one of the source
   words.

   dzmitry bahdanau and i together with yoshua bengio last summer (2014)
   proposed to include a small [59]neural network in a decoder to do
   almost exactly this. the small neural network, which we call the
   attention mechanism (purple-colored part in figure 3), takes as input
   the previous decoder   s hidden state z_i (what has been translated) and
   one of the source context-dependent word representations h_j . the
   attention mechanism is implemented as a neural network with a single
   hidden layer and a single scalar output e_{j} \in \mathbb{r} , as in
   figure 4. this is applied to every source word.
   figure 4. attention mechanism returns a single scalar corresponding to
   a relevance score e_j of the j-th source word. figure 4. attention
   mechanism returns a single scalar corresponding to a relevance score of
   the j-th source word.

   once we   ve computed the relevance score of every source word, we want
   to make sure that they sum to one. this can be done easily
   using softmax id172 such that

   \alpha_j = \frac{\exp(e_j)}{\sum_{j'} \exp(e_{j'})}.

   see figure 5 for the graphical illustration.

   why do we want this kind of id172? there can be many reasons,
   but my favourite reason is that this helps us interpret the scores
   assigned by the attention mechanism in a probabilistic framework. from
   this probabilistic perspective, one can think of the attention weight
   \alpha_j as the id203 of the decoder selecting the j -th
   context-dependent source word representation out of all t source words.
   then, we can compute the expected context-dependent word representation
   under this distribution (defined by the attention weights \alpha_j )
   using

   c_i = \sum_{j=1}^t \alpha_j h_j = \mathbb{e}_{\alpha_j'} \left[ h_j
   \right].

   this expected vector c_i summarizes the information about the whole
   source sentence, however, with different emphasis on different
   locations/words of the source sentence. any annotation vector
   (context-dependent vector) deemed relevant (in other words, with high
   attention weight) by the attention mechanism will be better represented
   than those with low attention weights.
   figure 5. the relevance scores returned by the attention mechanism are
   normalized to sum to 1, which helps us interpret them as probabilities.
   from this probabilistic perspective, we compute the expectation of the
   annotation vectors under this distribution. figure 5. the relevance
   scores returned by the attention mechanism are normalized to sum to 1,
   which helps us interpret them as probabilities. from this probabilistic
   perspective, we compute the expectation of the annotation vectors under
   this distribution.

   once this vector c_i is computed, everything happens as we discussed in
   the [60]decoder section of the previous post, except that instead of
   h_t we use c_i at each time step i .

what does soft attention mechanism bring to the table?

   this approach of incorporating attention mechanism has become one of
   the hottest topics in [61]deep learning recently (see [62]cho et al.,
   2015 and references therein.) it would be super interesting to talk
   about the consequences of having attention mechanism in a neural
   network and how it can lead us to yet another level of success in deep
   learning, but that would take much more than a blog post. instead,
   figure 6 shows an example of the kind of attention (or alignment) that
   the model learns without any supervision on the alignment. (note:
   although the term weakly supervised is often used to denote
   id23, i find this type of model equally weakly
   supervised. except for the final target translation, there was
   absolutely no supervision on the internal
   correspondence/attention/alignment.)
   figure 6. sample translations made by the id4
   model with the soft-attention mechanism. edge thicknesses represent the
   attention weights found by the attention model. figure 6. sample
   translations made by the id4 model with the
   soft-attention mechanism. edge thicknesses represent the attention
   weights found by the attention model.

   it   s pretty awesome that the model automatically found the
   correspondence structure between two languages. i   m sure you   ll
   appreciate it better if you speak either french or german (both of
   which i don   t)! but, the bigger question is, does the introduction of
   the attention mechanism improve translation performance?

   yes, it does, and quite tremendously! especially, in [63][bahdandau et
   al., 2015], we observed that with the addition of the attention
   mechanism, the quality of the translation does not drop as sentence
   length increases, even when the size of the model stays roughly the
   same, as figure 7 shows.
   figure 7. id56search-50 is a id4 model with the
   attention mechanism trained on all the sentence pairs of length at most
   50. figure 7. id56search-50 is a id4 model with
   the attention mechanism trained on all the sentence pairs of length at
   most 50.

   the last issue is that this looks way too complicated to implement.
   again, theano to the rescue! just write a forward computation pass (see
   [64]here for an example) and use theano.tensor.grad, and you   re ready
   to go.

id63s and memory networks

   reader zzzz [65]commented on my previous post in this series:

     have you guys tried to use id63 or memory networks
     for this purpose? or those models require much bigger training sets
     to produce better results?

   i meant to write a response sooner, but decided to wait until this
   post. why? because, both the id63 (ntm) by [66]graves
   et al. (2014) as well as the memory networks by [67]weston et al.
   (2014) can be thought of as variants/extensions of the described neural
   machine translation with soft attention mechanism. think of the set of
   context-dependent word representations h_j as the contents in the
   memory, the attention mechanism as the read head of ntm and the decoder
   as the controller of ntm. these are very similar!

   in fact, if you read the latest paper on memory networks by
   [68]sukhbaatar et al. (2015), it becomes very clear that the
   attention-based id4, the ntm and the memory
   networks are more or less equivalent except for some details and for
   which applications they were designed. i, and probably you as well,
   have to wonder what will be the ultimate generalization of all these
   approaches and what kind of consequences this ultimate model will bring
   in the future.

beyond translation: image/video id134

   the most surprising and important point of this whole neural machine
   translation business is that there   s nothing specific to languages. in
   particular, this approach can handle any type of input data as long as
   there   s a suitable neural architecture that returns either a fixed-size
   vector representation of the input or a set of annotation vectors of
   it.

   a recently published work from the university of montreal and the
   university of toronto showed that it is possible to design an
   attention-based encoder-decoder model which describes an image by
   replacing the encoder with a [69]convolutional neural network, as
   figure 8 shows. similar approaches were proposed also in [donahue et
   al., 2014; fang et al., 2014; karpathy and li, 2014; kiros et al.,
   2014; mao et al., 2014].
   figure 8. image id134 with attention mechanism. figure 8.
   image id134 with attention mechanism.

   pushing the boundary further, [70]li et al. (2015) applied a similar
   attention-based approach to video description generation by letting the
   decoder utilize temporal structures of the video. similarly, video
   description generation with the simple encoder-decoder architecture was
   proposed recently by [li et al., 2015; venugopalan et al., 2015] (see
   figure 9).

   figure 9. temporal attention for video description generation. from [li
   et al., 2015]. figure 9. temporal attention for video description
   generation. from [li et al., 2015].furthermore, this same strategy of
   incorporating attention mechanism into learning to map from structured
   input to structured output has recently been applied to unimaginably
   many applications. one of my favorite is [71]vinyals et al. (2015)   s
   application to discrete optimization, where they use this
   attention-based neural network to (approximately) solve the travelling
   salesperson problem! for the up-to-date extensive list of these
   applications, please refer to my recent overview [72]paper.

   looking at all these recent works makes me wonder what will come next.
   what do you think? let me know in the comments to this post.

what   s next?

   in this post, i introduced recent advances in deep learning, centered
   around id4. however, there are many challenges
   related to id4 remaining to be solved in the
   future. let me list a few of them here.
     * beyond modeling sentences: sentences, when represented as a
       sequence of words, are very short. the id26 algorithm
       for recurrent neural networks requires time proportional to the
       length of a sequence. can there be another algorithm more suitable
       for dealing with much longer sequences, such as paragraphs and
       documents? learning should probably be local, and weights should be
       updated online while processing a sequence.
     * beyond natural languages: id4 works for
       languages, but what else can it work for? perhaps gene expression
       sequences, protein structure prediction, [73]graphs and social
       networks, or weather data?
     * multimodal learning: can we leverage other sources of information
       for translation? what is the natural way to incorporate multiple
       sources of information?

where   s the code?

   in this series so far i have avoided the discussion on the practical
   implementation. however, we at the university of montreal have been
   actively making our code publicly available, because we believe
   open-source code helps speed up research progress by letting everyone
   try the code and easily customize or build upon it.

   one of the most important contributions we have made in recent years
   has been [74]theano. theano is a tool specialized in symbolically
   building an arbitrary neural network using python. it abstracts the
   underlying compute architecture such that the same code can be run
   either on a more traditional cpu-based backend or on a more specialized
   hardware architecture such as gpus. furthermore, theano implements
   symbolic differentiation which is crucial in training a neural network,
   making it extremely simple to quickly prototype complicated neural
   networks (such as the attention-based id4 model
   described in this post). however, theano only provides basic
   primitives, and one needs to sew those primitives into a [75]neural
   network, which is not at all a trivial task even with theano.

   we (razvan pascanu, caglar gulcehre, myself, dzmitry bahdanau and bart
   van merrienboer) earlier released [76]groundhog which implements all
   the necessary components to build a id4 model.
   unfortunately, this code was rather hastily developed, and the
   readability is extremely low. since then, orhan firat, dzmitry bahadanu
   and bart van merrienboer prepared an example script to build, train and
   use id4 models based on the newly introduced
   framework called [77]blocks. however, this should also be treated only
   as an example for now.

   in october this year (2015) at dublin city university i will give a
   lecture on id4 as part of the [78]dl4mt winter
   school. to make the winter school more useful and practical for the
   audience, i am now preparing a stripped-down version of neural machine
   translation based on theano. the code, which is called dl4mt-material
   and still in heavy preparation, can be found [79]here.

   currently, this code includes three subdirectories; session0, session1
   and session2. session0 contains the implementation of the [80]recurrent
   neural network language model using id149, and session1
   the implementation of the simple id4 model. in
   session2, you can find the implementation of the attention-based neural
   machine translation model we discussed today. i am planning to make a
   couple more sessions, so stay tuned!

   oh, one more thing before i finish this section, and the whole series.
   let me make it clear again: always train this type of model with gpus!
   to get a well-trained model, it takes about three to twelve days using
   a geforce gtx titan x, and with cpus, i cannot even give any reasonable
   estimate on how long it will take to train a model. of course, you can
   probably build a google-sized cluster and use a distributed
   optimization algorithm, but i believe this is probably not the most
   cost-efficient way to go (unless you   re microsoft, facebook or ibm).

acknowledgements

   i   ve covered a lot of recent research in this series of parallel forall
   posts on id4. hopefully i didn   t make it sound
   like i did all this work on my own. any work introduced here has been
   done by all the authors in the cited papers including those at the
   university of montreal as well as other institutes. furthermore, most
   of my work in the past few years wouldn   t have been possible without
   the availability of theano, and i   d like to thank all the contributors
   to theano, and especially, fred bastien, pascal lamblin and arnaud
   bergeron.

   note that any error in the text is my own, and feel free to contact me
   if you found anything suspicious here.

references

     * bahdanau, dzmitry, kyunghyun cho, and yoshua bengio.    neural
       machine translation by jointly learning to align and translate.   
       arxiv preprint arxiv:1409.0473 (2014).
     * bastien, fr  d  ric et al.    theano: new features and speed
       improvements.    arxiv preprint arxiv:1211.5590 (2012).
     * bergstra, james et al.    theano: a cpu and gpu math expression
       compiler.    proceedings of the python for scientific computing
       conference (scipy) 30 jun. 2010: 3.
     * bridle, j. s. (1990). training stochastic model recognition
       algorithms as networks can lead to maximum mutual information
       estimation of parameters. in touretzky, d., editor, advances in
       neural information processing systems, volume 2, (denver, 1989).
     * brown, peter f et al.    the mathematics of statistical machine
       translation: parameter estimation.    computational linguistics 19.2
       (1993): 263-311.
     * cho, kyunghyun et al.    learning phrase representations using id56
       encoder-decoder for id151.    arxiv
       preprint arxiv:1406.1078 (2014).
     * cho, kyunghyun, aaron courville, and yoshua bengio.    describing
       multimedia content using attention-based encoder   decoder networks.   
       arxiv preprint arxiv:1507.01053 (2015).
     * denil, misha et al.    learning where to attend with deep
       architectures for image tracking.    neural computation 24.8 (2012):
       2151-2184.
     * donahue, jeff et al.    long-term recurrent convolutional networks
       for visual recognition and description.    arxiv preprint
       arxiv:1411.4389 (2014).
     * fang, hao et al.    from captions to visual concepts and back.    arxiv
       preprint arxiv:1411.4952 (2014).
     * forcada, mikel l, and    eco, ram  n p.    recursive hetero-associative
       memories for translation.    biological and artificial computation:
       from neuroscience to technology (1997): 453-462.
     * graves, alex, greg wayne, and ivo danihelka.    neural turing
       machines.    arxiv preprint arxiv:1410.5401 (2014).
     * graves, alex, greg wayne, and ivo danihelka.    neural turing
       machines.    arxiv preprint arxiv:1410.5401 (2014).
     * gregor, karol et al.    draw: a recurrent neural network for image
       generation.    arxiv preprint arxiv:1502.04623 (2015).
     * gulcehre, caglar et al.    on using monolingual corpora in neural
       machine translation.    arxiv preprint arxiv:1503.03535 (2015).
     * kalchbrenner, nal, and phil blunsom.    recurrent continuous
       translation models.    emnlp 2013: 1700-1709.
     * karpathy, andrej, and li, fei-fei.    deep visual-semantic alignments
       for generating image descriptions.    arxiv preprint arxiv:1412.2306
       (2014).
     * kingma, d. p., and ba, j.    a method for stochastic optimization.   
       arxiv preprint arxiv:1412.6980 (2014).
     * kiros, ryan, ruslan salakhutdinov, and richard s zemel.    unifying
       visual-semantic embeddings with multimodal neural language models.   
       arxiv preprint arxiv:1411.2539 (2014).
     * koehn, philipp. id151. cambridge
       university press, 2009.
     * mao, junhua et al.    deep captioning with multimodal recurrent
       neural networks (m-id56).    arxiv preprint arxiv:1412.6632 (2014).
     * mnih, volodymyr, nicolas heess, and alex graves.    recurrent models
       of visual attention.    advances in neural information processing
       systems 2014: 2204-2212.
     * pascanu, razvan et al.    how to construct deep recurrent neural
       networks.    arxiv preprint arxiv:1312.6026 (2013).
     * schwenk, holger.    continuous space language models.    computer
       speech & language 21.3 (2007): 492-518.
     * sukhbaatar, sainbayar et al.    end-to-end memory networks.   
     * sutskever, ilya, oriol vinyals, and quoc v. le.    sequence to
       sequence learning with neural networks.    advances in neural
       information processing systems 2014: 3104-3112.
     * venugopalan, subhashini et al.    sequence to sequence   video to
       text.    arxiv preprint arxiv:1505.00487 (2015).
     * weston, jason, sumit chopra, and antoine bordes.    memory networks.   
       arxiv preprint arxiv:1410.3916 (2014).
     * xu, kelvin et al.    show, attend and tell: neural image caption
       generation with visual attention.    arxiv preprint arxiv:1502.03044
       (2015).
     * yao, li et al.    video description generation incorporating
       spatio-temporal features and a soft-attention mechanism.    arxiv
       preprint arxiv:1502.08029 (2015).
     * zeiler, matthew d.    adadelta: an adaptive learning rate method.   
       arxiv preprint arxiv:1212.5701 (2012).

   [81]35 comments
   about the authors
   kyunghyun cho
   about kyunghyun cho
   kyunghyun cho is an assistant professor in the department of computer
   science, courant institute of mathematical sciences and the center for
   data science at new york university (nyu) (starting september, 2015).
   previously, he was a postdoctoral researcher at the university of
   montreal under the supervision of prof. yoshua bengio after obtaining a
   doctorate degree at aalto university (finland) in early 2014.
   kyunghyun's main research interests include neural networks, generative
   models and their applications, especially, to language understanding.
   [82]view all posts by kyunghyun cho
   related posts
   [83]introduction to id4 with gpus (part 1)
   by [84]kyunghyun cho | [85]may 27, 2015
   [86]figure 3. graphical illustration of different types of recurrent
   neural networks. from [pascanu et al., 2014]
   [87]introduction to id4 with gpus (part 2)
   by [88]kyunghyun cho | [89]june 14, 2015
   [90]figure 3. step 1: a word to a one-hot vector.
   [91]deep learning in a nutshell: core concepts
   by [92]tim dettmers | [93]november 3, 2015
   [94]dl_dog_340x340
   [95]understanding natural language with deep neural networks using
   torch
   by [96]soumith chintala | [97]march 3, 2015
   [98]torch_lstm_thumb
   comments

   copyright    2019 nvidia corporation
   [99]legal information [100]privacy policy

   [101]close

parallel forall

     * [102]features

   search for: ____________________ search

accelerated computing

     * [103]accelerated computing
     * [104]downloads
     * [105]training
     * [106]ecosystem
     * [107]forums
     * [108]register now
     * [109]login

references

   visible links
   1. https://devblogs.nvidia.com/feed/
   2. https://devblogs.nvidia.com/comments/feed/
   3. https://devblogs.nvidia.com/introduction-neural-machine-translation-gpus-part-3/feed/
   4. https://devblogs.nvidia.com/wp-json/oembed/1.0/embed?url=https://devblogs.nvidia.com/introduction-neural-machine-translation-gpus-part-3/
   5. https://devblogs.nvidia.com/wp-json/oembed/1.0/embed?url=https://devblogs.nvidia.com/introduction-neural-machine-translation-gpus-part-3/&format=xml
   6. https://developer.nvidia.com/
   7. https://developer.nvidia.com/
   8. https://developer.nvidia.com/accelerated-computing-developer
   9. https://developer.nvidia.com/user
  10. https://devblogs.nvidia.com/
  11. https://devblogs.nvidia.com/introduction-neural-machine-translation-gpus-part-3/#content
  12. https://devblogs.nvidia.com/introduction-neural-machine-translation-gpus-part-3/#secondary
  13. https://news.developer.nvidia.com/
  14. https://devblogs.nvidia.com/introduction-neural-machine-translation-gpus-part-3/
  15. https://devblogs.nvidia.com/introduction-neural-machine-translation-gpus-part-3/
  16. https://devblogs.nvidia.com/introduction-neural-machine-translation-gpus-part-3/
  17. https://devblogs.nvidia.com/introduction-neural-machine-translation-gpus-part-3/
  18. https://devblogs.nvidia.com/introduction-neural-machine-translation-gpus-part-3/
  19. https://devblogs.nvidia.com/introduction-neural-machine-translation-gpus-part-3/
  20. https://devblogs.nvidia.com/introduction-neural-machine-translation-gpus-part-3/
  21. https://devblogs.nvidia.com/introduction-neural-machine-translation-gpus-part-3/
  22. https://devblogs.nvidia.com/category/accelerated-computing/
  23. https://devblogs.nvidia.com/category/artificial-intelligence/
  24. https://devblogs.nvidia.com/category/autonomous-vehicles/
  25. https://devblogs.nvidia.com/category/design-visualization/
  26. https://devblogs.nvidia.com/category/features/
  27. https://devblogs.nvidia.com/category/game-development/
  28. https://devblogs.nvidia.com/category/robotics/
  29. https://devblogs.nvidia.com/category/smart-cities/
  30. https://devblogs.nvidia.com/category/virtual-reality/
  31. https://devblogs.nvidia.com/category/accelerated-computing/
  32. https://devblogs.nvidia.com/category/artificial-intelligence/
  33. https://devblogs.nvidia.com/category/autonomous-vehicles/
  34. https://devblogs.nvidia.com/category/design-visualization/
  35. https://devblogs.nvidia.com/category/features/
  36. https://devblogs.nvidia.com/category/game-development/
  37. https://devblogs.nvidia.com/category/robotics/
  38. https://devblogs.nvidia.com/category/smart-cities/
  39. https://devblogs.nvidia.com/category/virtual-reality/
  40. https://devblogs.nvidia.com/category/artificial-intelligence/
  41. https://devblogs.nvidia.com/author/kcho/
  42. https://devblogs.nvidia.com/introduction-neural-machine-translation-gpus-part-3/
  43. https://devblogs.nvidia.com/tag/deep-learning/
  44. https://devblogs.nvidia.com/tag/machine-learning/
  45. https://devblogs.nvidia.com/tag/machine-translation/
  46. https://devblogs.nvidia.com/tag/natural-language-processing/
  47. https://devblogs.nvidia.com/tag/natural-language-understanding/
  48. https://devblogs.nvidia.com/tag/neural-networks/
  49. https://devblogs.nvidia.com/tag/theano/
  50. https://devblogs.nvidia.com/parallelforall/introduction-neural-machine-translation-with-gpus/
  51. https://devblogs.nvidia.com/parallelforall/introduction-neural-machine-translation-gpus-part-2/
  52. https://devblogs.nvidia.com/parallelforall/introduction-neural-machine-translation-gpus-part-2/
  53. http://arxiv.org/abs/1409.1259
  54. http://www.aclweb.org/anthology/w14-4000
  55. http://arxiv.org/abs/1409.3215
  56. http://arxiv.org/abs/1409.3215
  57. https://developer.nvidia.com/discover/recurrentneuralnetwork
  58. https://devblogs.nvidia.com/parallelforall/introduction-neural-machine-translation-with-gpus/
  59. https://developer.nvidia.com/discover/artificial-neural-network
  60. https://devblogs.nvidia.com/parallelforall/introduction-neural-machine-translation-gpus-part-2/
  61. https://developer.nvidia.com/deep-learning
  62. http://arxiv.org/abs/1507.01053
  63. http://arxiv.org/abs/1409.0473
  64. https://github.com/kyunghyuncho/dl4mt-material/blob/master/session2/id4.py#l464-l539
  65. https://devblogs.nvidia.com/parallelforall/introduction-neural-machine-translation-gpus-part-2/#comment-2083041588
  66. http://arxiv.org/abs/1410.5401
  67. http://arxiv.org/abs/1410.3916
  68. http://arxiv.org/abs/1503.08895
  69. https://developer.nvidia.com/discover/convolutionalneuralnetwork
  70. http://arxiv.org/abs/1502.08029
  71. http://arxiv.org/abs/1506.03134
  72. http://arxiv.org/abs/1507.01053
  73. https://developer.nvidia.com/discover/graphanalytics
  74. http://deeplearning.net/software/theano/
  75. https://developer.nvidia.com/discover/artificialneuralnetwork
  76. https://github.com/lisa-groundhog/groundhog
  77. https://github.com/mila-udem/blocks
  78. http://dl4mt.computing.dcu.ie/#/
  79. https://github.com/kyunghyuncho/dl4mt-material
  80. https://devblogs.nvidia.com/parallelforall/introduction-neural-machine-translation-with-gpus/
  81. https://devblogs.nvidia.com/introduction-neural-machine-translation-gpus-part-3/#comments
  82. https://devblogs.nvidia.com/author/kcho/
  83. https://devblogs.nvidia.com/introduction-neural-machine-translation-with-gpus/
  84. https://devblogs.nvidia.com/author/kcho/
  85. https://devblogs.nvidia.com/introduction-neural-machine-translation-with-gpus/
  86. https://devblogs.nvidia.com/introduction-neural-machine-translation-with-gpus/
  87. https://devblogs.nvidia.com/introduction-neural-machine-translation-gpus-part-2/
  88. https://devblogs.nvidia.com/author/kcho/
  89. https://devblogs.nvidia.com/introduction-neural-machine-translation-gpus-part-2/
  90. https://devblogs.nvidia.com/introduction-neural-machine-translation-gpus-part-2/
  91. https://devblogs.nvidia.com/deep-learning-nutshell-core-concepts/
  92. https://devblogs.nvidia.com/author/tdettmers/
  93. https://devblogs.nvidia.com/deep-learning-nutshell-core-concepts/
  94. https://devblogs.nvidia.com/deep-learning-nutshell-core-concepts/
  95. https://devblogs.nvidia.com/understanding-natural-language-deep-neural-networks-using-torch/
  96. https://devblogs.nvidia.com/author/schintala/
  97. https://devblogs.nvidia.com/understanding-natural-language-deep-neural-networks-using-torch/
  98. https://devblogs.nvidia.com/understanding-natural-language-deep-neural-networks-using-torch/
  99. http://www.nvidia.com/object/legal_info.html
 100. http://www.nvidia.com/object/privacy_policy.html
 101. https://devblogs.nvidia.com/introduction-neural-machine-translation-gpus-part-3/#sidr-left
 102. https://devblogs.nvidia.com/category/features/
 103. https://developer.nvidia.com/accelerated-computing
 104. https://developer.nvidia.com/accelerated-computing-toolkit
 105. https://developer.nvidia.com/accelerated-computing-training
 106. https://developer.nvidia.com/tools-ecosystem
 107. https://devtalk.nvidia.com/
 108. https://developer.nvidia.com/accelerated-computing-developer
 109. https://developer.nvidia.com/user

   hidden links:
 111. https://devblogs.nvidia.com/introduction-neural-machine-translation-gpus-part-3/
 112. https://devblogs.nvidia.com/introduction-neural-machine-translation-gpus-part-3/
 113. https://devblogs.nvidia.com/introduction-neural-machine-translation-gpus-part-3/
