[1]id4 - tutorial acl 2016

   ____________________
   search this site

navigation

     * tutorial
          + [2]prerequisites
          + [3]references
          + [4]resources
     * [5]speakers

tutorial

   welcome to the homepage for our acl 2016 tutorial, with more
   information and updated material to supplement the [6]official acl
   page! the presenters were thang luong [7]@lmthang, kyunghyun
   cho [8]@kchonyc, and christopher manning [9]@chrmanning.

   [10][id4.png?height=225&amp;width=400]

   id4 (id4) is a simple new architecture for
   getting machines to learn to translate. despite being relatively new
   (kalchbrenner and blunsom, 2013; cho et al., 2014; sutskever et al.,
   2014), id4 has already shown promising results, achieving
   state-of-the-art performance for various language pairs (luong et al,
   2015a; jean et al, 2015; luong et al, 2015b; sennrich et al., 2016;
   luong and manning, 2016). while many of these id4 papers were presented
   to the acl community, research and practice of id4 are only at their
   beginning stage. this tutorial would be a great opportunity for the
   whole community of machine translation and natural language processing
   to learn more about a very promising new approach to mt. this tutorial
   has four parts.

   in the first part, we start with an introduction to (neural) machine
   translation before discussing phrase-based statistical machine
   translation which has been a dominant approach over the past twenty
   years. we then go through background of neural language models,
   including recurrent neural language models, which is the basis for id4.

   the second part describes basics of id4. we go into details how to
   train id4 with the id113 approach and the
   back-propagation-through-time algorithm. we explain why the vanishing
   gradient problem happens to motivate usages of gated recurrent and long
   short-term memory units. after that, various decoding strategies are
   highlighted.

   the third part of our tutorial describes techniques to build
   state-of-the-art id4. we start with approaches to extend the vocabulary
   coverage of id4 (luong et al., 2015a; jean et al., 2015; chitnis and
   denero, 2015). we then introduce the idea of jointly learning both
   translations and alignments through an attention mechanism (bahdanau et
   al., 2015); other variants of attention (luong et al., 2015b; tu et
   al., 2016) are discussed too. we describe a recent trend in id4, that
   is to translate at the sub-word level (chung et al., 2016; luong and
   manning, 2016; sennrich et al., 2016), so that language variations can
   be effectively handled.

   lastly, we conclude by describing promising approaches and areas for
   the future or id4. topics include (a) combining multiple tasks to help
   translation (dong et al., 2015; luong et al., 2016; firat et al.,
   2016; zoph and knight, 2016), (b) building larger-context id4, (c)
   running id4 on mobile devices (see et al., 2016; kim and rush, 2016),
   (d) making unsupervised learning work, (and) approaches beyond maximum
   likelihood estimation.
   slides
   you can download: [11]slides (version 4). this was the version used at
   the acl 2016 tutorial.

   tutorial content
    1. introduction - 40mins (chris manning)

    1. intro to (neural) machine translation
    2. phrase-based id151
    3. neural language models



   basic id4 - 50mins (kyunghyun cho)
    1. training: id113 with id26
       through time
    2. vanishing gradient and id149/long short-term memory
       units
    3. conditional recurrent id38: encoder-decoder
    4. decoding strategies



   advanced id4 - 60mins (thang luong)
    1. extending the vocabulary coverage
    2. learning alignment: attention mechanism
    3. handling language variations: subword-level translation
    4. utilizing monolingual data



   future of id4 - 30mins (kyunghyun cho and thang luong)
    1. multilingual/id72
    2. larger context
    3. mobile devices
    4. beyond id113

   selected references (see the sidebar for a link to all references for
   the tutorial)

   dzmitry bahdanau, kyunghyun cho, and yoshua bengio. 2015. [12]neural
   machine translation by jointly learning to align and translate. iclr.

   rohan chitnis and john denero. 2015. [13]variable-length word encodings
   for neural translation models. emnlp.

   kyunghyun cho, bart van merrienboer, caglar gulcehre, dzmitry bahdanau,
   fethi bougares, holger schwenk, and yoshua bengio. 2014. [14]learning
   phrase representations using id56 encoder-decoder for statistical
   machine translation. emnlp.

   junyoung chung, kyunghyun cho, and yoshua bengio. 2016. [15]a
   character-level decoder without explicit segmentation for neural
   machine translation. acl.

   daxiang dong, hua wu, wei he, dianhai yu, and haifeng wang. 2015.
   [16]id72 for multiple language translation. acl.

   orhan firat, kyunghyun cho, yoshua bengio. 2016. [17]multi-way,
   multilingual id4 with a shared attention
   mechanism. naacl.

   mikel l. forcada and ram  n   eco. 1997. [18]recursive hetero-associative
   memories for translation. in biological and artificial computation:
   from neuroscience to technology, pages 453   462. springer.

   sebastien jean, kyunghyun cho, roland memisevic, and yoshua bengio.
   2015. [19]on using very large target vocabulary for neural machine
   translation. acl.

   nal kalchbrenner and phil blunsom. 2013. [20]recurrent continuous
   translation models. emnlp.

   yoon kim and alexander m. rush. 2016. [21]sequence-level knowledge
   distillation. emnlp

   minh-thang luong, ilya sutskever, quoc v. le, oriol vinyals, and
   wojciech zaremba, 2015a. [22]addressing the rare word problem in neural
   machine translation. acl.

   minh-thang luong, hieu pham, and christopher d manning. 2015b.
   [23]effective approaches to attention-based id4.
   emnlp.

   minh-thang luong, quoc v. le, ilya sutskever, oriol vinyals, and lukasz
   kaiser, 2016. [24]multi-task sequence to sequence learning. iclr.

   minh-thang luong and christopher d manning. 2016. [25]achieving open
   vocabulary id4 with hybrid word-character
   models. acl.

   abigail see, minh-thang luong, and christopher d manning. 2016.
   [26]compression of id4 models via pruning.
   conll.

   rico sennrich, barry haddow, and alexandra birch. 2016. [27]improving
   id4 models with monolingual data. acl.

   rico sennrich, barry haddow, and alexandra birch. 2016. [28]neural
   machine translation of rare words with subword units. acl.

   ilya sutskever, oriol vinyals, and quoc v. le. 2014. [29]sequence to
   sequence learning with neural networks. nips.

   zhaopeng tu, zhengdong lu, yang liu, xiaohua liu, and hang li. 2016.
   [30]modeling coverage for id4. acl.

   barret zoph and kevin knight. 2016. [31]multi-source neural
   translation. in naacl.
   subpages (3): [32]prerequisites [33]references [34]resources

   [35]sign in|[36]recent site activity|[37]report abuse|[38]print
   page|powered by [39]google sites

references

   1. https://sites.google.com/site/acl16id4/
   2. https://sites.google.com/site/acl16id4/home/prerequisites
   3. https://sites.google.com/site/acl16id4/home/references
   4. https://sites.google.com/site/acl16id4/home/resources
   5. https://sites.google.com/site/acl16id4/speakers
   6. http://acl2016.org/index.php?article_id=55
   7. https://twitter.com/lmthang
   8. https://twitter.com/kchonyc
   9. https://twitter.com/chrmanning
  10. https://sites.google.com/site/acl16id4/home/id4.png?attredirects=0
  11. http://nlp.stanford.edu/projects/id4/luong-cho-manning-id4-acl2016-v4.pdf
  12. https://arxiv.org/pdf/1409.0473.pdf
  13. http://www.denero.org/content/pubs/emnlp15_chitnis_encoding.pdf
  14. http://aclweb.org/anthology/d/d14/d14-1179.pdf
  15. http://arxiv.org/abs/1603.06147
  16. http://www.aclweb.org/anthology/p15-1166
  17. https://arxiv.org/pdf/1601.01073.pdf
  18. http://www.dlsi.ua.es/~mlf/docum/forcada97p.pdf
  19. http://www.aclweb.org/anthology/p15-1001
  20. http://www.aclweb.org/anthology/d13-1176
  21. https://arxiv.org/pdf/1606.07947.pdf
  22. http://aclweb.org/anthology/p/p15/p15-1002.pdf
  23. https://arxiv.org/pdf/1508.04025.pdf
  24. http://arxiv.org/pdf/1511.06114v4.pdf
  25. http://arxiv.org/abs/1604.00788
  26. http://nlp.stanford.edu/pubs/see2016compression.pdf
  27. http://arxiv.org/pdf/1511.06709.pdf
  28. http://arxiv.org/pdf/1508.07909.pdf
  29. https://papers.nips.cc/paper/5346-sequence-to-sequence-learning-with-neural-networks.pdf
  30. http://arxiv.org/pdf/1601.04811.pdf
  31. http://www.isi.edu/natural-language/mt/multi-source-neural.pdf
  32. https://sites.google.com/site/acl16id4/home/prerequisites
  33. https://sites.google.com/site/acl16id4/home/references
  34. https://sites.google.com/site/acl16id4/home/resources
  35. https://accounts.google.com/servicelogin?continue=https://sites.google.com/site/acl16id4/home&service=jotspot
  36. https://sites.google.com/site/acl16id4/system/app/pages/recentchanges
  37. https://sites.google.com/site/acl16id4/system/app/pages/reportabuse
  38. javascript:;
  39. http://sites.google.com/site
