   #[1]publisher [2]medium [3]alternate

   [4]homepage
   [5]homepage
   [6]sign in[7]get started

   [8]becoming human: artificial intelligence magazine
     * [9]     consulting
     * [10]     tutorials
     * [11]       submit an article
     * [12]     communities
     * [13]     our bot
     __________________________________________________________________

a noob   s guide to implementing id56-lstm using tensorflow

   [14]go to the profile of monik pamecha
   [15]monik pamecha (button) blockedunblock (button) followfollowing
   jun 19, 2016
   [1*bf5ibhobq2uziy11uxjzeg.png]

   the purpose of this tutorial is to help anybody write their first
   [16]id56 [17]lstm model without much background in artificial neural
   networks or machine learning. the discussion is not centered on the
   theory or working of such networks but on writing code for solving a
   particular problem. we will understand how neural networks let us solve
   some problems effortlessly, and how they can be applied to a multitude
   of other problems.

what are id56s?

   simple multi-layered neural networks are classifiers which when given a
   certain input, tag the input as belonging to one of the many classes.
   they are trained using the existing id26 algorithms. these
   networks are great at what they do but they are not capable of handling
   inputs which come in a sequence. for example, for a neural net to
   identify the nouns in a sentence, having just the word as input is not
   helpful at all. a lot of information is present in the context of the
   word which can only be determined by looking at the words near the
   given word. the entire sequence is to be studied to determine the
   output. this is where recurrent neural networks (id56s) find their use.
   as the id56 traverses the input sequence, output for every input also
   becomes a part of the input for the next item of the sequence. you can
   read more about the utility of id56s in[18] andrej karpathy   s brilliant
   blog post. it is helpful to note the    recurrent    property of the
   network, where the previous output for an input item becomes a part of
   the current input which comprises the current item in the sequence and
   the last output. when done over and over, the last output would be the
   result of all the previous inputs and the last input.

what is lstm?

   id56s are very apt for sequence classification problems and the reason
   they   re so good at this is that they   re able to retain important data
   from the previous inputs and use that information to modify the current
   output. if the sequences are quite long, the gradients (values
   calculated to tune the network) computed during their training
   (id26) either vanish (multiplication of many 0< values < 1)
   or explode (multiplication of many large values) causing it to train
   very slowly.

   long short term memory is a id56 architecture which addresses the
   problem of training over long sequences and retaining memory. lstms
   solve the gradient problem by introducing a few more gates that control
   access to the cell state. you could refer to [19]colah   s blog post
   which is a great place to understand the working of lstms. if you
   didn   t get what is being discussed, that   s fine and you can safely move
   to the next part.

the task

   given a binary string (a string with just 0s and 1s) of length 20, we
   need to determine the count of 1s in a binary string. for example,
      01010010011011100110    has 11 ones. so the input for our program will
   be a string of length twenty that contains 0s and 1s and the output
   must be a single number between 0 and 20 which represents the number of
   ones in the string. here is a link to the [20]complete gist, in case
   you just want to jump at the code.

   even an amateur programmer can   t help but giggle at the task
   definition. it won   t take anybody more than a minute to execute this
   program and get the correct output on every input (0% error).
count = 0
for i in input_string:
    if i == '1':
        count+=1

   anybody in their right mind would wonder, if it is so easy, why the
   hell can   t a computer figure it out by itself? computers aren   t that
   smart without a human instructor. computers need to be given precise
   instructions and the    thinking    has to be done by the human issuing the
   commands. machines can repeat the most complicated calculations a
   gazillion times over but they still fail miserably at things humans do
   painlessly, like recognizing cats in a picture.

   what we plan to do is to feed neural network enough input data and tell
   it the correct output values for those inputs. post that, we will give
   it input that it has not seen before and we will see how many of those
   does the program get right.

generating the training input data

   each input is a binary string of length twenty. the way we will
   represent it will be as a python list of 0s and 1s. the test input to
   be used for training will contain many such lists.
import numpy as np
from random import shuffle
train_input = ['{0:020b}'.format(i) for i in range(2**20)]
shuffle(train_input)
train_input = [map(int,i) for i in train_input]
ti  = []
for i in train_input:
    temp_list = []
    for j in i:
            temp_list.append([j])
    ti.append(np.array(temp_list))
train_input = ti

   there can be a total of 220 ~ 106 combinations of 1s and 0s in a string
   of length 20. we generate a list of all the 220 numbers, convert it to
   their binary string and shuffle the entire list. each binary string is
   then converted to a list of 0s and 1s. tensorflow requires input as a
   tensor (a tensorflow variable) of the dimensions [batch_size,
   sequence_length, input_dimension] (a 3d variable). in our case,
   batch_size is something we   ll determine later but sequence_length is
   fixed at 20 and input_dimension is 1 (i.e each individual bit of the
   string). each bit will actually be represented as a list containing
   just that bit. a list of 20 such lists will form a sequence which we
   convert to a numpy array. a list of all such sequences is the value of
   train_input that we   re trying to compute. if you print the first few
   values of train_input, it would look like
[
 array([[0],[0],[1],[0],[0],[1],[0],[1],[1],[0],[0],[0],[1],[1],[1],[1],[1],[1],
[0],[0]]),
 array([[1],[1],[0],[0],[0],[0],[1],[1],[1],[1],[1],[0],[0],[1],[0],[0],[0],[1],
[0],[1]]),
 .....
]

   don   t worry about the values if they don   t match yours because they
   will be different as they are in random order.

generating the training output data

   for every sequence, the result can be anything between 0 and 20. so we
   have 21 choices per sequence. very clearly, our task is a sequence
   classification problem. each sequence belongs to the class number which
   is the same as the count of ones in the sequence. the representation of
   the output would be a list of the length of 21 with zeros at all
   positions except a one at the index of the class to which the sequence
   belongs.
[0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]
 0  1  2  3  4  5  6  7  8  9  10 11 12 13 14 15 16 17 18 19 20
this is a sample output for a sequence which belongs to 4th class i.e has 4 ones

   more formally, this is called the one hot encoded representation.
train_output = []
for i in train_input:
    count = 0
    for j in i:
        if j[0] == 1:
            count+=1
    temp_list = ([0]*21)
    temp_list[count]=1
    train_output.append(temp_list)

   for every training input sequence, we generate an equivalent one hot
   encoded output representation.

generating the test data

   for any supervised machine learning task, we need some data as training
   data to teach our program to identify the correct outputs and some data
   as test data to check how our program performs on inputs that it hasn   t
   seen before. letting test and training data overlap is self-defeating
   because, if you had already practiced the questions that were to come
   in your exam, you would most definitely ace it. currently in our
   train_input and train_output, we have 220 (1,048,576) unique examples.
   we will split those into two sets, one for training and the other for
   testing. we will take 10,000 examples (0.9% of the entire data) from
   the dataset and use it as training data and use the rest of the
   1,038,576 examples as test data.
num_examples = 10000
test_input = train_input[num_examples:]
test_output = train_output[num_examples:] #everything beyond 10,000
train_input = train_input[:num_examples]
train_output = train_output[:num_examples] #till 10,000

designing the model

   this is the most important part of the tutorial. tensorflow and various
   other libraries ([21]theano, [22]torch, [23]pybrain) provide tools for
   users to design the model without getting into the nitty-gritty of
   implementing the neural network, the optimization or the
   id26 algorithm.

   danijar outlines a great way to [24]organize tensorflow models which
   you might want to use later to organize tidy up your code. for the
   purpose of this tutorial, we will skip that and focus on writing code
   that just works.

   import the required packages to begin with. if you haven   t already
   installed tensorflow, follow the instructions on [25]this page and then
   continue.
import tensorflow as tf

   after importing the tensorflow, we will define two variables which will
   hold the input data and the target data.
data = tf.placeholder(tf.float32, [none, 20,1])
target = tf.placeholder(tf.float32, [none, 21])

   the dimensions for data are [batch size, sequence length, input
   dimension]. we let the batch size be unknown and to be determined at
   runtime. target will hold the training output data which are the
   correct results that we desire. we   ve made tensorflow placeholders
   which are basically just what they are, placeholders that will be
   supplied with data later.

   now we will create the id56 cell. tensorflow provides support for lstm,
   gru (slightly different architecture than lstm) and simple id56 cells.
   we   re going to use lstm for this task.
num_hidden = 24
cell = tf.nn.id56_cell.lstmcell(num_hidden,state_is_tuple=true)

   for each lstm cell that we initialise, we need to supply a value for
   the hidden dimension, or as some people like to call it, the number of
   units in the lstm cell. the value of it is it up to you, too high a
   value may lead to overfitting or a very low value may yield extremely
   poor results. as many experts have put it, selecting the right
   parameters is more of an art than science.

   before we write any more code, it is imperative to understand how
   tensorflow computation graphs work. from a hacker perspective, it is
   enough to think of it as having two phases. the first phase is building
   the computation graph where you define all the calculations and
   functions that you will execute during runtime. the second phase is the
   execution phase where a tensorflow session is created and the graph
   that was defined earlier is executed with the data we supply.
val, state = tf.nn.dynamic_id56(cell, data, dtype=tf.float32)

   we unroll the network and pass the data to it and store the output in
   val. we also get the state at the end of the dynamic run as a return
   value but we discard it because every time we look at a new sequence,
   the state becomes irrelevant for us. please note, writing this line of
   code doesn   t mean it is executed. we   re still in the first phase of
   designing the model. think of these as functions that are stored in
   variables which will be invoked when we start a session.
val = tf.transpose(val, [1, 0, 2])
last = tf.gather(val, int(val.get_shape()[0]) - 1)

   we transpose the output to switch batch size with sequence size. after
   that we take the values of outputs only at sequence   s last input, which
   means in a string of 20 we   re only interested in the output we got at
   the 20th character and the rest of the output for previous characters
   is irrelevant here.
weight = tf.variable(tf.truncated_normal([num_hidden, int(target.get_shape()[1])
]))
bias = tf.variable(tf.constant(0.1, shape=[target.get_shape()[1]]))

   what we want to do is apply the final transformation to the outputs of
   the lstm and map it to the 21 output classes. we define weights and
   biases, and multiply the output with the weights and add the bias
   values to it. the dimension of the weights will be num_hidden x
   number_of_classes. thus on multiplication with the output (val), the
   resulting dimension will be batch_size x number_of_classes which is
   what we are looking for.
prediction = tf.nn.softmax(tf.matmul(last, weight) + bias)

   after multiplying the output with the weights and adding the bias, we
   will have a matrix with a variety of different values for each class.
   what we are interested in is the id203 score for each class i.e
   the chance that the sequence belongs to a particular class. we then
   calculate the [26]softmax activation to give us the id203 scores.

   what is this function and why are we using it?
   [1*jn8luoqyhtb9erbtb4u4tq.gif]

   this function takes in a vector of values and returns a id203
   distribution for each index depending upon its value. this function
   returns a id203 scores (sum of all the values equate to one)
   which is the final output that we need. if you want to learn more about
   softmax, head over to [27]this link.
cross_id178 = -tf.reduce_sum(target * tf.log(tf.clip_by_value(prediction,1e-10
,1.0)))

   the next step is to calculate the loss or in less technical words, our
   degree of incorrectness. we calculate the cross id178 loss (more
   details [28]here) and use that as our cost function. the cost function
   will help us determine how poorly or how well our predictions stack
   against the actual results. this is the function that we are trying to
   minimize. if you don   t want to delve into the technical details, it is
   okay to just understand what cross id178 loss is calculating. the log
   term helps us measure the degree to which the network got it right or
   wrong. say for example, if the target was 1 and the prediction is close
   to one, our loss would not be much because the values of -log(x) where
   x nears 1 is almost 0. for the same target, if the prediction was 0,
   the cost would increase by a huge amount because -log(x) is very high
   when x is close to zero. adding the log term helps in penalizing the
   model more if it is terribly wrong and very little when the prediction
   is close to the target. the last step in model design is to prepare the
   optimization function.
optimizer = tf.train.adamoptimizer()
minimize = optimizer.minimize(cross_id178)

   tensorflow has a few optimization functions like rmspropoptimizer,
   adagradoptimizer, etc. we choose adamoptimzer and we set minimize to
   the function that shall minimize the cross_id178 loss that we
   calculated previously.

calculating the error on test data

mistakes = tf.not_equal(tf.argmax(target, 1), tf.argmax(prediction, 1))
error = tf.reduce_mean(tf.cast(mistakes, tf.float32))

   this error is a count of how many sequences in the test dataset were
   classified incorrectly. this gives us an idea of the correctness of the
   model on the test dataset.

execution of the graph

   we   re done with designing the model. now the model is to be executed!
init_op = tf.initialize_all_variables()
sess = tf.session()
sess.run(init_op)

   we start a session and initialize all the variables that we   ve defined.
   after that, we begin our training process.
batch_size = 1000
no_of_batches = int(len(train_input)/batch_size)
epoch = 5000
for i in range(epoch):
    ptr = 0
    for j in range(no_of_batches):
        inp, out = train_input[ptr:ptr+batch_size], train_output[ptr:ptr+batch_s
ize]
        ptr+=batch_size
        sess.run(minimize,{data: inp, target: out})
    print "epoch - ",str(i)
incorrect = sess.run(error,{data: test_input, target: test_output})
print('epoch {:2d} error {:3.1f}%'.format(i + 1, 100 * incorrect))
sess.close()

   we decide the batch size and divide the training data accordingly. i   ve
   fixed the batch size at 1000 but you would want to experiment by
   changing it to see how it impacts your results and training time.

   if you are familiar with [29]stochastic id119, this idea
   would seem fairly simple. instead of updating the values after running
   it through all the training samples, we break the training set into
   smaller batches and run it for those. after processing each batch, the
   values of the network are tuned. so every few steps, the network
   weights are adjusted. stochastic optimization methods are known to
   perform better than their counterparts for certain functions. this is
   because the stochastic methods converge much faster but this may not
   always be the case.

   for every batch, we get the input and output data and we run minimize,
   the optimizer function to minimize the cost. all the calculation of
   prediction, cost and id26 is done by tensorflow. we pass the
   feed_dict in sess.run along with the function. the feed_dict is a way
   of assigning data to tensorflow variables in that frame. so we pass the
   input data along with target (correct) outputs. the functions that we
   wrote above, are now being executed.

   that   s all. we   ve made our toy lstm-id56 that learns to count just by
   looking at correct examples! this wasn   t very intuitive to me when i
   trained it for the first time, so i added this line of code below the
   error calculation that would print the result for a particular example.
print sess.run(model.prediction,{data: [[[1],[0],[0],[1],[1],[0],[1],[1],[1],[0]
,[1],[0],[0],[1],[1],[0],[1],[1],[1],[0]]]})

   so as the model trains, you will notice how the id203 score at
   the correct index in the list gradually increases. here   s a link to the
   [30]complete gist of the code.

concerns regarding the training data

   many would ask, why use a training data set which is just 1% of the all
   the data. well, to be able to train it on a cpu with a single core, a
   higher number would increase the time exponentially. you could of
   course adjust the batch size to still keep the number of updates same
   but the final decision is always up to the model designer. despite
   everything, you will be surprised with the results when you realize
   that 1% of the data was enough to let the network achieve stellar
   results!

tinkering with the model

   you can try changing the parameter values to see how it affects the
   performance and training time. you can also try adding multiple layers
   to the id56 to make your model more complex and enable it to learn more
   features. an important feature you can implement is to add the ability
   to [31]save the model values after every few iterations and retrieve
   those values to perform predictions in future. you could also change
   the cell from lstm to gru or a simple id56 cell and compare the
   performance.

results

   training the model with 10,000 sequences, batch size of 1,000 and 5000
   epochs on a macbookpro/8gb/2.4ghz/i5 and no gpu took me about 3   4
   hours. and now the answer to the question, everybody is waiting for.
   how well did it perform?
epoch 5000 error 0.1%

   for the final epoch, the error rate is 0.1% across the entire (almost
   so because our test data is 99% of all possible combinations) dataset!
   this is pretty close to what somebody with the least programming skills
   would have been able to achieve (0% error). but, our neural network
   figured that out by itself! we did not instruct it to perform any of
   the counting operations.

   if you want to speed up the process, you could try reducing the length
   of the binary string and adjusting the values elsewhere in the code to
   make it work.

what can you do now?

   now that you   ve implemented your lstm model, what else is there that
   you can do? sequence classification can be applied to a lot of
   different problems, like [32]handwritten digit recognition or even
   autonomous car driving! think of the rows of the image as individual
   steps or inputs and the entire image to be the sequence. you must
   classify the image as belonging to one of the classes which could be to
   halt, accelerate, turn left, turn right or continue at same speed.
   training data could be a stopper but hell, you could even generate it
   yourself. there is so much more waiting to be done!
     * the post has been updated to be compatible with tensorflow versions
       0.9 and above.

   iframe: [33]/media/c43026df6fee7cdb1aab8aaf916125ea?postid=1907a5bbb1fa

   [1*bqlrszfhjemf4q7pyrlgng.gif]
   [34][1*2f7oqe2ajk1ksrhkmd9zmw.png]
   [35][1*v-ppfkswhbvlwwamsvhhwg.png]
   [36][1*wt2auqisieaozxj-i7brdq.png]

     * [37]neural networks
     * [38]machine learning
     * [39]deep learning
     * [40]artificial intelligence
     * [41]tensorflow

   (button)
   (button)
   (button) 303 claps
   (button) (button) (button) 2 (button) (button)

     (button) blockedunblock (button) followfollowing
   [42]go to the profile of monik pamecha

[43]monik pamecha

   student

     (button) follow
   [44]becoming human: artificial intelligence magazine

[45]becoming human: artificial intelligence magazine

   latest news, info and tutorials on artificial intelligence, machine
   learning, deep learning, big data and what it means for humanity.

     * (button)
       (button) 303
     * (button)
     *
     *

   [46]becoming human: artificial intelligence magazine
   never miss a story from becoming human: artificial intelligence
   magazine, when you sign up for medium. [47]learn more
   never miss a story from becoming human: artificial intelligence
   magazine
   (button) get updatesget updates

references

   visible links
   1. https://plus.google.com/103654360130207659246
   2. https://becominghuman.ai/osd.xml
   3. android-app://com.medium.reader/https/medium.com/p/1907a5bbb1fa
   4. https://medium.com/
   5. https://medium.com/
   6. https://medium.com/m/signin?redirect=https://becominghuman.ai/a-noobs-guide-to-implementing-id56-lstm-using-tensorflow-1907a5bbb1fa&source=--------------------------nav_reg&operation=login
   7. https://medium.com/m/signin?redirect=https://becominghuman.ai/a-noobs-guide-to-implementing-id56-lstm-using-tensorflow-1907a5bbb1fa&source=--------------------------nav_reg&operation=register
   8. https://becominghuman.ai/?source=logo-lo_3a7bxsq0ewq0---5e5bef33608a
   9. https://becominghuman.ai/artificial-intelligence-software-developers-af09386dc05d
  10. https://becominghuman.ai/tagged/tutorial
  11. https://becominghuman.ai/write-for-us-48270209de63
  12. https://becominghuman.ai/artificial-intelligence-communities-c305f28e674c
  13. http://m.me/becominghumanai
  14. https://becominghuman.ai/@monikkinom?source=post_header_lockup
  15. https://becominghuman.ai/@monikkinom
  16. https://en.wikipedia.org/wiki/recurrent_neural_network
  17. https://en.wikipedia.org/wiki/long_short-term_memory
  18. http://karpathy.github.io/2015/05/21/id56-effectiveness/
  19. http://colah.github.io/posts/2015-08-understanding-lstms/
  20. https://gist.github.com/monikkinom/e97d518fe02a79177b081c028a83ec1c
  21. http://deeplearning.net/software/theano/
  22. http://torch.ch/
  23. http://pybrain.org/pages/features
  24. http://danijar.com/structuring-your-tensorflow-models/
  25. https://www.tensorflow.org/versions/r0.9/get_started/os_setup.html
  26. https://en.wikipedia.org/wiki/softmax_function
  27. http://neuralnetworksanddeeplearning.com/chap3.html#softmax
  28. http://neuralnetworksanddeeplearning.com/chap3.html#the_cross-id178_cost_function
  29. https://en.wikipedia.org/wiki/stochastic_gradient_descent
  30. https://gist.github.com/monikkinom/e97d518fe02a79177b081c028a83ec1c
  31. https://www.tensorflow.org/versions/r0.9/how_tos/variables/index.html
  32. https://github.com/aymericdamien/tensorflow-examples/blob/master/examples/3_neuralnetworks/recurrent_network.py
  33. https://becominghuman.ai/media/c43026df6fee7cdb1aab8aaf916125ea?postid=1907a5bbb1fa
  34. https://becominghuman.ai/artificial-intelligence-communities-c305f28e674c
  35. https://upscri.be/8f5f8b
  36. https://becominghuman.ai/write-for-us-48270209de63
  37. https://becominghuman.ai/tagged/neural-networks?source=post
  38. https://becominghuman.ai/tagged/machine-learning?source=post
  39. https://becominghuman.ai/tagged/deep-learning?source=post
  40. https://becominghuman.ai/tagged/artificial-intelligence?source=post
  41. https://becominghuman.ai/tagged/tensorflow?source=post
  42. https://becominghuman.ai/@monikkinom?source=footer_card
  43. https://becominghuman.ai/@monikkinom
  44. https://becominghuman.ai/?source=footer_card
  45. https://becominghuman.ai/?source=footer_card
  46. https://becominghuman.ai/
  47. https://medium.com/@medium/personalize-your-medium-experience-with-users-publications-tags-26a41ab1ee0c#.hx4zuv3mg

   hidden links:
  49. https://medium.com/p/1907a5bbb1fa/share/twitter
  50. https://medium.com/p/1907a5bbb1fa/share/facebook
  51. https://medium.com/p/1907a5bbb1fa/share/twitter
  52. https://medium.com/p/1907a5bbb1fa/share/facebook
