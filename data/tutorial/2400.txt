   #[1]github [2]recent commits to deepframeworks:master

   [3]skip to content

   (button)

     * why github?
       [4]features    
          + [5]code review
          + [6]project management
          + [7]integrations
          + [8]actions
          + [9]team management
          + [10]social coding
          + [11]documentation
          + [12]code hosting
          + [13]customer stories    
          + [14]security    
     * [15]enterprise
     * explore
          + [16]explore github    

learn & contribute
          + [17]topics
          + [18]collections
          + [19]trending
          + [20]learning lab
          + [21]open source guides

connect with others
          + [22]events
          + [23]community forum
          + [24]github education
     * [25]marketplace
     * pricing
       [26]plans    
          + [27]compare plans
          + [28]contact sales
          + [29]nonprofit    
          + [30]education    

   ____________________
     * in this repository all github    
       jump to    

     * no suggested jump to results

     * in this repository all github    
       jump to    
     * in this repository all github    
       jump to    

   [31]sign in [32]sign up

     * [33]watch [34]212
     * [35]star [36]2,069
     * [37]fork [38]325

[39]zer0n/[40]deepframeworks

   [41]code [42]issues 15 [43]pull requests 2 [44]projects 0 [45]insights
   (button) dismiss

join github today

   github is home to over 31 million developers working together to host
   and review code, manage projects, and build software together.
   [46]sign up
   evaluation of deep learning frameworks
     * [47]14 commits
     * [48]1 branch
     * [49]0 releases
     * [50]fetching contributors

   branch: master (button) new pull request
   [51]find file
   clone or download

clone with https

   use git or checkout with svn using the web url.
   https://github.com/z
   [52]download zip

downloading...

   want to be notified of new releases in zer0n/deepframeworks?
   [53]sign in [54]sign up

launching github desktop...

   if nothing happens, [55]download github desktop and try again.

   (button) go back

launching github desktop...

   if nothing happens, [56]download github desktop and try again.

   (button) go back

launching xcode...

   if nothing happens, [57]download xcode and try again.

   (button) go back

launching visual studio...

   if nothing happens, [58]download the github extension for visual studio
   and try again.

   (button) go back
   fetching latest commit   
   cannot retrieve the latest commit at this time.
   [59]permalink
   type      name     latest commit message commit time
        failed to load latest commit information.
        [60]readme.md

readme.md

evaluation of deep learning toolkits

   warning: this research was done in late 2015 with slight modifications
   in early 2016. many toolkits have improved significantly since then.

   abstract. in this study, i evaluate some popular deep learning
   toolkits. the candidates are listed in alphabetical order: [61]caffe,
   [62]cntk, [63]tensorflow, [64]theano, and [65]torch.

   i also provide ratings in some areas because for a lot of people,
   ratings are useful. however, keep in mind that ratings are inherently
   subjective [1].

   if you find something wrong or inadequate, please help improve by
   filing an issue.

   table of contents
    1. [66]modeling capability

     * [67]interfaces
     * [68]model deployment
     * [69]performance
     * [70]architecture
     * [71]ecosystem
     * [72]cross-platform
     __________________________________________________________________

modeling capability

   in this section, we evaluate each toolkit's ability to train common and
   state-of-the-art networks without writing too much code. some of these
   networks are:
     * convnets: alexnet, oxfordnet, googlenet
     * recurrentnets: plain id56, lstm/gru, bidirectional id56
     * sequential modeling with attention.

   in addition, we also evaluate the flexibility to create a new type of
   model.

caffe
[73][687474703a2f2f7777772e7770636c69706172742e636f6d2f7369676e735f73796d626f
6c2f73746172732f355f737461725f726174696e675f73797374656d2f2e63616368652f355f5
37461725f526174696e675f53797374656d5f335f73746172732e706e67]

   caffe is perhaps the first mainstream industry-grade deep learning
   toolkit, started in late 2013, due to its excellent convnet
   implementation (at the time). it is still the most popular toolkit
   within the id161 community, with many extensions being
   actively added.

   however, its support for recurrent networks and id38 in
   general is poor, due to its legacy architecture, which's limitations
   are detailed in the [74]architecture section.

cntk
[75][687474703a2f2f7777772e7770636c69706172742e636f6d2f7369676e735f73796d626f
6c2f73746172732f355f737461725f726174696e675f73797374656d2f2e63616368652f355f5
37461725f526174696e675f53797374656d5f325f73746172732e706e67]

   cntk is a deep learning system started by the speech people who
   [76]started the deep learning craze and grown into a more general
   platform-independent deep learning system. it is better known in the
   speech community than in the general deep learning community.

   in cntk (as in tensorflow and theano), a network is specified as a
   symbolic graph of vector operations, such as matrix add/multiply or
   convolution. a layer is just a composition of those operations. the
   fine granularity of the building blocks (operations) allows users to
   invent new complex layer types without implementing them in a low-level
   language (as in caffe).

tensorflow
[77][687474703a2f2f7777772e7770636c69706172742e636f6d2f7369676e735f73796d626f
6c2f73746172732f355f737461725f726174696e675f73797374656d2f2e63616368652f355f5
37461725f526174696e675f53797374656d5f345f616e645f615f68616c665f73746172732e70
6e67]

   state-of-the-art models
     * id56 api and implementation are suboptimal. the team also commented
       about it [78]here and [79]here.
     * bidirectional id56 [80]not available yet
     * no 3d convolution, which is useful for video recognition

   new models since tf uses symbolic graph of vector operations approach,
   specifying a new network is fairly easy. although it doesn't support
   symbolic loop yet (at least not well tested/documented, as of 05/2016),
   id56s can be made easy and efficient using the [81]bucketing trick.

   however, tf has a major weakness in terms of modeling flexibility.
   every computational flow has be constructed as a static graph. that
   makes some computations difficult, such as [82]id125 (which is
   used frequently in sequence prediction tasks).

theano
[83][687474703a2f2f7777772e7770636c69706172742e636f6d2f7369676e735f73796d626f
6c2f73746172732f355f737461725f726174696e675f73797374656d2f2e63616368652f355f5
37461725f526174696e675f53797374656d5f345f616e645f615f68616c665f73746172732e70
6e67]

   state-of-the-art models. theano has implementation for most
   state-of-the-art networks, either in the form of a higher-level
   framework (e.g. [84]blocks, [85]keras, etc.) or in pure theano.

   new models. theano pioneered the trend of using symbolic graph for
   programming a network. theano's symbolic api supports looping control,
   so-called [86]scan, which makes implementing id56s easy and efficient.
   users don't always have to define a new model at the tensor operations
   level. there are a few higher-level frameworks, mentioned above, which
   make model definition and training simpler.

torch
[87][687474703a2f2f7777772e7770636c69706172742e636f6d2f7369676e735f73796d626f
6c2f73746172732f355f737461725f726174696e675f73797374656d2f2e63616368652f355f5
37461725f526174696e675f53797374656d5f355f73746172732e706e67]

   state-of-the-art models
     * excellent for conv nets. it's worth noting that temporal
       convolution can be done in tensorflow/theano via conv2d but that's
       a trick. the native interface for temporal convolution in torch
       makes it slightly more intuitive to use.
     * rich set of id56s available through a [88]non-official extension [2]

   new models. in torch, there are multiple ways (stack of layers or graph
   of layers) to define a network but essentially, a network is defined as
   a graph of layers. because of this coarser granularity, torch is
   sometimes considered less flexible because for new layer types, users
   have to implement the full forward, backward, and gradient input
   update.

   however, unlike caffe, defining a new layer in torch is much easier
   because you don't have to program in c++. plus, in torch, the
   difference between new layer definition and network definition is
   minimal. in caffe, layers are defined in c++ while networks are defined
   via protobuf.

   torch is more flexible than tensorflow and theano in that it is
   imperative while tf/theano are declarative (i.e. one has to declare a
   computational graph). that makes some operations, e.g. id125,
   much easier to do in torch.
     __________________________________________________________________

   [89][687474703a2f2f692e736e61672e67792f306c6f4e762e6a7067]

   [90][68747470733a2f2f7261772e6769746875622e636f6d2f6b6f7261796b762f746f
   7263682d6e6e67726170682f6d61737465722f646f632f6d6c70335f666f72776172642
   e706e67]
   left: graph model of cntk/theano/tensorflow; right: graph model of
   caffe/torch

interfaces

caffe
[91][687474703a2f2f7777772e7770636c69706172742e636f6d2f7369676e735f73796d626f
6c2f73746172732f355f737461725f726174696e675f73797374656d2f2e63616368652f355f5
37461725f526174696e675f53797374656d5f335f73746172732e706e67]

   caffe has pycaffe interface but that's a mere secondary alternative to
   the command line interface. the model has to be defined in protobuf
   (usually with a plain text editor), even if you use pycaffe.

cntk
[92][687474703a2f2f7777772e7770636c69706172742e636f6d2f7369676e735f73796d626f
6c2f73746172732f355f737461725f726174696e675f73797374656d2f2e63616368652f355f5
37461725f526174696e675f53797374656d5f325f616e645f615f68616c665f73746172732e70
6e67]

   the way to use cntk, similar to caffe, is to specify a config file and
   run command line. cntk has python support since v2.0 and c# support in
   progress.

tensorflow
[93][687474703a2f2f7777772e7770636c69706172742e636f6d2f7369676e735f73796d626f
6c2f73746172732f355f737461725f726174696e675f73797374656d2f2e63616368652f355f5
37461725f526174696e675f53797374656d5f345f616e645f615f68616c665f73746172732e70
6e67]

   tf supports two interfaces: python and c++. this means that you can do
   experiments in a rich, high-level environment and deploy your model in
   an environment that requires native code or low latency.

   it would be perfect if tf supports f# or typescript. the lack of static
   type in python is just ... painful :).

theano
[94][687474703a2f2f7777772e7770636c69706172742e636f6d2f7369676e735f73796d626f
6c2f73746172732f355f737461725f726174696e675f73797374656d2f2e63616368652f355f5
37461725f526174696e675f53797374656d5f345f73746172732e706e67]

   python

torch
[95][687474703a2f2f7777772e7770636c69706172742e636f6d2f7369676e735f73796d626f
6c2f73746172732f355f737461725f726174696e675f73797374656d2f2e63616368652f355f5
37461725f526174696e675f53797374656d5f345f73746172732e706e67]

   torch runs on luajit, which is amazingly fast (comparable with
   industrial languages such as c++/c#/java). hence developers don't have
   to think about symbolic programming, which can be limited. they can
   just write all kinds of computations without worrying about performance
   penalty.

   however, let's face it, lua is not yet a mainstream language.

model deployment

   how easy to deploy a new model?

caffe
[96][687474703a2f2f7777772e7770636c69706172742e636f6d2f7369676e735f73796d626f
6c2f73746172732f355f737461725f726174696e675f73797374656d2f2e63616368652f355f5
37461725f526174696e675f53797374656d5f355f73746172732e706e67]

   caffe is c++ based, which can be compiled on a variety of devices. it
   is cross-platform (windows port is available and maintained [97]here).
   which makes caffe the best choice with respect deployment.

cntk
[98][687474703a2f2f7777772e7770636c69706172742e636f6d2f7369676e735f73796d626f
6c2f73746172732f355f737461725f726174696e675f73797374656d2f2e63616368652f355f5
37461725f526174696e675f53797374656d5f345f616e645f615f68616c665f73746172732e70
6e67]

   like caffe, cntk is also c++ based and is cross-platform. hence,
   deployment should be easy in most cases. however, to my understanding,
   it doesn't work on arm architecture, which limits its its capability on
   mobile devices.

tensorflow
[99][687474703a2f2f7777772e7770636c69706172742e636f6d2f7369676e735f73796d626f
6c2f73746172732f355f737461725f726174696e675f73797374656d2f2e63616368652f355f5
37461725f526174696e675f53797374656d5f345f616e645f615f68616c665f73746172732e70
6e67]

   tf supports c++ interface and the library can be compiled/optimized on
   arm architectures because it uses [100]eigen (instead of a blas
   library). this means that you can deploy your trained models on a
   variety of devices (servers or mobile devices) without having to
   implement a separate model decoder or load python/luajit interpreter
   [3].

   tf doesn't work on windows yet so tf models can't be deployed on
   windows devices though.

theano
[101][687474703a2f2f7777772e7770636c69706172742e636f6d2f7369676e735f73796d626
f6c2f73746172732f355f737461725f726174696e675f73797374656d2f2e63616368652f355f
537461725f526174696e675f53797374656d5f335f73746172732e706e67]

   the lack of low-level interface and the inefficiency of python
   interpreter makes theano less attractive for industrial users. for a
   large model, the overhead of python isn   t too bad but the dogma is
   still there.

   the cross-platform nature (mentioned below) enables a theano model to
   be deployed in a windows environment. which helps it gain some points.

torch
[102][687474703a2f2f7777772e7770636c69706172742e636f6d2f7369676e735f73796d626
f6c2f73746172732f355f737461725f726174696e675f73797374656d2f2e63616368652f355f
537461725f526174696e675f53797374656d5f335f73746172732e706e67]

   torch require luajit to run models. this makes it less attractive than
   bare bone c++ support of caffe/cntk/tf. it   s not just the performance
   overhead, which is minimal. the bigger problem is integration, at api
   level, with a larger production pipeline.

performance

single-gpu

   all of these toolkits call cudnn so as long as there   s no major
   computations or memory allocations at the outer level, they should
   perform similarly.

   soumith@fb has done some [103]benchmarking for convnets. deep learning
   is not just about feedforward convnets, not just about id163, and
   certainly not just about a few passes over the network. however,
   soumith   s benchmark is the only notable one as of today. so we will
   base the single-gpu performance rating based on his benchmark.

tensorflow and torch
[104][687474703a2f2f7777772e7770636c69706172742e636f6d2f7369676e735f73796d626
f6c2f73746172732f355f737461725f726174696e675f73797374656d2f2e63616368652f355f
537461725f526174696e675f53797374656d5f355f73746172732e706e67]

   tensorflow used to be slow when it first came out but as of 05/2016, it
   has reached the ballpark of other frameworks in terms of convnet speed.
   this is not surprising because every framework nowadays calls cudnn for
   the actual computations.

   here's my latest micro benchmark of tensorflow 0.8 vs before. the
   measurement is latency, in milliseconds, for one full minibatch
   forward-backward pass on a single titan x gpu.
     network    tf 0.6 [[105]ref] tf 0.8 [my run] torch fp32 [my run]
     alexnet           292                     97                  81
   inception v1       1237                    518                 470

theano
[106][687474703a2f2f7777772e7770636c69706172742e636f6d2f7369676e735f73796d626
f6c2f73746172732f355f737461725f726174696e675f73797374656d2f2e63616368652f355f
537461725f526174696e675f53797374656d5f335f73746172732e706e67]

   on big networks, theano   s performance is on par with torch7, according
   to [107]this benchmark. the main issue of theano is startup time, which
   is terrible, because theano has to compile c/cuda code to binary. we
   don   t always train big models. in fact, dl researchers often spend more
   time debugging than training big models. tensorflow doesn   t have this
   problem. it simply maps the symbolic tensor operations to the
   already-compiled corresponding function calls.

   even import theano takes time because this import apparently does a lot
   of stuffs. also, after import theano, you are stuck with a
   pre-configured device (e.g. gpu0).

multi-gpu

   tbd

architecture

   developer zone

caffe
[108][687474703a2f2f7777772e7770636c69706172742e636f6d2f7369676e735f73796d626
f6c2f73746172732f355f737461725f726174696e675f73797374656d2f2e63616368652f355f
537461725f526174696e675f53797374656d5f335f73746172732e706e67]

   caffe's architecture was considered excellent when it was born but in
   the modern standard, it is considered average. the main pain points of
   caffe are its layer-wise design in c++ and the protobuf interface for
   model definition.

   layer-wise design. the building block of a network in caffe is layer.
     * for new layer types, you have to define the full forward, backward,
       and gradient update. you can see an already [109]long-list of
       layers implemented in (official) caffe.
     * what's worse is that if you want to support both cpu and gpu, you
       need to implement extra functions, e.g. [110]forward_gpu and
       backward_gpu.
     * worse, you need to assign an int id to your layer type and add that
       to the [111]proto file. if your pull request is not merged early,
       you may need to change the id because someone else already claims
       that.

   protobuf. caffe has pycaffe interface but that's a mere replacement of
   the command line interface. the model has to be defined in protobuf
   (usually with a plain text editor), even if you use pycaffe.

   [copied from [112]my own answer on quora]

cntk

   to be updated ...

tensorflow
[113][687474703a2f2f7777772e7770636c69706172742e636f6d2f7369676e735f73796d626
f6c2f73746172732f355f737461725f726174696e675f73797374656d2f2e63616368652f355f
537461725f526174696e675f53797374656d5f355f73746172732e706e67]

   tf has a clean, modular architecture with multiple frontends and
   execution platforms. details are in the [114]white paper.

   [115][687474703a2f2f692e736e61672e67792f734a6c5a652e6a7067]

theano
[116][687474703a2f2f7777772e7770636c69706172742e636f6d2f7369676e735f73796d626
f6c2f73746172732f355f737461725f726174696e675f73797374656d2f2e63616368652f355f
537461725f526174696e675f53797374656d5f335f73746172732e706e67]

   the architecture is fairly hacky: the whole code base is python where
   c/cuda code is packaged as python string. this makes it hard to
   navigate, debug, refactor, and hence contribute as developers.

torch
[117][687474703a2f2f7777772e7770636c69706172742e636f6d2f7369676e735f73796d626
f6c2f73746172732f355f737461725f726174696e675f73797374656d2f2e63616368652f355f
537461725f526174696e675f53797374656d5f355f73746172732e706e67]

   torch7 and nn libraries are also well-designed with clean, modular
   interfaces.

ecosystem

     * caffe and cntk: c++
     * tensorflow: python and c++
     * theano: python
     * torch: lua is not a mainstream language and hence libraries built
       for it are not as rich as ones built for python.

cross-platform

   caffe, cntk, tensorflow and theano work on all oses. torch does not
   work on windows and there's no known plan to port from either camp.
   ___

   footnotes

   [1] note that i don   t aggregate ratings because different
   users/developers have different priorities.

   [2] disclaimer: i haven   t analyzed this extension carefully.

   [3] see my [118]blog post for why this is desirable.

     *    2019 github, inc.
     * [119]terms
     * [120]privacy
     * [121]security
     * [122]status
     * [123]help

     * [124]contact github
     * [125]pricing
     * [126]api
     * [127]training
     * [128]blog
     * [129]about

   (button) you can   t perform that action at this time.

   you signed in with another tab or window. [130]reload to refresh your
   session. you signed out in another tab or window. [131]reload to
   refresh your session.

   (button)

references

   visible links
   1. https://github.com/opensearch.xml
   2. https://github.com/zer0n/deepframeworks/commits/master.atom
   3. https://github.com/zer0n/deepframeworks#start-of-content
   4. https://github.com/features
   5. https://github.com/features/code-review/
   6. https://github.com/features/project-management/
   7. https://github.com/features/integrations
   8. https://github.com/features/actions
   9. https://github.com/features#team-management
  10. https://github.com/features#social-coding
  11. https://github.com/features#documentation
  12. https://github.com/features#code-hosting
  13. https://github.com/customer-stories
  14. https://github.com/security
  15. https://github.com/enterprise
  16. https://github.com/explore
  17. https://github.com/topics
  18. https://github.com/collections
  19. https://github.com/trending
  20. https://lab.github.com/
  21. https://opensource.guide/
  22. https://github.com/events
  23. https://github.community/
  24. https://education.github.com/
  25. https://github.com/marketplace
  26. https://github.com/pricing
  27. https://github.com/pricing#feature-comparison
  28. https://enterprise.github.com/contact
  29. https://github.com/nonprofit
  30. https://education.github.com/
  31. https://github.com/login?return_to=/zer0n/deepframeworks
  32. https://github.com/join
  33. https://github.com/login?return_to=/zer0n/deepframeworks
  34. https://github.com/zer0n/deepframeworks/watchers
  35. https://github.com/login?return_to=/zer0n/deepframeworks
  36. https://github.com/zer0n/deepframeworks/stargazers
  37. https://github.com/login?return_to=/zer0n/deepframeworks
  38. https://github.com/zer0n/deepframeworks/network/members
  39. https://github.com/zer0n
  40. https://github.com/zer0n/deepframeworks
  41. https://github.com/zer0n/deepframeworks
  42. https://github.com/zer0n/deepframeworks/issues
  43. https://github.com/zer0n/deepframeworks/pulls
  44. https://github.com/zer0n/deepframeworks/projects
  45. https://github.com/zer0n/deepframeworks/pulse
  46. https://github.com/join?source=prompt-code
  47. https://github.com/zer0n/deepframeworks/commits/master
  48. https://github.com/zer0n/deepframeworks/branches
  49. https://github.com/zer0n/deepframeworks/releases
  50. https://github.com/zer0n/deepframeworks/graphs/contributors
  51. https://github.com/zer0n/deepframeworks/find/master
  52. https://github.com/zer0n/deepframeworks/archive/master.zip
  53. https://github.com/login?return_to=https://github.com/zer0n/deepframeworks
  54. https://github.com/join?return_to=/zer0n/deepframeworks
  55. https://desktop.github.com/
  56. https://desktop.github.com/
  57. https://developer.apple.com/xcode/
  58. https://visualstudio.github.com/
  59. https://github.com/zer0n/deepframeworks/tree/b8113bd45c9432848159ae855ca220095f24b219
  60. https://github.com/zer0n/deepframeworks/blob/master/readme.md
  61. https://github.com/bvlc/caffe
  62. https://github.com/microsoft/cntk
  63. https://github.com/tensorflow/tensorflow
  64. https://github.com/theano/theano
  65. https://github.com/torch/torch7
  66. https://github.com/zer0n/deepframeworks#modeling-capability
  67. https://github.com/zer0n/deepframeworks#interfaces
  68. https://github.com/zer0n/deepframeworks#model-deployment
  69. https://github.com/zer0n/deepframeworks#performance
  70. https://github.com/zer0n/deepframeworks#architecture
  71. https://github.com/zer0n/deepframeworks#ecosystem
  72. https://github.com/zer0n/deepframeworks#cross-platform
  73. https://camo.githubusercontent.com/d0eb347e927a07a5d5b153e2da782a09038c2007/687474703a2f2f7777772e7770636c69706172742e636f6d2f7369676e735f73796d626f6c2f73746172732f355f737461725f726174696e675f73797374656d2f2e63616368652f355f537461725f526174696e675f53797374656d5f335f73746172732e706e67
  74. https://github.com/zer0n/deepframeworks#architecture
  75. https://camo.githubusercontent.com/1a60dfba8174ed132fb7a4a63d36f56ee6c98871/687474703a2f2f7777772e7770636c69706172742e636f6d2f7369676e735f73796d626f6c2f73746172732f355f737461725f726174696e675f73797374656d2f2e63616368652f355f537461725f526174696e675f53797374656d5f325f73746172732e706e67
  76. http://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.185.1908&rep=rep1&type=pdf
  77. https://camo.githubusercontent.com/4f9b74f73d5b83b604e7a6c3f778a0a0c5860b96/687474703a2f2f7777772e7770636c69706172742e636f6d2f7369676e735f73796d626f6c2f73746172732f355f737461725f726174696e675f73797374656d2f2e63616368652f355f537461725f526174696e675f53797374656d5f345f616e645f615f68616c665f73746172732e706e67
  78. https://github.com/tensorflow/tensorflow/issues/7
  79. https://groups.google.com/a/tensorflow.org/forum/?utm_medium=email&utm_source=footer#!msg/discuss/b8hyi0tvtpy/ar43oiuuawaj
  80. https://groups.google.com/a/tensorflow.org/forum/?utm_medium=email&utm_source=footer#!msg/discuss/lwgal7weuw4/uxal4bykagaj
  81. https://www.tensorflow.org/versions/r0.8/tutorials/id195/index.html#bucketing-and-padding
  82. https://github.com/tensorflow/tensorflow/issues/654
  83. https://camo.githubusercontent.com/4f9b74f73d5b83b604e7a6c3f778a0a0c5860b96/687474703a2f2f7777772e7770636c69706172742e636f6d2f7369676e735f73796d626f6c2f73746172732f355f737461725f726174696e675f73797374656d2f2e63616368652f355f537461725f526174696e675f53797374656d5f345f616e645f615f68616c665f73746172732e706e67
  84. https://github.com/mila-udem/blocks
  85. https://github.com/fchollet/keras
  86. http://deeplearning.net/software/theano/tutorial/loop.html
  87. https://camo.githubusercontent.com/407fe396c0c76a0e4e77a4b2efa8acca55cf4c77/687474703a2f2f7777772e7770636c69706172742e636f6d2f7369676e735f73796d626f6c2f73746172732f355f737461725f726174696e675f73797374656d2f2e63616368652f355f537461725f526174696e675f53797374656d5f355f73746172732e706e67
  88. https://github.com/element-research/id56
  89. https://camo.githubusercontent.com/8dfce50523935a928019352342dc649494cafb8c/687474703a2f2f692e736e61672e67792f306c6f4e762e6a7067
  90. https://camo.githubusercontent.com/49ac7d0f42e99d979c80a10d0ffd125f4b3df0ea/68747470733a2f2f7261772e6769746875622e636f6d2f6b6f7261796b762f746f7263682d6e6e67726170682f6d61737465722f646f632f6d6c70335f666f72776172642e706e67
  91. https://camo.githubusercontent.com/d0eb347e927a07a5d5b153e2da782a09038c2007/687474703a2f2f7777772e7770636c69706172742e636f6d2f7369676e735f73796d626f6c2f73746172732f355f737461725f726174696e675f73797374656d2f2e63616368652f355f537461725f526174696e675f53797374656d5f335f73746172732e706e67
  92. https://camo.githubusercontent.com/7e2662e3157af40e8b118f0e0e9ed0faf214d218/687474703a2f2f7777772e7770636c69706172742e636f6d2f7369676e735f73796d626f6c2f73746172732f355f737461725f726174696e675f73797374656d2f2e63616368652f355f537461725f526174696e675f53797374656d5f325f616e645f615f68616c665f73746172732e706e67
  93. https://camo.githubusercontent.com/4f9b74f73d5b83b604e7a6c3f778a0a0c5860b96/687474703a2f2f7777772e7770636c69706172742e636f6d2f7369676e735f73796d626f6c2f73746172732f355f737461725f726174696e675f73797374656d2f2e63616368652f355f537461725f526174696e675f53797374656d5f345f616e645f615f68616c665f73746172732e706e67
  94. https://camo.githubusercontent.com/4f8f2790b8f2abab48a64329fd5fc2b70cf63185/687474703a2f2f7777772e7770636c69706172742e636f6d2f7369676e735f73796d626f6c2f73746172732f355f737461725f726174696e675f73797374656d2f2e63616368652f355f537461725f526174696e675f53797374656d5f345f73746172732e706e67
  95. https://camo.githubusercontent.com/4f8f2790b8f2abab48a64329fd5fc2b70cf63185/687474703a2f2f7777772e7770636c69706172742e636f6d2f7369676e735f73796d626f6c2f73746172732f355f737461725f726174696e675f73797374656d2f2e63616368652f355f537461725f526174696e675f53797374656d5f345f73746172732e706e67
  96. https://camo.githubusercontent.com/407fe396c0c76a0e4e77a4b2efa8acca55cf4c77/687474703a2f2f7777772e7770636c69706172742e636f6d2f7369676e735f73796d626f6c2f73746172732f355f737461725f726174696e675f73797374656d2f2e63616368652f355f537461725f526174696e675f53797374656d5f355f73746172732e706e67
  97. https://github.com/msrdl/caffe
  98. https://camo.githubusercontent.com/4f9b74f73d5b83b604e7a6c3f778a0a0c5860b96/687474703a2f2f7777772e7770636c69706172742e636f6d2f7369676e735f73796d626f6c2f73746172732f355f737461725f726174696e675f73797374656d2f2e63616368652f355f537461725f526174696e675f53797374656d5f345f616e645f615f68616c665f73746172732e706e67
  99. https://camo.githubusercontent.com/4f9b74f73d5b83b604e7a6c3f778a0a0c5860b96/687474703a2f2f7777772e7770636c69706172742e636f6d2f7369676e735f73796d626f6c2f73746172732f355f737461725f726174696e675f73797374656d2f2e63616368652f355f537461725f526174696e675f53797374656d5f345f616e645f615f68616c665f73746172732e706e67
 100. http://eigen.tuxfamily.org/
 101. https://camo.githubusercontent.com/d0eb347e927a07a5d5b153e2da782a09038c2007/687474703a2f2f7777772e7770636c69706172742e636f6d2f7369676e735f73796d626f6c2f73746172732f355f737461725f726174696e675f73797374656d2f2e63616368652f355f537461725f526174696e675f53797374656d5f335f73746172732e706e67
 102. https://camo.githubusercontent.com/d0eb347e927a07a5d5b153e2da782a09038c2007/687474703a2f2f7777772e7770636c69706172742e636f6d2f7369676e735f73796d626f6c2f73746172732f355f737461725f726174696e675f73797374656d2f2e63616368652f355f537461725f526174696e675f53797374656d5f335f73746172732e706e67
 103. https://github.com/soumith/convnet-benchmarks
 104. https://camo.githubusercontent.com/407fe396c0c76a0e4e77a4b2efa8acca55cf4c77/687474703a2f2f7777772e7770636c69706172742e636f6d2f7369676e735f73796d626f6c2f73746172732f355f737461725f726174696e675f73797374656d2f2e63616368652f355f537461725f526174696e675f53797374656d5f355f73746172732e706e67
 105. https://github.com/soumith/convnet-benchmarks/blob/efb3d9321d14856f49951980dbea2f554190161a/readme.md
 106. https://camo.githubusercontent.com/d0eb347e927a07a5d5b153e2da782a09038c2007/687474703a2f2f7777772e7770636c69706172742e636f6d2f7369676e735f73796d626f6c2f73746172732f355f737461725f726174696e675f73797374656d2f2e63616368652f355f537461725f526174696e675f53797374656d5f335f73746172732e706e67
 107. http://arxiv.org/pdf/1211.5590v1.pdf
 108. https://camo.githubusercontent.com/d0eb347e927a07a5d5b153e2da782a09038c2007/687474703a2f2f7777772e7770636c69706172742e636f6d2f7369676e735f73796d626f6c2f73746172732f355f737461725f726174696e675f73797374656d2f2e63616368652f355f537461725f526174696e675f53797374656d5f335f73746172732e706e67
 109. https://github.com/bvlc/caffe/tree/master/src/caffe/layers
 110. https://github.com/bvlc/caffe/blob/master/src/caffe/layers/cudnn_conv_layer.cu
 111. https://github.com/bvlc/caffe/blob/master/src/caffe/proto/caffe.proto#l1046
 112. https://www.quora.com/how-is-tensorflow-architected-differently-from-caffe
 113. https://camo.githubusercontent.com/407fe396c0c76a0e4e77a4b2efa8acca55cf4c77/687474703a2f2f7777772e7770636c69706172742e636f6d2f7369676e735f73796d626f6c2f73746172732f355f737461725f726174696e675f73797374656d2f2e63616368652f355f537461725f526174696e675f53797374656d5f355f73746172732e706e67
 114. http://download.tensorflow.org/paper/whitepaper2015.pdf
 115. https://camo.githubusercontent.com/7e6ab40dc873dae2b0bdde0a89ab61b92f307f07/687474703a2f2f692e736e61672e67792f734a6c5a652e6a7067
 116. https://camo.githubusercontent.com/d0eb347e927a07a5d5b153e2da782a09038c2007/687474703a2f2f7777772e7770636c69706172742e636f6d2f7369676e735f73796d626f6c2f73746172732f355f737461725f726174696e675f73797374656d2f2e63616368652f355f537461725f526174696e675f53797374656d5f335f73746172732e706e67
 117. https://camo.githubusercontent.com/407fe396c0c76a0e4e77a4b2efa8acca55cf4c77/687474703a2f2f7777772e7770636c69706172742e636f6d2f7369676e735f73796d626f6c2f73746172732f355f737461725f726174696e675f73797374656d2f2e63616368652f355f537461725f526174696e675f53797374656d5f355f73746172732e706e67
 118. http://www.kentran.net/2014/12/challenges-in-machine-learning-practice.html
 119. https://github.com/site/terms
 120. https://github.com/site/privacy
 121. https://github.com/security
 122. https://githubstatus.com/
 123. https://help.github.com/
 124. https://github.com/contact
 125. https://github.com/pricing
 126. https://developer.github.com/
 127. https://training.github.com/
 128. https://github.blog/
 129. https://github.com/about
 130. https://github.com/zer0n/deepframeworks
 131. https://github.com/zer0n/deepframeworks

   hidden links:
 133. https://github.com/
 134. https://github.com/zer0n/deepframeworks
 135. https://github.com/zer0n/deepframeworks
 136. https://github.com/zer0n/deepframeworks
 137. https://help.github.com/articles/which-remote-url-should-i-use
 138. https://github.com/zer0n/deepframeworks#evaluation-of-deep-learning-toolkits
 139. https://github.com/zer0n/deepframeworks#modeling-capability
 140. https://github.com/zer0n/deepframeworks#caffe-
 141. https://github.com/zer0n/deepframeworks#cntk-
 142. https://github.com/zer0n/deepframeworks#tensorflow-
 143. https://github.com/zer0n/deepframeworks#theano-
 144. https://github.com/zer0n/deepframeworks#torch-
 145. https://github.com/zer0n/deepframeworks#interfaces
 146. https://github.com/zer0n/deepframeworks#caffe--1
 147. https://github.com/zer0n/deepframeworks#cntk--1
 148. https://github.com/zer0n/deepframeworks#tensorflow--1
 149. https://github.com/zer0n/deepframeworks#theano--1
 150. https://github.com/zer0n/deepframeworks#torch--1
 151. https://github.com/zer0n/deepframeworks#model-deployment
 152. https://github.com/zer0n/deepframeworks#caffe--2
 153. https://github.com/zer0n/deepframeworks#cntk--2
 154. https://github.com/zer0n/deepframeworks#tensorflow--2
 155. https://github.com/zer0n/deepframeworks#theano--2
 156. https://github.com/zer0n/deepframeworks#torch--2
 157. https://github.com/zer0n/deepframeworks#performance
 158. https://github.com/zer0n/deepframeworks#single-gpu
 159. https://github.com/zer0n/deepframeworks#tensorflow-and-torch-
 160. https://github.com/zer0n/deepframeworks#theano--3
 161. https://github.com/zer0n/deepframeworks#multi-gpu
 162. https://github.com/zer0n/deepframeworks#architecture
 163. https://github.com/zer0n/deepframeworks#caffe--3
 164. https://github.com/zer0n/deepframeworks#cntk
 165. https://github.com/zer0n/deepframeworks#tensorflow--3
 166. https://github.com/zer0n/deepframeworks#theano--4
 167. https://github.com/zer0n/deepframeworks#torch--3
 168. https://github.com/zer0n/deepframeworks#ecosystem
 169. https://github.com/zer0n/deepframeworks#cross-platform
 170. https://github.com/
