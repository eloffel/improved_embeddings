   #[1]kdnuggets: analytics, big data, data mining and data science feed
   [2]kdnuggets    feed [3]kdnuggets    comments feed [4]kdnuggets    must
   know tips for deep learning neural networks comments feed [5]big data,
   data visualization, internet of things, san francisco, april 21-22
   [6]lift analysis     a data scientist   s secret weapon

kdnuggets

     [7]subscribe to kdnuggets news  | [8]twitter    [9]facebook
   [10]linkedin  |  [11]contact
   ____________________ search
   [menu-30.png]
   [search-icon.png]
     * [12]software
     * [13]news/blog
     * [14]top stories
     * [15]opinions
     * [16]tutorials
     * [17]jobs
     * [18]companies
     * [19]courses
     * [20]datasets
     * [21]education
     * [22]certificates
     * [23]meetings
     * [24]webinars


   [25]kdnuggets home    [26]news    [27]2016    [28]mar    [29]tutorials,
   overviews    must know tips for deep learning neural networks
   ( [30]16:n10 )

must know tips for deep learning neural networks

   [31][prv.gif] previous post
   [32]next post [nxt.gif]

     http likes 130
   tags: [33]convolutional neural networks, [34]deep learning

   deep learning is white hot research topic. add some solid deep learning
   neural network tips and tricks from a phd researcher.
     __________________________________________________________________

   by xiu-shen wei, nanjing university.

   deep neural networks, especially convolutional neural networks (id98),
   allows computational models that are composed of multiple processing
   layers to learn representations of data with multiple levels of
   abstraction. these methods have dramatically improved the
   state-of-the-arts in visual object recognition, id164, text
   recognition and many other domains such as drug discovery and genomics.

   tip & tricks

   in addition, many solid papers have been published in this topic, and
   some high quality open source id98 software packages have been made
   available. there are also well-written id98 tutorials or id98 software
   manuals. however, it might lack a recent and comprehensive summary
   about the details of how to implement an excellent deep convolutional
   neural networks from scratch. thus, we collected and concluded many
   implementation details for did98s. here we will introduce these
   extensive implementation details, i.e., tricks or tips, for building
   and training your own deep networks.

                                introduction

   we assume you already know the basic knowledge of deep learning, and
   here we will present the implementation details (tricks or tips) in
   deep neural networks, especially id98 for image-related tasks, mainly in
   eight aspects:
    1. data augmentation
    2. pre-processing on images
    3. initializations of networks
    4. some tips during training
    5. selections of id180
    6. diverse id173s
    7. some insights found from figures
    8. methods of ensemble multiple deep networks

   additionally, the corresponding slides are available at [35][slide]. if
   there are any problems/mistakes in these materials and slides, or there
   are something important/interesting you consider that should be added,
   just feel free to [36]contact me.

                            1. data augmentation

   since deep networks need to be trained on a huge number of training
   images to achieve satisfactory performance, if the original image data
   set contains limited training images, it is better to do data
   augmentation to boost the performance. also, data augmentation becomes
   the thing must to do when training a deep network.

   there are many ways to do data augmentation, such as the popular
   horizontally flipping, random crops and color jittering. moreover, you
   could try combinations of multiple different processing, e.g., doing
   the rotation and random scaling at the same time. in addition, you can
   try to raise saturation and value (s and v components of the hsv color
   space) of all pixels to a power between 0.25 and 4 (same for all pixels
   within a patch), multiply these values by a factor between 0.7 and 1.4,
   and add to them a value between -0.1 and 0.1. also, you could add a
   value between [-0.1, 0.1] to the hue (h component of hsv) of all pixels
   in the image/patch.

   krizhevsky et al. [37][1] proposed fancy pca when training the famous
   alex-net in 2012. fancy pca alters the intensities of the rgb channels
   in training images. in practice, you can firstly perform pca on the set
   of rgb pixel values throughout your training images. and then, for each
   training image, just add the following quantity to each rgb image pixel
   (i.e., i[xy]=[i[xy]^r,i[xy]^g,i[xy]^b]^t): p[1],p[2],p[3]][  [1]
     [1],  [2]  [2],  [3]  [3]]^t where, p[i] and   [i] are the i-th eigenvector
   and eigenvalue of the 3    3 covariance matrix of rgb pixel values,
   respectively, and   [i] is a random variable drawn from a gaussian with
   mean zero and standard deviation 0.1. please note that, each   [i] is
   drawn only once for all the pixels of a particular training image until
   that image is used for training again. that is to say, when the model
   meets the same training image again, it will randomly produce another
     [i] for data augmentation. in [38][1], they claimed that    fancy pca
   could approximately capture an important property of natural images,
   namely, that object identity is invariant to changes in the intensity
   and color of the illumination   . to the classification performance, this
   scheme reduced the top-1 error rate by over 1% in the competition of
   id163 2012.

                              2. pre-processing

   now we have obtained a large number of training samples (images/crops),
   but please do not hurry! actually, it is necessary to do pre-processing
   on these images/crops. in this section, we will introduce several
   approaches for pre-processing.

   the first and simple pre-processing approach is zero-center the data,
   and then normalize them, which is presented as two lines python codes
   as follows:
>>> x -= np.mean(x, axis = 0) # zero-center
>>> x /= np.std(x, axis = 0) # normalize

   where, x is the input data (numins  numdim). another form of this
   pre-processing normalizes each dimension so that the min and max along
   the dimension is -1 and 1 respectively. it only makes sense to apply
   this pre-processing if you have a reason to believe that different
   input features have different scales (or units), but they should be of
   approximately equal importance to the learning algorithm. in case of
   images, the relative scales of pixels are already approximately equal
   (and in range from 0 to 255), so it is not strictly necessary to
   perform this additional pre-processing step.

   another pre-processing approach similar to the first one is pca
   whitening. in this process, the data is first centered as described
   above. then, you can compute the covariance matrix that tells us about
   the correlation structure in the data:
>>> x -= np.mean(x, axis = 0) # zero-center
>>> cov = np.dot(x.t, x) / x.shape[0] # compute the covariance matrix

   after that, you decorrelate the data by projecting the original (but
   zero-centered) data into the eigenbasis:
>>> u,s,v = np.linalg.svd(cov) # compute the svd factorization of the data covar
iance matrix
>>> xrot = np.dot(x, u) # decorrelate the data

   the last transformation is whitening, which takes the data in the
   eigenbasis and divides every dimension by the eigenvalue to normalize
   the scale:
>>> xwhite = xrot / np.sqrt(s + 1e-5) # divide by the eigenvalues (which are squ
are roots of the singular values)

   note that here it adds 1e-5 (or a small constant) to prevent division
   by zero. one weakness of this transformation is that it can greatly
   exaggerate the noise in the data, since it stretches all dimensions
   (including the irrelevant dimensions of tiny variance that are mostly
   noise) to be of equal size in the input. this can in practice be
   mitigated by stronger smoothing (i.e., increasing 1e-5 to be a larger
   number).

   please note that, we describe these pre-processing here just for
   completeness. in practice, these transformations are not used with
   convolutional neural networks. however, it is also very important to
   zero-center the data, and it is common to see id172 of every
   pixel as well.

   pages: 1 [39]2
     __________________________________________________________________

   [40][prv.gif] previous post
   [41]next post [nxt.gif]
     __________________________________________________________________

top stories past 30 days

                                              most popular
    1. [42]another 10 free must-read books for machine learning and data
       science
    2. [43]9 must-have skills you need to become a data scientist, updated
    3. [44]who is a typical data scientist in 2019?
    4. [45]the pareto principle for data scientists
    5. [46]what no one will tell you about data science job applications
    6. [47]19 inspiring women in ai, big data, data science, machine
       learning
    7. [48]my favorite mind-blowing machine learning/ai breakthroughs

                                                most shared
    1. [49]id158s optimization using genetic algorithm
       with python
    2. [50]who is a typical data scientist in 2019?
    3. [51]8 reasons why you should get a microsoft azure certification
    4. [52]the pareto principle for data scientists
    5. [53]r vs python for data visualization
    6. [54]how to work in data science, ai, big data
    7. [55]the deep learning toolset     an overview

[56]latest news

     * [57]download your datax guide to ai in marketing
     * [58]kdnuggets offer: save 20% on strata in london
     * [59]training a champion: building deep neural nets for big ...
     * [60]building a recommender system
     * [61]predict age and gender using convolutional neural netwo...
     * [62]top tweets, mar 27     apr 02: here is a great ex...

more recent stories

     * [63]top tweets, mar 27     apr 02: here is a great explanat...
     * [64]odsc east is selling out; odsc india announced
     * [65]accelerate ai and data science career expo, may 4, 2019
     * [66]grow your data career at datasciencego, san diego, sep 27-29
     * [67]getting started with nlp using the pytorch framework
     * [68]how to diy your data science education
     * [69]top 8 data science use cases in gaming
     * [70]kdnuggets 19:n13, apr 3: top 10 data scientist coding mista...
     * [71]make better data-driven business decisions
     * [72]top stories, mar 25-31: r vs python for data visualization;
       th...
     * [73]two predictive analytics world events in europe this fall
     * [74]7 qualities your big data visualization tools absolutely must
       ...
     * [75]yeshiva university: tenure-track faculty in ai and machine
       lea...
     * [76]which face is real?
     * [77]yeshiva university: program director / tenure track faculty
       me...
     * [78]top 10 coding mistakes made by data scientists
     * [79]uber   s case study at paw industry 4.0: machine learning ...
     * [80]xai     a data scientist   s mouthpiece
     * [81]what does gpt-2 think about the ai arms race?
     * [82]openclassrooms: data freelance online course creator
       [telecomm...

   [83]kdnuggets home    [84]news    [85]2016    [86]mar    [87]tutorials,
   overviews    must know tips for deep learning neural networks
   ( [88]16:n10 )
      2019 kdnuggets. [89]about kdnuggets.  [90]privacy policy. [91]terms
   of service

   [92]subscribe to kdnuggets news
   [93][tw_c48.png] [94]facebook [95]linkedin
   x
   [envelope.png] [96]get kdnuggets, a leading newsletter on ai, data
   science, and machine learning
   email: ______________________________
   sign up
   leave this field empty if you're human: ____________________

references

   visible links
   1. https://www.kdnuggets.com/feed/
   2. https://www.kdnuggets.com/feed
   3. https://www.kdnuggets.com/comments/feed
   4. https://www.kdnuggets.com/2016/03/must-know-tips-deep-learning-part-1.html/feed
   5. https://www.kdnuggets.com/2016/03/ieg-big-data-innovation-visualization-iot-san-francisco-april.html
   6. https://www.kdnuggets.com/2016/03/lift-analysis-data-scientist-secret-weapon.html
   7. https://www.kdnuggets.com/news/subscribe.html
   8. https://twitter.com/kdnuggets
   9. https://www.facebook.com/kdnuggets
  10. https://www.linkedin.com/groups/54257/
  11. https://www.kdnuggets.com/contact.html
  12. https://www.kdnuggets.com/software/index.html
  13. https://www.kdnuggets.com/news/index.html
  14. https://www.kdnuggets.com/news/top-stories.html
  15. https://www.kdnuggets.com/opinions/index.html
  16. https://www.kdnuggets.com/tutorials/index.html
  17. https://www.kdnuggets.com/jobs/index.html
  18. https://www.kdnuggets.com/companies/index.html
  19. https://www.kdnuggets.com/courses/index.html
  20. https://www.kdnuggets.com/datasets/index.html
  21. https://www.kdnuggets.com/education/index.html
  22. https://www.kdnuggets.com/education/analytics-data-mining-certificates.html
  23. https://www.kdnuggets.com/meetings/index.html
  24. https://www.kdnuggets.com/webcasts/index.html
  25. https://www.kdnuggets.com/
  26. https://www.kdnuggets.com/news/index.html
  27. https://www.kdnuggets.com/2016/index.html
  28. https://www.kdnuggets.com/2016/03/index.html
  29. https://www.kdnuggets.com/2016/03/tutorials.html
  30. https://www.kdnuggets.com/2016/n10.html
  31. https://www.kdnuggets.com/2016/03/ieg-big-data-innovation-visualization-iot-san-francisco-april.html
  32. https://www.kdnuggets.com/2016/03/lift-analysis-data-scientist-secret-weapon.html
  33. https://www.kdnuggets.com/tag/convolutional-neural-networks
  34. https://www.kdnuggets.com/tag/deep-learning
  35. http://lamda.nju.edu.cn/weixs/slide/id98tricks_slide.pdf
  36. http://lamda.nju.edu.cn/weixs/
  37. http://papers.nips.cc/paper/4824-id163-classification-with-deep-convolutional-neural-networks.pdf
  38. http://papers.nips.cc/paper/4824-id163-classification-with-deep-convolutional-neural-networks.pdf
  39. https://www.kdnuggets.com/2016/03/must-know-tips-deep-learning-part-1.html/2
  40. https://www.kdnuggets.com/2016/03/ieg-big-data-innovation-visualization-iot-san-francisco-april.html
  41. https://www.kdnuggets.com/2016/03/lift-analysis-data-scientist-secret-weapon.html
  42. https://www.kdnuggets.com/2019/03/another-10-free-must-read-books-for-machine-learning-and-data-science.html
  43. https://www.kdnuggets.com/2018/05/simplilearn-9-must-have-skills-data-scientist.html
  44. https://www.kdnuggets.com/2019/03/typical-data-scientist-2019.html
  45. https://www.kdnuggets.com/2019/03/pareto-principle-data-scientists.html
  46. https://www.kdnuggets.com/2019/03/data-science-job-applications.html
  47. https://www.kdnuggets.com/2019/03/women-ai-big-data-science-machine-learning.html
  48. https://www.kdnuggets.com/2019/03/favorite-ml-ai-breakthroughs.html
  49. https://www.kdnuggets.com/2019/03/artificial-neural-networks-optimization-genetic-algorithm-python.html
  50. https://www.kdnuggets.com/2019/03/typical-data-scientist-2019.html
  51. https://www.kdnuggets.com/2019/03/simplilearn-8-reasons-microsoft-azure-certification.html
  52. https://www.kdnuggets.com/2019/03/pareto-principle-data-scientists.html
  53. https://www.kdnuggets.com/2019/03/r-vs-python-data-visualization.html
  54. https://www.kdnuggets.com/2019/03/work-data-science-ai-big-data.html
  55. https://www.kdnuggets.com/2019/03/deep-learning-toolset-overview.html
  56. https://www.kdnuggets.com/news/index.html
  57. https://www.kdnuggets.com/2019/04/datax-download-guide-ai-marketing.html
  58. https://www.kdnuggets.com/2019/04/strata-kdnuggets-offer-save-london.html
  59. https://www.kdnuggets.com/2019/04/sisense-deep-neural-nets-big-data-analytics.html
  60. https://www.kdnuggets.com/2019/04/building-recommender-system.html
  61. https://www.kdnuggets.com/2019/04/predict-age-gender-using-convolutional-neural-network-opencv.html
  62. https://www.kdnuggets.com/2019/04/top-tweets-mar27-apr02.html
  63. https://www.kdnuggets.com/2019/04/top-tweets-mar27-apr02.html
  64. https://www.kdnuggets.com/2019/04/odsc-east-selling-out-india-announced.html
  65. https://www.kdnuggets.com/jobs/19/04-03-accelerate-ai-data-science-career-expo-2019.html
  66. https://www.kdnuggets.com/2019/04/formulated-data-career-datasciencego-san-diego.html
  67. https://www.kdnuggets.com/2019/04/nlp-pytorch.html
  68. https://www.kdnuggets.com/2019/04/diy-your-data-science-education.html
  69. https://www.kdnuggets.com/2019/04/top-8-data-science-use-cases-gaming.html
  70. https://www.kdnuggets.com/2019/n13.html
  71. https://www.kdnuggets.com/2019/04/psu-make-better-data-driven-business-decisions.html
  72. https://www.kdnuggets.com/2019/04/top-news-week-0325-0331.html
  73. https://www.kdnuggets.com/2019/04/paw-two-predictive-analytics-world-events-europe-fall.html
  74. https://www.kdnuggets.com/2019/04/7-qualities-big-data-visualization-tools.html
  75. https://www.kdnuggets.com/jobs/19/04-02-yeshiva-university-faculty-ai-machine-learning.html
  76. https://www.kdnuggets.com/2019/04/which-face-real-stylegan.html
  77. https://www.kdnuggets.com/jobs/19/04-02-yeshiva-university-program-director-faculty-artificial-intelligence-machine-learning.html
  78. https://www.kdnuggets.com/2019/04/top-10-coding-mistakes-data-scientists.html
  79. https://www.kdnuggets.com/2019/04/paw-uber-case-study-machine-learning-enforce-mobile-performance.html
  80. https://www.kdnuggets.com/2019/04/xai-data-scientist.html
  81. https://www.kdnuggets.com/2019/04/gpt-2-think-about-ai-arms-race.html
  82. https://www.kdnuggets.com/jobs/19/04-01-openclassrooms-data-freelance-online-course-creator-b.html
  83. https://www.kdnuggets.com/
  84. https://www.kdnuggets.com/news/index.html
  85. https://www.kdnuggets.com/2016/index.html
  86. https://www.kdnuggets.com/2016/03/index.html
  87. https://www.kdnuggets.com/2016/03/tutorials.html
  88. https://www.kdnuggets.com/2016/n10.html
  89. https://www.kdnuggets.com/about/index.html
  90. https://www.kdnuggets.com/news/privacy-policy.html
  91. https://www.kdnuggets.com/terms-of-service.html
  92. https://www.kdnuggets.com/news/subscribe.html
  93. https://twitter.com/kdnuggets
  94. https://facebook.com/kdnuggets
  95. https://www.linkedin.com/groups/54257
  96. https://www.kdnuggets.com/news/subscribe.html

   hidden links:
  98. https://www.kdnuggets.com/
  99. https://www.kdnuggets.com/
