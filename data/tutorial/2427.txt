deep learning tutorial
release 0.1

lisa lab, university of montreal

september 01, 2015

1 license

2 deep learning tutorials

contents

1

3

3 getting started
. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
3.1 download .
. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
3.2 datasets .
.
3.3 notation .
. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
3.4 a primer on supervised optimization for deep learning . . . . . . . . . . . . . . . . . . .
3.5

. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .

theano/python tips

5
5
5
7
8
. 14

.
.
.

.
.
.

.
.
.

.
.
.

.
.
.

.
.
.

.
.
.

.
.
.

.
.
.

.

.

.

.

.

.

.

.

.

.

.

.

the model

4 classifying mnist digits using id28

17
. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 17
. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 18
. 19
creating a logisticregression class . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 22
.
learning the model
.
. 23
testing the model
.
putting it all together .
. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 24
prediction using a trained model . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 34

4.1
.
4.2 de   ning a id168 .
4.3
4.4
4.5
4.6
4.7

. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .

.
.
.

.
.
.

.
.

.
.

.

the model

5 multilayer id88
.

35
. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 35
. 36
putting it all together .
. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 40
tips and tricks for training mlps . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 48

5.1
5.2 going from id28 to mlp . . . . . . . . . . . . . . . . . . . . . . . . . . .
5.3
5.4

.

.

.

.

.

.

.

.

.

.

6 convolutional neural networks (lenet)

.

.

.

.

.

.

.
.
.
.

.
.
.
.

.
6.1 motivation .
sparse connectivity .
6.2
shared weights .
.
6.3
6.4 details and notation .
6.5
6.6 maxpooling .
6.7
6.8
6.9

.
.
.
.
the convolution operator .
.
.
.
.

.
the full model: lenet .
putting it all together .
running the code .
.

.
.
.
.

.

.

.

.

.

. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .

51
. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 51
.
. 52
. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 52
. 53
.
.
. 54
. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 56
.
. 57
. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 58
. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 62

. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .

. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .

i

6.10 tips and tricks .

.

.

.

.

.

7 denoising autoencoders (da)
.

7.1 autoencoders .
.
7.2 denoising autoencoders .
.
7.3
7.4
.

putting it all together .
running the code .
.

.

.

.

.

.

.

.
.
.
.

. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 63

65
.
. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 65
. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 72
. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 77
.
.
. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 78

.
.
.
.

8 stacked denoising autoencoders (sda)

8.1
8.2
8.3
8.4

stacked autoencoders .
.
putting it all together .
running the code .
.
.
.
.
.
tips and tricks .

.

.
.
.
.

.
.
.
.

81
. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 81
. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 87
.
.
. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 88
. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 89

.
.

9 restricted id82s (rbm)

91
. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 91
energy-based models (ebm)
restricted id82s (rbm) . . . . . . . . . . . . . . . . . . . . . . . . . . . . 93
. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 94
sampling in an rbm .
. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 95
.
.
implementation .
results .
.
.
.
. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 106

.
.
.

.
.
.

.
.
.

.
.

.
.

.
.

.

.

.

9.1
9.2
9.3
9.4
9.5

.

10 id50

109
10.1 id50 .
. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 109
10.2 justifying greedy-layer wise pre-training . . . . . . . . . . . . . . . . . . . . . . . . . . 110
. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 111
10.3 implementation .
.
.
. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 116
10.4 putting it all together .
.
.
.
10.5 running the code .
. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 117
10.6 tips and tricks .
.
.
. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 118

.
.
.
.

.
.
.
.

.
.
.
.

.
.
.

.

.

.

.

.

.

11 hybrid monte-carlo sampling
.

119
. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 119
11.1 theory .
11.2 implementing hmc using theano . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 121
. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 130
11.3 testing our sampler
11.4 references .
.
. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 132

.
.

.
.

.
.

.
.

.

.

.

.

.

.

.

.

.

.

.

.

.

.

12 recurrent neural networks with id27s

.

.

.

.

.

.

.
.

.
.

.
.
.
.

12.1 summary .
.
.
12.2 code - citations - contact
.
12.3 task .
.
.
12.4 dataset
.
.
12.5 recurrent neural network model
12.6 evaluation .
.
12.7 training .
.
.
12.8 running the code .

.
.
.

.
.
.

.
.
.

.
.
.

.
.

.
.

.
.

.
.

.
.

.
.

.
.

.
.

.
.

.
.

133
. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 133
. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 133
.
. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 134
. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 134
.
. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 135
. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 139
. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 140
. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 140

.
.
.

.
.
.

13 id137 for id31

13.1 summary .
.
13.2 data .
.
13.3 model .
.

.
.

.
.
.

.
.
.

.
.
.

.
.
.

.
.
.

.
.
.

.
.
.

.
.
.

.
.
.

ii

143
. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 143
. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 143
.
. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 143

.

13.4 code - citations - contact
.
.
13.5 references .

.

.

.

.

.

.
.

. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 145
. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 148

14 modeling and generating sequences of polyphonic music with the id56-rbm

.
14.1 the id56-rbm .
.
.
14.2 implementation .
14.3 results .
.
.
.
14.4 how to improve this code .

.
.
.

.
.
.

.
.
.

.
.
.

.

.

.

.
.
.
.

.
.
.
.

149
. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 149
. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 150
. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 155
. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 157

15 miscellaneous

159
15.1 plotting samples and filters . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 159

16 references

bibliography

index

163

165

167

iii

iv

chapter
one

license

copyright (c) 2008   2013, theano development team all rights reserved.

redistribution and use in source and binary forms, with or without modi   cation, are permitted provided that
the following conditions are met:

    redistributions of source code must retain the above copyright notice, this list of conditions and the

following disclaimer.

    redistributions in binary form must reproduce the above copyright notice, this list of conditions and
the following disclaimer in the documentation and/or other materials provided with the distribution.

    neither the name of theano nor the names of its contributors may be used to endorse or promote

products derived from this software without speci   c prior written permission.

this software is provided by the copyright holders       as is    and any express
or implied warranties, including, but not limited to, the implied warranties
of merchantability and fitness for a particular purpose are disclaimed. in
no event shall the copyright holders be liable for any direct, indirect, in-
cidental, special, exemplary, or consequential damages (including, but not
limited to, procurement of substitute goods or services; loss of use, data, or
profits; or business interruption) however caused and on any theory of lia-
bility, whether in contract, strict liability, or tort (including negligence or
otherwise) arising in any way out of the use of this software, even if advised
of the possibility of such damage.

1

deep learning tutorial, release 0.1

2

chapter 1. license

chapter
two

deep learning tutorials

deep learning is a new area of machine learning research, which has been introduced with the objective of
moving machine learning closer to one of its original goals: arti   cial intelligence. see these course notes
for a brief introduction to machine learning for ai and an introduction to deep learning algorithms.

deep learning is about learning multiple levels of representation and abstraction that help to make sense of
data such as images, sound, and text. for more about deep learning algorithms, see for example:

    the monograph or review paper learning deep architectures for ai (foundations & trends in ma-

chine learning, 2009).

    the icml 2009 workshop on learning feature hierarchies webpage has a list of references.

    the lisa public wiki has a reading list and a bibliography.

    geoff hinton has readings from 2009   s nips tutorial.

the tutorials presented here will introduce you to some of the most important deep learning algorithms and
will also show you how to run them using theano. theano is a python library that makes writing deep
learning models easy, and gives the option of training them on a gpu.

the algorithm tutorials have some prerequisites. you should know some python, and be familiar with
numpy. since this tutorial is about using theano, you should read over the theano basic tutorial    rst. once
you   ve done that, read through our getting started chapter     it introduces the notation, and [downloadable]
datasets used in the algorithm tutorials, and the way we do optimization by stochastic id119.

the purely supervised learning algorithms are meant to be read in order:

1. id28 - using theano for something simple

2. multilayer id88 - introduction to layers

3. deep convolutional network - a simpli   ed version of lenet5

the unsupervised and semi-supervised learning algorithms can be read in any order (the auto-encoders can
be read independently of the rbm/dbn thread):

    auto encoders, denoising autoencoders - description of autoencoders

    stacked denoising auto-encoders - easy steps into unsupervised pre-training for deep nets

    restricted id82s - single layer generative rbm model

    id50 - unsupervised generative pre-training of stacked rbms followed by supervised

   ne-tuning

3

deep learning tutorial, release 0.1

building towards including the mcrbm model, we have a new tutorial on sampling from energy models:

    hmc sampling - hybrid (aka hamiltonian) monte-carlo sampling with scan()

building towards including the contractive auto-encoders tutorial, we have the code for now:

    contractive auto-encoders code - there is some basic doc in the code.

recurrent neural networks with id27s and context window:

    id29 of speech using recurrent net

lstm network for id31:

    lstm network

energy-based recurrent neural network (id56-rbm):

    modeling and generating sequences of polyphonic music

4

chapter 2. deep learning tutorials

chapter
three

getting started

these tutorials do not attempt to make up for a graduate or undergraduate course in machine learning, but
we do make a rapid overview of some important concepts (and notation) to make sure that we   re on the same
page. you   ll also need to download the datasets mentioned in this chapter in order to run the example code
of the up-coming tutorials.

3.1 download

on each learning algorithm page, you will be able to download the corresponding    les. if you want to
download all of them at the same time, you can clone the git repository of the tutorial:

git clone https://github.com/lisa-lab/deeplearningtutorials.git

3.2 datasets

3.2.1 mnist dataset

(mnist.pkl.gz)

the mnist dataset consists of handwritten digit images and it is divided in 60,000 examples
for the training set and 10,000 examples for testing. in many papers as well as in this tutorial,
the of   cial training set of 60,000 is divided into an actual training set of 50,000 examples and
10,000 validation examples (for selecting hyper-parameters like learning rate and size of the
model). all digit images have been size-normalized and centered in a    xed size image of 28 x
28 pixels. in the original dataset each pixel of the image is represented by a value between 0
and 255, where 0 is black, 255 is white and anything in between is a different shade of grey.

here are some examples of mnist digits:

for convenience we pickled the dataset to make it easier to use in python. it is available for
download here. the pickled    le represents a tuple of 3 lists : the training set, the validation
set and the testing set. each of the three lists is a pair formed from a list of images and a list
of class labels for each of the images. an image is represented as numpy 1-dimensional array

5

deep learning tutorial, release 0.1

of 784 (28 x 28)    oat values between 0 and 1 (0 stands for black, 1 for white). the labels are
numbers between 0 and 9 indicating which digit the image represents. the code block below
shows how to load the dataset.

import cpickle, gzip, numpy

# load the dataset
f = gzip.open(   mnist.pkl.gz   ,    rb   )
train_set, valid_set, test_set = cpickle.load(f)
f.close()

when using the dataset, we usually divide it in minibatches (see stochastic id119).
we encourage you to store the dataset into shared variables and access it based on the minibatch
index, given a    xed and known batch size. the reason behind shared variables is related to using
the gpu. there is a large overhead when copying data into the gpu memory. if you would
copy data on request ( each minibatch individually when needed) as the code will do if you do
not use shared variables, due to this overhead, the gpu code will not be much faster then the
cpu code (maybe even slower). if you have your data in theano shared variables though, you
give theano the possibility to copy the entire data on the gpu in a single call when the shared
variables are constructed. afterwards the gpu can access any minibatch by taking a slice
from this shared variables, without needing to copy any information from the cpu memory
and therefore bypassing the overhead. because the datapoints and their labels are usually of
different nature (labels are usually integers while datapoints are real numbers) we suggest to
use different variables for label and data. also we recommend using different variables for
the training set, validation set and testing set to make the code more readable (resulting in 6
different shared variables).

since now the data is in one variable, and a minibatch is de   ned as a slice of that variable, it
comes more natural to de   ne a minibatch by indicating its index and its size. in our setup the
batch size stays constant throughout the execution of the code, therefore a function will actually
require only the index to identify on which datapoints to work. the code below shows how to
store your data and how to access a minibatch:

def shared_dataset(data_xy):

""" function that loads the dataset into shared variables

the reason we store our dataset in shared variables is to allow
theano to copy it into the gpu memory (when code is run on gpu).
since copying data into the gpu is slow, copying a minibatch everytime
is needed (the default behaviour if the data is not in a shared
variable) would lead to a large decrease in performance.
"""
data_x, data_y = data_xy
shared_x = theano.shared(numpy.asarray(data_x, dtype=theano.config.floatx))
shared_y = theano.shared(numpy.asarray(data_y, dtype=theano.config.floatx))
# when storing data on the gpu it has to be stored as floats
# therefore we will store the labels as       floatx       as well
# (      shared_y       does exactly that). but during our computations
# we need them as ints (we use labels as index, and if they are
# floats it doesn   t make sense) therefore instead of returning
#       shared_y       we will have to cast it to int. this little hack
# lets us get around this issue

6

chapter 3. getting started

deep learning tutorial, release 0.1

return shared_x, t.cast(shared_y,    int32   )

test_set_x, test_set_y = shared_dataset(test_set)
valid_set_x, valid_set_y = shared_dataset(valid_set)
train_set_x, train_set_y = shared_dataset(train_set)

batch_size = 500

# size of the minibatch

# accessing the third minibatch of the training set

data = train_set_x[2 * batch_size: 3 * batch_size]
label = train_set_y[2 * batch_size: 3 * batch_size]

the data has to be stored as    oats on the gpu ( the right dtype for storing on the gpu is given by
theano.config.floatx). to get around this shortcomming for the labels, we store them as    oat, and
then cast it to int.

note: if you are running your code on the gpu and the dataset you are using is too large to    t in memory
the code will crash. in such a case you should store the data in a shared variable. you can however store a
suf   ciently small chunk of your data (several minibatches) in a shared variable and use that during training.
once you got through the chunk, update the values it stores. this way you minimize the number of data
transfers between cpu memory and gpu memory.

3.3 notation

3.3.1 dataset notation
we label data sets as d. when the distinction is important, we indicate train, validation, and test sets as:
dtrain, dvalid and dtest. the validation set is used to perform model selection and hyper-parameter selec-
tion, whereas the test set is used to evaluate the    nal generalization error and compare different algorithms
in an unbiased way.
the tutorials mostly deal with classi   cation problems, where each data set d is an indexed set of pairs
(x(i), y(i)). we use superscripts to distinguish training set examples: x(i)     rd is thus the i-th training
example of dimensionality d. similarly, y(i)     {0, ..., l} is the i-th label assigned to input x(i).
it is
straightforward to extend these examples to ones where y(i) has other types (e.g. gaussian for regression,
or groups of multinomials for predicting multiple symbols).

3.3.2 math conventions

    w : upper-case symbols refer to a matrix unless speci   ed otherwise

    wij: element at i-th row and j-th column of matrix w
    wi  , wi: vector, i-th row of matrix w
    w  j: vector, j-th column of matrix w

3.3. notation

7

deep learning tutorial, release 0.1

    b: lower-case symbols refer to a vector unless speci   ed otherwise

    bi: i-th element of vector b

3.3.3 list of symbols and acronyms

    d: number of input dimensions.

h : number of hidden units in the i-th layer.

    d(i)
    f  (x), f(x): classi   cation function associated with a model p (y |x,   ), de   ned as argmaxkp (y =
k|x,   ). note that we will often drop the    subscript.
    l: number of labels.
    l(  ,d): log-likelihood d of the model de   ned by parameters   .
    (cid:96)(  ,d) empirical loss of the prediction function f parameterized by    on data set d.
    nll: negative log-likelihood

      : set of all parameters for a given model

3.3.4 python namespaces

tutorial code often uses the following namespaces:

import theano
import theano.tensor as t
import numpy

3.4 a primer on supervised optimization for deep learning

what   s exciting about deep learning is largely the use of unsupervised learning of deep networks. but
supervised learning also plays an important role. the utility of unsupervised pre-training is often evaluated
on the basis of what performance can be achieved after supervised    ne-tuning. this chapter reviews the
basics of supervised learning for classi   cation models, and covers the minibatch stochastic id119
algorithm that is used to    ne-tune many of the models in the deep learning tutorials. have a look at these
introductory course notes on gradient-based learning for more basics on the notion of optimizing a training
criterion using the gradient.

3.4.1 learning a classi   er

zero-one loss

the models presented in these deep learning tutorials are mostly used for classi   cation. the objective in
training a classi   er is to minimize the number of errors (zero-one loss) on unseen examples. if f : rd    

8

chapter 3. getting started

{0, ..., l} is the prediction function, then this loss can be written as:

deep learning tutorial, release 0.1

(cid:96)0,1 =

if (x(i))(cid:54)=y(i)

|d|(cid:88)

i=0

(cid:26) 1

0

where either d is the training set (during training) or d     dtrain =     (to avoid biasing the evaluation of
validation or test error). i is the indicator function de   ned as:

ix =

in this tutorial, f is de   ned as:

if x is true
otherwise

f(x) = argmaxkp (y = k|x,   )

in python, using theano this can be written as :

# zero_one_loss is a theano variable representing a symbolic
# expression of the zero one loss ; to get the actual value this
# symbolic expression has to be compiled into a theano function (see
# the theano tutorial for more details)
zero_one_loss = t.sum(t.neq(t.argmax(p_y_given_x), y))

negative log-likelihood loss

|d|(cid:88)

i=0

|d|(cid:88)

since the zero-one loss is not differentiable, optimizing it for large models (thousands or millions of param-
eters) is prohibitively expensive (computationally). we thus maximize the log-likelihood of our classi   er
given all the labels in a training set.

l(  ,d) =

log p (y = y(i)|x(i),   )

the likelihood of the correct class is not the same as the number of right predictions, but from the point of
view of a randomly initialized classi   er they are pretty similar. remember that likelihood and zero-one loss
are different objectives; you should see that they are corralated on the validation set but sometimes one will
rise while the other falls, or vice-versa.
since we usually speak in terms of minimizing a id168, learning will thus attempt to minimize the
negative log-likelihood (nll), de   ned as:

n ll(  ,d) =    

log p (y = y(i)|x(i),   )

the nll of our classi   er is a differentiable surrogate for the zero-one loss, and we use the gradient of this
function over our training data as a supervised learning signal for deep learning of a classi   er.

this can be computed using the following line of code :

i=0

3.4. a primer on supervised optimization for deep learning

9

deep learning tutorial, release 0.1

# nll is a symbolic variable ; to get the actual value of nll, this symbolic
# expression has to be compiled into a theano function (see the theano
# tutorial for more details)
nll = -t.sum(t.log(p_y_given_x)[t.arange(y.shape[0]), y])
# note on syntax: t.arange(y.shape[0]) is a vector of integers [0,1,2,...,len(y)].
# indexing a matrix m by the two vectors [0,1,...,k], [a,b,...,k] returns the
# elements m[0,a], m[1,b], ..., m[k,k] as a vector.
# syntax to retrieve the log-id203 of the correct labels, y.

here, we use this

3.4.2 stochastic id119

what is ordinary id119? it is a simple algorithm in which we repeatedly make small steps down-
ward on an error surface de   ned by a id168 of some parameters. for the purpose of ordinary gradient
descent we consider that the training data is rolled into the id168. then the pseudocode of this algo-
rithm can be described as :

# id119

while true:

loss = f(params)
d_loss_wrt_params = ... # compute gradient
params -= learning_rate * d_loss_wrt_params
if <stopping condition is met>:

return params

stochastic id119 (sgd) works according to the same principles as ordinary id119, but
proceeds more quickly by estimating the gradient from just a few examples at a time instead of the entire
training set. in its purest form, we estimate the gradient from just a single example at a time.

# stochastic id119
for (x_i,y_i) in training_set:

# imagine an infinite generator
# that may repeat examples (if there is only a finite training set)

loss = f(params, x_i, y_i)
d_loss_wrt_params = ... # compute gradient
params -= learning_rate * d_loss_wrt_params
if <stopping condition is met>:

return params

the variant that we recommend for deep learning is a further twist on stochastic id119 using so-
called    minibatches   . minibatch sgd works identically to sgd, except that we use more than one training
example to make each estimate of the gradient. this technique reduces variance in the estimate of the
gradient, and often makes better use of the hierarchical memory organization in modern computers.

for (x_batch,y_batch) in train_batches:

# imagine an infinite generator
# that may repeat examples

loss = f(params, x_batch, y_batch)
d_loss_wrt_params = ... # compute gradient using theano
params -= learning_rate * d_loss_wrt_params

10

chapter 3. getting started

deep learning tutorial, release 0.1

if <stopping condition is met>:

return params

there is a tradeoff in the choice of the minibatch size b. the reduction of variance and use of simd
instructions helps most when increasing b from 1 to 2, but the marginal improvement fades rapidly to
nothing. with large b, time is wasted in reducing the variance of the gradient estimator, that time would be
better spent on additional gradient steps. an optimal b is model-, dataset-, and hardware-dependent, and
can be anywhere from 1 to maybe several hundreds. in the tutorial we set it to 20, but this choice is almost
arbitrary (though harid113ss).

note:
if you are training for a    xed number of epochs, the minibatch size becomes important because it
controls the number of updates done to your parameters. training the same model for 10 epochs using a
batch size of 1 yields completely different results compared to training for the same 10 epochs but with a
batchsize of 20. keep this in mind when switching between batch sizes and be prepared to tweak all the
other parameters acording to the batch size used.

all code-blocks above show pseudocode of how the algorithm looks like. implementing such algorithm in
theano can be done as follows :

# minibatch stochastic id119

# assume loss is a symbolic description of the id168 given
# the symbolic variables params (shared variable), x_batch, y_batch;

# compute gradient of loss with respect to params
d_loss_wrt_params = t.grad(loss, params)

# compile the msgd step into a theano function
updates = [(params, params - learning_rate * d_loss_wrt_params)]
msgd = theano.function([x_batch,y_batch], loss, updates=updates)

for (x_batch, y_batch) in train_batches:

# here x_batch and y_batch are elements of train_batches and
# therefore numpy arrays; function msgd also updates the params
print(   current loss is    , msgd(x_batch, y_batch))
if stopping_condition_is_met:

return params

3.4.3 id173

there is more to machine learning than optimization. when we train our model from data we are trying
to prepare it to do well on new examples, not the ones it has already seen. the training loop above for
msgd does not take this into account, and may over   t the training examples. a way to combat over   tting
is through id173. there are several techniques for id173; the ones we will explain here are
l1/l2 id173 and early-stopping.

3.4. a primer on supervised optimization for deep learning

11

deep learning tutorial, release 0.1

l1 and l2 id173

l1 and l2 id173 involve adding an extra term to the id168, which penalizes certain parameter
con   gurations. formally, if our id168 is:

|d|(cid:88)

n ll(  ,d) =    

log p (y = y(i)|x(i),   )

then the regularized loss will be:

i=0

e(  ,d) = n ll(  ,d) +   r(  )

or, in our case

where

e(  ,d) = n ll(  ,d) +   ||  ||p

p

       |  |(cid:88)

       1

p

||  ||p =

|  j|p

j=0

which is the lp norm of   .    is a hyper-parameter which controls the relative importance of the id173
parameter. commonly used values for p are 1 and 2, hence the l1/l2 nomenclature.
if p=2, then the
regularizer is also called    weight decay   .

in principle, adding a id173 term to the loss will encourage smooth network mappings in a neural
network (by penalizing large values of the parameters, which decreases the amount of nonlinearity that
the network models). more intuitively, the two terms (nll and r(  )) correspond to modelling the data
well (nll) and having    simple    or    smooth    solutions (r(  )). thus, minimizing the sum of both will, in
theory, correspond to    nding the right trade-off between the    t to the training data and the    generality    of
the solution that is found. to follow occam   s razor principle, this minimization should    nd us the simplest
solution (as measured by our simplicity criterion) that    ts the training data.

note that the fact that a solution is    simple    does not mean that it will generalize well. empirically, it
was found that performing such id173 in the context of neural networks helps with generalization,
especially on small datasets. the code block below shows how to compute the loss in python when it
contains both a l1 id173 term weighted by   1 and l2 id173 term weighted by   2

# symbolic theano variable that represents the l1 id173 term
l1

= t.sum(abs(param))

# symbolic theano variable that represents the squared l2 term
l2_sqr = t.sum(param ** 2)

# the loss
loss = nll + lambda_1 * l1 + lambda_2 * l2

early-stopping

early-stopping combats over   tting by monitoring the model   s performance on a validation set. a validation
set is a set of examples that we never use for id119, but which is also not a part of the test set. the

12

chapter 3. getting started

deep learning tutorial, release 0.1

validation examples are considered to be representative of future test examples. we can use them during
training because they are not part of the test set. if the model   s performance ceases to improve suf   ciently
on the validation set, or even degrades with further optimization, then the heuristic implemented here gives
up on much further optimization.

the choice of when to stop is a judgement call and a few heuristics exist, but these tutorials will make use
of a strategy based on a geometrically increasing amount of patience.

# early-stopping parameters
patience = 5000
patience_increase = 2

# look as this many examples regardless

# wait this much longer when a new best is

improvement_threshold = 0.995

# a relative improvement of this much is
# considered significant
validation_frequency = min(n_train_batches, patience/2)

# found

# go through this many
# minibatches before checking the network
# on the validation set; in this case we
# check every epoch

best_params = none
best_validation_loss = numpy.inf
test_score = 0.
start_time = time.clock()

done_looping = false
epoch = 0
while (epoch < n_epochs) and (not done_looping):

# report "1" for first epoch, "n_epochs" for last epoch
epoch = epoch + 1
for minibatch_index in xrange(n_train_batches):

d_loss_wrt_params = ... # compute gradient
params -= learning_rate * d_loss_wrt_params # id119

# iteration number. we want it to start at 0.
iter = (epoch - 1) * n_train_batches + minibatch_index
# note that if we do    iter % validation_frequency    it will be
# true for iter = 0 which we do not want. we want it true for
# iter = validation_frequency - 1.
if (iter + 1) % validation_frequency == 0:

this_validation_loss = ... # compute zero-one loss on validation set

if this_validation_loss < best_validation_loss:

# improve patience if loss improvement is good enough
if this_validation_loss < best_validation_loss * improvement_threshold:

patience = max(patience, iter * patience_increase)

best_params = copy.deepcopy(params)
best_validation_loss = this_validation_loss

if patience <= iter:

3.4. a primer on supervised optimization for deep learning

13

deep learning tutorial, release 0.1

done_looping = true
break

# postcondition:
# best_params refers to the best out-of-sample parameters observed during the optimization

if we run out of batches of training data before running out of patience, then we just go back to the beginning
of the training set and repeat.

note: the validation_frequency should always be smaller than the patience. the code should
check at least two times how it performs before running out of patience. this is the reason we used the
formulation validation_frequency = min( value, patience/2.)

note: this algorithm could possibly be improved by using a test of statistical signi   cance rather than the
simple comparison, when deciding whether to increase the patience.

3.4.4 testing

after the loop exits, the best_params variable refers to the best-performing model on the validation set. if
we repeat this procedure for another model class, or even another random initialization, we should use the
same train/valid/test split of the data, and get other best-performing models. if we have to choose what the
best model class or the best initialization was, we compare the best_validation_loss for each model. when
we have    nally chosen the model we think is the best (on validation data), we report that model   s test set
performance. that is the performance we expect on unseen examples.

3.4.5 recap

that   s it for the optimization section. the technique of early-stopping requires us to partition the set of
examples into three sets (training dtrain, validation dvalid, test dtest). the training set is used for minibatch
stochastic id119 on the differentiable approximation of the objective function. as we perform
this id119, we periodically consult the validation set to see how our model is doing on the real
objective function (or at least our empirical estimate of it). when we see a good model on the validation set,
we save it. when it has been a long time since seeing a good model, we abandon our search and return the
best parameters found, for evaluation on the test set.

3.5 theano/python tips

3.5.1 loading and saving models

when you   re doing experiments, it can take hours (sometimes days!) for gradient-descent to    nd the best
parameters. you will want to save those weights once you    nd them. you may also want to save your
current-best estimates as the search progresses.
pickle the numpy ndarrays from your shared variables

14

chapter 3. getting started

deep learning tutorial, release 0.1

the best way to save/archive your model   s parameters is to use pickle or deepcopy the ndarray objects. so
for example, if your parameters are in shared variables w, v, u, then your save command should look
something like:

>>> import cpickle
>>> save_file = open(   path   ,    wb   )
>>> cpickle.dump(w.get_value(borrow=true), save_file, -1)
>>> cpickle.dump(v.get_value(borrow=true), save_file, -1)
>>> cpickle.dump(u.get_value(borrow=true), save_file, -1)
>>> save_file.close()

# this will overwrite current contents

# the -1 is for highest_protocol
# .. and it triggers much more efficient
# .. storage than numpy   s default

then later, you can load your data back like this:

>>> save_file = open(   path   )
>>> w.set_value(cpickle.load(save_file), borrow=true)
>>> v.set_value(cpickle.load(save_file), borrow=true)
>>> u.set_value(cpickle.load(save_file), borrow=true)

this technique is a bit verbose, but it is tried and true. you will be able to load your data and render it in
matplotlib without trouble, years after saving it.
do not pickle your training or test functions for long-term storage

theano functions are compatible with python   s deepcopy and pickle mechanisms, but you should not nec-
essarily pickle a theano function. if you update your theano folder and one of the internal changes, then
you may not be able to un-pickle your model. theano is still in active development, and the internal apis
are subject to change. so to be on the safe side     do not pickle your entire training or testing functions for
long-term storage. the pickle mechanism is aimed at for short-term storage, such as a temp    le, or a copy
to another machine in a distributed job.

read more about serialization in theano, or python   s pickling.

3.5.2 plotting intermediate results

visualizations can be very powerful tools for understanding what your model or training algorithm is doing.
you might be tempted to insert matplotlib plotting commands, or pil image-rendering commands
into your model-training script. however, later you will observe something interesting in one of those pre-
rendered images and want to investigate something that isn   t clear from the pictures. you   ll wished you had
saved the original model.
if you have enough disk space, your training script should save intermediate models and a visualiza-
tion script should process those saved models.

you already have a model-saving function right? just use it again to save these intermediate models.

libraries you   ll want to know about: python image library (pil), matplotlib.

3.5. theano/python tips

15

deep learning tutorial, release 0.1

16

chapter 3. getting started

chapter
four

classifying mnist digits using id28

note: this sections assumes familiarity with the following theano concepts: shared variables , basic
arithmetic ops , t.grad ,    oatx. if you intend to run the code on gpu also read gpu.

note: the code for this section is available for download here.

in this section, we show how theano can be used to implement the most basic classi   er: the logistic regres-
sion. we start off with a quick primer of the model, which serves both as a refresher but also to anchor the
notation and show how mathematical expressions are mapped onto theano graphs.

in the deepest of machine learning traditions, this tutorial will tackle the exciting problem of mnist digit
classi   cation.

4.1 the model

id28 is a probabilistic, linear classi   er. it is parametrized by a weight matrix w and a bias
vector b. classi   cation is done by projecting an input vector onto a set of hyperplanes, each of which
corresponds to a class. the distance from the input to a hyperplane re   ects the id203 that the input is
a member of the corresponding class.

mathematically, the id203 that an input vector x is a member of a class i, a value of a stochastic variable
y , can be written as:

p (y = i|x, w, b) = sof tmaxi(w x + b)

(cid:80)

= ewix+bi
j ewj x+bj

the model   s prediction ypred is the class whose id203 is maximal, speci   cally:

ypred = argmaxip (y = i|x, w, b)

the code to do this in theano is the following:

17

deep learning tutorial, release 0.1

# initialize with 0 the weights w as a matrix of shape (n_in, n_out)
self.w = theano.shared(

value=numpy.zeros(
(n_in, n_out),
dtype=theano.config.floatx

),
name=   w   ,
borrow=true

)
# initialize the biases b as a vector of n_out 0s
self.b = theano.shared(

value=numpy.zeros(

(n_out,),
dtype=theano.config.floatx

),
name=   b   ,
borrow=true

)

# symbolic expression for computing the matrix of class-membership
# probabilities
# where:
# w is a matrix where column-k represent the separation hyperplane for
# class-k
# x is a matrix where row-j
represents input training sample-j
# b is a vector where element-k represent the free parameter of
# hyperplane-k
self.p_y_given_x = t.nnet.softmax(t.dot(input, self.w) + self.b)

# symbolic description of how to compute prediction as class whose
# id203 is maximal
self.y_pred = t.argmax(self.p_y_given_x, axis=1)

since the parameters of the model must maintain a persistent state throughout training, we allocate shared
variables for w, b. this declares them both as being symbolic theano variables, but also initializes their
contents. the dot and softmax operators are then used to compute the vector p (y |x, w, b). the result
p_y_given_x is a symbolic variable of vector-type.

to get the actual model prediction, we can use the t.argmax operator, which will return the index at which
p_y_given_x is maximal (i.e. the class with maximum id203).

now of course, the model we have de   ned so far does not do anything useful yet, since its parameters are
still in their initial state. the following section will thus cover how to learn the optimal parameters.

note: for a complete list of theano ops, see: list of ops

4.2 de   ning a id168

learning optimal model parameters involves minimizing a id168. in the case of multi-class logistic
regression, it is very common to use the negative log-likelihood as the loss. this is equivalent to maximizing

18

chapter 4. classifying mnist digits using id28

deep learning tutorial, release 0.1

the likelihood of the data set d under the model parameterized by   . let us    rst start by de   ning the
likelihood l and loss (cid:96):

|d|(cid:88)

l(   = {w, b},d) =

log(p (y = y(i)|x(i), w, b))
(cid:96)(   = {w, b},d) =    l(   = {w, b},d)

i=0

while entire books are dedicated to the topic of minimization, id119 is by far the simplest method
for minimizing arbitrary non-linear functions. this tutorial will use the method of stochastic gradient method
with mini-batches (msgd). see stochastic id119 for more details.

the following theano code de   nes the (symbolic) loss for a given minibatch:

# y.shape[0] is (symbolically) the number of rows in y, i.e.,
# number of examples (call it n) in the minibatch
# t.arange(y.shape[0]) is a symbolic vector which will contain
# [0,1,2,... n-1] t.log(self.p_y_given_x) is a matrix of
# log-probabilities (call it lp) with one row per example and
# one column per class lp[t.arange(y.shape[0]),y] is a vector
# v containing [lp[0,y[0]], lp[1,y[1]], lp[2,y[2]], ...,
# lp[n-1,y[n-1]]] and t.mean(lp[t.arange(y.shape[0]),y]) is
# the mean (across minibatch examples) of the elements in v,
# i.e., the mean log-likelihood across the minibatch.
return -t.mean(t.log(self.p_y_given_x)[t.arange(y.shape[0]), y])

note: even though the loss is formally de   ned as the sum, over the data set, of individual error terms,
in practice, we use the mean (t.mean) in the code. this allows for the learning rate choice to be less
dependent of the minibatch size.

4.3 creating a logisticregression class

we now have all the tools we need to de   ne a logisticregression class, which encapsulates the basic
behaviour of id28. the code is very similar to what we have covered so far, and should be self
explanatory.

class logisticregression(object):

"""multi-class id28 class

the id28 is fully described by a weight matrix :math:   w   
and bias vector :math:   b   . classification is done by projecting data
points onto a set of hyperplanes, the distance to which is used to
determine a class membership id203.
"""

def __init__(self, input, n_in, n_out):

""" initialize the parameters of the id28

:type input: theano.tensor.tensortype
:param input: symbolic variable that describes the input of the

4.3. creating a logisticregression class

19

deep learning tutorial, release 0.1

architecture (one minibatch)

:type n_in: int
:param n_in: number of input units, the dimension of the space in

which the datapoints lie

:type n_out: int
:param n_out: number of output units, the dimension of the space in

which the labels lie

"""
# start-snippet-1
# initialize with 0 the weights w as a matrix of shape (n_in, n_out)
self.w = theano.shared(

value=numpy.zeros(
(n_in, n_out),
dtype=theano.config.floatx

),
name=   w   ,
borrow=true

)
# initialize the biases b as a vector of n_out 0s
self.b = theano.shared(

value=numpy.zeros(

(n_out,),
dtype=theano.config.floatx

),
name=   b   ,
borrow=true

)

# symbolic expression for computing the matrix of class-membership
# probabilities
# where:
# w is a matrix where column-k represent the separation hyperplane for
# class-k
# x is a matrix where row-j
represents input training sample-j
# b is a vector where element-k represent the free parameter of
# hyperplane-k
self.p_y_given_x = t.nnet.softmax(t.dot(input, self.w) + self.b)

# symbolic description of how to compute prediction as class whose
# id203 is maximal
self.y_pred = t.argmax(self.p_y_given_x, axis=1)
# end-snippet-1

# parameters of the model
self.params = [self.w, self.b]

# keep track of model input
self.input = input

def negative_log_likelihood(self, y):

20

chapter 4. classifying mnist digits using id28

deep learning tutorial, release 0.1

"""return the mean of the negative log-likelihood of the prediction
of this model under a given target distribution.

.. math::

\frac{1}{|\mathcal{d}|} \mathcal{l} (\theta=\{w,b\}, \mathcal{d}) =
\frac{1}{|\mathcal{d}|} \sum_{i=0}^{|\mathcal{d}|}

\log(p(y=y^{(i)}|x^{(i)}, w,b)) \\

\ell (\theta=\{w,b\}, \mathcal{d})

:type y: theano.tensor.tensortype
:param y: corresponds to a vector that gives for each example the

correct label

note: we use the mean instead of the sum so that

the learning rate is less dependent on the batch size

"""
# start-snippet-2
# y.shape[0] is (symbolically) the number of rows in y, i.e.,
# number of examples (call it n) in the minibatch
# t.arange(y.shape[0]) is a symbolic vector which will contain
# [0,1,2,... n-1] t.log(self.p_y_given_x) is a matrix of
# log-probabilities (call it lp) with one row per example and
# one column per class lp[t.arange(y.shape[0]),y] is a vector
# v containing [lp[0,y[0]], lp[1,y[1]], lp[2,y[2]], ...,
# lp[n-1,y[n-1]]] and t.mean(lp[t.arange(y.shape[0]),y]) is
# the mean (across minibatch examples) of the elements in v,
# i.e., the mean log-likelihood across the minibatch.
return -t.mean(t.log(self.p_y_given_x)[t.arange(y.shape[0]), y])
# end-snippet-2

def errors(self, y):

"""return a float representing the number of errors in the minibatch
over the total number of examples of the minibatch ; zero one
loss over the size of the minibatch

:type y: theano.tensor.tensortype
:param y: corresponds to a vector that gives for each example the

correct label

"""

# check if y has same dimension of y_pred
if y.ndim != self.y_pred.ndim:

raise typeerror(

   y should have the same shape as self.y_pred   ,
(   y   , y.type,    y_pred   , self.y_pred.type)

)

# check if y is of the correct datatype
if y.dtype.startswith(   int   ):

# the t.neq operator returns a vector of 0s and 1s, where 1
# represents a mistake in prediction
return t.mean(t.neq(self.y_pred, y))

else:

4.3. creating a logisticregression class

21

deep learning tutorial, release 0.1

raise notimplementederror()

we instantiate this class as follows:

# generate symbolic variables for input (x and y represent a
# minibatch)
x = t.matrix(   x   )
y = t.ivector(   y   )

# data, presented as rasterized images

# labels, presented as 1d vector of [int] labels

# construct the id28 class
# each mnist image has size 28*28
classifier = logisticregression(input=x, n_in=28 * 28, n_out=10)

we start by allocating symbolic variables for the training inputs x and their corresponding classes y. note
that x and y are de   ned outside the scope of the logisticregression object. since the class requires
the input to build its graph, it is passed as a parameter of the __init__ function. this is useful in case you
want to connect instances of such classes to form a deep network. the output of one layer can be passed as
the input of the layer above. (this tutorial does not build a multi-layer network, but this code will be reused
in future tutorials that do.)

finally, we de   ne
classifier.negative_log_likelihood.

(symbolic) cost variable

a

to minimize,

using the

instance method

# the cost we minimize during training is the negative log likelihood of
# the model in symbolic format
cost = classifier.negative_log_likelihood(y)

note that x is an implicit symbolic input to the de   nition of cost, because the symbolic variables of
classifier were de   ned in terms of x at initialization.

4.4 learning the model

to implement msgd in most programming languages (c/c++, matlab, python), one would start by manu-
ally deriving the expressions for the gradient of the loss with respect to the parameters: in this case    (cid:96)/   w ,
and    (cid:96)/   b, this can get pretty tricky for complex models, as expressions for    (cid:96)/      can get fairly complex,
especially when taking into account problems of numerical stability.

with theano, this work is greatly simpli   ed. it performs automatic differentiation and applies certain math
transforms to improve numerical stability.

to get the gradients    (cid:96)/   w and    (cid:96)/   b in theano, simply do the following:

g_w = t.grad(cost=cost, wrt=classifier.w)
g_b = t.grad(cost=cost, wrt=classifier.b)

g_w and g_b are symbolic variables, which can be used as part of a computation graph. the function
train_model, which performs one step of id119, can then be de   ned as follows:

# specify how to update the parameters of the model as a list of
# (variable, update expression) pairs.
updates = [(classifier.w, classifier.w - learning_rate * g_w),

22

chapter 4. classifying mnist digits using id28

deep learning tutorial, release 0.1

(classifier.b, classifier.b - learning_rate * g_b)]

# compiling a theano function    train_model    that returns the cost, but in
# the same time updates the parameter of the model based on the rules
# defined in    updates   
train_model = theano.function(

inputs=[index],
outputs=cost,
updates=updates,
givens={

x: train_set_x[index * batch_size: (index + 1) * batch_size],
y: train_set_y[index * batch_size: (index + 1) * batch_size]

}

)

updates is a list of pairs. in each pair, the    rst element is the symbolic variable to be updated in the
step, and the second element is the symbolic function for calculating its new value. similarly, givens is a
dictionary whose keys are symbolic variables and whose values specify their replacements during the step.
the function train_model is then de   ned such that:

    the input is the mini-batch index index that, together with the batch size (which is not an input since

it is    xed) de   nes x with corresponding labels y

    the return value is the cost/loss associated with the x, y de   ned by the index

    on every function call, it will    rst replace x and y with the slices from the training set speci   ed by
index. then, it will evaluate the cost associated with that minibatch and apply the operations de   ned
by the updates list.

each time train_model(index) is called, it will thus compute and return the cost of a minibatch,
while also performing a step of msgd. the entire learning algorithm thus consists in looping over all
examples in the dataset, considering all the examples in one minibatch at a time, and repeatedly calling the
train_model function.

4.5 testing the model

as explained in learning a classi   er, when testing the model we are interested in the number of misclassi-
   ed examples (and not only in the likelihood). the logisticregression class therefore has an extra
instance method, which builds the symbolic graph for retrieving the number of misclassi   ed examples in
each minibatch.

the code is as follows:

def errors(self, y):

"""return a float representing the number of errors in the minibatch
over the total number of examples of the minibatch ; zero one
loss over the size of the minibatch

:type y: theano.tensor.tensortype
:param y: corresponds to a vector that gives for each example the

correct label

4.5. testing the model

23

deep learning tutorial, release 0.1

"""

# check if y has same dimension of y_pred
if y.ndim != self.y_pred.ndim:

raise typeerror(

   y should have the same shape as self.y_pred   ,
(   y   , y.type,    y_pred   , self.y_pred.type)

)

# check if y is of the correct datatype
if y.dtype.startswith(   int   ):

# the t.neq operator returns a vector of 0s and 1s, where 1
# represents a mistake in prediction
return t.mean(t.neq(self.y_pred, y))

else:

raise notimplementederror()

we then create a function test_model and a function validate_model, which we can call to retrieve
this value. as you will see shortly, validate_model is key to our early-stopping implementation (see
early-stopping). these functions take a minibatch index and compute, for the examples in that minibatch,
the number that were misclassi   ed by the model. the only difference between them is that test_model
draws its minibatches from the testing set, while validate_model draws its from the validation set.

# compiling a theano function that computes the mistakes that are made by
# the model on a minibatch
test_model = theano.function(

inputs=[index],
outputs=classifier.errors(y),
givens={

x: test_set_x[index * batch_size: (index + 1) * batch_size],
y: test_set_y[index * batch_size: (index + 1) * batch_size]

}

)

validate_model = theano.function(

inputs=[index],
outputs=classifier.errors(y),
givens={

x: valid_set_x[index * batch_size: (index + 1) * batch_size],
y: valid_set_y[index * batch_size: (index + 1) * batch_size]

}

)

4.6 putting it all together

the    nished product is as follows.

"""
this tutorial introduces id28 using theano and stochastic
id119.

id28 is a probabilistic, linear classifier. it is parametrized

24

chapter 4. classifying mnist digits using id28

deep learning tutorial, release 0.1

by a weight matrix :math:   w    and a bias vector :math:   b   . classification is
done by projecting data points onto a set of hyperplanes, the distance to
which is used to determine a class membership id203.

mathematically, this can be written as:

.. math::

p(y=i|x, w,b) &= softmax_i(w x + b) \\

&= \frac {e^{w_i x + b_i}} {\sum_j e^{w_j x + b_j}}

the output of the model or prediction is then done by taking the argmax of
the vector whose i   th element is p(y=i|x).

.. math::

y_{pred} = argmax_i p(y=i|x,w,b)

this tutorial presents a stochastic id119 optimization method
suitable for large datasets.

references:

- textbooks: "pattern recognition and machine learning" -

christopher m. bishop, section 4.3.2

"""
__docformat__ =    restructedtext en   

import cpickle
import gzip
import os
import sys
import timeit

import numpy

import theano
import theano.tensor as t

class logisticregression(object):

"""multi-class id28 class

the id28 is fully described by a weight matrix :math:   w   
and bias vector :math:   b   . classification is done by projecting data
points onto a set of hyperplanes, the distance to which is used to
determine a class membership id203.
"""

def __init__(self, input, n_in, n_out):

4.6. putting it all together

25

deep learning tutorial, release 0.1

""" initialize the parameters of the id28

:type input: theano.tensor.tensortype
:param input: symbolic variable that describes the input of the

architecture (one minibatch)

:type n_in: int
:param n_in: number of input units, the dimension of the space in

which the datapoints lie

:type n_out: int
:param n_out: number of output units, the dimension of the space in

which the labels lie

"""
# start-snippet-1
# initialize with 0 the weights w as a matrix of shape (n_in, n_out)
self.w = theano.shared(

value=numpy.zeros(
(n_in, n_out),
dtype=theano.config.floatx

),
name=   w   ,
borrow=true

)
# initialize the biases b as a vector of n_out 0s
self.b = theano.shared(

value=numpy.zeros(

(n_out,),
dtype=theano.config.floatx

),
name=   b   ,
borrow=true

)

# symbolic expression for computing the matrix of class-membership
# probabilities
# where:
# w is a matrix where column-k represent the separation hyperplane for
# class-k
# x is a matrix where row-j
represents input training sample-j
# b is a vector where element-k represent the free parameter of
# hyperplane-k
self.p_y_given_x = t.nnet.softmax(t.dot(input, self.w) + self.b)

# symbolic description of how to compute prediction as class whose
# id203 is maximal
self.y_pred = t.argmax(self.p_y_given_x, axis=1)
# end-snippet-1

# parameters of the model
self.params = [self.w, self.b]

26

chapter 4. classifying mnist digits using id28

deep learning tutorial, release 0.1

# keep track of model input
self.input = input

def negative_log_likelihood(self, y):

"""return the mean of the negative log-likelihood of the prediction
of this model under a given target distribution.

.. math::

\frac{1}{|\mathcal{d}|} \mathcal{l} (\theta=\{w,b\}, \mathcal{d}) =
\frac{1}{|\mathcal{d}|} \sum_{i=0}^{|\mathcal{d}|}

\log(p(y=y^{(i)}|x^{(i)}, w,b)) \\

\ell (\theta=\{w,b\}, \mathcal{d})

:type y: theano.tensor.tensortype
:param y: corresponds to a vector that gives for each example the

correct label

note: we use the mean instead of the sum so that

the learning rate is less dependent on the batch size

"""
# start-snippet-2
# y.shape[0] is (symbolically) the number of rows in y, i.e.,
# number of examples (call it n) in the minibatch
# t.arange(y.shape[0]) is a symbolic vector which will contain
# [0,1,2,... n-1] t.log(self.p_y_given_x) is a matrix of
# log-probabilities (call it lp) with one row per example and
# one column per class lp[t.arange(y.shape[0]),y] is a vector
# v containing [lp[0,y[0]], lp[1,y[1]], lp[2,y[2]], ...,
# lp[n-1,y[n-1]]] and t.mean(lp[t.arange(y.shape[0]),y]) is
# the mean (across minibatch examples) of the elements in v,
# i.e., the mean log-likelihood across the minibatch.
return -t.mean(t.log(self.p_y_given_x)[t.arange(y.shape[0]), y])
# end-snippet-2

def errors(self, y):

"""return a float representing the number of errors in the minibatch
over the total number of examples of the minibatch ; zero one
loss over the size of the minibatch

:type y: theano.tensor.tensortype
:param y: corresponds to a vector that gives for each example the

correct label

"""

# check if y has same dimension of y_pred
if y.ndim != self.y_pred.ndim:

raise typeerror(

   y should have the same shape as self.y_pred   ,
(   y   , y.type,    y_pred   , self.y_pred.type)

)

# check if y is of the correct datatype
if y.dtype.startswith(   int   ):

4.6. putting it all together

27

deep learning tutorial, release 0.1

# the t.neq operator returns a vector of 0s and 1s, where 1
# represents a mistake in prediction
return t.mean(t.neq(self.y_pred, y))

else:

raise notimplementederror()

def load_data(dataset):

          loads the dataset

:type dataset: string
:param dataset: the path to the dataset (here mnist)
         

#############
# load data #
#############

# download the mnist dataset if it is not present
data_dir, data_file = os.path.split(dataset)
if data_dir == "" and not os.path.isfile(dataset):

# check if dataset is in the data directory.
new_path = os.path.join(

os.path.split(__file__)[0],
"..",
"data",
dataset

)
if os.path.isfile(new_path) or data_file ==    mnist.pkl.gz   :

dataset = new_path

if (not os.path.isfile(dataset)) and data_file ==    mnist.pkl.gz   :

import urllib
origin = (

   http://www.iro.umontreal.ca/~lisa/deep/data/mnist/mnist.pkl.gz   

)
print    downloading data from %s    % origin
urllib.urlretrieve(origin, dataset)

print    ... loading data   

# load the dataset
f = gzip.open(dataset,    rb   )
train_set, valid_set, test_set = cpickle.load(f)
f.close()
#train_set, valid_set, test_set format: tuple(input, target)
#input is an numpy.ndarray of 2 dimensions (a matrix)
#witch row   s correspond to an example. target is a
#numpy.ndarray of 1 dimensions (vector)) that have the same length as
#the number of rows in the input. it should give the target
#target to the example with the same index in the input.

def shared_dataset(data_xy, borrow=true):

28

chapter 4. classifying mnist digits using id28

deep learning tutorial, release 0.1

""" function that loads the dataset into shared variables

the reason we store our dataset in shared variables is to allow
theano to copy it into the gpu memory (when code is run on gpu).
since copying data into the gpu is slow, copying a minibatch everytime
is needed (the default behaviour if the data is not in a shared
variable) would lead to a large decrease in performance.
"""
data_x, data_y = data_xy
shared_x = theano.shared(numpy.asarray(data_x,

dtype=theano.config.floatx),

shared_y = theano.shared(numpy.asarray(data_y,

borrow=borrow)

borrow=borrow)

dtype=theano.config.floatx),

# when storing data on the gpu it has to be stored as floats
# therefore we will store the labels as       floatx       as well
# (      shared_y       does exactly that). but during our computations
# we need them as ints (we use labels as index, and if they are
# floats it doesn   t make sense) therefore instead of returning
#       shared_y       we will have to cast it to int. this little hack
# lets ous get around this issue
return shared_x, t.cast(shared_y,    int32   )

test_set_x, test_set_y = shared_dataset(test_set)
valid_set_x, valid_set_y = shared_dataset(valid_set)
train_set_x, train_set_y = shared_dataset(train_set)

rval = [(train_set_x, train_set_y), (valid_set_x, valid_set_y),

(test_set_x, test_set_y)]

return rval

def sgd_optimization_mnist(learning_rate=0.13, n_epochs=1000,

dataset=   mnist.pkl.gz   ,
batch_size=600):

"""
demonstrate stochastic id119 optimization of a log-linear
model

this is demonstrated on mnist.

:type learning_rate: float
:param learning_rate: learning rate used (factor for the stochastic

gradient)

:type n_epochs: int
:param n_epochs: maximal number of epochs to run the optimizer

:type dataset: string
:param dataset: the path of the mnist dataset file from

http://www.iro.umontreal.ca/~lisa/deep/data/mnist/mnist.pkl.gz

4.6. putting it all together

29

deep learning tutorial, release 0.1

"""
datasets = load_data(dataset)

train_set_x, train_set_y = datasets[0]
valid_set_x, valid_set_y = datasets[1]
test_set_x, test_set_y = datasets[2]

# compute number of minibatches for training, validation and testing
n_train_batches = train_set_x.get_value(borrow=true).shape[0] / batch_size
n_valid_batches = valid_set_x.get_value(borrow=true).shape[0] / batch_size
n_test_batches = test_set_x.get_value(borrow=true).shape[0] / batch_size

######################
# build actual model #
######################
print    ... building the model   

# allocate symbolic variables for the data
index = t.lscalar()

# index to a [mini]batch

# generate symbolic variables for input (x and y represent a
# minibatch)
x = t.matrix(   x   )
y = t.ivector(   y   )

# data, presented as rasterized images

# labels, presented as 1d vector of [int] labels

# construct the id28 class
# each mnist image has size 28*28
classifier = logisticregression(input=x, n_in=28 * 28, n_out=10)

# the cost we minimize during training is the negative log likelihood of
# the model in symbolic format
cost = classifier.negative_log_likelihood(y)

# compiling a theano function that computes the mistakes that are made by
# the model on a minibatch
test_model = theano.function(

inputs=[index],
outputs=classifier.errors(y),
givens={

x: test_set_x[index * batch_size: (index + 1) * batch_size],
y: test_set_y[index * batch_size: (index + 1) * batch_size]

}

)

validate_model = theano.function(

inputs=[index],
outputs=classifier.errors(y),
givens={

x: valid_set_x[index * batch_size: (index + 1) * batch_size],
y: valid_set_y[index * batch_size: (index + 1) * batch_size]

}

)

30

chapter 4. classifying mnist digits using id28

deep learning tutorial, release 0.1

# compute the gradient of cost with respect to theta = (w,b)
g_w = t.grad(cost=cost, wrt=classifier.w)
g_b = t.grad(cost=cost, wrt=classifier.b)

# start-snippet-3
# specify how to update the parameters of the model as a list of
# (variable, update expression) pairs.
updates = [(classifier.w, classifier.w - learning_rate * g_w),
(classifier.b, classifier.b - learning_rate * g_b)]

# compiling a theano function    train_model    that returns the cost, but in
# the same time updates the parameter of the model based on the rules
# defined in    updates   
train_model = theano.function(

inputs=[index],
outputs=cost,
updates=updates,
givens={

x: train_set_x[index * batch_size: (index + 1) * batch_size],
y: train_set_y[index * batch_size: (index + 1) * batch_size]

}

)
# end-snippet-3

###############
# train model #
###############
print    ... training the model   
# early-stopping parameters
patience = 5000
patience_increase = 2

# look as this many examples regardless

# wait this much longer when a new best is

improvement_threshold = 0.995

# a relative improvement of this much is

validation_frequency = min(n_train_batches, patience / 2)

# considered significant

# found

# go through this many
# minibatche before checking the network
# on the validation set; in this case we
# check every epoch

best_validation_loss = numpy.inf
test_score = 0.
start_time = timeit.default_timer()

done_looping = false
epoch = 0
while (epoch < n_epochs) and (not done_looping):

epoch = epoch + 1
for minibatch_index in xrange(n_train_batches):

minibatch_avg_cost = train_model(minibatch_index)
# iteration number
iter = (epoch - 1) * n_train_batches + minibatch_index

4.6. putting it all together

31

deep learning tutorial, release 0.1

if (iter + 1) % validation_frequency == 0:

# compute zero-one loss on validation set
validation_losses = [validate_model(i)

this_validation_loss = numpy.mean(validation_losses)

for i in xrange(n_valid_batches)]

print(

   epoch %i, minibatch %i/%i, validation error %f %%    %
(

epoch,
minibatch_index + 1,
n_train_batches,
this_validation_loss * 100.

)

)

# if we got the best validation score until now
if this_validation_loss < best_validation_loss:

#improve patience if loss improvement is good enough
if this_validation_loss < best_validation_loss *

\

improvement_threshold:
patience = max(patience, iter * patience_increase)

best_validation_loss = this_validation_loss
# test it on the test set

test_losses = [test_model(i)

test_score = numpy.mean(test_losses)

for i in xrange(n_test_batches)]

print(

(

) %
(

)

)

   
    best model %f %%   

epoch %i, minibatch %i/%i, test error of   

epoch,
minibatch_index + 1,
n_train_batches,
test_score * 100.

# save the best model
with open(   best_model.pkl   ,    w   ) as f:

cpickle.dump(classifier, f)

if patience <= iter:

done_looping = true
break

end_time = timeit.default_timer()
print(

32

chapter 4. classifying mnist digits using id28

deep learning tutorial, release 0.1

(

   optimization complete with best validation score of %f %%,   
   with test performance %f %%   

)
% (best_validation_loss * 100., test_score * 100.)

)
print    the code run for %d epochs, with %f epochs/sec    % (

epoch, 1. * epoch / (end_time - start_time))

print >> sys.stderr, (   the code for file     +

os.path.split(__file__)[1] +
    ran for %.1fs    % ((end_time - start_time)))

def predict():

"""
an example of how to load a trained model and use it
to predict labels.
"""

# load the saved model
classifier = cpickle.load(open(   best_model.pkl   ))

# compile a predictor function
predict_model = theano.function(

inputs=[classifier.input],
outputs=classifier.y_pred)

# we can test it on some examples from test test
dataset=   mnist.pkl.gz   
datasets = load_data(dataset)
test_set_x, test_set_y = datasets[2]
test_set_x = test_set_x.get_value()

predicted_values = predict_model(test_set_x[:10])
print ("predicted values for the first 10 examples in test set:")
print predicted_values

if __name__ ==    __main__   :

sgd_optimization_mnist()

the user can learn to classify mnist digits with sgd id28, by typing, from within the
deeplearningtutorials folder:

python code/logistic_sgd.py

the output one should expect is of the form :
...
epoch 72, minibatch 83/83, validation error 7.510417 %

epoch 72, minibatch 83/83, test error of best model 7.510417 %

epoch 73, minibatch 83/83, validation error 7.500000 %

epoch 73, minibatch 83/83, test error of best model 7.489583 %

optimization complete with best validation score of 7.500000 %,with test performance 7.489583 %

4.6. putting it all together

33

deep learning tutorial, release 0.1

the code run for 74 epochs, with 1.936983 epochs/sec

on an intel(r) core(tm)2 duo cpu e8400 @ 3.00 ghz the code runs with approximately 1.936 epochs/sec
and it took 75 epochs to reach a test error of 7.489%. on the gpu the code does almost 10.0 epochs/sec.
for this instance we used a batch size of 600.

4.7 prediction using a trained model

sgd_optimization_mnist serialize and pickle the model each time new lowest validation error is
reached. we can reload this model and predict labels of new data. predict function shows an example of
how this could be done.

def predict():

"""
an example of how to load a trained model and use it
to predict labels.
"""

# load the saved model
classifier = cpickle.load(open(   best_model.pkl   ))

# compile a predictor function
predict_model = theano.function(

inputs=[classifier.input],
outputs=classifier.y_pred)

# we can test it on some examples from test test
dataset=   mnist.pkl.gz   
datasets = load_data(dataset)
test_set_x, test_set_y = datasets[2]
test_set_x = test_set_x.get_value()

predicted_values = predict_model(test_set_x[:10])
print ("predicted values for the first 10 examples in test set:")
print predicted_values

34

chapter 4. classifying mnist digits using id28

chapter
five

multilayer id88

note: this section assumes the reader has already read through classifying mnist digits using logistic
regression. additionally, it uses the following new theano functions and concepts: t.tanh, shared variables,
basic arithmetic ops, t.grad, l1 and l2 id173,    oatx. if you intend to run the code on gpu also
read gpu.

note: the code for this section is available for download here.

the next architecture we are going to present using theano is the single-hidden-layer multi-layer percep-
tron (mlp). an mlp can be viewed as a id28 classi   er where the input is    rst transformed
using a learnt non-linear transformation   . this transformation projects the input data into a space where it
becomes linearly separable. this intermediate layer is referred to as a hidden layer. a single hidden layer is
suf   cient to make mlps a universal approximator. however we will see later on that there are substantial
bene   ts to using many such hidden layers, i.e. the very premise of deep learning. see these course notes
for an introduction to mlps, the back-propagation algorithm, and how to train mlps.

this tutorial will again tackle the problem of mnist digit classi   cation.

5.1 the model

an mlp (or arti   cial neural network - ann) with a single hidden layer can be represented graphically as
follows:

formally, a one-hidden-layer mlp is a function f : rd     rl, where d is the size of input vector x and l

35

deep learning tutorial, release 0.1

is the size of the output vector f(x), such that, in matrix notation:

f(x) = g(b(2) + w (2)(s(b(1) + w (1)x))),

with bias vectors b(1), b(2); weight matrices w (1), w (2) and id180 g and s.
the vector h(x) =   (x) = s(b(1) + w (1)x) constitutes the hidden layer. w (1)     rd  dh is the weight
matrix connecting the input vector to the hidden layer. each column w (1)
represents the weights from the
  i
input units to the i-th hidden unit. typical choices for s include tanh, with tanh(a) = (ea   e   a)/(ea+e   a),
or the logistic sigmoid function, with sigmoid(a) = 1/(1 + e   a). we will be using tanh in this tutorial
because it typically yields to faster training (and sometimes also to better local minima). both the tanh and
sigmoid are scalar-to-scalar functions but their natural extension to vectors and tensors consists in applying
them element-wise (e.g. separately on each element of the vector, yielding a same-size vector).

the output vector is then obtained as: o(x) = g(b(2) + w (2)h(x)). the reader should recognize the form
we already used for classifying mnist digits using id28. as before, class-membership prob-
abilities can be obtained by choosing g as the sof tmax function (in the case of multi-class classi   cation).
to train an mlp, we learn all parameters of the model, and here we use stochastic id119 with
minibatches. the set of parameters to learn is the set    = {w (2), b(2), w (1), b(1)}. obtaining the gradi-
ents    (cid:96)/      can be achieved through the id26 algorithm (a special case of the chain-rule of
derivation). thankfully, since theano performs automatic differentation, we will not need to cover this in
the tutorial !

5.2 going from id28 to mlp

this tutorial will focus on a single-hidden-layer mlp. we start off by implementing a class that will represent
a hidden layer. to construct the mlp we will then only need to throw a id28 layer on top.

class hiddenlayer(object):

def __init__(self, rng, input, n_in, n_out, w=none, b=none,

activation=t.tanh):

"""
typical hidden layer of a mlp: units are fully-connected and have
sigmoidal activation function. weight matrix w is of shape (n_in,n_out)
and the bias vector b is of shape (n_out,).

note : the nonlinearity used here is tanh

hidden unit activation is given by: tanh(dot(input,w) + b)

:type rng: numpy.random.randomstate
:param rng: a random number generator used to initialize weights

:type input: theano.tensor.dmatrix
:param input: a symbolic tensor of shape (n_examples, n_in)

:type n_in: int
:param n_in: dimensionality of input

:type n_out: int

36

chapter 5. multilayer id88

deep learning tutorial, release 0.1

:param n_out: number of hidden units

:type activation: theano.op or function
:param activation: non linearity to be applied in the hidden

"""
self.input = input

layer

(cid:113)

that the interval should be [   (cid:113)
(cid:113)

the initial values for the weights of a hidden layer i should be uniformly sampled from a symmetric interval
that depends on the activation function. for tanh activation function results obtained in [xavier10] show
], where f anin is the number of units in the
(i     1)-th layer, and f anout is the number of units in the i-th layer. for the sigmoid function the interval
is [   4
]. this initialization ensures that, early in training, each neuron
operates in a regime of its activation function where information can easily be propagated both upward
(activations    owing from inputs to outputs) and backward (gradients    owing from outputs to inputs).

f anin+f anout

f anin+f anout

f anin+f anout

f anin+f anout

(cid:113)

, 4

6

6

6

6

,

#    w    is initialized with    w_values    which is uniformely sampled
# from sqrt(-6./(n_in+n_hidden)) and sqrt(6./(n_in+n_hidden))
# for tanh activation function
# the output of uniform if converted using asarray to dtype
# theano.config.floatx so that the code is runable on gpu
# note : optimal initialization of weights is dependent on the
#
#
#
#
#
#
if w is none:

activation function used (among other things).
for example, results presented in [xavier10] suggest that you
should use 4 times larger initial weights for sigmoid
compared to tanh
we have no info for other function, so we use the same as
tanh.

w_values = numpy.asarray(

rng.uniform(

low=-numpy.sqrt(6. / (n_in + n_out)),
high=numpy.sqrt(6. / (n_in + n_out)),
size=(n_in, n_out)

),
dtype=theano.config.floatx

)
if activation == theano.tensor.nnet.sigmoid:

w_values *= 4

w = theano.shared(value=w_values, name=   w   , borrow=true)

if b is none:

b_values = numpy.zeros((n_out,), dtype=theano.config.floatx)
b = theano.shared(value=b_values, name=   b   , borrow=true)

self.w = w
self.b = b

note that we used a given non-linear function as the activation function of the hidden layer. by default this
is tanh, but in many cases we might want to use something else.

5.2. going from id28 to mlp

37

deep learning tutorial, release 0.1

lin_output = t.dot(input, self.w) + self.b
self.output = (

lin_output if activation is none
else activation(lin_output)

)

if you look into theory this class implements the graph that computes the hidden layer value h(x) =   (x) =
s(b(1) + w (1)x). if you give this graph as input to the logisticregression class, implemented in the
previous tutorial classifying mnist digits using id28, you get the output of the mlp. you
can see this in the following short implementation of the mlp class.

class mlp(object):

"""multi-layer id88 class

a multilayer id88 is a feedforward id158 model
that has one layer or more of hidden units and nonlinear activations.
intermediate layers usually have as activation function tanh or the
sigmoid function (defined here by a       hiddenlayer       class)
top layer is a softmax layer (defined here by a       logisticregression      
class).
"""

while the

def __init__(self, rng, input, n_in, n_hidden, n_out):

"""initialize the parameters for the multilayer id88

:type rng: numpy.random.randomstate
:param rng: a random number generator used to initialize weights

:type input: theano.tensor.tensortype
:param input: symbolic variable that describes the input of the
architecture (one minibatch)

:type n_in: int
:param n_in: number of input units, the dimension of the space in
which the datapoints lie

:type n_hidden: int
:param n_hidden: number of hidden units

:type n_out: int
:param n_out: number of output units, the dimension of the space in
which the labels lie

"""

# since we are dealing with a one hidden layer mlp, this will translate
# into a hiddenlayer with a tanh activation function connected to the
# logisticregression layer; the activation function can be replaced by
# sigmoid or any other nonlinear function
self.hiddenlayer = hiddenlayer(

rng=rng,
input=input,
n_in=n_in,

38

chapter 5. multilayer id88

deep learning tutorial, release 0.1

n_out=n_hidden,
activation=t.tanh

)

# the id28 layer gets as input the hidden units
# of the hidden layer
self.logregressionlayer = logisticregression(

input=self.hiddenlayer.output,
n_in=n_hidden,
n_out=n_out

)

in this tutorial we will also use l1 and l2 id173 (see l1 and l2 id173). for this, we need
to compute the l1 norm and the squared l2 norm of the weights w (1), w (2).

# l1 norm ; one id173 option is to enforce l1 norm to
# be small
self.l1 = (

abs(self.hiddenlayer.w).sum()
+ abs(self.logregressionlayer.w).sum()

)

# square of l2 norm ; one id173 option is to enforce
# square of l2 norm to be small
self.l2_sqr = (

(self.hiddenlayer.w ** 2).sum()
+ (self.logregressionlayer.w ** 2).sum()

)

# negative log likelihood of the mlp is given by the negative
# log likelihood of the output of the model, computed in the
# id28 layer
self.negative_log_likelihood = (

self.logregressionlayer.negative_log_likelihood

)
# same holds for the function computing the number of errors
self.errors = self.logregressionlayer.errors

# the parameters of the model are the parameters of the two layer it is
# made out of
self.params = self.hiddenlayer.params + self.logregressionlayer.params

as before, we train this model using stochastic id119 with mini-batches. the difference is that we
modify the cost function to include the id173 term. l1_reg and l2_reg are the hyperparameters
controlling the weight of these id173 terms in the total cost function. the code that computes the
new cost is:

# the cost we minimize during training is the negative log likelihood of
# the model plus the id173 terms (l1 and l2); cost is expressed
# here symbolically
cost = (

classifier.negative_log_likelihood(y)
+ l1_reg * classifier.l1

5.2. going from id28 to mlp

39

deep learning tutorial, release 0.1

+ l2_reg * classifier.l2_sqr

)

we then update the parameters of the model using the gradient. this code is almost identical to the one
for id28. only the number of parameters differ. to get around this ( and write code that
could work for any number of parameters) we will use the list of parameters that we created with the model
params and parse it, computing a gradient at each step.

# compute the gradient of cost with respect to theta (sotred in params)
# the resulting gradients will be stored in a list gparams
gparams = [t.grad(cost, param) for param in classifier.params]

# specify how to update the parameters of the model as a list of
# (variable, update expression) pairs

# given two lists of the same length, a = [a1, a2, a3, a4] and
# b = [b1, b2, b3, b4], zip generates a list c of same size, where each
# element is a pair formed from the two lists :
#
updates = [

c = [(a1, b1), (a2, b2), (a3, b3), (a4, b4)]

(param, param - learning_rate * gparam)
for param, gparam in zip(classifier.params, gparams)

]

# compiling a theano function    train_model    that returns the cost, but
# in the same time updates the parameter of the model based on the rules
# defined in    updates   
train_model = theano.function(

inputs=[index],
outputs=cost,
updates=updates,
givens={

x: train_set_x[index * batch_size: (index + 1) * batch_size],
y: train_set_y[index * batch_size: (index + 1) * batch_size]

}

)

5.3 putting it all together

having covered the basic concepts, writing an mlp class becomes quite easy. the code below shows how
this can be done, in a way which is analogous to our previous id28 implementation.

"""
this tutorial introduces the multilayer id88 using theano.

a multilayer id88 is a logistic regressor where

instead of feeding the input to the id28 you insert a
intermediate layer, called the hidden layer, that has a nonlinear
activation function (usually tanh or sigmoid) . one can use many such
hidden layers making the architecture deep. the tutorial will also tackle
the problem of mnist digit classification.

40

chapter 5. multilayer id88

deep learning tutorial, release 0.1

.. math::

f(x) = g( b^{(2)} + w^{(2)}( s( b^{(1)} + w^{(1)} x))),

references:

- textbooks: "pattern recognition and machine learning" -

christopher m. bishop, section 5

"""
__docformat__ =    restructedtext en   

import os
import sys
import timeit

import numpy

import theano
import theano.tensor as t

from logistic_sgd import logisticregression, load_data

# start-snippet-1
class hiddenlayer(object):

def __init__(self, rng, input, n_in, n_out, w=none, b=none,

activation=t.tanh):

"""
typical hidden layer of a mlp: units are fully-connected and have
sigmoidal activation function. weight matrix w is of shape (n_in,n_out)
and the bias vector b is of shape (n_out,).

note : the nonlinearity used here is tanh

hidden unit activation is given by: tanh(dot(input,w) + b)

:type rng: numpy.random.randomstate
:param rng: a random number generator used to initialize weights

:type input: theano.tensor.dmatrix
:param input: a symbolic tensor of shape (n_examples, n_in)

:type n_in: int
:param n_in: dimensionality of input

:type n_out: int
:param n_out: number of hidden units

:type activation: theano.op or function
:param activation: non linearity to be applied in the hidden

5.3. putting it all together

41

deep learning tutorial, release 0.1

layer

"""
self.input = input
# end-snippet-1

#    w    is initialized with    w_values    which is uniformely sampled
# from sqrt(-6./(n_in+n_hidden)) and sqrt(6./(n_in+n_hidden))
# for tanh activation function
# the output of uniform if converted using asarray to dtype
# theano.config.floatx so that the code is runable on gpu
# note : optimal initialization of weights is dependent on the
#
#
#
#
#
#
if w is none:

activation function used (among other things).
for example, results presented in [xavier10] suggest that you
should use 4 times larger initial weights for sigmoid
compared to tanh
we have no info for other function, so we use the same as
tanh.

w_values = numpy.asarray(

rng.uniform(

low=-numpy.sqrt(6. / (n_in + n_out)),
high=numpy.sqrt(6. / (n_in + n_out)),
size=(n_in, n_out)

),
dtype=theano.config.floatx

)
if activation == theano.tensor.nnet.sigmoid:

w_values *= 4

w = theano.shared(value=w_values, name=   w   , borrow=true)

if b is none:

b_values = numpy.zeros((n_out,), dtype=theano.config.floatx)
b = theano.shared(value=b_values, name=   b   , borrow=true)

self.w = w
self.b = b

lin_output = t.dot(input, self.w) + self.b
self.output = (

lin_output if activation is none
else activation(lin_output)

)
# parameters of the model
self.params = [self.w, self.b]

# start-snippet-2
class mlp(object):

"""multi-layer id88 class

a multilayer id88 is a feedforward id158 model
that has one layer or more of hidden units and nonlinear activations.

42

chapter 5. multilayer id88

deep learning tutorial, release 0.1

intermediate layers usually have as activation function tanh or the
sigmoid function (defined here by a       hiddenlayer       class)
top layer is a softmax layer (defined here by a       logisticregression      
class).
"""

while the

def __init__(self, rng, input, n_in, n_hidden, n_out):

"""initialize the parameters for the multilayer id88

:type rng: numpy.random.randomstate
:param rng: a random number generator used to initialize weights

:type input: theano.tensor.tensortype
:param input: symbolic variable that describes the input of the
architecture (one minibatch)

:type n_in: int
:param n_in: number of input units, the dimension of the space in
which the datapoints lie

:type n_hidden: int
:param n_hidden: number of hidden units

:type n_out: int
:param n_out: number of output units, the dimension of the space in
which the labels lie

"""

# since we are dealing with a one hidden layer mlp, this will translate
# into a hiddenlayer with a tanh activation function connected to the
# logisticregression layer; the activation function can be replaced by
# sigmoid or any other nonlinear function
self.hiddenlayer = hiddenlayer(

rng=rng,
input=input,
n_in=n_in,
n_out=n_hidden,
activation=t.tanh

)

# the id28 layer gets as input the hidden units
# of the hidden layer
self.logregressionlayer = logisticregression(

input=self.hiddenlayer.output,
n_in=n_hidden,
n_out=n_out

)
# end-snippet-2 start-snippet-3
# l1 norm ; one id173 option is to enforce l1 norm to
# be small
self.l1 = (

abs(self.hiddenlayer.w).sum()

5.3. putting it all together

43

deep learning tutorial, release 0.1

+ abs(self.logregressionlayer.w).sum()

)

# square of l2 norm ; one id173 option is to enforce
# square of l2 norm to be small
self.l2_sqr = (

(self.hiddenlayer.w ** 2).sum()
+ (self.logregressionlayer.w ** 2).sum()

)

# negative log likelihood of the mlp is given by the negative
# log likelihood of the output of the model, computed in the
# id28 layer
self.negative_log_likelihood = (

self.logregressionlayer.negative_log_likelihood

)
# same holds for the function computing the number of errors
self.errors = self.logregressionlayer.errors

# the parameters of the model are the parameters of the two layer it is
# made out of
self.params = self.hiddenlayer.params + self.logregressionlayer.params
# end-snippet-3

# keep track of model input
self.input = input

def test_mlp(learning_rate=0.01, l1_reg=0.00, l2_reg=0.0001, n_epochs=1000,

dataset=   mnist.pkl.gz   , batch_size=20, n_hidden=500):

"""
demonstrate stochastic id119 optimization for a multilayer
id88

this is demonstrated on mnist.

:type learning_rate: float
:param learning_rate: learning rate used (factor for the stochastic
gradient

:type l1_reg: float
:param l1_reg: l1-norm   s weight when added to the cost (see
id173)

:type l2_reg: float
:param l2_reg: l2-norm   s weight when added to the cost (see
id173)

:type n_epochs: int
:param n_epochs: maximal number of epochs to run the optimizer

:type dataset: string
:param dataset: the path of the mnist dataset file from

44

chapter 5. multilayer id88

deep learning tutorial, release 0.1

http://www.iro.umontreal.ca/~lisa/deep/data/mnist/mnist.pkl.gz

"""

datasets = load_data(dataset)

train_set_x, train_set_y = datasets[0]
valid_set_x, valid_set_y = datasets[1]
test_set_x, test_set_y = datasets[2]

# compute number of minibatches for training, validation and testing
n_train_batches = train_set_x.get_value(borrow=true).shape[0] / batch_size
n_valid_batches = valid_set_x.get_value(borrow=true).shape[0] / batch_size
n_test_batches = test_set_x.get_value(borrow=true).shape[0] / batch_size

######################
# build actual model #
######################
print    ... building the model   

# allocate symbolic variables for the data
index = t.lscalar()
x = t.matrix(   x   )
y = t.ivector(   y   )

# index to a [mini]batch

# the data is presented as rasterized images

# the labels are presented as 1d vector of
# [int] labels

rng = numpy.random.randomstate(1234)

# construct the mlp class
classifier = mlp(

rng=rng,
input=x,
n_in=28 * 28,
n_hidden=n_hidden,
n_out=10

)

# start-snippet-4
# the cost we minimize during training is the negative log likelihood of
# the model plus the id173 terms (l1 and l2); cost is expressed
# here symbolically
cost = (

classifier.negative_log_likelihood(y)
+ l1_reg * classifier.l1
+ l2_reg * classifier.l2_sqr

)
# end-snippet-4

# compiling a theano function that computes the mistakes that are made
# by the model on a minibatch
test_model = theano.function(

inputs=[index],
outputs=classifier.errors(y),

5.3. putting it all together

45

deep learning tutorial, release 0.1

givens={

x: test_set_x[index * batch_size:(index + 1) * batch_size],
y: test_set_y[index * batch_size:(index + 1) * batch_size]

}

)

validate_model = theano.function(

inputs=[index],
outputs=classifier.errors(y),
givens={

x: valid_set_x[index * batch_size:(index + 1) * batch_size],
y: valid_set_y[index * batch_size:(index + 1) * batch_size]

}

)

# start-snippet-5
# compute the gradient of cost with respect to theta (sotred in params)
# the resulting gradients will be stored in a list gparams
gparams = [t.grad(cost, param) for param in classifier.params]

# specify how to update the parameters of the model as a list of
# (variable, update expression) pairs

# given two lists of the same length, a = [a1, a2, a3, a4] and
# b = [b1, b2, b3, b4], zip generates a list c of same size, where each
# element is a pair formed from the two lists :
#
updates = [

c = [(a1, b1), (a2, b2), (a3, b3), (a4, b4)]

(param, param - learning_rate * gparam)
for param, gparam in zip(classifier.params, gparams)

]

# compiling a theano function    train_model    that returns the cost, but
# in the same time updates the parameter of the model based on the rules
# defined in    updates   
train_model = theano.function(

inputs=[index],
outputs=cost,
updates=updates,
givens={

x: train_set_x[index * batch_size: (index + 1) * batch_size],
y: train_set_y[index * batch_size: (index + 1) * batch_size]

}

)
# end-snippet-5

###############
# train model #
###############
print    ... training   

# early-stopping parameters
patience = 10000

# look as this many examples regardless

46

chapter 5. multilayer id88

deep learning tutorial, release 0.1

patience_increase = 2

# wait this much longer when a new best is
# found

improvement_threshold = 0.995

# a relative improvement of this much is
# considered significant

validation_frequency = min(n_train_batches, patience / 2)

# go through this many
# minibatche before checking the network
# on the validation set; in this case we
# check every epoch

best_validation_loss = numpy.inf
best_iter = 0
test_score = 0.
start_time = timeit.default_timer()

epoch = 0
done_looping = false

while (epoch < n_epochs) and (not done_looping):

epoch = epoch + 1
for minibatch_index in xrange(n_train_batches):

minibatch_avg_cost = train_model(minibatch_index)
# iteration number
iter = (epoch - 1) * n_train_batches + minibatch_index

if (iter + 1) % validation_frequency == 0:

# compute zero-one loss on validation set
validation_losses = [validate_model(i) for i

this_validation_loss = numpy.mean(validation_losses)

in xrange(n_valid_batches)]

print(

   epoch %i, minibatch %i/%i, validation error %f %%    %
(

epoch,
minibatch_index + 1,
n_train_batches,
this_validation_loss * 100.

)

)

# if we got the best validation score until now
if this_validation_loss < best_validation_loss:

#improve patience if loss improvement is good enough
if (

this_validation_loss < best_validation_loss *
improvement_threshold

):

patience = max(patience, iter * patience_increase)

best_validation_loss = this_validation_loss
best_iter = iter

5.3. putting it all together

47

deep learning tutorial, release 0.1

# test it on the test set
test_losses = [test_model(i) for i

test_score = numpy.mean(test_losses)

in xrange(n_test_batches)]

print((   

epoch %i, minibatch %i/%i, test error of    

   best model %f %%   ) %

(epoch, minibatch_index + 1, n_train_batches,
test_score * 100.))

if patience <= iter:

done_looping = true
break

end_time = timeit.default_timer()
print((   optimization complete. best validation score of %f %%    

   obtained at iteration %i, with test performance %f %%   ) %
(best_validation_loss * 100., best_iter + 1, test_score * 100.))

print >> sys.stderr, (   the code for file     +

os.path.split(__file__)[1] +
    ran for %.2fm    % ((end_time - start_time) / 60.))

if __name__ ==    __main__   :

test_mlp()

the user can then run the code by calling :

python code/mlp.py

the output one should expect is of the form :

optimization complete. best validation score of 1.690000 % obtained at iteration 2070000, with test performance 1.650000 %
the code for file mlp.py ran for 97.34m

on an intel(r) core(tm) i7-2600k cpu @ 3.40ghz the code runs with approximately 10.3 epoch/minute
and it took 828 epochs to reach a test error of 1.65%.

to put this into perspective, we refer the reader to the results section of this page.

5.4 tips and tricks for training mlps

there are several hyper-parameters in the above code, which are not (and, generally speaking, cannot be)
optimized by id119. strictly speaking,    nding an optimal set of values for these hyper-parameters
is not a feasible problem. first, we can   t simply optimize each of them independently. second, we cannot
readily apply gradient techniques that we described previously (partly because some parameters are discrete
values and others are real-valued). third, the optimization problem is not convex and    nding a (local)
minimum would involve a non-trivial amount of work.

the good news is that over the last 25 years, researchers have devised various rules of thumb for choosing
hyper-parameters in a neural network. a very good overview of these tricks can be found in ef   cient

48

chapter 5. multilayer id88

deep learning tutorial, release 0.1

backprop by yann lecun, leon bottou, genevieve orr, and klaus-robert mueller. in here, we summarize
the same issues, with an emphasis on the parameters and techniques that we actually used in our code.

5.4.1 nonlinearity

two of the most common ones are the sigmoid and the tanh function. for reasons explained in section 4.4,
nonlinearities that are symmetric around the origin are preferred because they tend to produce zero-mean
inputs to the next layer (which is a desirable property). empirically, we have observed that the tanh has
better convergence properties.

5.4.2 weight initialization

at initialization we want the weights to be small enough around the origin so that the activation func-
tion operates in its linear regime, where gradients are the largest. other desirable properties, especially
for deep networks, are to conserve variance of the activation as well as variance of back-propagated gra-
dients from layer to layer. this allows information to    ow well upward and downward in the network
and reduces discrepancies between layers. under some assumptions, a compromise between these two
constraints leads to the following initialization: unif orm[   
] for tanh and
unif orm[   4    
] for sigmoid. where f anin is the number of inputs and
f anout the number of hidden units. for mathematical considerations please refer to [xavier10].

f anin+f anout

f anin+f anout

f anin+f anout

f anin+f anout

, 4    

   

   

   

   

   

   

   

   

6

6

6

6

,

5.4.3 learning rate

there is a great deal of literature on choosing a good learning rate. the simplest solution is to simply have
a constant rate. rule of thumb: try several log-spaced values (10   1, 10   2, . . .) and narrow the (logarithmic)
grid search to the region where you obtain the lowest validation error.

decreasing the learning rate over time is sometimes a good idea. one simple rule for doing that is
1+d  t
where   0 is the initial rate (chosen, perhaps, using the grid search technique explained above), d is a so-
called    decrease constant    which controls the rate at which the learning rate decreases (typically, a smaller
positive number, 10   3 and smaller) and t is the epoch/stage.
section 4.7 details procedures for choosing a learning rate for each parameter (weight) in our network and
for choosing them adaptively based on the error of the classi   er.

  0

5.4.4 number of hidden units

this hyper-parameter is very much dataset-dependent. vaguely speaking, the more complicated the input
distribution is, the more capacity the network will require to model it, and so the larger the number of
hidden units that will be needed (note that the number of weights in a layer, perhaps a more direct measure
of capacity, is d    dh (recall d is the number of inputs and dh is the number of hidden units).
unless we employ some id173 scheme (early stopping or l1/l2 penalties), a typical number of
hidden units vs. generalization performance graph will be u-shaped.

5.4. tips and tricks for training mlps

49

deep learning tutorial, release 0.1

5.4.5 id173 parameter
typical values to try for the l1/l2 id173 parameter    are 10   2, 10   3, . . .. in the framework that
we described so far, optimizing this parameter will not lead to signi   cantly better solutions, but is worth
exploring nonetheless.

50

chapter 5. multilayer id88

chapter
six

convolutional neural networks (lenet)

note: this section assumes the reader has already read through classifying mnist digits using logistic
regression and multilayer id88. additionally, it uses the following new theano functions and con-
cepts: t.tanh, shared variables, basic arithmetic ops, t.grad,    oatx, downsample , conv2d, dimshuf   e. if
you intend to run the code on gpu also read gpu.

to run this example on a gpu, you need a good gpu. it needs at least 1gb of gpu ram. more may be
required if your monitor is connected to the gpu.

when the gpu is connected to the monitor, there is a limit of a few seconds for each gpu function call.
this is needed as current gpus can   t be used for the monitor while doing computation. without this limit,
the screen would freeze for too long and make it look as if the computer froze. this example hits this limit
with medium-quality gpus. when the gpu isn   t connected to a monitor, there is no time limit. you can
lower the batch size to    x the time out problem.

note: the code for this section is available for download here and the 3wolfmoon image

6.1 motivation

convolutional neural networks (id98) are biologically-inspired variants of mlps. from hubel and
wiesel   s early work on the cat   s visual cortex [hubel68], we know the visual cortex contains a complex
arrangement of cells. these cells are sensitive to small sub-regions of the visual    eld, called a receptive
   eld. the sub-regions are tiled to cover the entire visual    eld. these cells act as local    lters over the input
space and are well-suited to exploit the strong spatially local correlation present in natural images.

additionally, two basic cell types have been identi   ed: simple cells respond maximally to speci   c edge-like
patterns within their receptive    eld. complex cells have larger receptive    elds and are locally invariant to
the exact position of the pattern.

the animal visual cortex being the most powerful visual processing system in existence, it seems natural to
emulate its behavior. hence, many neurally-inspired models can be found in the literature. to name a few:
the neocognitron [fukushima], hmax [serre07] and lenet-5 [lecun98], which will be the focus of this
tutorial.

51

deep learning tutorial, release 0.1

6.2 sparse connectivity

id98s exploit spatially-local correlation by enforcing a local connectivity pattern between neurons of adja-
cent layers. in other words, the inputs of hidden units in layer m are from a subset of units in layer m-1,
units that have spatially contiguous receptive    elds. we can illustrate this graphically as follows:

imagine that layer m-1 is the input retina. in the above    gure, units in layer m have receptive    elds of width
3 in the input retina and are thus only connected to 3 adjacent neurons in the retina layer. units in layer m+1
have a similar connectivity with the layer below. we say that their receptive    eld with respect to the layer
below is also 3, but their receptive    eld with respect to the input is larger (5). each unit is unresponsive to
variations outside of its receptive    eld with respect to the retina. the architecture thus ensures that the learnt
      lters    produce the strongest response to a spatially local input pattern.

however, as shown above, stacking many such layers leads to (non-linear)       lters    that become increasingly
   global    (i.e. responsive to a larger region of pixel space). for example, the unit in hidden layer m+1 can
encode a non-linear feature of width 5 (in terms of pixel space).

6.3 shared weights

in addition, in id98s, each    lter hi is replicated across the entire visual    eld. these replicated units share
the same parameterization (weight vector and bias) and form a feature map.

in the above    gure, we show 3 hidden units belonging to the same feature map. weights of the same color
are shared   constrained to be identical. id119 can still be used to learn such shared parameters,
with only a small change to the original algorithm. the gradient of a shared weight is simply the sum of the
gradients of the parameters being shared.

replicating units in this way allows for features to be detected regardless of their position in the visual    eld.
additionally, weight sharing increases learning ef   ciency by greatly reducing the number of free parameters
being learnt. the constraints on the model enable id98s to achieve better generalization on vision problems.

52

chapter 6. convolutional neural networks (lenet)

deep learning tutorial, release 0.1

6.4 details and notation

a feature map is obtained by repeated application of a function across sub-regions of the entire image, in
other words, by convolution of the input image with a linear    lter, adding a bias term and then applying a
non-linear function. if we denote the k-th feature map at a given layer as hk, whose    lters are determined
by the weights w k and bias bk, then the feature map hk is obtained as follows (for tanh non-linearities):

ij = tanh((w k     x)ij + bk).
hk

note:

u=       f[u]g[n     u] =(cid:80)   
(cid:80)   
this can be extended to 2d as follows: o[m, n] = f[m, n]     g[m, n] = (cid:80)   

recall the following de   nition of convolution for a 1d signal.

u=       f[n     u]g[u].

u=      (cid:80)   

o[n] = f[n]     g[n] =

v=       f[u, v]g[m    

u, n     v].

to form a richer representation of the data, each hidden layer is composed of multiple feature maps,
{h(k), k = 0..k}. the weights w of a hidden layer can be represented in a 4d tensor containing ele-
ments for every combination of destination feature map, source feature map, source vertical position, and
source horizontal position. the biases b can be represented as a vector containing one element for every
destination feature map. we illustrate this graphically as follows:

figure 6.1: figure 1: example of a convolutional layer

the    gure shows two layers of a id98. layer m-1 contains four feature maps. hidden layer m contains
two feature maps (h0 and h1). pixels (neuron outputs) in h0 and h1 (outlined as blue and red squares) are
computed from pixels of layer (m-1) which fall within their 2x2 receptive    eld in the layer below (shown as
colored rectangles). notice how the receptive    eld spans all four input feature maps. the weights w 0 and

6.4. details and notation

53

deep learning tutorial, release 0.1

w 1 of h0 and h1 are thus 3d weight tensors. the leading dimension indexes the input feature maps, while
the other two refer to the pixel coordinates.

putting it all together, w kl
the pixel at coordinates (i,j) of the l-th feature map of layer (m-1).

ij denotes the weight connecting each pixel of the k-th feature map at layer m, with

6.5 the convolution operator

convop is the main workhorse for implementing a convolutional layer in theano. convop is used by
theano.tensor.signal.conv2d, which takes two symbolic inputs:

    a 4d tensor corresponding to a mini-batch of input images. the shape of the tensor is as follows:

[mini-batch size, number of input feature maps, image height, image width].

    a 4d tensor corresponding to the weight matrix w . the shape of the tensor is: [number of feature

maps at layer m, number of feature maps at layer m-1,    lter height,    lter width]

below is the theano code for implementing a convolutional layer similar to the one of figure 1. the input
consists of 3 features maps (an rgb color image) of size 120x160. we use two convolutional    lters with
9x9 receptive    elds.

import theano
from theano import tensor as t
from theano.tensor.nnet import conv

import numpy

rng = numpy.random.randomstate(23455)

# instantiate 4d tensor for input
input = t.tensor4(name=   input   )

# initialize shared variable for weights.
w_shp = (2, 3, 9, 9)
w_bound = numpy.sqrt(3 * 9 * 9)
w = theano.shared( numpy.asarray(

rng.uniform(

low=-1.0 / w_bound,
high=1.0 / w_bound,
size=w_shp),

dtype=input.dtype), name =   w   )

# initialize shared variable for bias (1d tensor) with random values
# important: biases are usually initialized to zero. however in this
# particular application, we simply apply the convolutional layer to
# an image without learning the parameters. we therefore initialize
# them to random values to "simulate" learning.
b_shp = (2,)
b = theano.shared(numpy.asarray(

rng.uniform(low=-.5, high=.5, size=b_shp),
dtype=input.dtype), name =   b   )

54

chapter 6. convolutional neural networks (lenet)

deep learning tutorial, release 0.1

# build symbolic expression that computes the convolution of input with filters in w
conv_out = conv.conv2d(input, w)

      dimshuffle       is a powerful tool in reshaping a tensor;
what it allows you to do is to shuffle dimension around
but also to insert new ones along which the tensor will be
broadcastable;
dimshuffle(   x   , 2,    x   , 0, 1)
this will work on 3d tensors with no broadcastable
dimensions. the first dimension will be broadcastable,
then we will have the third dimension of the input tensor as
the second of the resulting tensor, etc. if the tensor has
shape (20, 30, 40), the resulting tensor will have dimensions
(1, 40, 1, 20, 30). (axbxc tensor is mapped to 1xcx1xaxb tensor)
more examples:

# build symbolic expression to add bias and apply activation function, i.e. produce neural net layer output
# a few words on       dimshuffle       :
#
#
#
#
#
#
#
#
#
#
#
#
#
#
#
#
#
#
#
#
output = t.nnet.sigmoid(conv_out + b.dimshuffle(   x   , 0,    x   ,    x   ))

dimshuffle(   x   ) -> make a 0d (scalar) into a 1d vector
dimshuffle(0, 1) -> identity
dimshuffle(1, 0) -> inverts the first and second dimensions
dimshuffle(   x   , 0) -> make a row out of a 1d vector (n to 1xn)
dimshuffle(0,    x   ) -> make a column out of a 1d vector (n to nx1)
dimshuffle(2, 0, 1) -> axbxc to cxaxb
dimshuffle(0,    x   , 1) -> axb to ax1xb
dimshuffle(1,    x   , 0) -> axb to bx1xa

# create theano function to compute filtered images
f = theano.function([input], output)

let   s have a little bit of fun with this...

import numpy
import pylab
from pil import image

# open random image of dimensions 639x516
img = image.open(open(   doc/images/3wolfmoon.jpg   ))
# dimensions are (height, width, channel)
img = numpy.asarray(img, dtype=   float64   ) / 256.

# put image in 4d tensor of shape (1, 3, height, width)
img_ = img.transpose(2, 0, 1).reshape(1, 3, 639, 516)
filtered_img = f(img_)

# plot original image and first and second components of output
pylab.subplot(1, 3, 1); pylab.axis(   off   ); pylab.imshow(img)
pylab.gray();
# recall that the convop output (filtered image) is actually a "minibatch",
# of size 1 here, so we take index 0 in the first dimension:
pylab.subplot(1, 3, 2); pylab.axis(   off   ); pylab.imshow(filtered_img[0, 0, :, :])
pylab.subplot(1, 3, 3); pylab.axis(   off   ); pylab.imshow(filtered_img[0, 1, :, :])
pylab.show()

6.5. the convolution operator

55

deep learning tutorial, release 0.1

this should generate the following output.

notice that a randomly initialized    lter acts very much like an edge detector!

note that we use the same weight initialization formula as with the mlp. weights are sampled randomly
from a uniform distribution in the range [-1/fan-in, 1/fan-in], where fan-in is the number of inputs to a hidden
unit. for mlps, this was the number of units in the layer below. for id98s however, we have to take into
account the number of input feature maps and the size of the receptive    elds.

6.6 maxpooling

another important concept of id98s is max-pooling, which is a form of non-linear down-sampling. max-
pooling partitions the input image into a set of non-overlapping rectangles and, for each such sub-region,
outputs the maximum value.
max-pooling is useful in vision for two reasons:

1. by eliminating non-maximal values, it reduces computation for upper layers.

2. it provides a form of translation invariance.

imagine cascading a max-pooling layer with a
convolutional layer. there are 8 directions in which one can translate the input image by a
single pixel. if max-pooling is done over a 2x2 region, 3 out of these 8 possible con   gurations
will produce exactly the same output at the convolutional layer. for max-pooling over a 3x3
window, this jumps to 5/8.

since it provides additional robustness to position, max-pooling is a    smart    way of reducing
the dimensionality of intermediate representations.

max-pooling is done in theano by way of theano.tensor.signal.downsample.max_pool_2d.
this function takes as input an n dimensional tensor (where n >= 2) and a downscaling factor and performs
max-pooling over the 2 trailing dimensions of the tensor.

an example is worth a thousand words:

from theano.tensor.signal import downsample

input = t.dtensor4(   input   )
maxpool_shape = (2, 2)
pool_out = downsample.max_pool_2d(input, maxpool_shape, ignore_border=true)
f = theano.function([input],pool_out)

invals = numpy.random.randomstate(1).rand(3, 2, 5, 5)

56

chapter 6. convolutional neural networks (lenet)

deep learning tutorial, release 0.1

print    with ignore_border set to true:   
print    invals[0, 0, :, :] =\n   , invals[0, 0, :, :]
print    output[0, 0, :, :] =\n   , f(invals)[0, 0, :, :]

pool_out = downsample.max_pool_2d(input, maxpool_shape, ignore_border=false)
f = theano.function([input],pool_out)
print    with ignore_border set to false:   
print    invals[1, 0, :, :] =\n    , invals[1, 0, :, :]
print    output[1, 0, :, :] =\n    , f(invals)[1, 0, :, :]

this should generate the following output:

with ignore_border set to true:

invals[0, 0, :, :] =
[[
[
[
[
[

4.17022005e-01
9.23385948e-02
4.19194514e-01
6.70467510e-01
8.00744569e-01

7.20324493e-01
1.86260211e-01
6.85219500e-01
4.17304802e-01
9.68261576e-01

1.14374817e-04
3.45560727e-01
2.04452250e-01
5.58689828e-01
3.13424178e-01

3.02332573e-01 1.46755891e-01]
3.96767474e-01 5.38816734e-01]
8.78117436e-01 2.73875932e-02]
1.40386939e-01 1.98101489e-01]
6.92322616e-01 8.76389152e-01]]

output[0, 0, :, :] =
[[ 0.72032449 0.39676747]

[ 0.6852195

0.87811744]]

with ignore_border set to false:

invals[1, 0, :, :] =
[[ 0.01936696 0.67883553 0.21162812
[ 0.05336255 0.57411761 0.14672857
[ 0.10233443 0.41405599 0.69440016
[ 0.53589641 0.66379465 0.51488911
[ 0.90340192 0.1374747
0.13927635

0.26554666
0.58930554
0.41417927
0.94459476
0.80739129

0.49157316]
0.69975836]
0.04995346]
0.58655504]
0.39767684]]

output[1, 0, :, :] =
[[ 0.67883553 0.58930554 0.69975836]
[ 0.66379465 0.94459476 0.58655504]
[ 0.90340192 0.80739129 0.39767684]]

note that compared to most theano code, the max_pool_2d operation is a little special. it requires the
downscaling factor ds (tuple of length 2 containing downscaling factors for image width and height) to be
known at graph build time. this may change in the near future.

6.7 the full model: lenet

sparse, convolutional layers and max-pooling are at the heart of the lenet family of models. while the
exact details of the model will vary greatly, the    gure below shows a graphical depiction of a lenet model.

6.7. the full model: lenet

57

deep learning tutorial, release 0.1

the lower-layers are composed to alternating convolution and max-pooling layers. the upper-layers how-
ever are fully-connected and correspond to a traditional mlp (hidden layer + id28). the input
to the    rst fully-connected layer is the set of all features maps at the layer below.

from an implementation point of view, this means lower-layers operate on 4d tensors. these are then
   attened to a 2d matrix of rasterized feature maps, to be compatible with our previous mlp implementation.

note: note that the term    convolution    could corresponds to different mathematical operations:

1. theano.tensor.nnet.conv2d, which is the most common one in almost all of the recent published con-
volutional models. in this operation, each output feature map is connected to each input feature map
by a different 2d    lter, and its value is the sum of the individual convolution of all inputs through the
corresponding    lter.

2. the convolution used in the original lenet model: in this work, each output feature map is only

connected to a subset of input feature maps.

3. the convolution used in signal processing: theano.tensor.signal.conv.conv2d, which works only on

single channel inputs.

here, we use the    rst operation, so this models differ slightly from the original lenet paper. one reason to
use 2. would be to reduce the amount of computation needed, but modern hardware makes it as fast to have
the full connection pattern. another reason would be to slightly reduce the number of free parameters, but
we have other id173 techniques at our disposal.

6.8 putting it all together

we now have all we need to implement a lenet model in theano. we start with the lenetconvpoollayer
class, which implements a {convolution + max-pooling} layer.

class lenetconvpoollayer(object):

"""pool layer of a convolutional network """

def __init__(self, rng, input, filter_shape, image_shape, poolsize=(2, 2)):

"""
allocate a lenetconvpoollayer with shared variable internal parameters.

:type rng: numpy.random.randomstate
:param rng: a random number generator used to initialize weights

:type input: theano.tensor.dtensor4

58

chapter 6. convolutional neural networks (lenet)

deep learning tutorial, release 0.1

:param input: symbolic image tensor, of shape image_shape

:type filter_shape: tuple or list of length 4
:param filter_shape: (number of filters, num input feature maps,

filter height, filter width)

:type image_shape: tuple or list of length 4
:param image_shape: (batch size, num input feature maps,

image height, image width)

:type poolsize: tuple or list of length 2
:param poolsize: the downsampling (pooling) factor (#rows, #cols)
"""

assert image_shape[1] == filter_shape[1]
self.input = input

# there are "num input feature maps * filter height * filter width"
# inputs to each hidden unit
fan_in = numpy.prod(filter_shape[1:])
# each unit in the lower layer receives a gradient from:
# "num output feature maps * filter height * filter width" /
#
fan_out = (filter_shape[0] * numpy.prod(filter_shape[2:]) /

pooling size

numpy.prod(poolsize))

# initialize weights with random weights
w_bound = numpy.sqrt(6. / (fan_in + fan_out))
self.w = theano.shared(

numpy.asarray(

rng.uniform(low=-w_bound, high=w_bound, size=filter_shape),
dtype=theano.config.floatx

),
borrow=true

)

# the bias is a 1d tensor -- one bias per output feature map
b_values = numpy.zeros((filter_shape[0],), dtype=theano.config.floatx)
self.b = theano.shared(value=b_values, borrow=true)

# convolve input feature maps with filters
conv_out = conv.conv2d(

input=input,
filters=self.w,
filter_shape=filter_shape,
image_shape=image_shape

)

# downsample each feature map individually, using maxpooling
pooled_out = downsample.max_pool_2d(

input=conv_out,
ds=poolsize,
ignore_border=true

)

6.8. putting it all together

59

deep learning tutorial, release 0.1

# add the bias term. since the bias is a vector (1d array), we first
# reshape it to a tensor of shape (1, n_filters, 1, 1). each bias will
# thus be broadcasted across mini-batches and feature map
# width & height
self.output = t.tanh(pooled_out + self.b.dimshuffle(   x   , 0,    x   ,    x   ))

# store parameters of this layer
self.params = [self.w, self.b]

# keep track of model input
self.input = input

notice that when initializing the weight values, the fan-in is determined by the size of the receptive    elds
and the number of input feature maps.

finally, using the logisticregression class de   ned in classifying mnist digits using id28
and the hiddenlayer class de   ned in multilayer id88 , we can instantiate the network as follows.

x = t.matrix(   x   )
y = t.ivector(   y   )

# the data is presented as rasterized images
# the labels are presented as 1d vector of
# [int] labels

######################
# build actual model #
######################
print    ... building the model   

# reshape matrix of rasterized images of shape (batch_size, 28 * 28)
# to a 4d tensor, compatible with our lenetconvpoollayer
# (28, 28) is the size of mnist images.
layer0_input = x.reshape((batch_size, 1, 28, 28))

# construct the first convolutional pooling layer:
# filtering reduces the image size to (28-5+1 , 28-5+1) = (24, 24)
# maxpooling reduces this further to (24/2, 24/2) = (12, 12)
# 4d output tensor is thus of shape (batch_size, nkerns[0], 12, 12)
layer0 = lenetconvpoollayer(

rng,
input=layer0_input,
image_shape=(batch_size, 1, 28, 28),
filter_shape=(nkerns[0], 1, 5, 5),
poolsize=(2, 2)

)

# construct the second convolutional pooling layer
# filtering reduces the image size to (12-5+1, 12-5+1) = (8, 8)
# maxpooling reduces this further to (8/2, 8/2) = (4, 4)
# 4d output tensor is thus of shape (batch_size, nkerns[1], 4, 4)
layer1 = lenetconvpoollayer(

rng,
input=layer0.output,
image_shape=(batch_size, nkerns[0], 12, 12),
filter_shape=(nkerns[1], nkerns[0], 5, 5),

60

chapter 6. convolutional neural networks (lenet)

deep learning tutorial, release 0.1

poolsize=(2, 2)

)

# the hiddenlayer being fully-connected, it operates on 2d matrices of
# shape (batch_size, num_pixels) (i.e matrix of rasterized images).
# this will generate a matrix of shape (batch_size, nkerns[1] * 4 * 4),
# or (500, 50 * 4 * 4) = (500, 800) with the default values.
layer2_input = layer1.output.flatten(2)

# construct a fully-connected sigmoidal layer
layer2 = hiddenlayer(

rng,
input=layer2_input,
n_in=nkerns[1] * 4 * 4,
n_out=500,
activation=t.tanh

)

# classify the values of the fully-connected sigmoidal layer
layer3 = logisticregression(input=layer2.output, n_in=500, n_out=10)

# the cost we minimize during training is the nll of the model
cost = layer3.negative_log_likelihood(y)

# create a function to compute the mistakes that are made by the model
test_model = theano.function(

[index],
layer3.errors(y),
givens={

x: test_set_x[index * batch_size: (index + 1) * batch_size],
y: test_set_y[index * batch_size: (index + 1) * batch_size]

}

)

validate_model = theano.function(

[index],
layer3.errors(y),
givens={

x: valid_set_x[index * batch_size: (index + 1) * batch_size],
y: valid_set_y[index * batch_size: (index + 1) * batch_size]

}

)

# create a list of all model parameters to be fit by id119
params = layer3.params + layer2.params + layer1.params + layer0.params

# create a list of gradients for all model parameters
grads = t.grad(cost, params)

# train_model is a function that updates the model parameters by
# sgd since this model has many parameters, it would be tedious to
# manually create an update rule for each model parameter. we thus
# create the updates list by automatically looping over all

6.8. putting it all together

61

deep learning tutorial, release 0.1

# (params[i], grads[i]) pairs.
updates = [

(param_i, param_i - learning_rate * grad_i)
for param_i, grad_i in zip(params, grads)

]

train_model = theano.function(

[index],
cost,
updates=updates,
givens={

x: train_set_x[index * batch_size: (index + 1) * batch_size],
y: train_set_y[index * batch_size: (index + 1) * batch_size]

}

)

we leave out the code that performs the actual training and early-stopping, since it is exactly the same as
with an mlp. the interested reader can nevertheless access the code in the    code    folder of deeplearning-
tutorials.

6.9 running the code

the user can then run the code by calling:

python code/convolutional_mlp.py

the following output was obtained with the default parameters on a core i7-2600k cpu clocked at 3.40ghz
and using    ags       oatx=   oat32   :

optimization complete.
best validation score of 0.910000 % obtained at iteration 17800,with test
performance 0.920000 %
the code for file convolutional_mlp.py ran for 380.28m

using a geforce gtx 285, we obtained the following:

optimization complete.
best validation score of 0.910000 % obtained at iteration 15500,with test
performance 0.930000 %
the code for file convolutional_mlp.py ran for 46.76m

and similarly on a geforce gtx 480:

optimization complete.
best validation score of 0.910000 % obtained at iteration 16400,with test
performance 0.930000 %
the code for file convolutional_mlp.py ran for 32.52m

note that the discrepancies in validation and test error (as well as iteration count) are due to different imple-
mentations of the rounding mechanism in hardware. they can be safely ignored.

62

chapter 6. convolutional neural networks (lenet)

deep learning tutorial, release 0.1

6.10 tips and tricks

6.10.1 choosing hyperparameters

id98s are especially tricky to train, as they add even more hyper-parameters than a standard mlp. while
the usual rules of thumb for learning rates and id173 constants still apply, the following should be
kept in mind when optimizing id98s.

number of    lters

when choosing the number of    lters per layer, keep in mind that computing the activations of a single
convolutional    lter is much more expensive than with traditional mlps !
assume layer (l   1) contains kl   1 feature maps and m   n pixel positions (i.e., number of positions times
number of feature maps), and there are kl    lters at layer l of shape m    n. then computing a feature map
(applying an m    n    lter at all (m     m)    (n     n) pixel positions where the    lter can be applied) costs
(m     m)    (n     n)    m    n    kl   1. the total cost is kl times that. things may be more complicated if
not all features at one level are connected to all features at the previous one.
for a standard mlp, the cost would only be kl    kl   1 where there are kl different neurons at level l. as
such, the number of    lters used in id98s is typically much smaller than the number of hidden units in mlps
and depends on the size of the feature maps (itself a function of input image size and    lter shapes).

since feature map size decreases with depth, layers near the input layer will tend to have fewer    lters while
layers higher up can have much more. in fact, to equalize computation at each layer, the product of the
number of features and the number of pixel positions is typically picked to be roughly constant across
layers. to preserve the information about the input would require keeping the total number of activations
(number of feature maps times number of pixel positions) to be non-decreasing from one layer to the next
(of course we could hope to get away with less when we are doing supervised learning). the number of
feature maps directly controls capacity and so that depends on the number of available examples and the
complexity of the task.

filter shape

common    lter shapes found in the litterature vary greatly, usually based on the dataset. best results on
mnist-sized images (28x28) are usually in the 5x5 range on the    rst layer, while natural image datasets
(often with hundreds of pixels in each dimension) tend to use larger    rst-layer    lters of shape 12x12 or
15x15.

the trick is thus to    nd the right level of    granularity    (i.e.    lter shapes) in order to create abstractions at
the proper scale, given a particular dataset.

max pooling shape

typical values are 2x2 or no max-pooling. very large input images may warrant 4x4 pooling in the lower-
layers. keep in mind however, that this will reduce the dimension of the signal by a factor of 16, and may
result in throwing away too much information.

6.10. tips and tricks

63

deep learning tutorial, release 0.1

tips

if you want to try this model on a new dataset, here are a few tips that can help you get better results:

    whitening the data (e.g. with pca)

    decay the learning rate in each epoch

64

chapter 6. convolutional neural networks (lenet)

chapter
seven

denoising autoencoders (da)

note: this section assumes the reader has already read through classifying mnist digits using logistic
regression and multilayer id88. additionally it uses the following theano functions and concepts
: t.tanh, shared variables, basic arithmetic ops, t.grad, random numbers,    oatx. if you intend to run the
code on gpu also read gpu.

note: the code for this section is available for download here.

the denoising autoencoder (da) is an extension of a classical autoencoder and it was introduced as a
building block for deep networks in [vincent08]. we will start the tutorial with a short discussion on
autoencoders.

7.1 autoencoders

see section 4.6 of [bengio09] for an overview of auto-encoders. an autoencoder takes an input x     [0, 1]d
and    rst maps it (with an encoder) to a hidden representation y     [0, 1]d(cid:48)
through a deterministic mapping,
e.g.:

y = s(wx + b)

where s is a non-linearity such as the sigmoid. the latent representation y, or code is then mapped back
(with a decoder) into a reconstruction z of the same shape as x. the mapping happens through a similar
transformation, e.g.:

z = s(w(cid:48)y + b(cid:48))

(here, the prime symbol does not indicate matrix transposition.) z should be seen as a prediction of x,
given the code y. optionally, the weight matrix w(cid:48) of the reverse mapping may be constrained to be the
transpose of the forward mapping: w(cid:48) = wt . this is referred to as tied weights. the parameters of this
model (namely w, b, b(cid:48) and, if one doesn   t use tied weights, also w(cid:48)) are optimized such that the average
reconstruction error is minimized.

the reconstruction error can be measured in many ways, depending on the appropriate distributional as-
sumptions on the input given the code. the traditional squared error l(xz) = ||x     z||2, can be used. if

65

deep learning tutorial, release 0.1

the input is interpreted as either bit vectors or vectors of bit probabilities, cross-id178 of the reconstruction
can be used:

lh(x, z) =     d(cid:88)

[xk log zk + (1     xk) log(1     zk)]

k=1

the hope is that the code y is a distributed representation that captures the coordinates along the main
factors of variation in the data. this is similar to the way the projection on principal components would
capture the main factors of variation in the data. indeed, if there is one linear hidden layer (the code) and the
mean squared error criterion is used to train the network, then the k hidden units learn to project the input in
the span of the    rst k principal components of the data. if the hidden layer is non-linear, the auto-encoder
behaves differently from pca, with the ability to capture multi-modal aspects of the input distribution. the
departure from pca becomes even more important when we consider stacking multiple encoders (and their
corresponding decoders) when building a deep auto-encoder [hinton06].

because y is viewed as a lossy compression of x, it cannot be a good (small-loss) compression for all x.
optimization makes it a good compression for training examples, and hopefully for other inputs as well, but
not for arbitrary inputs. that is the sense in which an auto-encoder generalizes: it gives low reconstruction
error on test examples from the same distribution as the training examples, but generally high reconstruction
error on samples randomly chosen from the input space.

we want to implement an auto-encoder using theano, in the form of a class, that could be afterwards used
in constructing a stacked autoencoder. the    rst step is to create shared variables for the parameters of the
autoencoder w, b and b(cid:48). (since we are using tied weights in this tutorial, wt will be used for w(cid:48)):

def __init__(

self,
numpy_rng,
theano_rng=none,
input=none,
n_visible=784,
n_hidden=500,
w=none,
bhid=none,
bvis=none

):

"""
initialize the da class by specifying the number of visible units (the
dimension d of the input ), the number of hidden units ( the dimension
d    of the latent or hidden space ) and the corruption level. the
constructor also receives symbolic variables for the input, weights and
bias. such a symbolic variables are useful when, for example the input
is the result of some computations, or when weights are shared between
the da and an mlp layer. when dealing with sdas this always happens,
the da on layer 2 gets as input the output of the da on layer 1,
and the weights of the da are used in the second stage of training
to construct an mlp.

:type numpy_rng: numpy.random.randomstate
:param numpy_rng: number random generator used to generate weights

:type theano_rng: theano.tensor.shared_randomstreams.randomstreams

66

chapter 7. denoising autoencoders (da)

deep learning tutorial, release 0.1

:param theano_rng: theano random generator; if none is given one is

generated based on a seed drawn from    rng   

:type input: theano.tensor.tensortype
:param input: a symbolic description of the input or none for

standalone da

:type n_visible: int
:param n_visible: number of visible units

:type n_hidden: int
:param n_hidden: number of hidden units

:type w: theano.tensor.tensortype
:param w: theano variable pointing to a set of weights that should be
shared belong the da and another architecture; if da should
be standalone set this to none

:type bhid: theano.tensor.tensortype
:param bhid: theano variable pointing to a set of biases values (for

hidden units) that should be shared belong da and another
architecture; if da should be standalone set this to none

:type bvis: theano.tensor.tensortype
:param bvis: theano variable pointing to a set of biases values (for

visible units) that should be shared belong da and another
architecture; if da should be standalone set this to none

"""
self.n_visible = n_visible
self.n_hidden = n_hidden

# create a theano random generator that gives symbolic random values
if not theano_rng:

theano_rng = randomstreams(numpy_rng.randint(2 ** 30))

# note : w    was written as    w_prime    and b    as    b_prime   
if not w:

# w is initialized with    initial_w    which is uniformely sampled
# from -4*sqrt(6./(n_visible+n_hidden)) and
# 4*sqrt(6./(n_hidden+n_visible))the output of uniform if
# converted using asarray to dtype
# theano.config.floatx so that the code is runable on gpu
initial_w = numpy.asarray(

numpy_rng.uniform(

low=-4 * numpy.sqrt(6. / (n_hidden + n_visible)),
high=4 * numpy.sqrt(6. / (n_hidden + n_visible)),
size=(n_visible, n_hidden)

),
dtype=theano.config.floatx

)
w = theano.shared(value=initial_w, name=   w   , borrow=true)

7.1. autoencoders

67

deep learning tutorial, release 0.1

if not bvis:

bvis = theano.shared(

value=numpy.zeros(

n_visible,
dtype=theano.config.floatx

),
borrow=true

)

if not bhid:

bhid = theano.shared(

value=numpy.zeros(

n_hidden,
dtype=theano.config.floatx

),
name=   b   ,
borrow=true

)

self.w = w
# b corresponds to the bias of the hidden
self.b = bhid
# b_prime corresponds to the bias of the visible
self.b_prime = bvis
# tied weights, therefore w_prime is w transpose
self.w_prime = self.w.t
self.theano_rng = theano_rng
# if no input is given, generate a variable representing the input
if input is none:

# we use a matrix because we expect a minibatch of several
# examples, each example being a row
self.x = t.dmatrix(name=   input   )

else:

self.x = input

self.params = [self.w, self.b, self.b_prime]

note that we pass the symbolic input to the autoencoder as a parameter. this is so that we can concatenate
layers of autoencoders to form a deep network: the symbolic output (the y above) of layer k will be the
symbolic input of layer k + 1.

now we can express the computation of the latent representation and of the reconstructed signal:

def get_hidden_values(self, input):

""" computes the values of the hidden layer """
return t.nnet.sigmoid(t.dot(input, self.w) + self.b)

def get_reconstructed_input(self, hidden):

"""computes the reconstructed input given the values of the
hidden layer

"""
return t.nnet.sigmoid(t.dot(hidden, self.w_prime) + self.b_prime)

68

chapter 7. denoising autoencoders (da)

deep learning tutorial, release 0.1

and using these functions we can compute the cost and the updates of one stochastic id119 step :

def get_cost_updates(self, corruption_level, learning_rate):

""" this function computes the cost and the updates for one trainng
step of the da """

minibatches, l will be a vector, with one entry per
example in minibatch

tilde_x = self.get_corrupted_input(self.x, corruption_level)
y = self.get_hidden_values(tilde_x)
z = self.get_reconstructed_input(y)
# note : we sum over the size of a datapoint; if we are using
#
#
l = - t.sum(self.x * t.log(z) + (1 - self.x) * t.log(1 - z), axis=1)
# note : l is now a vector, where each element is the
#
#
#
#
cost = t.mean(l)

cross-id178 cost of the reconstruction of the
corresponding example of the minibatch. we need to
compute the average of all these to get the cost of
the minibatch

# compute the gradients of the cost of the    da    with respect
# to its parameters
gparams = t.grad(cost, self.params)
# generate the list of updates
updates = [

(param, param - learning_rate * gparam)
for param, gparam in zip(self.params, gparams)

]

return (cost, updates)

we can now de   ne a function that applied iteratively will update the parameters w, b and b_prime such
that the reconstruction cost is approximately minimized.

da = da(

numpy_rng=rng,
theano_rng=theano_rng,
input=x,
n_visible=28 * 28,
n_hidden=500

)

cost, updates = da.get_cost_updates(

corruption_level=0.,
learning_rate=learning_rate

)

train_da = theano.function(

[index],
cost,
updates=updates,
givens={

x: train_set_x[index * batch_size: (index + 1) * batch_size]

}

7.1. autoencoders

69

deep learning tutorial, release 0.1

)

start_time = timeit.default_timer()

############
# training #
############

# go through training epochs
for epoch in xrange(training_epochs):

# go through trainng set
c = []
for batch_index in xrange(n_train_batches):

c.append(train_da(batch_index))

print    training epoch %d, cost     % epoch, numpy.mean(c)

end_time = timeit.default_timer()

training_time = (end_time - start_time)

print >> sys.stderr, (   the no corruption code for file     +

os.path.split(__file__)[1] +
    ran for %.2fm    % ((training_time) / 60.))

image = image.fromarray(

tile_raster_images(x=da.w.get_value(borrow=true).t,

img_shape=(28, 28), tile_shape=(10, 10),
tile_spacing=(1, 1)))

image.save(   filters_corruption_0.png   )

# start-snippet-3
#####################################
# building the model corruption 30% #
#####################################

rng = numpy.random.randomstate(123)
theano_rng = randomstreams(rng.randint(2 ** 30))

da = da(

numpy_rng=rng,
theano_rng=theano_rng,
input=x,
n_visible=28 * 28,
n_hidden=500

)

cost, updates = da.get_cost_updates(

corruption_level=0.3,
learning_rate=learning_rate

)

train_da = theano.function(

[index],

70

chapter 7. denoising autoencoders (da)

deep learning tutorial, release 0.1

cost,
updates=updates,
givens={

x: train_set_x[index * batch_size: (index + 1) * batch_size]

}

)

start_time = timeit.default_timer()

############
# training #
############

# go through training epochs
for epoch in xrange(training_epochs):

# go through trainng set
c = []
for batch_index in xrange(n_train_batches):

c.append(train_da(batch_index))

print    training epoch %d, cost     % epoch, numpy.mean(c)

end_time = timeit.default_timer()

training_time = (end_time - start_time)

print >> sys.stderr, (   the 30% corruption code for file     +

os.path.split(__file__)[1] +
    ran for %.2fm    % (training_time / 60.))

# end-snippet-3

# start-snippet-4
image = image.fromarray(tile_raster_images(

x=da.w.get_value(borrow=true).t,
img_shape=(28, 28), tile_shape=(10, 10),
tile_spacing=(1, 1)))

image.save(   filters_corruption_30.png   )
# end-snippet-4

os.chdir(   ../   )

if __name__ ==    __main__   :

test_da()

if there is no constraint besides minimizing the reconstruction error, one might expect an auto-encoder with
n inputs and an encoding of dimension n (or greater) to learn the identity function, merely mapping an input
to its copy. such an autoencoder would not differentiate test examples (from the training distribution) from
other input con   gurations.

surprisingly, experiments reported in [bengio07] suggest that, in practice, when trained with stochastic
id119, non-linear auto-encoders with more hidden units than inputs (called overcomplete) yield
useful representations. (here,    useful    means that a network taking the encoding as input has low classi   -

7.1. autoencoders

71

deep learning tutorial, release 0.1

cation error.)

a simple explanation is that stochastic id119 with early stopping is similar to an l2 id173
of the parameters. to achieve perfect reconstruction of continuous inputs, a one-hidden layer auto-encoder
with non-linear hidden units (exactly like in the above code) needs very small weights in the    rst (encoding)
layer, to bring the non-linearity of the hidden units into their linear regime, and very large weights in the
second (decoding) layer. with binary inputs, very large weights are also needed to completely minimize
the reconstruction error. since the implicit or explicit id173 makes it dif   cult to reach large-weight
solutions, the optimization algorithm    nds encodings which only work well for examples similar to those in
the training set, which is what we want. it means that the representation is exploiting statistical regularities
present in the training set, rather than merely learning to replicate the input.

there are other ways by which an auto-encoder with more hidden units than inputs could be prevented from
learning the identity function, capturing something useful about the input in its hidden representation. one
is the addition of sparsity (forcing many of the hidden units to be zero or near-zero). sparsity has been ex-
ploited very successfully by many [ranzato07] [lee08]. another is to add randomness in the transformation
from input to reconstruction. this technique is used in restricted id82s (discussed later in
restricted id82s (rbm)), as well as in denoising auto-encoders, discussed below.

7.2 denoising autoencoders

the idea behind denoising autoencoders is simple. in order to force the hidden layer to discover more robust
features and prevent it from simply learning the identity, we train the autoencoder to reconstruct the input
from a corrupted version of it.

the denoising auto-encoder is a stochastic version of the auto-encoder. intuitively, a denoising auto-encoder
does two things: try to encode the input (preserve the information about the input), and try to undo the effect
of a corruption process stochastically applied to the input of the auto-encoder. the latter can only be done
by capturing the statistical dependencies between the inputs. the denoising auto-encoder can be understood
from different perspectives (the manifold learning perspective, stochastic operator perspective, bottom-up    
information theoretic perspective, top-down     generative model perspective), all of which are explained in
[vincent08]. see also section 7.2 of [bengio09] for an overview of auto-encoders.

in [vincent08], the stochastic corruption process randomly sets some of the inputs (as many as half of them)
to zero. hence the denoising auto-encoder is trying to predict the corrupted (i.e. missing) values from the
uncorrupted (i.e., non-missing) values, for randomly selected subsets of missing patterns. note how being
able to predict any subset of variables from the rest is a suf   cient condition for completely capturing the
joint distribution between a set of variables (this is how id150 works).

to convert the autoencoder class into a denoising autoencoder class, all we need to do is to add a stochastic
corruption step operating on the input. the input can be corrupted in many ways, but in this tutorial we will
stick to the original corruption mechanism of randomly masking entries of the input by making them zero.
the code below does just that :

def get_corrupted_input(self, input, corruption_level):

"""this function keeps       1-corruption_level       entries of the inputs the
same and zero-out randomly selected subset of size       coruption_level      
note : first argument of theano.rng.binomial is the shape(size) of

random numbers that it should produce
second argument is the number of trials

72

chapter 7. denoising autoencoders (da)

deep learning tutorial, release 0.1

third argument is the id203 of success of any trial

this will produce an array of 0s and 1s where 1 has a
id203 of 1 -       corruption_level       and 0 with
      corruption_level      

the binomial function return int64 data type by
default. int64 multiplicated by the input
to keep all data
type(floatx) always return float64.
in floatx when floatx is float32, we set the dtype of
the binomial to floatx. as in our case the value of
the binomial is always 0 or 1, this don   t change the
result. this is needed to allow the gpu to work
correctly as it only support float32 for now.

"""
return self.theano_rng.binomial(size=input.shape, n=1,

p=1 - corruption_level,
dtype=theano.config.floatx) * input

in the stacked autoencoder class (stacked autoencoders) the weights of the da class have to be shared with
those of a corresponding sigmoid layer. for this reason, the constructor of the da also gets theano variables
pointing to the shared parameters. if those parameters are left to none, new ones will be constructed.

the    nal denoising autoencoder class becomes :

class da(object):

"""denoising auto-encoder class (da)

a denoising autoencoders tries to reconstruct the input from a corrupted
version of it by projecting it first in a latent space and reprojecting
it afterwards back in the input space. please refer to vincent et al.,2008
for more details. if x is the input then equation (1) computes a partially
destroyed version of x by means of a stochastic mapping q_d. equation (2)
computes the projection of the input into the latent space. equation (3)
computes the reconstruction of the input, while equation (4) computes the
reconstruction error.

.. math::

\tilde{x} ~ q_d(\tilde{x}|x)

y = s(w \tilde{x} + b)

x = s(w    y + b   )

l(x,z) = -sum_{k=1}^d [x_k \log z_k + (1-x_k) \log( 1-z_k)]

(1)

(2)

(3)

(4)

"""

def __init__(

self,
numpy_rng,

7.2. denoising autoencoders

73

deep learning tutorial, release 0.1

theano_rng=none,
input=none,
n_visible=784,
n_hidden=500,
w=none,
bhid=none,
bvis=none

):

"""
initialize the da class by specifying the number of visible units (the
dimension d of the input ), the number of hidden units ( the dimension
d    of the latent or hidden space ) and the corruption level. the
constructor also receives symbolic variables for the input, weights and
bias. such a symbolic variables are useful when, for example the input
is the result of some computations, or when weights are shared between
the da and an mlp layer. when dealing with sdas this always happens,
the da on layer 2 gets as input the output of the da on layer 1,
and the weights of the da are used in the second stage of training
to construct an mlp.

:type numpy_rng: numpy.random.randomstate
:param numpy_rng: number random generator used to generate weights

:type theano_rng: theano.tensor.shared_randomstreams.randomstreams
:param theano_rng: theano random generator; if none is given one is

generated based on a seed drawn from    rng   

:type input: theano.tensor.tensortype
:param input: a symbolic description of the input or none for

standalone da

:type n_visible: int
:param n_visible: number of visible units

:type n_hidden: int
:param n_hidden: number of hidden units

:type w: theano.tensor.tensortype
:param w: theano variable pointing to a set of weights that should be
shared belong the da and another architecture; if da should
be standalone set this to none

:type bhid: theano.tensor.tensortype
:param bhid: theano variable pointing to a set of biases values (for

hidden units) that should be shared belong da and another
architecture; if da should be standalone set this to none

:type bvis: theano.tensor.tensortype
:param bvis: theano variable pointing to a set of biases values (for

visible units) that should be shared belong da and another
architecture; if da should be standalone set this to none

74

chapter 7. denoising autoencoders (da)

deep learning tutorial, release 0.1

"""
self.n_visible = n_visible
self.n_hidden = n_hidden

# create a theano random generator that gives symbolic random values
if not theano_rng:

theano_rng = randomstreams(numpy_rng.randint(2 ** 30))

# note : w    was written as    w_prime    and b    as    b_prime   
if not w:

# w is initialized with    initial_w    which is uniformely sampled
# from -4*sqrt(6./(n_visible+n_hidden)) and
# 4*sqrt(6./(n_hidden+n_visible))the output of uniform if
# converted using asarray to dtype
# theano.config.floatx so that the code is runable on gpu
initial_w = numpy.asarray(

numpy_rng.uniform(

low=-4 * numpy.sqrt(6. / (n_hidden + n_visible)),
high=4 * numpy.sqrt(6. / (n_hidden + n_visible)),
size=(n_visible, n_hidden)

),
dtype=theano.config.floatx

)
w = theano.shared(value=initial_w, name=   w   , borrow=true)

if not bvis:

bvis = theano.shared(

value=numpy.zeros(

n_visible,
dtype=theano.config.floatx

),
borrow=true

)

if not bhid:

bhid = theano.shared(

value=numpy.zeros(

n_hidden,
dtype=theano.config.floatx

),
name=   b   ,
borrow=true

)

self.w = w
# b corresponds to the bias of the hidden
self.b = bhid
# b_prime corresponds to the bias of the visible
self.b_prime = bvis
# tied weights, therefore w_prime is w transpose
self.w_prime = self.w.t
self.theano_rng = theano_rng
# if no input is given, generate a variable representing the input

7.2. denoising autoencoders

75

deep learning tutorial, release 0.1

if input is none:

# we use a matrix because we expect a minibatch of several
# examples, each example being a row
self.x = t.dmatrix(name=   input   )

else:

self.x = input

self.params = [self.w, self.b, self.b_prime]

def get_corrupted_input(self, input, corruption_level):

"""this function keeps       1-corruption_level       entries of the inputs the
same and zero-out randomly selected subset of size       coruption_level      
note : first argument of theano.rng.binomial is the shape(size) of

random numbers that it should produce
second argument is the number of trials
third argument is the id203 of success of any trial

this will produce an array of 0s and 1s where 1 has a
id203 of 1 -       corruption_level       and 0 with
      corruption_level      

the binomial function return int64 data type by
default. int64 multiplicated by the input
type(floatx) always return float64.
to keep all data
in floatx when floatx is float32, we set the dtype of
the binomial to floatx. as in our case the value of
the binomial is always 0 or 1, this don   t change the
result. this is needed to allow the gpu to work
correctly as it only support float32 for now.

"""
return self.theano_rng.binomial(size=input.shape, n=1,

p=1 - corruption_level,
dtype=theano.config.floatx) * input

def get_hidden_values(self, input):

""" computes the values of the hidden layer """
return t.nnet.sigmoid(t.dot(input, self.w) + self.b)

def get_reconstructed_input(self, hidden):

"""computes the reconstructed input given the values of the
hidden layer

"""
return t.nnet.sigmoid(t.dot(hidden, self.w_prime) + self.b_prime)

def get_cost_updates(self, corruption_level, learning_rate):

""" this function computes the cost and the updates for one trainng
step of the da """

tilde_x = self.get_corrupted_input(self.x, corruption_level)
y = self.get_hidden_values(tilde_x)
z = self.get_reconstructed_input(y)

76

chapter 7. denoising autoencoders (da)

deep learning tutorial, release 0.1

minibatches, l will be a vector, with one entry per
example in minibatch

# note : we sum over the size of a datapoint; if we are using
#
#
l = - t.sum(self.x * t.log(z) + (1 - self.x) * t.log(1 - z), axis=1)
# note : l is now a vector, where each element is the
#
#
#
#
cost = t.mean(l)

cross-id178 cost of the reconstruction of the
corresponding example of the minibatch. we need to
compute the average of all these to get the cost of
the minibatch

# compute the gradients of the cost of the    da    with respect
# to its parameters
gparams = t.grad(cost, self.params)
# generate the list of updates
updates = [

(param, param - learning_rate * gparam)
for param, gparam in zip(self.params, gparams)

]

return (cost, updates)

7.3 putting it all together

it is easy now to construct an instance of our da class and train it.

# allocate symbolic variables for the data
index = t.lscalar()
x = t.matrix(   x   )

# index to a [mini]batch

# the data is presented as rasterized images

#####################################
# building the model corruption 30% #
#####################################

rng = numpy.random.randomstate(123)
theano_rng = randomstreams(rng.randint(2 ** 30))

da = da(

numpy_rng=rng,
theano_rng=theano_rng,
input=x,
n_visible=28 * 28,
n_hidden=500

)

cost, updates = da.get_cost_updates(

corruption_level=0.3,
learning_rate=learning_rate

)

train_da = theano.function(

7.3. putting it all together

77

deep learning tutorial, release 0.1

[index],
cost,
updates=updates,
givens={

x: train_set_x[index * batch_size: (index + 1) * batch_size]

}

)

start_time = timeit.default_timer()

############
# training #
############

# go through training epochs
for epoch in xrange(training_epochs):

# go through trainng set
c = []
for batch_index in xrange(n_train_batches):

c.append(train_da(batch_index))

print    training epoch %d, cost     % epoch, numpy.mean(c)

end_time = timeit.default_timer()

training_time = (end_time - start_time)

print >> sys.stderr, (   the 30% corruption code for file     +

os.path.split(__file__)[1] +
    ran for %.2fm    % (training_time / 60.))

in order to get a feeling of what the network learned we are going to plot the    lters (de   ned by the weight
matrix). bear in mind, however, that this does not provide the entire story, since we neglect the biases and
plot the weights up to a multiplicative constant (weights are converted to values between 0 and 1).

to plot our    lters we will need the help of tile_raster_images (see plotting samples and filters) so
we urge the reader to study it. also using the help of the python image library, the following lines of code
will save the    lters as an image :

image = image.fromarray(tile_raster_images(

x=da.w.get_value(borrow=true).t,
img_shape=(28, 28), tile_shape=(10, 10),
tile_spacing=(1, 1)))

image.save(   filters_corruption_30.png   )

7.4 running the code

to run the code :

python da.py

78

chapter 7. denoising autoencoders (da)

the resulted    lters when we do not use any noise are :

deep learning tutorial, release 0.1

the    lters for 30 percent noise :

7.4. running the code

79

deep learning tutorial, release 0.1

80

chapter 7. denoising autoencoders (da)

chapter
eight

stacked denoising autoencoders (sda)

note: this section assumes you have already read through classifying mnist digits using logistic regres-
sion and multilayer id88. additionally it uses the following theano functions and concepts : t.tanh,
shared variables, basic arithmetic ops, t.grad, random numbers,    oatx. if you intend to run the code on
gpu also read gpu.

note: the code for this section is available for download here.

the stacked denoising autoencoder (sda) is an extension of the stacked autoencoder [bengio07] and it
was introduced in [vincent08].

this tutorial builds on the previous tutorial denoising autoencoders. especially if you do not have experi-
ence with autoencoders, we recommend reading it before going any further.

8.1 stacked autoencoders

denoising autoencoders can be stacked to form a deep network by feeding the latent representation (output
code) of the denoising autoencoder found on the layer below as input to the current layer. the unsupervised
pre-training of such an architecture is done one layer at a time. each layer is trained as a denoising
autoencoder by minimizing the error in reconstructing its input (which is the output code of the previous
layer). once the    rst k layers are trained, we can train the k + 1-th layer because we can now compute the
code or latent representation from the layer below.
once all layers are pre-trained, the network goes through a second stage of training called    ne-tuning. here
we consider supervised    ne-tuning where we want to minimize prediction error on a supervised task. for
this, we    rst add a id28 layer on top of the network (more precisely on the output code of the
output layer). we then train the entire network as we would train a multilayer id88. at this point, we
only consider the encoding parts of each auto-encoder. this stage is supervised, since now we use the target
class during training. (see the multilayer id88 for details on the multilayer id88.)

this can be easily implemented in theano, using the class de   ned previously for a denoising autoencoder.
we can see the stacked denoising autoencoder as having two facades: a list of autoencoders, and an mlp.
during pre-training we use the    rst facade, i.e., we treat our model as a list of autoencoders, and train each
autoencoder seperately. in the second stage of training, we use the second facade. these two facades are
linked because:

81

deep learning tutorial, release 0.1

    the autoencoders and the sigmoid layers of the mlp share parameters, and

    the latent representations computed by intermediate layers of the mlp are fed as input to the autoen-

coders.

class sda(object):

"""stacked denoising auto-encoder class (sda)

a stacked denoising autoencoder model is obtained by stacking several
das. the hidden layer of the da at layer    i    becomes the input of
the da at layer    i+1   . the first layer da gets as input the input of
the sda, and the hidden layer of the last da represents the output.
note that after pretraining, the sda is dealt with as a normal mlp,
the das are only used to initialize the weights.
"""

def __init__(

self,
numpy_rng,
theano_rng=none,
n_ins=784,
hidden_layers_sizes=[500, 500],
n_outs=10,
corruption_levels=[0.1, 0.1]

):

""" this class is made to support a variable number of layers.

:type numpy_rng: numpy.random.randomstate
:param numpy_rng: numpy random number generator used to draw initial

weights

:type theano_rng: theano.tensor.shared_randomstreams.randomstreams
:param theano_rng: theano random generator; if none is given one is

generated based on a seed drawn from    rng   

:type n_ins: int
:param n_ins: dimension of the input to the sda

:type n_layers_sizes: list of ints
:param n_layers_sizes: intermediate layers size, must contain

at least one value

:type n_outs: int
:param n_outs: dimension of the output of the network

:type corruption_levels: list of float
:param corruption_levels: amount of corruption to use for each

"""

layer

self.sigmoid_layers = []
self.da_layers = []
self.params = []
self.n_layers = len(hidden_layers_sizes)

82

chapter 8. stacked denoising autoencoders (sda)

deep learning tutorial, release 0.1

assert self.n_layers > 0

if not theano_rng:

theano_rng = randomstreams(numpy_rng.randint(2 ** 30))

# allocate symbolic variables for the data
self.x = t.matrix(   x   )
self.y = t.ivector(   y   )

# the data is presented as rasterized images

# the labels are presented as 1d vector of
# [int] labels

self.sigmoid_layers will store the sigmoid layers of the mlp facade, while self.da_layers
will store the denoising autoencoder associated with the layers of the mlp.

next, we construct n_layers sigmoid layers and n_layers denoising autoencoders, where n_layers
is the depth of our model. we use the hiddenlayer class introduced in multilayer id88, with one
modi   cation: we replace the tanh non-linearity with the logistic function s(x) = 1
1+e   x ). we link the
sigmoid layers to form an mlp, and construct the denoising autoencoders such that each shares the weight
matrix and the bias of its encoding part with its corresponding sigmoid layer.

for i in xrange(self.n_layers):

# construct the sigmoidal layer

# the size of the input is either the number of hidden units of
# the layer below or the input size if we are on the first layer
if i == 0:

input_size = n_ins

else:

input_size = hidden_layers_sizes[i - 1]

# the input to this layer is either the activation of the hidden
# layer below or the input of the sda if you are on the first
# layer
if i == 0:

layer_input = self.x

else:

layer_input = self.sigmoid_layers[-1].output

sigmoid_layer = hiddenlayer(rng=numpy_rng,

input=layer_input,
n_in=input_size,
n_out=hidden_layers_sizes[i],
activation=t.nnet.sigmoid)

# add the layer to our list of layers
self.sigmoid_layers.append(sigmoid_layer)
# its arguably a philosophical question...
# but we are going to only declare that the parameters of the
# sigmoid_layers are parameters of the stackeddaa
# the visible biases in the da are parameters of those
# da, but not the sda
self.params.extend(sigmoid_layer.params)

# construct a denoising autoencoder that shared weights with this
# layer
da_layer = da(numpy_rng=numpy_rng,

8.1. stacked autoencoders

83

deep learning tutorial, release 0.1

theano_rng=theano_rng,
input=layer_input,
n_visible=input_size,
n_hidden=hidden_layers_sizes[i],
w=sigmoid_layer.w,
bhid=sigmoid_layer.b)

self.da_layers.append(da_layer)

all we need now is to add a logistic layer on top of the sigmoid layers such that we have an mlp. we will
use the logisticregression class introduced in classifying mnist digits using id28.

# we now need to add a logistic layer on top of the mlp
self.loglayer = logisticregression(

input=self.sigmoid_layers[-1].output,
n_in=hidden_layers_sizes[-1],
n_out=n_outs

)

self.params.extend(self.loglayer.params)
# construct a function that implements one step of finetunining

# compute the cost for second phase of training,
# defined as the negative log likelihood
self.finetune_cost = self.loglayer.negative_log_likelihood(self.y)
# compute the gradients with respect to the model parameters
# symbolic variable that points to the number of errors made on the
# minibatch given by self.x and self.y
self.errors = self.loglayer.errors(self.y)

the sda class also provides a method that generates training functions for the denoising autoencoders in its
layers. they are returned as a list, where element i is a function that implements one step of training the da
corresponding to layer i.

def pretraining_functions(self, train_set_x, batch_size):

          generates a list of functions, each of them implementing one
step in trainnig the da corresponding to the layer with same index.
the function will require as input the minibatch index, and to train
a da you just need to iterate, calling the corresponding function on
all minibatch indexes.

:type train_set_x: theano.tensor.tensortype
:param train_set_x: shared variable that contains all datapoints used

for training the da

:type batch_size: int
:param batch_size: size of a [mini]batch

:type learning_rate: float
:param learning_rate: learning rate used during training for any of

the da layers

         

# index to a [mini]batch

84

chapter 8. stacked denoising autoencoders (sda)

deep learning tutorial, release 0.1

index = t.lscalar(   index   )

# index to a minibatch

to be able to change the corruption level or the learning rate during training, we associate theano variables
with them.

corruption_level = t.scalar(   corruption   )
learning_rate = t.scalar(   lr   )
# begining of a batch, given    index   
batch_begin = index * batch_size
# ending of a batch given    index   
batch_end = batch_begin + batch_size

# % of corruption to use

# learning rate to use

pretrain_fns = []
for da in self.da_layers:

# get the cost and the updates list
cost, updates = da.get_cost_updates(corruption_level,

learning_rate)

# compile the theano function
fn = theano.function(

inputs=[

index,
theano.param(corruption_level, default=0.2),
theano.param(learning_rate, default=0.1)

],
outputs=cost,
updates=updates,
givens={

self.x: train_set_x[batch_begin: batch_end]

}

)
# append    fn    to the list of functions
pretrain_fns.append(fn)

return pretrain_fns

now any function pretrain_fns[i] takes as arguments index and optionally corruption   the
corruption level or lr   the learning rate. note that the names of the parameters are the names given to the
theano variables when they are constructed, not the names of the python variables (learning_rate or
corruption_level). keep this in mind when working with theano.

in the same fashion we build a method for constructing the functions required during    netuning
(train_fn, valid_score and test_score).

def build_finetune_functions(self, datasets, batch_size, learning_rate):

         generates a function    train    that implements one step of
finetuning, a function    validate    that computes the error on
a batch from the validation set, and a function    test    that
computes the error on a batch from the testing set

:type datasets: list of pairs of theano.tensor.tensortype
:param datasets: it is a list that contain all the datasets;

the has to contain three pairs,    train   ,
   valid   ,    test    in this order, where each pair

8.1. stacked autoencoders

85

deep learning tutorial, release 0.1

is formed of two theano variables, one for the
datapoints, the other for the labels

:type batch_size: int
:param batch_size: size of a minibatch

:type learning_rate: float
:param learning_rate: learning rate used during finetune stage
         

(train_set_x, train_set_y) = datasets[0]
(valid_set_x, valid_set_y) = datasets[1]
(test_set_x, test_set_y) = datasets[2]

# compute number of minibatches for training, validation and testing
n_valid_batches = valid_set_x.get_value(borrow=true).shape[0]
n_valid_batches /= batch_size
n_test_batches = test_set_x.get_value(borrow=true).shape[0]
n_test_batches /= batch_size

index = t.lscalar(   index   )

# index to a [mini]batch

# compute the gradients with respect to the model parameters
gparams = t.grad(self.finetune_cost, self.params)

# compute list of fine-tuning updates
updates = [

(param, param - gparam * learning_rate)
for param, gparam in zip(self.params, gparams)

]

train_fn = theano.function(

inputs=[index],
outputs=self.finetune_cost,
updates=updates,
givens={

self.x: train_set_x[

index * batch_size: (index + 1) * batch_size

],
self.y: train_set_y[

index * batch_size: (index + 1) * batch_size

]

},
name=   train   

)

test_score_i = theano.function(

[index],
self.errors,
givens={

self.x: test_set_x[

index * batch_size: (index + 1) * batch_size

],

86

chapter 8. stacked denoising autoencoders (sda)

deep learning tutorial, release 0.1

self.y: test_set_y[

index * batch_size: (index + 1) * batch_size

]

},
name=   test   

)

valid_score_i = theano.function(

[index],
self.errors,
givens={

self.x: valid_set_x[

index * batch_size: (index + 1) * batch_size

],
self.y: valid_set_y[

index * batch_size: (index + 1) * batch_size

]

},
name=   valid   

)

# create a function that scans the entire validation set
def valid_score():

return [valid_score_i(i) for i in xrange(n_valid_batches)]

# create a function that scans the entire test set
def test_score():

return [test_score_i(i) for i in xrange(n_test_batches)]

return train_fn, valid_score, test_score

note that valid_score and test_score are not theano functions, but rather python functions that
loop over the entire validation set and the entire test set, respectively, producing a list of the losses over
these sets.

8.2 putting it all together

the few lines of code below construct the stacked denoising autoencoder:

numpy_rng = numpy.random.randomstate(89677)
print    ... building the model   
# construct the stacked denoising autoencoder class
sda = sda(

numpy_rng=numpy_rng,
n_ins=28 * 28,
hidden_layers_sizes=[1000, 1000, 1000],
n_outs=10

)

there are two stages of training for this network: layer-wise pre-training followed by    ne-tuning.

for the pre-training stage, we will loop over all the layers of the network. for each layer we will use the

8.2. putting it all together

87

deep learning tutorial, release 0.1

compiled theano function that implements a sgd step towards optimizing the weights for reducing the
reconstruction cost of that layer. this function will be applied to the training set for a    xed number of
epochs given by pretraining_epochs.

#########################
# pretraining the model #
#########################
print    ... getting the pretraining functions   
pretraining_fns = sda.pretraining_functions(train_set_x=train_set_x,

batch_size=batch_size)

print    ... pre-training the model   
start_time = timeit.default_timer()
## pre-train layer-wise
corruption_levels = [.1, .2, .3]
for i in xrange(sda.n_layers):

# go through pretraining epochs
for epoch in xrange(pretraining_epochs):

# go through the training set
c = []
for batch_index in xrange(n_train_batches):

c.append(pretraining_fns[i](index=batch_index,

corruption=corruption_levels[i],
lr=pretrain_lr))

print    pre-training layer %i, epoch %d, cost     % (i, epoch),
print numpy.mean(c)

end_time = timeit.default_timer()

print >> sys.stderr, (   the pretraining code for file     +

os.path.split(__file__)[1] +
    ran for %.2fm    % ((end_time - start_time) / 60.))

the    ne-tuning loop is very similar to the one in the multilayer id88. the only difference is that it
uses the functions given by build_finetune_functions.

8.3 running the code

the user can run the code by calling:

python code/sda.py

by default the code runs 15 pre-training epochs for each layer, with a batch size of 1. the corruption levels
are 0.1 for the    rst layer, 0.2 for the second, and 0.3 for the third. the pretraining learning rate is 0.001
and the    netuning learning rate is 0.1. pre-training takes 585.01 minutes, with an average of 13 minutes per
epoch. fine-tuning is completed after 36 epochs in 444.2 minutes, with an average of 12.34 minutes per
epoch. the    nal validation score is 1.39% with a testing score of 1.3%. these results were obtained on a
machine with an intel xeon e5430 @ 2.66ghz cpu, with a single-threaded gotoblas.

88

chapter 8. stacked denoising autoencoders (sda)

deep learning tutorial, release 0.1

8.4 tips and tricks

one way to improve the running time of your code (assuming you have suf   cient memory available), is to
compute how the network, up to layer k     1, transforms your data. namely, you start by training your    rst
layer da. once it is trained, you can compute the hidden units values for every datapoint in your dataset
and store this as a new dataset that you will use to train the da corresponding to layer 2. once you have
trained the da for layer 2, you compute, in a similar fashion, the dataset for layer 3 and so on. you can see
now, that at this point, the das are trained individually, and they just provide (one to the other) a non-linear
transformation of the input. once all das are trained, you can start    ne-tuning the model.

8.4. tips and tricks

89

deep learning tutorial, release 0.1

90

chapter 8. stacked denoising autoencoders (sda)

chapter
nine

restricted id82s (rbm)

note: this section assumes the reader has already read through classifying mnist digits using logistic
regression and multilayer id88. additionally it uses the following theano functions and concepts :
t.tanh, shared variables, basic arithmetic ops, t.grad, random numbers,    oatx and scan. if you intend to
run the code on gpu also read gpu.

note: the code for this section is available for download here.

9.1 energy-based models (ebm)

energy-based models associate a scalar energy to each con   guration of the variables of interest. learning
corresponds to modifying that energy function so that its shape has desirable properties. for example, we
would like plausible or desirable con   gurations to have low energy. energy-based probabilistic models
de   ne a id203 distribution through an energy function, as follows:

the normalizing factor z is called the partition function by analogy with physical systems.

.

(9.1)

z

p(x) = e   e(x)
z =(cid:88)

e   e(x)

x

an energy-based model can be learnt by performing (stochastic) id119 on the empirical negative
log-likelihood of the training data. as for the id28 we will    rst de   ne the log-likelihood and
then the id168 as being the negative log-likelihood.

(cid:88)

l(  ,d) =

log p(x(i))

1
n
(cid:96)(  ,d) =    l(  ,d)

x(i)   d

using the stochastic gradient         log p(x(i))

     

, where    are the parameters of the model.

91

deep learning tutorial, release 0.1

ebms with hidden units

in many cases of interest, we do not observe the example x fully, or we want to introduce some non-observed
variables to increase the expressive power of the model. so we consider an observed part (still denoted x
here) and a hidden part h. we can then write:

e   e(x,h)

z

.

(9.2)

in such cases, to map this formulation to one similar to eq. (9.1), we introduce the notation (inspired from
physics) of free energy, de   ned as follows:

p (x) =(cid:88)

p (x, h) =(cid:88)

h

h

f(x) =     log(cid:88)

e   e(x,h)

which allows us to write,

h

with z =(cid:88)

x

e   f (x).

p (x) = e   f (x)

z

the data negative log-likelihood gradient then has a particularly interesting form.

        log p(x)

     

=    f(x)

     

p(  x)    f(  x)

     

.

   (cid:88)

  x

(9.3)

(9.4)

notice that the above gradient contains two terms, which are referred to as the positive and negative phase.
the terms positive and negative do not refer to the sign of each term in the equation, but rather re   ect their
effect on the id203 density de   ned by the model. the    rst term increases the id203 of training
data (by reducing the corresponding free energy), while the second term decreases the id203 of samples
generated by the model.
it is usually dif   cult to determine this gradient analytically, as it involves the computation of ep [    f (x)
].
this is nothing less than an expectation over all possible con   gurations of the input x (under the distribution
p formed by the model) !

     

the    rst step in making this computation tractable is to estimate the expectation using a    xed number of
model samples. samples used to estimate the negative phase gradient are referred to as negative particles,
which are denoted as n . the gradient can then be written as:
    1
|n|

       f(x)

        log p(x)

   f(  x)
     

(cid:88)

(9.5)

     

     

.

  x   n

where we would ideally like elements   x of n to be sampled according to p (i.e. we are doing monte-
carlo). with the above formula, we almost have a pratical, stochastic algorithm for learning an ebm. the
only missing ingredient is how to extract these negative particles n . while the statistical literature abounds
with sampling methods, id115 methods are especially well suited for models such as
the restricted id82s (rbm), a speci   c type of ebm.

92

chapter 9. restricted id82s (rbm)

deep learning tutorial, release 0.1

9.2 restricted id82s (rbm)

id82s (bms) are a particular form of log-linear markov random field (mrf), i.e., for
which the energy function is linear in its free parameters. to make them powerful enough to represent
complicated distributions (i.e., go from the limited parametric setting to a non-parametric one), we consider
that some of the variables are never observed (they are called hidden). by having more hidden variables (also
called hidden units), we can increase the modeling capacity of the id82 (bm). restricted
id82s further restrict bms to those without visible-visible and hidden-hidden connections.
a graphical depiction of an rbm is shown below.

the energy function e(v, h) of an rbm is de   ned as:

e(v, h) =    b(cid:48)v     c(cid:48)h     h(cid:48)w v

(9.6)

where w represents the weights connecting hidden and visible units and b, c are the offsets of the visible
and hidden layers respectively.

this translates directly to the following free energy formula:

because of the speci   c structure of rbms, visible and hidden units are conditionally independent given
one-another. using this property, we can write:

ehi(ci+wiv).

log(cid:88)

hi

i

f(v) =    b(cid:48)v    (cid:88)
p(h|v) =(cid:89)
p(v|h) =(cid:89)

i

p(hi|v)
p(vj|h).

j

rbms with binary units
in the commonly studied case of using binary units (where vj and hi     {0, 1}), we obtain from eq. (9.6)
and (9.2), a probabilistic version of the usual neuron activation function:
p (hi = 1|v) = sigm(ci + wiv)

(9.7)

p (vj = 1|h) = sigm(bj + w (cid:48)
the free energy of an rbm with binary units further simpli   es to:

jh)

f(v) =    b(cid:48)v    (cid:88)

log(1 + e(ci+wiv)).

9.2. restricted id82s (rbm)

i

(9.8)

(9.9)

93

deep learning tutorial, release 0.1

update equations with binary units

combining eqs. (9.5) with (9.9), we obtain the following log-likelihood gradients for an rbm with binary
units:

       log p(v)
   wij
       log p(v)
       log p(v)

   ci

   bj

= ev[p(hi|v)    vj]     v(i)

j

   sigm(wi    v(i) + ci)

= ev[p(hi|v)]     sigm(wi    v(i))
= ev[p(vj|h)]     v(i)

j

(9.10)

for a more detailed derivation of these equations, we refer the reader to the following page, or to section 5
of learning deep architectures for ai. we will however not use these formulas, but rather get the gradient
using theano t.grad from equation (9.4).

9.3 sampling in an rbm

samples of p(x) can be obtained by running a markov chain to convergence, using id150 as the
transition operator.
id150 of the joint of n random variables s = (s1, ..., sn ) is done through a sequence of n
sampling sub-steps of the form si     p(si|s   i) where s   i contains the n     1 other random variables in s
excluding si.
for rbms, s consists of the set of visible and hidden units. however, since they are conditionally indepen-
dent, one can perform block id150. in this setting, visible units are sampled simultaneously given
   xed values of the hidden units. similarly, hidden units are sampled simultaneously given the visibles. a
step in the markov chain is thus taken as follows:

h(n+1)     sigm(w (cid:48)v(n) + c)
v(n+1)     sigm(w h(n+1) + b),

is randomly chosen to be 1 (versus 0) with id203 sigm(w (cid:48)

where h(n) refers to the set of all hidden units at the n-th step of the markov chain. what it means is that, for
example, h(n+1)
i v(n) + ci), and similarly,
v(n+1)
j
this can be illustrated graphically:

is randomly chosen to be 1 (versus 0) with id203 sigm(w.jh(n+1) + bj).

i

94

chapter 9. restricted id82s (rbm)

deep learning tutorial, release 0.1

as t        , samples (v(t), h(t)) are guaranteed to be accurate samples of p(v, h).
in theory, each parameter update in the learning process would require running one such chain to conver-
gence. it is needless to say that doing so would be prohibitively expensive. as such, several algorithms have
been devised for rbms, in order to ef   ciently sample from p(v, h) during the learning process.

9.3.1 contrastive divergence (cd-k)

contrastive divergence uses two tricks to speed up the sampling process:

    since we eventually want p(v)     ptrain(v) (the true, underlying distribution of the data), we initialize
the markov chain with a training example (i.e., from a distribution that is expected to be close to p, so
that the chain will be already close to having converged to its    nal distribution p).

    cd does not wait for the chain to converge. samples are obtained after only k-steps of id150.

in pratice, k = 1 has been shown to work surprisingly well.

9.3.2 persistent cd

persistent cd [tieleman08] uses another approximation for sampling from p(v, h). it relies on a single
markov chain, which has a persistent state (i.e., not restarting a chain for each observed example). for each
parameter update, we extract new samples by simply running the chain for k-steps. the state of the chain is
then preserved for subsequent updates.

the general intuition is that if parameter updates are small enough compared to the mixing rate of the chain,
the markov chain should be able to    catch up    to changes in the model.

9.4 implementation

we construct an rbm class. the parameters of the network can either be initialized by the constructor or can
be passed as arguments. this option is useful when an rbm is used as the building block of a deep network,
in which case the weight matrix and the hidden layer bias is shared with the corresponding sigmoidal layer
of an mlp network.

class rbm(object):

"""restricted id82 (rbm)
def __init__(

"""

self,
input=none,
n_visible=784,
n_hidden=500,
w=none,
hbias=none,
vbias=none,
numpy_rng=none,
theano_rng=none

):

"""
rbm constructor. defines the parameters of the model along with

9.4.

implementation

95

deep learning tutorial, release 0.1

basic operations for inferring hidden from visible (and vice-versa),
as well as for performing cd updates.

:param input: none for standalone rbms or symbolic variable if rbm is
part of a larger graph.

:param n_visible: number of visible units

:param n_hidden: number of hidden units

:param w: none for standalone rbms or symbolic variable pointing to a
shared weight matrix in case rbm is part of a dbn network; in a dbn,
the weights are shared between rbms and layers of a mlp

:param hbias: none for standalone rbms or symbolic variable pointing
to a shared hidden units bias vector in case rbm is part of a
different network

:param vbias: none for standalone rbms or a symbolic variable
pointing to a shared visible units bias
"""

self.n_visible = n_visible
self.n_hidden = n_hidden

if numpy_rng is none:

# create a number generator
numpy_rng = numpy.random.randomstate(1234)

if theano_rng is none:

theano_rng = randomstreams(numpy_rng.randint(2 ** 30))

if w is none:

# w is initialized with    initial_w    which is uniformely
# sampled from -4*sqrt(6./(n_visible+n_hidden)) and
# 4*sqrt(6./(n_hidden+n_visible)) the output of uniform if
# converted using asarray to dtype theano.config.floatx so
# that the code is runable on gpu
initial_w = numpy.asarray(

numpy_rng.uniform(

low=-4 * numpy.sqrt(6. / (n_hidden + n_visible)),
high=4 * numpy.sqrt(6. / (n_hidden + n_visible)),
size=(n_visible, n_hidden)

),
dtype=theano.config.floatx

)
# theano shared variables for weights and biases
w = theano.shared(value=initial_w, name=   w   , borrow=true)

if hbias is none:

# create shared variable for hidden units bias
hbias = theano.shared(
value=numpy.zeros(

96

chapter 9. restricted id82s (rbm)

deep learning tutorial, release 0.1

n_hidden,
dtype=theano.config.floatx

),
name=   hbias   ,
borrow=true

)

if vbias is none:

# create shared variable for visible units bias
vbias = theano.shared(
value=numpy.zeros(

n_visible,
dtype=theano.config.floatx

),
name=   vbias   ,
borrow=true

)

# initialize input layer for standalone rbm or layer0 of dbn
self.input = input
if not input:

self.input = t.matrix(   input   )

self.w = w
self.hbias = hbias
self.vbias = vbias
self.theano_rng = theano_rng
# **** warning: it is not a good idea to put things in this list
# other than shared variables created in this function.
self.params = [self.w, self.hbias, self.vbias]

next step is to de   ne functions which construct the symbolic graph associated with eqs. (9.7) - (9.8). the
code is as follows:

def propup(self, vis):

         this function propagates the visible units activation upwards to
the hidden units

note that we return also the pre-sigmoid activation of the
layer. as it will turn out later, due to how theano deals with
optimizations, this symbolic variable will be needed to write
down a more stable computational graph (see details in the
reconstruction cost function)

         
pre_sigmoid_activation = t.dot(vis, self.w) + self.hbias
return [pre_sigmoid_activation, t.nnet.sigmoid(pre_sigmoid_activation)]

def sample_h_given_v(self, v0_sample):

          this function infers state of hidden units given visible units          
# compute the activation of the hidden units given a sample of
# the visibles
pre_sigmoid_h1, h1_mean = self.propup(v0_sample)

9.4.

implementation

97

deep learning tutorial, release 0.1

# get a sample of the hiddens given their activation
# note that theano_rng.binomial returns a symbolic sample of dtype
# int64 by default. if we want to keep our computations in floatx
# for the gpu we need to specify to return the dtype floatx
h1_sample = self.theano_rng.binomial(size=h1_mean.shape,

n=1, p=h1_mean,
dtype=theano.config.floatx)

return [pre_sigmoid_h1, h1_mean, h1_sample]

def propdown(self, hid):

         this function propagates the hidden units activation downwards to
the visible units

note that we return also the pre_sigmoid_activation of the
layer. as it will turn out later, due to how theano deals with
optimizations, this symbolic variable will be needed to write
down a more stable computational graph (see details in the
reconstruction cost function)

         
pre_sigmoid_activation = t.dot(hid, self.w.t) + self.vbias
return [pre_sigmoid_activation, t.nnet.sigmoid(pre_sigmoid_activation)]

def sample_v_given_h(self, h0_sample):

          this function infers state of visible units given hidden units          
# compute the activation of the visible given the hidden sample
pre_sigmoid_v1, v1_mean = self.propdown(h0_sample)
# get a sample of the visible given their activation
# note that theano_rng.binomial returns a symbolic sample of dtype
# int64 by default. if we want to keep our computations in floatx
# for the gpu we need to specify to return the dtype floatx
v1_sample = self.theano_rng.binomial(size=v1_mean.shape,

return [pre_sigmoid_v1, v1_mean, v1_sample]

n=1, p=v1_mean,
dtype=theano.config.floatx)

we can then use these functions to de   ne the symbolic graph for a id150 step. we de   ne two
functions:

    gibbs_vhv which performs a step of id150 starting from the visible units. as we shall

see, this will be useful for sampling from the rbm.

    gibbs_hvh which performs a step of id150 starting from the hidden units. this function

will be useful for performing cd and pcd updates.

the code is as follows:

def gibbs_hvh(self, h0_sample):

          this function implements one step of id150,

starting from the hidden state         

pre_sigmoid_v1, v1_mean, v1_sample = self.sample_v_given_h(h0_sample)
pre_sigmoid_h1, h1_mean, h1_sample = self.sample_h_given_v(v1_sample)
return [pre_sigmoid_v1, v1_mean, v1_sample,
pre_sigmoid_h1, h1_mean, h1_sample]

98

chapter 9. restricted id82s (rbm)

deep learning tutorial, release 0.1

def gibbs_vhv(self, v0_sample):

          this function implements one step of id150,

starting from the visible state         

pre_sigmoid_h1, h1_mean, h1_sample = self.sample_h_given_v(v0_sample)
pre_sigmoid_v1, v1_mean, v1_sample = self.sample_v_given_h(h1_sample)
return [pre_sigmoid_h1, h1_mean, h1_sample,
pre_sigmoid_v1, v1_mean, v1_sample]

# start-snippet-2

note that we also return the pre-sigmoid activation. to understand why this is so you need to understand a
bit about how theano works. whenever you compile a theano function, the computational graph that you
pass as input gets optimized for speed and stability. this is done by changing several parts of the subgraphs
with others. one such optimization expresses terms of the form log(sigmoid(x)) in terms of softplus. we
need this optimization for the cross-id178 since sigmoid of numbers larger than 30. (or even less then
that) turn to 1. and numbers smaller than -30. turn to 0 which in terms will force theano to compute log(0)
and therefore we will get either -inf or nan as cost. if the value is expressed in terms of softplus we do not
get this undesirable behaviour. this optimization usually works    ne, but here we have a special case. the
sigmoid is applied inside the scan op, while the log is outside. therefore theano will only see log(scan(..))
instead of log(sigmoid(..)) and will not apply the wanted optimization. we can not go and replace the
sigmoid in scan with something else also, because this only needs to be done on the last step. therefore the
easiest and more ef   cient way is to get also the pre-sigmoid activation as an output of scan, and apply both
the log and sigmoid outside scan such that theano can catch and optimize the expression.

the class also has a function that computes the free energy of the model, needed for computing the gradient
of the parameters (see eq. (9.4)). note that we also return the pre-sigmoid

def free_energy(self, v_sample):

          function to compute the free energy          
wx_b = t.dot(v_sample, self.w) + self.hbias
vbias_term = t.dot(v_sample, self.vbias)
hidden_term = t.sum(t.log(1 + t.exp(wx_b)), axis=1)
return -hidden_term - vbias_term

we then add a get_cost_updates method, whose purpose is to generate the symbolic gradients for
cd-k and pcd-k updates.

def get_cost_updates(self, lr=0.1, persistent=none, k=1):

"""this functions implements one step of cd-k or pcd-k

:param lr: learning rate used to train the rbm

:param persistent: none for cd. for pcd, shared variable

containing old state of gibbs chain. this must be a shared
variable of size (batch size, number of hidden units).

:param k: number of gibbs steps to do in cd-k/pcd-k

returns a proxy for the cost and the updates dictionary. the
dictionary contains the update rules for weights and biases but
also an update of the shared variable used to store the persistent
chain, if one is used.

9.4.

implementation

99

deep learning tutorial, release 0.1

"""

# compute positive phase
pre_sigmoid_ph, ph_mean, ph_sample = self.sample_h_given_v(self.input)

# decide how to initialize persistent chain:
# for cd, we use the newly generate hidden sample
# for pcd, we initialize from the old state of the chain
if persistent is none:

chain_start = ph_sample

else:

chain_start = persistent

note that get_cost_updates takes as argument a variable called persistent. this allows us to use
the same code to implement both cd and pcd. to use pcd, persistent should refer to a shared variable
which contains the state of the gibbs chain from the previous iteration.

if persistent is none, we initialize the gibbs chain with the hidden sample generated during the positive
phase, therefore implementing cd. once we have established the starting point of the chain, we can then
compute the sample at the end of the gibbs chain, sample that we need for getting the gradient (see eq.
(9.4)). to do so, we will use the scan op provided by theano, therefore we urge the reader to look it up by
following this link.

# perform actual negative phase
# in order to implement cd-k/pcd-k we need to scan over the
# function that implements one gibbs step k times.
# read theano tutorial on scan for more information :
# http://deeplearning.net/software/theano/library/scan.html
# the scan will return the entire gibbs chain
(

[

pre_sigmoid_nvs,
nv_means,
nv_samples,
pre_sigmoid_nhs,
nh_means,
nh_samples

],
updates

) = theano.scan(

self.gibbs_hvh,
# the none are place holders, saying that
# chain_start is the initial state corresponding to the
# 6th output
outputs_info=[none, none, none, none, none, chain_start],
n_steps=k

)

once we have the generated the chain we take the sample at the end of the chain to get the free energy of the
negative phase. note that the chain_end is a symbolical theano variable expressed in terms of the model
parameters, and if we would apply t.grad naively, the function will try to go through the gibbs chain to
get the gradients. this is not what we want (it will mess up our gradients) and therefore we need to indicate

100

chapter 9. restricted id82s (rbm)

deep learning tutorial, release 0.1

to t.grad that chain_end is a constant. we do this by using the argument consider_constant of
t.grad.

# determine gradients on rbm parameters
# note that we only need the sample at the end of the chain
chain_end = nv_samples[-1]

cost = t.mean(self.free_energy(self.input)) - t.mean(

self.free_energy(chain_end))

# we must not compute the gradient through the id150
gparams = t.grad(cost, self.params, consider_constant=[chain_end])

finally, we add to the updates dictionary returned by scan (which contains updates rules for random states
of theano_rng) to contain the parameter updates. in the case of pcd, these should also update the shared
variable containing the state of the gibbs chain.

# constructs the update dictionary
for gparam, param in zip(gparams, self.params):

# make sure that the learning rate is of the right dtype
updates[param] = param - gparam * t.cast(

lr,
dtype=theano.config.floatx

)

if persistent:

# note that this works only if persistent is a shared variable
updates[persistent] = nh_samples[-1]
# pseudo-likelihood is a better proxy for pcd
monitoring_cost = self.get_pseudo_likelihood_cost(updates)

else:

# reconstruction cross-id178 is a better proxy for cd
monitoring_cost = self.get_reconstruction_cost(updates,

pre_sigmoid_nvs[-1])

return monitoring_cost, updates

9.4.1 tracking progress

rbms are particularly tricky to train. because of the partition function z of eq. (9.1), we cannot estimate
the log-likelihood log(p (x)) during training. we therefore have no direct useful metric for choosing the
optimal hyperparameters.

several options are available to the user.
inspection of negative samples

negative samples obtained during training can be visualized. as training progresses, we know that the
model de   ned by the rbm becomes closer to the true underlying distribution, ptrain(x). negative samples
should thus look like samples from the training set. obviously bad hyperparameters can be discarded in this
fashion.
visual inspection of filters

the    lters learnt by the model can be visualized. this amounts to plotting the weights of each unit as a

9.4.

implementation

101

deep learning tutorial, release 0.1

gray-scale image (after reshaping to a square matrix). filters should pick out strong features in the data.
while it is not clear for an arbitrary dataset, what these features should look like, training on mnist usually
results in    lters which act as stroke detectors, while training on natural images lead to gabor like    lters if
trained in conjunction with a sparsity criteria.
proxies to likelihood

other, more tractable functions can be used as a proxy to the likelihood. when training an rbm with pcd,
one can use pseudo-likelihood as the proxy. pseudo-likelihood (pl) is much less expensive to compute, as
it assumes that all bits are independent. therefore,

p l(x) =(cid:89)
log p l(x) =(cid:88)

i

p (xi|x   i) and
log p (xi|x   i)

i

here x   i denotes the set of all bits of x except bit i. the log-pl is therefore the sum of the log-probabilities
of each bit xi, conditioned on the state of all other bits. for mnist, this would involve summing over the
784 input dimensions, which remains rather expensive. for this reason, we use the following stochastic
approximation to log-pl:

g = n    log p (xi|x   i), where i     u(0, n), , and
e[g] = log p l(x)

where the expectation is taken over the uniform random choice of index i, and n is the number of visible
units. in order to work with binary units, we further introduce the notation   xi to refer to x with bit-i being
   ipped (1->0, 0->1). the log-pl for an rbm with binary units is then written as:

log p l(x)     n    log

e   f e(x)

e   f e(x) + e   f e(  xi)

    n    log[sigm(f e(  xi)     f e(x))]

we therefore return this cost as well as the rbm updates in the get_cost_updates function of the rbm
class. notice that we modify the updates dictionary to increment the index of bit i. this will result in bit i
cycling over all possible values {0, 1, ..., n}, from one update to another.
note that for cd training the cross-id178 cost between the input and the reconstruction (the same as the
one used for the de-noising autoencoder) is more reliable then the pseudo-loglikelihood. here is the code
we use to compute the pseudo-likelihood:

def get_pseudo_likelihood_cost(self, updates):

"""stochastic approximation to the pseudo-likelihood"""

# index of bit i in expression p(x_i | x_{\i})
bit_i_idx = theano.shared(value=0, name=   bit_i_idx   )

# binarize the input image by rounding to nearest integer
xi = t.round(self.input)

102

chapter 9. restricted id82s (rbm)

deep learning tutorial, release 0.1

# calculate free energy for the given bit configuration
fe_xi = self.free_energy(xi)

# flip bit x_i of matrix xi and preserve all other bits x_{\i}
# equivalent to xi[:,bit_i_idx] = 1-xi[:, bit_i_idx], but assigns
# the result to xi_flip, instead of working in place on xi.
xi_flip = t.set_subtensor(xi[:, bit_i_idx], 1 - xi[:, bit_i_idx])

# calculate free energy with bit flipped
fe_xi_flip = self.free_energy(xi_flip)

# equivalent to e^(-fe(x_i)) / (e^(-fe(x_i)) + e^(-fe(x_{\i})))
cost = t.mean(self.n_visible * t.log(t.nnet.sigmoid(fe_xi_flip -

fe_xi)))

# increment bit_i_idx % number as part of updates
updates[bit_i_idx] = (bit_i_idx + 1) % self.n_visible

return cost

9.4.2 main loop

we now have all the necessary ingredients to start training our network.

before going over the training loop however, the reader should familiarize himself with the function
tile_raster_images (see plotting samples and filters). since rbms are generative models, we
are interested in sampling from them and plotting/visualizing these samples. we also want to visualize the
   lters (weights) learnt by the rbm, to gain insights into what the rbm is actually doing. bear in mind
however, that this does not provide the entire story, since we neglect the biases and plot the weights up to a
multiplicative constant (weights are converted to values between 0 and 1).

having these utility functions, we can start training the rbm and plot/save the    lters after each training
epoch. we train the rbm using pcd, as it has been shown to lead to a better generative model ([tiele-
man08]).

# it is ok for a theano function to have no output
# the purpose of train_rbm is solely to update the rbm parameters
train_rbm = theano.function(

[index],
cost,
updates=updates,
givens={

x: train_set_x[index * batch_size: (index + 1) * batch_size]

},
name=   train_rbm   

)

plotting_time = 0.
start_time = timeit.default_timer()

# go through training epochs

9.4.

implementation

103

deep learning tutorial, release 0.1

for epoch in xrange(training_epochs):

# go through the training set
mean_cost = []
for batch_index in xrange(n_train_batches):

mean_cost += [train_rbm(batch_index)]

print    training epoch %d, cost is     % epoch, numpy.mean(mean_cost)

# plot filters after each training epoch
plotting_start = timeit.default_timer()
# construct image from the weight matrix
image = image.fromarray(

tile_raster_images(

x=rbm.w.get_value(borrow=true).t,
img_shape=(28, 28),
tile_shape=(10, 10),
tile_spacing=(1, 1)

)

)
image.save(   filters_at_epoch_%i.png    % epoch)
plotting_stop = timeit.default_timer()
plotting_time += (plotting_stop - plotting_start)

end_time = timeit.default_timer()

pretraining_time = (end_time - start_time) - plotting_time

print (   training took %f minutes    % (pretraining_time / 60.))

once the rbm is trained, we can then use the gibbs_vhv function to implement the gibbs chain required
for sampling. we initialize the gibbs chain starting from test examples (although we could as well pick it
from the training set) in order to speed up convergence and avoid problems with random initialization. we
again use theano   s scan op to do 1000 steps before each plotting.

sampling from the rbm

#################################
#
#
#################################
# find out the number of test samples
number_of_test_samples = test_set_x.get_value(borrow=true).shape[0]

# pick random test examples, with which to initialize the persistent chain
test_idx = rng.randint(number_of_test_samples - n_chains)
persistent_vis_chain = theano.shared(

numpy.asarray(

test_set_x.get_value(borrow=true)[test_idx:test_idx + n_chains],
dtype=theano.config.floatx

)

)

next we create the 20 persistent chains in parallel to get our samples. to do so, we compile a theano function
which performs one gibbs step and updates the state of the persistent chain with the new visible sample. we
apply this function iteratively for a large number of steps, plotting the samples at every 1000 steps.

104

chapter 9. restricted id82s (rbm)

deep learning tutorial, release 0.1

plot_every = 1000
# define one step of id150 (mf = mean-field) define a
# function that does    plot_every    steps before returning the
# sample for plotting
(

[

presig_hids,
hid_mfs,
hid_samples,
presig_vis,
vis_mfs,
vis_samples

],
updates

) = theano.scan(

rbm.gibbs_vhv,
outputs_info=[none, none, none, none, none, persistent_vis_chain],
n_steps=plot_every

)

# add to updates the shared variable that takes care of our persistent
# chain :.
updates.update({persistent_vis_chain: vis_samples[-1]})
# construct the function that implements our persistent chain.
# we generate the "mean field" activations for plotting and the actual
# samples for reinitializing the state of our persistent chain
sample_fn = theano.function(

[],
[

vis_mfs[-1],
vis_samples[-1]

],
updates=updates,
name=   sample_fn   

)

# create a space to store the image for plotting ( we need to leave
# room for the tile_spacing as well)
image_data = numpy.zeros(

(29 * n_samples + 1, 29 * n_chains - 1),
dtype=   uint8   

)
for idx in xrange(n_samples):

# generate    plot_every    intermediate samples that we discard,
# because successive samples in the chain are too correlated
vis_mf, vis_sample = sample_fn()
print     ... plotting sample    , idx
image_data[29 * idx:29 * idx + 28, :] = tile_raster_images(

x=vis_mf,
img_shape=(28, 28),
tile_shape=(1, n_chains),
tile_spacing=(1, 1)

)

9.4.

implementation

105

deep learning tutorial, release 0.1

# construct image
image = image.fromarray(image_data)
image.save(   samples.png   )

9.5 results

we ran the code with pcd-15, learning rate of 0.1 and a batch size of 20, for 15 epochs. training the model
takes 122.466 minutes on a intel xeon e5430 @ 2.66ghz cpu, with a single-threaded gotoblas.

the output was the following:

... loading data
training epoch 0, cost is -90.6507246003
training epoch 1, cost is -81.235857373
training epoch 2, cost is -74.9120966945
training epoch 3, cost is -73.0213216101
training epoch 4, cost is -68.4098570497
training epoch 5, cost is -63.2693021647
training epoch 6, cost is -65.99578971
training epoch 7, cost is -68.1236650015
training epoch 8, cost is -68.3207365087
training epoch 9, cost is -64.2949797113
training epoch 10, cost is -61.5194867893
training epoch 11, cost is -61.6539369402
training epoch 12, cost is -63.5465278086
training epoch 13, cost is -63.3787093527
training epoch 14, cost is -62.755739271
training took 122.466000 minutes

... plotting sample 0
... plotting sample 1
... plotting sample 2
... plotting sample 3
... plotting sample 4
... plotting sample 5
... plotting sample 6
... plotting sample 7
... plotting sample 8
... plotting sample 9

the pictures below show the    lters after 15 epochs :

here are the samples generated by the rbm after training. each row represents a mini-batch of negative
particles (samples from independent gibbs chains). 1000 steps of id150 were taken between each
of those rows.

106

chapter 9. restricted id82s (rbm)

deep learning tutorial, release 0.1

figure 9.1: filters obtained after 15 epochs.

9.5. results

107

deep learning tutorial, release 0.1

108

chapter 9. restricted id82s (rbm)

chapter
ten

id50

note: this section assumes the reader has already read through classifying mnist digits using logistic
regression and multilayer id88 and restricted id82s (rbm). additionally it uses the
following theano functions and concepts : t.tanh, shared variables, basic arithmetic ops, t.grad, random
numbers,    oatx. if you intend to run the code on gpu also read gpu.

note: the code for this section is available for download here.

10.1 id50

(cid:32)(cid:96)   2(cid:89)

(cid:33)

[hinton06] showed that rbms can be stacked and trained in a greedy manner to form so-called deep belief
networks (dbn). dbns are id114 which learn to extract a deep hierarchical representation of
the training data. they model the joint distribution between observed vector x and the (cid:96) hidden layers hk as
follows:

p (x, h1, . . . , h(cid:96)) =

p (hk|hk+1)

p (h(cid:96)   1, h(cid:96))

(10.1)

k=0

where x = h0, p (hk   1|hk) is a conditional distribution for the visible units conditioned on the hidden units
of the rbm at level k, and p (h(cid:96)   1, h(cid:96)) is the visible-hidden joint distribution in the top-level rbm. this is
illustrated in the    gure below.

the principle of greedy layer-wise unsupervised training can be applied to dbns with rbms as the building
blocks for each layer [hinton06], [bengio07]. the process is as follows:

1. train the    rst layer as an rbm that models the raw input x = h(0) as its visible layer.

2. use that    rst layer to obtain a representation of the input that will be used as data for the second layer. two
common solutions exist. this representation can be chosen as being the mean activations p(h(1) = 1|h(0))
or samples of p(h(1)|h(0)).
3. train the second layer as an rbm, taking the transformed data (samples or mean activations) as training
examples (for the visible layer of that rbm).

4. iterate (2 and 3) for the desired number of layers, each time propagating upward either samples or mean
values.

109

deep learning tutorial, release 0.1

5. fine-tune all the parameters of this deep architecture with respect to a proxy for the dbn log- likelihood,
or with respect to a supervised training criterion (after adding extra learning machinery to convert the learned
representation into supervised predictions, e.g. a linear classi   er).

in this tutorial, we focus on    ne-tuning via supervised id119. speci   cally, we use a logistic
regression classi   er to classify the input x based on the output of the last hidden layer h(l) of the dbn.
fine-tuning is then performed via supervised id119 of the negative log-likelihood cost function.
since the supervised gradient is only non-null for the weights and hidden layer biases of each layer (i.e.
null for the visible biases of each rbm), this procedure is equivalent to initializing the parameters of a deep
mlp with the weights and hidden layer biases obtained with the unsupervised training strategy.

10.2 justifying greedy-layer wise pre-training

why does such an algorithm work ? taking as example a 2-layer dbn with hidden layers h(1) and h(2) (with
respective weight parameters w (1) and w (2)), [hinton06] established (see also bengio09]_ for a detailed
derivation) that log p(x) can be rewritten as,

log p(x) =kl(q(h(1)|x)||p(h(1)|x)) + hq(h(1)|x)+
q(h(1)|x)(log p(h(1)) + log p(x|h(1))).

(cid:88)

(10.2)

h

kl(q(h(1)|x)||p(h(1)|x)) represents the kl divergence between the posterior q(h(1)|x) of the    rst rbm
if it were standalone, and the id203 p(h(1)|x) for the same layer but de   ned by the entire dbn (i.e.
taking into account the prior p(h(1), h(2)) de   ned by the top-level rbm). hq(h(1)|x) is the id178 of the
distribution q(h(1)|x).
it can be shown that if we initialize both hidden layers such that w (2) = w (1)t , q(h(1)|x) = p(h(1)|x)
and the kl divergence term is null. if we learn the    rst level rbm and then keep its parameters w (1)    xed,
optimizing eq. (10.2) with respect to w (2) can thus only increase the likelihood p(x).

110

chapter 10. id50

deep learning tutorial, release 0.1

also, notice that if we isolate the terms which depend only on w (2), we get:

(cid:88)

q(h(1)|x)p(h(1))

h

optimizing this with respect to w (2) amounts to training a second-stage rbm, using the output of q(h(1)|x)
as the training distribution, when x is sampled from the training distribution for the    rst rbm.

10.3 implementation

to implement dbns in theano, we will use the class de   ned in the restricted id82s (rbm)
tutorial. one can also observe that the code for the dbn is very similar with the one for sda, because both
involve the principle of unsupervised layer-wise pre-training followed by supervised    ne-tuning as a deep
mlp. the main difference is that we use the rbm class instead of the da class.

we start off by de   ning the dbn class which will store the layers of the mlp, along with their associated
rbms. since we take the viewpoint of using the rbms to initialize an mlp, the code will re   ect this by
seperating as much as possible the rbms used to initialize the network and the mlp used for classi   cation.

class dbn(object):

"""deep belief network

a deep belief network is obtained by stacking several rbms on top of each
other. the hidden layer of the rbm at layer    i    becomes the input of the
rbm at layer    i+1   . the first layer rbm gets as input the input of the
network, and the hidden layer of the last rbm represents the output. when
used for classification, the dbn is treated as a mlp, by adding a logistic
regression layer on top.
"""

def __init__(self, numpy_rng, theano_rng=none, n_ins=784,

hidden_layers_sizes=[500, 500], n_outs=10):

"""this class is made to support a variable number of layers.

:type numpy_rng: numpy.random.randomstate
:param numpy_rng: numpy random number generator used to draw initial

weights

:type theano_rng: theano.tensor.shared_randomstreams.randomstreams
:param theano_rng: theano random generator; if none is given one is

generated based on a seed drawn from    rng   

:type n_ins: int
:param n_ins: dimension of the input to the dbn

:type hidden_layers_sizes: list of ints
:param hidden_layers_sizes: intermediate layers size, must contain

at least one value

:type n_outs: int

10.3.

implementation

111

deep learning tutorial, release 0.1

:param n_outs: dimension of the output of the network
"""

self.sigmoid_layers = []
self.rbm_layers = []
self.params = []
self.n_layers = len(hidden_layers_sizes)

assert self.n_layers > 0

if not theano_rng:

theano_rng = mrg_randomstreams(numpy_rng.randint(2 ** 30))

# allocate symbolic variables for the data
self.x = t.matrix(   x   )
self.y = t.ivector(   y   )

# the data is presented as rasterized images

# the labels are presented as 1d vector
# of [int] labels

self.sigmoid_layers will store the feed-forward graphs which together form the mlp, while
self.rbm_layers will store the rbms used to pretrain each layer of the mlp.

next step, we construct n_layers sigmoid layers (we use the hiddenlayer class introduced in mul-
tilayer id88, with the only modi   cation that we replaced the non-linearity from tanh to the logistic
function s(x) = 1
1+e   x ) and n_layers rbms, where n_layers is the depth of our model. we link the
sigmoid layers such that they form an mlp, and construct each rbm such that they share the weight matrix
and the hidden bias with its corresponding sigmoid layer.

for i in xrange(self.n_layers):

# construct the sigmoidal layer

# the size of the input is either the number of hidden
# units of the layer below or the input size if we are on
# the first layer
if i == 0:

input_size = n_ins

else:

input_size = hidden_layers_sizes[i - 1]

# the input to this layer is either the activation of the
# hidden layer below or the input of the dbn if you are on
# the first layer
if i == 0:

layer_input = self.x

else:

layer_input = self.sigmoid_layers[-1].output

sigmoid_layer = hiddenlayer(rng=numpy_rng,

input=layer_input,
n_in=input_size,
n_out=hidden_layers_sizes[i],
activation=t.nnet.sigmoid)

# add the layer to our list of layers

112

chapter 10. id50

deep learning tutorial, release 0.1

self.sigmoid_layers.append(sigmoid_layer)

# its arguably a philosophical question...
# going to only declare that the parameters of the
# sigmoid_layers are parameters of the dbn. the visible
# biases in the rbm are parameters of those rbms, but not
# of the dbn.
self.params.extend(sigmoid_layer.params)

but we are

# construct an rbm that shared weights with this layer
rbm_layer = rbm(numpy_rng=numpy_rng,

theano_rng=theano_rng,
input=layer_input,
n_visible=input_size,
n_hidden=hidden_layers_sizes[i],
w=sigmoid_layer.w,
hbias=sigmoid_layer.b)

self.rbm_layers.append(rbm_layer)

all that is left is to stack one last id28 layer in order to form an mlp. we will use the
logisticregression class introduced in classifying mnist digits using id28.

self.loglayer = logisticregression(

input=self.sigmoid_layers[-1].output,
n_in=hidden_layers_sizes[-1],
n_out=n_outs)

self.params.extend(self.loglayer.params)

# compute the cost for second phase of training, defined as the
# negative log likelihood of the id28 (output) layer
self.finetune_cost = self.loglayer.negative_log_likelihood(self.y)

# compute the gradients with respect to the model parameters
# symbolic variable that points to the number of errors made on the
# minibatch given by self.x and self.y
self.errors = self.loglayer.errors(self.y)

the class also provides a method which generates training functions for each of the rbms. they are returned
as a list, where element i is a function which implements one step of training for the rbm at layer i.

def pretraining_functions(self, train_set_x, batch_size, k):

         generates a list of functions, for performing one step of
id119 at a given layer. the function will require
as input the minibatch index, and to train an rbm you just
need to iterate, calling the corresponding function on all
minibatch indexes.

:type train_set_x: theano.tensor.tensortype
:param train_set_x: shared var. that contains all datapoints used

for training the rbm

:type batch_size: int
:param batch_size: size of a [mini]batch
:param k: number of gibbs steps to do in cd-k / pcd-k

10.3.

implementation

113

deep learning tutorial, release 0.1

         

# index to a [mini]batch
index = t.lscalar(   index   )

# index to a minibatch

in order to be able to change the learning rate during training, we associate a theano variable to it that has
a default value.

learning_rate = t.scalar(   lr   )

# learning rate to use

# number of batches
n_batches = train_set_x.get_value(borrow=true).shape[0] / batch_size
# begining of a batch, given    index   
batch_begin = index * batch_size
# ending of a batch given    index   
batch_end = batch_begin + batch_size

pretrain_fns = []
for rbm in self.rbm_layers:

# get the cost and the updates list
# using cd-k here (persisent=none) for training each rbm.
# todo: change cost function to reconstruction error
cost, updates = rbm.get_cost_updates(learning_rate,

persistent=none, k=k)

# compile the theano function
fn = theano.function(

inputs=[index, theano.param(learning_rate, default=0.1)],
outputs=cost,
updates=updates,
givens={

self.x: train_set_x[batch_begin:batch_end]

}

)
# append    fn    to the list of functions
pretrain_fns.append(fn)

return pretrain_fns

now any function pretrain_fns[i] takes as arguments index and optionally lr     the learning rate.
note that the names of the parameters are the names given to the theano variables (e.g. lr) when they are
constructed and not the name of the python variables (e.g. learning_rate). keep this in mind when
working with theano. optionally, if you provide k (the number of gibbs steps to perform in cd or pcd)
this will also become an argument of your function.

in the same fashion, the dbn class includes a method for building the functions required for    netuning ( a
train_model, a validate_model and a test_model function).

def build_finetune_functions(self, datasets, batch_size, learning_rate):

         generates a function    train    that implements one step of
finetuning, a function    validate    that computes the error on a
batch from the validation set, and a function    test    that

114

chapter 10. id50

deep learning tutorial, release 0.1

computes the error on a batch from the testing set

:type datasets: list of pairs of theano.tensor.tensortype
:param datasets: it is a list that contain all the datasets;

the has to contain three pairs,    train   ,
   valid   ,    test    in this order, where each pair
is formed of two theano variables, one for the
datapoints, the other for the labels

:type batch_size: int
:param batch_size: size of a minibatch
:type learning_rate: float
:param learning_rate: learning rate used during finetune stage

         

(train_set_x, train_set_y) = datasets[0]
(valid_set_x, valid_set_y) = datasets[1]
(test_set_x, test_set_y) = datasets[2]

# compute number of minibatches for training, validation and testing
n_valid_batches = valid_set_x.get_value(borrow=true).shape[0]
n_valid_batches /= batch_size
n_test_batches = test_set_x.get_value(borrow=true).shape[0]
n_test_batches /= batch_size

index = t.lscalar(   index   )

# index to a [mini]batch

# compute the gradients with respect to the model parameters
gparams = t.grad(self.finetune_cost, self.params)

# compute list of fine-tuning updates
updates = []
for param, gparam in zip(self.params, gparams):

updates.append((param, param - gparam * learning_rate))

train_fn = theano.function(

inputs=[index],
outputs=self.finetune_cost,
updates=updates,
givens={

self.x: train_set_x[

index * batch_size: (index + 1) * batch_size

],
self.y: train_set_y[

index * batch_size: (index + 1) * batch_size

]

}

)

test_score_i = theano.function(

[index],
self.errors,
givens={

10.3.

implementation

115

deep learning tutorial, release 0.1

self.x: test_set_x[

index * batch_size: (index + 1) * batch_size

],
self.y: test_set_y[

index * batch_size: (index + 1) * batch_size

]

}

)

valid_score_i = theano.function(

[index],
self.errors,
givens={

self.x: valid_set_x[

index * batch_size: (index + 1) * batch_size

],
self.y: valid_set_y[

index * batch_size: (index + 1) * batch_size

]

}

)

# create a function that scans the entire validation set
def valid_score():

return [valid_score_i(i) for i in xrange(n_valid_batches)]

# create a function that scans the entire test set
def test_score():

return [test_score_i(i) for i in xrange(n_test_batches)]

return train_fn, valid_score, test_score

note that the returned valid_score and test_score are not theano functions, but rather python
functions. these loop over the entire validation set and the entire test set to produce a list of the losses
obtained over these sets.

10.4 putting it all together

the few lines of code below constructs the deep belief network :

numpy_rng = numpy.random.randomstate(123)
print    ... building the model   
# construct the deep belief network
dbn = dbn(numpy_rng=numpy_rng, n_ins=28 * 28,

hidden_layers_sizes=[1000, 1000, 1000],
n_outs=10)

there are two stages in training this network: (1) a layer-wise pre-training and (2) a    ne-tuning stage.

for the pre-training stage, we loop over all the layers of the network. for each layer, we use the com-
piled theano function which determines the input to the i-th level rbm and performs one step of cd-

116

chapter 10. id50

deep learning tutorial, release 0.1

k within this rbm. this function is applied to the training set for a    xed number of epochs given by
pretraining_epochs.

#########################
# pretraining the model #
#########################
print    ... getting the pretraining functions   
pretraining_fns = dbn.pretraining_functions(train_set_x=train_set_x,

batch_size=batch_size,
k=k)

print    ... pre-training the model   
start_time = timeit.default_timer()
## pre-train layer-wise
for i in xrange(dbn.n_layers):

# go through pretraining epochs
for epoch in xrange(pretraining_epochs):

# go through the training set
c = []
for batch_index in xrange(n_train_batches):

c.append(pretraining_fns[i](index=batch_index,

lr=pretrain_lr))

print    pre-training layer %i, epoch %d, cost     % (i, epoch),
print numpy.mean(c)

end_time = timeit.default_timer()

the    ne-tuning loop is very similar to the one in the multilayer id88 tutorial, the only difference being
that we now use the functions given by build_finetune_functions.

10.5 running the code

the user can run the code by calling:

python code/dbn.py

with the default parameters, the code runs for 100 pre-training epochs with mini-batches of size 10. this
corresponds to performing 500,000 unsupervised parameter updates. we use an unsupervised learning rate
of 0.01, with a supervised learning rate of 0.1. the dbn itself consists of three hidden layers with 1000
units per layer. with early-stopping, this con   guration achieved a minimal validation error of 1.27 with
corresponding test error of 1.34 after 46 supervised epochs.

on an intel(r) xeon(r) cpu x5560 running at 2.80ghz, using a multi-threaded mkl library (running on
4 cores), pretraining took 615 minutes with an average of 2.05 mins/(layer * epoch). fine-tuning took only
101 minutes or approximately 2.20 mins/epoch.

hyper-parameters were selected by optimizing on the validation error. we tested unsupervised learning
rates in {10   1, ..., 10   5} and supervised learning rates in {10   1, ..., 10   4}. we did not use any form of
id173 besides early-stopping, nor did we optimize over the number of pretraining updates.

10.5. running the code

117

deep learning tutorial, release 0.1

10.6 tips and tricks

one way to improve the running time of your code (given that you have suf   cient memory available), is
to compute the representation of the entire dataset at layer i in a single pass, once the weights of the
i     1-th layers have been    xed. namely, start by training your    rst layer rbm. once it is trained, you can
compute the hidden units values for every example in the dataset and store this as a new dataset which is
used to train the 2nd layer rbm. once you trained the rbm for layer 2, you compute, in a similar fashion,
the dataset for layer 3 and so on. this avoids calculating the intermediate (hidden layer) representations,
pretraining_epochs times at the expense of increased memory usage.

118

chapter 10. id50

chapter
eleven

hybrid monte-carlo sampling

note: this is an advanced tutorial, which shows how one can implemented hybrid monte-carlo (hmc)
sampling using theano. we assume the reader is already familiar with theano and energy-based models
such as the rbm.

note: the code for this section is available for download here.

11.1 theory

maximum likelihood learning of energy-based models requires a robust algorithm to sample negative phase
particles (see eq.(4) of the restricted id82s (rbm) tutorial). when training rbms with cd
or pcd, this is typically done with block id150, where the conditional distributions p(h|v) and
p(v|h) are used as the transition operators of the markov chain.
in certain cases however, these conditional distributions might be dif   cult to sample from (i.e. requiring
expensive matrix inversions, as in the case of the    mean-covariance rbm   ). also, even if id150
can be done ef   ciently, it nevertheless operates via a random walk which might not be statistically ef   cient
for some distributions. in this context, and when sampling from continuous variables, hybrid monte carlo
(hmc) can prove to be a powerful tool [duane87]. it avoids random walk behavior by simulating a phys-
ical system governed by hamiltonian dynamics, potentially avoiding tricky conditional distributions in the
process.

in hmc, model samples are obtained by simulating a physical system, where particles move about a high-
dimensional landscape, subject to potential and kinetic energies. adapting the notation from [neal93],
particles are characterized by a position vector or state s     rd and velocity vector        rd. the combined
state of a particle is denoted as    = (s,   ). the hamiltonian is then de   ned as the sum of potential energy
e(s) (same energy function de   ned by energy-based models) and kinetic energy k(  ), as follows:

h(s,   ) = e(s) + k(  ) = e(s) +

1
2

(cid:88)

i

  2
i

instead of sampling p(s) directly, hmc operates by sampling from the canonical distribution p(s,   ) =
z exp(   h(s,   )) = p(s)p(  ). because the two variables are independent, marginalizing over    is trivial
1
and recovers the original distribution of interest.
hamiltonian dynamics

119

deep learning tutorial, release 0.1

state s and velocity    are modi   ed such that h(s,   ) remains constant throughout the simulation. the
differential equations are given by:

=    h
=        h

     i

   si

=   i
=        e
   si

dsi
dt
d  i
dt

(11.1)

as shown in [neal93], the above transformation preserves volume and is reversible. the above dynamics
can thus be used as transition operators of a markov chain and will leave p(s,   ) invariant. that chain by
itself is not ergodic however, since simulating the dynamics maintains a    xed hamiltonian h(s,   ). hmc
thus alternates hamiltonian dynamic steps, with id150 of the velocity. because p(s) and p(  ) are
independent, sampling   new     p(  |s) is trivial since p(  |s) = p(  ), where p(  ) is often taken to be the
uni-variate gaussian.
the leap-frog algorithm

in practice, we cannot simulate hamiltonian dynamics exactly because of the problem of time discretization.
there are several ways one can do this. to maintain invariance of the markov chain however, care must be
taken to preserve the properties of volume conservation and time reversibility. the leap-frog algorithm
maintains these properties and operates in 3 steps:

  i(t +  /2) =   i(t)      
2

   
   si

e(s(t))

si(t +  ) = si(t) +    i(t +  /2)
  i(t +  ) =   i(t +  /2)      
   
2
   si

e(s(t +  ))

(11.2)

we thus perform a half-step update of the velocity at time t +  /2, which is then used to compute s(t +  )
and   (t +  ).
accept / reject
in practice, using    nite stepsizes   will not preserve h(s,   ) exactly and will introduce bias in the simulation.
also, rounding errors due to the use of    oating point numbers means that the above transformation will not
be perfectly reversible.
hmc cancels these effects exactly by adding a metropolis accept/reject stage, after n leapfrog steps. the
new state   (cid:48) = (s(cid:48),   (cid:48)) is accepted with id203 pacc(  ,   (cid:48)), de   ned as:
exp(   h(s(cid:48),   (cid:48))
exp(   h(s,   )

pacc(  ,   (cid:48)) = min

(cid:19)

(cid:18)

1,

hmc algorithm

in this tutorial, we obtain a new hmc sample as follows:

1. sample a new velocity from a univariate gaussian distribution
2. perform n leapfrog steps to obtain the new state   (cid:48)
3. perform accept/reject move of   (cid:48)

120

chapter 11. hybrid monte-carlo sampling

deep learning tutorial, release 0.1

11.2 implementing hmc using theano

in theano, update dictionaries and shared variables provide a natural way to implement a sampling algo-
rithm. the current state of the sampler can be represented as a theano shared variable, with hmc updates
being implemented by the updates list of a theano function.

we breakdown the hmc algorithm into the following sub-components:

    simulate_dynamics: a symbolic python function which, given an initial position and velocity, will
perform n_steps leapfrog updates and return the symbolic variables for the proposed state   (cid:48).
    hmc_move: a symbolic python function which given a starting position, generates    by randomly
sampling a velocity vector. it then calls simulate_dynamics and determines whether the transition
         (cid:48) is to be accepted.
    hmc_updates: a python function which, given the symbolic outputs of hmc_move, generates the list

of updates for a single iteration of hmc.

    hm c_sampler: a python helper class which wraps everything together.

simulate_dynamics

to perform n leapfrog steps, we    rst need to de   ne a function over which scan can iterate over. instead
of implementing eq. (11.2) verbatim, notice that we can obtain s(t + n ) and   (t + n ) by performing an
initial half-step update for   , followed by n full-step updates for s,    and one last half-step update for   . in
loop form, this gives:

  i(t +  /2) =   i(t)      
2
si(t +  ) = si(t) +    i(t +  /2)
for m     [2, n], perform full updates:

e(s(t))

   
   si

  i(t + (m     1/2) ) =   i(t + (m     3/2) )      
si(t + m ) = si(t) +    i(t + (m     1/2) )

   
   si

  i(t + n ) =   i(t + (n     1/2) )      
2

   
   si

e(s(t + n ))

e(s(t + (m     1) ))

(11.3)

the inner-loop de   ned above is implemented by the following leapf rog function, with pos, vel and step
replacing s,    and   respectively.

def leapfrog(pos, vel, step):

"""
inside loop of scan. performs one step of leapfrog update, using
hamiltonian dynamics.

parameters
----------
pos: theano matrix

in leapfrog update equations, represents pos(t), position at time t

vel: theano matrix

in leapfrog update equations, represents vel(t - stepsize/2),
velocity at time (t - stepsize/2)

11.2.

implementing hmc using theano

121

deep learning tutorial, release 0.1

step: theano scalar

scalar value controlling amount by which to move

returns
-------
rval1: [theano matrix, theano matrix]

symbolic theano matrices for new position pos(t + stepsize), and
velocity vel(t + stepsize/2)

rval2: dictionary

dictionary of updates for the scan op

"""
# from pos(t) and vel(t-stepsize/2), compute vel(t+stepsize/2)
de_dpos = tt.grad(energy_fn(pos).sum(), pos)
new_vel = vel - step * de_dpos
# from vel(t+stepsize/2) compute pos(t+stepsize)
new_pos = pos + step * new_vel
return [new_pos, new_vel], {}

# compute velocity at time-step: t + stepsize/2

the simulatedynamics function performs the full algorithm of eqs. (11.3). we start with the initial half-
step update of    and full-step of s, and then scan over the leapf rog method n_steps     1 times.
def simulate_dynamics(initial_pos, initial_vel, stepsize, n_steps, energy_fn):

"""
return final (position, velocity) obtained after an    n_steps    leapfrog
updates, using hamiltonian dynamics.

parameters
----------
initial_pos: shared theano matrix

initial position at which to start the simulation

initial_vel: shared theano matrix
initial velocity of particles

stepsize: shared theano scalar

scalar value controlling amount by which to move

energy_fn: python function

python function, operating on symbolic theano variables, used to
compute the potential energy at a given position.

returns
-------
rval1: theano matrix

final positions obtained after simulation

rval2: theano matrix

final velocity obtained after simulation

"""

def leapfrog(pos, vel, step):

"""
inside loop of scan. performs one step of leapfrog update, using
hamiltonian dynamics.

122

chapter 11. hybrid monte-carlo sampling

deep learning tutorial, release 0.1

parameters
----------
pos: theano matrix

in leapfrog update equations, represents pos(t), position at time t

vel: theano matrix

in leapfrog update equations, represents vel(t - stepsize/2),
velocity at time (t - stepsize/2)

step: theano scalar

scalar value controlling amount by which to move

returns
-------
rval1: [theano matrix, theano matrix]

symbolic theano matrices for new position pos(t + stepsize), and
velocity vel(t + stepsize/2)

rval2: dictionary

dictionary of updates for the scan op

"""
# from pos(t) and vel(t-stepsize/2), compute vel(t+stepsize/2)
de_dpos = tt.grad(energy_fn(pos).sum(), pos)
new_vel = vel - step * de_dpos
# from vel(t+stepsize/2) compute pos(t+stepsize)
new_pos = pos + step * new_vel
return [new_pos, new_vel], {}

# compute velocity at time-step: t + stepsize/2
initial_energy = energy_fn(initial_pos)
de_dpos = tt.grad(initial_energy.sum(), initial_pos)
vel_half_step = initial_vel - 0.5 * stepsize * de_dpos

# compute position at time-step: t + stepsize
pos_full_step = initial_pos + stepsize * vel_half_step

# perform leapfrog updates: the scan op is used to repeatedly compute
# vel(t + (m-1/2)*stepsize) and pos(t + m*stepsize) for m in [2,n_steps].
(all_pos, all_vel), scan_updates = theano.scan(

leapfrog,
outputs_info=[

dict(initial=pos_full_step),
dict(initial=vel_half_step),

],
non_sequences=[stepsize],
n_steps=n_steps - 1)

final_pos = all_pos[-1]
final_vel = all_vel[-1]
# note: scan always returns an updates dictionary, in case the
# scanned function draws samples from a randomstream. these
# updates must then be used when compiling the theano function, to
# avoid drawing the same random numbers each time the function is
# called. in this case however, we consciously ignore
# "scan_updates" because we know it is empty.
assert not scan_updates

11.2.

implementing hmc using theano

123

deep learning tutorial, release 0.1

# the last velocity returned by scan is vel(t +
# (n_steps - 1 / 2) * stepsize) we therefore perform one more half-step
# to return vel(t + n_steps * stepsize)
energy = energy_fn(final_pos)
final_vel = final_vel - 0.5 * stepsize * tt.grad(energy.sum(), final_pos)

# return new proposal state
return final_pos, final_vel

# start-snippet-1
a    nal half-step is performed to compute   (t + n ), and the    nal proposed state   (cid:48) is returned.
hmc_move

the hmc_move function implements the remaining steps (steps 1 and 3) of an hmc move proposal (while
wrapping the simulate_dynamics function). given a matrix of initial states s     rn  d (positions) and
energy function e(s) (energy_f n), it de   nes the symbolic graph for computing n_steps of hmc, using a
given stepsize. the function prototype is as follows:

def hmc_move(s_rng, positions, energy_fn, stepsize, n_steps):

"""
this function performs one-step of hybrid monte-carlo sampling. we start by
sampling a random velocity from a univariate gaussian distribution, perform
   n_steps    leap-frog updates using hamiltonian dynamics and accept-reject
using metropolis-hastings.

parameters
----------
s_rng: theano shared random stream

symbolic random number generator used to draw random velocity and
perform accept-reject move.
positions: shared theano matrix

symbolic matrix whose rows are position vectors.

energy_fn: python function

python function, operating on symbolic theano variables, used to
compute the potential energy at a given position.

stepsize: shared theano scalar

shared variable containing the stepsize to use for    n_steps    of hmc
simulation steps.

n_steps: integer

number of hmc steps to perform before proposing a new position.

returns
-------
rval1: boolean

true if move is accepted, false otherwise

rval2: theano matrix

matrix whose rows contain the proposed "new position"

"""

we start by sampling random velocities, using the provided shared randomstream object. velocities are
sampled independently for each dimension and for each particle under simulation, yielding a n    d matrix.

124

chapter 11. hybrid monte-carlo sampling

deep learning tutorial, release 0.1

# sample random velocity
initial_vel = s_rng.normal(size=positions.shape)

since we now have an initial position and velocity, we can now call the simulate_dynamics to obtain the
proposal for the new state   (cid:48).

# perform simulation of particles subject to hamiltonian dynamics
final_pos, final_vel = simulate_dynamics(

initial_pos=positions,
initial_vel=initial_vel,
stepsize=stepsize,
n_steps=n_steps,
energy_fn=energy_fn

)

we then accept/reject the proposed state based on the metropolis algorithm.

# accept/reject the proposed move based on the joint distribution
accept = metropolis_hastings_accept(

energy_prev=hamiltonian(positions, initial_vel, energy_fn),
energy_next=hamiltonian(final_pos, final_vel, energy_fn),
s_rng=s_rng

)

where metropolis_hastings_accept and hamiltonian are helper functions, de   ned as follows.

def metropolis_hastings_accept(energy_prev, energy_next, s_rng):

"""
performs a metropolis-hastings accept-reject move.

parameters
----------
energy_prev: theano vector

symbolic theano tensor which contains the energy associated with the
configuration at time-step t.

energy_next: theano vector

symbolic theano tensor which contains the energy associated with the
proposed configuration at time-step t+1.

s_rng: theano.tensor.shared_randomstreams.randomstreams

theano shared random stream object used to generate the random number
used in proposal.

returns
-------
return: boolean

true if move is accepted, false otherwise

"""
ediff = energy_prev - energy_next
return (tt.exp(ediff) - s_rng.uniform(size=energy_prev.shape)) >= 0

def hamiltonian(pos, vel, energy_fn):

"""
returns the hamiltonian (sum of potential and kinetic energy) for the given
velocity and position.

11.2.

implementing hmc using theano

125

deep learning tutorial, release 0.1

parameters
----------
pos: theano matrix

symbolic matrix whose rows are position vectors.

vel: theano matrix

symbolic matrix whose rows are velocity vectors.

energy_fn: python function

python function, operating on symbolic theano variables, used tox
compute the potential energy at a given position.

returns
-------
return: theano vector

vector whose i-th entry is the hamiltonian at position pos[i] and
velocity vel[i].

"""
# assuming mass is 1
return energy_fn(pos) + kinetic_energy(vel)

def kinetic_energy(vel):

"""returns the kinetic energy associated with the given velocity
and mass of 1.

parameters
----------
vel: theano matrix

symbolic matrix whose rows are velocity vectors.

returns
-------
return: theano vector

vector whose i-th entry is the kinetic entry associated with vel[i].

"""
return 0.5 * (vel ** 2).sum(axis=1)

hmc_move    nally returns the tuple (accept, f inal_pos). accept is a symbolic boolean variable indicating
whether or not the new state f inalpos should be used or not.
hmc_updates

the purpose of hmc_updates is to generate the list of updates to perform, whenever our hmc sam-
pling function is called. hmc_updates thus receives as parameters, a series of shared variables to update
(positions, stepsize and avg_acceptance_rate), and the parameters required to compute their new state.

def hmc_updates(positions, stepsize, avg_acceptance_rate, final_pos, accept,

target_acceptance_rate, stepsize_inc, stepsize_dec,
stepsize_min, stepsize_max, avg_acceptance_slowness):

"""this function is executed after    n_steps    of hmc sampling
(   hmc_move    function). it creates the updates dictionary used by
the    simulate    function. it takes care of updating: the position
(if the move is accepted), the stepsize (to track a given target
acceptance rate) and the average acceptance rate (computed as a

126

chapter 11. hybrid monte-carlo sampling

deep learning tutorial, release 0.1

moving average).

parameters
----------
positions: shared variable, theano matrix

shared theano matrix whose rows contain the old position

stepsize: shared variable, theano scalar

shared theano scalar containing current step size

avg_acceptance_rate: shared variable, theano scalar

shared theano scalar containing the current average acceptance rate

final_pos: shared variable, theano matrix

shared theano matrix whose rows contain the new position

accept: theano scalar

boolean-type variable representing whether or not the proposed hmc move
should be accepted or not.

target_acceptance_rate: float

the stepsize is modified in order to track this target acceptance rate.

stepsize_inc: float

amount by which to increment stepsize when acceptance rate is too high.

stepsize_dec: float

amount by which to decrement stepsize when acceptance rate is too low.

stepsize_min: float

lower-bound on    stepsize   .

stepsize_min: float

upper-bound on    stepsize   .
avg_acceptance_slowness: float

average acceptance rate is computed as an exponential moving average.
(1-avg_acceptance_slowness) is the weight given to the newest
observation.

returns
-------
rval1: dictionary-like

a dictionary of updates to be used by the    hmc_sampler.simulate   
function. the updates target the position, stepsize and average
acceptance rate.

"""

## position updates ##
# broadcast    accept    scalar to tensor with the same dimensions as
# final_pos.
accept_matrix = accept.dimshuffle(0, *((   x   ,) * (final_pos.ndim - 1)))
# if accept is true, update to    final_pos    else stay put
new_positions = tt.switch(accept_matrix, final_pos, positions)

using the above code, the dictionary positions : new_positions can be used to update the state of the
sampler with either (1) the new state f inal_pos if accept is true, or (2) the old state if accept is false. this
conditional assignment is performed by the switch op.

switch expects as its    rst argument, a boolean mask with the same broadcastable dimensions as the second
and third argument. since accept is scalar-valued, we must    rst use dimshuf   e to transform it to a tensor
with f inal_pos.ndim broadcastable dimensions (accept_matrix).

11.2.

implementing hmc using theano

127

deep learning tutorial, release 0.1

hmc_updates additionally implements an adaptive version of hmc, as implemented in the accom-
panying code to [ranzato10]. we start by tracking the average acceptance rate of the hmc move
proposals (across many simulations), using an exponential moving average with time constant 1    
avg_acceptance_slowness.

## accept rate updates ##
# perform exponential moving average
mean_dtype = theano.scalar.upcast(accept.dtype, avg_acceptance_rate.dtype)
new_acceptance_rate = tt.add(

avg_acceptance_slowness * avg_acceptance_rate,
(1.0 - avg_acceptance_slowness) * accept.mean(dtype=mean_dtype))

if the average acceptance rate is larger than the target_acceptance_rate, we increase the stepsize by a
factor of stepsize_inc in order to increase the mixing rate of our chain. if the average acceptance rate is too
low however, stepsize is decreased by a factor of stepsize_dec, yielding a more conservative mixing rate.
the clip op allows us to maintain the stepsize in the range [stepsize_min, stepsize_max].

## stepsize updates ##
# if acceptance rate is too low, our sampler is too "noisy" and we reduce
# the stepsize. if it is too high, our sampler is too conservative, we can
# get away with a larger stepsize (resulting in better mixing).
_new_stepsize = tt.switch(avg_acceptance_rate > target_acceptance_rate,

# maintain stepsize in [stepsize_min, stepsize_max]
new_stepsize = tt.clip(_new_stepsize, stepsize_min, stepsize_max)

stepsize * stepsize_inc, stepsize * stepsize_dec)

the    nal updates list is then returned.

return [(positions, new_positions),

(stepsize, new_stepsize),
(avg_acceptance_rate, new_acceptance_rate)]

hmc_sampler

we    nally tie everything together using the hm c_sampler class. its main elements are:

    new_f rom_shared_positions: a constructor method which allocates various shared variables and
it also builds the theano function

strings together the calls to hmc_move and hmc_updates.
simulate, whose sole purpose is to execute the updates generated by hmc_updates.

    draw: a convenience method which calls the theano function simulate and returns a copy of the

contents of the shared variable self.positions.

class hmc_sampler(object):

"""
convenience wrapper for performing hybrid monte carlo (hmc). it creates the
symbolic graph for performing an hmc simulation (using    hmc_move    and
   hmc_updates   ). the graph is then compiled into the    simulate    function, a
theano function which runs the simulation and updates the required shared
variables.

users should interface with the sampler thorugh the    draw    function which
advances the markov chain and returns the current sample by calling
   simulate    and    get_position    in sequence.

128

chapter 11. hybrid monte-carlo sampling

deep learning tutorial, release 0.1

the hyper-parameters are the same as those used by marc   aurelio   s
   train_mcrbm.py    file (available on his personal home page).
"""

def __init__(self, **kwargs):

self.__dict__.update(kwargs)

@classmethod
def new_from_shared_positions(

cls,
shared_positions,
energy_fn,
initial_stepsize=0.01,
target_acceptance_rate=.9,
n_steps=20,
stepsize_dec=0.98,
stepsize_min=0.001,
stepsize_max=0.25,
stepsize_inc=1.02,
# used in geometric avg. 1.0 would be not moving at all
avg_acceptance_slowness=0.9,
seed=12345

"""
:param shared_positions: theano ndarray shared var with

many particle [initial] positions

):

:param energy_fn:

callable such that energy_fn(positions)
returns theano vector of energies.
the len of this vector is the batchsize.

the sum of this energy vector must be differentiable (with
theano.tensor.grad) with respect to the positions for hmc
sampling to work.

"""
# allocate shared variables
stepsize = sharedx(initial_stepsize,    hmc_stepsize   )
avg_acceptance_rate = sharedx(target_acceptance_rate,

s_rng = tt.shared_randomstreams.randomstreams(seed)

   avg_acceptance_rate   )

# define graph for an    n_steps    hmc simulation
accept, final_pos = hmc_move(

s_rng,
shared_positions,
energy_fn,
stepsize,
n_steps)

# define the dictionary of updates, to apply on every    simulate    call
simulate_updates = hmc_updates(

11.2.

implementing hmc using theano

129

deep learning tutorial, release 0.1

shared_positions,
stepsize,
avg_acceptance_rate,
final_pos=final_pos,
accept=accept,
stepsize_min=stepsize_min,
stepsize_max=stepsize_max,
stepsize_inc=stepsize_inc,
stepsize_dec=stepsize_dec,
target_acceptance_rate=target_acceptance_rate,
avg_acceptance_slowness=avg_acceptance_slowness)

# compile theano function
simulate = function([], [], updates=simulate_updates)

# create hmc_sampler object with the following attributes ...
return cls(

positions=shared_positions,
stepsize=stepsize,
stepsize_min=stepsize_min,
stepsize_max=stepsize_max,
avg_acceptance_rate=avg_acceptance_rate,
target_acceptance_rate=target_acceptance_rate,
s_rng=s_rng,
_updates=simulate_updates,
simulate=simulate)

def draw(self, **kwargs):

"""
returns a new position obtained after    n_steps    of hmc simulation.

parameters
----------
kwargs: dictionary

the    kwargs    dictionary is passed to the shared variable
(self.positions)    get_value()    function.
copying the shared variable value, consider passing    borrow=true   .

for example, to avoid

returns
-------
rval: numpy matrix

numpy matrix whose of dimensions similar to    initial_position   .

"""

self.simulate()
return self.positions.get_value(borrow=false)

11.3 testing our sampler

we test our implementation of hmc by sampling from a multi-variate gaussian distribution. we start by
generating a random mean vector mu and covariance matrix cov, which allows us to de   ne the energy
function of the corresponding gaussian distribution: gaussian_energy. we then initialize the state of the

130

chapter 11. hybrid monte-carlo sampling

deep learning tutorial, release 0.1

sampler by allocating a position shared variable. it is passed to the constructor of hm c_sampler along
with our target energy function.

following a burn-in period, we then generate a large number of samples and compare the empirical mean
and covariance matrix to their true values.

def sampler_on_nd_gaussian(sampler_cls, burnin, n_samples, dim=10):

batchsize = 3

rng = numpy.random.randomstate(123)

# define a covariance and mu for a gaussian
mu = numpy.array(rng.rand(dim) * 10, dtype=theano.config.floatx)
cov = numpy.array(rng.rand(dim, dim), dtype=theano.config.floatx)
cov = (cov + cov.t) / 2.
cov[numpy.arange(dim), numpy.arange(dim)] = 1.0
cov_inv = linalg.inv(cov)

# define energy function for a multi-variate gaussian
def gaussian_energy(x):

return 0.5 * (theano.tensor.dot((x - mu), cov_inv) *

(x - mu)).sum(axis=1)

# declared shared random variable for positions
position = rng.randn(batchsize, dim).astype(theano.config.floatx)
position = theano.shared(position)

# create hmc sampler
sampler = sampler_cls(position, gaussian_energy,

initial_stepsize=1e-3, stepsize_max=0.5)

# start with a burn-in process
garbage = [sampler.draw() for r in xrange(burnin)]
# burn-in draw
#    n_samples   : result is a 3d tensor of dim [n_samples, batchsize,
# dim]
_samples = numpy.asarray([sampler.draw() for r in xrange(n_samples)])
# flatten to [n_samples * batchsize, dim]
samples = _samples.t.reshape(dim, -1).t

print    ****** target values ******   
print    target mean:   , mu
print    target cov:\n   , cov

print    ****** empirical mean/cov using hmc ******   
print    empirical mean:    , samples.mean(axis=0)
print    empirical_cov:\n   , numpy.cov(samples.t)

print    ****** hmc internals ******   
print    final stepsize   , sampler.stepsize.get_value()
print    final acceptance_rate   , sampler.avg_acceptance_rate.get_value()

return sampler

11.3. testing our sampler

131

deep learning tutorial, release 0.1

def test_hmc():

sampler = sampler_on_nd_gaussian(hmc_sampler.new_from_shared_positions,

burnin=1000, n_samples=1000, dim=5)

assert abs(sampler.avg_acceptance_rate.get_value() -

sampler.target_acceptance_rate) < .1

assert sampler.stepsize.get_value() >= sampler.stepsize_min
assert sampler.stepsize.get_value() <= sampler.stepsize_max

the above code can be run using the command:    nosetests -s code/hmc/test_hmc.py   . the output is as
follows:

[desjagui@atchoum hmc]$ python test_hmc.py

****** target values ******
target mean: [ 6.96469186 2.86139335
target cov:
[[ 1.

0.66197111 0.71141257
0.31053199

[ 0.66197111 1.
[ 0.71141257 0.31053199 1.
[ 0.55766643 0.45455485 0.62800335
[ 0.35753822 0.37991646 0.38004541

2.26851454

5.51314769

7.1946897 ]

0.55766643
0.45455485
0.62800335
1.
0.50807871

0.35753822]
0.37991646]
0.38004541]
0.50807871]
1.

]]

****** empirical mean/cov using hmc ******
empirical mean: [ 6.94155164 2.81526039
empirical_cov:
[[ 1.05152997 0.68393537 0.76038645
[ 0.68393537 0.97708159 0.37351422
[ 0.76038645 0.37351422 1.03797111
[ 0.59930252 0.48362404 0.67342957
[ 0.37478746 0.3839558
0.41529132

0.59930252
0.48362404
0.67342957
1.02865056
0.53613649

0.37478746]
0.3839558 ]
0.41529132]
0.53613649]
0.98721449]]

2.26301715

5.46536853

7.19414496]

****** hmc internals ******
final stepsize 0.460446628091
final acceptance_rate 0.922502043428

as can be seen above, the samples generated by our hmc sampler yield an empirical mean and covariance
matrix, which are very close to the true underlying parameters. the adaptive algorithm also seemed to work
well as the    nal acceptance rate is close to our target of 0.9.

11.4 references

132

chapter 11. hybrid monte-carlo sampling

chapter
twelve

recurrent neural networks with id27s

12.1 summary

in this tutorial, you will learn how to:

    learn id27s
    using recurrent neural networks architectures
    with context windows

in order to perform id29 / slot-filling (spoken language understanding)

12.2 code - citations - contact

12.2.1 code

directly running experiments is also possible using this github repository.

12.2.2 papers

if you use this tutorial, cite the following papers:

    [pdf] gr  goire mesnil, xiaodong he, li deng and yoshua bengio. investigation of recurrent-neural-
interspeech,

network architectures and learning methods for spoken language understanding.
2013.

    [pdf] gokhan tur, dilek hakkani-tur and larry heck. what is left to be understood in atis?

    [pdf] christian raymond and giuseppe riccardi. generative and discriminative algorithms for spoken

language understanding. interspeech, 2007.

    [pdf] bastien, fr  d  ric, lamblin, pascal, pascanu, razvan, bergstra, james, goodfellow, ian, berg-
eron, arnaud, bouchard, nicolas, and bengio, yoshua. theano: new features and speed improve-
ments. nips workshop on deep learning and unsupervised id171, 2012.

    [pdf] bergstra, james, breuleux, olivier, bastien, fr  d  ric, lamblin, pascal, pascanu, razvan, des-
jardins, guillaume, turian, joseph, warde-farley, david, and bengio, yoshua. theano: a cpu and

133

deep learning tutorial, release 0.1

gpu math expression compiler. in proceedings of the python for scienti   c computing conference
(scipy), june 2010.

thank you!

12.2.3 contact

please email to gr  goire mesnil for any problem report or feedback. we will be glad to hear from you.

12.3 task

the slot-filling (spoken language understanding) consists in assigning a label to each word given a sen-
tence. it   s a classi   cation task.

12.4 dataset

an old and small benchmark for this task is the atis (airline travel information system) dataset collected
by darpa. here is a sentence (or utterance) example using the inside outside beginning (iob) represen-
tation.
input (words)
output (labels) o
the atis of   cal split contains 4,978/893 sentences for a total of 56,590/9,198 words (average sentence
length is 15) in the train/test set. the number of classes (different slots) is 128 including the o label (null).

from boston
o

today
i-arr b-date

b-dept o b-arr

to new york

show    ights

o

as microsoft research people, we deal with unseen words in the test set by marking any words with only
one single occurrence in the training set as <unk> and use this token to represent those unseen words in the
test set. as ronan collobert and colleagues, we converted sequences of numbers with the string digit i.e.
1984 is converted to digitdigitdigitdigit.

we split the of   cial train set into a training and validation set that contain respectively 80% and 20% of the
of   cial training sentences. signi   cant performance improvement difference has to be greater than 0.6% in
f1 measure at the 95% level due to the small size of the dataset. for evaluation purpose, experiments have
to report the following metrics:

    precision

    recall

    f1 score

we will use the conlleval perl script to measure the performance of our models.

134

chapter 12. recurrent neural networks with id27s

deep learning tutorial, release 0.1

12.5 recurrent neural network model

12.5.1 raw input encoding

a token corresponds to a word. each token in the atis vocabulary is associated to an index. each sentence
is a array of indexes (int32). then, each set (train, valid, test) is a list of arrays of indexes. a python
dictionary is de   ned for mapping the space of indexes to the space of words.

>>> sentence
array([383, 189, 13, 193, 208, 307, 195, 502, 260, 539,

7,

60, 72, 8, 350, 384], dtype=int32)

>>> map(lambda x: index2word[x], sentence)
[   please   ,    find   ,    a   ,    flight   ,    from   ,    miami   ,    florida   ,

   to   ,    las   ,    vegas   ,    <unk>   ,    arriving   ,    before   ,    digit   , "o   clock",    pm   ]

same thing for labels corresponding to this particular sentence.

>>> labels
array([126, 126, 126, 126, 126,

48,

50, 126,

78, 123,

81, 126,

15,

14, 89, 89], dtype=int32)

>>> map(lambda x: index2label[x], labels)
[   o   ,    o   ,    o   ,    o   ,    o   ,    b-fromloc.city_name   ,    b-fromloc.state_name   ,

   o   ,    b-toloc.city_name   ,    i-toloc.city_name   ,    b-toloc.state_name   ,
   o   ,    b-arrive_time.time_relative   ,    b-arrive_time.time   ,
   i-arrive_time.time   ,    i-arrive_time.time   ]

12.5.2 context window

given a sentence i.e. an array of indexes, and a window size i.e. 1,3,5,..., we need to convert each word in
the sentence to a context window surrounding this particular word. in details, we have:

def contextwin(l, win):

         
win :: int corresponding to the size of the window
given a list of indexes composing a sentence

l :: array containing the word indexes

it will return a list of list of indexes corresponding
to context windows surrounding each word in the sentence
         
assert (win % 2) == 1
assert win >= 1
l = list(l)

lpadded = win // 2 * [-1] + l + win // 2 * [-1]
out = [lpadded[i:(i + win)] for i in range(len(l))]

assert len(out) == len(l)
return out

12.5. recurrent neural network model

135

deep learning tutorial, release 0.1

the index -1 corresponds to the padding index we insert at the beginning/end of the sentence.

here is a sample:
>>> x
array([0, 1, 2, 3, 4], dtype=int32)
>>> contextwin(x, 3)
[[-1, 0, 1],
[ 0, 1, 2],
[ 1, 2, 3],
[ 2, 3, 4],
[ 3, 4,-1]]

>>> contextwin(x, 7)
[[-1, -1, -1, 0, 1, 2, 3],
[-1, -1, 0, 1, 2, 3, 4],
0, 1, 2, 3, 4,-1],
[-1,
1, 2, 3, 4,-1,-1],
[ 0,
[ 1,
2, 3, 4,-1,-1,-1]]

to summarize, we started with an array of indexes and ended with a matrix of indexes. each line corresponds
to the context window surrounding this word.

12.5.3 id27s

once we have the sentence converted to context windows i.e. a matrix of indexes, we have to associate these
indexes to the embeddings (real-valued vector associated to each word). using theano, it gives:

import theano, numpy
from theano import tensor as t

# nv :: size of our vocabulary
# de :: dimension of the embedding space
# cs :: context window size
nv, de, cs = 1000, 50, 5

embeddings = theano.shared(0.2 * numpy.random.uniform(-1.0, 1.0, \

(nv+1, de)).astype(theano.config.floatx)) # add one for padding at the end

idxs = t.imatrix() # as many columns as words in the context window and as many lines as words in the sentence
x

= self.emb[idxs].reshape((idxs.shape[0], de*cs))

the x symbolic variable corresponds to a matrix of shape (number of words in the sentences, dimension of
the embedding space x context window size).

let   s compile a theano function to do so

>>> sample
array([0, 1, 2, 3, 4], dtype=int32)
>>> csample = contextwin(sample, 7)
[[-1, -1, -1, 0, 1, 2, 3],
[-1, -1, 0, 1, 2, 3, 4],
0, 1, 2, 3, 4,-1],
[-1,
[ 0,
1, 2, 3, 4,-1,-1],

136

chapter 12. recurrent neural networks with id27s

deep learning tutorial, release 0.1

[ 1,

2, 3, 4,-1,-1,-1]]

>>> f = theano.function(inputs=[idxs], outputs=x)
>>> f(csample)
array([[-0.08088442, 0.08458307,

0.05064092, ...,

-0.06648078, -0.15192257],

0.06876887,

[-0.08088442, 0.08458307,

0.05064092, ...,

0.11192625,

0.08745284, 0.04381778],

[-0.08088442, 0.08458307,

0.05064092, ..., -0.00937143,

0.10804889, 0.1247109 ],

[ 0.11038255, -0.10563177, -0.18760249, ..., -0.00937143,

0.10804889, 0.1247109 ],

[ 0.18738101, 0.14727569, -0.069544

, ..., -0.00937143,

0.10804889, 0.1247109 ]], dtype=float32)

>>> f(csample).shape
(5, 350)

we now have a sequence (of length 5 which is corresponds to the length of the sentence) of context window
id27s which is easy to feed to a simple recurrent neural network to iterate with.

12.5.4 elman recurrent neural network

the followin (elman) recurrent neural network (e-id56) takes as input the current input (time t) and the
previous hiddent state (time t-1). then it iterates.

in the previous section, we processed the input to    t this sequential/temporal structure. it consists in a matrix
where the row 0 corresponds to the time step t=0, the row 1 corresponds to the time step t=1, etc.
the parameters of the e-id56 to be learned are:

    the id27s (real-valued matrix)

    the initial hidden state (real-value vector)

    two matrices for the linear projection of the input t and the previous hidden layer state t-1

    (optional) bias. recommendation: don   t use it.

    softmax classi   cation layer on top

the hyperparameters de   ne the whole architecture:

    dimension of the id27

    size of the vocabulary

    number of hidden units

    number of classes

    random seed + way to initialize the model

it gives the following code:

class id56slu(object):

          elman neural net model          
def __init__(self, nh, nc, ne, de, cs):

12.5. recurrent neural network model

137

deep learning tutorial, release 0.1

         
nh :: dimension of the hidden layer
nc :: number of classes
ne :: number of id27s in the vocabulary
de :: dimension of the id27s
cs :: word window context size
         
# parameters of the model
self.emb = theano.shared(name=   embeddings   ,

value=0.2 * numpy.random.uniform(-1.0, 1.0,
(ne+1, de))
# add one for padding at the end
.astype(theano.config.floatx))

self.wx = theano.shared(name=   wx   ,

value=0.2 * numpy.random.uniform(-1.0, 1.0,
(de * cs, nh))
.astype(theano.config.floatx))

self.wh = theano.shared(name=   wh   ,

value=0.2 * numpy.random.uniform(-1.0, 1.0,
(nh, nh))
.astype(theano.config.floatx))

self.w = theano.shared(name=   w   ,

value=0.2 * numpy.random.uniform(-1.0, 1.0,
(nh, nc))
.astype(theano.config.floatx))

self.bh = theano.shared(name=   bh   ,

value=numpy.zeros(nh,
dtype=theano.config.floatx))

self.b = theano.shared(name=   b   ,

self.h0 = theano.shared(name=   h0   ,

value=numpy.zeros(nc,
dtype=theano.config.floatx))

value=numpy.zeros(nh,
dtype=theano.config.floatx))

# bundle
self.params = [self.emb, self.wx, self.wh, self.w,

self.bh, self.b, self.h0]

then we integrate the way to build the input from the embedding matrix:

idxs = t.imatrix()
x = self.emb[idxs].reshape((idxs.shape[0], de*cs))
y_sentence = t.ivector(   y_sentence   )

# labels

we use the scan operator to construct the recursion, works like a charm:

def recurrence(x_t, h_tm1):

h_t = t.nnet.sigmoid(t.dot(x_t, self.wx)

s_t = t.nnet.softmax(t.dot(h_t, self.w) + self.b)
return [h_t, s_t]

+ t.dot(h_tm1, self.wh) + self.bh)

[h, s], _ = theano.scan(fn=recurrence,

138

chapter 12. recurrent neural networks with id27s

deep learning tutorial, release 0.1

sequences=x,
outputs_info=[self.h0, none],
n_steps=x.shape[0])

p_y_given_x_sentence = s[:, 0, :]
y_pred = t.argmax(p_y_given_x_sentence, axis=1)

theano will then compute all the gradients automatically to maximize the log-likelihood:

lr = t.scalar(   lr   )

sentence_nll = -t.mean(t.log(p_y_given_x_sentence)

[t.arange(x.shape[0]), y_sentence])

sentence_gradients = t.grad(sentence_nll, self.params)
sentence_updates = ordereddict((p, p - lr*g)

for p, g in
zip(self.params, sentence_gradients))

next compile those functions:

self.classify = theano.function(inputs=[idxs], outputs=y_pred)
self.sentence_train = theano.function(inputs=[idxs, y_sentence, lr],

outputs=sentence_nll,
updates=sentence_updates)

we keep the id27s on the unit sphere by normalizing them after each update:

self.normalize = theano.function(inputs=[],

updates={self.emb:

self.emb /
t.sqrt((self.emb**2)
.sum(axis=1))
.dimshuffle(0,    x   )})

and that   s it!

12.6 evaluation

with the previous de   ned functions, you can compare the predicted labels with the true labels and compute
some metrics. in this repo, we build a wrapper around the conlleval perl script. it   s not trivial to compute
those metrics due to the inside outside beginning (iob) representation i.e. a prediction is considered correct
if the word-beginning and the word-inside and the word-outside predictions are all correct. note that the
extension is txt and you will have to change it to pl.

12.6. evaluation

139

deep learning tutorial, release 0.1

12.7 training

12.7.1 updates

for stochastic id119 (sgd) update, we consider the whole sentence as a mini-batch and perform
one update per sentence. it is possible to perform a pure sgd (contrary to mini-batch) where the update is
done on only one single word at a time.

after each iteration/update, we normalize the id27s to keep them on a unit sphere.

12.7.2 stopping criterion

early-stopping on a validation set is our id173 technique: the training is run for a given number of
epochs (a single pass through the whole dataset) and keep the best model along with respect to the f1 score
computed on the validation set after each epoch.

12.7.3 hyper-parameter selection

although there is interesting research/code on the topic of automatic hyper-parameter selection, we use the
kiss random search.

the following intervals can give you some starting point:

    learning rate : uniform([0.05,0.01])

    window size : random value from {3,...,19}

    number of hidden units : random value from {100,200}

    embedding dimension : random value from {50,100}

12.8 running the code

after downloading the data using download.sh, the user can then run the code by calling:

python code/id56slu.py

(   new best: epoch   , 25,    valid f1   , 96.84,    best test f1   , 93.79)
[learning] epoch 26 >> 100.00% completed in 28.76 (sec) <<
[learning] epoch 27 >> 100.00% completed in 28.76 (sec) <<
...
(   best result: epoch   , 57,    valid f1   , 97.23,    best test f1   , 94.2,    with the model   ,    id56slu   )

12.8.1 timing

running experiments on atis using this repository will run one epoch in less than 40 seconds on i7 cpu
950 @ 3.07ghz using less than 200 mo of ram:

140

chapter 12. recurrent neural networks with id27s

deep learning tutorial, release 0.1

[learning] epoch 0 >> 100.00% completed in 34.48 (sec) <<

after a few epochs, you obtain decent performance 94.48 % of f1 score.:

new best: epoch 28 valid f1 96.61 best test f1 94.19
new best: epoch 29 valid f1 96.63 best test f1 94.42
[learning] epoch 30 >> 100.00% completed in 35.04 (sec) <<
[learning] epoch 31 >> 100.00% completed in 34.80 (sec) <<
[...]
new best: epoch 40 valid f1 97.25 best test f1 94.34
[learning] epoch 41 >> 100.00% completed in 35.18 (sec) <<
new best: epoch 42 valid f1 97.33 best test f1 94.48
[learning] epoch 43 >> 100.00% completed in 35.39 (sec) <<
[learning] epoch 44 >> 100.00% completed in 35.31 (sec) <<
[...]

12.8.2 id27 nearest neighbors

we can check the k-nearest neighbors of the learned embeddings. l2 and cosine distance gave the same
results so we plot them for the cosine distance.
atlanta
phoenix
denver
tacoma
columbus
seattle
minneapolis
pittsburgh
ontario
montreal
philadelphia
as you can judge, the limited size of the vocabulary (about 500 words) gives us mitigated performance.
according to human judgement: some are good, some are bad.

but
if
up
a
now
amount
more
abbreviation
restrictions
mean
interested

a
people
do
but
numbers
abbreviation
if
up
serve
database
passengers

ap80
ap57
ap
connections
tomorrow
before
earliest
connect
thrift
coach
today

august
september
january
june
december
november
april
july
jfk
october
may

aircraft
plane
service
airplane
seating
stand
that
on
turboprop
mean
amount

business
coach
   rst
fourth
thrift
tenth
second
   fth
third
twelfth
sixth

back
live
lives
both
how
me
out
other
plane
service
fare

actually
provide
prices
stop
number
   ight
there
serving
thank
ticket
are

cheap
weekday
weekdays
am
early
sfo
milwaukee
jfk
shortest
bwi
lastest

12.8. running the code

141

deep learning tutorial, release 0.1

142

chapter 12. recurrent neural networks with id27s

chapter
thirteen

id137 for id31

13.1 summary

this tutorial aims to provide an example of how a recurrent neural network (id56) using the long short
term memory (lstm) architecture can be implemented using theano. in this tutorial, this model is used
to perform id31 on movie reviews from the large movie review dataset, sometimes known
as the imdb dataset.

in this task, given a movie review, the model attempts to predict whether it is positive or negative. this is a
binary classi   cation task.

13.2 data

as previously mentioned, the provided scripts are used to train a lstm recurrent neural network on the
large movie review dataset dataset.

while the dataset is public, in this tutorial we provide a copy of the dataset that has previously been pre-
processed according to the needs of this lstm implementation. running the code provided in this tutorial
will automatically download the data to the local directory. in order to use your own data, please use a
(preprocessing script) provided as a part of this tutorial.

once the model is trained, you can test it with your own corpus using the word-index dictionary
(imdb.dict.pkl.gz) provided as a part of this tutorial.

13.3 model

13.3.1 lstm

in a traditional recurrent neural network, during the gradient back-propagation phase, the gradient signal
can end up being multiplied a large number of times (as many as the number of timesteps) by the weight
matrix associated with the connections between the neurons of the recurrent hidden layer. this means that,
the magnitude of weights in the transition matrix can have a strong impact on the learning process.

if the weights in this matrix are small (or, more formally, if the leading eigenvalue of the weight matrix
is smaller than 1.0), it can lead to a situation called vanishing gradients where the gradient signal gets so

143

deep learning tutorial, release 0.1

small that learning either becomes very slow or stops working altogether. it can also make more dif   cult
the task of learning long-term dependencies in the data. conversely, if the weights in this matrix are large
(or, again, more formally, if the leading eigenvalue of the weight matrix is larger than 1.0), it can lead to a
situation where the gradient signal is so large that it can cause learning to diverge. this is often referred to
as exploding gradients.

these issues are the main motivation behind the lstm model which introduces a new structure called a
memory cell (see figure 1 below). a memory cell is composed of four main elements: an input gate, a
neuron with a self-recurrent connection (a connection to itself), a forget gate and an output gate. the self-
recurrent connection has a weight of 1.0 and ensures that, barring any outside interference, the state of a
memory cell can remain constant from one timestep to another. the gates serve to modulate the interactions
between the memory cell itself and its environment. the input gate can allow incoming signal to alter the
state of the memory cell or block it. on the other hand, the output gate can allow the state of the memory
cell to have an effect on other neurons or prevent it. finally, the forget gate can modulate the memory cell   s
self-recurrent connection, allowing the cell to remember or forget its previous state, as needed.

figure 13.1: figure 1 : illustration of an lstm memory cell.

the equations below describe how a layer of memory cells is updated at every timestep t. in these equations
:

    xt is the input to the memory cell layer at time t
    wi, wf , wc, wo, ui, uf , uc, uo and vo are weight matrices
    bi, bf , bc and bo are bias vectors

first, we compute the values for it, the input gate, and(cid:102)ct the candidate value for the states of the memory

cells at time t :

it =   (wixt + uiht   1 + bi)

(cid:102)ct = tanh(wcxt + ucht   1 + bc)

(13.1)

(13.2)

144

chapter 13. id137 for id31

second, we compute the value for ft, the activation of the memory cells    forget gates at time t :

deep learning tutorial, release 0.1

given the value of the input gate activation it, the forget gate activation ft and the candidate state value(cid:102)ct,

ft =   (wf xt + uf ht   1 + bf )

(13.3)

we can compute ct the memory cells    new state at time t :

ct = it    (cid:102)ct + ft     ct   1

(13.4)

with the new state of the memory cells, we can compute the value of their output gates and, subsequently,
their outputs :

ot =   (woxt + uoht   1 + voct + bo)

ht = ot     tanh(ct)

(13.5)

(13.6)

13.3.2 our model

the model we used in this tutorial is a variation of the standard lstm model. in this variant, the activation
of a cell   s output gate does not depend on the memory cell   s state ct. this allows us to perform part of
the computation more ef   ciently (see the implementation note, below, for details). this means that, in the
variant we have implemented, there is no matrix vo and equation (13.5) is replaced by equation (13.7) :

ot =   (woxt + uoht   1 + bo)

(13.7)

our model is composed of a single lstm layer followed by an average pooling and a id28
layer as illustrated in figure 2 below. thus, from an input sequence x0, x1, x2, ..., xn, the memory cells in
the lstm layer will produce a representation sequence h0, h1, h2, ..., hn. this representation sequence is
then averaged over all timesteps resulting in representation h. finally, this representation is fed to a logistic
regression layer whose target is the class label associated with the input sequence.
implementation note : in the code included this tutorial, the equations (13.1), (13.2), (13.3) and (13.7)
are performed in parallel to make the computation more ef   cient. this is possible because none of these
equations rely on a result produced by the other ones. it is achieved by concatenating the four matrices w   
into a single weight matrix w and performing the same concatenation on the weight matrices u    to produce
the matrix u and the bias vectors b    to produce the vector b. then, the pre-nonlinearity activations can be
computed with :

the result is then sliced to obtain the pre-nonlinearity activations for i, f,(cid:102)ct, and o and the non-linearities

z =   (w xt + u ht   1 + b)

are then applied independently for each.

13.4 code - citations - contact

13.4.1 code

the lstm implementation can be found in the two following    les :

13.4. code - citations - contact

145

deep learning tutorial, release 0.1

figure 13.2: figure 2 : illustration of the model used in this tutorial. it is composed of a single lstm layer
followed by mean pooling over time and id28.

146

chapter 13. id137 for id31

deep learning tutorial, release 0.1

    lstm.py : main script. de   nes and train the model.

    imdb.py : secondary script. handles the loading and preprocessing of the imdb dataset.

after downloading both scripts and putting both in the same folder, the user can run the code by calling:

theano_flags="floatx=float32" python lstm.py

the script will automatically download the data and decompress it.
note : the provided code supports the stochastic id119 (sgd), adadelta and rmsprop opti-
mization methods. you are advised to use adadelta or rmsprop because sgd appears to performs poorly
on this task with this particular model.

13.4.2 papers

if you use this tutorial, please cite the following papers.

introduction of the lstm model:

    [pdf] hochreiter, s., & schmidhuber, j. (1997). long short-term memory. neural computation, 9(8),

1735-1780.

addition of the forget gate to the lstm model:

    [pdf] gers, f. a., schmidhuber, j., & cummins, f. (2000). learning to forget: continual prediction

with lstm. neural computation, 12(10), 2451-2471.

more recent lstm paper:

    [pdf] graves, alex. supervised sequence labelling with recurrent neural networks. vol. 385. springer,

2012.

papers related to theano:

    [pdf] bastien, fr  d  ric, lamblin, pascal, pascanu, razvan, bergstra, james, goodfellow, ian, berg-
eron, arnaud, bouchard, nicolas, and bengio, yoshua. theano: new features and speed improve-
ments. nips workshop on deep learning and unsupervised id171, 2012.

    [pdf] bergstra, james, breuleux, olivier, bastien, fr  d  ric, lamblin, pascal, pascanu, razvan, des-
jardins, guillaume, turian, joseph, warde-farley, david, and bengio, yoshua. theano: a cpu and
gpu math expression compiler. in proceedings of the python for scienti   c computing conference
(scipy), june 2010.

thank you!

13.4.3 contact

please email pierre luc carrier or kyunghyun cho for any problem report or feedback. we will be glad to
hear from you.

13.4. code - citations - contact

147

deep learning tutorial, release 0.1

13.5 references

    hochreiter, s., & schmidhuber, j. (1997). long short-term memory. neural computation, 9(8), 1735-

1780.

    gers, f. a., schmidhuber, j., & cummins, f. (2000). learning to forget: continual prediction with

lstm. neural computation, 12(10), 2451-2471.

    graves, a. (2012). supervised sequence labelling with recurrent neural networks (vol. 385). springer.

    hochreiter, s., bengio, y., frasconi, p., & schmidhuber, j. (2001). gradient    ow in recurrent nets:

the dif   culty of learning long-term dependencies.

    bengio, y., simard, p., & frasconi, p. (1994). learning long-term dependencies with id119

is dif   cult. neural networks, ieee transactions on, 5(2), 157-166.

    maas, a. l., daly, r. e., pham, p. t., huang, d., ng, a. y., & potts, c. (2011, june). learning
word vectors for id31. in proceedings of the 49th annual meeting of the association
for computational linguistics: human language technologies-volume 1 (pp. 142-150). association
for computational linguistics.

148

chapter 13. id137 for id31

chapter
fourteen

modeling and generating sequences of polyphonic
music with the id56-rbm

note: this tutorial demonstrates a basic implementation of the id56-rbm as described in [boulanger-
lewandowski12] (pdf). we assume the reader is familiar with recurrent neural networks using the scan op
and restricted id82s (rbm).

note: the code for this section is available for download here: id56rbm.py.
you will need the modi   ed python midi package (gpl license) in your $pythonpath or in the working
directory in order to convert midi    les to and from piano-rolls. the script also assumes that the content
of the nottingham database of folk tunes has been extracted in the ../data directory. alternative midi
datasets are available here.

note that both dependencies above can be setup automatically by running the download.sh script in the
../data directory.

caution: need theano 0.6 or more recent.

14.1 the id56-rbm

the id56-rbm is an energy-based model for density estimation of temporal sequences, where the feature
vector v(t) at time step t may be high-dimensional. it allows to describe multimodal conditional distributions
of v(t)|a(t), where a(t)     {v  |   < t} denotes the sequence history at time t, via a series of conditional
rbms (one a each time step) whose parameters b(t)
h depend on the output of a deterministic id56 with
hidden units u(t):

v , b(t)

v = bv + wuvu(t   1)
b(t)

h = bh + wuhu(t   1)
b(t)

and the single-layer id56 recurrence relation is de   ned by:

u(t) = tanh(bu + wuuu(t   1) + wvuv(t))

(14.1)

(14.2)

(14.3)

149

deep learning tutorial, release 0.1

the resulting model is unrolled in time in the following    gure:

t(cid:88)

the overall id203 distribution is given by the sum over the t time steps in a given sequence:

p ({v(t)}) =

p (v(t)|a(t))

(14.4)

where the right-hand side multiplicand is the marginalized id203 of the tth rbm.

note that for clarity of the implementation, contrarily to [boulangerlewandowski12], we use the obvious
naming convention for weight matrices and we use u(t) instead of   h(t) for the recurrent hidden units.

t=1

14.2 implementation

we wish to construct two theano functions: one to train the id56-rbm, and one to generate sample se-
quences from it.
for training, i.e. given {v(t)}, the id56 hidden state {u(t)} and the associated {b(t)
h } parameters are
deterministic and can be readily computed for each training sequence. a stochastic id119 (sgd)
update on the parameters can then be estimated via contrastive divergence (cd) on the individual time steps
of a sequence in the same way that individual training examples are treated in a mini-batch for regular
rbms.

v , b(t)

sequence generation is similar except that the v(t) must be sampled sequentially at each time step with a
separate (non-batch) gibbs chain before being passed down to the recurrence and the sequence history.

14.2.1 the rbm layer

the build_rbm function shown below builds a gibbs chain from an input mini-batch (a binary matrix)
via the cd approximation. note that it also supports a single frame (a binary vector) in the non-batch case.

150chapter 14. modeling and generating sequences of polyphonic music with the id56-rbm

deep learning tutorial, release 0.1

def build_rbm(v, w, bv, bh, k):

         construct a k-step gibbs chain starting at v for an rbm.

v : theano vector or matrix

if a matrix, multiple chains will be run in parallel (batch).

w : theano matrix

weight matrix of the rbm.

bv : theano vector

visible bias vector of the rbm.

bh : theano vector

hidden bias vector of the rbm.

k : scalar or theano scalar

length of the gibbs chain.

return a (v_sample, cost, monitor, updates) tuple:

v_sample : theano vector or matrix with the same shape as    v   

corresponds to the generated sample(s).

cost : theano scalar

expression whose gradient with respect to w, bv, bh is the cd-k
approximation to the log-likelihood of    v    (training example) under the
rbm. the cost is averaged in the batch case.

monitor: theano scalar

pseudo log-likelihood (also averaged in the batch case).

updates: dictionary of theano variable -> theano variable

the    updates    object returned by scan.         

def gibbs_step(v):

mean_h = t.nnet.sigmoid(t.dot(v, w) + bh)
h = rng.binomial(size=mean_h.shape, n=1, p=mean_h,

dtype=theano.config.floatx)

mean_v = t.nnet.sigmoid(t.dot(h, w.t) + bv)
v = rng.binomial(size=mean_v.shape, n=1, p=mean_v,

dtype=theano.config.floatx)

return mean_v, v

chain, updates = theano.scan(lambda v: gibbs_step(v)[1], outputs_info=[v],

v_sample = chain[-1]

n_steps=k)

mean_v = gibbs_step(v_sample)[0]
monitor = t.xlogx.xlogy0(v, mean_v) + t.xlogx.xlogy0(1 - v, 1 - mean_v)
monitor = monitor.sum() / v.shape[0]

def free_energy(v):

return -(v * bv).sum() - t.log(1 + t.exp(t.dot(v, w) + bh)).sum()

cost = (free_energy(v) - free_energy(v_sample)) / v.shape[0]

return v_sample, cost, monitor, updates

14.2.

implementation

151

deep learning tutorial, release 0.1

14.2.2 the id56 layer

the build_id56rbm function de   nes the id56 recurrence relation to obtain the rbm parameters; the
recurrence function is    exible enough to serve both in the training scenario where v(t) is given and the
   batch    rbm is constructed at the end on the whole sequence at once, and in the generation scenario where
v(t) is sampled separately at each time step using the gibbs chain de   ned above.

def build_id56rbm(n_visible, n_hidden, n_hidden_recurrent):

         construct a symbolic id56-rbm and initialize parameters.

n_visible : integer

number of visible units.

n_hidden : integer

number of hidden units of the conditional rbms.

n_hidden_recurrent : integer

number of hidden units of the id56.

return a (v, v_sample, cost, monitor, params, updates_train, v_t,
updates_generate) tuple:

v : theano matrix

symbolic variable holding an input sequence (used during training)

v_sample : theano matrix

symbolic variable holding the negative particles for cd log-likelihood
gradient estimation (used during training)

cost : theano scalar

expression whose gradient (considering v_sample constant) corresponds
to the ll gradient of the id56-rbm (used during training)

monitor : theano scalar

frame-level pseudo-likelihood (useful for monitoring during training)

params : tuple of theano shared variables

the parameters of the model to be optimized during training.
updates_train : dictionary of theano variable -> theano variable

update object that should be passed to theano.function when compiling
the training function.

v_t : theano matrix

symbolic variable holding a generated sequence (used during sampling)

updates_generate : dictionary of theano variable -> theano variable

update object that should be passed to theano.function when compiling
the generation function.         

w = shared_normal(n_visible, n_hidden, 0.01)
bv = shared_zeros(n_visible)
bh = shared_zeros(n_hidden)
wuh = shared_normal(n_hidden_recurrent, n_hidden, 0.0001)
wuv = shared_normal(n_hidden_recurrent, n_visible, 0.0001)
wvu = shared_normal(n_visible, n_hidden_recurrent, 0.0001)
wuu = shared_normal(n_hidden_recurrent, n_hidden_recurrent, 0.0001)
bu = shared_zeros(n_hidden_recurrent)

params = w, bv, bh, wuh, wuv, wvu, wuu, bu

# learned parameters as shared
# variables

152chapter 14. modeling and generating sequences of polyphonic music with the id56-rbm

deep learning tutorial, release 0.1

v = t.matrix()
u0 = t.zeros((n_hidden_recurrent,))

# a training sequence

# initial value for the id56 hidden
# units

# if    v_t    is given, deterministic recurrence to compute the variable
# biases bv_t, bh_t at each time step. if    v_t    is none, same recurrence
# but with a separate gibbs chain at each time step to sample (generate)
# from the id56-rbm. the resulting sample v_t is returned in order to be
# passed down to the sequence history.
def recurrence(v_t, u_tm1):

bv_t = bv + t.dot(u_tm1, wuv)
bh_t = bh + t.dot(u_tm1, wuh)
generate = v_t is none
if generate:

v_t, _, _, updates = build_rbm(t.zeros((n_visible,)), w, bv_t,

bh_t, k=25)

u_t = t.tanh(bu + t.dot(v_t, wvu) + t.dot(u_tm1, wuu))
return ([v_t, u_t], updates) if generate else [u_t, bv_t, bh_t]

# for training, the deterministic recurrence is used to compute all the
# {bv_t, bh_t, 1 <= t <= t} given v. conditional rbms can then be trained
# in batches using those parameters.
(u_t, bv_t, bh_t), updates_train = theano.scan(

lambda v_t, u_tm1, *_: recurrence(v_t, u_tm1),
sequences=v, outputs_info=[u0, none, none], non_sequences=params)

v_sample, cost, monitor, updates_rbm = build_rbm(v, w, bv_t[:], bh_t[:],

updates_train.update(updates_rbm)

k=15)

# symbolic loop for sequence generation
(v_t, u_t), updates_generate = theano.scan(

lambda u_tm1, *_: recurrence(none, u_tm1),
outputs_info=[none, u0], non_sequences=params, n_steps=200)

return (v, v_sample, cost, monitor, params, updates_train, v_t,

updates_generate)

14.2.3 putting it all together

we now have all the necessary ingredients to start training our network on real symbolic sequences of
polyphonic music.

class id56rbm:

         simple class to train an id56-rbm from midi files and to generate sample
sequences.         

def __init__(

self,
n_hidden=150,
n_hidden_recurrent=100,
lr=0.001,
r=(21, 109),

14.2.

implementation

153

deep learning tutorial, release 0.1

dt=0.3

):

         constructs and compiles theano functions for training and sequence
generation.

n_hidden : integer

number of hidden units of the conditional rbms.

n_hidden_recurrent : integer

number of hidden units of the id56.

lr : float

learning rate

r : (integer, integer) tuple

specifies the pitch range of the piano-roll in midi note numbers,
including r[0] but not r[1], such that r[1]-r[0] is the number of
visible units of the rbm at a given time step. the default (21,
109) corresponds to the full range of piano (88 notes).

dt : float

sampling period when converting the midi files into piano-rolls, or
equivalently the time difference between consecutive time steps.         

self.r = r
self.dt = dt
(v, v_sample, cost, monitor, params, updates_train, v_t,

updates_generate) = build_id56rbm(

r[1] - r[0],
n_hidden,
n_hidden_recurrent

)

gradient = t.grad(cost, params, consider_constant=[v_sample])
updates_train.update(

((p, p - lr * g) for p, g in zip(params, gradient))

)
self.train_function = theano.function(

[v],
monitor,
updates=updates_train

)
self.generate_function = theano.function(

[],
v_t,
updates=updates_generate

)

def train(self, files, batch_size=100, num_epochs=200):

         train the id56-rbm via stochastic id119 (sgd) using midi
files converted to piano-rolls.

files : list of strings

list of midi files that will be loaded as piano-rolls for training.

batch_size : integer

training sequences will be split into subsequences of at most this
size before applying the sgd updates.

154chapter 14. modeling and generating sequences of polyphonic music with the id56-rbm

deep learning tutorial, release 0.1

num_epochs : integer

number of epochs (pass over the training set) performed. the user
can safely interrupt training with ctrl+c at any time.         

assert len(files) > 0,    training set is empty!    \

    (did you download the data files?)   

dataset = [midiread(f, self.r,

self.dt).piano_roll.astype(theano.config.floatx)

for f in files]

try:

for epoch in xrange(num_epochs):

numpy.random.shuffle(dataset)
costs = []

for s, sequence in enumerate(dataset):

for i in xrange(0, len(sequence), batch_size):

cost = self.train_function(sequence[i:i + batch_size])
costs.append(cost)

print    epoch %i/%i    % (epoch + 1, num_epochs),
print numpy.mean(costs)
sys.stdout.flush()

except keyboardinterrupt:

print    interrupted by user.   

def generate(self, filename, show=true):

         generate a sample sequence, plot the resulting piano-roll and save
it as a midi file.

filename : string

a midi file will be created at this location.

show : boolean

if true, a piano-roll of the generated sequence will be shown.         

piano_roll = self.generate_function()
midiwrite(filename, piano_roll, self.r, self.dt)
if show:

extent = (0, self.dt * len(piano_roll)) + self.r
pylab.figure()
pylab.imshow(piano_roll.t, origin=   lower   , aspect=   auto   ,

interpolation=   nearest   , cmap=pylab.cm.gray_r,
extent=extent)

pylab.xlabel(   time (s)   )
pylab.ylabel(   midi note number   )
pylab.title(   generated piano-roll   )

14.3 results

we ran the code on the nottingham database for 200 epochs; training took approximately 24 hours.

14.3. results

155

deep learning tutorial, release 0.1

the output was the following:

epoch 1/200 -15.0308940028
epoch 2/200 -10.4892606673
epoch 3/200 -10.2394696138
epoch 4/200 -10.1431669994
epoch 5/200 -9.7005382843
epoch 6/200 -8.5985647524
epoch 7/200 -8.35115428534
epoch 8/200 -8.26453580552
epoch 9/200 -8.21208991542
epoch 10/200 -8.16847274143

... truncated for brevity ...

epoch 190/200 -4.74799179994
epoch 191/200 -4.73488515216
epoch 192/200 -4.7326138489
epoch 193/200 -4.73841636884
epoch 194/200 -4.70255511452
epoch 195/200 -4.71872634914
epoch 196/200 -4.7276415885
epoch 197/200 -4.73497644728
epoch 198/200 -inf
epoch 199/200 -4.75554987143
epoch 200/200 -4.72591935412

the    gures below show the piano-rolls of two sample sequences and we provide the corresponding midi
   les:

figure 14.1: listen to sample1.mid

156chapter 14. modeling and generating sequences of polyphonic music with the id56-rbm

deep learning tutorial, release 0.1

figure 14.2: listen to sample2.mid

14.4 how to improve this code

the code shown in this tutorial is a stripped-down version that can be improved in the following ways:

    preprocessing: transposing the sequences in a common tonality (e.g. c major / minor) and normaliz-
ing the tempo in beats (quarternotes) per minute can have the most effect on the generative quality of
the model.

    pretraining techniques: initialize the w, bv, bh parameters with independent rbms with fully shuf-
   ed frames (i.e. wuh = wuv = wuu = wvu = 0); initialize the wuv, wuu, wvu, bu parameters
of the id56 with the auxiliary cross-id178 objective via either sgd or, preferably, hessian-free
optimization [boulangerlewandowski12].

    optimization techniques: gradient clipping, nesterov momentum and the use of nade for condi-

tional density estimation.

    hyperparameter search: learning rate (separately for the rbm and id56 parts), learning rate sched-
ules, batch size, number of hidden units (recurrent and rbm), momentum coef   cient, momentum
schedule, gibbs chain length k and early stopping.

    learn the initial condition u(0) as a model parameter.

a few samples generated with code including these features are available here: sequences.zip.

14.4. how to improve this code

157

deep learning tutorial, release 0.1

158chapter 14. modeling and generating sequences of polyphonic music with the id56-rbm

chapter
fifteen

miscellaneous

15.1 plotting samples and filters

note: the code for this section is available for download here.

to plot a sample, what we need to do is to take the visible units, which are a    attened image (there is no 2d
structure to the visible units, just a 1d string of unit activations) and reshape it into a 2d image. the order
in which the points from the 1d array go into the 2d image is given by the order in which the inital mnist
images where converted into a 1d array. lucky for us this is just a call of the numpy.reshape function.

plotting the weights is a bit more tricky. we have n_hidden hidden units, each of them corresponding to a
column of the weight matrix. a column has the same shape as the visible, where the weight corresponding
to the connection with visible unit j is at position j. therefore, if we reshape every such column, using
numpy.reshape, we get a    lter image that tells us how this hidden unit is in   uenced by the input image.

we need a utility function that takes a minibatch, or the weight matrix, and converts each row ( for the
weight matrix we do a transpose ) into a 2d image and then tile these images together. once we converted
the minibatch or the weights in this image of tiles, we can use pil to plot and save. pil is a standard python
libarary to deal with images.

tiling minibatches together is done for us by the tile_raster_image function which we provide here.

def scale_to_unit_interval(ndar, eps=1e-8):

""" scales all values in the ndarray ndar to be between 0 and 1 """
ndar = ndar.copy()
ndar -= ndar.min()
ndar *= 1.0 / (ndar.max() + eps)
return ndar

def tile_raster_images(x, img_shape, tile_shape, tile_spacing=(0, 0),

scale_rows_to_unit_interval=true,
output_pixel_vals=true):

"""
transform an array with one flattened image per row, into an array in
which images are reshaped and layed out like tiles on a floor.

this function is useful for visualizing datasets whose rows are images,
and also columns of matrices for transforming those rows

159

deep learning tutorial, release 0.1

(such as the first layer of a neural net).

:type x: a 2-d ndarray or a tuple of 4 channels, elements of which can
be 2-d ndarrays or none;
:param x: a 2-d array in which every row is a flattened image.

:type img_shape: tuple; (height, width)
:param img_shape: the original shape of each image

:type tile_shape: tuple; (rows, cols)
:param tile_shape: the number of images to tile (rows, cols)

:param output_pixel_vals: if output should be pixel values (i.e. int8
values) or floats

:param scale_rows_to_unit_interval: if the values need to be scaled before
being plotted to [0,1] or not

:returns: array suitable for viewing as an image.
(see:   image.fromarray   .)
:rtype: a 2-d array with same dtype as x.

"""

assert len(img_shape) == 2
assert len(tile_shape) == 2
assert len(tile_spacing) == 2

# the expression below can be re-written in a more c style as
# follows :
#
# out_shape = [0,0]
# out_shape[0] = (img_shape[0] + tile_spacing[0]) * tile_shape[0] -
#
# out_shape[1] = (img_shape[1] + tile_spacing[1]) * tile_shape[1] -
#
out_shape = [(ishp + tsp) * tshp - tsp for ishp, tshp, tsp

tile_spacing[0]

tile_spacing[1]

in zip(img_shape, tile_shape, tile_spacing)]

if isinstance(x, tuple):

assert len(x) == 4
# create an output numpy ndarray to store the image
if output_pixel_vals:

out_array = numpy.zeros((out_shape[0], out_shape[1], 4), dtype=   uint8   )

else:

out_array = numpy.zeros((out_shape[0], out_shape[1], 4), dtype=x.dtype)

#colors default to 0, alpha defaults to 1 (opaque)
if output_pixel_vals:

channel_defaults = [0, 0, 0, 255]

else:

channel_defaults = [0., 0., 0., 1.]

160

chapter 15. miscellaneous

deep learning tutorial, release 0.1

for i in xrange(4):

if x[i] is none:

# if channel is none, fill it with zeros of the correct
# dtype
out_array[:, :, i] = numpy.zeros(out_shape,

dtype=   uint8    if output_pixel_vals else out_array.dtype
) + channel_defaults[i]

else:

# use a recurrent call to compute the channel and store it
# in the output
out_array[:, :, i] = tile_raster_images(x[i], img_shape, tile_shape, tile_spacing, scale_rows_to_unit_interval, output_pixel_vals)

return out_array

else:

# if we are dealing with only one channel
h, w = img_shape
hs, ws = tile_spacing

# generate a matrix to store the output
out_array = numpy.zeros(out_shape, dtype=   uint8    if output_pixel_vals else x.dtype)

for tile_row in xrange(tile_shape[0]):

for tile_col in xrange(tile_shape[1]):

if tile_row * tile_shape[1] + tile_col < x.shape[0]:

if scale_rows_to_unit_interval:

# if we should scale values to be between 0 and 1
# do this by calling the    scale_to_unit_interval   
# function
this_img = scale_to_unit_interval(x[tile_row * tile_shape[1] + tile_col].reshape(img_shape))

else:

this_img = x[tile_row * tile_shape[1] + tile_col].reshape(img_shape)

# add the slice to the corresponding position in the
# output array
out_array[

tile_row * (h+hs): tile_row * (h + hs) + h,
tile_col * (w+ws): tile_col * (w + ws) + w
] \
= this_img * (255 if output_pixel_vals else 1)

return out_array

15.1. plotting samples and filters

161

deep learning tutorial, release 0.1

162

chapter 15. miscellaneous

chapter
sixteen

references

163

deep learning tutorial, release 0.1

164

chapter 16. references

bibliography

[alder59] alder, b. j. and wainwright, t. e. (1959)    studies in molecular dynamics. 1. general method   ,

journal of chemical physics, vol. 31, pp. 459-466.

[andersen80] andersen, h.c. (1980)    molecular dynamics simulations at constant pressure and/or temper-

ature   , journal of chemical physics, vol. 72, pp. 2384-2393.

[duane87] duane, s., kennedy, a. d., pendleton, b. j., and roweth, d. (1987)    hybrid monte carlo   ,

physics letters, vol. 195, pp. 216-222.

[neal93] neal, r. m. (1993)    probabilistic id136 using id115 methods   , tech-

nical report crg-tr-93-1, dept. of computer science, university of toronto, 144 pages

[bengio07] 25. bengio, p. lamblin, d. popovici and h. larochelle, greedy layer-wise training of deep
networks, in advances in neural information processing systems 19 (nips   06), pages 153-160,
mit press 2007.

[bengio09] 25. bengio, learning deep architectures for ai, foundations and trends in machine learning

1(2) pages 1-127.

[bengiodelalleau09] 25. bengio, o. delalleau, justifying and generalizing contrastive divergence

(2009), neural computation, 21(6): 1601-1621.

[boulangerlewandowski12] n boulanger-lewandowski, y. bengio and p. vincent, modeling temporal
dependencies in high-dimensional sequences: application to polyphonic music generation and tran-
scription, in proceedings of the 29th international conference on machine learning (icml), 2012.

[fukushima] fukushima, k. (1980). neocognitron: a self-organizing neural network model for a mecha-

nism of pattern recognition unaffected by shift in position. biological cybernetics, 36, 193   202.

[hinton06] g.e. hinton and r.r. salakhutdinov, reducing the dimensionality of data with neural net-

works, science, 28 july 2006, vol. 313. no. 5786, pp. 504 - 507.

[hinton07] g.e. hinton, s. osindero, and y. teh,    a fast learning algorithm for deep belief nets   , neural

computation, vol 18, 2006

[hubel68] hubel, d. and wiesel, t. (1968). receptive    elds and functional architecture of monkey striate

cortex. journal of physiology (london), 195, 215   243.

[lecun98] lecun, y., bottou, l., bengio, y., and haffner, p. (1998d). gradient-based learning applied to

document recognition. proceedings of the ieee, 86(11), 2278   2324.

165

deep learning tutorial, release 0.1

[lee08]

8. lee, c. ekanadham, and a.y. ng., sparse deep belief net model for visual area v2, in ad-

vances in neural information processing systems (nips) 20, 2008.

[lee09]

8. lee, r. grosse, r. ranganath, and a.y. ng,    convolutional id50 for scalable

unsupervised learning of hierarchical representations.   , icml 2009

[ranzato10] 13. ranzato, a. krizhevsky, g. hinton,    factored 3-way restricted id82s for
modeling natural images   . proc. of the 13-th international conference on arti   cial intelligence
and statistics (aistats 2010), italy, 2010

[ranzato07] m.a. ranzato, c. poultney, s. chopra and y. lecun, in j. platt et al., ef   cient learning
of sparse representations with an energy-based model, advances in neural information processing
systems (nips 2006), mit press, 2007.

[serre07] serre, t., wolf, l., bileschi, s., and riesenhuber, m. (2007). robust object recog- nition with
cortex-like mechanisms. ieee trans. pattern anal. mach. intell., 29(3), 411   426. member-poggio,
tomaso.

[vincent08] 16. vincent, h. larochelle y. bengio and p.a. manzagol, extracting and composing robust
features with denoising autoencoders, proceedings of the twenty-   fth international conference
on machine learning (icml   08), pages 1096 - 1103, acm, 2008.

[tieleman08] 20. tieleman, training restricted id82s using approximations to the likeli-

hood gradient, icml 2008.

[xavier10] 25. bengio, x. glorot, understanding the dif   culty of training deep feedforward neuralnet-

works, aistats 2010

166

bibliography

d
dataset notation, 7
datasets, 5
download:, 5
e
early-stopping, 12
l
l1 and l2 id173, 11
list of symbols and acronyms, 8
id28, 15
m
math convetions, 7
mnist dataset, 5
multilayer id88, 34
n
negative log   likelihood loss, 9
notation, 7
p
python namespaces, 8
r
id173, 11
s
stochastic id119, 10
t
testing, 14
z
zero-one loss, 8

index

167

