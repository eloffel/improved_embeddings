bilingual word representations with monolingual quality in mind

  minh-thang luong, hieu pham, and christopher d. manning

   thanks for reading our [1]paper and visiting this project page! if you
   have any questions, feel free to email us.
   english-german bilingual embeddings

   data:
   we release a counter part of the wordsim 353 dataset in german [2]here.

   bilingual embeddings:
   our trained bilingual embeddings whose performances are reported in the
   paper can be found below:
   using unsupervised alignments learned by berkeley aligner:
   [[3]unsup.40.en]   [[4]unsup.40.de]   [[5]unsup.128.en]
   [[6]unsup.128.de]   [[7]unsup.256.en]   [[8]unsup.256.de]
   [[9]unsup.512.en]   [[10]unsup.512.de] . using monotonic alignment
   assumption: [[11]mono.40.en]   [[12]mono.40.de]   [[13]mono.128.en]
   [[14]mono.128.de] .

   code:
   the code is available on [15]github.

   description:
   the bivec code was originated from tomas mikolov's id97. it trains
   bilingual embeddings as described in our paper. besides, it has all the
   functionalities of id97 with added features and code clarity.

   features:
   (a) train bilingual embeddings as described in our naacl 2015 workshop
   paper. (b) when training bilingual embeddings for english and german,
   it automatically produces the cross-lingual document classification
   results. (c) for monolingual embeddings, the code outputs word
   similarity results for english, german and word analogy results for
   english. (d) save output vectors besides input vectors. (e)
   automatically save vocab file and load vocab (if there's one exists).
   (f) the code has been extensively refactored to make it easier to
   understand and more comments have been added.

   references:
   (a) https://code.google.com/p/id97/.

   citation:

   @inproceedings{luong-etal:naacl15:bivec,_______________________________
           address = {denver, united states}______________________________
           author = {luong, minh-thang  and  pham, hieu and manning, chris
           booktitle = {naacl workshop on vector space modeling for nlp},_
           title = {bilingual word representations with monolingual qualit
           year = {2015}}_________________________________________________

references

   1. https://nlp.stanford.edu/~lmthang/data/papers/naacl15_bivec.pdf
   2. https://nlp.stanford.edu/~lmthang/bivec/de.txt
   3. http://nlp.stanford.edu/~lmthang/bivec/embed/unsup.40.en
   4. http://nlp.stanford.edu/~lmthang/bivec/embed/unsup.40.de
   5. http://nlp.stanford.edu/~lmthang/bivec/embed/unsup.128.en
   6. http://nlp.stanford.edu/~lmthang/bivec/embed/unsup.128.de
   7. http://nlp.stanford.edu/~lmthang/bivec/embed/unsup.256.en
   8. http://nlp.stanford.edu/~lmthang/bivec/embed/unsup.256.de
   9. http://nlp.stanford.edu/~lmthang/bivec/embed/unsup.512.en
  10. http://nlp.stanford.edu/~lmthang/bivec/embed/unsup.512.de
  11. http://nlp.stanford.edu/~lmthang/bivec/embed/mono.40.en
  12. http://nlp.stanford.edu/~lmthang/bivec/embed/mono.40.de
  13. http://nlp.stanford.edu/~lmthang/bivec/embed/mono.128.en
  14. http://nlp.stanford.edu/~lmthang/bivec/embed/mono.128.de
  15. https://github.com/lmthang/bivec
