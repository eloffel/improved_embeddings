   iframe: [1]//www.googletagmanager.com/ns.html?id=gtm-trbqmn

   [2]mit technology review

   hello,

   we noticed you're browsing in private or incognito mode.

   to continue reading this article, please exit incognito mode or [3]log
   in.

   not a subscriber? subscribe now for unlimited access to online
   articles.
   [4]subscribe today

why we made this change

   visitors are allowed 3 free articles per month (without a
   subscription), and private browsing prevents us from counting how many
   stories you've read. we hope you understand, and consider
   [5]subscribing for unlimited online access.
   [6]back to mit technology review home
   [7]contact customer service if you are seeing this message in error.

   [8]mit technology review (button) menu
     * topics
          +
               o [9]business impact
               o [10]connectivity
               o [11]intelligent machines
               o [12]rewriting life
               o [13]sustainable energy
          +
               o [14]10 breakthrough technologies
               o [15]35 innovators under 35
               o [16]50 smartest companies
          + [17]views
          + [18]views from the marketplace
     * [19]the download
     * [20]magazine
     * [21]events
     * more
          + [22]video
          + [23]podcasts
          + [24]special publications
          + [25]mit news magazine
          + [26]newsletters
          + [27]help/support
          + [28]advertise with us
     * [29]log in / create and account

     * [30]subscribe

     * [31]log in / [32]create an account
     * search

     * ____________________ submit
       click search or press enter

     *
     *
     *
     *
     *
     *
     *

   [so16ai1.jpg?sw=520&amp;cx=9&amp;cy=33&amp;cw=1903&amp;ch=2239]

[33]intelligent machines

ai   s language problem

machines that truly understand language would be incredibly useful. but we
don   t know how to build them.

     * by [34]will knight
     * august 9, 2016

   mel bochner
   babble
   2011
     *
     *
     *
     *
     *
     *
     *

   about halfway through a particularly tense game of go held in seoul,
   south korea, between lee sedol, one of the best players of all time,
   and alphago, an artificial intelligence created by google, the ai
   program made a mysterious move that demonstrated an unnerving edge over
   its human opponent.

   on move 37, alphago chose to put a black stone in what seemed, at
   first, like a ridiculous position. it looked certain to give up
   substantial territory   a rookie mistake in a game that is all about
   controlling the space on the board. two television commentators
   wondered if they had misread the move or if the machine had
   malfunctioned somehow. in fact, contrary to any conventional wisdom,
   move 37 would enable alphago to build a formidable foundation in the
   center of the board. the google program had effectively won the game
   using a move that no human would   ve come up with.

about the art

     * one reason that understanding language is so difficult for
       computers and ai systems is that words often have meanings based on
       context and even the appearance of the letters and words. in the
       images that accompany this story, several artists demonstrate the
       use of a variety of visual clues to convey meanings far beyond the
       actual letters.

   [35][so16coverx2000.jpg?sw=180]
   this story is part of our september/october 2016 issue
   [36]see the rest of the issue
   [37]subscribe

   alphago   s victory is particularly impressive because the ancient game
   of go is often looked at as a test of intuitive intelligence. the rules
   are quite simple. two players take turns putting black or white stones
   at the intersection of horizontal and vertical lines on a board, trying
   to surround their opponent   s pieces and remove them from play. playing
   well, however, is incredibly hard.

   whereas chess players are able to look a few moves ahead, in go this
   isn   t possible without the game unfolding into intractable complexity,
   and there are no classic gambits. there is also no straightforward way
   to measure advantage, and it can be hard for even an expert player to
   explain precisely why he or she made a particular move. this makes it
   impossible to write a simple set of rules for an expert-level computer
   program to follow.

   alphago wasn   t told how to play go at all. instead, the program
   analyzed hundreds of thousands of games and played millions of matches
   against itself. among several ai techniques, it used an increasingly
   popular method known as deep learning, which involves mathematical
   calculations inspired, very loosely, by the way interconnected layers
   of neurons fire in a brain as it learns to make sense of new
   information. the program taught itself through hours of practice,
   gradually honing an intuitive sense of strategy. that it was then able
   to beat one of the world   s best go players represents a true milestone
   in machine intelligence and ai.
   [so16ai2.jpg?sw=1180&amp;cx=13&amp;cy=13&amp;cw=2723&amp;ch=872]
   lawrence weiner
   a rubber ball thrown on the sea
   1970 / 2014

   a few hours after move 37, alphago won the game to go up two games to
   nothing in the best-of-five match. afterward sedol stood before a crowd
   of journalists and photographers, politely apologizing for letting
   humankind down.    i am quite speechless,    he said, blinking through a
   storm of flash photography.

   alphago   s surprising success points to just how much progress has been
   made in artificial intelligence over the last few years, after decades
   of frustration and setbacks often described as an    ai winter.    deep
   learning means that machines can increasingly teach themselves how to
   perform complex tasks that only a couple of years ago were thought to
   require the unique intelligence of humans. self-driving cars are
   already a foreseeable possibility. in the near future, systems based on
   deep learning will help diagnose diseases and recommend treatments.

   deep learning means that machines can increasingly teach themselves how
   to perform complex tasks that only a couple of years ago were thought
   to require the unique intelligence of humans.

   yet despite these impressive advances, one fundamental capability
   remains elusive: language. systems like siri and ibm   s watson can
   follow simple spoken or typed commands and answer basic questions, but
   they can   t hold a conversation and have no real understanding of the
   words they use. if ai is to be truly transformative, this must change.

   even though alphago cannot speak, it contains technology that might
   lead to greater language understanding. at companies such as google,
   facebook, and amazon, as well as at leading academic ai labs,
   researchers are attempting to finally solve that seemingly intractable
   problem, using some of the same ai tools   including deep learning   that
   are responsible for alphago   s success and today   s ai revival. whether
   they succeed will determine the scale and character of what is turning
   into an artificial-intelligence revolution. it will help determine
   whether we have machines we can easily communicate with   machines that
   become an intimate part of our everyday life   or whether ai systems
   remain mysterious black boxes, even as they become more autonomous.
      there   s no way you can have an ai system that   s humanlike that doesn   t
   have language at the heart of it,    says josh tenenbaum, a professor of
   cognitive science and computation at mit.    it   s one of the most obvious
   things that set human intelligence apart.   

   perhaps the same techniques that let alphago conquer go will finally
   enable computers to master language, or perhaps something else will
   also be required. but without language understanding, the impact of ai
   will be different. of course, we can still have immensely powerful and
   intelligent software like alphago. but our relationship with ai may be
   far less collaborative and perhaps far less friendly.    a nagging
   question since the beginning was    what if you had things that were
   intelligent in the sense of being effective, but not like us in the
   sense of not empathizing with what we are?       says terry winograd, a
   professor emeritus at stanford university.    you can imagine machines
   that are not based on human intelligence, which are based on this
   big-data stuff, and which run the world.   

   machine whisperers

   a couple of months after alphago   s triumph, i traveled to silicon
   valley, the heart of the latest boom in artificial intelligence. i
   wanted to visit the researchers who are making remarkable progress on
   practical applications of ai and who are now trying to give machines
   greater understanding of language.

   i started with winograd, who lives in a suburb nestled into the
   southern edge of stanford   s campus in palo alto, not far from the
   headquarters of google, facebook, and apple. with curly white hair and
   a bushy mustache, he looks the part of a venerable academic, and he has
   an infectious enthusiasm.

   back in 1968, winograd made one of the earliest efforts to teach a
   machine to talk intelligently. a math prodigy fascinated with language,
   he had come to mit   s new ai lab to study for his phd, and he decided to
   build a program that would converse with people, via a text prompt,
   using everyday language. it didn   t seem an outlandish ambition at the
   time. incredible strides were being made in ai, and others at mit were
   building complex id161 systems and futuristic robot arms.
      there was a sense of unknown, unbounded possibilities,    he recalls.
   [so16ai4.jpg?sw=600&amp;cx=0&amp;cy=12&amp;cw=2091&amp;ch=1541]
   joseph kosuth
   four colors four words
   1966

   not everyone was convinced that language could be so easily mastered,
   though. some critics, including the influential linguist and mit
   professor noam chomsky, felt that the ai researchers would struggle to
   get machines to understand, given that the mechanics of language in
   humans were so poorly understood. winograd remembers attending a party
   where a student of chomsky   s walked away when he heard him say that he
   worked in the ai lab.

   but there was reason to be optimistic, too. joseph weizenbaum, a
   german-born professor at mit, had built the very first chatbot program
   a couple of years earlier. called eliza, it was programmed to act like
   a cartoon psychotherapist, repeating key parts of a statement or asking
   questions to encourage further conversation. if you told the program
   you were angry at your mother, for instance, it would say,    what else
   comes to mind when you think about your mother?    a cheap trick, but it
   worked surprisingly well. weizenbaum was shocked when some subjects
   began confessing their darkest secrets to his machine.

   there   s an obvious problem with applying deep learning to language.
   it   s that words are arbitrary symbols, and as such they are
   fundamentally different from imagery.

   winograd wanted to create something that really seemed to understand
   language. he began by reducing the scope of the problem. he created a
   simple virtual environment, a    block world,    consisting of a handful of
   imaginary objects sitting on an imaginary table. then he created a
   program, [38]which he named shrdlu, that was capable of parsing all the
   nouns, verbs, and simple rules of grammar needed to refer to this
   stripped-down virtual world. shrdlu (a nonsense word formed by the
   second column of keys on a linotype machine) could describe the
   objects, answer questions about their relationships, and make changes
   to the block world in response to typed commands. it even had a kind of
   memory, so that if you told it to move    the red cone    and then later
   referred to    the cone,    it would assume you meant the red one rather
   than one of another color.

   shrdlu was held up as a sign that the field of ai was making profound
   progress. but it was just an illusion. when winograd tried to make the
   program   s block world larger, the rules required to account for the
   necessary words and grammatical complexity became unmanageable. just a
   few years later, he had given up, and eventually he abandoned ai
   altogether to focus on other areas of research.    the limitations were a
   lot closer than it seemed at the time,    he says.

   winograd concluded that it would be impossible to give machines true
   language understanding using the tools available then. the problem, as
   hubert dreyfus, a professor of philosophy at uc berkeley, argued in a
   1972 book called what computers can   t do, is that many things humans do
   require a kind of instinctive intelligence that cannot be captured with
   hard-and-fast rules. this is precisely why, before the match between
   sedol and alphago, many experts were dubious that machines would master
   go.
   [so16ai3.jpg?sw=600&amp;cx=17&amp;cy=41&amp;cw=2245&amp;ch=2209]
   john baldessari
   pure beauty
   1966   68

   but even as dreyfus was making that argument, a few researchers were,
   in fact, developing an approach that would eventually give machines
   this kind of intelligence. taking loose inspiration from neuroscience,
   they were experimenting with id158s   layers of
   mathematically simulated neurons that could be trained to fire in
   response to certain inputs. to begin with, these systems were painfully
   slow, and the approach was dismissed as impractical for logic and
   reasoning. crucially, though, neural networks could learn to do things
   that couldn   t be hand-coded, and later this would prove useful for
   simple tasks such as recognizing handwritten characters, a skill that
   was commercialized in the 1990s for [39]reading the numbers on checks.
   proponents maintained that neural networks would eventually let
   machines to do much, much more. one day, they claimed, the technology
   would even understand language.

   over the past few years, neural networks have become vastly more
   complex and powerful. the approach has benefited from key mathematical
   refinements and, more important, faster computer hardware and oodles of
   data. by 2009, researchers at the university of toronto had shown that
   a many-layered deep-learning network could recognize speech with record
   accuracy. and then in 2012, the same group won a machine-vision contest
   using a deep-learning algorithm that was astonishingly accurate.

   a deep-learning neural network recognizes objects in images using a
   simple trick. a layer of simulated neurons receives input in the form
   of an image, and some of those neurons will fire in response to the
   intensity of individual pixels. the resulting signal passes through
   many more layers of interconnected neurons before reaching an output
   layer, which signals that the object has been seen. a mathematical
   technique known as id26 is used to adjust the sensitivity of
   the network   s neurons to produce the correct response. it is this step
   that gives the system the ability to learn. different layers inside the
   network will respond to features such as edges, colors, or texture.
   such systems can now recognize objects, animals, or faces with an
   accuracy that rivals that of humans.

   there   s an obvious problem with applying deep learning to language.
   it   s that words are arbitrary symbols, and as such they are
   fundamentally different from imagery. two words can be similar in
   meaning while containing completely different letters, for instance;
   and the same word can mean various things in different contexts.

   in the 1980s, researchers had come up with a clever idea about how to
   turn language into the type of problem a neural network can tackle.
   they showed that words can be represented as mathematical vectors,
   allowing similarities between related words to be calculated. for
   example,    boat    and    water    are close in vector space even though they
   look very different. researchers at the university of montreal, led by
   yoshua bengio, and another group at google, have used this insight to
   build networks in which each word in a sentence can be used to
   construct a more complex representation   something that geoffrey hinton,
   a professor at the university of toronto and a prominent deep-learning
   researcher who works part-time at google, calls a    thought vector.   

   by using two such networks, it is possible to translate between two
   languages with excellent accuracy. and by combining this type of
   network with one designed to recognize objects in images, it is
   possible to conjure up surprisingly plausible captions.

   the purpose of life

   sitting in a conference room at the heart of google   s bustling
   headquarters in mountain view, california, one of the company   s
   researchers who helped develop this approach, [40]quoc le, is
   contemplating the idea of a machine that could hold a proper
   conversation. le   s ambitions cut right to the heart of why talking
   machines could be useful.    i want a way to simulate thoughts in a
   machine,    he says.    and if you want to simulate thoughts, then you
   should be able to ask a machine what it   s thinking about.   
   [so16ai5.jpg?sw=600&amp;cx=17&amp;cy=17&amp;cw=1883&amp;ch=2258]
   tauba auerbach
   the answer/wasn   t here ii
   2008

   google is already teaching its computers the basics of language. this
   may the company announced a system, dubbed parsey mcparseface, that can
   look at syntax, recognizing nouns, verbs, and other elements of text.
   it isn   t hard to see how valuable better language understanding could
   be to the company. google   s search algorithm used to simply track
   keywords and links between web pages. now, using a system called
   rankbrain, it reads the text on pages in an effort to glean meaning and
   deliver better results. le wants to take that much further. adapting
   the system that   s proved useful in translation and image captioning, he
   and his colleagues built smart reply, which reads the contents of gmail
   messages and suggests a handful of possible replies. he also created a
   program that learned from google   s it support chat logs how to answer
   simple technical queries.

   most recently, le built a program capable of producing passable
   responses to open-ended questions; it was trained by being fed dialogue
   from 18,900 movies. some of its replies seem eerily spot-on. for
   example, le asked,    what is the purpose of life?    and the program
   responded,    to serve the greater good.       it was a pretty good answer,   
   he remembers with a big grin.    probably better than mine would have
   been.   

   there   s only one problem, as quickly becomes apparent when you look at
   more of the system   s answers. when le asked,    how many legs does a cat
   have?    his system answered,    four, i think.    then he tried,    how many
   legs does a centipede have?    which produced a curious response:
      eight.    basically, le   s program has no idea what it   s talking about.
   it understands that certain combinations of symbols go together, but it
   has no appreciation of the real world. it doesn   t know what a centipede
   actually looks like, or how it moves. it is still just an illusion of
   intelligence, without the kind of common sense that humans take for
   granted. deep-learning systems can often be wonky this way. the one
   google created to generate captions for images would make bizarre
   errors, like describing a street sign as a refrigerator filled with
   food.

   le asked,    what is the purpose of life?    and the program responded,    to
   serve the greater good.   

   by a curious coincidence, terry winograd   s next-door neighbor in palo
   alto is someone who might be able to help computers attain a deeper
   appreciation of what words actually mean. fei-fei li, director of the
   stanford artificial intelligence lab, was on maternity leave when i
   visited, but she invited me to her home and proudly introduced me to
   her beautiful three-month-old baby, phoenix.    see how she looks at you
   more than me,    li said as phoenix stared at me.    that   s because you are
   new; it   s early facial recognition.   

   li has spent much of her career researching machine learning and
   id161. several years ago, she led an effort to build a
   database of millions of images of objects, each tagged with an
   appropriate keyword. but li believes machines need an even more
   sophisticated understanding of what   s happening in the world, and this
   year her team released another database of images, annotated in much
   richer detail. each image has been tagged by a human with dozens of
   descriptors:    a dog riding a skateboard,       dog has fluffy, wavy fur,   
      road is cracked,    and so on. the hope is that machine-learning systems
   will learn to understand more about the physical world.    the language
   part of the brain gets fed a lot of information, including from the
   visual system,    li says.    an important part of ai will be integrating
   these systems.   

   this is closer to the way children learn, by associating words with
   objects, relationships, and actions. but the analogy with human
   learning goes only so far. young children do not need to see a
   skateboarding dog to be able to imagine or verbally describe one.
   indeed, li believes that today   s machine-learning and ai tools won   t be
   enough to bring about real ai.    it   s not just going to be data-rich
   deep learning,    she says. li believes ai researchers will need to think
   about things like emotional and social intelligence.    we [humans] are
   terrible at computing with huge data,    she says,    but we   re great at
   abstraction and creativity.   

   no one knows how to give machines those human skills   if it is even
   possible. is there something uniquely human about such qualities that
   puts them beyond the reach of ai?

   cognitive scientists like mit   s tenenbaum theorize that important
   components of the mind are missing from today   s neural networks, no
   matter how large those networks might be. humans have the ability to
   learn very quickly from a relatively small amount of data and have a
   built-in ability to model the world in 3-d very efficiently.    language
   builds on other abilities that are probably more basic, that are
   present in young infants before they have language: perceiving the
   world visually, acting on our motor systems, understanding the physics
   of the world or other agents    goals,    tenenbaum says.

   if he is right, then it will be difficult to re-create language
   understanding in machines and ai systems without trying to mimic human
   learning, mental model building, and psychology.

   explain yourself

   noah goodman   s office in stanford   s psychology department is
   practically bare except for a couple of abstract paintings propped
   against one wall and a few overgrown plants. when i arrived, goodman
   was typing away on a laptop, his bare feet up on a table. we took a
   stroll across the sun-bleached campus for iced coffee.    language is
   special in that it relies on a lot of knowledge about language but it
   also relies on a huge amount of common-sense knowledge about the world,
   and those two go together in very subtle ways,    he explained.

   goodman and his students have developed a programming language, called
   webppl, that can be used to give computers a kind of probabilistic
   common sense, which turns out to be pretty useful in a conversation.
   one experimental version can understand puns, and another can cope with
   hyperbole. if it is told that some people had to wait    forever    for a
   table in a restaurant, it will automatically decide that the literal
   meaning is improbable, and they most likely just hung around for a long
   time and were annoyed. the system is far from truly intelligent, but it
   shows how new approaches could help make ai programs that talk in a
   more lifelike way.

   at the same time, goodman   s example also suggests just how difficult it
   will be to teach language to machines. understanding the contextual
   meaning of    forever    is the kind of thing that ai systems will need to
   learn, but it is a rather simple and rudimentary accomplishment.

      i want a way to simulate thoughts in a machine,    he says.    and if you
   want to simulate thoughts, then you should be able to ask a machine
   what it   s thinking about.   

   still, despite the difficulty and complexity of the problem, the
   startling success that researchers have had using deep-learning
   techniques to recognize images and excel at games like go does at least
   provide hope that we might be on the verge of breakthroughs in
   language, too. if so, those advances will come just in time. if ai is
   to serve as a ubiquitous tool that people use to augment their own
   intelligence and trust to take over tasks in a seaid113ss collaboration,
   language will be key. that will be especially true as ai systems
   increasingly use deep learning and other techniques to essentially
   program themselves.

      in general, deep-learning systems are awe-inspiring,    says john
   leonard, a professor at mit who researches automated driving.    but on
   the other hand, their performance is really hard to understand.   

   toyota, which is studying a range of self-driving technologies, has
   initiated a research project at mit led by gerald sussman, an expert on
   artificial intelligence and programming language, to develop automated
   driving systems capable of explaining why they took a particular
   action. and an obvious way for a self-driving car to do this would be
   by talking.    building systems that know what they know is a really hard
   problem,    says leonard, who is leading a different toyota-backed
   project at mit.    but yeah, ideally they would give not just an answer
   but an explanation.   

   a few weeks after returning from california, i saw david silver, the
   google deepmind researcher who designed alphago, give a talk about the
   match against sedol at an academic conference in new york. silver
   explained that when the program came up with its killer move during
   game two, his team was just as surprised as everyone else. all they
   could see was alphago   s predicted odds of winning, which changed little
   even after move 37. it was only several days later, after careful
   analysis, that the google team made a discovery: by digesting previous
   games, the program had calculated the chances of a human player making
   the same move at one in 10,000. and its practice games had also shown
   that the play offered an unusually strong positional advantage.

   so in a way, the machine knew that sedol would be completely
   blindsided.

   silver said that google is considering several options for
   commercializing the technology, including some sort of intelligent
   assistant and a tool for health care. afterward, i asked him about the
   importance of being able to communicate with the ai behind such
   systems.    that   s an interesting question,    he said after a pause.    for
   some applications it may be important. like in health care, it may be
   important to know why a decision is being made.   

   indeed, as ai systems become increasingly sophisticated and complex, it
   is hard to envision how we will collaborate with them without
   language   without being able to ask them,    why?    more than this, the
   ability to communicate effortlessly with computers would make them
   infinitely more useful, and it would feel nothing short of magical.
   after all, language is our most powerful way of making sense of the
   world and interacting with it. it   s about time that our machines
   caught up.

   will knight is senior editor for ai and robotics at mit technology
   review. his feature    [41]the people   s robots    appeared in the
   [42]may/june issue.

   learn from the humans leading the way in intelligent machines at emtech
   next. register today!
   june 11-12, 2019
   cambridge, ma
   [43]register now
   lawrence weiner
   a rubber ball thrown on the sea
   1970 / 2014
   joseph kosuth
   four colors four words
   1966
   john baldessari
   pure beauty
   1966   68
   tauba auerbach
   the answer/wasn   t here ii
   2008
   (button)
   (button)

share

     *
     *
     *
     *
     *
     *
     *

tagged

   [44]fei-fei li, [45]josh tenenbaum, [46]google deepmind, [47]go,
   [48]artificial intelligence, [49]ai, [50]alphago, [51]lee sedol,
   [52]terry winograd, [53]emtech 2016, [54]mit technology review events

credit

   courtesy of mel bochner and peter freeman inc. (bochner); photo by
   cathy carver | courtesy of moved pictures archive |    2016 lawrence
   weiner / artists rights society, new york (weiner); courtesy of john
   baldessari and marian goodman gallery (baldessari); courtesy of joseph
   kosuth and sean kelly, new york;    2016 joseph kosuth/artists rights
   society (ars), new york (kosuth);    tauba auerbach; courtesy of paula
   cooper gallery (auerbach)
   will knight

   [55]will knight senior editor, ai

   will knight is mit technology review   s senior editor for artificial
   intelligence. he covers the latest advances in ai and related fields,
   including machine learning, automated driving, and robotics. will
   joined mit technology review in    [56]more 2008 from the uk science
   weekly new scientist magazine.
   [57]read comments

   please read our [58]commenting guidelines.
   please enable javascript to view the [59]comments powered by disqus.

  related video

   [60]more videos

   [will_knight.png?sw=75]

   intelligent machines
   accelerating discovery with self-driving laboratories 27:00
   [will_knight.png?sw=75]

   intelligent machines
   how to develop your own ai playbook 27:32
   [will_knight.png?sw=75]

   intelligent machines
   ai transforming the developing world 20:56
   [will_knight.png?sw=75]

   intelligent machines
   ai for social good 22:27

   more from intelligent machines

   artificial intelligence and robots are transforming how we work and
   live.

     * facebook   s ad-serving algorithm discriminates by gender and race
       even if an advertiser is well-intentioned, the algorithm still
       prefers certain groups of people over others.
       by karen hao
     * machine learning is making pesto even more delicious
       researchers at mit have used ai to improve the flavor of basil.
       it   s part of a trend that is seeing artificial intelligence
       revolutionize farming.
       by will knight
     * boston dynamics buys a better brain for its robots
       the world   s most agile robots are about to get a lot smarter thanks
       to the purchase of a startup focused on id161 and machine
       learning.
       by will knight

   [61]more from intelligent machines

   from our advertisers
     * [62]in association with vmware
       digital transformation sparks innovation in networking
     * [63]in association with google
       for data-savvy marketers, there   s a new keyword: intent
     * [64]in association with google
       machine learning teaches marketers to cultivate a growth mindset
     * [65]in association with oracle and intel
       machine learning - driven analytics: key to digital transformation

   want more award-winning journalism? subscribe to mit technology review.
     * print + all access digital {! insider.prices.print_digital !}* best
       value
       {! insider.display.menuoptionslabel !}
       the best of mit technology review in print and online, plus
       unlimited access to our online archive, an ad-free web experience,
       discounts to mit technology review events, and the download
       delivered to your email in-box each weekday.
       {! insider.buttons.print_digital.buttontext !}
       see details+
       12-month subscription
       unlimited access to all our daily online news and feature stories
       6 bi-monthly issues of print + digital magazine
       10% discount to mit technology review events
       access to entire pdf magazine archive dating back to 1899
       ad-free website experience
       the download: newsletter delivery each weekday to your inbox
       the mit technology review app
     * all access digital {! insider.prices.digital !}*
       {! insider.display.menuoptionslabel !}
       the digital magazine, plus unlimited site access, our online
       archive, and the download delivered to your email in-box each
       weekday.
       {! insider.buttons.digital.buttontext !}
       see details+
       12-month subscription
       unlimited access to all our daily online news and feature stories
       digital magazine (6 bi-monthly issues)
       access to entire pdf magazine archive dating back to 1899
       the download: newsletter delivery each weekday to your inbox
     * print subscription {! insider.prices.print_only !}*
       {! insider.display.menuoptionslabel !}
       six print issues per year plus the download delivered to your email
       in-box each weekday.
       {! insider.buttons.print_only.buttontext !}
       see details+
       12-month subscription
       print magazine (6 bi-monthly issues)
       the download: newsletter delivery each weekday to your inbox

   * {! insider.display.footerlabel !}

   [66]see international prices

   [67]see u.s. prices

   [68]revert to standard pricing

   the algorithm artificial intelligence, demystified

   follow us
   [69]twitter [70]facebook [71]rss

   mit technology review

   the mission of mit technology review is to bring about better-informed
   and more conscious decisions about technology through authoritative,
   influential, and trustworthy journalism.
   [72]

   browse
   international
   editions
     * company
          + [73]about us
          + [74]careers
          + [75]advertise with us
          + [76]insights
          + [77]licensing, syndication, & reuse
          + [78]press room
          + [79]subscriptions
     * your account
          + [80]log in / create account
          + [81]activate account
          + [82]newsletters
          + [83]manage account
          + [84]manage subscription
     * customer support
          + [85]help/faqs
          + [86]contact us
          + [87]feedback
          + [88]sitemap
     * more
          + [89]events
          + [90]mit enterprise forum
          + [91]mit news
     * policies
          + [92]ethics statement
          + [93]terms of service
          + [94]privacy
          + [95]cookie statement
          + [96]commenting guidelines

   [97]mit technology review    2019 v.|e^i  |

   /3
   you've read of three free articles this month. [98]subscribe now for
   unlimited online access. you've read of three free articles this month.
   [99]subscribe now for unlimited online access. this is your last free
   article this month. [100]subscribe now for unlimited online access.
   you've read all your free articles this month. [101]subscribe now for
   unlimited online access. you've read of three free articles this month.
   [102]log in for more, or [103]subscribe now for unlimited online
   access. [104]log in for two more free articles, or [105]subscribe now
   for unlimited online access.

references

   visible links
   1. https://www.googletagmanager.com/ns.html?id=gtm-trbqmn
   2. https://www.technologyreview.com/
   3. https://www.technologyreview.com/login/?redirectto=/s/602094/ais-language-problem/
   4. https://go.technologyreview.com/insider/pricing/
   5. https://go.technologyreview.com/insider/pricing/
   6. https://www.technologyreview.com/
   7. https://www.technologyreview.com/help/contact/
   8. https://www.technologyreview.com/
   9. https://www.technologyreview.com/topic/business-impact/
  10. https://www.technologyreview.com/topic/connectivity/
  11. https://www.technologyreview.com/topic/intelligent-machines/
  12. https://www.technologyreview.com/topic/rewriting-life/
  13. https://www.technologyreview.com/topic/sustainable-energy/
  14. https://www.technologyreview.com/lists/technologies/
  15. https://www.technologyreview.com/lists/innovators-under-35/
  16. https://www.technologyreview.com/lists/companies/
  17. https://www.technologyreview.com/views/
  18. https://www.technologyreview.com/views-from-the-marketplace/
  19. https://www.technologyreview.com/the-download/
  20. https://www.technologyreview.com/magazine/
  21. https://events.technologyreview.com/
  22. https://www.technologyreview.com/videos/
  23. https://www.technologyreview.com/business-lab/
  24. https://www.technologyreview.com/magazine/special-publications/
  25. https://www.technologyreview.com/mit-news/
  26. https://go.technologyreview.com/newsletters
  27. https://www.technologyreview.com/help/
  28. https://mediakit.technologyreview.com/
  29. https://www.technologyreview.com/login/?redirectto=/s/602094/ais-language-problem/
  30. https://www.technologyreview.com/subscribe/
  31. https://www.technologyreview.com/login/?redirectto=/s/602094/ais-language-problem/
  32. https://www.technologyreview.com/login/?redirectto=/s/602094/ais-language-problem/
  33. https://www.technologyreview.com/topic/intelligent-machines/
  34. https://www.technologyreview.com/profile/will-knight/
  35. https://www.technologyreview.com/magazine/2016/09/
  36. https://www.technologyreview.com/magazine/2016/09/
  37. https://www.technologyreview.com/subscribe/
  38. http://hci.stanford.edu/winograd/shrdlu/name.html
  39. https://www.technologyreview.com/s/540001/teaching-machines-to-understand-us/
  40. https://www.technologyreview.com/lists/innovators-under-35/2014/visionary/quoc-le/
  41. https://www.technologyreview.com/s/601215/china-is-building-a-robot-army-of-model-workers/
  42. https://www.technologyreview.com/magazine/2016/05/
  43. https://events.technologyreview.com/emtech/next/19/?utm_medium=trsite&utm_source=instory&utm_campaign=emtech_next_2019.unpaid.acquisition&utm_content=fact&discount=tagnxinst#section-register
  44. https://www.technologyreview.com/g/fei-fei-li/
  45. https://www.technologyreview.com/g/josh-tenenbaum/
  46. https://www.technologyreview.com/g/google-deepmind/
  47. https://www.technologyreview.com/g/go/
  48. https://www.technologyreview.com/g/artificial-intelligence/
  49. https://www.technologyreview.com/g/ai/
  50. https://www.technologyreview.com/g/alphago/
  51. https://www.technologyreview.com/g/lee-sedol/
  52. https://www.technologyreview.com/g/terry-winograd/
  53. https://www.technologyreview.com/g/emtech-2016/
  54. https://www.technologyreview.com/g/mit-technology-review-events/
  55. https://www.technologyreview.com/profile/will-knight/
  56. https://www.technologyreview.com/s/602094/ais-language-problem/
  57. https://www.technologyreview.com/s/602094/ais-language-problem/
  58. https://www.technologyreview.com/about/commenting-guidelines/
  59. https://disqus.com/?ref_noscript
  60. https://www.technologyreview.com/videos/
  61. https://www.technologyreview.com/topic/intelligent-machines/
  62. https://www.technologyreview.com/s/612364/digital-transformation-sparks-innovation-in-networking/
  63. https://www.technologyreview.com/s/612244/for-data-savvy-marketers-theres-a-new-keyword-intent/
  64. https://www.technologyreview.com/s/611994/machine-learning-teaches-marketers-to-cultivate-a-growth-mindset/
  65. https://www.technologyreview.com/s/611996/machine-learning-driven-analytics-key-to-digital-transformation/
  66. https://www.technologyreview.com/s/602094/ais-language-problem/
  67. https://www.technologyreview.com/s/602094/ais-language-problem/
  68. https://www.technologyreview.com/s/602094/ais-language-problem/
  69. https://twitter.com/techreview
  70. https://www.facebook.com/technologyreview
  71. https://www.technologyreview.com/rss/
  72. https://www.technologyreview.com/editions/
  73. https://www.technologyreview.com/about/
  74. https://www.technologyreview.com/careers/
  75. https://www.technologyreview.com/media/
  76. https://www.technologyreview.com/s/603603/mit-technology-review-custom-content-showcase/
  77. https://www.technologyreview.com/about/licensing-syndication/
  78. https://www.technologyreview.com/press-room/
  79. https://go.technologyreview.com/insider/pricing/
  80. https://www.technologyreview.com/login/
  81. https://www.technologyreview.com/activate/
  82. https://go.technologyreview.com/newsletters
  83. https://www.technologyreview.com/account/
  84. https://subscribe.technologyreview.com/ecom/mtr/app/live/subcustserv?pagemode=start&org=mtr&publ=tr&php=y
  85. https://www.technologyreview.com/help/
  86. https://www.technologyreview.com/help/contact/
  87. https://www.technologyreview.com/help/contact/
  88. https://www.technologyreview.com/sitemap/
  89. https://www.technologyreview.com/events/
  90. http://www.mitef.org/
  91. https://www.technologyreview.com/mit-news/
  92. https://www.technologyreview.com/about/ethics-statement/
  93. https://www.technologyreview.com/about/terms-of-service/
  94. https://www.technologyreview.com/about/privacy/
  95. https://www.technologyreview.com/about/cookies/
  96. https://www.technologyreview.com/about/commenting-guidelines/
  97. https://www.technologyreview.com/about/terms-of-service/
  98. https://go.technologyreview.com/insider/pricing/
  99. https://go.technologyreview.com/insider/pricing/
 100. https://go.technologyreview.com/insider/pricing/
 101. https://go.technologyreview.com/insider/pricing/
 102. https://www.technologyreview.com/login/?redirectto=/s/602094/ais-language-problem/
 103. https://go.technologyreview.com/insider/pricing/
 104. https://www.technologyreview.com/login/?redirectto=/s/602094/ais-language-problem/
 105. https://go.technologyreview.com/insider/pricing/

   hidden links:
 107. https://www.technologyreview.com/s/602094/ais-language-problem/#disqus_thread
 108. https://www.technologyreview.com/s/602094/ais-language-problem/
 109. https://www.technologyreview.com/s/602094/ais-language-problem/
 110. https://www.technologyreview.com/s/602094/ais-language-problem/
 111. https://www.technologyreview.com/s/602094/ais-language-problem/
 112. https://www.technologyreview.com/s/602094/ais-language-problem/
 113. https://www.technologyreview.com/s/602094/ais-language-problem/
 114. https://www.technologyreview.com/s/602094/ais-language-problem/#disqus_thread
 115. https://www.technologyreview.com/s/602094/ais-language-problem/
 116. https://www.technologyreview.com/s/602094/ais-language-problem/
 117. https://www.technologyreview.com/s/602094/ais-language-problem/
 118. https://www.technologyreview.com/s/602094/ais-language-problem/
 119. https://www.technologyreview.com/s/602094/ais-language-problem/
 120. https://www.technologyreview.com/s/602094/ais-language-problem/
 121. https://www.technologyreview.com/s/602094/ais-language-problem/#disqus_thread
 122. https://www.technologyreview.com/s/602094/ais-language-problem/
 123. https://www.technologyreview.com/s/602094/ais-language-problem/
 124. https://www.technologyreview.com/s/602094/ais-language-problem/
 125. https://www.technologyreview.com/s/602094/ais-language-problem/
 126. https://www.technologyreview.com/s/602094/ais-language-problem/
 127. https://www.technologyreview.com/s/602094/ais-language-problem/
 128. https://events.technologyreview.com/video/watch/aspuru-guzik-accellerating-discovery/
 129. https://events.technologyreview.com/video/watch/aspuru-guzik-accellerating-discovery/
 130. https://events.technologyreview.com/video/watch/andrew-ng-ai-playbook/
 131. https://events.technologyreview.com/video/watch/andrew-ng-ai-playbook/
 132. https://events.technologyreview.com/video/watch/solomon-assefa-ai-developing-world/
 133. https://events.technologyreview.com/video/watch/solomon-assefa-ai-developing-world/
 134. https://events.technologyreview.com/video/watch/rahul-panicker-ai-social-good/
 135. https://events.technologyreview.com/video/watch/rahul-panicker-ai-social-good/
 136. https://www.technologyreview.com/s/613274/facebook-algorithm-discriminates-ai-bias/
 137. https://www.technologyreview.com/s/613274/facebook-algorithm-discriminates-ai-bias/
 138. https://www.technologyreview.com/s/613262/machine-learning-is-making-pesto-even-more-delicious/
 139. https://www.technologyreview.com/s/613262/machine-learning-is-making-pesto-even-more-delicious/
 140. https://www.technologyreview.com/s/613260/boston-dynamics-kinema-acquisition/
 141. https://www.technologyreview.com/s/613260/boston-dynamics-kinema-acquisition/
