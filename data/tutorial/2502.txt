                 the [1]takelab semantic text similarity system

   version: 1.0
   release date: april 18, 2012

1 description

   the [2]takelab semantic text similarity system was entered as
   task6-takelab-simple in the [3]semeval-2012: semantic evaluation
   exercises to perform the [4]semantic textual similarity task:
   given two sentences, s1 and s2, the system provides a similarity score
   as a floating point number on the scale of 0 (no relation) to 5
   (semantic equivalence).
   the semeval-2012 organizers measured the performance of our system by
   comparing its output with the aggregated similarity scores obtained
   from human subjects on the same data set using the [5]pearson
   correlation coefficient.
   please see [6]this page for more detailed information.
   if you use the software or the datasets, please cite the following
   paper:
   [7]  ari  , f., glava   g., karan m.,   najder j., dalbelo ba  i   b.:
   takelab: systems for measuring semantic text similarity. in proceedings
   of the sixth international workshop on semantic evaluation (semeval
   2012). pp. 441-448. acl, montreal, canada (7-8 june 2012).
   the bibtex format is:
@inproceedings{saric2012takelab,
  author    = {\v{s}ari\'{c}, frane  and  glava\v{s}, goran  and  karan, mladen

               and  \v{s}najder, jan  and  dalbelo ba\v{s}i\'{c}, bojana},
  title     = {takelab: systems for measuring semantic text similarity},
  booktitle = {proceedings of the sixth international workshop on semantic evalu
ation
               {(semeval 2012)}},
  month     = {7-8 june},
  year      = {2012},
  address   = {montr\'{e}al, canada},
  publisher = {association for computational linguistics},
  pages     = {441--448},
  url       = {http://www.aclweb.org/anthology/s12-1060}
}

2 instructions

  2.1 installation prerequisites

   this system requires the following packages: [8]python 2.7, [9]nltk,
   [10]numpy, and [11]libid166.
   if you are using ubuntu linux or a similar distribution, you can
   install all of the prerequisites by typing:
sudo apt-get install python-nltk python-numpy libid166-tools

   once you install the [12]nltk package, you need to issue the following
   commands to download the pos tagger model and the id138 corpus:
python -c "import nltk; nltk.download()"

   when prompted, please select the maxent_treebank_pos_tagger model and
   the id138 corpus.

  2.2 download

   the source code and the data files can be downloaded from this
   location:
     * [13]takelab_sts.tgz (78 mb)

  2.3 usage

    generating the features

   issuing
python takelab_simple_features.py train/sts.input.msrvid.txt train/sts.gs.msrvid
.txt > msrvid-train.txt
python takelab_simple_features.py test/sts.input.msrvid.txt > msrvid-test.txt

   will generate the requisite features from the
   train/sts.input.msrvid.txt and test/sts.input.msrvid.txt files
   respectively. note: in order to avoid an unreasonably large file
   download, the provided implementation contains the file with the word
   frequencies (word-frequencies.txt) and the lsa word vectors
   (nyt_words.txt, nyt_word_vectors.txt, wikipedia_words.txt and
   wikipedia_word_vectors.txt) which were filtered to contain only the
   words appearing in the official [14]train and [15]test sets. using the
   larger unfiltered datasets on the provided train and test sets will not
   affect the output of this software in any way.

    obtaining the model parameters

   executing the provided shell script grid-search.sh
./grid-search.sh msrvid-train.txt

   will find the optimal model parameters for the support vector
   regression using [16]libid166. the above command will finish with the
   following output:
best correlation: 0.873686
type: id166-train -s 3 -t 2 -c 200 -g .02 -p .5 msrvid-train.txt model.txt

   thus the optimal libid166 parameters for msrvid-train.txt are: -s 3 -t 2
   -c 200 -g .02 -p .5.
   note: the best correlation and the set of optimal parameters might vary
   slightly depending on the installed version of nltk, the id138
   corpus, and libid166.

    training

   by copy-pasting the command suggested by grid-search.sh, i.e. the text
   following "type:"
id166-train -s 3 -t 2 -c 200 -g .02 -p .5 msrvid-train.txt model.txt

   one trains the model for msr-video corpus.
   the training will finish with the following output:
.
warning: using -h 0 may be faster
*.*
optimization finished, #iter = 2777
nu = 0.431544
obj = -33239.258433, rho = -2.938525
nsv = 337, nbsv = 311

    evaluation

   to evaluate the msrvid model against the msrvid test set, one can issue
id166-predict msrvid-test.txt model.txt msrvid-output.txt

   which should output the following:
mean squared error = 7.03655 (regression)
squared correlation coefficient = -nan (regression)

   the obtained sentence similarity scores need postprocessing by the
   postprocess_scores.py script
python postprocess_scores.py test/sts.input.msrvid.txt msrvid-output.txt

   which handles some trivial corner cases of our scoring function. to
   obtain the pearson correlation, one can run the correlation.pl script
   which was provided by the semeval organizers alongside the training
   data:
perl correlation.pl msrvid-output.txt test/sts.gs.msrvid.txt

   which outputs
pearson: 0.88516

   indicating that the sentence similarity scores produced by our system
   have the pearson correlation of 0.88516 when compared to the similarity
   scores reported by the human subjects (contained in the file
   test/sts.gs.msrvid.txt). please note that the system that we provide on
   this page differs slightly from the system that was submitted to
   semeval. a couple of features described in the paper are not used in
   this implementation (in particular sentence length and the number of
   differing lemmas) and the implementation of some features might be
   slightly different. please [17]email us if you notice any major
   differences.

  2.4 additional data

   we used the [18]google books ngrams dataset to obtain word frequencies.
   the word-frequencies.txt file provided herein is filtered to only the
   words appearing in the train and test sets. however, providing a
   larger, unfiltered file does not change the output of the system in any
   way. several features use the word lsa vectors obtained from the
   wikipedia and [19]new york times annotated corpus. since the full
   matrices containing all the lsa vectors are very large, we provide only
   the shortened versions containing the vectors corresponding to train
   and test set words. if you are interested in full matrices or the code
   that generates them, please email [20]info@takelab.hr.

3 license

   this code is available under a derivative of a bsd-license that
   requires proper attribution. essentially, you can use, modify and sell
   this software or the derived software in academic and non-academic,
   commercial and non-commercial, open-source and closed-source settings,
   but you have to give proper credit.

references

   1. http://takelab.fer.hr/
   2. http://takelab.fer.hr/
   3. http://www.cs.york.ac.uk/semeval-2012/
   4. http://www.cs.york.ac.uk/semeval-2012/task6/
   5. http://en.wikipedia.org/wiki/pearson_product-moment_correlation_coefficient
   6. http://www.cs.york.ac.uk/semeval-2012/task6/data/uploads/datasets/train-readme.txt
   7. http://www.aclweb.org/anthology/s12-1060
   8. http://www.python.org/
   9. http://nltk.org/
  10. http://takelab.fer.hr/sts/numpy
  11. http://www.csie.ntu.edu.tw/~cjlin/libid166
  12. http://nltk.org/
  13. http://takelab.fer.hr/sts/takelab_sts.tgz
  14. http://www.cs.york.ac.uk/semeval-2012/task6/data/uploads/datasets/train.tgz
  15. http://www.cs.york.ac.uk/semeval-2012/task6/data/uploads/datasets/test-gold.tgz
  16. http://www.csie.ntu.edu.tw/~cjlin/libid166
  17. mailto:info@takelab.hr
  18. http://books.google.com/ngrams/datasets
  19. http://www.ldc.upenn.edu/catalog/catalogentry.jsp?catalogid=ldc2008t19
  20. mailto:info@takelab.hr
