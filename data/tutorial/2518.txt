   #[1]deep learning    feed [2]deep learning    comments feed [3]deep
   learning    software links comments feed [4]alternate [5]alternate

     * [6]home
     * [7]about
     * [8]reading list
          + [9]tutorials
     * [10]software links
     * [11]blog
     * [12]demos
     * [13]datasets
     * [14]events
     * [15]bibliography
     * [16]deep learning research groups
     * [17]icml 2013 challenges in representation learning
          + [18]challenges
          + [19]schedule
     * [20]deep learning job listings
     * [21]startup news

   [22]deep learning

[23]deep learning

       moving beyond shallow machine learning since 2006!
                       [24]comments[25]posts
   ____________________




archives

     * [26]july 2016
     * [27]december 2015
     * [28]november 2015
     * [29]october 2015
     * [30]september 2015
     * [31]july 2015
     * [32]november 2014
     * [33]october 2014
     * [34]september 2014
     * [35]may 2014
     * [36]april 2014
     * [37]january 2014
     * [38]december 2013
     * [39]october 2013
     * [40]september 2013
     * [41]august 2013
     * [42]july 2013
     * [43]june 2013
     * [44]may 2013
     * [45]april 2013
     * [46]march 2013
     * [47]february 2013
     * [48]january 2013
     * [49]december 2012
     * [50]january 2012
     * [51]august 2011
     * [52]june 2011
     * [53]february 2011
     * [54]december 2010
     * [55]october 2010
     * [56]april 2010
     * [57]march 2010
     * [58]january 2010

meta

     * [59]log in
     * [60]entries rss
     * [61]comments rss
     * [62]wordpress.org

software links

    1. [63]theano     cpu/gpu symbolic expression compiler in python (from
       mila lab at university of montreal)
    2. [64]torch     provides a matlab-like environment for state-of-the-art
       machine learning algorithms in lua (from ronan collobert, clement
       farabet and koray kavukcuoglu)
    3. [65]pylearn2     pylearn2 is a library designed to make machine
       learning research easy.
    4. [66]blocks     a theano framework for training neural networks
    5. [67]tensorflow     tensorflow    is an open source software library for
       numerical computation using data flow graphs.
    6. [68]mxnet     mxnet is a deep learning framework designed for both
       efficiency and flexibility.
    7. [69]caffe -caffe is a deep learning framework made with expression,
       speed, and modularity in mind.caffe is a deep learning framework
       made with expression, speed, and modularity in mind.
    8. [70]lasagne     lasagne is a lightweight library to build and train
       neural networks in theano.
    9. [71]keras    a theano based deep learning library.
   10. [72]deep learning tutorials     examples of how to do deep learning
       with theano (from lisa lab at university of montreal)
   11. [73]chainer     a gpu based neural network framework
   12. [74]matlab deep learning     matlab deep learning tools
   13. [75]cntk     computational network toolkit     is a unified
       deep-learning toolkit by microsoft research.
   14. [76]matconvnet     a matlab toolbox implementing convolutional neural
       networks (id98s) for id161 applications. it is simple,
       efficient, and can run and learn state-of-the-art id98s.
   15. [77]deeplearntoolbox     a matlab toolbox for deep learning (from
       rasmus berg palm)
   16. bigdl. a distributed open-source apache spark deep learning library
       designed for efficient scale-out to multiple nodes. cpu-optimized
       via mkl. scala and python support. (developed and supported by
       intel corp). [78]https://software.intel.com/bigdl.
       [79]https://github.com/intel-analytics/bigdl
   17. [80]cuda-convnet     a fast c++/cuda implementation of convolutional
       (or more generally, feed-forward) neural networks. it can model
       arbitrary layer connectivity and network depth. any directed
       acyclic graph of layers will do. training is done using the
       back-propagation algorithm.
   18. [81]id50. matlab code for learning deep belief
       networks (from ruslan salakhutdinov).
   19. [82]id56lm    tomas mikolov   s recurrent neural network based language
       models toolkit.
   20. [83]id56lib-id56lib is a recurrent neural network library for
       sequence learning problems. applicable to most types of
       spatiotemporal data, it has proven particularly effective for
       speech and handwriting recognition.
   21. [84]matrbm. simplified version of ruslan salakhutdinov   s code, by
       andrej karpathy (matlab).
   22. [85]deeplearning4j    deeplearning4j is an apache 2.0-licensed,
       open-source, distributed neural net library written in java and
       scala.
   23. [86]estimating partition functions of rbm   s. matlab code for
       estimating partition functions of restricted id82s
       using annealed importance sampling (from ruslan salakhutdinov).
   24. [87]learning deep id82s matlab code for training and
       fine-tuning deep id82s (from ruslan salakhutdinov).
   25. the [88]lush programming language and development environment,
       which is used @ nyu for deep convolutional networks
   26. [89]eblearn.lsh is a lush-based machine learning library for doing
       energy-based learning. it includes code for    predictive sparse
       decomposition    and other sparse auto-encoder methods for
       unsupervised learning. [90]koray kavukcuoglu provides eblearn code
       for several deep learning papers on this [91]page.
   27. [92]deepmat    deepmat, matlab based deep learning algorithms.
   28. [93]mshadow     mshadow is a lightweight cpu/gpu matrix/tensor
       template library in c++/cuda. the goal of mshadow is to support
       efficient, device invariant and simple tensor library for machine
       learning project that aims for both simplicity and performance.
       supports cpu/gpu/multi-gpu and distributed system.
   29. [94]cxxnet     cxxnet is fast, concise, distributed deep learning
       framework based on mshadow. it is a lightweight and easy extensible
       c++/cuda neural network toolkit with friendly python/matlab
       interface for training and prediction.
   30. [95]nengo-nengo is a graphical and scripting based software package
       for simulating large-scale neural systems.
   31. [96]eblearn is a c++ machine learning library with a bsd license
       for energy-based learning, convolutional networks,
       vision/recognition applications, etc. eblearn is primarily
       maintained by [97]pierre sermanet at nyu.
   32. [98]cudamat is a gpu-based matrix library for python. example code
       for training neural networks and restricted id82s is
       included.
   33. [99]gnumpy is a python module that interfaces in a way almost
       identical to numpy, but does its computations on your computer   s
       gpu. it runs on top of cudamat.
   34. the [100]cuv library (github [101]link) is a c++ framework with
       python bindings for easy use of nvidia cuda functions on matrices.
       it contains an rbm implementation, as well as annealed importance
       sampling code and code to calculate the partition function exactly
       (from [102]ais lab at university of bonn).
   35. [103]3-way factored rbm and [104]mcrbm is python code calling
       cudamat to train models of natural images (from [105]marc   aurelio
       ranzato).
   36. matlab code for training [106]conditional rbms/dbns and
       [107]factored conditional rbms (from [108]graham taylor).
   37. [109]mpot is python code using cudamat and gnumpy to train models
       of natural images (from [110]marc   aurelio ranzato).
   38. [111]neuralnetworks is a java based gpu library for deep learning
       algorithms.
   39. [112]convnet is a matlab based convolutional neural network
       toolbox.
   40. [113]elektronn is a deep learning toolkit that makes powerful
       neural networks accessible to scientists outside the machine
       learning community.
   41. [114]opennn is an open source class library written in c++
       programming language which implements neural networks, a main area
       of deep learning research.
   42. [115]neuraldesigner  is an innovative deep learning tool for
       predictive analytics.
   43. [116]theano generalized hebbian learning.
   44. [117]apache singa is an open source deep learning library that
       provides a flexible architecture for scalable distributed training.
       it is extensible to run over a wide range of hardware, and has a
       focus on health-care applications.
   45. [118]lightnet  is a lightweight, versatile and purely matlab-based
       deep learning framework. the aim of the design is to provide an
       easy-to-understand, easy-to-use and efficient computational
       platform for deep learning research.
   46. [119]simplednn is a machine learning lightweight open-source
       library written in kotlin whose purpose is to support the
       development of feed-forward and recurrent artificial neural
       networks.

   if your software belongs here, [120]email us and let us know.
   last modified on august 23, 2017, at 6:55 am by simon

recent posts

     * [121]mila is hiring two software engineers
     * [122]openai: a new non-profit ai company
     * [123]conference on the economics of machine intelligence-dec 15
     * [124]open discussion of iclr 2016 papers is now open
     * [125]software developer position at mila

links

     * [126]blocks
     * [127]deep learning id161 talks
     * [128]google plus deep learning community
     * [129]metaoptimize qa/forum
     * [130]pylearn2
     * [131]reddit machine learning
     * [132]social news for deep learning
     * [133]theano

references

   1. http://deeplearning.net/feed/
   2. http://deeplearning.net/comments/feed/
   3. http://deeplearning.net/software_links/feed/
   4. http://deeplearning.net/wp-json/oembed/1.0/embed?url=http://deeplearning.net/software_links/
   5. http://deeplearning.net/wp-json/oembed/1.0/embed?url=http://deeplearning.net/software_links/&format=xml
   6. http://deeplearning.net/
   7. http://deeplearning.net/
   8. http://deeplearning.net/reading-list/
   9. http://deeplearning.net/reading-list/tutorials/
  10. http://deeplearning.net/software_links/
  11. http://deeplearning.net/blog/
  12. http://deeplearning.net/demos/
  13. http://deeplearning.net/datasets/
  14. http://deeplearning.net/events/
  15. http://deeplearning.net/bibliography/
  16. http://deeplearning.net/deep-learning-research-groups-and-labs/
  17. http://deeplearning.net/icml2013-workshop-competition/
  18. http://deeplearning.net/icml2013-workshop-competition/challenges/
  19. http://deeplearning.net/icml2013-workshop-competition/schedule/
  20. http://deeplearning.net/deep-learning-job-listings/
  21. http://deeplearning.net/startup-news/
  22. http://deeplearning.net/
  23. http://deeplearning.net/
  24. http://deeplearning.net/comments/feed/
  25. http://deeplearning.net/feed/
  26. http://deeplearning.net/2016/07/
  27. http://deeplearning.net/2015/12/
  28. http://deeplearning.net/2015/11/
  29. http://deeplearning.net/2015/10/
  30. http://deeplearning.net/2015/09/
  31. http://deeplearning.net/2015/07/
  32. http://deeplearning.net/2014/11/
  33. http://deeplearning.net/2014/10/
  34. http://deeplearning.net/2014/09/
  35. http://deeplearning.net/2014/05/
  36. http://deeplearning.net/2014/04/
  37. http://deeplearning.net/2014/01/
  38. http://deeplearning.net/2013/12/
  39. http://deeplearning.net/2013/10/
  40. http://deeplearning.net/2013/09/
  41. http://deeplearning.net/2013/08/
  42. http://deeplearning.net/2013/07/
  43. http://deeplearning.net/2013/06/
  44. http://deeplearning.net/2013/05/
  45. http://deeplearning.net/2013/04/
  46. http://deeplearning.net/2013/03/
  47. http://deeplearning.net/2013/02/
  48. http://deeplearning.net/2013/01/
  49. http://deeplearning.net/2012/12/
  50. http://deeplearning.net/2012/01/
  51. http://deeplearning.net/2011/08/
  52. http://deeplearning.net/2011/06/
  53. http://deeplearning.net/2011/02/
  54. http://deeplearning.net/2010/12/
  55. http://deeplearning.net/2010/10/
  56. http://deeplearning.net/2010/04/
  57. http://deeplearning.net/2010/03/
  58. http://deeplearning.net/2010/01/
  59. http://deeplearning.net/wp-login.php
  60. http://deeplearning.net/feed/
  61. http://deeplearning.net/comments/feed/
  62. https://wordpress.org/
  63. http://deeplearning.net/software/theano
  64. http://www.torch.ch/
  65. https://github.com/lisa-lab/pylearn2
  66. https://github.com/mila-udem/blocks
  67. http://www.tensorflow.org/get_started/index.html
  68. https://github.com/dmlc/mxnet
  69. http://caffe.berkeleyvision.org/
  70. https://github.com/lasagne/lasagne
  71. http://keras.io/
  72. http://deeplearning.net/tutorial
  73. https://github.com/pfnet/chainer
  74. https://www.mathworks.com/discovery/deep-learning.html
  75. https://github.com/microsoft/cntk/wiki
  76. http://www.vlfeat.org/matconvnet/
  77. https://github.com/rasmusbergpalm/deeplearntoolbox
  78. https://software.intel.com/bigdl
  79. https://github.com/intel-analytics/bigdl
  80. http://code.google.com/p/cuda-convnet/
  81. http://www.cs.toronto.edu/~hinton/matlabforsciencepaper.html
  82. http://www.fit.vutbr.cz/~imikolov/id56lm/
  83. http://sourceforge.net/projects/id56l/
  84. http://code.google.com/p/matrbm/
  85. https://github.com/deeplearning4j/deeplearning4j
  86. http://www.cs.toronto.edu/~rsalakhu/rbm_ais.html
  87. http://web.mit.edu/~rsalakhu/www/dbm.html
  88. http://lush.sourceforge.net/
  89. http://cs.nyu.edu/~koray/wp/?page_id=29
  90. http://cs.nyu.edu/~koray/wp/
  91. http://cs.nyu.edu/~koray/wp/?page_id=17
  92. https://github.com/kyunghyuncho/deepmat
  93. https://github.com/dmlc/mshadow
  94. https://github.com/dmlc/cxxnet
  95. http://nengo.ca/
  96. http://eblearn.sourceforge.net/index.shtml
  97. http://cs.nyu.edu/~sermanet/
  98. http://code.google.com/p/cudamat/
  99. http://www.cs.toronto.edu/~tijmen/gnumpy.html
 100. http://www.ais.uni-bonn.de/deep_learning/downloads.html
 101. https://github.com/deeplearningais/cuv
 102. http://www.ais.uni-bonn.de/
 103. http://www.cs.toronto.edu/~ranzato/publications/factored3wayrbm/code/factored3waybm_04may2010.zip
 104. http://www.cs.toronto.edu/~ranzato/publications/mcrbm/code/mcrbm_04may2010.zip
 105. http://www.cs.toronto.edu/~ranzato
 106. http://www.cs.nyu.edu/~gwtaylor/publications/nips2006mhmublv/code.html
 107. http://www.cs.nyu.edu/~gwtaylor/publications/icml2009/code/
 108. http://www.cs.nyu.edu/~gwtaylor/
 109. http://www.cs.toronto.edu/~ranzato/publications/mpot/mpot.html
 110. http://www.cs.toronto.edu/~ranzato
 111. https://github.com/ivan-vasilev/neuralnetworks
 112. https://github.com/sdemyanov/convnet
 113. http://elektronn.org/
 114. http://www.opennn.net/
 115. https://neuraldesigner.com/
 116. https://github.com/ironbar/theano_generalized_hebbian_learning
 117. http://singa.apache.org/en/index.html
 118. https://github.com/yechengxi/lightnet
 119. https://github.com/kotlinnlp/simplednn
 120. mailto:ca9lar@gmail.com
 121. http://deeplearning.net/2016/07/14/4153924/
 122. http://deeplearning.net/2015/12/20/openai-a-new-non-profit-ai-company/
 123. http://deeplearning.net/2015/12/01/conference-on-the-economics-of-machine-intelligence-dec-15/
 124. http://deeplearning.net/2015/11/26/open-discussions-for-iclr-2016-is-now-open/
 125. http://deeplearning.net/2015/10/16/software-developer-position-at-mila/
 126. https://blocks.readthedocs.org/en/latest/
 127. http://www.computervisiontalks.com/tag/deep-learning/
 128. https://plus.google.com/communities/112866381580457264725
 129. http://metaoptimize.com/qa/
 130. http://deeplearning.net/software/pylearn2/
 131. http://www.reddit.com/r/machinelearning
 132. http://news.startup.ml/
 133. http://deeplearning.net/software/theano
