   #[1]github [2]recent commits to paper-notes:master

   [3]skip to content

   (button)

     * why github?
       [4]features    
          + [5]code review
          + [6]project management
          + [7]integrations
          + [8]actions
          + [9]team management
          + [10]social coding
          + [11]documentation
          + [12]code hosting
          + [13]customer stories    
          + [14]security    
     * [15]enterprise
     * explore
          + [16]explore github    

learn & contribute
          + [17]topics
          + [18]collections
          + [19]trending
          + [20]learning lab
          + [21]open source guides

connect with others
          + [22]events
          + [23]community forum
          + [24]github education
     * [25]marketplace
     * pricing
       [26]plans    
          + [27]compare plans
          + [28]contact sales
          + [29]nonprofit    
          + [30]education    

   ____________________
     * in this repository all github    
       jump to    

     * no suggested jump to results

     * in this repository all github    
       jump to    
     * in this repository all github    
       jump to    

   [31]sign in [32]sign up

     * [33]watch [34]116
     * [35]star [36]573
     * [37]fork [38]76

[39]karpathy/[40]paper-notes

   [41]code [42]issues 3 [43]pull requests 0 [44]projects 0 [45]insights
   [46]permalink
   (button) dismiss

join github today

   github is home to over 31 million developers working together to host
   and review code, manage projects, and build software together.
   [47]sign up
   branch: master
   [48]paper-notes/wikireading.md
   [49]find file copy path
   fetching contributors   
   cannot retrieve contributors at this time
   113 lines (53 sloc) 9.84 kb
   [50]raw [51]blame [52]history
   (button) (button)

wikireading paper notes

   daniel hewlett, alexandre lacoste, llion jones, illia polosukhin,
   andrew fandrianto, jay han, matthew kelcey and david berthelot, google
   research.

   pdf link: [53]http://www.aclweb.org/anthology/p/p16/p16-1145.pdf

   data release link: [54]http://goo.gl/wikireading

   18.58m instances across 884 sub-tasks of reading comprehension: text
   classification, information extraction. task: predict textual values
   from wikidata given text from wikipedia articles. examples form the
   dataset (cool; wish there were more in appendix or so...):

   ![screen shot 2016-08-07 at 1.53.11 pm](img/wikireading/screen shot
   2016-08-07 at 1.53.11 pm.png)

wikireading dataset

   wikidata: 16m items with 80m statements across 844 properties. each
   statement is (property, value) tuple. e.g. item paris has statement
   (country, france).

   wikireading:
     * instead consolidate all to (item, property, {answer}), where item
       is replaced with the text of the linked wikipedia article.
     * this involves 4.7m unique wikipedia articles (i.e. ~80% of english
       wikipedia is represented).
     * most common categories are human, taxon, film, album, human
       settlement (~50% of docs).
     * mean/median document lengths are 489.2, 203 words
     * 30% of the answers in the test set are not in training data answers
       (i.e. must be "read out" from the document).

on a side: related datasets

     * wikiqa (yang et al 2015): only thousands of examples (too small for
       end-to-end)
     * news dataset (hermann et al 2015): 1m instances
     * babi dataset (weston et al 2015): synthetically generated

   wikiqa and news both involve pointing to locations within the document.

methods: classification

   in this case we have a finite number of possible answers, so there's an
   encoding of item,property to a vector y which goes into a softmax
   classifier over the finite number of categories.
     * bow baseline: encode both item and property to bow vectors, concat,
       linear classify to fixed number of answers with softmax (or
       id28? (since it's multi-label setting))
     * neural net bow: embed item and property by averaging word
       representations in both separately, concat, classify.
     * paragraph vector: encode the item with paragraph vector (le and
       mikolov 2014, pv-dbow model; an unsupervised method). no
       fine-tuning throught the model.
     * lstm encoders: use last hidden representation of an lstm that
       "read" both item/property separately. presumable these are
       concatenated into vector y that ships off to the softmax.
     * attentive reader from hermann et al. 2015: encode the property with
       an lstm reader into vector u. then encode the document words into
       vectors z_t using another lstm. then produce an attention mask over
       the document based on concatenation of (u,z_t) for all t, and use
       it to do a weighted sum on z to get r. finally, compute the output
       encoding y (which goes into final softmax classifier) with one more
       layer as a function of (r,u). the concrete equations are: ![screen
       shot 2016-08-07 at 2.38.24 pm](img/wikireading/screen shot
       2016-08-07 at 2.38.24 pm.png) where v is a learned vector, so
       attention is a soft-maxed output of a small 2-layer neural net.
       also note to self: isn't it a problem that lstms are
       one-directional? what if the the relevant words containing an
       answer for a property are found preceding the property "identifier"
       in text?
     * memory network of sukhbaatar et al 2015, which maps the property p
       and sequence of sentences x_1,    , x_n to single joint
       representation y as follows. each sentence in the item (document)
       is encoded to a key vector m and a content vector c and property
       into a lookup vector u. the attention over sentences is computed
       independently of the property vector, and used to average the
       content vectors. the output vector y is the sum:

   ![screen shot 2016-08-07 at 3.18.05 pm](img/wikireading/screen shot
   2016-08-07 at 3.18.05 pm.png) note that this is kind of weird: the
   document is encoded separately from the query information, and they
   only interact additively at the very end in equation (7), and the
   vector y is shipped off directly to the (linear!) classifier. it's less
   intuitive than the attentive reader, and will be later shown to also
   work slightly worse.

methods: answer extraction with "id56 labeler"

   quries that concern date of birth, mother, author etc have too many
   possible answers to be handled in a classification framework.

   id56 labeler approach: predict id203 of each word being part of
   the answer. during training annotate document at all occurrences of
   answer with 1, 0 otherwise. for multi-word answers exact match is
   required. instances where answers don't appear are discarded. at test:
   sequences of consecutive locations scoring above a threshold are
   chunked into single answer, and top-scoring answer is recorded.

   this approach is slightly gross, not end to end, and restricted to only
   predicting words that are verbatim in the document as answers. also,
   writeup is a bit vague on how the property is conditioned on in the
   id56. figure 1 seems to suggest that the property is prepended to the
   document? this seems like a very weak form of conditioning that is
   bound to fail from the start.

methods: answer extraction with sequence to sequence

     * basic id195: encode the (item,property) with one lstm, decode the
       answer with another in a basic sutskever et al. id195 manner. the
       id27 is shared but lstm dynamics aren't. the paper is
       unfortunately very vague here - how are the item and property
       encoded exactly? would make sense to maybe encode each, then
       concatenate? figure 1 seems to incidate the property is read first
       and the document next.
     * placeholder id195: an extension inspired by luong et al. 2015 /
       hermann et al. 2015, where out of vocabulary (oov) words are
       replaced at random by one of finite number of placeholder vectors.
       the softmax word classifier is similarily extended to contain these
       placeholder words. just a note: this is really weird, since the
       training has to learn across an entire cross product of placeholder
       replacements. it feels wrong, but i also can't come up with
       anything much better.=, except for:
     * character id195: characters all the way! no such thing as oov
       words, weird preprocessing techniques etc., but at the cost of
       doing much more compute and having much longer dependencies. i like
       this because the least amount of arbitrary non-differentiable
       decisions are made.
     * character id195 with pretraining: train a character-level lm on
       the training data first as initialization (shown as sensible by dai
       and le 2015).

   ![screen shot 2016-08-07 at 4.07.18 pm](img/wikireading/screen shot
   2016-08-07 at 4.07.18 pm.png)

   one more note: these models are suspicious in how lazily they encode
   the (item, property). it seems they read the property first, and then
   they read the item for many next time steps, likely nearly forgetting
   the property by the end. wouldn't it be much more sensible to use very
   simple attention here, or "plug in" the property at each time step, or
   at the last time step etc    many other easy and sensible possibilities
   here.

experiements

   eval criterion: use mean f1-score (harmonic mean of precision and
   recall) due to multiple possible answers; this measures "degree of
   overlap" between predicted answer and true answer. details are a bit
   sparse here, do they segment multiple answers with e.g. a comma? since
   most questions in the dataset have a single answer, f1-score ~=
   accuracy.

   prepro: whoa, "all documents are truncated to first 300 words, except
   in char id195 to 400 characters" - that is short!.

   hyperparams: tensorflow implementation. embeddings are 300d. vocab size
   100,000 most freq words. answer classification is over 50,000 words,
   "answer representation size is 300" - wait, is this not a softmax? id56s
   are grus with 1024 cells. opt with adam of (beta1 0.9, beta2 0.999, eps
   1e-8). grad clipping done proportionally to threhold norm c (not
   mentioned if seqlength/batches are normalized in loss). learning rate
   in 1e-5 to 1e-2, c in [1e-3, 1e1], selected as best from 50.

   results!! as follows: ![screen shot 2016-08-07 at 4.22.13
   pm](img/wikireading/screen shot 2016-08-07 at 4.22.13 pm.png)

   attentive reader works well on cls: attentive reader performs best at
   classification, as it intuitively should imo. i'm slightly surprised
   that the lstm reader performs nearly as well (0.880 vs 0.886) - note it
   also has fewer params (45m vs 56m).

   order of words has ~little info: lstm reader is 0.880 vs. averaged
   embeddings is 0.849, so order of words information here is adding
   approx ~0.031of accuracy. this is not a supergreat apples-to-apples
   comparison though.

   more frequent classes work better, shown in figure 3. expected,
   interesting to see quantitatively. softmax classifier doesn't share
   statistcal strength across candidate answers. could have been
   interesting to maybe model the networks are (item, property, candidate
   answer) -> id203. this way the answers wouldn't blow up the
   softmax, and id136 would be much slower and require a gross loop,
   but answers could share statistical strength.

   char id56s works surprisingly well. quite surprised to see char id195
   do 0.699 vs. placeholder id195 at 0.718 (and with ~8x less params,
   but possibly with more flops (would be fun to see this comparison too
   in the table)). that's not a huge delta; encouraging! and this only
   uses the first 400 characters (instead of 300 words, which should be
   much more information/context!) of the document and with no
   attentions/other fanciness. pretraining is mentioned to help with
   convergence, final performance, and hyperparameter sensitivity.

   no attention fancy models for id195; wish these experiments were
   included. would expect an additional bump, as is the case in the
   categorical setting.

conclusions

   lets push fully end-to-end character id56 models further.
   ____________________ (button) go

     *    2019 github, inc.
     * [55]terms
     * [56]privacy
     * [57]security
     * [58]status
     * [59]help

     * [60]contact github
     * [61]pricing
     * [62]api
     * [63]training
     * [64]blog
     * [65]about

   (button) you can   t perform that action at this time.

   you signed in with another tab or window. [66]reload to refresh your
   session. you signed out in another tab or window. [67]reload to refresh
   your session.

   (button)

references

   visible links
   1. https://github.com/opensearch.xml
   2. https://github.com/karpathy/paper-notes/commits/master.atom
   3. https://github.com/karpathy/paper-notes/blob/master/wikireading.md#start-of-content
   4. https://github.com/features
   5. https://github.com/features/code-review/
   6. https://github.com/features/project-management/
   7. https://github.com/features/integrations
   8. https://github.com/features/actions
   9. https://github.com/features#team-management
  10. https://github.com/features#social-coding
  11. https://github.com/features#documentation
  12. https://github.com/features#code-hosting
  13. https://github.com/customer-stories
  14. https://github.com/security
  15. https://github.com/enterprise
  16. https://github.com/explore
  17. https://github.com/topics
  18. https://github.com/collections
  19. https://github.com/trending
  20. https://lab.github.com/
  21. https://opensource.guide/
  22. https://github.com/events
  23. https://github.community/
  24. https://education.github.com/
  25. https://github.com/marketplace
  26. https://github.com/pricing
  27. https://github.com/pricing#feature-comparison
  28. https://enterprise.github.com/contact
  29. https://github.com/nonprofit
  30. https://education.github.com/
  31. https://github.com/login?return_to=/karpathy/paper-notes/blob/master/wikireading.md
  32. https://github.com/join
  33. https://github.com/login?return_to=/karpathy/paper-notes
  34. https://github.com/karpathy/paper-notes/watchers
  35. https://github.com/login?return_to=/karpathy/paper-notes
  36. https://github.com/karpathy/paper-notes/stargazers
  37. https://github.com/login?return_to=/karpathy/paper-notes
  38. https://github.com/karpathy/paper-notes/network/members
  39. https://github.com/karpathy
  40. https://github.com/karpathy/paper-notes
  41. https://github.com/karpathy/paper-notes
  42. https://github.com/karpathy/paper-notes/issues
  43. https://github.com/karpathy/paper-notes/pulls
  44. https://github.com/karpathy/paper-notes/projects
  45. https://github.com/karpathy/paper-notes/pulse
  46. https://github.com/karpathy/paper-notes/blob/75f4b42f3630252e86728bd78572a666c5f4de1a/wikireading.md
  47. https://github.com/join?source=prompt-blob-show
  48. https://github.com/karpathy/paper-notes
  49. https://github.com/karpathy/paper-notes/find/master
  50. https://github.com/karpathy/paper-notes/raw/master/wikireading.md
  51. https://github.com/karpathy/paper-notes/blame/master/wikireading.md
  52. https://github.com/karpathy/paper-notes/commits/master/wikireading.md
  53. http://www.aclweb.org/anthology/p/p16/p16-1145.pdf
  54. http://goo.gl/wikireading
  55. https://github.com/site/terms
  56. https://github.com/site/privacy
  57. https://github.com/security
  58. https://githubstatus.com/
  59. https://help.github.com/
  60. https://github.com/contact
  61. https://github.com/pricing
  62. https://developer.github.com/
  63. https://training.github.com/
  64. https://github.blog/
  65. https://github.com/about
  66. https://github.com/karpathy/paper-notes/blob/master/wikireading.md
  67. https://github.com/karpathy/paper-notes/blob/master/wikireading.md

   hidden links:
  69. https://github.com/
  70. https://github.com/karpathy/paper-notes/blob/master/wikireading.md
  71. https://github.com/karpathy/paper-notes/blob/master/wikireading.md
  72. https://github.com/karpathy/paper-notes/blob/master/wikireading.md
  73. https://github.com/karpathy/paper-notes/blob/master/wikireading.md#wikireading-paper-notes
  74. https://github.com/karpathy/paper-notes/blob/master/wikireading.md#wikireading-dataset
  75. https://github.com/karpathy/paper-notes/blob/master/wikireading.md#on-a-side-related-datasets
  76. https://github.com/karpathy/paper-notes/blob/master/wikireading.md#methods-classification
  77. https://github.com/karpathy/paper-notes/blob/master/wikireading.md#methods-answer-extraction-with-id56-labeler
  78. https://github.com/karpathy/paper-notes/blob/master/wikireading.md#methods-answer-extraction-with-sequence-to-sequence
  79. https://github.com/karpathy/paper-notes/blob/master/wikireading.md#experiements
  80. https://github.com/karpathy/paper-notes/blob/master/wikireading.md#conclusions
  81. https://github.com/
