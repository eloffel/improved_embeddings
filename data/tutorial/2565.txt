   #[1]rasmus andersson

                                  [2]signature

     * [3]home
     * [4]archive
     * [5]about me

intuition behind concept of gradient

   jun 05, 2016

   [6]tweet

lets begin with a story. dino, our little dinosour, is at location
(10,5).temperature @ (10,5) is 16 degrees celcius. dino wants to move to
colder place a soon as possible

   [dino_libre.png]

   fig1:screen capture from good dino movie

temperature distribution of the lake is

   [surafce1.png]

   fig2:those concentric circles are called contours

let me introduce you to technical terms - vector and gradient.

to explain vector, let   s look in to the picture below

   [vector1.png]
   [vector2.png]

   fig4: vectors are defined by a magnitude (the length of the vector) and
   a direction

now lets define gradient. gradient points in the direction of the greatest
rate of increase of a function.

   [surface2_gradient.png]

   fig4: gradients ( at all points) are vectors pointing towards greater
   increase in temperature

to get the direction of the greatest rate of decrease of temperature, take
negative of gradients at each point

   [surface3_gradient.png]

   fig5: negative of gradients are pointing towards greater decrease in
   temperature

to move to a colder location, dino should swim in the direction of greatest
decrease in temperature.

let us use some basic id202 to find the gradient vector at point
(10,5)

   find partial derivatives with respect to x and y directions
   [dino2.png]
   1
   2
      

remember we will take negative of gradient

   [calc1_gradient.png]

   fig5: gradient vector suggests that dino should move to the (right and
   then up) from current location (10,5)
   [dino_final.png]

   fig6:it is importaid4 to note that this direction is clearly not
   directly towards the coldest point, but rather is the direction of
   greatest decrease in temperature at the point.

   checkout these directional derivative examples[7]interactives

   [8]tweet

where is gradient vectors concept used?

   given, information about a function, you can find direction of greatest
   change in function. in deep learning, gradients are used to adjust
   weights and find direction of greatest change in id168 in
   finance, economics gradient concept can be employed to find direction
   of greatest change in function

   please enable javascript to view the [9]comments powered by disqus.
   [10]comments powered by disqus

   [11][cc-cc.png] [cc-by.png] this work is licensed under a [12]creative
   commons license

machine learning posts

   [13]precision, recall and f1 score [14]secretary problem. strategy to
   select the best candidate [15]a walk through machine learning
   conference held at toronto [16]introduction to the concept of cross
   id178 and its application [17]build a neural net to solve exclusive
   or (xor) problem [18]ai winter. how canadians contributed to end it?
   [19]id88 learning algorithm in plain words [20]maximum likelihood
   estimate and id28 simplified [21]deep learning
   highlights month by month [22]intuition behind concept of gradient

finance posts

   [23]s&p500 2018 returns [24]let's learn about convertible note
   [25]sp500 stocks performance in 2017

general

   [26]immense power of interactive math explainers

r/python

references

   1. https://pmirla.github.io/atom.xml
   2. https://pmirla.github.io/
   3. https://pmirla.github.io/
   4. https://pmirla.github.io/archive/
   5. https://pmirla.github.io/about/
   6. https://twitter.com/share
   7. http://mathinsight.org/directional_derivative_gradient_introduction
   8. https://twitter.com/share
   9. http://disqus.com/?ref_noscript
  10. http://disqus.com/
  11. http://creativecommons.org/licenses/by/3.0/deed.en_us
  12. http://creativecommons.org/licenses/by/3.0/deed.en_us
  13. https://pmirla.github.io/2018/11/15/precison_recall.html
  14. https://pmirla.github.io/2017/06/12/secretary_problem.html
  15. https://pmirla.github.io/2016/10/27/ml-conference-notes.html
  16. https://pmirla.github.io/2016/10/09/basics-crossid178.html
  17. https://pmirla.github.io/2016/09/10/neural-network-xor-problem.html
  18. https://pmirla.github.io/2016/08/16/ai-winter.html
  19. https://pmirla.github.io/2016/08/04/what-is-id88.html
  20. https://pmirla.github.io/2016/07/20/maximum-likelihood-explanation.html
  21. https://pmirla.github.io/2016/07/11/deep-learning-news.html
  22. https://pmirla.github.io/2016/06/05/gradient-explanation.html
  23. https://pmirla.github.io/2019/01/17/sp500_2018.html
  24. https://pmirla.github.io/2018/10/06/convertible-note.html
  25. https://pmirla.github.io/2017/12/25/sp500_2017.html
  26. https://pmirla.github.io/2017/09/15/answer_id203.html
