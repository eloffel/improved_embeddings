   #[1]github [2]recent commits to hed-dlg-truncated:master

   [3]skip to content

   (button)

     * why github?
       [4]features    
          + [5]code review
          + [6]project management
          + [7]integrations
          + [8]actions
          + [9]team management
          + [10]social coding
          + [11]documentation
          + [12]code hosting
          + [13]customer stories    
          + [14]security    
     * [15]enterprise
     * explore
          + [16]explore github    

learn & contribute
          + [17]topics
          + [18]collections
          + [19]trending
          + [20]learning lab
          + [21]open source guides

connect with others
          + [22]events
          + [23]community forum
          + [24]github education
     * [25]marketplace
     * pricing
       [26]plans    
          + [27]compare plans
          + [28]contact sales
          + [29]nonprofit    
          + [30]education    

   ____________________
     * in this repository all github    
       jump to    

     * no suggested jump to results

     * in this repository all github    
       jump to    
     * in this repository all github    
       jump to    

   [31]sign in [32]sign up

     * [33]watch [34]21
     * [35]star [36]273
     * [37]fork [38]123

[39]julianser/[40]hed-dlg-truncated

   [41]code [42]issues 15 [43]pull requests 0 [44]projects 0 [45]insights
   (button) dismiss

join github today

   github is home to over 31 million developers working together to host
   and review code, manage projects, and build software together.
   [46]sign up
   hierarchical encoder decoder id56 (hred) with truncated id26
   through time (truncated bptt)
     * [47]173 commits
     * [48]1 branch
     * [49]1 release
     * [50]fetching contributors
     * [51]gpl-3.0

    1. [52]python 95.5%
    2. [53]java 4.5%

   (button) python java
   branch: master (button) new pull request
   [54]find file
   clone or download

clone with https

   use git or checkout with svn using the web url.
   https://github.com/j
   [55]download zip

downloading...

   want to be notified of new releases in julianser/hed-dlg-truncated?
   [56]sign in [57]sign up

launching github desktop...

   if nothing happens, [58]download github desktop and try again.

   (button) go back

launching github desktop...

   if nothing happens, [59]download github desktop and try again.

   (button) go back

launching xcode...

   if nothing happens, [60]download xcode and try again.

   (button) go back

launching visual studio...

   if nothing happens, [61]download the github extension for visual studio
   and try again.

   (button) go back
   [62]@julianser
   [63]julianser [64]create license
   latest commit [65]2cfa08e aug 29, 2018
   [66]permalink
   type name latest commit message commit time
   failed to load latest commit information.
   [67]evaluation [68]substantial code clean up. jun 8, 2016
   [69]linguisticevaluation [70]added script and extensive instructions to
   compute linguistic and sem    may 11, 2015
   [71]tests [72]implemented new dictionary format and script to create
   dictionary and    jul 1, 2015
   [73].gitignore
   [74]license
   [75]readme.md
   [76]ss_dataset.py [77]substantial code clean up. jun 8, 2016
   [78]__init__.py [79]initial commit apr 7, 2015
   [80]adam.py [81]initial commit apr 7, 2015
   [82]chat.py
   [83]compute_dialogue_embeddings.py
   [84]convert-text2dict.py
   [85]convert-wordemb-dict2emb-matrix.py
   [86]create-text-file-for-tests.py
   [87]data_iterator.py
   [88]dialog_encdec.py
   [89]evaluate.py
   [90]evaluation.py
   [91]generate_encodings.py [92]minor changes. nov 28, 2015
   [93]model.py [94]minor correction to last commit. nov 22, 2015
   [95]numpy_compat.py
   [96]sample.py
   [97]search.py
   [98]split-examples-by-token.py
   [99]split_documents_by_dialogues.py
   [100]state.py
   [101]train.py
   [102]utils.py

readme.md

description

   this repository hosts the hierarchical encoder decoder id56 model (hred)
   and the latent variable hierarchical recurrent encoder-decoder id56
   model (vhred) for generative dialog modeling as described by serban et
   al. (2016a) and serban et al. (2016c).

truncated bptt

   both models are implemented using truncated id26 through
   time (truncated bptt). the truncated computation is carried out by
   splitting each document (dialogue) into shorter sequences (e.g. 80
   tokens) and computing gradients for each sequence separately, such that
   the hidden state of the id56s on each subsequence are initialized from
   the preceding sequences (i.e. the hidden states have been forward
   propagated through the previous states).

creating datasets

   the script convert-text2dict.py can be used to generate model datasets
   based on text files with dialogues. it only requires that the document
   contains end-of-utterance tokens </s> which are used to construct the
   model graph, since the utterance encoder is only connected to the
   dialogue encoder at the end of each utterance.

   prepare your dataset as a text file for with one document per line
   (e.g. one dialogue per line). the documents are assumed to be
   tokenized. if you have validation and test sets, they must satisfy the
   same requirements.

   once you're ready, you can create the model dataset files by running:

   python convert-text2dict.py <training_file> --cutoff <vocabulary_size>
   training python convert-text2dict.py <validation_file>
   --dict=training.dict.pkl validation python convert-text2dict.py
   <test_file> --dict=training.dict.pkl <vocabulary_size> test

   where <training_file>, <validation_file> and <test_file> are the
   training, validation and test files, and <vocabulary_size> is the
   number of tokens that you want to train on (all other tokens, but the
   most frequent <vocabulary_size> tokens, will be converted to <unk>
   symbols).

   note: the script automatically adds the following special tokens
   specific to movie scripts:
     * end-of-utterance: </s>
     * end-of-dialogue: </d>
     * first speaker: <first_speaker>
     * second speaker: <second_speaker>
     * third speaker: <third_speaker>
     * minor speaker: <minor_speaker>
     * voice over: <voice_over>
     * off screen: <off_screen>
     * pause: <pause>

   if these do not exist in your dataset, you can safely ignore these. the
   model will learn to assign approximately zero id203 mass to them.

model training

   if you have theano with gpu installed (bleeding edge version), you can
   train the model as follows:
    1. clone the github repository
    2. create a new "output" and "data" directories inside it.
    3. unpack your dataset files into "data" directory.
    4. create a new prototype inside state.py (look at
       prototype_ubuntu_hred for an example)
    5. from the terminal, cd into the code directory and run:
       theano_flags=mode=fast_run,device=gpu,floatx=float32 python
       train.py --prototype <prototype_name> > model_output.txt

   where <prototype_name> is a state (model architecture) defined inside
   state.py. training a model to convergence on a modern gpu on the ubuntu
   dialogue corpus with 46 million tokens takes about 1-2 weeks. if your
   gpu runs out of memory, you can adjust the bs (batch size) parameter in
   the model state, but training will be slower. you can also play around
   with the other parameters inside state.py.

   (currently not supported) to test a model w.r.t. word perplexity run:
theano_flags=mode=fast_run,device=gpu,floatx=float32 python evaluate.py <model_n
ame> model_evaluation.txt

   where <model_name> is the model name automatically generated during
   training.

model sampling & testing

   to generate model responses using id125 run:
theano_flags=mode=fast_run,floatx=float32,device=gpu python sample.py <model_nam
e> <contexts> <model_outputs> --beam_search --n-samples=<beams> --ignore-unk --v
erbose

   where <model_name> is the name automatically generated during training,
   <contexts> is a file containing the dialogue contexts with one dialogue
   per line, and <beams> is the size of the id125. the results are
   saved in the file <model_outputs>.

   to compute the embedding-based metrics on the generated responses run:
python evaluation/embedding_metrics.py <ground_truth_responses> <model_outputs>
<word_emb>

   where <ground_truth_responses> is a file containing the ground truth
   responses, <model_outputs> is the file generated above and <word_emb>
   is the path to the binarized id27s. for the id27s,
   we recommend to use id97 trained on the googlenews corpus:
   [103]https://drive.google.com/file/d/0b7xkcwpi5kdynlnuttlss21pqmm.

citation

   if you build on this work, we'd really appreciate it if you could cite
   our papers:
a hierarchical latent variable encoder-decoder model for generating dialogues. i
ulian vlad serban, alessandro sordoni, ryan lowe, laurent charlin, joelle pineau
, aaron courville, yoshua bengio. 2016. http://arxiv.org/abs/1605.06069

building end-to-end dialogue systems using generative hierarchical neural networ
k models. iulian v. serban, alessandro sordoni, yoshua bengio, aaron courville,
joelle pineau. 2016. aaai. http://arxiv.org/abs/1507.04808.

datasets

   the pre-processed ubuntu dialogue corpus and model responses used by
   serban et al. (2016a) are available at:
   [104]http://www.iulianserban.com/files/ubuntudialoguecorpus.zip. these
   can be used with the model states "prototype_ubuntu_lstm",
   "prototype_ubuntu_hred", and "prototype_ubuntu_vhred" (see state.py) to
   reproduce the results of serban et al. (2016a) on the ubuntu dialogue
   corpus.

   the original ubuntu dialogue corpus as released by lowe et al. (2015)
   can be found here:
   [105]http://cs.mcgill.ca/~jpineau/datasets/ubuntu-corpus-1.0/

   unfortunately due to twitter's terms of service we are not allowed to
   distribute twitter content. therefore we can only make available the
   tweet ids, which can then be used with the twitter api to build a
   similar dataset. the tweet ids and model test responses can be found
   here: [106]http://www.iulianserban.com/files/twitterdialoguecorpus.zip.

   the movietriples script is also available for research purposes only by
   contacting iulian vlad serban by email, although we strongly recommend
   researchers to benchmark their models on ubuntu and twitter, since
   these datasets are substantially larger and represent more well-defined
   tasks.

references

a hierarchical latent variable encoder-decoder model for generating dialogues. i
ulian vlad serban, alessandro sordoni, ryan lowe, laurent charlin, joelle pineau
, aaron courville, yoshua bengio. 2016a. http://arxiv.org/abs/1605.06069

multiresolution recurrent neural networks: an application to dialogue response g
eneration. iulian vlad serban, tim klinger, gerald tesauro, kartik talamadupula,
 bowen zhou, yoshua bengio, aaron courville. 2016b. http://arxiv.org/abs/1606.00
776.

building end-to-end dialogue systems using generative hierarchical neural networ
k models. iulian v. serban, alessandro sordoni, yoshua bengio, aaron courville,
joelle pineau. 2016c. aaai. http://arxiv.org/abs/1507.04808.

the ubuntu dialogue corpus: a large dataset for research in unstructured multi-t
urn dialogue systems. ryan lowe, nissan pow, iulian serban, joelle pineau. 2015.
 sigdial. http://arxiv.org/abs/1506.08909.

     *    2019 github, inc.
     * [107]terms
     * [108]privacy
     * [109]security
     * [110]status
     * [111]help

     * [112]contact github
     * [113]pricing
     * [114]api
     * [115]training
     * [116]blog
     * [117]about

   (button) you can   t perform that action at this time.

   you signed in with another tab or window. [118]reload to refresh your
   session. you signed out in another tab or window. [119]reload to
   refresh your session.

   (button)

references

   visible links
   1. https://github.com/opensearch.xml
   2. https://github.com/julianser/hed-dlg-truncated/commits/master.atom
   3. https://github.com/julianser/hed-dlg-truncated#start-of-content
   4. https://github.com/features
   5. https://github.com/features/code-review/
   6. https://github.com/features/project-management/
   7. https://github.com/features/integrations
   8. https://github.com/features/actions
   9. https://github.com/features#team-management
  10. https://github.com/features#social-coding
  11. https://github.com/features#documentation
  12. https://github.com/features#code-hosting
  13. https://github.com/customer-stories
  14. https://github.com/security
  15. https://github.com/enterprise
  16. https://github.com/explore
  17. https://github.com/topics
  18. https://github.com/collections
  19. https://github.com/trending
  20. https://lab.github.com/
  21. https://opensource.guide/
  22. https://github.com/events
  23. https://github.community/
  24. https://education.github.com/
  25. https://github.com/marketplace
  26. https://github.com/pricing
  27. https://github.com/pricing#feature-comparison
  28. https://enterprise.github.com/contact
  29. https://github.com/nonprofit
  30. https://education.github.com/
  31. https://github.com/login?return_to=/julianser/hed-dlg-truncated
  32. https://github.com/join
  33. https://github.com/login?return_to=/julianser/hed-dlg-truncated
  34. https://github.com/julianser/hed-dlg-truncated/watchers
  35. https://github.com/login?return_to=/julianser/hed-dlg-truncated
  36. https://github.com/julianser/hed-dlg-truncated/stargazers
  37. https://github.com/login?return_to=/julianser/hed-dlg-truncated
  38. https://github.com/julianser/hed-dlg-truncated/network/members
  39. https://github.com/julianser
  40. https://github.com/julianser/hed-dlg-truncated
  41. https://github.com/julianser/hed-dlg-truncated
  42. https://github.com/julianser/hed-dlg-truncated/issues
  43. https://github.com/julianser/hed-dlg-truncated/pulls
  44. https://github.com/julianser/hed-dlg-truncated/projects
  45. https://github.com/julianser/hed-dlg-truncated/pulse
  46. https://github.com/join?source=prompt-code
  47. https://github.com/julianser/hed-dlg-truncated/commits/master
  48. https://github.com/julianser/hed-dlg-truncated/branches
  49. https://github.com/julianser/hed-dlg-truncated/releases
  50. https://github.com/julianser/hed-dlg-truncated/graphs/contributors
  51. https://github.com/julianser/hed-dlg-truncated/blob/master/license
  52. https://github.com/julianser/hed-dlg-truncated/search?l=python
  53. https://github.com/julianser/hed-dlg-truncated/search?l=java
  54. https://github.com/julianser/hed-dlg-truncated/find/master
  55. https://github.com/julianser/hed-dlg-truncated/archive/master.zip
  56. https://github.com/login?return_to=https://github.com/julianser/hed-dlg-truncated
  57. https://github.com/join?return_to=/julianser/hed-dlg-truncated
  58. https://desktop.github.com/
  59. https://desktop.github.com/
  60. https://developer.apple.com/xcode/
  61. https://visualstudio.github.com/
  62. https://github.com/julianser
  63. https://github.com/julianser/hed-dlg-truncated/commits?author=julianser
  64. https://github.com/julianser/hed-dlg-truncated/commit/2cfa08e9e08d4b9a910ff70e5a2696e10236b438
  65. https://github.com/julianser/hed-dlg-truncated/commit/2cfa08e9e08d4b9a910ff70e5a2696e10236b438
  66. https://github.com/julianser/hed-dlg-truncated/tree/2cfa08e9e08d4b9a910ff70e5a2696e10236b438
  67. https://github.com/julianser/hed-dlg-truncated/tree/master/evaluation
  68. https://github.com/julianser/hed-dlg-truncated/commit/db5b9faa88484e7127a08cdf65cf3dbc316755f0
  69. https://github.com/julianser/hed-dlg-truncated/tree/master/linguisticevaluation
  70. https://github.com/julianser/hed-dlg-truncated/commit/4bf4a609a1b9dedd9ff8af4e459100f5b43603d5
  71. https://github.com/julianser/hed-dlg-truncated/tree/master/tests
  72. https://github.com/julianser/hed-dlg-truncated/commit/56af74b14185081adae5268af7e2785a5f2d253c
  73. https://github.com/julianser/hed-dlg-truncated/blob/master/.gitignore
  74. https://github.com/julianser/hed-dlg-truncated/blob/master/license
  75. https://github.com/julianser/hed-dlg-truncated/blob/master/readme.md
  76. https://github.com/julianser/hed-dlg-truncated/blob/master/ss_dataset.py
  77. https://github.com/julianser/hed-dlg-truncated/commit/db5b9faa88484e7127a08cdf65cf3dbc316755f0
  78. https://github.com/julianser/hed-dlg-truncated/blob/master/__init__.py
  79. https://github.com/julianser/hed-dlg-truncated/commit/3e427755e8aff551b4c5517f95511af113f6ddd5
  80. https://github.com/julianser/hed-dlg-truncated/blob/master/adam.py
  81. https://github.com/julianser/hed-dlg-truncated/commit/3e427755e8aff551b4c5517f95511af113f6ddd5
  82. https://github.com/julianser/hed-dlg-truncated/blob/master/chat.py
  83. https://github.com/julianser/hed-dlg-truncated/blob/master/compute_dialogue_embeddings.py
  84. https://github.com/julianser/hed-dlg-truncated/blob/master/convert-text2dict.py
  85. https://github.com/julianser/hed-dlg-truncated/blob/master/convert-wordemb-dict2emb-matrix.py
  86. https://github.com/julianser/hed-dlg-truncated/blob/master/create-text-file-for-tests.py
  87. https://github.com/julianser/hed-dlg-truncated/blob/master/data_iterator.py
  88. https://github.com/julianser/hed-dlg-truncated/blob/master/dialog_encdec.py
  89. https://github.com/julianser/hed-dlg-truncated/blob/master/evaluate.py
  90. https://github.com/julianser/hed-dlg-truncated/blob/master/evaluation.py
  91. https://github.com/julianser/hed-dlg-truncated/blob/master/generate_encodings.py
  92. https://github.com/julianser/hed-dlg-truncated/commit/2e794e6b73a17092e73b6235504615c56ae2af6d
  93. https://github.com/julianser/hed-dlg-truncated/blob/master/model.py
  94. https://github.com/julianser/hed-dlg-truncated/commit/39972b16edb1d9e6fb38ef061469b5dd62f034f2
  95. https://github.com/julianser/hed-dlg-truncated/blob/master/numpy_compat.py
  96. https://github.com/julianser/hed-dlg-truncated/blob/master/sample.py
  97. https://github.com/julianser/hed-dlg-truncated/blob/master/search.py
  98. https://github.com/julianser/hed-dlg-truncated/blob/master/split-examples-by-token.py
  99. https://github.com/julianser/hed-dlg-truncated/blob/master/split_documents_by_dialogues.py
 100. https://github.com/julianser/hed-dlg-truncated/blob/master/state.py
 101. https://github.com/julianser/hed-dlg-truncated/blob/master/train.py
 102. https://github.com/julianser/hed-dlg-truncated/blob/master/utils.py
 103. https://drive.google.com/file/d/0b7xkcwpi5kdynlnuttlss21pqmm
 104. http://www.iulianserban.com/files/ubuntudialoguecorpus.zip
 105. http://cs.mcgill.ca/~jpineau/datasets/ubuntu-corpus-1.0/
 106. http://www.iulianserban.com/files/twitterdialoguecorpus.zip
 107. https://github.com/site/terms
 108. https://github.com/site/privacy
 109. https://github.com/security
 110. https://githubstatus.com/
 111. https://help.github.com/
 112. https://github.com/contact
 113. https://github.com/pricing
 114. https://developer.github.com/
 115. https://training.github.com/
 116. https://github.blog/
 117. https://github.com/about
 118. https://github.com/julianser/hed-dlg-truncated
 119. https://github.com/julianser/hed-dlg-truncated

   hidden links:
 121. https://github.com/
 122. https://github.com/julianser/hed-dlg-truncated
 123. https://github.com/julianser/hed-dlg-truncated
 124. https://github.com/julianser/hed-dlg-truncated
 125. https://help.github.com/articles/which-remote-url-should-i-use
 126. https://github.com/julianser/hed-dlg-truncated#description
 127. https://github.com/julianser/hed-dlg-truncated#truncated-bptt
 128. https://github.com/julianser/hed-dlg-truncated#creating-datasets
 129. https://github.com/julianser/hed-dlg-truncated#model-training
 130. https://github.com/julianser/hed-dlg-truncated#model-sampling--testing
 131. https://github.com/julianser/hed-dlg-truncated#citation
 132. https://github.com/julianser/hed-dlg-truncated#datasets
 133. https://github.com/julianser/hed-dlg-truncated#references
 134. https://github.com/
