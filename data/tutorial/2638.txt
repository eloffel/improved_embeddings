   menu

[1]computational neuroscience     in  excel

     * [2]home
     * [3]advantages of neural networks
     * [4]id88 1: basic neuron
     * [5]id88 2: logical operations
     * [6]id88 3: learning
     * [7]id88 4: formalising & visualising
     * [8]id88 5: xor (how & why neurons work together)
     * [9]neurons fire & ideas emerge
     * [10]visual system 1: retina
     * [11]visual system 2: illusions (in the retina)
     * [12]visual system 3: v1 - line detectors
     * [13]comments
     * [14]recursive connections
     * [15]bayesian brain

   [1357767026.jpg]

why  do  neurons  make  networks

   on the [16]logical operations page, i showed how single neurons can
   perform simple logical operations, but that they are unable to perform
   some more difficult ones like the xor operation (shown above). and i
   described how an xor network can be made, but didn't go into much
   detail about why the xor requires an extra layer for its solution.
   this page is about using the knowledge we have from the [17]formalising
   & visualising page to help us understand why neurons need to make
   networks. the only network we will look at is the xor, but at the end
   you will play with a network that visualises the xor problem as a pair
   of lines through input space that you can adjust by changing the
   parameters of the neurons.

the   xor   problem

   we have a problem that can be described with the logic table below, and
   visualised in input space as shown on the right.
   picture
   picture
   blue circles are desired outputs of 1 (objects 2 & 3 in the logic table
   on the left), while red squares are desired outputs of 0 (objects 1 &
   4).
   in [18]formalising & visualising, we saw that there is no way that a
   single neuron can solve this problem because it is only able to draw
   one single straight line through input space in order to divide the
   input space into two categories.
   the minimum number of lines that we need to draw through the input
   space to solve this problem is two.
   on the right there is an example of how this can be done.  -->  -->
   -->
   in this case, the area between the lines equates to desired outputs of
   1, while both the area above the blue line and the area below the
   orange line equate to desired outputs of 0.
   easy question:  if one neuron defines one line through input space,
   what do we need in order to draw two lines?
   the answer is, of course, to have two neurons working in parallel (next
   to each other rather than in different layers).   --->
   notice that both neurons are connected to the same input sensors.  this
   is because they are both drawing lines on the same input space in order
   to makes decisions about the same inputs.  they need to work together
   to decide if the single thing that they are looking at is a member of
   category 1 or category 0.
   the other thing to notice is that we now have two output commands
   rather than one.  this actually poses a much bigger problem than it
   first seems.  we want the neural network to categorise the objects it
   sees into just two groups, but having two output commands that can each
   be either 1 or 0 gives us four possible combinations:
        [00, 01, 10, 11]
   picture
   you might notice that the result of drawing two lines through input
   space is actually three distinct categories rather than the two that we
   wanted.  this is a problem, but we won't worry about it until later.
   [19]picture
   if you're on the ball, you might notice that these four options can be
   arranged to make a logic table, just like the one at the top of the
   page.  so we have two neurons, each performing a logical function
   described by a logic table, and then the two neurons feed their results
   forward into a third neuron that again performs a logical function
   described by a logic table.  it has a beautiful simplicity to it!
   picture
   on the left i've added the output neuron.
   to summarise:
     * there are two inputs and one output to the network (just as in the
       single neurons of the and and or functions)
     * both of the neurons in the first layer are connected to the same
       inputs
     * the first layer (the two neurons) draws two lines through input
       space, while the second layer (the single neuron) draws one line
       through a space defined by the neurons in the previous layer

   let's see graphically what the space defined by the two first layer
   neurons looks like, and how the second layer neuron divides it...
   on the right is the same graph that we saw at the top of the page.  be
   sure you understand what is happening here perfectly (see my
   [20]formalising & visualising page if you don't know the relevance of
   lines to neurons).
   picture
   picture
   picture
   the way we do this is to have one neuron calculate the bottom line, as
   shown in the graph on the left and the logic table below....
   [21]picture
   notice that the only combination of inputs that isn't allowed by this
   neuron is (0,0), just as shown in the graph.
   ... and the second neuron determine the upper line, as shown in the
   graph on the left and the logic table below...
   [22]picture
   and then we subtract the latter from the former.  in graphical terms,
   that leaves us with the bit of the graph shown on the right.
   however, it's more informative to look at the logic tables to
   understand the next stage.
   picture
   the single neuron in the output (second) layer uses the outputs of the
   two neurons in the previous layer as its input.  in logic table terms,
   this means the third columns of the two first layer neurons become the
   first two columns of the second layer neuron.
   below i have shown how the logic table for the single neuron in the
   second layer is formed from the third columns (outputs) of the two
   neurons in the first layer.
   [23]picture
   then we use the logic table that we've just made for the single second
   layer neuron to draw its graph, with input 1 (from first layer neuron
   1's output) as the horizontal axis, and input 2 (from first layer
   neuron 2's output) as the vertical axis.  the red squares (output = 0)
   and blue circle (output = 1) taken from the third column.   this is
   shown on the right.
   you can see that although there are four rows in the logic table, there
   are only three points on the graph.  this is because the two points
   that require an output of 1 are situated in the same place (1,0).
   you can also see that it's possible to draw a single line that
   separates the two kinds of output, as i have done in green, and as the
   single output neuron in the second layer does.
   picture

something  to  play  with...

   here's an excel file i made to demonstrate how the weights control the
   orientation of the line, and how the network will behave properly as
   long as the lines defined by the neurons in the first layer correctly
   divide up the input space and the line defined by the neuron in the
   second layer correctly divides up the space defined by the outputs of
   the first layer neurons.
   the network is initially set up as shown on the right, which is the
   same as the one we created on a [24]previous page.
   [25][xls.png]
   xor.xlsm
   file size: 27 kb
   file type: xlsm
   [26]download file
     __________________________________________________________________

   [27]picture
   below is a picture of what it looks like when it's open.  the first
   layer neurons are coloured in blue and orange and both receive inputs
   from the yellow cells; b1 and c1.  the second layer neuron is coloured
   green and uses the outputs from the first layer neurons (cells c5 and
   f5) as its inputs.
   the lines on the graphs are coloured to match, with the top graph being
   the input space and the bottom graph being the space defined by the
   outputs of the first layer neurons.
   the logic table is shown in yellow at the bottom as a single table
   rather than the three that are shown above.
   picture
   to play with the file, just change the weights around and see how it
   affects the lines and whether it gives rise to an error (red cell).
   you can also change the threshold if you like, as this also affects the
   line (see [28]formalising & visualising).
   one effect of having the second layer neuron dividing the space which
   is defined by the outputs of the first layer neurons is that if the
   first layer neurons are not behaving correctly, the second layer neuron
   cannot behave correctly.  so when making similar networks that learn
   (this one doesn't), it's important that the first layer learns
   (settles) faster.

conclusion

   a single neuron has just one axon to send outputs with, and the output
   it sends are the all or nothing spikes of action potentials - they are
   either active or not.  in other words, there are only two possible
   outputs for any single neuron: on or off (1 or 0, yes or no, true or
   false, firing or quiet).  because there are only two possibilities, a
   single neuron can only categorise its inputs into two groups.  this is
   irrespective of how many inputs there are into the neuron (inputs give
   you more information to help make the decision, but don't add different
   possibilities for what the decision will be).  moreover, the neuron's
   method of making this binary categorisation is to draw a straight line
   through its input space.
   since a neuron can only draw a single straight line through its input
   space, there are some categorisations that are impossible for a single
   neuron to perform; an example being the xor logical operation (and
   there are many more).
   it doesn't help to add more neurons in the same layer because we still
   need a way of combining all of their outputs to get a single
   conclusion.  the only solution is, therefore, to add another layer of
   neurons.
   adding extra layers of neurons allows the network to break down the
   problem into sub-problems that can be solved, and then combine the
   results later (via another neuron)..

   version: mobile | [29]web
   created with weebly

   computational neuroscience     in  excel

references

   visible links
   1. http://toritris.weebly.com/
   2. http://toritris.weebly.com/
   3. http://toritris.weebly.com/advantages-of-neural-networks.html
   4. http://toritris.weebly.com/id88-1-basic-neuron.html
   5. http://toritris.weebly.com/id88-2-logical-operations.html
   6. http://toritris.weebly.com/id88-3-learning.html
   7. http://toritris.weebly.com/id88-4-formalising--visualising.html
   8. http://toritris.weebly.com/id88-5-xor-how--why-neurons-work-together.html
   9. http://toritris.weebly.com/neurons-fire--ideas-emerge.html
  10. http://toritris.weebly.com/visual-system-1-retina.html
  11. http://toritris.weebly.com/visual-system-2-illusions-in-the-retina.html
  12. http://toritris.weebly.com/visual-system-3-v1---line-detectors.html
  13. http://toritris.weebly.com/comments.html
  14. http://toritris.weebly.com/recursive-connections.html
  15. http://toritris.weebly.com/bayesian-brain.html
  16. http://toritris.weebly.com/id88-2-logical-operations.html
  17. http://toritris.weebly.com/id88-4-formalising--visualising.html
  18. http://toritris.weebly.com/id88-4-formalising--visualising.html
  19. http://toritris.weebly.com/uploads/1/4/1/3/14134854/5010545_orig.jpg?323
  20. http://toritris.weebly.com/id88-4-formalising--visualising.html
  21. http://toritris.weebly.com/uploads/1/4/1/3/14134854/2410611_orig.jpg?292
  22. http://toritris.weebly.com/uploads/1/4/1/3/14134854/7576855_orig.jpg?302
  23. http://toritris.weebly.com/uploads/1/4/1/3/14134854/8257876_orig.jpg?658
  24. http://toritris.weebly.com/id88-2-logical-operations.html
  25. http://toritris.weebly.com/uploads/1/4/1/3/14134854/xor.xlsm
  26. http://toritris.weebly.com/uploads/1/4/1/3/14134854/xor.xlsm
  27. http://toritris.weebly.com/uploads/1/4/1/3/14134854/4959601_orig.jpg
  28. http://toritris.weebly.com/id88-4-formalising--visualising.html
  29. http://toritris.weebly.com/id88-5-xor-how--why-neurons-work-together.html?view=full

   hidden links:
  31. http://www.weebly.com/weebly/apps/install_app.php?source=footer
  32. http://www.weebly.com/
