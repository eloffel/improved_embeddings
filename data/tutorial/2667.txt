   [1]deep learning summer school 2016

     * [2]overview
     * [3]schedule
     * invited speakers
     * [4]venue
     * [5]accommodation
     * [6]applications

invited speakers

   the deep learning summer school (2016 edition) features these invited
   speakers:
   [7][doina-head.jpg?height=200&amp;width=150]
   [8]doina precup from mcgill university
   machine learning
   we provide a general introduction to machine learning, aimed to put all
   participants on the same page in terms of definitions and basic
   background. after a brief overview of different machine learning
   problems, we discuss id75, its objective function and
   closed-form solution. we discuss the bias-variance trade-off and the
   issue of overfitting (and the proper use of cross-validation to measure
   performance objectively). we discuss the probabilistic view of the
   sum-squared error as maximizing likelihood under specific assumptions
   on the data generation process, and present l2 and l1 id173
   methods as priors from a bayesian perspective. we briefly discuss
   bayesian methodology for learning. finally, we present logistic
   regression, the cross-id178 optimization criterion and its solution
   through first- and second-order methods.
   the slides for this lecture are available [9]here.
   the video of this lecture is available [10]here.
   the video of doina's talk on "advanced topics in rl" is
   available [11]here.
   [12][larochelle.jpg?height=200&amp;width=150]
   [13]hugo larochelle from twitter and universit   de sherbrooke
   neural networks
   in this lecture, i will cover the basic concepts behind feedforward
   neural networks. the talk will be split into 2 parts. in the first
   part, i'll cover forward propagation and id26 in neural
   networks. specifically, i'll discuss the parameterization of
   feedforward nets, the most common types of units, the capacity of
   neural networks and how to compute the gradients of the training loss
   for classification with neural networks. in the second part, i'll
   discuss the final components necessary to train neural networks by
   id119 and then discuss the more recent ideas that are now
   commonly used for training deep neural networks. i will thus present
   different variants of id119 algorithms, dropout, batch
   id172 and unsupervised pretraining.
   the slides for this lecture are available [14]here.
   the video of this lecture is available [15]here.
   [16][lamblin.jpg?height=200&amp;width=150]
   [17]pascal lamblin from universit   de montr  al
   introduction to theano (theano i & practical session)
   the slides for this lecture are available [18]here.
   the video of this lecture is available [19]here.
   [20][fergus.jpg?height=200&amp;width=156]
   [21]rob fergus from new york university
   convolutional neural networks and id161
   this talk will review convolutional neural network models and the
   tremendous impact they have made on id161 problems in the
   last few years.
   the slides for this lecture are available [22]here.
   the video of this lecture is available [23]here.
   [24][torralba.jpg?height=200&amp;width=150]
   [25]antonio torralba from massachusetts institute of technology
   learning to see
   it is an exciting time for id161. with the success of new
   computational architectures for visual processing, such as deep neural
   networks (e.g., convnets) and access to image databases with millions
   of labeled examples (e.g., id163, places), the state of the art in
   id161 is advancing rapidly. id161 is now present
   among many commercial products, such as digital cameras, web
   applications, security applications, etc.
   the performances achieved by convnets are remarkable and constitute the
   state of the art on many recognition tasks. but why it works so well?
   what is the nature of the internal representation learned by the
   network? i will show that the internal representation can be
   interpretable. in particular, object detectors emerge in a scene
   classification task. then, i will show that an ambient audio signal can
   be used as a supervisory signal for learning visual representations. we
   do this by taking advantage of the fact that vision and hearing often
   tell us about similar structures in the world, such as when we see an
   object and simultaneously hear it make a sound. we train a convnet to
   predict ambient sound from video frames, and we show that, through this
   process, the model learns a visual representation that conveys
   significant information about objects and scenes.
   the video of this lecture is available [26]here.
   [27][alex.jpg?height=200&amp;width=149]
   [28]alex wiltschko from twitter
   introduction to torch (torch i & practical session)
   torch is an open platform for scientific computing in the lua language,
   with a focus on machine learning, in particular deep learning. torch is
   distinguished from other array libraries by having first-class support
   for gpu computation, and a clear, interactive and imperative style.
   further, through the "nn" library, torch has broad support for building
   and training neural networks by composing primitive blocks or layers
   together in compute graphs. torch, although benefitting from extensive
   industry support, is a community owned and community developed
   ecosystem.
   all neural net libraries, including torch nn, rely on automatic
   differentiation (ad) to manage the computation of gradients of complex
   compositions of functions. i will also present some general background
   on automatic differentiation (ad), which is the fundamental abstraction
   of gradient-based optimization, and demonstrate twitter's flexible
   implementation of ad in the library torch-autograd.
   the slides for this lecture are available [29]here.
   the video of this lecture is available [30]here.
   [31][bengio.jpg?height=200&amp;width=149]
   [32]yoshua bengio from universit   de montr  al
   recurrent neural networks
   this lecture will cover recurrent neural networks, the key ingredient
   in the deep learning toolbox for handling sequential computation and
   modelling sequences. it will start by explaining how gradients can be
   computed (by considering the time-unfolded graph) and how different
   architectures can be designed to summarize a sequence, generate a
   sequence by ancestral sampling in a fully-observed directed model, or
   learn to map a vector to a sequence, a sequence to a sequence (of the
   same or different length) or a sequence to a vector. the issue of
   long-term dependencies, why it arises, and what has been proposed to
   alleviate it will be core subject of the discussion in this lecture.
   this includes changes in the architecture and initialization, as well
   as how to properly characterize the architecture in terms of recurrent
   or feedforward depth and its ability to create shortcuts or fast
   propagation of gradients in the unfolded graph. open questions
   regarding the limitations of training by maximum likelihood (teacher
   forcing) and ideas towards towards making learning online (not
   requiring backprop through time) will also be discussed.
   the slides for this lecture are available [33]here.
   the video of this lecture is available [34]here.
   [35][chopra.jpg?height=200&amp;width=150]
   [36]sumit chopra from facebook
   reasoning, attention and memory
   the machine learning community has had great success in the last
   decades at solving basic prediction tasks such as text classification,
   image annotation and id103. however, solutions to deeper
   reasoning tasks have remained elusive. a key component towards
   achieving deeper reasoning is the use of long term dependencies as well
   as short term context during id136. until recently, most existing
   machine learning models have lacked an easy way to read and write to
   part of a (potentially very large) long-term memory component, and to
   combine this seaid113ssly with id136. to combine memory with
   reasoning, a model must learn how to access it, i.e. to perform
   *attention* over its memory.
   within the last year or so, there has been some notable progress in
   this area however. models developing notions of attention have shown
   positive results on a number of real-world tasks such as machine
   translation and image captioning. there has also been a surge in
   building models of computation which explore differing forms of
   explicit storage. towards that end, i   ll shed some light on a set of
   models that fall in this category. in particular, i   ll discuss the
   memory networks, and its application to a wide variety of tasks, such
   as, id53 based on simulated stories, cloze style question
   answering, and dialog modeling. i   ll also talk about their subsequently
   proposed variants, including, end2end memory networks and key value
   memory networks. in addition, i will also talk about neural turing
   machines, and stack augmented recurrent neural networks. throughout the
   talk i   ll discuss the advantages and disadvantages of each of these
   models and their variants. i will conclude with a discussion on what is
   still lacking among these models and potential open problems.
   the slides for this lecture are available [37]here.
   the video of this lecture is available [38]here.
   [39][dean.jpg?height=200&amp;width=150]
   [40]jeff dean from google
   large scale deep learning with tensorflow
   the last few years have seen deep learning make significant advances in
   fields as diverse as id103, image understanding, natural
   language understanding, translation, robotics, and healthcare. in this
   talk i'll describe some of the machine learning research done by the
   google brain team (often in collaboration with others at google). as
   part of our research, we have built two systems, distbelief, and
   tensorflow, for training large-scale deep learning models on large
   datasets. i'll describe some of the distributed system techniques we
   use to scale training of such modelsbeyond single devices, as well
   describe some of the design decisions and implementation of tensorflow
   system, which was open sourced in november, 2015.
   the slides for this lecture are available [41]here.
   video that accompanies slide 218 is [42]here.
   the video of this lecture is available [43]here.
   [44][cho.jpg?height=200&amp;width=149]
   [45]kyunghyun cho from new york university
   deep natural language understanding
   in this lecture, i start with a claim that natural language
   understanding can largely be approached as building a better language
   model and explain three widely-adopted approaches to language
   modelling. they are id165 language modelling, feedforward neural
   language modelling and recurrent language modelling. as i develop from
   the traditional id165 language model toward recurrent language model,
   i discuss the concepts of data sparsity and generalization via
   continuous space representations. i then continue on to the recent
   development of a novel paradigm in machine translation based on
   recurrent language modelling, often called id4.
   the lecture concludes with three new opportunities in natural language
   processing/understanding made possible by the introduction of
   continuous space representations in deep neural networks.
   the slides for this lecture are available [46]here.
   the video of this lecture is available [47]here.
   [48][grefenstette.jpg?height=200&amp;width=150]
   [49]edward grefenstette from google deepmind
   beyond id195 with augmented id56s
   sequence to sequence models in their most basic form, following an
   encoder-decoder paradigm, compressively encode source sequence
   representations into a single vector representation and decode this
   representation into a target sequence. this lecture will discuss the
   problems with this compressive approach, some solutions involving
   attention and external differentiable memory, and issues faced by these
   extensions. motivating examples from the field of natural language
   understanding will be provided throughout.
   the slides for this lecture are available [50]here.
   the video of this lecture is available [51]here.
   [52][julie.jpg?height=200&amp;width=150]
    [53]julie bernauer from nvidia
   gpu programming for deep learning
   the slides for this lecture are available [54]here.
   the video of this lecture is available [55]here.
   [56][joelle-pineau_oe.jpg?height=200&amp;width=151]
   [57]joelle pineau from mcgill university
   introduction to id23
   the slides for this lecture are available [58]here.
   the video of this talk is available
   is available [59]here.
   the video of joelle's talk on "advanced topics in rl" is
   available [60]here.
   [61][abbeel.png?height=200&amp;width=149]
   [62]pieter abbeel from uc berkeley
   deep id23
   the slides for this lecture are available [63]here.
   the video of this talk is available
   is available [64]here.
   [65][salakhutdinov.jpg?height=200&amp;width=148]
   [66]ruslan salakhutdinov from carnegie mellon university
   learning deep generative models
   in this tutorial i will discuss mathematical basics of many popular
   deep generative models, including restricted id82s
   (rbms), deep id82s (dbms), helmholtz machines, variational
   autoencoders (vae) and importance weighted autoencoders (iwae). i will
   further demonstrate that these models are capable of extracting
   meaningful representations from high-dimensional data with applications
   in visual object recognition, information retrieval, and natural
   language processing.
   the slides for this lecture are available [67]here.
   the video of this talk is available
   is available [68]here.
   [69][mohammad.png?height=200&amp;width=150]
   [70]shakir mohamed from google deepmind
   building machines that imagine and reason: principles and applications
   of deep generative models
   deep generative models provide a solution to the problem of
   unsupervised learning, in which a machine learning system is required
   to discover the structure hidden within unlabelled data streams.
   because they are generative, such models can form a rich imagery the
   world in which they are used: an imagination that can harnessed to
   explore variations in data, to reason about the structure and behaviour
   of the world, and ultimately, for decision-making. this tutorial looks
   at how we can build machine learning systems with a capacity for
   imagination using deep generative models, the types of probabilistic
   reasoning that they make possible, and the ways in which they can be
   used for decision making and acting.
   deep generative models have widespread applications including those in
   density estimation, image denoising and in-painting, data compression,
   scene understanding, representation learning, 3d scene construction,
   semi-supervised classification, and hierarchical control, amongst many
   others. after exploring these applications, we'll sketch a landscape of
   generative models, drawing-out three groups of models: fully-observed
   models, transformation models, and latent variable models. different
   models require different principles for id136 and we'll explore the
   different options available. different combinations of model and
   id136 give rise to different algorithms, including auto-regressive
   distribution estimators, variational auto-encoders, and generative
   adversarial networks. although we will emphasise deep generative
   models, and the latent-variable class in particular, the intention of
   the tutorial will be to explore the general principles, tools and
   tricks that can be used throughout machine learning. these reusable
   topics include bayesian deep learning, variational approximations,
   memoryless and amortised id136, and stochastic gradient estimation.
   we'll end by highlighting the topics that were not discussed, and
   imagine the future of generative models.
   the slides for this lecture are available [71]here.
   the video of this talk is available
   is available [72]here.
   [73][olshausen.jpg?height=200&amp;width=149]
   [74]bruno olshausen from uc berkeley
   beyond inspiration: five lessons from biology on building intelligent
   machines
   the only known systems that exhibit truly intelligent, autonomous
   behavior are biological. if we wish to build machines that are capable
   of such behavior, then it makes sense to learn as much as we can about
   how these systems work. inspiration is a good starting point, but real
   progress will require gaining a more solid understanding of the
   principles of information processing at work in nervous systems. here i
   will focus on five areas of investigation that i believe will be
   especially fruitful: 1) the study of perception and cognition in tiny
   nervous systems such as wasps and jumping spiders, 2) developing good
   computational models of nonlinear signal integration in dendritic
   trees, 3) the use of sparse, overcomplete representations of sensory
   input, 4) understanding the computational role of feedback in neural
   systems, and 5) the use of active sensing systems for acquiring
   information about the world.
   the slides for this lecture are available [75]here.
   the video of this talk is available
   is available [76]here.
   [77][ganguli.jpg?height=200&amp;width=149]
   [78]surya ganguli from stanford university
   theoretical neuroscience and deep learning theory
   both neuroscience and machine learning are experiencing a renaissance
   in which fundamental technological changes are driving qualitatively
   new phases of conceptual progress. in neuroscience, new methods for
   probing and perturbing multi-neuronal dynamics during behavior have
   lead to the ability to create complex neural network models for the
   emergence of behavior from the brain. in machine learning, new methods
   and computing infrastructure for training neural networks have lead to
   the creation of deep neural networks capable of solving complex
   computational problems. these advances in each of these individual
   fields are laying the groundwork for a new alliance between
   neuroscience and machine learning. a key dividend of this alliance
   would be the genesis of new unified theories underlying neural learning
   dynamics, expressive power, generalization capability, and
   interpretability of both biological and artificial networks. ideally
   such theories could yield both scientific insight into the operation of
   biological and id158s, as well as provide
   engineering design principles for the creation of new artificial neural
   networks. here we outline a roadmap for this new alliance, and discuss
   several vignettes from the beginnings of such an alliance, including
   how neural network learning dynamics can model infant semantic
   learning, how dynamically critical weight initializations can lead to
   rapid training, and how the expressive power of deep neural networks
   can have its origins in the theory of chaos. we also speculate on how
   several elements of neurobiological reality, as yet not extensively
   employed by neural network practitioners, could aid in the design of
   future id158s. such elements include structured
   neural network architectures motivated by the canonical cortical
   microcircuit, nested neural loops with a diversity of time scales, and
   complex synapses with rich internal dynamics.
   the slides for this lecture are available [79]here.
   the video of this talk is available
   is available [80]here.
   comments

   [81]sign in|[82]recent site activity|[83]report abuse|[84]print
   page|powered by [85]google sites

references

   visible links
   1. https://sites.google.com/site/deeplearningsummerschool2016/
   2. https://sites.google.com/site/deeplearningsummerschool2016/home
   3. https://sites.google.com/site/deeplearningsummerschool2016/schedule
   4. https://sites.google.com/site/deeplearningsummerschool2016/venue
   5. https://sites.google.com/site/deeplearningsummerschool2016/accomodation
   6. https://sites.google.com/site/deeplearningsummerschool2016/applications
   7. https://sites.google.com/site/deeplearningsummerschool2016/speakers/doina-head.jpg?attredirects=0
   8. http://www.cs.mcgill.ca/~dprecup/
   9. https://drive.google.com/file/d/0b_wzp_jlvfckthf1rmxsbmjsb200wuvplvfnx21nykdjlwjv/view?usp=sharing
  10. http://videolectures.net/deeplearning2016_precup_machine_learning/
  11. http://videolectures.net/deeplearning2016_precup_advanced_lr/
  12. https://sites.google.com/site/deeplearningsummerschool2016/speakers/larochelle.jpg?attredirects=0
  13. https://twitter.com/hugo_larochelle
  14. https://drive.google.com/file/d/0b_wzp_jlvfckrdnuoxf2wnplszg/view?usp=sharing
  15. http://videolectures.net/deeplearning2016_larochelle_neural_networks/
  16. https://sites.google.com/site/deeplearningsummerschool2016/speakers/lamblin.jpg?attredirects=0
  17. https://mila.umontreal.ca/en/person/lamblin-pascal/
  18. https://github.com/mila-udem/summerschool2016/raw/master/theano/course/intro_theano.pdf
  19. http://videolectures.net/deeplearning2016_lamblin_theano/
  20. https://sites.google.com/site/deeplearningsummerschool2016/speakers/fergus.jpg?attredirects=0
  21. http://cs.nyu.edu/~fergus/pmwiki/pmwiki.php
  22. https://drive.google.com/file/d/0b_wzp_jlvfckrkhra0dzuedklwc/view?usp=sharing
  23. http://videolectures.net/deeplearning2016_fergus_neural_networks/
  24. https://sites.google.com/site/deeplearningsummerschool2016/speakers/torralba.jpg?attredirects=0
  25. http://web.mit.edu/torralba/www/
  26. http://videolectures.net/deeplearning2016_torralba_learning_see/
  27. https://sites.google.com/site/deeplearningsummerschool2016/speakers/alex.jpg?attredirects=0
  28. https://www.linkedin.com/in/alex-wiltschko-0a7b7537
  29. https://drive.google.com/file/d/0b_wzp_jlvfckwndjtek3a2ndx0u/view?usp=sharing
  30. http://videolectures.net/deeplearning2016_wiltschko_torch/
  31. https://sites.google.com/site/deeplearningsummerschool2016/speakers/bengio.jpg?attredirects=0
  32. http://www.iro.umontreal.ca/~bengioy/yoshua_en/index.html
  33. https://drive.google.com/file/d/0b_wzp_jlvfckdlhtug9kmtvjlvnhmljkynjybc1bcdjevngw/view?usp=sharing
  34. http://videolectures.net/deeplearning2016_bengio_neural_networks/
  35. https://sites.google.com/site/deeplearningsummerschool2016/speakers/chopra.jpg?attredirects=0
  36. https://research.facebook.com/sumit-chopra
  37. https://drive.google.com/open?id=0b_wzp_jlvfckbhdpyvdzmjg3etbqd2f1og9qzlvhogjox0dz
  38. http://videolectures.net/deeplearning2016_chopra_attention_memory/
  39. https://sites.google.com/site/deeplearningsummerschool2016/speakers/dean.jpg?attredirects=0
  40. http://research.google.com/pubs/jeff.html
  41. https://drive.google.com/open?id=0b_wzp_jlvfcks2lydm5jdv9kmk1yuenoala5tg5pv0lqws1v
  42. https://www.youtube.com/watch?v=iaf43ze1oei
  43. http://videolectures.net/deeplearning2016_dean_deep_learning/
  44. https://sites.google.com/site/deeplearningsummerschool2016/speakers/cho.jpg?attredirects=0
  45. http://www.kyunghyuncho.me/
  46. https://drive.google.com/open?id=0b_wzp_jlvfckc0xrmjrhru9dn2jrqlb0tjdkdmplz0fsatfz
  47. http://videolectures.net/deeplearning2016_cho_language_understanding/
  48. https://sites.google.com/site/deeplearningsummerschool2016/speakers/grefenstette.jpg?attredirects=0
  49. http://egrefen.com/
  50. https://drive.google.com/open?id=0b_wzp_jlvfckytfatvfjn18tbmtkx2v0weetwxvsddv4uhvz
  51. http://videolectures.net/deeplearning2016_grefenstette_augmented_id56/
  52. https://sites.google.com/site/deeplearningsummerschool2016/speakers/julie.jpg?attredirects=0
  53. https://www.linkedin.com/in/juliebernauer
  54. https://drive.google.com/open?id=0b_wzp_jlvfckmxhjs21wvg92b0npem5reuluethszg1ov2u4
  55. http://videolectures.net/deeplearning2016_bernauer_olson_deep_learning/
  56. https://sites.google.com/site/deeplearningsummerschool2016/speakers/joelle-pineau_oe.jpg?attredirects=0
  57. http://cs.mcgill.ca/~jpineau/
  58. https://drive.google.com/open?id=0b_wzp_jlvfckddg4yy1xqtbzluhgtg5tt29rexdycxdes1lv
  59. http://videolectures.net/deeplearning2016_pineau_reinforcement_learning/
  60. http://videolectures.net/deeplearning2016_pineau_advanced_topics/
  61. https://sites.google.com/site/deeplearningsummerschool2016/speakers/abbeel.png?attredirects=0
  62. http://www.cs.berkeley.edu/~pabbeel/
  63. https://drive.google.com/open?id=0b_wzp_jlvfcks2ddwuzqttzgalu
  64. http://videolectures.net/deeplearning2016_abbeel_deep_reinforcement/
  65. https://sites.google.com/site/deeplearningsummerschool2016/speakers/salakhutdinov.jpg?attredirects=0
  66. http://www.cs.toronto.edu/~rsalakhu/
  67. https://drive.google.com/open?id=0b_wzp_jlvfckyxzktkjwuwe2nja
  68. http://videolectures.net/deeplearning2016_salakhutdinov_generative_models/
  69. https://sites.google.com/site/deeplearningsummerschool2016/speakers/mohammad.png?attredirects=0
  70. http://blog.shakirm.com/about-me/
  71. https://drive.google.com/open?id=0b_wzp_jlvfckmnfmnnatytvkv28
  72. http://videolectures.net/deeplearning2016_mohamed_generative_models/
  73. https://sites.google.com/site/deeplearningsummerschool2016/speakers/olshausen.jpg?attredirects=0
  74. http://redwood.berkeley.edu/bruno/
  75. https://drive.google.com/open?id=0b_wzp_jlvfckmuf4aujns3f5tm1puzhktezqv25nyjy1mxvj
  76. http://videolectures.net/deeplearning2016_olshausen_beyond_inspiration/
  77. https://sites.google.com/site/deeplearningsummerschool2016/speakers/ganguli.jpg?attredirects=0
  78. https://web.stanford.edu/dept/app-physics/cgi-bin/person/surya-gangulijanuary-2012/
  79. https://drive.google.com/open?id=0b_wzp_jlvfckevrfvvnkx0nmele
  80. http://videolectures.net/deeplearning2016_ganguli_theoretical_neuroscience/
  81. https://accounts.google.com/servicelogin?continue=https://sites.google.com/site/deeplearningsummerschool2016/speakers&service=jotspot
  82. https://sites.google.com/site/deeplearningsummerschool2016/system/app/pages/recentchanges
  83. https://sites.google.com/site/deeplearningsummerschool2016/system/app/pages/reportabuse
  84. javascript:;
  85. http://sites.google.com/site

   hidden links:
  87. https://sites.google.com/site/deeplearningsummerschool2016/speakers/fred.jpg?attredirects=0
  88. https://sites.google.com/site/deeplearningsummerschool2016/speakers/fred.jpg?attredirects=0
