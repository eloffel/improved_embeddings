   #[1]publisher [2]the new stack    feed [3]the new stack    comments feed
   [4]alternate [5]alternate

   [tr?id=1824226617806384&ev=pageview&noscript=1]

search (enter to see all results)

   [search-cancel-icon.png] ____________________

stories

tags

authors

   [6]stories [7]tags [8]authors

popular topics

   [9]analysis
   [10]podcasts
   [11]events
   [12]news
   [13]the new stack makers
   [14]interviews
   [15]open source
   [16]contributed
   [17]tutorials
   [18]research

   [19][the-new-stack-logo.svg]

   [20]skip to content
     * [21]ebooks
          + [22]machine learning
          + [23]devops
          + [24]serverless
          + [25]microservices
          + [26]kubernetes ecosystem
          + [27]docker ecosystem
          + [28]all ebooks
     * [29]podcasts
          + [30]tns @scale series
          + [31]tns analysts round table
          + [32]tns context weekly news
          + [33]tns makers interviews
          + [34]all podcasts
     * [35]events
     * [36]newsletter

     * [37]           
          + [38]ebooks
               o [39]machine learning
               o [40]devops
               o [41]serverless
               o [42]microservices
               o [43]kubernetes ecosystem
               o [44]docker ecosystem
               o [45]all ebooks
          + [46]podcasts
               o [47]tns @scale series
               o [48]tns analysts round table
               o [49]tns context weekly news
               o [50]tns makers interviews
               o [51]all podcasts
          + [52]events
          + [53]newsletter

   [54]skip to content
     * [55]architecture
          + [56]cloud native
          + [57]containers
          + [58]edge/iot
          + [59]microservices
          + [60]networking
          + [61]serverless
          + [62]storage
     * [63]development
          + [64]application security
          + [65]cloud services
          + [66]data
          + [67]machine learning
          + [68]programming languages
     * [69]operations
          + [70]ci/cd
          + [71]culture
          + [72]devops
          + [73]kubernetes
          + [74]monitoring
          + [75]tools

   [search-icon.svg]



   2017-01-25 08:00:38
   artificial intelligence's next big step: id23
   analysis,

[76]containers / [77]data / [78]machine learning / [79]programming languages

artificial intelligence   s next big step: id23

25 jan 2017 8:00am, by [80]mary branscombe

   [81]tweet about this on twitter
   twitter
   [82]share on reddit
   reddit
   [83]share on facebook
   facebook
   [84]share on linkedin
   linkedin
   [85]share on hacker news
   [86]+

   almost every [87]machine learning breakthrough you hear about (and most
   of what   s currently called    artificial intelligence   ) is supervised
   learning; where you start with a curated and labeled data set. but
   another technique, id23, is just starting to make its
   way out of the research lab.

   id23 is where an agent learns by interacting with its
   environment. it isn   t told by a trainer what to do and it learns what
   actions to take to get the highest reward in the situation by trial and
   error, even when the reward isn   t obvious and immediate. it learns how
   to solve problems rather than being taught what solutions look like.

   id23 is how deepmind created the [88]alphago system
   that beat a high-ranking go player (and has recently been winning
   online go matches anonymously). it   s how [89]university of california
   berkeley   s brett robot learns how to move its hands and arms to perform
   physical tasks like stacking blocks or screwing the lid onto a bottle,
   in just three hours (or ten minutes if it   s told where the objects are
   that it   s going to work with, and where they need to end up).
   developers at a hackathon built a smart trash can be called
   [90]autotrash that used id23 to sort compostable and
   recyclable rubbish into the right compartments.

   id23 is the reason [91]microsoft just bought maluuba,
   which microsoft plans to use it to aid in understanding natural
   language for search and chatbots, as a stepping stone to general
   intelligence.

   commercial deployments are far rarer, though. in 2016, google started
   using deepmind   s id23 to save power in some of its
   data centers by learning how to optimize around 120 different settings
   like how the fans and cooling systems run, adding up to a 15 percent
   improvement in power usage efficiency.

   and without anyone really noticing, back in january 2016 microsoft
   started using a very specific subset of id23 called
   contextual bandits to pick the personalized headlines for msn.com;
   something multiple machine learning systems had failed to improve.

   the contextual bandit system increased clickthrough by 25 percent     and
   a few months later, microsoft turned it into an open source
   [92]multiworld testing decision service built on the [93]vowpal wabbit
   machine learning system, that you can run on [94]azure.
   [d0a1ccaf-langford-300x300.jpg]

   microsoft   s john langford discusses multiworld testing at qcon nyc last
   june.

      we have a deployable system, which i think is the first anywhere in
   the world,    claims [95]john langford, the microsoft researcher who
   started work on vowpal wabbit when he was at yahoo.

   multiworld testing runs multiple context-sensitive experiments at the
   same time and it lets you answer much more detailed questions than
   standard a/b testing. contextual bandits are a mathematical
   representation of a slot machine with multiple arms, and before
   choosing which arm to pull each time the agent sees a feature vector
   showing the current context (from the multiworld testing), as well as
   the rewards for arms it   s played in the past.

   contextual bandits are one of two    islands of tractability    in the
   id23 space    which is clearly still more of a research
   endeavor than supervised learning,    warned langford.    there are a lot
   of problems that are readily posed as id23 problems
   for which we have no effective solution.   

      they work in situations where the reward is immediately clear and you
   get feedback on your actions,    he explained;    where you have contextual
   control over small numbers of actions and where you get feedback about
   that action. we want to try to tame these techniques, to normalize them
   and make them easy to use; that   s what we   re trying to do with the
   decision service.   

   sometimes the feedback isn   t immediate, so you might need to use reward
   shaping, which    lets you take a long-term goal and decompose the reward
   for that into a bunch of short-term rewards     the sum of which, if you
   get it right, gives you the long-term goal. this is a key problem you
   need to resolve when trying to solve id23 problems.   

   sticking to those situations is how the team was able to create a
   id23 solution that works in the real world rather
   than just a research problem.    it   s very much a limitation of scope
   that makes it tractable,    langford points out.    there   s a particular
   subset, contextual bandits, where we know that things are tractable and
   the decision service tackles that subset.   

      the important thing to note is there is no long-term decision-making
   aspect,    further explained [96]alekh agarwal of microsoft research, who
   also worked on the decision service.    it   s a sequential process where
   you observe some context and take an action and immediately get a
   reward; there   s no long-term reward to worry about. there   s still a
   limitation; if you take an action you only see the reward for that
   action, not what would have happened if you took another action. you   re
   trying to optimize your choice of actions given the contextual
   information you have.    that   s another way id23
   differs from supervised learning, he notes.

   the problem isn   t just long-term rewards, but    the credit assignment
   across multiple actions,    added langford.    if you take 30 actions and
   any of those can affect the rewards you observe, that   s a different
   situation. it   s easy to come up with problems where all the existing
   algorithms will fail badly.   

the right problems

   [97][9edf12b9-mwds-259x300.png]

   the multiworld decision service is live and costs about 20 cents an
   hour to run on azure (click to enlarge).

   there are problems where id23 is better than the
   better known supervised learning, though.    right now there are a lot of
   problems people are trying to solve that don   t fit the supervised
   learning paradigm but they   re used to supervised learning so they try
   to use it,    langford explained.    the canonical one is trying to predict
   clicks and optimize which ad you place.    contextual bandits are ideal
   for that, and for making other personalized content recommendations.

   another applicable area is personalized user interfaces that adapt to
   your behavior. imagine that you wanted to use an eeg to control a
   computer.    every time you put the eeg on your head, it   s in a slightly
   different position and the system needs to learn to very quickly adjust
   to how where it   s been placed on your head,    suggested langford.    the
   person using the interface is going to notice when things go wrong and
   they can issue a correction; that was right, that was wrong. there
   would be a natural co-learning process.   

   personalized healthcare is a trickier problem, especially given privacy
   issues and fragmented medical records, but at least theoretically,
   contextual bandits might help.    not all healthcare is the sort where a
   single action leads to a clear outcome, but a portion is,    he noted.
      instead of the drug trials we have today, imagine trials that are ten
   or twenty times larger that learn a policy for deploying treatments
   personalized to individual subjects rather than the one-size fits all
   policy we do right now.   

   resource allocation     for humans or computers     is applicable well
   beyond google   s data center management trials and it   s also a good fit
   for contextual bandits, says agarwal.    when you send a request to a
   website, which server should handle it? operating systems solve many
   resource allocation problems. in many of these cases you have to do
   some work to define the right functions, but some of them end up being
   reasonable fits for bandits.   

   getting the rewards right is key;    it tends to be where the art is in
   trying to solve id23 problems,    says langford.
      sometimes it   s dead obvious, like clicks. sometimes it   s more subtle.
   but figuring out how to frame the problem is the silver bullet for
   solving the problem.   

show me

   if that   s just too difficult, researchers turn to the second type of
   id23 that we can currently do well: imitation
   learning, by demonstrating a technique.    it may be easier for a human
   to supply the information about the right thing to do than to come up
   with a good reward function that matches the problem.   

      you see this a lot in robotics where you demonstrate to a robot what
   you want it to do and it can learn to do something like the same thing,
   sometimes even better than a human can do,    he noted. you need to make
   a long sequence of decisions to succeed and it   s hard to break down the
   value of incremental decisions. robots work from sensory feedback; they
   have cameras and sensors for where the actuators are and they translate
   this feedback into short-term rewards. the beauty of this is that the
   demos keep you out of local minima and maxima.   

   self-driving car systems work in the same way, noted agarwal, and he
   points out that to be effective, imitation learning needs high-quality
   demos.    if you   re getting very expert demonstrations with optimal
   sequences of actions most of the time, you can learn to imitate them
   well and generalize them to unseen situations and not get stuck.   

   unlike contextual bandits, there isn   t just one technique for imitation
   learning. there isn   t a standardized platform like the multiworld
   decision service that you can use on your own problems. but we   re
   starting to get platforms to help researchers experiment.

play a game?

   games are a common way to train id23 systems because
   they have built-in rewards. atari 2600 games have been a popular
   choice, but often they   re fairly simplistic environments. at the end of
   2016, both google and [98]open.ai announced that they were opening up
   their id23 training systems to researchers, giving
   far more people access to complex simulated environments for training
   ai agents previously reserved for companies with the budget to build
   them.

   google   s [99]deepmind lab     known internally as labyrinth     looks like
   a simple 3-d game, with a floating orb representing the ai agent. the
   world includes 14 levels and four kinds of learning tasks like
   navigating a maze (static or generated on the fly), playing laser tag
   and collecting fruit, but researchers can get the code for this virtual
   environment from [100]github, create their own levels (using a game
   editor or programmatically in c and python) and experiment with
   different reward schemes and gameplay logic.
   [101][8cafd7b7-deepmindlab-1024x571.png]

   the ai agent in deepmind lab is an orb that can view and navigate the
   3d world (photo: google).

   [102]openai   s universe is also an experimentation platform for working
   on ai agents that try to learn to use computers the way humans do; by
   looking at the pixels on screen and operating virtual controls. as with
   lab, the aim of universe is to develop an ai agent that can not only
   learn to deal with one situation but use the learning techniques it   s
   developed to tackle unfamiliar environments as a stepping stone to
   creating ai that goes beyond a single, narrow domain     and openai   s
   approach is to give researchers access to a lot of environments that
   were created for humans, not specially crafted for ai agents to learn
   in. not only does that turn games and apps we already have into a
   training ground; it also means ai agents can watch people using the
   software to kick-start their learning     and we can compare the ai to
   human performance rather than just each other.

   universe lets you use any program with [103]openai   s gym toolkit for
   building id23 agents in frameworks like tensorflow
   and [104]theano. gym already included simulated robots, go and a range
   of classic atari games and universe extends that to over a thousand
   environments, including flash games, 80 common browser tasks like
   typing in a password or a booking a flight, and games like grand theft
   auto v.

   universe packages them up as docker images, launches them on a [105]vnc
   remote desktop and controls them through python scripts     although not
   all of them support id23 yet. ocr runs in the
   python program that controls the docker container to scrape the game
   scores to use as rewards; of the 1,000 flash games, 100 have reward
   functions and openai has plans to use human players to demonstrate more
   of the games to ai agents, to make it easier to analyze what the
   rewards should be. in the future, universe ai agents will get access to
   games like portal and wing commander iii, as well as [106]wolfram
   mathematica, and maybe android and unity games as well.

   they   re also going to be able to run inside [107]project malmo,
   microsoft   s id23 experimentation platform which runs
   on top of [108]minecraft (which it started work on in 2014 and open
   sourced in mid-2016).

      some ai techniques that were purely on the research side for decades
   are starting to move closer and closer to real world applications,   
   says [109]katja hofmann, from microsoft   s research lab in cambridge.
      that   s very exciting. to really push those techniques forward, we need
   to flexibly, rapidly be able to experiment with techniques. that need
   for pushing forward experimentation was the motivation for project
   malmo. now there are more and more of these platforms, which is
   exciting     and important for both pushing research forward and opening
   that research up to the broader community of developers and enthusiasts
   who can join in and start productizing.   

   currently, universe and project malmo use slightly different apis to
   integrate bots and agents in games and to run experiments. the first
   step will be making it easier to train an agent on one platform and
   then test it on the other.    there   s a lot to be gained by standardizing
   some of those apis to make it as easy as possible for the community to
   switch back and forth.   

   in the long run, that will let researchers create portable agent
   architectures.    we   re working with variants of deep reinforcement
   learning agents that can not only learn 2-d atari games but also plug
   into agents that navigate the 3-d minecraft world where they can look
   around and see where to go. having the same kind of architecture for
   both will translate to effective learning in both those scenarios, so
   we can rapidly make progress, though experimentation, on aspects that
   focus on interactive learning.   

   the two platforms have different research agendas. project malmo is
   about what hofmann calls flexible learning.

      the idea is to develop ai that that doesn   t just address a single task
   but that flexibly learn and build up common sense knowledge and use
   that to tackle more and more complex problems. we think minecraft is
   fantastic for this because it creates a sandbox. you have an entire
   world that   s infinite and that   s procedurally generated. you put the
   agent in the environment and it experiences is from a first-person
   perspective. today, the agent can learn basic survival     how to
   navigate and avoid lava. as the technology matures, it can build up
   more complex skills like construction, learning how to build up complex
   items. agents will be able to reuse their knowledge and basic
   understanding of the minecraft world when they learn new tasks. that   s
   similar to how people learn about the world in one particular way and
   adopt that to the task at hand.   

   ultimately, she hopes that work will lead to collaborative ai, where
   agents learn to collaborate with human users.    if you want to achieve a
   goal, we   ll need an agent that can understand the goal and reason about
   the steps it needs to take in order to help you achieve that goal.
   that   s one of our key motivations.   

   the openai project has a rather different goal; they   re hoping to
   create a single ai agent with a generic problem-solving strategy, a
   first step towards general ai.

experimentation is the way forward

   like so much of ai, id23 isn   t new; the first
   textbook covering it dates to 1998 (and the second edition will finally
   come out this year). what   s different now is partly that we have
   experience with some problems that are well understood, particularly in
   the two areas of contextual bandits and imitation learning. but we also
   need these new experimentation platforms like universe and project
   malmo and deepmind lab to give more researchers access, and to compare
   solutions in the same environment to benchmark progress.

   agarwal compares the availability of experimentation platforms for
   id23 to the impact large labeled data sets like
   [110]id163 had on supervised learning.    the way we make a lot of
   progress in supervised learning was that we started accumulating large
   data sets and repositories and once we had those, we could try
   algorithms out on them reliably and iterate those algorithms.    a static
   data set isn   t useful for evaluating more general reinforcement
   learning;    two different agents will take two different trajectories
   through an environment.   

   instead, researchers need a large, diverse set of environments that   s
   also standardized so everyone in the field works against them.
      flexible, diverse platforms can serve the same function as a
   repository for id23 tasks where we can evaluate and
   iterate on ideas coming out of research much faster than was possible
   in the past, when we had to restrict the algorithms to simple
   evaluation problems because more complex ones weren   t available. now we
   can take ideas to the platforms and see whether or not they do a good
   job,    agarwal said.

   id23 will often be only one of the machine learning
   strategies in a solution. even alphago was initially trained to mimic
   human play using deep learning and a database of around 30 million
   moves from 160,000 games played by human go masters. it was only once
   it reached a certain level of skill that it began playing against other
   instances of alphago and using id23 to improve.

        it   s important in the long run to understand how an ai agent could
     be able to learn about those goals and about the peculiarities and
     abilities of the person it   s working with        katja hofmann

   that pattern might actually be key to making id23
   ready for wider use, hofmann suggested     either by using deep learning
   to prepare the actions and rewards for a id23 system,
   or by using id23 to reduce the work it takes to apply
   supervised learning to a domain.

      at the moment, if you put a id23 agent in a 3-d
   environment they would reason at the granularity of individual
   abstraction, taking one step forward, not on a higher level using the
   concept of walking to the next door. there are questions about
   abstraction that still need to be addressed before we can put the next
   pieces of id23 into applications, like understanding
   how to set goals in situations where a clean scoring function might not
   be available,    hofmann explained.

   the experimentation platforms help with that research, but so do the
   recent advances in deep learning.    for decades, the reinforcement
   learning problem of learning an appropriate presentation of a domain
   couldn   t be tackled in a systematic way because for every new app you
   could envision, you would need domain experts to find a representation
   [for that domain]. that was very resource intensive and didn   t scale to
   the breadth of applications we would like to unlock,    hofmann
   explained, adding that    we   ve had major advanced in learning
   representations and automatically extracting the features that describe
   a domain and that allows us to scale algorithms to new domains.   

   there is still plenty of research to be done, like how to get agents to
   explore their environment systematically, giving them the equivalent of
   curiosity or the intrinsic motivation to explore. and there   s also the
   problem that few developers are familiar with id23 at
   this point. it   s likely that systems like the multiworld decision
   service will help bring id23 to a broader developer
   audience, agarwal suggested.

   one of the differences between supervised learning and reinforcement
   learning is that in the supervised learning world it   s usually a
   machine learning person providing the algorithm and the user bringing
   the data.    in id23, it   s more that you bring your
   domain to the table and the agent by acting in the world is creating
   its own data. that creates a lot of complexity; the app developer has
   to build a lot more pieces of the solution if they want an algorithm to
   work in the right way and there are many things that can go wrong. it   s
   often better to design a whole system,    agarwal suggested.

   langford is also optimistic.    over the next say five years, i expect
   that education will happen and that we will see many more successful
   applications and see these kinds of systems become much more
   standardized in the world.   

   and hofmann has some big ambitions of her own.    you can envision and ai
   that   s able to learn; it would have some general knowledge about the
   environment, about what kinds of tasks people want to achieve and it
   would also be able to learn on the fly so it can personalize its help
   and support towards the goals of the person or the player.   

      in the real world, every person has different knowledge and abilities
   and desires,    she explained.    it   s important in the long run to
   understand how an ai agent could be able to learn about those goals and
   about the peculiarities and abilities of the person it   s working with
   and be able to personalize its assistance and actions to help that
   particular person achieve their goals.   

   feature image: laser tag levels in deepmind lab test agents on fine
   control, strategy, planning and dealing with a complex visual
   environment. image from google.

   [111]analysis
   [112]tweet about this on twitter
   twitter
   [113]share on reddit
   reddit
   [114]share on facebook
   facebook
   [115]share on linkedin
   linkedin
   [116]+

   [the-new-stack-updates-logo.svg]

a newsletter digest of the week   s most important stories & analyses.

   ____________________
   do you also want to be notified of the following?
   [ ] send me everything :-d
   [ ] upcoming ebook notifications [ ] research surveys [ ] upcoming
   event notifications [ ] new product & service notifications
   (button) subscribe [tns-button-loading.svg]
   we don   t sell or share your email. by continuing, you agree to our
   [117]terms of use.

   related stories

[118]+

   [podcastbrandingoverlay_tns_analysts.svg]

[119]kubernetes / [120]microservices / [121]networking

[122]how the service mesh redefines cloud native computing

28 mar 2019 5:00pm, by [123]b. cameron gain

[124]+

   []

[125]kubernetes

[126]kubernetes warms up to ipv6

25 feb 2019 11:55am, by [127]mary branscombe

   view / add comments

please stay on topic and be respectful of others. review our [128]terms of
use.

   sponsored feed
   [129][4a53d638-dynatrace@2x.png]
   [130]find quicker answers to your questions in the redesigned dynatrace
   help system
   april 05, 2019
   [131][bded1ace-openstack@2x.png]
   [132]what   s new in latest release of the openstack cloud provider for
   kubernetes
   april 05, 2019
   [133][b0aad753-tigera@2x.png]
   [134]what your kubernetes security checklist might be missing
   april 05, 2019
   [135][cncf@2x.png]
   [136]china unicom leveraged kubernetes to boost efficiency for 300
   million users
   april 05, 2019
   [137][cloudfoundry@2x.png]
   [138]interview avec thierry javelot, head of business process
   management west
   april 05, 2019
   [139][0b8a7166-gitlab@2x.png]
   [140]how we delivered more performant and robust task lists in gitlab
   april 04, 2019
   [141][69778945-portworx@2x.png]
   [142]kubernetes cassandra: how to run ha cassandra with rancher
   kubernetes engine
   april 04, 2019
   [143][45286d2f-pulumi@2x.png]
   [144]programming the cloud with python
   april 04, 2019
   [145][d2f23bca-circleci@2x.png]
   [146]how to test software, part i: mocking, stubbing, and contract
   testing
   april 04, 2019
   [147][b0438c93-puppet@2x.png]
   [148]fancy a round of pinball with your vox pupuli friends?
   april 04, 2019
   [149][d89d8e1a-influxdata@2x.png]
   [150]influxdata jumpstarts 2019 with new funding, customers, community
   growth and more
   april 04, 2019
   [151][df79640c-cloudbees@2x.png]
   [152]getting webhooks behind that firewall of yours
   april 04, 2019
   [153][345dfc95-lightbend@2x.png]
   [154]lightbend telemetry 2.11 released, adds support for scala 2.13,
   java futures, akka scheduler
   april 04, 2019
   [155][4e8ad9dc-exoscale@2x.png]
   [156]java for serverless: ahead-of-time compilation with micronaut and
   graalvm
   april 03, 2019
   [157][f5138a03-red-hat-openshift@2x.png]
   [158]kubernetes operator hands-on workshop at red hat summit on may 6th
   announced
   april 03, 2019
   [159][b7658547-raygun@2x.png]
   [160]c# debugging tools and techniques
   april 03, 2019
   [161][b22fecc6-linuxfoundation@2x.png]
   [162]lf networking passes one-year mark with expanded cross-community
   momentum
   april 03, 2019
   [163][042245f3-pagerduty@2x.png]
   [164]announcing pagerduty summit 2019! by pagerduty
   april 03, 2019
   [165][pivotal@2x.png]
   [166]cloud native buildpacks: an industry-standard build process for
   kubernetes and beyond.
   april 02, 2019
   [167][a93ae45a-memsql@2x.png]
   [168]how ceos can stay relevant in the age of ai
   april 02, 2019
   [169][67841a3d-aspenmesh@2x.png]
   [170]announcing aspen mesh 1.1
   april 02, 2019
   [171][35c9e830-oracle@2x.png]
   [172]site reliability engineering (sre) workbench at oracle code
   april 02, 2019
   [173][87a847e8-twistlock@2x.png]
   [174]service mesh. service fabric. service bus. what does it all mean?!
   april 02, 2019
   [175][d217cf09-chef@2x.png]
   [176]introducing the new chef: 100% open, always
   april 02, 2019
   [177][7fcc3a2c-haproxy@2x.png]
   [178]extending haproxy with the stream processing offload engine
   april 02, 2019
   [179][6cef594c-semaphore@2x.png]
   [180]a docker product manager on what the future holds for containers
   april 02, 2019
   [181][db4b1f93-atomist@2x.png]
   [182]announcing sdm 1.4
   april 01, 2019
   [183][5e8bc8be-wso2@2x.png]
   [184]women in open source tech roundup: march 2019
   march 31, 2019
   [185][02b6112a-epsagon@2x.png]
   [186]troubleshooting aws lambda 101
   march 29, 2019
   [187][3a06bcf4-nirmata@2x.png]
   [188]kubernetes jobs and cronjobs
   march 28, 2019
   [189][60fc8d25-harness@2x.png]
   [190]harness continuous delivery for aws cloud-native applications
   march 27, 2019
   [191][0c7335aa-stackery@2x.png]
   [192]can   t-miss serverless sessions for aws summit santa clara
   march 26, 2019
   [193][565068e6-packet@2x.png]
   [194]to infinity and beyond: illustrating the cloud native universe
   march 25, 2019
   [195][78f349c9-ns1@2x.png]
   [196]next-generation dns drives better sre: here's how
   march 21, 2019
   [197][4e8a205d-humio@2x.png]
   [198]better, faster, resilient software delivery through limitless
   logging
   march 20, 2019
   [199][85b960ce-rollbar@2x.png]
   [200]introducing interactive slack notifications
   march 11, 2019

architecture

     * [201]cloud native
     * [202]containers
     * [203]edge/iot
     * [204]microservices
     * [205]networking
     * [206]serverless
     * [207]storage

development

     * [208]application security
     * [209]cloud services
     * [210]data
     * [211]machine learning
     * [212]programming languages

operations

     * [213]ci/cd
     * [214]culture
     * [215]devops
     * [216]kubernetes
     * [217]monitoring
     * [218]tools

the new stack

     * [219]ebooks
     * [220]podcasts
     * [221]events
     * [222]newsletter
     * [223]about / contact
     * [224]sponsors
     * [225]disclosures
     * [226]contributions

     * [227]twitter
     * [228]facebook
     * [229]youtube
     * [230]soundcloud
     * [231]linkedin
     * [232]slideshare
     * [233]rss

   2019 the new stack. all rights reserved.

   [234]privacy policy. [235]terms of use.

   iframe: [236]//www.googletagmanager.com/ns.html?id=gtm-wgf7mx

   [tr?id=1667886366787627&ev=pageview&noscript=1]

references

   visible links
   1. https://plus.google.com/u/0/100040585732637649813
   2. https://thenewstack.io/feed/
   3. https://thenewstack.io/comments/feed/
   4. https://thenewstack.io/wp-json/oembed/1.0/embed?url=https://thenewstack.io/reinforcement-learning-ready-real-world/
   5. https://thenewstack.io/wp-json/oembed/1.0/embed?url=https://thenewstack.io/reinforcement-learning-ready-real-world/&format=xml
   6. https://thenewstack.io/reinforcement-learning-ready-real-world/
   7. https://thenewstack.io/reinforcement-learning-ready-real-world/
   8. https://thenewstack.io/reinforcement-learning-ready-real-world/
   9. https://thenewstack.io/tag/analysis
  10. https://thenewstack.io/tag/podcasts
  11. https://thenewstack.io/tag/events
  12. https://thenewstack.io/tag/news
  13. https://thenewstack.io/tag/the-new-stack-makers
  14. https://thenewstack.io/tag/interviews
  15. https://thenewstack.io/tag/open-source
  16. https://thenewstack.io/tag/contributed
  17. https://thenewstack.io/tag/tutorials
  18. https://thenewstack.io/tag/research
  19. https://thenewstack.io/
  20. https://thenewstack.io/reinforcement-learning-ready-real-world/#content
  21. https://thenewstack.io/ebooks/
  22. https://thenewstack.io/ebooks/machine-learning/
  23. https://thenewstack.io/ebooks/devops/
  24. https://thenewstack.io/ebooks/serverless/
  25. https://thenewstack.io/ebooks/microservices/
  26. https://thenewstack.io/ebooks/kubernetes/
  27. https://thenewstack.io/ebooks/docker-and-containers/
  28. https://thenewstack.io/ebooks/
  29. https://thenewstack.io/podcasts/
  30. https://thenewstack.io/podcasts/at-scale/
  31. https://thenewstack.io/podcasts/analysts/
  32. https://thenewstack.io/podcasts/context/
  33. https://thenewstack.io/podcasts/makers/
  34. https://thenewstack.io/podcasts/
  35. https://thenewstack.io/events/
  36. https://thenewstack.io/newsletter/
  37. https://thenewstack.io/
  38. https://thenewstack.io/ebooks/
  39. https://thenewstack.io/ebooks/machine-learning/
  40. https://thenewstack.io/ebooks/devops/
  41. https://thenewstack.io/ebooks/serverless/
  42. https://thenewstack.io/ebooks/microservices/
  43. https://thenewstack.io/ebooks/kubernetes/
  44. https://thenewstack.io/ebooks/docker-and-containers/
  45. https://thenewstack.io/ebooks/
  46. https://thenewstack.io/podcasts/
  47. https://thenewstack.io/podcasts/at-scale/
  48. https://thenewstack.io/podcasts/analysts/
  49. https://thenewstack.io/podcasts/context/
  50. https://thenewstack.io/podcasts/makers/
  51. https://thenewstack.io/podcasts/
  52. https://thenewstack.io/events/
  53. https://thenewstack.io/newsletter/
  54. https://thenewstack.io/reinforcement-learning-ready-real-world/#content
  55. https://thenewstack.io/
  56. https://thenewstack.io/category/cloud-native/
  57. https://thenewstack.io/category/containers/
  58. https://thenewstack.io/category/edge-iot/
  59. https://thenewstack.io/category/microservices/
  60. https://thenewstack.io/category/networking/
  61. https://thenewstack.io/category/serverless/
  62. https://thenewstack.io/category/storage/
  63. https://thenewstack.io/
  64. https://thenewstack.io/category/application-security/
  65. https://thenewstack.io/category/cloud-services/
  66. https://thenewstack.io/category/data/
  67. https://thenewstack.io/category/machine-learning/
  68. https://thenewstack.io/category/programming-languages/
  69. https://thenewstack.io/
  70. https://thenewstack.io/category/ci-cd/
  71. https://thenewstack.io/category/culture/
  72. https://thenewstack.io/category/devops/
  73. https://thenewstack.io/category/kubernetes/
  74. https://thenewstack.io/category/monitoring/
  75. https://thenewstack.io/category/tools/
  76. https://thenewstack.io/category/containers/
  77. https://thenewstack.io/category/data/
  78. https://thenewstack.io/category/machine-learning/
  79. https://thenewstack.io/category/programming-languages/
  80. https://thenewstack.io/author/marybranscombe/
  81. http://twitter.com/share?url=https://thenewstack.io/reinforcement-learning-ready-real-world/&text=artificial intelligence   s next big step: id23 
  82. http://reddit.com/submit?url=https://thenewstack.io/reinforcement-learning-ready-real-world/&title=artificial intelligence   s next big step: id23
  83. http://www.facebook.com/sharer.php?u=https://thenewstack.io/reinforcement-learning-ready-real-world/
  84. http://www.linkedin.com/sharearticle?mini=true&url=https://thenewstack.io/reinforcement-learning-ready-real-world/
  85. https://news.ycombinator.com/submitlink?u=https://thenewstack.io/reinforcement-learning-ready-real-world/&t=artificial intelligence   s next big step: id23
  86. https://thenewstack.io/reinforcement-learning-ready-real-world/#disqus_thread
  87. https://thenewstack.io/category/machine-learning/
  88. http://thenewstack.io/alphagos-win-human-go-champion-means-ai/
  89. http://news.berkeley.edu/2015/05/21/deep-learning-robot-masters-skills-via-trial-and-error/
  90. https://www.youtube.com/watch?v=sogk2y5vqdc
  91. http://www.theverge.com/2017/1/13/14266398/microsoft-acquires-maluuba-ai-deep-learning-yoshua-bengio
  92. https://github.com/microsoft/mwt-ds
  93. https://github.com/johnlangford/vowpal_wabbit
  94. http://mwtds.azurewebsites.net/
  95. https://github.com/johnlangford
  96. http://alekhagarwal.net/
  97. https://cdn.thenewstack.io/media/2017/01/9edf12b9-mwds.png
  98. https://openai.com/about/
  99. https://deepmind.com/
 100. https://github.com/deepmind/lab
 101. https://cdn.thenewstack.io/media/2017/01/8cafd7b7-deepmindlab.png
 102. https://universe.openai.com/
 103. https://gym.openai.com/
 104. https://github.com/theano/theano
 105. https://www.realvnc.com/
 106. http://www.wolfram.com/mathematica/?source=nav
 107. https://github.com/microsoft/malmo#getting-started
 108. https://minecraft.net/en-us/
 109. https://www.microsoft.com/en-us/research/people/kahofman/
 110. http://image-net.org/
 111. https://thenewstack.io/tag/analysis/
 112. http://twitter.com/share?url=https://thenewstack.io/reinforcement-learning-ready-real-world/&text=artificial intelligence   s next big step: id23 
 113. http://reddit.com/submit?url=https://thenewstack.io/reinforcement-learning-ready-real-world/&title=artificial intelligence   s next big step: id23
 114. http://www.facebook.com/sharer.php?u=https://thenewstack.io/reinforcement-learning-ready-real-world/
 115. http://www.linkedin.com/sharearticle?mini=true&url=https://thenewstack.io/reinforcement-learning-ready-real-world/
 116. https://thenewstack.io/reinforcement-learning-ready-real-world/#disqus_thread
 117. https://thenewstack.io/terms-of-use
 118. https://thenewstack.io/how-the-service-mesh-redefines-cloud-native-computing/#disqus_thread
 119. https://thenewstack.io/category/kubernetes/
 120. https://thenewstack.io/category/microservices/
 121. https://thenewstack.io/category/networking/
 122. https://thenewstack.io/how-the-service-mesh-redefines-cloud-native-computing/
 123. https://thenewstack.io/author/bruce-gain/
 124. https://thenewstack.io/kubernetes-warms-up-to-ipv6/#disqus_thread
 125. https://thenewstack.io/category/kubernetes/
 126. https://thenewstack.io/kubernetes-warms-up-to-ipv6/
 127. https://thenewstack.io/author/marybranscombe/
 128. https://thenewstack.io/terms-of-use
 129. https://www.dynatrace.com/news/blog/find-quicker-answers-to-your-questions-in-the-redesigned-dynatrace-help-system/
 130. https://www.dynatrace.com/news/blog/find-quicker-answers-to-your-questions-in-the-redesigned-dynatrace-help-system/
 131. https://superuser.openstack.org/articles/whats-new-v1-14-openstack-cloud-provider-kubernetes/
 132. https://superuser.openstack.org/articles/whats-new-v1-14-openstack-cloud-provider-kubernetes/
 133. https://www.tigera.io/blog/what-your-kubernetes-security-checklist-might-be-missing/
 134. https://www.tigera.io/blog/what-your-kubernetes-security-checklist-might-be-missing/
 135. https://www.cncf.io/blog/2019/04/05/china-unicom-leveraged-kubernetes-to-boost-efficiency-for-300-million-users/
 136. https://www.cncf.io/blog/2019/04/05/china-unicom-leveraged-kubernetes-to-boost-efficiency-for-300-million-users/
 137. https://ict.swisscom.ch/2019/04/interview-avec-thierry-javelot-head-of-business-process-management-west/
 138. https://ict.swisscom.ch/2019/04/interview-avec-thierry-javelot-head-of-business-process-management-west/
 139. https://about.gitlab.com/2019/04/05/more-performant-and-robust-task-lists-in-gitlab/
 140. https://about.gitlab.com/2019/04/05/more-performant-and-robust-task-lists-in-gitlab/
 141. https://portworx.com/kubernetes-cassandra-run-ha-cassandra-rancher-kubernetes-engine/
 142. https://portworx.com/kubernetes-cassandra-run-ha-cassandra-rancher-kubernetes-engine/
 143. https://blog.pulumi.com/programming-the-cloud-with-python
 144. https://blog.pulumi.com/programming-the-cloud-with-python
 145. https://circleci.com/blog/how-to-test-software-part-i-mocking-stubbing-and-contract-testing/
 146. https://circleci.com/blog/how-to-test-software-part-i-mocking-stubbing-and-contract-testing/
 147. https://puppet.com/blog/fancy-round-pinball-your-vox-pupuli-friends
 148. https://puppet.com/blog/fancy-round-pinball-your-vox-pupuli-friends
 149. https://www.influxdata.com/blog/2019-q1-update/
 150. https://www.influxdata.com/blog/2019-q1-update/
 151. https://www.cloudbees.com/blog/getting-webhooks-behind-firewall-yours
 152. https://www.cloudbees.com/blog/getting-webhooks-behind-firewall-yours
 153. http://www.lightbend.com/blog/lightbend-telemetry-2-11-released-latest-scala-java-futures-akka-scheduler
 154. http://www.lightbend.com/blog/lightbend-telemetry-2-11-released-latest-scala-java-futures-akka-scheduler
 155. https://www.exoscale.com/syslog/java-serverless-micronaut-graalvm/
 156. https://www.exoscale.com/syslog/java-serverless-micronaut-graalvm/
 157. https://blog.openshift.com/kubernetes-operator-hands-on-workshop-at-red-hat-summit-on-may-6th-announced/
 158. https://blog.openshift.com/kubernetes-operator-hands-on-workshop-at-red-hat-summit-on-may-6th-announced/
 159. https://raygun.com/blog/c-sharp-debugging-tools/
 160. https://raygun.com/blog/c-sharp-debugging-tools/
 161. https://www.linuxfoundation.org/press-release/2019/04/lf-networking-passes-one-year-mark-with-expanded-cross-community-momentum/
 162. https://www.linuxfoundation.org/press-release/2019/04/lf-networking-passes-one-year-mark-with-expanded-cross-community-momentum/
 163. https://www.pagerduty.com/blog/announcing-pagerduty-summit-2019/
 164. https://www.pagerduty.com/blog/announcing-pagerduty-summit-2019/
 165. https://content.pivotal.io/home-page/cloud-native-buildpacks-for-kubernetes-and-beyond
 166. https://content.pivotal.io/home-page/cloud-native-buildpacks-for-kubernetes-and-beyond
 167. https://www.memsql.com/blog/how-ceos-can-stay-relevant-in-the-age-of-ai/
 168. https://www.memsql.com/blog/how-ceos-can-stay-relevant-in-the-age-of-ai/
 169. https://aspenmesh.io/2019/04/announcing-aspen-mesh-1-1/
 170. https://aspenmesh.io/2019/04/announcing-aspen-mesh-1-1/
 171. https://blogs.oracle.com/cloudnative/site-reliability-engineering-sre-workbench-at-oracle-code
 172. https://blogs.oracle.com/cloudnative/site-reliability-engineering-sre-workbench-at-oracle-code
 173. https://www.twistlock.com/2019/04/02/service-mesh-service-fabric-service-bus-mean/
 174. https://www.twistlock.com/2019/04/02/service-mesh-service-fabric-service-bus-mean/
 175. https://blog.chef.io/2019/04/02/chef-software-announces-the-enterprise-automation-stack/
 176. https://blog.chef.io/2019/04/02/chef-software-announces-the-enterprise-automation-stack/
 177. https://www.haproxy.com/blog/extending-haproxy-with-the-stream-processing-offload-engine/
 178. https://www.haproxy.com/blog/extending-haproxy-with-the-stream-processing-offload-engine/
 179. https://semaphoreci.com/blog/a-docker-product-manager-on-what-the-future-holds-for-containers
 180. https://semaphoreci.com/blog/a-docker-product-manager-on-what-the-future-holds-for-containers
 181. https://blog.atomist.com/announcing-sdm-1-4/
 182. https://blog.atomist.com/announcing-sdm-1-4/
 183. https://wso2.com/blogs/thesource/2019/04/women-in-open-source-tech-roundup-march-2019/
 184. https://wso2.com/blogs/thesource/2019/04/women-in-open-source-tech-roundup-march-2019/
 185. https://epsagon.com/blog/troubleshooting-aws-lambda-101/
 186. https://epsagon.com/blog/troubleshooting-aws-lambda-101/
 187. https://www.nirmata.com/2019/03/29/jobs-and-cronjobs/
 188. https://www.nirmata.com/2019/03/29/jobs-and-cronjobs/
 189. https://harness.io/2019/03/harness-continuous-delivery-for-aws-cloud-native-applications/
 190. https://harness.io/2019/03/harness-continuous-delivery-for-aws-cloud-native-applications/
 191. https://www.stackery.io/blog/aws-santa-clara/
 192. https://www.stackery.io/blog/aws-santa-clara/
 193. https://www.packet.com/blog/illustrating-the-cloud-native-universe/
 194. https://www.packet.com/blog/illustrating-the-cloud-native-universe/
 195. https://ns1.com/blog/next-generation-dns-drives-better-sre-heres-how
 196. https://ns1.com/blog/next-generation-dns-drives-better-sre-heres-how
 197. https://humio.com/blog/2019-03-20-logging-better-faster-resilient-software/
 198. https://humio.com/blog/2019-03-20-logging-better-faster-resilient-software/
 199. https://rollbar.com/blog/slack-actions/
 200. https://rollbar.com/blog/slack-actions/
 201. https://thenewstack.io/category/cloud-native/
 202. https://thenewstack.io/category/containers/
 203. https://thenewstack.io/category/edge-iot/
 204. https://thenewstack.io/category/microservices/
 205. https://thenewstack.io/category/networking/
 206. https://thenewstack.io/category/serverless/
 207. https://thenewstack.io/category/storage/
 208. https://thenewstack.io/category/application-security/
 209. https://thenewstack.io/category/cloud-services/
 210. https://thenewstack.io/category/data/
 211. https://thenewstack.io/category/machine-learning/
 212. https://thenewstack.io/category/programming-languages/
 213. https://thenewstack.io/category/ci-cd/
 214. https://thenewstack.io/category/culture/
 215. https://thenewstack.io/category/devops/
 216. https://thenewstack.io/category/kubernetes/
 217. https://thenewstack.io/category/monitoring/
 218. https://thenewstack.io/category/tools/
 219. https://thenewstack.io/ebooks
 220. https://thenewstack.io/podcasts
 221. https://thenewstack.io/events
 222. https://thenewstack.io/newsletter-archive
 223. https://thenewstack.io/about-and-contact-info/
 224. https://thenewstack.io/sponsors/
 225. https://thenewstack.io/disclosure-guidelines/
 226. https://thenewstack.io/contributions/
 227. https://twitter.com/thenewstack
 228. https://www.facebook.com/thenewstack
 229. https://www.youtube.com/channel/ucwea_kfcntmd39uqua5tkoq
 230. https://soundcloud.com/search?q=the new stack
 231. https://www.linkedin.com/company/6611720
 232. http://www.slideshare.net/thenewstack
 233. http://thenewstack.io/rss-feeds
 234. https://thenewstack.io/privacy-policy
 235. https://thenewstack.io/terms-of-use
 236. https://www.googletagmanager.com/ns.html?id=gtm-wgf7mx

   hidden links:
 238. https://thenewstack.io/how-the-service-mesh-redefines-cloud-native-computing/
 239. https://thenewstack.io/kubernetes-warms-up-to-ipv6/
