   [1]kenneth heafield
   <me at kheafield.com>
   informatics forum 4.21
     * [2]code:
          + [3]kenlm
          + [4]memt
          + [5]quiz
          + [6]search
     * [7]papers
     __________________________________________________________________

kenlm language model toolkit

   [8]benchmark | [9]dependencies | [10]developers | [11]estimation |
   [12]filter | [13]moses | [14]structures
   [15]ken models with computer engineer barbie
   kenlm [16]estimates, [17]filters, and [18]queries language models.
   estimation is fast and scalable due to streaming algorithms explained
   in the paper

     [19]scalable modified kneser-ney language model estimation
     kenneth heafield, ivan pouzyrevsky, jonathan h. clark, and philipp
     koehn. [20]acl, sofia, bulgaria, 4   9 august, 2013.
     [[21]paper] [[22]slides] [[23]bibtex]

   querying is [24]fast and low-memory, as shown in the paper

     [25]kenlm: faster and smaller language model queries
     kenneth heafield. [26]wmt at emnlp, edinburgh, scotland, united
     kingdom, 30   31 july, 2011.
     [[27]paper] [[28]slides] [[29]bibtex]

usage

   moses, cdec, joshua, jane, and phrasal already distribute kenlm and
   build it along with the decoder. see their documentation on where to
   find the programs. estimation and filtering require [30]boost at least
   1.36.0 and zlib. i also recommend tcmalloc from [31]gperftools, bzlib
   (to read .bz2 files), and xz-utils (to read .xz files). if your
   distribution has "devel" packages, install those. for more help, see
   [32]dependencies. compilation follows the standard cmake process, for
   which we recommend a separate build directory:
   wget -o - [33]https://kheafield.com/code/kenlm.tar.gz |tar xz
   mkdir kenlm/build
   cd kenlm/build
   cmake ..
   make -j2
   if the dependencies are too difficult and you only need querying, use
   ./compile_query_only.sh that depends only on g++ and bash. programs
   will be located in bin/.

estimating

   language models are estimated from text using modified kneser-ney
   smoothing without pruning. it is done on disk, enabling one to build
   much larger models.
   bin/lmplz -o 5 <text >text.arpa
   see the page on [34]estimation for more.

querying

   the binary file format makes loading faster. run
   bin/build_binary text.arpa text.binary
   and pass text.binary instead of text.arpa. see [35]data structures for
   more on selecting data structures. once your binary file is built,
   query it:

   [36]moses
          in newer versions use e.g. kenlm factor=0 order=5
          path=filename.arpa. in older versions or legacy scripts, [37]use
          language model number 8.

   [38]cdec
          kenlm is the only supported language model.

   [39]joshua
          the lm line in joshua.config should begin with lm = kenlm.

   [40]phrasal
          put kenlm: before the file name.

   [41]kriya
          default. support for srilm requires editing source code.

   [42]hifst
          default. also includes an openfst wrapper for kenlm.

   command line
          bin/query text.binary <data

   python
          cat python/example.py and see the [43]readme.

   your code
          [44]download the source code and read the [45]developer
          documentation.

features

     "the biggest improvement for the language industry has been the
     addition of the new language model kenlm which is fast,
     memory-efficient, and above all, allows the use of multi-core
     processors under the open source license." --[46]achim ruopp, taus

     * [47]faster and lower memory than srilm and irstlm.
     * [48]on-disk estimation with user-specified ram.
     * two data structures for time-space tradeoff.
     * binary format with mmap. or load arpa files directly.
     * if you have the appropriate libraries installed, it can also read
       text and arpa files compressed with gzip, bzip2, or xz.
     * threadsafe.
     * more opportunities for hypothesis recombination. if the model backs
       off, state stores only the matched words. the fullscore function
       also returns the length of id165 matched by the model.
     * querying has few dependencies: a c++ compiler and posix system
       calls. filtering and estimation are multi-threaded, so they depend
       on boost.
     * supports models of any order greater than one (recompilation
       required for orders >= 7).
     * thorough error handling. for example, arpa parse errors include a
       message, the problematic string, the byte offset, and the file
       name. compare with irstlm.
     * loading progress bar.
     * tests. these depend on boost.
     * querying supports id165s containing <unk> tokens; these appear in
       models built with restricted vocabulary.
     * permissive [49]license means you can distribute it unlike srilm.
       there isn't a form to fill out before you can [50]download.

supported platforms

   best on linux. also supports mac os x, cygwin, and windows. tested on
   x86, x86_64, ppc64, and arm. the arm port was contributed by nict.

windows users

   i do not actively maintain the visual studio build files or test on
   windows. a version that works on windows is tagged on [51]github. see
   the windows directory for visual studio project files based on a
   contribution by cong duy vu hoang. compile the kenlm project before the
   build_binary and ngram_query projects, preferably in x64 release mode.

   cygwin works too. however, please note that cygwin is 32-bit even on
   64-bit windows, so you should not expect cygwin to work with model
   sizes over 2 gb.

license

   my code is lgpl but there are files from other sources too. see the
   [52]license file for details.

confusion

   not to be confused with [53]klm or [54]the cmu-cambridge statistical
   id38 toolkit. hieu hoang gave the name [55]kenlm.

   this implementation was [56]mentioned in my january 2010 mt marathon
   paper when early source code was publicly available. integration into
   moses [57]was publicly announced on 18 october 2010. these precede both
   the 17 december 2010 submission deadline for the berkeleylm paper and
   their 20 june 2011 public release. tests performed by adam pauls in may
   2011 showed that kenlm is 4.49x faster. he omitted kenlm from his paper
   and his 20 june 2011 talk, claiming srilm is the fastest package. after
   his talk, an error was discovered in the 4.49x number he reported, but
   corrected results still show kenlm is faster; see the [58]benchmarks.

references

   1. https://kheafield.com/
   2. https://kheafield.com/code/
   3. https://kheafield.com/code/kenlm/
   4. https://kheafield.com/code/memt/
   5. https://kheafield.com/code/quiz/
   6. https://kheafield.com/code/search/
   7. https://kheafield.com/papers/
   8. https://kheafield.com/code/kenlm/benchmark/
   9. https://kheafield.com/code/kenlm/dependencies/
  10. https://kheafield.com/code/kenlm/developers/
  11. https://kheafield.com/code/kenlm/estimation/
  12. https://kheafield.com/code/kenlm/filter/
  13. https://kheafield.com/code/kenlm/moses/
  14. https://kheafield.com/code/kenlm/structures/
  15. https://kheafield.com/code/kenlm/barbie.jpg
  16. https://kheafield.com/code/kenlm/estimation/
  17. https://kheafield.com/code/kenlm/filter/
  18. https://kheafield.com/code/kenlm/structures/
  19. https://kheafield.com/professional/edinburgh/estimate_paper.pdf
  20. http://acl2013.org/
  21. https://kheafield.com/professional/edinburgh/estimate_paper.pdf
  22. https://kheafield.com/professional/edinburgh/estimate_talk.pdf
  23. https://kheafield.com/professional/bib/heafield-estimate.bib
  24. https://kheafield.com/code/kenlm/benchmark/
  25. https://kheafield.com/professional/avenue/kenlm.pdf
  26. http://statmt.org/wmt11/
  27. https://kheafield.com/professional/avenue/kenlm.pdf
  28. https://kheafield.com/professional/avenue/kenlm_talk.pdf
  29. https://kheafield.com/professional/bib/heafield-kenlm.bib
  30. http://www.boost.org/
  31. https://code.google.com/p/gperftools/
  32. https://kheafield.com/code/kenlm/dependencies/
  33. https://kheafield.com/code/kenlm.tar.gz
  34. https://kheafield.com/code/kenlm/estimation/
  35. https://kheafield.com/code/kenlm/structures/
  36. http://www.statmt.org/moses/
  37. https://kheafield.com/code/kenlm/moses/
  38. http://cdec-decoder.org/
  39. http://joshua-decoder.org/
  40. http://www-nlp.stanford.edu/wiki/software/phrasal2
  41. https://github.com/sfu-natlang/kriya
  42. https://ucam-smt.github.io/
  43. https://github.com/kpu/kenlm/blob/master/readme.md
  44. https://kheafield.com/code/kenlm.tar.gz
  45. https://kheafield.com/code/kenlm/developers/
  46. https://www.taus.net/articles/will-there-be-a-thousand-moses-mt-systems
  47. https://kheafield.com/code/kenlm/benchmark/
  48. https://kheafield.com/code/kenlm/estimation/
  49. https://raw.github.com/kpu/kenlm/master/license
  50. https://kheafield.com/code/kenlm.tar.gz
  51. https://github.com/kpu/kenlm/archive/windows.zip
  52. https://raw.github.com/kpu/kenlm/master/license
  53. http://www.klm.com/
  54. http://www.speech.cs.cmu.edu/slm/toolkit.html
  55. https://github.com/moses-smt/mosesdecoder/commit/49b41cb07efbbe736e672385b1acb1fe096ce9a0
  56. https://kheafield.com/professional/avenue/marathon2010.pdf
  57. http://www.mail-archive.com/moses-support@mit.edu/msg03011.html
  58. https://kheafield.com/code/kenlm/benchmark/
