   #[1]publisher [2]medium [3]alternate

   [4]homepage
   [5]homepage
   [6]sign in[7]get started

   [8]startup grind
     * [9]founder stories
     * [10]vc corner
     * [11]find a startup grind near you
     __________________________________________________________________

   [1*onywwlvwhx-qqknoxv537a.jpeg]

fueling the gold rush: the greatest public datasets for ai

   [12]go to the profile of luke de oliveira
   [13]luke de oliveira (button) blockedunblock (button) followfollowing
   feb 11, 2017

   it has never been easier to build ai or machine learning-based systems
   than it is today. the ubiquity of cutting edge open-source tools such
   as [14]tensorflow, [15]torch, and [16]spark, coupled with the
   availability of massive amounts of computation power through [17]aws,
   [18]google cloud, or other cloud providers, means that you can train
   cutting-edge models from your laptop over an afternoon coffee.

   though not at the forefront of the ai hype train, the unsung hero of
   the ai revolution is data         lots and lots of labeled and annotated
   data, curated with the elbow grease of great [19]research groups and
   [20]companies who [21]recognize that the democratization of data is a
   necessary step towards accelerating ai.

   however, most products involving machine learning or ai rely heavily on
   proprietary datasets that are often not released, as this provides
   implicit [22]defensibility.

   with that said, it can be hard to piece through what public datasets
   are useful to look at, which are viable for a proof of concept, and
   what datasets can be useful as a potential product or feature
   validation step before you collect your own proprietary data.

   it   s important to remember that good performance on data set doesn   t
   guarantee a machine learning system will perform well in real product
   scenarios. most people in ai forget that the hardest part of building a
   new ai solution or product is not the ai or algorithms         it   s the data
   collection and labeling. standard datasets can be used as validation or
   a good starting point for building a more tailored solution.

   this week, a few machine learning experts and i were talking about all
   this. to make your life easier, we   ve collected an (opinionated) list
   of some open datasets that you can   t afford not to know about in the ai
   world.
     __________________________________________________________________

legend:
     classic     these are some of the more famous, legacy, or storied datasets in ai
. it   s hard to find a researcher or engineer who hasn   t heard of them.
     useful     these are datasets that are about as close to real-world that a curat
ed, cleaned dataset can be. also, these are often general enough to be useful in
 both the product and r&d world.
     academic baseline     these are datasets that are commonly used the in the acade
mic side of machine learning and ai as benchmarks or baselines. for better or wo
rse, people use these datasets to validate algorithms.
     old - these datasets, irrespective of utility, have been around for a while.

id161

     *                [23]mnist: most commonly used sanity check. dataset of 25x25,
       centered, b&w handwritten digits. it is an easy task         just because
       something works on mnist, doesn   t mean it works.
     *           [24]cifar 10 & cifar 100: 32x32 color images. not commonly used
       anymore, though once again, can be an interesting sanity check.
     *                [25]id163: the de-facto image dataset for new algorithms.
       many image api companies have labels from their rest interfaces
       that are suspiciously close to the 1000 category [26]id138
       hierarchy from id163.
     * [27]lsun: scene understanding with many ancillary tasks (room
       layout estimation, saliency prediction, etc.) and an associated
       competition.
     *      [28]pascal voc: generic image segmentation / classification         not
       terribly useful for building real-world image annotation, but great
       for baselines.
     *      [29]svhn: house numbers from google street view. think of this as
       recurrent mnist in the wild.
     * [30]ms coco: generic image understanding / captioning, with an
       associated competition.
     *      [31]visual genome: very detailed visual knowledge base with deep
       captioning of ~100k images.
     *                     [32]labeled faces in the wild: cropped facial regions
       (using [33]viola-jones) that have been labeled with a name
       identifier. a subset of the people present have two images in the
       dataset         it   s quite common for people to train facial matching
       systems here.

natural language

     *           [34]text classification datasets (google drive link) from
       [35]zhang et al., 2015: an extensive set of eight datasets for text
       classification. these are the most commonly reported baselines for
       new text classification baselines. sample size of 120k to 3.6m,
       ranging from binary to 14 class problems. datasets from dbpedia,
       amazon, yelp, yahoo!, sogou, and ag.
     *          [36] wikitext: large id38 corpus from quality
       wikipedia articles, curated by [37]salesforce metamind.
     *     [38] question pairs: first dataset release from quora containing
       duplicate / semantic similarity labels.
     *          [39] squad: the stanford id53 dataset         broadly
       useful id53 and reading comprehension dataset, where
       every answer to a question is posed as a span, or segment of text.
     * [40]cmu q/a dataset: manually-generated factoid question/answer
       pairs with difficulty ratings from wikipedia articles.
     *     [41] maluuba datasets: sophisticated, human-generated datasets for
       stateful natural language understanding research.
     *           [42]billion words: large, general purpose id38
       dataset. often used to train distributed word representations such
       as [43]id97 or [44]glove.
     *           [45]common crawl: petabyte-scale crawl of the web         most
       frequently used for learning id27s. available [46]for
       free from amazon s3. can also be useful as a network dataset for
       it   s crawl of the www.
     *           [47]babi: synthetic reading comprehension and question
       answering dataset from [48]facebook ai research (fair).
     *      [49]the children   s book test ([50]download link): baseline of
       (question + context, answer) pairs extracted from children   s books
       available through project gutenberg. useful for question-answering,
       reading comprehension, and factoid look-up.
     *                [51]stanford sentiment treebank: standard sentiment dataset
       with fine-grained sentiment annotations at every node of each
       sentence   s parse tree.
     *           [52]20 newsgroups: one of the classic datasets for text
       classification, usually useful as a benchmark for either pure
       classification or as a validation of any ir / indexing algorithm.
     *           [53]reuters: older, purely classification based dataset with
       text from the newswire. commonly used in tutorials.
     *           [54]imdb: an older, relatively small dataset for binary
       sentiment classification. fallen out of favor for benchmarks in the
       literature in lieu of larger datasets.
     *           [55]uci   s spambase: older, classic spam email dataset from the
       famous [56]uci machine learning repository. due to details of how
       the dataset was curated, this can be an interesting baseline for
       learning personalized spam filtering.

speech

   most id103 datasets are proprietary         the data holds a lot
   of value for the company that curates. most datasets available in the
   field are quite old.
     *           [57]2000 hub5 english: english-only speech data used most
       recently in the [58]deep speech paper from baidu.
     *      [59]librispeech: audio books data set of text and speech. nearly
       500 hours of clean speech of various audio books read by multiple
       speakers, organized by chapters of the book containing both the
       text and the speech.
     *           [60]voxforge: clean speech dataset of accented english, useful
       for instances in which you expect to need robustness to different
       accents or intonations.
     *                [61]timit: english-only id103 dataset.
     *      [62]chime: noisy id103 challenge dataset. dataset
       contains real, simulated and clean voice recordings. real being
       actual recordings of 4 speakers in nearly 9000 recordings over 4
       noisy locations, simulated is generated by combining multiple
       environments over speech utterances and clean being non-noisy
       recordings.
     * [63]ted-lium: audio transcription of ted talks. 1495 ted talks
       audio recordings along with full text transcriptions of those
       recordings.

recommendation and ranking systems

     *           [64]netflix challenge: first major kaggle style data challenge.
       only available unofficially, as [65]privacy issues arose.
     *               [66] movielens: various sizes of movie review data         commonly
       used for id185 baselines.
     * [67]million song dataset: large, metadata-rich, open source dataset
       on kaggle that can be good for people experimenting with hybrid
       id126s.
     *     [68] last.fm: music recommendation dataset with access to
       underlying social network and other metadata that can be useful for
       hybrid systems.

networks and graphs

     *      [69]amazon co-purchasing and [70]amazon reviews: crawled data
       from the    users who bought this also bought       section of amazon, as
       well as amazon review data for related products. good for
       experimenting with id126s in networks.
     * [71]friendster social network dataset: before their pivot as a
       gaming website, friendster released anonymized data in the form of
       friends lists for 103,750,348 users.

geospatial data

     *           [72]openstreetmap: vector data for the entire planet under a
       [73]free license. it [74]includes (an older version of) the us
       census bureau   s [75]tiger data.
     *      [76]landsat8: satellite shots of the entire earth surface,
       updated every several weeks.
     *      [77]nexrad: doppler radar scans of atmospheric conditions in the
       us.

         people often think solving a problem on one dataset is equivalent to
   having a well thought out product. use these datasets as validation or
   proofs of concept, but don   t forget to test or prototype how the
   product will function and obtain new, more realistic data to improve
   its operation. successful data-driven companies usually derive strength
   from their ability to collect new, proprietary data that improves their
   performance in a defensible way.
     __________________________________________________________________

please contribute!

   if you think we   ve missed a dataset or two (which we definitely have!)
   or have a conflicting opinion about a dataset discussed here, please
   let me know with a comment, or you can shoot me an email at
   [78]lukedeo@ldo.io!

     p.s.         this post is part of a open, collaborative effort to build an
     online reference, the open guide to practical ai, which we   ll
     release in draft form in a few weeks. see this [79]popular previous
     guide for an example. if you   d like to get updates on or help with
     with this effort, drop me a comment or email me at
     [80]lukedeo@ldo.io.

   [81][1*mro-phkgjv4rzq223oyosa.jpeg]
   [82][1*08eqaty95fgobp_dcsmgja.jpeg]
   [83][1*aryi71qrq78clpwku2be2w.jpeg]

     special thanks to [84]joshua levy, [85]srinath sridhar, and [86]max
     grigorev.

   thanks to [87]joshua levy.
     * [88]machine learning
     * [89]artificial intelligence
     * [90]deep learning
     * [91]data science
     * [92]big data

   (button)
   (button)
   (button) 1.6k claps
   (button) (button) (button) 29 (button) (button)

     (button) blockedunblock (button) followfollowing
   [93]go to the profile of luke de oliveira

[94]luke de oliveira

   deep learning, infrastructure, and open source. founder @ vai, visiting
   scientist @ berkeley labs, stanford/yale alum.

     (button) follow
   [95]startup grind

[96]startup grind

   the life, work, and tactics of entrepreneurs around the world.
   welcoming submissions on technology trends, product design, growth
   strategies, and venture investing. learn more about how you can get
   involved at startupgrind.com.

     * (button)
       (button) 1.6k
     * (button)
     *
     *

   [97]startup grind
   never miss a story from startup grind, when you sign up for medium.
   [98]learn more
   never miss a story from startup grind
   (button) get updatesget updates

references

   visible links
   1. https://plus.google.com/103654360130207659246
   2. https://medium.com/osd.xml
   3. android-app://com.medium.reader/https/medium.com/p/7ae438505bc2
   4. https://medium.com/
   5. https://medium.com/
   6. https://medium.com/m/signin?redirect=https://medium.com/startup-grind/fueling-the-ai-gold-rush-7ae438505bc2&source=--------------------------nav_reg&operation=login
   7. https://medium.com/m/signin?redirect=https://medium.com/startup-grind/fueling-the-ai-gold-rush-7ae438505bc2&source=--------------------------nav_reg&operation=register
   8. https://medium.com/startup-grind?source=logo-lo_momsh8mgifmi---f5c95cc981bd
   9. https://medium.com/startup-grind/tagged/entrepreneurship
  10. https://medium.com/startup-grind/https-medium-com-tag-vc-corner-latest/home
  11. https://www.startupgrind.com/events
  12. https://medium.com/@lukedeo?source=post_header_lockup
  13. https://medium.com/@lukedeo
  14. https://www.tensorflow.org/
  15. http://torch.ch/
  16. http://spark.apache.org/
  17. https://github.com/open-guides/og-aws
  18. https://cloud.google.com/
  19. http://visualgenome.org/
  20. https://metamind.io/research/the-wikitext-long-term-dependency-language-modeling-dataset
  21. https://data.quora.com/first-quora-dataset-release-question-pairs
  22. https://codingvc.com/the-value-of-data-part-1-using-data-as-a-competitive-advantage
  23. http://pjreddie.com/projects/mnist-in-csv/
  24. https://www.cs.toronto.edu/~kriz/cifar.html
  25. http://image-net.org/
  26. http://id138.princeton.edu/
  27. http://lsun.cs.princeton.edu/2016/
  28. http://host.robots.ox.ac.uk/pascal/voc/
  29. http://ufldl.stanford.edu/housenumbers/
  30. http://mscoco.org/
  31. http://visualgenome.org/
  32. http://vis-www.cs.umass.edu/lfw/
  33. https://en.wikipedia.org/wiki/viola   jones_object_detection_framework
  34. https://drive.google.com/drive/u/0/folders/0bz8a_dbh9qhbfll6bvpmnutucfdjymf2sepmzuzucvnimuw1twn6rdv3a0jht3kxlvhvr2m
  35. http://arxiv.org/abs/1509.01626
  36. http://metamind.io/research/the-wikitext-long-term-dependency-language-modeling-dataset/
  37. https://metamind.io/
  38. https://data.quora.com/first-quora-dataset-release-question-pairs
  39. https://rajpurkar.github.io/squad-explorer/
  40. http://www.cs.cmu.edu/~ark/qa-data/
  41. https://datasets.maluuba.com/
  42. http://www.statmt.org/lm-benchmark/
  43. https://www.tensorflow.org/tutorials/id97/
  44. http://nlp.stanford.edu/projects/glove/
  45. http://commoncrawl.org/the-data/
  46. https://aws.amazon.com/public-datasets/common-crawl/
  47. https://research.fb.com/projects/babi/
  48. https://research.fb.com/category/facebook-ai-research-fair/
  49. https://research.fb.com/projects/babi/
  50. http://www.thespermwhale.com/jaseweston/babi/cbtest.tgz
  51. http://nlp.stanford.edu/sentiment/code.html
  52. http://qwone.com/~jason/20newsgroups/
  53. https://archive.ics.uci.edu/ml/datasets/reuters-21578+text+categorization+collection
  54. http://ai.stanford.edu/~amaas/data/sentiment/
  55. https://archive.ics.uci.edu/ml/datasets/spambase
  56. http://archive.ics.uci.edu/ml/
  57. https://catalog.ldc.upenn.edu/ldc2002t43
  58. https://arxiv.org/abs/1412.5567
  59. http://www.openslr.org/12/
  60. http://www.voxforge.org/
  61. https://catalog.ldc.upenn.edu/ldc93s1
  62. http://spandh.dcs.shef.ac.uk/chime_challenge/data.html
  63. http://www-lium.univ-lemans.fr/en/content/ted-lium-corpus
  64. http://www.netflixprize.com/
  65. https://www.wired.com/2010/03/netflix-cancels-contest/
  66. https://grouplens.org/datasets/movielens/
  67. https://www.kaggle.com/c/msdchallenge
  68. http://grouplens.org/datasets/hetrec-2011/
  69. http://snap.stanford.edu/data/#amazon
  70. http://snap.stanford.edu/data/amazon-meta.html
  71. https://archive.org/details/friendster-dataset-201107
  72. http://wiki.openstreetmap.org/wiki/planet.osm
  73. http://www.openstreetmap.org/copyright
  74. http://wiki.openstreetmap.org/wiki/tiger
  75. https://www.census.gov/geo/maps-data/data/tiger.html
  76. https://landsat.usgs.gov/landsat-8
  77. https://www.ncdc.noaa.gov/data-access/radar-data/nexrad
  78. mailto:lukedeo@ldo.io
  79. https://github.com/open-guides/og-aws
  80. mailto:lukedeo@ldo.io
  81. http://eepurl.com/bbbrfx
  82. https://startupgrind2017.eventbrite.com/?aff=readon
  83. http://startupgrind.com/chapters
  84. https://twitter.com/ojoshe
  85. https://www.linkedin.com/in/sridharsrinath
  86. https://twitter.com/forwidur
  87. https://medium.com/@ojoshe?source=post_page
  88. https://medium.com/tag/machine-learning?source=post
  89. https://medium.com/tag/artificial-intelligence?source=post
  90. https://medium.com/tag/deep-learning?source=post
  91. https://medium.com/tag/data-science?source=post
  92. https://medium.com/tag/big-data?source=post
  93. https://medium.com/@lukedeo?source=footer_card
  94. https://medium.com/@lukedeo
  95. https://medium.com/startup-grind?source=footer_card
  96. https://medium.com/startup-grind?source=footer_card
  97. https://medium.com/startup-grind
  98. https://medium.com/@medium/personalize-your-medium-experience-with-users-publications-tags-26a41ab1ee0c#.hx4zuv3mg

   hidden links:
 100. https://medium.com/p/7ae438505bc2/share/twitter
 101. https://medium.com/p/7ae438505bc2/share/facebook
 102. https://medium.com/p/7ae438505bc2/share/twitter
 103. https://medium.com/p/7ae438505bc2/share/facebook
