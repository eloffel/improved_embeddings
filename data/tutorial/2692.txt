   #[1]kdnuggets: analytics, big data, data mining and data science feed
   [2]kdnuggets    feed [3]kdnuggets    comments feed [4]kdnuggets    jupyter
   notebook best practices for data science comments feed [5]top linkedin
   groups for analytics, big data, data mining, and data science in 2016
   [6]nvidia: deep learning library software development engineer

kdnuggets

     [7]subscribe to kdnuggets news  | [8]twitter    [9]facebook
   [10]linkedin  |  [11]contact
   ____________________ search
   [menu-30.png]
   [search-icon.png]
     * [12]software
     * [13]news/blog
     * [14]top stories
     * [15]opinions
     * [16]tutorials
     * [17]jobs
     * [18]companies
     * [19]courses
     * [20]datasets
     * [21]education
     * [22]certificates
     * [23]meetings
     * [24]webinars


   [25]kdnuggets home    [26]news    [27]2016    [28]oct    [29]tutorials,
   overviews    jupyter notebook best practices for data science
   ( [30]16:n38 )

jupyter notebook best practices for data science

   [31][prv.gif] previous post
   [32]next post [nxt.gif]

     http likes 124
   tags: [33]data science, [34]jupyter, [35]python, [36]svds

   check out this overview of jupyter notebook best practices as pertains
   to data science. novice or expert, you may find something of use here.
     __________________________________________________________________

   by jonathan whitmore, silicon valley data science.

   the [37]jupyter notebook is a fantastic tool that can be used in many
   different ways. because of its flexibility, working with the notebook
   on data science problems in a team setting can be challenging. we
   present here some best-practices that svds has implemented after
   working with the notebook in teams and with our clients   and that might
   help your data science teams as well.

   jupyter

   the need to keep work under version control, and to maintain shared
   space without getting in each other   s way, has been a tricky one to
   meet. we present here our current view into a system that works for
   us   and that might help your data science teams as well.

overall thought process


   there are two kinds of notebooks to store in a data science project:
   the lab notebook and the deliverable notebook. first, there is the
   organizational approach to each notebook.

   lab (or dev) notebooks:

   let a traditional paper laboratory notebook be your guide here:
     * each notebook keeps a historical (and dated) record of the analysis
       as it   s being explored.
     * the notebook is not meant to be anything other than a place for
       experimentation and development.
     * each notebook is controlled by a single author: a data scientist on
       the team (marked with initials).
     * notebooks can be split when they get too long (think turn the
       page).
     * notebooks can be split by topic, if it makes sense.

   deliverable (or report) notebooks
     * they are the fully polished versions of the lab notebooks.
     * they store the final outputs of analysis.
     * notebooks are controlled by the whole data science team, rather
       than by any one individual.

version control


   here   s an example of how we use git and github. one beautiful new
   feature of github is that they now render jupyter notebooks
   automatically in repositories.

   when we do our analysis, we do internal reviews of our code and our
   data science output. we do this with a traditional pull-request
   approach. when issuing pull-requests, however, looking at the
   differences between updated .ipynb files, the updates are not rendered
   in a helpful way. one solution people tend to recommend is to commit
   the conversion to .py instead. this is great for seeing the differences
   in the input code (while jettisoning the output), and is useful for
   seeing the changes. however, when reviewing data science work, it is
   also incredibly important to see the output itself.

   for example, a fellow data scientist might provide feedback on the
   following initial plot, and hope to see an improvement:

   [38]not-great

   [39]better-fit

   the plot on the top is a rather poor fit to the data, while the plot on
   the bottom is better. being able to see these plots directly in a
   pull-request review of a team-member   s work is vital.

   see the github commit example [40]here.

   note that there are three ways to see the updated figure (options are
   along the bottom).

   post-save hooks

   we work with many different clients. some of their version control
   environments lack the nice rendering capabilities. there are options
   for deploying an instance of nbviewer behind the corporate firewall,
   but sometimes that still is not an option. if you find yourself in this
   situation, and you want to maintain the above framework of reviewing
   code we have a workaround. in these situations, we commit the .ipynb,
   .py, and .html of every notebook in each commit. creating the .py and
   .html files can be done simply and automatically every time a notebook
   is saved by editing the jupyter config file and adding a post-save
   hook.

   the default jupyter config file is found at:

   ~/.jupyter/jupyter_notebook_config.py

   if you don   t have this file, run:

   jupyter notebook --generate-config

   to create this file, and add the following text:

   run jupyter notebook and you   re ready to go!

   if you want to have this saving .html and .py files only when using a
   particular    profile,    it   s a bit trickier as jupyter doesn   t use the
   notion of profiles anymore.

   first create a new profile name via a bash command line:

   this will create a new directory and file at
   ~/.jupyter_profile2/jupyter_notebook_config.py. then run jupyter
   notebook and work as usual. to switch back to your default profile you
   will have to set (either by hand, shell function, or your .bashrc) back
   to:

   export jupyter_config_dir=~/.jupyter.

   now every save to a notebook updates identically-named .py and .html
   files. add these in your commits and pull-requests, and you will gain
   the benefits from each of these file formats.

putting it all together


   here   s the directory structure of a project in progress, with some
   explicit rules about naming the files.

   example directory structure
- develop # (lab-notebook style)
 + [iso 8601 date]-[ds-initials]-[2-4 word description].ipynb
 + 2015-06-28-jw-initial-data-clean.html
 + 2015-06-28-jw-initial-data-clean.ipynb
 + 2015-06-28-jw-initial-data-clean.py
 + 2015-07-02-jw-coal-productivity-factors.html
 + 2015-07-02-jw-coal-productivity-factors.ipynb
 + 2015-07-02-jw-coal-productivity-factors.py
- deliver # (final analysis, code, presentations, etc)
 + coal-mine-productivity.ipynb
 + coal-mine-productivity.html
 + coal-mine-productivity.py
- figures
 + 2015-07-16-jw-production-vs-hours-worked.png
- src # (modules and scripts)
 + init.py
 + load_coal_data.py
 + figures # (figures and plots)
 + production-vs-number-employees.png
 + production-vs-hours-worked.png
- data (backup-separate from version control)
 + coal_prod_cleaned.csv

   benefits

   there are many benefits to this workflow and structure. the first and
   primary one is that they create a historical record of how the analysis
   progressed. it   s also easily searchable:
     * by date (ls 2015-06*.ipynb)
     * by author (ls 2015*-jw-*.ipynb)
     * by topic (ls *-coal-*.ipynb)

   second, during pull-requests, having the .py files lets a person
   quickly see which input text has changed, while having the .html files
   lets a person quickly see which outputs have changed. having this be a
   painless post-save-hook makes this workflow effortless.

   finally, there are many smaller advantages of this approach that are
   too numerous to list here   please [41]get in touch if you have
   questions, or suggestions for further improvements on the model! for
   more on this topic, check out the [42]related video from o   reilly
   media.

   bio: [43]jonathan whitmore is a data scientist at svds. following a
   postdoctoral position in astrophysics, jonathan is a sought after
   speaker on computing and astronomy. he is excited by the application of
   machine learning and statistical techniques to industry problems and
   has developed novel data analysis techniques.

   [44]original. reposted with permission.

   related:
     * [45]statistical data analysis in python
     * [46]jupyter+spark+mesos: an    opinionated    docker image
     * [47]getting started with data science     python
     __________________________________________________________________

   [48][prv.gif] previous post
   [49]next post [nxt.gif]
     __________________________________________________________________

top stories past 30 days

                                              most popular
    1. [50]another 10 free must-read books for machine learning and data
       science
    2. [51]9 must-have skills you need to become a data scientist, updated
    3. [52]who is a typical data scientist in 2019?
    4. [53]the pareto principle for data scientists
    5. [54]what no one will tell you about data science job applications
    6. [55]19 inspiring women in ai, big data, data science, machine
       learning
    7. [56]my favorite mind-blowing machine learning/ai breakthroughs

                                                most shared
    1. [57]id158s optimization using genetic algorithm
       with python
    2. [58]who is a typical data scientist in 2019?
    3. [59]8 reasons why you should get a microsoft azure certification
    4. [60]the pareto principle for data scientists
    5. [61]r vs python for data visualization
    6. [62]how to work in data science, ai, big data
    7. [63]the deep learning toolset     an overview

[64]latest news

     * [65]download your datax guide to ai in marketing
     * [66]kdnuggets offer: save 20% on strata in london
     * [67]training a champion: building deep neural nets for big ...
     * [68]building a recommender system
     * [69]predict age and gender using convolutional neural netwo...
     * [70]top tweets, mar 27     apr 02: here is a great ex...

   [71]kdnuggets home    [72]news    [73]2016    [74]oct    [75]tutorials,
   overviews    jupyter notebook best practices for data science
   ( [76]16:n38 )
      2019 kdnuggets. [77]about kdnuggets.  [78]privacy policy. [79]terms
   of service

   [80]subscribe to kdnuggets news
   [81][tw_c48.png] [82]facebook [83]linkedin
   x

   [envelope.png] [84]get kdnuggets, a leading newsletter on ai, data
   science, and machine learning
   email: ______________________________
   sign up
   leave this field empty if you're human: ____________________

references

   visible links
   1. https://www.kdnuggets.com/feed/
   2. https://www.kdnuggets.com/feed
   3. https://www.kdnuggets.com/comments/feed
   4. https://www.kdnuggets.com/2016/10/jupyter-notebook-best-practices-data-science.html/feed
   5. https://www.kdnuggets.com/2016/10/top-linkedin-groups-analytics-big-data-mining-data-science.html
   6. https://www.kdnuggets.com/jobs/16/10-20-nvidia-deep-learning-library-software-development-engineer.html
   7. https://www.kdnuggets.com/news/subscribe.html
   8. https://twitter.com/kdnuggets
   9. https://www.facebook.com/kdnuggets
  10. https://www.linkedin.com/groups/54257/
  11. https://www.kdnuggets.com/contact.html
  12. https://www.kdnuggets.com/software/index.html
  13. https://www.kdnuggets.com/news/index.html
  14. https://www.kdnuggets.com/news/top-stories.html
  15. https://www.kdnuggets.com/opinions/index.html
  16. https://www.kdnuggets.com/tutorials/index.html
  17. https://www.kdnuggets.com/jobs/index.html
  18. https://www.kdnuggets.com/companies/index.html
  19. https://www.kdnuggets.com/courses/index.html
  20. https://www.kdnuggets.com/datasets/index.html
  21. https://www.kdnuggets.com/education/index.html
  22. https://www.kdnuggets.com/education/analytics-data-mining-certificates.html
  23. https://www.kdnuggets.com/meetings/index.html
  24. https://www.kdnuggets.com/webcasts/index.html
  25. https://www.kdnuggets.com/
  26. https://www.kdnuggets.com/news/index.html
  27. https://www.kdnuggets.com/2016/index.html
  28. https://www.kdnuggets.com/2016/10/index.html
  29. https://www.kdnuggets.com/2016/10/tutorials.html
  30. https://www.kdnuggets.com/2016/n38.html
  31. https://www.kdnuggets.com/2016/10/top-linkedin-groups-analytics-big-data-mining-data-science.html
  32. https://www.kdnuggets.com/jobs/16/10-20-nvidia-deep-learning-library-software-development-engineer.html
  33. https://www.kdnuggets.com/tag/data-science
  34. https://www.kdnuggets.com/tag/jupyter
  35. https://www.kdnuggets.com/tag/python
  36. https://www.kdnuggets.com/tag/svds
  37. http://www.jupyter.org/
  38. http://www.svds.com/wp-content/uploads/2015/09/not-great.png
  39. http://www.svds.com/wp-content/uploads/2015/09/better-fit.png
  40. https://github.com/jbwhit/oscon-2015/commit/6750b962606db27f69162b802b5de4f84ac916d5
  41. http://www.svds.com/contact/
  42. http://shop.oreilly.com/product/0636920044260.do
  43. https://www.linkedin.com/in/jonathanbwhitmore/
  44. https://www.svds.com/tbt-jupyter-notebook-best-practices-data-science/?utm_source=kdnuggets&utm_medium=referral
  45. https://www.kdnuggets.com/2016/07/statistical-data-analysis-python.html
  46. https://www.kdnuggets.com/2016/05/ibm-jupyter-spark-mesos-docker.html
  47. https://www.kdnuggets.com/2016/07/getting-started-data-science-python.html
  48. https://www.kdnuggets.com/2016/10/top-linkedin-groups-analytics-big-data-mining-data-science.html
  49. https://www.kdnuggets.com/jobs/16/10-20-nvidia-deep-learning-library-software-development-engineer.html
  50. https://www.kdnuggets.com/2019/03/another-10-free-must-read-books-for-machine-learning-and-data-science.html
  51. https://www.kdnuggets.com/2018/05/simplilearn-9-must-have-skills-data-scientist.html
  52. https://www.kdnuggets.com/2019/03/typical-data-scientist-2019.html
  53. https://www.kdnuggets.com/2019/03/pareto-principle-data-scientists.html
  54. https://www.kdnuggets.com/2019/03/data-science-job-applications.html
  55. https://www.kdnuggets.com/2019/03/women-ai-big-data-science-machine-learning.html
  56. https://www.kdnuggets.com/2019/03/favorite-ml-ai-breakthroughs.html
  57. https://www.kdnuggets.com/2019/03/artificial-neural-networks-optimization-genetic-algorithm-python.html
  58. https://www.kdnuggets.com/2019/03/typical-data-scientist-2019.html
  59. https://www.kdnuggets.com/2019/03/simplilearn-8-reasons-microsoft-azure-certification.html
  60. https://www.kdnuggets.com/2019/03/pareto-principle-data-scientists.html
  61. https://www.kdnuggets.com/2019/03/r-vs-python-data-visualization.html
  62. https://www.kdnuggets.com/2019/03/work-data-science-ai-big-data.html
  63. https://www.kdnuggets.com/2019/03/deep-learning-toolset-overview.html
  64. https://www.kdnuggets.com/news/index.html
  65. https://www.kdnuggets.com/2019/04/datax-download-guide-ai-marketing.html
  66. https://www.kdnuggets.com/2019/04/strata-kdnuggets-offer-save-london.html
  67. https://www.kdnuggets.com/2019/04/sisense-deep-neural-nets-big-data-analytics.html
  68. https://www.kdnuggets.com/2019/04/building-recommender-system.html
  69. https://www.kdnuggets.com/2019/04/predict-age-gender-using-convolutional-neural-network-opencv.html
  70. https://www.kdnuggets.com/2019/04/top-tweets-mar27-apr02.html
  71. https://www.kdnuggets.com/
  72. https://www.kdnuggets.com/news/index.html
  73. https://www.kdnuggets.com/2016/index.html
  74. https://www.kdnuggets.com/2016/10/index.html
  75. https://www.kdnuggets.com/2016/10/tutorials.html
  76. https://www.kdnuggets.com/2016/n38.html
  77. https://www.kdnuggets.com/about/index.html
  78. https://www.kdnuggets.com/news/privacy-policy.html
  79. https://www.kdnuggets.com/terms-of-service.html
  80. https://www.kdnuggets.com/news/subscribe.html
  81. https://twitter.com/kdnuggets
  82. https://facebook.com/kdnuggets
  83. https://www.linkedin.com/groups/54257
  84. https://www.kdnuggets.com/news/subscribe.html

   hidden links:
  86. https://www.kdnuggets.com/
  87. https://www.kdnuggets.com/
