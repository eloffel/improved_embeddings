                                   siid113x-999

   siid113x-999 is a gold standard resource for the evaluation of models
   that learn the meaning of words and concepts.

   siid113x-999 provides a way of measuring how well models capture
   similarity, rather than relatedness or association. the scores in
   siid113x-999 therefore differ from other well-known evaluation datasets
   such as wordsim-353 (finkelstein et al. 2002). the following two
   example pairs illustrate the difference - note that clothes are not
   similar to closets (different materials, function etc.), even though
   they are very much related:

   pair             siid113x-999 rating wordsim-353 rating
   coast - shore    9.00              9.10
   clothes - closet 1.96              8.00

   our experiments indicate that siid113x-999 is challenging for
   computational models to replicate because, in order to perform well,
   they must learn to capture similarity independently of
   relatedness/association. this is hard because most language-based
   representation-learning models infer connections between concepts from
   their co-occurrence in corpora, and co-occurrence primarity reflects
   relatedness not similarity.

   in addition to general-purpose evaluations of semantic models,
   siid113x-999 is structured to facilitate focused evaluations based around
   the following conceptual distinctions:
     * concreteness: each concept in each siid113x-999 pair is rated for its
       conceptual concreteness. because abstract concepts are more common
       than concrete concepts in most everyday language ([1] and can
       behave quite differently in semantic models ), siid113x-999 contains
       a balanced selection of concrete ( dog, cup ) and abstract ( envy,
       deny ) concepts.
     * part-of-speech: siid113x-999 comprises 666 noun-noun pairs, 222
       verb-verb pairs and 111 adjective-adjective pairs.
     * free-association: siid113x-999 includes an independent empirical
       measure of the strength of association (or relatedness) between
       each of its pairs, taken from the [2]university of south florida
       free association norms.

download the dataset

   [3]download siid113x-999 by clicking here. all design details are
   outlined in the following paper (click to access). please cite it if
   you use siid113x-999:

   [4]siid113x-999: evaluating semantic models with (genuine) similarity
   estimation. 2014. felix hill, roi reichart and anna korhonen.
   computational linguistics. 2015

   contact felix hill (felix.hill@cl.cam.ac.uk) if your questions are not
   addressed in the paper.

new: siid113x in other languages

   siid113x-999 is now in german, italian and russian thanks to ira leviant
   and roi reichart. see [5]this page for more information.

state-of-the-art

   the well-known skipgram (id97) model trained on 1bn words of
   wikipedia text achieves a spearman correlation of 0.37 with siid113x-999
   [1].

   the best performance of a model trained on running monolingual text is
   a spearman correlation of 0.56 [2].

   a id4 model (en->fr) trained on a relatively
   small bilingual corpus achieves a spearman correlation of 0.52 [3].

   a model that exploits curated knowledge-bases (id138, framenet etc)
   can reach a spearman correlation of 0.58 [4].

   new: a model that uses rich paraphrase data for training can reach a
   spearman correlation of 0.68 [5].

   newer: a hybrid model trained on features from various id27s
   and two lexical databases achieves a spearman correlation of 0.76 [6].

   newerer: counterfitting works well [7].

   the average pairwise spearman correlation between two human raters is
   0.67. however, it may be fairer to compare the performance of models
   with the average correlation of a human rater with the average of all
   the other raters. this number is 0.78.

   please email felix.hill@cl.cam.ac.uk if you know of better performing
   models.

   [1] [6]efficient estimation of word representations in vector space.
   tomas mikolov, kai chen, greg corrado and jeffrey dean. arxiv preprint
   arxiv:1301.3781. 2013.

   [2] [7]symmetric pattern based id27s for improved word
   similarity prediction. roy schwarz, roi reichart and ari rappoport,
   conll 2015.

   [3] [8]embedding word similarity with id4. felix
   hill, kyunghyun cho, sebastien jean, coline devin and yoshua bengio.
   iclr. 2015.

   [4] [9]non-distributional word vector representations. manaal faruqui
   and chris dyer. acl. 2015.

   [5] [10]from paraphrase database to compositional paraphrase model and
   back john weiting, mohit bansal, kevin gimpel, karen livescu and dan
   roth. tacl 2015.

   [6] [11]measuring semantic similarity of words using concept networks.
   gabor recski and eszter iklodi and katalin pajkossy and andras kornai.
   to appear in repl4nlp 2016.

   [7] [12]measuring semantic similarity of words using concept networks.
   nikola mrksic et al. counter-fitting word vectors to linguistic
   constraints. emnlp 2016.

annotator instructions

   siid113x-999 was produced by mining the opinions of 500 annotators via
   amazon mechanical turk. see below for annotator instructions.
   [screenshot1.png]

references

   1. http://www.cl.cam.ac.uk/~fh295/emnlp_final.pdf
   2. http://w3.usf.edu/freeassociation/
   3. https://fh295.github.io//siid113x-999.zip
   4. http://arxiv.org/abs/1408.3456v1
   5. http://www.leviants.com/ira.leviant/multilingualvsmdata.html
   6. http://arxiv.org/abs/1301.3781
   7. http://www.cs.huji.ac.il/~roys02/papers/sp_embeddings/sp_embeddings.html
   8. http://arxiv.org/abs/1412.6448
   9. http://www.aclweb.org/anthology/p15-2076
  10. http://ttic.uchicago.edu/~wieting/wieting2015tacl.pdf
  11. http://hlt.bme.hu/en/publ/recski_2016c
  12. https://arxiv.org/abs/1603.00892
