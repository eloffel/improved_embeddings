    #[1]terra incognita    feed [2]terra incognita    comments feed [3]terra
   incognita    machine learning :: text feature extraction (tf-idf)     part
   i comments feed [4]the interactive robotic painting machine !
   [5]machine learning :: text feature extraction (tf-idf)     part ii
   [6]alternate

   [7]skip to content

   [8]terra incognita
   by christian s. perone

   (button) menu
     * [9]home
     * [10]twitter
     * [11]github
     * [12]profile

   search for: ____________________ search

   [ins: :ins]

   [13]machine learning/[14]python

machine learning :: text feature extraction (tf-idf)     part i

   posted on [15]18/09/2011 by [16]christian s. perone / [17]109 comments
   reading time: 6 minutes

short introduction to vector space model (vsm)

   in information retrieval or id111, the [18]term frequency    
   inverse document frequency (also called tf-idf), is a well know method
   to evaluate how important is a word in a document. tf-idf are is a very
   interesting way to convert the textual representation of information
   into a [19]vector space model (vsm), or into sparse features, we   ll
   discuss more about it later, but first, let   s try to understand what is
   tf-idf and the vsm.

   vsm has a very confusing past, see for example the paper [20]the most
   influential paper gerard salton never wrote that explains the history
   behind the ghost cited paper which in fact never existed; in sum, vsm
   is an algebraic model representing textual information as a vector, the
   components of this vector could represent the importance of a term
   (tf   idf) or even the absence or presence ([21]bag of words) of it in a
   document; it is important to note that the classical vsm proposed by
   salton incorporates local and global parameters/information (in a sense
   that it uses both the isolated term being analyzed as well the entire
   collection of documents). vsm, interpreted in a lato sensu, is a space
   where text is represented as a vector of numbers instead of its
   original string textual representation; the vsm represents the features
   extracted from the document.

   let   s try to mathematically define the vsm and tf-idf together with
   concrete examples, for the concrete examples i   ll be using python (as
   well the amazing [22]scikits.learn python module).

going to the vector space

   the first step in modeling the document into a vector space is to
   create a dictionary of terms present in documents. to do that, you can
   simple select all terms from the document and convert it to a dimension
   in the vector space, but we know that there are some kind of words
   (stop words) that are present in almost all documents, and what we   re
   doing is extracting important features from documents, features do
   identify them among other similar documents, so using terms like    the,
   is, at, on   , etc.. isn   t going to help us, so in the information
   extraction, we   ll just ignore them.

   let   s take the documents below to define our (stupid) document space:
train document set:

d1: the sky is blue.
d2: the sun is bright.

test document set:

d3: the sun in the sky is bright.
d4: we can see the shining sun, the bright sun.

   now, what we have to do is to create a index vocabulary (dictionary) of
   the words of the train document set, using the documents d1 and d2 from
   the document set, we   ll have the following index vocabulary denoted as
   \mathrm{e}(t) where the t is the term:
   \mathrm{e}(t) = \begin{cases} 1, & \mbox{if } t\mbox{ is ``blue''} \\
   2, & \mbox{if } t\mbox{ is ``sun''} \\ 3, & \mbox{if } t\mbox{ is
   ``bright''} \\ 4, & \mbox{if } t\mbox{ is ``sky''} \\ \end{cases}


   note that the terms like    is    and    the    were ignored as cited before.
   now that we have an index vocabulary, we can convert the test document
   set into a vector space where each term of the vector is indexed as our
   index vocabulary, so the first term of the vector represents the    blue   
   term of our vocabulary, the second represents    sun    and so on. now,
   we   re going to use the term-frequency to represent each term in our
   vector space; the term-frequency is nothing more than a measure of how
   many times the terms present in our vocabulary \mathrm{e}(t) are
   present in the documents d3 or d4 , we define the term-frequency as a
   couting function:
   \mathrm{tf}(t,d) = \sum\limits_{x\in d} \mathrm{fr}(x, t)

   where the \mathrm{fr}(x, t) is a simple function defined as:
   \mathrm{fr}(x,t) = \begin{cases} 1, & \mbox{if } x = t \\ 0, &
   \mbox{otherwise} \\ \end{cases}

   so, what the tf(t,d) returns is how many times is the term t is present
   in the document d . an example of this, could be tf(``sun'', d4) = 2
   since we have only two occurrences of the term    sun    in the document d4
   . now you understood how the term-frequency works, we can go on into
   the creation of the document vector, which is represented by:
   \displaystyle \vec{v_{d_n}} =(\mathrm{tf}(t_1,d_n),
   \mathrm{tf}(t_2,d_n), \mathrm{tf}(t_3,d_n), \ldots,
   \mathrm{tf}(t_n,d_n))

   each dimension of the document vector is represented by the term of the
   vocabulary, for example, the \mathrm{tf}(t_1,d_2) represents the
   frequency-term of the term 1 or t_1 (which is our    blue    term of the
   vocabulary) in the document d_2 .

   let   s now show a concrete example of how the documents d_3 and d_4 are
   represented as vectors:
   \vec{v_{d_3}} = (\mathrm{tf}(t_1,d_3), \mathrm{tf}(t_2,d_3),
   \mathrm{tf}(t_3,d_3), \ldots, \mathrm{tf}(t_n,d_3)) \\ \vec{v_{d_4}} =
   (\mathrm{tf}(t_1,d_4), \mathrm{tf}(t_2,d_4), \mathrm{tf}(t_3,d_4),
   \ldots, \mathrm{tf}(t_n,d_4))

   which evaluates to:
   \vec{v_{d_3}} = (0, 1, 1, 1) \\ \vec{v_{d_4}} = (0, 2, 1, 0)

   as you can see, since the documents d_3 and d_4 are:
d3: the sun in the sky is bright.
d4: we can see the shining sun, the bright sun.

   the resulting vector \vec{v_{d_3}} shows that we have, in order, 0
   occurrences of the term    blue   , 1 occurrence of the term    sun   , and so
   on. in the \vec{v_{d_3}} , we have 0 occurences of the term    blue   , 2
   occurrences of the term    sun   , etc.

   but wait, since we have a collection of documents, now represented by
   vectors, we can represent them as a matrix with |d| \times f shape,
   where |d| is the cardinality of the document space, or how many
   documents we have and the f is the number of features, in our case
   represented by the vocabulary size. an example of the matrix
   representation of the vectors described above is:
   m_{|d| \times f} = \begin{bmatrix} 0 & 1 & 1 & 1\\ 0 & 2 & 1 & 0
   \end{bmatrix}

   as you may have noted, these matrices representing the term frequencies
   tend to be very [23]sparse (with majority of terms zeroed), and that   s
   why you   ll see a common representation of these matrix as sparse
   matrices.

python practice

   environment used: [24]python v.2.7.2, [25]numpy 1.6.1, [26]scipy
   v.0.9.0, [27]sklearn (scikits.learn) v.0.9.

   since we know the  theory behind the term frequency and the vector
   space conversion, let   s show how easy is to do that using the amazing
   [28]scikit.learn python module.

   scikit.learn comes with [29]lots of examples as well real-life
   interesting [30]datasets you can use and also some[31] helper functions
   to download 18k newsgroups posts for instance.

   since we already defined our small train/test dataset before, let   s use
   them to define the dataset in a way that scikit.learn can use:
train_set = ("the sky is blue.", "the sun is bright.")
test_set = ("the sun in the sky is bright.",
    "we can see the shining sun, the bright sun.")

   in scikit.learn, what we have presented as the term-frequency, is
   called countvectorizer, so we need to import it and create a news
   instance:
from sklearn.feature_extraction.text import countvectorizer
vectorizer = countvectorizer()

   the countvectorizer already uses as default    analyzer    called
   wordngramanalyzer, which is responsible to convert the text to
   lowercase, accents removal, token extraction, filter stop words, etc   
   you can see more information by printing the class information:
print vectorizer

countvectorizer(analyzer__min_n=1,
analyzer__stop_words=set(['all', 'six', 'less', 'being', 'indeed', 'over', 'move
', 'anyway', 'four', 'not', 'own', 'through', 'yourselves', (...)

   let   s create now the vocabulary index:
vectorizer.fit_transform(train_set)
print vectorizer.vocabulary
{'blue': 0, 'sun': 1, 'bright': 2, 'sky': 3}

   see that the vocabulary created is the same as e(t) (except because it
   is zero-indexed).

   let   s use the same vectorizer now to create the sparse matrix of our
   test_set documents:
smatrix = vectorizer.transform(test_set)

print smatrix

(0, 1)        1
(0, 2)        1
(0, 3)        1
(1, 1)        2
(1, 2)        1

   note that the sparse matrix created called smatrix is a [32]scipy
   sparse matrix with elements stored in a [33]coordinate format. but you
   can convert it into a dense format:
smatrix.todense()

matrix([[0, 1, 1, 1],
........[0, 2, 1, 0]], dtype=int64)

   note that the sparse matrix created is the same matrix m_{|d| \times f}
   we cited earlier in this post, which represents the two document
   vectors \vec{v_{d_3}} and \vec{v_{d_4}} .

   we   ll see in the next post how we define the idf (inverse document
   frequency) instead of the simple term-frequency, as well how
   logarithmic scale is used to adjust the measurement of term frequencies
   according to its importance, and how we can use it to classify
   documents using some of the well-know machine learning approaches.

   i hope you liked this post, and if you really liked, leave a comment so
   i   ll able to know if there are enough people interested in these series
   of posts in machine learning topics.

   as promised, [34]here is the second part of this tutorial series.

references

   [35]the classic vector space model

   [36]the most influential paper gerard salton never wrote

   [37]wikipedia: tf-idf

   [38]wikipedia: vector space model

   [39]scikits.learn examples

updates

   21 sep 11     fixed some typos and the vector notation
   22 sep 11     fixed import of sklearn according to the new 0.9 release
   and added the environment section
   02 oct 11     fixed latex math typos
   18 oct 11     added link to the second part of the tutorial series
   04 mar 11     fixed formatting issues
   [40]feature extraction, [41]machine learning, [42]id111,
   [43]tf-idf, [44]vector space model, [45]vsm
   christian s. perone
   [46]view all posts by christian s. perone    

post navigation

   older post
   [47]the interactive robotic painting machine !
   newer post
   [48]machine learning :: text feature extraction (tf-idf)     part ii

109 comments

    1. [ins: :ins]
    2.
   justrreadrrr says:
       [49]18/09/2011 at 16:19
       latex path not specified.
       all over the text
       [50]reply
         1.
        [51]christian s. perone says:
            [52]18/09/2011 at 16:22
            i   m using the latex from wordpress.com service, for me it is
            working, maybe they service is down for a while =( thanks for
            reporting.
            [53]reply
    3.
    4.
   [54]patrick durusau says:
       [55]18/09/2011 at 16:49
       the link to the the most influential paper gerard salton never
       wrote fails. try the cached copy at citeseer: [56]the most
       influential paper gerard salton never wrote.
       very enjoyable post! i have pointed to it from my blog:
       [57]http://tm.durusau.net/?p=15199
       [58]reply
         1.
        [59]christian s. perone says:
            [60]18/09/2011 at 16:56
            thank you patrick, i   m glad you liked it. i updated the link
            with the citeseer copy.
            [61]reply
    5.
    6.
   [62]helio perroni filho says:
       [63]18/09/2011 at 22:31
       very interesting read. keep the good work.
       [64]reply
    7.
    8.
   [65]anand jeyahar says:
       [66]19/09/2011 at 06:11
       thanks, the mix of actual examples with theory is very handy to see
       the theory in action and helps retain the theory better. though in
       this particular post, i was a little disappointed as i felt it
       ended too soon. i would like more longer articles. but i guess
       longer articles turn off majority of the readers.
       [67]reply
    9.
   10.
   [68]dvdgrs says:
       [69]19/09/2011 at 12:06
       very interesting blogpost, i   m sure up for more on the topic :)!
       i recently had to handle vsm & tf-idf in python too, in a
       text-processing task of returning most similar strings of an
       input-string. i haven   t looked at scikits.learn, but it sure looks
       useful and straightforward.
       i use gensim (vsm for human beings:
       [70]http://radimrehurek.com/gensim/) together with nltk for
       preparing the data (aka word tokenizing, lowering words, and
       removing stopwords). i can highly recommend both libraries!
       for some more (slightly out of date) details of my approach, see:
       [71]http://graus.nu/blog/simple-keyword-extraction-in-python/
       thanks for the post, and looking forward to part ii :).
       [72]reply
         1.
        rahul says:
            [73]11/09/2017 at 17:15
            informative blog post, helped me a lot in understanding the
            concept. please, keep the series going.
            [74]reply
   11.
   12.
   trey says:
       [75]19/09/2011 at 18:17
       thanks for posting this, would love to see more.
       [76]reply
   13.
   14.
   johan says:
       [77]20/09/2011 at 04:57
       very well written and interesting!
       [78]reply
   15.
   16.
   led says:
       [79]21/09/2011 at 11:22
       thanks for this, most interesting. i look forward to reading your
       future posts on the subject.
       [80]reply
   17.
   18. pingback: [81]machine learning :: text feature extraction (tf-idf)
           part ii | pyevolve
   19.
   20.
   niu says:
       [82]24/11/2011 at 12:30
       it is very useful and easy for start and is well organized. thanks.
       [83]reply
         1.
        [84]christian s. perone says:
            [85]24/11/2011 at 13:31
            thanks, i   m glad you liked it.
            [86]reply
   21.
   22.
   baali says:
       [87]21/12/2011 at 07:12
       thanks a lot for this writeup. at times its really good to know
       what is cooking backstage behind all fancy and magical functions.
       [88]reply
   23.
   24.
   geetha r says:
       [89]04/01/2012 at 04:34
       thank you! it is very useful for me to learn about the vector space
       model. but i am having some doubts, please make me clear.
       1. in my work i have added terms,inverse document frequency. i want
       to achieve more accuracy. so i want to add some more, please
       suggest me   
       [90]reply
   25.
   26.
   [91]alex says:
       [92]10/01/2012 at 15:52
       great post, i will certainly try this out.
       i would be interested to see a similar detailed break down on using
       something like id166light in conjunction with these techniques.
       thanks!
       [93]reply
   27.
   28.
   [94]jaques grobler says:
       [95]26/03/2012 at 10:16
       hey again     my outputs are slighlty different to yours.. think
       there may have been changes to the module on scikit-learn.
       will let you know what i find out.
       take care
       [96]reply
   29.
   30.
   [97]jaques grobler says:
       [98]27/03/2012 at 06:54
       hello there,
       so basically the class feature_selection.text.vectorizer in sklearn
       is now deprecated and replaced by
       feature_selection.text.tfidfvectorizer.
       the whole module has been completely re-factored    
       here   s the change-log from the scikit-learn website:
       [99]http://scikit-learn.org/dev/whats_new.html
       see under    api changes summary    for what   s changed
       just thought i   d give you a headsup about this.
       enjoyed your post regardless!
       take care
       [100]reply
         1.
        [101]christian s. perone says:
            [102]27/03/2012 at 10:11
            hello jaques, great thanks for the feedback !
            [103]reply
   31.
   32.
   anita mazur says:
       [104]20/04/2012 at 06:36
       thank you for your post. i am currently working on a way how to
       index documents, but with vocabulary terms taken from a thesaurus
       in skos format.
       your posts are interesting and very helpful to me.
       [105]reply
         1.
        [106]christian s. perone says:
            [107]20/04/2012 at 15:06
            thanks for the feedback anita, i   m glad you liked it.
            [108]reply
   33.
   34.
   zach says:
       [109]06/06/2012 at 16:24
       hey thanks for the very insightful post! i had no idea modules
       existed in python that could do that for you ( i calculated it the
       hard way :/)
       just curious did you happen to know about using tf-idf weighting as
       a feature selection or text categorization method. i   ve been
       looking at many papers (most from china for some reason) but am
       finding numerous ways of approaching this question.
       if there   s any advice or direction to steer me towards as far as
       additional resources, that would be greatly appreciated.
       [110]reply
   35.
   36.
   andres soto says:
       [111]03/08/2012 at 22:01
       hi
       i am using python-2.7.3, numpy-1.6.2-win32-superpack-python2.7,
       scipy-0.11.0rc1-win32-superpack-python2.7,
       scikit-learn-0.11.win32-py2.7
       i tried to repeat your steps but i couldn  t print the
       vectorizer.vocabulary (see below).
       any suggestions?
       regards
       andres soto
       >>> train_set = (   the sky is blue.   ,    the sun is bright.   )
       >>> test_set = (   the sun in the sky is bright.   ,
          we can see the shining sun, the bright sun.   )
       >>> from sklearn.feature_extraction.text import countvectorizer
       >>> vectorizer = countvectorizer()
       >>> print vectorizer
       countvectorizer(analyzer=word, binary=false, charset=utf-8,
       charset_error=strict, dtype=, input=content,
       lowercase=true, max_df=1.0, max_features=none, max_n=1, min_n=1,
       preprocessor=none, stop_words=none, strip_accents=none,
       token_pattern=bww+b, tokenizer=none, vocabulary=none)
       >>> vectorizer.fit_transform(train_set)
       <2  6 sparse matrix of type '   
       with 8 stored elements in coordinate format>
       >>> print vectorizer.vocabulary
       traceback (most recent call last):
       file       , line 1, in
       print vectorizer.vocabulary
       attributeerror:    countvectorizer    object has no attribute
          vocabulary   
       >>>
       [112]reply
         1.
        koos vanderwilt says:
            [113]17/09/2016 at 09:36
            use underscore:
            print vectorizer.vocabulary_
            [114]reply
   37.
   38.
   [115]andres soto says:
       [116]06/08/2012 at 14:32
       i tried to fix the parameters of countvectorizer (analyzer =
       wordngramanalyzer, vocabulary = dict) but it didn   t work. therefore
       i decided to install sklearn 0.9 and it works, so we could say that
       everything is ok but i still would like to know what is wrong with
       version sklearn 0.11
       [117]reply
         1.
        [118]christian s. perone says:
            [119]06/08/2012 at 17:48
            hello andres, what i know is that this api has changed a lot
            on the sklearn 0.10/0.11, i heard some discussions about these
            changes but i can   t remember where right now.
            [120]reply
   39.
   40.
   gavin igor says:
       [121]16/08/2012 at 23:41
       thanks for the great overview, looks like the part 2 link is
       broken. it would be great if you could fix it. thank you.
       [122]reply
         1.
        [123]christian s. perone says:
            [124]17/08/2012 at 09:55
            thanks for the feedback gavin, the link is ok, it seems that
            the problem is sourceforge hosting that is throwing some
            errors.
            [125]reply
   41.
   42.
   gavin igor says:
       [126]24/08/2012 at 17:48
       i am using a mac and running 0.11 version but i got the following
       error i wonder how i change this according to the latest api
       >> train_set
       (   the sky is blue.   ,    the sun is bright.   )
       >>> vectorizer.fit_transform(train_set)
       <2  6 sparse matrix of type '   
       with 8 stored elements in coordinate format>
       >>> print vectorizer.vocabulary
       traceback (most recent call last):
       file       , line 1, in
       attributeerror:    countvectorizer    object has no attribute
          vocabulary   
       >>> vocabulary
       [127]reply
   43.
   44.
   [128]creativega says:
       [129]03/10/2012 at 05:18
       hello, mr. perone! thank you very much, i   m newbie in tf-idf and
       your posts have helped me a lot to understand it. greetings from
       japan^^
       [130]reply
         1.
        [131]christian s. perone says:
            [132]03/10/2012 at 16:21
            great thanks for the feedback, i   m very glad you liked and
            that the post helped you !
            [133]reply
   45.
   46.
   mohit says:
       [134]20/10/2012 at 08:18
       wonderful post    it helps me to understand vsm concept     
       [135]reply
   47.
   48.
   ryan says:
       [136]30/01/2013 at 04:08
       thanks for this awesome post! eminently readable introduction to
       the topic.
       [137]reply
   49.
   50.
   thomas says:
       [138]15/09/2013 at 07:42
       very well written. good example presented in a form that makes it
       easy to follow and understand. curious now to read more   
       thank you for sharing your knowledge
       thomas, germany
       [139]reply
         1.
        [140]christian s. perone says:
            [141]15/09/2013 at 12:47
            thanks thomas, i appreciate your feedback.
            [142]reply
   51.
   52.
   ua says:
       [143]17/09/2013 at 16:59
       hi. i am having trouble understanding how to compute tf-idf weights
       for a text file i have which contains 300k lines of text. each line
       is considered as a document. example excerpt from the text file:
       hacking hard
       jeetu smart editor
       shyamal vizualizr
       setting demo hacks
       vivek mans land
       social routing guys minute discussions learn photography properly
       naseer ahmed yahealer
       sridhar vibhash yahoo search mashup
       vaibhav chintan facebook friend folio
       vaibhav chintan facebook friend folio
       judgess comments
       slickrnot
       i   m pretty confused as to what i should do. thanks
       [144]reply
   53.
   54.
   [145]nishant says:
       [146]08/10/2013 at 02:49
       thanks. it was helpful. was looking for a good python vectorizer
       tutorial.
       [147]reply
   55.
   56.
   igor says:
       [148]09/10/2013 at 15:59
       that   s really interesting post, thanks a lot!
       [149]reply
         1.
        [150]christian s. perone says:
            [151]15/10/2013 at 12:56
            thanks for the feedback igor.
            [152]reply
   57.
   58.
   navdeep says:
       [153]08/11/2013 at 08:30
       really helpful post
       [154]reply
   59.
   60.
   haneef says:
       [155]06/12/2013 at 07:02
       really a very good effort in explaining in such a simple way.
       [156]reply
   61.
   62.
   williame rocha says:
       [157]20/01/2014 at 18:19
       it is a very good text.
       thanks for explanation.
       [158]reply
   63.
   64.
   need info says:
       [159]10/03/2014 at 15:25
       its giving idf vector as zero if test is same as train. why???
       [160]reply
   65.
   66.
   chamso says:
       [161]10/04/2014 at 18:24
       thank you very much i encourage you to continue this is very
       helpful post <3
       [162]reply
   67.
   68.
   matthieu says:
       [163]05/05/2014 at 11:49
       thanks
       a well written clear explanation
       definitely a reference when taking the first steps in id111.
       [164]reply
         1.
        [165]christian s. perone says:
            [166]06/05/2014 at 09:56
            thank you matthieu !
            [167]reply
   69.
   70.
   purna says:
       [168]27/06/2014 at 01:26
       good post with example
       [169]reply
   71.
   72.
   hannah says:
       [170]30/07/2014 at 11:21
       thank you very much. this post helped me alot. very well written
       and clear explanation.
       hannah
       [171]reply
   73.
   74.
   tim i. says:
       [172]02/09/2014 at 08:04
       awesome stuff. i really appreciate the simplicity and clarity of
       the information. a great, great help.
       [173]reply
         1.
        [174]christian s. perone says:
            [175]02/09/2014 at 10:29
            great thanks tim, i   m glad you liked it.
            [176]reply
   75.
   76.
   ganesh says:
       [177]13/11/2014 at 13:48
       thanks for the great post. you have explained it in simple words,
       so that a novice like me can understand. will move on to read the
       next part!
       [178]reply
   77.
   78.
   usher says:
       [179]25/03/2015 at 16:39
       solution to question of andres and gavin:
       >>> print vectorizer.vocabulary_
       (with underscore at the end in new versions of scikit!)
       will output:
       {u   blue   : 0, u   bright   : 1, u   sun   : 4, u   is   : 2, u   sky   : 3, u   the   :
       5}
       [180]reply
         1.
        [181]sultan says:
            [182]10/11/2015 at 23:55
            hey brother,
            do you know exactly what is the difference between
            (vectorizer.vocabulary_) and (vectorizer.get_feature_names()
            )?
            [183]reply
   79.
   80.
   sanja7s says:
       [184]01/06/2015 at 09:17
       thanks, a great one and useful!
       [185]reply
   81.
   82.
   jpf says:
       [186]24/06/2015 at 20:16
               you can simple select        ->    >>> you can simply select       
       [187]reply
   83.
   84.
   narendra rawat says:
       [188]04/09/2015 at 09:25
       very nice post!
       you made tf-idf look really interesting. i am looking forward to
       some more such posts.
       [189]reply
   85.
   86.
   [190]sandanaanil says:
       [191]19/09/2015 at 12:31
       hi christian,
       thank u for sharing. seeing more updates from you
       [192]reply
   87.
   88.
   anil says:
       [193]21/10/2015 at 07:08
       this is great!
       really helpful for starters like me!
       thanks & keep up the good work!
       cheers!
       [194]reply
   89.
   90.
   [195]sultan says:
       [196]10/11/2015 at 23:53
       could you tell me please what is the difference between feature
       names and vocabulary_ ?
       i printed them both after vectorizing,, they seem having different
       words??
       also, i need to print out the most informative words in each class,
       could you suggest me a way please?
       thanks
       [197]reply
   91.
   92.
   sambit says:
       [198]23/11/2015 at 18:00
       thank you. this was a very informative post.
       [199]reply
   93.
   94.
   farhan khan says:
       [200]25/12/2015 at 10:28
       nice one   .helped a lot   !!
       [201]reply
   95.
   96.
   shashi says:
       [202]30/12/2015 at 11:10
       thanks   very nicely explained. i feel i could understand the concept
       and now i will experiment. it will be very helpful in my work
       [203]reply
   97.
   98. pingback: [204]an attempt at quantifying changes to genre medium
   99.
   100. pingback: [205]inverse document frequency issue: unexpected
       results   
   101.
   102.
   pinki talukdar says:
       [206]04/03/2016 at 22:46
       thank u for u r post..it is very helpful.if possible can you tell
       in matlab how it will work
       [207]reply
   103.
   104.
   eduardo says:
       [208]01/05/2016 at 20:25
       great and simple. thanks,very helpful!
       [209]reply
   105.
   106.
   hazem says:
       [210]27/07/2016 at 08:37
       thanks .. it was very inspiring tutorial for me
       [211]reply
   107.
   108.
   swat says:
       [212]11/10/2016 at 23:57
       well written blog..i really loved it..:) thank you..
       [213]reply
   109.
   110.
   reza says:
       [214]07/11/2016 at 20:36
       hi, you have a nice blog.
       you mentioned by id111, stop words like    the, is, at, on   ,
       etc.. isn   t going to help us   . this is partly true, for example in
       case of analyzing webpages, you want to ignore the advertisements
       on a webpage, one good thing is to ignore the those sentences that
       do no have stop words. compared to normal sentences which do have
       these words.
       [215]reply
   111.
   112.
   devang says:
       [216]11/11/2016 at 04:53
       very helpful. like your writing style.
       [217]reply
   113.
   114.
   pan says:
       [218]21/11/2016 at 17:54
       i tried out this, did not quite get the expected result:
       please see below:
       train_set = (   the sky is blue.   ,    the sun is bright.   )
       test_set = (   the sun in the sky is bright.   ,    we can see the
       shining sun, the bright sun.   )
       from sklearn.feature_extraction.text import countvectorizer
       vectorizer = countvectorizer()
       stopwords = nltk.corpus.stopwords.words(   english   )
       vectorizer.stop_words = stopwords
       print vectorizer
       vectorizer.fit_transform(train_set)
       print vectorizer.vocabulary
       and i get    none   
       [219]reply
         1.
        [220]christian hubbs says:
            [221]01/01/2017 at 11:24
            instead, try:
            print(vectorizer.vocabulary_)
            [222]reply
              1.
             anonymous says:
                 [223]06/02/2017 at 13:40
                 great, it works. thanks!
                 [224]reply
   115.
   116.
   ankur says:
       [225]02/12/2016 at 22:09
       very helpful post!
       [226]reply
   117.
   118.
   kathereine says:
       [227]07/12/2016 at 01:58
       great post! thanks.
       [228]reply
   119.
   120.
   priya says:
       [229]15/12/2016 at 04:23
       great tutorial!! thankz
       [230]reply
   121.
   122.
   alex says:
       [231]04/01/2017 at 14:32
       really nice tutorial. very helpful to get some context additional
       to the official skikit-learn tutorial and user guide. thanks.
       [232]reply
   123.
   124.
   yizhen says:
       [233]21/01/2017 at 23:45
       it cool work
       [234]reply
   125.
   126.
   kiran reddy says:
       [235]13/02/2017 at 07:58
       thank you for helping in understanding.
       [236]reply
   127.
   128.
   michael says:
       [237]06/03/2017 at 14:16
       thank you so much, christian! this post helped me a lot!
       [238]reply
   129.
   130.
   isco sarita says:
       [239]19/03/2017 at 16:17
       i need a java program for indexing a set of files by computing tf
       and idf please help me
       [240]reply
   131.
   132.
   krishna priya says:
       [241]22/03/2017 at 07:17
       thanks a lot      ..post really helped me a lot!!!!!!!!!
       [242]reply
   133.
   134.
   kalai says:
       [243]19/04/2017 at 04:24
       the article is helpful. thanks.
       [244]reply
   135.
   136.
   rens says:
       [245]24/04/2017 at 07:08
       as a phd candidate in sociology who is diving into the world of
       machine learning, this post was also very helpful for me. thanks!
       [246]reply
   137.
   138.
   akhil says:
       [247]03/05/2017 at 19:48
       this is very helpful     it gave me thorough understanding of the
       concepts    
       [248]reply
   139.
   140.
   c17 says:
       [249]17/05/2017 at 13:07
       great article!! read much but this belongs definitely to the    good
       stuff   !!!
       [250]reply
   141.
   142.
   rajat says:
       [251]12/06/2017 at 14:01
       it was cool man
       [252]reply
   143.
   144.
   nen says:
       [253]18/06/2017 at 22:02
       hello there!
       i have a question regarding natural language processing. there are
       two terms in this field    feature extraction    and    feature
       selection   . i don   t exactly understand the difference between them
       and whether we only use one of them or is it possible to use both
       for text classification?
       my second question is whether    tf    and    tfidf    are considered
       feature extraction methods in nlp?
       [254]reply
   145.
   146.
   [255]rosangela oliveira says:
       [256]06/07/2017 at 15:47
       typeerror: __init__() got an unexpected keyword argument
          analyzer__stop_words   
       [257]reply
         1.
        [258]rosangela oliveira says:
            [259]06/07/2017 at 15:48
            could you hel with this error?
            [260]reply
   147.
   148.
   pedram says:
       [261]19/07/2017 at 16:39
       it is an interesting article indeed. personally, i know everything
       that has been mentioned in this post and i did all of them before,
       but sometimes it is worth spending little time to review some stuff
       that you already know. keep up the good work!
       [262]reply
   149.
   150.
   afsan gujarati says:
       [263]19/10/2017 at 19:49
       really appreciate you taking the time to write this post.
       pretty detailed and well explained.
       appreciated.
       [264]reply
   151.
   152.
   itxel zavala says:
       [265]24/10/2017 at 19:33
       i tried with print(vectorizer.vocabulary_) and it   s works, but my
       output is:
       {   the   : 5,    sky   : 3,    is   : 2,    blue   : 0,    sun   : 4,    bright   : 1}
       do you know why doesn   t ignored    is    and    the    ?
       [266]reply
         1.
        ldag says:
            [267]17/11/2017 at 04:22
            i was also facing the same issue but got solution. you can
            initialize the vectorizer as follow:
            vectorizer = countvectorizer(stop_words=   english   )
            above will escape all english stop words.
            cheers..
            [268]reply
   153.
   154.
   ldag says:
       [269]17/11/2017 at 04:45
       nice work christian   
       [270]reply
   155.
   156.
   manoj says:
       [271]24/11/2017 at 18:03
       this is by far the best article on tf-idf and vector spaces. thank
       you for posting such a helpful article. please keep writing more
       articles on machine learning basics and concepts. thank you!
       [272]reply
   157.
   158.
   ali mohammad says:
       [273]01/12/2017 at 06:22
       very nice explanation allah bless you
       [274]reply
   159.
   160.
   manoj says:
       [275]29/12/2017 at 04:33
       good tutorial. it explains things in a simple and clear way to new
       bees like me    thanks for sharing it   
       [276]reply
   161.
   162.
   ameera says:
       [277]12/02/2018 at 07:53
       thank you
       you made it so easy to understand!
       [278]reply
   163.
   164.
   anonymous says:
       [279]12/02/2018 at 10:46
       excellent article   very informative and way of explanation is very
       good.
       thank you so much!!!
       [280]reply
   165.
   166.
   bren says:
       [281]06/03/2018 at 03:37
       this post helped a lot   .waiting for next article   .
       [282]reply
   167.
   168.
   harish says:
       [283]03/04/2018 at 00:05
       print vectorizer.vocabulary_ (_) is missing.
       [284]reply
   169.
   170.
   harish says:
       [285]03/04/2018 at 00:16
       countvectorizer() method for stopword removal does not seem to be
       clear, please complete the function with correct syntax
       [286]reply
   171.
   172.
   aswitha visvesvaran says:
       [287]22/05/2018 at 12:29
       great post..very clean explanation of the concept. python codes are
       an added bonus. thank you     
       [288]reply
   173.
   174.
   [289]m  rcio jesus says:
       [290]05/06/2018 at 13:55
       thanks christian, very good. too bad it took me to start studying
       about this.
       [291]reply
   175.
   176.
   amanda says:
       [292]10/08/2018 at 11:05
       hi! i   m currently make a search engine for journals with tfidf
       method for my undergraduate. but my professor said that my method
       is too old. could you recommend some new method in this past 5
       years? or maybe method to optimize the tfidf? additional research
       paper about the method will be great. thankyou very much!
       [293]reply
   177.
   178.
   insect spring says:
       [294]03/10/2018 at 17:21
       very interesting and succinct read! i am ramping on to ml and it
       really helped. going to read your other posts too.
       [295]reply
   179.
   180.
   ana says:
       [296]10/02/2019 at 02:33
       this post is soo great keep the good work
       [297]reply
   181.

leave a comment [298]cancel reply

   your email address will not be published.

   comment
   _____________________________________________
   _____________________________________________
   _____________________________________________
   _____________________________________________
   _____________________________________________
   _____________________________________________
   _____________________________________________
   _____________________________________________

   name ______________________________

   email ______________________________

   website ______________________________

   post comment

   this site uses akismet to reduce spam. [299]learn how your comment data
   is processed.

author

   christian s. perone
   christian s. perone

                                 researcher
                          machine learning engineer
                            montreal, qc, canada
               [b68d3dd0b32cb9292e6fc40b3d812a66c596b2b1.png]
               [1bdd60f7a408916bd488c5bf064911bfc0fb2eca.png]

   [ins: :ins]

popular posts

     * [300]machine learning :: cosine similarity for vector space models
       (part iii)
     * machine learning :: text feature extraction (tf-idf)     part i
     * [301]google   s s2, geometry on the sphere, cells and hilbert curve
     * [302]deep learning     convolutional neural networks and feature
       extraction with python
     * [303]machine learning :: text feature extraction (tf-idf)     part ii
     * [304]a sane introduction to id113 (id113) and
       maximum a posteriori (map)
     * [305]simple and effective coin segmentation using python and opencv
     * [306]the effective receptive field on id98s
     * [307]real time drone object tracking using python and opencv
     * [308]pytorch 1.0 tracing jit and libtorch c++ api to integrate
       pytorch into nodejs

   [309]creative commons license
   this work is licensed under a [310]creative commons
   attribution-noncommercial 4.0 international license.

      2019 [311]terra incognita
   powered by [312]wordpress | theme: [313]graphy by themegraphy

references

   visible links
   1. http://blog.christianperone.com/feed/
   2. http://blog.christianperone.com/comments/feed/
   3. http://blog.christianperone.com/2011/09/machine-learning-text-feature-extraction-tf-idf-part-i/feed/
   4. http://blog.christianperone.com/2011/08/the-interactive-robotic-painting-machine/
   5. http://blog.christianperone.com/2011/10/machine-learning-text-feature-extraction-tf-idf-part-ii/
   6. http://blog.christianperone.com/wp-json/oembed/1.0/embed?url=http://blog.christianperone.com/2011/09/machine-learning-text-feature-extraction-tf-idf-part-i/
   7. http://blog.christianperone.com/2011/09/machine-learning-text-feature-extraction-tf-idf-part-i/#content
   8. http://blog.christianperone.com/
   9. http://blog.christianperone.com/
  10. https://twitter.com/tarantulae
  11. https://github.com/perone
  12. https://www.linkedin.com/in/cperone
  13. http://blog.christianperone.com/category/machine-learning/
  14. http://blog.christianperone.com/category/python/
  15. http://blog.christianperone.com/2011/09/machine-learning-text-feature-extraction-tf-idf-part-i/
  16. http://blog.christianperone.com/author/admin/
  17. http://blog.christianperone.com/2011/09/machine-learning-text-feature-extraction-tf-idf-part-i/#comments
  18. http://en.wikipedia.org/wiki/tf   idf
  19. http://en.wikipedia.org/wiki/vector_space_model
  20. http://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.184.910&rep=rep1&type=pdf
  21. http://en.wikipedia.org/wiki/bag_of_words_model
  22. http://scikit-learn.sourceforge.net/stable/
  23. http://en.wikipedia.org/wiki/sparse_matrix
  24. http://www.python.org/download/
  25. http://new.scipy.org/download.html
  26. http://new.scipy.org/download.html
  27. http://scikit-learn.sourceforge.net/stable/install.html
  28. http://scikit-learn.sourceforge.net/
  29. http://scikit-learn.sourceforge.net/stable/auto_examples/index.html
  30. http://scikit-learn.sourceforge.net/stable/modules/datasets.html#datasets-shipped-with-the-scikit-learn
  31. http://scikit-learn.sourceforge.net/stable/modules/datasets.html#the-20-newsgroups-text-dataset
  32. http://www.scipy.org/doc/api_docs/scipy.sparse.sparse.coo_matrix.html
  33. http://en.wikipedia.org/wiki/sparse_matrix#coordinate_list_.28coo.29
  34. http://blog.christianperone.com/?p=1747
  35. http://www.miislita.com/term-vector/term-vector-3.html
  36. http://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.184.910&rep=rep1&type=pdf
  37. http://en.wikipedia.org/wiki/tf   idf
  38. http://en.wikipedia.org/wiki/vector_space_model
  39. http://scikit-learn.sourceforge.net/stable/auto_examples/index.html
  40. http://blog.christianperone.com/tag/feature-extraction/
  41. http://blog.christianperone.com/tag/machine-learning-2/
  42. http://blog.christianperone.com/tag/text-mining/
  43. http://blog.christianperone.com/tag/tf-idf/
  44. http://blog.christianperone.com/tag/vector-space-model/
  45. http://blog.christianperone.com/tag/vsm/
  46. http://blog.christianperone.com/author/admin/
  47. http://blog.christianperone.com/2011/08/the-interactive-robotic-painting-machine/
  48. http://blog.christianperone.com/2011/10/machine-learning-text-feature-extraction-tf-idf-part-ii/
  49. http://blog.christianperone.com/2011/09/machine-learning-text-feature-extraction-tf-idf-part-i/#comment-968
  50. http://blog.christianperone.com/2011/09/machine-learning-text-feature-extraction-tf-idf-part-i/?replytocom=968#respond
  51. http://blog.christianperone.com/
  52. http://blog.christianperone.com/2011/09/machine-learning-text-feature-extraction-tf-idf-part-i/#comment-969
  53. http://blog.christianperone.com/2011/09/machine-learning-text-feature-extraction-tf-idf-part-i/?replytocom=969#respond
  54. http://tm.durusau.net/
  55. http://blog.christianperone.com/2011/09/machine-learning-text-feature-extraction-tf-idf-part-i/#comment-970
  56. http://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.184.910&rep=rep1&type=pdf
  57. http://tm.durusau.net/?p=15199
  58. http://blog.christianperone.com/2011/09/machine-learning-text-feature-extraction-tf-idf-part-i/?replytocom=970#respond
  59. http://blog.christianperone.com/
  60. http://blog.christianperone.com/2011/09/machine-learning-text-feature-extraction-tf-idf-part-i/#comment-971
  61. http://blog.christianperone.com/2011/09/machine-learning-text-feature-extraction-tf-idf-part-i/?replytocom=971#respond
  62. http://machineawakening.blogspot.com/
  63. http://blog.christianperone.com/2011/09/machine-learning-text-feature-extraction-tf-idf-part-i/#comment-972
  64. http://blog.christianperone.com/2011/09/machine-learning-text-feature-extraction-tf-idf-part-i/?replytocom=972#respond
  65. http://anandjeyahar.wordpress.com/
  66. http://blog.christianperone.com/2011/09/machine-learning-text-feature-extraction-tf-idf-part-i/#comment-973
  67. http://blog.christianperone.com/2011/09/machine-learning-text-feature-extraction-tf-idf-part-i/?replytocom=973#respond
  68. http://graus.nu/blog
  69. http://blog.christianperone.com/2011/09/machine-learning-text-feature-extraction-tf-idf-part-i/#comment-974
  70. http://radimrehurek.com/gensim/
  71. http://graus.nu/blog/simple-keyword-extraction-in-python/
  72. http://blog.christianperone.com/2011/09/machine-learning-text-feature-extraction-tf-idf-part-i/?replytocom=974#respond
  73. http://blog.christianperone.com/2011/09/machine-learning-text-feature-extraction-tf-idf-part-i/#comment-233939
  74. http://blog.christianperone.com/2011/09/machine-learning-text-feature-extraction-tf-idf-part-i/?replytocom=233939#respond
  75. http://blog.christianperone.com/2011/09/machine-learning-text-feature-extraction-tf-idf-part-i/#comment-975
  76. http://blog.christianperone.com/2011/09/machine-learning-text-feature-extraction-tf-idf-part-i/?replytocom=975#respond
  77. http://blog.christianperone.com/2011/09/machine-learning-text-feature-extraction-tf-idf-part-i/#comment-976
  78. http://blog.christianperone.com/2011/09/machine-learning-text-feature-extraction-tf-idf-part-i/?replytocom=976#respond
  79. http://blog.christianperone.com/2011/09/machine-learning-text-feature-extraction-tf-idf-part-i/#comment-977
  80. http://blog.christianperone.com/2011/09/machine-learning-text-feature-extraction-tf-idf-part-i/?replytocom=977#respond
  81. http://blog.christianperone.com/?p=1747
  82. http://blog.christianperone.com/2011/09/machine-learning-text-feature-extraction-tf-idf-part-i/#comment-979
  83. http://blog.christianperone.com/2011/09/machine-learning-text-feature-extraction-tf-idf-part-i/?replytocom=979#respond
  84. http://blog.christianperone.com/
  85. http://blog.christianperone.com/2011/09/machine-learning-text-feature-extraction-tf-idf-part-i/#comment-980
  86. http://blog.christianperone.com/2011/09/machine-learning-text-feature-extraction-tf-idf-part-i/?replytocom=980#respond
  87. http://blog.christianperone.com/2011/09/machine-learning-text-feature-extraction-tf-idf-part-i/#comment-981
  88. http://blog.christianperone.com/2011/09/machine-learning-text-feature-extraction-tf-idf-part-i/?replytocom=981#respond
  89. http://blog.christianperone.com/2011/09/machine-learning-text-feature-extraction-tf-idf-part-i/#comment-982
  90. http://blog.christianperone.com/2011/09/machine-learning-text-feature-extraction-tf-idf-part-i/?replytocom=982#respond
  91. http://codesauce.com/
  92. http://blog.christianperone.com/2011/09/machine-learning-text-feature-extraction-tf-idf-part-i/#comment-983
  93. http://blog.christianperone.com/2011/09/machine-learning-text-feature-extraction-tf-idf-part-i/?replytocom=983#respond
  94. https://github.com/jaquesgrobler/scikit-learn/wiki/jaques-grobler
  95. http://blog.christianperone.com/2011/09/machine-learning-text-feature-extraction-tf-idf-part-i/#comment-984
  96. http://blog.christianperone.com/2011/09/machine-learning-text-feature-extraction-tf-idf-part-i/?replytocom=984#respond
  97. https://github.com/jaquesgrobler/scikit-learn/wiki/jaques-grobler
  98. http://blog.christianperone.com/2011/09/machine-learning-text-feature-extraction-tf-idf-part-i/#comment-985
  99. http://scikit-learn.org/dev/whats_new.html
 100. http://blog.christianperone.com/2011/09/machine-learning-text-feature-extraction-tf-idf-part-i/?replytocom=985#respond
 101. http://blog.christianperone.com/
 102. http://blog.christianperone.com/2011/09/machine-learning-text-feature-extraction-tf-idf-part-i/#comment-986
 103. http://blog.christianperone.com/2011/09/machine-learning-text-feature-extraction-tf-idf-part-i/?replytocom=986#respond
 104. http://blog.christianperone.com/2011/09/machine-learning-text-feature-extraction-tf-idf-part-i/#comment-987
 105. http://blog.christianperone.com/2011/09/machine-learning-text-feature-extraction-tf-idf-part-i/?replytocom=987#respond
 106. http://blog.christianperone.com/
 107. http://blog.christianperone.com/2011/09/machine-learning-text-feature-extraction-tf-idf-part-i/#comment-988
 108. http://blog.christianperone.com/2011/09/machine-learning-text-feature-extraction-tf-idf-part-i/?replytocom=988#respond
 109. http://blog.christianperone.com/2011/09/machine-learning-text-feature-extraction-tf-idf-part-i/#comment-989
 110. http://blog.christianperone.com/2011/09/machine-learning-text-feature-extraction-tf-idf-part-i/?replytocom=989#respond
 111. http://blog.christianperone.com/2011/09/machine-learning-text-feature-extraction-tf-idf-part-i/#comment-990
 112. http://blog.christianperone.com/2011/09/machine-learning-text-feature-extraction-tf-idf-part-i/?replytocom=990#respond
 113. http://blog.christianperone.com/2011/09/machine-learning-text-feature-extraction-tf-idf-part-i/#comment-105187
 114. http://blog.christianperone.com/2011/09/machine-learning-text-feature-extraction-tf-idf-part-i/?replytocom=105187#respond
 115. http://newexperiments/
 116. http://blog.christianperone.com/2011/09/machine-learning-text-feature-extraction-tf-idf-part-i/#comment-991
 117. http://blog.christianperone.com/2011/09/machine-learning-text-feature-extraction-tf-idf-part-i/?replytocom=991#respond
 118. http://blog.christianperone.com/
 119. http://blog.christianperone.com/2011/09/machine-learning-text-feature-extraction-tf-idf-part-i/#comment-992
 120. http://blog.christianperone.com/2011/09/machine-learning-text-feature-extraction-tf-idf-part-i/?replytocom=992#respond
 121. http://blog.christianperone.com/2011/09/machine-learning-text-feature-extraction-tf-idf-part-i/#comment-993
 122. http://blog.christianperone.com/2011/09/machine-learning-text-feature-extraction-tf-idf-part-i/?replytocom=993#respond
 123. http://blog.christianperone.com/
 124. http://blog.christianperone.com/2011/09/machine-learning-text-feature-extraction-tf-idf-part-i/#comment-994
 125. http://blog.christianperone.com/2011/09/machine-learning-text-feature-extraction-tf-idf-part-i/?replytocom=994#respond
 126. http://blog.christianperone.com/2011/09/machine-learning-text-feature-extraction-tf-idf-part-i/#comment-995
 127. http://blog.christianperone.com/2011/09/machine-learning-text-feature-extraction-tf-idf-part-i/?replytocom=995#respond
 128. http://egadioniputri.wordpress.com/
 129. http://blog.christianperone.com/2011/09/machine-learning-text-feature-extraction-tf-idf-part-i/#comment-996
 130. http://blog.christianperone.com/2011/09/machine-learning-text-feature-extraction-tf-idf-part-i/?replytocom=996#respond
 131. http://blog.christianperone.com/
 132. http://blog.christianperone.com/2011/09/machine-learning-text-feature-extraction-tf-idf-part-i/#comment-997
 133. http://blog.christianperone.com/2011/09/machine-learning-text-feature-extraction-tf-idf-part-i/?replytocom=997#respond
 134. http://blog.christianperone.com/2011/09/machine-learning-text-feature-extraction-tf-idf-part-i/#comment-998
 135. http://blog.christianperone.com/2011/09/machine-learning-text-feature-extraction-tf-idf-part-i/?replytocom=998#respond
 136. http://blog.christianperone.com/2011/09/machine-learning-text-feature-extraction-tf-idf-part-i/#comment-999
 137. http://blog.christianperone.com/2011/09/machine-learning-text-feature-extraction-tf-idf-part-i/?replytocom=999#respond
 138. http://blog.christianperone.com/2011/09/machine-learning-text-feature-extraction-tf-idf-part-i/#comment-1000
 139. http://blog.christianperone.com/2011/09/machine-learning-text-feature-extraction-tf-idf-part-i/?replytocom=1000#respond
 140. http://blog.christianperone.com/
 141. http://blog.christianperone.com/2011/09/machine-learning-text-feature-extraction-tf-idf-part-i/#comment-1001
 142. http://blog.christianperone.com/2011/09/machine-learning-text-feature-extraction-tf-idf-part-i/?replytocom=1001#respond
 143. http://blog.christianperone.com/2011/09/machine-learning-text-feature-extraction-tf-idf-part-i/#comment-1002
 144. http://blog.christianperone.com/2011/09/machine-learning-text-feature-extraction-tf-idf-part-i/?replytocom=1002#respond
 145. http://naishe.in/
 146. http://blog.christianperone.com/2011/09/machine-learning-text-feature-extraction-tf-idf-part-i/#comment-1003
 147. http://blog.christianperone.com/2011/09/machine-learning-text-feature-extraction-tf-idf-part-i/?replytocom=1003#respond
 148. http://blog.christianperone.com/2011/09/machine-learning-text-feature-extraction-tf-idf-part-i/#comment-1004
 149. http://blog.christianperone.com/2011/09/machine-learning-text-feature-extraction-tf-idf-part-i/?replytocom=1004#respond
 150. http://blog.christianperone.com/
 151. http://blog.christianperone.com/2011/09/machine-learning-text-feature-extraction-tf-idf-part-i/#comment-1005
 152. http://blog.christianperone.com/2011/09/machine-learning-text-feature-extraction-tf-idf-part-i/?replytocom=1005#respond
 153. http://blog.christianperone.com/2011/09/machine-learning-text-feature-extraction-tf-idf-part-i/#comment-1006
 154. http://blog.christianperone.com/2011/09/machine-learning-text-feature-extraction-tf-idf-part-i/?replytocom=1006#respond
 155. http://blog.christianperone.com/2011/09/machine-learning-text-feature-extraction-tf-idf-part-i/#comment-1007
 156. http://blog.christianperone.com/2011/09/machine-learning-text-feature-extraction-tf-idf-part-i/?replytocom=1007#respond
 157. http://blog.christianperone.com/2011/09/machine-learning-text-feature-extraction-tf-idf-part-i/#comment-1008
 158. http://blog.christianperone.com/2011/09/machine-learning-text-feature-extraction-tf-idf-part-i/?replytocom=1008#respond
 159. http://blog.christianperone.com/2011/09/machine-learning-text-feature-extraction-tf-idf-part-i/#comment-1009
 160. http://blog.christianperone.com/2011/09/machine-learning-text-feature-extraction-tf-idf-part-i/?replytocom=1009#respond
 161. http://blog.christianperone.com/2011/09/machine-learning-text-feature-extraction-tf-idf-part-i/#comment-1010
 162. http://blog.christianperone.com/2011/09/machine-learning-text-feature-extraction-tf-idf-part-i/?replytocom=1010#respond
 163. http://blog.christianperone.com/2011/09/machine-learning-text-feature-extraction-tf-idf-part-i/#comment-1011
 164. http://blog.christianperone.com/2011/09/machine-learning-text-feature-extraction-tf-idf-part-i/?replytocom=1011#respond
 165. http://blog.christianperone.com/
 166. http://blog.christianperone.com/2011/09/machine-learning-text-feature-extraction-tf-idf-part-i/#comment-1012
 167. http://blog.christianperone.com/2011/09/machine-learning-text-feature-extraction-tf-idf-part-i/?replytocom=1012#respond
 168. http://blog.christianperone.com/2011/09/machine-learning-text-feature-extraction-tf-idf-part-i/#comment-1013
 169. http://blog.christianperone.com/2011/09/machine-learning-text-feature-extraction-tf-idf-part-i/?replytocom=1013#respond
 170. http://blog.christianperone.com/2011/09/machine-learning-text-feature-extraction-tf-idf-part-i/#comment-1014
 171. http://blog.christianperone.com/2011/09/machine-learning-text-feature-extraction-tf-idf-part-i/?replytocom=1014#respond
 172. http://blog.christianperone.com/2011/09/machine-learning-text-feature-extraction-tf-idf-part-i/#comment-1015
 173. http://blog.christianperone.com/2011/09/machine-learning-text-feature-extraction-tf-idf-part-i/?replytocom=1015#respond
 174. http://blog.christianperone.com/
 175. http://blog.christianperone.com/2011/09/machine-learning-text-feature-extraction-tf-idf-part-i/#comment-1016
 176. http://blog.christianperone.com/2011/09/machine-learning-text-feature-extraction-tf-idf-part-i/?replytocom=1016#respond
 177. http://blog.christianperone.com/2011/09/machine-learning-text-feature-extraction-tf-idf-part-i/#comment-1017
 178. http://blog.christianperone.com/2011/09/machine-learning-text-feature-extraction-tf-idf-part-i/?replytocom=1017#respond
 179. http://blog.christianperone.com/2011/09/machine-learning-text-feature-extraction-tf-idf-part-i/#comment-11522
 180. http://blog.christianperone.com/2011/09/machine-learning-text-feature-extraction-tf-idf-part-i/?replytocom=11522#respond
 181. http://na/
 182. http://blog.christianperone.com/2011/09/machine-learning-text-feature-extraction-tf-idf-part-i/#comment-52275
 183. http://blog.christianperone.com/2011/09/machine-learning-text-feature-extraction-tf-idf-part-i/?replytocom=52275#respond
 184. http://blog.christianperone.com/2011/09/machine-learning-text-feature-extraction-tf-idf-part-i/#comment-25561
 185. http://blog.christianperone.com/2011/09/machine-learning-text-feature-extraction-tf-idf-part-i/?replytocom=25561#respond
 186. http://blog.christianperone.com/2011/09/machine-learning-text-feature-extraction-tf-idf-part-i/#comment-30561
 187. http://blog.christianperone.com/2011/09/machine-learning-text-feature-extraction-tf-idf-part-i/?replytocom=30561#respond
 188. http://blog.christianperone.com/2011/09/machine-learning-text-feature-extraction-tf-idf-part-i/#comment-42873
 189. http://blog.christianperone.com/2011/09/machine-learning-text-feature-extraction-tf-idf-part-i/?replytocom=42873#respond
 190. http://anipr.com/
 191. http://blog.christianperone.com/2011/09/machine-learning-text-feature-extraction-tf-idf-part-i/#comment-45190
 192. http://blog.christianperone.com/2011/09/machine-learning-text-feature-extraction-tf-idf-part-i/?replytocom=45190#respond
 193. http://blog.christianperone.com/2011/09/machine-learning-text-feature-extraction-tf-idf-part-i/#comment-49815
 194. http://blog.christianperone.com/2011/09/machine-learning-text-feature-extraction-tf-idf-part-i/?replytocom=49815#respond
 195. http://na/
 196. http://blog.christianperone.com/2011/09/machine-learning-text-feature-extraction-tf-idf-part-i/#comment-52274
 197. http://blog.christianperone.com/2011/09/machine-learning-text-feature-extraction-tf-idf-part-i/?replytocom=52274#respond
 198. http://blog.christianperone.com/2011/09/machine-learning-text-feature-extraction-tf-idf-part-i/#comment-54225
 199. http://blog.christianperone.com/2011/09/machine-learning-text-feature-extraction-tf-idf-part-i/?replytocom=54225#respond
 200. http://blog.christianperone.com/2011/09/machine-learning-text-feature-extraction-tf-idf-part-i/#comment-57513
 201. http://blog.christianperone.com/2011/09/machine-learning-text-feature-extraction-tf-idf-part-i/?replytocom=57513#respond
 202. http://blog.christianperone.com/2011/09/machine-learning-text-feature-extraction-tf-idf-part-i/#comment-57834
 203. http://blog.christianperone.com/2011/09/machine-learning-text-feature-extraction-tf-idf-part-i/?replytocom=57834#respond
 204. https://technaverbascripta.wordpress.com/2016/01/19/831/
 205. http://nu-no.nl/inverse-document-frequency-issue-unexpected-results/
 206. http://blog.christianperone.com/2011/09/machine-learning-text-feature-extraction-tf-idf-part-i/#comment-62188
 207. http://blog.christianperone.com/2011/09/machine-learning-text-feature-extraction-tf-idf-part-i/?replytocom=62188#respond
 208. http://blog.christianperone.com/2011/09/machine-learning-text-feature-extraction-tf-idf-part-i/#comment-75276
 209. http://blog.christianperone.com/2011/09/machine-learning-text-feature-extraction-tf-idf-part-i/?replytocom=75276#respond
 210. http://blog.christianperone.com/2011/09/machine-learning-text-feature-extraction-tf-idf-part-i/#comment-89190
 211. http://blog.christianperone.com/2011/09/machine-learning-text-feature-extraction-tf-idf-part-i/?replytocom=89190#respond
 212. http://blog.christianperone.com/2011/09/machine-learning-text-feature-extraction-tf-idf-part-i/#comment-113114
 213. http://blog.christianperone.com/2011/09/machine-learning-text-feature-extraction-tf-idf-part-i/?replytocom=113114#respond
 214. http://blog.christianperone.com/2011/09/machine-learning-text-feature-extraction-tf-idf-part-i/#comment-121655
 215. http://blog.christianperone.com/2011/09/machine-learning-text-feature-extraction-tf-idf-part-i/?replytocom=121655#respond
 216. http://blog.christianperone.com/2011/09/machine-learning-text-feature-extraction-tf-idf-part-i/#comment-122798
 217. http://blog.christianperone.com/2011/09/machine-learning-text-feature-extraction-tf-idf-part-i/?replytocom=122798#respond
 218. http://blog.christianperone.com/2011/09/machine-learning-text-feature-extraction-tf-idf-part-i/#comment-127476
 219. http://blog.christianperone.com/2011/09/machine-learning-text-feature-extraction-tf-idf-part-i/?replytocom=127476#respond
 220. http://datahubbs.com/
 221. http://blog.christianperone.com/2011/09/machine-learning-text-feature-extraction-tf-idf-part-i/#comment-151892
 222. http://blog.christianperone.com/2011/09/machine-learning-text-feature-extraction-tf-idf-part-i/?replytocom=151892#respond
 223. http://blog.christianperone.com/2011/09/machine-learning-text-feature-extraction-tf-idf-part-i/#comment-175037
 224. http://blog.christianperone.com/2011/09/machine-learning-text-feature-extraction-tf-idf-part-i/?replytocom=175037#respond
 225. http://blog.christianperone.com/2011/09/machine-learning-text-feature-extraction-tf-idf-part-i/#comment-135499
 226. http://blog.christianperone.com/2011/09/machine-learning-text-feature-extraction-tf-idf-part-i/?replytocom=135499#respond
 227. http://blog.christianperone.com/2011/09/machine-learning-text-feature-extraction-tf-idf-part-i/#comment-139029
 228. http://blog.christianperone.com/2011/09/machine-learning-text-feature-extraction-tf-idf-part-i/?replytocom=139029#respond
 229. http://blog.christianperone.com/2011/09/machine-learning-text-feature-extraction-tf-idf-part-i/#comment-143122
 230. http://blog.christianperone.com/2011/09/machine-learning-text-feature-extraction-tf-idf-part-i/?replytocom=143122#respond
 231. http://blog.christianperone.com/2011/09/machine-learning-text-feature-extraction-tf-idf-part-i/#comment-154335
 232. http://blog.christianperone.com/2011/09/machine-learning-text-feature-extraction-tf-idf-part-i/?replytocom=154335#respond
 233. http://blog.christianperone.com/2011/09/machine-learning-text-feature-extraction-tf-idf-part-i/#comment-165162
 234. http://blog.christianperone.com/2011/09/machine-learning-text-feature-extraction-tf-idf-part-i/?replytocom=165162#respond
 235. http://blog.christianperone.com/2011/09/machine-learning-text-feature-extraction-tf-idf-part-i/#comment-179377
 236. http://blog.christianperone.com/2011/09/machine-learning-text-feature-extraction-tf-idf-part-i/?replytocom=179377#respond
 237. http://blog.christianperone.com/2011/09/machine-learning-text-feature-extraction-tf-idf-part-i/#comment-191246
 238. http://blog.christianperone.com/2011/09/machine-learning-text-feature-extraction-tf-idf-part-i/?replytocom=191246#respond
 239. http://blog.christianperone.com/2011/09/machine-learning-text-feature-extraction-tf-idf-part-i/#comment-199366
 240. http://blog.christianperone.com/2011/09/machine-learning-text-feature-extraction-tf-idf-part-i/?replytocom=199366#respond
 241. http://blog.christianperone.com/2011/09/machine-learning-text-feature-extraction-tf-idf-part-i/#comment-200992
 242. http://blog.christianperone.com/2011/09/machine-learning-text-feature-extraction-tf-idf-part-i/?replytocom=200992#respond
 243. http://blog.christianperone.com/2011/09/machine-learning-text-feature-extraction-tf-idf-part-i/#comment-211008
 244. http://blog.christianperone.com/2011/09/machine-learning-text-feature-extraction-tf-idf-part-i/?replytocom=211008#respond
 245. http://blog.christianperone.com/2011/09/machine-learning-text-feature-extraction-tf-idf-part-i/#comment-212205
 246. http://blog.christianperone.com/2011/09/machine-learning-text-feature-extraction-tf-idf-part-i/?replytocom=212205#respond
 247. http://blog.christianperone.com/2011/09/machine-learning-text-feature-extraction-tf-idf-part-i/#comment-214380
 248. http://blog.christianperone.com/2011/09/machine-learning-text-feature-extraction-tf-idf-part-i/?replytocom=214380#respond
 249. http://blog.christianperone.com/2011/09/machine-learning-text-feature-extraction-tf-idf-part-i/#comment-217273
 250. http://blog.christianperone.com/2011/09/machine-learning-text-feature-extraction-tf-idf-part-i/?replytocom=217273#respond
 251. http://blog.christianperone.com/2011/09/machine-learning-text-feature-extraction-tf-idf-part-i/#comment-220703
 252. http://blog.christianperone.com/2011/09/machine-learning-text-feature-extraction-tf-idf-part-i/?replytocom=220703#respond
 253. http://blog.christianperone.com/2011/09/machine-learning-text-feature-extraction-tf-idf-part-i/#comment-221292
 254. http://blog.christianperone.com/2011/09/machine-learning-text-feature-extraction-tf-idf-part-i/?replytocom=221292#respond
 255. https://plus.google.com/100568023325795074941
 256. http://blog.christianperone.com/2011/09/machine-learning-text-feature-extraction-tf-idf-part-i/#comment-223637
 257. http://blog.christianperone.com/2011/09/machine-learning-text-feature-extraction-tf-idf-part-i/?replytocom=223637#respond
 258. https://plus.google.com/100568023325795074941
 259. http://blog.christianperone.com/2011/09/machine-learning-text-feature-extraction-tf-idf-part-i/#comment-223638
 260. http://blog.christianperone.com/2011/09/machine-learning-text-feature-extraction-tf-idf-part-i/?replytocom=223638#respond
 261. http://blog.christianperone.com/2011/09/machine-learning-text-feature-extraction-tf-idf-part-i/#comment-224661
 262. http://blog.christianperone.com/2011/09/machine-learning-text-feature-extraction-tf-idf-part-i/?replytocom=224661#respond
 263. http://blog.christianperone.com/2011/09/machine-learning-text-feature-extraction-tf-idf-part-i/#comment-237679
 264. http://blog.christianperone.com/2011/09/machine-learning-text-feature-extraction-tf-idf-part-i/?replytocom=237679#respond
 265. http://blog.christianperone.com/2011/09/machine-learning-text-feature-extraction-tf-idf-part-i/#comment-238163
 266. http://blog.christianperone.com/2011/09/machine-learning-text-feature-extraction-tf-idf-part-i/?replytocom=238163#respond
 267. http://blog.christianperone.com/2011/09/machine-learning-text-feature-extraction-tf-idf-part-i/#comment-239971
 268. http://blog.christianperone.com/2011/09/machine-learning-text-feature-extraction-tf-idf-part-i/?replytocom=239971#respond
 269. http://blog.christianperone.com/2011/09/machine-learning-text-feature-extraction-tf-idf-part-i/#comment-239974
 270. http://blog.christianperone.com/2011/09/machine-learning-text-feature-extraction-tf-idf-part-i/?replytocom=239974#respond
 271. http://blog.christianperone.com/2011/09/machine-learning-text-feature-extraction-tf-idf-part-i/#comment-240723
 272. http://blog.christianperone.com/2011/09/machine-learning-text-feature-extraction-tf-idf-part-i/?replytocom=240723#respond
 273. http://blog.christianperone.com/2011/09/machine-learning-text-feature-extraction-tf-idf-part-i/#comment-241212
 274. http://blog.christianperone.com/2011/09/machine-learning-text-feature-extraction-tf-idf-part-i/?replytocom=241212#respond
 275. http://blog.christianperone.com/2011/09/machine-learning-text-feature-extraction-tf-idf-part-i/#comment-242979
 276. http://blog.christianperone.com/2011/09/machine-learning-text-feature-extraction-tf-idf-part-i/?replytocom=242979#respond
 277. http://blog.christianperone.com/2011/09/machine-learning-text-feature-extraction-tf-idf-part-i/#comment-244697
 278. http://blog.christianperone.com/2011/09/machine-learning-text-feature-extraction-tf-idf-part-i/?replytocom=244697#respond
 279. http://blog.christianperone.com/2011/09/machine-learning-text-feature-extraction-tf-idf-part-i/#comment-244700
 280. http://blog.christianperone.com/2011/09/machine-learning-text-feature-extraction-tf-idf-part-i/?replytocom=244700#respond
 281. http://blog.christianperone.com/2011/09/machine-learning-text-feature-extraction-tf-idf-part-i/#comment-245443
 282. http://blog.christianperone.com/2011/09/machine-learning-text-feature-extraction-tf-idf-part-i/?replytocom=245443#respond
 283. http://blog.christianperone.com/2011/09/machine-learning-text-feature-extraction-tf-idf-part-i/#comment-246451
 284. http://blog.christianperone.com/2011/09/machine-learning-text-feature-extraction-tf-idf-part-i/?replytocom=246451#respond
 285. http://blog.christianperone.com/2011/09/machine-learning-text-feature-extraction-tf-idf-part-i/#comment-246452
 286. http://blog.christianperone.com/2011/09/machine-learning-text-feature-extraction-tf-idf-part-i/?replytocom=246452#respond
 287. http://blog.christianperone.com/2011/09/machine-learning-text-feature-extraction-tf-idf-part-i/#comment-249973
 288. http://blog.christianperone.com/2011/09/machine-learning-text-feature-extraction-tf-idf-part-i/?replytocom=249973#respond
 289. https://medium.com/marciojesus/
 290. http://blog.christianperone.com/2011/09/machine-learning-text-feature-extraction-tf-idf-part-i/#comment-252041
 291. http://blog.christianperone.com/2011/09/machine-learning-text-feature-extraction-tf-idf-part-i/?replytocom=252041#respond
 292. http://blog.christianperone.com/2011/09/machine-learning-text-feature-extraction-tf-idf-part-i/#comment-254298
 293. http://blog.christianperone.com/2011/09/machine-learning-text-feature-extraction-tf-idf-part-i/?replytocom=254298#respond
 294. http://blog.christianperone.com/2011/09/machine-learning-text-feature-extraction-tf-idf-part-i/#comment-256021
 295. http://blog.christianperone.com/2011/09/machine-learning-text-feature-extraction-tf-idf-part-i/?replytocom=256021#respond
 296. http://blog.christianperone.com/2011/09/machine-learning-text-feature-extraction-tf-idf-part-i/#comment-263451
 297. http://blog.christianperone.com/2011/09/machine-learning-text-feature-extraction-tf-idf-part-i/?replytocom=263451#respond
 298. http://blog.christianperone.com/2011/09/machine-learning-text-feature-extraction-tf-idf-part-i/#respond
 299. https://akismet.com/privacy/
 300. http://blog.christianperone.com/2013/09/machine-learning-cosine-similarity-for-vector-space-models-part-iii/
 301. http://blog.christianperone.com/2015/08/googles-s2-geometry-on-the-sphere-cells-and-hilbert-curve/
 302. http://blog.christianperone.com/2015/08/convolutional-neural-networks-and-feature-extraction-with-python/
 303. http://blog.christianperone.com/2011/10/machine-learning-text-feature-extraction-tf-idf-part-ii/
 304. http://blog.christianperone.com/2019/01/a-sane-introduction-to-maximum-likelihood-estimation-id113-and-maximum-a-posteriori-map/
 305. http://blog.christianperone.com/2014/06/simple-and-effective-coin-segmentation-using-python-and-opencv/
 306. http://blog.christianperone.com/2017/11/the-effective-receptive-field-on-id98s/
 307. http://blog.christianperone.com/2015/01/real-time-drone-object-tracking-using-python-and-opencv/
 308. http://blog.christianperone.com/2018/10/pytorch-1-0-tracing-jit-and-libtorch-c-api-to-integrate-pytorch-into-nodejs/
 309. http://creativecommons.org/licenses/by-nc/4.0/
 310. http://creativecommons.org/licenses/by-nc/4.0/
 311. http://blog.christianperone.com/
 312. https://wordpress.org/
 313. http://themegraphy.com/wordpress-themes/graphy/

   hidden links:
 315. http://blog.christianperone.com/
 316. https://twitter.com/tarantulae
 317. https://www.linkedin.com/in/cperone
 318. https://github.com/perone
 319. https://www.youtube.com/c/christiansperone
 320. https://scholar.google.ca/citations?user=eqbv0qkaaaaj&hl=en
