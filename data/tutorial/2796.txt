     * [1]home
     * [2]getting started
     * [3]people

   cat image

   building coreference chains since 2007

bart - a beautiful id2 toolkit

   bart, the beautiful id2 toolkit, is a product of the
   project exploiting lexical and encyclopedic resources for entity
   disambiguation at the johns hopkins summer workshop 2007.

   bart performs automatic coreference resolution, including all necessary
   preprocessing steps.

   bart incorporates a variety of machine learning approaches and can use
   several machine learning toolkits, including weka and an included
   maxent implementation.

getting started

   bart internally works with a standoff-based representation based on the
   format of mmax2 (an annotation tool for coreference and other discourse
   annotation). the easiest way of getting text into bart and coreference
   chains out is the rest-based web service that is part of bart and
   allows you to easily import raw text, process it, and export the result
   as inline xml.

     * grab the bart-snapshot.tgz tarball from
       http://www.sfs.uni-tuebingen.de/~versley/bart/ and untar it
       somewhere.
       this is pretty big, but it contains all the software you need
       (including berkeley parser and stanford ner), as well as a model
       trained on muc6 (which works ok-ish without requiring you to set up
       external databases and stuff).
     * change to that directory and do:
source setup.sh
java -xmx1024m elkfed.webdemo.bartserver

       (the first command sets up the classpath, whereas the second starts
       bart's web service).
     * point your browser at http://localhost:8125/index.jsp and then
       enter some text into the form and verify that it does something
       (clicking on the "coref" tab should run the coreference resolver
       and display markables that are part of a coreference chain in a
       greenish tinge).
     * to use bart on larger quantities of text, you would want to use the
       rest webservice, e.g. with libwww-perl's post program:
cat text1.txt | post http://localhost:8125/bartdemo/showtext/process/

       this should give you the text with pos tags and coreference chains
       in inline xml format. (if you also want the parses, you could add
       "parse" to the array wanted_levels in showtext.exportcoref in the
       elkfed.webdemo package.

publications

   versley, y., moschitti, a., poesio, m. and yang, x. (2008)
   coreference systems based on kernel methods. proceedings of the 22nd
   international conference on computational linguistics (coling 2008).
   versley, y., ponzetto, s.p., poesio, m., eidelman, v., jern, a., smith,
   j., yang, x., moschitti, a. (2008)
   bart: a modular toolkit for coreference resolution. proceedings of the
   6th international conference on language resources and evaluation (lrec
   2008).
   versley, y., ponzetto, s.p., poesio, m., eidelman, v., jern, a., smith,
   j., yang, x., moschitti, a. (2008)
   bart: a modular toolkit for coreference resolution. companion volume of
   the proceedings of the 46th annual meeting of the association for
   compuatational linguistics (acl 2008).
   poesio, m., day, d., artstein, r., duncan, j., eidelman, v., giuliano,
   c., hall, r., hitzeman, j., jern, a., kabadjov, m., yong wai keong, s.,
   mann, g., moschitti, a., ponzetto, s., smith, j., steinberger, j.,
   strube, m., su, j., versley, y., yang, x., wick, m. (2007)
   elerfed: final report from the jhu 2007 summer workshop. technical
   report.

people

   the following people have been involved in the creation and evolution
   of bart:
     * massimo poesio (fearless leader)
     * simone ponzetto (main contributor)
     * yannick versley (main contributor)
     * vladimir eidelman (undergraduate student at the jhu workshop)
     * alan jern (undergraduate student at the jhu workshop)
     * alessandro moschitti (researcher at the jhu workshop)
     * xiaofeng yang (researcher at the jhu workshop)
     * kepa rodriguez (phd student, cimec)
     * olga uryupina (postdoc, [4]wordpresshosts.org)

   [5]coreference chains in mmax2

   results view in mmax2

frequently asked questions

   bart is open source. what license is it under?
   the core of bart - i.e., everything that's in the src/ folder when you
   unpack it - is licensed under the apache license (v2.0), except for a
   small number of classes
   (elkfed.coref.discourse_entities.discourseentity, which is inherited
   from guitar code, and the lbfgs code in riso.numerical, which comes
   from a project called riso; both are gpl-licensed). the libraries that
   bart uses also fall under either apache license (e.g., xmlbeans,
   different helper libraries), but some important components (all the
   parsers that can be used, the stanford ner, weka) are also
   gpl-licensed.
   as a result, you can (in my understanding):
   * use bart internally with no restrictions - both the apache license
   and the gpl allow this. ("internally" excludes letting others use the
   code by means of a web service or a closed appliance).
   * build derived works with bart and give these to others under a
   license that is compatible with both the gpl and the apache license
   (which includes both the gpl and the apache license).
   * replace the parts that have a license that is too restrictive for
   your taste and/or get a commercial license from the respective owners
   (which may be a nontrivial undertaking, as all parsers and all machine
   learning libraries that bart currently interfaces to are gpl-licensed).
   nautica x

references

   1. http://www.bart-coref.org/index.html
   2. http://www.bart-coref.org/index.html
   3. http://www.bart-coref.org/index.html
   4. http://www.wordpresshosts.org/
   5. http://www.bart-coref.org/images/mmax_muc.png
