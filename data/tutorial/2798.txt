   histwords:
   id27s for historical text [1]william l. hamilton,   [2]jure
   leskovec,   [3]dan jurafsky

   introduction

   histwords is a collection of tools and datasets for analyzing language
   change using word vector embeddings. the goal of this project is to
   facilitate quantitative research in diachronic linguistics, history,
   and the digital humanities.

   we used the historical word vectors in histwords to study the semantic
   evolution of more than 30,000 words across 4 languages. this study led
   us to propose two statistical laws that govern the evolution of word
   meaning ([4]paper link).

      law of conformity: words that are used more frequently change less
   and have meanings that are more stable over time.

      law of innovation: words that are polysemous (have many meanings)
   change at faster rates.

   we released pre-trained historical id27s (spanning all
   decades from 1800 to 2000) for multiple languages (english, french,
   german, and chinese). embeddings constructed from many different
   corpora and using different embedding approaches are included.

   the paper [5]diachronic id27s reveal statistical laws of
   semantic change details how these embeddings were constructed.

   getting started (code download)
   all the code is available [6]on github

   download pre-trained word vectors

   1.   historical id97 (sgns) embeddings (get started quick)

   these downloads contain historical id97 vectors without any extra
   stats or other information. the [7]the histwords code contains tools
   (and examples) for manipulating the embeddings.
     * [8]all english (1800s-1990s) (from [9]google id165s eng-all)
     * [10]english fiction (1800s-1990s) (from [11]google id165s
       eng-fiction-all)
     * [12]genre-balanced american english (1830s-2000s) (from [13]corpus
       of historical american english)
     * [14]genre-balanced american english, word lemmas (1830s-2000s)
       (from [15]corpus of historical american english)
     * [16]french (1800s-1990s) (from [17]google id165s fre-all)
     * [18]german (1800s-1990s) (from [19]google id165s ger-all)
     * [20]simplified chinese (1950-1990s) (from [21]google id165s
       chi-sim-all)

   2.   multiple historical embedding types + detailed historical
   statistics

   these downloads contain all the data necessary to replicate the results
   of our [22]published study, using the three types of embeddings
   described in that work. each corpus zip-file includes these historical,
   post-processed word vectors along with some useful historical
   statistics. [23]see this page for a detailed description of the data.
   this data is available for all the corpora:
     * [24]all english (1800s-1990s)
     * [25]english fiction (1800s-1990s)
     * [26]genre-balanced american english (1830s-2000s)
     * [27]genre-balanced american english, word lemmas (1830s-2000s)
     * [28]french (1800s-1990s)
     * [29]german (1800s-1990s)
     * [30]simplified chinese (1950-1990s)

   this data is made available under the [31]public domain dedication and
   license v1.0 whose full text can be found at:
   [32]http://www.opendatacommons.org/licenses/pddl/1.0/.

   citing histwords

   william l. hamilton, jure leskovec, and dan jurafsky. acl 2016.
   [33]diachronic id27s reveal statistical laws of semantic
   change.

   highlights

   1.   visualizing changes in word meaning
   [34][wordpaths.png]
   changes in word meaning can be visualized by projecting historical word
   vectors into a 2-d space.
    a. gay shifted in meaning over the last century, from meaning "showy"
       or "cheerful" to denoting "homosexuality".
    b. broadcast used to refer to the act of throwing seeds, but then this
       motion became associated with the throwing of newspapers, and
       eventually broadcast developed its current meaning of
       "disseminating information."
    c. awful underwent a process known as pejoration; it used to literally
       mean "full of awe", but over time it became more negative and now
       signifies that something is "upsetting."

   2.   uncovering statistical laws of semantic change
   [35][statlaws.png]
   using historical id27s we measured the rate of semantic
   change for thousands of words across 7 datasets, 4 languages, and 150
   years. these quantitative measurements allowed us to propose new
   statistical laws of semantic change. we found that
    a. the meanings of higher-frequency (i.e., more common) words are more
       stable. this means that words that get used a lot tend to keep the
       meanings, while uncommon words can gain new meanings more easily.
    b. words that are more polysemous (i.e., that have more meanings, or
       are used in more contexts) tend to change faster. this means that
       words that can be used in lots of different ways (like the word
       "like") tend to be more semantically unstable.

   bugs/issues/discussion

   github: histwords is [36]on github. for bug reports and patches, you're
   best off using the github issues and pull requests features.

   william l. hamilton |

   site design courtesy of [37]jason chuang

references

   visible links
   1. http://stanford.edu/~wleif
   2. https://cs.stanford.edu/people/jure
   3. http://web.stanford.edu/~jurafsky
   4. http://arxiv.org/pdf/1605.09096.pdf
   5. http://arxiv.org/pdf/1605.09096.pdf
   6. https://github.com/williaid113if/histwords
   7. https://github.com/williaid113if/histwords
   8. http://snap.stanford.edu/historical_embeddings/eng-all_sgns.zip
   9. http://storage.googleapis.com/books/ngrams/books/datasetsv2.html
  10. http://snap.stanford.edu/historical_embeddings/eng-fiction-all_sgns.zip
  11. http://storage.googleapis.com/books/ngrams/books/datasetsv2.html
  12. http://snap.stanford.edu/historical_embeddings/coha-word_sgns.zip
  13. http://corpus.byu.edu/coha/
  14. http://snap.stanford.edu/historical_embeddings/coha-lemma_sgns.zip
  15. http://corpus.byu.edu/coha/
  16. http://snap.stanford.edu/historical_embeddings/fre-all_sgns.zip
  17. http://storage.googleapis.com/books/ngrams/books/datasetsv2.html
  18. http://snap.stanford.edu/historical_embeddings/ger-all_sgns.zip
  19. http://storage.googleapis.com/books/ngrams/books/datasetsv4.html
  20. http://snap.stanford.edu/historical_embeddings/chi-sim-all_sgns.zip
  21. http://storage.googleapis.com/books/ngrams/books/datasetsv2.html
  22. http://arxiv.org/pdf/1605.09096.pdf
  23. http://nlp.stanford.edu/projects/histwords/data_description.html
  24. http://snap.stanford.edu/historical_embeddings/eng-all.zip
  25. http://snap.stanford.edu/historical_embeddings/eng-fiction-all.zip
  26. http://snap.stanford.edu/historical_embeddings/coha-word.zip
  27. http://snap.stanford.edu/historical_embeddings/coha-lemma.zip
  28. http://snap.stanford.edu/historical_embeddings/fre-all.zip
  29. http://snap.stanford.edu/historical_embeddings/ger-all.zip
  30. http://snap.stanford.edu/historical_embeddings/chi-sim-all.zip
  31. http://opendatacommons.org/licenses/pddl/
  32. http://www.opendatacommons.org/licenses/pddl/1.0/
  33. http://arxiv.org/pdf/1605.09096.pdf
  34. https://nlp.stanford.edu/projects/histwords/images/wordpaths.png
  35. https://nlp.stanford.edu/projects/histwords/images/statlaws.png
  36. https://github.com/williaid113if/histwords
  37. http://jason.chuang.info/

   hidden links:
  39. https://www.linkedin.com/in/william-hamilton-2a6112108
