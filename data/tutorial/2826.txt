   #[1]      uantitative    ourney full atom feed

     * [2]home
     * [3]about
     * [4]tags
     * [5]categories
     * [6]archives

[7]      uantitative    ourney

    our experiences in learning quantitative applications

jul 15, 2015

[8]simple genetic algorithm in 15 lines of python

genetic algorithm in 15 lines of python code

a simple yet powerful genetic algorithm implementation used to train a neural
network in 15 lines of code.

   disclaimer: i am not a machine learning expert by any means, i mostly
   do web development, so this is not my forte at all, but i have enjoyed
   messing around writing basic neural nets and id107 and am
   just trying to share what little i've learned to other neophytes out
   there.

   summary: this is a spinoff of a really great tutorial called "a neural
   network in 11 lines of python" found here: <
   http://iamtrask.github.io/2015/07/12/basic-python-network/ > so please
   go through that article first otherwise this may not make any sense.
   here i will show you how i wrote a basic genetic algorithm (ga) that
   finds an optimal set of weights to train the neural network. i'm not
   going to go into detail about what a genetic algorithm is, so if you're
   already not familiar with them, please do some googling.

   by the way, gas are generally much slower than good ol' gradient
   descent, but i think applying gas to a simple neural net is a more fun
   way to learn it. also, gas may be good for finding an optimal set of
   hyperparameters for a neural net (e.g. the net architecture).

just give me the code:

   in [ ]:
import random, numpy as np, neuralnet as nn
params = [100, 0.05, 250, 3, 20]
curpop = np.random.choice(np.arange(-15,15,step=0.01),size=(params[0],params[3])
,replace=false)
nextpop = np.zeros((curpop.shape[0], curpop.shape[1]))
fitvec = np.zeros((params[0], 2))
for i in range(params[2]):
        fitvec = np.array([np.array([x, np.sum(nn.costfunction(nn.x, nn.y, curpo
p[x].reshape(3,1)))]) for x in range(params[0])])
        winners = np.zeros((params[4], params[3])) #20x2
        for n in range(len(winners)):
                selected = np.random.choice(range(len(fitvec)), params[4]/2, rep
lace=false)
                wnr = np.argmin(fitvec[selected,1])
                winners[n] = curpop[int(fitvec[selected[wnr]][0])]
        nextpop[:len(winners)] = winners
        nextpop[len(winners):] = np.array([np.array(np.random.permutation(np.rep
eat(winners[:, x], ((params[0] - len(winners))/len(winners)), axis=0))) for x in
 range(winners.shape[1])]).t
        curpop = np.multiply(nextpop, np.matrix([np.float(np.random.normal(0,2,1
)) if random.random() < params[1] else 1 for x in range(nextpop.size)]).reshape(
nextpop.shape))

   ok, so i'm assuming that code is completely not helpful at this point,
   and in fact, it won't even run if you tried to copy and paste and run
   it because you also need the code for the neural network, which i
   stored in a separate file and imported. let's first talk about the
   general steps in implementing a genetic algorithm and then we'll break
   down the code line by line, add in some print() statements to see
   what's going on, and maybe even make some fancy graphs.

   essentially, a genetic algorithm is a search algorithm that will
   hopefully find an optimal solution through a process that simulates
   natural selection and evolution. here's the overall flow for how they
   work:
     * we generate a population of random potential solutions
     * then we iterate through this population and assess the fitness of
       (i.e. how good of a solution) each solution
     * we prefentially select solutions with higher fitness to survive and
       make it to the next generation. solutions with higher fitness have
       a higher id203 of being selected
     * these "winner" solutions then "mate" and produce offspring
       solutions. for example, if our solutions are simply vectors of
       integers, then mating vector1 with vector2 involves taking a few
       elements from vector1 and combining it with a few elements of
       vector2 to make a new offspring vector of the same dimensions.
       vector1: [1 2 3], vector2: [4 5 6]. vector1 mates with vector2 to
       produce [4 5 3] and [1 2 6]
     * so now we have a new population with the top solutions from the
       last generation along with new offspring solutions, at this point,
       we will iterate over our solutions and randomly mutate some of them
       to make sure to introduce new "genetic diversity" into every
       generation to prevent premature convergence on a local optimum.
     * repeat this process for x number of generations or until we have a
       sufficiently good solution

   as a quick review, the iamtrask article shows you how to implement a
   really simple 2-layer (1 input layer, 1 output layer) neural network
   that is trained to solve this problem:

    inputs  output
   0 0 1    0
   1 1 1    1
   1 0 1    1
   0 1 1    0

   as you can see, the output simply depends on whether the first input is
   a 1 or not. the 2nd input is irrelevant and the 3rd input is our bias
   (explained elsewhere).

   if you train the 2-layer neural net (thus one set of weights) using
   id119 using the implementation in the iamtrask article, you
   will get a set of weights close to this:

     [[ 9.67299303],[-0.2078435],[-4.62963669]]

   and if you calculate the cost using these weights (the cost function is
   a simple difference between expected and actual output values), you
   get...

     cost: 0.0557587344696

   pretty low right? now just to jump ahead a bit, when i tuned the
   genetic algorithm and ran it a couple of times, it found a completely
   different set of weights:

     [[ 3.09686945e+05 -7.88485054e-03 -1.67477116e+03]]
     cost: 0.0

   obviously these weights resulted in a significantly lower cost (better
   fitness). in all honesty however, for this simplistic problem, the
   difference in cost is pretty inconsequential. in more complex problems,
   a cost that low is probably resulting in overfitting. not to mention,
   id107 almost certainly will take longer to converge than
   id119. but let's ignore all those details, we just want to
   build a genetic algorithm because they're cool.

   before i jump into the details of the genetic algorithm, i want to
   revisit the neural net. here's the code for the neural net i
   implemented, which is an adaptation from the one by iamtrask:
   in [3]:
import numpy as np
import math

x = np.array([ [0,0,1],[0,1,1],[1,0,1],[1,1,1]]) #training data x
y = np.array([[0,0,1,1, 1, 0, 0]]).t #training data y
syn0 = 2*np.random.random((3,1)) - 1 #randomize intial weights (theta)

def runforward(x, theta): #this runs our net and returns the output
        return sigmoid(np.dot(x, theta))
def costfunction(x, y, theta): #our cost function, simply determines the arithme
tic difference between the expected y and our actual y
        m = float(len(x))
        hthetax = np.array(runforward(x, theta))
        return np.sum(np.abs(y - hthetax))
def sigmoid(x): return 1 / (1 + np.exp(- x)) #just our run-of-the-mill sigmoid f
unction

   you should be able to figure this out if you've run through the
   iamtrask article or already have an understanding of neural nets. just
   a note: i call the weights theta. let's go ahead and run this network
   just to make sure it's working right.
   in [4]:
runforward(np.array([0,1,1]), syn0)

   out[4]:
array([ 0.31364485])

   we expect to get about [ 0 ] for an input of [0,1,1], but obviously
   when we use random weights, that's not likely to happen. let's try
   again with those weights i got from doing id119 (not shown
   here).
   in [5]:
optimal_theta = np.array([[ 9.67299303],[-0.2078435],[-4.62963669]])
runforward(np.array([0,1,1]), optimal_theta)

   out[5]:
array([ 0.00786466])

   as you can see, we get a value pretty close to 0, as expected. nice.
   okay, so now let's try the weights i got from running the genetic
   algorithm.
   in [6]:
optimal_theta_ga = np.array([3.09686945e+05,-7.88485054e-03,-1.67477116e+03])
runforward(np.array([0,1,1]), optimal_theta_ga)

/library/frameworks/python.framework/versions/3.4/lib/python3.4/site-packages/ip
ython/kernel/__main__.py:14: runtimewarning: overflow encountered in exp

   out[6]:
0.0

   wow! the result we get here is so close to zero we get an overflow
   warning. just ignore that, the point is, the error/cost is really,
   really low. (again, this is not necessarily a good thing...becauase of
   potential overfitting, but for this particular problem, overfitting is
   fine). just to make things really clear, let's take a look at what
   these weights are doing diagramatically.
   [nndiagram1.png] [nndiagram2.png]

   so as you can see on the right, whenever the bottom (left-most) input
   is 1, a really, really big number gets sent over to our sigmoid
   function, which will of course return something very close to 1.

   alright, so enough about the neural network. let's go line by line with
   the genetic algorithm (skipping imports).
   in [7]:
params = [100, 0.05, 250, 3, 20] #these are just some parameters for the ga, def
ined below in order:
# [init pop (pop=100), mut rate (=5%), num generations (250), chromosome/solutio
n length (3), # winners/per gen]

   nothing too interesting there, but just noting that params[3] (solution
   length) refers to the number of elements in each individual solution.
   since our solutions are weights to the 2-layer neural net, each
   solution is a 3 element vector (numpy array). also need to note the
   last parameter, params[4] refers to how many solutions we will pick as
   winners from each generation to populate the new generation. so out of
   total population of 100, every generation we will preferentially pick
   the top 20 solutions, populate the new generation with them and their
   offspring.
   in [8]:
curpop = np.random.choice(np.arange(-15,15,step=0.01),size=(params[0],params[3])
,replace=false)
nextpop = np.zeros((curpop.shape[0], curpop.shape[1]))
fitvec = np.zeros((params[0], 2))

   the top line is the most important here. basically we're creating a
   matrix 100x3 with an initial population of random solutions. we're
   using the np.arange() function to create a bunch of values -15, -14.99,
   -14.89....15 in order in a long array, then we use np.random.choice()
   to randomly choose 100x3 = 300 of them to build the 100x3 matrix of
   initial solutions. this isn't the most computationally efficient way to
   do things, but i've found it works really well. this is certainly not
   the only way to do it, and i encourage you to mess around with
   different ways to intialize your population. it turns out this step is
   really important to how well it does. if your initial population is not
   well randomized and not very diverse, you won't get good results.
   in [ ]:
for i in range(params[2]):
        fitvec = np.array([np.array([x, np.sum(nn.costfunction(nn.x, nn.y, curpo
p[x].reshape(3,1)))]) for x in range(params[0])])

   params[2] is our number of generations, so this is our main, outer loop
   to go through the whole flow each generation. our first step is to
   calculate the cost/error of each solution (there's 100) and add it to a
   matrix called fitvec. each element of fitvec is an array consisting of
   the index of the solution in curpop and its cost, e.g. [0, 2.54] means
   that the 0th element in curpop (first solution) has an error of 2.54
   in [10]:
winners = np.zeros((params[4], params[3]))

   we initialize a new matrix called winners; this will hold our winning
   solutions temporarily until we move them to the next generation.
   in [11]:
        for n in range(len(winners)):
                selected = np.random.choice(range(len(fitvec)), params[4]/2, rep
lace=false)

   now we're in a loop to populate the winners matrix. we use
   np.random.choice() to randomly pick params[4]/2 (20/2=10) solutions.
   we're gonna use a tournament style selection process where we randomly
   choose a subset of our population, and then pick the best solution from
   that subset and add it to our winners array. obviously higher fitness
   (lower error) solutions have a higher chance of making it to the
   winners array, but we don't just pick the top 20 solutions because we
   want to maintain some genetic diversity in each generation, so have a
   few higher error solutions is generally a good thing.
   in [12]:
        wnr = np.argmin(fitvec[selected,1])

   so the array 'selected' contains 10 random solutions (actually the
   indices to 10 solutions) from our population. now we reference fitvec
   to find the actual elements, use np.argmin() to pick the one with the
   smallest error/cost and assign the index of that winning element to a
   variable, 'wnr'
   in [13]:
        winners[n] = curpop[int(fitvec[selected[wnr]][0])]

   then we reference the winner in curpop, the array of all solutions of
   the current generation, and copy it to our 'winners' array.
   in [14]:
        nextpop[:len(winners)] = winners

   nextpop is the array containing all the solutions for the next
   generation. we populate the first 20 elements of nextpop with our
   winning solutions from 'winners' array.
   in [15]:
        nextpop[len(winners):] = np.array([np.array(np.random.permutation(np.rep
eat(winners[:, x], ((params[0] - len(winners))/len(winners)), axis=0))) for x in
 range(winners.shape[1])]).t

   okay, yeah this is a really long line and it's not very readable. i
   kind of cheated to make this all in 15 lines. this line is our mating
   process, and it's probably the most complicated part of a genetic
   algorithm. let's start with the core of this nasty line.

     np.repeat(winners[:, x], ((params[0] - len(winners))/len(winners)),
     axis=0)

   basically np.repeat() will duplicate our 20x3 matrix to create a 80x3
   matrix. we already populated the first 20 elements of nextpop with the
   winners from last generation. now we want to populate the last 80
   elements with their offspring.

     np.random.permutation(np.repeat(winners[:, x], ((params[0] -
     len(winners))/len(winners)), axis=0))

   now we just use np.random.permutation() to shuffle the columns of this
   next 80x3 matrix. this is how we accomplish the crossover functional.
   imagine we have a 3x3 matrix (2 solutions) like this:
   np.array([[1,2,3],[4,5,6],[7,8,9]]) , when we run the permutation
   function, it will change it something like:
   np.array([[7,5,3],[1,8,9],[4,2,3]])
   go look at the numpy documentation to learn more about permutation if
   you still don't understand how it's working here.
   in [ ]:
        curpop = np.multiply(nextpop, np.matrix([np.float(np.random.normal(0,2,1
)) if random.random() < params[1] else 1 for x in range(nextpop.size)]).reshape(
nextpop.shape))

   ahh. our last line of code! this is our mutation process. i'm using a
   list comprehension to build a matrix of the same dimensions as nextpop,
   but filled with 1s. however, with a id203 of params[1] (our
   mutation rate), we randomly "mutate" some of the elements. our mutation
   is basically using a random value from numpy.random.normal() instead of
   1. so we end up with a matrix like this (i've shrunk it to 10x3 to make
   it fit here and changed the mutation rate to 20% so you can see more
   mutated elements):
   in [19]:
np.matrix([np.float(np.random.normal(0,2,1)) if random.random() < 0.20 else 1 fo
r x in range(30)]).reshape(10,3)

   out[19]:
matrix([[ 1.        ,  1.        , -0.274611  ],
        [ 1.        ,  1.        ,  1.        ],
        [ 1.        ,  1.        ,  1.        ],
        [ 1.        ,  0.05055137,  1.98058061],
        [ 1.        ,  2.62563321,  1.        ],
        [ 1.        ,  1.        ,  3.35454534],
        [ 1.        ,  1.        ,  1.        ],
        [ 1.        ,  1.        , -1.96160288],
        [ 1.        ,  1.        ,  1.0381105 ],
        [-0.64245344,  2.04278346,  1.        ]])

   then we multiply this matrix (element-wise multiplication) to our
   nextpop matrix. most of the time we're multiplying each element in
   nextpop by 1, so leaving them unchanged, but sometimes we multiply by
   one of the mutated values and thus will randomly change some elements
   in nextpop. this adds genetic diversity to our next generation. so now
   we've filled up nextpop with a new generation of higher fitness
   solutions. we just repeat this process for how ever many generations we
   defined in params.

alright, so we're done! that's it! we made a genetic algorithm that trains a
neural network, cool!

   ...okay, yeah technically we did, but let's actually watch it do
   something. here we go...
   in [20]:
import random, numpy as np
import neuralnet as nn
params = [100, 0.05, 10, 3, 20] # [init pop (pop=100), mut rate (=5%), num gener
ations (250), chromosome/solution length (3), # winners/per gen]
curpop = np.random.choice(np.arange(-15,15,step=0.01),size=(params[0],params[3])
,replace=false) #initialize current population to random values within range
nextpop = np.zeros((curpop.shape[0], curpop.shape[1]))
fitvec = np.zeros((params[0], 2)) #1st col is indices, 2nd col is cost
for i in range(params[2]): #iterate through num generations
        fitvec = np.array([np.array([x, np.sum(nn.costfunction(nn.x, nn.y, curpo
p[x].reshape(3,1)))]) for x in range(params[0])]) #create vec of all errors from
 cost function
        print("(gen: #%s) total error: %s\n" % (i, np.sum(fitvec[:,1])))
        winners = np.zeros((params[4], params[3])) #20x2
        for n in range(len(winners)): #for n in range(10)
                selected = np.random.choice(range(len(fitvec)), params[4]/2, rep
lace=false)
                wnr = np.argmin(fitvec[selected,1])
                winners[n] = curpop[int(fitvec[selected[wnr]][0])]
        nextpop[:len(winners)] = winners #populate new gen with winners
        nextpop[len(winners):] = np.array([np.array(np.random.permutation(np.rep
eat(winners[:, x], ((params[0] - len(winners))/len(winners)), axis=0))) for x in
 range(winners.shape[1])]).t #populate the rest of the generation with offspring
 of mating pairs
        nextpop = np.multiply(nextpop, np.matrix([np.float(np.random.normal(0,2,
1)) if random.random() < params[1] else 1 for x in range(nextpop.size)]).reshape
(nextpop.shape)) #randomly mutate part of the population
        curpop = nextpop

best_soln = curpop[np.argmin(fitvec[:,1])]
x = np.array([[0,1,1],[1,1,1],[0,0,1],[1,0,1]])
result = np.round(nn.runforward(x, best_soln.reshape(3,1)))
print("best sol'n:\n%s\ncost:%s" % (best_soln,np.sum(nn.costfunction(nn.x, nn.y,
 best_soln.reshape(3,1)))))
print("when x = \n%s \nhthetax = \n%s" % (x[:,:2], result,))

(gen: #0) total error: 360.621647726

(gen: #1) total error: 164.147038902

(gen: #2) total error: 42.1044097511

(gen: #3) total error: 24.2327815785

(gen: #4) total error: 17.0591462061

(gen: #5) total error: 11.0531107277

(gen: #6) total error: 14.4015531463

(gen: #7) total error: 21.6185558409

(gen: #8) total error: 12.6716347732

(gen: #9) total error: 13.5456215099

best sol'n:
[[ 139.26240253    2.64168216   -8.3325537 ]]
cost:0.00721156902032
when x =
[[0 1]
 [1 1]
 [0 0]
 [1 0]]
hthetax =
[[ 0.]
 [ 1.]
 [ 0.]
 [ 1.]]

sweet!

   looks like it converged, finding a solution with a cost of only 0.007,
   pretty close to the error of the solution found with id119.
   notice i only ran it for 10 generations 1) because clearly that's all
   it takes and 2) because i didn't want a 20 page long document here.

where to go from here?

   first off, thanks. if you made it this far, i must've done something
   right.
   but if you want to do more, then i really encourage you to play around
   with the parameters, maybe change up the neural network, or change the
   neural network cost function, etc and see what happens. the best way to
   learn is to get your hands dirty. keep in mind this ga was kind of
   hard-wired for our little neural net by iamtrask, but if you understand
   the concepts and methods, you should be able to adapt it to more
   complex problems.

bonus! let's graph the population errors vs the generation #

   in [30]:
import matplotlib as plt
%matplotlib inline

   in [37]:
import random, numpy as np
import neuralnet as nn
params = [100, 0.05, 25, 3, 20] # [init pop (pop=100), mut rate (=5%), num gener
ations (250), chromosome/solution length (3), # winners/per gen]
curpop = np.random.choice(np.arange(-15,15,step=0.01),size=(params[0],params[3])
,replace=false) #initialize current population to random values within range
nextpop = np.zeros((curpop.shape[0], curpop.shape[1]))
fitvec = np.zeros((params[0], 2)) #1st col is indices, 2nd col is cost
for i in range(params[2]): #iterate through num generations
        fitvec = np.array([np.array([x, np.sum(nn.costfunction(nn.x, nn.y, curpo
p[x].reshape(3,1)))]) for x in range(params[0])]) #create vec of all errors from
 cost function
        plt.pyplot.scatter(i,np.sum(fitvec[:,1]))
        winners = np.zeros((params[4], params[3])) #20x2
        for n in range(len(winners)): #for n in range(10)
                selected = np.random.choice(range(len(fitvec)), params[4]/2, rep
lace=false)
                wnr = np.argmin(fitvec[selected,1])
                winners[n] = curpop[int(fitvec[selected[wnr]][0])]
        nextpop[:len(winners)] = winners #populate new gen with winners
        nextpop[len(winners):] = np.array([np.array(np.random.permutation(np.rep
eat(winners[:, x], ((params[0] - len(winners))/len(winners)), axis=0))) for x in
 range(winners.shape[1])]).t #populate the rest of the generation with offspring
 of mating pairs
        nextpop = np.multiply(nextpop, np.matrix([np.float(np.random.normal(0,2,
1)) if random.random() < params[1] else 1 for x in range(nextpop.size)]).reshape
(nextpop.shape)) #randomly mutate part of the population
        curpop = nextpop

best_soln = curpop[np.argmin(fitvec[:,1])]
x = np.array([[0,1,1],[1,1,1],[0,0,1],[1,0,1]])
result = np.round(nn.runforward(x, best_soln.reshape(3,1)))
print("best sol'n:\n%s\ncost:%s" % (best_soln,np.sum(nn.costfunction(nn.x, nn.y,
 best_soln.reshape(3,1)))))
print("when x = \n%s \nhthetax = \n%s" % (x[:,:2], result,))

best sol'n:
[[ 625.07750262  -48.12579247 -532.48348958]]
cost:1.11272735801e-231
when x =
[[0 1]
 [1 1]
 [0 0]
 [1 0]]
hthetax =
[[ 0.]
 [ 1.]
 [ 0.]
 [ 1.]]

/users/brandonbrown/desktop/projects/minigaandnn/neuralnet.py:15: runtimewarning
: overflow encountered in exp
  def sigmoid(x): return 1 / (1 + np.exp(- x))

   [85gq5dvkwaaaabjru5erkjggg== ]

   looks like we converge after just 4 generations! also notice we get
   these little bumps in error every 10 generations or so, likely due to a
   particularly dramatic mutation round.
   [9]posted at 00:00 by brandon brown     [10]id107    
   [11]ga  [12]evolution
   please enable javascript to view the [13]comments powered by disqus.

references

   visible links
   1. http://outlace.com/feeds/all.atom.xml
   2. http://outlace.com/
   3. http://outlace.com/pages/about.html
   4. http://outlace.com/tags/
   5. http://outlace.com/categories/
   6. http://outlace.com/archives/{slug}/
   7. http://outlace.com/
   8. http://outlace.com/miniga.html
   9. http://outlace.com/miniga.html
  10. http://outlace.com/category/genetic-algorithms/
  11. http://outlace.com/tag/ga/
  12. http://outlace.com/tag/evolution/
  13. https://disqus.com/?ref_noscript

   hidden links:
  15. mailto:outlacedev@gmail.com
  16. http://github.com/outlace
  17. http://outlace.com/feeds/all.atom.xml
