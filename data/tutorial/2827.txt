   #[1]      uantitative    ourney full atom feed

     * [2]home
     * [3]about
     * [4]tags
     * [5]categories
     * [6]archives

[7]      uantitative    ourney

    our experiences in learning quantitative applications

sep 12, 2015

[8]simple genetic algorithm in python --addendum

simple genetic algorithm in python --addendum[9]  

a brief addendum to my previous post [10]"simple genetic algorithm in 15
lines of python"[11]  

   first, i'd like to apologize for jumping on the
   here's-how-to-implement-x-in-y-lines-of-code bandwagon in my previous
   post. as many people have pointed out, who care's how many lines of
   code it takes to implement x as long as it's well-explained?

   okay, now that i've cleansed my soul of that sin, let's get to what
   this addendum is all about. basically this is just a quick
   demonstration of the same genetic algorithm (ga) from my last post
   except instead of using it to find the weights for that ultra-simple
   2-layer neural network, i've just modified it slightly to find the
   weights for a 3 layer xor neural network (yes, i'm tired of xor too,
   but it's just soo useful). so this neural network has a total of 13
   weights: 3x3 weights for the input-to-hidden layer, and 4x1 weights for
   the hidden-to-output layer.

   __why is this necessary?__ i received some comments that suggested
   doubt over whether the genetic algorithm is actually robust. i think
   that's valid because the problem it was solving was really too easy.
   with such a small search space, there was likely a good solution in the
   very first, randomly intialized, generation. thus it is a reasonable
   suspicion that our mutation and 'mating' process, for example, weren't
   actually contributing to solving the problem. extending our search
   space from a 3-element vector to a 13-element vector significantly
   increases the difficulty of the problem and we can see the ga utilizing
   all it's evolutionary 'tools,' so to speak.

   we'll begin by running it with some optimized parameters i figured out
   empirically, but then we'll explore the effects of varying the
   parameters and hopefully convince ourselves the ga is actually
   'evolving' toward an optimal solution versus doing something less
   interesting.

   i'm not going to go line-by-line and explain what's going on here,
   because i really haven't changed much from my previous post and this
   isn't meant to be a tutorial, it's an exploration. here's the code for
   the xor neural network (which i store in a separate file and import
   into the ga file).
   in [70]:
import numpy as np
import math

x = np.array([[0,0,1],[0,1,1],[1,0,1],[1,1,1]]) #the third element in each tuple
 is the bias value (1)
y = np.array([[0, 1, 1, 0]]).t
init_theta = 10*(np.random.random((13,1)) - 0.5) #lazy way to initialize

def runforward(x, theta):
        theta1 = np.array(theta[:9]).reshape(3,3)
        theta2 = np.array(theta[9:]).reshape(4,1)
        h1 = sigmoid(np.dot(x, theta1)) #4x3 * 3x3 = 4x3
        h1_bias = np.insert(h1, 3, [1,1,1,1], axis=1)
        output = sigmoid(np.dot(h1_bias, theta2)) #4x4 * 4x1 = 4x1
        return output
        #4x3 * 3x1 = 4x1
def costfunction(x, y, theta):
        m = float(len(x))
        hthetax = np.array(runforward(x, theta))
        return np.sum(np.abs(y - hthetax))
def sigmoid(x): return 1 / (1 + np.exp(- x))

def demorun():
        print("random theta: \n%s\n" % (np.round(runforward(x, init_theta), 2)))
        print("cost: %s\n" % (costfunction(x,y, init_theta)))
    #this "optimal theta" was found from a previous run of the ga
        theta = np.array([-10.27649069, -14.03, 10.45888659, 9.12, 14.87, -21.50
294038, 1.85, -13.28,
                       -0.15360052, -11.21345025, 35.77912716, 11.05, -2.4958957
7])
        print("optimal theta: \n%s\n" % (np.round(runforward(x, theta), 2)))
        print("cost: %s\n" % (costfunction(x, y, theta)))
demorun()

random theta:
[[ 0.71]
 [ 0.53]
 [ 0.74]
 [ 0.7 ]]

cost: 2.13729248257

optimal theta:
[[ 0.]
 [ 1.]
 [ 1.]
 [ 0.]]

cost: 0.00107762026703


   okay, just making sure the neural network works properly...and it
   does...

   keep in mind that we're working with 'unrolled' theta (weight) vectors.
   unlike my previous post that only had one set of weights between the
   two layers, now we have 3 layers but our ga is only going to generate
   and use 1-dimensional vectors of length 13, then our neural network
   will just slice that up to get two weight vectors, theta1 and theta2.
   i.e. theta1 = the first 9 elements reshaped to a 3x3 matrix, and theta2
   = the last 4 elements reshaped to a 4x1 matrix.

   here's the code for the ga. it's nearly exactly the same as the ga code
   posted at the bottom (the more readable version) of the previous post.

   i've made the following modifications to the paremeters:
    1. reduced the initial population (initpop) size to 80. why? to reduce
       chance of getting a good solution from the random first generation,
       i want to make sure to show off the evolutionary process.
    2. reduced mutation rate (mutrate) to 0.01 = 1%. i did this from
       experimenting.
    3. changed the number of generations (numgen) to 30
    4. increased the solution length from 3 to 13 (since our new unrolled
       theta vector is of length 13)

   alright, let's watch it run with those parameters:
   in [15]:
import matplotlib as plt
%matplotlib inline
import random as rn, numpy as np
import neuralnetxor as nn
# [initial population size, mutation rate (=1%), num generations (30), solution
length (30), # winners/per gen]
initpop, mutrate, numgen, sollen, numwin = 80, 0.01, 30, 13, 10
#initialize current population to random values within range
curpop = np.random.choice(np.arange(-15,15,step=0.01),size=(initpop, sollen),rep
lace=false)
nextpop = np.zeros((curpop.shape[0], curpop.shape[1]))
fitvec = np.zeros((initpop, 2)) #1st col is indices, 2nd col is cost
for i in range(numgen): #iterate through num generations
    #create vector of all errors from cost function for each solution
        fitvec = np.array([np.array([x, np.sum(nn.costfunction(nn.x, nn.y, curpo
p[x].t))]) for x in range(initpop)])
        plt.pyplot.scatter(i,np.sum(fitvec[:,1]))
        winners = np.zeros((numwin, sollen))
        for n in range(len(winners)): #for n in range(10)
                selected = np.random.choice(range(len(fitvec)), numwin/2, replac
e=false)
                wnr = np.argmin(fitvec[selected,1])
                winners[n] = curpop[int(fitvec[selected[wnr]][0])]
        nextpop[:len(winners)] = winners #populate new gen with winners
        duplicwin = np.zeros((((initpop - len(winners))),winners.shape[1]))
        for x in range(winners.shape[1]): #for each col in winners (3 cols)
        #duplicate winners (20x3 matrix) 3 times to create 80x3 matrix, then shu
ffle columns
                numdups = ((initpop - len(winners))/len(winners)) #num times to
duplicate to fill rest of nextpop
                duplicwin[:, x] = np.repeat(winners[:, x], numdups, axis=0)#dupl
icate each col
                duplicwin[:, x] = np.random.permutation(duplicwin[:, x]) #shuffl
e each col ("crossover")
    #populate the rest of the generation with offspring of mating pairs
        nextpop[len(winners):] = np.matrix(duplicwin)
    #create a mutation matrix, mostly 1s, but some elements are random numbers f
rom a normal distribution
        mutmatrix = [np.float(np.random.normal(0,2,1)) if rn.random() < mutrate
else 1 for x in range(nextpop.size)]
    #randomly mutate part of the population by multiplying nextpop by our mutati
on matrix
        nextpop = np.multiply(nextpop, np.matrix(mutmatrix).reshape(nextpop.shap
e))
        curpop = nextpop
plt.pyplot.ylabel('total cost/err')
plt.pyplot.xlabel('generation #')
best_soln = curpop[np.argmin(fitvec[:,1])]
x = np.array([[0,0,1],[0,1,1],[1,0,1],[1,1,1]])
result = np.round(nn.runforward(x, best_soln.t))
print("best sol'n:\n%s\ncost:%s" % (best_soln,np.sum(nn.costfunction(nn.x, nn.y,
 best_soln.t))))
print("when x = \n%s \nhthetax = \n%s" % (x[:,:2], result,))

best sol'n:
[[-10.27649069 -14.03        10.45888659   9.12        14.87       -21.50294038
    1.85       -13.28        -0.15360052 -11.21345025  35.77912716  11.05
   -2.49589577]]
cost:0.00107762027157
when x =
[[0 0]
 [0 1]
 [1 0]
 [1 1]]
hthetax =
[[ 0.]
 [ 1.]
 [ 1.]
 [ 0.]]

   [zcearvolnc2+dvjbihge+arwa+x8g4avlu9upgfa98aat5vb9t3g7iqfqeokk1cat5cp
   69m7fjkb1dfe3srjqmrzkyspkiehsapkseiskhkskqrkhoqkqzihiumqzehikiozepkksv8
   fx2st mx0nqd0aaaaasuvork5cyii= ]

   you can see it converges after about 10 generations, a little over
   twice as long as it took for the simple 2-layer neural network despite
   our search space is more than 4 times bigger. with the parameters i've
   used here, it properly converges almost every time i run it.

   now i want to demonstrate what it looks like when we change the
   mutation rate to 10% (i've removed all the comments to reduce the code
   size a bit).
   in [73]:
import matplotlib as plt, random as rn, numpy as np, neuralnetxor as nn
%matplotlib inline
initpop, mutrate, numgen, sollen, numwin = 80, 0.10, 30, 13, 10
curpop = np.random.choice(np.arange(-15,15,step=0.01),size=(initpop, sollen),rep
lace=false)
nextpop = np.zeros((curpop.shape[0], curpop.shape[1]))
fitvec = np.zeros((initpop, 2))
for i in range(numgen):
        fitvec = np.array([np.array([x, np.sum(nn.costfunction(nn.x, nn.y, curpo
p[x].t))]) for x in range(initpop)])
        plt.pyplot.scatter(i,np.sum(fitvec[:,1]))
        winners = np.zeros((numwin, sollen))
        for n in range(len(winners)):
                selected = np.random.choice(range(len(fitvec)), numwin/2, replac
e=false)
                wnr = np.argmin(fitvec[selected,1])
                winners[n] = curpop[int(fitvec[selected[wnr]][0])]
        nextpop[:len(winners)] = winners
        duplicwin = np.zeros((((initpop - len(winners))),winners.shape[1]))
        for x in range(winners.shape[1]):
                numdups = ((initpop - len(winners))/len(winners))
                duplicwin[:, x] = np.repeat(winners[:, x], numdups, axis=0)
                duplicwin[:, x] = np.random.permutation(duplicwin[:, x])
        nextpop[len(winners):] = np.matrix(duplicwin)
        mutmatrix = [np.float(np.random.normal(0,2,1)) if rn.random() < mutrate
else 1 for x in range(nextpop.size)]
        nextpop = np.multiply(nextpop, np.matrix(mutmatrix).reshape(nextpop.shap
e))
        curpop = nextpop
plt.pyplot.ylabel('total cost/err')
plt.pyplot.xlabel('generation #')
best_soln = curpop[np.argmin(fitvec[:,1])]
x = np.array([[0,0,1],[0,1,1],[1,0,1],[1,1,1]])
result = np.round(nn.runforward(x, best_soln.t))
print("best sol'n:\n%s\ncost:%s" % (best_soln,np.sum(nn.costfunction(nn.x, nn.y,
 best_soln.t))))
print("when x = \n%s \nhthetax = \n%s" % (x[:,:2], result,))

best sol'n:
[[ -8.01259712e+00   3.14587352e+01   1.40600000e+01   6.65543028e-02
    1.01012825e+02  -8.45144543e+01   8.72955079e+00  -1.04300000e+01
   -4.53000000e+00  -1.74629574e+01   2.64781112e+01   6.63253301e+01
   -1.97971192e+00]]
cost:1.00087335923
when x =
[[0 0]
 [0 1]
 [1 0]
 [1 1]]
hthetax =
[[ 0.]
 [ 1.]
 [ 1.]
 [ 1.]]

   [bwqdnifrfwxfaaaaaelftksuqmcc ]

   with a mutation rate of 10% the error trends downward but fails to
   converge (trust me, i ran it a few times, it almost never converges).
   this mutation rate is too big, any good solution is likely to just get
   destroyed by the mutation process.

   let's try a really low mutation rate, actually let's just make the
   mutation rate 0%.
   in [77]:
import matplotlib as plt, random as rn, numpy as np, neuralnetxor as nn
%matplotlib inline
initpop, mutrate, numgen, sollen, numwin = 80, 0.0, 30, 13, 10
curpop = np.random.choice(np.arange(-15,15,step=0.01),size=(initpop, sollen),rep
lace=false)
nextpop = np.zeros((curpop.shape[0], curpop.shape[1]))
fitvec = np.zeros((initpop, 2))
for i in range(numgen):
        fitvec = np.array([np.array([x, np.sum(nn.costfunction(nn.x, nn.y, curpo
p[x].t))]) for x in range(initpop)])
        plt.pyplot.scatter(i,np.sum(fitvec[:,1]))
        winners = np.zeros((numwin, sollen))
        for n in range(len(winners)):
                selected = np.random.choice(range(len(fitvec)), numwin/2, replac
e=false)
                wnr = np.argmin(fitvec[selected,1])
                winners[n] = curpop[int(fitvec[selected[wnr]][0])]
        nextpop[:len(winners)] = winners
        duplicwin = np.zeros((((initpop - len(winners))),winners.shape[1]))
        for x in range(winners.shape[1]):
                numdups = ((initpop - len(winners))/len(winners))
                duplicwin[:, x] = np.repeat(winners[:, x], numdups, axis=0)
                duplicwin[:, x] = np.random.permutation(duplicwin[:, x])
        nextpop[len(winners):] = np.matrix(duplicwin)
        mutmatrix = [np.float(np.random.normal(0,2,1)) if rn.random() < mutrate
else 1 for x in range(nextpop.size)]
        nextpop = np.multiply(nextpop, np.matrix(mutmatrix).reshape(nextpop.shap
e))
        curpop = nextpop
plt.pyplot.ylabel('total cost/err')
plt.pyplot.xlabel('generation #')
best_soln = curpop[np.argmin(fitvec[:,1])]
x = np.array([[0,0,1],[0,1,1],[1,0,1],[1,1,1]])
result = np.round(nn.runforward(x, best_soln.t))
print("best sol'n:\n%s\ncost:%s" % (best_soln,np.sum(nn.costfunction(nn.x, nn.y,
 best_soln.t))))
print("when x = \n%s \nhthetax = \n%s" % (x[:,:2], result,))

best sol'n:
[[  5.08 -12.1    6.61   0.48  14.44  -8.22  -9.47   1.94   8.45 -13.2
   -4.37  -4.07   6.79]]
cost:0.92032599599
when x =
[[0 0]
 [0 1]
 [1 0]
 [1 1]]
hthetax =
[[ 0.]
 [ 1.]
 [ 1.]
 [ 0.]]

   [rmkvzununl8aaaaasuvork5cyii= ]

   here the error trends downward and just flatlines every time. from
   running this a few times, it converges most of the time but not as
   frequently as with a mutation rate of 1%. also, you'll notice that the
   total error at the end is 0.92 and it generally stays about the same
   from a few runs. however, looking back when we used mutrate=0.01, the
   error get's really, really low at about 0.0011

   this demonstrates how a good mutation rate can help the ga escape local
   minima and maintain 'genetic diversity' in every generation.

   now let's return to our good mutation rate of 1% but let's disable the
   'mating' process by commenting out that line of code and see what
   happens.

mating disabled:[12]  

   in [84]:
import matplotlib as plt, random as rn, numpy as np, neuralnetxor as nn
%matplotlib inline
initpop, mutrate, numgen, sollen, numwin = 80, 0.01, 30, 13, 10
curpop = np.random.choice(np.arange(-15,15,step=0.01),size=(initpop, sollen),rep
lace=false)
nextpop = np.zeros((curpop.shape[0], curpop.shape[1]))
fitvec = np.zeros((initpop, 2))
for i in range(numgen):
        fitvec = np.array([np.array([x, np.sum(nn.costfunction(nn.x, nn.y, curpo
p[x].t))]) for x in range(initpop)])
        plt.pyplot.scatter(i,np.sum(fitvec[:,1]))
        winners = np.zeros((numwin, sollen))
        for n in range(len(winners)):
                selected = np.random.choice(range(len(fitvec)), numwin/2, replac
e=false)
                wnr = np.argmin(fitvec[selected,1])
                winners[n] = curpop[int(fitvec[selected[wnr]][0])]
        nextpop[:len(winners)] = winners
        duplicwin = np.zeros((((initpop - len(winners))),winners.shape[1]))
        for x in range(winners.shape[1]):
                numdups = ((initpop - len(winners))/len(winners))
                duplicwin[:, x] = np.repeat(winners[:, x], numdups, axis=0)
                #duplicwin[:, x] = np.random.permutation(duplicwin[:, x]) disabl
ed mating process
        nextpop[len(winners):] = np.matrix(duplicwin)
        mutmatrix = [np.float(np.random.normal(0,2,1)) if rn.random() < mutrate
else 1 for x in range(nextpop.size)]
        nextpop = np.multiply(nextpop, np.matrix(mutmatrix).reshape(nextpop.shap
e))
        curpop = nextpop
plt.pyplot.ylabel('total cost/err')
plt.pyplot.xlabel('generation #')
best_soln = curpop[np.argmin(fitvec[:,1])]
x = np.array([[0,0,1],[0,1,1],[1,0,1],[1,1,1]])
result = np.round(nn.runforward(x, best_soln.t))
print("best sol'n:\n%s\ncost:%s" % (best_soln,np.sum(nn.costfunction(nn.x, nn.y,
 best_soln.t))))
print("when x = \n%s \nhthetax = \n%s" % (x[:,:2], result,))

best sol'n:
[[ 17.04173136  10.77       -28.33009951 -10.72        -0.30622293
  -20.70366345  13.6         -3.37855753   3.62        13.16        -4.68347871
  -17.17325518  -1.88      ]]
cost:1.00371505771
when x =
[[0 0]
 [0 1]
 [1 0]
 [1 1]]
hthetax =
[[ 0.]
 [ 1.]
 [ 1.]
 [ 1.]]

   [afmu3gd8ctuhaaaa aelftksuqmcc ]

   this is a particularly interesting run (i ran it with these parameters
   about 8 times). it only correctly converged once (but didn't achieve
   the really low error rate we got in the beginning with 1% mut rate and
   mating enabled). the error vs. num generations graph looked quite
   different each time i ran it but i'm displaying this one because i
   think it illustrates nicely what happens when there's no mating.

   at first we get a sharp drop in error; it's simply selecting for the
   best solutions in our first generation. then it flattens out for awhile
   because we're having a really hard time improving on those initial
   decent solutions without mating, but eventually, due to a lucky
   mutation round, we get another sharp decline in error and then it
   flattens out again. but it's still not good enough to globally converge
   and solve the problem.

   clearly, the mating process is more important than the mutation
   process.

closing words...[13]  

   i hope that quells any concerns about the genetic algorithm not
   actually doing it's evolutionary due diligence. it's also just
   interesting to experiment with the parameters to see how it affects the
   performance of the algorithm.

   this is a simple genetic algorithm implementation. natural organisms
   have evolved much more sophisticated ways of controlling their own
   evolution. "in general, the mutation rate in unicellular eukaryotes and
   bacteria is roughly 0.003 mutations per genome per cell generation" -
   [14]wikipedia. this much lower than our 1% mutation rate, but our
   solution space is also much, much smaller.

   interestingly, however, different genes in the same organism can
   experience different rates of mutation. in fact, some organisms
   intentionally subject particular genes to higher rates of mutation (for
   example, the human immune system involves hypermutating the genes of
   antibodies to produce higher affinity versions; a sort of evolutionary
   process in the cells of our own bodies that evolved from an
   evolutionary process). it would be a fun experiment to try to emulate
   this behavior in a ga by allowing a separate mutation rate for each
   'gene' (element in a vector, in our case) and subjecting those mutation
   rates themselves to an evolutionary process. it's very unlikely this
   would help the ga for a simple feedforward neural network (and the
   overhead to implement it wouldn't be worth it) but could be useful with
   more complex problems.

   as a former neuroscience researcher and current medical student, i'm
   quite fascinated by "bio-similar" algorithms like gas and neural
   networks, so combining those two here has just filled me with nerd joy.

   cheers
   [15]posted at 00:00 by brandon brown     [16]id107    
   [17]ga  [18]evolution
   please enable javascript to view the [19]comments powered by disqus.

references

   visible links
   1. http://outlace.com/feeds/all.atom.xml
   2. http://outlace.com/
   3. http://outlace.com/pages/about.html
   4. http://outlace.com/tags/
   5. http://outlace.com/categories/
   6. http://outlace.com/archives/{slug}/
   7. http://outlace.com/
   8. http://outlace.com/miniga_addendum.html
   9. http://outlace.com/miniga_addendum.html#simple-genetic-algorithm-in-python---addendum
  10. http://outlace.com/simple-genetic-algorithm-in-15-lines-of-python/
  11. http://outlace.com/miniga_addendum.html#a-brief-addendum-to-my-previous-post-"simple-genetic-algorithm-in-15-lines-of-python"
  12. http://outlace.com/miniga_addendum.html#mating-disabled:
  13. http://outlace.com/miniga_addendum.html#closing-words...
  14. https://en.wikipedia.org/wiki/mutation_rate
  15. http://outlace.com/miniga_addendum.html
  16. http://outlace.com/category/genetic-algorithms/
  17. http://outlace.com/tag/ga/
  18. http://outlace.com/tag/evolution/
  19. https://disqus.com/?ref_noscript

   hidden links:
  21. mailto:outlacedev@gmail.com
  22. http://github.com/outlace
  23. http://outlace.com/feeds/all.atom.xml
