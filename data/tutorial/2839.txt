   #[1]github [2]recent commits to awesome-rl:master

   [3]skip to content

   (button)

     * why github?
       [4]features    
          + [5]code review
          + [6]project management
          + [7]integrations
          + [8]actions
          + [9]team management
          + [10]social coding
          + [11]documentation
          + [12]code hosting
          + [13]customer stories    
          + [14]security    
     * [15]enterprise
     * explore
          + [16]explore github    

learn & contribute
          + [17]topics
          + [18]collections
          + [19]trending
          + [20]learning lab
          + [21]open source guides

connect with others
          + [22]events
          + [23]community forum
          + [24]github education
     * [25]marketplace
     * pricing
       [26]plans    
          + [27]compare plans
          + [28]contact sales
          + [29]nonprofit    
          + [30]education    

   ____________________
     * in this repository all github    
       jump to    

     * no suggested jump to results

     * in this repository all github    
       jump to    
     * in this repository all github    
       jump to    

   [31]sign in [32]sign up

     * [33]watch [34]433
     * [35]star [36]5,312
     * [37]fork [38]1,255

[39]aikorea/[40]awesome-rl

   [41]code [42]issues 4 [43]pull requests 11 [44]projects 0 [45]wiki
   [46]insights
   (button) dismiss

join github today

   github is home to over 31 million developers working together to host
   and review code, manage projects, and build software together.
   [47]sign up
   id23 resources curated
   [48]http://aikorea.org/awesome-rl
     * [49]161 commits
     * [50]2 branches
     * [51]0 releases
     * [52]fetching contributors

   branch: master (button) new pull request
   [53]find file
   clone or download

clone with https

   use git or checkout with svn using the web url.
   https://github.com/a
   [54]download zip

downloading...

   want to be notified of new releases in aikorea/awesome-rl?
   [55]sign in [56]sign up

launching github desktop...

   if nothing happens, [57]download github desktop and try again.

   (button) go back

launching github desktop...

   if nothing happens, [58]download github desktop and try again.

   (button) go back

launching xcode...

   if nothing happens, [59]download xcode and try again.

   (button) go back

launching visual studio...

   if nothing happens, [60]download the github extension for visual studio
   and try again.

   (button) go back
   [61]@hshyunsookim
   [62]hshyunsookim [63]merge pull request [64]#63 [65]from
   dekatria/master (button)    
added deepmind's trfl to list of open source libraries

   latest commit [66]53a8de3 dec 9, 2018
   [67]permalink
   type      name     latest commit message commit time
        failed to load latest commit information.
        [68]readme.md

readme.md

awesome id23 [69]awesome

   a curated list of resources dedicated to id23.

   we have pages for other topics: [70]awesome-id56,
   [71]awesome-deep-vision, [72]awesome-random-forest

   maintainers: [73]hyunsoo kim, [74]jiwon kim

   we are looking for more contributors and maintainers!

contributing

   please feel free to [75]pull requests

table of contents

     * [76]codes
     * [77]theory
          + [78]lectures
          + [79]books
          + [80]surveys
          + [81]papers / thesis
     * [82]applications
          + [83]game playing
          + [84]robotics
          + [85]control
          + [86]operations research
          + [87]human computer interaction
     * [88]tutorials / websites
     * [89]online demos
     * [90]open source id23 platforms

codes

     * codes for examples and exercises in richard sutton and andrew
       barto's id23: an introduction
          + [91]python code
          + [92]matlab code
          + [93]c/lisp code
          + [94]book
     * simulation code for id23 control problems
          + [95]pole-cart problem
          + [96]id24 controller
     * [97]matlab environment and gui for id23
     * [98]id23 repository - university of
       massachusetts, amherst
     * [99]brown-umbc id23 and planning library (java)
     * [100]id23 in r (mdp, value iteration)
     * [101]id23 environment in python and matlab
     * [102]rl-glue (standard interface for rl) and [103]rl-glue library
     * [104]pybrain library - python-based id23,
       artificial intelligence, and neural network
     * [105]rlpy framework - value-function-based id23
       framework for education and research
     * [106]maja - machine learning framework for problems in
       id23 in python
     * [107]teachingbox - java based id23 framework
     * [108]policy gradient id23 toolbox for matlab
     * [109]piqle - platform implementing id24 and other rl
       algorithms
     * [110]beliefbox - bayesian id23 library and
       toolkit
     * [111]deep id24 with tensorflow - a deep id24
       demonstration using google tensorflow
     * [112]atari - deep q-networks and asynchronous agents in torch
     * [113]agentnet - a python library for deep id23
       and custom recurrent networks using theano+lasagne.
     * [114]id23 examples by rlcode - a collection of
       minimal and clean id23 examples
     * [115]openai baselines - well tested implementations ([116]and
       results) of id23 algorithms from openai
     * [117]pytorch deep rl - popular deep rl algorithm implementations
       with pytorch
     * [118]chainerrl - popular deep rl algorithm implementations with
       chainer
     * [119]black-drops - modular and generic code for the model-based
       policy search black-drops algorithm (iros 2017 paper) and easy
       integration with the [120]dart simulator

theory

lectures

     * [ucl] [121]compm050/compgi13 id23 by david silver
     * [uc berkeley] cs188 artificial intelligence by pieter abbeel
          + [122]lecture 8: id100 1
          + [123]lecture 9: id100 2
          + [124]lecture 10: id23 1
          + [125]lecture 11: id23 2
     * [udacity (georgia tech.)] [126]cs7642 id23
     * [stanford] [127]cs229 machine learning - lecture 16: reinforcement
       learning by andrew ng
     * [uc berkeley] [128]deep rl bootcamp
     * [uc berkeley] [129]cs294 deep id23 by john
       schulman and pieter abbeel
     * [cmu] [130]10703: deep id23 and control, spring
       2017
     * [mit] [131]6.s094: deep learning for self-driving cars
          + [132]lecture 2: deep id23 for motion
            planning
     * [siraj raval]: introduction to ai for video games (reinforcement
       learning video series)
          + [133]introduction to ai for video games
          + [134]monte carlo prediction
          + [135]id24 explained
          + [136]solving the basic game of pong
          + [137]actor critic algorithms
          + [138]war robots

books

     * richard sutton and andrew barto, id23: an
       introduction (1st edition, 1998) [139][book] [140][code]
     * richard sutton and andrew barto, id23: an
       introduction (2nd edition, in progress, 2018) [141][book]
       [142][code]
     * csaba szepesvari, algorithms for id23 [143][book]
     * david poole and alan mackworth, artificial intelligence:
       foundations of computational agents [144][book chapter]
     * dimitri p. bertsekas and john n. tsitsiklis, neuro-dynamic
       programming [145][book (amazon)] [146][summary]
     * mykel j. kochenderfer, decision making under uncertainty: theory
       and application [147][book (amazon)]
     * deep id23 in action [148][book(manning)]

surveys

     * leslie pack kaelbling, michael l. littman, andrew w. moore,
       id23: a survey, jair, 1996. [149][paper]
     * s. s. keerthi and b. ravindran, a tutorial survey of reinforcement
       learning, sadhana, 1994. [150][paper]
     * matthew e. taylor, peter stone, id21 for reinforcement
       learning domains: a survey, jmlr, 2009. [151][paper]
     * jens kober, j. andrew bagnell, jan peters, id23
       in robotics, a survey, ijrr, 2013. [152][paper]
     * michael l. littman, "id23 improves behaviour from
       evaluative feedback." nature 521.7553 (2015): 445-451. [153][paper]
     * marc p. deisenroth, gerhard neumann, jan peter, a survey on policy
       search for robotics, foundations and trends in robotics, 2014.
       [154][book]
     * kai arulkumaran, marc peter deisenroth, miles brundage, anil
       anthony bharath, a brief survey of deep rei nforcement learning,
       ieee signal processing magazine, 2017. [155][paper]

papers / thesis

   foundational papers
     * marvin minsky, steps toward artificial intelligence, proceedings of
       the ire, 1961. [156][paper] (discusses issues in rl such as the
       "credit assignment problem")
     * ian h. witten, an adaptive optimal controller for discrete-time
       markov environments, information and control, 1977. [157][paper]
       (earliest publication on temporal-difference (td) learning rule)

   methods
     * id145 (dp):
          + christopher j. c. h. watkins, learning from delayed rewards,
            ph.d. thesis, cambridge university, 1989. [158][thesis]
     * monte carlo:
          + andrew barto, michael duff, monte carlo inversion and
            id23, nips, 1994. [159][paper]
          + satinder p. singh, richard s. sutton, id23
            with replacing eligibility traces, machine learning, 1996.
            [160][paper]
     * temporal-difference:
          + richard s. sutton, learning to predict by the methods of
            temporal differences. machine learning 3: 9-44, 1988.
            [161][paper]
     * id24 (off-policy td algorithm):
          + chris watkins, learning from delayed rewards, cambridge, 1989.
            [162][thesis]
     * sarsa (on-policy td algorithm):
          + g.a. rummery, m. niranjan, on-line id24 using
            connectionist systems, technical report, cambridge univ.,
            1994. [163][report]
          + richard s. sutton, generalization in id23:
            successful examples using sparse coding, nips, 1996.
            [164][paper]
     * r-learning (learning of relative values)
          + andrew schwartz, a id23 method for
            maximizing undiscounted rewards, icml, 1993.
            [165][paper-google scholar]
     * function approximation methods (least-square temporal difference,
       least-square policy iteration)
          + steven j. bradtke, andrew g. barto, linear least-squares
            algorithms for temporal difference learning, machine learning,
            1996. [166][paper]
          + michail g. lagoudakis, ronald parr, model-free least squares
            policy iteration, nips, 2001. [167][paper] [168][code]
     * policy search / policy gradient
          + richard sutton, david mcallester, satinder singh, yishay
            mansour, id189 for id23
            with function approximation, nips, 1999. [169][paper]
          + jan peters, sethu vijayakumar, stefan schaal, natural
            actor-critic, ecml, 2005. [170][paper]
          + jens kober, jan peters, policy search for motor primitives in
            robotics, nips, 2009. [171][paper]
          + jan peters, katharina mulling, yasemin altun, relative id178
            policy search, aaai, 2010. [172][paper]
          + freek stulp, olivier sigaud, path integral policy improvement
            with covariance matrix adaptation, icml, 2012. [173][paper]
          + nate kohl, peter stone, policy gradient id23
            for fast quadrupedal locomotion, icra, 2004. [174][paper]
          + marc deisenroth, carl rasmussen, pilco: a model-based and
            data-efficient approach to policy search, icml, 2011.
            [175][paper]
          + scott kuindersma, roderic grupen, andrew barto, learning
            dynamic arm motions for postural recovery, humanoids, 2011.
            [176][paper]
          + konstantinos chatzilygeroudis, roberto rama, rituraj kaushik,
            dorian goepp, vassilis vassiliades, jean-baptiste mouret,
            black-box data-efficient policy search for robotics, iros,
            2017. [[177]paper]
     * hierarchical rl
          + richard sutton, doina precup, satinder singh, between mdps and
            semi-mdps: a framework for temporal abstraction in
            id23, artificial intelligence, 1999.
            [178][paper]
          + george konidaris, andrew barto, building portable options:
            skill transfer in id23, ijcai, 2007.
            [179][paper]
     * deep learning + id23 (a sample of recent works on
       dl+rl)
          + v. mnih, et. al., human-level control through deep
            id23, nature, 2015. [180][paper]
          + xiaoxiao guo, satinder singh, honglak lee, richard lewis,
            xiaoshi wang, deep learning for real-time atari game play
            using offline monte-carlo tree search planning, nips, 2014.
            [181][paper]
          + sergey levine, chelsea finn, trevor darrel, pieter abbeel,
            end-to-end training of deep visuomotor policies. arxiv, 16 oct
            2015. [182][arxiv]
          + tom schaul, john quan, ioannis antonoglou, david silver,
            prioritized experience replay, arxiv, 18 nov 2015.
            [183][arxiv]
          + hado van hasselt, arthur guez, david silver, deep
            id23 with double id24, arxiv, 22 sep
            2015. [184][arxiv]
          + volodymyr mnih, adri   puigdom  nech badia, mehdi mirza, alex
            graves, timothy p. lillicrap, tim harley, david silver, koray
            kavukcuoglu, asynchronous methods for deep reinforcement
            learning, arxiv, 4 feb 2016. [185][arxiv]

applications

game playing

   traditional games
     * backgammon - "td-gammon" game play using td(  ) (tesauro, acm 1995)
       [186][paper]
     * chess - "knightcap" program using td(  ) (baxter, arxiv 1999)
       [187][arxiv]
     * chess - giraffe: using deep id23 to play chess
       (lai, arxiv 2015) [188][arxiv]

   computer games
     * human-level control through deep id23 (mnih,
       nature 2015) [189][paper] [190][code] [191][video]
     * [192]flappy bird id23 [193][video]
     * mari/o - learning to play mario with evolutionary reinforcement
       learning using id158s (stanley, evolutionary
       computation 2002) [194][paper] [195][video]

robotics

     * policy gradient id23 for fast quadrupedal
       locomotion (kohl, icra 2004) [196][paper]
     * robot motor skill coordination with em-based id23
       (kormushev, iros 2010) [197][paper] [198][video]
     * generalized model learning for id23 on a humanoid
       robot (hester, icra 2010) [199][paper] [200][video]
     * autonomous skill acquisition on a mobile manipulator (konidaris,
       aaai 2011) [201][paper] [202][video]
     * pilco: a model-based and data-efficient approach to policy search
       (deisenroth, icml 2011) [203][paper]
     * incremental semantically grounded learning from demonstration
       (niekum, rss 2013) [204][paper]
     * efficient id23 for robots using informative
       simulated priors (cutler, icra 2015) [205][paper] [206][video]
     * robots that can adapt like animals (cully, nature 2015)
       [[207]paper] [[208]video] [[209]code]
     * black-box data-efficient policy search for robotics
       (chatzilygeroudis, iros 2017) [[210]paper] [[211]video] [[212]code]

control

     * an application of id23 to aerobatic helicopter
       flight (abbeel, nips 2006) [213][paper] [214][video]
     * autonomous helicopter control using id23 policy
       search methods (bagnell, icra 2001) [215][paper]

operations research

     * scaling average-reward id23 for product delivery
       (proper, aaai 2004) [216][paper]
     * cross channel optimized marketing by id23 (abe,
       kdd 2004) [217][paper]

human computer interaction

     * optimizing dialogue management with id23:
       experiments with the njfun system (singh, jair 2002) [218][paper]

tutorials / websites

     * mance harmon and stephanie harmon, [219]id23: a
       tutorial
     * c. igel, m.a. riedmiller, et al., id23 in a
       nutshell, esann, 2007. [220][paper]
     * unsw - [221]id23
          + [222]introduction
          + [223]td-learning
          + [224]id24 and sarsa
          + [225]applet for "cat and mouse" game
     * [226]ros id23 tutorial
     * [227]pomdp for dummies
     * scholarpedia articles on:
          + [228]id23
          + [229]temporal difference learning
     * repository with useful [230]matlab software, presentations, and
       demo videos
     * [231]bibliography on id23
     * uc berkeley - cs 294: deep id23, fall 2015 (john
       schulman, pieter abbeel) [232][class website]
     * [233]blog posts on id23, parts 1-4 by travis
       dewolf
     * [234]the arcade learning environment - atari 2600 games environment
       for developing ai agents
     * [235]deep id23: pong from pixels by andrej
       karpathy
     * [236]demystifying deep id23
     * [237]let   s make a id25
     * [238]simple id23 with tensorflow, parts 0-8 by
       arthur juliani
     * [239]practical_rl - github-based course in id23
       in the wild (lectures, coding labs, projects)
     * [240]rlenv.directory: explore and find new id23
       environments.

online demos

     * [241]real-world demonstrations of id23
     * [242]deep id24 demo - a deep id24 demonstration using
       convnetjs
     * [243]deep id24 with tensor flow - a deep id24
       demonstration using google tensorflow
     * [244]id23 demo - a id23 demo
       using reinforcejs by andrej karpathy

open source id23 platforms

     * [245]openai gym - a toolkit for developing and comparing
       id23 algorithms
     * [246]openai universe - a software platform for measuring and
       training an ai's general intelligence across the world's supply of
       games, websites and other applications
     * [247]deepmind lab - a customisable 3d platform for agent-based ai
       research
     * [248]project malmo - a platform for artificial intelligence
       experimentation and research built on top of minecraft by microsoft
     * [249]vizdoom - doom-based ai research platform for reinforcement
       learning from raw visual information
     * [250]retro learning environment - an ai platform for reinforcement
       learning based on video game emulators. currently supports snes and
       sega genesis. compatible with openai gym.
     * [251]torch-twrl - a package that enables id23 in
       torch by twitter
     * [252]uetorch - a torch plugin for unreal engine 4 by facebook
     * [253]torchcraft - connecting torch to starcraft
     * [254]rllab - a framework for developing and evaluating
       id23 algorithms, fully compatible with openai gym
     * [255]tensorforce - practical deep id23 on
       tensorflow with gitter support and openai gym/universe/deepmind lab
       integration.
     * [256]tf-trfl - a library built on top of tensorflow that exposes
       several useful building blocks for implementing reinforcement
       learning agents.
     * [257]openai lab - an experimentation system for reinforcement
       learning using openai gym, tensorflow, and keras.
     * [258]keras-rl - state-of-the art deep id23
       algorithms in keras designed for compatibility with openai.
     * [259]burlap - brown-umbc id23 and planning, a
       library written in java
     * [260]magent - a platform for many-agent id23.
     * [261]ray rllib - ray rllib is a id23 library that
       aims to provide both performance and composability.
     * [262]slm lab - a research framework for deep id23
       using unity, openai gym, pytorch, tensorflow.
     * [263]unity ml agents - create id23 environments
       using the unity editor
     * [264]intel coach - coach is a python id23
       research framework containing implementation of many
       state-of-the-art algorithms.

     *    2019 github, inc.
     * [265]terms
     * [266]privacy
     * [267]security
     * [268]status
     * [269]help

     * [270]contact github
     * [271]pricing
     * [272]api
     * [273]training
     * [274]blog
     * [275]about

   (button) you can   t perform that action at this time.

   you signed in with another tab or window. [276]reload to refresh your
   session. you signed out in another tab or window. [277]reload to
   refresh your session.

   (button)

references

   visible links
   1. https://github.com/opensearch.xml
   2. https://github.com/aikorea/awesome-rl/commits/master.atom
   3. https://github.com/aikorea/awesome-rl#start-of-content
   4. https://github.com/features
   5. https://github.com/features/code-review/
   6. https://github.com/features/project-management/
   7. https://github.com/features/integrations
   8. https://github.com/features/actions
   9. https://github.com/features#team-management
  10. https://github.com/features#social-coding
  11. https://github.com/features#documentation
  12. https://github.com/features#code-hosting
  13. https://github.com/customer-stories
  14. https://github.com/security
  15. https://github.com/enterprise
  16. https://github.com/explore
  17. https://github.com/topics
  18. https://github.com/collections
  19. https://github.com/trending
  20. https://lab.github.com/
  21. https://opensource.guide/
  22. https://github.com/events
  23. https://github.community/
  24. https://education.github.com/
  25. https://github.com/marketplace
  26. https://github.com/pricing
  27. https://github.com/pricing#feature-comparison
  28. https://enterprise.github.com/contact
  29. https://github.com/nonprofit
  30. https://education.github.com/
  31. https://github.com/login?return_to=/aikorea/awesome-rl
  32. https://github.com/join
  33. https://github.com/login?return_to=/aikorea/awesome-rl
  34. https://github.com/aikorea/awesome-rl/watchers
  35. https://github.com/login?return_to=/aikorea/awesome-rl
  36. https://github.com/aikorea/awesome-rl/stargazers
  37. https://github.com/login?return_to=/aikorea/awesome-rl
  38. https://github.com/aikorea/awesome-rl/network/members
  39. https://github.com/aikorea
  40. https://github.com/aikorea/awesome-rl
  41. https://github.com/aikorea/awesome-rl
  42. https://github.com/aikorea/awesome-rl/issues
  43. https://github.com/aikorea/awesome-rl/pulls
  44. https://github.com/aikorea/awesome-rl/projects
  45. https://github.com/aikorea/awesome-rl/wiki
  46. https://github.com/aikorea/awesome-rl/pulse
  47. https://github.com/join?source=prompt-code
  48. http://aikorea.org/awesome-rl
  49. https://github.com/aikorea/awesome-rl/commits/master
  50. https://github.com/aikorea/awesome-rl/branches
  51. https://github.com/aikorea/awesome-rl/releases
  52. https://github.com/aikorea/awesome-rl/graphs/contributors
  53. https://github.com/aikorea/awesome-rl/find/master
  54. https://github.com/aikorea/awesome-rl/archive/master.zip
  55. https://github.com/login?return_to=https://github.com/aikorea/awesome-rl
  56. https://github.com/join?return_to=/aikorea/awesome-rl
  57. https://desktop.github.com/
  58. https://desktop.github.com/
  59. https://developer.apple.com/xcode/
  60. https://visualstudio.github.com/
  61. https://github.com/hshyunsookim
  62. https://github.com/aikorea/awesome-rl/commits?author=hshyunsookim
  63. https://github.com/aikorea/awesome-rl/commit/53a8de3399d9ed4dd6325bf258dedea2858b9427
  64. https://github.com/aikorea/awesome-rl/pull/63
  65. https://github.com/aikorea/awesome-rl/commit/53a8de3399d9ed4dd6325bf258dedea2858b9427
  66. https://github.com/aikorea/awesome-rl/commit/53a8de3399d9ed4dd6325bf258dedea2858b9427
  67. https://github.com/aikorea/awesome-rl/tree/53a8de3399d9ed4dd6325bf258dedea2858b9427
  68. https://github.com/aikorea/awesome-rl/blob/master/readme.md
  69. https://github.com/sindresorhus/awesome
  70. https://github.com/kjw0612/awesome-id56
  71. https://github.com/kjw0612/awesome-deep-vision
  72. https://github.com/kjw0612/awesome-random-forest
  73. http://sites.duke.edu/hyunsookim/
  74. http://github.com/kjw0612
  75. https://github.com/aikorea/awesome-rl/pulls
  76. https://github.com/aikorea/awesome-rl#codes
  77. https://github.com/aikorea/awesome-rl#theory
  78. https://github.com/aikorea/awesome-rl#lectures
  79. https://github.com/aikorea/awesome-rl#books
  80. https://github.com/aikorea/awesome-rl#surveys
  81. https://github.com/aikorea/awesome-rl#papers--thesis
  82. https://github.com/aikorea/awesome-rl#applications
  83. https://github.com/aikorea/awesome-rl#game-playing
  84. https://github.com/aikorea/awesome-rl#robotics
  85. https://github.com/aikorea/awesome-rl#control
  86. https://github.com/aikorea/awesome-rl#operations-research
  87. https://github.com/aikorea/awesome-rl#human-computer-interaction
  88. https://github.com/aikorea/awesome-rl#tutorials--websites
  89. https://github.com/aikorea/awesome-rl#online-demos
  90. https://github.com/aikorea/awesome-rl#open-source-reinforcement-learning-platforms
  91. https://github.com/shangtongzhang/reinforcement-learning-an-introduction
  92. http://waxworksmath.com/authors/n_z/sutton/sutton.html
  93. https://webdocs.cs.ualberta.ca/~sutton/book/code/code.html
  94. http://webdocs.cs.ualberta.ca/~sutton/book/ebook/the-book.html
  95. http://pages.cs.wisc.edu/~finton/poledriver.html
  96. http://pages.cs.wisc.edu/~finton/qcontroller.html
  97. http://www.cs.colostate.edu/~anderson/res/rl/matlabpaper/rl.html
  98. http://www-anw.cs.umass.edu/rlr/
  99. http://burlap.cs.brown.edu/
 100. http://www.moneyscience.com/pg/blog/statalgo/read/635759/reinforcement-learning-in-r-markov-decision-process-mdp-and-value-iteration
 101. https://jamh-web.appspot.com/download.htm
 102. http://glue.rl-community.org/wiki/main_page
 103. http://library.rl-community.org/wiki/main_page
 104. http://www.pybrain.org/
 105. http://rlpy.readthedocs.org/en/latest/
 106. http://mmlf.sourceforge.net/
 107. http://servicerobotik.hs-weingarten.de/en/teachingbox.php
 108. http://www.ias.informatik.tu-darmstadt.de/research/policygradienttoolbox
 109. http://sourceforge.net/projects/piqle/
 110. https://code.google.com/p/beliefbox/
 111. https://github.com/nivwusquorum/tensorflow-deepq
 112. https://github.com/kaixhin/atari
 113. https://github.com/yandexdataschool/agentnet
 114. https://github.com/rlcode/reinforcement-learning
 115. https://github.com/openai/baselines
 116. https://github.com/openai/baselines-results
 117. https://github.com/shangtongzhang/deeprl
 118. https://github.com/chainer/chainerrl
 119. https://github.com/resibots/blackdrops
 120. http://dartsim.github.io/
 121. http://www0.cs.ucl.ac.uk/staff/d.silver/web/teaching.html
 122. https://www.youtube.com/watch?v=i0o-ui1n35u
 123. https://www.youtube.com/watch?v=csiiv6wgzkm
 124. https://www.youtube.com/watch?v=ifma8g7lege
 125. https://www.youtube.com/watch?v=si1_ytw960c
 126. https://classroom.udacity.com/courses/ud600
 127. https://www.youtube.com/watch?v=rtxi449zjsc&feature=relmfu
 128. https://sites.google.com/view/deep-rl-bootcamp/lectures
 129. http://rll.berkeley.edu/deeprlcourse/
 130. https://katefvision.github.io/
 131. http://selfdrivingcars.mit.edu/
 132. https://www.youtube.com/watch?v=qdzm8r3wgbw&list=plraxtmerzgoeikm4sgnokngvnjby9efdf
 133. https://youtu.be/i_mcnbdp9qs
 134. https://youtu.be/-ypalutqckw
 135. https://youtu.be/acevtrtno-m
 136. https://youtu.be/pn7etkoizgm
 137. https://youtu.be/w_3mmm0p0j8
 138. https://youtu.be/tm5kqmjfzn8
 139. http://incompleteideas.net/book/ebook/the-book.html
 140. http://incompleteideas.net/book/code/code.html
 141. http://incompleteideas.net/book/bookdraft2018jan1.pdf
 142. https://github.com/shangtongzhang/reinforcement-learning-an-introduction
 143. http://www.ualberta.ca/~szepesva/papers/rlalgsinmdps.pdf
 144. http://artint.info/html/artint_262.html
 145. http://www.amazon.com/neuro-dynamic-programming-optimization-neural-computation/dp/1886529108/ref=sr_1_3?s=books&ie=utf8&qid=1442461075&sr=1-3&refinements=p_27:john+n.+tsitsiklis+dimitri+p.+bertsekas
 146. http://www.mit.edu/~dimitrib/ndp_encycl.pdf
 147. http://www.amazon.com/decision-making-under-uncertainty-application/dp/0262029251/ref=sr_1_1?ie=utf8&qid=1441126550&sr=8-1&keywords=kochenderfer&pebp=1441126551594&perid=1y6rg2egrd26659cjhh9
 148. https://www.manning.com/books/deep-reinforcement-learning-in-action
 149. https://www.jair.org/media/301/live-301-1562-jair.pdf
 150. http://www.cse.iitm.ac.in/~ravi/papers/keerthi.rl-survey.pdf
 151. http://machinelearning.wustl.edu/mlpapers/paper_files/jmlr10_taylor09a.pdf
 152. http://www.ias.tu-darmstadt.de/uploads/publications/kober_ijrr_2013.pdf
 153. http://www.nature.com/nature/journal/v521/n7553/full/nature14540.html
 154. https://spiral.imperial.ac.uk:8443/bitstream/10044/1/12051/7/fnt_corrected_2014-8-22.pdf
 155. https://arxiv.org/abs/1708.05866
 156. http://staffweb.worc.ac.uk/drc/courses 2010-11/comp 3104/tutor inputs/session 9 prep/reading material/minsky60steps.pdf
 157. http://www.cs.waikato.ac.nz/~ihw/papers/77-ihw-adaptivecontroller.pdf
 158. https://www.cs.rhul.ac.uk/home/chrisw/new_thesis.pdf
 159. http://papers.nips.cc/paper/865-monte-carlo-matrix-inversion-and-reinforcement-learning.pdf
 160. http://www-all.cs.umass.edu/pubs/1995_96/singh_s_ml96.pdf
 161. http://webdocs.cs.ualberta.ca/~sutton/papers/sutton-88-with-erratum.pdf
 162. http://www.cs.rhul.ac.uk/home/chrisw/thesis.html
 163. https://www.google.com/url?sa=t&rct=j&q=&esrc=s&source=web&cd=3&ved=0cdiqfjacahukewj2lmm5wzdiahuhkg0kha6kavm&url=ftp://mi.eng.cam.ac.uk/pub/reports/auto-pdf/rummery_tr166.pdf&usg=afqjcnhz6irgcaao5lzc7t8oeiby9epozg&sig2=sa-empme1m5jav7ymaxsnq&cad=rja
 164. http://webdocs.cs.ualberta.ca/~sutton/papers/sutton-96.pdf
 165. https://scholar.google.com/scholar?q=reinforcement+learning+method+for+maximizing+undiscounted+rewards&hl=en&as_sdt=0&as_vis=1&oi=scholart&sa=x&ved=0cbsqgqmwagovchmiho6p_moqyaivwh0ech3xwawm
 166. http://www-anw.cs.umass.edu/pubs/1995_96/bradtke_b_ml96.pdf
 167. http://www.cs.duke.edu/research/ai/lspi/nips01.pdf
 168. http://www.cs.duke.edu/research/ai/lspi/
 169. http://papers.nips.cc/paper/1713-policy-gradient-methods-for-reinforcement-learning-with-function-approximation.pdf
 170. https://homes.cs.washington.edu/~todorov/courses/amath579/reading/naturalactorcritic.pdf
 171. http://papers.nips.cc/paper/3545-policy-search-for-motor-primitives-in-robotics.pdf
 172. http://www.kyb.tue.mpg.de/fileadmin/user_upload/files/publications/attachments/aaai-2010-peters_6439[0].pdf
 173. http://arxiv.org/pdf/1206.4621v1.pdf
 174. http://www.cs.utexas.edu/~pstone/papers/bib2html-links/icra04.pdf
 175. http://mlg.eng.cam.ac.uk/pub/pdf/deiras11.pdf
 176. http://www-all.cs.umass.edu/pubs/2011/kuindersma_g_b_11.pdf
 177. https://arxiv.org/abs/1703.07261
 178. https://webdocs.cs.ualberta.ca/~sutton/papers/sps-aij.pdf
 179. http://www-anw.cs.umass.edu/pubs/2007/konidaris_b_ijcai07.pdf
 180. http://www.readcube.com/articles/10.1038/nature14236?shared_access_token=lo_2hfdw4muqecf3cvbzm9rgn0jajwel9jnr3zotv0p5kedccnjz3fj2fhqcgxkapor3zssjaldp-tw3iwgtsernlpac9xqq-vta2z5ji9lg16_wvcy4saogpk5xxa6ecqo8d8j7l4ejsdjwai53gqkt-7juiog0r3iv67mqiro74l6ixvmcvnkbgowimgi8u0izjstlpmqp6vmi_8lw_a==
 181. http://papers.nips.cc/paper/5421-deep-learning-for-real-time-atari-game-play-using-offline-monte-carlo-tree-search-planning.pdf
 182. http://arxiv.org/pdf/1504.00702v3.pdf
 183. http://arxiv.org/pdf/1511.05952v2.pdf
 184. http://arxiv.org/abs/1509.06461
 185. https://arxiv.org/abs/1602.01783
 186. http://www.bkgm.com/articles/tesauro/tdl.html
 187. http://arxiv.org/pdf/cs/9901002v1.pdf
 188. http://arxiv.org/pdf/1509.01549v2.pdf
 189. http://www.readcube.com/articles/10.1038/nature14236?shared_access_token=lo_2hfdw4muqecf3cvbzm9rgn0jajwel9jnr3zotv0p5kedccnjz3fj2fhqcgxkapor3zssjaldp-tw3iwgtsernlpac9xqq-vta2z5ji9lg16_wvcy4saogpk5xxa6ecqo8d8j7l4ejsdjwai53gqkt-7juiog0r3iv67mqiro74l6ixvmcvnkbgowimgi8u0izjstlpmqp6vmi_8lw_a==
 190. https://sites.google.com/a/deepmind.com/id25/
 191. https://www.youtube.com/watch?v=iqxkqf2bose
 192. https://github.com/sarvagyavaish/flappybirdrl
 193. https://www.youtube.com/watch?v=xm62spkazhu
 194. http://nn.cs.utexas.edu/downloads/papers/stanley.ec02.pdf
 195. https://www.youtube.com/watch?v=qv6uvoq0f44
 196. http://www.cs.utexas.edu/~pstone/papers/bib2html-links/icra04.pdf
 197. http://kormushev.com/papers/kormushev-iros2010.pdf
 198. https://www.youtube.com/watch?v=w_gxlksssie
 199. https://ccc.inaoep.mx/~mdprl/documentos/hester_2010.pdf
 200. https://www.youtube.com/watch?v=mrpx9dfcdwi&list=pl5nbayuyjtrm48dviibyi68urttmluv7e&index=12
 201. http://lis.csail.mit.edu/pubs/konidaris-aaai11b.pdf
 202. https://www.youtube.com/watch?v=yuicaksqtzy
 203. http://mlg.eng.cam.ac.uk/pub/pdf/deiras11.pdf
 204. http://people.cs.umass.edu/~sniekum/pubs/niekumrss2013.pdf
 205. http://markjcutler.com/papers/cutler15_icra.pdf
 206. https://www.youtube.com/watch?v=kkclfx6l1hy
 207. https://arxiv.org/abs/1407.3501
 208. https://www.youtube.com/watch?v=t-c17rkh3ue
 209. https://github.com/resibots/cully_2015_nature
 210. https://arxiv.org/abs/1703.07261
 211. https://www.youtube.com/watch?v=kteyyiifgpm
 212. https://github.com/resibots/blackdrops
 213. http://heli.stanford.edu/papers/nips06-aerobatichelicopter.pdf
 214. https://www.youtube.com/watch?v=vcdxqn0fcne
 215. http://repository.cmu.edu/cgi/viewcontent.cgi?article=1082&context=robotics
 216. http://web.engr.oregonstate.edu/~proper/aaai04sproper.pdf
 217. http://www.research.ibm.com/people/n/nabe/kdd04avas.pdf
 218. http://web.eecs.umich.edu/~baveja/papers/rldsjair.pdf
 219. http://old.nbu.bg/cogs/events/2000/readings/petrov/rltutorial.pdf
 220. http://image.diku.dk/igel/paper/rlian.pdf
 221. http://www.cse.unsw.edu.au/~cs9417ml/rl1/index.html
 222. http://www.cse.unsw.edu.au/~cs9417ml/rl1/introduction.html
 223. http://www.cse.unsw.edu.au/~cs9417ml/rl1/tdlearning.html
 224. http://www.cse.unsw.edu.au/~cs9417ml/rl1/algorithms.html
 225. http://www.cse.unsw.edu.au/~cs9417ml/rl1/applet.html
 226. http://wiki.ros.org/reinforcement_learning/tutorials/id23 tutorial
 227. http://cs.brown.edu/research/ai/pomdp/tutorial/index.html
 228. http://www.scholarpedia.org/article/reinforcement_learning
 229. http://www.scholarpedia.org/article/temporal_difference_learning
 230. http://busoniu.net/repository.php
 231. http://liinwww.ira.uka.de/bibliography/neural/reinforcement.learning.html
 232. http://rll.berkeley.edu/deeprlcourse/
 233. https://studywolf.wordpress.com/2012/11/25/reinforcement-learning-id24-and-exploration/
 234. http://www.arcadelearningenvironment.org/
 235. http://karpathy.github.io/2016/05/31/rl/
 236. https://www.nervanasys.com/demystifying-deep-reinforcement-learning/
 237. https://jaromiru.com/2016/09/27/lets-make-a-id25-theory/
 238. https://medium.com/emergent-future/simple-reinforcement-learning-with-tensorflow-part-0-id24-with-tables-and-neural-networks-d195264329d0#.78km20i8r
 239. https://github.com/yandexdataschool/practical_rl
 240. https://rlenv.directory/
 241. http://www.dcsc.tudelft.nl/~robotics/media.html
 242. http://cs.stanford.edu/people/karpathy/convnetjs/demo/rldemo.html
 243. https://github.com/nivwusquorum/tensorflow-deepq
 244. http://cs.stanford.edu/people/karpathy/reinforcejs/
 245. https://github.com/openai/gym
 246. https://github.com/openai/universe
 247. https://github.com/deepmind/lab
 248. https://github.com/microsoft/malmo
 249. https://github.com/marqt/vizdoom
 250. https://github.com/nadavbh12/retro-learning-environment
 251. https://github.com/twitter/torch-twrl
 252. https://github.com/facebook/uetorch
 253. https://github.com/torchcraft/torchcraft
 254. https://github.com/openai/rllab
 255. https://github.com/reinforceio/tensorforce
 256. https://github.com/deepmind/trfl/
 257. https://github.com/kengz/openai_lab
 258. https://github.com/matthiasplappert/keras-rl
 259. http://burlap.cs.brown.edu/
 260. https://github.com/geek-ai/magent
 261. http://ray.readthedocs.io/en/latest/rllib.html
 262. https://github.com/kengz/slm-lab
 263. https://github.com/unity-technologies/ml-agents
 264. https://github.com/nervanasystems/coach
 265. https://github.com/site/terms
 266. https://github.com/site/privacy
 267. https://github.com/security
 268. https://githubstatus.com/
 269. https://help.github.com/
 270. https://github.com/contact
 271. https://github.com/pricing
 272. https://developer.github.com/
 273. https://training.github.com/
 274. https://github.blog/
 275. https://github.com/about
 276. https://github.com/aikorea/awesome-rl
 277. https://github.com/aikorea/awesome-rl

   hidden links:
 279. https://github.com/
 280. https://github.com/aikorea/awesome-rl
 281. https://github.com/aikorea/awesome-rl
 282. https://github.com/aikorea/awesome-rl
 283. https://help.github.com/articles/which-remote-url-should-i-use
 284. https://github.com/aikorea/awesome-rl#awesome-reinforcement-learning--
 285. https://github.com/aikorea/awesome-rl#contributing
 286. https://github.com/aikorea/awesome-rl#table-of-contents
 287. https://github.com/aikorea/awesome-rl#codes
 288. https://github.com/aikorea/awesome-rl#theory
 289. https://github.com/aikorea/awesome-rl#lectures
 290. https://github.com/aikorea/awesome-rl#books
 291. https://github.com/aikorea/awesome-rl#surveys
 292. https://github.com/aikorea/awesome-rl#papers--thesis
 293. https://github.com/aikorea/awesome-rl#applications
 294. https://github.com/aikorea/awesome-rl#game-playing
 295. https://github.com/aikorea/awesome-rl#robotics
 296. https://github.com/aikorea/awesome-rl#control
 297. https://github.com/aikorea/awesome-rl#operations-research
 298. https://github.com/aikorea/awesome-rl#human-computer-interaction
 299. https://github.com/aikorea/awesome-rl#tutorials--websites
 300. https://github.com/aikorea/awesome-rl#online-demos
 301. https://github.com/aikorea/awesome-rl#open-source-reinforcement-learning-platforms
 302. https://github.com/
