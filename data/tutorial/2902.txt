   #[1]github [2]recent commits to sentiment-analyzer:master

   [3]skip to content

   (button)

     * why github?
       [4]features    
          + [5]code review
          + [6]project management
          + [7]integrations
          + [8]actions
          + [9]team management
          + [10]social coding
          + [11]documentation
          + [12]code hosting
          + [13]customer stories    
          + [14]security    
     * [15]enterprise
     * explore
          + [16]explore github    

learn & contribute
          + [17]topics
          + [18]collections
          + [19]trending
          + [20]learning lab
          + [21]open source guides

connect with others
          + [22]events
          + [23]community forum
          + [24]github education
     * [25]marketplace
     * pricing
       [26]plans    
          + [27]compare plans
          + [28]contact sales
          + [29]nonprofit    
          + [30]education    

   ____________________
     * in this repository all github    
       jump to    

     * no suggested jump to results

     * in this repository all github    
       jump to    
     * in this repository all github    
       jump to    

   [31]sign in [32]sign up

     * [33]watch [34]9
     * [35]star [36]44
     * [37]fork [38]26

[39]madhusudancs/[40]sentiment-analyzer

   [41]code [42]issues 0 [43]pull requests 0 [44]projects 0 [45]insights
   (button) dismiss

join github today

   github is home to over 31 million developers working together to host
   and review code, manage projects, and build software together.
   [46]sign up
   tweets sentiment analyzer
     * [47]165 commits
     * [48]1 branch
     * [49]0 releases
     * [50]fetching contributors
     * [51]apache-2.0

    1. [52]javascript 71.2%
    2. [53]python 28.8%

   (button) javascript python
   branch: master (button) new pull request
   [54]find file
   clone or download

clone with https

   use git or checkout with svn using the web url.
   https://github.com/m
   [55]download zip

downloading...

   want to be notified of new releases in madhusudancs/sentiment-analyzer?
   [56]sign in [57]sign up

launching github desktop...

   if nothing happens, [58]download github desktop and try again.

   (button) go back

launching github desktop...

   if nothing happens, [59]download github desktop and try again.

   (button) go back

launching xcode...

   if nothing happens, [60]download xcode and try again.

   (button) go back

launching visual studio...

   if nothing happens, [61]download the github extension for visual studio
   and try again.

   (button) go back
   fetching latest commit   
   cannot retrieve the latest commit at this time.
   [62]permalink
   type            name            latest commit message commit time
        failed to load latest commit information.
        [63]analyzer
        [64]webui
        [65].gitignore
        [66]license
        [67]readme.rst
        [68]datasettings.py
        [69]datasettings.py.sample

readme.rst

sentiment analyzer

   the goal of this project is to perform id31 on textual
   data that people generally post on websites like social networks and
   movie review sites. at the moment, this project does a sentiment
   analysis on tweets (from twitter.com). it has two modes of operation

     * offline mode: this mode relies on the discoproject
       ([70]http://discoproject.org/), which is a mapreduce framework
       written in erlang and python and has a cool python api. this mode
       can be used to fetch a large number of tweets using the twitter
       search api and to feature extract and classify them.
     * online mode: online mode has a web ui written in django. this mode
       can fetch only a thousand tweets for one request and classify them.

technologies used and dependencies

   you should never use python without ipython!!! although nothing in this
   project directly uses ipython or its api, it is highly recommended to
   install ipython 0.12 or later to make your life easier :-)

   the following technologies/packages/libraries are used and hence
   required:

base requirements

     * the project is written in python! so python 2.7 is the bare minimum
       requirement. note this project uses several features of python 2.7
       to make sure that the transition to python 3.x will be smooth. so
       it is intentionally written not to support the previous versions of
       python. once the dependent libraries like django are packages are
       ported to python 3.x this project should theoritically run on
       python 3.x, but it has not been tested as of now.
     * the classifier is implemented using scikit-learn (sklearn) library
       which is a python machine learning library written on top of python
       for scientific computing stack. so scikit-learn is required. this
       project runs only on the current bleeding edge version of
       scikit-learn. you need to git clone scikit-learn's repository from
       their github page and install it from there. the project uses some
       api that are not available in previous versions. so only
       scikit-learn 0.11+ works.
     * since scikit-learn depends on python for scientific computing
       stack. numpy and scipy which are the foundations of this stack are
       required.
     * data persistence is achieved using mongodb. so mongodb v2.0.3 or
       later is required.
     * mongoengine which is a python api for mongodb is used to make the
       python components talk to mongodb. so mongoengine 0.6.2 or later is
       required.
     * requests library which is an awesome library for all http related
       things in python is used for fetching tweets through the twitter
       search api. so requests 0.10.4 is required.

mapreduce/offline mode requirements

     * discoproject needs to be installed for this mode. this needs the
       bleeding edge version of discoproject. so discoproject needs to be
       installed from their github repository.

web ui/online mode requirements

     * the webui is implemented using django. but we use mongodb as our
       data backend which is a nosql. django still doesn't officially
       support any nosqls. so the thirdparty django fork called
       django-nonrel is required. the version of django-nonrel that works
       with django 1.3 or later is required for this mode.
     * for making django components talk to mongodb backend, djangotoolbox
       and django mondodb engine are required. these can be any recent
       versions from their respective bitbucket and github repositories.
     * additionally caching is supported for classified tweets in order to
       speedup the request-to-response cycle. this is implemented using
       memcached. so memcached 1.4.7 or later is required.
     * the python api for memcached pylibmc is used to make python
       components talk to memcached backend. bleeding edge of pylibmc is
       used so, this needs to be git-cloned from their github repository.
     * django-mongonaut is used to provide django admin like functionality
       on top of mongodb. so django-mongonaut 0.2.11 or later is required.

setting up

   the steps to setup this project are

     * first of all, to get this code locally, git-clone this repository.
       the git clone url is at the front page of this project.
     * then make sure the package requirements as mentioned in the
       requirements section above are met.
     * you will need to create a python file called datasettings.py in the
       project root directory. this file contains all the project specific
       settings that are local to your machine. the sample datasettings
       file is provided in the project root directory. if you want to
       reuse it just copy it to a new file and name it datasettings.py
     * for both modes of operation, the mongodb database to connect to is
       defined in webui/fatninja/models.py with the line:
mongoengine.connect('<database name>')

       replace the <> place holder with your database name. this is
       required for mapreduce/offline mode too since we write the data to
       database even during mapreduce.
     * for running in web ui/online mode you will also need local.py in
       the webui directory under project root. this file contains
       information either some sensitive information like the database
       name, password etc. a sample is provided. you can just copy it to a
       new file and call it local.py and replace all the placeholders
       shown by angular brackets (<>) with information specific to your
       machine.

what was the training data used and what else is required?

   you need to create a data directory and point the settings variable
   data_directory in your datasettings.py file to point to that location.
   then you will need the training corpus. the training corpus used can be
   obtained from here:
http://www.sananalytics.com/lab/twitter-sentiment/

   build a training corpus out of it this data as a csv file and name it
   full-corpus.csv. place this csv file under your data directory.

   additionally imdb reviews classification was tried for training but it
   did not improve precision values in any way. so it was discared. if you
   are interested to experiment you can get that data from here:
http://alias-i.com/lingpipe/demos/tutorial/sentiment/read-me.html

   these files can be directly placed under directories positive and
   negative under your data directory and the imdb data parser in
   parser.py can be used to parse this data and fed into the classifier
   while training it. but this is left as an exercise :-)

training the classifiers

   only the first time, to train the classifiers and store the vectorizer
   and the trained classifier navigate to analyzer directory and run:
python train.py --serialize

   assuming you have setup everything else, this trains 3 classifiers

     * a multinomial naive-bayes classifier
     * a bernoulli's naive-bayes classifier
     * a support-vector machine

   and stores the trained classifiers in the given order in the serialized
   file called classifiers.pickle in your data directory:

   this also stores the vectorizer object in the file vectorizer.pickle in
   your data directory.

enough is enough, tell me how to run?

   ok finally! to run in the mapreduce/offline mode navigate to analyzer
   directory and run:
$ python classification.py -q "oscars" -p 10

   where the argument to -q is the search query to search for tweets on
   twitter and the argument to -p is the number of pages of search results
   to fetch. each page roughly contains 80-100 tweets and this option
   defaults to 10.

   usage:
$ python classification.py -h
usage: classification.py [-h] [-q query] [-p [pages]]

classifier arguments.

optional arguments:
  -h, --help            show this help message and exit
  -q query, --query query
                        the query that must be used to search for tweets.
  -p [pages], --pages [pages]
                        number of pages of tweets to fetch. one page is
                        approximately 100 tweets.

   to run in the web ui mode all you have to do is start the django
   webserver. to do this navigate to webui directory and run:
$ python manage.py runserver

   you can visit the url that the django webserver points to see how it
   runs.

why discoproject for mapreduce, why not x?

   the api of discoproject is much much cleaner, better and easier to use
   than hadoop or any other related mapreduce apis that we came across.
   also, setting up discoproject is extremely easy. if we are not
   interested in installing discoproject, we can even run it from the
   source directory after git-cloning it! and it runs on python! not in
   any other x programming language that is defective-by-design! also, on
   a single node cluster, discoproject seems to run faster than hadoop at
   least. however we don't consider this as a win yet. we need to really
   profile discoproject and other frameworks on large clusters with
   terabytes of data to know which actually outperforms the other.

authors

     * ajay s. narayan
     * madhusudan.c.s
     * shobhit n.s.

license and copyright

   the authors of this project are the sole copyright holders of the
   source code of this project, unless otherwise explicitly mentioned in
   the individual source files. the source code includes anything that can
   be written in any computer programming or scipting or markup languages.

   this is an open source project licensed under apache license v2.0. the
   terms and the conditions of the license is available in the "license"
   file.

     *    2019 github, inc.
     * [71]terms
     * [72]privacy
     * [73]security
     * [74]status
     * [75]help

     * [76]contact github
     * [77]pricing
     * [78]api
     * [79]training
     * [80]blog
     * [81]about

   (button) you can   t perform that action at this time.

   you signed in with another tab or window. [82]reload to refresh your
   session. you signed out in another tab or window. [83]reload to refresh
   your session.

   (button)

references

   visible links
   1. https://github.com/opensearch.xml
   2. https://github.com/madhusudancs/sentiment-analyzer/commits/master.atom
   3. https://github.com/madhusudancs/sentiment-analyzer#start-of-content
   4. https://github.com/features
   5. https://github.com/features/code-review/
   6. https://github.com/features/project-management/
   7. https://github.com/features/integrations
   8. https://github.com/features/actions
   9. https://github.com/features#team-management
  10. https://github.com/features#social-coding
  11. https://github.com/features#documentation
  12. https://github.com/features#code-hosting
  13. https://github.com/customer-stories
  14. https://github.com/security
  15. https://github.com/enterprise
  16. https://github.com/explore
  17. https://github.com/topics
  18. https://github.com/collections
  19. https://github.com/trending
  20. https://lab.github.com/
  21. https://opensource.guide/
  22. https://github.com/events
  23. https://github.community/
  24. https://education.github.com/
  25. https://github.com/marketplace
  26. https://github.com/pricing
  27. https://github.com/pricing#feature-comparison
  28. https://enterprise.github.com/contact
  29. https://github.com/nonprofit
  30. https://education.github.com/
  31. https://github.com/login?return_to=/madhusudancs/sentiment-analyzer
  32. https://github.com/join
  33. https://github.com/login?return_to=/madhusudancs/sentiment-analyzer
  34. https://github.com/madhusudancs/sentiment-analyzer/watchers
  35. https://github.com/login?return_to=/madhusudancs/sentiment-analyzer
  36. https://github.com/madhusudancs/sentiment-analyzer/stargazers
  37. https://github.com/login?return_to=/madhusudancs/sentiment-analyzer
  38. https://github.com/madhusudancs/sentiment-analyzer/network/members
  39. https://github.com/madhusudancs
  40. https://github.com/madhusudancs/sentiment-analyzer
  41. https://github.com/madhusudancs/sentiment-analyzer
  42. https://github.com/madhusudancs/sentiment-analyzer/issues
  43. https://github.com/madhusudancs/sentiment-analyzer/pulls
  44. https://github.com/madhusudancs/sentiment-analyzer/projects
  45. https://github.com/madhusudancs/sentiment-analyzer/pulse
  46. https://github.com/join?source=prompt-code
  47. https://github.com/madhusudancs/sentiment-analyzer/commits/master
  48. https://github.com/madhusudancs/sentiment-analyzer/branches
  49. https://github.com/madhusudancs/sentiment-analyzer/releases
  50. https://github.com/madhusudancs/sentiment-analyzer/graphs/contributors
  51. https://github.com/madhusudancs/sentiment-analyzer/blob/master/license
  52. https://github.com/madhusudancs/sentiment-analyzer/search?l=javascript
  53. https://github.com/madhusudancs/sentiment-analyzer/search?l=python
  54. https://github.com/madhusudancs/sentiment-analyzer/find/master
  55. https://github.com/madhusudancs/sentiment-analyzer/archive/master.zip
  56. https://github.com/login?return_to=https://github.com/madhusudancs/sentiment-analyzer
  57. https://github.com/join?return_to=/madhusudancs/sentiment-analyzer
  58. https://desktop.github.com/
  59. https://desktop.github.com/
  60. https://developer.apple.com/xcode/
  61. https://visualstudio.github.com/
  62. https://github.com/madhusudancs/sentiment-analyzer/tree/33914573e1242b3760ec0ee2fef401b26636d1b1
  63. https://github.com/madhusudancs/sentiment-analyzer/tree/master/analyzer
  64. https://github.com/madhusudancs/sentiment-analyzer/tree/master/webui
  65. https://github.com/madhusudancs/sentiment-analyzer/blob/master/.gitignore
  66. https://github.com/madhusudancs/sentiment-analyzer/blob/master/license
  67. https://github.com/madhusudancs/sentiment-analyzer/blob/master/readme.rst
  68. https://github.com/madhusudancs/sentiment-analyzer/blob/master/datasettings.py
  69. https://github.com/madhusudancs/sentiment-analyzer/blob/master/datasettings.py.sample
  70. http://discoproject.org/
  71. https://github.com/site/terms
  72. https://github.com/site/privacy
  73. https://github.com/security
  74. https://githubstatus.com/
  75. https://help.github.com/
  76. https://github.com/contact
  77. https://github.com/pricing
  78. https://developer.github.com/
  79. https://training.github.com/
  80. https://github.blog/
  81. https://github.com/about
  82. https://github.com/madhusudancs/sentiment-analyzer
  83. https://github.com/madhusudancs/sentiment-analyzer

   hidden links:
  85. https://github.com/
  86. https://github.com/madhusudancs/sentiment-analyzer
  87. https://github.com/madhusudancs/sentiment-analyzer
  88. https://github.com/madhusudancs/sentiment-analyzer
  89. https://help.github.com/articles/which-remote-url-should-i-use
  90. https://github.com/madhusudancs/sentiment-analyzer#sentiment-analyzer
  91. https://github.com/madhusudancs/sentiment-analyzer#technologies-used-and-dependencies
  92. https://github.com/madhusudancs/sentiment-analyzer#base-requirements
  93. https://github.com/madhusudancs/sentiment-analyzer#mapreduceoffline-mode-requirements
  94. https://github.com/madhusudancs/sentiment-analyzer#web-uionline-mode-requirements
  95. https://github.com/madhusudancs/sentiment-analyzer#setting-up
  96. https://github.com/madhusudancs/sentiment-analyzer#what-was-the-training-data-used-and-what-else-is-required
  97. https://github.com/madhusudancs/sentiment-analyzer#training-the-classifiers
  98. https://github.com/madhusudancs/sentiment-analyzer#enough-is-enough-tell-me-how-to-run
  99. https://github.com/madhusudancs/sentiment-analyzer#why-discoproject-for-mapreduce-why-not-x
 100. https://github.com/madhusudancs/sentiment-analyzer#authors
 101. https://github.com/madhusudancs/sentiment-analyzer#license-and-copyright
 102. https://github.com/
