   #[1]dnlcrl

   [2]dnlcrl

five hundred deep learning papers, graphviz and python

   oct 10, 2015

update

   check out the [3]part ii of this post in which you can interact with
   the svg graph by hovering and clicking the nodes, thanks to javascript.

tl;dr

   i invested days creating a graph with pygraphviz, representing the
   evolutionary process of deep learning   s state of the art for the last
   twenty-five years, or at least this was my objective. this is the final
   result:

   graph test 0

introduction

   i am currently writing my computer engineering master thesis about deep
   learning. when i came to the state-of-art part i thought i could build
   up something interesting by making a graph of the most relevant papers
   for the last twenty-five years, the only problem is that i don   t have
   much experience with graphviz so after i built a sort of json archive
   by scraping (sorry for that) google scholar, i made a lot of tries to
   figure out how graphviz works and how i could visualize the results in
   a meaningful way. in this post i will show how in brief how i obtained
   the papers data and how i came to the final result above.

obtaining data

   the first thing i was needing was the papers data, i wanted to create a
   graph in which each node represents an author or a paper, each article
   is connected with their authors through    author->paper    arches and each
   paper is connected with the papers who cited them through
      paper->paper    arches. i also thought about sorting the papers
   according to the date of publication.

   in other words i needed a list of relevant papers and for each paper:
     * title
     * authors
     * publication date
     * bibliography (or a    cited by    list)

   so i searched on google and i found out that arxiv.org has an api that
   allows programmatic access all of the e-prints hosted by them,    good!   
   i thought, but when i went through the arxiv api user   s manual i found
   out that it   s impossible (correct me if i   m wrong), to get information
   about the bibliography of the papers or to search all the papers    cited
   by    another paper, the only hosting service that give this piece of
   information i found was google scholar, plus it gives the possibility
   to search all the papers citing a specific paper by the    cites   
   parameter, so i searched    scholar api    on google and what i saw is
   this:

   "scholar api" results

   after i read [4]some reasons about why big g doesn   t offer an api
   service i went on github and tried [5]scholar.py, but it outputs the
   results only in txt or csv file formats, so i [6]forked it and added
   some feature like exporting the results in a json file, setting the
   starting result number by adding the    start    parameter in the search
   query and the ability to get as much results as one wants (results
   seems to be limited by circa 1000 on server side though), so i started
   getting the    deep learning    results saved on a list of dictionaries in
   a json file with this schema:

[
 {
        "num_versions": 3,
        "url_citation": null,
        "title": "deep self-taught learning for handwritten character recognitio
n",
        "url": "http://arxiv.org/abs/1009.3589",
        "url_versions": "http://scholar.google.com/scholar?cluster=1343013624256
8199344&hl=en&as_sdt=1,5&as_vis=1",
        "authors": "f bastien, y bengio, a bergeron\u2026 - arxiv preprint arxiv
: \u2026",
        "excerpt": "... 1 introduction deep learning has emerged as a promising
new area of research instatistical machine learn- ing (see bengio [1] for a revi
ew). ... in particular the relativeadvantage of deep learning for these settings
 has not been evaluated. ...",
        "url_pdf": null,
        "num_citations": 4,
        "cluster_id": "13430136242568199344",
        "year": "2010",
        "url_citations": "http://scholar.google.com/scholar?cites=13430136242568
199344&as_sdt=2005&sciodt=1,5&hl=en"
 },
 ...
]

   as you can see there are obvious limitations to this approach but i
   will come to them later, because the biggest obvious problem is that
   after a few dozen of results the command line script stops working
   because of google   s recaptcha page that obviously means that google
   knows you are doing something not conforming to their tos. what to do
   then?

   i could not wait hours nor change my public ip every time for sure, so
   given my little experience with [7]selenium, i implemented what i call
   a    supervised scraper    starting from my scholar.py fork and published
   it as [8]pyscholar (is still a work in progress, and i haven   t created
   yet an installation guide but to run it you simply have to install
   selenium and eventually other needed packages through pip, you also
   need the selenium correspondent stable version of firefox installed on
   your machine).

   the main feature of pyscholar is that it instantiate a firefox window,
   and i know it is boring for many people but this permit users to see
   when the script pauses because of a capthca, put the solution and let
   the script continues typing    continue    or    c    in the terminal window,
   at the moment it makes use of pdb to pause the script. please note that
   pyscholar is only a prototype, there would be various way to improve it
   (and you can contribute if you want). anyway i wanted to make use of
   selenium webdriver for two main reasons: the first one is that i wanted
   to see what was going on while scraping, secondly but not certainly for
   importance, the new    i   m not a robot    recaptcha:

   python is not a robot

   i also tried to minimize the number of times this really annoying
   challenge shows up, by saving all firefox profile files and load them
   each time the tool stops and starts and i have to say that with this
   trick the    i   m not a robot    page shown up to me very few times during
   this job, let    say that from my experience on 100 requests a standard
   (automatically generated) capthca is shown every 25 pages circa, while
   the    i   m not a robot    is shown every 500 requests circa (from what i
   remember). the funny thing is that google uses recaptcha service to
   build their machine learning training datasets, among other obvious
   uses.

   so what pyscholar did was to search for the most relevant    deep
   learning    papers in scholar, excluding pure citations and patents, and
   saving the results in a json file as said before, so i had the    first
   layer    of papers, then i added a feature on pyscholar to input a json
   file and getting at most the first x relevant papers citing a for each
   paper a in the first layer of papers.

   i thought i could get a relevant representation of the deep learning
   state of art evolution for the last years by skipping all results with
   less than 10 citations and applying x = 50 to build a second json list,
   the    second layer    of papers, and searching again for the x = 50 most
   relevant papers which cite b, for each paper b in the second layer   s
   papers excluding the b papers that with less than 10 citations (i also
   decided to keep in the second layer b all the papers published in the
   years 2014 and 2015). thus i created the third and last papers layer,
   after that i figured out i could stop because practically all of the
   papers citing the papers in the third layer (excluding the papers not
   published in the last two years with less than 10 citations) already
   resided in one of the layers.

results limitations

   as i said before if you see the json output example, you can see there
   are some limitations to this approach, the first big one is that in the
   author field there aren   t only authors, there we have the publication
   year (that scholar.py extracts and put at the    year    key), the research
   field or other information (like the    arxiv preprint arxiv    in the
   example) that i honestly dropped because some result contains too much
   authors that the string get truncated, and other characters i had to
   remove, so i took all authors i could from this field, conscious that i
   lost some authors for sure. rarely also the extraction of the
   publication year from the    authors    value gave me problems, as we will
   see below.

graphviz + python = let the fun begin

   after getting enough data to build a meaningful graph i started
   searching the best way to build and show a big graph, preferably using
   python, suddenly i found [9]graphviz. i used it before implicitly
   trough doxygen and remembered that it was a very powerful tool, so i
   installed pygraphviz, downloaded the dot documentation and started
   playing around with the graph creation process, putting all author
   nodes on a row and all paper nodes below the authors, connecting the
   authors to their correspondent papers and the papers to correspondent
   papers which cited them. after some tries i get the first meaningful
   result, limiting the minimum number of citations and the number of
   arches in the graph:

   graph test 0

   note that to create the pngs i had to take screenshots of quickview
   because i tried to export the pdf in various ways but waiting times are
   too much long because the process is computationally very hard (or more
   likely i am doing something wrong).

   i coloured green the paths representing a    wrote    relation (authors are
   almost invisibles here though), blue the paths represent a    cited_by   
   relation and then i sized the paper nodes depending on the total number
   of citations received. obviously there still were a lot of bugs to fix:
   sizes weren   t meaningful at all, position parameters were ignored, node
   colouring to be implemented, etc. but i think it was an exciting
   starting point.

   so i started playing with both the dot parameters and various
   parameters created by me to select the papers to be shown, then i added
   the paper   s links to the paper nodes:

   graph test 02 graph test 04 graph test 10

   as perhaps you have noticed, i started understanding that there are two
   completely uncorrelated group of papers in many tests, by clicking on
   the nodes on the left i got it, there are a lot of useless articles,
   because in the results there were a lot of papers talking about deep
   learning, in psychology terms: how to teach to students in a proper
   way, various studies regarding students    learning processes, papers
   totally unrelated to neural networks or machine learning, my fault, i
   could spend more time refining the search query. by the way i figured
   out a way to remove the authors and their relative papers from the
   dataset, when the uncorrelation became evident in the graph, by fixing
   all author nodes on a row in the graph so i could select all authors of
   the uncorrelated papers, copy, paste in a file and remove them with
   minimum effort.

   then i implemented a paper nodes    sizing by    citations ratio   
   (citations / year) and started colouring the paper nodes depending on
   the publication year, also we can finally see the authors, in a green
   star shape, and finally sized depending on the number of written
   papers:

   graph test 30 graph test 39

   after removing some other outliers and some not-papers nodes like books
   or slides, i fixed the node colouring and positioning by adding
   invisibles paths through the nodes:

   graph test 44 graph test 46

   so i found the last outlier, a paper whose year was interpreted as 2080
   instead of 2014 because of the limitations written before, finally i
   came to this graph:

   graph test 0

   not-green paths are the citations starting from a paper a and ending to
   a paper b citing a, blue paths start from the first layer papers, red
   paths from the second and pink paths from the third one.

   i started with 1071 papers (probably most relevant papers citing papers
   in the first layer were already in the first layer) and ended with 513
   unique relevant papers by 945 unique authors and a total of 1548
   citations. i don   t think this graph is complete, if i had more time i
   would enlarged the paper set by including papers inherent to at least
      id158s    and something about    machine learning    but
   i have to pay bills and i cannot invest much time in this spin-off
   project at the moment. i would also appreciate any suggestions/critics.

other resources

   you can find [10]here a list of all the screenshots of the tests i
   kept. i also uploaded the final svg file with a paper information popup
   when hovering nodes and correspondent pdf: [11]test48.svg and
   [12]test48.pdf. keep in mind that there are a lot of things that could
   be improved: citations information when hovering the paths, more
   informations about the authors, i would also like to add some css
   effects to the svg.

update

   check out the [13]part ii of this post in which you can interact with
   the svg graph by hovering and clicking the nodes, thanks to javascript.
   please enable javascript to view the [14]comments powered by disqus.

references

   1. http://feeds.feedburner.com/danieleciriello
   2. https://dnlcrl.github.io/
   3. http://dnlcrl.github.io/projects/2015/10/15/500-deep-learning-papers-part-2.html
   4. https://www.quora.com/why-doesnt-google-have-an-official-api-for-google-scholar
   5. https://github.com/ckreibich/scholar.py
   6. https://github.com/danieleciriello/scholar.py
   7. http://docs.seleniumhq.org/
   8. https://github.com/danieleciriello/pyscholar
   9. http://www.graphviz.org/
  10. https://dnlcrl.github.io/metapost/2015/10/10/500-deep-learning-papers-graphviz-python-tests.html
  11. http://dnlcrl.github.io/assets/dl-gviz/test48.svg
  12. http://dnlcrl.github.io/assets/dl-gviz/test48.pdf
  13. http://dnlcrl.github.io/projects/2015/10/15/500-deep-learning-papers-part-2.html
  14. https://disqus.com/?ref_noscript
