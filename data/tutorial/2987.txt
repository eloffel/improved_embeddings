   (button) toggle navigation
   [1][nav_logo.svg?v=479cefe8d932fb14a67b93911b97d70f]
     * [2]jupyter
     * [3]faq
     * [4]view as code
     * [5]python 3 kernel
     * [6]download notebook

the traveling salesperson problem[7]  

   consider the [8]traveling salesperson problem:

     given a set of cities and the distances between each pair of cities,
     what is the shortest possible tour that visits each city exactly
     once, and returns to the starting city?

   in this notebook we will develop some solutions to the problem, and
   more generally show how to think about solving a problem like this.
   [9]elsewhere you can read about how the algorithms developed here are
   used in serious applications that millions of people rely on every day.

   [10][dantzig.gif]

                              an example tour.

understanding what we're talking about (vocabulary)[11]  

   do we understand precisely what the problem is asking? do we understand
   all the concepts that the problem talks about? do we understand them
   well enough to implement them in a programming language? let's take a
   first pass:
     * a set of cities: we will need to represent a set of cities;
       python's set datatype might be appropriate.
     * distance between each pair of cities: if a and b are cities, this
       could be a function, distance(a, b), or a table lookup,
       distance[a][b]. the resulting distance will be a real number.
     * city: all we have to know about an individual city is how far it is
       from other cities. we don't have to know its name, population, best
       restaurants, or anything else. so a city could be just an integer
       (0, 1, 2, ...) used as an index into a distance table, or a city
       could be a pair of (x, y) coordinates, if we are using
       straight-line distance on a plane.
     * tour: a tour is a specified order in which to visit the cities;
       python's list or tuple datatypes would work. for example, given the
       set of cities {a, b, c, d}, a tour might be the list [b, d, a, c],
       which means to travel from b to d to a to c and finally back to b.
     * shortest possible tour: the shortest tour is the one whose tour
       length is the minimum of all tours.
     * tour length: the sum of the distances between adjacent cities in
       the tour (including the last city back to the first city). probably
       a function, tour_length(tour).
     * what is ...: we can define a function to answer the question what
       is the shortest possible tour? the function takes a set of cities
       as input and returns a tour as output. i will use the convention
       that any such function will have a name ending in the letters
       "tsp", the traditional abbreviation for traveling salesperson
       problem.

   at this stage i have a rough sketch of how to attack the problem. i
   don't have all the answers, and i haven't committed to specific
   representations for all the concepts, but i know what all the pieces
   are, and i don't see anything that stops me from proceeding.

   here are the imports used throughout this notebook. i'm assuming python
   3.
   in [1]:
%matplotlib inline
import matplotlib.pyplot as plt
import random
import time
import itertools
import urllib
import csv
import functools
from statistics import mean, stdev

all tours algorithm: alltours_tsp[12]  

   let's start with an algorithm that is guaranteed to solve the problem,
   although it is inefficient for large sets of cities:

     all tours algorithm: generate all possible tours of the cities, and
     choose the shortest tour (the one with minimum tour length).

   my design philosophy is to first write an english description of the
   algorithm, then write python code that closely mirrors the english
   description. this will probably require some auxilliary functions and
   data structures; just assume they exist; put them on a to do list, and
   eventually define them with the same design philosophy.

   here is the start of the implementation:
   in [2]:
def alltours_tsp(cities):
    "generate all possible tours of the cities and choose the shortest tour."
    return shortest_tour(alltours(cities))

def shortest_tour(tours):
    "choose the tour with the minimum tour length."
    return min(tours, key=tour_length)

# to do: data types: cities, tours, functions: alltours, tour_length

   note: in python min(collection,key=function) means to find the element
   x that is a member of collection such that function(x) is minimized. so
   shortest finds the tour whose tour_length in the minimal among the
   tours.

   this gives us a good start; the python code closely matches the english
   description. and we know what we need to do next: represent cities and
   tours, and implement the functions alltours and tour_length. let's
   start with tours.

representing tours[13]  

   a tour starts in one city, and then visits each of the other cities in
   order, before returning to the start city. a natural representation of
   a tour is a sequence of cities. for example (1, 2, 3) could represent a
   tour that starts in city 1, moves to 2, then 3, and finally returns to
   1.

   note: i considered using (1, 2, 3, 1) as the representation of this
   tour. i also considered an ordered list of edges between cities: ((1,
   2), (2, 3), (3, 1)). in the end, i decided (1, 2, 3) was simplest.

   now for the alltours function. if a tour is a sequence of cities, then
   all the tours are permutations of the set of all cities. a function to
   generate all permutations of a set is already provided in python's
   standard itertools library module; we can use it as our implementation
   of alltours:
   in [3]:
alltours = itertools.permutations

   for n cities there are n! (that is, the factorial of n) permutations.
   here's are all 3! = 6 tours of 3 cities:
   in [4]:
cities = {1, 2, 3}

list(alltours(cities))

   out[4]:
[(1, 2, 3), (1, 3, 2), (2, 1, 3), (2, 3, 1), (3, 1, 2), (3, 2, 1)]

   the length of a tour is the sum of the lengths of each edge in the
   tour; in other words, the sum of the distances between consecutive
   cities in the tour, including the distance form the last city back to
   the first:
   in [5]:
def tour_length(tour):
    "the total of distances between each pair of consecutive cities in the tour.
"
    return sum(distance(tour[i], tour[i-1])
               for i in range(len(tour)))

# to do: functions: distance, data types: cities

   note: i use one python-specific trick: when i is 0, then
   distance(tour[0], tour[-1]) gives us the wrap-around distance between
   the first and last cities, because tour[-1] is the last element of
   tour.

representing cities[14]  

   we determined that the only thing that matters about cities is the
   distance between them. but before we can decide about how to represent
   cities, and before we can define distance(a, b), we have to make a
   choice. in the fully general version of the tsp, the "distance" between
   two cities could be anything: it could factor in the amount of time it
   takes to travel between cities, the twistiness of the road, or anything
   else. the distance(a, b) might be different from distance(b, a). so the
   distances could be represented by a matrix distance[a][b], where any
   entry in the matrix could be any (non-negative) numeric value.

   but we will ignore the fully general tsp and concentrate on an
   important special case, the euclidean tsp, where the distance between
   any two cities is the [15]euclidean distance, the straight-line
   distance between points in a two-dimensional plane. so a city can be
   represented by a two-dimensional point: a pair of x and y coordinates.
   we will use the constructor function city, so that city(300, 0) creates
   a city with x-coordinate of 300 and y coordinate of 0. then distance(a,
   b) will be a function that uses the x and y coordinates to compute the
   distance between a and b.

representing points and computing distance[16]  

   ok, so a city can be represented as just a two-dimensional point. but
   how will we represent points? here are some choices, with their pros
   and cons:
     * tuple: a point is a two-tuple of (x, y) coordinates, for example,
       (300, 0). pro: very simple. con: doesn't distinguish points from
       other two-tuples.
     * class: define a custom point class with x and y slots. pro:
       explicit, gives us p.x and p.y accessors. con: less efficient.
     * complex: python already has the two-dimensional point as a built-in
       numeric data type, but in a non-obvious way: as complex numbers,
       which inhabit the two-dimensional (real    imaginary) plane. pro:
       efficient. con: a little confusing; doesn't distinguish points from
       other complex numbers.
     * subclass of complex: all the pros of complex, and eliminating the
       major con.

   any of these choices would work perfectly well; i decided to use a
   subclass of complex:
   in [6]:
# cities are represented as points, which are a subclass of complex numbers

class point(complex):
    x = property(lambda p: p.real)
    y = property(lambda p: p.imag)

city = point

def distance(a, b):
    "the distance between two points."
    return abs(a - b)

   here's an example of computing the distance between two cities:
   in [7]:
a = city(3, 0)
b = city(0, 4)
distance(a, b)

   out[7]:
5.0

random sets of cities[17]  

   the input to a tsp algorithm should be a set of cities. i can make a
   random set of n cities by calling city n times, each with different
   random x and y coordinates:
   in [8]:
{city(random.randrange(1000), random.randrange(1000)) for c in range(6)}

   out[8]:
{(193+375j), (427+384j), (497+585j), (179+546j), (224+543j), (245+643j)}

   the function cities does that (and a bit more):
   in [9]:
def cities(n, width=900, height=600, seed=42):
    "make a set of n cities, each with random coordinates within a (width x heig
ht) rectangle."
    random.seed(seed * n)
    return frozenset(city(random.randrange(width), random.randrange(height))
                     for c in range(n))

   there are three complications that i decided to tackle in cities:
    1. ipython's matplotlib plots (by default) in a rectangle that is 1.5
       times wider than it is high; that's why i specified a width of 900
       and a height of 600. if you want the coordinates of your cities to
       be bounded by a different size rectangle, you can change width or
       height.
    2. sometimes i want cities(n) to be a true function, returning the
       same result each time. this is very helpful for getting repeatable
       results: if i run a test twice, i get the same results twice. but
       other times i would like to be able to do an experiment, where, for
       example, i call cities(n) 30 times and get 30 different sets, and i
       then compute the average tour length produced by my algorithm
       across these 30 sets. can i get both behaviors out of one function?
       yes! the trick is the additional optional parameter, seed. two
       calls to cities with the same n and seed parameters will always
       return the same set of cities, and two calls with different values
       for seed will return different sets. this is implemented by calling
       the function random.seed, which resets the random number generator.
    3. once i create a set of cities, i don't want anyone messing with my
       set. for example, i don't want an algorithm that claims to "solve"
       a problem by deleting half the cities from the input set, then
       finding a tour of the remaining cities. therefore, i make cities
       return a frozenset rather than a set. a frozenset is immutable;
       nobody can change it once it is created. (likewise, each city is
       immutable.)

   for example:
   in [10]:
# a set of 5 cities
cities(5)

   out[10]:
frozenset({(172+20j), (234+40j), (696+415j), (393+7j), (671+296j)})

   in [11]:
# the exact same set of 5 cities each time
[cities(5) for i in range(3)]

   out[11]:
[frozenset({(172+20j), (234+40j), (696+415j), (393+7j), (671+296j)}),
 frozenset({(172+20j), (234+40j), (696+415j), (393+7j), (671+296j)}),
 frozenset({(172+20j), (234+40j), (696+415j), (393+7j), (671+296j)})]

   in [12]:
# a different set of 5 cities each time
[cities(5, seed=i) for i in range(3)]

   out[12]:
[frozenset({(414+310j), (776+430j), (41+265j), (864+394j), (523+497j)}),
 frozenset({(814+542j), (29+476j), (637+261j), (759+367j), (794+255j)}),
 frozenset({(439+494j), (211+473j), (585+33j), (832+503j), (591+15j)})]

   now we are ready to apply the alltours_tsp function to find the
   shortest tour:
   in [13]:
alltours_tsp(cities(8))

   out[13]:
((6+546j),
 (199+147j),
 (350+65j),
 (737+26j),
 (847+187j),
 (891+465j),
 (554+374j),
 (505+548j))

   in [14]:
tour_length(alltours_tsp(cities(8)))

   out[14]:
2509.307587720301

   quick, is that the right answer? i have no idea, and you probably can't
   tell either. but if we could plot the tour we'd understand it better
   and might be able to see at a glance if the tour is optimal.

plotting tours[18]  

   i define plot_tour(tour) to plot the cities (as circles) and the tour
   (as lines):
   in [15]:
def plot_tour(tour):
    "plot the cities as circles and the tour as lines between them."
    plot_lines(list(tour) + [tour[0]])

def plot_lines(points, style='bo-'):
    "plot lines to connect a series of points."
    plt.plot([p.x for p in points], [p.y for p in points], style)
    plt.axis('scaled'); plt.axis('off')

   in [16]:
plot_tour(alltours_tsp(cities(8)))

   [hna+gtsxkdsaaaaasuvo rk5cyii= ]

   that looks much better! to me, it looks like the shortest possible
   tour, although i don't have an easy way to prove it. let's go one step
   further and define a function, plot_tsp(algorithm, cities) that will
   take a tsp algorithm (such as alltours_tsp) and a set of cities, apply
   the algorithm to the cities to get a tour, check that the tour is
   reasonable, plot the tour, and print information about the length of
   the tour and the time it took to find it:
   in [17]:
def plot_tsp(algorithm, cities):
    "apply a tsp algorithm to cities, plot the resulting tour, and print informa
tion."
    # find the solution and time how long it takes
    t0 = time.clock()
    tour = algorithm(cities)
    t1 = time.clock()
    assert valid_tour(tour, cities)
    plot_tour(tour); plt.show()
    print("{} city tour with length {:.1f} in {:.3f} secs for {}"
          .format(len(tour), tour_length(tour), t1 - t0, algorithm.__name__))

def valid_tour(tour, cities):
    "is tour a valid tour for these cities?"
    return set(tour) == set(cities) and len(tour) == len(cities)

   in [18]:
plot_tsp(alltours_tsp, cities(8))

   [hna+gtsxkdsaaaaasuvo rk5cyii= ]
8 city tour with length 2509.3 in 0.110 secs for alltours_tsp

all non-redundant tours algorithm (improved alltours_tsp)[19]  

   we said there are n! tours of n cities, and thus 6 tours of 3 cities:
   in [19]:
list(alltours({1, 2, 3}))

   out[19]:
[(1, 2, 3), (1, 3, 2), (2, 1, 3), (2, 3, 1), (3, 1, 2), (3, 2, 1)]

   but this is redundant: (1, 2, 3), (2, 3, 1), and (3, 1, 2) are three
   ways of describing the same tour. so let's arbitrarily say that all
   tours must start with the first city in the set of cities. we'll just
   pull the first city out, and then tack it back on to all the
   permutations of the rest of the cities.

   while we're re-assembling a tour from the start city and the rest,
   we'll take the opportunity to construct the tour as a list rather than
   a tuple. it doesn't matter much now, but later on we will want to
   represent partial tours, to which we will want to append cities one by
   one; appending can only be done to lists, not tuples.
   in [20]:
def alltours(cities):
    "return a list of tours, each a permutation of cities, but each one starting
 with the same city."
    start = first(cities)
    return [[start] + tour(rest)
            for rest in itertools.permutations(cities - {start})]

def first(collection):
    "start iterating over collection, and return the first element."
    return next(iter(collection))

tour = list  # tours are implemented as lists of cities

   we can verify that for 3 cities there are now only 2 tours (not 6) and
   for 4 cities there are 6 tours (not 24):
   in [21]:
alltours({1, 2, 3})

   out[21]:
[[1, 2, 3], [1, 3, 2]]

   in [22]:
alltours({1, 2, 3, 4})

   out[22]:
[[1, 2, 3, 4],
 [1, 2, 4, 3],
 [1, 3, 2, 4],
 [1, 3, 4, 2],
 [1, 4, 2, 3],
 [1, 4, 3, 2]]

   note: we could say that there is only one tour of three cities, because
   [1, 2, 3] and [1, 3, 2] are in some sense the same tour, one going
   clockwise and the other counterclockwise. however, i choose not to do
   that, for two reasons. first, it would mean we can never handle tsp
   problems where the distance from a to b is different from b to a.
   second, it would complicate the code (if only by a line or two).

   we can verify that calling alltours_tsp(cities(8)) still works and
   gives the same tour with the same total distance. but it now runs
   faster:
   in [23]:
plot_tsp(alltours_tsp, cities(8))

   [wfvwj8xzvbkwqaaaabjru5erkjg gg== ]
8 city tour with length 2509.3 in 0.018 secs for alltours_tsp

   now let's try a much harder 10-city tour:
   in [24]:
plot_tsp(alltours_tsp, cities(10))

   [8phnoefrd2xc4a aaaasuvork5cyii= ]
10 city tour with length 2291.8 in 1.636 secs for alltours_tsp

complexity of alltours_tsp[20]  

   it takes about 2 seconds on my machine to solve this 10-city problem.
   in general, the function tsp looks at (n-1)! tours for an n-city
   problem, and each tour has n cities, so the total time required for n
   cities should be roughly proportional to n!. this means that the time
   grows rapidly with the number of cities. really rapidly. this table
   shows the actual time for solving a 10 city problem, and the exepcted
   time for solving larger problems:
   n     expected time for `alltours_tsp(cities(n))`
   10 covering 10! tours = 2 secs
   11 2 secs    11! / 10! &approx; 22 secs
   12 2 secs    12! / 10! &approx; 4 mins
   14 2 secs    14! / 10! &approx; 13 hours
   16 2 secs    16! / 10! &approx; 200 days
   18 2 secs    18! / 10! &approx; 112 years
   25 2 secs    25! / 10! &approx; [21]270 billion years

   there must be a better way ...

approximate algorithms[22]  

   what if we are willing to settle for a tour that is short, but not
   guaranteed to be shortest? then we can save billions of years of
   compute time: we will show several approximate algorithms, which find
   tours that are typically within 10% of the shortest possible tour, and
   can handle thousands of cities in a few seconds. (note: there are more
   sophisticated approximate algorithms that can handle hundreds of
   thousands of cities and come within 0.01% or better of the shortest
   possible tour.)

   so how do we come up with an approximate algorithm? here are two
   general plans of how to create a tour:
     * nearest neighbor algorithm: make the tour go from a city to its
       nearest neighbor. repeat.
     * greedy algorithm: find the shortest distance between any two cities
       and include that edge in the tour. repeat.

   we will expand these ideas into full algorithms.

   in addition, here are four very general strategies that apply not just
   to tsp, but to any optimization problem. an optimization problem is one
   in which the goal is to find a solution that is best (or near-best)
   according to some metric, out of a pool of many candidate solutions.
   the strategies are:
     * repetition strategy: take some algorithm and re-run it multiple
       times, varying some aspect each time, and take the solution with
       the best score.
     * alteration strategy: use some algorithm to create a solution, then
       make small changes to the solution to improve it.
     * ensemble strategy: take two or more algorithms, apply all of them
       to the problem, and pick the best solution.

   and here are two more strategies that work for a wide variety of
   problems:
     * divide and conquer: split the input in half, solve the problem for
       each half, and then combine the two partial solutions.
     * stand on the shoulders of giants or just google it: find out what
       others have done in the past, and either copy it or build on it.

nearest neighbor algorithm: nn_tsp[23]  

   here is a description of the nearest neighbor algorithm:

     nearest neighbor algorithm: start at any city; at each step extend
     the tour by moving from the previous city to its nearest neighbor
     that has not yet been visited.

   so now, instead of considering all n! tours, we are generating a single
   tour. it takes o(n^2 ) time to find the tour, because it has n-1 steps,
   and at each step we consider each of the remaining cities. i implement
   the algorithm as follows:
     * "start at any city": arbitrarily pick the first city.
     * "extend the tour": append to the end of a list of cities.
     * "by moving from the previous city": previous city is tour[-1].
     * "to its nearest neighbor": i will define the function
       nearest_neighbor.
     * "that has not yet been visited": i will keep a set of unvisited
       cities.

   that gives us:
   in [25]:
def nn_tsp(cities):
    """start the tour at the first city; at each step extend the tour
    by moving from the previous city to the nearest neighboring city, c,
    that has not yet been visited."""
    start = first(cities)
    tour = [start]
    unvisited = set(cities - {start})
    while unvisited:
        c = nearest_neighbor(tour[-1], unvisited)
        tour.append(c)
        unvisited.remove(c)
    return tour

def nearest_neighbor(a, cities):
    "find the city in cities that is nearest to city a."
    return min(cities, key=lambda c: distance(c, a))

   note: in python, as in the formal mathematical theory of computability,
   lambda (or   ) is the symbol for function, so "lambda c: distance(c, a)"
   means the function of c that computes the distance from c to the city
   a.

   we can compare the the slow (but optimal) alltours_tsp algorithm to the
   new fast (but approximate) nn_tsp algorithm:
   in [26]:
plot_tsp(alltours_tsp, cities(10))

   [8phnoefrd2xc4a aaaasuvork5cyii= ]
10 city tour with length 2291.8 in 1.681 secs for alltours_tsp

   in [27]:
plot_tsp(nn_tsp, cities(10))

   [waaaaasuvork5cyii= ]
10 city tour with length 2381.4 in 0.000 secs for nn_tsp

   so the nearest neighbor algorithm is a lot faster, but it didn't find
   the shortest tour. to understand where it went wrong, it would be
   helpful to know what city it started from. i can modify plot_tour by
   adding one line of code to highlight the start city with a red square:
   in [28]:
def plot_tour(tour):
    "plot the cities as circles and the tour as lines between them. start city i
s red square."
    start = tour[0]
    plot_lines(list(tour) + [start])
    plot_lines([start], 'rs') # mark the start city with a red square

   in [29]:
plot_tsp(nn_tsp, cities(10))

   [dlm2hrd3zebmnzesgjz
   zopubyhi8bnzfdywilodz73aip4unewbalzemqs7e45z0h+yvytpuzttvpwserai0jt9uwg
   mt4cn
   1+7oqi5wgqjwrcqzahgiigreassikhefrihirhswiiizucckigreassikhefrihirhswiii
   zucck
   igreassikhefrihirhswiiizucckigreassikhefrihirhswiiizucckigreassikhefrih
   irhsw iiizucckigreassikhefrihirv4ffivksewtloqaaaaasuvork5cyii= ]
10 city tour with length 2381.4 in 0.000 secs for nn_tsp

   we can see that the tour moves clockwise from the start city, and
   mostly makes good decisions, but not optimal ones.

   we can compare the performance of these two algorithms on, say, eleven
   different sets of cities instead of just one:
   in [30]:
def length_ratio(cities):
    "the ratio of the tour lengths for nn_tsp and alltours_tsp algorithms."
    return tour_length(nn_tsp(cities)) / tour_length(alltours_tsp(cities))

sorted(length_ratio(cities(8, seed=i*i)) for i in range(11))

   out[30]:
[1.0,
 1.0,
 1.0,
 1.0,
 1.0118279018107388,
 1.0121039193389436,
 1.107851821362778,
 1.139713084817861,
 1.1531140497779002,
 1.1972133336642432,
 1.2160497559961319]

   the ratio of 1.0 means the two algorithms got the same (optimal)
   result; that happened 4 times out of 10. the other times, we see that
   the nn_tsp produces a longer tour, by anything up to 21% worse, with a
   median of 1% worse.

   but more important than that 1% (or even 21%) difference is that the
   nearest neighbor algorithm can quickly tackle problems that the all
   tours algorithm can't touch in the lifetime of the universe. finding a
   tour of 1000 cities takes well under a second:
   in [31]:
plot_tsp(nn_tsp, cities(1000))

   [rrpvzqpvb2oflb9gulvmqlvvag8v8bho6moq6wr2saaaaasuvork5cyii= ]
1000 city tour with length 21275.9 in 0.145 secs for nn_tsp

   can we do better? can we combine the speed of the nearest neighbor
   algorithm with the optimality of the all tours algorithm?

   let's consider where nn_tsp can go wrong. at the end of
   plot_tsp(nn_tsp, cities(10)), we see a very long edge, because there
   are no remaining cities near by. in a way, this just seems like bad
   luck   we started in a place that left us with no good choices at the
   end. just as with buying lottery tickets, we could improve our chance
   of winning by trying more often; in other words, by using the
   repetition strategy.

repeated nearest neighbor algorithm: repeated_nn_tsp[24]  

   here is an easy way to apply the repetition strategy to improve nearest
   neighbors:

     repeated nearest neighbor algorithm: for each of the cities, run the
     nearest neighbor algorithm with that city as the starting point, and
     choose the resulting tour with the shortest total distance.

   so, with n cities we could run the nn_tsp algorithm n times,
   regrettably making the total run time n times longer, but hopefully
   making at least one of the n tours shorter.

   to implement repeated_nn_tsp we just take the shortest tour over all
   starting cities:
   in [32]:
def repeated_nn_tsp(cities):
    "repeat the nn_tsp algorithm starting from each city; return the shortest to
ur."
    return shortest_tour(nn_tsp(cities, start)
                         for start in cities)

   to do that requires a modification of nn_tsp so that the start city can
   be specified as an optional argument:
   in [33]:
def nn_tsp(cities, start=none):
    """start the tour at the first city; at each step extend the tour
    by moving from the previous city to its nearest neighbor
    that has not yet been visited."""
    if start is none: start = first(cities)
    tour = [start]
    unvisited = set(cities - {start})
    while unvisited:
        c = nearest_neighbor(tour[-1], unvisited)
        tour.append(c)
        unvisited.remove(c)
    return tour

   in [34]:
# compare nn_tsp to repeated_nn_tsp
plot_tsp(nn_tsp, cities(100))
plot_tsp(repeated_nn_tsp, cities(100))

   [d6i9nwsgamgjaaaaaelftksuqmcc ]
100 city tour with length 6734.1 in 0.002 secs for nn_tsp

   [x4ywjahe6r2aaaaaelftksuqmcc ]
100 city tour with length 5912.6 in 0.157 secs for repeated_nn_tsp

   we see that repeated_nn_tsp does indeed take longer to run, and yields
   a tour that is shorter.

   let's try again with a smaller map that makes it easier to visualize
   the tours:
   in [35]:
for f in [nn_tsp, repeated_nn_tsp, alltours_tsp]:
    plot_tsp(f, cities(10))

   [dlm2hrd3zebmnzesgjz
   zopubyhi8bnzfdywilodz73aip4unewbalzemqs7e45z0h+yvytpuzttvpwserai0jt9uwg
   mt4cn
   1+7oqi5wgqjwrcqzahgiigreassikhefrihirhswiiizucckigreassikhefrihirhswiii
   zucck
   igreassikhefrihirhswiiizucckigreassikhefrihirhswiiizucckigreassikhefrih
   irhsw iiizucckigreassikhefrihirv4ffivksewtloqaaaaasuvork5cyii= ]
10 city tour with length 2381.4 in 0.000 secs for nn_tsp

   [otwlcobvkaeaaaaasuvork5cyii= ]
10 city tour with length 2297.7 in 0.000 secs for repeated_nn_tsp

   [8pia8v8vultu4aaaaasuvork5cyii= ]
10 city tour with length 2291.8 in 1.619 secs for alltours_tsp

   this time the repeated_nn_tsp gives us a tour that is better than
   nn_tsp, but not quite optimal. so, it looks like repetition is helping.
   but if i want to tackle 1000 cities, i don't really want the run time
   to be 1000 times slower. i'd like a way to moderate the repetition   to
   repeat the nn_tsp starting from a sample of the cities but not all the
   cities.

sampled repeated nearest neighbor algorithm: revised repeated_nn_tsp[25]  

   we can give repeated_nn_tsp an optional argument specifying the number
   of different cities to try starting from. we will implement the
   function sample to draw a random sample of the specified size from all
   the cities. most of the work is done by the standard library function
   random.sample. what our sample adds is the same thing we did with the
   function cities: we ensure that the function returns the same result
   each time for the same arguments, but can return different results if a
   seed parameter is passed in. (in addition, if the sample size, k is
   none or is larger than the population, then return the whole
   population.)
   in [36]:
def repeated_nn_tsp(cities, repetitions=100):
    "repeat the nn_tsp algorithm starting from specified number of cities; retur
n the shortest tour."
    return shortest_tour(nn_tsp(cities, start)
                         for start in sample(cities, repetitions))

def sample(population, k, seed=42):
    "return a list of k elements sampled from population. set random.seed with s
eed."
    if k is none or k > len(population):
        return population
    random.seed(len(population) * k * seed)
    return random.sample(population, k)

   let's compare with 1, 10, and 100 starting cities on a 300 city map:
   in [37]:
def repeat_10_nn_tsp(cities): return repeated_nn_tsp(cities, 10)
def repeat_100_nn_tsp(cities): return repeated_nn_tsp(cities, 100)

   in [38]:
plot_tsp(nn_tsp, cities(300))
plot_tsp(repeat_10_nn_tsp, cities(300))
plot_tsp(repeat_100_nn_tsp, cities(300))

   [w8kjsgl2scg7waaaabjru5erkjggg== ]
299 city tour with length 12752.7 in 0.014 secs for nn_tsp

   [e7f0pbutuh8aaaaasuvork5cyii= ]
299 city tour with length 12070.6 in 0.127 secs for repeat_10_nn_tsp

   [bd7vygv5pruuaaaaaelftksuqmcc ]
299 city tour with length 11598.6 in 1.285 secs for repeat_100_nn_tsp

   as we add more starting cities, the run times get longer and the tours
   get shorter.

   i'd like to understand the tradefoff better. i'd like to have a way to
   compare different algorithms (or different choices of parameters for
   one algorithm) over multiple trials, and summarize the results. that
   means we now have a new vocabulary item:

new vocabulary: "maps"[26]  

   we use the term cities and the function cities to denote a set of
   cities. but now i want to talk about multiple trials over a collection
   of sets of cities: a plural of a plural. english doesn't give us a good
   way to do that, so it would be nice to have a singular noun that is a
   synonym for "set of cities." we'll use the term "map" for this, and the
   function maps to create a collection of maps. just like cities, the
   function maps will give the same result every time it is called with
   the same arguments.
   in [39]:
def maps(num_maps, num_cities):
    "return a tuple of maps, each consisting of the given number of cities."
    return tuple(cities(num_cities, seed=(m, num_cities))
                 for m in range(num_maps))

benchmarking[27]  

   the term benchmarking means running a function on a standard collection
   of inputs, in order to compare its performance. we'll define a
   general-purpose function, benchmark, which takes a function and a
   collection of inputs for that function, and runs the function on each
   of the inputs. it then returns two values: the average time taken per
   input, and the list of results of the function.
   in [40]:
@functools.lru_cache(none)
def benchmark(function, inputs):
    "run function on all the inputs; return pair of (average_time_taken, results
)."
    t0           = time.clock()
    results      = [function(x) for x in inputs]
    t1           = time.clock()
    average_time = (t1 - t0) / len(inputs)
    return (average_time, results)

   note: each time we develop a new algorithm, we would like to compare
   its performance to some standard old algorithms. the use of
   @functools.lru_cache here means that we don't need to to re-run the old
   algorithms on a standard data set each time; we can just cache the old
   results.

   we can use benchmark to see the average call to the absolute value
   function takes less than a microsecond:
   in [41]:
benchmark(abs, range(-10, 10))

   out[41]:
(5.00000000069889e-07,
 [10, 9, 8, 7, 6, 5, 4, 3, 2, 1, 0, 1, 2, 3, 4, 5, 6, 7, 8, 9])

   and we can see that alltours_tsp can handle 6-city maps in under a
   millisecond each:
   in [42]:
benchmark(alltours_tsp, maps(10, 6))

   out[42]:
(0.00032370000000003785,
 [[(574+214j), (236+141j), (556+348j), (677+277j), (833+33j), (578+224j)],
  [(433+6j), (396+143j), (527+431j), (167+227j), (113+100j), (127+105j)],
  [(571+206j), (724+42j), (703+269j), (797+331j), (543+474j), (310+248j)],
  [(12+30j), (344+45j), (693+77j), (548+186j), (279+508j), (171+229j)],
  [(243+271j), (379+72j), (859+331j), (840+411j), (651+478j), (8+369j)],
  [(672+502j), (820+460j), (887+489j), (853+65j), (422+69j), (433+135j)],
  [(38+119j), (644+90j), (622+288j), (602+511j), (509+424j), (275+536j)],
  [(18+208j), (832+456j), (483+477j), (314+533j), (314+539j), (23+596j)],
  [(274+560j), (213+594j), (248+84j), (550+317j), (508+577j), (377+575j)],
  [(813+467j), (438+216j), (270+118j), (71+18j), (125+320j), (199+578j)]])

benchmarking specifically for tsp algorithms[28]  

   now let's add another function, benchmarks, which builds on benchmark
   in two ways:
    1. it compares multiple algorithms, rather than just running one
       algorithm. (hence the plural benchmarks.)
    2. it is specific to tsp algorithms, and rather than returning
       results, it prints summary statistics: the mean, standard
       deviation, min, and max of tour lengths, as well as the time taken
       and the number and size of the sets of cities.

   in [43]:
def benchmarks(tsp_algorithms, maps=maps(30, 60)):
    "print benchmark statistics for each of the algorithms."
    for tsp in tsp_algorithms:
        time, results = benchmark(tsp, maps)
        lengths = [tour_length(r) for r in results]
        print("{:>25} |{:7.0f}   {:4.0f} ({:5.0f} to {:5.0f}) |{:7.3f} secs/map |
 {}     {}-city maps"
              .format(tsp.__name__, mean(lengths), stdev(lengths), min(lengths),
 max(lengths),
                      time, len(maps), len(maps[0])))

how many starting cities is best for nn_tsp?[29]  

   now we are in a position to gain some insight into how many
   repetitions, or starting cities, we need to get a good result from
   nn_tsp.
   in [44]:
def repeat_25_nn_tsp(cities): return repeated_nn_tsp(cities, 25)
def repeat_50_nn_tsp(cities): return repeated_nn_tsp(cities, 50)

   in [45]:
algorithms = [nn_tsp, repeat_10_nn_tsp, repeat_25_nn_tsp, repeat_50_nn_tsp, repe
at_100_nn_tsp]

benchmarks(algorithms, maps(30, 60))

                   nn_tsp |   5668    488 ( 4674 to  6832) |  0.001 secs/map | 30
     60-city maps
         repeat_10_nn_tsp |   5232    374 ( 4577 to  6172) |  0.006 secs/map | 30
     60-city maps
         repeat_25_nn_tsp |   5159    394 ( 4620 to  6069) |  0.014 secs/map | 30
     60-city maps
         repeat_50_nn_tsp |   5118    386 ( 4512 to  6069) |  0.029 secs/map | 30
     60-city maps
        repeat_100_nn_tsp |   5113    384 ( 4512 to  6069) |  0.034 secs/map | 30
     60-city maps

   we see that adding more starting cities results in shorter tours, but
   you start getting diminishing returns after 50 repetitions.

   let's try again with bigger maps:
   in [46]:
benchmarks(algorithms, maps(30, 120))

                   nn_tsp |   7789    458 ( 6877 to  8632) |  0.002 secs/map | 30
     120-city maps
         repeat_10_nn_tsp |   7316    334 ( 6646 to  7870) |  0.021 secs/map | 30
     120-city maps
         repeat_25_nn_tsp |   7242    287 ( 6725 to  7870) |  0.053 secs/map | 30
     120-city maps
         repeat_50_nn_tsp |   7189    295 ( 6646 to  7742) |  0.106 secs/map | 30
     120-city maps
        repeat_100_nn_tsp |   7173    289 ( 6646 to  7736) |  0.213 secs/map | 30
     120-city maps

   in [47]:
benchmarks(algorithms, maps(30, 150))

                   nn_tsp |   8668    485 ( 7183 to  9636) |  0.003 secs/map | 30
     150-city maps
         repeat_10_nn_tsp |   8220    364 ( 7290 to  9197) |  0.033 secs/map | 30
     150-city maps
         repeat_25_nn_tsp |   8117    326 ( 7222 to  8918) |  0.083 secs/map | 30
     150-city maps
         repeat_50_nn_tsp |   8086    300 ( 7237 to  8676) |  0.166 secs/map | 30
     150-city maps
        repeat_100_nn_tsp |   8062    284 ( 7174 to  8603) |  0.331 secs/map | 30
     150-city maps

   the results are similar. so depending on what your priorities are (run
   time versus tour length), somewhere around 25 or 50 repetitions might
   be a good tradeoff.

   next let's try to analyze where nearest neighbors goes wrong, and see
   if we can do something about it.

a problem with nearest neighbors: outliers[30]  

   consider the 20-city map that we build below:
   in [48]:
outliers_list = [city(2, 2),  city(2, 3),  city(2, 4),  city(2, 5),  city(2, 6),

                 city(3, 6),  city(4, 6),  city(5, 6),  city(6, 6),
                 city(6, 5),  city(6, 4),  city(6, 3),  city(6, 2),
                 city(5, 2),  city(4, 2),  city(3, 2),
                 city(1, 6.8),  city(7.8, 6.4),  city(7, 1.2),  city(0.2, 2.8)]

outliers = set(outliers_list)

plot_lines(outliers, 'bo')

   [
   hri8q8+icbccpgmeuqqioggqrbegicjaeewaiioaqrqbgigcbfeeckiieeqriigiqbbfgcc
   kaeeu ayioagrrbaiicbbeesciikaqryagigbbfahc30zgfq1utuahaaaaaelftksuqmcc
   ]

   let's see what a nearest neighbor search does on this map:
   in [49]:
plot_tsp(nn_tsp, outliers)

   [jzkiomrumqmbqlqcjqlkqkq1gskgxfsaowfcwp
   wlcupapduziqdevjqjaujancujskcknrkiomrumqmbqlqcjqlkqkq1gskgxfsaowfcwpwlc
   upapd uziqdevjqjaujancujskiv8hoslz7kcrymaaaaaasuvork5cyii= ]
20 city tour with length 38.8 in 0.000 secs for nn_tsp

   the tour starts out going around the inner square. but then we are left
   with long lines to pick up the outliers. let's try to understand what
   went wrong. first we'll create a new tool to draw better diagrams:
   in [50]:
def plot_labeled_lines(points, *args):
    """plot individual points, labeled with an index number.
    then, args describe lines to draw between those points.
    an arg can be a matplotlib style, like 'ro--', which sets the style until ch
anged,
    or it can be a list of indexes of points, like [0, 1, 2], saying what line t
o draw."""
    # draw points and label them with their index number
    plot_lines(points, 'bo')
    for (label, p) in enumerate(points):
        plt.text(p.x, p.y, '  '+str(label))
    # draw lines indicated by args
    style = 'bo-'
    for arg in args:
        if isinstance(arg, str):
            style = arg
        else: # arg is a list of indexes into points, forming a line
            xs = [points[i].x for i in arg]
            ys = [points[i].y for i in arg]
            plt.plot(xs, ys, style)
    plt.axis('scaled'); plt.axis('off'); plt.show()

   in the diagram below, imagine we are running a nearest neighbor
   algorithm, and it has created a partial tour from city 0 to city 4. now
   there is a choice. city 5 is the nearest neighbor. but if we don't take
   city 16 at this point, we will have to pay a higher price sometime
   later to pick up city 16.
   in [51]:
plot_labeled_lines(outliers_list, 'bo-', [0, 1, 2, 3, 4], 'ro--', [4, 16], 'bo--
', [4, 5])

   [gaaaabjru5erkjggg== ]

   it seems that picking up an outlier is sometimes a good idea, but
   sometimes going directly to the nearest neighbor is a better idea. so
   what can we do? it is difficult to make the choice between an outlier
   and a nearest neighbor while we are constructing a tour, because we
   don't have the context of the whole tour yet. so here's an alternative
   idea: don't try to make the right choice while constructing the tour;
   just go ahead and make any choice, then when the tour is complete,
   alter it to correct problems caused by outliers (or other causes).

new vocabulary: "segment"[31]  

   we'll define a segment as a subsequence of a tour: a sequence of
   consecutive cities within a tour. a tour forms a loop, but a segment
   does not have a loop; it is open-ended on both ends. so, if [a, b, c,
   d] is a 4-city tour, then segments include [a, b], [b, c, d], and many
   others. note that the segment [a, b, c, d] is different than the tour
   [a, b, c, d]; the tour returns from d to a but the segment does not.

altering tours by reversing segments[32]  

   one way we could try to improve a tour is by reversing a segment.
   consider this tour:
   in [52]:
cross = [city(9, 3),  city(3, 10),  city(2, 16),  city(3, 21),  city(9, 28),
         city(26, 3), city(32, 10), city(33, 16), city(32, 21), city(26, 28)]

plot_labeled_lines(cross, range(-1,10))

   [piundgwac7tpee9gmpsipi1
   ne6jsnbupeqka2psipi1nskryzqalihktu1krlkmjiuiwvotepgsqumjsnbupeqka2psipi
   1nskr
   yzqalihktu1krlkmjiuiwvotepgsqumjsnbupeqka2psipi1nskryzqalihktu1krlkmjiu
   iwvot
   epgsqumjsnbupeqka2psipi1nskryzqalihktu1krlkmjiuiwvotepgsqumjsnbupeqka2p
   sipi1 nskryzqalihktu1krlkmjiuiwfsv+abpfa0u1hmaaaaasuvork5cyii= ]

   this is clearly not an optimal tour. we should "uncross" the lines,
   which can be achieved by reversing a segment. the tour as it stands is
   [0, 1, 2, 3, 4, 5, 6, 7, 8, 9]. if we reverse the segment [5, 6, 7, 8,
   9], we get the tour [0, 1, 2, 3, 4, 9, 8, 7, 6, 5], which is the
   optimal tour. in the diagram below, reversing [5, 6, 7, 8, 9] is
   equivalent to deleting the red dashed lines and adding the green dotted
   lines. if the sum of the lengths of the green dotted lines is less than
   the sum of the lengths of the red dashed lines, then we know the
   reversal is an improvement.
   in [53]:
plot_labeled_lines(cross, 'bo-', range(5), range(5, 10),
                          'g:', (4, 9), (0, 5),
                          'r--', (4, 5), (0, 9))

   [iica aaaasuvork5cyii= ]

   here we see that reversing [5, 6, 7, 8, 9] works:
   in [54]:
tour = tour(cross)
tour[5:10] = reversed(tour[5:10])
plot_tour(tour)

   [caaaaasuvork5cyii= ]

   here is how we can check if reversing a segment is an improvement, and
   if so to do it:
   in [55]:
def reverse_segment_if_better(tour, i, j):
    "if reversing tour[i:j] would make the tour shorter, then do it."
    # given tour [...a-b...c-d...], consider reversing b...c to get [...a-c...b-
d...]
    a, b, c, d = tour[i-1], tour[i], tour[j-1], tour[j % len(tour)]
    # are old edges (ab + cd) longer than new ones (ac + bd)? if so, reverse seg
ment.
    if distance(a, b) + distance(c, d) > distance(a, c) + distance(b, d):
        tour[i:j] = reversed(tour[i:j])

   now let's write a function, alter_tour, which finds segments to swap.
   what segments should we consider? i don't know how to be clever about
   the choice, but i do know how to be fairly thorough: try all segments
   of all lengths at all starting positions. i have an intuition that
   trying longer ones first is better (although i'm not sure).

   i worry that even trying all segements won't be enough: after i reverse
   one segment, it might open up opportunities to reverse other segments.
   so, after trying all possible segments, i'll check the tour length. if
   it has been reduced, i'll go through the alter_tour process again.
   in [56]:
def alter_tour(tour):
    "try to alter tour for the better by reversing segments."
    original_length = tour_length(tour)
    for (start, end) in all_segments(len(tour)):
        reverse_segment_if_better(tour, start, end)
    # if we made an improvement, then try again; else stop and return tour.
    if tour_length(tour) < original_length:
        return alter_tour(tour)
    return tour

def all_segments(n):
    "return (start, end) pairs of indexes that form segments of tour of length n
."
    return [(start, start + length)
            for length in range(n, 2-1, -1)
            for start in range(n - length + 1)]

   here is what the list of all segments look like, for n=4:
   in [57]:
all_segments(4)

   out[57]:
[(0, 4), (0, 3), (1, 4), (0, 2), (1, 3), (2, 4)]

   we can see that altering the cross tour does straighten it out:
   in [58]:
plot_tour(alter_tour(tour(cross)))

   [caaaaasuvork5cyii= ]

altered nearest neighbor algorithm (altered_nn_tsp)[33]  

   let's see what happens when we alter the output of nn_tsp:
   in [59]:
def altered_nn_tsp(cities):
    "run nearest neighbor tsp algorithm, and alter the results by reversing segm
ents."
    return alter_tour(nn_tsp(cities))

   let's try this new algorithm on some test cases:
   in [60]:
plot_tsp(altered_nn_tsp, set(cross))

   [caaaaasuvork5cyii= ]
10 city tour with length 93.2 in 0.000 secs for altered_nn_tsp

   in [61]:
plot_tsp(altered_nn_tsp, cities(10))

   [mf+vfo0flfwaaaabjru5erkjggg== ]
10 city tour with length 2333.4 in 0.000 secs for altered_nn_tsp

   it fails to get the optimal result here. let's try benchmarking:
   in [62]:
algorithms = [nn_tsp, repeat_50_nn_tsp, altered_nn_tsp]

benchmarks(algorithms)

                   nn_tsp |   5668    488 ( 4674 to  6832) |  0.001 secs/map | 30
     60-city maps
         repeat_50_nn_tsp |   5118    386 ( 4512 to  6069) |  0.029 secs/map | 30
     60-city maps
           altered_nn_tsp |   4820    233 ( 4450 to  5346) |  0.008 secs/map | 30
     60-city maps

   this is quite encouraging; altered_nn_tsp gives shorter tours and is
   faster than repeating nearest neighbors from 50 starting cities. could
   we do better?

altered repeated nearest neighbor algorithm (altered_repeated_nn_tsp)[34]  

   we have seen that the nearest neighbor algorithm is improved by both
   the alteration and repetition strategies. so why not apply both
   strategies?
   in [63]:
def repeated_altered_nn_tsp(cities, repetitions=20):
    "use alteration to improve each repetition of nearest neighbors."
    return shortest_tour(alter_tour(nn_tsp(cities, start))
                         for start in sample(cities, repetitions))

def repeat_5_altered_nn_tsp(cities): return repeated_altered_nn_tsp(cities, 5)

   let's see it in action:
   in [64]:
plot_tsp(repeated_altered_nn_tsp, cities(100))

   [wppcyzq1v5brgaa aabjru5erkjggg== ]
100 city tour with length 5701.6 in 0.541 secs for repeated_altered_nn_tsp

   that looks like a good tour. let's gather more data:
   in [65]:
algorithms = [nn_tsp, repeat_50_nn_tsp, altered_nn_tsp, repeated_altered_nn_tsp]

benchmarks(algorithms)
print('-' * 100)
benchmarks(algorithms, maps(30, 120))

                   nn_tsp |   5668    488 ( 4674 to  6832) |  0.001 secs/map | 30
     60-city maps
         repeat_50_nn_tsp |   5118    386 ( 4512 to  6069) |  0.029 secs/map | 30
     60-city maps
           altered_nn_tsp |   4820    233 ( 4450 to  5346) |  0.008 secs/map | 30
     60-city maps
  repeated_altered_nn_tsp |   4640    194 ( 4298 to  4991) |  0.148 secs/map | 30
     60-city maps
--------------------------------------------------------------------------------
--------------------
                   nn_tsp |   7789    458 ( 6877 to  8632) |  0.002 secs/map | 30
     120-city maps
         repeat_50_nn_tsp |   7189    295 ( 6646 to  7742) |  0.106 secs/map | 30
     120-city maps
           altered_nn_tsp |   6589    202 ( 6188 to  7016) |  0.036 secs/map | 30
     120-city maps
  repeated_altered_nn_tsp |   6402    185 ( 6015 to  6779) |  0.701 secs/map | 30
     120-city maps

   so, alteration gives the most gain, but alteration plus repetition
   gives a modest improvement in tour length, at the cost of 20 times more
   run time.

non-random maps[35]  

   i thought it would be fun to work on some real maps, instead of random
   maps. first i found [36]a page that lists geographical coordinates of
   us cities. here is an excerpt from that page:
[tcl]  33.23   87.62  tuscaloosa,al
[flg]  35.13  111.67  flagstaff,az
[phx]  33.43  112.02  phoenix,az

   i also found a [37]blog post by randal s. olson who chose 50 landmarks
   across the states and found a tour based on actual road-travel
   distances, not straight-line distance. his data looks like this:

mount rushmore national memorial, south dakota 244, keystone, sd    43.879102
-103.459067
toltec mounds, scott, ar    34.647037   -92.065143
ashfall fossil bed, royal, ne   42.425000   -98.158611

   you can't see, but fields are separated by tabs in this data.

   now we have a problem: we have two similar but different data formats,
   and we want to convert both of them to maps (sets of cities). python
   provides a module, [38]csv (for "comma-separated values"), to parse
   data like this. the function csv.reader takes an input that should be
   an iterable over lines of text, and optionally you can tell it what
   character to use as a delimiter (as well as several other options). for
   each line, it generates a list of fields. for example, for the line
   "[tcl] 33.23 87.62 tuscaloosa,al" it would generate the list ['[tcl]',
   '33.23', '87.62', 'tuscaloosa,al'].

   i define the function coordinate_map to take an iterable of lines (a
   file object or a list of strings), parse it with csv_reader, pick out
   the latitude and longitude columns, and build a city out of each one:
   in [66]:
def lines(text): return text.strip().splitlines()

def coordinate_map(lines, delimiter=' ', lat_col=1, long_col=2, lat_scale=69, lo
ng_scale=-48):
    """make a set of cities from an iterable of lines of text.
    specify the column delimiter, and the zero-based column number of lat and lo
ng.
    treat long/lat as a square x/y grid, scaled by long_scale and lat_scale.
    source can be a file object, or list of lines."""
    return frozenset(city(long_scale * float(row[long_col]),
                          lat_scale  * float(row[lat_col]))
                     for row in csv.reader(lines, delimiter=delimiter, skipiniti
alspace=true))

   you might be wondering about the lat_scale=69, long_scale=-48 part. the
   issue is that we have latitude and longitude for cities, and we want to
   compute the distance between cities. to do that accurately requires
   [39]complicated trigonometry. but we can get an approximation by
   assuming the earth is flat, and that latitude and longitude are on a
   rectangular grid. (this is a bad approximation if you're talking about
   distances of 10,000 miles, but close enough for 100 miles, as long as
   you're not too close to the poles.) i took the latitude of the center
   of the country (wichita, ks: latitude 37.65) and plugged it into a
   [40]length of a degree of latitude and longitude calculator to find
   that, in wichita, one degree of latitude is 69 miles, and one degree of
   longitude is 48 miles. (it is -48 rather than +48 because the us is
   west of the prime meridian.)

   now let's create the map of usa cities, and find a tour for it:
   in [67]:
usa_map = coordinate_map(lines("""
[tcl]  33.23   87.62  tuscaloosa,al
[flg]  35.13  111.67  flagstaff,az
[phx]  33.43  112.02  phoenix,az
[pga]  36.93  111.45  page,az
[tus]  32.12  110.93  tucson,az
[lit]  35.22   92.38  little rock,ar
[sfo]  37.62  122.38  san francisco,ca
[lax]  33.93  118.40  los angeles,ca
[sac]  38.52  121.50  sacramento,ca
[san]  32.73  117.17  san diego,ca
[sbp]  35.23  120.65  san luis obi,ca
[eka]  41.33  124.28  eureka,ca
[den]  39.75  104.87  denver,co
[dca]  38.85   77.04  washington/natl,dc
[mia]  25.82   80.28  miami intl,fl
[tpa]  27.97   82.53  tampa intl,fl
[jax]  30.50   81.70  jacksonville,fl
[tlh]  30.38   84.37  tallahassee,fl
[atl]  33.65   84.42  atlanta,ga
[boi]  43.57  116.22  boise,id
[chi]  41.90   87.65  chicago,il
[ind]  39.73   86.27  indianapolis,in
[dsm]  41.53   93.65  des moines,ia
[sux]  42.40   96.38  sioux city,ia
[ict]  37.65   97.43  wichita,ks
[lex]  38.05   85.00  lexington,ky
[new]  30.03   90.03  new orleans,la
[bos]  42.37   71.03  boston,ma
[pwm]  43.65   70.32  portland,me
[bgr]  44.80   68.82  bangor,me
[car]  46.87   68.02  caribou mun,me
[det]  42.42   83.02  detroit,mi
[stc]  45.55   94.07  st cloud,mn
[dlh]  46.83   92.18  duluth,mn
[stl]  38.75   90.37  st louis,mo
[jan]  32.32   90.08  jackson,ms
[bil]  45.80  108.53  billings,mt
[btm]  45.95  112.50  butte,mt
[rdu]  35.87   78.78  raleigh-durh,nc
[int]  36.13   80.23  winston-salem,nc
[oma]  41.30   95.90  omaha/eppley,ne
[las]  36.08  115.17  las vegas,nv
[rno]  39.50  119.78  reno,nv
[awh]  41.33  116.25  wildhorse,nv
[ewr]  40.70   74.17  newark intl,nj
[saf]  35.62  106.08  santa fe,nm
[nyc]  40.77   73.98  new york,ny
[buf]  42.93   78.73  buffalo,ny
[alb]  42.75   73.80  albany,ny
[far]  46.90   96.80  fargo,nd
[bis]  46.77  100.75  bismarck,nd
[cvg]  39.05   84.67  cincinnati,oh
[cle]  41.42   81.87  cleveland,oh
[okc]  35.40   97.60  oklahoma cty,ok
[pdx]  45.60  122.60  portland,or
[mfr]  42.37  122.87  medford,or
[agc]  40.35   79.93  pittsburgh,pa
[pvd]  41.73   71.43  providence,ri
[chs]  32.90   80.03  charleston,sc
[rap]  44.05  103.07  rapid city,sd
[fsd]  43.58   96.73  sioux falls,sd
[mem]  35.05   90.00  memphis intl,tn
[tys]  35.82   83.98  knoxville,tn
[crp]  27.77   97.50  corpus chrst,tx
[drt]  29.37  100.92  del rio,tx
[iah]  29.97   95.35  houston,tx
[sat]  29.53   98.47  san antonio,tx
[lgu]  41.78  111.85  logan,ut
[slc]  40.78  111.97  salt lake ct,ut
[sgu]  37.08  113.60  saint george,ut
[cny]  38.77  109.75  moab,ut
[mpv]  44.20   72.57  montpelier,vt
[ric]  37.50   77.33  richmond,va
[bli]  48.80  122.53  bellingham,wa
[sea]  47.45  122.30  seattle,wa
[alw]  46.10  118.28  walla walla,wa
[grb]  44.48   88.13  green bay,wi
[mke]  42.95   87.90  milwaukee,wi
[cys]  41.15  104.82  cheyenne,wy
[shr]  44.77  106.97  sheridan,wy
"""))

   in [68]:
plot_lines(usa_map, 'bo')

   [yzjaaaa aelftksuqmcc ]
   in [69]:
plot_tsp(repeated_altered_nn_tsp, usa_map)

   [yrvdjurkb8qaaaabjru5erkjggg== ]
80 city tour with length 13562.6 in 0.297 secs for repeated_altered_nn_tsp

   not bad! there are no obvious errors in the tour (although i'm not at
   all confident it is the optimal tour).

   now let's do the same for randal olson's landmarks. note that the data
   is delimited by tabs, not spaces, and the longitude already has a minus
   sign, so we don't need another one in long_scale.
   in [70]:
usa_landmarks_map = coordinate_map(lines("""
mount rushmore national memorial, south dakota 244, keystone, sd        43.87910
2       -103.459067
toltec mounds, scott, ar        34.647037       -92.065143
ashfall fossil bed, royal, ne   42.425000       -98.158611
maryland state house, 100 state cir, annapolis, md 21401        38.978828
-76.490974
the mark twain house & museum, farmington avenue, hartford, ct  41.766759
-72.701173
columbia river gorge national scenic area, oregon       45.711564       -121.519
633
mammoth cave national park, mammoth cave pkwy, mammoth cave, ky 37.186998
-86.100528
bryce canyon national park, hwy 63, bryce, ut   37.593038       -112.187089
uss alabama, battleship parkway, mobile, al     30.681803       -88.014426
graceland, elvis presley boulevard, memphis, tn 35.047691       -90.026049
wright brothers national memorial visitor center, manteo, nc    35.908226
-75.675730
vicksburg national military park, clay street, vicksburg, ms    32.346550
-90.849850
statue of liberty, liberty island, nyc, ny      40.689249       -74.044500
mount vernon, fairfax county, virginia  38.729314       -77.107386
fort union trading post national historic site, williston, north dakota 1804, nd
48.000160       -104.041483
san andreas fault, san benito county, ca        36.576088       -120.987632
chickasaw national recreation area, 1008 w 2nd st, sulphur, ok 73086    34.45704
3       -97.012213
hanford site, benton county, wa 46.550684       -119.488974
spring grove cemetery, spring grove avenue, cincinnati, oh      39.174331
-84.524997
craters of the moon national monument & preserve, arco, id      43.416650
-113.516650
the alamo, alamo plaza, san antonio, tx 29.425967       -98.486142
new castle historic district, delaware  38.910832       -75.527670
gateway arch, washington avenue, st louis, mo   38.624647       -90.184992
west baden springs hotel, west baden avenue, west baden springs, in     38.56669
7       -86.617524
carlsbad caverns national park, carlsbad, nm    32.123169       -104.587450
pikes peak, colorado    38.840871       -105.042260
okefenokee swamp park, okefenokee swamp park road, waycross, ga 31.056794
-82.272327
cape canaveral, fl      28.388333       -80.603611
glacier national park, west glacier, mt 48.759613       -113.787023
congress hall, congress place, cape may, nj 08204       38.931843       -74.9241
84
olympia entertainment, woodward avenue, detroit, mi     42.387579       -83.0849
43
fort snelling, tower avenue, saint paul, mn     44.892850       -93.180627
hoover dam, boulder city, co    36.012638       -114.742225
white house, pennsylvania avenue northwest, washington, dc      38.897676
-77.036530
uss constitution, boston, ma    42.372470       -71.056575
omni mount washington resort, mount washington hotel road, bretton woods, nh
44.258120       -71.441189
grand canyon national park, arizona     36.106965       -112.112997
the breakers, ochre point avenue, newport, ri   41.469858       -71.298265
fort sumter national monument, sullivan's island, sc    32.752348       -79.8746
92
cable car museum, 94108, 1201 mason st, san francisco, ca 94108 37.794781
-122.411715
yellowstone national park, wy 82190     44.462085       -110.642441
french quarter, new orleans, la 29.958443       -90.064411
c. w. parker carousel museum, south esplanade street, leavenworth, ks   39.31724
5       -94.909536
shelburne farms, harbor road, shelburne, vt     44.408948       -73.247227
taliesin, county road c, spring green, wisconsin        43.141031       -90.0704
67
acadia national park, maine     44.338556       -68.273335
liberty bell, 6th street, philadelphia, pa      39.949610       -75.150282
terrace hill, grand avenue, des moines, ia      41.583218       -93.648542
lincoln home national historic site visitor center, 426 south 7th street, spring
field, il       39.797501       -89.646211
lost world caverns, lewisburg, wv       37.801788       -80.445630
"""), delimiter='\t', long_scale=48)

   in [71]:
plot_lines(usa_landmarks_map, 'bo')

   [d8cnlaaouuagdtlfohfg
   ebbaam7pxg4fbuaa9rlacmebhkdpds7st1gab7dozsmebxaa61ywqusscbdrxjzbwabqzbo
   kgcjh
   aucrsacgsfgaucqsacgsfgaucqsaioqfaexcaoaiyqfakbaaoehyafaklaaoehyafaklaiq
   ebqbf
   wgkaimebqjgwakbiwabqjcwakbiwabqjcwckhauarcicgcjhaucrsacgsfgaucqsacgsfga
   ucqsa ioqfaexcaoaiyqfa0f8adudcibijudgaaaaasuvork5cyii= ]
   in [72]:
plot_tsp(repeated_altered_nn_tsp, usa_landmarks_map)

   [ayjiqv3eiqocaaaaaelftksuqmcc ]
50 city tour with length 10236.7 in 0.125 secs for repeated_altered_nn_tsp

   we can compare that to the tour that randal olson computed as the
   shortest based on road distances:

   [41][best-road-trip-major-landmarks.jpg]

   the two tours are similar but not the same. i think the difference is
   that roads through the rockies and along the coast of the carolinas
   tend to be very windy, so randal's tour avoids them, whereas my program
   assumes staright-line roads and thus includes them. william cook
   provides an analysis, and a [42]tour that is shorter than either
   randal's or mine.

   now let's go back to the [43]original web page to get a bigger map with
   over 1000 cities. a shell command fetches the file:
   in [73]:
! [ -e latlong.htm ] || curl -o http://www.realestate3d.com/gps/latlong.htm

   i note that the page has some lines that i don't want, so i will filter
   out lines that are not in the continental us (that is, cities in alaska
   or hawaii), as well as header lines that do not start with '['.
   in [74]:
def continental_usa(line):
    "does line denote a city in the continental united states?"
    return line.startswith('[') and ',ak' not in line and ',hi' not in line

usa_big_map = coordinate_map(filter(continental_usa, open('latlong.htm')))

   in [75]:
plot_lines(usa_big_map, 'bo')

   [turyhkoqng4aaaaasuvork5cyii= ]

   let's get a baseline tour with nn_tsp:
   in [76]:
plot_tsp(nn_tsp, usa_big_map)

   [sbleaumqedg2eon
   1xrqzaeoiqleostqiqiosiyqlbrfuzryvfkoiqiosaiyubrfuwjrzaeoiqleospcurrfiuw
   vhaio
   ihklkgtfurqlfluwiqiosiyqlbrfuzryvfkoiqiosaiyubrfuwjrzaeoiqleospcurrfiuw
   vhaio
   ihklkgtfurqlfluwiqiosiyqlbrfuzryvfkoiqiosaiyubrfuwjrzaeoiqleospcurrfiuw
   vhaio
   ihklkgtfurqlfluwiqiosiyqlbrfuzryvfkoiqiosfwfzmrvf67dwd0aaaaasuvork5cyii
   = ]
1089 city tour with length 52879.1 in 0.177 secs for nn_tsp

   now try to improve on that with repeat_100_nn_tsp and with
   repeat_5_altered_nn_tsp (which will take a while with over 1000
   cities):
   in [77]:
plot_tsp(repeat_100_nn_tsp, usa_big_map)

   [wi5qrsspkko5gaaaabjru5erkjggg== ]
1089 city tour with length 50802.6 in 17.126 secs for repeat_100_nn_tsp

   in [78]:
plot_tsp(repeat_5_altered_nn_tsp, usa_big_map)

   [r5a1bnyts6stjlkij3qwdgxr
   qefdx9tpziveryk4hardoolbbqw4crhta66yt01acxnjjv0owg1ysefr9bkasxjkzsekhe2
   3id18l
   cxy7tmqypbuni4fn0f556wxlaa1ewahjidsqabhqcqmlstmqct2eznsvlkpfwcqryuawbcf
   ejmo7
   miwpgqkphobiw14g8fyen9ccympceir4ivbdkcwnwhnw6qqoqjguyal2s1bewc0iqidgawd
   0y9dr
   etj1farvwrwcgfionrvbenxcyypcqhcembhbufs+sutuezevadt2w7klzqxrphcbhsaiaqw
   ttquf
   mj+paxf0kwsn7qcrfoigbocxeysfiypvp4iweaqhacv3lpmqjvusrmw3f0ryciiqqnlsu3m
   7up5f
   waw4x7yfxmatceigxsg9+bltsruoolgets0s43b7qysfiaiceiiooqrbeirarfgigiaigyi
   wearb
   eairyseigiaeisjcearbcesehsaighcicatbeaqhebewgiaiqiailarbeirarfgigiaigyi
   wearb
   eairyseigiaeisjcearbcesehsaighcicatbeaqhebewgiaiqiailarbeirarfgigiaigyi
   wearb
   eairyseigiaeisjcearbcesehsaighcicatbeaqhebewgiaiqiailarbeirarfgigiaigyi
   wearb eal5fxkvhtv2itp1aaaaaelftksuqmcc ]
1089 city tour with length 44234.6 in 23.149 secs for repeat_5_altered_nn_tsp

   again we see that we do better by spending our run time budget on
   alteration rather than on repetition. this time we saved over 8,000
   miles of travel in half a minute of computation!

greedy algorithm: greedy_tsp[44]  

   at the start of the approximate algorithms section, we mentioned two
   ideas:
    1. nearest neighbor algorithm: make the tour go from a city to its
       nearest neighbor. repeat.
    2. greedy algorithm: find the shortest distance between any two cities
       and include that in the tour. repeat.

   it is time to develop the greedy algorithm, so-called because at every
   step it greedily adds to the tour the edge that is shortest (even if
   that is not best in terms of long-range planning). the nearest neighbor
   algorithm always extended the tour by adding on to the end. the greedy
   algorithm is different in that it doesn't have a notion of end of the
   tour; instead it keeps a set of partial segments. here's a brief
   statement of the algorithm:

     greedy algorithm: maintain a set of segments; intially each city
     defines its own 1-city segment. find the shortest possible edge that
     connects two endpoints of two different segments, and join those
     segments with that edge. repeat until we form a segment that tours
     all the cities.

   on each step of the algorithm, we want to "find the shortest possible
   edge that connects two endpoints." that seems like an expensive
   operation to do on each step. so we will add in some data structures to
   enable us to speed up the computation. here's a more detailed sketch of
   the algorithm:
    1. pre-compute a list of edges, sorted by shortest edge first. an edge
       is a pair of cities; if the list contains (a, b) then it does not
       contain (b, a), and it never contains (a, a).
    2. maintain a dict that maps endpoints to segments, e.g. {a: [a, b, c,
       d], d: [a, b, c, d]}. initially, each city is the endpoint of its
       own 1-city-long segment, but as we join segments together, some
       cities are no longer endpoints and are removed from the dict.
    3. go through the edges in shortest-first order. when you find an edge
       (a, b) such that both a and b are endpoints of different segments,
       then join the two segments together. maintain the endpoints dict to
       reflect this new segment. stop when you create a segment that
       contains all the cities.

   let's consider an example: assume we have seven cities, labeled a
   through g. suppose cg happens to be the shortest edge. we would add the
   edge to the partial tour, by joining the segment that contains c with
   the segment that contains g. in this case, the joining is easy, because
   each segment is one city long; we join them to form a segment two
   cities long. we then look at the next shortest edge and continue the
   process, joining segments as we go, as shown in the table below. some
   edges cannot be used. for example, fd cannot be used, because by the
   time it becomes the shortest edge, d is already in the interior of a
   segment. next, ae cannot be used, even though both a and e are
   endpoints, because it would make a loop out of acgde. finally, note
   that sometimes we may have to reverse a segment. for example, ef can
   merge agcde and bf, but first we have to reverse bf to fb.
   shortest edge  usage of edge   resulting segments
                                      a; b; c; d; e; f; g
   cg            join c to g      a; b; cg; d; e; f
   de            join d to e      a; b; cg; de; f
   ac            join a to cg     b; acg; de; f
   gd            join acg to d    b; acgde; f
   fd            discard          b; acgde; f
   ae            discard          b; acgde; f
   bf            join b to f      bf; acgde
   cf            discard          bf; acgde
   ef            join acgde to fb acgdefb

   here is the code:
   in [79]:
def greedy_tsp(cities):
    """go through edges, shortest first. use edge to join segments if possible."
""
    endpoints = {c: [c] for c in cities} # a dict of {endpoint: segment}
    for (a, b) in shortest_edges_first(cities):
        if a in endpoints and b in endpoints and endpoints[a] != endpoints[b]:
            new_segment = join_endpoints(endpoints, a, b)
            if len(new_segment) == len(cities):
                return new_segment

# to do: functions: shortest_edges_first, join_endpoints

   note: the endpoints dict is serving two purposes. first, the keys of
   the dict are all the cities that are endpoints of some segments, making
   it possible to ask "a in endpoints" to see if city a is an endpoint.
   second, the values of the dict are all the segments, making it possible
   to ask "endpoints[a] != endpoints[b]" to make sure that the two cities
   are endpoints of different segments, not of the same segment.

   the shortest_edges_first function is easy: generate all (a, b) pairs of
   cities, and sort by the distance between the cities. (note: i use the
   conditional if id(a) < id(b) so that i won't have both (a, b) and (b,
   a) in my list of edges, and i won't ever have (a, a).)
   in [80]:
def shortest_edges_first(cities):
    "return all edges between distinct cities, sorted shortest first."
    edges = [(a, b) for a in cities for b in cities
                    if id(a) < id(b)]
    return sorted(edges, key=lambda edge: distance(*edge))

   for the join_endpoints function, i first make sure that a is the last
   element of one segment and b is the first element of the other, by
   reversing segments if necessary. then i add the b segment on to the end
   of the a segment. finally, i update the endpoints dict. this is a bit
   tricky! my first thought was that a and b are no longer endpoints,
   because they have been joined together in the interior of the segment.
   however, that isn't always true. if a was the endpoint of a 1-city
   segment, then when you join it to b, a is still an endpoint. i could
   have had complicated logic to handle the case when a, b, or both, or
   neither were 1-city segments, but i decided on a different tactic:
   first unconditionally delete a and b from the endpoints dict, no matter
   what. then add the two endpoints of the new segment (which is asegment)
   to the endpoints dict.
   in [81]:
def join_endpoints(endpoints, a, b):
    "join b's segment onto the end of a's and return the segment. maintain endpo
ints dict."
    asegment, bsegment = endpoints[a], endpoints[b]
    if asegment[-1] is not a: asegment.reverse()
    if bsegment[0] is not b: bsegment.reverse()
    asegment.extend(bsegment)
    del endpoints[a], endpoints[b] # a and b are no longer endpoints
    endpoints[asegment[0]] = endpoints[asegment[-1]] = asegment
    return asegment

   let's try out the greedy_tsp algorithm on the two usa maps:
   in [82]:
plot_tsp(greedy_tsp, usa_map)

   [hurrvlsj8mfozhfeh5svikwlgktgfiyrhggwqr
   ljrsnhvlshfmszamo2csmbleqbsmfozhgezebbnkmazdyiujhweyhpexewvdmawjlyywhme
   yrl5m
   lazdmiy8mfgyhmeyetgxmazdmpjiymeyhmhkxctcmazdyiujhweyhpexewvdmawjlyywhme
   yrl5m
   lazdmiy8mfgyhmeyetgxmazdmpjiymeyhmhkxctcmazdyiujhweyhpexewvdmawjlyywhme
   yrl5m
   lazdmiy8mfgyhmeyetgxmazdmpjiymeyhmhkxctcmazdyiujhweyhpexewvdmawjlyywhme
   yrl5m
   lazdmiy8mfgyhmeyetgxmazdmpjiymeyhmhkxctcmazdyiujhweyhpexewvdmawjlyywhme
   yrl7+ h76nk+b8wxpeaaaaaelftksuqmcc ]
80 city tour with length 16087.5 in 0.006 secs for greedy_tsp

   in [83]:
plot_tsp(greedy_tsp, usa_big_map)

   [ay5suy5twxczaaaaaelftksuqmcc ]
1089 city tour with length 46981.5 in 1.052 secs for greedy_tsp

   the greedy algorithm is worse than nearest neighbors, but it is fast
   (especially on the big map). let's see if the alteration strategy can
   help:
   in [84]:
def altered_greedy_tsp(cities):
    "run greedy tsp algorithm, and alter the results by reversing segments."
    return alter_tour(greedy_tsp(cities))

   in [85]:
plot_tsp(altered_greedy_tsp, usa_map)

   [wpmeycbxnnllqaaaabjru5erkjggg== ]
80 city tour with length 14133.3 in 0.022 secs for altered_greedy_tsp

   in [86]:
plot_tsp(altered_greedy_tsp, usa_big_map)

   [0ry8ylk7ycffeg3eq0ls29rqisfiagxmyji1cpyuododbxry1gx
   shyqrqoxwqiceelxxftqgj0b6tiuuq+i9sdcqhceejy5tyyymmuh1ktolyiweaqhhkdcua1
   ivyrw
   gwglqrbckc+dmtvcrrfzmhw4xt22tsagbkeqqjfg7h7zih8avaoh1sk2wwlcbj2isbaeqrb
   cetwu
   iaiceioic0eqbceueraciahckcisbeeqhfbewaiciaihilaqbeeqqhfhiqiciiqiwkiqbee
   irysf
   iaiceioic0eqbceueraciahckcisbeeqhfbewaiciaihilaqbeeqqhfhiqiciiqiwkiqbee
   irysf
   iaiceioic0eqbceueraciahckcisbeeqhfbewaiciaihilaqbeeqqhfhiqiciiqiwkiqbee
   irysf iaiceioic0eqbceueraciahckp8pflmb7s53vumaaaaasuvork5cyii= ]
1089 city tour with length 43769.9 in 4.177 secs for altered_greedy_tsp

   that's the best result yet on the big map. let's look at some
   benchmarks:
   in [87]:
algorithms = [altered_nn_tsp, altered_greedy_tsp, repeated_altered_nn_tsp]

benchmarks(algorithms)
print('-' * 100)
benchmarks(algorithms, maps(30, 120))

           altered_nn_tsp |   4820    233 ( 4450 to  5346) |  0.008 secs/map | 30
     60-city maps
       altered_greedy_tsp |   4766    207 ( 4320 to  5185) |  0.009 secs/map | 30
     60-city maps
  repeated_altered_nn_tsp |   4640    194 ( 4298 to  4991) |  0.148 secs/map | 30
     60-city maps
--------------------------------------------------------------------------------
--------------------
           altered_nn_tsp |   6589    202 ( 6188 to  7016) |  0.036 secs/map | 30
     120-city maps
       altered_greedy_tsp |   6539    240 ( 5994 to  7203) |  0.037 secs/map | 30
     120-city maps
  repeated_altered_nn_tsp |   6402    185 ( 6015 to  6779) |  0.701 secs/map | 30
     120-city maps

   so overall, the altered greedy algorithm looks slightly better than the
   altered nearest neighbor algorithm and runs in about the same time.
   however, the repeated altered nearest neighbor algorithm does best of
   all (although it takes much longer).

   what about a repeated altered greedy algorithm? that might be a good
   idea, but there is no obvious way to do it. we can't just start from a
   sample of cities, because the greedy algorithm doesn't have a notion of
   starting city.

visualizing the greedy algorithm[45]  

   i would like to see how the process of joining segments unfolds.
   although i dislike copy-and-paste (because it violates the [46]don't
   repeat yourself principle), i'll copy greedy_tsp and make a new version
   called visualize_greedy_tsp which adds one line to plot the segments
   several times as the algorithm is running:
   in [88]:
def visualize_greedy_tsp(cities, plot_sizes):
    """go through edges, shortest first. use edge to join segments if possible.
    plot segments at specified sizes."""
    edges = shortest_edges_first(cities) # a list of (a, b) pairs
    endpoints = {c: [c] for c in cities} # a dict of {endpoint: segment}
    for (a, b) in edges:
        if a in endpoints and b in endpoints and endpoints[a] != endpoints[b]:
            new_segment = join_endpoints(endpoints, a, b)
            plot_segments(endpoints, plot_sizes, distance(a, b)) # <<<< new
            if len(new_segment) == len(cities):
                return new_segment

def plot_segments(endpoints, plot_sizes, dist):
    "if the number of distinct segments is one of plot_sizes, then plot segments
."
    segments = set(map(tuple, endpoints.values()))
    if len(segments) in plot_sizes:
        for s in segments:
            plot_lines(s)
        plt.show()
        print('{} segments, longest edge = {:.0f}'.format(
              len(segments), dist))

   in [89]:
visualize_greedy_tsp(usa_map, (50, 25, 10, 5, 2, 1));

   [t+l9lsuceixjqaaaabjru5erkjggg== ]
50 segments, longest edge = 119

   [d9agjkeypwqhiu3svansl4el7owphy9ks8lcrnrnjc2aj4ft3bk7ddyshsuleekq
   mw4abgc+6c6s0pfinjr1vkq6xj3zwp8anztvoignqmlcrdrjipl7x5mha5fsqbtkrdrfjo1
   iqvmo
   cfcz86jty0jeoswdl4gtgwlm9awdj9sxwhyiuhmzjgpbal9qcfjiuriqkzokm0v95um44b+
   w5s2k
   3iowqranakojsi2aesgo7ndlx1qvv9lpjeglrwmwilkjgrphih1uer7ylcxepeyqcd8ilcx
   epeba
   lkkrkfmisi3kbzy0dpe2syowzyyskzqpjhzxkvmiiehv6oysezgqlcxerkqqjqsrealkyuj
   erkps
   sharkaqulerepcolcxerqurjqkreqlkyebgrqpqsreskkiulergpsslcresquriqezgqlcx
   erkqq
   jqsrealkyujerkpssharkaqulerepcolcxerqurjqkreqlkyebgrqpqsreskkiulergpssl
   cresq
   uriqezgqlcxerkqqjqsrealkyujerkpssharkaqulerepcolcxerqurjqkreqlkyebgrqpq
   sresk kiulergpsslcresq+v925hp4hkfwdqaaaabjru5erkjggg== ]
25 segments, longest edge = 190

   [2waaaabjru5erkjggg== ]
10 segments, longest edge = 255

   [aas89+bbexgraaaaaelftksuqmcc ]
5 segments, longest edge = 335

   [qjfezvtlcz8tzgdhgeajva6gw9a1lpdzxpsfyrglyinhywftfozh
   ligvsyohtfkyhlei+yoldzhmxzkyhuvdgyzrmpyspvuysjamwzckymyowzamoyimlazdmiy
   imliw
   dmmwimlkwjamwyikkqvdmayjkkysdmmwjkkysjamwzckysrcmazdkiopc8mwdkmopiwmwzc
   mopiy
   mazdmipiysiwdmmoiiklwzamoyimlazdmiyimliwdmmwimlkwjamwyikkqvdmayjkkysdmm
   wjkky
   sjamwzckysrcmazdkiopc8mwdkmopiwmwzcmopiymazdmipiysiwdmmoiiklwzamoyimlaz
   dmiyi
   mliwdmmwimlkwjamwyikkqvdmayjkkysdmmwjkkysjamwzckysrcmazdkiopc8mwdkmopiw
   mwzcm opiymazdmipiysiwdmmoyv8d+nb7pkw2teeaaaaasuvork5cyii= ]
2 segments, longest edge = 597

   [wgxfm15ck05aaaaaabjru5erkjggg== ]
1 segments, longest edge = 1021

divide and conquer strategy[47]  

   the next general strategy to consider is divide and conquer. suppose we
   have an algorithm, like alltours_tsp, that is inefficient for large n
   (the alltours_tsp algorithm is o(n!) for n cities). so we can't apply
   alltours_tsp directly to a large set of cities. but we can divide the
   problem into smaller pieces, and then combine those pieces:
    1. split the set of cities in half.
    2. find a tour for each half.
    3. join those two tours into one.

   the trick is that when n is small, then step 2 can be done directly.
   but when n is large, step 2 is done with a recursive call, breaking the
   half into two smaller halves.

   let's work out by hand an example with a small map of just six cities.
   here are the cities:
   in [90]:
cities = cities(6)

plot_labeled_lines(cities)

   [swr4zv6uysjzbavzzrsrseg6gzvyfabmooe04gdbhanqea2gtdqbnoia24qdahanoew6g
   ttianuea2oqdabmooe04gdbhanqea2gtdqbnoia24qdahanoew6g7x+yevmk+y2tigaaaab
   jru5e rkjggg== ]

   step 1 is to divide this set in half. i'll divide it into a left half
   (blue circles) and a right half (black squares):
   in [91]:
plot_labeled_lines(list(cities), 'bo', [3, 4, 0], 'ks', [1, 2, 5])

   [zwu4wfwb0xgaaaaasuvork5cyii= ]

   step 2 is to find a tour for each half:
   in [92]:
plot_labeled_lines(list(cities), 'bo-', [0, 3, 4, 0], 'ks-', [1, 2, 5, 1])

   [ax29ryzxzu88aaaaaelftksuqmcc ]

   step 3 is to combine the two halves. we do that by choosing an edge
   from each half to delete (the edges marked by red dashes) and replacing
   those two edges by two edges that connect the halves (the blue dash-dot
   edges). note that there are two choices of ways to connect the new
   dash-dot lines. pick the one that yields the shortest tour.
   in [93]:
# one way to connect the two segments, giving the tour [1, 3, 4, 0, 2, 5]
plot_labeled_lines(list(cities), 'bo-', [0, 3, 4], 'ks-', [1, 2, 5],
                   'b-.', [0, 1], [4, 5],
                   'r--', [0, 4], [1, 5])

   [a1pj5dmqz3pqaaaa aelftksuqmcc ]

   now we have a feel for what we have to do. let's define the divide and
   conquer algorithm, which we will call dq_tsp. like all tsp algorithms
   it gets a set of cities as input and returns a tour. if the size of the
   set of cities is 3 or less, then just listing the cities in any order
   produces an optimal tour. if there are more than 3 cities, then split
   the cities in half (using split_cities), find a tour for each half
   (using dq_tsp recursively), and join the two tours together (using
   join_tours):
   in [94]:
def dq_tsp(cities):
    """find a tour by divide and conquer: if number of cities is 3 or less,
    any tour is optimal.  otherwise, split the cities in half, solve each
    half recursively, then join those two tours together."""
    if len(cities) <= 3:
        return tour(cities)
    else:
        cs1, cs2 = split_cities(cities)
        return join_tours(dq_tsp(cs1), dq_tsp(cs2))

# to do: functions: split_cities, join_tours

   let's verify that dq_tsp works for three cities:
   in [95]:
plot_tsp(dq_tsp, cities(3))

   [h8rtfzdgdthkqaaaabj ru5erkjggg== ]
3 city tour with length 1203.4 in 0.000 secs for dq_tsp

   if we have more than 3 cities, how do we split them? my approach is to
   imagine drawing an axis-aligned rectangle that is just big enough to
   contain all the cities. if the rectangle is wider than it is tall, then
   order all the cities by x coordiante and split that ordered list in
   half. if the rectangle is taller than it is wide, order and split the
   cities by y coordinate.
   in [96]:
def split_cities(cities):
    "split cities vertically if map is wider; horizontally if map is taller."
    width, height = extent([c.x for c in cities]), extent([c.y for c in cities])
    key = 'x' if (width > height) else 'y'
    cities = sorted(cities, key=lambda c: getattr(c, key))
    mid = len(cities) // 2
    return frozenset(cities[:mid]), frozenset(cities[mid:])

def extent(numbers): return max(numbers) - min(numbers)

   let's show that split_cities is working:
   in [97]:
cs1, cs2 = split_cities(cities)
plot_tour(dq_tsp(cs1))
plot_tour(dq_tsp(cs2))

   [am3+de092x74obcryu3giliez
   h8jlp4ebh8ep+kbfobu4zwfmoajo5ahieckts4nug0doyb2tt1ubiye7p31qqlyvodkokbi
   znjho
   +yx3bqyotpgmklqcimwzudmmmdpqbzy0p0htssookbjpghvmnnrko22oo2lsylsvodkokti
   y6z8e
   ho8lhydlmqfpbnemrkhfisil0kgkiertcyhinbwhiertcyhinbwhiertcyhinbwhiertcyh
   inbwh
   iertcyhinbwhiertcyhinbwhiertcyhinbwhiertcyhinbwhiertcyhinbwhiertcyhinbw
   hiert cyhitp8hf62p30lzgqcaaaaasuvork5cyii= ]

   now for the tricky part: joining two tours together. first we consider
   all ways of deleting one edge from each of the two tours. if we delete
   a edge from a tour we get a segment. we are representing segments as
   lists of cities, the same surface representation as tours. but there is
   a difference in their interpretation. the tour [0, 2, 5] is a triangle
   of three edges, but the segment [0, 2, 5] consists of only two edges,
   from 0 to 2 and from 2 to 5. the segments that result from deleting an
   edge from the tour [0, 2, 5] are:
[0, 2, 5],    [2, 5, 0],    [5, 0, 2]

   you may recognize these as the rotations of the segment [0, 2, 5]. so
   any candidate combined tour consists of taking a rotation of the first
   tour, and appending to it a rotation of the second tour, with one
   caveat: when we go to append the two segments, there are two ways of
   doing it: either keep the second segment as is, or reverse the second
   segment.

   note: in python, sequence[::-1] means to reverse the sequence.
   in [98]:
def join_tours(tour1, tour2):
    "consider all ways of joining the two tours together, and pick the shortest.
"
    segments1, segments2 = rotations(tour1), rotations(tour2)
    tours = [s1 + s2
             for s1 in segments1
             for s  in segments2
             for s2 in (s, s[::-1])]
    return shortest_tour(tours)

def rotations(sequence):
    "all possible rotations of a sequence."
    # a rotation is some suffix of the sequence followed by the rest of the sequ
ence.
    return [sequence[i:] + sequence[:i] for i in range(len(sequence))]

   let's see if it works, first on the 6 city example:
   in [99]:
plot_tsp(dq_tsp, cities(6))

   [wyp9ndfmi9tytjtcyiugbmh
   wgs3wq1d4zqnos2whbg0byb2yvt5qdhesstsohhw+ea+dftpcqdvepdpp6tkvq5a4xapmy6
   dwoo8
   5lzah04p0pstikokzbbmdyomxpydc+ensfnokg6rkqmvc2sadexrsmzrx5cyvtlojuokhmz
   adyzu
   v4fpycl5uf+xt4vruhgisatoqiiimak4rcqzfyeizkbiejhmvbwikpmkq0qyu3gisgyqdhh
   jtmuh
   ipmpoeqkmxwhigsm4hcrzfqcipkziknemlnxiehmkg4ryuzfiskzqthejdmvh4hkpuiqkcx
   uhcks mypdrdl7f32inzgsou2iaaaaaelftksuqmcc ]
6 city tour with length 1431.7 in 0.000 secs for dq_tsp

   that is indeed the optimal tour, achieved by deleting the two dashed
   red lines and adding the dotted blue lines.

   now for the usa map:
   in [100]:
plot_tsp(dq_tsp, usa_map)

   [n
   fbvxzaxlgeadeke1bkxrc2gbnktkd3+lmnkfrswmw6gtqnyjc3ipauydha1dyxsxlyvhgbk
   hwp24
   lcwhqgdvfvsrkzeltfkyhperimwfn82ast1h+vz45gid86owevhvkmiwmkw4bvrvdxfwh8d6
   wfm8r
   cr89zgdhgeagtb8od+1ojegjjsklwzayxercfwkmlazdyjc0miuzicwuhweygrkvwdkahqm
   ajrkh
   xakhdmpigcsjh31mwrigyrhjmtouyrigkrrtfozhgezstfkyhmeystflyrigystflivhgia
   rffmw
   hmeyrljmwrigyrhjmwvhgizhjmwuhweyhpeuuxagyrhgukxzgizhgekxzweyhmekxzsfyri
   gkrrt
   fozhgezstfkyhmeystflyrigystflivhgiarffmwhmeyrljmwrigyrhjmwvhgizhjmwuhwe
   yhpeu
   uxagyrhgukxzgizhgekxzweyhmekxzsfyrigkrrtfozhgezstfkyhmeystflyrigystfliv
   hgiar
   ffmwhmeyrljmwrigyrhjmwvhgizhjmwuhweyhpeuuxagyrhgukxzgizhgekxzweyhmek5f8
   bc671 bdopa1iaaaaasuvork5cyii= ]
80 city tour with length 14883.2 in 0.142 secs for dq_tsp

   not quite as good as altered_greedy_tsp. let's alter it!
   in [101]:
def altered_dq_tsp(cities): return alter_tour(dq_tsp(cities))

   in [102]:
plot_tsp(altered_dq_tsp, usa_map)

   [ido3c5swscl81kyhpelryrg4x0sjxy8mwvhgeawwer4moapc8mwsisj
   yklgrdflyrhgliqqltr7qzjisuzeswgowzcyxllcxx9tfozhgezkzaxlgizhpmsuhweyhpe
   suxag
   yrhgskxzgizhgckxzweyhmgkxjsfyrigkrjtfozhgezktfkyhmeyktflyrigyatelivhgia
   relmw
   hmeyrkpmwrigyrgpmwvhgizhpmsuhweyhpesuxagyrhgskxzgizhgckxzweyhmgkxjsfyri
   gkrjt
   fozhgezktfkyhmeyktflyrigyatelivhgiarelmwhmeyrkpmwrigyrgpmwvhgizhpmsuhwe
   yhpes
   uxagyrhgskxzgizhgckxzweyhmgkxjsfyrigkrjtfozhgezktfkyhmeyktflyrigyateliv
   hgiar elmwhmeyrkpmwrigyrgp+x8tjqufxstwbwaaaabjru5erkjggg== ]
80 city tour with length 14209.6 in 0.109 secs for altered_dq_tsp

   let's just remind ourselves how the algorithms behave on the standard
   test cases:
   in [103]:
algorithms = [nn_tsp, greedy_tsp, dq_tsp, altered_dq_tsp, altered_nn_tsp, altere
d_greedy_tsp,
              repeated_altered_nn_tsp]

benchmarks(algorithms)

                   nn_tsp |   5668    488 ( 4674 to  6832) |  0.001 secs/map | 30
     60-city maps
               greedy_tsp |   5392    306 ( 4554 to  5967) |  0.002 secs/map | 30
     60-city maps
                   dq_tsp |   5268    236 ( 4743 to  5752) |  0.042 secs/map | 30
     60-city maps
           altered_dq_tsp |   4953    221 ( 4575 to  5399) |  0.049 secs/map | 30
     60-city maps
           altered_nn_tsp |   4820    233 ( 4450 to  5346) |  0.008 secs/map | 30
     60-city maps
       altered_greedy_tsp |   4766    207 ( 4320 to  5185) |  0.009 secs/map | 30
     60-city maps
  repeated_altered_nn_tsp |   4640    194 ( 4298 to  4991) |  0.148 secs/map | 30
     60-city maps

   of the non-altered algorithms (the first three lines), divide and
   conquer (dq_tsp) does best. but interestingly, divide and conquer is
   helped less by alter_tour than is the greedy algorithm or nearest
   neighbor algorithm. perhaps it is because divide and conquer constructs
   its tour by putting together pieces that are already good, so
   alter_tour is less able to improve it. also, dq_tsp has a standard
   deviation that is much smaller than the other two   this suggests that
   dq_tsp is not producing really bad tours that can be easily improved by
   alter_tour. in any event, altered_dq_tsp is the worst of the altered
   algorithms, both in average tour length and in run time.

   repeated_altered_nn_tsp remains the best in tour length, although the
   worst in run time.

shoulders of giants: minimum spanning tree algorithm: mst_tsp[48]  

   [49][j.kruskal.jpg]

                         joseph kruskal (wikipedia)

   </a>

   i hope you now believe that you could have come up with some ideas for
   solving the tsp. but even if you can't come up with something all on
   your own, you can always [50]google it, in which case you'll no doubt
   find a giant of a mathematician, [51]joseph kruskal, who, in 1956,
   published [52]a paper that led to an algorithm that most people would
   not have thought of on their own (i know i wouldn't have):

     minimum spanning tree traversal algorithm: construct a minimum
     spanning tree, then do a pre-order traversal. that will give you a
     tour that is guaranteed to be no more than twice as long as the
     minimal tour.

   what does all this jargon mean? it is part of id207, the study
   of vertexes and edges. here is a glossary of terms:
     * a graph is a collection of vertexes and edges.
     * a vertex is a point (such as a city).
     * an edge is a link between two vertexes. edges have lengths.
     * a directed graph is a graph where the edges have a direction. we
       say that the edge goes from the parent vertex to the child vertex.
     * a tree is a directed graph in which there is one distinguished
       vertex called the root that has no parent; every other vertex has
       exactly one parent.
     * a spanning tree (of a set of vertexes) is a tree that contains all
       the vertexes.
     * a minimum spanning tree is a spanning tree with the smallest
       possible sum of edge lengths.
     * a traversal of a tree is a way of visiting all the vertexes in some
       order.
     * a pre-order traversal means that you visit the root first, then do
       a pre-order traversal of each of the children.
     * a guarantee means that, no matter what set of cities is selected,
       the tour found by the minimum spanning tree traversal algorithm
       will never be more than twice as long as the shortest possible
       tour. none of the other algorithms has any guarantee at all (except
       for alltours_tsp, which is guaranteed to find the optimal
       algorithm, if it has enough time to complete).

   we will implement a vertex as a point, and a directed graph as a dict
   of {parent: [child, ...]} pairs.

visualizing graphs and trees[53]  

   i think we will need visualization right away, so before doing anything
   else i will define plot_graph. i will make it plot in red so that we
   can easily tell a tour (blue) from a graph (red).
   in [104]:
def plot_graph(graph):
    "given a graph of the form {parent: [child...]}, plot the vertexes and edges
."
    vertexes = {v for parent in graph for v in graph[parent]} | set(graph)
    edges = {(parent, child) for parent in graph for child in graph[parent]}
    for edge in edges:
        plot_lines(edge, 'ro-')
    total_length = sum(distance(p, c) for (p, c) in edges)
    print('{} node graph of total length: {:.1f}'.format(len(vertexes), total_le
ngth))

   let's try it out:
   in [105]:
ps = [point(0, 0.1),
      point(-2, -1), point(0, -1), point(2, -1),
      point(-2.9, -1.9), point(-1, -1.9), point(1, -1.9), point(2.9, -1.9)]

ptree = {ps[0]: ps[1:4], ps[1]: ps[4:6], ps[3]: ps[6:8]}

plot_graph(ptree)

8 node graph of total length: 10.9

   [whexqnhybwx7waaaabjru5erkjggg== ]

   now our plan is:
    1. implement an algorithm to create a minimum spanning tree.
    2. implement a tree traversal; that will give us our mst_tsp
       algorithm.
    3. understand the guarantee,

creating a minimum spanning tree (mst)[54]  

   now let's see how to create a minimum spanning tree (or mst). kruskal
   has a very nice algorithm to find msts, but with what we have done so
   far, it will be a bit easier to implement another giant's algorithm:

     [55]prim's algorithm for creating a mst: list all the edges and sort
     them, shortest first. initialize a tree to be a single root city
     (we'll arbitrarily shoose the first city). now repeat the following
     until the tree contains all the cities: find the shortest edge that
     links a city (a) that is in the tree to a city (b) that is not yet
     in the tree, and add b to the list of a's children in the tree.

   here's the code. one tricky bit: in the first line inside the while
   loop, we define (a, b) to be an edge in which one of a or b is in the
   tree, using the exclusive-or operator, ^. then in the next line, we
   make sure that a is the one that is in the tree and b is not, by
   swapping if necessary.
   in [106]:
def mst(vertexes):
    """given a set of vertexes, build a minimum spanning tree: a dict of the for
m {parent: [child...]},
    where parent and children are vertexes, and the root of the tree is first(ve
rtexes)."""
    tree  = {first(vertexes): []} # the first city is the root of the tree.
    edges = shortest_edges_first(vertexes)
    while len(tree) < len(vertexes):
        (a, b) = shortest_usable_edge(edges, tree)
        tree[a].append(b)
        tree[b] = []
    return tree

def shortest_usable_edge(edges, tree):
    "find the ehortest edge (a, b) where a is in tree and b is not."
    (a, b) = first((a, b) for (a, b) in edges if (a in tree) ^ (b in tree)) # ^
is "xor"
    return (a, b) if (a in tree) else (b, a)

   let's see what a minimum spanning tree looks like:
   in [107]:
plot_graph(mst(usa_map))

80 node graph of total length: 11518.4

   [wpwnxi6w2xowaaaaabjru5erkjggg== ]

   this algorithm clearly produced a spanning tree. it looks pretty good,
   but how can we be sure the algorithm will always produce a minimum
   spanning tree?
    1. the output is a tree because (1) every city is connected by a path
       from the root, and (2) every city only gets one parent (we only add
       a b that is not in tree), so there can be no loops.
    2. the output is a spanning tree because it contains all the cities.
    3. the output is a minimum spanning tree because each city was added
       with the shortest possible edge. suppose this algorithm produces
       the tree t. for another putative spanning tree to be shorter, it
       would have to contain at least one city c whose edge from its
       parent was shorter than the edge in t. but that is not possible,
       because the algorithm always chooses the shortest possible edge
       from c's parent to c.

   note: there are refinements to prim's algorithm to make it more
   efficient. i won't bother with them because they complicate the code,
   and because mst is already fast enough for our purposes.

turning a minimum spanning tree into a tour (mst_tsp)[56]  

   given a minimum spanning tree, we can generate a tour by doing a
   pre-order traversal, which means the tour starts at the root, then
   visits all the cities in the pre-order traversal of the first child of
   the root, followed by the pre-order traversals of any other children.
   in [108]:
def mst_tsp(cities):
    "create a minimum spanning tree and walk it in pre-order, omitting duplicate
s."
    return preorder_traversal(mst(cities), first(cities))

def preorder_traversal(tree, root):
    "traverse tree in pre-order, starting at root of tree."
    result = [root]
    for child in tree.get(root, ()):
        result.extend(preorder_traversal(tree, child))
    return result

   to better understand pre-order traversal, let's go back to the ptree
   example, and this time label the vertexes:
   in [109]:
p = [point(0, 0.1),
     point(-2, -1), point(0, -1), point(2, -1),
     point(-2.9, -1.9), point(-1, -1.9), point(1, -1.9), point(2.9, -1.9)]

ptree = {p[0]: p[1:4], p[1]: p[4:6], p[3]: p[6:8]}

plot_graph(ptree)
plot_labeled_lines(p)

8 node graph of total length: 10.9

   [wdxi4dvw4bqgwaaaabjru5erkjggg== ]

   a pre-order traversal starting at 0 would go to the first child, 1,
   then to its children, 4 and 5, then since there are no children of 4
   and 5, it would continue with the other children of 0, hitting 2, then
   3, and finally the children of 3, namely 6 and 7. so the following
   should be true:
   in [110]:
preorder_traversal(ptree, p[0]) == [p[0], p[1], p[4], p[5], p[2], p[3], p[6], p[
7]]

   out[110]:
true

   and this is what the pre-order traversal looks like as a tour:
   in [111]:
plot_tour([p[0], p[1], p[4], p[5], p[2], p[3], p[6], p[7]])

   [g
   3j2wul77ywbvsqtxxqeyef3kmirr1onalysntoepdcrjo2tgs9jagpisnbagviqnhievsqn
   h4evs
   qbj4kjqqbr4kdysbl0kdyebl0kay+ji0eaa+ja2egs9ja2hgs9jagpisnbagviqnhievsqn
   h4evs qbj4kjqqbr4kdysbl0kdyebl0kd8h0vc3z07tyq6aaaaaelftksuqmcc ]

   you can think of this as starting at the root (at the top) and going
   around the outside of the tree counterclockwise, as if you were walking
   with your left hand always touching an edge, but skipping cities you
   have already been to.

   we see that the result is a tour, but not an optimal one.

   let's see what mst_tsp can do on the usa map:
   in [112]:
plot_tsp(mst_tsp, usa_map)

   [bwznzamfc5hqaaaaaelftksuqmcc ]
80 city tour with length 17924.5 in 0.004 secs for mst_tsp

   not so great. can the alteration strategy help?
   in [113]:
def altered_mst_tsp(cities): return alter_tour(mst_tsp(cities))

   in [114]:
plot_tsp(altered_mst_tsp, usa_map)

   [vq y0ktgvw7aaaaaelftksuqmcc ]
80 city tour with length 14105.0 in 0.022 secs for altered_mst_tsp

   better. let's go to the benchmarks:
   in [115]:
benchmarks([mst_tsp, nn_tsp, greedy_tsp, dq_tsp])

                  mst_tsp |   5953    361 ( 5334 to  7030) |  0.002 secs/map | 30
     60-city maps
                   nn_tsp |   5668    488 ( 4674 to  6832) |  0.001 secs/map | 30
     60-city maps
               greedy_tsp |   5392    306 ( 4554 to  5967) |  0.002 secs/map | 30
     60-city maps
                   dq_tsp |   5268    236 ( 4743 to  5752) |  0.042 secs/map | 30
     60-city maps

   not very encouraging: mst_tsp is the second slowest and has the longest
   tours. i'm sure i could make it faster (at the cost of making the code
   a bit more complicated), but there is no point if the tours are going
   to be longer.

   what happens when we add the alteration strategy?
   in [116]:
benchmarks([altered_dq_tsp, altered_nn_tsp, altered_mst_tsp, altered_greedy_tsp,
 repeated_altered_nn_tsp])

           altered_dq_tsp |   4953    221 ( 4575 to  5399) |  0.049 secs/map | 30
     60-city maps
           altered_nn_tsp |   4820    233 ( 4450 to  5346) |  0.008 secs/map | 30
     60-city maps
          altered_mst_tsp |   4823    227 ( 4354 to  5250) |  0.009 secs/map | 30
     60-city maps
       altered_greedy_tsp |   4766    207 ( 4320 to  5185) |  0.009 secs/map | 30
     60-city maps
  repeated_altered_nn_tsp |   4640    194 ( 4298 to  4991) |  0.148 secs/map | 30
     60-city maps

   now altered_mst_tsp is in the middle of the pack, both in tour length
   and in run time.

   so why would we want to use the rather complicated minimum spanning
   tree algorithm, when the greedy algorithm is simpler to implement, runs
   faster, and produces shorter tours?

guaranteed tour length![57]  

   the great thing about the minimum spanning tree algorithm is that it
   comes with a guarantee, which none of the other algorithms offer. you
   are guaranteed that the tour length it comes up with will be no worse
   than twice as long as the optimal tour. (and, with a bit more
   complication, you can modify it to give a guarantee of 1.5 times
   longer.) the guarantee works like this:
    1. the minimum spanning tree, by definition, connects all the cities
       with the shortest possible total edge length.
    2. so if you could follow each edge in the spanning tree just once,
       and that formed a legal tour, then that would be guaranteed to be a
       minimal tour.
    3. but you can't do that in general; in general there will be places
       where you skip to the next city without following the spanning
       tree. any such skip, however, is a straight line, and thus will be
       less than you would take if you went to the next city by following
       along the spanning tree.
    4. if you did follow along the spanning tree, you would follow some
       edges twice, and some edges once. hence the total length of the
       tour would be at most twice the spanning tree, and thus at most
       twice the minimal tour.

   a guarantee is great from a theoretical point of view, but in practice
   the greedy or nearest neighbor algorithms do just better than the
   minimum spanning tree, on the maps that we actually see.

shoulders of giants: held-karp algorithm: hk_tsp[58]  

   [59][ibm.3_mathematicians_held_shareshian_karp.ca1964.102650390.lg.jpg]

              held, shareshian, karp (computer history museum)

   </a>

   [60][travelling_salesman_problem.png]

                                  xkcd 399

   </a>

   another algorithm that shows up with a literature search is the
   [61]held-karp id145 algorithm, named after giants
   [62]michael held and [63]richard karp. it is an algorithm for finding
   optimal tours, not approximate ones, so it is not appropriate for large
   n. but even in its simplest form, without any programming tricks, it
   can go quite a bit further than alltours_tsp. that is because
   alltours_tsp is o(n!), while the held-karp algorithm is only o(n^2
   2^*n*). how did held and karp achieve this speedup? they noticed that
   alltours_tsp wastes a lot of time with permutations that can't possibly
   be optimal tours. consider the following 10-city problem, with a 6-city
   segment shown:
   in [117]:
plot_labeled_lines(cross, 'r-', [0, 4, 1, 3, 2, 9])

   [wcvwiou80hyoaaaaabjru5erkjggg== ]

   the alltours_tsp would consider 4! = 24 different tours that start with
   those 6 cities. but that seems wasteful: there is no way that this
   segment could be part of an optimal tour, so why waste time on any
   continuation of it? the proof that this segment can never be part of an
   optimal tour comes down to two things. first, we demonstrate another
   tour that also starts in city 0 and ends in city 9, and along the way
   goes through cities 1 through 4, and is shorter:
   in [118]:
plot_labeled_lines(cross, [0, 1, 2, 3, 4, 9])

   [wcmgqyehh1nmgaaaabjru5erkjggg== ]

   second, we need this key property:

     *given a start city a, an end city c, and a set of middle cities bs,
     then out of all the possible segments that start in a, end in c, and
     go through all and only the cities in bs, only the shortest of those
     segments could ever be part of an optimal tour.

   of course, we don't know that the optimal tour goes through exactly
   those bs cities before hitting c. but if it does, then we need only
   consider the permutation of bs that leads to the shortest segment. so
   we can throw out the red zig-zag segment above, and keep the nice
   smooth blue segment.

   so far we have only been talking about segments. we know that the tsp
   is defined for tours, not segments. so even if we find the shortest
   possible segment, it might not be the shortest possible tour. but
   here's something we do know: a tour has to end somewhere. so just find
   the shortest segment from the start city, a, to every possible end
   city, c. that will give you n-2 segments. out of those, don't choose
   the shortest segment, but rather choose the shortest tour.

   that gives us our algorithm:
   in [119]:
def hk_tsp(cities):
    """the h eld-karpshortest tour of this set of cities.
    for each end city c, find the shortest segment from a (the start) to c.
    out of all these shortest segments, pick the one that is the shortest tour."
""
    a = first(cities)
    return shortest_tour(shortest_segment(a, cities - {a, c}, c)
                         for c in cities if c is not a)

# to do: function: shortest_segment(a, bs, c)

   now for shortest_segment(a, bs, c). it is defined to produce the
   shortest segment that starts in city a, ends in c, and visits some
   permutation of bs cities in the middle. if there are no bs cities, then
   of course the shortest segment is to go directly from a to c. if there
   are bs cities, then one of them has to be the last b city visited (just
   before visiting c). so for each b, find the shortest segment that first
   goes from a, through all the other bs cities, then to b, and finally to
   c. out of all these candidate segments, return the one with the minimum
   segment length.

   note: the decorator @functools.lru_cache makes this a dynamic
   programming algorithm, which is a fancy name meaning that we cache the
   results of sub-computations because we will re-use them multiple times.
   in [120]:
@functools.lru_cache(none)
def shortest_segment(a, bs, c):
    "the shortest segment starting at a, going through all bs, and ending at c."
    if not bs:
        return [a, c]
    else:
        segments = [shortest_segment(a, bs - {b}, b) + [c]
                    for b in bs]
        return min(segments, key=segment_length)

def segment_length(segment):
    "the total of distances between each pair of consecutive cities in the segme
nt."
    # same as tour_length, but without distance(tour[0], tour[-1])
    return sum(distance(segment[i], segment[i-1])
               for i in range(1, len(segment)))

   that's all there is to it. let's compare alltours_tsp with hk_tsp on 10
   city tours:
   in [121]:
plot_tsp(alltours_tsp, cities(10))

   [8pia8v8vultu4aaaaasuvork5cyii= ]
10 city tour with length 2291.8 in 1.650 secs for alltours_tsp

   in [122]:
plot_tsp(hk_tsp, cities(10))

   [8pia8v8vultu4aaaaasuvork5cyii= ]
10 city tour with length 2291.8 in 0.037 secs for hk_tsp

   we see that hk_tsp returns the optimal tour, and it is a lot faster. we
   can take hk_tsp into uncharted territory well beyond the reach of
   alltours_tsp:
   in [123]:
plot_tsp(hk_tsp, cities(14))

   [d6ggx6fvxhhkaaaa aelftksuqmcc ]
14 city tour with length 2886.6 in 1.464 secs for hk_tsp

   in [124]:
plot_tsp(hk_tsp, cities(16))

   [0dji4tti8yaaaaabjru5erkjggg== ]
16 city tour with length 2868.6 in 9.018 secs for hk_tsp

   not bad! in 11 seconds, we did what alltours_tsp would have taken an
   estimated 200 days to complete! let's repeat the table of expected
   times, comparing the all tours algorithm with the held-karp algorithm:
   n `alltours_tsp(cities(n))` `hk_tsp(cities(n))`
   expected time &approx; o(n!) expected time &approx; o(n^2 2^n)
   10 10! tours = 2 secs 0.1 secs
   11 2 secs    11! / 10! &approx; 22 secs 0.2 secs
   12 2 secs    12! / 10! &approx; 4 mins 0.4 secs
   14 2 secs    14! / 10! &approx; 13 hours 3 secs
   16 2 secs    16! / 10! &approx; 200 days 16^2 2^16 tours = 11 secs
   18 2 secs    18! / 10! &approx; 112 years 11 secs    (18/16)^2 2^(18-16)
   &approx; 1 min
   25 2 secs    25! / 10! &approx; 270 billion years 11 secs    (25/16)^2
   2^(25-16) &approx; 4 hours
   50 2 secs    50! / 10! &approx; 5    10^50 years 11 secs    (50/16)^2
   2^(50-16) &approx; 58,000 years

   so if we had some patience, we could find the optimal tour for a 25
   city map, but we still can't handle the 50-city landmarks map. (there
   are refinements to held-karp that can handle 50-city maps, and could do
   it even with 1960s-era computing power.)

   we're starting to run out of tricks, but we have one more general
   strategy to consider.

ensembles of other algorithms: ensemble_tsp[64]  

   when we have several optimization algorithms and we're not sure which
   is best, we can always try them all and take the best result. we will
   define ensemble_tsp, to combine the algorithms we have previously
   developed. first, if the set of input cities is small enough, it solves
   the problem optimally with hk_tsp. if the set is too large, it tries a
   selection of algorithms, and chooses the best resulting tour. the
   result is guaranteed to be as good or better than any of the component
   algorithms; but the run time is guaranteed to be longer than any of the
   component algorithms.
   in [125]:
ensemble = [altered_dq_tsp, altered_greedy_tsp, altered_mst_tsp, repeated_altere
d_nn_tsp]

def ensemble_tsp(cities, threshold=16, algorithms=ensemble):
    "apply all algorithms to cities and take the shortest resulting tour."
    if len(cities) <= threshold:
        return hk_tsp(cities)
    else:
        return shortest_tour(tsp(cities) for tsp in algorithms)

   let's go to the benchmarks:
   in [126]:
benchmarks(ensemble + [ensemble_tsp])

           altered_dq_tsp |   4953    221 ( 4575 to  5399) |  0.049 secs/map | 30
     60-city maps
       altered_greedy_tsp |   4766    207 ( 4320 to  5185) |  0.009 secs/map | 30
     60-city maps
          altered_mst_tsp |   4823    227 ( 4354 to  5250) |  0.009 secs/map | 30
     60-city maps
  repeated_altered_nn_tsp |   4640    194 ( 4298 to  4991) |  0.148 secs/map | 30
     60-city maps
             ensemble_tsp |   4630    187 ( 4298 to  4991) |  0.213 secs/map | 30
     60-city maps

   in [127]:
benchmarks(ensemble + [ensemble_tsp], maps(30, 120))

           altered_dq_tsp |   6771    220 ( 6273 to  7248) |  0.347 secs/map | 30
     120-city maps
       altered_greedy_tsp |   6539    240 ( 5994 to  7203) |  0.037 secs/map | 30
     120-city maps
          altered_mst_tsp |   6616    213 ( 6268 to  7010) |  0.050 secs/map | 30
     120-city maps
  repeated_altered_nn_tsp |   6402    185 ( 6015 to  6779) |  0.701 secs/map | 30
     120-city maps
             ensemble_tsp |   6390    184 ( 6015 to  6779) |  1.100 secs/map | 30
     120-city maps

   in [128]:
benchmarks(ensemble + [ensemble_tsp], maps(10, 250))

           altered_dq_tsp |   9750    288 ( 9187 to 10167) |  3.052 secs/map | 10
     250-city maps
       altered_greedy_tsp |   9229    261 ( 8723 to  9606) |  0.215 secs/map | 10
     250-city maps
          altered_mst_tsp |   9484    142 ( 9190 to  9668) |  0.221 secs/map | 10
     250-city maps
  repeated_altered_nn_tsp |   9187    194 ( 8785 to  9390) |  3.524 secs/map | 10
     250-city maps
             ensemble_tsp |   9153    216 ( 8723 to  9390) |  6.959 secs/map | 10
     250-city maps

   so the ensemble_tsp returns tours that are shortest, but the run time
   is slowest, as expected. it improves on repeated_altered_nn_tsp by less
   than 1%.

further explorations[65]  

   that's all i'm going to write for now. but there are still plenty of
   open questions for you to explore:
     * branch and cut: this is a technique to cut off a search early, when
       a partial solution is obviously not optimal. we saw how held-karp
       cuts off some permutations of cities when another permutation is
       better. a refinement on that is to keep track of, say, the best
       total length of the segment going through all the bs cities. then,
       any time you have a partial segment through some of the bs cities
       that exceeds the best total, we can stop right there, before even
       finishing all the bs. with this technique, you can find optimal
       tours for around 50 cities.
     * id135: lookup the topic "id135" and see
       how it applies to tsp.
     * heuristic algorithms: there are many approaches for using
       heurisitic estimates to find good (but not optimal) tours. for
       example, ant colony optimization algorithms make random choices of
       which edge to follow, and then the edges that occur in the best
       tours get reinforced with some virtual pheromones, and other ants
       tend to follow those pheromones. simulated annealing takes its
       inspiration from metallurgy.
     * the [66]lin-kernighan heuristic is one of the best.
     * the [67]christofides algorithm gives a guarantee of 3/2 the optimal
       tour length (improving on the minimum-spanning-tree guarantee).
     * altered as a function: we defined a lot of one-line functions that
       just called another algorithm, and then calls alter_tour on the
       result. can you write a function, altered(func), which takes a tsp
       algorithm as argument, and returns a tsp algorithm that does the
       original algorithm and then calls alter_tour?
     * why does mst produce an optimal result, while greedy_tsp does not,
       even though the two algorithms have similar structure in the way
       they iterate over shortest_edges_first?
     * the code in this notebook was designed for clarity, not efficiency.
       can you make the code faster?
     * [68]william cook maintains a great page on the tsp.
     * william cook also has a [69]draft chapter on discrete optimization
       featuring tsp. his algorithms are in c, and he chooses a different
       set of algorithms to explore. i find his explanation very beautiful
       and concise.
     * if you are heavily into math, there's a [70]taxonomy of solutions.
     * what else are you interested in?

   this website does not host notebooks, it only renders notebooks
   available on other websites.

   delivered by [71]fastly, rendered by [72]rackspace

   nbviewer github [73]repository.

   nbviewer version: [74]33c4683

   nbconvert version: [75]5.4.0

   rendered (fri, 05 apr 2019 18:20:30 utc)

references

   1. https://nbviewer.jupyter.org/
   2. http://jupyter.org/
   3. https://nbviewer.jupyter.org/faq
   4. https://nbviewer.jupyter.org/format/script/url/norvig.com/ipython/tsp.ipynb
   5. https://nbviewer.jupyter.org/url/norvig.com/ipython/tsp.ipynb
   6. http://norvig.com/ipython/tsp.ipynb
   7. https://nbviewer.jupyter.org/url/norvig.com/ipython/tsp.ipynb#the-traveling-salesperson-problem
   8. http://en.wikipedia.org/wiki/traveling_salesman_problem
   9. https://research.googleblog.com/2016/09/the-280-year-old-algorithm-inside.html
  10. http://www.math.uwaterloo.ca/tsp/history/pictorial/dfj.html
  11. https://nbviewer.jupyter.org/url/norvig.com/ipython/tsp.ipynb#understanding-what-we're-talking-about-(vocabulary)
  12. https://nbviewer.jupyter.org/url/norvig.com/ipython/tsp.ipynb#all-tours-algorithm:-alltours_tsp
  13. https://nbviewer.jupyter.org/url/norvig.com/ipython/tsp.ipynb#representing-tours
  14. https://nbviewer.jupyter.org/url/norvig.com/ipython/tsp.ipynb#representing-cities
  15. http://en.wikipedia.org/wiki/euclidean_distance
  16. https://nbviewer.jupyter.org/url/norvig.com/ipython/tsp.ipynb#representing-points-and-computing-distance
  17. https://nbviewer.jupyter.org/url/norvig.com/ipython/tsp.ipynb#random-sets-of-cities
  18. https://nbviewer.jupyter.org/url/norvig.com/ipython/tsp.ipynb#plotting-tours
  19. https://nbviewer.jupyter.org/url/norvig.com/ipython/tsp.ipynb#all-non-redundant-tours-algorithm-(improved-alltours_tsp)
  20. https://nbviewer.jupyter.org/url/norvig.com/ipython/tsp.ipynb#complexity-of-alltours_tsp
  21. https://www.google.com/search?q=2+seconds*25!+/+10!+in+years
  22. https://nbviewer.jupyter.org/url/norvig.com/ipython/tsp.ipynb#approximate-algorithms
  23. https://nbviewer.jupyter.org/url/norvig.com/ipython/tsp.ipynb#nearest-neighbor-algorithm:-nn_tsp
  24. https://nbviewer.jupyter.org/url/norvig.com/ipython/tsp.ipynb#repeated-nearest-neighbor-algorithm:-repeated_nn_tsp
  25. https://nbviewer.jupyter.org/url/norvig.com/ipython/tsp.ipynb#sampled-repeated-nearest-neighbor-algorithm:-revised-repeated_nn_tsp
  26. https://nbviewer.jupyter.org/url/norvig.com/ipython/tsp.ipynb#new-vocabulary:-"maps"
  27. https://nbviewer.jupyter.org/url/norvig.com/ipython/tsp.ipynb#benchmarking
  28. https://nbviewer.jupyter.org/url/norvig.com/ipython/tsp.ipynb#benchmarking-specifically-for-tsp-algorithms
  29. https://nbviewer.jupyter.org/url/norvig.com/ipython/tsp.ipynb#how-many-starting-cities-is-best-for-nn_tsp?
  30. https://nbviewer.jupyter.org/url/norvig.com/ipython/tsp.ipynb#a-problem-with-nearest-neighbors:-outliers
  31. https://nbviewer.jupyter.org/url/norvig.com/ipython/tsp.ipynb#new-vocabulary:-"segment"
  32. https://nbviewer.jupyter.org/url/norvig.com/ipython/tsp.ipynb#altering-tours-by-reversing-segments
  33. https://nbviewer.jupyter.org/url/norvig.com/ipython/tsp.ipynb#altered-nearest-neighbor-algorithm-(altered_nn_tsp)
  34. https://nbviewer.jupyter.org/url/norvig.com/ipython/tsp.ipynb#altered-repeated-nearest-neighbor-algorithm-(altered_repeated_nn_tsp)
  35. https://nbviewer.jupyter.org/url/norvig.com/ipython/tsp.ipynb#non-random-maps
  36. http://www.realestate3d.com/gps/latlong.htm
  37. http://www.randalolson.com/2015/03/08/computing-the-optimal-road-trip-across-the-u-s/
  38. https://docs.python.org/3/library/csv.html
  39. http://en.wikipedia.org/wiki/haversine_formula
  40. http://www.id19network.com/degreelenllavcalc.html
  41. http://www.randalolson.com/2015/03/08/computing-the-optimal-road-trip-across-the-u-s/
  42. http://www.math.uwaterloo.ca/tsp/usa50/index.html
  43. http://www.realestate3d.com/gps/latlong.htm
  44. https://nbviewer.jupyter.org/url/norvig.com/ipython/tsp.ipynb#greedy-algorithm:-greedy_tsp
  45. https://nbviewer.jupyter.org/url/norvig.com/ipython/tsp.ipynb#visualizing-the-greedy-algorithm
  46. http://en.wikipedia.org/wiki/don't_repeat_yourself
  47. https://nbviewer.jupyter.org/url/norvig.com/ipython/tsp.ipynb#divide-and-conquer-strategy
  48. https://nbviewer.jupyter.org/url/norvig.com/ipython/tsp.ipynb#shoulders-of-giants:-minimum-spanning-tree-algorithm:-mst_tsp
  49. https://en.wikipedia.org/wiki/joseph_kruskal
  50. http://bit.ly/xngt2y
  51. http://en.wikipedia.org/wiki/joseph_kruskal
  52. http://www.cmat.edu.uy/~marclan/tag/sellanes/kruskal.pdf
  53. https://nbviewer.jupyter.org/url/norvig.com/ipython/tsp.ipynb#visualizing-graphs-and-trees
  54. https://nbviewer.jupyter.org/url/norvig.com/ipython/tsp.ipynb#creating-a-minimum-spanning-tree-(mst)
  55. http://en.wikipedia.org/wiki/prim's_algorithm
  56. https://nbviewer.jupyter.org/url/norvig.com/ipython/tsp.ipynb#turning-a-minimum-spanning-tree-into-a-tour-(mst_tsp)
  57. https://nbviewer.jupyter.org/url/norvig.com/ipython/tsp.ipynb#guaranteed-tour-length!
  58. https://nbviewer.jupyter.org/url/norvig.com/ipython/tsp.ipynb#shoulders-of-giants:-held-karp-algorithm:-hk_tsp
  59. http://www.computerhistory.org/collections/catalog/102650390
  60. http://xkcd.com/399/
  61. http://en.wikipedia.org/wiki/held   karp_algorithm
  62. http://www.computerhistory.org/collections/catalog/102650390
  63. http://en.wikipedia.org/wiki/richard_m._karp
  64. https://nbviewer.jupyter.org/url/norvig.com/ipython/tsp.ipynb#ensembles-of-other-algorithms:-ensemble_tsp
  65. https://nbviewer.jupyter.org/url/norvig.com/ipython/tsp.ipynb#further-explorations
  66. http://akira.ruc.dk/~keld/research/lkh/lkh-1.3/doc/lkh_report.pdf
  67. https://en.wikipedia.org/wiki/christofides_algorithm
  68. http://www.math.uwaterloo.ca/tsp/
  69. http://www.math.uwaterloo.ca/~bico/papers/comp_chapter1.pdf
  70. http://cstheory.stackexchange.com/questions/9241/approximation-algorithms-for-metric-tsp
  71. http://www.fastly.com/
  72. https://developer.rackspace.com/?nbviewer=awesome
  73. https://github.com/jupyter/nbviewer
  74. https://github.com/jupyter/nbviewer/commit/33c4683164d5ee4c92dbcd53afac7f13ef033c54
  75. https://github.com/jupyter/nbconvert/releases/tag/5.4.0
