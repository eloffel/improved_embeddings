   (button) toggle navigation
   [1][nav_logo.svg?v=479cefe8d932fb14a67b93911b97d70f]
     * [2]jupyter
     * [3]faq
     * [4]view as code
     * [5]view on gist
     * [6]execute on binder
     * [7]download notebook

a crash course in python for scientists[8]  

   [9]rick muller, sandia national laboratories

   version 0.6

   this work is licensed under a [10]creative commons
   attribution-sharealike 3.0 unported license.

why python?[11]  

   python is the programming language of choice for many scientists to a
   large degree because it offers a great deal of power to analyze and
   model scientific data with relatively little overhead in terms of
   learning, installation or development time. it is a language you can
   pick up in a weekend, and use for the rest of one's life.

   the [12]python tutorial is a great place to start getting a feel for
   the language. to complement this material, i taught a [13]python short
   course years ago to a group of computational chemists during a time
   that i was worried the field was moving too much in the direction of
   using canned software rather than developing one's own methods. i
   wanted to focus on what working scientists needed to be more
   productive: parsing output of other programs, building simple models,
   experimenting with object oriented programming, extending the language
   with c, and simple guis.

   i'm trying to do something very similar here, to cut to the chase and
   focus on what scientists need. in the last year or so, the [14]ipython
   project has put together a notebook interface that i have found
   incredibly valuable. a large number of people have released very good
   ipython notebooks that i have taken a huge amount of pleasure reading
   through. some ones that i particularly like include:
     * rob johansson's [15]excellent notebooks, including [16]scientific
       computing with python and [17]computational quantum physics with
       qutip lectures;
     * [18]xkcd style graphs in matplotlib;
     * [19]a collection of notebooks for using ipython effectively
     * [20]a gallery of interesting ipython notebooks

   i find ipython notebooks an easy way both to get important work done in
   my everyday job, as well as to communicate what i've done, how i've
   done it, and why it matters to my coworkers. i find myself endlessly
   sweeping the [21]ipython subreddit hoping someone will post a new
   notebook. in the interest of putting more notebooks out into the wild
   for other people to use and enjoy, i thought i would try to recreate
   some of what i was trying to get across in the original python short
   course, updated by 15 years of python, numpy, scipy, matplotlib, and
   ipython development, as well as my own experience in using python
   almost every day of this time.

what you need to install[22]  

   there are two branches of current releases in python: the older-syntax
   python 2, and the newer-syntax python 3. this schizophrenia is largely
   intentional: when it became clear that some non-backwards-compatible
   changes to the language were necessary, the python dev-team decided to
   go through a five-year (or so) transition, during which the new
   language features would be introduced and the old language was still
   actively maintained, to make such a transition as easy as possible.
   we're now (2013) past the halfway point, and, imho, at the first time
   when i'm considering making the change to python 3.

   nonetheless, i'm going to write these notes with python 2 in mind,
   since this is the version of the language that i use in my day-to-day
   job, and am most comfortable with. if these notes are important and are
   valuable to people, i'll be happy to rewrite the notes using python 3.

   with this in mind, these notes assume you have a python distribution
   that includes:
     * [23]python version 2.7;
     * [24]numpy, the core numerical extensions for id202 and
       multidimensional arrays;
     * [25]scipy, additional libraries for scientific programming;
     * [26]matplotlib, excellent plotting and graphing libraries;
     * [27]ipython, with the additional libraries required for the
       notebook interface.

   a good, easy to install option that supports mac, windows, and linux,
   and that has all of these packages (and much more) is the [28]entought
   python distribution, also known as epd, which appears to be changing
   its name to enthought canopy. enthought is a commercial company that
   supports a lot of very good work in scientific python development and
   application. you can either purchase a license to use epd, or there is
   also a [29]free version that you can download and install.

   here are some other alternatives, should you not want to use epd:

   linux most distributions have an installation manager. redhat has yum,
   ubuntu has apt-get. to my knowledge, all of these packages should be
   available through those installers.

   mac i use [30]macports, which has up-to-date versions of all of these
   packages.

   windows the [31]pythonxy package has everything you need: install the
   package, then go to start > pythonxy > command prompts > ipython
   notebook server.

   cloud this notebook is currently not running on the [32]ipython
   notebook viewer, but will be shortly, which will allow the notebook to
   be viewed but not interactively. i'm keeping an eye on [33]wakari, from
   [34]continuum analytics, which is a cloud-based ipython notebook.
   wakari appears to support free accounts as well. continuum is a company
   started by some of the core enthought numpy/scipy people focusing on
   big data.

   continuum also supports a bundled, multiplatform python package called
   [35]anaconda that i'll also keep an eye on.

i. python overview[36]  

   this is a quick introduction to python. there are lots of other places
   to learn the language more thoroughly. i have collected a list of
   useful links, including ones to other learning resources, at the end of
   this notebook. if you want a little more depth, [37]python tutorial is
   a great place to start, as is zed shaw's [38]learn python the hard way.

   the lessons that follow make use of the ipython notebooks. there's a
   good introduction to notebooks [39]in the ipython notebook
   documentation that even has a [40]nice video on how to use the
   notebooks. you should probably also flip through the [41]ipython
   tutorial in your copious free time.

   briefly, notebooks have code cells (that are generally followed by
   result cells) and text cells. the text cells are the stuff that you're
   reading now. the code cells start with "in []:" with some number
   generally in the brackets. if you put your cursor in the code cell and
   hit shift-enter, the code will run in the python interpreter and the
   result will print out in the output cell. you can then change things
   around and see whether you understand what's going on. if you need to
   know more, see the [42]ipython notebook documentation or the
   [43]ipython tutorial.

using python as a calculator[44]  

   many of the things i used to use a calculator for, i now use python
   for:
   in [1]:
2+2

   out[1]:
4

   in [2]:
(50-5*6)/4

   out[2]:
5

   (if you're typing this into an ipython notebook, or otherwise using
   notebook file, you hit shift-enter to evaluate a cell.)

   there are some gotchas compared to using a normal calculator.
   in [3]:
7/3

   out[3]:
2

   python integer division, like c or fortran integer division, truncates
   the remainder and returns an integer. at least it does in version 2. in
   version 3, python returns a floating point number. you can get a sneak
   preview of this feature in python 2 by importing the module from the
   future features:
from __future__ import division

   alternatively, you can convert one of the integers to a floating point
   number, in which case the division function returns another floating
   point number.
   in [4]:
7/3.

   out[4]:
2.3333333333333335

   in [5]:
7/float(3)

   out[5]:
2.3333333333333335

   in the last few lines, we have sped by a lot of things that we should
   stop for a moment and explore a little more fully. we've seen, however
   briefly, two different data types: integers, also known as whole
   numbers to the non-programming world, and floating point numbers, also
   known (incorrectly) as decimal numbers to the rest of the world.

   we've also seen the first instance of an import statement. python has a
   huge number of libraries included with the distribution. to keep things
   simple, most of these variables and functions are not accessible from a
   normal python interactive session. instead, you have to import the
   name. for example, there is a math module containing many useful
   functions. to access, say, the square root function, you can either
   first
from math import sqrt


   and then
   in [6]:
sqrt(81)

   out[6]:
9.0

   or you can simply import the math library itself
   in [7]:
import math
math.sqrt(81)

   out[7]:
9.0

   you can define variables using the equals (=) sign:
   in [8]:
width = 20
length = 30
area = length*width
area

   out[8]:
600

   if you try to access a variable that you haven't yet defined, you get
   an error:
   in [9]:
volume

---------------------------------------------------------------------------
nameerror                                 traceback (most recent call last)
<ipython-input-9-0c7fc58f9268> in <module>()
----> 1 volume

nameerror: name 'volume' is not defined

   and you need to define it:
   in [ ]:
depth = 10
volume = area*depth
volume

   you can name a variable almost anything you want. it needs to start
   with an alphabetical character or "_", can contain alphanumeric
   charcters plus underscores ("_"). certain words, however, are reserved
   for the language:
and, as, assert, break, class, continue, def, del, elif, else, except,
exec, finally, for, from, global, if, import, in, is, lambda, not, or,
pass, print, raise, return, try, while, with, yield


   trying to define a variable using one of these will result in a syntax
   error:
   in [10]:
return = 0

  file "<ipython-input-10-2b99136d4ec6>", line 1
    return = 0
           ^
syntaxerror: invalid syntax

   the [45]python tutorial has more on using python as an interactive
   shell. the [46]ipython tutorial makes a nice complement to this, since
   ipython has a much more sophisticated iteractive shell.

strings[47]  

   strings are lists of printable characters, and can be defined using
   either single quotes
   in [11]:
'hello, world!'

   out[11]:
'hello, world!'

   or double quotes
   in [12]:
"hello, world!"

   out[12]:
'hello, world!'

   but not both at the same time, unless you want one of the symbols to be
   part of the string.
   in [13]:
"he's a rebel"

   out[13]:
"he's a rebel"

   in [14]:
'she asked, "how are you today?"'

   out[14]:
'she asked, "how are you today?"'

   just like the other two data objects we're familiar with (ints and
   floats), you can assign a string to a variable
   in [15]:
greeting = "hello, world!"

   the print statement is often used for printing character strings:
   in [16]:
print greeting

hello, world!

   but it can also print data types other than strings:
   in [17]:
print "the area is ",area

the area is  600

   in the above snipped, the number 600 (stored in the variable "area") is
   converted into a string before being printed out.

   you can use the + operator to concatenate strings together:
   in [18]:
statement = "hello," + "world!"
print statement

hello,world!

   don't forget the space between the strings, if you want one there.
   in [19]:
statement = "hello, " + "world!"
print statement

hello, world!

   you can use + to concatenate multiple strings in a single statement:
   in [20]:
print "this " + "is " + "a " + "longer " + "statement."

this is a longer statement.

   if you have a lot of words to concatenate together, there are other,
   more efficient ways to do this. but this is fine for linking a few
   strings together.

lists[48]  

   very often in a programming language, one wants to keep a group of
   similar items together. python does this using a data type called
   lists.
   in [21]:
days_of_the_week = ["sunday","monday","tuesday","wednesday","thursday","friday",
"saturday"]

   you can access members of the list using the index of that item:
   in [22]:
days_of_the_week[2]

   out[22]:
'tuesday'

   python lists, like c, but unlike fortran, use 0 as the index of the
   first element of a list. thus, in this example, the 0 element is
   "sunday", 1 is "monday", and so on. if you need to access the nth
   element from the end of the list, you can use a negative index. for
   example, the -1 element of a list is the last element:
   in [23]:
days_of_the_week[-1]

   out[23]:
'saturday'

   you can add additional items to the list using the .append() command:
   in [24]:
languages = ["fortran","c","c++"]
languages.append("python")
print languages

['fortran', 'c', 'c++', 'python']

   the range() command is a convenient way to make sequential lists of
   numbers:
   in [25]:
range(10)

   out[25]:
[0, 1, 2, 3, 4, 5, 6, 7, 8, 9]

   note that range(n) starts at 0 and gives the sequential list of
   integers less than n. if you want to start at a different number, use
   range(start,stop)
   in [26]:
range(2,8)

   out[26]:
[2, 3, 4, 5, 6, 7]

   the lists created above with range have a step of 1 between elements.
   you can also give a fixed step size via a third command:
   in [27]:
evens = range(0,20,2)
evens

   out[27]:
[0, 2, 4, 6, 8, 10, 12, 14, 16, 18]

   in [28]:
evens[3]

   out[28]:
6

   lists do not have to hold the same data type. for example,
   in [29]:
["today",7,99.3,""]

   out[29]:
['today', 7, 99.3, '']

   however, it's good (but not essential) to use lists for similar objects
   that are somehow logically connected. if you want to group different
   data types together into a composite data object, it's best to use
   tuples, which we will learn about below.

   you can find out how long a list is using the len() command:
   in [30]:
help(len)

help on built-in function len in module __builtin__:

len(...)
    len(object) -> integer

    return the number of items of a sequence or collection.


   in [31]:
len(evens)

   out[31]:
10

iteration, indentation, and blocks[49]  

   one of the most useful things you can do with lists is to iterate
   through them, i.e. to go through each element one at a time. to do this
   in python, we use the for statement:
   in [32]:
for day in days_of_the_week:
    print day

sunday
monday
tuesday
wednesday
thursday
friday
saturday

   this code snippet goes through each element of the list called
   days_of_the_week and assigns it to the variable day. it then executes
   everything in the indented block (in this case only one line of code,
   the print statement) using those variable assignments. when the program
   has gone through every element of the list, it exists the block.

   (almost) every programming language defines blocks of code in some way.
   in fortran, one uses end statements (enddo, endif, etc.) to define code
   blocks. in c, c++, and perl, one uses curly braces {} to define these
   blocks.

   python uses a colon (":"), followed by indentation level to define code
   blocks. everything at a higher level of indentation is taken to be in
   the same block. in the above example the block was only a single line,
   but we could have had longer blocks as well:
   in [33]:
for day in days_of_the_week:
    statement = "today is " + day
    print statement

today is sunday
today is monday
today is tuesday
today is wednesday
today is thursday
today is friday
today is saturday

   the range() command is particularly useful with the for statement to
   execute loops of a specified length:
   in [34]:
for i in range(20):
    print "the square of ",i," is ",i*i

the square of  0  is  0
the square of  1  is  1
the square of  2  is  4
the square of  3  is  9
the square of  4  is  16
the square of  5  is  25
the square of  6  is  36
the square of  7  is  49
the square of  8  is  64
the square of  9  is  81
the square of  10  is  100
the square of  11  is  121
the square of  12  is  144
the square of  13  is  169
the square of  14  is  196
the square of  15  is  225
the square of  16  is  256
the square of  17  is  289
the square of  18  is  324
the square of  19  is  361

slicing[50]  

   lists and strings have something in common that you might not suspect:
   they can both be treated as sequences. you already know that you can
   iterate through the elements of a list. you can also iterate through
   the letters in a string:
   in [35]:
for letter in "sunday":
    print letter

s
u
n
d
a
y

   this is only occasionally useful. slightly more useful is the slicing
   operation, which you can also use on any sequence. we already know that
   we can use indexing to get the first element of a list:
   in [36]:
days_of_the_week[0]

   out[36]:
'sunday'

   if we want the list containing the first two elements of a list, we can
   do this via
   in [37]:
days_of_the_week[0:2]

   out[37]:
['sunday', 'monday']

   or simply
   in [38]:
days_of_the_week[:2]

   out[38]:
['sunday', 'monday']

   if we want the last items of the list, we can do this with negative
   slicing:
   in [39]:
days_of_the_week[-2:]

   out[39]:
['friday', 'saturday']

   which is somewhat logically consistent with negative indices accessing
   the last elements of the list.

   you can do:
   in [40]:
workdays = days_of_the_week[1:6]
print workdays

['monday', 'tuesday', 'wednesday', 'thursday', 'friday']

   since strings are sequences, you can also do this to them:
   in [41]:
day = "sunday"
abbreviation = day[:3]
print abbreviation

sun

   if we really want to get fancy, we can pass a third element into the
   slice, which specifies a step length (just like a third argument to the
   range() function specifies the step):
   in [42]:
numbers = range(0,40)
evens = numbers[2::2]
evens

   out[42]:
[2, 4, 6, 8, 10, 12, 14, 16, 18, 20, 22, 24, 26, 28, 30, 32, 34, 36, 38]

   note that in this example i was even able to omit the second argument,
   so that the slice started at 2, went to the end of the list, and took
   every second element, to generate the list of even numbers less that
   40.

booleans and truth testing[51]  

   we have now learned a few data types. we have integers and floating
   point numbers, strings, and lists to contain them. we have also learned
   about lists, a container that can hold any data type. we have learned
   to print things out, and to iterate over items in lists. we will now
   learn about boolean variables that can be either true or false.

   we invariably need some concept of conditions in programming to control
   branching behavior, to allow a program to react differently to
   different situations. if it's monday, i'll go to work, but if it's
   sunday, i'll sleep in. to do this in python, we use a combination of
   boolean variables, which evaluate to either true or false, and if
   statements, that control branching based on boolean values.

   for example:
   in [43]:
if day == "sunday":
    print "sleep in"
else:
    print "go to work"

sleep in

   (quick quiz: why did the snippet print "go to work" here? what is the
   variable "day" set to?)

   let's take the snippet apart to see what happened. first, note the
   statement
   in [44]:
day == "sunday"

   out[44]:
true

   if we evaluate it by itself, as we just did, we see that it returns a
   boolean value, false. the "==" operator performs equality testing. if
   the two items are equal, it returns true, otherwise it returns false.
   in this case, it is comparing two variables, the string "sunday", and
   whatever is stored in the variable "day", which, in this case, is the
   other string "saturday". since the two strings are not equal to each
   other, the truth test has the false value.

   the if statement that contains the truth test is followed by a code
   block (a colon followed by an indented block of code). if the boolean
   is true, it executes the code in that block. since it is false in the
   above example, we don't see that code executed.

   the first block of code is followed by an else statement, which is
   executed if nothing else in the above if statement is true. since the
   value was false, this code is executed, which is why we see "go to
   work".

   you can compare any data types in python:
   in [45]:
1 == 2

   out[45]:
false

   in [46]:
50 == 2*25

   out[46]:
true

   in [47]:
3 < 3.14159

   out[47]:
true

   in [48]:
1 == 1.0

   out[48]:
true

   in [49]:
1 != 0

   out[49]:
true

   in [50]:
1 <= 2

   out[50]:
true

   in [51]:
1 >= 1

   out[51]:
true

   we see a few other boolean operators here, all of which which should be
   self-explanatory. less than, equality, non-equality, and so on.

   particularly interesting is the 1 == 1.0 test, which is true, since
   even though the two objects are different data types (integer and
   floating point number), they have the same value. there is another
   boolean operator is, that tests whether two objects are the same
   object:
   in [52]:
1 is 1.0

   out[52]:
false

   we can do boolean tests on lists as well:
   in [53]:
[1,2,3] == [1,2,4]

   out[53]:
false

   in [54]:
[1,2,3] < [1,2,4]

   out[54]:
true

   finally, note that you can also string multiple comparisons together,
   which can result in very intuitive tests:
   in [55]:
hours = 5
0 < hours < 24

   out[55]:
true

   if statements can have elif parts ("else if"), in addition to if/else
   parts. for example:
   in [56]:
if day == "sunday":
    print "sleep in"
elif day == "saturday":
    print "do chores"
else:
    print "go to work"

sleep in

   of course we can combine if statements with for loops, to make a
   snippet that is almost interesting:
   in [57]:
for day in days_of_the_week:
    statement = "today is " + day
    print statement
    if day == "sunday":
        print "   sleep in"
    elif day == "saturday":
        print "   do chores"
    else:
        print "   go to work"

today is sunday
   sleep in
today is monday
   go to work
today is tuesday
   go to work
today is wednesday
   go to work
today is thursday
   go to work
today is friday
   go to work
today is saturday
   do chores

   this is something of an advanced topic, but ordinary data types have
   boolean values associated with them, and, indeed, in early versions of
   python there was not a separate boolean object. essentially, anything
   that was a 0 value (the integer or floating point 0, an empty string
   "", or an empty list []) was false, and everything else was true. you
   can see the boolean value of any data object using the bool() function.
   in [58]:
bool(1)

   out[58]:
true

   in [59]:
bool(0)

   out[59]:
false

   in [60]:
bool(["this "," is "," a "," list"])

   out[60]:
true

code example: the fibonacci sequence[52]  

   the [53]fibonacci sequence is a sequence in math that starts with 0 and
   1, and then each successive entry is the sum of the previous two. thus,
   the sequence goes 0,1,1,2,3,5,8,13,21,34,55,89,...

   a very common exercise in programming books is to compute the fibonacci
   sequence up to some number n. first i'll show the code, then i'll
   discuss what it is doing.
   in [61]:
n = 10
sequence = [0,1]
for i in range(2,n): # this is going to be a problem if we ever set n <= 2!
    sequence.append(sequence[i-1]+sequence[i-2])
print sequence

[0, 1, 1, 2, 3, 5, 8, 13, 21, 34]

   let's go through this line by line. first, we define the variable n,
   and set it to the integer 20. n is the length of the sequence we're
   going to form, and should probably have a better variable name. we then
   create a variable called sequence, and initialize it to the list with
   the integers 0 and 1 in it, the first two elements of the fibonacci
   sequence. we have to create these elements "by hand", since the
   iterative part of the sequence requires two previous elements.

   we then have a for loop over the list of integers from 2 (the next
   element of the list) to n (the length of the sequence). after the
   colon, we see a hash tag "#", and then a comment that if we had set n
   to some number less than 2 we would have a problem. comments in python
   start with #, and are good ways to make notes to yourself or to a user
   of your code explaining why you did what you did. better than the
   comment here would be to test to make sure the value of n is valid, and
   to complain if it isn't; we'll try this later.

   in the body of the loop, we append to the list an integer equal to the
   sum of the two previous elements of the list.

   after exiting the loop (ending the indentation) we then print out the
   whole list. that's it!

functions[54]  

   we might want to use the fibonacci snippet with different sequence
   lengths. we could cut an paste the code into another cell, changing the
   value of n, but it's easier and more useful to make a function out of
   the code. we do this with the def statement in python:
   in [62]:
def fibonacci(sequence_length):
    "return the fibonacci sequence of length *sequence_length*"
    sequence = [0,1]
    if sequence_length < 1:
        print "fibonacci sequence only defined for length 1 or greater"
        return
    if 0 < sequence_length < 3:
        return sequence[:sequence_length]
    for i in range(2,sequence_length):
        sequence.append(sequence[i-1]+sequence[i-2])
    return sequence

   we can now call fibonacci() for different sequence_lengths:
   in [63]:
fibonacci(2)

   out[63]:
[0, 1]

   in [64]:
fibonacci(12)

   out[64]:
[0, 1, 1, 2, 3, 5, 8, 13, 21, 34, 55, 89]

   we've introduced a several new features here. first, note that the
   function itself is defined as a code block (a colon followed by an
   indented block). this is the standard way that python delimits things.
   next, note that the first line of the function is a single string. this
   is called a docstring, and is a special kind of comment that is often
   available to people using the function through the python command line:
   in [65]:
help(fibonacci)

help on function fibonacci in module __main__:

fibonacci(sequence_length)
    return the fibonacci sequence of length *sequence_length*


   if you define a docstring for all of your functions, it makes it easier
   for other people to use them, since they can get help on the arguments
   and return values of the function.

   next, note that rather than putting a comment in about what input
   values lead to errors, we have some testing of these values, followed
   by a warning if the value is invalid, and some conditional code to
   handle special cases.

recursion and factorials[55]  

   functions can also call themselves, something that is often called
   recursion. we're going to experiment with recursion by computing the
   factorial function. the factorial is defined for a positive integer n
   as
   $$ n! = n(n-1)(n-2)\cdots 1 $$

   first, note that we don't need to write a function at all, since this
   is a function built into the standard math library. let's use the help
   function to find out about it:
   in [66]:
from math import factorial
help(factorial)

help on built-in function factorial in module math:

factorial(...)
    factorial(x) -> integral

    find x!. raise a valueerror if x is negative or non-integral.


   this is clearly what we want.
   in [67]:
factorial(20)

   out[67]:
2432902008176640000

   however, if we did want to write a function ourselves, we could do
   recursively by noting that
   $$ n! = n(n-1)!$$

   the program then looks something like:
   in [68]:
def fact(n):
    if n <= 0:
        return 1
    return n*fact(n-1)

   in [69]:
fact(20)

   out[69]:
2432902008176640000

   recursion can be very elegant, and can lead to very simple programs.

two more data structures: tuples and dictionaries[56]  

   before we end the python overview, i wanted to touch on two more data
   structures that are very useful (and thus very common) in python
   programs.

   a tuple is a sequence object like a list or a string. it's constructed
   by grouping a sequence of objects together with commas, either without
   brackets, or with parentheses:
   in [70]:
t = (1,2,'hi',9.0)
t

   out[70]:
(1, 2, 'hi', 9.0)

   tuples are like lists, in that you can access the elements using
   indices:
   in [71]:
t[1]

   out[71]:
2

   however, tuples are immutable, you can't append to them or change the
   elements of them:
   in [72]:
t.append(7)

---------------------------------------------------------------------------
attributeerror                            traceback (most recent call last)
<ipython-input-72-50c7062b1d5f> in <module>()
----> 1 t.append(7)

attributeerror: 'tuple' object has no attribute 'append'

   in [73]:
t[1]=77

---------------------------------------------------------------------------
typeerror                                 traceback (most recent call last)
<ipython-input-73-03cc8ba9c07d> in <module>()
----> 1 t[1]=77

typeerror: 'tuple' object does not support item assignment

   tuples are useful anytime you want to group different pieces of data
   together in an object, but don't want to create a full-fledged class
   (see below) for them. for example, let's say you want the cartesian
   coordinates of some objects in your program. tuples are a good way to
   do this:
   in [74]:
('bob',0.0,21.0)

   out[74]:
('bob', 0.0, 21.0)

   again, it's not a necessary distinction, but one way to distinguish
   tuples and lists is that tuples are a collection of different things,
   here a name, and x and y coordinates, whereas a list is a collection of
   similar things, like if we wanted a list of those coordinates:
   in [75]:
positions = [
             ('bob',0.0,21.0),
             ('cat',2.5,13.1),
             ('dog',33.0,1.2)
             ]

   tuples can be used when functions return more than one value. say we
   wanted to compute the smallest x- and y-coordinates of the above list
   of objects. we could write:
   in [76]:
def minmax(objects):
    minx = 1e20 # these are set to really big numbers
    miny = 1e20
    for obj in objects:
        name,x,y = obj
        if x < minx:
            minx = x
        if y < miny:
            miny = y
    return minx,miny

x,y = minmax(positions)
print x,y

0.0 1.2

   here we did two things with tuples you haven't seen before. first, we
   unpacked an object into a set of named variables using tuple
   assignment:
>>> name,x,y = obj


   we also returned multiple values (minx,miny), which were then assigned
   to two other variables (x,y), again by tuple assignment. this makes
   what would have been complicated code in c++ rather simple.

   tuple assignment is also a convenient way to swap variables:
   in [77]:
x,y = 1,2
y,x = x,y
x,y

   out[77]:
(2, 1)

   dictionaries are an object called "mappings" or "associative arrays" in
   other languages. whereas a list associates an integer index with a set
   of objects:
   in [78]:
mylist = [1,2,9,21]

   the index in a dictionary is called the key, and the corresponding
   dictionary entry is the value. a dictionary can use (almost) anything
   as the key. whereas lists are formed with square brackets [],
   dictionaries use curly brackets {}:
   in [79]:
ages = {"rick": 46, "bob": 86, "fred": 21}
print "rick's age is ",ages["rick"]

rick's age is  46

   there's also a convenient way to create dictionaries without having to
   quote the keys.
   in [80]:
dict(rick=46,bob=86,fred=20)

   out[80]:
{'bob': 86, 'fred': 20, 'rick': 46}

   the len() command works on both tuples and dictionaries:
   in [81]:
len(t)

   out[81]:
4

   in [82]:
len(ages)

   out[82]:
3

plotting with matplotlib[57]  

   we can generally understand trends in data by using a plotting program
   to chart it. python has a wonderful plotting library called
   [58]matplotlib. the ipython notebook interface we are using for these
   notes has that functionality built in.

   as an example, we have looked at two different functions, the fibonacci
   function, and the factorial function, both of which grow faster than
   polynomially. which one grows the fastest? let's plot them. first,
   let's generate the fibonacci sequence of length 20:
   in [83]:
fibs = fibonacci(10)

   next lets generate the factorials.
   in [84]:
facts = []
for i in range(10):
    facts.append(factorial(i))

   now we use the matplotlib function plot to compare the two.
   in [85]:
figsize(8,6)
plot(facts,label="factorial")
plot(fibs,label="fibonacci")
xlabel("n")
legend()

   out[85]:
<matplotlib.legend.legend at 0x10d1b4890>

   [h0sxosygshlraaaaaelftksuqmcc ]

   the factorial function grows much faster. in fact, you can't even see
   the fibonacci sequence. it's not entirely surprising: a function where
   we multiply by n each iteration is bound to grow faster than one where
   we add (roughly) n each iteration.

   let's plot these on a semilog plot so we can see them both a little
   more clearly:
   in [86]:
semilogy(facts,label="factorial")
semilogy(fibs,label="fibonacci")
xlabel("n")
legend()

   out[86]:
<matplotlib.legend.legend at 0x10d2bee90>

   [wezcl5pbdd7rgaaaabjru5erkjggg== ]

   there are many more things you can do with matplotlib. we'll be looking
   at some of them in the sections to come. in the meantime, if you want
   an idea of the different things you can do, look at the matplotlib
   [59]gallery. rob johansson's ipython notebook [60]introduction to
   matplotlib is also particularly good.

conclusion of the python overview[61]  

   there is, of course, much more to the language than i've covered here.
   i've tried to keep this brief enough so that you can jump in and start
   using python to simplify your life and work. my own experience in
   learning new things is that the information doesn't "stick" unless you
   try and use it for something in real life.

   you will no doubt need to learn more as you go. i've listed several
   other good references, including the [62]python tutorial and [63]learn
   python the hard way. additionally, now is a good time to start
   familiarizing yourself with the [64]python documentation, and, in
   particular, the [65]python language reference.

   tim peters, one of the earliest and most prolific python contributors,
   wrote the "zen of python", which can be accessed via the "import this"
   command:
   in [87]:
import this

the zen of python, by tim peters

beautiful is better than ugly.
explicit is better than implicit.
simple is better than complex.
complex is better than complicated.
flat is better than nested.
sparse is better than dense.
readability counts.
special cases aren't special enough to break the rules.
although practicality beats purity.
errors should never pass silently.
unless explicitly silenced.
in the face of ambiguity, refuse the temptation to guess.
there should be one-- and preferably only one --obvious way to do it.
although that way may not be obvious at first unless you're dutch.
now is better than never.
although never is often better than *right* now.
if the implementation is hard to explain, it's a bad idea.
if the implementation is easy to explain, it may be a good idea.
namespaces are one honking great idea -- let's do more of those!

   no matter how experienced a programmer you are, these are words to
   meditate on.

ii. numpy and scipy[66]  

   [67]numpy contains core routines for doing fast vector, matrix, and
   id202-type operations in python. [68]scipy contains additional
   routines for optimization, special functions, and so on. both contain
   modules written in c and fortran so that they're as fast as possible.
   together, they give python roughly the same capability that the
   [69]matlab program offers. (in fact, if you're an experienced matlab
   user, there a [70]guide to numpy for matlab users just for you.)

making vectors and matrices[71]  

   fundamental to both numpy and scipy is the ability to work with vectors
   and matrices. you can create vectors from lists using the array
   command:
   in [88]:
array([1,2,3,4,5,6])

   out[88]:
array([1, 2, 3, 4, 5, 6])

   you can pass in a second argument to array that gives the numeric type.
   there are a number of types [72]listed here that your matrix can be.
   some of these are aliased to single character codes. the most common
   ones are 'd' (double precision floating point number), 'd' (double
   precision complex number), and 'i' (int32). thus,
   in [89]:
array([1,2,3,4,5,6],'d')

   out[89]:
array([ 1.,  2.,  3.,  4.,  5.,  6.])

   in [90]:
array([1,2,3,4,5,6],'d')

   out[90]:
array([ 1.+0.j,  2.+0.j,  3.+0.j,  4.+0.j,  5.+0.j,  6.+0.j])

   in [91]:
array([1,2,3,4,5,6],'i')

   out[91]:
array([1, 2, 3, 4, 5, 6], dtype=int32)

   to build matrices, you can either use the array command with lists of
   lists:
   in [92]:
array([[0,1],[1,0]],'d')

   out[92]:
array([[ 0.,  1.],
       [ 1.,  0.]])

   you can also form empty (zero) matrices of arbitrary shape (including
   vectors, which numpy treats as vectors with one row), using the zeros
   command:
   in [93]:
zeros((3,3),'d')

   out[93]:
array([[ 0.,  0.,  0.],
       [ 0.,  0.,  0.],
       [ 0.,  0.,  0.]])

   the first argument is a tuple containing the shape of the matrix, and
   the second is the data type argument, which follows the same
   conventions as in the array command. thus, you can make row vectors:
   in [94]:
zeros(3,'d')

   out[94]:
array([ 0.,  0.,  0.])

   in [95]:
zeros((1,3),'d')

   out[95]:
array([[ 0.,  0.,  0.]])

   or column vectors:
   in [96]:
zeros((3,1),'d')

   out[96]:
array([[ 0.],
       [ 0.],
       [ 0.]])

   there's also an identity command that behaves as you'd expect:
   in [97]:
identity(4,'d')

   out[97]:
array([[ 1.,  0.,  0.,  0.],
       [ 0.,  1.,  0.,  0.],
       [ 0.,  0.,  1.,  0.],
       [ 0.,  0.,  0.,  1.]])

   as well as a ones command.

linspace, matrix functions, and plotting[73]  

   the linspace command makes a linear array of points from a starting to
   an ending value.
   in [98]:
linspace(0,1)

   out[98]:
array([ 0.        ,  0.02040816,  0.04081633,  0.06122449,  0.08163265,
        0.10204082,  0.12244898,  0.14285714,  0.16326531,  0.18367347,
        0.20408163,  0.2244898 ,  0.24489796,  0.26530612,  0.28571429,
        0.30612245,  0.32653061,  0.34693878,  0.36734694,  0.3877551 ,
        0.40816327,  0.42857143,  0.44897959,  0.46938776,  0.48979592,
        0.51020408,  0.53061224,  0.55102041,  0.57142857,  0.59183673,
        0.6122449 ,  0.63265306,  0.65306122,  0.67346939,  0.69387755,
        0.71428571,  0.73469388,  0.75510204,  0.7755102 ,  0.79591837,
        0.81632653,  0.83673469,  0.85714286,  0.87755102,  0.89795918,
        0.91836735,  0.93877551,  0.95918367,  0.97959184,  1.        ])

   if you provide a third argument, it takes that as the number of points
   in the space. if you don't provide the argument, it gives a length 50
   linear space.
   in [99]:
linspace(0,1,11)

   out[99]:
array([ 0. ,  0.1,  0.2,  0.3,  0.4,  0.5,  0.6,  0.7,  0.8,  0.9,  1. ])

   linspace is an easy way to make coordinates for plotting. functions in
   the numpy library (all of which are imported into ipython notebook) can
   act on an entire vector (or even a matrix) of points at once. thus,
   in [100]:
x = linspace(0,2*pi)
sin(x)

   out[100]:
array([  0.00000000e+00,   1.27877162e-01,   2.53654584e-01,
         3.75267005e-01,   4.90717552e-01,   5.98110530e-01,
         6.95682551e-01,   7.81831482e-01,   8.55142763e-01,
         9.14412623e-01,   9.58667853e-01,   9.87181783e-01,
         9.99486216e-01,   9.95379113e-01,   9.74927912e-01,
         9.38468422e-01,   8.86599306e-01,   8.20172255e-01,
         7.40277997e-01,   6.48228395e-01,   5.45534901e-01,
         4.33883739e-01,   3.15108218e-01,   1.91158629e-01,
         6.40702200e-02,  -6.40702200e-02,  -1.91158629e-01,
        -3.15108218e-01,  -4.33883739e-01,  -5.45534901e-01,
        -6.48228395e-01,  -7.40277997e-01,  -8.20172255e-01,
        -8.86599306e-01,  -9.38468422e-01,  -9.74927912e-01,
        -9.95379113e-01,  -9.99486216e-01,  -9.87181783e-01,
        -9.58667853e-01,  -9.14412623e-01,  -8.55142763e-01,
        -7.81831482e-01,  -6.95682551e-01,  -5.98110530e-01,
        -4.90717552e-01,  -3.75267005e-01,  -2.53654584e-01,
        -1.27877162e-01,  -2.44929360e-16])

   in conjunction with matplotlib, this is a nice way to plot things:
   in [101]:
plot(x,sin(x))

   out[101]:
[<matplotlib.lines.line2d at 0x10d49f510>]

   [actej6vdgeujaaaaaelftksu qmcc ]

matrix operations[74]  

   matrix objects act sensibly when multiplied by scalars:
   in [102]:
0.125*identity(3,'d')

   out[102]:
array([[ 0.125,  0.   ,  0.   ],
       [ 0.   ,  0.125,  0.   ],
       [ 0.   ,  0.   ,  0.125]])

   as well as when you add two matrices together. (however, the matrices
   have to be the same shape.)
   in [103]:
identity(2,'d') + array([[1,1],[1,2]])

   out[103]:
array([[ 2.,  1.],
       [ 1.,  3.]])

   something that confuses matlab users is that the times (*) operator
   give element-wise multiplication rather than id127:
   in [104]:
identity(2)*ones((2,2))

   out[104]:
array([[ 1.,  0.],
       [ 0.,  1.]])

   to get id127, you need the dot command:
   in [105]:
dot(identity(2),ones((2,2)))

   out[105]:
array([[ 1.,  1.],
       [ 1.,  1.]])

   dot can also do dot products (duh!):
   in [106]:
v = array([3,4],'d')
sqrt(dot(v,v))

   out[106]:
5.0

   as well as matrix-vector products.

   there are determinant, inverse, and transpose functions that act as you
   would suppose. transpose can be abbreviated with ".t" at the end of a
   matrix object:
   in [107]:
m = array([[1,2],[3,4]])
m.t

   out[107]:
array([[1, 3],
       [2, 4]])

   there's also a diag() function that takes a list or a vector and puts
   it along the diagonal of a square matrix.
   in [108]:
diag([1,2,3,4,5])

   out[108]:
array([[1, 0, 0, 0, 0],
       [0, 2, 0, 0, 0],
       [0, 0, 3, 0, 0],
       [0, 0, 0, 4, 0],
       [0, 0, 0, 0, 5]])

   we'll find this useful later on.

matrix solvers[75]  

   you can solve systems of linear equations using the solve command:
   in [109]:
a = array([[1,1,1],[0,2,5],[2,5,-1]])
b = array([6,-4,27])
solve(a,b)

   out[109]:
array([ 5.,  3., -2.])

   there are a number of routines to compute eigenvalues and eigenvectors
     * eigvals returns the eigenvalues of a matrix
     * eigvalsh returns the eigenvalues of a hermitian matrix
     * eig returns the eigenvalues and eigenvectors of a matrix
     * eigh returns the eigenvalues and eigenvectors of a hermitian
       matrix.

   in [110]:
a = array([[13,-4],[-4,7]],'d')
eigvalsh(a)

   out[110]:
array([  5.,  15.])

   in [111]:
eigh(a)

   out[111]:
(array([  5.,  15.]), array([[-0.4472136 , -0.89442719],
        [-0.89442719,  0.4472136 ]]))

example: finite differences[76]  

   now that we have these tools in our toolbox, we can start to do some
   cool stuff with it. many of the equations we want to solve in physics
   involve differential equations. we want to be able to compute the
   derivative of functions:
   $$ y' = \frac{y(x+h)-y(x)}{h} $$

   by discretizing the function $y(x)$ on an evenly spaced set of points
   $x_0, x_1, \dots, x_n$, yielding $y_0, y_1, \dots, y_n$. using the
   discretization, we can approximate the derivative by
   $$ y_i' \approx \frac{y_{i+1}-y_{i-1}}{x_{i+1}-x_{i-1}} $$

   we can write a derivative function in python via
   in [208]:
def nderiv(y,x):
    "finite difference derivative of the function f"
    n = len(y)
    d = zeros(n,'d') # assume double
    # use centered differences for the interior points, one-sided differences fo
r the ends
    for i in range(1,n-1):
        d[i] = (y[i+1]-y[i-1])/(x[i+1]-x[i-1])
    d[0] = (y[1]-y[0])/(x[1]-x[0])
    d[n-1] = (y[n-1]-y[n-2])/(x[n-1]-x[n-2])
    return d

   let's see whether this works for our sin example from above:
   in [209]:
x = linspace(0,2*pi)
dsin = nderiv(sin(x),x)
plot(x,dsin,label='numerical')
plot(x,cos(x),label='analytical')
title("comparison of numerical and analytical derivatives of sin(x)")
legend()

   out[209]:
<matplotlib.legend.legend at 0x110b39c10>

   [uhjfxuvkcwa aaaasuvork5cyii= ]

   pretty close!

one-dimensional harmonic oscillator using finite difference[77]  

   now that we've convinced ourselves that finite differences aren't a
   terrible approximation, let's see if we can use this to solve the
   one-dimensional harmonic oscillator.

   we want to solve the time-independent schrodinger equation
   $$ -\frac{\hbar^2}{2m}\frac{\partial^2\psi(x)}{\partial x^2} +
   v(x)\psi(x) = e\psi(x)$$

   for $\psi(x)$ when $v(x)=\frac{1}{2}m\omega^2x^2$ is the harmonic
   oscillator potential. we're going to use the standard trick to
   transform the differential equation into a matrix equation by
   multiplying both sides by $\psi^*(x)$ and integrating over $x$. this
   yields
   $$ -\frac{\hbar}{2m}\int\psi(x)\frac{\partial^2}{\partial x^2}\psi(x)dx
   + \int\psi(x)v(x)\psi(x)dx = e$$

   we will again use the finite difference approximation. the finite
   difference formula for the second derivative is
   $$ y'' = \frac{y_{i+1}-2y_i+y_{i-1}}{x_{i+1}-x_{i-1}} $$

   we can think of the first term in the schrodinger equation as the
   overlap of the wave function $\psi(x)$ with the second derivative of
   the wave function $\frac{\partial^2}{\partial x^2}\psi(x)$. given the
   above expression for the second derivative, we can see if we take the
   overlap of the states $y_1,\dots,y_n$ with the second derivative, we
   will only have three points where the overlap is nonzero, at $y_{i-1}$,
   $y_i$, and $y_{i+1}$. in matrix form, this leads to the tridiagonal
   laplacian matrix, which has -2's along the diagonals, and 1's along the
   diagonals above and below the main diagonal.

   the second term turns leads to a diagonal matrix with $v(x_i)$ on the
   diagonal elements. putting all of these pieces together, we get:
   in [114]:
def laplacian(x):
    h = x[1]-x[0] # assume uniformly spaced points
    n = len(x)
    m = -2*identity(n,'d')
    for i in range(1,n):
        m[i,i-1] = m[i-1,i] = 1
    return m/h**2

   in [115]:
x = linspace(-3,3)
m = 1.0
ohm = 1.0
t = (-0.5/m)*laplacian(x)
v = 0.5*(ohm**2)*(x**2)
h =  t + diag(v)
e,u = eigh(h)
h = x[1]-x[0]

# plot the harmonic potential
plot(x,v,color='k')

for i in range(4):
    # for each of the first few solutions, plot the energy level:
    axhline(y=e[i],color='k',ls=":")
    # as well as the eigenfunction, displaced by the energy level so they don't
    # all pile up on each other:
    plot(x,-u[:,i]/sqrt(h)+e[i])
title("eigenfunctions of the quantum harmonic oscillator")
xlabel("displacement (bohr)")
ylabel("energy (hartree)")

   out[115]:
<matplotlib.text.text at 0x10d7b9650>

   [jirqloibhxbccbuu78bdid35ecooehkiiivrqjpaqqgih
   gikbhxbccbuuctyeeekooejgiyqqqgx9h8z1s9optcauaaaaaelftksuqmcc ]

   we've made a couple of hacks here to get the orbitals the way we want
   them. first, i inserted a -1 factor before the wave functions, to fix
   the phase of the lowest state. the phase (sign) of a quantum wave
   function doesn't hold any information, only the square of the wave
   function does, so this doesn't really change anything.

   but the eigenfunctions as we generate them aren't properly normalized.
   the reason is that finite difference isn't a real basis in the quantum
   mechanical sense. it's a basis of dirac    functions at each point; we
   interpret the space betwen the points as being "filled" by the wave
   function, but the finite difference basis only has the solution being
   at the points themselves. we can fix this by dividing the
   eigenfunctions of our finite difference hamiltonian by the square root
   of the spacing, and this gives properly normalized functions.

special functions[78]  

   the solutions to the harmonic oscillator are supposed to be hermite
   polynomials. the wikipedia page has the ho states given by
   $$\psi_n(x) = \frac{1}{\sqrt{2^n n!}}
   \left(\frac{m\omega}{\pi\hbar}\right)^{1/4} \exp\left(-\frac{m\omega
   x^2}{2\hbar}\right) h_n\left(\sqrt{\frac{m\omega}{\hbar}}x\right)$$

   let's see whether they look like those. there are some special
   functions in the numpy library, and some more in scipy. hermite
   polynomials are in numpy:
   in [116]:
from numpy.polynomial.hermite import hermite
def ho_evec(x,n,m,ohm):
    vec = [0]*9
    vec[n] = 1
    hn = hermite(vec)
    return (1/sqrt(2**n*factorial(n)))*pow(m*ohm/pi,0.25)*exp(-0.5*m*ohm*x**2)*h
n(x*sqrt(m*ohm))

   let's compare the first function to our solution.
   in [117]:
plot(x,ho_evec(x,0,1,1),label="analytic")
plot(x,-u[:,0]/sqrt(h),label="numeric")
xlabel('x (bohr)')
ylabel(r'$\psi(x)$')
title("comparison of numeric and analytic solutions to the harmonic oscillator")
legend()

   out[117]:
<matplotlib.legend.legend at 0x10da6b950>

   [a8e6alnstusgaaaaaelf tksuqmcc ]

   the agreement is almost exact.

   we can use the subplot command to put multiple comparisons in different
   panes on a single plot:
   in [118]:
phase_correction = [-1,1,1,-1,-1,1]
for i in range(6):
    subplot(2,3,i+1)
    plot(x,ho_evec(x,i,1,1),label="analytic")
    plot(x,phase_correction[i]*u[:,i]/sqrt(h),label="numeric")

   [wecrzkolhw2iaaaaabjru5erkjggg== ]

   other than phase errors (which i've corrected with a little hack: can
   you find it?), the agreement is pretty good, although it gets worse the
   higher in energy we get, in part because we used only 50 points.

   the scipy module has many more special functions:
   in [119]:
from scipy.special import airy,jn,eval_chebyt,eval_legendre
subplot(2,2,1)
x = linspace(-1,1)
ai,aip,bi,bip = airy(x)
plot(x,ai)
plot(x,aip)
plot(x,bi)
plot(x,bip)
title("airy functions")

subplot(2,2,2)
x = linspace(0,10)
for i in range(4):
    plot(x,jn(i,x))
title("bessel functions")

subplot(2,2,3)
x = linspace(-1,1)
for i in range(6):
    plot(x,eval_chebyt(i,x))
title("chebyshev polynomials of the first kind")

subplot(2,2,4)
x = linspace(-1,1)
for i in range(6):
    plot(x,eval_legendre(i,x))
title("legendre polynomials")

   out[119]:
<matplotlib.text.text at 0x10e809c50>

   [dnplzkuro wgaaaabjru5erkjggg== ]

   as well as jacobi, laguerre, hermite polynomials, hypergeometric
   functions, and many others. there's a full listing at the [79]scipy
   special functions page.

least squares fitting[80]  

   very often we deal with some data that we want to fit to some sort of
   expected behavior. say we have the following:
   in [120]:
raw_data = """\
3.1905781584582433,0.028208609537968457
4.346895074946466,0.007160804747670053
5.374732334047101,0.0046962988461934805
8.201284796573875,0.0004614473299618756
10.899357601713055,0.00005038370219939726
16.295503211991434,4.377451812785309e-7
21.82012847965739,3.0799922117601088e-9
32.48394004282656,1.524776208284536e-13
43.53319057815846,5.5012073588707224e-18"""

   there's a section below on parsing csv data. we'll steal the parser
   from that. for an explanation, skip ahead to that section. otherwise,
   just assume that this is a way to parse that text into a numpy array
   that we can plot and do other analyses with.
   in [121]:
data = []
for line in raw_data.splitlines():
    words = line.split(',')
    data.append(map(float,words))
data = array(data)

   in [122]:
title("raw data")
xlabel("distance")
plot(data[:,0],data[:,1],'bo')

   out[122]:
[<matplotlib.lines.line2d at 0x10e70dc90>]

   [bwcdsdmku3dhaaaaaelftksuqmcc ]

   since we expect the data to have an exponential decay, we can plot it
   using a semi-log plot.
   in [123]:
title("raw data")
xlabel("distance")
semilogy(data[:,0],data[:,1],'bo')

   out[123]:
[<matplotlib.lines.line2d at 0x10dfc6fd0>]

   [d1bg zypy5xciaaaaaelftksuqmcc ]

   for a pure exponential decay like this, we can fit the log of the data
   to a straight line. the above plot suggests this is a good
   approximation. given a function $$ y = ae^{-ax} $$ $$ \log(y) = \log(a)
   - ax$$ thus, if we fit the log of the data versus x, we should get a
   straight line with slope $a$, and an intercept that gives the constant
   $a$.

   there's a numpy function called polyfit that will fit data to a
   polynomial form. we'll use this to fit to a straight line (a polynomial
   of order 1)
   in [124]:
params = polyfit(data[:,0],log(data[:,1]),1)
a = params[0]
a = exp(params[1])

   let's see whether this curve fits the data.
   in [125]:
x = linspace(1,45)
title("raw data")
xlabel("distance")
semilogy(data[:,0],data[:,1],'bo')
semilogy(x,a*exp(a*x),'b-')

   out[125]:
[<matplotlib.lines.line2d at 0x10dcdffd0>]

   [x6p9zkedrdwaaaabjru5erkjggg== ]

   if we have more complicated functions, we may not be able to get away
   with fitting to a simple polynomial. consider the following data:
   in [126]:
gauss_data = """\
-0.9902286902286903,1.4065274110372852e-19
-0.7566104566104566,2.2504438576596563e-18
-0.5117810117810118,1.9459459459459454
-0.31887271887271884,10.621621621621626
-0.250997150997151,15.891891891891893
-0.1463309463309464,23.756756756756754
-0.07267267267267263,28.135135135135133
-0.04426734426734419,29.02702702702703
-0.0015939015939017698,29.675675675675677
0.04689304689304685,29.10810810810811
0.0840994840994842,27.324324324324326
0.1700546700546699,22.216216216216214
0.370878570878571,7.540540540540545
0.5338338338338338,1.621621621621618
0.722014322014322,0.08108108108108068
0.9926849926849926,-0.08108108108108646"""

data = []
for line in gauss_data.splitlines():
    words = line.split(',')
    data.append(map(float,words))
data = array(data)

plot(data[:,0],data[:,1],'bo')

   out[126]:
[<matplotlib.lines.line2d at 0x10ddecc90>]

   [ h3ussnp57lcmaaaaaelftksuqmcc ]

   this data looks more gaussian than exponential. if we wanted to, we
   could use polyfit for this as well, but let's use the curve_fit
   function from scipy, which can fit to arbitrary functions. you can
   learn more using help(curve_fit).

   first define a general gaussian function to fit to.
   in [127]:
def gauss(x,a,a): return a*exp(a*x**2)

   now fit to it using curve_fit:
   in [128]:
from scipy.optimize import curve_fit

params,conv = curve_fit(gauss,data[:,0],data[:,1])
x = linspace(-1,1)
plot(data[:,0],data[:,1],'bo')
a,a = params
plot(x,gauss(x,a,a),'b-')

   out[128]:
[<matplotlib.lines.line2d at 0x10f86a110>]

   [ycaaaaaasuvork5cyii= ]

   the curve_fit routine we just used is built on top of a very good
   general minimization capability in scipy. you can learn more [81]at the
   scipy documentation pages.

monte carlo, random numbers, and computing $\pi$[82]  

   many methods in scientific computing rely on monte carlo integration,
   where a sequence of (pseudo) random numbers are used to approximate the
   integral of a function. python has good random number generators in the
   standard library. the random() function gives pseudorandom numbers
   uniformly distributed between 0 and 1:
   in [129]:
from random import random
rands = []
for i in range(100):
    rands.append(random())
plot(rands)

   out[129]:
[<matplotlib.lines.line2d at 0x10f9bf210>]

   [gnh9z+fo0qiraibaihpwqffaj
   guageageexbbewgeaogqiyigcqqcgudieetqbakbqcbkccjoaofaibaybbe0guageagzggi
   aqcaq ciqmqqrnibaibekg+p8bl2ilh8akquuaaaaasuvork5cyii= ]

   random() uses the [83]mersenne twister algorithm, which is a highly
   regarded pseudorandom number generator. there are also functions to
   generate random integers, to randomly shuffle a list, and functions to
   pick random numbers from a particular distribution, like the normal
   distribution:
   in [130]:
from random import gauss
grands = []
for i in range(100):
    grands.append(gauss(0,1))
plot(grands)

   out[130]:
[<matplotlib.lines.line2d at 0x10fb08910>]

   [byca 7zoytoy5aaaaaelftksuqmcc ]

   it is generally more efficient to generate a list of random numbers all
   at once, particularly if you're drawing from a non-uniform
   distribution. numpy has functions to generate vectors and matrices of
   particular types of random distributions.
   in [131]:
plot(rand(100))

   out[131]:
[<matplotlib.lines.line2d at 0x10fc69a50>]

   [wf1jab63ksjbgaaaabjru5erkjg gg== ]

   one of the first programs i ever wrote was a program to compute $\pi$
   by taking random numbers as x and y coordinates, and counting how many
   of them were in the unit circle. for example:
   in [132]:
npts = 5000
xs = 2*rand(npts)-1
ys = 2*rand(npts)-1
r = xs**2+ys**2
ninside = (r<1).sum()
figsize(6,6) # make the figure square
title("approximation to pi = %f" % (4*ninside/float(npts)))
plot(xs[r<1],ys[r<1],'b.')
plot(xs[r>1],ys[r>1],'r.')
figsize(8,6) # change the figsize back to 4x3 for the rest of the notebook

   [iqx0tqd4kgbcuwknvowruvodangd
   gnozpnkxysxzx02xuwlxhaktjtxmubvmprmmtjgwyy2ygp+ecrmm3gaygp+ecrmm3gaygp+
   ecrmm
   3gaygp+ecrmm3gaygp+ecrmm3gaygp+ecrmm3gaygp+ecrmm3gb4fwmtlik0acjpaaaaael
   ftksu qmcc ]

   the idea behind the program is that the ratio of the area of the unit
   circle to the square that inscribes it is $\pi/4$, so by counting the
   fraction of the random points in the square that are inside the circle,
   we get increasingly good estimates to $\pi$.

   the above code uses some higher level numpy tricks to compute the
   radius of each point in a single line, to count how many radii are
   below one in a single line, and to filter the x,y points based on their
   radii. to be honest, i rarely write code like this: i find some of
   these numpy tricks a little too cute to remember them, and i'm more
   likely to use a list comprehension (see below) to filter the points i
   want, since i can remember that.

   as methods of computing $\pi$ go, this is among the worst. a much
   better method is to use leibniz's expansion of arctan(1):
   $$\frac{\pi}{4} = \sum_k \frac{(-1)^k}{2*k+1}$$
   in [133]:
n = 100
total = 0
for k in range(n):
    total += pow(-1,k)/(2*k+1.0)
print 4*total

3.13159290356

   if you're interested a great method, check out [84]ramanujan's method.
   this converges so fast you really need arbitrary precision math to
   display enough decimal places. you can do this with the python decimal
   module, if you're interested.

numerical integration[85]  

   integration can be hard, and sometimes it's easier to work out a
   definite integral using an approximation. for example, suppose we
   wanted to figure out the integral:
   $$\int_0^\infty\exp(-x)dx=1$$
   in [134]:
from numpy import sqrt
def f(x): return exp(-x)
x = linspace(0,10)
plot(x,exp(-x))

   out[134]:
[<matplotlib.lines.line2d at 0x10ff00490>]

   [x6hg4nikprf3tcgksrjazoqjukqaqnzkqqs
   mjalssoba1mspbiwkcvjkgedwzkkejcqjukqgf8pnjupufxhe6kaaaaasuvork5cyii= ]

   scipy has a numerical integration routine quad (since sometimes
   numerical integration is called quadrature), that we can use for this:
   in [135]:
from scipy.integrate import quad
quad(f,0,inf)

   out[135]:
(1.0000000000000002, 5.842606742906004e-11)

   there are also 2d and 3d numerical integrators in scipy. [86]see the
   docs for more information.

fast fourier transform and signal processing[87]  

   very often we want to use fft techniques to help obtain the signal from
   noisy data. scipy has several different options for this.
   in [136]:
from scipy.fftpack import fft,fftfreq

npts = 4000
nplot = npts/10
t = linspace(0,120,npts)
def acc(t): return 10*sin(2*pi*2.0*t) + 5*sin(2*pi*8.0*t) + 2*rand(npts)

signal = acc(t)

fft = abs(fft(signal))
freqs = fftfreq(npts, t[1]-t[0])

subplot(211)
plot(t[:nplot], signal[:nplot])
subplot(212)
plot(freqs,20*log10(fft),',')
show()

   [wegjsyrqone7waa aabjru5erkjggg== ]

   there are additional signal processing routines in scipy that you can
   [88]read about here.

iii. intermediate python[89]  

output parsing[90]  

   as more and more of our day-to-day work is being done on and through
   computers, we increasingly have output that one program writes, often
   in a text file, that we need to analyze in one way or another, and
   potentially feed that output into another file.

   suppose we have the following output:
   in [137]:
myoutput = """\
@ step       energy      delta e   gmax     grms     xrms     xmax   walltime
@ ---- ---------------- -------- -------- -------- -------- -------- --------
@    0   -6095.12544083  0.0d+00  0.03686  0.00936  0.00000  0.00000   1391.5
@    1   -6095.25762870 -1.3d-01  0.00732  0.00168  0.32456  0.84140  10468.0
@    2   -6095.26325979 -5.6d-03  0.00233  0.00056  0.06294  0.14009  11963.5
@    3   -6095.26428124 -1.0d-03  0.00109  0.00024  0.03245  0.10269  13331.9
@    4   -6095.26463203 -3.5d-04  0.00057  0.00013  0.02737  0.09112  14710.8
@    5   -6095.26477615 -1.4d-04  0.00043  0.00009  0.02259  0.08615  20211.1
@    6   -6095.26482624 -5.0d-05  0.00015  0.00002  0.00831  0.03147  21726.1
@    7   -6095.26483584 -9.6d-06  0.00021  0.00004  0.01473  0.05265  24890.5
@    8   -6095.26484405 -8.2d-06  0.00005  0.00001  0.00555  0.01929  26448.7
@    9   -6095.26484599 -1.9d-06  0.00003  0.00001  0.00164  0.00564  27258.1
@   10   -6095.26484676 -7.7d-07  0.00003  0.00001  0.00161  0.00553  28155.3
@   11   -6095.26484693 -1.8d-07  0.00002  0.00000  0.00054  0.00151  28981.7
@   11   -6095.26484693 -1.8d-07  0.00002  0.00000  0.00054  0.00151  28981.7"""

   this output actually came from a geometry optimization of a silicon
   cluster using the [91]nwchem quantum chemistry suite. at every step the
   program computes the energy of the molecular geometry, and then changes
   the geometry to minimize the computed forces, until the energy
   converges. i obtained this output via the unix command
% grep @ nwchem.out


   since nwchem is nice enough to precede the lines that you need to
   monitor job progress with the '@' symbol.

   we could do the entire analysis in python; i'll show how to do this
   later on, but first let's focus on turning this code into a usable
   python object that we can plot.

   first, note that the data is entered into a multi-line string. when
   python sees three quote marks """ or ''' it treats everything following
   as part of a single string, including newlines, tabs, and anything
   else, until it sees the same three quote marks (""" has to be followed
   by another """, and ''' has to be followed by another ''') again. this
   is a convenient way to quickly dump data into python, and it also
   reinforces the important idea that you don't have to open a file and
   deal with it one line at a time. you can read everything in, and deal
   with it as one big chunk.

   the first thing we'll do, though, is to split the big string into a
   list of strings, since each line corresponds to a separate piece of
   data. we will use the splitlines() function on the big myout string to
   break it into a new element every time it sees a newline (\n)
   character:
   in [138]:
lines = myoutput.splitlines()
lines

   out[138]:
['@ step       energy      delta e   gmax     grms     xrms     xmax   walltime'
,
 '@ ---- ---------------- -------- -------- -------- -------- -------- --------'
,
 '@    0   -6095.12544083  0.0d+00  0.03686  0.00936  0.00000  0.00000   1391.5'
,
 '@    1   -6095.25762870 -1.3d-01  0.00732  0.00168  0.32456  0.84140  10468.0'
,
 '@    2   -6095.26325979 -5.6d-03  0.00233  0.00056  0.06294  0.14009  11963.5'
,
 '@    3   -6095.26428124 -1.0d-03  0.00109  0.00024  0.03245  0.10269  13331.9'
,
 '@    4   -6095.26463203 -3.5d-04  0.00057  0.00013  0.02737  0.09112  14710.8'
,
 '@    5   -6095.26477615 -1.4d-04  0.00043  0.00009  0.02259  0.08615  20211.1'
,
 '@    6   -6095.26482624 -5.0d-05  0.00015  0.00002  0.00831  0.03147  21726.1'
,
 '@    7   -6095.26483584 -9.6d-06  0.00021  0.00004  0.01473  0.05265  24890.5'
,
 '@    8   -6095.26484405 -8.2d-06  0.00005  0.00001  0.00555  0.01929  26448.7'
,
 '@    9   -6095.26484599 -1.9d-06  0.00003  0.00001  0.00164  0.00564  27258.1'
,
 '@   10   -6095.26484676 -7.7d-07  0.00003  0.00001  0.00161  0.00553  28155.3'
,
 '@   11   -6095.26484693 -1.8d-07  0.00002  0.00000  0.00054  0.00151  28981.7'
,
 '@   11   -6095.26484693 -1.8d-07  0.00002  0.00000  0.00054  0.00151  28981.7'
]

   splitting is a big concept in text processing. we used splitlines()
   here, and we will use the more general split() function below to split
   each line into whitespace-delimited words.

   we now want to do three things:
     * skip over the lines that don't carry any information
     * break apart each line that does carry information and grab the
       pieces we want
     * turn the resulting data into something that we can plot.

   for this data, we really only want the energy column, the gmax column
   (which contains the maximum gradient at each step), and perhaps the
   walltime column.

   since the data is now in a list of lines, we can iterate over it:
   in [139]:
for line in lines[2:]:
    # do something with each line
    words = line.split()

   let's examine what we just did: first, we used a for loop to iterate
   over each line. however, we skipped the first two (the lines[2:] only
   takes the lines starting from index 2), since lines[0] contained the
   title information, and lines[1] contained underscores.

   we then split each line into chunks (which we're calling "words", even
   though in most cases they're numbers) using the string split() command.
   here's what split does:
   in [140]:
import string
help(string.split)

help on function split in module string:

split(s, sep=none, maxsplit=-1)
    split(s [,sep [,maxsplit]]) -> list of strings

    return a list of the words in the string s, using sep as the
    delimiter string.  if maxsplit is given, splits at no more than
    maxsplit places (resulting in at most maxsplit+1 words).  if sep
    is not specified or is none, any whitespace string is a separator.

    (split and splitfields are synonymous)


   here we're implicitly passing in the first argument (s, in the doctext)
   by calling a method .split() on a string object. in this instance,
   we're not passing in a sep character, which means that the function
   splits on whitespace. let's see what that does to one of our lines:
   in [141]:
lines[2].split()

   out[141]:
['@',
 '0',
 '-6095.12544083',
 '0.0d+00',
 '0.03686',
 '0.00936',
 '0.00000',
 '0.00000',
 '1391.5']

   this is almost exactly what we want. we just have to now pick the
   fields we want:
   in [142]:
for line in lines[2:]:
    # do something with each line
    words = line.split()
    energy = words[2]
    gmax = words[4]
    time = words[8]
    print energy,gmax,time

-6095.12544083 0.03686 1391.5
-6095.25762870 0.00732 10468.0
-6095.26325979 0.00233 11963.5
-6095.26428124 0.00109 13331.9
-6095.26463203 0.00057 14710.8
-6095.26477615 0.00043 20211.1
-6095.26482624 0.00015 21726.1
-6095.26483584 0.00021 24890.5
-6095.26484405 0.00005 26448.7
-6095.26484599 0.00003 27258.1
-6095.26484676 0.00003 28155.3
-6095.26484693 0.00002 28981.7
-6095.26484693 0.00002 28981.7

   this is fine for printing things out, but if we want to do something
   with the data, either make a calculation with it or pass it into a
   plotting, we need to convert the strings into regular floating point
   numbers. we can use the float() command for this. we also need to save
   it in some form. i'll do this as follows:
   in [143]:
data = []
for line in lines[2:]:
    # do something with each line
    words = line.split()
    energy = float(words[2])
    gmax = float(words[4])
    time = float(words[8])
    data.append((energy,gmax,time))
data = array(data)

   we now have our data in a numpy array, so we can choose columns to
   print:
   in [144]:
plot(data[:,0])
xlabel('step')
ylabel('energy (hartrees)')
title('convergence of nwchem geometry optimization for si cluster')

   out[144]:
<matplotlib.text.text at 0x110335650>

   [wccpvxbrhuciwaaaabjru5erkjggg== ]

   i would write the code a little more succinctly if i were doing this
   for myself, but this is essentially a snippet i use repeatedly.

   suppose our data was in csv (comma separated values) format, a format
   that originally came from microsoft excel, and is increasingly used as
   a data interchange format in big data applications. how would we parse
   that?
   in [145]:
csv = """\
-6095.12544083, 0.03686, 1391.5
-6095.25762870, 0.00732, 10468.0
-6095.26325979, 0.00233, 11963.5
-6095.26428124, 0.00109, 13331.9
-6095.26463203, 0.00057, 14710.8
-6095.26477615, 0.00043, 20211.1
-6095.26482624, 0.00015, 21726.1
-6095.26483584, 0.00021, 24890.5
-6095.26484405, 0.00005, 26448.7
-6095.26484599, 0.00003, 27258.1
-6095.26484676, 0.00003, 28155.3
-6095.26484693, 0.00002, 28981.7
-6095.26484693, 0.00002, 28981.7"""

   we can do much the same as before:
   in [146]:
data = []
for line in csv.splitlines():
    words = line.split(',')
    data.append(map(float,words))
data = array(data)

   there are two significant changes over what we did earlier. first, i'm
   passing the comma character ',' into the split function, so that it
   breaks to a new word every time it sees a comma. next, to simplify
   things a big, i'm using the map() command to repeatedly apply a single
   function (float()) to a list, and to return the output as a list.
   in [147]:
help(map)

help on built-in function map in module __builtin__:

map(...)
    map(function, sequence[, sequence, ...]) -> list

    return a list of the results of applying the function to the items of
    the argument sequence(s).  if more than one sequence is given, the
    function is called with an argument list consisting of the corresponding
    item of each sequence, substituting none for missing values when not all
    sequences have the same length.  if the function is none, return a list of
    the items of the sequence (or a list of tuples if more than one sequence).


   despite the differences, the resulting plot should be the same:
   in [148]:
plot(data[:,0])
xlabel('step')
ylabel('energy (hartrees)')
title('convergence of nwchem geometry optimization for si cluster')

   out[148]:
<matplotlib.text.text at 0x10fcc7d50>

   [wccpvxbrhuciwaaaabjru5erkjggg== ]

   hartrees (what most quantum chemistry programs use by default) are
   really stupid units. we really want this in kcal/mol or ev or something
   we use. so let's quickly replot this in terms of ev above the minimum
   energy, which will give us a much more useful plot:
   in [149]:
energies = data[:,0]
mine = min(energies)
energies_ev = 27.211*(energies-mine)
plot(energies_ev)
xlabel('step')
ylabel('energy (ev)')
title('convergence of nwchem geometry optimization for si cluster')

   out[149]:
<matplotlib.text.text at 0x110222350>

   [d7hliufyjyo3aaaaaelftksuqmcc ]

   this gives us the output in a form that we can think about: 4 ev is a
   fairly substantial energy change (chemical bonds are roughly this
   magnitude of energy), and most of the energy decrease was obtained in
   the first geometry iteration.

   we mentioned earlier that we don't have to rely on grep to pull out the
   relevant lines for us. the string module has a lot of useful functions
   we can use for this. among them is the startswith function. for
   example:
   in [150]:
lines = """\
                 ----------------------------------------
                 |  wall  |       0.45   |     443.61   |
                 ----------------------------------------

@ step       energy      delta e   gmax     grms     xrms     xmax   walltime
@ ---- ---------------- -------- -------- -------- -------- -------- --------
@    0   -6095.12544083  0.0d+00  0.03686  0.00936  0.00000  0.00000   1391.5
                                                       ok       ok



                                z-matrix (autoz)
                                --------
""".splitlines()

for line in lines:
    if line.startswith('@'):
        print line


@ step       energy      delta e   gmax     grms     xrms     xmax   walltime
@ ---- ---------------- -------- -------- -------- -------- -------- --------
@    0   -6095.12544083  0.0d+00  0.03686  0.00936  0.00000  0.00000   1391.5

   and we've successfully grabbed all of the lines that begin with the @
   symbol.

   the real value in a language like python is that it makes it easy to
   take additional steps to analyze data in this fashion, which means you
   are thinking more about your data, and are more likely to see important
   patterns.

more sophisticated string formatting and processing[92]  

   strings are a big deal in most modern languages, and hopefully the
   previous sections helped underscore how versatile python's string
   processing techniques are. we will continue this topic in this chapter.

   we can print out lines in python using the print command.
   in [151]:
print "i have 3 errands to run"

i have 3 errands to run

   in ipython we don't even need the print command, since it will display
   the last expression not assigned to a variable.
   in [152]:
"i have 3 errands to run"

   out[152]:
'i have 3 errands to run'

   print even converts some arguments to strings for us:
   in [153]:
a,b,c = 1,2,3
print "the variables are ",1,2,3

the variables are  1 2 3

   as versatile as this is, you typically need more freedom over the data
   you print out. for example, what if we want to print a bunch of data to
   exactly 4 decimal places? we can do this using formatted strings.

   formatted strings share a syntax with the c printf statement. we make a
   string that has some funny format characters in it, and then pass a
   bunch of variables into the string that fill out those characters in
   different ways.

   for example,
   in [154]:
print "pi as a decimal = %d" % pi
print "pi as a float = %f" % pi
print "pi with 4 decimal places = %.4f" % pi
print "pi with overall fixed length of 10 spaces, with 6 decimal places = %10.6f
" % pi
print "pi as in exponential format = %e" % pi

pi as a decimal = 3
pi as a float = 3.141593
pi with 4 decimal places = 3.1416
pi with overall fixed length of 10 spaces, with 6 decimal places =   3.141593
pi as in exponential format = 3.141593e+00

   we use a percent sign in two different ways here. first, the format
   character itself starts with a percent sign. %d or %i are for integers,
   %f is for floats, %e is for numbers in exponential formats. all of the
   numbers can take number immediately after the percent that specifies
   the total spaces used to print the number. formats with a decimal can
   take an additional number after a dot . to specify the number of
   decimal places to print.

   the other use of the percent sign is after the string, to pipe a set of
   variables in. you can pass in multiple variables (if your formatting
   string supports it) by putting a tuple after the percent. thus,
   in [155]:
print "the variables specified earlier are %d, %d, and %d" % (a,b,c)

the variables specified earlier are 1, 2, and 3

   this is a simple formatting structure that will satisfy most of your
   string formatting needs. more information on different format symbols
   is available in the [93]string formatting part of the standard docs.

   it's worth noting that more complicated string formatting methods are
   in development, but i prefer this system due to its simplicity and its
   similarity to c formatting strings.

   recall we discussed multiline strings. we can put format characters in
   these as well, and fill them with the percent sign as before.
   in [156]:
form_letter = """\

          %s

dear %s,

we regret to inform you that your product did not
ship today due to %s.

we hope to remedy this as soon as possible.

          from,
          your supplier
"""

print form_letter % ("july 1, 2013","valued customer bob","alien attack")

          july 1, 2013

dear valued customer bob,

we regret to inform you that your product did not
ship today due to alien attack.

we hope to remedy this as soon as possible.

          from,
          your supplier


   the problem with a long block of text like this is that it's often hard
   to keep track of what all of the variables are supposed to stand for.
   there's an alternate format where you can pass a dictionary into the
   formatted string, and give a little bit more information to the
   formatted string itself. this method looks like:
   in [157]:
form_letter = """\

          %(date)s

dear %(customer)s,

we regret to inform you that your product did not
ship today due to %(lame_excuse)s.

we hope to remedy this as soon as possible.

          from,
          your supplier
"""

print form_letter % {"date" : "july 1, 2013","customer":"valued customer bob","l
ame_excuse":"alien attack"}

          july 1, 2013

dear valued customer bob,

we regret to inform you that your product did not
ship today due to alien attack.

we hope to remedy this as soon as possible.

          from,
          your supplier


   by providing a little bit more information, you're less likely to make
   mistakes, like referring to your customer as "alien attack".

   as a scientist, you're less likely to be sending bulk mailings to a
   bunch of customers. but these are great methods for generating and
   submitting lots of similar runs, say scanning a bunch of different
   structures to find the optimal configuration for something.

   for example, you can use the following template for nwchem input files:
   in [158]:
nwchem_format = """
start %(jobname)s

title "%(thetitle)s"
charge %(charge)d

geometry units angstroms print xyz autosym
%(geometry)s
end

basis
  * library 6-31g**
end

dft
  xc %(dft_functional)s
  mult %(multiplicity)d
end

task dft %(jobtype)s
"""

   if you want to submit a sequence of runs to a computer somewhere, it's
   pretty easy to put together a little script, maybe even with some more
   string formatting in it:
   in [159]:
oxygen_xy_coords = [(0,0),(0,0.1),(0.1,0),(0.1,0.1)]
charge = 0
multiplicity = 1
dft_functional = "b3lyp"
jobtype = "optimize"

geometry_template = """\
  o    %f     %f      0.0
  h    0.0    1.0     0.0
  h    1.0    0.0     0.0"""

for i,xy in enumerate(oxygen_xy_coords):
    thetitle = "water run #%d" % i
    jobname = "h2o-%d" % i
    geometry = geometry_template % xy
    print "---------"
    print nwchem_format % dict(thetitle=thetitle,charge=charge,jobname=jobname,j
obtype=jobtype,
                               geometry=geometry,dft_functional=dft_functional,m
ultiplicity=multiplicity)

---------

start h2o-0

title "water run #0"
charge 0

geometry units angstroms print xyz autosym
  o    0.000000     0.000000      0.0
  h    0.0    1.0     0.0
  h    1.0    0.0     0.0
end

basis
  * library 6-31g**
end

dft
  xc b3lyp
  mult 1
end

task dft optimize

---------

start h2o-1

title "water run #1"
charge 0

geometry units angstroms print xyz autosym
  o    0.000000     0.100000      0.0
  h    0.0    1.0     0.0
  h    1.0    0.0     0.0
end

basis
  * library 6-31g**
end

dft
  xc b3lyp
  mult 1
end

task dft optimize

---------

start h2o-2

title "water run #2"
charge 0

geometry units angstroms print xyz autosym
  o    0.100000     0.000000      0.0
  h    0.0    1.0     0.0
  h    1.0    0.0     0.0
end

basis
  * library 6-31g**
end

dft
  xc b3lyp
  mult 1
end

task dft optimize

---------

start h2o-3

title "water run #3"
charge 0

geometry units angstroms print xyz autosym
  o    0.100000     0.100000      0.0
  h    0.0    1.0     0.0
  h    1.0    0.0     0.0
end

basis
  * library 6-31g**
end

dft
  xc b3lyp
  mult 1
end

task dft optimize


   this is a very bad geometry for a water molecule, and it would be silly
   to run so many geometry optimizations of structures that are guaranteed
   to converge to the same single geometry, but you get the idea of how
   you can run vast numbers of simulations with a technique like this.

   we used the enumerate function to loop over both the indices and the
   items of a sequence, which is valuable when you want a clean way of
   getting both. enumerate is roughly equivalent to:
   in [160]:
def my_enumerate(seq):
    l = []
    for i in range(len(seq)):
        l.append((i,seq[i]))
    return l
my_enumerate(oxygen_xy_coords)

   out[160]:
[(0, (0, 0)), (1, (0, 0.1)), (2, (0.1, 0)), (3, (0.1, 0.1))]

   although enumerate uses generators (see below) so that it doesn't have
   to create a big list, which makes it faster for really long sequenes.

optional arguments[94]  

   you will recall that the linspace function can take either two
   arguments (for the starting and ending points):
   in [161]:
linspace(0,1)

   out[161]:
array([ 0.        ,  0.02040816,  0.04081633,  0.06122449,  0.08163265,
        0.10204082,  0.12244898,  0.14285714,  0.16326531,  0.18367347,
        0.20408163,  0.2244898 ,  0.24489796,  0.26530612,  0.28571429,
        0.30612245,  0.32653061,  0.34693878,  0.36734694,  0.3877551 ,
        0.40816327,  0.42857143,  0.44897959,  0.46938776,  0.48979592,
        0.51020408,  0.53061224,  0.55102041,  0.57142857,  0.59183673,
        0.6122449 ,  0.63265306,  0.65306122,  0.67346939,  0.69387755,
        0.71428571,  0.73469388,  0.75510204,  0.7755102 ,  0.79591837,
        0.81632653,  0.83673469,  0.85714286,  0.87755102,  0.89795918,
        0.91836735,  0.93877551,  0.95918367,  0.97959184,  1.        ])

   or it can take three arguments, for the starting point, the ending
   point, and the number of points:
   in [162]:
linspace(0,1,5)

   out[162]:
array([ 0.  ,  0.25,  0.5 ,  0.75,  1.  ])

   you can also pass in keywords to exclude the endpoint:
   in [163]:
linspace(0,1,5,endpoint=false)

   out[163]:
array([ 0. ,  0.2,  0.4,  0.6,  0.8])

   right now, we only know how to specify functions that have a fixed
   number of arguments. we'll learn how to do the more general cases here.

   if we're defining a simple version of linspace, we would start with:
   in [164]:
def my_linspace(start,end):
    npoints = 50
    v = []
    d = (end-start)/float(npoints-1)
    for i in range(npoints):
        v.append(start + i*d)
    return v
my_linspace(0,1)

   out[164]:
[0.0,
 0.02040816326530612,
 0.04081632653061224,
 0.061224489795918366,
 0.08163265306122448,
 0.1020408163265306,
 0.12244897959183673,
 0.14285714285714285,
 0.16326530612244897,
 0.18367346938775508,
 0.2040816326530612,
 0.22448979591836732,
 0.24489795918367346,
 0.26530612244897955,
 0.2857142857142857,
 0.3061224489795918,
 0.32653061224489793,
 0.3469387755102041,
 0.36734693877551017,
 0.3877551020408163,
 0.4081632653061224,
 0.42857142857142855,
 0.44897959183673464,
 0.4693877551020408,
 0.4897959183673469,
 0.5102040816326531,
 0.5306122448979591,
 0.5510204081632653,
 0.5714285714285714,
 0.5918367346938775,
 0.6122448979591836,
 0.6326530612244897,
 0.6530612244897959,
 0.673469387755102,
 0.6938775510204082,
 0.7142857142857142,
 0.7346938775510203,
 0.7551020408163265,
 0.7755102040816326,
 0.7959183673469387,
 0.8163265306122448,
 0.836734693877551,
 0.8571428571428571,
 0.8775510204081632,
 0.8979591836734693,
 0.9183673469387754,
 0.9387755102040816,
 0.9591836734693877,
 0.9795918367346939,
 0.9999999999999999]

   we can add an optional argument by specifying a default value in the
   argument list:
   in [165]:
def my_linspace(start,end,npoints = 50):
    v = []
    d = (end-start)/float(npoints-1)
    for i in range(npoints):
        v.append(start + i*d)
    return v

   this gives exactly the same result if we don't specify anything:
   in [166]:
my_linspace(0,1)

   out[166]:
[0.0,
 0.02040816326530612,
 0.04081632653061224,
 0.061224489795918366,
 0.08163265306122448,
 0.1020408163265306,
 0.12244897959183673,
 0.14285714285714285,
 0.16326530612244897,
 0.18367346938775508,
 0.2040816326530612,
 0.22448979591836732,
 0.24489795918367346,
 0.26530612244897955,
 0.2857142857142857,
 0.3061224489795918,
 0.32653061224489793,
 0.3469387755102041,
 0.36734693877551017,
 0.3877551020408163,
 0.4081632653061224,
 0.42857142857142855,
 0.44897959183673464,
 0.4693877551020408,
 0.4897959183673469,
 0.5102040816326531,
 0.5306122448979591,
 0.5510204081632653,
 0.5714285714285714,
 0.5918367346938775,
 0.6122448979591836,
 0.6326530612244897,
 0.6530612244897959,
 0.673469387755102,
 0.6938775510204082,
 0.7142857142857142,
 0.7346938775510203,
 0.7551020408163265,
 0.7755102040816326,
 0.7959183673469387,
 0.8163265306122448,
 0.836734693877551,
 0.8571428571428571,
 0.8775510204081632,
 0.8979591836734693,
 0.9183673469387754,
 0.9387755102040816,
 0.9591836734693877,
 0.9795918367346939,
 0.9999999999999999]

   but also let's us override the default value with a third argument:
   in [167]:
my_linspace(0,1,5)

   out[167]:
[0.0, 0.25, 0.5, 0.75, 1.0]

   we can add arbitrary keyword arguments to the function definition by
   putting a keyword argument **kwargs handle in:
   in [168]:
def my_linspace(start,end,npoints=50,**kwargs):
    endpoint = kwargs.get('endpoint',true)
    v = []
    if endpoint:
        d = (end-start)/float(npoints-1)
    else:
        d = (end-start)/float(npoints)
    for i in range(npoints):
        v.append(start + i*d)
    return v
my_linspace(0,1,5,endpoint=false)

   out[168]:
[0.0, 0.2, 0.4, 0.6000000000000001, 0.8]

   what the keyword argument construction does is to take any additional
   keyword arguments (i.e. arguments specified by name, like
   "endpoint=false"), and stick them into a dictionary called "kwargs"
   (you can call it anything you like, but it has to be preceded by two
   stars). you can then grab items out of the dictionary using the get
   command, which also lets you specify a default value. i realize it
   takes a little getting used to, but it is a common construction in
   python code, and you should be able to recognize it.

   there's an analogous *args that dumps any additional arguments into a
   list called "args". think about the range function: it can take one
   (the endpoint), two (starting and ending points), or three (starting,
   ending, and step) arguments. how would we define this?
   in [169]:
def my_range(*args):
    start = 0
    step = 1
    if len(args) == 1:
        end = args[0]
    elif len(args) == 2:
        start,end = args
    elif len(args) == 3:
        start,end,step = args
    else:
        raise exception("unable to parse arguments")
    v = []
    value = start
    while true:
        v.append(value)
        value += step
        if value > end: break
    return v

   note that we have defined a few new things you haven't seen before: a
   break statement, that allows us to exit a for loop if some conditions
   are met, and an exception statement, that causes the interpreter to
   exit with an error message. for example:
   in [170]:
my_range()

---------------------------------------------------------------------------
exception                                 traceback (most recent call last)
<ipython-input-170-0e8004dab150> in <module>()
----> 1 my_range()

<ipython-input-169-c34e09da2551> in my_range(*args)
      9         start,end,step = args
     10     else:
---> 11         raise exception("unable to parse arguments")
     12     v = []
     13     value = start

exception: unable to parse arguments

list comprehensions and generators[95]  

   list comprehensions are a streamlined way to make lists. they look
   something like a list definition, with some logic thrown in. for
   example:
   in [ ]:
evens1 = [2*i for i in range(10)]
print evens1

   you can also put some boolean testing into the construct:
   in [ ]:
odds = [i for i in range(20) if i%2==1]
odds

   here i%2 is the remainder when i is divided by 2, so that i%2==1 is
   true if the number is odd. even though this is a relative new addition
   to the language, it is now fairly common since it's so convenient.

   iterators are a way of making virtual sequence objects. consider if we
   had the nested loop structure:
for i in range(1000000):
    for j in range(1000000):


   inside the main loop, we make a list of 1,000,000 integers, just to
   loop over them one at a time. we don't need any of the additional
   things that a lists gives us, like slicing or random access, we just
   need to go through the numbers one at a time. and we're making
   1,000,000 of them.

   iterators are a way around this. for example, the xrange function is
   the iterator version of range. this simply makes a counter that is
   looped through in sequence, so that the analogous loop structure would
   look like:
for i in xrange(1000000):
    for j in xrange(1000000):


   even though we've only added two characters, we've dramatically sped up
   the code, because we're not making 1,000,000 big lists.

   we can define our own iterators using the yield statement:
   in [171]:
def evens_below(n):
    for i in xrange(n):
        if i%2 == 0:
            yield i
    return

for i in evens_below(9):
    print i

0
2
4
6
8

   we can always turn an iterator into a list using the list command:
   in [172]:
list(evens_below(9))

   out[172]:
[0, 2, 4, 6, 8]

   there's a special syntax called a generator expression that looks a lot
   like a list comprehension:
   in [173]:
evens_gen = (i for i in xrange(9) if i%2==0)
for i in evens_gen:
    print i

0
2
4
6
8

factory functions[96]  

   a factory function is a function that returns a function. they have the
   fancy name lexical closure, which makes you sound really intelligent in
   front of your cs friends. but, despite the arcane names, factory
   functions can play a very practical role.

   suppose you want the gaussian function centered at 0.5, with height 99
   and width 1.0. you could write a general function.
   in [174]:
def gauss(x,a,a,x0):
    return a*exp(-a*(x-x0)**2)

   but what if you need a function with only one argument, like f(x)
   rather than f(x,y,z,...)? you can do this with factory functions:
   in [175]:
def gauss_maker(a,a,x0):
    def f(x):
        return a*exp(-a*(x-x0)**2)
    return f

   in [176]:
x = linspace(0,1)
g = gauss_maker(99.0,1.0,0.5)
plot(x,g(x))

   out[176]:
[<matplotlib.lines.line2d at 0x110726990>]

   [k 7yeaaaaasuvork5cyii= ]

   everything in python is an object, including functions. this means that
   functions can be returned by other functions. (they can also be passed
   into other functions, which is also useful, but a topic for another
   discussion.) in the gauss_maker example, the g function that is output
   "remembers" the a, a, x0 values it was constructed with, since they're
   all stored in the local memory space (this is what the lexical closure
   really refers to) of that function.

   factories are one of the more important of the [97]software design
   patterns, which are a set of guidelines to follow to make high-quality,
   portable, readable, stable software. it's beyond the scope of the
   current work to go more into either factories or design patterns, but i
   thought i would mention them for people interested in software design.

serialization: save it for later[98]  

   serialization refers to the process of outputting data (and
   occasionally functions) to a database or a regular file, for the
   purpose of using it later on. in the very early days of programming
   languages, this was normally done in regular text files. python is
   excellent at text processing, and you probably already know enough to
   get started with this.

   when accessing large amounts of data became important, people developed
   database software based around the structured query language (sql)
   standard. i'm not going to cover sql here, but, if you're interested, i
   recommend using the [99]sqlite3 module in the python standard library.

   as data interchange became important, the extensible markup language
   (xml) has emerged. xml makes data formats that are easy to write
   parsers for, greatly simplifying the ambiguity that sometimes arises in
   the process. again, i'm not going to cover xml here, but if you're
   interested in learning more, look into [100]element trees, now part of
   the python standard library.

   python has a very general serialization format called pickle that can
   turn any python object, even a function or a class, into a
   representation that can be written to a file and read in later. but,
   again, i'm not going to talk about this, since i rarely use it myself.
   again, [101]the standard library documentation for pickle is the place
   to go.

   what i am going to talk about is a relatively recent format call
   [102]javascript object notation (json) that has become very popular
   over the past few years. [103]there's a module in the standard library
   for encoding and decoding json formats. the reason i like json so much
   is that it looks almost like python, so that, unlike the other options,
   you can look at your data and edit it, use it in another program, etc.

   here's a little example:
   in [177]:
# data in a json format:
json_data = """\
{
    "a": [1,2,3],
    "b": [4,5,6],
    "greeting" : "hello"
}"""
import json
json.loads(json_data)

   out[177]:
{u'a': [1, 2, 3], u'b': [4, 5, 6], u'greeting': u'hello'}

   ignore the little u's before the strings, these just mean the strings
   are in unicode. your data sits in something that looks like a python
   dictionary, and in a single line of code, you can load it into a python
   dictionary for use later.

   in the same way, you can, with a single line of code, put a bunch of
   variables into a dictionary, and then output to a file using json:
   in [178]:
json.dumps({"a":[1,2,3],"b":[9,10,11],"greeting":"hola"})

   out[178]:
'{"a": [1, 2, 3], "b": [9, 10, 11], "greeting": "hola"}'

functional programming[104]  

   functional programming is a very broad subject. the idea is to have a
   series of functions, each of which generates a new data structure from
   an input, without changing the input structure at all. by not modifying
   the input structure (something that is called not having side effects),
   many guarantees can be made about how independent the processes are,
   which can help parallelization and guarantees of program accuracy.
   there is a [105]python functional programming howto in the standard
   docs that goes into more details on functional programming. i just
   wanted to touch on a few of the most important ideas here.

   there is an operator module that has function versions of most of the
   python operators. for example:
   in [179]:
from operator import add, mul
add(1,2)

   out[179]:
3

   in [180]:
mul(3,4)

   out[180]:
12

   these are useful building blocks for functional programming.

   the lambda operator allows us to build anonymous functions, which are
   simply functions that aren't defined by a normal def statement with a
   name. for example, a function that doubles the input is:
   in [181]:
def doubler(x): return 2*x
doubler(17)

   out[181]:
34

   we could also write this as:
   in [182]:
lambda x: 2*x

   out[182]:
<function __main__.<lambda>>

   and assign it to a function separately:
   in [183]:
another_doubler = lambda x: 2*x
another_doubler(19)

   out[183]:
38

   lambda is particularly convenient (as we'll see below) in passing
   simple functions as arguments to other functions.

   map is a way to repeatedly apply a function to a list:
   in [184]:
map(float,'1 2 3 4 5'.split())

   out[184]:
[1.0, 2.0, 3.0, 4.0, 5.0]

   reduce is a way to repeatedly apply a function to the first two items
   of the list. there already is a sum function in python that is a
   reduction:
   in [185]:
sum([1,2,3,4,5])

   out[185]:
15

   we can use reduce to define an analogous prod function:
   in [186]:
def prod(l): return reduce(mul,l)
prod([1,2,3,4,5])

   out[186]:
120

object oriented programming[106]  

   we've seen a lot of examples of objects in python. we create a string
   object with quote marks:
   in [187]:
mystring = "hi there"

   and we have a bunch of methods we can use on the object:
   in [188]:
mystring.split()

   out[188]:
['hi', 'there']

   in [189]:
mystring.startswith('hi')

   out[189]:
true

   in [190]:
len(mystring)

   out[190]:
8

   object oriented programming simply gives you the tools to define
   objects and methods for yourself. it's useful anytime you want to keep
   some data (like the characters in the string) tightly coupled to the
   functions that act on the data (length, split, startswith, etc.).

   as an example, we're going to bundle the functions we did to make the
   1d harmonic oscillator eigenfunctions with arbitrary potentials, so we
   can pass in a function defining that potential, some additional
   specifications, and get out something that can plot the orbitals, as
   well as do other things with them, if desired.
   in [191]:
class schrod1d:
    """\
    schrod1d: solver for the one-dimensional schrodinger equation.
    """
    def __init__(self,v,start=0,end=1,npts=50,**kwargs):
        m = kwargs.get('m',1.0)
        self.x = linspace(start,end,npts)
        self.vx = v(self.x)
        self.h = (-0.5/m)*self.laplacian() + diag(self.vx)
        return

    def plot(self,*args,**kwargs):
        titlestring = kwargs.get('titlestring',"eigenfunctions of the 1d potenti
al")
        xstring = kwargs.get('xstring',"displacement (bohr)")
        ystring = kwargs.get('ystring',"energy (hartree)")
        if not args:
            args = [3]
        x = self.x
        e,u = eigh(self.h)
        h = x[1]-x[0]

        # plot the potential
        plot(x,self.vx,color='k')

        for i in range(*args):
            # for each of the first few solutions, plot the energy level:
            axhline(y=e[i],color='k',ls=":")
            # as well as the eigenfunction, displaced by the energy level so the
y don't
            # all pile up on each other:
            plot(x,u[:,i]/sqrt(h)+e[i])
        title(titlestring)
        xlabel(xstring)
        ylabel(ystring)
        return

    def laplacian(self):
        x = self.x
        h = x[1]-x[0] # assume uniformly spaced points
        n = len(x)
        m = -2*identity(n,'d')
        for i in range(1,n):
            m[i,i-1] = m[i-1,i] = 1
        return m/h**2

   the init() function specifies what operations go on when the object is
   created. the self argument is the object itself, and we don't pass it
   in. the only required argument is the function that defines the qm
   potential. we can also specify additional arguments that define the
   numerical grid that we're going to use for the calculation.

   for example, to do an infinite square well potential, we have a
   function that is 0 everywhere. we don't have to specify the barriers,
   since we'll only define the potential in the well, which means that it
   can't be defined anywhere else.
   in [192]:
square_well = schrod1d(lambda x: 0*x,m=10)
square_well.plot(4,titlestring="square well potential")

   [8brbfdets2acoaaaaasuvork5c yii= ]

   we can similarly redefine the harmonic oscillator potential.
   in [193]:
ho = schrod1d(lambda x: x**2,start=-3,end=3)
ho.plot(6,titlestring="harmonic oscillator")

   [ao5nmi1vphrugaaaabjru5erkjggg== ]

   let's define a finite well potential:
   in [194]:
def finite_well(x,v_left=1,v_well=0,v_right=1,d_left=10,d_well=10,d_right=10):
    v = zeros(x.size,'d')
    for i in range(x.size):
        if x[i] < d_left:
            v[i] = v_left
        elif x[i] > (d_left+d_well):
            v[i] = v_right
        else:
            v[i] = v_well
    return v

fw = schrod1d(finite_well,start=0,end=30,npts=100)
fw.plot()

   [waaaabjru5erkjggg== ]

   a triangular well:
   in [195]:
def triangular(x,f=30): return f*x

tw = schrod1d(triangular,m=10)
tw.plot()

   [iebmzmvkd8ztymzozbuzabmzm1sacym3mzbqya7mzmvkdcya3mznrya7kzmzmdexvopno
   xtlv27oaaaaasuvork5cyii= ]

   or we can combine the two, making something like a semiconductor
   quantum well with a top gate:
   in [196]:
def tri_finite(x): return finite_well(x)+triangular(x,f=0.025)

tfw = schrod1d(tri_finite,start=0,end=30,npts=100)
tfw.plot()

   [h8vsbtzlrmk3waaaabjru5erkjggg== ]

   there's a lot of philosophy behind object oriented programming. since
   i'm trying to focus on just the basics here, i won't go into them, but
   the internet is full of lots of resources on oo programming and theory.
   the best of this is contained in the [107]design patterns) book, which
   i highly recommend.

iv. speeding python: timeit, profiling, cython, swig, and pypy[108]  

   the first rule of speeding up your code is not to do it at all. as
   donald knuth said:

     "we should forget about small efficiencies, say about 97% of the
     time: premature optimization is the root of all evil."

   the second rule of speeding up your code is to only do it if you really
   think you need to do it. python has two tools to help with this
   process: a timing program called timeit, and a very good code profiler.
   we will discuss both of these tools in this section, as well as
   techniques to use to speed up your code once you know it's too slow.

timeit[109]  

   timeit helps determine which of two similar routines is faster. recall
   that some time ago we wrote a factorial routine, but also pointed out
   that python had its own routine built into the math module. is there
   any difference in the speed of the two? timeit helps us determine this.
   for example, timeit tells how long each method takes:
   in [197]:
%timeit factorial(20)

1000000 loops, best of 3: 714 ns per loop

   the little % sign that we have in front of the timeit call is an
   example of an ipython magic function, which we don't have time to go
   into here, but it's just some little extra mojo that ipython adds to
   the functions to make it run better in the ipython environment. you can
   read more about it in the [110]ipython tutorial.

   in any case, the timeit function runs 3 loops, and tells us that it
   took on the average of 583 ns to compute 20!. in contrast:
   in [198]:
%timeit fact(20)

100000 loops, best of 3: 6   s per loop

   the factorial function we wrote is about a factor of 10 slower. this is
   because the built-in factorial function is written in c code and called
   from python, and the version we wrote is written in plain old python. a
   python program has a lot of stuff in it that make it nice to interact
   with, but all that friendliness slows down the code. in contrast, the c
   code is less friendly but more efficient. if you want speed with as
   little effort as possible, write your code in an easy to program
   language like python, but dump the slow parts into a faster language
   like c, and call it from python. we'll go through some tricks to do
   this in this section.

profiling[111]  

   profiling complements what timeit does by splitting the overall timing
   into the time spent in each function. it can give us a better
   understanding of what our program is really spending its time on.

   suppose we want to create a list of even numbers. our first effort
   yields this:
   in [199]:
def evens(n):
    "return a list of even numbers below n"
    l = []
    for x in range(n):
        if x % 2 == 0:
            l.append(x)
    return l

   is this code fast enough? we find out by running the python profiler on
   a longer run:
   in [200]:
import cprofile
cprofile.run('evens(100000)')

         50004 function calls in 0.048 seconds

   ordered by: standard name

   ncalls  tottime  percall  cumtime  percall filename:lineno(function)
        1    0.038    0.038    0.048    0.048 <ipython-input-199-9d23d9d62f6b>:1
(evens)
        1    0.001    0.001    0.048    0.048 <string>:1(<module>)
    50000    0.007    0.000    0.007    0.000 {method 'append' of 'list' objects
}
        1    0.000    0.000    0.000    0.000 {method 'disable' of '_lsprof.prof
iler' objects}
        1    0.003    0.003    0.003    0.003 {range}



   this looks okay, 0.05 seconds isn't a huge amount of time, but looking
   at the profiling shows that the append function is taking almost 20% of
   the time. can we do better? let's try a list comprehension.
   in [201]:
def evens2(n):
    "return a list of even numbers below n"
    return [x for x in range(n) if x % 2 == 0]

   in [202]:
import cprofile
cprofile.run('evens2(100000)')

         4 function calls in 0.022 seconds

   ordered by: standard name

   ncalls  tottime  percall  cumtime  percall filename:lineno(function)
        1    0.020    0.020    0.022    0.022 <ipython-input-201-cbb0d0b3fc58>:1
(evens2)
        1    0.001    0.001    0.022    0.022 <string>:1(<module>)
        1    0.000    0.000    0.000    0.000 {method 'disable' of '_lsprof.prof
iler' objects}
        1    0.001    0.001    0.001    0.001 {range}



   by removing a small part of the code using a list comprehension, we've
   doubled the overall speed of the code!

   it seems like range is taking a long time, still. can we get rid of it?
   we can, using the xrange generator:
   in [203]:
def evens3(n):
    "return a list of even numbers below n"
    return [x for x in xrange(n) if x % 2 == 0]

   in [204]:
import cprofile
cprofile.run('evens3(100000)')

         3 function calls in 0.021 seconds

   ordered by: standard name

   ncalls  tottime  percall  cumtime  percall filename:lineno(function)
        1    0.021    0.021    0.021    0.021 <ipython-input-203-3ee1b2b2b034>:1
(evens3)
        1    0.001    0.001    0.021    0.021 <string>:1(<module>)
        1    0.000    0.000    0.000    0.000 {method 'disable' of '_lsprof.prof
iler' objects}



   this is where profiling can be useful. our code now runs 3x faster by
   making trivial changes. we wouldn't have thought to look in these
   places had we not had access to easy profiling. imagine what you would
   find in more complicated programs.

other ways to speed python[112]  

   when we compared the fact and factorial functions, above, we noted that
   c routines are often faster because they're more streamlined. once
   we've determined that one routine is a bottleneck for the performance
   of a program, we can replace it with a faster version by writing it in
   c. this is called extending python, and there's a [113]good section in
   the standard documents. this can be a tedious process if you have many
   different routines to convert. fortunately, there are several other
   options.

   [114]swig (the simplified wrapper and interface generator) is a method
   to generate binding not only for python but also for matlab, perl,
   ruby, and other scripting languages. swig can scan the header files of
   a c project and generate python binding for it. using swig is
   substantially easier than writing the routines in c.

   [115]cython is a c-extension language. you can start by compiling a
   python routine into a shared object libraries that can be imported into
   faster versions of the routines. you can then add additional static
   typing and make other restrictions to further speed the code. cython is
   generally easier than using swig.

   [116]pypy is the easiest way of obtaining fast code. pypy compiles
   python to a subset of the python language called rpython that can be
   efficiently compiled and optimized. over a wide range of tests, pypy is
   [117]roughly 6 times faster than the standard python distribution.

fun: finding primes[118]  

   [119]project euler is a site where programming puzzles are posed that
   might have interested euler. [120]problem 7 asks the question:

     by listing the first six prime numbers: 2, 3, 5, 7, 11, and 13, we
     can see that the 6th prime is 13.

     what is the 10,001st prime number?

   to solve this we need a very long list of prime numbers. first we'll
   make a function that uses the sieve of erastothenes to generate all the
   primes less than n.
   in [205]:
def primes(n):
    """\
    from python cookbook, returns a list of prime numbers from 2 to < n

    >>> primes(2)
    [2]
    >>> primes(10)
    [2, 3, 5, 7]
    """
    if n==2: return [2]
    elif n<2: return []
    s=range(3,n+1,2)
    mroot = n ** 0.5
    half=(n+1)/2-1
    i=0
    m=3
    while m <= mroot:
        if s[i]:
            j=(m*m-3)/2
            s[j]=0
            while j<half:
                s[j]=0
                j+=m
        i=i+1
        m=2*i+3
    return [2]+[x for x in s if x]

   in [206]:
number_to_try = 1000000
list_of_primes = primes(number_to_try)
print list_of_primes[10001]

104759

   you might think that python is a bad choice for something like this,
   but, in terms of time, it really doesn't take long:
   in [207]:
cprofile.run('primes(1000000)')

         4 function calls in 0.372 seconds

   ordered by: standard name

   ncalls  tottime  percall  cumtime  percall filename:lineno(function)
        1    0.335    0.335    0.363    0.363 <ipython-input-205-57e280631d57>:1
(primes)
        1    0.009    0.009    0.372    0.372 <string>:1(<module>)
        1    0.000    0.000    0.000    0.000 {method 'disable' of '_lsprof.prof
iler' objects}
        1    0.028    0.028    0.028    0.028 {range}



   only takes 1/4 of a second to generate a list of all the primes below
   1,000,000. it would be nice if we could use the same trick to get rid
   of the range function, but we actually need it, since we're using the
   object like a list, rather than like a counter as before.

vii. references[121]  

learning resources[122]  

     * [123]official python documentation, including
          + [124]python tutorial
          + [125]python language reference
     * if you're interested in python 3, the [126]official python 3 docs
       are here.
     * [127]ipython tutorial.
     * [128]learn python the hard way
     * [129]dive into python, in particular if you're interested in python
       3.
     * [130]invent with python, probably best for kids.
     * [131]python functional programming howto
     * [132]the structure and interpretation of computer programs, written
       in scheme, a lisp dialect, but one of the best books on computer
       programming ever written.
     * [133]generator tricks for systems programmers beazley's slides on
       just what generators can do for you.
     * [134]python module of the week is a series going through in-depth
       analysis of the python standard library in a very easy to
       understand way.

badass ipython notebooks[135]  

     * rob johansson's [136]excellent notebooks, including [137]scientific
       computing with python and [138]computational quantum physics with
       qutip lectures;
     * [139]xkcd style graphs in matplotlib;
     * [140]a collection of notebooks for using ipython effectively
     * [141]a gallery of interesting ipython notebooks
     * [142]cross-disciplinary computational analysis ipython notebooks
       from hadoop world 2012
     * [143]quantites units in python.
          + [144]another units module is here

packages for scientists[145]  

   important libraries
     * [146]python version 2.7;
     * [147]numpy, the core numerical extensions for id202 and
       multidimensional arrays;
     * [148]scipy, additional libraries for scientific programming;
     * [149]matplotlib, excellent plotting and graphing libraries;
     * [150]ipython, with the additional libraries required for the
       notebook interface.
     * [151]sympy, symbolic math in python
     * [152]pandas library for big data in python

   other packages of interest
     * [153]pyquante python quantum chemistry
     * [154]qutip quantum toolbox in python
     * konrad hinsen's [155]scientific python and [156]mmtk
     * [157]atomic simulation environment

cool stuff[158]  

     * [159]moin moin, a wiki written in python
     * [160]project euler, programming problems that would (?) have
       interested euler. python is one of the most commonly used languages
       there.

vi. acknowledgements[161]  

   thanks to alex and tess for everything!

   thanks to barbara muller and tom tarman for helpful suggestions.

   this work is licensed under a [162]creative commons
   attribution-sharealike 3.0 unported license. the work is offered for
   free, with the hope that it will be useful. please consider making a
   donation to the [163]john hunter memorial fund.

   cc by sa

   sandia

   sandia is a multiprogram laboratory operated by sandia corporation, a
   lockheed martin company, for the united states department of energy's
   national nuclear security administration under contract
   de-ac04-94al85000.

   doe
   in [207]:


   this website does not host notebooks, it only renders notebooks
   available on other websites.

   delivered by [164]fastly, rendered by [165]rackspace

   nbviewer github [166]repository.

   nbviewer version: [167]33c4683

   nbconvert version: [168]5.4.0

   rendered (fri, 05 apr 2019 18:20:39 utc)

references

   1. https://nbviewer.jupyter.org/
   2. http://jupyter.org/
   3. https://nbviewer.jupyter.org/faq
   4. https://nbviewer.jupyter.org/format/script/gist/rpmuller/5920182
   5. https://gist.github.com/5920182
   6. https://mybinder.org/v2/gist/rpmuller/5920182/master?filepath=crash course v0.5.ipynb.json
   7. https://gist.githubusercontent.com/rpmuller/5920182/raw/da4857f5fffbd7099285aeb8cdc36bad68a35b05/crash course v0.5.ipynb.json
   8. https://nbviewer.jupyter.org/gist/rpmuller/5920182#a-crash-course-in-python-for-scientists
   9. http://www.cs.sandia.gov/~rmuller/
  10. http://creativecommons.org/licenses/by-sa/3.0/deed.en_us
  11. https://nbviewer.jupyter.org/gist/rpmuller/5920182#why-python?
  12. http://docs.python.org/2/tutorial/
  13. http://www.wag.caltech.edu/home/rpm/python_course/
  14. http://ipython.org/
  15. http://jrjohansson.github.io/
  16. https://github.com/jrjohansson/scientific-python-lectures
  17. https://github.com/jrjohansson/qutip-lectures
  18. http://nbviewer.ipython.org/url/jakevdp.github.com/downloads/notebooks/xkcd_plots.ipynb
  19. https://github.com/ipython/ipython/tree/master/examples/notebooks#a-collection-of-notebooks-for-using-ipython-effectively
  20. https://github.com/ipython/ipython/wiki/a-gallery-of-interesting-ipython-notebooks
  21. http://ipython.reddit.com/
  22. https://nbviewer.jupyter.org/gist/rpmuller/5920182#what-you-need-to-install
  23. http://www.python.org/
  24. http://www.numpy.org/
  25. http://www.scipy.org/
  26. http://matplotlib.sf.net/
  27. http://ipython.org/
  28. https://www.enthought.com/products/epd
  29. https://www.enthought.com/products/epd/free/
  30. http://www.macports.org/
  31. https://code.google.com/p/pythonxy/
  32. http://nbviewer.ipython.org/
  33. http://www.wakari.io/
  34. http://continuum.io/
  35. https://store.continuum.io/
  36. https://nbviewer.jupyter.org/gist/rpmuller/5920182#i.-python-overview
  37. http://docs.python.org/2/tutorial/
  38. http://learnpythonthehardway.org/book/
  39. http://ipython.org/notebook.html
  40. http://www.youtube.com/watch?v=h6dlgqw9yfq#!
  41. http://ipython.org/ipython-doc/dev/interactive/tutorial.html
  42. http://ipython.org/notebook.html
  43. http://ipython.org/ipython-doc/dev/interactive/tutorial.html
  44. https://nbviewer.jupyter.org/gist/rpmuller/5920182#using-python-as-a-calculator
  45. http://docs.python.org/2/tutorial/introduction.html#using-python-as-a-calculator
  46. http://ipython.org/ipython-doc/dev/interactive/tutorial.html
  47. https://nbviewer.jupyter.org/gist/rpmuller/5920182#strings
  48. https://nbviewer.jupyter.org/gist/rpmuller/5920182#lists
  49. https://nbviewer.jupyter.org/gist/rpmuller/5920182#iteration,-indentation,-and-blocks
  50. https://nbviewer.jupyter.org/gist/rpmuller/5920182#slicing
  51. https://nbviewer.jupyter.org/gist/rpmuller/5920182#booleans-and-truth-testing
  52. https://nbviewer.jupyter.org/gist/rpmuller/5920182#code-example:-the-fibonacci-sequence
  53. http://en.wikipedia.org/wiki/fibonacci_number
  54. https://nbviewer.jupyter.org/gist/rpmuller/5920182#functions
  55. https://nbviewer.jupyter.org/gist/rpmuller/5920182#recursion-and-factorials
  56. https://nbviewer.jupyter.org/gist/rpmuller/5920182#two-more-data-structures:-tuples-and-dictionaries
  57. https://nbviewer.jupyter.org/gist/rpmuller/5920182#plotting-with-matplotlib
  58. http://matplotlib.sf.net/
  59. http://matplotlib.org/gallery.html
  60. http://nbviewer.ipython.org/urls/raw.github.com/jrjohansson/scientific-python-lectures/master/lecture-4-matplotlib.ipynb
  61. https://nbviewer.jupyter.org/gist/rpmuller/5920182#conclusion-of-the-python-overview
  62. http://docs.python.org/2/tutorial/
  63. http://learnpythonthehardway.org/book/
  64. http://docs.python.org/2.7/
  65. http://docs.python.org/2.7/reference/index.html
  66. https://nbviewer.jupyter.org/gist/rpmuller/5920182#ii.-numpy-and-scipy
  67. http://numpy.org/
  68. http://scipy/
  69. http://www.mathworks.com/products/matlab/
  70. http://www.scipy.org/numpy_for_matlab_users
  71. https://nbviewer.jupyter.org/gist/rpmuller/5920182#making-vectors-and-matrices
  72. http://docs.scipy.org/doc/numpy/user/basics.types.html
  73. https://nbviewer.jupyter.org/gist/rpmuller/5920182#linspace,-matrix-functions,-and-plotting
  74. https://nbviewer.jupyter.org/gist/rpmuller/5920182#matrix-operations
  75. https://nbviewer.jupyter.org/gist/rpmuller/5920182#matrix-solvers
  76. https://nbviewer.jupyter.org/gist/rpmuller/5920182#example:-finite-differences
  77. https://nbviewer.jupyter.org/gist/rpmuller/5920182#one-dimensional-harmonic-oscillator-using-finite-difference
  78. https://nbviewer.jupyter.org/gist/rpmuller/5920182#special-functions
  79. http://docs.scipy.org/doc/scipy/reference/special.html
  80. https://nbviewer.jupyter.org/gist/rpmuller/5920182#least-squares-fitting
  81. http://docs.scipy.org/doc/scipy/reference/generated/scipy.optimize.minimize.html
  82. https://nbviewer.jupyter.org/gist/rpmuller/5920182#monte-carlo,-random-numbers,-and-computing-$\pi$
  83. http://www.math.sci.hiroshima-u.ac.jp/~m-mat/mt/emt.html
  84. http://en.wikipedia.org/wiki/approximations_of_  
  85. https://nbviewer.jupyter.org/gist/rpmuller/5920182#numerical-integration
  86. http://docs.scipy.org/doc/scipy/reference/integrate.html
  87. https://nbviewer.jupyter.org/gist/rpmuller/5920182#fast-fourier-transform-and-signal-processing
  88. http://docs.scipy.org/doc/scipy/reference/tutorial/signal.html
  89. https://nbviewer.jupyter.org/gist/rpmuller/5920182#iii.-intermediate-python
  90. https://nbviewer.jupyter.org/gist/rpmuller/5920182#output-parsing
  91. http://www.nwchem-sw.org/index.php/main_page
  92. https://nbviewer.jupyter.org/gist/rpmuller/5920182#more-sophisticated-string-formatting-and-processing
  93. http://docs.python.org/release/2.5.2/lib/typesseq-strings.html
  94. https://nbviewer.jupyter.org/gist/rpmuller/5920182#optional-arguments
  95. https://nbviewer.jupyter.org/gist/rpmuller/5920182#list-comprehensions-and-generators
  96. https://nbviewer.jupyter.org/gist/rpmuller/5920182#factory-functions
  97. http://en.wikipedia.org/wiki/software_design_pattern
  98. https://nbviewer.jupyter.org/gist/rpmuller/5920182#serialization:-save-it-for-later
  99. http://docs.python.org/2/library/sqlite3.html
 100. http://docs.python.org/2/library/xml.etree.elementtree.html
 101. http://docs.python.org/2/library/pickle.html#module-cpickle
 102. http://json.org/
 103. http://docs.python.org/2/library/json.html
 104. https://nbviewer.jupyter.org/gist/rpmuller/5920182#functional-programming
 105. http://docs.python.org/2/howto/functional.html
 106. https://nbviewer.jupyter.org/gist/rpmuller/5920182#object-oriented-programming
 107. http://en.wikipedia.org/wiki/design_patterns_(book
 108. https://nbviewer.jupyter.org/gist/rpmuller/5920182#iv.-speeding-python:-timeit,-profiling,-cython,-swig,-and-pypy
 109. https://nbviewer.jupyter.org/gist/rpmuller/5920182#timeit
 110. http://ipython.org/ipython-doc/dev/interactive/tutorial.html
 111. https://nbviewer.jupyter.org/gist/rpmuller/5920182#profiling
 112. https://nbviewer.jupyter.org/gist/rpmuller/5920182#other-ways-to-speed-python
 113. http://docs.python.org/2/extending/extending.html
 114. http://swig.org/
 115. http://www.cython.org/
 116. http://pypy.org/
 117. http://speed.pypy.org/
 118. https://nbviewer.jupyter.org/gist/rpmuller/5920182#fun:-finding-primes
 119. http://projecteuler.net/
 120. http://projecteuler.net/problem=7
 121. https://nbviewer.jupyter.org/gist/rpmuller/5920182#vii.-references
 122. https://nbviewer.jupyter.org/gist/rpmuller/5920182#learning-resources
 123. http://docs.python.org/2.7
 124. http://docs.python.org/2.7/tutorial
 125. http://docs.python.org/2.7/reference
 126. http://docs.python.org/3/
 127. http://ipython.org/ipython-doc/dev/interactive/tutorial.html
 128. http://learnpythonthehardway.org/book/
 129. http://www.diveintopython.net/
 130. http://inventwithpython.com/
 131. http://docs.python.org/2/howto/functional.html
 132. http://mitpress.mit.edu/sicp/full-text/book/book.html
 133. http://www.dabeaz.com/generators/
 134. http://pymotw.com/2/contents.html
 135. https://nbviewer.jupyter.org/gist/rpmuller/5920182#badass-ipython-notebooks
 136. http://jrjohansson.github.io/
 137. https://github.com/jrjohansson/scientific-python-lectures
 138. https://github.com/jrjohansson/qutip-lectures
 139. http://nbviewer.ipython.org/url/jakevdp.github.com/downloads/notebooks/xkcd_plots.ipynb
 140. https://github.com/ipython/ipython/tree/master/examples/notebooks#a-collection-of-notebooks-for-using-ipython-effectively
 141. https://github.com/ipython/ipython/wiki/a-gallery-of-interesting-ipython-notebooks
 142. https://github.com/invisibleroads/crosscompute-tutorials
 143. http://nbviewer.ipython.org/urls/raw.github.com/tbekolay/pyconca2012/master/quantitiestutorial.ipynb
 144. http://www.southampton.ac.uk/~fangohr/blog/
 145. https://nbviewer.jupyter.org/gist/rpmuller/5920182#packages-for-scientists
 146. http://www.python.org/
 147. http://www.numpy.org/
 148. http://www.scipy.org/
 149. http://matplotlib.sf.net/
 150. http://ipython.org/
 151. http://sympy.org/
 152. http://pandas.pydata.org/
 153. http://pyquante.sf.net/
 154. https://code.google.com/p/qutip/
 155. http://dirac.cnrs-orleans.fr/plone/software/scientificpython/
 156. http://dirac.cnrs-orleans.fr/mmtk/
 157. https://wiki.fysik.dtu.dk/ase/
 158. https://nbviewer.jupyter.org/gist/rpmuller/5920182#cool-stuff
 159. http://moinmo.in/
 160. http://projecteuler.net/
 161. https://nbviewer.jupyter.org/gist/rpmuller/5920182#vi.-acknowledgements
 162. http://creativecommons.org/licenses/by-sa/3.0/deed.en_us
 163. http://numfocus.org/johnhunter/
 164. http://www.fastly.com/
 165. https://developer.rackspace.com/?nbviewer=awesome
 166. https://github.com/jupyter/nbviewer
 167. https://github.com/jupyter/nbviewer/commit/33c4683164d5ee4c92dbcd53afac7f13ef033c54
 168. https://github.com/jupyter/nbconvert/releases/tag/5.4.0
