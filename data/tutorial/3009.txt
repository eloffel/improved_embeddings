   #[1]publisher [2]medium [3]alternate

   [4]homepage
   [5]homepage
   [6]become a member[7]sign in[8]get started
     __________________________________________________________________

machine learning is fun! part 3: deep learning and convolutional
neural networks

   [9]go to the profile of adam geitgey
   [10]adam geitgey (button) blockedunblock (button) followfollowing
   jun 13, 2016

   update: this article is part of a series. check out the full series:
   [11]part 1, [12]part 2, [13]part 3, [14]part 4, [15]part 5, [16]part 6,
   [17]part 7 and [18]part 8! you can also read this article in [19]         ,
   [20]              , [21]         , [22]portugu  s, [23]ti   ng vi   t or [24]italiano.

   giant update: [25]i   ve written a new book based on these articles! it
   not only expands and updates all my articles, but it has tons of brand
   new content and lots of hands-on coding projects. [26]check it out now!

   are you tired of reading endless news stories about deep learning and
   not really knowing what that means? let   s change that!

   this time, we are going to learn how to write programs that recognize
   objects in images using deep learning. in other words, we   re going to
   explain the black magic that allows google photos to search your photos
   based on what is in the picture:
   [1*f-6upzsc6gmmtp9yheuwdg.gif]
   google now lets you search your own photos by description         even if
   they aren   t tagged! how does this work??

   just like [27]part 1 and [28]part 2, this guide is for anyone who is
   curious about machine learning but has no idea where to start. the goal
   is be accessible to anyone         which means that there   s a lot of
   generalizations and we skip lots of details. but who cares? if this
   gets anyone more interested in ml, then mission accomplished!

   (if you haven   t already read [29]part 1 and [30]part 2, read them now!)
     __________________________________________________________________

recognizing objects with deep learning

   [1*wuzii2mg2cncumwwxiibgq.png]
   xkcd #1425 ([31]view original here)

   you might have seen [32]this famous xkcd comic before.

   the goof is based on the idea that any 3-year-old child can recognize a
   photo of a bird, but figuring out how to make a computer recognize
   objects has puzzled the very best computer scientists for over 50
   years.

   in the last few years, we   ve finally found a good approach to object
   recognition using deep convolutional neural networks. that sounds like
   a a bunch of made up words from a william gibson sci-fi novel, but the
   ideas are totally understandable if you break them down one by one.

   so let   s do it         let   s write a program that can recognize birds!

starting simple

   before we learn how to recognize pictures of birds, let   s learn how to
   recognize something much simpler         the handwritten number    8   .

   in [33]part 2, we learned about how neural networks can solve complex
   problems by chaining together lots of simple neurons. we created a
   small neural network to estimate the price of a house based on how many
   bedrooms it had, how big it was, and which neighborhood it was in:
   [1*lt8rzaeq6f6b_ea1od32jq.png]

   we also know that the idea of machine learning is that the same generic
   algorithms can be reused with different data to solve different
   problems. so let   s modify this same neural network to recognize
   handwritten text. but to make the job really simple, we   ll only try to
   recognize one letter         the numeral    8   .

   machine learning only works when you have data         preferably a lot of
   data. so we need lots and lots of handwritten    8   s to get started.
   luckily, researchers created the [34]mnist data set of handwritten
   numbers for this very purpose. mnist provides 60,000 images of
   handwritten digits, each as an 18x18 image. here are some    8   s from the
   data set:
   [1*jykyxkfi4iae6qg-deuecq.jpeg]
   some 8s from the mnist data set

if you think about it, everything is just numbers

   the neural network we made in [35]part 2 only took in a three numbers
   as the input (   3    bedrooms,    2000    sq. feet , etc.). but now we want to
   process images with our neural network. how in the world do we feed
   images into a neural network instead of just numbers?

   the answer is incredible simple. a neural network takes numbers as
   input. to a computer, an image is really just a grid of numbers that
   represent how dark each pixel is:
   [1*zy1qfb9affzz66yxxoi2aw.gif]

   to feed an image into our neural network, we simply treat the 18x18
   pixel image as an array of 324 numbers:
   [1*udgde_-gms4qqbt8uopoga.png]

   the handle 324 inputs, we   ll just enlarge our neural network to have
   324 input nodes:
   [1*b31hqxibujixo2hsn_grfw.png]

   notice that our neural network also has two outputs now (instead of
   just one). the first output will predict the likelihood that the image
   is an    8    and thee second output will predict the likelihood it isn   t
   an    8   . by having a separate output for each type of object we want to
   recognize, we can use a neural network to classify objects into groups.

   our neural network is a lot bigger than last time (324 inputs instead
   of 3!). but any modern computer can handle a neural network with a few
   hundred nodes without blinking. this would even work fine on your cell
   phone.

   all that   s left is to train the neural network with images of    8   s and
   not-   8"s so it learns to tell them apart. when we feed in an    8   , we   ll
   tell it the id203 the image is an    8    is 100% and the id203
   it   s not an    8    is 0%. vice versa for the counter-example images.

   here   s some of our training data:
   [1*vevqdkp9mgzkvpk4m70eha.jpeg]
   mmm    sweet, sweet training data

   we can train this kind of neural network in a few minutes on a modern
   laptop. when it   s done, we   ll have a neural network that can recognize
   pictures of    8   s with a pretty high accuracy. welcome to the world of
   (late 1980   s-era) image recognition!

tunnel vision

   it   s really neat that simply feeding pixels into a neural network
   actually worked to build image recognition! machine learning is
   magic!    right?

   well, of course it   s not that simple.

   first, the good news is that our    8    recognizer really does work well
   on simple images where the letter is right in the middle of the image:
   [1*5cireal7xdyxcd-csrp7jw.png]

   but now the really bad news:

   our    8    recognizer totally fails to work when the letter isn   t
   perfectly centered in the image. just the slightest position change
   ruins everything:
   [1*b5jmtaiyvhoib9hhexid48a.png]

   this is because our network only learned the pattern of a
   perfectly-centered    8   . it has absolutely no idea what an off-center
      8    is. it knows exactly one pattern and one pattern only.

   that   s not very useful in the real world. real world problems are never
   that clean and simple. so we need to figure out how to make our neural
   network work in cases where the    8    isn   t perfectly centered.

brute force idea #1: searching with a sliding window

   we already created a really good program for finding an    8    centered in
   an image. what if we just scan all around the image for possible    8   s
   in smaller sections, one section at a time, until we find one?
   [1*bgbijvujntrj8025et0mcq.gif]

   this approach called a sliding window. it   s the brute force solution.
   it works well in some limited cases, but it   s really inefficient. you
   have to check the same image over and over looking for objects of
   different sizes. we can do better than this!

brute force idea #2: more data and a deep neural net

   when we trained our network, we only showed it    8   s that were perfectly
   centered. what if we train it with more data, including    8   s in all
   different positions and sizes all around the image?

   we don   t even need to collect new training data. we can just write a
   script to generate new images with the    8   s in all kinds of different
   positions in the image:
   [1*b es5eb6zxzieonnk-vq.png]
   we created synthetic training data by creating different versions of
   the training images we already had. this is a very useful technique!

   using this technique, we can easily create an endless supply of
   training data.

   more data makes the problem harder for our neural network to solve, but
   we can compensate for that by making our network bigger and thus able
   to learn more complicated patterns.

   to make the network bigger, we just stack up layer upon layer of nodes:
   [1*wfmpsofqwkc7vadjtjxwnq.png]

   we call this a    deep neural network    because it has more layers than a
   traditional neural network.

   this idea has been around since the late 1960s. but until recently,
   training this large of a neural network was just too slow to be useful.
   but once we figured out how to use 3d graphics cards (which were
   designed to do id127 really fast) instead of normal
   computer processors, working with large neural networks suddenly became
   practical. in fact, the exact same nvidia geforce gtx 1080 video card
   that you use to play [36]overwatch can be used to train neural networks
   incredibly quickly.
   [1*dsblj2ll7ex0qw-lt5zy8a.png]

   but even though we can make our neural network really big and train it
   quickly with a 3d graphics card, that still isn   t going to get us all
   the way to a solution. we need to be smarter about how we process
   images into our neural network.

   think about it. it doesn   t make sense to train a network to recognize
   an    8    at the top of a picture separately from training it to recognize
   an    8    at the bottom of a picture as if those were two totally
   different objects.

   there should be some way to make the neural network smart enough to
   know that an    8    anywhere in the picture is the same thing without all
   that extra training. luckily    there is!

the solution is convolution

   as a human, you intuitively know that pictures have a hierarchy or
   conceptual structure. consider this picture:
   [1*v_06o9d5u4k2lp9cthqutg.jpeg]
   gratuitous picture of my son

   as a human, you instantly recognize the hierarchy in this picture:
     * the ground is covered in grass and concrete
     * there is a child
     * the child is sitting on a bouncy horse
     * the bouncy horse is on top of the grass

   most importantly, we recognize the idea of a child no matter what
   surface the child is on. we don   t have to re-learn the idea of child
   for every possible surface it could appear on.

   but right now, our neural network can   t do this. it thinks that an    8   
   in a different part of the image is an entirely different thing. it
   doesn   t understand that moving an object around in the picture doesn   t
   make it something different. this means it has to re-learn the identify
   of each object in every possible position. that sucks.

   we need to give our neural network understanding of translation
   invariance         an    8    is an    8    no matter where in the picture it shows
   up.

   we   ll do this using a process called convolution. the idea of
   convolution is inspired partly by computer science and partly by
   biology (i.e. mad scientists literally poking cat brains with weird
   probes to figure out how cats process images).

how convolution works

   instead of feeding entire images into our neural network as one grid of
   numbers, we   re going to do something a lot smarter that takes advantage
   of the idea that an object is the same no matter where it appears in a
   picture.

   here   s how it   s going to work, step by step    

step 1: break the image into overlapping image tiles

   similar to our sliding window search above, let   s pass a sliding window
   over the entire original image and save each result as a separate, tiny
   picture tile:
   [1*xs7eugfgqhk68iph7ghpqg.png]

   by doing this, we turned our original image into 77 equally-sized tiny
   image tiles.

step 2: feed each image tile into a small neural network

   earlier, we fed a single image into a neural network to see if it was
   an    8   . we   ll do the exact same thing here, but we   ll do it for each
   individual image tile:
   [1*84-tdhvtahkfnzwa1zstvg.png]
   repeat this 77 times, once for each tile.

   however, there   s one big twist: we   ll keep the same neural network
   weights for every single tile in the same original image. in other
   words, we are treating every image tile equally. if something
   interesting appears in any given tile, we   ll mark that tile as
   interesting.

step 3: save the results from each tile into a new array

   we don   t want to lose track of the arrangement of the original tiles.
   so we save the result from processing each tile into a grid in the same
   arrangement as the original image. it looks like this:
   [1*tpmqyjafgsywpvlnkzgffw.png]

   in other words, we   ve started with a large image and we ended with a
   slightly smaller array that records which sections of our original
   image were the most interesting.

step 4: downsampling

   the result of step 3 was an array that maps out which parts of the
   original image are the most interesting. but that array is still pretty
   big:
   [1*1wwtbw9yyej69tf1rspv4g.png]

   to reduce the size of the array, we downsample it using an algorithm
   called [37]max pooling. it sounds fancy, but it isn   t at all!

   we   ll just look at each 2x2 square of the array and keep the biggest
   number:
   [1*xoarofiw9x0wskcwgcio6q.png]

   the idea here is that if we found something interesting in any of the
   four input tiles that makes up each 2x2 grid square, we   ll just keep
   the most interesting bit. this reduces the size of our array while
   keeping the most important bits.

final step: make a prediction

   so far, we   ve reduced a giant image down into a fairly small array.

   guess what? that array is just a bunch of numbers, so we can use that
   small array as input into another neural network. this final neural
   network will decide if the image is or isn   t a match. to differentiate
   it from the convolution step, we call it a    fully connected    network.

   so from start to finish, our whole five-step pipeline looks like this:
   [1*tj1rkl5xw_5izezxmnfh5q.png]

adding even more steps

   our image processing pipeline is a series of steps: convolution,
   max-pooling, and finally a fully-connected network.

   when solving problems in the real world, these steps can be combined
   and stacked as many times as you want! you can have two, three or even
   ten convolution layers. you can throw in max pooling wherever you want
   to reduce the size of your data.

   the basic idea is to start with a large image and continually boil it
   down, step-by-step, until you finally have a single result. the more
   convolution steps you have, the more complicated features your network
   will be able to learn to recognize.

   for example, the first convolution step might learn to recognize sharp
   edges, the second convolution step might recognize beaks using it   s
   knowledge of sharp edges, the third step might recognize entire birds
   using it   s knowledge of beaks, etc.

   here   s what a more realistic deep convolutional network (like you would
   find in a research paper) looks like:
   [1*jsnktzegihd4p6ulnv_c7w.png]

   in this case, they start a 224 x 224 pixel image, apply convolution and
   max pooling twice, apply convolution 3 more times, apply max pooling
   and then have two fully-connected layers. the end result is that the
   image is classified into one of 1000 categories!

constructing the right network

   so how do you know which steps you need to combine to make your image
   classifier work?

   honestly, you have to answer this by doing a lot of experimentation and
   testing. you might have to train 100 networks before you find the
   optimal structure and parameters for the problem you are solving.
   machine learning involves a lot of trial and error!

building our bird classifier

   now finally we know enough to write a program that can decide if a
   picture is a bird or not.

   as always, we need some data to get started. the free [38]cifar10 data
   set contains 6,000 pictures of birds and 52,000 pictures of things that
   are not birds. but to get even more data we   ll also add in the
   [39]caltech-ucsd birds-200   2011 data set that has another 12,000 bird
   pics.

   here   s a few of the birds from our combined data set:
   [1*r9i5d3nxcn8gnlojahusqa.png]

   and here   s some of the 52,000 non-bird images:
   [1*odaxolqy4-d7zqhrqea4uw.png]

   this data set will work fine for our purposes, but 72,000 low-res
   images is still pretty small for real-world applications. if you want
   google-level performance, you need millions of large images. in machine
   learning, having more data is almost always more important that having
   better algorithms. now you know why google is so happy to offer you
   unlimited photo storage. they want your sweet, sweet data!

   to build our classifier, we   ll use [40]tflearn. tflearn is a wrapper
   around google   s [41]tensorflow deep learning library that exposes a
   simplified api. it makes building convolutional neural networks as easy
   as writing a few lines of code to define the layers of our network.

   here   s the code to define and train the network:

   iframe: [42]/media/90b87fc19481de98d9f5183f358af784?postid=f40359318721

   if you are training with a good video card with enough ram (like an
   nvidia geforce gtx 980 ti or better), this will be done in less than an
   hour. if you are training with a normal cpu, it might take a lot
   longer.

   as it trains, the accuracy will increase. after the first pass, i got
   75.4% accuracy. after just 10 passes, it was already up to 91.7%. after
   50 or so passes, it capped out around 95.5% accuracy and additional
   training didn   t help, so i stopped it there.

   congrats! our program can now recognize birds in images!

testing our network

   now that we have a trained neural network, we can use it! [43]here   s a
   simple script that takes in a single image file and predicts if it is a
   bird or not.

   but to really see how effective our network is, we need to test it with
   lots of images. the data set i created held back 15,000 images for
   validation. when i ran those 15,000 images through the network, it
   predicted the correct answer 95% of the time.

   that seems pretty good, right? well    it depends!

how accurate is 95% accurate?

   our network claims to be 95% accurate. but the devil is in the details.
   that could mean all sorts of different things.

   for example, what if 5% of our training images were birds and the other
   95% were not birds? a program that guessed    not a bird    every single
   time would be 95% accurate! but it would also be 100% useless.

   we need to look more closely at the numbers than just the overall
   accuracy. to judge how good a classification system really is, we need
   to look closely at how it failed, not just the percentage of the time
   that it failed.

   instead of thinking about our predictions as    right    and    wrong   , let   s
   break them down into four separate categories    
     * first, here are some of the birds that our network correctly
       identified as birds. let   s call these true positives:

   [1*iuk7uonvxnfedwayed0hiq.png]
   wow! our network can recognize lots of different kinds of birds
   successfully!
     * second, here are images that our network correctly identified as
          not a bird   . these are called true negatives:

   [1*qzwijpimtlmoha-6tqpseg.png]
   horses and trucks don   t fool us!
     * third, here are some images that we thought were birds but were not
       really birds at all. these are our false positives:

   [1*uckik1mxe29wb9df1gembq.png]
   lots of planes were mistaken for birds! that makes sense.
     * and finally, here are some images of birds that we didn   t correctly
       recognize as birds. these are our false negatives:

   [1*ac9onpayukliejchrkikfq.png]
   these birds fooled us! stupid ostriches! do they even count as birds?

   using our validation set of 15,000 images, here   s how many times our
   predictions fell into each category:
   [1*lgsdq4-js3elxbpavip6fa.png]

   why do we break our results down like this? because not all mistakes
   are created equal.

   imagine if we were writing a program to detect cancer from an mri
   image. if we were detecting cancer, we   d rather have false positives
   than false negatives. false negatives would be the worse possible
   case         that   s when the program told someone they definitely didn   t have
   cancer but they actually did.

   instead of just looking at overall accuracy, we calculate [44]precision
   and recall metrics. precision and recall metrics give us a clearer
   picture of how well we did:
   [1*t8surwdvttey37yjuvu_pq.png]

   this tells us that 97% of the time we guessed    bird   , we were right!
   but it also tells us that we only found 90% of the actual birds in the
   data set. in other words, we might not find every bird but we are
   pretty sure about it when we do find one!

where to go from here

   now that you know the basics of deep convolutional networks, you can
   try out some of the [45]examples that come with tflearn to get your
   hands dirty with different neural network architectures. it even comes
   with built-in data sets so you don   t even have to find your own images.

   you also know enough now to start branching and learning about other
   areas of machine learning. why not learn [46]how to use algorithms to
   train computers how to play atari games next?
     __________________________________________________________________

   if you liked this article, please consider [47]signing up for my
   machine learning is fun! email list. i   ll only email you when i have
   something new and awesome to share. it   s the best way to find out when
   i write more articles like this.

   you can also follow me on twitter at [48]@ageitgey, [49]email me
   directly or [50]find me on linkedin. i   d love to hear from you if i can
   help you or your team with machine learning.

   now continue on to [51]machine learning is fun part 4, [52]part 5 and
   [53]part 6!

     * [54]machine learning
     * [55]artificial intelligence
     * [56]deep learning

   (button)
   (button)
   (button) 21k claps
   (button) (button) (button) 183 (button) (button)

     (button) blockedunblock (button) followfollowing
   [57]go to the profile of adam geitgey

[58]adam geitgey

   interested in computers and machine learning. likes to write about it.

     * (button)
       (button) 21k
     * (button)
     *
     *

   [59]go to the profile of adam geitgey
   never miss a story from adam geitgey, when you sign up for medium.
   [60]learn more
   never miss a story from adam geitgey
   (button) blockedunblock (button) followget updates

references

   visible links
   1. https://plus.google.com/103654360130207659246
   2. https://medium.com/osd.xml
   3. android-app://com.medium.reader/https/medium.com/p/f40359318721
   4. https://medium.com/
   5. https://medium.com/
   6. https://medium.com/membership?source=upgrade_membership---nav_full
   7. https://medium.com/m/signin?redirect=https://medium.com/@ageitgey/machine-learning-is-fun-part-3-deep-learning-and-convolutional-neural-networks-f40359318721&source=--------------------------nav_reg&operation=login
   8. https://medium.com/m/signin?redirect=https://medium.com/@ageitgey/machine-learning-is-fun-part-3-deep-learning-and-convolutional-neural-networks-f40359318721&source=--------------------------nav_reg&operation=register
   9. https://medium.com/@ageitgey?source=post_header_lockup
  10. https://medium.com/@ageitgey
  11. https://medium.com/@ageitgey/machine-learning-is-fun-80ea3ec3c471
  12. https://medium.com/@ageitgey/machine-learning-is-fun-part-2-a26a10b68df3
  13. https://medium.com/@ageitgey/machine-learning-is-fun-part-3-deep-learning-and-convolutional-neural-networks-f40359318721
  14. https://medium.com/@ageitgey/machine-learning-is-fun-part-4-modern-face-recognition-with-deep-learning-c3cffc121d78
  15. https://medium.com/@ageitgey/machine-learning-is-fun-part-5-language-translation-with-deep-learning-and-the-magic-of-sequences-2ace0acca0aa
  16. https://medium.com/@ageitgey/machine-learning-is-fun-part-6-how-to-do-speech-recognition-with-deep-learning-28293c162f7a
  17. https://medium.com/@ageitgey/abusing-generative-adversarial-networks-to-make-8-bit-pixel-art-e45d9b96cee7
  18. https://medium.com/@ageitgey/machine-learning-is-fun-part-8-how-to-intentionally-trick-neural-networks-b55da32b7196
  19. https://zhuanlan.zhihu.com/p/24524583
  20. http://algotravelling.com/ru/                -                -      -            -3/
  21. https://medium.com/@jongdae.lim/      -      -machine-learning-   -         -part-3-928a841a3aa
  22. https://medium.com/machina-sapiens/aprendizagem-de-m  quina-  -divertido-parte-3-deep-learning-e-redes-neuronais-convolutivas-879e0ee7ba48
  23. https://viblo.asia/p/machine-learning-that-thu-vi-3-tim-kiem-anh-chua-chim-vydzox1xlwj
  24. https://medium.com/botsupply/il-machine-learning-  -divertente-parte-3-deep-learning-e-convolutional-neural-network-id98s-cc106559ffa9
  25. https://www.machinelearningisfun.com/get-the-book/
  26. https://www.machinelearningisfun.com/get-the-book/
  27. https://medium.com/@ageitgey/machine-learning-is-fun-80ea3ec3c471
  28. https://medium.com/@ageitgey/machine-learning-is-fun-part-2-a26a10b68df3#.lbsa5her1
  29. https://medium.com/@ageitgey/machine-learning-is-fun-80ea3ec3c471
  30. https://medium.com/@ageitgey/machine-learning-is-fun-part-2-a26a10b68df3#.lbsa5her1
  31. http://xkcd.com/1425/
  32. http://xkcd.com/1425/
  33. https://medium.com/@ageitgey/machine-learning-is-fun-part-2-a26a10b68df3#.lbsa5her1
  34. http://yann.lecun.com/exdb/mnist/
  35. https://medium.com/@ageitgey/machine-learning-is-fun-part-2-a26a10b68df3#.lbsa5her1
  36. https://en.wikipedia.org/wiki/overwatch_(video_game)
  37. https://en.wikipedia.org/wiki/convolutional_neural_network#pooling_layer
  38. https://www.cs.toronto.edu/~kriz/cifar.html
  39. http://www.vision.caltech.edu/visipedia/cub-200-2011.html
  40. http://tflearn.org/
  41. https://www.tensorflow.org/
  42. https://medium.com/media/90b87fc19481de98d9f5183f358af784?postid=f40359318721
  43. https://gist.github.com/ageitgey/a40dded08e82e59724c70da23786bbf0
  44. https://en.wikipedia.org/wiki/precision_and_recall
  45. https://github.com/tflearn/tflearn/tree/master/examples#tflearn-examples
  46. http://karpathy.github.io/2016/05/31/rl/
  47. http://eepurl.com/b9fg2t
  48. https://twitter.com/ageitgey
  49. mailto:ageitgey@gmail.com
  50. https://www.linkedin.com/in/ageitgey
  51. https://medium.com/@ageitgey/machine-learning-is-fun-part-4-modern-face-recognition-with-deep-learning-c3cffc121d78
  52. https://medium.com/@ageitgey/machine-learning-is-fun-part-5-language-translation-with-deep-learning-and-the-magic-of-sequences-2ace0acca0aa
  53. https://medium.com/@ageitgey/machine-learning-is-fun-part-6-how-to-do-speech-recognition-with-deep-learning-28293c162f7a
  54. https://medium.com/tag/machine-learning?source=post
  55. https://medium.com/tag/artificial-intelligence?source=post
  56. https://medium.com/tag/deep-learning?source=post
  57. https://medium.com/@ageitgey?source=footer_card
  58. https://medium.com/@ageitgey
  59. https://medium.com/@ageitgey
  60. https://medium.com/@medium/personalize-your-medium-experience-with-users-publications-tags-26a41ab1ee0c#.hx4zuv3mg

   hidden links:
  62. https://medium.com/p/f40359318721/share/twitter
  63. https://medium.com/p/f40359318721/share/facebook
  64. https://medium.com/p/f40359318721/share/twitter
  65. https://medium.com/p/f40359318721/share/facebook
