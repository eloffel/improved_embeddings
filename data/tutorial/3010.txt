   #[1]publisher [2]medium [3]alternate

   [4]homepage
   [5]homepage
   [6]artificial intelligence
   [7]become a member[8]sign in[9]get started
     __________________________________________________________________

machine learning is fun! part 4: modern face recognition with deep learning

   [10]go to the profile of adam geitgey
   [11]adam geitgey (button) blockedunblock (button) followfollowing
   jul 24, 2016

   update: this article is part of a series. check out the full series:
   [12]part 1, [13]part 2, [14]part 3, [15]part 4, [16]part 5, [17]part 6,
   [18]part 7 and [19]part 8! you can also read this article in [20]         ,
   [21]              , [22]         , [23]portugu  s, [24]ti   ng vi   t or [25]italiano.

   giant update: [26]i   ve written a new book based on these articles! it
   not only expands and updates all my articles, but it has tons of brand
   new content and lots of hands-on coding projects. [27]check it out now!

   have you noticed that facebook has developed an uncanny ability to
   recognize your friends in your photographs? in the old days, facebook
   used to make you to tag your friends in photos by clicking on them and
   typing in their name. now as soon as you upload a photo, facebook tags
   everyone for you like magic:
   [1*wfi-rk1hu2yrdw3bqxyofq.gif]
   facebook automatically tags people in your photos that you have tagged
   before. i   m not sure if this is helpful or creepy!

   this technology is called face recognition. facebook   s algorithms are
   able to recognize your friends    faces after they have been tagged only
   a few times. it   s pretty amazing technology         facebook can recognize
   faces with [28]98% accuracy which is pretty much as good as humans can
   do!

   let   s learn how modern face recognition works! but just recognizing
   your friends would be too easy. we can push this tech to the limit to
   solve a more challenging problem         telling [29]will ferrell (famous
   actor) apart from [30]chad smith (famous rock musician)!
   [1*l7znw_4-afeofp_mxxs75w.jpeg]
   one of these people is will farrell. the other is chad smith. i swear
   they are different people!
     __________________________________________________________________

how to use machine learning on a very complicated problem

   so far in [31]part 1, [32]2 and [33]3, we   ve used machine learning to
   solve isolated problems that have only one step         [34]estimating the
   price of a house, [35]generating new data based on existing data and
   [36]telling if an image contains a certain object. all of those
   problems can be solved by choosing one machine learning algorithm,
   feeding in data, and getting the result.

   but face recognition is really a series of several related problems:
    1. first, look at a picture and find all the faces in it
    2. second, focus on each face and be able to understand that even if a
       face is turned in a weird direction or in bad lighting, it is still
       the same person.
    3. third, be able to pick out unique features of the face that you can
       use to tell it apart from other people    like how big the eyes are,
       how long the face is, etc.
    4. finally, compare the unique features of that face to all the people
       you already know to determine the person   s name.

   as a human, your brain is wired to do all of this automatically and
   instantly. in fact, humans are too good at recognizing faces and end up
   seeing faces in everyday objects:
   [1*hcwwlnd2du14e-rzj50tha.jpeg]

   computers are not capable of this kind of high-level generalization (at
   least not yet   ), so we have to teach them how to do each step in this
   process separately.

   we need to build a pipeline where we solve each step of face
   recognition separately and pass the result of the current step to the
   next step. in other words, we will chain together several machine
   learning algorithms:
   [1*wxbm1lb5wzdjrdxyfi9gtw.gif]
   how a basic pipeline for detecting faces might work
     __________________________________________________________________

face recognition         step by step

   let   s tackle this problem one step at a time. for each step, we   ll
   learn about a different machine learning algorithm. i   m not going to
   explain every single algorithm completely to keep this from turning
   into a book, but you   ll learn the main ideas behind each one and you   ll
   learn how you can build your own facial recognition system in python
   using [37]openface and [38]dlib.

step 1: finding all the faces

   the first step in our pipeline is face detection. obviously we need to
   locate the faces in a photograph before we can try to tell them apart!

   if you   ve used any camera in the last 10 years, you   ve probably seen
   face detection in action:
   [1*izquwclzcsjocw5ybqc01q.png]

   face detection is a great feature for cameras. when the camera can
   automatically pick out faces, it can make sure that all the faces are
   in focus before it takes the picture. but we   ll use it for a different
   purpose         finding the areas of the image we want to pass on to the next
   step in our pipeline.

   face detection went mainstream in the early 2000's when paul viola and
   michael jones invented a [39]way to detect faces that was fast enough
   to run on cheap cameras. however, much more reliable solutions exist
   now. we   re going to use [40]a method invented in 2005 called histogram
   of oriented gradients         or just hog for short.

   to find faces in an image, we   ll start by making our image black and
   white because we don   t need color data to find faces:
   [1*osgdb2bid4hhk1rtwo07ja.jpeg]

   then we   ll look at every single pixel in our image one at a time. for
   every single pixel, we want to look at the pixels that directly
   surrounding it:
   [1*rzs05e_5xxqdofdrx1gvpa.gif]

   our goal is to figure out how dark the current pixel is compared to the
   pixels directly surrounding it. then we want to draw an arrow showing
   in which direction the image is getting darker:
   [1*wf54tqnh1hgpoqk-vtf9lg.gif]
   looking at just this one pixel and the pixels touching it, the image is
   getting darker towards the upper right.

   if you repeat that process for every single pixel in the image, you end
   up with every pixel being replaced by an arrow. these arrows are called
   gradients and they show the flow from light to dark across the entire
   image:
   [1*otdaelx_m-_z9c_iawwqcw.gif]

   this might seem like a random thing to do, but there   s a really good
   reason for replacing the pixels with gradients. if we analyze pixels
   directly, really dark images and really light images of the same person
   will have totally different pixel values. but by only considering the
   direction that brightness changes, both really dark images and really
   bright images will end up with the same exact representation. that
   makes the problem a lot easier to solve!

   but saving the gradient for every single pixel gives us way too much
   detail. we end up [41]missing the forest for the trees. it would be
   better if we could just see the basic flow of lightness/darkness at a
   higher level so we could see the basic pattern of the image.

   to do this, we   ll break up the image into small squares of 16x16 pixels
   each. in each square, we   ll count up how many gradients point in each
   major direction (how many point up, point up-right, point right, etc   ).
   then we   ll replace that square in the image with the arrow directions
   that were the strongest.

   the end result is we turn the original image into a very simple
   representation that captures the basic structure of a face in a simple
   way:
   [1*uhisafuuw0fosoza992jdg.gif]
   the original image is turned into a hog representation that captures
   the major features of the image regardless of image brightnesss.

   to find faces in this hog image, all we have to do is find the part of
   our image that looks the most similar to a known hog pattern that was
   extracted from a bunch of other training faces:
   [1*6xgev0r-qn4or88frw6fia.png]

   using this technique, we can now easily find faces in any image:
   [1*dotp6yl7d4c0oar6npfwvg.jpeg]

   if you want to try this step out yourself using python and dlib,
   [42]here   s code showing how to generate and view hog representations of
   images.

step 2: posing and projecting faces

   whew, we isolated the faces in our image. but now we have to deal with
   the problem that faces turned different directions look totally
   different to a computer:
   [1*x-rg0aspkoer1jf-tejyug.png]
   humans can easily recognize that both images are of will ferrell, but
   computers would see these pictures as two completely different people.

   to account for this, we will try to warp each picture so that the eyes
   and lips are always in the sample place in the image. this will make it
   a lot easier for us to compare faces in the next steps.

   to do this, we are going to use an algorithm called face landmark
   estimation. there are lots of ways to do this, but we are going to use
   the approach [43]invented in 2014 by vahid kazemi and josephine
   sullivan.

   the basic idea is we will come up with 68 specific points (called
   landmarks) that exist on every face         the top of the chin, the outside
   edge of each eye, the inner edge of each eyebrow, etc. then we will
   train a machine learning algorithm to be able to find these 68 specific
   points on any face:
   [1*abeg31egkbxsqehunjblwg.png]
   the 68 landmarks we will locate on every face. this image was created
   by [44]brandon amos of cmu who works on [45]openface.

   here   s the result of locating the 68 face landmarks on our test image:
   [1*xbj4h2lbcmfzifmrom9beq.jpeg]
   protip: you can also use this same technique to implement your own
   version of snapchat   s real-time 3d face filters!

   now that we know were the eyes and mouth are, we   ll simply rotate,
   scale and [46]shear the image so that the eyes and mouth are centered
   as best as possible. we won   t do any fancy 3d warps because that would
   introduce distortions into the image. we are only going to use basic
   image transformations like rotation and scale that preserve parallel
   lines (called [47]affine transformations):
   [1*igezgcfn-tjzb94j15tcna.png]

   now no matter how the face is turned, we are able to center the eyes
   and mouth are in roughly the same position in the image. this will make
   our next step a lot more accurate.

   if you want to try this step out yourself using python and dlib, here   s
   the [48]code for finding face landmarks and here   s the [49]code for
   transforming the image using those landmarks.

step 3: encoding faces

   now we are to the meat of the problem         actually telling faces apart.
   this is where things get really interesting!

   the simplest approach to face recognition is to directly compare the
   unknown face we found in step 2 with all the pictures we have of people
   that have already been tagged. when we find a previously tagged face
   that looks very similar to our unknown face, it must be the same
   person. seems like a pretty good idea, right?

   there   s actually a huge problem with that approach. a site like
   facebook with billions of users and a trillion photos can   t possibly
   loop through every previous-tagged face to compare it to every newly
   uploaded picture. that would take way too long. they need to be able to
   recognize faces in milliseconds, not hours.

   what we need is a way to extract a few basic measurements from each
   face. then we could measure our unknown face the same way and find the
   known face with the closest measurements. for example, we might measure
   the size of each ear, the spacing between the eyes, the length of the
   nose, etc. if you   ve ever watched a bad crime show like [50]csi, you
   know what i am talking about:
   [1*_gnyjr3jlpos9grtivmkfq.gif]
   just like tv! so real! #science

the most reliable way to measure a face

   ok, so which measurements should we collect from each face to build our
   known face database? ear size? nose length? eye color? something else?

   it turns out that the measurements that seem obvious to us humans (like
   eye color) don   t really make sense to a computer looking at individual
   pixels in an image. researchers have discovered that the most accurate
   approach is to let the computer figure out the measurements to collect
   itself. deep learning does a better job than humans at figuring out
   which parts of a face are important to measure.

   the solution is to train a deep convolutional neural network ([51]just
   like we did in part 3). but instead of training the network to
   recognize pictures objects like we did last time, we are going to train
   it to generate 128 measurements for each face.

   the training process works by looking at 3 face images at a time:
    1. load a training face image of a known person
    2. load another picture of the same known person
    3. load a picture of a totally different person

   then the algorithm looks at the measurements it is currently generating
   for each of those three images. it then tweaks the neural network
   slightly so that it makes sure the measurements it generates for #1 and
   #2 are slightly closer while making sure the measurements for #2 and #3
   are slightly further apart:
   [1*n1r8vmydrw3rno3julybpq.png]

   after repeating this step millions of times for millions of images of
   thousands of different people, the neural network learns to reliably
   generate 128 measurements for each person. any ten different pictures
   of the same person should give roughly the same measurements.

   machine learning people call the 128 measurements of each face an
   embedding. the idea of reducing complicated raw data like a picture
   into a list of computer-generated numbers comes up a lot in machine
   learning (especially in language translation). the exact approach for
   faces we are using [52]was invented in 2015 by researchers at google
   but many similar approaches exist.

encoding our face image

   this process of training a convolutional neural network to output face
   embeddings requires a lot of data and computer power. even with an
   expensive [53]nvidia telsa video card, it takes [54]about 24 hours of
   continuous training to get good accuracy.

   but once the network has been trained, it can generate measurements for
   any face, even ones it has never seen before! so this step only needs
   to be done once. lucky for us, the fine folks at [55]openface already
   did this and they [56]published several trained networks which we can
   directly use. thanks [57]brandon amos and team!

   so all we need to do ourselves is run our face images through their
   pre-trained network to get the 128 measurements for each face. here   s
   the measurements for our test image:
   [1*6kmmqlt4ubcrn7htqnhmkw.png]

   so what parts of the face are these 128 numbers measuring exactly? it
   turns out that we have no idea. it doesn   t really matter to us. all
   that we care is that the network generates nearly the same numbers when
   looking at two different pictures of the same person.

   if you want to try this step yourself, openface [58]provides a lua
   script that will generate embeddings all images in a folder and write
   them to a csv file. you [59]run it like this.

step 4: finding the person   s name from the encoding

   this last step is actually the easiest step in the whole process. all
   we have to do is find the person in our database of known people who
   has the closest measurements to our test image.

   you can do that by using any basic machine learning classification
   algorithm. no fancy deep learning tricks are needed. we   ll use a simple
   linear [60]id166 classifier, but lots of classification algorithms could
   work.

   all we need to do is train a classifier that can take in the
   measurements from a new test image and tells which known person is the
   closest match. running this classifier takes milliseconds. the result
   of the classifier is the name of the person!

   so let   s try out our system. first, i trained a classifier with the
   embeddings of about 20 pictures each of will ferrell, chad smith and
   jimmy falon:
   [1*g6jxtxuxdygy_orepnzg9q.jpeg]
   sweet, sweet training data!

   then i ran the classifier on every frame of the famous youtube video of
   [61]will ferrell and chad smith pretending to be each other on the
   jimmy fallon show:
   [1*wopojjbd6lt7cfz9lhrvdw.gif]

   it works! and look how well it works for faces in different
   poses         even sideways faces!

running this yourself

   let   s review the steps we followed:
    1. encode a picture using the hog algorithm to create a simplified
       version of the image. using this simplified image, find the part of
       the image that most looks like a generic hog encoding of a face.
    2. figure out the pose of the face by finding the main landmarks in
       the face. once we find those landmarks, use them to warp the image
       so that the eyes and mouth are centered.
    3. pass the centered face image through a neural network that knows
       how to measure features of the face. save those 128 measurements.
    4. looking at all the faces we   ve measured in the past, see which
       person has the closest measurements to our face   s measurements.
       that   s our match!

   now that you know how this all works, here   s instructions from
   start-to-finish of how run this entire face recognition pipeline on
   your own computer:

   update 4/9/2017: you can still follow the steps below to use openface.
   however, i   ve released a new python-based face recognition library
   called [62]face_recognition that is much easier to install and use. so
   i   d recommend trying out [63]face_recognition first instead of
   continuing below!

   i even put together [64]a pre-configured virtual machine with
   face_recognition, opencv, tensorflow and lots of other deep learning
   tools pre-installed. you can download and run it on your computer very
   easily. give the virtual machine a shot if you don   t want to install
   all these libraries yourself!

   original openface instructions:

   iframe: [65]/media/4875895b9e03cf38ab5f29908cc43c91?postid=c3cffc121d78
     __________________________________________________________________

   if you liked this article, please consider signing up for my machine
   learning is fun! newsletter:

   iframe: [66]/media/8e44dc920f5299cf3fffec4fa04c7b49?postid=c3cffc121d78

   you can also follow me on twitter at [67]@ageitgey, [68]email me
   directly or [69]find me on linkedin. i   d love to hear from you if i can
   help you or your team with machine learning.

   now continue on to [70]machine learning is fun part 5!

     * [71]machine learning
     * [72]artificial intelligence
     * [73]deep learning

   (button)
   (button)
   (button) 24k claps
   (button) (button) (button) 183 (button) (button)

     (button) blockedunblock (button) followfollowing
   [74]go to the profile of adam geitgey

[75]adam geitgey

   interested in computers and machine learning. likes to write about it.

     * (button)
       (button) 24k
     * (button)
     *
     *

   [76]go to the profile of adam geitgey
   never miss a story from adam geitgey, when you sign up for medium.
   [77]learn more
   never miss a story from adam geitgey
   (button) blockedunblock (button) followget updates

references

   visible links
   1. https://plus.google.com/103654360130207659246
   2. https://medium.com/osd.xml
   3. android-app://com.medium.reader/https/medium.com/p/c3cffc121d78
   4. https://medium.com/
   5. https://medium.com/
   6. https://medium.com/topic/artificial-intelligence
   7. https://medium.com/membership?source=upgrade_membership---nav_full
   8. https://medium.com/m/signin?redirect=https://medium.com/@ageitgey/machine-learning-is-fun-part-4-modern-face-recognition-with-deep-learning-c3cffc121d78&source=--------------------------nav_reg&operation=login
   9. https://medium.com/m/signin?redirect=https://medium.com/@ageitgey/machine-learning-is-fun-part-4-modern-face-recognition-with-deep-learning-c3cffc121d78&source=--------------------------nav_reg&operation=register
  10. https://medium.com/@ageitgey?source=post_header_lockup
  11. https://medium.com/@ageitgey
  12. https://medium.com/@ageitgey/machine-learning-is-fun-80ea3ec3c471
  13. https://medium.com/@ageitgey/machine-learning-is-fun-part-2-a26a10b68df3
  14. https://medium.com/@ageitgey/machine-learning-is-fun-part-3-deep-learning-and-convolutional-neural-networks-f40359318721
  15. https://medium.com/@ageitgey/machine-learning-is-fun-part-4-modern-face-recognition-with-deep-learning-c3cffc121d78
  16. https://medium.com/@ageitgey/machine-learning-is-fun-part-5-language-translation-with-deep-learning-and-the-magic-of-sequences-2ace0acca0aa
  17. https://medium.com/@ageitgey/machine-learning-is-fun-part-6-how-to-do-speech-recognition-with-deep-learning-28293c162f7a
  18. https://medium.com/@ageitgey/abusing-generative-adversarial-networks-to-make-8-bit-pixel-art-e45d9b96cee7
  19. https://medium.com/@ageitgey/machine-learning-is-fun-part-8-how-to-intentionally-trick-neural-networks-b55da32b7196
  20. https://zhuanlan.zhihu.com/p/24567586
  21. http://algotravelling.com/ru/                -                -      -            -4/
  22. https://medium.com/@jongdae.lim/      -      -machine-learning-   -         -part-4-63ed781eee3c
  23. https://medium.com/machina-sapiens/aprendizagem-de-m  quina-  -divertido-parte-4-reconhecimento-facial-moderno-com-deep-learning-72525d9684c2
  24. https://viblo.asia/p/machine-learning-that-thu-vi-4-tu-dong-tag-ten-ban-be-ornzqpdqk0n
  25. https://medium.com/botsupply/il-machine-learning-  -divertente-parte-4-c707feee1cf8
  26. https://www.machinelearningisfun.com/get-the-book/
  27. https://www.machinelearningisfun.com/get-the-book/
  28. https://research.facebook.com/publications/deepface-closing-the-gap-to-human-level-performance-in-face-verification/
  29. https://en.wikipedia.org/wiki/will_ferrell
  30. https://en.wikipedia.org/wiki/chad_smith
  31. https://medium.com/@ageitgey/machine-learning-is-fun-80ea3ec3c471
  32. https://medium.com/@ageitgey/machine-learning-is-fun-part-2-a26a10b68df3
  33. https://medium.com/@ageitgey/machine-learning-is-fun-part-3-deep-learning-and-convolutional-neural-networks-f40359318721
  34. https://medium.com/@ageitgey/machine-learning-is-fun-80ea3ec3c471
  35. https://medium.com/@ageitgey/machine-learning-is-fun-part-2-a26a10b68df3
  36. https://medium.com/@ageitgey/machine-learning-is-fun-part-3-deep-learning-and-convolutional-neural-networks-f40359318721
  37. https://cmusatyalab.github.io/openface/
  38. http://dlib.net/
  39. https://en.wikipedia.org/wiki/viola   jones_object_detection_framework
  40. http://lear.inrialpes.fr/people/triggs/pubs/dalal-cvpr05.pdf
  41. https://en.wiktionary.org/wiki/see_the_forest_for_the_trees
  42. https://gist.github.com/ageitgey/1c1cb1c60ace321868f7410d48c228e1
  43. http://www.csc.kth.se/~vahidk/papers/kazemicvpr14.pdf
  44. http://bamos.github.io/
  45. https://github.com/cmusatyalab/openface
  46. https://en.wikipedia.org/wiki/shear_mapping#/media/file:verticalshear_m=1.25.svg
  47. https://en.wikipedia.org/wiki/affine_transformation
  48. https://gist.github.com/ageitgey/ae340db3e493530d5e1f9c15292e5c74
  49. https://gist.github.com/ageitgey/82d0ea0fdb56dc93cb9b716e7ceb364b
  50. https://en.wikipedia.org/wiki/csi:_crime_scene_investigation
  51. https://medium.com/@ageitgey/machine-learning-is-fun-part-3-deep-learning-and-convolutional-neural-networks-f40359318721
  52. http://www.cv-foundation.org/openaccess/content_cvpr_2015/app/1a_089.pdf
  53. http://www.nvidia.com/object/tesla-supercomputing-solutions.html
  54. https://twitter.com/brandondamos/status/757959518433243136
  55. https://cmusatyalab.github.io/openface/
  56. https://github.com/cmusatyalab/openface/tree/master/models/openface
  57. http://bamos.github.io/
  58. https://github.com/cmusatyalab/openface/blob/master/batch-represent/batch-represent.lua
  59. https://gist.github.com/ageitgey/ddbae3b209b6344a458fa41a3cf75719
  60. https://en.wikipedia.org/wiki/support_vector_machine
  61. https://www.youtube.com/watch?v=eswhybok2iq
  62. https://github.com/ageitgey/face_recognition#face-recognition
  63. https://github.com/ageitgey/face_recognition#face-recognition
  64. https://medium.com/@ageitgey/try-deep-learning-in-python-now-with-a-fully-pre-configured-vm-1d97d4c3e9b
  65. https://medium.com/media/4875895b9e03cf38ab5f29908cc43c91?postid=c3cffc121d78
  66. https://medium.com/media/8e44dc920f5299cf3fffec4fa04c7b49?postid=c3cffc121d78
  67. https://twitter.com/ageitgey
  68. mailto:ageitgey@gmail.com
  69. https://www.linkedin.com/in/ageitgey
  70. https://medium.com/@ageitgey/machine-learning-is-fun-part-5-language-translation-with-deep-learning-and-the-magic-of-sequences-2ace0acca0aa
  71. https://medium.com/tag/machine-learning?source=post
  72. https://medium.com/tag/artificial-intelligence?source=post
  73. https://medium.com/tag/deep-learning?source=post
  74. https://medium.com/@ageitgey?source=footer_card
  75. https://medium.com/@ageitgey
  76. https://medium.com/@ageitgey
  77. https://medium.com/@medium/personalize-your-medium-experience-with-users-publications-tags-26a41ab1ee0c#.hx4zuv3mg

   hidden links:
  79. https://medium.com/p/c3cffc121d78/share/twitter
  80. https://medium.com/p/c3cffc121d78/share/facebook
  81. https://medium.com/p/c3cffc121d78/share/twitter
  82. https://medium.com/p/c3cffc121d78/share/facebook
