   #[1]github [2]recent commits to nut:master

   [3]skip to content

   (button)

     * why github?
       [4]features    
          + [5]code review
          + [6]project management
          + [7]integrations
          + [8]actions
          + [9]team management
          + [10]social coding
          + [11]documentation
          + [12]code hosting
          + [13]customer stories    
          + [14]security    
     * [15]enterprise
     * explore
          + [16]explore github    

learn & contribute
          + [17]topics
          + [18]collections
          + [19]trending
          + [20]learning lab
          + [21]open source guides

connect with others
          + [22]events
          + [23]community forum
          + [24]github education
     * [25]marketplace
     * pricing
       [26]plans    
          + [27]compare plans
          + [28]contact sales
          + [29]nonprofit    
          + [30]education    

   ____________________
     * in this repository all github    
       jump to    

     * no suggested jump to results

     * in this repository all github    
       jump to    
     * in this repository all github    
       jump to    

   [31]sign in [32]sign up

     * [33]watch [34]8
     * [35]star [36]118
     * [37]fork [38]26

[39]pprett/[40]nut

   [41]code [42]issues 1 [43]pull requests 0 [44]projects 0 [45]insights
   (button) dismiss

join github today

   github is home to over 31 million developers working together to host
   and review code, manage projects, and build software together.
   [46]sign up
   natural language understanding toolkit
     * [47]75 commits
     * [48]2 branches
     * [49]0 releases
     * [50]fetching contributors

    1. [51]c 75.1%
    2. [52]python 24.9%

   (button) c python
   branch: master (button) new pull request
   [53]find file
   clone or download

clone with https

   use git or checkout with svn using the web url.
   https://github.com/p
   [54]download zip

downloading...

   want to be notified of new releases in pprett/nut?
   [55]sign in [56]sign up

launching github desktop...

   if nothing happens, [57]download github desktop and try again.

   (button) go back

launching github desktop...

   if nothing happens, [58]download github desktop and try again.

   (button) go back

launching xcode...

   if nothing happens, [59]download xcode and try again.

   (button) go back

launching visual studio...

   if nothing happens, [60]download the github extension for visual studio
   and try again.

   (button) go back
   fetching latest commit   
   cannot retrieve the latest commit at this time.
   [61]permalink
   type           name          latest commit message commit time
        failed to load latest commit information.
        [62]nut
        [63].gitignore
        [64]readme.rst
        [65]clscl_predict
        [66]clscl_train
        [67]model_de_v1.bz2
        [68]model_en_v1.bz2
        [69]ner_aso
        [70]ner_demo.py
        [71]ner_predict
        [72]ner_train
        [73]results_conll03.txt
        [74]setup.id18
        [75]setup.py

readme.rst

natural language understanding toolkit

toc

     * [76]requirements
     * [77]installation
     *

        [78]documentation

               o [79]clscl
               o [80]ner

     * [81]references

requirements

   to install nut you need:

     * python 2.5 or 2.6
     * numpy (>= 1.1)
     * sparsesvd (>= 0.1.4) [82][1] (only [83]clscl)

installation

   to clone the repository run,

     git clone git://github.com/pprett/nut.git

   to build the extension modules inplace run,

     python setup.py build_ext --inplace

   add project to python path,

     export pythonpath=$pythonpath:$home/workspace/nut

documentation

clscl

   an implementation of cross-language structural correspondence learning
   (clscl). see [84][prettenhofer2010] for a detailed description and
   [85][prettenhofer2011] for more experiments and enhancements.

   the data for cross-language sentiment classification that has been used
   in the above study can be found here [86][2].

clscl_train

   training script for clscl. see ./clscl_train --help for further
   details.

   usage:
$ ./clscl_train en de cls-acl10-processed/en/books/train.processed cls-acl10-pro
cessed/en/books/unlabeled.processed cls-acl10-processed/de/books/unlabeled.proce
ssed cls-acl10-processed/dict/en_de_dict.txt model.bz2 --phi 30 --max-unlabeled=
50000 -k 100 -m 450 --strategy=parallel

|v_s| = 64682
|v_t| = 106024
|v| = 170706
|s_train| = 2000
|s_unlabeled| = 50000
|t_unlabeled| = 50000
debug: dicttranslator contains 5012 translations.
mutualinformation took 5.624 sec
select_pivots took 7.197 sec
|pivots| = 450
create_inverted_index took 59.353 sec
run joblib.parallel
[parallel(n_jobs=-1)]: done   1 out of 450 |elapsed:    9.1s remaining: 67.8min
[parallel(n_jobs=-1)]: done   5 out of 450 |elapsed:   15.2s remaining: 22.6min
[..]
[parallel(n_jobs=-1)]: done 449 out of 450 |elapsed: 14.5min remaining:    1.9s
train_aux_classifiers took 881.803 sec
density: 0.1154
ut.shape = (100,170706)
learn took 903.588 sec
project took 175.483 sec

   note

   if you have access to a hadoop cluster, you can use --strategy=hadoop
   to train the pivot classifiers even faster, however, make sure that the
   hadoop nodes have bolt (feature-mask branch) [87][3] installed.

clscl_predict

   prediction script for clscl.

   usage:
$ ./clscl_predict cls-acl10-processed/en/books/train.processed model.bz2 cls-acl
10-processed/de/books/test.processed 0.01
|v_s| = 64682
|v_t| = 106024
|v| = 170706
load took 0.681 sec
load took 0.659 sec
classes = {negative,positive}
project took 2.498 sec
project took 2.716 sec
project took 2.275 sec
project took 2.492 sec
acc: 83.05

named-entity recognition

   a simple greedy left-to-right sequence labeling approach to named
   entity recognition (ner).

pre-trained models

   we provide pre-trained named entity recognizers for place, person, and
   organization names in english and german. to tag a sentence simply use:
>>> from nut.io import compressed_load
>>> from nut.util import wordtokenizer

>>> tagger = compressed_load("model_demo_en.bz2")
>>> tokenizer = wordtokenizer()
>>> tokens = tokenizer.tokenize("peter prettenhofer lives in austria .")

>>> # see tagger.tag.__doc__ for input format
>>> sent = [((token, "", ""), "") for token in tokens]
>>> g = tagger.tag(sent)  # returns a generator over tags
>>> print(" ".join(["/".join(tt) for tt in zip(tokens, g)]))
peter/b-per prettenhofer/i-per lives/o in/o austria/b-loc ./o

   you can also use the convenience demo script ner_demo.py:
$ python ner_demo.py model_en_v1.bz2

   the feature detector modules for the pre-trained models are
   en_best_v1.py and de_best_v1.py and can be found in the package
   nut.ner.features. in addition to baseline features (word presence,
   shape, pre-/suffixes) they use distributional features (brown
   clusters), non-local features (extended prediction history), and
   gazetteers (see [88][ratinov2009]). the models have been trained on
   conll03 [89][4]. both models use neither syntactic features (e.g.
   part-of-speech tags, chunks) nor word lemmas, thus, minimizing the
   required pre-processing. both models provide state-of-the-art
   performance on the conll03 shared task benchmark for english
   [90][ratinov2009]:
processed 46435 tokens with 4946 phrases; found: 4864 phrases; correct: 4455.
accuracy:  98.01%; precision:  91.59%; recall:  90.07%; fb1:  90.83
              loc: precision:  91.69%; recall:  90.53%; fb1:  91.11  1648
              org: precision:  87.36%; recall:  85.73%; fb1:  86.54  1630
              per: precision:  95.84%; recall:  94.06%; fb1:  94.94  1586

   and german [91][faruqui2010]:
processed 51943 tokens with 2845 phrases; found: 2438 phrases; correct: 2168.
accuracy:  97.92%; precision:  88.93%; recall:  76.20%; fb1:  82.07
              loc: precision:  87.67%; recall:  79.83%; fb1:  83.57  957
              org: precision:  82.62%; recall:  65.92%; fb1:  73.33  466
              per: precision:  93.00%; recall:  78.02%; fb1:  84.85  1015

   to evaluate the german model on the out-domain data provided by
   [92][faruqui2010] use the raw flag (-r) to write raw predictions
   (without b- and i- prefixes):
./ner_predict -r model_de_v1.bz2 clner/de/europarl/test.conll - | clner/scripts/
conlleval -r
loading tagger... [done]
use_eph:  true
use_aso:  false
processed input in 40.9214s sec.
processed 110405 tokens with 2112 phrases; found: 2930 phrases; correct: 1676.
accuracy:  98.50%; precision:  57.20%; recall:  79.36%; fb1:  66.48
              loc: precision:  91.47%; recall:  71.13%; fb1:  80.03  563
              org: precision:  43.63%; recall:  83.52%; fb1:  57.32  1673
              per: precision:  62.10%; recall:  83.85%; fb1:  71.36  694

   note that the above results cannot be compared directly to the resuls
   of [93][faruqui2010] since they use a slighly different setting (incl.
   misc entity).

ner_train

   training script for ner. see ./ner_train --help for further details.

   to train a conditional markov model with a greedy left-to-right
   decoder, the feature templates of [94][rationov2009]_ and extended
   prediction history (see [95][ratinov2009]) use:
./ner_train clner/en/conll03/train.iob2 model_rr09.bz2 -f rr09 -r 0.00001 -e 100
 --shuffle --eph
________________________________________________________________________________
feature extraction

min count:  1
use eph:  true
build_vocabulary took 24.662 sec
feature_extraction took 25.626 sec
creating training examples... build_examples took 42.998 sec
[done]
________________________________________________________________________________
training

num examples: 203621
num features: 553249
num classes: 9
classes:  ['i-loc', 'b-org', 'o', 'b-per', 'i-per', 'i-misc', 'b-misc', 'i-org',
 'b-loc']
reg: 0.00001000
epochs: 100
9 models trained in 239.28 seconds.
train took 282.374 sec

ner_predict

   you can use the prediction script to tag new sentences formatted in
   conll format and write the output to a file or to stdout. you can pipe
   the output directly to conlleval to assess the model performance:
./ner_predict model_rr09.bz2 clner/en/conll03/test.iob2 - | clner/scripts/conlle
val
loading tagger... [done]
use_eph:  true
use_aso:  false
processed input in 11.2883s sec.
processed 46435 tokens with 5648 phrases; found: 5605 phrases; correct: 4799.
accuracy:  96.78%; precision:  85.62%; recall:  84.97%; fb1:  85.29
              loc: precision:  87.29%; recall:  88.91%; fb1:  88.09  1699
             misc: precision:  79.85%; recall:  75.64%; fb1:  77.69  665
              org: precision:  82.90%; recall:  78.81%; fb1:  80.80  1579
              per: precision:  88.81%; recall:  91.28%; fb1:  90.03  1662

references

   [96][1] [97]http://pypi.python.org/pypi/sparsesvd/0.1.4
   [98][2]
   [99]http://www.webis.de/research/corpora/corpus-webis-cls-10/cls-acl10-
   processed.tar.gz
   [100][3] [101]https://github.com/pprett/bolt/tree/feature-mask
   [102][4] for german we use the updated version of conll03 by sven
   hartrumpf.
   [103][prettenhofer2010] prettenhofer, p. and stein, b.,
   [104]cross-language text classification using structural correspondence
   learning. in proceedings of acl '10.
   [105][prettenhofer2011] prettenhofer, p. and stein, b.,
   [106]cross-lingual adaptation using structural correspondence learning.
   acm tist (to appear). [107][preprint]
   [ratinov2009] ([108]1, [109]2, [110]3) ratinov, l. and roth, d.,
   [111]design challenges and misconceptions in id39.
   in proceedings of conll '09.
   [faruqui2010] ([112]1, [113]2, [114]3) faruqui, m. and pad   s.,
   training and evaluating a german named entity recognizer with semantic
   generalization. in proceedings of konvens '10

developer notes

     * if you copy a new version of bolt into the externals directory make
       sure to run cython on the *.pyx files. if you fail to do so you
       will get a pickleerror in multiprocessing.

     *    2019 github, inc.
     * [115]terms
     * [116]privacy
     * [117]security
     * [118]status
     * [119]help

     * [120]contact github
     * [121]pricing
     * [122]api
     * [123]training
     * [124]blog
     * [125]about

   (button) you can   t perform that action at this time.

   you signed in with another tab or window. [126]reload to refresh your
   session. you signed out in another tab or window. [127]reload to
   refresh your session.

   (button)

references

   visible links
   1. https://github.com/opensearch.xml
   2. https://github.com/pprett/nut/commits/master.atom
   3. https://github.com/pprett/nut#start-of-content
   4. https://github.com/features
   5. https://github.com/features/code-review/
   6. https://github.com/features/project-management/
   7. https://github.com/features/integrations
   8. https://github.com/features/actions
   9. https://github.com/features#team-management
  10. https://github.com/features#social-coding
  11. https://github.com/features#documentation
  12. https://github.com/features#code-hosting
  13. https://github.com/customer-stories
  14. https://github.com/security
  15. https://github.com/enterprise
  16. https://github.com/explore
  17. https://github.com/topics
  18. https://github.com/collections
  19. https://github.com/trending
  20. https://lab.github.com/
  21. https://opensource.guide/
  22. https://github.com/events
  23. https://github.community/
  24. https://education.github.com/
  25. https://github.com/marketplace
  26. https://github.com/pricing
  27. https://github.com/pricing#feature-comparison
  28. https://enterprise.github.com/contact
  29. https://github.com/nonprofit
  30. https://education.github.com/
  31. https://github.com/login?return_to=/pprett/nut
  32. https://github.com/join
  33. https://github.com/login?return_to=/pprett/nut
  34. https://github.com/pprett/nut/watchers
  35. https://github.com/login?return_to=/pprett/nut
  36. https://github.com/pprett/nut/stargazers
  37. https://github.com/login?return_to=/pprett/nut
  38. https://github.com/pprett/nut/network/members
  39. https://github.com/pprett
  40. https://github.com/pprett/nut
  41. https://github.com/pprett/nut
  42. https://github.com/pprett/nut/issues
  43. https://github.com/pprett/nut/pulls
  44. https://github.com/pprett/nut/projects
  45. https://github.com/pprett/nut/pulse
  46. https://github.com/join?source=prompt-code
  47. https://github.com/pprett/nut/commits/master
  48. https://github.com/pprett/nut/branches
  49. https://github.com/pprett/nut/releases
  50. https://github.com/pprett/nut/graphs/contributors
  51. https://github.com/pprett/nut/search?l=c
  52. https://github.com/pprett/nut/search?l=python
  53. https://github.com/pprett/nut/find/master
  54. https://github.com/pprett/nut/archive/master.zip
  55. https://github.com/login?return_to=https://github.com/pprett/nut
  56. https://github.com/join?return_to=/pprett/nut
  57. https://desktop.github.com/
  58. https://desktop.github.com/
  59. https://developer.apple.com/xcode/
  60. https://visualstudio.github.com/
  61. https://github.com/pprett/nut/tree/dd654c8ce4e963d4d92dd15c918309ec44de323b
  62. https://github.com/pprett/nut/tree/master/nut
  63. https://github.com/pprett/nut/blob/master/.gitignore
  64. https://github.com/pprett/nut/blob/master/readme.rst
  65. https://github.com/pprett/nut/blob/master/clscl_predict
  66. https://github.com/pprett/nut/blob/master/clscl_train
  67. https://github.com/pprett/nut/blob/master/model_de_v1.bz2
  68. https://github.com/pprett/nut/blob/master/model_en_v1.bz2
  69. https://github.com/pprett/nut/blob/master/ner_aso
  70. https://github.com/pprett/nut/blob/master/ner_demo.py
  71. https://github.com/pprett/nut/blob/master/ner_predict
  72. https://github.com/pprett/nut/blob/master/ner_train
  73. https://github.com/pprett/nut/blob/master/results_conll03.txt
  74. https://github.com/pprett/nut/blob/master/setup.id18
  75. https://github.com/pprett/nut/blob/master/setup.py
  76. https://github.com/pprett/nut#requirements
  77. https://github.com/pprett/nut#installation
  78. https://github.com/pprett/nut#documentation
  79. https://github.com/pprett/nut#clscl
  80. https://github.com/pprett/nut#ner
  81. https://github.com/pprett/nut#references
  82. https://github.com/pprett/nut#f1
  83. https://github.com/pprett/nut#clscl
  84. https://github.com/pprett/nut#prettenhofer2010
  85. https://github.com/pprett/nut#prettenhofer2011
  86. https://github.com/pprett/nut#f2
  87. https://github.com/pprett/nut#f3
  88. https://github.com/pprett/nut#ratinov2009
  89. https://github.com/pprett/nut#f4
  90. https://github.com/pprett/nut#ratinov2009
  91. https://github.com/pprett/nut#faruqui2010
  92. https://github.com/pprett/nut#faruqui2010
  93. https://github.com/pprett/nut#faruqui2010
  94. https://github.com/pprett/nut# 0
  95. https://github.com/pprett/nut#ratinov2009
  96. https://github.com/pprett/nut# 
  97. http://pypi.python.org/pypi/sparsesvd/0.1.4
  98. https://github.com/pprett/nut# 
  99. http://www.webis.de/research/corpora/corpus-webis-cls-10/cls-acl10-processed.tar.gz
 100. https://github.com/pprett/nut# 
 101. https://github.com/pprett/bolt/tree/feature-mask
 102. https://github.com/pprett/nut# 
 103. https://github.com/pprett/nut# 
 104. http://www.aclweb.org/anthology/p/p10/p10-1114.pdf
 105. https://github.com/pprett/nut# 
 106. http://tist.acm.org/papers/tist-2010-06-0137.r1.html
 107. http://arxiv.org/pdf/1008.0716v2
 108. https://github.com/pprett/nut# 
 109. https://github.com/pprett/nut# 
 110. https://github.com/pprett/nut# 
 111. http://www.aclweb.org/anthology/w/w09/w09-1119.pdf
 112. https://github.com/pprett/nut# 
 113. https://github.com/pprett/nut# 
 114. https://github.com/pprett/nut# 
 115. https://github.com/site/terms
 116. https://github.com/site/privacy
 117. https://github.com/security
 118. https://githubstatus.com/
 119. https://help.github.com/
 120. https://github.com/contact
 121. https://github.com/pricing
 122. https://developer.github.com/
 123. https://training.github.com/
 124. https://github.blog/
 125. https://github.com/about
 126. https://github.com/pprett/nut
 127. https://github.com/pprett/nut

   hidden links:
 129. https://github.com/
 130. https://github.com/pprett/nut
 131. https://github.com/pprett/nut
 132. https://github.com/pprett/nut
 133. https://help.github.com/articles/which-remote-url-should-i-use
 134. https://github.com/pprett/nut#natural-language-understanding-toolkit
 135. https://github.com/pprett/nut#toc
 136. https://github.com/pprett/nut#requirements
 137. https://github.com/pprett/nut#installation
 138. https://github.com/pprett/nut#documentation
 139. https://github.com/pprett/nut#clscl
 140. https://github.com/pprett/nut#clscl_train
 141. https://github.com/pprett/nut#clscl_predict
 142. https://github.com/pprett/nut#named-entity-recognition
 143. https://github.com/pprett/nut#pre-trained-models
 144. https://github.com/pprett/nut#ner_train
 145. https://github.com/pprett/nut#ner_predict
 146. https://github.com/pprett/nut#references
 147. https://github.com/pprett/nut#developer-notes
 148. https://github.com/
