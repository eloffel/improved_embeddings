   #[1]github [2]recent commits to jieba:master

   [3]skip to content

   (button)

     * why github?
       [4]features    
          + [5]code review
          + [6]project management
          + [7]integrations
          + [8]actions
          + [9]team management
          + [10]social coding
          + [11]documentation
          + [12]code hosting
          + [13]customer stories    
          + [14]security    
     * [15]enterprise
     * explore
          + [16]explore github    

learn & contribute
          + [17]topics
          + [18]collections
          + [19]trending
          + [20]learning lab
          + [21]open source guides

connect with others
          + [22]events
          + [23]community forum
          + [24]github education
     * [25]marketplace
     * pricing
       [26]plans    
          + [27]compare plans
          + [28]contact sales
          + [29]nonprofit    
          + [30]education    

   ____________________
     * in this repository all github    
       jump to    

     * no suggested jump to results

     * in this repository all github    
       jump to    
     * in this repository all github    
       jump to    

   [31]sign in [32]sign up

     * [33]watch [34]1,240
     * [35]star [36]17,944
     * [37]fork [38]4,729

[39]fxsjy/[40]jieba

   [41]code [42]issues 430 [43]pull requests 33 [44]projects 0 [45]wiki
   [46]insights
   (button) dismiss

join github today

   github is home to over 31 million developers working together to host
   and review code, manage projects, and build software together.
   [47]sign up
                     
     * [48]498 commits
     * [49]2 branches
     * [50]24 releases
     * [51]fetching contributors
     * [52]mit

    1. [53]python 51.9%
    2. [54]openedge abl 48.1%

   (button) python openedge abl
   branch: master (button) new pull request
   [55]find file
   clone or download

clone with https

   use git or checkout with svn using the web url.
   https://github.com/f
   [56]download zip

downloading...

   want to be notified of new releases in fxsjy/jieba?
   [57]sign in [58]sign up

launching github desktop...

   if nothing happens, [59]download github desktop and try again.

   (button) go back

launching github desktop...

   if nothing happens, [60]download github desktop and try again.

   (button) go back

launching xcode...

   if nothing happens, [61]download xcode and try again.

   (button) go back

launching visual studio...

   if nothing happens, [62]download the github extension for visual studio
   and try again.

   (button) go back
   [63]@fxsjy
   [64]fxsjy [65]update readme.md
   latest commit [66]8212b6c dec 3, 2018
   [67]permalink
   type name latest commit message commit time
   failed to load latest commit information.
   [68]extra_dict
   [69]jieba [70]merge pull request [71]#582 [72]from
   hosiet/pr-fix-typo-codespell sep 20, 2018
   [73]test [74]fix the error about imoprting chineseanalyzer sep 15, 2018
   [75].gitattributes
   [76].gitignore
   [77]changelog [78]version change 0.39 aug 28, 2017
   [79]license
   [80]manifest.in [81]include changelog & readme.md in the distribution
   package jul 29, 2013
   [82]readme.md
   [83]setup.py [84]fix typos found by codespell jan 21, 2018

readme.md

jieba

                                           python                   

   "jieba" (chinese for "to stutter") chinese text segmentation: built to
   be the best python chinese id40 module.
     * scroll down for english documentation.

      

     *                            
          +                                                                         
          +                                                                      ,                                              
          +                                                                                                                               
     *                   
     *                      
     * mit             

            

     * [85]https://github.com/baidu/lac                                  +      +               
     * [86]https://github.com/baidu/anyq       faq                  
     * [87]https://github.com/baidu/senta                         

            

             python 2/3          
     *                   easy_install jieba        pip install jieba / pip3 install jieba
     *                             [88]http://pypi.python.org/pypi/jieba/                    python
       setup.py install
     *                    jieba                                   site-packages       
     *        import jieba          

      

     *                                                                                                                          (dag)
     *                                              ,                                        
     *                                                           id48                    viterbi       

            

    1.       
     __________________________________________________________________

     * jieba.cut                               :                            cut_all                                           id48                               
       id48       
     * jieba.cut_for_search                                                                    id48
                                                                                              
     *                                unicode     utf-8             gbk                                            gbk
                                                        utf-8
     * jieba.cut        jieba.cut_for_search                                         generator                for
                                                       (unicode)            
     * jieba.lcut        jieba.lcut_for_search              list
     * jieba.tokenizer(dictionary=default_dict)
                                                                      jieba.dt                                                                                  

               
# encoding=utf-8
import jieba

seg_list = jieba.cut("                           ", cut_all=true)
print("full mode: " + "/ ".join(seg_list))  #          

seg_list = jieba.cut("                           ", cut_all=false)
print("default mode: " + "/ ".join(seg_list))  #             

seg_list = jieba.cut("                              ")  #                      
print(", ".join(seg_list))

seg_list = jieba.cut_for_search("                                                                              ")  #                   
print(", ".join(seg_list))

         :
               :    /       /       /       /             /       /       

                  :    /       /       /             

                        ,       ,    ,       ,       ,           (                                                         viterbi                     )

                                  ,       ,       ,    ,       ,       ,       ,          ,                ,       ,          ,    ,    ,       ,       ,       ,       
            ,       

    2.                      
     __________________________________________________________________

            

     *                                                              jieba                                jieba
                                                                                     
     *           jieba.load_userdict(file_name) # file_name                                              
     *                 dict.txt
                                                                                                                                                             file_name
                                                                          utf-8          
     *                                                                      

            
          3 i
          5
          nz
      

     *                             jieba.dt       tmp_dir     cache_file
                                                                                                             
     *          
          +                   [89]https://github.com/fxsjy/jieba/blob/master/test/user
            dict.txt
          +                [90]https://github.com/fxsjy/jieba/blob/master/test/test_
            userdict.py
               o                     /     /        /     /        /     /     /     /        /        /     /       
                 /
               o                                         /     /           /        /     /     /           /        /     /       
                 /

            

     *        add_word(word, freq=none, tag=none)     del_word(word)
                                           
     *        suggest_freq(segment, tune=true)                                                                         
     *                                         id48                                     

                  
>>> print('/'.join(jieba.cut('            post               ', id48=false)))
      /      /post/      /      /   
>>> jieba.suggest_freq(('   ', '   '), true)
494
>>> print('/'.join(jieba.cut('            post               ', id48=false)))
      /      /post/   /   /      /   
>>> print('/'.join(jieba.cut('                                       ', id48=false)))
   /   /   /   /      /      /      /   /      
>>> jieba.suggest_freq('      ', true)
69
>>> print('/'.join(jieba.cut('                                       ', id48=false)))
   /      /   /      /      /      /   /      

     * "                                                      " ---
       [91]https://github.com/fxsjy/jieba/issues/14

    3.                
     __________________________________________________________________

       tf-idf                         

   import jieba.analyse
     * jieba.analyse.extract_tags(sentence, topk=20, withweight=false,
       allowpos=())
          + sentence                      
          + topk                 tf/idf                                         20
          + withweight                                                        false
          + allowpos                                                             
     * jieba.analyse.tfidf(idf_path=none)        tfidf          idf_path     idf             

                                     

   [92]https://github.com/fxsjy/jieba/blob/master/test/extract_tags.py

                                                idf                                                            
     *           jieba.analyse.set_idf_path(file_name) # file_name                              
     *                            [93]https://github.com/fxsjy/jieba/blob/master/extra_dict/
       idf.txt.big
     *                [94]https://github.com/fxsjy/jieba/blob/master/test/extract_ta
       gs_idfpath.py

                                       stop words                                                            
     *           jieba.analyse.set_stop_words(file_name) # file_name                              
     *                            [95]https://github.com/fxsjy/jieba/blob/master/extra_dict/
       stop_words.txt
     *                [96]https://github.com/fxsjy/jieba/blob/master/test/extract_ta
       gs_stop_words.py

                                                
     *                [97]https://github.com/fxsjy/jieba/blob/master/test/extract_ta
       gs_with_weight.py

       textrank                         

     * jieba.analyse.textrank(sentence, topk=20, withweight=false,
       allowpos=('ns', 'n', 'vn', 'v'))                                                          
     * jieba.analyse.textrank()                 textrank       

                   [98]textrank: bringing order into texts

            :

    1.                                           
    2.                      (         5         span            )                                       
    3.                      id95                           

            :

       [99]test/demo.py
    4.             
     __________________________________________________________________

     * jieba.posseg.postokenizer(tokenizer=none)                            tokenizer
                                      jieba.tokenizer             jieba.posseg.dt                                  
     *                                                     ictclas                      
     *             

>>> import jieba.posseg as pseg
>>> words = pseg.cut("                     ")
>>> for word, flag in words:
...    print('%s %s' % (word, flag))
...
    r
    v
       ns
          ns

    5.             
     __________________________________________________________________

     *                                                                          python                                                                                  
     *        python           multiprocessing                             windows
     *          
          + jieba.enable_parallel(4) #                                                    
          + jieba.disable_parallel() #                         
     *          [100]https://github.com/fxsjy/jieba/blob/master/test/parallel/te
       st_file.py
     *                    4     3.4ghz linux                                                           1mb/s                                3.3       
     *                                               jieba.dt     jieba.posseg.dt   

    6. tokenize                                       
     __________________________________________________________________

     *                                unicode
     *             

result = jieba.tokenize(u'                              ')
for tk in result:
    print("word %s\t\t start: %d \t\t end:%d" % (tk[0],tk[1],tk[2]))

word                       start: 0                end:2
word                       start: 2                end:4
word                       start: 4                end:6
word                         start: 6                end:10


     *             

result = jieba.tokenize(u'                              ', mode='search')
for tk in result:
    print("word %s\t\t start: %d \t\t end:%d" % (tk[0],tk[1],tk[2]))

word                       start: 0                end:2
word                       start: 2                end:4
word                       start: 4                end:6
word                       start: 6                end:8
word                       start: 8                end:10
word                         start: 6                end:10

    7. chineseanalyzer for whoosh             
     __________________________________________________________________

     *           from jieba.analyse import chineseanalyzer
     *                [101]https://github.com/fxsjy/jieba/blob/master/test/test_whoo
       sh.py

    8.                
     __________________________________________________________________

                  python -m jieba news.txt > cut_result.txt

                                 
      : python -m jieba [options] filename

                        

            :
  filename                          

            :
  -h, --help                                          
  -d [delim], --delimiter [delim]
                               delim                                     ' / '   
                                     delim                                 
  -p [delim], --pos [delim]
                                                          delim                        
                                                 _       
  -d dict, --dict dict         dict                   
  -u user_dict, --user-dict user_dict
                               user_dict                                                                   
  -a, --cut-all                                                   
  -n, --no-id48                                           
  -q, --quiet                                    stderr
  -v, --version                                    

                                                      

   --help                
$> python -m jieba --help
jieba command line interface.

positional arguments:
  filename              input file

optional arguments:
  -h, --help            show this help message and exit
  -d [delim], --delimiter [delim]
                        use delim instead of ' / ' for word delimiter; or a
                        space if it is used without delim
  -p [delim], --pos [delim]
                        enable id52; if delim is specified, use delim
                        instead of '_' for pos delimiter
  -d dict, --dict dict  use dict as dictionary
  -u user_dict, --user-dict user_dict
                        use user_dict together with the default dictionary or
                        dict (if specified)
  -a, --cut-all         full pattern cutting (ignored with id52)
  -n, --no-id48          don't use the hidden markov model
  -q, --quiet           don't print loading messages to stderr
  -v, --version         show program's version number and exit

if no filename specified, use stdin instead.

                  

   jieba                      import jieba     jieba.tokenizer()
                                                                                                                         jieba                              
import jieba
jieba.initialize()  #                            

       0.28                                                                                                                      :
jieba.set_dictionary('data/dict.txt.big')

            
   [102]https://github.com/fxsjy/jieba/blob/master/test/test_change_dictpa
   th.py

            

    1.                                  
       [103]https://github.com/fxsjy/jieba/raw/master/extra_dict/dict.txt.
       small
    2.                                        
       [104]https://github.com/fxsjy/jieba/raw/master/extra_dict/dict.txt.
       big

                                              jieba/dict.txt                   
   jieba.set_dictionary('data/dict.txt.big')

                  

             java       

            piaolingxue          [105]https://github.com/huaban/jieba-analysis

             c++       

            yanyiwu          [106]https://github.com/yanyiwu/cppjieba

             node.js       

            yanyiwu          [107]https://github.com/yanyiwu/nodejieba

             erlang       

            falood          [108]https://github.com/falood/exjieba

             r       

            qinwf          [109]https://github.com/qinwf/jiebar

             ios       

            yanyiwu          [110]https://github.com/yanyiwu/iosjieba

             php       

            fukuball          [111]https://github.com/fukuball/jieba-php

             .net(c#)       

            anderscui          [112]https://github.com/anderscui/jieba.net/

             go       

     *       : wangbin       : [113]https://github.com/wangbin/jiebago
     *       : yanyiwu       : [114]https://github.com/yanyiwu/gojieba

            android      

     *        dongliang.w          [115]https://github.com/452896915/jieba-android

            

    1. solr: [116]https://github.com/sing1ee/jieba-solr

            

     * 1.5 mb / second in full mode
     * 400 kb / second in default mode
     *             : intel(r) core(tm) i7-2600 cpu @ 3.4ghz               .txt

            

1.                                     

             [117]https://github.com/fxsjy/jieba/issues/7

2.                                                                    

   p(      )     p(   )  p(   )                                                      

                                    

   jieba.add_word('      ')        jieba.suggest_freq('      ', true)

3.                                                                                              

                                    

   jieba.suggest_freq(('      ', '      '), true)

                            jieba.del_word('            ')

4.                                                       

                                    

   jieba.cut('               ', id48=false) jieba.cut('                           ', id48=false)

                           [118]https://github.com/fxsjy/jieba/issues?sort=updated&state=c
   losed

            

   [119]https://github.com/fxsjy/jieba/blob/master/changelog
     __________________________________________________________________

jieba

   "jieba" (chinese for "to stutter") chinese text segmentation: built to
   be the best python chinese id40 module.

features

     * support three types of segmentation mode:

    1. accurate mode attempts to cut the sentence into the most accurate
       segmentations, which is suitable for text analysis.
    2. full mode gets all the possible words from the sentence. fast but
       not accurate.
    3. search engine mode, based on the accurate mode, attempts to cut
       long words into several short words, which can raise the recall
       rate. suitable for search engines.

     * supports traditional chinese
     * supports customized dictionaries
     * mit license

online demo

   [120]http://jiebademo.ap01.aws.af.cm/

   (powered by appfog)

usage

     * fully automatic installation: easy_install jieba or pip install
       jieba
     * semi-automatic installation: download
       [121]http://pypi.python.org/pypi/jieba/ , run python setup.py
       install after extracting.
     * manual installation: place the jieba directory in the current
       directory or python site-packages directory.
     * import jieba.

algorithm

     * based on a prefix dictionary structure to achieve efficient word
       graph scanning. build a directed acyclic graph (dag) for all
       possible word combinations.
     * use id145 to find the most probable combination based
       on the word frequency.
     * for unknown words, a id48-based model is used with the viterbi
       algorithm.

main functions

    1. cut
     __________________________________________________________________

     * the jieba.cut function accepts three input parameters: the first
       parameter is the string to be cut; the second parameter is cut_all,
       controlling the cut mode; the third parameter is to control whether
       to use the hidden markov model.
     * jieba.cut_for_search accepts two parameter: the string to be cut;
       whether to use the hidden markov model. this will cut the sentence
       into short words suitable for search engines.
     * the input string can be an unicode/str object, or a str/bytes
       object which is encoded in utf-8 or gbk. note that using gbk
       encoding is not recommended because it may be unexpectly decoded as
       utf-8.
     * jieba.cut and jieba.cut_for_search returns an generator, from which
       you can use a for loop to get the segmentation result (in unicode).
     * jieba.lcut and jieba.lcut_for_search returns a list.
     * jieba.tokenizer(dictionary=default_dict) creates a new customized
       tokenizer, which enables you to use different dictionaries at the
       same time. jieba.dt is the default tokenizer, to which almost all
       global functions are mapped.

   code example: segmentation
#encoding=utf-8
import jieba

seg_list = jieba.cut("                           ", cut_all=true)
print("full mode: " + "/ ".join(seg_list))  #          

seg_list = jieba.cut("                           ", cut_all=false)
print("default mode: " + "/ ".join(seg_list))  #             

seg_list = jieba.cut("                              ")
print(", ".join(seg_list))

seg_list = jieba.cut_for_search("                                                                              ")  #                   
print(", ".join(seg_list))

   output:
[full mode]:    /       /       /       /             /       /       

[accurate mode]:    /       /       /             

[unknown words recognize]    ,       ,    ,       ,       ,           (in this case, "      " is not in
the dictionary, but is identified by the viterbi algorithm)

[search engine mode]          ,       ,       ,    ,       ,       ,       ,          ,                ,       ,          ,    ,    ,       ,
      ,       ,                   ,       

    2. add a custom dictionary
     __________________________________________________________________

load dictionary

     * developers can specify their own custom dictionary to be included
       in the jieba default dictionary. jieba is able to identify new
       words, but you can add your own new words can ensure a higher
       accuracy.
     * usage    jieba.load_userdict(file_name) # file_name is a file-like
       object or the path of the custom dictionary
     * the dictionary format is the same as that of dict.txt: one word per
       line; each line is divided into three parts separated by a space:
       word, word frequency, pos tag. if file_name is a path or a file
       opened in binary mode, the dictionary must be utf-8 encoded.
     * the word frequency and pos tag can be omitted respectively. the
       word frequency will be filled with a suitable value if omitted.

   for example:
          3 i
          5
          nz
      

     * change a tokenizer's tmp_dir and cache_file to specify the path of
       the cache file, for using on a restricted file system.
     * example:
            5
            2
            3

  [before]              /     /        /     /        /     /     /     /        /        /     /        /

  [after]                /     /           /        /     /     /           /        /     /        /

modify dictionary

     * use add_word(word, freq=none, tag=none) and del_word(word) to
       modify the dictionary dynamically in programs.
     * use suggest_freq(segment, tune=true) to adjust the frequency of a
       single word so that it can (or cannot) be segmented.
     * note that id48 may affect the final result.

   example:
>>> print('/'.join(jieba.cut('            post               ', id48=false)))
      /      /post/      /      /   
>>> jieba.suggest_freq(('   ', '   '), true)
494
>>> print('/'.join(jieba.cut('            post               ', id48=false)))
      /      /post/   /   /      /   
>>> print('/'.join(jieba.cut('                                       ', id48=false)))
   /   /   /   /      /      /      /   /      
>>> jieba.suggest_freq('      ', true)
69
>>> print('/'.join(jieba.cut('                                       ', id48=false)))
   /      /   /      /      /      /   /      

    3. keyword extraction
     __________________________________________________________________

   import jieba.analyse
     * jieba.analyse.extract_tags(sentence, topk=20, withweight=false,
       allowpos=())
          + sentence: the text to be extracted
          + topk: return how many keywords with the highest tf/idf
            weights. the default value is 20
          + withweight: whether return tf/idf weights with the keywords.
            the default value is false
          + allowpos: filter words with which poss are included. empty for
            no filtering.
     * jieba.analyse.tfidf(idf_path=none) creates a new tfidf instance,
       idf_path specifies idf file path.

   example (keyword extraction)

   [122]https://github.com/fxsjy/jieba/blob/master/test/extract_tags.py

   developers can specify their own custom idf corpus in jieba keyword
   extraction
     * usage    jieba.analyse.set_idf_path(file_name) # file_name is the
       path for the custom corpus
     * custom corpus
       sample   [123]https://github.com/fxsjy/jieba/blob/master/extra_dict/i
       df.txt.big
     * sample
       code   [124]https://github.com/fxsjy/jieba/blob/master/test/extract_t
       ags_idfpath.py

   developers can specify their own custom stop words corpus in jieba
   keyword extraction
     * usage    jieba.analyse.set_stop_words(file_name) # file_name is the
       path for the custom corpus
     * custom corpus
       sample   [125]https://github.com/fxsjy/jieba/blob/master/extra_dict/s
       top_words.txt
     * sample
       code   [126]https://github.com/fxsjy/jieba/blob/master/test/extract_t
       ags_stop_words.py

   there's also a [127]textrank implementation available.

   use: jieba.analyse.textrank(sentence, topk=20, withweight=false,
   allowpos=('ns', 'n', 'vn', 'v'))

   note that it filters pos by default.

   jieba.analyse.textrank() creates a new textrank instance.
    4. id52
     __________________________________________________________________

     * jieba.posseg.postokenizer(tokenizer=none) creates a new customized
       tokenizer. tokenizer specifies the jieba.tokenizer to internally
       use. jieba.posseg.dt is the default postokenizer.
     * tags the pos of each word after segmentation, using labels
       compatible with ictclas.
     * example:

>>> import jieba.posseg as pseg
>>> words = pseg.cut("                     ")
>>> for w in words:
...    print('%s %s' % (w.word, w.flag))
...
    r
    v
       ns
          ns

    5. parallel processing
     __________________________________________________________________

     * principle: split target text by line, assign the lines into
       multiple python processes, and then merge the results, which is
       considerably faster.
     * based on the multiprocessing module of python.
     * usage:
          + jieba.enable_parallel(4) # enable parallel processing. the
            parameter is the number of processes.
          + jieba.disable_parallel() # disable parallel processing.
     * example:
       [128]https://github.com/fxsjy/jieba/blob/master/test/parallel/test_
       file.py
     * result: on a four-core 3.4ghz linux machine, do accurate word
       segmentation on complete works of jin yong, and the speed reaches
       1mb/s, which is 3.3 times faster than the single-process version.
     * note that parallel processing supports only default tokenizers,
       jieba.dt and jieba.posseg.dt.

    6. tokenize: return words with position
     __________________________________________________________________

     * the input must be unicode
     * default mode

result = jieba.tokenize(u'                              ')
for tk in result:
    print("word %s\t\t start: %d \t\t end:%d" % (tk[0],tk[1],tk[2]))

word                       start: 0                end:2
word                       start: 2                end:4
word                       start: 4                end:6
word                         start: 6                end:10


     * search mode

result = jieba.tokenize(u'                              ',mode='search')
for tk in result:
    print("word %s\t\t start: %d \t\t end:%d" % (tk[0],tk[1],tk[2]))

word                       start: 0                end:2
word                       start: 2                end:4
word                       start: 4                end:6
word                       start: 6                end:8
word                       start: 8                end:10
word                         start: 6                end:10

    7. chineseanalyzer for whoosh
     __________________________________________________________________

     * from jieba.analyse import chineseanalyzer
     * example:
       [129]https://github.com/fxsjy/jieba/blob/master/test/test_whoosh.py

    8. command line interface
     __________________________________________________________________

$> python -m jieba --help
jieba command line interface.

positional arguments:
  filename              input file

optional arguments:
  -h, --help            show this help message and exit
  -d [delim], --delimiter [delim]
                        use delim instead of ' / ' for word delimiter; or a
                        space if it is used without delim
  -p [delim], --pos [delim]
                        enable id52; if delim is specified, use delim
                        instead of '_' for pos delimiter
  -d dict, --dict dict  use dict as dictionary
  -u user_dict, --user-dict user_dict
                        use user_dict together with the default dictionary or
                        dict (if specified)
  -a, --cut-all         full pattern cutting (ignored with id52)
  -n, --no-id48          don't use the hidden markov model
  -q, --quiet           don't print loading messages to stderr
  -v, --version         show program's version number and exit

if no filename specified, use stdin instead.

initialization

   by default, jieba don't build the prefix dictionary unless it's
   necessary. this takes 1-3 seconds, after which it is not initialized
   again. if you want to initialize jieba manually, you can call:
import jieba
jieba.initialize()  # (optional)

   you can also specify the dictionary (not supported before version 0.28)
   :
jieba.set_dictionary('data/dict.txt.big')

using other dictionaries

   it is possible to use your own dictionary with jieba, and there are
   also two dictionaries ready for download:
    1. a smaller dictionary for a smaller memory footprint:
       [130]https://github.com/fxsjy/jieba/raw/master/extra_dict/dict.txt.
       small
    2. there is also a bigger dictionary that has better support for
       traditional chinese (      ):
       [131]https://github.com/fxsjy/jieba/raw/master/extra_dict/dict.txt.
       big

   by default, an in-between dictionary is used, called dict.txt and
   included in the distribution.

   in either case, download the file you want, and then call
   jieba.set_dictionary('data/dict.txt.big') or just replace the existing
   dict.txt.

segmentation speed

     * 1.5 mb / second in full mode
     * 400 kb / second in default mode
     * test env: intel(r) core(tm) i7-2600 cpu @ 3.4ghz               .txt

     *    2019 github, inc.
     * [132]terms
     * [133]privacy
     * [134]security
     * [135]status
     * [136]help

     * [137]contact github
     * [138]pricing
     * [139]api
     * [140]training
     * [141]blog
     * [142]about

   (button) you can   t perform that action at this time.

   you signed in with another tab or window. [143]reload to refresh your
   session. you signed out in another tab or window. [144]reload to
   refresh your session.

   (button)

references

   visible links
   1. https://github.com/opensearch.xml
   2. https://github.com/fxsjy/jieba/commits/master.atom
   3. https://github.com/fxsjy/jieba#start-of-content
   4. https://github.com/features
   5. https://github.com/features/code-review/
   6. https://github.com/features/project-management/
   7. https://github.com/features/integrations
   8. https://github.com/features/actions
   9. https://github.com/features#team-management
  10. https://github.com/features#social-coding
  11. https://github.com/features#documentation
  12. https://github.com/features#code-hosting
  13. https://github.com/customer-stories
  14. https://github.com/security
  15. https://github.com/enterprise
  16. https://github.com/explore
  17. https://github.com/topics
  18. https://github.com/collections
  19. https://github.com/trending
  20. https://lab.github.com/
  21. https://opensource.guide/
  22. https://github.com/events
  23. https://github.community/
  24. https://education.github.com/
  25. https://github.com/marketplace
  26. https://github.com/pricing
  27. https://github.com/pricing#feature-comparison
  28. https://enterprise.github.com/contact
  29. https://github.com/nonprofit
  30. https://education.github.com/
  31. https://github.com/login?return_to=/fxsjy/jieba
  32. https://github.com/join
  33. https://github.com/login?return_to=/fxsjy/jieba
  34. https://github.com/fxsjy/jieba/watchers
  35. https://github.com/login?return_to=/fxsjy/jieba
  36. https://github.com/fxsjy/jieba/stargazers
  37. https://github.com/login?return_to=/fxsjy/jieba
  38. https://github.com/fxsjy/jieba/network/members
  39. https://github.com/fxsjy
  40. https://github.com/fxsjy/jieba
  41. https://github.com/fxsjy/jieba
  42. https://github.com/fxsjy/jieba/issues
  43. https://github.com/fxsjy/jieba/pulls
  44. https://github.com/fxsjy/jieba/projects
  45. https://github.com/fxsjy/jieba/wiki
  46. https://github.com/fxsjy/jieba/pulse
  47. https://github.com/join?source=prompt-code
  48. https://github.com/fxsjy/jieba/commits/master
  49. https://github.com/fxsjy/jieba/branches
  50. https://github.com/fxsjy/jieba/releases
  51. https://github.com/fxsjy/jieba/graphs/contributors
  52. https://github.com/fxsjy/jieba/blob/master/license
  53. https://github.com/fxsjy/jieba/search?l=python
  54. https://github.com/fxsjy/jieba/search?l=openedge-abl
  55. https://github.com/fxsjy/jieba/find/master
  56. https://github.com/fxsjy/jieba/archive/master.zip
  57. https://github.com/login?return_to=https://github.com/fxsjy/jieba
  58. https://github.com/join?return_to=/fxsjy/jieba
  59. https://desktop.github.com/
  60. https://desktop.github.com/
  61. https://developer.apple.com/xcode/
  62. https://visualstudio.github.com/
  63. https://github.com/fxsjy
  64. https://github.com/fxsjy/jieba/commits?author=fxsjy
  65. https://github.com/fxsjy/jieba/commit/8212b6c5725d08311952a3a08e5509eeaee33eb7
  66. https://github.com/fxsjy/jieba/commit/8212b6c5725d08311952a3a08e5509eeaee33eb7
  67. https://github.com/fxsjy/jieba/tree/8212b6c5725d08311952a3a08e5509eeaee33eb7
  68. https://github.com/fxsjy/jieba/tree/master/extra_dict
  69. https://github.com/fxsjy/jieba/tree/master/jieba
  70. https://github.com/fxsjy/jieba/commit/843cdc2b7cc9d5a0f76aa615eb0f24c97bf73b73
  71. https://github.com/fxsjy/jieba/pull/582
  72. https://github.com/fxsjy/jieba/commit/843cdc2b7cc9d5a0f76aa615eb0f24c97bf73b73
  73. https://github.com/fxsjy/jieba/tree/master/test
  74. https://github.com/fxsjy/jieba/commit/ca444fb4da7ffa5a83919656a28b495bd3eeace0
  75. https://github.com/fxsjy/jieba/blob/master/.gitattributes
  76. https://github.com/fxsjy/jieba/blob/master/.gitignore
  77. https://github.com/fxsjy/jieba/blob/master/changelog
  78. https://github.com/fxsjy/jieba/commit/cb0de2973b2fafaa67a0245a14206d8be70db515
  79. https://github.com/fxsjy/jieba/blob/master/license
  80. https://github.com/fxsjy/jieba/blob/master/manifest.in
  81. https://github.com/fxsjy/jieba/commit/3667a4ab01901119e69c98a05d2a9085a82a7fb6
  82. https://github.com/fxsjy/jieba/blob/master/readme.md
  83. https://github.com/fxsjy/jieba/blob/master/setup.py
  84. https://github.com/fxsjy/jieba/commit/17ef8abba38552e5b0a78de33765095c149b8c4d
  85. https://github.com/baidu/lac
  86. https://github.com/baidu/anyq
  87. https://github.com/baidu/senta
  88. http://pypi.python.org/pypi/jieba/
  89. https://github.com/fxsjy/jieba/blob/master/test/userdict.txt
  90. https://github.com/fxsjy/jieba/blob/master/test/test_userdict.py
  91. https://github.com/fxsjy/jieba/issues/14
  92. https://github.com/fxsjy/jieba/blob/master/test/extract_tags.py
  93. https://github.com/fxsjy/jieba/blob/master/extra_dict/idf.txt.big
  94. https://github.com/fxsjy/jieba/blob/master/test/extract_tags_idfpath.py
  95. https://github.com/fxsjy/jieba/blob/master/extra_dict/stop_words.txt
  96. https://github.com/fxsjy/jieba/blob/master/test/extract_tags_stop_words.py
  97. https://github.com/fxsjy/jieba/blob/master/test/extract_tags_with_weight.py
  98. http://web.eecs.umich.edu/~mihalcea/papers/mihalcea.emnlp04.pdf
  99. https://github.com/fxsjy/jieba/blob/master/test/demo.py
 100. https://github.com/fxsjy/jieba/blob/master/test/parallel/test_file.py
 101. https://github.com/fxsjy/jieba/blob/master/test/test_whoosh.py
 102. https://github.com/fxsjy/jieba/blob/master/test/test_change_dictpath.py
 103. https://github.com/fxsjy/jieba/raw/master/extra_dict/dict.txt.small
 104. https://github.com/fxsjy/jieba/raw/master/extra_dict/dict.txt.big
 105. https://github.com/huaban/jieba-analysis
 106. https://github.com/yanyiwu/cppjieba
 107. https://github.com/yanyiwu/nodejieba
 108. https://github.com/falood/exjieba
 109. https://github.com/qinwf/jiebar
 110. https://github.com/yanyiwu/iosjieba
 111. https://github.com/fukuball/jieba-php
 112. https://github.com/anderscui/jieba.net/
 113. https://github.com/wangbin/jiebago
 114. https://github.com/yanyiwu/gojieba
 115. https://github.com/452896915/jieba-android
 116. https://github.com/sing1ee/jieba-solr
 117. https://github.com/fxsjy/jieba/issues/7
 118. https://github.com/fxsjy/jieba/issues?sort=updated&state=closed
 119. https://github.com/fxsjy/jieba/blob/master/changelog
 120. http://jiebademo.ap01.aws.af.cm/
 121. http://pypi.python.org/pypi/jieba/
 122. https://github.com/fxsjy/jieba/blob/master/test/extract_tags.py
 123. https://github.com/fxsjy/jieba/blob/master/extra_dict/idf.txt.big
 124. https://github.com/fxsjy/jieba/blob/master/test/extract_tags_idfpath.py
 125. https://github.com/fxsjy/jieba/blob/master/extra_dict/stop_words.txt
 126. https://github.com/fxsjy/jieba/blob/master/test/extract_tags_stop_words.py
 127. http://web.eecs.umich.edu/~mihalcea/papers/mihalcea.emnlp04.pdf
 128. https://github.com/fxsjy/jieba/blob/master/test/parallel/test_file.py
 129. https://github.com/fxsjy/jieba/blob/master/test/test_whoosh.py
 130. https://github.com/fxsjy/jieba/raw/master/extra_dict/dict.txt.small
 131. https://github.com/fxsjy/jieba/raw/master/extra_dict/dict.txt.big
 132. https://github.com/site/terms
 133. https://github.com/site/privacy
 134. https://github.com/security
 135. https://githubstatus.com/
 136. https://help.github.com/
 137. https://github.com/contact
 138. https://github.com/pricing
 139. https://developer.github.com/
 140. https://training.github.com/
 141. https://github.blog/
 142. https://github.com/about
 143. https://github.com/fxsjy/jieba
 144. https://github.com/fxsjy/jieba

   hidden links:
 146. https://github.com/
 147. https://github.com/fxsjy/jieba
 148. https://github.com/fxsjy/jieba
 149. https://github.com/fxsjy/jieba
 150. https://help.github.com/articles/which-remote-url-should-i-use
 151. https://github.com/fxsjy/jieba#jieba
 152. https://github.com/fxsjy/jieba#%e7%89%b9%e7%82%b9
 153. https://github.com/fxsjy/jieba#%e5%8f%8b%e6%83%85%e9%93%be%e6%8e%a5
 154. https://github.com/fxsjy/jieba#%e5%ae%89%e8%a3%85%e8%af%b4%e6%98%8e
 155. https://github.com/fxsjy/jieba#%e7%ae%97%e6%b3%95
 156. https://github.com/fxsjy/jieba#%e4%b8%bb%e8%a6%81%e5%8a%9f%e8%83%bd
 157. https://github.com/fxsjy/jieba#%e8%bd%bd%e5%85%a5%e8%af%8d%e5%85%b8
 158. https://github.com/fxsjy/jieba#%e8%b0%83%e6%95%b4%e8%af%8d%e5%85%b8
 159. https://github.com/fxsjy/jieba#%e5%9f%ba%e4%ba%8e-tf-idf-%e7%ae%97%e6%b3%95%e7%9a%84%e5%85%b3%e9%94%ae%e8%af%8d%e6%8a%bd%e5%8f%96
 160. https://github.com/fxsjy/jieba#%e5%9f%ba%e4%ba%8e-textrank-%e7%ae%97%e6%b3%95%e7%9a%84%e5%85%b3%e9%94%ae%e8%af%8d%e6%8a%bd%e5%8f%96
 161. https://github.com/fxsjy/jieba#%e5%9f%ba%e6%9c%ac%e6%80%9d%e6%83%b3
 162. https://github.com/fxsjy/jieba#%e4%bd%bf%e7%94%a8%e7%a4%ba%e4%be%8b
 163. https://github.com/fxsjy/jieba#%e5%bb%b6%e8%bf%9f%e5%8a%a0%e8%bd%bd%e6%9c%ba%e5%88%b6
 164. https://github.com/fxsjy/jieba#%e5%85%b6%e4%bb%96%e8%af%8d%e5%85%b8
 165. https://github.com/fxsjy/jieba#%e5%85%b6%e4%bb%96%e8%af%ad%e8%a8%80%e5%ae%9e%e7%8e%b0
 166. https://github.com/fxsjy/jieba#%e7%bb%93%e5%b7%b4%e5%88%86%e8%af%8d-java-%e7%89%88%e6%9c%ac
 167. https://github.com/fxsjy/jieba#%e7%bb%93%e5%b7%b4%e5%88%86%e8%af%8d-c-%e7%89%88%e6%9c%ac
 168. https://github.com/fxsjy/jieba#%e7%bb%93%e5%b7%b4%e5%88%86%e8%af%8d-nodejs-%e7%89%88%e6%9c%ac
 169. https://github.com/fxsjy/jieba#%e7%bb%93%e5%b7%b4%e5%88%86%e8%af%8d-erlang-%e7%89%88%e6%9c%ac
 170. https://github.com/fxsjy/jieba#%e7%bb%93%e5%b7%b4%e5%88%86%e8%af%8d-r-%e7%89%88%e6%9c%ac
 171. https://github.com/fxsjy/jieba#%e7%bb%93%e5%b7%b4%e5%88%86%e8%af%8d-ios-%e7%89%88%e6%9c%ac
 172. https://github.com/fxsjy/jieba#%e7%bb%93%e5%b7%b4%e5%88%86%e8%af%8d-php-%e7%89%88%e6%9c%ac
 173. https://github.com/fxsjy/jieba#%e7%bb%93%e5%b7%b4%e5%88%86%e8%af%8d-netc-%e7%89%88%e6%9c%ac
 174. https://github.com/fxsjy/jieba#%e7%bb%93%e5%b7%b4%e5%88%86%e8%af%8d-go-%e7%89%88%e6%9c%ac
 175. https://github.com/fxsjy/jieba#%e7%bb%93%e5%b7%b4%e5%88%86%e8%af%8dandroid%e7%89%88%e6%9c%ac
 176. https://github.com/fxsjy/jieba#%e7%b3%bb%e7%bb%9f%e9%9b%86%e6%88%90
 177. https://github.com/fxsjy/jieba#%e5%88%86%e8%af%8d%e9%80%9f%e5%ba%a6
 178. https://github.com/fxsjy/jieba#%e5%b8%b8%e8%a7%81%e9%97%ae%e9%a2%98
 179. https://github.com/fxsjy/jieba#1-%e6%a8%a1%e5%9e%8b%e7%9a%84%e6%95%b0%e6%8d%ae%e6%98%af%e5%a6%82%e4%bd%95%e7%94%9f%e6%88%90%e7%9a%84
 180. https://github.com/fxsjy/jieba#2-%e5%8f%b0%e4%b8%ad%e6%80%bb%e6%98%af%e8%a2%ab%e5%88%87%e6%88%90%e5%8f%b0-%e4%b8%ad%e4%bb%a5%e5%8f%8a%e7%b1%bb%e4%bc%bc%e6%83%85%e5%86%b5
 181. https://github.com/fxsjy/jieba#3-%e4%bb%8a%e5%a4%a9%e5%a4%a9%e6%b0%94-%e4%b8%8d%e9%94%99%e5%ba%94%e8%af%a5%e8%a2%ab%e5%88%87%e6%88%90%e4%bb%8a%e5%a4%a9-%e5%a4%a9%e6%b0%94-%e4%b8%8d%e9%94%99%e4%bb%a5%e5%8f%8a%e7%b1%bb%e4%bc%bc%e6%83%85%e5%86%b5
 182. https://github.com/fxsjy/jieba#4-%e5%88%87%e5%87%ba%e4%ba%86%e8%af%8d%e5%85%b8%e4%b8%ad%e6%b2%a1%e6%9c%89%e7%9a%84%e8%af%8d%e8%af%ad%e6%95%88%e6%9e%9c%e4%b8%8d%e7%90%86%e6%83%b3
 183. https://github.com/fxsjy/jieba#%e4%bf%ae%e8%ae%a2%e5%8e%86%e5%8f%b2
 184. https://github.com/fxsjy/jieba#jieba-1
 185. https://github.com/fxsjy/jieba#features
 186. https://github.com/fxsjy/jieba#online-demo
 187. https://github.com/fxsjy/jieba#usage
 188. https://github.com/fxsjy/jieba#algorithm
 189. https://github.com/fxsjy/jieba#main-functions
 190. https://github.com/fxsjy/jieba#load-dictionary
 191. https://github.com/fxsjy/jieba#modify-dictionary
 192. https://github.com/fxsjy/jieba#initialization
 193. https://github.com/fxsjy/jieba#using-other-dictionaries
 194. https://github.com/fxsjy/jieba#segmentation-speed
 195. https://github.com/
