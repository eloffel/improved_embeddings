   #[1]publisher [2]medium [3]alternate

   [4]homepage
   [5]homepage
   [6]sign in[7]get started

   [8]becoming human: artificial intelligence magazine
     * [9]     consulting
     * [10]     tutorials
     * [11]       submit an article
     * [12]     communities
     * [13]     our bot
     __________________________________________________________________

making a simple neural network

   [14]go to the profile of keno leon
   [15]keno leon (button) blockedunblock (button) followfollowing
   apr 9, 2017

   what are we making ? we   ll try making a simple & minimal neural network
   which we will explain and train to identify something, there will be
   little to no history or math (tons of that stuff out there), instead i
   will try ( and possibly fail ) to explain it to both you and i mostly
   with doodles and code,let us begin.

   a lot of neural network terms both originate and make somehow more
   sense from a biological perspective, so let   s start from the very top :
   [1*2sj0fb-xlxrgcc-_hcfuow.jpeg]

   the brain is complex, but in general it can be divided into a few basic
   parts and operations:
   [1*tx7uqwfvlyt3sgnnnmfb1w.jpeg]

   stimuli can also be internal (like a percept or idea ):
   [1*lq5ezpxcfki7sc2yybo6xq.jpeg]

   let   s look at some basic and simplified brain parts:
   [1*zxatzn0dighewcyrcdp3bw.jpeg]
   the brain is surprisingly mostly cabling.

   the neuron is the basic unit of computation in the brain, it receives
   and integrates chemical signals from other neurons and depending on a
   number of factors it either does nothing or generates an electrical
   signal or action potential which in turn signals other connected
   neurons via synapses:
   [1*tjkrjyfyzgy1ehnfjgquoq.jpeg]

   dreams,memories,ideas,self regulated movement, reflexes and everything
   you think or do is all generated through this process: millions, maybe
   even billions of neurons firing at different rates and making
   connections which in turn create different subsystems all running in
   parallel and creating a biological neural network.

   this is of course both a generalization and a simplification,but now we
   can describe a minimal biological neural network:
   [1*yb1rufvkmudcgwqszdteow.jpeg]

   and describe it in a formal way with a graph :
   [1*siprvmzhopcs-d-ejhkg-q.jpeg]

   a little extra explanation is in order, the circles represent neurons,
   and the lines connections in between them, to keep things simple at
   this stage, the connections represent a forward movement of information
   from left to right. the first neuron is currently firing and is shaded
   to indicate it. it is also given a number ( 1 when it is firing, and 0
   when it is not ). the numbers in between neurons indicate the weight of
   the connection.

   the above graph represents a moment in time of the network, a more
   accurate depiction would be divided into time segments:
   [1*n-1epeog4hxz0sy673wboq.jpeg]

   before making our neural network, we need to understand how weights
   affect neurons and how neurons learn, let   s start with a bunny (a test
   bunny) and a classical conditioning experiment.
   [1*gharuwksfp4c2ccvnwke0a.jpeg]

   when subjected to a harid113ss puff of air, bunnies like humans usually
   blink:
   [1*f7ny1w_sqxwoqim4bpoixw.jpeg]

   we can model this behavior with a simple graph:
   [1*rxfgwz4iyeomvgwt8dddbq.jpeg]

   like in our previous graph, this one displays just the moment when the
   bunny is sensing the puff of air, we are thus encoding the puff into a
   boolean value. additionally, we are now calculating if the second
   neuron fires or not based on the weight value, if the weight is 1 and
   the sensory neuron is firing we blink,anything below 1 we don   t or in
   other words our second neuron has a threshold of 1.

   let   s introduce another element, a harid113ss auditory tone:
   [1*onlqk6mdtb6pyiw7q5nowg.jpeg]

   we can model the bunnies lack of interest in the following way:
   [1*he2voqgzlsbaeoyslru1cq.jpeg]

   the only difference is that the weight is now zero, so there won   t be a
   blinking bunny, at least not yet, let   s train our bunny to blink on
   command by mixing stimuli ( the tone and the air puff):
   [1*ztftctsfcj7jvnqt6hg9ja.jpeg]

   importantly each of this events happens at a different time epoch, or
   moments in time, the graph would look like this :
   [1*yjk1zmldpssq0vx3x4ni-g.jpeg]

   the tone does nothing, but the air puff still elicits a blink response,
   the important thing to note here is that we are indicating this through
   the weights multiplied by the stimuli (in red).

   learning while a complex behavior,can be simplified for the time being
   as the incremental change in weight between connected neurons in a
   neural network through time.

   in order to train our bunny, we would have to repeat the process:
   [1*sdkujoti- xdnmlldcoq.jpeg]
   the bunny trials ?

   the graph for the first 3 trials and the initial state would look like
   this:
   [1*rdsj-lqwhteugqgnyvljmw.jpeg]

   note that the weights for the tone go up after each trial (in red),
   this amount is arbitrary at this point         i chose 0.30, but it could be
   anything, even a negative number. up til after the 3rd trial we have
   the same behavior from the bunny, but after the 4th trial, something
   new and amazing happens    new behavior.
   [1*urcggpzh42a-hibieyzgdw.jpeg]

   we have removed the air puff yet the bunny still blinks after hearing
   the tone ! the explanation to this new behavior can be found in our
   final graph:
   [1*_yfyk9xdymya34q-swfijg.jpeg]

   we have now trained our bunny to recognize a tone and blink.
   [1*jykmdo4rvyluc6bj09bxdg.jpeg]
   real experiments of this kind can take about 60 trials over a few weeks
   or more to elicit a response.

   we now leave the biological world of brains and bunnies and will adapt
   some of what we have learned to make an id158. the
   first thing we will do is try to define a simple problem.
     __________________________________________________________________

   let   s say there is a 4 button machine that gives you food if you press
   the right button ( or perhaps energy if you are a robot),the objective
   will be to learn which button provides the goods:
   [1*mqyjpic9kj8ndvxi0liibq.jpeg]

   we can indicate when a button is pressed (graphically) in the following
   way:
   [1*yjppqfdkogo0uws2cwegqa.jpeg]

   this problem is easy to digest in it   s entirety, so let   s see all the
   possible outcomes including the solution:
   [1*qfd0qrqnpvemtwrgbvfyrw.jpeg]
   press 3 for chicken dinner.

   in order to create a neural network in code, we first need a model or
   graph we can match it with, here is one such arrangement suited for our
   current problem that loosely emulates it   s biological counterpart :
   [1*icgrnklbnjqmvr7wkbnkrw.jpeg]

   what this neural network does, is simply receive an input, which in
   this case would be the perception of which button was pressed,then
   modify said input by a weight, and finally return an output based on
   the addition of a layer. it sounds a little complicated, so let   s look
   at how our model would represent a button press:
   [1*j5_wkqepodlrcyz_eqouaq.jpeg]
   notice all the weights are zero, so the neural net is in a blank state
   yet fully connected, same as a newborn.

   we are thus mapping an external event to the neural nets input layer
   and calculating an output, this output might or might not match with
   reality, but for now we will ignore this fact and start writing this
   problem in a computer friendly way.

   let   s start with inputs and weights ( i will be using javascript ):
var inputs = [0,1,0,0];
var weights = [0,0,0,0];
// we can call these vectors for convenience.

   the next step is then to create a function that takes these inputs &
   weights and calculates an output; this is such a function:
function evaluateneuralnetwork(inputvector, weightvector){
  var result = 0;
  inputvector.foreach(function(inputvalue, weightindex) {
   layervalue = inputvalue*weightvector[weightindex];
    result += layervalue;
  });
  return (result.tofixed(2));
}
// might look complex, but all it does is multiply weight/input pairs and adds t
he result.

   and as expected if we run the above we would get the same result as our
   graph or model   
evaluateneuralnetwork(inputs, weights); // 0.00

   live example: [16]neural net 001
     __________________________________________________________________

   the next step or upgrade to our neural net will be a way to check its
   own output or result against the reality of the situation, let   s first
   encode this particular reality into a variable :
   [1*xksotegujfndyik2qolkra.jpeg]

   in order to detect a mismatch ( and by how much ) we will add an error
   function:
error = reality - neural net output

   with this 2 new components, we can now judge our neural net:
   [1*xw9esdmrfp5fejicawt3ua.jpeg]

   and more importantly how about when reality provides a positive
   result ? (chicken dinner in our example).
   [1*0moc8w1ow6f8bb37elxp8a.jpeg]

   so now we definitely know that our neural network model does not work
   (and by how much ), great ! this is great because now we can use this
   error to guide our learning, it all makes a little more sense if we
   redefine our error function as follows :
error = desired output - neural net output

   a subtle yet important difference that tacitly implies we will be using
   previously observed results to match against future performance ( and
   learning as we will soon see), this also works in real life because
   reality is full of repeating patterns, so it probably pays as an
   evolutionary strategy (most of the time).

   further modifying our code sample is just a matter of adding a new
   variable:
var input = [0,0,1,0];
var weights = [0,0,0,0];
var desiredresult = 1;

   and a new function:
function evaluateneuralneterror(desired,actual) {
  return (desired     actual);
}
// after evaluating both the network and the error we would get:
// "neural net output: 0.00 error: 1"

   live example: [17]neural net 002
     __________________________________________________________________

   friendly recap: we started with a problem, then we made a simple model
   of it in the image of a biological network of neurons and now we have a
   way of measuring its performance against reality or a desired output.
   what we need now is a way to fix this mismatch, a process that in both
   computers and humans can be thought of as learning.
     __________________________________________________________________

   so how does one teach a neural net ?

   the basis of learning both for biological networks and artificial ones
   seems to be repetition and a learning algorithm, so we will deal with
   each one separately, let   s start with the learning algorithm.

   in nature a learning algorithm can be thought of as a change in the
   physical and chemical characteristics of neurons after experience:
   [1*1je1i0zf-m9xasduet_glw.jpeg]
   dramatization of 2 neurons changing over time

   in code and in our model a learning algorithm simply means we will be
   changing something over time ,to make our life easier, let   s add a
   variable to symbolize by how much:
var learningrate = 0.20;
// bigger rate,bigger faster learnings : )

   and what will we be changing ?

   we will be changing the weights ( same as the bunny does ! ) ,
   specifically the weights of the outcome we want:
   [1*ar_vmig7dao2v7gwpgnuuw.jpeg]

   how one codes such an algorithm is a matter of choice, for simplicity
   sake i am just adding the learning rate to the weight, here it is as a
   function:
function learn(inputvector, weightvector) {
  weightvector.foreach(function(weight, index, weights) {
   if (inputvector[index] > 0) {
    weights[index] = weight + learningrate;
   }
  });
}

   in use this learn function would simply add our learning rate to the
   active neuron   s weight vector, before and after one learning round (or
   trial) this is the result:
// original weight vector: [0,0,0,0]
// neural net output: 0.00 error: 1
learn(input, weights);
// new weight vector: [0,0.20,0,0]
// neural net output: 0.20 error: 0.8
// if it is not apparently obvious, a neural net output closer to 1
// (chicken dinner) is what we want, so we are heading in the right
// direction

   live example: [18]neural net 003

   ok, so now that we are heading in the right direction, the last piece
   we need to incorporate is repetition.

   there is really not much to it, in nature we just do stuff over and
   over again, in code we just specify a number of trials:
var trials = 6;

   and apply our learn function to our neural net the number of times
   defined in our trials, a training function will do this:
function train(trials) {
 for (i = 0; i < trials; i++) {
  neuralnetresult = evaluateneuralnetwork(input, weights);
  learn(input, weights);
 }
}

   and our final readout:
neural net output: 0.00 error: 1.00 weight vector: [0,0,0,0]
neural net output: 0.20 error: 0.80 weight vector: [0,0,0.2,0]
neural net output: 0.40 error: 0.60 weight vector: [0,0,0.4,0]
neural net output: 0.60 error: 0.40 weight vector: [0,0,0.6,0]
neural net output: 0.80 error: 0.20 weight vector: [0,0,0.8,0]
neural net output: 1.00 error: 0.00 weight vector: [0,0,1,0]
// chicken dinner !

   live example: [19]neural net 004

   we now have a weight vector that will only result in the output of 1 (
   chicken dinner ) if the input vector corresponds to that of reality ( a
   push of the 3rd button down ).

   so what good is this thing we just built ?

   in our specific case, our neural net ( after being trained ) can
   recognize or discriminate in between inputs and tell you wich one will
   generate a desired output ( we would still need to code for the
   specific situation) :
   [1*e9oatq0xeg_k4mrpraj3wg.jpeg]
   hey kids, meet mr. neural net !

   additionally, it is a scale model, a toy and a learning tool for both
   you and i, so we can further learn about machine learning,neural
   networks and artificial intelligence.

   caveat emptor:
     * no mechanism for storing the learnt weights is provided, so this
       neural net looses everything it knows upon refreshing or running
       the code again.
     * it would take 6 succesful trials to fully train this neural net, if
       you consider a human or machine would push buttons at random    this
       could take a while.
     * for important things biological networks have a learning rate of 1,
       so it would only take one successful trial.
     * a learning algorithm that resembles biological neurons exists, it
       goes by the catchy name of widroff-hoff rule or widroff-hoff
       learning.
     * the neurons treshold (1 in our example) and the effects of over
       learning ( with more trials the output would be greater than 1),
       are glossed over, but they are important in nature and a source of
       great and complex behaviour.
     * so does negative weights.

   notes & further reading:

   i   ve tried avoiding math and strict terms, but if you want to know, we
   just built a [20]id88 which is defined as an algorithm for
   [21]supervised learning of [22]binary classifiers, heavy stuff.

   the biology of the brain is a big subject, in part because of it   s
   inaccesability and in part because it   s complexity, still there is a
   lot of information out there, possibly the best place to start is
   neuroscience (purves) and cognitive neuroscience (gazzaniga).

   i modified and adapted the bunny example from gateway to memory
   (gluck), which also has an excellent introduction to graphs.

   another heavily consulted source was an introduction to neural networks
   (gurney), good for your general a.i. needs.

   now in python ! thanks to [23]ilya anshmidt for providing a version in
   python:
inputs = [0, 1, 0, 0]
weights = [0, 0, 0, 0]
desired_result = 1
learning_rate = 0.2
trials = 6
def evaluate_neural_network(input_array, weight_array):
        result = 0
        for i in range(len(input_array)):
                layer_value = input_array[i] * weight_array[i]
                result += layer_value
        print("evaluate_neural_network: " + str(result))
        print("weights: " + str(weights))
        return result
        def evaluate_error(desired, actual):
        error = desired - actual
        print("evaluate_error: " + str(error))
        return error
        def learn(input_array, weight_array):
        print("learning...")
        for i in range(len(input_array)):
                if input_array[i] > 0:
                        weight_array[i] += learning_rate
                        def train(trials):
        for i in range(trials):
                neural_net_result = evaluate_neural_network(inputs, weights)
                learn(inputs, weights)
                        train(trials)

   now in go! thanks to [24]kieran maher for providing a version in go:
package main
import (
 "fmt"
 "math"
)
func main() {
 fmt.println("creating inputs and weights ...")
inputs := []float64{0.00, 0.00, 1.00, 0.00}
 weights := []float64{0.00, 0.00, 0.00, 0.00}
 desired := 1.00
 learningrate := 0.20
 trials := 6
train(trials, inputs, weights, desired, learningrate)
}
func train(trials int, inputs []float64, weights []float64, desired float64, lea
rningrate float64) {
for i := 1; i < trials; i++ {
  weights = learn(inputs, weights, learningrate)
  output := evaluate(inputs, weights)
  errorresult := evaluateerror(desired, output)
fmt.print("output: ")
  fmt.print(math.round(output*100) / 100)
  fmt.print("\nerror: ")
  fmt.print(math.round(errorresult*100) / 100)
  fmt.print("\n\n")
 }
}
func learn(inputvector []float64, weightvector []float64, learningrate float64)
[]float64 {
 for index, inputvalue := range inputvector {
  if inputvalue > 0.00 {
   weightvector[index] = weightvector[index] + learningrate
  }
 }
return weightvector
}
func evaluate(inputvector []float64, weightvector []float64) float64 {
 result := 0.00
for index, inputvalue := range inputvector {
  layervalue := inputvalue * weightvector[index]
  result = result + layervalue
 }
return result
}
func evaluateerror(desired float64, actual float64) float64 {
 return desired - actual
}

   about the author :

   eugenio n. leon (keno) is a designer,web developer/programmer, artist
   and inventor, currently living in mexico city, you can find bits and
   pieces of his work at [25]www.k3no.com , he likes problems,getting paid
   to solve them and curiously is mostly vegetarian and hasn   t touched
   chicken in ages.

   iframe: [26]/media/c43026df6fee7cdb1aab8aaf916125ea?postid=2ea1de81ec20

   [1*bqlrszfhjemf4q7pyrlgng.gif]
   [27][1*2f7oqe2ajk1ksrhkmd9zmw.png]
   [28][1*v-ppfkswhbvlwwamsvhhwg.png]
   [29][1*wt2auqisieaozxj-i7brdq.png]

     * [30]artificial intelligence
     * [31]neural networks
     * [32]machine learning
     * [33]neuroscience
     * [34]tutorial

   (button)
   (button)
   (button) 2.6k claps
   (button) (button) (button) 19 (button) (button)

     (button) blockedunblock (button) followfollowing
   [35]go to the profile of keno leon

[36]keno leon

   ai, software developer, designer : [37]www.k3no.com

     (button) follow
   [38]becoming human: artificial intelligence magazine

[39]becoming human: artificial intelligence magazine

   latest news, info and tutorials on artificial intelligence, machine
   learning, deep learning, big data and what it means for humanity.

     * (button)
       (button) 2.6k
     * (button)
     *
     *

   [40]becoming human: artificial intelligence magazine
   never miss a story from becoming human: artificial intelligence
   magazine, when you sign up for medium. [41]learn more
   never miss a story from becoming human: artificial intelligence
   magazine
   (button) get updatesget updates

references

   visible links
   1. https://plus.google.com/103654360130207659246
   2. https://becominghuman.ai/osd.xml
   3. android-app://com.medium.reader/https/medium.com/p/2ea1de81ec20
   4. https://medium.com/
   5. https://medium.com/
   6. https://medium.com/m/signin?redirect=https://becominghuman.ai/making-a-simple-neural-network-2ea1de81ec20&source=--------------------------nav_reg&operation=login
   7. https://medium.com/m/signin?redirect=https://becominghuman.ai/making-a-simple-neural-network-2ea1de81ec20&source=--------------------------nav_reg&operation=register
   8. https://becominghuman.ai/?source=logo-lo_lkuanlaok4kh---5e5bef33608a
   9. https://becominghuman.ai/artificial-intelligence-software-developers-af09386dc05d
  10. https://becominghuman.ai/tagged/tutorial
  11. https://becominghuman.ai/write-for-us-48270209de63
  12. https://becominghuman.ai/artificial-intelligence-communities-c305f28e674c
  13. http://m.me/becominghumanai
  14. https://becominghuman.ai/@k3no?source=post_header_lockup
  15. https://becominghuman.ai/@k3no
  16. http://codepen.io/k3no/pen/gwyjgp
  17. http://codepen.io/k3no/pen/dvagpx
  18. http://codepen.io/k3no/pen/qrjoxo
  19. http://codepen.io/k3no/pen/dvbzle?editors=0012
  20. https://en.wikipedia.org/wiki/id88
  21. https://en.wikipedia.org/wiki/supervised_classification
  22. https://en.wikipedia.org/wiki/binary_classification
  23. https://medium.com/@ilyaanshmidt
  24. https://medium.com/@kieranmaher13
  25. http://www.k3no.com/
  26. https://becominghuman.ai/media/c43026df6fee7cdb1aab8aaf916125ea?postid=2ea1de81ec20
  27. https://medium.com/becoming-human/artificial-intelligence-communities-c305f28e674c
  28. https://upscri.be/8f5f8b
  29. https://medium.com/becoming-human/write-for-us-48270209de63
  30. https://becominghuman.ai/tagged/artificial-intelligence?source=post
  31. https://becominghuman.ai/tagged/neural-networks?source=post
  32. https://becominghuman.ai/tagged/machine-learning?source=post
  33. https://becominghuman.ai/tagged/neuroscience?source=post
  34. https://becominghuman.ai/tagged/tutorial?source=post
  35. https://becominghuman.ai/@k3no?source=footer_card
  36. https://becominghuman.ai/@k3no
  37. http://www.k3no.com/
  38. https://becominghuman.ai/?source=footer_card
  39. https://becominghuman.ai/?source=footer_card
  40. https://becominghuman.ai/
  41. https://medium.com/@medium/personalize-your-medium-experience-with-users-publications-tags-26a41ab1ee0c#.hx4zuv3mg

   hidden links:
  43. https://medium.com/p/2ea1de81ec20/share/twitter
  44. https://medium.com/p/2ea1de81ec20/share/facebook
  45. https://medium.com/p/2ea1de81ec20/share/twitter
  46. https://medium.com/p/2ea1de81ec20/share/facebook
