   #[1]github [2]recent commits to practical-open:master

   [3]skip to content

   (button)

     * why github?
       [4]features    
          + [5]code review
          + [6]project management
          + [7]integrations
          + [8]actions
          + [9]team management
          + [10]social coding
          + [11]documentation
          + [12]code hosting
          + [13]customer stories    
          + [14]security    
     * [15]enterprise
     * explore
          + [16]explore github    

learn & contribute
          + [17]topics
          + [18]collections
          + [19]trending
          + [20]learning lab
          + [21]open source guides

connect with others
          + [22]events
          + [23]community forum
          + [24]github education
     * [25]marketplace
     * pricing
       [26]plans    
          + [27]compare plans
          + [28]contact sales
          + [29]nonprofit    
          + [30]education    

   ____________________
     * in this repository all github    
       jump to    

     * no suggested jump to results

     * in this repository all github    
       jump to    
     * in this repository all github    
       jump to    

   [31]sign in [32]sign up

     * [33]watch [34]18
     * [35]star [36]74
     * [37]fork [38]63

[39]oxford-cs-deepnlp-2017/[40]practical-open

   [41]code [42]issues 0 [43]pull requests 0 [44]projects 0 [45]insights
   (button) dismiss

join github today

   github is home to over 31 million developers working together to host
   and review code, manage projects, and build software together.
   [46]sign up
   oxford deep nlp 2017 course - open practical
   [47]machine-learning [48]nlp [49]natural-language-processing
   [50]deep-learning [51]oxford
     * [52]12 commits
     * [53]1 branch
     * [54]0 releases
     * [55]fetching contributors

   branch: master (button) new pull request
   [56]find file
   clone or download

clone with https

   use git or checkout with svn using the web url.
   https://github.com/o
   [57]download zip

downloading...

   want to be notified of new releases in
   oxford-cs-deepnlp-2017/practical-open?
   [58]sign in [59]sign up

launching github desktop...

   if nothing happens, [60]download github desktop and try again.

   (button) go back

launching github desktop...

   if nothing happens, [61]download github desktop and try again.

   (button) go back

launching xcode...

   if nothing happens, [62]download xcode and try again.

   (button) go back

launching visual studio...

   if nothing happens, [63]download the github extension for visual studio
   and try again.

   (button) go back
   [64]@iassael
   [65]iassael [66]update readme.md
   latest commit [67]494d16c may 16, 2017
   [68]permalink
   type        name        latest commit message  commit time
        failed to load latest commit information.
        [69]doc            [70]azure doc         feb 15, 2017
        [71]readme.md
        [72]azure.md
        [73]practical3.pdf

readme.md

open practical

   [chris dyer, phil blunsom, yannis assael, brendan shillingford, yishu
   miao, jan buys]

   the first three practicals covered a variety of introductory topics in
   deep learning for nlp. for the remainder of the term, you can select
   from among the following projects and explore them according to your
   interests. treat the following project descriptions as suggested
   starting points, but feel free to take any of these ideas in a
   different direction if you feel inspired to. the practical sessions
   offer you an opportunity to pursue such ideas while making use of the
   support and expertise of your practical demonstrators.

microsoft azure sponsorship

   [74][68747470733a2f2f7261776769742e636f6d2f6f78666f72642d63732d64656570
   6e6c702d323031372f70726163746963616c2d6f70656e2f6d61737465722f646f632f6
   17a7572652e737667]

   we would like to thank microsoft azure sponsorship 2 for their generous
   donation of gpu computational resources for this course, as well as,
   michael thomas, andrew webber and lee stott for their precious help.
   for more information setting up your gpu vm: [75]azure setup guide

conditional id38

conditioning on the topic set and generating text

   this is the inverse of the problem considered in practical 2/3: rather
   than conditioning on a talk, and predicting its labels, you should
   condition on an embedding of the label set and generate a ted talk.
   because the ted dataset is limited in terms of size, the (partial)
   [76]wikipedia dumps could be considered as an alternative choice.

   this can be summarized by the very simple stochastic program:

      x = embed(topic set) # map a set of topics into a (learned) vector
   representation

      y ~ id56lm( x ) # feed the topic set into the id56 so it can use this
   information

   the parameters of the id56 and the embedding model can be trained to
   maximize the log likelihood of a set of training pairs (topic set, y
   )*.

   you will need to design a function to create an embedding of the set of
   topics you are going to condition on. options here are using an "id56
   encoder" to read the list, an additive model, a convolutional
   architecture, or something else you come up with.

   questions
     * each topic is associated with an unordered set of topics. the
       simple additive embedding model obtains the same representation
       independent of the order of the elements of the set (because the
       commutative property holds for vector addition). what are the
       downsides of the additive model? on the other hand, the more
       sophisticated topic embedding models based on id56s or convnets
       require presenting the topic labels in a particular order. is this
       a problem? how might you address any problems you identify? can you
       come up with a better embedding model?
     * using the same held-out data, how does the perplexity of your model
       compare to the perplexity of the unconditional language models
       proposed in practical 3?
     * in the sutskever et al. (2014) paper we discussed in class, the
       initial states of the "decoder" lstm were initialised using the
       input embedding ( x ). there are alternatives: x can be fed in as
       an input in addition to the embedding of the previous word at each
       timestep. or it can be concatenated with the hidden state prior to
       projecting onto the output vocabulary. what are the expected
       advantages and disadvantages of these models? how well do these
       variants work in practice?

conditioning on the talk and generating an summary

   summarisation is an important application in nlp. sequence to sequence
   models are an appealing model for generating summaries: an encoder
   "reads" the contents of the talk and a decoder attends to the resulting
   representations and generates an output summary.

   each ted talk in our dataset comes with a short summary (located in the
   <description> xml tag). design and implement a model for learning to
   generate summaries. evaluate it using the [77]id8 metric.

   there are several challenges in this task:
     * ted talks are quite long, and running a bidirectional
       id56(/gru/lstm) over them is computationally expensive.
          + perhaps use a convolutional architecture instead. convnets
            read windows of text "in parallel" so they can be much faster
            on vectorised hardware (like gpus and modern cpus).
          + perhaps process each sentence of the document in parallel with
            an id56. this may require adapting the attention mechanism in
            some way. (since you will no longer be attending to a position
            in a sequence, but perhaps to a position in a sequence of
            sequences.)
     * summaries often reuse content from the original document. in fact,
       there is a task called "extractive summarisation" that only lets
       you reuse existing content (this contrasts with the more general
       "abstractive summarisation"). consider augmenting your
       summarisation model with a "copy mechanism" that decides to copy a
       word from a position, rather than encoding the word as a vector and
       re-decoding it.

machine translation (mt)

   machine translation has been one of the notable successes of deep
   learning in nlp. the ted corpus has been translated into many languages
   by a volunteer effort. and ted now holds regional talks in many
   different languages, many of which are also translated into english.
   the result is: we have a lot of "in domain" training data to learn how
   to translate ted talks.

   in this task, you should implement a sequence-to-sequence translation
   model for german to english translation, as described by [78]bahdanau
   et al. (2015). you can obtained preprocessed (tokenised, filtered for
   length, and lowercased, split into training/validation/test sets)
   [79]parallel german-english data (if you wish, you can copy this data
   somewhere [80]here). note: the validation/test sets contain oov words
   relative to the vocabulary in the training set, in both the source and
   target languages. you will need to deal with this (the simplest thing
   is to replace infrequent words with an unk token).

   for decoding, you should implement two decoding algorithms: the greedy
   left-to-right decoder, and one that generates sample translations
   proportional to the id203 p(translation | input). evaluate the
   output of your translation model using [81]multi-id7.perl.

   questions
     * why does the greedy decoding algorithm make search errors even
       though it is possible to generate unbiased samples from the
       translation model?
     * sample 20 translations of the test set. what is the
       min/max/mean/median/stddev of the id7 score? how do these compare
       to the id7 score obtained by the greedy decoder?
     * do you expect id27s for english and german words that
       mean the same to be "close" in terms of cosine similarity? why or
       why not?

speaking rate modeling

   how long does it take to read a document? different speakers speak at
   different base rates; and different words take more or less time to
   pronounce.

   in this task, you will use the timing data from the ted xml transcripts
   to build a model to predict how long different speakers will take to
   produce words. since each speaker will have a different base rate, we
   will control for that by observing the speaking rate both in the
   training set and test set.

   r = per-character speaking rate of speaker (observed in this case)

   [82]equation = context vector at time t ( can be processed by token
   embedding, bidirectional id56 or convnet)

   [83]equation = predict_duration [84]equation ( in milliseconds? or log
   milliseconds? should be positive?)

   [85]equation (what id168 is used here? what does the error
   distribution look like? is it symmetric? skewed?)

   in this task, you will need to:
     * prepare the training data (e.g., compute r for each speaker in the
       training/validation/test splits)
     * decide what the regression target will be
     * compute the per-character speaking rate for every talk in the
       training/validation/test splits
     * design and implement the token embedding function (do you want to
       incorporate context or not?)
     * design the prediction function that converts each $h_t$ to a scalar
       with the appropriate range (e.g., strictly positive)
     * design the id168.

   questions
     * use a character-based embedding function to represent each token
       (i.e., compose a sequence of characters into a "id27"
       using a convnet or id56). what are the advantages and disadvantages
       this of modeling the speaking rates of english words? which model
       works better?
     * this model is only trained to predict the length of the full
       sequences. the lengths of individual words are not present in the
       training data. plot the durations of words predicted by your model
       on the validation set. do these seem reasonable? how might you
       improve the training objective to give better per-word predictions?

propose your own task

   if none of the above tasks inspire you, or if you happen to have
   discovered an interesting source of data to model, feel free to propose
   and pursue your own research idea.

   some ideas might be:
     * using the multilingual data from the mt task, design and implement
       a id27 model such that words that have a similar meaning
       in english (e.g.: reject, deny) have vectors that are similar to
       each other, and words that are similar in meaning in translation
       have vectors that are close to each other (e.g., reject, ablehnen).
     * do something with the audio/video recordings and the transcripts
       (e.g., train an asr system based on conditional language models).
     * when will the audience laugh? the ted talk contain indications for
       when the audience laughs. can you predict what's going to cause the
       audience to laugh using the text?

     *    2019 github, inc.
     * [86]terms
     * [87]privacy
     * [88]security
     * [89]status
     * [90]help

     * [91]contact github
     * [92]pricing
     * [93]api
     * [94]training
     * [95]blog
     * [96]about

   (button) you can   t perform that action at this time.

   you signed in with another tab or window. [97]reload to refresh your
   session. you signed out in another tab or window. [98]reload to refresh
   your session.

   (button)

references

   visible links
   1. https://github.com/opensearch.xml
   2. https://github.com/oxford-cs-deepnlp-2017/practical-open/commits/master.atom
   3. https://github.com/oxford-cs-deepnlp-2017/practical-open#start-of-content
   4. https://github.com/features
   5. https://github.com/features/code-review/
   6. https://github.com/features/project-management/
   7. https://github.com/features/integrations
   8. https://github.com/features/actions
   9. https://github.com/features#team-management
  10. https://github.com/features#social-coding
  11. https://github.com/features#documentation
  12. https://github.com/features#code-hosting
  13. https://github.com/customer-stories
  14. https://github.com/security
  15. https://github.com/enterprise
  16. https://github.com/explore
  17. https://github.com/topics
  18. https://github.com/collections
  19. https://github.com/trending
  20. https://lab.github.com/
  21. https://opensource.guide/
  22. https://github.com/events
  23. https://github.community/
  24. https://education.github.com/
  25. https://github.com/marketplace
  26. https://github.com/pricing
  27. https://github.com/pricing#feature-comparison
  28. https://enterprise.github.com/contact
  29. https://github.com/nonprofit
  30. https://education.github.com/
  31. https://github.com/login?return_to=/oxford-cs-deepnlp-2017/practical-open
  32. https://github.com/join
  33. https://github.com/login?return_to=/oxford-cs-deepnlp-2017/practical-open
  34. https://github.com/oxford-cs-deepnlp-2017/practical-open/watchers
  35. https://github.com/login?return_to=/oxford-cs-deepnlp-2017/practical-open
  36. https://github.com/oxford-cs-deepnlp-2017/practical-open/stargazers
  37. https://github.com/login?return_to=/oxford-cs-deepnlp-2017/practical-open
  38. https://github.com/oxford-cs-deepnlp-2017/practical-open/network/members
  39. https://github.com/oxford-cs-deepnlp-2017
  40. https://github.com/oxford-cs-deepnlp-2017/practical-open
  41. https://github.com/oxford-cs-deepnlp-2017/practical-open
  42. https://github.com/oxford-cs-deepnlp-2017/practical-open/issues
  43. https://github.com/oxford-cs-deepnlp-2017/practical-open/pulls
  44. https://github.com/oxford-cs-deepnlp-2017/practical-open/projects
  45. https://github.com/oxford-cs-deepnlp-2017/practical-open/pulse
  46. https://github.com/join?source=prompt-code
  47. https://github.com/topics/machine-learning
  48. https://github.com/topics/nlp
  49. https://github.com/topics/natural-language-processing
  50. https://github.com/topics/deep-learning
  51. https://github.com/topics/oxford
  52. https://github.com/oxford-cs-deepnlp-2017/practical-open/commits/master
  53. https://github.com/oxford-cs-deepnlp-2017/practical-open/branches
  54. https://github.com/oxford-cs-deepnlp-2017/practical-open/releases
  55. https://github.com/oxford-cs-deepnlp-2017/practical-open/graphs/contributors
  56. https://github.com/oxford-cs-deepnlp-2017/practical-open/find/master
  57. https://github.com/oxford-cs-deepnlp-2017/practical-open/archive/master.zip
  58. https://github.com/login?return_to=https://github.com/oxford-cs-deepnlp-2017/practical-open
  59. https://github.com/join?return_to=/oxford-cs-deepnlp-2017/practical-open
  60. https://desktop.github.com/
  61. https://desktop.github.com/
  62. https://developer.apple.com/xcode/
  63. https://visualstudio.github.com/
  64. https://github.com/iassael
  65. https://github.com/oxford-cs-deepnlp-2017/practical-open/commits?author=iassael
  66. https://github.com/oxford-cs-deepnlp-2017/practical-open/commit/494d16c102e8ebdcde2ccae9b5c31f10ff4be3d2
  67. https://github.com/oxford-cs-deepnlp-2017/practical-open/commit/494d16c102e8ebdcde2ccae9b5c31f10ff4be3d2
  68. https://github.com/oxford-cs-deepnlp-2017/practical-open/tree/494d16c102e8ebdcde2ccae9b5c31f10ff4be3d2
  69. https://github.com/oxford-cs-deepnlp-2017/practical-open/tree/master/doc
  70. https://github.com/oxford-cs-deepnlp-2017/practical-open/commit/f2871fa79ed5c6f289c8460cf5dd599869e3faa3
  71. https://github.com/oxford-cs-deepnlp-2017/practical-open/blob/master/readme.md
  72. https://github.com/oxford-cs-deepnlp-2017/practical-open/blob/master/azure.md
  73. https://github.com/oxford-cs-deepnlp-2017/practical-open/blob/master/practical3.pdf
  74. https://camo.githubusercontent.com/8e19e677d3eb09c979c1bc047e3164cf022a1306/68747470733a2f2f7261776769742e636f6d2f6f78666f72642d63732d646565706e6c702d323031372f70726163746963616c2d6f70656e2f6d61737465722f646f632f617a7572652e737667
  75. https://github.com/oxford-cs-deepnlp-2017/practical-open/blob/master/azure.md
  76. https://dumps.wikimedia.org/backup-index.html
  77. http://www.beid8.com/pages/default.aspx
  78. https://arxiv.org/abs/1409.0473
  79. http://demo.clab.cs.cmu.edu/cdyer/iwslt-deen-prepared.tar.gz
  80. http://demo.clab.cs.cmu.edu/cdyer/iwslt-deen-prepared.tar.gz
  81. https://github.com/moses-smt/mosesdecoder/blob/master/scripts/generic/multi-id7.perl
  82. https://camo.githubusercontent.com/89de65a3626eff1d27e09aa8721e14e46fab3b57/687474703a2f2f7777772e736369776561766572732e6f72672f75706c6f61642f54657832496d675f313438363932393337342f72656e6465722e706e67
  83. https://camo.githubusercontent.com/3f3236978b0d5d58d637ac10ac4d76aa38543353/687474703a2f2f7777772e736369776561766572732e6f72672f75706c6f61642f54657832496d675f313438363932393333392f72656e6465722e706e67
  84. https://camo.githubusercontent.com/9aa024fca535fed9fc170052d78d88f6246f0f15/687474703a2f2f7777772e736369776561766572732e6f72672f75706c6f61642f54657832496d675f313438363932393431392f72656e6465722e706e67
  85. https://camo.githubusercontent.com/4ebdb2fd228e46fea8a6d512e7e41dc4973e8ac3/687474703a2f2f7777772e736369776561766572732e6f72672f75706c6f61642f54657832496d675f313438363932393436362f72656e6465722e706e67
  86. https://github.com/site/terms
  87. https://github.com/site/privacy
  88. https://github.com/security
  89. https://githubstatus.com/
  90. https://help.github.com/
  91. https://github.com/contact
  92. https://github.com/pricing
  93. https://developer.github.com/
  94. https://training.github.com/
  95. https://github.blog/
  96. https://github.com/about
  97. https://github.com/oxford-cs-deepnlp-2017/practical-open
  98. https://github.com/oxford-cs-deepnlp-2017/practical-open

   hidden links:
 100. https://github.com/
 101. https://github.com/oxford-cs-deepnlp-2017/practical-open
 102. https://github.com/oxford-cs-deepnlp-2017/practical-open
 103. https://github.com/oxford-cs-deepnlp-2017/practical-open
 104. https://help.github.com/articles/which-remote-url-should-i-use
 105. https://github.com/oxford-cs-deepnlp-2017/practical-open#open-practical
 106. https://github.com/oxford-cs-deepnlp-2017/practical-open#microsoft-azure-sponsorship
 107. https://github.com/oxford-cs-deepnlp-2017/practical-open#conditional-language-modeling
 108. https://github.com/oxford-cs-deepnlp-2017/practical-open#conditioning-on-the-topic-set-and-generating-text
 109. https://github.com/oxford-cs-deepnlp-2017/practical-open#conditioning-on-the-talk-and-generating-an-summary
 110. https://github.com/oxford-cs-deepnlp-2017/practical-open#machine-translation-mt
 111. https://github.com/oxford-cs-deepnlp-2017/practical-open#speaking-rate-modeling
 112. https://github.com/oxford-cs-deepnlp-2017/practical-open#propose-your-own-task
 113. https://github.com/
