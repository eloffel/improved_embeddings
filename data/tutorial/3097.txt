   #[1]salesforce research

   [2]salesforce logo [3]mission [4]research [5]careers [6]ethics
   [7]products [8]press

   [9]publications [10]blog [11]open source [12]grants

   [13]salesforce logo [14]   
   [15]mission [16]research [17]publications [18]blog [19]open source
   [20]grants [21]careers [22]ethics [23]products [24]press

   [25]salesforce logo [26]mission [27]research [28]careers [29]ethics
   [30]products [31]press

   [32]publications [33]blog [34]open source [35]grants

multiple different natural language processing tasks in a single deep model

   by: [36]kazuma hashimoto

   humans learn natural languages, such as english, starting from basic
   grammar to complex semantics in a single brain. how do we build such a
   single model to handle a variety of natural language processing (nlp)
   tasks in computers? as a first step towards this goal, we have
   developed a single deep neural network model which can learn five
   different nlp tasks and achieve state-of-the-art results. our model
   starts from basic tasks and gradually moves to more complex tasks,
   which is continuously repeated until our model finishes learning all of
   the tasks. by doing this, our model allows the tasks to interact each
   other with the potential to improve accuracy of all of the tasks.
   further details can be found in [37]our paper.
   [framework_kazuma.svg]

what can our model do?

   let's process the example sentence: "a man with a jersey is dunking the
   ball at a basketball game" using our model.
   [example_kazuma.png]

   our model first analyzes grammatical roles (part of speeches) of the
   words in the sentence. a part-of-speech tag is assigned for each word;
   for example, the tag nn means that the corresponding word is a noun.
   the task is one of the most basic and fundamental nlp tasks.

   next, the syntactic phrases (chunks) in the sentence are identified;
   for example, the tag np means that the corresponding span represents a
   noun phrase. the beyond word-level task can handle syntactically
   motivated phrases.

   subsequently, the syntactic relationships (dependencies) between the
   words are specified by using the previously analyzed results; for
   example, the arrow from the symbol "root" to the word "dunking" means
   that the word "dunking" plays the central role when representing the
   sentence, and the subject (nsubj) of the action is a man and the object
   (dobj) of the action is a ball. this task is fundamental in analyzing
   sentence structures and in detecting relationships between words.

   now that our model has finished syntactically analyzing the single
   sentence, it is time to go beyond the single sentence level tasks. in
   the next phases, our model tries to understand semantic relationships
   between two sentences. let us denote the above example sentence as the
   sentence a and take another sentence b:

     "the ball is being dunked by a man with a jersey at a basketball
     game".

   in the semantic tasks, our model predicts how much the two sentences
   are semantically related to each other, by using a real-valued score
   ranging from 1 to 5. the higher the score is, the more semantically
   related the sentence pair is. the score for the two sentences a and b
   is 4.9 because the two sentences describe the same situation. in
   addition, our model can recognize whether the sentence a entails the
   sentence b or not. here, our model says that the sentence a entails the
   sentence b.

state-of-the-art results on multiple tasks by a single model

   like this, our single model can handle different levels of nlp tasks.
   now one question arises: how accurate is our model on the five
   different tasks? as shown in [38]our paper, our single model achieves
   state-of-the-art results on syntactic chunking, id33,
   semantic relatedness, and id123. our part-of-speech
   tagging score is also competitive with state-of-the-art results. these
   results are notable because many of the previous models were designed
   to handle single or a few related tasks to achieve the best results
   only for the limited number of the tasks.

citation credit

   kazuma hashimoto, caiming xiong, yoshimasa tsuruoka, richard socher
   [39]a joint many-task model: growing a neural network for multiple nlp
   tasks

   [40]salesforce logo [41]content [42]terms [43]privacy
      copyright 2017 [44]salesforce.com, inc. [45]all rights reserved.
   rights of albert einstein are used with permission of the hebrew
   university of jerusalem. represented exclusively by greenlight.

references

   1. https://blog.einstein.ai/rss/
   2. https://www.einstein.ai/
   3. https://einstein.ai/mission
   4. https://einstein.ai/research
   5. https://einstein.ai/careers
   6. https://einstein.ai/ethics
   7. https://einstein.ai/products
   8. https://einstein.ai/press
   9. https://einstein.ai/research/publications
  10. https://einstein.ai/research/blog
  11. https://einstein.ai/research/open-source
  12. https://einstein.ai/research/grants
  13. https://www.einstein.ai/
  14. javascript:void(0);
  15. https://einstein.ai/mission
  16. https://einstein.ai/research
  17. https://einstein.ai/research/publications
  18. https://einstein.ai/research/blog
  19. https://einstein.ai/research/open-source
  20. https://einstein.ai/research/grants
  21. https://einstein.ai/careers
  22. https://einstein.ai/ethics
  23. https://einstein.ai/products
  24. https://einstein.ai/press
  25. https://www.einstein.ai/
  26. https://einstein.ai/mission
  27. https://einstein.ai/research
  28. https://einstein.ai/careers
  29. https://einstein.ai/ethics
  30. https://einstein.ai/products
  31. https://einstein.ai/press
  32. https://einstein.ai/research/publications
  33. https://einstein.ai/research/blog
  34. https://einstein.ai/research/open-source
  35. https://einstein.ai/research/grants
  36. https://blog.einstein.ai/author/kazuma/
  37. https://arxiv.org/abs/1611.01587
  38. https://arxiv.org/abs/1611.01587
  39. https://arxiv.org/abs/1611.01587
  40. https://www.salesforce.com/
  41. https://einstein.ai/content-takedown
  42. https://einstein.ai/terms-of-service
  43. https://einstein.ai/privacy
  44. https://www.salesforce.com/
  45. https://www.salesforce.com/company/legal/intellectual.jsp
