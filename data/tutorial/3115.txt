   #[1]github [2]recent commits to cntk:master

   [3]skip to content

   (button)

     * why github?
       [4]features    
          + [5]code review
          + [6]project management
          + [7]integrations
          + [8]actions
          + [9]team management
          + [10]social coding
          + [11]documentation
          + [12]code hosting
          + [13]customer stories    
          + [14]security    
     * [15]enterprise
     * explore
          + [16]explore github    

learn & contribute
          + [17]topics
          + [18]collections
          + [19]trending
          + [20]learning lab
          + [21]open source guides

connect with others
          + [22]events
          + [23]community forum
          + [24]github education
     * [25]marketplace
     * pricing
       [26]plans    
          + [27]compare plans
          + [28]contact sales
          + [29]nonprofit    
          + [30]education    

   ____________________
     * in this repository all github    
       jump to    

     * no suggested jump to results

     * in this repository all github    
       jump to    
     * in this repository all github    
       jump to    

   [31]sign in [32]sign up

     * [33]watch [34]1,385
     * [35]star [36]15,975
     * [37]fork [38]4,238

[39]microsoft/[40]cntk

   [41]code [42]issues 627 [43]pull requests 86 [44]wiki [45]insights
   (button) dismiss

join github today

   github is home to over 31 million developers working together to host
   and review code, manage projects, and build software together.
   [46]sign up
   microsoft cognitive toolkit (cntk), an open source deep-learning
   toolkit [47]https://docs.microsoft.com/cognitive-   
   [48]cognitive-toolkit [49]cntk [50]deep-learning [51]machine-learning
   [52]deep-neural-networks [53]neural-network [54]distributed [55]python
   [56]c-plus-plus [57]c-sharp [58]java
     * [59]16,083 commits
     * [60]1,035 branches
     * [61]38 releases
     * [62]199 contributors
     * [63]view license

    1. [64]c++ 55.6%
    2. [65]jupyter notebook 24.3%
    3. [66]python 12.2%
    4. [67]cuda 3.9%
    5. [68]c# 1.0%
    6. [69]shell 0.9%
    7. other 2.1%

   (button) c++ jupyter notebook python cuda c# shell other
   branch: master (button) new pull request
   [70]find file
   clone or download

clone with https

   use git or checkout with svn using the web url.
   https://github.com/m
   [71]download zip

downloading...

   want to be notified of new releases in microsoft/cntk?
   [72]sign in [73]sign up

launching github desktop...

   if nothing happens, [74]download github desktop and try again.

   (button) go back

launching github desktop...

   if nothing happens, [75]download github desktop and try again.

   (button) go back

launching xcode...

   if nothing happens, [76]download xcode and try again.

   (button) go back

launching visual studio...

   if nothing happens, [77]download the github extension for visual studio
   and try again.

   (button) go back
   [78]@rpengms
   [79]rpengms [80]fp16 - brain script add to cntk.core.bs ([81]#3617[82])
   latest commit [83]9688ac6 apr 1, 2019
   [84]permalink
   type name latest commit message commit time
   failed to load latest commit information.
   [85]documentation [86]support onnx export of 2gb models mar 14, 2019
   [87]examples
   [88]manual [89]bump up version number sep 13, 2018
   [90]pretrainedmodels
   [91]scripts [92]update conda to >= 4.3.30 mar 22, 2019
   [93]source [94]fp16 - brain script add to cntk.core.bs ([95]#3617[96])
   apr 1, 2019
   [97]tests [98]update oobe gpu dockerfile to cuda 10 mar 25, 2019
   [99]tools
   [100]tutorials [101]fix cntk tutorial 303 mar 25, 2019
   [102]bindings [103]support onnx export of 2gb models mar 14, 2019
   [104]external
   [105].clang-format
   [106].gitattributes
   [107].gitignore
   [108].gitmodules [109]submodule onnxruntime, and remove previous drop.
   jan 3, 2019
   [110]cmakelists.txt
   [111]cntk.common.props [112]set public_build to "no"/false sep 17, 2018
   [113]cntk.cpp.props
   [114]cntk.sln
   [115]contributing.md [116]updating links to old wiki - referencing now
   the doc site jun 7, 2017
   [117]cppcntk.vssettings [118]update cppcntk.vssettings (wolfma) jan 22,
   2016
   [119]license.md [120]update license.md mar 7, 2018
   [121]makefile
   [122]readme.md [123]merge branch 'pull/3431' feb 28, 2019
   [124]thirdpartynotices.md
   [125]configure

readme.md

cntk

   chat windows build status linux build status
   [126]join the chat at https://gitter.im/microsoft/cntk [127]build
   status [128]build status

   the microsoft cognitive toolkit ([129]https://cntk.ai) is a unified
   deep learning toolkit that describes neural networks as a series of
   computational steps via a directed graph. in this directed graph, leaf
   nodes represent input values or network parameters, while other nodes
   represent matrix operations upon their inputs. cntk allows users to
   easily realize and combine popular model types such as feed-forward
   dnns, convolutional nets (id98s), and recurrent networks (id56s/lstms).
   it implements stochastic id119 (sgd, error id26)
   learning with automatic differentiation and parallelization across
   multiple gpus and servers. cntk has been available under an open-source
   license since april 2015. it is our hope that the community will take
   advantage of cntk to share ideas more quickly through the exchange of
   open source working code.

installation

     * [130]setup cntk
          + windows ([131]python-only / [132]script-driven / [133]manual)
          + linux ([134]python-only / [135]script-driven / [136]manual /
            [137]docker)
     * [138]cntk backend for keras
     * [139]setup cntk development environment
          + windows ([140]script-driven / [141]manual)
          + linux ([142]manual)

installing nightly packages

   if you prefer to use latest cntk bits from master, use one of the cntk
   nightly packages:
     * [143]nightly packages for windows
     * [144]nightly packages for linux

learning cntk

   you can learn more about using and contributing to cntk with the
   following resources:
     * [145]general documentation
     * [146]python api documentation
     * [147]evaluation documentation (c++, c#/.net, python, java)
     * [148]manual
     * [149]tutorials
     * [150]examples
     * [151]pretrained models
     * [152]blog
     * [153]presentations
     * [154]license

more information

     * [155]contribute to cntk
     * [156]faq
     * [157]feedback

disclaimer

   cntk is in active use at microsoft and constantly evolving. there will
   be bugs.

microsoft open source code of conduct

   this project has adopted the [158]microsoft open source code of
   conduct. for more information see the [159]code of conduct faq or
   contact [160]opencode@microsoft.com with any additional questions or
   comments.

news

     you can find more news on [161]the official project feed

   2018-11-26.
   [162]netron now supports visualizing cntk v1 and cntk v2 .model files.

   [163]netroncntkdark1 [164]netroncntklight1

project changelog

   2018-09-17. cntk 2.6.0

efficient group convolution

   the implementation of group convolution in cntk has been updated. the
   updated implementation moves away from creating a sub-graph for group
   convolution (using slicing and splicing), and instead uses cudnn7 and
   mkl2017 apis directly. this improves the experience both in terms of
   performance and model size.

   as an example, for a single group convolution op with the following
   attributes:
     * input tensor (c, h, w) = (32, 128, 128)
     * number of output channels = 32 (channel multiplier is 1)
     * groups = 32 (depth wise convolution)
     * kernel size = (5, 5)

   the comparison numbers for this single node are as follows:
   first header gpu exec. time (in millisec., 1000 run avg.) cpu exec.
   time (in millisec., 1000 run avg.) model size (in kb, cntk format)
   old implementation 9.349 41.921 38
   new implementation 6.581 9.963 5
   speedup/savings approx. 30% approx. 65-75% approx. 87%

sequential convolution

   the implementation of sequential convolution in cntk has been updated.
   the updated implementation creates a separate sequential convolution
   layer. different from regular convolution layer, this operation
   convolves also on the dynamic axis(sequence), and filter_shape[0] is
   applied to that axis. the updated implementation supports broader
   cases, such as where stride > 1 for the sequence axis.

   for example, a sequential convolution over a batch of one-channel
   black-and-white images. the images have the same fixed height of 640,
   but each with width of variable lengths. the width is then represented
   by sequential axis. padding is enabled, and strides for both width and
   height are 2.
 >>> f = sequentialconvolution((3,3), reduction_rank=0, pad=true, strides=(2,2),
 activation=c.relu)
 >>> x = c.input_variable(**sequence[tensor[640]])
 >>> x.shape
     (640,)
 >>> h = f(x)
 >>> h.shape
     (320,)
 >>> f.w.shape
     (1, 1, 3, 3)

operators

depth_to_space and space_to_depth

   there is a breaking change in the depth_to_space and space_to_depth
   operators. these have been updated to match onnx specification,
   specifically the permutation for how the depth dimension is placed as
   blocks in the spatial dimensions, and vice-versa, has been changed.
   please refer to the updated doc examples for these two ops to see the
   change.

tan and atan

   added support for trigonometric ops tan and atan.

elu

   added support for alpha attribute in elu op.

convolution

   updated auto padding algorithms of convolution to produce symmetric
   padding at best effort on cpu, without affecting the final convolution
   output values. this update increases the range of cases that could be
   covered by mkl api and improves the performance, e.g. resnet50.

default arguments order

   there is a breaking change in the arguments property in cntk python
   api. the default behavior has been updated to return arguments in
   python order instead of in c++ order. this way it will return arguments
   in the same order as they are fed into ops. if you wish to still get
   arguments in c++ order, you can simply override the global option. this
   change should only affect the following ops: times, transposetimes, and
   gemm(internal).

bug fixes

     * updated doc for convolution layer to include group and dilation
       arguments.
     * added improved input validation for group convolution.
     * updated logsoftmax to use more numerically stable implementation.
     * fixed gather op's incorrect gradient value.
     * added validation for 'none' node in python clone substitution.
     * added validation for padding channel axis in convolution.
     * added cntk native default lotusir logger to fix the "attempt to use
       defaultlogger" error when loading some onnx models.
     * added proper initialization for onnx typestrtoprotomap.
     * updated python doctest to handle different print format for newer
       version numpy(version >= 1.14).
     * fixed pooling(cpu) to produce correct output values when kernel
       center is on padded input cells.

onnx

updates

     * updated cntk's onnx import/export to use onnx 1.2 spec.
     * major update to how batch and sequence axes are handled in export
       and import. as a result, the complex scenarios and edge cases are
       handled accurately.
     * updated cntk's onnx batchid172 op export/import to latest
       spec.
     * added model domain to onnx model export.
     * improved error reporting during import and export of onnx models.
     * updated depthtospace and spacetodepth ops to match onnx spec on the
       permutation for how the depth dimension is placed as block
       dimension.
     * added support for exporting alpha attribute in elu onnx op.
     * major overhaul to convolution and pooling export. unlike before,
       these ops do not export an explicit pad op in any situation.
     * major overhaul to convolutiontranspose export and import.
       attributes such as output_shape, output_padding, and pads are fully
       supported.
     * added support for cntk's stopgradient as a no-op.
     * added onnx support for topk op.
     * added onnx support for sequence ops: sequence.slice,
       sequence.first, sequence.last, sequence.reduce_sum,
       sequence.reduce_max, sequence.softmax. for these ops, there is no
       need to expand onnx spec. cntk onnx exporter just builds
       computation equivalent graphs for these sequence ops.
     * added full support for softmax op.
     * made cntk broadcast ops compatible with onnx specification.
     * handle to_batch, to_sequence, unpack_batch, sequence.unpack ops in
       cntk onnx exporter.
     * onnx tests to export onnx test cases for other toolkits to run and
       to validate.
     * fixed hardmax/softmax/logsoftmax import/export.
     * added support for select op export.
     * added import/export support for several trigonometric ops.
     * updated cntk support for onnx matmul op.
     * updated cntk support for onnx gemm op.
     * updated cntk's onnx meanvarianceid172 op export/import to
       latest spec.
     * updated cntk's onnx layerid172 op export/import to latest
       spec.
     * updated cntk's onnx prelu op export/import to latest spec.
     * updated cntk's onnx gather op export/import to latest spec.
     * updated cntk's onnx imagescaler op export/import to latest spec.
     * updated cntk's onnx reduce ops export/import to latest spec.
     * updated cntk's onnx flatten op export/import to latest spec.
     * added cntk support for onnx unsqueeze op.

bug or minor fixes:

     * updated lrn op to match onnx 1.2 spec where the size attribute has
       the semantics of diameter, not radius. added validation if lrn
       kernel size is larger than channel size.
     * updated min/max import implementation to handle variadic inputs.
     * fixed possible file corruption when resaving on top of existing
       onnx model file.

.net support

   the cntk.core.managed library has officially been converted to .net
   standard and supports .net core and .net framework applications on both
   windows and linux. starting from this release, .net developers should
   be able to restore cntk nuget packages using new .net sdk style project
   file with package management format set to packagereference.

   the following c# code now works on both windows and linux:
 >>> var weightparametername = "weight";
 >>> var biasparametername = "bias";
 >>> var inputname = "input";
 >>> var outputdim = 2;
 >>> var inputdim = 3;
 >>> variable inputvariable = variable.inputvariable(new int[] { inputdim }, dat
atype.float, inputname);
 >>> var weightparameter = new parameter(new int[] { outputdim, inputdim }, data
type.float, 1, device, weightparametername);
 >>> var biasparameter = new parameter(new int[] { outputdim }, datatype.float,
0, device, biasparametername);
 >>>
 >>> function modelfunc = cntklib.times(weightparameter, inputvariable) + biaspa
rameter;

   for example, simply adding an itemgroup clause in the .csproj file of a
   .net core application is sufficient: >>> >>> >>> >>> netcoreapp2.1 >>>
   x64 >>> >>> >>> >>> >>> >>> >>>

bug or minor fixes:

     * fixed c# string and char to native wstring and wchar utf conversion
       issues on linux.
     * fixed multibyte and wide character conversions across the codebase.
     * fixed nuget package mechanism to pack for .net standard.
     * fixed a memory leak issue in value class in c# api where dispose
       was not called upon object destruction.

misc

   2018-04-16. cntk 2.5.1

   repack cntk 2.5 with third party libraries included in the bundles
   (python wheel packages)
     __________________________________________________________________

   2018-03-15. cntk 2.5

   change profiler details output format to be chrome://tracing

   enable per-node timing. working example [165]here
     * per-node timing creates items in profiler details when profiler is
       enabled.
     * usage in python:

import cntk as c
c.debugging.debug.set_node_timing(true)
c.debugging.start_profiler() # optional
c.debugging.enable_profiler() # optional
#<trainer|evaluator|function> executions
<trainer|evaluator|function>.print_node_timing()
c.debugging.stop_profiler()

   example profiler details view in chrome://tracing
   [166]profilerdetailwithnodetiming

   cpu id136 performance improvements using mkl
     * accelerates some common tensor ops in intel cpu id136 for
       float32, especially for fully connected networks
     * can be turned on/off by
       cntk.cntk_py.enable_cpueval_optimization()/cntk.cntk_py.disable_cpu
       eval_optimization()

   1bitsgd incorporated into cntk
     * 1bitsgd source code is now available with cntk license (mit
       license) under source/1bitsgd/
     * 1bitsgd build target was merged into existing gpu target

   new id168: hierarchical softmax
     * thanks @yaochengji for the contribution!

   distributed training with multiple learners
     * trainer now accepts multiple parameter learners for distributed
       training. with this change, different parameters of a network can
       be learned by different learners in a single training session. this
       also facilitates distributed training for gans. for more
       information, please refer to the [167]basic_gan_distributed.py and
       the [168]cntk.learners.distributed_multi_learner_test.py

   operators
     * added meanvarianceid172 operator.

   bug fixes
     * fixed convergence issue in tutorial 201b
     * fixed pooling/unpooling to support free dimension for sequences
     * fixed crash in cntkbinaryformat deserializer when crossing sweep
       boundary
     * fixed shape id136 bug in id56 step function for scalar
       broadcasting
     * fixed a build bug when mpi=no
     * improved distributed training aggregation speed by increasing
       packing threshold, and expose the knob in v2
     * fixed a memory leak in mkl layout
     * fixed a bug in cntk.convert api in misc.converter.py, which
       prevents converting complex networks.

   onnx
     * updates
          + cntk exported onnx models are now onnx.checker compliant.
          + added onnx support for cntk   s optimizedid56stack operator (lstm
            only).
          + added support for lstm and gru operators
          + added support for experimental onnx op
            meanvarianceid172.
          + added support for experimental onnx op identity.
          + added support for exporting cntk   s layerid172 layer
            using onnx meanvarianceid172 op.
     * bug or minor fixes:
          + axis attribute is optional in cntk   s onnx concat operator.
          + bug fix in onnx broadcasting for scalars.
          + bug fix in onnx convtranspose operator.
          + backward compatibility bug fix in leakyrelu (argument    alpha   
            reverted to type double).

   misc
     * added a new api find_by_uid() under cntk.logging.graph.
     __________________________________________________________________

   2018-02-28. cntk supports nightly build

   if you prefer to use latest cntk bits from master, use one of the cntk
   nightly package.
     * [169]nightly packages for windows
     * [170]nightly packages for linux

   alternatively, you can also click corresponding build badge to land to
   nightly build page.
     __________________________________________________________________

   2018-01-31. cntk 2.4

   highlights:
     * moved to cuda9, cudnn 7 and visual studio 2017.
     * removed python 3.4 support.
     * added volta gpu and fp16 support.
     * better onnx support.
     * cpu perf improvement.
     * more ops.

   ops
     * top_k operation: in the forward pass it computes the top (largest)
       k values and corresponding indices along the specified axis. in the
       backward pass the gradient is scattered to the top k elements (an
       element not in the top k gets a zero gradient).
     * gather operation now supports an axis argument
     * squeeze and expand_dims operations for easily removing and adding
       singleton axes
     * zeros_like and ones_like operations. in many situations you can
       just rely on cntk correctly broadcasting a simple 0 or 1 but
       sometimes you need the actual tensor.
     * depth_to_space: rearranges elements in the input tensor from the
       depth dimension into spatial blocks. typical use of this operation
       is for implementing sub-pixel convolution for some image
       super-resolution models.
     * space_to_depth: rearranges elements in the input tensor from the
       spatial dimensions to the depth dimension. it is largely the
       inverse of depthtospace.
     * sum operation: create a new function instance that computes
       element-wise sum of input tensors.
     * softsign operation: create a new function instance that computes
       the element-wise softsign of a input tensor.
     * asinh operation: create a new function instance that computes the
       element-wise asinh of a input tensor.
     * log_softmax operation: create a new function instance that computes
       the logsoftmax normalized values of a input tensor.
     * hard_sigmoid operation: create a new function instance that
       computes the hard_sigmoid normalized values of a input tensor.
     * element_and, element_not, element_or, element_xor element-wise
       logic operations
     * reduce_l1 operation: computes the l1 norm of the input tensor's
       element along the provided axes.
     * reduce_l2 operation: computes the l2 norm of the input tensor's
       element along the provided axes.
     * reduce_sum_square operation: computes the sum square of the input
       tensor's element along the provided axes.
     * image_scaler operation: alteration of image by scaling its
       individual values.

   onnx
     * there have been several improvements to onnx support in cntk.
     * updates
          + updated onnx reshape op to handle inferreddimension.
          + adding producer_name and producer_version fields to onnx
            models.
          + handling the case when neither auto_pad nor pads atrribute is
            specified in onnx conv op.
     * bug fixes
          + fixed bug in onnx pooling op serialization
          + bug fix to create onnx inputvariable with only one batch axis.
          + bug fixes and updates to implementation of onnx transpose op
            to match updated spec.
          + bug fixes and updates to implementation of onnx conv,
            convtranspose, and pooling ops to match updated spec.

   operators
     * group convolution
          + fixed bug in group convolution. output of cntk convolution op
            will change for groups > 1. more optimized implementation of
            group convolution is expected in the next release.
          + better error reporting for group convolution in convolution
            layer.

   halide binary convolution
     * the cntk build can now use optional [171]halide libraries to build
       cntk.binaryconvolution.so/dll library that can be used with the
       netopt module. the library contains optimized binary convolution
       operators that perform better than the python based binarized
       convolution operators. to enable halide in the build, please
       download [172]halide release and set halide_path environment
       varibale before starting a build. in linux, you can use ./configure
       --with-halide[=directory] to enable it. for more information on how
       to use this feature, please refer to
       [173]how_to_use_network_optimization.

   see more in the [174]release notes. get the release from the [175]cntk
   releases page.
     __________________________________________________________________

   2018-01-22. cntk support for cuda 9

   cntk now supports cuda 9/cudnn 7. this requires an update to build
   environment to ubuntu 16/gcc 5 for linux, and visual studio
   2017/vctools 14.11 for windows. with cuda 9, cntk also added a preview
   for 16-bit floating point (a.k.a fp16) computation.

   please check out the example of fp16 in resnet50 [176]here

   notes on fp16 preview:
     * fp16 implementation on cpu is not optimized, and it's not supposed
       to be used in cpu id136 directly. user needs to convert the
       model to 32-bit floating point before running on cpu.
     * loss/criterion for fp16 training needs to be 32bit for accumulation
       without overflow, using cast function. please check the example
       above.
     * readers do not have fp16 output unless using numpy to feed data,
       cast from fp32 to fp16 is needed. please check the example above.
     * fp16 gradient aggregation is currently only implemented on gpu
       using nccl2. distributed training with fp16 with mpi is not
       supported.
     * fp16 math is a subset of current fp32 implementation. some model
       may get feature not implemented exception using fp16.
     * fp16 is currently not supported in brainscript. please use python
       for fp16.

   to setup build and runtime environment on windows:
     * install [177]visual studio 2017 with following workloads and
       components. from command line (use community version installer as
       example): vs_community.exe --add
       microsoft.visualstudio.workload.nativedesktop --add
       microsoft.visualstudio.workload.manageddesktop --add
       microsoft.visualstudio.workload.universal --add
       microsoft.component.pythontools --add
       microsoft.visualstudio.component.vc.tools.14.11
     * install [178]nvidia cuda 9
     * from powershell, run: [179]devinstall.ps1
     * start vctools 14.11 command line, run: cmd /k
       "%vs2017installdir%\vc\auxiliary\build\vcvarsall.bat" x64
       --vcvars_ver=14.11
     * open [180]cntk.sln from the vctools 14.11 command line. note that
       starting cntk.sln other than vctools 14.11 command line, would
       causes cuda 9 [181]build error.

   to setup build and runtime environment on linux using docker, please
   build unbuntu 16.04 docker image using dockerfiles [182]here. for other
   linux systems, please refer to the dockerfiles to setup dependent
   libraries for cntk.

     *    2019 github, inc.
     * [183]terms
     * [184]privacy
     * [185]security
     * [186]status
     * [187]help

     * [188]contact github
     * [189]pricing
     * [190]api
     * [191]training
     * [192]blog
     * [193]about

   (button) you can   t perform that action at this time.

   you signed in with another tab or window. [194]reload to refresh your
   session. you signed out in another tab or window. [195]reload to
   refresh your session.

   (button)

references

   visible links
   1. https://github.com/opensearch.xml
   2. https://github.com/microsoft/cntk/commits/master.atom
   3. https://github.com/microsoft/cntk#start-of-content
   4. https://github.com/features
   5. https://github.com/features/code-review/
   6. https://github.com/features/project-management/
   7. https://github.com/features/integrations
   8. https://github.com/features/actions
   9. https://github.com/features#team-management
  10. https://github.com/features#social-coding
  11. https://github.com/features#documentation
  12. https://github.com/features#code-hosting
  13. https://github.com/customer-stories
  14. https://github.com/security
  15. https://github.com/enterprise
  16. https://github.com/explore
  17. https://github.com/topics
  18. https://github.com/collections
  19. https://github.com/trending
  20. https://lab.github.com/
  21. https://opensource.guide/
  22. https://github.com/events
  23. https://github.community/
  24. https://education.github.com/
  25. https://github.com/marketplace
  26. https://github.com/pricing
  27. https://github.com/pricing#feature-comparison
  28. https://enterprise.github.com/contact
  29. https://github.com/nonprofit
  30. https://education.github.com/
  31. https://github.com/login?return_to=/microsoft/cntk
  32. https://github.com/join
  33. https://github.com/login?return_to=/microsoft/cntk
  34. https://github.com/microsoft/cntk/watchers
  35. https://github.com/login?return_to=/microsoft/cntk
  36. https://github.com/microsoft/cntk/stargazers
  37. https://github.com/login?return_to=/microsoft/cntk
  38. https://github.com/microsoft/cntk/network/members
  39. https://github.com/microsoft
  40. https://github.com/microsoft/cntk
  41. https://github.com/microsoft/cntk
  42. https://github.com/microsoft/cntk/issues
  43. https://github.com/microsoft/cntk/pulls
  44. https://github.com/microsoft/cntk/wiki
  45. https://github.com/microsoft/cntk/pulse
  46. https://github.com/join?source=prompt-code
  47. https://docs.microsoft.com/cognitive-toolkit/
  48. https://github.com/topics/cognitive-toolkit
  49. https://github.com/topics/cntk
  50. https://github.com/topics/deep-learning
  51. https://github.com/topics/machine-learning
  52. https://github.com/topics/deep-neural-networks
  53. https://github.com/topics/neural-network
  54. https://github.com/topics/distributed
  55. https://github.com/topics/python
  56. https://github.com/topics/c-plus-plus
  57. https://github.com/topics/c-sharp
  58. https://github.com/topics/java
  59. https://github.com/microsoft/cntk/commits/master
  60. https://github.com/microsoft/cntk/branches
  61. https://github.com/microsoft/cntk/releases
  62. https://github.com/microsoft/cntk/graphs/contributors
  63. https://github.com/microsoft/cntk/blob/master/license.md
  64. https://github.com/microsoft/cntk/search?l=c++
  65. https://github.com/microsoft/cntk/search?l=jupyter-notebook
  66. https://github.com/microsoft/cntk/search?l=python
  67. https://github.com/microsoft/cntk/search?l=cuda
  68. https://github.com/microsoft/cntk/search?l=c#
  69. https://github.com/microsoft/cntk/search?l=shell
  70. https://github.com/microsoft/cntk/find/master
  71. https://github.com/microsoft/cntk/archive/master.zip
  72. https://github.com/login?return_to=https://github.com/microsoft/cntk
  73. https://github.com/join?return_to=/microsoft/cntk
  74. https://desktop.github.com/
  75. https://desktop.github.com/
  76. https://developer.apple.com/xcode/
  77. https://visualstudio.github.com/
  78. https://github.com/rpengms
  79. https://github.com/microsoft/cntk/commits?author=rpengms
  80. https://github.com/microsoft/cntk/commit/9688ac6aea6e670a3136abc2132705ffc5a427de
  81. https://github.com/microsoft/cntk/pull/3617
  82. https://github.com/microsoft/cntk/commit/9688ac6aea6e670a3136abc2132705ffc5a427de
  83. https://github.com/microsoft/cntk/commit/9688ac6aea6e670a3136abc2132705ffc5a427de
  84. https://github.com/microsoft/cntk/tree/9688ac6aea6e670a3136abc2132705ffc5a427de
  85. https://github.com/microsoft/cntk/tree/master/documentation
  86. https://github.com/microsoft/cntk/commit/4765f69c7a557cbd0c573b40f5fb6b1ba4ebce69
  87. https://github.com/microsoft/cntk/tree/master/examples
  88. https://github.com/microsoft/cntk/tree/master/manual
  89. https://github.com/microsoft/cntk/commit/82d350d0ac4f2548f8e2ba33af5353a56d724a40
  90. https://github.com/microsoft/cntk/tree/master/pretrainedmodels
  91. https://github.com/microsoft/cntk/tree/master/scripts
  92. https://github.com/microsoft/cntk/commit/f48e11c1239f4fca68c0d5e95c86e541184e8ff7
  93. https://github.com/microsoft/cntk/tree/master/source
  94. https://github.com/microsoft/cntk/commit/9688ac6aea6e670a3136abc2132705ffc5a427de
  95. https://github.com/microsoft/cntk/pull/3617
  96. https://github.com/microsoft/cntk/commit/9688ac6aea6e670a3136abc2132705ffc5a427de
  97. https://github.com/microsoft/cntk/tree/master/tests
  98. https://github.com/microsoft/cntk/commit/49d4c2dea71a88ad93f06516cda6bc5c8d27ee6f
  99. https://github.com/microsoft/cntk/tree/master/tools
 100. https://github.com/microsoft/cntk/tree/master/tutorials
 101. https://github.com/microsoft/cntk/commit/764c8c4e313cd4831d5d43e9ee0605b06b35ebb1
 102. https://github.com/microsoft/cntk/tree/master/bindings
 103. https://github.com/microsoft/cntk/commit/4765f69c7a557cbd0c573b40f5fb6b1ba4ebce69
 104. https://github.com/microsoft/cntk/tree/master/external
 105. https://github.com/microsoft/cntk/blob/master/.clang-format
 106. https://github.com/microsoft/cntk/blob/master/.gitattributes
 107. https://github.com/microsoft/cntk/blob/master/.gitignore
 108. https://github.com/microsoft/cntk/blob/master/.gitmodules
 109. https://github.com/microsoft/cntk/commit/e2d79d7da03e879bb89a9befcb685214a893f974
 110. https://github.com/microsoft/cntk/blob/master/cmakelists.txt
 111. https://github.com/microsoft/cntk/blob/master/cntk.common.props
 112. https://github.com/microsoft/cntk/commit/4ed189633247ce4a5a6d3c5f1f77422cdd66dc6c
 113. https://github.com/microsoft/cntk/blob/master/cntk.cpp.props
 114. https://github.com/microsoft/cntk/blob/master/cntk.sln
 115. https://github.com/microsoft/cntk/blob/master/contributing.md
 116. https://github.com/microsoft/cntk/commit/5ecc8347226a866bfbb2119823f0120221bfe156
 117. https://github.com/microsoft/cntk/blob/master/cppcntk.vssettings
 118. https://github.com/microsoft/cntk/commit/5c0ccb6f44614047a7d7f1cf05e3d3511173fe3e
 119. https://github.com/microsoft/cntk/blob/master/license.md
 120. https://github.com/microsoft/cntk/commit/819baf083082af571200d2444565793482aa578a
 121. https://github.com/microsoft/cntk/blob/master/makefile
 122. https://github.com/microsoft/cntk/blob/master/readme.md
 123. https://github.com/microsoft/cntk/commit/6ef0224aa54e24cf0a5b6c94c73a34ae134fafa6
 124. https://github.com/microsoft/cntk/blob/master/thirdpartynotices.md
 125. https://github.com/microsoft/cntk/blob/master/configure
 126. https://gitter.im/microsoft/cntk?utm_source=badge&utm_medium=badge&utm_campaign=pr-badge&utm_content=badge
 127. https://cntk.ai/nightly-windows.html
 128. https://cntk.ai/nightly-linux.html
 129. https://cntk.ai/
 130. https://docs.microsoft.com/en-us/cognitive-toolkit/setup-cntk-on-your-machine
 131. https://docs.microsoft.com/en-us/cognitive-toolkit/setup-windows-python
 132. https://docs.microsoft.com/en-us/cognitive-toolkit/setup-windows-binary-script
 133. https://docs.microsoft.com/en-us/cognitive-toolkit/setup-windows-binary-manual
 134. https://docs.microsoft.com/en-us/cognitive-toolkit/setup-linux-python
 135. https://docs.microsoft.com/en-us/cognitive-toolkit/setup-linux-binary-script
 136. https://docs.microsoft.com/en-us/cognitive-toolkit/setup-linux-binary-manual
 137. https://docs.microsoft.com/en-us/cognitive-toolkit/cntk-docker-containers
 138. https://docs.microsoft.com/en-us/cognitive-toolkit/using-cntk-with-keras
 139. https://docs.microsoft.com/en-us/cognitive-toolkit/setup-development-environment
 140. https://docs.microsoft.com/en-us/cognitive-toolkit/setup-cntk-with-script-on-windows
 141. https://docs.microsoft.com/en-us/cognitive-toolkit/setup-cntk-on-windows
 142. https://docs.microsoft.com/en-us/cognitive-toolkit/setup-cntk-on-linux
 143. https://cntk.ai/nightly-windows.html
 144. https://cntk.ai/nightly-linux.html
 145. https://docs.microsoft.com/en-us/cognitive-toolkit/
 146. https://cntk.ai/pythondocs/
 147. https://docs.microsoft.com/en-us/cognitive-toolkit/cntk-evaluation-overview
 148. https://github.com/microsoft/cntk/tree/master/manual
 149. https://docs.microsoft.com/en-us/cognitive-toolkit/tutorials
 150. https://docs.microsoft.com/en-us/cognitive-toolkit/examples
 151. https://github.com/microsoft/cntk/blob/master/pretrainedmodels
 152. https://www.microsoft.com/en-us/cognitive-toolkit/blog/
 153. https://docs.microsoft.com/en-us/cognitive-toolkit/presentations
 154. https://github.com/microsoft/cntk/blob/master/license.md
 155. https://docs.microsoft.com/en-us/cognitive-toolkit/contributing-to-cntk
 156. https://docs.microsoft.com/en-us/cognitive-toolkit/cntk-faq
 157. https://docs.microsoft.com/en-us/cognitive-toolkit/feedback-channels
 158. https://opensource.microsoft.com/codeofconduct/
 159. https://opensource.microsoft.com/codeofconduct/faq/
 160. mailto:opencode@microsoft.com
 161. https://docs.microsoft.com/en-us/cognitive-toolkit/news
 162. https://github.com/lutzroeder/netron
 163. https://camo.githubusercontent.com/4eaf7364ba354f0445549cb6a78591e71f1f7a48/68747470733a2f2f636e746b2e61692f496d616765732f6e6574726f6e2f6e6574726f6e2d636e746b2d6461726b2d312e706e67
 164. https://camo.githubusercontent.com/e2551ea97065bb6f14da5f8e84bff654eaee03da/68747470733a2f2f636e746b2e61692f496d616765732f6e6574726f6e2f6e6574726f6e2d636e746b2d6c696768742d312e706e67
 165. https://github.com/microsoft/cntk/blob/master/examples/image/classification/mlp/python/simplemnist.py
 166. https://camo.githubusercontent.com/9578723a1db7c9767dbc0a5e3701a342919f7be3/68747470733a2f2f636e746b2e61692f496d616765732f50726f66696c657244657461696c576974684e6f646554696d696e672e6a7067
 167. https://github.com/microsoft/cntk/blob/master/examples/image/gan/basic_gan_distributed.py
 168. https://github.com/microsoft/cntk/blob/master/bindings/python/cntk/learners/tests/distributed_multi_learner_test.py
 169. https://cntk.ai/nightly-windows.html
 170. https://cntk.ai/nightly-linux.html
 171. http://halide-lang.org/
 172. https://github.com/halide/halide/releases
 173. https://github.com/microsoft/cntk/blob/master/manual/manual_how_to_use_network_optimizations.ipynb
 174. https://docs.microsoft.com/en-us/cognitive-toolkit/releasenotes/cntk_2_4_release_notes
 175. https://github.com/microsoft/cntk/releases
 176. https://github.com/microsoft/cntk/blob/master/examples/image/classification/resnet/python/trainresnet_id163_distributed.py
 177. https://www.visualstudio.com/downloads/
 178. https://developer.nvidia.com/cuda-90-download-archive?target_os=windows&target_arch=x86_64
 179. https://github.com/microsoft/cntk/blob/master/tools/devinstall/windows/devinstall.ps1
 180. https://github.com/microsoft/cntk/blob/master/cntk.sln
 181. https://developercommunity.visualstudio.com/content/problem/163758/vs-2017-155-doesnt-support-cuda-9.html
 182. https://github.com/microsoft/cntk/blob/master/tools/docker
 183. https://github.com/site/terms
 184. https://github.com/site/privacy
 185. https://github.com/security
 186. https://githubstatus.com/
 187. https://help.github.com/
 188. https://github.com/contact
 189. https://github.com/pricing
 190. https://developer.github.com/
 191. https://training.github.com/
 192. https://github.blog/
 193. https://github.com/about
 194. https://github.com/microsoft/cntk
 195. https://github.com/microsoft/cntk

   hidden links:
 197. https://github.com/
 198. https://github.com/microsoft/cntk
 199. https://github.com/microsoft/cntk
 200. https://github.com/microsoft/cntk
 201. https://help.github.com/articles/which-remote-url-should-i-use
 202. https://github.com/microsoft/cntk#cntk
 203. https://github.com/microsoft/cntk#installation
 204. https://github.com/microsoft/cntk#installing-nightly-packages
 205. https://github.com/microsoft/cntk#learning-cntk
 206. https://github.com/microsoft/cntk#more-information
 207. https://github.com/microsoft/cntk#disclaimer
 208. https://github.com/microsoft/cntk#microsoft-open-source-code-of-conduct
 209. https://github.com/microsoft/cntk#news
 210. https://github.com/microsoft/cntk#project-changelog
 211. https://github.com/microsoft/cntk#efficient-group-convolution
 212. https://github.com/microsoft/cntk#sequential-convolution
 213. https://github.com/microsoft/cntk#operators
 214. https://github.com/microsoft/cntk#depth_to_space-and-space_to_depth
 215. https://github.com/microsoft/cntk#tan-and-atan
 216. https://github.com/microsoft/cntk#elu
 217. https://github.com/microsoft/cntk#convolution
 218. https://github.com/microsoft/cntk#default-arguments-order
 219. https://github.com/microsoft/cntk#bug-fixes
 220. https://github.com/microsoft/cntk#onnx
 221. https://github.com/microsoft/cntk#updates
 222. https://github.com/microsoft/cntk#bug-or-minor-fixes
 223. https://github.com/microsoft/cntk#net-support
 224. https://github.com/microsoft/cntk#bug-or-minor-fixes-1
 225. https://github.com/microsoft/cntk#misc
 226. https://github.com/
