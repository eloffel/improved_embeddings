   #[1]kdnuggets: analytics, big data, data mining and data science feed
   [2]kdnuggets    feed [3]kdnuggets    comments feed [4]kdnuggets    machine
   learning workflows in python from scratch part 1: data preparation
   comments feed [5]the evolving science of sentiment and emotion ai,
   id31 symposium, june 27-28 [6]top stories, may 22-28:
   analytics, data science, machine learning software poll results;
   machine learning crash course

kdnuggets

     [7]subscribe to kdnuggets news  | [8]twitter    [9]facebook
   [10]linkedin  |  [11]contact
   ____________________ search
   [menu-30.png]
   [search-icon.png]
     * [12]software
     * [13]news/blog
     * [14]top stories
     * [15]opinions
     * [16]tutorials
     * [17]jobs
     * [18]companies
     * [19]courses
     * [20]datasets
     * [21]education
     * [22]certificates
     * [23]meetings
     * [24]webinars


   [25]kdnuggets home    [26]news    [27]2017    [28]may    [29]tutorials,
   overviews    machine learning workflows in python from scratch part 1:
   data preparation ( [30]17:n21 )

gold blog, may 2017 machine learning workflows in python from scratch part 1:
data preparation

   [31][prv.gif] previous post
   [32]next post [nxt.gif]

     http likes 987
   tags: [33]data preparation, [34]machine learning, [35]python,
   [36]workflow

   this post is the first in a series of tutorials for implementing
   machine learning workflows in python from scratch, covering the coding
   of algorithms and related tools from the ground up. the end result will
   be a handcrafted ml toolkit. this post starts things off with data
   preparation.
     __________________________________________________________________

   by [37]matthew mayo, kdnuggets.

   it seems that, anymore, the perception of machine learning is often
   reduced to passing a series of arguments to a growing number of
   libraries and apis, hoping for magic, and awaiting the results. maybe
   you have a very good idea of what's going on under the hood in these
   libraries -- from data preparation to model building to results
   interpretation and visualization and beyond -- but you are still
   relying on these various tools to get the job done.

                                  python ml
             machine learning workflows in python. from scratch.

   and that's fine. using well-tested and proven implementations of tools
   for performing regular tasks makes sense for a whole host of reasons.
   reinventing wheels which don't roll efficiently is not best practice...
   it's limiting, and it takes an unnecessarily long time. whether you are
   using open source or proprietary tools to get your work done, these
   implementations have been honed by teams of individuals ensuring that
   you get your hands on the best quality instruments with which to
   accomplish your goals.

   however, there is often value in doing the dirty work yourself, even if
   as an educational endeavor. i wouldn't suggest coding your own
   distributed deep learning training framework from scratch -- at least,
   not normally -- but having gone through the trials and tribulations of
   writing up your own algorithm implementations and supporting tools from
   scratch at least once is a great idea. i could be wrong, but i don't
   think the vast majority of people learning machine learning, data
   science, artificial intelligence, or << insert related buzzword here >>
   today are actually doing this.

   so let's build some machine learning workflows in python. from scratch.


what do we mean by "from scratch?"


   first, let's clarify: when i say "from scratch," i mean using as few
   helping hands as possible. it's all relative, but for our purposes i
   will draw the line this side of writing our own matrix, dataframe,
   and/or graphing libraries, and as such we will lean on numpy, pandas,
   and matplotlib, respectively. we won't even use all of the available
   functionality of these libraries in some cases, as we will see shortly,
   bypassing them in the name of better understanding. anything in the
   standard python library is also fair game. beyond that, however, we're
   on our own.

   we will need to start somewhere, and so this post will begin by looking
   at some simple data preparation tasks. we're going to start slowly, but
   ramp up quickly over the next few posts after we get a feel for what it
   is we're doing. beyond data preparation, we will also need additional
   data transformation, results interpretation, and visualization tools --
   not to mention machine learning algorithms -- to complete our journey,
   all of which we will get to.

   the idea is to manually cobble together whatever non-trivial
   functionality we need to accomplish our machine learning tasks. as the
   series unfolds, we can add new tools and algorithms, as well as rethink
   some of our previous assumptions, making the entire process as much
   iterative as it will be progressive. step by step, we will focus on
   what our goals are, strategize on how to accomplish them, implement
   them in python, and then test them to see if they work.

   the end result, as it is presently envisioned, will be a set of simple
   python modules organized into our own simple machine learning library.
   for the uninitiated, i believe this will be invaluable experience
   toward understanding how machine learning processes, workflows, and
   algorithms work.


what do we mean by workflow?


   workflow can mean different things to different people, but we are
   generally talking about the entire process considered to be part of a
   machine learning project. there are numerous [38]process frameworks
   which can help us keep track of what it is we are doing, but let's
   simplify things for now to include the following:
     * get some data
     * process and/or prepare the data
     * build a model
     * interpret the results

   we can expand on these as we go, but this is our simple machine
   learning process framework for now. also, "pipeline" implies the
   ability to chain workflow functionality together, and so we will also
   keep this in mind moving forward.

                       [ml-pipeline-simplified-1.png]
               very simple machine learning process framework.


getting our data


   before we get to building any models, we need some data, and need to
   make sure this data conforms to some reasonable expectations. for
   testing purposes (not in the sense of training/testing, but testing our
   infrastructure), we will use the iris dataset, [39]which you can
   download here. given that various versions of the dataset can be found
   online, i suggest we all start from the same raw data in order to
   ensure all of our preparation steps work.

   let's take a look:

   iris head

   given what we know about such a simple dataset and its file, let's
   first think about what it is we will need to do to go from raw data to
   results:
     * data is stored in csv file
     * instances are made up mostly of numeric attribute values
     * class is categorical text

   now, none of what is above is universally applicable to all datasets,
   but neither is any of it specific to this dataset. this affords us the
   opportunity to write code we can hopefully later re-use. good coding
   practices we will focus on herein will include both reusability and
   modularity.

   some simple [40]exploratory data analysis is shown below.

   iris describe

                               iris histogram
   very simple exploratory data analysis of the iris dataset: description
    of the dataset (above), and default attribute distribution histograms
                                  (below).


preparing our data


   while the data preparation we need in this particular scenario is
   minimal, there is still some needed. specifically, we need to ensure
   that we account for the header row, remove any indexing that pandas
   automatically performs, and convert our class values from nominal to
   numeric. since we have no nominal values in the features we will use
   for modeling, there will be no more complex transformations required --
   at least, not yet.

   ultimately, we need a better data representation for our algorithm as
   well, and so we will make sure we end up with a matrix -- or numpy
   ndarray -- before we move on. our data preparation workflow, then,
   should take the following form:

                data processing preparation process framework
                    very simple data preparation process.

   also, note that there is no reason to believe that all interesting data
   is stored in comma separated files. we may want to grab data from a sql
   database or directly from the web at some point, which we will come
   back to and visit in the future.

   first, let's write a simple function to load a csv file into dataframe;
   sure, it's simple to do inline, but thinking ahead we may want to add
   some additional steps to our dataset loading function in the future.
   trust me here.

   this code is quite straightforward. reading data files line by line
   easily allows for some additional pre-processing, such as ignoring
   non-data lines (we are assuming comments in data files begin with '#'
   at the moment, however ridiculous). we can specify whether or not the
   dataset file includes a header, and we also allow for both csv and tsv
   files, with csv being the default.

   a bit of error checking exists, but it isn't terribly robust yet, so we
   may want to come back to this later. also, reading a file line by line
   and making decisions on what to do with these lines one by one will be
   slower than using built-in functionality to read clean, conforming csvs
   directly into a dataframe, but the trade-off to allow for more
   flexibility is worth it at this stage (but may take considerably longer
   with larger files). don't forget, if some of these inner workings don't
   seem like the best approach, we can always make changes later.

   before we try out our code, we need to first write a function to
   convert the nominal class values to numeric values. to generalize the
   function, we should allow it to be used on any attribute in the
   dataset, not only the class. we should also keep track of the mapping
   of attribute names to what will end up being integers. given our
   previous step of loading csv or tsv data files into pandas dataframes,
   this function should accept both a pandas dataframe as well as the
   attribute name to convert to numeric.

   also note that we are sidestepping a conversation about using one-hot
   encoding as relates to categorical non-class attributes, but i suspect
   we will return to that later.

   the above function is, again, simple, but accomplishes what we want it
   to. we could have approached this task in a number of different ways,
   including using built-in functionality of pandas, but starting off by
   getting our hands a bit dirty is what this is all about.

   at this point we can now load a dataset from file, and replace
   categorical attribute values with numeric values (we also keep a
   dictionary of those mappings for later). as previously mentioned, we
   want our dataset ultimately in the form of a numpy ndarray, in order to
   most easily use it with our algorithms. again, a simple task, but
   making it a function will allow us to build on it in the future if
   necessary.

   even if any of the preceding functions did not look like overkill, this
   one probably does. but bear with me; we're actually following sound --
   if overly cautious -- programming principles. there is a good chance as
   we move forward that we will come up with changes or additions to the
   functions we have built thus far. being able to implement these changes
   in one place, and have these changes well-documented, makes sense in
   the long term.


testing our data preparation workflow


   out workflow thus far may still be in building block form, but let's
   give our code a test.

  sepal_length sepal_width petal_length petal_width species
0          5.1         3.5          1.4         0.2  setosa
1          4.9           3          1.4         0.2  setosa
2          4.7         3.2          1.3         0.2  setosa
3          4.6         3.1          1.5         0.2  setosa
4            5         3.6          1.4         0.2  setosa

  sepal_length sepal_width petal_length petal_width  species
0          5.1         3.5          1.4         0.2        0
1          4.9           3          1.4         0.2        0
2          4.7         3.2          1.3         0.2        0
3          4.6         3.1          1.5         0.2        0
4            5         3.6          1.4         0.2        0

{'setosa': 0, 'versicolor': 1, 'virginica': 2}

[['5.1' '3.5' '1.4' '0.2' 0]
 ['4.9' '3' '1.4' '0.2' 0]
 ['4.7' '3.2' '1.3' '0.2' 0]
 ['4.6' '3.1' '1.5' '0.2' 0]
 ['5' '3.6' '1.4' '0.2' 0]
 ['5.4' '3.9' '1.7' '0.4' 0]
 ['4.6' '3.4' '1.4' '0.3' 0]
 ['5' '3.4' '1.5' '0.2' 0]
 ['4.4' '2.9' '1.4' '0.2' 0]
 ['4.9' '3.1' '1.5' '0.1' 0]]

   with our code working as we hoped it would, let's do some quick house
   cleaning. we will come up with a more comprehensive organizational
   structure for our code once we get rolling, but for now we should
   [41]add all of these functions to a single file, and save it as
   dataset.py. this will allow for more convenient reuse, which we will
   see next time.


looking ahead


   next, we will turn our attention to something of greater substance, an
   implementation of the id116 id91 algorithm. then we will have a
   look at a simple classification algorithm, k-nearest neighbors. we will
   see how we can build both classification and id91 models in the
   context of our simple workflows. undoubtedly, this will require coding
   some additional tools to help with out project, and i'm sure
   modifications will be needed to what we have done already.

   but that's alright; practicing machine learning is the best
   prescription for understanding machine learning. implementing the
   algorithms and support tools we need for our workflows should
   ultimately prove useful. i hope you have found this helpful enough to
   check the next installment.


   related:
     * [42]data preparation tips, tricks, and tools: an interview with the
       insiders
     * [43]pandas cheat sheet: data science and data wrangling in python
     * [44]simplifying decision tree interpretability with python &
       scikit-learn
     __________________________________________________________________

   [45][prv.gif] previous post
   [46]next post [nxt.gif]
     __________________________________________________________________

top stories past 30 days

                                              most popular
    1. [47]another 10 free must-read books for machine learning and data
       science
    2. [48]9 must-have skills you need to become a data scientist, updated
    3. [49]who is a typical data scientist in 2019?
    4. [50]the pareto principle for data scientists
    5. [51]what no one will tell you about data science job applications
    6. [52]19 inspiring women in ai, big data, data science, machine
       learning
    7. [53]my favorite mind-blowing machine learning/ai breakthroughs

                                                most shared
    1. [54]id158s optimization using genetic algorithm
       with python
    2. [55]who is a typical data scientist in 2019?
    3. [56]8 reasons why you should get a microsoft azure certification
    4. [57]the pareto principle for data scientists
    5. [58]r vs python for data visualization
    6. [59]how to work in data science, ai, big data
    7. [60]the deep learning toolset     an overview

[61]latest news

     * [62]download your datax guide to ai in marketing
     * [63]kdnuggets offer: save 20% on strata in london
     * [64]training a champion: building deep neural nets for big ...
     * [65]building a recommender system
     * [66]predict age and gender using convolutional neural netwo...
     * [67]top tweets, mar 27     apr 02: here is a great ex...

more recent stories

     * [68]top tweets, mar 27     apr 02: here is a great explanat...
     * [69]odsc east is selling out; odsc india announced
     * [70]accelerate ai and data science career expo, may 4, 2019
     * [71]grow your data career at datasciencego, san diego, sep 27-29
     * [72]getting started with nlp using the pytorch framework
     * [73]how to diy your data science education
     * [74]top 8 data science use cases in gaming
     * [75]kdnuggets 19:n13, apr 3: top 10 data scientist coding mista...
     * [76]make better data-driven business decisions
     * [77]top stories, mar 25-31: r vs python for data visualization;
       th...
     * [78]two predictive analytics world events in europe this fall
     * [79]7 qualities your big data visualization tools absolutely must
       ...
     * [80]yeshiva university: tenure-track faculty in ai and machine
       lea...
     * [81]which face is real?
     * [82]yeshiva university: program director / tenure track faculty
       me...
     * [83]top 10 coding mistakes made by data scientists
     * [84]uber   s case study at paw industry 4.0: machine learning ...
     * [85]xai     a data scientist   s mouthpiece
     * [86]what does gpt-2 think about the ai arms race?
     * [87]openclassrooms: data freelance online course creator
       [telecomm...

   [88]kdnuggets home    [89]news    [90]2017    [91]may    [92]tutorials,
   overviews    machine learning workflows in python from scratch part 1:
   data preparation ( [93]17:n21 )
      2019 kdnuggets. [94]about kdnuggets.  [95]privacy policy. [96]terms
   of service

   [97]subscribe to kdnuggets news
   [98][tw_c48.png] [99]facebook [100]linkedin
   x
   [envelope.png] [101]get kdnuggets, a leading newsletter on ai, data
   science, and machine learning
   email: ______________________________
   sign up
   leave this field empty if you're human: ____________________

references

   visible links
   1. https://www.kdnuggets.com/feed/
   2. https://www.kdnuggets.com/feed
   3. https://www.kdnuggets.com/comments/feed
   4. https://www.kdnuggets.com/2017/05/machine-learning-workflows-python-scratch-part-1.html/feed
   5. https://www.kdnuggets.com/2017/05/sentiment-evolving-science-emotion-ai.html
   6. https://www.kdnuggets.com/2017/05/top-news-week-0522-0528.html
   7. https://www.kdnuggets.com/news/subscribe.html
   8. https://twitter.com/kdnuggets
   9. https://www.facebook.com/kdnuggets
  10. https://www.linkedin.com/groups/54257/
  11. https://www.kdnuggets.com/contact.html
  12. https://www.kdnuggets.com/software/index.html
  13. https://www.kdnuggets.com/news/index.html
  14. https://www.kdnuggets.com/news/top-stories.html
  15. https://www.kdnuggets.com/opinions/index.html
  16. https://www.kdnuggets.com/tutorials/index.html
  17. https://www.kdnuggets.com/jobs/index.html
  18. https://www.kdnuggets.com/companies/index.html
  19. https://www.kdnuggets.com/courses/index.html
  20. https://www.kdnuggets.com/datasets/index.html
  21. https://www.kdnuggets.com/education/index.html
  22. https://www.kdnuggets.com/education/analytics-data-mining-certificates.html
  23. https://www.kdnuggets.com/meetings/index.html
  24. https://www.kdnuggets.com/webcasts/index.html
  25. https://www.kdnuggets.com/
  26. https://www.kdnuggets.com/news/index.html
  27. https://www.kdnuggets.com/2017/index.html
  28. https://www.kdnuggets.com/2017/05/index.html
  29. https://www.kdnuggets.com/2017/05/tutorials.html
  30. https://www.kdnuggets.com/2017/n21.html
  31. https://www.kdnuggets.com/2017/05/sentiment-evolving-science-emotion-ai.html
  32. https://www.kdnuggets.com/2017/05/top-news-week-0522-0528.html
  33. https://www.kdnuggets.com/tag/data-preparation
  34. https://www.kdnuggets.com/tag/machine-learning
  35. https://www.kdnuggets.com/tag/python
  36. https://www.kdnuggets.com/tag/workflow
  37. https://www.kdnuggets.com/author/matt-mayo
  38. https://www.kdnuggets.com/2016/03/data-science-process-rediscovered.html
  39. https://raw.githubusercontent.com/uiuc-cse/data-fa14/gh-pages/data/iris.csv
  40. https://www.kdnuggets.com/2017/04/value-exploratory-data-analysis.html
  41. https://gist.github.com/mmmayo13/9859a457760db10ec4842be3aa1a2334
  42. https://www.kdnuggets.com/2016/10/data-preparation-tips-tricks-tools.html
  43. https://www.kdnuggets.com/2017/01/pandas-cheat-sheet.html
  44. https://www.kdnuggets.com/2017/05/simplifying-decision-tree-interpretation-decision-rules-python.html
  45. https://www.kdnuggets.com/2017/05/sentiment-evolving-science-emotion-ai.html
  46. https://www.kdnuggets.com/2017/05/top-news-week-0522-0528.html
  47. https://www.kdnuggets.com/2019/03/another-10-free-must-read-books-for-machine-learning-and-data-science.html
  48. https://www.kdnuggets.com/2018/05/simplilearn-9-must-have-skills-data-scientist.html
  49. https://www.kdnuggets.com/2019/03/typical-data-scientist-2019.html
  50. https://www.kdnuggets.com/2019/03/pareto-principle-data-scientists.html
  51. https://www.kdnuggets.com/2019/03/data-science-job-applications.html
  52. https://www.kdnuggets.com/2019/03/women-ai-big-data-science-machine-learning.html
  53. https://www.kdnuggets.com/2019/03/favorite-ml-ai-breakthroughs.html
  54. https://www.kdnuggets.com/2019/03/artificial-neural-networks-optimization-genetic-algorithm-python.html
  55. https://www.kdnuggets.com/2019/03/typical-data-scientist-2019.html
  56. https://www.kdnuggets.com/2019/03/simplilearn-8-reasons-microsoft-azure-certification.html
  57. https://www.kdnuggets.com/2019/03/pareto-principle-data-scientists.html
  58. https://www.kdnuggets.com/2019/03/r-vs-python-data-visualization.html
  59. https://www.kdnuggets.com/2019/03/work-data-science-ai-big-data.html
  60. https://www.kdnuggets.com/2019/03/deep-learning-toolset-overview.html
  61. https://www.kdnuggets.com/news/index.html
  62. https://www.kdnuggets.com/2019/04/datax-download-guide-ai-marketing.html
  63. https://www.kdnuggets.com/2019/04/strata-kdnuggets-offer-save-london.html
  64. https://www.kdnuggets.com/2019/04/sisense-deep-neural-nets-big-data-analytics.html
  65. https://www.kdnuggets.com/2019/04/building-recommender-system.html
  66. https://www.kdnuggets.com/2019/04/predict-age-gender-using-convolutional-neural-network-opencv.html
  67. https://www.kdnuggets.com/2019/04/top-tweets-mar27-apr02.html
  68. https://www.kdnuggets.com/2019/04/top-tweets-mar27-apr02.html
  69. https://www.kdnuggets.com/2019/04/odsc-east-selling-out-india-announced.html
  70. https://www.kdnuggets.com/jobs/19/04-03-accelerate-ai-data-science-career-expo-2019.html
  71. https://www.kdnuggets.com/2019/04/formulated-data-career-datasciencego-san-diego.html
  72. https://www.kdnuggets.com/2019/04/nlp-pytorch.html
  73. https://www.kdnuggets.com/2019/04/diy-your-data-science-education.html
  74. https://www.kdnuggets.com/2019/04/top-8-data-science-use-cases-gaming.html
  75. https://www.kdnuggets.com/2019/n13.html
  76. https://www.kdnuggets.com/2019/04/psu-make-better-data-driven-business-decisions.html
  77. https://www.kdnuggets.com/2019/04/top-news-week-0325-0331.html
  78. https://www.kdnuggets.com/2019/04/paw-two-predictive-analytics-world-events-europe-fall.html
  79. https://www.kdnuggets.com/2019/04/7-qualities-big-data-visualization-tools.html
  80. https://www.kdnuggets.com/jobs/19/04-02-yeshiva-university-faculty-ai-machine-learning.html
  81. https://www.kdnuggets.com/2019/04/which-face-real-stylegan.html
  82. https://www.kdnuggets.com/jobs/19/04-02-yeshiva-university-program-director-faculty-artificial-intelligence-machine-learning.html
  83. https://www.kdnuggets.com/2019/04/top-10-coding-mistakes-data-scientists.html
  84. https://www.kdnuggets.com/2019/04/paw-uber-case-study-machine-learning-enforce-mobile-performance.html
  85. https://www.kdnuggets.com/2019/04/xai-data-scientist.html
  86. https://www.kdnuggets.com/2019/04/gpt-2-think-about-ai-arms-race.html
  87. https://www.kdnuggets.com/jobs/19/04-01-openclassrooms-data-freelance-online-course-creator-b.html
  88. https://www.kdnuggets.com/
  89. https://www.kdnuggets.com/news/index.html
  90. https://www.kdnuggets.com/2017/index.html
  91. https://www.kdnuggets.com/2017/05/index.html
  92. https://www.kdnuggets.com/2017/05/tutorials.html
  93. https://www.kdnuggets.com/2017/n21.html
  94. https://www.kdnuggets.com/about/index.html
  95. https://www.kdnuggets.com/news/privacy-policy.html
  96. https://www.kdnuggets.com/terms-of-service.html
  97. https://www.kdnuggets.com/news/subscribe.html
  98. https://twitter.com/kdnuggets
  99. https://facebook.com/kdnuggets
 100. https://www.linkedin.com/groups/54257
 101. https://www.kdnuggets.com/news/subscribe.html

   hidden links:
 103. https://www.kdnuggets.com/
 104. https://www.kdnuggets.com/
