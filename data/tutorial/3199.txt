   #[1]publisher [2]medium [3]alternate

   [4]homepage
   [5]homepage
   [6]sign in[7]get started

   [8]safegraph
     * [9]about
     * [10]website
     __________________________________________________________________

   [1*solx4msi2wo0gsxjtkuleq.jpeg]

a non-technical introduction to machine learning

   [11]go to the profile of noah yonack
   [12]noah yonack (button) blockedunblock (button) followfollowing
   mar 3, 2017

why should i read this, and what will i learn?

   machine learning is a field that threatens to both augment and
   undermine exactly what it means to be human, and it   s becoming
   increasingly important that you   yes, you   actually understand it.

   i don   t think you should need to have a technical background to know
   what machine learning is or how it   s done. too much of the discussion
   about this field is either too technical or too uninformed, and,
   through this blog, i hope to level the playing field.

   this is for smart, ambitious people who want to know more about machine
   learning but who don   t care about the esoteric statistical and
   computational details underlying the field. you don   t need to know any
   math, statistics, or computer science to read and understand it.

   by the end of this post, you   ll:
    1. understand the basic logical framework of machine learning (ml).
    2. be able to define important relevant terms and concepts that anyone
       interested in this field should know. these terms are highlighted
       in boldface.
    3. know which high-level decisions go into building statistical
       models, and understand some of the implications of these decisions.
    4. be able to better analyze the question of when we should use the
       results of ml to make big decisions, such as determining public
       policy.

   this overview is in no way comprehensive. huge portions of the field
   are left out, either because they are too rare to merit study by
   non-technical decision makers, because they   re difficult to explain, or
   both.

what is machine learning?

   the field itself: ml is a field of study which harnesses principles of
   computer science and statistics to create statistical models. these
   models are generally used to do two things:
    1. prediction: make predictions about the future based on data about
       the past
    2. id136: discover patterns in data

   difference between ml and ai: there is no universally agreed upon
   distinction between ml and artificial intelligence (ai). ai usually
   concentrates on programming computers to make decisions (based on ml
   models and sets of logical rules), whereas ml focuses more on making
   predictions about the future.

   they are highly interconnected fields, and, for most non-technical
   purposes, they are the same.

what   s a statistical model?

   models: teaching a computer to make predictions involves feeding data
   into machine learning models, which are representations of how the
   world supposedly works. if i tell a statistical model that the world
   works a certain way (say, for example, that taller people make more
   money than shorter people), then this model can then tell me who it
   thinks will make more money, between cathy, who is 5   2   , and jill, who
   is 5   9   .

   what does a model actually look like? surely the concept of a model
   makes sense in the abstract, but knowing this is just half the battle.
   you should also know how it   s represented inside of a computer, or what
   it would look like if you wrote it down on paper.

   a model is just a mathematical function, which is merely a relationship
   between a set of inputs and a set of outputs. here   s an example:

   f(x) = x  

   this is a function that takes as input a number and returns that number
   squared. so, f(1) = 1, f(2) = 4, f(3) = 9.

   let   s briefly return to the example of the model that predicts income
   from height. i may believe, based on what i   ve seen in the corporate
   world, that a given human   s annual income is, on average, equal to her
   height (in inches) times 1,000. so, if you   re 60 inches tall (5 feet),
   then i   ll guess that you probably make $60,000 a year. if you   re a foot
   taller, i think you   ll make $72,000 a year.

   this model can be represented mathematically as follows:

   income = height    $1,000

   in other words, income is a function of height.

     here   s the main point: machine learning refers to a set of
     techniques for estimating functions (like the one involving income)
     based on datasets (pairs of heights and their associated incomes).
     these functions, which are called models, can then be used for
     predictions of future data.

   algorithms: these functions are estimated using algorithms. in this
   context, an algorithm is a predefined set of steps that takes as input
   a bunch of data and then transforms it through mathematical operations.
   you can think of an algorithm like a recipe         first do this, then do
   that, then do this. done.

   machine learning of all types uses models and algorithms as its
   building blocks to make predictions and id136s about the world.

   now i   ll show you how models actually work by breaking them apart,
   component by component. this next part is important.

a framework for understanding ml:

   inputs: statistical models learn from the past, formatted as structured
   tables of data (called training data). these datasets         such as those
   you might find in excel sheets         tend to be formatted in a very
   structured, easy-to-understand way: each row in the dataset represents
   an individual observation, also called a datum or measurement, and each
   column represents a different feature, also called a predictor, of an
   observation.

   for example, you might imagine a dataset about people, in which each
   row represents a different person, and each column represents a
   different feature about that person: height, weight, age, income, etc.

   most traditional models accept data formatted in the way i   ve just
   described. we call this structured data.

   because one common goal of ml is to make predictions (for example,
   about someone   s income), training data also includes a column
   containing the data you want to predict. this feature is called the
   response variable (or output variable, or dependent variable) and looks
   just like any other feature in the table.

   most common statistical models are constructed using a technique called
   supervised learning, which uses data that includes a response variable
   to make predictions or do id136. there is also a branch of ml
   called unsupervised learning, which doesn   t require a response variable
   and which is generally used just to find interesting patterns between
   variables (this pattern-finding process is known as id136). it is
   just as important as supervised learning, but it is usually much harder
   to understand and also less common in practice. this document won   t
   talk much about the latter subfield. the takeaway from this paragraph
   is simply that there are two    types    of learning, and that supervised
   learning is more common.

   continuing the people dataset example, we might try to predict
   someone   s income based on her name, age, and height, so our training
   dataset would look like this:
   [1*hwdxktlfmbao7z7aafbmlq.png]
   example of structured data. each row is a person (a unique observation
   we   ve made), and each column is a different measurement (called a
   feature or predictor) of that person.

   is this problem suitable for prediction? now that we have a dataset, we
   can begin building a statistical model.

   why should we do this? well, we assume that there   s some relationship
   between our predictors and our response         that income is somehow based
   on your age and your height, or a combination of the two. it   s
   reasonable to assume that you make more money as you get older, for
   instance, and that your height subtly influences your job prospects.

   we   ll leave the task of figuring out the exact details of the
   relationship (for instance, the precise role that age plays in
   determining your income) to the machine learning algorithm.

   model selection: we have our data, and we   ve decided that there   s
   probably a relationship between our predictors and our response. we   re
   ready to make predictions.

   as an aside, we don   t actually need to know if there   s a relationship
   between these variables. we could, in fact, just throw all of our data
   into an algorithm and see if the resulting model is able to make valid
   predictions.

   now we need to pick which model to use. naturally, there are many
   different types of models which explain how the data actually works,
   and we   d like to choose the one that most accurately describes the
   relationship between the predictors and the response variable.

   models generally fall into one of two categories:
    1. regression models, which are used when the response variable (i.e.
       the variable that you   re predicting) is continuous. for example,
       height, age, and income are all continuous. that is, they can be
       placed and ordered on a number line.
    2. classification models, which are used for categorical data         that
       is, data that doesn   t have a numerical ordering. for example, you
       may want to predict, based on an image of a flower, the species of
       that flower. or you may want to predict whether a student is a
       psychology major or a math major.

   the first step in picking a model is deciding whether or not your
   response variable is quantitative or categorical.
     __________________________________________________________________

   putting on the brakes: why is model selection an important concept for
   non-technical people? well, if a model is chosen poorly, then its
   predictions will be inaccurate, leading to tangible actions and
   policies that are uninformed. as a high-level decision maker, it   s
   important for you to question why certain models are being employed so
   that you don   t end up making even poorer decisions down the road.
     __________________________________________________________________

   below, i   ll walk you through an example of a popular, powerful, simple
   model from each category that can be used for prediction.

a common regression model: simple id75

   simple id75: chances are, you   ve constructed many simple
   id75 models in the past. again, a model is just a
   mathematical function, which describes a relationship between an input
   and an output.

   a (simple) id75 model is no different. we can describe the
   general case as follows:

   y = m    x + b

   the equation above relates the y value of a point to its x value.
   specifically, if we know the x value, we can get the y value by
   multiplying x by m (called the slope) and then adding b (called the y
   intercept).

   if you think that there exists a linear relationship between your
   features and your response         between, say, height and income         then you
   might be inclined to use a id75 model. in other words,
   this model is a good choice if you think you can describe the
   relationship between height and income with a straight line.

   so, let   s take this from the start. you find yourself with some data   
   [1*mfvdyzlmxbwlg0wndg4pua.png]
   structured training data for our simple id75 model.

      and you decide that you   d like to build a machine learning model to
   predict someone   s income based on their height.

   first, you   d plot the two variables on an xy-plane to visually observe
   the relationship. perhaps you   d see something like this:
   [0*-tblrnbtejl9rq0u.]
   a scatterplot of height vs. annual income. each blue dot is an
   individual observation.

   it looks like drawing a straight line somewhere through the blue dots
   would accurately characterize the visual relationship we   re seeing.
   this straight line, of course, can be described by the function i wrote
   out above:

   y = m    x + b

   now i   d like to build a id75 model. to do this, i train my
   model on my dataset: the id75 algorithm will estimate the
   values of m and b, giving us an equation for a line that we can then
   use for prediction.
     __________________________________________________________________

   putting on the brakes: we know that a model learns by looking at the
   training data and applying an algorithm. but what can go wrong if the
   training data is unrepresentative, biased, or incorrect?

   models don   t know whether or not training data is    good            that   s up
   the human who trains the model. unrepresentative training data can
   cause biased predictions which perpetuate social inequality.

   for example, imagine a situation in which a model used in the criminal
   justice system is trained on data which is biased against african
   americans. this model   s predictions, unsurprisingly, will then mirror
   that bias.
     __________________________________________________________________

   the details of the id75 algorithm aren   t totally
   important, but you should know that the algorithm isn   t random. it
   takes your training data, applies some fancy id202 to it, and
   comes back with the    best    possible line.

   here   s what that line might look like:
   [0*ttzvzcv7fp2wbp1t.]
   the id75 line (red) plotted against the true data (blue)

   the id75 model, then, can be written as follows:

   income = $989    height + $30,687

   this model implies that for every inch you grow, you can expect to make
   $989 more annually.
     __________________________________________________________________

   putting on the brakes: it   s unbelievably important to interpret these
   model parameters correctly. what we   ve found here is a correlation
   between height and income, not a causation. being taller doesn   t
   directly cause your income to increase, of course. rather, being tall
   usually means that people treat you with more respect (at least in
   western culture), which can give you a leg up in job interviews and
   salary negotiations, thereby increasing your income.

     this example teaches us a valuable lesson about ml: it   s not magic.
     it won   t discover fundamental truths about the world around us.
     rather, it will tell us how certain variables         like height and
     income         correlate with one another. concluding from the model above
     that height causes increased income is an incorrect conclusion, and
     failing to understand that these patterns are merely correlational
     might cause you to make inappropriate business or policy decisions
     down the road.
     __________________________________________________________________

   we now know enough to truly understand what the learning in machine
   learning means. many models, including id75, have
   parameters         which are variables (e.g. the m and the b in y = m    x +
   b) that the algorithm estimates (read: learns) by examining the
   training data. this process is called training.

   to drive this point home, the simple linear model used above has two
   parameters that needed learning: m and b. by running the linear
   regression algorithm, the model estimated m to be $989 and b to be
   $30,687.

   evaluation function: how do we know that this line is best? this is a
   subtle question, and there   s no universally agreed upon way to answer
   this question.

   best, of course, is a relative term, and, in this case, we   ve defined
   the best line to be the one that maximizes r   on the testing data
   (pronounced r-squared, also called the coefficient of determination),
   which we can calculate by applying an evaluation function to our
   results.

   an evaluation function is merely a way of determining just how good our
   predictions were. the way this is calculated in practice is to train a
   model on training data, but to reserve a handful of data (called
   testing data) for evaluation purposes.

   once your model is trained, you can hide the response variable in the
   testing set and run the rest of the test data through your model,
   resulting in a series of predictions. then, you can compare your
   predictions to the true values of the response variable in the testing
   set, and use the evaluation function to give you an exact determination
   of how well you did.

   r   is a very common evaluation function for regression models, though
   its explanation can get quite technical. it essentially describes how
      much    (measured as statistical variance) of our response (e.g. income)
   we can explain with our predictors (e.g. height).

   if r   is 1, then we can explain all of the variation in income, just by
   looking at height. that means height is a perfect predictor of income
   in the test set. in other words, we can make perfectly accurate
   predictions in the test set about someone   s income, just using
   knowledge about their height.
     __________________________________________________________________

   putting on the brakes: does an r   of 1 imply that we can always
   perfectly predict someone   s income given their height? no, and thinking
   so can have dangerous consequences.

   we received an r   of 1 by training our model on the training data and
   then predicting the response variable for the test data. we then
   compared our predictions to the true values of the response variable.
   what does this say about the validity of machine learning models?

   it tells us that machine learning models learn from the past, and they
   implicitly assume that the future is going to behave similarly. but
   sometimes the future changes         the relationship between height and
   income goes away when managers go through bias training         thus
   invalidating the model.

   what   s even more common is training on biased data in the first place,
   which might not accurately represent the phenomenon that we   re trying
   to measure. in building a training dataset for a model to predict
   income using height, i might be collecting data just from western
   cultures. is this model appropriate for eastern cultures, for which i
   don   t actually have training data? probably not.

   this has huge implications in learning systems that are [13]employed in
   the criminal justice system, for instance, which use models trained on
   data from the past. certainly we should remember to ask how recently
   the model was updated with fresh training data.

   we should also ask if the training data is comprehensive enough         what
   if our models never included training points from those under 60
   inches? is it fair to make predictions about people who are shorter
   than anyone else in our training set? is extrapolation just as fair as
   interpolation?
     __________________________________________________________________

   if r   is zero, then we can   t explain any of the variation in income by
   looking at height. this means that height tells us nothing about income
   in our training set         it   s a worthless predictor.

   this all means, of course, that a higher r   is better than a lower one.
   in machine learning jargon, a model with a higher r   is more predictive
   than a model with a lower r  .

   we could have also evaluated our model using a metric other than r  ,
   which would have caused our red line to look differently. in the
   medical domain, for instance, we may care more about eliminating
   under-predictions (of, say, cholesterol level) than about finding a
   line with the highest r  .

a common classification model: knn

   k-nearest neighbors (knn): knn is a powerful classification algorithm
   that is conceptually intuitive. it is exactly the type of model that a
   4-year-old might design, despite having never taken a math class.

   we   ll start with an example. let   s imagine that we   re contracting for
   the u.s. government, working on a team that wants to build and maintain
   an accurate dataset of which plots of land in the u.s. are vegetative
   (i.e. fertile) and which plots are not. having this dataset will help
   policymakers decide how to manage precious natural resources.

   a member of your team has already hand-labeled a few hundred
   latitude-longitude coordinates from a satellite image as being either
   vegetative or non-vegetative (see the plot below). your goal is to
   train a classification model that can take in a latitude-longitude pair
   (called a test datapoint) and predict whether or not it   s vegetative.
   [0*bnggnijpipwdo8cr.]
   a hand-labelled scatterplot. this example is inspired by cs109a, a
   course offered at harvard college in the fall of 2016.

   one of the most intuitive ways to solve this problem is to merely look
   at the test point   s closest neighbors. take, for example, a test point
   at (.35, .4), colored black below:
   [0*re2ieghilzrmrvpt.]

   we want to predict whether this coordinate represents a vegetative or a
   non-vegetative region. to do this, we can select, say, the 3 nearest
   dots. these three dots are all labeled as non-vegetative, so we   ll
   classify the test point as non-vegetative as well.
   [0*q31-zmvdigxbute8.]

   now we know why this model contains the phrase nearest
   neighbors   because we classify a test point based on that point   s
   already-classified neighbors. what   s the k for? simple: k is the number
   of neighbors we look at when determining how to classify a test point.

   if k is really small (say k = 1), we   ll only look at the singly closest
   neighbor when classifying our test point. if k is really large (say k =
   100), we   ll look at a huge range of neighbors before we make a
   classification.

   the k value that you choose when making classifications depends
   entirely on the problem at hand and is often not easily intuited.
   instead, data scientists will try plugging in many different values for
   k and seeing which value leads to the most accurate classifications.

   note that k is a parameter of the model, but it   s not necessarily a
   parameter that the model learns through training. rather, it   s a
   special parameter that the data scientist explicitly sets herself. we
   call these parameters hyperparameters, and you should know that a data
   scientist often decides which hyperparameter to use by evaluating a
   bunch of different possibilities for that hyperparameter (say, k = 1,
   5, 10, and 50). the process of evaluating these possible
   hyperparameters is called tuning.
     __________________________________________________________________

   putting on the brakes: why are hyperparameters important consideration
   for non-technical decision makers? it has to do with the way that most
   common software packages are implemented.

   most ml code libraries use default hyperparameters in the event that
   the data scientist forgets to explicitly set them herself. for example,
   if i forget to choose a value for k when running my knn model in code,
   the software will assume i wanted k to be, say, 5. but the value of k
   is important and can have big implications for the results of the
   model.

   should software packages be allowed to use default hyperparameters? i   m
   not sure. regardless, the important takeaway here is to always ask
   whether or not a model has been tuned properly         otherwise, it might
   not be doing its job correctly.
     __________________________________________________________________

lastly, a (very) brief discussion about artificial neural nets   

   it is not the goal of this post to describe in-detail how specific ml
   models work. that said, neural nets are especially important for
   non-technical readers because they   re incredibly powerful and are
   becoming ubiquitous in nearly any technology that merits the use of ml.
   [0*8u8utar_8q4ohhc1.]
   a toy neural net with 9 artificial neurons. borrowed from
   [14]https://en.wikipedia.org/wiki/artificial_neural_network

   neural nets are biologically inspired models, wherein collections of
   interconnected    neurons    (often called units or nodes) work together to
   transform input data to output data. each node applies a simple
   mathematical transformation to the data it receives; it then passes its
   result to the other nodes in its path.

   just as our brain contains billions of biological neurons, neural nets
   typically contain thousands or millions of these artificial neurons.

   each connection between nodes represents a different parameter to the
   model. this means, of course, that neural nets with millions of nodes
   have potentially billions of parameters associated with them.

   a common criticism of neural nets is that they are too difficult to
   interpret         that it   s too hard to understand    what   s going on    inside
   of them. this criticism springs from the fact that neural nets simply
   have too many parameters, most or all of which are determined via
   complex combinations of mathematical transformations to the training
   data. while a simple id75 has just two parameters (m and
   b), a neural network can have infinitely more, and it can be hard to
   figure out how they were calculated.
     __________________________________________________________________

   putting on the brakes: we often run into a trade off between a model   s
   interpretability and its predictive power. neural nets are hugely
   powerful, but are almost impossible to interpret. on the other hand,
   simple id75 is considerably easier to understand, but it   s
   generally not as powerful.

   should we trust the results of complicated neural nets if we can   t
   interpret their parameters? why might it be a good idea to trust neural
   nets used in criminal justice situations to determine sentence length?
   why might it be a bad idea?

   the answers to these questions are critically important. as a general
   rule of thumb, machine learning models have to balance a tradeoff
   between being easy to understand and being powerful. really powerful
   models like neural nets are often called black boxes because we   re not
   quite sure what   s inside of them, but these models can be extremely
   predictive.

   when building models         or when telling others to build them as a ceo or
   president or professor might do   we must decide what balance we   d like
   to strike between building models that are predictive and building
   models that are easy to understand.

   this balance almost always depends on the domain of the problem, of
   course. having a neural net predict who we should let out of jail is
   probably a poor idea, given how hard it is to understand exactly why
   the neural net is making certain predictions. on the hand, using a
   simple id75 is also inappropriate because its predictions
   will likely be poor.
     __________________________________________________________________

key takeaways:

   what are the big concepts that you should take away from this post? you
   should know that   
    1. machine learning combines computer science and statistics to create
       statistical models, which are then used to make predictions about
       the world or to infer patterns in your data.
    2. statistical models are really just mathematical functions (e.g. y =
       m    x + b). they are determined by their parameters (e.g. m and b),
       which are learned via the training process. models also have
       hyperparameters (e.g. the k in knn), which are tuned by trying out
       many possibilities.
    3. ml models learn from training data, which captures our knowledge
       about the past.
    4. there are, in general, two types of supervised models: those used
       for regression (like simple id75) and those used for
       classification (like knn).
    5. regardless of whether or not you   re building these models yourself,
       there are a handful of important ethical questions that require
       deep thought before you take action on the results of an ml model.

a parting message:

   people tend to view much of ml as magic, and i hoped i showed you that
   this assumption is far from the truth. assuming that models (like
   neural nets) are omniscient and infallible could potentially cause us
   to put too much faith in their output. knowing how many different
   components go into building a model should open your eyes to the many
   opportunities for bias and error in a model   s output, which should be
   fiercely scrutinized before being trusted.
     __________________________________________________________________

   join safegraph: we   re bringing together a world-class team, [15]see
   open positions.

     * [16]machine learning
     * [17]data science
     * [18]introduction
     * [19]non technical
     * [20]computer science

   (button)
   (button)
   (button) 613 claps
   (button) (button) (button) 13 (button) (button)

     (button) blockedunblock (button) followfollowing
   [21]go to the profile of noah yonack

[22]noah yonack

   data science @ safegraph. harvard    17. interested in machine learning
   and organizational behavior.

     (button) follow
   [23]safegraph

[24]safegraph

   safegraph news and data stories

     * (button)
       (button) 613
     * (button)
     *
     *

   [25]safegraph
   never miss a story from safegraph, when you sign up for medium.
   [26]learn more
   never miss a story from safegraph
   (button) get updatesget updates

references

   visible links
   1. https://plus.google.com/103654360130207659246
   2. https://blog.safegraph.com/osd.xml
   3. android-app://com.medium.reader/https/medium.com/p/b49fce202ae8
   4. https://medium.com/
   5. https://medium.com/
   6. https://medium.com/m/signin?redirect=https://blog.safegraph.com/a-non-technical-introduction-to-machine-learning-b49fce202ae8&source=--------------------------nav_reg&operation=login
   7. https://medium.com/m/signin?redirect=https://blog.safegraph.com/a-non-technical-introduction-to-machine-learning-b49fce202ae8&source=--------------------------nav_reg&operation=register
   8. https://blog.safegraph.com/?source=logo-lo_t6euqmnukn4p---9faf6e033b18
   9. https://blog.safegraph.com/about
  10. https://www.safegraph.com/?utm_source=blog
  11. https://blog.safegraph.com/@noahyonack?source=post_header_lockup
  12. https://blog.safegraph.com/@noahyonack
  13. https://www.propublica.org/article/machine-bias-risk-assessments-in-criminal-sentencing
  14. https://en.wikipedia.org/wiki/artificial_neural_network#/media/file:colored_neural_network.svg
  15. https://www.safegraph.com/careers
  16. https://blog.safegraph.com/tagged/machine-learning?source=post
  17. https://blog.safegraph.com/tagged/data-science?source=post
  18. https://blog.safegraph.com/tagged/introduction?source=post
  19. https://blog.safegraph.com/tagged/non-technical?source=post
  20. https://blog.safegraph.com/tagged/computer-science?source=post
  21. https://blog.safegraph.com/@noahyonack?source=footer_card
  22. https://blog.safegraph.com/@noahyonack
  23. https://blog.safegraph.com/?source=footer_card
  24. https://blog.safegraph.com/?source=footer_card
  25. https://blog.safegraph.com/
  26. https://medium.com/@medium/personalize-your-medium-experience-with-users-publications-tags-26a41ab1ee0c#.hx4zuv3mg

   hidden links:
  28. https://medium.com/p/b49fce202ae8/share/twitter
  29. https://medium.com/p/b49fce202ae8/share/facebook
  30. https://medium.com/p/b49fce202ae8/share/twitter
  31. https://medium.com/p/b49fce202ae8/share/facebook
