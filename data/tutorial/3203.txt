   #[1]publisher [2]medium [3]alternate

   [4]homepage
   [5]homepage
   [6]become a member[7]sign in[8]get started
     __________________________________________________________________

the anatomy of deep learning frameworks

   [9]go to the profile of gokula krishnan santhanam
   [10]gokula krishnan santhanam (button) blockedunblock (button)
   followfollowing
   jan 14, 2017

   deep learning, whether you like it or not is here to stay, and with any
   tech gold-rush comes a plethora of options that can seem daunting to
   newcomers.

   if you were to start off with deep learning, one of the first questions
   to ask is, which framework to learn? i   d say instead of a simple
   trial-and-error, if you try to understand the building blocks of all
   these frameworks, it would help you make an informed decision. common
   choices include [11]theano, [12]tensorflow, [13]torch, and [14]keras.
   all of these choices have their own pros and cons and have their own
   way of doing things. after exploring the white papers and the dev docs,
   i could understand the design choices and was able to abstract the
   fundamental concepts that are common to all of these.

   in this post, i have tried to sketch out these common principles which
   would help you better understand the frameworks and for the brave
   hearts among you, provide a guide on how to implement your own deep
   learning framework. the interesting thing about these principles is
   that they are not specific to dl alone, they are applicable whenever
   you want to do a series of computations on data. hence, most dl
   frameworks can be used for non-dl tasks as well (see
   [15]https://www.tensorflow.org/tutorials/mandelbrot/)

   there are a few core components of a dl framework, these are:
    1. a tensor object
    2. operations on the tensor object
    3. a computation graph and optimizations
    4. auto-differentiation tools
    5. blas / cublas and cudnn extensions

   these should make your framework complete, but you would need to polish
   it to make it more easy to use. i will be using references to the
   python numpy package in this article to make it easier to understand.
   if you haven   t used numpy before, fret not, this article should be easy
   to understand even if you skip the numpy parts. i   m a believer of
   understanding a system at multiple levels of abstractions so you will
   be seeing discussions of low-level optimizations interspersed with
   high-level calculus and id202. drop a comment below if
   something needs more explanation!

   note: i have been a contributor to theano and hence might be biased
   towards it in citing references. having said that, theano also has one
   of the most informative websites of all the frameworks i   ve come
   across.
     __________________________________________________________________

   a tensor object

   at the heart of the framework is the tensor object. a tensor is a
   generalization of a matrix to n-dimensions (think numpy   s ndarrays). in
   other words, a matrix is a two-dimensional tensor with (rows, columns).
   an easy way to understand tensors is to consider them as n-d arrays.

   as an example, take a color image. let   s say it   s an rgb bitmap image
   of size 258 x 320 (height x width). this is a three-dimensional tensor
   (height, width, channels). take a look at the following images to
   understand this better (taken from:
   [16]https://github.com/parambharat/carnd-helpers/blob/master/image_proc
   essing/image_processing_tutorial.ipynb)
   [0*sesx4_aw715qbgj_.]
   a normal rgb image
   [1*ive85-ts9v9di0zdcxhvia.png]
   red, green and blue channels of the same image
   [0*fld66pq-hgr4sjos.]
   the same image represented as a 3d tensor

   as an extension, a set of 100 images can be represented as a 4d tensor
   (id of image, height, width, channels).

   similarly, we represent all input data as tensors   before feeding them
   into the neural net. this is an abstraction necessary before we can
   feed data into a net, else we would have to define operations that work
   on each type and that   s a lot of wasted effort  . we would also need to
   be able to get back data in a form we want.

   so, we need a tensor object that supports storing the data in form of
   tensors. not just that, we would like the object to be able to convert
   other data types (images, text, video) into tensors and back. think of
   something like numpy.imread and numpy.imsave, they read images as
   ndarrays and store ndarrays as images respectively.

   the basic tensor object needs to support representing data in form of a
   tensor. this means supporting indexing, overloading operators, having a
   space efficient way to store the data and so on. depending on further
   design choices, you might have to add more features as well.

   operations on the tensor object

   a neural network can be considered as a series of operations performed
   on an input tensor to give an output. learning is done by correcting
   the errors between the output created by the net and the expected
   output  . these operations could be something simple like matrix
   multiplication (in sigmoids) or more complicated like convolutions,
   pooling or lstms.
   [0*otsckyvprjvybdor.]
   sigmoid layer represented as matrix operations, from
   http://www.datasciencecentral.com/profiles/blogs/matrix-multiplication-
   in-neural-networks

   check out the following links to get an idea of how extensive these
   operations could be:
    1. numpy:
       [17]http://www.scipy-lectures.org/intro/numpy/operations.html
    2. theano:
       [18]http://deeplearning.net/software/theano/library/tensor/basic.ht
       ml
    3. tensorflow:
       [19]https://www.tensorflow.org/api_docs/python/math_ops/

   you could just skip this part and ask the user to implement these
   operations themselves, but it is too cumbersome and outright
   inefficient. moreover, most operations are common enough that one could
   justify making them a part of the framework to spare headaches for the
   users. numpy does a pretty good job of having a lot of operations
   already implemented (it   s insanely fast as well) and there is a running
   theano [20]issue about incorporating more operations which show how
   important it is to have more operation supported by the framework.

   instead of implementing operations as functions, they are usually
   implemented as classes. this allows us to store more information about
   the operation like calculated shape of the output (useful for sanity
   checks), how to compute the gradient or the gradient itself (for the
   auto-differentiation), have ways to be able to decide whether to
   compute the op on gpu or cpu    and so on. again, this idea is similar to
   classes used for various algorithms implemented by scikit-learn. you
   could define a method called compute that does the actual computation
   and returns the tensor after the computation is done.

   these classes are usually derived from an abstract class (in theano,
   it   s the op class). this enforces a unified interface across the ops
   and also provide a way to add new ops later on. this makes the
   framework very flexible and ensures people can use it even as new
   network architectures and nonlinearities come along.

   computation graph and optimizations

   so far, we have classes for representing tensors and operations on
   them. the power of neural networks lies in the ability to chain
   multiple such operations to form a powerful approximator.

   therefore, the standard use case is that you can initialize a tensor,
   perform actions after actions on them and finally interpret the
   resulting tensor as labels or real values. sounds simple, enough?
   [0*8yjsnielgsce8grr.]
   chaining together different operations, taken from
   https://colah.github.io/posts/2015-08-backprop/

   unfortunately, as you chain more and more operations together, several
   issues arise that can drastically slow down your code and introduce
   bugs as well.

   1. start later ops only after the previous one is done or do them in
   parallel?

   2. how to assign to different devices and coordinate between them?

   3. how do you avoid redundant operations (multiplying with ones, adding
   zeros), cache useful intermediate values, and reduce multiple
   operations into one ( replace mul(mul(mul(tensor,2),2),2) with one
   mul(tensor, 8) )

   there are more such issues and it becomes necessary to be able to get a
   bigger picture to even notice that these issues exist. we need a way to
   optimize the resultant chain of operations for both space and time.

   in order to get a bigger picture, we introduce a computation graph
   which is basically an object that contains links to the instances of
   various ops and the relations between which operation takes the output
   of which operation as well as additional information. depending on the
   framework in question, this can be implemented in different ways.

   for example,
    1. theano
       [21]http://deeplearning.net/software/theano/extending/graphstructur
       es.html
    2. tensorflow
       [22]http://download.tensorflow.org/paper/whitepaper2015.pdf
    3. caffe[23]
       http://caffe.berkeleyvision.org/tutorial/net_layer_blob.html

   like many ideas in deep learning, the idea of computation graphs has
   been around for quite some time. take a look at any compilers textbook
   and you can find similar ideas in abstract syntax trees and
   intermediate representations used for optimization. these ideas have
   been extended and adapted to the deep learning scenario to give us the
   computational graph. the idea of optimizing the graph before code
   generation (will be covered later) is straightforward. the
   optimizations themselves could again be implemented as classes or
   functions    and could be selectively applied depending on whether you
   want the code to compile fast or run fast   .

   additionally, since you get a bird   s eye view of what will be happening
   in the network, the graph class can then decide on how to allocate gpu
   memory (like register allocation in compilers) and coordinate between
   various machines when deployed in a distributed environment. this helps
   us to effectively solve the three problems mentioned above.

   auto-differentiation tools

   another benefit of having the computational graph is that calculating
   gradients used in the learning phase becomes modular and
   straightforward to compute. this is thanks to the chain rule    that lets
   you calculate derivatives of composition of functions in a systematic
   way. as we saw earlier, neural nets can be thought of composition of
   simple nonlinearities giving rise to more complex functions.
   differentiating these functions is simply traversing the graph from the
   outputs back to the inputs   . symbolic differentiation or automatic
   differentiation    is a programmatic way by which gradients can be
   computed in a computation graph.

   symbolic differentiation refers to calculating the derivatives
   analytically i.e., you get an expression of what the gradient is. to
   use it, you simply plug in the values into the derivative and use it.
   unfortunately, some nonlinearities like relu (rectified linear units)
   are not differentiable at some points. so, we instead calculate the
   gradient in an iterative manner. since the second method could be used
   universally, most computational graph packages like computation graph
   toolkit([24]http://rll.berkeley.edu/cgt/) implement
   auto-differentiation but you can use symbolic differentiation if you
   are creating your own.

   it is usually not a good idea to roll out your own gradient computation
   module because it is easier and faster for the toolkit to provide it as
   part of the package. so, either have your own computation graph toolkit
   and auto-differentiation module or use an external package for both.

   since the derivative at each node has to computed with respect to only
   its adjacent nodes, the method to compute gradients can be added to the
   class           and can be invoked by the differentiation module.

   blas / cublas and cudnn extensions

   with all the above components, you can stop right now and have a fully
   functional deep learning framework. it would be able to take data as
   input and convert to tensors, perform operations on them in an
   efficient way, compute gradients to learn and return back results for
   the test dataset. the problem, however, lies in the fact that since you
   most likely implemented it in a high-level language (java / python /
   lua), there is an inherent upper limit to the speedups you can get.
   this is because even the simplest operations in a high-level language
   take more time (cpu cycles) than when done in a low-level language.

   in these situations, there are two different approaches we could take.

   the first one is an another analogy from compilers. the last step of a
   compilation process is hardware specific code generation in assembly.
   similarly, instead of running the graph written in the high-level
   language, the corresponding code for the network is generated in c and
   this is compiled and executed. the code for this is stored in each of
   the ops and can be combined together in the compilation phase    .
   transferring data to and from the low-level to high-level code is done
   by wrappers like pycuda and cython.

   the second approach is to have a backend implemented in a low-level
   language like c++, this means that the low-level language         high-level
   language interaction is internal to the framework unlike the previous
   approach and could be faster because we don   t need to compile the
   entire graph every time. instead, we could just call the compiled
   methods with the appropriate arguments    .

   another source of non-optimal behavior comes from slow implementations
   at the low-level language. it is difficult to write efficient code     
   and we will be better off using libraries that have optimized
   implementations of these methods. blas or basic id202
   subprograms are a collection of optimized matrix operations, initially
   written in fortran     . these can be leveraged to do very fast matrix
   (tensor) operations and can provide significant speedups. there are
   many other software packages like intel mkl, atlas which also perform
   similar functions. which one to choose is a personal preference.

   blas packages are usually optimized assuming that the instructions will
   be run on a cpu. in the deep learning situation, this is not the case
   and blas may not be able to fully exploit the parallelism offered by
   gpgpus. to solve this issue, nvidia has released cublas      which is
   optimized for gpus. this is now included with the cuda toolkit and is
   probably why not many people have heard of it. finally, cudnn      is a
   library that builds on the featureset of cublas and provides optimized
   neural network specific operations like winograd convolution and id56s.

   so, by using these packages, you could gain significant speed-ups in
   your framework. speed-ups are important in dl because it is the
   difference between training a neural network in four hours instead of
   four days. in the fast moving world of ai startups, that   s the
   difference between being a pioneer and playing a game of catch-up. so
   exploit parallelism and optimized libraries wherever you can!
     __________________________________________________________________

   conclusion

   we have finally come to the end of a pretty long post, thanks a lot for
   reading it. i hope i have demystified the anatomy of deep learning
   frameworks for many of you. my main goal in writing this post was to
   make concrete my understanding of how different frameworks are doing
   essentially the same thing. this will be a very helpful exercise for
   anyone who   s above a novice level but below a pro level (a semi-pro, if
   you will). once you can understand how things work behind the scenes,
   they become easier to approach and master. frameworks do a great job in
   abstracting away most of these ideas in order to provide a simple
   interface for the programmers. no wonder that most of these concepts
   are not very evident when you are learning a framework.

   as someone who   s interested in not just the applications of deep
   learning but also in the fundamental challenges of the field, i believe
   that knowing how things work under the hood is an important step
   towards mastery of the topic as it clears out many of the
   misunderstandings and provides a simpler way to think about why things
   are the way they are. i sincerely believe that a good worker knows not
   just which tool to use but also why that tool is the best choice. this
   blog is a step in that direction.

   hope you enjoyed reading this post as much as i did writing it. please
   do let me know your thoughts in the comments below!

   if you found this interesting, and want to know more about me, i   d love
   to hear from you! you can find my linkedin profile [25]here.

   footnotes

   [1] it   s not straightforward how you would represent text as tensors.
   the first way is to use a one-hot encoding, which is a very sparse
   matrix and wastes a lot of space. a more dense representation is word
   vectors. these are pretty cool and i probably might write another post
   on them if enough people are interested!

   [2] also, as you will see in the auto-differentiation part, it   s not
   clear how you would calculate the derivatives of words. they   re not
   even continuous!

   [3] this is the (in)famous id26 algorithm and is central to
   learning in multilayered neural networks.

   [4] this also means moving the data to gpu or back. i have noticed that
   in theano (possibly other frameworks as well), this is the most
   time-consuming part during execution.

   [5][26] http://www.deeplearning.net/software/theano/optimizations.html

   [6][27]
   http://deeplearning.net/software/theano/library/config.html#config.mode

   [7] d(f(g(x)) / dx = (df / dg) * (dg / dx). cf.[28]
   https://en.wikipedia.org/wiki/chain_rule

   [8] check out[29] https://colah.github.io/posts/2015-08-backprop/ for a
   more detailed discussion of derivatives on computational graphs

   [9][30] https://en.wikipedia.org/wiki/automatic_differentiation

   [10][31] https://www.tensorflow.org/how_tos/adding_an_op/

   [11][32]
   http://deeplearning.net/software/theano/tutorial/gradients.html

   [12][33]
   http://deeplearning.net/software/theano/extending/extending_theano_c.ht
   ml#methods-the-c-op-needs-to-define

   [13] both tensorflow and caffe do this.

   [14] if you are interested, you can check out the materials of[34]
   https://www.inf.ethz.ch/personal/markusp/teaching/263-2300-eth-spring11
   /course.html, will be taking this next sem :)

   [15][35] http://www.netlib.org/blas/

   [16][36] https://developer.nvidia.com/cublas

   [17][37] https://developer.nvidia.com/cudnn

     * [38]machine learning
     * [39]deep learning
     * [40]theano
     * [41]tensorflow
     * [42]framework

   (button)
   (button)
   (button) 228 claps
   (button) (button) (button) 7 (button) (button)

     (button) blockedunblock (button) followfollowing
   [43]go to the profile of gokula krishnan santhanam

[44]gokula krishnan santhanam

   masters student in cs at eth zurich, deep learning researcher,
   pythonista

     * (button)
       (button) 228
     * (button)
     *
     *

   [45]go to the profile of gokula krishnan santhanam
   never miss a story from gokula krishnan santhanam, when you sign up for
   medium. [46]learn more
   never miss a story from gokula krishnan santhanam
   (button) blockedunblock (button) followget updates

references

   visible links
   1. https://plus.google.com/103654360130207659246
   2. https://medium.com/osd.xml
   3. android-app://com.medium.reader/https/medium.com/p/46e2a7af5e47
   4. https://medium.com/
   5. https://medium.com/
   6. https://medium.com/membership?source=upgrade_membership---nav_full
   7. https://medium.com/m/signin?redirect=https://medium.com/@gokul_uf/the-anatomy-of-deep-learning-frameworks-46e2a7af5e47&source=--------------------------nav_reg&operation=login
   8. https://medium.com/m/signin?redirect=https://medium.com/@gokul_uf/the-anatomy-of-deep-learning-frameworks-46e2a7af5e47&source=--------------------------nav_reg&operation=register
   9. https://medium.com/@gokul_uf?source=post_header_lockup
  10. https://medium.com/@gokul_uf
  11. http://deeplearning.net/software/theano/
  12. https://www.tensorflow.org/
  13. http://torch.ch/
  14. https://keras.io/
  15. https://www.tensorflow.org/tutorials/mandelbrot/
  16. https://github.com/parambharat/carnd-helpers/blob/master/image_processing/image_processing_tutorial.ipynb
  17. http://www.scipy-lectures.org/intro/numpy/operations.html
  18. http://deeplearning.net/software/theano/library/tensor/basic.html
  19. https://www.tensorflow.org/api_docs/python/math_ops/
  20. https://github.com/theano/theano/issues/1916
  21. http://deeplearning.net/software/theano/extending/graphstructures.html
  22. http://download.tensorflow.org/paper/whitepaper2015.pdf
  23. http://caffe.berkeleyvision.org/tutorial/net_layer_blob.html
  24. http://rll.berkeley.edu/cgt/
  25. https://www.linkedin.com/in/sgokula/
  26. http://www.deeplearning.net/software/theano/optimizations.html
  27. http://deeplearning.net/software/theano/library/config.html#config.mode
  28. https://en.wikipedia.org/wiki/chain_rule
  29. https://colah.github.io/posts/2015-08-backprop/
  30. https://en.wikipedia.org/wiki/automatic_differentiation
  31. https://www.tensorflow.org/how_tos/adding_an_op/
  32. http://deeplearning.net/software/theano/tutorial/gradients.html
  33. http://deeplearning.net/software/theano/extending/extending_theano_c.html#methods-the-c-op-needs-to-define
  34. https://www.inf.ethz.ch/personal/markusp/teaching/263-2300-eth-spring11/course.html,
  35. http://www.netlib.org/blas/
  36. https://developer.nvidia.com/cublas
  37. https://developer.nvidia.com/cudnn
  38. https://medium.com/tag/machine-learning?source=post
  39. https://medium.com/tag/deep-learning?source=post
  40. https://medium.com/tag/theano?source=post
  41. https://medium.com/tag/tensorflow?source=post
  42. https://medium.com/tag/framework?source=post
  43. https://medium.com/@gokul_uf?source=footer_card
  44. https://medium.com/@gokul_uf
  45. https://medium.com/@gokul_uf
  46. https://medium.com/@medium/personalize-your-medium-experience-with-users-publications-tags-26a41ab1ee0c#.hx4zuv3mg

   hidden links:
  48. https://medium.com/p/46e2a7af5e47/share/twitter
  49. https://medium.com/p/46e2a7af5e47/share/facebook
  50. https://medium.com/p/46e2a7af5e47/share/twitter
  51. https://medium.com/p/46e2a7af5e47/share/facebook
