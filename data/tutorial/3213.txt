   an introduction to statistical learning

   with applications in r

   [1]gareth james, [2]daniela witten, [3]trevor hastie and [4]robert
   tibshirani

   [5]home [6]download the book pdf
   (corrected 7th printing)

   statistical learning mooc covering the entire isl book offered by
   trevor hastie and rob tibshirani. start anytime in self-paced mode.
   [7]about this book
   [8]r code for labs
   [9]data sets and figures
   [10]islr package
   [11]get the book
   [12]author bios
   [13]errata

   this book provides an introduction to statistical learning methods. it
   is aimed for upper level undergraduate students, masters students and
   ph.d. students in the non-mathematical sciences. the book also contains
   a number of r labs with detailed explanations on how to implement the
   various methods in real life settings, and should be a valuable
   resource for a practicing data scientist.

   winner of the 2014 eric ziegel award from technometrics.

   for a more advanced treatment of these topics: [14]the elements of
   statistical learning.

   slides and videos for statistical learning mooc by hastie and
   tibshirani available separately [15]here. slides and video tutorials
   related to this book by abass al sharif can be downloaded [16]here.

   "an introduction to statistical learning (isl)" by james, witten,
   hastie and tibshirani is the "how to'' manual for statistical learning.
   inspired by "the elements of statistical learning'' (hastie, tibshirani
   and friedman), this book provides clear and intuitive guidance on how
   to implement cutting edge statistical and machine learning methods. isl
   makes modern methods accessible to a wide audience without requiring a
   background in statistics or computer science. the authors give precise,
   practical explanations of what methods are available, and when to use
   them, including explicit r code. anyone who wants to intelligently
   analyze complex data should own this book.              larry
   wasserman, professor, department of statistics and department of
   machine learning, cmu.

   as a textbook for an introduction to data science through machine
   learning, there is much to like about islr. it   s thorough, lively,
   written at level appropriate  for undergraduates and usable by
   nonexperts. it   s chock full of interesting examples  of how modern
   predictive machine learning algorithms work (and don   t work) in a
   variety of settings." matthew richey, the american mathematical
   monthly, vol. 123, no. 7 (august-september 2016).

   "i just wanted to thank you all for the textbook    an introduction to
   statistical learning    that you have contributed to as authors.  as a
   junior at university, it is by far the most well-written textbook i
   have ever used, a sentiment mirrored by all my other classmates.  one
   friend, graduating this spring with majors in math and data analytics,
   cried out in anger that no other textbook had ever come close to the
   quality of this one.  you and your team have turned one of the most
   technical subjects in my curriculum into an understandable and even
   enjoyable field to learn about.  every concept is explained simply,
   every equation justified, and every figure chosen perfectly to clearly
   illustrate difficult ideas. this is the only textbook i have ever truly
   enjoyed reading, and i just wanted to thank you and all other
   contributors for your time and efforts in its production." cornell
   blake, junior, ohio state university.

   "as a former data scientist, there is no question i get asked more
   than,    what is the best way to learn statistics?    i always give the
   same answer: read an introduction to statistical learning. then, if you
   finish that and want more, read the elements of statistical learning.
   these two books, written by statistics professors at stanford
   university, the university of washington, and the university southern
   california, are the most intuitive and relevant books i   ve found on how
   to do statistics with modern technology." dan kopf, reporter, quartz.
   full review [17]here.


                             id75?
                          i covered that last year.
             wake me up when we get to support vector machines!
                                         noah mackey

references

   visible links
   1. http://www-bcf.usc.edu/~gareth
   2. http://www.biostat.washington.edu/~dwitten/
   3. http://www.stanford.edu/~hastie/
   4. http://www-stat.stanford.edu/~tibs/
   5. http://www-bcf.usc.edu/~gareth/isl/index.html
   6. http://www-bcf.usc.edu/~gareth/isl/islr seventh printing.pdf
   7. http://www-bcf.usc.edu/~gareth/isl/book.html
   8. http://www-bcf.usc.edu/~gareth/isl/code.html
   9. http://www-bcf.usc.edu/~gareth/isl/data.html
  10. http://cran.r-project.org/web/packages/islr/index.html
  11. http://www-bcf.usc.edu/~gareth/isl/getbook.html
  12. http://www-bcf.usc.edu/~gareth/isl/bios.html
  13. http://www-bcf.usc.edu/~gareth/isl/errata.html
  14. https://web.stanford.edu/~hastie/elemstatlearn/
  15. http://www.r-bloggers.com/in-depth-introduction-to-machine-learning-in-15-hours-of-expert-videos/
  16. http://www.alsharif.info/#!iom530/c21o7
  17. https://qz.com/1206229/this-is-the-best-book-for-learning-modern-statistics-its-free/

   hidden links:
  19. https://lagunita.stanford.edu/courses/humanitiessciences/statlearning/winter2016/about
