   #[1]the grand janitor blog v2    feed [2]the grand janitor blog v2   
   comments feed [3]the grand janitor blog v2    learning deep learning -
   my top-five list comments feed [4]how to get better at x (x =
   programming, math, etc ) ...... [5]facebook artificial
   intelligence/deep learning group @ 1000 members [6]alternate
   [7]alternate

[8]the grand janitor blog v2

   [9]search

   (button) primary menu [10]skip to content
     * [11]about
     * [12]contact me
     * [13]donate to this page
     * [14]full bio
     * [15]ldl: my top-5
     * [16]my ml portfolio
     * [17]publications
     * [18]resources

   search for: ____________________ search

   [19]deep learning, [20]machine learning, [21]id23

learning deep learning - my top-five list

   [22]august 15, 2016 [23]grandjanitor [24]13 comments

   many people have been nagging me to write a beginner guide on deep
   learning.    geez, that's a difficult task - there are so many
   tutorials, books, lectures to start with, and the best way to start
   highly depends on your background, knowledge and skill sets.  so it's
   very hard to give a simple guideline.

   in this post, i will do something less ambitious: i gather what i think
   is the top-5 most important resources which let you to start to learn
   deep learning.   check out the "philosophy" section on why this list is
   different from other lists you saw.

philosophy

   there are many lists of resources of deep learning.  to name a few, the
   "[25]awesome"  list,  the [26]reddit machine learning faq. i think they
   are quality resources, and it's fair to ask why i started "top-five" a
   year ago.

   unlike all the deep learning resource list you saw, "top-five" is not
   meant to be an exhaustive list.  rather it assumes you have only
   limited amount of time to study and gather resources while learning
   deep learning.    for example, suppose you like to learn through
   on-line classes.  each machine/deep learning class would likely take
   you 3 months to finish. it will take you a year to finish all the
   classes.   as a result, having a priority is good.  for instance,
   without any guidance, reading goodfellow's deep learning would confuse
   you.   a book such as bishop's pattern recognition and machine learning
   (prml) would likely be a better "introductory book".

   another difference between top-five list and other resource list is
   that the resource are curated. unless specified, i have either finished
   the material myself.  so for classes i have at least audit the whole
   lecture once.  for books i probably browse it once. in a way,  this is
   more an "arthur's list", rather than some disorganized links.  you also
   see a short commentary why (imo) they are useful.

which top-five?

   as the number of sections in my list grow, it's fair to ask what
   resources should you spend time on first.   that's a tough question
   because humans differ in their preference of learning.  my suggestion
   is start from the following,
    1. taking classes - by far i think it is the most effective way to
       learn.  listening+doing homework usually teach you a lot.
    2. book reading - this is important because usually lectures only
       summarize a subject.   only when you read through a certain
       subject, you start to get deeper understanding.
    3. playing with frameworks - this allows you to actually create some
       deep learning applications, and turn some your knowledge in
       real-life
    4. blog reading - this is useful but you better know which blogs to
       read (look at the section "blogs you want to read").  in general,
       there are just too many blog writers these days, and they might
       only have murky understanding of the topic.   reading those would
       only make you feel more confused.
    5. joining forums and ask questions - this is where you can dish out
       some of your ideas and ask for comments.  once again, the quality
       of the forum matters.   so take a look of the section "facebook
       forums".

lectures/courses

basic deep learning (also check out "[27]the basic-five")

   this are more the must-take courses if you want to learn the basic
   jargons of deep learning.   ng's, karparthy's and socher's class teach
   you basic concepts but they have a theme of building applications.
   silver's class link deep learning concepts with id23.
   so after these 4 classes, you should be able to talk deep learning well
   and work with some basic applications.
    1. [28]andrew ng's coursera machine learning class
          + you need to walk before you run.   ng's class is the best
            beginner class on machine learning in my opinion.  check out
            this page for [29]my review.
    2. [30]andrew ng's deeplearning.ai specialization
          + in my view, the best transition class from ng's machine
            learning class to more difficult classes such as cs231n and
            cs224n.   see my full reviews of[31] course 1 and [32]course
            2.  also check our my [33]quick impressions at here and review
            of one of the [34]"heros of deep learning" with prof. geoffrey
            hinton.
    3. [35]fei-fei li and andrew karpathy's id161
       class (stanford cs231n 2015/2016)
          + i listen through the lectures once.  many people just call
            this a karpathy's class, but it is also co-taught by another
            experienced graduate student, justin johnson.  for the most
            part this is the class for learning id98,  it also brings you
            to the latest technology of more difficult topics such as
            image localization, detection and segmentation.
    4. [36]richard socher's deep learning and natural language processing
       (standard cs224d)
          + i listen to the whole lecture once, the first few lectures
            were very useful for me when i tried to understand id56 and
            lstm.   this might also be the best set of lecture to learn
            socher's id56. compare to karpathy's
            class, socher's place more emphasis on mathematical
            derivation.  so if you are not familiar with matrix
            differentiation, this would be a good class to start with and
            get your hands wet.
    5. [37]david silver's id23
          + this is a great class taught by the main programmer of
            [38]alphago.  it starts from the basic of reinforcement
            learning such as dp-based method, then proceeds to more
            difficult topic such as monte-carlo and td method, as well as
            function approximation and policy gradient.   it takes quite a
            bit of understanding even if you already background of
            supervised learning.   as rl is being used more and more
            applications, this class should be a must-take for all of you.

   you should also consider:
     * [39]fast.ai's deep learning for coders
          + a class which has generally good review.  i would suggest you
            read [40]arvind nagaraj's post which compare deeplearning.ai
            and fast.ai.
     * [41]theories of deep learning
          + or stanford stat 385, which is one of the theory class of deep
            learning.
     * [42]hugo larochelle's neural network class
          + by another star-level innovator of the field.  i only heard
            larochelle's lecture in a deep learning class, but he is
            succinct and to the point than many.
     * [43]mit self driving 6.s094
          + see the description in the session of id23.
     * [44]nando de freita's class on machine/deep learning
          + i don't have a chance to go through this one, but it is both
            for beginner and more advanced learners.  it covers topics
            such as id23 and siamese network.    i also
            think this is the class if you want to use torch as your deep
            learning language.

intermediate deep/machine learning

   the intermediate courses are meant to be the more difficult sets of
   classes.  they are much more difficult to finish - math is necessary.
   there are also many confusing concepts even if you already have master.
    1. [45]hinton's neural network machine learning
          +  while the topics are advanced, prof. hinton's class is
            probably the one which can teach you the most on the
            philosophical difference between deep learning and general
            machine learning.  the first time i audit the class in 2016
            october, his explanation on models based on statistical
            mechanical model blew my mind.   i finished the course around
            2017 april, which results in a popular [46]review post.
            unfortunately, due to the difficulty of the class, it was
            ranked lower in this list. (it was ranked 2nd, then 4th on the
            basic five, but i found that it requires deeper understanding
            than the karparthy's, socher's and silver's.  later on when
            deeplearning.ai comes up, i shift prof hinton's course to one
            of the intermediate classes. )
    2. [47]daphne koller's probabilistic graphical model
          + if you want to understand tougher concepts in models such as
            dbn, you want to have some background in id110 as
            well.  if that's the route you like, koller's class is for
            you.  but this class, just like hinton's nnml, is notoriously
            difficult and not for faint of heart - you will be challenged
            on id203 concepts (course 1), id207 and algorithm
            (course ) and parameter estimation (course 3).

id23

   id23 has deep history by itself and you can think it
   has the heritage from both computer science and electrical engineering.

   my understanding of rl is fairly shallow so i can only tell you which
   are the easier class to take, but all of these classes are more
   advanced. georgia tech cs8803 should probably be your first. silvers'
   is fun, and it's based on sutton's book, but be ready to read the book
   in order to finish some of the exercises.
    1. [48]udacity's id23
          + this is a class which is jointly published by georgia tech and
            you can take it as an advanced course cs8803.  i took silver's
            class first, but i found the material this class provides a
            non-deep learning take and quite refreshing if you start out
            at id23.
    2. [49]david silver's id23
          + see description in the "introductory deep learning" section.
    3. [50]mit self driving 6.s094
          + a specialized class in self-driving.  the course is mostly
            id161, but there is one super-entertaining exercise
            on self driving, which mostly likely you want to use rl to
            solve the problem. (here is some [51]quick impression about
            the class.)

   you should also consider:
     * [52]berkeley's deep id23 potentially a third
       class about deep id23 (after silver's and
       schulmann's).

i heard good things about them......

     * [53]oxford deep nlp 2017
          + this is perhaps the second class of deep learning on nlp. i
            found the material interesting because it covers material
            which wasn't covered by the socher's class.  i haven't takem
            it yet.  so i will comment later.
     * [54]statistical computing by nicholas zabara
          + looks super interesting and most material are actually
            ml-based.
     * [55]cmu cs11-747 neural networks and nlp
          +  a great sets of lecture by graham neubig. neubig has written
            few useful tutorial on dl in nlp.  so i add his as more
            promising candidate here as well.
     * [56]nyu deep learning class at 2014
          + prof. yann lecun.  to me this is an important class, with
            similar importance as prof. hinton's class.  mostly because
            prof. lecun is one of the earliest experimenters on backprop
            and sgd.  unfortunately these nyu's lecture was removed.   but
            do check out the slides though.
     * also from prof. yann lecun, [57]deep learning inaugural lectures.
     * berkely's seminar on deep learning: by prof.  [58]ruslan
       salakhutdinov, an early researcher on unsupervised learning.
     * [59]university of amsterdam deep learning
          + if you have already audit cs231n and cs224d, perhaps the
            material here is not too new, but i found it useful to have a
            second source when i look at some of the material.   i also
            like the presentation of back-propagation, which is more
            mathematical than most beginner class.
     * [60]special topics in deep learning
          + i found it great resource if you want to drill on more
            exoteric topics in deep learning.
     * [61]deep learning for speech and language
          + of my own curiosity on id103. this course is
            perhaps is the only one i can find on dl on asr.   if you
            happen to stumble this paragraph, i'd say most software you
            find on-line are not really too applicable in real-life.  the
            only exceptions are discussed in [62]this very old article of
            mine.

for reference

     * [63]virginia tech deep learning at 2015
     * [64]university of waterloo by prof ali ghodsi
     * [65]mit 6.s191 introduction to deep learning
     * [66]deep rl and control from cmu
     * [67]udacity deep learning and deep learning nanodegree.

great preliminaries

     * [68]id202 by prof. gilbert strang
     * [69]probabilistic system and applied id203 by prof. john
       tsitsiklis

more on basic machine learning (unsorted)

     * columbiax: [70]csmm.102x
     * [71]esl
     * [72]caltech machine learning.
     * [73]andrew ng's machine learning 2008
     * [74]tony mitchell's machine learning 2011
     * [75]nando de freita's machine learning 2012

more ai than machine learning (unsorted)

     * [76]berkley cs 188
     * [77]stanford cs221
     * [78]edx ai
     * [79]mit ai courseware - lectures by patrick winston
     * [80]prof. marvin minsky's the society of minds

more about the brain:

   i don't have much, but you can take a look of my another list on
   [81]neuroscience moocs.

books

   i wrote quite a bit on the [82]recommended books page.   in a nutshell,
    i found that classics such as prml and duda and hart are still
   must-reads in the world of deep learning.   but if you still want a
   list, alright then......
    1. [83]michael nielson's deep learning book: or nndl,  highly
       recommended by many.  this book is very suitable for beginners who
       want to understand the basic insights of simple feed forward
       networks and their setups.    unlike most text books, it doesn't
       quite go through the math until it gives you some intuition.
       while i only went through recently, i highly recommend all of you
       to read it.  also see [84]my read on the book.
    2. prml : i love prml!  do go to read my [85]recommended books page to
       find out why.
    3. duda and hart:  i don't like it as much as prml, but it's my first
       machine learning bible.  again, go to my [86]recommended books
       page to find out why.
    4. t[87]he deep learning book by ian goodfellow, yoshua bengio and
       aaron courville:  this is the book for deep learning, but it's
       hardly for beginner.   i recently browse through the book.  here is
       [88]some quick impression.
    5. [89]natural language understanding with distributed
       representation by kyung hyun cho.   this is mainly for nlp people,
       but it's important to note how different that nlp is seen from a
       deep learning point of view.

   others: check out my [90]recommended books page.  for beginner, i found
   mitchell's and domingo's books are quite interesting.

frameworks

    1. [91]tensorflow : most popular, and could be daunting to install,
       also check out [92]tflearn.  [93]keras became the de-facto
       high-level layer lately.
    2. [94]torch :  very easy to use even if you don't know lua.   it also
       leads you to great tutorials.  also check out [95]pytorch.
    3. [96]theano : grandfather of deep learning frameworks, also check
       out [97]lasagne.
    4. [98]caffe : probably the fastest among the generic frameworks.  it
       takes you a while to understand the setup/syntax.
    5. [99]neon : the very speedy neon, it's optimized on modern cards. i
       don't have a benchmarking between caffe and neon yet, but its mnist
       training feels very fast.

   others:
     * [100]deeplearning4j: obviously in java, but i heard there are great
       support on enterprise machine learning.

tutorials

    1. [101]theano tutorial:  a great sets of tutorials and you can run it
       from cpu.
    2. [102]tensorflow tutorial : a very comprehensive sets of tutorial.
       i don't like it as much as theano's because some tasks require
       compilation, which could be fairly painful.
    3. [103]char-id56:  not exactly a tutorial but if you want to have fun
       with deep learning.  you should train at least one char-id56.   note
       that word-based version is available.  the package is also
       optimized now as torch-id56.  i think char-id56 is also a great
       starting code for intermediate learners to learn torch.
    4. misc: generally running the examples of a package can teach you a
       lot.  let's say this is one item.

   others: i also found [104]learning guide from yeravann's lab to be
   fairly impressive.  there is ranked resource list on several different
   topics, which is similar to the spirit of my list.

mailing lists

    1. [105](shameless plug) aidl weekly  curated by me and [106]waikit
       lau, aidl weekly is a tied-in newsletter of the [107]aidl facebook
       group. we provide in-depth analysis of weekly events of ai and deep
       learning.
    2. [108]mapping babel curated by jack clark.  i found it entertaining
       and well-curated.  clark is more in the journalism space and i
       found his commentary thoughtful.
    3. [109]data machina this is a link only letter.  the links are quite
       quality.

   of course, there are more newsletter than these three.  but i don't
   normally recommend them.   one reason is many "curators" don't always
   read the original sources before they share the links, which sometimes
   inadvertently spread faked news to the public.   in issue [110]#4 of
   aidl weekly, i described one of such incidences.  so you are warned!

facebook forums

   that's another category i am going to plug shamelessly.  it has to do
   with most facebook forums have too much noise and administrator pay too
   little attention to the group.
    1. (shameless plug) [111]aidl this is a forum curated by me and
       [112]waikit.  we like our forum because we actively curate it,
       delete spam and facilitate discussion within the group.  as a
       result it become one of the most active group.  it has 10k+
       members.  as of this writing, we have a tied-in mailing list as
       well as a weekly show.
    2. [113]deep learning  deep learning has comparable size as aidl, but
       less active, perhaps because the administrators use korean.  i
       still find some of the links interesting and use the group a lot
       before  administering aidl.
    3. [114]deep learning/ai curated by [115]sid dharth and [116]ish
       girwan.  dlai follows very similar philosophy and sid control
       posting tightly.  i think his group will be one of the
       up-and-coming group next year.
    4. [117]strong artificial intelligence  this is less about deep
       learning, but more on ai.   it is perhaps the biggest fb group on
       ai, its membership stabilized but posting is solid and there are
       still some life in discussion. i like the more philosophical ends
       of the posts which aidl usually refrained from.

non-trivial mathematics you should know

   due to popular demand,  this section is what i would say a bit on the
   most relevant math which you need to know.   everyone knows that math
   is useful, and yes, stuffs like calculus, id202, id203
   and statistics are super useful too.  but then i think they are too
   general, so i will name several specific topics which turns out to be
   very useful, but not very well taught in school.
    1. bayes'  theorem:  bayes' theorem is important not only as a simple
       rule which you will use it all the time.   the high school version
       usually just ask you to reverse the end of probabilities. but once
       it is apply in reasoning, you will need to be very clear how to
       interpret terms such as likelihood and priors. it's also very
       important what the term bayesian really means, and why people see
       it as better than frequentist.   all these thinking if you don't
       know bayes' rules, you are going to get very confused.
    2. properties of multi-variate gaussian distribution:  the
       one-dimensional gaussian distribution is an interesting
       mathematical quantity.  if you try to integrate it, it will be one
       of the integrals you quickly you can't integrate it in trivial way.
         that's the point you want to learn the [118]id203
       integral and how it was integrated.   of course, once you need to
       work on multi-variate gaussian, then you will need to learn further
       properties such as diagonalizing the covariance matrix and all the
       jazz.   those are non-trivial math.   but if you master them, it
       will helps you work through more difficult problems in prml.
    3. matrix differentiation : you can differentiate all right, but once
       it comes to vector/matrix, even the notation seems to be different
       from your college calculus.  no doubt, matrix differentiation is
       seldom taught in school.   so always refer to useful guide such
       as [119]matrix cook book, then you will be less confused.
       ([120]matrix reference manual is also good. )
    4. calculus of variation: if you want to find the best value which
       optimize a function you use calculus, if you want to find the best
       function/path which optimize a functional, you use calculus of
       variation. for the most part, [121]euler-langrange equation is what
       you need.
    5. id205:  id205 is widely used in machine
       learning.  more importantly the reasoning and thinking can be found
       everywhere.  e.g. why do you want to optimize cross-id178,
       instead of square error?  not only[122] square error over-penalize
       incorrect outputs.  you can also think of cross-id178 is learning
       from the surprise of a mistake.

blogs you should read

    1. [123]chris olah's blog  olah has great capability to express very
       difficult mathematical concepts to lay audience.   i greatly
       benefit from his articles on lstm and computational graph.   he
       also makes me understand learning topology is fun and profitable.
    2. [124]andrew karparthy's blog  if you hadn't read "[125]the
       unreasonable effectiveness of recurrent neural networks", you
       should.   karparthy's articles show both great enthusiasm on the
       topic and very good grasp on the principle.    i also like his
       article on id23.
    3. [126]wildml written by danny britz,  he is perhaps less well-known
       than either olah or karparthy, but he enunciate many topics well.
       for example, i enjoy his explanation on gru/lstm a lot.
    4. [127]tombone's id161 blog written by tomasz malisiewicz.
        this is the first few blogs i read about computer
       vision, malisiewicz has great insight on machine learning
       algorithms and id161.   many of his articles give
       insightful comments on relationship between ml techniques.
    5. [128]the spectactor written by shakir mohamad.  this is my goto
       page on mathematical statistics as well as theoretial basis
       of  deep learning techniques.  check out his thought on what make a
       ml technique deep, as well as his tricks in machine learning.

   that's it for now. check out this page and i might update with more
   contents. arthur

   this post is first published
   at [129]http://thegrandjanitor.com/2016/08/15/learning-deep-learning-my
   -top-five-resource/.

   you might also like [130]learning machine learning,  some personal
   experience.

   if you like this message, subscribe the [131]grand janitor blog's rss
   feed.  you can also find me at [132]twitter, [133]linkedin, [134]plus,
   [135]clarity.fm.  together with [136]waikit lau, i maintain the
   [137]deep learning facebook forum.  also check out my awesome employer:
   [138]voci.


   (20160817): i change the title couple of times, because this is more
   like a top-5 list of a list. so i retitled the post as "top-five
   resource", "top-five", now i settled to use "top-five list", which is a
   misnomer but close enough.

   (20160817): fixed couple of typos/wording issues.

   (20160824): add a section on important math to learn.

   (20160826): fixed typos, etc.

   (20160904): fixed typos

   (20161002): changed the section on books to link to my article on nndl.
     added a section on must-follow blogs.

   (20170128): as i go deep on socher's lectures, i boost up his class
   ranking to number 3.  i also made karparthay's lecture into rank number
   2. i think silver's class is important but the material is too
   advanced, and perhaps less of importance for deep learning learners.
   (it is more about id23 when you look at it closely.)
    hinton's class is absolutely crucial but it requires more mathematical
   understanding than karparthay's class.  thus the ranking.

   i also 2 more classes (nyu, mit)  to check out and 2 more as references
   (vtech and ua).

   (20161207): added descriptions of li, karparthy and johnson's class,
   added description of silver's class.

   (20170310): add "philosophy", "top-five of top-five", "top-five mailing
   list", "top-five forums".  adjusted description on socher's class,
   linked a quick impression on goodfellow's "deep learning".

   (20170312): add oxford nlp class, berkeley's deep rl into the mix.

   (20170319): add the udacity's course into the mix.  i think next
   version i might have a separate section on id23.

   (20170326): i did another rewrite last two weeks mainly because there
   are many new lectures released during spring 2017. here is a summary:
     *  i separate all "courses/lectures" session to two tracks: "basic
       deep learning" and "id23". it's more a
       decluttering of links. i also believe id23 should
       be separate track because it requires more specialized algorithms.
     * on the "basic deep learning" track, ranking has change. it was
       ng's, cs231n, cs224d, hinton's, silver's, now it becomes ng's,
       cs231n, cs224d, silvers's, hinton's. as i go deep into hinton's
       class, i found that it has more difficult concepts. both silver's
       and hinton's class are more difficult than the first 3 imo.
     * i also gives some basic description on the u. of amsterdam's class.
       i don't know much about it yet, but it's refreshing because it
       gives different presentation from the "basic 5" i recommend.

   (20170412): i finished hinton's nnml, added berkley cs294-131 into the
   mix.

   (20170620): links up "top-5" list with "basic 5".  added a list of ai,
   added link to my mooc list.

   (20170816): added deeplearning.ai into basic 5.  it becomes the new
   official recommendation to aidl newcomers.

   (20171126): added several ml classes. added stats 385 into the
   considered list.

   appendix:
   links to process: http://ai.berkeley.edu/lecture_videos.html

related

post navigation

   [139]previous posthow to get better at x (x = programming, math, etc )
   ......[140]next postfacebook artificial intelligence/deep learning
   group @ 1000 members

13 thoughts on    learning deep learning - my top-five list   

    1.
   unkle says:
       [141]august 16, 2016 at 5:52 am
       you should check out
       [142]https://www.kadenze.com/courses/creative-applications-of-deep-
       learning-with-tensorflow/info for some really impressive videos and
       the related course github: [143]https://github.com/pkmital/cadl/ -
       with complete lecture transcripts in python notebooks.
       [144]reply
    2.
   johan says:
       [145]august 26, 2016 at 6:36 pm
       this is so awesome resource. thank you for sharing this. i have
       also just begun my masters (post-grad) research in machine learning
       (neural networks). i have background of bachelors in electrical
       engineering.
       i have a question of 'how to' nature for research. should the
       optimization in the neural network algorithm be application
       specific or should it be general? so for-example, should the
       application dictate which function of the algorithm be optimized to
       achieve better results or should one optimize the algorithm in
       general and then compare it for any application?
       [146]reply
         1.
        grandjanitor says:
            [147]august 26, 2016 at 8:29 pm
            people adapt nn differently in different applications. e.g.
            relu is usually used in id98 but seldom used in id56. that's
            because the relu, together with the multiplicative nature of
            errors could easily blow up the training. on architecture, you
            may also find that the optimal architecture is
            application-based and is driven by experiments heavily.
            saying so it doesn't mean you can't use id56 on image
            recognition , nor you can't use id98 on nlp. it just requires
            very special care of how you model.
            [148]reply
    3.
   chetan says:
       [149]april 12, 2017 at 5:37 am
       thanks for sharing this detailed information about deep learning. i
       am pretty thankful to have you in my network over fb and thanks
       again for helping people with your knowledge around the globe.
       [150]reply
         1.
        grandjanitor says:
            [151]april 12, 2017 at 11:51 am
            you are welcome, chetan. hope this is useful for you.
            [152]reply
    4.
   tando says:
       [153]august 17, 2017 at 5:08 am
       awesome reviews and suggestion. thank you for your article. but i
       can not subscribe to your blog. could you please check it ?
       [154]reply
         1.
        grandjanitor says:
            [155]august 17, 2017 at 5:54 pm
            sure. i will take a look. thanks!
            [156]reply
    5.
   anilkumar es says:
       [157]august 18, 2017 at 5:53 am
       really very useful information.
       thanks a lot!
       but i am not able to subscribe for new letter.
       could you please check it once.
       thank you
       anil
       [158]reply
         1.
        grandjanitor says:
            [159]august 18, 2017 at 2:28 pm
            yeah.. my own blog's newsletter subscription is kind of
            broken. so i might want to remove the options.
            i would suggest you to subscribe[160] aidl weekly, which is
            also written by me. thanks!
            [161]reply
    6.
   khayrat glende says:
       [162]september 18, 2017 at 8:39 am
       hi arthur,
       thank you for sharing your insights. i'm a beginner to ml and
       fulltime developer with basic math. i've just finished andrew ng's
       ml-course for the second time with an interruption of 3 years where
       i tried to learn the math, but sadly get confused with where to
       start and what to learn in which order and made little progress.
       also i could follow the explanations in the andrew's course quit
       easily, i felt i need more insight. now is my second attempt to ml
       and i plan to learn the needed math along the way. now i was
       looking for how to proceed . i was thinking about yaser
       abu-mostafi's course at edx and then turn to the new
       deeplearning.ia from andrew. but after reading your advise i think
       the best way to proceed as you suggested.
       best regards, khayrat
       [163]reply
         1.
        grandjanitor says:
            [164]september 20, 2017 at 11:21 pm
            hey khayrat,
            i genuinely hope that my articles help you. the strength of
            the top-5 list i'd say is that its suggested course sequence
            of learning is quite reasonable for anyone who has
            college-level calculus. and i'd assume with persistence, you
            can go quite far just by taking classes.
            in any case, i hope you have good luck.
            thanks,
            arthur
            [165]reply
    7.
   docjag says:
       [166]april 9, 2018 at 10:48 am
       "prof. markin minsky's the society of minds" should be "prof.
       marvin minsky's the society of minds"
       [167]reply
         1.
        grandjanitor says:
            [168]april 26, 2018 at 7:20 pm
            fixed. thanks.
            [169]reply

leave a reply [170]cancel reply

   your email address will not be published. required fields are marked *

   comment
   _____________________________________________
   _____________________________________________
   _____________________________________________
   _____________________________________________
   _____________________________________________
   _____________________________________________
   _____________________________________________
   _____________________________________________

   name * ______________________________

   email * ______________________________

   website ______________________________

   iframe:
   [171]https://www.google.com/recaptcha/api/fallback?k=6let0bataaaaac4-so
   f5k7hth5luftwaiquva1qu


   ____________________________________________________________
   ____________________________________________________________
   ____________________________________________________________
   ____________________________________________________________

   post comment

   currently you have javascript disabled. in order to post comments,
   please make sure javascript and cookies are enabled, and reload the
   page. [172]click here for instructions on how to enable javascript in
   your browser.

   [ ] notify me of follow-up comments by email.

   [ ] notify me of new posts by email.

top posts & pages

     * [173]id119 for id28
     * [174]a review on hinton's coursera "neural networks and machine
       learning"
     * [175]learning deep learning - my top-five list
     * [176]what does an nlp engineer do?
     * [177]reading michael nielsen's "neural networks and deep learning"
     * [178]using arpa lm with python
     * [179]list of neuroscience moocs

id103, machine learning, and random musing of arthur chan

by arthur chan

     * [180]aidl weekly
     * [181]aidl fb group
     * [182]my cmu page
     * [183]my random thought
     * [184]the old "grand janitor blog"
     * [185]my self-study of clrs
     * [186]               
     * [187]            333      

   search for: ____________________ search

recent posts

     * [188]gtc 2019 write-up part 1: keynotes march 24, 2019
     * [189]resources on id103 february 18, 2019
     * [190]resources on understanding heaps december 13, 2018
     * [191]resources on cuda programming july 6, 2018
     * [192]resources on resnet may 9, 2018
     * [193]a read on "id163 training in minutes" may 9, 2018
     * [194]a read on "the consciousness prior" by prof. yoshua bengio may
       9, 2018

   [195]proudly powered by wordpress

references

   visible links
   1. http://thegrandjanitor.com/feed/
   2. http://thegrandjanitor.com/comments/feed/
   3. http://thegrandjanitor.com/2016/08/15/learning-deep-learning-my-top-five-resource/feed/
   4. http://thegrandjanitor.com/2016/06/14/how-to-get-better-at-x-x-programming-math-etc/
   5. http://thegrandjanitor.com/2016/08/29/facebook-artificial-intelligencedeep-learning-group-1000-members/
   6. http://thegrandjanitor.com/wp-json/oembed/1.0/embed?url=http://thegrandjanitor.com/2016/08/15/learning-deep-learning-my-top-five-resource/
   7. http://thegrandjanitor.com/wp-json/oembed/1.0/embed?url=http://thegrandjanitor.com/2016/08/15/learning-deep-learning-my-top-five-resource/&format=xml
   8. http://thegrandjanitor.com/
   9. http://thegrandjanitor.com/2016/08/15/learning-deep-learning-my-top-five-resource/#search-container
  10. http://thegrandjanitor.com/2016/08/15/learning-deep-learning-my-top-five-resource/#content
  11. http://thegrandjanitor.com/about-me/
  12. http://thegrandjanitor.com/contact-me/
  13. http://thegrandjanitor.com/donate-to-this-page-2/
  14. http://thegrandjanitor.com/full-bioresume/
  15. http://thegrandjanitor.com/ldl-my-top-5/
  16. http://thegrandjanitor.com/machine-learning-portfolio/
  17. http://thegrandjanitor.com/my-publications/
  18. http://thegrandjanitor.com/recommend-books-on-machine-learning/
  19. http://thegrandjanitor.com/category/deep-learning/
  20. http://thegrandjanitor.com/category/machine-learning/
  21. http://thegrandjanitor.com/category/reinforcement-learning/
  22. http://thegrandjanitor.com/2016/08/15/learning-deep-learning-my-top-five-resource/
  23. http://thegrandjanitor.com/author/grandjanitor/
  24. http://thegrandjanitor.com/2016/08/15/learning-deep-learning-my-top-five-resource/#comments
  25. https://github.com/christoschristofidis/awesome-deep-learning
  26. https://www.reddit.com/r/machinelearning/wiki/index
  27. http://thegrandjanitor.com/2017/05/13/learning-deep-learning-the-basic-five-five-beginner-course-on-deep-learning/
  28. https://www.coursera.org/learn/machine-learning
  29. http://thegrandjanitor.com/2015/11/11/for-the-not-so-uninitiated-review-of-ngs-coursera-machine-learning-class/
  30. https://www.coursera.org/learn/neural-networks-deep-learning
  31. http://thegrandjanitor.com/2017/10/14/review-of-ngs-deeplearning-ai-course-1-neural-networks-and-deep-learning/
  32. http://thegrandjanitor.com/2017/10/28/review-of-ngs-deeplearning-ai-course-2-improving-deep-neural-networks/
  33. http://thegrandjanitor.com/2017/08/09/quick-impression-on-deeplearning-ai/
  34. http://thegrandjanitor.com/2017/08/13/quick-impression-on-deeplearning-ai-heroes-of-deep-learning-geoffrey-hinton/
  35. http://cs231n.stanford.edu/
  36. http://cs224d.stanford.edu/
  37. http://www0.cs.ucl.ac.uk/staff/d.silver/web/teaching.html
  38. http://www.nature.com/nature/journal/v529/n7587/full/nature16961.html
  39. http://www.fast.ai/
  40. https://medium.com/towards-data-science/thoughts-after-taking-the-deeplearning-ai-courses-8568f132153
  41. https://www.researchgate.net/project/theories-of-deep-learning
  42. http://info.usherbrooke.ca/hlarochelle/neural_networks/content.html
  43. http://selfdrivingcars.mit.edu/
  44. https://www.cs.ox.ac.uk/people/nando.defreitas/machinelearning/
  45. https://www.coursera.org/learn/neural-networks
  46. http://thegrandjanitor.com/2017/04/10/review-of-hintons-coursera-neural-network-and-machine-learning/
  47. https://www.coursera.org/learn/probabilistic-graphical-models
  48. https://www.udacity.com/course/reinforcement-learning--ud600
  49. http://www0.cs.ucl.ac.uk/staff/d.silver/web/teaching.html
  50. http://selfdrivingcars.mit.edu/
  51. http://thegrandjanitor.com/2017/05/12/some-quick-impression-on-mit-dl4sdc-class-by-lex-friedman/
  52. http://rll.berkeley.edu/deeprlcourse/#lecture-videos
  53. https://github.com/oxford-cs-deepnlp-2017/lectures
  54. https://www.zabaras.com/statisticalcomputing
  55. https://www.youtube.com/user/neubig/playlists
  56. http://cilvr.cs.nyu.edu/doku.php?id=deeplearning:slides:start#week_1
  57. https://www.college-de-france.fr/site/en-yann-lecun/course-2015-2016.htm
  58. http://www.cs.cmu.edu/~rsalakhu/
  59. http://uvadlc.github.io/
  60. https://berkeley-deep-learning.github.io/cs294-131-s17/
  61. https://telecombcn-dl.github.io/2017-dlsl/
  62. http://thegrandjanitor.com/2013/11/17/learning-asr-through-coding/
  63. https://computing.ece.vt.edu/~f15ece6504/
  64. https://uwaterloo.ca/data-analytics/
  65. http://introtodeeplearning.com/index.html
  66. https://katefvision.github.io/
  67. https://classroom.udacity.com/courses/ud730
  68. https://ocw.mit.edu/courses/mathematics/18-06sc-linear-algebra-fall-2011/
  69. https://ocw.mit.edu/courses/electrical-engineering-and-computer-science/6-041sc-probabilistic-systems-analysis-and-applied-id203-fall-2013/index.htm
  70. https://www.edx.org/course/machine-learning-columbiax-csmm-102x-1
  71. http://www.dataschool.io/15-hours-of-expert-machine-learning-videos/
  72. https://work.caltech.edu/telecourse.html
  73. https://www.youtube.com/playlist?list=pla89dcfa6adace599
  74. http://www.cs.cmu.edu/~tom/10701_sp11/lectures.shtml
  75. https://www.youtube.com/playlist?list=ple6wd9fr--ecf_5ncbnsqmhqorpichfjf
  76. http://ai.berkeley.edu/lecture_videos.html
  77. http://web.stanford.edu/class/cs221/
  78. https://www.edx.org/course/artificial-intelligence-ai-columbiax-csmm-101x-0
  79. https://ocw.mit.edu/courses/electrical-engineering-and-computer-science/6-034-artificial-intelligence-fall-2010/
  80. https://ocw.mit.edu/courses/electrical-engineering-and-computer-science/6-868j-the-society-of-mind-fall-2011/
  81. http://thegrandjanitor.com/2017/04/10/list-of-neuroscience-mooc/
  82. http://thegrandjanitor.com/recommend-books-on-machine-learning/
  83. http://neuralnetworksanddeeplearning.com/
  84. http://thegrandjanitor.com/2016/10/02/reading-michael-nielsons-neural-networks-and-deep-learning/
  85. http://thegrandjanitor.com/recommend-books-on-machine-learning/
  86. http://thegrandjanitor.com/recommend-books-on-machine-learning/
  87. http://www.deeplearningbook.org/
  88. http://thegrandjanitor.com/2017/03/10/some-quick-impression-of-browsing-deep-learning/
  89. http://arxiv.org/abs/1511.07916
  90. http://thegrandjanitor.com/recommend-books-on-machine-learning/
  91. https://www.tensorflow.org/
  92. http://tflearn.org/
  93. https://keras.io/
  94. http://torch.ch/
  95. https://github.com/pytorch/pytorch
  96. http://deeplearning.net/software/theano/
  97. http://github.com/lasagne/lasagne
  98. http://caffe.berkeleyvision.org/
  99. https://github.com/nervanasystems/neon
 100. https://deeplearning4j.org/
 101. http://deeplearning.net/tutorial/
 102. https://www.tensorflow.org/versions/r0.10/tutorials/image_recognition/index.html
 103. http://karpathy.github.io/2015/05/21/id56-effectiveness/
 104. http://yerevann.com/a-guide-to-deep-learning/
 105. http://aidl.io/
 106. https://www.linkedin.com/in/waikit-lau-89129
 107. https://www.facebook.com/groups/deepnetgroup/
 108. https://jack-clark.net/2017/03/06/import-ai-issue-31-evolution-meets-deep-learning-busting-ai-hype-and-the-automatic-analysis-of-cities/
 109. https://tinyletter.com/datamachina
 110. http://aidl.io/issues/4#start
 111. https://www.facebook.com/groups/deepnetgroup/
 112. https://www.linkedin.com/in/waikit-lau-89129
 113. https://www.facebook.com/groups/deepleaid56g/
 114. https://www.facebook.com/groups/1738168866424224/
 115. https://www.facebook.com/sid027
 116. https://www.facebook.com/ish.girwan?fref=pb_other
 117. https://www.facebook.com/groups/strongartificialintelligence/
 118. http://thegrandjanitor.com/2016/01/04/the-id203-integral-2/
 119. https://www.math.uwaterloo.ca/~hwolkowi/matrixcookbook.pdf
 120. http://www.ee.ic.ac.uk/hp/staff/dmb/matrix/intro.html
 121. https://en.wikipedia.org/wiki/calculus_of_variations#euler.e2.80.93lagrange_equation
 122. https://jamesmccaffrey.wordpress.com/2013/11/05/why-you-should-use-cross-id178-error-instead-of-classification-error-or-mean-squared-error-for-neural-network-classifier-training/
 123. http://colah.github.io/
 124. http://karpathy.github.io/
 125. http://karpathy.github.io/2015/05/21/id56-effectiveness/
 126. http://www.wildml.com/about/
 127. http://www.computervisionblog.com/
 128. http://blog.shakirm.com/
 129. http://thegrandjanitor.com/2016/08/15/learning-deep-learning-my-top-five-resource/
 130. http://thegrandjanitor.com/2016/05/21/learning-machine-learning-some-personal-experience/
 131. http://thegrandjanitor.com/feed/
 132. https://twitter.com/arthchan2003
 133. https://www.linkedin.com/in/arthchan2003
 134. https://plus.google.com/
 135. https://clarity.fm/arthurchan
 136. https://www.linkedin.com/in/waikit-lau-89129?authtype=openlink&authtoken=ecvg&locale=en_us&srchid=32591551472085290618&srchindex=1&srchtotal=1&trk=vsrp_people_res_name&trkinfo=vsrpsearchid:32591551472085290618,vsrptargetid:58285,vsrpcmpt:primary,vsrpnm:true,authtype:openlink
 137. https://www.facebook.com/groups/deepnetgroup/
 138. https://www.linkedin.com/company/9382025?trk=tyah&trkinfo=clickedvertical:company,clickedentityid:9382025,idx:2-1-2,tarid:1472085172997,tas:voci
 139. http://thegrandjanitor.com/2016/06/14/how-to-get-better-at-x-x-programming-math-etc/
 140. http://thegrandjanitor.com/2016/08/29/facebook-artificial-intelligencedeep-learning-group-1000-members/
 141. http://thegrandjanitor.com/2016/08/15/learning-deep-learning-my-top-five-resource/#comment-1916
 142. https://www.kadenze.com/courses/creative-applications-of-deep-learning-with-tensorflow/info
 143. https://github.com/pkmital/cadl/
 144. http://thegrandjanitor.com/2016/08/15/learning-deep-learning-my-top-five-resource/?replytocom=1916#respond
 145. http://thegrandjanitor.com/2016/08/15/learning-deep-learning-my-top-five-resource/#comment-1917
 146. http://thegrandjanitor.com/2016/08/15/learning-deep-learning-my-top-five-resource/?replytocom=1917#respond
 147. http://thegrandjanitor.com/2016/08/15/learning-deep-learning-my-top-five-resource/#comment-1918
 148. http://thegrandjanitor.com/2016/08/15/learning-deep-learning-my-top-five-resource/?replytocom=1918#respond
 149. http://thegrandjanitor.com/2016/08/15/learning-deep-learning-my-top-five-resource/#comment-1920
 150. http://thegrandjanitor.com/2016/08/15/learning-deep-learning-my-top-five-resource/?replytocom=1920#respond
 151. http://thegrandjanitor.com/2016/08/15/learning-deep-learning-my-top-five-resource/#comment-1921
 152. http://thegrandjanitor.com/2016/08/15/learning-deep-learning-my-top-five-resource/?replytocom=1921#respond
 153. http://thegrandjanitor.com/2016/08/15/learning-deep-learning-my-top-five-resource/#comment-1929
 154. http://thegrandjanitor.com/2016/08/15/learning-deep-learning-my-top-five-resource/?replytocom=1929#respond
 155. http://thegrandjanitor.com/2016/08/15/learning-deep-learning-my-top-five-resource/#comment-1932
 156. http://thegrandjanitor.com/2016/08/15/learning-deep-learning-my-top-five-resource/?replytocom=1932#respond
 157. http://thegrandjanitor.com/2016/08/15/learning-deep-learning-my-top-five-resource/#comment-1933
 158. http://thegrandjanitor.com/2016/08/15/learning-deep-learning-my-top-five-resource/?replytocom=1933#respond
 159. http://thegrandjanitor.com/2016/08/15/learning-deep-learning-my-top-five-resource/#comment-1934
 160. http://www.aidl.io/
 161. http://thegrandjanitor.com/2016/08/15/learning-deep-learning-my-top-five-resource/?replytocom=1934#respond
 162. http://thegrandjanitor.com/2016/08/15/learning-deep-learning-my-top-five-resource/#comment-1935
 163. http://thegrandjanitor.com/2016/08/15/learning-deep-learning-my-top-five-resource/?replytocom=1935#respond
 164. http://thegrandjanitor.com/2016/08/15/learning-deep-learning-my-top-five-resource/#comment-1936
 165. http://thegrandjanitor.com/2016/08/15/learning-deep-learning-my-top-five-resource/?replytocom=1936#respond
 166. http://thegrandjanitor.com/2016/08/15/learning-deep-learning-my-top-five-resource/#comment-1958
 167. http://thegrandjanitor.com/2016/08/15/learning-deep-learning-my-top-five-resource/?replytocom=1958#respond
 168. http://thegrandjanitor.com/2016/08/15/learning-deep-learning-my-top-five-resource/#comment-1962
 169. http://thegrandjanitor.com/2016/08/15/learning-deep-learning-my-top-five-resource/?replytocom=1962#respond
 170. http://thegrandjanitor.com/2016/08/15/learning-deep-learning-my-top-five-resource/#respond
 171. https://www.google.com/recaptcha/api/fallback?k=6let0bataaaaac4-sof5k7hth5luftwaiquva1qu
 172. http://enable-javascript.com/
 173. http://thegrandjanitor.com/2015/08/20/gradient-descent-for-logistic-regression/
 174. http://thegrandjanitor.com/2017/04/10/review-of-hintons-coursera-neural-network-and-machine-learning/
 175. http://thegrandjanitor.com/2016/08/15/learning-deep-learning-my-top-five-resource/
 176. http://thegrandjanitor.com/2015/12/31/what-does-an-nlp-engineer-do/
 177. http://thegrandjanitor.com/2016/10/02/reading-michael-nielsons-neural-networks-and-deep-learning/
 178. http://thegrandjanitor.com/2015/12/28/using-arpa-lm-with-python/
 179. http://thegrandjanitor.com/2017/04/10/list-of-neuroscience-mooc/
 180. http://aidl.io/
 181. https://www.facebook.com/groups/deepnetgroup/
 182. http://www.cs.cmu.edu/~archan/
 183. http://arthur-chan.blogspot.com/
 184. http://grandjanitor.blogspot.com/
 185. https://tcrcstudy.blogspot.com/
 186. http://cumulomaniac.blogspot.com/
 187. http://333weeks.blogspot.com/
 188. http://thegrandjanitor.com/2019/03/24/gtc-2019-write-up-part-1-keynotes/
 189. http://thegrandjanitor.com/2019/02/18/resources-on-speech-recognition/
 190. http://thegrandjanitor.com/2018/12/13/resources-on-understanding-heaps/
 191. http://thegrandjanitor.com/2018/07/06/resources-on-cuda-programming/
 192. http://thegrandjanitor.com/2018/05/09/resources-on-resnet/
 193. http://thegrandjanitor.com/2018/05/09/a-read-on-id163-training-in-minutes/
 194. http://thegrandjanitor.com/2018/05/09/a-read-on-the-consciousness-prior-by-prof-yoshua-bengio/
 195. https://wordpress.org/

   hidden links:
 197. https://twitter.com/share
