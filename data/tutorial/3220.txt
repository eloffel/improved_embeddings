   #[1]alternate [2]alternate [3]alternate [4]alternate [5]alternate
   [6]alternate [7]alternate [8]alternate [9]alternate [10]alternate
   [11]alternate [12]alternate [13]alternate [14]alternate

   [15]r2d3

a visual introduction to machine learning

   language: : [english_________]

   in machine learning, computers apply statistical learning techniques to
   automatically identify patterns in data. these techniques can be used
   to make highly accurate predictions.

   keep scrolling. using a data set about homes, we will create a machine
   learning model to distinguish homes in new york from homes in san
   francisco.

   scroll
     __________________________________________________________________

first, some intuition

   let   s say you had to determine whether a home is in san francisco or in
   new york. in machine learning terms, categorizing data points is a
   classification task.

   since san francisco is relatively hilly, the elevation of a home may be
   a good way to distinguish the two cities.

   based on the home-elevation data to the right, you could argue that a
   home above 73 meters should be classified as one in san francisco.
     __________________________________________________________________

adding nuance

   adding another dimension allows for more nuance. for example, new york
   apartments can be extremely expensive per square foot.

   so visualizing elevation and price per square foot in a scatterplot
   helps us distinguish lower-elevation homes.

   the data suggests that, among homes at or below 73 meters, those that
   cost more than $19,116.7 per square meter are in new york city.

   dimensions in a data set are called features, predictors, or variables.
     __________________________________________________________________

drawing boundaries

   you can visualize your elevation (>73 m) and price per square foot
   (>$19,116.7) observations as the boundaries of regions in your
   scatterplot. homes plotted in the green and blue regions would be in
   san francisco and new york, respectively.

   identifying boundaries in data using math is the essence of statistical
   learning.

   of course, you   ll need additional information to distinguish homes with
   lower elevations and lower per-square-foot prices.
     __________________________________________________________________

   the dataset we are using to create the model has 7 different
   dimensions. creating a model is also known as training a model.

   on the right, we are visualizing the variables in a scatterplot matrix
   to show the relationships between each pair of dimensions.

   there are clearly patterns in the data, but the boundaries for
   delineating them are not obvious.
     __________________________________________________________________

and now, machine learning

   finding patterns in data is where machine learning comes in. machine
   learning methods use statistical learning to identify boundaries.

   one example of a machine learning method is a decision tree. decision
   trees look at one variable at a time and are a reasonably accessible
   (though rudimentary) machine learning method.
     __________________________________________________________________
     __________________________________________________________________

finding better boundaries

   let's revisit the 73-m elevation boundary proposed previously to see
   how we can improve upon our intuition.

   clearly, this requires a different perspective.
     __________________________________________________________________

   by transforming our visualization into a histogram, we can better see
   how frequently homes appear at each elevation.

   while the highest home in new york is 73m, the majority of them seem to
   have far lower elevations.
     __________________________________________________________________

your first fork

   a decision tree uses if-then statements to define patterns in data.

   for example, if a home's elevation is above some number, then the home
   is probably in san francisco.
     __________________________________________________________________

   in machine learning, these statements are called forks, and they split
   the data into two branches based on some value.

   that value between the branches is called a split point. homes to the
   left of that point get categorized in one way, while those to the right
   are categorized in another. a split point is the decision tree's
   version of a boundary.
     __________________________________________________________________

tradeoffs

   picking a split point has tradeoffs. our initial split (~73 m)
   incorrectly classifies some san francisco homes as new york ones.

   look at that large slice of green in the left pie chart, those are all
   the san francisco homes that are misclassified. these are called false
   negatives.
     __________________________________________________________________

   however, a split point meant to capture every san francisco home will
   include many new york homes as well. these are called false positives.
     __________________________________________________________________

the best split

   at the best split, the results of each branch should be as homogeneous
   (or pure) as possible. there are several mathematical methods you can
   choose between to calculate the best split.
     __________________________________________________________________

   as we see here, even the best split on a single feature does not fully
   separate the san francisco homes from the new york ones.
     __________________________________________________________________
     __________________________________________________________________

recursion

   to add another split point, the algorithm repeats the process above on
   the subsets of data. this repetition is called recursion, and it is a
   concept that appears frequently in training models.

   the histograms to the left show the distribution of each subset,
   repeated for each variable.
     __________________________________________________________________

   the best split will vary based which branch of the tree you are looking
   at.

   for lower elevation homes, price per square foot is, at $1061 per sqft,
   is the best variable for the next if-then statement. for higher
   elevation homes, it is price, at $514,500
   .
     __________________________________________________________________
     __________________________________________________________________

growing a tree

   additional forks will add new information that can increase a tree's
   prediction accuracy.
     __________________________________________________________________

   splitting one layer deeper, the tree's accuracy improves to 84%.
     __________________________________________________________________

   adding several more layers, we get to 96%.
     __________________________________________________________________

   you could even continue to add branches until the tree's predictions
   are 100% accurate, so that at the end of every branch, the homes are
   purely in san francisco or purely in new york.
     __________________________________________________________________

   these ultimate branches of the tree are called leaf nodes. our decision
   tree models will classify the homes in each leaf node according to
   which class of homes is in the majority.
     __________________________________________________________________
     __________________________________________________________________

making predictions

   the newly-trained decision tree model determines whether a home is in
   san francisco or new york by running each data point through the
   branches.
     __________________________________________________________________

   here you can see the data that was used to train the tree flow through
   the tree.

   this data is called training data because it was used to train the
   model.
     __________________________________________________________________

   because we grew the tree until it was 100% accurate, this tree maps
   each training data point perfectly to which city it is in.
     __________________________________________________________________

reality check

   of course, what matters more is how the tree performs on
   previously-unseen data.
     __________________________________________________________________

   to test the tree's performance on new data, we need to apply it to data
   points that it has never seen before. this previously unused data is
   called test data.
     __________________________________________________________________

   ideally, the tree should perform similarly on both known and unknown
   data.
     __________________________________________________________________

   so this one is less than ideal.
     __________________________________________________________________

   these errors are due to overfitting. our model has learned to treat
   every detail in the training data as important, even details that
   turned out to be irrelevant.

   overfitting is part of a fundamental concept in machine learning
   explained in our next post.
     __________________________________________________________________
     __________________________________________________________________

recap

    1. machine learning identifies patterns using statistical learning and
       computers by unearthing boundaries in data sets. you can use it to
       make predictions.
    2. one method for making predictions is called a id90, which
       uses a series of if-then statements to identify boundaries and
       define patterns in the data.
    3. overfitting happens when some boundaries are based on on
       distinctions that don't make a difference. you can see if a model
       overfits by having test data flow through the model.
     __________________________________________________________________

coming up next

   next, we explore overfitting, and how it relates to a fundamental
   trade-off in machine learning. [16]check out part ii: model tuning and
   the id160.

   questions? thoughts? we would love to hear from you. tweet us at
   [17]@r2d3us or email us at [18]team@r2d3.us.
     __________________________________________________________________

   follow us on twitter...

     a visual introduction to machine learning
     posted by [19]@r2d3us on [20]twitter

   ...or facebook...

     a visual introduction to machine learning
     posted by [21]r2d3 on [22]facebook

   ...or keep in touch with email

posts from r2d3.us

   your email here_____
   (button) keep in touch!
     __________________________________________________________________

footnotes

    1. machine learning concepts have arisen across disciplines (computer
       science, statistics, engineering, psychology, etc), thus the
       different nomenclature.
    2. to learn more about calculating the optimal split, search for 'gini
       index' or 'cross id178'
    3. one reason computers are so good at applying statistical learning
       techniques is that they're able to do repetitive tasks, very
       quickly and without getting bored.
    4. the algorithm described here is greedy, because it takes a top-down
       approach to splitting the data. in other words, it is looking for
       the variable that makes each subset the most homogeneous at that
       moment.
    5. hover over the dots to see the path it took in the tree.
    6. spoiler alert: it's the bias/variance tradeoff!

   we are so sorry, but we designed this site for desktop rather than
   mobile viewing. please come back on a desktop (or a screen at least
   1024 by 768 pixels in size)!

      or go ahead anyway.

   [23]r2d3

   r2d3 is an experiment in expressing statistical thinking with
   interactive design. find us at [24]@r2d3us.

   questions? check out the [25]faqs.
   stephanie

stephanie interprets r2

   stephanie is currently at [26]stitch fix ([27]& hiring !!!). in the
   past, she's been at [28]cardiogram, [29]sift science, google, [30]bain
   & company, and [31]vector capital. she's got a ms in statistics from
   stanford.

   find stephanie: [32]linkedin [33]twitter [34]email
   tony

tony visualizes with d3

   tony is a designer who loves data visualizations and information
   design. he is currently a principal designer at [35]noodle analytics.
   prior to noodle, tony led user experience and product design at [36]h2o
   and at [37]sift science. he holds an [38]mfa in interaction design at
   the school of visual arts in new york city, where he tried to
   [39]change congress with a fancy infographic.

   find tony: [40]portfolio [41]twitter [42]blog [43]linkedin [44]email

references

   1. http://www.r2d3.us/visuelle-einfuehrung-ins-maschinelle-lernen-teil-1/
   2. http://www.r2d3.us/                           /
   3. http://www.r2d3.us/pengantar-visual-pembelajaran-mesin-bag-1/
   4. http://www.r2d3.us/una-introduzione-visuale-al-machine-learning-1/
   5. http://www.r2d3.us/                  /
   6. http://www.r2d3.us/uma-introducao-visual-ao-aprendizado-de-maquina-1/
   7. http://www.r2d3.us/makine-ogrenmesine-gorsel-baslangic-1/
   8. http://www.r2d3.us/una-introduccion-visual-al-machine-learning-1/
   9. http://www.r2d3.us/            -                -      -                -            -          -1/
  10. http://www.r2d3.us/lapprentissage-automatique-en-images-chapitre-1/
  11. http://www.r2d3.us/visual-intro-to-machine-learning-part-1-ar/
  12. http://www.r2d3.us/                  -                -  -            -                  -                /
  13. http://www.r2d3.us/visual-intro-to-machine-learning-part-1/
  14. http://www.r2d3.us/visual-intro-to-machine-learning-part-1/
  15. http://www.r2d3.us/
  16. http://www.r2d3.us/visual-intro-to-machine-learning-part-2/
  17. https://twitter.com/r2d3us
  18. mailto:team@r2d3.us
  19. https://www.twitter.com/r2d3us
  20. https://twitter.com/r2d3us/status/625681063893864449
  21. https://www.facebook.com/r2d3us/
  22. https://www.facebook.com/r2d3us/posts/482259961951419
  23. http://www.r2d3.us/
  24. https://twitter.com/r2d3us
  25. http://www.r2d3.us/about/faqs/
  26. http://multithreaded.stitchfix.com/algorithms/
  27. http://multithreaded.stitchfix.com/careers/
  28. https://cardiogr.am/
  29. https://siftscience.com/
  30. http://www.bain.com/
  31. http://www.vectorcapital.com/
  32. http://www.linkedin.com/in/stephaniejyee
  33. http://twitter.com/stephaniejyee
  34. mailto:yee@r2d3.us
  35. http://noodle.ai/
  36. http://h2o.ai/
  37. https://siftscience.com/
  38. http://interactiondesign.sva.edu/
  39. http://letsfreecongress.org/
  40. http://tonyhschu.ca/
  41. http://twitter.com/tonyhschu/
  42. http://blog.tonyhschu.ca/
  43. https://www.linkedin.com/in/tonyhschu
  44. mailto:chu@r2d3.us
