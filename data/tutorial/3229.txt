   #[1]google ai blog - atom [2]google ai blog - rss [3]google ai blog -
   atom

   [4][googleai_logo_horizontal_color_rgb.png] [5]

blog

   the latest news from google ai

[6]teaching machines to draw

   thursday, april 13, 2017
   posted by david ha, google brain resident
   abstract visual communication is a key part of how people convey ideas
   to one another. from a young age, children develop the ability to
   depict objects, and arguably even emotions, with only a few pen
   strokes. these simple drawings may not resemble reality as captured by
   a photograph, but they do tell us something about how people represent
   and reconstruct images of the world around them.

                           [7][twitter_cover.png]
                   vector drawings produced by sketch-id56.

   in our recent paper,    [8]a neural representation of sketch drawings   ,
   we present a generative [9]recurrent neural network capable of
   producing sketches of common objects, with the goal of training a
   machine to draw and generalize abstract concepts in a manner similar to
   humans. we train our model on a dataset of hand-drawn sketches, each
   represented as a sequence of motor actions controlling a pen: which
   direction to move, when to lift the pen up, and when to stop drawing.
   in doing so, we created a model that potentially has many applications,
   from assisting the creative process of an artist, to helping teach
   students how to draw.
   while there is a already a large body of existing work on generative
   modelling of images using neural networks, most of the work focuses on
   modelling [10]raster images represented as a 2d grid of pixels. while
   these models are currently able to generate realistic images, due to
   the high dimensionality of a 2d grid of pixels, a key challenge for
   them is to generate images with coherent structure. for example, these
   models sometimes produce amusing images of cats with three or more
   eyes, or dogs with multiple heads.

                                          [11][image02.png]
     examples of animals generated with the wrong number of body parts,
   produced using previous gan models trained on 128x128 id163 dataset.
                       the image above is figure 29 of
       [12]id3, ian goodfellow, nips 2016
                                  tutorial.

   in this work, we investigate a lower-dimensional vector-based
   representation inspired by how people draw. our model, sketch-id56, is
   based on the [13]sequence-to-sequence (id195) autoencoder framework.
   it incorporates [14]variational id136 and utilizes
   [15]hypernetworks as recurrent neural network cells. the goal of a
   id195 autoencoder is to train a network to encode an input sequence
   into a vector of floating point numbers, called a latent vector, and
   from this latent vector reconstruct an output sequence using a decoder
   that replicates the input sequence as closely as possible.

                           [16][sketch_id56.png]
                          schematic of sketch-id56.

   in our model, we deliberately add noise to the latent vector. in our
   paper, we show that by inducing noise into the communication channel
   between the encoder and the decoder, the model is no longer be able to
   reproduce the input sketch exactly, but instead must learn to capture
   the essence of the sketch as a noisy latent vector. our decoder takes
   this latent vector and produces a sequence of motor actions used to
   construct a new sketch. in the figure below, we feed several actual
   sketches of cats into the encoder to produce reconstructed sketches
   using the decoder.

                             [17][image11.png]
            reconstructions from a model trained on cat sketches.

   it is important to emphasize that the reconstructed cat sketches are
   not copies of the input sketches, but are instead new sketches of cats
   with similar characteristics as the inputs. to demonstrate that the
   model is not simply copying from the input sequence, and that it
   actually learned something about the way people draw cats, we can try
   to feed in non-standard sketches into the encoder:
   [18][image13.png]
   when we feed in a sketch of a three-eyed cat, the model generates a
   similar looking cat that has two eyes instead, suggesting that our
   model has learned that cats usually only have two eyes. to show that
   our model is not simply choosing the closest normal-looking cat from a
   large collection of memorized cat-sketches, we can try to input
   something totally different, like a sketch of a toothbrush. we see that
   the network generates a cat-like figure with long whiskers that mimics
   the features and orientation of the toothbrush. this suggests that the
   network has learned to encode an input sketch into a set of abstract
   cat-concepts embedded into the latent vector, and is also able to
   reconstruct an entirely new sketch based on this latent vector.
   not convinced? we repeat the experiment again on a model trained on pig
   sketches and arrive at similar conclusions. when presented with an
   eight-legged pig, the model generates a similar pig with only four
   legs. if we feed a truck into the pig-drawing model, we get a pig that
   looks a bit like the truck.

                             [19][image10.png]
            reconstructions from a model trained on pig sketches.

   to investigate how these latent vectors encode conceptual animal
   features, in the figure below, we first obtain two latent vectors
   encoded from two very different pigs, in this case a pig head (in the
   green box) and a full pig (in the orange box). we want to get a sense
   of how our model learned to represent pigs, and one way to do this is
   to interpolate between the two different latent vectors, and visualize
   each generated sketch from each interpolated latent vector. in the
   figure below, we visualize how the sketch of the pig head slowly morphs
   into the sketch of the full pig, and in the process show how the model
   organizes the concepts of pig sketches. we see that the latent vector
   controls the relatively position and size of the nose relative to the
   head, and also the existence of the body and legs in the sketch.

                                         [20][image04.png]
      latent space interpolations generated from a model trained on pig
                                  sketches.

   we would also like to know if our model can learn representations of
   multiple animals, and if so, what would they look like? in the figure
   below, we generate sketches from interpolating latent vectors between a
   cat head and a full pig. we see how the representation slowly
   transitions from a cat head, to a cat with a tail, to a cat with a fat
   body, and finally into a full pig. like a child learning to draw
   animals, our model learns to construct animals by attaching a head,
   feet, and a tail to its body. we see that the model is also able to
   draw cat heads that are distinct from pig heads.

                                          [21][image12.png]
    latent space interpolations from a model trained on sketches of both
                               cats and pigs.

   these interpolation examples suggest that the latent vectors indeed
   encode conceptual features of a sketch. but can we use these features
   to augment other sketches without such features - for example, adding a
   body to a cat's head?

                                           [22][image05.png]
   learned relationships between abstract concepts, explored using latent
                             vector arithmetic.

   indeed, we find that sketch drawing analogies are possible for our
   model trained on both cat and pig sketches. for example, we can
   subtract the latent vector of an encoded pig head from the latent
   vector of a full pig, to arrive at a vector that represents the concept
   of a body. adding this difference to the latent vector of a cat head
   results in a full cat (i.e. cat head + body = full cat). these drawing
   analogies allow us to explore how the model organizes its latent space
   to represent different concepts in the manifold of generated sketches.
   creative applications
   in addition to the research component of this work, we are also super
   excited about potential creative applications of sketch-id56. for
   instance, even in the simplest use case, pattern designers can apply
   sketch-id56 to generate a large number of similar, but unique designs
   for textile or wallpaper prints.

                                  [23][multi_cat_examples.png]
    similar, but unique cats, generated from a single input sketch (green
                             and yellow boxes).

   as we saw earlier, a model trained to draw pigs can be made to draw
   pig-like trucks if given an input sketch of a truck. we can extend this
   result to applications that might help creative designers come up with
   abstract designs that can resonate more with their target audience.
   for instance, in the figure below, we feed sketches of four different
   chairs into our cat-drawing model to produce four chair-like cats. we
   can go further and incorporate the interpolation methodology described
   earlier to explore the latent space of chair-like cats, and produce a
   large grid of generated designs to select from.

                             [24][image03.png]
             exploring the latent space of generated chair-cats.

   exploring the latent space between different objects can potentially
   enable creative designers to find interesting intersections and
   relationships between different drawings.

                              [25][multiple_interpolations.png]
    exploring the latent space of generated sketches of everyday objects.
   latent space interpolation from left to right, and then top to bottom.

   we can also use the decoder module of sketch-id56 as a standalone model
   and train it to predict different possible endings of incomplete
   sketches. this technique can lead to applications where the model
   assists the creative process of an artist by suggesting alternative
   ways to finish an incomplete sketch. in the figure below, we draw
   different incomplete sketches (in red), and have the model come up with
   different possible ways to complete the drawings.

                                    [26][full_predictions.png]
   the model can start with incomplete sketches (the red partial sketches
   to the left of the vertical line) and automatically generate different
                                completions.

   we can take this concept even further, and have different models
   complete the same incomplete sketch. in the figures below, we see how
   to make the same circle and square figures become a part of various
   ants, flamingos, helicopters, owls, couches and even paint brushes. by
   using a diverse set of models trained to draw various objects,
   designers can explore creative ways to communicate meaningful visual
   messages to their audience.

                                    [27][multi_prediction.png]
    predicting the endings of the same circle and square figures (center)
     using various sketch-id56 models trained to draw different objects.

   we are very excited about the future possibilities of generative vector
   image modelling. these models will enable many exciting new creative
   applications in a variety of different directions. they can also serve
   as a tool to help us improve our understanding of our own creative
   thought processes. learn more about sketch-id56 by reading our paper,
      [28]a neural representation of sketch drawings   .
   acknowledgements
   we thank ian johnson, jonas jongejan, martin wattenberg, mike schuster,
   ben poole, kyle kastner, junyoung chung, kyle mcdonald for their help
   with this project. this work was done as part of the [29]google brain
   residency program.
   share on twitter share on facebook
   [30]    [31]    [32]   
   ____________________
   [ncccficb87qzqmia5fsjfoui0zmnmrvipu1ormhquxgtxusaccflxjqblbln4uoafglw8b
   katws5ec6cbebwvcshbiivxbkgqrcvbadii4uktabsesvgwgb9ezht3+tnwyo0qa9soiytv
   aqyaqdjhawwemecaaaaasuvork5cyii=]

labels

      
     * [33]2018
     * [34]accessibility
     * [35]acl
     * [36]acm
     * [37]acoustic modeling
     * [38]adaptive data analysis
     * [39]ads
     * [40]adsense
     * [41]adwords
     * [42]africa
     * [43]ai
     * [44]algorithms
     * [45]android
     * [46]android wear
     * [47]api
     * [48]app engine
     * [49]app inventor
     * [50]april fools
     * [51]art
     * [52]audio
     * [53]augmented reality
     * [54]australia
     * [55]automatic id103
     * [56]awards
     * [57]bigquery
     * [58]cantonese
     * [59]chemistry
     * [60]china
     * [61]chrome
     * [62]cloud computing
     * [63]collaboration
     * [64]compression
     * [65]computational imaging
     * [66]computational photography
     * [67]computer science
     * [68]id161
     * [69]conference
     * [70]conferences
     * [71]conservation
     * [72]correlate
     * [73]course builder
     * [74]crowd-sourcing
     * [75]cvpr
     * [76]data center
     * [77]data discovery
     * [78]data science
     * [79]datasets
     * [80]deep learning
     * [81]deepdream
     * [82]deepmind
     * [83]distributed systems
     * [84]diversity
     * [85]earth engine
     * [86]economics
     * [87]education
     * [88]electronic commerce and algorithms
     * [89]electronics
     * [90]emea
     * [91]emnlp
     * [92]encryption
     * [93]entities
     * [94]entity salience
     * [95]environment
     * [96]europe
     * [97]exacycle
     * [98]expander
     * [99]faculty institute
     * [100]faculty summit
     * [101]flu trends
     * [102]fusion tables
     * [103]gamification
     * [104]gboard
     * [105]gmail
     * [106]google accelerated science
     * [107]google books
     * [108]google brain
     * [109]google cloud platform
     * [110]google docs
     * [111]google drive
     * [112]google genomics
     * [113]google maps
     * [114]google photos
     * [115]google play apps
     * [116]google science fair
     * [117]google sheets
     * [118]google translate
     * [119]google trips
     * [120]google voice search
     * [121]google+
     * [122]government
     * [123]grants
     * [124]graph
     * [125]graph mining
     * [126]hardware
     * [127]hci
     * [128]health
     * [129]high dynamic range imaging
     * [130]iclr
     * [131]icml
     * [132]icse
     * [133]image annotation
     * [134]image classification
     * [135]image processing
     * [136]inbox
     * [137]india
     * [138]information retrieval
     * [139]internationalization
     * [140]internet of things
     * [141]interspeech
     * [142]ipython
     * [143]journalism
     * [144]jsm
     * [145]jsm2011
     * [146]k-12
     * [147]kdd
     * [148]keyboard input
     * [149]klingon
     * [150]korean
     * [151]labs
     * [152]linear optimization
     * [153]localization
     * [154]low-light photography
     * [155]machine hearing
     * [156]machine intelligence
     * [157]machine learning
     * [158]machine perception
     * [159]machine translation
     * [160]magenta
     * [161]mapreduce
     * [162]market algorithms
     * [163]market research
     * [164]mixed reality
     * [165]ml
     * [166]ml fairness
     * [167]mooc
     * [168]moore's law
     * [169]multimodal learning
     * [170]naacl
     * [171]natural language processing
     * [172]natural language understanding
     * [173]network management
     * [174]networks
     * [175]neural networks
     * [176]neurips
     * [177]nexus
     * [178]ngram
     * [179]nips
     * [180]nlp
     * [181]on-device learning
     * [182]open source
     * [183]operating systems
     * [184]id42
     * [185]optimization
     * [186]osdi
     * [187]osdi10
     * [188]patents
     * [189]peer review
     * [190]ph.d. fellowship
     * [191]phd fellowship
     * [192]photoscan
     * [193]physics
     * [194]pilab
     * [195]pixel
     * [196]policy
     * [197]professional development
     * [198]proposals
     * [199]public data explorer
     * [200]publication
     * [201]publications
     * [202]quantum ai
     * [203]quantum computing
     * [204]id23
     * [205]renewable energy
     * [206]research
     * [207]research awards
     * [208]resource optimization
     * [209]robotics
     * [210]schema.org
     * [211]search
     * [212]search ads
     * [213]security and privacy
     * [214]semantic models
     * [215]semi-supervised learning
     * [216]sigcomm
     * [217]sigmod
     * [218]site reliability engineering
     * [219]social networks
     * [220]software
     * [221]sound search
     * [222]speech
     * [223]id103
     * [224]statistics
     * [225]structured data
     * [226]style transfer
     * [227]supervised learning
     * [228]systems
     * [229]tensorboard
     * [230]tensorflow
     * [231]tpu
     * [232]translate
     * [233]trends
     * [234]tts
     * [235]tv
     * [236]ui
     * [237]university relations
     * [238]unix
     * [239]user experience
     * [240]video
     * [241]video analysis
     * [242]virtual reality
     * [243]vision research
     * [244]visiting faculty
     * [245]visualization
     * [246]vldb
     * [247]voice search
     * [248]wiki
     * [249]wikipedia
     * [250]www
     * [251]year in review
     * [252]youtube

      

archive

      
     *     [253]      [254]2019
          + [255]apr
          + [256]mar
          + [257]feb
          + [258]jan

     *     [259]      [260]2018
          + [261]dec
          + [262]nov
          + [263]oct
          + [264]sep
          + [265]aug
          + [266]jul
          + [267]jun
          + [268]may
          + [269]apr
          + [270]mar
          + [271]feb
          + [272]jan

     *     [273]      [274]2017
          + [275]dec
          + [276]nov
          + [277]oct
          + [278]sep
          + [279]aug
          + [280]jul
          + [281]jun
          + [282]may
          + [283]apr
          + [284]mar
          + [285]feb
          + [286]jan

     *     [287]      [288]2016
          + [289]dec
          + [290]nov
          + [291]oct
          + [292]sep
          + [293]aug
          + [294]jul
          + [295]jun
          + [296]may
          + [297]apr
          + [298]mar
          + [299]feb
          + [300]jan

     *     [301]      [302]2015
          + [303]dec
          + [304]nov
          + [305]oct
          + [306]sep
          + [307]aug
          + [308]jul
          + [309]jun
          + [310]may
          + [311]apr
          + [312]mar
          + [313]feb
          + [314]jan

     *     [315]      [316]2014
          + [317]dec
          + [318]nov
          + [319]oct
          + [320]sep
          + [321]aug
          + [322]jul
          + [323]jun
          + [324]may
          + [325]apr
          + [326]mar
          + [327]feb
          + [328]jan

     *     [329]      [330]2013
          + [331]dec
          + [332]nov
          + [333]oct
          + [334]sep
          + [335]aug
          + [336]jul
          + [337]jun
          + [338]may
          + [339]apr
          + [340]mar
          + [341]feb
          + [342]jan

     *     [343]      [344]2012
          + [345]dec
          + [346]oct
          + [347]sep
          + [348]aug
          + [349]jul
          + [350]jun
          + [351]may
          + [352]apr
          + [353]mar
          + [354]feb
          + [355]jan

     *     [356]      [357]2011
          + [358]dec
          + [359]nov
          + [360]sep
          + [361]aug
          + [362]jul
          + [363]jun
          + [364]may
          + [365]apr
          + [366]mar
          + [367]feb
          + [368]jan

     *     [369]      [370]2010
          + [371]dec
          + [372]nov
          + [373]oct
          + [374]sep
          + [375]aug
          + [376]jul
          + [377]jun
          + [378]may
          + [379]apr
          + [380]mar
          + [381]feb
          + [382]jan

     *     [383]      [384]2009
          + [385]dec
          + [386]nov
          + [387]aug
          + [388]jul
          + [389]jun
          + [390]may
          + [391]apr
          + [392]mar
          + [393]feb
          + [394]jan

     *     [395]      [396]2008
          + [397]dec
          + [398]nov
          + [399]oct
          + [400]sep
          + [401]jul
          + [402]may
          + [403]apr
          + [404]mar
          + [405]feb

     *     [406]      [407]2007
          + [408]oct
          + [409]sep
          + [410]aug
          + [411]jul
          + [412]jun
          + [413]feb

     *     [414]      [415]2006
          + [416]dec
          + [417]nov
          + [418]sep
          + [419]aug
          + [420]jul
          + [421]jun
          + [422]apr
          + [423]mar
          + [424]feb

   [425][8lnoxywfhzg4leaaqaaqheayuzhbaaaaabjru5erkjggg==]

feed

   (button) follow @googleai
   give us feedback in our [426]product forums.

   [427][p2daydaadwwawgawgg8fgmbgmbopbydd2cf8imaddrgoqte+e9aaaaabjru5erkjg
   gg==]
     * [428]google
     * [429]privacy
     * [430]terms

references

   visible links
   1. http://ai.googleblog.com/feeds/posts/default
   2. http://ai.googleblog.com/feeds/posts/default?alt=rss
   3. http://ai.googleblog.com/feeds/4616600409527198587/comments/default
   4. http://ai.googleblog.com/
   5. https://ai.googleblog.com/.
   6. http://ai.googleblog.com/2017/04/teaching-machines-to-draw.html
   7. https://1.bp.blogspot.com/-x0o-v6sqxti/wo6r8x22wli/aaaaaaaabts/qbvu5qovwzifkb-zev7po_juh9aqeb28gclcb/s1600/twitter_cover.png
   8. https://arxiv.org/abs/1704.03477
   9. https://en.wikipedia.org/wiki/recurrent_neural_network
  10. https://en.wikipedia.org/wiki/raster_graphics
  11. https://2.bp.blogspot.com/-6s_kqoj291m/wo6tjerwcdi/aaaaaaaabtw/ajqbzkwfdn0grrji1dvypty2g0b8o2xmgclcb/s1600/image02.png
  12. https://arxiv.org/abs/1701.00160
  13. https://research.google.com/pubs/pub43155.html
  14. https://research.googleblog.com/2014/12/advances-in-variational-id136.html
  15. https://research.google.com/pubs/pub45823.html
  16. https://1.bp.blogspot.com/-iuml0km0cv0/wo6u0ukcayi/aaaaaaaabt0/wsbg174lgtqsljgg2q6jkeotfp1eh3o3aclcb/s1600/sketch_id56.png
  17. https://4.bp.blogspot.com/-oaplgibet6s/wo6voprpzki/aaaaaaaabt4/vxkp4yy8-0guidu6ahkfp0vdnajbx5ssgclcb/s1600/image11.png
  18. https://1.bp.blogspot.com/-0t75jklzl7s/wo6vp1zirzi/aaaaaaaabt8/0gue3svceimntetsj2ontrb4tivytgkhqclcb/s1600/image13.png
  19. https://3.bp.blogspot.com/-5lztxfr0le8/wo6v6ym5voi/aaaaaaaabua/b5xkhbztsc4gke1r_sgdotkcmjzcje_bqclcb/s1600/image10.png
  20. https://3.bp.blogspot.com/-ttbabzubnd0/wo6wlyrmwti/aaaaaaaabue/ctutyj42bw8lbdm3u2-sgg3hktmrc84bqclcb/s1600/image04.png
  21. https://1.bp.blogspot.com/-gou3inivwg4/wo6xbiwe20i/aaaaaaaabui/qjwheugjbnwg5zrhknw2rcq1hzy868lggclcb/s1600/image12.png
  22. https://4.bp.blogspot.com/-yk7t-68xtza/wo6xntib66i/aaaaaaaabum/pqb64rz_ygmym3ekp2bejojnclhsamxqgclcb/s1600/image05.png
  23. https://4.bp.blogspot.com/-jkzxgg1pusy/wo6ynlzvffi/aaaaaaaabuq/_divckjwhheecmeixohcsng8v4rhdt3cwclcb/s1600/multi_cat_examples.png
  24. https://2.bp.blogspot.com/-xsxuqnjgaiu/wo6zbuts4gi/aaaaaaaabuu/ixrslolmzposzprhx797htnp65uvrhwcqclcb/s1600/image03.png
  25. https://2.bp.blogspot.com/-f1c-zcwb_xi/wo6zpv3a7si/aaaaaaaabuy/lilxxrw-kly2t0afdhjq2kugmjyjqoqagclcb/s1600/multiple_interpolations.png
  26. https://3.bp.blogspot.com/-tpppe68eusw/wo6zgdendvi/aaaaaaaabuc/3vhmomdz1litxqm65s4js1xvqopyyahzaclcb/s1600/full_predictions.png
  27. https://1.bp.blogspot.com/-5l1fyhe6o20/wo6zwamif2i/aaaaaaaabug/eecoxzlb9mgcmnjauhhpwftufchrzhm3aclcb/s1600/multi_prediction.png
  28. https://arxiv.org/abs/1704.03477
  29. https://g.co/brainresidency
  30. http://ai.googleblog.com/
  31. http://ai.googleblog.com/2017/04/photoscan-taking-glare-free-pictures-of.html
  32. http://ai.googleblog.com/2017/04/introducing-tf-id195-open-source.html
  33. http://ai.googleblog.com/search/label/2018
  34. http://ai.googleblog.com/search/label/accessibility
  35. http://ai.googleblog.com/search/label/acl
  36. http://ai.googleblog.com/search/label/acm
  37. http://ai.googleblog.com/search/label/acoustic modeling
  38. http://ai.googleblog.com/search/label/adaptive data analysis
  39. http://ai.googleblog.com/search/label/ads
  40. http://ai.googleblog.com/search/label/adsense
  41. http://ai.googleblog.com/search/label/adwords
  42. http://ai.googleblog.com/search/label/africa
  43. http://ai.googleblog.com/search/label/ai
  44. http://ai.googleblog.com/search/label/algorithms
  45. http://ai.googleblog.com/search/label/android
  46. http://ai.googleblog.com/search/label/android wear
  47. http://ai.googleblog.com/search/label/api
  48. http://ai.googleblog.com/search/label/app engine
  49. http://ai.googleblog.com/search/label/app inventor
  50. http://ai.googleblog.com/search/label/april fools
  51. http://ai.googleblog.com/search/label/art
  52. http://ai.googleblog.com/search/label/audio
  53. http://ai.googleblog.com/search/label/augmented reality
  54. http://ai.googleblog.com/search/label/australia
  55. http://ai.googleblog.com/search/label/automatic id103
  56. http://ai.googleblog.com/search/label/awards
  57. http://ai.googleblog.com/search/label/bigquery
  58. http://ai.googleblog.com/search/label/cantonese
  59. http://ai.googleblog.com/search/label/chemistry
  60. http://ai.googleblog.com/search/label/china
  61. http://ai.googleblog.com/search/label/chrome
  62. http://ai.googleblog.com/search/label/cloud computing
  63. http://ai.googleblog.com/search/label/collaboration
  64. http://ai.googleblog.com/search/label/compression
  65. http://ai.googleblog.com/search/label/computational imaging
  66. http://ai.googleblog.com/search/label/computational photography
  67. http://ai.googleblog.com/search/label/computer science
  68. http://ai.googleblog.com/search/label/id161
  69. http://ai.googleblog.com/search/label/conference
  70. http://ai.googleblog.com/search/label/conferences
  71. http://ai.googleblog.com/search/label/conservation
  72. http://ai.googleblog.com/search/label/correlate
  73. http://ai.googleblog.com/search/label/course builder
  74. http://ai.googleblog.com/search/label/crowd-sourcing
  75. http://ai.googleblog.com/search/label/cvpr
  76. http://ai.googleblog.com/search/label/data center
  77. http://ai.googleblog.com/search/label/data discovery
  78. http://ai.googleblog.com/search/label/data science
  79. http://ai.googleblog.com/search/label/datasets
  80. http://ai.googleblog.com/search/label/deep learning
  81. http://ai.googleblog.com/search/label/deepdream
  82. http://ai.googleblog.com/search/label/deepmind
  83. http://ai.googleblog.com/search/label/distributed systems
  84. http://ai.googleblog.com/search/label/diversity
  85. http://ai.googleblog.com/search/label/earth engine
  86. http://ai.googleblog.com/search/label/economics
  87. http://ai.googleblog.com/search/label/education
  88. http://ai.googleblog.com/search/label/electronic commerce and algorithms
  89. http://ai.googleblog.com/search/label/electronics
  90. http://ai.googleblog.com/search/label/emea
  91. http://ai.googleblog.com/search/label/emnlp
  92. http://ai.googleblog.com/search/label/encryption
  93. http://ai.googleblog.com/search/label/entities
  94. http://ai.googleblog.com/search/label/entity salience
  95. http://ai.googleblog.com/search/label/environment
  96. http://ai.googleblog.com/search/label/europe
  97. http://ai.googleblog.com/search/label/exacycle
  98. http://ai.googleblog.com/search/label/expander
  99. http://ai.googleblog.com/search/label/faculty institute
 100. http://ai.googleblog.com/search/label/faculty summit
 101. http://ai.googleblog.com/search/label/flu trends
 102. http://ai.googleblog.com/search/label/fusion tables
 103. http://ai.googleblog.com/search/label/gamification
 104. http://ai.googleblog.com/search/label/gboard
 105. http://ai.googleblog.com/search/label/gmail
 106. http://ai.googleblog.com/search/label/google accelerated science
 107. http://ai.googleblog.com/search/label/google books
 108. http://ai.googleblog.com/search/label/google brain
 109. http://ai.googleblog.com/search/label/google cloud platform
 110. http://ai.googleblog.com/search/label/google docs
 111. http://ai.googleblog.com/search/label/google drive
 112. http://ai.googleblog.com/search/label/google genomics
 113. http://ai.googleblog.com/search/label/google maps
 114. http://ai.googleblog.com/search/label/google photos
 115. http://ai.googleblog.com/search/label/google play apps
 116. http://ai.googleblog.com/search/label/google science fair
 117. http://ai.googleblog.com/search/label/google sheets
 118. http://ai.googleblog.com/search/label/google translate
 119. http://ai.googleblog.com/search/label/google trips
 120. http://ai.googleblog.com/search/label/google voice search
 121. http://ai.googleblog.com/search/label/google+
 122. http://ai.googleblog.com/search/label/government
 123. http://ai.googleblog.com/search/label/grants
 124. http://ai.googleblog.com/search/label/graph
 125. http://ai.googleblog.com/search/label/graph mining
 126. http://ai.googleblog.com/search/label/hardware
 127. http://ai.googleblog.com/search/label/hci
 128. http://ai.googleblog.com/search/label/health
 129. http://ai.googleblog.com/search/label/high dynamic range imaging
 130. http://ai.googleblog.com/search/label/iclr
 131. http://ai.googleblog.com/search/label/icml
 132. http://ai.googleblog.com/search/label/icse
 133. http://ai.googleblog.com/search/label/image annotation
 134. http://ai.googleblog.com/search/label/image classification
 135. http://ai.googleblog.com/search/label/image processing
 136. http://ai.googleblog.com/search/label/inbox
 137. http://ai.googleblog.com/search/label/india
 138. http://ai.googleblog.com/search/label/information retrieval
 139. http://ai.googleblog.com/search/label/internationalization
 140. http://ai.googleblog.com/search/label/internet of things
 141. http://ai.googleblog.com/search/label/interspeech
 142. http://ai.googleblog.com/search/label/ipython
 143. http://ai.googleblog.com/search/label/journalism
 144. http://ai.googleblog.com/search/label/jsm
 145. http://ai.googleblog.com/search/label/jsm2011
 146. http://ai.googleblog.com/search/label/k-12
 147. http://ai.googleblog.com/search/label/kdd
 148. http://ai.googleblog.com/search/label/keyboard input
 149. http://ai.googleblog.com/search/label/klingon
 150. http://ai.googleblog.com/search/label/korean
 151. http://ai.googleblog.com/search/label/labs
 152. http://ai.googleblog.com/search/label/linear optimization
 153. http://ai.googleblog.com/search/label/localization
 154. http://ai.googleblog.com/search/label/low-light photography
 155. http://ai.googleblog.com/search/label/machine hearing
 156. http://ai.googleblog.com/search/label/machine intelligence
 157. http://ai.googleblog.com/search/label/machine learning
 158. http://ai.googleblog.com/search/label/machine perception
 159. http://ai.googleblog.com/search/label/machine translation
 160. http://ai.googleblog.com/search/label/magenta
 161. http://ai.googleblog.com/search/label/mapreduce
 162. http://ai.googleblog.com/search/label/market algorithms
 163. http://ai.googleblog.com/search/label/market research
 164. http://ai.googleblog.com/search/label/mixed reality
 165. http://ai.googleblog.com/search/label/ml
 166. http://ai.googleblog.com/search/label/ml fairness
 167. http://ai.googleblog.com/search/label/mooc
 168. http://ai.googleblog.com/search/label/moore's law
 169. http://ai.googleblog.com/search/label/multimodal learning
 170. http://ai.googleblog.com/search/label/naacl
 171. http://ai.googleblog.com/search/label/natural language processing
 172. http://ai.googleblog.com/search/label/natural language understanding
 173. http://ai.googleblog.com/search/label/network management
 174. http://ai.googleblog.com/search/label/networks
 175. http://ai.googleblog.com/search/label/neural networks
 176. http://ai.googleblog.com/search/label/neurips
 177. http://ai.googleblog.com/search/label/nexus
 178. http://ai.googleblog.com/search/label/ngram
 179. http://ai.googleblog.com/search/label/nips
 180. http://ai.googleblog.com/search/label/nlp
 181. http://ai.googleblog.com/search/label/on-device learning
 182. http://ai.googleblog.com/search/label/open source
 183. http://ai.googleblog.com/search/label/operating systems
 184. http://ai.googleblog.com/search/label/id42
 185. http://ai.googleblog.com/search/label/optimization
 186. http://ai.googleblog.com/search/label/osdi
 187. http://ai.googleblog.com/search/label/osdi10
 188. http://ai.googleblog.com/search/label/patents
 189. http://ai.googleblog.com/search/label/peer review
 190. http://ai.googleblog.com/search/label/ph.d. fellowship
 191. http://ai.googleblog.com/search/label/phd fellowship
 192. http://ai.googleblog.com/search/label/photoscan
 193. http://ai.googleblog.com/search/label/physics
 194. http://ai.googleblog.com/search/label/pilab
 195. http://ai.googleblog.com/search/label/pixel
 196. http://ai.googleblog.com/search/label/policy
 197. http://ai.googleblog.com/search/label/professional development
 198. http://ai.googleblog.com/search/label/proposals
 199. http://ai.googleblog.com/search/label/public data explorer
 200. http://ai.googleblog.com/search/label/publication
 201. http://ai.googleblog.com/search/label/publications
 202. http://ai.googleblog.com/search/label/quantum ai
 203. http://ai.googleblog.com/search/label/quantum computing
 204. http://ai.googleblog.com/search/label/id23
 205. http://ai.googleblog.com/search/label/renewable energy
 206. http://ai.googleblog.com/search/label/research
 207. http://ai.googleblog.com/search/label/research awards
 208. http://ai.googleblog.com/search/label/resource optimization
 209. http://ai.googleblog.com/search/label/robotics
 210. http://ai.googleblog.com/search/label/schema.org
 211. http://ai.googleblog.com/search/label/search
 212. http://ai.googleblog.com/search/label/search ads
 213. http://ai.googleblog.com/search/label/security and privacy
 214. http://ai.googleblog.com/search/label/semantic models
 215. http://ai.googleblog.com/search/label/semi-supervised learning
 216. http://ai.googleblog.com/search/label/sigcomm
 217. http://ai.googleblog.com/search/label/sigmod
 218. http://ai.googleblog.com/search/label/site reliability engineering
 219. http://ai.googleblog.com/search/label/social networks
 220. http://ai.googleblog.com/search/label/software
 221. http://ai.googleblog.com/search/label/sound search
 222. http://ai.googleblog.com/search/label/speech
 223. http://ai.googleblog.com/search/label/id103
 224. http://ai.googleblog.com/search/label/statistics
 225. http://ai.googleblog.com/search/label/structured data
 226. http://ai.googleblog.com/search/label/style transfer
 227. http://ai.googleblog.com/search/label/supervised learning
 228. http://ai.googleblog.com/search/label/systems
 229. http://ai.googleblog.com/search/label/tensorboard
 230. http://ai.googleblog.com/search/label/tensorflow
 231. http://ai.googleblog.com/search/label/tpu
 232. http://ai.googleblog.com/search/label/translate
 233. http://ai.googleblog.com/search/label/trends
 234. http://ai.googleblog.com/search/label/tts
 235. http://ai.googleblog.com/search/label/tv
 236. http://ai.googleblog.com/search/label/ui
 237. http://ai.googleblog.com/search/label/university relations
 238. http://ai.googleblog.com/search/label/unix
 239. http://ai.googleblog.com/search/label/user experience
 240. http://ai.googleblog.com/search/label/video
 241. http://ai.googleblog.com/search/label/video analysis
 242. http://ai.googleblog.com/search/label/virtual reality
 243. http://ai.googleblog.com/search/label/vision research
 244. http://ai.googleblog.com/search/label/visiting faculty
 245. http://ai.googleblog.com/search/label/visualization
 246. http://ai.googleblog.com/search/label/vldb
 247. http://ai.googleblog.com/search/label/voice search
 248. http://ai.googleblog.com/search/label/wiki
 249. http://ai.googleblog.com/search/label/wikipedia
 250. http://ai.googleblog.com/search/label/www
 251. http://ai.googleblog.com/search/label/year in review
 252. http://ai.googleblog.com/search/label/youtube
 253. javascript:void(0)
 254. http://ai.googleblog.com/2019/
 255. http://ai.googleblog.com/2019/04/
 256. http://ai.googleblog.com/2019/03/
 257. http://ai.googleblog.com/2019/02/
 258. http://ai.googleblog.com/2019/01/
 259. javascript:void(0)
 260. http://ai.googleblog.com/2018/
 261. http://ai.googleblog.com/2018/12/
 262. http://ai.googleblog.com/2018/11/
 263. http://ai.googleblog.com/2018/10/
 264. http://ai.googleblog.com/2018/09/
 265. http://ai.googleblog.com/2018/08/
 266. http://ai.googleblog.com/2018/07/
 267. http://ai.googleblog.com/2018/06/
 268. http://ai.googleblog.com/2018/05/
 269. http://ai.googleblog.com/2018/04/
 270. http://ai.googleblog.com/2018/03/
 271. http://ai.googleblog.com/2018/02/
 272. http://ai.googleblog.com/2018/01/
 273. javascript:void(0)
 274. http://ai.googleblog.com/2017/
 275. http://ai.googleblog.com/2017/12/
 276. http://ai.googleblog.com/2017/11/
 277. http://ai.googleblog.com/2017/10/
 278. http://ai.googleblog.com/2017/09/
 279. http://ai.googleblog.com/2017/08/
 280. http://ai.googleblog.com/2017/07/
 281. http://ai.googleblog.com/2017/06/
 282. http://ai.googleblog.com/2017/05/
 283. http://ai.googleblog.com/2017/04/
 284. http://ai.googleblog.com/2017/03/
 285. http://ai.googleblog.com/2017/02/
 286. http://ai.googleblog.com/2017/01/
 287. javascript:void(0)
 288. http://ai.googleblog.com/2016/
 289. http://ai.googleblog.com/2016/12/
 290. http://ai.googleblog.com/2016/11/
 291. http://ai.googleblog.com/2016/10/
 292. http://ai.googleblog.com/2016/09/
 293. http://ai.googleblog.com/2016/08/
 294. http://ai.googleblog.com/2016/07/
 295. http://ai.googleblog.com/2016/06/
 296. http://ai.googleblog.com/2016/05/
 297. http://ai.googleblog.com/2016/04/
 298. http://ai.googleblog.com/2016/03/
 299. http://ai.googleblog.com/2016/02/
 300. http://ai.googleblog.com/2016/01/
 301. javascript:void(0)
 302. http://ai.googleblog.com/2015/
 303. http://ai.googleblog.com/2015/12/
 304. http://ai.googleblog.com/2015/11/
 305. http://ai.googleblog.com/2015/10/
 306. http://ai.googleblog.com/2015/09/
 307. http://ai.googleblog.com/2015/08/
 308. http://ai.googleblog.com/2015/07/
 309. http://ai.googleblog.com/2015/06/
 310. http://ai.googleblog.com/2015/05/
 311. http://ai.googleblog.com/2015/04/
 312. http://ai.googleblog.com/2015/03/
 313. http://ai.googleblog.com/2015/02/
 314. http://ai.googleblog.com/2015/01/
 315. javascript:void(0)
 316. http://ai.googleblog.com/2014/
 317. http://ai.googleblog.com/2014/12/
 318. http://ai.googleblog.com/2014/11/
 319. http://ai.googleblog.com/2014/10/
 320. http://ai.googleblog.com/2014/09/
 321. http://ai.googleblog.com/2014/08/
 322. http://ai.googleblog.com/2014/07/
 323. http://ai.googleblog.com/2014/06/
 324. http://ai.googleblog.com/2014/05/
 325. http://ai.googleblog.com/2014/04/
 326. http://ai.googleblog.com/2014/03/
 327. http://ai.googleblog.com/2014/02/
 328. http://ai.googleblog.com/2014/01/
 329. javascript:void(0)
 330. http://ai.googleblog.com/2013/
 331. http://ai.googleblog.com/2013/12/
 332. http://ai.googleblog.com/2013/11/
 333. http://ai.googleblog.com/2013/10/
 334. http://ai.googleblog.com/2013/09/
 335. http://ai.googleblog.com/2013/08/
 336. http://ai.googleblog.com/2013/07/
 337. http://ai.googleblog.com/2013/06/
 338. http://ai.googleblog.com/2013/05/
 339. http://ai.googleblog.com/2013/04/
 340. http://ai.googleblog.com/2013/03/
 341. http://ai.googleblog.com/2013/02/
 342. http://ai.googleblog.com/2013/01/
 343. javascript:void(0)
 344. http://ai.googleblog.com/2012/
 345. http://ai.googleblog.com/2012/12/
 346. http://ai.googleblog.com/2012/10/
 347. http://ai.googleblog.com/2012/09/
 348. http://ai.googleblog.com/2012/08/
 349. http://ai.googleblog.com/2012/07/
 350. http://ai.googleblog.com/2012/06/
 351. http://ai.googleblog.com/2012/05/
 352. http://ai.googleblog.com/2012/04/
 353. http://ai.googleblog.com/2012/03/
 354. http://ai.googleblog.com/2012/02/
 355. http://ai.googleblog.com/2012/01/
 356. javascript:void(0)
 357. http://ai.googleblog.com/2011/
 358. http://ai.googleblog.com/2011/12/
 359. http://ai.googleblog.com/2011/11/
 360. http://ai.googleblog.com/2011/09/
 361. http://ai.googleblog.com/2011/08/
 362. http://ai.googleblog.com/2011/07/
 363. http://ai.googleblog.com/2011/06/
 364. http://ai.googleblog.com/2011/05/
 365. http://ai.googleblog.com/2011/04/
 366. http://ai.googleblog.com/2011/03/
 367. http://ai.googleblog.com/2011/02/
 368. http://ai.googleblog.com/2011/01/
 369. javascript:void(0)
 370. http://ai.googleblog.com/2010/
 371. http://ai.googleblog.com/2010/12/
 372. http://ai.googleblog.com/2010/11/
 373. http://ai.googleblog.com/2010/10/
 374. http://ai.googleblog.com/2010/09/
 375. http://ai.googleblog.com/2010/08/
 376. http://ai.googleblog.com/2010/07/
 377. http://ai.googleblog.com/2010/06/
 378. http://ai.googleblog.com/2010/05/
 379. http://ai.googleblog.com/2010/04/
 380. http://ai.googleblog.com/2010/03/
 381. http://ai.googleblog.com/2010/02/
 382. http://ai.googleblog.com/2010/01/
 383. javascript:void(0)
 384. http://ai.googleblog.com/2009/
 385. http://ai.googleblog.com/2009/12/
 386. http://ai.googleblog.com/2009/11/
 387. http://ai.googleblog.com/2009/08/
 388. http://ai.googleblog.com/2009/07/
 389. http://ai.googleblog.com/2009/06/
 390. http://ai.googleblog.com/2009/05/
 391. http://ai.googleblog.com/2009/04/
 392. http://ai.googleblog.com/2009/03/
 393. http://ai.googleblog.com/2009/02/
 394. http://ai.googleblog.com/2009/01/
 395. javascript:void(0)
 396. http://ai.googleblog.com/2008/
 397. http://ai.googleblog.com/2008/12/
 398. http://ai.googleblog.com/2008/11/
 399. http://ai.googleblog.com/2008/10/
 400. http://ai.googleblog.com/2008/09/
 401. http://ai.googleblog.com/2008/07/
 402. http://ai.googleblog.com/2008/05/
 403. http://ai.googleblog.com/2008/04/
 404. http://ai.googleblog.com/2008/03/
 405. http://ai.googleblog.com/2008/02/
 406. javascript:void(0)
 407. http://ai.googleblog.com/2007/
 408. http://ai.googleblog.com/2007/10/
 409. http://ai.googleblog.com/2007/09/
 410. http://ai.googleblog.com/2007/08/
 411. http://ai.googleblog.com/2007/07/
 412. http://ai.googleblog.com/2007/06/
 413. http://ai.googleblog.com/2007/02/
 414. javascript:void(0)
 415. http://ai.googleblog.com/2006/
 416. http://ai.googleblog.com/2006/12/
 417. http://ai.googleblog.com/2006/11/
 418. http://ai.googleblog.com/2006/09/
 419. http://ai.googleblog.com/2006/08/
 420. http://ai.googleblog.com/2006/07/
 421. http://ai.googleblog.com/2006/06/
 422. http://ai.googleblog.com/2006/04/
 423. http://ai.googleblog.com/2006/03/
 424. http://ai.googleblog.com/2006/02/
 425. http://googleaiblog.blogspot.com/atom.xml
 426. http://support.google.com/bin/static.py?hl=en&page=portal_groups.cs
 427. https://www.google.com/
 428. https://www.google.com/
 429. https://www.google.com/policies/privacy/
 430. https://www.google.com/policies/terms/

   hidden links:
 432. https://www.blogger.com/rearrange?blogid=8474926331452026626&widgettype=html&widgetid=html8&action=editwidget&sectionid=sidebar-top
 433. https://www.blogger.com/rearrange?blogid=8474926331452026626&widgettype=label&widgetid=label1&action=editwidget&sectionid=sidebar
 434. https://www.blogger.com/rearrange?blogid=8474926331452026626&widgettype=blogarchive&widgetid=blogarchive1&action=editwidget&sectionid=sidebar
 435. https://www.blogger.com/rearrange?blogid=8474926331452026626&widgettype=html&widgetid=html6&action=editwidget&sectionid=sidebar
 436. https://www.blogger.com/rearrange?blogid=8474926331452026626&widgettype=html&widgetid=html5&action=editwidget&sectionid=sidebar-bottom
 437. https://www.blogger.com/rearrange?blogid=8474926331452026626&widgettype=html&widgetid=html1&action=editwidget&sectionid=sidebar-bottom
