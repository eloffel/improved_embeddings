   #[1]matrices

   [2](button) scale down pusher
   [3]matrices
     * [4]home
     * [5]about
     * [6]subscribe
     * [7]github
     * [8]rss

deep neural network from scratch

   math rendering...

   in this post we will learn how a deep neural network works, [9]then
   implement one in python, then using tensorflow. as a toy example, we
   will try to predict the price of a car using the following features:
   number of kilometers travelled, its age and its type of fuel. we will
   predict the price of only one model of car because our features does
   not have data about the brand or the model of the car. let's say bmw
   serie 1. our data will come from [10]leboncoin.fr.

   our model will certainly not work very well because we are missing
   important car attributes impacting the price, but the goal is to use
   real data while keeping things simple.

data pre processing

   the first step is to normalize our data (known as feature scaling). we
   have:
     * number of kilometers: quantitative, number between 0 and 350k.
     * type of fuel: binary data diesel/gasoline.
     * age: quantitative, number between 0 and 40.
     * price: quantitative, number between 0 and 40k.

   the number of kilometers and age (both quantitative) will be normalized
   using the means and standard deviation. the goal is to bring all the
   data to the same scale, generally between $[-6, 6]$. else the number of
   kilometers will have a value up to 350k and the age up to 40 years, and
   a change in a weight value will not impact the age or number of
   kilometers in the same way. the formula for the id172 is:
   $$x' = {x-\bar{x}\over \sigma}$$
   where $x$ is the original feature dataset (all the cars), $\bar{x}$ is
   the mean of that feature dataset, and $\sigma$ is the standard
   deviation of that feature dataset. we will do it in python later.

   the type of fuel (binary) will be encoded with $-1$ for one value and
   $1$ for the other. there is no categorical data here in order to keep
   the number of features light because each categorical feature would
   become a sparse matrix of the size of the number of classes. if you
   have categorical data in your features (i.e: red, green, pink and blue
   for a feature) you must use [11]effect encoding or dummy encoding. our
   number of features will not change, only the values after the encoding.

   we will normalize the price so that all the values are between $[0,1]$.
   this is necessary because our neural network will produce results
   between $[0,1]$. if the neural network guesses a price of 0.45 for a
   car whereas our initial price is 17k, the error between the guess and
   the real price will be high, 16 999.55   . as the guess will be at most
   1, the error will be at best 16 999    and will never improve. we will
   normalize the price using the formula:

   $$\frac{x_i-\min(x)}{\max(x)-\min(x)}$$

   $x_i$ is one car price whereas $x$ is the whole price dataset. it means
   that each car price will be processed using the maximum available price
   and the minimum available price.

   our 17k    price will become something like 0.43 and if our network
   predict 0.45 it will be a good prediction. we will do the exact
   opposite from the above formula to find the price back from 0.45.

forward propagation

   so we have three inputs (features), one binary, two quantitatives and
   one quantitative output. as we will predict a quantitative variable and
   we will use past data to train our network, it is called a supervised
   regression problem.

   dnn step 1

   one input is a car.

                      number of kms   fuel   age price
                      38 000        gasoline 3   17 000

   once the data has been normalized and encoded as previously described,
   we will have.

                        number of kms fuel age price
                        1.4           -1   0.4 0.45

   as we will have more than one car, our array will have more lines.

                        number of kms fuel age price
                        1.4           -1   0.4 0.45
                        0.4           -1   0.1 0.52
                        5.4           -1   4   0.25
                        1.5           -1   1   0.31
                        ...           ...  ... ...

   we can see this array as matrix.

   $$
   x = \begin{bmatrix}
   1.4 & -1 & 0.4 & 0.45 \\
   0.4 & -1 & 0.1 & 0.52 \\
   5.4 & -1 & 4 & 0.25 \\
   1.5 & -1 & 1 & 0.31 \\
   ... & ... & ... & ...
   \end{bmatrix}
   $$

   the price is not a feature and will not be available for a new car. we
   separate inputs (features) and outputs (prediction).

   $$
   x = \begin{bmatrix}
   1.4 & -1 & 0.4 \\
   0.4 & -1 & 0.1 \\
   5.4 & -1 & 4 \\
   1.5 & -1 & 1 \\
   ... & ... & ... & ...
   \end{bmatrix}
   y = \begin{bmatrix}
   0.45 \\
   0.52 \\
   0.25 \\
   0.31 \\
   ...
   \end{bmatrix}
   $$

   for now we have two matrices $x$ and $y$, it's time to complete our
   network. we choose to have two hidden layers between our inputs and our
   output, the first layer will have three neurons and the second one two.
   the number of hidden layers and the number of neurons by layer is up to
   you. these are two hyper parameters that you have to define before
   running your neural network.

   dnn step 2

   each of our input neuron will reach all the neurons in the next layer
   because we are using a fully connected network. each link from one
   neuron to another is called a synapse and comes with a weight. a weight
   on a synapse is of the form $w_{jk}^l$ where $l$ denotes the number of
   the layer, $j$ the number of the neuron from the $l^{th}$ layer and $k$
   the number of the neuron from the $(l+1)^{th}$ layer.

   dnn step 3

   we can view the weights as a matrix.

   $$
   w^1 = \begin{bmatrix}
   w_{11}^1 & w_{12}^1 & w_{13}^1 \\
   w_{21}^1 & w_{22}^1 & w_{23}^1 \\
   w_{31}^1 & w_{32}^1 & w_{33}^1
   \end{bmatrix}
   $$

   the number of rows equals the number of features (inputs) and the
   number of columns equals the number of neurons in the layer number $2$.
   here we have three features and the first layer has three neurons so
   our $w^1$ matrix is of the size $3 \times 3$. for now i don't talk
   about the bias unit to keep things simple.

   now we compute the values of the neurons of the first hidden layer (the
   first column of green circles). for each car defined by three features,
   we will have three neurons computed for the first hidden layer. we do
   that using matrix calculus.

   let's say that we have only one car in our dataset. we don't need $y$
   for now.

   $$
   x = \begin{bmatrix}
   1.4 & -1 & 0.4 \\
   \end{bmatrix}
   $$

   our $w^1$ matrix is randomly initialized the first time so we can use
   random values for the weights.

   $$
   w^1 = \begin{bmatrix}
   0.01 & 0.05 & 0.07 \\
   0.20 & 0.041 & 0.11 \\
   0.04 & 0.56 & 0.13
   \end{bmatrix}
   $$

   the values of the neurons of the first hidden layer are called the
   activities of the first hidden layer. they will be saved into a matrix
   called $a^{(2)}$. we begin by computing $z^{(2)}$ using the formula:
   $$z^{(2)} = x.w^1$$
   $$z^{(2)} = \begin{bmatrix}
   1.4 & -1 & 0.4 \\
   \end{bmatrix} . \begin{bmatrix}
   0.01 & 0.05 & 0.07 \\
   0.20 & 0.041 & 0.11 \\
   0.04 & 0.56 & 0.13
   \end{bmatrix}$$
   $$z^{(2)} = \begin{bmatrix}
   -0.17 & 0.253 & 0.04 \\
   \end{bmatrix}$$
   we can view it on our network.

   dnn step 4

   we are almost done with the first hidden layer, we just have to apply
   an activation function on $z^{(2)}$. we can view it like that.

   dnn step 5

   once we apply an activation function element wise to $z^{(2)}$ we
   obtain $a^{(2)}$, the activities of our second layer.

   $$a^{(2)} = \sigma(z^{(2)})$$

   where $\sigma(x)$ is our activation function. the activation function
   is applied element wise and is non linear, allowing the network to
   compute complicated problems using only a small number of nodes. the
   common ones are sigmoid, tanh, relu, leaky relu, maxout. the list is
   actually [12]bigger than that. which one to choose? [13]andrej karpathy
   says the following:

     tldr:    what neuron type should i use?    use the relu non-linearity,
     be careful with your learning rates and possibly monitor the
     fraction of    dead    units in a network. if this concerns you, give
     leaky relu or maxout a try. never use sigmoid. try tanh, but expect
     it to work worse than relu/maxout.

   so we should use relu as an activation function, it is short for
   rectified linear unit and is actually quite simple. if $x$ is greater
   than 0 we take it, else we take 0.
   $$\sigma(x) = \max(0, x)$$
   nonetheless we have very little neurons and one or two dying neuron
   will undermine the results of our network (when the value of the neuron
   becomes zero). instead we will use the tanh as an activation function.

   $$ \sigma(x) = tanh(x) = {e^x-e^{-x} \over e^x+e^{-x}}$$

   so the first neuron of our first hidden layer will become:

   $$ \sigma(-0.17) = tanh(-0.17) = {e^{-0.17}-e^{0.17} \over
   e^{-0.17}+e^{0.17}} = -0.168$$

   the second one:

   $$ \sigma(0.253) = tanh(0.253) = {e^{0.253}-e^{-0.253} \over
   e^{0.253}+e^{-0.253}} = 0,248$$

   so our first hidden layer with only one car looks like:

   dnn step 6

   thanks to the matrix calculus property, each neuron of the first hidden
   layer will receive a weighted sum of the inputs. we have:

   $$z^{(2)} = \begin{bmatrix}
   1.4 & -1 & 0.4 \\
   \end{bmatrix} . \begin{bmatrix}
   0.01 & 0.05 & 0.07 \\
   0.20 & 0.041 & 0.11 \\
   0.04 & 0.56 & 0.13
   \end{bmatrix}$$

   $$z^{(2)} = \begin{bmatrix}
   -0.17 & 0.253 & 0.04 \\
   \end{bmatrix}$$

   $z^{(2)}_1$ the first neuron of the layer two, for which we found
   $-0.17$ is the result of $1.4\times0.01 + -1\times0.2 + 0.4\times0.04$
   (cf id127). if you compare this to the neural network
   drawing, you see that in fact the first neuron of the layer two is the
   input 1 (number of kms) times the weight on the synapse plus the input
   2 (type of fuel) times the weight on the synapse plus the input 3 (age)
   times the weight on the synapse. it is exactly what matrix calculus
   does for us.

   for our example we assumed that only one car was in our dataset, that's
   why $x = \begin{bmatrix}
   1.4 & -1 & 0.4 \\
   \end{bmatrix}$. in reality we will have several cars, let's say five.
   so our inputs are:

   $$x = \begin{bmatrix}
   1.4 & -1 & 0.4 \\
   0.4 & -1 & 0.1 \\
   5.4 & -1 & 4 \\
   1.5 & -1 & 1 \\
   1.8 & 1 & 1 \\
   \end{bmatrix}$$

   and our $z^{(2)}$ calculation will be:

   $$z^{(2)} = \begin{bmatrix}
   1.4 & -1 & 0.4 \\
   0.4 & -1 & 0.1 \\
   5.4 & -1 & 4 \\
   1.5 & -1 & 1 \\
   1.8 & 1 & 1 \\
   \end{bmatrix} . \begin{bmatrix}
   0.01 & 0.05 & 0.07 \\
   0.20 & 0.041 & 0.11 \\
   0.04 & 0.56 & 0.13
   \end{bmatrix}$$

   $$z^{(2)} = \begin{bmatrix}
   -0.17 & 0.253 & 0.04 \\
   -0.192 & 0.035 & -0.069 \\
   0.014 & 2.469 & 0.788 \\
   -0.145 & 0.594 & 0.125 \\
   0.258 & 0.691 & 0.366
   \end{bmatrix}$$

   with the tanh applied element wise:

   $$a^{(2)} = \sigma(z^{(2)}) = tanh(z^{(2)}) = \begin{bmatrix}
   tanh(-0.17) & tanh(0.253) & tanh(0.04) \\
   tanh(-0.192) & tanh(0.035) & tanh(-0.069) \\
   tanh(0.014) & tanh(2.469) & tanh(0.788) \\
   tanh(-0.145) & tanh(0.594) & tanh(0.125) \\
   tanh(0.258) & tanh(0.691) & tanh(0.366)
   \end{bmatrix}$$

   $$a^{(2)} = \begin{bmatrix}
   -0.16838105 & 0.24773663 & 0.03997868 \\
   -0.18967498 & 0.03498572 & -0.06889071 \\
   0.01399909 & 0.98576421 & 0.65727455 \\
   -0.14399227 & 0.53276635 & 0.124353 \\
   0.25242392 & 0.59862403 & 0.35048801
   \end{bmatrix}$$

   $z^{(2)}$ and $a^{(2)}$ are of size $5\times3$, one row for each car
   and one column for each hidden unit (neuron) of the layer 2.

   to summarise, for now we have three matrices, our input $x$, our
   weights $w^1$ between the layer 1 and 2 and our first hidden layer
   $a^{(2)}=tanh(x.w^1)$ ($z^{(2)}$ is an intermediary matrix that holds
   the value of $x.w^1$).

   dnn step 7

   we will repeat the exact same steps but instead of using our matrix $x$
   as inputs, we will now use $a^{(2)}$. we add synapses from the layer 2
   to the layer 3.

   dnn step 8

   we also view the weights as a matrix.

   $$w^2 = \begin{bmatrix}
   w_{11}^2 & w_{12}^2 \\
   w_{21}^2 & w_{22}^2 \\
   w_{31}^2 & w_{32}^2
   \end{bmatrix}$$

   the number of rows equals the number of neurons in the layer 2 and the
   number of columns equals the number of neurons in the layer 3. we will
   compute the values of our second hidden layer into the matrix $z^{(3)}$
   as we did previously. for a given layer, the input is always the output
   of the previous layer. for the layer 2, the output of the previous
   layer are the data from the layer 1, meaning $x$, for the layer 3 the
   output of the previous layer are the data from the layer 2, meaning
   $a^{(2)}$.

   $$z^{(3)} = a^{(2)}.w^2$$

   and then we apply the activation function, we are keeping $tanh(x)$ as
   activation function because it is unusual to use different activation
   functions for each layer.

   $$a^{(3)} = tanh(z^{(3)})$$

   previously we found that:

   $$a^{(2)} = \begin{bmatrix}
   -0.16838105 & 0.24773663 & 0.03997868 \\
   -0.18967498 & 0.03498572 & -0.06889071 \\
   0.01399909 & 0.98576421 & 0.65727455 \\
   -0.14399227 & 0.53276635 & 0.124353 \\
   0.25242392 & 0.59862403 & 0.35048801
   \end{bmatrix}$$

   our $w^2$ matrix is randomly initialized the first time so we can use
   random values for the weights.

   $$w^2 = \begin{bmatrix}
   0.04 & 0.78 \\
   0.40 & 0.45 \\
   0.65 & 0.23
   \end{bmatrix}$$

   we calculate $z^{(3)}$:

   $$z^{(3)} = a^{(2)}.w^2$$

   $$z^{(3)} = \begin{bmatrix}
   -0.16838105 & 0.24773663 & 0.03997868 \\
   -0.18967498 & 0.03498572 & -0.06889071 \\
   0.01399909 & 0.98576421 & 0.65727455 \\
   -0.14399227 & 0.53276635 & 0.124353 \\
   0.25242392 & 0.59862403 & 0.35048801
   \end{bmatrix} . \begin{bmatrix}
   0.04 & 0.78 \\
   0.40 & 0.45 \\
   0.65 & 0.23
   \end{bmatrix}$$

   $$z^{(3)} = \begin{bmatrix}
   0.11834555 & -0.01066064 \\
   -0.03837167 & -0.14804778 \\
   0.8220941 & 0.60568633 \\
   0.2881763 & 0.15603208 \\
   0.47736378 & 0.54688371 \\
   \end{bmatrix}$$

   we then apply our activation function:

   $$a^{(3)} = tanh(z^{(3)})$$

   $$a^{(3)} = \begin{bmatrix}
   tanh(0.11834555) & tanh(-0.01066064) \\
   tanh(-0.03837167) & tanh(-0.14804778) \\
   tanh(0.8220941) & tanh(0.60568633) \\
   tanh(0.2881763) & tanh(0.15603208) \\
   tanh(0.47736378) & tanh(0.54688371) \\
   \end{bmatrix}$$

   $$a^{(3)} = \begin{bmatrix}
   0.11779613 & -0.01066023 \\
   -0.03835285 & -0.14697553 \\
   0.67620804 & 0.54108347 \\
   0.28045542 & 0.15477804 \\
   0.44412987 & 0.49818098 \\
   \end{bmatrix}$$

   $z^{(3)}$ and $a^{(3)}$ are of size $5\times2$, one row for each car
   and one column for each hidden unit (neuron) of the layer 3.

   our network looks like:

   dnn step 9

   we will now connect the last layer, using the same technique as
   previously seen.

   dnn step 10

   as for the two previous layers, we have:

   $$z^{(4)} = a^{(3)}.w^3$$
   $$a^{(4)} = tanh(z^{(4)})$$

   where:

   $$w^3 = \begin{bmatrix}
   w^3_{11} \\
   w^3_{21}
   \end{bmatrix}$$

   the number of rows equals the number of neurons in the layer 3 and the
   number of columns equals the number of neurons in the layer 4.

   our $w^3$ matrix is randomly initialized the first time so we can use
   random values for the weights. for instance:

   $$w^3 = \begin{bmatrix}
   0.04 \\
   0.41
   \end{bmatrix}$$

   we then calculate $z^{(4)}$ using $a^{(3)}$ which is the result of the
   previous layer.

   $$z^{(4)} = a^{(3)}.w^3$$
   $$z^{(4)} = \begin{bmatrix}
   0.11779613 & -0.01066023 \\
   -0.03835285 & -0.14697553 \\
   0.67620804 & 0.54108347 \\
   0.28045542 & 0.15477804 \\
   0.44412987 & 0.49818098 \\
   \end{bmatrix} . \begin{bmatrix}
   0.04 \\
   0.41
   \end{bmatrix}$$
   $$z^{(4)} = \begin{bmatrix}
   0.00034115 \\
   -0.06179408 \\
   0.24889254 \\
   0.07467721 \\
   0.22201939 \\
   \end{bmatrix}$$

   we then apply the activation function:

   $$a^{(4)} = tanh(z^{(4)}) = \begin{bmatrix}
   tanh(0.00034115) \\
   tanh(-0.06179408) \\
   tanh(0.24889254) \\
   tanh(0.07467721) \\
   tanh(0.22201939) \\
   \end{bmatrix}$$
   $$a^{(4)} = \begin{bmatrix}
   0.000341156 \\
   -0.0617156 \\
   0.243877 \\
   0.0745387 \\
   0.218442 \\
   \end{bmatrix}$$

   finally our network looks like the following:

   dnn step 11

   what we did is called the forward propagation, we have an input and we
   propagate it through the network. each time we have an hidden layer, we
   compute the values of its neurons using:

   $$a^{(l)} = \sigma(a^{(l - 1)} \times w^{(l - 1)})$$

   if $l = 1$, $a^{(1)} = x$ (our inputs), $\sigma(x)$ in our case is
   $tanh(x)$. each time you see the above formula, you should think
   "neural network layer".

bias

   we didn't used a bias unit to keep things simple, we will add it now.
   why do we need a bias? on the above picture we saw that $z^{(2)}_1 =
   x_1 \times w^1_{11} + x_2 \times w^1_{21} + x_3 \times w^1_{31}$ where
   $x_1$, $x_2$ and $x_3$ are the attributes of our car. this calculation
   will produce a number an then our activation function $tanh(z^{(2)}_1)$
   will be applied. we have a 3d input ($x_1$, $x_2$, $x_3$), to explain
   the bias usefulness, we will keep only one feature, for instance the
   number of kilometers and assume that only the number of kilometers of a
   car describes its price. we now have $a^{(2)}_1 = x_1 \times w^1_{11}$
   where $x_1$ is the car's number of kilometers. and once the activation
   function is applied, we have $a^{(2)}_1 = tanh(z^{(2)}_1) = tanh(x_1
   \times w^1_{11})$.

   after the training part described later, our $w^1_{11}$ will be a
   learned value. for instance 1.8. our $x_1$ is unknown and will be
   different for each car, $a^{(2)}_1$ will be the result of $tanh(1.8
   \times x_1)$. we can draw this function:

   dnn func1

   as you can see this function is centered in zero, as our $w^1_{11}$ is
   a learned value, our network will be able to tweak it. we assumed that
   our network learned $1.8$ but let's draw the graph when $w^1_{11}$ is
   larger, let's say $7$.

   dnn func2

   and when $w^1_{11} = 0.4$:

   dnn func3

   as we can see, changing $w^1_{11}$ changes the stiffness of the graph,
   as our network can only tweak the weights, it will only be able to
   change the stiffness but will stay centered in zero. is this a problem
   ?

   firstly the number of kilometers of a car will always be positive, so
   all the left part of the graph will be useless, $a^{(2)}_1$ will never
   be negative, is that a good thing ? we don't really know, but even if
   it was a good thing, we would have no choice.

   secondly, let's say that we have two cars, one with 30k kilometers and
   one with 170k kilometers, once normalized, we will have 0.5 and 2.5.
   let's say that the impact of the number of kilometers is clearly
   determined, like if the car is less than 50k kilometers the price is
   high and if the car is more than 50k kilometers the price is low, the
   limit is clear. once normalized 50k will be around 0.7, so we need a
   steep graph that produce -1 when x < 0.7 and produce 1 when x > 0.7.
   like this one:

   dnn func4

   that would be perfect but unfortunately we can't move the graph to the
   right, so we are stuck with a graph centered in zero (the first image).
   we can only make the graph steep using a high value for $w^1_{11}$. the
   above picture would be a good solution for us, it is the graph of the
   function:
   $$tanh(10x - 8)$$
   where 10 is the value for our $w^1_{11}$ and 8 is a constant that comes
   handy, the bias. instead of $a^{(2)}_1 = tanh(x_1 \times w^1_{11})$ we
   will have $a^{(2)}_1 = tanh(x_1 \times w^1_{11} + b)$ and this little
   $b$ will greatly improve our network performances because it will move
   the graph of our activation function to the left or the right and the
   result produced will be more representative of our problem. in our
   example (the above picture) $b = -8$.

   we used only one feature to easily draw graphs and display the impact
   of the bias but it is the same thing with more dimensions, our original
   example with a bias would be $a^{(2)}_1 = tanh(x_1 \times w^1_{11} +
   x_2 \times w^1_{21} + x_3 \times w^1_{31} + b)$.

   this value $b$ also needs to be learned, because regarding the problem,
   the bias will be different. the same bias must be added to each car. we
   saw previously the origin of the weights and their matrix
   representation, how can we add a bias?

   we will have a bias for each neuron. for instance for the first neuron
   of the first hidden layer we have:

   $a^{(2)}_1 = tanh(x_1 \times w^1_{11} + x_2 \times w^1_{21} + x_3
   \times w^1_{31} + b)$

   as we have three neurons in the first hidden layer, we will need three
   biases, we could use a bias matrix.

   bias without trick

   nonetheless managing the biases and the weights in separate matrices
   can be cumbersome. as the biases are learned, there are not different
   from the weights nonetheless they should not depend of a car attributes
   because all the car will have different attributes whereas the biases
   should be the same for all the cars. the solution is to add an
   additional feature to each car with a value $1$. so that this feature
   when multiplied with the bias will not change its value.

   bias trick

   note that $x_4$ is equal to $1$ so the calculations of the two previous
   pictures are exactly the same but using the bias trick we only have one
   weights matrix.

   adding a bias means adding a $1$ feature to all our inputs. we add
   biases to our input layer and each one of our hidden layers. now our
   network looks like.

   dnn step 12

   the link between the bias and the neurons are dotted to keep the
   network readable but they are normal weights. our cars have a new
   feature with the value $1$. each hidden layer has also a new neuron $1$
   because the problem that the bias solve appears each time we use the
   activation function (so each layer). there is no link between the bias
   and the previous layer because the bias is added after the
   calculations, it is not the result of a id127.

   we will do again all the calculus with the biases. we began by adding
   the bias unit to our input data, this means adding a new column of $1$.

   $$x = \begin{bmatrix}
   1.4 & -1 & 0.4 & 1\\
   0.4 & -1 & 0.1 & 1 \\
   5.4 & -1 & 4 & 1 \\
   1.5 & -1 & 1 & 1 \\
   1.8 & 1 & 1 & 1 \\
   \end{bmatrix}$$

   and our $w_1$ matrix has a new row $
   \begin{bmatrix}
   w_{41}^1 & w_{42}^1 & w_{43}^1
   \end{bmatrix}
   $, because adding $1$ to our input created new links. this row is the
   biases, we init them at $0.1$ so that we will see the differences with
   the previous values (they should be initialised at $0$ or around $0$).

   $$
   w^1 = \begin{bmatrix}
   0.01 & 0.05 & 0.07 \\
   0.20 & 0.041 & 0.11 \\
   0.04 & 0.56 & 0.13 \\
   0.1 & 0.1 & 0.1
   \end{bmatrix}
   $$

   then we are doing the same calculations as before.

   $$z^{(2)} = \begin{bmatrix}
   1.4 & -1 & 0.4 & 1\\
   0.4 & -1 & 0.1 & 1 \\
   5.4 & -1 & 4 & 1 \\
   1.5 & -1 & 1 & 1 \\
   1.8 & 1 & 1 & 1
   \end{bmatrix} . \begin{bmatrix}
   0.01 & 0.05 & 0.07 \\
   0.20 & 0.041 & 0.11 \\
   0.04 & 0.56 & 0.13 \\
   0.1 & 0.1 & 0.1
   \end{bmatrix}$$

   $$z^{(2)} = \begin{bmatrix}
   -0.07 & 0.353 & 0.14 \\
   -0.092 & 0.135 & 0.031\\
   0.114 & 2.569 & 0.888\\
   -0.045 & 0.694 & 0.225\\
   0.358 & 0.791 & 0.466\\
   \end{bmatrix}$$

   if you compare these $z^{(2)}$ results to the previous ones where we
   were not using biases, you see that each $z^{(2)}$ has $+0.1$. as
   before we then apply the activation function.

   $$a^{(2)} = tanh(z^{(2)})$$
   $$a^{(2)} = \begin{bmatrix}
   -0.06988589 & 0.33903341 & 0.13909245\\
   -0.09174131 & 0.13418581 & 0.03099007\\
   0.11350871 & 0.98832966 & 0.71040449\\
   -0.04496965 & 0.60054553 & 0.22127847\\
   0.34345116 & 0.65897516 & 0.43496173\\
   \end{bmatrix}$$

   we also add a bias to our first hidden layer. as we did with the inputs
   we must add $1$ as a fourth neuron to $a^{(2)}$. as a reminder, each
   row contains data for one car.

   $$a^{(2)} = \begin{bmatrix}
   -0.06988589 & 0.33903341 & 0.13909245 & 1\\
   -0.09174131 & 0.13418581 & 0.03099007 & 1\\
   0.11350871 & 0.98832966 & 0.71040449 & 1\\
   -0.04496965 & 0.60054553 & 0.22127847 & 1\\
   0.34345116 & 0.65897516 & 0.43496173 & 1\\
   \end{bmatrix}$$

   as we added a $1$ neuron to $a^{(2)}$ new links are created between the
   layer 2 and 3, as for $w^1$, $w^2$ will gain a row of biases that we
   init at $0.1$.

   $$w^2 = \begin{bmatrix}
   0.04 & 0.78 \\
   0.40 & 0.45 \\
   0.65 & 0.23 \\
   0.1 & 0.1
   \end{bmatrix}$$

   we do the same calculations as before:

   $$z^{(3)} = a^{(2)}.w^2$$

   $$z^{(3)} = \begin{bmatrix}
   -0.06988589 & 0.33903341 & 0.13909245 & 1\\
   -0.09174131 & 0.13418581 & 0.03099007 & 1\\
   0.11350871 & 0.98832966 & 0.71040449 & 1\\
   -0.04496965 & 0.60054553 & 0.22127847 & 1\\
   0.34345116 & 0.65897516 & 0.43496173 & 1\\
   \end{bmatrix} . \begin{bmatrix}
   0.04 & 0.78 \\
   0.40 & 0.45 \\
   0.65 & 0.23 \\
   0.1 & 0.1
   \end{bmatrix}$$

   $$z^{(3)} = \begin{bmatrix}
   0.32322802 & 0.2300453 \\
   0.17014822 & 0.09595311\\
   0.96163513 & 0.79667817\\
   0.48225043 & 0.38606321\\
   0.66005324 & 0.76447193\\
   \end{bmatrix}$$

   $$a^{(3)} = tanh(z^{(3)})$$

   $$a^{(3)} = \begin{bmatrix}
   0.31242279 & 0.22607134 \\
   0.16852506 & 0.09565971 \\
   0.74500533 & 0.66217559 \\
   0.44804409 & 0.3679614 \\
   0.57839884 & 0.64370347 \\
   \end{bmatrix}$$

   finally we also add a bias neuron to $a^{(3)}$, as before new links are
   created between the layer 3 and 4, as for $w^2$, $w^3$ will gain a row
   of biases that we init at $0.1$.

   $$z^{(4)} = a^{(3)}.w^3$$
   $$z^{(4)} = \begin{bmatrix}
   0.31242279 & 0.22607134 & 1\\
   0.16852506 & 0.09565971 & 1\\
   0.74500533 & 0.66217559 & 1\\
   0.44804409 & 0.3679614 & 1\\
   0.57839884 & 0.64370347 & 1\\
   \end{bmatrix} . \begin{bmatrix}
   0.04 \\
   0.41 \\
   0.1
   \end{bmatrix}$$
   $$z^{(4)} = \begin{bmatrix}
   0.20518616 \\
   0.14596148 \\
   0.4012922 \\
   0.26878594 \\
   0.38705438 \\
   \end{bmatrix}$$

   then we apply the activation function.

   $$a^{(4)} = tanh(z^{(4)}) = \begin{bmatrix}
   0.2023543 \\
   0.14493368 \\
   0.38105408 \\
   0.26249479 \\
   0.36881806 \\
   \end{bmatrix}$$

   the values obtained on the output layer are our network predictions. we
   will save them into the matrix $\hat{y} = a^{(4)}$. it is the price of
   the cars predicted by our network whereas $y$ is the real price of the
   cars (given by the dataset). for instance our network thinks that the
   car number one is less expensive than the car number five.

   adding the biases is really simple (just add a neuron $1$) and will
   greatly improve our results. the whole calculation that we did, from
   $x$ to $a^{(4)}$ is called forward propagation. this is how we will
   infer the price of a car in the future. we will take the car
   attributes, make the same calculations and get a price in the $a^{(4)}$
   matrix.

   right now our results are pretty bad because we randomly initialised
   our weights. we will train our network step by step in order to tweak
   the weights until it outputs good predictions.

   in our original dataset we have the car attributes and the car price.
   the features (attributes) of the first car with the bias was $x =
   \begin{bmatrix}
   1.4 & -1 & 0.4 & 1\end{bmatrix}$ and its price was $y = 0.45$. our
   network output was $\hat{y} = 0.2023543$ given in $a^{(4)}_1$. we
   clearly see that we are missing around 0.25 by doing $y - \hat{y}$.
   this is called the cost, how bad our network predicted the price
   compared to the actual price. actually we will define a cost function
   in order to mesure how bad our predictions are.

   $$ j(w) = \frac{1}{2}(y-\hat{y})^2$$

   this gives us the cost for one example. for instance for our first car,
   its real price is 0.45, our network outputted 0.2023543, using the
   above formula we have an error of $ j(w) =
   \frac{1}{2}(0.45-0.2023543)^2 = 0,031$

   this gives us the error for the first car, we will do it for all the
   cars then sum up the errors, so our formula become:

   $$ j(w) = \sum_{1}^{n}\frac{1}{2}(y-\hat{y})^2$$

   where $n$ is the number of cars. we squared the error to get its
   absolute value but also because the quadratic function $x^2$ is convex,
   it means that the function has only one minimum. we introduced
   $\frac{1}{2}$ for later convenience.

id119

   the function $j(w)$ gives us the error of our network regarding our
   inputs $x$ and the weights of our network. if we replace $\hat{y}$ by
   its calculations, our function is:

   $$ j(w) = \sum_{1}^{n}\frac{1}{2}(y-
   \tanh(\tanh(\tanh(x.w_1).w_2).w_3))^2$$

   $j(w)$ is a function that gives us the cost regarding our examples (the
   cars) and the weights ($w_1$, $w_2$ and $w_3$). the minimum the cost
   is, the better our network predicts. our goal is to minimize the
   function $j(w)$, i.e: find its minimum. this is an optimization
   problem. we can't touch our examples $x$ so we will minimize our
   function $j(w)$ by tweaking the weights. we will use the batch gradient
   descent algorithm (with a non convex cost function it is better to use
   the stochastic id119). we choose the id119 as the
   optimization algorithm but [14]other alternatives could be used. let's
   see what a gradient is.

   in mathematics, a function is a rule explaining how to process an input
   to give an output. the input is noted as \(x\) and the output as \(y\),
   the function is generally written as \(y = f(x)\). it is possible to
   have multiple inputs and outputs, multiple inputs is common and looks
   like \(z = f(x, y)\), multiple outputs is a vector valued function that
   produces a vector instead of only \(y\).

   strictly speaking the inputs are called independent variables and the
   outputs dependent variables. the function explains how the dependent
   variables depend on the independent variables.

   the derivative of a function is a key tool in machine learning, it is
   leveraged among others by the id119 algorithm. the
   derivative measures how a change in the independent variables impact
   the dependent variables (how changing \(x\) impacts \(y\)). the process
   of finding the derivative is called differentiation.

   there are two cases useful to us.

   the first case is when there is only one independent variable and one
   dependent variable (\(y = f(x)\) where \(x \in \mathbb{r}\) and \(y \in
   \mathbb{r}\)). in that case the derivative of a function at a given
   input is the slope of the tangent line to the graph of the function at
   the given input. it means that at the given input, the function is
   well-approximated by a straight line, and the derivative is the slope
   of this straight line. let's take an example. for instance if we take
   the sigmo  d function:
   $$\sigma(x) = \frac{1}{1+e^{-x}}$$
   the derivative of this function is:
   $$\dfrac{\mathrm{e}^x}{\left(\mathrm{e}^x+1\right)^2}$$
   you can compute the derivative detail [15]here. let's use this
   derivative to calculate the slope of the tangent at \(x=2\), we have:
   $$\dfrac{\mathrm{e}^2}{\left(\mathrm{e}^2+1\right)^2} \approx{0,105}$$
   if we draw the sigmoid function with its tangent at \(x=2\) we see that
   the slope of the tangent is \(\approx{0,105}\):

   dnn func 5

   our function does not looks like the sigmoid function because we used
   the same scale for the $x$ and $y$, it is easier to see that the slope
   of the tangent, the blue line, is indeed $\approx{0,105}$.

   the tangent is the best linear approximation of a function at a given
   value, it shows how the independent variable impacts the dependent
   variable (small or big slope).

   the second case is when there are several independent variables (\(y =
   f(x)\) where \(x \in \mathbb{r}^n\) and \(y \in \mathbb{r}\)). as the
   function takes as input several variables, we will now compute the
   partial derivative of the function with respect to each input variable.

   the partial derivative of a function w.r.t (with respect to) one of the
   input variable is the derivative of the function where others variables
   held constant. it indicates the rate of change of a function with
   respect to that variable surrounding an infinitesimally small region
   near a particular point.

   if we take for example, \(z = x^2 + y^3\), we have two inputs \(x\) and
   \(y\) so the derivative of the function will be a vector containing two
   partial derivatives:
   $$ f = \bigg[\frac{\partial f}{\partial x}, \frac{\partial f}{\partial
   y}\bigg]$$
   to calculate the partial derivative \(\frac{\partial f}{\partial x}\)
   we held \(y^3\) as a constant so we have:
   $$\frac{\partial f}{\partial x} = 2x + 0 = 2x$$
   to calculate the partial derivative \(\frac{\partial f}{\partial y}\)
   we held \(x^2\) as a constant so we have:
   $$\frac{\partial f}{\partial y} = 3y^2 + 0 = 3y^2$$
   so the derivative of our initial function is:
   $$ f = [2x, 3y^2]$$
   this vector of partial derivatives is the gradient. it represents the
   slope of the tangent of the graph of the function, it means that the
   gradient points in the direction of the greatest rate of increase of
   the function and its magnitude is the slope of the graph in that
   direction.

   for instance, for the previous function, if we are at \(x=4\) and
   \(y=2\), the corresponding gradient is \((8, 12)\) (we are using \((2x,
   3y^2)\)). it means that the function increases more in the direction of
   \(y\) than \(x\). using the two informations, it gives us a vector (a
   direction) for which z will increase the most.

   if we draw the previous function in a 3d space, it looks like the
   following:

   if we forget the \(z\) (because we can't tune its value) we have a 2d
   surface on which we can move on the \(x\) and \(y\) axis, it is like
   watching the previous 3d drawing from above, the \(z\) axis does not
   appear.

   we can place our original point (\(x=4\) and \(y=2\)) in red, its
   derivative \((8, 12)\) in blue and draw an arrow between them (orange).

   the orange arrow is the gradient, it gives us the direction of the
   steepest increase of \(z\) and the length of the arrow gives us how
   \(z\) changes, a long arrow means a big slope. if it is always unclear,
   [16]here is a 5 minutes video that can help you understand.

   id119 is an optimization algorithm, it allows to find a
   local minimum of a function.

   the algorithm comes from the observation that if one goes in the
   direction of the negative gradient of a function, the function
   decreases faster.

   as we saw previously, the gradient gives us the direction of the
   maximum increase of the function, we use the negation of this gradient
   to update the coordinates of our position in the space.

   by doing it repeatedly we are sure to find a local minimum of the
   function.

   let's say that our function is \(z = x^2 + y^3\), its gradient is \(f =
   [2x, 3y^2]\) so if we are at \(x=4\) and \(y=2\), the corresponding
   gradient is \((8, 12)\).

   the basic idea is to substract this gradient from our original
   coordinates, but directly substracting the gradient would produce a big
   jump from our original coordinates. for our example we are at $(4,2)$,
   if we directly substract the gradient, we will be at $(4 - 8, 2 - 12) =
   (-4, -10)$. what a big jump. so before to substract it we multiply it
   by a coefficient so that its value will be reduced. we have $(4 - 0.01
   * 8, 2 - 0.01 * 12) = (3.92, 1.88)$. we did a small move but at least
   we will not miss the minima.

   this coefficient $0.01$ is called the learning rate, how much the
   gradient will impact our current position. a big learning rate means
   bigger steps but we could jump over the minimum of the function. a
   small learning rate means a little but precise step and more steps
   needed to find the minimum. this value must be small and the perfect
   value is determined by a try/fail process.

   so if we summarize, we are at a point in our space and we want to find
   the minimum of a function. if we find the minimum we will have found
   the weights that give us the lowest error. so for the given
   coordinates, we compute the gradient, we multiply the gradient by a
   tiny coefficient and then we substract this updated gradient from our
   coordinates. this gives us our new coordinates and we start again.

   this repeated process is the id119 algorithm. if the
   function that we are trying to minimize is convex, all local minimas
   are also global minimas so id119 descent will give us the
   global solution (but it can take an eternity). a convex cost function
   is not mandatory.

   if we complete the image showing several iterations from wikipedia, we
   have:
   id119 iterations

   the red cross is our minima, the red arrow is the negative gradient
   that we substract from our coordinates and the orange arrows are the
   actual gradients. as you can see the red arrow is smaller than the
   orange arrow because the gradient has been multiplied by the learning
   rate (so reduced). the green dots are the new coordinates produced
   after each iteration. if $x_{0}$ is our original point, we see four
   iterations on the picture.

id26

   our goal is therefore to find the gradients of our function $j(w)$ and
   use them to update the weights of our network. our cost function
   computes three inputs that are the network weights. we have to find the
   partial derivatives (gradients) with regards to its weights.

   $$\nabla (j(w)) = \bigg[\frac{\partial j(w)}{\partial w_1},
   \frac{\partial j(w)}{\partial w_2}, \frac{\partial j(w)}{\partial
   w_3}\bigg]$$

   then we will update the weights using the gradients, for instance $w_1$
   will be updated using the following rule:

   $$w_1 = w_1 - \alpha \frac{1}{n} \frac{\partial j(w)}{\partial w_1}$$

   where $\alpha$ is our learning rate, we divide by $n$, which is the
   number of inputs (our cars) because the gradients for each car will be
   summed and we are using the averaged gradient to update our weights
   $w_1$.

   we could directly apply the id26 algorithm to find the
   gradients of $j(w)$ but we will compute the derivative of our cost
   function to get a better understanding of the algorithm.

   as a reminder:

   $$j(w) = \sum_{1}^{n}\frac{1}{2}(y -
   \tanh(\tanh(\tanh(x.w_1).w_2).w_3))^2$$

   our cost function is a composition of several functions, you can see a
   $tanh$ into a $tanh$ into a $tanh$. to derive it we will use the chain
   rule. it is a formula for computing the derivative of the composition
   of two or more functions.

   the usual formula is:

   $$(f \circ g)' = (f' \circ g).g'$$

   for instance if we take the function $f(x) = (2x^2 + 8)^3$ we see a
   composition. the result of the first function $g(x) = 2x^2 + 8$ is used
   by the second function $f(g(x)) = (g(x))^3$. the derivative of $g(x)$
   is $g'(x) = 4x$ and the derivative of $f(g(x))$ is $f'(g(x)) =
   3g(x)^2$. we apply the above formula:

   $$f'(x) = f'(g(x)).g'(x) = 3(2x^2 + 8)^2 \cdot 4x$$

   the chain rule can also be written in the following way:

   $$\frac{\partial z}{\partial x} = \frac{\partial z}{\partial y} \cdot
   \frac{\partial y}{\partial x}$$

   meaning that if $y$ depends on $x$ and $z$ depends on $y$, $z$ also
   depends on $x$. if we use our previous example. we want $\frac{\partial
   f}{\partial x}$. we know that $f$ depends on $g$ and $g$ depends on $x$
   because $f(g(x)) = g(x)^3$ and $g(x) = 2x^2 + 8$ so we can write:

   $$\frac{\partial f}{\partial x} = \frac{\partial f}{\partial g} \cdot
   \frac{\partial g}{\partial x}$$

   then we compute the derivative:

   $$\frac{\partial f}{\partial g} = 3g(x)^2$$

   $$\frac{\partial g}{\partial x} = 4x$$

   $$\frac{\partial f}{\partial x} = 3(2x^2 + 8)^2 \cdot 4x$$

   we will use the same way to compute the gradients of our cost function.
   there is a sum in our cost function, meaning that we have to add all
   together the cost of each input (our cars) in order to obtain the
   overall cost. we will forget it for now and talk about it later, the
   sum rule allows us to ignore it for now. the derivative of the sums
   equals the sum of the derivatives. at the end, once we have the
   derivative for one example we will just sum up the derivatives of all
   examples. so we have:

   $$j(w) = \frac{1}{2}(y-\hat{y})^2$$

   and we have to find:

   $$\nabla (j(w)) = \bigg[\frac{\partial j(w)}{\partial w_1},
   \frac{\partial j(w)}{\partial w_2}, \frac{\partial j(w)}{\partial
   w_3}\bigg]$$

   we begin from the output of our network, so let's find $\frac{\partial
   j(w)}{\partial w_3}$ first. we want the derivative of $j(w)$ with
   regards to $w_3$, it means that other variables, meaning $w_1$ and
   $w_2$ are held constants.

   we have:

   $$\frac{\partial j(w)}{\partial w_3} = \frac{1}{2}(y-\hat{y})^2$$

   we can see a first composition. $j(w) = \frac{1}{2}(g(x))^2$ where
   $g(x) = y-\hat{y}$ so we have:

   $$\frac{\partial j(w)}{\partial w_3} = \frac{\partial j(w)}{\partial g}
   \cdot \frac{\partial g}{\partial w_3}$$

   using the power rule, we have:

   $$\frac{\partial j(w)}{\partial g} = 2 \times \frac{1}{2}(g(x)) =
   g(x)$$

   thats why we put $\frac{1}{2}$ in our cost function, so that when
   differentiating things go smoothly and the term $2 \times \frac{1}{2}$
   disappear. so:

   $$\frac{\partial j(w)}{\partial w_3} = g(x) \cdot \frac{\partial
   g}{\partial w_3} = (y-\hat{y}) \cdot \frac{\partial g}{\partial w_3}$$

   now let's find the $\frac{\partial g}{\partial w_3}$ term, as a
   reminder $g(x) = y-\hat{y}$, we know that $y$ is a constant that does
   not depend on $w_3$ whereas $\hat{y}$ does depend on it. we have:

   $$\frac{\partial g}{\partial w_3} = 0 - \frac{\partial
   \hat{y}}{\partial w_3}$$

   and:

   $$\frac{\partial j(w)}{\partial w_3} = (y-\hat{y}) \cdot
   -\frac{\partial \hat{y}}{\partial w_3}$$

   as we said before, $\hat{y}$ is our predictions, meaning the output of
   our network, meaning $a^{(4)}$. we know that $\hat{y} = a^{(4)} =
   tanh(z^{(4)})$ so our $\hat{y}$ depends on $z^{(4)}$ and $z^{(4)}$
   depends on $w_3$. so we can write:

   $$\frac{\partial j(w)}{\partial w_3} = (y-\hat{y}) \cdot
   -\frac{\partial \hat{y}}{\partial z^{(4)}} \cdot \frac{\partial
   z^{(4)}}{\partial w_3}$$

   we can find $\frac{\partial \hat{y}}{\partial z^{(4)}}$ directly, we
   have: $\hat{y} = tanh(z^{(4)})$ so our derivative with regards to
   $z^{(4)}$ is the following:

   $$\frac{\partial \hat{y}}{\partial z^{(4)}} = tanh'(z^{(4)}) =
   1-\tanh(z^{(4)})^2$$

   we can replace its value in our initial formula:

   $$\frac{\partial j(w)}{\partial w_3} = (y-\hat{y}) \cdot -
   (1-\tanh(z^{(4)})^2) \cdot \frac{\partial z^{(4)}}{\partial w_3}$$

   now we have one final term to compute $\frac{\partial z^{(4)}}{\partial
   w_3}$ and we know that $z^{(4)} = a^{(3)} \cdot w^3$. finally $z^{(4)}$
   depends on $w_3$ directly so no more chain rule needed for this first
   gradient. we keep $a^{(3)}$ as a constant and $w^3$ becomes one because
   we are differentiating with regard to $w^3$. we have:

   $$\frac{\partial z^{(4)}}{\partial w_3} = a^{(3)} \times 1 = a^{(3)}$$

   we can replace it in our initial formula:

   $$\frac{\partial j(w)}{\partial w_3} = (y-\hat{y}) \cdot -
   (1-\tanh(z^{(4)})^2) \cdot a^{(3)}$$

   we found our first gradient! we will use it during the training process
   to update our weights $w_3$.

   we will introduce $\delta^{(4)}$ equals to:

   $$\delta^{(4)} = (y-\hat{y}) \cdot - (1-\tanh(z^{(4)})^2)$$

   so our previous gradient is in fact:

   $$\frac{\partial j(w)}{\partial w_3} = \delta^{(4)} \cdot a^{(3)}$$

   now we need our second gradient, $\frac{\partial j(w)}{\partial w_2}$,
   we will use the same steps as before for the beginning. we begin from:

   $$j(w) = \frac{1}{2}(y-\hat{y})^2$$

   using the exact same steps as for $w_3$ we will arrive at:

   $$\frac{\partial j(w)}{\partial w_2} = (y-\hat{y}) \cdot -
   (1-\tanh(z^{(4)})^2) \cdot \frac{\partial z^{(4)}}{\partial w_2}$$

   you can see above that we have the same term as before, that's why we
   introduced $\delta^{(4)}$, we can replace it in our formula:

   $$\frac{\partial j(w)}{\partial w_2} = \delta^{(4)} \cdot
   \frac{\partial z^{(4)}}{\partial w_2}$$

   before we were searching the derivative of $z^{(4)}$ with regards to
   $w_3$ so the derivative was $a^{(3)} \times 1$, as a reminder $z^{(4)}
   = a^{(3)} \cdot w_3$ but this time we are searching the derivative with
   regards to $w_2$. $w_3$ does not depend on $w_2$ so it becomes a
   constant, meanwhile $a^{(3)}$ depends on $w_2$ so we have to find its
   derivative with regards to $w_2$. this gives us:

   $$\frac{\partial z^{(4)}}{\partial w_2} = w_3 \cdot \frac{\partial
   a^{(3)}}{\partial w_2}$$

   we can replace it in our original formula:

   $$\frac{\partial j(w)}{\partial w_2} = \delta^{(4)} \cdot w_3 \cdot
   \frac{\partial a^{(3)}}{\partial w_2}$$

   now we have to compute $\frac{\partial a^{(3)}}{\partial w_2}$, we know
   that $a^{(3)}$ depends on $z^{(3)}$ (because $a^{(3)} = tanh(z^{(3)})$)
   which itself depends on $w_2$ (because $z^{(3)} = a^{(2)} \cdot w_2$).
   using the chain rule we can write:

   $$\frac{\partial a^{(3)}}{\partial w_2} = \frac{\partial
   a^{(3)}}{\partial z^{(3)}} \cdot \frac{\partial z^{(3)}}{\partial
   w_2}$$

   we can replace it in our original formula:

   $$\frac{\partial j(w)}{\partial w_2} = \delta^{(4)} \cdot w_3 \cdot
   \frac{\partial a^{(3)}}{\partial z^{(3)}} \cdot \frac{\partial
   z^{(3)}}{\partial w_2}$$

   we differentiate $\frac{\partial a^{(3)}}{\partial z^{(3)}}$, we have:

   $$\frac{\partial a^{(3)}}{\partial z^{(3)}} = tanh'(z^{(3)}) =
   1-\tanh(z^{(3)})^2$$

   we can replace it in our original formula:

   $$\frac{\partial j(w)}{\partial w_2} = \delta^{(4)} \cdot w_3 \cdot
   1-\tanh(z^{(3)})^2 \cdot \frac{\partial z^{(3)}}{\partial w_2}$$

   and we differentiate the last missing term $\frac{\partial
   z^{(3)}}{\partial w_2}$:

   $$\frac{\partial z^{(3)}}{\partial w_2} = a^{(2)} \cdot 1 = a^{(2)}$$

   we can replace it in our original formula:

   $$\frac{\partial j(w)}{\partial w_2} = \delta^{(4)} \cdot w_3 \cdot
   1-\tanh(z^{(3)})^2 \cdot a^{(2)}$$

   we found the second gradient of our function $j(w)$. as you can see,
   the more you go toward the beginning of the network, the more the
   differentiation will be long. that's why we introduced the
   $\delta^{(l)}$ terms where $l$ is the layer number. so that we don't
   have to differentiate again the first part of the function but directly
   use $\delta^{(l)}$. for the second gradient we introduce:

   $$\delta^{(3)} = \delta^{(4)} \cdot w_3 \cdot 1-\tanh(z^{(3)})^2$$

   we now have to find our last gradient $\frac{\partial j(w)}{\partial
   w_1}$, we will use the same steps as before for the beginning. we begin
   from:

   $$j(w) = \frac{1}{2}(y-\hat{y})^2$$

   using the exact same steps as for $w_2$ we will arrive at:

   $$\frac{\partial j(w)}{\partial w_1} = \delta^{(4)} \cdot w_3 \cdot
   1-\tanh(z^{(3)})^2 \cdot \frac{\partial z^{(3)}}{\partial w_1}$$

   as we introduced $\delta^{(3)}$ we can use it:

   $$\frac{\partial j(w)}{\partial w_1} = \delta^{(3)} \cdot
   \frac{\partial z^{(3)}}{\partial w_1}$$

   before we were searching the derivative of $z^{(3)}$ with regards to
   $w_2$ and so the derivative was equal to $a^{(2)}$. as a reminder
   $z^{(3)} = a^{(2)} \cdot w_2 $. this time we are searching the
   derivative of $z^{(3)}$ with regards to $w_1$ and so $w_2$ is only a
   constant, we have:

   $$\frac{\partial z^{(3)}}{\partial w_1} = w_2 \cdot \frac{\partial
   a^{(2)}}{\partial w_1}$$

   we can replace it in our original formula:

   $$\frac{\partial j(w)}{\partial w_1} = \delta^{(3)} \cdot w_2 \cdot
   \frac{\partial a^{(2)}}{\partial w_1}$$

   we now have to find the derivative of $\frac{\partial a^{(2)}}{\partial
   w_1}$, we know that $a^{(2)}$ depends on $z^{(2)}$ which itself depends
   on $w_1$. as before we can use the chain rule here. we have:

   $$\frac{\partial a^{(2)}}{\partial w_1} = \frac{\partial
   a^{(2)}}{\partial z^{(2)}} \cdot \frac{\partial z^{(2)}}{\partial
   w_1}$$

   where:

   $$\frac{\partial a^{(2)}}{\partial z^{(2)}} = tanh'(z^{(2)}) =
   1-\tanh(z^{(2)})^2$$

   we replace it in our original formula:

   $$\frac{\partial j(w)}{\partial w_1} = \delta^{(3)} \cdot w_2 \cdot
   1-\tanh(z^{(2)})^2 \cdot \frac{\partial z^{(2)}}{\partial w_1}$$

   we have one last term to differentiate, if you remember $z^{(2)} = x
   \cdot w_1$ as we differentiate with regards to $w_1$ we have:

   $$\frac{\partial z^{(2)}}{\partial w_1} = x \cdot w_1 = x$$

   so our last gradient is:

   $$\frac{\partial j(w)}{\partial w_1} = \delta^{(3)} \cdot w_2 \cdot
   1-\tanh(z^{(2)})^2 \cdot x$$

   we also introduce the term $\delta^{(2)}$, we have:

   $$\delta^{(2)} = \delta^{(3)} \cdot w_2 \cdot 1-\tanh(z^{(2)})^2$$

   and:

   $$\frac{\partial j(w)}{\partial w_1} = \delta^{(2)} \cdot x$$

   here we are, we found the gradient of $j(w)$ with regards to its
   weights. as a reminder we found:

   $$\frac{\partial j(w)}{\partial w_1} = \delta^{(2)} \cdot x$$

   $$\delta^{(2)} = \delta^{(3)} \cdot w_2 \cdot 1-\tanh(z^{(2)})^2$$

   $$\frac{\partial j(w)}{\partial w_2} = \delta^{(3)} \cdot a^{(2)}$$

   $$\delta^{(3)} = \delta^{(4)} \cdot w_3 \cdot 1-\tanh(z^{(3)})^2$$

   $$\frac{\partial j(w)}{\partial w_3} = \delta^{(4)} \cdot a^{(3)}$$

   $$\delta^{(4)} = (y-\hat{y}) \cdot - (1-\tanh(z^{(4)})^2)$$

   if you remember, each gradient will be used to update a weight matrix
   during one id119 iteration. this means that our gradients
   should have the same size as the weights matrix that will use it. for
   instance $w_3$ is a $2 \times 1$ matrix so $\frac{\partial
   j(w)}{\partial w_3}$ must be a $2 \times 1$ matrix.

   we will detail the dimensions of the matrices used to calculate our
   gradients so that it appears clearly that the gradients are summed up.
   it will also be useful to know when were are using element wise or
   id127. let's say that we have five cars, for
   $\frac{\partial j(w)}{\partial w_3}$ we found:

   dw3 dimensions

   the $\odot$ means an element wise multiplication, the $\cdot$ means a
   id127. from now on we will distinguish between the two.
   our $\delta^{(4)}$ term has a dimension of $5 \times 1$ and $a^{(3)}$
   has a dimension of $5 \times 2$. as we want the same dimension as $w_3$
   meaning $2 \times 1$ there is only one way to achieve that:

   dw3 dimensions step 2

   by inverting $\delta^{(4)}$ and $a^{(3)}$ and using the transpose of
   $a^{(3)}$ we are able to get the desired result. $a^{(3)}$ contains the
   neurons values of the the third layer, two for each car and
   $\delta^{(4)}$ contains the error for each car. by doing the matrix
   multiplication we are actually summing the neurons of all the cars
   where each car neuron value is multiplied by the error for the given
   car. if you remember we removed the sum from our cost function, this
   step takes care of the summation of the errors using the matrix
   multiplication.

   dw3 dimensions step 2

   so we modify our third gradient so that the summation is handled and
   the dimension of the matrices are compatible (the little $\intercal$
   means transpose):

   $$\frac{\partial j(w)}{\partial w_3} = a^{(3)\intercal} \cdot
   \delta^{(4)}$$

   $$\delta^{(4)} = (y-\hat{y}) \odot - (1-\tanh(z^{(4)})^2)$$

   our $\delta^{(l)}$ will always have the same size as $a^{(l)}$ because
   it mesures how much a neuron is responsible for any error in our
   output. this remark is important because during the forward propagation
   we added bias units to each of our layer, having the effect of
   increasing the $a^{(l)}$ dimension by one column. $\delta^{(l)}$ will
   also contain the error of the bias units. these bias units are not
   linked to the previous layers so when we backpropagate our
   $\delta^{(l)}$ into our $(l - 1)$ layer we will have to remove the bias
   error. we will detail the dimensions of the matrices, we also have five
   cars. using the same reasoning as before (transpose + inversion) we
   find that:

   $$\frac{\partial j(w)}{\partial w_2} = a^{(2)\intercal} \cdot
   \delta^{(3)}$$

   $$\delta^{(3)} = (\delta^{(4)} \cdot w_3^{\intercal}) \odot
   1-\tanh(z^{(3)})^2$$

   as you can see the order of the calculations follows the output toward
   input flow. we have:

   dw2-dimension

   the third element of $w_3$ is the bias value, as we also multiply it
   with $\delta^{(4)}$ the result of our product $\delta^{(4)} \cdot
   w_3^{\intercal}$ is of size $5 \times 3$ whereas $z^{(3)}$ is of size
   $5 \times 2$. to allow a smooth element wise multiplication we add a
   column of $1$ to $z^{(3)}$. the result is unchanged and $\delta^{(3)}$
   is of size $5 \times 3$ like $a^{(3)}$.

   nonetheless the bias is not linked to the previous layer, this means
   that when backpropagating the error $\delta^{(3)}$ we must remove the
   part about the bias in the error matrix. we have:

   dw2-dimension step2

   the greyed circles are removed from the $\delta^{(3)}$ before the
   multiplication, $\frac{\partial j(w)}{\partial w_2}$ has the same size
   as $w_2$.

   we use the same tricks for $\frac{\partial j(w)}{\partial w_1}$.

   $$\frac{\partial j(w)}{\partial w_1} = x^{\intercal} \cdot
   \delta^{(2)}$$

   $$\delta^{(2)} = (\delta^{(3)} \cdot w_2^{\intercal}) \odot
   1-\tanh(z^{(2)})^2$$

   we have:

   dw1 dimension

   and:

   dw1 dimension step 2

   $\frac{\partial j(w)}{\partial w_1}$ has the same size as $w_1$.

   this may seem difficult but using the dimension analysis and knowing
   when to remove the bias error and add a $1$ column, there is only one
   way to obtain the same dimension as the weight matrix.

   as you may have noticed the partial derivatives follow the same
   pattern, we did the differentiation manually to see the foundations but
   we can apply the id26 algorithm, for the last layer ($l$ is
   the index of the last layer) we have:

   $$ \delta^{(l)} = -(y - a^{(l)})\odot\sigma'(z^{(l)})$$

   for non output layer ($l$ is not the index of the last layer):

   $$ \delta^{(l)} = ((\delta^{(l + 1)} \cdot
   w_{(l)}^{\intercal})\odot\sigma'(z^{(l)}))$$

   then we compute the gradients:

   $$\frac{\partial j(w)}{\partial w_{(l)}} = a^{(l)\intercal} \cdot
   \delta^{(l + 1)}$$

   you can stack a bunch of layers and use the id26 formula to
   easily compute the gradients. let's use our previous examples to
   compute our gradients and do a id119 iteration.

   $$\delta^{(4)} = (y-\hat{y}) \odot - (1-\tanh(z^{(4)})^2)$$

   $$\delta^{(4)} = \begin{bmatrix}
   0.45 \\
   0.8 \\
   0.2 \\
   0.5 \\
   0.55 \\
   \end{bmatrix}-\begin{bmatrix}
   0.202354302599 \\
   0.144933682554 \\
   0.381054078721 \\
   0.262494787219 \\
   0.368818057375 \\
   \end{bmatrix} \odot - \begin{bmatrix}
   0.95905273622 \\
   0.978994227661 \\
   0.85479778909 \\
   0.931096486683 \\
   0.863973240554 \\
   \end{bmatrix}$$

   we took care of applying $1-\tanh(x)^2$ element wise to $z^{(4)}$
   values.

   $$\delta^{(4)} = \begin{bmatrix}
   0.247645697401 \\
   0.655066317446 \\
   -0.181054078721 \\
   0.237505212781 \\
   0.181181942625 \\
   \end{bmatrix} \odot - \begin{bmatrix}
   0.95905273622 \\
   0.978994227661 \\
   0.85479778909 \\
   0.931096486683 \\
   0.863973240554 \\
   \end{bmatrix}$$

   $$\delta^{(4)} = \begin{bmatrix}
   -0.237505283705 \\
   -0.641306143515 \\
   0.154764626197 \\
   -0.221140269189 \\
   -0.156536350099 \\
   \end{bmatrix}$$

   our gradient for w3 is:

   $$\frac{\partial j(w)}{\partial w_3} = a^{(3)\intercal} \cdot
   \delta^{(4)}$$

   $$\frac{\partial j(w)}{\partial w_3} = \begin{bmatrix}
   0.312422790277 & 0.16852505915 & 0.745005333554 & 0.448044091981 &
   0.578398840625 \\
   0.226071339877 & 0.0956597075832 & 0.662175586399 & 0.367961400586 &
   0.643703471035 \\
   1.0 & 1.0 & 1.0 & 1.0 & 1.0 \\
   \end{bmatrix} \cdot \begin{bmatrix}
   -0.237505283705 \\
   -0.641306143515 \\
   0.154764626197 \\
   -0.221140269189 \\
   -0.156536350099 \\
   \end{bmatrix}$$

   $$\frac{\partial j(w)}{\partial w_3} = \begin{bmatrix}
   -0.25659878177 \\
   -0.194693013848 \\
   -1.10172342031 \\
   \end{bmatrix}$$

   for $w_2$ we have:

   $$\delta^{(3)} = (\delta^{(4)} \cdot w_3^{\intercal}) \odot
   1-\tanh(z^{(3)})^2$$

   $$\delta^{(3)} = \begin{bmatrix}
   -0.237505283705 \\
   -0.641306143515 \\
   0.154764626197 \\
   -0.221140269189 \\
   -0.156536350099 \\
   \end{bmatrix} \cdot \begin{bmatrix}
   0.04 & 0.41 & 0.1 \\
   \end{bmatrix} \odot \begin{bmatrix}
   0.902392000116 & 0.948891749286 & 0.419974341614 \\
   0.971599304439 & 0.990849220345 & 0.419974341614 \\
   0.444967052977 & 0.561523492777 & 0.419974341614 \\
   0.799256491641 & 0.864604407679 & 0.419974341614 \\
   0.665454781164 & 0.585645841377 & 0.419974341614 \\
   \end{bmatrix}$$

   as before we took care of applying $1-\tanh(x)^2$ element wise to
   $z^{(3)}$ values. we also concatenated a column of 1 to $z^{(3)}$ as
   described before. the 1s became 0.419974341614 when applying
   $1-\tanh(x)^2$.

   $$\delta^{(3)} = \begin{bmatrix}
   -0.0095002113482 & -0.0973771663191 & -0.0237505283705 \\
   -0.0256522457406 & -0.262935518841 & -0.0641306143515 \\
   0.00619058504786 & 0.0634534967406 & 0.0154764626197 \\
   -0.00884561076757 & -0.0906675103676 & -0.0221140269189 \\
   -0.00626145400397 & -0.0641799035407 & -0.0156536350099 \\
   \end{bmatrix} \odot \begin{bmatrix}
   0.902392000116 & 0.948891749286 & 0.419974341614 \\
   0.971599304439 & 0.990849220345 & 0.419974341614 \\
   0.444967052977 & 0.561523492777 & 0.419974341614 \\
   0.799256491641 & 0.864604407679 & 0.419974341614 \\
   0.665454781164 & 0.585645841377 & 0.419974341614 \\
   \end{bmatrix}$$

   $$\delta^{(3)} = \begin{bmatrix}
   -0.00857291472002 & -0.092400389689 & -0.00997461251539 \\
   -0.0249237041189 & -0.260529453845 & -0.0269332125396 \\
   0.00275460638495 & 0.0356306291187 & 0.0064997171992 \\
   -0.0070699118285 & -0.078391529097 & -0.00928732389571 \\
   -0.00416671450398 & -0.0375866936086 & -0.00657412505716 \\
   \end{bmatrix}$$

   our gradient for w2 is:

   $$\frac{\partial j(w)}{\partial w_2} = a^{(2)\intercal} \cdot
   \delta^{(3)}$$

   $$\frac{\partial j(w)}{\partial w_2} = \begin{bmatrix}
   -0.0698858903164 & -0.0917413131084 & 0.113508705786 & -0.0449696495836
   & 0.34345116481 \\
   0.339033408721 & 0.134185809931 & 0.988329664432 & 0.600545525169 &
   0.658975160566 \\
   0.139092447878 & 0.0309900734824 & 0.710404487737 & 0.221278467898 &
   0.434961731831 \\
   1.0 & 1.0 & 1.0 & 1.0 & 1.0 \\
   \end{bmatrix} \cdot \begin{bmatrix}
   -0.00857291472002 & -0.092400389689 \\
   -0.0249237041189 & -0.260529453845 \\
   0.00275460638495 & 0.0356306291187 \\
   -0.0070699118285 & -0.078391529097 \\
   -0.00416671450398 & -0.0375866936086 \\
   \end{bmatrix}$$

   we took care of removing the last column of $\delta^{(3)}$ as the error
   on the bias is not backpropagated.

   $$\frac{\partial j(w)}{\partial w_2} = \begin{bmatrix}
   0.0020851994346 & 0.0250192301883 \\
   -0.010520017991 & -0.102917746604 \\
   -0.00338471099243 & -0.0293089952796 \\
   -0.0419786387864 & -0.433277437121 \\
   \end{bmatrix}$$

   finally for $w_1$ we have:

   $$\delta^{(2)} = (\delta^{(3)} \cdot w_2^{\intercal}) \odot
   1-\tanh(z^{(2)})^2$$

   $$\delta^{(2)} = \begin{bmatrix}
   -0.00857291472002 & -0.092400389689 \\
   -0.0249237041189 & -0.260529453845 \\
   0.00275460638495 & 0.0356306291187 \\
   -0.0070699118285 & -0.078391529097 \\
   -0.00416671450398 & -0.0375866936086 \\
   \end{bmatrix} \cdot \begin{bmatrix}
   0.04 & 0.4 & 0.65 & 0.1 \\
   0.78 & 0.45 & 0.23 & 0.1 \\
   \end{bmatrix} \odot \begin{bmatrix}
   0.995115962335 & 0.885056347771 & 0.980653290943 & 0.419974341614 \\
   0.991583531469 & 0.981994168413 & 0.999039615346 & 0.419974341614 \\
   0.987115773711 & 0.0232044744039 & 0.495325463803 & 0.419974341614 \\
   0.997977730616 & 0.6393450722 & 0.951035839645 & 0.419974341614 \\
   0.88204129739 & 0.565751737757 & 0.810808291842 & 0.419974341614 \\
   \end{bmatrix}$$

   we took care of removing the last column of $\delta^{(3)}$, we also
   concatenated a column of 1 to $z^{(2)}$ and applied $1-\tanh(x)^2$
   element wise to $z^{(2)}$ values.

   $$\delta^{(2)} = \begin{bmatrix}
   -0.0724152205462 & -0.0450093412481 & -0.0268244841965 &
   -0.0100973304409 \\
   -0.204209922164 & -0.127207735878 & -0.0761221820616 & -0.0285453157964
   \\
   0.0279020749679 & 0.0171356256574 & 0.00998553884751 & 0.00383852355036
   \\
   -0.0614281891688 & -0.0381041528251 & -0.0226254943808 &
   -0.00854614409256 \\
   -0.0294842895948 & -0.0185806979255 & -0.0113533039576 &
   -0.00417534081126 \\
   \end{bmatrix} \odot \begin{bmatrix}
   0.995115962335 & 0.885056347771 & 0.980653290943 & 0.419974341614 \\
   0.991583531469 & 0.981994168413 & 0.999039615346 & 0.419974341614 \\
   0.987115773711 & 0.0232044744039 & 0.495325463803 & 0.419974341614 \\
   0.997977730616 & 0.6393450722 & 0.951035839645 & 0.419974341614 \\
   0.88204129739 & 0.565751737757 & 0.810808291842 & 0.419974341614 \\
   \end{bmatrix}$$

   $$\delta^{(2)} = \begin{bmatrix}
   -0.0720615418815 & -0.0398358031806 & -0.0263055187051 &
   -0.00424061970398 \\
   -0.20249119578 & -0.124917254809 & -0.0760490754861 & -0.0119883002078
   \\
   0.0275425783201 & 0.000397623186961 & 0.00494609166096 &
   0.00161208140083 \\
   -0.0613039648226 & -0.0243617023391 & -0.0215176560459 &
   -0.00358916123861 \\
   -0.0260063610469 & -0.0105120621401 & -0.00920535298859 &
   -0.00175353600822 \\
   \end{bmatrix}$$

   our gradient for $w_1$ is:

   $$\frac{\partial j(w)}{\partial w_1} = x^{\intercal} \cdot
   \delta^{(2)}$$

   $$\frac{\partial j(w)}{\partial w_1} = \begin{bmatrix}
   1.4 & 0.4 & 5.4 & 1.5 & 1.8 \\
   -1.0 & -1.0 & -1.0 & -1.0 & 1.0 \\
   0.4 & 0.1 & 4.0 & 1.0 & 1.0 \\
   1.0 & 1.0 & 1.0 & 1.0 & 1.0 \\
   \end{bmatrix} \cdot \begin{bmatrix}
   -0.0720615418815 & -0.0398358031806 & -0.0263055187051 \\
   -0.20249119578 & -0.124917254809 & -0.0760490754861 \\
   0.0275425783201 & 0.000397623186961 & 0.00494609166096 \\
   -0.0613039648226 & -0.0243617023391 & -0.0215176560459 \\
   -0.0260063610469 & -0.0105120621401 & -0.00920535298859 \\
   \end{bmatrix}$$

   we took care of removing the last column of $\delta^{(2)}$ as the error
   on the bias is not backpropagated.

   $$\frac{\partial j(w)}{\partial w_1} = \begin{bmatrix}
   -0.171920111136 & -0.159054126528 & -0.0893845808607 \\
   0.282307763117 & 0.178205075002 & 0.109720805588 \\
   -0.0262137489196 & -0.0617093184844 & -0.0290657574213 \\
   -0.334320485211 & -0.199229199282 & -0.128131511565 \\
   \end{bmatrix}$$

   now that we have our gradients, we can apply one iteration of the
   id119 algorithm to update our weights. we saw previously the
   update formula:

   $$w_{(l)} = w_{(l)} - \alpha \frac{1}{n} \frac{\partial j(w)}{\partial
   w_{(l)}}$$

   we have five cars in our dataset so $n = 5$, we choose a learning rate
   of $\alpha = 0.1$.

   $$w_1 = w_1 - \alpha \frac{1}{n} \frac{\partial j(w)}{\partial w_1}$$

   $$w_1 = \begin{bmatrix}
   0.01 & 0.05 & 0.07 \\
   0.2 & 0.041 & 0.11 \\
   0.04 & 0.56 & 0.13 \\
   0.1 & 0.1 & 0.1 \\
   \end{bmatrix} - 0.1 \odot \frac{1}{5} \odot \begin{bmatrix}
   -0.171920111136 & -0.159054126528 & -0.0893845808607 \\
   0.282307763117 & 0.178205075002 & 0.109720805588 \\
   -0.0262137489196 & -0.0617093184844 & -0.0290657574213 \\
   -0.334320485211 & -0.199229199282 & -0.128131511565 \\
   \end{bmatrix}$$

   $$w_1 = \begin{bmatrix}
   0.0134384022227 & 0.0531810825306 & 0.0717876916172 \\
   0.194353844738 & 0.0374358985 & 0.107805583888 \\
   0.0405242749784 & 0.56123418637 & 0.130581315148 \\
   0.106686409704 & 0.103984583986 & 0.102562630231 \\
   \end{bmatrix}$$

   as you can see our weights matrix has been updated, some values are
   bigger, others smaller, we are moving in our space of solutions toward
   the best set of weights.

   we do the exact same thing for $w_2$ and $w_3$:

   $$w_2 = w_2 - \alpha \frac{1}{n} \frac{\partial j(w)}{\partial w_2}$$

   $$w_2 = \begin{bmatrix}
   0.04 & 0.78 \\
   0.4 & 0.45 \\
   0.65 & 0.23 \\
   0.1 & 0.1 \\
   \end{bmatrix} - 0.1 \odot \frac{1}{5} \odot \begin{bmatrix}
   0.0020851994346 & 0.0250192301883 \\
   -0.010520017991 & -0.102917746604 \\
   -0.00338471099243 & -0.0293089952796 \\
   -0.0419786387864 & -0.433277437121 \\
   \end{bmatrix}$$

   $$w_2 = \begin{bmatrix}
   0.0399582960113 & 0.779499615396 \\
   0.40021040036 & 0.452058354932 \\
   0.65006769422 & 0.230586179906 \\
   0.100839572776 & 0.108665548742 \\
   \end{bmatrix}$$

   $$w_3 = w_3 - \alpha \frac{1}{n} \frac{\partial j(w)}{\partial w_3}$$

   $$w_3 = \begin{bmatrix}
   0.04 \\
   0.41 \\
   0.1 \\
   \end{bmatrix} - 0.1 \odot \frac{1}{5} \odot \begin{bmatrix}
   -0.25659878177 \\
   -0.194693013848 \\
   -1.10172342031 \\
   \end{bmatrix}$$

   $$w_3 = \begin{bmatrix}
   0.0451319756354 \\
   0.413893860277 \\
   0.122034468406 \\
   \end{bmatrix}$$

   by doing the forward propagation, backward propagation and weights
   update in a loop you have an algorithm that learn.

gradient checking

   to do the id26 we found the derivative of our cost function.
   it is easy to do a mistake during the differentiation and while working
   ostensibly fine our neural network will perform poorly. we used the
   chain rule to find our gradients, this is called analytical
   differentiation.

   nonetheless the original definition of a derivative is the following:
   $$\frac{df(x)}{dx} = \lim_{h\ \to 0} \frac{f(x + h) - f(x)}{h}$$
   the idea is that for a small enough \(h\) value the previous formula
   approximates correctly the value of the derivative of the function
   \(f\). because if you zoom enough on a tiny part of the graph of the
   function, it will appear linear, and so approximate the tangent of the
   graph. this is called numerical differentiation. as you can see we are
   computing twice $f(x)$, that's why the numerical differentiation is
   slower and not used (even if it is less error prone).

   the idea is to use the numerical differentiation to check that our
   analytical differentiation implementation is correct. we will not use
   the strict definition but rather the centered formula (works better):

   $$\frac{df(x)}{dx} = \frac{f(x + h) - f(x - h)}{2h} \hspace{0.1in}$$

   in total we have three matrices containing the weights. we will test
   one weight at a time. we will proceed as follow.
     * we do a forward and backward propagation.
     * we save our gradients into a vector $v_1$.
     * for each weight:
          + we compute f(weight + h).
          + we compute f(weight - h).
          + we compute the centered formula and save the value into a
            vector $v_2$.
     * the difference between $v_1$ and $v_2$ should be less than $10^-8$.

   the function that we differentiated during the id26 is our
   cost function:

   $$ j(w) = \sum_{1}^{n} \frac{1}{2}(y-\hat{y})^2$$

   where $\hat{y}$ is in reality $a^{(4)}$.

   during the id26 we found our gradients equal to:

   $$\frac{\partial j(w)}{\partial w_1} = \begin{bmatrix}
   -0.171920111136 & -0.159054126528 & -0.0893845808607 \\
   0.282307763117 & 0.178205075002 & 0.109720805588 \\
   -0.0262137489196 & -0.0617093184844 & -0.0290657574213 \\
   -0.334320485211 & -0.199229199282 & -0.128131511565 \\
   \end{bmatrix}$$

   $$\frac{\partial j(w)}{\partial w_2} = \begin{bmatrix}
   0.0020851994346 & 0.0250192301883 \\
   -0.010520017991 & -0.102917746604 \\
   -0.00338471099243 & -0.0293089952796 \\
   -0.0419786387864 & -0.433277437121 \\
   \end{bmatrix}$$

   $$\frac{\partial j(w)}{\partial w_3} = \begin{bmatrix}
   -0.25659878177 \\
   -0.194693013848 \\
   -1.10172342031 \\
   \end{bmatrix}$$

   we save them into a vector $v^{(1)}$ of size $23 \times 1$. these
   gradients have been computed during the forward pass with the
   analytical differentiation.

   as you will see later in the code i am using a perturbation vector, i
   will keep the explanation simple and don't talk about it.

   the weights that we used are:

   $$w_1 = \begin{bmatrix}
   0.0134384022227 & 0.0531810825306 & 0.0717876916172 \\
   0.194353844738 & 0.0374358985 & 0.107805583888 \\
   0.0405242749784 & 0.56123418637 & 0.130581315148 \\
   0.106686409704 & 0.103984583986 & 0.102562630231 \\
   \end{bmatrix}$$

   $$w_2 = \begin{bmatrix}
   0.0399582960113 & 0.779499615396 \\
   0.40021040036 & 0.452058354932 \\
   0.65006769422 & 0.230586179906 \\
   0.100839572776 & 0.108665548742 \\
   \end{bmatrix}$$

   $$w_3 = \begin{bmatrix}
   0.0451319756354 \\
   0.413893860277 \\
   0.122034468406 \\
   \end{bmatrix}$$

   we disturb the first weight by adding a small value, we choose $h =
   10^{-4}$.

   $$w_1 = \begin{bmatrix}
   0.0134384022227 + 0.0001 & 0.0531810825306 & 0.0717876916172 \\
   0.194353844738 & 0.0374358985 & 0.107805583888 \\
   0.0405242749784 & 0.56123418637 & 0.130581315148 \\
   0.106686409704 & 0.103984583986 & 0.102562630231 \\
   \end{bmatrix}$$

   all the other weights stay the same. we do a forward propagation using
   the weights disturbed (just one value has been disturbed). we obtain:

   $$ a^{(4)} = \begin{bmatrix}
   0.202395039754 \\
   0.144946047163 \\
   0.381136194829 \\
   0.262533502845 \\
   0.368843890153 \\
   \end{bmatrix}$$

   we compute the sum of the costs (square the cost before summing):

   $$ j(w) = \frac{1}{2}\sum\left(\begin{bmatrix}
   0.45 \\
   0.8 \\
   0.2 \\
   0.5 \\
   0.55 \\
   \end{bmatrix}-\begin{bmatrix}
   0.202395039754 \\
   0.144946047163 \\
   0.381136194829 \\
   0.262533502845 \\
   0.368843890153 \\
   \end{bmatrix}\right)^2$$

   $$ j(w) = loss2 = 0.30621105$$

   we disturb again the first weight by removing the small value $h$.

   $$w_1 = \begin{bmatrix}
   0.0134384022227 - 0.0001 & 0.0531810825306 & 0.0717876916172 \\
   0.194353844738 & 0.0374358985 & 0.107805583888 \\
   0.0405242749784 & 0.56123418637 & 0.130581315148 \\
   0.106686409704 & 0.103984583986 & 0.102562630231 \\
   \end{bmatrix}$$

   all the other weights stay the same. we do a forward propagation using
   the weights disturbed (just one value has been disturbed). we obtain:

   $$ a^{(4)} = \begin{bmatrix}
   0.202313563549 \\
   0.144921317917 \\
   0.380971901463 \\
   0.262456067958 \\
   0.368792216736 \\
   \end{bmatrix}$$

   we also compute the sum of the costs:

   $$ j(w) = \frac{1}{2}\sum\left(\begin{bmatrix}
   0.45 \\
   0.8 \\
   0.2 \\
   0.5 \\
   0.55 \\
   \end{bmatrix}-\begin{bmatrix}
   0.202313563549 \\
   0.144921317917 \\
   0.380971901463 \\
   0.262456067958 \\
   0.368792216736 \\
   \end{bmatrix}\right)^2$$

   $$ j(w) = loss1 = 0.30624543$$

   then we compute the numerical gradient by doing:

   $$v^{(2)}_1 = \frac{(loss2 - loss1)}{(2*h)}$$

   $$v^{(2)}_1 = -0.17192014$$

   this is the first weight computed using the numerical differentiation.
   using the analytical differentiation we found $-0.171920111136$. as you
   can see they are almost identical.

   we repeat the process for each weight until we have computed our 23
   numerical gradients into the vector $v^{(2)}_1$. we then want to
   compare our analytical gradients with our numerical gradients. to
   quantify the difference we divide the norm of the difference by the
   norm of the sum of the vectors we would like to compare. typical
   results should be on the order of $10^-8$ or less if we   ve computed our
   gradient correctly.

   $$\frac{\left|v^{(1)} - v^{(2)}\right|}{\left|v^{(1)} + v^{(2)}\right|}
   = 1.15700817288e-08$$

   as you can see the difference is on the order of $10^-8$ this means
   that our backward propagation computes correctly the gradients $\nabla
   (j(w))$. if it is not the case, it means that there is an error in the
   id26 algorithm and you have to debug it, good luck, as you
   will see, you sometimes lose a great amount of time because of a little
   mistake.

id173

   one last step is missing, the id173. during the training our
   weights will evolve in order to predict correctly the price of a car
   from its attributes. nonetheless it could happen that the weights are
   perfectly predicting the price for the training data but can't
   generalize for an unseen car. this problem is called overfitting.
   during the training steps our network will display a small loss but
   when testing it with unseen data it will display a larger loss. it
   means that our weights are well suited for the training data only.

   id173 is useful when the network has a lot of parameters and
   not enough data. enough data is at least ten times the number of
   parameters. our network has 23 parameters so we need at least 230 cars.
   as our dataset of cars has more than 9k cars, overfitting is not really
   a problem for us, nonetheless we will solve the overfitting problem as
   it regularly occurs.

   one way to reduce overfitting is called id173. the idea is to
   penalize large weights by modifying our cost function. there are
   several way to do id173, the most used are l1, l2, max norm
   and dropout. we will use the l2 id173 because it is the most
   common. it is pretty simple, we only add one term to our cost function:

   $$ j(w) = \sum_{1}^{n}\frac{1}{2}(y-\hat{y})^2 - \frac{1}{2} \lambda
   \sum_{1}^{3} w_{(n)}^2$$

   the $\lambda$ is a hyper parameter that will change the impact of the
   id173, $\lambda = 1$ means a strong id173 whereas
   $\lambda = 0.001$ means a light id173. we sum all the weights
   squared and we add this sum times lambda to the cost function. if the
   weights are high, the id173 term will be high and the cost
   will increase, conversely if the weights are low the id173
   term will be low.

   because of that, the weights will be smoothed over all the features. if
   a feature has a strong impact on the price, let's say the age, the
   weights corresponding to the age should be high. as we regularize it
   will not happen. as for the cost function, the id173 term
   contains $\frac{1}{2}$ to ease things during the differentiation.
   previously we differentiated our cost function in order to find our
   gradients. we did not take into account the id173 term, but
   the differentiation is easy.

   when we expand our id173 sum we have:

   $$\frac{1}{2} \lambda \sum_{1}^{3} w_{(n)}^2 = \frac{1}{2}
   \lambda(w_{(1)}^2 + w_{(2)}^2 + w_{(3)}^2)$$

   when differentiating our cost function w.r.t $w_{(3)}$, we found:

   $$\frac{\partial j(w)}{\partial w_3} = a^{(3)\intercal} \cdot
   \delta^{(4)}$$

   if we differentiate the id173 term w.r.t $w_{(3)}$ we have:

   $$\frac{1}{2} \lambda(w_{(1)}^2 + w_{(2)}^2 + w_{(3)}^2)$$

   $$\frac{1}{2} \lambda(0 + 0 + w_{(3)}^2)$$

   $$2 \times \frac{1}{2} \lambda w_{(3)}$$

   $$\lambda w_{(3)}$$

   if we add the id173, our gradient w.r.t $w_{(3)}$ is:

   $$\frac{\partial j(w)}{\partial w_3} = a^{(3)\intercal} \cdot
   \delta^{(4)} - \lambda \cdot w_{(3)}$$

   the process is the same for the gradient w.r.t each weight matrix. we
   remove from the gradient $\lambda \cdot w_{(n)}$. this means that
   during each id119 iteration, using the l2 id173,
   each weight will linearly decay towards zero.

   when building a model, here is the list of things you have to choose:
     * the number of hidden layers
     * the number of neurons for each hidden layer
     * the activation function
     * the cost function
     * the optimization algorithm
     * the learning rate
     * the type of id173
     * the id173 rate
     * the number of id119 steps
     * the way of evaluating the accuracy of the network

   we saw the theoritical part of a deep neural network, there are other
   types of neural network that will be the topic of other blog posts. to
   name a few: convolutionnal neural network, long short term memory,
   id3...

python code

   we are finally done with the theoritical part. we will now implement
   all the stuffs we described in python. we will make a first version
   using only numpy and a second one using tensorflow. in a following blog
   post, we will build a version using cudnn and tensorflow c++.

   all the following code is available on [17]github.

id172

   the first step is to download the data from [18]leboncoin.fr, i made a
   [19]python script that loads each car page and save for each car its
   number of kilometers, type of fuel, age and price. the data are saved
   into a [20]csv file. we have 8717 cars.

   raw input data

   we have the raw input data, [21]normalize_lbc_cars_data.py will
   normalize these raw data as we described previously. for the kilometers
   and the age, we substract the mean and divide by the standard
   deviation.
# normalize kilometers: (x - mean)/std
km = features[:, 0].astype("int")
mean_km = np.mean(km)
std_km = np.std(km)
km = (km - mean_km)/std_km
features[:, 0] = km

# normalize age: (x - mean)/std
age = features[:, 2].astype("int")
mean_age = np.mean(age)
std_age = np.std(age)
age = (age - mean_age)/std_age
features[:, 2] = age

   for the type of fuel, we binary encode, diesel equals -1, essence
   equals 1:
# binary convert fuel: diesel = -1, essence = 1
features[:, 1] = [-1 if x == 'diesel' else 1 for x in features[:,1]]

   and finally for the price, we bring the data between [0, 1] because it
   will be the output of our network.
# normalize price: (x - min)/(max - min)
price = features[:, 3].astype("float")
min_price = np.min(price)
max_price = np.max(price)
features[:, 3] = (price - min_price)/(max_price - min_price)

   using the normalized data we create a new csv file called
   [22]normalized_car_features.csv. the first line contains mean_km,
   std_km, mean_age, std_age, min_price, max_price. we will use these data
   in the future when predicting. the user will input the raw car
   attributes, we will normalize them so that our network can use them and
   produce a result, than we will also process this result so that the
   user can see a price that looks like 13 456 euros and not 0.12789.

   during the id172 process we skipped some lines that had a bad
   format or wrong data. be careful if you are using the csv file of raw
   data.

using numpy

   the first step is to implement our network using numpy. we implement
   each part of the neural network described previously. the corresponding
   code is [23]dnn_from_scratch.py.

   we load our normalized data.
reader = csv.reader(open("normalized_car_features.csv", "rb"), delimiter=",")
x = list(reader)
features = np.array(x[2:]).astype("float")
np.random.shuffle(features)

   we shuffle the array because we will keep 80% for our data for the
   training set and 20% for the test set. the goal is to train our network
   using the training set and analyze the loss using the test set. if the
   loss is low with our test set, it means that our network generalizes
   well because it predicts correctly unseen data.

   we split the car attributes and the car prices in two matrices. we also
   append 1 to each car for the bias unit.
data_x = np.concatenate((features[:, :3], np.ones((features.shape[0], 1))), axis
=1)
data_y = features[:, 3:]

   we save the dataset metadata for the prediction part of the network, it
   will help us to normalize the input that we will predict and convert
   the output of the network into a human readable price. all the metadata
   are on the first line of the dataset (mean_km, std_km, mean_age,
   std_age, min_price, max_price).
self.predict = util.predict(float(x[0][0]), float(x[0][1]), float(x[0][2]), floa
t(x[0][3]), float(x[0][4]), float(x[0][5]))

   we calculate how many elements 80% of our networid116 and split the
   dataset into a train set and a test set.
self.m = float(features.shape[0])
self.m_train_set = int(self.m * 0.8)

self.x, self.x_test = data_x[:self.m_train_set, :], data_x[self.m_train_set:, :]
self.y, self.y_test = data_y[:self.m_train_set, :], data_y[self.m_train_set:, :]

   we init all the matrices that we will use, also lambda that is the
   id173 rate and the learning rate.
self.z2, self.a2, self.z3, self.a3, self.z4, self.a4 = (none,) * 6
self.delta2, self.delta3, self.delta4 = (none,) * 3
self.djdw1, self.djdw2, self.djdw3 = (none,) * 3
self.gradient, self.numericalgradient = (none,) * 2
self.lambda = 0.01
self.learning_rate = 0.01

   we init the weights with the values described in the blog post.
self.w1 = np.matrix([
    [0.01, 0.05, 0.07],
    [0.2, 0.041, 0.11],
    [0.04, 0.56, 0.13],
    [0.1, 0.1, 0.1]
])

self.w2 = np.matrix([
    [0.04, 0.78],
    [0.4, 0.45],
    [0.65, 0.23],
    [0.1, 0.1]
])

self.w3 = np.matrix([
    [0.04],
    [0.41],
    [0.1]
])

   once the network is initialized, we can begin the forward propagation.
   we do the calculations explained in the blog post. we put them into a
   forward method because we will call them repeatedly during the gradient
   descent.
def forward(self):

    # first layer
    self.z2 = np.dot(self.x, self.w1)
    self.a2 = np.tanh(self.z2)

    # we add the the 1 unit (bias) at the output of the first layer
    ba2 = np.ones((self.x.shape[0], 1))
    self.a2 = np.concatenate((self.a2, ba2), axis=1)

    # second layer
    self.z3 = np.dot(self.a2, self.w2)
    self.a3 = np.tanh(self.z3)

    # we add the the 1 unit (bias) at the output of the second layer
    ba3 = np.ones((self.a3.shape[0], 1))
    self.a3 = np.concatenate((self.a3, ba3), axis=1)

    # output layer, prediction of our network
    self.z4 = np.dot(self.a3, self.w3)
    self.a4 = np.tanh(self.z4)

   then we do the backward propagation, we are using the data computed
   during the forward propagation to compute the gradients. as the
   backward propagation gives us the sum of the gradients we divide them
   by the size of our train set.
def backward(self):

    # gradient of the cost function with regards to w3
    self.delta4 = np.multiply(-(self.y - self.a4), tanh_prime(self.z4))
    self.djdw3 = (self.a3.t * self.delta4) / self.m_train_set + self.lambda * se
lf.w3

    # gradient of the cost function with regards to w2
    self.delta3 = np.multiply(self.delta4 * self.w3.t, tanh_prime(np.concatenate
((self.z3, np.ones((self.z3.shape[0], 1))), axis=1)))
    self.djdw2 = (self.a2.t * np.delete(self.delta3, 2, axis=1)) / self.m_train_
set + self.lambda * self.w2

    # gradient of the cost function with regards to w1
    self.delta2 = np.multiply(np.delete(self.delta3, 2, axis=1) * self.w2.t, tan
h_prime(np.concatenate((self.z2, np.ones((self.z2.shape[0], 1))), axis=1)))
    self.djdw1 = (self.x.t * np.delete(self.delta2, 3, axis=1)) / self.m_train_s
et + self.lambda * self.w1

   where tanh_prime is the derivative of the tanh function.
def tanh_prime(x):
    return 1.0 - np.square(np.tanh(x))

   the backward propagation gives us the gradients of our cost function,
   we can use them to update our weights.
def update_gradient(self):
    self.w1 -= self.learning_rate * self.djdw1
    self.w2 -= self.learning_rate * self.djdw2
    self.w3 -= self.learning_rate * self.djdw3

   by doing these three steps several times, our network is learning. we
   choose 5000 steps.
nb_it = 5000
for step in xrange(nb_it):

    nn.forward()
    nn.backward()
    nn.update_gradient()

    if step % 100 == 0:
        nn.summary(step)

   the summary method gives us the scores regarding our network. i don't
   detail here the r2 score method.
def summary(self, step):
    print("iteration: %d, loss %f" % (step, self.cost_function()))
    print("rmse: " + str(np.sqrt(np.mean(np.square(self.a4 - self.y)))))
    print("mae: " + str(np.sum(np.absolute(self.a4 - self.y)) / self.m_train_set
))
    print("r2: " + str(self.r2()))

   to be sure that our id26 algorithm computes the gradients
   (partial derivatives) of our cost function correctly we use gradient
   checking. we compute the gradients using the forward and backward
   propagation, then we compute them using the numerical gradient and we
   compare both results.
def check_gradients(self):
    self.compute_gradients()
    self.compute_numerical_gradients()
    print("gradient checked: " + str(np.linalg.norm(self.gradient - self.numeric
algradient) / np.linalg.norm(
        self.gradient + self.numericalgradient)))

   the compute_gradient method is pretty simple, we save our three
   gradient matrices produced by the forward and backward prop into one [1
   x 23] vector.
def compute_gradients(self):
    nn.forward()
    nn.backward()
    self.gradient = np.concatenate((self.djdw1.ravel(), self.djdw2.ravel(), self
.djdw3.ravel()), axis=1).t

   the compute_numerical_gradients method is more complicated. to add or
   remove the perturbation as we described earlier our weights are
   flattened into one vector of size [1 x 23]. we test each weight
   separately. we have a perturbation vector of the same size [1 x 23]
   containing zeros everywhere except at the index of the weight that we
   are testing.

   if we are testing the 5th weight, our perturbation vector will have
   1e-4 at the 5th position. we add the perturbation vector to the
   weights, then we reconstruct our three weights matrices do a forward
   pass and compute the cost. then we remove the perturbation vector from
   the weights, reconstruct our three weights matrices, do a forward pass
   and compute the cost. our numerical gradient for the 5th weight is
   given by: (loss2 - loss1) / (2 * e). we do that for each weight. we
   obtain a [1 x 23] vector containing each numerical gradient for each
   weight.
def compute_numerical_gradients(self):
    weights = np.concatenate((self.w1.ravel(), self.w2.ravel(), self.w3.ravel())
, axis=1).t

    self.numericalgradient = np.zeros(weights.shape)
    perturbation = np.zeros(weights.shape)
    e = 1e-4

    for p in range(len(weights)):
        # set perturbation vector
        perturbation[p] = e

        self.set_weights(weights + perturbation)
        self.forward()
        loss2 = self.cost_function()

        self.set_weights(weights - perturbation)
        self.forward()
        loss1 = self.cost_function()

        self.numericalgradient[p] = (loss2 - loss1) / (2 * e)

        perturbation[p] = 0

    self.set_weights(weights)

   the cost function method used in the code above is the implementation
   of our cost function. as the cost function gives us the sum of the cost
   we divide it by the size of our train set:

   $$ j(w) = \sum_{1}^{n} \frac{1}{2}(y-\hat{y})^2 - \frac{1}{2} \lambda
   \sum_{1}^{3} w_{(n)}^2$$
def cost_function(self):
    return 0.5 * sum(np.square((self.y - self.a4))) / self.m_train_set + (self.l
ambda / 2) * (
        np.sum(np.square(self.w1)) +
        np.sum(np.square(self.w2)) +
        np.sum(np.square(self.w3))
    )

   the only difference compared to the formula is that the cost is
   averaged for all the training examples (because the gradients are
   averaged too, remember the $\frac{1}{n}$ when we update the weights
   using the gradients). the set_weights method is useful to convert the
   weights from one [1 x 23] vector to three matrices back and forth.
def set_weights(self, weights):
    self.w1 = np.reshape(weights[0:12], (4, 3))
    self.w2 = np.reshape(weights[12:20], (4, 2))
    self.w3 = np.reshape(weights[20:23], (3, 1))

   for the id173 there is no explicit part in the code, you can
   see that we add the id173 term to the cost function +
   (self.lambda / 2) * (np.sum(np.square(self.w1)) +
   np.sum(np.square(self.w2)) + np.sum(np.square(self.w3))), also when
   computing the gradients we add the weights times lambda (due to the
   differentiation process) + self.lambda * self.w3 for each weight
   matrix.

   if you remember we splitted our data between train set and test set. we
   want the network's summary (the metrics) with the test set, after 5000
   iterations we have:
### testing summary ###
iteration: 5000, loss 0.004642
rmse: 0.0459143540873
mae: 0.00770927707759
r2: 0.662649615919

   our r2 score could be better, but overall, given the number of features
   for a car (only 3) and the small size of our network, the results are
   pretty good.

   now let's predict the price of a car. we introduced a helper class
   called predict available into [24]predict.py. our predict object is
   constructed during the init part of the neural network, it only saves
   the metadata of our dataset, meaning: mean_km, std_km, mean_age,
   std_age, min_price, max_price. we then use the predict object to
   convert real life car attributes into a normalized version, so that our
   network can use them. our predict object is also useful to convert the
   output of the network into a human readable price.

   to use our network to predict a price, we only need to do a forward
   pass where x, the input, contains the car's data for which we want to
   predict the price. this is called id136, and it will use our
   previously learned weights.

   i took a random ads where a 5 years old car with 168000 kilometers and
   a diesel engine was sold 16 000 euros.

   once the training steps are done, to predict the price we run the
   following:
print("### predict ###")
nn.predict_price(168000, "diesel", 5)

   where predict_price is:
def predict_price(self, km, fuel, age):
    self.x = np.concatenate((self.predict.input(km, fuel, age), np.ones((1, 1)))
, axis=1)
    nn.forward()
    print("predicted price: " + str(self.predict.output(self.a4[0])))

   self.predict.input(km, fuel, age) will took the raw car attributes and
   give us the normalized version to which we append 1 for the bias.

   we then do a forward pass and the predicted price is predicted price:
   [[ 13484.89728828]]

   16 000 euros seems expensive according to our network.

using tensorflow

   we also implemented the same version of our network using tensorflow.
   the code is easier because tf do things for you. namely the whole
   optimization part. the corresponding code is
   [25]dnn_from_scratch_tensorflow.py.

   the idea of tf is that you build a graph in python and then once your
   graph is ready, you run it. the computation begins when the session is
   run, before it is only a graph definition. we are using the same
   normalized data as previously. reading the csv is the same code as
   before.

   the github code contains with statements that are useful to group nodes
   under a same group when displaying the graph in tensorboard, the name
   passed as parameter for each tf operation is also used by tensorboard
   to name nodes beautifully. i will omit them here in order to keep the
   code clear.

   we declare our variables.
x = tf.placeholder("float", name="cars")
y = tf.placeholder("float", name="prices")

w1 = tf.variable(tf.random_normal([3, 3]), name="w1")
w2 = tf.variable(tf.random_normal([3, 2]), name="w2")
w3 = tf.variable(tf.random_normal([2, 1]), name="w3")

b1 = tf.variable(tf.random_normal([1, 3]), name="b1")
b2 = tf.variable(tf.random_normal([1, 2]), name="b2")
b3 = tf.variable(tf.random_normal([1, 1]), name="b3")

   a placeholder will be completed when the session is run, the variables
   are initialized by randomly choosing data from a normal distribution.

   then we declare our execution graph. we separate the weights and the
   bias whereas in our previous examples we merged them. tensorflow
   manages them separately. we define our three layers.
layer_1 = tf.nn.tanh(tf.add(tf.matmul(x, w1), b1))
layer_2 = tf.nn.tanh(tf.add(tf.matmul(layer_1, w2), b2))
layer_3 = tf.nn.tanh(tf.add(tf.matmul(layer_2, w3),  b3))

   we compute the id173. the sum of the l2 loss of each weight
   matrix.
id173 = tf.nn.l2_loss(w1) + tf.nn.l2_loss(w2) + tf.nn.l2_loss(w3)

   we define our cost function (to which we add the id173).
loss = tf.reduce_mean(tf.square(layer_3 - y)) + lambda * id173

   we then define which algorithm we will use to minimize our cost
   function. we choose id119 and specify that the loss
   operation will be minimized. the loss operation is our cost function.
train_op = tf.train.gradientdescentoptimizer(learning_rate).minimize(loss)

   we defined the learning rate to 0.01. we can then train the network for
   5000 steps.
# launching the previously defined model begins here
init = tf.global_variables_initializer()

with tf.session() as session:
    session.run(init)

    for i in range(5000):
        session.run(train_op, feed_dict={x: x_data, y: y_data})

   our feed_dict contains the data by which the placeholders will be
   replaced. x_data contains the training data, meaning 80% of our data
   set, these data will be used when the placeholder x is used in our
   graph. y_data contains the prices of our cars.

   the great thing about tensorflow is that it knows which operations we
   stacked during our graph definition and how to differentiate each one
   of them. as we called
   gradientdescentoptimizer(learning_rate).minimize(loss) tf knows that
   the backward propagation will start from the loss formula back to the
   input and that it has to differentiate the whole calculation graph.

   when coding the network, the back propagation part is the most error
   prone. we don't check our gradient here, we assume that tf is unit
   tested and that the analytical differentiation of our cost function is
   correct.

   we use our testing data to validate the performances of our network. at
   the 5000th iteration our training set gives a loss of: 0.024727896 and
   our test set gives a loss of: 0.024568973 which is good.

   if we try to predict the same car as before, tensorflow gives us a
   price of predicted price: [[ 13471.90332031]]. we also do a forward
   pass using one input:
feed_dict = {x: predict.input(168000, "diesel", 5)}
print("predicted price: " + str(predict.output(session.run(layer_3, feed_dict)))
)

   as with our numpy network, the price is less than 16 000 euros.
   definitely overpriced. each launch will give a different price because
   we are learning the weights from scratch each time and they are
   randomly initialized.

   thanks for reading this post, if you have questions or see mistakes, do
   not hesitate to comment.
     __________________________________________________________________

   written by

florian courtial

   - 18 april 2017

   share this post on [26]twitter [27]facebook [28]google+
     __________________________________________________________________

   please enable javascript to view the [29]comments powered by disqus.

references

   1. https://matrices.io/rss/
   2. https://matrices.io/deep-neural-network-from-scratch/#menu
   3. https://matrices.io/
   4. https://matrices.io/
   5. https://matrices.io/about/
   6. https://matrices.io/subscribe/
   7. https://github.com/theflofly
   8. https://matrices.io/rss/
   9. https://github.com/theflofly/dnn_from_scratch_py
  10. http://leboncoin.fr/
  11. https://visualstudiomagazine.com/articles/2013/07/01/neural-network-data-id172-and-encoding.aspx
  12. http://stats.stackexchange.com/questions/115258/comprehensive-list-of-activation-functions-in-neural-networks-with-pros-cons
  13. http://cs231n.github.io/neural-networks-1/
  14. https://www.reddit.com/r/machinelearning/comments/4582s0/overview_of_optimization_algorithms/
  15. http://www.derivative-calculator.net/
  16. https://www.youtube.com/watch?v=gkb4vw16qhi&t=1s
  17. https://github.com/theflofly/dnn_from_scratch_py
  18. https://www.leboncoin.fr/voitures/offres/rhone_alpes/occasions/?o=0&brd=bmw&mdl=serie 1
  19. https://github.com/theflofly/dnn_from_scratch_py/blob/master/download_lbc_cars_data.py
  20. https://github.com/theflofly/dnn_from_scratch_py/blob/master/car_features.csv
  21. https://github.com/theflofly/dnn_from_scratch_py/blob/master/normalize_lbc_cars_data.py
  22. https://github.com/theflofly/dnn_from_scratch_py/blob/master/normalized_car_features.csv
  23. https://github.com/theflofly/dnn_from_scratch_py/blob/master/dnn_from_scratch.py
  24. https://github.com/theflofly/dnn_from_scratch_py/blob/master/predict.py
  25. https://github.com/theflofly/dnn_from_scratch_py/blob/master/dnn_from_scratch_tensorflow.py
  26. https://twitter.com/intent/tweet?text=deep neural network from scratch&url=https://matrices.io/deep-neural-network-from-scratch/
  27. https://www.facebook.com/sharer/sharer.php?u=https://matrices.io/deep-neural-network-from-scratch/
  28. https://plus.google.com/share?url=https://matrices.io/deep-neural-network-from-scratch/
  29. https://disqus.com/?ref_noscript
