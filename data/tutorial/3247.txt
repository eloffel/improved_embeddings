   #[1]github [2]recent commits to convnet:master

   [3]skip to content

   (button)

     * why github?
       [4]features    
          + [5]code review
          + [6]project management
          + [7]integrations
          + [8]actions
          + [9]team management
          + [10]social coding
          + [11]documentation
          + [12]code hosting
          + [13]customer stories    
          + [14]security    
     * [15]enterprise
     * explore
          + [16]explore github    

learn & contribute
          + [17]topics
          + [18]collections
          + [19]trending
          + [20]learning lab
          + [21]open source guides

connect with others
          + [22]events
          + [23]community forum
          + [24]github education
     * [25]marketplace
     * pricing
       [26]plans    
          + [27]compare plans
          + [28]contact sales
          + [29]nonprofit    
          + [30]education    

   ____________________
     * in this repository all github    
       jump to    

     * no suggested jump to results

     * in this repository all github    
       jump to    
     * in this repository all github    
       jump to    

   [31]sign in [32]sign up

     * [33]watch [34]37
     * [35]star [36]234
     * [37]fork [38]145

[39]sdemyanov/[40]convnet

   [41]code [42]issues 18 [43]pull requests 0 [44]projects 0 [45]insights
   (button) dismiss

join github today

   github is home to over 31 million developers working together to host
   and review code, manage projects, and build software together.
   [46]sign up
   convolutional neural networks for matlab for classification and
   segmentation, including invariang id26 (ibp) and adversarial
   training (at) algorithms. trained on gpu, require cudnn v5.
     * [47]165 commits
     * [48]1 branch
     * [49]0 releases
     * [50]fetching contributors

    1. [51]c++ 55.2%
    2. [52]cuda 31.9%
    3. [53]matlab 9.6%
    4. [54]c 2.0%
    5. [55]makefile 1.3%

   (button) c++ cuda matlab c makefile
   branch: master (button) new pull request
   [56]find file
   clone or download

clone with https

   use git or checkout with svn using the web url.
   https://github.com/s
   [57]download zip

downloading...

   want to be notified of new releases in sdemyanov/convnet?
   [58]sign in [59]sign up

launching github desktop...

   if nothing happens, [60]download github desktop and try again.

   (button) go back

launching github desktop...

   if nothing happens, [61]download github desktop and try again.

   (button) go back

launching xcode...

   if nothing happens, [62]download xcode and try again.

   (button) go back

launching visual studio...

   if nothing happens, [63]download the github extension for visual studio
   and try again.

   (button) go back
   sergey demyanov
   sergey demyanov [64]speedup update
   latest commit [65]04c87ca sep 26, 2016
   [66]permalink
   type        name        latest commit message commit time
        failed to load latest commit information.
        [67]c++
        [68]data
        [69]matlab
        [70]profiler
        [71].gitattributes
        [72].gitignore
        [73]readme.md
        [74]compile.m
        [75]fcn_test.m
        [76]mnist.m

readme.md

   copyright (c) 2016 [77]sergey demyanov

   contact: [78]my_name@my_sirname.net

   you can also find and use my [79]worklab for tensorflow.

   this toolbox has been written as a part of my phd project. it contains
   the implementation of convolitional neural nets for matlab, written on
   c++ and cuda. the most of the kernels are taken from cudnn v5 library,
   others are written manually. therefore cudnn, v5 or higher is required.

   it also contain the implementation of [80]invariant id26
   (ibp) and [adversarial training (at)]
   ([81]http://arxiv.org/abs/1412.6572) algorithms.

   general information

   convolutional neural network is a type of deep learning classification
   and segmentation algorithms, which can learn useful features from raw
   data by themselves. learning is performed by tuning its weights. id98s
   consist of several layers, which are usually convolutional and
   subsampling layers following each other. convolutional layer performs
   filtering of its input with a small matrix of weights and applies some
   non-linear function to the result. subsampling layer does not contain
   weights and simply reduces the size of its input by averaging of
   max-pooling operation. the number of channels on the last layer should
   coincide with the number of classes. if used for classification, the
   height and width of the last layer output should be 1.

   learning process consists of 2 steps: forward and backward passes,
   which are conducted for all objects in a training set. on the forward
   pass each layer transforms the output of the previous layer according
   to its function. the output of the last layer is compared with the
   label values and the id168 is computed. on the backward pass
   the derivatives of id168 with respect to outputs are
   consecutively computed from the last layer to the first, together with
   the derivatives with respect to weights. after that the weights are
   changed in the direction which decreases the value of the loss
   function. this process is performed for a batch of objects
   simultaneously, in order to decrease the sample bias. processing of all
   objects in the dataset is called the epoch. usually training consists
   of many epochs, conducted with different batch splits.

   description

   the toolbox was written for matlab and its functions can be called only
   from matlab scripts. the toolbox requires a cuda capable gpu. the
   toolbox does not require parallel computing toolbox as matconvnet, but
   you can import and use pretrained matconvnet models. the toolbox
   operates with 4-dimensional tensors with incides corresponding to
   height(h), width(w), channel(c) and number(n). labels should also be
   4-dimensional tensors. if used for classification, labels should have
   height=1 and width=1. before passing to c++ code the height and width
   dimensions are permuted, so the layout becomes nchw (n is the slowest
   index). same layout is used for weights everywhere. for speedup
   purposes weights are passed and returned as a long vector or stretched
   and concatenated weights from all layers. use functions weights =
   getweights(layers) and layers = setweights(layers, weights) to obtain
   the vector and assign it back to layers.

   the toolbox contains 3 main functions to call:
     * [weights] = genweights(layers, params)
       returns randomly generated initial weights for the net. has to be
       called before the training.
     * [weights, trainerr] = train(layers, weights, params, train_x,
       train_y)
       performs neural net training. returns the set of updated weights
       and values of the main and additional id168s.
     * [err, bad, pred] = test(layers, weights, params, test_x, test_y)
       returns predictions and calculates the test error.

   layers

   define the structure of id98. sets up as cell array, with each element
   representing an independent layer. currently 6 layer types are
   implemented:
     * input - input layer. must be the first and only the first one. must
       contain the "mapsize" field, that is a vector with 2 integer
       values, representing the objects size (height and width). may also
       contain the following additional fields:

    1. 'channels' - that specifies the number of data channels, if it
       differs from 1.

     * jitt - jittering layer. performs affine transformations of the
       image. with the default parameters performs central cropping. must
       have the parameter 'mapsize'. other possible parameters are:

    1. 'shift' - specifies the maximum shift of the image in each
       dimension,
    2. 'scale' - specifies the maximum scale in each dimension. must be
       more than 1. the image scales with the random factors from [1/x x].
    3. 'mirror' - determines if the image might be mirrored (1) in a
       particular dimension or not (0).
    4. 'angle' - scalar, that specifies the maximum angle of rotation.
       must be from [0, 1]. the value 1 corresponds to 180 degrees.
    5. 'defval' - specifies the value that is used when the transformed
       image lies outside the borders of the original image. if this value
       is not specified, the transformed value should be always inside the
       original one, otherwise there will be an error. on the test stage
       the images are just centrally cropped to the size 'mapsize', like
       there were no additional parameters.

     * conv - convolutional layer. must contain the "filtersize" field,
       that identifies the filter size. must also contain the "channels"
       field, which is the number of output channels. if the previous
       layer has "m" maps and the current one has "n" maps, the total
       number of filters on it is m * n. despite that it is called
       convolutional, it performs filtering, that is a convolution
       operation with flipped dimensions.
     * deconv - reverse convolutional layer. must contain the same fields
       as the convolutional layer. on the forward pass performs the same
       operation as performed on the backward pass of the "conv" layer,
       and otherwise. therefore, instead of scaling the dimensions by a
       factor of "stride" it multiplies them on "stride".
     * pool - pooling layer. the pooling type is specified by "pooling"
       field, which can be eigther "max" or "avg". default value is "max".
       must contain the "scale" and "stride" fields, which are the vectors
       with 2 integer values.
     * full - fully connected layer. produces a tensor with height=1 and
       width=1. must contain the "channels" field, which defines the
       number of output channels. considers its input as a single vector.

   additionally, all layers might have the following parameters:
     * function - defines the non-linear transformation function. it can
       be "relu", "sigm", "soft" or "none", which correspond to rectified
       linear unit, sigmoid, softmax or no transformation respectively.
       the default value is "relu". the value "soft" must be used only on
       the last layer.
     * padding - a 2-dimensional vector of non-negative integers.
       considered by "conv", "deconv" and "pool" layers. determines the
       number of zero padding rows (columns) on the top and bottom
       (padding[0]) and left and right (padding[1]).
     * stride - a 2-dimensional vector of non-negative integers.
       considered by "conv", "deconv" and "pool" layers. determines the
       distance between the positions of applied kernels in vertical and
       horizontal dimensions.
     * init_std - the standard deviation of normal distribution that is
       used to generate the weights. when is not defined, init_std =
       sqrt(2/(h * w * m)), where 'h' and 'w' is the filter size and 'm'
       is the number of input channels. considered by all layers with
       weights.
     * add_bias - whether the layer should add bias to the output or not.
       the length of the bias vector is equal to the number of output
       channels. considered by all layers. default is true for all layers
       with weights, false for others.
     * bias_coef - the multiplier for the bias learning rate. default is
       1.
     * lr_coef - the multiplier for the learning rate on this layer, both
       weights and biases. considered by all layers. set it to 0 to fix
       some layers.
     * dropout - a scalar from [0, 1), which determines the id203 of
       dropping the activations on this layer. should not be too large,
       otherwise it drops everything.

   params

   define the learning process. it is a structure with the fields
   described below.
     * seed - any integer, which allows to repeat the same random numbers.
       default is 0. note that if "conv", "deconv" or "pool" layers are
       used, the results are not guaranteed to be exactly the same even if
       the same seed is used. for more details read cudnn user guide.
     * batchsize - defines the size of batches. default is 32.
     * epochs - the number of repeats the training procedure with
       different batch splits. default is 1.
     * alpha - defines the learning rate. default is 1.
     * beta - defines the invariant learning rate (see the [82]article).
       the value '0' corresponds to the standard id26
       algorithm. default is 0.
     * shift - defines the shift in the adversarial training algorithm
       (see the [83]article). the value '0' corresponds to the standard
       id26 algorithm. default is 0.
     * normfun - defines the type of norm used as second id168 in
       ibp or used to generate adversarial examples in at. default is 1.
     * momentum - defines the actual direction of weight change according
       to the formula m ** dp + (1-m) ** d, where m is momentum, dp is the
       previous change and d is the current derivative. default is 0.
     * decay - defines the weight decay, i.e. every update all weights are
       multiplied on (1-decay).
     * lossfun - string. specifies the employed id168. must be
       eigher "squared" or "logreg", that correspond to sum of squared
       differences and negative log likelihood respectively. if you use
       "logreg", it is better to use "softmax" nonlinear function on the
       last layer and reduce the learning rate about 10 times. the default
       value is "logreg".
     * shuffle - determines whether the input dataset will be shuffled or
       not. if it is set to 0, the batches are created in a natural order:
       first "batchsize" objects become the first batch and so on.
       otherwise, it should be 1. default is 0.
     * verbose - determines output info during learning. for 0 there is no
       output, for 1 it prints only number of current epoch, for 2 it
       prints both numbers of epoch and batch. default is 0.
     * memory - determines the maximum number of megabytes of gpu memory
       allocated as a workspace for convolutional operations. default is
       512.
     * gpu - allows to specify the index of gpu device to work on. default
       is 0.
     * classcoefs - allow to specify coefficients of class importance, for
       example if the dataset is unbalanced. should be a vector of 1xn,
       where n is the number of classes. by default all coefficients are
       1. recommended class coefficients for an unbalanced dataset are
       c[i]= sum[i]^n n[i] / (n[i] * n).

   compilation

   if you cannot use the provided binaries, you need to compile them by
   yourself. the compilation options are defined in the file "settings.h".
   they are:
     * precision. might have two values: 1 - single, uses type 'float'. 2
       - double, uses type 'double'. the second version has not been
       tested.
     * precision_eps. equal to 1e-6 by default. for consistency purposes
       all values that are less than it are assigned to 0.

   compilation
     * linux - adjust the paths in the './c++/makefile' file and run
       "make". that should be enough.
     * windows - has been tested long time ago.

    1. using 'compile' script. while cpu compilation is easy, the gpu
       compilation is tricky and might take some efforts to do it. first
       of all, run 'mex -setup' in order to check that you have a proper
       c++ compiler. if not, install it. you need either a full version of
       visual studio or an express version with microsoft sdk, that are
       free. of course, you need to install cuda as well. download it from
       nvidia site. the cuda settings for 'mex' are located in file with
       the name like "mex_cuda_win64.xml". read more on the mathworks
       [84]website. you must have this file in your matlab folder. the one
       that works for me is located in "./c++/cuda" folder. adjust your
       microsoft sdk and cuda folders, cuda computation capability and
       other options there. make sure you have proper values of
       environment variables 'cuda_path' and 'vs100comntools'. you can do
       it using functions 'getenv' and 'setenv'. if you don't do it, you
       might get an error "no supported compiler or sdk was found". you
       might also get an error about the file 'vcvars64.bat'. in this case
       use the one that is located in "./c++/cuda" folder. adjust the path
       in it as well. after that you should be able to compile.
    2. using visual studio project.
       this is a project to compile 'id98train_mex'. add all '.h', '.cpp'
       and '.cu' files, adjust paths in include and libraries fields, and
       enjoy incremental compilation every time you change just one single
       file. create similar project with the same settings to compile
       'classify' and 'genweights'.

   loading pretrained weights

   it is possible to use pretrained models from [85]matconvnet. given that
   you reconstruct the same architecture, you can use the function
   'import_weights.m' to load the pretrained weights to the network. an
   example for fully convolutional network is provided.

   examples
     * mnist.m - provides an example of training a convolutional network
       on mnist dataset. the error after 5 epochs should be close to 1%.
     * fcn_test.m - provides an example of loading [86]pretrained weights
       from matconvnet and segmenting the images. on the provided test
       set, which is smaller than the original pascal test set, the
       results should be (meaniu = 0.5188, pixelaccuracy = 0.8766,
       meanaccuracy = 0.6574). this is because one of the classes is not
       presented, so its iu is 0.

   known errors
     * when you change gpu index, the first time it might fail. just run
       it again.

     *    2019 github, inc.
     * [87]terms
     * [88]privacy
     * [89]security
     * [90]status
     * [91]help

     * [92]contact github
     * [93]pricing
     * [94]api
     * [95]training
     * [96]blog
     * [97]about

   (button) you can   t perform that action at this time.

   you signed in with another tab or window. [98]reload to refresh your
   session. you signed out in another tab or window. [99]reload to refresh
   your session.

   (button)

references

   visible links
   1. https://github.com/opensearch.xml
   2. https://github.com/sdemyanov/convnet/commits/master.atom
   3. https://github.com/sdemyanov/convnet#start-of-content
   4. https://github.com/features
   5. https://github.com/features/code-review/
   6. https://github.com/features/project-management/
   7. https://github.com/features/integrations
   8. https://github.com/features/actions
   9. https://github.com/features#team-management
  10. https://github.com/features#social-coding
  11. https://github.com/features#documentation
  12. https://github.com/features#code-hosting
  13. https://github.com/customer-stories
  14. https://github.com/security
  15. https://github.com/enterprise
  16. https://github.com/explore
  17. https://github.com/topics
  18. https://github.com/collections
  19. https://github.com/trending
  20. https://lab.github.com/
  21. https://opensource.guide/
  22. https://github.com/events
  23. https://github.community/
  24. https://education.github.com/
  25. https://github.com/marketplace
  26. https://github.com/pricing
  27. https://github.com/pricing#feature-comparison
  28. https://enterprise.github.com/contact
  29. https://github.com/nonprofit
  30. https://education.github.com/
  31. https://github.com/login?return_to=/sdemyanov/convnet
  32. https://github.com/join
  33. https://github.com/login?return_to=/sdemyanov/convnet
  34. https://github.com/sdemyanov/convnet/watchers
  35. https://github.com/login?return_to=/sdemyanov/convnet
  36. https://github.com/sdemyanov/convnet/stargazers
  37. https://github.com/login?return_to=/sdemyanov/convnet
  38. https://github.com/sdemyanov/convnet/network/members
  39. https://github.com/sdemyanov
  40. https://github.com/sdemyanov/convnet
  41. https://github.com/sdemyanov/convnet
  42. https://github.com/sdemyanov/convnet/issues
  43. https://github.com/sdemyanov/convnet/pulls
  44. https://github.com/sdemyanov/convnet/projects
  45. https://github.com/sdemyanov/convnet/pulse
  46. https://github.com/join?source=prompt-code
  47. https://github.com/sdemyanov/convnet/commits/master
  48. https://github.com/sdemyanov/convnet/branches
  49. https://github.com/sdemyanov/convnet/releases
  50. https://github.com/sdemyanov/convnet/graphs/contributors
  51. https://github.com/sdemyanov/convnet/search?l=c++
  52. https://github.com/sdemyanov/convnet/search?l=cuda
  53. https://github.com/sdemyanov/convnet/search?l=matlab
  54. https://github.com/sdemyanov/convnet/search?l=c
  55. https://github.com/sdemyanov/convnet/search?l=makefile
  56. https://github.com/sdemyanov/convnet/find/master
  57. https://github.com/sdemyanov/convnet/archive/master.zip
  58. https://github.com/login?return_to=https://github.com/sdemyanov/convnet
  59. https://github.com/join?return_to=/sdemyanov/convnet
  60. https://desktop.github.com/
  61. https://desktop.github.com/
  62. https://developer.apple.com/xcode/
  63. https://visualstudio.github.com/
  64. https://github.com/sdemyanov/convnet/commit/04c87ca90b444706aac15e7ce19c2080ec30a042
  65. https://github.com/sdemyanov/convnet/commit/04c87ca90b444706aac15e7ce19c2080ec30a042
  66. https://github.com/sdemyanov/convnet/tree/04c87ca90b444706aac15e7ce19c2080ec30a042
  67. https://github.com/sdemyanov/convnet/tree/master/c++
  68. https://github.com/sdemyanov/convnet/tree/master/data
  69. https://github.com/sdemyanov/convnet/tree/master/matlab
  70. https://github.com/sdemyanov/convnet/tree/master/profiler
  71. https://github.com/sdemyanov/convnet/blob/master/.gitattributes
  72. https://github.com/sdemyanov/convnet/blob/master/.gitignore
  73. https://github.com/sdemyanov/convnet/blob/master/readme.md
  74. https://github.com/sdemyanov/convnet/blob/master/compile.m
  75. https://github.com/sdemyanov/convnet/blob/master/fcn_test.m
  76. https://github.com/sdemyanov/convnet/blob/master/mnist.m
  77. http://www.demyanov.net/
  78. mailto:my_name@my_sirname.net
  79. https://github.com/sdemyanov/tensorflow-worklab
  80. http://arxiv.org/abs/1502.04434
  81. http://arxiv.org/abs/1412.6572
  82. http://arxiv.org/abs/1502.04434
  83. http://arxiv.org/abs/1412.6572
  84. http://www.mathworks.com.au/help/distcomp/run-mex-functions-containing-cuda-code.html#btrgjh3-1
  85. http://www.vlfeat.org/matconvnet/
  86. http://www.vlfeat.org/matconvnet/models/pascal-fcn32s-dag.mat
  87. https://github.com/site/terms
  88. https://github.com/site/privacy
  89. https://github.com/security
  90. https://githubstatus.com/
  91. https://help.github.com/
  92. https://github.com/contact
  93. https://github.com/pricing
  94. https://developer.github.com/
  95. https://training.github.com/
  96. https://github.blog/
  97. https://github.com/about
  98. https://github.com/sdemyanov/convnet
  99. https://github.com/sdemyanov/convnet

   hidden links:
 101. https://github.com/
 102. https://github.com/sdemyanov/convnet
 103. https://github.com/sdemyanov/convnet
 104. https://github.com/sdemyanov/convnet
 105. https://help.github.com/articles/which-remote-url-should-i-use
 106. https://github.com/
