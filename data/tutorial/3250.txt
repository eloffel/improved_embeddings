   #[1]minh's virtual lab    feed [2]minh's virtual lab    comments feed
   [3]minh's virtual lab    reproducing chen & manning (2014) comments feed
   [4]skip-gram negative sampling as (unshifted) pmi id105
   [5]hyperparameter tuning in surfsara hpc cloud [6]alternate
   [7]alternate [8]minh's virtual lab [9]wordpress.com

[10]minh's virtual lab

menu

   [11]skip to content
     * [12]about me
          + [13]curriculum vitae
          + [14]publications
          + [15]software
     * [16]neural networks
     * [17]id23
     * [18]natural language understanding

reproducing chen & manning (2014)

   neural id33 is attractive for several reasons: first,
   distributed representation generalizes better, second, fast parsing
   unlocks new applications, and third, fast training means parsers can be
   co-trained with other nlp modules and integrated into a bigger system.

   chen & manning (2014) from stanford were the first to show that neural
   id33 works and google folks were quick to adopt this
   paradigm to improve the state-of-the-art (e.g. weiss et al., 2015).

   though stanford open-sourced their parser as part of corenlp, they
   didn   t release the code of their experiments. as anybody in academia
   probably knows, reproducing experiments is non-trivial, even extremely
   difficult at times. since i have painstakingly gone through the
   process, i think it   s a good idea to share with you.

   (for the impatient, the source code is available on [19]bitbucket.)

   first and foremost, the paper didn   t cover all details of the
   implementation. i think this holds true for most papers in nlp as there
   are always more nitty-gritties than what can be conveyed in 8 pages.
   for example, in [20]jackknifing, whether one divides the dataset by
   sentences or documents can shrink or enlarge the shared vocabulary
   between training and testing sets therefore affects accuracy.

   some details are left out probably because they are taken for granted
   by veterans. they might however be surprising for newcomers like me.
   for example, nowhere in chen & manning (2014) they mentioned wall
   street journal. nevertheless, the dataset should be understood as the
   wsj part of id32 instead of the whole thing. not knowing this,
   i spent 3 months thinking that the inferior results i got then was due
   to less training data. i only realized that my implementation was to
   blame when getting my hands on the full id32.

   so, i reimplemented the stanford neural dependency parser using torch7
   and got these results:
                                    stanford dep.   conll dep.
                                    uas  las        uas   las
   published results                91.8 89.6       92.0  90.7   (1)
   stanford impl. + published model 91.4 89.4       65.6  56.1   (2)
   stanford impl.                   90.4 89.0        86.4 84.8   (3)
   my impl. + published model       91.6 89.7       92.3  91.0   (4)
   my impl.                         90.2 88.7       90.8  89.7   (5)

   rows (1) and (2) tell us something about the current dataset and what
   chen & manning used. the    stanford dependency    dataset, i.e. wsj
   constituent trees converted into dependency tree using stanford
   software, seems fine but the    conll dependency    dataset, i.e. converted
   using lth conversion tool, doesn   t seem to match. when i compare the
   statistics, my conll dataset contains about 2000 words more than
   reported in the paper. i tried different parameters but couldn   t get
   the right number so i reverted back to pennconverter.jar -raw. since
   more recent papers mostly evaluate on stanford dependency anyway, i
   decided to move on.

   as noted on [21]stanford website, published models were trained with
   matlab code (not available) and you   re likely to get lower results
   using public the java code. this explains the difference between rows
   (1) and (3). i try here to match the performance of java implementation
   only (compare rows (3) and (5), (4) and (6)) and hope that better
   hyperparameter tuning will get us to the published results.

   this work provides researchers with some fast and reproducible
   experiments. with the help of a gpu, it took my code about 1.5 hour to
   train compared to 8 hour of stanford   s code. the parsing speed is
   slower: about 400 sentences/s compared to 1000 sentences/s however,
   given that wsj contains about 40k sentences, it will take just less
   than 2 minutes to parse the whole corpus. it   s possible to speed up
   using threads (what stanford   s implementation also does) but for now
   i   ll keep things simple.

   for more details, my notes are available on [22]wikia and source code
   on [23]bitbucket.

   references

   chen, d., & manning, c. (2014). a fast and accurate dependency parser
   using neural networks. in proceedings of the 2014 conference on
   empirical methods in natural language processing (emnlp) (pp. 740   750).
   doha, qatar: association for computational linguistics.

   weiss, d., alberti, c., collins, m., & petrov, s. (2015). structured
   training for neural network transition-based parsing. in proceedings of
   the 53rd annual meeting of the association for computational
   linguistics and the 7th international joint conference on natural
   language processing (volume 1: long papers) (pp. 323   333). association
   for computational linguistics.
   advertisements

share this:

     * [24]twitter
     * [25]facebook
     *

like this:

   like loading...

related

   [26]january 12, 2016[27]minhlab [28]code, [29]dataset, [30]dependency
   parsing, [31]reproducing

post navigation

   [32]    skip-gram negative sampling as (unshifted) pmi
   id105
   [33]hyperparameter tuning in surfsara hpc cloud    

3 thoughts on    reproducing chen & manning (2014)   

    1.
   [34]andrew matteson says:
       [35]march 9, 2017 at 6:40 pm
       thanks for the overview. this is really insightful. i have just a
       quick question that i   m really hoping you can answer. i   m probably
       misunderstanding something but i have similar frustrations due to
       the lack of details in implementation.
       i am still trying to reproduce the results of this paper (and
       replicate syntaxnet) in python, but i suspect one of the problems
       i   m coming across is error propagation. when i measure tokens
       independently (with gold deprel labeling for already-parsed
       siblings and children) the accuracy is in the ballpark of parsey   s
       cousins, but when i measure using entire sentences at once, the
       accuracy quickly heads downhill. i suspect this is because one
       wrong transition or one missing shift basically lands the entire
       remaining part of the sentence in the trash bin.
       is what i   m saying making sense, or perhaps i   m fundamentally
       misunderstanding something? is this a problem you ran into?
       ironically i noticed on your front page you had a paper about error
       propagation, but what i   d like to know is how your implementation
       here handles this sort of problem or whether you even ran into it
       in the first place.
       [36]likelike
       [37]reply
          +
        [38]minhlab says:
            [39]march 11, 2017 at 5:23 pm
            hi andrew. i don   t know the details of your setup but in
            regular cases, the evaluation starts *after* the parser has
            produced its output. so whatever difference there is, it isn   t
            in the parsing but in the evaluation itself. i guess it   s
            simply because sentence-based accuracy is harder. for example,
            a sentence with 1 incorrect link might be judged 90% correct
            in token-based evaluation but 0% correct in sentence-based
            evaluation (i.e. a sentence is correct only all links are
            correct).
            [40]likelike
            [41]reply
               o
             [42]andrew matteson says:
                 [43]march 12, 2017 at 4:26 pm
                 thanks for your reply. okay, so uas and las should be
                 after the parser has completed output. it should have
                 been obvious to me. i think my problem is not due to
                 error propagation but rather just a need of
                 hyperparameter tuning. my project is here, but still in
                 the early stages.
                 [44]https://github.com/xtknight/ash-parser
                 [45]likeliked by [46]1 person

leave a reply [47]cancel reply

   enter your comment here...

   ____________________________________________________________
   ____________________________________________________________
   ____________________________________________________________
   ____________________________________________________________

   fill in your details below or click an icon to log in:
     *
     *
     *

       iframe: [48]googleplus-sign-in

     *
     *

   [49]gravatar
   email (required) (address never made public)
   ____________________
   name (required)
   ____________________
   website
   ____________________
   wordpress.com logo

   you are commenting using your wordpress.com account. ( [50]log out /
   [51]change )
   google photo

   you are commenting using your google account. ( [52]log out /
   [53]change )
   twitter picture

   you are commenting using your twitter account. ( [54]log out /
   [55]change )
   facebook photo

   you are commenting using your facebook account. ( [56]log out /
   [57]change )
   [58]cancel

   connecting to %s

   [ ] notify me of new comments via email.

   post comment

   this site uses akismet to reduce spam. [59]learn how your comment data
   is processed.

archives

     * [60]march 2019
     * [61]november 2018
     * [62]may 2018
     * [63]march 2018
     * [64]july 2017
     * [65]june 2017
     * [66]april 2017
     * [67]march 2017
     * [68]february 2017
     * [69]june 2016
     * [70]january 2016
     * [71]october 2015
     * [72]june 2015
     * [73]march 2015
     * [74]december 2014
     * [75]november 2014
     * [76]october 2014

category

     * [77]computational lexical semantics (2)
     * [78]conference (3)
     * [79]data science (1)
     * [80]misc. (1)
     * [81]natural language understanding (6)
     * [82]neural networks (6)
     * [83]id126 (1)
     * [84]id23 (1)

feeds

     * [85]rss - posts
     * [86]rss - comments

my twitter

   [87]my tweets

   [88]create a free website or blog at wordpress.com.

   close and accept privacy & cookies: this site uses cookies. by
   continuing to use this website, you agree to their use.
   to find out more, including how to control cookies, see here:
   [89]cookie policy

   iframe: [90]likes-master

   %d bloggers like this:

references

   visible links
   1. https://minhlab.wordpress.com/feed/
   2. https://minhlab.wordpress.com/comments/feed/
   3. https://minhlab.wordpress.com/2016/01/12/reproducing-chen-manning-2014/feed/
   4. https://minhlab.wordpress.com/2015/10/18/skip-gram-negative-sampling-as-unshifted-pmi-matrix-factorization/
   5. https://minhlab.wordpress.com/2016/06/17/hyperparameter-tuning-in-surfsara-hpc-cloud/
   6. https://public-api.wordpress.com/oembed/?format=json&url=https://minhlab.wordpress.com/2016/01/12/reproducing-chen-manning-2014/&for=wpcom-auto-discovery
   7. https://public-api.wordpress.com/oembed/?format=xml&url=https://minhlab.wordpress.com/2016/01/12/reproducing-chen-manning-2014/&for=wpcom-auto-discovery
   8. https://minhlab.wordpress.com/osd.xml
   9. https://s1.wp.com/opensearch.xml
  10. https://minhlab.wordpress.com/
  11. https://minhlab.wordpress.com/2016/01/12/reproducing-chen-manning-2014/#content
  12. https://minhlab.wordpress.com/about/
  13. https://docs.google.com/document/d/1gfv-sahgotzyla4egcsnwpbysm8nfmt8m1y9kevloea/edit#heading=h.17me9og2rfhs
  14. https://minhlab.wordpress.com/about/publications/
  15. https://minhlab.wordpress.com/about/software/
  16. https://minhlab.wordpress.com/category/neural-networks/
  17. https://minhlab.wordpress.com/category/reinforcement-learning/
  18. https://minhlab.wordpress.com/category/natural-language-understanding/
  19. https://bitbucket.org/cltl/nndep-torch7
  20. http://natural-language-understanding.wikia.com/wiki/dependency_parsing_experiments#preprocessing:_pos_tagging
  21. http://nlp.stanford.edu/software/nndep.shtml
  22. http://natural-language-understanding.wikia.com/wiki/reproducing_chen_&_manning_(2014)
  23. https://bitbucket.org/cltl/nndep-torch7
  24. https://minhlab.wordpress.com/2016/01/12/reproducing-chen-manning-2014/?share=twitter
  25. https://minhlab.wordpress.com/2016/01/12/reproducing-chen-manning-2014/?share=facebook
  26. https://minhlab.wordpress.com/2016/01/12/reproducing-chen-manning-2014/
  27. https://minhlab.wordpress.com/author/minhlab/
  28. https://minhlab.wordpress.com/tag/code/
  29. https://minhlab.wordpress.com/tag/dataset/
  30. https://minhlab.wordpress.com/tag/dependency-parsing/
  31. https://minhlab.wordpress.com/tag/reproducing/
  32. https://minhlab.wordpress.com/2015/10/18/skip-gram-negative-sampling-as-unshifted-pmi-matrix-factorization/
  33. https://minhlab.wordpress.com/2016/06/17/hyperparameter-tuning-in-surfsara-hpc-cloud/
  34. http://www.andrewmatteson.name/
  35. https://minhlab.wordpress.com/2016/01/12/reproducing-chen-manning-2014/#comment-39
  36. https://minhlab.wordpress.com/2016/01/12/reproducing-chen-manning-2014/?like_comment=39&_wpnonce=df99d14e74
  37. https://minhlab.wordpress.com/2016/01/12/reproducing-chen-manning-2014/?replytocom=39#respond
  38. https://minhlab.wordpress.com/
  39. https://minhlab.wordpress.com/2016/01/12/reproducing-chen-manning-2014/#comment-41
  40. https://minhlab.wordpress.com/2016/01/12/reproducing-chen-manning-2014/?like_comment=41&_wpnonce=017bb8fb44
  41. https://minhlab.wordpress.com/2016/01/12/reproducing-chen-manning-2014/?replytocom=41#respond
  42. http://www.andrewmatteson.name/
  43. https://minhlab.wordpress.com/2016/01/12/reproducing-chen-manning-2014/#comment-42
  44. https://github.com/xtknight/ash-parser
  45. https://minhlab.wordpress.com/2016/01/12/reproducing-chen-manning-2014/?like_comment=42&_wpnonce=075b757d32
  46. https://minhlab.wordpress.com/2016/01/12/reproducing-chen-manning-2014/
  47. https://minhlab.wordpress.com/2016/01/12/reproducing-chen-manning-2014/#respond
  48. https://public-api.wordpress.com/connect/?googleplus-sign-in=https://minhlab.wordpress.com&color_scheme=light
  49. https://gravatar.com/site/signup/
  50. javascript:highlandercomments.doexternallogout( 'wordpress' );
  51. https://minhlab.wordpress.com/2016/01/12/reproducing-chen-manning-2014/
  52. javascript:highlandercomments.doexternallogout( 'googleplus' );
  53. https://minhlab.wordpress.com/2016/01/12/reproducing-chen-manning-2014/
  54. javascript:highlandercomments.doexternallogout( 'twitter' );
  55. https://minhlab.wordpress.com/2016/01/12/reproducing-chen-manning-2014/
  56. javascript:highlandercomments.doexternallogout( 'facebook' );
  57. https://minhlab.wordpress.com/2016/01/12/reproducing-chen-manning-2014/
  58. javascript:highlandercomments.cancelexternalwindow();
  59. https://akismet.com/privacy/
  60. https://minhlab.wordpress.com/2019/03/
  61. https://minhlab.wordpress.com/2018/11/
  62. https://minhlab.wordpress.com/2018/05/
  63. https://minhlab.wordpress.com/2018/03/
  64. https://minhlab.wordpress.com/2017/07/
  65. https://minhlab.wordpress.com/2017/06/
  66. https://minhlab.wordpress.com/2017/04/
  67. https://minhlab.wordpress.com/2017/03/
  68. https://minhlab.wordpress.com/2017/02/
  69. https://minhlab.wordpress.com/2016/06/
  70. https://minhlab.wordpress.com/2016/01/
  71. https://minhlab.wordpress.com/2015/10/
  72. https://minhlab.wordpress.com/2015/06/
  73. https://minhlab.wordpress.com/2015/03/
  74. https://minhlab.wordpress.com/2014/12/
  75. https://minhlab.wordpress.com/2014/11/
  76. https://minhlab.wordpress.com/2014/10/
  77. https://minhlab.wordpress.com/category/computational-lexical-semantics/
  78. https://minhlab.wordpress.com/category/conference/
  79. https://minhlab.wordpress.com/category/data-science/
  80. https://minhlab.wordpress.com/category/misc/
  81. https://minhlab.wordpress.com/category/natural-language-understanding/
  82. https://minhlab.wordpress.com/category/neural-networks/
  83. https://minhlab.wordpress.com/category/recommendation-system/
  84. https://minhlab.wordpress.com/category/reinforcement-learning/
  85. https://minhlab.wordpress.com/feed/
  86. https://minhlab.wordpress.com/comments/feed/
  87. https://twitter.com/minhle_r7
  88. https://wordpress.com/?ref=footer_website
  89. https://automattic.com/cookies
  90. https://widgets.wp.com/likes/master.html?ver=20190321#ver=20190321

   hidden links:
  92. https://minhlab.wordpress.com/2016/01/12/reproducing-chen-manning-2014/#comment-form-guest
  93. https://minhlab.wordpress.com/2016/01/12/reproducing-chen-manning-2014/#comment-form-load-service:wordpress.com
  94. https://minhlab.wordpress.com/2016/01/12/reproducing-chen-manning-2014/#comment-form-load-service:twitter
  95. https://minhlab.wordpress.com/2016/01/12/reproducing-chen-manning-2014/#comment-form-load-service:facebook
