     * [1]triviaqa
     * [2]data
     * [3]data sample
     * [4]paper
     * [5]code
     * [6]leaderboard
     * [7]contact

triviaqa: a large scale dataset for reading comprehension and question
answering

   triviaqa is a reading comprehension dataset containing over 650k
   question-answer-evidence triples. triviaqa includes 95k question-answer
   pairs authored by trivia enthusiasts and independently gathered
   evidence documents, six per question on average, that provide high
   quality distant supervision for answering the questions. the details
   can be found in our acl 17 paper [8]triviaqa: a large scale distantly
   supervised challenge dataset for reading comprehension

                                                            [logo-640.png]
   mandar joshi, eunsol choi, daniel weld, luke zettlemoyer. [9]triviaqa:
   a large scale distantly supervised challenge dataset for reading
   comprehension
   in association for computational linguistics (acl) 2017, vancouver,
   canada.
   [[10]bib]

news

jul 2017

   the triviaqa [11]leaderboard is now live on codalab. submit your
   predictions for evaluation on the test set!

data

   if you are interested in the reading comprehension task motivated in
   the paper, click on the link below to download the data.

               [12]download triviaqa version 1.0 for rc (2.5g)

   if you are interested in open domain qa, click on the link below to
   download the data. it contains the unfiltered dataset with 110k
   question-answer pairs. the wikipedia and top 10 search documents can be
   obtained from the rc version. the main difference between the rc
   version above and the unfiltered dataset is that not all documents (in
   the unfiltered set) for a given question contain the answer string(s).
   this makes the unfiltered dataset more appropriate for ir-style qa.

             [13]download unfiltered triviaqa version 1.0 (604m)

   the university of washington does not own the copyright of the
   questions and documents included in triviaqa.

code

   check out our [14]github repository.

contact

   for any questions about the code or data, please contact [15]mandar
   joshi -- {first name of the first
   author}90[at]cs[dot]washington[dot]edu

references

   1. http://nlp.cs.washington.edu/triviaqa/index.html
   2. http://nlp.cs.washington.edu/triviaqa/#data
   3. http://nlp.cs.washington.edu/triviaqa/sample.html
   4. https://arxiv.org/abs/1705.03551
   5. https://github.com/mandarjoshi90/triviaqa
   6. https://competitions.codalab.org/competitions/17208
   7. http://nlp.cs.washington.edu/triviaqa/#contact
   8. https://arxiv.org/abs/1705.03551
   9. https://arxiv.org/abs/1705.03551
  10. http://nlp.cs.washington.edu/triviaqa/bibs/triviaqa.bib
  11. https://competitions.codalab.org/competitions/17208
  12. http://nlp.cs.washington.edu/triviaqa/data/triviaqa-rc.tar.gz
  13. http://nlp.cs.washington.edu/triviaqa/data/triviaqa-unfiltered.tar.gz
  14. https://github.com/mandarjoshi90/triviaqa
  15. http://homes.cs.washington.edu/~mandar90
