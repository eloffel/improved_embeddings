   #[1]chris mccormick

[2]chris mccormick    [3]about    [4]tutorials    [5]archive

stanford deep learning tutorial

   25 may 2014

   stanford has a very nice [6]tutorial on deep learning that i   ve read
   through, and i   m in the process of going through it in more detail and
   completing the exercises. i   ll be posting my notes on each section as i
   go.

why deep learning?

   my understanding of the significance of deep learning is still
   evolving, but here are some of the high level points, as i currently
   understand it.

   deep networks

   one way to look at deep learning is as an approach for effectively
   training a multilayer id88 (mlp) neural network with multiple
   hidden layers. a    deep    mlp.  (note: the mlp architecture is what   s
   most commonly meant by    neural network   , and is the architecture taught
   in the coursera course on machine learning).

   given enough neurons, a 3-layer mlp (that is, an mlp with a single
   layer of hidden neurons) is capable of doing anything. it can
   approximate any function, or define any arbitrary decision boundary for
   classification. given that, why would we ever want to train an mlp with
   more than one hidden layer? the answer is that the same amount of
   complexity can be accomplished with fewer neurons if you use multiple
   hidden layers.

   according to the tutorial, there are some difficult issues with
   training a    deep    mlp, though, using the standard back propagation
   approach. so one way to view deep learning is as a solution to the
   problem of training deep networks, and thereby unlocking their awesome
   potential.

   unsupervised id171

   the other exciting aspect of these techniques is the ability to learn
   powerful feature extraction techniques using only unlabeled training
   data.

   if you follow my blog, you may know that i   ve spent a fair amount of
   time researching person detection using the histogram of oriented
   gradients (hog) approach. this is a perfect example of the challenge in
   machine learning that deep learning may address.

   first, the hog feature extraction algorithm had to be carefully and
   cleverly designed by researchers. navneet dalal is famous in the
   id161 community for his work on hog; the hog algorithm is a
   big deal. the techniques in this deep learning tutorial point at a
   methodology for learning feature extraction algorithms from unlabeled
   data, without requiring clever engineers like dalal to hand design the
   algorithm.

   second, the machine learning classififier (a linear id166 in the case of
   the original hog detector) must be trained on a large amount of
   hand-labeled training data in order to recognize people. the deep
   learning approach can learn from unlabeled data, which is obviously
   much more abundant.

the tutorial

   stanford   s deep learning tutorial seems to be structured like a course,
   with programming assignments in octave / matlab for each section.

   andrew ng contributed to this tutorial, and it largely uses the same
   notation and conventions as his coursera course, so that   s pretty nice
   if you (like myself) learned neural networks through his course.

   the tutorial is laid out as a list of wiki pages organized into
   sections.  at the end of each section is a programming exercise. the
   wiki format is a little confusing at first for a tutorial, since it   s
   just a series of links to articles (with no forward and back buttons in
   the articles for advancing to the next topic), but the website
   ultimately does appear to be intended as a tutorial to be read
   sequentially.
   [ins: :ins]
   please enable javascript to view the [7]comments powered by disqus.

related posts

     * [8]the inner workings of id97 12 mar 2019
     * [9]applying id97 to recommenders and advertising 15 jun 2018
     * [10]product quantizers for id92 tutorial part 2 22 oct 2017

      2019. all rights reserved.

references

   1. http://mccormickml.com/atom.xml
   2. http://mccormickml.com/
   3. http://mccormickml.com/about/
   4. http://mccormickml.com/tutorials/
   5. http://mccormickml.com/archive/
   6. http://ufldl.stanford.edu/wiki/index.php/ufldl_tutorial
   7. https://disqus.com/?ref_noscript
   8. http://mccormickml.com/2019/03/12/the-inner-workings-of-id97/
   9. http://mccormickml.com/2018/06/15/applying-id97-to-recommenders-and-advertising/
  10. http://mccormickml.com/2017/10/22/product-quantizer-tutorial-part-2/
