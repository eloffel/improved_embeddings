   #[1]chris mccormick

[2]chris mccormick    [3]about    [4]tutorials    [5]archive

id119 derivation

   04 mar 2014

   andrew ng   s [6]course on machine learning at coursera provides an
   excellent explanation of id119 for id75. to
   really get a strong grasp on it, i decided to work through some of the
   derivations and some simple examples here.

   this material assumes some familiarity with id75, and is
   primarily intended to provide additional insight into the gradient
   descent technique, not id75 in general.

   i am making use of the same notation as the coursera course, so it will
   be most helpful for students of that course.

   for id75, we have a linear hypothesis function, \( h(x)
   = \theta_0 + \theta_1 x \). we want to find the values of \( \theta_0
   \) and \( \theta_1 \) which provide the best fit of our hypothesis to a
   training set. the training set examples are labeled \( x, y \), where
   \( x \) is the input value and \( y \) is the output. the ith training
   example is labeled as \( x^{(i)}, y^{(i)} \). do not confuse this as an
   exponent! it just means that this is the ith training example.

mse cost function

   the cost function \( j \) for a particular choice of parameters \(
   \theta \) is the mean squared error (mse):

   [7]mse_cost_eq

   where the variables used are:

   [8]mse_variable_descriptions

   the mse measures the average amount that the model   s predictions vary
   from the correct values, so you can think of it as a measure of the
   model   s performance on the training set. the cost is higher when the
   model is performing poorly on the training set. the objective of the
   learning algorithm, then, is to find the parameters \( \theta \) which
   give the minimum possible cost \( j \).

   this minimization objective is expressed using the following notation,
   which simply states that we want to find the \( \theta \) which
   minimizes the cost \( j(\theta) \).

   [9]minimize_eq

id119 minimization - single variable example

   we   re going to be using id119 to find \( \theta \) that
   minimizes the cost. but let   s forget the mse cost function for a moment
   and look at id119 as a minimization technique in general.

   let   s take the much simpler function \( j(\theta) = {\theta}^2 \), and
   let   s say we want to find the value of \( \theta \) which minimizes \(
   j(\theta) \).

   id119 starts with a random value of \( \theta \), typically
   \( \theta = 0 \), but since \( \theta = 0 \) is already the minimum of
   our function \( {\theta}^2 \), let   s start with \( \theta = 3 \).

   id119 is an iterative algorithm which we will run many
   times. on each iteration, we apply the following    update rule    (the :=
   symbol means replace theta with the value computed on the right):

   [10]gradientdescentupdate

   alpha is a parameter called the learning rate which we   ll come back to,
   but for now we   re going to set it to 0.1. the derivative of \(
   j(\theta) \) is simply \( 2\theta \).

   [11]exampleterms

   below is a plot of our function, \( j(\theta) \), and the value of \(
   \theta \) over ten iterations of id119.

   [12]simple2dgradientdescent

   below is a table showing the value of theta prior to each iteration,
   and the update amounts.

   [13]gradientdescenttable

cost function derivative

   why does id119 use the derivative of the cost function?
   finding the slope of the cost function at our current \( \theta \)
   value tells us two things.

   the first is the direction to move theta in. when you look at the plot
   of a function, a positive slope means the function goes upward as you
   move right, so we want to move left in order to find the minimum.
   similarly, a negative slope means the function goes downard towards the
   right, so we want to move right to find the minimum.

   the second is how big of a step to take. if the slope is large we want
   to take a large step because we   re far from the minimum. if the slope
   is small we want to take a smaller step. note in the example above how
   id119 takes increasingly smaller steps towards the minimum
   with each iteration.

the learning rate - alpha

   the learning rate gives the engineer some additional control over how
   large of steps we make.

   selecting the right learning rate is critical. if the learning rate is
   too large, you can overstep the minimum and even diverge. for example,
   think through what would happen in the above example if we used a
   learning rate of 2. each iteration would take us farther away from the
   minimum!

   the only concern with using too small of a learning rate is that you
   will need to run more iterations of id119, increasing your
   training time.

convergence / stopping id119

   note in the above example that id119 will never actually
   converge on the minimum, \( \theta = 0 \). methods for deciding when to
   stop id119 are beyond my level of expertise, but i can tell
   you that when id119 is used in the assignments in the
   coursera course, id119 is run for a large, fixed number of
   iterations (for example, 100 iterations), with no test for convergence.

id119 - multiple variables example

   the mse cost function includes multiple variables, so let   s look at one
   more simple minimization example before going back to the cost
   function.

   let   s take the function:

   when there are multiple variables in the minimization objective,
   id119 defines a separate update rule for each variable. the
   update rule for \( \theta_1 \) uses the partial derivative of \( j \)
   with respect to \( \theta_1 \). a partial derivative just means that we
   hold all of the other variables constant   to take the partial derivative
   with respect to \( \theta_1 \), we just treat \( \theta_2 \) as a
   constant. the update rules are in the table below, as well as the math
   for calculating the partial derivatives. make sure you work through
   those; i wrote out the derivation to make it easy to follow.

   two variable update

   note that when implementing the update rule in software, \( \theta_1 \)
   and \( \theta_2 \) should not be updated until after you have computed
   the new values for both of them. specifically, you don   t want to use
   the new value of \( \theta_1 \) to calculate the new value of \(
   \theta_2 \).

id119 of mse

   now that we know how to perform id119 on an equation with
   multiple variables, we can return to looking at id119 on our
   mse cost function.

   the mse cost function is labeled as equation [1.0] below. taking the
   derivative of this equation is a little more tricky. the key thing to
   remember is that x and y are not variables for the sake of the
   derivative. rather, they represent a large set of constants (your
   training set). so when taking the derivative of the cost function,
   we   ll treat x and y like we would any other constant.

   once again, our hypothesis function for id75 is the
   following:

   i   ve written out the derivation below, and i explain each step in
   detail further down.

   thetazeroderivation

   to move from equation [1.1] to [1.2], we need to apply two basic
   derivative rules:

   [14]scalarmultipleandsumrules

   moving from [1.2] to [1.3], we apply both the power rule and the chain
   rule:

   [15]power rule

   [16]chain rule

   finally, to go from [1.3] to [1.4], we must evaluate the partial
   derivative as follows. recall again that when taking this partial
   derivative all letters except \( \theta_0 \) are treated as constants (
   \( \theta_1 \), \( x \), and \( y \)).

   derivative of the error with respect to theta_0

   equation [1.4] gives us the partial derivative of the mse cost function
   with respect to one of the variables, \( \theta_0 \). now we must also
   take the partial derivative of the mse function with respect to \(
   \theta_1 \). the only difference is in the final step, where we take
   the partial derivative of the error:

   [17]derivative of the error with respect to theta_1

one half mean squared error

   in andrew ng   s machine learning course, there is one small modification
   to this derivation. we multiply our mse cost function by 1/2 so that
   when we take the derivative, the 2s cancel out. multiplying the cost
   function by a scalar does not affect the location of its minimum, so we
   can get away with this.

   alternatively, you could think of this as folding the 2 into the
   learning rate. it makes sense to leave the 1/m term, though, because we
   want the same learning rate (alpha) to work for different training set
   sizes (m).

final update rules

   altogether, we have the following definition for id119 over
   our cost function.

   gradientdescentofmsetable

training set statistics

   note that each update of the theta variables is averaged over the
   training set. every training example suggests its own modification to
   the theta values, and then we take the average of these suggestions to
   make our actual update.

   this means that the statistics of your training set are being taken
   into account during the learning process. an outlier training example
   (or even a mislabeled / corrupted example) is going to have less
   influence over the final weights because it is one voice versus many.
   [ins: :ins]
   please enable javascript to view the [18]comments powered by disqus.

related posts

     * [19]the inner workings of id97 12 mar 2019
     * [20]applying id97 to recommenders and advertising 15 jun 2018
     * [21]product quantizers for id92 tutorial part 2 22 oct 2017

      2019. all rights reserved.

references

   1. http://mccormickml.com/atom.xml
   2. http://mccormickml.com/
   3. http://mccormickml.com/about/
   4. http://mccormickml.com/tutorials/
   5. http://mccormickml.com/archive/
   6. https://www.coursera.org/course/ml
   7. http://chrisjmccormick.files.wordpress.com/2014/02/mse_cost_eq1.png
   8. http://chrisjmccormick.files.wordpress.com/2014/02/mse_variable_descriptions.png
   9. http://chrisjmccormick.files.wordpress.com/2014/02/minimize_eq.png
  10. http://chrisjmccormick.files.wordpress.com/2014/02/gradientdescentupdate.png
  11. http://chrisjmccormick.files.wordpress.com/2014/02/exampleterms.png
  12. http://chrisjmccormick.files.wordpress.com/2014/02/simple2dgradientdescent.png
  13. http://chrisjmccormick.files.wordpress.com/2014/02/gradientdescenttable.png
  14. http://chrisjmccormick.files.wordpress.com/2014/03/scalarmultipleandsumrules.png
  15. http://mccormickml.com/assets/gradientdescent/powerrule.png
  16. http://mccormickml.com/assets/gradientdescent/chainrule.png
  17. http://mccormickml.com/assets/gradientdescent/thetaonederivativeoferror.png
  18. https://disqus.com/?ref_noscript
  19. http://mccormickml.com/2019/03/12/the-inner-workings-of-id97/
  20. http://mccormickml.com/2018/06/15/applying-id97-to-recommenders-and-advertising/
  21. http://mccormickml.com/2017/10/22/product-quantizer-tutorial-part-2/
