   #[1]github [2]recent commits to neural-style:master

   [3]skip to content

   (button)

     * why github?
       [4]features    
          + [5]code review
          + [6]project management
          + [7]integrations
          + [8]actions
          + [9]team management
          + [10]social coding
          + [11]documentation
          + [12]code hosting
          + [13]customer stories    
          + [14]security    
     * [15]enterprise
     * explore
          + [16]explore github    

learn & contribute
          + [17]topics
          + [18]collections
          + [19]trending
          + [20]learning lab
          + [21]open source guides

connect with others
          + [22]events
          + [23]community forum
          + [24]github education
     * [25]marketplace
     * pricing
       [26]plans    
          + [27]compare plans
          + [28]contact sales
          + [29]nonprofit    
          + [30]education    

   ____________________
     * in this repository all github    
       jump to    

     * no suggested jump to results

     * in this repository all github    
       jump to    
     * in this repository all github    
       jump to    

   [31]sign in [32]sign up

     * [33]watch [34]671
     * [35]star [36]16,700
     * [37]fork [38]2,533

[39]jcjohnson/[40]neural-style

   [41]code [42]issues 284 [43]pull requests 29 [44]projects 0 [45]wiki
   [46]insights
   (button) dismiss

join github today

   github is home to over 31 million developers working together to host
   and review code, manage projects, and build software together.
   [47]sign up
   torch implementation of neural style algorithm
     * [48]169 commits
     * [49]2 branches
     * [50]0 releases
     * [51]13 contributors
     * [52]mit

    1. [53]lua 98.0%
    2. [54]shell 2.0%

   (button) lua shell
   branch: master (button) new pull request
   [55]find file
   clone or download

clone with https

   use git or checkout with svn using the web url.
   https://github.com/j
   [56]download zip

downloading...

   want to be notified of new releases in jcjohnson/neural-style?
   [57]sign in [58]sign up

launching github desktop...

   if nothing happens, [59]download github desktop and try again.

   (button) go back

launching github desktop...

   if nothing happens, [60]download github desktop and try again.

   (button) go back

launching xcode...

   if nothing happens, [61]download xcode and try again.

   (button) go back

launching visual studio...

   if nothing happens, [62]download the github extension for visual studio
   and try again.

   (button) go back
   [63]@jcjohnson
   [64]jcjohnson [65]update readme.md
   latest commit [66]07c4b82 apr 15, 2017
   [67]permalink
   type name latest commit message commit time
   failed to load latest commit information.
   [68]examples
   [69]models [70]merged from jcjohnson/neural-style master branch dec 16,
   2015
   [71].gitignore
   [72]install.md
   [73]license
   [74]readme.md [75]update readme.md apr 15, 2017
   [76]neural_style.lua

readme.md

neural-style

   this is a torch implementation of the paper [77]a neural algorithm of
   artistic style by leon a. gatys, alexander s. ecker, and matthias
   bethge.

   the paper presents an algorithm for combining the content of one image
   with the style of another image using convolutional neural networks.
   here's an example that maps the artistic style of [78]the starry night
   onto a night-time photograph of the stanford campus:

          [79][starry_night_google.jpg] [80][hoovertowernight.jpg]
                      [81][starry_stanford_bigger.png]

   applying the style of different images to the same content image gives
   interesting results. here we reproduce figure 2 from the paper, which
   renders a photograph of the tubingen in germany in a variety of styles:

               [82][tubingen.jpg] [83][tubingen_shipwreck.png]
             [84][tubingen_starry.png] [85][tubingen_scream.png]
      [86][tubingen_seated_nude.png] [87][tubingen_composition_vii.png]

   here are the results of applying the style of various pieces of artwork
   to this photograph of the golden gate bridge:

              [88][frida_kahlo.jpg] [89][golden_gate_kahlo.png]
            [90][escher_sphere.jpg] [91][golden_gate_escher.png]

       [92][woman-with-hat-matisse.jpg] [93][golden_gate_matisse.png]
              [94][the_scream.jpg] [95][golden_gate_scream.png]

          [96][starry_night_crop.png] [97][golden_gate_starry.png]
             [98][seated-nude.jpg] [99][golden_gate_seated.png]

content / style tradeoff

   the algorithm allows the user to trade-off the relative weight of the
   style and content reconstruction terms, as shown in this example where
   we port the style of [100]picasso's 1907 self-portrait onto brad pitt:

            [101][picasso_selfport1907.jpg] [102][brad_pitt.jpg]

                 [103][pitt_picasso_content_5_style_10.png]
                 [104][pitt_picasso_content_1_style_10.png]
                 [105][pitt_picasso_content_01_style_10.png]
                [106][pitt_picasso_content_0025_style_10.png]

style scale

   by resizing the style image before extracting style features, we can
   control the types of artistic features that are transfered from the
   style image; you can control this behavior with the -style_scale flag.
   below we see three examples of rendering the golden gate bridge in the
   style of the starry night. from left to right, -style_scale is 2.0,
   1.0, and 0.5.

                    [107][golden_gate_starry_scale2.png]
                    [108][golden_gate_starry_scale1.png]
                    [109][golden_gate_starry_scale05.png]

multiple style images

   you can use more than one style image to blend multiple artistic
   styles.

   clockwise from upper left: "the starry night" + "the scream", "the
   scream" + "composition vii", "seated nude" + "composition vii", and
   "seated nude" + "the starry night"

                      [110][tubingen_starry_scream.png]
                 [111][tubingen_scream_composition_vii.png]
                      [112][tubingen_starry_seated.png]
               [113][tubingen_seated_nude_composition_vii.png]

style interpolation

   when using multiple style images, you can control the degree to which
   they are blended:

                  [114][golden_gate_starry_scream_3_7.png]
                  [115][golden_gate_starry_scream_5_5.png]
                  [116][golden_gate_starry_scream_7_3.png]

transfer style but not color

   if you add the flag -original_colors 1 then the output image will
   retain the colors of the original image; this is similar to [117]the
   recent blog post by deepart.io.

            [118][tubingen_starry.png] [119][tubingen_scream.png]
       [120][tubingen_composition_vii.png] [121][tubingen_starry.png]
       [122][tubingen_scream.png] [123][tubingen_composition_vii.png]

setup:

   dependencies:
     * [124]torch7
     * [125]loadcaffe

   optional dependencies:
     * for cuda backend:
          + cuda 6.5+
          + [126]cunn
     * for cudnn backend:
          + [127]cudnn.torch
     * for opencl backend:
          + [128]cltorch
          + [129]clnn

   after installing dependencies, you'll need to run the following script
   to download the vgg model:
sh models/download_models.sh

   this will download the original [130]vgg-19 model. leon gatys has
   graciously provided the modified version of the vgg-19 model that was
   used in their paper; this will also be downloaded. by default the
   original vgg-19 model is used.

   if you have a smaller memory gpu then using nin id163 model will be
   better and gives slightly worse yet comparable results. you can get the
   details on the model from [131]bvlc caffe modelzoo and can download the
   files from [132]nin-id163 download link

   you can find detailed installation instructions for ubuntu in the
   [133]installation guide.

usage

   basic usage:
th neural_style.lua -style_image <image.jpg> -content_image <image.jpg>

   opencl usage with nin model (this requires you download the nin
   id163 model files as described above):
th neural_style.lua -style_image examples/inputs/picasso_selfport1907.jpg -conte
nt_image examples/inputs/brad_pitt.jpg -output_image profile.png -model_file mod
els/nin_id163_conv.caffemodel -proto_file models/train_val.prototxt -gpu 0 -b
ackend clnn -num_iterations 1000 -seed 123 -content_layers relu0,relu3,relu7,rel
u12 -style_layers relu0,relu3,relu7,relu12 -content_weight 10 -style_weight 1000
 -image_size 512 -optimizer adam

   [134]opencl nin model picasso brad pitt

   to use multiple style images, pass a comma-separated list like this:

   -style_image starry_night.jpg,the_scream.jpg.

   note that paths to images should not contain the ~ character to
   represent your home directory; you should instead use a relative path
   or a full absolute path.

   options:
     * -image_size: maximum side length (in pixels) of of the generated
       image. default is 512.
     * -style_blend_weights: the weight for blending the style of multiple
       style images, as a comma-separated list, such as
       -style_blend_weights 3,7. by default all style images are equally
       weighted.
     * -gpu: zero-indexed id of the gpu to use; for cpu mode set -gpu to
       -1.

   optimization options:
     * -content_weight: how much to weight the content reconstruction
       term. default is 5e0.
     * -style_weight: how much to weight the style reconstruction term.
       default is 1e2.
     * -tv_weight: weight of total-variation (tv) id173; this
       helps to smooth the image. default is 1e-3. set to 0 to disable tv
       id173.
     * -num_iterations: default is 1000.
     * -init: method for generating the generated image; one of random or
       image. default is random which uses a noise initialization as in
       the paper; image initializes with the content image.
     * -optimizer: the optimization algorithm to use; either lbfgs or
       adam; default is lbfgs. l-bfgs tends to give better results, but
       uses more memory. switching to adam will reduce memory usage; when
       using adam you will probably need to play with other parameters to
       get good results, especially the style weight, content weight, and
       learning rate; you may also want to normalize gradients when using
       adam.
     * -learning_rate: learning rate to use with the adam optimizer.
       default is 1e1.
     * -normalize_gradients: if this flag is present, style and content
       gradients from each layer will be l1 normalized. idea from
       [135]andersbll/neural_artistic_style.

   output options:
     * -output_image: name of the output image. default is out.png.
     * -print_iter: print progress every print_iter iterations. set to 0
       to disable printing.
     * -save_iter: save the image every save_iter iterations. set to 0 to
       disable saving intermediate results.

   layer options:
     * -content_layers: comma-separated list of layer names to use for
       content reconstruction. default is relu4_2.
     * -style_layers: comma-separated list of layer names to use for style
       reconstruction. default is relu1_1,relu2_1,relu3_1,relu4_1,relu5_1.

   other options:
     * -style_scale: scale at which to extract features from the style
       image. default is 1.0.
     * -original_colors: if you set this to 1, then the output image will
       keep the colors of the content image.
     * -proto_file: path to the deploy.txt file for the vgg caffe model.
     * -model_file: path to the .caffemodel file for the vgg caffe model.
       default is the original vgg-19 model; you can also try the
       normalized vgg-19 model used in the paper.
     * -pooling: the type of pooling layers to use; one of max or avg.
       default is max. the vgg-19 models uses max pooling layers, but the
       paper mentions that replacing these layers with average pooling
       layers can improve the results. i haven't been able to get good
       results using average pooling, but the option is here.
     * -backend: nn, cudnn, or clnn. default is nn. cudnn requires
       [136]cudnn.torch and may reduce memory usage. clnn requires
       [137]cltorch and [138]clnn
     * -cudnn_autotune: when using the cudnn backend, pass this flag to
       use the built-in cudnn autotuner to select the best convolution
       algorithms for your architecture. this will make the first
       iteration a bit slower and can take a bit more memory, but may
       significantly speed up the cudnn backend.

frequently asked questions

   problem: generated image has saturation artifacts:

   [139][fa8e8782-5328-11e5-9c91-11f7b215ad19.png]

   solution: update the image packge to the latest version: luarocks
   install image

   problem: running without a gpu gives an error message complaining about
   cutorch not found

   solution: pass the flag -gpu -1 when running in cpu-only mode

   problem: the program runs out of memory and dies

   solution: try reducing the image size: -image_size 256 (or lower). note
   that different image sizes will likely require non-default values for
   -style_weight and -content_weight for optimal results. if you are
   running on a gpu, you can also try running with -backend cudnn to
   reduce memory usage.

   problem: get the following error message:

   models/vgg_ilsvrc_19_layers_deploy.prototxt.cpu.lua:7: attempt to call
   method 'ceil' (a nil value)

   solution: update nn package to the latest version: luarocks install nn

   problem: get an error message complaining about paths.extname

   solution: update torch.paths package to the latest version: luarocks
   install paths

   problem: nin id163 model is not giving good results.

   solution: make sure the correct -proto_file is selected. also make sure
   the correct parameters for -content_layers and -style_layers are set.
   (see opencl usage example above.)

   problem: -backend cudnn is slower than default nn backend

   solution: add the flag -cudnn_autotune; this will use the built-in
   cudnn autotuner to select the best convolution algorithms.

memory usage

   by default, neural-style uses the nn backend for convolutions and
   l-bfgs for optimization. these give good results, but can both use a
   lot of memory. you can reduce memory usage with the following:
     * use cudnn: add the flag -backend cudnn to use the cudnn backend.
       this will only work in gpu mode.
     * use adam: add the flag -optimizer adam to use adam instead of
       l-bfgs. this should significantly reduce memory usage, but may
       require tuning of other parameters for good results; in particular
       you should play with the learning rate, content weight, style
       weight, and also consider using gradient id172. this should
       work in both cpu and gpu modes.
     * reduce image size: if the above tricks are not enough, you can
       reduce the size of the generated image; pass the flag -image_size
       256 to generate an image at half the default size.

   with the default settings, neural-style uses about 3.5gb of gpu memory
   on my system; switching to adam and cudnn reduces the gpu memory
   footprint to about 1gb.

speed

   speed can vary a lot depending on the backend and the optimizer. here
   are some times for running 500 iterations with -image_size=512 on a
   maxwell titan x with different settings:
     * -backend nn -optimizer lbfgs: 62 seconds
     * -backend nn -optimizer adam: 49 seconds
     * -backend cudnn -optimizer lbfgs: 79 seconds
     * -backend cudnn -cudnn_autotune -optimizer lbfgs: 58 seconds
     * -backend cudnn -cudnn_autotune -optimizer adam: 44 seconds
     * -backend clnn -optimizer lbfgs: 169 seconds
     * -backend clnn -optimizer adam: 106 seconds

   here are the same benchmarks on a pascal titan x with cudnn 5.0 on cuda
   8.0 rc:
     * -backend nn -optimizer lbfgs: 43 seconds
     * -backend nn -optimizer adam: 36 seconds
     * -backend cudnn -optimizer lbfgs: 45 seconds
     * -backend cudnn -cudnn_autotune -optimizer lbfgs: 30 seconds
     * -backend cudnn -cudnn_autotune -optimizer adam: 22 seconds

multi-gpu scaling

   you can use multiple gpus to process images at higher resolutions;
   different layers of the network will be computed on different gpus. you
   can control which gpus are used with the -gpu flag, and you can control
   how to split layers across gpus using the -multigpu_strategy flag.

   for example in a server with four gpus, you can give the flag -gpu
   0,1,2,3 to process on gpus 0, 1, 2, and 3 in that order; by also giving
   the flag -multigpu_strategy 3,6,12 you indicate that the first two
   layers should be computed on gpu 0, layers 3 to 5 should be computed on
   gpu 1, layers 6 to 11 should be computed on gpu 2, and the remaining
   layers should be computed on gpu 3. you will need to tune the
   -multigpu_strategy for your setup in order to achieve maximal
   resolution.

   we can achieve very high quality results at high resolution by
   combining multi-gpu processing with multiscale generation as described
   in the paper [140]controlling perceptual factors in neural style
   transfer by leon a. gatys, alexander s. ecker, matthias bethge, aaron
   hertzmann and eli shechtman.

   here is a 3620 x 1905 image generated on a server with four pascal
   titan x gpus:

   [141][starry_stanford_bigger.png]

   the script used to generate this image [142]can be found here.

implementation details

   images are initialized with white noise and optimized using l-bfgs.

   we perform style reconstructions using the conv1_1, conv2_1, conv3_1,
   conv4_1, and conv5_1 layers and content reconstructions using the
   conv4_2 layer. as in the paper, the five style reconstruction losses
   have equal weights.

citation

   if you find this code useful for your research, please cite:
@misc{johnson2015,
  author = {johnson, justin},
  title = {neural-style},
  year = {2015},
  publisher = {github},
  journal = {github repository},
  howpublished = {\url{https://github.com/jcjohnson/neural-style}},
}

     *    2019 github, inc.
     * [143]terms
     * [144]privacy
     * [145]security
     * [146]status
     * [147]help

     * [148]contact github
     * [149]pricing
     * [150]api
     * [151]training
     * [152]blog
     * [153]about

   (button) you can   t perform that action at this time.

   you signed in with another tab or window. [154]reload to refresh your
   session. you signed out in another tab or window. [155]reload to
   refresh your session.

   (button)

references

   visible links
   1. https://github.com/opensearch.xml
   2. https://github.com/jcjohnson/neural-style/commits/master.atom
   3. https://github.com/jcjohnson/neural-style#start-of-content
   4. https://github.com/features
   5. https://github.com/features/code-review/
   6. https://github.com/features/project-management/
   7. https://github.com/features/integrations
   8. https://github.com/features/actions
   9. https://github.com/features#team-management
  10. https://github.com/features#social-coding
  11. https://github.com/features#documentation
  12. https://github.com/features#code-hosting
  13. https://github.com/customer-stories
  14. https://github.com/security
  15. https://github.com/enterprise
  16. https://github.com/explore
  17. https://github.com/topics
  18. https://github.com/collections
  19. https://github.com/trending
  20. https://lab.github.com/
  21. https://opensource.guide/
  22. https://github.com/events
  23. https://github.community/
  24. https://education.github.com/
  25. https://github.com/marketplace
  26. https://github.com/pricing
  27. https://github.com/pricing#feature-comparison
  28. https://enterprise.github.com/contact
  29. https://github.com/nonprofit
  30. https://education.github.com/
  31. https://github.com/login?return_to=/jcjohnson/neural-style
  32. https://github.com/join
  33. https://github.com/login?return_to=/jcjohnson/neural-style
  34. https://github.com/jcjohnson/neural-style/watchers
  35. https://github.com/login?return_to=/jcjohnson/neural-style
  36. https://github.com/jcjohnson/neural-style/stargazers
  37. https://github.com/login?return_to=/jcjohnson/neural-style
  38. https://github.com/jcjohnson/neural-style/network/members
  39. https://github.com/jcjohnson
  40. https://github.com/jcjohnson/neural-style
  41. https://github.com/jcjohnson/neural-style
  42. https://github.com/jcjohnson/neural-style/issues
  43. https://github.com/jcjohnson/neural-style/pulls
  44. https://github.com/jcjohnson/neural-style/projects
  45. https://github.com/jcjohnson/neural-style/wiki
  46. https://github.com/jcjohnson/neural-style/pulse
  47. https://github.com/join?source=prompt-code
  48. https://github.com/jcjohnson/neural-style/commits/master
  49. https://github.com/jcjohnson/neural-style/branches
  50. https://github.com/jcjohnson/neural-style/releases
  51. https://github.com/jcjohnson/neural-style/graphs/contributors
  52. https://github.com/jcjohnson/neural-style/blob/master/license
  53. https://github.com/jcjohnson/neural-style/search?l=lua
  54. https://github.com/jcjohnson/neural-style/search?l=shell
  55. https://github.com/jcjohnson/neural-style/find/master
  56. https://github.com/jcjohnson/neural-style/archive/master.zip
  57. https://github.com/login?return_to=https://github.com/jcjohnson/neural-style
  58. https://github.com/join?return_to=/jcjohnson/neural-style
  59. https://desktop.github.com/
  60. https://desktop.github.com/
  61. https://developer.apple.com/xcode/
  62. https://visualstudio.github.com/
  63. https://github.com/jcjohnson
  64. https://github.com/jcjohnson/neural-style/commits?author=jcjohnson
  65. https://github.com/jcjohnson/neural-style/commit/07c4b8299f8fbdafec0c514fc820ff1d7ff62e46
  66. https://github.com/jcjohnson/neural-style/commit/07c4b8299f8fbdafec0c514fc820ff1d7ff62e46
  67. https://github.com/jcjohnson/neural-style/tree/07c4b8299f8fbdafec0c514fc820ff1d7ff62e46
  68. https://github.com/jcjohnson/neural-style/tree/master/examples
  69. https://github.com/jcjohnson/neural-style/tree/master/models
  70. https://github.com/jcjohnson/neural-style/commit/8b7102f9bc12349dd6c6677b472d3d1511b51161
  71. https://github.com/jcjohnson/neural-style/blob/master/.gitignore
  72. https://github.com/jcjohnson/neural-style/blob/master/install.md
  73. https://github.com/jcjohnson/neural-style/blob/master/license
  74. https://github.com/jcjohnson/neural-style/blob/master/readme.md
  75. https://github.com/jcjohnson/neural-style/commit/07c4b8299f8fbdafec0c514fc820ff1d7ff62e46
  76. https://github.com/jcjohnson/neural-style/blob/master/neural_style.lua
  77. http://arxiv.org/abs/1508.06576
  78. https://en.wikipedia.org/wiki/the_starry_night
  79. https://raw.githubusercontent.com/jcjohnson/neural-style/master/examples/inputs/starry_night_google.jpg
  80. https://raw.githubusercontent.com/jcjohnson/neural-style/master/examples/inputs/hoovertowernight.jpg
  81. https://raw.githubusercontent.com/jcjohnson/neural-style/master/examples/outputs/starry_stanford_bigger.png
  82. https://raw.githubusercontent.com/jcjohnson/neural-style/master/examples/inputs/tubingen.jpg
  83. https://raw.githubusercontent.com/jcjohnson/neural-style/master/examples/outputs/tubingen_shipwreck.png
  84. https://raw.githubusercontent.com/jcjohnson/neural-style/master/examples/outputs/tubingen_starry.png
  85. https://raw.githubusercontent.com/jcjohnson/neural-style/master/examples/outputs/tubingen_scream.png
  86. https://raw.githubusercontent.com/jcjohnson/neural-style/master/examples/outputs/tubingen_seated_nude.png
  87. https://raw.githubusercontent.com/jcjohnson/neural-style/master/examples/outputs/tubingen_composition_vii.png
  88. https://raw.githubusercontent.com/jcjohnson/neural-style/master/examples/inputs/frida_kahlo.jpg
  89. https://raw.githubusercontent.com/jcjohnson/neural-style/master/examples/outputs/golden_gate_kahlo.png
  90. https://raw.githubusercontent.com/jcjohnson/neural-style/master/examples/inputs/escher_sphere.jpg
  91. https://raw.githubusercontent.com/jcjohnson/neural-style/master/examples/outputs/golden_gate_escher.png
  92. https://raw.githubusercontent.com/jcjohnson/neural-style/master/examples/inputs/woman-with-hat-matisse.jpg
  93. https://raw.githubusercontent.com/jcjohnson/neural-style/master/examples/outputs/golden_gate_matisse.png
  94. https://raw.githubusercontent.com/jcjohnson/neural-style/master/examples/inputs/the_scream.jpg
  95. https://raw.githubusercontent.com/jcjohnson/neural-style/master/examples/outputs/golden_gate_scream.png
  96. https://raw.githubusercontent.com/jcjohnson/neural-style/master/examples/inputs/starry_night_crop.png
  97. https://raw.githubusercontent.com/jcjohnson/neural-style/master/examples/outputs/golden_gate_starry.png
  98. https://raw.githubusercontent.com/jcjohnson/neural-style/master/examples/inputs/seated-nude.jpg
  99. https://raw.githubusercontent.com/jcjohnson/neural-style/master/examples/outputs/golden_gate_seated.png
 100. http://www.wikiart.org/en/pablo-picasso/self-portrait-1907
 101. https://raw.githubusercontent.com/jcjohnson/neural-style/master/examples/inputs/picasso_selfport1907.jpg
 102. https://raw.githubusercontent.com/jcjohnson/neural-style/master/examples/inputs/brad_pitt.jpg
 103. https://raw.githubusercontent.com/jcjohnson/neural-style/master/examples/outputs/pitt_picasso_content_5_style_10.png
 104. https://raw.githubusercontent.com/jcjohnson/neural-style/master/examples/outputs/pitt_picasso_content_1_style_10.png
 105. https://raw.githubusercontent.com/jcjohnson/neural-style/master/examples/outputs/pitt_picasso_content_01_style_10.png
 106. https://raw.githubusercontent.com/jcjohnson/neural-style/master/examples/outputs/pitt_picasso_content_0025_style_10.png
 107. https://raw.githubusercontent.com/jcjohnson/neural-style/master/examples/outputs/golden_gate_starry_scale2.png
 108. https://raw.githubusercontent.com/jcjohnson/neural-style/master/examples/outputs/golden_gate_starry_scale1.png
 109. https://raw.githubusercontent.com/jcjohnson/neural-style/master/examples/outputs/golden_gate_starry_scale05.png
 110. https://raw.githubusercontent.com/jcjohnson/neural-style/master/examples/outputs/tubingen_starry_scream.png
 111. https://raw.githubusercontent.com/jcjohnson/neural-style/master/examples/outputs/tubingen_scream_composition_vii.png
 112. https://raw.githubusercontent.com/jcjohnson/neural-style/master/examples/outputs/tubingen_starry_seated.png
 113. https://raw.githubusercontent.com/jcjohnson/neural-style/master/examples/outputs/tubingen_seated_nude_composition_vii.png
 114. https://raw.githubusercontent.com/jcjohnson/neural-style/master/examples/outputs/golden_gate_starry_scream_3_7.png
 115. https://raw.githubusercontent.com/jcjohnson/neural-style/master/examples/outputs/golden_gate_starry_scream_5_5.png
 116. https://raw.githubusercontent.com/jcjohnson/neural-style/master/examples/outputs/golden_gate_starry_scream_7_3.png
 117. http://blog.deepart.io/2016/06/04/color-independent-style-transfer/
 118. https://raw.githubusercontent.com/jcjohnson/neural-style/master/examples/outputs/tubingen_starry.png
 119. https://raw.githubusercontent.com/jcjohnson/neural-style/master/examples/outputs/tubingen_scream.png
 120. https://raw.githubusercontent.com/jcjohnson/neural-style/master/examples/outputs/tubingen_composition_vii.png
 121. https://raw.githubusercontent.com/jcjohnson/neural-style/master/examples/outputs/original_color/tubingen_starry.png
 122. https://raw.githubusercontent.com/jcjohnson/neural-style/master/examples/outputs/original_color/tubingen_scream.png
 123. https://raw.githubusercontent.com/jcjohnson/neural-style/master/examples/outputs/original_color/tubingen_composition_vii.png
 124. https://github.com/torch/torch7
 125. https://github.com/szagoruyko/loadcaffe
 126. https://github.com/torch/cunn
 127. https://github.com/soumith/cudnn.torch
 128. https://github.com/hughperkins/cltorch
 129. https://github.com/hughperkins/clnn
 130. https://gist.github.com/ksimonyan/3785162f95cd2d5fee77#file-readme-md
 131. https://github.com/bvlc/caffe/wiki/model-zoo
 132. https://drive.google.com/folderview?id=0b0iedyuunoqineftui1qnwvhvvu&usp=drive_web
 133. https://github.com/jcjohnson/neural-style/blob/master/install.md
 134. https://github.com/jcjohnson/neural-style/blob/master/examples/outputs/pitt_picasso_nin_opencl.png
 135. https://github.com/andersbll/neural_artistic_style
 136. https://github.com/soumith/cudnn.torch
 137. https://github.com/hughperkins/cltorch
 138. https://github.com/hughperkins/clnn
 139. https://cloud.githubusercontent.com/assets/1310570/9694690/fa8e8782-5328-11e5-9c91-11f7b215ad19.png
 140. https://arxiv.org/abs/1611.07865
 141. https://raw.githubusercontent.com/jcjohnson/neural-style/master/examples/outputs/starry_stanford_bigger.png
 142. https://github.com/jcjohnson/neural-style/blob/master/examples/multigpu_scripts/starry_stanford.sh
 143. https://github.com/site/terms
 144. https://github.com/site/privacy
 145. https://github.com/security
 146. https://githubstatus.com/
 147. https://help.github.com/
 148. https://github.com/contact
 149. https://github.com/pricing
 150. https://developer.github.com/
 151. https://training.github.com/
 152. https://github.blog/
 153. https://github.com/about
 154. https://github.com/jcjohnson/neural-style
 155. https://github.com/jcjohnson/neural-style

   hidden links:
 157. https://github.com/
 158. https://github.com/jcjohnson/neural-style
 159. https://github.com/jcjohnson/neural-style
 160. https://github.com/jcjohnson/neural-style
 161. https://help.github.com/articles/which-remote-url-should-i-use
 162. https://github.com/jcjohnson/neural-style#neural-style
 163. https://github.com/jcjohnson/neural-style#content--style-tradeoff
 164. https://github.com/jcjohnson/neural-style#style-scale
 165. https://github.com/jcjohnson/neural-style#multiple-style-images
 166. https://github.com/jcjohnson/neural-style#style-interpolation
 167. https://github.com/jcjohnson/neural-style#transfer-style-but-not-color
 168. https://github.com/jcjohnson/neural-style#setup
 169. https://github.com/jcjohnson/neural-style#usage
 170. https://github.com/jcjohnson/neural-style#frequently-asked-questions
 171. https://github.com/jcjohnson/neural-style#memory-usage
 172. https://github.com/jcjohnson/neural-style#speed
 173. https://github.com/jcjohnson/neural-style#multi-gpu-scaling
 174. https://github.com/jcjohnson/neural-style#implementation-details
 175. https://github.com/jcjohnson/neural-style#citation
 176. https://github.com/
