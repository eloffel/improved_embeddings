    #[1]id111 online    feed [2]id111 online    comments feed
   [3]id111 online    dive into nltk, part v: using stanford text
   analysis tools in python comments feed [4]dive into nltk, part iv:
   id30 and lemmatization [5]dive into nltk, part vi: add stanford
   word segmenter interface for python nltk [6]alternate [7]alternate

   [ins: :ins]

   [8]   



   javascript is disabled. please enable javascript on your browser to
   best view this site.

[9]id111 online

   search for: ____________________ search

id111 | text analysis | text process | natural language processing

   id111 online
     * [10]home
     * [11]textanalysis
     * [12]keywordextraction
     * [13]textsummarization
     * [14]wordsimilarity
     * [15]about

   [16]home   [17]id39   dive into nltk, part v: using
   stanford text analysis tools in python
   [ins: :ins]

post navigation

   [18]    dive into nltk, part iv: id30 and lemmatization
   [19]dive into nltk, part vi: add stanford word segmenter interface for
   python nltk    

dive into nltk, part v: using stanford text analysis tools in python

   posted on [20]september 7, 2014 by [21]textminermarch 26, 2017
   [22]deep learning specialization on coursera

   this is the fifth article in the series    [23]dive into nltk   , here is
   an index of all the articles in the series that have been published to
   date:
   [ins: :ins]

   [24]part i: getting started with nltk
   [25]part ii: sentence tokenize and word tokenize
   [26]part iii: part-of-speech tagging and pos tagger
   [27]part iv: id30 and lemmatization
   [28]part v: using stanford text analysis tools in python
   [29]part vi: add stanford word segmenter interface for python nltk
   [30]part vii: a preliminary study on text classification
   [31]part viii: using external maximum id178 modeling libraries for
   text classification
   [32]part ix: from text classification to id31
   [33]part x: play with id97 models based on nltk corpus

   we have already discussed    [34]how to use stanford named entity
   recognizer (ner) in python nltk and other programming languages   , and
   recently we have also tested the [35]stanford pos tagger and
   [36]stanford parser in nltk and used it in python. if you want use
   these stanford text analysis tools in other languages, you can use our
   [37]text analysis api which also integrated the stanford nlp tools in
   it. you can test it here on our [38]online text analysis demo: [39]text
   analysis online. now we will tell you how to use these java nlp tools
   in python nltk. you can also following the nltk official guide:
   [40]installing third party software   how nltk discovers third party
   software, here we test it in an ubuntu 12.04 vps.

   first you need set the java environment for those java [41]text
   analysis tools before you using them in nltk:

     sudo apt-get install default-jre
     this will install the java runtime environment (jre). if you instead
     need the java development kit (jdk), which is usually needed to
     compile java applications (for example apache ant, apache maven,
     eclipse and intellij idea execute the following command:

     sudo apt-get install default-jdk
     that is everything that is needed to install java.

   nltk now provides three interfaces for [42]stanford log-linear
   part-of-speech tagger, [43]stanford named entity recognizer (ner) and
   [44]stanford parser, following is the details about how to use them in
   nltk one by one.

   1) [45]stanford pos tagger

   following is from the official [46]stanford pos tagger website:

     a part-of-speech tagger (pos tagger) is a piece of software that
     reads text in some language and assigns parts of speech to each word
     (and other token), such as noun, verb, adjective, etc., although
     generally computational applications use more fine-grained pos tags
     like    noun-plural   .

     part-of-speech name abbreviations: the english taggers use the penn
     treebank tag set. here are some links to documentation of the penn
     treebank english pos tag set: 1993 computational linguistics article
     in pdf, amalgam page, aoife cahill   s list. see the included
     readme-models.txt in the models directory for more information about
     the tagsets for the other languages.

   we assumed you have installed the new version [47]nltk, here we use
   ipython and the nltk version is 3.0.0b1:

   in [1]: import nltk

   in [2]: nltk.__version__
   out[2]:    3.0.0b1   

   the stanford pos tagger official site provides two versions of pos
   tagger:

   [48]download basic english stanford tagger version 3.4.1 [21 mb]

   [49]download full stanford tagger version 3.4.1 [124 mb]

   we suggest you download the full version which contains a lot of
   models.

   after downloading the full version, unzip it and copy the related data
   in our test directory:

   mkdir postagger
   cd postagger/
   cp ../stanford-postagger-full-2014-08-27/stanford-postagger.jar .
   cp -r ../stanford-postagger-full-2014-08-27/models .
   ipython    pylab

   first test the english id52 result:

   in [1]: from nltk.tag.stanford import postagger

   in [2]: english_postagger =
   postagger(   models/english-bidirectional-distsim.tagger   ,
      stanford-postagger.jar   )

   in [3]: english_postagger.tag(   this is stanford postagger in nltk for
   python users   .split())
   out[3]:
   [(u   this   , u   dt   ),
   (u   is   , u   vbz   ),
   (u   stanford   , u   jj   ),
   (u   postagger   , u   nn   ),
   (u   in   , u   in   ),
   (u   nltk   , u   nn   ),
   (u   for   , u   in   ),
   (u   python   , u   nn   ),
   (u   users   , u   nns   )]

   then test the chinese id52 result:

   in [4]: chinese_postagger = postagger(   models/chinese-distsim.tagger   ,
      stanford-postagger.jar   , encoding=   utf-8   )

   in [5]: chinese_postagger.tag(               python                                       
         .split())
   out[5]:
   [(   , u   \u8fd9#pn   ),
   (   , u   \u662f#vc   ),
   (   , u   \u5728#p   ),
   (   , u   python#nn   ),
   (   , u   \u73af\u5883#nn   ),
   (   , u   \u4e2d#lc   ),
   (   , u   \u4f7f\u7528#vv   ),
   (   , u   \u65af\u5766\u798f#nr   ),
   (   , u   \u8bcd\u6027#jj   ),
   (   , u   \u6807\u6ce8\u5668#nn   )]

   the models contains a lot of pos tagger models, you can find the
   details info from the readme-models.txt:

     english taggers
                                
     wsj-0-18-bidirectional-distsim.tagger
     trained on wsj sections 0-18 using a bidirectional architecture and
     including word shape and distributional similarity features.
     id32 tagset.
     performance:
     97.28% correct on wsj 19-21
     (90.46% correct on unknown words)

     wsj-0-18-left3words.tagger
     trained on wsj sections 0-18 using the left3words architecture and
     includes word shape features. penn tagset.
     performance:
     96.97% correct on wsj 19-21
     (88.85% correct on unknown words)

     wsj-0-18-left3words-distsim.tagger
     trained on wsj sections 0-18 using the left3words architecture and
     includes word shape and distributional similarity features. penn
     tagset.
     performance:
     97.01% correct on wsj 19-21
     (89.81% correct on unknown words)

     english-left3words-distsim.tagger
     trained on wsj sections 0-18 and extra parser training data using
     the
     left3words architecture and includes word shape and distributional
     similarity features. penn tagset.

     english-bidirectional-distsim.tagger
     trained on wsj sections 0-18 using a bidirectional architecture and
     including word shape and distributional similarity features.
     id32 tagset.

     wsj-0-18-caseless-left3words-distsim.tagger
     trained on wsj sections 0-18 left3words architecture and includes
     word
     shape and distributional similarity features. penn tagset. ignores
     case.

     english-caseless-left3words-distsim.tagger
     trained on wsj sections 0-18 and extra parser training data using
     the
     left3words architecture and includes word shape and distributional
     similarity features. penn tagset. ignores case.

     chinese tagger
                                
     chinese-nodistsim.tagger
     trained on a combination of ctb7 texts from chinese and hong kong
     sources.
     ldc chinese treebank pos tag set.
     performance:
     93.46% on a combination of chinese and hong kong texts
     (79.40% on unknown words)

     chinese-distsim.tagger
     trained on a combination of ctb7 texts from chinese and hong kong
     sources with distributional similarity clusters.
     ldc chinese treebank pos tag set.
     performance:
     93.99% on a combination of chinese and hong kong texts
     (84.60% on unknown words)

     arabic tagger
                                
     arabic.tagger
     trained on the *entire* atb p1-3.
     when trained on the train part of the atb p1-3 split done for the
     2005
     jhu summer workshop (diab split), using (augmented) bies tags, it
     gets
     the following performance:
     96.26% on test portion according to diab split
     (80.14% on unknown words)

     french tagger
                                
     french.tagger
     trained on the french treebank.

     german tagger
                                
     german-hgc.tagger
     trained on the first 80% of the negra corpus, which uses the stts
     tagset.
     the stuttgart-t  bingen tagset (stts) is a set of 54 tags for
     annotating
     german text corpora with part-of-speech labels, which was jointly
     developed by the institut f  r maschinelle sprachverarbeitung of the
     university of stuttgart and the seminar f  r sprachwissenschaft of
     the
     university of t  bingen. see:
     http://www.ims.uni-stuttgart.de/projekte/cqpdemos/bundestag/help-tag
     set.html
     this model uses features from the distributional similarity clusters
     built over the hgc.
     performance:
     96.90% on the first half of the remaining 20% of the negra corpus
     (dev set)
     (90.33% on unknown words)

     german-dewac.tagger
     this model uses features from the distributional similarity clusters
     built from the dewac web corpus.

     german-fast.tagger
     lacks distributional similarity features, but is several times
     faster
     than the other alternatives.
     performance:
     96.61% overall / 86.72% unknown.

   2) [50]stanford named entity recognizer (ner)

   following introduction is from the official [51]stanford ner website:

     stanford ner is a java implementation of a named entity recognizer.
     id39 (ner) labels sequences of words in a text
     which are the names of things, such as person and company names, or
     gene and protein names. it comes with well-engineered feature
     extractors for id39, and many options for
     defining feature extractors. included with the download are good
     named entity recognizers for english, particularly for the 3 classes
     (person, organization, location), and we also make available on this
     page various other models for different languages and circumstances,
     including models trained on just the conll 2003 english training
     data. the distributional similarity features in some models improve
     performance but the models require considerably more memory.

   the website provides a download version of stanford ner:

   [52]download stanford named entity recognizer version 3.4.1

   it contains the stanford-ner.jar and models in the classifies
   directory, and like the stanford pos tagger, you can use it in nltk
   like this:

   in [1]: from nltk.tag.stanford import nertagger

   in [2]: english_nertagger =
   nertagger(   classifiers/english.all.3class.distsim.crf.ser.gz   ,
      stanford-ner.jar   )

   in [3]: english_nertagger.tag(   rami eid is studying at stony brook
   university in ny   .split())
   out[3]:
   [(u   rami   , u   person   ),
   (u   eid   , u   person   ),
   (u   is   , u   o   ),
   (u   studying   , u   o   ),
   (u   at   , u   o   ),
   (u   stony   , u   organization   ),
   (u   brook   , u   organization   ),
   (u   university   , u   organization   ),
   (u   in   , u   o   ),
   (u   ny   , u   o   )]

   the models included with stanford ner are a 4 class model trained for
   conll, a 7 class model trained for muc, and a 3 class model trained on
   both data sets for the intersection of those class sets.

   3 class: location, person, organization
   4 class: location, person, organization, misc
   7 class: time, location, organization, person, money, percent, date

   -rw-r   r   @ 1 textminer staff 24732086 9 7 11:43
   english.all.3class.distsim.crf.ser.gz
   -rw-r   r   @ 1 textminer staff 1274 9 7 11:43
   english.all.3class.distsim.prop
   -rw-r   r   @ 1 textminer staff 18350357 9 7 11:43
   english.conll.4class.distsim.crf.ser.gz
   -rw-r   r   @ 1 textminer staff 1421 9 7 11:43
   english.conll.4class.distsim.prop
   -rw-r   r   @ 1 textminer staff 17824631 9 7 11:43
   english.muc.7class.distsim.crf.ser.gz
   -rw-r   r   @ 1 textminer staff 1087 9 7 11:43
   english.muc.7class.distsim.prop
   -rw-r   r   @ 1 textminer staff 18954462 9 7 11:43
   english.nowiki.3class.distsim.crf.ser.gz
   -rw-r   r   @ 1 textminer staff 1218 9 7 11:43
   english.nowiki.3class.distsim.prop

   you can test the 7 class stanford ner on our [53]text analysis online
   demo: [54]nltk stanford named entity recognizer for 7class

   3    [55]stanford parser

   from the official [56]stanford parser introduction:

     a natural language parser is a program that works out the
     grammatical structure of sentences, for instance, which groups of
     words go together (as    phrases   ) and which words are the subject or
     object of a verb. probabilistic parsers use knowledge of language
     gained from hand-parsed sentences to try to produce the most likely
     analysis of new sentences. these statistical parsers still make some
     mistakes, but commonly work rather well. their development was one
     of the biggest breakthroughs in natural language processing in the
     1990s.

   you should download the stanford parser first: [57]download stanford
   parser version 3.4.1, then use it in the python by nltk:

   in [1]: from nltk.parse.stanford import stanfordparser

   in [3]: english_parser = stanfordparser(   stanford-parser.jar   ,
      stanford-parser-3.4-models.jar   )

   in [4]: english_parser.raw_parse_sents((   this is the english parser
   test   ,    the parser is from stanford parser   ))
   out[4]:
   [[u   this/dt is/vbz the/dt english/jj parser/nn test/nn   ],
   [u'(root   ,
   u    (s   ,
   u    (np (dt this))   ,
   u    (vp (vbz is)   ,
   u    (np (dt the) (jj english) (nn parser) (nn test)))))   ],
   [u   nsubj(test-6, this-1)   ,
   u   cop(test-6, is-2)   ,
   u   det(test-6, the-3)   ,
   u   amod(test-6, english-4)   ,
   u   nn(test-6, parser-5)   ,
   u   root(root-0, test-6)   ],
   [u   the/dt parser/nn is/vbz from/in stanford/jj parser/nn   ],
   [u'(root   ,
   u    (s   ,
   u    (np (dt the) (nn parser))   ,
   u    (vp (vbz is)   ,
   u    (pp (in from)   ,
   u    (np (jj stanford) (nn parser))))))   ],
   [u   det(parser-2, the-1)   ,
   u   nsubj(is-3, parser-2)   ,
   u   root(root-0, is-3)   ,
   u   amod(parser-6, stanford-5)   ,
   u   prep_from(is-3, parser-6)   ]]

   note that this is different from the default nltk
   nltk/parse/stanford.py, we modified some code, and output the tag,
   parse, and dependency result:

   #   -outputformat   ,    penn   , # original
      -outputformat   ,    wordsandtags,penn,typeddependencies   , # modified

   now you can use the stanford nlp tools like pos tagger, ner, and parser
   in python by nltk, just enjoy it.

   posted by [58]textminer

related posts:

    1. [59]text analysis online no longer provides nltk stanford nlp api
       interface
    2. [60]how to use stanford named entity recognizer (ner) in python
       nltk and other programming languages
    3. [61]dive into nltk, part iii: part-of-speech tagging and pos tagger
    4. [62]getting started with spacy

   [63]deep learning specialization on coursera

   posted in [64]id39, [65]nltk, [66]text analysis,
   [67]textanalysis api tagged [68]dependency parser, [69]named entity
   recognition, [70]id39 in python, [71]named entity
   recognizer, [72]ner, [73]nltk, [74]nltk stanford ner, [75]nltk stanford
   nlp tools, [76]nltk stanford parser, [77]nltk stanford pos tagger,
   [78]nltk stanford tagger, [79]parser in python, [80]pos tagger, [81]pos
   tagging, [82]stanford ner, [83]stanford ner for python, [84]stanford
   parser, [85]stanford parser for python, [86]stanford pos tagger,
   [87]stanford pos tagger for python [88]permalink

post navigation

   [89]    dive into nltk, part iv: id30 and lemmatization
   [90]dive into nltk, part vi: add stanford word segmenter interface for
   python nltk    
     __________________________________________________________________

comments

dive into nltk, part v: using stanford text analysis tools in python     7
comments

    1.
   brian on [91]june 9, 2015 at 3:15 pm said:
       have you figured out how to use the caseless version of the entity
       recognition? i downloaded
       [92]http://nlp.stanford.edu/software/stanford-ner-2015-04-20.zip
       and placed it in the site-packages folder of python. then i
       downloaded
       [93]http://nlp.stanford.edu/software/stanford-corenlp-caseless-2015
       -04-20-models.jar and placed it in the folder. then i ran this code
       in nltk
       from nltk.tag.stanford import nertagger
       english_nertagger =
       nertagger(   /home/anaconda/lib/python2.7/site-packages/stanford-ner-
       2015-04-20/classifiers/english.conll.4class.distsim.crf.ser.gz   ,
          /home/anaconda/lib/python2.7/site-packages/stanford-ner-2015-04-20
       /stanford-corenlp-caseless-2015-04-20-models.jar   )
       but when i run this:
       english_nertagger.tag(   rami eid is studying at stony brook
       university in ny   .split())
       i get an error:
       error: could not find or load main class
       edu.stanford.nlp.ie.crf.crfclassifier
       any help if you have experience is appreciated!
       thanks!
       [94]reply    
          +
        [95]clancy on [96]march 1, 2016 at 6:03 am said:
            i had some luck with this:
            stanpath =    c:\\users\\x\\stanford-ner-2014-08-27   
            stanfordnertagger(os.path.join(stanpath,   classifiers\\english.
            all.3class.distsim.crf.ser.gz   ),
            path_to_jar = os.path.join(stanpath,   stanford-ner.jar   ))
            after unzipping to the stanpath folder
            [97]reply    
               o
             [98]clancy on [99]march 1, 2016 at 6:58 am said:
                 then i did this:
                 os.environ[   javahome   ]=   c:\\program files
                 (x86)\\java\\jre1.8.0_73\\bin\\java.exe   
                 [100]reply    
    2.
   [101]clancy on [102]march 1, 2016 at 5:32 am said:
       brilliant walk throughs!!!
       thanks a bunch.
       [103]reply    
    3.
   [104]rahul on [105]september 18, 2016 at 5:19 am said:
       there seems to have been some renaming over the time.
       from nltk.tag.stanford import postagger
       may not work as it happened with me.
       instead try
       from nltk.tag.stanford import stanfordpostagger
       [106]reply    
    4.
   vivek on [107]september 30, 2016 at 6:01 am said:
       hi,
       i am trying to make domain specific ner , so how should i start,can
       somone suggest..
       [108]reply    
    5.
   bruno on [109]april 24, 2017 at 12:12 am said:
       how can i get this output in nltk current
          -outputformat   ,    wordsandtags,penn,typeddependencies   , # modified
       ?
       [110]reply    

leave a reply [111]cancel reply

   your email address will not be published. required fields are marked *

   comment
   _____________________________________________
   _____________________________________________
   _____________________________________________
   _____________________________________________
   _____________________________________________
   _____________________________________________
   _____________________________________________
   _____________________________________________

   name * ______________________________

   email * ______________________________

   website ______________________________

   [ ] save my name, email, and website in this browser for the next time
   i comment.

   post comment

   [112][dlai-logo-final-minus-font-plus-white-backg.png]
   [show?id=9iqcvd3eeqc&bids=541296.11421701896&type=2&subid=0]

   search for: ____________________ search

   [ins: :ins]

recent posts

     * [113]deep learning practice for nlp: large movie review data
       id31 from scratch
     * [114]best coursera courses for data science
     * [115]best coursera courses for machine learning
     * [116]best coursera courses for deep learning
     * [117]dive into nlp with deep learning, part i: getting started with
       dl4nlp

recent comments

     * textminer on [118]training id97 model on english wikipedia by
       gensim
     * ankit ramani on [119]training id97 model on english wikipedia
       by gensim
     * vincent on [120]training id97 model on english wikipedia by
       gensim
     * muhammad amin nadim on [121]andrew ng deep learning specialization:
       best deep learning course for beginners and deep learners
     * saranya on [122]training id97 model on english wikipedia by
       gensim

archives

     * [123]november 2018
     * [124]august 2018
     * [125]july 2018
     * [126]june 2018
     * [127]january 2018
     * [128]october 2017
     * [129]september 2017
     * [130]august 2017
     * [131]july 2017
     * [132]may 2017
     * [133]april 2017
     * [134]march 2017
     * [135]december 2016
     * [136]october 2016
     * [137]august 2016
     * [138]july 2016
     * [139]june 2016
     * [140]may 2016
     * [141]april 2016
     * [142]february 2016
     * [143]december 2015
     * [144]november 2015
     * [145]september 2015
     * [146]may 2015
     * [147]april 2015
     * [148]march 2015
     * [149]february 2015
     * [150]january 2015
     * [151]december 2014
     * [152]november 2014
     * [153]october 2014
     * [154]september 2014
     * [155]july 2014
     * [156]june 2014
     * [157]may 2014
     * [158]april 2014
     * [159]january 2014

categories

     * [160]ainlp
     * [161]coursera course
     * [162]data science
     * [163]deep learning
     * [164]dl4nlp
     * [165]how to use mashape api
     * [166]keras
     * [167]machine learning
     * [168]id39
     * [169]nlp
     * [170]nlp tools
     * [171]nltk
     * [172]id31
     * [173]tensorflow
     * [174]text analysis
     * [175]text classification
     * [176]id111
     * [177]text processing
     * [178]text similarity
     * [179]text summarization
     * [180]textanalysis api
     * [181]uncategorized
     * [182]id27
     * [183]id40

meta

     * [184]log in
     * [185]entries rss
     * [186]comments rss
     * [187]wordpress.org

     [188]text analysis online

     [189]text summarizer

     [190]text processing

     [191]word similarity

     [192]best coursera course

     [193]best coursera courses

     [194]elastic patent

     2019 - [195]id111 online - [196]weaver xtreme theme

   [197]   

references

   visible links
   1. https://textminingonline.com/feed
   2. https://textminingonline.com/comments/feed
   3. https://textminingonline.com/dive-into-nltk-part-v-using-stanford-text-analysis-tools-in-python/feed
   4. https://textminingonline.com/dive-into-nltk-part-iv-id30-and-lemmatization
   5. https://textminingonline.com/dive-into-nltk-part-vi-add-stanford-word-segmenter-interface-for-python-nltk
   6. https://textminingonline.com/wp-json/oembed/1.0/embed?url=https://textminingonline.com/dive-into-nltk-part-v-using-stanford-text-analysis-tools-in-python
   7. https://textminingonline.com/wp-json/oembed/1.0/embed?url=https://textminingonline.com/dive-into-nltk-part-v-using-stanford-text-analysis-tools-in-python&format=xml
   8. https://textminingonline.com/dive-into-nltk-part-v-using-stanford-text-analysis-tools-in-python#page-bottom
   9. https://textminingonline.com/
  10. https://textminingonline.com/
  11. http://textanalysisonline.com/#new_tab
  12. http://keywordextraction.net/#new_tab
  13. http://textsummarization.net/#new_tab
  14. https://wordsimilarity.com/#new_tab
  15. https://textminingonline.com/about
  16. https://textminingonline.com/
  17. https://textminingonline.com/category/named-entity-recognition
  18. https://textminingonline.com/dive-into-nltk-part-iv-id30-and-lemmatization
  19. https://textminingonline.com/dive-into-nltk-part-vi-add-stanford-word-segmenter-interface-for-python-nltk
  20. https://textminingonline.com/dive-into-nltk-part-v-using-stanford-text-analysis-tools-in-python
  21. https://textminingonline.com/author/yuzhen
  22. https://click.linksynergy.com/fs-bin/click?id=9iqcvd3eeqc&offerid=467035.416&subid=0&type=4
  23. http://textminingonline.com/dive-into-nltk-part-i-getting-started-with-nltk
  24. http://textminingonline.com/dive-into-nltk-part-i-getting-started-with-nltk
  25. http://textminingonline.com/dive-into-nltk-part-ii-sentence-tokenize-and-word-tokenize
  26. http://textminingonline.com/dive-into-nltk-part-iii-part-of-speech-tagging-and-pos-tagger
  27. http://textminingonline.com/dive-into-nltk-part-iv-id30-and-lemmatization
  28. http://textminingonline.com/dive-into-nltk-part-v-using-stanford-text-analysis-tools-in-python
  29. http://textminingonline.com/dive-into-nltk-part-vi-add-stanford-word-segmenter-interface-for-python-nltk
  30. http://textminingonline.com/dive-into-nltk-part-vii-a-preliminary-study-on-text-classification
  31. http://textminingonline.com/dive-into-nltk-part-viii-using-external-maximum-id178-modeling-libraries-for-text-classification
  32. http://textminingonline.com/dive-into-nltk-part-ix-from-text-classification-to-sentiment-analysis
  33. http://textminingonline.com/?p=872
  34. http://textminingonline.com/how-to-use-stanford-named-entity-recognizer-ner-in-python-nltk-and-other-programming-languages
  35. http://textanalysisonline.com/nltk-stanford-postagger
  36. http://textanalysisonline.com/nltk-stanford-parser
  37. http://textanalysisonline.com/
  38. http://textanalysisonline.com/
  39. http://textanalysisonline.com/
  40. https://github.com/nltk/nltk/wiki/installing-third-party-software
  41. http://textanalysisonline.com/
  42. http://nlp.stanford.edu/software/tagger.shtml
  43. http://nlp.stanford.edu/software/crf-ner.shtml
  44. http://nlp.stanford.edu/software/lex-parser.shtml
  45. http://textanalysisonline.com/nltk-stanford-postagger
  46. http://nlp.stanford.edu/software/tagger.shtml
  47. https://github.com/nltk/nltk
  48. http://nlp.stanford.edu/software/stanford-postagger-2014-08-27.zip
  49. http://nlp.stanford.edu/software/stanford-postagger-full-2014-08-27.zip
  50. http://textanalysisonline.com/nltk-stanford-ner
  51. http://nlp.stanford.edu/software/crf-ner.shtml
  52. http://nlp.stanford.edu/software/stanford-ner-2014-08-27.zip
  53. http://textanalysisonline.com/
  54. http://textanalysisonline.com/nltk-stanford-ner-7class
  55. http://textanalysisonline.com/nltk-stanford-parser
  56. http://nlp.stanford.edu/software/lex-parser.shtml
  57. http://nlp.stanford.edu/software/stanford-parser-full-2014-08-27.zip
  58. http://textminingonline.com/
  59. https://textminingonline.com/text-analysis-online-no-longer-provides-nltk-stanford-nlp-api-interface
  60. https://textminingonline.com/how-to-use-stanford-named-entity-recognizer-ner-in-python-nltk-and-other-programming-languages
  61. https://textminingonline.com/dive-into-nltk-part-iii-part-of-speech-tagging-and-pos-tagger
  62. https://textminingonline.com/getting-started-with-spacy
  63. https://click.linksynergy.com/fs-bin/click?id=9iqcvd3eeqc&offerid=467035.414&subid=0&type=4
  64. https://textminingonline.com/category/named-entity-recognition
  65. https://textminingonline.com/category/nltk
  66. https://textminingonline.com/category/text-analysis
  67. https://textminingonline.com/category/textanalysis-api-2
  68. https://textminingonline.com/tag/dependency-parser
  69. https://textminingonline.com/tag/named-entity-recognition
  70. https://textminingonline.com/tag/named-entity-recognition-in-python
  71. https://textminingonline.com/tag/named-entity-recognizer
  72. https://textminingonline.com/tag/ner
  73. https://textminingonline.com/tag/nltk
  74. https://textminingonline.com/tag/nltk-stanford-ner
  75. https://textminingonline.com/tag/nltk-stanford-nlp-tools
  76. https://textminingonline.com/tag/nltk-stanford-parser
  77. https://textminingonline.com/tag/nltk-stanford-pos-tagger
  78. https://textminingonline.com/tag/nltk-stanford-tagger
  79. https://textminingonline.com/tag/parser-in-python
  80. https://textminingonline.com/tag/pos-tagger
  81. https://textminingonline.com/tag/pos-tagging
  82. https://textminingonline.com/tag/stanford-ner
  83. https://textminingonline.com/tag/stanford-ner-for-python
  84. https://textminingonline.com/tag/stanford-parser
  85. https://textminingonline.com/tag/stanford-parser-for-python
  86. https://textminingonline.com/tag/stanford-pos-tagger
  87. https://textminingonline.com/tag/stanford-pos-tagger-for-python
  88. https://textminingonline.com/dive-into-nltk-part-v-using-stanford-text-analysis-tools-in-python
  89. https://textminingonline.com/dive-into-nltk-part-iv-id30-and-lemmatization
  90. https://textminingonline.com/dive-into-nltk-part-vi-add-stanford-word-segmenter-interface-for-python-nltk
  91. https://textminingonline.com/dive-into-nltk-part-v-using-stanford-text-analysis-tools-in-python#comment-97093
  92. http://nlp.stanford.edu/software/stanford-ner-2015-04-20.zip
  93. http://nlp.stanford.edu/software/stanford-corenlp-caseless-2015-04-20-models.jar
  94. https://textminingonline.com/dive-into-nltk-part-v-using-stanford-text-analysis-tools-in-python?replytocom=97093#respond
  95. http://griffith.edu.au/
  96. https://textminingonline.com/dive-into-nltk-part-v-using-stanford-text-analysis-tools-in-python#comment-117694
  97. https://textminingonline.com/dive-into-nltk-part-v-using-stanford-text-analysis-tools-in-python?replytocom=117694#respond
  98. http://griffith.edu.au/
  99. https://textminingonline.com/dive-into-nltk-part-v-using-stanford-text-analysis-tools-in-python#comment-117695
 100. https://textminingonline.com/dive-into-nltk-part-v-using-stanford-text-analysis-tools-in-python?replytocom=117695#respond
 101. http://griffith.edu.au/
 102. https://textminingonline.com/dive-into-nltk-part-v-using-stanford-text-analysis-tools-in-python#comment-117693
 103. https://textminingonline.com/dive-into-nltk-part-v-using-stanford-text-analysis-tools-in-python?replytocom=117693#respond
 104. http://tekplore.blogspot.in/
 105. https://textminingonline.com/dive-into-nltk-part-v-using-stanford-text-analysis-tools-in-python#comment-122268
 106. https://textminingonline.com/dive-into-nltk-part-v-using-stanford-text-analysis-tools-in-python?replytocom=122268#respond
 107. https://textminingonline.com/dive-into-nltk-part-v-using-stanford-text-analysis-tools-in-python#comment-122762
 108. https://textminingonline.com/dive-into-nltk-part-v-using-stanford-text-analysis-tools-in-python?replytocom=122762#respond
 109. https://textminingonline.com/dive-into-nltk-part-v-using-stanford-text-analysis-tools-in-python#comment-130308
 110. https://textminingonline.com/dive-into-nltk-part-v-using-stanford-text-analysis-tools-in-python?replytocom=130308#respond
 111. https://textminingonline.com/dive-into-nltk-part-v-using-stanford-text-analysis-tools-in-python#respond
 112. https://click.linksynergy.com/link?id=9iqcvd3eeqc&offerid=541296.11421701896&type=2&murl=https://www.coursera.org/specializations/deep-learning
 113. https://textminingonline.com/deep-learning-practice-for-nlp-large-movie-review-data-sentiment-analysis-from-scratch
 114. https://textminingonline.com/best-coursera-courses-for-data-science
 115. https://textminingonline.com/best-coursera-courses-for-machine-learning
 116. https://textminingonline.com/best-coursera-courses-for-deep-learning
 117. https://textminingonline.com/dive-into-nlp-with-deep-learning-part-i-getting-started-with-dl4nlp
 118. https://textminingonline.com/training-id97-model-on-english-wikipedia-by-gensim#comment-138841
 119. https://textminingonline.com/training-id97-model-on-english-wikipedia-by-gensim#comment-138807
 120. https://textminingonline.com/training-id97-model-on-english-wikipedia-by-gensim#comment-138723
 121. https://textminingonline.com/andrew-ng-deep-learning-specialization-best-deep-learning-course-for-beginners-and-deep-learners#comment-138475
 122. https://textminingonline.com/training-id97-model-on-english-wikipedia-by-gensim#comment-137923
 123. https://textminingonline.com/2018/11
 124. https://textminingonline.com/2018/08
 125. https://textminingonline.com/2018/07
 126. https://textminingonline.com/2018/06
 127. https://textminingonline.com/2018/01
 128. https://textminingonline.com/2017/10
 129. https://textminingonline.com/2017/09
 130. https://textminingonline.com/2017/08
 131. https://textminingonline.com/2017/07
 132. https://textminingonline.com/2017/05
 133. https://textminingonline.com/2017/04
 134. https://textminingonline.com/2017/03
 135. https://textminingonline.com/2016/12
 136. https://textminingonline.com/2016/10
 137. https://textminingonline.com/2016/08
 138. https://textminingonline.com/2016/07
 139. https://textminingonline.com/2016/06
 140. https://textminingonline.com/2016/05
 141. https://textminingonline.com/2016/04
 142. https://textminingonline.com/2016/02
 143. https://textminingonline.com/2015/12
 144. https://textminingonline.com/2015/11
 145. https://textminingonline.com/2015/09
 146. https://textminingonline.com/2015/05
 147. https://textminingonline.com/2015/04
 148. https://textminingonline.com/2015/03
 149. https://textminingonline.com/2015/02
 150. https://textminingonline.com/2015/01
 151. https://textminingonline.com/2014/12
 152. https://textminingonline.com/2014/11
 153. https://textminingonline.com/2014/10
 154. https://textminingonline.com/2014/09
 155. https://textminingonline.com/2014/07
 156. https://textminingonline.com/2014/06
 157. https://textminingonline.com/2014/05
 158. https://textminingonline.com/2014/04
 159. https://textminingonline.com/2014/01
 160. https://textminingonline.com/category/ainlp
 161. https://textminingonline.com/category/coursera-course
 162. https://textminingonline.com/category/data-science
 163. https://textminingonline.com/category/deep-learning
 164. https://textminingonline.com/category/dl4nlp
 165. https://textminingonline.com/category/how-to-use-mashape-api
 166. https://textminingonline.com/category/keras
 167. https://textminingonline.com/category/machine-learning
 168. https://textminingonline.com/category/named-entity-recognition
 169. https://textminingonline.com/category/nlp
 170. https://textminingonline.com/category/nlp-tools
 171. https://textminingonline.com/category/nltk
 172. https://textminingonline.com/category/sentiment-analysis
 173. https://textminingonline.com/category/tensorflow
 174. https://textminingonline.com/category/text-analysis
 175. https://textminingonline.com/category/text-classification
 176. https://textminingonline.com/category/text-mining
 177. https://textminingonline.com/category/text-processing
 178. https://textminingonline.com/category/text-similarity
 179. https://textminingonline.com/category/text-summarization
 180. https://textminingonline.com/category/textanalysis-api-2
 181. https://textminingonline.com/category/uncategorized
 182. https://textminingonline.com/category/word-embedding
 183. https://textminingonline.com/category/word-segmentation
 184. https://textminingonline.com/wp-login.php
 185. https://textminingonline.com/feed
 186. https://textminingonline.com/comments/feed
 187. https://wordpress.org/
 188. http://textanalysisonline.com/
 189. http://textsummarization.net/
 190. http://textprocessing.org/
 191. http://wordsimilarity.com/
 192. https://bestcourseracourse.com/
 193. https://bestcourseracourses.com/
 194. https://elasticpatent.com/
 195. https://textminingonline.com/
 196. https://weavertheme.com/
 197. https://textminingonline.com/dive-into-nltk-part-v-using-stanford-text-analysis-tools-in-python#page-top

   hidden links:
 199. https://wordpress.org/
