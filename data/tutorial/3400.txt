   #[1]the intelligence of information    feed [2]the intelligence of
   information    comments feed [3]the intelligence of information   
   sequence to sequence learning with convolutional neural networks
   comments feed [4]blockchain technology secured by quantum mechanics
   (digital distributed asset) [5]interruption of the normal posts
   scheduling [6]alternate [7]alternate [8]the intelligence of information
   [9]wordpress.com

   [10]skip to content

[11]the intelligence of information

all about information technology, computer science and data science

   [12]june 9, 2017june 9, 2017 [13]edgar press blogs

sequence to sequence learning with convolutional neural networks

   a team of researchers from facebook ai research released an interesting
   paper about sequence to sequence learning with convolutional neural
   networks (id98s). id98s has been mainly used in id161
   implementations, being a state-of-the-art stack for the  the researche
   and development in object recognition or image recognition. less often
   have id98s been implemented for machine translation or speech
   recognition. the paper we review here for [14]the intelligence of
   information is one such study about implementation of id98s to machine
   translation, especially the case of sequence to sequence learning of
   parts of speech in machine translation that are usually performed with
   recurrent neural networks (id56s), namely long-short term memory
   (lstms).


   indeed from the abstract we already learn that the authors claim to
   outperform the accuracy of deep lstms  in wmt   14 english-german and
   wmt   14 english-french translation at an order of magnitude faster
   speed, both on gpu and cpu.


   the success of id56s in machine translation tasks, id103
   and text summarization have been attributed to an encoding-decoding
   scheme of the input sequence with a series of bi-directional recurrent
   neural networks that generates a variable length output with another
   set of decoders id56s. this bi-directional stack is integrated with an
   interface via a soft-attention mechanism. such scheme have
   ouptperformed traditional phrase-based models by large margins.


   convolutional neural networks could also be implemented for sequence
   modelling given that there are some advantages in so doing. but they
   are less common.


[15]convolutional sequence to sequence learning



     compared to recurrent layers, convolutions create representations
     for fixed size contexts, however, the effective context size of the
     network can easily be made larger by stacking several layers on top
     of each other. this allows to precisely control the maximum length
     of dependencies to be modeled. convolutional networks do not depend
     on the computations of the previous time step and therefore allow
     parallelization over every element in a sequence. this contrasts
     with id56s which maintain a hidden state of the entire past that
     prevents parallel computation within a sequence.


   and the hierarchical representaion of multi-layered convolutional
   neural networks, whereby the layers of different levels interact with
   each other over the input sequence, provide a way for this hierarchical
   structure to capture long-range dependencies compared with the chain
   structure of recurrent neural networks, that is, the feature
   representation capturing relationships within a window of n words can
   be obtained by a less than linear computational complexity o(n/k),
   whereas id56s performs with linear computational complexity o(n).


     hierarchical structure provides a shorter path to capture long-range
     dependencies compared to the chain structure modeled by recurrent
     networks, e.g. we can obtain a feature representation capturing
     relationships within a window of n words applying only o(n/k)
     convolutional operations for a kernel of width k, compared to linear
     number o(n) for recurrent neural networks. inputs to a convolutional
     network are fed through a constant number of kernels and
     non-linearities, whereas recurrent networks apply up to n operations
     and non-linearities to the first word and only a single set of
     operations to the last word. fixing the number of nonlinearities
     applied to the inputs also eases learning.


   the source-code and the models for this research can be accessed in
   [16]this github repository.  one important aspects worth to mention in
   this paper concerns the use of gated linear units which eases the
   gradient propagation (with backprop this is an interesting
   methodological setup) and the fact that each decoder layer is equiped
   with a separate attention module.


     in this paper we propose an architecture for sequence to sequence
     modeling that is entirely convolutional. our model is equipped with
     gated linear units (dauphin et al., 2016) and residual connections
     (he et al., 2015a). we also use attention in every decoder layer and
     demonstrate that each attention layer only adds a negligible amount
     of overhead. the combination of these choices enables us to tackle
     largescale problems (  3).


   the paragraph below describes the preformance of this setup. the units
   printed (id7) affords a further scrutiny by the interested and more
   technical readership. noteworthy is also how this model can translate
   unseen sentences at an order of magnitude faster speed:


     we evaluate our approach on several large datasets for machine
     translation as well as summarization and compare to the current best
     architectures reported in the literature. on wmt   16 english-romanian
     translation we achieve a new state of the art, outperforming the
     previous best result by 1.8 id7. on wmt   14 english-german we
     outperform the strong lstm setup of wu et al. (2016) by 0.5 id7 and
     on wmt   14 english-french we outperform the likelihood trained system
     of wu et al. (2016) by 1.5 id7. furthermore, our model can
     translate unseen sentences at an order of magnitude faster speed
     than wu et al. (2016) on gpu and cpu hardware (  4,   5).


   how did the former recurrent neural network sequence to sequence
   modeling worked?:


     sequence to sequence modeling has been synonymous with recurrent
     neural network based encoder-decoder architectures (sutskever et
     al., 2014; bahdanau et al., 2014). the encoder id56 processes an
     input sequence x = (x1, . . . , xm) of m elements and returns state
     representations z = (z1. . . . , zm). the decoder id56 takes z and
     generates the output sequence y = (y1, . . . , yn) left to right,
     one element at a time. to generate output yi+1, the decoder computes
     a new hidden state hi+1 based on the previous state hi , an
     embedding gi of the previous target language word yi, as well as a
     conditional input ci derived from the encoder output z. based on
     this generic formulation, various encoder-decoder architectures have
     been proposed, which differ mainly in the conditional input and the
     type of id56.


   the models with attention compute a weighted sum over the (z1,   .,
   zms) representations at each time step.


     the weights of the sum are referred to as attention scores and allow
     the network to focus on different parts of the input sequence as it
     generates the output sequences. attention scores are computed by
     essentially comparing each encoder state zj to a combination of the
     previous decoder state hi and the last prediction yi; the result is
     normalized to be a distribution over input elements.

     popular choices for recurrent networks in encoder-decoder models are
     long short term memory networks (lstm; hochreiter & schmidhuber,
     1997) and id149 (gru; cho et al., 2014). both extend
     elman id56s (elman, 1990) with a gating mechanism that allows the
     memorization of information from previous time steps in order to
     model long-term dependencies. most recent approachesalso rely on
     bi-directional encoders to build representations of both past and
     future contexts (bahdanau et al., 2014; zhou et al., 2016; wu et
     al., 2016). models with many layers often rely on shortcut or
     residual connections (he et al., 2015a; zhou et al., 2016; wu et
     al., 2016).



the convolutional approach to sequence to sequence modeling


   the convolutional approach relies in a fully id98 architecture. this
   substitutes the id56s in computing the intermediate encoder states z and
   decoder states h. the architecture of the id98 used in this research is
   equiped with input elements is a distributional space and a strong
   sense of position by the introduction of a vector of position
   embeddings:


     first, we embed input elements x = (x1, . . . , xm) in
     distributional space as w = (w1, . .. , wm), where wj     r  f is a
     column in an embedding matrix d     r v   f. we also equip our model
     with a sense of order by embedding the absolute position of input
     elements p = (p1, . . . , pm) where pj     r  f. both are combined to
     obtain input element representations e = (w1 + p1, . . . , wm + pm).
     we proceed similarly for output elements that were already generated
     by the decoder network to yield output element representations that
     are being fed back into the decoder network g = (g1, . . ., gn).
     position embeddings are useful in our architecture since they give
     our model a sense of which portion of the sequence in the input or
     output it is currently dealing with (  5.4).


   the block structure of this convolutional neural network i a simple
   one. it computes intermediate states based on a fixed number of input
   elements. each block contains a one-dimensional convolution followed by
   a non-linearity. the non-linearites chosen in this research were the
   so-called gated linear units (glus). they impplement a simple gating
   mechanism over the output of the convolution:

   i will have to finish this post now. unfortunately some technical
   problems appeared unexpectedely. i encourage the readers to fully
   disclose the rest if the paper, which is recommended for the
   exoeriemtsl details and the overall results of the comparsison between
   the id98 and id56 approach to sequence to sequence learning and modeling.


   advertisements

share this:

     * [17]twitter
     * [18]facebook
     * [19]more
     *

     * [20]linkedin
     *

like this:

   like loading...

related

   posted in [21]artificial intelligence, [22]id158s,
   [23]computer science, [24]convolutional neural networks, [25]data
   science, [26]deep learning, [27]deep neural networks, [28]gated
   recurrent units, [29]information retrieval, [30]ltsm, [31]machine
   learning, [32]multilayer networks, [33]natural language processing,
   [34]recurrent neural networkstagged [35]convolutional neural
   networks[36]leave a comment

post navigation

   [37]previous postblockchain technology secured by quantum mechanics
   (digital distributed asset)[38]next postinterruption of the normal
   posts scheduling

leave a reply [39]cancel reply

   enter your comment here...

   ____________________________________________________________
   ____________________________________________________________
   ____________________________________________________________
   ____________________________________________________________

   fill in your details below or click an icon to log in:
     *
     *
     *

       iframe: [40]googleplus-sign-in

     *
     *

   [41]gravatar
   email (required) (address never made public)
   ____________________
   name (required)
   ____________________
   website
   ____________________
   wordpress.com logo

   you are commenting using your wordpress.com account. ( [42]log out /
   [43]change )
   google photo

   you are commenting using your google account. ( [44]log out /
   [45]change )
   twitter picture

   you are commenting using your twitter account. ( [46]log out /
   [47]change )
   facebook photo

   you are commenting using your facebook account. ( [48]log out /
   [49]change )
   [50]cancel

   connecting to %s

   [ ] notify me of new comments via email.

   post comment

nuno edgar nunes fernandes

     * [51]edgar press blogs
          + [52]inverse planning and theory of mind: understanding
            behavior in groups of agents
          + [53]state-of-the-art in self-driving cars and autonomous
            vehicles: a list of videos from mit
          + [54]paper with code series: semantic image synthesis with
            spatially-adaptive id172

the intelligence of information

   search for: ____________________ search

recent posts

     * [55]inverse planning and theory of mind: understanding behavior in
       groups of agents
     * [56]state-of-the-art in self-driving cars and autonomous vehicles:
       a list of videos from mit
     * [57]paper with code series: semantic image synthesis with
       spatially-adaptive id172
     * [58]from the import ai blog: a vision-based high speed driving with
       a deep dynamic observer or how self-driving cars will
       drive off-roads
     * [59]papers with code series: gan dissection or visualizing and
       understanding id3

meta

     * [60]register
     * [61]log in
     * [62]entries rss
     * [63]comments rss
     * [64]wordpress.com

archives

     * [65]april 2019
     * [66]march 2019
     * [67]december 2018
     * [68]november 2018
     * [69]october 2018
     * [70]september 2018
     * [71]august 2018
     * [72]june 2018
     * [73]may 2018
     * [74]january 2018
     * [75]july 2017
     * [76]june 2017
     * [77]may 2017
     * [78]april 2017
     * [79]march 2017
     * [80]february 2017
     * [81]january 2017
     * [82]december 2016
     * [83]november 2016
     * [84]october 2016
     * [85]september 2016
     * [86]july 2016
     * [87]june 2016
     * [88]may 2016
     * [89]april 2016
     * [90]february 2016
     * [91]december 2015
     * [92]october 2015

recent comments

   [93]edgar press blogs on [94]financial portfolio management   
   john smith on [95]financial portfolio management   
   [96]deep reinforcement l    on [97]papers with code series: reinf   
   [98]edgar press blogs on [99]papers with code series: self-   
   john regano on [100]papers with code series: self-   
   advertisements

   search for: ____________________ search

recent posts

     * [101]inverse planning and theory of mind: understanding behavior in
       groups of agents
     * [102]state-of-the-art in self-driving cars and autonomous vehicles:
       a list of videos from mit
     * [103]paper with code series: semantic image synthesis with
       spatially-adaptive id172
     * [104]from the import ai blog: a vision-based high speed driving
       with a deep dynamic observer or how self-driving cars will
       drive off-roads
     * [105]papers with code series: gan dissection or visualizing and
       understanding id3

recent comments

   [106]edgar press blogs on [107]financial portfolio management   
   john smith on [108]financial portfolio management   
   [109]deep reinforcement l    on [110]papers with code series: reinf   
   [111]edgar press blogs on [112]papers with code series: self-   
   john regano on [113]papers with code series: self-   

archives

     * [114]april 2019
     * [115]march 2019
     * [116]december 2018
     * [117]november 2018
     * [118]october 2018
     * [119]september 2018
     * [120]august 2018
     * [121]june 2018
     * [122]may 2018
     * [123]january 2018
     * [124]july 2017
     * [125]june 2017
     * [126]may 2017
     * [127]april 2017
     * [128]march 2017
     * [129]february 2017
     * [130]january 2017
     * [131]december 2016
     * [132]november 2016
     * [133]october 2016
     * [134]september 2016
     * [135]july 2016
     * [136]june 2016
     * [137]may 2016
     * [138]april 2016
     * [139]february 2016
     * [140]december 2015
     * [141]october 2015

meta

     * [142]register
     * [143]log in
     * [144]entries rss
     * [145]comments rss
     * [146]wordpress.com

   [147]wordpress.com.

   close and accept privacy & cookies: this site uses cookies. by
   continuing to use this website, you agree to their use.
   to find out more, including how to control cookies, see here:
   [148]cookie policy

   iframe: [149]likes-master

   %d bloggers like this:

references

   visible links
   1. https://theintelligenceofinformation.wordpress.com/feed/
   2. https://theintelligenceofinformation.wordpress.com/comments/feed/
   3. https://theintelligenceofinformation.wordpress.com/2017/06/09/sequence-to-sequence-learning-with-convolutional-neural-networks/feed/
   4. https://theintelligenceofinformation.wordpress.com/2017/06/08/blockchain-technology-secured-by-quantum-mechanics-digital-distributed-asset/
   5. https://theintelligenceofinformation.wordpress.com/2017/06/12/interruption-of-the-normal-posts-scheduling/
   6. https://public-api.wordpress.com/oembed/?format=json&url=https://theintelligenceofinformation.wordpress.com/2017/06/09/sequence-to-sequence-learning-with-convolutional-neural-networks/&for=wpcom-auto-discovery
   7. https://public-api.wordpress.com/oembed/?format=xml&url=https://theintelligenceofinformation.wordpress.com/2017/06/09/sequence-to-sequence-learning-with-convolutional-neural-networks/&for=wpcom-auto-discovery
   8. https://theintelligenceofinformation.wordpress.com/osd.xml
   9. https://s1.wp.com/opensearch.xml
  10. https://theintelligenceofinformation.wordpress.com/2017/06/09/sequence-to-sequence-learning-with-convolutional-neural-networks/#content
  11. https://theintelligenceofinformation.wordpress.com/
  12. https://theintelligenceofinformation.wordpress.com/2017/06/09/sequence-to-sequence-learning-with-convolutional-neural-networks/
  13. https://theintelligenceofinformation.wordpress.com/author/edgarventurescreative/
  14. https://theintelligenceofinformation.wordpress.com/
  15. https://arxiv.org/pdf/1705.03122.pdf
  16. https://github.com/facebookresearch/fairseq
  17. https://theintelligenceofinformation.wordpress.com/2017/06/09/sequence-to-sequence-learning-with-convolutional-neural-networks/?share=twitter
  18. https://theintelligenceofinformation.wordpress.com/2017/06/09/sequence-to-sequence-learning-with-convolutional-neural-networks/?share=facebook
  19. https://theintelligenceofinformation.wordpress.com/2017/06/09/sequence-to-sequence-learning-with-convolutional-neural-networks/
  20. https://theintelligenceofinformation.wordpress.com/2017/06/09/sequence-to-sequence-learning-with-convolutional-neural-networks/?share=linkedin
  21. https://theintelligenceofinformation.wordpress.com/category/artificial-intelligence/
  22. https://theintelligenceofinformation.wordpress.com/category/artificial-neural-networks/
  23. https://theintelligenceofinformation.wordpress.com/category/computer-science/
  24. https://theintelligenceofinformation.wordpress.com/tag/convolutional-neural-networks/
  25. https://theintelligenceofinformation.wordpress.com/category/data-science/
  26. https://theintelligenceofinformation.wordpress.com/category/deep-learning/
  27. https://theintelligenceofinformation.wordpress.com/category/deep-neural-networks/
  28. https://theintelligenceofinformation.wordpress.com/category/gated-recurrent-units/
  29. https://theintelligenceofinformation.wordpress.com/category/information-retrieval/
  30. https://theintelligenceofinformation.wordpress.com/category/ltsm/
  31. https://theintelligenceofinformation.wordpress.com/category/machine-learning/
  32. https://theintelligenceofinformation.wordpress.com/category/multilayer-networks/
  33. https://theintelligenceofinformation.wordpress.com/category/natural-language-processing/
  34. https://theintelligenceofinformation.wordpress.com/category/recurrent-neural-networks/
  35. https://theintelligenceofinformation.wordpress.com/tag/convolutional-neural-networks/
  36. https://theintelligenceofinformation.wordpress.com/2017/06/09/sequence-to-sequence-learning-with-convolutional-neural-networks/#respond
  37. https://theintelligenceofinformation.wordpress.com/2017/06/08/blockchain-technology-secured-by-quantum-mechanics-digital-distributed-asset/
  38. https://theintelligenceofinformation.wordpress.com/2017/06/12/interruption-of-the-normal-posts-scheduling/
  39. https://theintelligenceofinformation.wordpress.com/2017/06/09/sequence-to-sequence-learning-with-convolutional-neural-networks/#respond
  40. https://public-api.wordpress.com/connect/?googleplus-sign-in=https://theintelligenceofinformation.wordpress.com&color_scheme=light
  41. https://gravatar.com/site/signup/
  42. javascript:highlandercomments.doexternallogout( 'wordpress' );
  43. https://theintelligenceofinformation.wordpress.com/2017/06/09/sequence-to-sequence-learning-with-convolutional-neural-networks/
  44. javascript:highlandercomments.doexternallogout( 'googleplus' );
  45. https://theintelligenceofinformation.wordpress.com/2017/06/09/sequence-to-sequence-learning-with-convolutional-neural-networks/
  46. javascript:highlandercomments.doexternallogout( 'twitter' );
  47. https://theintelligenceofinformation.wordpress.com/2017/06/09/sequence-to-sequence-learning-with-convolutional-neural-networks/
  48. javascript:highlandercomments.doexternallogout( 'facebook' );
  49. https://theintelligenceofinformation.wordpress.com/2017/06/09/sequence-to-sequence-learning-with-convolutional-neural-networks/
  50. javascript:highlandercomments.cancelexternalwindow();
  51. https://theintelligenceofinformation.wordpress.com/author/edgarventurescreative/
  52. https://theintelligenceofinformation.wordpress.com/2019/04/01/inverse-planning-and-theory-of-mind-understanding-behavior-in-groups-of-agents/
  53. https://theintelligenceofinformation.wordpress.com/2019/03/27/state-of-the-art-in-self-driving-cars-and-autonomous-vehicles-a-list-of-videos-from-mit/
  54. https://theintelligenceofinformation.wordpress.com/2019/03/25/paper-with-code-series-semantic-image-synthesis-with-spatially-adaptive-id172/
  55. https://theintelligenceofinformation.wordpress.com/2019/04/01/inverse-planning-and-theory-of-mind-understanding-behavior-in-groups-of-agents/
  56. https://theintelligenceofinformation.wordpress.com/2019/03/27/state-of-the-art-in-self-driving-cars-and-autonomous-vehicles-a-list-of-videos-from-mit/
  57. https://theintelligenceofinformation.wordpress.com/2019/03/25/paper-with-code-series-semantic-image-synthesis-with-spatially-adaptive-id172/
  58. https://theintelligenceofinformation.wordpress.com/2018/12/10/from-the-import-ai-blog-a-vision-based-high-speed-driving-with-a-deep-dynamic-observer-or-how-self-driving-cars-will-drive-off-roads/
  59. https://theintelligenceofinformation.wordpress.com/2018/12/05/papers-with-code-series-gan-dissection-or-visualizing-and-understanding-generative-adversarial-networks/
  60. https://wordpress.com/start?ref=wplogin
  61. https://theintelligenceofinformation.wordpress.com/wp-login.php
  62. https://theintelligenceofinformation.wordpress.com/feed/
  63. https://theintelligenceofinformation.wordpress.com/comments/feed/
  64. https://wordpress.com/
  65. https://theintelligenceofinformation.wordpress.com/2019/04/
  66. https://theintelligenceofinformation.wordpress.com/2019/03/
  67. https://theintelligenceofinformation.wordpress.com/2018/12/
  68. https://theintelligenceofinformation.wordpress.com/2018/11/
  69. https://theintelligenceofinformation.wordpress.com/2018/10/
  70. https://theintelligenceofinformation.wordpress.com/2018/09/
  71. https://theintelligenceofinformation.wordpress.com/2018/08/
  72. https://theintelligenceofinformation.wordpress.com/2018/06/
  73. https://theintelligenceofinformation.wordpress.com/2018/05/
  74. https://theintelligenceofinformation.wordpress.com/2018/01/
  75. https://theintelligenceofinformation.wordpress.com/2017/07/
  76. https://theintelligenceofinformation.wordpress.com/2017/06/
  77. https://theintelligenceofinformation.wordpress.com/2017/05/
  78. https://theintelligenceofinformation.wordpress.com/2017/04/
  79. https://theintelligenceofinformation.wordpress.com/2017/03/
  80. https://theintelligenceofinformation.wordpress.com/2017/02/
  81. https://theintelligenceofinformation.wordpress.com/2017/01/
  82. https://theintelligenceofinformation.wordpress.com/2016/12/
  83. https://theintelligenceofinformation.wordpress.com/2016/11/
  84. https://theintelligenceofinformation.wordpress.com/2016/10/
  85. https://theintelligenceofinformation.wordpress.com/2016/09/
  86. https://theintelligenceofinformation.wordpress.com/2016/07/
  87. https://theintelligenceofinformation.wordpress.com/2016/06/
  88. https://theintelligenceofinformation.wordpress.com/2016/05/
  89. https://theintelligenceofinformation.wordpress.com/2016/04/
  90. https://theintelligenceofinformation.wordpress.com/2016/02/
  91. https://theintelligenceofinformation.wordpress.com/2015/12/
  92. https://theintelligenceofinformation.wordpress.com/2015/10/
  93. http://edgarventurescreative.wordpress.com/
  94. https://theintelligenceofinformation.wordpress.com/2016/12/21/financial-portfolio-management-with-deep-learning/comment-page-1/#comment-624
  95. https://theintelligenceofinformation.wordpress.com/2016/12/21/financial-portfolio-management-with-deep-learning/comment-page-1/#comment-623
  96. https://theintelligenceofinformation.wordpress.com/2018/10/26/deep-reinforcement-learning-class-at-berkeley-by-sergey-levine-lecture-16-bootstrap-id25-and-transfer-learning/
  97. https://theintelligenceofinformation.wordpress.com/2018/10/22/paper-with-code-series-reinforcement-learning-decoders-for-fault-tolerant-quantum-computation/comment-page-1/#comment-582
  98. http://edgarventurescreative.wordpress.com/
  99. https://theintelligenceofinformation.wordpress.com/2018/10/17/papers-with-code-series-self-attention-generative-adversarial-networks/comment-page-1/#comment-577
 100. https://theintelligenceofinformation.wordpress.com/2018/10/17/papers-with-code-series-self-attention-generative-adversarial-networks/comment-page-1/#comment-576
 101. https://theintelligenceofinformation.wordpress.com/2019/04/01/inverse-planning-and-theory-of-mind-understanding-behavior-in-groups-of-agents/
 102. https://theintelligenceofinformation.wordpress.com/2019/03/27/state-of-the-art-in-self-driving-cars-and-autonomous-vehicles-a-list-of-videos-from-mit/
 103. https://theintelligenceofinformation.wordpress.com/2019/03/25/paper-with-code-series-semantic-image-synthesis-with-spatially-adaptive-id172/
 104. https://theintelligenceofinformation.wordpress.com/2018/12/10/from-the-import-ai-blog-a-vision-based-high-speed-driving-with-a-deep-dynamic-observer-or-how-self-driving-cars-will-drive-off-roads/
 105. https://theintelligenceofinformation.wordpress.com/2018/12/05/papers-with-code-series-gan-dissection-or-visualizing-and-understanding-generative-adversarial-networks/
 106. http://edgarventurescreative.wordpress.com/
 107. https://theintelligenceofinformation.wordpress.com/2016/12/21/financial-portfolio-management-with-deep-learning/comment-page-1/#comment-624
 108. https://theintelligenceofinformation.wordpress.com/2016/12/21/financial-portfolio-management-with-deep-learning/comment-page-1/#comment-623
 109. https://theintelligenceofinformation.wordpress.com/2018/10/26/deep-reinforcement-learning-class-at-berkeley-by-sergey-levine-lecture-16-bootstrap-id25-and-transfer-learning/
 110. https://theintelligenceofinformation.wordpress.com/2018/10/22/paper-with-code-series-reinforcement-learning-decoders-for-fault-tolerant-quantum-computation/comment-page-1/#comment-582
 111. http://edgarventurescreative.wordpress.com/
 112. https://theintelligenceofinformation.wordpress.com/2018/10/17/papers-with-code-series-self-attention-generative-adversarial-networks/comment-page-1/#comment-577
 113. https://theintelligenceofinformation.wordpress.com/2018/10/17/papers-with-code-series-self-attention-generative-adversarial-networks/comment-page-1/#comment-576
 114. https://theintelligenceofinformation.wordpress.com/2019/04/
 115. https://theintelligenceofinformation.wordpress.com/2019/03/
 116. https://theintelligenceofinformation.wordpress.com/2018/12/
 117. https://theintelligenceofinformation.wordpress.com/2018/11/
 118. https://theintelligenceofinformation.wordpress.com/2018/10/
 119. https://theintelligenceofinformation.wordpress.com/2018/09/
 120. https://theintelligenceofinformation.wordpress.com/2018/08/
 121. https://theintelligenceofinformation.wordpress.com/2018/06/
 122. https://theintelligenceofinformation.wordpress.com/2018/05/
 123. https://theintelligenceofinformation.wordpress.com/2018/01/
 124. https://theintelligenceofinformation.wordpress.com/2017/07/
 125. https://theintelligenceofinformation.wordpress.com/2017/06/
 126. https://theintelligenceofinformation.wordpress.com/2017/05/
 127. https://theintelligenceofinformation.wordpress.com/2017/04/
 128. https://theintelligenceofinformation.wordpress.com/2017/03/
 129. https://theintelligenceofinformation.wordpress.com/2017/02/
 130. https://theintelligenceofinformation.wordpress.com/2017/01/
 131. https://theintelligenceofinformation.wordpress.com/2016/12/
 132. https://theintelligenceofinformation.wordpress.com/2016/11/
 133. https://theintelligenceofinformation.wordpress.com/2016/10/
 134. https://theintelligenceofinformation.wordpress.com/2016/09/
 135. https://theintelligenceofinformation.wordpress.com/2016/07/
 136. https://theintelligenceofinformation.wordpress.com/2016/06/
 137. https://theintelligenceofinformation.wordpress.com/2016/05/
 138. https://theintelligenceofinformation.wordpress.com/2016/04/
 139. https://theintelligenceofinformation.wordpress.com/2016/02/
 140. https://theintelligenceofinformation.wordpress.com/2015/12/
 141. https://theintelligenceofinformation.wordpress.com/2015/10/
 142. https://wordpress.com/start?ref=wplogin
 143. https://theintelligenceofinformation.wordpress.com/wp-login.php
 144. https://theintelligenceofinformation.wordpress.com/feed/
 145. https://theintelligenceofinformation.wordpress.com/comments/feed/
 146. https://wordpress.com/
 147. https://wordpress.com/?ref=footer_custom_com
 148. https://automattic.com/cookies
 149. https://widgets.wp.com/likes/master.html?ver=20190321#ver=20190321

   hidden links:
 151. https://theintelligenceofinformation.wordpress.com/
 152. https://theintelligenceofinformation.wordpress.com/2017/06/09/sequence-to-sequence-learning-with-convolutional-neural-networks/#comment-form-guest
 153. https://theintelligenceofinformation.wordpress.com/2017/06/09/sequence-to-sequence-learning-with-convolutional-neural-networks/#comment-form-load-service:wordpress.com
 154. https://theintelligenceofinformation.wordpress.com/2017/06/09/sequence-to-sequence-learning-with-convolutional-neural-networks/#comment-form-load-service:twitter
 155. https://theintelligenceofinformation.wordpress.com/2017/06/09/sequence-to-sequence-learning-with-convolutional-neural-networks/#comment-form-load-service:facebook
 156. http://edgarventurescreative.wordpress.com/
 157. https://theintelligenceofinformation.wordpress.com/2018/10/26/deep-reinforcement-learning-class-at-berkeley-by-sergey-levine-lecture-16-bootstrap-id25-and-transfer-learning/
 158. http://edgarventurescreative.wordpress.com/
 159. http://edgarventurescreative.wordpress.com/
 160. https://theintelligenceofinformation.wordpress.com/2018/10/26/deep-reinforcement-learning-class-at-berkeley-by-sergey-levine-lecture-16-bootstrap-id25-and-transfer-learning/
 161. http://edgarventurescreative.wordpress.com/
