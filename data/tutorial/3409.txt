   [1][visionlablogo.png]
   [2][stanfordlogo.jpg]

clevr: a diagnostic dataset for
compositional language and elementary visual reasoning

   [facebook_logo.png]
   [3][fair_logo.png]

abstract

   when building artificial intelligence systems that can reason and
   answer questions about visual data, we need diagnostic tests to analyze
   our progress and discover shortcomings. existing benchmarks for visual
   id53 can help, but have strong biases that models can
   exploit to correctly answer questions without reasoning. they also
   conflate multiple sources of error, making it hard to pinpoint model
   weaknesses. we present a diagnostic dataset that tests a range of
   visual reasoning abilities. it contains minimal biases and has detailed
   annotations describing the kind of reasoning each question requires. we
   use this dataset to analyze a variety of modern visual reasoning
   systems, providing novel insights into their abilities and limitations.
   [4][me-v2.jpg] justin johnson
   [5][bharath-hariharan.jpeg] bharath hariharan
   [6][laurens-van-der-maaten.jpg] laurens van
   der maaten
   [7][feifei2.jpeg] fei-fei li
   [8][larry-zitnick.jpg] larry zitnick
   [9][ross-girshick.jpeg] ross girshick
   [10][clevr-paper.png] download paper (arxiv)

presented at cvpr 2017

download

main dataset

   this is the main dataset used in the paper. it consists of:
     * a training set of 70,000 images and 699,989 questions
     * a validation set of 15,000 images and 149,991 questions
     * a test set of 15,000 images and 14,988 questions
     * answers for all train and val questions
     * scene graph annotations for train and val images giving
       ground-truth locations, attributes, and relationships for objects
     * functional program representations for all training and validation
       images

compositional generalization test (cogent)

   this data was used in section 4.7 of the paper to study the ability of
   models to recognize novel combinations of attributes at test-time. the
   data is generated in two different conditions:
   condition a
     * cubes are gray, blue, brown, or yellow
     * cylinders are red, green, purple, or cyan
     * spheres can have any color

   condition b
     * cubes are red, green, purple, or cyan
     * cylinders are gray, blue, brown, or yellow
     * spheres can have any color

   this dataset consists of:
     * a training set of 70,000 images and 699,960 questions in condition
       a
     * a validation set of 15,000 images and 150,000 questions in
       condition a
     * a validation set of 15,000 images and 149,991 questions in
       condition b

     * a test set of 15,000 images and 149,980 questions in condition b
     * a test set of 15,000 images and 149,992 questions in condition b
     * answers, scene graphs and functional programs for all train and val
       images and questions

   [11]download clevr v1.0 (18 gb)
   [12]download clevr v1.0 (no images) (86 mb)
   [13]download clevr-cogent v1.0 (24 gb)
   [14]download clevr-cogent v1.0 (no images) (106 mb)
   all data is released under the [15]creative commons cc by 4.0 license.
   questions in clevr test various aspects of visual reasoning including
   attribute identification, counting, comparison, spatial relationships,
   and logical operations. [teaser.jpg]
   q: are there an equal number of large things and metal spheres?
   q: what size is the cylinder that is left of the brown metal thing that
   is left of the big sphere?
   q: there is a sphere with the same size as the metal cube; is it made
   of the same material as the small red sphere?
   q: how many objects are either small cylinders or red things?
   each question in clevr is represented both in natural language and as a
   functional program. the functional program representation allows for
   precise determination of the reasoning skills required to answer each
   question.
   [functions.png]

dataset generation code

   the code for generating the clevr dataset is [16]available on github.
   with this code you can:
     * render new clevr images using [17]blender
     * generate new clevr questions for clevr images

acknowledgments

   this work was performed during a summer internship at [18]facebook ai
   research.

references

   1. http://vision.stanford.edu/
   2. http://stanford.edu/
   3. https://research.fb.com/category/facebook-ai-research-fair/
   4. http://cs.stanford.edu/people/jcjohns/
   5. http://home.bharathh.info/
   6. https://lvdmaaten.github.io/
   7. http://vision.stanford.edu/feifeili/
   8. http://larryzitnick.org/
   9. http://www.rossgirshick.info/
  10. https://arxiv.org/pdf/1612.06890.pdf
  11. https://dl.fbaipublicfiles.com/clevr/clevr_v1.0.zip
  12. https://dl.fbaipublicfiles.com/clevr/clevr_v1.0_no_images.zip
  13. https://dl.fbaipublicfiles.com/clevr/clevr_cogent_v1.0.zip
  14. https://dl.fbaipublicfiles.com/clevr/clevr_cogent_v1.0_no_images.zip
  15. https://creativecommons.org/licenses/by/4.0/
  16. https://github.com/facebookresearch/clevr-dataset-gen
  17. https://www.blender.org/
  18. https://research.fb.com/category/facebook-ai-research-fair/
