   #[1]github [2]recent commits to deep_srl:master

   [3]skip to content

   (button)

     * why github?
       [4]features    
          + [5]code review
          + [6]project management
          + [7]integrations
          + [8]actions
          + [9]team management
          + [10]social coding
          + [11]documentation
          + [12]code hosting
          + [13]customer stories    
          + [14]security    
     * [15]enterprise
     * explore
          + [16]explore github    

learn & contribute
          + [17]topics
          + [18]collections
          + [19]trending
          + [20]learning lab
          + [21]open source guides

connect with others
          + [22]events
          + [23]community forum
          + [24]github education
     * [25]marketplace
     * pricing
       [26]plans    
          + [27]compare plans
          + [28]contact sales
          + [29]nonprofit    
          + [30]education    

   ____________________
     * in this repository all github    
       jump to    

     * no suggested jump to results

     * in this repository all github    
       jump to    
     * in this repository all github    
       jump to    

   [31]sign in [32]sign up

     * [33]watch [34]15
     * [35]star [36]233
     * [37]fork [38]58

[39]luheng/[40]deep_srl

   [41]code [42]issues 8 [43]pull requests 1 [44]projects 1 [45]insights
   (button) dismiss

join github today

   github is home to over 31 million developers working together to host
   and review code, manage projects, and build software together.
   [46]sign up
   code and pre-trained model for: deep id14: what works
   and what's next
   [47]nlp [48]theano [49]srl [50]tagging [51]deep-learning [52]lstm
     * [53]20 commits
     * [54]3 branches
     * [55]0 releases
     * [56]fetching contributors
     * [57]apache-2.0

    1. [58]python 90.2%
    2. [59]shell 9.8%

   (button) python shell
   branch: master (button) new pull request
   [60]find file
   clone or download

clone with https

   use git or checkout with svn using the web url.
   https://github.com/l
   [61]download zip

downloading...

   want to be notified of new releases in luheng/deep_srl?
   [62]sign in [63]sign up

launching github desktop...

   if nothing happens, [64]download github desktop and try again.

   (button) go back

launching github desktop...

   if nothing happens, [65]download github desktop and try again.

   (button) go back

launching xcode...

   if nothing happens, [66]download xcode and try again.

   (button) go back

launching visual studio...

   if nothing happens, [67]download the github extension for visual studio
   and try again.

   (button) go back
   [68]@luheng
   [69]luheng [70]fixing bug related to predicate id usage (when
   --outputprops is not p    (button)    
   rovided).

   latest commit [71]544217c may 4, 2018
   [72]permalink
   type name latest commit message commit time
   failed to load latest commit information.
   [73]config [74]initial commit. jun 1, 2017
   [75]preprocess [76]initial commit. jun 1, 2017
   [77]python [78]fixing bug related to predicate id usage (when
   --outputprops is not p    may 4, 2018
   [79]resources [80]initial commit. jun 1, 2017
   [81]sample_data [82]initial commit. jun 1, 2017
   [83]scripts [84]script for running end-to-end experiments on conll2012
   (srl with pred    aug 23, 2017
   [85].gitattributes
   [86].gitignore [87]initial commit. jun 1, 2017
   [88]license
   [89]readme.md

readme.md

deep id14

   this repository contains code for training and using the deep srl model
   described in: [90]deep id14: what works and what's
   next

   if you use our code, please cite our paper as follows:

     @inproceedings{he2017deep,
         title={deep id14: what works and what   s next},
         author={he, luheng and lee, kenton and lewis, mike and
     zettlemoyer, luke},
         booktitle={proceedings of the annual meeting of the association
     for computational linguistics},
         year={2017}
     }

getting started

prerequisites:

     * python should be using python 2. you can simulate this with
       virtualenv.
     * pip install numpy
     * pip install theano==0.9.0 (compability with theano 1.0 is not
       tested yet)
     * pip install protobuf
     * pip install nltk (for id121, required only for the
       interactive console)
     * sudo apt-get install tcsh (only required for processing conll05
       data)
     * [git large file storage] ([91]https://git-lfs.github.com/):
       required to download the large model files. alternatively, you
       could get the models [92]here
     * [93]glove embeddings and the [94]srlconll scripts:
       ./scripts/fetch_required_data.sh

pretrained models

   decompress the models (in resources) under the neural_srl directory.
   for example, under the codebase directory:
   tar -zxvf resources/conll05_model.tar.gz

   here's a list of pretrained models:
     * conll05_model.tar.gz: single model trained on conll-2005 dataset.
     * conll05_ensemble.tar.gz: 5 model ensemble trained on conll-2005
       dataset.
     * conll05_propid_model.tar.gz: predicate identification model train
       on conll-2005.
     * conll2012_model.tar.gz: single model trained on conll-2012 dataset.
     * conll2012_ensemble.tar.gz: 5 model ensemble trained on conll-2012
       dataset.
     * conll2012_propid_model.tar.gz: predicate identification model train
       on conll-2012.

try out the interactive console!

   python python/interactive.py --model conll05_model/ --pidmodel
   conll05_propid_model

end-to-end srl prediction:

   run:
   ./scripts/run_end2end.sh sample_data/sentences_with_predicates.txt
   temp/sample.out (on cpu) or:
   ./scripts/run_end2end.sh sample_data/sentences_with_predicates.txt
   temp/sample.out ${gpu_id} (on gpu)

   note that the script adds /usr/local/cuda/... to path and
   cuda_ld_library_path, and loads pretrained models from
   ./conll05_propid_model and ./conll05_ensemble, please adjust the
   configurations according to your own setup.

   the input file contains tokenized sentences, one sentence per line.

   the output file will contain something like:

     john told pat to cut off the tree .
     predicate: told(1)
     a0: john
     v: told
     a2: pat
     a1: to cut off the tree

     john told pat to cut off the tree .
     predicate: cut(4)
     a0: pat
     v: cut off
     a1: the tree

scalability issue

     * building model for the first time might take a while (less then 30
       minutes).
     * currently predict.py loads the entire input file into memory, so it
       would be better to keep the number of sentences in each file under
       50,000.

conll data

   for replicating results on conll-2005 and conll-2012 datasets, please
   follow the steps below.

conll-2005

   the data is provided by: [95]conll-2005 shared task, but the original
   words are from the id32 dataset, which is not publicly
   available. if you have the ptb corpus, you can run:
   ./scripts/fetch_and_make_conll05_data.sh /path/to/ptb/

conll-2012

   you have to follow the instructions below to get conll-2012 data
   [96]conll-2012, this would result in a directory called
   /path/to/conll-formatted-ontonotes-5.0. run:
   ./scripts/make_conll2012_data.sh /path/to/conll-formatted-ontonotes-5.0

predicting srl with trained model

   see usage of python/train.py:
   python python/predict.py -h

   or as a quick start, run trained model (requires conll05_ensemble):
   ./scripts/run_predict_conll05.sh ${gpu_id} or:
   ./scripts/run_predict_conll05.sh for running on cpu.

   run the model end-to-end with predicted (requires conll05_ensemble, and
   conll05_propid_model):
   ./scripts/run_end_to_end_conll05.sh ${gpu_id}

   running the conll-2012 model works similarly.

training a new model

   see usage of python/train.py:
   python python/train.py -h

   train an srl model (with gold predicates) with pre-defined config
   files: ./scripts/run_train.sh ${gpu_id}

   train a predicate identifider: ./scripts/run_propid_train.sh ${gpu_id}

   note that at training time, train.pyruns in the fast_run model, which
   will result in a huge overhead of model compilation. it might take up
   to several minutes for a 2 layer model, and up to 8 hours for an 8
   layer model with variational dropout.

data format

   please refer to the files in sample_data and the explanations below for
   how to format the model input.

bio-tagging format for the srl model

   each line contains exactly one training sample, which has the predicate
   information (index in the sentences, starting from 0), the tokenized
   sentence, and a sequence of tags. if gold tags do not exist, just use a
   sequence of os. the sentence and the tag sequence is seperated with a
   ||| symbol. we use the [97]iob2 format. all the tokens and symbols are
   seperated by an arbitrary whitespace.

   example lines:

     2 my cats love hats . ||| b-a0 i-a0 b-v b-a1 o

tagging format for the predicate identication model

   the format is similar to the above defined, except that each line
   corresponds to an input sentence, and no predicate information is
   provided. the prediates correspond to the v tags and all other words
   are labeled with o tags.

   example lines:

     my cats love hats , they say . ||| o o v o o o v o

configuration for training.

   config contains some configuration files for training the srl model
   (srl_config.json and srl_small_config.json) as well as for training the
   predicate-id model (propid_config.json)

contact

   contact [98]luheng he if you have any questions!

     *    2019 github, inc.
     * [99]terms
     * [100]privacy
     * [101]security
     * [102]status
     * [103]help

     * [104]contact github
     * [105]pricing
     * [106]api
     * [107]training
     * [108]blog
     * [109]about

   (button) you can   t perform that action at this time.

   you signed in with another tab or window. [110]reload to refresh your
   session. you signed out in another tab or window. [111]reload to
   refresh your session.

   (button)

references

   visible links
   1. https://github.com/opensearch.xml
   2. https://github.com/luheng/deep_srl/commits/master.atom
   3. https://github.com/luheng/deep_srl#start-of-content
   4. https://github.com/features
   5. https://github.com/features/code-review/
   6. https://github.com/features/project-management/
   7. https://github.com/features/integrations
   8. https://github.com/features/actions
   9. https://github.com/features#team-management
  10. https://github.com/features#social-coding
  11. https://github.com/features#documentation
  12. https://github.com/features#code-hosting
  13. https://github.com/customer-stories
  14. https://github.com/security
  15. https://github.com/enterprise
  16. https://github.com/explore
  17. https://github.com/topics
  18. https://github.com/collections
  19. https://github.com/trending
  20. https://lab.github.com/
  21. https://opensource.guide/
  22. https://github.com/events
  23. https://github.community/
  24. https://education.github.com/
  25. https://github.com/marketplace
  26. https://github.com/pricing
  27. https://github.com/pricing#feature-comparison
  28. https://enterprise.github.com/contact
  29. https://github.com/nonprofit
  30. https://education.github.com/
  31. https://github.com/login?return_to=/luheng/deep_srl
  32. https://github.com/join
  33. https://github.com/login?return_to=/luheng/deep_srl
  34. https://github.com/luheng/deep_srl/watchers
  35. https://github.com/login?return_to=/luheng/deep_srl
  36. https://github.com/luheng/deep_srl/stargazers
  37. https://github.com/login?return_to=/luheng/deep_srl
  38. https://github.com/luheng/deep_srl/network/members
  39. https://github.com/luheng
  40. https://github.com/luheng/deep_srl
  41. https://github.com/luheng/deep_srl
  42. https://github.com/luheng/deep_srl/issues
  43. https://github.com/luheng/deep_srl/pulls
  44. https://github.com/luheng/deep_srl/projects
  45. https://github.com/luheng/deep_srl/pulse
  46. https://github.com/join?source=prompt-code
  47. https://github.com/topics/nlp
  48. https://github.com/topics/theano
  49. https://github.com/topics/srl
  50. https://github.com/topics/tagging
  51. https://github.com/topics/deep-learning
  52. https://github.com/topics/lstm
  53. https://github.com/luheng/deep_srl/commits/master
  54. https://github.com/luheng/deep_srl/branches
  55. https://github.com/luheng/deep_srl/releases
  56. https://github.com/luheng/deep_srl/graphs/contributors
  57. https://github.com/luheng/deep_srl/blob/master/license
  58. https://github.com/luheng/deep_srl/search?l=python
  59. https://github.com/luheng/deep_srl/search?l=shell
  60. https://github.com/luheng/deep_srl/find/master
  61. https://github.com/luheng/deep_srl/archive/master.zip
  62. https://github.com/login?return_to=https://github.com/luheng/deep_srl
  63. https://github.com/join?return_to=/luheng/deep_srl
  64. https://desktop.github.com/
  65. https://desktop.github.com/
  66. https://developer.apple.com/xcode/
  67. https://visualstudio.github.com/
  68. https://github.com/luheng
  69. https://github.com/luheng/deep_srl/commits?author=luheng
  70. https://github.com/luheng/deep_srl/commit/544217ccb68c363abe98a2a5835ca1d215864841
  71. https://github.com/luheng/deep_srl/commit/544217ccb68c363abe98a2a5835ca1d215864841
  72. https://github.com/luheng/deep_srl/tree/544217ccb68c363abe98a2a5835ca1d215864841
  73. https://github.com/luheng/deep_srl/tree/master/config
  74. https://github.com/luheng/deep_srl/commit/1428b1a2e29493de5ee490bdc6f92dd9346fa7c9
  75. https://github.com/luheng/deep_srl/tree/master/preprocess
  76. https://github.com/luheng/deep_srl/commit/1428b1a2e29493de5ee490bdc6f92dd9346fa7c9
  77. https://github.com/luheng/deep_srl/tree/master/python
  78. https://github.com/luheng/deep_srl/commit/544217ccb68c363abe98a2a5835ca1d215864841
  79. https://github.com/luheng/deep_srl/tree/master/resources
  80. https://github.com/luheng/deep_srl/commit/1428b1a2e29493de5ee490bdc6f92dd9346fa7c9
  81. https://github.com/luheng/deep_srl/tree/master/sample_data
  82. https://github.com/luheng/deep_srl/commit/1428b1a2e29493de5ee490bdc6f92dd9346fa7c9
  83. https://github.com/luheng/deep_srl/tree/master/scripts
  84. https://github.com/luheng/deep_srl/commit/7c72e88f26a0417d672bd31d48a52f1ff85bce4b
  85. https://github.com/luheng/deep_srl/blob/master/.gitattributes
  86. https://github.com/luheng/deep_srl/blob/master/.gitignore
  87. https://github.com/luheng/deep_srl/commit/1428b1a2e29493de5ee490bdc6f92dd9346fa7c9
  88. https://github.com/luheng/deep_srl/blob/master/license
  89. https://github.com/luheng/deep_srl/blob/master/readme.md
  90. https://homes.cs.washington.edu/~luheng/files/acl2017_hllz.pdf
  91. https://git-lfs.github.com/
  92. https://drive.google.com/drive/folders/0b5zhxdvxrsjnzux2yxj5cem0tw8?usp=sharing
  93. https://nlp.stanford.edu/projects/glove/
  94. http://www.lsi.upc.edu/~srlconll/soft.html
  95. http://www.lsi.upc.edu/~srlconll/soft.html
  96. http://cemantix.org/data/ontonotes.html
  97. https://en.wikipedia.org/wiki/inside_outside_beginning
  98. https://homes.cs.washington.edu/~luheng/
  99. https://github.com/site/terms
 100. https://github.com/site/privacy
 101. https://github.com/security
 102. https://githubstatus.com/
 103. https://help.github.com/
 104. https://github.com/contact
 105. https://github.com/pricing
 106. https://developer.github.com/
 107. https://training.github.com/
 108. https://github.blog/
 109. https://github.com/about
 110. https://github.com/luheng/deep_srl
 111. https://github.com/luheng/deep_srl

   hidden links:
 113. https://github.com/
 114. https://github.com/luheng/deep_srl
 115. https://github.com/luheng/deep_srl
 116. https://github.com/luheng/deep_srl
 117. https://help.github.com/articles/which-remote-url-should-i-use
 118. https://github.com/luheng/deep_srl#deep-semantic-role-labeling
 119. https://github.com/luheng/deep_srl#getting-started
 120. https://github.com/luheng/deep_srl#prerequisites
 121. https://github.com/luheng/deep_srl#pretrained-models
 122. https://github.com/luheng/deep_srl#try-out-the-interactive-console
 123. https://github.com/luheng/deep_srl#end-to-end-srl-prediction
 124. https://github.com/luheng/deep_srl#scalability-issue
 125. https://github.com/luheng/deep_srl#conll-data
 126. https://github.com/luheng/deep_srl#conll-2005
 127. https://github.com/luheng/deep_srl#conll-2012
 128. https://github.com/luheng/deep_srl#predicting-srl-with-trained-model
 129. https://github.com/luheng/deep_srl#training-a-new-model
 130. https://github.com/luheng/deep_srl#data-format
 131. https://github.com/luheng/deep_srl#bio-tagging-format-for-the-srl-model
 132. https://github.com/luheng/deep_srl#tagging-format-for-the-predicate-identication-model
 133. https://github.com/luheng/deep_srl#configuration-for-training
 134. https://github.com/luheng/deep_srl#contact
 135. https://github.com/
