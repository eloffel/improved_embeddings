   #[1]rss: 40 latest updates [2]rss: 40 newest packages [3]pypi

   [4]skip to main content (button) switch to mobile version

   warning: you are using testpypi     a separate instance of the python
   package index that allows you to try distribution tools and processes
   without affecting the real index.

   warning: some features may not work without javascript. please try
   enabling it if you encounter problems.

   [5]testpypi
   search pypi ____________________ (button) search

   [6]help [7]donate [8]log in [9]register

   search pypi ____________________ (button) search

parlai 0.1.0

   [10]latest version

   last released: may 4, 2017

   a framework for training and evaluating ai models on a variety of
   openly available dialog datasets.

navigation

   [11]project description [12]release history

project links

   [13]homepage

statistics

   view statistics for this project via [14]libraries.io, or by using
   [15]google bigquery

meta

   license: bsd license

   author: [16]alexander h miller

maintainers

   [17]avatar for ahm from gravatar.com [18]ahm

   [19]project description [20]project details [21]release history

project description

   <p align="center"><img width="40%"
   src="docs/source/\_static/img/parlai.png" /></p>
   -----------------------------------------------------------------------
   ---------
   parlai (pronounced    par-lay   ) is a framework for dialog ai research,
   implemented in python.
   its goal is to provide researchers:
   - a unified framework for training and testing dialog models
   - multi-task training over many datasets at once
   - seaid113ss integration of [amazon mechanical
   turk](https://www.mturk.com/mturk/welcome) for data collection and
   human evaluation
   over 20 tasks are supported in the first release, including popular
   datasets such as [squad](https://rajpurkar.github.io/squad-explorer/),
   [babi tasks](https://arxiv.org/abs/1502.05698),
   [mctest](https://www.microsoft.com/en-us/research/publication/mctest-ch
   allenge-dataset-open-domain-machine-comprehension-text/),
   [wikiqa](https://www.microsoft.com/en-us/download/details.aspx?id=52419
   ), [webquestions](http://www.aclweb.org/anthology/d13-1160),
   [simplequestions](https://arxiv.org/abs/1506.02075),
   [wikimovies](https://arxiv.org/abs/1606.03126), [qaid98 &
   qadailymail](https://arxiv.org/abs/1506.03340),
   [cbt](https://arxiv.org/abs/1511.02301),
   [booktest](https://arxiv.org/abs/1610.00956), [babi dialog
   tasks](https://arxiv.org/abs/1605.07683), [ubuntu
   dialog](https://arxiv.org/abs/1506.08909),
   [opensubtitles](http://opus.lingfil.uu.se/opensubtitles.php), [cornell
   movie](https://www.cs.cornell.edu/~cristian/cornell_movie-dialogs_corpu
   s.html) and [vqa-coco2014](http://visualqa.org/).
   included are examples of training neural models with
   [pytorch](http://pytorch.org/) and [lua torch](http://torch.ch/), with
   batch training on gpu or hogwild training on cpus. using
   [theano](http://deeplearning.net/software/theano/) or
   [tensorflow](https://www.tensorflow.org/) instead is also
   straightforward.
   our aim is for the number of tasks and agents that train on them to
   grow in a community-based way.
   we are in an early-release beta. expect some adventures and rough
   edges.
   ## goals
   unified framework for evaluation of dialogue models
   - downloads tasks/datasets on demand and provides the same simple
   interface to them
   - unifies dataset input and evaluation frameworks/metrics
   - `agents/` directory encourages researchers to submit their training
   code to the repository to share with others
   - aids reproducibility
   end goal is general dialogue, which includes many different skills
   - seaid113ssly combines simulated and real language tasks
   - encourages multi-task model development & evaluation
   - helps to reduce overfitting of models to specific datasets
   end goal is real dialogue with people
   - train and evaluate on live dialogue with humans via mechanical turk
   - easy setup for connecting turkers with your dialogue agent
   - allow to compare different research groups turk experiments
   set of datasets to bootstrap a working dialogue model for human
   interaction
   - motivates building new datasets that will go in the repository
   ## properties
   - all datasets look like natural dialogue: a single format / api.
   - both fixed datasets (conversation logs) and interactive (online/rl)
   tasks.
   - both real and simulated tasks.
   - supports other media, e.g. visual in vqa.
   - can use mechanical turk to run / collect data / evaluate.
   - python framework.
   - examples of training with pytorch.
   - uses zmq to talk to other toolboxes not in python, examples of lua
   torch given.
   - supports hogwild and batch training of models.
   ## basic examples
   display 10 random examples from task 1 of the "1k training examples"
   babi task:
   ```bash
   python examples/display_data.py -t babi:task1k:1
   ```
   displays 100 random examples from multi-tasking on the babi task and
   the squad dataset at the same time:
   ```bash
   python examples/display_data.py -t babi:task1k:1,squad -n 100
   ```
   evaluate an ir baseline model on the validation set of the movies
   subreddit dataset:
   ```bash
   python examples/eval_model.py -m ir_baseline -t "#moviedd-reddit" -dt
   valid
   ```
   display the predictions of that same ir baseline model:
   ```bash
   python examples/display_model.py -m ir_baseline -t "#moviedd-reddit"
   -dt valid
   ```
   train a simple cpu-based memory network on the "10k training examples"
   babi task 1 with 8 threads (python processes) using hogwild (requires
   zmq and lua torch):
   ```bash
   python examples/memnn_luatorch_cpu/full_task_train.py -t babi:task10k:1
   -n 8
   ```
   trains an attentive lstm model on the squad dataset with a batch size
   of 32 examples (pytorch and regex):
   ```bash
   python examples/drqa/train.py -t squad -b 32
   ```
   ## requirements
   parlai currently requires python3.
   dependencies of the core modules are listed in requirement.txt. several
   models included (in parlai/agents) have additional requirements such as
   [pytorch](http://pytorch.org/) or [lua torch](http://torch.ch/)--any
   python requirements in these modules are listed in
   requirements_ext.txt.
   ## installing parlai
   first, clone the repository, then enter the cloned directory.
   linked install:
   run `python setup.py develop` to link the cloned directory to your
   site-packages.
   this is the recommended installation procedure if you plan on modifying
   any parlai code for your run or submitting a pull request, especially
   if you want to add another task to repository.
   all needed data will be downloaded to ./data, and any model files
   (currently just the memnn model) if requested will be downloaded to
   ./downloads.
   copied install (use parlai only as a dependency):
   run `python setup.py install` to copy contents to your site-packages
   folder.
   all data will be downloaded to python's `site-packages` folder by
   default (can override via the command-line), and to make any changes to
   the code you will need to run install again.
   if you want to just use parlai as a dependency (e.g. to access the
   tasks or the core code), this works fine.
   if you want to clear out the downloaded data, then delete the `data`
   and `downloads` (if applicable) folder in `site-packages/parlai`.
   ## worlds, agents and teachers
   the main concepts (classes) in parlai:
   - world - defines the environment (can be very simple, just two agents
   talking to each other).
   - agent     an agent in the world, e.g. the learner. (there can be
   multiple learners.)
   - teacher     a type of agent that talks to the learner, implements one
   of the tasks listed before.
   after defining a world and the agents in it, a main loop can be run for
   training, testing or displaying, which calls the function
   world.parley(). the skeleton of an example main is given in the left
   panel, and the actual code for parley() on the right.
   <p align=center><img width="100%"
   src="docs/source/\_static/img/main.png" /></p>
   ## actions and observations
   all agents (including teachers) speak to each other with a single
   format -- the observation/action object (a python dict).
   this is used to pass text, labels and rewards between agents.
   it   s the same object type when talking (acting) or listening
   (observing), but a different view (with different values in the
   fields).
   the fields are as follows:
   <p align=center><img width="33%"
   src="docs/source/\_static/img/act-obs-dict.png" /></p>
   each of these fields are technically optional, depending on your
   dataset, though the 'text' field will most likely be used in nearly all
   exchanges.
   for a fixed supervised learning dataset like babi, a typical exchange
   from the training set might be as follows (the test set would not
   include labels):
   ```python
   teacher: {
   'text': 'sam went to the kitchen\npat gave sam the milk\nwhere is the
   milk?',
   'labels': ['kitchen'],
   'label_candidates': ['hallway', 'kitchen', 'bathroom'],
   'episode_done': false
   }
   student: {
   'text': 'hallway'
   }
   teacher: {
   'text': 'sam went to the hallway\npat went to the bathroom\nwhere is
   the milk?',
   'labels': ['hallway'],
   'label_candidates': ['hallway', 'kitchen', 'bathroom'],
   'episode_done': true
   }
   student: {
   'text': 'hallway'
   }
   teacher: {
   ... # starts next episode
   }
   ...
   ```
   ## code
   the code is set up into several main directories:
   - **core**: contains the primary code for the framework
   - **agents**: contains agents which can interact with the different
   tasks (e.g. machine learning models)
   - **examples**: contains a few basic examples of different loops
   (building dictionary, train/eval, displaying data)
   - **tasks**: contains code for the different tasks available from
   within parlai
   - **mturk**: contains code for setting up mechanical turk, as well as
   sample mturk tasks
   each directory is described in more detail below, ordered by
   dependencies.
   ### core
   the core library contains the following files:
   - **agents.py**: this file contains a few basic agents which can be
   extended by your own model
   - **_agent_**: base class for all other agents, implements the act()
   method which receives an observation table and returns a table in
   response
   - **_teacher_**: child of agent, also implements the report method for
   returning metrics. tasks implement the teacher class
   - **_multitaskteacher_**: creates a set of teachers based on a "task
   string" passed to the teacher, creating multiple teachers within it and
   alternating between them
   - create_task_teacher: instantiate a teacher from a given task string
   (e.g. 'babi:task:1' or 'squad')
   - **build_data.py**: basic utilities for setting up data for tasks. you
   can override if your filesystem needs different functionality.
   - **dialog_teacher.py**: contains a base teacher class for doing dialog
   with fixed chat logs, along with a data class for storing the data
   - **dict.py**: contains code for building general nlp-style
   dictionaries from observations
   - dictionaryagent: agent which tracks the index and frequency of words
   in a dictionary, and can parse a sentence into indices into its
   dictionary or back
   - **fbdialog_teacher.py**: contains a teacher class which implements a
   function setup_data which parses data in the fb dialog data format
   - **metrics.py**: computes id74 for dialog, e.g. ranking
   metrics, etc.
   - **params.py**: uses argparse to interpret command line arguments for
   parlai
   - **thread_utils.py**: utility classes/functions for use in hogwild
   multithreading (multiprocessing)
   - sharedtable: provides a lock-protected, shared-memory,
   dictionary-like interface for keeping track of metrics
   - **worlds.py**: contains a set of basic worlds for tasks to take place
   inside
   - **_world_**: base class for all other worlds, implements `parley`,
   `shutdown`, `__enter__`, and `__exit__`
   - **_dialogpartnerworld_**: default world for turn-based two-agent
   communication
   multiagentdialogworld: round-robin turn-based agent communication for
   two or more agents
   hogwildworld: default world for setting up a separate world for every
   thread when using multiple threads (processes)
   ### agents
   the agents directory contains agents that have been approved into the
   parlai framework for shared use.
   currently available within this directory:
   - **drqa**: an attentive lstm model drqa
   (https://arxiv.org/abs/1704.00051) implemented in pytorch that has
   competitive results on the squad dataset amongst others.
   - **memnn**: code for an end-to-end memory network in lua torch
   - **remote_agent**: basic class for any agent connecting over zmq
   (memnn_luatorch_cpu uses this)
   - **ir_baseline**: simple information retrieval baseline that scores
   candidate responses with tfidf-weighted matching
   - **repeat_label**: basic class for merely repeating all data sent to
   it (e.g. for piping to a file, debugging)
   ### examples
   this directory contains a few particular examples of basic loops.
   - base_train.py: _very simple example shows the outline of a
   training/validation loop using the default agent parent class_
   - display_data.py: _uses agent.repeat_label to display data from a
   particular task provided on the command-line_
   - display_model.py: _shows the predictions of a provided model on a
   particular task provided on the command-line_
   - eval_model.py: _uses the named agent to compute id74
   data for a particular task provided on the command-line_
   - build_dict.py: _build a dictionary from a particular task provided on
   the command-line using core.dict.dictionaryagent_
   - memnn_luatorch_cpu: _shows a few examples of training an end-to-end
   memory network on a few datasets_
   - drqa: _shows how to train the attentive lstm drqa model of [chen et
   al.](https://arxiv.org/abs/1704.00051) on squad._
   ### tasks
   over 20 tasks are supported in the first release, including popular
   datasets such as
   squad, babi tasks, mctest, wikiqa, webquestions, simplequestions,
   wikimovies, qaid98, qadailymail, cbt, booktest, babi dialog tasks,
   ubuntu, opensubtitles, cornell movie and vqa-coco2014.
   our first release includes the following datasets (shown in the left
   panel), and accessing one of them is as simple as specifying the name
   of the task as a command line option, as shown in the dataset display
   utility (right panel):
   <p align=center><img width="100%"
   src="docs/source/\_static/img/tasks.png" /></p>
   see
   [here](https://github.com/facebookresearch/parlai/blob/master/parlai/ta
   sks/task_list.py) for the current complete task list.
   choosing a task in parlai is as easy as specifying it on the command
   line, as shown in the above image (right). if the dataset has not been
   used before, parlai will automatically download it. as all datasets are
   treated in the same way in parlai (with a single dialog api), a dialog
   agent can in principle switch training and testing between any of them.
   even better, one can specify many tasks at once (multi-tasking) by
   simply providing a comma-separated list, e.g. the command line    -t
   babi,squad   , to use those two datasets, or even all the qa datasets at
   once (-t #qa) or indeed every task in parlai at once (-t #all). the aim
   is to make it easy to build and evaluate very rich dialog models.
   each task folder contains:
   - **build.py** file for setting up data for the task (downloading data,
   etc, only done the first time requested, and not downloaded if the task
   is not used).
   - **agents.py** file which contains default or special teacher classes
   used by core.create_task to instantiate these classes from command-line
   arguments (if desired).
   - **worlds.py** file can optionally be added for tasks that need to
   define new/complex environments.
   to add your own task:
   - (optional) implement build.py to download any needed data
   - implement agents.py, with at least a defaultteacher (extending
   teacher or one of its children)
   - if your data is in fb dialog format, subclass fbdialogteacher
   - if not...
   - if your data is text-based, you can use extend dialogteacher and thus
   core.data.textdata, in which case you just need to write your own
   setup_data function which provides an iterable over the data according
   to the format described in core.data
   - if your data uses other fields, write your own act() method which
   provides observations from your task each time it's called
   ### mturk
   an important part of parlai is seaid113ss integration with mechanical
   turk for data collection, training and evaluation.
   human turkers are also viewed as agents in parlai and hence
   person-person, person-bot, or multiple people and bots in group chat
   can all converse within the standard framework, switching out the roles
   as desired with no code changes to the agents. this is because turkers
   also receive and send via a (pretty printed) version of the same
   interface, using the fields of the observation/action dict.
   we provide two examples in the first release, collecting data, and
   human evaluation of a bot.
   <p align=center><img width="100%"
   src="docs/source/\_static/img/mturk.png" /></p>
   the mturk library contains the following directories and files:
   - **core**: this directory contains the core code for setting up aws
   backend that supports the mturk chat interface, and code for hit
   creation and approval.
   - **tasks**: this directory contains two sample mturk tasks that are
   provided in the first release.
   - **_qa\_data\_collection_**: get questions and answers from turkers,
   given a random paragraph from squad.
   - **_model\_evaluator_**: evaluate the information retrieval baseline
   model on the reddit movie dialog dataset.
   - **run_mturk.py**: file for calling mturk core code with
   user-specified task module, dialog model agent, number of hits, and
   reward for each hit.
   to run sample mturk task and agent:
   - in __run\_mturk.py__, uncomment the task module and the agent class
   you want to use
   - for `create_hits` method, change `num_hits` and `hit_reward` if
   needed. set `is_sandbox` to `true` if you want to run the sample in
   mturk sandbox only, or set it to `false` to allow turkers to work on it
   and potentially get paid for it.
   - run `python run_mturk.py`
   to add your own mturk task and dialog model:
   - create a new folder within the mturk/tasks directory for your new
   task
   - implement __task\_config.py__, with at least the following fields in
   the task_config dictionary:
   - `hit_title`: a short and descriptive title about the kind of task the
   hit contains. on the amazon mechanical turk web site, the hit title
   appears in search results, and everywhere the hit is mentioned.
   - `hit_description`: a description includes detailed information about
   the kind of task the hit contains. on the amazon mechanical turk web
   site, the hit description appears in the expanded view of search
   results, and in the hit and assignment screens.
   - `hit_keywords`: one or more words or phrases that describe the hit,
   separated by commas. on mturk website, these words are used in searches
   to find hits.
   - `worker_agent_id`: a short name indicating the turker's role in the
   conversation.
   - `task_description`: a detailed task description that will be shown on
   the hit task preview page and on the left side of the chat page.
   supports html formatting.
   - implement __agents.py__, with at least an agent class that extends
   from agent
   - write your own `__init__()` method that wraps your dialog model
   agent. (please see mturk/tasks/model_evaluator/agents.py file for a
   concrete example.)
   - write your own `act()` method that returns your dialog model's
   response as well as helpful text to the turker for what action they
   should take next.
   - import your task module and agent class in __run\_mturk.py__ file,
   and then run `python run_mturk.py`.
   ## the team
   parlai is currently maintained by alexander h. miller, will feng and
   jason weston.
   a non-exhaustive list of other major contributors includes:
   adam fisch, jiasen lu, antoine bordes, devi parikh and dhruv batra.
   ## license
   parlai is bsd-licensed. we also provide an additional patent grant.

project details

project links

   [22]homepage

statistics

   view statistics for this project via [23]libraries.io, or by using
   [24]google bigquery

meta

   license: bsd license

   author: [25]alexander h miller

maintainers

   [26]avatar for ahm from gravatar.com [27]ahm

release history [28]release notifications

   this version
   history node
   [29]

   0.1.0

   may 4, 2017

   logo

     * help
     * [30]installing packages
     * [31]uploading packages
     * [32]user guide
     * [33]faqs

     * about pypi
     * [34]pypi on twitter
     * [35]infrastructure dashboard
     * [36]package index name retention
     * [37]our sponsors

     * contributing to pypi
     * [38]bugs and feedback
     * [39]contribute on github
     * [40]development credits

     * using pypi
     * [41]code of conduct
     * [42]report security issue
     * [43]privacy policy
     * [44]terms of use
     __________________________________________________________________

   developed and maintained by the python community, for the python
   community.
   [45]donate today!

      2019 [46]python software foundation

   (button) desktop version

   supported by
   [47]elastic elastic search [48]pingdom pingdom monitoring [49]google
   google bigquery [50]sentry sentry error logging [51]aws aws cloud
   computing [52]datadog datadog monitoring [53]fastly fastly cdn
   [54]signalfx signalfx supporter [55]digicert digicert ev certificate
   [56]statuspage statuspage status page

references

   1. https://test.pypi.org/rss/updates.xml
   2. https://test.pypi.org/rss/packages.xml
   3. https://test.pypi.org/opensearch.xml
   4. https://test.pypi.org/project/parlai/0.1.0/#content
   5. https://test.pypi.org/
   6. https://test.pypi.org/help/
   7. https://donate.pypi.org/
   8. https://test.pypi.org/account/login/
   9. https://test.pypi.org/account/register/
  10. https://test.pypi.org/project/parlai/
  11. https://test.pypi.org/project/parlai/0.1.0/#description
  12. https://test.pypi.org/project/parlai/0.1.0/#history
  13. http://parl.ai/
  14. https://libraries.io/pypi/parlai
  15. https://packaging.python.org/guides/analyzing-pypi-package-downloads/
  16. mailto:ahm@fb.com
  17. https://test.pypi.org/user/ahm/
  18. https://test.pypi.org/user/ahm/
  19. https://test.pypi.org/project/parlai/0.1.0/#description
  20. https://test.pypi.org/project/parlai/0.1.0/#data
  21. https://test.pypi.org/project/parlai/0.1.0/#history
  22. http://parl.ai/
  23. https://libraries.io/pypi/parlai
  24. https://packaging.python.org/guides/analyzing-pypi-package-downloads/
  25. mailto:ahm@fb.com
  26. https://test.pypi.org/user/ahm/
  27. https://test.pypi.org/user/ahm/
  28. https://test.pypi.org/help/#project-release-notifications
  29. https://test.pypi.org/project/parlai/0.1.0/
  30. https://packaging.python.org/installing/
  31. https://packaging.python.org/tutorials/packaging-projects/
  32. https://packaging.python.org/
  33. https://test.pypi.org/help/
  34. https://twitter.com/pypi
  35. https://dtdg.co/pypi
  36. https://www.python.org/dev/peps/pep-0541/
  37. https://test.pypi.org/sponsors/
  38. https://test.pypi.org/help/#feedback
  39. https://github.com/pypa/warehouse
  40. https://github.com/pypa/warehouse/graphs/contributors
  41. https://www.pypa.io/en/latest/code-of-conduct/
  42. https://test.pypi.org/security/
  43. https://www.python.org/privacy/
  44. https://test.pypi.org/policy/terms-of-use/
  45. https://donate.pypi.org/
  46. https://www.python.org/psf/
  47. https://www.elastic.co/
  48. https://www.pingdom.com/
  49. https://cloud.google.com/
  50. https://getsentry.com/for/python
  51. https://aws.amazon.com/
  52. https://www.datadoghq.com/
  53. https://www.fastly.com/
  54. https://www.signalfx.com/
  55. https://www.digicert.com/
  56. https://statuspage.io/
