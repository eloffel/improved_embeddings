   #[1]publisher [2]medium [3]alternate

   [4]homepage
   [5]homepage
   [6]become a member[7]sign in[8]get started
     __________________________________________________________________

gans will change the world

   go to the profile of nikolai yakovenko
   [9]nikolai yakovenko (button) blockedunblock (button) followfollowing
   jan 3, 2017

   it   s new year   s 2017, so time to make predictions. portfolio
   diversification has never been me, so i   ll make just one.

   id3         gans for short         will be the next big
   thing in deep learning, and gans will change the way we look at the
   world.

   specifically, adversarial training will change how we think about
   teaching ais complex tasks. in a sense, they are learning how to
   imitate an expert. you know you   ve reached sufficient mastery of a task
   once an expert discriminator can not tell the difference between your
   outputs, and those that you were learning to imitate. this probably
   does not apply to large tasks like writing a paper         everyone   s final
   product is a little bit different, but adversarial training will be an
   essential tool for making progress on mid-sized outputs like writing
   sentences and paragraphs, and it   s already one of the keys to realistic
   image generation.

   in a      gans solve a problem by training two separate networks with
   competitive goals.
     * one network produces answers (generative)
     * another network distinguishes between the real and the generated
       answers (adversarial)

   the concept is to train these networks competitively, so that after
   some time, neither network can make further progress against the other.
   or the generator becomes so effective that the adversarial network can
   not distinguish between real and synthetic solutions, even with
   unlimited time and substantial resources.

   the details are interesting, but let   s put those aside for now. gans
   are being used to draw images, given an image category and a random
   seed:

        draw me a woodpecker, and it can   t be one of the woodpeckers that i
     showed you before.   

   [1*siphvx4tqaxjxtnznt3jwa.png]
   synthetic birds [10]generated by stackgan, [11]available in
   open source.

   for the mathematically inclined, scientists at [12]google research used
   gans to invent an    encryption    protocol. generator alice passes
   messages to bob, encrypted using a convolutional network and a shared
   secret key. eve acts as eve always does, in the adversarial role, with
   access to the encrypted messages but not the shared key. eve trains a
   network to distinguish between noise and alice   s encrypted information,
   but is not able to distinguish the two apart.

   it   s early days, and i don   t know of a gan public demo that writes
   compelling short text in a way that   s better than a feed-forward lstm.
   although if a feed-forward lstm (such as [13]karpathy   s character id56)
   is the baseline, it is hard to imagine that someone soon won   t create a
   gan to improve performance on something like [14]synthesizing amazon
   product reviews, given a product and star rating.

humans learn through directed feedback

   to me the adversarial process sounds close to how humans learn, and
   more so than id23 (rl). or perhaps i am just an
   adversarial person.

   rl is training that maximizes for (average) eventual rewards. these
   rewards may occur several steps away from the current state, but these
   eventual payoffs must be reasonably well defined by a    reward
   function.    i   m down with rl, and it   s led to significant advances in
   our field. but unless you   re playing a game, it   s hard to come up with
   a reward function that accurately values all of the significant
   feedback from one   s environment.

   id23 led to breakthroughs in backgammon in the 1990s,
   it was an important component of [15]deepmind   s alphago, and the
   deepmind team has even [16]used rl to save google money on datacenter
   cooling.

   it is possible to imagine that rl can find optimizations in the
   datacenter organization space, since the reward function (saving money
   while maintaining a maximum temperature) is reasonably well defined.
   it   s an example, perhaps a rare one outside of hollywood, of a real
   world problem fully parameterized as a game.

   for less game-y problems, what is the reward function? even for
   game-like tasks like driving, the goal is not really to get there very
   fast, or to stay as close to possible within the dotted lines. it   s
   easy to think of the negative rewards (damaging the car, scaring the
   passenger with unreasonable rates of acceleration), but it   s harder to
   correctly define positive rewards accrued during the drive.

monkey see, monkey do

   how do we learn something like handwriting? unless you went to a very
   strict elementary school, the process was not about optimizing for the
   reward of writing letters correctly. more likely you traced out the
   lines that you a teacher drew out on a screen overhead, until you
   internalized the process.

   your generative network drew the letters, and your discriminator
   network learned to note the differences between your page, and the
   platonic ideal from mcgraw-hill.
   [1*heherlwuauio6lrqhf0cba.png]
   adversarial training for third graders

your own toughest critic

   five years ago i was paralyzed above the waist on the right side of my
   body, after taking a blow to the head in a columbia university rugby
   game. two weeks later and out of the icu, i started teaching myself to
   write, back at my apartment in brooklyn.
   [1*r7apnmhspkcupxk_o8akjg.jpeg]
   teaching myself to write again, may 2012.

   my brain had sustained severe damage to the left hemisphere, so i had
   forgotten how to move my right (dominant) arm. however, the rest of my
   brain was relatively undamaged or sufficiently replicated, so i knew
   what proper writing looked like. in other words, i had a corrupt
   generative writing model, but my discriminator network remained intact.

   i joked that on account of the process, i might learn a new (and
   better) handwriting. however while i was able to teach myself to write
   rather quickly, the style i taught myself ended up in close proximity
   to the handwriting style i had before.

   i don   t know how our brains manages this    actor-critic    approach to
   learning, and whether this is really true or just a cute analogy. but
   it does appear that we learn more effectively when we are able to try
   something new, and get immediate feedback from an expert.

   when learning to code or to rock climb, you progress faster when
   receiving    beta    from an expert. until you have enough experience to
   act as your own internal critic, is much easier to train the generative
   part of your brain when a good external critic corrects every low-level
   mistake. even with an internal critic, learning an effective generator
   takes deliberate practice. we can   t offload our own personal training
   to an aws spot instance gpu.

burn the ships?

   gans are working for some problems. they are used to add    realistic   
   effects, like sharp edges for generated images, even if said images
   don   t necessarily have the correct number of heads on every animal.

   iframe: [17]/media/ab78bc2cef5dafe93ec8f0f529455a39?postid=7ed6ae8515ca

   placing the generative network in competition against a worthy
   adversary forces it to make hard choices. as a colleague put it, there
   is a choice where you can draw the parrot green, or you can draw the
   parrot blue. but it has to be one or the other. a supervised network
   trained on real parrots without an adversarial component will tend to
   draw some sort of average of the blue and the green. hence the fuzzy
   lines. an adversarial network has to draw that parrot green. or it has
   to draw the parrot blue. or it can sample from a id203
   distribution over the {blue, green} parrot space. but it won   t draw an
   image with some midpoint color that doesn   t exist in the real parrot
   distribution. which is by now the distribution of ex-parrots.

   my colleague recently [18]catalogued his thoughts about gans, including
   pessimism about their ability to fully converge or to generalize.

   in part, this is because the see-saw approach         training the generator
   for a while, training the discriminator for a while, repeat         is not
   guaranteed to converge on a stable solution, much less the optimal
   solution. as simply illustrated in this tweet from [19]alex j.
   champandard.

   iframe: [20]/media/8b7757b13c0dbefec3b91566c0396a01?postid=7ed6ae8515ca

   but let   s ignore these concerns for now, and dream a little. given that
   lstm models can write coherent product reviews, image captions, and to
   [21]tweet in the voice of president-elect donald trump [strangely
   silent since election night].

   doesn   t this suggest that even a slightly aware discriminator could
   improve performance on these tasks? we could use the generator we have
   now, and ask the discriminator to select amongst the top 20 choices
   offered, assuming that the lstm generates outputs with some randomness.
   isn   t this something that the man behind deepdrumpf already does
   manually?

   iframe: [22]/media/fcad31353884e61bf34297eb389d7c37?postid=7ed6ae8515ca

generator or discriminator         which knows best?

   a natural question arises         which network internalizes the
   understanding of the problem, the generator or the discriminator? is it
   the student or the teacher, who knows more about writing letters.

   in the real world it might be the teacher, but in the examples above, i
   think it would have to be the student. a discriminator for the product
   review generator could make itself useful simply by marking down
   grammatical mistakes that humans don   t usually make. what requires more
   skill, learning to paint like michelangelo, or looking up at the
   sistine chapel?

   as i understand it, the [23]prisma app trains a generative network for
   each of its styles, using an adversarial framework. that is how most of
   the styles generate crisp lines. i wish they could train the gan for a
   little bit longer, so that it would not only recognize the shadows in a
   photo and paint them different colors, but if it could do so in a style
   that an impressionist might. occasionally it gets the light and shadow
   just right, and when it does, the results can be pretty astounding.

   iframe: [24]/media/d6386169d469e1e7488a833f2c5cc557?postid=7ed6ae8515ca

   taking this line of thinking to its natural conclusion, the
   generative-adversarial approach gives the ais an ability to run
   experiments and a/b tests. an ai creates a fully functional generative
   solution. then it collects feedback on how well this generator compares
   to a gold standard, or to other ais that it is learning to replicate,
   or has already internalized. you won   t have to design a id168.
   it might take a while, but the ai will figure out its own evaluation
   rules.

know when to hold    em, know when to fold    em

   i write all of this, having not trained adversarial networks myself. in
   the sprits of mimicry, i   m waiting for others to achieve noticeable
   improvements with gans, ideally on the text generation problem. i
   predict that soon there will be accepted techniques that work well
   enough to get compelling results. our field advances by building on top
   of previous improvements.

   instead of speculating about things i haven   t built, i should be
   spending this time improving my [25]   pokerid98    no limit hold   em ai for
   this year   s [26]annual computer poker competition. code is due january
   13th, 2017.

   for next year   s contest i do plan to add some adversarial training.
   it   s not hard to imagine that adversarial training might help learn a
   good poker strategy. especially if one has access to a strong black-box
   poker ai to compete against.

   since the goal is science and my [27]poker ai code is already in open
   source [by the time you see this, i should have cleaned up the repo and
   added a real readme so that it   s a little bit easier to get started],
   please feel free to try this yourself.

links: looking back, and looking ahead

   i would be remiss not to point out some of my favorite advances in deep
   learning from 2016. a few of my favorite lists:
     * [28]major advances in deep learning in 2016. gans, advances in
       unsupervised learning, [29]super-resolution, and many others.
     *    [30]50 things i learned at nips    by [31]andreas stuhlm  ller
     * my favorite idea from the list above is training lstm memory units
       with different    phased    gating so that [32]some memory units are
       forced to learn longer-term information. other memory units would
       then be left to focus on short-term relationships in the text.
       makes intuitive sense, and potentially avoids having to do too much
       hyper-parameter tuning.
     * are big companies and well funded startups hogging all the good
       deep learning data? [33]maybe proprietary datasets aren   t the
       differentiator on all important ai problems. and wikipedia lists a
       large number of freely available datasets, [34]including the amazon
       reviews dataset mentioned above. there will be more data to come,
       as companies continue to make big sections of their data available
       for research.

   others in the deep learning community are also making predictions for
   2017. i   ll add more links below as i see them, so please post below if
   there are other    deep learning in 2017    predictions that i should read
   and include.
     * ankur handa: mostly also [35]gans taking over the world. also
       speculation about new deep learning hardware. i am naive about
       hardware, so by default i am bullish on nvidia and confused about
       everything else. but [36]intel didn   t buy nervana for $400m for no
       reason.
     * miles brundage: [37]games ais will continue to progress in 2017.
       performance on atari increased through 2016, and might be growing
       super-linearly [don   t make me say    exponential growth   ].
       montezuma   s revenge will improve to    super-human    results. [38]deep
       learning has started to work on starcraft         there   s an [39]open
       source bridge from starcraft to torch, with 500+ stars on github.
       miles predicts that ais will start to beat professional starcraft
       players in the coming year. that   s a very high bar         and in my
       mind, a bit ambitious. [40]remember when ai beating world
       championships at go was not likely, earlier last year?
     * will knight of mit technology review: [41]more reinforcement
       learning, gans again, an ai investment boom coming from china. will
       also predicts a breakthrough in language understanding. i tend to
       agree         a topic for another article.

     ask ai researchers what their next big target is, and they are
     likely to mention language. the hope is that techniques that have
     produced spectacular progress in voice and image recognition, among
     other areas, may also help computers parse and generate language
     more effectively.

     * [42]fred wilson   s [43]predictions for the new year are always worth
       reading:

     ai will be the new mobile. investors will ask management what their
        ai strategy    is before investing and will be wary of companies that
     don   t have one.

   on that note, have a happy, healthy and productive 2017. don   t get
   stuck on a bad problem, since there are so many good problems waiting
   to be explored, and there are not people available to try them all.

   for a bit of pushback against the ai-everywhere hype, [44]bradford
   cross gives his    [45]five ai predictions for 2017            with the benefit
   of posting these in march. still, very insightful. and i agree. ai will
   become more of a commodity in the coming year. full-stack businesses
   with ai at the core will emerge as the big winners. (this last point
   supports my theory that ai will create more jobs than it destroys in
   the medium term    but that   s a separate post.)

   iframe: [46]/media/7640739300ac9f0d3a5b2e734266c6d5?postid=7ed6ae8515ca

update

   this piece has been well received, but i did take some criticism about
   being too rosy on gans, especially as i have         admittedly         not learned
   the dark arts of training gans myself.

   what   s happened over the past two months since i published this piece
   right after new year   s?
     * facebook ai research group (fair) published a paper on wgans
       ([47]wasserstein gans         based on the wasserstein    earth mover   s
       distance    as a id168 to compare distribution). these gans
       are much more stable on image-generation tasks, give you useful
       gradients everywhere, and perhaps most importantly, training loss
       seems to correspond quite naturally to what qualitatively look like
       good results. needless to say, [48]there   s open source code.

   iframe: [49]/media/6ffd4bee2c39385bb3d7209b981438ad?postid=7ed6ae8515ca

     * [50]dev nag has written up the generator-discriminator gan for
       image generation as [51]50 lines of pytorch code, along with an
       engaging and thorough explanation. i recommend that you check it
       out, as have many of my colleagues.

   iframe: [52]/media/8876face30dbb630b92fe26f08532f98?postid=7ed6ae8515ca

   in other words, what started as a good idea with practical results and
   a messy implementation has become cleaner, more principled, and easier
   to use. no one should be surprised. the code, theory and algorithms
   will continue to improve.

   the question remains         which real problems with gans help us break
   through next?

ps

   gans are starting to look spooky good.

   iframe: [53]/media/2bbc687452397485e95efba33e7a6bfb?postid=7ed6ae8515ca

   iframe: [54]/media/fb2acdbb558e0aa042b3463e16001024?postid=7ed6ae8515ca

   the street scene below is generated from a segmentation map. this can
   be transferred real scenes, video game scenes, or created from your
   imagination.

   iframe: [55]/media/2ceca865f9ee018ed5ef4d60fdbe5601?postid=7ed6ae8515ca

   iframe: [56]/media/bbf588efb62c500b942a8badfca0b97d?postid=7ed6ae8515ca

   demo and code on github [57]https://tcwang0509.github.io/pix2pixhd/

     * [58]artificial intelligence
     * [59]deep learning
     * [60]predictions
     * [61]game theory

   (button)
   (button)
   (button) 942 claps
   (button) (button) (button) 8 (button) (button)

     (button) blockedunblock (button) followfollowing
   go to the profile of nikolai yakovenko

[62]nikolai yakovenko

   medium member since mar 2017

   ai (deep learning) researcher. moscow     nyc     palo alto

     * (button)
       (button) 942
     * (button)
     *
     *

   go to the profile of nikolai yakovenko
   never miss a story from nikolai yakovenko, when you sign up for medium.
   [63]learn more
   never miss a story from nikolai yakovenko
   (button) blockedunblock (button) followget updates

references

   visible links
   1. https://plus.google.com/103654360130207659246
   2. https://medium.com/osd.xml
   3. android-app://com.medium.reader/https/medium.com/p/7ed6ae8515ca
   4. https://medium.com/
   5. https://medium.com/
   6. https://medium.com/membership?source=upgrade_membership---nav_full
   7. https://medium.com/m/signin?redirect=https://medium.com/@moscow25/gans-will-change-the-world-7ed6ae8515ca&source=--------------------------nav_reg&operation=login
   8. https://medium.com/m/signin?redirect=https://medium.com/@moscow25/gans-will-change-the-world-7ed6ae8515ca&source=--------------------------nav_reg&operation=register
   9. https://medium.com/@moscow25
  10. https://arxiv.org/pdf/1612.03242v1.pdf
  11. https://github.com/hanzhanggit/stackgan
  12. http://arstechnica.com/information-technology/2016/10/google-ai-neural-network-cryptography/
  13. http://karpathy.github.io/2015/05/21/id56-effectiveness/
  14. https://arxiv.org/abs/1611.09900
  15. https://deepmind.com/research/alphago/
  16. http://www.theverge.com/2016/7/21/12246258/google-deepmind-ai-data-center-cooling
  17. https://medium.com/media/ab78bc2cef5dafe93ec8f0f529455a39?postid=7ed6ae8515ca
  18. http://www.id136.vc/my-summary-of-adversarial-training-nips-workshop/
  19. https://medium.com/@alexjc
  20. https://medium.com/media/8b7757b13c0dbefec3b91566c0396a01?postid=7ed6ae8515ca
  21. https://twitter.com/deepdrumpf
  22. https://medium.com/media/fcad31353884e61bf34297eb389d7c37?postid=7ed6ae8515ca
  23. http://prisma-ai.com/
  24. https://medium.com/media/d6386169d469e1e7488a833f2c5cc557?postid=7ed6ae8515ca
  25. https://www.pokernews.com/strategy/poker-ai-2016-annual-computer-poker-competition-24246.htm
  26. http://www.computerpokercompetition.org/
  27. https://github.com/moscow25/deep_draw
  28. https://tryolabs.com/blog/2016/12/06/major-advancements-deep-learning-2016/
  29. https://arxiv.org/pdf/1609.04802v3.pdf
  30. https://blog.ought.com/nips-2016-875bb8fadb8c
  31. https://medium.com/@stuhlmueller
  32. https://arxiv.org/abs/1610.09513
  33. https://erikbern.com/2016/11/01/are-data-sets-the-new-server-rooms.html
  34. https://en.m.wikipedia.org/wiki/list_of_datasets_for_machine_learning_research
  35. https://plus.google.com/u/0/+ankurhanda/posts/712zewcrk1k
  36. http://www.recode.net/2016/8/9/12413600/intel-buys-nervana--350-million
  37. http://www.milesbrundage.com/blog-posts/my-ai-forecasts-past-present-and-future-main-post
  38. http://www.wired.co.uk/article/deepmind-starchart-ai-games
  39. https://github.com/torchcraft/torchcraft
  40. https://www.inverse.com/article/12620-elon-musk-says-google-deepmind-s-go-victory-is-a-10-year-jump-for-a-i
  41. https://www.technologyreview.com/s/603216/5-big-predictions-for-artificial-intelligence-in-2017/
  42. https://medium.com/@fredwilson
  43. http://avc.com/2017/01/what-is-going-to-happen-in-2017/
  44. https://medium.com/@bradfordcross
  45. http://www.bradfordcross.com/blog/2017/3/3/five-ai-startup-predictions-for-2017
  46. https://medium.com/media/7640739300ac9f0d3a5b2e734266c6d5?postid=7ed6ae8515ca
  47. https://arxiv.org/pdf/1701.07875.pdf
  48. https://github.com/shekkizh/wassersteingan.tensorflow
  49. https://medium.com/media/6ffd4bee2c39385bb3d7209b981438ad?postid=7ed6ae8515ca
  50. https://medium.com/@devnag
  51. https://medium.com/@devnag/generative-adversarial-networks-gans-in-50-lines-of-code-pytorch-e81b79659e3f#.gti3p7s0d
  52. https://medium.com/media/8876face30dbb630b92fe26f08532f98?postid=7ed6ae8515ca
  53. https://medium.com/media/2bbc687452397485e95efba33e7a6bfb?postid=7ed6ae8515ca
  54. https://medium.com/media/fb2acdbb558e0aa042b3463e16001024?postid=7ed6ae8515ca
  55. https://medium.com/media/2ceca865f9ee018ed5ef4d60fdbe5601?postid=7ed6ae8515ca
  56. https://medium.com/media/bbf588efb62c500b942a8badfca0b97d?postid=7ed6ae8515ca
  57. https://tcwang0509.github.io/pix2pixhd/
  58. https://medium.com/tag/artificial-intelligence?source=post
  59. https://medium.com/tag/deep-learning?source=post
  60. https://medium.com/tag/predictions?source=post
  61. https://medium.com/tag/game-theory?source=post
  62. https://medium.com/@moscow25
  63. https://medium.com/@medium/personalize-your-medium-experience-with-users-publications-tags-26a41ab1ee0c#.hx4zuv3mg

   hidden links:
  65. https://medium.com/@moscow25?source=post_header_lockup
  66. https://medium.com/p/7ed6ae8515ca/share/twitter
  67. https://medium.com/p/7ed6ae8515ca/share/facebook
  68. https://medium.com/@moscow25?source=footer_card
  69. https://medium.com/p/7ed6ae8515ca/share/twitter
  70. https://medium.com/p/7ed6ae8515ca/share/facebook
  71. https://medium.com/@moscow25
