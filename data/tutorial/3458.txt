   #[1]rss feed for off the convex path

   [2][logo.jpg]

   [3]about [4]contact [5]subscribe

id3 (gans), some open questions

   sanjeev arora       mar 15, 2017       14 minute read

   since ability to generate    realistic-looking    data may be a step
   towards understanding its structure and exploiting it, generative
   models are an important component of unsupervised learning, which has
   been a frequent theme on this blog. today   s post is about generative
   adversarial networks (gans), introduced in 2014 by [6]goodfellow et
   al., which have quickly become very popular way to train generative
   models for complicated real-life data. it involves a game-theoretic
   tussle between a generator player and a discriminator player, which is
   very attractive and may be useful in other settings.

   this post describes gans and raises some open questions about them. the
   next post will describe [7]our recent paper addressing these questions.

   a generative model $g$ can be seen as taking a random seed $h$ (say, a
   sample from a multivariate normal distribution) and converting it into
   an output string $g(h)$ that    looks    like a real datapoint. such models
   are popular in classical statistics but the simpler ones like gaussian
   mixtures or dirichlet processes seem insufficient for modeling
   complicated distributions on natural images or natural language.
   generative models are also popular in statistical physics, e.g., ising
   models and their cousins. these physics models migrated into machine
   learning and neuroscience in the 1980s and 1990s, which led to a new
   generative view of neural nets (e.g., hinton   s [8]restricted boltzmann
   machines) which in turn led to multilayer generative models such as
   stacked denoising autoencoders and id5. at their
   heart, these are nothing but multilayer neural nets that transform the
   random seed into an output that looks like a realistic image. the
   primary differences in the model concern details of training. here is
   the obligatory set of generated images (source: [9]openai blog)
   [gans-2-6345b04cb02f720a95ea4cb9483e2fd5a5f6e46ec6ea5bbefadf002a010cda8
   2.jpg]

gans: the basic framework

   gans also train a deep net $g$ to produce realistic images, but the new
   and beautiful twist lies in a novel training procedure.

   to understand the new twist let   s first discuss what it could mean for
   the output to    look    realistic. a classic evaluation for generative
   models is [10]perplexity: a measure of the amount of id203 it
   gives to actual images. this requires that the generative model must be
   accompanied by an algorithm that computes the id203 density
   function for the generated distribution (i.e., given any image, it must
   output an estimate of the id203 that the model outputs this
   image.) i might do a future blog post discussing pros and cons of the
   perplexity measure, but today let   s instead dive straight to gans,
   which sidestep the need for perplexity computations.

     idea 1: since deep nets are good at recognizing images    e.g.,
     distinguishing pictures of people from pictures of cats   why not let
     a deep net be the judge of the outputs of a generative model?

   more concretely, let $p_{real}$ be the distribution over real images,
   and $p_{synth}$ the one output by the model (i.e., the distribution of
   $g(h)$ when $h$ is a random seed). we could try to train a
   discriminator deep net $d$ that maps images to numbers in $[0,1]$ and
   tries to discriminate between these distributions in the following
   sense. its expected output $e_{x}[d(x)]$ as high as possible when $x$
   is drawn from $p_{real}$ and as low as possible when $x$ is drawn from
   $p_{synth}$. this training can be done with the [11]usual
   id26. if the two distributions are identical then of course
   no such deep net can exist, and so the training will end in failure. if
   on the other hand we are able to train a good discriminator deep net
      one whose average output is noticeably different between real and
   synthetic samples    then this is proof positive that the two
   distributions are different. (there is an in-between case, whereby the
   distributions are different but the discriminator net doesn   t detect a
   difference. this is going to be important in the story in the next
   post.) a natural next question is whether the ability to train such a
   discriminator deep net can help us improve the generative model.

     idea 2: if a good discriminator net has been trained, use it to
     provide    gradient feedback    that improves the generative model.

   let $g$ denote the generator net, which means that samples in
   $p_{synth}$ are obtained by sampling a uniform gaussian seed $h$ and
   computing $g(h)$. the natural goal for the generator is to make
   $e_{h}[d(g(h))]$ as high as possible, because that means it is doing
   better at fooling the discriminator $d$. so if we fix $d$ the natural
   way to improve $g$ is to pick a few random seeds $h$, and slightly
   adjust the trainable parameters of $g$ to increase this objective. note
   that this gradient computation involves id26 through the
   composed net $d(g(\cdot))$).

   of course, if we let the generator improve itself, it also makes sense
   to then let the discriminator improve itself too, which leads to:

     idea 3: turn the training of the generative model into a game of
     many moves or alternations.

   each move for the discriminator consists of taking a few samples from
   $p_{real}$ and $p_{synth}$ and improving its ability to discriminate
   between them. each move for the generator consists of producing a few
   samples from $p_{synth}$ and updating its parameters so that
   $e_{u}[d(g(h))]$ goes up a bit.

   notice, the discriminator always uses the generator as a black box
      i.e., never examines its internal parameters    whereas the generator
   needs the discriminator   s parameters to compute its gradient direction.
   also, the generator does not ever use real images from $p_{real}$ for
   its computation. (though of course it does rely on the real images
   indirectly since the discriminator is trained using them.)

gans: more details

   one can fill in the above framework in multiple ways. the most obvious
   is that the generator could try to maximize $e_{u}[f(d(g(h)))]$ where
   $f$ is some increasing function. (we call this the measuring function.)
   this has the effect of giving different importance to different
   samples. goodfellow et al. originally used $f(x)=\log (x)$, which,
   since the derivative of $\log x$ is $1/x$, implicitly gives much more
   importance to synthetic data $g(u)$ where the discriminator outputs
   very low values $d(g(h))$. in other words, using $f(x) =\log x$ makes
   the training more sensitive to instances which the discriminator finds
   terrible than to instances which the discriminator finds so-so. by
   contrast, the above sketch implicitly used $f(x) =x$, which gives the
   same importance to all samples and appears in the recent
   [12]wasserstein gan.

   the discussion thus leads to the following mathematical formulation,
   where $d, g$ are deep nets with specified architecture and whose number
   of parameters is fixed in advance by the algorithm designer.

   there is now a big industry of improving this basic framework using
   various architectures and training variations, e.g. (a random sample;
   possibly missing some important ones): [13]dc-gan, [14]s-gan,
   [15]sr-gan, [16]info-gan, etc.

   usually, the training is continued until the generator wins, meaning
   the discriminator   s expected output on samples from $p_{real}$ and
   $p_{synth}$ becomes the same. but a serious practical difficulty is
   that training in practice is oscillatory, and the above objective is
   observed to go up and down. this is unlike usual deep net training,
   where training (at least in cases where it works) steadily improves the
   objective.

gans: some open questions

   (a) does an equilibrium exist?

   since gan is a 2-person game, the oscillatory behavior mentioned above
   is not unexpected. just as a necessary condition for id119
   to come to a stop is that the current point is a stationary point (ie
   gradient is zero), the corresponding situation in a 2-person game is an
   equilibrium: each player   s move happens to be its optimal response to
   the other   s move. in other words, switching the order of $\min$ and
   $\max$ in expression (1) doesn   t change the objective. the gan
   formulation above needs a so-called pure equilibrium, which may not
   exist in general. a simple example is the classic rock/paper/scissors
   game. regardless of whether one player plays rock, paper or scissor as
   a move, the other can counter with a move that beats it. thus no pure
   equilibrium exists.

   (b) does an equilibrium exist where the generator wins, i.e.
   discriminator ends up unable to distinguish the two distributions on
   finite samples?

   (c) suppose the generator wins. what does this say about whether or not
   $p_{real}$ is close to $p_{synth}$ ?

   question (c) has dogged gans research from the start. has the
   generative model actually learned something meaningful about real life
   images, or is it somehow memorizing existing images and presenting
   trivial modifications? (recall that $g$ is never exposed directly to
   real images, so any    memorizing    has to be happen via the gradient
   propagated through the discriminator.)

   if generator   s win does indeed say that $p_{real}$ and $p_{synth}$ are
   close then we think of the gans training as generalizing. (this by
   analogy to the usual notion of generalization for supervised learning.)

   in fact, the next post will show that this issue is indeed more subtle
   than hitherto recognized. but to complete the backstory i will
   summarize how this issue has been studied so far.

past efforts at understanding generalization

   the original paper of goodfellow et al. introduced an analysis of
   generalization    adopted since by other researchers    that works when
   deep nets are trained    sufficiently high capacity, samples and training
   time    (to use their phrasing).

   for the original objective function with $f(x) =\log x$ if the optimal
   discriminator is allowed to be any function all (i.e., not just one
   computable by a finite capacity neural net) it can be checked that the
   optimal choice is $d(x) = p_{real}(x)/(p_{real}(x)+p_{synth}(x))$.
   substituting this in the gans objective, up to linear transformation
   the maximum value achieved by discriminator turns out to be equivalent
   to the [17]jensen-shannon (js) divergence between $p_{real}$ and
   $p_{synth}$. hence if a generator wins the game against this ideal
   discriminator on a very large number of samples, then $p_{real}$ and
   $p_{synth}$ are close in js divergence, and thus the model has learnt
   the true distribution.

   a similar analysis for [18]wasserstein gans shows that if the generator
   wins using the wasserstein objective (i.e., $f(x) =x$) then the two
   distributions are close in [19]wasserstein or earth-mover distance.

   but we will see in the next post that these analyses can be misleading
   because in practice, deep nets have (very) finite capacity and sample
   size. thus even if training produces the optimal discriminator, the
   above analyses can be very off.

further resources

   openai has a [20]brief survey of recent approaches to generative
   models. the [21]id136 blog has many articles on gans.

   [22]goodfellow   s survey is the most authoritative account of this
   burgeoning field, and gives tons of insight. the text around figure 22
   discusses oscillation and lack of equilibria. he also discusses how
   gans trained on a broad spectrum of images seem to get confused and
   output images that are realistic at the micro level but nonsensical
   overall; e.g., an animal with a leg coming out of its head. clearly
   this field, despite its promise, has many open questions!
   subscribe to our [23]rss feed.
   spread the word:

comments

   please enable javascript to view the [24]comments powered by disqus.

   theme available on [25]github.

references

   visible links
   1. http://www.offconvex.org/feed.xml
   2. http://offconvex.github.io/
   3. http://www.offconvex.org/about/
   4. http://www.offconvex.org/contact/
   5. http://www.offconvex.org/subscribe/
   6. https://arxiv.org/abs/1406.2661
   7. https://arxiv.org/abs/1703.00573
   8. https://en.wikipedia.org/wiki/restricted_boltzmann_machine
   9. https://openai.com/blog/generative-models/
  10. https://en.wikipedia.org/wiki/perplexity
  11. http://www.offconvex.org/2016/12/20/backprop/
  12. https://arxiv.org/abs/1701.07875
  13. https://arxiv.org/abs/1511.06434v2
  14. https://arxiv.org/abs/1612.04357
  15. https://arxiv.org/abs/1609.04802
  16. https://arxiv.org/abs/1606.03657
  17. https://en.wikipedia.org/wiki/jensen   shannon_divergence
  18. https://arxiv.org/abs/1701.07875
  19. https://en.wikipedia.org/wiki/wasserstein_metric
  20. https://openai.com/blog/generative-models/
  21. http://www.id136.vc/
  22. https://arxiv.org/pdf/1701.00160.pdf
  23. http://www.offconvex.org/feed.xml
  24. http://disqus.com/?ref_noscript
  25. https://github.com/johnotander/pixyll

   hidden links:
  27. https://facebook.com/sharer.php?u=http://offconvex.github.io/2017/03/15/gans/
  28. https://twitter.com/intent/tweet?text=generative%20adversarial%20networks%20(gans),%20some%20open%20questions&url=http://offconvex.github.io/2017/03/15/gans/
  29. https://plus.google.com/share?url=http://offconvex.github.io/2017/03/15/gans/
  30. http://www.linkedin.com/sharearticle?url=http://offconvex.github.io/2017/03/15/gans/&title=generative%20adversarial%20networks%20(gans),%20some%20open%20questions
  31. http://reddit.com/submit?url=http://offconvex.github.io/2017/03/15/gans/&title=generative%20adversarial%20networks%20(gans),%20some%20open%20questions
  32. https://news.ycombinator.com/submitlink?u=http://offconvex.github.io/2017/03/15/gans/&t=generative%20adversarial%20networks%20(gans),%20some%20open%20questions
