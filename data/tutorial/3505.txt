   #[1]publisher [2]medium [3]alternate

   [4]homepage
   [5]homepage
   [6]sign in[7]get started

   [8]towards data science
     * [9]data science
     * [10]machine learning
     * [11]programming
     * [12]visualization
     * [13]ai
     * [14]data journalism
     * [15]contribute
     __________________________________________________________________

generative models and gans

what are generative models ?

   [16]go to the profile of anish singh walia
   [17]anish singh walia (button) blockedunblock (button) followfollowing
   may 18, 2017

   simply they are a class of unsupervised machine learning models which
   are used to generate some data . it uses the joint id203
   distribution over the observations. although generative models have
   short term applications but in the long run they actually have the
   potential and power to automatically learn the features from a
   dataset , categories or dimentions or anything and generate data .

note

     so talking of unsupervised learning , i wanted to attach links to
     the amazing data camp course on unsupervised learning in python and
     r. trust we when i say this unsupervised learning is still complex
     and tougher to understand and implement as compared to supervised
     learning. and i am sure that the courses below will help you out
     with grabbing the concepts and also implementing them to solve an
     unsupervised problem, as i believe you can learn anything better if
     you implement it practically on different problems and this is what
     i like about datcamp courses.

     [18]unsupervised learning in python.

     [19]unsupervised learning in r.

what are discriminative models?

   these are conditional models used for modelling the dependence of
   dependent variable(y) on the dependent variables(x) using the
   conditional probabilities- pr(y | x) = pr(x and y)/pr(x)= pr( x | y
   ).pr(y)/pr(x) between both of them.

what are gans ?

   gan         generative adversarial network is one of the most hottest topics
   in deep learning right now only because of their highly useful and
   practical applications in real time and the power they have to almost
   learn anything. it uses the above 2 class of machine learning models    
    1. generative models
    2. discriminative models

note

     if you don   t know the basics of deep learning and if you want to
     start with learning deep learning fundamentals and understand what
     it means and also implement it in python i strongly suggest taking
     this course by data camp on [20]deep learning in python. this is
     where i started my deep learning journey.

   now we use neural nets as a generative model in gan and what good it
   does is that using generative models on neural nets actually requires
   smaller number of parameters than the amount of data usually a neural
   net requires to be trained on hence the model does a good job at
   efficiently generating data.

   usually it is said that if we want to train a neural network model on
   small data sets with smaller number of parameters we should use
   unsupervised pre training i.e train the neural net in a unsupervised
   manner. otherwise generally a neural network model requires a lot of
   data to be trained effectively and learn properly from the data in
   order to avoid overfitting on small datsets.

how to train a generative model?

   to train a generative model we first collect lots of data of any
   domain(images , audio ,videos etc) and then feed the data to the model
   to generate data like it.

     example         generating images

   we first collect lots of images , millions in quantity and feed it to
   the model which is a large complicated convolutional neural network
   which outputs a sample of images by learning from the dataset.

   for example         we used a new-initialized network to generate 500 images,
   each time starting with a different random code. the question is that:
   how should we adjust the network   s parameters to encourage it to
   produce slightly more believable(real looking) samples in the future?
   one thing to take care is that we are actually doing unsupervised
   training on generative model,hence we don   t actually have the
   targets(outputs) corresponding to those 500 images , we merely want
   them to look real like training images.

   one clever approach to use here is using gan(generative adversarial
   network) , i.e introducing another discriminator model which
   discriminates or classifies the images that we feed it to real or fake
   images. for a instance lets consider we can feed the discriminator the
   real image dataset and another set of images generated from the
   generator and use it as a standard classifier to discriminate or
   differentiate amongst the 2 types of images real and fake(generated
   images), and here   s the magic    we can also [21]backpropagate through
   both the discriminator and the generator to find how we should change
   the generator   s parameters to make its 500 image samples slightly more
   confusing for the discriminator. and what actually happens by
   backpropogation is that the generator and the discriminator both are
   indulged in a battle of defeating each other in what they both are good
   at i.e the generator is trying to generate images and fool and confuse
   the discriminator into believing that they are real , and the
   discriminator tries distinguish the real images from the fake ones
   generated by the generator.

   in the end, the generator network is outputting images that are
   indistinguishable from real images for the discriminator.

     the training process of a generator

   [1*79_o02dxeomp2bhugyfkuq.gif]
   gan   s generator learning to generate images.

   as we can see the learning process of a generator         initially the
   generator generates noisy and low resolution images , but due to
   backpropogation- over time they actually learn to generate better and
   better images which look completely real and indistinguishable.

   isn   t it exciting ?         these neural networks are actually learning what
   the visual world looks like! these models usually have only about
   millions of parameters.

   this helps it to discover the most salient features of the data: for
   example, it will likely learn that pixels nearby are likely to have the
   same color, or that the world is made up of horizontal or vertical
   edges, or blobs of different colors. eventually, the over time the
   model may discover many more complex regularities and features from
   data : that there are certain types of backgrounds, objects, textures,
   that they occur in certain likely arrangements, or that they transform
   in certain ways over time in videos, etc.

let   s summarize what we have learned    

   [22]id3 - the training process is a fight
   between two models: a generator model and a second discriminator model
   that tries to classify samples as either coming from the true
   distribution p(x) or the model distribution p(x) using conditional
   probabilities. every time the discriminator notices a difference
   between the two distributions the generator adjusts its parameters
   slightly to make it go away and make the images much better and real
   looking , until at the end the generator exactly reproduces the true
   data distribution and the discriminator is guessing at random, unable
   to find a difference.

     * [23]machine learning
     * [24]deep learning
     * [25]generative models
     * [26]gan
     * [27]towards data science

   (button)
   (button)
   (button) 53 claps
   (button) (button) (button) 4 (button) (button)

     (button) blockedunblock (button) followfollowing
   [28]go to the profile of anish singh walia

[29]anish singh walia

   a data nerd. in love with cloud computing, virtualization technologies
   and data science as well.:github [30]https://github.com/anishsingh20.

     (button) follow
   [31]towards data science

[32]towards data science

   sharing concepts, ideas, and codes.

     * (button)
       (button) 53
     * (button)
     *
     *

   [33]towards data science
   never miss a story from towards data science, when you sign up for
   medium. [34]learn more
   never miss a story from towards data science
   (button) get updatesget updates

references

   visible links
   1. https://plus.google.com/103654360130207659246
   2. https://towardsdatascience.com/osd.xml
   3. android-app://com.medium.reader/https/medium.com/p/fe7efc20020b
   4. https://medium.com/
   5. https://medium.com/
   6. https://medium.com/m/signin?redirect=https://towardsdatascience.com/generative-models-and-gans-fe7efc20020b&source=--------------------------nav_reg&operation=login
   7. https://medium.com/m/signin?redirect=https://towardsdatascience.com/generative-models-and-gans-fe7efc20020b&source=--------------------------nav_reg&operation=register
   8. https://towardsdatascience.com/?source=logo-lo_kf3vnsvu7ol7---7f60cf5620c9
   9. https://towardsdatascience.com/data-science/home
  10. https://towardsdatascience.com/machine-learning/home
  11. https://towardsdatascience.com/programming/home
  12. https://towardsdatascience.com/data-visualization/home
  13. https://towardsdatascience.com/artificial-intelligence/home
  14. https://towardsdatascience.com/data-journalism/home
  15. https://towardsdatascience.com/contribute/home
  16. https://towardsdatascience.com/@anishsingh20?source=post_header_lockup
  17. https://towardsdatascience.com/@anishsingh20
  18. https://www.datacamp.com/courses/unsupervised-learning-in-python?tap_a=5644-dce66f&tap_s=210732-9d6bbf
  19. https://www.datacamp.com/courses/unsupervised-learning-in-r?tap_a=5644-dce66f&tap_s=210732-9d6bbf
  20. https://www.datacamp.com/courses/deep-learning-in-python?tap_a=5644-dce66f&tap_s=210732-9d6bbf
  21. http://neuralnetworksanddeeplearning.com/chap2.html
  22. http://arxiv.org/abs/1406.2661
  23. https://towardsdatascience.com/tagged/machine-learning?source=post
  24. https://towardsdatascience.com/tagged/deep-learning?source=post
  25. https://towardsdatascience.com/tagged/generative-model?source=post
  26. https://towardsdatascience.com/tagged/gans?source=post
  27. https://towardsdatascience.com/tagged/towards-data-science?source=post
  28. https://towardsdatascience.com/@anishsingh20?source=footer_card
  29. https://towardsdatascience.com/@anishsingh20
  30. https://github.com/anishsingh20
  31. https://towardsdatascience.com/?source=footer_card
  32. https://towardsdatascience.com/?source=footer_card
  33. https://towardsdatascience.com/
  34. https://medium.com/@medium/personalize-your-medium-experience-with-users-publications-tags-26a41ab1ee0c#.hx4zuv3mg

   hidden links:
  36. https://medium.com/p/fe7efc20020b/share/twitter
  37. https://medium.com/p/fe7efc20020b/share/facebook
  38. https://medium.com/p/fe7efc20020b/share/twitter
  39. https://medium.com/p/fe7efc20020b/share/facebook
