   #[1]publisher [2]medium [3]alternate

   [4]homepage
   [5]homepage
   [6]sign in[7]get started

   [8]towards data science
     * [9]data science
     * [10]machine learning
     * [11]programming
     * [12]visualization
     * [13]ai
     * [14]data journalism
     * [15]contribute
     __________________________________________________________________

deep learning #1: setting up aws & image recognition

   [16]go to the profile of rutger ruizendaal
   [17]rutger ruizendaal (button) blockedunblock (button) followfollowing
   apr 28, 2017

   this post is part of a series on deep learning. check-out part 2
   [18]here and part 3 [19]here.
   [1*y3gucmnkylf2ur09fslh5g.png]
   this week: classifying images of cats and dogs

   welcome to this first entry in this series on practical deep learning.
   in this entry i will setup the amazon web services (aws) instance and
   use a pre-trained model to classify images of cats and dogs.

   in this complete series i will be blogging about my process in the
   first part of the fast ai deep learning course. this course was first
   given at the data institute at the university of san francisco and is
   now available as a mooc. recently the authors gave part 2 of the course
   which will become available online in a couple of months. the main
   reason for following this course is my extreme interest in deep
   learning. i have found many online resources regarding machine learning
   but practical courses on deep learning seem to be a rarity. deep
   learning seems to be an exclusive group that is just a little harder to
   get into. the first thing needed to start on deep learning is a gpu. in
   this course we use the p2 instance from aws. let   s get that set up.

   the first week of this course really focused on the setup. getting your
   deep learning setup right can take a while and it is important to get
   everything working correctly. this includes setting up aws, creating
   and configuring the gpu instance, setting up the process of ssh-ing
   into the server and managing your directories.

   i ran into some issues with permissions on my internship laptop. let me
   give you one tip that will save a lot of time in trying to bypass this:
   make sure you have full administrator access on your laptop before
   attempting this. some lovely engineers offered to setup the gpu
   instance for me, but they didn   t have time to do it soon. so i decided
   to take matters into my own hands.

   the scrips for setting up the aws instance are written in bash. if
   you   re working on a windows machine you will need a program that can
   handle this. i   m using cygwin. i want to share some issues (and their
   solutions) that i ran into during the install. you can skip this if
   you   re not following the fast ai course and just reading along. some
   issues that i ran into during the setup process were:
     * the bash scripts throw an error

   i have read some possible explanations for this, but not a clear
   solution that worked for me. the setup script of the course on github
   is now split in two scripts: setup_p2.sh and setup_instance.sh. in case
   you cannot get these two scripts to work you can use [20]this script to
   setup your p2 instance. if the script does not run be sure to try the
   raw version as well.

   i had a similar issue with the aws-alias.sh script. adding a     at the
   end of line 7 fixed this issue. here is a before and after of line 7:
alias aws-state='aws ec2 describe-instances --instance-ids $instanceid --query "
reservations[0].instances[0].state.name"

alias aws-state='aws ec2 describe-instances --instance-ids $instanceid --query "
reservations[0].instances[0].state.name"'

   [21]here is a bash cheat sheet for everyone who is not familiar with
   bash. i greatly recommend this since you will need bash to interact
   with your instance.
     * the anaconda install. the video mentions that you should install
       anaconda before installing cygwin. this can be a bit confusing as
       you need to use the    cygwin python    to run the pip commands in
       there and not a local anaconda distribution.

   additionally, [22]this repository has a nice step-by-step guide on
   getting your instance running.
     __________________________________________________________________

getting started with deep learning

   after some issues i got my gpu instance running. time to get started
   with deep learning! a quick disclaimer: in these blogs i won   t be
   repeating exactly what is listed in the lesson notes, there is no need
   for that. i will be highlighting some things that i found really
   interesting, as well as issues and ideas that i ran into while going
   through the lesson.

   let   s start with the first question that is probably on your mind: what
   is deep learning and why is it experiencing such hype right now?

   deep learning simply is an id158 with multiple
   hidden layers, this makes them    deep   . a general neural network only
   has one, maybe two hidden layers. a deep neural network has much more
   hidden layers. they also have different types of layers than the
      simple    ones in the normal neural network.
   [1*ccqpggeblgej32mvf2lalg.png]
   (shallow) neural network

   currently deep learning is consistently beating performance on
   well-known datasets. therefore deep learning has been experiencing a
   lot of hype. there are three reasons for the popularity of deep
   learning:
     * infinitely flexible function
     * all-purpose parameter fitting
     * fast and scalable

   the neural network is modeled after the human brain. according to the
   universal approximation theorem it can theoretically solve any
   function. the neural network is trained through backward propagation,
   which allows us to fit the parameters of the model to all these
   different functions. the last reason is the main one for the recent
   achievements in deep learning. because of advancements in the gaming
   industry and the developments of powerful gpus it is now possible to
   train deep neural networks in a fast and scalable way.

   in this first lesson the goal is to use a pre-trained model, namely
   vgg16 to classify images of cats and dogs. vgg16 is a lightweight
   version of the model that won the id163 challenge in 2014. this is a
   yearly challenge and probably the biggest one in id161. we
   can take this pre-trained model and apply it to our dataset of cat and
   dog images. our dataset has been edited by the authors of the course to
   make sure it is in the right format for our model. the original dataset
   can be found on [23]kaggle. when this competition was originally run in
   2013, the state of the art was 80% accuracy. our simple model will
   already achieve 97% accuracy. mind-blowing right? this is how some of
   the pictures and their predicted labels look:
   [1*y3gucmnkylf2ur09fslh5g.png]
   predicted labels for dogs and cats

   the target labels are setup using a process called one-hot-encoding
   which is often used for categorical variables. [1. 0.] refers to a cat
   and [0. 1.] refers to a dog. instead of having one variable named
      target    with two levels 0 and 1, we create an array with two values.
   you can look at these variables as    cats    and    dogs   . if the variable
   is true it gets labeled as a 1 and otherwise as a 0. in a
   multi-classification problem this can mean that your output vector
   looks like this: [0 0 0 0 0 0 0 1 0 0 0]. in this case the vgg16 model
   outputs the id203 of the image belonging to class    cat    and the
   id203 of the image belonging to the class    dog   . the next
   challenge is to tweak this model so we can apply it to another dataset.
     __________________________________________________________________

dogs vs. cats redux

   essentially this is the same dataset as the previous one, but it is not
   pre-processed by the authors of the course. the kaggle command line
   interface (cli) provides a quick way to download the dataset. it can be
   installed via pip. a dollar sign is often used to show that a command
   is run in the terminal.
$ pip install kaggle-cli

   the training set contains 25.000 labeled images of dogs and cats, while
   the test set contains 12.500 unlabeled images. in order to finetune the
   parameters we also create a validation set by taking a small part of
   the training set. it is also useful to set-up a    sample    of the full
   dataset that you can use to quickly check if your model is working
   during the building proces.

   in order to run our model we use the keras library. this library sits
   on top of the popular deep learning libraries theano and tensorflow.
   keras basically makes it more intuitive to code your network. this
   means that you can focus more on the structure of the network and worry
   less about the tensorflow api. in order to know which picture belongs
   to which class keras looks at the directory it is stored in. therefore,
   it is important to make sure you move the images to the correct
   directories. the bash commands that are needed to do this can be run
   directly from the jupyter notebook where we do all our coding. [24]this
   link contains additional information on these commands.

   one epoch, which is a full pass through the dataset, takes 10 minutes
   on my amazon p2 instance. in this case that dataset is the training set
   which consists of 23.000 images. the other 2000 images are in the
   validation set. i decided to use 3 epochs here. the accuracy on the
   validation set is around 98%. after training the model we can take a
   look at some of the correctly classified images. in this case we use
   the probabilities of the image being a cat. 1.0 refers to full
   confidence that the image is of a cat and 0.0 that the image is of a
   dog.
   [1*fgox3g_imersodkubba8tg.png]
   correctly classified images

   now let   s take a look at some of the wrongly classified images. as we
   can see most of them are taken from far away and feature multiple
   animals. the original vgg model was used for images where one thing of
   the target class was clearly visible in the picture. am i the only one
   who finds the fourth picture slightly terrifying?
   [1*jd6t1ifvrrgq571eh5lqha.png]
   incorrectly classified images

   finally, these are the images that the model was most uncertain about.
   this means that the id203 was closest to 0.5 (where 1 is a cat
   and 0 a dog). the fourth picture features a cat where only the face is
   visible. the first and third picture are rectangular and not square
   like the the pictures the original model was trained on.
   [1*zlsupvspbf9zym175uay1w.png]
   images where the model is most uncertain

   that   s it for this week. personally i can   t wait to get started on
   lesson 2 and learn more about the internals of the model. hopefully we
   will also start on building a model from scratch with keras!

   also, thanks to everyone who is updating the github scripts. it helped
   a lot! another thank you to everyone on the fast ai forums, you   re
   awesome.

   if you liked this posts be sure to recommend it so others can see it.
   you can also follow this profile to keep up with my process in the fast
   ai course. see you there!
   [1*dco2zaglk2ukqojzv9jv8g.gif]
     __________________________________________________________________

   i   m currently working as a data scientist for micompany. we are looking
   hard for data engineers and software engineers. we are also recruiting
   data scientists for ourselves and our partners which include some of
   the biggest organisations in the netherlands, israel and some big
   global players!

   contact me on [25]linkedin and join us in amsterdam or tel aviv, or let
   me help you join one of our partner organisations all over the world!

     * [26]machine learning
     * [27]deep learning
     * [28]data science
     * [29]tech
     * [30]artificial intelligence

   (button)
   (button)
   (button) 185 claps
   (button) (button) (button) 1 (button) (button)

     (button) blockedunblock (button) followfollowing
   [31]go to the profile of rutger ruizendaal

[32]rutger ruizendaal

   data science, machine learning & deep learning. visit
   [33]https://musicaldata.com.

     (button) follow
   [34]towards data science

[35]towards data science

   sharing concepts, ideas, and codes.

     * (button)
       (button) 185
     * (button)
     *
     *

   [36]towards data science
   never miss a story from towards data science, when you sign up for
   medium. [37]learn more
   never miss a story from towards data science
   (button) get updatesget updates

references

   visible links
   1. https://plus.google.com/103654360130207659246
   2. https://towardsdatascience.com/osd.xml
   3. android-app://com.medium.reader/https/medium.com/p/1a7e7d9e3c07
   4. https://medium.com/
   5. https://medium.com/
   6. https://medium.com/m/signin?redirect=https://towardsdatascience.com/deep-learning-1-1a7e7d9e3c07&source=--------------------------nav_reg&operation=login
   7. https://medium.com/m/signin?redirect=https://towardsdatascience.com/deep-learning-1-1a7e7d9e3c07&source=--------------------------nav_reg&operation=register
   8. https://towardsdatascience.com/?source=logo-lo_qvmesmu1k91z---7f60cf5620c9
   9. https://towardsdatascience.com/data-science/home
  10. https://towardsdatascience.com/machine-learning/home
  11. https://towardsdatascience.com/programming/home
  12. https://towardsdatascience.com/data-visualization/home
  13. https://towardsdatascience.com/artificial-intelligence/home
  14. https://towardsdatascience.com/data-journalism/home
  15. https://towardsdatascience.com/contribute/home
  16. https://towardsdatascience.com/@r.ruizendaal?source=post_header_lockup
  17. https://towardsdatascience.com/@r.ruizendaal
  18. https://medium.com/@r.ruizendaal/deep-learning-2-f81ebe632d5c
  19. https://medium.com/@r.ruizendaal/deep-learning-3-more-on-id98s-handling-overfitting-2bd5d99abe5d
  20. https://github.com/ericschwarzkopf/courses/blob/dc06ce745a30850e7937858fb26a67df2aff329d/setup/setup_p2.sh
  21. https://gist.github.com/lecoupa/122b12050f5fb267e75f
  22. https://github.com/tomlous/practical-deep-learning
  23. https://www.kaggle.com/c/dogs-vs-cats
  24. https://www.cyberciti.biz/faq/mv-command-howto-move-folder-in-linux-terminal/
  25. https://www.linkedin.com/in/rutger-ruizendaal/
  26. https://towardsdatascience.com/tagged/machine-learning?source=post
  27. https://towardsdatascience.com/tagged/deep-learning?source=post
  28. https://towardsdatascience.com/tagged/data-science?source=post
  29. https://towardsdatascience.com/tagged/tech?source=post
  30. https://towardsdatascience.com/tagged/artificial-intelligence?source=post
  31. https://towardsdatascience.com/@r.ruizendaal?source=footer_card
  32. https://towardsdatascience.com/@r.ruizendaal
  33. https://musicaldata.com/
  34. https://towardsdatascience.com/?source=footer_card
  35. https://towardsdatascience.com/?source=footer_card
  36. https://towardsdatascience.com/
  37. https://medium.com/@medium/personalize-your-medium-experience-with-users-publications-tags-26a41ab1ee0c#.hx4zuv3mg

   hidden links:
  39. https://medium.com/p/1a7e7d9e3c07/share/twitter
  40. https://medium.com/p/1a7e7d9e3c07/share/facebook
  41. https://medium.com/p/1a7e7d9e3c07/share/twitter
  42. https://medium.com/p/1a7e7d9e3c07/share/facebook
