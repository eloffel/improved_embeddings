   #[1]publisher [2]medium [3]alternate

   [4]homepage
   [5]homepage
   [6]sign in[7]get started

   [8]towards data science
     * [9]data science
     * [10]machine learning
     * [11]programming
     * [12]visualization
     * [13]ai
     * [14]data journalism
     * [15]contribute
     __________________________________________________________________

deep learning #2: convolutional neural networks

how and what do id98s learn?

   [16]go to the profile of rutger ruizendaal
   [17]rutger ruizendaal (button) blockedunblock (button) followfollowing
   may 4, 2017

   this post is part of a series on deep learning. check-out part 1
   [18]here and part 3 [19]here.
   [1*z7hd8fzei_eodazwiapvaw.png]

   this week we will explore the inner workings of a convolutional neural
   network (id98). you might be wondering what happens inside these
   networks? and how do they learn?

   the teaching philosophy behind the course i   m following is based on a
   top-down approach. basically, we immediately get to play with the full
   models and as we go along we learn more and more about its inner
   workings. therefore, these blog posts will gradually dive deeper into
   the inner workings of neural networks. this is only week 2 so we are
   starting to make steps towards that goal.

   last week i trained the vgg16 model on a dataset of cat and dog images.
   i want to first start by addressing why using a pre-trained model is a
   good approach. in order to do this it is important to think about what
   these models are learning. in essence a id98 is learning filters and
   applying them to the images. these are not the same filters you apply
   to your instagram selfies but the concept is not that different. the
   id98 takes a small square and starts applying it over the image, this
   square is often referred to as a    window   . the network than looks for
   parts of the image where this filter matches the contents of the image.
   in the first layer the network might learn simple things like diagonal
   lines. in each layer the network is able to combine these findings and
   continually learn more complex concepts. this all still sounds pretty
   vague, so let   s look at some examples. [20]zeiler and fergus (2013) did
   a great job of visualizing what a id98 learns. this is the id98 they used
   in their paper. the vgg16 model that won the id163 competition is
   based on this model.
   [1*vkyugyrnjnz3xovvlvp80g.png]
   id98 by zeiler & fergus (2013)

   this image might look very confusing to you right now, don   t panic!
   let   s start with some things that we can all see from this picture.
   first, the input images are square and 224x224 pixels. the filters that
   i talked about earlier are 7x7 pixels. the model has an input layer, 7
   hidden layers and an output layer. c in the output layer refers to the
   number of classes the model will predict for. now let   s go to the most
   interesting stuff: what the model learns in different layers!
   [1*k57fsddndnfb4fendddnaw.png]
   layer 2 of the id98. the left image represents what the id98 has learned
   and the right image has parts of actual images.

   in layer 2 of the id98 the model is already picking up more interesting
   shapes than just diagonal lines. in the sixth square (counting
   horizontally) you can see that the model is picking up circular shapes.
   also, the last square is looking at corners.
   [1*7j5h2d0wsrbnevi-bxfong.png]
   layer 3 of the id98

   in layer 3 we can see that the model is starting to learn more specific
   things. the first square shows that the model is now able to recognize
   geographical patterns. the sixth square is recognizing car tires. and
   the eleventh square is recognizing people.
   [1*qkxqfap83wdu94n0a7aipg.png]
   layers 4 and 5 of the id98

   finally, layers 4 and 5 continue this trend. layer 5 is picking up
   tings that are very useful for our dogs and cats problem. it is also
   recognizing unicycles and bird/reptile eyes. be aware that these images
   only show a very small fraction of things learned by each layer.

   hopefully this shows you why using pre-trained models is useful. you
   can look up    id21    if you want to learn more about this
   research area. the vgg16 model already knows a lot about recognizing
   dogs and cats. the training set for our cats and dogs problem has only
   25.000 images. a new model might not be able to learn all these
   features from those images. through a process called finetuning we can
   change the last layer of the vgg16 model so that it does not output
   probabilities for a 1000 classes but only for 2, cats and dogs.

   if you are interested in reading more about the math behind deep
   learning, [21]stanford   s id98 pages provide a great resource. they also
   refer to shallow neural networks as    mathematically cute   , that   s a
   first.
     __________________________________________________________________

finetuning and linear layers

   the pre-trained vgg16 model that i used last week to classify cats and
   dogs does not naturally output these two categories. it actually puts
   out 1000 classes. additionally, the model does not even output the
   classes    cats and dogs    but it outputs specific breeds of cats and
   dogs. so how can we change this model efficiently to only classify the
   images as cats or dogs?

   one option would be to manually map these breeds to cats and dogs and
   sum the probabilities. however, this method ignores some critical
   information. for example, if there is a bone in the picture that image
   is probably of a dog. but if we only look at the probabilities per
   breed this information would be lost. there we replace the linear
   (dense) layer at the end of the model and replace it with one that only
   outputs 2 classes. the vgg16 model actually has 3 linear layers at the
   end. we can finetune all these layers and train them through
   id26. id26 is often seen as some kind of abstract
   magic, but it simply is calculating gradients using the chain rule.
   you   ll never have to worry about the details of the math. tensorflow,
   theano and other deep learning libraries will do that for you.

   if you are going through the notebook for lesson 2 of the fast ai
   course be aware of memory issues. i recommend that you first run the
   notebook using only the sample images. if you are using a p2 instance
   you can otherwise run out of memory if you keep saving and loading the
   numpy arrays.
     __________________________________________________________________

id180

   we just discussed the linear layer at the end of the network. however,
   all layers in a neural network are not linear. after calculating the
   values for each of the neurons in the neural network we put these
   values through an activation function. an id158
   basically consists of id127s. if we would only use
   linear calculations we could just stack these on top of each other.
   that would not be a very deep network     therefore, we often use
   non-linear id180 at each layer in the network. by
   stacking layers of linear and non-linear functions on top each other we
   can theoretically model anything. these are the three most popular
   non-linear id180:
     * sigmoid (parses a value to be between 0 and 1)
     * tanh (parses a value to be between -1 and 1)
     * relu (if the value is negative it becomes 0, otherwise it stays the
       same)

   [1*fehezp3rz5va0qvpi9dvng.png]
   three most used id180: sigmoid, tanh & rectified linear
   unit (relu)

   currently, the relu is by far the most used non-linear activation
   function. the main reasons for this are that it reduces the likelihood
   of a vanishing gradient and sparsity. we will discuss these reasons in
   more detail later. the last layer of the model generally uses a
   different activation function, because we want this layer to have a
   certain output. the softmax function is very popular when doing
   classification.

   after finetuning the last layers in the vgg16 model the model has
   138.357.544 parameters. thankfully we do not have the calculate all the
   gradients by hand :). next week i will dive further into the workings
   of a id98 and we will discuss underfitting and overfitting.

   if you liked this posts be sure to recommend it so others can see it.
   you can also follow this profile to keep up with my process in the fast
   ai course. see you there!
   [1*dco2zaglk2ukqojzv9jv8g.gif]
     __________________________________________________________________

   i   m currently working as a data scientist for micompany. we are looking
   hard for data engineers and software engineers. we are also recruiting
   data scientists for ourselves and our partners which include some of
   the biggest organisations in the netherlands, israel and some big
   global players!

   contact me on [22]linkedin and join us in amsterdam or tel aviv, or let
   me help you join one of our partner organisations all over the world!

     * [23]machine learning
     * [24]deep learning
     * [25]data science
     * [26]python
     * [27]tech

   (button)
   (button)
   (button) 322 claps
   (button) (button) (button) 3 (button) (button)

     (button) blockedunblock (button) followfollowing
   [28]go to the profile of rutger ruizendaal

[29]rutger ruizendaal

   data science, machine learning & deep learning. visit
   [30]https://musicaldata.com.

     (button) follow
   [31]towards data science

[32]towards data science

   sharing concepts, ideas, and codes.

     * (button)
       (button) 322
     * (button)
     *
     *

   [33]towards data science
   never miss a story from towards data science, when you sign up for
   medium. [34]learn more
   never miss a story from towards data science
   (button) get updatesget updates

references

   visible links
   1. https://plus.google.com/103654360130207659246
   2. https://towardsdatascience.com/osd.xml
   3. android-app://com.medium.reader/https/medium.com/p/f81ebe632d5c
   4. https://medium.com/
   5. https://medium.com/
   6. https://medium.com/m/signin?redirect=https://towardsdatascience.com/deep-learning-2-f81ebe632d5c&source=--------------------------nav_reg&operation=login
   7. https://medium.com/m/signin?redirect=https://towardsdatascience.com/deep-learning-2-f81ebe632d5c&source=--------------------------nav_reg&operation=register
   8. https://towardsdatascience.com/?source=logo-lo_qhjvwyaszxi5---7f60cf5620c9
   9. https://towardsdatascience.com/data-science/home
  10. https://towardsdatascience.com/machine-learning/home
  11. https://towardsdatascience.com/programming/home
  12. https://towardsdatascience.com/data-visualization/home
  13. https://towardsdatascience.com/artificial-intelligence/home
  14. https://towardsdatascience.com/data-journalism/home
  15. https://towardsdatascience.com/contribute/home
  16. https://towardsdatascience.com/@r.ruizendaal?source=post_header_lockup
  17. https://towardsdatascience.com/@r.ruizendaal
  18. https://medium.com/towards-data-science/deep-learning-1-1a7e7d9e3c07
  19. https://medium.com/@r.ruizendaal/deep-learning-3-more-on-id98s-handling-overfitting-2bd5d99abe5d
  20. https://arxiv.org/abs/1311.2901
  21. http://cs231n.github.io/
  22. https://www.linkedin.com/in/rutger-ruizendaal/
  23. https://towardsdatascience.com/tagged/machine-learning?source=post
  24. https://towardsdatascience.com/tagged/deep-learning?source=post
  25. https://towardsdatascience.com/tagged/data-science?source=post
  26. https://towardsdatascience.com/tagged/python?source=post
  27. https://towardsdatascience.com/tagged/tech?source=post
  28. https://towardsdatascience.com/@r.ruizendaal?source=footer_card
  29. https://towardsdatascience.com/@r.ruizendaal
  30. https://musicaldata.com/
  31. https://towardsdatascience.com/?source=footer_card
  32. https://towardsdatascience.com/?source=footer_card
  33. https://towardsdatascience.com/
  34. https://medium.com/@medium/personalize-your-medium-experience-with-users-publications-tags-26a41ab1ee0c#.hx4zuv3mg

   hidden links:
  36. https://medium.com/p/f81ebe632d5c/share/twitter
  37. https://medium.com/p/f81ebe632d5c/share/facebook
  38. https://medium.com/p/f81ebe632d5c/share/twitter
  39. https://medium.com/p/f81ebe632d5c/share/facebook
