   #[1]publisher [2]medium [3]alternate

   [4]homepage
   [5]homepage
   [6]sign in[7]get started

   [8]towards data science
     * [9]data science
     * [10]machine learning
     * [11]programming
     * [12]visualization
     * [13]ai
     * [14]data journalism
     * [15]contribute
     __________________________________________________________________

boosting your jupyter notebook productivity

   [16]go to the profile of nazif berat
   [17]nazif berat (button) blockedunblock (button) followfollowing
   apr 24, 2017

jupyter (ipython) notebooks features

   first of all, i want to point out that it is very flexible tool to
   create readable analyses, because one can keep code, images, comments,
   formula and plots together:
   [1*csmv827xddnuvvckhlmoka.png]

   jupyter is very extensible, supports other programming languages,
   easily hosted on almost any server         you just only need to have ssh or
   http access to a server. and it is completely free.

basics

   list of hotkeys is shown in help > keyboard shortcuts (list is extended
   from time to time, so don   t hesitate to look at it again).

   this gives an idea of how you   re expected to interact with notebook. if
   you   re using notebook constantly, you   ll of course learn most of the
   list. in particular:
     * esc + f find and replace to search only over the code, not outputs
     * esc + o toggle cell output
     * you can select several cells in a row and delete / copy / cut /
       paste them. this is helpful when you need to move parts of a
       notebook

   [0*jvznlntbpqfdnrwi.png]

sharing notebooks

   simplest way is to share notebook file (.ipynb), but not everyone is
   using notebooks, so the options are
     * convert notebooks to html file
     * share it with gists , which are rendering the notebooks.
     * store your notebook e.g. in dropbox and put the link to
       [18]nbviewer. nbviewer will render the notebook
     * github renders notebooks (with some limitations, but in most cases
       it is ok), which makes it very useful to keep history of your
       research (if research is public)

plotting in notebooks

   there are many plotting options:
     * matplotlib (de-facto standard), activated with %matplotlib inline
     * %matplotlib notebook is interactive regime, but very slow, since
       rendering is done on server-side.
     * mpld3 provides alternative renderer (using d3) for matplotlib code.
       quite nice, though incomplete
     * bokeh is a better option for building interactive plots
     * plot.ly can generate nice plots, but those will cost you money

   [0*_cvss8qz8qtwmtta.png]

magics

   magics are turning simple python into magical python. magics are the
   key to power of ipython.

   in [1]:
# list available python magics
%lsmagic

   out[1]:
available line magics:
%alias  %alias_magic  %autocall  %automagic  %autosave  %bookmark  %cat  %cd  %c
lear  %colors  %config  %connect_info  %cp  %debug  %dhist  %dirs  %doctest_mode
  %ed  %edit  %env  %gui  %hist  %history  %killbgscripts  %ldir  %less  %lf  %l
k  %ll  %load  %load_ext  %loadpy  %logoff  %logon  %logstart  %logstate  %logst
op  %ls  %lsmagic  %lx  %macro  %magic  %man  %matplotlib  %mkdir  %more  %mv  %
notebook  %page  %pastebin  %pdb  %pdef  %pdoc  %pfile  %pinfo  %pinfo2  %popd
%pprint  %precision  %profile  %prun  %psearch  %psource  %pushd  %pwd  %pycat
%pylab  %qtconsole  %quickref  %recall  %rehashx  %reload_ext  %rep  %rerun  %re
set  %reset_selective  %rm  %rmdir  %run  %save  %sc  %set_env  %store  %sx  %sy
stem  %tb  %time  %timeit  %unalias  %unload_ext  %who  %who_ls  %whos  %xdel  %
xmode
available cell magics:
%%!  %%html  %%svg  %%bash  %%capture  %%debug  %%file  %%html  %%javascript  %%
js  %%latex  %%perl  %%prun  %%pypy  %%python  %%python2  %%python3  %%ruby  %%s
cript  %%sh  %%svg  %%sx  %%system  %%time  %%timeit  %%writefile
automagic is on, % prefix is not needed for line magics.

%env

   you can manage environment variables of your notebook without
   restarting the jupyter server process. some libraries (like theano) use
   environment variables to control behavior, %env is the most convenient
   way.

   in [2]:
# %env - without arguments lists environmental variables
%env omp_num_threads=4
env: omp_num_threads=4

executing shell commands

   you can call any shell command. this in particular useful to manage
   your virtual environment.

   in [3]:
!pip install numpy
!pip list | grep theano
requirement already satisfied (use --upgrade to upgrade): numpy in /users/axelr/
.venvs/rep/lib/python2.7/site-packages
theano (0.8.2)

suppress output of last line

   sometimes output isn   t needed, so we can either use pass instruction on
   new line or semicolon at the end

   in [4]:
%matplotlib inline
from matplotlib import pyplot as plt
import numpy

   in [5]:
# if you don't put semicolon at the end, you'll have output of function printed
plt.hist(numpy.linspace(0, 1, 1000)**1.5);

see the source of python functions / classes / whatever with question mark
(?, ??)

   in [6]:
from sklearn.cross_validation import train_test_split
# show the sources of train_test_split function in the pop-up window
train_test_split??

   in [7]:
# you can use ? to get details about magics, for instance:
%pycat?

   will output in the pop-up window:
show a syntax-highlighted file through a pager.
this magic is similar to the cat utility, but it will assume the file
to be python source and will show it with syntax highlighting.
this magic command can either take a local filename, an url,
an history range (see %history) or a macro as argument ::
%pycat myscript.py
%pycat 7-27
%pycat mymacro
%pycat [19]http://www.example.com/myscript.py

%run to execute python code

   %run can execute python code from .py files         this is a well-documented
   behavior.

   but it also can execute other jupyter notebooks! sometimes it is quite
   useful.

   nb. %run is not the same as importing python module.

   in [8]:
# this will execute all the code cells from different notebooks
%run ./2015-09-29-numpytipsandtricks1.ipynb
[49 34 49 41 59 45 30 33 34 57]
[172 177 209 197 171 176 209 208 166 151]
[30 33 34 34 41 45 49 49 57 59]
[209 208 177 166 197 176 172 209 151 171]
[1 0 4 8 6 5 2 9 7 3]
['a' 'b' 'c' 'd' 'e' 'f' 'g' 'h' 'i' 'j']
['b' 'a' 'e' 'i' 'g' 'f' 'c' 'j' 'h' 'd']
['a' 'b' 'c' 'd' 'e' 'f' 'g' 'h' 'i' 'j']
[1 0 6 9 2 5 4 8 3 7]
[1 0 6 9 2 5 4 8 3 7]
[ 0.93551212  0.75079687  0.87495146  0.3344709   0.99628591  0.34355057
  0.90019059  0.88272132  0.67272068  0.24679158]
[8 4 5 1 9 2 7 6 3 0]
[-5 -4 -3 -2 -1  0  1  2  3  4]
[0 0 0 0 0 0 1 2 3 4]
['eh' 'cl' 'ah' ..., 'ab' 'bm' 'ab']
['ab' 'ac' 'ad' 'ae' 'af' 'ag' 'ah' 'ai' 'aj' 'ak' 'al' 'am' 'an' 'bc' 'bd'
 'be' 'bf' 'bg' 'bh' 'bi' 'bj' 'bk' 'bl' 'bm' 'bn' 'cd' 'ce' 'cf' 'cg' 'ch'
 'ci' 'cj' 'ck' 'cl' 'cm' 'cn' 'de' 'df' 'dg' 'dh' 'di' 'dj' 'dk' 'dl' 'dm'
 'dn' 'ef' 'eg' 'eh' 'ei' 'ej' 'ek' 'el' 'em' 'en' 'fg' 'fh' 'fi' 'fj' 'fk'
 'fl' 'fm' 'fn' 'gh' 'gi' 'gj' 'gk' 'gl' 'gm' 'gn' 'hi' 'hj' 'hk' 'hl' 'hm'
 'hn' 'ij' 'ik' 'il' 'im' 'in' 'jk' 'jl' 'jm' 'jn' 'kl' 'km' 'kn' 'lm' 'ln'
 'mn']
[48 33  6 ...,  0 23  0]
['eh' 'cl' 'ah' ..., 'ab' 'bm' 'ab']
['eh' 'cl' 'ah' ..., 'ab' 'bm' 'ab']
['bf' 'cl' 'dn' ..., 'dm' 'cn' 'dj']
['bf' 'cl' 'dn' ..., 'dm' 'cn' 'dj']
[ 2.29711325  1.82679746  2.65173344 ...,  2.15286813  2.308737    2.15286813]
1000 loops, best of 3: 1.09 ms per loop
the slowest run took 8.44 times longer than the fastest. this could mean that an
 intermediate result is being cached.
10000 loops, best of 3: 21.5   s per loop
0.416
0.416

%load

   loading code directly into cell. you can pick local file or file on the
   web.

   after uncommenting the code below and executing, it will replace the
   content of cell with contents of file.

   in [9]:
# %load [20]http://matplotlib.org/mpl_examples/pylab_examples/contour_demo.py

%store: lazy passing data between notebooks

   in [10]:
data = 'this is the string i want to pass to different notebook'
%store data
del data # deleted variable
stored 'data' (str)

   in [11]:
# in second notebook i will use:
%store -r data
print data
this is the string i want to pass to different notebook

%who: analyze variables of global scope

   in [12]:
# pring names of string variables
%who str
data

timing

   when you need to measure time spent or find the bottleneck in the code,
   ipython comes to the rescue.

   in [13]:
%%time
import time
time.sleep(2) # sleep for two seconds
cpu times: user 1.23 ms, sys: 4.82 ms, total: 6.05 ms
wall time: 2 s

   in [14]:
# measure small code snippets with timeit !
import numpy
%timeit numpy.random.normal(size=100)
the slowest run took 13.85 times longer than the fastest. this could mean that a
n intermediate result is being cached.
100000 loops, best of 3: 6.35   s per loop

   in [15]:
%%writefile pythoncode.py
import numpy
def append_if_not_exists(arr, x):
    if x not in arr:
        arr.append(x)

def some_useless_slow_function():
    arr = list()
    for i in range(10000):
        x = numpy.random.randint(0, 10000)
        append_if_not_exists(arr, x)
overwriting pythoncode.py

   in [16]:
# shows highlighted source of the newly-created file
%pycat pythoncode.py

   in [17]:
from pythoncode import some_useless_slow_function, append_if_not_exists

profiling: %prun, %lprun, %mprun

   in [18]:
# shows how much time program spent in each function
%prun some_useless_slow_function()

   example of output:
26338 function calls in 0.713 seconds
   ordered by: internal time
   ncalls  tottime  percall  cumtime  percall filename:lineno(function)
    10000    0.684    0.000    0.685    0.000 pythoncode.py:3(append_if_not_exis
ts)
    10000    0.014    0.000    0.014    0.000 {method 'randint' of 'mtrand.rando
mstate' objects}
        1    0.011    0.011    0.713    0.713 pythoncode.py:7(some_useless_slow_
function)
        1    0.003    0.003    0.003    0.003 {range}
     6334    0.001    0.000    0.001    0.000 {method 'append' of 'list' objects
}
        1    0.000    0.000    0.713    0.713 <string>:1(<module>)
        1    0.000    0.000    0.000    0.000 {method 'disable' of '_lsprof.prof
iler' objects}

   in [19]:
%load_ext memory_profiler

   in [20]:
# tracking memory consumption (show in the pop-up)
%mprun -f append_if_not_exists some_useless_slow_function()
('',)

   example of output:
line #    mem usage    increment   line contents
================================================
     3     20.6 mib      0.0 mib   def append_if_not_exists(arr, x):
     4     20.6 mib      0.0 mib       if x not in arr:
     5     20.6 mib      0.0 mib           arr.append(x)

   %lprun is line profiling, but it seems to be broken for latest ipython
   release, so we   ll manage without magic this time:

   in [21]:
import line_profiler
lp = line_profiler.lineprofiler()
lp.add_function(some_useless_slow_function)
lp.runctx('some_useless_slow_function()', locals=locals(), globals=globals())
lp.print_stats()
timer unit: 1e-06 s
total time: 1.27826 s
file: pythoncode.py
function: some_useless_slow_function at line 7
line #      hits         time  per hit   % time  line contents
==============================================================
     7                                           def some_useless_slow_function(
):
     8         1            5      5.0      0.0      arr = list()
     9     10001        17838      1.8      1.4      for i in range(10000):
    10     10000        38254      3.8      3.0          x = numpy.random.randin
t(0, 10000)
    11     10000      1222162    122.2     95.6          append_if_not_exists(ar
r, x)

debugging with %debug

   jupyter has own interface for [21]ipdb. makes it possible to go inside
   the function and investigate what happens there.

   this is not pycharm and requires much time to adapt, but when debugging
   on the server this can be the only option (or use pdb from terminal).

   in [22]:
#%%debug filename:line_number_for_breakpoint
# here some code that fails. this will activate interactive context for debuggin
g

   a bit easier option is %pdb, which activates debugger when exception is
   raised:

   in [23]:
# %pdb
# def pick_and_take():
#     picked = numpy.random.randint(0, 1000)
#     raise notimplementederror()

# pick_and_take()

writing formula in latex

   markdown cells render latex using mathjax.

   p(a   b)=p(b   a)p(a)p(b)p(a   b)=p(b   a)p(a)p(b)

   markdown is an important part of notebooks, so don   t forget to use its
   expressiveness!

using different languages inside single notebook

   if you   re missing those much, using other computational kernels:
     * %%python2
     * %%python3
     * %%ruby
     * %%perl
     * %%bash
     * %%r

   is possible, but obviously you   ll need to setup the corresponding
   kernel first.

   in [24]:
%%ruby
puts 'hi, this is ruby.'
hi, this is ruby.

   in [25]:
%%bash
echo 'hi, this is bash.'
hi, this is bash.

big data analysis

   a number of solutions are available for querying/processing large data
   samples:
     * [22]ipyparallel (formerly ipython cluster) is a good option for
       simple map-reduce operations in python. we use it in rep to train
       many machine learning models in parallel
     * [23]pyspark
     * spark-sql magic [24]%%sql

let others to play with your code without installing anything

   services like [25]mybinder give an access to machine with jupyter
   notebook with all the libraries installed, so user can play for half an
   hour with your code having only browser.

   you can setup your own system with [26]jupyterhub, this is very handy
   when you organize mini-course or workshop and don   t have time to care
   about students machines.

writing functions in other languages

   sometimes the speed of numpy is not enough and i need to write some
   fast code. in principle, you can compile function in the dynamic
   library and write python wrappers   

   but it is much better when this boring part is done for you, right?

   you can write functions in cython or fortran and use those directly
   from python code.

   first you   ll need to install:
!pip install cython fortran-magic

   in [26]:
%load_ext cython

   in [27]:
%%cython
def myltiply_by_2(float x):
    return 2.0 * x

   in [28]:
myltiply_by_2(23.)

   out[28]:
46.0

   personally i prefer to use fortran, which i found very convenient for
   writing number-crunching functions.

   in [29]:
%load_ext fortranmagic
/users/axelr/.venvs/rep/lib/python2.7/site-packages/ipython/utils/path.py:265: u
serwarning: get_ipython_cache_dir has moved to the ipython.paths module
  warn("get_ipython_cache_dir has moved to the ipython.paths module")

   in [30]:
%%fortran
subroutine compute_fortran(x, y, z)
    real, intent(in) :: x(:), y(:)
    real, intent(out) :: z(size(x, 1))
    z = sin(x + y)
end subroutine compute_fortran

   in [31]:
compute_fortran([1, 2, 3], [4, 5, 6])

   out[31]:
array([-0.95892429,  0.65698659,  0.41211849], dtype=float32)

   i also should mention that there are different jitter systems which can
   speed up your python code.

multiple cursors

   since recently jupyter supports multiple cursors (in a single cell),
   just like sublime ot intellij!
   [0*tpvqzsgo8kr0uwiq.gif]

   gif taken from
   [27]http://swanintelligence.com/multi-cursor-in-jupyter.html

[28]jupyter-contrib extensions

   are installed with
!pip install https://github.com/ipython-contrib/jupyter_contrib_nbextensions/tar
ball/master
!pip install jupyter_nbextensions_configurator
!jupyter contrib nbextension install --user
!jupyter nbextensions_configurator enable --user

   [0*cushawu7ejmdzp9b.png]

   this is a family of different extensions, including e.g. jupyter
   spell-checker and code-formatter, that are missing in jupyter by
   default.

[29]rise: presentations with notebook

   extension by damian avila makes it possible to show notebooks as
   demonstrations. example of such presentation:
   [30]http://bollwyvl.github.io/live_reveal/#/7

   it is very useful when you teach others e.g. to use some library.

jupyter output system

   notebooks are displayed as html and the cell output can be html, so you
   can return virtually anything: video/audio/images.

   in this example i scan the folder with images in my repository and show
   first five of them:

   in [32]:
import os
from ipython.display import display, image
names = [f for f in os.listdir('../images/ml_demonstrations/') if f.endswith('.p
ng')]
for name in names[:5]:
    display(image('../images/ml_demonstrations/' + name, width=300))

i could take the same list with a bash command

   because magics and bash calls return python variables:

   in [33]:
names = !ls ../images/ml_demonstrations/*.png
names[:5]

   out[33]:
['../images/ml_demonstrations/colah_embeddings.png',
 '../images/ml_demonstrations/convnetjs.png',
 '../images/ml_demonstrations/decision_tree.png',
 '../images/ml_demonstrations/decision_tree_in_course.png',
 '../images/ml_demonstrations/dream_mnist.png']

reconnect to kernel

   long before, when you started some long-taking process and at some
   point your connection to ipython server dropped, you completely lost
   the ability to track the computations process (unless you wrote this
   information to file). so either you interrupt the kernel and
   potentially lose some progress, or you wait till it completes without
   any idea of what is happening.

   reconnect to kernel option now makes it possible to connect again to
   running kernel without interrupting computations and get the newcoming
   output shown (but some part of output is already lost).

write your posts in notebooks

   like this one. use nbconvert to export them to html.

useful links

     * ipython [31]built-in magics
     * nice [32]interactive presentation about jupyter by ben zaitlen
     * advanced notebooks [33]part 1: magics and [34]part 2: widgets
     * [35]profiling in python with jupyter
     * [36]4 ways to extend notebooks
     * [37]ipython notebook tricks
     * [38]jupyter vs zeppelin for big data

     * [39]python
     * [40]data science
     * [41]machine learning
     * [42]artificial intelligence
     * [43]jupyter notebook

   (button)
   (button)
   (button) 1.1k claps
   (button) (button) (button) 8 (button) (button)

     (button) blockedunblock (button) followfollowing
   [44]go to the profile of nazif berat

[45]nazif berat

   deep learning engineer, a humanizer of industry.

     (button) follow
   [46]towards data science

[47]towards data science

   sharing concepts, ideas, and codes.

     * (button)
       (button) 1.1k
     * (button)
     *
     *

   [48]towards data science
   never miss a story from towards data science, when you sign up for
   medium. [49]learn more
   never miss a story from towards data science
   (button) get updatesget updates

references

   visible links
   1. https://plus.google.com/103654360130207659246
   2. https://towardsdatascience.com/osd.xml
   3. android-app://com.medium.reader/https/medium.com/p/1f26b08429ad
   4. https://medium.com/
   5. https://medium.com/
   6. https://medium.com/m/signin?redirect=https://towardsdatascience.com/jupyter-notebook-hints-1f26b08429ad&source=--------------------------nav_reg&operation=login
   7. https://medium.com/m/signin?redirect=https://towardsdatascience.com/jupyter-notebook-hints-1f26b08429ad&source=--------------------------nav_reg&operation=register
   8. https://towardsdatascience.com/?source=logo-lo_uutgat64von8---7f60cf5620c9
   9. https://towardsdatascience.com/data-science/home
  10. https://towardsdatascience.com/machine-learning/home
  11. https://towardsdatascience.com/programming/home
  12. https://towardsdatascience.com/data-visualization/home
  13. https://towardsdatascience.com/artificial-intelligence/home
  14. https://towardsdatascience.com/data-journalism/home
  15. https://towardsdatascience.com/contribute/home
  16. https://towardsdatascience.com/@nazifberat?source=post_header_lockup
  17. https://towardsdatascience.com/@nazifberat
  18. http://nbviewer.jupyter.org/
  19. http://www.example.com/myscript.py
  20. http://matplotlib.org/mpl_examples/pylab_examples/contour_demo.py
  21. https://docs.python.org/2/library/pdb.html
  22. https://github.com/ipython/ipyparallel
  23. http://www.cloudera.com/documentation/enterprise/5-5-x/topics/spark_ipython.html
  24. https://github.com/jupyter-incubator/sparkmagic
  25. http://mybinder.org/
  26. https://github.com/jupyterhub/jupyterhub
  27. http://swanintelligence.com/multi-cursor-in-jupyter.html
  28. https://github.com/ipython-contrib/jupyter_contrib_nbextensions
  29. https://github.com/damianavila/rise
  30. http://bollwyvl.github.io/live_reveal/#/7
  31. https://ipython.org/ipython-doc/3/interactive/magics.html
  32. http://quasiben.github.io/dfwmeetup_2014/#/
  33. https://blog.dominodatalab.com/lesser-known-ways-of-using-notebooks/
  34. https://blog.dominodatalab.com/interactive-dashboards-in-jupyter/
  35. http://pynash.org/2013/03/06/timing-and-profiling/
  36. http://mindtrove.info/4-ways-to-extend-jupyter-notebook/
  37. https://www.quora.com/what-are-your-favorite-tricks-for-ipython-notebook
  38. https://www.linkedin.com/pulse/comprehensive-comparison-jupyter-vs-zeppelin-hoc-q-phan-mba-
  39. https://towardsdatascience.com/tagged/python?source=post
  40. https://towardsdatascience.com/tagged/data-science?source=post
  41. https://towardsdatascience.com/tagged/machine-learning?source=post
  42. https://towardsdatascience.com/tagged/artificial-intelligence?source=post
  43. https://towardsdatascience.com/tagged/jupyter-notebook?source=post
  44. https://towardsdatascience.com/@nazifberat?source=footer_card
  45. https://towardsdatascience.com/@nazifberat
  46. https://towardsdatascience.com/?source=footer_card
  47. https://towardsdatascience.com/?source=footer_card
  48. https://towardsdatascience.com/
  49. https://medium.com/@medium/personalize-your-medium-experience-with-users-publications-tags-26a41ab1ee0c#.hx4zuv3mg

   hidden links:
  51. https://medium.com/p/1f26b08429ad/share/twitter
  52. https://medium.com/p/1f26b08429ad/share/facebook
  53. https://medium.com/p/1f26b08429ad/share/twitter
  54. https://medium.com/p/1f26b08429ad/share/facebook
