   #[1]adventures in machine learning    convolutional neural networks
   tutorial in tensorflow comments feed [2]alternate [3]alternate

   menu

     * [4]home
     * [5]about
     * [6]coding the deep learning revolution ebook
     * [7]contact
     * [8]ebook / newsletter sign-up

   search: ____________________

convolutional neural networks tutorial in tensorflow

   by [9]admin | [10]convolutional neural networks

     * you are here:
     * [11]home
     * [12]deep learning
     * [13]convolutional neural networks tutorial in tensorflow

   apr 24
   [14]24
   convolutional neural networks tutorial - full diagram

   in the two previous tutorial posts, [15]an introduction to neural
   networks and [16]an introduction to tensorflow, three layer neural
   networks were created and used to predict [17]the mnist dataset.  they
   performed pretty well, with a successful prediction accuracy on the
   order of 97-98%.  however, to take the next step in improving the
   accuracy of our networks, we need to delve into deep learning.  a
   particularly useful type of deep learning neural network for image
   classification is the convolutional neural network.  it should be noted
   that convolutional neural networks can also be used for applications
   other than images, such as time series prediction (recurrent neural
   networks are also good at time series predictions     see [18]my tutorial
   here).  however, this tutorial will concentrate on image classification
   only.

   this convolutional neural networks tutorial will introduce these
   networks by building them in [19]tensorflow.  if you   re not familiar
   with tensorflow, i   d suggest checking out [20]my previously mentioned
   tutorial, which is a gentle introduction.  otherwise, you   re welcome to
   wing it.  another option is to build the convolutional neural network
   in keras, which is more syntactically stream-lined     you can see how to
   do this my brief [21]keras tutorial. finally, if you   d like to see how
   to implement convolutional neural networks using the tensorflow eager
   imperative programming api, see my [22]tensorflow eager tutorial.
     __________________________________________________________________

eager to learn more? get the book [23]here
     __________________________________________________________________


what   s the problem?

   as shown in the previous tutorials, multi-layer neural networks can
   perform pretty well in predicting things like digits in the mnist
   dataset.  this is especially true if we apply [24]some improvements.
   so why do we need any other architecture?  well, first off     the mnist
   dataset is quite simple.  the images are small (only 28 x 28 pixels),
   are single layered (i.e. greyscale, rather than a coloured 3 layer rgb
   image) and include pretty simple shapes (digits only, no other
   objects).  once we start trying to classify things in more complicated
   colour images, such as buses, cars, trains etc. , we run into problems
   with our accuracy.  what do we do?

   well, first, we can try to increase the number of layers in our neural
   network to make it deeper.  that will increase the complexity of the
   network and allow us to model more complicated functions.  however, it
   will come at a cost     the number of parameters (i.e. weights and
   biases) will rapidly increase.  this makes the model more prone to
   [25]overfitting and will prolong training times.  in fact,
   learning such difficult problems can become intractable for normal
   neural networks.  this leads us to a solution     convolutional neural
   networks.

what is a convolutional neural network?

   the most commonly associated idea with convolutional neural networks is
   the idea of a    moving filter    which passes through the image.  this
   moving filter, or convolution, applies to a certain neighbourhood of
   nodes (which may be the input nodes i.e. pixels) as shown below, where
   the filter applied is 0.5 x the node value:
   convolutional neural network tutorial - moving filter

   moving 2  2 filter (all weights = 0.5)

   as can be observed, only two outputs of the moving/convolutional filter
   have been shown     here we are mapping a 2  2 input square into a single
   output node.  the weight of the mapping of each input square, as
   previously mentioned, is 0.5 across all four inputs.  in other words,
   the following calculations were performed:

   \begin{align}
   out_1 &= 0.5 in_1 + 0.5 in_2 + 0.5 in_6 + 0.5 in_7 \\
   &= 0.5 \times 2.0 + 0.5 \times 3.0 + 0.5 \times 2.0 + 0.5 \times
   1.5  \\
   &= 4.25 \\
   out_2 &= 0.5 in_2 + 0.5 in_3 + 0.5 in_7 + 0.5 in_8 \\
   &= 0.5 \times 3.0 + 0.5 \times 0.0 + 0.5 \times 1.5 + 0.5 \times 0.5
   \\
   &= 2.5 \\
   \end{align}

   in a convolution operation, this 2  2 moving filter would shuffle across
   each possible x and y co-ordinate combination to populate the output
   nodes.  this operation can also be illustrated using our standard
   neural network node diagrams:
   convolutional neural network tutorial - moving filter node diagram

   moving 2  2 filter     node diagram

   the first position of the moving filter connections is shown with the
   blue lines, the second (x + 1) is shown with the green lines.  the
   weights of these connections, in this example, are all equal to 0.5.

   a couple of things can be observed about this convolutional operation,
   in comparison to our [26]previous understanding of standard neural
   networks:
     * sparse connections     notice that not every input node is connected
       to the output nodes.  this is contrary to fully connected neural
       networks, where every node in one layer is connected to every node
       in the following layer.
     * constant filter parameters / weights     each filter has constant
       parameters.  in other words, as the filter moves around the image
       the same weights are being applied.  each filter therefore
       performs a certain transformation across the whole image.   this is
       in contrast to fully connected neural networks, which have a
       different weight value for every connection
          + note, i am not saying that each weight is constant witihin the
            filter, as in the example above (i.e. with weights [0.5, 0.5,
            0.5, 0.5]).  the weights within the filter could be any
            combination of values depending on how the filters are
            trained.

   these two features of convolutional neural networks can significantly
   reduce the number of parameters required in the network, compared to
   fully connected neural networks.

   the output of the convolutional mapping is then passed through some
   form of non-linear activation function, often the [27]rectified linear
   unit activation function.

   this step in convolutional neural networks is often called feature
   mapping.  before we move onto the next main feature of convolutional
   neural networks, pooling, it is worth saying a few things about this
   idea.

feature mapping and multiple channels

   earlier i mentioned that the filter parameters i.e. the weights, are
   held constant as the filter moves through the input.  this allows the
   filter to be trained to recognise certain features within the input
   data.  in the case of images, it may learn to recognise shapes such as
   lines, edges and other distinctive shapes.  this is why the convolution
   step is often called feature mapping.  however, in order to classify
   well, at each convolutional stage we usually need multiple filters.  so
   in reality, the moving filter diagram above looks like this:
   convolutional neural networks tutorial - multiple filters

   multiple convolutional filters

   on the right you can now see stacked outputs, and that the separately
   trained filters each produce their own 2d output (for a 2d image).
   this is often referred to as having multiple channels.  each of these
   channels will end up being trained to detect certain key features in
   the image.  therefore, the output of the convolutional layer will
   actually be 3 dimensional (again, for a 2d image).  if the input is
   itself multi-channelled, as in the case of a colour image with rgb
   layers, the output of the convolutional layer will be 4d.  thankfully,
   as will be shown later, tensorflow can handle all of this mapping quite
   easily.

   don   t forget that the convolutional output for each node, over all the
   channels, are passed through an activation function.

   the next important part of convolutional neural networks is
   called pooling.

pooling

   the idea of pooling in convolutional neural networks is to do two
   things:
     * reduce the number of parameters in your network (pooling is also
       called    down-sampling    for this reason)
     * to make feature detection more robust by making it more impervious
       to scale and orientation changes

   so what is pooling?  again it is a    sliding window    type technique, but
   in this case, instead of applying weights the pooling applies some sort
   of statistical function over the values within the window.  most
   commonly, the function used is the max() function, so max pooling will
   take the maximum value within the window.  there are other variants
   such as mean pooling or l2-norm pooling which are also used at times.
   however, in this convolutional neural network tutorial we will only
   concentrate on max pooling.  the diagram below shows some max pooling
   in action:
   convolutional neural network tutorial - max pooling example

   max pooling example (with padding)

   we   ll go through a number of points relating to the diagram above:

basic function

   as can be observed in the diagram above, the different coloured boxes
   on the input nodes / squares represent a sliding 2  2 window.  max
   pooling is performed on the nodes within the sliding window i.e. the
   simple maximum is taken of the output of the nodes.  in other words:

   \begin{align}
   out_1 &= max(in_1, in_2, in_6, in_7) \\
   out_2 &= max(in_3, in_4, in_8, in_9) \\
   out_3 &= max(in_5, pad_1, in_{10}, pad_2)  \\
   \end{align}

strides and down-sampling

   you may have noticed that in the convolutional / moving filter example
   above, the 2  2 filter moved only a single place in the x and y
   direction through the image / input.  this led to an overlap of filter
   areas.  this is called a stride of [1, 1]     that is, the filter moves 1
   step in the x and y directions.  with max pooling, the stride is
   usually set so that there is no overlap between the regions.  in this
   case, we need a stride of 2 (or [2, 2]) to avoid overlap.  this can be
   observed in the figure above when the max pooling box moves two steps
   in the x direction.  notice that having a stride of 2 actually reduces
   the dimensionality of the output.  we have gone from a 5  5 input grid
   (ignoring the 0.0 padding for the moment) to a 3  3 output grid     this
   is called down-sampling, and can be used to reduce the number of
   parameters in the model.

padding

   in the image above, you will notice the grey shaded boxes around the
   outside, all with 0.0 in the middle.  these are padding nodes     dummy
   nodes that are introduced so that 2  2 max pooling filter can make 3
   steps in the x and y directions with a stride of 2, despite there being
   only 5 nodes to traverse in either the x or y directions.  because the
   values are 0.0, with a rectified linear unit activation of the previous
   layer (which can   t output a negative number), these nodes will never
   actually be selected in the max pooling process.  tensorflow has
   padding options which need to be considered, and these will be
   discussed later in the tutorial.

   this covers how pooling works, but why is it included in convolutional
   neural networks?

why is pooling used in convolutional neural networks?

   in addition to the function of down-sampling, pooling is used in
   convolutional neural networks to make the detection of certain features
   in the input invariant to scale and orientation changes.  another way
   of thinking about what they do is that they generalise over lower
   level, more complex information.  consider the case where we have a
   number of convolutional filters that, during training, have learnt
   to detect the digit    9    in various orientations within the input
   images.  in order for the convolutional neural network to learn to
   classify the appearance of    9    in the image correctly, it needs to
   activate in some way no matter what the orientation of the digit is
   (except when it looks like a    6    that is). that is what pooling can
   assist with, consider the diagram below:
   convolutional neural networks tutorial - stylised representation of
   pooling

   stylised representation of pooling

   the diagram above is a kind of stylised representation of the pooling
   operation.  consider a small region of an input image that has the
   digit    9    in it (green box).  during training we have a few
   convolutional filters that have learnt to  activate when they    see    a
      9    shape in the image, but they activate most strongly depending on
   what orientation that    9    is.  we want the convolutional neural network
   to recognise a    9    regardless of what orientation it is in.  so
   the pooling    looks    over the output of these three filters and will
   give a high output so long as any one of these filters has a high
   activation.

   pooling acts as a generaliser of the lower level information and so
   enables us to move from high resolution data to lower resolution
   information.  in other words, pooling coupled with convolutional
   filters attempt to detect objects within an image.

the final picture

   the image below from wikipedia shows the final image of a fully
   developed convolutional neural network:
   convolutional neural networks tutorial - full diagram

   full convolutional neural network     by aphex34 (own work) [[28]cc by-sa
   4.0], [29]via wikimedia commons
   let   s step through this image from left to right.  first we have the
   input image of a robot.  then multiple convolutional filters (these
   would include rectified linear unit activations), followed by pooling /
   sub-sampling.  then we have another layer of convolution and pooling.
   notice the number of channels (the stacked blue squares) and the
   reduction in the x, y sizes of each channel as the sub-sampling /
   down-sampling occurs in the pooling layers.  finally, we reach a fully
   connected layer before the output.  this layer hasn   t been mentioned
   yet, and deserves some discussion.

the fully connected layer

   at the output of the convolutional-pooling layers we have moved from
   high resolution, low level data about the pixels to representations of
   objects within the image.  the purpose of these final, fully connected
   layers is to make classifications regarding these objects     in other
   words, we bolt a [30]standard neural network classifier onto the end of
   a trained object detector.  as you can observe, the output of the final
   pooling layer is many channels of x x y matrices.  to connect the
   output of the pooling layer to the fully connected layer, we need to
   flatten this output into a single (n x 1) tensor.

   let   s say we have 100 channels of 2 x 2 pooling matrices.  this means
   we need to flatten all of this data into a vector with one column and 2
   x 2 x 100 = 400 rows.  i   ll show how we can do this in tensorflow
   below.

   now we have covered the basics of how convolutional neural networks are
   structured and why they are created this way.  it is now time to show
   how we implement such a network in tensorflow.

a tensorflow based convolutional neural network

   tensorflow makes it easy to create convolutional neural networks once
   you understand some of the nuances of the framework   s handling of
   them.  in this tutorial, we are going to create a convolutional neural
   network with the structure detailed in the image below.  the network we
   are going to build will perform mnist digit classification, as we have
   performed in previous tutorials ([31]here and [32]here).  as usual, the
   full code for this tutorial can be found [33]here.
   convolutional neural network tutorial - example

   example convolutional neural network

   as can be observed, we start with the mnist 28  28 greyscale images of
   digits.  we then create 32, 5  5 convolutional filters / channels plus
   relu (rectified linear unit) node activations.  after this, we still
   have a height and width of 28 nodes.  we then perform down-sampling by
   applying a 2  2 max pooling operation with a stride of 2.  layer 2
   consists of the same structure, but now with 64 filters / channels and
   another stride-2 max pooling down-sample.  we then flatten the output
   to get a fully connected layer with 3164 nodes, followed by another
   hidden layer of 1000 nodes.  these layers will use relu node
   activations.  finally, we use a softmax classification layer to output
   the 10 digit probabilities.

   let   s step through the code.

input data and placeholders

   the code below sets up the input data and placeholders for the
   classifier.
import tensorflow as tf
from tensorflow.examples.tutorials.mnist import input_data
mnist = input_data.read_data_sets("mnist_data/", one_hot=true)

# python optimisation variables
learning_rate = 0.0001
epochs = 10
batch_size = 50

# declare the training data placeholders
# input x - for 28 x 28 pixels = 784 - this is the flattened image data that is
drawn from
# mnist.train.nextbatch()
x = tf.placeholder(tf.float32, [none, 784])
# dynamically reshape the input
x_shaped = tf.reshape(x, [-1, 28, 28, 1])
# now declare the output data placeholder - 10 digits
y = tf.placeholder(tf.float32, [none, 10])

   tensorflow has a handy loader for the mnist data which is sorted out in
   the first couple of lines.  after that we have some variable
   declarations which determine the optimisation behaviour (learning rate,
   batch size etc.).  next, we declare a placeholder (see [34]this
   tutorial for explanations of placeholders) for the image input data,
   x.  the image input data will be extracted using the
   mnist.train.nextbatch() function, which supplies a flattened 28  28=784
   node, single channel greyscale representation of the image. however,
   before we can use this data in the tensorflow convolution and
   pooling functions, such as conv2d() and max_pool() we need to reshape
   the data as these functions take 4d data only.

   the format of the data to be supplied is [i, j, k, l] where i is the
   number of training samples, j is the height of the image, k is
   the weight and l is the channel number.  because we have a greyscale
   image, l will always be equal to 1 (if we had an rgb image, it would be
   equal to 3).  the mnist images are 28 x 28, so both j and k are equal
   to 28.  when we reshape the input data x into x_shaped, theoretically
   we don   t know the size of the first dimension of x, so we don   t know
   what i is.  however, tf.reshape() allows us to put -1 in place of i and
   it will dynamically reshape based on the number of training samples as
   the training is performed.  so we use [-1, 28, 28, 1] for the second
   argument in tf.reshape().

   finally, we need a placeholder for our output training data, which is a
   [?, 10] sized tensor     where the 10 stands for the 10 possible digits
   to be classified.  we will use the mnist.train.next_batch() to extract
   the digits labels as a one-hot vector     in other words, a digit of    3   
   will be represented as [0, 0, 0, 1, 0, 0, 0, 0, 0, 0].

defining the convolution layers

   because we have to create a couple of convolutional layers, it   s best
   to create a function to reduce repetition:
def create_new_conv_layer(input_data, num_input_channels, num_filters, filter_sh
ape, pool_shape, name):
    # setup the filter input shape for tf.nn.conv_2d
    conv_filt_shape = [filter_shape[0], filter_shape[1], num_input_channels,
                      num_filters]

    # initialise weights and bias for the filter
    weights = tf.variable(tf.truncated_normal(conv_filt_shape, stddev=0.03),
                                      name=name+'_w')
    bias = tf.variable(tf.truncated_normal([num_filters]), name=name+'_b')

    # setup the convolutional layer operation
    out_layer = tf.nn.conv2d(input_data, weights, [1, 1, 1, 1], padding='same')

    # add the bias
    out_layer += bias

    # apply a relu non-linear activation
    out_layer = tf.nn.relu(out_layer)

    # now perform max pooling
    ksize = [1, pool_shape[0], pool_shape[1], 1]
    strides = [1, 2, 2, 1]
    out_layer = tf.nn.max_pool(out_layer, ksize=ksize, strides=strides,
                               padding='same')

    return out_layer

   i   ll step through each line/block of this function below:
conv_filt_shape = [filter_shape[0], filter_shape[1], num_input_channels,
                      num_filters]

   this line sets up a variable to hold the shape of the weights that
   determine the behaviour of the 5  5 convolutional filter.  the format
   that the conv2d() function receives for the filter is: [filter_height,
   filter_width, in_channels, out_channels].  the height and width of the
   filter are provided in the filter_shape variables (in this case [5,
   5]).  the number of input channels, for the first convolutional layer
   is simply 1, which corresponds to the single channel greyscale mnist
   image.  however, for the second convolutional layer it takes the output
   of the first convolutional layer, which has a 32 channel
   output.  therefore, for the second convolutional layer, the
   input channels is 32.  as defined in the block diagram above, the
   number of output channels of the first layer is 32, and for the second
   layer it is 64.
# initialise weights and bias for the filter
weights = tf.variable(tf.truncated_normal(conv_filt_shape, stddev=0.03),
                                  name=name+'_w')
bias = tf.variable(tf.truncated_normal([num_filters]), name=name+'_b')

   in these lines we create the weights and bias for the convolutional
   filter and randomly initialise the tensors.  if you need to brush up
   on these concepts, check out [35]this tutorial.
# setup the convolutional layer operation
out_layer = tf.nn.conv2d(input_data, weights, [1, 1, 1, 1], padding='same')

   this line is where we setup the convolutional filter operation.  the
   variable input_data is self-explanatory, as are the weights.  the size
   of the weights tensor show tensorflow what size the convolutional
   filter should be.  the next argument [1, 1, 1, 1] is the strides
   parameter that is required in conv2d().  in this case, we want the
   filter to move in steps of 1 in both the x and y directions (or height
   and width directions).  this information is conveyed in the strides[1]
   and strides[2] values     both equal to 1 in this case.  the first and
   last values of strides are always equal to 1, if they were not, we
   would be moving the filter between training samples or between
   channels, which we don   t want to do.  the final parameter is the
   padding.  padding determines the output size of each channel and when
   it is set to    same    it produces dimensions of:

   out_height = ceil(float(in_height) / float(strides[1]))
   out_width  = ceil(float(in_width) / float(strides[2]))

   for the first convolutional layer, in_height = in_width = 28,
   and strides[1] = strides[2] = 1.  therefore the padding of the input
   with 0.0 nodes will be arranged so that the out_height = out_width = 28
       there will be no change in size of the output.  this padding is to
   avoid the fact that, when traversing a (x,y) sized image or input with
   a convolutional filter of size (n,m), with a stride of 1 the output
   would be (x-n+1,y-m+1).  so in this case, without padding, the output
   size would be (24,24).  we want to keep the sizes of the outputs easy
   to track, so we chose the    same    option as the padding so we keep the
   same size.
# add the bias
out_layer += bias
# apply a relu non-linear activation
out_layer = tf.nn.relu(out_layer)

   in the two lines above, we simply add a bias to the output of the
   convolutional filter, then apply a relu non-linear activation function.
# now perform max pooling
ksize = [1, pool_shape[0], pool_shape[1], 1]
strides = [1, 2, 2, 1]
out_layer = tf.nn.max_pool(out_layer, ksize=ksize, strides=strides,
                               padding='same')

return out_layer

   the max_pool() function takes a tensor as its first input over which to
   perform the pooling.  the next two arguments ksize and strides define
   the operation of the pooling.  ignoring the first and last values of
   these vectors (which will always be set to 1), the middle values of
   ksize (pool_shape[0] and pool_shape[1]) define the shape of the max
   pooling window in the x and y directions.  in this convolutional neural
   networks example, we are using a 2  2 max pooling window size.  the same
   applies with the strides vector     because we want to down-sample, in
   this example we are choosing strides of size 2 in both the x and y
   directions (strides[1] and strides[2]). this will halve the input size
   of the (x,y) dimensions.

   finally, we have another example of a padding argument.  the same rules
   apply for the    same    option as for the convolutional function
   conv2d().  namely:

   out_height = ceil(float(in_height) / float(strides[1]))
   out_width  = ceil(float(in_width) / float(strides[2]))

   punching in values of 2 for strides[1] and strides[2] for the first
   convolutional layer we get an output size of (14, 14).  this is a
   halving of the input size (28, 28), which is what we are looking for.
   again, tensorflow will organise the padding so that this output shape
   is what is achieved, which makes things nice and clean for us.

   finally we return the out_layer object, which is actually a sub-graph
   of its own, containing all the operations and weight variables within
   it.  we create the two convolutional layers in the main program by
   calling the following commands:
# create some convolutional layers
layer1 = create_new_conv_layer(x_shaped, 1, 32, [5, 5], [2, 2], name='layer1')
layer2 = create_new_conv_layer(layer1, 32, 64, [5, 5], [2, 2], name='layer2')

   as you can see, the input to layer1 is the shaped input x_shaped and
   the input to layer2 is the output of the first layer.  now we can move
   on to creating the fully connected layers.

the fully connected layers

   as previously discussed, first we have to flatten out the output from
   the final convolutional layer.  it is now a 7  7 grid of nodes with 64
   channels, which equates to 3136 nodes per training sample.  we can use
   tf.reshape() to do what we need:
flattened = tf.reshape(layer2, [-1, 7 * 7 * 64])

   again, we have a dynamically calculated first dimension (the -1 above),
   corresponding to the number of input samples in the training batch.
   next we setup the first fully connected layer:
# setup some weights and bias values for this layer, then activate with relu
wd1 = tf.variable(tf.truncated_normal([7 * 7 * 64, 1000], stddev=0.03), name='wd
1')
bd1 = tf.variable(tf.truncated_normal([1000], stddev=0.01), name='bd1')
dense_layer1 = tf.matmul(flattened, wd1) + bd1
dense_layer1 = tf.nn.relu(dense_layer1)

   if the above operations are unfamiliar to you, please check out my
   previous [36]tensorflow tutorial.  basically we are initialising the
   weights of the fully connected layer, multiplying them with the
   flattened convolutional output, then adding a bias.  finally, a relu
   activation is applied.  the next layer is defined by:
# another layer with softmax activations
wd2 = tf.variable(tf.truncated_normal([1000, 10], stddev=0.03), name='wd2')
bd2 = tf.variable(tf.truncated_normal([10], stddev=0.01), name='bd2')
dense_layer2 = tf.matmul(dense_layer1, wd2) + bd2
y_ = tf.nn.softmax(dense_layer2)

   this layer connects to the output, and therefore we use a soft-max
   activation to produce the predicted output values y_.  we have now
   defined the basic structure of our convolutional neural network.  let   s
   now define the cost function.

the cross-id178 cost function

   we could develop our own [37]cross-id178 cost expression, as we did
   in the [38]previous tensorflow tutorial, based on the value y_.
   however, then we have to be careful about handling nan values.
   thankfully, tensorflow provides a handy function which
   applies soft-max followed by cross-id178 loss:
cross_id178 = tf.reduce_mean(tf.nn.softmax_cross_id178_with_logits(logits=de
nse_layer2, labels=y))

   the function softmax_cross_id178_with_logits() takes two arguments    
   the first (logits) is the output of the id127 of the
   final layer (plus bias) and the second is the training target vector.
   the function first takes the soft-max of the id127,
   then compares it to the training target using cross-id178.  the
   result is the cross-id178 calculation per training sample, so we need
   to reduce this tensor into a scalar (a single value).  to do this we
   use tf.reduce_mean() which takes a mean of the tensor.

the training of the convolutional neural network

   the following code is the remainder of what is required to train the
   network.  it is a replication of what is explained in my [39]previous
   tensorflow tutorial, so please refer to that tutorial if anything is
   unclear.  we   ll be using [40]mini-batches to train our network.  the
   essential structure is:
     * create an optimiser
     * create correct prediction and accuracy evaluation operations
     * initialise the operations
     * determine the number of batch runs within an training epoch
     * for each epoch:
          + for each batch:
               o extract the batch data
               o run the optimiser and cross-id178 operations
               o add to the average cost
          + calculate the current test accuracy
          + print out some results
     * calculate the final test accuracy and print

   the code to execute this is:
# add an optimiser
optimiser = tf.train.adamoptimizer(learning_rate=learning_rate).minimize(cross_e
ntropy)

# define an accuracy assessment operation
correct_prediction = tf.equal(tf.argmax(y, 1), tf.argmax(y_, 1))
accuracy = tf.reduce_mean(tf.cast(correct_prediction, tf.float32))

# setup the initialisation operator
init_op = tf.global_variables_initializer()

with tf.session() as sess:
    # initialise the variables
    sess.run(init_op)
    total_batch = int(len(mnist.train.labels) / batch_size)
    for epoch in range(epochs):
        avg_cost = 0
        for i in range(total_batch):
            batch_x, batch_y = mnist.train.next_batch(batch_size=batch_size)
            _, c = sess.run([optimiser, cross_id178],
                            feed_dict={x: batch_x, y: batch_y})
            avg_cost += c / total_batch
        test_acc = sess.run(accuracy,
                       feed_dict={x: mnist.test.images, y: mnist.test.labels})
        print("epoch:", (epoch + 1), "cost =", "{:.3f}".format(avg_cost), "
                 test accuracy: {:.3f}".format(test_acc))

    print("\ntraining complete!")
    print(sess.run(accuracy, feed_dict={x: mnist.test.images, y: mnist.test.labe
ls}))

   the final code can be found on this site   s [41]github repository.  note
   the final code on that repository contains some tensorboard
   visualisation operations, which have not been covered in this tutorial
   and will have a dedicated future article to explain.

   caution:  this is a relatively large network and on a standard home
   computer is likely to take at least 10-20 minutes to run.

the results

   running the above code will give the following output:
epoch: 1 cost = 0.739  test accuracy: 0.911
epoch: 2 cost = 0.169  test accuracy: 0.960
epoch: 3 cost = 0.100  test accuracy: 0.978
epoch: 4 cost = 0.074  test accuracy: 0.979
epoch: 5 cost = 0.057  test accuracy: 0.984
epoch: 6 cost = 0.047  test accuracy: 0.984
epoch: 7 cost = 0.040  test accuracy: 0.986
epoch: 8 cost = 0.034  test accuracy: 0.986
epoch: 9 cost = 0.029  test accuracy: 0.989
epoch: 10 cost = 0.025  test accuracy: 0.990

training complete!
0.9897

   we can also plot the test accuracy versus the number of epoch   s using
   tensorboard (tensorflow   s visualisation suite):
   convolutional neural network tutorial - mnist accuracy

   convolutional neural network mnist accuracy

   as can be observed, after 10 epochs we have reached an impressive
   prediction accuracy of 99%.  this result has been achieved without
   extensive optimisation of the convolutional neural network   s
   parameters, and also without any form of [42]regularisation.  this is
   compared to the best accuracy we could achieve in our standard neural
   network ~98%     as can be observed in [43]the previous tutorial.

   the accuracy difference will be even more prominent when comparing
   standard neural networks with convolutional neural networks on more
   complicated data-sets, like the [44]cifar data.  however, that is a
   topic for another day.  have fun using tensorflow and convolutional
   neural networks!  by the way, if you want to see how to build a neural
   network in keras, a more stream-lined framework, check out my [45]keras
   tutorial. also, if you   d like to explore more deep learning
   architectures in tensorflow, check out my [46]recurrent neural networks
   and lstm tutorial.
     __________________________________________________________________

eager to learn more? get the book [47]here
     __________________________________________________________________


about the author

     [48]thimira amaratunga says:
   [49]may 10, 2017 at 4:53 pm

   this is an excellent tutorial. thank you.
   i   ve added a link to here on my blog    
   [50]http://www.codesofinterest.com/p/resources.html
   i   m sure my readers too will find these tutorials very useful.
     * dirk gooris says:
       [51]august 4, 2018 at 5:59 pm
       andy,
       well done, this is outstanding work, many thanks for this article !
       the same applies for the keras article. your tutorials are easy to
       follow and one can get familiar with the topic in an enjoyable way.
       kind regards.
          + andy says:
            [52]august 6, 2018 at 1:53 am
            thanks dirk, glad they are a help for you

     asri says:
   [53]november 7, 2017 at 7:32 am

   hello, thanks for such detailed post. i was able to understand and
   implement the id98. thanks again!
   however, once i have trained the network, how can i deploy it/ make it
   available for others to use? would you mind illustrating an end-to-end
   flow(as would happen in real life)

     volvet says:
   [54]december 9, 2017 at 5:46 am

   this is a great post on the id98. i would like to introduce id98 to my
   guys with lots of contents from your post. thank you!

     vladimir says:
   [55]march 25, 2018 at 1:41 pm

   the best and most clearest explanation of id98!
   thanks god i found this.
   thank you for this.
     * andy says:
       [56]march 25, 2018 at 7:33 pm
       thanks vladimir, glad it helped

     prof. mohamed ezz says:
   [57]april 5, 2018 at 5:20 am

   great andy it awesome explanation for id98
   do you have any online course in id98?
     * andy says:
       [58]april 5, 2018 at 7:08 am
       hi prof. ezz     not yet but i am thinking about either a book or
       course. stay tuned i suppose

     parisa says:
   [59]april 16, 2018 at 8:03 am

   thank you so much     

     mohan radhakrishnan says:
   [60]may 4, 2018 at 1:06 pm

   this is the by far the best combination of lucid writing style and
   segmented code to match the sections.
     * andy says:
       [61]may 4, 2018 at 9:03 pm
       thanks mohan, i appreciate the feedback

     edwin says:
   [62]may 27, 2018 at 2:36 pm

   the explanation in this tutorial is easy to follow and very clear. i
   enjoy reading your tutorial. thank you very much.
     * andy says:
       [63]may 27, 2018 at 8:14 pm
       thanks edwin, glad you found it useful



   edwin says:
   [64]may 27, 2018 at 2:36 pm

   the explanation in this tutorial is easy to follow and very clear. i
   enjoy reading your tutorial. thank you very much.



   aryan says:
   [65]june 11, 2018 at 6:08 am

   your post was by far the best. you explained every intricate details
   very easily. i went to many websites but this was by far the best
   tutorial ever seen. i never write replies but this was really good

     * andy says:
       [66]june 11, 2018 at 6:39 am
       thanks aryan, glad it helped



   prashant brahmbhatt says:
   [67]july 27, 2018 at 8:24 am

   this is the best self learning site i have ever came across for deep
   learning. it is so appreciable! i was finding it hard two read through
   the arguments on my own relating it with the logic. you made it piece
   of cake!



   dhvani shah says:
   [68]august 2, 2018 at 2:50 pm

   best article till date on id98 with tf. thanks for sharing

     * andy says:
       [69]august 2, 2018 at 9:29 pm
       thanks dhvani, glad it was useful

   ____________________ (button)

   recent posts
     * [70]an introduction to id178, cross id178 and kl divergence in
       machine learning
     * [71]google colaboratory introduction     learn how to build deep
       learning systems in google colaboratory
     * [72]keras, eager and tensorflow 2.0     a new tf paradigm
     * [73]introduction to tensorboard and tensorflow visualization
     * [74]tensorflow eager tutorial

   recent comments
     * andry on [75]neural networks tutorial     a pathway to deep learning
     * sandipan on [76]keras lstm tutorial     how to easily build a
       powerful deep learning language model
     * andy on [77]neural networks tutorial     a pathway to deep learning
     * martin on [78]neural networks tutorial     a pathway to deep learning
     * uri on [79]the vanishing gradient problem and relus     a tensorflow
       investigation

   archives
     * [80]march 2019
     * [81]january 2019
     * [82]october 2018
     * [83]september 2018
     * [84]august 2018
     * [85]july 2018
     * [86]june 2018
     * [87]may 2018
     * [88]april 2018
     * [89]march 2018
     * [90]february 2018
     * [91]november 2017
     * [92]october 2017
     * [93]september 2017
     * [94]august 2017
     * [95]july 2017
     * [96]may 2017
     * [97]april 2017
     * [98]march 2017

   categories
     * [99]amazon aws
     * [100]cntk
     * [101]convolutional neural networks
     * [102]cross id178
     * [103]deep learning
     * [104]gensim
     * [105]gpus
     * [106]keras
     * [107]id168s
     * [108]lstms
     * [109]neural networks
     * [110]nlp
     * [111]optimisation
     * [112]pytorch
     * [113]recurrent neural networks
     * [114]id23
     * [115]tensorboard
     * [116]tensorflow
     * [117]tensorflow 2.0
     * [118]weight initialization
     * [119]id97

   meta
     * [120]log in
     * [121]entries rss
     * [122]comments rss
     * [123]wordpress.org

   copyright text 2019 by adventures in machine learning.   -  designed by
   [124]thrive themes | powered by [125]wordpress

   (button) close dialog

   session expired

   [126]please log in again. the login page will open in a new tab. after
   logging in you can close it and return to this page.

   >

   we use cookies to ensure that we give you the best experience on our
   website. if you continue to use this site we will assume that you are
   happy with it.[127]ok

references

   visible links
   1. https://adventuresinmachinelearning.com/convolutional-neural-networks-tutorial-tensorflow/feed/
   2. https://adventuresinmachinelearning.com/wp-json/oembed/1.0/embed?url=https://adventuresinmachinelearning.com/convolutional-neural-networks-tutorial-tensorflow/
   3. https://adventuresinmachinelearning.com/wp-json/oembed/1.0/embed?url=https://adventuresinmachinelearning.com/convolutional-neural-networks-tutorial-tensorflow/&format=xml
   4. https://www.adventuresinmachinelearning.com/
   5. https://adventuresinmachinelearning.com/about/
   6. https://adventuresinmachinelearning.com/coding-deep-learning-ebook/
   7. https://adventuresinmachinelearning.com/contact/
   8. https://adventuresinmachinelearning.com/ebook-newsletter-sign/
   9. https://adventuresinmachinelearning.com/author/admin/
  10. https://adventuresinmachinelearning.com/category/deep-learning/convolutional-neural-networks/
  11. https://adventuresinmachinelearning.com/
  12. https://adventuresinmachinelearning.com/category/deep-learning/
  13. https://adventuresinmachinelearning.com/convolutional-neural-networks-tutorial-tensorflow/
  14. http://adventuresinmachinelearning.com/convolutional-neural-networks-tutorial-tensorflow/#comments
  15. https://adventuresinmachinelearning.com/neural-networks-tutorial/
  16. https://adventuresinmachinelearning.com/python-tensorflow-tutorial/
  17. https://en.wikipedia.org/wiki/mnist_database
  18. https://adventuresinmachinelearning.com/recurrent-neural-networks-lstm-tutorial-tensorflow/
  19. https://www.tensorflow.org/
  20. https://adventuresinmachinelearning.com/python-tensorflow-tutorial/
  21. https://adventuresinmachinelearning.com/keras-tutorial-id98-11-lines/
  22. https://adventuresinmachinelearning.com/tensorflow-eager-tutorial/
  23. https://adventuresinmachinelearning.com/coding-deep-learning-ebook/
  24. https://adventuresinmachinelearning.com/improve-neural-networks-part-1/
  25. https://adventuresinmachinelearning.com/improve-neural-networks-part-1/
  26. https://adventuresinmachinelearning.com/neural-networks-tutorial/
  27. https://en.wikipedia.org/wiki/rectifier_(neural_networks)
  28. http://creativecommons.org/licenses/by-sa/4.0
  29. https://commons.wikimedia.org/wiki/file:typical_id98.png
  30. https://adventuresinmachinelearning.com/neural-networks-tutorial/
  31. https://adventuresinmachinelearning.com/neural-networks-tutorial/
  32. https://adventuresinmachinelearning.com/python-tensorflow-tutorial/
  33. https://github.com/adventuresinml/adventures-in-ml-code
  34. https://adventuresinmachinelearning.com/python-tensorflow-tutorial/
  35. https://adventuresinmachinelearning.com/neural-networks-tutorial/
  36. https://adventuresinmachinelearning.com/python-tensorflow-tutorial/
  37. https://en.wikipedia.org/wiki/cross_id178
  38. https://adventuresinmachinelearning.com/python-tensorflow-tutorial/
  39. https://adventuresinmachinelearning.com/python-tensorflow-tutorial/
  40. https://adventuresinmachinelearning.com/stochastic-gradient-descent/
  41. https://github.com/adventuresinml/adventures-in-ml-code
  42. https://adventuresinmachinelearning.com/improve-neural-networks-part-1/
  43. https://adventuresinmachinelearning.com/python-tensorflow-tutorial/
  44. https://www.cs.toronto.edu/~kriz/cifar.html
  45. https://adventuresinmachinelearning.com/keras-tutorial-id98-11-lines/
  46. https://adventuresinmachinelearning.com/recurrent-neural-networks-lstm-tutorial-tensorflow/
  47. https://adventuresinmachinelearning.com/coding-deep-learning-ebook/
  48. http://www.codesofinterest.com/
  49. https://adventuresinmachinelearning.com/convolutional-neural-networks-tutorial-tensorflow/#comments/665
  50. http://www.codesofinterest.com/p/resources.html
  51. https://adventuresinmachinelearning.com/convolutional-neural-networks-tutorial-tensorflow/#comments/799
  52. https://adventuresinmachinelearning.com/convolutional-neural-networks-tutorial-tensorflow/#comments/800
  53. https://adventuresinmachinelearning.com/convolutional-neural-networks-tutorial-tensorflow/#comments/755
  54. https://adventuresinmachinelearning.com/convolutional-neural-networks-tutorial-tensorflow/#comments/758
  55. https://adventuresinmachinelearning.com/convolutional-neural-networks-tutorial-tensorflow/#comments/766
  56. https://adventuresinmachinelearning.com/convolutional-neural-networks-tutorial-tensorflow/#comments/767
  57. https://adventuresinmachinelearning.com/convolutional-neural-networks-tutorial-tensorflow/#comments/773
  58. https://adventuresinmachinelearning.com/convolutional-neural-networks-tutorial-tensorflow/#comments/774
  59. https://adventuresinmachinelearning.com/convolutional-neural-networks-tutorial-tensorflow/#comments/777
  60. https://adventuresinmachinelearning.com/convolutional-neural-networks-tutorial-tensorflow/#comments/780
  61. https://adventuresinmachinelearning.com/convolutional-neural-networks-tutorial-tensorflow/#comments/781
  62. https://adventuresinmachinelearning.com/convolutional-neural-networks-tutorial-tensorflow/#comments/783
  63. https://adventuresinmachinelearning.com/convolutional-neural-networks-tutorial-tensorflow/#comments/785
  64. https://adventuresinmachinelearning.com/convolutional-neural-networks-tutorial-tensorflow/#comments/784
  65. https://adventuresinmachinelearning.com/convolutional-neural-networks-tutorial-tensorflow/#comments/788
  66. https://adventuresinmachinelearning.com/convolutional-neural-networks-tutorial-tensorflow/#comments/789
  67. https://adventuresinmachinelearning.com/convolutional-neural-networks-tutorial-tensorflow/#comments/795
  68. https://adventuresinmachinelearning.com/convolutional-neural-networks-tutorial-tensorflow/#comments/796
  69. https://adventuresinmachinelearning.com/convolutional-neural-networks-tutorial-tensorflow/#comments/797
  70. https://adventuresinmachinelearning.com/cross-id178-kl-divergence/
  71. https://adventuresinmachinelearning.com/introduction-to-google-colaboratory/
  72. https://adventuresinmachinelearning.com/keras-eager-and-tensorflow-2-0-a-new-tf-paradigm/
  73. https://adventuresinmachinelearning.com/introduction-to-tensorboard-and-tensorflow-visualization/
  74. https://adventuresinmachinelearning.com/tensorflow-eager-tutorial/
  75. https://adventuresinmachinelearning.com/neural-networks-tutorial/#comments/139
  76. https://adventuresinmachinelearning.com/keras-lstm-tutorial/#comments/5153
  77. https://adventuresinmachinelearning.com/neural-networks-tutorial/#comments/136
  78. https://adventuresinmachinelearning.com/neural-networks-tutorial/#comments/135
  79. https://adventuresinmachinelearning.com/vanishing-gradient-problem-tensorflow/#comments/5233
  80. https://adventuresinmachinelearning.com/2019/03/
  81. https://adventuresinmachinelearning.com/2019/01/
  82. https://adventuresinmachinelearning.com/2018/10/
  83. https://adventuresinmachinelearning.com/2018/09/
  84. https://adventuresinmachinelearning.com/2018/08/
  85. https://adventuresinmachinelearning.com/2018/07/
  86. https://adventuresinmachinelearning.com/2018/06/
  87. https://adventuresinmachinelearning.com/2018/05/
  88. https://adventuresinmachinelearning.com/2018/04/
  89. https://adventuresinmachinelearning.com/2018/03/
  90. https://adventuresinmachinelearning.com/2018/02/
  91. https://adventuresinmachinelearning.com/2017/11/
  92. https://adventuresinmachinelearning.com/2017/10/
  93. https://adventuresinmachinelearning.com/2017/09/
  94. https://adventuresinmachinelearning.com/2017/08/
  95. https://adventuresinmachinelearning.com/2017/07/
  96. https://adventuresinmachinelearning.com/2017/05/
  97. https://adventuresinmachinelearning.com/2017/04/
  98. https://adventuresinmachinelearning.com/2017/03/
  99. https://adventuresinmachinelearning.com/category/amazon-aws/
 100. https://adventuresinmachinelearning.com/category/deep-learning/cntk/
 101. https://adventuresinmachinelearning.com/category/deep-learning/convolutional-neural-networks/
 102. https://adventuresinmachinelearning.com/category/loss-functions/cross-id178/
 103. https://adventuresinmachinelearning.com/category/deep-learning/
 104. https://adventuresinmachinelearning.com/category/nlp/gensim/
 105. https://adventuresinmachinelearning.com/category/deep-learning/gpus/
 106. https://adventuresinmachinelearning.com/category/deep-learning/keras/
 107. https://adventuresinmachinelearning.com/category/loss-functions/
 108. https://adventuresinmachinelearning.com/category/deep-learning/lstms/
 109. https://adventuresinmachinelearning.com/category/deep-learning/neural-networks/
 110. https://adventuresinmachinelearning.com/category/nlp/
 111. https://adventuresinmachinelearning.com/category/optimisation/
 112. https://adventuresinmachinelearning.com/category/deep-learning/pytorch/
 113. https://adventuresinmachinelearning.com/category/deep-learning/recurrent-neural-networks/
 114. https://adventuresinmachinelearning.com/category/reinforcement-learning/
 115. https://adventuresinmachinelearning.com/category/deep-learning/tensorflow/tensorboard/
 116. https://adventuresinmachinelearning.com/category/deep-learning/tensorflow/
 117. https://adventuresinmachinelearning.com/category/deep-learning/tensorflow/tensorflow-2-0/
 118. https://adventuresinmachinelearning.com/category/deep-learning/weight-initialization/
 119. https://adventuresinmachinelearning.com/category/nlp/id97/
 120. https://adventuresinmachinelearning.com/wp-login.php
 121. https://adventuresinmachinelearning.com/feed/
 122. https://adventuresinmachinelearning.com/comments/feed/
 123. https://wordpress.org/
 124. https://www.thrivethemes.com/
 125. http://www.wordpress.org/
 126. https://adventuresinmachinelearning.com/wp-login.php
 127. http://adventuresinmachinelearning.com/convolutional-neural-networks-tutorial-tensorflow/

   hidden links:
 129. https://adventuresinmachinelearning.com/author/admin/
