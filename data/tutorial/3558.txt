   #[1]publisher [2]medium [3]alternate

   [4]homepage
   [5]homepage
   [6]sign in[7]get started

   [8]hacker noon
     * [9]latest
     * [10]editors' choice
     * [11]terms faq
     * [12]sign up for 2.0
     * [13]future of search
     __________________________________________________________________

learning ai if you suck at math         p5         deep learning and convolutional neural
nets in plain english!

   go to the profile of daniel jeffries
   [14]daniel jeffries (button) blockedunblock (button) followfollowing
   feb 27, 2017
   [1*arz_ljehui9ricowubmmma.jpeg]

   welcome to part five of learning ai if you suck at math. if you missed
   parts [15]1, [16]2, [17]3, [18]4, [19]6, and [20]7 be sure to check
   them out!

   today, we   re going to write our own python image recognition program.

   to do that, we   ll explore a powerful deep learning architecture called
   a deep convolutional neural network (did98).

   convnets are the workhorses of id161. they power everything
   from self-driving cars to google   s image search. at tensorflow summit
   2017, [21]a researcher showed how they   re using a convnet to detect
   skin cancer as well as a dermatologist with a smart phone!

   so why are neural networks so powerful? one key reason:

   they do automatic pattern recognition.

   so what   s pattern recognition and why do we care if it   s automatic?

   patterns come in many forms but let   s take two critical examples:
     * the features that define a physical form
     * the steps it takes to do a task

id161

   in image processing pattern recognition is known as [22]feature
   extraction.

   when you look at a photo or something in the real world you   re
   selectively picking out the key features that allow you to make sense
   of it. this is something you do unconsciously.

   when you see the picture of my cat dove you think    cat    or    awwwwww   
   but you don   t really know how you do that. you just do it.

   you don   t know how you do it because it   s happening automatically and
   unconsciously.
   [1*jt34jy1zyq8dxxmzrtjgpw.jpeg]
   my beautiful cat dove. your built in neural network knows this is
   a cat.

   it seems simple to you because you do it every day, but that   s because
   the complexity is hidden away from you.

   your brain is a black box. you come with no instruction manual.

   yet if you really stop to think about it, what you just did in a
   fraction of second involved a massive number of steps. on the surface
   it   s deceptively simple but it   s actually incredibly complex.
     * you moved your eyes.
     * you took in light and you processed that light into component parts
       which sent signals to your brain.
     * then your brain went to work, doing its magic, converting that
       light to electro-chemical signals.
     * those signals fired through your built in neural network,
       activating different parts of it, including memories, associations
       and feelings.
     * at the most    basic    level your brain highlighted low level patterns
       (ears, whiskers, tail) that it combined into higher order patterns
       (animal).
     * lastly, you made a classification, which means you turned it into a
       word, which is a symbolic representation of the real life thing, in
       this case a    cat.   

   all of that happened in the blink of an eye.

   if you tried to teach a computer to do that, where would you even
   begin?
     * could you tell it how to detect ears?
     * what are ears?
     * how do you describe them?
     * why are cat ears different than human ears or bat ears (or batman)?
     * what do ears look like from various angles?
     * are all cat ears the same (nope, check out a scottish fold)?

   the problems go on and on.

   if you couldn   t come up with a good answer on how to teach a computer
   all those steps with some c++ or python, don   t feel bad, because it
   stumped computer scientists for 50 years!

   what you do naturally is one of the key uses for a deep learning neural
   network, which is a    classifier   , in this case an image classifier.

   in the beginning, ai researchers tried to do the exercise we just went
   through. they attempted to define all the steps manually. for example,
   when it comes to natural language processing or nlp, they assembled the
   best linguists and said    write down all the    rules    for languages.   
   they called these early ai   s    id109.   

   the linguists sat down and puzzled out a dizzying array of if, then,
   unless, except statements:
     * does a bird fly?

   yes

   unless it   s:
     * dead
     * injured
     * a flightless bird like a penguin
     * missing a wing

   these lists of rules and exceptions are endless. unfortunately they   re
   also terribly brittle and prone to all kinds of errors. they   re time
   consuming to create, subject to debate and bias, hard to figure out,
   etc.

   deep neural networks represent a real breakthrough because instead of
   you having to figure out all the steps, you can let the machine extract
   the key features of a cat automatically.

      automatically    is essential because we bypass the impossible problem
   of trying to figure out all those thousands or millions of hidden steps
   we take to do any complex action.

   we can let the computer figure it out for itself!

the endless steps of everything

   let   s look at the second example: figuring out the steps to do a task.

   today we do this manually and define the steps for a computer. it   s
   called programming. let   s say you want to find all the image files on
   your hard drive and move them to a new folder.

   for most tasks the programmer is the neural network. he   s the
   intelligence. he studies the task, decomposes it into steps and then
   defines each step for the computer one by one. he describes it to the
   computer with a symbolic representation known as a computer programming
   language.

   here   s an example in python, from [23]   jolly jumper    on stack exchange:
import glob
import shutil
import os
src_dir =    your/source/dir   
dst_dir =    your/destination/dir   
for jpgfile in glob.iglob(os.path.join(src_dir,    *.jpg   )):
shutil.move(jpgfile, dst_dir)

   jolly jumper figured out all the steps and translated them for the
   computer, such as:
     * we need to know the source directory
     * also, we need a destination
     * we need a way of classifying the types of files we want, in this
       case a    jpg    file
     * lastly we go into the directory, search it for any jpgs and move
       them from the source to the destination directory

   this works well for simple and even moderately complex problems.
   operating systems are some of the most complex software on earth,
   composed of 100's of millions of lines of code. each line is an
   explicit instruction for how computers do tasks ( like draw things on
   the screen, store and update information ) as well as how people do
   tasks ( copy files, input text, send email, view photos, chat with
   others, etc. ).

   but as we evolve to try and solve more challenging problems we   re
   running into the limits of our ability to manually define the steps of
   the problem.

   for example, how do you define driving a car?

   there are hundreds of millions of tiny steps that we take to do this
   mind-numbingly complex task. we have to:
     * stay in the lines
     * know what a line is and be able to recognize it
     * navigate from one place to another
     * recognize obstructions like walls, people, debris
     * classify objects as helpful (street sign) or threat (pedestrian
       crossing a green light)
     * assess where all the drivers around us are constantly
     * make split second decisions

   in machine learning this is known as a decision making problem.
   examples of complex decision making problems are:
     * robot navigation and perception
     * language translation systems
     * self driving cars
     * stock trading systems

the secret inner life of neural networks

   let   s see how deep learning helps us solve the insane complexity of the
   real world by doing automatic feature extraction!
   [1*xaktszg3tme-vkqzzqmrcg.png]

   if you   ve ever read the excellent book [24]think like a programmer, by
   v. anton spraul (and you should), you know that programming is about
   problem solving. the programmer decomposes a problem down into smaller
   problems, creates an action plan to solve it and then writes code to
   make it happen.

   deep learning solves problems for us, but ai still needs humans at this
   point (thank god) to design and test ai architectures (at least for
   now.) so let   s decompose a neural net into its parts and build a
   program to recognize that the picture of my dove is a cat.

the deep in deep learning

   deep learning is subfield of machine learning. it   s name comes from the
   idea that we stack together a bunch of different layers to learn
   increasingly meaningful representations of data.

   each of those layers are neural networks, which consist of linked
   connections between artificial neurons.

   before we had powerful gpus to do the math for us we could only build
   very small    toy    neural nets. they couldn   t do very much. today we can
   stack many layers together hence the    deep    in deep learning.

   neural nets were inspired by biological research into the human brain
   in the 1950s. researchers created a mathematical representation of a
   neuron, which you can see below ([25]courtesy of the awesome open
   courseware on convolutional neural nets from stanford and wikimedia
   commons):
   [1*mz0a4eesdjysbvf5m_u-sw.png]
   biological neuron
   [1*yf6bwjq0kdhtumero99buq.jpeg]
   math model of a neuron.

   forget about all the more complex math symbols for now, because you
   don   t need them.

   the basics are super simple. data, represented by x0, travels through
   the connections between the neurons. the strength of the connections
   are represented by their weights (w0x0, w1x1, etc). if the signal is
   strong enough, it fires the neuron via its    activation function    and
   makes the neuron    active.   

   here is an example of a three layer deep neural net:
   [1*juydtid113ius-6uqzvuttkw.png]

   by activating some neurons and not others and by strengthening the
   connections between neurons, the system learns what   s important about
   the world and what   s not.
   [1*3r4z-jiob_qv2xqcc_oapg.jpeg]

building and training a neural network

   let   s take a deeper look at deep learning and write some code as we go.
   [26]all the code is available on my github here.

   the essential characteristics of the system are:
     * training
     * input data
     * layers
     * weights
     * targets
     * id168
     * optimizer function
     * predictions

training

   training is how we teach a neural network what we want it to learn. it
   follows a simple five step process:
    1. create a training data set, which we will call x and load its
       labels as targets y
    2. feed the x data forward through the network with the result being
       predictions y   
    3. figure out the    loss    of the network, which is the difference
       between the predictions y    and the correct targets y
    4. compute the    gradient    of the loss (l) and which tells us how fast
       we   re moving towards or away from the correct targets
    5. adjust the weights of the network in the opposite direction of the
       gradient and go back to step two to try again

   [1*6sugytmd0gg3r8hogmfe2a.jpeg]

input data

   in this case the input data to a did98 is a bunch of images. the more
   images the better. unlike people, computers need a lot of examples to
   learn how to classify them. ai researchers are working on ways to learn
   with a lot less data but that   s still a cutting edge problem.

   a famous example is the [27]id163 data set. it consists of lots of
   hand labeled images. in other words, they crowd sourced the humans to
   use their built in neural nets to look at all the images and provide
   meaning to the data. people uploaded their photos and labeled it with
   tags, like    dog   , or a specific type of dog like a    beagle.   

   those labels represent accurate predictions for the network. the closer
   the network gets to matching the hand labeled data (y) with their
   predictions (y   ) the more accurate the network grows.

   the data is broken into two pieces, a training set and testing set. the
   training set is the input that we feed to our neural network. it learns
   the key features of various kinds of objects and then we test whether
   it can accurately find those objects on random data in the test image
   set.

   in our program we   ll use the well known [28]cifar-10 dataset which was
   developed by the canadian institute for advanced research.

   cifar-10 has 60000 32x32 color images in 10 classes, with 6000 images
   per class. we get 50000 training images and 10000 test images.

   when i first started working with cifar i mistakenly assumed it would
   be an easier challenge than working with the larger images of the
   id163 challenge. it turns out cifar10 is more challenging because
   the images are so tiny and there are a lot less of them, so they have
   less identifiable characteristics for our neural network to lock in on.

   while some of the biggest and baddest did98 architectures like
   [29]resnet can hit 97% accuracy on id163, it can only hit about 87%
   on cifar 10, in my experience. the current state of the art on cifar 10
   is [30]densenet, which can hit around 95% with a monstrous 250 layers
   and 15 million parameters! i link to those frameworks at the bottom of
   the article for further exploration. but it   s best to start with
   something simpler before diving into those complex systems.
   [1*zctqwsq9kpau768ism82pg.jpeg]

   enough theory! let   s write code.

   if you   re not comfortable with python, i highly, highly, highly
   recommend [31]learning python by fabrizio romano. this book explains
   everything so well. i   ve never found a better python book and i have a
   bunch of them that failed to teach me much.

   the code for our did98 is based on [32]the keras example code on github.

   you can find [33]my modifications here.

   i   ve adjusted the architecture and parameters, as well as added
   tensorboard to help us visualize the network.

   let   s initialize our python program, import the dataset and the various
   classes we   ll need to build our did98. luckily, keras already knows how
   to get this dataset automatically so we don   t have too much work to do.
from __future__ import print_function
import numpy as np
from keras.datasets import cifar10
from keras.callbacks import tensorboard
from keras.models import sequential
from keras.layers import dense, dropout, activation, flatten
from keras.layers import convolution2d, maxpooling2d
from keras.utils import np_utils
from keras import backend as k

   our neural net starts off with a random configuration. it   s as good a
   starting place as any but we shouldn   t expect it to start off very
   smart. then again, it   s possible that some random configuration gives
   us amazing results completely by accident, so we seed the random
   weights to make sure that we don   t end up with state of the art results
   by sheer dumb luck!
np.random.seed(1337) # very l33t

layers

   now we   ll add some layers.

   most neural networks use fully connected layers. that means they
   connect every neuron to every other neuron.

   fully connected layers are fantastic for solving all kinds of problems.
   unfortunately they don   t scale very well for image recognition.

   so we   ll build our system using convolutional layers, which are unique
   because they don   t connect all the neurons together.

   let   s see [34]what the stanford course on id161 has to say
   about convnet scaling:

        in cifar-10, the image are merely 32x32x3 (32 wide, 32 high, 3
     color channels), so a single fully-connected neuron in a first
     hidden layer of a regular neural network would have 32*32*3 = 3072
     weights. this amount still seems manageable, but clearly this
     fully-connected structure does not scale to larger images. for
     example, an image of more respectible size, e.g. 200x200x3, would
     lead to neurons that have 200*200*3 = 120,000 weights. moreover, we
     would almost certainly want to have several such neurons, so the
     parameters would add up quickly! clearly, this full connectivity is
     wasteful and the huge number of parameters would quickly lead to
     overfitting.   

   overfitting is when you train the network so well that it kicks ass on
   the training data but sucks when you show it images it   s never seen. in
   other words it   s not much use in the real world.

   it   s as if you played the same game of chess over and over and over
   again until you had it perfectly memorized. then someone makes a
   different move in a real game and you have no idea what to do. we   ll
   look at overfitting more later.

   here   s how data flows through a did98. it looks at only a small subset
   of the data, hunting for patterns. it then builds those observations up
   into higher order understandings.
   [1*3rectefgskjj6sni5sxpta.png]
   a visual representation of a convolutional neural net from the mneuron
   plugin created for mit   s id161 courses/teams.

   notice how the first few layers are simple patterns like edges and
   colors and basic shapes.

   as the information flows through the layers, the system finds more and
   more complex patterns, like textures, and eventually it deduces various
   object classes.
   [1*mmojs0rzlztm9hklsjc8ng.png]

   the ideas were based on experiments on cat vision that showed that
   different cells responded to only certain kinds of stimuli such as an
   edge or a particular color.
   [1*3sthpkdw6v8iqxyyeobjka.jpeg]
   [35]slides from the excellent deep learning open course at oxford.

   the same is true for humans. our visual cells respond only to very
   specific features.
   [1*h28re9ug6staptccdsuwcw.jpeg]

   here is a typical did98 architecture diagram:
   [1*n4h1sgwbwid4rrhszm9ejg.png]

   you   ll notice a third kind of layer in there, a pooling layer. you can
   find all kinds of detail in the [36]oxford lectures and the
   [37]standford lectures. however, i   m going to skip a lot of the
   granular detail because most people just find it confusing. i know i
   did when i first tried to make sense of it.

   here   s what you need to know about pooling layers. their goal is
   simple. they do subsampling. in other words they shrink the input
   image, which reduces the computational load and memory usage. with less
   information to crunch we can work with the images more easily.

   they also help reduce a second kind of overfitting where the network
   zeros in on anomalies in the training set that really have nothing to
   do with picking out dogs or birds or cats. for example, there may be
   some garbled pixels or some lens flares on a bunch of the images. the
   network may then decide that lens flare and dog go together, when
   they   re about as closely related as an asteroid and a baby rattle.

   lastly, most did98s add a few densely connected, aka fully connected
   layers to process out all the features maps detected in earlier layers
   and make predictions.

   so let   s add a few layers to our convnet.

   first we add some variables that we will pull into our layers.
# defines how many images we will process at once
batch_size = 128
# defines how many types of objects we can detect in this set.  since cifar 10 o
nly detects 10 kinds of objects, we set this to 10.
nb_classes = 10
# the epoch defines how lone we train the system.  longer is not always better.
 after a period of time we reach the point of diminishing returns.  adjust this
as necessary.
nb_epoch = 45
# here we put in the image dimensions.  we know the images are 32 x 32.  they ar
e already preprocessed for us to be nicely uniform to work with at this point.
img_rows, img_cols = 32, 32
# here we set the number of convolutional filters to use
nb_filters = 32
# size of pooling area for max pooling
pool_size = (2, 2)
# convolution kernel size
kernel_size = (3, 3)

   the kernel and pooling size define how the convolutional network passes
   over the image looking for features. the smallest kernel size would be
   1x1, which means we think key features are only 1 pixel wide. typical
   kernel sizes check for useful features over 3 pixels at a time and then
   pool those features down to a 2x2 grid.

   the 2x2 grid pulls the features out of the image and stacks them up
   like trading cards. this disconnects them from a specific spot on the
   image and allows the system to look for straight lines or swirls
   anywhere, not just in the spot it found them in the first place.

   most tutorials describe this as dealing with    [38]translation
   invariance.   

   what the heck does that mean? good question.

   take a look at this image again:
   [1*mmojs0rzlztm9hklsjc8ng.png]

   without yanking the features out, like you see in layer 1 or layer 2,
   the system might decide that the circle of a cat   s nose was only
   important right smack in the center of the image where it found it.

   let   s see how that works with my dove. if the system originally finds a
   circle in her eye then it might mistakenly assume that the position of
   the circle in an image is relevant to detecting cats.
   [1*i3x7isryys0m12qdliy8ag.jpeg]

   instead the system should look for circles wherever they may roam, as
   we see below.
   [1*aarvv_dnjzvyfnvrk8uz5w.jpeg]

   before we can add the layers we need to load and process the data.
# this splits the data into training and test sets and loads the data.  cifar10
is a standard test data set for keras so it can download it automatically.  it's
 about 186mb expanded.
(x_train, y_train), (x_test, y_test) = cifar10.load_data()
# unfortunately, tensorflow and theano want their tenor parameters in a differen
t order, so we check for the backend from the json initialization file and set t
hem accordingly.
if k.image_dim_ordering() == 'th':
    x_train = x_train.reshape(x_train.shape[0], 3, img_rows, img_cols)
    x_test = x_test.reshape(x_test.shape[0], 3, img_rows, img_cols)
    input_shape = (1, img_rows, img_cols)
else:
    x_train = x_train.reshape(x_train.shape[0], img_rows, img_cols, 3)
    x_test = x_test.reshape(x_test.shape[0], img_rows, img_cols, 3)
    input_shape = (img_rows, img_cols, 3)
x_train = x_train.astype('float32')
x_test = x_test.astype('float32')
x_train /= 255
x_test /= 255
print('x_train shape:', x_train.shape)
print(x_train.shape[0], 'train samples')
print(x_test.shape[0], 'test samples')
# convert class vectors to binary class matrices
y_train = np_utils.to_categorical(y_train, nb_classes)
y_test = np_utils.to_categorical(y_test, nb_classes)

   ok, now we   re finally ready to add some layers to our program:
model = sequential()
model.add(convolution2d(nb_filters, kernel_size[0], kernel_size[1],
                        border_mode='valid',
                        input_shape=input_shape))
model.add(activation('relu'))
model.add(convolution2d(nb_filters, kernel_size[0], kernel_size[1]))
model.add(activation('relu'))
model.add(maxpooling2d(pool_size=pool_size))
model.add(dropout(0.25))

   the layers are stacked as follows:
     * convolution
     * activation
     * convolution
     * activation
     * pooling
     * dropout

   we   ve already discussed most of these layer types except for two of
   them, dropout and activation.

   dropout is the easiest to understand. basically it   s a percentage of
   how much of the model to randomly kill off. this is similar to how
   netflix uses [39]chaos monkey. they have scripts that turn off random
   servers in their network to ensure the network can survive with its
   built in resilience and redundancy. the same is true here. we want to
   make sure the network is not too dependent on any one feature.

   the activation layer is a way to decide if the neuron    fires    or gets
      activated.    there are dozens of id180 at this point.
   relu is the one of the most successful because of its computational
   efficiency. here is [40]a list of all the different kinds of activation
   functions available in keras.

   we   ll also add a second stack of convolutional layers that mirror the
   first one. if we were rewriting this program for efficiency we would
   create a model generator and do a for loop to create however many
   stacks we want. but in this case we will just cut and paste the layers
   from above, violating[41] the zen rules of python for expediency sake.
model.add(convolution2d(nb_filters, kernel_size[0], kernel_size[1]))
model.add(activation('relu'))
model.add(convolution2d(nb_filters, kernel_size[0], kernel_size[1]))
model.add(activation('relu'))
model.add(maxpooling2d(pool_size=pool_size))
model.add(dropout(0.25))

   lastly, we add the dense layers, some more drop out layers and we
   flatten all the features maps.
model.add(flatten())
model.add(dense(256))
model.add(activation('relu'))
model.add(dropout(0.5))
model.add(dense(nb_classes))
model.add(activation('softmax'))

   we use a different kind of activation called softmax on the last layer,
   because it defines a id203 distribution over the classes.

weights

   we talked briefly about what weights were earlier but now we   ll look at
   them in depth.

   weights are the strength of the connection between the various neurons.

   we have parallels for this in our own minds. in your brain, you have a
   series of biological neurons. they   re connected to other neurons with
   electrical/chemical signals passing between them.

   but the connections are not static. over time some of those connections
   get stronger and some weaker.

   the more electro-chemical signals flowing between two biological
   neurons, the stronger those connections get. in essence, your brain
   rewires itself constantly as you have new experiences. it encodes your
   memories and feelings and ideas about those experiences by
   strengthening the connections between some neurons.
   [1*lxzzdozgtya63ow0z7edgg.jpeg]
   source u.s. national institute of health         wikimedia commons.

   computer based neural networks are inspired by biological ones. we call
   them id158s or anns for short. usually when we say
      neural network    what we really mean is ann. ann   s don   t function
   exactly the same as biological ones, so don   t make the mistake of
   thinking an ann is some kind of simulated brain. it   s not. for example
   in a biological neural network (bnn), every neuron does not connect to
   every other neuron whereas in an ann every neuron in one layer
   generally connects to every neuron in the next layer.

   below is an image of a bnn showing connections between various neurons.
   notice they   re not all linked.
   [1*kbg5-_ccuzale32qbbg_yq.png]
   source: [42]wikimedia commons: soon-beom hongandrew zaleskyluca
   cocchialex fornitoeun-jung choiho-hyun kimjeong-eun suhchang-dai
   kimjae-won kimsoon-hyung yi

   though there are many differences, there are also very strong parallels
   between bnns and anns.

   just like the neurons in your head form stronger or weaker connections,
   the weights in our id158 define the strength of the
   connections between neurons. each neuron knows a little bit about the
   world. wiring them together allows them to have a more comprehensive
   view of the world when taken together. the ones that have stronger
   connections are considered more important for the problem we   re trying
   to solve.

   let   s look at several screenshots of [43]the neural network playground,
   a visualizer for tensorflow to help understand this better.

   the first network shows a simple six layer system. what the network is
   trying to do is cleanly separate the blue dots from the orange dots in
   the picture on the far right. it   s looking for the best pattern that
   separates them with a high degree of accuracy.

   i have not yet started training the system here. because of that we can
   see weights between neurons are mostly equal. the thin dotted lines are
   weak connections and the thicker lines are strong connections. the
   network is initialized with random weights as a starting point.
   [1*8w8krinjtkivwazexhzzaa.jpeg]

   now let   s take a look at the network after we   ve trained it.
   [1*zdadr-0uubv-ggear4ueaq.jpeg]

   first notice the picture on the far right. it now has a nice blue dot
   in the middle around the blue dots and orange around the rest of the
   picture. as you can see it   s done pretty well, with a high degree of
   accuracy. this happened over 80    epochs    or training rounds.

   also notice that many of the weights have strong blue dotted lines
   between various neurons. the weights have increased and now the system
   is trained and ready to take on the world!

training our neural net and optimizing it

   now let   s have the model crunch some numbers. to do that we compile it
   and set its optimizer function.
model.compile(loss='categorical_crossid178',
              optimizer='adam',
              metrics=['accuracy'])

   it took me a long time to understand the optimizer function because i
   find most explanations miss the    why    behind the    what.   

   in other words, why the heck do i need an optimizer?

   remember that a network has target predictions y and as it   s trained
   over many epochs it makes new predictions y   . the system tests these
   predictions against a random sample from the test dataset and that
   determines the system   s validation accuracy. a system can end up 99%
   accurate on the training data and only hit 50% or 70% on test images,
   so the real name of the game is validation accuracy, not accuracy.

   the optimizer calculates the gradient (also known as partial
   derivatives in math speak) of the error function with respect to the
   model weights.

   what does that mean? think of the weights distributed across a 3d hilly
   landscape (like you see below), which is called the    error landscape.   
   the    coordinates    of the landscape represent specific weight
   configurations (like coordinates on a map), while the    altitude    of the
   landscape corresponds to the total error/cost for the different weight
   configurations.
   [1*ytdwpxrnfbpndxxnw77o-w.png]
   error landscape

   the optimizer serves one important function. it figures out how to
   adjust the weights to try to minimize the errors. it does this by
   taking a page from the book of calculus.

   what is calculus? well if you turn to any math text book you   ll find
   some super unhelpful explanations such as it   s all about calculating
   derivatives or differentials. but what the heck does that mean?
   [1*wcsum9lcn6mpfkewwihpog.jpeg]

   i didn   t understand it until i read [44]calculus better explained, by
   kalid azad.

   here   s what nobody bothers to explain.

   calculus does two things:
     * breaks things down into smaller chunks, aka a circle into rings.
     * figures out rates of change.

   in other words if i slice up a circle into rings:
   [1*iz7phvfiz_noj1tcxfmihg.png]
   courtesy of the awesome [45]calculus explained website.

   i can unroll the rings to do some simple math on it:
   [1*kmqnnpllkstzglj6qcigag.png]

   bam!

   in our case we run a bunch of tests, adjust the weights of the network
   but did we actually get any closer to an better solution to the
   problem? the optimizer tells us that!

   you can read about id119 with [46]an incredible amount of
   detail here or in the [47]stanford course but you   ll probably find like
   i did that they   re long on detail and light on the crucial question of
   why.

   in essence, what you   re trying to do is minimize the errors. it   s a bit
   like driving around in the fog. in an earlier version of this post, i
   characterized id119 as a way to to find an optimal solution.
   but actually, there is really no way to know if we have an    optimal   
   solution at all. if we knew what that was, we would just go right to
   it. instead we are trying to find a    better    solution that works. this
   is a bit like evolution. we find something that is fit enough to
   survive but that doesn   t mean we created einstein!
   [1*du9pqaqk4zegjko8tebziw.jpeg]

   think of id119 like when you played marco polo as a kid.

   you closed your eyes and all your friends spread out in the pool. you
   shouted out    marco    and all the kids had to answer    polo.    you used
   your ears to figure if you were getting closer or farther away. if you
   were farther away you adjusted and tried a different path. if you were
   closer you kept going in that direction. here we   re figuring out how
   best to adjust the weights of the network to help them get closer to
   understanding the world.

   we chose the    adam    optimizer [48]described in this paper. i   ve found
   through brute force changing my program that it seems to produce the
   best results. this is the art of data science. there is no one
   algorithm to rule them all. if i changed the architecture of the
   network, i might find a different optimizer worked better.

   here is a list of all[49] the various optimizers in keras.

   next we set up tensorboard so we can visualize how the network
   performs.
# set up tensorboard
tb = tensorboard(log_dir='./logs')

   all we did was create a log directory. now we will train the model and
   point tensorboard at the logs.
model.fit(x_train, y_train, batch_size=batch_size, nb_epoch=nb_epoch, verbose=1,
 validation_data=(x_test, y_test), callbacks=[tb])
score = model.evaluate(x_test, y_test, verbose=0)
print('test score:', score[0])
print("accuracy: %.2f%%" % (score[1]*100))

   all right, let   s fire this bad boy up and see how it does!
50000/50000 [==============================] - 3s - loss: 0.4894 - acc: 0.8253 -
 val_loss: 0.6288 - val_acc: 0.7908
epoch 89/100
50000/50000 [==============================] - 3s - loss: 0.4834 - acc: 0.8269 -
 val_loss: 0.6286 - val_acc: 0.7911
epoch 90/100
50000/50000 [==============================] - 3s - loss: 0.4908 - acc: 0.8224 -
 val_loss: 0.6169 - val_acc: 0.7951
epoch 91/100
50000/50000 [==============================] - 4s - loss: 0.4817 - acc: 0.8238 -
 val_loss: 0.6052 - val_acc: 0.7952
epoch 92/100
50000/50000 [==============================] - 4s - loss: 0.4863 - acc: 0.8228 -
 val_loss: 0.6151 - val_acc: 0.7930
epoch 93/100
50000/50000 [==============================] - 3s - loss: 0.4837 - acc: 0.8255 -
 val_loss: 0.6209 - val_acc: 0.7964
epoch 94/100
50000/50000 [==============================] - 4s - loss: 0.4874 - acc: 0.8260 -
 val_loss: 0.6086 - val_acc: 0.7967
epoch 95/100
50000/50000 [==============================] - 3s - loss: 0.4849 - acc: 0.8248 -
 val_loss: 0.6206 - val_acc: 0.7919
epoch 96/100
50000/50000 [==============================] - 4s - loss: 0.4812 - acc: 0.8256 -
 val_loss: 0.6088 - val_acc: 0.7994
epoch 97/100
50000/50000 [==============================] - 3s - loss: 0.4885 - acc: 0.8246 -
 val_loss: 0.6119 - val_acc: 0.7929
epoch 98/100
50000/50000 [==============================] - 3s - loss: 0.4773 - acc: 0.8282 -
 val_loss: 0.6243 - val_acc: 0.7918
epoch 99/100
50000/50000 [==============================] - 3s - loss: 0.4811 - acc: 0.8271 -
 val_loss: 0.6201 - val_acc: 0.7975
epoch 100/100
50000/50000 [==============================] - 3s - loss: 0.4752 - acc: 0.8299 -
 val_loss: 0.6140 - val_acc: 0.7935
test score: 0.613968349266
accuracy: 79.35%

   we hit 79% accuracy after 100 epochs. not bad for a few lines of code.
   now you might think 79% is not that great, but remember that in 2011,
   that was better than state of the art on id163 and it took a decade
   to get there! and we did that with just some example code from the
   keras github and a few tweaks.
   [1*lf6nwh79jpp6lrja4jyusq.jpeg]

   you   ll notice that in 2012 is when new ideas started to make an
   appearance.

   alexnet, by ai researchers alex krizhevsky, ilya sutskever and geoffrey
   hinton, is the first orange dot. it marked the beginning of the current
   renaissance in deep learning. by the next year everyone was using deep
   learning. by 2014 the winning architecture was better than human level
   image recognition.

   even so, these architectures are often very tied to certain types of
   problems. several of the most popular architectures today, like
   [50]resnet and google   s [51]inception v3 do [52]only 88% on the tiny
   cifar10 images. they do even worse on the larger cifar100 set.

   the current state of the art is densenet, which won the id163
   contest last year in 2016. it chews through cifar10, hitting a killer
   94.81% accuracy with an insanely deep 250 layers and 15.3 million
   connections! it is an absolute monster to run. on a single nvidia
   1080gtx, if you run it with the 40 x 12 model which hits the 93%
   accuracy mark you see in the chart below, it will take a month to run.
   ouch!
   [1*wymtbgx6nwre-zzedtdwpa.jpeg]

   that said, i encourage you to explore these models in depth to see what
   you can learn from them.

   i did some experimenting and managed to hack together a weird
   architecture through brute force experimentation that achieve 81.40%
   accuracy using nothing but the build in keras layers and no custom
   layers. [53]you can find that on github here.
 epoch 70/75
 50000/50000 [==============================] - 10s - loss: 0.3503 - acc: 0.8761
 - val_loss: 0.6229 - val_acc: 0.8070
 epoch 71/75
 50000/50000 [==============================] - 10s - loss: 0.3602 - acc: 0.8740
 - val_loss: 0.6039 - val_acc: 0.8085
 epoch 72/75
 50000/50000 [==============================] - 10s - loss: 0.3543 - acc: 0.8753
 - val_loss: 0.5986 - val_acc: 0.8094
 epoch 73/75
 50000/50000 [==============================] - 10s - loss: 0.3461 - acc: 0.8780
 - val_loss: 0.6052 - val_acc: 0.8147
 epoch 74/75
 50000/50000 [==============================] - 10s - loss: 0.3418 - acc: 0.8775
 - val_loss: 0.6457 - val_acc: 0.8019
 epoch 75/75
 50000/50000 [==============================] - 10s - loss: 0.3440 - acc: 0.8776
 - val_loss: 0.5992 - val_acc: 0.8140
 test score: 0.599217191744
 accuracy: 81.40%

   we can load up tensorboard to visualize how we did as well.
tensorboard --logdir=./logs

   now open a browser and go to the following url:
127.0.1.1:6006

   here is a screenshot of the training over time.
   [1*j7_zbkcximffxjxgt7yvew.jpeg]

   you can see we quickly start to pass the point of diminishing returns
   at around 35 epochs and 79%. the rest of the time is spent getting it
   to 81.40% and likely overfitting at anything beyond 75 epochs.

   so how would you improve this model?

   here are a few strategies:
     * implement your own custom layers
     * do image augmentation, like flipping images, enhancing them,
       warping them, cloning them, etc
     * go deeper
     * change the settings on the layers
     * read through the winning architecture papers and stack up your own
       model that has similar characteristics

   and thus you have reached the real art of data science, which is using
   your brain to understand the data and hand craft a model to understand
   it better. perhaps you dig deep into cifar10 and notice that upping the
   contrast on those images would really make images stand out. do it!

   don   t be afraid to load things up in photoshop and start messing with
   filters to see if images get sharper and clearer. figure out if you can
   do the same thing with keras image manipulation functions.

   deep learning is far from a magic bullet. it requires patience and
   dedication to get right.

   it can do incredible things but you may find yourself glued to your
   workstation watching numbers tick by for hours until 2 in the morning,
   getting absolutely nowhere.

   but then you hit a breakthrough!

   it   s a bit like the trial and error a neural net goes through. try some
   stuff, get closer to an answer. try something else and get farther
   away.

   i am now exploring [54]how to use id107 to auto-evolve
   neural nets. there   s been [55]a bunch of work done on this front but
   not enough!

   eventually we   ll hit a point where many of the architectures are baked
   and easy to implement by pulling in some libraries and some pre-trained
   weights files but that is a few years down the road for enterprise it.

   this field is still fast developing and new ideas are coming out every
   day. the good news is you are on the early part of the wave. so get
   comfortable and start playing around with your own models.

   study. experiment. learn.

   do that and you can   t go wrong.

   [56]learning ai if you suck at math         part 1         this article guides you
   through the essential books to read if you were never a math fan but
   you   re learning it as an adult.

   [57]learning ai if you suck at math         part 2         practical
   projects         this article guides you through getting started with your
   first projects.

   [58]learning ai if you suck at math         part 3         building an ai dream
   machine         this article guides you through getting a powerful deep
   learning machine setup and installed with all the latest and greatest
   frameworks.

   [59]learning ai if you suck at math         part 4         tensors illustrated
   (with cats!)         this one answers the ancient mystery: what the hell is a
   tensor?

   [60]learning ai if you suck at math         part 5         deep learning and
   convolutional neural nets in plain english         here we create our first
   python program and explore the inner workings of neural networks!

   [61]learning ai if you suck at math         part 6         math notation made
   easy         still struggling to understand those funny little symbols? let   s
   change that now!

   [62]learning ai if you suck at math         part 7         the magic of natural
   language processing         understand how google and siri understand what
   you   re mumbling.

   ############################################

   if you love my work please [63]do me the honor of visiting my patreon
   page because that   s how we change the future together. help me
   disconnect from the matrix and i   ll repay your generosity a hundred
   fold by focusing all my time and energy on writing, research and
   delivering amazing content for you and world.

   ###########################################

   if you enjoyed this tutorial, i   d love it if you could clap it up to
   recommend it to others. after that please feel free email the article
   off to a friend! thanks much.

   ###########################################
   [1*5gotoj42ui30cu210u737g.png]

   a bit about me: i   m an author, engineer and serial entrepreneur. during
   the last two decades, i   ve covered a broad range of tech from linux to
   virtualization and containers.

   you can check out my latest novel, [64]an epic chinese sci-fi civil war
   saga where china throws off the chains of communism and becomes the
   world   s first direct democracy, running a highly advanced, artificially
   intelligent decentralized app platform with no leaders.

[65]you can get a free copy of my first novel, the scorpion game, when you
join my readers group. readers have called it    the first serious competition
to neuromancer    and   detective noir meets johnny mnemonic.   

lastly, you can [66]join my private facebook group, the nanopunk posthuman
assassins, where we discuss all things tech, sci-fi, fantasy and more.

   ############################################

   i occasionally make coin from the links in my articles but i only
   recommend things that i own, use and love. check my [67]full policy
   here.

   ############################################

   thanks for reading!
   [68][1*0hqoaabq7xgpt-oyngiubg.png]
   [69][1*vgw1jka6hgnvwztsfmlnpg.png]
   [70][1*gkbpq1ruui0fvk2um_i4tq.png]

     [71]hacker noon is how hackers start their afternoons. we   re a part
     of the [72]@ami family. we are now [73]accepting submissions and
     happy to [74]discuss advertising & sponsorship opportunities.

     if you enjoyed this story, we recommend reading our [75]latest tech
     stories and [76]trending tech stories. until next time, don   t take
     the realities of the world for granted!

   [1*35tcjopcvq6lbb3i6wegqw.jpeg]

     * [77]artificial intelligence
     * [78]machine learning
     * [79]deep learning
     * [80]python
     * [81]ai if you suck at math

   (button)
   (button)
   (button) 1.2k claps
   (button) (button) (button) 9 (button) (button)

     (button) blockedunblock (button) followfollowing
   go to the profile of daniel jeffries

[82]daniel jeffries

   medium member since mar 2017

   i am an author, futurist, systems architect, and thinker.

     (button) follow
   [83]hacker noon

[84]hacker noon

   how hackers start their afternoons.

     * (button)
       (button) 1.2k
     * (button)
     *
     *

   [85]hacker noon
   never miss a story from hacker noon, when you sign up for medium.
   [86]learn more
   never miss a story from hacker noon
   (button) get updatesget updates

references

   visible links
   1. https://plus.google.com/103654360130207659246
   2. https://hackernoon.com/osd.xml
   3. android-app://com.medium.reader/https/medium.com/p/cda79679bbe3
   4. https://medium.com/
   5. https://medium.com/
   6. https://medium.com/m/signin?redirect=https://hackernoon.com/learning-ai-if-you-suck-at-math-p5-deep-learning-and-convolutional-neural-nets-in-plain-english-cda79679bbe3&source=--------------------------nav_reg&operation=login
   7. https://medium.com/m/signin?redirect=https://hackernoon.com/learning-ai-if-you-suck-at-math-p5-deep-learning-and-convolutional-neural-nets-in-plain-english-cda79679bbe3&source=--------------------------nav_reg&operation=register
   8. https://hackernoon.com/?source=logo-lo_cm8kpc4g0amn---3a8144eabfe3
   9. https://hackernoon.com/latest-tech-stories/home
  10. https://hackernoon.com/editors-top-tech-stories/home
  11. https://hackernoon.com/your-most-frequently-asked-questions-about-our-terms-of-service-how-to-opt-out-and-more-66abf239a151
  12. https://hackernoon.com/sign-up-for-hacker-noon-2-0-9ff1ea0b60cc
  13. https://community.hackernoon.com/t/what-will-replace-google-search/992/14
  14. https://hackernoon.com/@dan.jeffries
  15. https://hackernoon.com/learning-ai-if-you-suck-at-math-8bdfb4b79037#.qv49ic2ok
  16. https://hackernoon.com/learning-ai-if-you-suck-at-math-part-two-practical-projects-47d7a1e4e21f#.p1x8tjxyx
  17. https://hackernoon.com/learning-ai-if-you-suck-at-math-p3-building-an-ai-dream-machine-or-budget-friendly-special-d5a3023140ef#.wktve8ouw
  18. https://hackernoon.com/learning-ai-if-you-suck-at-math-p4-tensors-illustrated-with-cats-27f0002c9b32#.kql2vj3yn
  19. https://hackernoon.com/learning-ai-if-you-suck-at-math-p6-math-notation-made-easy-1277d76a1fe5#.fra2px108
  20. https://hackernoon.com/learning-ai-if-you-suck-at-math-p7-the-magic-of-natural-language-processing-f3819a689386
  21. https://www.youtube.com/watch?v=tok1oslep3s
  22. https://en.wikipedia.org/wiki/feature_extraction
  23. http://stackoverflow.com/questions/11903037/copy-all-jpg-file-in-a-directory-to-another-directory-in-python
  24. http://amzn.to/2le2pqw
  25. http://cs231n.github.io/neural-networks-1/
  26. https://github.com/the-laughing-monkey/learning-ai-if-you-suck-at-math/tree/master/deep learning examples
  27. http://www.image-net.org/
  28. http://www.cs.toronto.edu/~kriz/cifar.html
  29. https://github.com/kaiminghe/deep-residual-networks
  30. https://github.com/titu1994/densenet
  31. http://amzn.to/2lde3fs
  32. https://github.com/fchollet/keras/tree/master/examples
  33. https://github.com/the-laughing-monkey/learning-ai-if-you-suck-at-math/tree/master/deep learning examples
  34. http://cs231n.github.io/convolutional-networks/
  35. https://www.youtube.com/watch?v=plhfwt7vaew
  36. https://www.youtube.com/watch?v=beux_56lojc
  37. http://cs231n.github.io/convolutional-networks/
  38. http://stats.stackexchange.com/questions/208936/what-is-translation-invariance-in-computer-vision-and-convolutional-netral-netwo
  39. http://techblog.netflix.com/2012/07/chaos-monkey-released-into-wild.html
  40. https://keras.io/activations/
  41. http://wiki.c2.com/?pythonphilosophy
  42. http://www.plosone.org/article/info:doi/10.1371/journal.pone.0057831
  43. http://playground.tensorflow.org/#activation=tanh&batchsize=10&dataset=circle&regdataset=reg-plane&learningrate=0.03&id173rate=0&noise=0&networkshape=4,2&seed=0.45414&showtestdata=false&discretize=false&perctraindata=50&x=true&y=true&xtimesy=false&xsquared=false&ysquared=false&cosx=false&sinx=false&cosy=false&siny=false&collectstats=false&problem=classification&initzero=false&hidetext=false
  44. http://amzn.to/2locejt
  45. https://betterexplained.com/calculus/
  46. http://sebastianruder.com/optimizing-gradient-descent/
  47. http://cs231n.github.io/optimization-1/
  48. https://arxiv.org/abs/1412.6980
  49. https://keras.io/optimizers/
  50. https://github.com/raghakot/keras-resnet
  51. https://github.com/tensorflow/models/tree/master/inception
  52. http://oduerr.github.io/blog/2016/04/06/deep-learning_for_lazybones
  53. https://github.com/the-laughing-monkey/learning-ai-if-you-suck-at-math/blob/master/deep learning examples/keras-example-simple-convnet-15c6.py
  54. http://nn.cs.utexas.edu/?neat
  55. http://neat-python.readthedocs.io/en/latest/
  56. https://hackernoon.com/learning-ai-if-you-suck-at-math-8bdfb4b79037#.ng7ggn5d9
  57. https://hackernoon.com/learning-ai-if-you-suck-at-math-part-two-practical-projects-47d7a1e4e21f#.yo1o1ar5h
  58. https://hackernoon.com/learning-ai-if-you-suck-at-math-p3-building-an-ai-dream-machine-or-budget-friendly-special-d5a3023140ef#.6frka033t
  59. https://hackernoon.com/learning-ai-if-you-suck-at-math-p4-tensors-illustrated-with-cats-27f0002c9b32#.2jpelkuhd
  60. https://hackernoon.com/learning-ai-if-you-suck-at-math-p5-deep-learning-and-convolutional-neural-nets-in-plain-english-cda79679bbe3#.xjah79lsd
  61. https://hackernoon.com/learning-ai-if-you-suck-at-math-p6-math-notation-made-easy-1277d76a1fe5
  62. https://hackernoon.com/learning-ai-if-you-suck-at-math-p7-the-magic-of-natural-language-processing-f3819a689386
  63. https://www.patreon.com/danjeffries
  64. http://amzn.to/2gag249
  65. http://meuploads.com/join-my-readers-group/
  66. https://www.facebook.com/groups/1736763229929363/
  67. http://meuploads.com/disclosure/
  68. http://bit.ly/hackernoonfb
  69. https://goo.gl/k7xybx
  70. https://goo.gl/4ofytp
  71. http://bit.ly/hackernoon
  72. http://bit.ly/atamiatami
  73. http://bit.ly/hackernoonsubmission
  74. mailto:partners@amipublications.com
  75. http://bit.ly/hackernoonlatestt
  76. https://hackernoon.com/trending
  77. https://hackernoon.com/tagged/artificial-intelligence?source=post
  78. https://hackernoon.com/tagged/machine-learning?source=post
  79. https://hackernoon.com/tagged/deep-learning?source=post
  80. https://hackernoon.com/tagged/python?source=post
  81. https://hackernoon.com/tagged/ai-if-you-suck-at-math?source=post
  82. https://hackernoon.com/@dan.jeffries
  83. https://hackernoon.com/?source=footer_card
  84. https://hackernoon.com/?source=footer_card
  85. https://hackernoon.com/
  86. https://medium.com/@medium/personalize-your-medium-experience-with-users-publications-tags-26a41ab1ee0c#.hx4zuv3mg

   hidden links:
  88. https://hackernoon.com/@dan.jeffries?source=post_header_lockup
  89. https://medium.com/p/cda79679bbe3/share/twitter
  90. https://medium.com/p/cda79679bbe3/share/facebook
  91. https://hackernoon.com/@dan.jeffries?source=footer_card
  92. https://medium.com/p/cda79679bbe3/share/twitter
  93. https://medium.com/p/cda79679bbe3/share/facebook
