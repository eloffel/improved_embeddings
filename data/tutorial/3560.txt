   #[1]publisher [2]medium [3]alternate

   [4]homepage
   [5]homepage
   [6]sign in[7]get started

   [8]hacker noon
     * [9]latest
     * [10]editors' choice
     * [11]terms faq
     * [12]sign up for 2.0
     * [13]future of search
     __________________________________________________________________

learning ai if you suck at math         p3         building an ai dream machine or budget
friendly special

   go to the profile of daniel jeffries
   [14]daniel jeffries (button) blockedunblock (button) followfollowing
   feb 6, 2017
   [1*iaecuiwjx-r_g4pfhsy4uq.jpeg]

   welcome to the third installment of learning ai if you suck at math. if
   you missed the earlier articles be sure to check out [15]part 1,
   [16]part 2, [17]part 4, [18]part 5, [19]part 6 and [20]part 7.

   today we   re going to build our own deep learning dream machine.
     * we   ll source the best parts and put them together into a number
       smashing monster.
     * we   ll also walk through installing all the latest deep learning
       frameworks step by step on ubuntu linux 16.04.

   this machine will slice through neural networks like a hot laser
   through butter. other than forking over $129,000 for [21]nvidia   s
   dgx-1, the ai supercomputer in a box, you simply can   t get better
   performance than what i   ll show you right here.
     * lastly, if you   re working with a tighter budget, don   t despair,
       i   ll also outline very budget friendly alternatives.

first, a tl;dr, ultracheap upgrade option

   before we dig into building a dl beast, i want to give you the easiest
   upgrade path.

   if you don   t want to build an entirely new machine, you still have one
   perfectly awesome option.
   [1*zlvw4lkpjsd236axzh6vcq.jpeg]

   simply upgrade your gpu (with either a [22]titan x or a [23]gtx 1080)
   and get [24]vmware workstation or use another virtualization software
   that supports [25]gpu acceleration! or you could simply install ubuntu
   bare metal and if you need a windows machine run that in a vm, so you
   max your performance for deep learning.

   install ubuntu and the dl frameworks using the tutorial at the end of
   the article and bam! you just bought yourself a deep learning superstar
   on the cheap!

   all right, let   s get to it.

   i   ll mark dream machine parts and budget parts like so:
     * mino (money is no object) = dream machine
     * adad (a dollar and a dream) = budget alternative

dream machine parts extravaganza

gpus first

   cpus are no longer the center of the universe. [26]ai applications have
   flipped the script. if you   ve ever build a custom rig for gaming, you
   probably pumped it up with the baddest intel chips you could get your
   hands on.

   but times change.

   [27]nvidia is the new intel.

   the most important component of any deep learning world destroyer is
   the gpu(s).

   while amd have made headway in cyptocoin mining in the last few years,
   they have yet to make their mark on ai. that will change soon, as they
   race to capture a piece of this exploding field, but for now nvidia is
   king. and don   t sleep on intel either. they purchased [28]nervana
   systems and plan to put out their own deep learning asics in 2017.
   [1*7kftxyr-m7z16w7r6bdkhq.jpeg]
   the king of dl gpus

   let   s start with mino. the ultimate gpu is the titan x. it has no
   competition.

   it   s packed with 3584 cuda cores at 1531 mhz, 12gb of g5x and it boasts
   a memory speed of 10 gbps.

   in dl, cores matter and so does more memory close to those cores.

   dl is really nothing but a lot of id202. think of it as an
   insanely large excel sheet. crunching all those numbers would slaughter
   a standard 4 or 8 core intel cpu.

   moving data in and out of memory is a massive bottleneck, so more
   memory on the card makes all the difference, which is why the titan x
   is the king of the world.

   you can [29]get titan x directly from nvidia for $1,200 msrp.
   unfortunately, you   re limited to two. but this is a dream machine and
   we   re buying four. that   s right quad sli!

   for that [30]you   ll need to pay a slight premium from a third party
   seller. feel free to get two from nvidia and two from amazon. that will
   bring you to $5300, by far the bulk of the cost for this workstation.

   now if you   re just planning to run minecraft, it   ll still look blocky
   but if [31]you want to train a model to beat cancer, these are your
   cards. :)

   gaming hardware benchmark sites will tell you [32]that anything more
   than two cards is well past the point of diminishing returns but that   s
   just for gaming ! when it comes to ai you   ll want to hurl as many cards
   at it as you can. of course, ai has its point of diminishing returns
   too but it   s closer to dozens or hundreds of cards (depending on the
   algo), not four. so stack up, my friend.

   please note you will not need an sli bridge, unless you   re also
   planning to use this machine for gaming. that   s strictly for graphics
   rendering and we   re doing very little graphics here, other than
   plotting a few graphs in matplotlib.

budget-friendly alternative gpus

   [1*6pdr-fcbez4xgu6bqqhsgq.jpeg]

   your adad card is the geforce gtx 1080 founders edition. the 1080 packs
   2560 cuda cores, a lot less than the titan x, but it rings in at half
   the price, with an msrp of $699.

   it also boasts less ram, at 8gb versus 12.

   [33]evga has always served me well so grab four of them for your
   machine. at $2796 vs $5300, that   s a lot of savings for nearly
   equivalent performance.

   the second best choice for adad is the geforce gtx 1070. it packs 1920
   cuda cores so it   s still a great choice. it comes in at around $499
   msrp but [34]superclocked evga 1070s will run you only $389 bucks so
   that brings the price to a more budget-friendly $1556. very doable.

   of course if you don   t have as much money to spend you can always get
   two or three cards. even one will get you moving in the right
   direction.

   let   s do the math on best bang for the buck with two or three cards:
     * 3 x titan x = 10,752 cuda cores, 36gb of gpu ram = $3800
     * 2 x titan x = 7,167 cuda cores, 24 gb of gpu ram = $2400
     * 3 x gtx 1080 = 7,680 cuda cores, 24gb of gpu ram = $2097
     * 2 x gtx 1080 = 5,120 cuda cores, 16gb of gpu ram = $1398
     * 3 x gtx 1070 = 5,760 cuda cores, 24gb of gpu ram = $1167
     * 2 x gtx 1070 = 3,840 cuda cores, 16gb of gpu ram = $778

   the sweet spot is 3 gtx 1080s. for half the price you   re only down 3072
   cores. full disclosure: that   s how i built my workstation.

ssd and spinning drive

   [1*hiz-1zbnbn9khnjlkdpbog.jpeg]

   you   ll want an ssd, especially if you   re building convolutional neural
   nets and working with lots of image data. [35]the samsung 850 evo 1 tb
   is the best of the best right now. even better, ssd prices have
   plummeted in the last year, so it won   t break the bank. the 850 1 tb
   currently comes in at about $319 bucks.

   the adad version of the [36]850 is the 250gb version. it   s very easy on
   the wallet at $98.

   you   ll also want a spindle drive for storing downloads. datasets can be
   massive in dl. a [37]4 tb seagate barracuda will do the trick.

motherboard

   [1*ovompivuin5sh393vmsmsa.png]

   because we want to stuff four gpus into this box your motherboard
   options narrow to a very small set of choices. to support four cards at
   full bus speeds we want the [38]msi extreme gaming x99a sli plus.

   you can also go with the [39]asus x99 deluxe ii.

   if you go with less than four cards you have many more options. when it
   comes to motherboards, i favor stability. i learned this the hard way
   building cryptocoin mining rigs. if you run your gpus constantly
   they   ll burn your machine to the ground in no time. gigabyte make an
   excellent line of very durable motherboards. the [40]x99 ultra gaming
   is absolutely rock solid and comes in at $237.

case

   [1*_suoqinrpa1k-woio5zifq.jpeg]

   the [41]cooler master cosmos ii is the ultimate full tower case. it   s
   sleek and stylish racecar design of brushed aluminum and steel make for
   one beautiful machine.

   if you want a mid-tower case, you can   t go wrong with the [42]cooler
   master maker 5t.

   i never favor getting a cheap-ass case for any machine. as soon as you
   have to open it to troubleshoot it, your mistake becomes glaringly
   clear. tool-less cases are ideal. but there are plenty of decent budget
   cases out there so do your homework.

cpu

   your deep learning machine doesn   t need much cpu power. most apps are
   single threaded as they load the data into the gpus where they do
   multicore work, so don   t bother spending a lot of capital here.
   [1*p28-o6rr4qloy7p94zq3kq.jpeg]

   that said, you might as well get the fastest clock speed for your
   processor, which is 4ghz on the i7   6700k. [43]you can snag it here with
   a fan. frankly, it   s ridiculous overkill here but prices have dropped
   drastically and i was looking for single-threaded performance. this is
   the cpu to beat.

   if you want to go quieter then [44]you can go with watercooling but you
   won   t be running the cpu that hard. most of the fan noise will come
   from the gpus.

   there   s no great adad alternative here. the [45]i5 at 3.5ghz with a
   water cooler runs about the same cost as the 4ghz so why bother?

power

   the [46]evga modular 1600w supernova g2 power supply is your best bet
   for a quad sli setup. it will run you about $305 bucks.

   the titan x   s pull about 250 watts each which brings you to 1000w easy.
   that doesn   t leave much overhead for cpu, memory, and systems power so
   go with the biggest supply to leave some head room.

   if you   re rocking less cards than go with the 1300w version, which
   drops the price to a more manageable $184.

software setup

   now that we   re done with the hardware, let   s get to the software setup.

   you have three options:
     * docker container
     * virtual machine
     * bare metal install

docker

   if you want to go with the docker option, you   ll want to start with
   [47]the official nvidia-docker project as a foundation. however to
   really get all of the frameworks, libraries and languages you   ll have
   to do a lot of installation on top of this image.

   you can go with an all-in-one deep learning container, like [48]this
   one on github.

   i wanted to love the all-in-one docker image, but it has a few issues,
   no surprise considering the complexity of the setup.

   i [49]found the answer to one issue (libopenjpeg2 is now libopenjpeg5
   on ubuntu 16.04 lts) but i got tired of [50]troubleshooting a second
   one. i   m still waiting on fixes. if you   re the type of person who likes
   fixing dockerfiles and submitting fixes on github, i encourage you to
   support the all-in-one project.

   a second major challenge is that it   s a very, very big image, so it
   won   t fit on dockerhub due to timeouts. that means you   ll have to build
   it yourself and that can take several hours of compiling and pulling
   layers and debugging, which is about as much time as you need to do it
   bare metal.

   lastly, it doesn   t include everything i wanted, including anaconda
   python.

   in the end i decided to use [51]the all-in-one bare metal tutorial as a
   guide, while updating it and adding my own special sauce.

virtual machine

   as i noted in the tl;dr section at the beginning of the doc, you can
   absolutely upgrade a current gaming machine, add vmware workstation
   pro, which supports gpu passthrough, and have a nice way to get started
   on a shoestring. this is a strong budget-friendly strategy. it also has
   several advantages, in that you can easily backup the virtual machine,
   snapshot and roll it back. it doesn   t start as fast as a docker
   container, but vm tech is very mature at this point and that gives you
   a lot of tools and best practices.

bare metal

   this is the option i ended up going with on my machine. it   s a little
   old school, but as a long time sys-admin it made the most sense to me,
   as it gave me the ultimate level of control.

   a few things of note about the software for [52]deep learning before we
   get started.

   you   ll find that the vast majority of ai research is done in python.
   that   s because it   s an easy language to learn and setup. i   m not sure
   that python will end up as the primary language once ai moves into
   production but for now python is the way to go. a number of the major
   frameworks run on top of it and its scientific libraries are second to
   none.

   the r language gets a lot of love too, as well as scala, so we will add
   those to the equation.

   here are a list of the major packages we   ll set up in this tutorial:

languages

     * python 2.x
     * [53]anaconda (and by extension python 3.6)         anaconda is a
       high-performance distribution of python and includes over a 100 of
       the most popular python, r and scala packages for data science.
     * [54]r         a language and environment for statistical computing and
       graphics.
     * [55]scala         scala is an acronym for    scalable language.    it   s
       similar to java but super high performance and modular.

drivers and apis

     * [56]nvidia drivers
     * [57]cuda         a proprietary parallel computing platform and
       application programming interface (api) model created by nvidia.
     * [58]cudnn         deep neural network accelerated library of primitives
       for nvidia gpus.

helper apps

     * [59]jupyter         this is an awesome web app that let   s you share
       documentation and live code in a single file.

frameworks/libraries

     * [60]tensorflow         google   s opensource dl framework that powers
       things like google translate.
     * [61]theano         a robust and popular machine learning framework.
     * [62]caffe         a deep learning framework that comes out of berkley.
     * [63]torch         a scientific computing framework with wide support for
       machine learning algorithms that puts gpus first.
     * [64]mxnet         highly scalable dl system backed by amazon and several
       universities.

high level abstraction libraries

     * [65]keras         a high-level neural networks library, written in python
       that runs on top of either tensorflow or theano.
     * [66]lasagne         a light weight library to build and train neural
       networks.

python libraries

   there area whole host of libraries that pretty much any scientific
   computing system will need to run effectively. so let   s install the
   most common ones off the bat.
     * pip = an installer and packaging system for python
     * pandas = high-performance data analysis
     * scikit-learn = a popular and powerful machine learning library
     * numpy = numerical python
     * matplotlib = visualization library
     * scipy = math and scientific computing
     * ipython = interactive python
     * scrappy = web crawling framework
     * nltk = natural language toolkit
     * pattern = a web mining library
     * seaborn = statistical visualization
     * opencv = a id161 library
     * rpy2 = an r interface
     * py-graphviz = statistical graphing
     * openblas = id202

linux workstation setup

   for cutting-edge work, you   ll want to [67]get the latest version of
   ubuntu lts, which is 16.04 at the time of writing. i   m looking forward
   to the days when more of the tutorials cover red hat and red hat
   derivatives like centos and scientific linux but as of now ubuntu is
   where it   s at for deep learning. i may follow up with an rh centric
   build as well.

   get ubuntu [68]burned to a usb stick via rufus.

   get it installed in uefi mode.

first boot

   your first boot will go to a black screen. that   s because the open
   source drivers are not up to date with the latest and greatest
   chipsets. to fix that you   ll need to do the following:

   as the machine boots, get to a tty:
ctrl + alt + f1

   get the latest nvidia drivers and reboot:
     * log into your root account in the tty.
     * run sudo apt-get purge nvidia-*
     * run sudo add-apt-repository ppa:graphics-drivers/ppa and then sudo
       apt-get update
     * run sudo apt-get install nvidia-375
     * reboot and your graphics issue should be fixed.

update the machine

   open a terminal and type the following:
sudo apt-get update -y
sudo apt-get upgrade -y
sudo apt-get install -y build-essential cmake g++ gfortran git pkg-config python
-dev software-properties-common wget
sudo apt-get autoremove
sudo rm -rf /var/lib/apt/lists/*

cuda

   download cuda 8 from [69]nvidia. go to the downloads directory and
   install cuda:
sudo dpkg -i cuda-repo-ubuntu1604-8-0-local.deb
sudo apt-get update -y
sudo apt-get install -y cuda

   add cuda to the environment variables:
echo    export path=/usr/local/cuda/bin:$path    >> ~/.bashrc
echo    export ld_library_path=/usr/local/cuda/lib64:$ld_library_path    >> ~/.bashr
c
source ~/.bashrc

   check to make sure the correct version of cuda is installed:
nvcc -v

   restart your computer:
sudo shutdown -r now

   check your cuda installation

   first install the cuda samples:
/usr/local/cuda/bin/cuda-install-samples-*.sh ~/cuda-samples
cd ~/cuda-samples/nvidia*samples
make -j $(($(nproc) + 1))

   note that the make section of this command uses +1 to indicate the
   number of gpus that you have, so if you have more than one you can up
   the number and install/compile will move a lot faster.

   run devicequery and ensure that it detects your graphics card and that
   the tests pass:
bin/x86_64/linux/release/devicequery

cudnn

   cudnn is a gpu accelerated library for dnns. unfortunately, you can   t
   just grab it from a repo. you   ll need to [70]register with nvidia to
   get access to it, which you can do right here. it can take a few hours
   or a few days to get approved for access. grab version 4 and version 5.
   i installed 5 in this tutorial.

   you will want to wait until you get this installed before moving on, as
   other frameworks depend on it and may fail to install.

   extract and copy the files:
cd ~/downloads/
tar xvf cudnn*.tgz
cd cuda
sudo cp */*.h /usr/local/cuda/include/
sudo cp */libcudnn* /usr/local/cuda/lib64/
sudo chmod a+r /usr/local/cuda/lib64/libcudnn*

   do a check by typing:

   nvidia-smi

   that should output some gpu stats.

python

sudo apt-get install -y python-pip python-dev
sudo apt-get update && apt-get install -y python-numpy python-scipy python-nose
python-h5py python-skimage python-matplotlib python-pandas python-sklearn python
-sympy libfreetype6-dev libpng12-dev libopenjpeg5
sudo apt-get clean && sudo apt-get autoremove
rm -rf /var/lib/apt/lists/*

   now install the rest of the libraries with pip
pip install seaborn rpy2 opencv-python pygraphviz pattern nltk scrappy

[71]tensorflow

pip install tensorflow-gpu

   that   s it. awesome!

   test tensorflow

   $ python
    ...
    >>> import tensorflow as tf
    >>> hello = tf.constant('hello, tensorflow!')
    >>> sess = tf.session()
    >>> print(sess.run(hello))
    hello, tensorflow!
    >>> a = tf.constant(10)
    >>> b = tf.constant(32)
    >>> print(sess.run(a + b))
    42
    >>>

openblas

sudo apt-get install -y libblas-test libopenblas-base libopenblas-dev

jupyter

   juypter is an awesome code sharing format that let   s you easily share
      notebooks    with code and tutorials. i will detail using it in the next
   post.
pip install -u ipython[all] jupyter

theano

   install the pre-requisites and install theano.
sudo apt-get install -y python-numpy python-scipy python-dev python-pip python-n
ose g++ python-pygments python-sphinx python-nose
sudo pip install theano

   yes that   s a capital in theano.

   test your theano installation. there should be no warnings/errors when
   the import command is executed.
python
>>> import theano
>>> exit()
nosetests theano

keras

   keras is an incredibly popular high level abstraction wrapper that can
   surf on top of theano and tensorflow. it   s installation and usage are
   so dead simple it   s not even funny.
sudo pip install keras

lasagne

   lasagne is another widely used high level wrapper that   s a bit more
   flexible than keras in that you can easily color outside the lines.
   think of keras as deep learning on rails and lasagne as the next step
   in your evolution. the instructions for lasagne install come from
   [72]here.
pip install -r [73]https://raw.githubusercontent.com/lasagne/lasagne/v0.1/requir
ements.txt

mxnet

   mxnet is a highly scalable framework [74]backed by amazon. [75]it   s
   install instructions can be found here. an install script for mxnet for
   python can be found right [76]here.

installing mxnet on ubuntu

   from the website:

     mxnet currently supports python, r, julia, and scala. for users of
     python and r on ubuntu operating systems, mxnet provides a set of
     git bash scripts that installs all of the required mxnet
     dependencies and the mxnet library.

     the simple installation scripts set up mxnet for python and r on
     computers running ubuntu 12 or later. the scripts install mxnet in
     your home folder ~/mxnet.

install mxnet for python

   clone the mxnet repository. in terminal, run the commands without
      sudo   :
git clone [77]https://github.com/dmlc/mxnet.git ~/mxnet --recursive

   we   re building with gpus, so add configurations to config.mk file:
cd ~/mxnet
cp make/config.mk .
echo "use_cuda=1" >>config.mk
echo "use_cuda_path=/usr/local/cuda" >>config.mk
echo "use_cudnn=1" >>config.mk

   install mxnet for python with all dependencies:
cd ~/mxnet/setup-utils
bash install-mxnet-ubuntu-python.sh

   add it to your path:
source ~/.bashrc

install mxnet for r

   we   ll need r so let   s do that now. the installation script to install
   mxnet for r can be found [78]here. the steps below call that script
   after setting up the r language.

   first add the r repo:
sudo echo    deb [79]http://cran.rstudio.com/bin/linux/ubuntu xenial/    | sudo tee
-a /etc/apt/sources.list

   add r to the ubuntu keyring:
gpg     keyserver keyserver.ubuntu.com     recv-key e084dab9
gpg -a     export e084dab9 | sudo apt-key add -

   install r-base:
sudo apt-get install r-base r-base-dev

   install r-studio (altering the command for the correct version number):
sudo apt-get install -y gdebi-core
wget [80]https://download1.rstudio.org/rstudio-0.99.896-amd64.deb
sudo gdebi -n rstudio-0.99.896-amd64.deb
rm rstudio-0.99.896-amd64.deb

   now install mxnet for r:
cd ~/mxnet/setup-utils
bash install-mxnet-ubuntu-r.sh

caffe

   these instructions come from [81]the caffe website. i found them to be
   a little flaky depending on how the wind was blowing that day, but your
   mileage may vary. frankly, i don   t use caffe all that much and many of
   the beginner tutorials out there won   t focus on it, so if this part
   screws up for you, just skip it for now and come back to it.

   install the prerequisites:
sudo apt-get install -y libprotobuf-dev libleveldb-dev libsnappy-dev libopencv-d
ev libhdf5-serial-dev protobuf-compiler
sudo apt-get install -y --no-install-recommends libboost-all-dev
sudo apt-get install -y libgflags-dev libgoogle-glog-dev liblmdb-dev

   clone the caffe repo:
cd ~/git
git clone [82]https://github.com/bvlc/caffe.git
cd caffe
cp makefile.config.example makefile.config

   to use cudnn set the flag use_cudnn := 1 in the makefile:
sed -i    s/# use_cudnn := 1/use_cudnn := 1/    makefile.config

   modify the blas parameters value to open:
sed -i 's/blas := atlas/blas := open/' makefile.config

   install the requirements, then build caffe, build the tests, run the
   tests and ensure that the all tests pass. note that all this takes some
   time. note again that the +1 indicates the number of gpus to build
   caffe with, so up it if you have more than one.
sudo pip install -r python/requirements.txt
make all -j $(($(nproc) + 1))
make test -j $(($(nproc) + 1))
make runtest -j $(($(nproc) + 1))

   build pycaffe, the python interface to caffe:
make pycaffe -j $(($(nproc) + 1))

   add caffe to your environment variable:
echo    export caffe_root=$(pwd)    >> ~/.bashrc
echo    export pythonpath=$caffe_root/python:$pythonpath    >> ~/.bashrc
source ~/.bashrc

   test to ensure that your caffe installation is successful. there should
   be no warnings/errors when the import command is executed.
ipython
>>> import caffe
>>> exit()

torch

   here are the torch install instructions from the [83]torch website.
   i   ve had some struggles with this framework installing but this usually
   works for most people.
git clone [84]https://github.com/torch/distro.git ~/git/torch     recursive
cd torch; bash install-deps;
./install.sh

scala

sudo apt-get -y install scala

anaconda

   download [85]anaconda for python 3.6 right here. it will also have a
   2.7.x version as well.

   install it:
sudo bash anaconda3   4.3.0-linux-x86_64.sh

   do not add it to your bashrc or when you reboot python will default to
   anaconda. it is set to    no    by default in the script but you might be
   tempted to do it as i was at first. don   t. you   ll want to keep the
   default pointed to ubuntu   s python as a number of things are dependent
   on it.

   besides anaconda let   s you create environments that let you move back
   and forth between versions.

   let   s create two anaconda environments:
conda create -n py2 python=2.7
conda create -n py3 python=3.6

   activate the 3 environment:
source activate py3

   now let   s install all the packages for anaconda:
conda install pip pandas scikit-learn scipy numpy matplotlib ipython-notebook se
aborn opencv scrappy nltk pattern

   now we install pygraphviz and the r bridge with pip which aren   t in
   conda:
pip install pygraphviz rpy2

   reboot:
sudo shutdown -r now

install tensorflow, theano, and keras for anaconda

   you   ll install these libraries for both the python 2 and 3 versions of
   anaconda. you may get better performance using the anaconda backed
   libraries, as they contain performance optimizations.

   let   s do python 3 first:
source activate py3
pip install tensorflow theano keras

   now deactivate the environment and activate the py2 environment:
source deactivate

   activate the python 2 environment:
source activate py2

   install for py2:
pip install tensorflow theano keras

   deactivate the environment:
source deactivate

   now you   re back in the standard ubuntu shell with the built in python
   2.7.x with all the frameworks we installed for the standard python that
   comes with ubuntu.

conclusion

   there you have it. you   ve purchased a top notch machine or a
   budget-friendly alternative. you   ve also got it setup with the latest
   and greatest software for deep learning.

   now get ready to do some heavy number crunching. dig up a tutorial and
   get to work! be on the look out for the next article in my series,
   which dives into my approach to the [86]kaggle data science bowl 2017,
   which races to beat lung cancer for a chance at prizes totaling one
   million dollars.

   again, be sure to check out the other articles in this series if you
   missed them:

   [87]learning ai if you suck at math         part 1         this article guides you
   through the essential books to read if you were never a math fan but
   you   re learning it as an adult.

   [88]learning ai if you suck at math         part 2         practical
   projects         this article guides you through getting started with your
   first projects.

   [89]learning ai if you suck at math         part 3         building an ai dream
   machine         this article guides you through getting a powerful deep
   learning machine setup and installed with all the latest and greatest
   frameworks.

   [90]learning ai if you suck at math         part 4         tensors illustrated
   (with cats!)         this one answers the ancient mystery: what the hell is a
   tensor?

   [91]learning ai if you suck at math         part 5         deep learning and
   convolutional neural nets in plain english         here we create our first
   python program and explore the inner workings of neural networks!

   [92]learning ai if you suck at math         part 6         math notation made
   easy         still struggling to understand those funny little symbols? let   s
   change that now!

   [93]learning ai if you suck at math         part 7         the magic of natural
   language processing         understand how google and siri understand what
   you   re mumbling.

   ############################################

   if you love my work please [94]do me the honor of visiting my patreon
   page because that   s how we change the future together. help me
   disconnect from the matrix and i   ll repay your generosity a hundred
   fold by focusing all my time and energy on writing, research and
   delivering amazing content for you and world.

   ###########################################

   if you enjoyed this tutorial, i   d love it if you could clap it up to
   recommend it to others. after that please feel free email the article
   off to a friend! thanks much.

   ###########################################
   [1*5gotoj42ui30cu210u737g.png]

   a bit about me: i   m an author, engineer and serial entrepreneur. during
   the last two decades, i   ve covered a broad range of tech from linux to
   virtualization and containers.

   you can check out my latest novel, [95]an epic chinese sci-fi civil war
   saga where china throws off the chains of communism and becomes the
   world   s first direct democracy, running a highly advanced, artificially
   intelligent decentralized app platform with no leaders.

[96]you can get a free copy of my first novel, the scorpion game, when you
join my readers group. readers have called it    the first serious competition
to neuromancer    and   detective noir meets johnny mnemonic.   

lastly, you can [97]join my private facebook group, the nanopunk posthuman
assassins, where we discuss all things tech, sci-fi, fantasy and more.

   ############################################

   i occasionally make coin from the links in my articles but i only
   recommend things that i own, use and love. check my [98]full policy
   here.

   ############################################

   thanks for reading!
   [99][1*0hqoaabq7xgpt-oyngiubg.png]
   [100][1*vgw1jka6hgnvwztsfmlnpg.png]
   [101][1*gkbpq1ruui0fvk2um_i4tq.png]

     [102]hacker noon is how hackers start their afternoons. we   re a part
     of the [103]@ami family. we are now [104]accepting submissions and
     happy to [105]discuss advertising & sponsorship opportunities.

     if you enjoyed this story, we recommend reading our [106]latest tech
     stories and [107]trending tech stories. until next time, don   t take
     the realities of the world for granted!

   [1*35tcjopcvq6lbb3i6wegqw.jpeg]

     * [108]machine learning
     * [109]docker
     * [110]artificial intelligence
     * [111]ai
     * [112]ai if you suck at math

   (button)
   (button)
   (button) 344 claps
   (button) (button) (button) 10 (button) (button)

     (button) blockedunblock (button) followfollowing
   go to the profile of daniel jeffries

[113]daniel jeffries

   medium member since mar 2017

   i am an author, futurist, systems architect, and thinker.

     (button) follow
   [114]hacker noon

[115]hacker noon

   how hackers start their afternoons.

     * (button)
       (button) 344
     * (button)
     *
     *

   [116]hacker noon
   never miss a story from hacker noon, when you sign up for medium.
   [117]learn more
   never miss a story from hacker noon
   (button) get updatesget updates

references

   visible links
   1. https://plus.google.com/103654360130207659246
   2. https://hackernoon.com/osd.xml
   3. android-app://com.medium.reader/https/medium.com/p/d5a3023140ef
   4. https://medium.com/
   5. https://medium.com/
   6. https://medium.com/m/signin?redirect=https://hackernoon.com/learning-ai-if-you-suck-at-math-p3-building-an-ai-dream-machine-or-budget-friendly-special-d5a3023140ef&source=--------------------------nav_reg&operation=login
   7. https://medium.com/m/signin?redirect=https://hackernoon.com/learning-ai-if-you-suck-at-math-p3-building-an-ai-dream-machine-or-budget-friendly-special-d5a3023140ef&source=--------------------------nav_reg&operation=register
   8. https://hackernoon.com/?source=logo-lo_rznmgvqgjgsd---3a8144eabfe3
   9. https://hackernoon.com/latest-tech-stories/home
  10. https://hackernoon.com/editors-top-tech-stories/home
  11. https://hackernoon.com/your-most-frequently-asked-questions-about-our-terms-of-service-how-to-opt-out-and-more-66abf239a151
  12. https://hackernoon.com/sign-up-for-hacker-noon-2-0-9ff1ea0b60cc
  13. https://community.hackernoon.com/t/what-will-replace-google-search/992/14
  14. https://hackernoon.com/@dan.jeffries
  15. https://hackernoon.com/learning-ai-if-you-suck-at-math-8bdfb4b79037#.n4c9ftf4n
  16. https://hackernoon.com/learning-ai-if-you-suck-at-math-part-two-practical-projects-47d7a1e4e21f#.yo1o1ar5h
  17. https://hackernoon.com/learning-ai-if-you-suck-at-math-p4-tensors-illustrated-with-cats-27f0002c9b32#.2jpelkuhd
  18. https://hackernoon.com/learning-ai-if-you-suck-at-math-p5-deep-learning-and-convolutional-neural-nets-in-plain-english-cda79679bbe3#.7tfyjjvdd
  19. https://hackernoon.com/learning-ai-if-you-suck-at-math-p6-math-notation-made-easy-1277d76a1fe5#.qa2f24xvq
  20. https://hackernoon.com/learning-ai-if-you-suck-at-math-p7-the-magic-of-natural-language-processing-f3819a689386
  21. http://www.nvidia.com/object/deep-learning-system.html
  22. http://amzn.to/2kuchob
  23. http://amzn.to/2kxypjz
  24. https://my.vmware.com/en/web/vmware/info/slug/desktop_end_user_computing/vmware_workstation_pro/12_0
  25. https://pubs.vmware.com/workstation-12/index.jsp?topic=/com.vmware.ws.using.doc/guid-f5186526-2382-4f4a-8009-3d07773a1404.html
  26. https://hackernoon.com/tagged/ai
  27. http://www.forbes.com/sites/aarontilley/2016/11/30/nvidia-deep-learning-ai-intel/
  28. http://www.yaabot.com/26356/intels-deep-learning-based-chips-launching-2017/
  29. https://www.nvidia.com/en-us/geforce/products/10series/titan-x-pascal/
  30. http://amzn.to/2kuchob
  31. https://www.kaggle.com/c/data-science-bowl-2017
  32. https://us.hardware.info/reviews/6033/13/nvidia-geforce-gtx-titan-x-sli--3-way-sli--4-way-sli-review-insane-performance-conclusion
  33. http://amzn.to/2kxypjz
  34. http://amzn.to/2kukdpr
  35. http://amzn.to/2ky5gdf
  36. http://amzn.to/2kxktpq
  37. http://amzn.to/2jyrkhn
  38. http://amzn.to/2kujgjy
  39. http://amzn.to/2ky2cha
  40. http://amzn.to/2jyhwnt
  41. http://amzn.to/2jfikmf
  42. http://amzn.to/2ku9zq3
  43. http://amzn.to/2kjhmao
  44. http://amzn.to/2k12nkv
  45. http://amzn.to/2ky31qo
  46. http://amzn.to/2kuhxsz
  47. https://github.com/nvidia/nvidia-docker
  48. https://github.com/floydhub/dl-docker
  49. https://github.com/floydhub/dl-docker/issues/36
  50. https://github.com/floydhub/dl-docker/issues/38
  51. https://github.com/floydhub/dl-setup
  52. https://hackernoon.com/tagged/deep-learning
  53. https://www.continuum.io/downloads
  54. https://www.r-project.org/about.html
  55. https://www.scala-lang.org/
  56. http://www.nvidia.com/download/index.aspx?lang=en-us
  57. https://developer.nvidia.com/cuda-downloads
  58. https://developer.nvidia.com/cudnn
  59. http://jupyter.org/
  60. https://www.tensorflow.org/
  61. http://deeplearning.net/software/theano/
  62. http://caffe.berkeleyvision.org/
  63. http://torch.ch/
  64. http://mxnet.io/
  65. https://keras.io/
  66. https://github.com/lasagne/lasagne
  67. https://www.ubuntu.com/download/server
  68. https://rufus.akeo.ie/
  69. https://developer.nvidia.com/cuda-toolkit
  70. https://developer.nvidia.com/cudnn
  71. https://hackernoon.com/tagged/tensorflow
  72. http://lasagne.readthedocs.io/en/latest/user/installation.html
  73. https://raw.githubusercontent.com/lasagne/lasagne/v0.1/requirements.txt
  74. http://www.allthingsdistributed.com/2016/11/mxnet-default-framework-deep-learning-aws.html
  75. http://mxnet.io/get_started/setup.html
  76. https://raw.githubusercontent.com/dmlc/mxnet/master/setup-utils/install-mxnet-ubuntu-python.sh
  77. https://github.com/dmlc/mxnet.git
  78. https://raw.githubusercontent.com/dmlc/mxnet/master/setup-utils/install-mxnet-ubuntu-r.sh
  79. http://cran.rstudio.com/bin/linux/ubuntu
  80. https://download1.rstudio.org/rstudio-0.99.896-amd64.deb
  81. http://caffe.berkeleyvision.org/install_apt.html
  82. https://github.com/bvlc/caffe.git
  83. http://torch.ch/docs/getting-started.html
  84. https://github.com/torch/distro.git
  85. https://www.continuum.io/downloads
  86. https://www.kaggle.com/c/data-science-bowl-2017
  87. https://hackernoon.com/learning-ai-if-you-suck-at-math-8bdfb4b79037#.ng7ggn5d9
  88. https://hackernoon.com/learning-ai-if-you-suck-at-math-part-two-practical-projects-47d7a1e4e21f#.yo1o1ar5h
  89. https://hackernoon.com/learning-ai-if-you-suck-at-math-p3-building-an-ai-dream-machine-or-budget-friendly-special-d5a3023140ef#.6frka033t
  90. https://hackernoon.com/learning-ai-if-you-suck-at-math-p4-tensors-illustrated-with-cats-27f0002c9b32#.2jpelkuhd
  91. https://hackernoon.com/learning-ai-if-you-suck-at-math-p5-deep-learning-and-convolutional-neural-nets-in-plain-english-cda79679bbe3#.xjah79lsd
  92. https://hackernoon.com/learning-ai-if-you-suck-at-math-p6-math-notation-made-easy-1277d76a1fe5
  93. https://hackernoon.com/learning-ai-if-you-suck-at-math-p7-the-magic-of-natural-language-processing-f3819a689386
  94. https://www.patreon.com/danjeffries
  95. http://amzn.to/2gag249
  96. http://meuploads.com/join-my-readers-group/
  97. https://www.facebook.com/groups/1736763229929363/
  98. http://meuploads.com/disclosure/
  99. http://bit.ly/hackernoonfb
 100. https://goo.gl/k7xybx
 101. https://goo.gl/4ofytp
 102. http://bit.ly/hackernoon
 103. http://bit.ly/atamiatami
 104. http://bit.ly/hackernoonsubmission
 105. mailto:partners@amipublications.com
 106. http://bit.ly/hackernoonlatestt
 107. https://hackernoon.com/trending
 108. https://hackernoon.com/tagged/machine-learning?source=post
 109. https://hackernoon.com/tagged/docker?source=post
 110. https://hackernoon.com/tagged/artificial-intelligence?source=post
 111. https://hackernoon.com/tagged/ai?source=post
 112. https://hackernoon.com/tagged/ai-if-you-suck-at-math?source=post
 113. https://hackernoon.com/@dan.jeffries
 114. https://hackernoon.com/?source=footer_card
 115. https://hackernoon.com/?source=footer_card
 116. https://hackernoon.com/
 117. https://medium.com/@medium/personalize-your-medium-experience-with-users-publications-tags-26a41ab1ee0c#.hx4zuv3mg

   hidden links:
 119. https://hackernoon.com/@dan.jeffries?source=post_header_lockup
 120. https://medium.com/p/d5a3023140ef/share/twitter
 121. https://medium.com/p/d5a3023140ef/share/facebook
 122. https://hackernoon.com/@dan.jeffries?source=footer_card
 123. https://medium.com/p/d5a3023140ef/share/twitter
 124. https://medium.com/p/d5a3023140ef/share/facebook
