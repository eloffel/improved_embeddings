   #[1]publisher [2]medium [3]alternate

   [4]homepage
   [5]homepage
   [6]merantix
   [7]merantix
   [8]sign in[9]get started
     __________________________________________________________________

[10]picasso: a free open-source visualizer for convolutional neural networks

cloudy with a chance of tanks

   [11]go to the profile of ryan henderson
   [12]ryan henderson (button) blockedunblock (button) followfollowing
   may 16, 2017

   while it   s easier than ever to define and train deep neural networks
   (dnns), understanding the learning process remains somewhat opaque.
   monitoring the loss or classification error during training won   t
   always prevent your model from learning the wrong thing or learning a
   proxy for your intended classification task. to understand what we
   mean, consider [13]this (possibly apocryphal) story [1]:

     once upon a time, the us army wanted to use neural networks to
     automatically detect camouflaged enemy tanks. the researchers
     trained a neural net on 50 photos of camouflaged tanks in trees, and
     50 photos of trees without tanks   

     wisely, the researchers had originally taken 200 photos, 100 photos
     of tanks and 100 photos of trees. they had used only 50 of each for
     the training set. the researchers ran the neural network on the
     remaining 100 photos, and without further training the neural
     network classified all remaining photos correctly. success
     confirmed! the researchers handed the finished work to the pentagon,
     which soon handed it back, complaining that in their own tests the
     neural network did no better than chance at discriminating photos.

     it turned out that in the researchers    dataset, photos of
     camouflaged tanks had been taken on cloudy days, while photos of
     plain forest had been taken on sunny days. the neural network had
     learned to distinguish cloudy days from sunny days, instead of
     distinguishing camouflaged tanks from empty forest.

   [1*ry6ayn4uwac5lfavuyr__a.gif]
   definitely a real image of a modern tank from the training set.
   [14]source: wikipedia

   regardless of the veracity of this tale, the point is familiar to
   machine learning researchers: training metrics don   t always tell the
   whole story. and the stakes are higher than ever before: for rising
   applications of deep learning like autonomous vehicles, these kinds of
   training errors [15]can be deadly [2].

   fortunately, standard visualizations like [16]partial occlusion [3] and
   [17]saliency maps [4] provide a sanity check on the learning process.
   [18]toolkits [5] for standard neural network visualizations exist,
   along with tools for monitoring the [19]training process. they   re often
   tied to the deep learning framework, if not model-specific. could a
   general, easy-to-setup tool for generating standard visualizations have
   saved these researchers from detecting sunny days instead of tanks?

picasso

   [20]picasso is a free open-source ([21]eclipse public license) dnn
   visualization tool that gives you partial occlusion and saliency maps
   with minimal fuss. at merantix, we work with a variety of neural
   network architectures; we developed picasso to make it easy to see
   standard visualizations across our models in our various verticals:
   including applications in [22]automotive, such as understanding when
   road segmentation or id164 fail; [23]advertisement, such as
   understanding why certain creatives receive higher click-through rates;
   and [24]medical imaging, such as analyzing what regions in a ct or
   x-ray image contain irregularities.

   picasso is a [25]flask application that glues together a deep-learning
   framework with a set of default and user-defined visualizations. you
   can use the built-in visualizations and easily add your own. picasso
   was developed to work with checkpointed keras and tensorflow neural
   networks. if you want to try it out but don   t have any trained models,
   we provide tensorflow and keras [26]mnist checkpoints and a keras
   [27]vgg16 checkpoint for you.
   [1*hlhdtbwlh7dkrds4wnxy4g.gif]
   an overview of the application flow with the default settings. the user
   has loaded a keras model trained on the mnist dataset, and generates a
   partial occlusion visualization on a couple handwritten digit images.
   see below for an in-depth explanation of occlusion maps.

   at merantix, we are particularly interested in convolutional neural
   networks (id98s) that take images as inputs and do classification. we
   developed picasso with these parameters in mind. however, the framework
   is flexible enough to use on all kinds of models. while the included
   visualizations should be fairly robust across different nns, you can
   still implement model-specific visualizations if you want to.

   we provide a few standard visualizations out of the box:
    1. [28]partial occlusion occlude parts of the image and see how the
       classification changes.
    2. [29]saliency map compute derivatives of class predictions with
       respect to the input image.
    3. class prediction not a visualization per se, but can be a handy,
       simple check on the learning process.

   and we have a couple more in the works! for a more in-depth exposition,
   see our paper on [30]arxiv.

picasso in practice

   let   s attack the tank problem with picasso   s two builtin
   visualizations: partial occlusion and saliency maps. in these examples,
   we   ll used a pre-trained vgg16 model for classification. we already
   know this model is pretty good at classifying tanks: can we use these
   visualizations to check that model is actually classifying based on the
   tank and not, say, the sky?
   [1*epfbw5fnfvz3m4ggpdp4ta.png]
   by sequentially blocking out parts of the image, we can tell which
   regions are more important to classification. this image was classified
   by the [31]vgg16 model, with a 94% classification id203 of
      tank.    bright parts of the image correspond to higher id203 of
   the given classification. for instance, the sky regions are very bright
   because occluding the sky doesn   t affect the id203 of this image
   being classified as a tank. and conversely, the tank tread regions are
   darker because without them, it   s hard to for the model to know if it   s
   looking at a tank.

   we can see how this visualization may have helped the army: it   s clear
   that when the    tanky    parts are missing (for instance, the tank
   treads), the model can   t successfully classify it. interestingly, when
   you block some of the tread, there   s a higher id203 of
   classifying the image as a half-track. this intuitively makes sense,
   because a [32]half-track has regular wheels in the front.
   [1*3bplabhnbgyntbfhmill3g.png]
   the model is quite sure this is a half-track         unless you block out the
   wheels! it   s also quite sure it   s not a tank; that is, unless you
   occlude the wheels. image source: [33]wikipedia

   in addition to partial occlusions, we also provide saliency maps
   out-of-the-box. saliency maps look at the derivative of the input image
   (via id26) with respect to classification. a high value at a
   given pixel means changing this pixel should more dramatically affect
   the classification.
   [1*yib_thfiforp_vw3vrvxea.png]
   saliency map for the tank. brighter pixels indicate higher values for
   the derivative of    tank    with respect to that input pixel for this
   image. the brightest pixels appear to be in the tank region of the
   image, which is a good sign. notice that with a few exceptions, the
   non-tank areas are largely dark         meaning changing these pixels should
   not make the image more or less    tanky.   

adding visualizations

   we wanted it to be particularly easy to integrate new visualizations.
   all you need to do is drop your visualization code in the
   visualizations folder and cook up an html template to display it.

   [34]see the tutorial on the [35]classprobabilites[36] visualization for
   an example on how to build very simple visualization.
   [1*jl_6m1nwkkdamgrl04uula.png]
   giving the relative classification probabilities is about the simplest
   visualization you can make.

using your own models

   naturally, you   ll want to use the included visualizations with your own
   trained neural networks. [37]we   ve tried to make this as simple as
   possible, but at the minimum you   ll need to define three methods:
    1. preprocess tell the visualization how to change uploaded images
       into nn inputs
    2. postprocess tell the visualization how to change flattened
       intermediate layers to the image dimensions (this is needed by
       visualizations which operate on intermediate layers, like saliency
       maps)
    3. decode_prob tell the visualization how to interpret the raw output,
       usually an array of probabilities, by annotating with class names

   how to construct these functions is detailed in this tutorial. these
   functions can be specified separately from the source code for the app.
   [1*vgcqgwhstrbgljoauvwmxg.png]
   the results for a saliency map visualization. the app is using the
   keras framework with a [38]vgg16 model. this example comes prepackaged
   with the code. since saliency maps depend on the derivative of the
   input layers with respect to an intermediate layer, you must tell the
   visualization how to reshape the output tensor back into an image with
   `decode_prob`.

contributing

   we   re very open to suggestions about how better to structure our
   application. and if you   d like to contribute a visualization or
   anything else, even better! head over to our [39]github repository for
   more. we   re releasing picasso under the epl because we intend for it to
   become part of the [40]eclipse foundation.

acknowledgements

     * [41]elias and [42]filippo for early code contributions and finding
       bugs and issues.
     * [43]john, [44]josh, [45]rasmus, and [46]stefan for their careful
       code review and feedback on this article.
     * [47]david and [48]nader for reviewing and discussion of this
       article.

references

    1. yudkowsky, eliezer.    artificial intelligence as a positive and
       negative factor in global risk.    global catastrophic risks, edited
       by nick bostrom and milan m.   irkovi  , 308   345. new york: oxford
       university press. 2008.
    2.    tesla driver killed in crash with autopilot active, nhtsa
       investigating   . the verge. n.p., 2017. web. 11 may 2017.
    3. zeiler, matthew d., and rob fergus.    visualizing and understanding
       convolutional networks.    european conference on id161.
       springer international publishing, 2014.
    4. simonyan, karen, andrea vedaldi, and andrew zisserman.    deep inside
       convolutional networks: visualising image classification models and
       saliency maps.    iclr workshop, 2014.
    5. yosinski, jason, et al.    understanding neural networks through deep
       visualization.    deep learning workshop, international conference on
       machine learning (icml), 2015.

   thanks to [49]josh chen, [50]rasmus rothe, and [51]nader al-naji.
     * [52]machine learning
     * [53]artificial intelligence
     * [54]visualization
     * [55]neural networks
     * [56]deep learning

   (button)
   (button)
   (button) 572 claps
   (button) (button) (button) 5 (button) (button)

     (button) blockedunblock (button) followfollowing
   [57]go to the profile of ryan henderson

[58]ryan henderson

   failed chemist

     (button) follow
   [59]merantix

[60]merantix

   transforming the world with curious minds

     * (button)
       (button) 572
     * (button)
     *
     *

   [61]merantix
   never miss a story from merantix, when you sign up for medium.
   [62]learn more
   never miss a story from merantix
   (button) get updatesget updates

references

   visible links
   1. https://plus.google.com/103654360130207659246
   2. https://medium.com/osd.xml
   3. android-app://com.medium.reader/https/medium.com/p/d8ed3a35cfc5
   4. https://medium.com/
   5. https://medium.com/
   6. https://medium.com/merantix?source=avatar-lo_qsrzbpyvcwuz-c748a4ee67e5
   7. https://medium.com/merantix?source=logo-lo_qsrzbpyvcwuz---c748a4ee67e5
   8. https://medium.com/m/signin?redirect=https://medium.com/merantix/picasso-a-free-open-source-visualizer-for-id98s-d8ed3a35cfc5&source=--------------------------nav_reg&operation=login
   9. https://medium.com/m/signin?redirect=https://medium.com/merantix/picasso-a-free-open-source-visualizer-for-id98s-d8ed3a35cfc5&source=--------------------------nav_reg&operation=register
  10. https://github.com/merantix/picasso
  11. https://medium.com/@rhsimplex?source=post_header_lockup
  12. https://medium.com/@rhsimplex
  13. http://intelligence.org/files/aiposnegfactor.pdf
  14. https://en.wikipedia.org/wiki/tank#/media/file:ft-17-argonne-1918.gif
  15. https://www.theverge.com/2016/6/30/12072408/tesla-autopilot-car-crash-death-autonomous-model-s
  16. https://arxiv.org/abs/1311.2901
  17. https://arxiv.org/abs/1312.6034
  18. https://github.com/yosinski/deep-visualization-toolbox
  19. https://www.tensorflow.org/get_started/summaries_and_tensorboard
  20. https://github.com/merantix/picasso
  21. https://www.eclipse.org/legal/epl-v10.html
  22. http://www.merantix.com/industry/automotive/
  23. http://www.merantix.com/industry/advertising/
  24. http://www.merantix.com/industry/health/
  25. http://flask.pocoo.org/
  26. http://yann.lecun.com/exdb/mnist/
  27. http://www.robots.ox.ac.uk/~vgg/research/very_deep/
  28. https://arxiv.org/abs/1311.2901
  29. https://arxiv.org/pdf/1312.6034.pdf
  30. https://arxiv.org/abs/1705.05627
  31. http://www.robots.ox.ac.uk/~vgg/research/very_deep/
  32. https://en.wikipedia.org/wiki/half-track
  33. https://upload.wikimedia.org/wikipedia/commons/c/c8/m3_half_track,_thunder_over_michigan_2006.jpg
  34. https://picasso.readthedocs.io/en/latest/visualizations.html
  35. https://picasso.readthedocs.io/en/latest/visualizations.html
  36. https://picasso.readthedocs.io/en/latest/visualizations.html
  37. https://picasso.readthedocs.io/en/latest/models.html
  38. http://www.robots.ox.ac.uk/~vgg/research/very_deep/
  39. https://github.com/merantix/picasso
  40. https://eclipse.org/org/foundation/
  41. https://github.com/sylvus
  42. https://github.com/scopelf
  43. https://github.com/johnmcspedon
  44. https://github.com/jwayne
  45. https://github.com/rrothe
  46. https://github.com/knub
  47. https://github.com/dmrd
  48. https://www.linkedin.com/in/nader-al-naji-86b14a3a/
  49. https://medium.com/@jwaynechen?source=post_page
  50. https://medium.com/@rasmus.rothe?source=post_page
  51. https://medium.com/@naderalnaji?source=post_page
  52. https://medium.com/tag/machine-learning?source=post
  53. https://medium.com/tag/artificial-intelligence?source=post
  54. https://medium.com/tag/visualization?source=post
  55. https://medium.com/tag/neural-networks?source=post
  56. https://medium.com/tag/deep-learning?source=post
  57. https://medium.com/@rhsimplex?source=footer_card
  58. https://medium.com/@rhsimplex
  59. https://medium.com/merantix?source=footer_card
  60. https://medium.com/merantix?source=footer_card
  61. https://medium.com/merantix
  62. https://medium.com/@medium/personalize-your-medium-experience-with-users-publications-tags-26a41ab1ee0c#.hx4zuv3mg

   hidden links:
  64. https://medium.com/p/d8ed3a35cfc5/share/twitter
  65. https://medium.com/p/d8ed3a35cfc5/share/facebook
  66. https://medium.com/p/d8ed3a35cfc5/share/twitter
  67. https://medium.com/p/d8ed3a35cfc5/share/facebook
