   #[1]facebook research    feed [2]facebook research    comments feed
   [3]facebook research    learning to segment comments feed [4]alternate
   [5]alternate

   [6]skip to content

   iframe: [7]https://www.googletagmanager.com/ns.html?id=gtm-wspss3d

   [8]facebook research
   search ____________________ (button) submit
   [9]toggle search (button)

     * [10]research areas (button) show dropdown menu
          + [11]ar/vr
          + [12]connectivity
          + [13]computational photography & intelligent cameras
          + [14]id161
          + [15]data science
          + [16]economics & computation
          + [17]facebook ai research
          + [18]human computer interaction & ux
          + [19]machine learning
          + [20]natural language processing & speech
          + [21]security & privacy
          + [22]systems & networking
     * [23]publications
     * [24]people
     * [25]academic programs (button) show dropdown menu
          + [26]facebook fellowship program
          + [27]research awards
          + [28]research collaborations
          + [29]research award recipients
          + [30]visiting researchers and postdocs
     * [31]downloads & projects
     * [32]careers
     * [33]blog

   search ____________________ (button) submit
   [34]close search

   august 25, 2016

learning to segment

   by: [35]piotr dollar

   can a computer distinguish between the many objects in a photograph as
   effortlessly as the human eye?

   when humans look at an image, they can identify objects down to the
   last pixel. at [36]facebook ai research (fair) we   re pushing machine
   vision to the next stage     our goal is to similarly understand images
   and objects at the pixel level.

   over the past few years, progress in deep convolutional neural networks
   and the advent of ever more powerful computing architectures has led to
   machine vision systems rapidly increasing in their accuracy and
   capabilities. we   ve witnessed massive advances in image classification
   (what is in the image?) as well as id164 (where are the
   objects?). see panels (a) and (b) in the image below. but this is just
   the beginning of understanding the most relevant visual content of any
   image or video. recently we   ve been designing techniques that identify
   and segment each and every object in an image, as in rightmost panel
   (c) of the image below, a key capability that will enable entirely new
   applications.

   post00013_image0002

   the main new algorithms driving our advances are the [37]deepmask^1
   segmentation framework coupled with our new [38]sharpmask^2 segment
   refinement module. together, they have enabled fair   s machine vision
   systems to detect and precisely delineate every object in an image. the
   final stage of our recognition pipeline uses a specialized
   convolutional net, which we call [39]multipathnet^3, to label each
   object mask with the object type it contains (e.g. person, dog, sheep).
   we will return to the details shortly.

   we   re making the code for [40]deepmask+sharpmask as well as
   [41]multipathnet     along with our research papers and [42]demos related
   to them     open and accessible to all, with the hope that they   ll help
   rapidly advance the field of machine vision. as we continue improving
   these core technologies we   ll continue publishing our latest results
   and updating the open source tools we make available to the community.

finding patterns in the pixels

   let   s take a look at the building blocks of these algorithms.

   glance at the first photo below, the one on the left. what do you see?
   a photographer operating his old-school camera. a grassy field.
   buildings in the background. and you probably notice countless other
   details as well. a machine sees none of this; an image is encoded as an
   array of numbers representing color values for each pixel, as in the
   second photo, the one on the right. so how do we enable machine vision
   to go from pixels to a deeper understanding of an image?

   post00013_image0003

   it   s not an easy task, due to the near infinite variability of objects
   and scenes in real-world settings. objects vary in their shapes and
   appearances, their sizes and positions, their textures and colors.
   couple this with the inherent complexity of real scenes, variable
   backgrounds and lighting conditions, and the general richness of our
   world and you see can start to see how the problem can be so difficult
   for machines.

   enter deep convolutional neural networks. rather than trying to
   programmatically define rule-based systems for id164, deep
   nets are relatively simple architectures with tens of millions of
   parameters that are trained rather than designed. these networks
   automatically learn patterns from millions of annotated examples, and
   having seen a sufficient number of such examples start to generalize to
   novel images. deep nets are particularly adapt at answering yes/no
   questions about an image (classification)     for example, does an image
   contain a sheep?

segmenting objects

   so how do we employ deep networks for detection and segmentation? the
   technique we use in deepmask is to think of segmentation as a very
   large number of binary classification problems. first, for every
   (overlapping) patch in an image we ask: does this patch contain an
   object? second, if the answer to the first question is yes for a given
   patch, then for every pixel in the patch we ask: is that pixel part of
   the central object in the patch? we use deep networks to answer each
   yes/no question, and by cleverly designing our networks so that
   computation is shared for every patch and every pixel, we can quickly
   discover and segment all the objects in an image.

   deepmask employs a fairly traditional feedforward deep network design.
   in such networks, with progressively deeper network stages information
   is more abstract and semantically meaningful. for example, early layers
   in a deep net might capture edges and blobs, while upper layers tend to
   capture more semantic concepts such as the presence of an animal   s face
   or limbs. by design, these upper-layer features are computed at a
   fairly low spatial resolution (for both computational reasons and in
   order to be invariant to small shifts in pixel locations). this
   presents a problem for mask prediction: the upper layer features can be
   used to predict masks that capture the general shape on an object but
   fail to precisely capture object boundaries.

   which brings us to sharpmask. sharpmask refines the output of deepmask,
   generating higher-fidelity masks that more accurately delineate object
   boundaries. while deepmask predicts coarse masks in a feedforward pass
   through the network, sharpmask reverses the flow of information in a
   deep network and refines the predictions made by deepmask by using
   features from progressively earlier layers in the network. think of it
   this way: to capture general object shape, you have to have a
   high-level understanding of what you are looking at (deepmask), but to
   accurately place the boundaries you need to look back at lower-level
   features all the way down to the pixels (sharpmask). in essence, we aim
   to make use of information from all layers of a network, with minimal
   additional overhead.

   below are some example outputs generated by deepmask and refined by
   sharpmask. to keep the visualizations simple we only show predicted
   masks that best align to the objects actually present in the images (as
   annotated by humans). note that the system is not perfect yet, objects
   with red outlines are those annotated by humans but missed by deepmask.

   post00013_image0004

classifying objects

   deepmask knows nothing about specific object types, so while it can
   delineate both a dog and a sheep, it can   t tell them apart. plus,
   deepmask is not very selective and can generate masks for image regions
   that are not especially interesting. so how do we narrow down the pool
   of relevant masks and identify the objects that are actually present?

   as you might expect, we turn to deep neural networks once again. given
   a mask generated by deepmask, we train a separate deep net to classify
   the object type of each mask (and    none    is a valid answer as well).
   here we are following the foundational paradigm called region-id98, or
   [43]rid98 for short, pioneered by [44]ross girshick (now also a member
   of fair). rid98 is a two-stage procedure where a first stage is used to
   draw attention to certain image regions, and in a second stage a deep
   net is used to identify the objects present. when developing rid98, the
   first stage of processing available was fairly primitive. by using
   deepmask as the first stage for rid98 and exploiting the power of deep
   networks we get a significant boost in detection accuracy and also gain
   the ability to segment objects.

   to further boost performance, we also focused on using a specialized
   network architecture to classify each mask (the second stage of rid98).
   as we discussed, real-world photographs contains objects at multiple
   scales, in context and among clutter, and under frequent occlusion.
   standard deep nets can have difficulty in such situations. to address
   this, we proposed a modified network that we call multipathnet. as its
   name implies, multipathnet allows information to flow along multiple
   paths through the net, enabling it to exploit information at multiple
   image scales and in surrounding image context.

   in summary, our id164 system follows a three stage
   procedure: (1) deepmask generates initial object masks, (2) sharpmask
   refines these masks, and finally (3) multipathnet identifies the
   objects delineated by each mask. here are some example outputs of our
   complete system:

   post00013_image0005

   not perfect but not too shabby given that the technology to do this
   simply didn   t exist a few short years ago!

wide-ranging uses

   there are wide ranging potential uses for visual recognition
   technology. building off this existing id161 technology and
   enabling computers to recognize objects in photos, for instance, it
   will be easier to search for specific images without an explicit tag on
   each photo. people with vision loss, too, will be able to understand
   what is in a photo their friends share because the system will be able
   to tell them, regardless of the caption posted alongside the image.

   most recently we [45]demonstrated technology we   re developing for blind
   users that will assess photos and describe their content. currently,
   visually impaired users browsing photos on facebook only hear the name
   of the person who shared the photo, followed by the term    photo,    when
   they come upon an image in their news feed. instead we aim to offer
   richer descriptions, such as    photo contains beach, trees, and three
   smiling people.    furthermore, leveraging the segmentation technology
   we   ve been developing, our goal is to enable even more immersive
   experiences that allow users to    see    a photo by swiping their finger
   across an image and having the system describe the content they   re
   touching.

   as we move forward, we will continue to improve our detection and
   segmentation algorithms. you can imagine one day this image detection,
   segmentation, and identification capability applied to augmented
   reality in areas like commerce, health, or others.

   post00013_image0006

   in addition, our next challenge will be to apply these techniques to
   video, where objects are moving, interacting, and changing over time.
   we   ve already made some progress with id161 techniques to
   watch videos and [46]understand and classify what   s in them in real
   time. real-time classification could help surface relevant and
   important live videos on facebook, while applying more refined
   techniques to detect scenes, objects, and actions over space and time
   could one day allow for real-time narration. we   re excited to continue
   pushing the state of the art and providing better experiences on
   facebook for everyone.

   [1] deepmask: [47]learning to segment object candidates. pedro o.
   pinheiro, ronan collobert, piotr doll  r (nips 2015)

   [2] sharpmask: [48]learning to refine object segments. pedro o.
   pinheiro, tsung-yi lin, ronan collobert, piotr doll  r (eccv 2016)

   [3] multipathnet: [49]a multipath network for id164. sergey
   zagoruyko, adam lerer, tsung-yi lin, pedro o. pinheiro, sam gross,
   soumith chintala, piotr doll  r (bmvc 2016)
   areas: [50]facebook ai research facebook ai research

related content

   [51]

   blog

open-sourcing pytorch-biggraph for faster embeddings of extremely large
graphs

   april 2, 2019
   [52]

   blog

turing award presented to yann lecun, geoffrey hinton and yoshua bengio

   march 27, 2019
   [53]

   blog

q&a with facebook ai residents tatiana likhomanenko and siddharth karamcheti

   march 15, 2019
   [54]

   blog

facebook ai researchers share perspectives on diversity on international
women   s day

   march 8, 2019

   iframe:
   [55]https://www.facebook.com/plugins/page.php?href=https%3a%2f%2fwww.fa
   cebook.com%2facademics&tabs&width=340&height=70&small_header=true&adapt
   _container_width=true&hide_cover=true&show_facepile=false&appid

     * [56]rss feed
     * [57]about
     * [58]careers
     * [59]privacy
     * [60]cookies
     * [61]terms
     * [62]help

   facebook    2019

   to help personalize content, tailor and measure ads, and provide a
   safer experience, we use cookies. by clicking or navigating the site,
   you agree to allow our collection of information on and off facebook
   through cookies. learn more, including about available controls:
   [63]cookies policy

references

   1. https://research.fb.com/feed/
   2. https://research.fb.com/comments/feed/
   3. https://research.fb.com/learning-to-segment/feed/
   4. https://research.fb.com/wp-json/oembed/1.0/embed?url=https://research.fb.com/learning-to-segment/
   5. https://research.fb.com/wp-json/oembed/1.0/embed?url=https://research.fb.com/learning-to-segment/&format=xml
   6. https://research.fb.com/learning-to-segment/#content
   7. https://www.googletagmanager.com/ns.html?id=gtm-wspss3d
   8. https://research.fb.com/
   9. javascript:void(0)
  10. https://research.fb.com/research-areas/
  11. https://research.fb.com/category/augmented-reality-virtual-reality/
  12. https://research.fb.com/category/connectivity/
  13. https://research.fb.com/category/computational-photography-and-intelligent-cameras/
  14. https://research.fb.com/category/computer-vision/
  15. https://research.fb.com/category/data-science/
  16. https://research.fb.com/category/economics-and-computation/
  17. https://research.fb.com/category/facebook-ai-research
  18. https://research.fb.com/category/human-computer-interaction-and-ux/
  19. https://research.fb.com/category/machine-learning/
  20. https://research.fb.com/category/natural-language-processing-and-speech/
  21. https://research.fb.com/category/security-and-privacy/
  22. https://research.fb.com/category/systems-and-networking/
  23. https://research.fb.com/publications/
  24. https://research.fb.com/people/
  25. https://research.fb.com/programs/
  26. https://research.fb.com/programs/fellowship/
  27. https://research.fb.com/programs/research-awards/
  28. https://research.fb.com/programs/research-collaborations/
  29. https://research.fb.com/programs/faculty-awards
  30. https://research.fb.com/programs/post-docs-and-sabbaticals/
  31. https://research.fb.com/downloads/
  32. https://research.fb.com/careers/
  33. https://research.fb.com/blog/
  34. javascript:void(0)
  35. https://research.fb.com/people/dollar-piotr/
  36. https://research.fb.com/category/facebook-ai-research-fair/
  37. https://arxiv.org/abs/1506.06204
  38. https://arxiv.org/abs/1603.08695
  39. http://arxiv.org/abs/1604.02135
  40. https://github.com/facebookresearch/deepmask
  41. https://github.com/facebookresearch/multipathnet
  42. https://www.facebook.com/aidemos/
  43. https://arxiv.org/abs/1311.2524
  44. https://research.facebook.com/ross-girshick/
  45. https://www.facebook.com/zuck/videos/10102801434799001/
  46. https://www.facebook.com/video.php?v=10154015375107200
  47. https://arxiv.org/abs/1506.06204
  48. https://arxiv.org/abs/1603.08695
  49. http://arxiv.org/abs/1604.02135
  50. https://research.fb.com/category/facebook-ai-research/
  51. https://ai.facebook.com/blog/open-sourcing-pytorch-biggraph-for-faster-embeddings-of-extremely-large-graphs/
  52. https://research.fb.com/turing-award-presented-to-yann-lecun-geoffrey-hinton-and-yoshua-bengio/
  53. https://research.fb.com/qa-with-facebook-ai-residents-tatiana-likhomanenko-and-siddharth-karamcheti/
  54. https://research.fb.com/facebook-ai-researchers-share-perspectives-on-diversity-on-international-womens-day/
  55. https://www.facebook.com/plugins/page.php?href=https://www.facebook.com/academics&tabs&width=340&height=70&small_header=true&adapt_container_width=true&hide_cover=true&show_facepile=false&appid
  56. https://research.fb.com/feed/
  57. https://www.facebook.com/facebook
  58. https://www.facebook.com/careers/university/
  59. https://www.facebook.com/about/privacy
  60. https://www.facebook.com/help/cookies
  61. https://www.facebook.com/policies
  62. https://www.facebook.com/help
  63. https://www.facebook.com/policies/cookies/
