   #[1]sebastian ruder

   [2]sebastian ruder
     * [3]about
     * [4]tags
     * [5]papers
     * [6]talks
     * [7]news
     * [8]faq
     * [9]nlp news
     * [10]nlp progress
     * [11]contact

   29 may 2017 / [12]id72

an overview of id72 in deep neural networks

   an overview of id72 in deep neural networks

   this post gives a general overview of the current state of multi-task
   learning.

   note: if you are looking for a review paper, this blog post is also
   available as an [13]article on arxiv.

   table of contents:
     * [14]introduction
     * [15]motivation
     * [16]two mtl methods for deep learning
          + [17]hard parameter sharing
          + [18]soft parameter sharing
     * [19]why does mtl work?
          + [20]implicit data augmentation
          + [21]attention focusing
          + [22]eavesdropping
          + [23]representation bias
          + [24]id173
     * [25]mtl in non-neural models
          + [26]block-sparse id173
          + [27]learning task relationships
     * [28]recent work on mtl for deep learning
          + [29]deep relationship networks
          + [30]fully-adaptive feature sharing
          + [31]cross-stitch networks
          + [32]low supervision
          + [33]a joint many-task model
          + [34]weighting losses with uncertainty
          + [35]tensor factorisation for mtl
          + [36]sluice networks
          + [37]what should i share in my model?
     * [38]auxiliary tasks
          + [39]related task
          + [40]adversarial
          + [41]hints
          + [42]focusing attention
          + [43]quantization smoothing
          + [44]predicting inputs
          + [45]using the future to predict the present
          + [46]representation learning
          + [47]what auxiliary tasks are helpful?
     * [48]conclusion

introduction

   in machine learning (ml), we typically care about optimizing for a
   particular metric, whether this is a score on a certain benchmark or a
   business kpi. in order to do this, we generally train a single model or
   an ensemble of models to perform our desired task. we then fine-tune
   and tweak these models until their performance no longer increases.
   while we can generally achieve acceptable performance this way, by
   being laser-focused on our single task, we ignore information that
   might help us do even better on the metric we care about. specifically,
   this information comes from the training signals of related tasks. by
   sharing representations between related tasks, we can enable our model
   to generalize better on our original task. this approach is called
   id72 (mtl) and will be the topic of this blog post.

   id72 has been used successfully across all applications
   of machine learning, from natural language processing ^[49][1] and
   id103 ^[50][2] to id161 ^[51][3] and drug
   discovery ^[52][4]. mtl comes in many guises: joint learning, learning
   to learn, and learning with auxiliary tasks are only some names that
   have been used to refer to it. generally, as soon as you find yourself
   optimizing more than one id168, you are effectively doing
   id72 (in contrast to single-task learning). in those
   scenarios, it helps to think about what you are trying to do explicitly
   in terms of mtl and to draw insights from it.

   even if you're only optimizing one loss as is the typical case, chances
   are there is an auxiliary task that will help you improve upon your
   main task. rich caruana ^[53][5] summarizes the goal of mtl succinctly:
   "mtl improves generalization by leveraging the domain-specific
   information contained in the training signals of related tasks".

   over the course of this blog post, i will try to give a general
   overview of the current state of id72, in particular
   when it comes to mtl with deep neural networks. i will first motivate
   mtl from different perspectives. i will then introduce the two most
   frequently employed methods for mtl in deep learning. subsequently, i
   will describe mechanisms that together illustrate why mtl works in
   practice. before looking at more advanced neural network-based mtl
   methods, i will provide some context by discussing the literature in
   mtl. i will then introduce some more powerful recently proposed methods
   for mtl in deep neural networks. finally, i will talk about commonly
   used types of auxiliary tasks and discuss what makes a good auxiliary
   task for mtl.

motivation

   we can motivate id72 in different ways: biologically, we
   can see id72 as being inspired by human learning. for
   learning new tasks, we often apply the knowledge we have acquired by
   learning related tasks. for instance, a baby first learns to recognize
   faces and can then apply this knowledge to recognize other objects.

   from a pedagogical perspective, we often learn tasks first that provide
   us with the necessary skills to master more complex techniques. this is
   true for learning the proper way of [54]falling in martial arts, e.g.
   judo as much as learning to program.

   taking an example out of pop culture, we can also consider the karate
   kid (1984) (thanks to [55]margaret mitchell and [56]adrian benton for
   the inspiration). in the movie, sensei mr miyagi teaches the karate kid
   seemingly unrelated tasks such as sanding the floor and waxing a car.
   in hindsight, these, however, turn out to equip him with invaluable
   skills that are [57]relevant for learning karate.

   finally, we can motivate id72 from a machine learning
   point of view: we can view id72 as a form of inductive
   transfer. inductive transfer can help improve a model by introducing an
   inductive bias, which causes a model to prefer some hypotheses over
   others. for instance, a common form of inductive bias is \(\ell_1\)
   id173, which leads to a preference for sparse solutions. in
   the case of mtl, the inductive bias is provided by the auxiliary tasks,
   which cause the model to prefer hypotheses that explain more than one
   task. as we will see shortly, this generally leads to solutions that
   generalize better.

two mtl methods for deep learning

   so far, we have focused on theoretical motivations for mtl. to make the
   ideas of mtl more concrete, we will now look at the two most commonly
   used ways to perform id72 in deep neural networks. in
   the context of deep learning, id72 is typically done
   with either hard or soft parameter sharing of hidden layers.

hard parameter sharing

   hard parameter sharing is the most commonly used approach to mtl in
   neural networks and goes back to ^[58][6]. it is generally applied by
   sharing the hidden layers between all tasks, while keeping several
   task-specific output layers.
   hard parameter sharing figure 1: hard parameter sharing for multi-task
   learning in deep neural networks

   hard parameter sharing greatly reduces the risk of overfitting. in
   fact, ^[59][7] showed that the risk of overfitting the shared
   parameters is an order n -- where n is the number of tasks -- smaller
   than overfitting the task-specific parameters, i.e. the output layers.
   this makes sense intuitively: the more tasks we are learning
   simultaneously, the more our model has to find a representation that
   captures all of the tasks and the less is our chance of overfitting on
   our original task.

soft parameter sharing

   in soft parameter sharing on the other hand, each task has its own
   model with its own parameters. the distance between the parameters of
   the model is then regularized in order to encourage the parameters to
   be similar. ^[60][8] for instance use the \(\ell_2\) norm for
   id173, while ^[61][9] use the trace norm.
   soft parameter sharing figure 2: soft parameter sharing for multi-task
   learning in deep neural networks

   the constraints used for soft parameter sharing in deep neural networks
   have been greatly inspired by id173 techniques for mtl that
   have been developed for other models, which we will soon discuss.

why does mtl work?

   even though an inductive bias obtained through id72
   seems intuitively plausible, in order to understand mtl better, we need
   to look at the mechanisms that underlie it. most of these have first
   been proposed by caruana (1998). for all examples, we will assume that
   we have two related tasks \(a\) and \(b\), which rely on a common
   hidden layer representation \(f\).

implicit data augmentation

   mtl effectively increases the sample size that we are using for
   training our model. as all tasks are at least somewhat noisy, when
   training a model on some task \(a\), our aim is to learn a good
   representation for task \(a\) that ideally ignores the data-dependent
   noise and generalizes well. as different tasks have different noise
   patterns, a model that learns two tasks simultaneously is able to learn
   a more general representation. learning just task \(a\) bears the risk
   of overfitting to task \(a\), while learning \(a\) and \(b\) jointly
   enables the model to obtain a better representation \(f\) through
   averaging the noise patterns.

attention focusing

   if a task is very noisy or data is limited and high-dimensional, it can
   be difficult for a model to differentiate between relevant and
   irrelevant features. mtl can help the model focus its attention on
   those features that actually matter as other tasks will provide
   additional evidence for the relevance or irrelevance of those features.

eavesdropping

   some features \(g\) are easy to learn for some task \(b\), while being
   difficult to learn for another task \(a\). this might either be because
   \(a\) interacts with the features in a more complex way or because
   other features are impeding the model's ability to learn \(g\). through
   mtl, we can allow the model to eavesdrop, i.e. learn \(g\) through task
   \(b\). the easiest way to do this is through hints ^[62][10], i.e.
   directly training the model to predict the most important features.

representation bias

   mtl biases the model to prefer representations that other tasks also
   prefer. this will also help the model to generalize to new tasks in the
   future as a hypothesis space that performs well for a sufficiently
   large number of training tasks will also perform well for learning
   novel tasks as long as they are from the same environment ^[63][11].

id173

   finally, mtl acts as a regularizer by introducing an inductive bias. as
   such, it reduces the risk of overfitting as well as the rademacher
   complexity of the model, i.e. its ability to fit random noise.

mtl in non-neural models

   in order to better understand mtl in deep neural networks, we will now
   look to the existing literature on mtl for linear models, kernel
   methods, and bayesian algorithms. in particular, we will discuss two
   main ideas that have been pervasive throughout the history of
   id72: enforcing sparsity across tasks through norm
   id173; and modelling the relationships between tasks.

   note that many approaches to mtl in the literature deal with a
   homogenous setting: they assume that all tasks are associated with a
   single output, e.g. the multi-class mnist dataset is typically cast as
   10 binary classification tasks. more recent approaches deal with a more
   realistic, heterogeneous setting where each task corresponds to a
   unique set of outputs.

block-sparse id173

   in order to better connect the following approaches, let us first
   introduce some notation. we have \(t\) tasks. for each task \(t\), we
   have a model \(m_t\) with parameters \(a_t\) of dimensionality \(d\).
   we can write the parameters as a column vector \(a_t =
   \begin{bmatrix}a_{1, t} \ \ldots \ a_{d, t} \end{bmatrix}^\top \). we
   now stack these column vectors \(a_1, \ldots, a_t\) column by column to
   form a matrix \(a \in
   \mathbb{r}^{d \times t}\). the \(i\)-th row of \(a\) then contains the
   parameter \(a_{i, \cdot}\) corresponding to the \(i\)-th feature of the
   model for every task, while the \(j\)-th column of \(a\) contains the
   parameters \(a_{\cdot,j}\) corresponding to the \(j\)-th model.

   many existing methods make some sparsity assumption with regard to the
   parameters of our models. ^[64][12] assume that all models share a
   small set of features. in terms of our task parameter matrix \(a\),
   this means that all but a few rows are \(0\), which corresponds to only
   a few features being used across all tasks. in order to enforce this,
   they generalize the \(\ell_1\) norm to the mtl setting. recall that the
   \(\ell_1\) norm is a constraint on the sum of the parameters, which
   forces all but a few parameters to be exactly \(0\). it is also known
   as lasso (__l__east __a__bsolute __s__hrinkage and __s__election
   __o__perator).

   while in the single-task setting, the \(\ell_1\) norm is computed based
   on the parameter vector \(a_t\) of the respective task \(t\), for mtl
   we compute it over our task parameter matrix \(a\). in order to do
   this, we first compute an \(\ell_q\) norm across each row \(a_i\)
   containing the parameter corresponding to the \(i\)-th feature across
   all tasks, which yields a vector \(b = \begin{bmatrix}|a_1|_q \ldots
   |a_d|_q \end{bmatrix} \in \mathbb{r}^d\). we then compute the
   \(\ell_1\) norm of this vector, which forces all but a few entries of
   \(b\), i.e. rows in \(a\) to be \(0\).

   as we can see, depending on what constraint we would like to place on
   each row, we can use a different \(\ell_q\). in general, we refer to
   these mixed-norm constraints as \(\ell_1/\ell_q\) norms. they are also
   known as block-sparse id173, as they lead to entire rows of
   \(a\) being set to \(0\). ^[65][13] use \(\ell_1/\ell_\infty\)
   id173, while argyriou et al. (2007) use a mixed
   \(\ell_1/\ell_2\) norm. the latter is also known as group lasso and was
   first proposed by ^[66][14].

   argyriou et al. (2007) also show that the problem of optimizing the
   non-convex group lasso can be made convex by penalizing the trace norm
   of \(a\), which forces \(a\) to be low-rank and thereby constrains the
   column parameter vectors \(a_{\cdot, 1}, \ldots, a_{\cdot, t}\) to live
   in a low-dimensional subspace. ^[67][15] furthermore establish upper
   bounds for using the group lasso in id72.

   as much as this block-sparse id173 is intuitively plausible,
   it is very dependent on the extent to which the features are shared
   across tasks. ^[68][16] show that if features do not overlap by much,
   \(\ell_1/\ell_q\) id173 might actually be worse than
   element-wise \(\ell_1\) id173.

   for this reason, ^[69][17] improve upon block-sparse models by
   proposing a method that combines block-sparse and element-wise sparse
   id173. they decompose the task parameter matrix \(a\) into two
   matrices \(b\) and \(s\) where \(a = b + s\). \(b\) is then enforced to
   be block-sparse using \(\ell_1/\ell_\infty\) id173, while
   \(s\) is made element-wise sparse using lasso. recently, ^[70][18]
   propose a distributed version of group-sparse id173.

learning task relationships

   while the group-sparsity constraint forces our model to only consider a
   few features, these features are largely used across all tasks. all of
   the previous approaches thus assume that the tasks used in multi-task
   learning are closely related. however, each task might not be closely
   related to all of the available tasks. in those cases, sharing
   information with an unrelated task might actually hurt performance, a
   phenomenon known as negative transfer.

   rather than sparsity, we would thus like to leverage prior knowledge
   indicating that some tasks are related while others are not. in this
   scenario, a constraint that enforces a id91 of tasks might be
   more appropriate. ^[71][19] suggest to impose a id91 constraint
   by penalizing both the norms of our task column vectors \(a_{\cdot, 1},
   \ldots, a_{\cdot, t}\) as well as their variance with the following
   constraint:

   \(\omega = |\bar{a}|^2 + \dfrac{\lambda}{t} \sum^t_{t=1} | a_{\cdot, t}
   - \bar{a} |^2 \)

   where \(\bar{a} = (\sum^t_{t=1} a_{\cdot, t})/t \) is the mean
   parameter vector. this penalty enforces a id91 of the task
   parameter vectors \(a_{\cdot, 1}, \ldots, a_{\cdot, t}\) towards their
   mean that is controlled by \(\lambda\). they apply this constraint to
   kernel methods, but it is equally applicable to linear models.

   a similar constraint for id166s was also proposed by ^[72][20]. their
   constraint is inspired by bayesian methods and seeks to make all models
   close to some mean model. in id166s, the loss thus trades off having a
   large margin for each id166 with being close to the mean model.

   ^[73][21] make the assumptions underlying cluster id173 more
   explicit by formalizing a cluster constraint on \(a\) under the
   assumption that the number of clusters \(c\) is known in advance. they
   then decompose the penalty into three separate norms:
     * a global penalty which measures how large our column parameter
       vectors are on average: \(\omega_{mean}(a) = |\bar{a}|^2 \).
     * a measure of between-cluster variance that measures how close to
       each other the clusters are: \(\omega_{between}(a) = \sum^c_{c=1}
       t_c | \bar{a}_c - \bar{a} |^2 \) where \(t_c\) is the number of
       tasks in the \(c\)-th cluster and \(\bar{a}_c\) is the mean vector
       of the task parameter vectors in the \(c\)-th cluster.
     * a measure of within-cluster variance that gauges how compact each
       cluster is: \(\omega_{within} = \sum^c_{c=1} \sum_{t \in j(c)} |
       a_{\cdot, t} - \bar{a}_c |^2 \) where \(j(c)\) is the set of tasks
       in the \(c\)-th cluster.

   the final constraint then is the weighted sum of the three norms:

   \(\omega(a) = \lambda_1 \omega_{mean}(a) + \lambda_2
   \omega_{between}(a) + \lambda_3 \omega_{within}(a)\).

   as this constraint assumes clusters are known in advance, they
   introduce a convex relaxation of the above penalty that allows to learn
   the clusters at the same time.

   in another scenario, tasks might not occur in clusters but have an
   inherent structure. ^[74][22] extend the group lasso to deal with tasks
   that occur in a tree structure, while ^[75][23] apply it to tasks with
   graph structures.

   while the previous approaches to modelling the relationship between
   tasks employ norm id173, other approaches do so without
   id173: ^[76][24] were the first ones who presented a task
   id91 algorithm using k-nearest neighbour, while ^[77][25] learn a
   common structure from multiple related tasks with an application to
   semi-supervised learning.

   much other work on learning task relationships for id72
   uses bayesian methods:
   ^[78][26] propose a bayesian neural network for id72 by
   placing a prior on the model parameters to encourage similar parameters
   across tasks. ^[79][27] extend gaussian processes (gp) to mtl by
   inferring parameters for a shared covariance matrix. as this is
   computationally very expensive, they adopt a sparse approximation
   scheme that greedily selects the most informative examples. ^[80][28]
   also use gp for mtl by assuming that all models are sampled from a
   common prior.

   ^[81][29] place a gaussian as a prior distribution on each
   task-specific layer. in order to encourage similarity between different
   tasks, they propose to make the mean task-dependent and introduce a
   id91 of the tasks using a mixture distribution. importantly, they
   require task characteristics that define the clusters and the number of
   mixtures to be specified in advance.

   building on this, ^[82][30] draw the distribution from a dirichlet
   process and enable the model to learn the similarity between tasks as
   well as the number of clusters. they then share the same model among
   all tasks in the same cluster. ^[83][31] propose a hierarchical
   bayesian model, which learns a latent task hierarchy, while ^[84][32]
   use a gp-based id173 for mtl and extend a previous gp-based
   approach to be more computationally feasible in larger settings.

   other approaches focus on the online id72 setting:
   ^[85][33] adapt some existing methods such as the approach by evgeniou
   et al. (2005) to the online setting. they also propose a mtl extension
   of the regularized id88, which encodes task relatedness in a
   matrix. they use different forms of id173 to bias this task
   relatedness matrix, e.g. the closeness of the task characteristic
   vectors or the dimension of the spanned subspace. importantly, similar
   to some earlier approaches, they require the task characteristics that
   make up this matrix to be provided in advance. ^[86][34] then extend
   the previous approach by learning the task relationship matrix.

   ^[87][35] assume that tasks form disjoint groups and that the tasks
   within each group lie in a low-dimensional subspace. within each group,
   tasks share the same feature representation whose parameters are
   learned jointly together with the group assignment matrix using an
   alternating minimization scheme. however, a total disjointness between
   groups might not be the ideal way, as the tasks might still share some
   features that are helpful for prediction.

   ^[88][36] in turn allow two tasks from different groups to overlap by
   assuming that there exist a small number of latent basis tasks. they
   then model the parameter vector \(a_t\) of every actual task \(t\) as a
   linear combination of these: \(a_t = ls_t\) where \(l\ \in
   \mathbb{r}^{k \times d}\) is a matrix containing the parameter vectors
   of \(k\) latent tasks, while \(s_t\ \in \mathbb{r}^k\) is a vector
   containing the coefficients of the linear combination. in addition,
   they constrain the linear combination to be sparse in the latent tasks;
   the overlap in the sparsity patterns between two tasks then controls
   the amount of sharing between these. finally, ^[89][37] learn a small
   pool of shared hypotheses and then map each task to a single
   hypothesis.

recent work on mtl for deep learning

   while many recent deep learning approaches have used multi-task
   learning -- either explicitly or implicitly -- as part of their model
   (prominent examples will be featured in the next section), they all
   employ the two approaches we introduced earlier, hard and soft
   parameter sharing. in contrast, only a few papers have looked at
   developing better mechanisms for mtl in deep neural networks.

deep relationship networks

   in mtl for id161, approaches often share the convolutional
   layers, while learning task-specific fully-connected layers. ^[90][38]
   improve upon these models by proposing deep relationship networks. in
   addition to the structure of shared and task-specific layers, which can
   be seen in figure 3, they place matrix priors on the fully connected
   layers, which allow the model to learn the relationship between tasks,
   similar to some of the bayesian models we have looked at before. this
   approach, however, still relies on a pre-defined structure for sharing,
   which may be adequate for well-studied id161 problems, but
   prove error-prone for novel tasks.
   deep relationship networks figure 3: a deep relationship network with
   shared convolutional and task-specific fully connected layers with
   matrix priors (long and wang, 2015).

fully-adaptive feature sharing

   starting at the other extreme, ^[91][39] propose a bottom-up approach
   that starts with a thin network and dynamically widens it greedily
   during training using a criterion that promotes grouping of similar
   tasks. the widening procedure, which dynamically creates branches can
   be seen in figure 4. however, the greedy method might not be able to
   discover a model that is globally optimal, while assigning each branch
   to exactly one task does not allow the model to learn more complex
   interactions between tasks.
   fully-adaptive feature sharing figure 4: the widening procedure for
   fully-adaptive feature sharing (lu et al., 2016).

cross-stitch networks

   ^[92][40] start out with two separate model architectures just as in
   soft parameter sharing. they then use what they refer to as
   cross-stitch units to allow the model to determine in what way the
   task-specific networks leverage the knowledge of the other task by
   learning a linear combination of the output of the previous layers.
   their architecture can be seen in figure 5, in which they only place
   cross-stitch units after pooling and fully-connected layers.
   cross-stitch networks figure 5: cross-stitch networks for two tasks
   (misra et al., 2016).

low supervision

   in contrast, in natural language processing (nlp), recent work focused
   on finding better task hierarchies for id72: ^[93][41]
   show that low-level tasks, i.e. nlp tasks typically used for
   preprocessing such as part-of-speech tagging and named entity
   recognition, should be supervised at lower layers when used as
   auxiliary task.

a joint many-task model

   building on this finding, ^[94][42] pre-define a hierarchical
   architecture consisting of several nlp tasks, which can be seen in
   figure 6, as a joint model for id72.
   joint many-task model figure 6: a joint many-task model (hashimoto et
   al., 2016).

weighting losses with uncertainty

   instead of learning the structure of sharing, ^[95][43] take a
   orthogonal approach by considering the uncertainty of each task. they
   then adjust each task's relative weight in the cost function by
   deriving a multi-task id168 based on maximizing the gaussian
   likelihood with task-dependant uncertainty. their architecture for
   per-pixel depth regression, semantic and instance segmentation can be
   seen in figure 7.
   uncertainty-based id168 weighting figure 7: uncertainty-based
   id168 weighting for id72 (kendall et al., 2017).

tensor factorisation for mtl

   more recent work seeks to generalize existing approaches to mtl to deep
   learning: ^[96][44] generalize some of the previously discussed matrix
   factorisation approaches using tensor factorisation to split the model
   parameters into shared and task-specific parameters for every layer.

sluice networks

   finally, we propose sluice networks ^[97][45], a model that generalizes
   deep learning-based mtl approaches such as hard parameter sharing and
   cross-stitch networks, block-sparse id173 approaches, as well
   as recent nlp approaches that create a task hierarchy. the model, which
   can be seen in figure 8, allows to learn what layers and subspaces
   should be shared, as well as at what layers the network has learned the
   best representations of the input sequences.
   sluice networks figure 8: a sluice network for two tasks (ruder et al.,
   2017).

what should i share in my model?

   having surveyed these recent approaches, let us now briefly summarize
   and draw a conclusion on what to share in our deep mtl models. most
   approaches in the history of mtl have focused on the scenario where
   tasks are drawn from the same distribution (baxter, 1997). while this
   scenario is beneficial for sharing, it does not always hold. in order
   to develop robust models for mtl, we thus have to be able to deal with
   unrelated or only loosely related tasks.

   while early work in mtl for deep learning has pre-specified which
   layers to share for each task pairing, this strategy does not scale and
   heavily biases mtl architectures. hard parameter sharing, a technique
   that was originally proposed by caruana (1996), is still the norm 20
   years later. while useful in many scenarios, hard parameter sharing
   quickly breaks down if tasks are not closely related or require
   reasoning on different levels. recent approaches have thus looked
   towards learning what to share and generally outperform hard parameter
   sharing. in addition, giving our models the capacity to learn a task
   hierarchy is helpful, particularly in cases that require different
   granularities.

   as mentioned initially, we are doing mtl as soon as we are optimizing
   more than one id168. rather than constraining our model to
   compress the knowledge of all tasks into the same parameter space, it
   is thus helpful to draw on the advances in mtl that we have discussed
   and enable our model to learn how the tasks should interact with each
   other.

auxiliary tasks

   mtl is a natural fit in situations where we are interested in obtaining
   predictions for multiple tasks at once. such scenarios are common for
   instance in finance or economics forecasting, where we might want to
   predict the value of many possibly related indicators, or in
   bioinformatics where we might want to predict symptoms for multiple
   diseases simultaneously. in scenarios such as drug discovery, where
   tens or hundreds of active compounds should be predicted, mtl accuracy
   increases continuously with the number of tasks (ramsundar et al.,
   2015).

   in most situations, however, we only care about performance on one
   task. in this section, we will thus look at how we can find a suitable
   auxiliary task in order to still reap the benefits of multi-task
   learning.

related task

   using a related task as an auxiliary task for mtl is the classical
   choice. to get an idea what a related task can be, we will present some
   prominent examples. caruana (1998) uses tasks that predict different
   characteristics of the road as auxiliary tasks for predicting the
   steering direction in a self-driving car; ^[98][46] use head pose
   estimation and facial attribute id136 as auxiliary tasks for facial
   landmark detection; ^[99][47] jointly learn query classification and
   web search; girshick (2015) jointly predicts the class and the
   coordinates of an object in an image; finally, ^[100][48] jointly
   predict the phoneme duration and frequency profile for text-to-speech.

adversarial

   often, labeled data for a related task is unavailable. in some
   circumstances, however, we have access to a task that is opposite of
   what we want to achieve. this data can be leveraged using an
   adversarial loss, which does not seek to minimize but maximize the
   training error using a gradient reversal layer. this setup has found
   recent success in id20 ^[101][49]. the adversarial task in
   this case is predicting the domain of the input; by reversing the
   gradient of the adversarial task, the adversarial task loss is
   maximized, which is beneficial for the main task as it forces the model
   to learn representations that cannot distinguish between domains.

hints

   as mentioned before, mtl can be used to learn features that might not
   be easy to learn just using the original task. an effective way to
   achieve this is to use hints, i.e. predicting the features as an
   auxiliary task. recent examples of this strategy in the context of
   natural language processing are ^[102][50] who predict whether an input
   sentence contains a positive or negative sentiment word as auxiliary
   tasks for id31 and ^[103][51] who predict whether a name
   is present in a sentence as auxiliary task for name error detection.

focusing attention

   similarly, the auxiliary task can be used to focus attention on parts
   of the image that a network might normally ignore. for instance, for
   learning to steer (caruana, 1998) a single-task model might typically
   ignore lane markings as these make up only a small part of the image
   and are not always present. predicting lane markings as auxiliary task,
   however, forces the model to learn to represent them; this knowledge
   can then also be used for the main task. analogously, for facial
   recognition, one might learn to predict the location of facial
   landmarks as auxiliary tasks, since these are often distinctive.

quantization smoothing

   for many tasks, the training objective is quantized, i.e. while a
   continuous scale might be more plausible, labels are available as a
   discrete set. this is the case in many scenarios that require human
   assessment for data gathering, such as predicting the risk of a disease
   (e.g. low/medium/high) or id31
   (positive/neutral/negative). using less quantized auxiliary tasks might
   help in these cases, as they might be learned more easily due to their
   objective being smoother.

predicting inputs

   in some scenarios, it is impractical to use some features as inputs as
   they are unhelpful for predicting the desired objective. however, they
   might still be able to guide the learning of the task. in those cases,
   the features can be used as outputs rather than inputs. ^[104][52]
   present several problems where this is applicable.

using the future to predict the present

   in many situations, some features only become available after the
   predictions are supposed to be made. for instance, for self-driving
   cars, more accurate measurements of obstacles and lane markings can be
   made once the car is passing them. caruana (1998) also gives the
   example of pneumonia prediction, after which the results of additional
   medical trials will be available. for these examples, the additional
   data cannot be used as features as it will not be available as input at
   runtime. however, it can be used as an auxiliary task to impart
   additional knowledge to the model during training.

representation learning

   the goal of an auxiliary task in mtl is to enable the model to learn
   representations that are shared or helpful for the main task. all
   auxiliary tasks discussed so far do this implicitly: they are closely
   related to the main task, so that learning them likely allows the model
   to learn beneficial representations. a more explicit modelling is
   possible, for instance by employing a task that is known to enable a
   model to learn transferable representations. the language modelling
   objective as employed by cheng et al. (2015) and ^[105][53] fulfils
   this role. in a similar vein, an autoencoder objective can also be used
   as an auxiliary task.

what auxiliary tasks are helpful?

   in this section, we have discussed different auxiliary tasks that can
   be used to leverage mtl even if we only care about one task. we still
   do not know, though, what auxiliary task will be useful in practice.
   finding an auxiliary task is largely based on the assumption that the
   auxiliary task should be related to the main task in some way and that
   it should be helpful for predicting the main task.

   however, we still do not have a good notion of when two tasks should be
   considered similar or related. caruana (1998) defines two tasks to be
   similar if they use the same features to make a decision. baxter (2000)
   argues only theoretically that related tasks share a common optimal
   hypothesis class, i.e. have the same inductive bias. ^[106][54] propose
   that two tasks are \(\mathcal{f}\)-related if the data for both tasks
   can be generated from a fixed id203 distribution using a set of
   transformations \(\mathcal{f}\). while this allows to reason over tasks
   where different sensors collect data for the same classification
   problem, e.g. object recognition with data from cameras with different
   angles and lighting conditions, it is not applicable to tasks that do
   not deal with the same problem. xue et al. (2007) finally argue that
   two tasks are similar if their classification boundaries, i.e.
   parameter vectors are close.

   in spite of these early theoretical advances in understanding task
   relatedness, we have not made much recent progress towards this goal.
   task similarity is not binary, but resides on a spectrum. more similar
   tasks should help more in mtl, while less similar tasks should help
   less. allowing our models to learn what to share with each task might
   allow us to temporarily circumvent the lack of theory and make better
   use even of only loosely related tasks. however, we also need to
   develop a more principled notion of task similarity with regard to
   id72 in order to know which tasks we should prefer.

   recent work ^[107][55] have found auxiliary tasks with compact and
   uniform label distributions to be preferable for sequence tagging
   problems in nlp, which we have confirmed in experiments (ruder et al.,
   2017). in addition, gains have been found to be more likely for main
   tasks that quickly plateau with non-plateauing auxiliary tasks
   ^[108][56].

   these experiments, however, have so far been limited in scope and
   recent findings only provide the first clues towards a deeper
   understanding of id72 in neural networks.

conclusion

   in this overview, i have reviewed both the history of literature in
   id72 as well as more recent work on mtl for deep
   learning. while mtl is being more frequently used, the 20-year old hard
   parameter sharing paradigm is still pervasive for neural-network based
   mtl. recent advances on learning what to share, however, are promising.
   at the same time, our understanding of tasks -- their similarity,
   relationship, hierarchy, and benefit for mtl -- is still limited and we
   need to learn more about them to gain a better understanding of the
   generalization capabilities of mtl with regard to deep neural networks.

   i hope you found this overview helpful. if i made any error, missed a
   reference, or misrepresented some aspect, or if you would just like to
   share your thoughts, please leave a comment below.

printable version and citation

   this blog post is also available as an [109]article on arxiv, in case
   you want to refer to it later.

   in case you found it helpful, consider citing the corresponding arxiv
   article as:
   sebastian ruder (2017). an overview of id72 in deep
   neural networks. arxiv preprint arxiv:1706.05098.
     __________________________________________________________________

    1. collobert, r., & weston, j. (2008). a unified architecture for
       natural language processing. proceedings of the 25th international
       conference on machine learning - icml    08, 20(1), 160   167.
       [110]https://doi.org/10.1145/1390156.1390177 [111]      
    2. deng, l., hinton, g. e., & kingsbury, b. (2013). new types of deep
       neural network learning for id103 and related
       applications: an overview. 2013 ieee international conference on
       acoustics, speech and signal processing, 8599   8603.
       [112]https://doi.org/10.1109/icassp.2013.6639344 [113]      
    3. girshick, r. (2015). fast r-id98. in proceedings of the ieee
       international conference on id161 (pp. 1440   1448).
       [114]https://doi.org/10.1109/iccv.2015.169 [115]      
    4. ramsundar, b., kearnes, s., riley, p., webster, d., konerding, d.,
       & pande, v. (2015). massively multitask networks for drug
       discovery. [116]https://doi.org/https://arxiv.org/abs/1502.02072
       [117]      
    5. caruana, r. (1998). multitask learning. autonomous agents and
       multi-agent systems, 27(1), 95   133.
       [118]https://doi.org/10.1016/j.csl.2009.08.003 [119]      
    6. caruana, r. "multitask learning: a knowledge-based source of
       inductive bias." proceedings of the tenth international conference
       on machine learning. 1993. [120]      
    7. baxter, j. (1997). a bayesian/information theoretic model of
       learning to learn via multiple task sampling. machine learning, 28,
       7   39. retrieved from
       [121]http://link.springer.com/article/10.1023/a:1007327622663
       [122]      
    8. duong, l., cohn, t., bird, s., & cook, p. (2015). low resource
       id33: cross-lingual parameter sharing in a neural
       network parser. proceedings of the 53rd annual meeting of the
       association for computational linguistics and the 7th international
       joint conference on natural language processing (short papers),
       845   850. [123]      
    9. yang, y., & hospedales, t. m. (2017). trace norm regularised deep
       id72. in workshop track - iclr 2017. retrieved from
       [124]http://arxiv.org/abs/1606.04038 [125]      
   10. abu-mostafa, y. s. (1990). learning from hints in neural networks.
       journal of complexity, 6(2), 192   198.
       [126]https://doi.org/10.1016/0885-064x(90)90006-y [127]      
   11. baxter, j. (2000). a model of inductive bias learning. journal of
       artificial intelligence research, 12, 149   198. [128]      
   12. argyriou, a., & pontil, m. (2007). multi-task id171. in
       advances in neural information processing systems.
       [129]http://doi.org/10.1007/s10994-007-5040-8 [130]      
   13. c.zhang and j.huang. model selection consistency of the lasso
       selection in high-dimensional id75. annals of
       statistics, 36:1567   1594, 2008 [131]      
   14. yuan, ming, and yi lin. "model selection and estimation in
       regression with grouped variables." journal of the royal
       statistical society: series b (statistical methodology) 68.1
       (2006): 49-67. [132]      
   15. lounici, k., pontil, m., tsybakov, a. b., & van de geer, s. (2009).
       taking advantage of sparsity in id72. stat, (1).
       retrieved from [133]http://arxiv.org/pdf/0903.1468 [134]      
   16. negahban, s., & wainwright, m. j. (2008). joint support recovery
       under high-dimensional scaling : benefits and perils of
       \(\ell_{1,\infty}\)-id173. advances in neural information
       processing systems, 1161   1168. [135]      
   17. jalali, a., ravikumar, p., sanghavi, s., & ruan, c. (2010). a dirty
       model for id72. advances in neural information
       processing systems. retrieved from
       [136]https://papers.nips.cc/paper/4125-a-dirty-model-for-multi-task
       -learning.pdf [137]      
   18. liu, s., pan, s. j., & ho, q. (2016). distributed multi-task
       relationship learning. in proceedings of the 19th international
       conference on artificial intelligence and statistics (aistats) (pp.
       751   760). retrieved from [138]http://arxiv.org/abs/1612.04022
       [139]      
   19. evgeniou, t., micchelli, c., & pontil, m. (2005). learning multiple
       tasks with kernel methods. journal of machine learning research, 6,
       615   637. retrieved from [140]http://discovery.ucl.ac.uk/13423/
       [141]      
   20. evgeniou, t., & pontil, m. (2004). regularized id72.
       international conference on knowledge discovery and data mining,
       109. [142]https://doi.org/10.1145/1014052.1014067 [143]      
   21. jacob, l., vert, j., bach, f. r., & vert, j. (2009). clustered
       id72: a convex formulation. advances in neural
       information processing systems 21, 745   752. retrieved from
       [144]http://eprints.pascal-network.org/archive/00004705/\nhttp://pa
       pers.nips.cc/paper/3499-clustered-multi-task-learning-a-convex-form
       ulation.pdf [145]      
   22. kim, s., & xing, e. p. (2010). tree-guided group lasso for
       multi-task regression with structured sparsity. 27th international
       conference on machine learning, 1   14.
       [146]https://doi.org/10.1214/12-aoas549 [147]      
   23. chen, x., kim, s., lin, q., carbonell, j. g., & xing, e. p. (2010).
       graph-structured multi-task regression and an efficient
       optimization method for general fused lasso, 1   21.
       [148]https://doi.org/10.1146/annurev.arplant.56.032604.144204
       [149]      
   24. thrun, s., & o   sullivan, j. (1996). discovering structure in
       multiple learning tasks: the tc algorithm. proceedings of the
       thirteenth international conference on machine learning, 28(1),
       5   5. retrieved from
       [150]http://scholar.google.com/scholar?cluster=956054018507723832&h
       l=en [151]      
   25. ando, r. k., & tong, z. (2005). a framework for learning predictive
       structures from multiple tasks and unlabeled data. journal of
       machine learning research, 6, 1817   1853. [152]      
   26. heskes, t. (2000). empirical bayes for learning to learn.
       proceedings of the seventeenth international conference on machine
       learning, 367   364. [153]      
   27. lawrence, n. d., & platt, j. c. (2004). learning to learn with the
       informative vector machine. twenty-first international conference
       on machine learning - icml    04, 65.
       [154]https://doi.org/10.1145/1015330.1015382 [155]      
   28. yu, k., tresp, v., & schwaighofer, a. (2005). learning gaussian
       processes from multiple tasks. proceedings of the international
       conference on machine learning (icml), 22, 1012   1019.
       [156]https://doi.org/10.1145/1102351.1102479 [157]      
   29. bakker, b., & heskes, t. (2003). task id91 and gating for
       bayesian multitask learning. journal of machine learning research,
       1(1), 83   99. [158]https://doi.org/10.1162/153244304322765658
       [159]      
   30. xue, y., liao, x., carin, l., & krishnapuram, b. (2007). multi-task
       learning for classification with dirichlet process priors. journal
       of machine learning research, 8, 35   63. [160]      
   31. daum   iii, h. (2009). bayesian multitask learning with latent
       hierarchies, 135   142. retrieved from
       [161]http://dl.acm.org.sci-hub.io/citation.cfm?id=1795131 [162]      
   32. zhang, y., & yeung, d. (2010). a convex formulation for learning
       task relationships in id72. uai, 733   442. [163]      
   33. cavallanti, g., cesa-bianchi, n., & gentile, c. (2010). linear
       algorithms for online multitask classification. journal of machine
       learning research, 11, 2901   2934. [164]      
   34. saha, a., rai, p., daum  , h., & venkatasubramanian, s. (2011).
       online learning of multiple tasks and their relationships. journal
       of machine learning research, 15, 643   651. retrieved from
       [165]http://www.scopus.com/inward/record.url?eid=2-s2.0-84862275213
       &partnerid=tzotx3y1 [166]      
   35. kang, z., grauman, k., & sha, f. (2011). learning with whom to
       share in multi-task id171. proceedings of the 28th
       international conference on machine learning, (4), 4   5. retrieved
       from
       [167]http://machinelearning.wustl.edu/mlpapers/paper_files/icml2011
       kang_344.pdf [168]      
   36. kumar, a., & daum   iii, h. (2012). learning task grouping and
       overlap in id72. proceedings of the 29th
       international conference on machine learning, 1383   1390. [169]      
   37. crammer, k., & mansour, y. (2012). learning multiple tasks using
       shared hypotheses. neural information processing systems (nips),
       1484   1492 [170]      
   38. long, m., & wang, j. (2015). learning multiple tasks with deep
       relationship networks. arxiv preprint arxiv:1506.02117. retrieved
       from [171]http://arxiv.org/abs/1506.02117 [172]      
   39. lu, y., kumar, a., zhai, s., cheng, y., javidi, t., & feris, r.
       (2016). fully-adaptive feature sharing in multi-task networks with
       applications in person attribute classification. retrieved from
       [173]http://arxiv.org/abs/1611.05377 [174]      
   40. misra, i., shrivastava, a., gupta, a., & hebert, m. (2016).
       cross-stitch networks for id72. in proceedings of
       the ieee conference on id161 and pattern recognition.
       [175]https://doi.org/10.1109/cvpr.2016.433 [176]      
   41. s  gaard, a., & goldberg, y. (2016). deep id72 with
       low level tasks supervised at lower layers. proceedings of the 54th
       annual meeting of the association for computational linguistics,
       231   235. [177]      
   42. hashimoto, k., xiong, c., tsuruoka, y., & socher, r. (2016). a
       joint many-task model: growing a neural network for multiple nlp
       tasks. arxiv preprint arxiv:1611.01587. retrieved from
       [178]http://arxiv.org/abs/1611.01587 [179]      
   43. kendall, a., gal, y., & cipolla, r. (2017). id72
       using uncertainty to weigh losses for scene geometry and semantics.
       retrieved from [180]http://arxiv.org/abs/1705.07115 [181]      
   44. yang, y., & hospedales, t. (2017). deep multi-task representation
       learning: a tensor factorisation approach. in iclr 2017.
       [182]https://doi.org/10.1002/joe.20070 [183]      
   45. ruder, s., bingel, j., augenstein, i., & s  gaard, a. (2017). sluice
       networks: learning what to share between loosely related tasks.
       retrieved from [184]http://arxiv.org/abs/1705.08142 [185]      
   46. zhang, z., luo, p., loy, c. c., & tang, x. (2014). facial landmark
       detection by deep id72. in european conference on
       id161 (pp. 94   108).
       [186]https://doi.org/10.1007/978-3-319-10599-4_7 [187]      
   47. liu, x., gao, j., he, x., deng, l., duh, k., & wang, y.-y. (2015).
       representation learning using multi-task deep neural networks for
       semantic classification and information retrieval. naacl-2015,
       912   921. [188]      
   48. ar  k, s.   ., chrzanowski, m., coates, a., diamos, g., gibiansky,
       a., kang, y.,     shoeybi, m. (2017). deep voice: real-time neural
       text-to-speech. in icml 2017. [189]      
   49. ganin, y., & lempitsky, v. (2015). unsupervised id20
       by id26. in proceedings of the 32nd international
       conference on machine learning. (vol. 37). [190]      
   50. yu, j., & jiang, j. (2016). learning sentence embeddings with
       auxiliary tasks for cross-domain sentiment classification.
       proceedings of the 2016 conference on empirical methods in natural
       language processing (emnlp2016), 236   246. retrieved from
       [191]http://www.aclweb.org/anthology/d/d16/d16-1023.pdf [192]      
   51. cheng, h., fang, h., & ostendorf, m. (2015). open-domain name error
       detection using a multi-task id56. in proceedings of the 2015
       conference on empirical methods in natural language processing (pp.
       737   746). [193]      
   52. caruana, r., & sa, v. r. de. (1997). promoting poor features to
       supervisors: some inputs work better as outputs. advances in neural
       information processing systems 9: proceedings of the 1996
       conference, 9, 389. retrieved from
       [194]http://scholar.google.com/scholar?start=20&q=author:"rich+caru
       ana"&hl=en#6 [195]      
   53. rei, m. (2017). semi-supervised multitask learning for sequence
       labeling. in acl 2017. [196]      
   54. ben-david, s., & schuller, r. (2003). exploiting task relatedness
       for multiple task learning. learning theory and kernel machines,
       567   580. [197]https://doi.org/10.1007/978-3-540-45167-9_41 [198]      
   55. alonso, h. m., & plank, b. (2017). when is multitask learning
       effective? multitask learning for semantic sequence prediction
       under varying data conditions. in eacl. retrieved from
       [199]http://arxiv.org/abs/1612.02251 [200]      
   56. bingel, j., & s  gaard, a. (2017). identifying beneficial task
       relations for id72 in deep neural networks. in eacl.
       retrieved from [201]http://arxiv.org/abs/1702.08303 [202]      

   sebastian ruder

[203]sebastian ruder

   read [204]more posts by this author.
   [205]read more

       sebastian ruder    

[206]id72

     * [207]neural id21 for natural language processing (phd
       thesis)
     * [208]10 exciting ideas of 2018 in nlp
     * [209]a review of the neural history of natural language processing

   [210]see all 5 posts    

   [211]deep learning for nlp best practices

   natural language processing

deep learning for nlp best practices

   neural networks are widely used in nlp, but many details such as task
   or domain-specific considerations are left to the practitioner. this
   post collects best practices that are relevant for most tasks in nlp.

     * sebastian ruder
       [212]sebastian ruder

   [213]id21 - machine learning's next frontier

   id21

id21 - machine learning's next frontier

   deep learning models excel at learning from a large number of labeled
   examples, but typically do not generalize to conditions not seen during
   training. this post gives an overview of id21, motivates
   why it warrants our application, and discusses practical applications
   and methods.

     * sebastian ruder
       [214]sebastian ruder

   [215]sebastian ruder
      
   an overview of id72 in deep neural networks
   share this
   please enable javascript to view the [216]comments powered by disqus.

   [217]sebastian ruder    2019

   [218]latest posts [219]twitter [220]ghost

references

   visible links
   1. http://ruder.io/rss/
   2. http://ruder.io/
   3. http://ruder.io/about/
   4. http://ruder.io/tags/
   5. http://ruder.io/publications/
   6. http://ruder.io/talks/
   7. http://ruder.io/news/
   8. http://ruder.io/faq/
   9. http://ruder.io/nlp-news/
  10. https://nlpprogress.com/
  11. http://ruder.io/contact/
  12. http://ruder.io/tag/multi-task-learning/index.html
  13. https://arxiv.org/abs/1706.05098
  14. http://ruder.io/multi-task/index.html#introduction
  15. http://ruder.io/multi-task/index.html#motivation
  16. http://ruder.io/multi-task/index.html#twomtlmethodsfordeeplearning
  17. http://ruder.io/multi-task/index.html#hardparametersharing
  18. http://ruder.io/multi-task/index.html#softparametersharing
  19. http://ruder.io/multi-task/index.html#whydoesmtlwork
  20. http://ruder.io/multi-task/index.html#implicitdataaugmentation
  21. http://ruder.io/multi-task/index.html#attentionfocusing
  22. http://ruder.io/multi-task/index.html#eavesdropping
  23. http://ruder.io/multi-task/index.html#representationbias
  24. http://ruder.io/multi-task/index.html#id173
  25. http://ruder.io/multi-task/index.html#mtlinnonneuralmodels
  26. http://ruder.io/multi-task/index.html#blocksparseid173
  27. http://ruder.io/multi-task/index.html#learningtaskrelationships
  28. http://ruder.io/multi-task/index.html#recentworkoid4lfordeeplearning
  29. http://ruder.io/multi-task/index.html#deeprelationshipnetworks
  30. http://ruder.io/multi-task/index.html#fullyadaptivefeaturesharing
  31. http://ruder.io/multi-task/index.html#crossstitchnetworks
  32. http://ruder.io/multi-task/index.html#lowsupervision
  33. http://ruder.io/multi-task/index.html#ajointmanytaskmodel
  34. http://ruder.io/multi-task/index.html#weightinglosseswithuncertainty
  35. http://ruder.io/multi-task/index.html#tensorfactorisationformtl
  36. http://ruder.io/multi-task/index.html#sluicenetworks
  37. http://ruder.io/multi-task/index.html#whatshouldishareinmymodel
  38. http://ruder.io/multi-task/index.html#auxiliarytasks
  39. http://ruder.io/multi-task/index.html#relatedtask
  40. http://ruder.io/multi-task/index.html#adversarial
  41. http://ruder.io/multi-task/index.html#hints
  42. http://ruder.io/multi-task/index.html#focusingattention
  43. http://ruder.io/multi-task/index.html#quantizationsmoothing
  44. http://ruder.io/multi-task/index.html#predictinginputs
  45. http://ruder.io/multi-task/index.html#usingthefuturetopredictthepresent
  46. http://ruder.io/multi-task/index.html#representationlearning
  47. http://ruder.io/multi-task/index.html#whatauxiliarytasksarehelpful
  48. http://ruder.io/multi-task/index.html#conclusion
  49. http://ruder.io/multi-task/index.html#fn1
  50. http://ruder.io/multi-task/index.html#fn2
  51. http://ruder.io/multi-task/index.html#fn3
  52. http://ruder.io/multi-task/index.html#fn4
  53. http://ruder.io/multi-task/index.html#fn5
  54. https://www.youtube.com/watch?v=nfpprhxpfr4
  55. http://m-mitchell.com/publications/multitask-blurb.html
  56. https://twitter.com/mmitchell_ai/status/849596878694096896
  57. https://www.youtube.com/embed/dslk6hvbe6y
  58. http://ruder.io/multi-task/index.html#fn6
  59. http://ruder.io/multi-task/index.html#fn7
  60. http://ruder.io/multi-task/index.html#fn8
  61. http://ruder.io/multi-task/index.html#fn9
  62. http://ruder.io/multi-task/index.html#fn10
  63. http://ruder.io/multi-task/index.html#fn11
  64. http://ruder.io/multi-task/index.html#fn12
  65. http://ruder.io/multi-task/index.html#fn13
  66. http://ruder.io/multi-task/index.html#fn14
  67. http://ruder.io/multi-task/index.html#fn15
  68. http://ruder.io/multi-task/index.html#fn16
  69. http://ruder.io/multi-task/index.html#fn17
  70. http://ruder.io/multi-task/index.html#fn18
  71. http://ruder.io/multi-task/index.html#fn19
  72. http://ruder.io/multi-task/index.html#fn20
  73. http://ruder.io/multi-task/index.html#fn21
  74. http://ruder.io/multi-task/index.html#fn22
  75. http://ruder.io/multi-task/index.html#fn23
  76. http://ruder.io/multi-task/index.html#fn24
  77. http://ruder.io/multi-task/index.html#fn25
  78. http://ruder.io/multi-task/index.html#fn26
  79. http://ruder.io/multi-task/index.html#fn27
  80. http://ruder.io/multi-task/index.html#fn28
  81. http://ruder.io/multi-task/index.html#fn29
  82. http://ruder.io/multi-task/index.html#fn30
  83. http://ruder.io/multi-task/index.html#fn31
  84. http://ruder.io/multi-task/index.html#fn32
  85. http://ruder.io/multi-task/index.html#fn33
  86. http://ruder.io/multi-task/index.html#fn34
  87. http://ruder.io/multi-task/index.html#fn35
  88. http://ruder.io/multi-task/index.html#fn36
  89. http://ruder.io/multi-task/index.html#fn37
  90. http://ruder.io/multi-task/index.html#fn38
  91. http://ruder.io/multi-task/index.html#fn39
  92. http://ruder.io/multi-task/index.html#fn40
  93. http://ruder.io/multi-task/index.html#fn41
  94. http://ruder.io/multi-task/index.html#fn42
  95. http://ruder.io/multi-task/index.html#fn43
  96. http://ruder.io/multi-task/index.html#fn44
  97. http://ruder.io/multi-task/index.html#fn45
  98. http://ruder.io/multi-task/index.html#fn46
  99. http://ruder.io/multi-task/index.html#fn47
 100. http://ruder.io/multi-task/index.html#fn48
 101. http://ruder.io/multi-task/index.html#fn49
 102. http://ruder.io/multi-task/index.html#fn50
 103. http://ruder.io/multi-task/index.html#fn51
 104. http://ruder.io/multi-task/index.html#fn52
 105. http://ruder.io/multi-task/index.html#fn53
 106. http://ruder.io/multi-task/index.html#fn54
 107. http://ruder.io/multi-task/index.html#fn55
 108. http://ruder.io/multi-task/index.html#fn56
 109. https://arxiv.org/abs/1706.05098
 110. https://doi.org/10.1145/1390156.1390177
 111. http://ruder.io/multi-task/index.html#fnref1
 112. https://doi.org/10.1109/icassp.2013.6639344
 113. http://ruder.io/multi-task/index.html#fnref2
 114. https://doi.org/10.1109/iccv.2015.169
 115. http://ruder.io/multi-task/index.html#fnref3
 116. https://doi.org/https://arxiv.org/abs/1502.02072
 117. http://ruder.io/multi-task/index.html#fnref4
 118. https://doi.org/10.1016/j.csl.2009.08.003
 119. http://ruder.io/multi-task/index.html#fnref5
 120. http://ruder.io/multi-task/index.html#fnref6
 121. http://link.springer.com/article/10.1023/a:1007327622663
 122. http://ruder.io/multi-task/index.html#fnref7
 123. http://ruder.io/multi-task/index.html#fnref8
 124. http://arxiv.org/abs/1606.04038
 125. http://ruder.io/multi-task/index.html#fnref9
 126. https://doi.org/10.1016/0885-064x(90)90006-y
 127. http://ruder.io/multi-task/index.html#fnref10
 128. http://ruder.io/multi-task/index.html#fnref11
 129. http://doi.org/10.1007/s10994-007-5040-8
 130. http://ruder.io/multi-task/index.html#fnref12
 131. http://ruder.io/multi-task/index.html#fnref13
 132. http://ruder.io/multi-task/index.html#fnref14
 133. http://arxiv.org/pdf/0903.1468
 134. http://ruder.io/multi-task/index.html#fnref15
 135. http://ruder.io/multi-task/index.html#fnref16
 136. https://papers.nips.cc/paper/4125-a-dirty-model-for-multi-task-learning.pdf
 137. http://ruder.io/multi-task/index.html#fnref17
 138. http://arxiv.org/abs/1612.04022
 139. http://ruder.io/multi-task/index.html#fnref18
 140. http://discovery.ucl.ac.uk/13423/
 141. http://ruder.io/multi-task/index.html#fnref19
 142. https://doi.org/10.1145/1014052.1014067
 143. http://ruder.io/multi-task/index.html#fnref20
 144. http://eprints.pascal-network.org/archive/00004705/\nhttp://papers.nips.cc/paper/3499-clustered-multi-task-learning-a-convex-formulation.pdf
 145. http://ruder.io/multi-task/index.html#fnref21
 146. https://doi.org/10.1214/12-aoas549
 147. http://ruder.io/multi-task/index.html#fnref22
 148. https://doi.org/10.1146/annurev.arplant.56.032604.144204
 149. http://ruder.io/multi-task/index.html#fnref23
 150. http://scholar.google.com/scholar?cluster=956054018507723832&hl=en
 151. http://ruder.io/multi-task/index.html#fnref24
 152. http://ruder.io/multi-task/index.html#fnref25
 153. http://ruder.io/multi-task/index.html#fnref26
 154. https://doi.org/10.1145/1015330.1015382
 155. http://ruder.io/multi-task/index.html#fnref27
 156. https://doi.org/10.1145/1102351.1102479
 157. http://ruder.io/multi-task/index.html#fnref28
 158. https://doi.org/10.1162/153244304322765658
 159. http://ruder.io/multi-task/index.html#fnref29
 160. http://ruder.io/multi-task/index.html#fnref30
 161. http://dl.acm.org.sci-hub.io/citation.cfm?id=1795131
 162. http://ruder.io/multi-task/index.html#fnref31
 163. http://ruder.io/multi-task/index.html#fnref32
 164. http://ruder.io/multi-task/index.html#fnref33
 165. http://www.scopus.com/inward/record.url?eid=2-s2.0-84862275213&partnerid=tzotx3y1
 166. http://ruder.io/multi-task/index.html#fnref34
 167. http://machinelearning.wustl.edu/mlpapers/paper_files/icml2011kang_344.pdf
 168. http://ruder.io/multi-task/index.html#fnref35
 169. http://ruder.io/multi-task/index.html#fnref36
 170. http://ruder.io/multi-task/index.html#fnref37
 171. http://arxiv.org/abs/1506.02117
 172. http://ruder.io/multi-task/index.html#fnref38
 173. http://arxiv.org/abs/1611.05377
 174. http://ruder.io/multi-task/index.html#fnref39
 175. https://doi.org/10.1109/cvpr.2016.433
 176. http://ruder.io/multi-task/index.html#fnref40
 177. http://ruder.io/multi-task/index.html#fnref41
 178. http://arxiv.org/abs/1611.01587
 179. http://ruder.io/multi-task/index.html#fnref42
 180. http://arxiv.org/abs/1705.07115
 181. http://ruder.io/multi-task/index.html#fnref43
 182. https://doi.org/10.1002/joe.20070
 183. http://ruder.io/multi-task/index.html#fnref44
 184. http://arxiv.org/abs/1705.08142
 185. http://ruder.io/multi-task/index.html#fnref45
 186. https://doi.org/10.1007/978-3-319-10599-4_7
 187. http://ruder.io/multi-task/index.html#fnref46
 188. http://ruder.io/multi-task/index.html#fnref47
 189. http://ruder.io/multi-task/index.html#fnref48
 190. http://ruder.io/multi-task/index.html#fnref49
 191. http://www.aclweb.org/anthology/d/d16/d16-1023.pdf
 192. http://ruder.io/multi-task/index.html#fnref50
 193. http://ruder.io/multi-task/index.html#fnref51
 194. http://scholar.google.com/scholar?start=20&q=author:"rich+caruana"&hl=en#6
 195. http://ruder.io/multi-task/index.html#fnref52
 196. http://ruder.io/multi-task/index.html#fnref53
 197. https://doi.org/10.1007/978-3-540-45167-9_41
 198. http://ruder.io/multi-task/index.html#fnref54
 199. http://arxiv.org/abs/1612.02251
 200. http://ruder.io/multi-task/index.html#fnref55
 201. http://arxiv.org/abs/1702.08303
 202. http://ruder.io/multi-task/index.html#fnref56
 203. http://ruder.io/author/sebastian/index.html
 204. http://ruder.io/author/sebastian/index.html
 205. http://ruder.io/author/sebastian/index.html
 206. http://ruder.io/tag/multi-task-learning/index.html
 207. http://ruder.io/thesis/index.html
 208. http://ruder.io/10-exciting-ideas-of-2018-in-nlp/index.html
 209. http://ruder.io/a-review-of-the-recent-history-of-nlp/index.html
 210. http://ruder.io/tag/multi-task-learning/index.html
 211. http://ruder.io/index.html
 212. http://ruder.io/author/sebastian/index.html
 213. http://ruder.io/index.html
 214. http://ruder.io/author/sebastian/index.html
 215. http://ruder.io/
 216. https://disqus.com/?ref_noscript
 217. http://ruder.io/
 218. http://ruder.io/
 219. https://twitter.com/seb_ruder
 220. https://ghost.org/

   hidden links:
 222. https://twitter.com/seb_ruder
 223. http://ruder.io/rss/index.rss
 224. http://ruder.io/index.html
 225. http://ruder.io/index.html
 226. https://twitter.com/share?text=an%20overview%20of%20multi-task%20learning%20in%20deep%20neural%20networks&url=http://ruder.io/multi-task/
 227. https://www.facebook.com/sharer/sharer.php?u=http://ruder.io/multi-task/
