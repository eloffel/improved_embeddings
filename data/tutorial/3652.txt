   #[1]publisher [2]medium [3]alternate

   [4]homepage
   [5]homepage
   [6]deep learning 101
   [7]deep learning 101
   [8]sign in[9]get started
     __________________________________________________________________

video of a neural network learning

   [10]go to the profile of milo spencer-harper
   [11]milo spencer-harper (button) blockedunblock (button)
   followfollowing
   aug 11, 2015

   as part of my quest to learn about ai, i generated a video of a neural
   network learning.

   many of the examples on the internet use matrices (grids of numbers) to
   represent a neural network. this method is favoured, because it is:
     * mathematically equivalent to a neural network
     * computationally faster

   however, it   s difficult to understand what is happening. from a
   learning perspective, being able to visually see a neural network is
   hugely beneficial.

   the video you are about to see, shows a neural network trying to solve
   this pattern. can you work it out?
   [1*wlcd6kgxqb2yqpcutlhywq.png]
   training set

   it   s the same problem i posed in [12]my previous blog post. the trick
   is to notice that the third column is irrelevant, but the first two
   columns exhibit the behaviour of a xor gate. if either the first column
   or the second column is 1, then the output is 1. however, if both
   columns are 0 or both columns are 1, then the output is 0.

   so the correct answer is 0.

   our neural network will cycle through these 7 examples, 60,000 times.
   to speed up the video, i will only show you 13 of these cycles, pausing
   for a second on each frame. why the number 13? it ensures the video
   lasts exactly as long as the music.

   each time she considers an example in the training set, you will see
   her think (you will see her neurons and her synaptic connections glow).
   she will then calculate the error (the difference between the output
   and the desired output). she will then propagate this error backwards,
   adjusting her synaptic connections.

   green synaptic connections represent positive weights (a signal flowing
   through this synapse will excite the next neuron to fire). red synaptic
   connections represent negative weights (a signal flowing through this
   synapse will inhibit the next neuron from firing). thicker synapses
   represent stronger connections (larger weights).

   in the beginning, her synaptic weights are randomly assigned. notice
   how some synapses are green (positive) and others are red (negative).
   if these synapses turn out to be beneficial in calculating the right
   answer, she will strengthen them over time. however, if they are
   unhelpful, these synapses will wither. it   s even possible for a synapse
   which was originally positive to become negative, and vice versa. an
   example of this, is the first synapse into the output neuron         early on
   in the video it turns from red to green. in the beginning her brain
   looks like this:
   [1*imskq8g3_e5q-d1dncwuva.png]
   our neural network before she starts training.

   did you notice that all her neurons are dark? this is because she isn   t
   currently thinking about anything. the numbers to the right of each
   neuron, represent the level of neural activity and vary between 0 and
   1.

   ok. now she is going to think about the pattern we saw earlier. watch
   the video carefully to see her synapses grow thicker as she learns.

   iframe: [13]/media/b18e6c168f873a2eb95f1e65fcae92c8?postid=62f5c520e85c

   video of our neural network learning.

   did you notice how i slowed the video down at the beginning, by
   skipping only a small number of cycles? when i first shot the video, i
   didn   t do this. however, i realised that learning is subject to the
   [14]   law of diminishing returns   . the neural network changes more
   rapidly during the initial stage of training, which is why i slowed
   this bit down.

   now that she has learned about the pattern using the 7 examples in the
   training set, let   s examine her brain again. do you see how she has
   strengthened some of her synapses, at the expense of others? for
   instance, do you remember how the third column in the training set is
   irrelevant in determining the answer? you can see she has discovered
   this, because the synapses coming out of her third input neuron have
   almost withered away, relative to the others.
   [1*f8ilgq5hnlcmqq-vf6vhiw.png]
   our neural network after she has finished training.

   let   s give her a new situation [1, 1, 0] to think about. you can see
   her neural pathways light up.
   [1*py7s3gryukw-enq3_supvw.png]
   our neural network considering a new situation.

   she has estimated 0.01. the correct answer is 0. so she was very close!

   pretty cool. traditional computer programs can   t learn. but neural
   networks can learn and adapt to new situations. just like the human
   mind!

   how did i do it? i used the python library [15]matplotlib, which
   provides methods for drawing and animation. i created the glow effects
   using alpha transparency.

   you can view my full source code here:
   [16]miloharper/neural-network-animation
   neural-network-animation - watch a neural network think. written in
   python.github.com

   thanks for reading!

   if you enjoyed reading this article, please click the heart icon to
      recommend   .

     * [17]artificial intelligence
     * [18]neural networks
     * [19]deep learning

   (button)
   (button)
   (button) 1.93k claps
   (button) (button) (button) 15 (button) (button)

     (button) blockedunblock (button) followfollowing
   [20]go to the profile of milo spencer-harper

[21]milo spencer-harper

   studied economics at oxford university. founder of [22]www.moju.io.
   interested in politics and ai.

     (button) follow
   [23]deep learning 101

[24]deep learning 101

   fundamentals and latest developments in #deeplearning

     * (button)
       (button) 1.93k
     * (button)
     *
     *

   [25]deep learning 101
   never miss a story from deep learning 101, when you sign up for medium.
   [26]learn more
   never miss a story from deep learning 101
   (button) get updatesget updates

references

   visible links
   1. https://plus.google.com/103654360130207659246
   2. https://medium.com/osd.xml
   3. android-app://com.medium.reader/https/medium.com/p/62f5c520e85c
   4. https://medium.com/
   5. https://medium.com/
   6. https://medium.com/deep-learning-101?source=avatar-lo_pgd2ngazggao-4b937bfee025
   7. https://medium.com/deep-learning-101?source=logo-lo_pgd2ngazggao---4b937bfee025
   8. https://medium.com/m/signin?redirect=https://medium.com/deep-learning-101/how-to-generate-a-video-of-a-neural-network-learning-in-python-62f5c520e85c&source=--------------------------nav_reg&operation=login
   9. https://medium.com/m/signin?redirect=https://medium.com/deep-learning-101/how-to-generate-a-video-of-a-neural-network-learning-in-python-62f5c520e85c&source=--------------------------nav_reg&operation=register
  10. https://medium.com/@miloharper?source=post_header_lockup
  11. https://medium.com/@miloharper
  12. https://medium.com/technology-invention-and-more/how-to-build-a-multi-layered-neural-network-in-python-53ec3d1d326a
  13. https://medium.com/media/b18e6c168f873a2eb95f1e65fcae92c8?postid=62f5c520e85c
  14. https://en.wikipedia.org/wiki/diminishing_returns
  15. http://matplotlib.org/
  16. https://github.com/miloharper/neural-network-animation
  17. https://medium.com/tag/artificial-intelligence?source=post
  18. https://medium.com/tag/neural-networks?source=post
  19. https://medium.com/tag/deep-learning?source=post
  20. https://medium.com/@miloharper?source=footer_card
  21. https://medium.com/@miloharper
  22. http://www.moju.io/
  23. https://medium.com/deep-learning-101?source=footer_card
  24. https://medium.com/deep-learning-101?source=footer_card
  25. https://medium.com/deep-learning-101
  26. https://medium.com/@medium/personalize-your-medium-experience-with-users-publications-tags-26a41ab1ee0c#.hx4zuv3mg

   hidden links:
  28. https://github.com/miloharper/neural-network-animation
  29. https://medium.com/p/62f5c520e85c/share/twitter
  30. https://medium.com/p/62f5c520e85c/share/facebook
  31. https://medium.com/p/62f5c520e85c/share/twitter
  32. https://medium.com/p/62f5c520e85c/share/facebook
