   #[1]rss feed for the berkeley artificial intelligence research blog

   [2][bair_logo.png]

   [3]subscribe [4]about [5]archive [6]bair

learning to reason with neural module networks

   jacob andreas    jun 20, 2017

   (joint work with ronghang hu, marcus rohrbach, trevor darrell, dan
   klein and kate saenko.)

   suppose we   re building a household robot, and want it to be able to
   answer questions about its surroundings. we might ask questions like
   these:

   [examples.jpg]

   how can we ensure that the robot can answer these questions correctly?
   the standard approach in deep learning is to collect a large dataset of
   questions, images, and answers, and train a single neural network to
   map directly from questions and images to answers. if most questions
   look like the one on the left, we have a familiar image recognition
   problem, and these kinds of monolithic approaches are quite effective:

   [cat_pred.jpg]

   but things don   t work quite so well for questions like the one on the
   right:

   [clevr_pred.jpg]

   here the network we trained has given up and guessed the most common
   color in the image. what makes this question so much harder? even
   though the image is cleaner, the question requires many steps of
   reasoning: rather than simply recognizing the main object in the image,
   the model must first find the blue cylinder, locate the other object
   with the same size, and then determine its color. this is a complicated
   computation, and it   s a computation specific to the question that was
   asked. different questions require different sequences of steps to
   solve.

   the dominant paradigm in deep learning is a "one size fits all"
   approach: for whatever problem we   re trying to solve, we write down a
   fixed model architecture that we hope can capture everything about the
   relationship between the input and output, and learn parameters for
   that fixed model from labeled training data.

   but real-world reasoning doesn   t work this way: it involves a variety
   of different capabilities, combined and synthesized in new ways for
   every new challenge we encounter in the wild. what we need is a model
   that can dynamically determine how to reason about the problem in front
   of it   a network that can choose its own structure on the fly. in this
   post, we   ll talk about a new class of models we call neural module
   networks (nmns), which incorporate this more flexible approach to
   problem-solving while preserving the expressive power that makes deep
   learning so effective.
     __________________________________________________________________

   earlier, we noticed that there are three different steps involved in
   answering the question above: finding a blue cylinder, finding
   something else the same size, and determining its color. we can draw
   this schematically like:

   [layout1.jpg]

   a different question might involve a different series of steps. if we
   ask "how many things are the same size as the ball?", we might have
   something like:

   [layout2.jpg]

   basic operations like "compare size" are shared between questions, but
   they get used in different ways. the key idea behind nmns is to make
   this sharing explicit: we use two different network structures to
   answer the two questions above, but we share weights between pieces of
   networks that involve the same basic operations:

   [tying.jpg]

   how do we learn a model like this? rather than training a single large
   network on lots of input/output pairs, we actually train a huge number
   of different networks at the same time, while tying their parameters
   together where appropriate:

   [training.jpg]

   (several recent deep learning frameworks, including dynet and
   tensorflow fold, were explicitly designed with this kind of dynamic
   computation in mind.)

   what we get at the end of the training process is not a single deep
   network, but rather a collection of neural "modules", each of which
   implements a single step of reasoning. when we want to use our trained
   model on a new problem instance, we can assemble these modules
   dynamically to produce a new network structure tailored to that
   problem.

   one of the remarkable things about this process is that we don   t need
   to provide any low-level supervision for individual modules: the model
   never sees an isolated example of blue object or a "left-of"
   relationship. modules are learned only inside larger composed
   structures, with only (question, answer) pairs as supervision. but the
   training procedure is able to automatically infer the correct
   relationship between pieces of structure and the computations they   re
   responsible for:

   [exploded.jpg]

   this same process works for answering questions about more realistic
   photographs, and even other knowledge sources like databases:

   [vqa.jpg] [geo.jpg]
     __________________________________________________________________

   the key ingredient in this whole process is a collection of high-level
   "reasoning blueprints" like the ones above. these blueprints tell us
   how the network for each question should be laid out, and how different
   questions relate to one another. but where do the blueprints come from?

   in our initial work on these models (1, 2), we drew on a surprising
   connection between the problem of designing question-specific neural
   networks and the problem of analyzing grammatical structure. linguists
   have long observed that the grammar of a question is closely related to
   the sequence of computational steps needed to answer it. thanks to
   recent advances in natural language processing, we can use
   off-the-shelf tools for grammatical analysis to provide approximate
   versions of these blueprints automatically.

   but finding exactly the right mapping from linguistic structure to
   network structure is still a challenging problem, and the conversion
   process is prone to errors. in later work, rather than relying on this
   kind of linguistic analysis, we instead turned to data produced by
   human experts who directly labeled a collection of questions with
   idealized reasoning blueprints (3). by learning to imitate these
   humans, our model was able to improve the quality of its predictions
   substantially. most surprisingly, when we took a model trained to
   imitate experts, but allowed it to explore its own modifications to
   these expert predictions, it was able to find even better solutions
   than experts on a variety of questions.
     __________________________________________________________________

   despite the remarkable success of deep learning methods in recent
   years, many problems   including few-shot learning and complex
   reasoning   remain a challenge. but these are exactly the sorts of
   problems where more structured classical techniques like semantic
   parsing and program induction really shine. neural module networks give
   us the best of both worlds: the flexibility and data efficiency of
   discrete compositionality, combined with the representational power of
   deep networks. nmns have already seen a number of successes for visual
   and textual reasoning tasks, and we   re excited to start applying them
   to other ai problems as well.
     __________________________________________________________________

   this post is based on the following papers:
    1. neural module networks. jacob andreas, marcus rohrbach, trevor
       darrell and dan klein. cvpr 2016. ([7]arxiv)
    2. learning to compose neural networks for id53. jacob
       andreas, marcus rohrbach, trevor darrell and dan klein. naacl 2016.
       ([8]arxiv)
    3. modeling relationships in referential expressions with
       compositional modular networks. ronghang hu, marcus rohrbach, jacob
       andreas, trevor darrell and kate saenko. cvpr 2017. ([9]arxiv)

   images are from the [10]vqa and [11]clevr datasets.
   subscribe to our [12]rss feed.
   spread the word:

comments

   please enable javascript to view the [13]comments powered by disqus.

references

   visible links
   1. https://bair.berkeley.edu/blog/feed.xml
   2. https://bair.berkeley.edu/blog/
   3. https://bair.berkeley.edu/blog/subscribe/
   4. https://bair.berkeley.edu/blog/about/
   5. https://bair.berkeley.edu/blog/archive/
   6. http://bair.berkeley.edu/
   7. https://arxiv.org/abs/1511.02799
   8. https://arxiv.org/abs/1601.01705
   9. https://arxiv.org/abs/1611.09978
  10. http://www.visualqa.org/
  11. http://cs.stanford.edu/people/jcjohns/clevr/
  12. https://bair.berkeley.edu/blog/feed.xml
  13. http://disqus.com/?ref_noscript

   hidden links:
  15. https://facebook.com/sharer.php?u=http://bair.berkeley.edu/blog/2017/06/20/learning-to-reason-with-neural-module-networks/
  16. https://twitter.com/intent/tweet?text=learning%20to%20reason%20with%20neural%20module%20networks&url=http://bair.berkeley.edu/blog/2017/06/20/learning-to-reason-with-neural-module-networks/
  17. https://plus.google.com/share?url=http://bair.berkeley.edu/blog/2017/06/20/learning-to-reason-with-neural-module-networks/
  18. http://www.linkedin.com/sharearticle?url=http://bair.berkeley.edu/blog/2017/06/20/learning-to-reason-with-neural-module-networks/&title=learning%20to%20reason%20with%20neural%20module%20networks
  19. http://reddit.com/submit?url=http://bair.berkeley.edu/blog/2017/06/20/learning-to-reason-with-neural-module-networks/&title=learning%20to%20reason%20with%20neural%20module%20networks
  20. https://news.ycombinator.com/submitlink?u=http://bair.berkeley.edu/blog/2017/06/20/learning-to-reason-with-neural-module-networks/&t=learning%20to%20reason%20with%20neural%20module%20networks
