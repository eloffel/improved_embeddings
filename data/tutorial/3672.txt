   #[1]analytics vidhya    feed [2]analytics vidhya    comments feed
   [3]analytics vidhya    architecture of convolutional neural networks
   (id98s) demystified comments feed [4]alternate [5]alternate

   iframe: [6]//googletagmanager.com/ns.html?id=gtm-mpsm42v

   [7]new certified ai & ml blackbelt program (beginner to master) -
   enroll today @ launch offer (coupon: blackbelt10)

   (button) search______________
     * [8]learn
          + [9]blog archive
               o [10]machine learning
               o [11]deep learning
               o [12]career
               o [13]stories
          + [14]datahack radio
          + [15]infographics
          + [16]training
          + [17]learning paths
               o [18]sas business analyst
               o [19]learn data science on r
               o [20]data science in python
               o [21]data science in weka
               o [22]data visualization with tableau
               o [23]data visualization with qlikview
               o [24]interactive data stories with d3.js
          + [25]glossary
     * [26]engage
          + [27]discuss
          + [28]events
          + [29]datahack summit 2018
          + [30]datahack summit 2017
          + [31]student datafest
          + [32]write for us
     * [33]compete
          + [34]hackathons
     * [35]get hired
          + [36]jobs
     * [37]courses
          + [38]id161 using deep learning
          + [39]natural language processing using python
          + [40]introduction to data science
          + [41]microsoft excel
          + [42]more courses
     * [43]contact

     *
     *
     *
     *

     * [44]home
     * [45]blog archive
     * [46]trainings
     * [47]discuss
     * [48]datahack
     * [49]jobs
     * [50]corporate

     *

   [51]analytics vidhya - learn everything about analytics

learn everything about analytics

   [52][black-belt-2.gif]
   [53][black-belt-2.gif]
   [54][black-belt-2.gif]
   (button) search______________

   [55]analytics vidhya - learn everything about analytics
     * [56]learn
          + [57]blog archive
               o [58]machine learning
               o [59]deep learning
               o [60]career
               o [61]stories
          + [62]datahack radio
          + [63]infographics
          + [64]training
          + [65]learning paths
               o [66]sas business analyst
               o [67]learn data science on r
               o [68]data science in python
               o [69]data science in weka
               o [70]data visualization with tableau
               o [71]data visualization with qlikview
               o [72]interactive data stories with d3.js
          + [73]glossary
     * [74]engage
          + [75]discuss
          + [76]events
          + [77]datahack summit 2018
          + [78]datahack summit 2017
          + [79]student datafest
          + [80]write for us
     * [81]compete
          + [82]hackathons
     * [83]get hired
          + [84]jobs
     * [85]courses
          + [86]id161 using deep learning
          + [87]natural language processing using python
          + [88]introduction to data science
          + [89]microsoft excel
          + [90]more courses
     * [91]contact

   [92]home [93]deep learning [94]architecture of convolutional neural
   networks (id98s) demystified

   [95]deep learning

architecture of convolutional neural networks (id98s) demystified

   [96]dishashree gupta, june 29, 2017

introduction

   i will start with a confession     there was a time when i didn   t really
   understand deep learning. i would look at the research papers and
   articles on the topic and feel like it is a very complex topic. i tried
   understanding neural networks and their various types, but it still
   looked difficult.

   then one day, i decided to take one step at a time. i decided to start
   with basics and build on them. i decided that i will break down the
   steps applied in these techniques and do the steps (and calculations)
   manually, until i understand how they work. it was time taking and
   intense effort     but the results were phenomenal.

   now, i can not only understand the spectrum of deep learning, i can
   visualize things and come up with better ways because my fundamentals
   are clear. it is one thing to apply neural networks mindlessly and it
   is other to understand what is going on and how are things happening at
   the back.

   today, i am going to share this secret recipe with you. i will show you
   how i took the convolutional neural networks and worked on them till i
   understood them. i will walk you through the journey so that you
   develop a deep understanding of how id98s work.

   in this article i am going to discuss the architecture behind
   convolutional neural networks, which are designed to address image
   recognition and classification problems.

   i am assuming that you have a basic understanding of how a neural
   network works. if you   re not sure of your understanding i would request
   you to go through [97]this article before you read on.


table of contents:

    1. how does a machine look at an image?
    2. how do we help a neural network to identify images?
    3. defining a convolutional neural network
         1. convolution layer
         2. pooling layer
         3. output layer
    4. putting it all together
    5. using id98 to classify images


1. how does a machine look at an image?

   human brain is a very powerful machine. we see (capture) multiple
   images every second and process them without realizing how the
   processing is done. but, that is not the case with machines. the first
   step in image processing is to understand, how to represent an image so
   that the machine can read it?

   in simple terms, every image is an arrangement of dots (a pixel)
   arranged in a special order. if you change the order or color of a
   pixel, the image would change as well. let us take an example. let us
   say, you wanted to store and read an image with a number 4 written on
   it.

   the machine will basically break this image into a matrix of pixels and
   store the color code for each pixel at the representative location. in
   the representation below     number 1 is white and 256 is the darkest
   shade of green color (i have constrained the example to have only one
   color for simplicity).

   once you have stored the images in this format, the next challenge is
   to have our neural network understand the arrangement and the pattern.


2. how do we help a neural network to identify images  ?

   a number is formed by having pixels arranged in a certain fashion.

   let   s say we try to use a fully connected network to identify it? what
   does it do ?

   a fully connected network would take this image as an array by
   flattening it and considering pixel values as features to predict the
   number in image. definitely it   s tough for the network to understand
   what   s happening underneath.

   it   s impossible even for a human to identify that this is a
   representation of number 4. we have lost the spatial arrangement of
   pixels completely.

   what can we possibly do? let   s try to to extract features from the
   original image such that the spatial arrangement is preserved.


 case 1:

   here we have used a weight to multiply the initial pixel values.

   it does get easier for the naked eye to identify that this is a 4. but
   again to send this image to a fully connected network, we would have to
   flatten it. we are unable to preserve the spatial arrangement of the
   image.


case 2:

   now we can see that flattening the image destroys its arrangement
   completely. we need to devise a way to send images to a network without
   flattening them and retaining its spatial arrangement. we need to send
   2d/3d arrangement of pixel values.

   let   s try taking two pixel values of the image at a time rather than
   taking just one. this would give the network a very good insight as to
   how does the adjacent pixel look like. now that we   re taking two pixels
   at a time, we shall take two weight values too.

   i hope you noted that the image now became a 3 column arrangement from
   a 4 column arrangement initially. the image got smaller since we   re now
   moving two pixels at a time (pixels are getting shared in each
   movement). we made the image smaller and we can still understand that
   it   s a 4 to quite a great extent. also, an important fact to realise is
   that we we   re taking two consecutive horizontal pixels, therefore only
   horizontal arrangement is considered here.

   this is one way to extract features from an image. we   re able to see
   the left and middle part well, however the right side is not so clear.
   this is because of the following two problems-
    1. the left and right corners of the image is multiplied by the
       weights just once.
    2. the left part is still retained since the weight value is high
       while the right part is getting slightly lost due to low weight
       value.

   now we have two problems, we shall have two solutions to solve them as
   well.


case 3:

   the problem encountered is that the left and right corners of the image
   is getting passed by the weight just once. what we need to do is we
   need the network to consider the corners also like other pixels.

   we have a simple solution to solve this. put zeros along the sides of
   the weight movement.

   you can see that by adding the zeroes the information from the corners
   is retained. the size of the image is higher too. this can be used in
   cases where we don   t want the image size to reduce.


case 4:

   the problem we   re trying to address here is that a smaller weight value
   in the right side corner is reducing the pixel value thereby making it
   tough for us to recognize. what we can do is, we take multiple weight
   values in a single turn and put them together.

   a weight value of (1,0.3) gave us an output of the form

   while a weight value of the form (0.1,5) would give us an output of the
   form

   a combined version of these two images would give us a very clear
   picture. therefore what we did was simply use multiple weights rather
   than just one to retain more information about the image. the final
   output would be a combined version of the above two images.


case 5:

   till now we have used the weights which were trying to take horizontal
   pixels together. but in most cases we need to preserve the spatial
   arrangement in both horizontal and vertical direction. we can take the
   weight as a 2d matrix which takes pixels together in both horizontal
   and vertical direction. also, keep in mind that since we have taken
   both horizontal and vertical movement of weights, the output is one
   pixel lower in both horizontal and vertical direction.

   special thanks to jeremy howard for the inspiring me to create these
   visuals.

so what did we do ?

   what we did above was that we were trying to extract features from an
   image by using the spatial arrangement of the images. to understand an
   image its extremely important for a network to understand how the
   pixels are arranged. what we did above is what exactly a convolutional
   neural network does. we can take the input image, define a weight
   matrix and the input is convolved to extract specific features from the
   image without losing the information about its spatial arrangement.

   another great benefit this approach has is that it reduces the number
   of parameters from the image. as you saw above the convolved images had
   lesser pixels as compared to the original image. this dramatically
   reduces the number of parameters we need to train for the network.

3. defining a convolutional neural network

   we need three basic components to define a basic convolutional network.
    1. the convolutional layer
    2. the pooling layer[optional]
    3. the output layer

   let   s see each of these in a little more detail


2.1 the convolution layer

   in this layer, what happens is exactly what we saw in case 5 above.
   suppose we have an image of size 6*6. we define a weight matrix which
   extracts certain features from the images

   we have initialized the weight as a 3*3 matrix. this weight shall now
   run across the image such that all the pixels are covered at least
   once, to give a convolved output. the value 429 above, is obtained by
   the adding the values obtained by element wise multiplication of the
   weight matrix and the highlighted 3*3 part of the input image.

   the 6*6 image is now converted into a 4*4 image.  think of weight
   matrix like a paint brush painting a wall. the brush first paints the
   wall horizontally and then comes down and paints the next row
   horizontally. pixel values are used again when the weight matrix moves
   along the image. this basically enables parameter sharing in a
   convolutional neural network.

   let   s see how this looks like in a real image.


   the weight matrix behaves like a filter in an image extracting
   particular information from the original image matrix. a weight
   combination might be extracting edges, while another one might a
   particular color, while another one might just blur the unwanted noise.

   the weights are learnt such that the id168 is minimized similar
   to an mlp. therefore weights are learnt to extract features from the
   original image which help the network in correct prediction. when we
   have multiple convolutional layers, the initial layer extract more
   generic features, while as the network gets deeper, the features
   extracted by the weight matrices are more and more complex and more
   suited to the problem at hand.


the concept of stride and padding

   as we saw above, the filter or the weight matrix, was moving across the
   entire image moving one pixel at a time. we can define it like a
   hyperparameter, as to how we would want the weight matrix to move
   across the image. if the weight matrix moves 1 pixel at a time, we call
   it as a stride of 1. let   s see how a stride of 2 would look like.

   as you can see the size of image keeps on reducing as we increase the
   stride value. padding the input image with zeros across it solves this
   problem for us. we can also add more than one layer of zeros around the
   image in case of higher stride values.

   we can see how the initial shape of the image is retained after we
   padded the image with a zero. this is known as same padding since the
   output image has the same size as the input.

   this is known as same padding (which means that we considered only the
   valid pixels of the input image). the middle 4*4 pixels would be the
   same. here we have retained more information from the borders and have
   also preserved the size of the image.


multiple filters and the activation map

   one thing to keep in mind is that the depth dimension of the weight
   would be same as the depth dimension of the input image. the weight
   extends to the entire depth of the input image. therefore, convolution
   with a single weight matrix would result into a convolved output with a
   single depth dimension. in most cases instead of a single filter(weight
   matrix), we have multiple filters of the same dimensions applied
   together.

   the output from the each filter is stacked together forming the depth
   dimension of the convolved image. suppose we have an input image of
   size 32*32*3. and we apply 10 filters of size 5*5*3 with valid padding.
   the output would have the dimensions as 28*28*10.

   you can visualize it as    

   this activation map is the output of the convolution layer.


2.2 the pooling layer

   sometimes when the images are too large, we would need to reduce the
   number of trainable parameters. it is then desired to periodically
   introduce pooling layers between subsequent convolution layers. pooling
   is done for the sole purpose of reducing the spatial size of the image.
   pooling is done independently on each depth dimension, therefore the
   depth of the image remains unchanged. the most common form of pooling
   layer generally applied is the max pooling.

   here we have taken stride as 2, while pooling size also as 2. the max
   operation is applied to each depth dimension of the convolved output.
   as you can see, the 4*4 convolved output has become 2*2 after the max
   pooling operation.

   let   s see how max pooling looks on a real image.

   as you can see i have taken convoluted image and have applied max
   pooling on it. the max pooled image still retains the information that
   it   s a car on a street. if you look carefully, the dimensions if the
   image have been halved. this helps to reduce the parameters to a great
   extent.

   similarly other forms of pooling can also be applied like average
   pooling or the l2 norm pooling.


output dimensions

   it might be getting a little confusing for you to understand the input
   and output dimensions at the end of each convolution layer. i decided
   to take these few lines to make you capable of identifying the output
   dimensions. three hyperparameter would control the size of output
   volume.
    1. the number of filters     the depth of the output volume will be
       equal to the number of filter applied. remember how we had stacked
       the output from each filter to form an activation map. the depth of
       the activation map will be equal to the number of filters.
    2. stride     when we have a stride of one we move across and down a
       single pixel. with higher stride values, we move large number of
       pixels at a time and hence produce smaller output volumes.
    3. zero padding     this helps us to preserve the size of the input
       image. if a single zero padding is added, a single stride filter
       movement would retain the size of the original image.

   we can apply a simple formula to calculate the output dimensions. the
   spatial size of the output image can be calculated as( [w-f+2p]/s)+1.
   here, w is the input volume size, f is the size of the filter, p is the
   number of padding applied and s is the number of strides. suppose we
   have an input image of size 32*32*3, we apply 10 filters of size 3*3*3,
   with single stride and no zero padding.

   here w=32, f=3, p=0 and s=1. the output depth will be equal to the
   number of filters applied i.e. 10.

   the size of the output volume will be ([32-3+0]/1)+1 = 30. therefore
   the output volume will be 30*30*10.


2.3 the output layer

   after multiple layers of convolution and padding, we would need the
   output in the form of a class. the convolution and pooling layers would
   only be able to extract features and reduce the number of parameters
   from the  original images. however, to generate the final output we
   need to apply a fully connected layer to generate an output equal to
   the number of classes we need. it becomes tough to reach that number
   with just the convolution layers. convolution layers generate 3d
   activation maps while we just need the output as whether or not an
   image belongs to a particular class. the output layer has a loss
   function like categorical cross-id178, to compute the error in
   prediction. once the forward pass is complete the id26
   begins to update the weight and biases for error and loss reduction.


3. putting it all together     how does the entire network look like ?

   id98 as you can now see is composed of various convolutional and pooling
   layers. let   s see how the network looks like.

     * we pass an input image to the first convolutional layer. the
       convoluted output is  obtained as an activation map. the filters
       applied in the convolution layer extract relevant features from the
       input image to pass further.
     * each filter shall give a different feature to aid the correct class
       prediction. in case we need to retain the size of the image, we use
       same padding(zero padding), other wise valid padding is used since
       it helps to reduce the number of features.
     * pooling layers are then added to further reduce the number of
       parameters
     * several convolution and pooling layers are added before the
       prediction is made. convolutional layer help in extracting
       features. as we go deeper in the network more specific features are
       extracted as compared to a shallow network where the features
       extracted are more generic.
     * the output layer in a id98 as mentioned previously is a fully
       connected layer, where the input from the other layers is flattened
       and sent so as the transform the output into the number of classes
       as desired by the network.
     * the output is then generated through the output layer and is
       compared to the output layer for error generation. a id168
       is defined in the fully connected output layer to compute the mean
       square loss. the gradient of error is then calculated.
     * the error is then backpropagated to update the filter(weights) and
       bias values.
     * one training cycle is completed in a single forward and backward
       pass.


4. using id98 to classify images in keras

   let   s try taking an example where we input several images of cats and
   dogs and we try to classify these images into their respective animal
   category. this is a classic problem of image recognition and
   classification. what the machine needs to do is it needs to see the
   image and understand by the various features as to whether its a cat or
   a dog.

   the features can be like extracting the edges, or extracting the
   whiskers of a cat etc. the convolutional layer would extract these
   features. let   s take a hand on the data set.

   these are the examples of some of the images in the dataset.

   we would first need to resize these images to get them all in the same
   shape. this is something we would generally need to do while handling
   images, since while capturing images, it would be impossible to capture
   all images of the same size.

   for simplicity of your understanding i have just used a single
   convolution layer and a single pooling layer, which generally doesn   t
   happen when we   re trying to make predictions. dataset used can be
   downloaded from [98]here.

   #import various packages

   import os
   import numpy as np
   import pandas as pd
   import scipy
   import sklearn
   import keras
   from keras.models import sequential
   import cv2
   from skimage import io
   %matplotlib inline

   #defining the file path

   cat=os.listdir("/mnt/hdd/datasets/dogs_cats/train/cat")
   dog=os.listdir("/mnt/hdd/datasets/dogs_cats/train/dog")
   filepath="/mnt/hdd/datasets/dogs_cats/train/cat/"
   filepath2="/mnt/hdd/datasets/dogs_cats/train/dog/"

   #loading the images

   images=[]
   label = []
   for i in cat:
       image = scipy.misc.imread(filepath+i)
       images.append(image)
       label.append(0) #for cat images

   for i in dog:
       image = scipy.misc.imread(filepath2+i)
       images.append(image)
       label.append(1) #for dog images

   #resizing all the images

   for i in range(0,23000):
       images[i]=cv2.resize(images[i],(300,300))

   #converting images to arrays

   images=np.array(images)
   label=np.array(label)

   # defining the hyperparameters

   filters=10
   filtersize=(5,5)

   epochs =5
   batchsize=128

   input_shape=(300,300,3)

   #converting the target variable to the required size

   from keras.utils.np_utils import to_categorical
   label = to_categorical(label)

   #defining the model

   model = sequential()

   model.add(keras.layers.inputlayer(input_shape=input_shape))

   model.add(keras.layers.convolutional.conv2d(filters, filtersize,
   strides=(1, 1), padding='valid', data_format="channels_last",
   activation='relu'))
   model.add(keras.layers.maxpooling2d(pool_size=(2, 2)))
   model.add(keras.layers.flatten())

   model.add(keras.layers.dense(units=2,
   input_dim=50,activation='softmax'))

   model.compile(loss='categorical_crossid178', optimizer='adam',
   metrics=['accuracy'])
   model.fit(images, label, epochs=epochs,
   batch_size=batchsize,validation_split=0.3)

   model.summary()

   in this model, i have only used a single convolution and pooling layer
   and the trainable parameters are 219,801. wonder how many would i have
   had if i had used an mlp in this case. you can reduce the number of
   parameters by further by adding more convolution and pooling layers.
   the more convolution layers we add the features extracted would be more
   specific and intricate.


projects

   now, its time to take the plunge and actually play with some other real
   datasets. so are you ready to take on the challenge? accelerate your
   deep learning journey with the following practice problems:


   [99]practice problem: identify the apparels identify the type of
   apparel for given images
   [100]practice problem: identify the digits identify the digit in given
   images

end notes

   i hope through this article i was able to provide you an intuition into
   convolutional neural networks. i did not go into the complex
   mathematics of id98. in case you   re fond of understanding the same    
   stay tuned, there   s much more lined up for you. try building your own
   id98 network to understand how it operates and makes predictions on
   images. let me know your findings and approach using the comments
   section.
   you can also read this article on analytics vidhya's android app
   [101]get it on google play

share this:

     * [102]click to share on linkedin (opens in new window)
     * [103]click to share on facebook (opens in new window)
     * [104]click to share on twitter (opens in new window)
     * [105]click to share on pocket (opens in new window)
     * [106]click to share on reddit (opens in new window)
     *

like this:

   like loading...

related articles

   [ins: :ins]

   tags : [107]id98, [108]convolution layer, [109]convolution neural
   networks, [110]depp learning, [111]neural networks
   next article

30 questions to test a data scientist on id75 [solution:
skilltest     id75]

   previous article

big data architect- mumbai (7+ years of experience)

[112]dishashree gupta

   dishashree is passionate about statistics and is a machine learning
   enthusiast. she has an experience of 1.5 years of market research using
   r, advanced excel, azure ml.

   this article is quite old and you might not get a prompt response from
   the author. we request you to post this comment on analytics vidhya's
   [113]discussion portal to get your queries resolved

59 comments

     * venkat says:
       [114]june 29, 2017 at 1:04 pm
       very well explained with visuals, and good work! but we are missing
          bias    information (may be the part of future post).
       i wonder if you can help me understand what hardware has been used
       and what is the minimum hardware required.
       [115]reply
          + dishashree gupta says:
            [116]june 29, 2017 at 4:53 pm
            hi venkat,
            you should have a gpu to run this seaid113ssly. for more details
            read
            [117]https://www.analyticsvidhya.com/blog/2016/11/building-a-m
            achine-learning-deep-learning-workstation-for-under-5000/
            [118]reply
          + debarshi datta says:
            [119]july 3, 2017 at 1:41 am
            @venkat, you can run deep learning algorithms in very basic
            pcs. problem you will face when you increase the number of
            parameters or epochs. i have ran mnist data using mlp in my
            5yr old laptop with 3gb ram and an i5 processor. but having a
            gpu makes the process much faster. i think the cheapest and
            basic gpu for deeplearning available in ncr is geforce gtx 750
            ti (~rs.8k), adding another 30k for other parts, will make it
            ~40k for a basic deeplearning gpu enabled hardware.
            [120]reply
     * t  nis says:
       [121]june 29, 2017 at 1:33 pm
       but weight matrix itself, how it is initialized? randomly or with
       certain alghorithm?
       [122]reply
          + dishashree gupta says:
            [123]june 29, 2017 at 4:43 pm
            hi tonis,
            weight can be initialized randomly. however, we do have
            methods like xavier   s initialization to initialize a weight
            matrix as well.
            [124]reply
     * carl says:
       [125]june 29, 2017 at 1:56 pm
       great article. one question: how does one determine the number of
       filters to use for each convolutional layer? you used 10 for your
       example, but why not 5, 20, 100, etc?
       [126]reply
          + dishashree gupta says:
            [127]june 29, 2017 at 4:33 pm
            number of filters is a hyperparameter. there is no fixed
            number to it.
            [128]reply
     * [129]aditya lahiri says:
       [130]june 29, 2017 at 2:56 pm
       great read.! however, is the softmax function really a loss
       function? isn   t it simply an activation function that takes in real
       numbers and spits them out as probabilities, squashing them between
       0 and 1?
       [131]reply
     * dishashree gupta says:
       [132]june 29, 2017 at 4:30 pm
       hi aditya,
       yes your point is absolutely correct. softmax is an activation
       function while cross-id178 would be a id168
       [133]reply
     * chandu says:
       [134]june 29, 2017 at 4:32 pm
       excellent    !
       good work disha .
       have red many postes related to id98 , but this the best of all .
       thank you .
       [135]reply
     * david a says:
       [136]june 29, 2017 at 4:58 pm
       i don   t quite understand the input shape and the general concept
       behind images description tuples having 3 items. like (300, 300, 3)
       in the cats and dog example or the 32*32*3 input you talked about
       before. i get the first two values being x and y but what is the
       third value?
       great post!! it really helped further my understanding
       [137]reply
          + dishashree gupta says:
            [138]june 29, 2017 at 5:02 pm
            hi david,
            so a coloured image normally has channels. 3 in the third
            dimension refers to the rgb channels of the image. try loading
            a single image and check its dimensions. it would be in 3d.
            [139]reply
     * dr venugopala rao says:
       [140]june 29, 2017 at 6:40 pm
       good o one
       [141]reply
     * shahmustafa mujawar says:
       [142]june 30, 2017 at 1:17 am
       great article, i have one question, in output layer    .
          convolution layers generate 3d activation maps while we just need
       the output as whether or not an image belongs to a particular
       class    who this be don?
       [143]reply
          + dishashree gupta says:
            [144]june 30, 2017 at 11:45 am
            that   s the reason why output layer is a dense layer instead of
            being a id98 layer, after extracting features using the id98
            architecture the image can be sent to a fully connected output
            layer which can generate the output as a particular class
            [145]reply
     * andrew says:
       [146]june 30, 2017 at 3:19 pm
       great article, thanks!
       in the text you   re saying, that    the depth dimension of the weight
       would be same as the depth dimension of the input image   , but in
       the code example input_shape=(300,300,3), but weights have only 2
       dimensions filtersize=(5,5)
       can you clarify it, please?
       [147]reply
          + dishashree gupta says:
            [148]june 30, 2017 at 3:27 pm
            it would automatically take the third dimension equal to that
            of the input image/activation map. hence we need not define it
            explicitly.
            [149]reply
     * ion says:
       [150]june 30, 2017 at 6:34 pm
       very nice explanation
       do you have full source code with images that i can replicate in
       github or bitbucket ?
       thx
       [151]reply
     * amrish pandey says:
       [152]july 2, 2017 at 8:17 pm
       awesome explanation . i always found this explanation very complex
       and would get stressed out. your explanation was like a story
       evolving through paragraphs.
       [153]reply
     * ravi theja says:
       [154]july 4, 2017 at 7:15 pm
       really awesome. you have broken the illusion i was under, about
       id98. thanks a ton for the wonderful explanation. first time i have
       visualized id98.
       [155]reply
     * anil kumar reddy says:
       [156]july 4, 2017 at 8:48 pm
       it is indeed a very nice article. i liked the way you explained the
       things.
       but i need a small clarification regarding the decrement of
       parameters in convnets compared to neural nets.
       yes, the size of the image is getting smaller but at the same time
       we are also getting multiple feature maps right?.there by the
       number of pixels are also increasing.am i going in the right
       direction? please explain.
       thank you.
       [157]reply
     * debarshi says:
       [158]july 10, 2017 at 4:01 pm
       hi dishashree, thanks for sharing.
       two question:
          model.add(keras.layers.convolutional.conv2d(filters, filtersize,
       strides=(1, 1)   
       this step creates    filters    number of convoluted images using
          filtersize    dimensions of pixels.
       are all the    filters    number of convoluted images are exactly same?
       or these are randomize at any stage?
          model.add(keras.layers.flatten())   
       is it necessary to convert the images to a single dimension?
       [159]reply
     * [160]les guessing says:
       [161]july 12, 2017 at 8:51 am
       truly helpful. i   ve struggled to understand id98   s. i really
       appreciate you taking the time and patience to spell it out.
       excellent work.
       [162]reply
          + faizan shaikh says:
            [163]march 21, 2018 at 11:58 am
            thanks les
            [164]reply
     * disha says:
       [165]july 12, 2017 at 1:24 pm
       nice explanation. thanks, waiting for articles on id56, gan..
       i found this video very intuitive    
       [166]https://www.youtube.com/watch?v=2-ol7zb0mmu
       [167]reply
     * [168]shashwat says:
       [169]july 26, 2017 at 3:31 pm
       browsing the web i found applications in speech and object
       recognition. however i would be interested to get some guidance on
       how to apply id98 as a binary classifier with all features having
       numeric values. can id98 even be used for this application?
       thanks for the detailed explanation!
       [170]reply
     * kanchan says:
       [171]august 6, 2017 at 8:05 pm
       well explained. id98 becomes more clear than before.
       [172]reply
     * shahmustafa mujawar says:
       [173]august 17, 2017 at 8:55 pm
       hi, convolution layer, features has been extracted. so what kind of
       features they are?    means only edge detection or any other kind of
       feature and do we have any control on it?
       [174]reply
     * sanghapriya bose says:
       [175]august 24, 2017 at 9:06 pm
       very helpful article. thanks.
       [176]reply
     * [177]thomas says:
       [178]august 25, 2017 at 5:39 am
       great post! have nice day !      09ji4
       [179]reply
     * amit says:
       [180]august 27, 2017 at 9:25 pm
       hi. great article.
       i   ve read that using many convolutions layers leads to more complex
       features in the deeper layers .
       can you please give me some color as to why this is the case? i   m
       having trouble intuitively understanding this.
       [181]reply
     * mona says:
       [182]august 29, 2017 at 2:38 pm
       hi dishashree
       i have doubt in weight learning procedure. can you please tell me
       how weight values are updated and what value we are using at time
       off comparison to calculate loss here?
       [183]reply
     * sitarama gunturi says:
       [184]august 30, 2017 at 3:58 pm
       one of the best explanation of convolution networks. brilliant
       work.
       [185]reply
     * sroy says:
       [186]september 8, 2017 at 4:59 pm
       we have followed your steps and trained the model successfully. can
       you please give some information on how to test on an unclassified
       test dataset ?
       [187]reply
     * hamzeh says:
       [188]september 11, 2017 at 8:37 pm
       explained very well speciall the visualizarion of the process was
       amazing. thank you.
       [189]reply
          + hamzeh says:
            [190]september 11, 2017 at 8:40 pm
            sorry for mistakes
            specially
            visuallization
            [191]reply
     * shiv onkar deepak kumar says:
       [192]september 20, 2017 at 11:00 pm
       where is image training data for cats and dogs
       [193]reply
     * chong kim says:
       [194]september 24, 2017 at 10:55 pm
       an excellent article about convolution networks! it has demystified
       it.
       [195]reply
     * john bhat says:
       [196]september 30, 2017 at 2:31 pm
       import numpy as np
       from keras.preprocessing import image
       example 4 single prediction:
       image4test = image.load_img(   path with image.format   , target_size =
       (64, 64))
       image4test = image.img_to_array(image4test)
       image4test= np.expand_dims(image4test, axis = 0)
       prediction= classifier.predict(image4test)
       hope this ll help
       [197]reply
     * prince ita says:
       [198]october 17, 2017 at 2:45 am
       hi dishashree thanks for the article. please i would love to know,
       in the process of training a convolutional neural network to
       recognize images, im aware that you compare the actual output of
       the network with the label of the target image with the help of a
       id168. my question is, are the labels actually arbitrary
       numbers that one can give to the target image?
       [199]reply
     * amit says:
       [200]october 18, 2017 at 1:44 pm
       can you please share from where to download the dataset?
       [201]reply
     * kris says:
       [202]october 23, 2017 at 2:40 pm
       excellent    !
       good work disha .
       have reed many postes related to id98 , but this the best of all .
       thank you .
       [203]reply
     * vijaya kumar kudari says:
       [204]october 24, 2017 at 12:11 am
       very neatly explained about id98, and its helped a lot.
       [205]reply
     * swapnil rai says:
       [206]october 27, 2017 at 12:04 am
       hi,
       great article and well explained.i am not able to understand the
       last layer(    units    and    input_dim    term)
       model.add(keras.layers.dense(units=2,
       input_dim=50,activation=   softmax   )).
       thanks!
       [207]reply
     * tarun says:
       [208]november 2, 2017 at 5:57 pm
       great article, very well explained.
       [209]reply
     * neha keshari says:
       [210]november 3, 2017 at 9:24 am
       great work! id98 well explained.
       it would be very helpful if you can explain id56 in the same way.
       [211]reply
     * vikas says:
       [212]november 5, 2017 at 4:20 pm
       i have not understood the stacking of convo layers and the no.of
       filters. can anyone please elaborate?
       [213]reply
     * prof ravi vadlamani says:
       [214]november 7, 2017 at 6:01 am
       very well explained!
       [215]reply
     * tanasan srikotr says:
       [216]november 7, 2017 at 10:10 pm
       ohh! finally i got it, thank you so much
       [217]reply
          + charmidholakia says:
            [218]december 23, 2017 at 5:23 pm
            so finally , how do we conclude and interpret the output
            whether it is a cat or a dog.
            how do we read the output?
            [219]reply
     * sandip gupta says:
       [220]december 25, 2017 at 8:29 pm
       thank you for explaining things in such a simple way .it will be
       very helpful if you please breakdown the    #defining the model    part
       line by line .thank you once again
       [221]reply
     * md. asadur rahman says:
       [222]january 3, 2018 at 10:22 am
       thank you mam, for your very well explanation. it helps me a lot to
       understand id98. thank you again.
       [223]reply
     * aditya padala says:
       [224]february 12, 2018 at 12:49 pm
       great article disha! keep up
       [225]reply
     * [226]darshan says:
       [227]march 8, 2018 at 11:12 pm
       great blog .
       thank you madam.
       [228]reply
     * sneha says:
       [229]march 15, 2018 at 11:01 am
       can anyone tell me how id98 is works on classification of
       text??   step by step working i needed?
       [230]reply
          + faizan shaikh says:
            [231]march 19, 2018 at 1:59 pm
            hi sneha, the internal working of id98 will be the same for a
            text classification model
            [232]reply
     * [233]gabriel says:
       [234]march 19, 2018 at 7:32 am
       excellent! thanks for article.
       [235]reply
     * anant says:
       [236]april 5, 2018 at 4:21 pm
       good article, worth reading!
       [237]reply
     * soumya shreya says:
       [238]april 9, 2018 at 10:48 pm
       very good article!!
       i am just beginning to learn deep learning. can anybody suggest me
       some online resources where i can run these programs. the hardware
       of my laptop seems insufficient for them.
       [239]reply

   [ins: :ins]

top analytics vidhya users

   rank                  name                  points
   1    [1.jpg?date=2019-04-05] [240]srk       3924
   2    [2.jpg?date=2019-04-05] [241]mark12    3510
   3    [3.jpg?date=2019-04-05] [242]nilabha   3261
   4    [4.jpg?date=2019-04-05] [243]nitish007 3237
   5    [5.jpg?date=2019-04-05] [244]tezdhar   3082
   [245]more user rankings
   [ins: :ins]
   [ins: :ins]

popular posts

     * [246]24 ultimate data science projects to boost your knowledge and
       skills (& can be accessed freely)
     * [247]understanding support vector machine algorithm from examples
       (along with code)
     * [248]essentials of machine learning algorithms (with python and r
       codes)
     * [249]a complete tutorial to learn data science with python from
       scratch
     * [250]7 types of regression techniques you should know!
     * [251]6 easy steps to learn naive bayes algorithm (with codes in
       python and r)
     * [252]a simple introduction to anova (with applications in excel)
     * [253]stock prices prediction using machine learning and deep
       learning techniques (with python codes)

   [ins: :ins]

recent posts

   [254]top 5 machine learning github repositories and reddit discussions
   from march 2019

[255]top 5 machine learning github repositories and reddit discussions from
march 2019

   april 4, 2019

   [256]id161 tutorial: a step-by-step introduction to image
   segmentation techniques (part 1)

[257]id161 tutorial: a step-by-step introduction to image
segmentation techniques (part 1)

   april 1, 2019

   [258]nuts and bolts of id23: introduction to temporal
   difference (td) learning

[259]nuts and bolts of id23: introduction to temporal
difference (td) learning

   march 28, 2019

   [260]16 opencv functions to start your id161 journey (with
   python code)

[261]16 opencv functions to start your id161 journey (with python
code)

   march 25, 2019

   [262][ds-finhack.jpg]

   [263][hikeathon.png]

   [av-white.d14465ee4af2.png]

analytics vidhya

     * [264]about us
     * [265]our team
     * [266]career
     * [267]contact us
     * [268]write for us

   [269]about us
   [270]   
   [271]our team
   [272]   
   [273]careers
   [274]   
   [275]contact us

data scientists

     * [276]blog
     * [277]hackathon
     * [278]discussions
     * [279]apply jobs
     * [280]leaderboard

companies

     * [281]post jobs
     * [282]trainings
     * [283]hiring hackathons
     * [284]advertising
     * [285]reach us

   don't have an account? [286]sign up here.

join our community :

   [287]46336 [288]followers
   [289]20224 [290]followers
   [291]followers
   [292]7513 [293]followers
   ____________________ >

      copyright 2013-2019 analytics vidhya.
     * [294]privacy policy
     * [295]terms of use
     * [296]refund policy

   don't have an account? [297]sign up here

   iframe: [298]likes-master

   %d bloggers like this:

   [loading.gif]
   ____________________

   ____________________

   ____________________
   [button input] (not implemented)_________________

   download resource

join the nextgen data science ecosystem

     * learn: get access to some of the best courses on data science
       created by us
     * engage: interact with thousands of data science professionals
       across the globe!
     * compete: compete in our hackathons and win exciting prizes
     * get hired: get information of jobs in data science community and
       build your profile

   [299](button) join now

   subscribe!

   iframe: [300]likes-master

   %d bloggers like this:

   [loading.gif]
   ____________________

   ____________________

   ____________________
   [button input] (not implemented)_________________

   download resource

join the nextgen data science ecosystem

     * learn: get access to some of the best courses on data science
       created by us
     * engage: interact with thousands of data science professionals
       across the globe!
     * compete: compete in our hackathons and win exciting prizes
     * get hired: get information of jobs in data science community and
       build your profile

   [301](button) join now

   subscribe!

references

   visible links
   1. https://www.analyticsvidhya.com/feed/
   2. https://www.analyticsvidhya.com/comments/feed/
   3. https://www.analyticsvidhya.com/blog/2017/06/architecture-of-convolutional-neural-networks-simplified-demystified/feed/
   4. https://www.analyticsvidhya.com/wp-json/oembed/1.0/embed?url=https://www.analyticsvidhya.com/blog/2017/06/architecture-of-convolutional-neural-networks-simplified-demystified/
   5. https://www.analyticsvidhya.com/wp-json/oembed/1.0/embed?url=https://www.analyticsvidhya.com/blog/2017/06/architecture-of-convolutional-neural-networks-simplified-demystified/&format=xml
   6. https://googletagmanager.com/ns.html?id=gtm-mpsm42v
   7. https://courses.analyticsvidhya.com/bundles/ai-blackbelt-beginner-to-master?utm_source=blog&utm_medium=flashstrip
   8. https://www.analyticsvidhya.com/blog/2017/06/architecture-of-convolutional-neural-networks-simplified-demystified/
   9. https://www.analyticsvidhya.com/blog-archive/
  10. https://www.analyticsvidhya.com/blog/category/machine-learning/
  11. https://www.analyticsvidhya.com/blog/category/deep-learning/
  12. https://www.analyticsvidhya.com/blog/category/career/
  13. https://www.analyticsvidhya.com/blog/category/stories/
  14. https://www.analyticsvidhya.com/blog/category/podcast/
  15. https://www.analyticsvidhya.com/blog/category/infographics/
  16. https://courses.analyticsvidhya.com/?utm_source=home_blog_navbar
  17. https://www.analyticsvidhya.com/learning-paths-data-science-business-analytics-business-intelligence-big-data/
  18. https://www.analyticsvidhya.com/learning-paths-data-science-business-analytics-business-intelligence-big-data/learning-path-business-analyst-sas/
  19. https://www.analyticsvidhya.com/learning-paths-data-science-business-analytics-business-intelligence-big-data/learning-path-r-data-science/
  20. https://www.analyticsvidhya.com/learning-paths-data-science-business-analytics-business-intelligence-big-data/learning-path-data-science-python/
  21. https://www.analyticsvidhya.com/learning-paths-data-science-business-analytics-business-intelligence-big-data/weka-gui-learn-machine-learning/
  22. https://www.analyticsvidhya.com/learning-paths-data-science-business-analytics-business-intelligence-big-data/tableau-learning-path/
  23. https://www.analyticsvidhya.com/learning-paths-data-science-business-analytics-business-intelligence-big-data/qlikview-learning-path/
  24. https://www.analyticsvidhya.com/learning-paths-data-science-business-analytics-business-intelligence-big-data/newbie-d3-js-expert-complete-path-create-interactive-visualization-d3-js/
  25. https://www.analyticsvidhya.com/glossary-of-common-statistics-and-machine-learning-terms/
  26. https://www.analyticsvidhya.com/blog/2017/06/architecture-of-convolutional-neural-networks-simplified-demystified/
  27. https://discuss.analyticsvidhya.com/
  28. https://www.analyticsvidhya.com/blog/category/events/
  29. https://www.analyticsvidhya.com/datahack-summit-2018/
  30. https://www.analyticsvidhya.com/datahacksummit/
  31. https://www.analyticsvidhya.com/student-datafest-2018/?utm_source=homepage_menu
  32. http://www.analyticsvidhya.com/about-me/write/
  33. https://www.analyticsvidhya.com/blog/2017/06/architecture-of-convolutional-neural-networks-simplified-demystified/
  34. https://datahack.analyticsvidhya.com/contest/all
  35. https://www.analyticsvidhya.com/blog/2017/06/architecture-of-convolutional-neural-networks-simplified-demystified/
  36. https://www.analyticsvidhya.com/jobs/
  37. https://courses.analyticsvidhya.com/
  38. https://courses.analyticsvidhya.com/courses/computer-vision-using-deep-learning/?utm_source=blog-navbar&utm_medium=web
  39. https://courses.analyticsvidhya.com/courses/natural-language-processing-nlp/?utm_source=blog-navbar&utm_medium=web
  40. https://courses.analyticsvidhya.com/courses/introduction-to-data-science-2/?utm_source=blog-navbar&utm_medium=web
  41. https://courses.analyticsvidhya.com/courses/microsoft-excel-beginners-to-advanced/?utm_source=blog-navbar&utm_medium=web
  42. https://courses.analyticsvidhya.com/collections/?utm_source=blog-navbar&utm_medium=web
  43. https://www.analyticsvidhya.com/contact/
  44. https://www.analyticsvidhya.com/
  45. https://www.analyticsvidhya.com/blog-archive/
  46. https://courses.analyticsvidhya.com/?utm_source=home_blog_navbar
  47. https://discuss.analyticsvidhya.com/
  48. https://datahack.analyticsvidhya.com/
  49. https://www.analyticsvidhya.com/jobs/
  50. https://www.analyticsvidhya.com/corporate/
  51. https://www.analyticsvidhya.com/blog/
  52. https://courses.analyticsvidhya.com/bundles/ai-blackbelt-beginner-to-master?utm_source=avtopbanner&utm_medium=display
  53. https://courses.analyticsvidhya.com/bundles/ai-blackbelt-beginner-to-master?utm_source=avtopbanner&utm_medium=display
  54. https://courses.analyticsvidhya.com/bundles/ai-blackbelt-beginner-to-master?utm_source=avtopbanner&utm_medium=display
  55. https://www.analyticsvidhya.com/blog/
  56. https://www.analyticsvidhya.com/blog/2017/06/architecture-of-convolutional-neural-networks-simplified-demystified/
  57. https://www.analyticsvidhya.com/blog-archive/
  58. https://www.analyticsvidhya.com/blog/category/machine-learning/
  59. https://www.analyticsvidhya.com/blog/category/deep-learning/
  60. https://www.analyticsvidhya.com/blog/category/career/
  61. https://www.analyticsvidhya.com/blog/category/stories/
  62. https://www.analyticsvidhya.com/blog/category/podcast/
  63. https://www.analyticsvidhya.com/blog/category/infographics/
  64. https://courses.analyticsvidhya.com/?utm_source=home_blog_navbar
  65. https://www.analyticsvidhya.com/learning-paths-data-science-business-analytics-business-intelligence-big-data/
  66. https://www.analyticsvidhya.com/learning-paths-data-science-business-analytics-business-intelligence-big-data/learning-path-business-analyst-sas/
  67. https://www.analyticsvidhya.com/learning-paths-data-science-business-analytics-business-intelligence-big-data/learning-path-r-data-science/
  68. https://www.analyticsvidhya.com/learning-paths-data-science-business-analytics-business-intelligence-big-data/learning-path-data-science-python/
  69. https://www.analyticsvidhya.com/learning-paths-data-science-business-analytics-business-intelligence-big-data/weka-gui-learn-machine-learning/
  70. https://www.analyticsvidhya.com/learning-paths-data-science-business-analytics-business-intelligence-big-data/tableau-learning-path/
  71. https://www.analyticsvidhya.com/learning-paths-data-science-business-analytics-business-intelligence-big-data/qlikview-learning-path/
  72. https://www.analyticsvidhya.com/learning-paths-data-science-business-analytics-business-intelligence-big-data/newbie-d3-js-expert-complete-path-create-interactive-visualization-d3-js/
  73. https://www.analyticsvidhya.com/glossary-of-common-statistics-and-machine-learning-terms/
  74. https://www.analyticsvidhya.com/blog/2017/06/architecture-of-convolutional-neural-networks-simplified-demystified/
  75. https://discuss.analyticsvidhya.com/
  76. https://www.analyticsvidhya.com/blog/category/events/
  77. https://www.analyticsvidhya.com/datahack-summit-2018/
  78. https://www.analyticsvidhya.com/datahacksummit/
  79. https://www.analyticsvidhya.com/student-datafest-2018/?utm_source=homepage_menu
  80. http://www.analyticsvidhya.com/about-me/write/
  81. https://www.analyticsvidhya.com/blog/2017/06/architecture-of-convolutional-neural-networks-simplified-demystified/
  82. https://datahack.analyticsvidhya.com/contest/all
  83. https://www.analyticsvidhya.com/blog/2017/06/architecture-of-convolutional-neural-networks-simplified-demystified/
  84. https://www.analyticsvidhya.com/jobs/
  85. https://courses.analyticsvidhya.com/
  86. https://courses.analyticsvidhya.com/courses/computer-vision-using-deep-learning/?utm_source=blog-navbar&utm_medium=web
  87. https://courses.analyticsvidhya.com/courses/natural-language-processing-nlp/?utm_source=blog-navbar&utm_medium=web
  88. https://courses.analyticsvidhya.com/courses/introduction-to-data-science-2/?utm_source=blog-navbar&utm_medium=web
  89. https://courses.analyticsvidhya.com/courses/microsoft-excel-beginners-to-advanced/?utm_source=blog-navbar&utm_medium=web
  90. https://courses.analyticsvidhya.com/collections/?utm_source=blog-navbar&utm_medium=web
  91. https://www.analyticsvidhya.com/contact/
  92. https://www.analyticsvidhya.com/
  93. https://www.analyticsvidhya.com/blog/category/deep-learning/
  94. https://www.analyticsvidhya.com/blog/2017/06/architecture-of-convolutional-neural-networks-simplified-demystified/
  95. https://www.analyticsvidhya.com/blog/category/deep-learning/
  96. https://www.analyticsvidhya.com/blog/author/dishashree26/
  97. https://www.analyticsvidhya.com/blog/2017/05/neural-network-from-scratch-in-python-and-r/
  98. http://files.fast.ai/data/dogscats.zip
  99. https://datahack.analyticsvidhya.com/contest/practice-problem-identify-the-apparels/?utm_source=architecture-of-convolutional-neural-networks-simplified-demystified&utm_medium=blog
 100. https://datahack.analyticsvidhya.com/contest/practice-problem-identify-the-digits/?utm_source=architecture-of-convolutional-neural-networks-simplified-demystified&utm_medium=blog
 101. https://play.google.com/store/apps/details?id=com.analyticsvidhya.android&utm_source=blog_article&utm_campaign=blog&pcampaignid=mkt-other-global-all-co-prtnr-py-partbadge-mar2515-1
 102. https://www.analyticsvidhya.com/blog/2017/06/architecture-of-convolutional-neural-networks-simplified-demystified/?share=linkedin
 103. https://www.analyticsvidhya.com/blog/2017/06/architecture-of-convolutional-neural-networks-simplified-demystified/?share=facebook
 104. https://www.analyticsvidhya.com/blog/2017/06/architecture-of-convolutional-neural-networks-simplified-demystified/?share=twitter
 105. https://www.analyticsvidhya.com/blog/2017/06/architecture-of-convolutional-neural-networks-simplified-demystified/?share=pocket
 106. https://www.analyticsvidhya.com/blog/2017/06/architecture-of-convolutional-neural-networks-simplified-demystified/?share=reddit
 107. https://www.analyticsvidhya.com/blog/tag/id98/
 108. https://www.analyticsvidhya.com/blog/tag/convolution-layer/
 109. https://www.analyticsvidhya.com/blog/tag/convolution-neural-networks/
 110. https://www.analyticsvidhya.com/blog/tag/depp-learning/
 111. https://www.analyticsvidhya.com/blog/tag/neural-networks/
 112. https://www.analyticsvidhya.com/blog/author/dishashree26/
 113. https://discuss.analyticsvidhya.com/
 114. https://www.analyticsvidhya.com/blog/2017/06/architecture-of-convolutional-neural-networks-simplified-demystified/#comment-131282
 115. https://www.analyticsvidhya.com/blog/2017/06/architecture-of-convolutional-neural-networks-simplified-demystified/#comment-131282
 116. https://www.analyticsvidhya.com/blog/2017/06/architecture-of-convolutional-neural-networks-simplified-demystified/#comment-131314
 117. https://www.analyticsvidhya.com/blog/2016/11/building-a-machine-learning-deep-learning-workstation-for-under-5000/
 118. https://www.analyticsvidhya.com/blog/2017/06/architecture-of-convolutional-neural-networks-simplified-demystified/#comment-131314
 119. https://www.analyticsvidhya.com/blog/2017/06/architecture-of-convolutional-neural-networks-simplified-demystified/#comment-131455
 120. https://www.analyticsvidhya.com/blog/2017/06/architecture-of-convolutional-neural-networks-simplified-demystified/#comment-131455
 121. https://www.analyticsvidhya.com/blog/2017/06/architecture-of-convolutional-neural-networks-simplified-demystified/#comment-131285
 122. https://www.analyticsvidhya.com/blog/2017/06/architecture-of-convolutional-neural-networks-simplified-demystified/#comment-131285
 123. https://www.analyticsvidhya.com/blog/2017/06/architecture-of-convolutional-neural-networks-simplified-demystified/#comment-131312
 124. https://www.analyticsvidhya.com/blog/2017/06/architecture-of-convolutional-neural-networks-simplified-demystified/#comment-131312
 125. https://www.analyticsvidhya.com/blog/2017/06/architecture-of-convolutional-neural-networks-simplified-demystified/#comment-131287
 126. https://www.analyticsvidhya.com/blog/2017/06/architecture-of-convolutional-neural-networks-simplified-demystified/#comment-131287
 127. https://www.analyticsvidhya.com/blog/2017/06/architecture-of-convolutional-neural-networks-simplified-demystified/#comment-131310
 128. https://www.analyticsvidhya.com/blog/2017/06/architecture-of-convolutional-neural-networks-simplified-demystified/#comment-131310
 129. http://odesandcodes.wordpress.com/
 130. https://www.analyticsvidhya.com/blog/2017/06/architecture-of-convolutional-neural-networks-simplified-demystified/#comment-131294
 131. https://www.analyticsvidhya.com/blog/2017/06/architecture-of-convolutional-neural-networks-simplified-demystified/#comment-131294
 132. https://www.analyticsvidhya.com/blog/2017/06/architecture-of-convolutional-neural-networks-simplified-demystified/#comment-131308
 133. https://www.analyticsvidhya.com/blog/2017/06/architecture-of-convolutional-neural-networks-simplified-demystified/#comment-131308
 134. https://www.analyticsvidhya.com/blog/2017/06/architecture-of-convolutional-neural-networks-simplified-demystified/#comment-131309
 135. https://www.analyticsvidhya.com/blog/2017/06/architecture-of-convolutional-neural-networks-simplified-demystified/#comment-131309
 136. https://www.analyticsvidhya.com/blog/2017/06/architecture-of-convolutional-neural-networks-simplified-demystified/#comment-131316
 137. https://www.analyticsvidhya.com/blog/2017/06/architecture-of-convolutional-neural-networks-simplified-demystified/#comment-131316
 138. https://www.analyticsvidhya.com/blog/2017/06/architecture-of-convolutional-neural-networks-simplified-demystified/#comment-131317
 139. https://www.analyticsvidhya.com/blog/2017/06/architecture-of-convolutional-neural-networks-simplified-demystified/#comment-131317
 140. https://www.analyticsvidhya.com/blog/2017/06/architecture-of-convolutional-neural-networks-simplified-demystified/#comment-131321
 141. https://www.analyticsvidhya.com/blog/2017/06/architecture-of-convolutional-neural-networks-simplified-demystified/#comment-131321
 142. https://www.analyticsvidhya.com/blog/2017/06/architecture-of-convolutional-neural-networks-simplified-demystified/#comment-131333
 143. https://www.analyticsvidhya.com/blog/2017/06/architecture-of-convolutional-neural-networks-simplified-demystified/#comment-131333
 144. https://www.analyticsvidhya.com/blog/2017/06/architecture-of-convolutional-neural-networks-simplified-demystified/#comment-131353
 145. https://www.analyticsvidhya.com/blog/2017/06/architecture-of-convolutional-neural-networks-simplified-demystified/#comment-131353
 146. https://www.analyticsvidhya.com/blog/2017/06/architecture-of-convolutional-neural-networks-simplified-demystified/#comment-131360
 147. https://www.analyticsvidhya.com/blog/2017/06/architecture-of-convolutional-neural-networks-simplified-demystified/#comment-131360
 148. https://www.analyticsvidhya.com/blog/2017/06/architecture-of-convolutional-neural-networks-simplified-demystified/#comment-131361
 149. https://www.analyticsvidhya.com/blog/2017/06/architecture-of-convolutional-neural-networks-simplified-demystified/#comment-131361
 150. https://www.analyticsvidhya.com/blog/2017/06/architecture-of-convolutional-neural-networks-simplified-demystified/#comment-131366
 151. https://www.analyticsvidhya.com/blog/2017/06/architecture-of-convolutional-neural-networks-simplified-demystified/#comment-131366
 152. https://www.analyticsvidhya.com/blog/2017/06/architecture-of-convolutional-neural-networks-simplified-demystified/#comment-131446
 153. https://www.analyticsvidhya.com/blog/2017/06/architecture-of-convolutional-neural-networks-simplified-demystified/#comment-131446
 154. https://www.analyticsvidhya.com/blog/2017/06/architecture-of-convolutional-neural-networks-simplified-demystified/#comment-131529
 155. https://www.analyticsvidhya.com/blog/2017/06/architecture-of-convolutional-neural-networks-simplified-demystified/#comment-131529
 156. https://www.analyticsvidhya.com/blog/2017/06/architecture-of-convolutional-neural-networks-simplified-demystified/#comment-131534
 157. https://www.analyticsvidhya.com/blog/2017/06/architecture-of-convolutional-neural-networks-simplified-demystified/#comment-131534
 158. https://www.analyticsvidhya.com/blog/2017/06/architecture-of-convolutional-neural-networks-simplified-demystified/#comment-131920
 159. https://www.analyticsvidhya.com/blog/2017/06/architecture-of-convolutional-neural-networks-simplified-demystified/#comment-131920
 160. https://www.creativealgorithm.org/
 161. https://www.analyticsvidhya.com/blog/2017/06/architecture-of-convolutional-neural-networks-simplified-demystified/#comment-131994
 162. https://www.analyticsvidhya.com/blog/2017/06/architecture-of-convolutional-neural-networks-simplified-demystified/#comment-131994
 163. https://www.analyticsvidhya.com/blog/2017/06/architecture-of-convolutional-neural-networks-simplified-demystified/#comment-152047
 164. https://www.analyticsvidhya.com/blog/2017/06/architecture-of-convolutional-neural-networks-simplified-demystified/#comment-152047
 165. https://www.analyticsvidhya.com/blog/2017/06/architecture-of-convolutional-neural-networks-simplified-demystified/#comment-132004
 166. https://www.youtube.com/watch?v=2-ol7zb0mmu
 167. https://www.analyticsvidhya.com/blog/2017/06/architecture-of-convolutional-neural-networks-simplified-demystified/#comment-132004
 168. http://shashwatsiddhant.strikingly.com/
 169. https://www.analyticsvidhya.com/blog/2017/06/architecture-of-convolutional-neural-networks-simplified-demystified/#comment-132930
 170. https://www.analyticsvidhya.com/blog/2017/06/architecture-of-convolutional-neural-networks-simplified-demystified/#comment-132930
 171. https://www.analyticsvidhya.com/blog/2017/06/architecture-of-convolutional-neural-networks-simplified-demystified/#comment-133782
 172. https://www.analyticsvidhya.com/blog/2017/06/architecture-of-convolutional-neural-networks-simplified-demystified/#comment-133782
 173. https://www.analyticsvidhya.com/blog/2017/06/architecture-of-convolutional-neural-networks-simplified-demystified/#comment-134546
 174. https://www.analyticsvidhya.com/blog/2017/06/architecture-of-convolutional-neural-networks-simplified-demystified/#comment-134546
 175. https://www.analyticsvidhya.com/blog/2017/06/architecture-of-convolutional-neural-networks-simplified-demystified/#comment-135034
 176. https://www.analyticsvidhya.com/blog/2017/06/architecture-of-convolutional-neural-networks-simplified-demystified/#comment-135034
 177. http://x0oxhg0sv8.com/
 178. https://www.analyticsvidhya.com/blog/2017/06/architecture-of-convolutional-neural-networks-simplified-demystified/#comment-135055
 179. https://www.analyticsvidhya.com/blog/2017/06/architecture-of-convolutional-neural-networks-simplified-demystified/#comment-135055
 180. https://www.analyticsvidhya.com/blog/2017/06/architecture-of-convolutional-neural-networks-simplified-demystified/#comment-135259
 181. https://www.analyticsvidhya.com/blog/2017/06/architecture-of-convolutional-neural-networks-simplified-demystified/#comment-135259
 182. https://www.analyticsvidhya.com/blog/2017/06/architecture-of-convolutional-neural-networks-simplified-demystified/#comment-135431
 183. https://www.analyticsvidhya.com/blog/2017/06/architecture-of-convolutional-neural-networks-simplified-demystified/#comment-135431
 184. https://www.analyticsvidhya.com/blog/2017/06/architecture-of-convolutional-neural-networks-simplified-demystified/#comment-135633
 185. https://www.analyticsvidhya.com/blog/2017/06/architecture-of-convolutional-neural-networks-simplified-demystified/#comment-135633
 186. https://www.analyticsvidhya.com/blog/2017/06/architecture-of-convolutional-neural-networks-simplified-demystified/#comment-136648
 187. https://www.analyticsvidhya.com/blog/2017/06/architecture-of-convolutional-neural-networks-simplified-demystified/#comment-136648
 188. https://www.analyticsvidhya.com/blog/2017/06/architecture-of-convolutional-neural-networks-simplified-demystified/#comment-136877
 189. https://www.analyticsvidhya.com/blog/2017/06/architecture-of-convolutional-neural-networks-simplified-demystified/#comment-136877
 190. https://www.analyticsvidhya.com/blog/2017/06/architecture-of-convolutional-neural-networks-simplified-demystified/#comment-136879
 191. https://www.analyticsvidhya.com/blog/2017/06/architecture-of-convolutional-neural-networks-simplified-demystified/#comment-136879
 192. https://www.analyticsvidhya.com/blog/2017/06/architecture-of-convolutional-neural-networks-simplified-demystified/#comment-137567
 193. https://www.analyticsvidhya.com/blog/2017/06/architecture-of-convolutional-neural-networks-simplified-demystified/#comment-137567
 194. https://www.analyticsvidhya.com/blog/2017/06/architecture-of-convolutional-neural-networks-simplified-demystified/#comment-137890
 195. https://www.analyticsvidhya.com/blog/2017/06/architecture-of-convolutional-neural-networks-simplified-demystified/#comment-137890
 196. https://www.analyticsvidhya.com/blog/2017/06/architecture-of-convolutional-neural-networks-simplified-demystified/#comment-138361
 197. https://www.analyticsvidhya.com/blog/2017/06/architecture-of-convolutional-neural-networks-simplified-demystified/#comment-138361
 198. https://www.analyticsvidhya.com/blog/2017/06/architecture-of-convolutional-neural-networks-simplified-demystified/#comment-139830
 199. https://www.analyticsvidhya.com/blog/2017/06/architecture-of-convolutional-neural-networks-simplified-demystified/#comment-139830
 200. https://www.analyticsvidhya.com/blog/2017/06/architecture-of-convolutional-neural-networks-simplified-demystified/#comment-139977
 201. https://www.analyticsvidhya.com/blog/2017/06/architecture-of-convolutional-neural-networks-simplified-demystified/#comment-139977
 202. https://www.analyticsvidhya.com/blog/2017/06/architecture-of-convolutional-neural-networks-simplified-demystified/#comment-140526
 203. https://www.analyticsvidhya.com/blog/2017/06/architecture-of-convolutional-neural-networks-simplified-demystified/#comment-140526
 204. https://www.analyticsvidhya.com/blog/2017/06/architecture-of-convolutional-neural-networks-simplified-demystified/#comment-140597
 205. https://www.analyticsvidhya.com/blog/2017/06/architecture-of-convolutional-neural-networks-simplified-demystified/#comment-140597
 206. https://www.analyticsvidhya.com/blog/2017/06/architecture-of-convolutional-neural-networks-simplified-demystified/#comment-140971
 207. https://www.analyticsvidhya.com/blog/2017/06/architecture-of-convolutional-neural-networks-simplified-demystified/#comment-140971
 208. https://www.analyticsvidhya.com/blog/2017/06/architecture-of-convolutional-neural-networks-simplified-demystified/#comment-141919
 209. https://www.analyticsvidhya.com/blog/2017/06/architecture-of-convolutional-neural-networks-simplified-demystified/#comment-141919
 210. https://www.analyticsvidhya.com/blog/2017/06/architecture-of-convolutional-neural-networks-simplified-demystified/#comment-142015
 211. https://www.analyticsvidhya.com/blog/2017/06/architecture-of-convolutional-neural-networks-simplified-demystified/#comment-142015
 212. https://www.analyticsvidhya.com/blog/2017/06/architecture-of-convolutional-neural-networks-simplified-demystified/#comment-142300
 213. https://www.analyticsvidhya.com/blog/2017/06/architecture-of-convolutional-neural-networks-simplified-demystified/#comment-142300
 214. https://www.analyticsvidhya.com/blog/2017/06/architecture-of-convolutional-neural-networks-simplified-demystified/#comment-142499
 215. https://www.analyticsvidhya.com/blog/2017/06/architecture-of-convolutional-neural-networks-simplified-demystified/#comment-142499
 216. https://www.analyticsvidhya.com/blog/2017/06/architecture-of-convolutional-neural-networks-simplified-demystified/#comment-142619
 217. https://www.analyticsvidhya.com/blog/2017/06/architecture-of-convolutional-neural-networks-simplified-demystified/#comment-142619
 218. https://www.analyticsvidhya.com/blog/2017/06/architecture-of-convolutional-neural-networks-simplified-demystified/#comment-149225
 219. https://www.analyticsvidhya.com/blog/2017/06/architecture-of-convolutional-neural-networks-simplified-demystified/#comment-149225
 220. https://www.analyticsvidhya.com/blog/2017/06/architecture-of-convolutional-neural-networks-simplified-demystified/#comment-149444
 221. https://www.analyticsvidhya.com/blog/2017/06/architecture-of-convolutional-neural-networks-simplified-demystified/#comment-149444
 222. https://www.analyticsvidhya.com/blog/2017/06/architecture-of-convolutional-neural-networks-simplified-demystified/#comment-150490
 223. https://www.analyticsvidhya.com/blog/2017/06/architecture-of-convolutional-neural-networks-simplified-demystified/#comment-150490
 224. https://www.analyticsvidhya.com/blog/2017/06/architecture-of-convolutional-neural-networks-simplified-demystified/#comment-151323
 225. https://www.analyticsvidhya.com/blog/2017/06/architecture-of-convolutional-neural-networks-simplified-demystified/#comment-151323
 226. http://analytics vidhya/
 227. https://www.analyticsvidhya.com/blog/2017/06/architecture-of-convolutional-neural-networks-simplified-demystified/#comment-151779
 228. https://www.analyticsvidhya.com/blog/2017/06/architecture-of-convolutional-neural-networks-simplified-demystified/#comment-151779
 229. https://www.analyticsvidhya.com/blog/2017/06/architecture-of-convolutional-neural-networks-simplified-demystified/#comment-151909
 230. https://www.analyticsvidhya.com/blog/2017/06/architecture-of-convolutional-neural-networks-simplified-demystified/#comment-151909
 231. https://www.analyticsvidhya.com/blog/2017/06/architecture-of-convolutional-neural-networks-simplified-demystified/#comment-151995
 232. https://www.analyticsvidhya.com/blog/2017/06/architecture-of-convolutional-neural-networks-simplified-demystified/#comment-151995
 233. http://www.datah.com.br/
 234. https://www.analyticsvidhya.com/blog/2017/06/architecture-of-convolutional-neural-networks-simplified-demystified/#comment-151973
 235. https://www.analyticsvidhya.com/blog/2017/06/architecture-of-convolutional-neural-networks-simplified-demystified/#comment-151973
 236. https://www.analyticsvidhya.com/blog/2017/06/architecture-of-convolutional-neural-networks-simplified-demystified/#comment-152388
 237. https://www.analyticsvidhya.com/blog/2017/06/architecture-of-convolutional-neural-networks-simplified-demystified/#comment-152388
 238. https://www.analyticsvidhya.com/blog/2017/06/architecture-of-convolutional-neural-networks-simplified-demystified/#comment-152481
 239. https://www.analyticsvidhya.com/blog/2017/06/architecture-of-convolutional-neural-networks-simplified-demystified/#comment-152481
 240. https://datahack.analyticsvidhya.com/user/profile/srk
 241. https://datahack.analyticsvidhya.com/user/profile/mark12
 242. https://datahack.analyticsvidhya.com/user/profile/nilabha
 243. https://datahack.analyticsvidhya.com/user/profile/nitish007
 244. https://datahack.analyticsvidhya.com/user/profile/tezdhar
 245. https://datahack.analyticsvidhya.com/top-competitor/?utm_source=blog-navbar&utm_medium=web
 246. https://www.analyticsvidhya.com/blog/2018/05/24-ultimate-data-science-projects-to-boost-your-knowledge-and-skills/
 247. https://www.analyticsvidhya.com/blog/2017/09/understaing-support-vector-machine-example-code/
 248. https://www.analyticsvidhya.com/blog/2017/09/common-machine-learning-algorithms/
 249. https://www.analyticsvidhya.com/blog/2016/01/complete-tutorial-learn-data-science-python-scratch-2/
 250. https://www.analyticsvidhya.com/blog/2015/08/comprehensive-guide-regression/
 251. https://www.analyticsvidhya.com/blog/2017/09/naive-bayes-explained/
 252. https://www.analyticsvidhya.com/blog/2018/01/anova-analysis-of-variance/
 253. https://www.analyticsvidhya.com/blog/2018/10/predicting-stock-price-machine-learningnd-deep-learning-techniques-python/
 254. https://www.analyticsvidhya.com/blog/2019/04/top-5-machine-learning-github-reddit/
 255. https://www.analyticsvidhya.com/blog/2019/04/top-5-machine-learning-github-reddit/
 256. https://www.analyticsvidhya.com/blog/2019/04/introduction-image-segmentation-techniques-python/
 257. https://www.analyticsvidhya.com/blog/2019/04/introduction-image-segmentation-techniques-python/
 258. https://www.analyticsvidhya.com/blog/2019/03/reinforcement-learning-temporal-difference-learning/
 259. https://www.analyticsvidhya.com/blog/2019/03/reinforcement-learning-temporal-difference-learning/
 260. https://www.analyticsvidhya.com/blog/2019/03/opencv-functions-computer-vision-python/
 261. https://www.analyticsvidhya.com/blog/2019/03/opencv-functions-computer-vision-python/
 262. https://datahack.analyticsvidhya.com/contest/ltfs-datascience-finhack-an-online-hackathon/?utm_source=sticky_banner1&utm_medium=display
 263. https://datahack.analyticsvidhya.com/contest/hikeathon/?utm_source=sticky_banner2&utm_medium=display
 264. http://www.analyticsvidhya.com/about-me/
 265. https://www.analyticsvidhya.com/about-me/team/
 266. https://www.analyticsvidhya.com/career-analytics-vidhya/
 267. https://www.analyticsvidhya.com/contact/
 268. https://www.analyticsvidhya.com/about-me/write/
 269. http://www.analyticsvidhya.com/about-me/
 270. https://www.analyticsvidhya.com/about-me/team/
 271. https://www.analyticsvidhya.com/about-me/team/
 272. https://www.analyticsvidhya.com/about-me/team/
 273. https://www.analyticsvidhya.com/career-analytics-vidhya/
 274. https://www.analyticsvidhya.com/about-me/team/
 275. https://www.analyticsvidhya.com/contact/
 276. https://www.analyticsvidhya.com/blog
 277. https://datahack.analyticsvidhya.com/
 278. https://discuss.analyticsvidhya.com/
 279. https://www.analyticsvidhya.com/jobs/
 280. https://datahack.analyticsvidhya.com/users/
 281. https://www.analyticsvidhya.com/corporate/
 282. https://trainings.analyticsvidhya.com/
 283. https://datahack.analyticsvidhya.com/
 284. https://www.analyticsvidhya.com/contact/
 285. https://www.analyticsvidhya.com/contact/
 286. https://datahack.analyticsvidhya.com/signup/
 287. https://www.facebook.com/analyticsvidhya/
 288. https://www.facebook.com/analyticsvidhya/
 289. https://twitter.com/analyticsvidhya
 290. https://twitter.com/analyticsvidhya
 291. https://plus.google.com/+analyticsvidhya
 292. https://in.linkedin.com/company/analytics-vidhya
 293. https://in.linkedin.com/company/analytics-vidhya
 294. https://www.analyticsvidhya.com/privacy-policy/
 295. https://www.analyticsvidhya.com/terms/
 296. https://www.analyticsvidhya.com/refund-policy/
 297. https://id.analyticsvidhya.com/accounts/signup/
 298. https://widgets.wp.com/likes/master.html?ver=201914#ver=201914
 299. https://id.analyticsvidhya.com/accounts/login/?next=https://www.analyticsvidhya.com/blog/&utm_source=blog-subscribe&utm_medium=web
 300. https://widgets.wp.com/likes/master.html?ver=201914#ver=201914
 301. https://id.analyticsvidhya.com/accounts/login/?next=https://www.analyticsvidhya.com/blog/&utm_source=blog-subscribe&utm_medium=web

   hidden links:
 303. https://www.facebook.com/analyticsvidhya
 304. https://twitter.com/analyticsvidhya
 305. https://plus.google.com/+analyticsvidhya/posts
 306. https://in.linkedin.com/company/analytics-vidhya
 307. https://datahack.analyticsvidhya.com/contest/practice-problem-identify-the-apparels/?utm_source=architecture-of-convolutional-neural-networks-simplified-demystified&utm_medium=blog
 308. https://datahack.analyticsvidhya.com/contest/practice-problem-identify-the-digits/?utm_source=architecture-of-convolutional-neural-networks-simplified-demystified&utm_medium=blog
 309. https://www.analyticsvidhya.com/blog/2017/07/30-questions-to-test-a-data-scientist-on-linear-regression/
 310. https://www.analyticsvidhya.com/blog/2017/06/big-data-architect-mumbai-7-years-of-experience/
 311. https://www.analyticsvidhya.com/blog/author/dishashree26/
 312. http://www.edvancer.in/certified-data-scientist-with-python-course?utm_source=av&utm_medium=avads&utm_campaign=avadsnonfc&utm_content=pythonavad
 313. https://www.facebook.com/analyticsvidhya/
 314. https://twitter.com/analyticsvidhya
 315. https://plus.google.com/+analyticsvidhya
 316. https://plus.google.com/+analyticsvidhya
 317. https://in.linkedin.com/company/analytics-vidhya
 318. https://www.addtoany.com/add_to/facebook?linkurl=https%3a%2f%2fwww.analyticsvidhya.com%2fblog%2f2017%2f06%2farchitecture-of-convolutional-neural-networks-simplified-demystified%2f&linkname=architecture%20of%20convolutional%20neural%20networks%20%28id98s%29%20demystified
 319. https://www.addtoany.com/add_to/twitter?linkurl=https%3a%2f%2fwww.analyticsvidhya.com%2fblog%2f2017%2f06%2farchitecture-of-convolutional-neural-networks-simplified-demystified%2f&linkname=architecture%20of%20convolutional%20neural%20networks%20%28id98s%29%20demystified
 320. https://www.addtoany.com/add_to/linkedin?linkurl=https%3a%2f%2fwww.analyticsvidhya.com%2fblog%2f2017%2f06%2farchitecture-of-convolutional-neural-networks-simplified-demystified%2f&linkname=architecture%20of%20convolutional%20neural%20networks%20%28id98s%29%20demystified
 321. https://www.addtoany.com/add_to/flipboard?linkurl=https%3a%2f%2fwww.analyticsvidhya.com%2fblog%2f2017%2f06%2farchitecture-of-convolutional-neural-networks-simplified-demystified%2f&linkname=architecture%20of%20convolutional%20neural%20networks%20%28id98s%29%20demystified
 322. https://www.addtoany.com/add_to/whatsapp?linkurl=https%3a%2f%2fwww.analyticsvidhya.com%2fblog%2f2017%2f06%2farchitecture-of-convolutional-neural-networks-simplified-demystified%2f&linkname=architecture%20of%20convolutional%20neural%20networks%20%28id98s%29%20demystified
 323. https://www.addtoany.com/add_to/facebook?linkurl=https%3a%2f%2fwww.analyticsvidhya.com%2fblog%2f2017%2f06%2farchitecture-of-convolutional-neural-networks-simplified-demystified%2f&linkname=architecture%20of%20convolutional%20neural%20networks%20%28id98s%29%20demystified
 324. https://www.addtoany.com/add_to/twitter?linkurl=https%3a%2f%2fwww.analyticsvidhya.com%2fblog%2f2017%2f06%2farchitecture-of-convolutional-neural-networks-simplified-demystified%2f&linkname=architecture%20of%20convolutional%20neural%20networks%20%28id98s%29%20demystified
 325. https://www.addtoany.com/add_to/linkedin?linkurl=https%3a%2f%2fwww.analyticsvidhya.com%2fblog%2f2017%2f06%2farchitecture-of-convolutional-neural-networks-simplified-demystified%2f&linkname=architecture%20of%20convolutional%20neural%20networks%20%28id98s%29%20demystified
 326. https://www.addtoany.com/add_to/flipboard?linkurl=https%3a%2f%2fwww.analyticsvidhya.com%2fblog%2f2017%2f06%2farchitecture-of-convolutional-neural-networks-simplified-demystified%2f&linkname=architecture%20of%20convolutional%20neural%20networks%20%28id98s%29%20demystified
 327. https://www.addtoany.com/add_to/whatsapp?linkurl=https%3a%2f%2fwww.analyticsvidhya.com%2fblog%2f2017%2f06%2farchitecture-of-convolutional-neural-networks-simplified-demystified%2f&linkname=architecture%20of%20convolutional%20neural%20networks%20%28id98s%29%20demystified
 328. javascript:void(0);
 329. javascript:void(0);
 330. https://www.addtoany.com/add_to/facebook?linkurl=https%3a%2f%2fwww.analyticsvidhya.com%2fblog%2f2017%2f06%2farchitecture-of-convolutional-neural-networks-simplified-demystified%2f&linkname=architecture%20of%20convolutional%20neural%20networks%20%28id98s%29%20demystified
 331. https://www.addtoany.com/add_to/twitter?linkurl=https%3a%2f%2fwww.analyticsvidhya.com%2fblog%2f2017%2f06%2farchitecture-of-convolutional-neural-networks-simplified-demystified%2f&linkname=architecture%20of%20convolutional%20neural%20networks%20%28id98s%29%20demystified
 332. https://www.addtoany.com/add_to/linkedin?linkurl=https%3a%2f%2fwww.analyticsvidhya.com%2fblog%2f2017%2f06%2farchitecture-of-convolutional-neural-networks-simplified-demystified%2f&linkname=architecture%20of%20convolutional%20neural%20networks%20%28id98s%29%20demystified
 333. https://www.addtoany.com/add_to/flipboard?linkurl=https%3a%2f%2fwww.analyticsvidhya.com%2fblog%2f2017%2f06%2farchitecture-of-convolutional-neural-networks-simplified-demystified%2f&linkname=architecture%20of%20convolutional%20neural%20networks%20%28id98s%29%20demystified
 334. https://www.addtoany.com/add_to/whatsapp?linkurl=https%3a%2f%2fwww.analyticsvidhya.com%2fblog%2f2017%2f06%2farchitecture-of-convolutional-neural-networks-simplified-demystified%2f&linkname=architecture%20of%20convolutional%20neural%20networks%20%28id98s%29%20demystified
 335. https://www.addtoany.com/add_to/facebook?linkurl=https%3a%2f%2fwww.analyticsvidhya.com%2fblog%2f2017%2f06%2farchitecture-of-convolutional-neural-networks-simplified-demystified%2f&linkname=architecture%20of%20convolutional%20neural%20networks%20%28id98s%29%20demystified
 336. https://www.addtoany.com/add_to/twitter?linkurl=https%3a%2f%2fwww.analyticsvidhya.com%2fblog%2f2017%2f06%2farchitecture-of-convolutional-neural-networks-simplified-demystified%2f&linkname=architecture%20of%20convolutional%20neural%20networks%20%28id98s%29%20demystified
 337. https://www.addtoany.com/add_to/linkedin?linkurl=https%3a%2f%2fwww.analyticsvidhya.com%2fblog%2f2017%2f06%2farchitecture-of-convolutional-neural-networks-simplified-demystified%2f&linkname=architecture%20of%20convolutional%20neural%20networks%20%28id98s%29%20demystified
 338. https://www.addtoany.com/add_to/flipboard?linkurl=https%3a%2f%2fwww.analyticsvidhya.com%2fblog%2f2017%2f06%2farchitecture-of-convolutional-neural-networks-simplified-demystified%2f&linkname=architecture%20of%20convolutional%20neural%20networks%20%28id98s%29%20demystified
 339. https://www.addtoany.com/add_to/whatsapp?linkurl=https%3a%2f%2fwww.analyticsvidhya.com%2fblog%2f2017%2f06%2farchitecture-of-convolutional-neural-networks-simplified-demystified%2f&linkname=architecture%20of%20convolutional%20neural%20networks%20%28id98s%29%20demystified
 340. javascript:void(0);
 341. javascript:void(0);
