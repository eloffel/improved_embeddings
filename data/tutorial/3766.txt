   #[1]github [2]recent commits to neural-style-transfer:master

   [3]skip to content

   (button)

     * why github?
       [4]features    
          + [5]code review
          + [6]project management
          + [7]integrations
          + [8]actions
          + [9]team management
          + [10]social coding
          + [11]documentation
          + [12]code hosting
          + [13]customer stories    
          + [14]security    
     * [15]enterprise
     * explore
          + [16]explore github    

learn & contribute
          + [17]topics
          + [18]collections
          + [19]trending
          + [20]learning lab
          + [21]open source guides

connect with others
          + [22]events
          + [23]community forum
          + [24]github education
     * [25]marketplace
     * pricing
       [26]plans    
          + [27]compare plans
          + [28]contact sales
          + [29]nonprofit    
          + [30]education    

   ____________________
     * in this repository all github    
       jump to    

     * no suggested jump to results

     * in this repository all github    
       jump to    
     * in this repository all github    
       jump to    

   [31]sign in [32]sign up

     * [33]watch [34]59
     * [35]star [36]1,392
     * [37]fork [38]284

[39]titu1994/[40]neural-style-transfer

   [41]code [42]issues 1 [43]pull requests 0 [44]projects 0 [45]insights
   (button) dismiss

join github today

   github is home to over 31 million developers working together to host
   and review code, manage projects, and build software together.
   [46]sign up
   keras implementation of neural style transfer from the paper "a neural
   algorithm of artistic style" ([47]http://arxiv.org/abs/1508.06576) in
   keras 2.0+
     * [48]289 commits
     * [49]1 branch
     * [50]33 releases
     * [51]fetching contributors
     * [52]apache-2.0

    1. [53]jupyter notebook 91.1%
    2. [54]python 8.9%

   (button) jupyter notebook python
   branch: master (button) new pull request
   [55]find file
   clone or download

clone with https

   use git or checkout with svn using the web url.
   https://github.com/t
   [56]download zip

downloading...

   want to be notified of new releases in titu1994/neural-style-transfer?
   [57]sign in [58]sign up

launching github desktop...

   if nothing happens, [59]download github desktop and try again.

   (button) go back

launching github desktop...

   if nothing happens, [60]download github desktop and try again.

   (button) go back

launching xcode...

   if nothing happens, [61]download xcode and try again.

   (button) go back

launching visual studio...

   if nothing happens, [62]download the github extension for visual studio
   and try again.

   (button) go back
   [63]@titu1994
   [64]titu1994 [65]merge pull request [66]#49 [67]from schneiderl/master
   (button)    
fixed typo at readme.md

   latest commit [68]536a96d oct 6, 2018
   [69]permalink
   type name latest commit message commit time
   failed to load latest commit information.
   [70].idea [71]fix "tuple index out of range" bug jun 24, 2017
   [72]images [73]update the masks may 29, 2018
   [74]script_helper [75]update script helper to fix the mono linux
   execution bug apr 20, 2018
   [76]guide.md
   [77]inetwork.py
   [78]licence
   [79]mrfnetwork.py [80]corrected support for python 2.7 oct 25, 2016
   [81]network.py
   [82]neuralstyletransfer.ipynb
   [83]readme.md
   [84]color_transfer.py
   [85]improved_neural_doodle.py [86]better support for python 2 jun 27,
   2017
   [87]mask_transfer.py
   [88]neural_doodle.py

readme.md

neural style transfer & neural doodles

   implementation of neural style transfer from the paper [89]a neural
   algorithm of artistic style in keras 2.0+

   inetwork implements and focuses on certain improvements suggested in
   [90]improving the neural algorithm of artistic style.

   color preservation is based on the paper [91]preserving color in neural
   artistic style transfer.

   masked style transfer is based on the paper [92]show, divide and
   neural: weighted style transfer

colaboratory support

   [93]this codebase can now be run directly from colaboratory using the
   following link, or by opening neuralstyletransfer.ipynb and visiting
   the colab link.

   colab link supports almost all of the additional arguments, except of
   the masking ones. they will probably be added at a later date.

   note : make sure you use a gpu in colab or else the notebook will fail.
   to change runtimes : runtime -> change runtime type ->. here select
   python 3 and gpu as the hardware accelerator.

guide

   see the [94]guide for details regarding how to use the script to
   achieve the best results

   it also explains how to setup theano (with gpu support) on both windows
   and linux. theano on windows is a long and tedious process, so the
   guide can speed up the process by simply letting you finish all the
   steps in the correct order, so as not to screw up the finicky theano +
   windows setup.

   the script helper program can be downloaded from the releases tab of
   this repository, [95]script helper releases. extract it into any folder
   and run the neural style transfer.exe program. on linux, you will need
   to install mono c# to run the script helper program.

examples

single style transfer

   [96]blue moon lake [97]starry night
   results after 100 iterations using the inetwork
   [98]blue moon lake style transfer
   deepart.io result (1000 iterations and using improvements such as
   markov random field id173)
   [99][deepart_blue_moon_lake.jpg]

style transfer with color preservation

   an example of color preservation with kinkaku-ji, a buddhist temple, as
   the content image and monet's "water lilies" as the art style:
   [100][kinkaku-ji.jpg?raw=true] [101][water-lilies-1919-2.jpg?raw=true]
   [102]kinkaku color preservation [103]kinkaku style transfer
   as an example, here are two images of the sagano bamboo forest with the
   "pattened-leaf" style, with and without color preservation
   [104][sagano_bamboo_forest.jpg?raw=true]
   [105][patterned_leaves.jpg?raw=true]
   [106]sagano bamboo forest style transfer color preservation [107]sagano
   bamboo forest style transfer

   color preservation can also be done using a mask. using the
   color_transfer.py script and supplying a mask image, in which white
   regions will allow the content's colors to be transfered and black
   regions will keep the style-generated colors.

   below, the content image is "sunlit mountain", with the style image as
   "seated nude" by picasso. notice that the color preservation mask
   ensures that color transfer occurs only for the sky region, while the
   mountains are untouched. [108][sunlit%20mountains.jpg?raw=true]
   [109][sunlit%20mountains%20color%20mask.jpg?raw=true]
   [110][seated-nude.jpg?raw=true]

   [111][sunlit-mountain.jpg?raw=true]
   [112][sunlit-mountain_color_preservation.jpg?raw=true]

style interpolation

   style weight and content weight can be manipulated to get drastically
   different results.

   leonid afremov's "misty mood" is the style image and "dipping sun" is
   the content image :
   [113][dipping-sun.jpg?raw=true]
   [114][misty-mood-leonid-afremov.jpg?raw=true]
       style=1, content=1000 style=1, content=1 style=1000, content=1
   [115][dippingsun3.jpg?raw=true] [116][dippingsun2.jpg?raw=true]
   [117][dippingsun1.jpg?raw=true]

multiple style transfer

   the next few images use the blue moon lake as a content image and
   vincent van gogh's "starry night" and georgia o'keeffe's "red canna" as
   the style images:
   [118][starry_night.jpg] [119][red-canna.jpg?raw=true]

   the below are the results after 50 iterations using 3 different style
   weights :

     starry night : 1.0, red canna 0.2 starry night : 1.0, red canna 0.4
                      starry night : 1.0, red canna 1.0
                  [120][blue_moon_lake_1-0_2.jpg?raw=true]
                  [121][blue_moon_lake_1-0_4.jpg?raw=true]
           [122][blue_moon_lake_1-1_at_iteration_50.jpg?raw=true]

masked style transfer

   supplying an additional binary mask for each style, we can apply the
   style to a selected region and preserve the content in other regions.we
   can also use multiple masks to apply 2 different styles in 2 different
   regions of the same content image.

   note that with the mask_transfer.py script, a single content image can
   be masked with 1 mask to preserve content in blackend regions and
   preserve style transfer in whitened regions in the generated image.
   currently, only content can be transfered in a post processed manner.

   "the starry night" is used as the style image in the below images. the
   mask tries to preserve the woman's shape and color, while applying the
   style to all other regions. results are very good, as "the starry
   night" has a tendency to overpower the content shape and color.
   [123]dawn sky anime [124][starry_night.jpg]

   [125][dawn-sky-mask.jpg?raw=true] [126]dawn sky style transfer anime
   another example of masked style transfer is provided below. "winter
   wolf" is used as the content image and "bamboo forest" is used as the
   style image. the mask attempts to preserve the darkened cloudy sky, and
   apply the style only to the mountains and the wolf itself.

   [127][winter-wolf.jpg?raw=true] [128][bamboo_forest.jpg?raw=true]

   [129][winter-wolf-mask.jpg?raw=true] [130]winter wolf style transfer
   these last few images use "cherry blossoms" as the content image, and
   uses two styles : "candy style" and monet's "water lillies" using their
   respective masks to create an image with unique results.

   [131][candy-style.jpg?raw=true] [132][water-lilies-1919-2.jpg?raw=true]
   [133][japanese-cherry-widescreen-wallpaper-picture-1366x768.jpg?raw=tru
   e]

   [134][cherry-blossom-1.jpg?raw=true]
   [135][cherry-blossom-2.jpg?raw=true]
   [136][cherry-blossoms.jpg?raw=true]

silhouette transfer

   using masked transfer, one can post process image silhouettes to
   generate from scratch artwork that is sharp, clear and manipulates the
   style to conform to the shape of the silhouette itself.

   first we discuss the use of a silhouette of the content vs the content
   image itself. a silhouette offers a chance to generate new artwork in
   the artistic vein of the style, while conforming only to the shape of
   the content, and disregarding the content itself. combined with post
   process masking, it is easy to generate artwork similar to the style
   image itself.

   for this image, starry night was used as the style image.

                           content mask generated
              [137][fai%20d%20flowrite%20-%20ring.jpg?raw=true]
         [138][fai%20d%20flowrite%20-%20ring%20-%20inv.jpg?raw=true]
                      [139][fai-silhuete.jpg?raw=true]

   for this example, we use "blue strokes" as the style image

                                content                  style
               [140][sakura%20no%20tsubasa.png?raw=true]
                     [141][blue%20strokes.jpg?raw=true]
                  [142][wings-silhuete.jpg?raw=true]
                   [143][wings-silhuete%202.jpg?raw=true]

texture transfer

   utilizing a style image with a very distinctive texture, we can apply
   this texture to the content without any alterating in the algorithm. it
   is to be noted that the style image must possess a very strong texture
   to transfer correctly.

   the below is an example of the content image "aurea luna", with the
   texture images which are available in the /style/metals directory,
   which are silver and gold. color preservation is applied to both
   images, and a mask is applied on the "burnt gold" image to style just
   the circle and not the entire square image.

   [144]aurea luna golden moon clow reed [145][silver_plate.jpg?raw=true]
   [146][burnt_gold.jpg?raw=true]

   [147]molten silver moon [148]burnt gold moon

all transfer techniques

   each of these techniques can be used together, or in stages to generate
   stunning images.

   in the folowing image, i have used masked style transfer in a multi
   scale style transfer technique - with scales of 192x192, 384x384,
   768x768, applied a super resolution algorithm (4x and then downscaled
   to 1920x1080), applied color transfer and mask transfer again to
   sharpen the edges, used a simple sharpening algorithm and then finally
   denoise algorithm.

   [149]ancient city japanese [150][blue_swirls.jpg?raw=true]
   [151][ancient-city.jpg?raw=true]

   result :
   [152]ancient city japanese

various results with / without color preservation

   example of various styles (with and without color preservation). images
   of the "lost grounds" from .hack g.u.
   [153][lost-grounds.jpg?raw=true]

neural doodle examples

   renoit style + content image
   [154][renoit_new.png?raw=true]
   monet style + doodle creation
   [155][monet_new.png?raw=true]
   van gogh + doodle creation
   [156][van%20gogh.png?raw=true]

weights (vgg 16)

   weights are now automatically downloaded and cached in the ~/.keras
   (users//.keras for windows) folder under the 'models' subdirectory. the
   weights are a smaller version which include only the convolutional
   layers without zero padding layers, thereby increasing the speed of
   execution.

   note: requires the latest version of keras (1.0.7+) due to use of new
   methods to get files and cache them into .keras directory.

modifications to original implementation :

     * uses 'conv5_2' output to measure content loss. original paper
       utilizes 'conv4_2' output
     * initial image used for image is the base image (instead of random
       noise image) this method tends to create better output images,
       however parameters have to be well tuned. therefore their is a
       argument 'init_image' which can take the options 'content' or
       'noise'
     * can use averagepooling2d inplace of maxpooling2d layers the
       original paper uses averagepooling for better results, but this can
       be changed to use maxpooling2d layers via the argument
       --pool_type="max". by default maxpooling is used, since if offers
       sharper images, but averagepooling applies the style better in some
       cases (especially when style image is the "starry night" by van
       gogh).
     * style weight scaling
     * rescaling of image to original dimensions, using lossy upscaling
       present
     * maintain aspect ratio of intermediate and final stage images, using
       lossy upscaling

improvements in inetwork

     * improvement 3.1 in paper : geometric layer weight adjustment for
       style id136
     * improvement 3.2 in paper : using all layers of vgg-16 for style
       id136
     * improvement 3.3 in paper : activation shift of gram matrix
     * improvement 3.5 in paper : correlation chain

   these improvements are almost same as the chain blurred version,
   however a few differences exist :
     * blurring of gram matrix g is not used, as in the paper the author
       concludes that the results are often not major, and convergence
       speed is greatly diminished due to very complex gradients.
     * only one layer for content id136 instead of using all the
       layers as suggested in the chain blurred version.
     * does not use id98 mrf network, but applies these modifications to
       the original algorithm.
     * all of this is applied on the vgg-16 network, not on the vgg-19
       network. it is trivial to extrapolate this to the vgg-19 network.
       simply adding the layer names to the feature_layers list will be
       sufficient to apply these changes to the vgg-19 network.

script helper

   it is a c# program written to more easily generate the arguments for
   the python script network.py or inetwork.py (using neural style
   transfer tab) and neural_doodle.py or improved_neural_doodle.py script
   (using neural doodle tab)

   [157][neural%20art%20windows.jpg?raw=true]
     * upon first run, it will request the python path. traverse your
       directory to locate the python.exe of your choice (anaconda is
       tested)
     * the script helper program code is available at:
       [158]https://github.com/titu1994/neural-style-transfer-windows the
       program runs on linux using mono

benefits

     * allows style transfer, neural doodles, color transfer and masked
       style transfer easily
     * automatically executes the script based on the arguments.
     * easy selection of images (content, style (multiple selection
       allowed), output prefix)
     * easy parameter selection
     * easily generate argument list, if command line execution is
       preferred.
     * creates log folders for each execution so settings can be preserved
     * runs on windows (native) and linux (using mono)

   to use multiple style images, when the image choice window opens,
   select all style images as needed. pass multiple style weights by using
   a space between each style weight in the parameters section.

usage

neural style transfer

   both network.py and inetwork.py have similar usage styles, and share
   all parameters.

   network.py / inetwork.py
python network.py/inetwork.py "/path/to/content image" "path/to/style image" "re
sult prefix or /path/to/result prefix"

   to pass multiple style images, after passing the content image path,
   seperate each style path with a space
python inetwork.py "/path/to/content image" "path/to/style image 1" "path/to/sty
le image 2" ... "result prefix or /path/to/result prefix" --style_weight 1.0 1.0
 ...

   there are various parameters discussed below which can be modified to
   alter the output image. note that many parameters require the command
   to be enclosed in double quotes ( " " ).

   example:
python inetwork.py "/path/to/content image" "path/to/style image" "result prefix
 or /path/to/result prefix" --preserve_color "true" --pool_type "ave" --rescale_
method "bicubic" --content_layer "conv4_2"

   to perform color preservation on an already generated image, use the
   color_transform.py as below. it will save the image in the same folder
   as the generated image with "_original_color" suffix.
python color_transfer.py "path/to/content/image" "path/to/generated/image"

   a mask can also be supplied to color preservation script, using the
   --mask argument, where the white region signifies that color
   preservation should be done there, and black regions signify the color
   should not be preserved here.
python color_transfer.py "path/to/content/image" "path/to/generated/image" --mas
k "/path/to/mask/image"

   a note on mask images:
     * they should be binary images (only black and white)
     * white represents parts of the image that you want style transfer to
       occur
     * black represents parts of the image that you want to preserve the
       content
     * be careful of the order in which mask images are presented in multi
       style multi mask generation. they have a 1 : 1 mapping between
       style images and style masks.
     * when using the script helper program, it may happen that the masks
       are being ordered incorrectly due to name-wise sorting. therefore,
       rename the masks in alphabetic order to correct this flaw.

   as a general example, here is the list of parameters to generate a
   multi style multi mask image:
python network.py "japanese-cherry-widescreen-wallpaper-picture-1366x768.jpg" "c
andy-style.jpg" "water-lilies-1919-2.jpg" \
"cherry blossom" --style_masks "cherry-blossom-1.jpg" "cherry-blossom-2.jpg" --c
ontent_weight 5 --style_weight 1.0 1.0 \
--num_iter 20 --model "vgg16" --content_loss_type 0

   like color transfer, single mask style transfer can also be applied as
   a post processing step instead of directly doing so in the style
   transfer script. you can preserve some portion of the content image in
   the generated image using the post processing script mask_transfer.py.

   example:
python mask_transfer.py "path/to/content/image" "path/to/generated/image" "path/
to/content/mask"

neural doodles

   both the neural_doodle.py and improved_neural_doodle.py script share
   similar usage styles.

   neural_doodle.py & improved_neural_doodle.py
python neural_doodle.py --nlabels -style-image --style-mask --target-mask --cont
ent-image --target-image-prefix

   example 1 : doodle using a style image, style mask and target mask
   (from keras examples)
python neural_doodle.py --nlabels 4 --style-image monet/style.png \
    --style-mask monet/style_mask.png --target-mask monet/target_mask.png \
    --target-image-prefix generated/monet

   example 2: doodle using a style image, style mask, target mask and an
   optional content image.
 python neural_doodle.py --nlabels 4 --style-image renoir/style.png \
    --style-mask renoir/style_mask.png --target-mask renoir/target_mask.png \
    --content-image renoir/creek.jpg \
    --target-image-prefix generated/renoir

   multiple phases example : doodle using a style image, style mask,
   target mask and using it multiple times to acheive better results.
     * assume that an image has a size (400 x 600).
     * divide the image size by 4 (100 x 125)
     * create 1st doodle according to the below script #1 (--img_size 100)
     * create 2nd doodle according to the below script #2 (note that we
       pass 1st doodle as content image here) (--img_size 200)
     * create 3rd and last doodle acc to below script #3 (note we pass 2nd
       doodle as content image here) (do not put img_size parameter)

# script 1
python improved_neural_doodle.py --nlabels 4 --style-image srcl.jpg --style-mask
 srcl-m.png --target-mask dst-m.png  --target-image-prefix ./doodle3-100 --num_i
ter 50 --img_size 100 --min_improvement 5.0

# script 2
python improved_neural_doodle.py --nlabels 4 --style-image srcl.jpg --style-mask
 srcl-m.png --target-mask dst-m.png  --target-image-prefix ./doodle3-200 --num_i
ter 50 --content-image ./doodle3-100_at_iteration_xxxx.png --img_size 200 --min_
improvement 2.5

############# replace xxxx by last iteration number ################

# script 3
python improved_neural_doodle.py --nlabels 4 --style-image srcl.jpg --style-mask
 srcl-m.png --target-mask dst-m.png  --target-image-prefix ./doodle3-500 --num_i
ter 50 --content-image ./doodle3-200_at_iteration_xxxx.png

############# replace xxxx by last iteration number ################

color transfer (post processing)

   color transfer can be performed after the stylized image has already
   been generated. this can be done via the color_transfer.py script or
   via the color transfer tab in the script helper. note that the script
   will save the image in the same folder as the generated image with
   "_original_color" suffix.

   example:
python color_transfer.py "path/to/content/image" "path/to/generated/image"

   a mask can also be supplied to color preservation script, using the
   --mask argument, where the white region signifies that color
   preservation should be done there, and black regions signify the color
   should not be preserved here.
python color_transfer.py "path/to/content/image" "path/to/generated/image" --mas
k "/path/to/mask/image"

   using the --hist_match parameter set to 1, it will perform histogram
   color matching instead of direct color transfer
python color_transfer.py "path/to/content/image" "path/to/generated/image" --his
t_match 1

   please note that for masks for color preservation and for style
   transfer have different representations. color preservations will
   preserve white areas as content colors, and mask transfer will preserve
   black areas as content image.

masked style transfer (post processing)

   if the general requirement is to preserve some portions of the content
   in the stylized image, then it can simply be done as a post processing
   step using the mask_transfer.py script or the mask transfer tab of the
   script helper.

   for now, only the content can be preserved (by coloring the area black
   in the mask). to perform multi style multi mask style transfer, you
   must supply the styles and masks to the neural style script and let it
   run for several iterations. this cannot be done as a post processing
   step.

   example:
python mask_transfer.py "path/to/content/image" "path/to/generated/image" "path/
to/content/mask"

parameters (neural style)

--style_masks : multiple style masks may be provided for masking certain regions
 of an image for style transfer. number of
  style_weight parameters must match number of style masks.
--color_mask : a single color mask, which defines the region where the color mus
t be preserved.

--image_size : allows to set the gram matrix size. default is 400 x 400, since i
t produces good results fast.
--num_iter : number of iterations. default is 10. test the output with 10 iterat
ions, and increase to improve results.
--init_image : can be "content", "noise" or "gray". default is "content", since
it reduces reproduction noise. "gray" is useful when you want only the color of
the style to be used in the image.
--pool_type : pooling type. maxpooling ("max") is default. for smoother images,
use averagepooling ("ave").

--model : can be "vgg16" or "vgg19". changes between use of vgg 16 or vgg 19 mod
el.
--content_loss_type : can be 0, 1 or 2.
                      0 does not add any scaling of the loss.
                      1 = 1 / (2 * sqrt(channels) * sqrt(width * height))
                      2 = 1 / (channels * width * height)
--preserve_color : preserves the original color space of the content image, whil
e applying only style. post processing technique on final image, therefore does
not harm quality of style.
--min_improvement : sets the minimum improvement required to continue training.
default is 0.0, indicating no minimum threshold. advised values are 0.05 or 0.01

--content_weight : weightage given to content in relation to style. default if 0
.025
--style_weight : weightage given to style. default is 1. when using multiple sty
les, seperate each style weight with a space
--style_scale : scales the style_weight. default is 1.
--total_variation_weight : id173 factor. smaller values tend to produce
 crisp images, but 0 is not useful. default = 8.5e-5

--rescale_image : rescale image to original dimensions after each iteration. (bi
linear upscaling)
--rescale_method : rescaling algorithm. default is bilinear. options are nearest
, bilinear, bicubic and cubic.
--maintain_aspect_ratio : rescale the image just to the original aspect ratio. s
ize will be (gram_matrix_size, gram_matrix_size * aspect_ratio). default is true
--content_layer : selects the content layer. paper suggests conv4_2, but better
results can be obtained from conv5_2. default is conv5_2.

parameters (neural doodle)

--nlabels : number of colors or labels in mask image
--image_size : allows to set the gram matrix size. default is -1, which means th
at it uses style image size automatically.
--num_iter : number of iterations. default is 10. test the output with 10 iterat
ions, and increase to improve results.
--preserve_color : preserves the original color space of the content image, whil
e applying only style. post processing technique on final image, therefore does
not harm quality of style. works only when using content image for guided style
transfer
--min_improvement : minimum improvement in percentage required to continue train
ing. set to 0.0 to disable.

--content_weight : weightage given to content in relation to style. default if 0
.1
--style_weight : weightage given to style in relation to content. default is 1.
--total_variation_weight : id173 factor. smaller values tend to produce
 crisp images, but 0 is not useful. default = 8.5e-5
--region_style_weight : weight for region style id173. keep it set to 1
.0 unless testing for experimental purposes.

parameters (color transfer)

--masks : optional, performs masked color transfer
--hist_match : performs histogram color matching if set to 1. default is 0.

network.py in action

   [159]alt text

requirements

     * theano / tensorflow
     * keras
     * cuda (gpu) -- recommended
     * cudnn (gpu) -- recommended
     * scipy + pil
     * numpy
     * h5py

speed

   on a 980m gpu, the time required for each epoch depends on mainly image
   size (gram matrix size) :

   for a 400x400 gram matrix, each epoch takes approximately 8-10 seconds.
   for a 512x512 gram matrix, each epoch takes approximately 15-18
   seconds.
   for a 600x600 gram matrix, each epoch takes approximately 24-28
   seconds.

   for masked style transfer, the speed is now same as if using no mask.
   this was acheived by preventing gradient computation of the mask
   multiplied with the style and content features.

   for multiple style transfer, inetwork.py requires slightly more time
   (~2x single style transfer as shown above for 2 styles, ~3x for 3
   styles and so on). results are better with inetwork.py in multiple
   style transfer.

   for multi style multi mask style transfer, the speed is now same as if
   using multiple styles only. it was acheived by preventing gradient
   computation of the mask multiplied with the style and content features.
     * for multi style multi mask network, network.py requires roughly 24
       (previously 72) seconds per iteration, whereas inetwork.py requires
       87 (previously 248) seconds per iteration

issues

     * due to usage of content image as initial image, output depends
       heavily on parameter tuning.
       test to see if the image is appropriate in the first 10 epochs, and
       if it is correct, increase the number of iterations to smoothen and
       improve the quality of the output.
     * due to small gram sizes, the output image is usually small.
       to correct this, use the implementations of this paper "image
       super-resolution using deep convolutional networks"
       [160]http://arxiv.org/abs/1501.00092 to upscale the images with
       minimal loss.
       some implementations of the above paper for windows :
       [161]https://github.com/lltcggie/waifu2x-caffe/releases
       (download the waifu2x-caffe.zip and extract, program supports
       english)
     * implementation of markov random field id173 and patch
       match algorithm are currently being tested. mrfnetwork.py contains
       the basic code, which need to be integrated to use mrf and patch
       match as in image analogies paper [162]combining markov random
       fields and convolutional neural networks for image synthesis

     *    2019 github, inc.
     * [163]terms
     * [164]privacy
     * [165]security
     * [166]status
     * [167]help

     * [168]contact github
     * [169]pricing
     * [170]api
     * [171]training
     * [172]blog
     * [173]about

   (button) you can   t perform that action at this time.

   you signed in with another tab or window. [174]reload to refresh your
   session. you signed out in another tab or window. [175]reload to
   refresh your session.

   (button)

references

   visible links
   1. https://github.com/opensearch.xml
   2. https://github.com/titu1994/neural-style-transfer/commits/master.atom
   3. https://github.com/titu1994/neural-style-transfer#start-of-content
   4. https://github.com/features
   5. https://github.com/features/code-review/
   6. https://github.com/features/project-management/
   7. https://github.com/features/integrations
   8. https://github.com/features/actions
   9. https://github.com/features#team-management
  10. https://github.com/features#social-coding
  11. https://github.com/features#documentation
  12. https://github.com/features#code-hosting
  13. https://github.com/customer-stories
  14. https://github.com/security
  15. https://github.com/enterprise
  16. https://github.com/explore
  17. https://github.com/topics
  18. https://github.com/collections
  19. https://github.com/trending
  20. https://lab.github.com/
  21. https://opensource.guide/
  22. https://github.com/events
  23. https://github.community/
  24. https://education.github.com/
  25. https://github.com/marketplace
  26. https://github.com/pricing
  27. https://github.com/pricing#feature-comparison
  28. https://enterprise.github.com/contact
  29. https://github.com/nonprofit
  30. https://education.github.com/
  31. https://github.com/login?return_to=/titu1994/neural-style-transfer
  32. https://github.com/join
  33. https://github.com/login?return_to=/titu1994/neural-style-transfer
  34. https://github.com/titu1994/neural-style-transfer/watchers
  35. https://github.com/login?return_to=/titu1994/neural-style-transfer
  36. https://github.com/titu1994/neural-style-transfer/stargazers
  37. https://github.com/login?return_to=/titu1994/neural-style-transfer
  38. https://github.com/titu1994/neural-style-transfer/network/members
  39. https://github.com/titu1994
  40. https://github.com/titu1994/neural-style-transfer
  41. https://github.com/titu1994/neural-style-transfer
  42. https://github.com/titu1994/neural-style-transfer/issues
  43. https://github.com/titu1994/neural-style-transfer/pulls
  44. https://github.com/titu1994/neural-style-transfer/projects
  45. https://github.com/titu1994/neural-style-transfer/pulse
  46. https://github.com/join?source=prompt-code
  47. http://arxiv.org/abs/1508.06576
  48. https://github.com/titu1994/neural-style-transfer/commits/master
  49. https://github.com/titu1994/neural-style-transfer/branches
  50. https://github.com/titu1994/neural-style-transfer/releases
  51. https://github.com/titu1994/neural-style-transfer/graphs/contributors
  52. https://github.com/titu1994/neural-style-transfer/blob/master/licence
  53. https://github.com/titu1994/neural-style-transfer/search?l=jupyter-notebook
  54. https://github.com/titu1994/neural-style-transfer/search?l=python
  55. https://github.com/titu1994/neural-style-transfer/find/master
  56. https://github.com/titu1994/neural-style-transfer/archive/master.zip
  57. https://github.com/login?return_to=https://github.com/titu1994/neural-style-transfer
  58. https://github.com/join?return_to=/titu1994/neural-style-transfer
  59. https://desktop.github.com/
  60. https://desktop.github.com/
  61. https://developer.apple.com/xcode/
  62. https://visualstudio.github.com/
  63. https://github.com/titu1994
  64. https://github.com/titu1994/neural-style-transfer/commits?author=titu1994
  65. https://github.com/titu1994/neural-style-transfer/commit/536a96df79dc6c155eb84ded3bd71cdd21553d1e
  66. https://github.com/titu1994/neural-style-transfer/pull/49
  67. https://github.com/titu1994/neural-style-transfer/commit/536a96df79dc6c155eb84ded3bd71cdd21553d1e
  68. https://github.com/titu1994/neural-style-transfer/commit/536a96df79dc6c155eb84ded3bd71cdd21553d1e
  69. https://github.com/titu1994/neural-style-transfer/tree/536a96df79dc6c155eb84ded3bd71cdd21553d1e
  70. https://github.com/titu1994/neural-style-transfer/tree/master/.idea
  71. https://github.com/titu1994/neural-style-transfer/commit/6a27fc3b53b98f5767ba18f6b375e54d57cf274d
  72. https://github.com/titu1994/neural-style-transfer/tree/master/images
  73. https://github.com/titu1994/neural-style-transfer/commit/193ea80033d66f65194ac08995c641cde757f38a
  74. https://github.com/titu1994/neural-style-transfer/tree/master/script_helper
  75. https://github.com/titu1994/neural-style-transfer/commit/bc5ec8b8889cf71935b3caffa80d1cb2f99c5526
  76. https://github.com/titu1994/neural-style-transfer/blob/master/guide.md
  77. https://github.com/titu1994/neural-style-transfer/blob/master/inetwork.py
  78. https://github.com/titu1994/neural-style-transfer/blob/master/licence
  79. https://github.com/titu1994/neural-style-transfer/blob/master/mrfnetwork.py
  80. https://github.com/titu1994/neural-style-transfer/commit/c61fe5306be1251b131cb1da6fdf620931562d22
  81. https://github.com/titu1994/neural-style-transfer/blob/master/network.py
  82. https://github.com/titu1994/neural-style-transfer/blob/master/neuralstyletransfer.ipynb
  83. https://github.com/titu1994/neural-style-transfer/blob/master/readme.md
  84. https://github.com/titu1994/neural-style-transfer/blob/master/color_transfer.py
  85. https://github.com/titu1994/neural-style-transfer/blob/master/improved_neural_doodle.py
  86. https://github.com/titu1994/neural-style-transfer/commit/98c688f0e1f7530a63ce50611c405aa7d2aa068f
  87. https://github.com/titu1994/neural-style-transfer/blob/master/mask_transfer.py
  88. https://github.com/titu1994/neural-style-transfer/blob/master/neural_doodle.py
  89. http://arxiv.org/abs/1508.06576
  90. http://arxiv.org/abs/1605.04603
  91. https://arxiv.org/abs/1606.05897
  92. http://cs231n.stanford.edu/reports/2016/pdfs/208_report.pdf
  93. https://colab.research.google.com/github/titu1994/neural-style-transfer/blob/master/neuralstyletransfer.ipynb
  94. https://github.com/titu1994/neural-style-transfer/blob/master/guide.md
  95. https://github.com/titu1994/neural-style-transfer/releases
  96. https://raw.githubusercontent.com/titu1994/neural_style_transfer/master/images/inputs/content/blue-moon-lake.jpg
  97. https://raw.githubusercontent.com/titu1994/neural_style_transfer/master/images/inputs/style/starry_night.jpg
  98. https://github.com/titu1994/neural-style-transfer/blob/master/images/output/blue-moon-lake_at_iteration_100.jpg?raw=true
  99. https://raw.githubusercontent.com/titu1994/neural_style_transfer/master/images/output/deepart_blue_moon_lake.jpg
 100. https://github.com/titu1994/neural-style-transfer/blob/master/images/inputs/content/kinkaku-ji.jpg?raw=true
 101. https://github.com/titu1994/neural-style-transfer/blob/master/images/inputs/style/water-lilies-1919-2.jpg?raw=true
 102. https://github.com/titu1994/neural-style-transfer/blob/master/images/output/jukai_color_preservation.jpg?raw=true
 103. https://github.com/titu1994/neural-style-transfer/blob/master/images/output/jukai.jpg?raw=true
 104. https://github.com/titu1994/neural-style-transfer/blob/master/images/inputs/content/sagano_bamboo_forest.jpg?raw=true
 105. https://github.com/titu1994/neural-style-transfer/blob/master/images/inputs/style/patterned_leaves.jpg?raw=true
 106. https://github.com/titu1994/neural-style-transfer/blob/master/images/output/bamboo-fores.jpg?raw=true
 107. https://github.com/titu1994/neural-style-transfer/blob/master/images/output/bamboo-forest-no-color-preservation.jpg?raw=true
 108. https://github.com/titu1994/neural-style-transfer/blob/master/images/inputs/content/sunlit mountains.jpg?raw=true
 109. https://github.com/titu1994/neural-style-transfer/blob/master/images/inputs/mask/sunlit mountains color mask.jpg?raw=true
 110. https://github.com/titu1994/neural-style-transfer/blob/master/images/inputs/style/seated-nude.jpg?raw=true
 111. https://github.com/titu1994/neural-style-transfer/blob/master/images/output/sunlit-mountain.jpg?raw=true
 112. https://github.com/titu1994/neural-style-transfer/blob/master/images/output/sunlit-mountain_color_preservation.jpg?raw=true
 113. https://github.com/titu1994/neural-style-transfer/blob/master/images/inputs/content/dipping-sun.jpg?raw=true
 114. https://github.com/titu1994/neural-style-transfer/blob/master/images/inputs/style/misty-mood-leonid-afremov.jpg?raw=true
 115. https://github.com/titu1994/neural-style-transfer/blob/master/images/output/dippingsun3.jpg?raw=true
 116. https://github.com/titu1994/neural-style-transfer/blob/master/images/output/dippingsun2.jpg?raw=true
 117. https://github.com/titu1994/neural-style-transfer/blob/master/images/output/dippingsun1.jpg?raw=true
 118. https://raw.githubusercontent.com/titu1994/neural_style_transfer/master/images/inputs/style/starry_night.jpg
 119. https://github.com/titu1994/neural-style-transfer/blob/master/images/inputs/style/red-canna.jpg?raw=true
 120. https://github.com/titu1994/neural-style-transfer/blob/master/images/output/blue_moon_lake_1-0_2.jpg?raw=true
 121. https://github.com/titu1994/neural-style-transfer/blob/master/images/output/blue_moon_lake_1-0_4.jpg?raw=true
 122. https://github.com/titu1994/neural-style-transfer/blob/master/images/output/blue_moon_lake_1-1_at_iteration_50.jpg?raw=true
 123. https://github.com/titu1994/neural-style-transfer/blob/master/images/inputs/content/dawn sky.jpg?raw=true
 124. https://raw.githubusercontent.com/titu1994/neural_style_transfer/master/images/inputs/style/starry_night.jpg
 125. https://github.com/titu1994/neural-style-transfer/blob/master/images/inputs/mask/dawn-sky-mask.jpg?raw=true
 126. https://github.com/titu1994/neural-style-transfer/blob/master/images/output/dawn_sky_masked.jpg?raw=true
 127. https://github.com/titu1994/neural-style-transfer/blob/master/images/inputs/content/winter-wolf.jpg?raw=true
 128. https://github.com/titu1994/neural-style-transfer/blob/master/images/inputs/style/bamboo_forest.jpg?raw=true
 129. https://github.com/titu1994/neural-style-transfer/blob/master/images/inputs/mask/winter-wolf-mask.jpg?raw=true
 130. https://github.com/titu1994/neural-style-transfer/blob/master/images/output/winterwolf-masked.jpg?raw=true
 131. https://github.com/titu1994/neural-style-transfer/blob/master/images/inputs/style/candy-style.jpg?raw=true
 132. https://github.com/titu1994/neural-style-transfer/blob/master/images/inputs/style/water-lilies-1919-2.jpg?raw=true
 133. https://github.com/titu1994/neural-style-transfer/blob/master/images/inputs/content/japanese-cherry-widescreen-wallpaper-picture-1366x768.jpg?raw=true
 134. https://github.com/titu1994/neural-style-transfer/blob/master/images/inputs/mask/cherry-blossom-1.jpg?raw=true
 135. https://github.com/titu1994/neural-style-transfer/blob/master/images/inputs/mask/cherry-blossom-2.jpg?raw=true
 136. https://github.com/titu1994/neural-style-transfer/blob/master/images/output/cherry-blossoms.jpg?raw=true
 137. https://github.com/titu1994/neural-style-transfer/blob/master/images/inputs/mask/fai d flowrite - ring.jpg?raw=true
 138. https://github.com/titu1994/neural-style-transfer/blob/master/images/inputs/mask/fai d flowrite - ring - inv.jpg?raw=true
 139. https://github.com/titu1994/neural-style-transfer/blob/master/images/output/fai-silhuete.jpg?raw=true
 140. https://github.com/titu1994/neural-style-transfer/blob/master/images/inputs/mask/sakura no tsubasa.png?raw=true
 141. https://github.com/titu1994/neural-style-transfer/blob/master/images/inputs/style/blue strokes.jpg?raw=true
 142. https://github.com/titu1994/neural-style-transfer/blob/master/images/output/wings-silhuete.jpg?raw=true
 143. https://github.com/titu1994/neural-style-transfer/blob/master/images/output/wings-silhuete 2.jpg?raw=true
 144. https://github.com/titu1994/neural-style-transfer/blob/master/images/inputs/content/aurea-luna.jpg?raw=true
 145. https://github.com/titu1994/neural-style-transfer/blob/master/images/inputs/style/metals/silver_plate.jpg?raw=true
 146. https://github.com/titu1994/neural-style-transfer/blob/master/images/inputs/style/metals/burnt_gold.jpg?raw=true
 147. https://github.com/titu1994/neural-style-transfer/blob/master/images/output/molten-silver.jpg?raw=true
 148. https://github.com/titu1994/neural-style-transfer/blob/master/images/output/burnt-gold.jpg?raw=true
 149. https://github.com/titu1994/neural-style-transfer/blob/master/images/inputs/content/ancient_city.jpg?raw=true
 150. https://github.com/titu1994/neural-style-transfer/blob/master/images/inputs/style/blue_swirls.jpg?raw=true
 151. https://github.com/titu1994/neural-style-transfer/blob/master/images/inputs/mask/ancient-city.jpg?raw=true
 152. https://github.com/titu1994/neural-style-transfer/blob/master/images/output/ancient_city_multiscale.jpg?raw=true
 153. https://github.com/titu1994/neural-style-transfer/blob/master/images/output/lost-grounds.jpg?raw=true
 154. https://github.com/titu1994/neural-style-transfer/blob/master/images/neural_doodle/generated/renoit_new.png?raw=true
 155. https://github.com/titu1994/neural-style-transfer/blob/master/images/neural_doodle/generated/monet_new.png?raw=true
 156. https://github.com/titu1994/neural-style-transfer/blob/master/images/neural_doodle/generated/van gogh.png?raw=true
 157. https://github.com/titu1994/neural-style-transfer/blob/master/images/neural art windows.jpg?raw=true
 158. https://github.com/titu1994/neural-style-transfer-windows
 159. https://raw.githubusercontent.com/titu1994/neural-style-transfer/master/images/blue moon lake.gif
 160. http://arxiv.org/abs/1501.00092
 161. https://github.com/lltcggie/waifu2x-caffe/releases
 162. http://arxiv.org/abs/1601.04589
 163. https://github.com/site/terms
 164. https://github.com/site/privacy
 165. https://github.com/security
 166. https://githubstatus.com/
 167. https://help.github.com/
 168. https://github.com/contact
 169. https://github.com/pricing
 170. https://developer.github.com/
 171. https://training.github.com/
 172. https://github.blog/
 173. https://github.com/about
 174. https://github.com/titu1994/neural-style-transfer
 175. https://github.com/titu1994/neural-style-transfer

   hidden links:
 177. https://github.com/
 178. https://github.com/titu1994/neural-style-transfer
 179. https://github.com/titu1994/neural-style-transfer
 180. https://github.com/titu1994/neural-style-transfer
 181. https://help.github.com/articles/which-remote-url-should-i-use
 182. https://github.com/titu1994/neural-style-transfer#neural-style-transfer--neural-doodles
 183. https://github.com/titu1994/neural-style-transfer#colaboratory-support
 184. https://github.com/titu1994/neural-style-transfer#guide
 185. https://github.com/titu1994/neural-style-transfer#examples
 186. https://github.com/titu1994/neural-style-transfer#single-style-transfer
 187. https://github.com/titu1994/neural-style-transfer#style-transfer-with-color-preservation
 188. https://github.com/titu1994/neural-style-transfer#style-interpolation
 189. https://github.com/titu1994/neural-style-transfer#multiple-style-transfer
 190. https://github.com/titu1994/neural-style-transfer#masked-style-transfer
 191. https://github.com/titu1994/neural-style-transfer#silhouette-transfer
 192. https://github.com/titu1994/neural-style-transfer#texture-transfer
 193. https://github.com/titu1994/neural-style-transfer#all-transfer-techniques
 194. https://github.com/titu1994/neural-style-transfer#various-results-with--without-color-preservation
 195. https://github.com/titu1994/neural-style-transfer#neural-doodle-examples
 196. https://github.com/titu1994/neural-style-transfer#weights-vgg-16
 197. https://github.com/titu1994/neural-style-transfer#modifications-to-original-implementation-
 198. https://github.com/titu1994/neural-style-transfer#improvements-in-inetwork
 199. https://github.com/titu1994/neural-style-transfer#script-helper
 200. https://github.com/titu1994/neural-style-transfer#benefits
 201. https://github.com/titu1994/neural-style-transfer#usage
 202. https://github.com/titu1994/neural-style-transfer#neural-style-transfer
 203. https://github.com/titu1994/neural-style-transfer#neural-doodles
 204. https://github.com/titu1994/neural-style-transfer#color-transfer-post-processing
 205. https://github.com/titu1994/neural-style-transfer#masked-style-transfer-post-processing
 206. https://github.com/titu1994/neural-style-transfer#parameters-neural-style
 207. https://github.com/titu1994/neural-style-transfer#parameters-neural-doodle
 208. https://github.com/titu1994/neural-style-transfer#parameters-color-transfer
 209. https://github.com/titu1994/neural-style-transfer#networkpy-in-action
 210. https://github.com/titu1994/neural-style-transfer#requirements
 211. https://github.com/titu1994/neural-style-transfer#speed
 212. https://github.com/titu1994/neural-style-transfer#issues
 213. https://github.com/
