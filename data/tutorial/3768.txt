   #[1]kdnuggets: analytics, big data, data mining and data science feed
   [2]kdnuggets    feed [3]kdnuggets    comments feed [4]kdnuggets    deep
   learning for text understanding from scratch comments feed [5]top
   kdnuggets tweets, mar 09-11: learning path from noob to kaggler in
   python; 10 steps for success in kaggle competitions [6]top big data
   influencers of 2014, according to hadoopsphere

kdnuggets

     [7]subscribe to kdnuggets news  | [8]twitter    [9]facebook
   [10]linkedin  |  [11]contact
   ____________________ search
   [menu-30.png]
   [search-icon.png]
     * [12]software
     * [13]news/blog
     * [14]top stories
     * [15]opinions
     * [16]tutorials
     * [17]jobs
     * [18]companies
     * [19]courses
     * [20]datasets
     * [21]education
     * [22]certificates
     * [23]meetings
     * [24]webinars


   [25]kdnuggets home    [26]news    [27]2015    [28]mar    [29]opinions,
   interviews, reports    deep learning for text understanding from scratch
   ( [30]15:n09 )

deep learning for text understanding from scratch

   [31][prv.gif] previous post
   [32]next post [nxt.gif]

     http likes 1018
   tags: [33]convnet, [34]deep learning, [35]francois petitjean, [36]text
   classification, [37]torch, [38]yann lecun

   forget about the meaning of words, forget about grammar, forget about
   syntax, forget even the very concept of a word. now let the machine
   learn everything by itself.
     __________________________________________________________________

                                                            c [39]comments

   by fran  ois petitjean, [40]@ledataminer.
   forget about the meaning of words, forget about grammar, forget about
   syntax, forget even the very concept of a word. now let the machine
   learn everything by itself.
   this is the amazing story that xiang zhang and yann lecun from nyu tell
   us in their recent paper    [41]text understanding from scratch   . they
   posit that deep learning could make it possible to understand text,
   without having any knowledge about the language.
   the brief     deep learning for text classification
   the paper shows how to use deep learning to perform text
   classification, for instance to determine if a review given by a
   customer on a product is positive or negative.
   deep learning has been very successful for big data in the last few
   years, in particular for temporally and spatially structured data such
   as images and videos. but it has been less successful in dealing with
   text: texts are usually treated as a sequence of words, and one big
   problem with that is that there are too many words in a language to
   directly use deep learning systems.
   english has more than a quarter of a million distinct words, so neural
   networks would have a quarter of a million neurons in the input layer.
   this high-dimensionality would prevent us from discovering the most
   interesting patterns with (deep) networks, and we would have to
   meticulously engineer the model to include knowledge about syntax and
   semantic structures.
   lecun   s team has developed a solution to this problem:

     what if, instead of seeing a text as a sequence of words, we saw it
     as a sequence of characters?

   since there are only a few dozen possible characters, that would make
   it possible to directly use deep learning systems for text
   classification.
   now, this is a very audacious idea, because what they   re basically
   saying here is    let   s forget everything we know about languages:
   meaning of words, the very concept of a word, grammar, syntax     let   s
   make the machine learning system discover everything relevant to the
   task, by itself   .
   and the amazing thing? it works!
   the core     convnets
   convolutional networks (convnets) [1,2] is the deep learning system
   used in the paper. invented by lecun in the late 80s, convnets work by
   trying to discover the convolutions that, applied to the data, would be
   useful to perform the recognition/classification task. the intuition
   behind convolutions is that they can be used to code many different
   mathematical transformations of the input.
   for images, a convolution is often used with a kernel to reveal certain
   properties of the image. for example, i depict below the application of
   different kernels (or matrix) to the same image (see also [42]here for
   a great explanation of convolutions); the convolution uses the matrix
   the matrix is the function that is applied.
   convnets convnets use this idea but instead of using fixed values for
   the kernel, they let the network infer them automatically so that the
   produced transformation of the image is specifically designed to
   perform the recognition task.
   learning icml characters they use the same idea in this paper: each
   character is transformed into a binary vector (   a    is [1,0,   ,0],    b    is
   [0,1,0,   ,0] and    z    is [0,   ,0,1]). broadly speaking, a sequence of
   characters looks like an image, on which convolutions can be applied.
   the network is designed as a traditional deep convnet, with successions
   of convolutional and pooling layers, finishing with 2 fully connected
   layers. the succession of convolutions makes it possible to learn very
   diverse sets of features, by learning convolutions of convolutions of
   convolutions (as if we looked at, for example, the blurred embossed
   image of the edges of an image, but with the actual operation being
   learned by the system).
   text deep learning how well does it work?
   as i mentioned at the start of the paper, the first amazing thing is
   that it works at all. remember, they do not even tell the system how to
   construct words! but not only have they shown proof of concept, but the
   team   s experiments show that their system actually works very well on
   many different tasks, including:
     * deciding if a review posted on amazon is positive or negative with
       96% accuracy, and predict the actual number of stars with 73%
       accuracy.
     * predicting the main topic of news articles (both in english and
       chinese) or the one of yahoo! answers with accuracies of 92%, 97%
       and 70% respectively.

   my take i really liked the work and the paper, particularly the
   authors    capacity to think out of the box    it   s an audacious idea to
   classify text without any knowledge of words (would you have bet on it
   succeeding so well?).

     related:
     - [43]juergen schmidhuber ama: the principles of intelligence and
     machine learning
     - [44]facebook open sources deep-learning modules for torch
     - [45]deep learning, the curse of dimensionality, and autoencoders

   i do however hope to see the team compare their method to stronger
   competitors in follow-up work, and keep working towards a deeper
   understanding of text than mere classification allows.
   deep learning has proved useful to bring lower bias classifier,
   essential characteristics to tackle classification for big data [3].
   this paper enables deep learning to be applied to text data, a very
   useful addition to the data mining toolbox. i look forward to seeing
   what the authors will do about extending this approach from sequences
   (of characters) to time series.
   (update: here is [46]crepe, code in torch 7 for text classification
   from character-level using convolutional networks, used for this work,
   released by xiang zhang on github, april 2015)
   bio
   [47]fran  ois petitjean completed his phd working for the french space
   agency in 2012, and is now a research fellow in geoff webb   s team at
   monash university   s centre for data science. he tweets at @ledataminer.
   references
   [1] lecun, y., bottou, l., bengio, y., and haffner, p. gradient-based
   learning applied to document recognition. proceedings of the ieee,
   86(11):2278   2324, november1998.
   [2] y. lecun, b. boser, j. s. denker, d. henderson, r. e. howard, w.
   hubbard, and l. d. jackel,    handwritten digit recognition with a
   back-propagation network,    in nips   89.
   [3] s. chen, a. martinez, and g.i. webb (2014). highly scalable
   attribute selection for aode. in proceedings of the 18th pacific-asia
   conference on knowledge discovery and data mining, pp. 86-97.
     __________________________________________________________________

   [48][prv.gif] previous post
   [49]next post [nxt.gif]
     __________________________________________________________________

top stories past 30 days

                                              most popular
    1. [50]another 10 free must-read books for machine learning and data
       science
    2. [51]9 must-have skills you need to become a data scientist, updated
    3. [52]who is a typical data scientist in 2019?
    4. [53]the pareto principle for data scientists
    5. [54]what no one will tell you about data science job applications
    6. [55]19 inspiring women in ai, big data, data science, machine
       learning
    7. [56]my favorite mind-blowing machine learning/ai breakthroughs

                                                most shared
    1. [57]id158s optimization using genetic algorithm
       with python
    2. [58]who is a typical data scientist in 2019?
    3. [59]8 reasons why you should get a microsoft azure certification
    4. [60]the pareto principle for data scientists
    5. [61]r vs python for data visualization
    6. [62]how to work in data science, ai, big data
    7. [63]the deep learning toolset     an overview

[64]latest news

     * [65]download your datax guide to ai in marketing
     * [66]kdnuggets offer: save 20% on strata in london
     * [67]training a champion: building deep neural nets for big ...
     * [68]building a recommender system
     * [69]predict age and gender using convolutional neural netwo...
     * [70]top tweets, mar 27     apr 02: here is a great ex...

   [71]kdnuggets home    [72]news    [73]2015    [74]mar    [75]opinions,
   interviews, reports    deep learning for text understanding from scratch
   ( [76]15:n09 )
      2019 kdnuggets. [77]about kdnuggets.  [78]privacy policy. [79]terms
   of service

   [80]subscribe to kdnuggets news
   [81][tw_c48.png] [82]facebook [83]linkedin
   x

   [envelope.png] [84]get kdnuggets, a leading newsletter on ai, data
   science, and machine learning
   email: ______________________________
   sign up
   leave this field empty if you're human: ____________________

references

   visible links
   1. https://www.kdnuggets.com/feed/
   2. https://www.kdnuggets.com/feed
   3. https://www.kdnuggets.com/comments/feed
   4. https://www.kdnuggets.com/2015/03/deep-learning-text-understanding-from-scratch.html/feed
   5. https://www.kdnuggets.com/2015/03/top-tweets-mar09-11.html
   6. https://www.kdnuggets.com/2015/03/hadoopsphere-top-big-data-influencers-2014.html
   7. https://www.kdnuggets.com/news/subscribe.html
   8. https://twitter.com/kdnuggets
   9. https://www.facebook.com/kdnuggets
  10. https://www.linkedin.com/groups/54257/
  11. https://www.kdnuggets.com/contact.html
  12. https://www.kdnuggets.com/software/index.html
  13. https://www.kdnuggets.com/news/index.html
  14. https://www.kdnuggets.com/news/top-stories.html
  15. https://www.kdnuggets.com/opinions/index.html
  16. https://www.kdnuggets.com/tutorials/index.html
  17. https://www.kdnuggets.com/jobs/index.html
  18. https://www.kdnuggets.com/companies/index.html
  19. https://www.kdnuggets.com/courses/index.html
  20. https://www.kdnuggets.com/datasets/index.html
  21. https://www.kdnuggets.com/education/index.html
  22. https://www.kdnuggets.com/education/analytics-data-mining-certificates.html
  23. https://www.kdnuggets.com/meetings/index.html
  24. https://www.kdnuggets.com/webcasts/index.html
  25. https://www.kdnuggets.com/
  26. https://www.kdnuggets.com/news/index.html
  27. https://www.kdnuggets.com/2015/index.html
  28. https://www.kdnuggets.com/2015/03/index.html
  29. https://www.kdnuggets.com/2015/03/opinions-interviews.html
  30. https://www.kdnuggets.com/2015/n09.html
  31. https://www.kdnuggets.com/2015/03/top-tweets-mar09-11.html
  32. https://www.kdnuggets.com/2015/03/hadoopsphere-top-big-data-influencers-2014.html
  33. https://www.kdnuggets.com/tag/convnet
  34. https://www.kdnuggets.com/tag/deep-learning
  35. https://www.kdnuggets.com/tag/francois-petitjean
  36. https://www.kdnuggets.com/tag/text-classification
  37. https://www.kdnuggets.com/tag/torch
  38. https://www.kdnuggets.com/tag/yann-lecun
  39. https://www.kdnuggets.com/2015/03/deep-learning-text-understanding-from-scratch.html#comments
  40. https://twitter.com/ledataminer
  41. http://arxiv.org/abs/1502.01710
  42. https://developer.apple.com/library/ios/documentation/performance/conceptual/vimage/convolutionoperations/convolutionoperations.html
  43. https://www.kdnuggets.com/2015/03/juergen-schmidhuber-ama-principles-intelligence-machine-learning.html
  44. https://www.kdnuggets.com/2015/02/facebook-open-source-deep-learning-torch.html
  45. https://www.kdnuggets.com/2015/03/deep-learning-curse-dimensionality-autoencoders.html
  46. https://github.com/zhangxiangxiao/crepe
  47. http://www.francois-petitjean.com/
  48. https://www.kdnuggets.com/2015/03/top-tweets-mar09-11.html
  49. https://www.kdnuggets.com/2015/03/hadoopsphere-top-big-data-influencers-2014.html
  50. https://www.kdnuggets.com/2019/03/another-10-free-must-read-books-for-machine-learning-and-data-science.html
  51. https://www.kdnuggets.com/2018/05/simplilearn-9-must-have-skills-data-scientist.html
  52. https://www.kdnuggets.com/2019/03/typical-data-scientist-2019.html
  53. https://www.kdnuggets.com/2019/03/pareto-principle-data-scientists.html
  54. https://www.kdnuggets.com/2019/03/data-science-job-applications.html
  55. https://www.kdnuggets.com/2019/03/women-ai-big-data-science-machine-learning.html
  56. https://www.kdnuggets.com/2019/03/favorite-ml-ai-breakthroughs.html
  57. https://www.kdnuggets.com/2019/03/artificial-neural-networks-optimization-genetic-algorithm-python.html
  58. https://www.kdnuggets.com/2019/03/typical-data-scientist-2019.html
  59. https://www.kdnuggets.com/2019/03/simplilearn-8-reasons-microsoft-azure-certification.html
  60. https://www.kdnuggets.com/2019/03/pareto-principle-data-scientists.html
  61. https://www.kdnuggets.com/2019/03/r-vs-python-data-visualization.html
  62. https://www.kdnuggets.com/2019/03/work-data-science-ai-big-data.html
  63. https://www.kdnuggets.com/2019/03/deep-learning-toolset-overview.html
  64. https://www.kdnuggets.com/news/index.html
  65. https://www.kdnuggets.com/2019/04/datax-download-guide-ai-marketing.html
  66. https://www.kdnuggets.com/2019/04/strata-kdnuggets-offer-save-london.html
  67. https://www.kdnuggets.com/2019/04/sisense-deep-neural-nets-big-data-analytics.html
  68. https://www.kdnuggets.com/2019/04/building-recommender-system.html
  69. https://www.kdnuggets.com/2019/04/predict-age-gender-using-convolutional-neural-network-opencv.html
  70. https://www.kdnuggets.com/2019/04/top-tweets-mar27-apr02.html
  71. https://www.kdnuggets.com/
  72. https://www.kdnuggets.com/news/index.html
  73. https://www.kdnuggets.com/2015/index.html
  74. https://www.kdnuggets.com/2015/03/index.html
  75. https://www.kdnuggets.com/2015/03/opinions-interviews.html
  76. https://www.kdnuggets.com/2015/n09.html
  77. https://www.kdnuggets.com/about/index.html
  78. https://www.kdnuggets.com/news/privacy-policy.html
  79. https://www.kdnuggets.com/terms-of-service.html
  80. https://www.kdnuggets.com/news/subscribe.html
  81. https://twitter.com/kdnuggets
  82. https://facebook.com/kdnuggets
  83. https://www.linkedin.com/groups/54257
  84. https://www.kdnuggets.com/news/subscribe.html

   hidden links:
  86. https://www.kdnuggets.com/
  87. https://www.kdnuggets.com/
