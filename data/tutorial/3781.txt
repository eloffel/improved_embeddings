   #[1]github [2]recent commits to lectures:master

   [3]skip to content

   (button)

     * why github?
       [4]features    
          + [5]code review
          + [6]project management
          + [7]integrations
          + [8]actions
          + [9]team management
          + [10]social coding
          + [11]documentation
          + [12]code hosting
          + [13]customer stories    
          + [14]security    
     * [15]enterprise
     * explore
          + [16]explore github    

learn & contribute
          + [17]topics
          + [18]collections
          + [19]trending
          + [20]learning lab
          + [21]open source guides

connect with others
          + [22]events
          + [23]community forum
          + [24]github education
     * [25]marketplace
     * pricing
       [26]plans    
          + [27]compare plans
          + [28]contact sales
          + [29]nonprofit    
          + [30]education    

   ____________________
     * in this repository all github    
       jump to    

     * no suggested jump to results

     * in this repository all github    
       jump to    
     * in this repository all github    
       jump to    

   [31]sign in [32]sign up

     * [33]watch [34]1,261
     * [35]star [36]13,642
     * [37]fork [38]3,195

[39]oxford-cs-deepnlp-2017/[40]lectures

   [41]code [42]issues 9 [43]pull requests 0 [44]projects 0 [45]insights
   (button) dismiss

join github today

   github is home to over 31 million developers working together to host
   and review code, manage projects, and build software together.
   [46]sign up
   oxford deep nlp 2017 course
   [47]deep-learning [48]machine-learning [49]natural-language-processing
   [50]nlp [51]oxford
     * [52]64 commits
     * [53]1 branch
     * [54]0 releases
     * [55]fetching contributors

   branch: master (button) new pull request
   [56]find file
   clone or download

clone with https

   use git or checkout with svn using the web url.
   https://github.com/o
   [57]download zip

downloading...

   want to be notified of new releases in oxford-cs-deepnlp-2017/lectures?
   [58]sign in [59]sign up

launching github desktop...

   if nothing happens, [60]download github desktop and try again.

   (button) go back

launching github desktop...

   if nothing happens, [61]download github desktop and try again.

   (button) go back

launching xcode...

   if nothing happens, [62]download xcode and try again.

   (button) go back

launching visual studio...

   if nothing happens, [63]download the github extension for visual studio
   and try again.

   (button) go back
   [64]@pblunsom
   [65]pblunsom [66]create readme.md
   latest commit [67]de8daf5 jun 12, 2017
   [68]permalink
   type name latest commit message commit time
   failed to load latest commit information.
   [69]lecture 10 - text to speech.pdf [70]add files via upload feb 25,
   2017
   [71]lecture 11 - id53.pdf
   [72]lecture 12- memory lecture.pdf
   [73]lecture 13 - linguistics.pdf
   [74]lecture 1a - introduction.pdf
   [75]lecture 1b - deep neural networks are our friends.pdf
   [76]lecture 2a- word level semantics.pdf
   [77]lecture 2b - overview of the practicals.pdf
   [78]lecture 3 - language modelling and id56s part 1.pdf
   [79]lecture 4 - language modelling and id56s part 2.pdf [80]add files
   via upload feb 6, 2017
   [81]lecture 5 - text classification.pdf
   [82]lecture 6 - nvidia id56s and gpus.pdf
   [83]lecture 7 - conditional id38.pdf [84]add files via
   upload feb 14, 2017
   [85]lecture 8 - conditional id38 with attention.pdf
   [86]lecture 9 - id103.pdf
   [87]readme.md

readme.md

preamble

   this repository contains the lecture slides and course description for
   the [88]deep natural language processing course offered in hilary term
   2017 at the university of oxford.

   this is an advanced course on natural language processing.
   automatically processing natural language inputs and producing language
   outputs is a key component of artificial general intelligence. the
   ambiguities and noise inherent in human communication render
   traditional symbolic ai techniques ineffective for representing and
   analysing language data. recently statistical techniques based on
   neural networks have achieved a number of remarkable successes in
   natural language processing leading to a great deal of commercial and
   academic interest in the field

   this is an applied course focussing on recent advances in analysing and
   generating speech and text using recurrent neural networks. we
   introduce the mathematical definitions of the relevant machine learning
   models and derive their associated optimisation algorithms. the course
   covers a range of applications of neural networks in nlp including
   analysing latent dimensions in text, transcribing speech to text,
   translating between languages, and answering questions. these topics
   are organised into three high level themes forming a progression from
   understanding the use of neural networks for sequential language
   modelling, to understanding their use as conditional language models
   for transduction tasks, and finally to approaches employing these
   techniques in combination with other mechanisms for advanced
   applications. throughout the course the practical implementation of
   such models on cpu and gpu hardware is also discussed.

   this course is organised by phil blunsom and delivered in partnership
   with the deepmind natural language research group.

lecturers

     * phil blunsom (oxford university and deepmind)
     * chris dyer (carnegie mellon university and deepmind)
     * edward grefenstette (deepmind)
     * karl moritz hermann (deepmind)
     * andrew senior (deepmind)
     * wang ling (deepmind)
     * jeremy appleyard (nvidia)

tas

     * yannis assael
     * yishu miao
     * brendan shillingford
     * jan buys

timetable

practicals

     * group 1 - monday, 9:00-11:00 (weeks 2-8), 60.05 thom building
     * group 2 - friday, 16:00-18:00 (weeks 2-8), room 379

    1. [89]practical 1: id97
    2. [90]practical 2: text classification
    3. [91]practical 3: recurrent neural networks for text classification
       and language modelling
    4. [92]practical 4: open practical

lectures

   public lectures are held in lecture theatre 1 of the maths institute,
   on tuesdays and thursdays (except week 8), 16:00-18:00 (hilary term
   weeks 1,3-8).

lecture materials

1. lecture 1a - introduction [phil blunsom]

   this lecture introduces the course and motivates why it is interesting
   to study language processing using deep learning techniques.

   [93][slides] [94][video]

2. lecture 1b - deep neural networks are our friends [wang ling]

   this lecture revises basic machine learning concepts that students
   should know before embarking on this course.

   [95][slides] [96][video]

3. lecture 2a- word level semantics [ed grefenstette]

   words are the core meaning bearing units in language. representing and
   learning the meanings of words is a fundamental task in nlp and in this
   lecture the concept of a id27 is introduced as a practical
   and scalable solution.

   [97][slides] [98][video]

reading

embeddings basics

     * [99]firth, john r. "a synopsis of linguistic theory, 1930-1955."
       (1957): 1-32.
     * [100]curran, james richard. "from distributional to semantic
       similarity." (2004).
     * [101]collobert, ronan, et al. "natural language processing (almost)
       from scratch." journal of machine learning research 12. aug (2011):
       2493-2537.
     * [102]mikolov, tomas, et al. "distributed representations of words
       and phrases and their compositionality." advances in neural
       information processing systems. 2013.

datasets and visualisation

     * [103]finkelstein, lev, et al. "placing search in context: the
       concept revisited." proceedings of the 10th international
       conference on world wide web. acm, 2001.
     * [104]hill, felix, roi reichart, and anna korhonen. "siid113x-999:
       evaluating semantic models with (genuine) similarity estimation."
       computational linguistics (2016).
     * [105]maaten, laurens van der, and geoffrey hinton. "visualizing
       data using id167." journal of machine learning research 9.nov
       (2008): 2579-2605.

blog posts

     * [106]deep learning, nlp, and representations, christopher olah.
     * [107]visualizing top tweeps with id167, in javascript, andrej
       karpathy.

further reading

     * [108]hermann, karl moritz, and phil blunsom. "multilingual models
       for compositional distributed semantics." arxiv preprint
       arxiv:1404.4641 (2014).
     * [109]levy, omer, and yoav goldberg. "neural id27 as
       implicit id105." advances in neural information
       processing systems. 2014.
     * [110]levy, omer, yoav goldberg, and ido dagan. "improving
       distributional similarity with lessons learned from word
       embeddings." transactions of the association for computational
       linguistics 3 (2015): 211-225.
     * [111]ling, wang, et al. "two/too simple adaptations of id97 for
       syntax problems." hlt-naacl. 2015.

4. lecture 2b - overview of the practicals [chris dyer]

   this lecture motivates the practical segment of the course.

   [112][slides] [113][video]

5. lecture 3 - language modelling and id56s part 1 [phil blunsom]

   language modelling is important task of great practical use in many nlp
   applications. this lecture introduces language modelling, including
   traditional id165 based approaches and more contemporary neural
   approaches. in particular the popular recurrent neural network (id56)
   language model is introduced and its basic training and evaluation
   algorithms described.

   [114][slides] [115][video]

reading

textbook

     * [116]deep learning, chapter 10.

blogs

     * [117]the unreasonable effectiveness of recurrent neural networks,
       andrej karpathy.
     * [118]the unreasonable effectiveness of character-level language
       models, yoav goldberg.
     * [119]explaining and illustrating orthogonal initialization for
       recurrent neural networks, stephen merity.

6. lecture 4 - language modelling and id56s part 2 [phil blunsom]

   this lecture continues on from the previous one and considers some of
   the issues involved in producing an effective implementation of an id56
   language model. the vanishing and exploding gradient problem is
   described and architectural solutions, such as long short term memory
   (lstm), are introduced.

   [120][slides] [121][video]

reading

textbook

     * [122]deep learning, chapter 10.

vanishing gradients, lstms etc.

     * [123]on the difficulty of training recurrent neural networks.
       pascanu et al., icml 2013.
     * [124]long short-term memory. hochreiter and schmidhuber, neural
       computation 1997.
     * [125]learning phrase representations using id56 encoderdecoder for
       id151. cho et al, emnlp 2014.
     * blog: [126]understanding id137, christopher olah.

dealing with large vocabularies

     * [127]a scalable hierarchical distributed language model. mnih and
       hinton, nips 2009.
     * [128]a fast and simple algorithm for training neural probabilistic
       language models. mnih and teh, icml 2012.
     * [129]on using very large target vocabulary for neural machine
       translation. jean et al., acl 2015.
     * [130]exploring the limits of id38. jozefowicz et al.,
       arxiv 2016.
     * [131]efficient softmax approximation for gpus. grave et al., arxiv
       2016.
     * [132]notes on noise contrastive estimation and negative sampling.
       dyer, arxiv 2014.
     * [133]pragmatic neural language modelling in machine translation.
       baltescu and blunsom, naacl 2015

regularisation and dropout

     * [134]a theoretically grounded application of dropout in recurrent
       neural networks. gal and ghahramani, nips 2016.
     * blog: [135]uncertainty in deep learning, yarin gal.

other stuff

     * [136]recurrent id199. zilly et al., arxiv 2016.
     * [137]capacity and trainability in recurrent neural networks.
       collins et al., arxiv 2016.

7. lecture 5 - text classification [karl moritz hermann]

   this lecture discusses text classification, beginning with basic
   classifiers, such as naive bayes, and progressing through to id56s and
   convolution networks.

   [138][slides] [139][video]

reading

     * [140]recurrent convolutional neural networks for text
       classification. lai et al. aaai 2015.
     * [141]a convolutional neural network for modelling sentences,
       kalchbrenner et al. acl 2014.
     * [142]semantic compositionality through recursive matrix-vector,
       socher et al. emnlp 2012.
     * blog: [143]understanding convolution neural networks for nlp, denny
       britz.
     * thesis: [144]distributional representations for compositional
       semantics, hermann (2014).

8. lecture 6 - deep nlp on nvidia gpus [jeremy appleyard]

   this lecture introduces graphical processing units (gpus) as an
   alternative to cpus for executing deep learning algorithms. the
   strengths and weaknesses of gpus are discussed as well as the
   importance of understanding how memory bandwidth and computation impact
   throughput for id56s.

   [145][slides] [146][video]

reading

     * [147]optimizing performance of recurrent neural networks on gpus.
       appleyard et al., arxiv 2016.
     * [148]persistent id56s: stashing recurrent weights on-chip, diamos et
       al., icml 2016
     * [149]efficient softmax approximation for gpus. grave et al., arxiv
       2016.

9. lecture 7 - conditional language models [chris dyer]

   in this lecture we extend the concept of language modelling to
   incorporate prior information. by conditioning an id56 language model on
   an input representation we can generate contextually relevant language.
   this very general idea can be applied to transduce sequences into new
   sequences for tasks such as translation and summarisation, or images
   into captions describing their content.

   [150][slides] [151][video]

reading

     * [152]recurrent continuous translation models. kalchbrenner and
       blunsom, emnlp 2013
     * [153]sequence to sequence learning with neural networks. sutskever
       et al., nips 2014
     * [154]multimodal neural language models. kiros et al., icml 2014
     * [155]show and tell: a neural image caption generator. vinyals et
       al., cvpr 2015

10. lecture 8 - generating language with attention [chris dyer]

   this lecture introduces one of the most important and influencial
   mechanisms employed in deep neural networks: attention. attention
   augments recurrent networks with the ability to condition on specific
   parts of the input and is key to achieving high performance in tasks
   such as machine translation and image captioning.

   [156][slides] [157][video]

reading

     * [158]id4 by jointly learning to align and
       translate. bahdanau et al., iclr 2015
     * [159]show, attend, and tell: neural image id134 with
       visual attention. xu et al., icml 2015
     * [160]incorporating structural alignment biases into an attentional
       neural translation model. cohn et al., naacl 2016
     * [161]id7: a method for automatic evaluation of machine
       translation. papineni et al, acl 2002

11. lecture 9 - id103 (asr) [andrew senior]

   automatic id103 (asr) is the task of transducing raw audio
   signals of spoken language into text transcriptions. this talk covers
   the history of asr models, from gaussian mixtures to attention
   augmented id56s, the basic linguistics of speech, and the various input
   and output representations frequently employed.

   [162][slides] [163][video]

12. lecture 10 - text to speech (tts) [andrew senior]

   this lecture introduces algorithms for converting written language into
   spoken language (text to speech). tts is the inverse process to asr,
   but there are some important differences in the models applied. here we
   review traditional tts models, and then cover more recent neural
   approaches such as deepmind's wavenet model.

   [164][slides] [165][video]

13. lecture 11 - id53 [karl moritz hermann]

   [166][slides] [167][video]

reading

     * [168]teaching machines to read and comprehend. hermann et al., nips
       2015
     * [169]deep learning for answer sentence selection. yu et al., nips
       deep learning workshop 2014

14. lecture 12 - memory [ed grefenstette]

   [170][slides] [171][video]

reading

     * [172]hybrid computing using a neural network with dynamic external
       memory. graves et al., nature 2016
     * [173]reasoning about entailment with neural attention. rockt  schel
       et al., iclr 2016
     * [174]learning to transduce with unbounded memory. grefenstette et
       al., nips 2015
     * [175]end-to-end memory networks. sukhbaatar et al., nips 2015

15. lecture 13 - linguistic knowledge in neural networks

   [176][slides] [177][video]

piazza

   we will be using piazza to facilitate class discussion during the
   course. rather than emailing questions directly, i encourage you to
   post your questions on piazza to be answered by your fellow students,
   instructors, and lecturers. however do please do note that all the
   lecturers for this course are volunteering their time and may not
   always be available to give a response.

   find our class page at:
   [178]https://piazza.com/ox.ac.uk/winter2017/dnlpht2017/home

assessment

   the primary assessment for this course will be a take-home assignment
   issued at the end of the term. this assignment will ask questions
   drawing on the concepts and models discussed in the course, as well as
   from selected research publications. the nature of the questions will
   include analysing mathematical descriptions of models and proposing
   extensions, improvements, or evaluations to such models. the assignment
   may also ask students to read specific research publications and
   discuss their proposed algorithms in the context of the course. in
   answering questions students will be expected to both present coherent
   written arguments and use appropriate mathematical formulae, and
   possibly pseudo-code, to illustrate answers.

   the practical component of the course will be assessed in the usual
   way.

acknowledgements

   this course would not have been possible without the support of
   [179]deepmind, [180]the university of oxford department of computer
   science, [181]nvidia, and the generous donation of gpu resources from
   [182]microsoft azure.

     *    2019 github, inc.
     * [183]terms
     * [184]privacy
     * [185]security
     * [186]status
     * [187]help

     * [188]contact github
     * [189]pricing
     * [190]api
     * [191]training
     * [192]blog
     * [193]about

   (button) you can   t perform that action at this time.

   you signed in with another tab or window. [194]reload to refresh your
   session. you signed out in another tab or window. [195]reload to
   refresh your session.

   (button)

references

   visible links
   1. https://github.com/opensearch.xml
   2. https://github.com/oxford-cs-deepnlp-2017/lectures/commits/master.atom
   3. https://github.com/oxford-cs-deepnlp-2017/lectures#start-of-content
   4. https://github.com/features
   5. https://github.com/features/code-review/
   6. https://github.com/features/project-management/
   7. https://github.com/features/integrations
   8. https://github.com/features/actions
   9. https://github.com/features#team-management
  10. https://github.com/features#social-coding
  11. https://github.com/features#documentation
  12. https://github.com/features#code-hosting
  13. https://github.com/customer-stories
  14. https://github.com/security
  15. https://github.com/enterprise
  16. https://github.com/explore
  17. https://github.com/topics
  18. https://github.com/collections
  19. https://github.com/trending
  20. https://lab.github.com/
  21. https://opensource.guide/
  22. https://github.com/events
  23. https://github.community/
  24. https://education.github.com/
  25. https://github.com/marketplace
  26. https://github.com/pricing
  27. https://github.com/pricing#feature-comparison
  28. https://enterprise.github.com/contact
  29. https://github.com/nonprofit
  30. https://education.github.com/
  31. https://github.com/login?return_to=/oxford-cs-deepnlp-2017/lectures
  32. https://github.com/join
  33. https://github.com/login?return_to=/oxford-cs-deepnlp-2017/lectures
  34. https://github.com/oxford-cs-deepnlp-2017/lectures/watchers
  35. https://github.com/login?return_to=/oxford-cs-deepnlp-2017/lectures
  36. https://github.com/oxford-cs-deepnlp-2017/lectures/stargazers
  37. https://github.com/login?return_to=/oxford-cs-deepnlp-2017/lectures
  38. https://github.com/oxford-cs-deepnlp-2017/lectures/network/members
  39. https://github.com/oxford-cs-deepnlp-2017
  40. https://github.com/oxford-cs-deepnlp-2017/lectures
  41. https://github.com/oxford-cs-deepnlp-2017/lectures
  42. https://github.com/oxford-cs-deepnlp-2017/lectures/issues
  43. https://github.com/oxford-cs-deepnlp-2017/lectures/pulls
  44. https://github.com/oxford-cs-deepnlp-2017/lectures/projects
  45. https://github.com/oxford-cs-deepnlp-2017/lectures/pulse
  46. https://github.com/join?source=prompt-code
  47. https://github.com/topics/deep-learning
  48. https://github.com/topics/machine-learning
  49. https://github.com/topics/natural-language-processing
  50. https://github.com/topics/nlp
  51. https://github.com/topics/oxford
  52. https://github.com/oxford-cs-deepnlp-2017/lectures/commits/master
  53. https://github.com/oxford-cs-deepnlp-2017/lectures/branches
  54. https://github.com/oxford-cs-deepnlp-2017/lectures/releases
  55. https://github.com/oxford-cs-deepnlp-2017/lectures/graphs/contributors
  56. https://github.com/oxford-cs-deepnlp-2017/lectures/find/master
  57. https://github.com/oxford-cs-deepnlp-2017/lectures/archive/master.zip
  58. https://github.com/login?return_to=https://github.com/oxford-cs-deepnlp-2017/lectures
  59. https://github.com/join?return_to=/oxford-cs-deepnlp-2017/lectures
  60. https://desktop.github.com/
  61. https://desktop.github.com/
  62. https://developer.apple.com/xcode/
  63. https://visualstudio.github.com/
  64. https://github.com/pblunsom
  65. https://github.com/oxford-cs-deepnlp-2017/lectures/commits?author=pblunsom
  66. https://github.com/oxford-cs-deepnlp-2017/lectures/commit/de8daf5adb86f2c4f88bf1a5d9a688a7d2acac1e
  67. https://github.com/oxford-cs-deepnlp-2017/lectures/commit/de8daf5adb86f2c4f88bf1a5d9a688a7d2acac1e
  68. https://github.com/oxford-cs-deepnlp-2017/lectures/tree/de8daf5adb86f2c4f88bf1a5d9a688a7d2acac1e
  69. https://github.com/oxford-cs-deepnlp-2017/lectures/blob/master/lecture 10 - text to speech.pdf
  70. https://github.com/oxford-cs-deepnlp-2017/lectures/commit/b49a1efb2563e8682919c8938fb73590a9971f02
  71. https://github.com/oxford-cs-deepnlp-2017/lectures/blob/master/lecture 11 - id53.pdf
  72. https://github.com/oxford-cs-deepnlp-2017/lectures/blob/master/lecture 12- memory lecture.pdf
  73. https://github.com/oxford-cs-deepnlp-2017/lectures/blob/master/lecture 13 - linguistics.pdf
  74. https://github.com/oxford-cs-deepnlp-2017/lectures/blob/master/lecture 1a - introduction.pdf
  75. https://github.com/oxford-cs-deepnlp-2017/lectures/blob/master/lecture 1b - deep neural networks are our friends.pdf
  76. https://github.com/oxford-cs-deepnlp-2017/lectures/blob/master/lecture 2a- word level semantics.pdf
  77. https://github.com/oxford-cs-deepnlp-2017/lectures/blob/master/lecture 2b - overview of the practicals.pdf
  78. https://github.com/oxford-cs-deepnlp-2017/lectures/blob/master/lecture 3 - language modelling and id56s part 1.pdf
  79. https://github.com/oxford-cs-deepnlp-2017/lectures/blob/master/lecture 4 - language modelling and id56s part 2.pdf
  80. https://github.com/oxford-cs-deepnlp-2017/lectures/commit/9c7565039c3e843d086a8c4841740ce1d5c9ab72
  81. https://github.com/oxford-cs-deepnlp-2017/lectures/blob/master/lecture 5 - text classification.pdf
  82. https://github.com/oxford-cs-deepnlp-2017/lectures/blob/master/lecture 6 - nvidia id56s and gpus.pdf
  83. https://github.com/oxford-cs-deepnlp-2017/lectures/blob/master/lecture 7 - conditional id38.pdf
  84. https://github.com/oxford-cs-deepnlp-2017/lectures/commit/5847d16bb4a5f80d8655903fbfc27841d2d5e0dd
  85. https://github.com/oxford-cs-deepnlp-2017/lectures/blob/master/lecture 8 - conditional id38 with attention.pdf
  86. https://github.com/oxford-cs-deepnlp-2017/lectures/blob/master/lecture 9 - id103.pdf
  87. https://github.com/oxford-cs-deepnlp-2017/lectures/blob/master/readme.md
  88. http://www.cs.ox.ac.uk/teaching/courses/2016-2017/dl/
  89. https://github.com/oxford-cs-deepnlp-2017/practical-1
  90. https://github.com/oxford-cs-deepnlp-2017/practical-2
  91. https://github.com/oxford-cs-deepnlp-2017/practical-3
  92. https://github.com/oxford-cs-deepnlp-2017/practical-open
  93. https://github.com/oxford-cs-deepnlp-2017/lectures/blob/master/lecture 1a - introduction.pdf
  94. http://media.podcasts.ox.ac.uk/comlab/deep_learning_nlp/2017-01_deep_nlp_1a_intro.mp4
  95. https://github.com/oxford-cs-deepnlp-2017/lectures/blob/master/lecture 1b - deep neural networks are our friends.pdf
  96. http://media.podcasts.ox.ac.uk/comlab/deep_learning_nlp/2017-01_deep_nlp_1b_friends.mp4
  97. https://github.com/oxford-cs-deepnlp-2017/lectures/blob/master/lecture 2a- word level semantics.pdf
  98. http://media.podcasts.ox.ac.uk/comlab/deep_learning_nlp/2017-01_deep_nlp_2a_lexical_semantics.mp4
  99. http://annabellelukin.edublogs.org/files/2013/08/firth-jr-1962-a-synopsis-of-linguistic-theory-wfihi5.pdf
 100. https://www.era.lib.ed.ac.uk/bitstream/handle/1842/563/ip030023.pdf?sequence=2&isallowed=y
 101. http://www.jmlr.org/papers/volume12/collobert11a/collobert11a.pdf
 102. http://papers.nips.cc/paper/5021-distributed-representations-of-words-and-phrases-and-their-compositionality.pdf
 103. http://www.iicm.tugraz.at/thesis/cguetl_diss/literatur/kapitel07/references/finkelstein_et_al._2002/p116-finkelstein.pdf
 104. http://www.aclweb.org/website/old_anthology/j/j15/j15-4004.pdf
 105. http://www.jmlr.org/papers/volume9/vandermaaten08a/vandermaaten08a.pdf
 106. http://colah.github.io/posts/2014-07-nlp-id56s-representations/
 107. http://karpathy.github.io/2014/07/02/visualizing-top-tweeps-with-id167-in-javascript/
 108. https://arxiv.org/pdf/1404.4641.pdf
 109. http://u.cs.biu.ac.il/~nlp/wp-content/uploads/neural-word-embeddings-as-implicit-matrix-factorization-nips-2014.pdf
 110. https://www.transacl.org/ojs/index.php/tacl/article/view/570/124
 111. https://www.aclweb.org/anthology/n/n15/n15-1142.pdf
 112. https://github.com/oxford-cs-deepnlp-2017/lectures/blob/master/lecture 2b - overview of the practicals.pdf
 113. http://media.podcasts.ox.ac.uk/comlab/deep_learning_nlp/2017-01_deep_nlp_2b_practicals.mp4
 114. https://github.com/oxford-cs-deepnlp-2017/lectures/blob/master/lecture 3 - language modelling and id56s part 1.pdf
 115. http://media.podcasts.ox.ac.uk/comlab/deep_learning_nlp/2017-01_deep_nlp_3_modelling_1.mp4
 116. http://www.deeplearningbook.org/contents/id56.html
 117. http://karpathy.github.io/2015/05/21/id56-effectiveness/
 118. http://nbviewer.jupyter.org/gist/yoavg/d76121dfde2618422139
 119. http://smerity.com/articles/2016/orthogonal_init.html
 120. https://github.com/oxford-cs-deepnlp-2017/lectures/blob/master/lecture 4 - language modelling and id56s part 2.pdf
 121. http://media.podcasts.ox.ac.uk/comlab/deep_learning_nlp/2017-01_deep_nlp_4_modelling_2.mp4
 122. http://www.deeplearningbook.org/contents/id56.html
 123. http://jmlr.csail.mit.edu/proceedings/papers/v28/pascanu13.pdf
 124. http://dl.acm.org/citation.cfm?id=1246450
 125. https://arxiv.org/abs/1406.1078
 126. http://colah.github.io/posts/2015-08-understanding-lstms/
 127. https://papers.nips.cc/paper/3583-a-scalable-hierarchical-distributed-language-model.pdf
 128. https://www.cs.toronto.edu/~amnih/papers/ncelm.pdf
 129. http://www.aclweb.org/anthology/p15-1001
 130. https://arxiv.org/abs/1602.02410
 131. https://arxiv.org/abs/1609.04309
 132. https://arxiv.org/abs/1410.8251
 133. http://www.aclweb.org/anthology/n15-1083
 134. https://arxiv.org/abs/1512.05287
 135. http://mlg.eng.cam.ac.uk/yarin/blog_2248.html
 136. https://arxiv.org/abs/1607.03474
 137. https://arxiv.org/abs/1611.09913
 138. https://github.com/oxford-cs-deepnlp-2017/lectures/blob/master/lecture 5 - text classification.pdf
 139. http://media.podcasts.ox.ac.uk/comlab/deep_learning_nlp/2017-01_deep_nlp_5_text_classification.mp4
 140. http://www.aaai.org/ocs/index.php/aaai/aaai15/paper/download/9745/9552
 141. http://www.aclweb.org/anthology/p14-1062
 142. http://nlp.stanford.edu/pubs/socherhuvalmanningng_emnlp2012.pdf
 143. http://www.wildml.com/2015/11/understanding-convolutional-neural-networks-for-nlp/
 144. https://arxiv.org/abs/1411.3146
 145. https://github.com/oxford-cs-deepnlp-2017/lectures/blob/master/lecture 6 - nvidia id56s and gpus.pdf
 146. http://media.podcasts.ox.ac.uk/comlab/deep_learning_nlp/2017-01_deep_nlp_6_nvidia_gpus.mp4
 147. https://arxiv.org/abs/1604.01946
 148. http://jmlr.org/proceedings/papers/v48/diamos16.pdf
 149. https://arxiv.org/abs/1609.04309
 150. https://github.com/oxford-cs-deepnlp-2017/lectures/blob/master/lecture 7 - conditional id38.pdf
 151. http://media.podcasts.ox.ac.uk/comlab/deep_learning_nlp/2017-01_deep_nlp_7_conditional_lang_mod.mp4
 152. http://anthology.aclweb.org/d/d13/d13-1176.pdf
 153. https://arxiv.org/abs/1409.3215
 154. http://www.cs.toronto.edu/~rkiros/papers/mnlm2014.pdf
 155. https://arxiv.org/abs/1411.4555
 156. https://github.com/oxford-cs-deepnlp-2017/lectures/blob/master/lecture 8 - conditional id38 with attention.pdf
 157. http://media.podcasts.ox.ac.uk/comlab/deep_learning_nlp/2017-01_deep_nlp_8_conditional_lang_mod_att.mp4
 158. https://arxiv.org/abs/1409.0473
 159. https://arxiv.org/pdf/1502.03044.pdf
 160. http://www.aclweb.org/anthology/n16-1102
 161. http://www.aclweb.org/anthology/p02-1040.pdf
 162. https://github.com/oxford-cs-deepnlp-2017/lectures/blob/master/lecture 9 - id103.pdf
 163. http://media.podcasts.ox.ac.uk/comlab/deep_learning_nlp/2017-01_deep_nlp_9_speech_recognition.mp4
 164. https://github.com/oxford-cs-deepnlp-2017/lectures/blob/master/lecture 10 - text to speech.pdf
 165. http://media.podcasts.ox.ac.uk/comlab/deep_learning_nlp/2017-01_deep_nlp_10_text_speech.mp4
 166. https://github.com/oxford-cs-deepnlp-2017/lectures/blob/master/lecture 11 - id53.pdf
 167. http://media.podcasts.ox.ac.uk/comlab/deep_learning_nlp/2017-01_deep_nlp_11_question_answering.mp4
 168. http://papers.nips.cc/paper/5945-teaching-machines-to-read-and-comprehend
 169. https://arxiv.org/abs/1412.1632
 170. https://github.com/oxford-cs-deepnlp-2017/lectures/blob/master/lecture 12- memory lecture.pdf
 171. http://media.podcasts.ox.ac.uk/comlab/deep_learning_nlp/2017-01_deep_nlp_12_memory.mp4
 172. http://www.nature.com/nature/journal/v538/n7626/abs/nature20101.html
 173. https://arxiv.org/abs/1509.06664
 174. http://papers.nips.cc/paper/5648-learning-to-transduce-with-unbounded-memory
 175. https://arxiv.org/abs/1503.08895
 176. https://github.com/oxford-cs-deepnlp-2017/lectures/blob/master/lecture 13 - linguistics.pdf
 177. http://media.podcasts.ox.ac.uk/comlab/deep_learning_nlp/2017-01_deep_nlp_13_linguistic_knowledge_neural.mp4
 178. https://piazza.com/ox.ac.uk/winter2017/dnlpht2017/home
 179. http://www.deepmind.com/
 180. http://www.cs.ox.ac.uk/
 181. http://www.nvidia.com/
 182. https://azure.microsoft.com/
 183. https://github.com/site/terms
 184. https://github.com/site/privacy
 185. https://github.com/security
 186. https://githubstatus.com/
 187. https://help.github.com/
 188. https://github.com/contact
 189. https://github.com/pricing
 190. https://developer.github.com/
 191. https://training.github.com/
 192. https://github.blog/
 193. https://github.com/about
 194. https://github.com/oxford-cs-deepnlp-2017/lectures
 195. https://github.com/oxford-cs-deepnlp-2017/lectures

   hidden links:
 197. https://github.com/
 198. https://github.com/oxford-cs-deepnlp-2017/lectures
 199. https://github.com/oxford-cs-deepnlp-2017/lectures
 200. https://github.com/oxford-cs-deepnlp-2017/lectures
 201. https://help.github.com/articles/which-remote-url-should-i-use
 202. https://github.com/oxford-cs-deepnlp-2017/lectures#preamble
 203. https://github.com/oxford-cs-deepnlp-2017/lectures#lecturers
 204. https://github.com/oxford-cs-deepnlp-2017/lectures#tas
 205. https://github.com/oxford-cs-deepnlp-2017/lectures#timetable
 206. https://github.com/oxford-cs-deepnlp-2017/lectures#practicals
 207. https://github.com/oxford-cs-deepnlp-2017/lectures#lectures
 208. https://github.com/oxford-cs-deepnlp-2017/lectures#lecture-materials
 209. https://github.com/oxford-cs-deepnlp-2017/lectures#1-lecture-1a---introduction-phil-blunsom
 210. https://github.com/oxford-cs-deepnlp-2017/lectures#2-lecture-1b---deep-neural-networks-are-our-friends-wang-ling
 211. https://github.com/oxford-cs-deepnlp-2017/lectures#3-lecture-2a--word-level-semantics-ed-grefenstette
 212. https://github.com/oxford-cs-deepnlp-2017/lectures#reading
 213. https://github.com/oxford-cs-deepnlp-2017/lectures#embeddings-basics
 214. https://github.com/oxford-cs-deepnlp-2017/lectures#datasets-and-visualisation
 215. https://github.com/oxford-cs-deepnlp-2017/lectures#blog-posts
 216. https://github.com/oxford-cs-deepnlp-2017/lectures#further-reading
 217. https://github.com/oxford-cs-deepnlp-2017/lectures#4-lecture-2b---overview-of-the-practicals-chris-dyer
 218. https://github.com/oxford-cs-deepnlp-2017/lectures#5-lecture-3---language-modelling-and-id56s-part-1-phil-blunsom
 219. https://github.com/oxford-cs-deepnlp-2017/lectures#reading-1
 220. https://github.com/oxford-cs-deepnlp-2017/lectures#textbook
 221. https://github.com/oxford-cs-deepnlp-2017/lectures#blogs
 222. https://github.com/oxford-cs-deepnlp-2017/lectures#6-lecture-4---language-modelling-and-id56s-part-2-phil-blunsom
 223. https://github.com/oxford-cs-deepnlp-2017/lectures#reading-2
 224. https://github.com/oxford-cs-deepnlp-2017/lectures#textbook-1
 225. https://github.com/oxford-cs-deepnlp-2017/lectures#vanishing-gradients-lstms-etc
 226. https://github.com/oxford-cs-deepnlp-2017/lectures#dealing-with-large-vocabularies
 227. https://github.com/oxford-cs-deepnlp-2017/lectures#regularisation-and-dropout
 228. https://github.com/oxford-cs-deepnlp-2017/lectures#other-stuff
 229. https://github.com/oxford-cs-deepnlp-2017/lectures#7-lecture-5---text-classification-karl-moritz-hermann
 230. https://github.com/oxford-cs-deepnlp-2017/lectures#reading-3
 231. https://github.com/oxford-cs-deepnlp-2017/lectures#8-lecture-6---deep-nlp-on-nvidia-gpus-jeremy-appleyard
 232. https://github.com/oxford-cs-deepnlp-2017/lectures#reading-4
 233. https://github.com/oxford-cs-deepnlp-2017/lectures#9-lecture-7---conditional-language-models-chris-dyer
 234. https://github.com/oxford-cs-deepnlp-2017/lectures#reading-5
 235. https://github.com/oxford-cs-deepnlp-2017/lectures#10-lecture-8---generating-language-with-attention-chris-dyer
 236. https://github.com/oxford-cs-deepnlp-2017/lectures#reading-6
 237. https://github.com/oxford-cs-deepnlp-2017/lectures#11-lecture-9---speech-recognition-asr-andrew-senior
 238. https://github.com/oxford-cs-deepnlp-2017/lectures#12-lecture-10---text-to-speech-tts-andrew-senior
 239. https://github.com/oxford-cs-deepnlp-2017/lectures#13-lecture-11---question-answering-karl-moritz-hermann
 240. https://github.com/oxford-cs-deepnlp-2017/lectures#reading-7
 241. https://github.com/oxford-cs-deepnlp-2017/lectures#14-lecture-12---memory-ed-grefenstette
 242. https://github.com/oxford-cs-deepnlp-2017/lectures#reading-8
 243. https://github.com/oxford-cs-deepnlp-2017/lectures#15-lecture-13---linguistic-knowledge-in-neural-networks
 244. https://github.com/oxford-cs-deepnlp-2017/lectures#piazza
 245. https://github.com/oxford-cs-deepnlp-2017/lectures#assessment
 246. https://github.com/oxford-cs-deepnlp-2017/lectures#acknowledgements
 247. https://github.com/
