   unpaired image-to-image translation using cycle-consistent adversarial
                                  networks

[1]jun-yan zhu*    [2]taesung park*    [3]phillip isola    [4]alexei a. efros

                               [5]uc berkeley

                                in iccv 2017

                 [6]paper | [7]pytorch code | [8]torch code

                               [9][teaser.jpg]

abstract

   image-to-image translation is a class of vision and graphics problems
   where the goal is to learn the mapping between an input image and an
   output image using a training set of aligned image pairs. however, for
   many tasks, paired training data will not be available. we present an
   approach for learning to translate an image from a source domain x to a
   target domain y in the absence of paired examples. our goal is to learn
   a mapping g: x     y such that the distribution of images from g(x) is
   indistinguishable from the distribution y using an adversarial loss.
   because this mapping is highly under-constrained, we couple it with an
   inverse mapping f: y     x and introduce a cycle consistency loss to push
   f(g(x))     x (and vice versa). qualitative results are presented on
   several tasks where paired training data does not exist, including
   collection style transfer, object transfiguration, season transfer,
   photo enhancement, etc. quantitative comparisons against several prior
   methods demonstrate the superiority of our approach.
   [10]paper thumbnail

paper

   [11]arxiv 1703.10593, 2017.

citation

   jun-yan zhu*, taesung park*, phillip isola, and alexei a. efros.
   "unpaired image-to-image translation using cycle-consistent adversarial
   networks", in ieee international conference on id161 (iccv),
   2017.
   (* indicates equal contributions) [12]bibtex

code: [13]pytorch | [14]torch

   if you have questions about our pytorch code, please check out
   [15]model training/test tips and [16]frequently asked questions.

course

   cyclegan course assignment [17]code and [18]handout designed by prof.
   [19]roger grosse for [20]"intro to neural networks and machine
   learning" at university of toronto. please contact the instructor if
   you would like to adopt this assignment in your course.

other implementations

   [21]tensorflow (harry yang) | [22]tensorflow (archit rathore) |
   [23]tensorflow (van huy) | [24]tensorflow (xiaowei hu) |
   [25]tensorlayer (luoxier)
   [26]tensorflow-simple (zhenliang he) | [27]chainer (yanghua jin) |
   [28]minimal pytorch (yunjey) | [29]mxnet (ldpe2g) | [30]lasagne/keras
   (tjwei)

                             iccv spotlight talk

            iframe: [31]https://www.youtube.com/embed/axrkvfjsbia

                       expository articles and videos

two minute papers

   iframe: [32]https://www.youtube.com/embed/d4c1db9uheq

   karoly zsolnai-feher made the above as part of his very cool [33]"two
   minute papers" series.

understanding and implementing cyclegan

   [34][cyclegan_blogs.jpg]

   nice explanation by hardik bansal and archit rathore, with tensorflow
   code documentation.

                      creative applications of cyclegan

   researchers, developers and artists have tried our code on various
   image manipulation and artistic creatiion tasks. here we highlight a
   few of the many compelling examples. search [35]cyclegan in twitter for
   more applications.

converting monet into thomas kinkade

   [36][monet_david.jpg]

   what if [37]claude monet had lived to see the rise of americana
   pastoral kitsch in the style of [38]thomas kinkade? and what if he
   resorted to it to support himself in his old age? using cyclegan, our
   great [39]david fouhey finally realized the dream of claude monet
   revisiting his cherished work in light of thomas kinkade, the
   self-stylized painter of light.

resurrecting ancient cities

   [40][ancient_maps.jpg]

   [41]jack clark used our code to convert ancient maps of [42]babylon,
   [43]jerusalem and [44]london into modern google maps and satellite
   views.

animal transfiguration

   [45][bears_pandas.jpg] [46][birds_transform2.jpg]

   [47]tatsuya hatanaka trained our method to translate black bears to
   pandas. see more examples and download the models at the [48]website.
   [49]matt powell performed transfiguration between different species of
   birds

portrait to dollface

   [50][dollface.jpg]

   [51]mario klingemann used our code to translate portraits into
   dollface. see how the characters in game of thrones look like in the
   doll world.

face     ramen

   [52][face_to_ramen.jpg]

   [53]takuya kato performed a magical and hilarious face     ramen
   translation with cyclegan. check out more results [54]here

colorizing legacy photographs

   [55][colorization.jpg]

   [56]mario klingemann trained our method to turn legacy black and white
   photos into color versions.

cats     dogs

   [57][cats2dogs.jpg]

   [58]itok_msi produced cats     dogs cyclegan results with a local+global
   discriminator and a smaller cycle loss.

the electronic curator

   iframe: [59]https://www.youtube.com/embed/4szsx4fpmxg

   eran hadas and eyal gruss used cyclegan to convert human faces into
   vegetable portraits. they built a real-time art demo which allows users
   to interact with the model with their own faces.

turning fortnite into pubg

   iframe: [60]https://www.youtube.com/embed/xkltgwwxrec

   [61]chintan trivedi used cyclegan to translate between fornite and
   purb, two popular battle royale games with hundreds of millions of
   users. now you can enjoy the gameplay of one game in the visuals of the
   other. check out his [62]blog for more cool demos.

                                popular press

          [63][forbes.jpg] [64][hackernews.jpg] [65][mashable.jpg]
        [66][engadget.jpg] [67][digital_trend.jpg] [68][dpreview.jpg]
                              [69][konbini.jpg]
       [70][wired.jpg] [71][nvidia.jpg] [72][tnw.jpg] [73][yahoo.jpg]
          [74][petapixel.jpg] [75][gizmodo.jpg] [76][horsetalk.jpg]

                          applications in our paper

monet paintings     photos

   mapping monet paintings to landscape photographs from flickr:
   [77]best results | [78]random training set results | [79]random test
   set results
   [80][painting2photo.jpg]


collection style transfer

   transferring input images into artistic styles of monet, van gogh,
   ukiyo-e, and cezanne.
   [81]results on the author's personal photos
   [82]random training set results | [83]random test set results
   [84][photo2painting.jpg]


object transfiguration

   object transfiguration between horses and zebras:
   [85]best results | [86]random training set results | [87]random test
   set results
   object transfiguration between apples and oranges:
   [88]best results | [89]random training set results | [90]random test
   set results
   [91][objects.jpg]

horse video to zebra video

   iframe: [92]https://www.youtube.com/embed/9rehvktowly


   driving applications (cg     real and day     night )

    translation between driving scenes in different style. each frame was
                           rendered independently.

                 between [93]cityscapes and [94]gta dataset

            iframe: [95]https://www.youtube.com/embed/lcr9st9mbis

   between day and night driving using the [96]berkeley deep drive dataset
                              (not public yet)

            iframe: [97]https://www.youtube.com/embed/n7kbfwodxje

      the gta     cityscapes results of cyclegan can be used for domain
                        adaptation for segmentation.
   a segmentation model trained on the cityscapes-style gta images yields
            miou of 37.0 on the segmentation task on cityscapes.
                more information can be found at [98]cycada.
      you can download the [99]original gta images (18gb) and [100]the
               translated cityscapes-style gta images (16gb).
   [gta2cityscapes.png]


season transfer

   transferring seasons of yosemite in the flickr photos:
   [101]best results | [102]random training set results | [103]random test
   set results
   [104][season.jpg]


photo enhancement

   iphone photos     dslr photos: generating photos with shallower depth of
   field.
   [105]best results | [106]random training set results | [107]random test
   set results
   [108][photo_enhancement.jpg]


experiments and comparisons

     * [109]comparison on cityscapes: different methods for mapping labels
           photos trained on cityscapes.
     * [110]comparison on maps: different methods for mapping aerialphotos
           maps on google maps.
     * [111]facade results: cyclegan for mapping labels     facades on
       [112]cmp facades datasets.
     * [113]ablation studies: different variants of our method for mapping
       labels     photos trained on cityscapes.
     * [114]image reconstruction results: the reconstructed images f(g(x))
       and g(f(y)) from various experiments.
     * [115]style transfer comparison: we compare our method with neural
       style transfer [gatys et al. '15].
     * [116]identity mapping loss: the effect of the identity mapping loss
       on monet to photo.

failure cases

   [117]failure

   our model does not work well when a test image looks unusual compared
   to training images, as shown in the left figure. see more typical
   failure cases [118][here]. on translation tasks that involve color and
   texture changes, like many of those reported above, the method often
   succeeds. we have also explored tasks that require geometric changes,
   with little success. for example, on the task of dog     cat
   transfiguration, the learned translation degenerates into making
   minimal changes to the input. handling more varied and extreme
   transformations, especially geometric changes, is an important problem
   for future work. we also observe a lingering gap between the results
   achievable with paired training data and those achieved by our unpaired
   method. in some cases, this gap may be very hard -- or even impossible,
   -- to close: for example, our method sometimes permutes the labels for
   tree and building in the output of the cityscapes photos     labels task.
   to resolve this ambiguity may require some form of weak semantic
   supervision. integrating weak or semi-supervised data may lead to
   substantially more powerful translators, still at a fraction of the
   annotation cost of the fully-supervised systems.

meet the authors of cyclegan

   iframe:
   [119]https://www.youtube.com/embed/05zzhkyofle?rel=0&autoplay=1;loop=1;
   playlist=05zzhkyofle

related work

     * ian j. goodfellow, jean pouget-abadie, mehdi mirza, bing xu, david
       warde-farley, sherjil ozair, aaron courville, yoshua bengio
       [120]"id3", in nips 2014.
     * alec radford, luke metz and soumith chintala [121]"unsupervised
       representation learning with deep convolutional generative
       adversarial networks", in iclr 2016.
     * jun-yan zhu, philipp kr  henb  hl, eli shechtman, and alexei a.
       efros. [122]"generative visual manipulation on the natural image
       manifold", in eccv 2016.
     * phillip isola, jun-yan zhu, tinghui zhou, and alexei a. efros.
       [123]"image-to-image translation with conditional adversarial
       networks", in cvpr 2017.

acknowledgement

   we thank aaron hertzmann, shiry ginosar, deepak pathak, bryan russell,
   eli shechtman, richard zhang, and tinghui zhou for many helpful
   comments. this work was supported in part by nsf sma-1514512, nsf
   iis-1633310, a google research award, intel corp, and hardware
   donations from nvidia. jyz is supported by the facebook graduate
   fellowship, and tp is supported by the samsung scholarship. the
   photographs used in style transfer were taken by ae, mostly in france.

   [124]web page statistics from gostats

references

   1. http://www.eecs.berkeley.edu/~junyanz/
   2. https://taesung.me/
   3. http://web.mit.edu/phillipi/
   4. http://www.eecs.berkeley.edu/~efros/
   5. http://bair.berkeley.edu/
   6. https://arxiv.org/pdf/1703.10593.pdf
   7. https://github.com/junyanz/pytorch-cyclegan-and-pix2pix
   8. https://github.com/junyanz/cyclegan
   9. https://junyanz.github.io/cyclegan/images/teaser_high_res.jpg
  10. https://arxiv.org/pdf/1703.10593.pdf
  11. https://arxiv.org/pdf/1703.10593.pdf
  12. https://junyanz.github.io/cyclegan/cyclegan.txt
  13. https://github.com/junyanz/pytorch-cyclegan-and-pix2pix
  14. https://github.com/junyanz/cyclegan
  15. https://github.com/junyanz/pytorch-cyclegan-and-pix2pix/blob/master/docs/tips.md
  16. https://github.com/junyanz/pytorch-cyclegan-and-pix2pix/blob/master/docs/qa.md
  17. http://www.cs.toronto.edu/~rgrosse/courses/csc321_2018/assignments/a4-code.zip
  18. http://www.cs.toronto.edu/~rgrosse/courses/csc321_2018/assignments/a4-handout.pdf
  19. http://www.cs.toronto.edu/~rgrosse/
  20. http://www.cs.toronto.edu/~rgrosse/courses/csc321_2018/
  21. https://github.com/leehomyc/cyclegan-1
  22. https://github.com/architrathore/cyclegan/
  23. https://github.com/vanhuyz/cyclegan-tensorflow
  24. https://github.com/xhujoy/cyclegan-tensorflow
  25. https://github.com/luoxier/cyclegan_tensorlayer
  26. https://github.com/lynnho/cyclegan-tensorflow-simple
  27. https://github.com/aixile/chainer-cyclegan
  28. https://github.com/yunjey/mnist-svhn-transfer
  29. https://github.com/ldpe2g/deeplearningforfun/tree/master/mxnet-scala/cyclegan
  30. https://github.com/tjwei/ganotebooks
  31. https://www.youtube.com/embed/axrkvfjsbia
  32. https://www.youtube.com/embed/d4c1db9uheq
  33. https://www.youtube.com/channel/ucbfypyitq-7l4upox8nvctg
  34. https://hardikbansal.github.io/cycleganblog/
  35. https://twitter.com/search?q=cyclegan&src=typd
  36. https://people.eecs.berkeley.edu/~dfouhey/fun/monet/index.html
  37. https://en.wikipedia.org/wiki/claude_monet
  38. https://en.wikipedia.org/wiki/thomas_kinkade
  39. https://people.eecs.berkeley.edu/~dfouhey/
  40. https://jack-clark.net/2017/06/05/import-ai-issue-45/
  41. https://jack-clark.net/about/
  42. https://twitter.com/jackclarksf/status/870148599052500993
  43. https://twitter.com/jackclarksf/status/870935487313100800
  44. https://twitter.com/jackclarksf/status/870115860639121408
  45. https://github.com/tatsuyah/cyclegan-models
  46. https://junyanz.github.io/cyclegan/images/birds_transform.jpg
  47. https://github.com/tatsuyah
  48. https://github.com/tatsuyah/cyclegan-models
  49. https://twitter.com/jointid178
  50. https://twitter.com/quasimondo/status/868912712180518912
  51. http://quasimondo.com/
  52. https://junyanz.github.io/cyclegan/images/faces_and_ramens.jpg
  53. https://sites.google.com/site/liltak2takuyakato/
  54. https://junyanz.github.io/cyclegan/images/faces_and_ramens.jpg
  55. https://twitter.com/quasimondo/status/867023499214413830
  56. http://quasimondo.com/
  57. http://qiita.com/itok_msi/items/b6b615bc28b1a720afd7#                  20170614      7
  58. http://qiita.com/itok_msi
  59. https://www.youtube.com/embed/4szsx4fpmxg
  60. https://www.youtube.com/embed/xkltgwwxrec
  61. https://towardsdatascience.com/@chintan.t93
  62. https://towardsdatascience.com/turning-fortnite-into-pubg-with-deep-learning-cyclegan-2f9d339dcdb0
  63. https://www.forbes.com/sites/quora/2017/07/21/whats-next-for-deep-learning/#2b758c631002
  64. https://news.ycombinator.com/item?id=14004329
  65. http://mashable.com/2017/04/03/ucberkeley-bair-image-translation/#j9lyvbqrmsqg
  66. https://www.engadget.com/2017/04/03/reverse-prisma-ai-turns-monet-paintings-into-photos/
  67. https://www.digitaltrends.com/photography/uc-berkeley-ai-software-unpaired-image-transfer/
  68. https://www.dpreview.com/news/0947543575/image-style-ai-can-convert-paintings-to-photographs
  69. http://www.konbini.com/us/lifestyle/cycle-gan-app-turn-paintings-into-photos/
  70. https://www.wired.com/story/future-of-artificial-intelligence-2018/
  71. https://blogs.nvidia.com/blog/d2017/05/17/generative-adversarial-network/
  72. https://thenextweb.com/artificial-intelligence/2017/04/19/artificial-intelligence-turn-horse-zebra/#.tnw_vlytdj53
  73. https://www.yahoo.com/tech/researchers-invent-opposite-prisma-science-195146532.html
  74. https://petapixel.com/2017/04/03/ai-can-convert-paintings-photos-summer-winter/
  75. http://gizmodo.com/someone-finally-hijacked-deep-learning-tech-to-create-m-1793957126
  76. http://www.horsetalk.co.nz/2017/04/23/algorithm-party-trick-horses-zebras/#axzz4j5orhvud
  77. https://taesungp.github.io/cyclegan/2017/03/25/monet-to-photo-summary.html
  78. https://taesungp.github.io/cyclegan/2017/03/25/monet-to-photo-trainset.html
  79. https://taesung.github.io/cyclegan/2017/03/25/monet-to-photo-testset.html
  80. https://junyanz.github.io/cyclegan/images/painting2photo.jpg
  81. https://taesungp.github.io/cyclegan/2017/03/25/style-transfer-supplemental.html
  82. https://taesungp.github.io/cyclegan/2017/03/25/style-transfer-train.html
  83. https://taesungp.github.io/cyclegan/2017/03/25/style-transfer-test.html
  84. https://junyanz.github.io/cyclegan/images/photo2painting.jpg
  85. https://taesungp.github.io/cyclegan/2017/03/25/horse-to-zebra-supplemental-best.html
  86. https://taesungp.github.io/cyclegan/2017/03/25/horse-to-zebra-supplemental-train.html
  87. https://taesungp.github.io/cyclegan/2017/03/25/horse-to-zebra-supplemental-test.html
  88. https://taesungp.github.io/cyclegan/2017/03/25/apple-to-orange-supplemental-best.html
  89. https://taesungp.github.io/cyclegan/2017/03/25/supplemental-apple-to-orange-train.html
  90. https://taesungp.github.io/cyclegan/2017/03/25/supplemental-apple-to-orange-test.html
  91. https://junyanz.github.io/cyclegan/images/objects.jpg
  92. https://www.youtube.com/embed/9rehvktowly
  93. https://www.cityscapes-dataset.com/
  94. https://download.visinf.tu-darmstadt.de/data/from_games/
  95. https://www.youtube.com/embed/lcr9st9mbis
  96. https://deepdrive.berkeley.edu/
  97. https://www.youtube.com/embed/n7kbfwodxje
  98. https://arxiv.org/abs/1711.03213
  99. http://efrosgans.eecs.berkeley.edu/cyclegta/gta.zip
 100. http://efrosgans.eecs.berkeley.edu/cyclegta/cyclegta.zip
 101. https://taesungp.github.io/cyclegan/2017/03/25/yosemite-supplemental-best.html
 102. https://taesungp.github.io/cyclegan/2017/03/25/yosemite-supplemental-train.html
 103. https://taesungp.github.io/cyclegan/2017/03/25/yosemite-supplemental-test.html
 104. https://junyanz.github.io/cyclegan/images/season.jpg
 105. https://taesungp.github.io/cyclegan/2017/03/25/iphone-to-dslr-flower-best.html
 106. https://taesungp.github.io/cyclegan/2017/03/25/iphone-to-dslr-flower-train-random.html
 107. https://taesungp.github.io/cyclegan/2017/03/25/iphone-to-dslr-flower-test-random.html
 108. https://junyanz.github.io/cyclegan/images/photo_enhancement.jpg
 109. https://taesungp.github.io/cyclegan/2017/03/25/cityscapes-comparison.html
 110. https://taesungp.github.io/cyclegan/2017/03/25/maps-comparison.html
 111. https://taesungp.github.io/cyclegan/2017/03/25/facades.html
 112. http://cmp.felk.cvut.cz/~tylecr1/facade/
 113. https://taesungp.github.io/cyclegan/2017/03/25/cityscapes-ablation.html
 114. https://taesungp.github.io/cyclegan/2017/03/25/reconstructed-images.html
 115. https://taesungp.github.io/cyclegan/2017/03/25/gatys-comparison.html
 116. https://taesungp.github.io/cyclegan/2017/03/25/monet-to-photo-idt-comparison.html
 117. https://junyanz.github.io/cyclegan/images/failure_putin.jpg
 118. https://junyanz.github.io/cyclegan/images/failures.jpg
 119. https://www.youtube.com/embed/05zzhkyofle?rel=0&autoplay=1;loop=1;playlist=05zzhkyofle
 120. https://arxiv.org/abs/1406.2661
 121. https://arxiv.org/abs/1511.06434
 122. https://efrosgans.eecs.berkeley.edu/igan
 123. https://phillipi.github.io/pix2pix/
 124. http://gostats.com/
