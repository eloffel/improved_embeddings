   #[1]stswiki (en-gb) [2]stswiki atom feed

stsbenchmark

   from stswiki
   jump to: [3]navigation, [4]search

contents

     * [5]1 sts benchmark dataset and companion dataset
     * [6]2 results
     * [7]3 companion
     * [8]4 reference
     * [9]5 contact

sts benchmark dataset and companion dataset

   sts benchmark comprises a selection of the english datasets used in the
   sts tasks organized in the context of semeval between 2012 and 2017.
   the selection of datasets include text from image captions, news
   headlines and user forums.

   in order to provide a standard benchmark to compare among meaning
   representation systems in future years, we organized it into train,
   development and test. the development part can be used to develop and
   tune hyperparameters of the systems, and the test part should be only
   used once for the final system. some authors (e.g. [10]arora et al.
   2017; [11]mu et al. 2017; [12]wieting et al. 2016) report the results
   across different years, with a mixture of many genres and training
   conditions. sts benchmark provides a standard setup for training,
   development and test on three selected genres (news, captions, forums).

   see semeval 2017 task paper (section 8 [13]here).

   download [14]here.

   also included in [15]senteval

   the benchmark comprises 8628 sentence pairs. this is the breakdown
   according to genres and train-dev-test splits:
               train  dev test total
       -----------------------------
       news     3299  500  500  4299
       caption  2000  625  625  3250
       forum     450  375  254  1079
       -----------------------------
       total    5749 1500 1379  8628

   for reference, this is the breakdown according to the original names
   and task years of the datasets:
 genre     file           years   train  dev test
 ------------------------------------------------
 news      msrpar         2012     1000  250  250
 news      headlines      2013-16  1999  250  250
 news      deft-news      2014      300    0    0
 captions  msrvid         2012     1000  250  250
 captions  images         2014-15  1000  250  250
 captions  track5.en-en   2017        0  125  125
 forum     deft-forum     2014      450    0    0
 forum     answers-forums 2015        0  375    0
 forum     answer-answer  2016        0    0  254


results

   we report systems in two tables: in the top table we report systems
   that use neural representation models alone, and in the other table we
   report feature engineered and mixed systems.

   for each system we further detail two traits:
     * sentence representation model used in the system:
          + independent: systems that are solely based on a pair of
            sentence representations that are computed independently of
            one another
          + other: systems that also use interactions between sentences
            (e.g. alignments, attention or other features like word
            overlap)
     * amount of supervision used by the system:
          + unsupervised: systems that do not use any sts train or
            development data (can include id21, or resources
            like id138 or ppdb)
          + dev: systems that only use the sts benchmark development data
            (weakly supervised)
          + train: systems that only use the sts benchmark training and
            development data (fully supervised)
          + unconstrained: systems that in addition to sts benchmark use
            other sts training data like sick or semeval 2015 task 1

   caption: neural representation models

   sentence representation supervision paper comments dev test
   independent unsupervised [16]pennington et al. 14 glove ^1 52.4 40.6
   [17]joulin et al., 2016 fastext ^1 65.3 53.6
   [18]salle et al., 2016 lexvec ^1 68.9 55.8
   [19]mikolov et al. 13 id97 skipgram ^1 70.0 56.5
   [20]duma and menzel, 17 doc2vec (sef@uhh^3) 61.6 59.2
   [21]pham et al. 15 c-phrase ^1 74.3 63.9
   [22]le and mikolov, 14; [23]lau and baldwin, 16 pv-dbow paragraph
   vectors, doc2vec dbow ^1 72.2 64.9
   [24]wieting et al. 16b charagram (uses ppdb) ^2 76.8 71.6
   [25]wieting et al. 16a paragram-phrase (uses ppdb) ^2 73.9 73.2
   [26]conneau et al. 17 infersent (bi-lstm trained on snli) ^2 80.1 75.8
   [27]pagliardini et al. 17 sent2vec ^1 78.7 75.5
   [28]yang et al. 2018 conversation response prediction + snli 81.4 78.2
   [29]ethayarajh et al. 2018 unsupervised sif on paraid4 vectors ^2 84.2
   79.5
   dev [30]arora et al. 17 sif on glove vectors ^1 80.1 72.0
   [31]wieting et al. 17 gran (uses simpwiki) ^2 81.8 76.4
   train [32]tai et al. 15 lstm ^1 75.0 70.5
   [33]tai et al. 15 bilstm ^1 76.0 71.1
   [34]tai et al. 15 dependency tree-lstm ^1 76.0 71.2
   [35]tai et al. 15 constituency tree-lstm ^1 77.0 71.9
   [36]yang et al. 2018 conversation response prediction + snli 83.5 80.8
   other train [37]yang, 17 id98 (hcti^3) 83.4 78.4

   caption: feature engineered and mixed systems

   sentence representation supervision paper comments dev test
   other train [38]al-natsheh et al. 17 mixed ensemble (udl^3) 79.0 72.4
   [39]maharjan et al. 17 mixed ensemble (dt_team^3) 83.0 79.2
   [40]wu et al. 17 id138+alignment+embeddings (bit^3) 82.9 80.9
   [41]tian et al. 17 ^2 mixed ensemble (ecnu^3) 84.7 81.0

   notes:

   1 software trained and tested by us (see [42]details)

   2 results reported by personal communication

   3 semeval 2017 participant team

companion

   the companion datasets to the sts benchmark comprise the rest of the
   english datasets used in the sts tasks organized by us in the context
   of semeval between 2012 and 2017.

   we collated two datasets, one with pairs of sentences related to
   machine translation evaluation. another one with the rest of datasets,
   which can be used for id20 studies.

   download [43]here.

   for reference, this is the breakdown according to the original names
   and task years of the datasets:

   mt-related datasets: sts-mt.csv
    file              years pairs
    -----------------------------
    smtnews            2012   399
    smteuroparl        2012  1293
    postediting        2016   244

   other datasets: sts-other.csv
    file              years pairs
    -----------------------------
    onwn               2012   750
    onwn               2013   561
    onwn               2014   750
    fnwn               2013   189
    tweet-news         2014   750
    belief             2015   375
    plagiarism         2016   230
    question-question  2016   209

   note, the 2013 smt dataset is available through ldc only.

reference

   daniel cer, mona diab, eneko agirre, i  igo lopez-gazpio, and lucia
   specia (2017) semeval-2017 task 1: semantic textual similarity
   multilingual and cross-lingual focused evaluation proceedings of the
   10th international workshop on semantic evaluation (semeval 2017)
   [44][1]

contact

   [45]eneko agirre
   retrieved from
      [46]http://u026638.si.ehu.es/stswiki/index.php?title=stsbenchmark&oldi
   d=8   

navigation menu

personal tools

     * [47]log in

namespaces

     * [48]page
     * [49]discussion

   [ ]

variants

views

     * [50]read
     * [51]view source
     * [52]view history

   [ ]

more

search

   ____________________ search go

navigation

     * [53]main page
     * [54]recent changes
     * [55]random page
     * [56]help

tools

     * [57]what links here
     * [58]related changes
     * [59]special pages
     * [60]printable version
     * [61]permanent link
     * [62]page information

     * this page was last modified on 22 january 2019, at 14:59.

     * [63]privacy policy
     * [64]about stswiki
     * [65]disclaimers

     * [66]powered by mediawiki

references

   visible links
   1. http://ixa2.si.ehu.es/stswiki/opensearch_desc.php
   2. http://ixa2.si.ehu.es/stswiki/index.php?title=special:recentchanges&feed=atom
   3. http://ixa2.si.ehu.es/stswiki/index.php/stsbenchmark#mw-head
   4. http://ixa2.si.ehu.es/stswiki/index.php/stsbenchmark#p-search
   5. http://ixa2.si.ehu.es/stswiki/index.php/stsbenchmark#sts_benchmark_dataset_and_companion_dataset
   6. http://ixa2.si.ehu.es/stswiki/index.php/stsbenchmark#results
   7. http://ixa2.si.ehu.es/stswiki/index.php/stsbenchmark#companion
   8. http://ixa2.si.ehu.es/stswiki/index.php/stsbenchmark#reference
   9. http://ixa2.si.ehu.es/stswiki/index.php/stsbenchmark#contact
  10. https://openreview.net/pdf?id=syk00v5xx
  11. https://arxiv.org/abs/1702.01417
  12. https://arxiv.org/abs/1511.08198
  13. http://www.aclweb.org/anthology/s/s17/s17-2001.pdf
  14. http://ixa2.si.ehu.es/stswiki/images/4/48/stsbenchmark.tar.gz
  15. https://github.com/facebookresearch/senteval
  16. https://nlp.stanford.edu/pubs/glove.pdf
  17. https://arxiv.org/abs/1607.01759
  18. https://arxiv.org/pdf/1606.01283v1
  19. https://arxiv.org/abs/1301.3781
  20. http://nlp.arizona.edu/semeval-2017/pdf/semeval024.pdf
  21. http://clic.cimec.unitn.it/marco/publications/acl2015/pham-et-al-cphrase-acl2015.pdf
  22. https://arxiv.org/abs/1405.4053
  23. https://arxiv.org/abs/1607.05368,
  24. http://ttic.uchicago.edu/~wieting/wieting2016charagram.pdf
  25. http://ttic.uchicago.edu/~wieting/wieting2016iclr.pdf
  26. https://arxiv.org/abs/1705.02364
  27. https://arxiv.org/abs/1703.02507
  28. https://arxiv.org/abs/1804.07754
  29. http://aclweb.org/anthology/w18-3012
  30. https://openreview.net/pdf?id=syk00v5xx
  31. http://ttic.uchicago.edu/~wieting/wieting2017recurrent.pdf
  32. http://www.aclweb.org/anthology/p15-1150
  33. http://www.aclweb.org/anthology/p15-1150
  34. http://www.aclweb.org/anthology/p15-1150
  35. http://www.aclweb.org/anthology/p15-1150
  36. https://arxiv.org/abs/1804.07754
  37. http://nlp.arizona.edu/semeval-2017/pdf/semeval016.pdf
  38. http://nlp.arizona.edu/semeval-2017/pdf/semeval013.pdf
  39. http://nlp.arizona.edu/semeval-2017/pdf/semeval014.pdf
  40. http://nlp.arizona.edu/semeval-2017/pdf/semeval007.pdf
  41. http://nlp.arizona.edu/semeval-2017/pdf/semeval028.pdf
  42. http://ixa2.si.ehu.es/stswiki/index.php/sts_benchmark_reproducibility
  43. http://ixa2.si.ehu.es/stswiki/images/e/ee/stscompanion.tar.gz
  44. http://nlp.arizona.edu/semeval-2017/pdf/semeval001.pdf
  45. mailto:e.surnamehere_at_ehu_dot_eus
  46. http://u026638.si.ehu.es/stswiki/index.php?title=stsbenchmark&oldid=8
  47. http://ixa2.si.ehu.es/stswiki/index.php?title=special:userlogin&returnto=stsbenchmark
  48. http://ixa2.si.ehu.es/stswiki/index.php/stsbenchmark
  49. http://ixa2.si.ehu.es/stswiki/index.php?title=talk:stsbenchmark&action=edit&redlink=1
  50. http://ixa2.si.ehu.es/stswiki/index.php/stsbenchmark
  51. http://ixa2.si.ehu.es/stswiki/index.php?title=stsbenchmark&action=edit
  52. http://ixa2.si.ehu.es/stswiki/index.php?title=stsbenchmark&action=history
  53. http://ixa2.si.ehu.es/stswiki/index.php/main_page
  54. http://ixa2.si.ehu.es/stswiki/index.php/special:recentchanges
  55. http://ixa2.si.ehu.es/stswiki/index.php/special:random
  56. https://www.mediawiki.org/wiki/special:mylanguage/help:contents
  57. http://ixa2.si.ehu.es/stswiki/index.php/special:whatlinkshere/stsbenchmark
  58. http://ixa2.si.ehu.es/stswiki/index.php/special:recentchangeslinked/stsbenchmark
  59. http://ixa2.si.ehu.es/stswiki/index.php/special:specialpages
  60. http://ixa2.si.ehu.es/stswiki/index.php?title=stsbenchmark&printable=yes
  61. http://ixa2.si.ehu.es/stswiki/index.php?title=stsbenchmark&oldid=8
  62. http://ixa2.si.ehu.es/stswiki/index.php?title=stsbenchmark&action=info
  63. http://ixa2.si.ehu.es/stswiki/index.php/stswiki:privacy_policy
  64. http://ixa2.si.ehu.es/stswiki/index.php/stswiki:about
  65. http://ixa2.si.ehu.es/stswiki/index.php/stswiki:general_disclaimer
  66. http://www.mediawiki.org/

   hidden links:
  68. http://ixa2.si.ehu.es/stswiki/index.php/main_page
