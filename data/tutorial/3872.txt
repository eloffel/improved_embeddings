   #[1]publisher [2]medium [3]alternate

   [4]homepage
   [5]homepage
   [6]become a member[7]sign in[8]get started
     __________________________________________________________________

how to build a recurrent neural network in tensorflow (1/7)

   [9]go to the profile of erik hallstr  m
   [10]erik hallstr  m (button) blockedunblock (button) followfollowing
   nov 10, 2016

   in this tutorial i   ll explain how to build a simple working recurrent
   neural network in tensorflow. this is the first in a series of seven
   parts where various aspects and techniques of building recurrent neural
   networks in tensorflow are covered. a short introduction to tensorflow
   is [11]available here. for now, let   s get started with the id56!

what is a id56?

   it is short for    recurrent neural network   , and is basically a neural
   network that can be used when your data is treated as a sequence, where
   the particular order of the data-points matter. more importantly, this
   sequence can be of arbitrary length.

   the most straight-forward example is perhaps a time-series of numbers,
   where the task is to predict the next value given previous values. the
   input to the id56 at every time-step is the current value as well as a
   state vector which represent what the network has    seen    at time-steps
   before. this state-vector is the encoded memory of the id56, initially
   set to zero.
   [1*uki9za9ztr-hl8um15wmzw.png]
   schematic of a id56 processing sequential data over time.

   the best and most comprehensive article explaining id56:s i   ve found so
   far is [12]this article by researchers at ucsd, highly recommended. for
   now you only need to understand the basics, read it until the    modern
   id56 architectures   -section. that will be covered later.

   although this article contains some explanations, it is mostly focused
   on the practical part, how to build it. you are encouraged to look up
   more theory on the internet, there are plenty of good explanations.

setup

   we will build a simple echo-id56 that remembers the input data and then
   echoes it after a few time-steps. first let   s set some constants we   ll
   need, what they mean will become clear in a moment.

   iframe: [13]/media/3121ad24d21439dd962987d0272bd90b?postid=83cd7105b767

generate data

   now generate the training data, the input is basically a random binary
   vector. the output will be the    echo    of the input, shifted echo_step
   steps to the right.

   iframe: [14]/media/f8f7cc7ac17c8d5b4ca88389eee93a9b?postid=83cd7105b767

   notice the reshaping of the data into a matrix with batch_size rows.
   neural networks are trained by approximating the gradient of loss
   function with respect to the neuron-weights, by looking at only a small
   subset of the data, also known as a mini-batch. the theoretical reason
   for doing this is further elaborated in [15]this question. the
   reshaping takes the whole dataset and puts it into a matrix, that later
   will be sliced up into these mini-batches.
   [1*aftwufsbolv8z5pkeznlxa.png]
   schematic of the reshaped data-matrix, arrow curves shows adjacent
   time-steps that ended up on different rows. light-gray rectangle
   represent a    zero    and dark-gray a    one   .

building the computational graph

   tensorflow works by first building up a computational graph, that
   specifies what operations will be done. the input and output of this
   graph is typically multidimensional arrays, also known as tensors. the
   graph, or parts of it can then be executed iteratively in a session,
   this can either be done on the cpu, gpu or even a resource on a remote
   server.

variables and placeholders

   the two basic tensorflow data-structures that will be used in this
   example are placeholders and variables. on each run the batch data is
   fed to the placeholders, which are    starting nodes    of the
   computational graph. also the id56-state is supplied in a placeholder,
   which is saved from the output of the previous run.

   iframe: [16]/media/c8fe3cba4266df3e1b70348e69b5e552?postid=83cd7105b767

   the weights and biases of the network are declared as tensorflow
   variables, which makes them persistent across runs and enables them to
   be updated incrementally for each batch.

   iframe: [17]/media/f7f2e43ab1f817cf1e277ed703edb9c7?postid=83cd7105b767

   the figure below shows the input data-matrix, and the current batch
   batchx_placeholder is in the dashed rectangle. as we will see later,
   this    batch window    is slided truncated_backprop_length steps to the
   right at each run, hence the arrow. in our example below batch_size =
   3, truncated_backprop_length = 3, and total_series_length = 36. note
   that these numbers are just for visualization purposes, the values are
   different in the code. the series order index is shown as numbers in a
   few of the data-points.
   [1*n45uynaftdrbvg87j-poca.jpeg]
   schematic of the training data, the current batch is sliced out in the
   dashed rectangle. the time-step index of the datapoint is displayed.

unpacking

   now it   s time to build the part of the graph that resembles the actual
   id56 computation, first we want to split the batch data into adjacent
   time-steps.

   iframe: [18]/media/85a1d97adf6955549d5f66ebb837b890?postid=83cd7105b767

   as you can see in the picture below that is done by unpacking the
   columns (axis = 1) of the batch into a python list. the id56 will
   simultaneously be training on different parts in the time-series; steps
   4 to 6, 16 to 18 and 28 to 30 in the current batch-example. the reason
   for using the variable names    plural   _   series    is to emphasize that the
   variable is a list that represent a time-series with multiple entries
   at each step.
   [1*f2il4zokbubgopve7kyajg.png]
   schematic of the current batch split into columns, the order index is
   shown on each data-point and arrows show adjacent time-steps.

   the fact that the training is done on three places simultaneously in
   our time-series, requires us to save three instances of states when
   propagating forward. that has already been accounted for, as you see
   that the init_state placeholder has batch_size rows.

forward pass

   next let   s build the part of the graph that does the actual id56
   computation.

   iframe: [19]/media/9ff4a9e31a1f25349e953bf04fff59de?postid=83cd7105b767

   notice the concatenation on line 6, what we actually want to do is
   calculate the sum of two affine transforms current_input * wa +
   current_state * wb in the figure below. by concatenating those two
   tensors you will only use one id127. the addition of
   the bias b is [20]broadcasted on all samples in the batch.
   [1*fdwnnj5uoe3sx0r_cyfmyg.png]
   schematic of the computations of the matrices on line 8 in the code
   example above, the non-linear transform arctan is omitted.

   you may wonder the variable name truncated_backprop_length is supposed
   to mean. when a id56 is trained, it is actually treated as a deep neural
   network with reoccurring weights in every layer. these layers will not
   be unrolled to the beginning of time, that would be too computationally
   expensive, and are therefore truncated at a limited number of
   time-steps. in our sample schematics above, the error is backpropagated
   three steps in our batch.

calculating loss

   this is the final part of the graph, a fully connected softmax layer
   from the state to the output that will make the classes one-hot
   encoded, and then calculating the loss of the batch.

   iframe: [21]/media/c3ab1f7a5112754409c78c08667b6eca?postid=83cd7105b767

   the last line is adding the training functionality, tensorflow will
   perform back-propagation for us automatically         the computation graph
   is executed once for each mini-batch and the network-weights are
   updated incrementally.

   notice the api call to sparse_softmax_cross_id178_with_logits, it
   automatically calculates the softmax internally and then computes the
   cross-id178. in our example the classes are mutually exclusive (they
   are either zero or one), which is the reason for using the
      sparse-softmax   , you can read more about it in [22]the api. the usage
   is to havelogits is of shape [batch_size, num_classes] and labels of
   shape [batch_size].

visualizing the training

   there is a visualization function so we can se what   s going on in the
   network as we train. it will plot the loss over the time, show training
   input, training output and the current predictions by the network on
   different sample series in a training batch.

   iframe: [23]/media/e71e53dfd4174dca5be06db4785da6ab?postid=83cd7105b767

running a training session

   it   s time to wrap up and train the network, in tensorflow the graph is
   executed in a session. new data is generated on each epoch (not the
   usual way to do it, but it works in this case since everything is
   predictable).

   iframe: [24]/media/21c4b66a2db0c05c9d768d1b719f3d32?postid=83cd7105b767

   you can see that we are moving truncated_backprop_length steps forward
   on each iteration (line 15   19), but it is possible have different
   strides. this subject is further elaborated in [25]this article. the
   downside with doing this is that truncated_backprop_length need to be
   significantly larger than the time dependencies (three steps in our
   case) in order to encapsulate the relevant training data. otherwise
   there might a lot of    misses   , as you can see on the figure below.
   [1*ukuukp_m55zapczaiemuca.png]
   time series of squares, the elevated black square symbolizes an
   echo-output, which is activated three steps from the echo input (black
   square). the sliding batch window is also striding three steps at each
   run, which in our sample case means that no batch will encapsulate the
   dependency, so it can not train.

   also realize that this is just simple example to explain how a id56
   works, this functionality could easily be programmed in just a few
   lines of code. the network will be able to exactly learn the echo
   behavior so there is no need for testing data.

   the program will update the plot as training progresses, shown in the
   picture below. blue bars denote a training input signal (binary one),
   red bars show echos in the training output and green bars are the echos
   the net is generating. the different bar plots show different sample
   series in the current batch.

   our algorithm will fairly quickly learn the task. the graph in the
   top-left corner shows the output of the id168, but why are
   there spikes in the curve? think of it for a moment, answer is below.
   [1*ytqumdmgmjo0-3kxmci1gg.png]
   visualization of the loss, input and output training data (blue, red)
   as well as the prediction (green).

   the reason for the spikes is that we are starting on a new epoch, and
   generating new data. since the matrix is reshaped, the first element on
   each row is adjacent to the last element in the previous row. the first
   few elements on all rows (except the first) have dependencies that will
   not be included in the state, so the net will always perform badly on
   the first batch.

whole program

   this is the whole runnable program, just copy-paste and run. after each
   part in the article series the whole runnable program will be
   presented. if a line is referenced by number, these are the line
   numbers that we mean.

   iframe: [26]/media/69ee83ad87c17530dc7ed5a68b7898c9?postid=83cd7105b767

next step

   in [27]the next post in this series we will be simplify the
   computational graph creation by using the native tensorflow id56 api.

     * [28]machine learning
     * [29]artificial intelligence
     * [30]deep learning
     * [31]tensorflow
     * [32]recurrent neural network

   (button)
   (button)
   (button) 3.3k claps
   (button) (button) (button) 42 (button) (button)

     (button) blockedunblock (button) followfollowing
   [33]go to the profile of erik hallstr  m

[34]erik hallstr  m

   studied engineering physics and in machine learning at royal institute
   of technology in stockholm. also been living in taiwan             . interested
   in deep learning.

     * (button)
       (button) 3.3k
     * (button)
     *
     *

   [35]go to the profile of erik hallstr  m
   never miss a story from erik hallstr  m, when you sign up for medium.
   [36]learn more
   never miss a story from erik hallstr  m
   (button) blockedunblock (button) followget updates

references

   visible links
   1. https://plus.google.com/103654360130207659246
   2. https://medium.com/osd.xml
   3. android-app://com.medium.reader/https/medium.com/p/83cd7105b767
   4. https://medium.com/
   5. https://medium.com/
   6. https://medium.com/membership?source=upgrade_membership---nav_full
   7. https://medium.com/m/signin?redirect=https://medium.com/@erikhallstrm/hello-world-id56-83cd7105b767&source=--------------------------nav_reg&operation=login
   8. https://medium.com/m/signin?redirect=https://medium.com/@erikhallstrm/hello-world-id56-83cd7105b767&source=--------------------------nav_reg&operation=register
   9. https://medium.com/@erikhallstrm?source=post_header_lockup
  10. https://medium.com/@erikhallstrm
  11. https://medium.com/@erikhallstrm/hello-world-tensorflow-649b15aed18c#.kogbhxazp
  12. https://arxiv.org/pdf/1506.00019.pdf
  13. https://medium.com/media/3121ad24d21439dd962987d0272bd90b?postid=83cd7105b767
  14. https://medium.com/media/f8f7cc7ac17c8d5b4ca88389eee93a9b?postid=83cd7105b767
  15. https://www.quora.com/in-deep-learning-why-dont-we-use-the-whole-training-set-to-compute-the-gradient/answer/ian-goodfellow?srid=9kxj
  16. https://medium.com/media/c8fe3cba4266df3e1b70348e69b5e552?postid=83cd7105b767
  17. https://medium.com/media/f7f2e43ab1f817cf1e277ed703edb9c7?postid=83cd7105b767
  18. https://medium.com/media/85a1d97adf6955549d5f66ebb837b890?postid=83cd7105b767
  19. https://medium.com/media/9ff4a9e31a1f25349e953bf04fff59de?postid=83cd7105b767
  20. https://docs.scipy.org/doc/numpy/user/basics.broadcasting.html
  21. https://medium.com/media/c3ab1f7a5112754409c78c08667b6eca?postid=83cd7105b767
  22. https://www.tensorflow.org/versions/r0.11/api_docs/python/nn.html#sparse_softmax_cross_id178_with_logits
  23. https://medium.com/media/e71e53dfd4174dca5be06db4785da6ab?postid=83cd7105b767
  24. https://medium.com/media/21c4b66a2db0c05c9d768d1b719f3d32?postid=83cd7105b767
  25. http://r2rt.com/styles-of-truncated-id26.html
  26. https://medium.com/media/69ee83ad87c17530dc7ed5a68b7898c9?postid=83cd7105b767
  27. https://medium.com/@erikhallstrm/tensorflow-id56-api-2bb31821b185#.u3wew5ck0
  28. https://medium.com/tag/machine-learning?source=post
  29. https://medium.com/tag/artificial-intelligence?source=post
  30. https://medium.com/tag/deep-learning?source=post
  31. https://medium.com/tag/tensorflow?source=post
  32. https://medium.com/tag/recurrent-neural-network?source=post
  33. https://medium.com/@erikhallstrm?source=footer_card
  34. https://medium.com/@erikhallstrm
  35. https://medium.com/@erikhallstrm
  36. https://medium.com/@medium/personalize-your-medium-experience-with-users-publications-tags-26a41ab1ee0c#.hx4zuv3mg

   hidden links:
  38. https://medium.com/p/83cd7105b767/share/twitter
  39. https://medium.com/p/83cd7105b767/share/facebook
  40. https://medium.com/p/83cd7105b767/share/twitter
  41. https://medium.com/p/83cd7105b767/share/facebook
