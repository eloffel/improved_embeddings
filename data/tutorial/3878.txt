   #[1]publisher [2]medium [3]alternate

   [4]homepage
   [5]homepage
   [6]become a member[7]sign in[8]get started
     __________________________________________________________________

id26 from the beginning

   [9]go to the profile of erik hallstr  m
   [10]erik hallstr  m (button) blockedunblock (button) followfollowing
   dec 4, 2016

   i have tried to understand id26 by reading some
   explanations, but i   ve always felt that the derivations lack some
   details. in this article i will try to explain it from the beginning
   hopefully not leaving anything out (theory wise at least). let   s get
   started!

forward propagation

   we have a fully-connected feed-forward neural network. it has l layers
   (could be any number) and any number of neurons in each layer. the
   activations of the neurons in layer l is stored in an activations
   column-vector a  , where the superscript index denote the layer. the
   connections from the neurons in layer l-1 to the layer l are stored in
   a weight matrix w  , and the biases for each neuron is stored in a bias
   column-vector b  .

   for a simple forward pass we have that:
   [1*dpeubd90lb1tewoqlotomw.gif]

   the id127s in this formula is visualized in the figure
   below, where we have introduced a new vector z  . which is the
   activation without the application of a component-wise transfer
   function, so that a   =   ( z   ). i will call this value the    input sum   
   of a neuron.
   [1*8jzqwlwuyjxx5vnybecrig.png]
   schematic of a fully connected layer and a id127
   without transfer-function applied.

   the whole network is shown below, from the input vector x, to the
   output activation vector a   . the connections leading in to a specific
   neuron is shown in colors in two layers:
   [1*xvabbjolxsexgx-m7snn2g.png]
   the whole network visualized

   one thing we can do, just to get a feeling of it is to write the
   network computation into one mathematical expression. let   s write down
   the formula for calculating the n:th element of the output vector in
   the final layer:
   [1*4plz16sc8b5p7rubi46xlw.gif]
   formula for the computation of the whole network.

   here we have introduced new notation where w         is denoting the
   connection from the v:th neuron in layer l-1 to the u:th neuron in
   layer l, and b      is the bias of the u:th neuron in layer l. the
   expression can be a bit confusing, particularly because of all the new
   indices. but the biggest takeaway from this is that the neural network
   is just a mathematical function. and this function can be derived with
   respect to any variable. we will use our newly introduced notation, and
   define an error function, or    cost    function c using a sample of our
   training data, and then see how the error changes as we change our
   weights.

deriving the error

   three adjacent layers anywhere in the network are shown in the figure
   below, the index letter for the neurons in the layers are j, k and m
   respectively, and the index letter for the layer is l.
   [1*uffxjk09pt9tmfysnvzwog.png]
   tree layers anywhere in the network, derivative is taken with respect
   to the weight shown in red. the middle neuron is enlarged for
   visualization purposes.

   first calculate the input sum of a neuron k in layer l:
   [1*6laeotl0var2wkz5utxtxw.gif]

   then take the transfer function, it could be any function with a first
   derivative:
   [1*nhz5chc9ored7f6zdsg_vg.gif]

   now finally calculate the input sum of a neuron m in layer l+1.
   [1*t5ntaz4t2ee_mvq2qjgqla.gif]

   here we have gone forward one step in the layers, from the activations
   in layer l-1 to the input sums of neurons in layer l+1. an error
   function c is defined using one example from our training data, and its
   derivative is calculated with respect to a single weight in layer l.
   [1*pid4gjbuikgtf_ryw8t7gw.gif]

   you may notice the sum in the expression above, it is due to the chain
   rule, all contributions from the neurons in layer l+1 have to be
   accounted for since their value is affecting the end error (their value
   is depending on the weight that we are taking the derivative with
   respect to). this is visualized in the figure shown above.

   one important thing to remember is that we have fixed k and j, thus we
   only see how the error changes when one single weight is manipulated in
   the calculation. all the other weights are held constant, and the
   derivative of a constant is simply zero. but the m index in layer l+1
   is not fixed, the activation of all neurons in that layer are changed
   as we change our specified weight.

error signal

   now let   s make a definition, the    error signal    of a neuron k in layer
   l as how much the total error changes when the input sum of the neuron
   is changed:
   [1*05wqe06-vm6obvxrfbvqmw.gif]

   so every neuron in the whole network now has an error signal defined.
   but if you look at the equation above, you will see that we have
   already expanded this expression:
   [1*9fky4vfigzm40hwxxkwqcw.gif]

   so we have a recursive formula for the error signals, using our
   definitions:
   [1*5bhyxsuduiemphyd1dhw4g.gif]

   you may wonder what happened with the biases, they are also    weights   
   and the error function should be derived with respect to them as well.
   [1*rretryeynm42zu7imu1jow.gif]

   so the gradient of the cost function with respect to the bias for each
   neuron is simply its error signal!

propagating backwards

   in order to use this recursive formula we need to obtain the first
   error signal in the series, i.e. the error signal of the neurons in the
   final layer l. this is the starting value, after having this we can
      propagate    backwards calculating all the error signals.
   [1*xid166gjc2guzsthxsrad5mg.gif]

   the only derivative that has to be calculated here is the derivative of
   the cost function with respect to the activations of the last layer,
   which is the output of the network. so this will depend on the
   error-function we choose.

matrix form

   since we now can recursively calculate all the error signals for all
   neurons in the network, it is possible to obtain the derivative of the
   cost function with respect to all weights. training is done by
   subtracting from each weight a small fraction of its corresponding
   derivative, called the [11]delta rule. since everything is known, the
   network is trainable! but we would like a more efficient notation,
   since we previously only worked with scalars. vector and matrix
   notation is to the rescue! remember that we stored all weights for
   layer l in a matrix w  , where the weights connecting from all neurons
   in l-1 to a neuron in l are stored as as rows? take a look at the first
   figure in the article to be reminded about this. now use the weight
   matrix, take its transpose. that will mean that the connections to the
   neurons in the layer are stored as columns. put all the error signals
   for the layer in a column vector, and multiply it with with the
   transposed weight matrix. sorry about this, but new notation again,
   there are a total of m neurons in layer l+1 and k neurons in layer l.
   [1*iushtxf7hsjbephr2toy6a.gif]

   the similarity sign is because we are lacking the multiplication of the
   derivative of the input sum in layer l. make sure you understand this
   id127, use pen an paper to sketch the calculations if
   possible.

   finally using all we derived previously, we can state formulas for
   calculating the gradient of the cost function with respect to the
   weights as following:
   [1*j40obzo5wna2rycw3og58a.gif]

   the nabla symbol is the derivative with respect to the output variables
   of the final layer, and the dot with a circle denotes component-wise
   multiplication.

outline of training algorithm

   using these formulas we can effectively write an algorithm train the
   network, using single training sample at a time.
    1. do forwards propagation, calculate the input sum and activation of
       each neuron by iteratively do matrix-vector multiplication and
       taking component-wise transfer function of all neurons in every
       layer. save the results for later.
    2. calculate the the error signal of the final layer l, by obtaining
       the gradient of the cost function with respect to the outputs of
       the network. this expression will depend on the current training
       sample (input and output), as well as the chosen cost function.
    3. do backwards propagation, calculate the error signals of the
       neurons in each layer. the input sum of each neuron is required to
       do this, and it is also done by iteratively computing matrix-vector
       multiplications (see formula above).
    4. calculate the derivative of the cost function with respect to the
       weights, the activation of each neuron is required to do this (see
       the formula above). this will be a matrix with the same shape as
       the weight matrix.
    5. calculate the derivative of the cost function with respect to the
       biases (see the formula above). this will only be a column vector.

   7. update the weights according to the [12]delta rule.

next step

   this explanation is how to train a network using only one training
   sample at a time, but how to do it using batch learning? what we can do
   is just putting the inputs of the training samples as columns in a
   matrix, doing the forward propagation the input sums and activations
   will also be in matrices, where column index is the sample index, and
   the row index is the neuron index.

   similarly the error signals for different layers and samples will be in
   matrices. however, the derivatives of the cost function with respect to
   the weights will be in a three-dimensional tensor using the dimensions
   [sample_idx, neuron_idx, weight_idx]. reducing a sum over the samples
   in this tensor will give the gradient matrix for the weights in the
   actual layer, and the weights can be updated using the delta rule.

   in the next article we will be building a simple neural network from
   scratch, that can be trained using this theory (coming soon).

     * [13]neural networks
     * [14]artificial intelligence
     * [15]id26
     * [16]deep learning

   (button)
   (button)
   (button) 1.8k claps
   (button) (button) (button) 17 (button) (button)

     (button) blockedunblock (button) followfollowing
   [17]go to the profile of erik hallstr  m

[18]erik hallstr  m

   studied engineering physics and in machine learning at royal institute
   of technology in stockholm. also been living in taiwan             . interested
   in deep learning.

     * (button)
       (button) 1.8k
     * (button)
     *
     *

   [19]go to the profile of erik hallstr  m
   never miss a story from erik hallstr  m, when you sign up for medium.
   [20]learn more
   never miss a story from erik hallstr  m
   (button) blockedunblock (button) followget updates

references

   visible links
   1. https://plus.google.com/103654360130207659246
   2. https://medium.com/osd.xml
   3. android-app://com.medium.reader/https/medium.com/p/77356edf427d
   4. https://medium.com/
   5. https://medium.com/
   6. https://medium.com/membership?source=upgrade_membership---nav_full
   7. https://medium.com/m/signin?redirect=https://medium.com/@erikhallstrm/id26-from-the-beginning-77356edf427d&source=--------------------------nav_reg&operation=login
   8. https://medium.com/m/signin?redirect=https://medium.com/@erikhallstrm/id26-from-the-beginning-77356edf427d&source=--------------------------nav_reg&operation=register
   9. https://medium.com/@erikhallstrm?source=post_header_lockup
  10. https://medium.com/@erikhallstrm
  11. https://en.wikipedia.org/wiki/delta_rule
  12. https://en.wikipedia.org/wiki/delta_rule
  13. https://medium.com/tag/neural-networks?source=post
  14. https://medium.com/tag/artificial-intelligence?source=post
  15. https://medium.com/tag/id26?source=post
  16. https://medium.com/tag/deep-learning?source=post
  17. https://medium.com/@erikhallstrm?source=footer_card
  18. https://medium.com/@erikhallstrm
  19. https://medium.com/@erikhallstrm
  20. https://medium.com/@medium/personalize-your-medium-experience-with-users-publications-tags-26a41ab1ee0c#.hx4zuv3mg

   hidden links:
  22. https://medium.com/p/77356edf427d/share/twitter
  23. https://medium.com/p/77356edf427d/share/facebook
  24. https://medium.com/p/77356edf427d/share/twitter
  25. https://medium.com/p/77356edf427d/share/facebook
