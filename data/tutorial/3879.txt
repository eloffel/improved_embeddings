   #[1]publisher [2]medium [3]alternate

   [4]homepage
   [5]homepage
   [6]become a member[7]sign in[8]get started
     __________________________________________________________________

work remotely with pycharm, tensorflow and ssh

   [9]go to the profile of erik hallstr  m
   [10]erik hallstr  m (button) blockedunblock (button) followfollowing
   nov 11, 2016

   wouldn   t it be awesome to sit at a caf   with your laptop, creating
   large neural networks in tensorflow, crunching data with speeds of
   several terraflops, without even hearing your fan spinning up? this is
   possible using a remote interpreter in pycharm, and you get almost the
   same experience working remotely as working locally.

   however, this is currently only possible in pycharm professional
   (community edition will not do). if you are a student your university
   should have an arrangement so you can download it for free, otherwise
   you   ll have to buy it. here is how i set it up from scratch (you may
   want to skip some of the steps):

remote data crunching machine

   [1*nmjvtiwm9huypr4aibendq.jpeg]
   hopefully your remote machine doesn   t look like this.

   this is your stationary remote machine, perhaps fitted with one or
   several state-of-the-art gpu:s from nvidia! (i don   t like the current
   deep learning monopoly, but tensorflow can only use nvidia gpus). first
   let   s install the latest ubuntu, i recommend the desktop version, you
   can always kill the gui-service later to free up graphics memory.
   connect it to internet and check you lan ip-address by opening up a
   terminal typing ifconfig. i will assume it is 192.168.0.1 in the
   instructions later.

setup ssh

   in order to be able to communicate with your crunching-machine, you
   need to install ssh on it. open up a terminal on your stationary
   computer and get it:
sudo apt-get install ssh

   enable ssh x11-forwarding so that you can plot things, open the
   configuration file like this.
sudo gedit /etc/ssh/sshd_config

   then locate the row that says
# x11forwarding yes

   simply remove the hash-sign to uncomment the line, save and close the
   file.

graphics

   next install the graphics drivers, they are usually proprietary, so you
   need to add a new repository to your package manager. what package
   you   ll need depend on your graphics card and ubuntu version. as of
   writing nvidia-367 is the latest one, see more on [11]this page.
sudo add-apt-repository ppa:graphics-drivers/ppa
sudo apt-get update
sudo apt-get install nvidia-367

cuda and cudnn

   now it   s time to install [12]cuda toolkit and and [13]cudnn, which are
   required to run tensorflow. they are available from nvidia   s webpage,
   and to download cudnn you are required to register. as of writing cuda
   8.0 and cudnn 5.1 are the latest versions. for cuda i prefer using the
   built in package manager, it makes it easier to keep track of what you
   have installed:
sudo dpkg -i cuda-repo-ubuntu1604_8.0.44-1_amd64.deb
sudo apt-get update
sudo apt-get install cuda-toolkit-8.0

   make sure that the symlink is set up correctly:
readlink -f /usr/local/cuda
>> /usr/local/cuda-8.0

   this is how to extract the cudnn headers and copy them into the cuda
   folder, and make them readable in the terminal (some of the filenames
   may be different for you):
tar xvzf cudnn-8.0-linux-x64-v5.1.tgz
sudo cp cuda/include/cudnn.h /usr/local/cuda/include
sudo cp cuda/lib64/libcudnn* /usr/local/cuda/lib64
sudo chmod a+r /usr/local/cuda/include/cudnn.h /usr/local/cuda/lib64/libcudnn*

   finally add the environment variables you will need, append them to
   your .bashrc file and then source it:
echo 'export ld_library_path=   $ld_library_path:/usr/local/cuda/lib64:/usr/local/
cuda/extras/cupti/lib64"' >> ~/.bashrc
echo 'export cuda_home=/usr/local/cuda' >> ~/.bashrc
source ~/.bashrc

python and tensorflow

   install some required python libraries:
sudo apt-get install python-pip python-dev build-essential python-numpy python-s
cipy python-matplotlib

   and then install gpu enabled tensorflow, check the version you need on
   [14]this page (tf_binary_url is different for different systems):
export tf_binary_url=https://storage.googleapis.com/tensorflow/linux/gpu/tensorf
low-0.11.0rc2-cp27-none-linux_x86_64.whl
pip install --ignore-installed --upgrade $tf_binary_url

   verify that the installation is working by typing the following in your
   terminal:
python
import tensorflow

   you should get output similar to this if you have installed it on a gpu
   enabled system:
>i tensorflow/stream_executor/dso_loader.cc:111] successfully opened cuda librar
y libcublas.so locally
>i tensorflow/stream_executor/dso_loader.cc:111] successfully opened cuda librar
y libcudnn.so locally
>i tensorflow/stream_executor/dso_loader.cc:111] successfully opened cuda librar
y libcufft.so locally
>i tensorflow/stream_executor/dso_loader.cc:111] successfully opened cuda librar
y libcuda.so.1 locally
>i tensorflow/stream_executor/dso_loader.cc:111] successfully opened cuda librar
y libcurand.so locally

   did it work? great! let   s move on to your laptop

super sleek ultrabook

   [1*wbl_2hezva09vl8amjmpdw.jpeg]

   open up your laptop and connect it to the same local network as your
   stationary machine.

install stuff

   so i   m using a macbook and it allows me to install programs with a very
   nice package manager called [15]homebrew. even desktop apps can easily
   be downloaded with [16]homebrew cask.

   install homebrew and cask:
/usr/bin/ruby -e    $(curl -fssl [17]https://raw.githubusercontent.com/homebrew/in
stall/master/install)"
brew tap caskroom/cask

   get what you need, including the pycharm ide.
brew install cask ssh-copy-id python
brew cask install java pycharm xquartz

setup ssh

   generate a ssh key-pair by executing the command below and then walk
   trough the guide (if you haven   t done this already):
ssh-keygen -t rsa

   now copy the key to your remote machine so you can connect to it
   without typing a password every time. on the first time doing this you
   need to authenticate yourself with the password of your remote machine:
ssh-copy-id [remote username here]@[remote ip here]

   enable compression and x11-forwarding (useful for plotting data) by
   appending this to your config file on your local machine.
echo 'forwardx11 yes' >> ~/.ssh/config
echo 'compression yes' >> ~/.ssh/config

   verify that everything is working by connecting to your remote machine
   from your laptop.
ssh [remote username here]@[remote ip here]

   while still logged in, you should disable password login on your remote
   machine for security reasons. open the configuration file with your
   favorite command-line editor.
sudo vim /etc/ssh/sshd_config

   and uncomment the following line by removing the hash-sign:
passwordauthentication no

   restart your ssh server while still logged in on your remote (you have
   to authenticate yourself again).
service ssh restart

   the final thing you should do while still logged in with ssh on your
   remote is to find your display environment variable. this will be used
   later for plotting, i usually get localhost:10.0.
echo $display
> localhost:10.0

   remember the output of this command, we will use it later.

remote interpreter in pycharm

   [1*fax_fsxlofbjhymflioj6w.png]

   this is the funny part, how we can set up the remote interpreter so you
   execute the scripts on your remote machine. let   s get started, start up
   pycharm and create a new python project.

interpreter

   open    preferences > project > project interpreter   . click on the
      dotted button    in the top-right corner and then    add remote   .
   [1*2vrhj2lntpgj6oykpc3gdw.png]

   click on the    ssh credentials    radio-button and input your information.
   select    key pair    on the    auth type   , and select the    private key
   file   . it should be located in /users/<your username>/.ssh/id_rsa.
   [1*eppsps-d5b5tmqy8gigvva.png]

   click on    ok > apply   . notice the    r    for remote on the project
   interpreter.
   [1*oawdpvd2b8tlgzpnmnhjia.png]

deployment

   the remote interpreter can not execute a local file, pycharm have to
   copy your source files (your project) to a destination folder on your
   remote server, but this will be done automatically and you don   t need
   to think about it! while still in the    preferences    pane, open    build,
   execution, deployment > deployment > options   . make sure that    create
   empty directories    is checked. this way pycharm will automatically
   synchronize when you create folders:
   [1*k7qsrtvsdouelrshilqgcq.png]

   now go back to    build, execution, deployment > deployment    and click on
   the    plus button   , select    sftp    and give a name to your remote. click
   on    ok   :
   [1*q839zzt9ep3mpjgtrlf4xw.png]

   set up the connection by first typing the ip of your remote in    sftp
   host   , then selecting    key pair    on the    auth type   , and finally
   selecting the    private key file   . it should be located in /users/<your
   username>/.ssh/id_rsa, as shown in the screenshot below. you may then
   click on    test sftp connection   . given that you can successfully
   connect you should set up mappings. if you   d like you can click on
      autodetect    beside the    rooth path   , it will then find the place of
   your home directory on the remote. all paths you specify after this
   will be relative to this home path. then go to the    mappings    tab.
   [1*h314zg7vshvrqst0esbdbq.png]

   as soon as you save or create a file in your local path, it will be
   copied to the    deployment path    on your remote server. perhaps you want
   to deploy it in a deployedprojects/ folder as shown below. this will be
   relative to your    rooth path    specified earlier, so the absolute
   deployment path will in our case be be
   /home/username/deployedprojects/testproject/:
   [1*gwi-7wfklpqqbvbrqz7jeg.png]

   now we are finished with the preferences, click on    apply    >    ok   , and
   then click    tools > deployment > automatic upload    and confirm that it
   is checked:
   [1*4_nikqv7ufumnhoi70uh7g.png]

   to do the initial upload, right-click on you project folder in the
   project explorer and click on    upload to remote   :
   [1*dzdkpuindsurk2pghgotmw.png]

   you should get a    file transfer    tab on your bottom pane where you can
   see all the progress:
   [1*t7n96l4-1ggto-zwbygr_g.png]

   then click on    tools > deployment > browse remote host   . drag and drop
   the window just beside the project tab to the left. that way it will be
   really simple to switch between your local and remote project.
   [1*vrnxqrni_lrbclralvwlcg.png]

   these deployment settings will work seaid113ssly as soon as you save and
   run a file, it is done so quickly you won   t even notice it.

setup the console

   open    preferences > build, execution, deployment > console > python
   console    and select the    python interpreter    to be your remote one.
   next click on the    dotted button    and input the required environment
   variables that we added before to ~/.bashrc when we set up the server.
   notice that we also added a value to the    display    variable we found
   out earlier when connecting to the server with ssh:
   [1*9tebk6kvr9uq1l4w7kkiyq.png]

   then go back to    build, execution, deployment >deployment > console   
   and select    always show the debug console   . it will be very handy when
   we   re debugging:
   [1*xcfitlwujurku2z9l-aplq.png]

create a run configuration

   create a simple test-file called test.py in your project, just
   containing this.
import tensorflow
print "tensorflow imported"

   now go to    run > edit configurations       click on the    plus button    and
   create a new python configuration. name it and select the script to
   run:
   [1*pn-jtaufq5g9lojeqjmdpw.png]

   now enter the required environment variables as before. tips: you can
   copy them all from the console settings we specified earlier, by using
   ctrl+a and then the copy/paste buttons in the lower left corner. you
   access them by clicking the    dotted button    just to the right of the
      environment variables    line.
   [1*7guohzmx7ikdaidn1ul8cg.png]

   click on    ok > ok   . it   s time for testing!

testing the setup

   now we should be all done, it   s time to test our setup. first open a
   terminal and make sure that you have at least one shh channel with
   x-forwarding connected your server. if you have had a connections open
   for a while, you may have to exit and restart them:
ssh [remote username here]@[remote ip here]

console

   then open the    python console    in the lower bar in pycharm and type
   import tensorflow. then you may type ls / to verify that you are
   actually executing the commands on your server! this is what the output
   should be:
   [1*9oxxj61ig8f5dxbv68rcow.png]

running script

   now go over to your test.py script and select    run > run       from the top
   toolbar. select your newly create run configuration    test   . it should
   output something like this:
   [1*rtperk9xmfaejj-hzrpvqw.png]

plotting

   let   s do some plotting, change your test.py file to this:
import tensorflow
import matplotlib
matplotlib.use('gtkagg')
import matplotlib.pyplot as plt
import numpy as np
print "tensorflow imported"
plt.plot(np.arange(100))
plt.show()

   and then run it again with your run configuration    test   , you should
   get this plot.
   [1*rwsgxeja2attfe-eper_ja.png]

   the plot is actually done on your remote server, but the window data is
   forwarded to your local machine. notice that we changed the backed with
   matplotlib.use('gtxagg'), because it   s a [18]x11-supported display
   backend. you can read more about matplotlib backends [19]here. you can
   also change the default behavior in your matplotlibrc-file. remember
   that you need to have at least one open ssh-connection in a separate
   terminal to get this to work, with the correct value of the display
   environment variable. if it didn   t work try to restart your ssh
   connection.

debugging script

   finally do some debugging, click on the left bar to put a breakpoint,
   then go    run > debug       and select the    test    configuration. you will
   see that the execution has halted and you are debugging your script
   remotely.
   [1*wavirvcuxjqf1rqxvajqdg.png]

next step

   in order to access your machine over the internet you have to forward
   ports on you home router, that is different for different vendors. i
   recommend forwarding a different port than 22 on your router. there are
   plenty bots out there trying to hack in, and they will check that port
   by default, and might slow your connection (although you are pretty
   secure since you have turned of password authentication). so you could
   perhaps forward port 4343 on your router to port 22 on ip 192.168.0.1
   (the default ip of our remote in this tutorial). also to speed up the
   plotting you may change to a [20]faster encryption.

   next, let   s do some more tensorflow, perhaps experimenting with matrix
   multiplication on the cpu and gpu? (coming soon)

     * [21]machine learning
     * [22]pycharm
     * [23]ssh
     * [24]tensorflow
     * [25]deep learning

   (button)
   (button)
   (button) 1.2k claps
   (button) (button) (button) 18 (button) (button)

     (button) blockedunblock (button) followfollowing
   [26]go to the profile of erik hallstr  m

[27]erik hallstr  m

   studied engineering physics and in machine learning at royal institute
   of technology in stockholm. also been living in taiwan             . interested
   in deep learning.

     * (button)
       (button) 1.2k
     * (button)
     *
     *

   [28]go to the profile of erik hallstr  m
   never miss a story from erik hallstr  m, when you sign up for medium.
   [29]learn more
   never miss a story from erik hallstr  m
   (button) blockedunblock (button) followget updates

references

   visible links
   1. https://plus.google.com/103654360130207659246
   2. https://medium.com/osd.xml
   3. android-app://com.medium.reader/https/medium.com/p/c60564be862d
   4. https://medium.com/
   5. https://medium.com/
   6. https://medium.com/membership?source=upgrade_membership---nav_full
   7. https://medium.com/m/signin?redirect=https://medium.com/@erikhallstrm/work-remotely-with-pycharm-tensorflow-and-ssh-c60564be862d&source=--------------------------nav_reg&operation=login
   8. https://medium.com/m/signin?redirect=https://medium.com/@erikhallstrm/work-remotely-with-pycharm-tensorflow-and-ssh-c60564be862d&source=--------------------------nav_reg&operation=register
   9. https://medium.com/@erikhallstrm?source=post_header_lockup
  10. https://medium.com/@erikhallstrm
  11. https://help.ubuntu.com/community/binarydriverhowto/nvidia
  12. https://developer.nvidia.com/cuda-downloads
  13. https://developer.nvidia.com/cudnn
  14. https://www.tensorflow.org/versions/r0.11/get_started/os_setup.html
  15. http://brew.sh/
  16. https://caskroom.github.io/
  17. https://raw.githubusercontent.com/homebrew/install/master/install
  18. http://stackoverflow.com/questions/3453188/matplotlib-display-plot-on-a-remote-machine
  19. http://matplotlib.org/faq/usage_faq.html#what-is-a-backend
  20. http://xmodulo.com/how-to-speed-up-x11-forwarding-in-ssh.html
  21. https://medium.com/tag/machine-learning?source=post
  22. https://medium.com/tag/pycharm?source=post
  23. https://medium.com/tag/ssh?source=post
  24. https://medium.com/tag/tensorflow?source=post
  25. https://medium.com/tag/deep-learning?source=post
  26. https://medium.com/@erikhallstrm?source=footer_card
  27. https://medium.com/@erikhallstrm
  28. https://medium.com/@erikhallstrm
  29. https://medium.com/@medium/personalize-your-medium-experience-with-users-publications-tags-26a41ab1ee0c#.hx4zuv3mg

   hidden links:
  31. https://medium.com/p/c60564be862d/share/twitter
  32. https://medium.com/p/c60564be862d/share/facebook
  33. https://medium.com/p/c60564be862d/share/twitter
  34. https://medium.com/p/c60564be862d/share/facebook
