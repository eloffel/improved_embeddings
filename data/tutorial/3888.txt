    #[1]nvidia developer blog    feed [2]nvidia developer blog    comments
   feed [3]nvidia developer blog    introduction to neural machine
   translation with gpus (part 2) comments feed [4]alternate [5]alternate

   [6]nvidia accelerated computing [7]developer
     * ____________________
       [ ] search nvidia developer
     * [8]join
     * [9]login

   ____________________
   [ ] search nvidia developer

[10]nvidia developer blog

main menu

   [11]skip to primary content
   [12]skip to secondary content
   [13]developer news
   [14]subscribe
   [15]follow us
   [16]nvidiaaidev
   [17]nvidiahpcdev
   [18]nvidiagamedev
   [19]nvidiaembedded
   [20]nvidiadrive
   [21]nvidiadesign

   (button) toggle navigation

   topics
     * [22]accelerated computing
     * [23]artificial intelligence
     * [24]autonomous vehicles
     * [25]design & visualization
     * [26]features
     * [27]game development
     * [28]robotics
     * [29]smart cities
     * [30]virtual reality

   [31]accelerated computing
   [32]artificial intelligence
   [33]autonomous vehicles
   [34]design & visualization
   [35]features
   [36]game development
   [37]robotics
   [38]smart cities
   [39]virtual reality

   [40]artificial intelligence


introduction to id4 with gpus (part 2)

   by [41]kyunghyun cho | [42]june 14, 2015
   tags: [43]deep learning, [44]machine learning, [45]machine translation,
   [46]natural language processing, [47]natural language understanding,
   [48]neural networks, [49]theano

   note: this is part two of a detailed three-part series on machine
   translation with neural networks by kyunghyun cho. you may
   enjoy [50]part 1 and [51]part 3.

   in [52]my previous post, i introduced id151
   and showed how it can and should be viewed from the perspective of
   machine learning: as supervised learning where the input and output are
   both variable-length sequences. in order to introduce you to neural
   machine translation, i spent half of the previous post on [53]recurrent
   neural networks, specifically about how they can (1) summarize a
   sequence and (2) probabilistically model a sequence. based on these two
   properties of recurrent neural networks, in this post i will describe
   in detail an encoder-decoder model for id151.

encoder-decoder architecture for machine translation

   figure 1. encoder-decoder for machine translation. figure 1.
   encoder-decoder for machine translation.

   i   m not a neuroscientist or a cognitive scientist, so i can   t speak
   authoritatively about how the brain works. however, if i were to guess
   what happens in my brain when i try to translate a short sentence in
   english to korean, my brain encodes the english sentence into a set of
   neuronal activations as i hear them, and from those activations, i
   decode the corresponding korean sentence. in other words, the process
   of (human) translation involves the encoder which turns a sequence of
   words into a set of neuronal activations (or spikes, or whatever   s
   going on inside a biological brain) and the decoder which generates a
   sequence of words in another language, from the set of activations (see
   figure 1).

   this idea of encoder-decoder architectures is the basic principle
   behind id4. in fact, this type of architecture
   is at the core of [54]deep learning, where the biggest emphasis is on
   learning a good representation. in some sense, you can always cut any
   [55]neural network in half, and call the first half an encoder and the
   other a decoder.

   starting with the work by kalchbrenner and blunsom at the university of
   oxford in 2013, this encoder-decoder architecture has been proposed by
   a number of groups, including the machine learning lab (now, mila) at
   the university of montreal (where i work) and google, as a new way to
   approach id151 [kalchbrenner and blunsom,
   2013; sutskever et al., 2014; cho et al., 2014; bahdanau et al., 2015].
   (there is also older, related work by mikel forcada at the university
   of alcante from 1997! [forcada and neco, 1997].) although there is no
   restriction on which particular type of neural network is used as
   either an encoder or a decoder, i   ll focus on using a recurrent neural
   network for both.

   let   s build our first id4 system! but, before i
   go into details, let me first show you a big picture of the whole
   system in figure 2. doesn   t it look scarily complicated? nothing to
   worry about, as i will walk you through this system one step at a time.
   figure 2. the very first id4 system. figure 2.
   the very first id4 system.

the encoder

   we start from the encoder, a straightforward application of a recurrent
   neural network, based on its property of sequence summarization. if you
   recall the previous post, this should be very natural. in short, we
   apply the recurrent activation function recursively over the input
   sequence, or sentence, until the end when the final internal state of
   the id56 h_t is the summary of the whole input sentence.

   first, each word in the source sentence is represented as a so-called
   one-hot vector, or 1-of-k coded vector as in figure 3. this kind of
   representation is the dumbest representation you can ever find. every
   word is equidistant from every other word, meaning that it does not
   preserve any relationships among them.
   figure 3. step 1: a word to a one-hot vector. figure 3. step 1: a word
   to a one-hot vector.

   we take a [56]hierarchical approach to extracting a sentence
   representation, a vector that summarizes the input sentence. in that
   hierarchy, the first step is to obtain a meaningful representation of
   each word. but, what do i mean by    meaningful    representation? a short
   answer is    we let the model learn from data!   , and there isn   t any
   longer answer.

   the encoder linearly projects the 1-of-k coded vector w_i (see figure
   3) with a matrix e which has as many columns as there are words in the
   source vocabulary and as many rows as you want (typically, 100     500.)
   this projection s_i = e w_i , shown in figure 4, results in a
   continuous vector for each source word, and each element of the vector
   is later updated to maximize the translation performance. i   ll get back
   to what this means shortly.
   figure 4. step 2: a one-hot vector to a continuous-space
   representation. figure 4. step 2: a one-hot vector to a
   continuous-space representation.

   at this point, we have transformed a sequence of words into a sequence
   of continuous vectors s_i s, and the recurrent neural network comes in.
   at the end of the last post, i said that one of the two key
   capabilities of the id56 was a capability of summarizing a sequence, and
   here, i will use an id56 to summarize the sequence of continuous vectors
   corresponding to the words in a source sentence. figure 5 illustrates
   how an id56 does it.

   i can write this process of summarization in mathematical notation as

   h_i = \phi_{\theta}(h_{i-1}, s_i)

   where h_0 is an all-zero vector. in other words, after the last word   s
   continuous vector s_t is read, the id56   s internal state h_t represents
   a summary of the whole source sentence.
   figure 5. step 3: sequence summarization by a recurrent neural network.
   figure 5. step 3: sequence summarization by a recurrent neural network.

what does the summary vector look like?

   now that we have a summary vector, a natural question comes to mind:
      what does this summary vector look like?    i would love to spend hours
   talking about what that summary vector should look like, what it means
   and how it   s probably related to representation learning and [57]deep
   learning, but i think one figure from [sutskever et al., 2014] says it
   all in a much more compact form (figure 6).

   to plot the points in figure 6, sutskever et al. (2014) trained a
   id4 system which we   re now training on a large
   parallel corpus of english and french. once the model was trained on
   the corpus, he fed in several english sentences into the encoder to get
   their corresponding sentence representations, or summary vectors h_t
      s. (i guess, in order to show off their model   s awesomeness!)

   unfortunately, human beings are pretty three dimensional, and our
   screens and papers can only faithfully draw two-dimensional
   projections. so it   s not easy to show anyone a vector which has
   hundreds of numbers, especially on paper. there are a number of
   [58]information visualization techniques for high-dimensional vectors
   using a much lower-dimensional space. in the case of figure 6,
   sutskever et al. (2014) used principal component analysis ([59]pca) to
   project each vector onto a two-dimensional space spanned by the first
   two principal components (x-axis and y-axis in figure 6). from this, we
   can get a rough sense of the relative locations of the summary vectors
   in the original space. what we can see from figure 6 is that the
   summary vectors do preserve the underlying structure, including
   semantics and syntax ([60]if there   s a such thing as syntax); in other
   words, similar sentences are close together in summary vector space.
   figure 6. 2-d visualization of sentence representations from [sutskever
   et al., 2014]. similar sentences are close together in summary-vector
   space. figure 6. 2-d visualization of sentence representations from
   [sutskever et al., 2014]. similar sentences are close together in
   summary-vector space.

the decoder

   now that we have a nice fixed-size representation of a source sentence,
   let   s build a decoder, again using a recurrent neural network (the top
   half in figure 2). again, i will go through each step of the decoder.
   it may help to keep in mind that the decoder is essentially the encoder
   flipped upside down.
   figure 7. decoder - step 1: computing the internal hidden state of the
   decoder. figure 7. decoder     step 1: computing the internal hidden
   state of the decoder.

   let   s start by computing the id56   s internal state z_i based on the
   summary vector h_t of the source sentence, the previous word u_{i-1}
   and the previous internal state z_{i-1} . don   t worry, i   ll shortly
   tell you how to get the word. the new internal state z_i is computed by

   z_i = \phi_{\theta'} (h_t, u_{i-1}, z_{i-1}).

   the details of \phi_{\theta'} were described in the previous post.
   figure 7 illustrates this computation. with the decoder   s internal
   hidden state z_i ready, we can now score each target word based on how
   likely it is to follow all the preceding translated words given the
   source sentence. this is done by assigning a id203 p_i to each
   word (figure 8). note, a id203 is different from a score in that
   the probabilities over all possible words sum to one, while the scores
   don   t need to.
   figure 8. decoder - step 2: next word id203. figure 8. decoder    
   step 2: next word id203.

   first, we score each word k given a hidden state z_i such that

   e(k) = w_k^{\top} z_i + b_k,

   where w_k and b_k are the (target) word vector and a bias,
   respectively.

   let   s forget about the bias b_k for now, and think of the first term,
   the dot product between two vectors. the dot product is larger when the
   target word vector w_k and the decoder   s internal state z_i are similar
   to each other, and smaller otherwise. remember: a dot product gives the
   length of the projection of one vector onto another; if they are
   similar vectors (nearly parallel) the projection is longer than if they
   very different (nearly perpendicular). so this mechanism scores a word
   high if it aligns well with the decoder   s internal state.

   once we compute the score of every word, we now need to turn the scores
   into proper probabilities using

   p(w_i=k|w_1, w_2, \ldots, w_{i-1}, h_t) = \frac{\exp(e(k))}{\sum_{j}
   \exp(e(j))}.

   this type of id172 is called softmax [61][bridle, 1990].

   now we have a id203 distribution over the target words, which we
   can use to select a word by sampling the distribution (see [62]here),
   as figure 9 shows. after choosing the i -th word, we go back to the
   first step of computing the decoder   s internal hidden state (figure 7),
   scoring and normalizing the target words (figure 8) and selecting the
   next (i+1) -th word (figure 9), repeating until we select the
   end-of-sentence word (<eos>).
   figure 9. decoder - step 3: sampling the next word. figure 9. decoder    
   step 3: sampling the next word.

training: id113

   okay, now we have a id4 system ready. how do we
   train this system so that it can actually translate? as usual with any
   machine learning model, there are many ways to tune this model to do
   actual translation. here, i will describe how to train a neural machine
   translation model based on the previously described encoder-decoder by
   maximizing the log-likelihood. [63]maximum (log-) likelihood estimation
   (id113) is a common statistical technique.

   first, a so-called parallel corpus d must be prepared. each sample in
   the corpus is a pair (x^n, y^n) of source and target sentences. each
   sentence is a sequence of integer indices corresponding to words, which
   is equivalent to a sequence of one-hot vectors. (a one-hot vector is a
   binary vector with a single element set to 1. multiplying a one-hot
   vector with a matrix (from the left) is equivalent to taking the i -th
   column of the matrix, where the i -th element of the one-hot vector is
   1.) given any pair from the corpus, the id4 model can compute the
   conditional log-id203 of y^n given x^n : \log p(y^n | x^n,
   \theta) , and we write the log-likelihood of the whole training corpus
   as

   \mathcal{l}(d, \theta) = \frac{1}{n} \sum_{n=1}^n \log p(y^n | x^n,
   \theta),

   where n is the number of training pairs.

   all we need to do is to maximize this log-likelihood function, which we
   can do using [64]stochastic id119 (sgd).

   the gradient of the log-likelihood \mathcal{l} with respect to all the
   parameters can be easily and efficiently computed by
   [65]id26. all you need to do is to build a backward
   [66]graph starting from the final log-id203 to the input, and
   compute derivatives of each operator in the forward computational
   graph. well, i don   t know about you, but that sounds awfully
   complicated and time-consuming to me. instead of doing it manually, we
   can use theano   s automatic differentiation procedure by calling
   theano.tensor.grad(-loglikelihood, parameters). [67]here is an example,
   and [68]here is more detailed documentation.

   once theano has automatically computed the derivative of the
   log-likelihood with respect to each parameter, we update the parameter
   to move along that derivative slowly. often, this slowly moving part is
   one that frustrates a lot of people, and this is one of the reasons why
   many people mistake deep learning for black magic. i agree that finding
   good learning parameters (initial learning rate, learning rate
   scheduling, momentum coefficient and its scheduling, and so on) can be
   frustrating.

   so, i often simply go for one of the recently proposed adaptive
   learning rate algorithms. among many of them, adadelta [zeiler, 2012]
   and adam [kingma and ba, 2015] are my favourites. they can be easily
   implemented in theano, and if you   re not too keen on reading the paper
   and implementing the algorithm, you can refer to [69]the theano
   documentation. also you might want to have a look at these
   [70]visualizations of the
   figure 10. behaviour of adaptive learning rate algorithms at a saddle
   point. from http://imgur.com/a/hqolp figure 10. behaviour of adaptive
   learning rate algorithms at a saddle point. from
   http://imgur.com/a/hqolp

   [71]optimization algorithms (also figure 10), although i must warn you
   that the behavior in this low dimensional space is not necessarily
   representative of the behavior in a higher dimensional space.

why gpus? the computational complexity of id4 training

   does this mean that i can train a id4 model on a
   large parallel corpus with my laptop? unfortunately, no. as you may
   have guessed, the amount of computation you need for each update is
   quite large, and the number of sgd updates needed to fully train a
   model is also large. let   s first count what kind of computation is
   required for a single forward pass:
    1. source id27s: t \times |v| ( t source words, |v| unique
       words)
    2. source embeddings to the encoder: t \times n_e \times (3 \times
       n_r) ( n_e -dim embedding, n_r recurrent units; two gates and one
       unit for gru)
    3. h_{t-1} to h_t : t \times n_r \times (3 \times n_r)
    4. context vector to the decoder: t \times n_r \times (3 \times n_r)
    5. z_{t-1} to z_t : t \times n_r \times (3 \times n_r)
    6. the decoder to the target id27s: t' \times n_r \times
       n_{e'} ( t' target words, n_{e'} -dim target embedding)
    7. target embeddings to the output: t' \times n_{e'} \times |v'| (
       |v'| target words)
    8. softmax id172 of the output: t' \times |v'|

   considering that |v| and |v'| are often on the order of tens or
   hundreds of thousands and that n_e , n_{e'} and n_r are on the order of
   hundreds to thousands, the whole computation load is quite substantial.
   furthermore, almost the same amount of computation is required for
   id26, i.e., computing the gradient of the log-likelihood
   function.

   note that most of these computations are matrix-vector or matrix-matrix
   multiplications of high-dimensional vectors or matrices, and when it
   comes to generalized matrix-id127s (gemm) of large
   matrices, it   s well-known that gpus significantly outperform cpus (in
   terms of wall-clock time.) so it   s crucial to have a nice set of the
   latest gpus to develop, debug and train id4
   models.

   for instance, see table 1 for how much time you can save by using gpus.
   the table presents only the time needed for translation, and the gap
   between cpu and gpu grows much greater when training a model, as the
   complexity estimates above show.
   cpu (intel i7-4820k) gpu (gtx titan black)
   id56search [72][bahadanau et al,, 2015] 0.09s 0.02s
   table 1. the average per-word decoding/translation time. from [73][jean
   et al., 2015]

   i can assure you that i didn   t write this section to impress nvidia;
   you really do need good gpus to train any realistic neural machine
   translation models, at least until scalable and affordable universal
   quantum computers become available!

the story so far

   continuing from the previous post, today i described how a recently
   proposed id4 system is designed using recurrent
   neural networks. the id4 system in today   s post
   is a simple, basic model that was recently shown to be excellent in
   practice for english-french translation.

   based on this basic id4 model, in my next post i
   will tell you how we can push id4 much further
   by introducing an attention mechanism into the model. furthermore, i
   will show you how we can use id4 to translate
   from images and even videos into their descriptions! stay tuned.
   [74]26 comments
   about the authors
   kyunghyun cho
   about kyunghyun cho
   kyunghyun cho is an assistant professor in the department of computer
   science, courant institute of mathematical sciences and the center for
   data science at new york university (nyu) (starting september, 2015).
   previously, he was a postdoctoral researcher at the university of
   montreal under the supervision of prof. yoshua bengio after obtaining a
   doctorate degree at aalto university (finland) in early 2014.
   kyunghyun's main research interests include neural networks, generative
   models and their applications, especially, to language understanding.
   [75]view all posts by kyunghyun cho
   related posts
   [76]introduction to id4 with gpus (part 3)
   by [77]kyunghyun cho | [78]july 26, 2015
   [79]figure 8. image id134 with attention mechanism.
   [80]introduction to id4 with gpus (part 1)
   by [81]kyunghyun cho | [82]may 27, 2015
   [83]figure 3. graphical illustration of different types of recurrent
   neural networks. from [pascanu et al., 2014]
   [84]deep learning in a nutshell: core concepts
   by [85]tim dettmers | [86]november 3, 2015
   [87]dl_dog_340x340
   [88]understanding natural language with deep neural networks using
   torch
   by [89]soumith chintala | [90]march 3, 2015
   [91]torch_lstm_thumb
   comments

   copyright    2019 nvidia corporation
   [92]legal information [93]privacy policy

   [94]close

parallel forall

     * [95]features

   search for: ____________________ search

accelerated computing

     * [96]accelerated computing
     * [97]downloads
     * [98]training
     * [99]ecosystem
     * [100]forums
     * [101]register now
     * [102]login

references

   visible links
   1. https://devblogs.nvidia.com/feed/
   2. https://devblogs.nvidia.com/comments/feed/
   3. https://devblogs.nvidia.com/introduction-neural-machine-translation-gpus-part-2/feed/
   4. https://devblogs.nvidia.com/wp-json/oembed/1.0/embed?url=https://devblogs.nvidia.com/introduction-neural-machine-translation-gpus-part-2/
   5. https://devblogs.nvidia.com/wp-json/oembed/1.0/embed?url=https://devblogs.nvidia.com/introduction-neural-machine-translation-gpus-part-2/&format=xml
   6. https://developer.nvidia.com/
   7. https://developer.nvidia.com/
   8. https://developer.nvidia.com/accelerated-computing-developer
   9. https://developer.nvidia.com/user
  10. https://devblogs.nvidia.com/
  11. https://devblogs.nvidia.com/introduction-neural-machine-translation-gpus-part-2/#content
  12. https://devblogs.nvidia.com/introduction-neural-machine-translation-gpus-part-2/#secondary
  13. https://news.developer.nvidia.com/
  14. https://devblogs.nvidia.com/introduction-neural-machine-translation-gpus-part-2/
  15. https://devblogs.nvidia.com/introduction-neural-machine-translation-gpus-part-2/
  16. https://devblogs.nvidia.com/introduction-neural-machine-translation-gpus-part-2/
  17. https://devblogs.nvidia.com/introduction-neural-machine-translation-gpus-part-2/
  18. https://devblogs.nvidia.com/introduction-neural-machine-translation-gpus-part-2/
  19. https://devblogs.nvidia.com/introduction-neural-machine-translation-gpus-part-2/
  20. https://devblogs.nvidia.com/introduction-neural-machine-translation-gpus-part-2/
  21. https://devblogs.nvidia.com/introduction-neural-machine-translation-gpus-part-2/
  22. https://devblogs.nvidia.com/category/accelerated-computing/
  23. https://devblogs.nvidia.com/category/artificial-intelligence/
  24. https://devblogs.nvidia.com/category/autonomous-vehicles/
  25. https://devblogs.nvidia.com/category/design-visualization/
  26. https://devblogs.nvidia.com/category/features/
  27. https://devblogs.nvidia.com/category/game-development/
  28. https://devblogs.nvidia.com/category/robotics/
  29. https://devblogs.nvidia.com/category/smart-cities/
  30. https://devblogs.nvidia.com/category/virtual-reality/
  31. https://devblogs.nvidia.com/category/accelerated-computing/
  32. https://devblogs.nvidia.com/category/artificial-intelligence/
  33. https://devblogs.nvidia.com/category/autonomous-vehicles/
  34. https://devblogs.nvidia.com/category/design-visualization/
  35. https://devblogs.nvidia.com/category/features/
  36. https://devblogs.nvidia.com/category/game-development/
  37. https://devblogs.nvidia.com/category/robotics/
  38. https://devblogs.nvidia.com/category/smart-cities/
  39. https://devblogs.nvidia.com/category/virtual-reality/
  40. https://devblogs.nvidia.com/category/artificial-intelligence/
  41. https://devblogs.nvidia.com/author/kcho/
  42. https://devblogs.nvidia.com/introduction-neural-machine-translation-gpus-part-2/
  43. https://devblogs.nvidia.com/tag/deep-learning/
  44. https://devblogs.nvidia.com/tag/machine-learning/
  45. https://devblogs.nvidia.com/tag/machine-translation/
  46. https://devblogs.nvidia.com/tag/natural-language-processing/
  47. https://devblogs.nvidia.com/tag/natural-language-understanding/
  48. https://devblogs.nvidia.com/tag/neural-networks/
  49. https://devblogs.nvidia.com/tag/theano/
  50. https://devblogs.nvidia.com/parallelforall/introduction-neural-machine-translation-with-gpus/
  51. https://devblogs.nvidia.com/parallelforall/introduction-neural-machine-translation-gpus-part-3/
  52. https://devblogs.nvidia.com/parallelforall/introduction-neural-machine-translation-with-gpus/
  53. https://developer.nvidia.com/discover/recurrent-neural-network
  54. https://developer.nvidia.com/deep-learning
  55. https://developer.nvidia.com/discover/artificial-neural-network
  56. https://developer.nvidia.com/discover/cluster-analysis
  57. https://developer.nvidia.com/deep-learning
  58. http://en.wikipedia.org/wiki/information_visualization
  59. http://en.wikipedia.org/wiki/principal_component_analysis
  60. http://talks.cam.ac.uk/talk/index/58498
  61. http://papers.nips.cc/paper/195-training-stochastic-model-recognition-algorithms-as-networks-can-lead-to-maximum-mutual-information-estimation-of-parameters
  62. http://en.wikipedia.org/wiki/multinomial_distribution#sampling_from_a_multinomial_distribution
  63. http://en.wikipedia.org/wiki/maximum_likelihood
  64. https://en.wikipedia.org/wiki/stochastic_gradient_descent
  65. https://en.wikipedia.org/?title=id26
  66. https://developer.nvidia.com/discover/graph-analytics
  67. https://github.com/lisa-lab/deeplearningtutorials/blob/master/code/lstm.py#l457
  68. http://deeplearning.net/software/theano/library/gradient.html
  69. http://deeplearning.net/software/theano/library/gradient.html
  70. http://imgur.com/a/hqolp
  71. http://imgur.com/a/hqolp
  72. http://arxiv.org/abs/1409.0473
  73. http://arxiv.org/abs/1412.2007
  74. https://devblogs.nvidia.com/introduction-neural-machine-translation-gpus-part-2/#comments
  75. https://devblogs.nvidia.com/author/kcho/
  76. https://devblogs.nvidia.com/introduction-neural-machine-translation-gpus-part-3/
  77. https://devblogs.nvidia.com/author/kcho/
  78. https://devblogs.nvidia.com/introduction-neural-machine-translation-gpus-part-3/
  79. https://devblogs.nvidia.com/introduction-neural-machine-translation-gpus-part-3/
  80. https://devblogs.nvidia.com/introduction-neural-machine-translation-with-gpus/
  81. https://devblogs.nvidia.com/author/kcho/
  82. https://devblogs.nvidia.com/introduction-neural-machine-translation-with-gpus/
  83. https://devblogs.nvidia.com/introduction-neural-machine-translation-with-gpus/
  84. https://devblogs.nvidia.com/deep-learning-nutshell-core-concepts/
  85. https://devblogs.nvidia.com/author/tdettmers/
  86. https://devblogs.nvidia.com/deep-learning-nutshell-core-concepts/
  87. https://devblogs.nvidia.com/deep-learning-nutshell-core-concepts/
  88. https://devblogs.nvidia.com/understanding-natural-language-deep-neural-networks-using-torch/
  89. https://devblogs.nvidia.com/author/schintala/
  90. https://devblogs.nvidia.com/understanding-natural-language-deep-neural-networks-using-torch/
  91. https://devblogs.nvidia.com/understanding-natural-language-deep-neural-networks-using-torch/
  92. http://www.nvidia.com/object/legal_info.html
  93. http://www.nvidia.com/object/privacy_policy.html
  94. https://devblogs.nvidia.com/introduction-neural-machine-translation-gpus-part-2/#sidr-left
  95. https://devblogs.nvidia.com/category/features/
  96. https://developer.nvidia.com/accelerated-computing
  97. https://developer.nvidia.com/accelerated-computing-toolkit
  98. https://developer.nvidia.com/accelerated-computing-training
  99. https://developer.nvidia.com/tools-ecosystem
 100. https://devtalk.nvidia.com/
 101. https://developer.nvidia.com/accelerated-computing-developer
 102. https://developer.nvidia.com/user

   hidden links:
 104. https://devblogs.nvidia.com/introduction-neural-machine-translation-gpus-part-2/
 105. https://devblogs.nvidia.com/introduction-neural-machine-translation-gpus-part-2/
 106. https://devblogs.nvidia.com/introduction-neural-machine-translation-gpus-part-2/
