causality	

dominik janzing & bernhard sch  lkopf 
max planck institute for intelligent systems 

t  bingen, germany 

 

http://ei.is.tuebingen.mpg.de 

roadmap	
    informal motivation
    structural causal models
    causal id114;

d-separation, markov conditions, faithfulness

    do-calculus
    causal id136...

    using conditional independences

    using restricted function classes or scores

    using    autonomy    of causal mechanisms: igci and invariant condi-

tionals

    using time order

    implications for machine learning: ssl, transfer, confounder removal

dependence vs. causation 

thanks to p. laskov. 

   correlation does not tell us anything about causality    
       better to talk of dependence than correlation 
       most statisticians would agree that causality does tell us 

something about dependence 

       but dependence does tell us something about causality 

too:       

common cause principle 
(reichenbach)

(i) if x and y are sta-
tistically dependent,
then there exists z
causally in   uencing
both;

(ii) z

screens x
and y from each
other
(given z,
x und y become
independent)

z 

special case: 

by permission of the  
university of pittsburgh.  
all rights reserved. 

x 

y 

x 

y 

x 

y 

p(x,y) 

notation 

    a, b event
    x, y, z random variable
    x value of a random variable
    pr id203 measure
    px id203 distribution of x
    p density
    px or p(x) density of px
    p(x) density of px evaluated at the point x
    always assume the existence of a joint density, w.r.t. a product

measure

independence 

two events a and b are called independent if

pr(a \ b) = pr(a)    pr(b).

a1, . . . , an are called independent if for every subset s    { 1, . . . , n}
we have

pr \i2s

ai! =yi2s

pr(ai).

note: for n   3, pairwise independence pr(ai\aj) = pr(ai)  pr(aj)
for all i, j does not imply independence.

independence of random variables 
two real-valued random variables x and y are called independent,

x ?? y,

if for every a, b 2 r, the events {x     a} and {y     b} are indepen-
dent.

equivalently, in terms of densities: for all x, y,

p(x, y) = p(x)p(y)

note:
if x ?? y , then e[xy ] = e[x]e[y ], and cov[x, y ] = e[xy ]  e[x]e[y ] = 0.
the converse is not true: cov[x, y ] = 0 6) x ?? y .
however, we have, for large f: (8f, g 2f : cov[f (x), g(y )] = 0) ) x ?? y

conditional independence of random variables 

two real-valued random variables x and y are called conditionally
independent given z,

(x ?? y )|z or x ?? y |z or (x ?? y |z)p

if

for all x, y, and for all z s.t. p(z) > 0.

p(x, y|z) = p(x|z)p(y|z)

note: it is possible to    nd x, y which are conditionally independent
(given z) but unconditionally dependent, and vice versa.

what is cause and what is effect? 

autonomous/invariant mechanisms 

    intervention on a: raise the city,    nd that t changes
    hypothetical intervention on a: still expect that t
changes, since we can think of a physical mechanism
p(t|a) that is independent of p(a)
    we expect that p(t|a) is invariant across, say, di   er-
ent countries in a similar climate zone

independence of cause & mechanism 

    the conditional density p(t|a) (viewed as a function of
t and a) provides no information about the marginal
density function p(a)
    this also applies if we only have a single density

independence of noise terms 

    view the distribution as entailed by a structural causal
model (scm)

a := na,
t := ft (a, nt ),

where nt ?? na
    this allows identi   cation of the causal graph under
suitable restrictions on the functional form of ft

dependent noises can lead to dependent mechanisms 

a 

t 

n 

    consider the graph a ! t
    scm

t = f (a, n)

a ?? n
if n can take d di   erent values, it could switch between mech-
anisms f 1(a), . . . , f d(a)
    if a 6?? n, then n could    select    a mechanism f i depending on
(the mechanism selected by) a

    a    structural    relation not only explains the observed data, it captures
a structure connecting the variables; related to autonomy and invariance
(haavelmo 1943, frisch 1948, ...)

    an equation system becomes structural by virtue of invariance to a do-

main of modi   cations (harwich, 1962)

       simon   s invariance criterion:    the true causal order is the one that is
invariant under the right sort of intervention (simon, 1953; hoover, 2008)

    each parent-child relationship in the network represents a stable and au-

tonomous physical mechanism (pearl, 2009)

    formalised using algorithmic id205 (janzing & sch  olkopf,

2010)

 

definition of a structural causal model 
      
 (pearl et al.) 
    directed acyclic graph g with vertices x1, . . . , xn

 

 

 

(following arrows does not lead to loops)

    semantics: vertices = observables, arrows = direct causation
    xi := fi(pai, ui) , with independent rvs u1, . . . , un that possess a

joint density

    ui stands for    unexplained    (alternatively    noise    or    exogenous variable   )
    this is also called a (nonlinear) structural equation model

reichenbach   s principle and causal sufficiency 

    this model can be shown to satisfy reichenbach   s principle:

1. functions of independent variables are independent, hence dependence
can only arise in two vertices that depend (partly) on the same noise
term(s).

2. if we condition on these noise terms, the variables become independent

    independence of noises is a form of    causal su ciency:    if the noises were
dependent, then reichenbach   s principle would tell us the causal graph is
incomplete

fz
z 

fx
x 

fy
y 

entailed distribution 

    xi := fi(pai, ui),
with independent u1, . . . , un.

    recursively substitute the parent equations to get xi = gi(u1, . . . , un),
with independent u1, . . . , un.
    each xi is thus a rv and we get a joint distribution of x1, . . . , xn,
called the observational distribution.
    the distribution and the dag form a directed graphical model and
any directed graphical model can be written as a functional causal
model.

entailed distribution 

    a structural causal model entails a joint distribution p(x1, . . . , xn).
questions:
(1) what can we say about it?
(2) can we recover g from p?

markov conditions (lauritzen 1996, pearl 2000) 

theorem: the following are equivalent:
    existence of a structural causal model
    local causal markov condition: xi statistically independent of
non-descendants, given parents (i.e.: every information exchange with its
non-descendants involves its parents)

    global causal markov condition:    d-separation    (characterizes the

set of independences implied by local markov condition     see below)

    factorization p(x1, . . . , xn) =qi p (xi | pai)

(subject to technical conditions)

p (xi | pai) is called a causal conditional or causal markov kernel.
it corresponds to the structural    equation    xi := fi(pai, ui).
not every conditional is causal     only those that condition on the
parents in our dag.

graphical causal id136 (spirtes, glymour, scheines, pearl, ...) 

question: how can we recover g from a single p (e.g., from the observational
distribution)?
answer: by conditional independence testing, infer a class containing
the correct g
(i.e., track how the noise information spreads).

problems:
    markov condition states (x ?? y |z)g ) (x ?? y |z)p, but
we need    faithfulness   :

(x ?? y |z)g ( (x ?? y |z)p

(sprites, glamour, scheines 2001)

hard to justify for    nite data (uhler, raskutti, b  uhlmann, yu, 2013).
    if the fi are complex, then conditional independence testing based
on    nite samples becomes arbitrarily hard

interventions and shifts 

    de   nition. replacing xi := fi(pai, ui) with another assignment
(e.g., xi := const.) is called an intervention on xi.
    the entailed distribution is called the interventional distribution.
    this contains as special cases: domain shift distribution and covari-
ate shift distribution (see below).
    a general intervention corresponds to changing some causal con-
ditionals p(xi|pai)

principle of independent mechanisms 
    a precondition for interventions is that the mechanisms in
p (xi | pai)

p(x1, . . . , xn) =

nyi=1

are independent, hence changing one p (xi | pai) does not change the condition-
als p (xj | paj) for j 6= i     cf. independence of noise terms
    can help infer causal structures: exploit that the terms in one factorisation are
independent from each other (janzing & sch  olkopf, 2010); exploit that terms remain invari-
ant across domains (peters et al., 2015; zhang et al., 2015, hoover, 1990), i.e., vary some of them
and check if the others remain unchanged
    can help in machine learning: semi-supervised learning (sch  olkopf et al., 2012), domain
shift (zhang et al., 2013), id21 (rojas-carulla et al., 2015)

cf. independence of mechanisms (janzing & sch  olkopf, 2010), independence of cause and mechanism
(janzing et al., 2012), autonomy, (structural) invariance, separability, exogeneity, stability, modular-
ity (aldrich, 1989; pearl, 2009)

independence principle: 
the causal generative 
process is composed of 
autonomous modules that 
do not inform or 
influence each other. 

the ambassadors, hans holbein d.j. 
 
national gallery, london 

counterfactuals 

    david hume (1711   76):    ... we may de   ne a cause to be an object, fol-
lowed by another, and where all the objects similar to the    rst are followed
by objects similar to the second. or in other words where, if the    rst object
had not been, the second never had existed.   

    jerzy neyman (1923): consider m plots of land and     varieties of crop.
denote uij the crop yield that would be observed if variety i = 1, . . . ,   
were planted in plot j = 1, . . . , m
for each plot j, we can only experimentally determine one uij in each
growing season.

the others are called    counterfactuals   .

    this leads to the view of causal id136 as a missing data problem     the

   potential outcomes    framework (rubin, 1974)

xi := fi(pai, ui) with
independent rvs u1, . . . , un.

method
conditional
pendence
(n   3)
customized tests

inde-
testing

regression & un-
conditional
inde-
pendence testing

intuition
track how the
noises spread

noises pick up
footprints of the
functions
restriction
function class

of

can we recover g from p?

approach
graphical
(pearl,

approach
glymour,

spirtes,

scheines)
icm
(daniu  sis

et al., uai 2010;

shajarisales et al., icml 2015)
additive noise model
janzing,
(peters,

mooij,

sch  olkopf, jmlr 2014)

jointly

assumptions
noises
independent;
faithfulness
noises
independent;
fi learnable
xi = fi(pai)+ui
with learnable fi

and fi

does it make sense to talk about 
causality without mentioning time? 

does it make sense to talk about 
statistics without mentioning time? 

a modeling taxonomy 

model 

predict in iid 
setting 

mechanistic 
model 
   

structural 
causal model 

causal 
graphical 
model 
statistical 
model 

y 

y 

y 

y 

predict under 
changing 
distributions /
interventions 
y 

answer 
counter-
factual 
questions 
y 

y 

y 

n 

y 

n 

n 

obtain 
physical 
insight 

automatically 
learn from 
data 

y 

n 

n 

n 

? 

y?? 

y? 

y 

see also rubenstein, bongers, mooij, sch  lkopf, 2016 

uai 2013 

   imitate the superficial exterior of a process 
or system without having any understanding 
of the underlying substance". 
(source: http://philosophyisfashionable.blogspot.com/) 

   cargo cult    

 
-   

for prediction in the iid setting, imitating the 
exterior of a process is often enough  
     (i.e., can disregard causal structure) 
-    anything else can benefit from causal learning 

interval 

recall:

    causal structure formalized by dag (directed cyclic graph) g with random

variables x1, . . . , xn as nodes

    causal markov condition states that density p(x1, . . . , xn) then factorizes

into

p(xj|paj),
where paj denotes the values of the parents of xj

p(x1, . . . , xn) =

nyj=1

    causal conditionals p(xj|paj) represent causal mechanisms

pearl   s do-notation

    motivation: goal of causality is to infer the e   ect of

interventions

    distribution of y given that x is set to x:

p(y |do x = x) or p(y |do x)

    don   t confuse it with p (y |x)
    can be computed from p and g

di   erence between seeing and doing

id203 that someone gets 100 years old given that we know that he/she
drinks 10 cups of co   ee per day

p(y|x)

id203 that some randomly chosen person gets 100 years old after he/she
has been forced to drink 10 cups of co   ee per day

p(y|do x)

computing p(x1, . . . , xn|do xi)

from p(x1, . . . , xn) and g

    start with causal factorization

p(x1, . . . , xn) =

nyj=1

p(xj|p aj)

    replace p(xi|p ai) with  xixi

p(x1, . . . , xn|do xi) :=yj6=i

p(xj|p aj) xixi

computing p(xk|do xi)

summation over xi yields

p(x1, . . . , xi 1, xi+1, . . . , xn|do xi) =yj6=i

p(xj|p aj(xi)) .

    distribution of xj with j 6= i is given by dropping p(xi|p ai) and substi-

tuting xi into p aj to get p aj(xi).

    obtain p(xk|do xi) by marginalization

examples for p(.|do x) = p(.|x)

examples for p(.|do x)    = p(.|x)

    p(y |do x) = p (y )    = p (y |x)

    p(y |do x) = p (y )    = p (y |x)

example: controlling for confounding

x 6?? y partly due to the confounder z and partly due to x ! y

    causal factorization

p(x, y, z) = p(z)p(x|z)p(y |x, z)

    replace p (x|z) with  xx

p(y, z|do x) = p(z)  xx p(y |x, z)

    marginalize

p(y |do x) =xz

p(z)p(y |x, z) 6=xz

p(z|x)p(y |x, z) = p(y |x) .

identi   ability problem

e.g. tian & pearl (2002)

    given the causal dag g and two nodes xi, xj

    which nodes need to be observed to compute p(xi|do xj) ?

inferring the dag

    key postulate: causal markov condition

    essential mathematical concept: d-separation

(describes the conditional independences required by a causal dag)

d-separation (pearl 1988)

path = sequence of pairwise distinct nodes where consecutive ones are adjacent

a path q is said to be blocked by the set z if

    q contains a chain i     m     j or a fork i     m     j such

that the middle node is in z, or

    q contains a collider i     m     j such that the middle node

is not in z and such that no descendant of m is in z.

z is said to d-separate x and y in the dag g, formally

if z blocks every path from a node in x to a node in y .

(x        y |z)g

example (blocking of paths)

 

 

 

 

path from x to y is blocked by conditioning on u or z or both

example (unblocking of paths)

    path from x to y is blocked by  
    unblocked by conditioning on z or w or both

unblocking by conditioning on common e   ects

berkson   s paradox (1946)
example: x, y, z binary

x

y

z

= x or y

x ?? y

but x 6?? y |z

    assume: for politicians there is no correlation between being a good speaker

and being intelligent

    politician is successful if (s)he is a good speaker or intelligent
    among the successful politicians, being intelligent is negatively correlated

with being a good speaker

asymmetry under inverting arrows

(reichenbach 1956)

x        y
x         y |z

x         y
x        y |z

examples (d-separation)

 

 

 

 

 

 

(x        y |zw )g
(x        y |zu w )g
(x        y |v zu w )g

(x         y |v zu)g

causal id136 for time-ordered variables

assume x           y and x earlier. then x   y excluded, but still two options:

x 

y 

z 

x 

y 

example (fukumizu 2007): barometer falls before it rains, but it does not
cause the rain

conclusion: time order makes causal problem (slightly?) easier but does not
solve it

causal id136 for time-ordered variables

assume x1, . . . , xn are time-ordered and causally su cient, i.e., there are no
hidden common causes and density is strictly positive

    start with complete dag
x1

x2

x3
    remove as many parents as possible:

p 2 p aj can be removed if

x4

xj ?? p|p aj \ p

(going from potential arrows to true arrows    only    requires
statistical testing)

time series and granger causality

does x cause y and/or y cause x?

xt-2

xt-1

...

?

?

?

yt-2

yt-1

xt

yt

xt+1

yt+1

exclude instantaeous e   ects and common causes

    if

ypresent 6?? xpast |ypast

there must be arrows from x to y (otherwise d-separation)

    granger (1969): the past of x helps when predicting yt from its past
    strength of causal in   uence often measured by transfer id178

i(ypresent; xpast |ypast)

confounded granger

hidden common cause z relates x and y

xt-2

zt-2

yt-2

xt-1

v

v

zt-1

yt-1

xt

zt

yt

v

xt+1

zt+1

yt+1

due to di   erent time delays we have

but

granger infers x ! y

ypresent 6?? xpast |ypast

xpresent ?? ypast |xpast

why transfer id178 does not

quantify causal strength (ay & polani, 2008)

deterministic mutual in   uence between x and y

xt-2

xt-1

yt-2

yt-1

xt

yt

xt+1

yt+1

    although the in   uence is strong

i(ypresent; xpast |ypast) = 0 ,
because the past of y already determines its present

    quantitatively still wrong for non-deterministic relation
    see paper on de   nitions of causal strength: janzing, balduzzi, grosse-

wentrup, sch  olkopf, annals of statistics 2013

quantifying causal in   uence for general dags

given:
causally su cient set of variables x1, . . . , xn with

    known causal dag g
    known joint distribution p (x1, . . . , xn)

x

1

x

3

x

2

goal:
construct a measure that quanti   es the strength of xi!xj
with the following properties:

postulate 1: (mutual information)

x

y

for this simple dag we postulate

cx!y = i(x; y )

(no other path from x to y , hence the dependence is caused by the arrow
x ! y )

postulate 2: (localility)

causes of causes and e   ects of e   ects don   t matter

x

y

here we also postulate

cx!y = i(x; y )

postulate 3: (strength majorizes conditional dependence,
given the other parents)

z

y

x

(without x ! y the markov condition would imply i(x; y |z) = 0)

cx!y   i(x; y |z)

why cx!y = i(x; y |z) is a bad idea

z

y

x

contains

x

z

y

as a limiting case
(weak in   uence z ! y ),

where we postulated cx!y = i(x; y ) instead of i(x; y |z)

our approach:    edge deletion   

    de   ne a new distribution

px!y (x, y, z) = p (z)p (x|z)xx0

p (y|x0, z)p (x0)

    de   ne causal strength by the    impact of edge deletion   

cx!y := d(pkpx!y )

    intuition of edge deletion:

cut the wire between devices and feed the open end with an iid copy of
the original signal

z

x

              x'  ~ p(x)

y

related work:
ay & krakauer (2007)

properties of our measure

    strength also de   ned for set of edges
    satis   es all our postulates
    also applicable to time series
    conceptually more reasonable than granger causality and transfer id178

inferring the causal dag without time information

    setting: given observed n-tuples drawn from p(x1, . . . , xn), infer g
    key postulates: causal markov condition and causal faithfulness

causal faithfulness
spirtes, glymour, scheines

p is called faithful relative to g if only those independences hold
true that are implied by the markov condition, i.e.,

(x        y |z)g   (x        y |z)p

recall: markov condition reads

(x        y |z)g     (x        y |z)p

examples of unfaithful distributions (1)

cancellation of direct and indirect in   uence in linear models

x = ux
y =    x + uy
z =  x +  y + uz

with independent noise terms ux, uy , uz

  +      = 0 ) x ?? z

 

 

y

x

 

z

examples of unfaithful distributions (2)

binary causes with xor as e   ect

    for p(x), p(y ) uniform: x ?? z, y ?? z .

i.e., unfaithful (since x, z and y, z are connected in the graph).

    for p(x), p(y ) non-uniform: x 6?? z, y 6?? z .

i.e., faithful

x
(fair coins)
y

z  =x y

unfaithfulness considered unlikely because it only occurs for
non-generic parameter values

conditional-independence based causal id136

spirtes, glymour, scheines and pearl

causal markov condition + causal faithfulness:

    accept only those dags g as causal hypotheses for which

(x ?? y |z)g , (x ?? y |z)p .

    identi   es causal dag up to markov equivalence class

(dags that imply the same conditional independences)

markov equivalence class

theorem (verma and pearl, 1990): two dags are markov
equivalent i    they have the same skeleton and the same
v-structures.

skeleton: corresponding undirected graph
v-structure: substructure x ! y   z with no edge between
x and z

markov equivalent dags

x

x

x

y

y

y

z

z

z

same skeleton, no v-structure

x    z |y

markov equivalent dags

w

w

x

y

x

y

z

z

same skeleton, same v-structure at w

algorithmic construction of causal hypotheses

ic algorithm by verma & pearl (1990) to reconstruct dag from p

idea:

1. construct skeleton

2. find v-structures

3. direct further edges that follow from

    graph is acyclic
    all v-structures have been found in 2)

construct skeleton

theorem: x and y are linked by an edge i    there is no set sxy
such that

(x ?? y |sxy .
(assuming markov condition and faithfulness)

explanation: dependence mediated by other variables can be screened o    by
conditioning on an appropriate set

x ?? y |{z, w}

. . . but not by conditioning on all other variables!

sxy is called a sepset for (x, y )

e cient construction of skeleton

pc algorithm by spirtes & glymour (1991)

iteration over size of sepset

1. remove all edges x   y with x        y

2. remove all edges x   y for which there is a neighbor z    = y

of x with x        y |z

3. remove all edges x   y for which there are two neighbors

z1, z2    = y of x with x        y |z1, z2

4. ...

advantages

    many edges can be removed already for small sets
    testing all sets sxy containing the adjacencies

of x is su cient

    depending on sparseness, algorithm only requires
independence tests with small conditioning tests

    polynomial for graphs of bounded degree

find v-structures

    given x   y   z with x and y non-adjacent
    given sxy with x ?? y |sxy

a priori, there are 4 possible orientations:

x ! z ! y
x   z ! y

x   z   y 9=;

x ! z   y

z 2 sxy

z 62 sxy

orientation rule: create v-structure if z 62 sxy

direct further edges (rule 1)

(otherwise we get a new v-structure)

direct further edges (rule 2)

 

 

 

 

 

 

(otherwise one gets a cycle)

direct further edges (rule 3)

could not be completed
without creating a cycle
or a new v-structure

direct further edges (rule 4)

could not be completed
without creating a cycle
or a new v-structure

examples

(taken from spirtes et al, 2010)
true dag

x

y

w

z

u

start with fully connected undirected graph

x

y

w

z

u

remove all edges x   y with x ?? y |;

x

y

w

z

u

remove all edges having sepset of size 1

x ?? w y ?? w

x

y

w

z

u

x ?? z |y x ?? u |y

y ?? u |z w ?? u |z

   nd v-structure

x

y

w

z

u

z 62 sy w

orient further edges (no further v-structure)

x

y

w

z

u

edge x   y remains undirected

conditional independence tests

    discrete case: contingency tables
    multi-variate gaussian case:

covariance matrix

non-gaussian continuous case: challenging, recent progress
via reproducing kernel hilbert spaces (fukumizu...zhang...)

improvements

    cpc (conservative pc) by ramsey, zhang, spirtes (1995)

uses weaker form of faithfulness

    fci (fast causal id136) by spirtes, glymour, scheines
(1993) and spirtes, meek, richardson (1999) infers causal
links in the presence of latent common causes

    for implementations of the algorithms see homepage of the
tetrad project at carnegie mellon university pittsburgh

equivalence of markov conditions 
theorem: the following are equivalent:

    existence of a structural causal model
    local causal markov condition: xj statistically independent of non-

descendants, given parents

    global causal markov condition: d-separation

    factorization p(x1, . . . , xn) =qj p (xj | p aj)

(subject to technical conditions)

local markov ) factorization (lauritzen 1996)

    assume xn is a terminal node, i.e., it has no descendants, then n dn =

{x1, . . . , xn 1}. thus the local markov condition implies

xn ?? {x1, . . . , xn 1}|p an .

    hence the general decomposition

p(x1, . . . , xn) = p(xn|x1, . . . , xn 1)p(x1, . . . , xn 1)

becomes

p(x1, . . . , xn) = p(xn|pan)p(x1, . . . , xn 1) .

    induction over n yields

p(x1, . . . , xn) =

nyj=1

p(xj|paj) .

factorization ) global markov

(lauritzen 1996)

need to prove (x ?? y |z)g ) (x ?? y |z)p.
assume (x ?? y |z)g

    de   ne the smallest subgraph g0 containing x, y, z

and all their ancestors

    consider moral graph g0m (undirected graph containing

the edges of g0 and links between all parents)

    use results that relate factorization of probabilities with

separation in undirected graphs

global markov ) local markov

know that if z d-separates x, y , then x ?? y |z.
need to show that xj ?? n dj |p aj.
simply need to show that the parents p aj d-separate xj from its non-descendants
n dj:
all paths connecting xj and n dj include a p 2 p aj, but never as a collider

hence all paths are chains

or forks

  ! p   xj

  ! p ! xj

    p ! xj

therefore, the parents block every path between xj and n dj.

structural causal model ) local markov condition

g

g'

(pearl 2000)

x1

x2

x1

x2

x3

x4

x3

x4

    augmented dag g0 contains unobserved noise
    local markov-condition holds for g0:

(i): the unexplained noise terms uj are jointly independent, and thus

(unconditionally) independent of their non-descendants

(ii): for the xj, we have

because xj is a (deterministic) function of p a0j.

xj ?? n d0j |p a0j

    local markov in g0 implies global markov in g0
    global markov in g0 implies local markov in g (proof as previous slide)

factorization ) structural causal model

generate each p(xj|p aj) in

p(x1, . . . , xn) =

nyj=1

p(xj|p aj)

by a deterministic function:

    de   ne a vector valued noise variable uj
    each component uj[paj] corresponds to a possible value

paj of p aj

    de   ne structural equation

xj = fj(paj, uj) := uj[paj] .

    let component uj[paj] be distributed according to p(xj|paj).

note: joint distribution of all uj[paj] is irrelevant, only
marginals matter

di   erent point of view

x

y

u

=g(x),        u  chooses g     g   
                  

    g denotes set of deterministic mechanisms
    u randomly chooses a mechanism

example: x, y binary

x

u

y

= g(x), u chooses g   {id, n ot, 1, 0}

the same p(x, y ) can be induced by di   erent distributions on g:

    model 1 (no causal link from x to y )

p (g = 0) = 1/2, p (g = 1) = 1/2

    model 2 (random switching between id and n ot )

p (g = id) = 1/2, p (g = n ot ) = 1/2

both induce the uniform distribution for y , independent of x

interval 

what   s the cause and what   s the e   ect?

what   s the cause and what   s the e   ect?

x (altitude) ! y (temperature)

what   s the cause and what   s the e   ect?

what   s the cause and what   s the e   ect?

y (solar radiation) ! x (temperature)

what   s the cause and what   s the e   ect?

what   s the cause and what   s the e   ect?

x (age) ! y (income)

what   s the cause and what   s the e   ect?

30

20

10

0

   10

   20

   30

0

50

100

150

200

250

300

350

400

what   s the cause and what   s the e   ect?

30

20

10

0

   10

   20

   30

0

50

100

150

200

250

300

350

400

x (day in the year) ! y (temperature)

recap: structural causal model 
    xi = fi(parentsofi, noisei), with jointly independent noise1, . . . , noisen.

parents of xj   (pa

)  

j

xj

= fj (paj , uj)

    entails p(x1, . . . , xn) with particular conditional independence structure
assuming markov condition + faithfulness we can recover an equivalence
class containing the correct graph using conditional independence testing.

problems:

1. does not work for graphs with only 2 vertices (even with in   nite data)

2. if we don   t have in   nite data, conditional independence testing can be
arbitrarily hard

hypothesis:

both issues can be resolved by making assumptions on function classes.

restricting the structural causal model 

    consider the graph x ! y
    general functional model

y = f (x, n)

x 

y 

n 

x ?? n

note: if n can take d di   erent values, it could switch randomly
between mechanisms f 1(x), . . . , f d(x)

    additive noise model

y = f (x) + n

causal id136 with additive noise, 2-variable case 

additive noise model (anm):
y := f (x) + ny , with x ?? ny
identi   ability: when is
there a
backward model of the same form?

x 

? 

y 

answer: generically, there is no model
x = g(y ) + nx with y ?? nx

hoyer et al.: nonlinear causal discovery with additive noise models. nips 21, 2009
peters et al: causal discovery with continuous additive noise models, jmlr 2014
peters et al.: detecting the direction of causal time series. icml 2009

intuition 
       assume noise of bounded range	

       additive noise model implies range of y around f is constant	

       for nonlinear f, range of x around backward function non-constant	

identifiability result (hoyer, janzing, mooij, peters, sch  lkopf, 2008) 

theorem 1 (identi   ability of anms) for the purpose of this theorem, let
us call the anm smooth if ny and x have strictly positive densities pny and
px and fy , pny , and px are three times di   erentiable.
assume that py |x admits a smooth anm from x to y , and there exists a y 2 r
such that
(1)

(log pny )00(y   fy (x))f0y (x) 6= 0

for all but countably many values x. then, the set of log densities log px for
which the obtained joint distribution px,y admits a smooth anm from y to x
is contained in a 3-dimensional a ne space.

except for some rare cases, an anm from x to y induces a joint
distribution pxy that does not admit an anm from y to x

idea of the proof

if p(x, y) admits an additive noise model

y = f (x) + ny

with x ?? ny

we have

it then satis   es the di   erential equation

p(x, y) = q(x)r(y   f (x)) .

@

@x    @2 log p(x, y)/@x2

@2 log p(x, y)/@x@y    = 0 .

if it also holds with exchanging x and y, only speci   c cases remain.

alternative view (cf. zhang & hyv  rinen, 2009) 
h di   erential id178
i mutual information
ny := y   f (x), nx := x   g(y ) residual noises
lemma: for arbitrary joint distribution of x, y and functions f ,
g : r ! r, we have:
h(x, y ) = h(x)+h(ny ) i(ny : x) = h(y )+h(nx) i(nx : y ).

note: i(ny : 0) = 0 i    there is an additive noise model from x to
y with function f , i.e.,

y = f (x) + ny

with ny ?? x.

then

h(x) + h(ny )     h(y ) + h(nx).

hence, we can infer the causal direction by comparing sum of en-
tropies

causal id136 method 

prefer the causal direction that can better be    t
with an additive noise model.

implementation:

    compute a function f as non-id75 of x on y
    compute the residual

ny := y   f (x)

    check whether ny and x are statistically independent (un-

correlated is not enough)

experiments 

relation between altitude (cause) and average temperature (effect) 
of places in germany 

!"# $%&'('%&'%)' *'+*+ &'*')* +*#,%- &'('%&'%)'.
/'%)' *0' 1'*0,& (#'2'#+ *0' ),##')* &$#')*$,%

34*$*"&'   *'1('#3*"#'

generalization of anm: post-nonlinear model

assume

then, there is in the    generic    case no such a pnl model from y to x

y = g(f (x) + ny ) with ny ?? x

zhang & hyv  arinen, uai 2009

side note on multivariate anms

for some dag g with nodes x1, . . . , xn assume

xj = fj(p aj) + nj

where all nj are independent

    then one can identify the dag g (except for some rare cases)
    distinguishes even between markov equivalent dags
    avoids conditional

independence testing: if all residuals xj   fj(p aj) are

independent, px1,...,xn satis   es the markov condition w.r.t. g

(addresses two problems with the conditional-independence based approach)

peters et al, uai 2011

inferring conditional independences...

...from unconditional ones

example: if there are functions f, g such that

then

x   f (z) ?? y   f (z)

x ?? y |z.

(condition is su cient, but not necessary)

causal id136 in brain research

grosse-wentrup, janzing, siegel, sch  olkopf, neuroimage 2016

let x, y be some brain state features and s some randomized experimental
condition (i.e., a parentless node!) assume

s 6?? x
s 6?? y
s ?? y | x
then markov condition and faithfulness imply

s ! x ! y

applied to:
x:  -power in the parietal cortex
y :  -power in the medial prefrontal cortex
s instruction to up- or down-regulate x
(conditional independence veri   ed via regression)

so far, we have employed the presence of noise:

    in deterministic causal relations conditional independences get mostly triv-

ial

    anm-based id136 requires noise

what about the noiseless case?

inferring deterministic causality daniusis et al, uai 2010

    problem:

model

infer whether y = f (x) or x = f 1(y ) is the right causal

    idea: if x ! y then f and the density px are chosen independently    by

nature   

    hence, peaks of px do not correlate with the slope of f
    then, peaks of py correlate with the slope of f 1

formalization 
assume that f is a monotonously increasing bijection of [0, 1].
view px and log f 0 as rvs on the prob. space [0, 1] w. lebesgue measure.

postulate (independence of mechanism and input):

cov (log f 0, px) = 0

note: this is equivalent to

z 1

0

log f0(x)p(x)dx =z 1

0

log f0(x)dx,

since
cov (log f 0, px) = e [ log f 0  px] e [ log f 0] e [ px] = e [ log f 0  px] e [ log f 0].

proposition:

cov (log f  10, py)   0

with equality i    f = id.

testable implication / id136 rule

    if x ! y then

z log |f0(x)|p(x)dx    z log |f 10(y)|p(y)dy

(high density p(y) tends to occur at points with large slope)

    empirical estimator
  cx!y :=

1
m

mxj=1

    infer x ! y whenever

log    

yj+1   yj

xj+1   xj        z log |f0(x)|p(x)dx

  cx!y <   cy !x .

   information geometric causal id136   

benchmark dataset with 106 cause-e   ect pairs

http://webdav.tuebingen.mpg.de/cause-effect/

discussion of the ground truth and extensive performance studies for bivariate
causal id136 methods:

mooij et al: distinguishing cause from e   ect using observational data: meth-
ods and benchmarks, jmlr 2016

   cause-effect pairs     examples 

!"# $

!"# %

&"'"()'

*#+,-& '#,'.

>)5)-'
&"03a "3>+.+3 >+-(,5/'0+-

/"0#111$ 23'0',&)
/"0#1118 2*) 9:0-*(;
/"0#11$% 2*)
/"0#11%8
/"0#11@@
/"0#11b1 2*)
&"a
/"0#11b%
/"0#11bg
h>"#(i%b.
&#0-l0-* m"')# ">>)((
/"0#11kb
=a')( ()-'
/"0#11kp
/"0#11kr
0-(0&) #++5 ')5/)#"',#)
/"#"5)')#
/"0#11g1
/"0#11g%
(,-(/+' "#)"
/"0#11gb wox /)# >"/0'"
/"0#11gp

4)5/)#"',#)
<)-*'.
7"*) /)# .+,#
>+5/#)((0!) ('#)-*'.
5>! 5)"- >+#/,(>,3"# !+3,5)
&0"('+30> =3++& /#)((,#)
')5/)#"',#)
(/)>0j0> &"a(
0-j"-' 5+#'"30'a #"')
+/)- .''/ >+--)>'0+-(
+,'(0&) ')5/)#"',#)
()u
*3+="3 5)"- ')5/)#"',#)
30j) )u/)>'"->a "' =0#'.

676
2="3+-)
>)-(,( 0->+5)
>+->#)')?&"'"
30!)# &0(+#&)#(
/05" 0-&0"-
cd e"-f0-*
'#"jj0>
no&"'"
qd 6"-0,(0(
ed sd s++0t
cv3'.+jj
(,-(/+' &"'"
no&"'"

qqy6 9q.+'+(a-'.d q.+'+- y3,u; ozq 9o)' z>+(a(')5 q#+&,>'0!0'a; s+jj"' 2d sd

   
   
   
   
   
   
   
 
   
 
 
   
   
   
   

igci: 
deterministic 
method 
 
lingam: 
shimizu et al., 
2006 
 
an: 
additive noise 
model (nonlinear) 
 
pnl: 
an with post- 
nonlinearity 
 
gpi: 
mooij et al., 
2010 
 
 
(source: mooij et 
al, jmlr 2016) 

independence of input and mechanism 

causal structure:

c cause
e e   ect
n noise
' mechanism

assumption:
p(c) and p(e|c) are    independent   

janzing & sch  olkopf, ieee trans. inf. theory, 2010; cf. also lemeire & dirkx, 2007

recall di   erent aspects of independence

    informational: pc and pe|c don   t contain information about each other
    modularity: pc and pe|c often change independently across datasets
) machine learning should care about the causal direction in prediction tasks

causal learning and anticausal learning 
sch  lkopf, janzing, peters, sgouritsa, zhang, mooij, icml 2012 

    example 1: predict gene from mrna sequence

prediction

x

id
nx

  

y

ny

source: http://commons.wikimedia.org/wiki/file:peptide_syn.png 

causal mechanism '

    example 2: predict class membership from handwritten digit
prediction

  

x

nx

y

id
ny

prediction with changing distributions

assume distributions px and p 0x di   er between training and test data

    causal prediction, x = c, y = e: use the same py |x also for the test
data because probably py |x remained the same (even if we knew that it
changed too we would still use py |x in absence of a better candidate).
   covariate shift   

    anticausal prediction, x = e, y = c: probably also py |x has changed

(maybe only py changed or only px|y )

semi-supervised learning (ssl)

in addition to (x, y)-pairs, ssl uses unlabeled x-values to predict y from x

    causal prediction: px doesn   t tell us something about py |x, why should

unlabeled instances help?

(ssl requires more subtle phenomena to work)

    anticausal prediction: px may contain information about py |x there-

fore the unlabeled instances help

y=0  y=1 

covariate shift and semi-supervised learning 
goal: learn x 7! y , i.e., estimate (properties of) p(y |x)
semi-supervised learning: improve estimate by more data from p(x)
covariate shift: p(x) changes between training and test
causal assumption: p(c) and mechanism p(e|c)    independent   
causal learning
p(x) and p(y |x) independent
1. semi-supervised learning hard
2. p(y |x) invariant under change in p(x)
anticausal learning
p(y ) and p(x|y ) independent
hence p(x) and p(y |x) dependent
1. semi-supervised learning possible
2. p(y |x) changes with p(x)

id
nx

sch  lkopf, janzing, peters, sgouritsa, zhang, mooij, 2012, cf. storkey, 2009; bareinboim & pearl, 2012 

nx

x

x

  

  

ny
causal mechanism '
prediction

prediction

y

y

id
ny

semi-supervised learning (sch  lkopf et al., icml 2012) 
       known ssl assumptions link p(x) to p(y|x): 

       cluster assumption: points in same cluster of p(x) have 

the same y 

       low density separation assumption: p(y|x) should cross 

0.5 in an area where p(x) is small 

       semi-supervised smoothness assumption: e(y|x) should be 

smooth where p(x) is large 

       next slides: experimental analysis 

 

000
001
002
003
004
005
006
007
008
009
010
011
012
013
014
015
016
017
018
019
020
021
022
023
024
025
026
027
028
029
030
031
032

ssl book benchmark datasets     chapelle et al. (2006) 
supplementary material for: on causal and anticausal learning

table 1. categorization of eight benchmark datasets as anticausal/confounded, causal or unclear

category

anticausal/
confounded

causal
unclear

dataset
g241c: the class causes the 241 features.
g241d: the class (binary) and the features are confounded by a variable with 4 states.
digit1: the positive or negative angle and the features are confounded by the variable of continuous angle.
usps: the class and the features are confounded by the 10-state variable of all digits.
coil: the six-state class and the features are confounded by the 24-state variable of all objects.
secstr: the amino acid is the cause of the secondary structure.
bci, text: unclear which is the cause and which the effect.

table 2. categorization of 26 uci datasets as anticausal/confounded, causal or unclear

categ.

d
e
d
n
u
o
f
n
o
c

/
l
a
s
u
a
c
i
t
n
a

dataset
breast cancer wisconsin: the class of the tumor (benign or malignant) causes some of the features of the tumor (e.g.,
thickness, size, shape etc.).
diabetes: whether or not a person has diabetes affects some of the features (e.g., glucose concentration, blood pres-
sure), but also is an effect of some others (e.g. age, number of times pregnant).
hepatitis: the class (die or survive) and many of the features (e.g., fatigue, anorexia, liver big) are confounded by the
presence or absence of hepatitis. some of the features, however, may also cause death.
iris: the size of the plant is an effect of the category it belongs to.
labor: cyclic causal relationships: good or bad labor relations can cause or be caused by many features (e.g., wage
increase, number of working hours per week, number of paid vacation days, employer   s help during employee    s long
term disability). moreover, the features and the class may be confounded by elements of the character of the employer
and the employee (e.g., ability to cooperate).

055
056
057
058
059
060
061
062
063
064
065
066
067
068
069
070
071
072
073
074
075
076
077
078
079
080
081
082
083
084
085
086
087

causal
unclear

coil: the six-state class and the features are confounded by the 24-state variable of all objects.
secstr: the amino acid is the cause of the secondary structure.
bci, text: unclear which is the cause and which the effect.

uci datasets used in ssl benchmark     guo et al., 2010 

categ.

d
e
d
n
u
o
f
n
o
c

/
l
a
s
u
a
c
i
t
n
a

causal

table 2. categorization of 26 uci datasets as anticausal/confounded, causal or unclear

dataset
breast cancer wisconsin: the class of the tumor (benign or malignant) causes some of the features of the tumor (e.g.,
thickness, size, shape etc.).
diabetes: whether or not a person has diabetes affects some of the features (e.g., glucose concentration, blood pres-
sure), but also is an effect of some others (e.g. age, number of times pregnant).
hepatitis: the class (die or survive) and many of the features (e.g., fatigue, anorexia, liver big) are confounded by the
presence or absence of hepatitis. some of the features, however, may also cause death.
iris: the size of the plant is an effect of the category it belongs to.
labor: cyclic causal relationships: good or bad labor relations can cause or be caused by many features (e.g., wage
increase, number of working hours per week, number of paid vacation days, employer   s help during employee    s long
term disability). moreover, the features and the class may be confounded by elements of the character of the employer
and the employee (e.g., ability to cooperate).
letter: the class (letter) is a cause of the produced image of the letter.
mushroom: the attributes of the mushroom (shape, size) and the class (edible or poisonous) are confounded by the
taxonomy of the mushroom (23 species).
image segmentation: the class of the image is the cause of the features of the image.
sonar, mines vs. rocks: the class (mine or rock) causes the sonar signals.
vehicle: the class of the vehicle causes the features of its silhouette.
vote: this dataset may contain causal, anticausal, confounded and cyclic causal relations. e.g., having handicapped
infants or being part of religious groups in school can cause one   s vote, being democrat or republican can causally
in   uence whether one supports nicaraguan contras, immigration may have a cyclic causal relation with the class.
crime and the class may be confounded, e.g., by the environment in which one grew up.
vowel: the class (vowel) causes the features.
wave: the class of the wave causes its attributes.
balance scale: the features (weight and distance) cause the class.
chess (king-rook vs. king-pawn): the board-description causally in   uences whether white will win.
splice: the dna sequence causes the splice sites.

unclear breast-c, colic, sick, ionosphere, heart, credit approval were unclear to us. in some of the datasets, it is unclear
whether the class label may have been generated or de   ned based on the features (e.g., ionoshpere, credit approval,
sick).

016
017
018
019
020
021
022
023
024
025
026
027
028
029
030
031
032
033
034
035
036
037
038
039
040
041
042
043
044
045
046
047
048
049
050
051
052
053

071
072
073
074
075
076
077
078
079
080
081
082
083
084
085
086
087
088
089
090
091
092
093
094
095
096
097
098
099
100
101
102
103
104
105
106
107
108

datasets, co-regularized ls regression     brefeld et al., 2006 

table 3. categorization of 31 datasets (described in the paragraph    semi-supervised regression   ) as anticausal/confounded, causal or
unclear

categ. dataset

breasttumor
cholesterol

cleveland

lowbwt
pbc

pollution

wisconsin
autompg

cpu

   shcatch
housing

machine cpu
meta

target variable
tumor size
cholesterol

presence of heart disease in the pa-
tient
birth weight
histologic stage of disease

age-adjusted mortality rate per
100,000
time to recur of breast cancer
city-cycle fuel consumption in
miles per gallon
cpu relative performance

   sh weight
housing values
boston
cpu relative performance
normalized prediction error

in suburbs of

pwlinear
sensory
servo

value of piecewise linear function
wine quality
rise time of a servomechanism

remark
causing predictors such as inv-nodes and deg-malig
causing predictors such as resting blood pressure and fasting blood
sugar
causing predictors such as chest pain type, resting blood pressure,
and fasting blood sugar
causing the predictor indicating low birth weight
causing predictors such as serum bilirubin, prothrombin time, and
albumin
causing the predictor number of 1960 smsa population aged 65
or older
causing predictors such as perimeter, smoothness, and concavity
caused by predictors such as horsepower and weight

caused by predictors such as machine cycle time, maximum main
memory, and cache memory
caused by predictors such as    sh length and    sh width
caused by predictors such as pupil-teacher ratio and nitric oxides
concentration
see remark on    cpu   
caused by predictors such as number of examples, number of at-
tributes, and id178 of classes
caused by all 10 involved predictors
caused by predictors such as trellis
caused by predictors such as gain settings and choices of mechan-
ical linkages

auto93 (target: midrange price of cars); bodyfat (target: percentage of body fat); autohorse (target: price of cars);
autoprice (target: price of cars); baskball (target: points scored per minute);
cloud (target: period rainfalls in the east target); echomonths (target: number of months patient survived);
fruit   y (target: longevity of mail fruit   ies); pharynx (target: patient survival);
pyrim (quantitative structure activity relationships); sleep (target: total sleep in hours per day);
stock (target: price of one particular stock); strike (target: strike volume);
triazines (target: activity); veteran (survival in days)

d
e
d
n
u
o
f
n
o
c

/
l
a
s
u
a
c
i
t
n
a

l
a
s
u
a
c

r
a
e
l
c
n
u

116
117
118
119
120
121
122
123
124
125
126
127
128
129
130
131
132
133
134
135
136
137
138
139
140
141
142
143
144
145
146
147
148
149
150
151
152
153
154
155
156

171
172
173
174
175
176
177
178
179
180
181
182
183
184
185
186
187
188
189
190
191
192
193
194
195
196
197
198
199
200
201
202
203
204
205
206
207
208
209
210
211

on causal and anticausal learning

benchmark datasets of chapelle et al. (2006)  

data points sampled from p (c, e) and additional points
from p 0(e) 6= p (e), we wish to decide whether p (c) or
p (e|c) has changed. to show that appropriate assump-
tions render this problem solvable, we sketch some rough
ideas. let e =  (c) + ne , with the same   for both
distributions p (e, c) and p 0(e, c), but the distribution
of the noise ne or the distribution of c changes. let
p ( (c)) denote the distribution of  (c).4 then the

where either p 0( (c)) = p ( (c)) or p 0(ne) = p (ne).
in the following situations, for instance, we can decide

1) if the fourier transform of p (e) contains zeros, then

s
r
e
i
f
i
s
s
a
l
c
 
d
e
s
i
v
r
e
p
u
s
   
m
e
s
 

i

d
n
a
 
e
s
a
b
 
f
o
 
y
c
a
r
u
c
c
a

100

90

80

70

60

50

40

30

 

anticausal/confounded
causal
unclear
g241c g241d digit1 usps coil bci

 

605
606
607
608
609
610
611
612
613
614
615
616
617
618
619
620
asterisk = 1-nn, id166 
621
622
623

text secstr

figure 5. accuracy of base classi   ers (star shape) and different
ssl methods on eight benchmark datasets.

679
680
681
682
683
684
685
686
687
688
689
690
691
692
693
694
695
696
697

and were not extensions of the base classi   ers; moreover,
the results for the secstr dataset are based on a different set
of methods than the rest of the benchmarks.
self-training does not help for causal problems (cf. guo et al., 2010)  

r

60

40

20

0

   20

   40

   60

   80

   100

 

 

anticausal/confounded
causal
unclear

ba   sc br   c br   w col col.o cr   a cr   g diab he   c he   h he   s hep

ion

iris kr   kp lab

lett mush seg sick son splic vehi vote vow wave

relative error decrease = (error(base)    error(self-train)) / error(base) 

figure 6. plot of the relative decrease of error when using self-
training, for six base classi   ers on 26 uci datasets. here, rel-
ative decrease is de   ned as (error(base)   error(self-train)) / er-

r
o
r
r
e

 
.

d
t
s
 
  

in view of our hypothesis, it is encouraging to see (fig-
ure 5) that ssl does not signi   cantly improve the accuracy
in the one causal dataset, but it helps in most of the anti-
causal/confounded datasets. however, it is dif   cult to draw
conclusions from this small collection of datasets; more-
over, two additional issues may confound things: (1) the
experiments were carried out in a transductive setting. in-
ductive methods use unlabeled data to arrive at a classi   er
which is subsequently applied to an unknown test set; in
contrast, transductive methods use the test inputs to make
predictions. this could potentially allow performance im-
provements independent of whether a dataset is causal or
anticausal; (2) the ssl methods used cover a broad range,
and were not extensions of the base classi   ers; moreover,
the results for the secstr dataset are based on a different set

 

anticausal/confounded
causal
unclear

our hypothesis that if mechanism and input are indepen-
dent, ssl will not help for causal datasets.

co-id173 helps for the anticausal problems of brefeld et al., 2006 

r
o
r
r
e
 
.
d
t
s
 
  
 
e
s
m
r

0.5
0.45
0.4
0.35
0.3
0.25
0.2
0.15
0.1
0.05
0
 
bre a stt

supervised
semi   supervised

 

m

u

or
c h ole sterol

cle v ela n d

w t

b

w

lo

p b c

p ollutio n

w is c o n sin

figure 7. rmse for anticausal/confounded datasets.

721
722
723
724
725
726
727
728
729
730
731
732
733
734
735
736
737
738
739
740
741
742
743
744

figure 7. rmse for anticausal/confounded datasets.

co-id173 hardly helps for the causal problems of brefeld et al., 2006 

lett mush seg sick son splic vehi vote vow wave

figure 6. plot of the relative decrease of error when using self-
training, for six base classi   ers on 26 uci datasets. here, rel-
ative decrease is de   ned as (error(base)   error(self-train)) / er-
ror(base). self-training, a method for ssl, overall does not help
for the causal datasets, but it does help for several of the anti-

we next consider 26 uci datasets and six different base
classi   ers. the original results are from tables iii and iv
in (guo et al., 2010), and are presently re-analyzed in terms
of the above dataset categories. the comprehensive results
of guo et al. (2010) allow us the luxury of (1) consider-
ing only self-training, which is an extension of supervised

supervised
semi   supervised

 

0.35

0.3

0.25

0.2

0.15

0.1

0.05

r
o
r
r
e

 
.

d

t
s
 
  
 
e
s
m
r

0
 
a uto

p g

m

fis h c atc h
c p u

a c hin e _ c p u
h o u sin g
m

m

eta
p

lin e ar

s e n s ory

w

s erv o

figure 8. rmse for causal datasets.

742
743
744
745
746
747
748
749
750
751
752
753
754
755
756
757
758
759
760
761

causal id136 for individual objects (janzing & sch  lkopf, 2010) 

!"#"$%&"'"() *('+((, )",-$( .*/(0') %$). ",1"0%'( 0%2)%$ &($%'".,)3

4.+(5(&6 "7 )"#"$%&"'"() %&( '.. )"#8$( '9(&( ,((1 ,.' *( % 0.##., 0%2)(3

) try to quantify complexity of similarities

kolmogorov complexity 

conditional kolmogorov complexity 

    k(y | x   ): length of the shortest program that generates y
from the shortest description of the input x. for simplicity, we
write k(y | x).
tion of x is given

    number of bits required for describing y if the shortest descrip-

    note: x can be generated from its shortest description but not

vice versa because there is no algorithmic way to
   nd the shortest compression

algorithmic mutual information (chaitin, gacs) 

information of x about y

    i (x : y)

:= k(x) + k(y)   k(x, y)
= k(x)   k(x| y) = k(y)   k(y | x)

    interpretation: number of bits saved when compressing x, y

jointly rather than independently

    algorithmic independence x ?? y : () i (x : y) = 0

 conditional algorithmic mutual information 

information that x has on y (and vice versa) when z is given

    i (x : y | z   ) := k (x| z   ) + k (y | z   )   k (x, y | z   )
    analogy to statistical mutual information:

i (x : y | z) = s (x | z) + s (y | z)   s (x, y | z)

    conditional algor. independence x ?? y | z :() i (x : y | z) = 0

algorithmic mutual information: example 

postulate: local algorithmic markov condition 

let x1, . . . , xn be observations (formalized as strings). given its di-
rect causes paj, every xj is conditionally algorithmically independent
of its non-e   ects ndj

xj ?? ndj | paj

causal markov conditions 

    recall the (local) causal markov condition:

an observable is statistically independent of its non-descendants, given
parents

    reformulation:

given all direct causes of an observable, its non-e   ects provide no addi-
tional statistical information on it

causal markov conditions 

    generalization:

given all direct causes of an observable, its non-e   ects provide no addi-
tional statistical information on it

    algorithmic causal markov condition:

given all direct causes of an object, its non-e   ects provide no additional
algorithmic information on it

equivalence of algorithmic markov conditions 

for n strings x1, . . . , xn the following conditions are equivalent

    local markov condition

i (xj : ndj | paj ) = 0

    global markov condition:

if r d-separates s and t then i (s : t | r) = 0

    recursion formula for joint complexity

k(x1, . . . , xn) =

nxj=1

k(xj | paj)

janzing & sch  olkopf, ieee trans. id205, 2010

algorithmic model of causality 

from its parents paj

    for every node xj there exists a program uj that computes xj
uj	

paj	

=t(paj,uj)	
    all uj are jointly independent
    the program uj represents the causal mechanism that generates

xj	
xj	

the e   ect from its causes

    uj are the analog of the unobserved noise terms in the statistical

functional model

theorem: this model implies the algorithmic markov condition

generalized independences steudel, janzing, sch  olkopf (2010)

given n objects o := {x1, . . . , xn}
observation: if a function r : 2o ! r+

0 is submodular, i.e.,

r(s) + r(t )   r(s [ t ) + r(s \ t )

8s, t    o

then

i(a; b |c) := r(a [ c) + r(b [ c)   r(a [ b [ c)   r(c)   0

for all disjoint sets a, b, c    o
interpretation: i measures conditional dependence
(replace r with shannon id178 to obtain usual mutual information)

generalized markov condition

theorem: the following conditions are equivalent for a dag g

    local markov condition

xj ?? ndj |paj

    global markov condition: d-separation implies independence

    sum rule

r(a) =xj2a

r(xj|paj) ,

for every ancestral set a of nodes.

   but can we postulate that the conditions hold w.r.t. to the true dag?

generalized structural causal model

theorem:

    assume there are unobserved objects u1, . . . , un

paj	

xj	

uj	

    assume

r(xj, paj, uj) = r(paj, uj)

(xj contains only information that is already contained in its parents +
noise object)

then x1, . . . , xn satisfy the markov conditions

) causal markov condition is justi   ed provided that mechanisms    t to infor-
mation measure

generalized pc

pc algorithm also works with generalized conditional independence

examples:

1. r := number of di erent words in a text

2. r := compression length (e.g. lempel ziv is approximately submodular)

3. r := logarithm of period length of a periodic function

example 2 yielded reasonable results on simple real texts (di erent versions of
a paper abstract)

   independent   = algorithmically independent?

postulate (janzing & sch  olkopf, 2010, inspired by lemeire & dirkx, 2006):
the causal conditionals p(xj|p aj) are algorithmically independent

    special case: p(x) and p(y |x) are alg. independent for x ! y
    abstract version: the mechanism that relates cause and e   ect is algorith-

mically independent of the cause

    can be used as justi   cation for novel id136 rules (e.g., for additive noise

models: steudel & janzing 2010)

    excludes many, but not all violations of faithfulness (lemeire & janzing,

2012)

a physical example 

particles scattered at an object

    by default, only the outgoing particles contain information about
the object
    time-reversing the scenario requires    ne-tuning the incoming beam
    consider incoming and outgoing beams as    cause    and    e   ect   
       cause    contains no information about the mechanism relating cause
and e   ect (the object), but    e   ect    does

algorithmic independence of initial state and dynamics 

independence principle.
if s is the initial state of a physical
system and m a map describing the e   ect of applying the system
dynamics for some    xed time, then s and m are algorithmically inde-
pendent

i(s : m) += 0,

i.e., knowing s does not enable a shorter description of m and vice
versa.

reproduces the thermodynamic arrow of time 

theorem [non-decrease of id178]. let d be a bijective map
on the set of states of a system then i(s : d) += 0 implies

k(d(s))

+

  k(s)

proof idea: if d(s) admits a shorter description than s, knowing d admits a shorter
description of s: just describe d(s) and then apply d 1.

    k(s) has been proposed as physical id178 (zurek, bennett)
    id178 increase amounts to heat production (irreversible process)

janzing, chaves, sch  olkopf: algorithmic independence of initial condition and
dynamical law in thermodynamics and causal id136. new journal of physics,
2016

common root of thermodyn. and causal id136

algorithmic independence of

cause
and

mechanism relating cause and e   ect

    reproduces arrow of time in physics
    justi   es new causal id136 rules

exoplanet transits 

 
       earth: annual 84ppm signal for    day, visible from 0.5% of all 

directions 

       many planets found, but nothing quite like earth/sun 

       both spacecraft and stars vary, leading to changes that are 

sometimes much bigger than the signal 

mit hogg, wang, foreman-
mackey, janzing, simon-gabriel, 
peters, montet, and morton. 
icml 2015 
astrophysical journal 2015 
pnas 2016 

half-siblings 

|  3 months  | 

half-sibling regression 

unobserved

observed

q

y

n

x

idea: remove e[y |x] from y to reconstruct q.

x ?? q
x and y share information
(only) through n

if we try to predict y from x,
we only pick up the part due to n

with david hogg, dan foreman-mackey, dun wang, dominik janzing,
jonas peters, carl-johann simon-gabriel (icml 2015)

proposition. q, n, y, x random variables, x ?? q, and f measurable.
de   ne
      q := y   e[y |x].
suppose e[q] = 0 and
    y = q + f (n) (additive noise model)
then e[(   q   q)2] = e[var[f (n)|x]] .
if f (n) can (in principle) be predicted well from x,
then q can be reconstructed well by   q.

unobserved

observed

q

y

n

x

proposition. r, n, q jointly independent.
suppose

x = g(n) + r

recovery results if either
(i) magnitude of r goes to 0 (i.e., in   uence of stars negligible), or
(ii) r is a random vector whose components are jointly independent
(i.e., many independent stars).

r 

summary

    conventional causal id136 algorithms use conditional statistical depen-

dences

    more recent approaches also use other properties of the joint distribution
    non-statistical dependences also tell us something about causal directions

