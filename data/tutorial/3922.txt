   #[1]search ercim news

   (button)

sidebar

   (button)   
     * [2]research and innovation
          + [3]predictive modelling from data streams
          + [4]mandola: monitoring and detecting online hate speech
          + [5]the b  se testbed     analytic evaluation of it security tools
            in specified network environments
          + [6]behaviour-based security for cyber-physical systems
          + [7]the tisrim-telco toolset     an it regulatory framework to
            support security compliance in the telecommunications sector
          + [8]predicting the extremely low frequency magnetic field
            radiation emitted from laptops: a new approach to laptop
            design
          + [9]managing security in distributed computing: self-protective
            multi-cloud applications
          + [10]basmati     cloud brokerage across borders for mobile users
            and applications
     * [11]in brief
          + [12]2016 internet defense prize for quantum-safe cryptography
     * [13]special theme
          + [14]modern machine learning: more with less, cheaper and
            better
          + [15]micro-data learning: the other end of the spectrum
          + [16]making learning physical: machine intelligence and quantum
            resources
          + [17]marrying id114 with deep learning
          + [18]privacy aware machine learning and the    right to be
            forgotten   
          + [19]robust and adaptive methods for sequential decision making
          + [20]neural random access machines
          + [21]mining similarities and concepts at scale
          + [22]fast traversal of large ensembles of regression trees
          + [23]optimising deep learning for infinite applications in text
            analytics
          + [24]towards streamlined big data analytics
          + [25]autonomous machine learning
          + [26]curiosity and intrinsic motivation for autonomous machine
            learning
          + [27]applied data science: using machine learning for alarm
            verification
          + [28]towards predictive pharmacogenomics models
          + [29]optimisation system for cutting continuous flat glass
          + [30]online learning for aggregating forecasts in renewable
            energy systems
          + [31]bonaparte: id110s to give victims back their
            names
     * [32]research and society
          + [33]open science: taking our destiny into our own hands
          + [34]ercim goes to open access
          + [35]will europe liberate knowledge through content mining?
          + [36]roads to open access: the good, the bad and the ugly
          + [37]open-access repositories and the open science challenge
          + [38]lipics     an open-access series for international
            conference proceedings
          + [39]scientific data and preservation     policy issues for the
            long-term record
          + [40]mathematics in open access     mathoa

   [41]ercim news
   (button)
   ____________________

     * [42]subscription
     * [43]back issues
     * [44]about
     * [45]call for contributions
     * [46]advertise

    1.
    2. [47]home
    3. [48]ercim news 107
    4. [49]special theme
    5. marrying id114 with deep learning


   [50]image ercim news 107 cover page

   ercim news 107
   october 2016
   special theme: machine learning

   guest editors: sander bohte (cwi ) and hung son nguyen (university of
   warsaw)

   this issue in [51]pdf (60 pages)
     * [52]ercim news 116
     * [53]ercim news 115
     * [54]ercim news 114
     * [55]ercim news 113
     * [56]ercim news 112
     * [57]ercim news 111
     * [58]ercim news 110
     * [59]ercim news 109
     * [60]ercim news 108
     * [61]ercim news 107
     * [62]ercim news 106
     * [63]ercim news 105
     * [64]ercim news 104
     * [65]ercim news 103
     * [66]ercim news 102
     * [67]ercim news 101
     * [68]ercim news 100
     * [69]ercim news 99
     * [70]ercim news 98
     * [71]ercim news 97
     * [72]ercim news 96
     * [73]ercim news 95
     * [74]ercim news 94
     * [75]ercim news 93
     * [76]ercim news 92
     * [77]ercim news 91
     * [78]ercim news 90
     * [79]ercim news 89
     * [80]ercim news 88
     * [81]ercim news 87
     * [82]ercim news 86
     * [83]ercim news 85
     * [84]ercim news 84
     * [85]ercim news 83
     * [86]ercim news 82
     * [87]ercim news 81
     * [88]ercim news 80
     * [89]ercim news 79
     * [90]ercim news 78
     * [91]ercim news 77
     * [92]ercim news 76
     * [93]ercim news 75
     * [94]ercim news 74
     * [95]ercim news 73
     * [96]ercim news 71
     * [97]ercim news 72
     * [98]ercim news 70
     * [99]ercim news 68
     * [100]ercim news 67
     * [101]ercim news 69

contents

     * [102]research and innovation
     * [103]in brief
     * [104]special theme
     * [105]research and society

[106]marrying id114 with deep learning

   details
          [107]special theme: machine learning
          28 september 2016

   hits: 9446

   by max welling (university of amsterdam)

   in our research at the university of amsterdam we have married two
   types of models into a single comprehensive framework which we have
   called    variational auto encoders   . the two types of models are: 1)
   generative models where the data generation process is modelled, and 2)
   discriminative models, such as deep learning, where measurements are
   directly mapped to class labels.

   deep learning is particularly successful in learning powerful (e.g.,
   predictive/ discriminative) features from raw, unstructured sensor
   data. deep neural networks can effectively turn raw data streams into
   new representations that represent abstract, disentangled and
   semantically meaningful concepts. based on these, a simple linear
   classifier can achieve the state of the art. but to learn them one
   needs very large quantities of annotated data. they are flexible
   input-output mappings but do not incorporate a very sophisticated
   inductive bias about the world. an important question is how far will
   this take us?

   if we are asked to analyse a scene depicted in an image we seek a story
   that can explain the things we see in the image. yes, there is a fast
   feedforward pipeline that quickly segments out the objects and
   classifies them into object classes. but when you need to truly
   understand a scene you will try to infer a story about which events
   caused other events, which in turn led to the image you are looking at.
   this causal story is also a powerful tool to predict how the events may
   unfold into the future.

   so, to understand and reason about the world we need to find its causal
   atoms and their relationships. now this is precisely what bayesian
   networks [1] were intended to do. each random variable connects to
   other random variables and their directed relations model their causal
   relationships. (id110s do not necessarily represent the
   causal relationships, but an extension called    structural equation
   models    does.) another key advantage of interpretable models like
   id110s is that they can express our expert knowledge. if we
   know x causes y then we can simply hard-code that relation into the
   model. relations that we do not know will need to be learned from the
   data. incorporating expert knowledge (e.g., the laws of physics) into
   models is the everyday business of scientists. they build sophisticated
   simulators with relatively few unidentified parameters, for instance
   implemented as a collection of partial differential equations (pdes).

   generative models can also be used for classification by inverting the
   relationship they model from class label to input features. when you
   have a lot of (labelled) data at your disposal this type of classifier
   will generally speaking not work as well as a direct mapping from input
   features to labels (such as a deep neural network). but when the amount
   of data is small relative to the complexity of the task, the
   opportunity to inject expert knowledge may pay back. concluding, for
   very complex tasks (causal) generative models should in my opinion be
   part of the equation.

   can id114 and deep neural networks be meaningfully combined
   into a more powerful framework? the variational auto-encoder (vae)
   naturally combines generative models with discriminative models where
   the generative model can be a id110 or a simulator and the
   discriminative model a deep neural network [2]. the discriminative
   model performs id136 of the unobserved (latent) variables necessary
   to perform the (variational em) learning updates. in this view the
   discriminative model approximately inverts the generative model.
   however, one can also interpret the vae differently if we are more
   interested in the latent representation itself (based on which we can
   for instance perform classification). now the generative model guides
   the discriminative model to learn interesting, semantically meaningful
   representations. they represent the fundamental sources of variation
   that are the input for the generative model. thus, the generative model
   may be viewed as an informed way to regularize the discriminative
   model.

   vaes as described above are a framework for unsupervised learning.
   however, they are easily extended to semi-supervised learning by
   incorporating labels in the generative model [3]. in this case the
   input data are generated by instantiating a label and some latent
   variables and sampling from the id110. in contrast, the
   discriminative model inverts this relationship and learns a mapping
   from input directly to class labels and latent variables (see figure
   1). semi-supervised learning is now easy, because for the unlabelled
   examples, the label variable is treated as latent, while for a labelled
   data-case it is treated as observed.

   figure 1: example of a variational auto-encoder model. on the right we
   have the generative model with three groups of variables at the top:
   class labels y, nuisance variables s and latent variables z. in this
   example, we may think of y as disease labels, s as hospital identifiers
   and z as size, shape and other relevant properties of a brain. these
   variables are input to the generative process that generates a pseudo
   data case; in the example an mri image of a brain. the discriminative
   or recognition model on the left takes all the observed variables as
   input and generates posterior distributions over the latent variables
   and possibly (if unobserved) the class labels. the models are trained
   jointly using the variational em framework.
   figure 1: example of a variational auto-encoder model. on the right we
   have the generative model with three groups of variables at the top:
   class labels y, nuisance variables s and latent variables z. in this
   example, we may think of y as disease labels, s as hospital identifiers
   and z as size, shape and other relevant properties of a brain. these
   variables are input to the generative process that generates a pseudo
   data case; in the example an mri image of a brain. the discriminative
   or recognition model on the left takes all the observed variables as
   input and generates posterior distributions over the latent variables
   and possibly (if unobserved) the class labels. the models are trained
   jointly using the variational em framework.

   in summary, marrying (discriminative) deep learning with causality and
   probabilistic reasoning in id114 may be an important
   component in reaching the ambitious goals of artificial general
   intelligence. however, most likely completely new ideas are needed as
   well.

   references:
   [1] pearl, judea:    probabilistic reasoning in intelligent systems:
   networks of plausible id136    morgan kaufmann, 2014.
   [2] kingma, p. diederik, and m. welling:    auto-encoding variational
   bayes   , the international conference on learning representations
   (iclr), banff, 2014.
   [3] kingma, p. diederik et al.:    semi-supervised learning with deep
   generative models   , advances in neural information processing systems
   2014: 3581-3589.
   [108]https://www.youtube.com/watch?v=xnzin7jh3sg
   http://dpkingma.com/?page_id=277

   please contact:
   max welling
   university of amsterdam (uva)
   +31 (0)20 525 8256
   this email address is being protected from spambots. you need
   javascript enabled to view it.
   [109]http://www.ics.uci.edu/~welling/staff.fnwi.uva.nl/m.welling/

   next issue: april 2019
   special theme:
   5g
   [110]call for the next issue
     __________________________________________________________________

   [111]image ercim news 107 epub
   this issue in [112]epub format
     __________________________________________________________________

   [ins: :ins]
   get the latest issue to your desktop
   [113]rss feed

   (button)

   ercim news is licensed under a [114]creative commons attribution 4.0
   international license. you are free to share     copy and redistribute
   the material in any medium or format, as long as the author(s) and the
   source are credited.
   ercim articles (sections "special theme" and "research and innovation)
   are referenced by [115]dblp
   ercim news is a joint publication of italy  [116]cnr the netherlands
   [117]cwi germany  [118]fraunhofer luxembourg  [119]fnr greece
   [120]forth portugal  [121]inesc france  [122]inria greece  [123]isi
   norway  [124]ntnu austria  [125]sba sweden  [126]sics hungary
   [127]sztaki   the netherlands [128]tno cyprus  [129]ucy poland
   [130]uwaw finland  [131]vtt    ercim 2016 | [132]legal information

references

   visible links
   1. https://ercim-news.ercim.eu/component/search/?itemid=2326&format=opensearch
   2. https://ercim-news.ercim.eu/en107/r-i
   3. https://ercim-news.ercim.eu/en107/r-i/predictive-modelling-from-data-streams
   4. https://ercim-news.ercim.eu/en107/r-i/mandola-monitoring-and-detecting-online-hate-speech
   5. https://ercim-news.ercim.eu/en107/r-i/the-baese-testbed-analytic-evaluation-of-it-security-tools-in-specified-network-environments
   6. https://ercim-news.ercim.eu/en107/r-i/behaviour-based-security-for-cyber-physical-systems
   7. https://ercim-news.ercim.eu/en107/r-i/the-tisrim-telco-toolset-an-it-regulatory-framework-to-support-security-compliance-in-the-telecommunications-sector
   8. https://ercim-news.ercim.eu/en107/r-i/predicting-the-extremely-low-frequency-magnetic-field-radiation-emitted-from-laptops-a-new-approach-to-laptop-design
   9. https://ercim-news.ercim.eu/en107/r-i/managing-security-in-distributed-computing-self-protective-multi-cloud-applications
  10. https://ercim-news.ercim.eu/en107/r-i/basmati-cloud-brokerage-across-borders-for-mobile-users-and-applications
  11. https://ercim-news.ercim.eu/en107/ib
  12. https://ercim-news.ercim.eu/en107/ib/2016-internet-defense-prize-for-quantum-safe-cryptography
  13. https://ercim-news.ercim.eu/en107/special
  14. https://ercim-news.ercim.eu/en107/special/modern-machine-learning-more-with-less-cheaper-and-better
  15. https://ercim-news.ercim.eu/en107/special/micro-data-learning-the-other-end-of-the-spectrum
  16. https://ercim-news.ercim.eu/en107/special/making-learning-physical-machine-intelligence-and-quantum-resources
  17. https://ercim-news.ercim.eu/en107/special/marrying-graphical-models-with-deep-learning
  18. https://ercim-news.ercim.eu/en107/special/privacy-aware-machine-learning-and-the-right-to-be-forgotten
  19. https://ercim-news.ercim.eu/en107/special/robust-and-adaptive-methods-for-sequential-decision-making
  20. https://ercim-news.ercim.eu/en107/special/neural-random-access-machines
  21. https://ercim-news.ercim.eu/en107/special/mining-similarities-and-concepts-at-scale
  22. https://ercim-news.ercim.eu/en107/special/fast-traversal-of-large-ensembles-of-regression-trees
  23. https://ercim-news.ercim.eu/en107/special/optimising-deep-learning-for-infinite-applications-in-text-analytics
  24. https://ercim-news.ercim.eu/en107/special/towards-streamlined-big-data-analytics
  25. https://ercim-news.ercim.eu/en107/special/autonomous-machine-learning
  26. https://ercim-news.ercim.eu/en107/special/curiosity-and-intrinsic-motivation-for-autonomous-machine-learning
  27. https://ercim-news.ercim.eu/en107/special/applied-data-science-using-machine-learning-for-alarm-verification
  28. https://ercim-news.ercim.eu/en107/special/towards-predictive-pharmacogenomics-models
  29. https://ercim-news.ercim.eu/en107/special/optimisation-system-for-cutting-continuous-flat-glass
  30. https://ercim-news.ercim.eu/en107/special/online-learning-for-aggregating-forecasts-in-renewable-energy-systems
  31. https://ercim-news.ercim.eu/en107/special/bonaparte-bayesian-networks-to-give-victims-back-their-names
  32. https://ercim-news.ercim.eu/en107/r-s
  33. https://ercim-news.ercim.eu/en107/r-s/open-science-taking-our-destiny-into-our-own-hands
  34. https://ercim-news.ercim.eu/en107/r-s/ercim-goes-to-open-access
  35. https://ercim-news.ercim.eu/en107/r-s/will-europe-liberate-knowledge-through-content-mining
  36. https://ercim-news.ercim.eu/en107/r-s/roads-to-open-access-the-good-the-bad-and-the-ugly
  37. https://ercim-news.ercim.eu/en107/r-s/open-access-repositories-and-the-open-science-challenge
  38. https://ercim-news.ercim.eu/en107/r-s/lipics-an-open-access-series-for-international-conference-proceedings
  39. https://ercim-news.ercim.eu/en107/r-s/scientific-data-and-preservation-policy-issues-for-the-long-term-record
  40. https://ercim-news.ercim.eu/en107/r-s/mathematics-in-open-access-mathoa
  41. https://ercim-news.ercim.eu/
  42. https://ercim-news.ercim.eu/subscribe
  43. https://ercim-news.ercim.eu/back-issues-online
  44. https://ercim-news.ercim.eu/about-ercim-news
  45. https://ercim-news.ercim.eu/call
  46. https://ercim-news.ercim.eu/advertise
  47. https://ercim-news.ercim.eu/
  48. https://ercim-news.ercim.eu/en107
  49. https://ercim-news.ercim.eu/en107/special
  50. https://ercim-news.ercim.eu/images/stories/en107/en107-web.pdf
  51. https://ercim-news.ercim.eu/images/stories/en107/en107-web.pdf
  52. https://ercim-news.ercim.eu/
  53. https://ercim-news.ercim.eu/en115
  54. https://ercim-news.ercim.eu/en114
  55. https://ercim-news.ercim.eu/en113
  56. https://ercim-news.ercim.eu/en112
  57. https://ercim-news.ercim.eu/en111
  58. https://ercim-news.ercim.eu/en110
  59. https://ercim-news.ercim.eu/en109
  60. https://ercim-news.ercim.eu/en108
  61. https://ercim-news.ercim.eu/en107
  62. https://ercim-news.ercim.eu/en106
  63. https://ercim-news.ercim.eu/en105
  64. https://ercim-news.ercim.eu/en104
  65. https://ercim-news.ercim.eu/en103
  66. https://ercim-news.ercim.eu/en102
  67. https://ercim-news.ercim.eu/en101
  68. https://ercim-news.ercim.eu/en100
  69. https://ercim-news.ercim.eu/en99
  70. https://ercim-news.ercim.eu/en98
  71. https://ercim-news.ercim.eu/en97
  72. https://ercim-news.ercim.eu/en96
  73. https://ercim-news.ercim.eu/en95
  74. https://ercim-news.ercim.eu/en94
  75. https://ercim-news.ercim.eu/en93
  76. https://ercim-news.ercim.eu/en92
  77. https://ercim-news.ercim.eu/en91
  78. https://ercim-news.ercim.eu/en90
  79. https://ercim-news.ercim.eu/en89
  80. https://ercim-news.ercim.eu/en88
  81. https://ercim-news.ercim.eu/en87
  82. https://ercim-news.ercim.eu/en86
  83. https://ercim-news.ercim.eu/en85
  84. https://ercim-news.ercim.eu/en84
  85. https://ercim-news.ercim.eu/en83
  86. https://ercim-news.ercim.eu/en82
  87. https://ercim-news.ercim.eu/en81
  88. https://ercim-news.ercim.eu/en80
  89. https://ercim-news.ercim.eu/en79
  90. https://ercim-news.ercim.eu/en78
  91. https://ercim-news.ercim.eu/en77
  92. https://ercim-news.ercim.eu/en76
  93. https://ercim-news.ercim.eu/en75
  94. https://ercim-news.ercim.eu/en74
  95. https://ercim-news.ercim.eu/en73
  96. https://ercim-news.ercim.eu/en71
  97. https://ercim-news.ercim.eu/en72
  98. https://ercim-news.ercim.eu/en70
  99. https://ercim-news.ercim.eu/en68
 100. https://ercim-news.ercim.eu/en67
 101. https://ercim-news.ercim.eu/en69
 102. https://ercim-news.ercim.eu/en107/r-i
 103. https://ercim-news.ercim.eu/en107/ib
 104. https://ercim-news.ercim.eu/en107/special
 105. https://ercim-news.ercim.eu/en107/r-s
 106. https://ercim-news.ercim.eu/en107/special/marrying-graphical-models-with-deep-learning
 107. https://ercim-news.ercim.eu/en107/special
 108. https://www.youtube.com/watch?v=xnzin7jh3sg
 109. http://www.ics.uci.edu/~welling/staff.fnwi.uva.nl/m.welling/
 110. https://ercim-news.ercim.eu/call
 111. https://ercim-news.ercim.eu/images/stories/en107/en107.epub
 112. https://ercim-news.ercim.eu/images/stories/en107/en107.epub
 113. https://ercim-news.ercim.eu/?format=feed&type=rss
 114. http://creativecommons.org/licenses/by/4.0/
 115. http://dblp.uni-trier.de/db/journals/ercim/index.html
 116. https://www.ercim.eu/cnr
 117. https://www.ercim.eu/cwi
 118. https://www.ercim.eu/fhg
 119. https://www.ercim.eu/fnr
 120. https://www.ercim.eu/forth
 121. https://www.ercim.eu/inesc
 122. https://www.ercim.eu/inria
 123. https://www.ercim.eu/isi
 124. https://www.ercim.eu/ntnu
 125. https://www.ercim.eu/sba
 126. https://www.ercim.eu/sics
 127. https://www.ercim.eu/sztaki
 128. https://www.ercim.eu/tno
 129. https://www.ercim.eu/ucy
 130. https://www.ercim.eu/uwaw
 131. https://www.ercim.eu/vtt
 132. http://www.ercim.eu/about/legal

   hidden links:
 134. http://www.linkedin.com/groups/ercim-81390
 135. https://twitter.com/ercim_news
 136. http://www.facebook.com/ercimnews
 137. http://dpkingma.com/?page_id=277
