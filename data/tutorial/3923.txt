optimization for machine learning

(lecture 1)

suvrit sra

massachusetts institute of technology

mpi-is t   ubingen

machine learning summer school, june 2017

course materials

my website (teaching)
some references:
(cid:4) introductory lectures on id76     nesterov
(cid:4) id76     boyd & vandenberghe
(cid:4) nonid135     bertsekas
(cid:4) convex analysis     rockafellar
(cid:4) fundamentals of convex analysis     urruty, lemar  echal
(cid:4) lectures on modern id76     nemirovski
(cid:4) optimization for machine learning     sra, nowozin, wright
(cid:4) nips 2016 optimization tutorial     bach, sra
some related courses:
(cid:4) ee227a, spring 2013, (sra, uc berkeley)
(cid:4) 10-801, spring 2014 (sra, cmu)
(cid:4) ee364a,b (boyd, stanford)
(cid:4) ee236b,c (vandenberghe, ucla)
venues: nips, icml, uai, aistats, siopt, math. prog.

suvrit sra (suvrit@mit.edu)

optimization for machine learning

2 / 64

lecture plan

    introduction
    recap of convexity, sets, functions
    recap of duality, optimality, problems
    first-order optimization algorithms and techniques
    large-scale optimization (sgd and friends)
    directions in non-id76

suvrit sra (suvrit@mit.edu)

optimization for machine learning

3 / 64

introduction

supervised machine learning

(cid:73) data: n observations (xi, yi)n
(cid:73) prediction function: h(x,   )     r parameterized by        rd

i=1     x    y

suvrit sra (suvrit@mit.edu)

optimization for machine learning

4 / 64

introduction

supervised machine learning

(cid:73) data: n observations (xi, yi)n
(cid:73) prediction function: h(x,   )     r parameterized by        rd
(cid:73) motivating examples:

i=1     x    y

    linear predictions: h(x,   ) =   (cid:62)  (x) using features   (x)
    neural networks: h(x,   ) =   (cid:62)m   (  (cid:62)m   1  (         (cid:62)2   (  (cid:62)1 x))

(cid:73) estimating    parameters is an optimization problem

suvrit sra (suvrit@mit.edu)

optimization for machine learning

4 / 64

introduction

supervised machine learning

(cid:73) data: n observations (xi, yi)n
(cid:73) prediction function: h(x,   )     r parameterized by        rd
(cid:73) motivating examples:

i=1     x    y

    linear predictions: h(x,   ) =   (cid:62)  (x) using features   (x)
    neural networks: h(x,   ) =   (cid:62)m   (  (cid:62)m   1  (         (cid:62)2   (  (cid:62)1 x))

(cid:73) estimating    parameters is an optimization problem

unsupervised and other ml setups

(cid:73) different formulations, but ultimately optimization at heart

suvrit sra (suvrit@mit.edu)

optimization for machine learning

4 / 64

the problem!

f (  )

min
     s

suvrit sra (suvrit@mit.edu)

optimization for machine learning

5 / 64

the problem!

f (  )

min
     s

suvrit sra (suvrit@mit.edu)

optimization for machine learning

5 / 64

convex analysis

suvrit sra (suvrit@mit.edu)

optimization for machine learning

6 / 64

convex sets

suvrit sra (suvrit@mit.edu)

optimization for machine learning

7 / 64

convex sets

def. set c     rn called convex, if for any x, y     c, the line-
segment   x + (1       )y, where        [0, 1], also lies in c.

suvrit sra (suvrit@mit.edu)

optimization for machine learning

8 / 64

convex sets

def. set c     rn called convex, if for any x, y     c, the line-
segment   x + (1       )y, where        [0, 1], also lies in c.

combinations of points

(cid:73) convex:   1x +   2y     c, where   1,   2     0 and   1 +   2 = 1.
(cid:73) linear: if restrictions on   1,   2 are dropped
(cid:73) conic: if restriction   1 +   2 = 1 is dropped
different restrictions lead to different    algebra   

suvrit sra (suvrit@mit.edu)

optimization for machine learning

8 / 64

recognizing / constructing convex sets

theorem. (intersection).
let c1, c2 be convex sets. then, c1     c2 is also convex.
proof.
    if c1     c2 =    , then true vacuously.
    let x, y     c1     c2. then, x, y     c1 and x, y     c2.
    but c1, c2 are convex, hence   x + (1       )y     c1, and also in c2.

    inductively follows that(cid:84)m

thus,   x + (1       )y     c1     c2.

i=1 ci is also convex.

suvrit sra (suvrit@mit.edu)

optimization for machine learning

9 / 64

convex sets

(psdcone image from convexoptimization.com, dattorro)

suvrit sra (suvrit@mit.edu)

optimization for machine learning

10 / 64

convex sets

(cid:88)
    let x1, x2, . . . , xm     rn. their convex hull is
  ixi |   i     0,

co(x1, . . . , xm) :=

(cid:110)(cid:88)

i

i

(cid:111)

  i = 1

.

an af   ne space over subspace of solutions of ax = 0).

    let a     rm  n, and b     rm. the set {x | ax = b} is convex (it is

    halfspace(cid:8)x | atx     b(cid:9).
    ellipsoid(cid:8)x | (x     x0)ta(x     x0)     1(cid:9), (a: semide   nite)

    polyhedron {x | ax     b, cx = d}.

    convex cone x     k =      x     k for        0 (and k convex)

exercise: verify that these sets are convex.

   

suvrit sra (suvrit@mit.edu)

optimization for machine learning

10 / 64

challenge 1

(cid:110)
let a, b     rn  n be symmetric. prove that
(xtax, xtbx) | xtx = 1

r(a, b) :=

(cid:111)

is a compact convex set for n     3.

suvrit sra (suvrit@mit.edu)

optimization for machine learning

11 / 64

convex functions

(cid:8)(x, t)     rd+1 | x     rd, t     r, f (x)     t(cid:9) is a convex set.

def. a function f : rd     r is convex if and only if its epigraph

suvrit sra (suvrit@mit.edu)

optimization for machine learning

12 / 64

convex functions

(cid:8)(x, t)     rd+1 | x     rd, t     r, f (x)     t(cid:9) is a convex set.

def. a function f : rd     r is convex if and only if its epigraph

def. a function f : rn     r is called convex if its domain dom(f )
is a convex set and for any x, y     dom(f ) and        0,
f ((1       )x +   y)     (1       )f (x) +   f (y).

these functions also known as jensen convex; named after
j.l.w.v. jensen (after his in   uential 1905 paper).

suvrit sra (suvrit@mit.edu)

optimization for machine learning

12 / 64

convex functions

(cid:8)(x, t)     rd+1 | x     rd, t     r, f (x)     t(cid:9) is a convex set.

def. a function f : rd     r is convex if and only if its epigraph

def. a function f : rn     r is called convex if its domain dom(f )
is a convex set and for any x, y     dom(f ) and        0,
f ((1       )x +   y)     (1       )f (x) +   f (y).

these functions also known as jensen convex; named after
j.l.w.v. jensen (after his in   uential 1905 paper).

exercise: why are we focusing on these functions?

suvrit sra (suvrit@mit.edu)

optimization for machine learning

12 / 64

convex functions: jensen   s inequality

f (  x + (1       )y)       f (x) + (1       )f (y)

suvrit sra (suvrit@mit.edu)

optimization for machine learning

13 / 64

xyf(x)f(y)  f(x)+(1     )f(y)convex functions: af   ne lower bounds

f (x)     f (y) + (cid:104)   f (y), x     y(cid:105)

suvrit sra (suvrit@mit.edu)

optimization for machine learning

14 / 64

f(y)yxf(x)f(y)+h   f(y),x   yiconvex functions: increasing slopes

slope pq     slope pr     slope qr

suvrit sra (suvrit@mit.edu)

optimization for machine learning

15 / 64

xypqrz=  x+(1     )yrecognizing convex functions

    if f is continuous and midpoint convex, then it is convex.
    if f is differentiable, then f is convex if and only if dom f is
convex and f (x)     f (y) + (cid:104)   f (y), x     y(cid:105) for all x, y     dom f .
    if f is twice differentiable, then f is convex if and only if dom f
is convex and    2f (x) (cid:23) 0 at every x     dom f .

suvrit sra (suvrit@mit.edu)

optimization for machine learning

16 / 64

recognizing convex functions

    if f is continuous and midpoint convex, then it is convex.
    if f is differentiable, then f is convex if and only if dom f is
convex and f (x)     f (y) + (cid:104)   f (y), x     y(cid:105) for all x, y     dom f .
    if f is twice differentiable, then f is convex if and only if dom f
is convex and    2f (x) (cid:23) 0 at every x     dom f .
    by showing f : dom(f )     r is convex if and only if its
restriction to any line that intersects dom(f ) is convex. that
is, for any x     dom(f ) and any v, the function g(t) = f (x + tv)
is convex (on its domain {t | x + tv     dom(f )}).

suvrit sra (suvrit@mit.edu)

optimization for machine learning

16 / 64

recognizing convex functions

    if f is continuous and midpoint convex, then it is convex.
    if f is differentiable, then f is convex if and only if dom f is
convex and f (x)     f (y) + (cid:104)   f (y), x     y(cid:105) for all x, y     dom f .
    if f is twice differentiable, then f is convex if and only if dom f
is convex and    2f (x) (cid:23) 0 at every x     dom f .
    by showing f : dom(f )     r is convex if and only if its
restriction to any line that intersects dom(f ) is convex. that
is, for any x     dom(f ) and any v, the function g(t) = f (x + tv)
is convex (on its domain {t | x + tv     dom(f )}).

    by showing f to be a pointwise max of convex functions
    see exercises (ch. 3) in boyd & vandenberghe for more!

suvrit sra (suvrit@mit.edu)

optimization for machine learning

16 / 64

operations preserving convexity

example. let f : rn     r be convex. let a     rm  n, and b     rm.
prove that g(x) = f (ax + b) is convex.
exercise: verify!

suvrit sra (suvrit@mit.edu)

optimization for machine learning

17 / 64

operations preserving convexity

example. let f : rn     r be convex. let a     rm  n, and b     rm.
prove that g(x) = f (ax + b) is convex.
exercise: verify!
theorem. let f : i1     r and g : i2     r, where range(f )     i2. if
f and g are convex, and g is increasing, then g     f is convex on i1

suvrit sra (suvrit@mit.edu)

optimization for machine learning

17 / 64

operations preserving convexity

example. let f : rn     r be convex. let a     rm  n, and b     rm.
prove that g(x) = f (ax + b) is convex.
exercise: verify!
theorem. let f : i1     r and g : i2     r, where range(f )     i2. if
f and g are convex, and g is increasing, then g     f is convex on i1
proof. let x, y     i1, and let        (0, 1).

f (  x + (1       )y)       f (x) + (1       )f (y)

g(f (  x + (1       )y))     g(cid:0)  f (x) + (1       )f (y)(cid:1)
      g(cid:0)f (x)(cid:1) + (1       )g(cid:0)f (y)(cid:1).

suvrit sra (suvrit@mit.edu)

optimization for machine learning

17 / 64

operations preserving convexity

example. let f : rn     r be convex. let a     rm  n, and b     rm.
prove that g(x) = f (ax + b) is convex.
exercise: verify!
theorem. let f : i1     r and g : i2     r, where range(f )     i2. if
f and g are convex, and g is increasing, then g     f is convex on i1
proof. let x, y     i1, and let        (0, 1).

f (  x + (1       )y)       f (x) + (1       )f (y)

g(f (  x + (1       )y))     g(cid:0)  f (x) + (1       )f (y)(cid:1)
      g(cid:0)f (x)(cid:1) + (1       )g(cid:0)f (y)(cid:1).

(cid:73) do not miss out on several other important examples in bv!

suvrit sra (suvrit@mit.edu)

optimization for machine learning

17 / 64

constructing convex functions: sup

example. the pointwise maximum of a family of convex functions
is convex. that is, if f (x; y) is a convex function of x for every y
in an arbitrary    index set    y, then
f (x) := sup
y   y

f (x; y)

is a convex function of x.
exercise: verify!

suvrit sra (suvrit@mit.edu)

optimization for machine learning

18 / 64

constructing convex functions: sup

example. the pointwise maximum of a family of convex functions
is convex. that is, if f (x; y) is a convex function of x for every y
in an arbitrary    index set    y, then
f (x) := sup
y   y

f (x; y)

is a convex function of x.
exercise: verify!

suvrit sra (suvrit@mit.edu)

optimization for machine learning

18 / 64

constructing convex functions: joint inf

theorem. let y be a nonempty convex set. suppose l(x, y) is
convex in both (x, y), then,

f (x) := inf
y   y

l(x, y)

is a convex function of x, provided f (x) >       .

suvrit sra (suvrit@mit.edu)

optimization for machine learning

19 / 64

constructing convex functions: joint inf

theorem. let y be a nonempty convex set. suppose l(x, y) is
convex in both (x, y), then,

f (x) := inf
y   y

l(x, y)

is a convex function of x, provided f (x) >       .
proof. let u, v     dom f . since f (u) = infy l(u, y), for each   > 0, there is a
y1     y, s.t. f (u) +  
similarly, there is y2     y, such that l(v, y2)     f (v) +  
2 .
now we prove that f (  u + (1       )v)       f (u) + (1       )f (v) directly.

2 is not the in   mum. thus, l(u, y1)     f (u) +  
2 .

f (  u + (1       )v) = inf

y   y l(  u + (1       )v, y)

    l(  u + (1       )v,   y1 + (1       )y2)
      l(u, y1) + (1       )l(v, y2)
      f (u) + (1       )f (v) +  .

since   > 0 is arbitrary, claim follows.
suvrit sra (suvrit@mit.edu)

optimization for machine learning

19 / 64

convex functions     norms

let     : rd     r be a function that satis   es
1    (x)     0, and    (x) = 0 if and only if x = 0 (de   niteness)
2    (  x) = |  |   (x) for any        r (positive homogeneity)
3    (x + y)        (x) +    (y) (subadditivity)
such function called norms   usually denoted (cid:107)x(cid:107).
theorem. norms are convex.

suvrit sra (suvrit@mit.edu)

optimization for machine learning

20 / 64

convex functions     norms

let     : rd     r be a function that satis   es
1    (x)     0, and    (x) = 0 if and only if x = 0 (de   niteness)
2    (  x) = |  |   (x) for any        r (positive homogeneity)
3    (x + y)        (x) +    (y) (subadditivity)
such function called norms   usually denoted (cid:107)x(cid:107).
theorem. norms are convex.

often used in    regularized    ml problems

min

  

f (  ) +      (  ).

suvrit sra (suvrit@mit.edu)

optimization for machine learning

20 / 64

norms: important examples

(cid:1)1/2
example. ((cid:96)2-norm): (cid:107)x(cid:107)2 =(cid:0)(cid:80)
example. ((cid:96)p-norm): let p     1. (cid:107)x(cid:107)p =(cid:0)(cid:80)

i x2
i

i |xi|p(cid:1)1/p

example. ((cid:96)   -norm): (cid:107)x(cid:107)    = max1   i   n |xi|

(cid:113)(cid:80)

example. (frobenius-norm): let a     rm  n. (cid:107)a(cid:107)f :=
ij |aij|2
example. let a be any matrix. then, the operator norm of a is

(cid:107)a(cid:107) := sup
(cid:107)x(cid:107)2(cid:54)=0

(cid:107)ax(cid:107)2
(cid:107)x(cid:107)2

=   max(a).

exercise: verify that above functions are actually norms!

suvrit sra (suvrit@mit.edu)

optimization for machine learning

21 / 64

convex functions     indicator

let 1x be the indicator function for x de   ned as:

(cid:40)
if x     x ,
0
    otherwise.

1x (x) :=

note: 1x (x) is convex if and only if x is convex.
(cid:73) also called    extended value    convex function.

suvrit sra (suvrit@mit.edu)

optimization for machine learning

22 / 64

fenchel conjugate

def. the fenchel conjugate of a function f is
xtz     f (x).

f    (z) := sup
x   dom f

suvrit sra (suvrit@mit.edu)

optimization for machine learning

23 / 64

fenchel conjugate

def. the fenchel conjugate of a function f is
xtz     f (x).

f    (z) := sup
x   dom f

note: f     is pointwise (over x) sup of linear functions of z. hence,
it is always convex (even if f is not convex).

example. +    and        conjugate to each other.

suvrit sra (suvrit@mit.edu)

optimization for machine learning

23 / 64

fenchel conjugate

def. the fenchel conjugate of a function f is
xtz     f (x).

f    (z) := sup
x   dom f

note: f     is pointwise (over x) sup of linear functions of z. hence,
it is always convex (even if f is not convex).

example. +    and        conjugate to each other.
example. let f (x) = (cid:107)x(cid:107). we have f    (z) = 1(cid:107)  (cid:107)      1(z). that is,
conjugate of norm is the indicator function of dual norm ball.
proof. f    (z) = supx ztx     (cid:107)x(cid:107). if (cid:107)z(cid:107)    > 1, by defn. of the dual norm,    u such
that (cid:107)u(cid:107)     1 and utz > 1. now select x =   u and let           . then,
ztx     (cid:107)x(cid:107) =   (ztu     (cid:107)u(cid:107))        . if (cid:107)z(cid:107)        1, then ztx     (cid:107)x(cid:107)(cid:107)z(cid:107)   , which
implies the sup must be zero.

suvrit sra (suvrit@mit.edu)

optimization for machine learning

23 / 64

fenchel conjugate: examples

example. f (x) = 1

2xtax, where a (cid:31) 0. then, f    (z) = 1

2zta   1z.

example. f (x) = max(0, 1     x). verify: dom f     = [   1, 0], and on
this domain, f    (z) = z.
example. f (x) = 1x (x): f    (z) = supx   x(cid:104)x, z(cid:105) (aka support func)
example. if f        = f , we say f is a closed convex function.

exercise: suppose f (x) = ((cid:80)

i |xi|1/2)2. what is f       ?

exercise: suppose f (x) = xtax + btx but a (cid:23) 0; what is f    ?

suvrit sra (suvrit@mit.edu)

optimization for machine learning

24 / 64

challenge 2

consider the following functions on strictly positive variables:

h1(x)

:=

1
x
1
x +
1
x +

:=

h2(x, y)

h3(x, y, z)

1
    1
y
x + y
1
1
    1
y +
z
x + y
    prove that hn(x) > 0 (easy)
    prove that h1, h2, h3, and in general hn are convex (hard)
    prove that in fact each 1/hn is concave (harder).

    1
y + z

    1

x + z +

:=

1

x + y + z

suvrit sra (suvrit@mit.edu)

optimization for machine learning

25 / 64

optimization

suvrit sra (suvrit@mit.edu)

optimization for machine learning

26 / 64

optimization problems

let fi : rn     r (0     i     m). generic nonlinear program

min f0(x)

s.t. fi(x)     0,
x    {dom f0     dom f1            dom fm} .

1     i     m,

henceforth, we drop condition on domains for brevity.

suvrit sra (suvrit@mit.edu)

optimization for machine learning

27 / 64

optimization problems

let fi : rn     r (0     i     m). generic nonlinear program

min f0(x)

s.t. fi(x)     0,
x    {dom f0     dom f1            dom fm} .

1     i     m,

henceforth, we drop condition on domains for brevity.
    if fi are differentiable     smooth optimization
    if any fi is non-differentiable     nonsmooth optimization
    if all fi are convex     id76
    if m = 0, i.e., only f0 is there     unconstrained minimization

suvrit sra (suvrit@mit.edu)

optimization for machine learning

27 / 64

id76

let x be feasible set and p    the optimal value

p    := inf{f0(x) | x     x}

suvrit sra (suvrit@mit.edu)

optimization for machine learning

28 / 64

id76

let x be feasible set and p    the optimal value

p    := inf{f0(x) | x     x}

(cid:73) if x is empty, we say problem is infeasible
(cid:73) by convention, we set p    = +    for infeasible problems
(cid:73) if p    =       , we say problem is unbounded below.
(cid:73) example, min x on r, or min    log x on r++
(cid:73) sometimes minimum doesn   t exist (as x          )
(cid:73) say f0(x) = 0, problem is called convex feasibility

suvrit sra (suvrit@mit.edu)

optimization for machine learning

28 / 64

optimality

def. a point x        x is locally optimal if f (x   )     f (x) for all x in
a neighborhood of x   . global if f (x   )     f (x) for all x     x .
theorem. for convex problems, local =    global!
exercise: prove this theorem (hint: try contradiction)

suvrit sra (suvrit@mit.edu)

optimization for machine learning

29 / 64

optimality

def. a point x        x is locally optimal if f (x   )     f (x) for all x in
a neighborhood of x   . global if f (x   )     f (x) for all x     x .
theorem. for convex problems, local =    global!
exercise: prove this theorem (hint: try contradiction)
theorem. let f : rn     r be continuously differentiable in an
open set s containing x   , a local min of f . then,    f (x   ) = 0.
if f is convex, then    f (x   ) = 0 suf   cient for global optimality.
(this property makes id76 special!)

suvrit sra (suvrit@mit.edu)

optimization for machine learning

29 / 64

optimality     constrained

    for every x, y     dom f , we have f (y)     f (x) + (cid:104)   f (x), y     x(cid:105).

suvrit sra (suvrit@mit.edu)

optimization for machine learning

30 / 64

x      f(x   )xf(x)xoptimality     constrained

    for every x, y     dom f , we have f (y)     f (x) + (cid:104)   f (x), y     x(cid:105).
    thus, x    is optimal if and only if
(cid:104)   f (x   ), y     x   (cid:105)     0,

for all y     x .

suvrit sra (suvrit@mit.edu)

optimization for machine learning

30 / 64

x      f(x   )xf(x)xoptimality     constrained

    for every x, y     dom f , we have f (y)     f (x) + (cid:104)   f (x), y     x(cid:105).
    thus, x    is optimal if and only if
(cid:104)   f (x   ), y     x   (cid:105)     0,

for all y     x .

    if x = rn, this reduces to    f (x   ) = 0

    if    f (x   ) (cid:54)= 0, it de   nes supporting hyperplane to x at x   

suvrit sra (suvrit@mit.edu)

optimization for machine learning

30 / 64

x      f(x   )xf(x)xoptimization:
via subgradients

suvrit sra (suvrit@mit.edu)

optimization for machine learning

31 / 64

subgradients: global underestimators

f (x)     f (y) + (cid:104)   f (y), x     y(cid:105)

hence    f (y) = 0 implies that y is global min.

suvrit sra (suvrit@mit.edu)

optimization for machine learning

32 / 64

f(y)yxf(x)f(y)+h   f(y),x   yisubgradients: global underestimators

f (x)     f (y) + (cid:104)g, x     y(cid:105)

if one of the g = 0, then y a global min.

suvrit sra (suvrit@mit.edu)

optimization for machine learning

32 / 64

yf(y)xg1g2g3f(y)+hgy,x   yif(x)subgradients     basic facts

(cid:73) f is convex, differentiable:    f (y) the unique subgradient at y
(cid:73) a vector g is a subgradient at a point y if and only if

f (y) + (cid:104)g, x     y(cid:105) is globally smaller than f (x).

(cid:73) usually, one subgradient costs approx. as much as f (x)

suvrit sra (suvrit@mit.edu)

optimization for machine learning

33 / 64

subgradients     basic facts

(cid:73) f is convex, differentiable:    f (y) the unique subgradient at y
(cid:73) a vector g is a subgradient at a point y if and only if

f (y) + (cid:104)g, x     y(cid:105) is globally smaller than f (x).

(cid:73) usually, one subgradient costs approx. as much as f (x)
(cid:73) determining all subgradients at a given point     dif   cult.
(cid:73) subgradient calculus   major achievement in convex analysis
(cid:73) fenchel-young inequality: f (x) + f    (s)     (cid:104)s, x(cid:105) (tight at a

subgradient)

suvrit sra (suvrit@mit.edu)

optimization for machine learning

33 / 64

example: computing subgradients

f (x) := sup
y   y

h(x, y)

simple way to obtain some g        f (x):

suvrit sra (suvrit@mit.edu)

optimization for machine learning

34 / 64

example: computing subgradients

f (x) := sup
y   y

h(x, y)

simple way to obtain some g        f (x):
(cid:73) pick any y    for which h(x, y   ) = f (x)
(cid:73) pick any subgradient g        h(x, y   )
(cid:73) this g        f (x)
proof:

h(z, y   )     h(x, y   ) + gt(z     x)
h(z, y   )     f (x) + gt(z     x)
f (z)     h(z, y)
f (z)     f (x) + gt(z     x).

(because of sup)

suvrit sra (suvrit@mit.edu)

optimization for machine learning

34 / 64

computing subgradients

several other simple rules can be proved; see boyd   s lecture
notes (or my ee227a lecture slides)

subgradient from max
subgradient from expectation
subgradient of composition

suvrit sra (suvrit@mit.edu)

optimization for machine learning

35 / 64

subdifferential   

suvrit sra (suvrit@mit.edu)

optimization for machine learning

36 / 64

subdifferential

def. the set of all subgradients at y denoted by    f (y). this set
is called subdifferential of f at y

suvrit sra (suvrit@mit.edu)

optimization for machine learning

37 / 64

subdifferential

def. the set of all subgradients at y denoted by    f (y). this set
is called subdifferential of f at y
if f is convex,    f (x) is nice:
    if x     relative interior of dom f , then    f (x) nonempty

suvrit sra (suvrit@mit.edu)

optimization for machine learning

37 / 64

subdifferential

def. the set of all subgradients at y denoted by    f (y). this set
is called subdifferential of f at y
if f is convex,    f (x) is nice:
    if x     relative interior of dom f , then    f (x) nonempty
    if f differentiable at x, then    f (x) = {   f (x)}

suvrit sra (suvrit@mit.edu)

optimization for machine learning

37 / 64

subdifferential

def. the set of all subgradients at y denoted by    f (y). this set
is called subdifferential of f at y
if f is convex,    f (x) is nice:
    if x     relative interior of dom f , then    f (x) nonempty
    if f differentiable at x, then    f (x) = {   f (x)}
    if    f (x) = {g}, then f is differentiable and g =    f (x)
exercise: what is    f (x) for the relu function: max(0, x)?

suvrit sra (suvrit@mit.edu)

optimization for machine learning

37 / 64

subdifferential     example

f (x) := max(f1(x), f2(x)); both f1, f2 convex, differentiable

suvrit sra (suvrit@mit.edu)

optimization for machine learning

38 / 64

subdifferential     example

f (x) := max(f1(x), f2(x)); both f1, f2 convex, differentiable

suvrit sra (suvrit@mit.edu)

optimization for machine learning

38 / 64

f1(x)subdifferential     example

f (x) := max(f1(x), f2(x)); both f1, f2 convex, differentiable

suvrit sra (suvrit@mit.edu)

optimization for machine learning

38 / 64

f1(x)f2(x)subdifferential     example

f (x) := max(f1(x), f2(x)); both f1, f2 convex, differentiable

suvrit sra (suvrit@mit.edu)

optimization for machine learning

38 / 64

f1(x)f2(x)f(x)subdifferential     example

f (x) := max(f1(x), f2(x)); both f1, f2 convex, differentiable

suvrit sra (suvrit@mit.edu)

optimization for machine learning

38 / 64

f1(x)f2(x)f(x)ysubdifferential     example

f (x) := max(f1(x), f2(x)); both f1, f2 convex, differentiable

(cid:63) f1(x) > f2(x): unique subgradient of f is f (cid:48)1(x)

suvrit sra (suvrit@mit.edu)

optimization for machine learning

38 / 64

f1(x)f2(x)f(x)ysubdifferential     example

f (x) := max(f1(x), f2(x)); both f1, f2 convex, differentiable

(cid:63) f1(x) > f2(x): unique subgradient of f is f (cid:48)1(x)
(cid:63) f1(x) < f2(x): unique subgradient of f is f (cid:48)2(x)

suvrit sra (suvrit@mit.edu)

optimization for machine learning

38 / 64

f1(x)f2(x)f(x)ysubdifferential     example

f (x) := max(f1(x), f2(x)); both f1, f2 convex, differentiable

(cid:63) f1(x) > f2(x): unique subgradient of f is f (cid:48)1(x)
(cid:63) f1(x) < f2(x): unique subgradient of f is f (cid:48)2(x)
(cid:63) f1(y) = f2(y): subgradients, the segment [f (cid:48)1(y), f (cid:48)2(y)]
(imagine all supporting lines turning about point y)

suvrit sra (suvrit@mit.edu)

optimization for machine learning

38 / 64

f1(x)f2(x)f(x)ysubdifferential for abs value

f (x) = |x|

suvrit sra (suvrit@mit.edu)

optimization for machine learning

39 / 64

   f(x)   1+1xsubdifferential for abs value

f (x) = |x|

suvrit sra (suvrit@mit.edu)

optimization for machine learning

39 / 64

   f(x)   1+1xsubdifferential for abs value

f (x) = |x|

                  1

x < 0,
x > 0,
+1
[   1, 1] x = 0.

   |x| =

suvrit sra (suvrit@mit.edu)

optimization for machine learning

39 / 64

   f(x)   1+1xsubdifferential for euclidean norm

(cid:40)
example. f (x) = (cid:107)x(cid:107)2. then,
x/(cid:107)x(cid:107)2
{z | (cid:107)z(cid:107)2     1}

   f (x) :=

x (cid:54)= 0,
x = 0.

suvrit sra (suvrit@mit.edu)

optimization for machine learning

40 / 64

subdifferential for euclidean norm

   f (x) :=

(cid:40)
example. f (x) = (cid:107)x(cid:107)2. then,
x/(cid:107)x(cid:107)2
{z | (cid:107)z(cid:107)2     1}
proof.
(cid:107)x(cid:107)2 + (cid:104)g, z     x(cid:105)
(cid:104)g, z(cid:105)

(cid:107)z(cid:107)2
(cid:107)z(cid:107)2

   
   
=    (cid:107)g(cid:107)2     1.

x (cid:54)= 0,
x = 0.

suvrit sra (suvrit@mit.edu)

optimization for machine learning

40 / 64

example: dif   culties

example. a convex function need not be subdifferentiable ev-
erywhere. let

(cid:40)
   (1     (cid:107)x(cid:107)2
+   

f (x) :=

2)1/2

if (cid:107)x(cid:107)2     1,
otherwise.

f diff. for all x with (cid:107)x(cid:107)2 < 1, but    f (x) =     whenever (cid:107)x(cid:107)2     1.

suvrit sra (suvrit@mit.edu)

optimization for machine learning

41 / 64

subid128

    finding one subgradient within    f (x)
    determining entire subdifferential    f (x) at a point x
    do we have the chain rule?

suvrit sra (suvrit@mit.edu)

optimization for machine learning

42 / 64

given by h(x) = f (ax + b). then,

subid128

(cid:72) if f is differentiable,    f (x) = {   f (x)}
(cid:72) scaling    > 0,    (  f )(x) =      f (x) = {  g | g        f (x)}
(cid:72) addition   :    (f + k)(x) =    f (x) +    k(x) (set addition)
(cid:72) chain rule   : let a     rm  n, b     rm, f : rm     r, and h : rn     r be
(cid:72) chain rule   : h(x) = f     k, where k : x     y is diff.
(cid:72) max function   : if f (x) := max1   i   m fi(x), then
(cid:72) conjugation: z        f (x) if and only if x        f    (z)

   h(x) =    f (k(x))     dk(x) = [dk(x)]t   f (k(x))

convex hull over subdifferentials of    active    functions at x

{   fi(x) | fi(x) = f (x)} ,

   h(x) = at   f (ax + b).

   f (x) = conv

(cid:91)

*     can fail to hold without precise assumptions.
suvrit sra (suvrit@mit.edu)

optimization for machine learning

43 / 64

example: breakdown

it can happen that    (f1 + f2) (cid:54)=    f1 +    f2

(cid:40)
example. de   ne f1 and f2 by
   2   x if x     0,
+    if x < 0,

f1(x) :=

and f2(x) :=

(cid:40)
+   
   2      x

if x > 0,
if x     0.

then, f = max{f1, f2} = 1{0}, whereby    f (0) = r
but    f1(0) =    f2(0) =    .
however,    f1(x) +    f2(x)        (f1 + f2)(x) always holds.

suvrit sra (suvrit@mit.edu)

optimization for machine learning

44 / 64

subdifferential     example

example. f (x) = (cid:107)x(cid:107)   . then,

   f (0) = conv{  e1, . . . ,  en} ,
(cid:9)

(cid:8)
where ei is i-th canonical basis vector.
|et
to prove, notice that f (x) = max1   i   n
i x|
then use, chain rule and max rule and    |    |

suvrit sra (suvrit@mit.edu)

optimization for machine learning

45 / 64

subdifferential - example (boyd)

example. let f (x) = max(cid:8)stx | si     {   1, 1}

(cid:9) (2n members)

   f at x = (0, 0)

   f at x = (1, 0)

   f at x = (1, 1)

suvrit sra (suvrit@mit.edu)

optimization for machine learning

46 / 64

(   1,1)(1,   1)   1+11   1+1(1,1)optimality via subdifferentials

theorem. (fermat   s rule): let f : rn     (      , +   ]. then,

argmin f = zer(   f ) := {x     rn | 0        f (x)} .

suvrit sra (suvrit@mit.edu)

optimization for machine learning

47 / 64

optimality via subdifferentials

theorem. (fermat   s rule): let f : rn     (      , +   ]. then,

argmin f = zer(   f ) := {x     rn | 0        f (x)} .
proof: x     argmin f implies that f (x)     f (y) for all y     rn.

suvrit sra (suvrit@mit.edu)

optimization for machine learning

47 / 64

optimality via subdifferentials

theorem. (fermat   s rule): let f : rn     (      , +   ]. then,

argmin f = zer(   f ) := {x     rn | 0        f (x)} .
proof: x     argmin f implies that f (x)     f (y) for all y     rn.
equivalently, f (y)     f (x) + (cid:104)0, y     x(cid:105)    y,

suvrit sra (suvrit@mit.edu)

optimization for machine learning

47 / 64

optimality via subdifferentials

theorem. (fermat   s rule): let f : rn     (      , +   ]. then,

argmin f = zer(   f ) := {x     rn | 0        f (x)} .
proof: x     argmin f implies that f (x)     f (y) for all y     rn.
equivalently, f (y)     f (x) + (cid:104)0, y     x(cid:105)    y,     0        f (x).

suvrit sra (suvrit@mit.edu)

optimization for machine learning

47 / 64

optimality via subdifferentials

theorem. (fermat   s rule): let f : rn     (      , +   ]. then,

argmin f = zer(   f ) := {x     rn | 0        f (x)} .
proof: x     argmin f implies that f (x)     f (y) for all y     rn.
equivalently, f (y)     f (x) + (cid:104)0, y     x(cid:105)    y,     0        f (x).

nonsmooth optimality
s.t. x     x

f (x)
f (x) + 1x (x).

min
min

suvrit sra (suvrit@mit.edu)

optimization for machine learning

47 / 64

optimality via subdifferentials: application

(cid:73) minimizing x must satisfy: 0        (f + 1x )(x)
(cid:73) (cq) assuming ri(dom f )     ri(x ) (cid:54)=    , 0        f (x) +    1x(x)
(cid:73) recall, g        1x (x) iff 1x (y)     1x (x) + (cid:104)g, y     x(cid:105) for all y.
(cid:73) so g        1x (x) means x     x and 0     (cid:104)g, y     x(cid:105)    y     x .
(cid:73) normal cone:
nx (x) := {g     rn | 0     (cid:104)g, y     x(cid:105)    y     x}

application. min f (x)
    if f is diff., we get 0        f (x   ) + nx (x   )

s.t. x     x :

suvrit sra (suvrit@mit.edu)

optimization for machine learning

48 / 64

optimality via subdifferentials: application

(cid:73) minimizing x must satisfy: 0        (f + 1x )(x)
(cid:73) (cq) assuming ri(dom f )     ri(x ) (cid:54)=    , 0        f (x) +    1x(x)
(cid:73) recall, g        1x (x) iff 1x (y)     1x (x) + (cid:104)g, y     x(cid:105) for all y.
(cid:73) so g        1x (x) means x     x and 0     (cid:104)g, y     x(cid:105)    y     x .
(cid:73) normal cone:
nx (x) := {g     rn | 0     (cid:104)g, y     x(cid:105)    y     x}

application. min f (x)
    if f is diff., we get 0        f (x   ) + nx (x   )
          f (x   )     nx (x   )        (cid:104)   f (x   ), y     x   (cid:105)     0 for all y     x .

s.t. x     x :

suvrit sra (suvrit@mit.edu)

optimization for machine learning

48 / 64

duality

f (  )

min
     s

suvrit sra (suvrit@mit.edu)

optimization for machine learning

49 / 64

primal problem

let fi : rn     r (0     i     m). generic nonlinear program

min f0(x)

s.t. fi(x)     0,
x    {dom f0     dom f1            dom fm} .

1     i     m,

(p)

def. domain: the set d := {dom f0     dom f1            dom fm}
(cid:73) we call (p) the primal problem
(cid:73) the variable x is the primal variable
(cid:73) we will attach to (p) a dual problem
(cid:73) in our initial derivation: no restriction to convexity.

suvrit sra (suvrit@mit.edu)

optimization for machine learning

50 / 64

lagrangian

(cid:88)m

to the primal problem, associate lagrangian l : rn    rm     r,

  ifi(x).
    variables        rm called lagrange multipliers

l(x,   ) := f0(x) +

i=1

suvrit sra (suvrit@mit.edu)

optimization for machine learning

51 / 64

lagrangian

(cid:88)m

to the primal problem, associate lagrangian l : rn    rm     r,

l(x,   ) := f0(x) +

  ifi(x).
    variables        rm called lagrange multipliers
    suppose x is feasible, and        0. then, we get the

i=1

lower-bound:

f0(x)     l(x,   )

   x     x ,        rm
+.

suvrit sra (suvrit@mit.edu)

optimization for machine learning

51 / 64

lagrangian

(cid:88)m

to the primal problem, associate lagrangian l : rn    rm     r,

l(x,   ) := f0(x) +

  ifi(x).
    variables        rm called lagrange multipliers
    suppose x is feasible, and        0. then, we get the

i=1

lower-bound:

f0(x)     l(x,   )

   x     x ,        rm
+.

    lagrangian helps write problem in unconstrained form

suvrit sra (suvrit@mit.edu)

optimization for machine learning

51 / 64

lagrange dual function

def. we de   ne the lagrangian dual as

g(  ) := infx l(x,   ).

suvrit sra (suvrit@mit.edu)

optimization for machine learning

52 / 64

lagrange dual function

def. we de   ne the lagrangian dual as

g(  ) := infx l(x,   ).

observations:
(cid:73) g is pointwise inf of af   ne functions of   
(cid:73) thus, g is concave; it may take value       

suvrit sra (suvrit@mit.edu)

optimization for machine learning

52 / 64

lagrange dual function

def. we de   ne the lagrangian dual as

g(  ) := infx l(x,   ).

observations:
(cid:73) g is pointwise inf of af   ne functions of   
(cid:73) thus, g is concave; it may take value       
(cid:73) recall: f0(x)     l(x,   )    x     x ,        0; thus
(cid:73)    x     x ,
f0(x)     infx(cid:48) l(x(cid:48),   ) =: g(  )
(cid:73) now minimize over x on lhs, to obtain

           rm

+

p        g(  ).

suvrit sra (suvrit@mit.edu)

optimization for machine learning

52 / 64

lagrange dual problem

g(  )

sup
  

s.t.        0.

suvrit sra (suvrit@mit.edu)

optimization for machine learning

53 / 64

lagrange dual problem

g(  )

sup
  

s.t.        0.
(cid:73) dual feasible: if        0 and g(  ) >       
(cid:73) dual optimal:       if sup is achieved
(cid:73) lagrange dual is always concave, regardless of original

suvrit sra (suvrit@mit.edu)

optimization for machine learning

53 / 64

weak duality

def. denote dual optimal value by d   , i.e.,

d    := sup
     0

g(  ).

suvrit sra (suvrit@mit.edu)

optimization for machine learning

54 / 64

weak duality

def. denote dual optimal value by d   , i.e.,

d    := sup
     0

g(  ).

theorem. (weak-duality): for problem (p), we have p        d   .

suvrit sra (suvrit@mit.edu)

optimization for machine learning

54 / 64

weak duality

def. denote dual optimal value by d   , i.e.,

d    := sup
     0

g(  ).

theorem. (weak-duality): for problem (p), we have p        d   .
proof: we showed that for all        rm
thus, it follows that p        sup g(  ) = d   .

+, p        g(  ).

suvrit sra (suvrit@mit.edu)

optimization for machine learning

54 / 64

duality gap

p        d        0

suvrit sra (suvrit@mit.edu)

optimization for machine learning

55 / 64

duality gap

p        d        0

strong duality if duality gap is zero: p    = d   

notice: both p    and d    may be +   

suvrit sra (suvrit@mit.edu)

optimization for machine learning

55 / 64

duality gap

p        d        0

strong duality if duality gap is zero: p    = d   

notice: both p    and d    may be +   

several suf   cient conditions known, especially for

id76.

   easy    necessary and suf   cient conditions: unknown

suvrit sra (suvrit@mit.edu)

optimization for machine learning

55 / 64

example: slater   s suf   cient conditions

min f0(x)

s.t. fi(x)     0,
ax = b.

1     i     m,

suvrit sra (suvrit@mit.edu)

optimization for machine learning

56 / 64

example: slater   s suf   cient conditions

min f0(x)

s.t. fi(x)     0,
ax = b.

1     i     m,

constraint quali   cation: there exists x     rid s.t.

fi(x) < 0,

ax = b.

that is, there is a strictly feasible point.

theorem. let the primal problem be convex. if there is a feasible
point such that is strictly feasible for the non-af   ne constraints
(and merely feasible for af   ne, linear ones), then strong duality
holds. moreover, the dual optimal is attained (i.e., d    >       ).
reading: read bv   5.3.2 for a proof.

suvrit sra (suvrit@mit.edu)

optimization for machine learning

56 / 64

example: failure of strong duality

e   x

min
x,y

x2/y     0,

over the domain d = {(x, y) | y > 0}.

suvrit sra (suvrit@mit.edu)

optimization for machine learning

57 / 64

example: failure of strong duality

e   x

min
x,y

x2/y     0,

over the domain d = {(x, y) | y > 0}.
clearly, only feasible x = 0. so p    = 1

suvrit sra (suvrit@mit.edu)

optimization for machine learning

57 / 64

example: failure of strong duality

e   x

min
x,y

x2/y     0,

over the domain d = {(x, y) | y > 0}.
clearly, only feasible x = 0. so p    = 1

l(x, y,   ) = e   x +   x2/y,

so dual function is

g(  ) = inf
x,y>0

e   x +   x2y =

(cid:40)
0
       0
          < 0.

suvrit sra (suvrit@mit.edu)

optimization for machine learning

57 / 64

example: failure of strong duality

e   x

min
x,y

x2/y     0,

over the domain d = {(x, y) | y > 0}.
clearly, only feasible x = 0. so p    = 1

l(x, y,   ) = e   x +   x2/y,

so dual function is

g(  ) = inf
x,y>0

e   x +   x2y =

(cid:40)
0
       0
          < 0.

dual problem

d    = max

  

0

s.t.        0.

thus, d    = 0, and gap is p        d    = 1.
here, we had no strictly feasible solution.

suvrit sra (suvrit@mit.edu)

optimization for machine learning

57 / 64

zero duality gap: nonconvex example

trust region subproblem (trs)

min

xtax + 2btx

xtx     1.

a is symmetric but not necessarily semide   nite!

theorem. trs always has zero duality gap.

remark: above theorem extremely important result; part of a
family of related results on strong duality for certain quadratic
nonconvex problems.

suvrit sra (suvrit@mit.edu)

optimization for machine learning

58 / 64

example: dual for support vector machine

2 + c(cid:88)

1

2(cid:107)x(cid:107)2

min
x,  
s.t. ax     1       ,

i

  i
       0.

suvrit sra (suvrit@mit.edu)

optimization for machine learning

59 / 64

example: dual for support vector machine

2 + c(cid:88)

1

2(cid:107)x(cid:107)2

min
x,  
s.t. ax     1       ,
2(cid:107)x(cid:107)2

i

  i
       0.

l(x,   ,   ,   ) = 1

2 + c1t         t(ax     1 +   )       t  

suvrit sra (suvrit@mit.edu)

optimization for machine learning

59 / 64

example: dual for support vector machine

l(x,   ,   ,   ) = 1

2 + c1t         t(ax     1 +   )       t  

i

  i
       0.

2 + c(cid:88)

1

2(cid:107)x(cid:107)2

min
x,  
s.t. ax     1       ,
2(cid:107)x(cid:107)2
(cid:40)
:= inf l(x,   ,   ,   )
  t1     1
+   
d    = max
     0,     0

=

g(  ,   )

g(  ,   )

2(cid:107)at  (cid:107)2

2    +    = c1
otherwise

exercise: using        0, eliminate    from above problem.

suvrit sra (suvrit@mit.edu)

optimization for machine learning

59 / 64

example: norm regularized problems

min

f (x) + (cid:107)ax(cid:107)

suvrit sra (suvrit@mit.edu)

optimization for machine learning

60 / 64

example: norm regularized problems

min

f (x) + (cid:107)ax(cid:107)
dual problem

min

y

f    (   aty)

s.t. (cid:107)y(cid:107)        1.

suvrit sra (suvrit@mit.edu)

optimization for machine learning

60 / 64

example: norm regularized problems

min

f (x) + (cid:107)ax(cid:107)
dual problem

min

y

f    (   aty)

s.t. (cid:107)y(cid:107)        1.

say (cid:107)  y(cid:107)    < 1, such that at  y     ri(dom f    ), then we have strong
duality (e.g., for instance 0     ri(dom f    ))

suvrit sra (suvrit@mit.edu)

optimization for machine learning

60 / 64

example: lasso-like problem

p    := minx

(cid:107)ax     b(cid:107)2 +   (cid:107)x(cid:107)1.

suvrit sra (suvrit@mit.edu)

optimization for machine learning

61 / 64

example: lasso-like problem

p    := minx

(cid:107)x(cid:107)1 = max
(cid:107)x(cid:107)2 = max

(cid:110)
(cid:111)
(cid:107)ax     b(cid:107)2 +   (cid:107)x(cid:107)1.
(cid:111)
(cid:110)
xtv | (cid:107)v(cid:107)        1
xtu | (cid:107)u(cid:107)2     1

.

suvrit sra (suvrit@mit.edu)

optimization for machine learning

61 / 64

example: lasso-like problem

p    := minx

(cid:110)
(cid:111)
(cid:107)ax     b(cid:107)2 +   (cid:107)x(cid:107)1.
(cid:111)
(cid:110)
xtv | (cid:107)v(cid:107)        1
(cid:107)x(cid:107)1 = max
xtu | (cid:107)u(cid:107)2     1
(cid:107)x(cid:107)2 = max
(cid:111)
(cid:110)
saddle-point formulation
ut(b     ax) + vtx | (cid:107)u(cid:107)2     1, (cid:107)v(cid:107)          

.

max
u,v

p    = min

x

suvrit sra (suvrit@mit.edu)

optimization for machine learning

61 / 64

example: lasso-like problem

p    := minx

(cid:110)
(cid:111)
(cid:107)ax     b(cid:107)2 +   (cid:107)x(cid:107)1.
(cid:111)
(cid:110)
xtv | (cid:107)v(cid:107)        1
(cid:107)x(cid:107)1 = max
xtu | (cid:107)u(cid:107)2     1
(cid:107)x(cid:107)2 = max
(cid:111)
(cid:110)
saddle-point formulation
(cid:110)
(cid:111)
ut(b     ax) + vtx | (cid:107)u(cid:107)2     1, (cid:107)v(cid:107)          
ut(b     ax) + xtv | (cid:107)u(cid:107)2     1, (cid:107)v(cid:107)          

.

x

max
u,v

min

p    = min

x

= max
u,v

suvrit sra (suvrit@mit.edu)

optimization for machine learning

61 / 64

example: lasso-like problem

p    := minx

(cid:110)
(cid:111)
(cid:107)ax     b(cid:107)2 +   (cid:107)x(cid:107)1.
(cid:111)
(cid:110)
xtv | (cid:107)v(cid:107)        1
(cid:107)x(cid:107)1 = max
xtu | (cid:107)u(cid:107)2     1
(cid:107)x(cid:107)2 = max
(cid:111)
(cid:110)
saddle-point formulation
(cid:110)
(cid:111)
ut(b     ax) + vtx | (cid:107)u(cid:107)2     1, (cid:107)v(cid:107)          
ut(b     ax) + xtv | (cid:107)u(cid:107)2     1, (cid:107)v(cid:107)          
atu = v, (cid:107)u(cid:107)2     1, (cid:107)v(cid:107)          

.

max
u,v

min

x
utb

p    = min

x

= max
u,v
= max
u,v

suvrit sra (suvrit@mit.edu)

optimization for machine learning

61 / 64

example: lasso-like problem

p    := minx

.

(cid:110)
(cid:111)
(cid:107)ax     b(cid:107)2 +   (cid:107)x(cid:107)1.
(cid:111)
(cid:110)
xtv | (cid:107)v(cid:107)        1
(cid:107)x(cid:107)1 = max
xtu | (cid:107)u(cid:107)2     1
(cid:107)x(cid:107)2 = max
(cid:111)
(cid:110)
saddle-point formulation
(cid:110)
(cid:111)
ut(b     ax) + vtx | (cid:107)u(cid:107)2     1, (cid:107)v(cid:107)          
ut(b     ax) + xtv | (cid:107)u(cid:107)2     1, (cid:107)v(cid:107)          
atu = v, (cid:107)u(cid:107)2     1, (cid:107)v(cid:107)          
(cid:107)u(cid:107)2     1,

(cid:107)atv(cid:107)          .

p    = min

x

= max
u,v
= max
u,v
= max

u

max
u,v

min

x
utb

utb

suvrit sra (suvrit@mit.edu)

optimization for machine learning

61 / 64

example: kkt conditions

min

f0(x)

fi(x)     0,

i = 1, . . . , m.

suvrit sra (suvrit@mit.edu)

optimization for machine learning

62 / 64

example: kkt conditions

min

i = 1, . . . , m.
(cid:73) recall: (cid:104)   f0(x   ), x     x   (cid:105)     0 for all feasible x     x

fi(x)     0,

f0(x)

suvrit sra (suvrit@mit.edu)

optimization for machine learning

62 / 64

example: kkt conditions

min

f0(x)

fi(x)     0,

i = 1, . . . , m.
(cid:73) recall: (cid:104)   f0(x   ), x     x   (cid:105)     0 for all feasible x     x
(cid:73) g(  ) = infx l(x,   ) := f0(x) +(cid:80)
(cid:73) can we simplify this using lagrangian?
i   ifi(x)

suvrit sra (suvrit@mit.edu)

optimization for machine learning

62 / 64

example: kkt conditions

min

f0(x)

fi(x)     0,

i = 1, . . . , m.
(cid:73) recall: (cid:104)   f0(x   ), x     x   (cid:105)     0 for all feasible x     x
(cid:73) g(  ) = infx l(x,   ) := f0(x) +(cid:80)
(cid:73) can we simplify this using lagrangian?
i   ifi(x)

assume strong duality; and both p    and d    attained!

suvrit sra (suvrit@mit.edu)

optimization for machine learning

62 / 64

example: kkt conditions

min

f0(x)

fi(x)     0,

i = 1, . . . , m.
(cid:73) recall: (cid:104)   f0(x   ), x     x   (cid:105)     0 for all feasible x     x
(cid:73) g(  ) = infx l(x,   ) := f0(x) +(cid:80)
(cid:73) can we simplify this using lagrangian?
i   ifi(x)

assume strong duality; and both p    and d    attained!

thus, there exists a pair (x   ,      ) such that

p    = f0(x   )

suvrit sra (suvrit@mit.edu)

optimization for machine learning

62 / 64

example: kkt conditions

min

f0(x)

fi(x)     0,

i = 1, . . . , m.
(cid:73) recall: (cid:104)   f0(x   ), x     x   (cid:105)     0 for all feasible x     x
(cid:73) g(  ) = infx l(x,   ) := f0(x) +(cid:80)
(cid:73) can we simplify this using lagrangian?
i   ifi(x)

assume strong duality; and both p    and d    attained!

thus, there exists a pair (x   ,      ) such that

p    = f0(x   ) = d    = g(     )

suvrit sra (suvrit@mit.edu)

optimization for machine learning

62 / 64

example: kkt conditions

min

f0(x)

fi(x)     0,

i = 1, . . . , m.
(cid:73) recall: (cid:104)   f0(x   ), x     x   (cid:105)     0 for all feasible x     x
(cid:73) g(  ) = infx l(x,   ) := f0(x) +(cid:80)
(cid:73) can we simplify this using lagrangian?
i   ifi(x)

assume strong duality; and both p    and d    attained!

thus, there exists a pair (x   ,      ) such that
x l(x,      )

p    = f0(x   ) = d    = g(     ) = min

suvrit sra (suvrit@mit.edu)

optimization for machine learning

62 / 64

example: kkt conditions

min

f0(x)

fi(x)     0,

i = 1, . . . , m.
(cid:73) recall: (cid:104)   f0(x   ), x     x   (cid:105)     0 for all feasible x     x
(cid:73) g(  ) = infx l(x,   ) := f0(x) +(cid:80)
(cid:73) can we simplify this using lagrangian?
i   ifi(x)

assume strong duality; and both p    and d    attained!

thus, there exists a pair (x   ,      ) such that

p    = f0(x   ) = d    = g(     ) = min

x l(x,      )     l(x   ,      )

suvrit sra (suvrit@mit.edu)

optimization for machine learning

62 / 64

example: kkt conditions

min

f0(x)

fi(x)     0,

i = 1, . . . , m.
(cid:73) recall: (cid:104)   f0(x   ), x     x   (cid:105)     0 for all feasible x     x
(cid:73) g(  ) = infx l(x,   ) := f0(x) +(cid:80)
(cid:73) can we simplify this using lagrangian?
i   ifi(x)

assume strong duality; and both p    and d    attained!

thus, there exists a pair (x   ,      ) such that

p    = f0(x   ) = d    = g(     ) = min

x l(x,      )     l(x   ,      )     f0(x   ) = p   

suvrit sra (suvrit@mit.edu)

optimization for machine learning

62 / 64

example: kkt conditions

min

f0(x)

fi(x)     0,

i = 1, . . . , m.
(cid:73) recall: (cid:104)   f0(x   ), x     x   (cid:105)     0 for all feasible x     x
(cid:73) g(  ) = infx l(x,   ) := f0(x) +(cid:80)
(cid:73) can we simplify this using lagrangian?
i   ifi(x)

assume strong duality; and both p    and d    attained!

thus, there exists a pair (x   ,      ) such that

p    = f0(x   ) = d    = g(     ) = min
(cid:73) thus, equalities hold in above chain.

x l(x,      )     l(x   ,      )     f0(x   ) = p   

suvrit sra (suvrit@mit.edu)

optimization for machine learning

62 / 64

example: kkt conditions

min

f0(x)

fi(x)     0,

i = 1, . . . , m.
(cid:73) recall: (cid:104)   f0(x   ), x     x   (cid:105)     0 for all feasible x     x
(cid:73) g(  ) = infx l(x,   ) := f0(x) +(cid:80)
(cid:73) can we simplify this using lagrangian?
i   ifi(x)

assume strong duality; and both p    and d    attained!

thus, there exists a pair (x   ,      ) such that

p    = f0(x   ) = d    = g(     ) = min
(cid:73) thus, equalities hold in above chain.

x l(x,      )     l(x   ,      )     f0(x   ) = p   

x        argminx l(x,      ).

suvrit sra (suvrit@mit.edu)

optimization for machine learning

62 / 64

example: kkt conditions

x        argminx l(x,      ).

if f0, f1, . . . , fm are differentiable, this implies

suvrit sra (suvrit@mit.edu)

optimization for machine learning

63 / 64

example: kkt conditions

x        argminx l(x,      ).

if f0, f1, . . . , fm are differentiable, this implies

(cid:88)

   xl(x,      )|x=x    =    f0(x   ) +

     i    fi(x   ) = 0.

i

suvrit sra (suvrit@mit.edu)

optimization for machine learning

63 / 64

example: kkt conditions

x        argminx l(x,      ).

if f0, f1, . . . , fm are differentiable, this implies

(cid:88)

   xl(x,      )|x=x    =    f0(x   ) +

     i    fi(x   ) = 0.

i

moreover, since l(x   ,      ) = f0(x   ), we also have

suvrit sra (suvrit@mit.edu)

optimization for machine learning

63 / 64

example: kkt conditions

x        argminx l(x,      ).

if f0, f1, . . . , fm are differentiable, this implies

(cid:88)

   xl(x,      )|x=x    =    f0(x   ) +

     i    fi(x   ) = 0.

i

moreover, since l(x   ,      ) = f0(x   ), we also have

(cid:88)

     i fi(x   ) = 0.

i

suvrit sra (suvrit@mit.edu)

optimization for machine learning

63 / 64

example: kkt conditions

x        argminx l(x,      ).

if f0, f1, . . . , fm are differentiable, this implies

(cid:88)

   xl(x,      )|x=x    =    f0(x   ) +

     i    fi(x   ) = 0.

i

moreover, since l(x   ,      ) = f0(x   ), we also have

(cid:88)
but      i     0 and fi(x   )     0,

i

     i fi(x   ) = 0.

suvrit sra (suvrit@mit.edu)

optimization for machine learning

63 / 64

example: kkt conditions

x        argminx l(x,      ).

if f0, f1, . . . , fm are differentiable, this implies

(cid:88)

   xl(x,      )|x=x    =    f0(x   ) +

     i    fi(x   ) = 0.

i

moreover, since l(x   ,      ) = f0(x   ), we also have

(cid:88)

     i fi(x   ) = 0.

i

but      i     0 and fi(x   )     0, so complementary slackness

     i fi(x   ) = 0,

i = 1, . . . , m.

suvrit sra (suvrit@mit.edu)

optimization for machine learning

63 / 64

kkt conditions

fi(x   )     0,
     i     0,
     i fi(x   ) = 0,
   xl(x,      )|x=x    = 0

i = 1, . . . , m
i = 1, . . . , m
i = 1, . . . , m

(primal feasibility)
(dual feasibility)
(compl. slackness)
(lagrangian stationarity)

suvrit sra (suvrit@mit.edu)

optimization for machine learning

64 / 64

kkt conditions

i = 1, . . . , m
i = 1, . . . , m
i = 1, . . . , m

fi(x   )     0,
     i     0,
     i fi(x   ) = 0,
   xl(x,      )|x=x    = 0
(cid:73) we showed: if strong duality holds, and (x   ,      ) exist, then
kkt conditions are necessary for pair (x   ,      ) to be optimal

(primal feasibility)
(dual feasibility)
(compl. slackness)
(lagrangian stationarity)

suvrit sra (suvrit@mit.edu)

optimization for machine learning

64 / 64

kkt conditions

i = 1, . . . , m
i = 1, . . . , m
i = 1, . . . , m

fi(x   )     0,
     i     0,
     i fi(x   ) = 0,
   xl(x,      )|x=x    = 0
(cid:73) we showed: if strong duality holds, and (x   ,      ) exist, then
kkt conditions are necessary for pair (x   ,      ) to be optimal

(primal feasibility)
(dual feasibility)
(compl. slackness)
(lagrangian stationarity)

(cid:73) if problem is convex, then kkt also suf   cient

suvrit sra (suvrit@mit.edu)

optimization for machine learning

64 / 64

kkt conditions

i = 1, . . . , m
i = 1, . . . , m
i = 1, . . . , m

fi(x   )     0,
     i     0,
     i fi(x   ) = 0,
   xl(x,      )|x=x    = 0
(cid:73) we showed: if strong duality holds, and (x   ,      ) exist, then
kkt conditions are necessary for pair (x   ,      ) to be optimal

(primal feasibility)
(dual feasibility)
(compl. slackness)
(lagrangian stationarity)

(cid:73) if problem is convex, then kkt also suf   cient
exercise: prove the above suf   ciency of kkt. hint: use that
l(x,      ) is convex, and conclude from kkt conditions that
g(     ) = f0(x   ), so that (x   ,      ) optimal primal-dual pair.

suvrit sra (suvrit@mit.edu)

optimization for machine learning

64 / 64

