chapter 16

spectral id207

daniel spielman

yale university

16.1 introduction . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
16.2 preliminaries . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
16.3 the matrices associated with a graph . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
16.3.1 operators on the vertices . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
16.3.2 the laplacian quadratic form . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
16.3.3 the normalized laplacian . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
16.3.4 naming the eigenvalues . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
16.4 some examples
. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
16.5 the role of the courant-fischer theorem . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
16.5.1 low-rank approximations . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
16.6 elementary facts . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
16.7 spectral graph drawing . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
16.8 algebraic connectivity and graph partitioning . . . . . . . . . . . . . . . . . . . . . . . . . .
16.8.1 convergence of id93 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
16.8.2 expander graphs
. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
16.8.3 ramanujan graphs . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
16.8.4 bounding   2 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
16.9 coloring and independent sets . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
16.10perturbation theory and random graphs . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
16.11relative spectral id207 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
16.12directed graphs . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
16.13concluding remarks . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
bibliography . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .

1
2
2
3
4
5
5
6
9
9
10
11
11
14
14
16
16
17
18
20
21
22
23

16.1

introduction

spectral id207 is the study and exploration of graphs through
the eigenvalues and eigenvectors of matrices naturally associated with those
graphs. it is intuitively related to attempts to understand graphs through the
simulation of processes on graphs and through the consideration of physical
systems related to graphs. spectral id207 provides many useful algo-
rithms, as well as some that can be rigorously analyzed. we begin this chapter
by providing intuition as to why interesting properties of graphs should be
revealed by these eigenvalues and eigenvectors. we then survey a few appli-
cations of spectral id207.

1

2

combinatorial scienti   c computing

the    gures in this chapter are accompanied by the matlab code used to

generate them.

16.2 preliminaries

we ordinarily view an undirected graph1 g as a pair (v, e), where v
denotes its set of vertices and e denotes its set of edges. each edge in e is an
unordered pair of vertices, with the edge connecting distinct vertices a and b
written as (a, b). a weighted graph is a graph in which a weight (typically a
real number) has been assigned to every edge. we denote a weighted graph
by a triple (v, e, w), where (v, e) is the associated unweighted graph, and w
is a function from e to the real numbers. we restrict our attention to weight
functions w that are strictly positive. we reserve the letter n for the number
of vertices in a graph. the degree of a vertex in an unweighted graph is the
number of edges in which it is involved. we say that a graph is regular if every
vertex has the same degree, and d-regular if that degree is d.

we denote vectors by bold letters, and denote the ith component of a vector
x by x (i). similarly, we denote the entry in the ith row and jth column of a
matrix m by m (i, j).

if we are going to discuss the eigenvectors and eigenvalues of a matrix m ,
we should be sure that they exist. when considering undirected graphs, most
of the matrices we consider are symmetric, and thus they have an orthonormal
basis of eigenvectors and n eigenvalues, counted with multiplicity. the other
matrices we associate with undirected graphs are similar to symmetric ma-
trices, and thus also have n eigenvalues, counted by multiplicity, and possess
a basis of eigenvectors. in particular, these matrices are of the form m d   1,
where m is symmetric and d is a non-singular diagonal matrix. in this case,
d   1/2m d   1/2 is symmetric, and we have

d   1/2m d   1/2v i =   iv i

=    m d   1(d1/2v i) =   i!d1/2v i" .

so, if v 1, . . . , v n form an orthonormal basis of eigenvectors of d   1/2m d   1/2,
then we obtain a basis (not necessarily orthonormal) of eigenvectors of m d   1
by multiplying these vectors by d1/2. moreover, these matrices have the same
eigenvalues.

the matrices we associate with directed graphs will not necessarily be

diagonalizable.

1strictly speaking, we are considering simple graphs. these are the graphs in which all
edges go between distinct vertices and in which there can be at most one edge between a
given pair of vertices. graphs that have multiple-edges or self-loops are often called multi-
graphs.

spectral id207

3

16.3 the matrices associated with a graph

many di   erent matrices arise in the    eld of spectral id207. in this

section we introduce the most prominent.

16.3.1 operators on the vertices

eigenvalues and eigenvectors are used to understand what happens when
one repeatedly applies an operator to a vector. if a is an n-by-n matrix having
a basis of right-eigenvectors v 1, . . . , v n with

av i =   iv i,

then we can use these eigenvectors to understand the impact of multiplying a
vector x by a. we    rst express x in the eigenbasis

and then compute

civ i

x =#i

akx =#i

ciakv i =#i

ci  k

i v i.

if we have an operator that is naturally associated with a graph g, then
properties of this operator, and therefore of the graph, will be revealed by its
eigenvalues and eigenvectors. the    rst operator one typically associates with
a graph g is its adjacency operator, realized by its adjacency matrix ag and
de   ned by

ag(i, j) =$1 if (i, j)     e

0 otherwise.

to understand spectral id207, one must view vectors x     irn as
functions from the vertices to the reals. that is, they should be understood
as vectors in irv . when we apply the adjacency operator to such a function,
the resulting value at a vertex a is the sum of the values of the function x
over all neighbors b of a:

(agx ) (a) = #b:(a,b)   e

x (b).

this is very close to one of the most natural operators on a graph: the
di   usion operator. intuitively, the di   usion operator represents a process in
which    stu       or    mass    moves from vertices to their neighbors. as mass
should be conserved, the mass at a given vertex is distributed evenly among

4

combinatorial scienti   c computing

its neighbors. formally, we de   ne the degree of a vertex a to be the number
of edges in which it participates. we naturally encode this in a vector, labeled
d :

d (a) = |{b : (a, b)     e}| ,

where we write |s| to indicate the number of elements in a set s. we then
de   ne the degree matrix dg by

dg(a, b) =$d (a)

0

if a = b
otherwise.

the di   usion matrix of g, also called the walk matrix of g, is then given by

wg

def= agd   1
g .

(16.1)

it acts on a vector x by

(wgx ) (a) = #b:(a,b)   e

x (b)/d (b).

this matrix is called the walk matrix of g because it encodes the dynamics
of a random walk on g. recall that a random walk is a process that begins
at some vertex, then moves to a random neighbor of that vertex, and then a
random neighbor of that vertex, and so on. the walk matrix is used to study
the evolution of the id203 distribution of a random walk. if p     irn
is a id203 distribution on the vertices, then wgp is the id203
distribution obtained by selecting a vertex according to p, and then selecting
a random neighbor of that vertex. as the eigenvalues and eigenvectors of wg
provide information about the behavior of a random walk on g, they also
provide information about the graph.

of course, adjacency and walk matrices can also be de   ned for weighted

graphs g = (v, e, w). for a weighted graph g, we de   ne

ag(a, b) =$w(a, b)

0

if (a, b)     e
otherwise.

when dealing with weighted graphs, we distinguish between the weighted de-
gree of a vertex, which is de   ned to be the sum of the weights of its attached
edges, and the combinatorial degree of a vertex, which is the number of such
edges. we reserve the vector d for the weighted degree, so

d (a) = #b:(a,b)   e

w(a, b).

the random walk on a weighted graph moves from a vertex a to a neighbor b
with id203 proportional to w(a, b), so we still de   ne its walk matrix by
equation (16.1).

spectral id207

5

16.3.2 the laplacian quadratic form

matrices and spectral theory also arise in the study of quadratic forms.
the most natural quadratic form to associate with a graph is the laplacian,
which is given by

x t lgx = #(a,b)   e

w(a, b)(x (a)     x (b))2.

(16.2)

this form measures the smoothness of the function x . it will be small if the
function x does not jump too much over any edge. the matrix de   ning this
form is the laplacian matrix of the graph g,
def= dg     ag.

lg

the laplacian matrices of weighted graphs arise in many applications.
for example, they appear when applying the certain discretization schemes to
solve laplace   s equation with neumann boundary conditions. they also arise
when modeling networks of springs or resistors. as resistor networks provide a
very useful physical model for graphs, we explain the analogy in more detail.
we associate an edge of weight w with a resistor of resistance 1/w, since
higher weight corresponds to higher connectivity which corresponds to less
resistance.

when we inject and withdraw current from a network of resistors, we let
i ext(a) denote the amount of current we inject into node a. if this quantity is
negative then we are removing current. as electrical    ow is a potential    ow,
there is a vector v     irv so that the amount of current that    ows across edge
(a, b) is

i (a, b) = (v (a)     v (b)) /r(a, b),

where r(a, b) is the resistance of edge (a, b). the laplacian matrix provides a
system of linear equations that may be used to solve for v when given i ext:

i ext = lgv .

(16.3)

we refer the reader to [1] or [2] for more information about the connections

between resistor networks and graphs.

16.3.3 the normalized laplacian

when studying id93 on a graph, it often proves useful to nor-
malize the laplacian by its degrees. the normalized laplacian of g is de   ned
by

ng = d   1/2

g lgd   1/2

g

= i     d   1/2

g agd   1/2

g

.

it should be clear that normalized laplacian is closely related to the walk
matrix of a graph. chung   s monograph on spectral id207 focuses on
the normalized laplacian [3].

6

combinatorial scienti   c computing

16.3.4 naming the eigenvalues

when the graph g is understood, we will always let

  1       2                n

denote the eigenvalues of the adjacency matrix. we order the eigenvalues of
the laplacian in the other direction:

0 =   1       2                n.

we will always let

0 =   1       2                n

denote the eigenvalues of the normalized laplacian. even though    is not a
greek variant of w, we use

1 =   1       2                n

to denote the eigenvalues of the walk matrix. it is easy to show that   i = 1     i.
for graphs in which every vertex has the same weighted degree the degree
matrix is a multiple of the identity; so, ag and lg have the same eigenvectors.
for graphs that are not regular, the eigenvectors of ag and lg can behave
very di   erently.

16.4 some examples

the most striking demonstration of the descriptive power of the eigenvec-
tors of a graph comes from hall   s spectral approach to graph drawing [4]. to
begin a demonstration of hall   s method, we generate the delaunay graph of
200 randomly chosen points in the unit square.

xy = rand(200,2);
tri = delaunay(xy(:,1),xy(:,2));
elem = ones(3)-eye(3);
for i = 1:length(tri),

a(tri(i,:),tri(i,:)) = elem;

end
a = double(a > 0);
gplot(a,xy)

we will now discard the information we had about the coordinates of
the vertices, and draw a picture of the graph using only the eigenvectors of
its laplacian matrix. we    rst compute the adjacency matrix a, the degree
matrix d, and the laplacian matrix l of the graph. we then compute the

spectral id207

7

eigenvectors of the second and third smallest eigenvalues of l, v 2 and v 3.
we then draw the same graph, using v 2 and v 3 to provide the coordinates of
vertices. that is, we locate vertex a at position (v 2(a), v 3(a)), and draw the
edges as straight lines between the vertices.

d = diag(sum(a));
l = d - a;
[v,e] = eigs(l, 3,    sm   );
gplot(a,v(:,[2 1]))

amazingly, this process produces a very nice picture of the graph, in spite
of the fact that the coordinates of the vertices were generated solely from the
combinatorial structure of the graph. note that the interior is almost planar.
we could have obtained a similar, and possibly better, picture from the left-
eigenvectors of the walk matrix of the graph.

w = a * inv(d);
[v,e] = eigs(w   , 3);
gplot(a,v(:,[2 3]));

we defer the motivation for hall   s graph drawing technique to section 16.7,

so that we may    rst explore other examples.

0.5

one of the simplest graphs is the path graph. in the following    gure, we
plot the 2nd, 3rd, 4th, and 12th eigenvectors of the laplacian of the path
graph on 12 vertices. in each plot, the x-axis is the number of the vertex, and
the y-axis is the value of the eigenvector at that vertex. we do not bother to
plot the 1st eigenvector, as it is a constant vector.
a = diag(ones(1,11),1);
a = a + a   ;
d = diag(sum(a));
l = d - a;
[v,e] = eig(l);
plot(v(:,2),   o   ); hold on;
plot(v(:,2));
plot(v(:,3),   o   ); hold on;
plot(v(:,3));
. . .

observe that the 2nd eigenvector is monotonic along the path, that the
second changes sign twice, and that the 12th alternates negative and positive.
this can be explained by viewing these eigenvectors as the fundamental modes

   0.5
0.5

   0.5
0.5

   0.5
0.5

   0.5

10

11

12

10

11

12

10

11

12

10

11

12

1

2

3

4

5

6

7

8

9

0

1

2

3

4

5

6

7

8

9

0

1

2

3

4

5

6

7

8

9

0

1

2

3

4

5

6

7

8

9

0

8

combinatorial scienti   c computing

of vibration of a discretization of a string. we recommend [5] for a formal
treatment.

by now, the reader should not be surprised to see that ring graphs have
the obvious spectral drawings. in this case, we obtain the ring from the path
by adding an edge between vertex 1 and 12.

a(1,12) = 1; a(12,1) = 1;
d = diag(sum(a));
l = d - a;
[v,e] = eig(l);
gplot(a,v(:,[2 3]))
hold on
gplot(a,v(:,[2 3]),   o   )

our last example comes from the skeleton of the    buckyball   . this is the
same as the graph between the corners of the buckminster fuller geodesic
dome and of the seams on a standard soccer ball.

a = full(bucky);
d = diag(sum(a));
l = d - a;
[v,e] = eig(l);
gplot(a,v(:,[2 3]))
hold on;
gplot(a,v(:,[2 3]),   o   )

0.25

0.2

0.15

0.1

0.05

0

   0.05

   0.1

   0.15

   0.2

   0.25

   0.25

   0.2

   0.15

   0.1

   0.05

0

0.05

0.1

0.15

0.2

0.25

note that the picture looks like a squashed buckyball. the reason is that
there is no canonical way to choose the eigenvectors v 2 and v 3. the smallest
non-zero eigenvalue of the laplacian has multiplicity three. this graph should
really be drawn in three dimensions, using any set of orthonormal vectors
v 2, v 3, v 4 of the smallest non-zero eigenvalue of the laplacian. as this picture
hopefully shows, we obtain the standard embedding of the buckyball in ir3.

[x,y] = gplot(a,v(:,[2 3]));
[x,z] = gplot(a,v(:,[2 4]));
plot3(x,y,z)

0.2

0.15

0.1

0.05

0

   0.05

   0.1

   0.15

   0.2

0.2

0.15

0.1

0.05

0

   0.05

   0.1

   0.15

   0.2

   0.2

   0.1

   0.15

0

   0.05

0.2

0.15

0.1

0.05

spectral id207

9

the platonic solids and all vertex-transitive convex polytopes in ird dis-
play similar behavior. we refer the reader interested in learning more about
this phenomenon to either godsil   s book [6] or to [7].

16.5 the role of the courant-fischer theorem

recall that the rayleigh quotient of a non-zero vector x with respect to a

symmetric matrix a is

x t ax
x t x

.

the courant-fischer characterization of the eigenvalues of a symmetric matrix
a in terms of the maximizers and minimizers of the rayleigh quotient (see
[8]) plays a fundamental role in spectral id207.

theorem 3 (courant-fischer) let a be a symmetric matrix with eigen-
values   1       2                n. then,

  k = max
s   irn
dim(s)=k

min
x   s
x$=0

x t ax
x t x

=

min
t   irn

dim(t )=n   k+1

max
x   t
x$=0

x t ax
x t x

.

the maximum in the    rst expression is taken over all subspaces of dimension
k, and the minimum in the second is over all subspaces of dimension n   k +1.
henceforth, whenever we minimize of maximize rayleigh quotients we will
only consider non-zero vectors, and thus will drop the quanti   er    x &= 0   .

for example, the courant-fischer theorem tells us that

  1 = max
x   irn

x t ax
x t x

and   n = min
x   irn

x t ax
x t x

.

we recall that a symmetric matrix a is positive semide   nite, written
a ! 0, if all of its eigenvalues are non-negative. from (16.2) we see that
the laplacian is positive semide   nite. adjacency matrices and walk matrices
of non-empty graphs are not positive semide   nite as the sum of their eigen-
values equals their trace, which is 0. for this reason, one often considers the
lazy random walk on a graph instead of the ordinary random walk. this walk
stays put at each step with id203 1/2. this means that the corresponding
matrix is (1/2)i + (1/2)wg, which can be shown to positive semide   nite.

16.5.1 low-rank approximations

one explanation for the utility of the eigenvectors of extreme eigenvalues
of matrices is that they provide low-rank approximations of a matrix. recall

10

combinatorial scienti   c computing

that if a is a symmetric matrix with eigenvalues   1       2                n and a
corresponding orthonormal basis of column eigenvectors v 1, . . . , v n, then

  iv iv t
i .

a =#i

we can measure how well a matrix b approximates a matrix a by either the
operator norm    a     b    or the frobenius norm    a     b   f , where we recall

   m    def= max

x

   m x   
   x   

and

   m   f

def= %#i,j

m (i, j)2.

using the courant-fischer theorem, one can prove that for every k, the
best approximation of a by a rank-k matrix is given by summing the terms
  iv iv t
i over the k values of i for which |  i| is largest. this holds regardless of
whether we measure the quality of approximation in the operator or frobenius
norm.

when the di   erence between a and its best rank-k approximation is small,
it explains why the eigenvectors of the largest k eigenvalues of a should provide
a lot of information about a. however, one must be careful when applying
this intuition as the analogous eigenvectors of the laplacian correspond to is
smallest eigenvalues. perhpas the best way to explain the utility of these small
eigenvectors is to observe that they provide the best low-rank approximation
of the pseudoinverse of the laplacian.

16.6 elementary facts

we list some elementary facts about the extreme eigenvalues of the lapla-
cian and adjacency matrices. we recommend deriving proofs yourself, or con-
sulting the suggested references.

1. the all-1s vector is always an eigenvector of lg of eigenvalue 0.

2. the largest eigenvalue of the adjacency matrix is at least the average
degree of a vertex of g and at most the maximum degree of a vertex of
g (see [9] or [10, section 3.2]).

3. if g is connected, then   1 >   2 and the eigenvector of   1 may be taken
to be positive (this follows from the perron-frobenius theory; see [11]).

4. the all-1s vector is an eigenvector of ag with eigenvalue   1 if and only

if g is an   1-regular graph.

5. the multiplicity of 0 as an eigenvalue of lg is equal to the number of

connected components of lg.

spectral id207

11

6. the largest eigenvalue of lg is at most twice the maximum degree of a

vertex in g.

7.   n =      1 if and only if g is bipartite (see [12], or [10, theorem 3.4]).

16.7 spectral graph drawing

we can now explain the motivation behind hall   s spectral graph drawing
technique [4]. hall    rst considered the problem of assigning a real number
x (a) to each vertex a so that (x (a)     x (b))2 is small for most edges (a, b).
this led him to consider the problem of minimizing (16.2). so as to avoid
the degenerate solutions in which every vertex is mapped to zero, or any
other value, he introduces the restriction that x be orthogonal to b1. as the
utility of the embedding does not really depend upon its scale, he suggested
the id172    x    = 1. by the courant-fischer theorem, the solution to
the resulting optimization problem is precisely an eigenvector of the second-
smallest eigenvalue of the laplacian.

but, what if we want to assign the vertices to points in ir2? the natural

minimization problem,

   (x (a), y (a))     (x (b), y (b))   2

such that

(x (a), y (a)) = (0, 0)

min

x ,y   irv #(a,b)   e
#a

typically results in the degenerate solution x = y = v 2. to ensure that the two
coordinates are di   erent, hall introduced the restriction that x be orthogonal
to y. one can use the courant-fischer theorem to show that the optimal
solution is then given by setting x = v 2 and y = v 3, or by taking a rotation
of this solution.

hall observes that this embedding seems to cluster vertices that are close
in the graph, and separate vertices that are far in the graph. for more sophis-
ticated approaches to drawing graphs, we refer the reader to chapter 15.

16.8 algebraic connectivity and graph partitioning

many useful ideas in spectral id207 have arisen from e   orts to    nd
quantitative analogs of qualitative statements. for example, it is easy to show

12

combinatorial scienti   c computing

that   2 > 0 if and only if g is connected. this led fiedler [13] to label   2
the algebraic connectivity of a graph, and to prove in various ways that better
connected graphs have higher values of   2. this also led fiedler to consider
dividing the nodes of a graph into two pieces by choosing a real number t, and
partitioning the nodes depending on whether or not v 2(a)     t. for t = 0, this
corresponds to selecting all vertices in the right-half of the spectral embedding
of the graph.

s = find(v(:,2) >= 0);
plot(v(s,2),v(s,1),   o   )

fiedler proved [14] that for all t     0, the set of nodes a for which v 2(a)     t
forms a connected component. this type of    nodal domain theorem    was
extended by van der holst [15] to the set of a such that v(a) > 0, when v is
an eigenvector of   2 of minimal support.

the use of graph eigenvectors to partition graphs was also pioneered by
donath and ho   man [16, 17] and barnes [18]. it was popularized by experi-
mental studies showing that it could give very good results [19, 20, 21, 22].

in many applications, one wants to partition the nodes of a graph into a few
pieces of roughly equal size without removing too many edges (see chapters
10 and 13). for simplicity, consider the problem of dividing the vertices of a
graph into two pieces. in this case, we need merely identify one piece s     v .
we then de   ne    (s) to be the set of edges with exactly one endpoint in
s. we will also refer to s as a cut, as it implicitly divides the vertices into
s and v     s, cutting all edges in    (s). a tradeo    between the number of
edges cut and the balance of the partition is obtained by dividing the    rst
by a measure of the second, resulting in quantities called cut ratio, sparsity,
isoperimetric number, and conductance, although these terms are sometimes
used interchangeably. wei and cheng [23] suggested measuring the ratio of a
cut, which they de   ned to be

r(s) def=

|   (s)|

|s||v     s|

.

hagen and kahng [24] observe that this quantity is always at least   2/n, and
that v 2 can be described as a relaxation of the characteristic vector2 of the
set s that minimizes r(s).

let   s be the characteristic vector of a set s. for an unweighted graph g

2here, we de   ne the characteristic vector of a set to be the vector that is one at vertices

inside the set and zero elsewhere.

spectral id207

13

  

t

s lg  s = |   (s)| ,

(  s(a)       s(b))2 = |s||v     s| .

#a<b

we have

and

so,

on the other hand, fiedler [14] proved that

r(s) =

  2 = n min
x$=b0

  

t
s lg  s

&a<b(  s(a)       s(b))2 .
&a<b(x (a)     x (b))2 .

x t lgx

if we impose the restriction that x be a zero-one valued vector and then
minimize this last expression, we obtain the characteristic vector of the set
of minimum ratio. as we have imposed a constraint on the vector x , the
minimum ratio obtained must be larger than   2. hagen and kahng make this
observation, and suggest using v 2 to try to    nd a set of low ratio by choosing
some value t, and setting s = {a : v (a)     t}.
one may actually prove that the set obtained in this fashion does not have
ratio too much worse than the minimum. statements of this form follow from
discrete versions of cheeger   s inequality [25]. the cleanest version relates to
the the conductance of a set s

  (s) def=

w(   (s))

min(d (s), d (v     s))

,

where d (s) denotes the sum of the degrees of the vertices in s and w(   (s))
denotes the sum of the weights of the edges in    (s). the conductance of the
graph g is de   ned by

by a similar relaxation argument, one can show

  g = min
      s   v

  (s).

sinclair and jerrum   s discrete version of cheeger   s inequality [26] says that

2  g       2.

  2       2

g/2.

moreover, their proof reveals that if v 2 is an eigenvector of   2, then there
exists a t so that

  !   a : d   1/2(a)v 2(a)     t("        2  2.

other discretizations of cheeger   s inequality were proved around the same

14

combinatorial scienti   c computing

time by a number of researchers. see [27, 28, 29, 30, 31]. we remark that
lawler and sokal de   ne conductance by

w(   (s))

d (s)d (v     s)

,

which is proportional to the normalized cut measure
w(   (v     s))
d (v     s)

w(   (s))

d (s)

+

popularized by shi and malik [21]. the advantage of this later formulation is
that it has an obvious generalization to partitions into more than two pieces.
in general, the eigenvalues and entries of eigenvectors of laplacian matri-
ces will not be rational numbers; so, it is unreasonable to hope to compute
them exactly. mihail [32] proves that an approximation of the second-smallest
eigenvector su   ces. while her argument was stated for regular graphs, one
can apply it to irregular, weighted graphs to show that for every vector x
orthogonal to d 1/2 there exists a t so that

  !   a : d   1/2(a)x (a)     t("    )2

x t ngx

x t x

.

while spectral partitioning heuristics are easy to implement, they are nei-
ther the most e   ective in practice or in theory. theoretically better algorithms
have been obtained by id135 [33] and by semi-de   nite program-
ming [34]. fast variants of these algorithms may be found in [35, 36, 37, 38, 39].
more practical algorithms are discussed in chapters 10 and 13.

16.8.1 convergence of id93

if g is a connected, undirected graph, then the largest eigenvalue of wg,
  1, has multiplicity 1, equals 1, and has eigenvector d . we may convert this
eigenvector into a id203 distribution    by setting

   =

d

.

&a d (a)

if   n &=    1, then the distribution of every random walk eventually converges
to   . the rate of this convergence is governed by how close max(  2,     n) is
to   1. for example, let p t denote the distribution after t steps of a random
walk that starts at vertex a. then for every vertex b,

|pt(b)       (b)|    % d (b)

d (a)

(1     max(  2,     n))t .

one intuition behind cheeger   s inequality is that sets of small conductance
are precisely the obstacles to the convergence of id93.

for more information about id93 on graphs, we recommend the

survey of lov`asz [40] and the book by doyle and snell [2].

spectral id207

15

16.8.2 expander graphs

some of the most fascinating graphs are those on which id93
mix quickly and which have high conductance. these are called expander
graphs, and may be de   ned as the d-regular graphs for which all non-zero
laplacian eigenvalues are bounded away from zero. in the better expander
graphs, all the laplacian eigenvalues are close to d. one typically considers
in   nite families of such graphs in which d and a lower bound on the distance of
the non-zero eigenvalues from d remain constant. these are counter-examples
to many naive conjectures about graphs, and should be kept in mind whenever
one is thinking about graphs. they have many amazing properties, and have
been used throughout theoretical computer science. in addition to playing a
prominent role in countless theorems, they are used in the design of pseudo-
random generators [41, 42, 43], error-correcting codes [44, 45, 46, 47, 48],
fault-tolerant circuits [49] and routing networks [50].

the reason such graphs are called expanders is that all small sets of vertices
in these graphs have unusually large numbers of neighbors. that is, their
neighborhoods expand. for s     v , let n (s) denote the set of vertices that
are neighbors of vertices in s. tanner [51] provides a lower bound on the size
of n (s) in bipartite graphs. in general graphs, it becomes the following.

theorem 4 let g = (v, e) be a d-regular graph on n vertices and set

then, for all s     v ,

  = max*1    

  2
d

,

  n

d     1+

|n (s)|   

|s|

 2(1       ) +   

,

where |s| =   n.
the term   is small when all of the eigenvalues are close to d. note that when
   is much less than  2, the term on the right is approximately |s| / 2, which
can be much larger than |s|.
an example of the pseudo-random properties of expander graphs is the
   expander mixing lemma   . to understand it, consider choosing two subsets
of the vertices, s and t of sizes   n and   n, at random. let )e(s, t ) denote the
set of ordered pairs (a, b) with a     s, b     t and (a, b)     e. the expected size
of )e(s, t ) is     dn. this theorem tells us that for every pair of large sets s
and t , the number of such pairs is approximately this quantity. alternatively,
one may view an expander as an approximation of the complete graph. the
fraction of edges in the complete graph going from s to t is     . the following
theorem says that the same is approximately true for all su   ciently large sets
s and t .

theorem 5 (expander mixing lemma) let g = (v, e) be a d-regular

16

combinatorial scienti   c computing

graph and set

  = max*1    
then, for every s     v and t     v ,

  2
d

,

  n

d     1+

,,,,,,

)e(s, t ),,,         dn,,,      dn-(         2)(         2),

where |s| =   n and |t| =   n.
this bound is a slight extension by beigel, margulis and spielman [52] of a
bound originally proved by alon and chung [53]. observe that when    and   
are greater than  , the term on the right is less than     dn. theorem 4 may
be derived from theorem 5.

we refer readers who would like to learn more about expander graphs to

the survey of hoory, linial and wigderson [54].

16.8.3 ramanujan graphs

given the importance of   2, we should know how close it can be to d.

nilli [55] shows that it cannot be much closer than 2   d     1.

theorem 6 let g be an unweighted d-regular graph containing two edges
(u0, u1) and (v0, v1) whose vertices are at distance at least 2k + 2 from each
other. then

  2     d     2   d     1 +

2   d     1     1

.

k + 1

amazingly, margulis [56] and lubotzky, phillips and sarnak [57] have
constructed in   nite families of d-regular graphs, called ramanujan graphs,

for which   2     d     2   d     1.

however, this is not the end of the story. kahale [58] proves that vertex
expansion by a factor greater than d/2 cannot be derived from bounds on   2.
expander graphs that have expansion greater than d/2 on small sets of vertices
have been derived by capalbo et. al. [59] through non-spectral arguments.

16.8.4 bounding   2

i consider   2 to be the most interesting parameter of a connected graph.
if it is large, the graph is an expander. if it is small, then the graph can
be cut into two pieces without removing too many edges. either way, we
learn something about the graph. thus, it is very interesting to    nd ways of
estimating the value of   2 for families of graphs.

one way to explain the success of spectral partitioning heuristics is to
prove that the graphs to which they are applied have small values of   2 or   2.
a line of work in this direction was started by spielman and teng [60], who
proved upper bounds on   2 for planar graphs and well-shaped    nite element
meshes.

spectral id207

17

theorem 7 ([60]) let g be a planar graph with n vertices of maximum de-
gree d, and let   2 be the second-smallest eigenvalue of its laplacian. then,

  2    

8d
n

.

this theorem has been extended to graphs of bounded genus by kelner [61].
entirely new techniques were developed by biswal, lee and rao [62] to extend
this bound to graphs excluding bounded minors. bounds on higher laplacian
eigenvalues have been obtained by kelner, lee, price and teng [63].

theorem 8 ([63]) let g be a graph with n vertices and constant maximum
degree. if g is planar, has constant genus, or has a constant-sized forbidden
minor, then

  k     o(k/n).

proving lower bounds on   2 is a more di   cult problem. the dominant
approach is to relate the graph under consideration to a graph with known
eigenvalues, such as the complete graph. write

lg ! clh

if lg     clh ! 0. in this case, we know that

  i(g)     c  i(h),

for all i. inequalities of this form may be proved by identifying each edge
of the graph h with a path in g. the resulting bounds are called poincar  e
inequalities, and are closely related to the bounds used in the analysis of pre-
conditioners in chapter 12 and in related works [64, 65, 66, 67]. for examples
of such arguments, we refer the reader to one of [68, 69, 70].

16.9 coloring and independent sets

in the graph coloring problem one is asked to assign a color to every vertex
of a graph so that every edge connects vertices of di   erent colors, while using
as few colors as possible. replacing colors with numbers, we de   ne a k-coloring
of a graph g = (v, e) to be a function c : v    { 1, . . . , k} such that

c(i) &= c(j), for all (i, j)     e.

the chromatic number of a graph g, written   (g), is the least k for which g
has a k-coloring. wilf [71] proved that the chromatic number of a graph may
be bounded above by its largest adjacency eigenvalue.

18

combinatorial scienti   c computing

theorem 9 ([71])

  (g)       1 + 1.

on the other hand, ho   man [72] proved a lower bound on the chromatic
number in terms of the adjacency matrix eigenvalues. when reading this the-
orem, recall that   n is negative.

theorem 10 if g is a graph with at least one edge, then

  (g)    

  1       n
     n

= 1 +

.

  1
     n

in fact, this theorem holds for arbitrary weighted graphs. thus, one may prove
lower bounds on the chromatic number of a graph by assigning a weight to
every edge, and then computing the resulting ratio.

it follows from theorem 10 that g is not bipartite if |  n| <   1. moreover,
as |  n| becomes closer to 0, more colors are needed to properly color the
graph. another way to argue that graphs with small |  n| are far from being
bipartite was found by trevisan [73]. to be precise, trevisan proves a bound,
analogous to cheeger   s inequality, relating |e|    maxs   v |   (s)| to the smallest
eigenvalue of the signless laplacian matrix, dg + ag.
an independent set of vertices in a graph g is a set s     v such that no
edge connects two vertices of s. the size of the largest independent set in
a graph is called its independence number, and is denoted   (g). as all the
nodes of one color in a coloring of g are independent, we know

  (g)     n/  (g).

for regular graphs, ho   man derived the following upper bound on the size

of an independent set.

theorem 11 let g = (v, e) be a d-regular graph. then

  (g)     n      n
d       n
this implies theorem 10 for regular graphs.

.

16.10 perturbation theory and random graphs

mcsherry [74] observes that the spectral partitioning heuristics and the
related spectral heuristics for graph coloring can be understood through ma-
trix perturbation theory. for example, let g be a graph and let s be a subset

spectral id207

19

of the vertices of g. without loss of generality, assume that s is the set of the
   rst |s| vertices of g. then, we can write the adjacency matrix of g as

.a(s)

0

0

a(v     s)/ +.

0

a(v     s, s)

/ ,
a(s, v     s)

0

where we write a(s) to denote the restriction of the adjacency matrix to the
vertices in s, and a(s, v     s) to capture the entries in rows indexed by s and
columns indexed by v    s. the set s can be discovered from an examination of
the eigenvectors of the left-hand matrix: it has one eigenvector that is positive
on s and zero elsewhere, and another that is positive on v     s and zero
elsewhere. if the right-hand matrix is a    small    perturbation of the left-hand
matrix, then we expect similar eigenvectors to exist in a. it seems reasonable
that the right-hand matrix should be small if it contains few edges. whether
or not this may be made rigorous depends on the locations of the edges. we
will explain mcsherry   s analysis, which makes this rigorous in certain random
models.

we    rst recall the basics perturbation theory for matrices. let a and b
be symmetric matrices with eigenvalues   1       2                n and   1       2    
            n, respectively. let m = a     b. weyl   s theorem, which follows from
the courant-fischer theorem, tells us that

|  i       i|        m   

for all i. as m is symmetric,    m    is merely the largest absolute value of an
eigenvalue of m .
when some eigenvalue   i is well-separated from the others, one can show
that a small perturbation does not change the corresponding eigenvector too
much. demmel [75, theorem 5.2] proves the following bound.

theorem 12 let v 1, . . . , v n be an orthonormal basis of eigenvectors of a
corresponding to   1, . . . ,   n and let u 1, . . . , u n be an orthonormal basis of
eigenvectors of b corresponding to   1, . . . ,   n. let   i be the angle between v i
and w i. then,

1
2

sin 2  i    

   m   

.

minj$=i |  i       j|

mcsherry applies these ideas from perturbation theory to analyze the be-
havior of spectral partitioning heuristics on random graphs that are generated
to have good partitions. for example, he considered the planted partition
model of boppana [76]. this is de   ned by a weighted complete graph h de-
termined by a s     v in which

w(a, b) =$p if both or neither of a and b are in s, and

if exactly one of a and b are in s,

q

for q < p. a random unweighted graph g is then constructed by including

20

combinatorial scienti   c computing

edge (a, b) in g with id203 w(a, b). for appropriate values of q and p, the
cut determined by s is very likely to be the sparsest. if q is not too close to p,
then the largest two eigenvalues of h are far from the rest, and correspond to
the all-1s vector and a vector that is uniform and positive on s and uniform
and negative on v     s. using results from random matrix theory of f  uredi
and koml  os [77], vu [78], and alon, krievlevich and vu [79], mcsherry proves
that g is a slight perturbation of h, and that the eigenvectors of g can be
used to recover the set s, with high id203.

both mcsherry [74] and alon and kahale [80] have shown that the eigen-
vectors of the smallest adjacency matrix eigenvalues may be used to k-color
randomly generated k-colorable graphs. these graphs are generated by    rst
partitioning the vertices into k sets, s1, . . . , sk, and then adding edges between
vertices in di   erent sets with id203 p, for some small p.

for more information on these and related results, we suggest the book by

kannan and vempala [81].

16.11 relative spectral id207

preconditioning (see chapter 12) has inspired the study of the relative
eigenvalues of graphs. these are the eigenvalues of lgl+
h, where lg is the
laplacian of a graph g and l+
h is the pseudo-inverse of the laplacian of a
graph h. we recall that the pseudo-inverse of a symmetric matrix l is given
by

1
  i

#i:  i$=0

v iv t
i ,

where the   i and v i are the eigenvalues and eigenvectors of the matrix l. the
eigenvalues of lgl+

h reveal how well h approximates g.

let kn denote the complete graph on n vertices. all of the non-trivial
eigenvalues of the laplacian of kn equal n. so, lkn acts as n times the identity
on the space orthogonal to b1. thus, for every g the eigenvalues of lgl+
kn
are just the eigenvalues of lg divided by n, and the eigenvectors are the same.
many results on expander graphs, including those in section 16.8.2, can be
derived by using this perspective to treat an expander as an approximation
of the complete graph (see [82]).

recall that when lg and lh have the same range,   f (lg, lh) is de   ned
h divided by the smallest. the

to be the largest non-zero eigenvalue of lgl+
ramanujan graphs are d-regular graphs g for which

  f (lg, lkn)    

d + 2   d     1
d     2   d     1

.

spectral id207

21

batson, spielman and srivastava [82] prove that every graph h can be ap-
proximated by a sparse graph almost as well as this.

theorem 13 for every weighted graph g on n vertices and every d > 1,
there exists a weighted graph h with at most ,d(n     1)- edges such that

  f (lg, lh)    

d + 1 + 2   d
d + 1     2   d

.

spielman and srivastava [83] show that if one forms a graph h by sam-
pling o(n log n/ 2) edges of g with id203 proportional to their ef-
fective resistance and rescaling their weights, then with high id203
  f (lg, lh)     1 +  .
spielman and woo [84] have found a characterization of the well-studied
stretch of a spanning tree with respect to a graph in terms of relative graph
spectra. for simplicity, we just de   ne it for unweighted graphs. if t is a
spanning tree of a graph g = (v, e), then for every (a, b)     e there is a
unique path in t connecting a to b. the stretch of (a, b) with respect to t ,
written stt (a, b), is the number of edges in that path in t . the stretch of g
with respect to t is then de   ned to be

stt (g) def= #(a,b)   e

stt (a, b).

theorem 14 ([84])

see chapter 12 for a proof.

stt (g) = trace0lgl+
t1 .

16.12 directed graphs

there has been much less success in the study of the spectra of directed
graphs, perhaps because the nonsymmetric matrices naturally associated with
directed graphs are not necessarily diagonalizable. one naturally de   nes the
adjacency matrix of a directed graph g by

ag(a, b) =$1

0

if g has a directed edge from b to a
otherwise.

similarly, if we let d (a) denote the number of edges leaving vertex a and de   ne
d as before, then the matrix realizing the random walk on g is

wg = agd   1
g .

22

combinatorial scienti   c computing

the perron-frobenius theorem (see [11, 8]) tells us that if g is strongly con-
nected, then ag has a unique positive eigenvector v with a positive eigenvalue
   such that every other eigenvalue    of a satis   es |  |      . the same holds
for wg. when |  | <   for all other eigenvalues   , this vector is proportional
to the unique limiting distribution of the random walk on g.
these perron-frobenius eigenvectors have proved incredibly useful in a
number of situations. for instance, athey are at the heart of google   s pager-
ank algorithm for answering web search queries (see [85, 86]). this algorithm
constructs a directed graph by associating vertices with web pages, and cre-
ating a directed edge for each link. it also adds a large number of low-weight
edges by allowing the random walk to move to a random vertex with some
small id203 at each step. the id95 score of a web page is then
precisely the value of the perron-frobenius vector at the associated vertex.
interestingly, this idea was actually proposed by bonacich [87, 88, 89] in the
1970   s as a way of measuring the centrality of nodes in a social network. an
analogous measure, using the adjacency matrix, was proposed by berge [90,
chapter 4, section 5] for ranking teams in sporting events. palacios-huerta
and volij [91] and altman and tennenholtz [92] have given abstract, axiomatic
descriptions of the rankings produced by these vectors.

an related approach to obtaining rankings from directed graphs was pro-
posed by kleinberg [93]. he suggested using singular vectors of the directed
adjacency matrix. surprising, we are unaware of other combinatorially in-
teresting uses of the singular values or vectors of matrices associated with
directed graphs.

to avoid the complications of non-diagonalizable matrices, chung [94] has
de   ned a symmetric laplacian matrix for directed graphs. her de   nition is
inspired by the observation that the degree matrix d used in the de   nition of
the undirected laplacian is the diagonal matrix of d , which is proportional to
the limiting distribution of a random walk on an undirected graph. chung   s
laplacian for directed graphs is constructed by replacing d by the perron-
frobenius vector for the random walk on the graph. using this laplacian,
she derives analogs of cheeger   s inequality, de   ning conductance by counting
edges by the id203 they appear in a random walk [95].

16.13 concluding remarks

many fascinating and useful results in spectral id207 are omitted
in this survey. for those who want to learn more, the following books and
survey papers take an approach in the spirit of this chapter: [96, 97, 98, 81,
3, 40]. i also recommend [10, 99, 6, 100, 101].

anyone contemplating spectral id207 should be aware that there
are graphs with very pathological spectra. expanders could be considered ex-

spectral id207

23

amples. but, strongly regular graphs (which only have 3 distinct eigenvalues)
and distance regular graphs should also be considered. excellent treatments
of these appear in some of the aforementioned works, and also in [6, 102].

bibliography

[1] bollob  as, b., modern id207, springer-verlag, new york, 1998.

[2] doyle, p. g. and snell, j. l., id93 and electric networks,
vol. 22 of carus mathematical monographs, mathematical association
of america, 1984.

[3] chung, f. r. k., spectral id207, american mathematical soci-

ety, 1997.

[4] hall, k. m.,    an r-dimensional quadratic placement algorithm,    man-

agement science, vol. 17, 1970, pp. 219   229.

[5] gould, s. h., variational methods for eigenvalue problems, dover, 1995.

[6] godsil, c., algebraic combinatorics, chapman & hall, 1993.

[7] van der holst, h., lov`asz, l., and schrijver, a.,    the colin de verdi`ere

graph parameter,    bolyai soc. math. stud., vol. 7, 1999, pp. 29   85.

[8] horn, r. a. and johnson, c. r., matrix analysis, cambridge university

press, 1985.

[9] collatz, l. and sinogowitz, u.,    spektren endlicher grafen,    abh. math.

sem. univ. hamburg, vol. 21, 1957, pp. 63   77.

[10] cvetkovi  c, d. m., doob, m., and sachs, h., spectra of graphs, academic

press, 1978.

[11] bapat, r. b. and raghavan, t. e. s., nonnegative matrices and appli-
cations, no. 64 in encyclopedia of mathematics and its applications,
cambridge university press, 1997.

[12] ho   man, a. j.,    on the polynomial of a graph,    the american math-

ematical monthly, vol. 70, no. 1, 1963, pp. 30   36.

[13] fiedler., m.,    algebraic connectivity of graphs,    czechoslovak mathe-

matical journal, vol. 23, no. 98, 1973, pp. 298   305.

[14] fiedler, m.,    a property of eigenvectors of nonnegative symmetric ma-
trices and its applications to id207,    czechoslovak mathematical
journal, vol. 25, no. 100, 1975, pp. 618   633.

24

combinatorial scienti   c computing

[15] van der holst, h.,    a short proof of the planarity characterization of
colin de verdi`ere,    journal of combinatorial theory, series b, vol. 65,
no. 2, 1995, pp. 269     272.

[16] donath, w. e. and ho   man, a. j.,    algorithms for partitioning graphs
and computer logic based on eigenvectors of connection matrices,   
ibm technical disclosure bulletin, vol. 15, no. 3, 1972, pp. 938   944.

[17] donath, w. e. and ho   man, a. j.,    lower bounds for the partitioning
of graphs,    ibm journal of research and development, vol. 17, no. 5,
sept. 1973, pp. 420   425.

[18] barnes, e. r.,    an algorithm for partitioning the nodes of a graph,   
siam journal on algebraic and discrete methods, vol. 3, no. 4, 1982,
pp. 541   550.

[19] simon, h. d.,    partitioning of unstructured problems for parallel pro-
cessing,    computing systems in engineering, vol. 2, 1991, pp. 135   148.

[20] pothen, a., simon, h. d., and liou, k.-p.,    partitioning sparse matrices
with eigenvectors of graphs,    siam journal on matrix analysis and
applications, vol. 11, no. 3, 1990, pp. 430   452.

[21] shi, j. b. and malik, j.,    normalized cuts and image segmentation,   
ieee trans. pattern analysis and machine intelligence, vol. 22, no. 8,
aug. 2000, pp. 888   905.

[22] ng, a. y., jordan, m. i., and weiss, y.,    on spectral id91: anal-
ysis and an algorithm,    adv. in neural inf. proc. sys. 14 , 2001, pp.
849   856.

[23] wei, y.-c. and cheng, c.-k.,    ratio cut partitioning for hierarchical
designs,    ieee transactions on computer-aided design of integrated
circuits and systems, vol. 10, no. 7, jul 1991, pp. 911   921.

[24] hagen, l. and kahng, a. b.,    new id106 for ratio cut
partitioning and id91,    ieee transactions on computer-aided
design of integrated circuits and systems, vol. 11, 1992, pp. 1074   1085.

[25] cheeger, j.,    a lower bound for smallest eigenvalue of the laplacian,   

problems in analysis, princeton university press, 1970, pp. 195   199.

[26] sinclair, a. and jerrum, m.,    approximate counting, uniform gener-
ation and rapidly mixing markov chains,    information and computa-
tion, vol. 82, no. 1, july 1989, pp. 93   133.

[27] lawler, g. f. and sokal, a. d.,    bounds on the l2 spectrum for
markov chains and markov processes: a generalization of cheeger   s in-
equality,    transactions of the american mathematical society, vol. 309,
no. 2, 1988, pp. 557   580.

spectral id207

25

[28] alon, n. and milman, v. d.,      1, isoperimetric inequalities for graphs,
and superconcentrators,    j. comb. theory, ser. b, vol. 38, no. 1, 1985,
pp. 73   88.

[29] alon, n.,    eigenvalues and expanders,    combinatorica, vol. 6, no. 2,

1986, pp. 83   96.

[30] dodziuk, j.,    di   erence equations, isoperimetric inequality and tran-
sience of certain id93,    transactions of the american math-
ematical society, vol. 284, no. 2, 1984, pp. 787   794.

[31] varopoulos, n. t.,    isoperimetric inequalities and markov chains,   

journal of functional analysis, vol. 63, no. 2, 1985, pp. 215     239.

[32] mihail, m.,    conductance and convergence of markov chains   a com-
binatorial treatment of expanders,    30th annual ieee symposium on
foundations of computer science, 1989, pp. 526   531.

[33] leighton, t. and rao, s.,    multicommodity max-   ow min-cut theorems
and their use in designing approximation algorithms,    journal of the
acm , vol. 46, no. 6, nov. 1999, pp. 787   832.

[34] arora, s., rao, s., and vazirani, u.,    expander    ows, geometric embed-
dings and graph partitioning,    j. acm , vol. 56, no. 2, 2009, pp. 1   37.

[35] khandekar, r., rao, s., and vazirani, u.,    graph partitioning using

single commodity    ows,    j. acm , vol. 56, no. 4, 2009, pp. 1   15.

[36] sherman, j.,    breaking the multicommodity flow barrier for o(sqrt(log
n))-approximations to sparsest cut,    proceedings of the 50th ieee
symposium on foundations of computer science, 2009, pp. 363     372.

[37] arora, s., hazan, e., and kale, s.,    o(sqrt (log n)) approximation to
sparsest cut in   o(n2) time,    45th ieee symposium on foundations
of computer science, 2004, pp. 238   247.

[38] arora, s. and kale, s.,    a combinatorial, primal-dual approach to
semide   nite programs,    proceedings of the 39th annual acm sympo-
sium on theory of computing, 2007, pp. 227   236.

[39] orecchia, l., schulman, l. j., vazirani, u. v., and vishnoi, n. k.,    on
partitioning graphs via single commodity    ows,    proceedings of the 40th
annual acm symposium on theory of computing, 2008, pp. 461   470.

[40] lov  asz, l.,    id93 on graphs: a survey,    combinatorics, paul
erd  os is eighty, vol. 2 , edited by t. s. d. miklos, v. t. sos, janos
b  olyai mathematical society, budapest, 1996, pp. 353   398.

[41] impagliazzo, r. and zuckerman, d.,    how to recycle random bits,    30th
annual ieee symposium on foundations of computer science, 1989,
pp. 248   253.

26

combinatorial scienti   c computing

[42] karp, r. m., pippenger, n., and sipser, m.,    a time randomness trade-
o   ,    ams conf. on probabilistic computational complexity, durham,
new hampshire, 1985.

[43] ajtai, m., koml  os, j., and szemer  edi, e.,    deterministic simulation in
logspace,    proceedings of the nineteenth annual acm symposium
on theory of computing, 1987, pp. 132   140.

[44] alon, n., bruck, j., naor, j., naor, m., and roth, r. m.,    construc-
tion of asymptotically good low-rate error-correcting codes through
pseudo-random graphs,    ieee transactions on id205,
vol. 38, no. 2, march 1992, pp. 509   516.

[45] sipser, m. and spielman, d.,    expander codes,    ieee transactions on

id205, vol. 42, no. 6, nov 1996, pp. 1710   1722.

[46] zemor, g.,    on expander codes,    ieee transactions on information

theory, vol. 47, no. 2, feb 2001, pp. 835   837.

[47] barg, a. and zemor, g.,    error exponents of expander codes,    ieee
transactions on id205, vol. 48, no. 6, jun 2002, pp. 1725   
1729.

[48] guruswami, v.,    guest column: error-correcting codes and expander

graphs,    sigact news, vol. 35, no. 3, 2004, pp. 25   41.

[49] pippenger, n.,    on networks of noisy gates,    proceedings of the 26th
ann. ieee symposium on foundations of computer science, 1985, pp.
30   38.

[50] pippenger, n.,    self-routing superconcentrators,    journal of computer

and system sciences, vol. 52, no. 1, feb. 1996, pp. 53   60.

[51] tanner, r. m.,    explicit construction of concentrators from generalized
n-gons,    siam j. algebraic discrete methods, vol. 5, 1984, pp. 287   293.

[52] beigel, r., margulis, g., and spielman, d. a.,    fault diagnosis in a
small constant number of parallel testing rounds,    spaa    93: proceed-
ings of the    fth annual acm symposium on parallel algorithms and
architectures, acm, new york, ny, usa, 1993, pp. 21   29.

[53] alon, n. and chung, f.,    explicit construction of linear sized tolerant

networks,    discrete mathematics, vol. 72, 1988, pp. 15   19.

[54] hoory, s., linial, n., and wigderson, a.,    expander graphs and their
applications,    bulletin of the american mathematical society, vol. 43,
no. 4, 2006, pp. 439   561.

[55] nilli, a.,    on the second eigenvalue of a graph,    discrete math, vol. 91,

1991, pp. 207   210.

spectral id207

27

[56] margulis, g. a.,    explicit group theoretical constructions of combina-
torial schemes and their application to the design of expanders and
concentrators,    problems of information transmission, vol. 24, no. 1,
july 1988, pp. 39   46.

[57] lubotzky, a., phillips, r., and sarnak, p.,    ramanujan graphs,    com-

binatorica, vol. 8, no. 3, 1988, pp. 261   277.

[58] kahale, n.,    eigenvalues and expansion of regular graphs,    j. acm ,

vol. 42, no. 5, 1995, pp. 1091   1106.

[59] capalbo, m., reingold, o., vadhan, s., and wigderson, a.,    random-
ness conductors and constant-degree lossless expanders,    proceedings of
the 34th annual acm symposium on theory of computing, 2002, pp.
659   668.

[60] spielman, d. a. and teng, s.-h.,    spectral partitioning works: planar
graphs and    nite element meshes,    id202 and its applications,
vol. 421, no. 2-3, 2007, pp. 284     305, special issue in honor of miroslav
fiedler.

[61] kelner, j. a.,    spectral partitioning, eigenvalue bounds, and circle pack-
ings for graphs of bounded genus,    siam j. comput., vol. 35, no. 4,
2006, pp. 882   902.

[62] biswal, p., lee, j., and rao, s.,    eigenvalue bounds, spectral partition-
ing, and metrical deformations via    ows,    journal of the acm , 2010,
to appear.

[63] kelner, j. a., lee, j., price, g., and teng, s.-h.,    higher eigenvalues
of graphs,    proceedings of the 50th ieee symposium on foundations
of computer science, 2009, pp. 735   744.

[64] vaidya, p. m.,    solving linear equations with symmetric diagonally
dominant matrices by constructing good preconditioners.    unpublished
manuscript uiuc 1990. a talk based on the manuscript was presented
at the ima workshop on id207 and sparse matrix computa-
tion, october 1991, minneapolis.

[65] bern, m., gilbert, j., hendrickson, b., nguyen, n., and toledo, s.,
   support-graph preconditioners,    siam journal on matrix analysis
and applications, vol. 27, no. 4, 2006, pp. 930   951.

[66] boman, e. g. and hendrickson, b.,    support theory for precondition-
ing,    siam journal on matrix analysis and applications, vol. 25, no. 3,
2003, pp. 694   717.

[67] spielman, d. a. and teng, s.-h.,    nearly-linear time algorithms
for preconditioning and solving symmetric, diagonally dominant

28

combinatorial scienti   c computing

linear systems,    corr, vol. abs/cs/0607105, 2009, available at
http://www.arxiv.org/abs/cs.na/0607105.

[68] diaconis, p. and stroock, d.,    geometric bounds for eigenvalues of
markov chains,    the annals of applied id203, vol. 1, no. 1, 1991,
pp. 36   61.

[69] guattery, s., leighton, t., and miller, g. l.,    the path resistance
method for bounding the smallest nontrivial eigenvalue of a lapla-
cian,    combinatorics, id203 and computing, vol. 8, 1999, pp. 441   
460.

[70] guattery, s. and miller, g. l.,    graph embeddings and laplacian
eigenvalues,    siam journal on matrix analysis and applications,
vol. 21, no. 3, 2000, pp. 703   723.

[71] wilf, h. s.,    the eigenvalues of a graph and its chromatic number,   

j. london math. soc., vol. 42, 1967, pp. 330   332.

[72] ho   man, a. j.,    on eigenvalues and colorings of graphs,    id207

and its applications, academic press, new york, 1970, pp. 79   92.

[73] trevisan, l.,    max cut and the smallest eigenvalue,    proceedings of the
41st annual acm symposium on theory of computing, 2009, pp. 263   
272.

[74] mcsherry, f.,    spectral partitioning of random graphs,    proceedings
of the 42nd ieee symposium on foundations of computer science,
2001, pp. 529   537.

[75] demmel, j., applied numerical id202, siam, 1997.

[76] boppana, r. b.,    eigenvalues and graph bisection: an average-case anal-
ysis,    proc. 28th ieee symposium on foundations of computer sci-
ence, 1987, pp. 280   285.

[77] f  uredi, z. and koml  os, j.,    the eigenvalues of random symmetric ma-

trices,    combinatorica, vol. 1, no. 3, 1981, pp. 233   241.

[78] vu, v.,    spectral norm of random matrices,    combinatorica, vol. 27,

no. 6, 2007, pp. 721   736.

[79] alon, n., krivelevich, m., and vu, v. h.,    on the concentration of eigen-
values of random symmetric matrices,    israel journal of mathematics,
vol. 131, no. 1, 2002, pp. 259   267.

[80] alon, n. and kahale, n.,    a spectral technique for coloring ran-
dom 3-colorable graphs,    siam journal on computing, vol. 26, 1997,
pp. 1733   1748.

spectral id207

29

[81] kannan, r. and vempala, s.,    spectral algorithms,    foundations and
trends in theoretical computer science, vol. 4, no. 3-4, 2008, pp. 132   
288.

[82] batson, j. d., spielman, d. a., and srivastava, n.,    twice-ramanujan
sparsi   ers,    proceedings of the 41st annual acm symposium on theory
of computing, 2009, pp. 255   262.

[83] spielman, d. a. and srivastava, n.,    graph sparsi   cation by e   ective
resistances,    siam journal on computing, 2010, to appear. prelim-
inary version appeared in the proceedings of the 40th annual acm
symposium on theory of computing.

[84] spielman, d. a. and woo, j.,    a note on preconditioning by low-
stretch spanning trees,    corr, vol. abs/0903.2816, 2009, available at
http://arxiv.org/abs/0903.2816.

[85] page, l., brin, s., motwani, r., and winograd, t.,    the id95
citation ranking: bringing order to the web,    tech. rep., computer
science department, stanford university, 1998.

[86] langville, a. n. and meyer, c. d., google   s id95 and beyond:
the science of search engine rankings, princeton university press,
princeton, nj, usa, 2006.

[87] bonacich, p.,    technique for analyzing overlapping memberships,    so-

ciological methodology, vol. 4, 1972, pp. 176   185.

[88] bonacich, p.,    factoring and weighting approaches to status scores
and clique identi   cation,    journal of mathematical sociology, vol. 2,
1972, pp. 113   120.

[89] bonacich, p.,    power and centrality: a family of measures,    american

journal of sociology, vol. 92, 1987, pp. 1170   1182.

[90] berge, c., graphs, north-holland, 1985.

[91] palacios-huerta, i. and volij, o.,    the measurement of intellectual in-

   uence,    econometrica, vol. 72, no. 3, 2004, pp. 963   977.

[92] altman, a. and tennenholtz, m.,    ranking systems: the id95 ax-
ioms,    proceedings of the 6th acm conference on electronic commerce,
2005, pp. 1   8.

[93] kleinberg, j.,    authoratitive sources in a hyperlinked environment,   

journal of the acm , vol. 48, 1999, pp. 604   632.

[94] chung, f.,    the diameter and laplacian eigenvalues of directed
graphs,    the electronic journal of combinatorics, vol. 13, no. 1, 2006.

30

combinatorial scienti   c computing

[95] chung, f.,    laplacians and the cheeger inequality for directed

graphs,    annals of combinatorics, vol. 9, no. 1, 2005, pp. 1   19.

[96] mohar, b. and poljak, s.,    eigenvalues in combinatorial optimization,   
combinatorial and graph-theoretical problems in id202, ima
volumes in mathematics and its applications, springer-verlag, 1993,
pp. 107   151.

[97] mohar, b.,    the laplacian spectrum of graphs,    id207, com-

binatorics, and applications, wiley, 1991, pp. 871   898.

[98] brouwer, a. e. and haemers, w. h.,    spectra of graphs,    electronic

book. available at http://www.win.tue.nl/   aeb/ipm.pdf.

[99] godsil, c. and royle, g., algebraic id207, graduate texts in

mathematics, springer, 2001.

[100] biggs, n. l., algebraic id207, cambridge tracts in math., cam-

bridge university press, london, new york, 1974.

[101] brualdi, r. a. and ryser, h. j., combinatorial matrix theory, cam-

bridge university press, new york, 1991.

[102] brouwer, a. e., cohen, a. m., and neumaier, a., distance-regular

graphs., springer verlag, 1989.

