 
understanding machine learning     
a theory perspective 
 

shai ben-david 

university of waterloo 

 

 
 

 

 mlss at mpi tubingen, 2017 

 

some infinite classes are 
learnable 
examples: 

l    initial segments of the real line. 

l    the class of singletons over any domain 

set 

other classes of the same    size    
are not learnable 

l    the class of all finite subsets of an 

infinite domain. 

proof:  note that for possible value for 
m=mh(1/8,1/8) there is a domain subset 
am of double the size for which every 
possible f:am     {0,1} agrees with some h 
in h. 

a combinatorial characterization 
of pac learnable classes 

shattering: 
a class h shatters a domain subset a if 
for every b subset of a 
there is some hb in h so that for all x in a  
hb(x)=1 if and only if x is in b. 
 
l   examples: 

the vapnik chervonenkis dimension 

given a class of binary valued functions, h, 
the vapnik-chervonenkis dimension of h is 
 

vcdim(h) =sup {|a|: h shatters a} 

 

first connection to pac learning 

note that our proof of the no free lunch 
theorem shows, in fact, that: 
 
for any class h, mh(1/8, 1/8) > vcdim(h)/2 

corollary: if vcdim(h) is infinite then h is 
not pac learnable. 

the fundamental theorem 
(qualitative) 

theorem: given a class h of binary valued 
functions the following statements are 
equivalent: 
a)    h has the uniform convergence property 
b)    erm is an agnostic pac learner for h 
c)    h is agnostic pac learnable 
d)    h is pac learnable 
e)    vcdim(h) is finite 

main tool for (e) implies (a) 

the shatter function 
for a class h define a function   h: n   n 
as    h(m) = max{a: |a|=m}|{h|a : h in h}|  
 
some basic properties of the shatter 
function: 
1.    for every m     vcdim(h),   h(m) =2m 
2.    for every m > vcdim(h),   h(m) < 2m 
 

the sauer (shelah, perles) 
lemma 
for every class h of finite vc-dimension, d, 
  
for every m,  
 
           h(m)       i=0
 
 

d  (m choose i)     md 

a typical corollary 

the number of linear partitions of a set of 
points in the plain. 

quantitative version of the  
fundamental theorem 
for some constants c1, c2, for every d and every 
class h of binary valued functions such that 
vcdim(h)=d,  
1.  h has uniform convergence property with 
     c1(d+log(1/  ))/  2 < muc
 2. h is agnostic pac learnable with 
     c1(d+log(1/  ))/  2 < mh(  ,   ) < c1(d+log(1/  ))/  2  
 3.  h is pac learnable with 
    c1(d+log(1/  ))/   < mh(  ,   ) < c1(d+log(1/  ))/    
 

h(  ,   ) < c1(d+log(1/  ))/  2  

