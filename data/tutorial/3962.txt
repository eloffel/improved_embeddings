   #[1]rss [2]slideshare search [3]alternate [4]alternate [5]alternate
   [6]alternate [7]alternate [8]alternate [9]slideshow json oembed profile
   [10]slideshow xml oembed profile [11]alternate [12]alternate
   [13]alternate

   (button)

   slideshare uses cookies to improve functionality and performance, and
   to provide you with relevant advertising. if you continue browsing the
   site, you agree to the use of cookies on this website. see our [14]user
   agreement and [15]privacy policy.

   slideshare uses cookies to improve functionality and performance, and
   to provide you with relevant advertising. if you continue browsing the
   site, you agree to the use of cookies on this website. see our
   [16]privacy policy and [17]user agreement for details.

   [18]slideshare [19]explore search [20]you

     * [21]linkedin slideshare

     * [22]upload
     * [23]login
     * [24]signup

     *
     * ____________________ (button) submit search

     * [25]home
     * [26]explore

     * [27]presentation courses
     * [28]powerpoint courses
     *
     * by [29]linkedin learning

   ____________________
   successfully reported this slideshow.

   we use your linkedin profile and activity data to personalize ads and
   to show you more relevant ads. [30]you can change your ad preferences
   anytime.
   recurrent neural networks i (d2l2 deep learning for speech and language
   upc 2017)

   [course site] day 2 lecture 2 recurrent neural networks i santiago
   pascual

   2 outline 1. the importance of context 2. where is the memory? 3.
   vanilla id56 4. problems 5. gating methodology a. lstm b....

   3 the importance of context     recall the 5th digit of your phone number
       sing your favourite song beginning at third sent...

   recall from day 1 lecture 2    4 feedforward every y/hi is computed from
   the sequence of forward activations out of input x.

   5 where is the memory? if we have a sequence of samples... predict
   sample x[t+1] knowing previous values {x[t], x[t-1], x[...

   6 where is the memory? feed forward approach:     static window of size l
       slide the window time-step wise ... ... ... x[t+...

   7 where is the memory? feed forward approach:     static window of size l
       slide the window time-step wise ... ... ... x[t+...

   8 where is the memory? feed forward approach:     static window of size l
       slide the window time-step wise x[t+3] l ... ......

   9 where is the memory? ... ... ... x1, x2,    , xl problems for the feed
   forward + static window approach:     what   s the matt...

   10 recurrent neural network solution: build specific connections
   capturing the temporal evolution     shared weights in time...

   11 solution: build specific connections capturing the temporal
   evolution     shared weights in time     give volatile memory t...

   recurrent neural network time time rotation 90o front view side view
   rotation 90o slide credit: xavi giro

   recurrent neural network hence we have two data flows: forward in space
   + time propagation: 2 projections per layer activa...

   recurrent neural network hence we have two data flows: forward in space
   + time propagation: 2 projections per layer activa...

   recurrent neural network hence we have two data flows: forward in space
   + time propagation: 2 projections per layer activa...

   recurrent neural network hence we have two data flows: forward in space
   + time propagation: 2 projections per layer activa...

   recurrent neural network hence we have two data flows: forward in space
   + time propagation: 2 projections per layer activa...

   18 bidirectional id56 (bid56) alex graves,    supervised sequence labelling
   with recurrent neural networks    must learn weights...

   recurrent neural network back propagation through time (bptt): the
   training method has to take into account the time opera...

   recurrent neural network main problems:     long-term memory (remembering
   quite far time-steps) vanishes quickly because of ...

   gating method solutions: 1. change the way in which past information is
   kept     create the notion of cell state, a memory u...

   22 hochreiter, sepp, and j  rgen schmidhuber. "long short-term memory."
   neural computation 9, no. 8 (1997): 1735-1780. long...

   long short term memory (lstm) cell an lstm cell is defined by two
   groups of neurons plus the cell state (memory unit): 1. ...

   24 long short-term memory (lstm) three gates are governed by sigmoid
   units (btw [0,1]) define the control of in & out info...

   25 long short-term memory (lstm) forget gate: concatenate figure:
   cristopher olah,    understanding id137    (2015) / ...

   26 long short-term memory (lstm) input gate layer new contribution to
   cell state classic neuron figure: cristopher olah,    ...

   27 long short-term memory (lstm) update cell state (memory): figure:
   cristopher olah,    understanding id137    (2015)...

   28 long short-term memory (lstm) output gate layer output to next layer
   figure: cristopher olah,    understanding lstm netwo...

   29 long short-term memory (lstm) figure: cristopher olah,
      understanding id137    (2015) / slide: alberto montes

   long short term memory (lstm) cell an lstm cell is defined by two
   groups of neurons plus the cell state (memory unit): 1. ...

   31 gated recurrent unit (gru) cho, kyunghyun, bart van merri  nboer,
   caglar gulcehre, dzmitry bahdanau, fethi bougares, hol...

   32 gated recurrent unit (gru) cho, kyunghyun, bart van merri  nboer,
   caglar gulcehre, dzmitry bahdanau, fethi bougares, hol...

   33figure: cristopher olah,    understanding id137    (2015) /
   slide: alberto montes gated recurrent unit (gru)

   34 thanks ! q&a ? @santty128
   upcoming slideshare
   []
   loading in    5
     
   [] 1
   (button)
   1 of 34 (button)
   (button) (button)
   like this presentation? why not share!
     * share
     * email
     *
     *

     * [31]electricity price forecasting with ... electricity price
       forecasting with ... by taegyun jeon 30822 views

   (button)

   share slideshare
     __________________________________________________________________

     * [32]facebook
     * [33]twitter
     * [34]linkedin

   embed
   ____________________________________________________________
   ____________________________________________________________
   ____________________________________________________________
   ____________________________________________________________
   size (px)
   start on
   [x] show related slideshares at end
   wordpress shortcode ____________________
   link ____________________

recurrent neural networks i (d2l2 deep learning for speech and language upc
2017)

   1,575 views

     * (button) share
     * (button) like
     * (button) download
     * ...
          +

   [35]universitat polit  cnica de catalunya

[36]universitat polit  cnica de catalunya

   [37]follow

   (button) (button) (button)

   published on jan 25, 2017

   https://telecombcn-dl.github.io/2017-dlsl/
   winter school on deep learning for speech and language. upc
   barcelonatech etsetb telecombcn.
   the aim of this course is to train students in methods of deep learning
   for speech and language. recurrent neural networks (id56) will be
   presented and analyzed in detail to understand the potential of these
   state of the art tools for time series processing. engineering tips and
   scalability issues will be addressed to solve tasks such as machine
   translation, id103, id133 or question
   answering. hands-on sessions will provide development skills so that
   attendees can become competent in contemporary data analytics tools.
   (button) ...

   published in: [38]data & analytics

     * [39]0 comments
     * [40]2 likes
     * [41]statistics
     * [42]notes

     * full name
       full name
       comment goes here.
       12 hours ago   [43]delete [44]reply [45]block
       are you sure you want to [46]yes [47]no
       your message goes here

   no profile picture user
   ____________________
   [48](button) post
     * be the first to comment

     * [49]hafinatashakamis
       [50]hafinatasha kamis
       6 months ago
     * [51]mehdikorjani
       [52]mehdi korjani , senior data scientist at capital group, machine
       learning, deep learning, nlp at senior data scientist
       2 years ago

   no downloads
   views
   total views
   1,575
   on slideshare
   0
   from embeds
   0
   number of embeds
   1
   actions
   shares
   0
   downloads
   145
   comments
   0
   likes
   2
   embeds 0
   no embeds
   no notes for slide

recurrent neural networks i (d2l2 deep learning for speech and language upc
2017)

    1. 1. [course site] day 2 lecture 2 recurrent neural networks i
       santiago pascual
    2. [53]2. 2 outline 1. the importance of context 2. where is the
       memory? 3. vanilla id56 4. problems 5. gating methodology a. lstm b.
       gru
    3. [54]3. 3 the importance of context     recall the 5th digit of your
       phone number     sing your favourite song beginning at third sentence
           recall 10th character of the alphabet probably you went straight
       from the beginning of the stream in each case    because in sequences
       order matters! idea: retain the information preserving the
       importance of order
    4. [55]4. recall from day 1 lecture 2    4 feedforward every y/hi is
       computed from the sequence of forward activations out of input x.
    5. [56]5. 5 where is the memory? if we have a sequence of samples...
       predict sample x[t+1] knowing previous values {x[t], x[t-1],
       x[t-2],    , x[t-  ]}
    6. [57]6. 6 where is the memory? feed forward approach:     static
       window of size l     slide the window time-step wise ... ... ...
       x[t+1] x[t-l],    , x[t-1], x[t] x[t+1] l
    7. [58]7. 7 where is the memory? feed forward approach:     static
       window of size l     slide the window time-step wise ... ... ...
       x[t+2] x[t-l+1],    , x[t], x[t+1] ... ... ... x[t+1] x[t-l],    ,
       x[t-1], x[t] x[t+2] l
    8. [59]8. 8 where is the memory? feed forward approach:     static
       window of size l     slide the window time-step wise x[t+3] l ... ...
       ... x[t+3] x[t-l+2],    , x[t+1], x[t+2] ... ... ... x[t+2] x[t-l+1],
          , x[t], x[t+1] ... ... ... x[t+1] x[t-l],    , x[t-1], x[t]
    9. [60]9. 9 where is the memory? ... ... ... x1, x2,    , xl problems
       for the feed forward + static window approach:     what   s the matter
       increasing l?     fast growth of num of parameters!     decisions are
       independent between time-steps!     the network doesn   t care about
       what happened at previous time-step, only present window matters    
       doesn   t look good     cumbersome padding when there are not enough
       samples to fill l size     can   t work with variable sequence lengths
       x1, x2,    , xl,    , x2l ... ... x1, x2,    , xl,    , x2l,    , x3l ... ...
       ... ...
   10. [61]10. 10 recurrent neural network solution: build specific
       connections capturing the temporal evolution     shared weights in
       time     give volatile memory to the network feed-forward
       fully-connected figure credit: xavi giro
   11. [62]11. 11 solution: build specific connections capturing the
       temporal evolution     shared weights in time     give volatile memory
       to the network feed-forward fully-connected figure credit: xavi
       giro fully connected in time: recurrent matrix recurrent neural
       network
   12. [63]12. recurrent neural network time time rotation 90o front view
       side view rotation 90o slide credit: xavi giro
   13. [64]13. recurrent neural network hence we have two data flows:
       forward in space + time propagation: 2 projections per layer
       activation. beware: we have extra depth now! every time-step is an
       extra level of depth (as a deeper stack of layers in a feed-forward
       fashion!)
   14. [65]14. recurrent neural network hence we have two data flows:
       forward in space + time propagation: 2 projections per layer
       activation     last time-step includes the context of our decisions
       recursively
   15. [66]15. recurrent neural network hence we have two data flows:
       forward in space + time propagation: 2 projections per layer
       activation     last time-step includes the context of our decisions
       recursively
   16. [67]16. recurrent neural network hence we have two data flows:
       forward in space + time propagation: 2 projections per layer
       activation     last time-step includes the context of our decisions
       recursively
   17. [68]17. recurrent neural network hence we have two data flows:
       forward in space + time propagation: 2 projections per layer
       activation     last time-step includes the context of our decisions
       recursively
   18. [69]18. 18 bidirectional id56 (bid56) alex graves,    supervised
       sequence labelling with recurrent neural networks    must learn
       weights w2, w3, w4 & w5; in addition to w1 & w6. slide credit: xavi
       giro
   19. [70]19. recurrent neural network back propagation through time
       (bptt): the training method has to take into account the time
       operations     a cost function e is defined to train our id56, and in
       this case the total error at the output of the network is the sum
       of the errors at each time-step: t: max amount of time-steps to do
       back-prop. in keras this is specified when defining the    input
       shape    to the id56 layer, by means of: (batch size, sequence length
       (t), input_dim)
   20. [71]20. recurrent neural network main problems:     long-term memory
       (remembering quite far time-steps) vanishes quickly because of the
       recursive operation with u     during training gradients
       explode/vanish easily because of depth-in-time    
       exploding/vanishing gradients!
   21. [72]21. gating method solutions: 1. change the way in which past
       information is kept     create the notion of cell state, a memory
       unit that keeps long-term information in a safer way by protecting
       it from recursive operations 2. make every id56 unit able to decide
       whether the current time-step information matters or not, to accept
       or discard (optimized reading mechanism) 3. make every id56 unit
       able to forget whatever may not be useful anymore by clearing that
       info from the cell state (optimized clearing mechanism) 4. make
       every id56 unit able to output the decisions whenever it is ready to
       do so (optimized output mechanism)
   22. [73]22. 22 hochreiter, sepp, and j  rgen schmidhuber. "long
       short-term memory." neural computation 9, no. 8 (1997): 1735-1780.
       long short-term memory (lstm) slide credit: xavi giro
   23. [74]23. long short term memory (lstm) cell an lstm cell is defined
       by two groups of neurons plus the cell state (memory unit): 1.
       gates 2. activation units 3. cell state computation flow
   24. [75]24. 24 long short-term memory (lstm) three gates are governed
       by sigmoid units (btw [0,1]) define the control of in & out
       information.. figure: cristopher olah,    understanding lstm
       networks    (2015) slide credit: xavi giro
   25. [76]25. 25 long short-term memory (lstm) forget gate: concatenate
       figure: cristopher olah,    understanding id137    (2015) /
       slide: alberto montes
   26. [77]26. 26 long short-term memory (lstm) input gate layer new
       contribution to cell state classic neuron figure: cristopher olah,
          understanding id137    (2015) / slide: alberto montes
   27. [78]27. 27 long short-term memory (lstm) update cell state
       (memory): figure: cristopher olah,    understanding id137   
       (2015) / slide: alberto montes
   28. [79]28. 28 long short-term memory (lstm) output gate layer output
       to next layer figure: cristopher olah,    understanding lstm
       networks    (2015) / slide: alberto montes
   29. [80]29. 29 long short-term memory (lstm) figure: cristopher olah,
          understanding id137    (2015) / slide: alberto montes
   30. [81]30. long short term memory (lstm) cell an lstm cell is defined
       by two groups of neurons plus the cell state (memory unit): 1.
       gates 2. activation units 3. cell state 3 gates + input activation
   31. [82]31. 31 gated recurrent unit (gru) cho, kyunghyun, bart van
       merri  nboer, caglar gulcehre, dzmitry bahdanau, fethi bougares,
       holger schwenk, and yoshua bengio. "learning phrase representations
       using id56 encoder-decoder for id151."
       amnlp 2014. similar performance as lstm with less computation.
       slide credit: xavi giro
   32. [83]32. 32 gated recurrent unit (gru) cho, kyunghyun, bart van
       merri  nboer, caglar gulcehre, dzmitry bahdanau, fethi bougares,
       holger schwenk, and yoshua bengio. "learning phrase representations
       using id56 encoder-decoder for id151."
       amnlp 2014. similar performance as lstm with less computation.
       slide credit: xavi giro
   33. [84]33. 33figure: cristopher olah,    understanding id137   
       (2015) / slide: alberto montes gated recurrent unit (gru)
   34. [85]34. 34 thanks ! q&a ? @santty128

          [86]recommended

     * creative insights: renaldo lawrence on elearning
       creative insights: renaldo lawrence on elearning
       online course - linkedin learning
     * academic research foundations: quantitative
       academic research foundations: quantitative
       online course - linkedin learning
     * teaching complex topics
       teaching complex topics
       online course - linkedin learning
     * electricity price forecasting with recurrent neural networks
       electricity price forecasting with recurrent neural networks
       taegyun jeon
     * self-supervised audiovisual learning - xavier giro - upc barcelona
       2019
       self-supervised audiovisual learning - xavier giro - upc barcelona
       2019
       universitat polit  cnica de catalunya
     * deep video object tracking - xavier giro - upc barcelona 2019
       deep video object tracking - xavier giro - upc barcelona 2019
       universitat polit  cnica de catalunya
     * self-supervised learning from video sequences - xavier giro - upc
       barcelona 2019
       self-supervised learning from video sequences - xavier giro - upc
       barcelona 2019
       universitat polit  cnica de catalunya
     * deep learning architectures for video - xavier giro - upc barcelona
       2019
       deep learning architectures for video - xavier giro - upc barcelona
       2019
       universitat polit  cnica de catalunya
     * deep video object segmentation - xavier giro - upc barcelona 2019
       deep video object segmentation - xavier giro - upc barcelona 2019
       universitat polit  cnica de catalunya
     * wav2pix: speech-conditioned face generation using generative
       adversarial networksa
       wav2pix: speech-conditioned face generation using generative
       adversarial netw...
       universitat polit  cnica de catalunya

     * [87]english
     * [88]espa  ol
     * [89]portugu  s
     * [90]fran  ais
     * [91]deutsch

     * [92]about
     * [93]dev & api
     * [94]blog
     * [95]terms
     * [96]privacy
     * [97]copyright
     * [98]support

     *
     *
     *
     *
     *

   linkedin corporation    2019

     

share clipboard
     __________________________________________________________________

   [99]  
     * facebook
     * twitter
     * linkedin

   link ____________________

public clipboards featuring this slide
     __________________________________________________________________

   (button)   
   no public clipboards found for this slide

select another clipboard
     __________________________________________________________________

   [100]  

   looks like you   ve clipped this slide to already.
   ____________________

   create a clipboard

you just clipped your first slide!

   clipping is a handy way to collect important slides you want to go back
   to later. now customize the name of a clipboard to store your clips.
     __________________________________________________________________

   name* ____________________
   description ____________________
   visibility
   others can see my clipboard [ ]
   (button) cancel (button) save

   bizographics tracking image

references

   visible links
   1. https://www.slideshare.net/rss/latest
   2. https://www.slideshare.net/opensearch.xml
   3. https://www.slideshare.net/xavigiro/recurrent-neural-networks-1-d2l2-deep-learning-for-speech-and-language-upc-2017
   4. https://es.slideshare.net/xavigiro/recurrent-neural-networks-1-d2l2-deep-learning-for-speech-and-language-upc-2017
   5. https://fr.slideshare.net/xavigiro/recurrent-neural-networks-1-d2l2-deep-learning-for-speech-and-language-upc-2017
   6. https://de.slideshare.net/xavigiro/recurrent-neural-networks-1-d2l2-deep-learning-for-speech-and-language-upc-2017
   7. https://pt.slideshare.net/xavigiro/recurrent-neural-networks-1-d2l2-deep-learning-for-speech-and-language-upc-2017
   8. https://www.slideshare.net/xavigiro/recurrent-neural-networks-1-d2l2-deep-learning-for-speech-and-language-upc-2017
   9. https://www.slideshare.net/api/oembed/2?format=json&url=http://www.slideshare.net/xavigiro/recurrent-neural-networks-1-d2l2-deep-learning-for-speech-and-language-upc-2017
  10. https://www.slideshare.net/api/oembed/2?format=xml&url=http://www.slideshare.net/xavigiro/recurrent-neural-networks-1-d2l2-deep-learning-for-speech-and-language-upc-2017
  11. https://www.slideshare.net/mobile/xavigiro/recurrent-neural-networks-1-d2l2-deep-learning-for-speech-and-language-upc-2017
  12. android-app://net.slideshare.mobile/slideshare-app/ss/71385579
  13. ios-app://917418728/slideshare-app/ss/71385579
  14. http://www.linkedin.com/legal/user-agreement
  15. http://www.linkedin.com/legal/privacy-policy
  16. http://www.linkedin.com/legal/privacy-policy
  17. http://www.linkedin.com/legal/user-agreement
  18. https://www.slideshare.net/
  19. https://www.slideshare.net/explore
  20. https://www.slideshare.net/login
  21. https://www.slideshare.net/
  22. https://www.slideshare.net/upload
  23. https://www.slideshare.net/login
  24. https://www.slideshare.net/w/signup
  25. https://www.slideshare.net/
  26. https://www.slideshare.net/explore
  27. https://www.linkedin.com/learning/topics/presentations?trk=slideshare_subnav_learning&entitytype=course&sortby=recency
  28. https://www.linkedin.com/learning/topics/powerpoint?trk=slideshare_subnav_learning&entitytype=course&sortby=recency
  29. https://www.linkedin.com/learning?trk=slideshare_subnav_learning
  30. https://www.linkedin.com/psettings/privacy
  31. https://public.slidesharecdn.com/taegyunjeon1/electricity-price-forecasting-with-recurrent-neural-networks
  32. https://www.slideshare.net/xavigiro/recurrent-neural-networks-1-d2l2-deep-learning-for-speech-and-language-upc-2017
  33. https://www.slideshare.net/xavigiro/recurrent-neural-networks-1-d2l2-deep-learning-for-speech-and-language-upc-2017
  34. https://www.slideshare.net/xavigiro/recurrent-neural-networks-1-d2l2-deep-learning-for-speech-and-language-upc-2017
  35. https://www.slideshare.net/xavigiro?utm_campaign=profiletracking&utm_medium=sssite&utm_source=ssslideview
  36. https://www.slideshare.net/xavigiro?utm_campaign=profiletracking&utm_medium=sssite&utm_source=ssslideview
  37. https://www.slideshare.net/signup?login_source=slideview.popup.follow&from=addcontact&from_source=https://www.slideshare.net/xavigiro/recurrent-neural-networks-1-d2l2-deep-learning-for-speech-and-language-upc-2017
  38. https://www.slideshare.net/featured/category/data-analytics
  39. https://www.slideshare.net/xavigiro/recurrent-neural-networks-1-d2l2-deep-learning-for-speech-and-language-upc-2017#comments-panel
  40. https://www.slideshare.net/xavigiro/recurrent-neural-networks-1-d2l2-deep-learning-for-speech-and-language-upc-2017#likes-panel
  41. https://www.slideshare.net/xavigiro/recurrent-neural-networks-1-d2l2-deep-learning-for-speech-and-language-upc-2017#stats-panel
  42. https://www.slideshare.net/xavigiro/recurrent-neural-networks-1-d2l2-deep-learning-for-speech-and-language-upc-2017#notes-panel
  43. https://www.slideshare.net/xavigiro/recurrent-neural-networks-1-d2l2-deep-learning-for-speech-and-language-upc-2017
  44. https://www.slideshare.net/xavigiro/recurrent-neural-networks-1-d2l2-deep-learning-for-speech-and-language-upc-2017
  45. https://www.slideshare.net/xavigiro/recurrent-neural-networks-1-d2l2-deep-learning-for-speech-and-language-upc-2017
  46. https://www.slideshare.net/xavigiro/recurrent-neural-networks-1-d2l2-deep-learning-for-speech-and-language-upc-2017
  47. https://www.slideshare.net/xavigiro/recurrent-neural-networks-1-d2l2-deep-learning-for-speech-and-language-upc-2017
  48. https://www.slideshare.net/signup?login_source=slideview.popup.comment&from=comments&from_source=https://www.slideshare.net/xavigiro/recurrent-neural-networks-1-d2l2-deep-learning-for-speech-and-language-upc-2017
  49. https://www.slideshare.net/hafinatashakamis?utm_campaign=profiletracking&utm_medium=sssite&utm_source=ssslideshow
  50. https://www.slideshare.net/hafinatashakamis?utm_campaign=profiletracking&utm_medium=sssite&utm_source=ssslideshow
  51. https://www.slideshare.net/mehdikorjani?utm_campaign=profiletracking&utm_medium=sssite&utm_source=ssslideshow
  52. https://www.slideshare.net/mehdikorjani?utm_campaign=profiletracking&utm_medium=sssite&utm_source=ssslideshow
  53. https://image.slidesharecdn.com/dlsl2017d2l2recurrentneuralnetworksi-170125171004/95/recurrent-neural-networks-i-d2l2-deep-learning-for-speech-and-language-upc-2017-2-638.jpg?cb=1485365064
  54. https://image.slidesharecdn.com/dlsl2017d2l2recurrentneuralnetworksi-170125171004/95/recurrent-neural-networks-i-d2l2-deep-learning-for-speech-and-language-upc-2017-3-638.jpg?cb=1485365064
  55. https://image.slidesharecdn.com/dlsl2017d2l2recurrentneuralnetworksi-170125171004/95/recurrent-neural-networks-i-d2l2-deep-learning-for-speech-and-language-upc-2017-4-638.jpg?cb=1485365064
  56. https://image.slidesharecdn.com/dlsl2017d2l2recurrentneuralnetworksi-170125171004/95/recurrent-neural-networks-i-d2l2-deep-learning-for-speech-and-language-upc-2017-5-638.jpg?cb=1485365064
  57. https://image.slidesharecdn.com/dlsl2017d2l2recurrentneuralnetworksi-170125171004/95/recurrent-neural-networks-i-d2l2-deep-learning-for-speech-and-language-upc-2017-6-638.jpg?cb=1485365064
  58. https://image.slidesharecdn.com/dlsl2017d2l2recurrentneuralnetworksi-170125171004/95/recurrent-neural-networks-i-d2l2-deep-learning-for-speech-and-language-upc-2017-7-638.jpg?cb=1485365064
  59. https://image.slidesharecdn.com/dlsl2017d2l2recurrentneuralnetworksi-170125171004/95/recurrent-neural-networks-i-d2l2-deep-learning-for-speech-and-language-upc-2017-8-638.jpg?cb=1485365064
  60. https://image.slidesharecdn.com/dlsl2017d2l2recurrentneuralnetworksi-170125171004/95/recurrent-neural-networks-i-d2l2-deep-learning-for-speech-and-language-upc-2017-9-638.jpg?cb=1485365064
  61. https://image.slidesharecdn.com/dlsl2017d2l2recurrentneuralnetworksi-170125171004/95/recurrent-neural-networks-i-d2l2-deep-learning-for-speech-and-language-upc-2017-10-638.jpg?cb=1485365064
  62. https://image.slidesharecdn.com/dlsl2017d2l2recurrentneuralnetworksi-170125171004/95/recurrent-neural-networks-i-d2l2-deep-learning-for-speech-and-language-upc-2017-11-638.jpg?cb=1485365064
  63. https://image.slidesharecdn.com/dlsl2017d2l2recurrentneuralnetworksi-170125171004/95/recurrent-neural-networks-i-d2l2-deep-learning-for-speech-and-language-upc-2017-12-638.jpg?cb=1485365064
  64. https://image.slidesharecdn.com/dlsl2017d2l2recurrentneuralnetworksi-170125171004/95/recurrent-neural-networks-i-d2l2-deep-learning-for-speech-and-language-upc-2017-13-638.jpg?cb=1485365064
  65. https://image.slidesharecdn.com/dlsl2017d2l2recurrentneuralnetworksi-170125171004/95/recurrent-neural-networks-i-d2l2-deep-learning-for-speech-and-language-upc-2017-14-638.jpg?cb=1485365064
  66. https://image.slidesharecdn.com/dlsl2017d2l2recurrentneuralnetworksi-170125171004/95/recurrent-neural-networks-i-d2l2-deep-learning-for-speech-and-language-upc-2017-15-638.jpg?cb=1485365064
  67. https://image.slidesharecdn.com/dlsl2017d2l2recurrentneuralnetworksi-170125171004/95/recurrent-neural-networks-i-d2l2-deep-learning-for-speech-and-language-upc-2017-16-638.jpg?cb=1485365064
  68. https://image.slidesharecdn.com/dlsl2017d2l2recurrentneuralnetworksi-170125171004/95/recurrent-neural-networks-i-d2l2-deep-learning-for-speech-and-language-upc-2017-17-638.jpg?cb=1485365064
  69. https://image.slidesharecdn.com/dlsl2017d2l2recurrentneuralnetworksi-170125171004/95/recurrent-neural-networks-i-d2l2-deep-learning-for-speech-and-language-upc-2017-18-638.jpg?cb=1485365064
  70. https://image.slidesharecdn.com/dlsl2017d2l2recurrentneuralnetworksi-170125171004/95/recurrent-neural-networks-i-d2l2-deep-learning-for-speech-and-language-upc-2017-19-638.jpg?cb=1485365064
  71. https://image.slidesharecdn.com/dlsl2017d2l2recurrentneuralnetworksi-170125171004/95/recurrent-neural-networks-i-d2l2-deep-learning-for-speech-and-language-upc-2017-20-638.jpg?cb=1485365064
  72. https://image.slidesharecdn.com/dlsl2017d2l2recurrentneuralnetworksi-170125171004/95/recurrent-neural-networks-i-d2l2-deep-learning-for-speech-and-language-upc-2017-21-638.jpg?cb=1485365064
  73. https://image.slidesharecdn.com/dlsl2017d2l2recurrentneuralnetworksi-170125171004/95/recurrent-neural-networks-i-d2l2-deep-learning-for-speech-and-language-upc-2017-22-638.jpg?cb=1485365064
  74. https://image.slidesharecdn.com/dlsl2017d2l2recurrentneuralnetworksi-170125171004/95/recurrent-neural-networks-i-d2l2-deep-learning-for-speech-and-language-upc-2017-23-638.jpg?cb=1485365064
  75. https://image.slidesharecdn.com/dlsl2017d2l2recurrentneuralnetworksi-170125171004/95/recurrent-neural-networks-i-d2l2-deep-learning-for-speech-and-language-upc-2017-24-638.jpg?cb=1485365064
  76. https://image.slidesharecdn.com/dlsl2017d2l2recurrentneuralnetworksi-170125171004/95/recurrent-neural-networks-i-d2l2-deep-learning-for-speech-and-language-upc-2017-25-638.jpg?cb=1485365064
  77. https://image.slidesharecdn.com/dlsl2017d2l2recurrentneuralnetworksi-170125171004/95/recurrent-neural-networks-i-d2l2-deep-learning-for-speech-and-language-upc-2017-26-638.jpg?cb=1485365064
  78. https://image.slidesharecdn.com/dlsl2017d2l2recurrentneuralnetworksi-170125171004/95/recurrent-neural-networks-i-d2l2-deep-learning-for-speech-and-language-upc-2017-27-638.jpg?cb=1485365064
  79. https://image.slidesharecdn.com/dlsl2017d2l2recurrentneuralnetworksi-170125171004/95/recurrent-neural-networks-i-d2l2-deep-learning-for-speech-and-language-upc-2017-28-638.jpg?cb=1485365064
  80. https://image.slidesharecdn.com/dlsl2017d2l2recurrentneuralnetworksi-170125171004/95/recurrent-neural-networks-i-d2l2-deep-learning-for-speech-and-language-upc-2017-29-638.jpg?cb=1485365064
  81. https://image.slidesharecdn.com/dlsl2017d2l2recurrentneuralnetworksi-170125171004/95/recurrent-neural-networks-i-d2l2-deep-learning-for-speech-and-language-upc-2017-30-638.jpg?cb=1485365064
  82. https://image.slidesharecdn.com/dlsl2017d2l2recurrentneuralnetworksi-170125171004/95/recurrent-neural-networks-i-d2l2-deep-learning-for-speech-and-language-upc-2017-31-638.jpg?cb=1485365064
  83. https://image.slidesharecdn.com/dlsl2017d2l2recurrentneuralnetworksi-170125171004/95/recurrent-neural-networks-i-d2l2-deep-learning-for-speech-and-language-upc-2017-32-638.jpg?cb=1485365064
  84. https://image.slidesharecdn.com/dlsl2017d2l2recurrentneuralnetworksi-170125171004/95/recurrent-neural-networks-i-d2l2-deep-learning-for-speech-and-language-upc-2017-33-638.jpg?cb=1485365064
  85. https://image.slidesharecdn.com/dlsl2017d2l2recurrentneuralnetworksi-170125171004/95/recurrent-neural-networks-i-d2l2-deep-learning-for-speech-and-language-upc-2017-34-638.jpg?cb=1485365064
  86. https://www.slideshare.net/xavigiro/recurrent-neural-networks-1-d2l2-deep-learning-for-speech-and-language-upc-2017#related-tab-content
  87. https://www.slideshare.net/xavigiro/recurrent-neural-networks-1-d2l2-deep-learning-for-speech-and-language-upc-2017
  88. https://es.slideshare.net/xavigiro/recurrent-neural-networks-1-d2l2-deep-learning-for-speech-and-language-upc-2017
  89. https://pt.slideshare.net/xavigiro/recurrent-neural-networks-1-d2l2-deep-learning-for-speech-and-language-upc-2017
  90. https://fr.slideshare.net/xavigiro/recurrent-neural-networks-1-d2l2-deep-learning-for-speech-and-language-upc-2017
  91. https://de.slideshare.net/xavigiro/recurrent-neural-networks-1-d2l2-deep-learning-for-speech-and-language-upc-2017
  92. https://www.slideshare.net/about
  93. https://www.slideshare.net/developers
  94. http://blog.slideshare.net/
  95. https://www.slideshare.net/terms
  96. https://www.slideshare.net/privacy
  97. http://www.linkedin.com/legal/copyright-policy
  98. https://www.linkedin.com/help/slideshare
  99. https://www.slideshare.net/xavigiro/recurrent-neural-networks-1-d2l2-deep-learning-for-speech-and-language-upc-2017
 100. https://www.slideshare.net/xavigiro/recurrent-neural-networks-1-d2l2-deep-learning-for-speech-and-language-upc-2017

   hidden links:
 102. https://www.slideshare.net/xavigiro/recurrent-neural-networks-1-d2l2-deep-learning-for-speech-and-language-upc-2017
 103. https://www.slideshare.net/signup?login_source=slideview.clip.like&from=clip&layout=foundation&from_source=
 104. https://www.slideshare.net/login?from_source=%2fxavigiro%2frecurrent-neural-networks-1-d2l2-deep-learning-for-speech-and-language-upc-2017%3ffrom_action%3dsave&from=download&layout=foundation
 105. https://www.slideshare.net/signup?login_source=slideview.popup.flags&from=flagss&from_source=https%3a%2f%2fwww.slideshare.net%2fxavigiro%2frecurrent-neural-networks-1-d2l2-deep-learning-for-speech-and-language-upc-2017
 106. https://www.linkedin.com/learning/creative-insights-renaldo-lawrence-on-elearning?trk=slideshare_sv_learning
 107. https://www.linkedin.com/learning/academic-research-foundations-quantitative?trk=slideshare_sv_learning
 108. https://www.linkedin.com/learning/teaching-complex-topics?trk=slideshare_sv_learning
 109. https://www.slideshare.net/taegyunjeon1/electricity-price-forecasting-with-recurrent-neural-networks
 110. https://www.slideshare.net/xavigiro/selfsupervised-audiovisual-learning-xavier-giro-upc-barcelona-2019
 111. https://www.slideshare.net/xavigiro/deep-video-object-tracking-xavier-giro-upc-barcelona-2019
 112. https://www.slideshare.net/xavigiro/selfsupervised-learning-from-video-sequences-xavier-giro-upc-barcelona-2019
 113. https://www.slideshare.net/xavigiro/deep-learning-architectures-for-video-xavier-giroinieto-upc-barcelona
 114. https://www.slideshare.net/xavigiro/deep-video-object-segmentation-xavier-giroinieto-upc-2019
 115. https://www.slideshare.net/xavigiro/wav2pix-speechconditioned-face-generation-using-generative-adversarial-networksa
 116. http://www.linkedin.com/company/linkedin
 117. http://www.facebook.com/linkedin
 118. http://twitter.com/slideshare
 119. http://www.google.com/+linkedin
 120. https://www.slideshare.net/rss/latest
