   #[1]rss [2]slideshare search [3]alternate [4]alternate [5]alternate
   [6]alternate [7]alternate [8]alternate [9]slideshow json oembed profile
   [10]slideshow xml oembed profile [11]alternate [12]alternate
   [13]alternate

   (button)

   slideshare uses cookies to improve functionality and performance, and
   to provide you with relevant advertising. if you continue browsing the
   site, you agree to the use of cookies on this website. see our [14]user
   agreement and [15]privacy policy.

   slideshare uses cookies to improve functionality and performance, and
   to provide you with relevant advertising. if you continue browsing the
   site, you agree to the use of cookies on this website. see our
   [16]privacy policy and [17]user agreement for details.

   [18]slideshare [19]explore search [20]you

     * [21]linkedin slideshare

     * [22]upload
     * [23]login
     * [24]signup

     *
     * ____________________ (button) submit search

     * [25]home
     * [26]explore

     * [27]presentation courses
     * [28]powerpoint courses
     *
     * by [29]linkedin learning

   ____________________
   successfully reported this slideshow.

   we use your linkedin profile and activity data to personalize ads and
   to show you more relevant ads. [30]you can change your ad preferences
   anytime.
   language model (d3l1 deep learning for speech and language upc 2017)

   [course site] day 3 lecture 1 language model marta r. costa-juss  

   2 previous concepts from this course     id27s     feed-forward
   network and softmax     recurrent neural network (hand...

   3 what is the most probable sentence? two birds are flying two beards
   are flying

   id203 of a sentence            

   5 a language model finds the id203 of a sentence     given a
   sentence (w1, w2,     wt),     what is p(w1, w2, . . . ,wt) =?

   an id165 language model

   chain rule id203 and markov simplifying assumption p(w1, w2, . .
   . ,wt) = p(wt|w(t-1),w(t-2)...w1) p(w(t-1)|w(t-2),w...

   objective

   9 an id165-based language model            

   10 an id165-based language model

   any issues with the above model?

   some examples... "<s> que la fuerza te acompa  e </s>", = may the force
   be with you bigrams and trigrams like: fuerza te la...

   13 sparse counts are a big problem     backing off avoids zero
   probabilities

   14 sparse counts are a big problem     smoothing avoids zero
   probabilities

   any other issue?

   16 lack of generalization

   a neural language model to generalize to un-seen id165s

   18 a neural language model find a function that takes as input n-1
   words and returns a id155 of the next...

   architecture: neural language model w_(t-1) w_(t-2) w_(t-n) figure: k.
   cho, dl4mt course, 2015

   figure: k. cho, dl4mt course, 2015 architecture: representation of
   input words our goal is to put the least amount of prio...

   word one-hot encoding economic 000010... growth 001000... has 100000...
   slowed 000001... step 1: one-hot encoding natural ...

   architecture: continuous word representation input vectors are
   multiplied by the weight matrix (e), to obtain continuous v...

   architecture: context vector we get a sequence of continuous vectors,
   by concatenating the continuous representations of t...

   architecture: nonlinear projection the context vector is fed through
   one or several transformation layers (which extract f...

   architecture: output id203 distribution lm has a categorical
   distribution, where the id203 of the k-th event h...

   why this model is generalizing to unseen events?

   27 further generalization comes from embeddings two three

   recurrent language model to further generalize to un-seen id165s

   29 a neural language model still assumes the n-th order markov property
   it looks only as n-1 past words in france , there ...

   30 how we can modelate variable-length input?

   31 how we can modelate variable-length input? we directly model the
   original conditional probabilities via recursion: summ...

   32 how we can modelate variable-length input? we directly model the
   original conditional probabilities via recursion: summ...

   33 example p(mary, buys, the,apple) (1) intialization: h0=0 ->
   p(mary)=g(h0) (2) recursion (a) h1=f(h0,mary) ->p(buys|mary...

   34 a recurrent neural language model can modelate the id203 of a
   variable-length input sequence conditional probabil...

   35 a recurrent neural language model what we need (1) transition
   function (2) output function

   36 (naive) transition function inputs: one-hot vector + hidden state
   parameters: input weight matrix + transition weight m...

   37 (naive) transition function continuous-space representation of word
   linear transformation of the previous hidden state ...

   38 output function input: hidden state (ht) parameters: output matrix
   bias vector (c)

   39 output function this summary vector is affine-transformed followed
   by a softmax nonlinear function to compute the condi...

   measure to evaluate perplexity

   41 perplexity: a measure to evaluate id38 perplexity
   measures how high a id203 the language model assig...

   42 comparing language models lm hidden layers ppl id165-based 131.2
   +feed-forward 600 112.5 +id56 600 108.1 +lstm 600 92.0...

   43 applications of id38 id103 machine
   translation handwriting recognition information retrieval ...

   44 a bad language model

   45 summary     id38 consists in assigning a id203 to a
   sequence of words.     we can model a sequence of wo...

   46 learn more yoshua bengio, r  jean ducharme, pascal vincent, and
   christian janvin. 2003. a neural probabilistic language ...

   thanks ! q&a ? https://www.costa-jussa.com

   architecture: neural language model

   language model (d3l1 deep learning for speech and language upc 2017)
   upcoming slideshare
   []
   loading in    5
     
   [] 1
   (button)
   1 of 49 (button)
   (button) (button)
   like this presentation? why not share!
     * share
     * email
     *
     *

     * [31]id103 with deep neural... id103 with
       deep neural... by universitat polit... 5777 views
     * [32]end-to-end id103 with ... end-to-end speech
       recognition with ... by universitat polit... 6937 views
     * [33]recurrent neural networks ii (d2l3 ... recurrent neural
       networks ii (d2l3 ... by universitat polit... 2189 views
     * [34]id27s (d2l4 deep learning... id27s (d2l4
       deep learning... by universitat polit... 1013 views
     * [35]recurrent neural networks i (d2l2 d... recurrent neural
       networks i (d2l2 d... by universitat polit... 1576 views
     * [36]speaker id ii (d4l1 deep learning f... speaker id ii (d4l1 deep
       learning f... by universitat polit... 845 views

   (button)

   share slideshare
     __________________________________________________________________

     * [37]facebook
     * [38]twitter
     * [39]linkedin

   embed
   ____________________________________________________________
   ____________________________________________________________
   ____________________________________________________________
   ____________________________________________________________
   size (px)
   start on
   [x] show related slideshares at end
   wordpress shortcode ____________________
   link ____________________

language model (d3l1 deep learning for speech and language upc 2017)

   816 views

     * (button) share
     * (button) like
     * (button) download
     * ...
          +

   [40]universitat polit  cnica de catalunya

[41]universitat polit  cnica de catalunya

   [42]follow

   (button) (button) (button)

   published on jan 27, 2017

   https://telecombcn-dl.github.io/2017-dlsl/
   winter school on deep learning for speech and language. upc
   barcelonatech etsetb telecombcn.
   the aim of this course is to train students in methods of deep learning
   for speech and language. recurrent neural networks (id56) will be
   presented and analyzed in detail to understand the potential of these
   state of the art tools for time series processing. engineering tips and
   scalability issues will be addressed to solve tasks such as machine
   translation, id103, id133 or question
   answering. hands-on sessions will provide development skills so that
   attendees can become competent in contemporary data analytics tools.
   (button) ...

   published in: [43]data & analytics

     * [44]0 comments
     * [45]0 likes
     * [46]statistics
     * [47]notes

     * full name
       full name
       comment goes here.
       12 hours ago   [48]delete [49]reply [50]block
       are you sure you want to [51]yes [52]no
       your message goes here

   no profile picture user
   ____________________
   [53](button) post
     * be the first to comment

     * be the first to like this

   no downloads
   views
   total views
   816
   on slideshare
   0
   from embeds
   0
   number of embeds
   0
   actions
   shares
   0
   downloads
   113
   comments
   0
   likes
   0
   embeds 0
   no embeds
   no notes for slide

language model (d3l1 deep learning for speech and language upc 2017)

    1. 1. [course site] day 3 lecture 1 language model marta r.
       costa-juss  
    2. [54]2. 2 previous concepts from this course     id27s    
       feed-forward network and softmax     recurrent neural network (handle
       variable-length sequences)
    3. [55]3. 3 what is the most probable sentence? two birds are flying
       two beards are flying
    4. [56]4. id203 of a sentence            
    5. [57]5. 5 a language model finds the id203 of a sentence    
       given a sentence (w1, w2,     wt),     what is p(w1, w2, . . . ,wt) =?
    6. [58]6. an id165 language model
    7. [59]7. chain rule id203 and markov simplifying assumption
       p(w1, w2, . . . ,wt) = p(wt|w(t-1),w(t-2)...w1)
       p(w(t-1)|w(t-2),w(t-3)...w1)     p(w1) markov simplying assumption:
       the current word only depends on n previous words.
       p(wt|w(t-1)w(t-2)..w1) ~ p(wt|w(t-1))
    8. [60]8. objective
    9. [61]9. 9 an id165-based language model            
   10. [62]10. 10 an id165-based language model
   11. [63]11. any issues with the above model?
   12. [64]12. some examples... "<s> que la fuerza te acompa  e </s>", =
       may the force be with you bigrams and trigrams like: fuerza te la
       fuerza te fuerza te acompa  e te acompa  e </s> do not appear in the
       big corpus of el periodico (40 m words) but id203 of the
       sentence should not be zero!!!!
   13. [65]13. 13 sparse counts are a big problem     backing off avoids
       zero probabilities
   14. [66]14. 14 sparse counts are a big problem     smoothing avoids zero
       probabilities
   15. [67]15. any other issue?
   16. [68]16. 16 lack of generalization
   17. [69]17. a neural language model to generalize to un-seen id165s
   18. [70]18. 18 a neural language model find a function that takes as
       input n-1 words and returns a id155 of the next
       one
   19. [71]19. architecture: neural language model w_(t-1) w_(t-2) w_(t-n)
       figure: k. cho, dl4mt course, 2015
   20. [72]20. figure: k. cho, dl4mt course, 2015 architecture:
       representation of input words our goal is to put the least amount
       of prior knowledge
   21. [73]21. word one-hot encoding economic 000010... growth 001000...
       has 100000... slowed 000001... step 1: one-hot encoding natural
       language words can be one-hot encoded on a vector of dimensionality
       equal to the size of the dictionary (k=|v|). from previous lectures
   22. [74]22. architecture: continuous word representation input vectors
       are multiplied by the weight matrix (e), to obtain continuous
       vectors this weight matrix (e) is also called id27 and
       should reflect the meaning of a word figure: k. cho, dl4mt course,
       2015
   23. [75]23. architecture: context vector we get a sequence of
       continuous vectors, by concatenating the continuous representations
       of the input words context vector figure: k. cho, dl4mt course,
       2015
   24. [76]24. architecture: nonlinear projection the context vector is
       fed through one or several transformation layers (which extract
       features), here, just we used a simple transformation layer, with w
       and b as parameters figure: k. cho, dl4mt course, 2015
   25. [77]25. architecture: output id203 distribution lm has a
       categorical distribution, where the id203 of the k-th event
       happening is denoted as the function needs to return a
       k-dimensional vector and corresponds to the id203 of the i-th
       word in the vocabulary for the next wordfigure: k. cho, dl4mt
       course, 2015
   26. [78]26. why this model is generalizing to unseen events?
   27. [79]27. 27 further generalization comes from embeddings two three
   28. [80]28. recurrent language model to further generalize to un-seen
       id165s
   29. [81]29. 29 a neural language model still assumes the n-th order
       markov property it looks only as n-1 past words in france , there
       are around 66 million people and they speak french.
   30. [82]30. 30 how we can modelate variable-length input?
   31. [83]31. 31 how we can modelate variable-length input? we directly
       model the original conditional probabilities via recursion:
       summarizes the history from w1 to w(t-1) initial condition
       recursion
   32. [84]32. 32 how we can modelate variable-length input? we directly
       model the original conditional probabilities via recursion:
       summarizes the history from w1 to w(t-1) initial condition
       recursion the id56 is capable of summarizing a variable-length input
       sequence (w) into a memory state (h)
   33. [85]33. 33 example p(mary, buys, the,apple) (1) intialization: h0=0
       -> p(mary)=g(h0) (2) recursion (a) h1=f(h0,mary)
       ->p(buys|mary)=g(h1) (b) h2=f(h1,buys) -> p(the|mary,buys)=g(h2)
       (c) h3=f(h2,the) -> p(apple|mary,buys,the)=g(h3) (3) output:
       p(mary,buys,the,apple)=g(h0)g(h1)g(h2)g(h3) it works for any number
       of context words read, update, predict
   34. [86]34. 34 a recurrent neural language model can modelate the
       id203 of a variable-length input sequence conditional
       id203 that we want to compute
   35. [87]35. 35 a recurrent neural language model what we need (1)
       transition function (2) output function
   36. [88]36. 36 (naive) transition function inputs: one-hot vector +
       hidden state parameters: input weight matrix + transition weight
       matrix + bias vector (b)
   37. [89]37. 37 (naive) transition function continuous-space
       representation of word linear transformation of the previous hidden
       state nonlinear transformation
   38. [90]38. 38 output function input: hidden state (ht) parameters:
       output matrix bias vector (c)
   39. [91]39. 39 output function this summary vector is
       affine-transformed followed by a softmax nonlinear function to
       compute the id155 of each word.
   40. [92]40. measure to evaluate perplexity
   41. [93]41. 41 perplexity: a measure to evaluate id38
       perplexity measures how high a id203 the language model
       assigns to correct next words in the test corpus    on average   . a
       better language model is the one with a lower perplexity.
       perplexity measures as well how complex is a task equals size of
       vocabulary (v) pp=v
   42. [94]42. 42 comparing language models lm hidden layers ppl
       id165-based 131.2 +feed-forward 600 112.5 +id56 600 108.1 +lstm 600
       92.0 results from sundermeyer et al, 2015
   43. [95]43. 43 applications of id38 id103
       machine translation handwriting recognition information retrieval
       ...
   44. [96]44. 44 a bad language model
   45. [97]45. 45 summary     id38 consists in assigning a
       id203 to a sequence of words.     we can model a sequence of
       words with id165s, feed -forward networks and recurrent networks.
           feed-forward networks are able to generalise unseen contexts    
       id56 are able to use variable contexts
   46. [98]46. 46 learn more yoshua bengio, r  jean ducharme, pascal
       vincent, and christian janvin. 2003. a neural probabilistic
       language model. j. mach. learn. res. 3 (march 2003), 1137-1155.
       martin sundermeyer, hermann ney, and ralf schl  ter. 2015. from
       feedforward to recurrent lstm neural networks for language
       modeling. ieee/acm trans. audio, speech and lang. proc. 23, 3
       (march 2015), 517-529.
       doi=http://dx.doi.org/10.1109/taslp.2015.2400218
   47. [99]47. thanks ! q&a ? https://www.costa-jussa.com
   48. [100]48. architecture: neural language model

          [101]recommended

     * communication in the 21st century classroom
       communication in the 21st century classroom
       online course - linkedin learning
     * teaching techniques: classroom cloud strategy
       teaching techniques: classroom cloud strategy
       online course - linkedin learning
     * time management tips weekly
       time management tips weekly
       online course - linkedin learning
     * id103 with deep neural networks (d3l2 deep learning
       for speech and language upc 2017)
       id103 with deep neural networks (d3l2 deep learning
       for speech a...
       universitat polit  cnica de catalunya
     * end-to-end id103 with recurrent neural networks (d3l6
       deep learning for speech and language upc 2017)
       end-to-end id103 with recurrent neural networks (d3l6
       deep learn...
       universitat polit  cnica de catalunya
     * recurrent neural networks ii (d2l3 deep learning for speech and
       language upc 2017)
       recurrent neural networks ii (d2l3 deep learning for speech and
       language upc ...
       universitat polit  cnica de catalunya
     * id27s (d2l4 deep learning for speech and language upc
       2017)
       id27s (d2l4 deep learning for speech and language upc
       2017)
       universitat polit  cnica de catalunya
     * recurrent neural networks i (d2l2 deep learning for speech and
       language upc 2017)
       recurrent neural networks i (d2l2 deep learning for speech and
       language upc 2...
       universitat polit  cnica de catalunya
     * speaker id ii (d4l1 deep learning for speech and language upc 2017)
       speaker id ii (d4l1 deep learning for speech and language upc 2017)
       universitat polit  cnica de catalunya
     * advanced id4 (d4l2 deep learning for speech
       and language upc 2017)
       advanced id4 (d4l2 deep learning for speech
       and langua...
       universitat polit  cnica de catalunya

     * [102]english
     * [103]espa  ol
     * [104]portugu  s
     * [105]fran  ais
     * [106]deutsch

     * [107]about
     * [108]dev & api
     * [109]blog
     * [110]terms
     * [111]privacy
     * [112]copyright
     * [113]support

     *
     *
     *
     *
     *

   linkedin corporation    2019

     

share clipboard
     __________________________________________________________________

   [114]  
     * facebook
     * twitter
     * linkedin

   link ____________________

public clipboards featuring this slide
     __________________________________________________________________

   (button)   
   no public clipboards found for this slide

select another clipboard
     __________________________________________________________________

   [115]  

   looks like you   ve clipped this slide to already.
   ____________________

   create a clipboard

you just clipped your first slide!

   clipping is a handy way to collect important slides you want to go back
   to later. now customize the name of a clipboard to store your clips.
     __________________________________________________________________

   name* ____________________
   description ____________________
   visibility
   others can see my clipboard [ ]
   (button) cancel (button) save

   bizographics tracking image

references

   visible links
   1. https://www.slideshare.net/rss/latest
   2. https://www.slideshare.net/opensearch.xml
   3. https://www.slideshare.net/xavigiro/language-model-d3l1-deep-learning-for-speech-and-language-upc-2017
   4. https://es.slideshare.net/xavigiro/language-model-d3l1-deep-learning-for-speech-and-language-upc-2017
   5. https://fr.slideshare.net/xavigiro/language-model-d3l1-deep-learning-for-speech-and-language-upc-2017
   6. https://de.slideshare.net/xavigiro/language-model-d3l1-deep-learning-for-speech-and-language-upc-2017
   7. https://pt.slideshare.net/xavigiro/language-model-d3l1-deep-learning-for-speech-and-language-upc-2017
   8. https://www.slideshare.net/xavigiro/language-model-d3l1-deep-learning-for-speech-and-language-upc-2017
   9. https://www.slideshare.net/api/oembed/2?format=json&url=http://www.slideshare.net/xavigiro/language-model-d3l1-deep-learning-for-speech-and-language-upc-2017
  10. https://www.slideshare.net/api/oembed/2?format=xml&url=http://www.slideshare.net/xavigiro/language-model-d3l1-deep-learning-for-speech-and-language-upc-2017
  11. https://www.slideshare.net/mobile/xavigiro/language-model-d3l1-deep-learning-for-speech-and-language-upc-2017
  12. android-app://net.slideshare.mobile/slideshare-app/ss/71471039
  13. ios-app://917418728/slideshare-app/ss/71471039
  14. http://www.linkedin.com/legal/user-agreement
  15. http://www.linkedin.com/legal/privacy-policy
  16. http://www.linkedin.com/legal/privacy-policy
  17. http://www.linkedin.com/legal/user-agreement
  18. https://www.slideshare.net/
  19. https://www.slideshare.net/explore
  20. https://www.slideshare.net/login
  21. https://www.slideshare.net/
  22. https://www.slideshare.net/upload
  23. https://www.slideshare.net/login
  24. https://www.slideshare.net/w/signup
  25. https://www.slideshare.net/
  26. https://www.slideshare.net/explore
  27. https://www.linkedin.com/learning/topics/presentations?trk=slideshare_subnav_learning&entitytype=course&sortby=recency
  28. https://www.linkedin.com/learning/topics/powerpoint?trk=slideshare_subnav_learning&entitytype=course&sortby=recency
  29. https://www.linkedin.com/learning?trk=slideshare_subnav_learning
  30. https://www.linkedin.com/psettings/privacy
  31. https://public.slidesharecdn.com/xavigiro/speech-recognition-with-deep-neural-networks-d3l2-deep-learning-for-speech-and-language-upc-2017
  32. https://public.slidesharecdn.com/xavigiro/endtoend-speech-recognition-with-recurrent-neural-networks-d3l6-deep-learning-for-speech-and-language-upc-2017
  33. https://public.slidesharecdn.com/xavigiro/recurrent-neural-networks-2-d2l3-deep-learning-for-speech-and-language-upc-2017
  34. https://public.slidesharecdn.com/xavigiro/word-embeddings-d2l4-deep-learning-for-speech-and-language-upc-2017
  35. https://public.slidesharecdn.com/xavigiro/recurrent-neural-networks-1-d2l2-deep-learning-for-speech-and-language-upc-2017
  36. https://public.slidesharecdn.com/xavigiro/speaker-id-ii-d4l1-deep-learning-for-speech-and-language-upc-2017
  37. https://www.slideshare.net/xavigiro/language-model-d3l1-deep-learning-for-speech-and-language-upc-2017
  38. https://www.slideshare.net/xavigiro/language-model-d3l1-deep-learning-for-speech-and-language-upc-2017
  39. https://www.slideshare.net/xavigiro/language-model-d3l1-deep-learning-for-speech-and-language-upc-2017
  40. https://www.slideshare.net/xavigiro?utm_campaign=profiletracking&utm_medium=sssite&utm_source=ssslideview
  41. https://www.slideshare.net/xavigiro?utm_campaign=profiletracking&utm_medium=sssite&utm_source=ssslideview
  42. https://www.slideshare.net/signup?login_source=slideview.popup.follow&from=addcontact&from_source=https://www.slideshare.net/xavigiro/language-model-d3l1-deep-learning-for-speech-and-language-upc-2017
  43. https://www.slideshare.net/featured/category/data-analytics
  44. https://www.slideshare.net/xavigiro/language-model-d3l1-deep-learning-for-speech-and-language-upc-2017#comments-panel
  45. https://www.slideshare.net/xavigiro/language-model-d3l1-deep-learning-for-speech-and-language-upc-2017#likes-panel
  46. https://www.slideshare.net/xavigiro/language-model-d3l1-deep-learning-for-speech-and-language-upc-2017#stats-panel
  47. https://www.slideshare.net/xavigiro/language-model-d3l1-deep-learning-for-speech-and-language-upc-2017#notes-panel
  48. https://www.slideshare.net/xavigiro/language-model-d3l1-deep-learning-for-speech-and-language-upc-2017
  49. https://www.slideshare.net/xavigiro/language-model-d3l1-deep-learning-for-speech-and-language-upc-2017
  50. https://www.slideshare.net/xavigiro/language-model-d3l1-deep-learning-for-speech-and-language-upc-2017
  51. https://www.slideshare.net/xavigiro/language-model-d3l1-deep-learning-for-speech-and-language-upc-2017
  52. https://www.slideshare.net/xavigiro/language-model-d3l1-deep-learning-for-speech-and-language-upc-2017
  53. https://www.slideshare.net/signup?login_source=slideview.popup.comment&from=comments&from_source=https://www.slideshare.net/xavigiro/language-model-d3l1-deep-learning-for-speech-and-language-upc-2017
  54. https://image.slidesharecdn.com/dlsl2017d3l1languagemodel-170127183702/95/language-model-d3l1-deep-learning-for-speech-and-language-upc-2017-2-638.jpg?cb=1485542415
  55. https://image.slidesharecdn.com/dlsl2017d3l1languagemodel-170127183702/95/language-model-d3l1-deep-learning-for-speech-and-language-upc-2017-3-638.jpg?cb=1485542415
  56. https://image.slidesharecdn.com/dlsl2017d3l1languagemodel-170127183702/95/language-model-d3l1-deep-learning-for-speech-and-language-upc-2017-4-638.jpg?cb=1485542415
  57. https://image.slidesharecdn.com/dlsl2017d3l1languagemodel-170127183702/95/language-model-d3l1-deep-learning-for-speech-and-language-upc-2017-5-638.jpg?cb=1485542415
  58. https://image.slidesharecdn.com/dlsl2017d3l1languagemodel-170127183702/95/language-model-d3l1-deep-learning-for-speech-and-language-upc-2017-6-638.jpg?cb=1485542415
  59. https://image.slidesharecdn.com/dlsl2017d3l1languagemodel-170127183702/95/language-model-d3l1-deep-learning-for-speech-and-language-upc-2017-7-638.jpg?cb=1485542415
  60. https://image.slidesharecdn.com/dlsl2017d3l1languagemodel-170127183702/95/language-model-d3l1-deep-learning-for-speech-and-language-upc-2017-8-638.jpg?cb=1485542415
  61. https://image.slidesharecdn.com/dlsl2017d3l1languagemodel-170127183702/95/language-model-d3l1-deep-learning-for-speech-and-language-upc-2017-9-638.jpg?cb=1485542415
  62. https://image.slidesharecdn.com/dlsl2017d3l1languagemodel-170127183702/95/language-model-d3l1-deep-learning-for-speech-and-language-upc-2017-10-638.jpg?cb=1485542415
  63. https://image.slidesharecdn.com/dlsl2017d3l1languagemodel-170127183702/95/language-model-d3l1-deep-learning-for-speech-and-language-upc-2017-11-638.jpg?cb=1485542415
  64. https://image.slidesharecdn.com/dlsl2017d3l1languagemodel-170127183702/95/language-model-d3l1-deep-learning-for-speech-and-language-upc-2017-12-638.jpg?cb=1485542415
  65. https://image.slidesharecdn.com/dlsl2017d3l1languagemodel-170127183702/95/language-model-d3l1-deep-learning-for-speech-and-language-upc-2017-13-638.jpg?cb=1485542415
  66. https://image.slidesharecdn.com/dlsl2017d3l1languagemodel-170127183702/95/language-model-d3l1-deep-learning-for-speech-and-language-upc-2017-14-638.jpg?cb=1485542415
  67. https://image.slidesharecdn.com/dlsl2017d3l1languagemodel-170127183702/95/language-model-d3l1-deep-learning-for-speech-and-language-upc-2017-15-638.jpg?cb=1485542415
  68. https://image.slidesharecdn.com/dlsl2017d3l1languagemodel-170127183702/95/language-model-d3l1-deep-learning-for-speech-and-language-upc-2017-16-638.jpg?cb=1485542415
  69. https://image.slidesharecdn.com/dlsl2017d3l1languagemodel-170127183702/95/language-model-d3l1-deep-learning-for-speech-and-language-upc-2017-17-638.jpg?cb=1485542415
  70. https://image.slidesharecdn.com/dlsl2017d3l1languagemodel-170127183702/95/language-model-d3l1-deep-learning-for-speech-and-language-upc-2017-18-638.jpg?cb=1485542415
  71. https://image.slidesharecdn.com/dlsl2017d3l1languagemodel-170127183702/95/language-model-d3l1-deep-learning-for-speech-and-language-upc-2017-19-638.jpg?cb=1485542415
  72. https://image.slidesharecdn.com/dlsl2017d3l1languagemodel-170127183702/95/language-model-d3l1-deep-learning-for-speech-and-language-upc-2017-20-638.jpg?cb=1485542415
  73. https://image.slidesharecdn.com/dlsl2017d3l1languagemodel-170127183702/95/language-model-d3l1-deep-learning-for-speech-and-language-upc-2017-21-638.jpg?cb=1485542415
  74. https://image.slidesharecdn.com/dlsl2017d3l1languagemodel-170127183702/95/language-model-d3l1-deep-learning-for-speech-and-language-upc-2017-22-638.jpg?cb=1485542415
  75. https://image.slidesharecdn.com/dlsl2017d3l1languagemodel-170127183702/95/language-model-d3l1-deep-learning-for-speech-and-language-upc-2017-23-638.jpg?cb=1485542415
  76. https://image.slidesharecdn.com/dlsl2017d3l1languagemodel-170127183702/95/language-model-d3l1-deep-learning-for-speech-and-language-upc-2017-24-638.jpg?cb=1485542415
  77. https://image.slidesharecdn.com/dlsl2017d3l1languagemodel-170127183702/95/language-model-d3l1-deep-learning-for-speech-and-language-upc-2017-25-638.jpg?cb=1485542415
  78. https://image.slidesharecdn.com/dlsl2017d3l1languagemodel-170127183702/95/language-model-d3l1-deep-learning-for-speech-and-language-upc-2017-26-638.jpg?cb=1485542415
  79. https://image.slidesharecdn.com/dlsl2017d3l1languagemodel-170127183702/95/language-model-d3l1-deep-learning-for-speech-and-language-upc-2017-27-638.jpg?cb=1485542415
  80. https://image.slidesharecdn.com/dlsl2017d3l1languagemodel-170127183702/95/language-model-d3l1-deep-learning-for-speech-and-language-upc-2017-28-638.jpg?cb=1485542415
  81. https://image.slidesharecdn.com/dlsl2017d3l1languagemodel-170127183702/95/language-model-d3l1-deep-learning-for-speech-and-language-upc-2017-29-638.jpg?cb=1485542415
  82. https://image.slidesharecdn.com/dlsl2017d3l1languagemodel-170127183702/95/language-model-d3l1-deep-learning-for-speech-and-language-upc-2017-30-638.jpg?cb=1485542415
  83. https://image.slidesharecdn.com/dlsl2017d3l1languagemodel-170127183702/95/language-model-d3l1-deep-learning-for-speech-and-language-upc-2017-31-638.jpg?cb=1485542415
  84. https://image.slidesharecdn.com/dlsl2017d3l1languagemodel-170127183702/95/language-model-d3l1-deep-learning-for-speech-and-language-upc-2017-32-638.jpg?cb=1485542415
  85. https://image.slidesharecdn.com/dlsl2017d3l1languagemodel-170127183702/95/language-model-d3l1-deep-learning-for-speech-and-language-upc-2017-33-638.jpg?cb=1485542415
  86. https://image.slidesharecdn.com/dlsl2017d3l1languagemodel-170127183702/95/language-model-d3l1-deep-learning-for-speech-and-language-upc-2017-34-638.jpg?cb=1485542415
  87. https://image.slidesharecdn.com/dlsl2017d3l1languagemodel-170127183702/95/language-model-d3l1-deep-learning-for-speech-and-language-upc-2017-35-638.jpg?cb=1485542415
  88. https://image.slidesharecdn.com/dlsl2017d3l1languagemodel-170127183702/95/language-model-d3l1-deep-learning-for-speech-and-language-upc-2017-36-638.jpg?cb=1485542415
  89. https://image.slidesharecdn.com/dlsl2017d3l1languagemodel-170127183702/95/language-model-d3l1-deep-learning-for-speech-and-language-upc-2017-37-638.jpg?cb=1485542415
  90. https://image.slidesharecdn.com/dlsl2017d3l1languagemodel-170127183702/95/language-model-d3l1-deep-learning-for-speech-and-language-upc-2017-38-638.jpg?cb=1485542415
  91. https://image.slidesharecdn.com/dlsl2017d3l1languagemodel-170127183702/95/language-model-d3l1-deep-learning-for-speech-and-language-upc-2017-39-638.jpg?cb=1485542415
  92. https://image.slidesharecdn.com/dlsl2017d3l1languagemodel-170127183702/95/language-model-d3l1-deep-learning-for-speech-and-language-upc-2017-40-638.jpg?cb=1485542415
  93. https://image.slidesharecdn.com/dlsl2017d3l1languagemodel-170127183702/95/language-model-d3l1-deep-learning-for-speech-and-language-upc-2017-41-638.jpg?cb=1485542415
  94. https://image.slidesharecdn.com/dlsl2017d3l1languagemodel-170127183702/95/language-model-d3l1-deep-learning-for-speech-and-language-upc-2017-42-638.jpg?cb=1485542415
  95. https://image.slidesharecdn.com/dlsl2017d3l1languagemodel-170127183702/95/language-model-d3l1-deep-learning-for-speech-and-language-upc-2017-43-638.jpg?cb=1485542415
  96. https://image.slidesharecdn.com/dlsl2017d3l1languagemodel-170127183702/95/language-model-d3l1-deep-learning-for-speech-and-language-upc-2017-44-638.jpg?cb=1485542415
  97. https://image.slidesharecdn.com/dlsl2017d3l1languagemodel-170127183702/95/language-model-d3l1-deep-learning-for-speech-and-language-upc-2017-45-638.jpg?cb=1485542415
  98. https://image.slidesharecdn.com/dlsl2017d3l1languagemodel-170127183702/95/language-model-d3l1-deep-learning-for-speech-and-language-upc-2017-46-638.jpg?cb=1485542415
  99. https://image.slidesharecdn.com/dlsl2017d3l1languagemodel-170127183702/95/language-model-d3l1-deep-learning-for-speech-and-language-upc-2017-47-638.jpg?cb=1485542415
 100. https://image.slidesharecdn.com/dlsl2017d3l1languagemodel-170127183702/95/language-model-d3l1-deep-learning-for-speech-and-language-upc-2017-48-638.jpg?cb=1485542415
 101. https://www.slideshare.net/xavigiro/language-model-d3l1-deep-learning-for-speech-and-language-upc-2017#related-tab-content
 102. https://www.slideshare.net/xavigiro/language-model-d3l1-deep-learning-for-speech-and-language-upc-2017
 103. https://es.slideshare.net/xavigiro/language-model-d3l1-deep-learning-for-speech-and-language-upc-2017
 104. https://pt.slideshare.net/xavigiro/language-model-d3l1-deep-learning-for-speech-and-language-upc-2017
 105. https://fr.slideshare.net/xavigiro/language-model-d3l1-deep-learning-for-speech-and-language-upc-2017
 106. https://de.slideshare.net/xavigiro/language-model-d3l1-deep-learning-for-speech-and-language-upc-2017
 107. https://www.slideshare.net/about
 108. https://www.slideshare.net/developers
 109. http://blog.slideshare.net/
 110. https://www.slideshare.net/terms
 111. https://www.slideshare.net/privacy
 112. http://www.linkedin.com/legal/copyright-policy
 113. https://www.linkedin.com/help/slideshare
 114. https://www.slideshare.net/xavigiro/language-model-d3l1-deep-learning-for-speech-and-language-upc-2017
 115. https://www.slideshare.net/xavigiro/language-model-d3l1-deep-learning-for-speech-and-language-upc-2017

   hidden links:
 117. https://www.slideshare.net/xavigiro/language-model-d3l1-deep-learning-for-speech-and-language-upc-2017
 118. https://www.slideshare.net/signup?login_source=slideview.clip.like&from=clip&layout=foundation&from_source=
 119. https://www.slideshare.net/login?from_source=%2fxavigiro%2flanguage-model-d3l1-deep-learning-for-speech-and-language-upc-2017%3ffrom_action%3dsave&from=download&layout=foundation
 120. https://www.slideshare.net/signup?login_source=slideview.popup.flags&from=flagss&from_source=https%3a%2f%2fwww.slideshare.net%2fxavigiro%2flanguage-model-d3l1-deep-learning-for-speech-and-language-upc-2017
 121. https://www.linkedin.com/learning/communication-in-the-21st-century-classroom?trk=slideshare_sv_learning
 122. https://www.linkedin.com/learning/teaching-techniques-classroom-cloud-strategy?trk=slideshare_sv_learning
 123. https://www.linkedin.com/learning/time-management-tips-weekly?trk=slideshare_sv_learning
 124. https://www.slideshare.net/xavigiro/speech-recognition-with-deep-neural-networks-d3l2-deep-learning-for-speech-and-language-upc-2017
 125. https://www.slideshare.net/xavigiro/endtoend-speech-recognition-with-recurrent-neural-networks-d3l6-deep-learning-for-speech-and-language-upc-2017
 126. https://www.slideshare.net/xavigiro/recurrent-neural-networks-2-d2l3-deep-learning-for-speech-and-language-upc-2017
 127. https://www.slideshare.net/xavigiro/word-embeddings-d2l4-deep-learning-for-speech-and-language-upc-2017
 128. https://www.slideshare.net/xavigiro/recurrent-neural-networks-1-d2l2-deep-learning-for-speech-and-language-upc-2017
 129. https://www.slideshare.net/xavigiro/speaker-id-ii-d4l1-deep-learning-for-speech-and-language-upc-2017
 130. https://www.slideshare.net/xavigiro/advanced-neural-machine-translation-d4l2-deep-learning-for-speech-and-language-upc-2017
 131. http://www.linkedin.com/company/linkedin
 132. http://www.facebook.com/linkedin
 133. http://twitter.com/slideshare
 134. http://www.google.com/+linkedin
 135. https://www.slideshare.net/rss/latest
