tutorial on universal dependencies

conll shared task on ud parsing

joakim nivre1

daniel zeman2

filip ginter3

francis m. tyers45

1department of linguistics and philology, uppsala university, sweden

2institute of formal and applied linguistics, charles university, prague, czechia

3department of information technology, university of turku, finland

4giela ja kultuvrra instituhtta, uit norgga   rktala   universitehta, troms  , norway

5arvutiteaduse instituut, tartu   likool, estonia

id33 shared tasks

conll 2006 (13 langs: ar, cs, bg, da, de, es, ja, nl, pt, sl, sv, tr, zh)
conll 2007 (10 langs: ar, ca, cs, el, en, eu, hu, it, tr, zh)

1

id33 shared tasks

conll 2006 (13 langs: ar, cs, bg, da, de, es, ja, nl, pt, sl, sv, tr, zh)
conll 2007 (10 langs: ar, ca, cs, el, en, eu, hu, it, tr, zh)
conll 2008: + semantic dependencies (english)
conll 2009: + semantic dependencies (ca, cs, de, en, es, ja, zh)

1

id33 shared tasks

conll 2006 (13 langs: ar, cs, bg, da, de, es, ja, nl, pt, sl, sv, tr, zh)
conll 2007 (10 langs: ar, ca, cs, el, en, eu, hu, it, tr, zh)
conll 2008: + semantic dependencies (english)
conll 2009: + semantic dependencies (ca, cs, de, en, es, ja, zh)
icon 2009 (hindi, bangla, telugu)
icon 2010 (hindi, bangla, telugu)

1

id33 shared tasks

conll 2006 (13 langs: ar, cs, bg, da, de, es, ja, nl, pt, sl, sv, tr, zh)
conll 2007 (10 langs: ar, ca, cs, el, en, eu, hu, it, tr, zh)
conll 2008: + semantic dependencies (english)
conll 2009: + semantic dependencies (ca, cs, de, en, es, ja, zh)
icon 2009 (hindi, bangla, telugu)
icon 2010 (hindi, bangla, telugu)
spmrl 2013 (9 languages: ar, de, eu, fr, he, hu, ko, pl, sv)
spmrl 2014 (9 languages: ar, de, eu, fr, he, hu, ko, pl, sv)

1

id33 shared tasks

conll 2006 (13 langs: ar, cs, bg, da, de, es, ja, nl, pt, sl, sv, tr, zh)
conll 2007 (10 langs: ar, ca, cs, el, en, eu, hu, it, tr, zh)
conll 2008: + semantic dependencies (english)
conll 2009: + semantic dependencies (ca, cs, de, en, es, ja, zh)
icon 2009 (hindi, bangla, telugu)
icon 2010 (hindi, bangla, telugu)
spmrl 2013 (9 languages: ar, de, eu, fr, he, hu, ko, pl, sv)
spmrl 2014 (9 languages: ar, de, eu, fr, he, hu, ko, pl, sv)
vardial 2017 (cross-lingual: cs-sk, sl-hr, da/sv-no)

1

id33 shared tasks

conll 2006 (13 langs: ar, cs, bg, da, de, es, ja, nl, pt, sl, sv, tr, zh)
conll 2007 (10 langs: ar, ca, cs, el, en, eu, hu, it, tr, zh)
conll 2008: + semantic dependencies (english)
conll 2009: + semantic dependencies (ca, cs, de, en, es, ja, zh)
icon 2009 (hindi, bangla, telugu)
icon 2010 (hindi, bangla, telugu)
spmrl 2013 (9 languages: ar, de, eu, fr, he, hu, ko, pl, sv)
spmrl 2014 (9 languages: ar, de, eu, fr, he, hu, ko, pl, sv)
vardial 2017 (cross-lingual: cs-sk, sl-hr, da/sv-no)
conll 2017 (45 languages + surprise + end-to-end parsing)

1

languages and treebanks

all ud 2.0 treebanks except:

too small
non-free

2

languages and treebanks

all ud 2.0 treebanks except:

too small
non-free

arabic nyuad: not available free of charge

2

languages and treebanks

all ud 2.0 treebanks except:

too small
non-free

arabic nyuad: not available free of charge
at least 10k test words )

exclude: belarusian, coptic, lithuanian, sanskrit, tamil
include but small training: french partut, galician treegal,
irish, kazakh, latin, slovenian sst, ukrainian, uyghur

2

languages and treebanks

all ud 2.0 treebanks except:

too small
non-free

arabic nyuad: not available free of charge
at least 10k test words )

exclude: belarusian, coptic, lithuanian, sanskrit, tamil
include but small training: french partut, galician treegal,
irish, kazakh, latin, slovenian sst, ukrainian, uyghur

expected about 4 surprise languages

2

languages and treebanks

all ud 2.0 treebanks except:

too small
non-free

arabic nyuad: not available free of charge
at least 10k test words )

exclude: belarusian, coptic, lithuanian, sanskrit, tamil
include but small training: french partut, galician treegal,
irish, kazakh, latin, slovenian sst, ukrainian, uyghur

expected about 4 surprise languages
new parallel test set (dfki, google and others):

15   20 languages

2

additional data

just one    closed    track
registered participants were asked for suggestions

commoncrawl + id27s
word atlas of language structures (wals)
wikipedia dumps

wikipedia word vectors (90 languages) by facebook

opus parallel corpora
wmt 2016 parallel + monolingual data
apertium + giellatekno morphological analyzers
french treebank ud v2 conversion

3

multi-language and multi-domain

english language

ud english (web treebank): blog, social, reviews

205k train, 25k dev, 25k test

ud english lines:    ction, non   ction (sw localization),
spoken

50k train, 17k dev, 16k test

ud english partut: legal, news, wiki

26k train, 12k dev, 12k test

ud english dgpt: non   ction/legal (europarl), news, wiki

roughly 20k test only!

you can train one model for all if you want
but they are different domains!

main system score:

macro-average las across all test sets (not languages)

4

end-to-end parsing

a real-world scenario
no gold-standard processing available in the test data

5

end-to-end parsing

a real-world scenario
no gold-standard processing available in the test data

sentence segmentation

5

end-to-end parsing

a real-world scenario
no gold-standard processing available in the test data

sentence segmentation
id121
id40 (multi-word tokens)

5

end-to-end parsing

a real-world scenario
no gold-standard processing available in the test data

sentence segmentation
id121
id40 (multi-word tokens)
morphological analysis

if your parser needs it
exception: predicted morphology available for surprise
languages

5

end-to-end parsing

a real-world scenario
no gold-standard processing available in the test data

sentence segmentation
id121
id40 (multi-word tokens)
morphological analysis

if your parser needs it
exception: predicted morphology available for surprise
languages

parsing

5

baseline models

udpipe (  fal): trained segmenter, tagger+lemmatizer, parser
pre-processed test data (except syntax) directly available
just use that if you don   t have anything better

syntaxnet / parseysaurus (google)

no interest in surprise languages?
use simple delexicalized parser.

6

id74

align system-output tokens to gold tokens

al-zaman : american forces killed shaikh abdullah al-ani, the
preacher at the mosque in the town of qaim, near the syrian border.

gold:
offset: 0-1 2

- zaman : american forces killed shaikh
34-39

20-25

27-32

11-18

3-7

al

9

all characters except for whitespace match => easy align!

system: al-zaman : american forces killed shaikh
offset:
34-39

20-25

27-32

11-18

0-7

9

7

id74

align system-output tokens to gold tokens

die kosten sind de   nitiv auch im rahmen.

gold: die kosten sind de   nitiv auch
rahmen
split: die kosten sind de   nitiv auch in dem rahmen
34-39
offset: 0-2

26-29

16-24

31-32

11-14

4-9

im

.
.
40

corresponding but not identical spans?
find longest common subsequence

system: kosten sind de   nitiv auch
split:
kosten sind de    nitiv auch
offset:

16-24

11-14

4-9

26-29 31-32

im rahmen
im rahmen
34-39

.
.
40

8

id74

align system-output tokens to gold tokens

die kosten sind de   nitiv auch im rahmen.

gold: die kosten sind de   nitiv auch
rahmen
split: die kosten sind de   nitiv auch in dem rahmen
34-39
offset: 0-2

26-29

16-24

31-32

11-14

4-9

im

.
.
40

corresponding but not identical spans?
find longest common subsequence

system: auch
split:
offset: 26-29

rahmen
auch in einem , dem alle zustimmen , rahmen
34-39

31-32

im

.
.
40

8

id74

word ids no longer match between gold and system    les!
instead of comparing gold head to system head

headsystem(i) = headgold(i)
(comparing just integers here.)

9

id74

word ids no longer match between gold and system    les!
instead of comparing gold head to system head

headsystem(i) = headgold(i)
(comparing just integers here.)

compare aligned nodes, if alignment is found

node : integer ! node
align : systemnode ! goldnode
align(headsystem(nodei)) = headgold(align(nodei))
(comparing node objects.)

9

id74

word ids no longer match between gold and system    les!
instead of comparing gold head to system head

headsystem(i) = headgold(i)
(comparing just integers here.)

compare aligned nodes, if alignment is found

node : integer ! node
align : systemnode ! goldnode
align(headsystem(nodei)) = headgold(align(nodei))
(comparing node objects.)

cannot align? no point for attachment!

9

id74

word ids no longer match between gold and system    les!
instead of comparing gold head to system head

headsystem(i) = headgold(i)
(comparing just integers here.)

compare aligned nodes, if alignment is found

node : integer ! node
align : systemnode ! goldnode
align(headsystem(nodei)) = headgold(align(nodei))
(comparing node objects.)

cannot align? no point for attachment!
wrong sentence boundary?
) one or more wrong relations

9

labeled attachment score

correct relation     alignment of parent equals to parent of
alignment, and the universal pre   x of dependency relation types
match on both sides

precision: p = #correctrelations
#systemnodes
recall: r = #correctrelations

#goldnodes

laf (labeled attachment f1-score): laf = 2pr
p+r

10

ud-speci   c weighted metric (experimental)

relations between content words are more important
cross-linguistically
attachment of function word = morphology in other languages
weighted scoring of correct relations:

weight = 1 for root, nsubj, obj, iobj, csubj, ccomp, xcomp, obl,
vocative, expl, dislocated, advcl, advmod, discourse, nmod,
appos, nummod, acl, amod, conj,    xed,    at, compound, list,
parataxis, orphan, goeswith, reparandum, dep
weight = 0 for aux, case, cc, clf, cop, det, mark
weight = 0 for punct

11

still time to join!

http://universaldependencies.org/conll17/

11

