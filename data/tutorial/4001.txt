deep gated mrf's

marc'aurelio ranzato

ranzato@google.com

www.cs.toronto.edu/~ranzato

ipam summer school, 23 july 2012

two approaches to unsupervised learning

- structure is learned by scoring input data vectors
- implicit/explicit mapping between input and feature space
ranzato et al.    a unified energy-based framework for unsupervised learning    aistats 2007

training sample
input vector which is not a training sample
feature vector
x

feature space:

input space:

p    x   h   

p   h   x   

h

2

two approaches to unsupervised learning

- structure is learned by scoring input data vectors
- implicit/explicit mapping between input and feature space
ranzato et al.    a unified energy-based framework for unsupervised learning    aistats 2007

training sample
input vector which is not a training sample
feature vector
x
input space: 

feature space:

h

g    x ,h   

f     x ,h   

3

two approaches to unsupervised learning

1st strategy: constrain latent representation & 

optimize score only at training samples 

input space:

x

feature space: h

4

two approaches to unsupervised learning

1st strategy: constrain latent representation & 

optimize score only at training samples 

   x   wh   2
                    e.g., id116: score = reconstruction error:
                                          constraint = h  1-of-n: [0 0 0 1 0 0     0]

input space:

x

feature space:

h

[1,0,0 ]

[0,1,0]

[0,0,1]

5

two approaches to unsupervised learning

1st strategy: constrain latent representation & 

optimize score only at training samples 

   x   wh   2
                    e.g., id116: score = reconstruction error:
                                          constraint = h  1-of-n: [0 0 0 1 0 0     0]

input space:

x

decoding

feature space:

h

[1,0,0 ]

wh

[0,1,0]

[0,0,1]

6

two approaches to unsupervised learning

1st strategy: constrain latent representation & 

optimize score only at training samples 

   x   wh   2
                    e.g., id116: score = reconstruction error:
                                          constraint = h  1-of-n: [0 0 0 1 0 0     0]

input space:

x

decoding

feature space:

h

[1,0,0 ]

wh

[0,1,0]

[0,0,1]

7

two approaches to unsupervised learning

1st strategy: constrain latent representation & 

optimize score only at training samples 

   x   wh   2
                    e.g., id116: score = reconstruction error:
                                          constraint = h  1-of-n: [0 0 0 1 0 0     0]

input space:

x

decoding

feature space:

wh

h

[1,0,0 ]

[0,1,0]

[0,0,1]

8

two approaches to unsupervised learning

1st strategy: constrain latent representation & 

optimize score only at training samples 

   x   wh   2
                    e.g., id116: score = reconstruction error:
                                          constraint = h  1-of-n: [0 0 0 1 0 0     0]

input space:

x

encoding

feature space:

h

[1,0,0 ]

f     x ,h   

[0,1,0]

[0,0,1]

9

two approaches to unsupervised learning

1st strategy: constrain latent representation & 

optimize score only at training samples 

   x   wh   2
                    e.g., id116: score = reconstruction error:
                                          constraint = h  1-of-n: [0 0 0 1 0 0     0]

input space:

x

encoding

feature space:

h

[1,0,0 ]

f     x ,h   

[0,1,0]

[0,0,1]

10

two approaches to unsupervised learning

1st strategy: constrain latent representation & 

optimize score only at training samples 

   x   wh   2
                    e.g., id116: score = reconstruction error:
                                          constraint = h  1-of-n: [0 0 0 1 0 0     0]

input space:

x

feature space:

h

f     x ,h   

[1,0,0 ]

[0,1,0]

[0,0,1]

11

two approaches to unsupervised learning

1st strategy: constrain latent representation & 

optimize score only at training samples 

                    - id116 

- sparse coding
- use lower dimensional representations  

12

two approaches to unsupervised learning

1st strategy: constrain latent representation & 

optimize score only at training samples 

                    - id116 

- sparse coding
- use lower dimensional representations  

2nd strategy: optimize score for training samples while normalizing      
  

the score over the whole space (maximum likelihood)

p(x)

x

13

two approaches to unsupervised learning

1st strategy: constrain latent representation & 

optimize score only at training samples 

                    - id116 

- sparse coding
- use lower dimensional representations  

2nd strategy: optimize score for training samples while normalizing      
  

the score over the whole space (maximum likelihood)

y

a

d

o

t

p(x)

x

14

two approaches to unsupervised learning

1st strategy: constrain latent representation & 

optimize score only at training samples 

                    - id116 

w

o

r

r

- sparse coding
- use lower dimensional representations  

o

m

o

t

2nd strategy: optimize score for training samples while normalizing      
  

the score over the whole space (maximum likelihood)

p(x)

x

15

outline

 
- mathematical formulation of the model
- training
- generation of natural images
- recognition of facial expression under occlusion
- learning acoustic features for spech recognition
- conclusion

  

  

16

outline

 
- mathematical formulation of the model
- training
- generation of natural images
- recognition of facial expression under occlusion
- learning acoustic features for spech recognition
- conclusion

17

conditional distribution over input

p    x   h   = n    mean   h    ,d    
- examples: ppca, factor analysis, ica, gaussian rbm

input space

latent space

p    x   h   

training sample

latent vector

18

conditional distribution over input

p    x   h   = n    mean   h    ,d    
- examples: ppca, factor analysis, ica, gaussian rbm

p   h   x   

p    x   h   

input image

latent variables

generated image

model does not represent well dependecies, only mean intensity
19

conditional distribution over input

p    x   h   = n    0,covariance   h      
- examples: pot, crbm

input space

latent space

p    x   h   

training sample

latent vector

20

welling et al. nips 2003, ranzato et al. aistats 10

conditional distribution over input

p    x   h   = n    0,covariance   h      
- examples: pot, crbm

p   h   x   

p    x   h   

input image

latent variables

generated image

model does not represent well mean intensity, only dependencies
21

welling et al. nips 2003, ranzato et al. aistats 10

andy warhol 1960

conditional distribution over input

p    x   h   = n    mean   h    ,covariance    h      
- this is what we propose: mcrbm, mpot

input space

latent space

p    x   h   

training sample

latent vector

22

ranzato et al. cvpr 10, ranzato et al. nips 2010, ranzato et al. cvpr 11

conditional distribution over input

p    x   h   = n    mean   h    ,covariance    h      
- this is what we propose: mcrbm, mpot

input space

latent space

p    x   h   

p    x   =   h p    x   h     p   h   

training sample

latent vector

23

ranzato et al. cvpr 10, ranzato et al. nips 2010, ranzato et al. cvpr 11

pot

n(0,s )

our model

ppca

n(m,i)

n(m,s )

24

geometric interpretation of conditional over x

n    0,       hc      

n    m   hm   , i    

if we multiply them, we get...

25

geometric interpretation of conditional over x

n    m' ,    '    

n    0,       hc      

n    m   hm   , i    

if we multiply them, we get...
a sharper and shorter gaussian

26

mcrbm

x

x

x

x

- two sets of latent variables to modulate mean and covariance 
of the conditional distribution over the input

- energy-based model

p    x ,hm ,hc      exp      e    x ,hm ,hc      

x      d
hc   {0,1 }m
hm   {0,1}n

ranzato hinton cvpr 10

27

covariance part of the energy function:
e     x ,hc ,hm   = 1
x      d
      1      d   d

2 x '       1 x

x p

pair-wise mrf

xq

ranzato hinton cvpr 10

28

covariance part of the energy function:
e     x ,hc ,hm   = 1
x      d
c       d   f

2 x ' c c ' x
factorization

x p

f

pair-wise mrf

xq

ranzato hinton cvpr 10

29

covariance part of the energy function:
e     x ,hc ,hm   = 1
x      d
c       d   f

2 x ' c c ' x
factorization

x p

f

pair-wise mrf

xq

e     x ,hc ,hm   = 1

2 x ' c c ' x=   11 x1

2      12 x1 x2   ...

ranzato hinton cvpr 10

30

covariance part of the energy function:
e     x ,hc ,hm   = 1
x      d
c       d   f

2 x ' c c ' x
factorization

x p

f

pair-wise mrf

xq

e     x ,hc ,hm   = 1

2 x ' c c ' x= 1

2    i =1

f

   c i ' x   2

ranzato hinton cvpr 10

31

covariance part of the energy function:
e     x ,hc ,hm   = 1
2 x ' c [diag    hc   ]c ' x
x      d
factorization + hiddens
c       d   f
hc   {0,1 }f

c
hk

gated mrf

x p

c

f

f

c

xq

ranzato hinton cvpr 10

32

covariance part of the energy function:
e     x ,hc ,hm   = 1
2 x ' c [diag    hc   ]c ' x
x      d
factorization + hiddens
c       d   f
hc   {0,1 }f

c
hk

gated mrf

x p

c

f

f

c

xq

e     x ,hc ,hm   = 1

2 x ' c [diag    hc   ]c ' x= 1

f hi
2    i =1

c   c i ' x   2

ranzato hinton cvpr 10

33

2 x ' c [diag    p hc   ]c ' x
factorization + hiddens

covariance part of the energy function:
e     x ,hc ,hm   = 1
x      d
c       d   f
hc   {0,1 }m
p       f   m
gated mrf

c
hk
p

m

x p

c

f

c

xq

ranzato hinton cvpr 10

34

2 x ' c [diag    p hc   ]c ' x
factorization + hiddens

covariance part of the energy function:
e     x ,hc ,hm   = 1
x      d
c       d   f
hc   {0,1 }m
p       f   m
gated mrf

c
hk
p

m

x p

c

f

c

xq

e     x ,hc ,hm   = 1

2    k =1

m    i =1

f hk

c pik    c i' x   2

ranzato hinton cvpr 10

35

overall energy function:
e     x ,hc ,hm   = 1
x      d
w       d  n
hm   {0,1}n

gated mrf

x p

c

m

f

n

2 x ' c [diag    p hc   ]c ' x    1

covariance part

2 x ' x    x' w hm

mean part

c
hk
p

c
w
m
h j

xq

ranzato hinton cvpr 10

36

overall energy function:
e     x ,hc ,hm   = 1
x      d
w       d  n
hm   {0,1}n

gated mrf

x p

c

m

f

n

2 x ' c [diag    p hc   ]c ' x    1

covariance part

2 x ' x    x' w hm

mean part

c
hk
p

c
w
m
h j

xq

ranzato hinton cvpr 10

37

overall energy function:
e     x ,hc ,hm   = 1
x      d
w       d  n
hm   {0,1}n

gated mrf

x p

c

m

f

n

2 x ' c [diag    p hc   ]c ' x    1

covariance part

2 x ' x    x' w hm

mean part

c
hk
p

c
w
m
h j

xq

p    x   hc ,hm   = n           whm   ,       
      1=c diag [ p hc]c '    i

ranzato hinton cvpr 10

38

overall energy function:
e     x ,hc ,hm   = 1

2 x ' c [diag    p hc   ]c ' x    1

covariance part

2 x ' x    x' w hm

mean part

id136

x p

c

m

f

n

c
hk
p

c=1   x   =          1

p   hk

2 pk    c ' x   2   bk    

c
w
m
h j

xq

p   h j

m=1   x   =       w j ' x   b j   

ranzato hinton cvpr 10

39

overall energy function:
e     x ,hc ,hm   = 1

2 x ' c [diag    p hc   ]c ' x    1

2 x ' x    x' w hm

covariance part

mean part
complex-cell:

id136

x p

c

m

f

n

c
hk
p

c
w
m
h j

pools rectified simple cells
c=1   x   =          1

2 pk    c ' x   2   bk    

p   hk

xq

simple-cell:

non-linear filtering
m=1   x   =       w j ' x   b j   

p   h j

ranzato hinton cvpr 10

40

interpretation

e =   w ' x   2

minimizing e over the training set yields the 
minor component: w = [-1,1] since images are 
usually smooth.

41

interpretation

e =   w ' x   2

minimizing e over the training set yields the 
minor component: w = [-1,1] since images are 
usually smooth.

this edge shows the strong dependency 
(correlation) between image pixels!

42

interpretation

e =   w ' x   2

this enforces a strong penalty against the 
violation of the constraint:

x1= x2

this edge shows the strong dependency 
(correlation) between image pixels!

43

interpretation

e =   w ' x   2

how to make the penalty less strong?
how to model violations of the constraint?

this edge shows the strong dependency 
(correlation) between image pixels!

44

interpretation

e =   w ' x   2

how to make the penalty less strong?
how to model violations of the constraint?

add latent variables!

this edge shows the strong dependency 
(correlation) between image pixels!

45

interpretation

e = h   w ' x   2     bh, b   0

w ' x=0, h=1
e =   b

w ' x   0, h=0
e =0

penalty discount!

black rangarajan     on..line process..    ijcv 96

46

interpretation

mrf with adaptive (input-dependent) 
affinities

47

interpretation

integrating out latent variable, we 
get    robust    error metric.

f =   log[e   0      w ' x    2   b   0   e      w' x    2    b]
=   log[1   e      w' x    2   b ]

f

w ' x

48

interpretation

pixel correlations

mean intensity

49

how mean & covariance units cooperate

reconstruction using only mean units

input

whm

reconstruction using both mean&cov units

      hc         whm   

p    x   hc ,hm   = n           whm   ,       
      1=c diag [ p hc]c '    i

50

how mean & covariance units cooperate

setting mean unit reconstruction by hand

input

m

reconstruciton using covariance units

      hc      m

51

how mean & covariance units cooperate

setting mean unit reconstruction by hand

input

m

reconstruciton using covariance units

      hc      m

52

how mean & covariance units cooperate

setting mean unit reconstruction by hand

input

m

reconstruciton using covariance units

      hc      m

53

comparison

54

comparison

55

comparison

56

comparison

57

comparison

58

comparison

59

relation to prior work

- looking at 

p   v   h   

x

x

x

x

- looking at  e    v ,h   

hc

v 1

3rd order bm
v 2

- relation to pca, fa, pot, etc.

- relation to conditional 3-way rbm
memisevic et al 07,  taylor et al.  2009

- looking at hiddens 

hc

v 1
- relation to line process and pot

v 2

- looking at 
c=1   v    =           1

p   hk

p   h   v   

2 p k    c ' v   2   bk   

+

geman etal 84, blake etal 87, black etal 96

- relation to simple-complex cell model

outline

 
- mathematical formulation of the model
- training
- generation of natural images
- recognition of facial expression under occlusion
- learning acoustic features for spech recognition
- conclusion

61

learning

- maximum likelihood

p    x   =

   hm , hc e   e    x , hm , hc    
   x ,h m, hc e    e   x ,h m ,hc    

  - fast persistent contrastive divergence 
  - hybrid monte carlo to draw samples  

c
hk
p

xi

cc

w

x j

m
hn

e = 1

2 x' c [ diag    p hc   ]c ' x   x ' w hm   ...

62

learning

p    x   =

   hm , hc e   e    x , hm , hc    
   x ,h m, hc e    e   x ,h m ,hc     = e    f    x   
   x e    f    x   

f    x   =   log   hm , hc e   e    x , hm , hc   

63

interpretation

integrating out latent variable, we 
get    robust    error metric.

f =   log[e   0      w ' x    2   b   0   e      w' x    2    b]
=   log[1   e      w' x    2   b ]

f

w ' x

64

learning

p    x ;      = e    f    x ;      
   y e    f    y ;       

l    x ;      =   log p    x ;      

                 

    l
      

65

learning

p    x ;      = e    f    x ;      
   y e    f    y ;       

l    x ;      =   log p    x ;      

                 

    l
      

=   

    l
      
    f     x ;      

       

   x ~trainset       

    f     y ;      

       

   y~ p     y ;      

66

learning

p    x ;      = e    f    x ;      
   y e    f    y ;       

l    x ;      =   log p    x ;      

                 

    l
      

=   

    l
      
    f     x ;      

       

   x ~trainset       

    f     y ;      

       

   y~ p     y ;      

we estimate this by using 

an mcmc method: hmc

67

learning

f= - log(p(x)) + k 

    f
    w

training sample 

68

learning

f= - log(p(x)) + k 

    f
    w

hmc dynamics

training sample 

69

learning

f= - log(p(x)) + k 

    f
    w

hmc dynamics

training sample 

70

learning

f= - log(p(x)) + k 

    f
    w

hmc dynamics

training sample 

71

learning

f= - log(p(x)) + k 

    f
    w

hmc dynamics

training sample 

72

learning

f= - log(p(x)) + k 

    f
    w

hmc dynamics

training sample 

73

learning

f= - log(p(x)) + k 

    f
    w

hmc dynamics

74

learning

f= - log(p(x)) + k 

    f
    w

    f
    w

weight update

sample 

data
point

w     w         

    f
    w    data

   

    f
   
    w    sample

75

learning

f= - log(p(x)) + k 

    f
    w

    f
    w

weight update

sample 

data
point

w     w         

    f
    w    data

   

    f
   
    w    sample

76

learning

f= - log(p(x)) + k 

start next dynamics 

from this sample

sample 

data
point

w     w         

    f
    w    data

   

    f
   
    w    sample

77

outline

 
- mathematical formulation of the model
- training
- generation of natural images
- recognition of facial expression under occlusion
- learning acoustic features for spech recognition
- conclusion

78

learned filters: mean filters w

c
hk

p

c

n

c

f

w

m
h j

m

v p

v q

79

learned filters: covariance filters c

c
hk

p

c

f

w

m
h j

n

c

m

80

random walk: p(v|h)

1) given image -> infer latent variables using p(h|v)
2) keeping latent variables fixed, sample from p(v|h) 
 

ooooooo

x

generation natural 

image patches

natural images

mcrbm
ranzato and hinton  cvpr 2010

grbm
from osindero and hinton nips 2008

s-rbm + dbn
from osindero and hinton nips 2008

82

83

training on small image patches

pick patches at random 
locations for training

84

from patches to high-resolution  images
this is not a good way to extend the model to 

big images: block artifacts

but we could also take 
them from a grid

85

from patches to high-resolution  images

idea: have one subset of filters applied to these locations,

86

from patches to high-resolution  images

idea: have one subset of filters applied to these locations, 
another subset to these locations 

87

from patches to high-resolution  images

idea: have one subset of filters applied to these locations, 
another subset to these locations, etc. 

train jointly all parameters.

gregor lecun  arxiv 2010
ranzato, mnih, hinton nips 2010

no block artifacts 
reduced redundancy

88

sampling high-resolution images

gaussian model

marginal wavelet

from simoncelli 2005

89

sampling high-resolution images

gaussian model

marginal wavelet

from simoncelli 2005

pair-wise mrf

foe

from schmidt, gao, roth cvpr 2010

90

sampling high-resolution images

gaussian model

marginal wavelet

mean covariance model

from simoncelli 2005

pair-wise mrf

foe

ranzato, mnih, hinton nips 2010

from schmidt, gao, roth cvpr 2010

91

sampling high-resolution images

gaussian model

marginal wavelet

mean covariance model

from simoncelli 2005

pair-wise mrf

foe

ranzato, mnih, hinton nips 2010

from schmidt, gao, roth cvpr 2010

92

sampling high-resolution images

gaussian model

marginal wavelet

mean covariance model

from simoncelli 2005

pair-wise mrf

foe

ranzato, mnih, hinton nips 2010

from schmidt, gao, roth cvpr 2010

93

making the model..    deeper    

treat these units as data 

to train a similar model on the top

second stage
field of binary rbm's. 
each hidden unit has a 
receptive field of 30x30 
pixels in input space.

94

sampling from the deeper model

- sample from 2nd layer restricted id82 (rbm)
- project sample in image space using 1st layer p(x|h)

h2
rbm

h1

rbm

rbm

...

rbm

2nd layer

e    h1 ,h2   =   h1' w h2
p   h j
p   hk

2=1   h1   =       w j ' h1   b j
2   
1=1   h2   =       w k h2   bk
1   

gmrf

1st layer

95

samples from deep generative model

1st stage model

3rd stage model

96

samples from deep generative model

1st stage model

3rd stage model

97

samples from deep generative model

1st stage model

3rd stage model

98

samples from deep generative model

1st stage model

3rd stage model

99

sampling high-resolution images

foe

gaussian model

marginal wavelet

from schmidt, gao, roth cvpr 2010

from simoncelli 2005

from simoncelli 2005

deep - 1 layer

deep - 3 layers

ranzato, mnih, hinton nips 2010

ranzato, et al. cvpr 2011

100

using -energy to score images

less likely

test images

>

>

>

101

using energy to score images

upside-down images

>

>

>

>

>

>

102

using energy to score images

average of those images for which 

difference of energy is higher

103

scene recognition

- 15 scene dataset   (lazebnik et al. cvpr 2006)

- 15 categories, 100 images per class for training

104

scene recognition

- use hiddens at 2nd layer to represent 46x46 input image patches
- spatial pyramid matching on 1st and 2nd layer fearures

- result

 accuracy non-linear id166 (histogram intersection)
-  sift............................................................................................81.4%
    lazebnik et al. cvpr 2006
 - deep features: ........................................................................81.2%
    ranzato et al. cvpr 2011
- best method (sift + sparse coding)..................................84.1%
    boureau et al. cvpr 2010

105

       

original image

image denoising
noisy image: psnr=22.1db

denoised: psnr=28.0db

x    =argmin 1
2

   x     n   

    2     f     x    

106

original image

image denoising
noisy image: psnr=22.1db

denoised: psnr=29.2db

repeat
x    =argmin 1
2
      =argmin      log p    x    ;      

   x     n   

    2     f     x    

107

original image

image denoising
noisy image: psnr=22.1db

denoised: psnr=30.7db

x    =    x mpot

          1          x nonlocalmeans

   

108

outline

 
- mathematical formulation of the model
- training
- generation of natural images
- recognition of facial expression under occlusion
- learning acoustic features for spech recognition
- conclusion

109

facial expression recognition

toronto face dataset  (j. susskind et al. 2010)
 ~ 100k unlabeled faces from different sources
 ~ 4k labeled images
 resolution: 48x48 pixels 
 7 facial expressions

anger

ranzato, et al. cvpr 2011

110

facial expression recognition

toronto face dataset  (j. susskind et al. 2010)
 ~ 100k unlabeled faces from different sources
 ~ 4k labeled images
 resolution: 48x48 pixels 
 7 facial expressions

disgust

111

facial expression recognition

toronto face dataset  (j. susskind et al. 2010)
 ~ 100k unlabeled faces from different sources
 ~ 4k labeled images
 resolution: 48x48 pixels 
 7 facial expressions

fear

112

facial expression recognition

toronto face dataset  (j. susskind et al. 2010)
 ~ 100k unlabeled faces from different sources
 ~ 4k labeled images
 resolution: 48x48 pixels 
 7 facial expressions

happiness

113

facial expression recognition

toronto face dataset  (j. susskind et al. 2010)
 ~ 100k unlabeled faces from different sources
 ~ 4k labeled images
 resolution: 48x48 pixels 
 7 facial expressions

neutral

114

facial expression recognition

toronto face dataset  (j. susskind et al. 2010)
 ~ 100k unlabeled faces from different sources
 ~ 4k labeled images
 resolution: 48x48 pixels 
 7 facial expressions

sadness

115

facial expression recognition

toronto face dataset  (j. susskind et al. 2010)
 ~ 100k unlabeled faces from different sources
 ~ 4k labeled images
 resolution: 48x48 pixels 
 7 facial expressions

surprise

116

facial expression recognition

- 1st layer using local (not shared) connectivity
- layers above are fully connected
- 5 layers in total 

- result

- linear classifier on raw pixels
- gaussian rbf id166 on raw pixels
- gabor + pca + linear classifier
   dailey et al. j. cog. science 2002
- sparse coding   
   wright et al. pami 2008
- deep model (3 layers):

71.5%
76.2%
80.1%  

74.6%

82.5%
117

facial expression recognition

drawing samples from the model (5th layer with 128 hiddens)

h5
rbm

...

h4

rbm

rbm

rbm 5th layer

rbm

...
gmrf

1st layer

118

facial expression recognition

drawing samples from the model (5th layer with 128 hiddens)

119

facial expression recognition

- 7 synthetic occlusions
- use generative model to fill-in
   (conditional on the known pixels)

rbm
rbm
rbm
gmrf

rbm
rbm
rbm
gmrf

rbm
rbm
rbm
gmrf

rbm
rbm
rbm
gmrf

rbm
rbm
rbm
gmrf

...

120

facial expression recognition

originals

type 1 occlusion: eyes

restored images

121

facial expression recognition

originals

type 2 occlusion: mouth

restored images

122

facial expression recognition

originals

type 3 occlusion: right half

restored images

123

facial expression recognition

originals

type 4 occlusion: bottom half

restored images

124

facial expression recognition

originals

type 5 occlusion: top half

restored images

125

facial expression recognition

originals

type 6 occlusion: nose

restored images

126

facial expression recognition

originals

type 7 occlusion: 70% of pixels at random

restored images

127

facial expression recognition

original

input

128

facial expression recognition

original

input

1st layer

gmrf

gmrf

129

facial expression recognition

original

input

1st layer 2nd layer

rbm
gmrf

rbm
gmrf

130

facial expression recognition

original

input

1st layer 2nd layer 3rd layer

rbm
rbm
gmrf

rbm
rbm
gmrf

131

facial expression recognition

original

input

1st layer 2nd layer 3rd layer 4th layer

rbm
rbm
rbm
gmrf

rbm
rbm
rbm
gmrf

132

facial expression recognition

original

input

1st layer 2nd layer 3rd layer 4th layer

 10 times

rbm
rbm
rbm
gmrf

rbm
rbm
rbm
gmrf

rbm
rbm
rbm
gmrf

rbm
rbm
rbm
gmrf

rbm
rbm
rbm
gmrf

...

133

facial expression recognition

occluded images for both training and test

dailey, et al. j. cog. neuros. 2003
wright, et al. pami 2008

ranzato, et al. cvpr 2011

134

outline

 
- mathematical formulation of the model
- training
- generation of natural images
- recognition of facial expression under occlusion
- learning acoustic features for spech recognition
- conclusion

135

id103 on timit

input: standard pre-processing, but without augmentation 
(no 1st & 2nd order termporal derivatives)

training:
- unsupervised layer-wise training (8 layers, ~2000 units per layer)
- supervised training to predict states of id48

test: frame-by-frame prediction 

   

 viterbi decoding 

<-235 ms->

dahl, ranzato, mohamed, hinton, nips 2010

136

id103 on timit
per
34.8%  
33.0%  
27.3%  
26.6%  
26.1%   
25.6%  
22.7%  
20.5%  

method
crf
large-margin gmm
cd-id48
augmented crf
id56
bayesian triphone id48
triphone id48 discrim. trained 
dbn with gated mrf

137

id103 on timit
per
year
34.8%    2008
33.0%    2006
27.3%    2009
26.6%    2009
26.1%     1994
25.6%    1998
22.7%    2009
20.5%    2010

method
crf
large-margin gmm
cd-id48
augmented crf
id56
bayesian triphone id48
triphone id48 discrim. trained 
dbn with gated mrf

138

summary

 unsupervised learning
 deep generative model
 1st layer: gated mrf
 higher layers: binary rbm's
 fast id136
 realistic generation: natural images 
 applications:
 scene recognition, denoising, facial expression recognition 
robust to occlusion...
 id103

139

thank  you 

140

references on gated mrfs

 pot like models for modeling natural images
 hinton, the - discovering multiple constraints that are frequently approximately satisfied uai 
2001
 welling, hinton, osindero - learning sparse topographic representations with products of 
student's t distributions nips 2003
 teh, welling, osindero, hinton     energy-based models for sparse overcomplete representations 
jmlr 2003
 osindero, welling, hinton     topographic product models applied to natural scene statistics neural 
comp. 2006
 roth, black     field of experts ijcv 2009
 ranzato, krizhevsky, hinton     factored 3-way rbms for modeling natural images aistats 2010 
 mpot like models for modeling images and speech
 ranzato, hinton     modeling pixel means and covariances using factored 3rd order boltzmann 
machines cvpr 2010
 dahl, ranzato, mohamed, hinton     phone recognition with mcrbm nips 2010
 ranzato, mnih, hinton     generating more realistic images using gated mrf's nips 2010
 ranzato, susskind, mnih, hinton     on deep generative models with applications to recognition 
cvpr 2011
 kivinen, williams     multiple texture id82s aistats 2012

141

 models similar to mpot
 courville, bergstra, bengio     the spike and slab rbm nips 2010
 courville, bergstra, bengio     unsupervised models of image by ssrbm icml2011
 goodfellow, courville, bengio     large-scale id171 with spike-and-slab sparse coding. 
icml 2012
 3-way rbm applied to sequences
 memisevic, hinton     unsupervised learning of image transformations  cvpr 2007
 taylor, hinton     factored conditional rbm for modeling motion style icml 2009
 memisevic, hinton     learning to represent spatial transformations with a factored high-order 
id82 neural comp 2010
 memisevic     gradient-based learning of higher-order image features iccv 2011
 memisevic     on multi-view id171  icml 2012

142

