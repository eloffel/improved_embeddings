from natural scene statistics to models 

of neural coding and representation

(part 2)

bruno a. olshausen

helen wills neuroscience institute, school of optometry

and redwood center for theoretical neuroscience

uc berkeley

today   s talk

group sparse coding

id187

group sparse coding

sparse components exhibit statistical dependencies.

how to model this structure?

j. opt. soc. am. a/vol. 16, no. 7/july 1999

time),  2840  hz  (shifted  9  ms)  and  4019  hz
(shifted 9 ms).

x

b
simoncelli (1997)

   bow ties   

allows a system with limited response
range to handle a wider dynamic range of
input. divisive id172 achieves
this  goal,  producing  sigmoidal  con-
trast   response functions similar to those
seen in neurons. in addition, it seems
advantageous for tuning curves in stim-
ulus parameters such as orientation to
1556
retain their shape at different contrasts,
even in the presence of response satura-
tion20. previous models have accom-
plished this by computing a id172
signal that is independent of parameters
such as orientation (achieved with a uni-
formly weighted sum over the entire neur-
al population). a consequence of this
design is that the models can account for
the response suppression that occurs, for example, when a grat-
ing of non-optimal orientation is superimposed on a stimulus.

zetzsche (2000)

circularly symmetric 

x

distributions

model simulations versus physiology
we compared our model with electrophysiological measurements
from single neurons. to simulate an experiment, we chose a pri-
mary filter and a set of neighboring filters that would interact
with this primary filter. we pre-computed the optimal normal-
ization weights for an ensemble of natural signals (see methods).
we then simulated each experiment, holding all parameters of
the model fixed, by computing the normalized responses of the
primary filter to the experimental stimuli. we compared these
responses to the physiologically measured average firing rates of

x

x

x

x

x

x

zetzsche et al.

x

x

x

x

tion of the center contrast for a particular surround contrast. the
sigmoidal shape of the curves results from the squaring nonlin-
earity and the id172. presentation of the mask grating
alone does not elicit a response from the neuron, but its presence
suppresses the responses to the center grating. specifically, the
contrast response curves are shifted to the right (on a log axis),
indicative of a divisive gain change. when the mask orientation is
parallel to the center, this shift is much larger than when the mask
orientation is orthogonal to the center (fig. 6b).

fig. 2. even- and odd-symmetric linear    lters with standard parameters (radial octave bandwidth,    15-deg orientation bandwidth)
were applied to the set of natural images shown on the left, and the individual    lter statistics p(e), p(o), and the joint pdf p(e, o) were
evaluated to determine whether p(e, o)     p   (e, o)     p(e)p(o), i.e., whether the linear cartesian components are statistically indepen-

our model exhibits similar behavior (fig. 6a and b), which
is due to suppressive weighting of neighboring model neurons
with the same orientation preference that is stronger than that
of neurons with perpendicular orientation preference (see also

articles

   2001 nature publishing group  http://neurosci.nature.com

divisive id172
(schwartz & simoncelli 2001)

1

0

-1
-1

4

0

0

1

other squared
filter responses

other squared
filter responses

0

2

!

2

!

stimulus

f1

f2

fig. 4. generic id172 model for vision and audition. each filter
response is divided by the weighted sum of squared responses of neigh-
boring filters and an additive constant. parameters are determined using
maximum likelihood on a generic ensemble of signals (see methods).
the conditional histogram of normalized filter responses demonstrates
that the variance of n2 is roughly constant, independent of n1. the dia-
gram is a representation of the computation and is not meant to specify
a particular mechanism or implementation (see discussion).

4

that is primarily established by the numerator kernel of the model.
in fig. 7b, the high contrast secondary mode corresponds to fre-
quency bands with minimal id172 weighting.

discussion
we have described a generic nonlinear model for early sensory
processing, in which linear responses were squared and then
divided by a gain control signal computed as a weighted sum of
the squared linear responses of neighboring neurons and a con-

m
o
c

.
e
r
u
t
a
n

.
i
c
s
o
r
u
e
n

/
/
:
p

factorization

i

)
t
(
a
 
e
d
u
t
i
l

p
m
a
 
t
n
e
i
c
   

f
e
o
c

time

statistical dependencies among coef   cients arise due to 

interpolation of image features occurring at different positions 

along a continuum

a.

b.

a2

c.

  1(   x)

+ -

  2(   x)

+ -

a1

sparse representations tile the manifold of natural images 
in such a way that data points along the manifold are 
spanned by a small number of basis vectors.

coef   cients are interpolation weights within linear 
subspaces spanned by basis vectors along the manifold.

subspace ica model
hyvarinen & hoyer (2000)

emergence of phase- and shift-invariant features

1709

emergence of phase- and shift-invariant features

1713

figure 2: linear    lter sets associated with the feature subspaces (model complex
cells), as estimated from natural image data. every group of four    lters spans a
single feature subspace (for whitened data).

figure 1: graphical depiction of the feature subspaces. first, dot products of the
input data with a set of basis vectors are taken. here, we have two subspaces
with four basis vectors in each. the dot products are then squared, and the

changes in the learning rule. the density p was chosen as in equation 3.4.
the algorithm was initialized as in bell and sejnowski (1997) by taking as
wi the 160 middle columns of the identity matrix. we also tried random

topographic ica model
hyvarinen, hoyer & inki (2001) 

topographic independent component analysis

1533

u
1

u
2

s1

s

2

s

f

s

f

s

1

s

2

a

topographic independent component analysis

3

s

s

f

s

3

u
3

x
1

x
2

x
3

1547

figure 2: illustration of the topographic ica model. first, the    variance-
generating    variables ui are generated randomly. they are then mixed linearly
inside their topographic neighborhoods. (the    gure shows a one-dimensional
topography.) the mixtures are then transformed using a nonlinearity w , thus
giving the local variances s2
i . components si are then generated with variances
s2
i . finally, the components si are mixed linearly to give the observed variables xi.

    all the components si are uncorrelated. this is because according to

equation 2.6 we have

efsisjg d efzigefzjge(w   xk

h(i, k)uk  w   xk

h(j, k)uk  ) d 0

(2.7)

due to the independence of the uk from zi and zj. (recall that zi and zj are
zero mean.) to simplify things, one can de   ne that the marginal variances
(i.e., integrated over the distibution of si) of the si are equal to unity, as in
ordinary ica. in fact, we have

efs2

i g d efz2

w   xk

i ge8<:

h(i, k)uk  29=;

,

(2.8)

so we only need to rescale h(i, j) (the variance of zi is equal to unity by
de   nition). thus, the vector s can be considered to be sphered, that is, white.
   components that are far from each other are more or less independent.
more precisely, assume that si and sj are such that their neighborhoods have

w.s. geisler et al. /vision research 41 (2001) 711   724

715

   association    eld    statistics

geisler (2001)

both undirected and directed edges. it bears similarities to [15], which however does not have the
modeling dependencies with horizontal connections
intermediate layer a and is not a sparse coding model. to sample from this generative model, one
   rst obtains a sample s from the ising model, then samples coef   cients a according to p(a | s), and
then x according to p(x | a)     n (  a,  2in).

garrigues & olshausen (2008)

!

"

1

2

w1m

s1

s2

sm

w2m

0

!0.5

!1
0

0
0

50

100

150

200

250

b

50

100

150

200

250

figure 3: on the left is shown the entire set of basis functions    learned on natural images. on the
right are the learned variances (  2

i )i=1..m (top) and the biases b in the ising model (bottom).

am

a1

a2

the spatial properties (position, orientation, length) of the basis functions that are linked together
by them. each basis function is denoted by a bar that indicates its position, orientation, and length
within the 16    16 patch.

xn

x2

x1

  

figure 1: proposed graphical model

#
i

#
j

#
k

(a) 10 most positive weights

the parameters of the model to be learned from data are    = (  , (  2
i )i=1..m, w, b). this model
does not make any assumption about which linear code    should be used, and about which units
should exhibit dependencies. the matrix w of the interaction weights in the ising model describes
these dependencies. wij > 0 favors positive correlations and thus corresponds to an excitatory
connection, whereas wij < 0 corresponds to an inhibitory connection. a local magnetic    eld
bi < 0 favors the spin si to be down, which in turn makes the basis function   i mostly silent.

(b) 10 most negative weights

(c) weights visualization

2

(d) association    elds

id187

cortex has hierarchical structure.

scenes have compositional structure.

how to learn from images?

multiple paths to recognition

(ledoux et al. 1994)

what do these edges mean?

figure 24.6  variants on the koffka ring. (a) the ring appears about
uniform. (b) when split, the two half-rings appear distinctly differ-

figure 24.6  variants on the koffka ring. (a) the ring appears about
uniform. (b) when split, the two half-rings appear distinctly differ-

re   ectance

shading

(adelson, 2000)

how to factorize time-varying images 

into form and motion?

traditional motion estimation

time-varying image

estimate motion

optic    ow

estimate motion

motion

id173 
(smoothness)

natural scene 
statistics prior

time-varying image

  v = arg min

v

||i(x, t +    t)     i(x     v   t, t)||2

estimate pattern

pattern

natural scene 
statistics prior

a)

b)

motion and form must be estimated

simultaneously

a)

b)

time-varying image

estimate motion

optic    ow

time-varying image

estimate motion

motion

estimate pattern

form

pattern
form

id173 
(smoothness)

natural scene 
statistics prior

natural scene 
statistics prior

factorization of form and motion

cadieu & olshausen (2012), neural computation, 24

form

v(t)

b

exp()

a(t)

motion

w(t)

d

   

j

exp()

ej  (t)

  
a

i (t)

second layer

   rst layer

image

sparse coding 
image model

external
world

internal
model

i(x,y)

  i(x,y)

.
.
.

ai

image

neural
activities
(sparse)

features

other
stuff

amplitudes change slowly (presence of edge)

phases precess (movement of edge)

factorization of sparse components into

invariant and variant parts

i(t) =    a(t) +    (t)

ai(t) =   i(t)    ui(t)

invariant part:  presence, 

amplitude (contrast) of feature

variant part:  interpolation weight,

relative contribution of feature

see also:

wainwright & simoncelli (2002)
hyvarinen & hoyer (2002)
karklin & lewicki (2003)
schwartz & simoncelli (2004)
osindero & hinton (2005)
berkes, turner & sahani (2009)
zou, ng & yu (2011)

amplitude and phase decomposition

via complex basis functions

*

zi(t)   i(x, y)#

i(x, y, t) = !!"i
= "i

  i(t) [cos   i(t)   r

i (x, y) + sin   i(t)   i

i (x, y)]

zi(t) =   i(t) ej   i(t)

  i(x, y) =   r

i
i (x, y) + j   r
i (x, y)

complex basis function model

sparse + slow

   z
a

w

  

amplitude + phase

coef   cients

features

image

learned complex basis functions

a)

ari (x) aii (x)

|ai(x)|    ai(x)

b)

l

s
e
x
p

+
)
i
(
&

'

*

b)

%!

#!

,

b)

$!

$"

%!

%!

$"

$!

#"

#!

"

!

!

"

#!

#"

&'()*+

pixels

l

s
e
x
p

+
)
i
(
&

'

*

h
c
t

a
p

*

2
&

4
/
3

1
+
)
/
0
/

 
/
 
s
e
c
y
c

l

%!

$"

$!

#"

#!

"

!

!

#!

,

-

.

$

!

!$

!.

!-

!,

!#!

!#$

"

#!

#"

&'()*+

pixels

$!

$"

%!

!#!

!,

!-

!.

!$

cycles / patch

/0/*)+1&23/4

!

$

.

-

,

#!

h
c
t

a
p

*

4
/
3

2
&
1
+
)
/
0
/

 
/
 
s
e
c
y
c

l

#!

,

-

.

$

!

!$

!.

!-

!,

!#!

!#$

!#!

amplitude and phase linearize statistical dependencies

moving edge sequence

natural movie sequence

ur

l

a
e
r

ui

y
r
a
n
g
a
m

i

i

a

e
d
u

t
i
l

p
m
a

  

 
e
s
a
h
p

)
d
e
p
p
a
r
w
n
u
(

1

0
   1

1

0

   1

1.5
1
0.5
0

0
   10
   20
   30

10

20

30

1
0
   1

1
0
   1

10

20

30

10

20

30

10

20

30

10

20

30

1.5
1
0.5
0

0
   5
   10

10

20

30

10
time (frame index)

20

30

10
time (frame index)

20

30

amplitude and phase linearize statistical dependencies

a)

b)

c)

)
2
6
8
a
(
g
o
l

4
4
4
    

cc = 
0.46

d)

)
5
6
4
a
(
g
o
l

)
9
5
4
a
(
g
o
l

log(a247)

log(a72)

log(a62)

cc = 
0.28

e)

cc = 
0.12

f)

6
3
7
    

9
9
8
    

    193

    177

    5

cc = 
0.48

cc = 
0.43

cc = 
-0.27

form information by dividing out the local image contrast. this divisive id172
operation is analogous to the separation of amplitude and phase in the    rst layer of our
model. we can make this relationship explicit by expressing the time derivative of the
phase in terms of quadrature-pair simple cell responses, uc and us:

may be computed from normalized simple cell responses

    

d
dt

  (t) =

d
dt

arctan   us

uc    =

  usuc     us   uc
u2
c + u2
s

=

usut   1
c     ut   1
s uc
u2
c + u2
s

where the last equality is achieved by approximating the time derivative with a    rst-
order difference. this relationship, described by simoncelli (1993), shows an alterna-
tive way to compute the phase-shift variables in our model in terms of variables that are
readily available in divisive id172 models simoncelli and heeger (1998); rust
et al. (2006).

(see eero simoncelli thesis)

the structure that emerges within the phase-shift components re   ects the dynamics

factorization of form and motion

cadieu & olshausen (2012), neural computation, 24

sparse + slow

form

v(t)

b

exp()

a(t)

motion

w(t)

d

   

j

exp()

ej  (t)

  
a

i (t)

second layer

   rst layer

image

visualizing second-layer weights

spatial position

spatial frequency

a184
a184
d10

(

)
'
&
$

%

$!
$!
$!

#!

#"
#"
#"

)

)
)

*
*
*
(
(
(
'
'
'
"!
%
%
%

&
&

&

#!
#!
#!

"
"
"

!
!
!
!
!
!
!
!

+
+

+
1
,
,
,
,
0
2
2
2
$
$
$
/
-
-
-
1
1
1
0
0
0
$
!
!
!
%
%
%
.
/
/
/
*
*
*
)
(
(
(
!$
!$
!$
'
-
-
-
.
.
.
(
!,
!,
-
-
!,
-
,
-
!+
!+
!+
,

)
)

)

*
+
#
!
!#
!+
!*

2

"

!

!"

"!

"
"
"

#!
#!
#!
%&'()*
%&'()*
$%&'()
%&'()*

#!
#"
#"
#"

$!

$!
$!

!+

!+
!+

2

!

!,
!,

!*!+!# ! # + *
!,
+
+
,-,(').$/0,1

!$
,
!$
,
-.-)(*/%01-2
-.-)(*/%01-2

!$
,
$
$
-.-)(*/%01-2

!
!

$

+

learned form components b

a) amplitude component weights
freq. domain

spatial domain

positive response patches

negative response patches

b) amplitude component weights
freq. domain

spatial domain

positive response patches

negative response patches

c) amplitude component weights
freq. domain

spatial domain

positive response patches

negative response patches

d)

amplitude component weights
freq. domain
spatial domain

positive response patches

negative response patches

e) amplitude component weights
freq. domain

spatial domain

positive response patches

negative response patches

f) amplitude component weights
freq. domain

spatial domain

positive response patches

negative response patches

image patches yielding maximum response

learned form components b

texture boundaries

a)
spatial domain

freq. domain

oriented structure

b)
spatial domain

freq. domain

cross-orientation

c)
spatial domain

freq. domain

spatially global

d)
spatial domain

freq. domain

learned motion components d

a) phase-shift component weights

estimated motion vectors

b) phase-shift component weights

estimated motion vectors

spatial domain

freq. domain

spatial domain

freq. domain

l

s
e
x
p
-
y

i

spatial domain

freq. domain

spatial domain

freq. domain

x-pixels

d)

l

s
e
x
p
-
y

i

l

s
e
x
p
-
y

i

spatial domain

freq. domain

spatial domain

freq. domain

x-pixels

f)

l

s
e
x
p
-
y

i

c)

e)

x-pixels

x-pixels

l

s
e
x
p
-
y

i

l

s
e
x
p
-
y

i

x-pixels

x-pixels

051015202530051015202530051015202530051015202530051015202530051015202530051015202530051015202530051015202530051015202530051015202530051015202530learned motion component

w

space

freq.

d10

a

  

x

x

ur

ui

i

learned motion component

w

space

freq.

d21

a

  

x

x

ur

ui

i

other examples

learned motion components d
direction tiling

spatial tiling (small)

b)
spatial domain

spatial tiling (medium)
freq. domain

c)
spatial domain

spatial domain

freq. domain

freq. domain

a)

recursive ica

shan, zhang & cottrell (2007)

figure 1: the rica (recursive ica) model. after the    rst layer of linear ef   cient encoding,
sensory inputs x are now represented by s. the signs of s are discarded. then coordinate-wise
nonlinear id180 gi are applied to each dimension of s, so that the input of the next
layer x    = g(|s|) satis   es the input constraints imposed by the lee model. the statistical structure
figure 4: a subset of the 397 ica image basis functions. each basis function is 20x20 pixels. they
among dimensions of x    are then extracted by the next layer of linear ef   cient encoding.
are 2d gabor like    lters.

figure 5: sample units from the second layer. the upper panel arranges the connection weights

figure 4: a subset of the 397 ica image basis functions. each basis function is 20x20 pixels. they
are 2d gabor like    lters.

recursive ica

figure 6: activation maps on two images (upper and lower panel respectively) for two units per

statistics

coding strategy

contrast histogram

histogram equalization

neurobiological 

substrate

photoreceptors/

bipolar cells

autocorrelation

function

whitening

retina/lgn

sparse components localized, oriented, bandpass

feature decomposition

v1    simple cells   

amplitude
components

texture coding

v1/v2 

   complex cells   

phase components

motion coding

mt

