from natural scene statistics to models 

of neural coding and representation

(part 1)

bruno a. olshausen

helen wills neuroscience institute, school of optometry

and redwood center for theoretical neuroscience

uc berkeley

review article:

what natural scene statistics can tell us about 

cortical representation

bruno a. olshausen & michael s. lewicki

to appear in:

the new visual neurosciences
chalupa and werner, eds.

mit press

today   s talk

why natural scene statistics?

  - (a bit about biology)

theory of redundancy reduction

sparse coding

what are the principles of computation and 

representation governing this system? 

natural images are full of ambiguity

100

120

140

100

120

140

180

200

220

240

180

200

220

240

natural images are full of ambiguity

100
100

120
120

140
140

100
100

120
120

140
140

180
180

200
200

220
220

240
240

180
180

200
200

220
220

240
240

vision as id136

lens

world

image

model

visual cortical areas - macaque monkey

visual cortical areas

46

tf

th

stpa

aitd

aitv

7a

fef

stpp

citv

citd

faces/objects

vip

lip mstd msti fst

pitd

pitv

dp

vot

mdp mip

po

mt

v4t

pip

v3a

v4

v2

v1

   intermediate-level   

vision

(courtesy of jeff hawkins)

1 mm2 of cortex analyzes ca. 14 x 14 array of retinal
sample nodes and contains 100,000 neurons

(anderson & van essen, 1995)

anatomy of a 

synapse

the evolution of eyes

land & fernald (1992)

http://redwood.berkeley.edu/wiki/vs298:_animal_eyes

ef   cient coding

 represent the most relevant visual information with the 

fewest physical and metabolic resources

theory of    redundancy reduction   

attneave (1954) some informational aspects of  visual 
perception 

barlow (1961) possible principles underlying the 
transformations of sensory messages
 - nervous system should reduce redundancy
 - makes more ef   cient use of neural resources
 - enables storing information about prior 
probabilities since
p (x) =   ip (xi)
         suspicious coincidences         

from theory to models

laughlin (1981) - histogram equalization

laughlin, srinivasan and dubs (1982) -   predictive 
coding: a fresh view of inhibition in the retina

field (1987) - natural images have        power spectra

1/f 2

atick & redlich (1992); van hateren (1992; 1993) - 
whitening

dan, atick, and reid (1996) - lgn whitens natural 
movies

natural scene statistics and visual coding

images.  this  difference 

effort  was made  to ensure  this,  and  they  may therefore  rep-
resent  biased  samples.
the  negatives  were  digitized  on  a  laser  densitometer
(joyce  loebel)  into  256 x 256 pixels  with  a  depth  of 8 bits/
pixel  (256 density  levels).  the  images  were  analyzed  on a
sun workstation computer using conventional software de-
veloped by the author.

calibration
the modulation transfer function (mtf) of the optical sys-
from the
tem  (lens and  developing  process)  was  determined 
response  of the  system  to  a point  source.  a photograph  of a
point  source was taken with the same camera and film, and
the  negative  was  developed  in  the  same  manner  as  the  six
natural  scenes.  the results described below were corrected
in accordance with this mtf.

surfaces  containing  various  patterns  at a wide range  of orien-
tations.  amid this complexity, it may seem surprising that
such images share any consistent statistical features.  con-
sider the  six images  shown in fig. 6.  such  images  may seem
widely  different,  but  as  a group  they  can  be  easily  distin-
guished  from  a variety  of other  classes  of image.  for  exam-
ple, random-dot  patterns  are statistically different from all
is  best  de-
six  of  these  natural 
scribed in terms of the amplitude spectra or power spectra of
the images, where the amplitude spectrum is defined as the
square root of the power spectrum.
the two-dimensional amplitude spectra for two of the six
images  are shown in  fig. 7.  the  spectra  of these  images  are
quite  characteristic  and  are quite  different  from that  of
white  noise, which  is by definition  flat.  they  show greatest
amplitude at low frequencies (i.e., at the center of the plot)
and decreasing amplitude as the frequency increases.  the

f

a

b

c

d 

e 

fig. 6.  examples  of the  six images  (a-f)  in this  study.  each  image  consists  of 256 x 256 pixels  with  256 gray levels (8 bits).  however,  only
the  central  region  was  directly  analyzed  (160 x 160).  see the  text  or details.

aa:.:i
f

(field 1987)

whitening (or decorrelation) theory

(atick & redlich, 1992)

1/f image

whitening    lter

decorrelated 

image

e
d
u
t
i
l

p
m
a

x

e
d
u
t
i
l

p
m
a

=

e
d
u
t
i
l

p
m
a

frequency

frequency

frequency

    w  x, (28)

  at aw        diag   ln[diag(w  xwt )/  2

diag(w  xwt )

diag[w  xwt ] =   2

j x    =   2
u1m

   robust coding   

(5)
  in is the covariance of the observation. it can further be simpli   ed to
(6)
(7)

a receptive    eld: the constraint for the k-th neuron is de   ned by   j |wkj|(   d 2
doi & lewicki (2006) - a theory of retinal 
population coding 

   w        at (awh     in)  sht       2
with e = tr         t    by de   nition,          the average over samples, and   s the covariance matrix of the
image signal s. the problem is to    nd w and a that minimize e.
where    is a positive constant that controls the strength of the variance constraint. our initial results
indicated that the optimal solutions are not unique and these solutions are equivalent in terms of
to model limited neural capacity, the representation r must have limited snr. this constraint is
equivalent to    xing the variance of    lter output    wt
u, where wj is the j-th row of w (here
mse. we then imposed an additional neural resource constraint that penalizes the spatial extent of
we assume all neurons have the same capacity). it is expressed in the matrix form as
kj + 1) where dkj
is the spatial distance between the j-th weight and the center of mass of all weights, and    is a
positive constant de   ning the strength of the spatial constraint. this assumption is consistent with
where   x = h  sht +   2
the spatially restricted computation in the retina. if    = 0, it imposes sparse weights [16], though
not necessarily spatially localized. in our simulations we    xed    = 0.5.
for the fovea, we examined 15  15 pixel image patches sampled from a large set of natural im-
ages, where each pixel corresponds to a cone photoreceptor. since the cell ratio is assumed to be
1 : 1, there were 225 model neurons in the population. as shown in fig. 4, the optimal    lters
show concentric center-surround organization that is well    t with a difference-of-gaussian function
(which is one major characteristic of mrgcs). the precise organization of the model receptive    eld
changes according to the snr of the observation: as the snr decreases, the surround inhibition
gradually disappears and the center becomes larger, which serves to remove sensory noise by aver-
aging. as a population, this yields a signi   cant overlap among adjacent receptive    elds. in terms of
spatial-frequency, this change corresponds to a shift from band-pass to low-pass    ltering, which is
figure 2: the model diagram. if there is no degradation of the image (h = i and   2
consistent with psychophysical measurements of the human and the macaque [17].
model is reduced to the original robust coding model [2]. if channel noise is zero as well (  2
it boils down to conventional block coding such as pca, ica, or wavelet transforms.
(a)

diag[vvt ] = 1m ,

   = 0), the
   = 0),

w =   uvs   1

x et ,

reconstruction

representation

channel noise

observation

optical blur

sensory noise

encoder

decoder

w

image

h

a

-10db

20db

10db

0db

  

x

  

r

s

  s

(b)

(c)

(d)

e
d
u
t
i
n
g
a
m

20db

-10db

spatial freq.

figure 4: the model receptive    elds at the fovea under different snrs of the observation. (a) a

   robust coding   
karklin & simoncelli 
(2011) - ef   cient coding 
of natural images with a 
population of noisy 
linear-nonlinear neurons

a

c
15

b
16

1

1

b

16

on   center

off   center

figure 1: a. schematic of the model (see text for description). the goal is to maximize information
transfer between images x and the neural response r, subject to metabolic cost of    ring spikes. b.
information about the stimulus is conveyed both by the arrangement of the    lters and the steepness
of the neural nonlinearities. top: two neurons encode two stimulus components (e.g. two pixels of
an image, x1 and x2) with linear    lters (black lines) whose output is passed through scalar nonlinear
functions (thick color lines; thin color lines show isoresponse contours at evenly spaced output
levels). the steepness of the nonlinearities speci   es the precision with which each projection is
represented: regions of steep slope correspond to    ner partitioning of the input space, reducing the
uncertainty about the input. bottom: joint encoding leads to binning of the input space according to
the isoresponse lines above. grayscale shading indicates the level of uncertainty (id178) in regions
of the input (lighter shades correspond to higher uncertainty). ef   cient codes optimize this binning,
subject to input distribution, noise levels, and metabolic costs on the outputs.

1

1

16

parameter   j speci   es the trade-off between information gained by    ring more spikes, and the cost
of generating them. it is dif   cult to obtain a biologically valid estimate for this parameter, and
ultimately, the value of sensory information gained depends on the behavioral task and its context
[26]. alternatively, we can use   j as a lagrange multiplier to enforce the constraint on the mean
output of each neuron.

16

0
figure 2: in the presence of biologically realistic level of noise, the optimal    lters are center-

beyond ef   cient coding

rr is appropriate when there is a bottleneck.

but v1 expands dimensionality - many more neurons than inputs

the real goal of sensory representation is to model the 
redundancy in images, not necessarily to reduce it (barlow 2001)

what we desire is a meaningful representation.

rr provides a valid probabilistic model only when the world can 
be described in terms of statistically independent components.

to understand cortical representation we must appeal to a 
different principle.

temporal reconstruction o f  the  image 

v1 is highly overcomplete

the  homunculus  also  has  t o  face  t'he problem  t h a t   the  image  is  often  nioving 
continuously, b u t  is only represented  b y  impulses a t  discrete moments in time. i n  
these days he often has to deal with visual images derived from cinema screens and 
television  sets t h a t  represent scenes sampled a t  quite long intervals, and we  know 

lgn 
afferents

ivb 

layer 4 
cortex

barlow (1981)

figure8. a  tracing  of  the  outlines  of  the  granule cells of  area  17 in  layers i v b  and  i v c  of 
monkey cortex, where the incoming geniculate  fibres termmate  (from fig. 3 c of  hubel  & 
wiesel  1972)  the dots a t  the top lndlcate the calct~lated separation of  the sample points 
coming  in  from  the  r e t ~ n a ,  allowing  tmo  per  cycle  of  the  higllest  spatial  frequency 

0 1 m m

i 

c 

sparse, distributed representation

ai

i(x,y)

    provides a way to group things together so that the world 
can be described in terms of a small number of events at any 
given moment. 

    converts higher-order redundancy in images into a simple 
form of redundancy.

sparse vs. dense vs. 

   grandmother cell    codes

dense codes

(ascii)

sparse, distributed codes

local codes

(grandmother cells)

. . .

. . .

+ high combinatorial
   capacity (2n)

-  difficult to read out

+ decent combinatorial
   capacity (~nk)

+ still easy to read out

-  low combinatorial
   capacity (n)

+ easy to read out

gabor-   lter response histogram

sparse coding 
image model

external
world

internal
model

i(x,y)

  i(x,y)

.
.
.

ai

image

neural
activities
(sparse)

features

other
stuff

learned dictionary   

(critically sampled)

)
s
e
e
r
g
e
d
(
 
h
t
d
w
d
n
a
b
 
n
o

i

i
t

t

a
n
e
i
r
o

 

180
160
140
120
100
80
60
40
20
0

0

0.5
2
 radial bandwidth (octaves)

1.5

1

2.5

effect of overcompleteness and    hard sparsity   
142

(rehn and sommer 2006)

fig. 5 receptive    elds from the ef   cient coding models and from

learned 
dictionary 

10x

overcomplete

(joint work with 
david warland, 

uc davis)

10x

l

s
s
e
n
e
t
e
p
m
o
c
-
r
e
v
o

5x

2.5x

10%

sparsity

5%

27db

20db

1%

8.2db

19db

13db

5.3db

13db

8.5db

snr: 3.2db

180
160
140
120
100
80
60
40
20

)
s
e
e
r
g
e
d
(
 
h
t
d
w
d
n
a
b

i

 

n
o

i
t

a

t

n
e
i
r
o

 

0.5

1

1.5

2

2.5

 radial bandwidth (octaves)

10x, 1%

blob

ridge-like

grating

10x

l

s
s
e
n
e
t
e
p
m
o
c
-
r
e
v
o

5x

2.5x

10%

sparsity

5%

27db

20db

1%

blob

8.2db

19db

grating

13db

ridge-like

5.3db

13db

8.5db

snr: 3.2db

180
160
140
120
100
80
60
40
20

)
s
e
e
r
g
e
d
(
 
h
t
d
w
d
n
a
b

i

 

n
o

i
t

a

t

n
e
i
r
o

 

0.5

1

1.5

2

2.5

 radial bandwidth (octaves)

solutions are stable

tiling properties:  blobs

(highest spatial-frequency band only)

(cid:81)
(cid:82)

(cid:76)
(cid:87)
(cid:76)
(cid:86)
(cid:82)
(cid:83)
(cid:239)
(cid:92)
(cid:3)

16
14
12
10
8
6
4
2
0

0

5
(cid:3)(cid:91)(cid:239)(cid:83)(cid:82)(cid:86)(cid:76)(cid:87)(cid:76)(cid:82)(cid:81)

10

15

tiling properties:  ridge-like

n
o
i
t
a
t
n
e
i
r
o

spatial position

where " denotes cross-correlation. note however
again, a sparse, factorial prior is imposed on the
that in order to be considered a causal system, the
coe   cients over both space (i) and time (t), and the
value of a coe   cient at time t! must be determined
coe   cients for an image sequence are computed via
figure 4: basis functions learned from natural images. shown are a set of 200 basis functions, each 12   12
sparse coding of 
solely from image frames and other coe   cient val-
id119 on the negative log-posterior:
pixels in size. most have become localized well within the image patch, and all have become oriented,
ues prior to t!. for now though we shall not bother
with the exception of one function which took on the d.c. component. the functions are also bandpass
time-varying images
imposing this restriction, and in the next section
in spatial-frequency, occupying di   erent regions of the spatial-frequency domain.
we shall entertain some possibilities for making the
model causal.
"##!$

     ai(t) = bi(t)    !j
bi(t) =   n!x
cij(t) =   n!x

cij(t) " aj(t)     s!(ai(t))(13)

given in olshausen & field (1996b) and field (1993).
the learned basis functions are well    t by gabor
functions, and the entire set of functions evenly tiles
the joint space of position, orientation, and scale, as
demonstrated in previous publications (olshausen &

  i(x, t) "   j(x, t)

  i(x, t) " i(x, t)

!

%

%

$

!&

(cid:73)#'$(%(!)!&*

where " denotes cross-correlation. note however
that in order to be considered a causal system, the
value of a coe   cient at time t! must be determined
solely from image frames and other coe   cient val-
ues prior to t!. for now though we shall not bother
imposing this restriction, and in the next section
(cid:87)
we shall entertain some possibilities for making the
model causal.

a learning rule for the spatiotemporal basis func-
tions may be derived by maximizing the average
log-likelihood as before (for details see olshausen,
2002). when the basis functions are adapted in this
manner, using time-varying natural images as train-
ing data (van hateren, 2000), they converge to a
set of spatially localized, oriented, bandpass func-
tions that now translate over time. shown in fig-
ure 6 is a randomly chosen subset of the 200 basis
functions learned, each 12  12 pixels and 7 frames
in time. again, it seems intuitively reasonable that
these functions would form a sparse representation
of time-varying natural images, since only a few of
them are needed to describe a contour segment mov-
ing through this patch of the image.
ai(t)       i(   x, t) +    (   x, t)
the tiling properties for velocity, as well as speed
(12)
spatial-frequency, are shown in    gure 7. the
majority of basis functions translate by less than one
pixel per frame. (the frame rate is 25 frames/sec.,
so a speed of one pixel per frame corresponds to 25

a learning rule for the spatiotemporal basis func-
+#$%%%!$
tions may be derived by maximizing the average
log-likelihood as before (for details see olshausen,
2002). when the basis functions are adapted in this
manner, using time-varying natural images as train-
ing data (van hateren, 2000), they converge to a
180
set of spatially localized, oriented, bandpass func-
tions that now translate over time. shown in fig-
ure 6 is a randomly chosen subset of the 200 basis
functions learned, each 12  12 pixels and 7 frames
in time. again, it seems intuitively reasonable that
these functions would form a sparse representation
of time-varying natural images, since only a few of
them are needed to describe a contour segment mov-

figure 5: spatiotemporal image model. a time-
varying image patch, i(x, t), is modeled as a lin-
ear superposition of spatio-temporal basis functions,
  i(x, t), each of which is localized in time but may
be applied at any point within the image sequence.

i(   x, t) =   i

!"!"!

8

$

!

150

210

figure 6: space-time basis functions learned from
time-varying natural images. shown are 30 basis
functions randomly selected from the entire set of
200 functions learned, arranged into two columns of
15. each basis function is 12  12 pixels in space and
7 frames in time. each row within a column shows
a di   erent basis function, with time proceeding left
to right.

t

90

60

  3

120

speed vs. direction

figure 6: space-time basis functions learned from
time-varying natural images. shown are 30 basis
speed vs. spatial   frequency
functions randomly selected from the entire set of
200 functions learned, arranged into two columns of
15. each basis function is 12  12 pixels in space and
7 frames in time. each row within a column shows
a di   erent basis function, with time proceeding left
to right.

)
e
m
a
r
f
/
s
e
x
p
(
 

1.5

2.5

  1

  2

30

0

2

3

i

l

240

150

speed vs. direction
300

  3

90

60

120

270

  2

  1

330

30

0.5

0
3

0

2.5

2

speed vs. spatial   frequency

0.2

spatial   frequency (cy/pixel)

0.4

d
e
e
p
s

1

)
e
m
a
r
f
/
s
e

l

figure 7: basis function tiling properties. each data

0

1.5

180

the model may be extended to the time domain
by describing a sequence of images (i.e., a movie)
in terms of a linear superposition of spatiotemporal
functions,   i(x, t). here, the basis functions are ap-
plied in a shift-invariant fashion over time, meaning
that the same function is assumed to be repeated at
each point in time. thus, an image sequence is de-
scribed by convolving the spatiotemporal basis func-
tions with a set of time-varying coe   cients, ai(t):
ai(t!)   i(x, t     t!) +   (x, t)

the model is illustrated schematically in    gure 5.

learned basis space-time basis functions 

(200 bfs, 12 x12 x 7)

sparse coding and reconstruction

2

0

   2

0

2

0

   2

0

e
d
u

t
i
l

p
m
a

sparsified

1

1

2

2

3

4

convolution

3

4
time (sec)

5

5

6

6

7

7

extensions to color, disparity

wachtler, lee and sejnowski (2001), hoyer & hyvarinen (2000)

wachtler et al.

vol. 18, no. 1/january 2001/j. opt. soc. am. a

71

figure 14: ica basis of stereo images. each pair of patches represents one basis vector ai of the estimated
mixing matrix a. note the similarity of these features to those obtained from standard image data. in
addition, these exhibit various degrees of binocularity and varying relative positions and phases.

80

60

nonlinear encoding

solutions may be computed by a network 
of leaky integrators and threshold units

(rozell et al. 2008)

   explaining away   

g

g

g

g

g

!!

feedforward 
response ("#)

sparsified
response ($#)

!!

!

!

!!

!

!

nonlinear encoding

   explaining away    explains ncrf effects

lee et al. (2007), zhu & rozell (2010)

   end-stopping   

contrast-invariant tuning

e
s
n
o
p
s
e
r

5

4

3

2

1

0

0

(a)

figure 1: rozell.

target
competing

5

10

15

bar length (pixels)

(b)

(a)

(b)

   surround
suppression   

iso surround

orth surround

uniform

(a)

center
orth surround
iso surround

(b)

(c)

(c)

(d)

figure 5: rozell.

60

50

40

30

20

10

s

l
l

e
c

 
f

o
#

 

0
   0.4

   0.2

0

0.2

0.4

slope (half   width vs. contrast)

(d)

figure 6: rozell.

14516552545658510512500.10.20.30.40.50.60.70.8orientation(deg)response(a)c=0.1c=0.2c=0.3c=0.4c=0.50.10.20.5100.20.40.60.811.2surroundcontrastresponseisosurroundorthsurrounduniform0.10.20.5100.20.40.60.81centercontrastresponse(a)centerorthsurroundisosurroundenergy-based models
osindero, welling and hinton (2005)

a

1.0x

b

ica

p (x) =

1
z

e   e(x)

   osinderowellinghinton  pot  nc05  accdraft  ss        2005/8/23     13:07     page 11     #11

  i log   1 +

(ji x)2

2    

m   i=1

   

   

c

1.7x

d

2.4x

beta=5
beta=2
beta=1/2

e(x) =

1

0.9

0.8

0.7

0.6

0.5

0.4

0.3

0.2

0.1

0
-10 -8

-6

-4

-2

0

2

4

6

8

10

figure 2: functions f(x) = 1/(1 + |x|  ) for different values of   .

the distribution of complex cell outputs and the way they are penalized, the model ought

figure 3: learnt    lters shown in the raw data space. each small square represents
a    lter vector, plotted as an image. the gray scale of each    lter display has been

