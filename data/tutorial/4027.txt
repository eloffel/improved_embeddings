deep learning in the 
visual cortex
thomas serre
brown university

i.  fundamentals of primate vision
ii. computational mechanisms of rapid 

recognition and feedforward processing

iii. beyond feedforward processing: 

attentional mechanisms and cortical 
feedback

1

feedforward hierarchical 
model of object recognition

2

ventral visual streamfeedforward hierarchical 
model of object recognition

2

ventral visual streamx

feedforward hierarchical 
model of object recognition

2

ventral visual stream    qualitative neurobiological models 

(hubel & wiesel    59; perrett & oram    93)

    biologically-inspired id161 

systems
(fukushima    80; mel    97; lecun et al    98; lowe, 
   00; thorpe    02; ullman et al    02;  wersing and 
koerner    03; mutch & lowe    06)

    quantitative neurobiological models 
(wallis & rolls    97; riesenhuber & poggio    99; 
amit & mascaro    03; serre et al 2005; deco & 
rolls    06; masquelier & thorpe    07)

feedforward hierarchical 
model of object recognition

3

     system-level feedforward 

computational model, large-scale 
(100m units), spans several areas of 
the visual cortex

     some similarities with state-of-the-
art id161 systems (e.g., 
convolutional and deep belief nets)
     but constrained by anatomy and 
physiology and shown to be 
consistent with experimental data 
across areas of visual cortex

feedforward hierarchical 
model of object recognition

4

cortical mechanisms of 
invariant recognition

    processing based on selective 

pooling mechanisms (to gradually 
increase selectivity and invariance of 
units along hierarchy)

5

cortical mechanisms of 
invariant recognition

    processing based on selective 

pooling mechanisms (to gradually 
increase selectivity and invariance of 
units along hierarchy)

simple
cells

5

cortical mechanisms of 
invariant recognition

    processing based on selective 

pooling mechanisms (to gradually 
increase selectivity and invariance of 
units along hierarchy)

simple
cells

complex

cells

5

finally, in analogy with gabor's original information di-

the  simple  cells are generally  considered  linear  integrators  of

cortical mechanisms 
of invariant recognition
s1 simple units

2d receptive field

2d gabor function

difference

a  x~~~'

fig. 3. 
illustration of experimentally measured 2d receptive-field profiles of three simple cells in cat striate cortex (top row) obtained in the
laboratory of l. a. palmer and j. p. jones  (university of pennsylvania medical school).  each plot shows the excitatory or inhibitory effect
of a small flashing light or dark spot  on the firing rate of the cell, as a function  of the (x, y) location  of the stimulus,  computed  by reverse correlation
of the  2d stimulus  sequence  with  the  neural-response 
sequence.  the  second  row shows  the  best-fitting  2d gabor  function  for  each coll's  re-
ceptive-field profile, based on eqs. (3) with the parameters fitted by least squares.  the third row shows the residual error between the measured
response  profile  of each  cell and  eqs.  (3).  in  formal  statistical 
from  random  error  for  33 of the  36
simple  cells tested. 

jones & palmer    87

tests,  the  residuals  were  indistinguishable 

(from  ref.  28.)

gabor    lters at multiple phases (one phase shown), orientations and spatial 
frequencies/scales (parameters derived from available experimental data)

6

cortical mechanisms 
of invariant recognition
s1 simple units

gabor    lters at multiple phases (one phase shown), orientations and spatial 
frequencies/scales (parameters derived from available experimental data)

6

cortical mechanisms 
of invariant recognition
c1 complex units
(1) half-recti   cation and summing over phases at 
each location for tolerance to contrast reversal

(   )2

+

(   )2

+...

7

heeger & carandini    94; lampl et al    01; touryan et al    02; rust et al    05; finn & ferster    07

cortical mechanisms 
of invariant recognition
c1 complex units
(1) half-recti   cation and summing over phases at 
each location for tolerance to contrast reversal

8622 j. neurosci., november 1, 1997, 17(21):8621   8644

(   )2

+

(   )2

+...

(2) gain control / divisive id172

carandini et al.     linearity and id172 in simple cells

bromide (norcuron, 0.1 mgzkg    1zhr    1) in lactated ringer   s solution with
dextrose (5.4 ml/hr). the pupils were dilated and accommodation par-
alyzed with topical atropine. the corneas were protected with zero
power gas-permeable contact lenses; supplementary lenses were chosen
to focus the eyes on a tangent screen plotting table set up at a distance
of 57 in. to maintain the animal in good physiological condition during
experiments (typically 72   96 hr), intravenous supplementation of 2.5%
dextrose/lactated ringer   s was given at 5   15 ml/hr. animals received
daily injections of a broad-spectrum antibiotic (bicillin) as well as an
anti-in   ammatory agent (dexamethasone) to prevent cerebral edema.

stimuli
stimuli were generated by a truevision atvista board operating at a
resolution of 582     752 and a frame rate of 106 hz, the output of which
was directed to a nanao t560i monitor (mean luminance, 72 cd/m 2,
subtending 10   25   of visual angle). nonlinearities in the relation be-
tween applied voltage and phosphor luminance were compensated by
appropriate look-up tables. stimulus strength is measured in units of
contrast, de   ned as the difference between the highest and lowest inten-
sities, divided by the sum of the two.

drifting luminance-modulated sinusoidal gratings were presented
alone or superimposed on another grating or on a noise background.
superposition was obtained by interleaving, i.e., by presenting the two
components in alternate frames. when two gratings were presented
together they had the same temporal frequency and differed in orienta-
tion and/or spatial frequency. their contrast could be varied indepen-
dently. the noise background was composed of square pixels, the size of
which was chosen for each cell to be approximately one-fourth of the
spatial period of
the optimal grating. occasionally we used one-
dimensional noise (bars rather than squares). the intensity of each

figure 1. two models of simple cell function. a, the linear model,
composed of a linear stage (receptive    eld) and a recti   cation stage. the
7
linear stage performs a weighted sum of the light intensities over local
space and recent time. this sum is converted into a positive    ring rate by
the recti   cation stage. recti   cation is a nonlinearity, so the    linear

heeger & carandini    94; lampl et al    01; touryan et al    02; rust et al    05; finn & ferster    07

cortical mechanisms 
of invariant recognition
c1 complex units
(1) half-recti   cation and summing over phases at 
each location for tolerance to contrast reversal

8622 j. neurosci., november 1, 1997, 17(21):8621   8644

(   )2

+

(   )2

+...

(3) selective max-like pooling 
over nearby positions and scales 
for tolerance to 2d 
transformations
increase in tolerance to position 

c1

local max over 
pool of s1 cells

carandini et al.     linearity and id172 in simple cells

(2) gain control / divisive id172

increase in tolerance to scale

local max over 
pool of s1 cells

s1

bromide (norcuron, 0.1 mgzkg    1zhr    1) in lactated ringer   s solution with
dextrose (5.4 ml/hr). the pupils were dilated and accommodation par-
alyzed with topical atropine. the corneas were protected with zero
power gas-permeable contact lenses; supplementary lenses were chosen
to focus the eyes on a tangent screen plotting table set up at a distance
of 57 in. to maintain the animal in good physiological condition during
experiments (typically 72   96 hr), intravenous supplementation of 2.5%
dextrose/lactated ringer   s was given at 5   15 ml/hr. animals received
daily injections of a broad-spectrum antibiotic (bicillin) as well as an
anti-in   ammatory agent (dexamethasone) to prevent cerebral edema.

stimuli
stimuli were generated by a truevision atvista board operating at a
resolution of 582     752 and a frame rate of 106 hz, the output of which
was directed to a nanao t560i monitor (mean luminance, 72 cd/m 2,
subtending 10   25   of visual angle). nonlinearities in the relation be-
tween applied voltage and phosphor luminance were compensated by
appropriate look-up tables. stimulus strength is measured in units of
contrast, de   ned as the difference between the highest and lowest inten-
sities, divided by the sum of the two.

c1

drifting luminance-modulated sinusoidal gratings were presented
alone or superimposed on another grating or on a noise background.
superposition was obtained by interleaving, i.e., by presenting the two
components in alternate frames. when two gratings were presented
together they had the same temporal frequency and differed in orienta-
tion and/or spatial frequency. their contrast could be varied indepen-
dently. the noise background was composed of square pixels, the size of
which was chosen for each cell to be approximately one-fourth of the
spatial period of
the optimal grating. occasionally we used one-
dimensional noise (bars rather than squares). the intensity of each

figure 1. two models of simple cell function. a, the linear model,
composed of a linear stage (receptive    eld) and a recti   cation stage. the
7
linear stage performs a weighted sum of the light intensities over local
space and recent time. this sum is converted into a positive    ring rate by
the recti   cation stage. recti   cation is a nonlinearity, so the    linear

heeger & carandini    94; lampl et al    01; touryan et al    02; rust et al    05; finn & ferster    07

g
y

cortical mechanisms of 
invariant recognition

 
x
e
p
m
o
c
 

 
s
e
p
m
a
x
e

 
t
c
e
b
o

 
.
s
n
o
g
e
r

u
m
i
t
s

a
o

e
h

e
h

a
r

e
h

e
h

t
 
f

 
i
l

o

o

o

 
,

i
t

 
l

o

n

4

 
.

t

f

t

 

 

t

 

t

 

t

t

l

j

 

 

t

 

 

l

i

i

e
y

 
,

l

 
x
e
p
m
o
c

n
w
o
r
b

 
,
r

b

 
;

n
e
e
r
g

 
s
e
r
u

t

a
e

f

 
l

a
c

 

s
e
r
u
t
a
e
f

 

t
c
e
j
b
o

 

x
e
l
p
m
o
c

 

o
t

 

s
e
s
n
o
p
s
e
r

 
.

1
1

 
.

g
f

i

 

t

i

 
r
o
i
r
e
n
a

t

 

t

i

 
r
o
i
r
e
t
s
o
p

 

4
v

 

2
v

 

y
u
z
t
%
@

 
)

kobatake & tanaka 1994 

8

 
f

o

a
m

t

u
a
e

m

t

i

t

 

e
c
n
e
d
v
e

i

 
s
a

 
l

a
e
p
p
a

 
r
o
i
r
e
n
a

t

 

d
n
a

 

4
v

 

n

i

 
t

h
g
m

i

i

 
s
h
t

 
.
)
0
1

 
.

i

g
f
(

 
s
e
c
n
a
v
d
a

 
s
e
r
u
a
e

t

f

 
f

o

 

l

e
p
m
a
s

 

e
h

t

 
t

a
h

t

 

e
m
u
s
s
a

 

o

t

 

n
o
s
a
e
r

 

o
n

 
s

i

 

e
r
e
h

t

 

t

i

 
r
o
i
r
e
t
n
a

i

 
d
e
n
m
a
x
e

 
n
e
e
b

l

 
y
s
u
o
v
e
r
p

i

 
e
v
a
h

 
s
e
s
n
o
p
s
e
r

 
l
l

e
c

 
r
o

f

 
s
e
r
u
a
e
f

t

 
n
o
i
t
a
r
g
e
t
n

i

 
,
r
e
v
e
w
o
h

 
;
2
7
9
1

 
.
l
a
 
t
e

 
a
k
a
n
a
t
(

 
4
v

 
d
n
a

 
,

t

i

 
r
o
i
r
e
t
s
o
p

 
,
 )
1

 

9
9
1

 
.
l

a

 
t

e

 
.
l
a

 
t
e

 
s
s
o
r
g

 
;
4
8
9
1

 
.
l
a

 
t
e

 

e
n
o
m
s
e
d

i

(

 

t

i

 
r
o
i
r
e
n
a

t

 
n

i

 

e
h

t

 

d
e
w
o
h
s

 
,
s

l
l

e
c

 
l

i

a
u
d
v
d
n

i

i

 

e
h

t

 
f

o

 

e
s
n
o
p
s
e
r

 

m
u
m

 
s
s
e
n
e
v
i
t
c
n
i
t
s
d

i

i

 
g
n
y
r
a
v
 
f
o

 
y
t
i
v
i
t
c
e
e
s

l

 

h

t
i

w

 
s

l
l

e
c

 
r
o
i
r
e
t
s
o
p

 

m
o
r
f

 

d
n
a

 

4
v

 

o

t

 

2
v

 

m
o
r
f

 
s
e
g
n
a
h
c

i

 
t
n
e
n
m
o
r
p

 
l
a
c
i
t
i
r
c

 
e
h
t

 
h
g
u
o
h
t
l

a

 
.

t

i

 
r
o
i
r
e
t
s
o
p

 

d
n
a

 

4
v

 

n

i

 
t

u
b

 
,

e
v
i
t
c
n
i
t

 

l

i

d
e
g
n
m
r
e
t
n

i

e
c

 

e
h

t

 
,
r
e
h
a
r

t

 
.
s
a
e
r
a

 

e
h

t

 
f

o

 
s
t
u
p
u
o

t

 

t

d
e
n
e
s
e
r
p
e
r

 
s

l
l

e
c

 
d
e
n
r
u
t

 
h
c
h
w

i

 
,
y
t
i
v
i
t
c
e
e
s

l

 
e
h
t

 
f
o

 
s
s
e
n
e
v
i
t
c
n

i
t
s
d

i

 

e
h

t

o
h
s

 
,

t

h
p
e
d

 
s
u
o
i
r
a
v

 
t

a

 

l

d
e
p
m
a
s

l

 
y
m
o
d
n
a
r

 

e
r
e
w

 
h
c
h
w

i

 
d
e
i
f
i
t
n
a
u
q
 
s
a
w

 
,
4
v

 
d
n
a

 

t

i

 
r
o
i
r
e
t
s
o
p

 

n

i

 

e
u
s
s

i

 
y
e
k
 
a

 

e
b

 

o

t

v

 

1
a
e
r
a
-
a
r
t
n

i

t

 
t
s
e
a
e
r
g

 

e
h

t

 

d
e
w
o
h
s

 

x
a
m

/
,
,
 ,

s

 

o
i
t
a
r

 
e
h
t

k
r
o
w
e
n

t

 
l

a
c
o

l

 

e
h

t

 
f

o

 
s
e
g
a
t
s

 
s
u
o
i
r
a
v
 
t

a

 
s

l
l

e
c

 

d
e
d
u
c
n

l

i

 
e
v
a
h

 
e
s
a
e
r
c
n

i

 
-
e
t
n
a

 
o
t

i

 
t
n
e
n
m
o
r
p
 

a

 
.
y
d
u
t
s

 
t
n
e
s
e
r
p

 

e
h

t

 

n

i

 

e
m

i
t

 
t
s
r
i
f

 

e
h

t

 

t

i

 
r
o
i
r
e
t
s
o
p

 

m
o
r
f

 
s
d
e
i
f

l

 

e
v
i
t

p
e
c
e
r

 

e
h

t

 
f

o

 

e
z
s

i

 

e
h
t

 
n

i

 

a
k
a
n
a
t

 
,
 )
1

 

9
9
1

 
t
u
o

 
r
o
f

u
s
s
a

 

e
w

 
f
i

 
.
)
0
1

 

d
n
a

 

8

 
.
s
g
f
(

i

 

4
v

 

d
n
a

 

t

i

 
r
o
i
r
e
t
s
o
p

 
n

i

 
y
t
e

c

 
f

o

 

l

e
p
m
a
s

 

m
o
d
n
a
r

 

a

 
,
s
n
o

i
t
c
e
n
n
o
c

 
l

a
c
i
t
r
o
c
o
c
i
t
r
o
c

 
n

i

 
t

u
b

 
s
k
r
o
w
e
n

t

 
l

a
c
o

l

 

n

i

 

i

d
e
n
m
r
e
e
d

t

 
s

i

 
y
t
i
v
i
t
c
e
e
s

l

 
e
h
t

 
t
a
h
t

 
f
o

 
t
e

 
a
k
a
n
a
t

 
;
9
7
9
1

 
s
s
o
r
g

 
d
n
a

 
e
n
o
m
s
e
d

i

(

 
s
t
l

u
s
e
r

i

 
s
u
o
v
e
r
p

 
e
h
t

 
n
o
i
t
a
m

r
i
f
n
o
c

 
r
e
h
t
a
r
 
s

i

i

 
s
h
t

 
t
u
b

 
,

d
e
v
r
e
s
b
o

 

o
s
a

l

 
s
a
w

 

t

i

 
r
o
i
r

a
v

 

h

t
i

w

 
s

l
l

e
c

 

e
d
u
c
n

l

i

 

l

d
u
o
h
s

 
k
r
o
w
e
n

t

 
l

a
c
o

l

 

h
c
u
s
 
e
n
o

 

m
o
r
f

 
f
o
 

%
2

l

 
y
n
o

 
t
a
h
t

 
d
e
t
r
o
p
e
r

l

 
y
s
u
o
v
e
r
p

i

 
s
r
o
h
u
a

t

 

e
h

t

 

e
h

t

 

o

t

 

e
s
o
c

l

 

t

d
e
a
c
o

l

 
l
l

e
c
 

a

 
.
y
t
i
v
i
t
c
e
e
s
 
f

l

o

l

 
y
t
i
x
e
p
m
o
c

t

a
e

f

 
y
r
a
m

i
r
p

 

e
m
o
s
 

o

t

 
y

l
l

i

a
m
x
a
m

 

d
n
o
p
s
e
r

 

l

d
u
o
h
s

 
d
n
e

 
g
n

i

 
t
u
p

 

t

i

 
r
o
i
r
e
t
s
o
p

 
n

i

 
e
s
o
h
t

 
f
o

 

%
2
1

 
d
n
a

 

4
v

 

n

i

 
s

l
l

e
c

 

i

e
v
s
n
o
p
s
e
r

 
t
e

 
a
k
a
n
a
t
(

 
s
e
r
u
t
a
e
f

 
t
c
e
b
o

j

l

 
x
e
p
m
o
c
 

o

t

 

d
e
d
n
o
p
s
e
r

l

 
y
e
v
i
t
c
e
e
s

l

 

a

e
s

 
t

a

 
,

e
r
u
a
e

t

f

 
l

a
n

i
f

 

e
h

t

 
f

o

 
t

n
e
n
o
p
m
o
c
 

a

 

o

t

 
s
d
n
o
p
s
e
r
r
o
c

 
t
a
h
t

 
-
o
r
p

 
r
e
t
a
e
r
g

 
t
a
h
t

 
d
n
u
o
f
 
e
w

 
y
d
u
t
s

 
t

n
e
s
e
r
p

 

e
h

t

 

n

i

 
.
)
1

 

9
9
1

 
.
l
a

 
r
e
h
a
r

t

 

d
n
o
p
s
e
r

 

l

d
u
o
h
s
 

d
n
e

 
t

u
p
u
o

t

 

e
h

t

 

o

t

 

e
s
o
c

l

 
d
e
t
a
c
o

l

 
n

i

 

%
9
4

 
d
n
a

 
4
v

 
n

i

 

%
8
3

 
,
.
e
.
i

 
,
s
a
e
r
a

 

e
s
e
h

t

 

n

i

 
s

l
l

e
c
 
f

o

 

n
o

i
t
r
o
p

 

t

d
e
a
c
o

l

 
l
l

e
c
 
a

 

d
n
a

 
,

e
r
u
a
e

t

f

 

t

d
e
a
r
g
e
n

t

i

 
l

a
n

i
f

 

e
h

t

 
o
t

l

 
y
e
v
i
t

 
-

m
o
c

 
d
e
r
i
u
q
e
r

 
,
)
o

l

 
.
g
f

i

 
,
5
7
.
0

 

<

 

x
a
m

/
,
,
,

s

(

 

t

i

 
r
o
i
r
e
t
s
o
p

a
s

 

e
h
t

 
.
y
t
r
e
p
o
r
p

 

i

t

e
a
d
e
m
r
e
n

t

i

 

n
a

 

w
o
h
s

 

l

d
u
o
h
s

l

 
e
d
d
m

i

 
t
a
h
t

 
d
n
u
o
f

 
e
w

 
.
n
o
i
t
a
v
i
t
c
a

i

 
l
a
m
x
a
m

 
r
i
e
h

t

 
r
o

f

 
s
e
r
u
a
e

t

f

 
x
e
p

l

t

r
e
n
a

 

m
o
r
f

 

e
s
o
h

t

 
t

o
n

 
t

u
b

 

t

i

 
r
o
i
r
e
t
s
o
p

 

d
n
a

 

4
v

 

m
o
r
f

 
s
g
n

i
l

p

 
-
e
r

 
g
n
o
r
t
s

l

 
y
e
t
a
r
e
d
o
m

 
d
e
w
o
h
s

 
s
a
e
r
a

 

e
s
e
h

t

 

n

i

 
s

l
l

e
c

 
y
n
a
m

u
a
p

l

 
s

i

 

n
o

i
t

p
m
u
s
s
a

 
l

a

i
t
i

n

i

 

e
h
t

 
.

n
o

i
t
i

d
n
o
c

 
s
h

i

t

 
d
e

l
l
i
f
l
u
f

 

t

i

 

m
u
m
x
a
m

i

 
e
h
t
 
s
a

 
l
l

e
w
 
s
a

l

 
s
u
u
m
i
t
s

 

l

e
p
m
s

i

 

e
m
o
s

 

o

t

 
s
e
s
n
o
p
s

 
s
n
o

i
t
c
e
n
n
o
c

i

 
c
s
n
i
r
t
n

i

 

d
e
a
c

t

i
l

p
m
o
c

 

e
h

t
 
f

o

i

 
s
s
a
b

 

e
h
t

 
n
o

 

e
d

 

t

e
n
e
r
o
l
(

 
x
e
t
r
o
c

 
l

a
r
b
e
r
e
c

 

e
h

t

 
f

o

 
s
n
o
g
e
r

i

 
l
a
c
o

l

 
e
b

l

 
e
h
t

 
e
b

i

 
t
h
g
m
 
s

l
l

e
c
 
h
c
u
s

 
.
e
r
u
t
a
e
f

 
l
a
c
i
t
i
r
c

l

 
x
e
p
m
o
c
 

e
h

t

 

o

t

 

e
s
n
o
p
s
e
r

 
h
c
h
w

i

 
n

i

 
,
y
d
u
t
s

i

 
s
u
o
v
e
r
p

 
e
h
t

 
n

i

 
   
s

l
l

e
c

 
y
r
a
m

i
r
p
   
 
s
a

 

d
e

i
f
i
s
s
a
c

l

o
c
 

e
s
e
h

t
 
f

o

 
r
e
w
o
p

 
l

a
n
o

i
t

t

a
u
p
m
o
c

 

e
h
t

 
.
)
8
8
9
1

 

d
n
u
l
 
;
8
3
9
1

 
y
b

l

 
y
e
v
i
t
a
t
i
l

a
u
q

 
y
l
t
s
o
m

 
d
e
m
r
o
f
r
e
p

 
s
a
w

 

n
o

i
t

a
c
i
f
i
s
s
a
c

l

 
e
h
t

 
f

o

 
t

a
h

t

 

n
a
h

t

t

 
r
e
a
e
r
g

 

e
b

 

l

d
u
o
h
s

 
s
e
i
r
t
i

u
c
r
i
c

 
l

a
c
o

l

 
d
e
t
a
c

i
l

p

l

 
e
p
m
s

i

 
e
m
o
s
 
o
t

 
d
e
d
n
o
p
s
e
r

 
y
e
h
t

 
e
s
u
a
c
e
b

 
,
s
e
g
r
a
h
c
s
d

i

 

g
n
i
r
a
e
h

t

 
t
s
e
g
g
u
s
 

e
w

 
s
u
h
t

 
.
s
n
o

i
t
c
e
n
n
o
c

 
l

a
c
i
t
r
o
c
o
c
i
t
r
o
c

 
p
e
t
s
-
e
n
o

 
r
e
t
u
p
m
o
c

i

 
l
a
c
e
p
s

 
a

 
f
o

 
n
o
i
t
c
u
d
o
r
t
n

i

l

p
m
o
c

 

m
r
o

f

 

o

t

 

t

d
e
a
r
g
e
n

t

i

 

e
r
a

 
s
e
r
u
a
e

t

f

 
y
r
a
m

i
r
p

 
f
o

l

 
s
a
n
g
s

i

 
e
h
t

 
d
e
t
a
t
i
l
i

c
a
f

 
s
t
n
e
m

i
r
e
p
x
e

 
t
n
e
s
e
r
p

 

e
h

t

 

e
h

t

 

n

i

 
,

o
s
a

l

 

m
e
t
s
y
s

 
.
i
l

u
m
i
t
s

i

 
c
h
p
a
r
g

 
.

t

i

 
r
o
i
r
e
t
s
o
p

 

d
n
a

 

4
v

 
f

o

 
s
k
r
o
w
e
n

t

 
l

a
c
o

l

 

n

i

 
s
e
r
u
t
a
e
f

 
-

m
o
c

 
e
v
i
t
a
t
i
t
n
a
u
q

 
e
h
t

 
d
n
a

 
i
l

u
m
i
t
s

 

e
v
i
t
c
e

f
f

e

 
f

o

 

n
o

i
t

l

a
r
o
p
x
e

c
e
r

 
l
l

a
m
s

 

e
s
e
h
t

 
.

t

i

 
r
o
i
r
e
n
a

t

 

n

i

 
s

l
l

e
c
 
f

o

 

e
s
o
h

t

 

n
a
h
t

 
r
e

l
l

a
m
s

n
e
n
o
p
m
o
c
 
f

o

 

n
o

i
t

a
r
g
e
n

t

i

 
r
o

f

 
s
u
o
e
g
a
n
a
v
d
a

t

 

e
r
a

 
s
d
e
i
f

l

 
e
v
i
t

 
f
o

 
o
t

 
e
c
n
e
s
e
r
p

 
e
h
t

 
d
e
t
r
o
p
e
r

 
)
6
8
9
1
 
(

 
.
l

a

 
t

e

 

a
k
a
n
a
t

 
,
r
e

i
l
r
a
e

 
d
e
d
n
o
p
s
e
r

 
y

l
l

a
c
i
f
i
c
e
p
s

 
t
a
h
t

 
s
u
r
y
g

 

t

e
a
n
u
e
r
p

l

 

e
h

t

 

n

i

 
s

l
l

e
c

s
t
n
e
n
o
p
m
o
c

i

v
o
r
p

 
s
d
e

l

i
f

g
e
n

t

i

 

e
h

t

 
f
i

 

e
h

t

 
f

o

 

n
o

i
t
i
s
o
p

 

e
h

t

 

i

g
n
d
r
a
g
e
r

 
n
o
i
t
a
m
r
o
f
n

i

 
-
o
r
p

l

 
e
b
a
z
s
 
a

i

 
t
a
h
t

 
d
e
t
r
o
p
e
r

 
)
3
9
9
1

 
(

 
.
l

a

 
t

e

 
t

n
a

l
l

a
g

 

e
v
i
t

p
e
c
e
r

 
l
l

a
m
s

 

h

t
i

w

 
s

l
l

e
c
 
f

o

 
s
e

i
t
i
v
i
t
c
a
 
e
s
u
a
c
e
b

 
   
.
e
r
u
t
x
e
t

 
r
o

 
e
r
u
t
c
u
r
t
s

 
l
a
n
r
e
t
n

i

l

 
r
a
u
g
e
r
r
i

 

n
a

 

h

t
i

w

 
,
y
l
t

n
e
c
e
r

 
i
l

u
m
i
t
s
   

 
.

n
o

i
t

a
r
g
e
n

t

i

 

e
h

t

 
r
o

f

 
y
r
a
s
s
e
c
e
n

 

e
b

 
y
a
m

 
h
c
h
w

i

 
c

i
l

o
b
r
e
p
y
h

 
r
o

 
c
i
r
t
n
e
c
n
o
c

 
o
t

 
d
e
d
n
o
p
s
e
r

 
s

l
l

e
c

 

4
v

 
f

o

 

n
o

i
t
r
o
p

 

e
s
o
h

t
 
s
a

 

h
c
u
s

 
s
d
e

l

i
f

 

e
v
i
t

p
e
c
e
r

 

e
g
r
a

l

 

h

t
i

w

 

d
e
r
r
u
c
c
o

 
n
o
i
t

 
-
n
e
i
r
o
 
y
n
a
 
f
o

 
s
g
n
i
t
a
r
g

i

 
t
h
g
a
r
t
s
 
o
t

 
n
a
h

t

l

 
y
g
n
o
r
t
s

 

e
r
o
m

 
s
n
r
e
t
t
a
p

i

m
s
n
a
h
c
e
m

 

t

d
e
a
c
i
t
s
h
p
o
s

i

 

e
m
o
s
 

e
b

 

l

d
u
o
h
s

 

e
r
e
h

t

 
,

t

i

 
r
o
i
r
e
t
n
a

 

t

i

 
r
o
i
r
e
t
s
o
p

 
d
n
a

 
4
v

 
n

i

 
s
e
r
u
t
a
e
f

 
l

a
c
i
t
i
r
c

 
r
u
o

 
f

o

 

e
m
o
s

 
.

n
o

i
t
a
t

s
t
n
e
n
o
p
m
o
c
 

e
h

t

 

n
e
e
w
e
b

t

 

i

p
h
s
n
o

i
t

l

a
e
r

 
l

a
n
o

i
t
i
s
o
p

i

 
r
e
t
s
g
e
r
 
o
t

 
t
u
b

 
,
s
n
r
e
t
t
a
p

 
c

i
l

o
b
r
e
p
y
h
 
r
o

 
c
i
r
t
n
e
c
n
o
c

 

e
h

t

 

o

t

 
r
o
i
r
e
n
a

t

 

n

i

 
s
d
e

l

i
f

 

e
v
i
t

p
e
c
e
r

 

e
g
r
a

l

 

e
h

t

 

d
n
a
h

 
r
e
h
t
o

 
e
h
t

 
n
o

 
.
t
n
e
g
r
e
v
d

i

 
e
r
o
m

 

e
r
e
w

 
s
e
r
u
a
e

t

f

l
i

 
r
a
m
s
 

i

e
r
e
w

 
l

a
c
i
t
i
r
c

 
r
u
o

w

 

t

i

 
r
o
i
r
e
t
s
o
p

 

d
n
a

 

4
v

 

n

i

 
s

l
l

e
c
 
f

o

 
s
d
e

l

i
f

 

e
v
i
t

p
e
c
e
r

 
e
h
t

 
.
i
l

u
m
i
t
s

 
t
n
e
r
e
f
f
i
d
 
f
o

 
s
s
e
n
e
v
i
t
c
e

f
f

e

 

e
h

t

 
f

o

 

n
o
s
i
r
a
p

 
f

o

 

e
n
o

 
.
)
1
9
9
1

 
.
l
a

x
a
m
&
s

 
f

o

 

n
o

i
t

u
b
i
r
t
s
d

i

 

e
h
t

 
?
d
e
n
a
t
t
a

i

 
)
2

 
.

t

i

 
r
o
i
r
e
t
n
a

 
n

i

 
s

l
l

e
c

i

 
d
d
 
s
a

 
,
s
e
r
u
a
e

t

f

 
t
c
e
b
o

j

l

 
x
e
p
m
o
c

 

l

e
p
m
s

i

 

o

t

 

e
s
n
o
p
s
e
r

 

m
u
m
x
a
m

i

 
-
s
d

i

 
y

l
l

a
r
e
n
e
g
 
s
a
w

 

t

i

 
r
o
i
r
e
t
n
a

 
n

i

 
s

l
l

e
c

 

e
h

t

 
f

o

 
y
t
i
v
i
t
c
e
e
s

l

 
r
a
u

l

 

e
h
t

 
y
t
i
v
i
t
c
e
e
s
 

l

e
h

t
 
s

i

 
t

i

n
o
p

 
t
a
h
w

 
t

a

 
-
c
i
t
r
a
p
 
o
t

 
y

l
l

i

a
m
x
a
m

 
d
e
d
n
o
p
s
e
r

 
,
2
v

 

n

i

 
t

o
n

 
t

u
b

 
,

t

i

 
r
o
i
r
e
t
s
o
p

cortical mechanisms of 
invariant recognition

kobatake & tanaka 1994 

9

simple units

template matching 
bell-shape like tuning

~    and   

complex units

invariance pooling
max-like operation

~   or   

selective pooling 
mechanisms

riesenhuber & poggio 1999 (building on 
fukushima    80 and hubel & wiesel    62) 

10

tuning in the visual cortex

dayan & abbott    01

logothetis pauls & poggio    95

tuning for orientation in v1

tuning around 3d views in it

11

max-like computation in the visual cortex

lampl et al    04

gawne & martin    02

max-like in v1

max-like in v4

12

mechanisms of 
invariant recognition

    unit parameters (i.e., rf sizes, 

pooling ranges, etc) constrained by 
available experimental data

    unsupervised learning of (hierarchy) 
of frequent image fragments during 
development (in intermediate 
stages) shared across categories

    rapid object recognition based on 
bottom-up activation of hierarchy of 
image fragments that allow category 
info. to be decoded by higher level 
categorization processes 

13

it

v1

mechanisms of 
invariant recognition

    unit parameters (i.e., rf sizes, 

pooling ranges, etc) constrained by 
available experimental data

    unsupervised learning of (hierarchy) 
of frequent image fragments during 
development (in intermediate 
stages) shared across categories

    rapid object recognition based on 
bottom-up activation of hierarchy of 
image fragments that allow category 
info. to be decoded by higher level 
categorization processes 

14

it

v1

mechanisms of 
invariant recognition

    unit parameters (i.e., rf sizes, 

pooling ranges, etc) constrained by 
available experimental data

    unsupervised learning of (hierarchy) 
of frequent image fragments during 
development (in intermediate 
stages) shared across categories

    rapid object recognition based on 
bottom-up activation of hierarchy of 
image fragments that allow category 
info. to be decoded by higher level 
categorization processes 

14

category 
selective 

units

linear decoder

it

v1

simple units

   frequent image features   
i.e., correlation in space

selective pooling 
mechanisms

complex units

   frequent image transformations   

i.e., correlation in time

masquelier serre thorpe & poggio    07
see also foldiak    91; hietanen et al    92; wallis et al    93; 

wachsmuth et al    94; wallis & rolls    97; wiskott & 

sejnowski    02; einhauser et al    02; spratling    05 and many 

others

15

learning the invariance 
from temporal continuity

7x7 rf

on

off

4 c1

lgn

4 x 4 cortical columns
16 s1 in each

figure 3: overview of the speci   c implementation of the
hubel & wiesel v1 model used. lgn-like on- and off-cen-
ter units are modeled by difference-of-gaussian (dog)    lters.
simple units (denoted s1) sample their inputs from a 7 7 grid
of lgn-type afferent units. simple s1 units are organized in
cortical hypercolumns (4   4 grid, 3 pixels apart, 16 s1 units
per hypercolumn). at the next stage, 4 complex units c1 cells

16

figure 4: reconstructed s1 preferred stimuli for each one of
the 4   4 cortical hypercolumns (on this    gure the position
of the reconstructions within a cortical column is arbitrary).

movie courtesy of wolfgang einhauser

learning the invariance 
from temporal continuity

7x7 rf

on

off

4 c1

lgn

4 x 4 cortical columns
16 s1 in each

figure 3: overview of the speci   c implementation of the
hubel & wiesel v1 model used. lgn-like on- and off-cen-
ter units are modeled by difference-of-gaussian (dog)    lters.
simple units (denoted s1) sample their inputs from a 7 7 grid
of lgn-type afferent units. simple s1 units are organized in
cortical hypercolumns (4   4 grid, 3 pixels apart, 16 s1 units
per hypercolumn). at the next stage, 4 complex units c1 cells
receive inputs from these 4 4 16 s1 cells. this paper focuses
on the learning of the s1 to c1 connectivity.

7x7 rf

on

off

lgn

and sejnowski, 1998; stringer and rolls, 2000; rolls and
milward, 2000; wiskott and sejnowski, 2002; einh  auser
et al., 2002; spratling, 2005).

4 c1

4 x 4 cortical columns
16 s1 in each

however, as pointed out by spratling (2005), the trace
rule by itself is inappropriate when multiple objects
are present in a scene: it cannot distinguish which in-
put corresponds to which object, and it may end-up
combining multiple objects in the same representation.
hence most trace-rule based algorithm require stimuli
to be presented in isolation (f  oldi  ak, 1991; oram and
f  oldi  ak, 1996; wallis, 1996; stringer and rolls, 2000),
and would fail to learn from cluttered natural input se-
quences.

figure 3: overview of the speci   c implementation of the
hubel & wiesel v1 model used. lgn-like on- and off-cen-
ter units are modeled by difference-of-gaussian (dog)    lters.
simple units (denoted s1) sample their inputs from a 7 7 grid
of lgn-type afferent units. simple s1 units are organized in
cortical hypercolumns (4   4 grid, 3 pixels apart, 16 s1 units
per hypercolumn). at the next stage, 4 complex units c1 cells

to solve this problem, spratling made the hypothe-
sis that the same object could not activate two distinct
inputs, hence co-active units necessarily correspond to

16

figure 4: reconstructed s1 preferred stimuli for each one of
the 4   4 cortical hypercolumns (on this    gure the position
of the reconstructions within a cortical column is arbitrary).
most units show a gabor-like selectivity similar to what has
been previously reported in the literature (see text).

and complex c1 units (see fig. 3), which constitutes a
direct implementation of the hubel and wiesel (1962)
model of striate cortex (see box 1). the goal of a c1 unit
is to pool over s1 units with the same preferred orien-
tation, but with shifted receptive    elds. in this context
our hypothesis becomes:    in a given neighborhood, the
dominant orientation is likely to be the same from one
frame to another   . as our results suggests (see later),
this constitutes a reasonable hypothesis, which leads to
appropriate pooling.

2 results
we tested the proposed learning mechanisms in a
3 layer feedforward network mimicking the lateral
movie courtesy of wolfgang einhauser
geniculate nucleus (lgn) and v1 (see fig. 3). details
of the implementation can be found in section 4.

figure 4: reconstructed s1 preferred stimuli for each one of
the 4   4 cortical hypercolumns (on this    gure the position
of the reconstructions within a cortical column is arbitrary).

learning the invariance 
from temporal continuity

7x7 rf

on

off

4 c1

lgn

4 x 4 cortical columns
16 s1 in each

figure 3: overview of the speci   c implementation of the
hubel & wiesel v1 model used. lgn-like on- and off-cen-
ter units are modeled by difference-of-gaussian (dog)    lters.
simple units (denoted s1) sample their inputs from a 7 7 grid
of lgn-type afferent units. simple s1 units are organized in
cortical hypercolumns (4   4 grid, 3 pixels apart, 16 s1 units
per hypercolumn). at the next stage, 4 complex units c1 cells
receive inputs from these 4 4 16 s1 cells. this paper focuses
on the learning of the s1 to c1 connectivity.

7x7 rf

on

off

lgn

and sejnowski, 1998; stringer and rolls, 2000; rolls and
milward, 2000; wiskott and sejnowski, 2002; einh  auser
et al., 2002; spratling, 2005).

4 c1

4 x 4 cortical columns
16 s1 in each

however, as pointed out by spratling (2005), the trace
rule by itself is inappropriate when multiple objects
are present in a scene: it cannot distinguish which in-
put corresponds to which object, and it may end-up
combining multiple objects in the same representation.
hence most trace-rule based algorithm require stimuli
to be presented in isolation (f  oldi  ak, 1991; oram and
f  oldi  ak, 1996; wallis, 1996; stringer and rolls, 2000),
and would fail to learn from cluttered natural input se-
quences.

s1 units

figure 3: overview of the speci   c implementation of the
hubel & wiesel v1 model used. lgn-like on- and off-cen-
ter units are modeled by difference-of-gaussian (dog)    lters.
simple units (denoted s1) sample their inputs from a 7 7 grid
of lgn-type afferent units. simple s1 units are organized in
cortical hypercolumns (4   4 grid, 3 pixels apart, 16 s1 units
per hypercolumn). at the next stage, 4 complex units c1 cells

to solve this problem, spratling made the hypothe-
sis that the same object could not activate two distinct
inputs, hence co-active units necessarily correspond to

16

figure 4: reconstructed s1 preferred stimuli for each one of
the 4   4 cortical hypercolumns (on this    gure the position
of the reconstructions within a cortical column is arbitrary).
most units show a gabor-like selectivity similar to what has
been previously reported in the literature (see text).

and complex c1 units (see fig. 3), which constitutes a
direct implementation of the hubel and wiesel (1962)
model of striate cortex (see box 1). the goal of a c1 unit
is to pool over s1 units with the same preferred orien-
tation, but with shifted receptive    elds. in this context
our hypothesis becomes:    in a given neighborhood, the
dominant orientation is likely to be the same from one
frame to another   . as our results suggests (see later),
this constitutes a reasonable hypothesis, which leads to
appropriate pooling.

2 results
we tested the proposed learning mechanisms in a
3 layer feedforward network mimicking the lateral
movie courtesy of wolfgang einhauser
geniculate nucleus (lgn) and v1 (see fig. 3). details
of the implementation can be found in section 4.

figure 4: reconstructed s1 preferred stimuli for each one of
the 4   4 cortical hypercolumns (on this    gure the position
of the reconstructions within a cortical column is arbitrary).

learning the invariance 
from temporal continuity

7x7 rf

on

off

4 c1

lgn

4 x 4 cortical columns
16 s1 in each

figure 3: overview of the speci   c implementation of the
hubel & wiesel v1 model used. lgn-like on- and off-cen-
ter units are modeled by difference-of-gaussian (dog)    lters.
simple units (denoted s1) sample their inputs from a 7 7 grid
of lgn-type afferent units. simple s1 units are organized in
cortical hypercolumns (4   4 grid, 3 pixels apart, 16 s1 units
per hypercolumn). at the next stage, 4 complex units c1 cells
receive inputs from these 4 4 16 s1 cells. this paper focuses
on the learning of the s1 to c1 connectivity.

7x7 rf

on

off

lgn

and sejnowski, 1998; stringer and rolls, 2000; rolls and
milward, 2000; wiskott and sejnowski, 2002; einh  auser
et al., 2002; spratling, 2005).

4 c1

4 x 4 cortical columns
16 s1 in each

however, as pointed out by spratling (2005), the trace
rule by itself is inappropriate when multiple objects
are present in a scene: it cannot distinguish which in-
put corresponds to which object, and it may end-up
combining multiple objects in the same representation.
hence most trace-rule based algorithm require stimuli
to be presented in isolation (f  oldi  ak, 1991; oram and
f  oldi  ak, 1996; wallis, 1996; stringer and rolls, 2000),
and would fail to learn from cluttered natural input se-
quences.

s1 units

figure 3: overview of the speci   c implementation of the
hubel & wiesel v1 model used. lgn-like on- and off-cen-
ter units are modeled by difference-of-gaussian (dog)    lters.
simple units (denoted s1) sample their inputs from a 7 7 grid
of lgn-type afferent units. simple s1 units are organized in
cortical hypercolumns (4   4 grid, 3 pixels apart, 16 s1 units
per hypercolumn). at the next stage, 4 complex units c1 cells

to solve this problem, spratling made the hypothe-
sis that the same object could not activate two distinct
inputs, hence co-active units necessarily correspond to

16

c1 unit

figure 4: reconstructed s1 preferred stimuli for each one of
the 4   4 cortical hypercolumns (on this    gure the position
of the reconstructions within a cortical column is arbitrary).
most units show a gabor-like selectivity similar to what has
been previously reported in the literature (see text).

and complex c1 units (see fig. 3), which constitutes a
direct implementation of the hubel and wiesel (1962)
model of striate cortex (see box 1). the goal of a c1 unit
is to pool over s1 units with the same preferred orien-
tation, but with shifted receptive    elds. in this context
our hypothesis becomes:    in a given neighborhood, the
dominant orientation is likely to be the same from one
frame to another   . as our results suggests (see later),
this constitutes a reasonable hypothesis, which leads to
appropriate pooling.

2 results
we tested the proposed learning mechanisms in a
3 layer feedforward network mimicking the lateral
movie courtesy of wolfgang einhauser
geniculate nucleus (lgn) and v1 (see fig. 3). details
of the implementation can be found in section 4.

figure 4: reconstructed s1 preferred stimuli for each one of
the 4   4 cortical hypercolumns (on this    gure the position
of the reconstructions within a cortical column is arbitrary).

to    nd the model capable of recogniz-
ing complex images,27 performing at a 
level  comparable  to  some  of  the  best 
existing  systems  on  the  caltech-101 
image  database  of  101  object  catego-
ries  with  a  recognition  rate  of  about 
55%  (chance  level  <  1%);  see  serre  et 
al.27  and  mutch  and  lowe.19  a  related 
system  with  fewer  layers,  less  invari-
ance, and more units had an even bet-
ter  recognition  rate  on  the  caltech 

we  also  developed  an  automated 
system  for  parsing  street-scene  im-
ages27  based  in  part  on  the  class  of 
models described earlier. the system 
recognizes seven different object cat-
egories   cars,  pedestrians,  bikes, 
skies,  roads,  buildings,  trees   from 
natural  images  of  street  scenes  de-
spite  very  large  variations  in  shape 
(such  as  trees  in  summer  and  winter 
and suvs and compact cars from any 

recognition  and 
search  in  videos  is  an  emerging  ap-
plication of id161, whereby 
neuroscience  may  again  suggest  an 
avenue  for  approaching  the  problem. 
in 2007, we developed an initial mod-
el  for  recognizing  biological  motion 
and  actions  from  video  sequences 
based on the organization of the dor-
sal stream of the visual cortex,13 which 
is  critically  linked  to  the  processing 
of  motion  information,  from  v1  and 
mt  to  higher  motion-selective  areas 
mst/fst  and  sts.  the  system  relies 
on  computational  principles  similar 
to  those  in  the  model  of  the  ventral 
stream described earlier but that start 
with  spatio-temporal     lters  modeled 
after motion-sensitive cells in the pri-

psychophysics on human subjects. 

type of data

area
psych. rapid animal categorization

v4

v1

loc
pfc
it

    an initial attempt to reverse-

engineer the ventral stream of the 
visual cortex

face inversion effect
face processing (fmri)
differential role of it and pfc in categorization
tuning and invariance properties
read out for object category
average effect in it
max operation
tuning for two-bar stimuli
two-spot interaction
tuning for boundary conformation
tuning for cartesian and non-cartesian gratings
simple and complex cells tuning properties
max operation in subset of complex cells

    large-scale (108 units), spans 

several areas of the visual cortex

ref. biol. data ref. model data
(1)
(2)
(3)
(5)
(5)
(8,9)
(10)
(5)
(8,9)
(8)
(8,15)
(8)
(8)
(5)

(1)
(2)
(3)
(4)
(6)
(7)
(10)
(11)
(12)
(13)
(14)
(16)
(17   19)
(20)

    some similarities with state-of-the-
art id161 systems based 
on hierarchies of reusable parts 
(geman, bienstock, yuille, zhu, etc) 
as well as convolutional and deep 
belief networks (lecun, hinton, 
bengio, ng, etc)

1.  serre, t., oliva, a., and poggio, t. proc. natl. acad. sci.104, 6424 (apr. 2007). 
2.  riesenhuber, m. et al. proc. biol. sci. 271, s448 (2004). 
3.  jiang, x. et al. neuron 50, 159 (2006). 
4.  freedman, d.j., riesenhuber, m., poggio, t., and miller, e.k. journ. neurosci. 23, 5235 (2003). 
5.  riesenhuber, m. and poggio, t. nature neuroscience 2, 1019 (1999). 
6.  logothetis, n.k., pauls, j., and poggio, t. curr. biol. 5, 552 (may 1995). 
7.  hung, c.p., kreiman, g., poggio, t., and dicarlo, j.j. science 310, 863 (nov. 2005). 
8.  serre, t. et al. mit ai memo 2005-036 / cbcl memo 259 (2005).
9.  serre, t. et al. prog. brain res. 165, 33 (2007). 
10.  zoccolan, d., kouh, m., poggio, t., and dicarlo, j.j. journ. neurosci. 27, 12292 (2007). 
11.  gawne, t.j. and martin, j.m. journ. neurophysiol. 88, 1128 (2002). 
12.  reynolds, j.h., chelazzi, l., and desimone, r. journ. neurosci.19, 1736 (mar. 1999). 
13.  taylor, k., mandon, s., freiwald, w.a., and kreiter, a.k. cereb. cortex 15, 1424 (2005). 
14.  pasupathy, a. and connor, c. journ. neurophysiol. 82, 2490 (1999). 
15.  cadieu, c. et al. journ. neurophysiol. 98, 1733 (2007). 
16.  gallant, j.l. et al. journ. neurophysiol. 76, 2718 (1996). 
17.  schiller, p.h., finlay, b.l., and volman, s.f. journ. neurophysiol. 39, 1288 (1976). 
18.  hubel, d.h. and wiesel, t.n. journ. physiol. 160, 106 (1962). 
19.  de valois, r.l., albrecht, d.g., and thorell, l.g. vision res. 22, 545 (1982). 
20.  lampl, i., ferster, d., poggio, t., and riesenhuber, m. journ. neurophysiol. 92, 2704 (2004). 

es,13    nding that the model of the dor-
sal  stream  competed  with  a  state-of-
the-art action-recognition system (that 
outperformed many other systems) on 
all three data sets.13 a direct extension 
of this approach led to a computer sys-
tem for the automated monitoring and 

feedforward hierarchical 
model of object recognition

this model produced a large dictionary 
of optic-   ow patterns that seems con-
sistent with the response properties of 
cells in the medial temporal (mt) area 
in  response  to  both  isolated  gratings 
and  plaids,  or  two  gratings  superim-
posed on one another. 

17

comparison w| v4

pasupathy & connor    01

tuning for curvature and 
boundary conformations?

stronger 
facilitation

stronger 
suppression

18

no parameter    tting!

 v4 neuron tuned to 
boundary conformations

 most similar model c2 unit

modi   ed from (pasupathy & connor 1999)

serre kouh cadieu knoblich kreiman & poggio    05

0.7
0.56
0.42
0.28
0.14
0

19

no parameter    tting!

 v4 neuron tuned to 
boundary conformations

 most similar model c2 unit

modi   ed from (pasupathy & connor 1999)

   = 0.78

serre kouh cadieu knoblich kreiman & poggio    05

0.7
0.56
0.42
0.28
0.14
0

19

0.8

0.6

0.4

0.2

0

 

e
c
n
a
m
r
o
f
r
e
p
n
o
i
t
a
c
!
i
s
s
a
c

l

size:
position:

train

test

a)

1

it

model

b)b)

1

 

e
c
n
a
m
r
o
f
r
e
p
n
o
i
t
a
c
!
i
s
s
a
c

l

0.8

0.6

0.4

0.2

0
0.06

0.14

0.40
area ratio

0.69

3.4o
center

3.4o
center

1.7o
center

6.8o
center

3.4o
2o horz.

3.4o
4o horz.

c)c)

1

model: serre et al    05 
experimental data: hung* kreiman*et al    05

0.4

 

e
c
n
a
m
r
o
f
r
e
p
n
o
i
t
a
c
!
i
s
s
a
c

l

0.8

0.6

0.2

0

1

invariance in it

4

16

64
number of units

256

20

0.8

0.6

0.4

0.2

0

 

e
c
n
a
m
r
o
f
r
e
p
n
o
i
t
a
c
!
i
s
s
a
c

l

size:
position:

train

test

a)

1

it

model

b)b)

1

 

e
c
n
a
m
r
o
f
r
e
p
n
o
i
t
a
c
!
i
s
s
a
c

l

0.8

0.6

0.4

0.2

0
0.06

0.14

0.40
area ratio

0.69

3.4o
center

3.4o
center

1.7o
center

6.8o
center

3.4o
2o horz.

3.4o
4o horz.

c)c)

1

model: serre et al    05 
experimental data: hung* kreiman*et al    05

0.4

 

e
c
n
a
m
r
o
f
r
e
p
n
o
i
t
a
c
!
i
s
s
a
c

l

0.8

0.6

0.2

0

1

invariance in it

4

16

64
number of units

256

21

bottom-up processing 
and rapid categorization

image

interval 

image-mask

mask
1/f noise

80 ms

animal present

or not ?

20 ms

30 ms isi

22

   

d
 
e
c
n
a
m
r
o
f
r
e
p

2.6

2.2

1.8

1.4

1.0

animals

natural 
distractors

artificial 
distractors

model
human observers

head
head

body medium far
close-body medium-body

far-body

serre oliva & poggio    07 

ongoing model extensions

    edges/object boundaries happen at 

image discontinuities, e.g,:
- surface re   ectance (hue)
- depth (binocular vision)
- surface orientation
- material properties
- etc

f i g . 1 . 8
the low order derivative operators lead to a small number to
two-dimensional receptive field types.

a

d

g

y

t

  

j

vx

x

x

x

b

e

h

y

t

  

k

vx

x

x

x

c

f

i

l

y

t

  

vx

x

x

x

x

x
source: adelson & bergen (1991)

f i g . 1 . 9
the same receptive field structures produce different visual
measurements when placed along different planes in plenoptic
space.

x

duu  +  dvv.  we  do  not  wish  to  suggest  that  center-   
surround  structures  in  biological  visual  systems  are  nec-
essarily constructed in this  way;  we  are  simply  describing
the  formal  relationships  among  the  various  types  of
operators.)
visual mechanisms for extracting plenoptic structure
the  visual  mechanisms  suggested  by  this  approach  in-
clude  some  familiar  receptive  field  structures,  as  well  as
some  that  are  more  novel  (cf.  young,  1989).  figure  l.9
shows  some  examples  of  idealized  receptive  fields  that    
one  could  construct  to  analyze  change  in  various  direc-  
tions  in  plenoptic  space   ignoring  implementational  con-
straints  for  the  moment.  these  particular  receptive  fields
represent only two dimensions  of  information,  and  one  of
the dimensions  shown  is  always  the  spatial  dimension  x.
all receptive fields have an implicit  shape in the full set of
plenoptic dimen-sions; they are assumed  to  be  bloblike  in
all of the dimensions not shown.

although  these  measurements  do  not  precisely  corre-
spond  to  properties  that  are  described  by  ordinary  lan-  
guage, it is possible to assign approximate labels for them:
(a)  horizontally  oriented  structure  (edgelike);  (b)  vertically
oriented  structure  (edgelike);  (c)  diagonally  oriented  struc-
ture  (edgelike);  (d)  full-field  brightening,  (e)  static  spatial
structure; (f) moving edgelike structure; (g) full-field bluish
color; (h) achromatic edgelike structure; (i)  spatiochromatic
variation; (j) full-field  intensity  change  with  eye  position;
(k)  absence  of  horizontal  parallax  (edgelike  structure);  (1)
horizontal parallax (edgelike structure).

plenoptic  measurements  in  the  human  visual
system
we  have  presented  an  idealized  view  of  the  basic  struc-   
ture  available  in  the  plenoptic  function,  and  of  the  mea-
surements  that  early  vision  could  employ  to  characterize
that  structure.  we  now  ask  how  these  measurements,  or
closely  related  measurements,  might  be  implemented  in   
the human visual system.  (while we refer  to  the  "human"
visual  system,  much  of  the  evidence  upon  which  our
analysis  is  based  comes  from  physiological  studies  of    
other mammals. we will assume without arguing the point
that  the  early  stages  of  processing  are  similar  across
species.)

23

10

the task of vision

color processing in the ventral 
stream

parameters    tted to 

psychophysics data on color 

perception

r/g

r/c

y/b

lum

eccv-12 submission id 1052

spatio-chromatic opponent operator

, )s(cid:84)(cid:77)
( ,

s
l
e
n
n
a
h
c
 
r
o
l
o
c

24

(cid:166)

r(cid:90)

g(cid:90)

b(cid:90)

half-squaring

r g(cid:14)
(cid:16)(cid:16)

/

divisive

 id172

so

half-wave

do 

r g(cid:16)

(cid:166)

2 ,c (cid:77)

(cid:265)

(cid:266)

zhang barhomi & serre    12

fig. 2. spatio-chromatic opponent descriptor: individual r, g, b color channels are

color processing in the ventral 
stream

eccv
#1052

10

eccv-12 submission id 1052

    so/do approach improves on 

eccv
all recognition and 
#1052
segmentation datasets tested 
as compared to existing color 
representations
eccv
#1052
    color datasets 

360

361

360

361

362

eccv
#1052

405

a. gradient used in sift

eccv-12 submission id 1052

361

364

363

362

365

364

363

360

color

table 2. recognition performance on soccer team and 17-category    ower dataset.
the data in each feature type are percentage of classi   cation accuracy (data inside
the parentheses are the initial performance reported by [10, 31] using the same features
in a bag-of-words scheme.)

soccer team

shape both

eccv
#1052

flower
shape both

366
a. gradient used in sift
367

eccv-12 submission id 1052
b. gabor filters used in hmax

406
fig. 4. filters and their components used in the spatio-chromatic opponent operator.
407
(a) gradient in the y directions used in sift computation [14]. (b) gabor    lters used
408
in hmax [15]. (c) gaussian derivatives used in segmentation [19]. from left to right
409
410
are: the original    lter and the individual center and surround components used to
411
process the input color channels. note that additional    lters (not shown) at multiple
412
orientations, scales and phases are also used in hmax and segmentation.
413
414

9
c. gaussian derivatives used in segmentation

method
color
hue/sift
69 (67) 43 (43) 73 (73) 58 (40) 65 (65) 77 (79)
opp/sift
69 (65) 43 (43) 74 (72) 57 (39) 65 (65) 74 (79)
sosift/dosift
82
sohmax/dohmax 87

    pascal challenge

83
365
89
366
a. gradient used in sift
367

table 3. recognition performance on pascal voc 2007 dataset. performance corre-
sponds to the mean average precision (ap) over all 20 classes. performance (in paren-
thesis) corresponds to the best performance reported in [37, 6]

eccv-12 submission id 1052
fig. 4. filters and their components used in the spatio-chromatic opponent operator.
68
(a) gradient in the y directions used in sift computation [14]. (b) gabor    lters used
77
in hmax [15]. (c) gaussian derivatives used in segmentation [19]. from left to right
are: the original    lter and the individual center and surround components used to
process the input color channels. note that additional    lters (not shown) at multiple
orientations, scales and phases are also used in hmax and segmentation.

c. gaussian derivatives used in segmentation
on these two datasets, unlike the pascal voc dataset, color cues are
372
417
highly diagnostic of object category. individual color descriptors perform better
fig. 4. filters and their components used in the spatio-chromatic opponent operator.
approaches that do not rely on any prior knowledge about object categories. it
418
373
was shown, however, that the performance of various color descriptors could be
sodohmax
than their grayscale counterparts on both datasets, and so- and do- (sift
(a) gradient in the y directions used in sift computation [14]. (b) gabor    lters used
419
further improved on this dataset (up to 96% performance) when used in con-
374
in hmax [15]. (c) gaussian derivatives used in segmentation [19]. from left to right
and hmax) descriptors signi   cantly boost the performance compar-
420
junction with semantic color features (i.e., color names) and bottom-up
375
are: the original    lter and the individual center and surround components used to
421
ing to other color descriptors (compare the performance under color vs.
and top-down attentional mechanisms [32]. whether such an approach would
422
376
process the input color channels. note that additional    lters (not shown) at multiple
similarly boost the performance of the so and do descriptors should be further
25
shape in table 2). the hue and opponent angle color descriptors (huesift and
table 4. recognition performance on scene categorization
423
studied.
orientations, scales and phases are also used in hmax and segmentation.
377
oppsift in table 2) have shown to be the best descriptors for use in combina-
424
the results obtained on the    ower dataset are qualitatively very similar (see

on these two datasets, unlike the pascal voc dataset, color cues are
highly diagnostic of object category. individual color descriptors perform better
than their grayscale counterparts on both datasets, and so- and do- (sift

zhang barhomi & serre    12

43 (44.0) 46.5 (33.3/39.8) 46.8 (30.1/36.4)

huesift opponentsift csift

b. gabor filters used in hmax

method sift

40 (38.4) 41

sodosift

43 (42.5)

79
83

66
76

69
73

362

363

364

365

366

367

368

369

368

370

371

368

369

370

371

372

373

369

ap

11

450

451

452

453

454

459

458

455

456

457

415

416

color processing in the ventral 
stream

eccv-12 submission id 1052

eccv
#1052
15

eccv
#1052

630

631

632

633

634

635

636

a. gradient used in sift

eccv-12 submission id 1052

eccv
#1052

360

361

362

363

364

365

366
a. gradient used in sift
367

360

361

362

363

364

365

368

eccv
#1052

360

361

362

363

364

365

366

367

368

369

26

1

0.9

0.8

366
a. gradient used in sift
367

eccv-12 submission id 1052
b. gabor filters used in hmax

637
fig. 4. filters and their components used in the spatio-chromatic opponent operator.
638
639
(a) gradient in the y directions used in sift computation [14]. (b) gabor    lters used
640
in hmax [15]. (c) gaussian derivatives used in segmentation [19]. from left to right
641
are: the original    lter and the individual center and surround components used to
642
process the input color channels. note that additional    lters (not shown) at multiple
643
orientations, scales and phases are also used in hmax and segmentation.
644
645

9
c. gaussian derivatives used in segmentation

369

370

b. gabor filters used in hmax

a. color-texton map vs. grayscale texton map

fig. 4. filters and their components used in the spatio-chromatic opponent operator.
(a) gradient in the y directions used in sift computation [14]. (b) gabor    lters used
in hmax [15]. (c) gaussian derivatives used in segmentation [19]. from left to right
are: the original    lter and the individual center and surround components used to
process the input color channels. note that additional    lters (not shown) at multiple
orientations, scales and phases are also used in hmax and segmentation.

fig. 4. filters and their components used in the spatio-chromatic opponent operator.
(a) gradient in the y directions used in sift computation [14]. (b) gabor    lters used
in hmax [15]. (c) gaussian derivatives used in segmentation [19]. from left to right
are: the original    lter and the individual center and surround components used to
process the input color channels. note that additional    lters (not shown) at multiple
orientations, scales and phases are also used in hmax and segmentation.

c. gaussian derivatives used in segmentation
on these two datasets, unlike the pascal voc dataset, color cues are
648
highly diagnostic of object category. individual color descriptors perform better
649
than their grayscale counterparts on both datasets, and so- and do- (sift
650
and hmax) descriptors signi   cantly boost the performance compar-
651
652
ing to other color descriptors (compare the performance under color vs.
653
shape in table 2). the hue and opponent angle color descriptors (huesift and
654
oppsift in table 2) have shown to be the best descriptors for use in combina-
655

on these two datasets, unlike the pascal voc dataset, color cues are
highly diagnostic of object category. individual color descriptors perform better
than their grayscale counterparts on both datasets, and so- and do- (sift

zhang barhomi & serre    12

original textons

color textons

371

372

373

374

375

376

377

368

369

370

371

372

373

646

647

disparity processing

source: qian    94

27

disparity processing

source: qian    94

27

disparity processing

28

riesen & serre unpublished data
see sasaki et al    10 for qualitatively similar results

disparity processing

28

riesen & serre unpublished data
see sasaki et al    10 for qualitatively similar results

dorsal    motion    pathway

...

...

ventral    shape    pathway

3 

c 

100 

0 
0 

v4/it

v1/v2

nonlagged 

v1/mt

sts

lgn 
a 
200 

3 
simple, separable 
nonlagged 
250 

lagged 

mt/mst

b 

250 

125 

g. deangelis, i. ohzawa and r. freeman --- receptive-field dynamics
fig. 3.  spatiotemporal rf profiles (x-t
plots) for neurons recorded from the
lgn and striate cortex of the cat.  in
each panel, the horizontal axis represents
space (x) and the vertical axis represents
time (t).  for panels a-f, solid contours de-
limit  bright-excitatory  regions,  whereas
dashed contours indicate dark-excitatory
regions.  to construct these x-t plots, 1-d
rf profiles (see fig. 2) are obtained, at
finely spaced time intervals (5-10ms), over
a range of values of t.  these 1-d profiles
are then "stacked up" to form a surface,
lgn 
which is smoothed and plotted as a contour
a 
map (for details, see refs. 8,34).  (a) an x-
200 
t profile is shown here for a typical on-
center, non-lagged x-cell from the lgn.
for t<50 ms, the rf has a bright-excitatory
100 
center  and  a  dark-excitatory  surround.
however, for t>50 ms, the rf center be-
e
m
comes dark-excitatory and the surround
t
becomes bright-excitatory.  similar spa-
0 
0 
3 
tiotemporal profiles are presented else-
where9,36.  (b) an x-t plot is shown for an
simple, separable 
on-center, lagged x-cell.  note that the
c 
second temporal phase of the profile is
250 
strongest.  (c) an x-t profile for a simple
cell with a space-time separable rf.  for
t<100 ms, the rf has a dark-excitatory
125 
subregion to the left of a bright-excitatory
subregion.  for t>100 ms, each subregion
reverses polarity, so that the bright-excita-
tory region is now on the left.  similar x-t
0 
0 
6 
data are presented elsewhere8,30,34.  (d)
data for another simple cell with an approx-
separable 
simple, inseparable 
imately separable x-t profile.  (e) data are
complex 
e 
f 
shown for a simple cell with a clearly insep-
space-time rfs
200 
300 
arable x-t profile.  note how the spatial ar-
200 
rangement of bright- and dark-excitatory
dark 
subregions (i.e., the spatial phase of the

0 
0 
g. deangelis, i. ohzawa and r. freeman --- receptive-field dynamics
fig. 3.  spatiotemporal rf profiles (x-t
plots) for neurons recorded from the
lgn and striate cortex of the cat.  in
each panel, the horizontal axis represents
space (x) and the vertical axis represents
time (t).  for panels a-f, solid contours de-
limit  bright-excitatory  regions,  whereas
dashed contours indicate dark-excitatory
regions.  to construct these x-t plots, 1-d
rf profiles (see fig. 2) are obtained, at
finely spaced time intervals (5-10ms), over
a range of values of t.  these 1-d profiles
are then "stacked up" to form a surface,
which is smoothed and plotted as a contour
map (for details, see refs. 8,34).  (a) an x-
figure 13.1
t profile is shown here for a typical on-
center, non-lagged x-cell from the lgn.
neural model for the processing of dynamic face stimuli. form and motion features are extracted in two
for t<50 ms, the rf has a bright-excitatory
separate pathways. the addition of asymmetric recurrent connections at the top levels makes the units se-
center and a dark-excitatory surround.
lective for temporal order. the highest level consists of neurons that fuse form and motion information.
however, for t>50 ms, the rf center be-
comes dark-excitatory and the surround
becomes bright-excitatory.  similar spa-
tiotemporal profiles are presented else-
where9,36.  (b) an x-t plot is shown for an
on-center, lagged x-cell.  note that the
second temporal phase of the profile is
strongest.  (c) an x-t profile for a simple
cell with a space-time separable rf.  for
t<100 ms, the rf has a dark-excitatory

0 
0 
non-separable 
space-time rfs

6 
simple, inseparable 
e 
200 

f 
300 

lagged 
400 

)
s
m
t  

)
t
s
m
t  

 
,
e
m
t

x
0 
0 

0 
0 

v1

v1

0 
0 

bright 

0 
0 

0 
0 

125 

200 

100 

150 

250 

400 

200 

125 

g 

d 

x

d 

b 

29

 
,

t

6 

4 

6 

3 

6 

(

(

i

i

dorsal    motion    pathway

...

...

ventral    shape    pathway

3 

c 

100 

0 
0 

v4/it

v1/v2

nonlagged 

v1/mt

sts

lgn 
a 
200 

3 
simple, separable 
nonlagged 
250 

lagged 

mt/mst

b 

250 

125 

g. deangelis, i. ohzawa and r. freeman --- receptive-field dynamics
fig. 3.  spatiotemporal rf profiles (x-t
plots) for neurons recorded from the
lgn and striate cortex of the cat.  in
each panel, the horizontal axis represents
space (x) and the vertical axis represents
time (t).  for panels a-f, solid contours de-
limit  bright-excitatory  regions,  whereas
dashed contours indicate dark-excitatory
regions.  to construct these x-t plots, 1-d
rf profiles (see fig. 2) are obtained, at
finely spaced time intervals (5-10ms), over
a range of values of t.  these 1-d profiles
are then "stacked up" to form a surface,
lgn 
which is smoothed and plotted as a contour
a 
map (for details, see refs. 8,34).  (a) an x-
200 
t profile is shown here for a typical on-
center, non-lagged x-cell from the lgn.
for t<50 ms, the rf has a bright-excitatory
100 
center  and  a  dark-excitatory  surround.
however, for t>50 ms, the rf center be-
e
m
comes dark-excitatory and the surround
t
becomes bright-excitatory.  similar spa-
0 
0 
3 
tiotemporal profiles are presented else-
where9,36.  (b) an x-t plot is shown for an
simple, separable 
on-center, lagged x-cell.  note that the
c 
second temporal phase of the profile is
250 
strongest.  (c) an x-t profile for a simple
cell with a space-time separable rf.  for
t<100 ms, the rf has a dark-excitatory
125 
subregion to the left of a bright-excitatory
subregion.  for t>100 ms, each subregion
reverses polarity, so that the bright-excita-
tory region is now on the left.  similar x-t
0 
0 
6 
data are presented elsewhere8,30,34.  (d)
data for another simple cell with an approx-
separable 
simple, inseparable 
imately separable x-t profile.  (e) data are
complex 
e 
f 
shown for a simple cell with a clearly insep-
space-time rfs
200 
300 
arable x-t profile.  note how the spatial ar-
200 
rangement of bright- and dark-excitatory
dark 
subregions (i.e., the spatial phase of the

0 
0 
g. deangelis, i. ohzawa and r. freeman --- receptive-field dynamics
fig. 3.  spatiotemporal rf profiles (x-t
plots) for neurons recorded from the
lgn and striate cortex of the cat.  in
each panel, the horizontal axis represents
space (x) and the vertical axis represents
time (t).  for panels a-f, solid contours de-
limit  bright-excitatory  regions,  whereas
dashed contours indicate dark-excitatory
regions.  to construct these x-t plots, 1-d
rf profiles (see fig. 2) are obtained, at
finely spaced time intervals (5-10ms), over
a range of values of t.  these 1-d profiles
are then "stacked up" to form a surface,
which is smoothed and plotted as a contour
map (for details, see refs. 8,34).  (a) an x-
figure 13.1
t profile is shown here for a typical on-
center, non-lagged x-cell from the lgn.
neural model for the processing of dynamic face stimuli. form and motion features are extracted in two
for t<50 ms, the rf has a bright-excitatory
separate pathways. the addition of asymmetric recurrent connections at the top levels makes the units se-
center and a dark-excitatory surround.
lective for temporal order. the highest level consists of neurons that fuse form and motion information.
however, for t>50 ms, the rf center be-
comes dark-excitatory and the surround
becomes bright-excitatory.  similar spa-
tiotemporal profiles are presented else-
where9,36.  (b) an x-t plot is shown for an
on-center, lagged x-cell.  note that the
second temporal phase of the profile is
strongest.  (c) an x-t profile for a simple
cell with a space-time separable rf.  for
t<100 ms, the rf has a dark-excitatory

0 
0 
non-separable 
space-time rfs

6 
simple, inseparable 
e 
200 

f 
300 

lagged 
400 

)
s
m
t  

)
t
s
m
t  

 
,
e
m
t

x
0 
0 

0 
0 

v1

v1

0 
0 

bright 

0 
0 

0 
0 

125 

200 

100 

150 

250 

400 

200 

125 

g 

d 

x

d 

b 

29

 
,

t

6 

4 

6 

3 

6 

(

(

i

i

action recognition with a dorsal stream model

weizmann	
   human	
   ac*on	
   

(9	
   classes)

kth	
   human	
   ac*ons	
   

(6	
   classes)

dollar	
   et	
   al	
      05

jhuang	
   et	
   al	
      07

kth	
   human

ucsd	
   mice

weiz.	
   human

81.3 %

75.6 %

86.7 %

91.6 %

79.0 %

96.3 %

jhuang	
   serre	
   wolf	
   &	
   poggio	
      07

ye   et	
   &	
   wolf	
      09

ye   et	
   &	
   wolf	
      09	
   

wang	
   &	
   mori	
      08	
   

30

automated rodent behavioral 
analysis

image source: shmuel & grinvald    96

31

jhuang serre et al    07    10; kuehne jhuang et al    11

automated rodent behavioral 
analysis

image source: shmuel & grinvald    96

31

jhuang serre et al    07    10; kuehne jhuang et al    11

automated rodent behavioral 
analysis

article

nature communications  |    doi:  10.1038/ncomms1064 

the hierarchy. !  ese motion features are obtained by combining the 
response of v1-like a" erent motion units that are tuned to di" erent 
directions of motion ( fig. 2e ). 

 !  e  output  of  this  hierarchical  preprocessing  module  consists 
of  a  dictionary  of  about  300  space-time  motion  features  (s2 / c2 
layers,  fig. 2e ) that are obtained by matching the output of the s1 / c1 
layers with a dictionary of motion-feature templates. !  is basic dic-
tionary of motion-feature templates corresponds to discriminative 
motion features that are learnt from a training set of videos contain-
ing labelled behaviours of interest (the      clipped database     ), through 
a feature selection technique. 

 to optimize the performance of the system for the recognition 
of  mouse  behaviours,  several  key  parameters  of  the  model  were 
adjusted. !  e parameters of the spatio-temporal # lters in the # rst 
stage (e.g., their preferred speed tuning and direction of motion, the 
nature of the nonlinear transfer function used, the video resolution 
32
and so on) were adjusted so as to maximize performance on the 
     clipped database     . 

    table 1      |    accuracy of the system. 

  our system

  

  cleversys 
commercial 

system  

  human 

(      annotator 
group 2      )  

 77.3 %  /  76.4 %   

 60.9 %  /  64.0 %   

 71.6 %  /  75.7 %   

 78.3 %  /  77.1 %   

 61.0 %  /  65.8 %   

  

    
        set b      (1.6   h 
of video) 
        full database      
(over 10   h of video) 

     accuracies are reported as averaged across frames / across behaviours (underlined numbers, 
computed as the average of the diagonal entities in  figure 3  confusion matrix; chance level is 
12.5% for an eight-class classi    cation problem).   

 assessing  the  accuracy  of  the  system  is  a  critical  task.  !  ere-
jhuang serre et al    07    10; kuehne jhuang et al    11
fore, we made two comparisons: (i) between the resulting system 
and commercial so% ware ( homecagescan 2.0 ,  cleversys inc. ) for 
mouse home-cage behaviour classi# cation and (ii) between the sys-

visual control of navigation

target

obstacles

r
e

t

e
m
n

 

i
 

y

10

8

6

4

2

0
 
   2

viewer-centered 

visual scene

v1-like unit 
responses

distance: p=528.5459   h=1.0007      parameter:  d1x20   c7x35   c8x20

12

 

obstacle/target
locomotion model
hmax model
human
model

   1

0

x in meter

1

2

motion direction 

decoding

33

bonneaud bruggeman olfers irwin & serre in prep

    feedforward hierarchical learning 

architectures seem consistent:
- with anatomy and physiology of 

visual cortex 

- with human psychophysics 

during rapid categorization tasks

    but incomplete models of visual 

processing
- suffer from    clutter problem    and 
cannot parse and interpret visual 
scenes

- possible role for cortical feedback 

and shifts of attention

summary

34

    what should you care about 

biology?
- i.e., why not learning everything? 

    parameter space is prohibitively 

large
- biology might give you at least a 

starting point

summary

35

deep learning in the 
visual cortex
thomas serre
brown university

i.  fundamentals of primate vision
ii. computational mechanisms of rapid 

recognition and feedforward processing

iii. beyond feedforward processing: 

attentional mechanisms and cortical 
feedback

36

