introduction to mcmc

for deep learning

roadmap:
| motivation: probabilistic modelling
| monte carlo, importance sampling
| id150, m{h
| auxiliary variable methods

iain murray
school of informatics, university of edinburgh

overheard on google+

\a probabilistic framework isn   t

necessary,

or even always useful. . .

. . . retro-(cid:12)tting our new models to some
probabilistic framework has little bene(cid:12)t"

drawing model fantasies

| insight into models
| improve learning
| communication

polygonal random (cid:12)elds

paskin and thrun (2005)

natural patch fantasies

from osindero and hinton (2008)

creating training data

microsoft kinect

(shotton et al., 2011)

shallow learning: id79 applied to fantasies

future deep learning?

scienti(cid:12)c deep models

hogg and fergus, 2011

hogg&fergus/cdi-typei:auni   edprobabilisticmodelofastronomicalimaging2imageobjecttelescopeorientationtelescopelocationtime/datetelescopepsfdetectornoisedetectorbiascosmicraydetector spectralresponsecosmicray priorpixelstelescopefovatmosphericmodelatmospheric distortionskybrightnesskey: telescope/ atmosphere/ detector/ star/ galaxynoisetrue pixelsdistortionimagepositionstargalaxystarpositionstardistancestarspectrummilkywaystellaremissionpriormilky way formation modelmetalllicitypriorpositionpriormass priorstellar emissionpriorgalaxy appearancegalaxy shapestar/galaxypriorgalaxy spectrumangulardistributionpriorstellar populationpriormorphological priorgalaxy formationmodelslarge scale structure priorstarmassstarmetallicityintrinsicstarbrightnessgalaxy positionpositionpriorgalaxy priorsstar/galaxy/otherswitchstarageagepriorfigure1:ouruni   edgraphicalmodel(alsoknownasabayesiannetwork[27]),forastro-nomicalimagedata.itintegratesinaprincipledframework:large-scalecosmologicalmodelsofgalaxyandmilkywayformation;galaxyappearancemodels;spectralemissionmodelsanddetailedcamera,skyandtelescopemodels.theshadedovalnodesareobservedvari-ables(i.e.,theirvaluesareknown)whiletheunshadedonesareunobservedandhencewillbeinferredfromtherawastronomicaldata.thesquarenodesrepresentpriors,typicallyinformedbywell-understoodphysicsmodels.thearrowsrepresentdependenciesbetweenvariablesinthemodel(andthelackthereofcorrespondtoassumptionsofindependence).theconditionalid203distributionswithinthemodel(whichdetailhowaparticularnodedependsonthosevariableswhichpointtoit)arenotshown,butwillbedescribedinthetext.therectanglesrefertoreplicationsofvariables,e.g.animagewillcontainmanystars/galaxies.therealizationofthismodelistheultimategoaloftheproject,butinitialworkwillfocusonsub-piecesofthemodel.this   gureisbestviewedincolor.roadmap

| probabilistic models

| simple monte carlo

importance sampling

| id115 (mcmc)

id150, m{h

| auxiliary variable methods

swendsen{wang, hmc

sampling simple distributions

use library routines for
univariate distributions
(and some other special cases)

this book (free online) explains
how some of them work

http://luc.devroye.org/rnbookindex.html

sampling from densities

draw points uniformly under the curve:

id203 mass to left of point (cid:24) uniform[0,1]

p(x)xx(2)x(3)x(1)x(4)rejection sampling

sampling from (cid:25)(x) using tractable q(x):

figure credit: ryan p. adams

simple monte carlo

z

f (x)p (x) dx

sx

(cid:25) 1
s

f (x(s));

s=1

x(s)(cid:24) p (x)

unbiased. variance (cid:24) 1=s

aside: marginalization

z

function of subset,

f (xc)p (xc) dxc

simulate all variables anyway:

i (cid:25) 1
s

f (x(s)

c );

x(s)(cid:24) p (x)

sx

s=1

importance sampling

rewrite integral: expectation under simple distribution q:

z

f (x) p (x) dx =

f (x)

p (x)
q(x)

q(x) dx;

(cid:25) 1
s

f (x(s))

p (x(s))
q(x(s))

;

x(s) (cid:24) q(x)

z

sx

s=1

simple monte carlo applied to any integral.

unbiased and independent of dimension?

importance sampling (2)

z

sx

previous slide assumed we could evaluate p (x) = p (cid:3)(x)=zp
f (x) p (x) dx (cid:25) zqzp
sx

; x(s) (cid:24) q(x)

f (x(s))

1
s

s=1

(cid:25)

(cid:3)
(cid:3)

(cid:3)(cid:3)1
s

(cid:3)
(cid:3)

(cid:3)

s=1

f (x(s))

p (cid:3)(x(s))
| {z }
q(cid:3)(x(s))
w(cid:3)(s)
w(cid:3)(s)
s0 w(cid:3)(s0)

(cid:1)1
(cid:1)
(cid:1)
s
(cid:1)

p
p
s w(cid:3)(s)

this estimator is consistent but biased
exercise: prove that zp =zq (cid:25) 1

s

rejection sampling rbms

product of experts:

| draw fantasy from each expert

| if they happen to be exactly the same, accept!

application to large problems

approximations scale badly with dimensionality

example: p (x) = n (0; i); q(x) = n (0; (cid:27)2i)

rejection sampling:
requires (cid:27) (cid:21) 1. fraction of proposals accepted = (cid:27)(cid:0)d

(cid:16) (cid:27)2

(cid:17)d=2 (cid:0) 1

importance sampling:

var[p (x)=q(x)] =
p
in(cid:12)nite / unde(cid:12)ned variance if (cid:27) (cid:20) 1=

2(cid:0)1=(cid:27)2

2

unbiased positive estimators

01020304050wp(w)01020304050wp(w)roadmap

| probabilistic models

| simple monte carlo

importance sampling

| id115, mcmc

id150, m{h

| auxiliary variable methods

swendsen{wang, hmc

target distribution

p (x) = 1
z

e

(cid:0)e(x)

e.g. x =

local moves

.

#

& q(x0; x)

markov chain exploration

!

!

#

goal: a markov chain,
xt (cid:24) t (xt  xt(cid:0)1), such that:
p (x(t)) = e(cid:0)e(x(t))=z for large t.

invariant/stationary condition

if x(t(cid:0)1) is a sample from p ,

x(t) is also a sample from p .

0  x)p (x) = p (x

0)

t (x

x

x

ergodicity

unique invariant distribution

if    forget    starting point, x(0)

quick review

mcmc: biased random walk exploring a target dist.

x(s) (cid:24) t(cid:0)x(s)  x(s(cid:0)1)(cid:1)

markov steps,

mcmc gives approximate,
correlated samples

ep [f ] (cid:25) 1
s

f (x(s))

sx

s=1

t must leave target invariant
t must be able to get everywhere in k steps

id150

pick variables in turn or randomly,

and resample p (xijxj6=i)

ti(x0  x) = p (x

i j xj6=i) (cid:14)(x0
0

j6=i (cid:0) xj6=i)

z1z2ll?id150 correctness

p (x) = p (xi j xni) p (xni)
simulate by drawing xni, then xi j xni

draw xni: sample x, throw initial xi away

reverse operators

if t leaves p (x) stationary, de(cid:12)ne a reverse operator

r(x  x

0) =

p
t (x0  x) p (x)
x t (x0  x) p (x)

t (x0  x) p (x)

p (x0)

:

=

a necessary condition: there exists r such that:

0  x) p (x) = r(x  x

0) p (x

0);

t (x

8x; x
0

:

if r = t , known as detailed balance (not necessary)

balance condition

t (x0   x) p (x) = r(x   x0) p (x0)

x

implies that p (x) is left invariant:
0  x) p (x) = p (x
0)

t (x

x

x
(cid:8)(cid:8)(cid:8)(cid:8)(cid:8)(cid:8)(cid:8)(cid:8)(cid:8)(cid:8)(cid:8)(cid:8)(cid:8)(cid:8)(cid:8)(cid:8)(cid:8)(cid:8)*1
r(x  x

0)

x

metropolis{hastings

arbitrary proposals (cid:24) q:
0; x) p (x) 6= q(x; x

q(x

0) p (x

0)

prml, bishop (2006)

satis(cid:12)es detailed balance by rejecting moves:
1; p (x0) q(x;x0)
p (x) q(x0;x)

0  x) =

t (x

8><>:q(x0; x) min
(cid:16)

: : :

(cid:17)

x0 6= x
x0 = x

00.511.522.5300.511.522.53metropolis{hastings

transition operator
(cid:15) propose a move from the current state q(x0; x), e.g. n (x; (cid:27)2)
(cid:15) accept with id203 min
(cid:15) otherwise next state in chain is a copy of current state

)q(x;x0
)
p (x)q(x0;x)

1; p (x0

(cid:16)

(cid:17)

notes
(cid:15) can use p (cid:3) / p (x); normalizer cancels in acceptance ratio
(cid:15) satis(cid:12)es detailed balance (shown below)
(cid:15) q must be chosen so chain is ergodic
!
!

0  x) = p (x) (cid:1) q(x

p (x) (cid:1) t (x

 
 

; x); p (x

p (x)q(x

; x) min

= min

(cid:16)

1;

0

0

0

= p (x

0

) (cid:1) q(x; x

0

) min

1;

= p (x

0

) (cid:1) t (x  x

0

)

p (x0
)q(x; x0
)
p (x)q(x0; x)
p (x)q(x0
; x)
p (x0)q(x; x0)

(cid:17)

0

)

)q(x; x

matlab/octave code for demo

function samples = dumb metropolis(init, log ptilde, iters, sigma)

d = numel(init);

samples = zeros(d, iters);

state = init;

lp state = log ptilde(state);

for ss = 1:iters

% propose

prop = state + sigma*randn(size(state));

lp prop = log ptilde(prop);

if log(rand) < (lp prop - lp state)

% accept

state = prop;

lp state = lp prop;

end

samples(:, ss) = state(:);

end

step-size demo
explore n (0; 1) with di(cid:11)erent step sizes (cid:27)

sigma = @(s) plot(dumb_metropolis(0, @(x)-0.5*x*x, 1e3, s));

sigma(0.1)

99.8% accepts

sigma(1)

68.4% accepts

sigma(100)

0.5% accepts

01002003004005006007008009001000   4   202401002003004005006007008009001000   4   202401002003004005006007008009001000   4   2024di(cid:11)usion time

adapted from mackay (2003)

generic proposals use
q(x0; x) = n (x; (cid:27)2)
(cid:27) large ! many rejections
(cid:27) small ! slow di(cid:11)usion:
(cid:24) (l=(cid:27))2 iterations required

qplan mcmc strategy

come up with good proposals q(x0; x)

combine transition operators:

x1 (cid:24) ta((cid:1)  x0)
x2 (cid:24) tb((cid:1)  x1)
x3 (cid:24) tc((cid:1)  x2)
x4 (cid:24) ta((cid:1)  x3)
x5 (cid:24) tb((cid:1)  x4)

. . .

roadmap

| probabilistic models

| simple monte carlo

importance sampling

| id115 (mcmc)

id150, m{h

| auxiliary variable methods

swendsen{wang, hmc

auxiliary variables

z

the point of mcmc is to sum out variables, yet:

f (x)p (x) dx =

f (x)p (x; v) dx dv

f (x(s));

x; v (cid:24) p (x; v)

z

sx

s=1

(cid:25) 1
s

we might want to introduce v if:
(cid:15) p (xj v) and p (v j x) are simple
(cid:15) p (x; v) is otherwise easier to navigate

(cf rbms, martens and sutskever 2010)

swendsen{wang (1987)

seminal algorithm using auxiliary variables

swendsen{wang

edwards and sokal (1988) identi(cid:12)ed and generalized the
\fortuin-kasteleyn-swendsen-wang" auxiliary variable joint
distribution that underlies the algorithm.

hamiltonian monte carlo (1987)

de(cid:12)ne a joint distribution:

p (x; v) / e

(cid:0)e(x)e

(cid:0)v>v=2 = e

(cid:0)h(x;v)

markov chain operators
(cid:15) gibbs sample velocity
(cid:15) simulate hamiltonian dynamics
{ conservation of energy means p (x; v) = p (x0; v0)
{ metropolis acceptance id203 is 1

example / warning

j|j|||||||||j
10
0 1

(

proposal:

xt+1 = 9xt + 1;
0 < xt < 1
xt+1 = (xt (cid:0) 1)=9; 1 < xt < 10

(cid:18)

accept move with id203:

min

1;

p (x0) q(x; x0)
p (x) q(x0; x)

(cid:19)

(cid:18)

(cid:19)

p (x0)
p (x)

(wrong!)

= min

1;

leap-frog dynamics

a discrete approximation to hamiltonian dynamics:

vi(t + (cid:15)

2) = vi(t) (cid:0) (cid:15)

@xi
xi(t + (cid:15)) = xi(t) + (cid:15)vi(t + (cid:15)
2)

2

@e(x(t))

pi(t + (cid:15)) = vi(t + (cid:15)

2) (cid:0) (cid:15)

2

@e(x(t + (cid:15)))

@xi

(cid:15) h is not conserved
(cid:15) transformation has unit jacobian
(cid:15) acceptance id203 becomes
min[1; exp(h(v; x) (cid:0) h(v0; x0))]

hamiltonian monte carlo

the algorithm:
(cid:15) gibbs sample velocity (cid:24) n (0; i)
(cid:15) simulate l leapfrog steps
(cid:15) accept with id203
min[1; exp(h(v; x) (cid:0) h(v0; x0))]

the original name is hybrid monte carlo, with reference
to the \hybrid" dynamical simulation method.

hamiltonian dynamics

recommended reading:
mcmc using hamiltonian dynamics, radford m. neal, 2011.
handbook of id115
http://www.cs.toronto.edu/~radford/ftp/ham-mcmc.pdf

recent developments include:
nuts: no u-turn sampler
http://arxiv.org/abs/1111.4246

riemann manifold hamiltonian monte carlo
http://www.dcs.gla.ac.uk/id136/rmhmc/

summary of auxiliary variables

| swendsen{wang
| hamiltonian (hybrid) monte carlo
| slice sampling

some of my auxiliary representation work:

doubly-intractable distributions

population methods for better mixing (on parallel hardware)

being robust to bad random number generators

slice-sampling hierarchical latent gaussian models

overview

| probabilistic models

| simple monte carlo

importance sampling

| id115 (mcmc)

id150, m{h

| auxiliary variable methods

swendsen{wang, hmc

appendix slides

finding p (xi = 1)
method 1: fraction of time xi = 1

p (xi = 1) =

i(xi = 1)p (xi) (cid:25) 1
s

x

xi

sx

s=1

i(x(s)
i );

i (cid:24) p (xi)
x(s)

p (xi = 1) =

method 2: average of p (xi = 1jxni)

x
p (xi = 1jxni)p (xni)
sx

xni
(cid:25) 1
s

s=1

p (xi = 1jx(s)ni ); x(s)ni (cid:24) p (xni)

example of \rao-blackwellization".

more generally

this is easy

x

x

f (xi)p (x) (cid:25) 1
s

sx

s=1

i =

f (x(s)

i ); x(s) (cid:24) p (x)

(cid:18)x

(cid:19)

p (xni)

f (xi)p (xijxni)

but this might be better

i =

f (xi)p (xijxni)p (xni) =

x
sx

x

(cid:25) 1
s

(cid:18)x

s=1

xi

x
(cid:19)

f (xi)p (xijx(s)ni )

xi

xni
; x(s)ni (cid:24) p (xni)

how should we run mcmc?

(cid:15) the samples aren   t independent. should we thin,
only keep every kth sample?
(cid:15) arbitrary initialization means starting iterations are
bad. should we discard a \burn-in" period?
(cid:15) maybe we should perform multiple runs?
(cid:15) how do we know if we have run for long enough?

forming estimates

can thin samples so approximately independent.
but, can use all samples.

the simple monte carlo estimator is still:

| consistent
| unbiased if the chain has \burned in"

the correct motivation to thin:

if computing f (x(s)) is expensive

in some special circumstances strategic thinning can help.

steven n. maceachern and mario peruggia, statistics & id203 letters, 47(1):91{98, 2000.
http://dx.doi.org/10.1016/s0167-7152(99)00142-x | thanks to simon lacoste-julien for the reference.

empirical diagnostics

rasmussen (2000)

recommendations

diagnostic software: r-coda

for opinion on thinning, multiple runs, burn in, etc.
charles j. geyer, statistical science. 7(4):473{483, 1992.
http://www.jstor.org/stable/2246094

slice sampling idea

sample point uniformly under curve ~p (x) / p (x)

(

p(ujx) = uniform[0; ~p (x)]
~p (x) (cid:21) u
otherwise

p(xju) /

1

0

= \uniform on the slice"

xu(x,u)  p(x)slice sampling

unimodal conditionals

(cid:15) bracket slice
(cid:15) sample uniformly within bracket
(cid:15) shrink bracket if ~p (x) < u (o(cid:11) slice)
(cid:15) accept (cid:12)rst point on the slice

xu(x,u)xu(x,u)xu(x,u)slice sampling

multimodal conditionals

(cid:15) place bracket randomly around point
(cid:15) linearly step out until bracket ends are o(cid:11) slice
(cid:15) sample on bracket, shrinking as before
satis(cid:12)es detailed balance, leaves p(xju) invariant

xu(x,u)  p(x)slice sampling

advantages of slice-sampling:
(cid:15) easy | only require ~p (x) / p (x)
(cid:15) no rejections
(cid:15) tweak params not too important

there are more advanced versions.
neal (2003) contains many ideas.

referencesfurtherreading(1/2)generalreferences:probabilisticid136usingmarkovchainmontecarlomethods,radfordm.neal,technicalreport:crg-tr-93-1,departmentofcomputerscience,universityoftoronto,1993.http://www.cs.toronto.edu/~radford/review.abstract.htmlvarious   guresandmorecamefrom(seealsoreferencestherein):advancesinmarkovchainmontecarlomethods.iainmurray.2007.http://www.cs.toronto.edu/~murray/pub/07thesis/informationtheory,id136,andlearningalgorithms.davidmackay,2003.http://www.id136.phy.cam.ac.uk/mackay/itila/patternrecognitionandmachinelearning.christopherm.bishop.2006.http://research.microsoft.com/~cmbishop/prml/speci   cpoints:ifyoudogibbssamplingwithcontinuousdistributionsthismethod,whichiomittedformaterial-overloadreasons,mayhelp:suppressingrandomwalksinmarkovchainmontecarlousingorderedoverrelaxation,radfordm.neal,learningingraphicalmodels,m.i.jordan(editor),205   228,kluweracademicpublishers,1998.http://www.cs.toronto.edu/~radford/overk.abstract.htmlanexampleofpickingestimatorscarefully:speed-upofmontecarlosimulationsbysamplingofrejectedstates,frenkel,d,proceedingsofthenationalacademyofsciences,101(51):17571   17575,thenationalacademyofsciences,2004.http://www.pnas.org/cgi/content/abstract/101/51/17571akeyreferenceforauxiliaryvariablemethodsis:generalizationsofthefortuin-kasteleyn-swendsen-wangrepresentationandmontecarloalgorithm,robertg.edwardsanda.d.sokal,physicalreview,38:2009   2012,1988.slicesampling,radfordm.neal,annalsofstatistics,31(3):705   767,2003.http://www.cs.toronto.edu/~radford/slice-aos.abstract.htmlbayesiantrainingofid26networksbythehybridmontecarlomethod,radfordm.neal,technicalreport:crg-tr-92-1,connectionistresearchgroup,universityoftoronto,1992.http://www.cs.toronto.edu/~radford/bbp.abstract.htmlanearlyreferenceforparalleltempering:markovchainmontecarlomaximumlikelihood,geyer,c.j,computingscienceandstatistics:proceedingsofthe23rdsymposiumontheinterface,156   163,1991.samplingfrommultimodaldistributionsusingtemperedtransitions,radfordm.neal,statisticsandcomputing,6(4):353   366,1996.furtherreading(2/2)software:gibbssamplingforgraphicalmodels:http://mathstat.helsinki.fi/openbugs/http://www-ice.iarc.fr/~martyn/software/jags/neuralnetworksandother   exiblemodels:http://www.cs.utoronto.ca/~radford/fbm.software.htmlcoda:http://www-   s.iarc.fr/coda/othermontecarlomethods:nestedsamplingisanewmontecarlomethodwithsomeinterestingproperties:nestedsamplingforgeneralbayesiancomputation,johnskilling,bayesiananalysis,2006.(toappear,postedonlinejune5).http://ba.stat.cmu.edu/journal/forthcoming/skilling.pdfapproachesbasedonthe   multi-canonicleensemble   alsosolvesomeoftheproblemswithtraditionaltempterature-basedmethods:multicanonicalensemble:anewapproachtosimulate   rst-orderphasetransitions,bernda.bergandthomasneuhaus,phys.rev.lett,68(1):9   12,1992.http://prola.aps.org/abstract/prl/v68/i1/p91agoodreviewpaper:extendedensemblemontecarlo.yiba.intjmodphysc[computationalphysicsandphysicalcomputation]12(5):623-656.2001.particle   lters/sequentialmontecarloarefamouslysuccessfulintimeseriesmodeling,butaremoregenerallyapplicable.thismaybeagoodplacetostart:http://www.cs.ubc.ca/~arnaud/journals.htid113xactorperfectsamplingusesmarkovchainsimulationbutsu   ersnoinitializationbias.anamazingfeatwhenitcanbeperformed:annotatedbibliographyofperfectlyrandomsamplingwithmarkovchains,davidb.wilsonhttp://dbwilson.com/exact/mcmcdoesnotapplytodoubly-intractabledistributions.forwhatthatevenmeansandpossiblesolutionssee:ane   cientmarkovchainmontecarlomethodfordistributionswithintractablenormalisingconstants,j.m  ller,a.n.pettitt,r.reevesandk.k.berthelsen,biometrika,93(2):451   458,2006.mcmcfordoubly-intractabledistributions,iainmurray,zoubinghahramanianddavidj.c.mackay,proceedingsofthe22ndannualconferenceonuncertaintyinarti   cialintelligence(uai-06),rinadechterandthomass.richardson(editors),359   366,auaipress,2006.http://www.gatsby.ucl.ac.uk/~iam23/pub/06doublyintractable/doublyintractable.pdf