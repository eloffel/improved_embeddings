   #[1]github [2]recent commits to infersent:master

   [3]skip to content

   (button)

     * why github?
       [4]features    
          + [5]code review
          + [6]project management
          + [7]integrations
          + [8]actions
          + [9]team management
          + [10]social coding
          + [11]documentation
          + [12]code hosting
          + [13]customer stories    
          + [14]security    
     * [15]enterprise
     * explore
          + [16]explore github    

learn & contribute
          + [17]topics
          + [18]collections
          + [19]trending
          + [20]learning lab
          + [21]open source guides

connect with others
          + [22]events
          + [23]community forum
          + [24]github education
     * [25]marketplace
     * pricing
       [26]plans    
          + [27]compare plans
          + [28]contact sales
          + [29]nonprofit    
          + [30]education    

   ____________________
     * in this repository all github    
       jump to    

     * no suggested jump to results

     * in this repository all github    
       jump to    
     * in this repository all github    
       jump to    

   [31]sign in [32]sign up

     * [33]watch [34]75
     * [35]star [36]1,503
     * [37]fork [38]296

[39]facebookresearch/[40]infersent

   [41]code [42]issues 11 [43]pull requests 3 [44]projects 0 [45]insights
   (button) dismiss

join github today

   github is home to over 31 million developers working together to host
   and review code, manage projects, and build software together.
   [46]sign up
   sentence embeddings (infersent) and training code for nli.
     * [47]58 commits
     * [48]3 branches
     * [49]0 releases
     * [50]fetching contributors
     * [51]view license

    1. [52]python 48.2%
    2. [53]jupyter notebook 47.7%
    3. [54]sed 2.2%
    4. [55]shell 1.9%

   (button) python jupyter notebook sed shell
   branch: master (button) new pull request
   [56]find file
   clone or download

clone with https

   use git or checkout with svn using the web url.
   https://github.com/f
   [57]download zip

downloading...

   want to be notified of new releases in facebookresearch/infersent?
   [58]sign in [59]sign up

launching github desktop...

   if nothing happens, [60]download github desktop and try again.

   (button) go back

launching github desktop...

   if nothing happens, [61]download github desktop and try again.

   (button) go back

launching xcode...

   if nothing happens, [62]download xcode and try again.

   (button) go back

launching visual studio...

   if nothing happens, [63]download the github extension for visual studio
   and try again.

   (button) go back
   [64]@aconneau
   [65]aconneau [66]fixes conflicts
   latest commit [67]bc83e21 feb 7, 2019
   [68]permalink
   type name latest commit message commit time
   failed to load latest commit information.
   [69]dataset [70]added infersent2 trained with fasttext. simplified
   model loading. add    jun 27, 2018
   [71]encoder [72]added .cuda option in demo.ipynb, clarified word
   embeddings loading. oct 4, 2018
   [73].gitignore
   [74]license
   [75]readme.md
   [76]data.py
   [77]models.py
   [78]mutils.py
   [79]train_nli.py

readme.md

infersent

   infersent is a sentence embeddings method that provides semantic
   representations for english sentences. it is trained on natural
   language id136 data and generalizes well to many different tasks.

   we provide our pre-trained english sentence encoder [80]our paper and
   our [81]senteval evaluation toolkit.

   recent changes: added infersent2 model trained on fasttext vectors and
   added max-pool option.

dependencies

   this code is written in python. dependencies include:
     * python 2/3
     * [82]pytorch (recent version)
     * nltk >= 3

download datasets

   to get snli and multinli, run (in dataset/):
./get_data.bash

   this will download and preprocess snli/multinli datasets. for macos,
   you may have to use p7zip instead of unzip.

   download [83]glove (v1) or [84]fasttext (v2) vectors:
mkdir dataset/glove
curl -lo dataset/glove/glove.840b.300d.zip http://nlp.stanford.edu/data/glove.84
0b.300d.zip
unzip dataset/glove/glove.840b.300d.zip -d dataset/glove/
mkdir dataset/fasttext
curl -lo dataset/fasttext/crawl-300d-2m.vec.zip https://dl.fbaipublicfiles.com/f
asttext/vectors-english/crawl-300d-2m-subword.zip
unzip dataset/fasttext/crawl-300d-2m.vec.zip -d dataset/fasttext/

use our sentence encoder

   we provide a simple interface to encode english sentences. see
   [85]encoder/demo.ipynb for a practical example. get started with the
   following steps:

   0.0) download our infersent models (v1 trained with glove, v2 trained
   with fasttext)[147mb]:
curl -lo encoder/infersent1.pickle https://dl.fbaipublicfiles.com/infersent/infe
rsent1.pkl
curl -lo encoder/infersent2.pickle https://dl.fbaipublicfiles.com/infersent/infe
rsent2.pkl

   note that infersent1 is trained with glove (which have been trained on
   text preprocessed with the ptb tokenizer) and infersent2 is trained
   with fasttext (which have been trained on text preprocessed with the
   moses tokenizer). the latter also removes the padding of zeros with
   max-pooling which was inconvenient when embedding sentences outside of
   their batches.

   0.1) make sure you have the nltk tokenizer by running the following
   once:
import nltk
nltk.download('punkt')

   1) [86]load our pre-trained model (in encoder/):
from models import infersent
v = 2
model_path = 'encoder/infersent%s.pkl' % v
params_model = {'bsize': 64, 'word_emb_dim': 300, 'enc_lstm_dim': 2048,
                'pool_type': 'max', 'dpout_model': 0.0, 'version': v}
infersent = infersent(params_model)
infersent.load_state_dict(torch.load(model_path))

   2) set word vector path for the model:
w2v_path = 'fasttext/crawl-300d-2m.vec'
infersent.set_w2v_path(w2v_path)

   3) build the vocabulary of word vectors (i.e keep only those needed):
infersent.build_vocab(sentences, tokenize=true)

   where sentences is your list of n sentences. you can update your
   vocabulary using infersent.update_vocab(sentences), or directly load
   the k most common english words with
   infersent.build_vocab_k_words(k=100000). if tokenize is true (by
   default), sentences will be tokenized using ntlk.

   4) encode your sentences (list of n sentences):
embeddings = infersent.encode(sentences, tokenize=true)

   this outputs a numpy array with n vectors of dimension 4096. speed is
   around 1000 sentences per second with batch size 128 on a single gpu.

   5) visualize the importance that our model attributes to each word:

   we provide a function to visualize the importance of each word in the
   encoding of a sentence:
infersent.visualize('a man plays an instrument.', tokenize=true)

   [87]model

train model on natural language id136 (snli)

   to reproduce our results on [88]snli, run:
python train_nli.py --word_emb_path '<path to id27s>'

   you should obtain a dev accuracy of 85 and a test accuracy of [89]84.5
   with the default setting.

evaluate the encoder on transfer tasks

   to evaluate the model on transfer tasks, see [90]senteval. be mindful
   to choose the same id121 used for training the encoder. you
   should obtain the following test results for the baselines and the
   infersent models:
   model mr cr subj mpqa sts14 [91]sts benchmark sick relatedness sick
   entailment sst trec mrpc
   infersent1 81.1 86.3 92.4 90.2 .68/.65 75.8/75.5 0.884 86.1 84.6 88.2
   76.2/83.1
   infersent2 79.7 84.2 92.7 89.4 .68/.66 78.4/78.4 0.888 86.3 84.3 90.8
   76.0/83.8
   skipthought 79.4 83.1 93.7 89.3 .44/.45 72.1/70.2 0.858 79.5 82.9 88.4
   -
   fasttext-bov 78.2 80.2 91.8 88.0 .65/.63 70.2/68.3 0.823 78.9 82.3 83.4
   74.4/82.4

reference

   please consider citing [92][1] if you found this code useful.

supervised learning of universal sentence representations from natural
language id136 data (emnlp 2017)

   [1] a. conneau, d. kiela, h. schwenk, l. barrault, a. bordes,
   [93]supervised learning of universal sentence representations from
   natural language id136 data
@inproceedings{conneau-etal:2017:emnlp2017,
  author    = {conneau, alexis  and  kiela, douwe  and  schwenk, holger  and  ba
rrault, lo\"{i}c  and  bordes, antoine},
  title     = {supervised learning of universal sentence representations from na
tural language id136 data},
  booktitle = {proceedings of the 2017 conference on empirical methods in natura
l language processing},
  month     = {september},
  year      = {2017},
  address   = {copenhagen, denmark},
  publisher = {association for computational linguistics},
  pages     = {670--680},
  url       = {https://www.aclweb.org/anthology/d17-1070}
}

related work

     * [94]j. r kiros, y. zhu, r. salakhutdinov, r. s. zemel, a. torralba,
       r. urtasun, s. fidler - skipthought vectors, nips 2015
     * [95]s. arora, y. liang, t. ma - a simple but tough-to-beat baseline
       for sentence embeddings, iclr 2017
     * [96]y. adi, e. kermany, y. belinkov, o. lavi, y. goldberg -
       fine-grained analysis of sentence embeddings using auxiliary
       prediction tasks, iclr 2017
     * [97]a. conneau, d. kiela - senteval: an evaluation toolkit for
       universal sentence representations, lrec 2018
     * [98]s. subramanian, a. trischler, y. bengio, c. j pal - learning
       general purpose distributed sentence representations via large
       scale id72, iclr 2018
     * [99]a. nie, e. d. bennett, n. d. goodman - dissent: sentence
       representation learning from explicit discourse relations, 2018
     * [100]d. cer, y. yang, s. kong, n. hua, n. limtiaco, r. st. john, n.
       constant, m. guajardo-cespedes, s. yuan, c. tar, y. sung, b.
       strope, r. kurzweil - universal sentence encoder, 2018
     * [101]a. conneau, g. kruszewski, g. lample, l. barrault, m. baroni -
       what you can cram into a single vector: probing sentence embeddings
       for linguistic properties, acl 2018
     * [102]a. wang, a. singh, j. michael, f. hill, o. levy, s. bowman -
       glue: a multi-task benchmark and analysis platform for natural
       language understanding

     *    2019 github, inc.
     * [103]terms
     * [104]privacy
     * [105]security
     * [106]status
     * [107]help

     * [108]contact github
     * [109]pricing
     * [110]api
     * [111]training
     * [112]blog
     * [113]about

   (button) you can   t perform that action at this time.

   you signed in with another tab or window. [114]reload to refresh your
   session. you signed out in another tab or window. [115]reload to
   refresh your session.

   (button)

references

   visible links
   1. https://github.com/opensearch.xml
   2. https://github.com/facebookresearch/infersent/commits/master.atom
   3. https://github.com/facebookresearch/infersent#start-of-content
   4. https://github.com/features
   5. https://github.com/features/code-review/
   6. https://github.com/features/project-management/
   7. https://github.com/features/integrations
   8. https://github.com/features/actions
   9. https://github.com/features#team-management
  10. https://github.com/features#social-coding
  11. https://github.com/features#documentation
  12. https://github.com/features#code-hosting
  13. https://github.com/customer-stories
  14. https://github.com/security
  15. https://github.com/enterprise
  16. https://github.com/explore
  17. https://github.com/topics
  18. https://github.com/collections
  19. https://github.com/trending
  20. https://lab.github.com/
  21. https://opensource.guide/
  22. https://github.com/events
  23. https://github.community/
  24. https://education.github.com/
  25. https://github.com/marketplace
  26. https://github.com/pricing
  27. https://github.com/pricing#feature-comparison
  28. https://enterprise.github.com/contact
  29. https://github.com/nonprofit
  30. https://education.github.com/
  31. https://github.com/login?return_to=/facebookresearch/infersent
  32. https://github.com/join
  33. https://github.com/login?return_to=/facebookresearch/infersent
  34. https://github.com/facebookresearch/infersent/watchers
  35. https://github.com/login?return_to=/facebookresearch/infersent
  36. https://github.com/facebookresearch/infersent/stargazers
  37. https://github.com/login?return_to=/facebookresearch/infersent
  38. https://github.com/facebookresearch/infersent/network/members
  39. https://github.com/facebookresearch
  40. https://github.com/facebookresearch/infersent
  41. https://github.com/facebookresearch/infersent
  42. https://github.com/facebookresearch/infersent/issues
  43. https://github.com/facebookresearch/infersent/pulls
  44. https://github.com/facebookresearch/infersent/projects
  45. https://github.com/facebookresearch/infersent/pulse
  46. https://github.com/join?source=prompt-code
  47. https://github.com/facebookresearch/infersent/commits/master
  48. https://github.com/facebookresearch/infersent/branches
  49. https://github.com/facebookresearch/infersent/releases
  50. https://github.com/facebookresearch/infersent/graphs/contributors
  51. https://github.com/facebookresearch/infersent/blob/master/license
  52. https://github.com/facebookresearch/infersent/search?l=python
  53. https://github.com/facebookresearch/infersent/search?l=jupyter-notebook
  54. https://github.com/facebookresearch/infersent/search?l=sed
  55. https://github.com/facebookresearch/infersent/search?l=shell
  56. https://github.com/facebookresearch/infersent/find/master
  57. https://github.com/facebookresearch/infersent/archive/master.zip
  58. https://github.com/login?return_to=https://github.com/facebookresearch/infersent
  59. https://github.com/join?return_to=/facebookresearch/infersent
  60. https://desktop.github.com/
  61. https://desktop.github.com/
  62. https://developer.apple.com/xcode/
  63. https://visualstudio.github.com/
  64. https://github.com/aconneau
  65. https://github.com/facebookresearch/infersent/commits?author=aconneau
  66. https://github.com/facebookresearch/infersent/commit/bc83e21c03b12f586ff9d71665e2c7b82aab78f2
  67. https://github.com/facebookresearch/infersent/commit/bc83e21c03b12f586ff9d71665e2c7b82aab78f2
  68. https://github.com/facebookresearch/infersent/tree/bc83e21c03b12f586ff9d71665e2c7b82aab78f2
  69. https://github.com/facebookresearch/infersent/tree/master/dataset
  70. https://github.com/facebookresearch/infersent/commit/14b7ebb01d9186e9130330deb720367ce67bb9f4
  71. https://github.com/facebookresearch/infersent/tree/master/encoder
  72. https://github.com/facebookresearch/infersent/commit/88526e3f9a374306fa75cd3a07ed4b49c4854e86
  73. https://github.com/facebookresearch/infersent/blob/master/.gitignore
  74. https://github.com/facebookresearch/infersent/blob/master/license
  75. https://github.com/facebookresearch/infersent/blob/master/readme.md
  76. https://github.com/facebookresearch/infersent/blob/master/data.py
  77. https://github.com/facebookresearch/infersent/blob/master/models.py
  78. https://github.com/facebookresearch/infersent/blob/master/mutils.py
  79. https://github.com/facebookresearch/infersent/blob/master/train_nli.py
  80. https://arxiv.org/abs/1705.02364
  81. https://github.com/facebookresearch/senteval
  82. http://pytorch.org/
  83. https://nlp.stanford.edu/projects/glove/
  84. https://fasttext.cc/docs/en/english-vectors.html
  85. https://github.com/facebookresearch/infersent/blob/master/encoder/demo.ipynb
  86. https://github.com/facebookresearch/infersent/blob/master/encoder/demo.ipynb
  87. https://camo.githubusercontent.com/fdaffbdcdc7ea780e0b4d468b77d51f6baf24e9f/68747470733a2f2f646c2e666261697075626c696366696c65732e636f6d2f696e66657273656e742f76697375616c697a6174696f6e2e706e67
  88. https://nlp.stanford.edu/projects/snli/
  89. https://nlp.stanford.edu/projects/snli/
  90. https://github.com/facebookresearch/senteval/tree/master/examples
  91. http://ixa2.si.ehu.es/stswiki/index.php/stsbenchmark#results
  92. https://arxiv.org/abs/1705.02364
  93. https://arxiv.org/abs/1705.02364
  94. https://arxiv.org/abs/1506.06726
  95. https://openreview.net/pdf?id=syk00v5xx
  96. https://arxiv.org/abs/1608.04207
  97. https://arxiv.org/abs/1803.05449
  98. https://arxiv.org/abs/1804.00079
  99. https://arxiv.org/abs/1710.04334
 100. https://arxiv.org/abs/1803.11175
 101. https://arxiv.org/abs/1805.01070
 102. https://arxiv.org/abs/1804.07461
 103. https://github.com/site/terms
 104. https://github.com/site/privacy
 105. https://github.com/security
 106. https://githubstatus.com/
 107. https://help.github.com/
 108. https://github.com/contact
 109. https://github.com/pricing
 110. https://developer.github.com/
 111. https://training.github.com/
 112. https://github.blog/
 113. https://github.com/about
 114. https://github.com/facebookresearch/infersent
 115. https://github.com/facebookresearch/infersent

   hidden links:
 117. https://github.com/
 118. https://github.com/facebookresearch/infersent
 119. https://github.com/facebookresearch/infersent
 120. https://github.com/facebookresearch/infersent
 121. https://help.github.com/articles/which-remote-url-should-i-use
 122. https://github.com/facebookresearch/infersent#infersent
 123. https://github.com/facebookresearch/infersent#dependencies
 124. https://github.com/facebookresearch/infersent#download-datasets
 125. https://github.com/facebookresearch/infersent#use-our-sentence-encoder
 126. https://github.com/facebookresearch/infersent#train-model-on-natural-language-id136-snli
 127. https://github.com/facebookresearch/infersent#evaluate-the-encoder-on-transfer-tasks
 128. https://github.com/facebookresearch/infersent#reference
 129. https://github.com/facebookresearch/infersent#supervised-learning-of-universal-sentence-representations-from-natural-language-id136-data-emnlp-2017
 130. https://github.com/facebookresearch/infersent#related-work
 131. https://github.com/
