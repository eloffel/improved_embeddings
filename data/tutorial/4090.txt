   #[1]github [2]recent commits to bi-att-flow:master

   [3]skip to content

   (button)

     * why github?
       [4]features    
          + [5]code review
          + [6]project management
          + [7]integrations
          + [8]actions
          + [9]team management
          + [10]social coding
          + [11]documentation
          + [12]code hosting
          + [13]customer stories    
          + [14]security    
     * [15]enterprise
     * explore
          + [16]explore github    

learn & contribute
          + [17]topics
          + [18]collections
          + [19]trending
          + [20]learning lab
          + [21]open source guides

connect with others
          + [22]events
          + [23]community forum
          + [24]github education
     * [25]marketplace
     * pricing
       [26]plans    
          + [27]compare plans
          + [28]contact sales
          + [29]nonprofit    
          + [30]education    

   ____________________
     * in this repository all github    
       jump to    

     * no suggested jump to results

     * in this repository all github    
       jump to    
     * in this repository all github    
       jump to    

   [31]sign in [32]sign up

     * [33]watch [34]86
     * [35]star [36]1,149
     * [37]fork [38]540

[39]allenai/[40]bi-att-flow

   [41]code [42]issues 53 [43]pull requests 9 [44]projects 0 [45]insights
   (button) dismiss

join github today

   github is home to over 31 million developers working together to host
   and review code, manage projects, and build software together.
   [46]sign up
   bi-directional attention flow (bidaf) network is a multi-stage
   hierarchical process that represents context at different levels of
   granularity and uses a bi-directional attention flow mechanism to
   achieve a query-aware context representation without early
   summarization. [47]http://allenai.github.io/bi-att-flow
   [48]squad [49]nlp [50]tensorflow [51]question-answering [52]bidaf
     * [53]224 commits
     * [54]11 branches
     * [55]5 releases
     * [56]fetching contributors
     * [57]apache-2.0

    1. [58]python 75.3%
    2. [59]jupyter notebook 22.2%
    3. [60]html 1.9%
    4. [61]shell 0.6%

   (button) python jupyter notebook html shell
   branch: master (button) new pull request
   [62]find file
   clone or download

clone with https

   use git or checkout with svn using the web url.
   https://github.com/a
   [63]download zip

downloading...

   want to be notified of new releases in allenai/bi-att-flow?
   [64]sign in [65]sign up

launching github desktop...

   if nothing happens, [66]download github desktop and try again.

   (button) go back

launching github desktop...

   if nothing happens, [67]download github desktop and try again.

   (button) go back

launching xcode...

   if nothing happens, [68]download xcode and try again.

   (button) go back

launching visual studio...

   if nothing happens, [69]download the github extension for visual studio
   and try again.

   (button) go back
   [70]@seominjoon
   [71]seominjoon [72]update readme.md
   latest commit [73]4900454 jan 24, 2018
   [74]permalink
   type name latest commit message commit time
   failed to load latest commit information.
   [75]basic [76]readme includes test results, running codalab worksheet
   nov 28, 2016
   [77]basic_id98 [78]final commit for iclr nov 5, 2016
   [79]id98_dm [80]move things around, var decay config, official ensemble
   nov 27, 2016
   [81]my [82]file moves / deletes nov 27, 2016
   [83]squad
   [84]tree [85]file moves / deletes nov 27, 2016
   [86]visualization [87]add script to compare the performance of two
   models nov 1, 2016
   [88]license
   [89]readme.md
   [90]download.sh
   [91]requirements.txt

readme.md

bi-directional attention flow for machine comprehension

     * this the original implementation of [92]bi-directional attention
       flow for machine comprehension.
     * the codalab worksheet for the [93]squad leaderboard submission is
       available [94]here.
     * for tensorflow v1.2 compatible version, see the [95]dev branch.
     * please contact [96]minjoon seo ([97]@seominjoon) for questions and
       suggestions.

0. requirements

general

     * python (verified on 3.5.2. issues have been reported with python
       2!)
     * unzip, wget (for running download.sh only)

python packages

     * tensorflow (deep learning library, only works on r0.11)
     * nltk (nlp tools, verified on 3.2.1)
     * tqdm (progress bar, verified on 4.7.4)
     * jinja2 (for visaulization; if you only train and test, not needed)

1. pre-processing

   first, prepare data. donwload squad data and glove and nltk corpus
   (~850 mb, this will download files to $home/data):
chmod +x download.sh; ./download.sh

   second, preprocess stanford qa dataset (along with glove vectors) and
   save them in $pwd/data/squad (~5 minutes):
python -m squad.prepro

2. training

   the model has ~2.5m parameters. the model was trained with nvidia titan
   x (pascal architecture, 2016). the model requires at least 12gb of gpu
   ram. if your gpu ram is smaller than 12gb, you can either decrease
   batch size (performance might degrade), or you can use multi gpu (see
   below). the training converges at ~18k steps, and it took ~4s per step
   (i.e. ~20 hours).

   before training, it is recommended to first try the following code to
   verify everything is okay and memory is sufficient:
python -m basic.cli --mode train --noload --debug

   then to fully train, run:
python -m basic.cli --mode train --noload

   you can speed up the training process with optimization flags:
python -m basic.cli --mode train --noload --len_opt --cluster

   you can still omit them, but training will be much slower.

   note that during the training, the em and f1 scores from the occasional
   evaluation are not the same with the score from official squad
   evaluation script. the printed scores are not official (our scoring
   scheme is a bit harsher). to obtain the official number, use the
   official evaluator (copied in squad folder, squad/evaluate-v1.1.py).
   for more information see 3.test.

3. test

   to test, run:
python -m basic.cli

   similarly to training, you can give the optimization flags to speed up
   test (5 minutes on dev data):
python -m basic.cli --len_opt --cluster

   this command loads the most recently saved model during training and
   begins testing on the test data. after the process ends, it prints f1
   and em scores, and also outputs a json file
   ($pwd/out/basic/00/answer/test-####.json, where #### is the step # that
   the model was saved). note that the printed scores are not official
   (our scoring scheme is a bit harsher). to obtain the official number,
   use the official evaluator (copied in squad folder) and the output json
   file:
python squad/evaluate-v1.1.py $home/data/squad/dev-v1.1.json out/basic/00/answer
/test-####.json

3.1 loading from pre-trained weights

   instead of training the model yourself, you can choose to use
   pre-trained weights that were used for [98]squad leaderboard
   submission. refer to [99]this worksheet in codalab to reproduce the
   results. if you are unfamiliar with codalab, follow these simple steps
   (given that you met all prereqs above):
    1. download save.zip from the [100]worksheet and unzip it in the
       current directory.
    2. copy glove.6b.100d.txt from your glove data folder
       ($home/data/glove/) to the current directory.
    3. to reproduce single model:

basic/run_single.sh $home/data/squad/dev-v1.1.json single.json

   this writes the answers to single.json in the current directory. you
   can then use the official evaluator to obtain em and f1 scores. if you
   want to run on gpu (~5 mins), change the value of batch_size flag in
   the shell file to a higher number (60 for 12gb gpu ram). 4. similarly,
   to reproduce ensemble method:
basic/run_ensemble.sh $home/data/squad/dev-v1.1.json ensemble.json

   if you want to run on gpu, you should run the script sequentially by
   removing '&' in the forloop, or you will need to specify different gpus
   for each run of the for loop.

results

dev data

   note these scores are from the official evaluator (copied in squad
   folder, squad/evaluate-v1.1.py). for more information see 3.test. the
   scores appeared during the training could be lower than the scores from
   the official evaluator.
            em (%) f1 (%)
   single    67.7   77.3
   ensemble  72.6   80.7

test data

            em (%) f1 (%)
   single    68.0   77.3
   ensemble  73.3   81.1

   refer to [101]our paper for more details. see [102]squad leaderboard to
   compare with other models.

multi-gpu training & testing

   our model supports multi-gpu training. we follow the parallelization
   paradigm described in [103]tensorflow tutorial. in short, if you want
   to use batch size of 60 (default) but if you have 3 gpus with 4gb of
   ram, then you initialize each gpu with batch size of 20, and combine
   the gradients on cpu. this can be easily done by running:
python -m basic.cli --mode train --noload --num_gpus 3 --batch_size 20

   similarly, you can speed up your testing by:
python -m basic.cli --num_gpus 3 --batch_size 20

demo

   for now, please refer to the demo branch of this repository.

     *    2019 github, inc.
     * [104]terms
     * [105]privacy
     * [106]security
     * [107]status
     * [108]help

     * [109]contact github
     * [110]pricing
     * [111]api
     * [112]training
     * [113]blog
     * [114]about

   (button) you can   t perform that action at this time.

   you signed in with another tab or window. [115]reload to refresh your
   session. you signed out in another tab or window. [116]reload to
   refresh your session.

   (button)

references

   visible links
   1. https://github.com/opensearch.xml
   2. https://github.com/allenai/bi-att-flow/commits/master.atom
   3. https://github.com/allenai/bi-att-flow#start-of-content
   4. https://github.com/features
   5. https://github.com/features/code-review/
   6. https://github.com/features/project-management/
   7. https://github.com/features/integrations
   8. https://github.com/features/actions
   9. https://github.com/features#team-management
  10. https://github.com/features#social-coding
  11. https://github.com/features#documentation
  12. https://github.com/features#code-hosting
  13. https://github.com/customer-stories
  14. https://github.com/security
  15. https://github.com/enterprise
  16. https://github.com/explore
  17. https://github.com/topics
  18. https://github.com/collections
  19. https://github.com/trending
  20. https://lab.github.com/
  21. https://opensource.guide/
  22. https://github.com/events
  23. https://github.community/
  24. https://education.github.com/
  25. https://github.com/marketplace
  26. https://github.com/pricing
  27. https://github.com/pricing#feature-comparison
  28. https://enterprise.github.com/contact
  29. https://github.com/nonprofit
  30. https://education.github.com/
  31. https://github.com/login?return_to=/allenai/bi-att-flow
  32. https://github.com/join
  33. https://github.com/login?return_to=/allenai/bi-att-flow
  34. https://github.com/allenai/bi-att-flow/watchers
  35. https://github.com/login?return_to=/allenai/bi-att-flow
  36. https://github.com/allenai/bi-att-flow/stargazers
  37. https://github.com/login?return_to=/allenai/bi-att-flow
  38. https://github.com/allenai/bi-att-flow/network/members
  39. https://github.com/allenai
  40. https://github.com/allenai/bi-att-flow
  41. https://github.com/allenai/bi-att-flow
  42. https://github.com/allenai/bi-att-flow/issues
  43. https://github.com/allenai/bi-att-flow/pulls
  44. https://github.com/allenai/bi-att-flow/projects
  45. https://github.com/allenai/bi-att-flow/pulse
  46. https://github.com/join?source=prompt-code
  47. http://allenai.github.io/bi-att-flow
  48. https://github.com/topics/squad
  49. https://github.com/topics/nlp
  50. https://github.com/topics/tensorflow
  51. https://github.com/topics/question-answering
  52. https://github.com/topics/bidaf
  53. https://github.com/allenai/bi-att-flow/commits/master
  54. https://github.com/allenai/bi-att-flow/branches
  55. https://github.com/allenai/bi-att-flow/releases
  56. https://github.com/allenai/bi-att-flow/graphs/contributors
  57. https://github.com/allenai/bi-att-flow/blob/master/license
  58. https://github.com/allenai/bi-att-flow/search?l=python
  59. https://github.com/allenai/bi-att-flow/search?l=jupyter-notebook
  60. https://github.com/allenai/bi-att-flow/search?l=html
  61. https://github.com/allenai/bi-att-flow/search?l=shell
  62. https://github.com/allenai/bi-att-flow/find/master
  63. https://github.com/allenai/bi-att-flow/archive/master.zip
  64. https://github.com/login?return_to=https://github.com/allenai/bi-att-flow
  65. https://github.com/join?return_to=/allenai/bi-att-flow
  66. https://desktop.github.com/
  67. https://desktop.github.com/
  68. https://developer.apple.com/xcode/
  69. https://visualstudio.github.com/
  70. https://github.com/seominjoon
  71. https://github.com/allenai/bi-att-flow/commits?author=seominjoon
  72. https://github.com/allenai/bi-att-flow/commit/49004549e9a88b78c359b31481afa7792dbb3f4a
  73. https://github.com/allenai/bi-att-flow/commit/49004549e9a88b78c359b31481afa7792dbb3f4a
  74. https://github.com/allenai/bi-att-flow/tree/49004549e9a88b78c359b31481afa7792dbb3f4a
  75. https://github.com/allenai/bi-att-flow/tree/master/basic
  76. https://github.com/allenai/bi-att-flow/commit/b050e4d28408698865637b801a0dff4e0e91cdc8
  77. https://github.com/allenai/bi-att-flow/tree/master/basic_id98
  78. https://github.com/allenai/bi-att-flow/commit/d21df71b850645d673ba98a31b1c6bfb0e451b63
  79. https://github.com/allenai/bi-att-flow/tree/master/id98_dm
  80. https://github.com/allenai/bi-att-flow/commit/71e15d731c8746c936224e88d615319e9ab5fb7a
  81. https://github.com/allenai/bi-att-flow/tree/master/my
  82. https://github.com/allenai/bi-att-flow/commit/0ab9a6670df522b6d187ccb266c938823bca45da
  83. https://github.com/allenai/bi-att-flow/tree/master/squad
  84. https://github.com/allenai/bi-att-flow/tree/master/tree
  85. https://github.com/allenai/bi-att-flow/commit/0ab9a6670df522b6d187ccb266c938823bca45da
  86. https://github.com/allenai/bi-att-flow/tree/master/visualization
  87. https://github.com/allenai/bi-att-flow/commit/76c6bffd493830974e90e0f5de5ac0d8a6d30d59
  88. https://github.com/allenai/bi-att-flow/blob/master/license
  89. https://github.com/allenai/bi-att-flow/blob/master/readme.md
  90. https://github.com/allenai/bi-att-flow/blob/master/download.sh
  91. https://github.com/allenai/bi-att-flow/blob/master/requirements.txt
  92. https://arxiv.org/abs/1611.01603
  93. http://stanford-qa.com/
  94. https://worksheets.codalab.org/worksheets/0x37a9b8c44f6845c28866267ef941c89d/
  95. https://github.com/allenai/bi-att-flow/tree/dev
  96. https://seominjoon.github.io/
  97. https://github.com/seominjoon
  98. http://stanford-qa.com/
  99. https://worksheets.codalab.org/worksheets/0x37a9b8c44f6845c28866267ef941c89d/
 100. https://worksheets.codalab.org/worksheets/0x37a9b8c44f6845c28866267ef941c89d/
 101. https://arxiv.org/abs/1611.01603
 102. http://stanford-qa.com/
 103. https://www.tensorflow.org/versions/r0.11/tutorials/deep_id98/index.html#training-a-model-using-multiple-gpu-cards
 104. https://github.com/site/terms
 105. https://github.com/site/privacy
 106. https://github.com/security
 107. https://githubstatus.com/
 108. https://help.github.com/
 109. https://github.com/contact
 110. https://github.com/pricing
 111. https://developer.github.com/
 112. https://training.github.com/
 113. https://github.blog/
 114. https://github.com/about
 115. https://github.com/allenai/bi-att-flow
 116. https://github.com/allenai/bi-att-flow

   hidden links:
 118. https://github.com/
 119. https://github.com/allenai/bi-att-flow
 120. https://github.com/allenai/bi-att-flow
 121. https://github.com/allenai/bi-att-flow
 122. https://help.github.com/articles/which-remote-url-should-i-use
 123. https://github.com/allenai/bi-att-flow#bi-directional-attention-flow-for-machine-comprehension
 124. https://github.com/allenai/bi-att-flow#0-requirements
 125. https://github.com/allenai/bi-att-flow#general
 126. https://github.com/allenai/bi-att-flow#python-packages
 127. https://github.com/allenai/bi-att-flow#1-pre-processing
 128. https://github.com/allenai/bi-att-flow#2-training
 129. https://github.com/allenai/bi-att-flow#3-test
 130. https://github.com/allenai/bi-att-flow#31-loading-from-pre-trained-weights
 131. https://github.com/allenai/bi-att-flow#results
 132. https://github.com/allenai/bi-att-flow#dev-data
 133. https://github.com/allenai/bi-att-flow#test-data
 134. https://github.com/allenai/bi-att-flow#multi-gpu-training--testing
 135. https://github.com/allenai/bi-att-flow#demo
 136. https://github.com/
