   #[1]github [2]recent commits to deepqa:master

   [3]skip to content

   (button)

     * why github?
       [4]features    
          + [5]code review
          + [6]project management
          + [7]integrations
          + [8]actions
          + [9]team management
          + [10]social coding
          + [11]documentation
          + [12]code hosting
          + [13]customer stories    
          + [14]security    
     * [15]enterprise
     * explore
          + [16]explore github    

learn & contribute
          + [17]topics
          + [18]collections
          + [19]trending
          + [20]learning lab
          + [21]open source guides

connect with others
          + [22]events
          + [23]community forum
          + [24]github education
     * [25]marketplace
     * pricing
       [26]plans    
          + [27]compare plans
          + [28]contact sales
          + [29]nonprofit    
          + [30]education    

   ____________________
     * in this repository all github    
       jump to    

     * no suggested jump to results

     * in this repository all github    
       jump to    
     * in this repository all github    
       jump to    

   [31]sign in [32]sign up

     * [33]watch [34]202
     * [35]star [36]2,391
     * [37]fork [38]1,055

[39]conchylicultor/[40]deepqa

   [41]code [42]issues 85 [43]pull requests 4 [44]projects 0 [45]insights
   (button) dismiss

join github today

   github is home to over 31 million developers working together to host
   and review code, manage projects, and build software together.
   [46]sign up
   my tensorflow implementation of "a neural conversational model", a deep
   learning based chatbot
   [47]chatbot [48]deep-learning [49]tensorflow [50]id195
     * [51]182 commits
     * [52]1 branch
     * [53]0 releases
     * [54]fetching contributors
     * [55]apache-2.0

    1. [56]python 56.9%
    2. [57]css 32.0%
    3. [58]javascript 8.9%
    4. [59]html 1.8%
    5. [60]shell 0.4%

   (button) python css javascript html shell
   branch: master (button) new pull request
   [61]find file
   clone or download

clone with https

   use git or checkout with svn using the web url.
   https://github.com/c
   [62]download zip

downloading...

   want to be notified of new releases in conchylicultor/deepqa?
   [63]sign in [64]sign up

launching github desktop...

   if nothing happens, [65]download github desktop and try again.

   (button) go back

launching github desktop...

   if nothing happens, [66]download github desktop and try again.

   (button) go back

launching xcode...

   if nothing happens, [67]download xcode and try again.

   (button) go back

launching visual studio...

   if nothing happens, [68]download the github extension for visual studio
   and try again.

   (button) go back
   [69]@dfenglei [70]@conchylicultor
   [71]dfenglei and [72]conchylicultor [73]fix for issue [74]#183
   [75]([76]#184[77]) (button)    
commanderror: you have not set asgi_application, which is needed to run the serv
er. [78]#183

   latest commit [79]efcfbf3 apr 8, 2018
   [80]permalink
   type name latest commit message commit time
   failed to load latest commit information.
   [81]chatbot [82]making compliant pathes for linux and windows os sep 4,
   2017
   [83]chatbot_website [84]fix for issue [85]#183 [86]([87]#184[88]) apr
   7, 2018
   [89]data [90]update readme for migration instruction, load default
   idcount for bac    mar 19, 2017
   [91]docker [92]fix link from previous commit mar 4, 2017
   [93]save [94]testing mode, better model saving/loading gestion aug 17,
   2016
   [95].dockerignore
   [96].gitignore [97]enh: ignore nvidia-docker-compose output dec 20,
   2016
   [98]dockerfile [99]update dockerfiles for tf 1.0 feb 18, 2017
   [100]dockerfile.gpu [101]update dockerfiles for tf 1.0 feb 18, 2017
   [102]license
   [103]readme.md
   [104]chatbot_miniature.png [105]solve a tf 0.12 compatibility issue,
   use local screenshot miniature i    dec 9, 2016
   [106]main.py
   [107]requirements.txt
   [108]setup_server.sh [109]interactive connexion between
   client-server-chatbot aug 23, 2016
   [110]testsuite.py

readme.md

deep q&a

   [111]join the chat at https://gitter.im/chatbot-pilots/deepqa

table of contents

     * [112]presentation
     * [113]installation
     * [114]running
          + [115]chatbot
          + [116]web interface
     * [117]results
     * [118]pretrained model
     * [119]improvements
     * [120]upgrade

presentation

   this work tries to reproduce the results of [121]a neural
   conversational model (aka the google chatbot). it uses a id56 (id195
   model) for sentence predictions. it is done using python and
   tensorflow.

   the loading corpus part of the program is inspired by the torch
   [122]neuralconvo from [123]macournoyer.

   for now, deepqa support the following dialog corpus:
     * [124]cornell movie dialogs corpus (default). already included when
       cloning the repository.
     * [125]opensubtitles (thanks to [126]eschnou). much bigger corpus
       (but also noisier). to use it, follow [127]those instructions and
       use the flag --corpus opensubs.
     * supreme court conversation data (thanks to [128]julien-c).
       available using --corpus scotus. see the [129]instructions for
       installation.
     * [130]ubuntu dialogue corpus (thanks to [131]julien-c). available
       using --corpus ubuntu. see the [132]instructions for installation.
     * your own data (thanks to [133]julien-c) by using a simple custom
       conversation format (see [134]here for more info).

   to speedup the training, it's also possible to use pre-trained word
   embeddings (thanks to [135]eschnou). more info [136]here.

installation

   the program requires the following dependencies (easy to install using
   pip: pip3 install -r requirements.txt):
     * python 3.5
     * tensorflow (tested with v1.0)
     * numpy
     * cuda (for using gpu)
     * nltk (natural language toolkit for tokenized the sentences)
     * tqdm (for the nice progression bars)

   you might also need to download additional data to make nltk work.
python3 -m nltk.downloader punkt

   the cornell dataset is already included. for the other datasets, look
   at the readme files into their respective folders (inside data/).

   the web interface requires some additional packages:
     * django (tested with 1.10)
     * channels
     * redis (see [137]here)
     * asgi_redis (at least 1.0)

   a docker installation is also available. more detailed instructions
   [138]here.

running

chatbot

   to train the model, simply run main.py. once trained, you can test the
   results with main.py --test (results generated in
   'save/model/samples_predictions.txt') or main.py --test interactive
   (more fun).

   here are some flags which could be useful. for more help and options,
   use python main.py -h:
     * --modeltag <name>: allow to give a name to the current model to
       differentiate between them when testing/training.
     * --keepall: use this flag when training if when testing, you want to
       see the predictions at different steps (it can be interesting to
       see the program changes its name and age as the training progress).
       warning: it can quickly take a lot of storage space if you don't
       increase the --saveevery option.
     * --filtervocab 20 or --vocabularysize 30000: limit the vocabulary
       size to and optimize the performances and memory usage. replace the
       words used less than 20 times by the <unknown> token and set a
       maximum vocabulary size.
     * --verbose: when testing, will print the sentences as they are
       computed.
     * --playdataset: show some dialogue samples from the dataset (can be
       use conjointly with --createdataset if this is the only action you
       want to perform).

   to visualize the computational graph and the cost with
   [139]tensorboard, just run tensorboard --logdir save/.

   by default, the network architecture is a standard encoder/decoder with
   two lstm layers (hidden size of 256) and an embedding size for the
   vocabulary of 32. the network is trained using adam. the maximum
   sentence length is set to 10 words, but can be increased.

web interface

   once trained, it's possible to chat with it using a more user friendly
   interface. the server will look at the model copied to
   save/model-server/model.ckpt. the first time you want to use it, you'll
   need to configure it with:
export chatbot_secret_key="my-secret-key"
cd chatbot_website/
python manage.py makemigrations
python manage.py migrate

   then, to launch the server locally, use the following commands:
cd chatbot_website/
redis-server &  # launch redis in background
python manage.py runserver

   after launch, the interface should be available on
   [140]http://localhost:8000/. if you want to deploy the program on a
   server, use python manage.py runserver 0.0.0.0 instead. more info
   [141]here.

   [142]chatbot web interface

results

   surprisingly, it's possible to get some results after only 1 or 2 hours
   of training (on a geforce gt 740m), by drastically reducing the input
   sequence to 5 words and output to 3 (plus the go and eos tokens) and by
   using a small embedding size (something like 25). since then i modified
   the code and now the output length has to match the input one but you
   can still reproduce the original results, using [143]this version. of
   course, the network won't be really chatty:
q: hi
a: hi.

q: what is your name ?
a: laura.

q: what does that mean ?
a: i dunno.

q: how old are you ?
a: thirty-five.

q: will google hire me ?
a: no.

q: tell me the alphabet
a: fuck you.

q: that's not nice
a: yeah.

   here is some case where it fails:
q: who is laura ?
a: my brother.

q: say 'goodbye'
a: alright.

q: what is cooking ?
a: a channel.

q: can you say no ?
a: no.

q: two plus two
a: manny...

   with longer sentences, the network is much slower to train. after
   250000 iterations with maxlength=10, the network still mainly gives
   evasive answers (by answering most of the open ended questions by 'i
   don't know') but it seems to have integrated some basic semantic:
q: when are the fireworks ?
a: tomorrow.

q: what color ?
a: gray.

q: which apple ?
a: that's the first one.

q: what time is it ?
a: eleven o'clock.

q: who is skywalker ?
a: she's a freelance bio-exorcist.

q: who is john ?
a: the old man.

q: who is jenny ?
a: the man who killed herself.

q: when were you born ?
a: soon.

   as shown on the last questions, the network still does some confusion
   between the genders and the present/future. i also tried some deeper
   philosophical questions with more or less success.
q: what is the purpose of being intelligent ?
a: the man are obsolete.

q: what is immoral ?
a: the truth.

q: what is morality ?
a: the worst.

q: what is the purpose of existence ?
a: it 's private.

q: what happens if machines can think ?
a: i think i'll just lie with you.

   the model i trained is quite limited by the embedding size i put and by
   its size, and by the training corpus size. its 'thought vector' is also
   probably too small to answer the kind of following:
q: my name is david. what is my name ?
a: debbie.

q: my name is john. what is my name ?
a: carl smith.

q: how many legs does a cat have ?
a: four.

q: how many legs does a spider have ?
a: four.

q: do you prefer football or soccer ?
a: whiskey.

   it also seems to overfit as sometimes it will just pop out sentences
   from its training set unrelated to the question. adding some dropout
   should reduce the issue.
q: i play tennis. what do i play ?
a: i'm going to get laid.

q: what color is the sky ?
a: one of the deputies is everywhere.

pretrained model

   you can find a pre-trained model [144]here, trained of the default
   corpus. to use it:
    1. extract the zip file inside deepqa/save/
    2. copy the preprocessed dataset from
       save/model-pretrainedv2/dataset-cornell-old-lenght10-filter0-vocabs
       ize0.pkl to data/samples/.
    3. run ./main.py --modeltag pretrainedv2 --test interactive.

   thanks to nicholas c., [145]here ([146]original) are some additional
   pre-trained models (compatible with tf 1.2) for diverse datasets. the
   folder also contains the pre-processed dataset for cornell,
   opensubtitles, ubuntu and scotus (to move inside data/samples/). those
   are required is you don't want to process the datasets yourself.

   if you have a high-end gpu, don't hesitate to play with the
   hyper-parameters/corpus to train a better model. from my experiments,
   it seems that the learning rate and dropout rate have the most impact
   on the results. also if you want to share your models, don't hesitate
   to contact me and i'll add it here.

improvements

   in addition to trying larger/deeper model, there are a lot of small
   improvements which could be tested. don't hesitate to send a pull
   request if you implement one of those. here are some ideas:
     * for now, the predictions are deterministic (the network just take
       the most likely output) so when answering a question, the network
       will always gives the same answer. by adding a sampling mechanism,
       the network could give more diverse (and maybe more interesting)
       answers. the easiest way to do that is to sample the next predicted
       word from the softmax id203 distribution. by combining that
       with the loop_function argument of tf.nn.id195.id56_decoder, it
       shouldn't be too difficult to add. after that, it should be
       possible to play with the softmax temperature to get more
       conservative or exotic predictions.
     * adding attention could potentially improve the predictions,
       especially for longer sentences. it should be straightforward by
       replacing embedding_id56_id195 by embedding_attention_id195 on
       model.py.
     * having more data usually don't hurt. training on a bigger corpus
       should be beneficial. [147]reddit comments dataset seems the
       biggest for now (and is too big for this program to support it).
       another trick to artificially increase the dataset size when
       creating the corpus could be to split the sentences of each
       training sample (ex: from the sample q:sentence 1. sentence 2. =>
       a:sentence x. sentence y. we could generate 3 new samples:
       q:sentence 1. sentence 2. => a:sentence x., q:sentence 2. =>
       a:sentence x. sentence y. and q:sentence 2. => a:sentence x..
       warning: other combinations like q:sentence 1. => a:sentence x.
       won't work because it would break the transition 2 => x which links
       the question to the answer)
     * the testing curve should really be monitored as done in my other
       [148]music generation project. this would greatly help to see the
       impact of dropout on overfitting. for now it's just done
       empirically by manually checking the testing prediction at
       different training steps.
     * for now, the questions are independent from each other. to link
       questions together, a straightforward way would be to feed all
       previous questions and answer to the encoder before giving the
       answer. some caching could be done on the final encoder stated to
       avoid recomputing it each time. to improve the accuracy, the
       network should be retrain on entire dialogues instead of just
       individual qa. also when feeding the previous dialogue to the
       encoder, new tokens <q> and <a> could be added so the encoder knows
       when the interlocutor is changing. i'm not sure though that the
       simple id195 model would be sufficient to capture long term
       dependencies between sentences. adding a bucket system to group
       similar input lengths together could greatly improve training
       speed.

     *    2019 github, inc.
     * [149]terms
     * [150]privacy
     * [151]security
     * [152]status
     * [153]help

     * [154]contact github
     * [155]pricing
     * [156]api
     * [157]training
     * [158]blog
     * [159]about

   (button) you can   t perform that action at this time.

   you signed in with another tab or window. [160]reload to refresh your
   session. you signed out in another tab or window. [161]reload to
   refresh your session.

   (button)

references

   visible links
   1. https://github.com/opensearch.xml
   2. https://github.com/conchylicultor/deepqa/commits/master.atom
   3. https://github.com/conchylicultor/deepqa#start-of-content
   4. https://github.com/features
   5. https://github.com/features/code-review/
   6. https://github.com/features/project-management/
   7. https://github.com/features/integrations
   8. https://github.com/features/actions
   9. https://github.com/features#team-management
  10. https://github.com/features#social-coding
  11. https://github.com/features#documentation
  12. https://github.com/features#code-hosting
  13. https://github.com/customer-stories
  14. https://github.com/security
  15. https://github.com/enterprise
  16. https://github.com/explore
  17. https://github.com/topics
  18. https://github.com/collections
  19. https://github.com/trending
  20. https://lab.github.com/
  21. https://opensource.guide/
  22. https://github.com/events
  23. https://github.community/
  24. https://education.github.com/
  25. https://github.com/marketplace
  26. https://github.com/pricing
  27. https://github.com/pricing#feature-comparison
  28. https://enterprise.github.com/contact
  29. https://github.com/nonprofit
  30. https://education.github.com/
  31. https://github.com/login?return_to=/conchylicultor/deepqa
  32. https://github.com/join
  33. https://github.com/login?return_to=/conchylicultor/deepqa
  34. https://github.com/conchylicultor/deepqa/watchers
  35. https://github.com/login?return_to=/conchylicultor/deepqa
  36. https://github.com/conchylicultor/deepqa/stargazers
  37. https://github.com/login?return_to=/conchylicultor/deepqa
  38. https://github.com/conchylicultor/deepqa/network/members
  39. https://github.com/conchylicultor
  40. https://github.com/conchylicultor/deepqa
  41. https://github.com/conchylicultor/deepqa
  42. https://github.com/conchylicultor/deepqa/issues
  43. https://github.com/conchylicultor/deepqa/pulls
  44. https://github.com/conchylicultor/deepqa/projects
  45. https://github.com/conchylicultor/deepqa/pulse
  46. https://github.com/join?source=prompt-code
  47. https://github.com/topics/chatbot
  48. https://github.com/topics/deep-learning
  49. https://github.com/topics/tensorflow
  50. https://github.com/topics/id195
  51. https://github.com/conchylicultor/deepqa/commits/master
  52. https://github.com/conchylicultor/deepqa/branches
  53. https://github.com/conchylicultor/deepqa/releases
  54. https://github.com/conchylicultor/deepqa/graphs/contributors
  55. https://github.com/conchylicultor/deepqa/blob/master/license
  56. https://github.com/conchylicultor/deepqa/search?l=python
  57. https://github.com/conchylicultor/deepqa/search?l=css
  58. https://github.com/conchylicultor/deepqa/search?l=javascript
  59. https://github.com/conchylicultor/deepqa/search?l=html
  60. https://github.com/conchylicultor/deepqa/search?l=shell
  61. https://github.com/conchylicultor/deepqa/find/master
  62. https://github.com/conchylicultor/deepqa/archive/master.zip
  63. https://github.com/login?return_to=https://github.com/conchylicultor/deepqa
  64. https://github.com/join?return_to=/conchylicultor/deepqa
  65. https://desktop.github.com/
  66. https://desktop.github.com/
  67. https://developer.apple.com/xcode/
  68. https://visualstudio.github.com/
  69. https://github.com/dfenglei
  70. https://github.com/conchylicultor
  71. https://github.com/conchylicultor/deepqa/commits?author=dfenglei
  72. https://github.com/conchylicultor/deepqa/commits?author=conchylicultor
  73. https://github.com/conchylicultor/deepqa/commit/efcfbf3d4b22e93f6e94a6fc26674aa9557ab60f
  74. https://github.com/conchylicultor/deepqa/issues/183
  75. https://github.com/conchylicultor/deepqa/commit/efcfbf3d4b22e93f6e94a6fc26674aa9557ab60f
  76. https://github.com/conchylicultor/deepqa/pull/184
  77. https://github.com/conchylicultor/deepqa/commit/efcfbf3d4b22e93f6e94a6fc26674aa9557ab60f
  78. https://github.com/conchylicultor/deepqa/issues/183
  79. https://github.com/conchylicultor/deepqa/commit/efcfbf3d4b22e93f6e94a6fc26674aa9557ab60f
  80. https://github.com/conchylicultor/deepqa/tree/efcfbf3d4b22e93f6e94a6fc26674aa9557ab60f
  81. https://github.com/conchylicultor/deepqa/tree/master/chatbot
  82. https://github.com/conchylicultor/deepqa/commit/6605d1e70080f314c0d2b2b7468759cadb57dbc2
  83. https://github.com/conchylicultor/deepqa/tree/master/chatbot_website
  84. https://github.com/conchylicultor/deepqa/commit/efcfbf3d4b22e93f6e94a6fc26674aa9557ab60f
  85. https://github.com/conchylicultor/deepqa/issues/183
  86. https://github.com/conchylicultor/deepqa/commit/efcfbf3d4b22e93f6e94a6fc26674aa9557ab60f
  87. https://github.com/conchylicultor/deepqa/pull/184
  88. https://github.com/conchylicultor/deepqa/commit/efcfbf3d4b22e93f6e94a6fc26674aa9557ab60f
  89. https://github.com/conchylicultor/deepqa/tree/master/data
  90. https://github.com/conchylicultor/deepqa/commit/b83c7a9c9a5ceace45dfadc6491dd20211be84d3
  91. https://github.com/conchylicultor/deepqa/tree/master/docker
  92. https://github.com/conchylicultor/deepqa/commit/b1808119af4c5cfeda1f4614a31750b8584f8dd7
  93. https://github.com/conchylicultor/deepqa/tree/master/save
  94. https://github.com/conchylicultor/deepqa/commit/549516dab60b85be3be4cff85dc1418299a21934
  95. https://github.com/conchylicultor/deepqa/blob/master/.dockerignore
  96. https://github.com/conchylicultor/deepqa/blob/master/.gitignore
  97. https://github.com/conchylicultor/deepqa/commit/d4fdeebcec9fc23c6d725de88e6620b4f81b9f7a
  98. https://github.com/conchylicultor/deepqa/blob/master/dockerfile
  99. https://github.com/conchylicultor/deepqa/commit/c444e858040aae9dbd31e768ca7df647d7b34bbd
 100. https://github.com/conchylicultor/deepqa/blob/master/dockerfile.gpu
 101. https://github.com/conchylicultor/deepqa/commit/c444e858040aae9dbd31e768ca7df647d7b34bbd
 102. https://github.com/conchylicultor/deepqa/blob/master/license
 103. https://github.com/conchylicultor/deepqa/blob/master/readme.md
 104. https://github.com/conchylicultor/deepqa/blob/master/chatbot_miniature.png
 105. https://github.com/conchylicultor/deepqa/commit/031fa35a1509c36768464aef7d55c3a2bb37eadd
 106. https://github.com/conchylicultor/deepqa/blob/master/main.py
 107. https://github.com/conchylicultor/deepqa/blob/master/requirements.txt
 108. https://github.com/conchylicultor/deepqa/blob/master/setup_server.sh
 109. https://github.com/conchylicultor/deepqa/commit/26c116c18bbd75a37ddbd5e9e4dc8a00cb2fe6a3
 110. https://github.com/conchylicultor/deepqa/blob/master/testsuite.py
 111. https://gitter.im/chatbot-pilots/deepqa?utm_source=badge&utm_medium=badge&utm_campaign=pr-badge&utm_content=badge
 112. https://github.com/conchylicultor/deepqa#presentation
 113. https://github.com/conchylicultor/deepqa#installation
 114. https://github.com/conchylicultor/deepqa#running
 115. https://github.com/conchylicultor/deepqa#chatbot
 116. https://github.com/conchylicultor/deepqa#web-interface
 117. https://github.com/conchylicultor/deepqa#results
 118. https://github.com/conchylicultor/deepqa#pretrained-model
 119. https://github.com/conchylicultor/deepqa#improvements
 120. https://github.com/conchylicultor/deepqa#upgrade
 121. http://arxiv.org/abs/1506.05869
 122. https://github.com/macournoyer/neuralconvo
 123. https://github.com/macournoyer
 124. http://www.cs.cornell.edu/~cristian/cornell_movie-dialogs_corpus.html
 125. http://opus.lingfil.uu.se/opensubtitles.php
 126. https://github.com/eschnou
 127. https://github.com/conchylicultor/deepqa/blob/master/data/opensubs
 128. https://github.com/julien-c
 129. https://github.com/conchylicultor/deepqa/blob/master/data/scotus
 130. https://arxiv.org/abs/1506.08909
 131. https://github.com/julien-c
 132. https://github.com/conchylicultor/deepqa/blob/master/data/ubuntu
 133. https://github.com/julien-c
 134. https://github.com/conchylicultor/deepqa/blob/master/data/lightweight
 135. https://github.com/eschnou
 136. https://github.com/conchylicultor/deepqa/blob/master/data/embeddings
 137. http://redis.io/topics/quickstart
 138. https://github.com/conchylicultor/deepqa/blob/master/docker/readme.md
 139. https://www.tensorflow.org/how_tos/summaries_and_tensorboard/
 140. http://localhost:8000/
 141. https://docs.djangoproject.com/en/1.10/howto/deployment/checklist/
 142. http://e-pot.xyz/cv/chatbot.png
 143. https://github.com/conchylicultor/deepqa/tree/92863e2929580818f866f16969909fe2093d41d1
 144. https://drive.google.com/file/d/0bw-phsnskq23oxrftknqn0jguu0/view?usp=sharing
 145. https://drive.google.com/drive/folders/0bw-phsnskq23c29zq2n6x3lyc1u?usp=sharing
 146. https://mcastedu-my.sharepoint.com/personal/nicholas_cutajar_a100636_mcast_edu_mt/_layouts/15/guestaccess.aspx?folderid=077576c4cf9854642a968f67909380f45&authkey=avt2jwmpkf2r_mwbpi1eauy
 147. https://www.reddit.com/r/datasets/comments/59039y/updated_reddit_comment_dataset_up_to_201608/
 148. https://github.com/conchylicultor/musicgenerator
 149. https://github.com/site/terms
 150. https://github.com/site/privacy
 151. https://github.com/security
 152. https://githubstatus.com/
 153. https://help.github.com/
 154. https://github.com/contact
 155. https://github.com/pricing
 156. https://developer.github.com/
 157. https://training.github.com/
 158. https://github.blog/
 159. https://github.com/about
 160. https://github.com/conchylicultor/deepqa
 161. https://github.com/conchylicultor/deepqa

   hidden links:
 163. https://github.com/
 164. https://github.com/conchylicultor/deepqa
 165. https://github.com/conchylicultor/deepqa
 166. https://github.com/conchylicultor/deepqa
 167. https://help.github.com/articles/which-remote-url-should-i-use
 168. https://github.com/conchylicultor/deepqa#deep-qa
 169. https://github.com/conchylicultor/deepqa#table-of-contents
 170. https://github.com/conchylicultor/deepqa#presentation
 171. https://github.com/conchylicultor/deepqa#installation
 172. https://github.com/conchylicultor/deepqa#running
 173. https://github.com/conchylicultor/deepqa#chatbot
 174. https://github.com/conchylicultor/deepqa#web-interface
 175. https://github.com/conchylicultor/deepqa#results
 176. https://github.com/conchylicultor/deepqa#pretrained-model
 177. https://github.com/conchylicultor/deepqa#improvements
 178. https://github.com/
