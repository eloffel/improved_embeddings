
   (button)
     * [1]home
     * [2]research
          + [3]publications
          + [4]alphago
          + [5]id25
          + [6]dnc
          + [7]open source
          + [8]access to science
     * [9]applied
          + [10]deepmind health
          + [11]deepmind for google
          + [12]deepmind ethics & society
     * [13]news & blog
     * [14]about us
     * [15]careers

   (button) search (button) search
   [deepmind_logo_swirl.png]

[16]research

highlighted research

     * [17]alphago
     * [18]id25
     * [19]dnc

[20]publications

[21]open source

latest research news

   [22]towards robust and verified ai: specification testing, robust
   training, and formal verification

[23]applied

[24]deepmind health

[25]deepmind for google

[26]deepmind ethics & society

latest applied news

   [27]scaling streams with google

[28]careers

     * [29]home
     * [30]news & blog
     * [31]about us
     * [32]press
     * [33]terms and conditions
     * [34]privacy policy     updated

     *
     *
     *

kinetics

about

   kinetics-600 is a large-scale, high-quality dataset of youtube video
   urls which include a diverse range of human focused actions. our aim in
   releasing the kinetics dataset is to help the machine learning
   community to advance models for video understanding. it is an
   approximate super-set of the initial kinetics dataset released in 2017,
   now called kinetics-400.

   the dataset consists of approximately 500,000 video clips, and covers
   600 human action classes with at least 600 video clips for each action
   class. each clip lasts around 10 seconds and is labeled with a single
   class. all of the clips have been through multiple rounds of human
   annotation, and each is taken from a unique youtube video. the actions
   cover a broad range of classes including human-object interactions such
   as playing instruments, as well as human-human interactions such as
   shaking hands and hugging.

   kinetics forms the basis of an international human action
   classification competition being organised by [35]activitynet.

paper

   for a detailed description of how the dataset was compiled and baseline
   classifier performance see our [36]paper.

   the kinetics human action video dataset
   will kay, joao carreira,  karen simonyan, brian zhang, chloe hillier,
   sudheendra vijayanarasimhan, fabio viola, tim green, trevor back, paul
   natsev, mustafa suleyman, andrew zisserman,
   arxiv:1705.06950, may 2017

   please cite the paper if you use the dataset.

download

   kinetics-600

   these files were replaced on 1st may 2018 due to a splitting issue with
   the dataset:

     * [37]kinetics-600 training (zip file)
     * [38]kinetics-600 validation (zip file)
     * [39]kinetics-600 holdout test (zip file)
     * [40]kinetics-600 test (zip file)
     * [41]kinetics-600 readme (txt file)

   kinetics-400
     * [42]kinetics-400 training (zip file)
     * [43]kinetics-400 validation (zip file)
     * [44]kinetics-400 test (zip file)
     * [45]kinetics-400 readme (txt file)

   note, these files are updated periodically to remove video links that
   have been deleted on youtube or have been made non-public.

   the dataset is made available by google, inc. under a creative commons
   attribution 4.0 international (cc by 4.0) license.

   to provide suggestions for new human action classes and other feedback
   on the dataset [46]click here.

browse the dataset

   explore a selection of clips from the dataset. you can also [47]browse
   full screen.

   iframe:
   [48]https://storage.googleapis.com/deepmind-media/_widgets/kinetics/app
   .html

   a cautionary note on the use of this dataset: kinetics is drawn from
   the videos uploaded to youtube, based on the title of the video
   provided by the uploader. this means that the clips obtained reflect
   the distribution of the uploaded videos. for example, some classes may
   contain predominantly males or females, and there might be a bias
   towards exciting and unusual videos. consequently, the dataset is
   neither intended to be a canonical catalogue of human activities, nor
   are the example clips for the included action classes intended to be
   canonical representations of these actions. in particular, the
   distribution of gender, race, age or other factors across the depicted
   human actors should not be interpreted as representing the actual
   distribution of human actors.

meet the kinetics team

will kay

   [2017-05-19.2e16d0ba.fill-520x520_3pyc2o4.png]

product manager

jo  o carreira

   [joao.2e16d0ba.fill-520x520_gzfvk8k.jpg]

research scientist

eric noland

   [ericnoland.2e16d0ba.fill-520x520.jpg]

software engineer

brian zhang

   [brian2.2e16d0ba.fill-520x520_qryvsia.jpg]

research engineer

chloe hillier

   [chloe.2e16d0ba.fill-520x520_qffawqt.jpg]

program manager

prof. andrew zisserman

   [img_4037.2e16d0ba.fill-520x520_vid1136qk.jpg]

research scientist

   ____________________
   ____________________
   [49]show all results
   (button) close

[50]deepmind logo

   follow
     *
     *
     *

     * [51]research [52]research
     * [53]applied [54]applied
     * [55]news & blog [56]news & blog
     * [57]about us [58]about us
     * [59]careers [60]careers

     * [61]press
     * [62]terms and conditions
     * [63]privacy policy     updated
     * [64]modern slavery statement
     * [65]alphabet inc

      2019 deepmind technologies limited

   deepmind.com uses cookies to help give you the best possible user
   experience and to allow us to see how the site is used. by using this
   site, you agree that we can set and use these cookies. for more
   information on cookies and how to change your settings, see our
   [66]privacy policy.

references

   visible links
   1. https://deepmind.com/
   2. https://deepmind.com/research/
   3. https://deepmind.com/research/publications/
   4. https://deepmind.com/research/alphago/
   5. https://deepmind.com/research/id25/
   6. https://deepmind.com/research/dnc/
   7. https://deepmind.com/research/open-source/
   8. https://deepmind.com/research/access-science/
   9. https://deepmind.com/applied/
  10. https://deepmind.com/applied/deepmind-health/
  11. https://deepmind.com/applied/deepmind-google/
  12. https://deepmind.com/applied/deepmind-ethics-society/
  13. https://deepmind.com/blog/
  14. https://deepmind.com/about/
  15. https://deepmind.com/careers/
  16. https://deepmind.com/research/
  17. https://deepmind.com/research/alphago/
  18. https://deepmind.com/research/id25/
  19. https://deepmind.com/research/dnc/
  20. https://deepmind.com/research/publications/
  21. https://deepmind.com/research/open-source/
  22. https://deepmind.com/blog/robust-and-verified-ai/
  23. https://deepmind.com/applied/
  24. https://deepmind.com/applied/deepmind-health/
  25. https://deepmind.com/applied/deepmind-google/
  26. https://deepmind.com/applied/deepmind-ethics-society/
  27. https://deepmind.com/blog/scaling-streams-google/
  28. https://deepmind.com/careers/
  29. https://deepmind.com/
  30. https://deepmind.com/blog/
  31. https://deepmind.com/about/
  32. https://deepmind.com/press/
  33. https://deepmind.com/terms-and-conditions/
  34. https://deepmind.com/privacy-policy/
  35. http://activity-net.org/challenges/2018/
  36. https://arxiv.org/abs/1705.06950
  37. https://deepmind.com/documents/193/kinetics_600_train (1).zip
  38. https://deepmind.com/documents/194/kinetics_600_val (1).zip
  39. https://deepmind.com/documents/231/kinetics_600_holdout_test.zip
  40. https://deepmind.com/documents/232/kinetics_600_test (2).zip
  41. https://deepmind.com/documents/197/kinetics_600_readme (1).txt
  42. https://deepmind.com/documents/66/kinetics_train.zip
  43. https://deepmind.com/documents/65/kinetics_val.zip
  44. https://deepmind.com/documents/81/kinetics_test.zip
  45. https://deepmind.com/documents/67/kinetics_readme.txt
  46. https://docs.google.com/a/google.com/forms/d/e/1faipqlsekipadfx-v6jvjzvp4i4nhxfvhzszlza_tsgbztohrgmv1jw/viewform
  47. https://storage.googleapis.com/deepmind-media/_widgets/kinetics/app.html#/labels-all
  48. https://storage.googleapis.com/deepmind-media/_widgets/kinetics/app.html
  49. https://deepmind.com/research/open-source/open-source-datasets/kinetics/
  50. https://deepmind.com/
  51. https://deepmind.com/research/
  52. https://deepmind.com/research/
  53. https://deepmind.com/applied/
  54. https://deepmind.com/applied/
  55. https://deepmind.com/blog/
  56. https://deepmind.com/blog/
  57. https://deepmind.com/about/
  58. https://deepmind.com/about/
  59. https://deepmind.com/careers/
  60. https://deepmind.com/careers/
  61. https://deepmind.com/press/
  62. https://deepmind.com/terms-and-conditions/
  63. https://deepmind.com/privacy-policy/
  64. https://storage.googleapis.com/deepmind-media/modern_slavery/final_201_google_modern_slavery_statement.pdf
  65. https://abc.xyz/
  66. https://deepmind.com/privacy-policy/

   hidden links:
  68. https://twitter.com/deepmindai
  69. https://www.youtube.com/channel/ucp7jmxsy2xbc3kcae0mhq-a
  70. https://plus.google.com/+deepmindai
  71. https://twitter.com/deepmindai
  72. https://www.youtube.com/channel/ucp7jmxsy2xbc3kcae0mhq-a
  73. https://plus.google.com/+deepmindai
