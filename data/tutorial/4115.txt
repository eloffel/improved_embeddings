   #[1]publisher [2]medium [3]alternate

   [4]homepage
   [5]homepage
   [6]sign in[7]get started

   [8]towards data science
     * [9]data science
     * [10]machine learning
     * [11]programming
     * [12]visualization
     * [13]ai
     * [14]data journalism
     * [15]contribute
     __________________________________________________________________

getting started with python for data analysis

   [16]go to the profile of zak jost
   [17]zak jost (button) blockedunblock (button) followfollowing
   jun 20, 2017
   [1*whf2-yddjq1wdbgovao8gw.gif]
   [1*jqyfmpg4yhbwway8yldceq.png]

   a friend recently asked this and i thought it might benefit others if
   published here. this is for someone new to python that wants the
   easiest path from zero to one.
    1. download the python 3.x version of the anaconda distribution for
       your operating system [18]here. you will avoid a lot of
       install-related headaches by choosing this pre-bundled
       distribution. it comes with most of the important data analysis
       packages pre-installed.
    2. once you have it installed, test to make sure that the default
       python interpreter is the one you   ve just installed. this is
       important because your system may already have a version of python
       installed, but it won   t have all the good stuff in the anaconda
       bundle, so you need to make sure the new one is the default. on
       mac/linux this might mean typing which python in the terminal. or
       you can just run the python interpreter and make sure the version
       matches what you downloaded. if all went well, it should have been
       done by the install. if not, you   ll need to stop here and fix it.
    3. issue the jupyter notebook command in your shell. this should open
       a browser window. if not, open a browser and navigate to
       [19]http://localhost:8888. once there, create a new python
       notebook.
    4. go to the kernels section of [20]www.kaggle.com and filter to
       [21]python kernels. these are mostly jupyter notebooks of other
       people doing analysis or building models on data sets that are
       freely available on kaggle   s website. look for titles with things
       like eda (exploratory data analysis), as opposed to those building
       predictive models. find one that   s interesting and start recreating
       it in your notebook.

     note: you   ll find that when you try to recreate some of these
     analyses that you get import errors. this is likely because they   ve
     installed packages that are not bundled in the anaconda
     distribution. you   ll eventually need to learn how to interact with
     the conda package manager and this will be one of many rabbit holes
     you   ll eventually go down. usually it   s as easy as conda install
     <package_name> but you   ll need to find the right package name and
     sometimes you   ll need to specify other details. and other times
     you   ll need to use pip install <other_package_name>, but you   ll
     learn all that later.

high level library summary

   here   s a quick summary of the important libraries you   ll interact with
   frequently.
     * numpy: has a lot of the core functionality for scientific
       computing. under the hood is calling c-compiled code, so is much
       faster than the same functions written in python. not the most
       user-friendly.
     * scipy: similar to numpy but has more means for sampling from
       distributions, calculating test statistics   etc.
     * matplotlib: the main plotting framework. a necessary evil.
     * seaborn: import it after matplotlib and it will make your plots a
       lot prettier by default. also has its own functionality, but i find
       the coolest stuff runs too slow.
     * pandas: mostly a thin wrapper around numpy/scipy to make more user
       friendly. ideal for interacting with tables of data, which they
       call a dataframe. also has wrappers around plotting functionality
       to enable quick plotting while avoiding complications of mpl. i use
       pandas more than anything for manipulating data.
     * scikit-learn: has a lot of supervised and unsupervised machine
       learning algorithms. also has many metrics for doing model
       selection and a nice preprocessing library for doing things like
       principal component analysis or encoding categorical variables.

quick tips

    1. when in a jupyter notebook, put a question mark in front of any
       object before running the cell and it will open up the
       documentation for it. this is really handy when you   ve forgotten
       the details of what the function you   re trying to call is expecting
       you to pass. e.g. ?my_dataframe.apply will explain the apply method
       of the pandas.dataframe object, represented here by my_dataframe.
    2. you will likely always need to refer to the documentation for
       whatever library you   re using, so just keep it open in your
       browser. there   s just too many optional arguments and nuances.
    3. when it comes to the inevitable task of troubleshooting,
       s[22]tackoverflow probably has the answer.
    4. accept the fact that you   ll be doing things you don   t fully
       understand for awhile or you   ll get bogged down by details that
       aren   t that important. some day you   ll probably need to understand
       virtual environments and it   s really not that hard, but there are
       many detours like that that add unnecessary pain for someone
       getting started.
    5. read other people   s code. it   s the best way to learn conventions
       and best practices. that   s where the kaggle kernels really help.
       github also supports the display of jupyter notebooks in the
       browser, so there are tons of examples on the internet.

     * [23]data science
     * [24]python
     * [25]data analysis
     * [26]statistics

   (button)
   (button)
   (button) 78 claps
   (button) (button) (button) (button)

     (button) blockedunblock (button) followfollowing
   [27]go to the profile of zak jost

[28]zak jost

   research scientist at amazon aws. father. husband.

     (button) follow
   [29]towards data science

[30]towards data science

   sharing concepts, ideas, and codes.

     * (button)
       (button) 78
     * (button)
     *
     *

   [31]towards data science
   never miss a story from towards data science, when you sign up for
   medium. [32]learn more
   never miss a story from towards data science
   (button) get updatesget updates

references

   visible links
   1. https://plus.google.com/103654360130207659246
   2. https://towardsdatascience.com/osd.xml
   3. android-app://com.medium.reader/https/medium.com/p/64d6f6c256b2
   4. https://medium.com/
   5. https://medium.com/
   6. https://medium.com/m/signin?redirect=https://towardsdatascience.com/getting-started-with-python-for-data-analysis-64d6f6c256b2&source=--------------------------nav_reg&operation=login
   7. https://medium.com/m/signin?redirect=https://towardsdatascience.com/getting-started-with-python-for-data-analysis-64d6f6c256b2&source=--------------------------nav_reg&operation=register
   8. https://towardsdatascience.com/?source=logo-lo_f6bieiyz55f6---7f60cf5620c9
   9. https://towardsdatascience.com/data-science/home
  10. https://towardsdatascience.com/machine-learning/home
  11. https://towardsdatascience.com/programming/home
  12. https://towardsdatascience.com/data-visualization/home
  13. https://towardsdatascience.com/artificial-intelligence/home
  14. https://towardsdatascience.com/data-journalism/home
  15. https://towardsdatascience.com/contribute/home
  16. https://towardsdatascience.com/@zjost85?source=post_header_lockup
  17. https://towardsdatascience.com/@zjost85
  18. https://www.continuum.io/downloads
  19. http://localhost:8888/
  20. http://www.kaggle.com/
  21. https://www.kaggle.com/kernels?language=python
  22. https://stackoverflow.com/
  23. https://towardsdatascience.com/tagged/data-science?source=post
  24. https://towardsdatascience.com/tagged/python?source=post
  25. https://towardsdatascience.com/tagged/data-analysis?source=post
  26. https://towardsdatascience.com/tagged/statistics?source=post
  27. https://towardsdatascience.com/@zjost85?source=footer_card
  28. https://towardsdatascience.com/@zjost85
  29. https://towardsdatascience.com/?source=footer_card
  30. https://towardsdatascience.com/?source=footer_card
  31. https://towardsdatascience.com/
  32. https://medium.com/@medium/personalize-your-medium-experience-with-users-publications-tags-26a41ab1ee0c#.hx4zuv3mg

   hidden links:
  34. https://medium.com/p/64d6f6c256b2/share/twitter
  35. https://medium.com/p/64d6f6c256b2/share/facebook
  36. https://medium.com/p/64d6f6c256b2/share/twitter
  37. https://medium.com/p/64d6f6c256b2/share/facebook
