   [1]ideas [2]learning platform [3]conferences [4]shop
   search ____________________ submit
   [5]sign in

on our radar

   [6]ai
   [7]data
   [8]economy
   [9]operations
   [10]software architecture
   [11]software engineering
   [12]web programming
   [13]see all

   [14]ideas [15]learning platform [16]conferences [17]shop search
   ____________________ submit

on our radar

   [18]ai
   [19]data
   [20]economy
   [21]operations
   [22]software architecture
   [23]software engineering
   [24]web programming
   [25]see all

   [26]ai

             how to build and run your first deep learning network

   step-by-step instruction on training your own neural network.

   by [27]pete warden

   july 23, 2014

   [learning-71ec3da75e94b4cb67fd8dff171f391f.jpg]

   experiment with deep learning neural networks with [28]getting started
   with deep learning using keras and python, an oriole online tutorial by
   mike williams.

   when i first became interested in using deep learning for computer
   vision i found it hard to get started. there were only a couple of open
   source projects available, they had little documentation, were very
   experimental, and relied on a lot of tricky-to-install dependencies. a
   lot of new projects have appeared since, but they   re still aimed at
   vision researchers, so you   ll still hit a lot of the same obstacles if
   you   re approaching them from outside the field.

   in this article     and [29]the accompanying webcast     i   m going to show
   you how to run a pre-built network, and then take you through the steps
   of training your own. i   ve listed the steps i followed to set up
   everything toward the end of the article, but because the process is so
   involved, i recommend you download a vagrant virtual machine that i   ve
   pre-loaded with everything you need. this vm lets us skip over all the
   installation headaches and focus on building and running the neural
   networks.

setting up the virtual machine

   you   ll need an os x or linux machine and the free vagrant
   virtualization software to run the virtual machine. if you don   t
   already have vagrant, go to [30]http://www.vagrantup.com/ and follow
   the    getting started    instructions.

   once you have vagrant installed, open up a new terminal window. the
   first step will be to create a directory for the vm to use, by running
   these commands:

mkdir ~/dl_webcast

cd ~/dl_webcast


   then you   ll download the image of the virtual machine, which is almost
   2gb, so it may take a while.

vagrant box add dl_webcast https://d2rlgkokhpr1uq.cloudfront.net/dl_webcast.box

   now that you have the box downloaded, we   ll spin up a new virtual
   server:

vagrant init dl_webcast

vagrant up

   next, you   ll log into the virtual machine:

vagrant ssh

running a pre-built network

   i   m going to show you how to use the [31]caffe deep learning
   framework started by [32]yangqing jia and the berkeley vision and
   learning team. it has an active developer community, the code is
   entirely open source (though you can   t use the pre-built networks
   commercially), and there   s a lot of documentation, so it   s a great
   starting point. to begin, move into the project directory:

cd ~/caffe

   you   re going to run a network that   s based on the architecture used by
   [33]krizhevsky et al to win the id163 2012 contest. the bvlc team
   trained the network themselves, but because it   s built on [34]a set of
   images that are only available for non-commercial use, it   s not
   licensed for anything other than research. it attempts to recognize
   1,000 different categories of objects, and running it is as simple as
   this:

python python/classify.py --print_results examples/images/cat.jpg foo

   you should see a whole stream of logging messages, with a final line
   that looks like this:

[('kit fox', '0.27215'), ('red fox', '0.19984'), ('wood rabbit', '0.13209'), ('h
are', '0.07283'), ('egyptian cat', '0.06632')]

   congratulations     you   ve just run your first deep neural network! the
   output is an array of guesses about what the image contains, with the
   numbers representing how confident the algorithm is, and the text
   describing each category. if you check out the image it   s being run on,
   you   ll see it   s not quite a kit fox, but you can understand the
   mistake.
   image from the caffe open-source project, licensed under the bsd
   license
   [35]https://github.com/bvlc/caffe/blob/master/examples/images/cat.jpg

   to try it on your own images, copy them into the
~/dl_webcast/

   folder from your main os, and they   ll show up inside
/vagrant/

   in the vm   s file system.

training your own network

   the id163 network you just used had a thousand categories, so it
   requires more than a million different images in its training set, and
   takes more than a week to train even on a high-end gpu. luckily, there
   are simpler image recognition problems that take a lot less time to
   teach a network how to solve, and i   ll show you how to train a network
   for one of those.

   one of the first tasks that convolutional neural networks were used for
   was recognizing handwritten digits. [36]yann lecun did [37]a lot of
   pioneering work on this in the 90s, and a version of his lenet
   architecture is [38]included in caffe. you   ll need to download his
   [39]mnist database of 70,000 examples of handwritten digits:

cd data/mnist

./get_mnist.sh

cd ../..

cd examples/mnist

   once those images have been downloaded, you   ll need to make one change
   to the settings for the training process. i   ve already done this on the
   supplied vm, but if you   re starting from scratch you   ll need to
   run nano (or your favorite editor) on lenet_solver.prototxt, and update
   the final line to specify cpu rather than gpu, since there   s no
   usable graphics card within the virtual machine. then, running a
   supplied script will kick off the training process:

./train_lenet.sh

   you should see a lot of logging messages, and after a few minutes a
   completion message. if you do an
ls -l

   , you should see a recent
lenet_iter_10000

   file that contains the weights of the trained network. now you can run
   that network on a test image to check its performance. i   ve supplied
   several inside the vm, but you should be able to use any white-on-black
   digit.

python python/classify.py --print_results --model_def examples/mnist/lenet.proto
txt --pretrained_model examples/mnist/lenet_iter_10000 --force_grayscale --cente
r_only --labels_file data/mnist/mnist_words.txt --images_dim 28,28 data/mnist/sa
mple_digit.png foo


   the final output should be a score indicating a 100% id203 that
   this digit is a 4, which it is!

setup instructions

   below you   ll find the commands i ran to build the vagrant vm this
   section uses. if you   re using vagrant, create a clean ubuntu 14.04 box
   like this:

   vagrant box add ubuntu-14.04
   https://cloud-images.ubuntu.com/vagrant/trusty/current/trusty-server-cl
   oudimg-amd64-vagrant-disk1.box

   once you   ve created and initialized your vm, or if you   re using another
   method of running 14.04, log into the machine and start the [40]cuda
   setup. caffe relies on the cuda headers and libraries being present to
   build, even if you   re only going to run on the cpu, so you have to
   install the 900mb package.

sudo apt-get install linux-headers-
uname -r

   curl -o
   "http://developer.download.nvidia.com/compute/cuda/6_0/rel/installers/c
   uda_6.0.37_linux_64.run"
   chmod +x cuda_6.0.37_linux_64.run
   sudo ./cuda_6.0.37_linux_64.run
   --kernel-source-path=/usr/src/linux-headers-3.13.0-30-generic/

   at this point, you   ll see a series of prompts. you want to answer    no   
   to installing the driver (since we don   t have a compatible gpu), but
   yes to the samples and sdk, leaving the paths at the default. once
   that   s complete, you   ll need to update the library path to include the
   sdk.

echo 'export ld_library_path=$ld_library_path:/usr/local/cuda/lib64' >> ~/.bashr
c

source ~/.bashrc


   now we need a grab bag of dependencies installed via apt-get:

sudo apt-get install -y libprotobuf-dev libleveldb-dev libsnappy-dev libopencv-d
ev libboost-all-dev libhdf5-serial-dev protobuf-compiler gcc-4.6 g++-4.6 gcc-4.6
-multilib g++-4.6-multilib gfortran libjpeg62 libfreeimage-dev libatlas-base-dev
 git python-dev python-pip

   google   s logging framework isn   t available through a repository, so you
   have to build that from source:

wget https://google-glog.googlecode.com/files/glog-0.3.3.tar.gz

tar zxvf glog-0.3.3.tar.gz

cd glog-0.3.3

./configure

make

sudo make install

cd ..


   you should be ready to pull down the caffe source code:

   git clone https://github.com/bvlc/caffe.git
   cd caffe

   cuda has problems with the default gcc 4.8 compiler, so you   ll need to
   switch to 4.6:

 sudo update-alternatives --install /usr/bin/cc cc /usr/bin/gcc-4.6 30

sudo update-alternatives --install /usr/bin/c++ c++ /usr/bin/g++-4.6 30


   there   s a list of python module dependencies inside the caffe project,
   so you   ll use pip to install those, which can take a while:

   sudo pip install -r python/requirements.txt

   the current version of caffe isn   t set up to allow compiler switching,
   so you   ll need to do some patching of the make files:

cp makefile.config.example makefile.config

echo "cxx := /usr/bin/g++-4.6" >> makefile.config

sed -i 's/cxx :=/cxx ?=/' makefile


   the next step is compiling the project itself:

 make all

make test


   finally, download the pre-built neural network and label data:

examples/id163/get_caffe_reference_id163_model.sh

mv caffe_reference_id163_model examples/id163

data/ilsvrc12/get_ilsvrc_aux.sh

what now?

   you   ve run and even trained deep neural networks, but you haven   t been
   able to see very far inside the black box. i   m betting you need to
   recognize more than just digits and kittens, so in my next installment
   i   ll go into more detail about what   s happening under the hood and how
   you can start adapting them to the problems you want to solve!

   experiment with deep learning neural networks with [41]getting started
   with deep learning using keras and python, an oriole online tutorial by
   mike williams.

   article image:

   share
    1. [42]tweet
    2.
    3.
     __________________________________________________________________

   [43]pete warden

[44]pete warden

   pete warden is the tech lead of the tensorflow mobile team, and was
   formerly the cto of jetpac, which was acquired by google in 2014 for
   its deep learning technology optimized to run on mobile and embedded
   devices. he's previously worked at apple on gpu optimizations for image
   processing, and has written several books on data processing for
   o'reilly.
   [45]more
     __________________________________________________________________

   [46]bots landscape.

   [47]ai

[48]infographic: the bot platform ecosystem

   by [49]jon bruner

   a look at the artificial intelligence and messaging platforms behind
   the fast-growing chatbot community

   video
   [50]vertical forest, milan.

   [51]ai

[52]evolve ai

   by [53]naveen rao

   naveen rao explains how intel nervana is evolving the ai stack from
   silicon to the cloud.

   [54]welcome sign at o'reilly ai conference 2016

   [55]ai

[56]highlights from the o'reilly ai conference in new york 2016

   by [57]mac slocum

   watch highlights covering artificial intelligence, machine learning,
   intelligence engineering, and more. from the o'reilly ai conference in
   new york 2016.

   video
   [58]close up of uber's self driving car in pittsburgh.

   [59]ai

[60]how ai is propelling driverless cars, the future of surface transport

   by [61]shahin farshchi

   shahin farshchi examines role artificial intelligence will play in
   driverless cars.

about us

     * [62]our company
     * [63]teach/speak/write
     * [64]careers
     * [65]customer service
     * [66]contact us

site map

     * [67]ideas
     * [68]learning
     * [69]topics
     * [70]all

     *
     *
     *
     *
     *

      2019 o'reilly media, inc. all trademarks and registered trademarks
   appearing on oreilly.com are the property of their respective owners.
   [71]terms of service     [72]privacy policy     [73]editorial independence

   animal

   iframe: [74]https://www.googletagmanager.com/ns.html?id=gtm-5p4v6z

references

   visible links
   1. https://www.oreilly.com/ideas
   2. https://learning.oreilly.com/
   3. http://www.oreilly.com/conferences/
   4. http://shop.oreilly.com/
   5. https://www.oreilly.com/sign-in.html
   6. https://www.oreilly.com/topics/ai
   7. https://www.oreilly.com/topics/data
   8. https://www.oreilly.com/topics/economy
   9. https://www.oreilly.com/topics/operations
  10. https://www.oreilly.com/topics/software-architecture
  11. https://www.oreilly.com/topics/software-engineering
  12. https://www.oreilly.com/topics/web-programming
  13. https://www.oreilly.com/topics
  14. https://www.oreilly.com/ideas
  15. https://learning.oreilly.com/
  16. http://www.oreilly.com/conferences/
  17. http://shop.oreilly.com/
  18. https://www.oreilly.com/topics/ai
  19. https://www.oreilly.com/topics/data
  20. https://www.oreilly.com/topics/economy
  21. https://www.oreilly.com/topics/operations
  22. https://www.oreilly.com/topics/software-architecture
  23. https://www.oreilly.com/topics/software-engineering
  24. https://www.oreilly.com/topics/web-programming
  25. https://www.oreilly.com/topics
  26. https://www.oreilly.com/topics/ai
  27. https://www.oreilly.com/people/9cbf6-pete-warden
  28. https://www.safaribooksonline.com/oriole/getting-started-with-deep-learning-using-keras-and-python
  29. http://www.oreilly.com/pub/e/3121
  30. http://www.vagrantup.com/
  31. http://caffe.berkeleyvision.org/
  32. http://daggerfs.com/
  33. http://www.image-net.org/challenges/lsvrc/2012/supervision.pdf
  34. http://www.image-net.org/download.php
  35. https://github.com/bvlc/caffe/blob/master/examples/images/cat.jpg
  36. http://yann.lecun.com/
  37. http://yann.lecun.com/exdb/lenet/
  38. http://caffe.berkeleyvision.org/gathered/examples/mnist.html
  39. http://yann.lecun.com/exdb/mnist/
  40. http://docs.nvidia.com/cuda/cuda-getting-started-guide-for-linux/#axzz37xrgxx3w
  41. https://www.safaribooksonline.com/oriole/getting-started-with-deep-learning-using-keras-and-python
  42. https://twitter.com/share
  43. https://www.oreilly.com/people/9cbf6-pete-warden
  44. https://www.oreilly.com/people/9cbf6-pete-warden
  45. https://www.oreilly.com/people/9cbf6-pete-warden
  46. https://www.oreilly.com/ideas/infographic-the-bot-platform-ecosystem
  47. https://www.oreilly.com/topics/ai
  48. https://www.oreilly.com/ideas/infographic-the-bot-platform-ecosystem
  49. https://www.oreilly.com/people/b1d73-jon-bruner
  50. https://www.oreilly.com/ideas/evolve-ai
  51. https://www.oreilly.com/topics/ai
  52. https://www.oreilly.com/ideas/evolve-ai
  53. https://www.oreilly.com/people/14d38-naveen-rao
  54. https://www.oreilly.com/ideas/keynotes-from-ai-new-york-2016
  55. https://www.oreilly.com/topics/ai
  56. https://www.oreilly.com/ideas/keynotes-from-ai-new-york-2016
  57. https://www.oreilly.com/people/0d2c1-mac-slocum
  58. https://www.oreilly.com/ideas/how-ai-is-propelling-driverless-cars-the-future-of-surface-transport
  59. https://www.oreilly.com/topics/ai
  60. https://www.oreilly.com/ideas/how-ai-is-propelling-driverless-cars-the-future-of-surface-transport
  61. https://www.oreilly.com/people/c7521-shahin-farshchi
  62. http://oreilly.com/about/
  63. http://oreilly.com/work-with-us.html
  64. http://oreilly.com/careers/
  65. http://shop.oreilly.com/category/customer-service.do
  66. http://shop.oreilly.com/category/customer-service.do
  67. https://www.oreilly.com/ideas
  68. https://www.oreilly.com/topics/oreilly-learning
  69. https://www.oreilly.com/topics
  70. https://www.oreilly.com/all
  71. http://oreilly.com/terms/
  72. http://oreilly.com/privacy.html
  73. http://www.oreilly.com/about/editorial_independence.html
  74. https://www.googletagmanager.com/ns.html?id=gtm-5p4v6z

   hidden links:
  76. https://www.oreilly.com/
  77. https://www.facebook.com/oreilly/
  78. https://twitter.com/oreillymedia
  79. https://www.youtube.com/user/oreillymedia
  80. https://plus.google.com/+oreillymedia
  81. https://www.linkedin.com/company/oreilly-media
  82. https://www.oreilly.com/
