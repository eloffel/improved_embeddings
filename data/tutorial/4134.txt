   [1]ideas [2]learning platform [3]conferences [4]shop
   search ____________________ submit
   [5]sign in

on our radar

   [6]ai
   [7]data
   [8]economy
   [9]operations
   [10]software architecture
   [11]software engineering
   [12]web programming
   [13]see all

   [14]ideas [15]learning platform [16]conferences [17]shop search
   ____________________ submit

on our radar

   [18]ai
   [19]data
   [20]economy
   [21]operations
   [22]software architecture
   [23]software engineering
   [24]web programming
   [25]see all

   [26]ai

               an illustrated introduction to the id167 algorithm

   this post is an introduction to a popular id84
   algorithm: t-distributed stochastic neighbor embedding (id167).

   by [27]cyrille rossant

   march 3, 2015

   id167 plot id167 plot

an illustrated introduction to the id167 algorithm

   in the big data era, data is not only becoming bigger and bigger; it is
   also becoming more and more complex. this translates into a spectacular
   increase of the dimensionality of the data. for example, the
   dimensionality of a set of images is the number of pixels in any image,
   which ranges from thousands to millions.

   computers have no problem processing that many dimensions. however, we
   humans are limited to three dimensions. computers still need us
   (thankfully), so we often need ways to effectively visualize
   high-dimensional data before handing it over to the computer.

   how can we possibly reduce the dimensionality of a dataset from an
   arbitrary number to two or three, which is what we   re doing when we
   visualize data on a screen?

   the answer lies in the observation that many real-world datasets have a
   low intrinsic dimensionality, even though they   re embedded in a
   high-dimensional space. imagine that you   re shooting a panoramic
   landscape with your camera, while rotating around yourself. we can
   consider every picture as a point in a 16,000,000-dimensional space
   (assuming a 16 megapixels camera). yet, the set of pictures
   approximately lie in a three-dimensional space (yaw, pitch, roll). this
   low-dimensional space is embedded within the high-dimensional space in
   a complex, nonlinear way. hidden in the data, this structure can only
   be recovered via specific mathematical methods.

   this is the topic of [28]manifold learning, also called nonlinear
   id84, a branch of machine learning (more
   specifically, unsupervised learning). it is still an active area of
   research today to develop algorithms that can automatically recover a
   hidden structure in a high-dimensional dataset.

   this post is an introduction to a popular dimensonality reduction
   algorithm: [29]t-distributed stochastic neighbor embedding (id167).
   developed by [30]laurens van der maaten and [31]geoffrey hinton (see
   the [32]original paper here), this algorithm has been successfully
   applied to many real-world datasets. here, we   ll follow the original
   paper and describe the key mathematical concepts of the method, when
   applied to a toy dataset (handwritten digits). we   ll use python and the
   [33]scikit-learn library.

visualizing handwritten digits

   let   s first import a few libraries.
# that's an impressive list of imports.
import numpy as np
from numpy import linalg
from numpy.linalg import norm
from scipy.spatial.distance import squareform, pdist

# we import sklearn.
import sklearn
from sklearn.manifold import tsne
from sklearn.datasets import load_digits
from sklearn.preprocessing import scale

# we'll hack a bit with the id167 code in sklearn 0.15.2.
from sklearn.metrics.pairwise import pairwise_distances
from sklearn.manifold.t_sne import (_joint_probabilities,
                                    _kl_divergence)
from sklearn.utils.extmath import _ravel
# random state.
rs = 20150101

# we'll use matplotlib for graphics.
import matplotlib.pyplot as plt
import matplotlib.patheffects as patheffects
import matplotlib
%matplotlib inline

# we import seaborn to make nice plots.
import seaborn as sns
sns.set_style('darkgrid')
sns.set_palette('muted')
sns.set_context("notebook", font_scale=1.5,
                rc={"lines.linewidth": 2.5})

# we'll generate an animation with matplotlib and moviepy.
from moviepy.video.io.bindings import mplfig_to_npimage
import moviepy.editor as mpy

   now we load the classic [34]handwritten digits datasets. it contains
   1797 images with \(8*8=64\) pixels each.
digits = load_digits()
digits.data.shape

print(digits['descr'])

   here are the images:
nrows, ncols = 2, 5
plt.figure(figsize=(6,3))
plt.gray()
for i in range(ncols * nrows):
    ax = plt.subplot(nrows, ncols, i + 1)
    ax.matshow(digits.images[i,...])
    plt.xticks([]); plt.yticks([])
    plt.title(digits.target[i])
plt.savefig('images/digits-generated.png', dpi=150)

   digits

   now let   s run the id167 algorithm on the dataset. it just takes one
   line with scikit-learn.
# we first reorder the data points according to the handwritten numbers.
x = np.vstack([digits.data[digits.target==i]
               for i in range(10)])
y = np.hstack([digits.target[digits.target==i]
               for i in range(10)])

digits_proj = tsne(random_state=rs).fit_transform(x)

   here is a utility function used to display the transformed dataset. the
   color of each point refers to the actual digit (of course, this
   information was not used by the id84 algorithm).
def scatter(x, colors):
    # we choose a color palette with seaborn.
    palette = np.array(sns.color_palette("hls", 10))

    # we create a scatter plot.
    f = plt.figure(figsize=(8, 8))
    ax = plt.subplot(aspect='equal')
    sc = ax.scatter(x[:,0], x[:,1], lw=0, s=40,
                    c=palette[colors.astype(np.int)])
    plt.xlim(-25, 25)
    plt.ylim(-25, 25)
    ax.axis('off')
    ax.axis('tight')

    # we add the labels for each digit.
    txts = []
    for i in range(10):
        # position of each label.
        xtext, ytext = np.median(x[colors == i, :], axis=0)
        txt = ax.text(xtext, ytext, str(i), fontsize=24)
        txt.set_path_effects([
            patheffects.stroke(linewidth=5, foreground="w"),
            patheffects.normal()])
        txts.append(txt)

    return f, ax, sc, txts

   here is the result.
scatter(digits_proj, y)
plt.savefig('images/digits_tsne-generated.png', dpi=120)

   transformed digits with id167

   we observe that the images corresponding to the different digits are
   clearly separated into different clusters of points.

mathematical framework

   let   s explain how the algorithm works. first, a few definitions.

   a data point is a point \(x_i\) in the original data space
   \(\mathbf{r}^d\), where \(d=64\) is the dimensionality of the data
   space. every point is an image of a handwritten digit here. there are
   \(n=1797\) points.

   a map point is a point \(y_i\) in the map space \(\mathbf{r}^2\). this
   space will contain our final representation of the dataset. there is a
   bijection between the data points and the map points: every map point
   represents one of the original images.

   how do we choose the positions of the map points? we want to conserve
   the structure of the data. more specifically, if two data points are
   close together, we want the two corresponding map points to be close
   too. let   s \(\left| x_i - x_j \right|\) be the euclidean distance
   between two data points, and \(\left| y_i - y_j \right|\) the distance
   between the map points. we first define a conditional similarity
   between the two data points:

   \(p_{j|i} = \frac{\exp\left(-\left| x_i - x_j\right|^2 \big/
   2\sigma_i^2\right)}{\displaystyle\sum_{k \neq i} \exp\left(-\left| x_i
   - x_k\right|^2 \big/ 2\sigma_i^2\right)}\)

   this measures how close \(x_j\) is from \(x_i\), considering a gaussian
   distribution around \(x_i\) with a given variance \(\sigma_i^2\). this
   variance is different for every point; it is chosen such that points in
   dense areas are given a smaller variance than points in sparse areas.
   the original paper details how this variance is computed exactly.

   now, we define the similarity as a symmetrized version of the
   conditional similarity:

   \(p_{ij} = \frac{p_{j|i} + p_{i|j}}{2n}\)

   we obtain a similarity matrix for our original dataset. what does this
   matrix look like?

similarity matrix

   the following function computes the similarity with a constant
   \(\sigma\).
def _joint_probabilities_constant_sigma(d, sigma):
    p = np.exp(-d**2/2 * sigma**2)
    p /= np.sum(p, axis=1)
    return p

   we now compute the similarity with a \(\sigma_i\) depending on the data
   point (found via a binary search, according to the original id167
   paper). this algorithm is implemented in the _joint_probabilities
   private function in scikit-learn   s code.
# pairwise distances between all data points.
d = pairwise_distances(x, squared=true)
# similarity with constant sigma.
p_constant = _joint_probabilities_constant_sigma(d, .002)
# similarity with variable sigma.
p_binary = _joint_probabilities(d, 30., false)
# the output of this function needs to be reshaped to a square matrix.
p_binary_s = squareform(p_binary)

   we can now display the distance matrix of the data points, and the
   similarity matrix with both a constant and variable sigma.
plt.figure(figsize=(12, 4))
pal = sns.light_palette("blue", as_cmap=true)

plt.subplot(131)
plt.imshow(d[::10, ::10], interpolation='none', cmap=pal)
plt.axis('off')
plt.title("distance matrix", fontdict={'fontsize': 16})

plt.subplot(132)
plt.imshow(p_constant[::10, ::10], interpolation='none', cmap=pal)
plt.axis('off')
plt.title("$p_{j|i}$ (constant $\sigma$)", fontdict={'fontsize': 16})

plt.subplot(133)
plt.imshow(p_binary_s[::10, ::10], interpolation='none', cmap=pal)
plt.axis('off')
plt.title("$p_{j|i}$ (variable $\sigma$)", fontdict={'fontsize': 16})
plt.savefig('images/similarity-generated.png', dpi=120)

   we can already observe the 10 groups in the data, corresponding to the
   10 numbers.

   let   s also define a similarity matrix for our map points.

   \(q_{ij} = \frac{f(\left| x_i - x_j\right|)}{\displaystyle\sum_{k \neq
   i} f(\left| x_i - x_k\right|)} \quad \textrm{with} \quad f(z) =
   \frac{1}{1+z^2}\)

   this is the same idea as for the data points, but with a different
   distribution ([35]t-student with one degree of freedom, or [36]cauchy
   distribution, instead of a gaussian distribution). we   ll elaborate on
   this choice later.

   whereas the data similarity matrix \(\big(p_{ij}\big)\) is fixed, the
   map similarity matrix \(\big(q_{ij}\big)\) depends on the map points.
   what we want is for these two matrices to be as close as possible. this
   would mean that similar data points yield similar map points.

a physical analogy

   let   s assume that our map points are all connected with springs. the
   stiffness of a spring connecting points \(i\) and \(j\) depends on the
   mismatch between the similarity of the two data points and the
   similarity of the two map points, that is, \(p_{ij} - q_{ij}\). now, we
   let the system evolve according to the laws of physics. if two map
   points are far apart while the data points are close, they are
   attracted together. if they are nearby while the data points are
   dissimilar, they are repelled.

   the final mapping is obtained when the equilibrium is reached.

   here is an illustration of a dynamic graph layout based on a similar
   idea. nodes are connected via springs and the system evolves according
   to law of physics (example by [37]mike bostock).

   iframe:
   [38]https://d3ansictanv2wj.cloudfront.net/rossant-f06184034ba66a0bd06a-
   001.html

algorithm

   remarkably, this physical analogy stems naturally from the mathematical
   algorithm. it corresponds to minimizing the [39]kullback-leiber
   divergence between the two distributions \(\big(p_{ij}\big)\) and
   \(\big(q_{ij}\big)\):

   \(kl(p||q) = \sum_{i, j} p_{ij} \, \log \frac{p_{ij}}{q_{ij}}.\)

   this measures the distance between our two similarity matrices.

   to minimize this score, we perform a id119. the gradient can
   be computed analytically:

   \(\frac{\partial \, kl(p || q)}{\partial y_i} = 4 \sum_j (p_{ij} -
   q_{ij}) g\left( \left| x_i - x_j\right| \right) u_{ij} \quad
   \textrm{where} \, g(z) = \frac{z}{1+z^2}.\)

   here, \(u_{ij}\) is a unit vector going from \(y_j\) to \(y_i\). this
   gradient expresses the sum of all spring forces applied to map point
   \(i\).

   let   s illustrate this process by creating an animation of the
   convergence. we   ll have to [40]monkey-patch the internal
   _gradient_descent() function from scikit-learn   s id167 implementation
   in order to register the position of the map points at every iteration.
# this list will contain the positions of the map points at every iteration.
positions = []
def _gradient_descent(objective, p0, it, n_iter, n_iter_without_progress=30,
                      momentum=0.5, learning_rate=1000.0, min_gain=0.01,
                      min_grad_norm=1e-7, min_error_diff=1e-7, verbose=0,
                      args=[]):
    # the documentation of this function can be found in scikit-learn's code.
    p = p0.copy().ravel()
    update = np.zeros_like(p)
    gains = np.ones_like(p)
    error = np.finfo(np.float).max
    best_error = np.finfo(np.float).max
    best_iter = 0

    for i in range(it, n_iter):
        # we save the current position.
        positions.append(p.copy())

        new_error, grad = objective(p, *args)
        error_diff = np.abs(new_error - error)
        error = new_error
        grad_norm = linalg.norm(grad)

        if error < best_error:
            best_error = error
            best_iter = i
        elif i - best_iter > n_iter_without_progress:
            break
        if min_grad_norm >= grad_norm:
            break
        if min_error_diff >= error_diff:
            break

        inc = update * grad >= 0.0
        dec = np.invert(inc)
        gains[inc] += 0.05
        gains[dec] *= 0.95
        np.clip(gains, min_gain, np.inf)
        grad *= gains
        update = momentum * update - learning_rate * grad
        p += update

    return p, error, i
sklearn.manifold.t_sne._gradient_descent = _gradient_descent

   let   s run the algorithm again, but this time saving all intermediate
   positions.
x_proj = tsne(random_state=rs).fit_transform(x)

x_iter = np.dstack(position.reshape(-1, 2)
                   for position in positions)

   we create an animation using [41]moviepy.
f, ax, sc, txts = scatter(x_iter[..., -1], y)

def make_frame_mpl(t):
    i = int(t*40)
    x = x_iter[..., i]
    sc.set_offsets(x)
    for j, txt in zip(range(10), txts):
        xtext, ytext = np.median(x[y == j, :], axis=0)
        txt.set_x(xtext)
        txt.set_y(ytext)
    return mplfig_to_npimage(f)

animation = mpy.videoclip(make_frame_mpl,
                          duration=x_iter.shape[2]/40.)
animation.write_gif("https://d3ansictanv2wj.cloudfront.net/images/animation-94a2
c1ff.gif", fps=20)

   [animation-94a2c1ff.gif]

   we can clearly observe the different phases of the optimization, as
   described in the original paper.

   let   s also create an animation of the similarity matrix of the map
   points. we   ll observe that it   s getting closer and closer to the
   similarity matrix of the data points.
n = 1. / (pdist(x_iter[..., -1], "sqeuclidean") + 1)
q = n / (2.0 * np.sum(n))
q = squareform(q)

f = plt.figure(figsize=(6, 6))
ax = plt.subplot(aspect='equal')
im = ax.imshow(q, interpolation='none', cmap=pal)
plt.axis('tight')
plt.axis('off')

def make_frame_mpl(t):
    i = int(t*40)
    n = 1. / (pdist(x_iter[..., i], "sqeuclidean") + 1)
    q = n / (2.0 * np.sum(n))
    q = squareform(q)
    im.set_data(q)
    return mplfig_to_npimage(f)

animation = mpy.videoclip(make_frame_mpl,
                          duration=x_iter.shape[2]/40.)
animation.write_gif("https://d3ansictanv2wj.cloudfront.net/images/animation_matr
ix-da2d5f1b.gif", fps=20)

   [animation_matrix-da2d5f1b.gif]

the t-student distribution

   let   s now explain the choice of the t-student distribution for the map
   points, while a normal distribution is used for the data points. [42]it
   is well known that the volume of the \(n\)-dimensional ball of radius
   \(r\) scales as \(r^n\). when \(n\) is large, if we pick random points
   uniformly in the ball, most points will be close to the surface, and
   very few will be near the center.

   this is illustrated by the following simulation, showing the
   distribution of the distances of these points, for different
   dimensions.
npoints = 1000
plt.figure(figsize=(15, 4))
for i, d in enumerate((2, 5, 10)):
    # normally distributed points.
    u = np.random.randn(npoints, d)
    # now on the sphere.
    u /= norm(u, axis=1)[:, none]
    # uniform radius.
    r = np.random.rand(npoints, 1)
    # uniformly within the ball.
    points = u * r**(1./d)
    # plot.
    ax = plt.subplot(1, 3, i+1)
    ax.set_xlabel('ball radius')
    if i == 0:
        ax.set_ylabel('distance from origin')
    ax.hist(norm(points, axis=1),
            bins=np.linspace(0., 1., 50))
    ax.set_title('d=%d' % d, loc='left')
plt.savefig('images/spheres-generated.png', dpi=100, bbox_inches='tight')

   spheres

   when reducing the dimensionality of a dataset, if we used the same
   gaussian distribution for the data points and the map points, we would
   get an imbalance in the distribution of the distances of a point   s
   neighbors. this is because the distribution of the distances is so
   different between a high-dimensional space and a low-dimensional space.
   yet, the algorithm tries to reproduce the same distances in the two
   spaces. this imbalance would lead to an excess of attraction forces and
   a sometimes unappealing mapping. this is actually what happens in the
   original sne algorithm, by [43]hinton and roweis (2002).

   the id167 algorithm works around this problem by using a t-student with
   one degree of freedom (or cauchy) distribution for the map points. this
   distribution has a much heavier tail than the gaussian distribution,
   which compensates the original imbalance. for a given similarity
   between two data points, the two corresponding map points will need to
   be much further apart in order for their similarity to match the data
   similarity. this can be seen in the following plot.
z = np.linspace(0., 5., 1000)
gauss = np.exp(-z**2)
cauchy = 1/(1+z**2)
plt.plot(z, gauss, label='gaussian distribution')
plt.plot(z, cauchy, label='cauchy distribution')
plt.legend()
plt.savefig('images/distributions-generated.png', dpi=100)

   gaussian and cauchy distributions

   using this distribution leads to more effective data visualizations,
   where clusters of points are more distinctly separated.

conclusion

   the id167 algorithm provides an effective method to visualize a complex
   dataset. it successfully uncovers hidden structures in the data,
   exposing natural clusters and smooth nonlinear variations along the
   dimensions. it has been implemented in many languages, including
   python, and it can be easily used thanks to the scikit-learn library.

   the references below describe some optimizations and improvements that
   can be made to the algorithm and implementations. in particular, the
   algorithm described here is quadratic in the number of samples, which
   makes it unscalable to large datasets. one could for example obtain an
   \(o(n \log n)\) complexity by using the barnes-hut algorithm to
   accelerate the n-body simulation via a quadtree or an octree.

references

     * [44]original paper
     * [45]optimized id167 paper
     * [46]a notebook on id167 by alexander flabish
     * [47]official id167 page
     * [48]scikit documentation
     * [49]barnes-hut id167 implementation in python
     * [50]barnes-hut on wikipedia
     * [51]id167 on wikipedia
     * [52]implementation in scikit-learn

   article image: id167 plot

   share
    1. [53]tweet
    2.
    3.
     __________________________________________________________________

[54]cyrille rossant

   data scientist | software engineer. #neuroinformatics #maths #python
   #opendata #dataviz. author of the #ipython minibook and cookbook
   http://ipython-books.github.io/
   [55]more
     __________________________________________________________________

   [56]bots landscape.

   [57]ai

[58]infographic: the bot platform ecosystem

   by [59]jon bruner

   a look at the artificial intelligence and messaging platforms behind
   the fast-growing chatbot community

   video
   [60]vertical forest, milan.

   [61]ai

[62]evolve ai

   by [63]naveen rao

   naveen rao explains how intel nervana is evolving the ai stack from
   silicon to the cloud.

   [64]welcome sign at o'reilly ai conference 2016

   [65]ai

[66]highlights from the o'reilly ai conference in new york 2016

   by [67]mac slocum

   watch highlights covering artificial intelligence, machine learning,
   intelligence engineering, and more. from the o'reilly ai conference in
   new york 2016.

   video
   [68]close up of uber's self driving car in pittsburgh.

   [69]ai

[70]how ai is propelling driverless cars, the future of surface transport

   by [71]shahin farshchi

   shahin farshchi examines role artificial intelligence will play in
   driverless cars.

about us

     * [72]our company
     * [73]teach/speak/write
     * [74]careers
     * [75]customer service
     * [76]contact us

site map

     * [77]ideas
     * [78]learning
     * [79]topics
     * [80]all

     *
     *
     *
     *
     *

      2019 o'reilly media, inc. all trademarks and registered trademarks
   appearing on oreilly.com are the property of their respective owners.
   [81]terms of service     [82]privacy policy     [83]editorial independence

   animal

   iframe: [84]https://www.googletagmanager.com/ns.html?id=gtm-5p4v6z

references

   visible links
   1. https://www.oreilly.com/ideas
   2. https://learning.oreilly.com/
   3. http://www.oreilly.com/conferences/
   4. http://shop.oreilly.com/
   5. https://www.oreilly.com/sign-in.html
   6. https://www.oreilly.com/topics/ai
   7. https://www.oreilly.com/topics/data
   8. https://www.oreilly.com/topics/economy
   9. https://www.oreilly.com/topics/operations
  10. https://www.oreilly.com/topics/software-architecture
  11. https://www.oreilly.com/topics/software-engineering
  12. https://www.oreilly.com/topics/web-programming
  13. https://www.oreilly.com/topics
  14. https://www.oreilly.com/ideas
  15. https://learning.oreilly.com/
  16. http://www.oreilly.com/conferences/
  17. http://shop.oreilly.com/
  18. https://www.oreilly.com/topics/ai
  19. https://www.oreilly.com/topics/data
  20. https://www.oreilly.com/topics/economy
  21. https://www.oreilly.com/topics/operations
  22. https://www.oreilly.com/topics/software-architecture
  23. https://www.oreilly.com/topics/software-engineering
  24. https://www.oreilly.com/topics/web-programming
  25. https://www.oreilly.com/topics
  26. https://www.oreilly.com/topics/ai
  27. https://www.oreilly.com/people/4dff1-cyrille-rossant
  28. http://en.wikipedia.org/wiki/nonlinear_dimensionality_reduction
  29. http://en.wikipedia.org/wiki/t-distributed_stochastic_neighbor_embedding
  30. http://lvdmaaten.github.io/
  31. http://www.cs.toronto.edu/~hinton/
  32. http://jmlr.csail.mit.edu/papers/volume9/vandermaaten08a/vandermaaten08a.pdf
  33. http://scikit-learn.org/stable/index.html
  34. http://scikit-learn.org/stable/modules/generated/sklearn.datasets.load_digits.html#sklearn.datasets.load_digits
  35. http://en.wikipedia.org/wiki/student's_t-distribution
  36. http://en.wikipedia.org/wiki/cauchy_distribution
  37. http://bl.ocks.org/mbostock/4062045
  38. https://d3ansictanv2wj.cloudfront.net/rossant-f06184034ba66a0bd06a-001.html
  39. http://en.wikipedia.org/wiki/kullback   leibler_divergence
  40. http://en.wikipedia.org/wiki/monkey_patch
  41. http://zulko.github.io/moviepy/
  42. http://en.wikipedia.org/wiki/volume_of_an_n-ball
  43. http://www.cs.toronto.edu/~fritz/absps/sne.pdf
  44. http://jmlr.csail.mit.edu/papers/volume9/vandermaaten08a/vandermaaten08a.pdf
  45. http://lvdmaaten.github.io/publications/papers/jmlr_2014.pdf
  46. http://nbviewer.ipython.org/urls/gist.githubusercontent.com/alexanderfabisch/1a0c648de22eff4a2a3e/raw/59d5bc5ed8f8bfd9ff1f7faa749d1b095aa97d5a/id167.ipynb
  47. http://lvdmaaten.github.io/tsne/
  48. http://scikit-learn.org/stable/modules/generated/sklearn.manifold.tsne.html
  49. https://github.com/danielfrg/tsne
  50. http://en.wikipedia.org/wiki/barnes   hut_simulation
  51. http://en.wikipedia.org/wiki/t-distributed_stochastic_neighbor_embedding
  52. https://github.com/scikit-learn/scikit-learn/blob/master/sklearn/manifold/t_sne.py
  53. https://twitter.com/share
  54. https://www.oreilly.com/people/4dff1-cyrille-rossant
  55. https://www.oreilly.com/people/4dff1-cyrille-rossant
  56. https://www.oreilly.com/ideas/infographic-the-bot-platform-ecosystem
  57. https://www.oreilly.com/topics/ai
  58. https://www.oreilly.com/ideas/infographic-the-bot-platform-ecosystem
  59. https://www.oreilly.com/people/b1d73-jon-bruner
  60. https://www.oreilly.com/ideas/evolve-ai
  61. https://www.oreilly.com/topics/ai
  62. https://www.oreilly.com/ideas/evolve-ai
  63. https://www.oreilly.com/people/14d38-naveen-rao
  64. https://www.oreilly.com/ideas/keynotes-from-ai-new-york-2016
  65. https://www.oreilly.com/topics/ai
  66. https://www.oreilly.com/ideas/keynotes-from-ai-new-york-2016
  67. https://www.oreilly.com/people/0d2c1-mac-slocum
  68. https://www.oreilly.com/ideas/how-ai-is-propelling-driverless-cars-the-future-of-surface-transport
  69. https://www.oreilly.com/topics/ai
  70. https://www.oreilly.com/ideas/how-ai-is-propelling-driverless-cars-the-future-of-surface-transport
  71. https://www.oreilly.com/people/c7521-shahin-farshchi
  72. http://oreilly.com/about/
  73. http://oreilly.com/work-with-us.html
  74. http://oreilly.com/careers/
  75. http://shop.oreilly.com/category/customer-service.do
  76. http://shop.oreilly.com/category/customer-service.do
  77. https://www.oreilly.com/ideas
  78. https://www.oreilly.com/topics/oreilly-learning
  79. https://www.oreilly.com/topics
  80. https://www.oreilly.com/all
  81. http://oreilly.com/terms/
  82. http://oreilly.com/privacy.html
  83. http://www.oreilly.com/about/editorial_independence.html
  84. https://www.googletagmanager.com/ns.html?id=gtm-5p4v6z

   hidden links:
  86. https://www.oreilly.com/
  87. https://www.facebook.com/oreilly/
  88. https://twitter.com/oreillymedia
  89. https://www.youtube.com/user/oreillymedia
  90. https://plus.google.com/+oreillymedia
  91. https://www.linkedin.com/company/oreilly-media
  92. https://www.oreilly.com/
