   [1]ideas [2]learning platform [3]conferences [4]shop
   search ____________________ submit
   [5]sign in

on our radar

   [6]ai
   [7]data
   [8]economy
   [9]operations
   [10]software architecture
   [11]software engineering
   [12]web programming
   [13]see all

   [14]ideas [15]learning platform [16]conferences [17]shop search
   ____________________ submit

on our radar

   [18]ai
   [19]data
   [20]economy
   [21]operations
   [22]software architecture
   [23]software engineering
   [24]web programming
   [25]see all

   [26]ai

                              tensorflow for poets

   how to build your own image classifier with no coding.

   by [27]pete warden

   march 2, 2016

   photographic mosaic. photographic mosaic. (source: [28]by j2thawiki on
   wikimedia commons)

   to learn how to build and train your first tensorflow graph from the
   ground up, check out [29]aaron schumacher's oriole tutorial: hello,
   tensorflow!

   this post originally appeared on [30]pete warden's blog; it is
   republished here with permission.

   when i first started investigating the world of deep learning, i found
   it very hard to get started. there wasn   t much documentation, and what
   existed was aimed at academic researchers who already knew a lot of the
   jargon and background. thankfully, that has changed over the last few
   years, with a lot more guides and tutorials appearing.

   i always loved [31]ec2 for poets, though, and i haven   t seen anything
   for deep learning that   s aimed at as wide an audience. ec2 for poets is
   an explanation of cloud computing that removes a lot of the unnecessary
   mystery by walking anyone with basic computing knowledge step-by-step
   through building a simple application on the platform. in the same
   spirit, i want to show how anyone with a mac laptop and the ability to
   use the terminal can create their own image classifier using
   [32]tensorflow, without having to do any coding.

   i feel very lucky to be a part of building [33]tensorflow because it   s
   a great opportunity to bring the power of deep learning to a mass
   audience. i look around and see so many applications that could benefit
   from the technology by understanding the images, speech, or text their
   users enter. the frustrating part is that deep learning is still seen
   as a very hard topic for product engineers to grasp. that   s true at the
   cutting edge of research, but otherwise it   s mostly a holdover from the
   early days. there   s already a lot of great documentation on the
   [34]tensorflow site, but to demonstrate how easy it can be for general
   software engineers to pick up, i   m going to present a walk-through that
   takes you from a clean os x laptop all the way to classifying your own
   categories of images. you   ll find written instructions in this post,
   along with [35]a screencast showing exactly what i   m doing.


   iframe: [36]https://www.youtube.com/embed/h7xueizjqqo


docker

   it   s possible to get tensorflow running natively on os x, but there   s
   less standardization around how the development tools like python are
   installed, which makes it hard to give one-size-fits-all instructions.
   to make life easier, i   m going to use the free docker container system,
   which will allow me to install a linux virtual machine that runs on my
   macbook pro. the advantage is that i can start from a known system
   image, so the instructions are a lot more likely to work for everyone.

installing docker

   there   s full documentation on installing docker at [37]docker.com, and
   it   s likely to be updated over time, but i will run through exactly
   what steps i took to get it running here.
     * i went to [38]docs.docker.com/mac/ in my browser.
     * [39]step one of the instructions sent me to [40]download the docker
       toolbox.
     * on the toolbox page, i clicked on the mac download button.
     * that downloaded a dockertoolbox-1.10.2.pkg file.
     * i ran that downloaded pkg to install the toolbox.
     * at the end of the install process, i chose the docker quickstart
       terminal.
     * that opened up a new terminal window and ran through an
       installation script.
     * at the end of the script, i saw ascii art of a whale and i was left
       at a prompt.
     * i went back to [41]step one of the instructions, and ran the
       suggested command in the terminal:
docker run hello-world
     * this gave me output confirming my installation of docker had
       worked:
hello from docker.
this message shows that your installation appears to be working correctly.

installing tensorflow

   now that i   ve got docker installed and running, i can get a linux
   virtual machine with tensorflow pre-installed running. we create daily
   development images, and ones for every major release. because the
   example code i   m going to use came in after the last versioned release,
   0.7.1, we   ll have to do some extra work below to update the source code
   using git, but once 0.8 comes out you could replace the    0.7.1    below
   with the 0.8.0 instead, and skip the    updating the code    section.
   [42]the docker section in the tensorflow documentation has more
   information.

   to download and run the tensorflow docker image, use this command from
   the terminal:
docker run -it b.gcr.io/tensorflow/tensorflow:0.7.1-devel

   this will show a series of download and extraction steps. these are the
   different components of the tensorflow image being assembled. it needs
   to download roughly a gigabyte of data, so it can take a while on a
   slow network connection.

   once that   s complete, you   ll find yourself in a new terminal. this is
   now actually the shell for the linux virtual machine you   ve downloaded.
   to confirm this has been successful, run this command:
ls /tensorflow

   you should see a series of directories, including a tensorflow one and
   some .build files, something like this:
   series of directories

optimizing docker

   often docker is just used for testing web apps, where computational
   performance isn   t that important, so the speed of the processor in the
   virtual machine isn   t crucial. in our example, we   re going to be doing
   some very heavy number-crunching, though, so optimizing the
   configuration for speed is important.

   under the hood, docker actually uses [43]virtualbox to run its images,
   and we   ll use its control panel to manage the setup. to do that, we   ll
   need to take the following steps:
     * find the virtualbox application on your mac. i like to use
       spotlight to find and open it, so i don   t have to hunt around on
       the file system.
     * once virtualbox is open, you should see a left-hand pane showing
       virtual machines. there should be one called    default    that   s
       running.
     * right-click on    default    to bring up the context menu and chose
          close->acpi shutdown   . the other close options should also work,
       but this is the most clean.
     * once the shutdown is complete,    default    should have the text
          powered off    below it. right click on it again and choose
          settings       from the menu.
     * click on the    system    icon, and then choose the    motherboard    tab.
     * drag the    base memory    slider as far as the green section goes,
       which is normally around 75% of your total laptop   s memory. so in
       my case, it   s 12gb, because i have a 16gb machine.
     * click on the    processor    tab, and set the number of processors
       higher than the default of 1. most likely on a modern macbook pro 4
       is a good setting, but use the green bar below the slider as a
       guide.
     * click    ok    on the settings dialog.
     * right-click on    default    and choose    start->headless start   .

   you should find that your terminal was kicked out of the linux prompt
   when you stopped the    default    box, but now that you   ve restarted it,
   you can run the same command to access it again:
docker run -it b.gcr.io/tensorflow/tensorflow:0.7.1-devel

   the only difference is that now the virtual machine will have access to
   a lot more of your laptop   s computing power, so the example should run
   a lot faster!

downloading images

   the rest of this walk-through is based on [44]the image-retraining
   example on the tensorflow site. it shows you how to take your own
   images organized into folders by category and use them to quickly
   retrain the top layer of the inception image recognition neural network
   to recognize those categories. to get started, the first thing you need
   to do is get some example images. to begin, go to the terminal and
   enter the    exit    command if you still see the    root@       prompt that
   indicates you   re still in the linux virtual machine.

   then run the following commands to create a new folder in your
   downloads directory to hold training images, and download and extract
   the flower photos:
cd $home
mkdir tf_files
cd tf_files
curl -o http://download.tensorflow.org/example_images/flower_photos.tgz
tar xzf flower_photos.tgz
open flower_photos

   this should end up with a new finder window opening, showing a set of
   five folders:
   flower image

   this means you   ve successfully downloaded the example flower images. if
   you look at how they   re organized, you should be able to use the same
   structure with classes you care about, just replacing the folder names
   with the category labels you   re dealing with, and populating them with
   photos of those objects. [45]there   s more guidance on that process in
   the tutorial.

running the vm with shared folders

   now that you   ve got some images to train with, we   re going to start up
   the virtual machine again, this time sharing the folder you just
   created with linux so tensorflow can access the photos:
docker run -it -v $home/tf_files:/tf_files b.gcr.io/tensorflow/tensorflow:0.7.1-
devel

   you should find yourself back in a linux prompt. to make sure the file
   sharing worked, try the following command:
ls /tf_files/flower_photos

   you should see a list of the flower folders, like this:
root@2c570d651d08:~# ls /tf_files/flower_photos
license.txt daisy dandelion roses sunflowers tulips
root@2c570d651d08:~#

updating the code

   for this example, we need the very latest code since it   s just been
   added. unfortunately, getting it is a little involved, with some use of
   the source control program [46]git. i   ll walk through the steps below.

   pulling the code requires a default email address, which you can set to
   anything, since we   re not planning on pushing any changes back.
git config --global user.email "you@example.com"
git config --global user.name "your name"

   now you should be able to pull the latest source.
cd /tensorflow/
git pull origin master

   you   ll find yourself in a vim window. just type    :quit    to exit.

   you should now have fully up-to-date code. we want to sync it to a
   version we know works, though, so we   ll run this command:
git checkout 6d46c0b370836698a3195a6d73398f15fa44bcb2

building the code

   if that worked, the next step is to compile the code. you may notice
   there   s some optimization flags in the command that help speed it up on
   processors with avx, which almost all modern os x machines have.
cd /tensorflow/
bazel build -c opt --copt=-mavx tensorflow/examples/image_retraining:retrain

   this part can take five to 10 minutes, depending on the speed of your
   machine, as it   s compiling the full source code for tensorflow. don   t
   worry if you see a lot of warnings; this is normal (though we   re
   working on reducing them going forward).

running the code

   i can now run the retraining process using this command:
bazel-bin/tensorflow/examples/image_retraining/retrain \
--bottleneck_dir=/tf_files/bottlenecks \
--model_dir=/tf_files/inception \
--output_graph=/tf_files/retrained_graph.pb \
--output_labels=/tf_files/retrained_labels.txt \
--image_dir /tf_files/flower_photos

   you   ll see a message about downloading the inception model, and then a
   long series of messages about creating bottlenecks. there   s around
   3,700 photos in total to process, and my machine does around 200 a
   minute, so it takes around 20 minutes in total. if you want to know
   more about what   s happening under the hood while you wait, [47]you can
   check out the tutorial for a detailed explanation.

   i   ve changed the default /tmp destination for things like the output
   graph and cached bottlenecks to the shared /tf_files folder so that the
   results will be accessible from os x and will be retained between
   different runs of the virtual machine.

   once the bottlenecks are cached, it will then go into the training
   process, which takes another five minutes or so on my laptop. at the
   end, you should see the last output line giving the final estimated
   accuracy, which should be around 90%. that means you   ve trained your
   classifier to guess the right flower species nine times out of 10 when
   shown a photo!

using the classifier

   the training process outputs the retrained graph into
   /tmp/output_graph.pb, and to test it out yourself you can build another
   piece of sample code. the [48]label_image example is a small c++
   program that loads in a graph and applies it to a user-supplied image.
   give it a try like this:
bazel build tensorflow/examples/label_image:label_image && \
bazel-bin/tensorflow/examples/label_image/label_image \
--graph=/tf_files/retrained_graph.pb \
--labels=/tf_files/retrained_labels.txt \
--output_layer=final_result \
--image=/tf_files/flower_photos/daisy/21652746_cc379e0eea_m.jpg

   you should see a result showing that it identified a daisy in that
   picture; though, because the training process is random, you may
   occasionally have a model that makes a mistake on the image. try it
   with some of the other photos to get a feel for how it   s doing.

next steps

   the first thing you   ll probably want to do is train a classifier for
   objects you care about in your application. this should be as simple as
   creating a new folder in your downloads/tf_images directory, putting
   subfolders full of photos in it, and re-running the classifier
   commands. you can find more detailed advice on tuning that process
   [49]in the tutorial.

   finally, you   ll want to use this in your own application! the
   [50]label_image example is a good template to look at if you can
   integrate c++ into your product, and we even support running on mobile,
   so check out t[51]he android sample code if you   d like to run on a
   smart phone.

   thanks for working through this process with me. i hope it   s inspired
   you to think about how you can use deep learning to help your users,
   and i can   t wait to see what you build!
   article image: photographic mosaic. (source: [52]by j2thawiki on
   wikimedia commons).

   share
    1. [53]tweet
    2.
    3.
     __________________________________________________________________

   [54]pete warden

[55]pete warden

   pete warden is the tech lead of the tensorflow mobile team, and was
   formerly the cto of jetpac, which was acquired by google in 2014 for
   its deep learning technology optimized to run on mobile and embedded
   devices. he's previously worked at apple on gpu optimizations for image
   processing, and has written several books on data processing for
   o'reilly.
   [56]more
     __________________________________________________________________

   [57]bots landscape.

   [58]ai

[59]infographic: the bot platform ecosystem

   by [60]jon bruner

   a look at the artificial intelligence and messaging platforms behind
   the fast-growing chatbot community

   video
   [61]vertical forest, milan.

   [62]ai

[63]evolve ai

   by [64]naveen rao

   naveen rao explains how intel nervana is evolving the ai stack from
   silicon to the cloud.

   [65]welcome sign at o'reilly ai conference 2016

   [66]ai

[67]highlights from the o'reilly ai conference in new york 2016

   by [68]mac slocum

   watch highlights covering artificial intelligence, machine learning,
   intelligence engineering, and more. from the o'reilly ai conference in
   new york 2016.

   video
   [69]close up of uber's self driving car in pittsburgh.

   [70]ai

[71]how ai is propelling driverless cars, the future of surface transport

   by [72]shahin farshchi

   shahin farshchi examines role artificial intelligence will play in
   driverless cars.

about us

     * [73]our company
     * [74]teach/speak/write
     * [75]careers
     * [76]customer service
     * [77]contact us

site map

     * [78]ideas
     * [79]learning
     * [80]topics
     * [81]all

     *
     *
     *
     *
     *

      2019 o'reilly media, inc. all trademarks and registered trademarks
   appearing on oreilly.com are the property of their respective owners.
   [82]terms of service     [83]privacy policy     [84]editorial independence

   animal

   iframe: [85]https://www.googletagmanager.com/ns.html?id=gtm-5p4v6z

references

   visible links
   1. https://www.oreilly.com/ideas
   2. https://learning.oreilly.com/
   3. http://www.oreilly.com/conferences/
   4. http://shop.oreilly.com/
   5. https://www.oreilly.com/sign-in.html
   6. https://www.oreilly.com/topics/ai
   7. https://www.oreilly.com/topics/data
   8. https://www.oreilly.com/topics/economy
   9. https://www.oreilly.com/topics/operations
  10. https://www.oreilly.com/topics/software-architecture
  11. https://www.oreilly.com/topics/software-engineering
  12. https://www.oreilly.com/topics/web-programming
  13. https://www.oreilly.com/topics
  14. https://www.oreilly.com/ideas
  15. https://learning.oreilly.com/
  16. http://www.oreilly.com/conferences/
  17. http://shop.oreilly.com/
  18. https://www.oreilly.com/topics/ai
  19. https://www.oreilly.com/topics/data
  20. https://www.oreilly.com/topics/economy
  21. https://www.oreilly.com/topics/operations
  22. https://www.oreilly.com/topics/software-architecture
  23. https://www.oreilly.com/topics/software-engineering
  24. https://www.oreilly.com/topics/web-programming
  25. https://www.oreilly.com/topics
  26. https://www.oreilly.com/topics/ai
  27. https://www.oreilly.com/people/9cbf6-pete-warden
  28. https://commons.wikimedia.org/wiki/file:mosaicr_seagull.jpg
  29. https://www.safaribooksonline.com/oriole/hello-tensorflow-oriole?utm_source=oreilly&utm_medium=newsite&utm_campaign=tensorflow-for-poets-post-top-note-cta
  30. http://petewarden.com/2016/02/28/tensorflow-for-poets/
  31. http://ec2.forpoets.org/
  32. http://www.tensorflow.org/
  33. http://www.tensorflow.org/
  34. http://www.tensorflow.org/
  35. https://www.youtube.com/watch?v=h7xueizjqqo
  36. https://www.youtube.com/embed/h7xueizjqqo
  37. https://docs.docker.com/mac/
  38. https://docs.docker.com/mac/
  39. https://docs.docker.com/mac/step_one/
  40. https://www.docker.com/products/docker-toolbox
  41. https://docs.docker.com/mac/step_one/
  42. https://www.tensorflow.org/versions/r0.7/get_started/os_setup.html#docker-installation
  43. https://www.virtualbox.org/wiki/downloads
  44. https://www.tensorflow.org/versions/master/how_tos/image_retraining/index.html
  45. https://www.tensorflow.org/versions/master/how_tos/image_retraining/index.html#training-on-your-own-categories
  46. https://git-man-page-generator.lokaltog.net/
  47. https://www.tensorflow.org/versions/master/how_tos/image_retraining/index.html#bottlenecks
  48. https://github.com/tensorflow/tensorflow/tree/master/tensorflow/examples/label_image
  49. https://www.tensorflow.org/versions/master/how_tos/image_retraining/index.html#training-on-your-own-categories
  50. https://github.com/tensorflow/tensorflow/tree/master/tensorflow/examples/label_image
  51. https://github.com/tensorflow/tensorflow/tree/master/tensorflow/examples/android
  52. https://commons.wikimedia.org/wiki/file:mosaicr_seagull.jpg
  53. https://twitter.com/share
  54. https://www.oreilly.com/people/9cbf6-pete-warden
  55. https://www.oreilly.com/people/9cbf6-pete-warden
  56. https://www.oreilly.com/people/9cbf6-pete-warden
  57. https://www.oreilly.com/ideas/infographic-the-bot-platform-ecosystem
  58. https://www.oreilly.com/topics/ai
  59. https://www.oreilly.com/ideas/infographic-the-bot-platform-ecosystem
  60. https://www.oreilly.com/people/b1d73-jon-bruner
  61. https://www.oreilly.com/ideas/evolve-ai
  62. https://www.oreilly.com/topics/ai
  63. https://www.oreilly.com/ideas/evolve-ai
  64. https://www.oreilly.com/people/14d38-naveen-rao
  65. https://www.oreilly.com/ideas/keynotes-from-ai-new-york-2016
  66. https://www.oreilly.com/topics/ai
  67. https://www.oreilly.com/ideas/keynotes-from-ai-new-york-2016
  68. https://www.oreilly.com/people/0d2c1-mac-slocum
  69. https://www.oreilly.com/ideas/how-ai-is-propelling-driverless-cars-the-future-of-surface-transport
  70. https://www.oreilly.com/topics/ai
  71. https://www.oreilly.com/ideas/how-ai-is-propelling-driverless-cars-the-future-of-surface-transport
  72. https://www.oreilly.com/people/c7521-shahin-farshchi
  73. http://oreilly.com/about/
  74. http://oreilly.com/work-with-us.html
  75. http://oreilly.com/careers/
  76. http://shop.oreilly.com/category/customer-service.do
  77. http://shop.oreilly.com/category/customer-service.do
  78. https://www.oreilly.com/ideas
  79. https://www.oreilly.com/topics/oreilly-learning
  80. https://www.oreilly.com/topics
  81. https://www.oreilly.com/all
  82. http://oreilly.com/terms/
  83. http://oreilly.com/privacy.html
  84. http://www.oreilly.com/about/editorial_independence.html
  85. https://www.googletagmanager.com/ns.html?id=gtm-5p4v6z

   hidden links:
  87. https://www.oreilly.com/
  88. https://www.facebook.com/oreilly/
  89. https://twitter.com/oreillymedia
  90. https://www.youtube.com/user/oreillymedia
  91. https://plus.google.com/+oreillymedia
  92. https://www.linkedin.com/company/oreilly-media
  93. https://www.oreilly.com/
