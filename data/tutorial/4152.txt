   #[1]publisher [2]medium [3]alternate

   [4]homepage
   [5]homepage
   [6]sign in[7]get started

   [8]towards data science
     * [9]data science
     * [10]machine learning
     * [11]programming
     * [12]visualization
     * [13]ai
     * [14]data journalism
     * [15]contribute
     __________________________________________________________________

data science simplified part 2: key concepts of statistical learning

   [16]go to the profile of pradeep menon
   [17]pradeep menon (button) blockedunblock (button) followfollowing
   jul 15, 2017

   in the [18]first article of this series, i had touched upon key
   concepts and processes of data science. in this article, i will dive in
   a bit deeper. first, i will define what is statistical learning. then,
   we will dive into key concepts in statistical learning. believe me; it
   is simple.

what is statistical learning?

   [1*kicn85ndnygt3e0kyokyfw.png]

   as per [19]wikipedia, statistical learning theory is a framework for
   machine learning drawing from the fields of statistics and functional
   analysis.

   machine learning is a manifestation of statistical learning techniques
   implemented through software applications.

   what does this mean in practice? statistical learning refers to tools
   and techniques that enable us to understand data better. let   s take a
   step back here. what do we mean by understanding the data?

   in the context of statistical learning, there are two types of data:
    1. data that can be controlled directly a.k.a independent variables.
    2. data that cannot be controlled directly a.k.a dependent variables.

   the data that can   t be controlled i.e. dependent variables need to
   predicted or estimated.

   understanding the data better is to figure out more about the dependent
   variable in terms of independent variables. let me illustrate it with
   an example:

   say that i want to measure sales based on the advertising budget i
   allocate for tv, radio, and print. i can control the budget that i can
   assign to tv, radio, and print. what i can   t control is how they will
   impact the sales. i want to express data that i can   t control (sales)
   as a function of data that i can control (advertising budget). i want
   to uncover this hidden relationship.

   statistical learning reveals hidden data relationships. relationships
   between the dependent and the independent data.

parameters and models

   [1*astuxbf9wwobptvb0wtjoq.png]

   one of the famous business models in operations management is the ito
   model. it stands for input-transformation-output model. it is simple.
   there are inputs. these inputs undergo some transformations. an output
   is created.

   statistical learning also applies a similar concept. there are input
   data. input data is transformed. the output, something that needs to be
   predicted or estimated, is generated.

   the transformation engine is called as a model. these are functions
   that estimate the output.

   the transformation is mathematical. mathematical ingredients are added
   to the input data to estimate the output. these ingredients are called
   as the parameters.

   let   s walk through an example:

   what determines someone   s income? say that income is a determined by
   one   s year   s education and years of experience. a model that estimate   s
   the income can be something like this:

   income = c +   0 x education +   1 x experience

     0 and   1 are parameters that express income as a function of education
   and experience.

   education and experience are controllable variables. these controllable
   variables have different synonyms. they are called as independent
   variables. they are also called as features.

   income is uncontrollable variable. they are called as targets.

training and testing

   [1*srckl-bc3kqeown5jotcqa.png]

   what do we do when we have to prepare for an examination? study. learn.
   imbibe. take notes. practice mock papers. these are the tools to learn
   and to prepare for the unseen test.

   machine learning also uses a similar concept for learning. data is
   finite. the available data needs to be used prudently. the model built
   needs to be validated. the way to validate it is the following:
     * split the data into two parts.
     * use one part for training. let the model learn from it. let the
       model see the data. this dataset is called as the training data.
     * use the other part for testing the model. give the model    a test   
       on the unseen data. this dataset is called as the testing data.

   in a competitive examination, if the preparation is adequate, if the
   learning is sound then the performance on the test is expected to be
   satisfactory as well. similarly, in a machine learning, if the model
   has learned well from the training data, it will perform well on the
   test data.

   similarly, in machine learning, once the model is tested on the test
   dataset, the performance of the model is evaluated. it is assessed
   based on how close it has estimated the output to the actual value.

variance and bias

   [1*79pjv-fgbsdpkek00rk2va.png]

   george box, a famous british statistician, once quoted:

        all models are wrong; some are useful.   

   no model is 100% accurate. all models have errors. these errors emanate
   from two sources:
     * bias
     * variance

   let me attempt to explain this using an analogy.

   raj, a seven-year-old kid, was just introduced to the concept of
   multiplication. he had mastered the tables of 1 and 2. his next
   challenge was to learn the table of 3. he was very excited and started
   to practice the multiplication table of 3. his table is something like
   this:
     * 3 x 1 = 4
     * 3 x 2 = 7
     * 3 x 3 = 10
     * 3 x 4 = 13
     * 3 x 5 = 16

   bob, raj   s classmate, was on the same boat. his table looked something
   like this:
     * 3 x 1 = 5
     * 3 x 2 = 9
     * 3 x 3 = 18
     * 3 x 4 = 24
     * 3 x 5 = 30

   let us examine the multiplication models created by bob and raj from a
   machine learning perspective.
     * raj   s model has an invalid assumption. it assumes that the
       operation of multiplication implies to add one after the result.
       this assumption introduces the bias error. the assumption is
       consistent i.e. add 1 to the output. this means that raj   s model
       has a low bias.
     * raj   s model results in output that is consistently 1 number away
       from the actual. this means that his model has a low variance.
     * bob   s model   s output is all over the place. his model outputs
       deviates a lot from the actual value. there is no consistent
       pattern for deviation. bob   s model has high bias and high
       variation.

   the above example is a crude explanation of the important concept of
   variance and bias.
     * bias is the model   s tendency to consistently learn the wrong thing
       by not taking into account all the information in the data.
     * variance is the model   s tendency to acquire random things
       irrespective of the real signal.

bias-variance trade-off

   [1*yefjblttko5hstdwuqjixq.png]

   i have a school friend who was an amazing student. he was relatively
   weaker in mathematics. the way he used to study mathematics was through
   rote learning. he learned and memorized the mathematical problems. he
   could    recite    them very well.

   the challenge was the following: the examination problems were not the
   same problem that he memorized. the problems were a generalized
   application of the mathematical concept. obviously, he had a tough time
   clearing the exams.

   machine learning problems follow the same pattern. if the model learns
   too much about a particular data set and tries to apply the same model
   to the unseen data, it will have a high error. learning too much from a
   given dataset is called as overfitting. it has not generalized the
   learning to be usefully applied to unseen data. on the other end of the
   spectrum, learning too little results in underfitting. the model is so
   poor that it can   t even learn from the given data.

   albert einstein summarizes this concept succinctly. he said:

        everything should be made as simple as possible, but no simpler.   

   a constant endeavor in machine learning problem is to strike a right
   balance. create a model that is not too complex and not too simple.
   create a generalized model. create a model that is relatively
   inaccurate but useful.
     * a model that overfits is complex. it performs very well on training
       data. it performs poorly on testing data.
     * a model that underfits is too simplistic. it doesn   t perform will
       on both training and testing data.
     * a good model balances underfitting and overfitting. it generalizes
       well. it is as simple as possible but no simpler.

   this balancing act is called bias-variance trade-off.

conclusion

   statistical learning is the building block of complex machine learning
   applications. this article introduces some of the fundamental and
   essential concepts of statistical learning. top 5 takeaways from this
   article are:
    1. statistical learning reveals hidden data relationships.
       relationships between the dependent and the independent data.
    2. model is the transformation engine. parameters are the ingredients
       that enable the transformation.
    3. a model uses the training data to learn. a model uses the testing
       data to evaluate.
    4. all models are wrong; some are useful.
    5. bias-variance trade-off is a balancing act. balance to find optimal
       model. balance to find the sweet spot.

   we will delve deeper into specifics of machine learning models in
   subsequent articles of this series.

     * [20]machine learning
     * [21]data science

   (button)
   (button)
   (button) 451 claps
   (button) (button) (button) 7 (button) (button)

     (button) blockedunblock (button) followfollowing
   [22]go to the profile of pradeep menon

[23]pradeep menon

   director of #bigdata and #ai solution architecture @ alibaba cloud.
   impact driven. executive-level interpersonal skills. hands-on.
   #worldtraveller. #blogger

     (button) follow
   [24]towards data science

[25]towards data science

   sharing concepts, ideas, and codes.

     * (button)
       (button) 451
     * (button)
     *
     *

   [26]towards data science
   never miss a story from towards data science, when you sign up for
   medium. [27]learn more
   never miss a story from towards data science
   (button) get updatesget updates

references

   visible links
   1. https://plus.google.com/103654360130207659246
   2. https://towardsdatascience.com/osd.xml
   3. android-app://com.medium.reader/https/medium.com/p/45648049709e
   4. https://medium.com/
   5. https://medium.com/
   6. https://medium.com/m/signin?redirect=https://towardsdatascience.com/data-science-simplified-key-concepts-of-statistical-learning-45648049709e&source=--------------------------nav_reg&operation=login
   7. https://medium.com/m/signin?redirect=https://towardsdatascience.com/data-science-simplified-key-concepts-of-statistical-learning-45648049709e&source=--------------------------nav_reg&operation=register
   8. https://towardsdatascience.com/?source=logo-lo_w6sjzto7r7ci---7f60cf5620c9
   9. https://towardsdatascience.com/data-science/home
  10. https://towardsdatascience.com/machine-learning/home
  11. https://towardsdatascience.com/programming/home
  12. https://towardsdatascience.com/data-visualization/home
  13. https://towardsdatascience.com/artificial-intelligence/home
  14. https://towardsdatascience.com/data-journalism/home
  15. https://towardsdatascience.com/contribute/home
  16. https://towardsdatascience.com/@rpradeepmenon?source=post_header_lockup
  17. https://towardsdatascience.com/@rpradeepmenon
  18. https://medium.com/@prmen/data-science-simplified-principles-and-process-b06304d63308
  19. https://en.wikipedia.org/wiki/statistical_learning_theory
  20. https://towardsdatascience.com/tagged/machine-learning?source=post
  21. https://towardsdatascience.com/tagged/data-science?source=post
  22. https://towardsdatascience.com/@rpradeepmenon?source=footer_card
  23. https://towardsdatascience.com/@rpradeepmenon
  24. https://towardsdatascience.com/?source=footer_card
  25. https://towardsdatascience.com/?source=footer_card
  26. https://towardsdatascience.com/
  27. https://medium.com/@medium/personalize-your-medium-experience-with-users-publications-tags-26a41ab1ee0c#.hx4zuv3mg

   hidden links:
  29. https://medium.com/p/45648049709e/share/twitter
  30. https://medium.com/p/45648049709e/share/facebook
  31. https://medium.com/p/45648049709e/share/twitter
  32. https://medium.com/p/45648049709e/share/facebook
