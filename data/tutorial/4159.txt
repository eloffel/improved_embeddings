   #[1]tensorflow

   (button)
   [2]tensorflow
     *

   [3]install [4]learn
     * [5]introduction
       new to tensorflow?
     * [6]tensorflow
       the core open source ml library
     * [7]for javascript
       tensorflow.js for ml using javascript
     * [8]for mobile & iot
       tensorflow lite for mobile and embedded devices
     * [9]for production
       tensorflow extended for end-to-end ml components
     * [10]swift for tensorflow (in beta)

   [11]api
     * api r1
     * [12]r1.13 (stable)
     * [13]r1.12
     * [14]r1.11
     * [15]r1.10
     * [16]r1.9
     * [17]more   

     * api r2
     * [18]r2.0 (preview)

   [19]resources
     * [20]models & datasets
       pre-trained models and datasets built by google and the community
     * [21]tools
       ecosystem of tools to help you use tensorflow
     * [22]libraries & extensions
       libraries and extensions built on tensorflow

   [23]community [24]why tensorflow
     * [25]about
     * [26]case studies

   ____________________
   (button)
   (button)
   [27]github
     * [28]tensorflow core

   [29]overview [30]tutorials [31]guide [32]tf 2.0 alpha

   (button)
     * [33]install
     * [34]learn
          + more
          + [35]overview
          + [36]tutorials
          + [37]guide
          + [38]tf 2.0 alpha
     * [39]api
          + more
     * [40]resources
          + more
     * [41]community
     * [42]why tensorflow
          + more
     * [43]github

     * [44]get started with tensorflow
     * learn and use ml
          + [45]overview
          + [46]basic classification
          + [47]text classification
          + [48]regression
          + [49]overfitting and underfitting
          + [50]save and restore models
     * research and experimentation
          + [51]overview
          + [52]eager execution
          + [53]automatic differentiation
          + [54]custom training: basics
          + [55]custom layers
          + [56]custom training: walkthrough
     * ml at production scale
          + [57]linear model with estimators
          + [58]wide and deep learning
          + [59]boosted trees
          + [60]boosted trees model understanding
          + [61]build a id98 using estimators
     * generative models
          + [62]translation with attention
          + [63]image captioning
          + [64]dcgan
          + [65]vae
     * images
          + [66]image recognition
          + [67]pix2pix
          + [68]neural style transfer
          + [69]image segmentation
          + [70]advanced id98
     * sequences
          + [71]text generation with an id56
          + [72]recurrent neural network
          + [73]drawing classification
          + [74]simple audio recognition
          + [75]id4
     * load data
          + [76]load images
          + [77]tfrecords and tf.example
     * data representation
          + [78]vector representations of words
          + [79]kernel methods
          + [80]large-scale linear models
          + [81]unicode
     * non-ml
          + [82]mandelbrot set
          + [83]partial differential equations

     * [84]introduction
     * [85]tensorflow
     * [86]for javascript
     * [87]for mobile & iot
     * [88]for production
     * [89]swift for tensorflow (in beta)

     * api r1
     * [90]r1.13 (stable)
     * [91]r1.12
     * [92]r1.11
     * [93]r1.10
     * [94]r1.9
     * [95]more   
     * api r2
     * [96]r2.0 (preview)

     * [97]models & datasets
     * [98]tools
     * [99]libraries & extensions

     * [100]about
     * [101]case studies

   watch talks from the 2019 tensorflow dev summit [102]watch now
     * [103]tensorflow
     * [104]learn
     * [105]tensorflow core
     * [106]tutorials

build a convolutional neural network using estimators

   [107][tf_logo_32px.png] view on tensorflow.org
   [108][colab_logo_32px.png] run in google colab
   [109][github-mark-32px.png] view source on github

   the [110]tf.layers module provides a high-level api that makes it easy
   to construct a neural network. it provides methods that facilitate the
   creation of dense (fully connected) layers and convolutional layers,
   adding id180, and applying dropout id173. in
   this tutorial, you'll learn how to use layers to build a convolutional
   neural network model to recognize the handwritten digits in the mnist
   data set.

   handwritten digits 0   9 from the mnist data set

   the [111]mnist dataset comprises 60,000 training examples and 10,000
   test examples of the handwritten digits 0   9, formatted as 28x28-pixel
   monochrome images.

get started

   let's set up the imports for our tensorflow program:
from __future__ import absolute_import, division, print_function

import tensorflow as tf
import numpy as np

tf.logging.set_verbosity(tf.logging.info)

   as you work through the tutorial, you'll add code to construct, train,
   and evaluate the convolutional neural network. the complete, final code
   can be [112]found here.

intro to convolutional neural networks

   convolutional neural networks (id98s) are the current state-of-the-art
   model architecture for image classification tasks. id98s apply a series
   of filters to the raw pixel data of an image to extract and learn
   higher-level features, which the model can then use for classification.
   id98s contains three components:
     * convolutional layers, which apply a specified number of convolution
       filters to the image. for each subregion, the layer performs a set
       of mathematical operations to produce a single value in the output
       feature map. convolutional layers then typically apply a [113]relu
       activation function to the output to introduce nonlinearities into
       the model.
     * pooling layers, which [114]downsample the image data extracted by
       the convolutional layers to reduce the dimensionality of the
       feature map in order to decrease processing time. a commonly used
       pooling algorithm is max pooling, which extracts subregions of the
       feature map (e.g., 2x2-pixel tiles), keeps their maximum value, and
       discards all other values.
     * dense (fully connected) layers, which perform classification on the
       features extracted by the convolutional layers and downsampled by
       the pooling layers. in a dense layer, every node in the layer is
       connected to every node in the preceding layer.

   typically, a id98 is composed of a stack of convolutional modules that
   perform feature extraction. each module consists of a convolutional
   layer followed by a pooling layer. the last convolutional module is
   followed by one or more dense layers that perform classification. the
   final dense layer in a id98 contains a single node for each target class
   in the model (all the possible classes the model may predict), with a
   [115]softmax activation function to generate a value between 0   1 for
   each node (the sum of all these softmax values is equal to 1). we can
   interpret the softmax values for a given image as relative measurements
   of how likely it is that the image falls into each target class.

   note: for a more comprehensive walkthrough of id98 architecture, see
   stanford university's [116]convolutional neural networks for visual
   recognition course material.

building the id98 mnist classifier

   let's build a model to classify the images in the mnist dataset using
   the following id98 architecture:
    1. convolutional layer #1: applies 32 5x5 filters (extracting
       5x5-pixel subregions), with relu activation function
    2. pooling layer #1: performs max pooling with a 2x2 filter and stride
       of 2 (which specifies that pooled regions do not overlap)
    3. convolutional layer #2: applies 64 5x5 filters, with relu
       activation function
    4. pooling layer #2: again, performs max pooling with a 2x2 filter and
       stride of 2
    5. dense layer #1: 1,024 neurons, with dropout id173 rate of
       0.4 (id203 of 0.4 that any given element will be dropped
       during training)
    6. dense layer #2 (logits layer): 10 neurons, one for each digit
       target class (0   9).

   the [117]tf.layers module contains methods to create each of the three
   layer types above:
     * conv2d(). constructs a two-dimensional convolutional layer. takes
       number of filters, filter kernel size, padding, and activation
       function as arguments.
     * max_pooling2d(). constructs a two-dimensional pooling layer using
       the max-pooling algorithm. takes pooling filter size and stride as
       arguments.
     * dense(). constructs a dense layer. takes number of neurons and
       activation function as arguments.

   each of these methods accepts a tensor as input and returns a
   transformed tensor as output. this makes it easy to connect one layer
   to another: just take the output from one layer-creation method and
   supply it as input to another.

   add the following id98_model_fn function, which conforms to the
   interface expected by tensorflow's estimator api (more on this later in
   [118]create the estimator). this function takes mnist feature data,
   labels, and mode (from [119]tf.estimator.modekeys: train, eval,
   predict) as arguments; configures the id98; and returns predictions,
   loss, and a training operation:
def id98_model_fn(features, labels, mode):
  """model function for id98."""
  # input layer
  input_layer = tf.reshape(features["x"], [-1, 28, 28, 1])

  # convolutional layer #1
  conv1 = tf.layers.conv2d(
      inputs=input_layer,
      filters=32,
      kernel_size=[5, 5],
      padding="same",
      activation=tf.nn.relu)

  # pooling layer #1
  pool1 = tf.layers.max_pooling2d(inputs=conv1, pool_size=[2, 2], strides=2)

  # convolutional layer #2 and pooling layer #2
  conv2 = tf.layers.conv2d(
      inputs=pool1,
      filters=64,
      kernel_size=[5, 5],
      padding="same",
      activation=tf.nn.relu)
  pool2 = tf.layers.max_pooling2d(inputs=conv2, pool_size=[2, 2], strides=2)

  # dense layer
  pool2_flat = tf.reshape(pool2, [-1, 7 * 7 * 64])
  dense = tf.layers.dense(inputs=pool2_flat, units=1024, activation=tf.nn.relu)
  dropout = tf.layers.dropout(
      inputs=dense, rate=0.4, training=mode == tf.estimator.modekeys.train)

  # logits layer
  logits = tf.layers.dense(inputs=dropout, units=10)

  predictions = {
      # generate predictions (for predict and eval mode)
      "classes": tf.argmax(input=logits, axis=1),
      # add `softmax_tensor` to the graph. it is used for predict and by the
      # `logging_hook`.
      "probabilities": tf.nn.softmax(logits, name="softmax_tensor")
  }

  if mode == tf.estimator.modekeys.predict:
    return tf.estimator.estimatorspec(mode=mode, predictions=predictions)

  # calculate loss (for both train and eval modes)
  loss = tf.losses.sparse_softmax_cross_id178(labels=labels, logits=logits)

  # configure the training op (for train mode)
  if mode == tf.estimator.modekeys.train:
    optimizer = tf.train.gradientdescentoptimizer(learning_rate=0.001)
    train_op = optimizer.minimize(
        loss=loss,
        global_step=tf.train.get_global_step())
    return tf.estimator.estimatorspec(mode=mode, loss=loss, train_op=train_op)

  # add id74 (for eval mode)
  eval_metric_ops = {
      "accuracy": tf.metrics.accuracy(
          labels=labels, predictions=predictions["classes"])
  }
  return tf.estimator.estimatorspec(
      mode=mode, loss=loss, eval_metric_ops=eval_metric_ops)

   the following sections (with headings corresponding to each code block
   above) dive deeper into the [120]tf.layers code used to create each
   layer, as well as how to calculate loss, configure the training op, and
   generate predictions. if you're already experienced with id98s and
   [121]tensorflow estimators, and find the above code intuitive, you may
   want to skim these sections or just skip ahead to [122]"training and
   evaluating the id98 mnist classifier".

input layer

   the methods in the layers module for creating convolutional and pooling
   layers for two-dimensional image data expect input tensors to have a
   shape of [batch_size, image_height, image_width, channels] by default.
   this behavior can be changed using the data_format parameter; defined
   as follows:
     * batch_size    size of the subset of examples to use when performing
       id119 during training.
     * image_height    height of the example images.
     * image_width    width of the example images.
     * channels    number of color channels in the example images. for color
       images, the number of channels is 3 (red, green, blue). for
       monochrome images, there is just 1 channel (black).
     * data_format    a string, one of channels_last (default) or
       channels_first. channels_last corresponds to inputs with shape
       (batch, ..., channels) while channels_first corresponds to inputs
       with shape (batch, channels, ...).

   here, our mnist dataset is composed of monochrome 28x28 pixel images,
   so the desired shape for our input layer is [batch_size, 28, 28, 1].

   to convert our input feature map (features) to this shape, we can
   perform the following reshape operation:
input_layer = tf.reshape(features["x"], [-1, 28, 28, 1])

   note that we've indicated -1 for batch size, which specifies that this
   dimension should be dynamically computed based on the number of input
   values in features["x"], holding the size of all other dimensions
   constant. this allows us to treat batch_size as a hyperparameter that
   we can tune. for example, if we feed examples into our model in batches
   of 5, features["x"] will contain 3,920 values (one value for each pixel
   in each image), and input_layer will have a shape of [5, 28, 28, 1].
   similarly, if we feed examples in batches of 100, features["x"] will
   contain 78,400 values, and input_layer will have a shape of [100, 28,
   28, 1].

convolutional layer #1

   in our first convolutional layer, we want to apply 32 5x5 filters to
   the input layer, with a relu activation function. we can use the
   conv2d() method in the layers module to create this layer as follows:
conv1 = tf.layers.conv2d(
    inputs=input_layer,
    filters=32,
    kernel_size=[5, 5],
    padding="same",
    activation=tf.nn.relu)

   the inputs argument specifies our input tensor, which must have the
   shape [batch_size, image_height, image_width, channels]. here, we're
   connecting our first convolutional layer to input_layer, which has the
   shape [batch_size, 28, 28, 1].

   note: conv2d() will instead accept a shape of [<em>batch_size</em>,
   <em>channels</em>, <em>image_height</em>, <em>image_width</em>] when
   passed the argument data_format=channels_first.

   the filters argument specifies the number of filters to apply (here,
   32), and kernel_size specifies the dimensions of the filters as
   [<em>height</em>, <em>width</em>]</code> (here, <code>[5, 5]).

   tip: if filter height and width have the same value, you can instead
   specify a single integer for kernel_size   e.g., kernel_size=5.

   the padding argument specifies one of two enumerated values
   (case-insensitive): valid (default value) or same. to specify that the
   output tensor should have the same height and width values as the input
   tensor, we set padding=same here, which instructs tensorflow to add 0
   values to the edges of the input tensor to preserve height and width of
   28. (without padding, a 5x5 convolution over a 28x28 tensor will
   produce a 24x24 tensor, as there are 24x24 locations to extract a 5x5
   tile from a 28x28 grid.)

   the activation argument specifies the activation function to apply to
   the output of the convolution. here, we specify relu activation with
   [123]tf.nn.relu.

   our output tensor produced by conv2d() has a shape of [batch_size, 28,
   28, 32]: the same height and width dimensions as the input, but now
   with 32 channels holding the output from each of the filters.

pooling layer #1

   next, we connect our first pooling layer to the convolutional layer we
   just created. we can use the max_pooling2d() method in layers to
   construct a layer that performs max pooling with a 2x2 filter and
   stride of 2:
pool1 = tf.layers.max_pooling2d(inputs=conv1, pool_size=[2, 2], strides=2)

   again, inputs specifies the input tensor, with a shape of [batch_size,
   image_height, image_width, channels]. here, our input tensor is conv1,
   the output from the first convolutional layer, which has a shape of
   [batch_size, 28, 28, 32].

   note: as with conv2d(), max_pooling2d() will instead accept a shape of
   [batch_size, channels, image_height, image_width] when passed the
   argument data_format=channels_first.

   the pool_size argument specifies the size of the max pooling filter as
   [height, width] (here, [2, 2]). if both dimensions have the same value,
   you can instead specify a single integer (e.g., pool_size=2).

   the strides argument specifies the size of the stride. here, we set a
   stride of 2, which indicates that the subregions extracted by the
   filter should be separated by 2 pixels in both the height and width
   dimensions (for a 2x2 filter, this means that none of the regions
   extracted will overlap). if you want to set different stride values for
   height and width, you can instead specify a tuple or list (e.g.,
   stride=[3, 6]).

   our output tensor produced by max_pooling2d() (pool1) has a shape of
   [batch_size, 14, 14, 32]: the 2x2 filter reduces height and width by
   50% each.

convolutional layer #2 and pooling layer #2

   we can connect a second convolutional and pooling layer to our id98
   using conv2d() and max_pooling2d() as before. for convolutional layer
   #2, we configure 64 5x5 filters with relu activation, and for pooling
   layer #2, we use the same specs as pooling layer #1 (a 2x2 max pooling
   filter with stride of 2):
conv2 = tf.layers.conv2d(
    inputs=pool1,
    filters=64,
    kernel_size=[5, 5],
    padding="same",
    activation=tf.nn.relu)

pool2 = tf.layers.max_pooling2d(inputs=conv2, pool_size=[2, 2], strides=2)

   note that convolutional layer #2 takes the output tensor of our first
   pooling layer (pool1) as input, and produces the tensor conv2 as
   output. conv2 has a shape of [batch_size, 14, 14, 64], the same height
   and width as pool1 (due to padding="same"), and 64 channels for the 64
   filters applied.

   pooling layer #2 takes conv2 as input, producing pool2 as output. pool2
   has shape [batch_size, 7, 7, 64] (50% reduction of height and width
   from conv2).

dense layer

   next, we want to add a dense layer (with 1,024 neurons and relu
   activation) to our id98 to perform classification on the features
   extracted by the convolution/pooling layers. before we connect the
   layer, however, we'll flatten our feature map (pool2) to shape
   [batch_size, features], so that our tensor has only two dimensions:
pool2_flat = tf.reshape(pool2, [-1, 7 * 7 * 64])

   in the reshape() operation above, the -1 signifies that the batch_size
   dimension will be dynamically calculated based on the number of
   examples in our input data. each example has 7 (pool2 height) * 7
   (pool2 width) * 64 (pool2 channels) features, so we want the features
   dimension to have a value of 7 * 7 * 64 (3136 in total). the output
   tensor, pool2_flat, has shape [batch_size, 3136].

   now, we can use the dense() method in layers to connect our dense layer
   as follows:
dense = tf.layers.dense(inputs=pool2_flat, units=1024, activation=tf.nn.relu)

   the inputs argument specifies the input tensor: our flattened feature
   map, pool2_flat. the units argument specifies the number of neurons in
   the dense layer (1,024). the activation argument takes the activation
   function; again, we'll use [124]tf.nn.relu to add relu activation.

   to help improve the results of our model, we also apply dropout
   id173 to our dense layer, using the dropout method in layers:
dropout = tf.layers.dropout(
    inputs=dense, rate=0.4, training=mode == tf.estimator.modekeys.train)

   again, inputs specifies the input tensor, which is the output tensor
   from our dense layer (dense).

   the rate argument specifies the dropout rate; here, we use 0.4, which
   means 40% of the elements will be randomly dropped out during training.

   the training argument takes a boolean specifying whether or not the
   model is currently being run in training mode; dropout will only be
   performed if training is true. here, we check if the mode passed to our
   model function id98_model_fn is train mode.

   our output tensor dropout has shape [batch_size, 1024].

logits layer

   the final layer in our neural network is the logits layer, which will
   return the raw values for our predictions. we create a dense layer with
   10 neurons (one for each target class 0   9), with linear activation (the
   default):
logits = tf.layers.dense(inputs=dropout, units=10)

   our final output tensor of the id98, logits, has shape [batch_size, 10].

generate predictions

   the logits layer of our model returns our predictions as raw values in
   a [batch_size, 10]-dimensional tensor. let's convert these raw values
   into two different formats that our model function can return:
     * the predicted class for each example: a digit from 0   9.
     * the probabilities for each possible target class for each example:
       the id203 that the example is a 0, is a 1, is a 2, etc.

   for a given example, our predicted class is the element in the
   corresponding row of the logits tensor with the highest raw value. we
   can find the index of this element using the [125]tf.argmax function:
tf.argmax(input=logits, axis=1)

   the input argument specifies the tensor from which to extract maximum
   values   here logits. the axis argument specifies the axis of the input
   tensor along which to find the greatest value. here, we want to find
   the largest value along the dimension with index of 1, which
   corresponds to our predictions (recall that our logits tensor has shape
   [batch_size, 10]).

   we can derive probabilities from our logits layer by applying softmax
   activation using [126]tf.nn.softmax:
tf.nn.softmax(logits, name="softmax_tensor")

   note: we use the name argument to explicitly name this operation
   softmax_tensor, so we can reference it later. (we'll set up logging for
   the softmax values in [127]"set up a logging hook").

   we compile our predictions in a dict, and return an estimatorspec
   object:
predictions = {
    "classes": tf.argmax(input=logits, axis=1),
    "probabilities": tf.nn.softmax(logits, name="softmax_tensor")
}
if mode == tf.estimator.modekeys.predict:
  return tf.estimator.estimatorspec(mode=mode, predictions=predictions)

calculate loss

   for both training and evaluation, we need to define a [128]loss
   function that measures how closely the model's predictions match the
   target classes. for multiclass classification problems like mnist,
   [129]cross id178 is typically used as the loss metric. the following
   code calculates cross id178 when the model runs in either train or
   eval mode:
loss = tf.losses.sparse_softmax_cross_id178(labels=labels, logits=logits)

   let's take a closer look at what's happening above.

   our labels tensor contains a list of prediction indices for our
   examples, e.g. [1, 9, ...]. logits contains the linear outputs of our
   last layer.

   [130]tf.losses.sparse_softmax_cross_id178, calculates the softmax
   crossid178 (aka: categorical crossid178, negative log-likelihood)
   from these two inputs in an efficient, numerically stable way.

configure the training op

   in the previous section, we defined loss for our id98 as the softmax
   cross-id178 of the logits layer and our labels. let's configure our
   model to optimize this loss value during training. we'll use a learning
   rate of 0.001 and [131]stochastic id119 as the optimization
   algorithm:
if mode == tf.estimator.modekeys.train:
  optimizer = tf.train.gradientdescentoptimizer(learning_rate=0.001)
  train_op = optimizer.minimize(
      loss=loss,
      global_step=tf.train.get_global_step())
  return tf.estimator.estimatorspec(mode=mode, loss=loss, train_op=train_op)

   note: for a more in-depth look at configuring training ops for
   estimator model functions, see [132]"defining the training op for the
   model" in the [133]"creating estimations in tf.estimator" tutorial.

add id74

   to add accuracy metric in our model, we define eval_metric_ops dict in
   eval mode as follows:
eval_metric_ops = {
    "accuracy": tf.metrics.accuracy(
        labels=labels, predictions=predictions["classes"])
}
return tf.estimator.estimatorspec(
    mode=mode, loss=loss, eval_metric_ops=eval_metric_ops)

training and evaluating the id98 mnist classifier

   we've coded our mnist id98 model function; now we're ready to train and
   evaluate it.

load training and test data

   first, let's load our training and test data with the following code:
# load training and eval data
((train_data, train_labels),
 (eval_data, eval_labels)) = tf.keras.datasets.mnist.load_data()

train_data = train_data/np.float32(255)
train_labels = train_labels.astype(np.int32)  # not required

eval_data = eval_data/np.float32(255)
eval_labels = eval_labels.astype(np.int32)  # not required

downloading data from https://storage.googleapis.com/tensorflow/tf-keras-dataset
s/mnist.npz
11493376/11490434 [==============================] - 0s 0us/step

   we store the training feature data (the raw pixel values for 55,000
   images of hand-drawn digits) and training labels (the corresponding
   value from 0   9 for each image) as [134]numpy arrays in train_data and
   train_labels, respectively. similarly, we store the evaluation feature
   data (10,000 images) and evaluation labels in eval_data and
   eval_labels, respectively.

create the estimator

   next, let's create an estimator (a tensorflow class for performing
   high-level model training, evaluation, and id136) for our model.
   add the following code to main():
# create the estimator
mnist_classifier = tf.estimator.estimator(
    model_fn=id98_model_fn, model_dir="/tmp/mnist_convnet_model")

info:tensorflow:using default config.
info:tensorflow:using config: {'_num_ps_replicas': 0, '_num_worker_replicas': 1,
 '_keep_checkpoint_every_n_hours': 10000, '_service': none, '_global_id_in_clust
er': 0, '_save_checkpoints_secs': 600, '_save_summary_steps': 100, '_device_fn':
 none, '_save_checkpoints_steps': none, '_is_chief': true, '_evaluation_master':
 '', '_master': '', '_experimental_distribute': none, '_task_type': 'worker', '_
cluster_spec': <tensorflow.python.training.server_lib.clusterspec object at 0x7f
f37d301b70>, '_train_distribute': none, '_tf_random_seed': none, '_protocol': no
ne, '_model_dir': '/tmp/mnist_convnet_model', '_eval_distribute': none, '_sessio
n_config': allow_soft_placement: true
graph_options {
  rewrite_options {
    meta_optimizer_iterations: one
  }
}
, '_log_step_count_steps': 100, '_task_id': 0, '_keep_checkpoint_max': 5}

   the model_fn argument specifies the model function to use for training,
   evaluation, and prediction; we pass it the id98_model_fn we created in
   [135]"building the id98 mnist classifier." the model_dir argument
   specifies the directory where model data (checkpoints) will be saved
   (here, we specify the temp directory /tmp/mnist_convnet_model, but feel
   free to change to another directory of your choice).

   note: for an in-depth walkthrough of the tensorflow estimator api, see
   the tutorial [136]creating estimators in tf.estimator.

set up a logging hook

   since id98s can take a while to train, let's set up some logging so we
   can track progress during training. we can use tensorflow's
   [137]tf.train.sessionrunhook to create a
   [138]tf.train.loggingtensorhook that will log the id203 values
   from the softmax layer of our id98. add the following to main():
# set up logging for predictions
tensors_to_log = {"probabilities": "softmax_tensor"}

logging_hook = tf.train.loggingtensorhook(
    tensors=tensors_to_log, every_n_iter=50)

   we store a dict of the tensors we want to log in tensors_to_log. each
   key is a label of our choice that will be printed in the log output,
   and the corresponding label is the name of a tensor in the tensorflow
   graph. here, our probabilities can be found in softmax_tensor, the name
   we gave our softmax operation earlier when we generated the
   probabilities in id98_model_fn.

   note: if you don't explicitly assign a name to an operation via the
   name argument, tensorflow will assign a default name. a couple easy
   ways to discover the names applied to operations are to visualize your
   graph on [139]tensorboard) or to enable the [140]tensorflow debugger
   (tfdbg).

   next, we create the loggingtensorhook, passing tensors_to_log to the
   tensors argument. we set every_n_iter=50, which specifies that
   probabilities should be logged after every 50 steps of training.

train the model

   now we're ready to train our model, which we can do by creating
   train_input_fn and calling train() on mnist_classifier. in the
   numpy_input_fn call, we pass the training feature data and labels to x
   (as a dict) and y, respectively. we set a batch_size of 100 (which
   means that the model will train on minibatches of 100 examples at each
   step). num_epochs=none means that the model will train until the
   specified number of steps is reached. we also set shuffle=true to
   shuffle the training data. then train the model a single step and log
   the output:
# train the model
train_input_fn = tf.estimator.inputs.numpy_input_fn(
    x={"x": train_data},
    y=train_labels,
    batch_size=100,
    num_epochs=none,
    shuffle=true)

# train one step and display the probabilties
mnist_classifier.train(
    input_fn=train_input_fn,
    steps=1,
    hooks=[logging_hook])

warning:tensorflow:from /usr/local/lib/python3.5/dist-packages/tensorflow/python
/framework/op_def_library.py:263: colocate_with (from tensorflow.python.framewor
k.ops) is deprecated and will be removed in a future version.
instructions for updating:
colocations handled automatically by placer.
warning:tensorflow:from /usr/local/lib/python3.5/dist-packages/tensorflow_estima
tor/python/estimator/inputs/queues/feeding_queue_runner.py:62: queuerunner.__ini
t__ (from tensorflow.python.training.queue_runner_impl) is deprecated and will b
e removed in a future version.
instructions for updating:
to construct input pipelines, use the <a href="../../api_docs/python/tf/data"><c
ode>tf.data</code></a> module.
warning:tensorflow:from /usr/local/lib/python3.5/dist-packages/tensorflow_estima
tor/python/estimator/inputs/queues/feeding_functions.py:500: add_queue_runner (f
rom tensorflow.python.training.queue_runner_impl) is deprecated and will be remo
ved in a future version.
instructions for updating:
to construct input pipelines, use the <a href="../../api_docs/python/tf/data"><c
ode>tf.data</code></a> module.
info:tensorflow:calling model_fn.
warning:tensorflow:from <ipython-input-2-16a10fb7f348>:12: conv2d (from tensorfl
ow.python.layers.convolutional) is deprecated and will be removed in a future ve
rsion.
instructions for updating:
use keras.layers.conv2d instead.
warning:tensorflow:from <ipython-input-2-16a10fb7f348>:15: max_pooling2d (from t
ensorflow.python.layers.pooling) is deprecated and will be removed in a future v
ersion.
instructions for updating:
use keras.layers.max_pooling2d instead.
warning:tensorflow:from <ipython-input-2-16a10fb7f348>:28: dense (from tensorflo
w.python.layers.core) is deprecated and will be removed in a future version.
instructions for updating:
use keras.layers.dense instead.
warning:tensorflow:from <ipython-input-2-16a10fb7f348>:30: dropout (from tensorf
low.python.layers.core) is deprecated and will be removed in a future version.
instructions for updating:
use keras.layers.dropout instead.
warning:tensorflow:from /usr/local/lib/python3.5/dist-packages/tensorflow/python
/keras/layers/core.py:143: calling dropout (from tensorflow.python.ops.nn_ops) w
ith keep_prob is deprecated and will be removed in a future version.
instructions for updating:
please use `rate` instead of `keep_prob`. rate should be set to `rate = 1 - keep
_prob`.
warning:tensorflow:from /usr/local/lib/python3.5/dist-packages/tensorflow/python
/ops/losses/losses_impl.py:209: to_float (from tensorflow.python.ops.math_ops) i
s deprecated and will be removed in a future version.
instructions for updating:
use tf.cast instead.
info:tensorflow:done calling model_fn.
info:tensorflow:create checkpointsaverhook.
info:tensorflow:graph was finalized.
info:tensorflow:running local_init_op.
info:tensorflow:done running local_init_op.
warning:tensorflow:from /usr/local/lib/python3.5/dist-packages/tensorflow/python
/training/monitored_session.py:809: start_queue_runners (from tensorflow.python.
training.queue_runner_impl) is deprecated and will be removed in a future versio
n.
instructions for updating:
to construct input pipelines, use the <a href="../../api_docs/python/tf/data"><c
ode>tf.data</code></a> module.
info:tensorflow:saving checkpoints for 0 into /tmp/mnist_convnet_model/model.ckp
t.
info:tensorflow:probabilities = [[0.09814765 0.09244499 0.10081033 0.10804093 0.
09637886 0.09711793
  0.09609565 0.09307893 0.10885311 0.10903157]
 [0.09768429 0.09583082 0.0957139  0.09429494 0.09038909 0.11616832
  0.09012306 0.10395669 0.10381358 0.11202539]
 [0.08873812 0.09626804 0.0967943  0.10666492 0.09594218 0.10952878
  0.09540596 0.097888   0.10734777 0.10542186]
 [0.09028026 0.10238118 0.09824888 0.10746839 0.09031972 0.10666055
  0.0982739  0.09789792 0.09998649 0.10848268]
 [0.09649029 0.10322121 0.09380158 0.10317435 0.09366722 0.11095183
  0.10359363 0.09939642 0.09374755 0.1019559 ]
 [0.09722291 0.10824685 0.08659964 0.11378962 0.09305606 0.10451552
  0.09696827 0.10021482 0.10044912 0.09893721]
 [0.10974831 0.09934954 0.09097052 0.09845214 0.10186846 0.10883131
  0.09545906 0.1030085  0.09256221 0.09974991]
 [0.09298874 0.08970142 0.09417376 0.09848507 0.10997736 0.10690058
  0.10299174 0.10714611 0.09534581 0.10228945]
 [0.0980564  0.0950885  0.10273939 0.10366639 0.09845257 0.10543901
  0.09814783 0.10197263 0.09623619 0.1002011 ]
 [0.08611418 0.09204219 0.09869438 0.11534355 0.09612708 0.09993107
  0.1043229  0.09541078 0.09887666 0.11313721]
 [0.0911032  0.10094148 0.09864179 0.10325156 0.09313335 0.10152219
  0.10092542 0.10110351 0.10824786 0.10112967]
 [0.09052278 0.11120415 0.10413896 0.10844271 0.09419572 0.10442188
  0.09471755 0.092328   0.10132314 0.09870514]
 [0.09452067 0.1003839  0.10014904 0.09817781 0.10543428 0.10173164
  0.10635999 0.08806663 0.11082977 0.09434621]
 [0.09606165 0.10403834 0.09413929 0.11279032 0.10545824 0.10787785
  0.09034549 0.0939844  0.09833419 0.0969702 ]
 [0.09828904 0.10149893 0.09629421 0.10896525 0.10058206 0.10267839
  0.09209563 0.10267937 0.08723575 0.1096814 ]
 [0.0900801  0.10213673 0.09637352 0.10980678 0.10129063 0.09714489
  0.0964738  0.08454569 0.11147666 0.11067118]
 [0.08966635 0.09476012 0.09742686 0.11457699 0.09736237 0.09938361
  0.09662021 0.08773508 0.10661928 0.11584909]
 [0.09130581 0.09608059 0.0966349  0.10849014 0.09236234 0.11179829
  0.09962809 0.09529706 0.10248163 0.10592119]
 [0.10171985 0.09906711 0.09613606 0.10073393 0.09151705 0.10331579
  0.1027301  0.09461012 0.1034798  0.10669016]
 [0.09600988 0.10762009 0.09039794 0.11299745 0.08988072 0.09787023
  0.09623789 0.09753717 0.10011996 0.11132864]
 [0.09573218 0.10058041 0.11254801 0.10715622 0.08980645 0.10634666
  0.08758737 0.09289047 0.10152955 0.10582273]
 [0.09174504 0.10339034 0.09081784 0.10322856 0.10825954 0.09986341
  0.09654341 0.08914214 0.10508662 0.11192305]
 [0.09604157 0.10153174 0.09903545 0.10614318 0.09895597 0.10075326
  0.09677841 0.09994099 0.09730268 0.10351674]
 [0.09635509 0.10173629 0.09148251 0.10156522 0.0961458  0.10201288
  0.10052095 0.10329958 0.10277596 0.10410567]
 [0.0953673  0.10607281 0.09439699 0.10041973 0.10168203 0.09889284
  0.09883859 0.10229894 0.09372536 0.10830536]
 [0.09561785 0.10390594 0.09527458 0.11660122 0.08725276 0.10204626
  0.09782588 0.08973552 0.10485453 0.1068855 ]
 [0.08857152 0.10815524 0.09051957 0.11500679 0.09446583 0.09678315
  0.09595738 0.09647599 0.10217822 0.11188637]
 [0.10118023 0.09708978 0.10013844 0.108582   0.09920231 0.1013741
  0.09588955 0.09269062 0.1032167  0.10063631]
 [0.09801185 0.09635458 0.09962773 0.10852576 0.09839619 0.09881036
  0.09971265 0.09977752 0.10466983 0.09611353]
 [0.10318252 0.09880748 0.10059649 0.09905674 0.0932729  0.1049736
  0.09863422 0.10139165 0.09596761 0.10411675]
 [0.09431802 0.10103545 0.09481675 0.11047952 0.11502837 0.09529042
  0.09955253 0.08798832 0.08806773 0.11342295]
 [0.09824076 0.09829782 0.09451623 0.0997389  0.09794606 0.10718913
  0.09281551 0.1089665  0.09788704 0.1044021 ]
 [0.09358598 0.10922889 0.08853089 0.11638997 0.11033333 0.09664057
  0.10461508 0.08917224 0.09535707 0.09614605]
 [0.10009345 0.10108026 0.09261277 0.11250348 0.09166759 0.10996037
  0.09302732 0.0865068  0.09548744 0.11706059]
 [0.0893574  0.11078054 0.09571582 0.10633408 0.10038985 0.09638236
  0.09964976 0.08916795 0.10212585 0.1100964 ]
 [0.09268553 0.10869793 0.08724615 0.10462402 0.09848284 0.11111277
  0.09374806 0.09968261 0.10297277 0.10074741]
 [0.09546065 0.0962811  0.09904987 0.10706905 0.10180572 0.09489596
  0.09608647 0.10320792 0.09857744 0.10756581]
 [0.08738037 0.1009704  0.09742127 0.11956678 0.10063861 0.09921869
  0.09208162 0.09311019 0.09479056 0.11482147]
 [0.08654324 0.10138249 0.09644957 0.11529599 0.09849339 0.10107011
  0.10230077 0.09499969 0.09075804 0.11270678]
 [0.08594485 0.11273979 0.09450912 0.10456472 0.10324618 0.10537324
  0.10833061 0.09476797 0.08663385 0.10388973]
 [0.09355583 0.0953675  0.09762789 0.10446595 0.10052348 0.10079551
  0.10355423 0.10241424 0.09340621 0.10828913]
 [0.09603233 0.09685302 0.09312017 0.0982099  0.10246003 0.10388823
  0.09392464 0.10406053 0.10858563 0.10286559]
 [0.09334756 0.09843125 0.09265213 0.1082994  0.1131939  0.10162378
  0.09821971 0.08687469 0.10673107 0.10062651]
 [0.09381192 0.10364662 0.09474575 0.10339332 0.08964965 0.11061972
  0.10147911 0.09188261 0.10628311 0.10448828]
 [0.08892165 0.11904115 0.09981381 0.1135087  0.10459112 0.0901383
  0.09217603 0.08812384 0.10213732 0.10154804]
 [0.09664196 0.0969509  0.08796925 0.11191147 0.10261022 0.09557269
  0.09695197 0.0927556  0.10903846 0.10959744]
 [0.09918626 0.10168891 0.09803572 0.10157254 0.10153982 0.10008229
  0.10104776 0.09836181 0.09676577 0.10171921]
 [0.09160379 0.10124634 0.09248227 0.10771002 0.12099614 0.09935947
  0.09980427 0.09038404 0.08818231 0.1082313 ]
 [0.09642122 0.102862   0.10482978 0.09591291 0.10025015 0.10053412
  0.0922405  0.10067844 0.10080302 0.10546786]
 [0.08937372 0.10232776 0.1005203  0.10584651 0.10718722 0.09741392
  0.09959298 0.09778444 0.09447844 0.10547473]
 [0.08873004 0.10370611 0.09471022 0.11327737 0.10045362 0.10496572
  0.10041921 0.08529989 0.09958768 0.1088501 ]
 [0.09981875 0.10626238 0.093287   0.09953875 0.10755917 0.10391425
  0.09461445 0.09350796 0.1041084  0.09738895]
 [0.09453046 0.09915151 0.10835532 0.11978462 0.10058784 0.09743205
  0.08762411 0.09618603 0.09644713 0.09990098]
 [0.092902   0.09955543 0.100568   0.11056461 0.10046835 0.09866504
  0.10012259 0.10043208 0.09513514 0.10158676]
 [0.09623892 0.09839711 0.10134893 0.11112953 0.09160637 0.10444292
  0.09543825 0.09666274 0.10189849 0.1028368 ]
 [0.08978889 0.09040787 0.09548377 0.10339355 0.09829717 0.0998203
  0.10531809 0.10022204 0.11213153 0.1051368 ]
 [0.0990392  0.10349653 0.08540598 0.1065378  0.10282471 0.09788668
  0.09756339 0.09320137 0.10137004 0.1126743 ]
 [0.10051455 0.10173831 0.10052704 0.10192108 0.09663077 0.10015754
  0.09443218 0.09810024 0.09863593 0.10734232]
 [0.08831286 0.09900514 0.11177535 0.10679188 0.10182948 0.10379469
  0.09407522 0.09724206 0.08958578 0.10758755]
 [0.09895421 0.10170394 0.09984475 0.107074   0.09655383 0.10458772
  0.09420821 0.09413934 0.09763632 0.10529768]
 [0.08824007 0.1014552  0.10283528 0.11143114 0.09841802 0.10236996
  0.09829088 0.09521851 0.09823785 0.10350302]
 [0.0979858  0.09890826 0.09836968 0.10263775 0.10022467 0.10410731
  0.09789351 0.09807868 0.09679153 0.10500285]
 [0.09706652 0.09446435 0.09679864 0.10145044 0.09177434 0.10592812
  0.10274946 0.09685596 0.10289433 0.11001788]
 [0.09091125 0.10170545 0.09586224 0.11587739 0.09929825 0.10844799
  0.08569081 0.1005933  0.10410852 0.09750489]
 [0.09596185 0.09964238 0.09138954 0.1108413  0.0972278  0.09425504
  0.09193766 0.1016736  0.10072539 0.11634541]
 [0.10043746 0.10514856 0.09405597 0.10442674 0.10192121 0.10052694
  0.10498299 0.08667921 0.09502943 0.10679145]
 [0.1003202  0.09430425 0.09698205 0.1086642  0.09849323 0.0983881
  0.0990418  0.09640371 0.0976258  0.10977667]
 [0.09326755 0.10130624 0.09991129 0.10654101 0.0989248  0.09977674
  0.0890115  0.09424686 0.10171416 0.11529977]
 [0.0952445  0.10644601 0.0947395  0.10062921 0.09869768 0.10599726
  0.09661229 0.09602747 0.09867483 0.1069313 ]
 [0.09416027 0.10241971 0.0942222  0.11767054 0.10169039 0.09771985
  0.09903159 0.0878539  0.10666459 0.09856687]
 [0.09329656 0.10238691 0.10691883 0.10654651 0.09666109 0.10417851
  0.08715171 0.10569578 0.09973288 0.09743121]
 [0.1050102  0.10116672 0.10597873 0.10080291 0.10007357 0.0941375
  0.09361841 0.10123783 0.09709948 0.10087462]
 [0.08495129 0.09615234 0.09287811 0.11802793 0.10036501 0.10091895
  0.09872681 0.09007818 0.09955393 0.11834743]
 [0.09331349 0.10728154 0.08769204 0.10426544 0.10445572 0.10384694
  0.10080623 0.08943979 0.10351128 0.10538758]
 [0.09551427 0.10308839 0.09699223 0.11101083 0.10028346 0.09470844
  0.09704886 0.08807344 0.11036961 0.10291041]
 [0.08949962 0.10568504 0.09144713 0.11090624 0.09883656 0.10449804
  0.09694371 0.09724925 0.10021061 0.10472374]
 [0.09012292 0.1021887  0.10019828 0.11355843 0.09939677 0.09663287
  0.10420292 0.07983934 0.1020867  0.11177306]
 [0.09719034 0.0901747  0.09898265 0.11225204 0.10029607 0.09784026
  0.09476989 0.09655358 0.09742302 0.11451747]
 [0.09854102 0.09517493 0.09923    0.10109586 0.09624434 0.10502547
  0.09701004 0.09801187 0.09946308 0.11020332]
 [0.0939843  0.11455388 0.09392765 0.10403335 0.09564567 0.09824695
  0.09927551 0.09390302 0.10144876 0.10498098]
 [0.09186824 0.09385434 0.10642872 0.11987049 0.0956362  0.1040276
  0.09421264 0.08740144 0.09855562 0.10814472]
 [0.08584628 0.09587696 0.10176077 0.10908642 0.0982416  0.10236374
  0.09244376 0.10437483 0.1036512  0.10635445]
 [0.08653226 0.10128593 0.10029317 0.11210266 0.09414969 0.1033035
  0.10229436 0.09889025 0.09492384 0.10622436]
 [0.09243967 0.09859653 0.09466634 0.11446756 0.10872576 0.0954171
  0.09815422 0.0907835  0.10072668 0.1060227 ]
 [0.08632016 0.10280059 0.10295647 0.11853016 0.08949459 0.09918682
  0.09739561 0.09316463 0.09673889 0.1134121 ]
 [0.10075227 0.10721398 0.09895937 0.10315568 0.08916324 0.108132
  0.09524496 0.09380359 0.09536278 0.10821216]
 [0.09624109 0.10289072 0.09441718 0.09571033 0.09758015 0.09958486
  0.11450734 0.10110405 0.09969434 0.09826995]
 [0.09830879 0.10154869 0.08613823 0.10788829 0.09560067 0.10209841
  0.09575619 0.09973835 0.10492487 0.1079975 ]
 [0.09258462 0.09839676 0.10263189 0.11582264 0.10346422 0.0960208
  0.09242152 0.09612181 0.09857229 0.10396343]
 [0.09901138 0.09740745 0.09478541 0.10669693 0.09918224 0.10268448
  0.09839904 0.0966041  0.09721728 0.10801163]
 [0.09331058 0.09706809 0.10149837 0.11212907 0.09978285 0.10643713
  0.09682941 0.09645371 0.09090704 0.1055838 ]
 [0.09375338 0.09883419 0.09803129 0.1046678  0.09920859 0.1022219
  0.09685509 0.10545842 0.09586328 0.10510613]
 [0.08819251 0.10206438 0.0961441  0.10911998 0.10233422 0.10276911
  0.09476335 0.09961385 0.10148226 0.10351624]
 [0.08704353 0.10652339 0.10326986 0.10366923 0.09557523 0.10386191
  0.10196959 0.0959992  0.09678013 0.10530804]
 [0.08923662 0.09745993 0.09791221 0.1076473  0.10206109 0.10270201
  0.10361581 0.0949479  0.10350806 0.10090908]
 [0.10004867 0.09878463 0.09699501 0.1055755  0.09614269 0.11283921
  0.08763129 0.08927232 0.09689757 0.1158132 ]
 [0.11081409 0.09511841 0.09713332 0.101343   0.09621765 0.09815601
  0.10312684 0.08734889 0.10804369 0.10269815]
 [0.09903139 0.108316   0.10070005 0.1071276  0.09091476 0.10396387
  0.09259767 0.10103583 0.09274015 0.10357264]
 [0.08510682 0.10631745 0.10726117 0.10734592 0.0905598  0.10487398
  0.09099197 0.09477259 0.11042348 0.10234693]
 [0.09524962 0.10245375 0.09499474 0.11348926 0.11162694 0.094615
  0.09500292 0.08884564 0.10072819 0.1029939 ]]
info:tensorflow:loss = 2.310406, step = 1
info:tensorflow:saving checkpoints for 1 into /tmp/mnist_convnet_model/model.ckp
t.
info:tensorflow:loss for final step: 2.310406.

<tensorflow_estimator.python.estimator.estimator.estimator at 0x7ff37d301828>

   now   without logging each step   set steps=1000 to train the model longer,
   but in a reasonable time to run this example. training id98s is
   computationally intensive. to increase the accuracy of your model,
   increase the number of steps passed to train(), like 20,000 steps.
mnist_classifier.train(input_fn=train_input_fn, steps=1000)

info:tensorflow:calling model_fn.
info:tensorflow:done calling model_fn.
info:tensorflow:create checkpointsaverhook.
info:tensorflow:graph was finalized.
warning:tensorflow:from /usr/local/lib/python3.5/dist-packages/tensorflow/python
/training/saver.py:1266: checkpoint_exists (from tensorflow.python.training.chec
kpoint_management) is deprecated and will be removed in a future version.
instructions for updating:
use standard file apis to check for files with this prefix.
info:tensorflow:restoring parameters from /tmp/mnist_convnet_model/model.ckpt-1
warning:tensorflow:from /usr/local/lib/python3.5/dist-packages/tensorflow/python
/training/saver.py:1070: get_checkpoint_mtimes (from tensorflow.python.training.
checkpoint_management) is deprecated and will be removed in a future version.
instructions for updating:
use standard file utilities to get mtimes.
info:tensorflow:running local_init_op.
info:tensorflow:done running local_init_op.
info:tensorflow:saving checkpoints for 1 into /tmp/mnist_convnet_model/model.ckp
t.
info:tensorflow:loss = 2.2986903, step = 2
info:tensorflow:global_step/sec: 14.4539
info:tensorflow:loss = 2.2711368, step = 102 (6.920 sec)
info:tensorflow:global_step/sec: 14.6723
info:tensorflow:loss = 2.2634466, step = 202 (6.816 sec)
info:tensorflow:global_step/sec: 14.3592
info:tensorflow:loss = 2.2494085, step = 302 (6.964 sec)
info:tensorflow:global_step/sec: 15.4573
info:tensorflow:loss = 2.2136223, step = 402 (6.469 sec)
info:tensorflow:global_step/sec: 14.7598
info:tensorflow:loss = 2.1997516, step = 502 (6.775 sec)
info:tensorflow:global_step/sec: 14.1595
info:tensorflow:loss = 2.17101, step = 602 (7.062 sec)
info:tensorflow:global_step/sec: 14.7719
info:tensorflow:loss = 2.1265142, step = 702 (6.770 sec)
info:tensorflow:global_step/sec: 14.839
info:tensorflow:loss = 2.0933232, step = 802 (6.739 sec)
info:tensorflow:global_step/sec: 14.7068
info:tensorflow:loss = 1.9869853, step = 902 (6.800 sec)
info:tensorflow:saving checkpoints for 1001 into /tmp/mnist_convnet_model/model.
ckpt.
info:tensorflow:loss for final step: 1.8993526.

<tensorflow_estimator.python.estimator.estimator.estimator at 0x7ff37d301828>

evaluate the model

   once training is complete, we want to evaluate our model to determine
   its accuracy on the mnist test set. we call the evaluate method, which
   evaluates the metrics we specified in eval_metric_ops argument in the
   model_fn. add the following to main():
eval_input_fn = tf.estimator.inputs.numpy_input_fn(
    x={"x": eval_data},
    y=eval_labels,
    num_epochs=1,
    shuffle=false)

eval_results = mnist_classifier.evaluate(input_fn=eval_input_fn)
print(eval_results)

info:tensorflow:calling model_fn.
info:tensorflow:done calling model_fn.
info:tensorflow:starting evaluation at 2019-02-23t22:55:57z
info:tensorflow:graph was finalized.
info:tensorflow:restoring parameters from /tmp/mnist_convnet_model/model.ckpt-10
01
info:tensorflow:running local_init_op.
info:tensorflow:done running local_init_op.
info:tensorflow:finished evaluation at 2019-02-23-22:55:59
info:tensorflow:saving dict for global step 1001: accuracy = 0.7326, global_step
 = 1001, loss = 1.9049935
info:tensorflow:saving 'checkpoint_path' summary for global step 1001: /tmp/mnis
t_convnet_model/model.ckpt-1001
{'accuracy': 0.7326, 'loss': 1.9049935, 'global_step': 1001}

   to create eval_input_fn, we set num_epochs=1, so that the model
   evaluates the metrics over one epoch of data and returns the result. we
   also set shuffle=false to iterate through the data sequentially.

additional resources

   to learn more about tensorflow estimators and id98s in tensorflow, see
   the following resources:
     * [141]creating estimators in tf.estimator provides an introduction
       to the tensorflow estimator api. it walks through configuring an
       estimator, writing a model function, calculating loss, and defining
       a training op.
     * [142]advanced convolutional neural networks walks through how to
       build a mnist id98 classification model without estimators using
       lower-level tensorflow operations.

   except as otherwise noted, the content of this page is licensed under
   the [143]creative commons attribution 3.0 license, and code samples are
   licensed under the [144]apache 2.0 license. for details, see the
   [145]google developers site policies. java is a registered trademark of
   oracle and/or its affiliates.

     * stay connected
          + [146]blog
          + [147]github
          + [148]twitter
          + [149]youtube
     * support
          + [150]issue tracker
          + [151]release notes
          + [152]stack overflow
          + [153]brand guidelines

     * [154]terms
     * [155]privacy

   [english_____]

references

   visible links
   1. https://www.tensorflow.org/s/opensearch.xml
   2. https://www.tensorflow.org/
   3. https://www.tensorflow.org/install
   4. https://www.tensorflow.org/learn
   5. https://www.tensorflow.org/learn
   6. https://www.tensorflow.org/overview
   7. https://www.tensorflow.org/js
   8. https://www.tensorflow.org/lite
   9. https://www.tensorflow.org/tfx
  10. https://www.tensorflow.org/swift
  11. https://www.tensorflow.org/api_docs/python/tf
  12. https://www.tensorflow.org/api_docs/python/tf
  13. https://www.tensorflow.org/versions/r1.12/api_docs/python/tf
  14. https://www.tensorflow.org/versions/r1.11/api_docs/python/tf
  15. https://www.tensorflow.org/versions/r1.10/api_docs/python/tf
  16. https://www.tensorflow.org/versions/r1.9/api_docs/python/tf
  17. https://www.tensorflow.org/versions
  18. https://www.tensorflow.org/versions/r2.0/api_docs/python/tf
  19. https://www.tensorflow.org/resources/models-datasets
  20. https://www.tensorflow.org/resources/models-datasets
  21. https://www.tensorflow.org/resources/tools
  22. https://www.tensorflow.org/resources/libraries-extensions
  23. https://www.tensorflow.org/community
  24. https://www.tensorflow.org/about
  25. https://www.tensorflow.org/about
  26. https://www.tensorflow.org/about/case-studies
  27. https://github.com/tensorflow
  28. https://www.tensorflow.org/overview
  29. https://www.tensorflow.org/overview
  30. https://www.tensorflow.org/tutorials
  31. https://www.tensorflow.org/guide
  32. https://www.tensorflow.org/alpha
  33. https://www.tensorflow.org/install
  34. https://www.tensorflow.org/learn
  35. https://www.tensorflow.org/overview
  36. https://www.tensorflow.org/tutorials
  37. https://www.tensorflow.org/guide
  38. https://www.tensorflow.org/alpha
  39. https://www.tensorflow.org/api_docs/python/tf
  40. https://www.tensorflow.org/resources/models-datasets
  41. https://www.tensorflow.org/community
  42. https://www.tensorflow.org/about
  43. https://github.com/tensorflow
  44. https://www.tensorflow.org/tutorials
  45. https://www.tensorflow.org/tutorials/keras
  46. https://www.tensorflow.org/tutorials/keras/basic_classification
  47. https://www.tensorflow.org/tutorials/keras/basic_text_classification
  48. https://www.tensorflow.org/tutorials/keras/basic_regression
  49. https://www.tensorflow.org/tutorials/keras/overfit_and_underfit
  50. https://www.tensorflow.org/tutorials/keras/save_and_restore_models
  51. https://www.tensorflow.org/tutorials/eager
  52. https://www.tensorflow.org/tutorials/eager/eager_basics
  53. https://www.tensorflow.org/tutorials/eager/automatic_differentiation
  54. https://www.tensorflow.org/tutorials/eager/custom_training
  55. https://www.tensorflow.org/tutorials/eager/custom_layers
  56. https://www.tensorflow.org/tutorials/eager/custom_training_walkthrough
  57. https://www.tensorflow.org/tutorials/estimators/linear
  58. https://github.com/tensorflow/models/tree/master/official/wide_deep
  59. https://www.tensorflow.org/tutorials/estimators/boosted_trees
  60. https://www.tensorflow.org/tutorials/estimators/boosted_trees_model_understanding
  61. https://www.tensorflow.org/tutorials/estimators/id98
  62. https://github.com/tensorflow/tensorflow/blob/r1.13/tensorflow/contrib/eager/python/examples/id4_with_attention/id4_with_attention.ipynb
  63. https://github.com/tensorflow/tensorflow/blob/r1.13/tensorflow/contrib/eager/python/examples/generative_examples/image_captioning_with_attention.ipynb
  64. https://github.com/tensorflow/tensorflow/blob/r1.13/tensorflow/contrib/eager/python/examples/generative_examples/dcgan.ipynb
  65. https://github.com/tensorflow/tensorflow/blob/r1.13/tensorflow/contrib/eager/python/examples/generative_examples/cvae.ipynb
  66. https://www.tensorflow.org/tutorials/images/hub_with_keras
  67. https://github.com/tensorflow/tensorflow/blob/r1.13/tensorflow/contrib/eager/python/examples/pix2pix/pix2pix_eager.ipynb
  68. https://github.com/tensorflow/models/blob/master/research/nst_blogpost/4_neural_style_transfer_with_eager_execution.ipynb
  69. https://github.com/tensorflow/models/blob/master/samples/outreach/blogs/segmentation_blogpost/image_segmentation.ipynb
  70. https://www.tensorflow.org/tutorials/images/deep_id98
  71. https://www.tensorflow.org/tutorials/sequences/text_generation
  72. https://www.tensorflow.org/tutorials/sequences/recurrent
  73. https://www.tensorflow.org/tutorials/sequences/recurrent_quickdraw
  74. https://www.tensorflow.org/tutorials/sequences/audio_recognition
  75. https://github.com/tensorflow/id4
  76. https://www.tensorflow.org/tutorials/load_data/images
  77. https://www.tensorflow.org/tutorials/load_data/tf_records
  78. https://www.tensorflow.org/tutorials/representation/id97
  79. https://www.tensorflow.org/tutorials/representation/kernel_methods
  80. https://www.tensorflow.org/tutorials/representation/linear
  81. https://www.tensorflow.org/tutorials/representation/unicode
  82. https://www.tensorflow.org/tutorials/non-ml/mandelbrot
  83. https://www.tensorflow.org/tutorials/non-ml/pdes
  84. https://www.tensorflow.org/learn
  85. https://www.tensorflow.org/overview
  86. https://www.tensorflow.org/js
  87. https://www.tensorflow.org/lite
  88. https://www.tensorflow.org/tfx
  89. https://www.tensorflow.org/swift
  90. https://www.tensorflow.org/api_docs/python/tf
  91. https://www.tensorflow.org/versions/r1.12/api_docs/python/tf
  92. https://www.tensorflow.org/versions/r1.11/api_docs/python/tf
  93. https://www.tensorflow.org/versions/r1.10/api_docs/python/tf
  94. https://www.tensorflow.org/versions/r1.9/api_docs/python/tf
  95. https://www.tensorflow.org/versions
  96. https://www.tensorflow.org/versions/r2.0/api_docs/python/tf
  97. https://www.tensorflow.org/resources/models-datasets
  98. https://www.tensorflow.org/resources/tools
  99. https://www.tensorflow.org/resources/libraries-extensions
 100. https://www.tensorflow.org/about
 101. https://www.tensorflow.org/about/case-studies
 102. https://www.youtube.com/playlist?list=plqy2h8rroyvzouyi26khmksjbedn3squb
 103. https://www.tensorflow.org/
 104. https://www.tensorflow.org/learn
 105. https://www.tensorflow.org/overview
 106. https://www.tensorflow.org/tutorials
 107. https://www.tensorflow.org/tutorials/estimators/id98
 108. https://colab.research.google.com/github/tensorflow/docs/blob/master/site/en/tutorials/estimators/id98.ipynb
 109. https://github.com/tensorflow/docs/blob/master/site/en/tutorials/estimators/id98.ipynb
 110. https://www.tensorflow.org/api_docs/python/tf/layers
 111. http://yann.lecun.com/exdb/mnist/
 112. https://www.tensorflow.org/code/tensorflow/examples/tutorials/layers/id98_mnist.py
 113. https://en.wikipedia.org/wiki/rectifier_(neural_networks)
 114. https://en.wikipedia.org/wiki/convolutional_neural_network#pooling_layer
 115. https://en.wikipedia.org/wiki/softmax_function
 116. https://cs231n.github.io/convolutional-networks/
 117. https://www.tensorflow.org/api_docs/python/tf/layers
 118. https://www.tensorflow.org/tutorials/estimators/id98#create_the_estimator
 119. https://www.tensorflow.org/api_docs/python/tf/estimator/modekeys
 120. https://www.tensorflow.org/api_docs/python/tf/layers
 121. https://www.tensorflow.org/guide/custom_estimators
 122. https://www.tensorflow.org/tutorials/estimators/id98#train_eval_mnist
 123. https://www.tensorflow.org/api_docs/python/tf/nn/relu
 124. https://www.tensorflow.org/api_docs/python/tf/nn/relu
 125. https://www.tensorflow.org/api_docs/python/tf/math/argmax
 126. https://www.tensorflow.org/api_docs/python/tf/nn/softmax
 127. https://www.tensorflow.org/tutorials/estimators/id98#set_up_a_logging_hook
 128. https://en.wikipedia.org/wiki/loss_function
 129. https://en.wikipedia.org/wiki/cross_id178
 130. https://www.tensorflow.org/api_docs/python/tf/losses/sparse_softmax_cross_id178
 131. https://en.wikipedia.org/wiki/stochastic_gradient_descent
 132. https://www.tensorflow.org/guide/custom_estimators#defining-the-training-op-for-the-model
 133. https://www.tensorflow.org/guide/custom_estimators
 134. https://docs.scipy.org/doc/numpy/reference/generated/numpy.array.html
 135. https://www.tensorflow.org/tutorials/estimators/id98#building_the_id98_mnist_classifier
 136. https://www.tensorflow.org/guide/custom_estimators
 137. https://www.tensorflow.org/api_docs/python/tf/train/sessionrunhook
 138. https://www.tensorflow.org/api_docs/python/tf/train/loggingtensorhook
 139. https://www.tensorflow.org/guide/graph_viz
 140. https://www.tensorflow.org/guide/debugger
 141. https://www.tensorflow.org/guide/custom_estimators
 142. https://www.tensorflow.org/tutorials/images/deep_id98
 143. https://creativecommons.org/licenses/by/3.0/
 144. https://www.apache.org/licenses/license-2.0
 145. https://developers.google.com/site-policies
 146. https://medium.com/tensorflow
 147. https://github.com/tensorflow/
 148. https://twitter.com/tensorflow
 149. https://youtube.com/tensorflow
 150. https://github.com/tensorflow/tensorflow/issues
 151. https://github.com/tensorflow/tensorflow/blob/master/release.md
 152. https://stackoverflow.com/questions/tagged/tensorflow
 153. https://www.tensorflow.org/extras/tensorflow_brand_guidelines.pdf
 154. https://policies.google.com/terms
 155. https://policies.google.com/privacy

   hidden links:
 157. https://www.tensorflow.org/tutorials/estimators/id98
 158. https://www.tensorflow.org/tutorials/estimators/id98
 159. https://www.tensorflow.org/tutorials/estimators/id98
 160. https://www.tensorflow.org/tutorials/estimators/id98
