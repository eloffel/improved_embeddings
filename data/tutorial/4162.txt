   #[1]tensorflow

   (button)
   [2]tensorflow
     *

   [3]install [4]learn
     * [5]introduction
       new to tensorflow?
     * [6]tensorflow
       the core open source ml library
     * [7]for javascript
       tensorflow.js for ml using javascript
     * [8]for mobile & iot
       tensorflow lite for mobile and embedded devices
     * [9]for production
       tensorflow extended for end-to-end ml components
     * [10]swift for tensorflow (in beta)

   [11]api
     * api r1
     * [12]r1.13 (stable)
     * [13]r1.12
     * [14]r1.11
     * [15]r1.10
     * [16]r1.9
     * [17]more   

     * api r2
     * [18]r2.0 (preview)

   [19]resources
     * [20]models & datasets
       pre-trained models and datasets built by google and the community
     * [21]tools
       ecosystem of tools to help you use tensorflow
     * [22]libraries & extensions
       libraries and extensions built on tensorflow

   [23]community [24]why tensorflow
     * [25]about
     * [26]case studies

   ____________________
   (button)
   (button)
   [27]github
     * [28]tensorflow core

   [29]overview [30]tutorials [31]guide [32]tf 2.0 alpha

   (button)
     * [33]install
     * [34]learn
          + more
          + [35]overview
          + [36]tutorials
          + [37]guide
          + [38]tf 2.0 alpha
     * [39]api
          + more
     * [40]resources
          + more
     * [41]community
     * [42]why tensorflow
          + more
     * [43]github

     * [44]tensorflow guide
     * high level apis
     * [45]keras
     * [46]eager execution
     * [47]importing data
     * [48]introduction to estimators
     * estimators
     * [49]premade estimators
     * [50]checkpoints
     * [51]feature columns
     * [52]datasets for estimators
     * [53]creating custom estimators
     * accelerators
     * [54]distribute strategy
     * [55]using gpus
     * [56]using tpus
     * low level apis
     * [57]introduction
     * [58]tensors
     * [59]variables
     * [60]graphs and sessions
     * [61]save and restore
     * [62]control flow
     * [63]ragged tensors
     * ml concepts
     * [64]embeddings
     * debugging
     * [65]tensorflow debugger
     * performance
     * [66]overview
     * [67]data input pipeline
     * [68]benchmarks
     * extend
     * [69]tensorflow architecture
     * [70]create an op
     * [71]custom filesystem plugin
     * [72]custom file and record formats
     * [73]model files
     * [74]language bindings
     * [75]c++ guide
     * misc
     * [76]tensorflow version compatibility

     * [77]introduction
     * [78]tensorflow
     * [79]for javascript
     * [80]for mobile & iot
     * [81]for production
     * [82]swift for tensorflow (in beta)

     * api r1
     * [83]r1.13 (stable)
     * [84]r1.12
     * [85]r1.11
     * [86]r1.10
     * [87]r1.9
     * [88]more   
     * api r2
     * [89]r2.0 (preview)

     * [90]models & datasets
     * [91]tools
     * [92]libraries & extensions

     * [93]about
     * [94]case studies

   watch talks from the 2019 tensorflow dev summit [95]watch now
     * [96]tensorflow
     * [97]learn
     * [98]tensorflow core
     * [99]guide

using gpus

supported devices

   on a typical system, there are multiple computing devices. in
   tensorflow, the supported device types are cpu and gpu. they are
   represented as strings. for example:
     * "/cpu:0": the cpu of your machine.
     * "/device:gpu:0": the gpu of your machine, if you have one.
     * "/device:gpu:1": the second gpu of your machine, etc.

   if a tensorflow operation has both cpu and gpu implementations, the gpu
   devices will be given priority when the operation is assigned to a
   device. for example, matmul has both cpu and gpu kernels. on a system
   with devices cpu:0 and gpu:0, gpu:0 will be selected to run matmul.

logging device placement

   to find out which devices your operations and tensors are assigned to,
   create the session with log_device_placement configuration option set
   to true.
# creates a graph.
a = tf.constant([1.0, 2.0, 3.0, 4.0, 5.0, 6.0], shape=[2, 3], name='a')
b = tf.constant([1.0, 2.0, 3.0, 4.0, 5.0, 6.0], shape=[3, 2], name='b')
c = tf.matmul(a, b)
# creates a session with log_device_placement set to true.
sess = tf.session(config=tf.configproto(log_device_placement=true))
# runs the op.
print(sess.run(c))

   you should see the following output:
device mapping:
/job:localhost/replica:0/task:0/device:gpu:0 -> device: 0, name: tesla k40c, pci
 bus
id: 0000:05:00.0
b: /job:localhost/replica:0/task:0/device:gpu:0
a: /job:localhost/replica:0/task:0/device:gpu:0
matmul: /job:localhost/replica:0/task:0/device:gpu:0
[[ 22.  28.]
 [ 49.  64.]]

manual device placement

   if you would like a particular operation to run on a device of your
   choice instead of what's automatically selected for you, you can use
   with tf.device to create a device context such that all the operations
   within that context will have the same device assignment.
# creates a graph.
with tf.device('/cpu:0'):
  a = tf.constant([1.0, 2.0, 3.0, 4.0, 5.0, 6.0], shape=[2, 3], name='a')
  b = tf.constant([1.0, 2.0, 3.0, 4.0, 5.0, 6.0], shape=[3, 2], name='b')
c = tf.matmul(a, b)
# creates a session with log_device_placement set to true.
sess = tf.session(config=tf.configproto(log_device_placement=true))
# runs the op.
print(sess.run(c))

   you will see that now a and b are assigned to cpu:0. since a device was
   not explicitly specified for the matmul operation, the tensorflow
   runtime will choose one based on the operation and available devices
   (gpu:0 in this example) and automatically copy tensors between devices
   if required.
device mapping:
/job:localhost/replica:0/task:0/device:gpu:0 -> device: 0, name: tesla k40c, pci
 bus
id: 0000:05:00.0
b: /job:localhost/replica:0/task:0/cpu:0
a: /job:localhost/replica:0/task:0/cpu:0
matmul: /job:localhost/replica:0/task:0/device:gpu:0
[[ 22.  28.]
 [ 49.  64.]]

allowing gpu memory growth

   by default, tensorflow maps nearly all of the gpu memory of all gpus
   (subject to [100]cuda_visible_devices) visible to the process. this is
   done to more efficiently use the relatively precious gpu memory
   resources on the devices by reducing [101]memory fragmentation.

   in some cases it is desirable for the process to only allocate a subset
   of the available memory, or to only grow the memory usage as is needed
   by the process. tensorflow provides two config options on the session
   to control this.

   the first is the allow_growth option, which attempts to allocate only
   as much gpu memory based on runtime allocations: it starts out
   allocating very little memory, and as sessions get run and more gpu
   memory is needed, we extend the gpu memory region needed by the
   tensorflow process. note that we do not release memory, since that can
   lead to even worse memory fragmentation. to turn this option on, set
   the option in the configproto by:
config = tf.configproto()
config.gpu_options.allow_growth = true
session = tf.session(config=config, ...)

   the second method is the per_process_gpu_memory_fraction option, which
   determines the fraction of the overall amount of memory that each
   visible gpu should be allocated. for example, you can tell tensorflow
   to only allocate 40% of the total memory of each gpu by:
config = tf.configproto()
config.gpu_options.per_process_gpu_memory_fraction = 0.4
session = tf.session(config=config, ...)

   this is useful if you want to truly bound the amount of gpu memory
   available to the tensorflow process.

using a single gpu on a multi-gpu system

   if you have more than one gpu in your system, the gpu with the lowest
   id will be selected by default. if you would like to run on a different
   gpu, you will need to specify the preference explicitly:
# creates a graph.
with tf.device('/device:gpu:2'):
  a = tf.constant([1.0, 2.0, 3.0, 4.0, 5.0, 6.0], shape=[2, 3], name='a')
  b = tf.constant([1.0, 2.0, 3.0, 4.0, 5.0, 6.0], shape=[3, 2], name='b')
  c = tf.matmul(a, b)
# creates a session with log_device_placement set to true.
sess = tf.session(config=tf.configproto(log_device_placement=true))
# runs the op.
print(sess.run(c))

   if the device you have specified does not exist, you will get
   invalidargumenterror:
invalidargumenterror: invalid argument: cannot assign a device to node 'b':
could not satisfy explicit device specification '/device:gpu:2'
   [[{ {node b}} = const[dtype=dt_float, value=tensor<type: float shape: [3,2]
   values: 1 2 3...>, _device="/device:gpu:2"]()]]

   if you would like tensorflow to automatically choose an existing and
   supported device to run the operations in case the specified one
   doesn't exist, you can set allow_soft_placement to true in the
   configuration option when creating the session.
# creates a graph.
with tf.device('/device:gpu:2'):
  a = tf.constant([1.0, 2.0, 3.0, 4.0, 5.0, 6.0], shape=[2, 3], name='a')
  b = tf.constant([1.0, 2.0, 3.0, 4.0, 5.0, 6.0], shape=[3, 2], name='b')
  c = tf.matmul(a, b)
# creates a session with allow_soft_placement and log_device_placement set
# to true.
sess = tf.session(config=tf.configproto(
      allow_soft_placement=true, log_device_placement=true))
# runs the op.
print(sess.run(c))

using multiple gpus

   if you would like to run tensorflow on multiple gpus, you can construct
   your model in a multi-tower fashion where each tower is assigned to a
   different gpu. for example:
# creates a graph.
c = []
for d in ['/device:gpu:2', '/device:gpu:3']:
  with tf.device(d):
    a = tf.constant([1.0, 2.0, 3.0, 4.0, 5.0, 6.0], shape=[2, 3])
    b = tf.constant([1.0, 2.0, 3.0, 4.0, 5.0, 6.0], shape=[3, 2])
    c.append(tf.matmul(a, b))
with tf.device('/cpu:0'):
  sum = tf.add_n(c)
# creates a session with log_device_placement set to true.
sess = tf.session(config=tf.configproto(log_device_placement=true))
# runs the op.
print(sess.run(sum))

   you will see the following output.
device mapping:
/job:localhost/replica:0/task:0/device:gpu:0 -> device: 0, name: tesla k20m, pci
 bus
id: 0000:02:00.0
/job:localhost/replica:0/task:0/device:gpu:1 -> device: 1, name: tesla k20m, pci
 bus
id: 0000:03:00.0
/job:localhost/replica:0/task:0/device:gpu:2 -> device: 2, name: tesla k20m, pci
 bus
id: 0000:83:00.0
/job:localhost/replica:0/task:0/device:gpu:3 -> device: 3, name: tesla k20m, pci
 bus
id: 0000:84:00.0
const_3: /job:localhost/replica:0/task:0/device:gpu:3
const_2: /job:localhost/replica:0/task:0/device:gpu:3
matmul_1: /job:localhost/replica:0/task:0/device:gpu:3
const_1: /job:localhost/replica:0/task:0/device:gpu:2
const: /job:localhost/replica:0/task:0/device:gpu:2
matmul: /job:localhost/replica:0/task:0/device:gpu:2
addn: /job:localhost/replica:0/task:0/cpu:0
[[  44.   56.]
 [  98.  128.]]

   the [102]cifar10 tutorial is a good example demonstrating how to do
   training with multiple gpus.

   except as otherwise noted, the content of this page is licensed under
   the [103]creative commons attribution 3.0 license, and code samples are
   licensed under the [104]apache 2.0 license. for details, see the
   [105]google developers site policies. java is a registered trademark of
   oracle and/or its affiliates.

     * stay connected
          + [106]blog
          + [107]github
          + [108]twitter
          + [109]youtube
     * support
          + [110]issue tracker
          + [111]release notes
          + [112]stack overflow
          + [113]brand guidelines

     * [114]terms
     * [115]privacy

   [english_____]

references

   visible links
   1. https://www.tensorflow.org/s/opensearch.xml
   2. https://www.tensorflow.org/
   3. https://www.tensorflow.org/install
   4. https://www.tensorflow.org/learn
   5. https://www.tensorflow.org/learn
   6. https://www.tensorflow.org/overview
   7. https://www.tensorflow.org/js
   8. https://www.tensorflow.org/lite
   9. https://www.tensorflow.org/tfx
  10. https://www.tensorflow.org/swift
  11. https://www.tensorflow.org/api_docs/python/tf
  12. https://www.tensorflow.org/api_docs/python/tf
  13. https://www.tensorflow.org/versions/r1.12/api_docs/python/tf
  14. https://www.tensorflow.org/versions/r1.11/api_docs/python/tf
  15. https://www.tensorflow.org/versions/r1.10/api_docs/python/tf
  16. https://www.tensorflow.org/versions/r1.9/api_docs/python/tf
  17. https://www.tensorflow.org/versions
  18. https://www.tensorflow.org/versions/r2.0/api_docs/python/tf
  19. https://www.tensorflow.org/resources/models-datasets
  20. https://www.tensorflow.org/resources/models-datasets
  21. https://www.tensorflow.org/resources/tools
  22. https://www.tensorflow.org/resources/libraries-extensions
  23. https://www.tensorflow.org/community
  24. https://www.tensorflow.org/about
  25. https://www.tensorflow.org/about
  26. https://www.tensorflow.org/about/case-studies
  27. https://github.com/tensorflow
  28. https://www.tensorflow.org/overview
  29. https://www.tensorflow.org/overview
  30. https://www.tensorflow.org/tutorials
  31. https://www.tensorflow.org/guide
  32. https://www.tensorflow.org/alpha
  33. https://www.tensorflow.org/install
  34. https://www.tensorflow.org/learn
  35. https://www.tensorflow.org/overview
  36. https://www.tensorflow.org/tutorials
  37. https://www.tensorflow.org/guide
  38. https://www.tensorflow.org/alpha
  39. https://www.tensorflow.org/api_docs/python/tf
  40. https://www.tensorflow.org/resources/models-datasets
  41. https://www.tensorflow.org/community
  42. https://www.tensorflow.org/about
  43. https://github.com/tensorflow
  44. https://www.tensorflow.org/guide
  45. https://www.tensorflow.org/guide/keras
  46. https://www.tensorflow.org/guide/eager
  47. https://www.tensorflow.org/guide/datasets
  48. https://www.tensorflow.org/guide/estimators
  49. https://www.tensorflow.org/guide/premade_estimators
  50. https://www.tensorflow.org/guide/checkpoints
  51. https://www.tensorflow.org/guide/feature_columns
  52. https://www.tensorflow.org/guide/datasets_for_estimators
  53. https://www.tensorflow.org/guide/custom_estimators
  54. https://www.tensorflow.org/guide/distribute_strategy
  55. https://www.tensorflow.org/guide/using_gpu
  56. https://www.tensorflow.org/guide/using_tpu
  57. https://www.tensorflow.org/guide/low_level_intro
  58. https://www.tensorflow.org/guide/tensors
  59. https://www.tensorflow.org/guide/variables
  60. https://www.tensorflow.org/guide/graphs
  61. https://www.tensorflow.org/guide/saved_model
  62. https://www.tensorflow.org/guide/autograph
  63. https://www.tensorflow.org/guide/ragged_tensors
  64. https://www.tensorflow.org/guide/embedding
  65. https://www.tensorflow.org/guide/debugger
  66. https://www.tensorflow.org/guide/performance/overview
  67. https://www.tensorflow.org/guide/performance/datasets
  68. https://www.tensorflow.org/guide/performance/benchmarks
  69. https://www.tensorflow.org/guide/extend/architecture
  70. https://www.tensorflow.org/guide/extend/op
  71. https://www.tensorflow.org/guide/extend/filesystem
  72. https://www.tensorflow.org/guide/extend/formats
  73. https://www.tensorflow.org/guide/extend/model_files
  74. https://www.tensorflow.org/guide/extend/bindings
  75. https://www.tensorflow.org/guide/extend/cc
  76. https://www.tensorflow.org/guide/version_compat
  77. https://www.tensorflow.org/learn
  78. https://www.tensorflow.org/overview
  79. https://www.tensorflow.org/js
  80. https://www.tensorflow.org/lite
  81. https://www.tensorflow.org/tfx
  82. https://www.tensorflow.org/swift
  83. https://www.tensorflow.org/api_docs/python/tf
  84. https://www.tensorflow.org/versions/r1.12/api_docs/python/tf
  85. https://www.tensorflow.org/versions/r1.11/api_docs/python/tf
  86. https://www.tensorflow.org/versions/r1.10/api_docs/python/tf
  87. https://www.tensorflow.org/versions/r1.9/api_docs/python/tf
  88. https://www.tensorflow.org/versions
  89. https://www.tensorflow.org/versions/r2.0/api_docs/python/tf
  90. https://www.tensorflow.org/resources/models-datasets
  91. https://www.tensorflow.org/resources/tools
  92. https://www.tensorflow.org/resources/libraries-extensions
  93. https://www.tensorflow.org/about
  94. https://www.tensorflow.org/about/case-studies
  95. https://www.youtube.com/playlist?list=plqy2h8rroyvzouyi26khmksjbedn3squb
  96. https://www.tensorflow.org/
  97. https://www.tensorflow.org/learn
  98. https://www.tensorflow.org/overview
  99. https://www.tensorflow.org/guide
 100. https://docs.nvidia.com/cuda/cuda-c-programming-guide/index.html#env-vars
 101. https://en.wikipedia.org/wiki/fragmentation_(computing)
 102. https://www.tensorflow.org/tutorials/images/deep_id98
 103. https://creativecommons.org/licenses/by/3.0/
 104. https://www.apache.org/licenses/license-2.0
 105. https://developers.google.com/site-policies
 106. https://medium.com/tensorflow
 107. https://github.com/tensorflow/
 108. https://twitter.com/tensorflow
 109. https://youtube.com/tensorflow
 110. https://github.com/tensorflow/tensorflow/issues
 111. https://github.com/tensorflow/tensorflow/blob/master/release.md
 112. https://stackoverflow.com/questions/tagged/tensorflow
 113. https://www.tensorflow.org/extras/tensorflow_brand_guidelines.pdf
 114. https://policies.google.com/terms
 115. https://policies.google.com/privacy

   hidden links:
 117. https://www.tensorflow.org/guide/using_gpu
 118. https://www.tensorflow.org/guide/using_gpu
 119. https://www.tensorflow.org/guide/using_gpu
 120. https://www.tensorflow.org/guide/using_gpu
