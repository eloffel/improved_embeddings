   #[1]github [2]recent commits to tensor2tensor:master

   [3]skip to content

   (button)

     * why github?
       [4]features    
          + [5]code review
          + [6]project management
          + [7]integrations
          + [8]actions
          + [9]team management
          + [10]social coding
          + [11]documentation
          + [12]code hosting
          + [13]customer stories    
          + [14]security    
     * [15]enterprise
     * explore
          + [16]explore github    

learn & contribute
          + [17]topics
          + [18]collections
          + [19]trending
          + [20]learning lab
          + [21]open source guides

connect with others
          + [22]events
          + [23]community forum
          + [24]github education
     * [25]marketplace
     * pricing
       [26]plans    
          + [27]compare plans
          + [28]contact sales
          + [29]nonprofit    
          + [30]education    

   ____________________
     * in this repository all github    
       jump to    

     * no suggested jump to results

     * in this repository all github    
       jump to    
     * in this repository all github    
       jump to    

   [31]sign in [32]sign up

     * [33]watch [34]424
     * [35]star [36]7,380
     * [37]fork [38]1,871

[39]tensorflow/[40]tensor2tensor

   [41]code [42]issues 367 [43]pull requests 1 [44]insights
   (button) dismiss

join github today

   github is home to over 31 million developers working together to host
   and review code, manage projects, and build software together.
   [45]sign up
   library of deep learning models and datasets designed to make deep
   learning more accessible and accelerate ml research.
   [46]machine-learning [47]machine-translation [48]deep-learning
   [49]reinforcement-learning [50]tpu
     * [51]3,529 commits
     * [52]1 branch
     * [53]63 releases
     * [54]155 contributors
     * [55]apache-2.0

    1. [56]python 61.0%
    2. [57]jupyter notebook 37.2%
    3. other 1.8%

   (button) python jupyter notebook other
   branch: master (button) new pull request
   [58]find file
   clone or download

clone with https

   use git or checkout with svn using the web url.
   https://github.com/t
   [59]download zip

downloading...

   want to be notified of new releases in tensorflow/tensor2tensor?
   [60]sign in [61]sign up

launching github desktop...

   if nothing happens, [62]download github desktop and try again.

   (button) go back

launching github desktop...

   if nothing happens, [63]download github desktop and try again.

   (button) go back

launching xcode...

   if nothing happens, [64]download xcode and try again.

   (button) go back

launching visual studio...

   if nothing happens, [65]download the github extension for visual studio
   and try again.

   (button) go back
   [66]@dustinvtran copybara-service
   [67]dustinvtran and copybara-service [68]fix oss test for reversible
   layers. (button)    
piperorigin-revid: 242157332

   latest commit [69]3562111 apr 5, 2019
   [70]permalink
   type name latest commit message commit time
   failed to load latest commit information.
   [71]docs [72]add videoflow paper to t2t readme apr 3, 2019
   [73]oss_scripts
   [74]tensor2tensor
   [75].gitignore [76]rm all uses of xrange and fix decode_length for
   slow_greedy_infer apr 20, 2018
   [77].travis.yml
   [78]authors
   [79]contributing.md
   [80]issue_template.md
   [81]license [82]initial push jun 15, 2017
   [83]readme.md
   [84]floyd.yml
   [85]floyd_requirements.txt [86]internal merge of pr [87]#961 aug 8,
   2018
   [88]pylintrc
   [89]setup.py

readme.md

tensor2tensor

   [90]pypi version [91]github issues [92]contributions welcome [93]gitter
   [94]license [95]travis [96]run on fh

   [97]tensor2tensor, or [98]t2t for short, is a library of deep learning
   models and datasets designed to make deep learning more accessible and
   [99]accelerate ml research. t2t is actively used and maintained by
   researchers and engineers within the [100]google brain team and a
   community of users. we're eager to collaborate with you too, so feel
   free to [101]open an issue on github or send along a pull request (see
   [102]our contribution doc). you can chat with us on [103]gitter and
   join the [104]t2t google group.

quick start

   [105]this ipython notebook explains t2t and runs in your browser using
   a free vm from google, no installation needed. alternatively, here is a
   one-command version that installs t2t, downloads mnist, trains a model
   and evaluates it:
pip install tensor2tensor && t2t-trainer \
  --generate_data \
  --data_dir=~/t2t_data \
  --output_dir=~/t2t_train/mnist \
  --problem=image_mnist \
  --model=shake_shake \
  --hparams_set=shake_shake_quick \
  --train_steps=1000 \
  --eval_steps=100

contents

     * [106]suggested datasets and models
          + [107]mathematical language understanding
          + [108]story, question and answer
          + [109]image classification
          + [110]image generation
          + [111]id38
          + [112]id31
          + [113]id103
          + [114]summarization
          + [115]translation
     * [116]basics
          + [117]walkthrough
          + [118]installation
          + [119]features
     * [120]t2t overview
          + [121]datasets
          + [122]problems and modalities
          + [123]models
          + [124]hyperparameter sets
          + [125]trainer
     * [126]adding your own components
     * [127]adding a dataset
     * [128]papers
     * [129]run on floydhub

suggested datasets and models

   below we list a number of tasks that can be solved with t2t when you
   train the appropriate model on the appropriate problem. we give the
   problem and model below and we suggest a setting of hyperparameters
   that we know works well in our setup. we usually run either on cloud
   tpus or on 8-gpu machines; you might need to modify the hyperparameters
   if you run on a different setup.

mathematical language understanding

   for evaluating mathematical expressions at the character level
   involving addition, subtraction and multiplication of both positive and
   negative decimal numbers with variable digits assigned to symbolic
   variables, use
     * the [130]mlu data-set: --problem=algorithmic_math_two_variables

   you can try solving the problem with different transformer models and
   hyperparameters as described in the [131]paper:
     * standard transformer: --model=transformer
       --hparams_set=transformer_tiny
     * universal transformer: --model=universal_transformer
       --hparams_set=universal_transformer_tiny
     * adaptive universal transformer: --model=universal_transformer
       --hparams_set=adaptive_universal_transformer_tiny

story, question and answer

   for answering questions based on a story, use
     * the [132]babi data-set: --problem=babi_qa_concat_task1_1k

   you can choose the babi task from the range [1,20] and the subset from
   1k or 10k. to combine test data from all tasks into a single test set,
   use --problem=babi_qa_concat_all_tasks_10k

image classification

   for image classification, we have a number of standard data-sets:
     * id163 (a large data-set): --problem=image_id163, or one of
       the re-scaled versions (image_id163224, image_id16364,
       image_id16332)
     * cifar-10: --problem=image_cifar10 (or --problem=image_cifar10_plain
       to turn off data augmentation)
     * cifar-100: --problem=image_cifar100
     * mnist: --problem=image_mnist

   for id163, we suggest to use the resnet or xception, i.e., use
   --model=resnet --hparams_set=resnet_50 or --model=xception
   --hparams_set=xception_base. resnet should get to above 76% top-1
   accuracy on id163.

   for cifar and mnist, we suggest to try the shake-shake model:
   --model=shake_shake --hparams_set=shakeshake_big. this setting trained
   for --train_steps=700000 should yield close to 97% accuracy on
   cifar-10.

image generation

   for (un)conditional image generation, we have a number of standard
   data-sets:
     * celeba: --problem=img2img_celeba for image-to-image translation,
       namely, superresolution from 8x8 to 32x32.
     * celeba-hq: --problem=image_celeba256_rev for a downsampled 256x256.
     * cifar-10: --problem=image_cifar10_plain_gen_rev for
       class-conditional 32x32 generation.
     * lsun bedrooms: --problem=image_lsun_bedrooms_rev
     * ms-coco: --problem=image_text_ms_coco_rev for text-to-image
       generation.
     * small id163 (a large data-set):
       --problem=image_id16332_gen_rev for 32x32 or
       --problem=image_id16364_gen_rev for 64x64.

   we suggest to use the image transformer, i.e.,
   --model=imagetransformer, or the image transformer plus, i.e.,
   --model=imagetransformerpp that uses discretized mixture of logistics,
   or variational auto-encoder, i.e., --model=transformer_ae. for
   cifar-10, using --hparams_set=imagetransformer_cifar10_base or
   --hparams_set=imagetransformer_cifar10_base_dmol yields 2.90 bits per
   dimension. for id163-32, using
   --hparams_set=imagetransformer_id16332_base yields 3.77 bits per
   dimension.

id38

   for id38, we have these data-sets in t2t:
     * ptb (a small data-set): --problem=languagemodel_ptb10k for
       word-level modeling and --problem=languagemodel_ptb_characters for
       character-level modeling.
     * lm1b (a billion-word corpus): --problem=languagemodel_lm1b32k for
       subword-level modeling and --problem=languagemodel_lm1b_characters
       for character-level modeling.

   we suggest to start with --model=transformer on this task and use
   --hparams_set=transformer_small for ptb and
   --hparams_set=transformer_base for lm1b.

id31

   for the task of recognizing the sentiment of a sentence, use
     * the imdb data-set: --problem=sentiment_imdb

   we suggest to use --model=transformer_encoder here and since it is a
   small data-set, try --hparams_set=transformer_tiny and train for few
   steps (e.g., --train_steps=2000).

id103

   for speech-to-text, we have these data-sets in t2t:
     * librispeech (us english): --problem=librispeech for the whole set
       and --problem=librispeech_clean for a smaller but nicely filtered
       part.
     * mozilla common voice (us english): --problem=common_voice for the
       whole set --problem=common_voice_clean for a quality-checked
       subset.

summarization

   for summarizing longer text into shorter one we have these data-sets:
     * id98/dailymail articles summarized into a few sentences:
       --problem=summarize_id98_dailymail32k

   we suggest to use --model=transformer and
   --hparams_set=transformer_prepend for this task. this yields good id8
   scores.

translation

   there are a number of translation data-sets in t2t:
     * english-german: --problem=translate_ende_wmt32k
     * english-french: --problem=translate_enfr_wmt32k
     * english-czech: --problem=translate_encs_wmt32k
     * english-chinese: --problem=translate_enzh_wmt32k
     * english-vietnamese: --problem=translate_envi_iwslt32k

   you can get translations in the other direction by appending _rev to
   the problem name, e.g., for german-english use
   --problem=translate_ende_wmt32k_rev (note that you still need to
   download the original data with t2t-datagen
   --problem=translate_ende_wmt32k).

   for all translation problems, we suggest to try the transformer model:
   --model=transformer. at first it is best to try the base setting,
   --hparams_set=transformer_base. when trained on 8 gpus for 300k steps
   this should reach a id7 score of about 28 on the english-german
   data-set, which is close to state-of-the art. if training on a single
   gpu, try the --hparams_set=transformer_base_single_gpu setting. for
   very good results or larger data-sets (e.g., for english-french), try
   the big model with --hparams_set=transformer_big.

basics

walkthrough

   here's a walkthrough training a good english-to-german translation
   model using the transformer model from [133]attention is all you need
   on wmt data.
pip install tensor2tensor

# see what problems, models, and hyperparameter sets are available.
# you can easily swap between them (and add new ones).
t2t-trainer --registry_help

problem=translate_ende_wmt32k
model=transformer
hparams=transformer_base_single_gpu

data_dir=$home/t2t_data
tmp_dir=/tmp/t2t_datagen
train_dir=$home/t2t_train/$problem/$model-$hparams

mkdir -p $data_dir $tmp_dir $train_dir

# generate data
t2t-datagen \
  --data_dir=$data_dir \
  --tmp_dir=$tmp_dir \
  --problem=$problem

# train
# *  if you run out of memory, add --hparams='batch_size=1024'.
t2t-trainer \
  --data_dir=$data_dir \
  --problem=$problem \
  --model=$model \
  --hparams_set=$hparams \
  --output_dir=$train_dir

# decode

decode_file=$data_dir/decode_this.txt
echo "hello world" >> $decode_file
echo "goodbye world" >> $decode_file
echo -e 'hallo welt\nauf wiedersehen welt' > ref-translation.de

beam_size=4
alpha=0.6

t2t-decoder \
  --data_dir=$data_dir \
  --problem=$problem \
  --model=$model \
  --hparams_set=$hparams \
  --output_dir=$train_dir \
  --decode_hparams="beam_size=$beam_size,alpha=$alpha" \
  --decode_from_file=$decode_file \
  --decode_to_file=translation.en

# see the translations
cat translation.en

# evaluate the id7 score
# note: report this id7 score in papers, not the internal approx_id7 metric.
t2t-id7 --translation=translation.en --reference=ref-translation.de

installation

# assumes tensorflow or tensorflow-gpu installed
pip install tensor2tensor

# installs with tensorflow-gpu requirement
pip install tensor2tensor[tensorflow_gpu]

# installs with tensorflow (cpu) requirement
pip install tensor2tensor[tensorflow]

   binaries:
# data generator
t2t-datagen

# trainer
t2t-trainer --registry_help

   library usage:
python -c "from tensor2tensor.models.transformer import transformer"

features

     * many state of the art and baseline models are built-in and new
       models can be added easily (open an issue or pull request!).
     * many datasets across modalities - text, audio, image - available
       for generation and use, and new ones can be added easily (open an
       issue or pull request for public datasets!).
     * models can be used with any dataset and input mode (or even
       multiple); all modality-specific processing (e.g. embedding lookups
       for text tokens) is done with bottom and top transformations, which
       are specified per-feature in the model.
     * support for multi-gpu machines and synchronous (1 master, many
       workers) and asynchronous (independent workers synchronizing
       through a parameter server) [134]distributed training.
     * easily swap amongst datasets and models by command-line flag with
       the data generation script t2t-datagen and the training script
       t2t-trainer.
     * train on [135]google cloud ml and [136]cloud tpus.

t2t overview

problems

   problems consist of features such as inputs and targets, and metadata
   such as each feature's modality (e.g. symbol, image, audio) and
   vocabularies. problem features are given by a dataset, which is stored
   as a tfrecord file with tensorflow.example protocol buffers. all
   problems are imported in [137]all_problems.py or are registered with
   @registry.register_problem. run [138]t2t-datagen to see the list of
   available problems and download them.

models

   t2tmodels define the core tensor-to-tensor computation. they apply a
   default transformation to each input and output so that models may deal
   with modality-independent tensors (e.g. embeddings at the input; and a
   linear transform at the output to produce logits for a softmax over
   classes). all models are imported in the [139]models subpackage,
   inherit from [140]t2tmodel, and are registered with
   [141]@registry.register_model.

hyperparameter sets

   hyperparameter sets are encoded in [142]hparams objects, and are
   registered with [143]@registry.register_hparams. every model and
   problem has a hparams. a basic set of hyperparameters are defined in
   [144]common_hparams.py and hyperparameter set functions can compose
   other hyperparameter set functions.

trainer

   the trainer binary is the entrypoint for training, evaluation, and
   id136. users can easily switch between problems, models, and
   hyperparameter sets by using the --model, --problem, and --hparams_set
   flags. specific hyperparameters can be overridden with the --hparams
   flag. --schedule and related flags control local and distributed
   training/evaluation ([145]distributed training documentation).

adding your own components

   t2t's components are registered using a central registration mechanism
   that enables easily adding new ones and easily swapping amongst them by
   command-line flag. you can add your own components without editing the
   t2t codebase by specifying the --t2t_usr_dir flag in t2t-trainer.

   you can do so for models, hyperparameter sets, modalities, and
   problems. please do submit a pull request if your component might be
   useful to others.

   see the [146]example_usr_dir for an example user directory.

adding a dataset

   to add a new dataset, subclass [147]problem and register it with
   @registry.register_problem. see [148]translateendewmt8k for an example.
   also see the [149]data generators readme.

run on floydhub

   [150]run on floydhub

   click this button to open a [151]workspace on [152]floydhub. you can
   use the workspace to develop and test your code on a fully configured
   cloud gpu machine.

   tensor2tensor comes preinstalled in the environment, you can simply
   open a [153]terminal and run your code.
# test the quick-start on a workspace's terminal with this command
t2t-trainer \
  --generate_data \
  --data_dir=./t2t_data \
  --output_dir=./t2t_train/mnist \
  --problem=image_mnist \
  --model=shake_shake \
  --hparams_set=shake_shake_quick \
  --train_steps=1000 \
  --eval_steps=100

   note: ensure compliance with the floydhub [154]terms of service.

papers

   when referencing tensor2tensor, please cite [155]this paper.
@article{tensor2tensor,
  author    = {ashish vaswani and samy bengio and eugene brevdo and
    francois chollet and aidan n. gomez and stephan gouws and llion jones and
    \l{}ukasz kaiser and nal kalchbrenner and niki parmar and ryan sepassi and
    noam shazeer and jakob uszkoreit},
  title     = {tensor2tensor for id4},
  journal   = {corr},
  volume    = {abs/1803.07416},
  year      = {2018},
  url       = {http://arxiv.org/abs/1803.07416},
}

   tensor2tensor was used to develop a number of state-of-the-art models
   and deep learning methods. here we list some papers that were based on
   t2t from the start and benefited from its features and architecture in
   ways described in the [156]google research blog post introducing t2t.
     * [157]attention is all you need
     * [158]depthwise separable convolutions for neural machine
       translation
     * [159]one model to learn them all
     * [160]discrete autoencoders for sequence models
     * [161]generating wikipedia by summarizing long sequences
     * [162]image transformer
     * [163]training tips for the transformer model
     * [164]self-attention with relative position representations
     * [165]fast decoding in sequence models using discrete latent
       variables
     * [166]adafactor: adaptive learning rates with sublinear memory cost
     * [167]universal transformers
     * [168]attending to mathematical language with transformers
     * [169]the evolved transformer
     * [170]model-based id23 for atari
     * [171]videoflow: a flow-based generative model for video

   note: this is not an official google product.

     *    2019 github, inc.
     * [172]terms
     * [173]privacy
     * [174]security
     * [175]status
     * [176]help

     * [177]contact github
     * [178]pricing
     * [179]api
     * [180]training
     * [181]blog
     * [182]about

   (button) you can   t perform that action at this time.

   you signed in with another tab or window. [183]reload to refresh your
   session. you signed out in another tab or window. [184]reload to
   refresh your session.

   (button)

references

   visible links
   1. https://github.com/opensearch.xml
   2. https://github.com/tensorflow/tensor2tensor/commits/master.atom
   3. https://github.com/tensorflow/tensor2tensor#start-of-content
   4. https://github.com/features
   5. https://github.com/features/code-review/
   6. https://github.com/features/project-management/
   7. https://github.com/features/integrations
   8. https://github.com/features/actions
   9. https://github.com/features#team-management
  10. https://github.com/features#social-coding
  11. https://github.com/features#documentation
  12. https://github.com/features#code-hosting
  13. https://github.com/customer-stories
  14. https://github.com/security
  15. https://github.com/enterprise
  16. https://github.com/explore
  17. https://github.com/topics
  18. https://github.com/collections
  19. https://github.com/trending
  20. https://lab.github.com/
  21. https://opensource.guide/
  22. https://github.com/events
  23. https://github.community/
  24. https://education.github.com/
  25. https://github.com/marketplace
  26. https://github.com/pricing
  27. https://github.com/pricing#feature-comparison
  28. https://enterprise.github.com/contact
  29. https://github.com/nonprofit
  30. https://education.github.com/
  31. https://github.com/login?return_to=/tensorflow/tensor2tensor
  32. https://github.com/join
  33. https://github.com/login?return_to=/tensorflow/tensor2tensor
  34. https://github.com/tensorflow/tensor2tensor/watchers
  35. https://github.com/login?return_to=/tensorflow/tensor2tensor
  36. https://github.com/tensorflow/tensor2tensor/stargazers
  37. https://github.com/login?return_to=/tensorflow/tensor2tensor
  38. https://github.com/tensorflow/tensor2tensor/network/members
  39. https://github.com/tensorflow
  40. https://github.com/tensorflow/tensor2tensor
  41. https://github.com/tensorflow/tensor2tensor
  42. https://github.com/tensorflow/tensor2tensor/issues
  43. https://github.com/tensorflow/tensor2tensor/pulls
  44. https://github.com/tensorflow/tensor2tensor/pulse
  45. https://github.com/join?source=prompt-code
  46. https://github.com/topics/machine-learning
  47. https://github.com/topics/machine-translation
  48. https://github.com/topics/deep-learning
  49. https://github.com/topics/reinforcement-learning
  50. https://github.com/topics/tpu
  51. https://github.com/tensorflow/tensor2tensor/commits/master
  52. https://github.com/tensorflow/tensor2tensor/branches
  53. https://github.com/tensorflow/tensor2tensor/releases
  54. https://github.com/tensorflow/tensor2tensor/graphs/contributors
  55. https://github.com/tensorflow/tensor2tensor/blob/master/license
  56. https://github.com/tensorflow/tensor2tensor/search?l=python
  57. https://github.com/tensorflow/tensor2tensor/search?l=jupyter-notebook
  58. https://github.com/tensorflow/tensor2tensor/find/master
  59. https://github.com/tensorflow/tensor2tensor/archive/master.zip
  60. https://github.com/login?return_to=https://github.com/tensorflow/tensor2tensor
  61. https://github.com/join?return_to=/tensorflow/tensor2tensor
  62. https://desktop.github.com/
  63. https://desktop.github.com/
  64. https://developer.apple.com/xcode/
  65. https://visualstudio.github.com/
  66. https://github.com/dustinvtran
  67. https://github.com/tensorflow/tensor2tensor/commits?author=dustinvtran
  68. https://github.com/tensorflow/tensor2tensor/commit/3562111a30d3ede91345e277a3a8566ca0300fb6
  69. https://github.com/tensorflow/tensor2tensor/commit/3562111a30d3ede91345e277a3a8566ca0300fb6
  70. https://github.com/tensorflow/tensor2tensor/tree/3562111a30d3ede91345e277a3a8566ca0300fb6
  71. https://github.com/tensorflow/tensor2tensor/tree/master/docs
  72. https://github.com/tensorflow/tensor2tensor/commit/b6a9bbbd7c04e69ccfbf8f8d9c4b5b8947729bea
  73. https://github.com/tensorflow/tensor2tensor/tree/master/oss_scripts
  74. https://github.com/tensorflow/tensor2tensor/tree/master/tensor2tensor
  75. https://github.com/tensorflow/tensor2tensor/blob/master/.gitignore
  76. https://github.com/tensorflow/tensor2tensor/commit/8cf5fa411f391fddb15003dd362a5f438178dd16
  77. https://github.com/tensorflow/tensor2tensor/blob/master/.travis.yml
  78. https://github.com/tensorflow/tensor2tensor/blob/master/authors
  79. https://github.com/tensorflow/tensor2tensor/blob/master/contributing.md
  80. https://github.com/tensorflow/tensor2tensor/blob/master/issue_template.md
  81. https://github.com/tensorflow/tensor2tensor/blob/master/license
  82. https://github.com/tensorflow/tensor2tensor/commit/3d9c62f2aca9492db5c22676416974005b9dcbae
  83. https://github.com/tensorflow/tensor2tensor/blob/master/readme.md
  84. https://github.com/tensorflow/tensor2tensor/blob/master/floyd.yml
  85. https://github.com/tensorflow/tensor2tensor/blob/master/floyd_requirements.txt
  86. https://github.com/tensorflow/tensor2tensor/commit/b20f0073f09ece90b822628a43ad5299b4ecc445
  87. https://github.com/tensorflow/tensor2tensor/pull/961
  88. https://github.com/tensorflow/tensor2tensor/blob/master/pylintrc
  89. https://github.com/tensorflow/tensor2tensor/blob/master/setup.py
  90. https://badge.fury.io/py/tensor2tensor
  91. https://github.com/tensorflow/tensor2tensor/issues
  92. https://github.com/tensorflow/tensor2tensor/blob/master/contributing.md
  93. https://gitter.im/tensor2tensor/lobby
  94. https://opensource.org/licenses/apache-2.0
  95. https://travis-ci.org/tensorflow/tensor2tensor
  96. https://floydhub.com/run
  97. https://github.com/tensorflow/tensor2tensor
  98. https://github.com/tensorflow/tensor2tensor
  99. https://research.googleblog.com/2017/06/accelerating-deep-learning-research.html
 100. https://research.google.com/teams/brain/
 101. https://github.com/tensorflow/tensor2tensor/issues
 102. https://github.com/tensorflow/tensor2tensor/blob/master/contributing.md
 103. https://gitter.im/tensor2tensor/lobby
 104. https://groups.google.com/forum/#!forum/tensor2tensor
 105. https://colab.research.google.com/github/tensorflow/tensor2tensor/blob/master/tensor2tensor/notebooks/hello_t2t.ipynb
 106. https://github.com/tensorflow/tensor2tensor#suggested-datasets-and-models
 107. https://github.com/tensorflow/tensor2tensor#mathematical-language-understanding
 108. https://github.com/tensorflow/tensor2tensor#story-question-and-answer
 109. https://github.com/tensorflow/tensor2tensor#image-classification
 110. https://github.com/tensorflow/tensor2tensor#image-generation
 111. https://github.com/tensorflow/tensor2tensor#language-modeling
 112. https://github.com/tensorflow/tensor2tensor#sentiment-analysis
 113. https://github.com/tensorflow/tensor2tensor#speech-recognition
 114. https://github.com/tensorflow/tensor2tensor#summarization
 115. https://github.com/tensorflow/tensor2tensor#translation
 116. https://github.com/tensorflow/tensor2tensor#basics
 117. https://github.com/tensorflow/tensor2tensor#walkthrough
 118. https://github.com/tensorflow/tensor2tensor#installation
 119. https://github.com/tensorflow/tensor2tensor#features
 120. https://github.com/tensorflow/tensor2tensor#t2t-overview
 121. https://github.com/tensorflow/tensor2tensor#datasets
 122. https://github.com/tensorflow/tensor2tensor#problems-and-modalities
 123. https://github.com/tensorflow/tensor2tensor#models
 124. https://github.com/tensorflow/tensor2tensor#hyperparameter-sets
 125. https://github.com/tensorflow/tensor2tensor#trainer
 126. https://github.com/tensorflow/tensor2tensor#adding-your-own-components
 127. https://github.com/tensorflow/tensor2tensor#adding-a-dataset
 128. https://github.com/tensorflow/tensor2tensor#papers
 129. https://github.com/tensorflow/tensor2tensor#run-on-floydhub
 130. https://art.wangperawong.com/mathematical_language_understanding_train.tar.gz
 131. https://arxiv.org/abs/1812.02825
 132. https://research.fb.com/downloads/babi/
 133. https://arxiv.org/abs/1706.03762
 134. https://tensorflow.github.io/tensor2tensor/distributed_training.html
 135. https://tensorflow.github.io/tensor2tensor/cloud_id113ngine.html
 136. https://tensorflow.github.io/tensor2tensor/cloud_tpu.html
 137. https://github.com/tensorflow/tensor2tensor/tree/master/tensor2tensor/data_generators/all_problems.py
 138. https://github.com/tensorflow/tensor2tensor/tree/master/tensor2tensor/bin/t2t-datagen
 139. https://github.com/tensorflow/tensor2tensor/tree/master/tensor2tensor/models/__init__.py
 140. https://github.com/tensorflow/tensor2tensor/tree/master/tensor2tensor/utils/t2t_model.py
 141. https://github.com/tensorflow/tensor2tensor/tree/master/tensor2tensor/utils/registry.py
 142. https://github.com/tensorflow/tensor2tensor/tree/master/tensor2tensor/utils/hparam.py
 143. https://github.com/tensorflow/tensor2tensor/tree/master/tensor2tensor/utils/registry.py
 144. https://github.com/tensorflow/tensor2tensor/tree/master/tensor2tensor/layers/common_hparams.py
 145. https://github.com/tensorflow/tensor2tensor/tree/master/docs/distributed_training.md
 146. https://github.com/tensorflow/tensor2tensor/tree/master/tensor2tensor/test_data/example_usr_dir
 147. https://github.com/tensorflow/tensor2tensor/tree/master/tensor2tensor/data_generators/problem.py
 148. https://github.com/tensorflow/tensor2tensor/tree/master/tensor2tensor/data_generators/translate_ende.py
 149. https://github.com/tensorflow/tensor2tensor/tree/master/tensor2tensor/data_generators/readme.md
 150. https://floydhub.com/run
 151. https://blog.floydhub.com/workspaces/
 152. https://www.floydhub.com/?utm_medium=readme&utm_source=tensor2tensor&utm_campaign=jul_2018
 153. https://docs.floydhub.com/guides/workspace/#using-terminal
 154. https://www.floydhub.com/about/terms
 155. https://arxiv.org/abs/1803.07416
 156. https://research.googleblog.com/2017/06/accelerating-deep-learning-research.html
 157. https://arxiv.org/abs/1706.03762
 158. https://arxiv.org/abs/1706.03059
 159. https://arxiv.org/abs/1706.05137
 160. https://arxiv.org/abs/1801.09797
 161. https://arxiv.org/abs/1801.10198
 162. https://arxiv.org/abs/1802.05751
 163. https://arxiv.org/abs/1804.00247
 164. https://arxiv.org/abs/1803.02155
 165. https://arxiv.org/abs/1803.03382
 166. https://arxiv.org/abs/1804.04235
 167. https://arxiv.org/abs/1807.03819
 168. https://arxiv.org/abs/1812.02825
 169. https://arxiv.org/abs/1901.11117
 170. https://arxiv.org/abs/1903.00374
 171. https://arxiv.org/abs/1903.01434
 172. https://github.com/site/terms
 173. https://github.com/site/privacy
 174. https://github.com/security
 175. https://githubstatus.com/
 176. https://help.github.com/
 177. https://github.com/contact
 178. https://github.com/pricing
 179. https://developer.github.com/
 180. https://training.github.com/
 181. https://github.blog/
 182. https://github.com/about
 183. https://github.com/tensorflow/tensor2tensor
 184. https://github.com/tensorflow/tensor2tensor

   hidden links:
 186. https://github.com/
 187. https://github.com/tensorflow/tensor2tensor
 188. https://github.com/tensorflow/tensor2tensor
 189. https://github.com/tensorflow/tensor2tensor
 190. https://help.github.com/articles/which-remote-url-should-i-use
 191. https://github.com/tensorflow/tensor2tensor#tensor2tensor
 192. https://github.com/tensorflow/tensor2tensor#quick-start
 193. https://github.com/tensorflow/tensor2tensor#contents
 194. https://github.com/tensorflow/tensor2tensor#suggested-datasets-and-models
 195. https://github.com/tensorflow/tensor2tensor#mathematical-language-understanding
 196. https://github.com/tensorflow/tensor2tensor#story-question-and-answer
 197. https://github.com/tensorflow/tensor2tensor#image-classification
 198. https://github.com/tensorflow/tensor2tensor#image-generation
 199. https://github.com/tensorflow/tensor2tensor#language-modeling
 200. https://github.com/tensorflow/tensor2tensor#sentiment-analysis
 201. https://github.com/tensorflow/tensor2tensor#speech-recognition
 202. https://github.com/tensorflow/tensor2tensor#summarization
 203. https://github.com/tensorflow/tensor2tensor#translation
 204. https://github.com/tensorflow/tensor2tensor#basics
 205. https://github.com/tensorflow/tensor2tensor#walkthrough
 206. https://github.com/tensorflow/tensor2tensor#installation
 207. https://github.com/tensorflow/tensor2tensor#features
 208. https://github.com/tensorflow/tensor2tensor#t2t-overview
 209. https://github.com/tensorflow/tensor2tensor#problems
 210. https://github.com/tensorflow/tensor2tensor#models
 211. https://github.com/tensorflow/tensor2tensor#hyperparameter-sets
 212. https://github.com/tensorflow/tensor2tensor#trainer
 213. https://github.com/tensorflow/tensor2tensor#adding-your-own-components
 214. https://github.com/tensorflow/tensor2tensor#adding-a-dataset
 215. https://github.com/tensorflow/tensor2tensor#run-on-floydhub
 216. https://github.com/tensorflow/tensor2tensor#papers
 217. https://github.com/
