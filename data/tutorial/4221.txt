   #[1]the clever machine    feed [2]the clever machine    comments feed
   [3]the clever machine    a brief introduction to markov chains comments
   feed [4]monte carlo approximations [5]mcmc: the metropolis sampler
   [6]alternate [7]alternate [8]the clever machine [9]wordpress.com

     * [10]skip to navigation
     * [11]skip to main content
     * [12]skip to primary sidebar
     * [13]skip to secondary sidebar
     * [14]skip to footer

   [15]

the clever machine

topics in computational neuroscience & machine learning

     * [16]home
     * [17]about the author
     * [18]about the clever machine
     * [19]blog interface

   [20]    monte carlo approximations
   [21]mcmc: the metropolis sampler    

a brief introduction to markov chains

   [22]sep 24

   posted by [23]dustinstansbury

   markov chains are an essential component of id115
   (mcmc) techniques. under mcmc, the markov chain is used to sample from
   some target distribution. to get a better understanding of what a
   markov chain is, and further, how it can be used to sample form a
   distribution, this post introduces and applies a few basic concepts.

   a markov chain is a stochastic process that operates sequentially (e.g.
   temporally), transitioning from one state to another within an allowed
   set of states.^   

   x^{(0)} \rightarrow x^{(1)} \rightarrow x^{(2)} \dots \rightarrow
   x^{(t)} \rightarrow \dots

   a markov chain is defined by three elements:
    1. a state space x , which is a set of values that the chain is
       allowed to take
    2. a transition operator p(x^{(t+1)} | x^{(t)}) that defines  the
       id203 of moving from state x^{(t)} to  x^{(t+1)} .
    3. an initial condition distribution \pi^{(0)} which defines the
       id203 of being in any one of the possible states at the
       initial iteration t = 0 .

   the markov chain starts at some initial state, which is sampled from
   \pi^{(0)} , then transitions from one state to another according to the
   transition operator p(x^{(t+1)} | x^{(t)}) .

   a markov chain is called memoryless if the next state only depends on
   the current state and not on any of the states previous to the current:

   p(x^{(t+1)}|x^{(t)},x^{(t-1)},...x^{(0)}) = p(x^{(t+1)}|x^{(t)})

   (this memoryless property is formally know as the markov property).

   if the transition operator for a markov chain does not change across
   transitions, the markov chain is called time homogenous.  a nice
   property of time homogenous markov chains is that as the chain runs for
   a long time and t \rightarrow \infty , the chain will reach an
   equilibrium that is called the chain   s stationary distribution:

   p(x^{(t+1)} | x^{(t)}) = p(x^{(t)} | x^{(t-1)})

   we   ll see later how the stationary distribution of a markov chain is
   important for sampling from id203 distributions, a technique that
   is at the heart of id115 (mcmc) methods.

finite state-space (time homogenous) markov chain

   if the state space of a markov chain takes on a finite number of
   distinct values, and it is time homogenous, then the transition
   operator can be defined by a matrix p , where the entries of p are:

   p_{ij} = p(x^{(t+1)} = j | x^{(t)} = i)

   this means that if the chain is currently in the i -th state, the
   transition operator assigns the id203 of moving to the   j -th
   state by the entries of i -th row of p (i.e.  each row of p defines a
   id155 distribution on the state space). let   s take a
   look at a finite state-space markov chain in action with a simple
   example.

example: predicting the weather with a finite state-space markov chain

   in berkeley, ca, there are (literally) only 3 types of weather: sunny,
   foggy, or rainy (this is analogous to a state-space that takes on three
   discrete values). the weather patterns are very stable there, so a
   berkeley weatherman can easily predict the weather next week based on
   the weather today with the following transition rules:

   if it is sunny today, then
     * it is highly likely that it will be sunny next week
          + p(x^{(week)}=sunny | x^{(today)}=sunny)=0.8 ,
     * it is very unlikely that it will be raining next week
          + p(x^{(week)}=rainy | x^{(today)}=sunny)=0.05
     * and somewhat likely that it will foggy next week
          + p(x^{(week)}=foggy | x^{(today)}=sunny)=0.15

   if it is foggy today then
     * it is somewhat likely that it will be sunny next week
          + p(x^{(week)}=sunny | x^{(today)}=foggy)=0.4
     * but slightly less likely that it will be foggy next week
          + p(x^{(week)}=foggy | x^{(today)}=foggy)=0.5 ,
     * and fairly unlikely that it will be raining next week.
          + p(x^{(week)}=rainy | x^{(today)}=foggy)=0.1 ,

   if it is rainy today then
     * it is unlikely that it will be sunny next week
          + p(x^{(week)}=sunny | x^{(today)}=rainy)=0.1 ,
     * it is somewhat likely that it will be foggy next week
          + p(x^{(week)}=foggy | x^{(today)}=rainy)=0.3 ,
     * and it is fairly likely that it will be rainy next week
          + p(x^{(week)}=rainy | x^{(today)}=rainy)=0.6 ,

   all of these transition rules can be instantiated in a single 3 x 3
   transition operator matrix:

   p = \begin{bmatrix} 0.8 & 0.15 & 0.05\\ 0.4 & 0.5 & 0.1\\ 0.1& 0.3 &
   0.6 \end{bmatrix}

   where each row of p corresponds to the weather at iteration t (today),
   and each column corresponds to the weather the next week. let   s say
   that it is rainy today, what is the id203 it will be sunny next
   week, in two weeks, or in 6 months? we can answer these questions by
   running a markov chain from the initial state of    rainy,    transitioning
   according to p . the following chunk of matlab code runs the markov
   chain.
% finite state-space markov chain example

% transition operator
%     s  f  r
%     u  o  a
%     n  g  i
%     n  g  n
%     y  y  y
p = [.8 .15 .05;  % sunny
     .4 .5  .1;   % foggy
     .1 .3  .6];  % rainy
nweeks = 25

% initial state is rainy
x(1,:) = [0 0 1];

% run markov chain
for ib = 2:nweeks
    x(ib,:) = x(ib-1,:)*p; % transition
end

% display
figure; hold on
h(1) = plot(1:nweeks,x(:,1),'r','linewidth',2);
h(2) = plot(1:nweeks,x(:,2),'k','linewidth',2);
h(3) = plot(1:nweeks,x(:,3),'b','linewidth',2);
h(4) = plot([15 15],[0 1],'g--','linewidth',2);
hold off
legend(h, {'sunny','foggy','rainy','burn in'});
xlabel('week')
ylabel('p(weather)')
xlim([1,nweeks]);
ylim([0 1]);

% predictions
fprintf('\np(weather) in 1 week -->'), disp(x(2,:))
fprintf('\np(weather) in 2 weeks -->'), disp(x(3,:))
fprintf('\np(weather) in 6 months -->'), disp(x(25,:))

   finite state-space markov chain for predicting the weather

   here we see that at week 1 the id203 of sunny weather is 0.1. the
   next week, the id203 of sunny weather is 0.26, and in 6 months,
   there is a 60% chance that it will be sunny. also note that after
   approximately 15 weeks the markov chain has reached the
   equilibrium/stationary distribution and, chances are, the weather will
   be sunny. this 15-week period is what is known as the burn in period
   for the markov chain, and is the number of transitions it takes the
   chain to move from the initial conditions to the stationary
   distribution.

   a cool thing about finite state-space time-homogeneous markov chain is
   that it is not necessary  to run the chain sequentially through all
   iterations in order to predict a state in the future. instead we can
   predict by first raising the transition operator to the t -th power,
   where t is the iteration at which we want to predict, then multiplying
   the result by the distribution over the initial state, \pi^{(0)} . for
   instance, to predict the id203 of the weather in 2 weeks, knowing
   that it is rainy today (i.e. \pi^{(0)} = [0,0,1] ):

   p(x^{(week2)}) = \pi^{(0)}p^2 = [0.26, 0.345, 0.395]

   and in six months:

   p(x^{(week24)}) = \pi^{(0)}p^{24} = [0.596, 0.263, 0.140]

   these are the same results we get by running the markov chain
   sequentially through each number of transitions. therefore we can
   calculate an approximation to the stationary distribution from p by
   setting t to a large number. it turns out that it is also possible to
   analytically derive the stationary distribution from p (hint: think
   about the properties of eigenvectors).

continuous state-space markov chains

   a markov chain can also have a continuous state space that exists in
   the real numbers x \in \mathbb{r}^n . in this case the transition
   operator cannot be instantiated simply as a matrix, but is instead some
   continuous function on the real numbers. note that the continuous
   state-space markov chain also has a burn in period and a stationary
   distribution. however, the stationary distribution will also be over a
   continuous set of variables. to get a better understanding of the
   workings of a continuous state-space markov chain, let   s look at a
   simple example.

example: sampling from a continuous distribution using continuous state-space
markov chains

   we can use the stationary distribution of a continuous state-space
   markov chain in order to sample from a continuous id203
   distribution: we  run a markov chain for a sufficient amount of time so
   that it has reached its stationary distribution, then keep the states
   that the chain visits as samples from that stationary distribution.

   in the following example we define a continuous state-space markov
   chain. the transition operator is a normal distribution with unit
   variance and a mean that is half the distance between zero and the
   previous state, and the distribution over initial conditions is a
   normal distribution with zero mean and unit variance.

   to ensure that the chain has moved sufficiently far from the initial
   conditions and that we are sampling  from the chain   s stationary
   distribution,  we will choose to throw away the first 50 burn in states
   of the chain. we can also run multiple chains simultaneously in order
   to sample the stationary distribution more densely. here we choose to
   run 5 chains simultaneously.
% example of continuous state-space markov chain

% initialize
randn('seed',12345)
nburnin = 50; % # burnin
nchains = 5;  % # markov chains

% define transition operator
p = inline('normrnd(.5*x,1,1,nchains)','x','nchains');
ntransitions = 1000;
x = zeros(ntransitions,nchains);
x(1,:) = randn(1,nchains);

% run the chains
for it = 2:ntransitions
    x(it,:) = p(x(it-1),nchains);
end

% display burnin
figure
subplot(221); plot(x(1:100,:)); hold on;
minn = min(x(:));
maxx = max(x(:));
l = line([nburnin nburnin],[minn maxx],'color','k','linewidth',2);
ylim([minn maxx])
legend(l,'~burn-in','location','southeast')
title('first 100 samples'); hold off

% display entire markov chain
subplot(223); plot(x);hold on;
l = line([nburnin nburnin],[minn maxx],'color','k','linewidth',2);
legend(l,'~burn-in','location','southeast')
title('entire chain');

% display samples from stationary distribution
samples = x(nburnin+1:end,:);
subplot(122);
[counts,bins] = hist(samples(:),100); colormap hot
b = bar(bins,counts);
legend(b,sprintf('markov chain\nsamples'));
title(['\mu=',num2str(mean(samples(:))),' \sigma=',num2str(var(samples(:)))])

   sampling from the stationary distribution of a continuous state-space
   markov chain

   in the upper left panel of the code output we see a close up of the
   first 100 of the 1000 transitions made by the 5 simultaneous markov
   chains; the burn in cutoff is marked by the black line. in the lower
   left panel we see the entire sequence of transitions for the markov
   chains. in the right panel, we can tell from the sampled states that
   the stationary distribution for this chain is a normal distribution,
   with mean equal to zero, and a variance equal to 1.3.

wrapping up

   in the previous example we were able to deduce the stationary
   distribution of the markov chain by looking at the samples generated
   from the chain after the burn in period. however, in order to use
   markov chains to sample from a specific target distribution, we have to
   design the transition operator such that the resulting chain reaches a
   stationary distribution that matches the target distribution. this is
   where mcmc methods like the metropolis sampler, the metropolis-hastings
   sampler, and the gibbs sampler come to rescue. we will discuss each of
   these markov-chain-based sampling methods separately in later posts.

   ^    on notation:
     * here we use the shorthand notation p(x) to correspond to p(x = x) ,
       for some random variable x
     * a superscript in parentheses is an index into an iteration or point
       in time, not a power

   advertisements

share this:

     * [24]twitter
     * [25]facebook
     *

like this:

   like loading...

related

about dustinstansbury

   i recently received my phd from uc berkeley where i studied
   computational neuroscience and machine learning.
   [26]view all posts by dustinstansbury   

   posted on september 24, 2012, in [27]algorithms, [28]density
   estimation, [29]sampling methods, [30]statistics and tagged
   [31]continuous state-space markov chain, [32]finite state-space markov
   chain, [33]markov chain, [34]markov property, [35]state space,
   [36]stationary distribution, [37]time homogeneous markov chain,
   [38]transition operator. bookmark the [39]permalink. [40]4 comments.
   [41]    monte carlo approximations
   [42]mcmc: the metropolis sampler    
     * [43]leave a comment
     * [44]trackbacks 3
     * [45]comments 1

    1. steven | [46]july 5, 2018 at 5:01 pm
       hello, dustinstansbury. thanks for a very informative post on mc.
       could you help in simulating a 3-state finite mc characterized by a
       poisson arrival process? thank you.
       [47]reply

    1. pingback: [48]mcmc: the metropolis sampler    the clever machine
    2. pingback: [49]mcmc: the metropolis-hastings sampler    the clever
       machine
    3. pingback: [50]a gentle introduction to id115
       (mcmc)    the clever machine

leave a reply [51]cancel reply

   enter your comment here...

   ____________________________________________________________
   ____________________________________________________________
   ____________________________________________________________
   ____________________________________________________________

   fill in your details below or click an icon to log in:
     *
     *
     *

       iframe: [52]googleplus-sign-in

     *
     *

   [53]gravatar
   email (required) (address never made public)
   ____________________
   name (required)
   ____________________
   website
   ____________________
   wordpress.com logo

   you are commenting using your wordpress.com account. ( [54]log out /
   [55]change )
   google photo

   you are commenting using your google account. ( [56]log out /
   [57]change )
   twitter picture

   you are commenting using your twitter account. ( [58]log out /
   [59]change )
   facebook photo

   you are commenting using your facebook account. ( [60]log out /
   [61]change )
   [62]cancel

   connecting to %s

   [ ] notify me of new comments via email.

   post comment

     * search for: ____________________ go
     * follow theclevermachine
       to receive update notifications, enter your email here
       ____________________
       (button) follow
     * categories
       [63]algorithms [64]classification [65]id174
       [66]density estimation [67]derivations [68]id171
       [69]fmri [70]id119 [71]latex [72]machine learning
       [73]matlab [74]maximum likelihood [75]mcmc [76]neural networks
       [77]neuroscience [78]optimization [79]proofs [80]regression
       [81]sampling [82]sampling methods [83]simulations [84]statistics
       [85]theory [86]tips & tricks [87]uncategorized
     * recent posts
          + [88]derivation: maximum likelihood for id82s
          + [89]a gentle introduction to id158s
          + [90]derivation: derivatives for common neural network
            id180
          + [91]derivation: error id26 & id119 for
            neural networks
          + [92]model selection: underfitting, overfitting, and the
            id160
          + [93]supplemental proof 1
          + [94]the statistical whitening transform
          + [95]covariance matrices and data distributions
          + [96]fmri in neuroscience: efficiency of event-related
            experiment designs
          + [97]derivation: the covariance matrix of an ols estimator (and
            applications to gls)
     * archives
          + [98]september 2014
          + [99]april 2013
          + [100]march 2013
          + [101]january 2013
          + [102]december 2012
          + [103]november 2012
          + [104]october 2012
          + [105]september 2012
          + [106]march 2012
          + [107]february 2012
          + [108]january 2012
     * meta
          + [109]register
          + [110]log in
          + [111]entries rss
          + [112]comments rss
          + [113]wordpress.com
       advertisements

   [114]create a free website or blog at wordpress.com.


   ____________________________________________________________
   ____________________________________________________________
   ____________________________________________________________
   ____________________________________________________________
   post to
   [115]cancel reblog post

   close and accept privacy & cookies: this site uses cookies. by
   continuing to use this website, you agree to their use.
   to find out more, including how to control cookies, see here:
   [116]cookie policy

   iframe: [117]likes-master

   %d bloggers like this:

references

   visible links
   1. https://theclevermachine.wordpress.com/feed/
   2. https://theclevermachine.wordpress.com/comments/feed/
   3. https://theclevermachine.wordpress.com/2012/09/24/a-brief-introduction-to-markov-chains/feed/
   4. https://theclevermachine.wordpress.com/2012/09/22/monte-carlo-approximations/
   5. https://theclevermachine.wordpress.com/2012/10/05/mcmc-the-metropolis-sampler/
   6. https://public-api.wordpress.com/oembed/?format=json&url=https://theclevermachine.wordpress.com/2012/09/24/a-brief-introduction-to-markov-chains/&for=wpcom-auto-discovery
   7. https://public-api.wordpress.com/oembed/?format=xml&url=https://theclevermachine.wordpress.com/2012/09/24/a-brief-introduction-to-markov-chains/&for=wpcom-auto-discovery
   8. https://theclevermachine.wordpress.com/osd.xml
   9. https://s1.wp.com/opensearch.xml
  10. https://theclevermachine.wordpress.com/2012/09/24/a-brief-introduction-to-markov-chains/#access
  11. https://theclevermachine.wordpress.com/2012/09/24/a-brief-introduction-to-markov-chains/#main
  12. https://theclevermachine.wordpress.com/2012/09/24/a-brief-introduction-to-markov-chains/#sidebar
  13. https://theclevermachine.wordpress.com/2012/09/24/a-brief-introduction-to-markov-chains/#sidebar2
  14. https://theclevermachine.wordpress.com/2012/09/24/a-brief-introduction-to-markov-chains/#footer
  15. https://theclevermachine.wordpress.com/
  16. https://theclevermachine.wordpress.com/
  17. https://theclevermachine.wordpress.com/about-me/
  18. https://theclevermachine.wordpress.com/about-theclevermachine/
  19. https://theclevermachine.wordpress.com/interact/
  20. https://theclevermachine.wordpress.com/2012/09/22/monte-carlo-approximations/
  21. https://theclevermachine.wordpress.com/2012/10/05/mcmc-the-metropolis-sampler/
  22. https://theclevermachine.wordpress.com/2012/09/24/a-brief-introduction-to-markov-chains/
  23. https://theclevermachine.wordpress.com/author/dustinstansbury/
  24. https://theclevermachine.wordpress.com/2012/09/24/a-brief-introduction-to-markov-chains/?share=twitter
  25. https://theclevermachine.wordpress.com/2012/09/24/a-brief-introduction-to-markov-chains/?share=facebook
  26. https://theclevermachine.wordpress.com/author/dustinstansbury/
  27. https://theclevermachine.wordpress.com/category/algorithms/
  28. https://theclevermachine.wordpress.com/category/algorithms/density-estimation/
  29. https://theclevermachine.wordpress.com/category/sampling-methods/
  30. https://theclevermachine.wordpress.com/category/statistics/
  31. https://theclevermachine.wordpress.com/tag/continuous-state-space-markov-chain/
  32. https://theclevermachine.wordpress.com/tag/finite-state-space-markov-chain/
  33. https://theclevermachine.wordpress.com/tag/markov-chain/
  34. https://theclevermachine.wordpress.com/tag/markov-property/
  35. https://theclevermachine.wordpress.com/tag/state-space/
  36. https://theclevermachine.wordpress.com/tag/stationary-distribution/
  37. https://theclevermachine.wordpress.com/tag/time-homogeneous-markov-chain/
  38. https://theclevermachine.wordpress.com/tag/transition-operator/
  39. https://theclevermachine.wordpress.com/2012/09/24/a-brief-introduction-to-markov-chains/
  40. https://theclevermachine.wordpress.com/2012/09/24/a-brief-introduction-to-markov-chains/#comments
  41. https://theclevermachine.wordpress.com/2012/09/22/monte-carlo-approximations/
  42. https://theclevermachine.wordpress.com/2012/10/05/mcmc-the-metropolis-sampler/
  43. https://theclevermachine.wordpress.com/2012/09/24/a-brief-introduction-to-markov-chains/#respond
  44. https://theclevermachine.wordpress.com/2012/09/24/a-brief-introduction-to-markov-chains/#trackbacks
  45. https://theclevermachine.wordpress.com/2012/09/24/a-brief-introduction-to-markov-chains/#comments
  46. https://theclevermachine.wordpress.com/2012/09/24/a-brief-introduction-to-markov-chains/#comment-1439
  47. https://theclevermachine.wordpress.com/2012/09/24/a-brief-introduction-to-markov-chains/?replytocom=1439#respond
  48. https://theclevermachine.wordpress.com/2012/10/05/mcmc-the-metropolis-sampler/
  49. https://theclevermachine.wordpress.com/2012/10/20/mcmc-the-metropolis-hastings-sampler/
  50. https://theclevermachine.wordpress.com/2012/11/19/a-gentle-introduction-to-markov-chain-monte-carlo-mcmc/
  51. https://theclevermachine.wordpress.com/2012/09/24/a-brief-introduction-to-markov-chains/#respond
  52. https://public-api.wordpress.com/connect/?googleplus-sign-in=https://theclevermachine.wordpress.com&color_scheme=light
  53. https://gravatar.com/site/signup/
  54. javascript:highlandercomments.doexternallogout( 'wordpress' );
  55. https://theclevermachine.wordpress.com/2012/09/24/a-brief-introduction-to-markov-chains/
  56. javascript:highlandercomments.doexternallogout( 'googleplus' );
  57. https://theclevermachine.wordpress.com/2012/09/24/a-brief-introduction-to-markov-chains/
  58. javascript:highlandercomments.doexternallogout( 'twitter' );
  59. https://theclevermachine.wordpress.com/2012/09/24/a-brief-introduction-to-markov-chains/
  60. javascript:highlandercomments.doexternallogout( 'facebook' );
  61. https://theclevermachine.wordpress.com/2012/09/24/a-brief-introduction-to-markov-chains/
  62. javascript:highlandercomments.cancelexternalwindow();
  63. https://theclevermachine.wordpress.com/category/algorithms/
  64. https://theclevermachine.wordpress.com/category/algorithms/classification/
  65. https://theclevermachine.wordpress.com/category/data-preprocessing/
  66. https://theclevermachine.wordpress.com/category/algorithms/density-estimation/
  67. https://theclevermachine.wordpress.com/category/derivations/
  68. https://theclevermachine.wordpress.com/category/algorithms/feature-learning/
  69. https://theclevermachine.wordpress.com/category/fmri/
  70. https://theclevermachine.wordpress.com/category/algorithms/gradient-descent/
  71. https://theclevermachine.wordpress.com/category/tips-tricks/latex/
  72. https://theclevermachine.wordpress.com/category/algorithms/machine-learning/
  73. https://theclevermachine.wordpress.com/category/tips-tricks/matlab/
  74. https://theclevermachine.wordpress.com/category/maximum-likelihood/
  75. https://theclevermachine.wordpress.com/category/mcmc/
  76. https://theclevermachine.wordpress.com/category/neural-networks/
  77. https://theclevermachine.wordpress.com/category/neuroscience/
  78. https://theclevermachine.wordpress.com/category/optimization/
  79. https://theclevermachine.wordpress.com/category/proofs/
  80. https://theclevermachine.wordpress.com/category/algorithms/regression/
  81. https://theclevermachine.wordpress.com/category/algorithms/sampling/
  82. https://theclevermachine.wordpress.com/category/sampling-methods/
  83. https://theclevermachine.wordpress.com/category/simulations/
  84. https://theclevermachine.wordpress.com/category/statistics/
  85. https://theclevermachine.wordpress.com/category/theory/
  86. https://theclevermachine.wordpress.com/category/tips-tricks/
  87. https://theclevermachine.wordpress.com/category/uncategorized/
  88. https://theclevermachine.wordpress.com/2014/09/23/derivation-maximum-likelihood-for-boltzmann-machines/
  89. https://theclevermachine.wordpress.com/2014/09/11/a-gentle-introduction-to-artificial-neural-networks/
  90. https://theclevermachine.wordpress.com/2014/09/08/derivation-derivatives-for-common-neural-network-activation-functions/
  91. https://theclevermachine.wordpress.com/2014/09/06/derivation-error-id26-gradient-descent-for-neural-networks/
  92. https://theclevermachine.wordpress.com/2013/04/21/model-selection-underfitting-overfitting-and-the-bias-variance-tradeoff/
  93. https://theclevermachine.wordpress.com/2013/04/21/supplemental-proof-1/
  94. https://theclevermachine.wordpress.com/2013/03/30/the-statistical-whitening-transform/
  95. https://theclevermachine.wordpress.com/2013/03/29/covariance-matrices-and-data-distributions/
  96. https://theclevermachine.wordpress.com/2013/01/14/fmri-in-neuroscience-efficiency-of-event-related-experiment-designs/
  97. https://theclevermachine.wordpress.com/2013/01/14/derivation-the-covariance-matrix-of-an-ols-estimator-and-applications-to-gls/
  98. https://theclevermachine.wordpress.com/2014/09/
  99. https://theclevermachine.wordpress.com/2013/04/
 100. https://theclevermachine.wordpress.com/2013/03/
 101. https://theclevermachine.wordpress.com/2013/01/
 102. https://theclevermachine.wordpress.com/2012/12/
 103. https://theclevermachine.wordpress.com/2012/11/
 104. https://theclevermachine.wordpress.com/2012/10/
 105. https://theclevermachine.wordpress.com/2012/09/
 106. https://theclevermachine.wordpress.com/2012/03/
 107. https://theclevermachine.wordpress.com/2012/02/
 108. https://theclevermachine.wordpress.com/2012/01/
 109. https://wordpress.com/start?ref=wplogin
 110. https://theclevermachine.wordpress.com/wp-login.php
 111. https://theclevermachine.wordpress.com/feed/
 112. https://theclevermachine.wordpress.com/comments/feed/
 113. https://wordpress.com/
 114. https://wordpress.com/?ref=footer_website
 115. https://theclevermachine.wordpress.com/2012/09/24/a-brief-introduction-to-markov-chains/
 116. https://automattic.com/cookies
 117. https://widgets.wp.com/likes/master.html?ver=20190321#ver=20190321

   hidden links:
 119. https://theclevermachine.files.wordpress.com/2012/09/markovchainintro6.png
 120. https://theclevermachine.files.wordpress.com/2012/09/markovchainintro22.png
 121. https://theclevermachine.wordpress.com/2012/09/24/a-brief-introduction-to-markov-chains/#comment-form-guest
 122. https://theclevermachine.wordpress.com/2012/09/24/a-brief-introduction-to-markov-chains/#comment-form-load-service:wordpress.com
 123. https://theclevermachine.wordpress.com/2012/09/24/a-brief-introduction-to-markov-chains/#comment-form-load-service:twitter
 124. https://theclevermachine.wordpress.com/2012/09/24/a-brief-introduction-to-markov-chains/#comment-form-load-service:facebook
