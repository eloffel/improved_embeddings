   #[1]rss feed for the berkeley artificial intelligence research blog

   [2][bair_logo.png]

   [3]subscribe [4]about [5]archive [6]bair

learning to learn

   chelsea finn    jul 18, 2017

   a key aspect of intelligence is versatility     the capability of doing
   many different things. current ai systems excel at mastering a single
   skill, such as go, jeopardy, or even helicopter aerobatics. but, when
   you instead ask an ai system to do a variety of seemingly simple
   problems, it will struggle. a champion jeopardy program cannot hold a
   conversation, and an expert helicopter controller for aerobatics cannot
   navigate in new, simple situations such as locating, navigating to, and
   hovering over a fire to put it out. in contrast, a human can act and
   adapt intelligently to a wide variety of new, unseen situations. how
   can we enable our artificial agents to acquire such versatility?

   there are several techniques being developed to solve these sorts of
   problems and i   ll survey them in this post, as well as discuss a recent
   technique from our lab, called [7]model-agnostic meta-learning. (you
   can check out the [8]research paper here, and the code for the
   [9]underlying technique here.)

   current ai systems can master a complex skill from scratch, using an
   understandably large amount of time and experience. but if we want our
   agents to be able to acquire many skills and adapt to many
   environments, we cannot afford to train each skill in each setting from
   scratch. instead, we need our agents to learn how to learn new tasks
   faster by reusing previous experience, rather than considering each new
   task in isolation. this approach of learning to learn, or
   meta-learning, is a key stepping stone towards versatile agents that
   can continually learn a wide variety of tasks throughout their
   lifetimes.

so, what is learning to learn, and what has it been used for?

   early approaches to meta-learning date back to the late 1980s and early
   1990s, including [10]j  rgen schmidhuber   s thesis and [11]work by yoshua
   and samy bengio. recently meta-learning has become a hot topic, with a
   flurry of recent papers, most commonly using the technique for
   [12]hyperparameter and [13]neural [14]network [15]optimization, finding
   [16]good [17]network [18]architectures, [19]few-[20]shot [21]image
   [22]recognition, and [23]fast [24]reinforcement [25]learning.

   maml
   various recent meta-learning approaches.

few-shot learning

   maml in 2015, [26]brendan lake et al. published a paper that challenged
   modern machine learning methods to be able to learn new concepts from
   one or a few instances of that concept. as an example, lake suggested
   that humans can learn to identify    novel two-wheel vehicles    from a
   single picture (e.g. as shown on the right), whereas machines cannot
   generalize a concept from just a single image. (humans can also draw a
   character in a new alphabet after seeing just one example). along with
   the paper, lake included a dataset of handwritten characters,
   [27]omniglot, the    transpose    of [28]mnist, with 1623 character
   classes, each with 20 examples. two deep learning models quickly
   followed with papers at icml 2016 that used [29]memory-augmented neural
   networks and [30]sequential generative models; showing it is possible
   for deep models to learn to learn from a few examples, though not yet
   at the level of humans.

how recent meta-learning approaches work

   meta-learning systems are trained by being exposed to a large number of
   tasks and are then tested in their ability to learn new tasks; an
   example of a task might be classifying a new image within 5 possible
   classes, given one example of each class, or learning to efficiently
   navigate a new maze with only one traversal through the maze. this
   differs from many standard machine learning techniques, which involve
   training on a single task and testing on held-out examples from that
   task.

   maml
   example meta-learning set-up for few-shot image classification, visual
   adapted from [31]ravi & larochelle    17.

   during meta-learning, the model is trained to learn tasks in the
   meta-training set. there are two optimizations at play     the learner,
   which learns new tasks, and the meta-learner, which trains the learner.
   methods for meta-learning have typically fallen into one of three
   categories: recurrent models, metric learning, and learning optimizers.

   recurrent models

   these approaches train a recurrent model, e.g. an [32]lstm, to take in
   the dataset sequentially and then process new inputs from the task., in
   an image classification setting, this might involve passing in the set
   of (image, label) pairs of a dataset sequentially, followed by new
   examples which must be classified.

   maml
   recurrent model approach for inputs $\mathbf{x}_t$ and corresponding
   labels $y_t$, figure from [33]santoro et al. '16.

   the meta-learner uses id119, whereas the learner simply
   rolls out the recurrent network. this approach is one of the most
   general approaches and has been used for [34]few-shot classification
   and regression, [35]and [36]meta-reinforcement [37]learning. due to its
   flexibility, this approach also tends to be less (meta-)efficient than
   other methods because the learner network needs to come up with its
   learning strategy from scratch.

   metric learning

   this approach involves learning a metric space in which learning is
   particularly efficient. this approach has mostly been used for few-shot
   classification. intuitively, if our goal is to learn from a small
   number of example images, than a simple approach is to compare the
   image that you are trying to classify with the example images that you
   have. but, as you might imagine, comparing images in pixel space won   t
   work well. instead, you can train a [38]siamese network or perform
   comparisons in a [39]learned metric space. like the previous approach,
   meta-learning is performed using id119 (or your favorite
   neural network optimizer), whereas the learner corresponds to a
   comparison scheme, e.g. nearest neighbors, in the meta-learned metric
   space. these approaches work [40]quite [41]well for few-shot
   classification, though they have yet to be demonstrated in other
   meta-learning domains such as regression or id23.

   learning optimizers

   the final approach is to [42]learn an optimizer. in this method, there
   is one network (the meta-learner) which learns to update another
   network (the learner) so that the learner effectively learns the task.
   this approach has been extensively studied for [43]better [44]neural
   [45]network [46]optimization. the meta-learner is typically a recurrent
   network so that it can remember how it previously updated the learner
   model. the meta-learner can be trained with id23 or
   supervised learning. [47]ravi & larochelle recently demonstrated this
   approach   s merit for few-shot image classification, presenting the view
   that the learner model is an optimization process that should be
   learned.

learning initializations as meta-learning

   arguably, the biggest success story of id21 has been
   initializing vision network weights [48]using id163 pre-training. in
   particular, when approaching any new vision task, the well-known
   paradigm is to first collect labeled data for the task, acquire a
   network pre-trained on id163 classification, and then fine-tune the
   network on the collected data using id119. using this
   approach, neural networks can more effectively learn new image-based
   tasks from modestly-sized datasets. however, pre-training only goes so
   far. because the last layers of the network still need to be heavily
   adapted to the new task, datasets that are too small, as in the
   few-shot setting, will still cause severe overfitting. furthermore, we
   unfortunately don   t have an analogous pre-training scheme for
   non-vision domains such as speech, language, and control.^[49]1 is
   there something to learn from the remarkable success of id163
   fine-tuning?

model-agnostic meta-learning (maml)

   what if we directly optimized for an initial representation that can be
   effectively fine-tuned from a small number of examples? this is exactly
   the idea behind our recently-proposed algorithm, model-agnostic
   meta-learning (maml). like other meta-learning methods, maml trains
   over a wide range of tasks. it trains for a representation that can be
   quickly adapted to a new task, via a few gradient steps. the
   meta-learner seeks to find an initialization that is not only useful
   for adapting to various problems, but also can be adapted quickly (in a
   small number of steps) and efficiently (using only a few examples).
   below is a visualization     suppose we are seeking to find a set of
   parameters $\theta$ that are highly adaptable. during the course of
   meta-learning (the bold line), maml optimizes for a set of parameters
   such that when a gradient step is taken with respect to a particular
   task $i$ (the gray lines), the parameters are close to the optimal
   parameters $\theta_i^*$ for task $i$.

   maml
   diagram of the maml approach.

   this approach is quite simple, and has a number of advantages. it
   doesn   t make any assumptions on the form of the model. it is quite
   efficient     there are no additional parameters introduced for
   meta-learning and the learner   s strategy uses a known optimization
   process (id119), rather than having to come up with one from
   scratch. lastly, it can be easily applied to a number of domains,
   including classification, regression, and id23.

   despite the simplicity of the approach, we were surprised to find that
   the method was able to substantially outperform a number of existing
   approaches on popular few-shot image classification benchmarks,
   omniglot and miniid163^[50]2, including existing approaches that
   were much more complex or domain specific. beyond classification, we
   also tried to learn how to adapt a simulated robot   s behavior to
   different goals, akin to the motivation at the top of this blog post    
   versatility. to do so, we combined maml with id189
   for id23. maml discovered a policy which let a
   simulated robot adapt its locomotion direction and speed in a single
   gradient update. see videos below:

   maml
   maml on halfcheetah.

   maml
   maml on ant.

   the generality of the method     it can be combined with any model smooth
   enough for gradient-based optimization     makes maml applicable to a
   wide range of domains and learning objectives beyond those explored in
   the paper.

   we hope that maml   s simple approach for effectively teaching agents to
   adapt to variety of scenarios will bring us one step closer towards
   developing versatile agents that can learn a variety of skills in real
   world settings.
     __________________________________________________________________

   i would like to thank sergey levine and pieter abbeel for their
   valuable feedback.

   this last part of this post was based on the following research paper:
     * [51]model-agnostic meta-learning for fast adaptation of deep
       networks.
       c. finn, p. abbeel, s. levine. in icml, 2017. ([52]pdf, [53]code)
     __________________________________________________________________

    1. though, researchers have developed domain-agnostic initialization
       schemes to encourage [54]well-[55]conditioned [56]gradients and
       using [57]data-dependent [58]id172. [59]   
    2. introduced by vinyals et al.    16 and ravi & larochelle    17, the
       miniid163 benchmark is the same as omniglot but uses real rgb
       images from a subset of the id163 dataset. [60]   

   subscribe to our [61]rss feed.
   spread the word:

comments

   please enable javascript to view the [62]comments powered by disqus.

references

   visible links
   1. https://bair.berkeley.edu/blog/feed.xml
   2. https://bair.berkeley.edu/blog/
   3. https://bair.berkeley.edu/blog/subscribe/
   4. https://bair.berkeley.edu/blog/about/
   5. https://bair.berkeley.edu/blog/archive/
   6. http://bair.berkeley.edu/
   7. http://bair.berkeley.edu/blog/2017/07/18/learning-to-learn/#model-agnostic-meta-learning-maml
   8. https://arxiv.org/abs/1703.03400
   9. https://github.com/cbfinn/maml
  10. http://people.idsia.ch/~juergen/diploma.html
  11. http://bengio.abracadoudou.com/publications/pdf/bengio_1991_ijid98.pdf
  12. https://arxiv.org/abs/1502.03492
  13. https://arxiv.org/abs/1703.00441
  14. https://arxiv.org/abs/1703.04813
  15. http://www.cantab.net/users/yutian.chen/publications/chenetal_icml17_l2l.pdf
  16. https://arxiv.org/abs/1611.01578
  17. https://arxiv.org/abs/1611.02167
  18. https://arxiv.org/abs/1704.08792
  19. https://arxiv.org/abs/1606.04080
  20. https://openreview.net/forum?id=rjy0-kcll
  21. https://arxiv.org/abs/1703.03400
  22. https://arxiv.org/abs/1606.02819
  23. https://arxiv.org/abs/1611.02779
  24. https://arxiv.org/abs/1611.05763
  25. https://arxiv.org/abs/1703.03400
  26. https://www.cs.cmu.edu/~rsalakhu/papers/lakeetal2015science.pdf
  27. https://github.com/brendenlake/omniglot
  28. http://yann.lecun.com/exdb/mnist/
  29. http://proceedings.mlr.press/v48/santoro16.pdf
  30. https://arxiv.org/abs/1603.05106
  31. https://openreview.net/forum?id=rjy0-kcll
  32. http://www.bioinf.jku.at/publications/older/2604.pdf
  33. http://proceedings.mlr.press/v48/santoro16.pdf
  34. http://proceedings.mlr.press/v48/santoro16.pdf
  35. https://arxiv.org/abs/1707.03141
  36. https://arxiv.org/abs/1611.02779
  37. https://arxiv.org/abs/1611.05763
  38. https://www.cs.cmu.edu/~rsalakhu/papers/oneshot1.pdf
  39. https://arxiv.org/abs/1606.04080
  40. https://arxiv.org/abs/1703.05175
  41. https://arxiv.org/abs/1703.00767
  42. http://snowedin.net/tmp/hochreiter2001.pdf
  43. https://arxiv.org/abs/1606.01885
  44. https://arxiv.org/abs/1606.04474
  45. https://arxiv.org/abs/1703.00441
  46. https://arxiv.org/abs/1703.04813
  47. https://openreview.net/forum?id=rjy0-kcll
  48. http://proceedings.mlr.press/v32/donahue14.pdf
  49. https://bair.berkeley.edu/blog/2017/07/18/learning-to-learn/#fn:pre_training
  50. https://bair.berkeley.edu/blog/2017/07/18/learning-to-learn/#fn:mini_image
  51. https://arxiv.org/abs/1703.03400
  52. https://arxiv.org/pdf/1703.03400.pdf
  53. https://github.com/cbfinn/maml
  54. http://proceedings.mlr.press/v9/glorot10a.html
  55. https://arxiv.org/abs/1602.07868
  56. https://arxiv.org/abs/1312.6120
  57. https://arxiv.org/abs/1511.06856
  58. https://arxiv.org/abs/1511.06422
  59. https://bair.berkeley.edu/blog/2017/07/18/learning-to-learn/#fnref:pre_training
  60. https://bair.berkeley.edu/blog/2017/07/18/learning-to-learn/#fnref:mini_image
  61. https://bair.berkeley.edu/blog/feed.xml
  62. http://disqus.com/?ref_noscript

   hidden links:
  64. https://facebook.com/sharer.php?u=http://bair.berkeley.edu/blog/2017/07/18/learning-to-learn/
  65. https://twitter.com/intent/tweet?text=learning%20to%20learn&url=http://bair.berkeley.edu/blog/2017/07/18/learning-to-learn/
  66. https://plus.google.com/share?url=http://bair.berkeley.edu/blog/2017/07/18/learning-to-learn/
  67. http://www.linkedin.com/sharearticle?url=http://bair.berkeley.edu/blog/2017/07/18/learning-to-learn/&title=learning%20to%20learn
  68. http://reddit.com/submit?url=http://bair.berkeley.edu/blog/2017/07/18/learning-to-learn/&title=learning%20to%20learn
  69. https://news.ycombinator.com/submitlink?u=http://bair.berkeley.edu/blog/2017/07/18/learning-to-learn/&t=learning%20to%20learn
