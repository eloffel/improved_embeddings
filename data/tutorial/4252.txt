   #[1]publisher [2]medium [3]alternate

   [4]homepage
   [5]homepage
   [6]sign in[7]get started

   [8]towards data science
     * [9]data science
     * [10]machine learning
     * [11]programming
     * [12]visualization
     * [13]ai
     * [14]data journalism
     * [15]contribute
     __________________________________________________________________

using fasttext and svd to visualise id27s instantly

   [16]go to the profile of aditya lahiri
   [17]aditya lahiri (button) blockedunblock (button) followfollowing
   jul 22, 2017

   when i began with the basics of natural language processing a while
   back, i was fascinated by the way in which words were represented as
   vectors. even more enthralling was words being plotted on a graph with
   those having similar meaning and context grouped together. so, i
   struggled with generating my own embedding and it was a     struggle    
   because of the lack of computation power i had. id97 for generating
   vectors and id167 for visualising were popular choices but took a lot
   of time with the resources i had.

   well, that has not changed till now. however, i came across facebook   s
   fasttext that blew me away. it takes seconds to do things which used to
   take hours earlier with almost same performance results. in addition to
   that, i used some id202 to find out the way which is perhaps
   the     fastest     to generate your own id27 visualisations.
   let   s dive right into the process now and write some code.

   1.getting the data

   i decided to take chat data from whatsapp. i took up the data of the
   literary and debating club (ldc) of my college. this is because we have
   blabbered there on a wide range of topics and also the data amounted to
   nearly 1.1 mb which was good enough for the task.

   2. some pre-processing

   there were some issues that needed attention. first, there were phone
   numbers of people at the beginning of each new line if there contact
   name was not saved. also, there were weird special characters that
   represented emoticons in the chat but were a headache for our task. so,
   i used some regular expression tricks to clean the text.

   iframe: [18]/media/42870fa7c57682b8dbcf3fde5014b2c2?postid=5b8fa870c3d1

   3. setting up fasttext

   let us now move onto the big guy. getting facebook   s fasttext set up is
   a piece of cake. all you need is a modern c++ compiler (c++ 11)
   followed by a make command. fasttext is written in pure c++ which is
   another reason for its insanely quick implementation.

   a. go to [19]https://github.com/facebookresearch/fasttext and clone the
   repo.

   b. switch to the downloaded directory and type make command on your
   terminal

   c. voila! fasttext is ready to use.

   4. using fasttext on our data

   we shall now use the fasttext library to generate word vectors for our
   cleaned data. to do so, open up your terminal in the fasttext directory
   and type-

            ./fasttext skipgram -input ldc_clean.txt -output model         

   let me break down that statement down for you.

   ./fasttext         use the fasttext module we just compiled a step back, duh?

   skigram         there are two popular methods to generate vector
   representations of words. cbow and skipgram. we choose skipgram here.

   -input ldc_clean.txt         we specify as the input argument our file name
   that contains text data.

   -output model         this specifies the name with which fasttext will
   generate our two output files. model.vec is a text file containing the
   word vectors, one per line. model.bin is a binary file containing the
   parameters of the model along with the dictionary and all hyper
   parameters

   5. setting up python lists from the generated model.vec

   we now have our words and vectors in a .vec file but in order to plot
   them and also to perform svd on the vectors, we need to convert the
   words to a list and the corresponding vectors to another list. along
   the way, we also need to convert vector values from string to numpy   s
   float32 type to allow the above said operations.

   iframe: [20]/media/ea5868ed4a653b85a7b1c210d2d37af1?postid=5b8fa870c3d1

   6. using singular value decomposition to reduce dimensions.

   when i googled around for the first time, i found id167 being used
   everywhere to generate some amazing visualisations by reducing
   dimensionality. no doubt, i am a big fan of it. but sadly my
   computation power isn   t. so, i decided, why not use the good old svd.
   it worked like a charm. it als o contributed to the whole point of
   using fasttext in the first place, that is, giving real quick results.

   iframe: [21]/media/7cd96790867185a573f127097ea282bc?postid=5b8fa870c3d1

   7. the fun part. plotting our data to create insightful visualisation

   now, we have everything we need. a nice list that has all words and a
   wonderfully reduced representation our originally high dimensional
   vector representation, courtesy, svd. all we got to do now is use
   matplotlib and generate some visual awesomeness.

   iframe: [22]/media/a0b169f1ec9a7bd23483524f89faaa38?postid=5b8fa870c3d1

   that right there folks, was perhaps the quickest way you   ll ever find
   to take a raw piece of data, train it in seconds to generate vector
   representations of words using facebook   s fasttext and then do a bit of
   id202 magic to get the visualisations up in absolutely no real
   time.

   i plan to release a post explaining all the mathematical intricacies
   that lie under the hood. it will deal with how fasttext achieves sota
   results in such little time and what helps it to beat the existing
   competition like id97 , especially in terms of training time. so,
   if you liked this you will surely love that. so, stay tuned and keep
   embedding!
   [1*yq92vbw2nswh70ndr8p7vq.png]
   who   s up for a debate night?

   p.s - the image is highly zoomed in because of the extremely dense
   nature of the visualisations. use matplotlib   s zoom feature to do that.

     * [23]machine learning
     * [24]fasttext
     * [25]nlp
     * [26]id27s
     * [27]id97

   (button)
   (button)
   (button) 54 claps
   (button) (button) (button) 1 (button) (button)

     (button) blockedunblock (button) followfollowing
   [28]go to the profile of aditya lahiri

[29]aditya lahiri

   pre-final year undergrad. engaged in research of the crossover between
   deep learning with life sciences .

     (button) follow
   [30]towards data science

[31]towards data science

   sharing concepts, ideas, and codes.

     * (button)
       (button) 54
     * (button)
     *
     *

   [32]towards data science
   never miss a story from towards data science, when you sign up for
   medium. [33]learn more
   never miss a story from towards data science
   (button) get updatesget updates

references

   visible links
   1. https://plus.google.com/103654360130207659246
   2. https://towardsdatascience.com/osd.xml
   3. android-app://com.medium.reader/https/medium.com/p/5b8fa870c3d1
   4. https://medium.com/
   5. https://medium.com/
   6. https://medium.com/m/signin?redirect=https://towardsdatascience.com/using-fasttext-and-svd-to-visualise-word-embeddings-instantly-5b8fa870c3d1&source=--------------------------nav_reg&operation=login
   7. https://medium.com/m/signin?redirect=https://towardsdatascience.com/using-fasttext-and-svd-to-visualise-word-embeddings-instantly-5b8fa870c3d1&source=--------------------------nav_reg&operation=register
   8. https://towardsdatascience.com/?source=logo-lo_cllnf7jo02py---7f60cf5620c9
   9. https://towardsdatascience.com/data-science/home
  10. https://towardsdatascience.com/machine-learning/home
  11. https://towardsdatascience.com/programming/home
  12. https://towardsdatascience.com/data-visualization/home
  13. https://towardsdatascience.com/artificial-intelligence/home
  14. https://towardsdatascience.com/data-journalism/home
  15. https://towardsdatascience.com/contribute/home
  16. https://towardsdatascience.com/@adityalahiri13?source=post_header_lockup
  17. https://towardsdatascience.com/@adityalahiri13
  18. https://towardsdatascience.com/media/42870fa7c57682b8dbcf3fde5014b2c2?postid=5b8fa870c3d1
  19. https://github.com/facebookresearch/fasttext
  20. https://towardsdatascience.com/media/ea5868ed4a653b85a7b1c210d2d37af1?postid=5b8fa870c3d1
  21. https://towardsdatascience.com/media/7cd96790867185a573f127097ea282bc?postid=5b8fa870c3d1
  22. https://towardsdatascience.com/media/a0b169f1ec9a7bd23483524f89faaa38?postid=5b8fa870c3d1
  23. https://towardsdatascience.com/tagged/machine-learning?source=post
  24. https://towardsdatascience.com/tagged/fasttext?source=post
  25. https://towardsdatascience.com/tagged/nlp?source=post
  26. https://towardsdatascience.com/tagged/word-embeddings?source=post
  27. https://towardsdatascience.com/tagged/id97?source=post
  28. https://towardsdatascience.com/@adityalahiri13?source=footer_card
  29. https://towardsdatascience.com/@adityalahiri13
  30. https://towardsdatascience.com/?source=footer_card
  31. https://towardsdatascience.com/?source=footer_card
  32. https://towardsdatascience.com/
  33. https://medium.com/@medium/personalize-your-medium-experience-with-users-publications-tags-26a41ab1ee0c#.hx4zuv3mg

   hidden links:
  35. https://medium.com/p/5b8fa870c3d1/share/twitter
  36. https://medium.com/p/5b8fa870c3d1/share/facebook
  37. https://medium.com/p/5b8fa870c3d1/share/twitter
  38. https://medium.com/p/5b8fa870c3d1/share/facebook
