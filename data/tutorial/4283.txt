   #[1]search

     * (button)
     * [2]latest
          +
          +
          +
          +
     * [3]obsessions

these are the core obsessions that drive our newsroom   defining topics of
seismic importance to the global economy.
          +
          +
          +
          +
     * [4]featured
          +
          +
          +
          +
     *
     * [5]emails

our emails are made to shine in your inbox, with something fresh every
morning, afternoon, and weekend.
          +
          +
          +
          +
     * [6]editions

quartz is a guide to the new global economy for people excited by change.
          +

quartz africa
            the important stories of innovation across the continent   s
            wide-ranging economies
          +

quartz india
            in-depth coverage of the world   s largest democracy for india
            and its far-flung diaspora
          +

quartzy
            lifestyle, culture, and living well in the new global economy
          +

quartz at work
            management news, advice, and ideas for business leaders
          +

atlas
            create, share, and discover charts, using the same tools as
            the quartz newsroom
     * [7]become a member
     * (button)

   ap photo/jeff chiu
   stanford professor and google cloud chief scientist fei-fei li changed
   everything.
   it's not about the algorithm

the data that transformed ai research   and possibly the world

   by [8]dave gershgornjuly 26, 2017

   in 2006, fei-fei li started ruminating on an idea.

   li, a newly-minted computer science professor at university of illinois
   urbana-champaign, saw her colleagues across academia and the ai
   industry hammering away at the same concept: a better algorithm would
   make better decisions, regardless of the data.

   but she realized a limitation to this approach   the best algorithm
   wouldn   t work well if the data it learned from didn   t reflect the real
   world.

   her solution: build a better dataset.

      we decided we wanted to do something that was completely historically
   unprecedented,    li said, referring to a small team who would initially
   work with her.    we   re going to map out the entire world of objects.   

   the resulting dataset was called id163. originally published in 2009
   as a research poster stuck in the corner of a miami beach conference
   center, the dataset quickly evolved into an annual competition to see
   which algorithms could identify objects in the dataset   s images with
   the lowest error rate. many see it as the catalyst for the ai boom the
   world is experiencing today.

   alumni of the id163 challenge can be found in every corner of the
   tech world. the contest   s first winners in 2010 went on to take senior
   roles at baidu, google, and huawei. matthew zeiler built clarifai based
   off his 2013 id163 win, and is now backed by $40 million in vc
   funding. in 2014, google split the winning title with two researchers
   from oxford, who were quickly snapped up and added to its
   recently-acquired deepmind lab.

   li herself is now chief scientist at google cloud, a professor at
   stanford, and director of the university   s ai lab.

   today, she   ll take the stage at cvpr to talk about id163   s annual
   results for the last time   2017 was the final year of the competition.
   in just seven years, the winning accuracy in classifying objects in the
   dataset rose from 71.8% to 97.3%, surpassing human abilities and
   effectively proving that bigger data leads to better decisions.

   even as the competition ends, its legacy is already taking shape. since
   2009, dozens of new ai research datasets have been introduced in
   subfields like id161, natural language processing, and voice
   recognition.

      the paradigm shift of the id163 thinking is that while a lot of
   people are paying attention to models, let   s pay attention to data,    li
   said.    data will redefine how we think about models.   

what   s id163?

   in the late 1980s, princeton psychologist george miller started a
   project called id138, with the aim of building a hierarchal structure
   for the english language. it would be sort of like a dictionary, but
   words would be shown in relation to other words rather than
   alphabetical order. for example, within id138, the word    dog    would
   be nested under    canine,    which would be nested under    mammal,    and so
   on. it was a way to organize language that relied on machine-readable
   logic, and amassed more than 155,000 indexed words.
   id163
   the id163 hierarchy derived from id138.

   li, in her first teaching job at uiuc, had been grappling with one of
   the core tensions in machine learning: overfitting and generalization.
   when an algorithm can only work with data that   s close to what it   s
   seen before, the model is considered overfitting to the data; it can   t
   understand anything more general past those examples. on the other
   hand, if a model doesn   t pick up the right patterns between the data,
   it   s overgeneralizing.

   finding the perfect algorithm seemed distant, li says. she saw that
   previous datasets didn   t capture how variable the world could be   even
   just identifying pictures of cats is infinitely complex. but by giving
   the algorithms more examples of how complex the world could be, it made
   mathematic sense they could fare better. if you only saw five pictures
   of cats, you   d only have five camera angles, lighting conditions, and
   maybe variety of cat. but if you   ve seen 500 pictures of cats, there
   are many more examples to draw commonalities from.

   li started to read about how others had attempted to catalogue a fair
   representation of the world with data. during that search, she found
   id138.

   having read about id138   s approach, li met with professor christiane
   fellbaum, a researcher influential in the continued work on id138,
   during a 2006 visit to princeton. fellbaum had the idea that id138
   could have an image associated with each of the words, more as a
   reference rather than a id161 dataset. coming from that
   meeting, li imagined something grander   a large-scale dataset with many
   examples of each word.

   months later li joined the princeton faculty, her alma mater, and
   started on the id163 project in early 2007. she started to build a
   team to help with the challenge, first recruiting a fellow professor,
   kai li, who then convinced ph.d student jia deng to transfer into li   s
   lab. deng has helped run the id163 project through 2017.

      it was clear to me that this was something that was very different
   from what other people were doing, were focused on at the time,    deng
   said.    i had a clear idea that this would change how the game was
   played in vision research, but i didn   t know how it would change.   

   the objects in the dataset would range from concrete objects, like
   pandas or churches, to abstract ideas like love.

   li   s first idea was to hire undergraduate students for $10 an hour to
   manually find images and add them to the dataset. but
   back-of-the-napkin math quickly made li realize that at the undergrads   
   rate of collecting images it would take 90 years to complete.

   after the undergrad task force was disbanded, li and the team went back
   to the drawing board. what if computer-vision algorithms could pick the
   photos from the internet, and humans would then just curate the images?
   but after a few months of tinkering with algorithms, the team came to
   the conclusion that this technique wasn   t sustainable either   future
   algorithms would be constricted to only judging what algorithms were
   capable of recognizing at the time the dataset was compiled.

   undergrads were time-consuming, algorithms were flawed, and the team
   didn   t have money   li said the project failed to win any of the federal
   grants she applied for, receiving comments on proposals that it was
   shameful princeton would research this topic, and that the only
   strength of proposal was that li was a woman.

   a solution finally surfaced in a chance hallway conversation with a
   graduate student who asked li whether she had heard of amazon
   mechanical turk, a service where hordes of humans sitting at computers
   around the world would complete small online tasks for pennies.

      he showed me the website, and i can tell you literally that day i knew
   the id163 project was going to happen,    she said.    suddenly we found
   a tool that could scale, that we could not possibly dream of by hiring
   princeton undergrads.   
   id163
   the amazon mechanical turk backend for classifying images.

   mechanical turk brought its own slew of hurdles, with much of the work
   fielded by two of li   s ph.d students, jia deng and olga russakovsky .
   for example, how many turkers needed to look at each image? maybe two
   people could determine that a cat was a cat, but an image of a
   miniature husky might require 10 rounds of validation. what if some
   turkers tried to game or cheat the system? li   s team ended up creating
   a batch of statistical models for turker   s behaviors to help ensure the
   dataset only included correct images.

   even after finding mechanical turk, the dataset took two and a half
   years to complete. it consisted of 3.2 million labelled images,
   separated into 5,247 categories, sorted into 12 subtrees like    mammal,   
      vehicle,    and    furniture.   

   in 2009, li and her team published the [9]id163 paper with the
   dataset   to little fanfare. li recalls that cvpr, a leading conference
   in id161 research, only allowed a poster, instead of an oral
   presentation, and the team handed out id163-branded pens to drum up
   interest. people were skeptical of the basic idea that more data would
   help them develop better algorithms.

      there were comments like    if you can   t even do one object well, why
   would you do thousands, or tens of thousands of objects?    deng said.

   if data is the new oil, it was still dinosaur bones in 2009.

the id163 challenge

   later in 2009, at a id161 conference in kyoto, a researcher
   named alex berg approached li to suggest that adding an additional
   aspect to the contest where algorithms would also have to locate where
   the pictured object was, not just that it existed. li countered: come
   work with me.

   li, berg, and deng authored five papers together based on the dataset,
   exploring how algorithms would interpret such vast amounts of data. the
   first paper would become a benchmark for how an algorithm would react
   to thousands of classes of images, the predecessor to the id163
   competition.

      we realized to democratize this idea we needed to reach out further,   
   li said, speaking on the first paper.

   li then approached a well-known image recognition competition in europe
   called pascal voc, which agreed to collaborate and co-brand their
   competition with id163. the pascal challenge was a well-respected
   competition and dataset, but representative of the previous method of
   thinking. the competition only had 20 classes, compared to id163   s
   1,000.

   as the competition continued in 2011 and into 2012, it soon became a
   benchmark for how well image classification algorithms fared against
   the most complex visual dataset assembled at the time.
   id163
   a screenshot of the id163 database online

   but researchers also began to notice something more going on than just
   a competition   their algorithms worked better when they trained using
   the id163 dataset.

      the nice surprise was that people who trained their models on id163
   could use them to jumpstart models for other recognition tasks. you   d
   start with the id163 model and then you   d fine-tune it for another
   task,    said berg.    that was a breakthrough both for neural nets and
   just for recognition in general.   

   two years after the first id163 competition, in 2012, something even
   bigger happened. indeed, if the artificial intelligence boom we see
   today could be attributed to a single event, it would be the
   announcement of the 2012 id163 challenge results.

   geoffrey hinton, ilya sutskever, and alex krizhevsky from the
   university of toronto submitted a deep convolutional neural network
   architecture called alexnet   still used in research to this day   which
   beat the field by a whopping 10.8 percentage point margin, which was
   41% better than the next best.

   id163 couldn   t come at a better time for hinton and his two
   students. hinton had been working on id158s since
   the 1980s, and while some like yann lecun had been able to work the
   technology into atm check readers through the influence of bell labs,
   hinton   s research hadn   t found that kind of home. a few years earlier,
   research from graphics-card manufacturer nvidia had made these networks
   process faster, but still not better than other techniques.

   hinton and his team had demonstrated that their networks could perform
   smaller tasks on smaller datasets, like handwriting detection, but they
   needed much more data to be useful in the real world.

      it was so clear that if you do a really good on id163, you could
   solve image recognition,    said sutskever.

   today, these convolutional neural networks are everywhere   facebook,
   where lecun is director of ai research, uses them to tag your photos;
   self-driving cars are using them to detect objects; basically anything
   that knows what   s in a image or video uses them. they can tell what   s
   in an image by finding patterns between pixels on ascending levels of
   abstraction, using thousands to millions of tiny computations on each
   level. new images are put through the process to match their patterns
   to learned patterns. hinton had been pushing his colleagues to take
   them seriously for decades, but now he had proof that they could beat
   other state of the art techniques.

      what   s more amazing is that people were able to keep improving it with
   deep learning,    sutskever said, referring to the method that layers
   neural networks to allow more complex patterns to be processed, now the
   most popular favor of artificial intelligence.    deep learning is just
   the right stuff.   

   the 2012 id163 results sent id161 researchers scrambling
   to replicate the process. matthew zeiler, an nyu ph.d student who had
   studied under hinton, found out about the id163 results and, through
   the university of toronto connection, got early access to the paper and
   code. he started working with rob fergus, a nyu professor who had also
   built a career working on neural networks. the two started to develop
   their submission for the 2013 challenge, and zeiler eventually left a
   google internship weeks early to focus on the submission.

   zeiler and fergus won that year, and by 2014 all the high-scoring
   competitors would be deep neural networks, li said.

      this id163 2012 event was definitely what triggered the big
   explosion of ai today,    zeiler wrote in an email to quartz.    there were
   definitely some very promising results in id103 shortly
   before this (again many of them sparked by toronto), but they didn   t
   take off publicly as much as that id163 win did in 2012 and the
   following years.   

   today, many consider id163 solved   the error rate is incredibly low
   at around 2%. but that   s for classification, or identifying which
   object is in an image. this doesn   t mean an algorithm knows the
   properties of that object, where it comes from, what it   s used for, who
   made it, or how it interacts with its surroundings. in short, it
   doesn   t actually understand what it   s seeing. this is mirrored in
   id103, and even in much of natural language processing.
   while our ai today is fantastic at knowing what things are,
   understanding these objects in the context of the world is next. how ai
   researchers will get there is still unclear.

after id163

   while the competition is ending, the id163 dataset   updated over the
   years and now more than 13 million images strong   will live on.

   berg says the team tried to retire the one aspect of the challenge in
   2014, but faced pushback from companies including google and facebook
   who liked the centralized benchmark. the industry could point to one
   number and say,    we   re this good.   

   since 2010 there have been a number of other high-profile datasets
   introduced by google, microsoft, and the canadian institute for
   advanced research, as deep learning has proven to require data as vast
   as what id163 provided.

   datasets have become haute. startup founders and venture capitalists
   will [10]write medium posts shouting out the latest datasets, and how
   their algorithms fared on id163. internet companies such as google,
   facebook, and amazon have started creating their own internal datasets,
   based on the millions of images, voice clips, and text snippets entered
   and shared on their platforms every day. even startups are beginning to
   assemble their own datasets   twentybn, an ai company focused on video
   understanding, used amazon mechanical turk to collect videos of turkers
   performing simple hand gestures and actions on video. the company has
   released two datasets free for academic use, each with more than
   100,000 videos.

      there is a lot of mushrooming and blossoming of all kinds of datasets,
   from videos to speech to games to everything,    li said.

   it   s sometimes taken for granted that these datasets, which are
   intensive to collect, assemble, and vet, are free. being open and free
   to use is an original tenet of id163 that will outlive the challenge
   and likely even the dataset.

   in 2016, google released the open images database, containing 9 million
   images in 6,000 categories. google recently updated the dataset to
   include labels for where specific objects were located in each image, a
   staple of the id163 challenge after 2014. london-based deepmind,
   bought by google and spun into its own alphabet company, recently
   released its own video dataset of humans performing a variety of
   actions.

      one thing id163 changed in the field of ai is suddenly people
   realized the thankless work of making a dataset was at the core of ai
   research,    li said.    people really recognize the importance the dataset
   is front and center in the research as much as algorithms.   

   correction (july 26): an earlier version of this article misspelled the
   name of olga russakovsky.

   https://qz.com/10349
   [11]technology, [12]google, [13]artificial intelligence, [14]ai,
   [15]algorithms

   [16]latest[17]featured[18]obsessions[19]emails[20]editions
   (button) close

   iframe: [21]https://www.googletagmanager.com/ns.html?id=gtm-mrd738c

references

   visible links
   1. https://qz.com/public/meta/opensearch.xml
   2. https://qz.com/latest/
   3. https://qz.com/obsessions/
   4. https://qz.com/featured/
   5. https://qz.com/emails/
   6. https://qz.com/editions/
   7. https://qz.com/become-a-member/
   8. https://qz.com/author/dgershgornqz
   9. http://www.image-net.org/papers/id163_cvpr09.pdf
  10. https://medium.com/startup-grind/fueling-the-ai-gold-rush-7ae438505bc2
  11. https://qz.com/re/technology/
  12. https://qz.com/re/google/
  13. https://qz.com/re/artificial-intelligence/
  14. https://qz.com/re/ai/
  15. https://qz.com/re/algorithms/
  16. https://qz.com/latest/
  17. https://qz.com/featured/
  18. https://qz.com/obsessions/
  19. https://qz.com/emails/
  20. https://qz.com/editions/
  21. https://www.googletagmanager.com/ns.html?id=gtm-mrd738c

   hidden links:
  23. https://qz.com/
  24. https://qz.com/africa/
  25. https://qz.com/india/
  26. https://qz.com/quartzy/
  27. https://qz.com/work/
  28. https://www.theatlas.com/
  29. https://twitter.com/intent/tweet?url=https%3a%2f%2fqz.com%2f1034972%2f&text=the%20data%20that%20transformed%20ai%20research%e2%80%94and%20possibly%20the%20world&via=qz
  30. https://www.facebook.com/sharer.php?u=https%3a%2f%2fqz.com%2f1034972%2fthe-data-that-changed-the-direction-of-ai-research-and-possibly-the-world%2f&caption=qz.com%20%7c%20by%20dave%20gershgorn
  31. https://www.linkedin.com/sharearticle?mini=true&url=https%3a%2f%2fqz.com%2f1034972%2fthe-data-that-changed-the-direction-of-ai-research-and-possibly-the-world%2f&title=the%20data%20that%20transformed%20ai%20research%e2%80%94and%20possibly%20the%20world&summary=the%20id163%20competition%20ends%20today.%20but%20its%20legacy%20is%20just%20starting%20to%20take%20shape.
  32. mailto:?subject=quartz%3a%20the%20data%20that%20transformed%20ai%20research%e2%80%94and%20possibly%20the%20world&body=https%3a%2f%2fqz.com%2f1034972%2fthe-data-that-changed-the-direction-of-ai-research-and-possibly-the-world%2f%0a%0ain%202006%2c%20fei-fei%20li%20started%20ruminating%20on%20an%20idea.%20li%2c%20a%20newly-minted%20computer%20science%20professor%20at%20university%20of%20illinois%20urbana-champaign%2c%20saw%20her%20colleagues%20across%20academia%20and%20the%20ai%20industry%20hammering%20away%20at%20the%20same%20concept%3a%20a%20better%20algorithm%20would%20make%20better%20decisions%2c%20regardless%20of%20the%20data.%20but%20she%20realized%20a%20limitation%20to%20this%20approach%e2%80%94the%20best%e2%80%a6%0a%0asign%20up%20for%20the%20quartz%20daily%20brief%3a%20https%3a%2f%2fqz.com%2fdaily-brief
  33. whatsapp://send?text=from%20quartz%3a%20thedatathattransformedairesearch%e2%80%94andpossiblytheworld+https://qz.com/1034972/the-data-that-changed-the-direction-of-ai-research-and-possibly-the-world/
