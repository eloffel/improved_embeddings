   #[1]publisher [2]medium [3]alternate

   [4]homepage
   [5]homepage
   [6]sign in[7]get started

   [8]coastline automation
     * [9]99-line steering model
     * [10]coastline home
     __________________________________________________________________

let   s evolve a neural network with a genetic algorithm   code included

   [11]go to the profile of matt harvey
   [12]matt harvey (button) blockedunblock (button) followfollowing
   apr 6, 2017
   [1*tokyw6jtvla0uba5vsyyvg.jpeg]

   building the perfect deep learning network involves a hefty amount of
   art to accompany sound science. one way to go about finding the right
   hyperparameters is through brute force trial and error: try every
   combination of sensible parameters, send them to your spark cluster, go
   about your daily jive, and come back when you have an answer.

   but there   s gotta be a better way!

   here, we try to improve upon the brute force method by applying a
   genetic algorithm to evolve a network with the goal of achieving
   optimal hyperparameters in a fraction the time of a brute force search.

how much faster?

   let   s say it takes five minutes to train and evaluate a network on your
   dataset. and let   s say we have four parameters with five possible
   settings each. to try them all would take (5**4) * 5 minutes, or 3,125
   minutes, or about 52 hours.

   now let   s say we use a genetic algorithm to evolve 10 generations with
   a population of 20 (more on what this means below), with a plan to keep
   the top 25% plus a few more, so ~8 per generation. this means that in
   our first generation we score 20 networks (20 * 5 = 100 minutes). every
   generation after that only requires around 12 runs, since we don   t have
   the score the ones we keep. that   s 100 + (9 generations * 5 minutes *
   12 networks) = 640 minutes, or 11 hours.

   we   ve just reduced our parameter tuning time by almost 80%! that is,
   assuming it finds the best parameters   

ok google, what   s a genetic algorithm?

     id107 are commonly used to generate high-quality
     solutions to [13]optimization and [14]search problems by relying on
     bio-inspired operators such as [15]mutation, [16]crossover and
     [17]selection.         wikipedia

how do id107 work?

   at its core, a genetic algorithm   
    1. creates a population of (randomly generated) members
    2. scores each member of the population based on some goal. this score
       is called a fitness function.
    3. selects and breeds the best members of the population to produce
       more like them
    4. mutates some members randomly to attempt to find even better
       candidates
    5. kills off the rest (survival of the fittest and all), and
    6. repeats from step 2. each iteration through these steps is called a
       generation.

   repeat this process enough times and you should be left with the very
   best possible members of a population. sounds like a lot evolution,
   right? same deal.

applying id107 to neural networks

   we   ll attempt to evolve a fully connected network (mlp). our goal is to
   find the best parameters for an image classification task.

   we   ll tune four parameters:
     * number of layers (or the network depth)
     * neurons per layer (or the network width)
     * dense layer activation function
     * network optimizer

   the steps we   ll take to evolve the network, similar to those described
   above, are:
    1. initialize n random networks to create our population.
    2. score each network. this takes some time: we have to train the
       weights of each network and then see how well it performs at
       classifying the test set. since this will be an image
       classification task, we   ll use classification accuracy as our
       fitness function.
    3. sort all the networks in our population by score (accuracy). we   ll
       keep some percentage of the top networks to become part of the next
       generation and to breed children.
    4. we   ll also randomly keep a few of the non-top networks. this helps
       find potentially lucky combinations between worse-performers and
       top performers, and also helps keep us from getting stuck in a
       local maximum.
    5. now that we   ve decided which networks to keep, we randomly mutate
       some of the parameters on some of the networks.
    6. here comes the fun part: let   s say we started with a population of
       20 networks, we kept the top 25% (5 nets), randomly kept 3 more
       loser networks, and mutated a few of them. we let the other 12
       networks die. in an effort to keep our population at 20 networks,
       we need to fill 12 open spots. it   s time to breed!

breeding

   breeding is where we take two members of a population and generate one
   or more child, where that child represents a combination of its
   parents.

   in our neural network case, each child is a combination of a random
   assortment of parameters from its parents. for instance, one child
   might have the same number of layers as its mother and the rest of its
   parameters from its father. a second child of the same parents may have
   the opposite. you can see how this mirrors real-world biology and how
   it can lead to an optimized network quickly.

   now that we understand how it works, let   s actually do it.

dataset

   we   ll use the relatively simple but not easy [18]cifar10 dataset for
   our experiment. this dataset gives us a big enough challenge that most
   parameters won   t do well, while also being easy enough for an mlp to
   get a decent accuracy score.

   note: a convolutional neural network is certainly the better choice for
   a 10-class image classification problem like cifar10. but a fully
   connected network will do just fine for illustrating the effectiveness
   of using a genetic algorithm for hyperparameter tuning.

code explained

   hopefully [19]most of the code is self-explanatory and well-documented.
   (famous last words, i know.) here are parts of the optimizer.py module,
   which holds the meat of the genetic algorithm code. note that this code
   is heavily inspired by an excellent post by will larson, [20]genetic
   algorithms: cool name & damn simple.

   iframe: [21]/media/064c1dec6d4f124dccc3aaa4b7c48589?postid=8809bece164

   we start by creating a population. this instantiates    count    networks
   with randomly initialized settings, and adds them to our    pop    list.
   this is the seed for all generations.

   iframe: [22]/media/124d32fa37c8b1d917306dab90991de5?postid=8809bece164

   breeding children of our fittest networks is where a lot of the magic
   happens. breeding will be different for every application of genetic
   algorithms, and in our case, we   ve decided to randomly choose
   parameters for the child from the mother and father.

   iframe: [23]/media/cbac5b8c80decb9536c30be5f5bca65b?postid=8809bece164

   mutation is also really important as it helps us find chance greatness.
   in our case, we randomly choose a parameter and then randomly choose a
   new parameter for it. it can actually end up mutating to the same
   thing, but that   s all luck of the draw.

   iframe: [24]/media/ac2524d22b555881499ad83dbe055c6b?postid=8809bece164

   the evolve method is where everything is tied together. each run of
   this method is a single evolution. call it enough times, have enough
   babies and mutations, and    well, evolution!

results

   we   ll start by running the brute force algorithm to find the best
   network. that is, we   ll train and test every possible combination of
   network parameters we provided.

   our top result using brute force achieved 56.03% accuracy with the
   following parameters:
     * layers: 2
     * neurons: 768
     * activation: elu
     * optimizer: adamax

   this took 63 hours to run. yikes.

   now we   ll run our genetic algorithm, starting with a population of 20
   randomly initialized networks, and we   ll run it for 10 generations.

   final score? 56.56% accuracy! time? seven hours. and the resulting
   network? almost identical:
     * layers: 2
     * neurons: 512
     * activation: elu
     * optimizer: adamax

   the only difference is the genetic algorithm preferred 512 to 768
   neurons. (in the brute force run, the 512 network achieved 55.65%.
   should   ve set a random seed.)

   so what   s the big deal? the genetic algorithm gave us the same result
   in 1/9th the time! seven hours instead of 63. and it   s likely that as
   the parameter complexity increases, the genetic algorithm provides
   exponential speed benefit.

what   s next?

   i   m looking forward to applying this type of hyperparameter tuning to a
   much more complex problem and network. that will probably require
   distributed training, so perhaps we tackle that next!

   want the code? it   s [25]all right here on github.

     * [26]machine learning
     * [27]artificial intelligence
     * [28]deep learning
     * [29]genetic algorithm
     * [30]keras

   (button)
   (button)
   (button) 2k claps
   (button) (button) (button) 15 (button) (button)

     (button) blockedunblock (button) followfollowing
   [31]go to the profile of matt harvey

[32]matt harvey

   founder of coastline automation, using ai to make every car
   crash-proof.

     (button) follow
   [33]coastline automation

[34]coastline automation

   practical applications of deep learning and research reports from the
   road.

     * (button)
       (button) 2k
     * (button)
     *
     *

   [35]coastline automation
   never miss a story from coastline automation, when you sign up for
   medium. [36]learn more
   never miss a story from coastline automation
   (button) get updatesget updates

references

   visible links
   1. https://plus.google.com/103654360130207659246
   2. https://blog.coast.ai/osd.xml
   3. android-app://com.medium.reader/https/medium.com/p/8809bece164
   4. https://medium.com/
   5. https://medium.com/
   6. https://medium.com/m/signin?redirect=https://blog.coast.ai/lets-evolve-a-neural-network-with-a-genetic-algorithm-code-included-8809bece164&source=--------------------------nav_reg&operation=login
   7. https://medium.com/m/signin?redirect=https://blog.coast.ai/lets-evolve-a-neural-network-with-a-genetic-algorithm-code-included-8809bece164&source=--------------------------nav_reg&operation=register
   8. https://blog.coast.ai/?source=logo-lo_q8mqcd96qwwb---1336970de061
   9. https://blog.coast.ai/training-a-deep-learning-model-to-steer-a-car-in-99-lines-of-code-ba94e0456e6a
  10. https://coast.ai/
  11. https://blog.coast.ai/@harvitronix?source=post_header_lockup
  12. https://blog.coast.ai/@harvitronix
  13. https://en.wikipedia.org/wiki/optimization_(mathematics)
  14. https://en.wikipedia.org/wiki/search_algorithm
  15. https://en.wikipedia.org/wiki/mutation_(genetic_algorithm)
  16. https://en.wikipedia.org/wiki/crossover_(genetic_algorithm)
  17. https://en.wikipedia.org/wiki/selection_(genetic_algorithm)
  18. https://www.cs.toronto.edu/~kriz/cifar.html
  19. https://github.com/harvitronix/neural-network-genetic-algorithm
  20. https://lethain.com/genetic-algorithms-cool-name-damn-simple/
  21. https://blog.coast.ai/media/064c1dec6d4f124dccc3aaa4b7c48589?postid=8809bece164
  22. https://blog.coast.ai/media/124d32fa37c8b1d917306dab90991de5?postid=8809bece164
  23. https://blog.coast.ai/media/cbac5b8c80decb9536c30be5f5bca65b?postid=8809bece164
  24. https://blog.coast.ai/media/ac2524d22b555881499ad83dbe055c6b?postid=8809bece164
  25. https://github.com/harvitronix/neural-network-genetic-algorithm
  26. https://blog.coast.ai/tagged/machine-learning?source=post
  27. https://blog.coast.ai/tagged/artificial-intelligence?source=post
  28. https://blog.coast.ai/tagged/deep-learning?source=post
  29. https://blog.coast.ai/tagged/genetic-algorithm?source=post
  30. https://blog.coast.ai/tagged/keras?source=post
  31. https://blog.coast.ai/@harvitronix?source=footer_card
  32. https://blog.coast.ai/@harvitronix
  33. https://blog.coast.ai/?source=footer_card
  34. https://blog.coast.ai/?source=footer_card
  35. https://blog.coast.ai/
  36. https://medium.com/@medium/personalize-your-medium-experience-with-users-publications-tags-26a41ab1ee0c#.hx4zuv3mg

   hidden links:
  38. https://medium.com/p/8809bece164/share/twitter
  39. https://medium.com/p/8809bece164/share/facebook
  40. https://medium.com/p/8809bece164/share/twitter
  41. https://medium.com/p/8809bece164/share/facebook
