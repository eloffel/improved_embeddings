deep neural networks

are our friends

wang ling

outline

    part i - neural networks are our friends

    numbers are our friends 
    operators are our friends
    functions are our friends
    parameters are our friends
    cost functions are our friends
    optimizers are our friends
    gradients are our friends
    computation graphs are our friends

outline

    part i - neural networks are our friends
    part 2 - into deep learning

    nonlinear neural models
    multilayer id88s
    using discrete variables
    example applications

numbers are our friends

numbers are our friends

abby cadabby

how many apples 
does abby have?

numbers are our friends

abby cadabby

4

numbers are our friends

    types of numbers:

    integers : 5
    rationals : 1/2
    reals : 1.4e10

...

operators are our friends

bert

4

operators are our friends

bert

4

1

if abby has 4 apples, 
and gives bert 1 apple, 
how many apples will 

abby have?

operators are our friends

bert

3

1

operators are our friends

    arithmetic operators

    addition : 23 + 12 = 35
    subtraction : 31 - 15 = 16
    multiplication : 4 x 5 = 20
    division : 20 / 5 = 4

functions are our friends

4

1

functions are our friends

4

1

?

5

if bert always returns 3 
bananas for each apple, 
how many bananas will 
abby receive for 2 apples

functions are our friends

    input, x - number of 
apples given by abby

y = 3x

functions are our friends

y = 3x

    input, x - number of 
apples given by abby
    output, y - number of 

bananas received by abby

functions are our friends

4

1

?

5

y = 3x

functions are our friends

4

1

?

y = 3x , x =1

5

functions are our friends

4

1

3

5

y = 3x , x =1
y = 3

functions are our friends

y = 3x 

functions are our friends

cookie monster

y = 3x 

functions are our friends

y = ?? 

y = 3x 

functions are our friends

y = ?? 

1

0

functions are our friends

y = ?? 

1

5

0

16

functions are our friends

y = ?? 

1

5

6

0

16

20

y = ?? 

functions are our friends
if abby gives cookie monster 
3 apples, how many bananas 

does she get?

1

5

6

3

0

16

20

?

parameters are our friends

y = 3x + 1

    input
    output

parameters are our friends

y = wx + b

    input
    output
    parameters

input - fixed, comes from data
parameters - need to be estimated

parameters are our friends

y = wx + b

1

5

6

3

0

16

20

?

parameters are our friends

y = wx + b

data

1

5

6

3

0

16

20

?

parameters are our friends

y = wx + b

x

1

5

6

y

0

16

20

3

?

parameters are our friends

model

y = wx + b

data

x

1

5

6

y

0

16

20

parameters are our friends

model

y = wx + b

data

x

1

5

6

y

0

16

20

how to find the parameters w and b?

parameters are our friends

data

x

1

5

6

y

0

16

20

model

y = wx + b

model 

candidate 1

y = 1x + 0

x

1

5

6

y

0

16

20

  

1

5

6

parameters are our friends

model

y = wx + b

data

x

1

5

6

y

0

16

20

model 

candidate 1

y = 1x + 0

model 

candidate 2

y = 2x + 2

x

1

5

6

x

1

5

6

y

0

16

20

y

0

16

20

  

1

5

6

  

4

12

14

parameters are our friends

model

y = wx + b

data

x

1

5

6

y

0

16

20

model 

candidate 1

y = 1x + 0

model 

candidate 2

y = 2x + 2

which one is better ?

x

1

5

6

x

1

5

6

y

0

16

20

y

0

16

20

  

1

5

6

  

4

12

14

cost functions are our friends

model

yn = wxn + b

data

x

1

5

6

y

0

16

20

n

0

1

2

model 

candidate 1

y = 1x + 0

model 

candidate 2

y = 2x + 2

x

1

5

6

x

1

5

6

y

0

16

20

y

0

16

20

  

1

5

6

  

4

12

14

cost functions are our friends

model

yn = wxn + b

n

0

1

2

data

x

1

5

6

y

0

16

20

cost

c(w,b) =    (yn-  n)

2

n   {0,1,2}

model 

candidate 1

y = 1x + 0

model 

candidate 2

y = 2x + 2

x

1

5

6

x

1

5

6

y

0

16

20

y

0

16

20

  

1

5

6

  

4

12

14

cost functions are our friends

model

yn = wxn + b

n

0

1

2

data

x

1

5

6

y

0

16

20

cost

c(w,b) =    (yn-  n)

2

n   {0,1,2}

model 

candidate 1

y = 1x + 0

model 

candidate 2

y = 2x + 2

n

0

1

2

x

1

5

6

(y-  )
2

1

x

1

5

6

y

0

16

20

  

1

5

6

y

0

16

20

  

4

12

14

cost functions are our friends

model

yn = wxn + b

n

0

1

2

data

x

1

5

6

y

0

16

20

cost

c(w,b) =    (yn-  n)

2

n   {0,1,2}

model 

candidate 1

y = 1x + 0

model 

candidate 2

y = 2x + 2

n

0

1

2

x

1

5

6

x

1

5

6

y

0

16

20

  

1

5

6

(y-  )
2

1

121

y

0

16

20

  

4

12

14

cost functions are our friends

model

yn = wxn + b

n

0

1

2

data

x

1

5

6

y

0

16

20

cost

c(w,b) =    (yn-  n)

2

n   {0,1,2}

model 

candidate 1

y = 1x + 0

model 

candidate 2

y = 2x + 2

n

0

1

2

x

1

5

6

x

1

5

6

y

0

16

20

  

1

5

6

(y-  )
2

1

121

196

y

0

16

20

  

4

12

14

cost functions are our friends

model

yn = wxn + b

n

0

1

2

data

x

1

5

6

y

0

16

20

cost

c(w,b) =    (yn-  n)

2

n   {0,1,2}

model 

candidate 1

y = 1x + 0

model 

candidate 2

y = 2x + 2

n

0

1

2

x

1

5

6

x

1

5

6

y

0

16

  

1

5

20
6
c(1,0)

(y-  )
2

1

121

196

318

y

0

16

20

  

4

12

14

cost functions are our friends

model

yn = wxn + b

n

0

1

2

data

x

1

5

6

y

0

16

20

cost

c(w,b) =    (yn-  n)

2

n   {0,1,2}

model 

candidate 1

y = 1x + 0

model 

candidate 2

y = 2x + 2

n

0

1

2

n

0

1

2

x

1

5

6

x

1

5

6

y

0

16

  

1

5

20
6
c(1,0)
y
  

0

16

4

12

20
14
c(2,2)

(y-  )
2

1

121

196

318

(y-  )
2

16

16

36

68

cost functions are our friends

model

yn = wxn + b

n

0

1

2

data

x

1

5

6

y

0

16

20

cost

c(w,b) =    (yn-  n)

2

n   {0,1,2}

model 

candidate 1

y = 1x + 0

model 

candidate 2

y = 2x + 2

c(1,0)

318

c(2,2)

68

cost functions are our friends

model

yn = wxn + b

n

0

1

2

data

x

1

5

6

y

0

16

20

cost

c(w,b) =    (yn-  n)

2

n   {0,1,2}

cost functions are our friends

n

0

1

2

data

x

1

5

6

y

0

16

20

cost

model

yn = wxn + b

how to find the parameters w and b?

c(w,b) =    (yn-  n)

2

n   {0,1,2}

optimizers are our friends

model

yn = wxn + b

n

0

1

2

data

x

1

5

6

y

0

16

20

cost

c(w,b) =    (yn-  n)

2

n   {0,1,2}

optimizer

arg min c(w,b)

w,b   [-   ,   ]

optimizers are our friends

optimizer

arg min c(w,b)

w,b   [-   ,   ]

w

b

optimizers are our friends

optimizer

arg min c(w,b)

w,b   [-   ,   ]

w0,b0 = 2,2 : c(w0,b0) = 68

w

y = wx + b

b

optimizers are our friends

optimizer

arg min c(w,b)

w,b   [-   ,   ]

w0,b0 = 2,2 : c(w0,b0) = 68

w

2

y = wx + b

68

2

b

optimizers are our friends

w

y = wx + b

optimizer

arg min c(w,b)

w,b   [-   ,   ]

w0,b0 = 2,2 : c(w0,b0) = 68
w1,b1 = 3,2 : c(w1,b1) = ?

b

optimizers are our friends

optimizer

arg min c(w,b)

w,b   [-   ,   ]

w0,b0 = 2,2 : c(w0,b0) = 68
w1,b1 = 3,2 : c(w1,b1) = 26

n

0

1

2

x

1

5

6

y

0

  

5

16

17

20
20
c(3,2)

2
(y-  )

25

1

0

26

w

y = wx + b

b

optimizers are our friends

optimizer

arg min c(w,b)

w,b   [-   ,   ]

w0,b0 = 2,2 : c(w0,b0) = 68
w1,b1 = 3,2 : c(w1,b1) = 26

n

0

1

2

x

1

5

6

y

0

  

5

16

17

20
20
c(3,2)

2
(y-  )

25

1

0

26

w

y = wx + b

b

optimizers are our friends

w

y = wx + b

optimizer

arg min c(w,b)
w1,b1 = 3,2 : c(w1,b1) = 26
w2,b2 = 4,2 : c(w2,b2) = ??

w,b   [-   ,   ]

b

optimizers are our friends

optimizer

arg min c(w,b)
w1,b1 = 3,2 : c(w1,b1) = 26
w2,b2 = 4,2 : c(w2,b2) = 136

w,b   [-   ,   ]

n

0

1

2

x

1

5

6

y

0

  

6

16

22

20
26
c(4,2)

2
(y-  )

36

64

36

136

w

y = wx + b

b

optimizers are our friends

optimizer

arg min c(w,b)
w1,b1 = 3,2 : c(w1,b1) = 26

w,b   [-   ,   ]

w

y = wx + b

b

optimizers are our friends

optimizer

arg min c(w,b)
w1,b1 = 3,2 : c(w1,b1) = 26
w2,b2 = 3,3 : c(w2,b2) = 41

w,b   [-   ,   ]

n

0

1

2

x

1

5

6

y

0

  

6

16

18

20
21
c(3,3)

2
(y-  )

36

4

1

41

w

y = wx + b

b

optimizers are our friends

optimizer

arg min c(w,b)
w1,b1 = 3,2 : c(w1,b1) = 26

w,b   [-   ,   ]

w

y = wx + b

b

optimizers are our friends

optimizer

arg min c(w,b)
w1,b1 = 3,2 : c(w1,b1) = 26
w2,b2 = 3,1 : c(w2,b2) = 17

w,b   [-   ,   ]

n

0

1

2

x

1

5

6

y

0

  

4

16

16

20
19
c(3,1)

2
(y-  )

16

0

1

17

w

y = wx + b

b

optimizers are our friends

optimizer

arg min c(w,b)
w2,b2 = 3,1 : c(w2,b2) = 17

w,b   [-   ,   ]

w

y = wx + b

b

optimizers are our friends

optimizer

arg min c(w,b)
w2,b2 = 3,1 : c(w2,b2) = 17
w3,b3 = 3,0 : c(w3,b3) = 13

w,b   [-   ,   ]

n

0

1

2

x

1

5

6

y

0

  

3

16

15

20
18
c(3,0)

2
(y-  )

9

1

4

13

w

y = wx + b

b

optimizers are our friends

optimizer

arg min c(w,b)
w3,b3 = 3,0 : c(w3,b3) = 13

w,b   [-   ,   ]

w

y = wx + b

b

optimizers are our friends

optimizer

arg min c(w,b)
w3,b3 = 3,0 : c(w3,b3) = 13
w4,b4 = 3,-1 : c(w4,b4) = 17

w,b   [-   ,   ]

n

0

1

2

x

1

5

6

y

0

  

2

16

14

2
(y-  )

4

4

17

20
9
c(3,-1) 17

w

y = wx + b

b

optimizers are our friends

optimizer

arg min c(w,b)
w3,b3 = 3,0 : c(w3,b3) = 13
w4,b4 = 2,0 : c(w4,b4) = 104

w,b   [-   ,   ]

n

0

1

2

x

1

5

6

y

0

  

2

16

10

20
12
c(2,0)

2
(y-  )

4

36

64

104

w

y = wx + b

b

optimizers are our friends

optimizer

arg min c(w,b)
w3,b3 = 3,0 : c(w3,b3) = 13
w4,b4 = 4,0 : c(w4,b4) = 104

w,b   [-   ,   ]

n

0

1

2

x

1

5

6

y

0

  

4

16

20

20
24
c(2,0)

2
(y-  )

16

16

16

54

w

y = wx + b

b

optimizers are our friends

optimizer

arg min c(w,b)
w3,b3 = 3,0 : c(w3,b3) = 13

w,b   [-   ,   ]

w

y = wx + b

b

optimizers are our friends

optimizer

arg min c(w,b)
w?,b? = 4,-2 : c(w?,b?) = ??

w,b   [-   ,   ]

w

y = wx + b

b

optimizers are our friends

optimizer

arg min c(w,b)
w?,b? = 4,-2 : c(w?,b?) = 12

w,b   [-   ,   ]

n

0

1

2

x

1

5

6

y

0

  

2

16

18

2
(y-  )

4

4

22

20
4
c(4,-2) 12

w

y = wx + b

b

optimizers are our friends

optimizer

arg min c(w,b)
w3,b3 = 3,0 : c(w3,b3) = 13

w,b   [-   ,   ]

w

y = wx + b

b

optimizers are our friends

w

y = wx + b

optimizer

arg min c(w,b)
w3,b3 = 3,0 : c(w3,b3) = 13

w,b   [-   ,   ]

search 
problem

b

optimizers are our friends

w

optimizer

arg min c(w,b)
w3,b3 = 3,0 : c(w3,b3) = 13
w4,b4 = 3.01,0 : c(w4,b4) = 12.82

w,b   [-   ,   ]

y = wx + b

n

0

1

2

x

1

5

6

y

0

  

3.01

16

15.01

20

18.01
c(3.01,0)

2
(y-  )

9.06

0.98

3.96

12.82

b

optimizers are our friends

optimizer

arg min c(w,b)
w*,b* = 4,-2 : c(w*,b*) = 12

w,b   [-   ,   ]

w

y = wx + b

b

optimizers are our friends
w

optimizer

arg min c(w,b)
w*,b* = 4,-2 : c(w*,b*) = 12

w,b   [-   ,   ]

y = wx + b

b

optimizers are our friends
w

optimizer

arg min c(w,b)
w*,b* = 4,-4 : c(w*,b*) = 0

w,b   [-   ,   ]

y = wx + b

b

gradients are our friends

optimizer

arg min c(w,b)

w,b   [-   ,   ]

w

y = wx + b

should be used 
sparingly

b

gradients are our friends

optimizer

arg min c(w,b)

w,b   [-   ,   ]

w0,b0 = 2,2 : c(w0,b0) = 68

w

2

y = wx + b

68

2

b

gradients are our friends

optimizer

arg min c(w,b)

w,b   [-   ,   ]

w0,b0 = 2,2 : c(w0,b0) = 68
hw = 1

w

2

y = wx + b

hw
68

2

b

gradients are our friends

optimizer

arg min c(w,b)

w,b   [-   ,   ]

w0,b0 = 2,2 : c(w0,b0) = 68
hw = 1
c(w0+hw,b0) = c(3,2) = 26

w

2

y = wx + b

hw
68

2

b

gradients are our friends

optimizer

arg min c(w,b)

w,b   [-   ,   ]

w0,b0 = 2,2 : c(w0,b0) = 68
hw = 1
c(w0+hw,b0) = c(3,2) = 26
   (c(w0+1,b0)-c(w0,b0))
rw=
   (c(3,2)-c(2,2))=-42
rw=

1

1

w

2

hw
68

2

y = wx + b

b

gradients are our friends

optimizer

arg min c(w,b)

w,b   [-   ,   ]

w0,b0 = 2,2 : c(w0,b0) = 68
hw = 1, r = -42
hw = 0.1, r = -98
hw = 0.01, r = -104
hw = 0.001, r = -104

w

2

y = wx + b

hw
68

2

b

gradients are our friends

w

2

optimizer

arg min c(w,b)

w,b   [-   ,   ]

w0,b0 = 2,2 : c(w0,b0) = 68
hw = 1, r = -42
hw = 0.1, r = -98
hw = 0.01, r = -104
hw = 0.001, r = -104
                     c 
hw     0, r =
   w

(w0,b0)

hw
68

2

y = wx + b

b

gradients are our friends

optimizer

arg min c(w,b)

w,b   [-   ,   ]

w0,b0 = 2,2 : c(w0,b0) = 68
   c 
   w

      (  n-yn) 2

   w

= 

n

w

2

hw
68

2

y = wx + b

b

gradients are our friends

optimizer

arg min c(w,b)

w,b   [-   ,   ]

w0,b0 = 2,2 : c(w0,b0) = 68
   c 
   w

      (  n-yn) 2

   w

= 

n

n

=    -2(  n-yn)xn 

w

2

hw
68

2

y = wx + b

b

gradients are our friends

optimizer

arg min c(w,b)

w,b   [-   ,   ]

w0,b0 = 2,2 : c(w0,b0) = 68
   c 
   w

      (  n-yn) 2

   w

= 

n

n

=    -2(  n-yn)xn 

hw     0, rw =                   = -104

(w0,b0)

   c 
   w

n

0

1

2

x

1

5

6

y

0

16

20

  

4

12

14

(  -y)

-2(  -y)x

4

-4

-6

8

-40

-72

gradients are our friends

optimizer

arg min c(w,b)

w,b   [-   ,   ]

w0,b0 = 2,2 : c(w0,b0) = 68
   c 
   w

      (  n-yn) 2

   w

= 

n

n

=    -2(  n-yn)xn 

   c 
   b

= 

      (  n-yn) 2

n

   b

=    -2(  n-yn) 

n

w

2

hw
68

2

y = wx + b

b

gradients are our friends

optimizer

arg min c(w,b)

w,b   [-   ,   ]

w0,b0 = 2,2 : c(w0,b0) = 68

hw     0, rw =                   = -104

(w0,b0)

hb     0, rb =                   = -12

(w0,b0)

   c 
   w
   c 
   w

n

0

1

2

x

1

5

6

y

0

16

20

  

4

12

14

(  -y)

-2(  -y)

4

-4

-6

8

-8

-12

gradients are our friends

optimizer

arg min c(w,b)

w,b   [-   ,   ]

w0,b0 = 2,2 : c(w0,b0) = 68

hw     0, rw =                   = -104

(w0,b0)

hb     0, rb =                   = -12

(w0,b0)

   c 
   w
   c 
   w

w

2

w1 = w0 - rw(cid:7745)
b1 = b0 - rb(cid:7745)

(cid:7745)     learning rate

2

y = wx + b

b

gradients are our friends

y = 4x-4 

data

1

5

6

3

0

16

20

?

gradients are our friends

y = 4x-4 

data

1

5

6

3

0

16

20

8

computation graphs are our friends

c(w,b) =    (yn-  n)

2

n   {0,1,2}

y = wx + b

   c 
   w

= 

      (  n-yn) 

2

n

   w

=    -2(  n-yn)xn 

n

easy!

   c 
   b

= 

      (  n-yn) 2

n

   b

=    -2(  n-yn) 

n

computation graphs are our friends

y = wx + b + tanh(yx + b)2

harder!

computation graphs are our friends

y = wx + b + tanh(yx + b)2

computation 
graphs can 

compute 

gradients for you!

computation graphs are our friends

c(w,b) =    (yn-  n)

2

n   {0,1,2}

y = wx + b

   c 
   w

= 

      (  n-yn) 

2

n

   w

=    -2(  n-yn)xn 

n

   c 
   b

= 

      (  n-yn) 2

n

   b

=    -2(  n-yn) 

n

computation graphs are our friends

c(w,b) =    (yn-  n)

2

n   {0,1,2}

y = wx + b

   c 
   w

     (  n-yn) 
   
= 

2

n

   yn

   yn
   w

=    -2(  n-yn)xn 

n

   c 
   b

2

     (  n-yn) 
   
= 

n

   yn

   yn
   b

=    -2(  n-yn) 

n

computation graphs are our friends

c(w,b) =    (yn-  n)

2

n   {0,1,2}

y = wx + b

   c 
   w

     (  n-yn) 
   
= 

2

n

   yn

   yn
   w

   c 
   b

2

     (  n-yn) 
   
= 

n

   yn

   yn
   b

computation graphs are our friends

c(w,b) =    (yn-  n)

2

n   {0,1,2}

y = o + b
o = wx

   c 
   w

     (  n-yn) 
   
= 

2

n

   yn

   yn
   w

   c 
   b

2

     (  n-yn) 
   
= 

n

   yn

   yn
   b

computation graphs are our friends

c(w,b) =    cn

n   {0,1,2}

   c 
   w

     (  n-yn) 
   
= 

2

n

   yn

   yn
   w

2

c = d
d = y -   
y = o + b
o = wx

   c 
   b

2

     (  n-yn) 
   
= 

n

   yn

   yn
   b

computation graphs are our friends

c(w,b) =    cn

n   {0,1,2}

   c 
   w

   
= 

n

     cn 
   dn

   dn
   yn

   yn
   on

   on
   w

2

c = d
d = y -   
y = o + b
o = wx

   c 
   b

2

     (  n-yn) 
   
= 

n

   yn

   yn
   b

computation graphs are our friends

c(w,b) =    cn

n   {0,1,2}

   c 
   w

   
= 

n

     cn 
   dn

   dn
   yn

   yn
   on

   on
   w

   c 
   b

   
= 

n

     cn 
   dn

   dn
   yn

   yn
   b

2

c = d
d = y -   
y = o + b
o = wx

computation graphs are our friends

c(w,b) =    cn

n   {0,1,2}

   c 
   w

   
= 

n

     cn 
   dn

   dn
   yn

   yn
   on

   on
   w

   c 
   b

   
= 

n

     cn 
   dn

   dn
   yn

   yn
   b

2

c = d
d = y -   
y = o + b
o = wx

power 2

sub

add

product

sub

computation graphs are our friends

c(w,b) =    cn

n   {0,1,2}

   c 
   w

   
= 

n

     cn 
   dn

   dn
   yn

   yn
   on

   on
   w

   c 
   b

   
= 

n

     cn 
   dn

   dn
   yn

   yn
   b

2

c = d
d = y -   
y = o + b
o = wx

power 2

sub

add

product

sub

forward(x,y)     z
backward(x,y,dz)     dx,dy

computation graphs are our friends

c(w,b) =    cn

n   {0,1,2}

   c 
   w

   
= 

n

     cn 
   dn

   dn
   yn

   yn
   on

   on
   w

   c 
   b

   
= 

n

     cn 
   dn

   dn
   yn

   yn
   b

2

c = d
d = y -   
y = o + b
o = wx

power 2

sub

add

product

sub

forward(x,y) : return x - y
backward(x,y,dz) : return dz, -dz

computation graphs are our friends

c(w,b) =    cn

n   {0,1,2}

   c 
   w

   
= 

n

     cn 
   dn

   dn
   yn

   yn
   on

   on
   w

   c 
   b

   
= 

n

     cn 
   dn

   dn
   yn

   yn
   b

2

c = d
d = y -   
y = o + b
o = wx

power 2

sub

add

product

sub

forward(x,y) : return x - y
backward(x,y,dz) : return dz, -dz

computation graphs are our friends

c(w,b) =    cn

n   {0,1,2}

   c 
   w

   
= 

n

     cn 
   dn

   dn
   yn

   yn
   on

   on
   w

   c 
   b

   
= 

n

     cn 
   dn

   dn
   yn

   yn
   b

2

c = d
d = y -   
y = o + b
o = wx

sub

forward(x,y) : return x - y
backward(x,y,dz) : return 1, -1

power 2

sub

add

product

   dn
     n

computation graphs are our friends

c(w,b) =    cn

n   {0,1,2}

   c 
   w

   
= 

n

     cn 
   dn

   dn
   yn

   yn
   on

   on
   w

   c 
   b

   
= 

n

     cn 
   dn

   dn
   yn

   yn
   b

2

c = d
d = y -   
y = o + b
o = wx

power 2

sub

add

product

o

product

w

x

computation graphs are our friends

c(w,b) =    cn

n   {0,1,2}

   c 
   w

   
= 

n

     cn 
   dn

   dn
   yn

   yn
   on

   on
   w

   c 
   b

   
= 

n

     cn 
   dn

   dn
   yn

   yn
   b

2

c = d
d = y -   

power 2

sub

y

add

o

b

product

w

x

computation graphs are our friends

c(w,b) =    cn

n   {0,1,2}

   c 
   w

   
= 

n

     cn 
   dn

   dn
   yn

   yn
   on

   on
   w

   c 
   b

   
= 

n

     cn 
   dn

   dn
   yn

   yn
   b

power 2

c

d

sub

  

y

add

o

b

product

w

x

computation graphs are our friends

power 2

c

id

c

c(w,b) =    cn

n   {0}

   c 
   w

   
= 

n

     cn 
   dn

   dn
   yn

   yn
   on

   on
   w

y

add

d

sub

  

   c 
   b

   
= 

n

     cn 
   dn

   dn
   yn

   yn
   b

o

b

product

w

x

computation graphs are our friends

c(w,b) =    cn

n   {0}

   c 
   w

   
= 

n

     cn 
   dn

   dn
   yn

   yn
   on

   on
   w

y

add

d

sub

  

   c 
   b

   
= 

n

     cn 
   dn

   dn
   yn

   yn
   b

o

b

product

w

x

power 2

c

id

c

input

computation graphs are our friends

c(w,b) =    cn

n   {0}

   c 
   w

   
= 

n

     cn 
   dn

   dn
   yn

   yn
   on

   on
   w

y

add

d

sub

  

   c 
   b

   
= 

n

     cn 
   dn

   dn
   yn

   yn
   b

o

b

product

w

x

power 2

c

id

c

input

parameters

computation graphs are our friends

forward:

1-initialize inputs

power 2

c

id

c

d

sub

y

add

  

16

b

2

o

product

w

2

x

5

computation graphs are our friends

forward:

1-initialize inputs
2-initialize variables

power 2

c

id

c

variables

d

sub

y

add

  

16

b

2

o

product

w

2

x

5

computation graphs are our friends

forward:

1-initialize inputs
2-initialize variables

power 2

id

c
0,0

c
0,0

d

0,0

sub

  

16

y

0,0

add

o

0,0

product

b

2

w

2

x

5

variables

2 values: x and dx

computation graphs are our friends

forward:

1-initialize inputs
2-initialize variables
3-topological sort variables

power 2

id

c
0,0

c
0,0

d

0,0

sub

  

16

y

0,0

add

o

0,0

product

b

2

w

2

x

5

computation graphs are our friends

forward:

1-initialize inputs
2-initialize variables
3-topological sort variables

3rd

d

0,0

sub

power 2

id

c
0,0

c
0,0

4th

5th

2nd

  

16

y

0,0

add

1st

o

0,0

product

b

2

w

2

x

5

computation graphs are our friends

forward:

1-initialize inputs
2-initialize variables
3-topological sort variables

3rd

d

0,0

sub

power 2

id

c
0,0

c
0,0

4th

5th

2nd

  

16

y

0,0

add

1st

o

10,0

b

2

product

w

2

x

5

computation graphs are our friends

forward:

1-initialize inputs
2-initialize variables
3-topological sort variables

3rd

d

0,0

sub

power 2

id

c
0,0

c
0,0

4th

5th

2nd

y

12,0

  

16

add

1st

o

10,0

b

2

product

w

2

x

5

computation graphs are our friends

forward:

1-initialize inputs
2-initialize variables
3-topological sort variables

3rd

d

0,0

sub

power 2

id

c
0,0

c
0,0

4th

5th

1st

  

16

y

0,0

add

2nd

o

0,0

product

b

2

w

2

x

5

computation graphs are our friends

forward:

1-initialize inputs
2-initialize variables
3-topological sort variables

3rd

d

0,0

sub

power 2

id

c
0,0

c
0,0

4th

5th

1st

  

16

y

2,0

add

2nd

o

0,0

product

b

2

w

2

x

5

computation graphs are our friends

forward:

1-initialize inputs
2-initialize variables
3-topological sort variables

3rd

d

0,0

sub

power 2

id

c
0,0

c
0,0

4th

5th

1st

  

16

y

2,0

add

o

10,0

b

2

product

w

2

x

5

2nd

computation graphs are our friends

forward:

1-initialize inputs
2-initialize variables
3-topological sort variables

power 2

id

c
0,0

c
0,0

d

0,0

sub

  

16

y

0,0

add

o

0,0

product

b

2

w

2

x

5

computation graphs are our friends

forward:

1-initialize inputs
2-initialize variables
3-topological sort variables

d

0,0

sub

power 2

id

c
0,0

c
0,0

y

0,0

add

o

0,0

computation graphs are our friends

forward:

1-initialize inputs
2-initialize variables
3-topological sort variables

4th

c
0,0

3rd

d

0,0

2nd

y

0,0

1st

o

0,0

5th

c
0,0

computation graphs are our friends

forward:

1-initialize inputs
2-initialize variables
3-topological sort variables

d

0,0

sub

power 2

add

c
0,0

c
0,0

y

0,0

add

g

0,0

o

0,0

add

s

0,0

computation graphs are our friends

forward:

1-initialize inputs
2-initialize variables
3-topological sort variables

5th

d

0,0

6th

7th

c
0,0

c
0,0

4th

y

0,0

g

3th

0,0

1st

o

0,0

2nd

s

0,0

computation graphs are our friends

forward:

1-initialize inputs
2-initialize variables
3-topological sort variables
4-for each variable in topological 

order, run the forward method of all 
operations that link to them

3rd

d

0,0

sub

power 2

id

c
0,0

c
0,0

4th

5th

2nd

  

16

y

0,0

add

1st

o

0,0

product

b

2

w

2

x

5

computation graphs are our friends

forward:

1-initialize inputs
2-initialize variables
3-topological sort variables
4-for each variable in topological 

order, run the forward method of all 
operations that link to them

3rd

d

0,0

sub

power 2

id

c
0,0

c
0,0

4th

5th

2nd

  

16

y

0,0

add

1st

o

10,0

product

b

2

w

2

x

5

computation graphs are our friends

forward:

1-initialize inputs
2-initialize variables
3-topological sort variables
4-for each variable in topological 

order, run the forward method of all 
operations that link to them

3rd

d

0,0

sub

power 2

id

c
0,0

c
0,0

4th

5th

2nd

y

12,0

  

16

1st

o

add

10,0

b

2

product

w

2

x

5

computation graphs are our friends

forward:

1-initialize inputs
2-initialize variables
3-topological sort variables
4-for each variable in topological 

order, run the forward method of all 
operations that link to them

3rd

d

-4,0

power 2

id

c
0,0

c
0,0

sub

4th

5th

2nd

y

12,0

  

16

1st

o

add

10,0

b

2

product

w

2

x

5

computation graphs are our friends

forward:

1-initialize inputs
2-initialize variables
3-topological sort variables
4-for each variable in topological 

order, run the forward method of all 
operations that link to them

3rd

d

-4,0

power 2

id

c
16,0

c
0,0

sub

4th

5th

2nd

y

12,0

  

16

1st

o

add

10,0

b

2

product

w

2

x

5

computation graphs are our friends

forward:

1-initialize inputs
2-initialize variables
3-topological sort variables
4-for each variable in topological 

order, run the forward method of all 
operations that link to them

3rd

d

-4,0

power 2

id

c
16,0

c
16,0

sub

4th

5th

2nd

y

12,0

  

16

1st

o

add

10,0

b

2

product

w

2

x

5

computation graphs are our friends

forward:

1-initialize inputs
2-initialize variables
3-topological sort variables
4-for each variable in topological 

order, run the forward method of all 
operations that link to them

5-set gradients to final variables

3rd

d

-4,0

power 2

sub

4th

id

c
16,0

c
16,1

5th

2nd

y

12,0

  

16

1st

o

add

10,0

b

2

product

w

2

x

5

computation graphs are our friends

forward:

1-initialize inputs
2-initialize variables
3-topological sort variables
4-for each variable in topological 

order, run the forward method of all 
operations that link to them (forward)
5-set gradients to final variables
6-run the operations backward method 
1st

in reverse order (backward)

3rd

d

-4,0

power 2

sub

4th

id

c
16,0

c
16,1

5th

2nd

y

12,0

  

16

add

o

10,0

b

2

product

w

2

x

5

  c=c 

=1

     c 
   c
     c 
   c

dc = dc  

computation graphs are our friends

forward:

1-initialize inputs
2-initialize variables
3-topological sort variables
4-for each variable in topological 

order, run the forward method of all 
operations that link to them (forward)
5-set gradients to final variables
6-run the operations backward method 
1st

in reverse order (backward)

3rd

d

-4,0

power 2

sub

4th

id

c
16,1

c
16,1

5th

2nd

y

12,0

  

16

add

o

10,0

b

2

product

w

2

x

5

  c=c 

=1

     c 
   c
     c 
   c

dc = dc  

computation graphs are our friends

forward:

1-initialize inputs
2-initialize variables
3-topological sort variables
4-for each variable in topological 

order, run the forward method of all 
operations that link to them (forward)
5-set gradients to final variables
6-run the operations backward method 
1st

in reverse order (backward)

3rd

d

-4,0

power 2

sub

4th

id

c
16,1

c
16,1

5th

2nd

y

12,0

  

16

add

o

10,0

b

2

product

w

2

x

5

     c 
   d

= 2d

2

c = d

dd = dc  

     c 
   d

computation graphs are our friends

forward:

1-initialize inputs
2-initialize variables
3-topological sort variables
4-for each variable in topological 

order, run the forward method of all 
operations that link to them (forward)
5-set gradients to final variables
6-run the operations backward method 
1st

in reverse order (backward)

3rd

d

-4,0

power 2

sub

4th

id

c
16,1

c
16,1

5th

2nd

y

12,0

  

16

add

o

10,0

b

2

product

w

2

x

5

     c 
   d

= 2 x -4

2

c = d

dd = dc  

     c 
   d

computation graphs are our friends

forward:

1-initialize inputs
2-initialize variables
3-topological sort variables
4-for each variable in topological 

order, run the forward method of all 
operations that link to them (forward)
5-set gradients to final variables
6-run the operations backward method 
1st

in reverse order (backward)

3rd

d

-4,0

power 2

sub

4th

id

c
16,1

c
16,1

5th

2nd

y

12,0

  

16

add

o

10,0

b

2

product

w

2

x

5

     c 
   d

= -8

2

c = d

dd = dc  

     c 
   d

computation graphs are our friends

forward:

1-initialize inputs
2-initialize variables
3-topological sort variables
4-for each variable in topological 

order, run the forward method of all 
operations that link to them (forward)
5-set gradients to final variables
6-run the operations backward method 
1st

in reverse order (backward)

3rd

d

-4,-8

power 2

sub

4th

id

c
16,1

c
16,1

5th

2nd

y

12,0

  

16

add

o

10,0

b

2

product

w

2

x

5

     c 
   d

= -8

2

c = d

dd = dc  

     c 
   d

computation graphs are our friends

forward:

1-initialize inputs
2-initialize variables
3-topological sort variables
4-for each variable in topological 

order, run the forward method of all 
operations that link to them (forward)
5-set gradients to final variables
6-run the operations backward method 
1st

in reverse order (backward)

3rd

d

-4,-8

power 2

sub

4th

id

c
16,1

c
16,1

5th

2nd

y

12,0

  

16

add

o

10,0

b

2

d = y -   

     d 
   y

= 1

product

w

2

x

5

computation graphs are our friends

forward:

1-initialize inputs
2-initialize variables
3-topological sort variables
4-for each variable in topological 

order, run the forward method of all 
operations that link to them (forward)
5-set gradients to final variables
6-run the operations backward method 
1st

in reverse order (backward)

3rd

d

-4,-8

power 2

sub

4th

id

c
16,1

c
16,1

5th

2nd

y

12,-8

  

16

add

o

10,0

b

2

product

w

2

x

5

     d 
   y

= 1

d = y -   

dy = dd  

     d 
   y

computation graphs are our friends

forward:

1-initialize inputs
2-initialize variables
3-topological sort variables
4-for each variable in topological 

order, run the forward method of all 
operations that link to them (forward)
5-set gradients to final variables
6-run the operations backward method 
1st

in reverse order (backward)

3rd

d

-4,-8

power 2

sub

4th

id

c
16,1

c
16,1

5th

2nd

y

12,-8

  

16

y = o + b

add

o

10,-8

b

2

     y 
   o

= 1

do = dy  

     y 
   o

product

w

2

x

5

computation graphs are our friends

forward:

1-initialize inputs
2-initialize variables
3-topological sort variables
4-for each variable in topological 

order, run the forward method of all 
operations that link to them (forward)
5-set gradients to final variables
6-run the operations backward method 
1st

in reverse order (backward)

3rd

d

-4,-8

power 2

sub

4th

id

c
16,1

c
16,1

5th

2nd

y

12,-8

  

16

y = o + b

add

o

10,-8

b

2

     y 
   o

= 1

     y 
   b

= 1

product

w

2

x

5

bt+1 = b - (cid:7513)dy  

     y 
   b

computation graphs are our friends

forward:

1-initialize inputs
2-initialize variables
3-topological sort variables
4-for each variable in topological 

order, run the forward method of all 
operations that link to them (forward)
5-set gradients to final variables
6-run the operations backward method 
1st

in reverse order (backward)

3rd

d

-4,-8

power 2

sub

4th

id

c
16,1

c
16,1

5th

2nd

y

12,-8

  

16

y = o + b

add

o

10,-8

b

2

     y 
   o

= 1

     y 
   b

= 1

product

w

2

x

5

bt+1 = b - (cid:7513)dy  

     y 
   b

computation graphs are our friends

forward:

1-initialize inputs
2-initialize variables
3-topological sort variables
4-for each variable in topological 

order, run the forward method of all 
operations that link to them (forward)
5-set gradients to final variables
6-run the operations backward method 
1st

in reverse order (backward)

3rd

d

-4,-8

power 2

sub

4th

id

c
16,1

c
16,1

5th

2nd

y

12,-8

  

16

y = o + b

add

o

10,-8

b

2

     y 
   o

= 1

     y 
   b

= 1

product

w

2

x

5

bt+1 = b - (cid:7513)  

     c 
   c

     c 
   d

   d
   y

   y
   b

computation graphs are our friends

forward:

1-initialize inputs
2-initialize variables
3-topological sort variables
4-for each variable in topological 

order, run the forward method of all 
operations that link to them (forward)
5-set gradients to final variables
6-run the operations backward method 
1st

in reverse order (backward)

3rd

d

-4,-8

power 2

sub

4th

id

c
16,1

c
16,1

5th

2nd

y

12,-8

  

16

y = o + b

add

o

10,-8

b

2

     y 
   o

= 1

     y 
   b

= 1

product

w

2

x

5

bt+1 = b - (cid:7513)       c 
   b

computation graphs are our friends

forward:

1-initialize inputs
2-initialize variables
3-topological sort variables
4-for each variable in topological 

order, run the forward method of all 
operations that link to them (forward)
5-set gradients to final variables
6-run the operations backward method 
1st

in reverse order (backward)

3rd

d

-4,-8

power 2

sub

4th

id

c
16,1

c
16,1

5th

2nd

y

12,-8

  

16

add

o

10,-8

b

2

o = wx
     o 
   w

= x

product

w

2

x

5

wt+1 = w - (cid:7513) do       o 
   w

computation graphs are our friends

forward:

1-initialize inputs
2-initialize variables
3-topological sort variables
4-for each variable in topological 

order, run the forward method of all 
operations that link to them (forward)
5-set gradients to final variables
6-run the operations backward method 
1st

in reverse order (backward)
7-update parameters

3rd

d

-4,-8

power 2

sub

4th

id

c
16,1

c
16,1

5th

2nd

y

12,-8

  

16

add

o

10,-8

b

2.2

o = wx
     o 
   w

= x

product

w

2.8

x

5

wt+1 = w - (cid:7513) do       o 
   w

computation graphs are our friends

existing tools:
-tensorflow ( https://www.tensorflow.org )
-torch ( https://github.com/torch/nn )
-id98 ( https://github.com/clab/id98 )
-jnn ( https://github.com/wlin12/jnn )
-theano (http://deeplearning.net/software/theano/ )

d

-4,-8

power 2

id

c
16,1

c
16,1

sub

y

12,-8

  

16

add

o = wx
     o 
   w

= x

o

10,-8

b

2.2

product

w

2.8

x

5

wt+1 = w - (cid:7513) do       o 
   w

into deep learning

nonlinear neural models

y = 4x-4 

data

1

5

6

3

0

16

20

?

nonlinear neural models

data

there is a limit 
of bananas i 
can give you

1

5

6

3

0

16

20

?

nonlinear neural models

data

x

1

5

6

y

0

16

20

n

0

1

2

y

y = 4x-4 

x

nonlinear neural models

y = 4x-4 

y

data

x

1

5

6

9

11

y

0

16

20

20

20

n

0

1

2

3

4

x

nonlinear neural models

y = 2x+3 

y

data

n

0

1

2

3

4

x

1

5

6

9

11

y

0

16

20

20
model 
problem
20

x

nonlinear neural models

y

y = 2x+3 

underfitting

x

data

n

0

1

2

3

4

x

1

5

6

9

11

y

0

16

20

20
model 
problem
20

nonlinear neural models

y = ???

data

x

1

5

6

9

11

y

0

16

20

20

20

n

0

1

2

3

4

y

can we learn 
arbitrary functions?

x

nonlinear neural models

y = (w1x + b1)s1 + (w2x+b2)s2

use different linear functions 
depending on the value of x?

nonlinear neural models

y = (w1x + b1)s1 + (w2x+b2)s2

s1 - 1 if x < 6 and 0 otherwise
s2 - 1 if x >= 6 and 0 otherwise

nonlinear neural models

y = (w1x + b1)s1 + (w2x+b2)s2

s1 - 1 if x < 6 and 0 otherwise
s2 - 1 if x >= 6 and 0 otherwise

y = (4x - 4)s1 + (0x+20)s2

data

x

1

5

6

9

11

y

0

16

20

20

20

n

0

1

2

3

4

nonlinear neural models

s = (cid:7705)(wx + b)

(cid:7705)(t) =  1

1 + e-t

nonlinear neural models

s = (cid:7705)(1000x)

x = 0.1 then (cid:7705)(1000x) = 1
x = -0.1 then (cid:7705)(1000x) = 0

nonlinear neural models

s = (cid:7705)(1000x)

x = 0.1 then (cid:7705)(1000x) = 1
x = -0.1 then (cid:7705)(1000x) = 0

nonlinear neural models

s = (cid:7705)(1000x - 6000)

x = 6.1 then (cid:7705)(1000x - 6000) = 1
x = 5.9 then (cid:7705)(1000x - 6000) = 0

nonlinear neural models

y = (w1x + b1)s1 + (w2x+b2)s2
s1 = (cid:7705)(w3x + b3)
s2 = (cid:7705)(w4x + b4)

nonlinear neural models

y = (4x - 4)s1 + (0x+20)s2
s1 = (cid:7705)(-1000x + 6000)
s2 = (cid:7705)(1000x - 6000)

data

x

1

5

6

9

11

y

0

16

20

20

20

n

0

1

2

3

4

nonlinear neural models

y = (4x - 4)s1 + (0x+20)s2
s1 = (cid:7705)(-1000x + 6000)
s2 = (cid:7705)(1000x - 6000)

data

x

1

5

6

9

11

y

0

16

20

20

20

n

0

1

2

3

4

nonlinear neural models

y = (16)s1 + (0x+20)s2
s1 = (cid:7705)(-1000x + 6000)
s2 = (cid:7705)(1000x - 6000)

data

x

1

5

6

9

11

y

0

16

20

20

20

n

0

1

2

3

4

nonlinear neural models

y = (16)s1 + (20)s2
s1 = (cid:7705)(-1000x + 6000)
s2 = (cid:7705)(1000x - 6000)

data

x

1

5

6

9

11

y

0

16

20

20

20

n

0

1

2

3

4

nonlinear neural models

y = (16)s1 + (20)s2
s1 = (cid:7705)(1000)
s2 = (cid:7705)(1000x - 6000)

data

x

1

5

6

9

11

y

0

16

20

20

20

n

0

1

2

3

4

nonlinear neural models

y = (16)s1 + (20)s2
s1 = (cid:7705)(1000)
s2 = (cid:7705)(-1000)

data

x

1

5

6

9

11

y

0

16

20

20

20

n

0

1

2

3

4

nonlinear neural models

y = (16)1 + (20)0
s1 = (cid:7705)(1000)
s2 = (cid:7705)(-1000)

data

x

1

5

6

9

11

y

0

16

20

20

20

n

0

1

2

3

4

nonlinear neural models

y = 16
s1 = (cid:7705)(1000)
s2 = (cid:7705)(-1000)

data

x

1

5

6

9

11

y

0

16

20

20

20

n

0

1

2

3

4

nonlinear neural models

y = (4x - 4)s1 + (0x+20)s2
s1 = (cid:7705)(-1000x + 6000)
s2 = (cid:7705)(1000x - 6000)

data

x

1

5

6

9

11

y

0

16

20

20

20

n

0

1

2

3

4

nonlinear neural models

y = (32)s1 + (0x+20)s2
s1 = (cid:7705)(-1000x + 6000)
s2 = (cid:7705)(1000x - 6000)

data

x

1

5

6

9

11

y

0

16

20

20

20

n

0

1

2

3

4

nonlinear neural models

y = (32)s1 + (20)s2
s1 = (cid:7705)(-1000x + 6000)
s2 = (cid:7705)(1000x - 6000)

data

x

1

5

6

9

11

y

0

16

20

20

20

n

0

1

2

3

4

nonlinear neural models

y = (32)s1 + (20)s2
s1 = (cid:7705)(-3000)
s2 = (cid:7705)(1000x - 6000)

data

x

1

5

6

9

11

y

0

16

20

20

20

n

0

1

2

3

4

nonlinear neural models

y = (32)s1 + (20)s2
s1 = (cid:7705)(-3000)
s2 = (cid:7705)(3000)

data

x

1

5

6

9

11

y

0

16

20

20

20

n

0

1

2

3

4

nonlinear neural models

y = (32)0 + (20)1
s1 = (cid:7705)(-3000)
s2 = (cid:7705)(3000)

data

x

1

5

6

9

11

y

0

16

20

20

20

n

0

1

2

3

4

nonlinear neural models

y = 20
s1 = (cid:7705)(-3000)
s2 = (cid:7705)(3000)

data

x

1

5

6

9

11

y

0

16

20

20

20

n

0

1

2

3

4

nonlinear neural models

if you give me 
too many 
apples, i will 
give them to...

data

1

5

6

3

0

16

20

?

nonlinear neural models

count von count

data

1

5

6

3

0

16

20

?

multilayer id88s

y

y = (4x - 4)s1 + (0x+20)s2

x

data

x

1

5

6

9

11

y

0

16

20

20

20

n

0

1

2

3

4

multilayer id88s

y

y = (4x - 4)s1 + (0x+20)s2

x

data

x

1

5

6

9

11

15

19

y

0

16

20

20

20

1

1

n

0

1

2

3

4

5

6

multilayer id88s

data

x

1

5

6

9

11

15

19

y

0

16

20

20

20

1

1

n

0

1

2

3

4

5

6

y = (4x - 4)s1 + (0x+20)s2 + (0x+1)s3 
s1 = (cid:7705)(-1000x + 6000)
s2 = ????
s3 = (cid:7705)(1000x - 15000)

multilayer id88s

y = (4x - 4)s1 + (0x+20)s2 + (0x+1)s3 
s1 = (cid:7705)(-1000x + 6000)
s2 = not s1 and not s3
s3 = (cid:7705)(1000x - 15000)

data

x

1

5

6

9

11

15

19

y

0

16

20

20

20

1

1

n

0

1

2

3

4

5

6

multilayer id88s

y = (w1x + b1)s1 + (w2x+b2)s2 + (w3x+b3)s3
s1 = (cid:7705)(w4x + b4)
s2 = (cid:7705)(w5s1 + w6s3 + b5)
s3 = (cid:7705)(w7x + b6)

multilayer id88s

y = (w1x + b1)s1 + (w2x+b2)s2 + (w3x+b3)s3
s1 = (cid:7705)(w4x + b4)
s2 = (cid:7705)(w5s1 + w6s3 + b5)
s3 = (cid:7705)(w7x + b6)

layer 1 id88

layer 1 id88

multilayer id88s

y = (w1x + b1)s1 + (w2x+b2)s2 + (w3x+b3)s3
s1 = (cid:7705)(w4x + b4)
s2 = (cid:7705)(w5s1 + w6s3 + b5)
s3 = (cid:7705)(w7x + b6)

layer 2 id88

layer 1 id88

layer 1 id88

multilayer id88s

y = (4x - 4)s1 + (0x+20)s2 + (0x+1)s3 
s1 = (cid:7705)(-1000x + 6000)
s2 = not s1 and not s3
s3 = (cid:7705)(1000x - 15000)

data

x

1

5

6

9

11

15

19

y

0

16

20

20

20

1

1

n

0

1

2

3

4

5

6

multilayer id88s

y = (4x - 4)s1 + (0x+20)s2 + (0x+1)s3 
s1 = (cid:7705)(-1000x + 6000)
s2 = (cid:7705)(-1000s1 - 1000s3 + 500)
s3 = (cid:7705)(1000x - 15000)

data

x

1

5

6

9

11

15

19

y

0

16

20

20

20

1

1

n

0

1

2

3

4

5

6

multilayer id88s

y = (4x - 4)s1 + (0x+20)s2 + (0x+1)s3 
s1 = (cid:7705)(-1000x + 6000)
s2 = (cid:7705)(-1000s1 - 1000s3 + 500)
s3 = (cid:7705)(1000x - 15000)

data

x

1

5

6

9

11

15

19

y

0

16

20

20

20

1

1

n

0

1

2

3

4

5

6

multilayer id88s

y = (40)s1 + (20)s2 + (1)s3 
s1 = (cid:7705)(-1000x + 6000)
s2 = (cid:7705)(-1000s1 - 1000s3 + 500)
s3 = (cid:7705)(1000x - 15000)

data

x

1

5

6

9

11

15

19

y

0

16

20

20

20

1

1

n

0

1

2

3

4

5

6

multilayer id88s

y = (40)s1 + (20)s2 + (1)s3 
s1 = (cid:7705)(-5000) = 0
s2 = (cid:7705)(-1000s1 - 1000s3 + 500)
s3 = (cid:7705)(-4000) = 0

data

x

1

5

6

9

11

15

19

y

0

16

20

20

20

1

1

n

0

1

2

3

4

5

6

multilayer id88s

y = (40)s1 + (20)s2 + (1)s3 
s1 = (cid:7705)(-5000) = 0
s2 = (cid:7705)(-1000s4 - 1000s5 + 500)
s3 = (cid:7705)(-4000) = 0

data

x

1

5

6

9

11

15

19

y

0

16

20

20

20

1

1

n

0

1

2

3

4

5

6

multilayer id88s

y = (40)s1 + (20)s2 + (1)s3 
s1 = (cid:7705)(-5000) = 0
s2 = (cid:7705)(500)
s3 = (cid:7705)(-4000) = 0

data

x

1

5

6

9

11

15

19

y

0

16

20

20

20

1

1

n

0

1

2

3

4

5

6

multilayer id88s

y = (40)s1 + (20)s2 + (1)s3 
s1 = (cid:7705)(-5000) = 0
s2 = (cid:7705)(500) = 1
s3 = (cid:7705)(-4000) = 0

data

x

1

5

6

9

11

15

19

y

0

16

20

20

20

1

1

n

0

1

2

3

4

5

6

multilayer id88s

y = (40)0 + (20)1 + (1)0
s1 = (cid:7705)(-5000) = 0
s2 = (cid:7705)(500) = 1
s3 = (cid:7705)(-4000) = 0

data

x

1

5

6

9

11

15

19

y

0

16

20

20

20

1

1

n

0

1

2

3

4

5

6

multilayer id88s

y = 20
s1 = (cid:7705)(-5000) = 0
s2 = (cid:7705)(500) = 1
s3 = (cid:7705)(-4000) = 0

data

x

1

5

6

9

11

15

19

y

0

16

20

20

20

1

1

n

0

1

2

3

4

5

6

multilayer id88s

y = (4x - 4)s1 + (0x+20)s2 + (0x+1)s3 
s1 = (cid:7705)(-1000x + 6000)
s2 = (cid:7705)(-1000s1 - 1000s3 + 500)
s3 = (cid:7705)(1000x - 15000)

data

x

1

5

6

9

11

15

19

y

0

16

20

20

20

1

1

n

0

1

2

3

4

5

6

multilayer id88s

y = (772)s1 + (20)s2 + (1)s3 
s1 = (cid:7705)(-1000x + 6000)
s2 = (cid:7705)(-1000s4 - 1000s5 + 500)
s3 = (cid:7705)(1000x - 15000)

data

x

1

5

6

9

11

15

19

y

0

16

20

20

20

1

1

n

0

1

2

3

4

5

6

multilayer id88s

y = (772)s1 + (20)s2 + (1)s3 
s1 = (cid:7705)(-13000) = 0
s2 = (cid:7705)(-1000s4 - 1000s5 + 500)
s3 = (cid:7705)(4000) = 1

data

x

1

5

6

9

11

15

19

y

0

16

20

20

20

1

1

n

0

1

2

3

4

5

6

multilayer id88s

y = (772)s1 + (20)s2 + (1)s3 
s1 = (cid:7705)(-13000) = 0
s2 = (cid:7705)(-1000 + 0 + 500)
s3 = (cid:7705)(4000) = 1

data

x

1

5

6

9

11

15

19

y

0

16

20

20

20

1

1

n

0

1

2

3

4

5

6

multilayer id88s

y = (772)s1 + (20)s2 + (1)s3 
s1 = (cid:7705)(-13000) = 0
s2 = (cid:7705)(-500) = 0
s3 = (cid:7705)(4000) = 1

data

x

1

5

6

9

11

15

19

y

0

16

20

20

20

1

1

n

0

1

2

3

4

5

6

multilayer id88s

y = (772)0 + (20)0 + (1)1
s1 = (cid:7705)(-13000) = 0
s2 = (cid:7705)(-500) = 0
s3 = (cid:7705)(4000) = 1

data

x

1

5

6

9

11

15

19

y

0

16

20

20

20

1

1

n

0

1

2

3

4

5

6

multilayer id88s

y = 1
s1 = (cid:7705)(-13000) = 0
s2 = (cid:7705)(-500) = 0
s3 = (cid:7705)(4000) = 1

data

x

1

5

6

9

11

15

19

y

0

16

20

20

20

1

1

n

0

1

2

3

4

5

6

multilayer id88s

y = (4x - 4)s1 + (0x+20)s2 + (0x+1)s3 

y

data

x

1

5

6

9

11

15

19

y

0

16

20

20

20

1

1

n

0

1

2

3

4

5

6

x

multilayer id88s

y = (w1x + b1)s1 + (w2x+b2)s2 + (w3x+b3)s3
s1 = (cid:7705)(w4x + b4)
s2 = (cid:7705)(w5s1 + w6s3 + b5)
s3 = (cid:7705)(w7x + b6)

layer 2 id88

layer 1 id88

layer 1 id88

multilayer id88s

y = (w1x + b1)s1 + (w2x+b2)s2 + (w3x+b3)s3
s1 = (cid:7705)(w4x + b4)
s2 = (cid:7705)(w5s1 + w6s3 + b5)
s3 = (cid:7705)(w7x + b6)

w4x
s
1
b4

s
3

x

s
2

multilayer id88s

y = (w1x + b1)s1 + (w2x+b2)s2 + (w3x+b3)s3
s1 = (cid:7705)(w4x + b4)
s2 = (cid:7705)(w5s1 + w6s3 + b5)
s3 = (cid:7705)(w7x + b6)

w4x
s
1
b4

w7x
s
3
b5

x

s
2

multilayer id88s

y = (w1x + b1)s1 + (w2x+b2)s2 + (w3x+b3)s3
s1 = (cid:7705)(w4x + b4)
s2 = (cid:7705)(w5s1 + w6s3 + b5)
s3 = (cid:7705)(w7x + b6)

s
1
w5s1

s
3
w6s3

x

s
2

b5

multilayer id88s
y = (w1x + b1)s1 + (w2x+b2)s2 + (w3x+b3)s3

x < 6

s
1

x

s
2

s
3

x > 15

!(x > 15) & !(x < 6)

multilayer id88s
y = (w1x + b1)s1 + (w2x+b2)s2 + (w3x+b3)s3

x < 6

s
1

x

s
2

s
3

x > 15

x   [6,15]

multilayer id88s

x < 6

x

s
3

s
4

s
1

s
2

x > 15

x   [6,15]

x   ]-   ,6] & ]15,   ]

multilayer id88s

x

x > 15

s
2

s
6

x > 2

s
3

s
7

x < 3

s
4

s
7

x   ]-   ,6] & ]15,   ] x   [2,15]

x   [2,3]

x < 6

s
1

s
5
x   [6,15]

multilayer id88s

x

x > 15

s
2

s
6

x > 2

s
3

s
7

s
4

s
7

input

x < 3

layer 1 (input features)

x   ]-   ,6] & ]15,   ] x   [2,15]

x   [2,3]

layer 2 (and and or combinations)

x < 6

s
1

s
5
x   [6,15]

multilayer id88s

x

x > 15

s
2

s
6

x > 2

s
3

s
7

s
4

s
7

input

x < 3

layer 1 (input features)

x   ]-   ,6] & ]15,   ] x   [2,15]

x   [2,3]

layer 2 (and and or combinations)

x < 6

s
1

s
5
x   [6,15]

and(s1,s2) = (cid:7705)(1000s1 + 1000s3 - 1500)
or(s1,s2) = (cid:7705)(1000s1 + 1000s3 - 500)

multilayer id88s

x

input

s
1

s
5

s
8

s
2

s
6

s
9

s
3

s
7

s
a

s
4

s
7

s
b

layer 1 (input features)

layer 2 (and and or combinations)

layer 3 (xor combinations)

multilayer id88s

x

input

s
1

s
5

s
8

s
2

s
6

s
9

s
3

s
7

s
a

s
4

s
7

s
b

layer 1 (input features)

layer 2 (and and or combinations)

layer 3 (xor combinations)

xor(s1,s2) = or(and(s1,!s2), and(!s1,s2))

multilayer id88s

x

input

s
1

s
5

s
8

s
2

s
6

s
9

s
3

s
7

s
a

s
4

s
7

s
b

layer 1 (input features)

layer 2 (and and or combinations)

layer 3 (xor combinations)

xor(s1,s2) = or(s5, s6)

multilayer id88s

y

data

x

1

5

6

9

11

15

19

y

0

16

20

20

20

1

1

n

0

1

2

3

4

5

6

x

universal 
approximator

multilayer id88s

y

data

x

1

5

6

9

11

15

19

y

0

16

20

20

20

1

1

n

0

1

2

3

4

5

6

x

but...

multilayer id88s

y

data

x

1

5

6

9

11

15

19

y

0

16

20

20

20

1

1

n

0

1

2

3

4

5

6

x

no guarantee that 
the best function will 

be found

multilayer id88s

n

0

1

2

x

1

5

6

y

0

16

20

x 

x < 2

s
3

s
7

x > 1

s
1

s
5

s
2

s
6

x < 5

s
4

x < 6

x   ]-   ,1]

x   [5,6[

x   [6,   ]

y 

multilayer id88s

n

0

1

2

x

1

5

6

y

0

16

20

x

x < 2

s
2

s
6

s
3

s
7

x > 1

s
1

s
5

x < 5

s
4

x < 6

x   ]-   ,1]

x   [5,6[

x   [6,   ]

y = 0s5 + 16s6 + 20s7

y 

multilayer id88s

n

0

1

2

x

1

5

6

y

0

16

20

x

x < 2

s
2

s
6

s
3

s
7

x > 1

s
1

s
5

x < 5

s
4

x < 6

x   ]-   ,1]

x   [5,6[

x   [6,   ]

y = 0s5 + 16s6 + 20s7

y 

multilayer id88s

n

0

1

2

x

1

5

6

y

0

16

20

x

x < 2

s
2

s
6

s
3

s
7

x > 1

s
1

s
5

x < 5

s
4

x < 6

x   ]-   ,1]

x   [5,6[

x   [6,   ]

y = 0s5 + 16s6 + 20s7

y 

multilayer id88s

n

0

1

2

x

1

5

6

y

0

16

20

x > 1

s
1

s
5

s
2

s
6

x   ]-   ,1]

x   [5,6[

y 

y = 0s5 + 16s6 + 20s7

x

x < 2

s
3

x < 5

s
4

x < 6

overfitting

s
7
model 
problem

x   [6,   ]

multilayer id88s

task 

complexity

model 

complexity

multilayer id88s

task 

complexity

underfitting

model 

complexity

multilayer id88s

task 

complexity

underfitting

overfitting

model 

complexity

multilayer id88s

task 

complexity

underfitting

e

n

o

y   z

p

p

a

h

overfitting

model 

complexity

multilayer id88s

task 

complexity

underfitting

e

n

o

y   z

p

p

a

h

overfitting

model 

complexity

 

r
e
y
a
l
1
p
l
m

 

 

r
e
y
a
l
2
p
l
m

 

 

r
e
y
a
l
3
p
l
m

 

i

n
o
s
s
e
r
g
e
r

 

r
a
e
n
l

i

multilayer id88s

task 

complexity

underfitting

e

n

o

y   z

p

p

a

h

overfitting

model 

complexity

i

n
o
s
s
e
r
g
e
r

 

r
a
e
n
l

i

s
e
r
u
a
e

t

f
 

e
r
o
m

i

n
o
s
s
e
r
g
e
r

 
r
a
e
n
l

i

multilayer id88s

task 

complexity

underfitting

e

n

o

y   z

p

p

a

h

overfitting

model 

complexity

 

r
e
y
a
l
1
p
l
m

 

 

r
e
y
a
l
2
p
l
m

 

 

r
e
y
a
l
3
p
l
m

 

i

n
o
s
s
e
r
g
e
r

 

r
a
e
n
l

i

multilayer id88s

task 

complexity

underfitting

e

n

o

y   z

p

p

a

h

sentiment 
analysis

i

n
o
s
s
e
r
g
e
r

 

r
a
e
n
l

i

 

r
e
y
a
l
1
p
l
m

 

 

r
e
y
a
l
2
p
l
m

 

 

r
e
y
a
l
3
p
l
m

 

overfitting

model 

complexity

multilayer id88s

task 

complexity

machine 
translation

sentiment 
analysis

underfitting

e

n

o

y   z

p

p

a

h

i

n
o
s
s
e
r
g
e
r

 

r
a
e
n
l

i

 

r
e
y
a
l
1
p
l
m

 

 

r
e
y
a
l
2
p
l
m

 

 

r
e
y
a
l
3
p
l
m

 

overfitting

model 

complexity

multilayer id88s

task 

complexity

underfitting

e

n

o

y   z

p

p

a

h

data

overfitting

model 

complexity

multilayer id88s

task 

complexity

underfitting

data

h a p p y   z o n e

overfitting

model 

complexity

multilayer id88s

task 

complexity

underfitting

data

h a p p y   z o n e

overfitting

model 

complexity

multilayer id88s

y

y

y

n

0

1

2

x

1

5

6

y

0

16

20

multilayer id88s

y

y

y

n

0

1

2

3

x

1

5

6

2

y

0

16

20

4

multilayer id88s

y

y

n

0

1

2

3

x

1

5

6

2

y

0

16

20

4

multilayer id88s

task 

complexity

underfitting

e

n

o

y   z

p

p

a

h

model bias

overfitting

model 

complexity

multilayer id88s

task 

complexity

underfitting

e

n

  z o

y

p

p

h a

overfitting

model 

complexity

model bias
l1 & l2 id173
stochastic dropout (srivastava et al, 2014)
model structure (id98, id56s)

multilayer id88s

id173

c(w,b) =    (yn-  n) + (w+b)  

2

n   {0,1,2}

   = id173 constant

multilayer id88s

id173

x 

x < 2

s
3

s
7

x > 1

s
1

s
5

s
2

s
6

x < 5

s
4

x < 6

x   ]-   ,1]

x   [5,6[

x   [6,   ]

y 

multilayer id88s

id173

x 

nothing

s
3 nothing

s
4

x < 6

s
7

x > 1

s
1

s
5

s
2

s
6

x   ]-   ,1]

nothing

x   [6,   ]

y 

multilayer id88s

id173

x 

nothing

s
3 nothing

s
4

x < 6

s
7

x > 1

s
1

s
5

s
2

s
6

x   ]-   ,1]

nothing

x   [6,   ]

find solutions that 
require less effort

y 

multilayer id88s

stochastic dropout (srivastava et al, 2014)

x 

x < 2

s
3

s
7

x > 1

s
1

s
5

s
2

s
6

x < 5

s
4

x < 6

x   ]-   ,1]

x   [5,6[

x   [6,   ]

y 

multilayer id88s

stochastic dropout (srivastava et al, 2014)

x < 5

s
4

x < 6

x 

s
3

s
7

0

x > 1

s
1

s
5

x   ]-   ,1]

0

0

s
2

s
6

y 

multilayer id88s

stochastic dropout (srivastava et al, 2014)

x < 5

s
4

x < 6

x 

s
3

s
7

0

x > 1

s
1

s
5

x   ]-   ,1]

0

0

s
2

s
6

y 

find robust models

multilayer id88s

model structure

weighted sum of linear functions vs mlp
y = (w1x + b1)s1 + (w2x+b2)s2 + (w3x+b3)s3

multilayer id88s

model structure

weighted sum of linear functions vs mlp
y = (w1x + b1)s1 + (w2x+b2)s2 + (w3x+b3)s3

convolutional vs id56s

multilayer id88s

representation

s1 = (cid:7705)(w4x + b4)
s2 = (cid:7705)(w5s1 + w6s3 + b5)
s3 = (cid:7705)(w7x + b6)

s
1
w5s1

x

s
2

s
3
w6s3

b5

multilayer id88s

representation

s1 = (cid:7705)(w3x + b3)
s2 = (cid:7705)(w4s1 + b4)

s
1

x

s
2

s
3

x

s1

s2

1

2

1

multilayer id88s

representation

x

s1

s2

100

1000

1000

s1 = (cid:7705)(ws2 + b)

multilayer id88s

representation

tensoflow code

x

s1

s2

100

1000

1000

s1 = tf.matmul(x, w1) + b1

s1 = tf.nn.sigmoid(s1)

s2 = tf.matmul(s1, w2) + b2

s2 = tf.nn.sigmoid(s2)

s1 = (cid:7705)(ws2 + b)

using discrete variables

data

1

5

6

3

0

16

20

?

using discrete variables

data

1

5

6

3

0

16

20

?

using discrete variables

data

1

5

6

3

0

16

20

?

?

using discrete variables

number of fruit to offer

x

s
3

s
7

s
1

s
5

s
2

s
6

s
4

y 

number of fruit received

using discrete variables

number of fruit to offer

x

s1

s2

y 

number of fruit received

using discrete variables

type of fruit to offer

number of fruit to offer

u

type of fruit received

v

x

s1

s2

y 

number of fruit received

using discrete variables

type of fruit to offer

number of fruit to offer

u

type of fruit received

v

x

s1

s2

y 

u   {apple, banana, coconut}

number of fruit received

v   {apple, banana, coconut}

using discrete variables

lookup tables

u

e1 e2
-0.4
0.1

e3 e4
0.5
0.2

apple

banana

0.4

1.4

-1.0 0.1

coconut

v = 3

1.1

0.9

1.1

0.5

using discrete variables

lookup tables

u

e1 e2
-0.4
0.1

e3 e4
0.5
0.2

apple

banana

0.4

1.4

-1.0 0.1

coconut

v = 3

1.1

0.9

1.1

0.5

using discrete variables

lookup tables

e1 e2
-0.4
0.1

e3 e4
0.5
0.2

apple

banana

0.4

1.4

-1.0 0.1

coconut

v = 3

1.1

0.9

1.1

0.5

u

embedding for u

size = 4

using discrete variables

lookup tables

e1 e2
-0.4
0.1

e3 e4
0.5
0.2

apple

banana

0.4

1.4

-1.0 0.1

coconut

v = 3

1.1

0.9

1.1

0.5

banana

u

embedding for u

size = 4

using discrete variables

lookup tables

e1 e2
-0.4
0.1

e3 e4
0.5
0.2

0.4

1.4

-1.0 0.1

1.1

0.9

1.1

0.5

0

1

2

v = 3

1

u

embedding for u

size = 4

using discrete variables

lookup tables

1

u

lookup

embedding for u

size = 4

using discrete variables

type of fruit to offer

number of fruit to offer

lookup

u

eu

type of fruit received

v

x

s1

s2

y 

u   {apple, banana, coconut}

number of fruit received

v   {apple, banana, coconut}

using discrete variables

softmax

v = 3

apple banana coconut

w1
w2
w3
w4

0.1

0.4

1.1

1.3

-0.4

1.4

0.9

0.1

0.2

-1.0

1.1

0.4

using discrete variables

softmax

input vector

size = 4

v = 3

apple banana coconut

w1
w2
w3
w4

0.1

0.4

1.1

1.3

-0.4

1.4

0.9

0.1

0.2

-1.0

1.1

0.4

using discrete variables

softmax

input vector

size = 4

v = 3

logits

size = v

apple banana coconut

w1
w2
w3
w4

0.1

0.4

1.1

1.3

-0.4

1.4

0.9

0.1

0.2

-1.0

1.1

0.4

using discrete variables

softmax

s
1

s
2

s
3

s
4

input vector

v = 3

d
1

1

d
2

-1

d
3
-2

logits

apple banana coconut

w1
w2
w3
w4

0.1

0.4

1.1

1.3

-0.4

1.4

0.9

0.1

0.2

-1.0

1.1

0.4

using discrete variables

softmax

s
1

s
2

1

0.84

d
1

p
1

s
3

s
4

input vector

v = 3

d
2

p
2

-1

0.11

d
3

-2

p
2
0.05

logits

apple banana coconut

w1
w2
w3
w4

0.1

0.4

1.1

1.3

-0.4

1.4

0.9

0.1

0.2

-1.0

1.1

0.4

using discrete variables

softmax

s
1

s
2

1

0.84

d
1

p
1

apple

s
3

s
4

input vector

v = 3

d
2

p
2

-1

0.11

d
3

-2

p
2
0.05

logits

apple banana coconut

w1
w2
w3
w4

0.1

0.4

1.1

1.3

-0.4

1.4

0.9

0.1

0.2

-1.0

1.1

0.4

using discrete variables

type of fruit to offer

number of fruit to offer

lookup

u

eu

softmax

type of fruit received

v

x

s1

s2

y 

u   {apple, banana, coconut}

number of fruit received

v   {apple, banana, coconut}

using discrete variables

type of fruit to offer

number of fruit to offer

lookup

u

eu

softmax

type of fruit received

v

x

s1

s2

y 

u   {apple, banana, coconut}

number of fruit received

v   {apple, banana, coconut}

example applications

window-based tagging (collobert et al, 2011)

abby            likes         to         eat         apples      and        bananas

nnp              vbz         to       vb          nns        cc           nns

example applications

window-based tagging (collobert et al, 2011)

abby            likes         to         eat         apples      and        bananas

e-2

e-1

e-0

e1

e2

example applications

window-based tagging (collobert et al, 2011)

abby            likes         to         eat         apples      and        bananas

e-2

e-1

e-0

e1

e2

id27s

s1

s2

non-linear layer 1

non-linear layer 2

example applications

window-based tagging (collobert et al, 2011)

abby            likes         to         eat         apples      and        bananas

e-2

e-1

e-0

e1

e2

id27s

s1

s2

vb

non-linear layer 1

non-linear layer 2

softmax

example applications

window-based tagging (collobert et al, 2011)

abby            likes         to         eat         apples      and        bananas

e-2

e-1

e-0

e1

e2

id27s

s1

s2

vb

non-linear layer 1

non-linear layer 2

softmax

example applications

window-based tagging (collobert et al, 2011)

example applications

translation rescoring (devlin et al, 2014)

abby            likes         to         eat         apples      and        bananas

example applications

translation rescoring (devlin et al, 2014)

context

predict

abby            likes         to         eat         apples      and        bananas

example applications

translation rescoring (devlin et al, 2014)

abby            likes         to         eat         apples      and        bananas

e-4

e-3

e-2

e-1

s1

s2

softmax

example applications

translation rescoring (devlin et al, 2014)

<s>

abby            likes         to         eat         apples      and        bananas

0.2

example applications

translation rescoring (devlin et al, 2014)

abby            likes         to         eat         apples      and        bananas

0.2

0.1

example applications

translation rescoring (devlin et al, 2014)

abby            likes         to         eat         apples      and        bananas

0.2

0.1

0.3

example applications

translation rescoring (devlin et al, 2014)

abby            likes         to         eat         apples      and        bananas

0.2

0.1

0.3

0.5

0.7

0.4

0.2

0.000378

example applications

translation rescoring (devlin et al, 2014)

john            does         to         eat         coconuts      and        bananas

abby            likes         to         eat         apples      and        bananas

abby            dislikes         to         drink         apples      and        bananas

0.00003

0.000378

0.00012

example applications

translation rescoring (devlin et al, 2014)

john            does         to         eat         coconuts      and        bananas

abby            likes         to         eat         apples      and        bananas

abby            dislikes         to         drink         apples      and        bananas

0.00003

0.000378

0.00012

example applications

translation rescoring (devlin et al, 2014)

translation

context

abby            likes         to         eat         apples      and        bananas

predict

source

abby            gosta         de         comer         macas      e        bananas

example applications

translation rescoring (devlin et al, 2014)

translation

context

abby            likes         to         eat         apples      and        bananas

predict

source

abby            gosta         de         comer         macas      e        bananas

example applications

translation rescoring (devlin et al, 2014)

translation

abby            likes         to         eat         apples      and        bananas

e-4

e-3

e-2

e-1

s1

s2

f-1

macas

example applications

translation rescoring (devlin et al, 2014)

translation score (id7)

arabic - english

chinese - english

best rescored system

1st opeid412

hierarchical

52.8

49.5 

43.4

34.7

32.6

30.1

deep neural networks are our friends?

convolutional neural network

deep neural networks are our friends?

convolutional neural network

x1

x5

x9

x2

x6

x3

x7

x4

x8

x10

x11

x12

x13

x14

x15

x16

4x4 image

deep neural networks are our friends?

convolutional neural network

x1

x5

x9

x2

x6

x3

x7

x4

x8

x10

x11

x12

x13

x14

x15

x16

4x4 image

deep neural networks are our friends?

convolutional neural network

z1

x1

x5

x9

x2

x6

x3

x7

x4

x8

x10

x11

x12

x13

x14

x15

x16

4x4 image

x1

x2

...

x11

w1

w9

z1

deep neural networks are our friends?

convolutional neural network

z1

z2

x1

x5

x9

x2

x6

x3

x7

x4

x8

x10

x11

x12

x13

x14

x15

x16

4x4 image

x2

x3

...

x12

w1

w9

z1

deep neural networks are our friends?

convolutional neural network

x1

x5

x9

x2

x6

x3

x7

x4

x8

x10

x11

x12

x13

x14

x15

x16

4x4 image

z1

z3

z2

z4

deep neural networks are our friends?

convolutional neural network

x1

x5

x9

x2

x6

x3

x7

x4

x8

x10

x11

x12

x13

x14

x15

x16

4x4 image

z1

z3

z2

z4

z1

z2

z3

z4

y

is this 
a cat?

