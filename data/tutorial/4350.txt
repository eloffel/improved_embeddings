large-scale language 
grounding with vision

yejin choi

computer science & engineering



hal (a space odyssey, 1968)


                   - david stork (hal   s legacy, 1998)

 

   imagine, for example, a computer that could look at 
an arbitrary scene anything from a sunset over a fishing 
village to grand central station at rush hour and 
produce a verbal description. 
this is a problem of overwhelming difficulty, relying as 
it does on finding solutions to both vision and 
language and then integrating them. 
i suspect that scene analysis will be one of the last 
cognitive tasks to be performed well by computers    



language grounding with vision

      

       understanding the meaning of language with perceptual signals
       what does red mean?
       what does blood mean?
      

       blood     the red fluid that circulates through the heart   
red := 

red --- having a color resembling that of blood

       not just words, but phrases and sentences.

not just words, but descriptions

          playing a soccer    vs.    playing a piano    


   enjoying the ride   

automatic image captioning

can be useful for:
       ai agent that can see and talk
       automatic summary of your photo album
      

image search with complex natural language queries
       e.g., find all images with a man with a backpack entering a red car

       equal web access for visually impaired

"in the middle of flickering pages of 
action comics, appears the logo 
'marvel' in bold letters." 

- from the opening credit of 
   daredevil   


automatic image captioning

can be useful for:
       ai agent that can see and talk
       automatic summary of your photo album
      

image search with complex natural language queries
       e.g., find all images with a man with a backpack entering a red car

       equal web access for visually impaired

in this painting, dozens of irises rise up in 
waves of color, like green and blue flames 
fanned by a wind that blows them, now 
flattens them, ... on the left, a solitary white 
iris commands the swirl of purple and green 
from its outpost ...

- example from artbeyondsight.org


how to obtain rich annotations?

       label them all (by asking human workers)

       flickr 30k
       msr coco --- 100k images with 5 captions each

       learn from data in the wild

       facebook alone has over 250 billion images as of jun 2013, with 

350 million images added daily by over 1 billion users

       flickr has over 2 billion images
       data available at a significantly larger scale
       and significantly noisier

example annotations 
in the coco dataset

the man, the young girl, and dog are on the surfboard.

      
       a couple of people and a dog in the water.
       people and a dog take a ride on a surfboard
       a man holding a woman and a dog riding the same surfboard.
       a man holding a woman by her inner thighs on top of a 

surfboard over a small dog in a pink life jacket in the ocean.

flickr captions are noisier (some better examples)

       dad, daughter and doggie 

      

tandem surf ride
i believe this was a world 
record with two humans and 7 
dogs...

       oh no    here we go
       surrounded by splash
       pulling through
       tada!
       nani having a good time
       digging deep

learning from data in the wild

deja image-caption corpus (naacl 2015):

       of 750 million pairs of image-caption pairs from flickr
       retain only those captions that are repeated verbatim by more than one user
       yielding 4 million images with 180k unique captions

the sun sets for another day (12) 

sun is going to bed (21)

  

after the sun has set (9) 

the sky looks like it is on fire (58) 

rippled sky (44) 

related work

compose using detected 
words + hallucinated 
words
      
      
      
      
       mitchell et al (2012)

yang et al. (2011) 
li et al. ( 2011)
kuznetsova et al. (2012) 
elliot and keller (2013)

generation as whole sentence 
retrieval
      
farhadi et al. (2010)
       ordonez et al. (2011)
      
socher et al. (2013) 
       hodosh et al. (2013)

kuznetsova et al. (2012)

compose using retrieved text
      
       mason (2013)
      

feng and lapata (2013)

deep learning variants
      
      
      
      

 
kiros et al 2014
fang et al 2015
 
chen et al 2015  
 
xu et al 2015

 donahue et al. 2015 
 karpathy et al 2015 
 mao et al 2014 
 vinyals et al 2015 

compose using only 
detected words
      
yao et al. (2010)
      
kulkarni et al. (2011)
      
yatkar et al (2014)
      
thomason et al (2014)
       guadarrama et al (2013)

more precise
fixed/small vocabulary
fixed / formulaic language

1

2 , 
3 ,  
4  
1

1
0

0
a c l   2
0
a c l   2
t a c l   2

more expressive
open vocabulary
everyday people   s language


plan for the talk

       babytalk

       [cvpr 2011]

       treetalk

       [tacl 2014, acl 2013, acl 2012]

   this picture shows one person, one grass, one chair, and one potted 
plant. the person is near the green grass, and in the chair. the green 
grass is by the chair, and near the potted plant.   

   this picture shows one person, one grass, one chair, and one potted 
plant. the person is near the green grass, and in the chair. the green 
grass is by the chair, and near the potted plant.   

   this picture shows one person, one grass, one chair, and one potted 
plant. the person is near the green grass, and in the chair. the green 
grass is by the chair, and near the potted plant.   

   this picture shows one person, one grass, one chair, and one potted 
plant. the person is near the green grass, and in the chair. the green 
grass is by the chair, and near the potted plant.   

   this picture shows one person, one grass, one chair, and one potted 
plant. the person is near the green grass, and in the chair. the green 
grass is by the chair, and near the potted plant.   

   this picture shows one person, one grass, one chair, and one potted 
plant. the person is near the green grass, and in the chair. the green 
grass is by the chair, and near the potted plant.   

   this picture shows one person, one grass, one chair, and one potted 
plant. the person is near the green grass, and in the chair. the green 
grass is by the chair, and near the potted plant.   

   this picture shows one person, one grass, one chair, and one potted 
plant. the person is near the green grass, and in the chair. the green 
grass is by the chair, and near the potted plant.   

methodology overview

+,($%

brown 0.01
near(a,b) 1    
striped 0.16
near(b,a) 1 
furry .26
against(a,b) .11
wooden .2
!"#$%
against(b,a) .04 
feathered .06
beside(a,b) .24
        ...
beside(b,a) .17
        ...

brown 0.32
'()*-%
striped 0.09
near(a,c)  1  
furry .04
near(c,a)  1   
wooden .2
against(a,c) .3
feathered .
against(c,a) .05 
04
beside(a,c) .5
        ...
beside(c,a) .45
!"#-%
      ...

+,(-%

a) dog
a) dog
a) dog

b) person
b) person
b) person

'()*$%

+,(&%

!"#&%

this is a photograph of one 
person and one brown sofa and 
one dog. the person is against 
the brown sofa. and the dog is 
near the person, and beside the 
brown sofa. 

'()*&%

input image

near(b,c)  1   
brown 0.94
near(c,b)  1   
striped 0.10
<<null,person_b>,against,<brown,sofa_c>> 
against(b,c) .67
furry .06
generate natural 
<<null,dog_a>,near,<null,person_b>> 
against(c,b) .33 
wooden .8
<<null,dog_a>,beside,<brown,sofa_c>> 
beside(b,c) .0
feathered .
language description
beside(c,b) .19
08
      ...
predict labeling     vision potentials 
        ...
c) sofa
c) sofa
c) sofa
smoothed with text potentials
predict prepositions
predict attributes

extract objects/stuff

id49 (crf)

a)r1%

obj1%

prep1%

a)r2%

prep3%

obj2%

obj3%

prep2%

a)r3%

potential functions for crf

  (object_i)
  (attribute_i)
  (preposition_ij)
  (attribute_i ,object_i)
  (object_i,preposition_ij,object_ j)

unary 
potentials

relational
( binary & 
ternary) 
potentials

potential functions for crf
practical challenge of relational potentials:

!

observing all possible combinations of variables unlikely 

(limited corpus with detailed visual annotations)

  (object_i)
  (attribute_i)
  (preposition_ij)
  (attribute_i ,object_i)
  (object_i,preposition_ij,object_ j)

unary 
potentials

relational
( binary & 
ternary) 
potentials

potential functions for crf
practical challenge of relational potentials:

!

observing all possible combinations of variables unlikely 

(limited corpus with detailed visual annotations)

visual 

  (object_i)
  (attribute_i)
  (preposition_ij)
  (attribute_i ,object_i)
  (object_i,preposition_ij,object_ j)

textual 
potentials

potentials

unary 
potentials

relational
( binary & 
ternary) 
potentials

 
learning: mixture coefficients of 
different types of potentials (grid 
search) 
 
id136: tree re-weighted message 
passing (trw-s) (kolmogorov 2006)  
 

  (object_i)
  (attribute_i)
  (preposition_ij)
  (attribute_i ,object_i)
  (object_i,preposition_ij,object_ j)

unary 
potentials

relational
( binary & 
ternary) 
potentions

generation (aka    surface realization   )

template filling (traversing the graph and reading off 
the detected objects, attributes, and their spatial 
relations in sequence) 
 


cherry-picked examples

lemons

this is a picture of one 
sky, one road and one 
sheep. the gray sky is 
over the gray road. 
the gray sheep is by 
the gray road. 

here we see one 
road, one sky and 
one bicycle. the road 
is near the blue sky, 
and near the colorful 
bicycle. the colorful 
bicycle is within the 
blue sky. 

this is a picture of two dogs. the first 
dog is near the second furry dog. 

there are one road and one cat. 
the furry road is in the furry cat. 

this is a picture of one tree, 
one road and one person. 
the rusty tree is under the red 
road. the colorful person is 
near the rusty tree, and under 
the red road. 

computer vs human generated caption

 

                     this picture shows one 
computer:
person, one grass, one chair, and one 
potted plant. the person is near the 
green grass, and in the chair. the green 
grass is by the chair, and near the potted 
plant.   

blonde child with a cookie. 

human (uiuc pascal dataset):
a.    a lemonaide stand is manned by a 
b.    a small child at a lemonade and 
cookie stand on a city corner.  
c.    young child behind lemonade stand 

eating a cookie. 

(1) formulaic, robotic and unnatural
(2) limited semantic expressiveness, especially, no verb except    be    verb

                     this picture shows one 
computer:
person, one grass, one chair, and one 
potted plant. the person is near the 
green grass, and in the chair. the green 
grass is by the chair, and near the potted 
plant.   

how can we reduce the 
gap between these two? 

blonde child with a cookie. 

human (uiuc pascal dataset):
a.    a lemonaide stand is manned by a 
b.    a small child at a lemonade and 
cookie stand on a city corner.  
c.    young child behind lemonade stand 

eating a cookie. 

how can we scale up the range of 
descriptive words and phrases?

   butterfly and flower   

   a butterfly attracted to 

flowers   

   butterfly sipping nectar 

from the flower   

   butterfly feeding on a flower   

   a butterfly having lunch   

how can we scale up the range of 
descriptive words and phrases?

two challenges:

e.g.,      attracted_recognizer   ,    feeding_on_recognizer   

!   recognition: we don   t have descriptive-verb recognizers at scale. 
!   formalism: not easy for humans to formalize all these variations of 
meanings in symbolic meaning representation and annotate them

   butterfly feeding on a flower   

   a butterfly having lunch   


how can we scale up the range of 
descriptive words and phrases?

two challenges:

e.g.,      attracted_recognizer   ,    feeding_on_recognizer   

!   recognition: we don   t have descriptive-verb recognizers at scale. 
!   formalism: not easy for humans to formalize all these variations of 
meanings in symbolic meaning representation and annotate them

reflection on babytalk:

humans decide
 {what can be described} = {what can be recognized} 

   butterfly feeding on a flower   

   a butterfly having lunch   


web  
in 1995

web today: increasingly visual   
-- social media, news media, online shopping

       facebook.com%has%over%250%billion%images%uploaded%as%of%jun%2013%
       1.15%billion%users%uploading%350%million%images%a%day%on%average%

how can we scale up the range of 
descriptive words and phrases?

two challenges:

e.g.,      attracted_recognizer   ,    feeding_on_recognizer   

!   recognition: we don   t have descriptive-verb recognizers at scale. 
!   formalism: not easy for humans to formalize all these variations of 
meanings in symbolic meaning representation and annotate them

reflection on babytalk:

humans decide
 {what can be described} = {what can be recognized} 

   butterfly feeding on a flower   

   a butterfly having lunch   


how can we scale up the range of 
descriptive words and phrases?

two challenges:

e.g.,      attracted_recognizer   ,    feeding_on_recognizer   

!   recognition: we don   t have descriptive-verb recognizers at scale. 
!   formalism: not easy for humans to formalize all these variations of 
meanings in symbolic meaning representation and annotate them

reflection on babytalk:

humans decide

{what can be described} = {what can be recognized} 

key idea:


{what can be described}     {what can be recognized} 
~ farhadi et al. 2010

u

data decides

distributional hypothesis (harris 1954)

   butterfly feeding on a flower   

   a butterfly having lunch   



plan for the talk

       babytalk

       [cvpr 2011]

       treetalk

       [tacl 2014, acl 2013, acl 2012]

operational overview

given a query image (& an object)
(cid:1)    harvest tree branches 
(cid:2)    compose a new tree by combining tree branches

sbu captioned photo dataset
(ordonez et al. 2011)

1,000,000 (image, caption)

description generation

object appearance

object pose 

scene appearance

region 
appearance & 
relationship

np: the dirty sheep 

vp: meandered along a 
desolate road 

pp: in the highlands of scotland

pp: through frozen grass

example composition:

the dirty sheep meandered along a 
desolate road in the highlands of 
scotland through frozen grass

retrieving 

vps

contented dog just laying 
on the edge of the road in 
front of a house..

peruvian dog sleeping on 
city street in the city of 
cusco, (peru)
~ distributional hypothesis (harris 1954) 

detect: dog

find matching 
detections by 
pose similarity

--- using color, texton, 
hog and sift

this dog was laying in the 
middle of the road on a 
back street in jaco

closeup of my dog 
sleeping under my desk.


retrieving 

ppstuff

find matching regions 
by appearance + 
arrangement similarity
--- using color, texton, hog and sift

cordoba - lonely 
elephant under an 
orange tree...

i positioned the chairs 
around the lemon tree -- 
it's like a shrine

detect: stuff 

comfy chair under a tree.

mini nike soccer ball all 
alone in the grass


operational overview

given a query image

(cid:1)    harvest tree branches 
(cid:2)    compose a new tree by combining tree branches

1,000,000 (image, caption)

sbu captioned photo dataset

input to sentence composition := 

target image

object (np)

action (vp)

a cow

was staring at me

stuff (pp)

scene (pp)

in the grass

in the countryside

sentence composition := 

1.    select a subset of harvested phrases
2.    decide the ordering of the selected phrases

target image

object (np)

action (vp)

a cow 
in the grass
was staring at me
in the countryside 

a cow 
was staring at me
in the grass
in the countryside 

a cow

was staring at me

stuff (pp)

scene (pp)

in the grass

in the countryside

sentence composition := 

1.    select a subset of harvested phrases
2.    decide the ordering of the selected phrases

target image

object (np)

action (vp)

tree structure --- probabilistic id18s (pid18)

np 

dt 

nn 

a 

cow 

vp 

vbd 
was 

vbg 
staring 

vp 

in 

at 

pp 

np 

prp 

me 

stuff (pp)

scene (pp)

in 

in 

pp 

dt 

the 

np 

nn 

grass 

in 

in 

pp 

dt 

the 

np 

nn 

countryside 

a cow 
in the grass
was staring at me
in the countryside 

a cow 
was staring at me
in the grass
in the countryside 

sentence composition := 

in the grass --- was staring at me --- a cow

sinv 

vp 

vp 

vbd 
was 

vbg 
staring 

in 

in 

pp 

dt 

the 

np 

nn 

grass 

pp 

vp 

in 

at 

np 

dt 

a 

nn 

cow 

np 

prp 

me 

sentence composition := 

in the grass --- was staring at me --- a cow

sinv 

vp 

vp 

vbd 
was 

vbg 
staring 

in 

in 

pp 

dt 

the 

np 

nn 

grass 

pp 

vp 

in 

at 

np 

dt 

a 

nn 

cow 

np 

prp 

me 

a cow --- was staring at me --- in the countryside

np 

dt 

a 

nn 

cow 

s 

vp 

vbd 
was 

vbg 
staring 

vp 

in 

at 

vp 

pp 

np 

prp 

me 

in 

in 

: global sentence 
structure

: local cohesion

: global sentence 
structure

pp 

np 

dt 

the 

nn 

: local cohesion
countryside 

sentence composition := 

in the grass --- was staring at me --- a cow

sinv 

vp 

vp 

vbd 
was 

vbg 
staring 

in 

in 

pp 

dt 

the 

np 

nn 

grass 

pp 

vp 

in 

at 

np 

dt 

a 

nn 

cow 

np 

prp 

me 

: global sentence 
structure

: local cohesion

!   different from parsing because we must consider different 
choices of subtree selection and re-ordering simultaneously

object (np)

np 

dt 

nn 

a 

cow 

action (vp)

vp 

stuff (pp)

pp 

scene (pp)

pp 

vbd 
was 

vbg 
staring 

vp 

in 
at 

pp 

np 

prp 
me 

in 

in 

np 

dt 

the 

nn 

grass 

np 

dt 

nn 

in 

in 

the 

countryside 

sentence composition := 

in the grass --- was staring at me --- a cow

vp 

in 

in 

pp 

dt 

the 

np 

nn 

grass 

vp 

vbd 
was 

vbg 
staring 

vp 

in 

at 

pp 

a 
al., 2010)
al., 2010)
al., 2010)
np 

approach to tree composition using extracted tree
approach to tree composition using extracted tree
approach to tree composition using extracted tree
fragments as described in   2. the input to the algo-
fragments as described in   2. the input to the algo-
fragments as described in   2. the input to the algo-
rithm is a set of extracted phrases (as tree fragments)
rithm is a set of extracted phrases (as tree fragments)
rithm is a set of extracted phrases (as tree fragments)
for each phrase type. the goal of the algorithm is to
for each phrase type. the goal of the algorithm is to
for each phrase type. the goal of the algorithm is to

1we use color, texton (leung and malik, 1999), hog (dalal
1we use color, texton (leung and malik, 1999), hog (dalal
1we use color, texton (leung and malik, 1999), hog (dalal

as constraint optimization 
using integer id135 
 
: global sentence 
--- roth and yih (2004), clarke and lapata (2006), 
structure
martins and smith (2009), woodsend and lapata(2010)

2vision detections for verbs (actions or descriptive states)
2vision detections for verbs (actions or descriptive states)
2vision detections for verbs (actions or descriptive states)
remain to be a very challenging problem. we bypass this limita-
remain to be a very challenging problem. we bypass this limita-
remain to be a very challenging problem. we bypass this limita-
tion by exploiting the semantic relations between noun phrases
tion by exploiting the semantic relations between noun phrases
tion by exploiting the semantic relations between noun phrases
and verb phrases. we leave more precise alignment between
and verb phrases. we leave more precise alignment between
and verb phrases. we leave more precise alignment between
image parts and text as a future research direction.
image parts and text as a future research direction.
image parts and text as a future research direction.

and triggs, 2005) and sift (lowe, 2004) features.
and triggs, 2005) and sift (lowe, 2004) features.
and triggs, 2005) and sift (lowe, 2004) features.

sinv 

np 

 ijs = 1 iff
 ijs = 1 iff
 ijs = 1 iff

ditionally, we de   ne variables for each pair of adja-
ditionally, we de   ne variables for each pair of adja-
ditionally, we de   ne variables for each pair of adja-
cent phrases to capture sequence cohesion:
cent phrases to capture sequence cohesion:
cent phrases to capture sequence cohesion:

   ijkpq(k+1) = 1 iff    ijk =    pq(k+1) = 1
   ijkpq(k+1) = 1 iff    ijk =    pq(k+1) = 1
   ijkpq(k+1) = 1 iff    ijk =    pq(k+1) = 1

variables for tree structure: we de   ne variables
variables for tree structure: we de   ne variables
variables for tree structure: we de   ne variables
  to encode the parse structure:
  to encode the parse structure:
  to encode the parse structure:

3stuff refers to objects without rigid boundaries, e.g.,    wa-
3stuff refers to objects without rigid boundaries, e.g.,    wa-
3stuff refers to objects without rigid boundaries, e.g.,    wa-
ter   ,    sky    (typically mass nouns). we use the same features
ter   ,    sky    (typically mass nouns). we use the same features
ter   ,    sky    (typically mass nouns). we use the same features
as above.
as above.
as above.

nn 

dt 

4l2 distance between classi   cation score vectors (xiao et
4l2 distance between classi   cation score vectors (xiao et
4l2 distance between classi   cation score vectors (xiao et

cow 

where i 2 [0, n ) and j 2 [i, n ) index rows and
where i 2 [0, n ) and j 2 [i, n ) index rows and
where i 2 [0, n ) and j 2 [i, n ) index rows and
columns of the cky-style matrix in figure 3. we
columns of the cky-style matrix in figure 3. we
columns of the cky-style matrix in figure 3. we

5the number of positions is equal to the number of phrase
5the number of positions is equal to the number of phrase
5the number of positions is equal to the number of phrase

types, since we select at most one from each type.
types, since we select at most one from each type.
types, since we select at most one from each type.

prp 

me 

: local cohesion

!   different from parsing because we must consider different 
choices of subtree selection and re-ordering simultaneously
!   finding the optimum selection+ordering = np-hard (~= tsp) 

object (np)

np 

dt 

nn 

a 

cow 

action (vp)

vp 

stuff (pp)

pp 

scene (pp)

pp 

vbd 
was 

vbg 
staring 

vp 

in 
at 

pp 

np 

prp 
me 

in 

in 

np 

dt 

the 

nn 

grass 

np 

dt 

nn 

in 

in 

the 

countryside 


sentence composition := 

approach to tree composition using extracted tree
approach to tree composition using extracted tree
approach to tree composition using extracted tree
fragments as described in   2. the input to the algo-
fragments as described in   2. the input to the algo-
fragments as described in   2. the input to the algo-
rithm is a set of extracted phrases (as tree fragments)
rithm is a set of extracted phrases (as tree fragments)
rithm is a set of extracted phrases (as tree fragments)
for each phrase type. the goal of the algorithm is to
for each phrase type. the goal of the algorithm is to
for each phrase type. the goal of the algorithm is to

as constraint optimization 
using integer id135 

ditionally, we de   ne variables for each pair of adja-
ditionally, we de   ne variables for each pair of adja-
ditionally, we de   ne variables for each pair of adja-
cent phrases to capture sequence cohesion:
cent phrases to capture sequence cohesion:
cent phrases to capture sequence cohesion:

   ijkpq(k+1) = 1 iff    ijk =    pq(k+1) = 1
   ijkpq(k+1) = 1 iff    ijk =    pq(k+1) = 1
   ijkpq(k+1) = 1 iff    ijk =    pq(k+1) = 1

variables for tree structure: we de   ne variables
variables for tree structure: we de   ne variables
variables for tree structure: we de   ne variables
  to encode the parse structure:
  to encode the parse structure:
  to encode the parse structure:

k=2 
np 

and triggs, 2005) and sift (lowe, 2004) features.
and triggs, 2005) and sift (lowe, 2004) features.
and triggs, 2005) and sift (lowe, 2004) features.

1we use color, texton (leung and malik, 1999), hog (dalal
1we use color, texton (leung and malik, 1999), hog (dalal
1we use color, texton (leung and malik, 1999), hog (dalal
k=3 
2vision detections for verbs (actions or descriptive states)
2vision detections for verbs (actions or descriptive states)
2vision detections for verbs (actions or descriptive states)
remain to be a very challenging problem. we bypass this limita-
remain to be a very challenging problem. we bypass this limita-
remain to be a very challenging problem. we bypass this limita-
tion by exploiting the semantic relations between noun phrases
tion by exploiting the semantic relations between noun phrases
tion by exploiting the semantic relations between noun phrases
and verb phrases. we leave more precise alignment between
and verb phrases. we leave more precise alignment between
and verb phrases. we leave more precise alignment between
image parts and text as a future research direction.
image parts and text as a future research direction.
image parts and text as a future research direction.

dt 
3stuff refers to objects without rigid boundaries, e.g.,    wa-
3stuff refers to objects without rigid boundaries, e.g.,    wa-
3stuff refers to objects without rigid boundaries, e.g.,    wa-
ter   ,    sky    (typically mass nouns). we use the same features
ter   ,    sky    (typically mass nouns). we use the same features
ter   ,    sky    (typically mass nouns). we use the same features
a 
as above.
as above.
as above.
4l2 distance between classi   cation score vectors (xiao et
4l2 distance between classi   cation score vectors (xiao et
4l2 distance between classi   cation score vectors (xiao et
al., 2010)
al., 2010)
al., 2010)

cow 

nn 

 ijs = 1 iff
 ijs = 1 iff
 ijs = 1 iff

where i 2 [0, n ) and j 2 [i, n ) index rows and
where i 2 [0, n ) and j 2 [i, n ) index rows and
where i 2 [0, n ) and j 2 [i, n ) index rows and
columns of the cky-style matrix in figure 3. we
columns of the cky-style matrix in figure 3. we
columns of the cky-style matrix in figure 3. we

5the number of positions is equal to the number of phrase
5the number of positions is equal to the number of phrase
5the number of positions is equal to the number of phrase

types, since we select at most one from each type.
types, since we select at most one from each type.
types, since we select at most one from each type.

k=1 

vp 

vbd 
was 

vbg 
staring 

vp 

in 
at 

pp 

np 
prp 
me 

k=0 
pp 

np 

dt 

the 

nn 

grass 

in 

in 

decision variable:

objective function:

object (np)

np 

content selection score

action (vp)

vp 

pp 
recognition and matching
nn 

based on visual 
vbg 
staring 

vbd 
was 

vp 

dt 

a 

cow 

in 
at 

np 

prp 
me 

i   th phrase from 
stuff(pp)-type 

stuff (pp)

pp 

scene (pp)

pp 

in 

in 

np 

dt 

the 

nn 

grass 

np 

dt 

nn 

in 

in 

the 

countryside 

sentence composition := 

approach to tree composition using extracted tree
approach to tree composition using extracted tree
approach to tree composition using extracted tree
fragments as described in   2. the input to the algo-
fragments as described in   2. the input to the algo-
fragments as described in   2. the input to the algo-
rithm is a set of extracted phrases (as tree fragments)
rithm is a set of extracted phrases (as tree fragments)
rithm is a set of extracted phrases (as tree fragments)
for each phrase type. the goal of the algorithm is to
for each phrase type. the goal of the algorithm is to
for each phrase type. the goal of the algorithm is to

as constraint optimization 
using integer id135 

1we use color, texton (leung and malik, 1999), hog (dalal
1we use color, texton (leung and malik, 1999), hog (dalal
1we use color, texton (leung and malik, 1999), hog (dalal

and triggs, 2005) and sift (lowe, 2004) features.
and triggs, 2005) and sift (lowe, 2004) features.
and triggs, 2005) and sift (lowe, 2004) features.

ditionally, we de   ne variables for each pair of adja-
ditionally, we de   ne variables for each pair of adja-
ditionally, we de   ne variables for each pair of adja-
cent phrases to capture sequence cohesion:
cent phrases to capture sequence cohesion:
cent phrases to capture sequence cohesion:

   ijkpq(k+1) = 1 iff    ijk =    pq(k+1) = 1
   ijkpq(k+1) = 1 iff    ijk =    pq(k+1) = 1
   ijkpq(k+1) = 1 iff    ijk =    pq(k+1) = 1

variables for tree structure: we de   ne variables
variables for tree structure: we de   ne variables
variables for tree structure: we de   ne variables
  to encode the parse structure:
  to encode the parse structure:
  to encode the parse structure:

np 

2vision detections for verbs (actions or descriptive states)
2vision detections for verbs (actions or descriptive states)
2vision detections for verbs (actions or descriptive states)
remain to be a very challenging problem. we bypass this limita-
remain to be a very challenging problem. we bypass this limita-
remain to be a very challenging problem. we bypass this limita-
tion by exploiting the semantic relations between noun phrases
tion by exploiting the semantic relations between noun phrases
tion by exploiting the semantic relations between noun phrases
and verb phrases. we leave more precise alignment between
and verb phrases. we leave more precise alignment between
and verb phrases. we leave more precise alignment between
image parts and text as a future research direction.
image parts and text as a future research direction.
image parts and text as a future research direction.

dt 
3stuff refers to objects without rigid boundaries, e.g.,    wa-
3stuff refers to objects without rigid boundaries, e.g.,    wa-
3stuff refers to objects without rigid boundaries, e.g.,    wa-
ter   ,    sky    (typically mass nouns). we use the same features
ter   ,    sky    (typically mass nouns). we use the same features
ter   ,    sky    (typically mass nouns). we use the same features
a 
as above.
as above.
as above.
4l2 distance between classi   cation score vectors (xiao et
4l2 distance between classi   cation score vectors (xiao et
4l2 distance between classi   cation score vectors (xiao et
al., 2010)
al., 2010)
al., 2010)

cow 

nn 

 ijs = 1 iff
 ijs = 1 iff
 ijs = 1 iff

where i 2 [0, n ) and j 2 [i, n ) index rows and
where i 2 [0, n ) and j 2 [i, n ) index rows and
where i 2 [0, n ) and j 2 [i, n ) index rows and
columns of the cky-style matrix in figure 3. we
columns of the cky-style matrix in figure 3. we
columns of the cky-style matrix in figure 3. we

5the number of positions is equal to the number of phrase
5the number of positions is equal to the number of phrase
5the number of positions is equal to the number of phrase

types, since we select at most one from each type.
types, since we select at most one from each type.
types, since we select at most one from each type.

: local cohesion

in 

in 

pp 

dt 

the 

np 

nn 

grass 

vp 

vbd 
was 

vbg 
staring 

vp 

in 
at 

pp 

np 
prp 
me 

decision variable:

~%acl%2012%system%

objective function:

object (np)

np 

content selection score

action (vp)

vp 

pp 
recognition and matching
nn 

based on visual 
vbg 
staring 

vbd 
was 

vp 

in 
at 

dt 

a 

cow 

pp 

stuff (pp)
language model score for 
local linguistic cohesion

np 

in 

scene (pp)

in 

dt 

the 

nn 

grass 

pp 

google%
web%1et%
dataset%

nn 

dt 

np 

the 

countryside 

in 

in 

+

np 

prp 
me 

sentence composition := as constraint optimization 

approach to tree composition using extracted tree
approach to tree composition using extracted tree
approach to tree composition using extracted tree
fragments as described in   2. the input to the algo-
fragments as described in   2. the input to the algo-
fragments as described in   2. the input to the algo-
rithm is a set of extracted phrases (as tree fragments)
rithm is a set of extracted phrases (as tree fragments)
rithm is a set of extracted phrases (as tree fragments)
for each phrase type. the goal of the algorithm is to
for each phrase type. the goal of the algorithm is to
for each phrase type. the goal of the algorithm is to

ditionally, we de   ne variables for each pair of adja-
ditionally, we de   ne variables for each pair of adja-
ditionally, we de   ne variables for each pair of adja-
cent phrases to capture sequence cohesion:
cent phrases to capture sequence cohesion:
cent phrases to capture sequence cohesion:

   ijkpq(k+1) = 1 iff    ijk =    pq(k+1) = 1
   ijkpq(k+1) = 1 iff    ijk =    pq(k+1) = 1
   ijkpq(k+1) = 1 iff    ijk =    pq(k+1) = 1

using integer id135 

1we use color, texton (leung and malik, 1999), hog (dalal
1we use color, texton (leung and malik, 1999), hog (dalal
1we use color, texton (leung and malik, 1999), hog (dalal

and triggs, 2005) and sift (lowe, 2004) features.
and triggs, 2005) and sift (lowe, 2004) features.
and triggs, 2005) and sift (lowe, 2004) features.

variables for tree structure: we de   ne variables
variables for tree structure: we de   ne variables
variables for tree structure: we de   ne variables
  to encode the parse structure:
  to encode the parse structure:
  to encode the parse structure:

np 

2vision detections for verbs (actions or descriptive states)
2vision detections for verbs (actions or descriptive states)
2vision detections for verbs (actions or descriptive states)
remain to be a very challenging problem. we bypass this limita-
remain to be a very challenging problem. we bypass this limita-
remain to be a very challenging problem. we bypass this limita-
tion by exploiting the semantic relations between noun phrases
tion by exploiting the semantic relations between noun phrases
tion by exploiting the semantic relations between noun phrases
and verb phrases. we leave more precise alignment between
and verb phrases. we leave more precise alignment between
and verb phrases. we leave more precise alignment between
image parts and text as a future research direction.
image parts and text as a future research direction.
image parts and text as a future research direction.

dt 
3stuff refers to objects without rigid boundaries, e.g.,    wa-
3stuff refers to objects without rigid boundaries, e.g.,    wa-
3stuff refers to objects without rigid boundaries, e.g.,    wa-
ter   ,    sky    (typically mass nouns). we use the same features
ter   ,    sky    (typically mass nouns). we use the same features
ter   ,    sky    (typically mass nouns). we use the same features
a 
as above.
as above.
as above.
4l2 distance between classi   cation score vectors (xiao et
4l2 distance between classi   cation score vectors (xiao et
4l2 distance between classi   cation score vectors (xiao et
al., 2010)
al., 2010)
al., 2010)

cow 

nn 

 ijs = 1 iff
 ijs = 1 iff
 ijs = 1 iff

where i 2 [0, n ) and j 2 [i, n ) index rows and
where i 2 [0, n ) and j 2 [i, n ) index rows and
where i 2 [0, n ) and j 2 [i, n ) index rows and
columns of the cky-style matrix in figure 3. we
columns of the cky-style matrix in figure 3. we
columns of the cky-style matrix in figure 3. we

5the number of positions is equal to the number of phrase
5the number of positions is equal to the number of phrase
5the number of positions is equal to the number of phrase

types, since we select at most one from each type.
types, since we select at most one from each type.
types, since we select at most one from each type.

: local cohesion

in 

in 

pp 

dt 

the 

np 

nn 

grass 

vp 

vbd 
was 

vbg 
staring 

vp 

in 
at 

pp 

np 
prp 
me 

decision variable:

objective function:

object (np)

np 

content selection score

action (vp)

vp 

pp 
recognition and matching
nn 

based on visual 
vbg 
staring 

vbd 
was 

vp 

dt 

a 

cow 

in 
at 

np 

prp 
me 

pp 

stuff (pp)
language model score for 
local linguistic cohesion

np 

in 

scene (pp)

in 

dt 

the 

nn 

grass 

pp 

google%
web%1et%
dataset%

nn 

dt 

np 

the 

countryside 

in 

in 

age corpus of ordonez et al. (2011) for phrase ex-
age corpus of ordonez et al. (2011) for phrase ex-
age corpus of ordonez et al. (2011) for phrase ex-
traction and caption compression.
traction and caption compression.
traction and caption compression.

3 tree composition
3 tree composition
3 tree composition
in this section we describe a constraint optimization
in this section we describe a constraint optimization
in this section we describe a constraint optimization
approach to tree composition using extracted tree
approach to tree composition using extracted tree
approach to tree composition using extracted tree
fragments as described in   2. the input to the algo-
fragments as described in   2. the input to the algo-
fragments as described in   2. the input to the algo-
rithm is a set of extracted phrases (as tree fragments)
rithm is a set of extracted phrases (as tree fragments)
rithm is a set of extracted phrases (as tree fragments)
for each phrase type. the goal of the algorithm is to
for each phrase type. the goal of the algorithm is to
for each phrase type. the goal of the algorithm is to

sinv 

1we use color, texton (leung and malik, 1999), hog (dalal
1we use color, texton (leung and malik, 1999), hog (dalal
1we use color, texton (leung and malik, 1999), hog (dalal

and triggs, 2005) and sift (lowe, 2004) features.
and triggs, 2005) and sift (lowe, 2004) features.
and triggs, 2005) and sift (lowe, 2004) features.

np 

2vision detections for verbs (actions or descriptive states)
2vision detections for verbs (actions or descriptive states)
2vision detections for verbs (actions or descriptive states)
remain to be a very challenging problem. we bypass this limita-
remain to be a very challenging problem. we bypass this limita-
remain to be a very challenging problem. we bypass this limita-
tion by exploiting the semantic relations between noun phrases
tion by exploiting the semantic relations between noun phrases
tion by exploiting the semantic relations between noun phrases
and verb phrases. we leave more precise alignment between
and verb phrases. we leave more precise alignment between
and verb phrases. we leave more precise alignment between
image parts and text as a future research direction.
image parts and text as a future research direction.
image parts and text as a future research direction.

dt 
3stuff refers to objects without rigid boundaries, e.g.,    wa-
3stuff refers to objects without rigid boundaries, e.g.,    wa-
3stuff refers to objects without rigid boundaries, e.g.,    wa-
ter   ,    sky    (typically mass nouns). we use the same features
ter   ,    sky    (typically mass nouns). we use the same features
ter   ,    sky    (typically mass nouns). we use the same features
a 
as above.
as above.
as above.
4l2 distance between classi   cation score vectors (xiao et
4l2 distance between classi   cation score vectors (xiao et
4l2 distance between classi   cation score vectors (xiao et
al., 2010)
al., 2010)
al., 2010)

cow 

nn 

: local cohesion

   ijk = 1 iff phrase i of type j selected
   ijk = 1 iff phrase i of type j selected
   ijk = 1 iff phrase i of type j selected

where k is one of n=4 positions in a sentence.5 ad-
where k is one of n=4 positions in a sentence.5 ad-
where k is one of n=4 positions in a sentence.5 ad-
ditionally, we de   ne variables for each pair of adja-
ditionally, we de   ne variables for each pair of adja-
ditionally, we de   ne variables for each pair of adja-
cent phrases to capture sequence cohesion:
cent phrases to capture sequence cohesion:
cent phrases to capture sequence cohesion:

   ijkpq(k+1) = 1 iff    ijk =    pq(k+1) = 1
   ijkpq(k+1) = 1 iff    ijk =    pq(k+1) = 1
   ijkpq(k+1) = 1 iff    ijk =    pq(k+1) = 1

variables for tree structure: we de   ne variables
variables for tree structure: we de   ne variables
variables for tree structure: we de   ne variables
  to encode the parse structure:
  to encode the parse structure:
  to encode the parse structure:

 ijs = 1 iff
 ijs = 1 iff
 ijs = 1 iff

where i 2 [0, n ) and j 2 [i, n ) index rows and
where i 2 [0, n ) and j 2 [i, n ) index rows and
where i 2 [0, n ) and j 2 [i, n ) index rows and
columns of the cky-style matrix in figure 3. we
columns of the cky-style matrix in figure 3. we
columns of the cky-style matrix in figure 3. we

5the number of positions is equal to the number of phrase
5the number of positions is equal to the number of phrase
5the number of positions is equal to the number of phrase

types, since we select at most one from each type.
types, since we select at most one from each type.
types, since we select at most one from each type.

global 
sentence 
structure:

vp 

in 

in 

pp 

dt 

the 

np 

nn 

grass 

vp 

vbd 
was 

vbg 
staring 

vp 

in 
at 

pp 

np 
prp 
me 

decision variable:

objective function:

object (np)

np 

content selection score

action (vp)

vp 

based on visual 

vbd 

vp 

pp 

stuff (pp)
language model score for 
local linguistic cohesion

np 

in 

scene (pp)

in 

pp 

google%
web%1et%

np 

s 

age corpus of ordonez et al. (2011) for phrase ex-
age corpus of ordonez et al. (2011) for phrase ex-
age corpus of ordonez et al. (2011) for phrase ex-
traction and caption compression.
traction and caption compression.
traction and caption compression.

3 tree composition
3 tree composition
3 tree composition
in this section we describe a constraint optimization
in this section we describe a constraint optimization
in this section we describe a constraint optimization
approach to tree composition using extracted tree
approach to tree composition using extracted tree
approach to tree composition using extracted tree
fragments as described in   2. the input to the algo-
fragments as described in   2. the input to the algo-
fragments as described in   2. the input to the algo-
rithm is a set of extracted phrases (as tree fragments)
rithm is a set of extracted phrases (as tree fragments)
rithm is a set of extracted phrases (as tree fragments)
for each phrase type. the goal of the algorithm is to
for each phrase type. the goal of the algorithm is to
for each phrase type. the goal of the algorithm is to

vp 

np 

1we use color, texton (leung and malik, 1999), hog (dalal
1we use color, texton (leung and malik, 1999), hog (dalal
1we use color, texton (leung and malik, 1999), hog (dalal

and triggs, 2005) and sift (lowe, 2004) features.
and triggs, 2005) and sift (lowe, 2004) features.
and triggs, 2005) and sift (lowe, 2004) features.

pp 

np 

2vision detections for verbs (actions or descriptive states)
2vision detections for verbs (actions or descriptive states)
2vision detections for verbs (actions or descriptive states)
remain to be a very challenging problem. we bypass this limita-
remain to be a very challenging problem. we bypass this limita-
remain to be a very challenging problem. we bypass this limita-
tion by exploiting the semantic relations between noun phrases
tion by exploiting the semantic relations between noun phrases
tion by exploiting the semantic relations between noun phrases
and verb phrases. we leave more precise alignment between
and verb phrases. we leave more precise alignment between
and verb phrases. we leave more precise alignment between
np 
image parts and text as a future research direction.
image parts and text as a future research direction.
image parts and text as a future research direction.
dt 
3stuff refers to objects without rigid boundaries, e.g.,    wa-
3stuff refers to objects without rigid boundaries, e.g.,    wa-
3stuff refers to objects without rigid boundaries, e.g.,    wa-
ter   ,    sky    (typically mass nouns). we use the same features
ter   ,    sky    (typically mass nouns). we use the same features
ter   ,    sky    (typically mass nouns). we use the same features
a 
as above.
as above.
as above.
4l2 distance between classi   cation score vectors (xiao et
4l2 distance between classi   cation score vectors (xiao et
4l2 distance between classi   cation score vectors (xiao et
al., 2010)
al., 2010)
al., 2010)

cow 

nn 

dt 

in 

in 

   ijk = 1 iff phrase i of type j selected
   ijk = 1 iff phrase i of type j selected
   ijk = 1 iff phrase i of type j selected

where k is one of n=4 positions in a sentence.5 ad-
where k is one of n=4 positions in a sentence.5 ad-
where k is one of n=4 positions in a sentence.5 ad-
ditionally, we de   ne variables for each pair of adja-
ditionally, we de   ne variables for each pair of adja-
ditionally, we de   ne variables for each pair of adja-
cent phrases to capture sequence cohesion:
cent phrases to capture sequence cohesion:
cent phrases to capture sequence cohesion:

   ijkpq(k+1) = 1 iff    ijk =    pq(k+1) = 1
   ijkpq(k+1) = 1 iff    ijk =    pq(k+1) = 1
   ijkpq(k+1) = 1 iff    ijk =    pq(k+1) = 1

variables for tree structure: we de   ne variables
variables for tree structure: we de   ne variables
variables for tree structure: we de   ne variables
  to encode the parse structure:
  to encode the parse structure:
  to encode the parse structure:

 ijs = 1 iff
 ijs = 1 iff
 ijs = 1 iff

nn 

where i 2 [0, n ) and j 2 [i, n ) index rows and
where i 2 [0, n ) and j 2 [i, n ) index rows and
where i 2 [0, n ) and j 2 [i, n ) index rows and
columns of the cky-style matrix in figure 3. we
columns of the cky-style matrix in figure 3. we
columns of the cky-style matrix in figure 3. we

5the number of positions is equal to the number of phrase
5the number of positions is equal to the number of phrase
5the number of positions is equal to the number of phrase

types, since we select at most one from each type.
types, since we select at most one from each type.
types, since we select at most one from each type.

the 

countryside 

global 
sentence 
structure:

in 

in 

pp 

dt 

the 

np 

nn 

grass 

vp 

vbd 
was 

vbg 
staring 

vp 

in 
at 

pp 

np 
prp 
me 

decision variable:

objective function:

object (np)

np 

content selection score

action (vp)

vp 

based on visual 

vbd 

vp 

pp 

stuff (pp)
language model score for 
local linguistic cohesion

np 

in 

scene (pp)

in 

pp 

google%
web%1et%

np 

age corpus of ordonez et al. (2011) for phrase ex-
age corpus of ordonez et al. (2011) for phrase ex-
age corpus of ordonez et al. (2011) for phrase ex-
s 
traction and caption compression.
traction and caption compression.
traction and caption compression.

   ijk = 1 iff phrase i of type j selected
   ijk = 1 iff phrase i of type j selected
   ijk = 1 iff phrase i of type j selected

: vp " vp np 

vp 
vp 

3 tree composition
3 tree composition
3 tree composition
in this section we describe a constraint optimization
in this section we describe a constraint optimization
in this section we describe a constraint optimization
approach to tree composition using extracted tree
approach to tree composition using extracted tree
approach to tree composition using extracted tree
fragments as described in   2. the input to the algo-
fragments as described in   2. the input to the algo-
fragments as described in   2. the input to the algo-
rithm is a set of extracted phrases (as tree fragments)
rithm is a set of extracted phrases (as tree fragments)
rithm is a set of extracted phrases (as tree fragments)
for each phrase type. the goal of the algorithm is to
for each phrase type. the goal of the algorithm is to
for each phrase type. the goal of the algorithm is to

np 
np 

np 

pp 

pp 

dt 
a 

and triggs, 2005) and sift (lowe, 2004) features.
and triggs, 2005) and sift (lowe, 2004) features.
and triggs, 2005) and sift (lowe, 2004) features.

1we use color, texton (leung and malik, 1999), hog (dalal
1we use color, texton (leung and malik, 1999), hog (dalal
1we use color, texton (leung and malik, 1999), hog (dalal
np 
2vision detections for verbs (actions or descriptive states)
2vision detections for verbs (actions or descriptive states)
2vision detections for verbs (actions or descriptive states)
remain to be a very challenging problem. we bypass this limita-
remain to be a very challenging problem. we bypass this limita-
remain to be a very challenging problem. we bypass this limita-
tion by exploiting the semantic relations between noun phrases
tion by exploiting the semantic relations between noun phrases
tion by exploiting the semantic relations between noun phrases
and verb phrases. we leave more precise alignment between
and verb phrases. we leave more precise alignment between
and verb phrases. we leave more precise alignment between
image parts and text as a future research direction.
image parts and text as a future research direction.
image parts and text as a future research direction.

nn 
cow 

the 

dt 

in 

in 

np 
prp 
me 

nn 

3stuff refers to objects without rigid boundaries, e.g.,    wa-
3stuff refers to objects without rigid boundaries, e.g.,    wa-
3stuff refers to objects without rigid boundaries, e.g.,    wa-
ter   ,    sky    (typically mass nouns). we use the same features
ter   ,    sky    (typically mass nouns). we use the same features
ter   ,    sky    (typically mass nouns). we use the same features
as above.
as above.
as above.
4l2 distance between classi   cation score vectors (xiao et
4l2 distance between classi   cation score vectors (xiao et
4l2 distance between classi   cation score vectors (xiao et
for global parse tree structure
al., 2010)
al., 2010)
al., 2010)

language model score 

countryside 

where k is one of n=4 positions in a sentence.5 ad-
where k is one of n=4 positions in a sentence.5 ad-
where k is one of n=4 positions in a sentence.5 ad-
ditionally, we de   ne variables for each pair of adja-
ditionally, we de   ne variables for each pair of adja-
ditionally, we de   ne variables for each pair of adja-
cent phrases to capture sequence cohesion:
cent phrases to capture sequence cohesion:
cent phrases to capture sequence cohesion:

   ijkpq(k+1) = 1 iff    ijk =    pq(k+1) = 1
   ijkpq(k+1) = 1 iff    ijk =    pq(k+1) = 1
   ijkpq(k+1) = 1 iff    ijk =    pq(k+1) = 1

variables for tree structure: we de   ne variables
variables for tree structure: we de   ne variables
variables for tree structure: we de   ne variables
  to encode the parse structure:
  to encode the parse structure:
  to encode the parse structure:

 ijs = 1 iff
 ijs = 1 iff
 ijs = 1 iff

where i 2 [0, n ) and j 2 [i, n ) index rows and
where i 2 [0, n ) and j 2 [i, n ) index rows and
where i 2 [0, n ) and j 2 [i, n ) index rows and
columns of the cky-style matrix in figure 3. we
columns of the cky-style matrix in figure 3. we
columns of the cky-style matrix in figure 3. we

5the number of positions is equal to the number of phrase
5the number of positions is equal to the number of phrase
5the number of positions is equal to the number of phrase

types, since we select at most one from each type.
types, since we select at most one from each type.
types, since we select at most one from each type.

vp 

vbd 
was 

vbg 
staring 

vp 
vp 
in 
at 

global 
sentence 
structure:

in 
in 

pp 

dt 
the 

np 

nn 
grass 

decision variable:

objective function:

object (np)

np 

content selection score

action (vp)

vp 

based on visual 

vbd 

vp 

pp 

stuff (pp)
language model score for 
local linguistic cohesion

np 

in 

scene (pp)

in 

pp 

google%
web%1et%

np 

sentence composition := as constraint optimization 

using integer id135 

constraints:

consistency between 
sequence variables ------
& tree leaf variables -----

valid pid18 parse tree

objective function:

(content selection ~ visual rec)

(sequential cohesion ~ lang model)

(tree structure ~ pid18 model)

decision variable:

(sequential)

(tree structure)

automatic evaluation

machine translation: 
from images to text

id7     id165 precision 
(with modifications to handle degenerate cases)

0.22%
0.21%
0.2%
0.19%
0.18%
0.17%
0.16%
0.15%
0.14%

id7@15

tree: global sentence structure

sinv 

vp 

pp 

np 

dt 

nn 

the 

grass 

in 

in 

vp 

vbd 
was 

vbg 
staring 

vp 

in 

at 

np 

dt 

nn 

a 
pp 

cow 

np 

prp 

me 

sequence%

seq%+%tree% seq%+%pruning% seq%+%tree%+%

seq: local cohesion

pruning%

~%acl%2012%system%

half-successful examples (to motivate tree pruning)

an%old%clock%overlooks%the%old%river%bridge%
in%potes%in%cantabria%,%spain.%%

harvested%phrases%contain%overly%
extraneous%informa[on%%
!%generalize%cap[ons%before%extrac[ng%
tree%branches%

just%a%duck%swimming%in%the%river%
des%peres%in%heman%park%,%
university%city%,%missouri%e%may%13%,%
2008.%%

operational overview

given a query image

(cid:1)    harvest tree branches 
(cid:2)    compose a new tree by combining tree branches

1,000,000 (image, caption)

sbu captioned photo dataset

operational overview

1,000,000 (image, caption)

(cid:1)    prune trees

given a query image

(cid:2)    harvest tree branches 
(cid:3)    compose a new tree by combining tree branches

1,000,000 (image, caption)

sbu captioned photo dataset

image caption generalization

via tree compression

optimization:
 f =   (visual salience) +   (sequence cohesion) 

                                      +   (tree structure)

np5

np, 5

s 

vp 

pp 

np5

cc-jj 

jj5
(vintage)5 motorcycle5

nn5

nn5
(shot)5

vbn5
(done)5

in5
in5

cc5

jj5
black5 and5 white5

jj5

image caption generalization

via tree compression

optimization:
 f =   (visual salience) +   (sequence cohesion) 

                                      +   (tree structure)

       sentence compression with light-weight parsing
       dp algorithm possible (modification to cky parsing)

s 

vp, pp 
pp 

np 

cc-jj 

np 

np, nn 

nn 

(vintage) 

motorcycle 

(shot) 

(done) 

in 
in 

cc 

jj 
black  and  white 

jj 



machine translation: 
from images to text

#   
#   

id7     id165 precision (with 
modifications to handle degenerate cases)

automatic evaluation

machine caption   vs   human caption 

(forced choice w/ amazon mechanical turk)  

id7@15


 acl 2012 system (seq only):                   16% win

 final system (seq + tree + pruning):      24% win
0.22%
0.21%
0.2%
0.19%
0.18%
0.17%
0.16%
0.15%
0.14%

sequence%

seq%+%tree% seq%+%pruning% seq%+%tree%+%

pruning%

~%acl%2012%system%

good examples

correct%choice%of%
an%ac[on%verb%

the flower was so vivid 
and attractive. 

the duck sitting in the water. 

highly%
expressive!%

interes[ng%
choice%of%
an%abstract%
verb!%

this window depicts the church. 

blue flowers are running 
rampant in my garden. 

mini turing test: our system wins in ~ 24 % cases!

spring in a white dress. 

blue flowers have no scent. small white 
flowers have no idea what they are. 

almost%poe[c,%situa[onally%relevant%

scenes around the lake on my bike ride.

this horse walking along the road as 
we drove by. 

maybe the most common bird in the 
neighborhood, not just the most common 
water fowl in the neighborhood!

the duck was having a feast. 

examples with mistakes

the couch is definitely bigger 
than it looks in this photo. 

incorrect%object%
recogni[on%

yellow ball suspended in water. 

incorrect%scene%
matching%

my cat laying in my duffel bag. 

incorrect%
composi[on%

a high chair in 
the trees. 

examples with mistakes
a cat looking for a home. 
the other cats are making 
the computer room. 

??? 

the castle known for being 
the home of haid113t in the 
shakespeare play. 

conclusion

   butterfly sipping nectar 

from the flower   

   butterfly feeding on 

a flower   

   butterfly attracted to 

flowers   

how people write

web imagery

semantic 
correspondence

   a bu!er"y having lunch    

   a bu!er"y having lunch    

   a bu!er"y having lunch    

   a bu!er"y having lunch    

   a bu!er"y having lunch    

   a bu!er"y having lunch    

   a bu!er"y having lunch    

   a bu!er"y having lunch    

   a bu!er"y having lunch    

distributional hypothesis (harris 1954)

data decides

humans decide


{what can be described}     {what can be recognized} 

{what can be described} = {what can be recognized} 

treetalk(
babytalk(
$    start with a precise (but small) set of {what to recognize}, 

u

and increase the set

$    start with a large (but noisy) set of {what to describe}, 

and decrease the noise


   butterfly sipping nectar 

from the flower   

   butterfly feeding on 

a flower   

   butterfly attracted to 

flowers   

how people write

   a bu!er"y having lunch    

   a bu!er"y having lunch    

   a bu!er"y having lunch    

   a bu!er"y having lunch    

   a bu!er"y having lunch    

   a bu!er"y having lunch    

   a bu!er"y having lunch    

   a bu!er"y having lunch    

   a bu!er"y having lunch    

web imagery

semantic 
correspondence

world knowledge 

from language 
to improve vision
u

world knowledge 

from imagery 
to improve nlp


{what can be described}     {what can be recognized} 

{what can be described} = {what can be recognized} 

treetalk(
babytalk(
$    start with a precise (but small) set of {what to recognize}, 

and increase the set

$    start with a large (but noisy) set of {what to describe}, 

and decrease the noise


future: seeing beyond what   s in the image 

       what   s happening?
       how / why did this happen?
       what are the intent / goal of the participants?
       sentiment: are they happy?
       reaction: do we need to act on them (e.g., dispatching help)?



acknowledgements

my phd

song feng, polina kuznetsova 

other phd

jianfu chen, vicente ordonez, karl stratos, siming li, jesse 
dodge

ms

girish kulkarni, sagnik dhar, visruth premraj

undergrad

alyssa mensch

professor

industry

hal daum   iii, jia deng, alex berg, tamara berg, david warren
 
margaret mitchell, sujith ravi, ravi kumar, amit goyal





