syntax and parsing i 

constituency parsing

slav petrov     google 

thanks to: 

dan klein, ryan mcdonald, alexander rush, joakim nivre,    

greg durrett, david weiss 

lisbon machine learning school 2016

analyzing natural language

xs

vp
x

xvp

xv

x
np

pp
x

np
p
x

they     solved     the   problem     with    statistics

[

[

]

]

syntax and semantics

s

vp

np
p

np

v

np

pp

they     solved     the   problem     with    statistics

constituency and dependency

root

nsubj

prep

dobj

det

pobj

verb

pron
noun
they     solved     the   problem     with    statistics

noun

adp

det

constituency and dependency

root

nsubj

dobj

det

prep

pobj

verb

pron
noun
they     solved     the   problem     with    statistics

noun

adp

det

a    real    sentence

influential members of the house ways and means committee introduced 

legislation that would restrict how the new  

savings-and-loan bailout agency can raise capital, creating another potential 

obstacle to the government's sale of sick thrifts.

phrase structure parsing

    phrase structure parsing 
organizes syntax into 
constituents or brackets 
    in general, this involves 

nested trees 

    linguists can, and do, 

argue about details 
    lots of ambiguity 
    not the only kind of 

syntax    

    first part of today   s 

lecture

new art critics write reviews with computers

id33

    directed edges between pairs 

of word (head, dependent) 
    can handle free word-order 

languages 

    very efficient decoding 

algorithms exist 

    second part of today   s lecture

classical nlp: parsing

    write symbolic or logical rules: 

vbd                    vb            
vbn    vbz        vbp        vbz
nnp    nns        nn         nns    cd      nn
fed raises interest rates 0.5 percent

grammar (id18)

root     s 
s     np vp 
np     dt nn 
np     nn nns

np     np pp 
vp     vbp np 
vp     vbp np pp 
pp     in np

lexicon
nn     interest 
nns     raises 
vbp     interest 
vbz     raises 

    use deduction systems to prove parses from words 

    minimal grammar on    fed raises    sentence: 36 parses 
    real-size grammar: many millions of parses 

    this scaled very badly, didn   t yield broad-coverage tools

attachments

    i cleaned the dishes from dinner 

    i cleaned the dishes with detergent 

    i cleaned the dishes in my pajamas 

    i cleaned the dishes in the sink

id140

    a context-free grammar is a tuple <n, t, s, r> 

    n : the set of non-terminals 

    phrasal categories: s, np, vp, adjp, etc. 
    parts-of-speech (pre-terminals): nn, jj, dt, vb 

    t : the set of terminals (the words) 
    s : the start symbol 

    often written as root or top 
    not usually the sentence non-terminal s 

    r : the set of rules 

    of the form x     y1 y2     yk, with x, yi     n 
    examples: s     np vp, vp     vp cc vp 
    also called rewrites, productions, or local trees 

    a pid18 adds: 

    a top-down production id203 per rule p(y1 y2     yk | x)

treebank grammars

    need a pid18 for broad coverage parsing. 
    can take a grammar right off the trees (doesn   t work well): 

	
s     np vp .	
	
np     prp 	
np     dt nn	
	
vp     vbd np	 	
	
prp     she	
   

1.0 
0.5
0.5
1.0
1.0

    better results by enriching the grammar (e.g., lexicalization). 
    can also get reasonable parsers without lexicalization.

treebank grammar scale

    treebank grammars can be enormous 

    as fsas, the raw grammar has ~10k states, excluding the lexicon 
    better parsers usually make the grammars larger, not smaller

np

det

adj

noun

det

noun

plural noun

np

np

pp

np

conj

chomsky normal form

    chomsky normal form: 

    all rules of the form x     y z or x     w 
    in principle, this is no limitation on the space of (p)id18s 

    n-ary rules introduce new non-terminals 

vp

vbd   np    pp    pp

[vp     vbd np pp    ]

vp

[vp     vbd np    ]
vbd              np

pp

pp

    unaries / empties are    promoted    

    in practice it   s kind of a pain: 

    reconstructing n-aries is easy 
    reconstructing unaries is trickier 
    the straightforward transformations don   t preserve tree scores 

    makes parsing algorithms simpler!

a recursive parser

 bestscore(x,i,j,s) 
if (j = i+1) 
	
 return tagscore(x,s[i]) 
	
else 
	
 return max score(x->yz) * 
	

bestscore(y,i,k) * 
bestscore(z,k,j)

    will this parser work? 
    why or why not? 
    memory requirements?

a memoized parser

    one small change:

 bestscore(x,i,j,s) 
if (scores[x][i][j] == null) 
 if (j = i+1) 
    score = tagscore(x,s[i]) 
 else 
    score = max  score(x->yz) * 

	
	
	

	

       bestscore(y,i,k) * 
       bestscore(z,k,j) 

	

 scores[x][i][j] = score 
return scores[x][i][j] 

a bottom-up parser (cky)

x

y

z

	
	

	
	

    can also organize things bottom-up
 bestscore(s) 

for (i : [0,n-1]) 

 for (x : tags[s[i]]) 
 score[x][i][i+1] =  
    tagscore(x,s[i]) 

for (diff : [2,n]) 
for (i : [0,n-diff]) 
 j = i + diff 
 for (x->yz : rule) 
	   score[x][i][j] = max score[x][i][j], 
         score(x->yz) * 
         score[y][i][k] *  
         score[z][k][j] 

for (k : [i+1, j-1]) 

          
         

i                     k                     j

time: theory

    how much time will it take to parse? 

    for each diff (<= n) 

    for each i (<= n) 

    for each rule x     y z  

    for each split point k   
 

do constant work 

x

y

z

    total time: |rules|*n3 
    something like 5 sec for an unoptimized parse of a 

i                       k                     j

20-word sentences, or 0.2sec for an optimized 
parser

unary rules

    unary rules?

 bestscore(x,i,j,s) 
if (j = i+1) 
	
 return tagscore(x,s[i]) 
	
else 
	
 return max max score(x->yz) * 
	
       bestscore(y,i,k) * 
       bestscore(z,k,j) 
	
	

  max score(x->y) * 
	

  bestscore(y,i,j) 

	
	

cnf + unary closure

    we need unaries to be non-cyclic 

    can address by pre-calculating the unary closure 
    rather than having zero or more unaries, always have 

exactly one 

vp

vbd

np

dt

nn

vp

vbd

np

np

dt

nn

sbar

s

vp

sbar

vp

    alternate unary and binary layers 
    reconstruct unary chains afterwards

alternating layers

 return max max score(x->yz) * 

 bestscoreb(x,i,j,s) 
	
       bestscoreu(y,i,k) * 
       bestscoreu(z,k,j) 
	

	

 bestscoreu(x,i,j,s) 
	
	
	
	
	

if (j = i+1) 
 return tagscore(x,s[i]) 
else 
 return max max score(x->y) * 
	

	

  bestscoreb(y,i,j) 

treebank grammars

    need a pid18 for broad coverage parsing. 
    can take a grammar right off the trees (doesn   t work well): 

[charniak    96]

	
s     np vp .	
	
np     prp 	
np     dt nn	
	
vp     vbd np	 	
	
prp     she	
   

1.0 
0.5
0.5
1.0
1.0

    better results by enriching the grammar (e.g., lexicalization). 
f1
    can also get reasonable parsers without lexicalization.
72.0

model
charniak    96

conditional independence?

    not every np expansion can fill every np slot 

    a grammar with symbols like    np    won   t be 

context-free 

    statistically, conditional independence too 

strong

non-independence

    independence assumptions are often too strong. 

all nps

nps under s

nps under vp

np pp dt nn

prp

np pp dt nn

prp

np pp dt nn

prp

    example: the expansion of an np is highly dependent on 

the parent of the np (i.e., subjects vs. objects). 

    also: the subject and object expansions are correlated!

6%9%11%21%9%9%4%7%23%the game of designing a grammar

np

np

    structure annotation [johnson    98, klein & manning    03] 
    lexicalization [collins    99, charniak    00] 
    latent variables [matsuzaki et al. 05, petrov et al.    06] 
    (neural) crf parsing [hall et al.    14, durrett & klein    15]

a fully annotated (unlexicalized) tree

[klein & manning    03]

model
f1
charniak    96
72.0
klein&manning    03 86.3

the game of designing a grammar

    annotation refines base treebank symbols to 
improve statistical fit of the grammar 
    head lexicalization [collins    99, charniak    00]

problems with pid18s

    if we do no annotation, these trees differ only in one rule: 

    vp     vp pp 
    np     np pp 

    parse will go one way or the other, regardless of words 
    we addressed this in one way with unlexicalized grammars (how?) 
    lexicalization allows us to be sensitive to specific words

problems with pid18s

    what   s different between basic pid18 scores here? 
    what (lexical) correlations need to be scored?

lexicalized trees

[charniak    97, 

collins    97]

    add    headwords    to each 

phrasal node 
    syntactic vs. semantic heads 
    headship not in (most) 

treebanks 

    usually use head rules, e.g.: 

    np: 

    take leftmost np 
    take rightmost n* 
    take rightmost jj 
    take right child 

    vp: 

    take leftmost vb* 
    take leftmost vp 
    take left child

lexicalized pid18s?

    problem: we now have to estimate probabilities like 

    never going to get these atomically off of a treebank 

    solution: break up derivation into smaller steps

lexical derivation steps

    a derivation of a local tree [collins    99]

choose a head tag and word

choose a complement bag

generate children (incl. adjuncts)

recursively derive children

lexicalized grammars

    challenges: 

    many parameters to 

estimate: requires 
sophisticated smoothing 
techniques 

    exact id136 is too 
slow: requires pruning 
heuristics 

    difficult to adapt to new 
languages: at least head 
rules need to be 
specified, typically more 
changes needed

model
klein&manning    03 86.3
90.1
charniak    00

f1

lexicalized cky

(vp->vbd...np    )[saw]

(vp->vbd    )[saw]

np[her]

x[h]

y[h] z[h   ]

i           h          k         h             j

bestscore(x,i,j,h) 
  if (j = i+1) 
    return tagscore(x,s[i]) 
  else 
    return  
      max max score(x[h]->y[h] z[h   ]) * 
              bestscore(y,i,k,h) * 
              bestscore(z,k,j,h   ) 
          max score(x[h]->y[h   ] z[h]) * 
              bestscore(y,i,k,h   ) * 
              bestscore(z,k,j,h)

k,h   ,x->yz

k,h   ,x->yz

the game of designing a grammar

    annotation refines base treebank symbols to 
improve statistical fit of the grammar 
    automatic id91

latent variable grammars

[matsuzaki et al.    05, petrov et al.    06]

...

parse tree  
sentence

derivations

parameters 

learning latent annotations

em algorithm: 
	

    brackets are known 
    base categories are known 
    only induce subcategories

forward

x1

x4

x5

x6

x2
x3

just like forward-backward 
for id48s.

model
he
right
was
charniak    00
backward
petrov et al.    06

x7

.
f1
90.1
90.6

the game of designing a grammar

np

np

    annotation refines base treebank symbols to 
improve statistical fit of the grammar 
    crf parsing (+neural network representations)

generative vs. discriminative

generative

discriminative

maximize joint likelihood 

of gold tree and sentence

maximize conditional likelihood 

of gold tree given sentence

w1 w2 ... wn
w1 w2 ... wn

em-algorithm

w1 w2 ... wn

gradient-based  

algorithm

w1 w2 ... wn
w1 w2 ... wn

easy: expectations over 

observed trees 

[matsuzaki et al.    05, petrov et al.    06]

hard: expectations  

over all trees 
[petrov & klein    07,    08]

objective functions

generative objective function:

discriminative objective function:

 

(
 lmax
(
 lmax
p( 

 

 

,

)

w1... wn

[petrov, barrett, .... ...   
thibaux & klein    06]

)

w1... wn

[petrov & klein    08,   
finkel et. al    08]

,

)

w1... wn

)

(
 l

[liang, petrov, jordan & klein    07]

bayesian objective function:
max

(neural) crf parsing

[taskar et al.    04, petrov & klein    07, hall et al.    14, durrett et al.    15]

s

score of vp over

this span

fs.

w

be a
tree

vp

np

nnp

vbd

dt

nn

he gave

a speech

dense neural network
.w fs

l

e
d
o
m

 
r
a
e
n

i
l
-
g
o
l
 
e
s
r
a
p
s

crf parsing sparse features

p (t|x) / i[t is a tree]yr2t

exp (score(r))

& np     np pp

score(2np7     2np4 4pp7) =  w>f(2np7     2np4 4pp7)
firstword = a
prevword = gave
aftersplit = on
firstword = a
   

& np     np pp
& np

& np     np pp

np

np

pp

he  gave a  speech on  foreign  policy  .
0
7 8

2 3

1

4

5

6

neural crf model

score(2np7     2np4 4pp7) = 

(

w  fs(

2x7     2x4 4x7

)f>o

(np     np pp)
)

fs

fs = g(hv)

(arbitrary neural network)

fs

sparse

v

1

2 3

he  gave a  speech  on  foreign  policy  .
model
5
0
7 8
petrov et al.    06
durrett et al.    16

4

6

f1
90.6
91.3

lstm parsing

[vinyals et al.    15]

    treat parsing as a sequence-to-sequence prediction 

problem 

    completely ignores tree structure, uses lstms as 

black boxes

detailed english results

]
8
0
   
 
.
l
a
 
t
e
 
s
a
r
e
r
r
a
c
[

]
6
0
   
 
.
l
a
 
t
e
 
v
o
r
t
e
p
[

]
0
0
   
 
k
a
n
r
a
h
c
[

i

]
5
1
   
 
.
l
a
 
t
e
 
t
t
e
r
r
u
d
[

]
3
1
   
 
.
l
a
 
t
e
 
u
h
z
[

]
2
1
   
 
l
l

a
h
[

]
0
1
   
 
v
o
r
t
e
p
 
,
r
e
p
r
a
h
&
 
g
n
a
u
h
[

 

]
8
0
   
 
r
e
p
r
a
h
&
 
g
n
a
u
h
[

 

]
5
0
   
 
n
o
s
n
h
o
j
 
&
 
k
a
n
r
a
h
c
[

i

]
8
0
   
 
g
n
a
u
h
[

]
6
0
   
 
.
l
a
 
t
e
 
y
k
s
o
c
c
m

l

[

]
0
1
   
 
v
o
r
t
e
p
 
,
r
e
p
r
a
h
&
 
g
n
a
u
h
[

 

]
0
1
   
 
v
o
r
t
e
p
[

i

]
6
0
   
 
e
v
a
l
 
&
 
e
a
g
a
s
[

i

]
9
0
   
 
t
h
g
n
k
 
&
m
u
s
s
o
f
[

 

]
9
0
   
 
.
l
a
 
t
e
 
g
n
a
h
z
[

single parser

self-trained

reranker

product

combination

92.692.492.092.491.892.391.791.591.691.491.391.189.291.090.189.7multi-lingual results

petrov et al. '06*

hall et al.    14

durrett et al.    15

95

90

85

80

75

70

arabic

basque

french

german

hebrew

hungarian

korean

polish

swedish

average

t

s
h
g
n
e

l
 
l
l

a
 
1
f

 
t

e
s
 
t
s
e
t

85.183.593.082.290.788.681.081.385.480.283.282.090.780.288.387.278.479.783.478.880.980.686.878.685.285.478.379.874.778.7