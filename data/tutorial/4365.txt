machine translation as sequence modelling

philipp koehn

23 july 2016

philipp koehn

machine translation

23 july 2016

sequence model

1

    input sentence

eu quero ouvir uma apresentac     ao muito interessante.

    output

i want to listen to a very interesting presentation.

    idea: produce output one word at a time

philipp koehn

machine translation

23 july 2016

id165 model

2

    input sentence

eu quero ouvir uma apresentac     ao muito interessante.

    output
    p(i)
    p(want|i)
    p(to|i want)

    we learned how to do this today
    major    aw: output is not conditioned on input

philipp koehn

machine translation

23 july 2016

conditioning on input

3

    input sentence

eu quero ouvir uma apresentac     ao muito interessante.

    output

    p(i|eu quero ouvir uma apresentac     ao muito interessante.)
    p(want|i, eu quero ouvir uma apresentac     ao muito interessante.)
    p(to|i want, eu quero ouvir uma apresentac     ao muito interessante.)

    conditioning on entire source sentence too sparse to estimate

(unlikely that we have seen input sentence before)

philipp koehn

machine translation

23 july 2016

1-1 alignment to input

4

input

output

model

eu
|
i

quero

|

want

ouvir

|
hear

...

uma
|
a

p(i|eu)

p(want|quero)

p(hear|ouvir)

p(a|uma)

    we are slowly getting somewhere
    open problems

    we need to move beyond 1-1 alignments
    where do we get the probabilities from?

philipp koehn

machine translation

23 july 2016

5

ibm model 1

philipp koehn

machine translation

23 july 2016

lexical translation

6

    how to translate a word     look up in dictionary

haus     house, building, home, household, shell.

    multiple translations

    some more frequent than others
    for instance: house, and building most common
    special cases: haus of a snail is its shell

    note: in all lectures, we translate from a foreign language into english

philipp koehn

machine translation

23 july 2016

collect statistics

7

look at a parallel corpus (german text along with english translation)

translation of haus count
8,000
house
building
1,600
200
home
household
150
50
shell

philipp koehn

machine translation

23 july 2016

estimate translation probabilities

8

id113

                                             

pf (e) =

if e = house,
if e = building,
if e = home,

0.8
0.16
0.02
0.015 if e = household,
0.005 if e = shell.

philipp koehn

machine translation

23 july 2016

alignment

9

    in a parallel text (or when we translate), we align words in one language with

the words in the other

    word positions are numbered 1   4

philipp koehn

machine translation

23 july 2016

dashausistkleinthehouseissmall12341234alignment function

10

    formalizing alignment with an alignment function

    mapping an english target word at position i to a german source word at

position j with a function a : i     j

    example

a : {1     1, 2     2, 3     3, 4     4}

philipp koehn

machine translation

23 july 2016

reordering

11

words may be reordered during translation

a : {1     3, 2     4, 3     2, 4     1}

philipp koehn

machine translation

23 july 2016

dashausistkleinthehouseissmall12341234ibm model 1

12

    generative model: break up translation process into smaller steps

    ibm model 1 only uses lexical translation

    translation id203

    for a foreign sentence f = (f1, ..., flf ) of length lf
    to an english sentence e = (e1, ..., ele) of length le
    with an alignment of each english word ej to a foreign word fi according to

the alignment function a : j     i

p(e, a|f ) =

 

(lf + 1)le

    parameter   is a id172 constant

le(cid:89)

j=1

t(ej|fa(j))

philipp koehn

machine translation

23 july 2016

example

13

haus

t(e|f )
e
house
0.8
building
0.16
home
0.02
household 0.015
shell
0.005

ist

t(e|f )
0.8
0.16
0.02
0.015
0.005

e
is
   s
exists
has
are

klein

e
small
little
short
minor
petty

t(e|f )
0.4
0.4
0.1
0.06
0.04

das

e
the
that
which
who
this

t(e|f )
0.7
0.15
0.075
0.05
0.025

p(e, a|f ) =

=

 

43    t(the|das)    t(house|haus)    t(is|ist)    t(small|klein)
43    0.7    0.8    0.8    0.4

 

= 0.0028 

philipp koehn

machine translation

23 july 2016

learning lexical translation models

14

    we would like to estimate the lexical translation probabilities t(e|f ) from a

parallel corpus

    ... but we do not have the alignments
    chicken and egg problem
    if we had the alignments,

    we could estimate the parameters of our generative model

    if we had the parameters,

    we could estimate the alignments

philipp koehn

machine translation

23 july 2016

em algorithm

15

    incomplete data

    if we had complete data, would could estimate model
    if we had model, we could    ll in the gaps in the data

    expectation maximization (em) in a nutshell
1. initialize model parameters (e.g. uniform)
2. assign probabilities to the missing data
3. estimate model parameters from completed data
4. iterate steps 2   3 until convergence

philipp koehn

machine translation

23 july 2016

em algorithm

16

    initial step: all alignments equally likely
    model learns that, e.g., la is often aligned with the

philipp koehn

machine translation

23 july 2016

... la maison ... la maison blue ... la fleur ...... the house ... the blue house ... the flower ...em algorithm

17

    after one iteration
    alignments, e.g., between la and the are more likely

philipp koehn

machine translation

23 july 2016

... la maison ... la maison blue ... la fleur ...... the house ... the blue house ... the flower ...em algorithm

18

    after another iteration
    it becomes apparent that alignments, e.g., between    eur and    ower are more

likely (pigeon hole principle)

philipp koehn

machine translation

23 july 2016

... la maison ... la maison id7 ... la fleur ...... the house ... the blue house ... the flower ...em algorithm

19

    convergence
    inherent hidden structure revealed by em

philipp koehn

machine translation

23 july 2016

... la maison ... la maison id7 ... la fleur ...... the house ... the blue house ... the flower ...em algorithm

20

    parameter estimation from the aligned corpus

philipp koehn

machine translation

23 july 2016

... la maison ... la maison id7 ... la fleur ...... the house ... the blue house ... the flower ...p(la|the) = 0.453p(le|the) = 0.334p(maison|house) = 0.876p(id7|blue) = 0.563...ibm model 1 and em

21

    em algorithm consists of two steps
    expectation-step: apply model to the data

    parts of the model are hidden (here: alignments)
    using the model, assign probabilities to possible values

    maximization-step: estimate model from data

    take assign values as fact
    collect counts (weighted by probabilities)
    estimate model from counts

    iterate these steps until convergence

philipp koehn

machine translation

23 july 2016

ibm model 1 and em

22

    we need to be able to compute:

    expectation-step: id203 of alignments

    maximization-step: count collection

philipp koehn

machine translation

23 july 2016

ibm model 1 and em

23

    probabilities

p(the|la) = 0.7

p(the|maison) = 0.1

p(house|la) = 0.05

p(house|maison) = 0.8

    alignments
   
   

@

@

   
   @

la   
the
maison   
house
p(e, a|f ) = 0.56
p(a|e, f ) = 0.824

la   
the
maison   
house
p(e, a|f ) = 0.035
p(a|e, f ) = 0.052
c(the|la) = 0.824 + 0.052

c(the|maison) = 0.118 + 0.007

 

 

 
@

 
@ 

   
   @

   
    

la   
the
maison   
house
p(e, a|f ) = 0.08
p(a|e, f ) = 0.118

la   
the
maison   
house
p(e, a|f ) = 0.005
p(a|e, f ) = 0.007
c(house|la) = 0.052 + 0.007

c(house|maison) = 0.824 + 0.118

    counts

philipp koehn

machine translation

23 july 2016

24

id48 model

philipp koehn

machine translation

23 july 2016

modeling alignment

25

    ibm model 1 uses alignments to identify conditioning context

    but: does not model alignment itself

    is it better to start translating the 1st input word or 10th input word?

philipp koehn

machine translation

23 july 2016

id48 model

26

    condition word movements on previous word

    id48 alignment model:

p(a(j)|a(j     1), lf )

philipp koehn

machine translation

23 july 2016

decoding

27

    input sentence

eu quero ouvir uma apresentac     ao muito interessante.

    translation

input

output

translation

alignment

language

model

eu
|
i

/

want

quero

\

p(i|eu)
p(1|0, 7)
p(i|start)

p(want|quero)

p(2|1, 7)
p(want|i)

to

p(to|quero)
p(2|2, 7)
p(to|want)

ouvir

|
hear

...

uma
|
a

p(hear|ouvir)

p(3|2, 7)
p(hear|to)

p(a|uma)
p(4|3, 7)
p(a|hear)

philipp koehn

machine translation

23 july 2016

28

phrase-based model

philipp koehn

machine translation

23 july 2016

motivation

29

    word-based models translate words as atomic units
    phrase-based models translate phrases as atomic units
    advantages:

    many-to-many translation can handle non-compositional phrases
    use of local context in translation
    the more data, the longer phrases can be learned

       standard model   , used by google translate and others

philipp koehn

machine translation

23 july 2016

phrase-based model

30

    foreign input is segmented in phrases
    each phrase is translated into english
    phrases are reordered

philipp koehn

machine translation

23 july 2016

phrase translation table

31

    main knowledge source: table with phrase translations and their probabilities
    example: phrase translations for natuerlich

translation id203   (  e|   f )
of course
naturally
of course ,
, of course ,

0.5
0.3
0.15
0.05

philipp koehn

machine translation

23 july 2016

real example

32

    phrase translations for den vorschlag learned from the europarl corpus:

  (  e|   f )
0.6227
0.1068
0.0341
0.0250
0.0227
0.0205
0.0159
0.0159

english
the proposal
   s proposal
a proposal
the idea
this proposal
proposal
of the proposal
the proposals

english
the suggestions
the proposed
the motion
the idea of
the proposal ,
its proposal
it
...
    lexical variation (proposal vs suggestions)
    morphological variation (proposal vs proposals)
    included function words (the, a, ...)
    noise (it)

  (  e|   f )
0.0114
0.0114
0.0091
0.0091
0.0068
0.0068
0.0068
...

philipp koehn

machine translation

23 july 2016

learning a phrase translation table

33

    task: learn the model from a parallel corpus

    three stages:

    word alignment: using ibm models or other method
    extraction of phrase pairs
    scoring phrase pairs

philipp koehn

machine translation

23 july 2016

word alignment

34

philipp koehn

machine translation

23 july 2016

housetheinstaywillhethatassumesmichaelmichaelgehtdavonausdasserimhausbleibt,extracting phrase pairs

35

extract phrase pair consistent with word alignment:

assumes that / geht davon aus , dass

philipp koehn

machine translation

23 july 2016

housetheinstaywillhethatassumesmichaelmichaelgehtdavonausdasserimhausbleibt,consistent

36

ok

violated

one

alignment

point outside

ok

unaligned
word is    ne

all words of the phrase pair have to align to each other.

philipp koehn

machine translation

23 july 2016

phrase pair extraction

37

smallest phrase pairs:

michael     michael

assumes     geht davon aus / geht davon aus ,

that     dass / , dass

he     er

will stay     bleibt

in the     im
house     haus

unaligned words (here: german comma) lead to multiple translations

philipp koehn

machine translation

23 july 2016

housetheinstaywillhethatassumesmichaelmichaelgehtdavonausdasserimhausbleibt,larger phrase pairs

38

michael assumes     michael geht davon aus / michael geht davon aus ,

assumes that     geht davon aus , dass ; assumes that he     geht davon aus , dass er

in the house     im haus
that he     dass er / , dass er
michael assumes that     michael geht davon aus , dass

;

michael assumes that he     michael geht davon aus , dass er

michael assumes that he will stay in the house     michael geht davon aus , dass er im haus bleibt

assumes that he will stay in the house     geht davon aus , dass er im haus bleibt
that he will stay in the house     dass er im haus bleibt
; dass er im haus bleibt ,

he will stay in the house     er im haus bleibt

; will stay in the house     im haus bleibt

philipp koehn

machine translation

23 july 2016

housetheinstaywillhethatassumesmichaelmichaelgehtdavonausdasserimhausbleibt,scoring phrase translations

39

    phrase pair extraction: collect all phrase pairs from the data
    phrase pair scoring: assign probabilities to phrase translations
    score by relative frequency:

  (   f|  e) =

(cid:80)

count(  e,   f )
  fi count(  e,   fi)

philipp koehn

machine translation

23 july 2016

decoding
    we have a mathematical model for translation

p(e|f )

40

    task of decoding:    nd the translation ebest with highest id203

ebest = argmaxe p(e|f )

    two types of error

    the most probable translation is bad        x the model
    search does not    nd the most probably translation        x the search

    decoding is evaluated by search error, not quality of translations

(although these are often correlated)

philipp koehn

machine translation

23 july 2016

translation process

41

    task: translate this sentence from german into english

philipp koehn

machine translation

23 july 2016

ergehtjanichtnachhausetranslation process

42

    task: translate this sentence from german into english

    pick phrase in input, translate

philipp koehn

machine translation

23 july 2016

ergehtjanichtnachhauseerhetranslation process

43

    task: translate this sentence from german into english

    pick phrase in input, translate

    it is allowed to pick words out of sequence reordering
    phrases may have multiple words: many-to-many translation

philipp koehn

machine translation

23 july 2016

ergehtjanichtnachhauseerja nichthedoes nottranslation process

44

    task: translate this sentence from german into english

    pick phrase in input, translate

philipp koehn

machine translation

23 july 2016

ergehtjanichtnachhauseergehtja nichthedoes notgotranslation process

45

    task: translate this sentence from german into english

    pick phrase in input, translate

philipp koehn

machine translation

23 july 2016

ergehtjanichtnachhauseergehtja nichtnach hausehedoes notgohometranslation options

46

    many translation options to choose from

    in europarl phrase table: 2727 matching phrase pairs for this sentence
    by pruning to the top 20 per phrase, 202 translation options remain

philipp koehn

machine translation

23 july 2016

heergehtjanichtnachhauseit, it, heisaregoesgoyesis, of coursenotdo notdoes notis notaftertoaccording toinhousehomechamberat homenotis notdoes notdo nothomeunder housereturn homedo notit ishe will beit goeshe goesisareis after alldoestofollowingnot afternot to,notis notare notis not atranslation options

47

    the machine translation decoder does not know the right answer

    picking the right translation options
    arranging them in the right order

    search problem solved by heuristic id125

philipp koehn

machine translation

23 july 2016

heergehtjanichtnachhauseit, it, heisaregoesgoyesis, of coursenotdo notdoes notis notaftertoaccording toinhousehomechamberat homenotis notdoes notdo nothomeunder housereturn homedo notit ishe will beit goeshe goesisareis after alldoestofollowingnot afternot tonotis notare notis not adecoding: precompute translation options

48

consult phrase translation table for all input phrases

philipp koehn

machine translation

23 july 2016

ergehtjanichtnachhausedecoding: start with initial hypothesis

49

initial hypothesis: no input words covered, no output produced

philipp koehn

machine translation

23 july 2016

ergehtjanichtnachhausedecoding: hypothesis expansion

50

pick any translation option, create new hypothesis

philipp koehn

machine translation

23 july 2016

ergehtjanichtnachhausearedecoding: hypothesis expansion

51

create hypotheses for all other translation options

philipp koehn

machine translation

23 july 2016

ergehtjanichtnachhauseareithedecoding: hypothesis expansion

52

also create hypotheses from created partial hypothesis

philipp koehn

machine translation

23 july 2016

ergehtjanichtnachhauseareithegoesdoes notyesgotohomehomedecoding: find best path

53

backtrack from highest scoring complete hypothesis

philipp koehn

machine translation

23 july 2016

ergehtjanichtnachhauseareithegoesdoes notyesgotohomehomecomputational complexity

54

    the suggested process creates exponential number of hypothesis
    machine translation decoding is np-complete
    reduction of search space:
    recombination (risk-free)
    pruning (risky)

philipp koehn

machine translation

23 july 2016

recombination

55

    two hypothesis paths lead to two matching hypotheses

    same number of foreign words translated
    same english words in the output
    different scores

    worse hypothesis is dropped

philipp koehn

machine translation

23 july 2016

itisit isitisrecombination

56

    two hypothesis paths lead to hypotheses indistinguishable in subsequent search

    same number of foreign words translated
    same last two english words in output (assuming trigram language model)
    same last foreign word translated
    different scores

    worse hypothesis is dropped

philipp koehn

machine translation

23 july 2016

ithedoes notdoes notithedoes notpruning

57

    recombination reduces search space, but not enough
(we still have a np complete problem on our hands)

    pruning: remove bad hypotheses early
    put comparable hypothesis into stacks

(hypotheses that have translated same number of input words)

    limit number of hypotheses in each stack

philipp koehn

machine translation

23 july 2016

stacks

58

    hypothesis expansion in a stack decoder

    translation option is applied to hypothesis
    new hypothesis is dropped into a stack further down

philipp koehn

machine translation

23 july 2016

areithegoesdoes notyesno wordtranslatedone wordtranslatedtwo wordstranslatedthree wordstranslatedstack decoding algorithm

59

1: place empty hypothesis into stack 0
2: for all stacks 0...n     1 do

for all hypotheses in stack do

for all translation options do

if applicable then

3:
4:
5:
6:
7:
8:
9:
10:
11:
12:
13: end for

end if
end for

end for

create new hypothesis
place in stack
recombine with existing hypothesis if possible
prune stack if too big

philipp koehn

machine translation

23 july 2016

pruning

60

    pruning strategies

    histogram pruning: keep at most k hypotheses in each stack
    stack pruning: keep hypothesis with score       best score (   < 1)

    computational time complexity of decoding with histogram pruning
o(max stack size    translation options    sentence length)
    number of translation options is linear with sentence length, hence:

o(max stack size    sentence length2)

    quadratic complexity

philipp koehn

machine translation

23 july 2016

61

operation sequence model

philipp koehn

machine translation

23 july 2016

a critique: phrase segmentation is arbitrary

62

    if multiple segmentations possible - why chose one over the other?

spass am spiel vs.

spass

am spiel

    when choose larger phrase pairs or multiple shorter phrase pairs?

spass am spiel vs.

spass

am spiel vs.

spass am spiel

    none of this has been properly addressed

philipp koehn

machine translation

23 july 2016

a critique: strong independence assumptions

63

    lexical context considered only within phrase pairs

spass am     fun with

    no context considered between phrase pairs

spass am ?     ?

?

fun with ?

    some phrasal context considered in lexicalized reordering model

... but not based on the identity of neighboring phrases

philipp koehn

machine translation

23 july 2016

segmentation? minimal phrase pairs

64

   

philipp koehn

machine translation

23 july 2016

nat  rlichhatjohnspa   amspielof coursejohnhasfun with thegamenat  rlichhatjohnspa  spielof coursejohnhasfungameamwith theindependence?

65

consider sequence of operations

o1 generate(nat   urlich, of course)

insert gap

o2
o3 generate (john, john)
o4
o5 generate (hat, has)
o6

jump forward

jump back (1)

o7 generate(nat   urlich, of course)

o8 generate(am, with)
o9 generatetargetonly(the)
o10 generate(spiel, game)

nat   urlich    
of course
nat   urlich    
john
of course john
nat   urlich hat     john
of course john has
nat   urlich hat john    
of course john has
nat   urlich hat john spa      
of course john has fun
nat   urlich hat john spa   am    
of course john has fun with the
nat   urlich hat john spa   am spiel    
of course john has fun with the game

philipp koehn

machine translation

23 july 2016

operation sequence model

66

    operations

    generate (phrase translation)
    generate target only
    generate source only
    insert gap
    jump back
    jump forward

    id165 sequence model over operations, e.g., 5-gram model:
p(o1) p(o2|o1) p(o3|o1, o2) ... p(o10|o6, o7, o8, o9)

philipp koehn

machine translation

23 july 2016

in practice

67

    operation sequence model used as additional feature function

    signi   cant improvements over phrase-based baseline

    state-of-the-art systems include such a model

philipp koehn

machine translation

23 july 2016

68

syntax

philipp koehn

machine translation

23 july 2016

sequence model     really?

69

    different languages have different word order

    language is recursive     tree formalisms

    need to translate meaning, not words

philipp koehn

machine translation

23 july 2016

a vision

70

philipp koehn

machine translation

23 july 2016

sourcetargetlexical transfersyntactic transfersemantic transferinterlinguaanalysisgenerationphrase structure grammar

71

    phrase structure

    noun phrases: the big man, a house, ...
    prepositional phrases: at 5 o   clock, in edinburgh, ...
    verb phrases: going out of business, eat chicken, ...
    adjective phrases, ...

    context-free grammars (id18)

    non-terminal symbols: phrase structure labels, part-of-speech tags
    terminal symbols: words
    production rules: nt     [nt,t]+
example: np     det nn

philipp koehn

machine translation

23 july 2016

phrase structure grammar

72

phrase structure grammar tree for an english sentence

(as produced collins    parser)

philipp koehn

machine translation

23 july 2016

prpimdshallvbbevbgpassingrpontotoprpyoudtsomennscommentsnp-appvp-avp-avp-assynchronous phrase structure grammar

73

    english rule

    french rule

np     det jj nn

np     det nn jj

    synchronous rule (indices indicate alignment):

np     det1 nn2 jj3 | det1 jj3 nn2

philipp koehn

machine translation

23 july 2016

synchronous grammar rules

74

    nonterminal rules

    terminal rules

    mixed rules

np     det1 nn2 jj3 | det1 jj3 nn2

n     maison | house

np     la maison id7e | the blue house

np     la maison jj1 | the jj1 house

philipp koehn

machine translation

23 july 2016

tree-based translation model

75

    translation by parsing

    synchronous grammar has to parse entire input sentence
    output tree is generated at the same time
    process is broken up into a number of rule applications

    translation id203

score(tree, e, f) =

(cid:89)

i

rulei

    many ways to assign probabilities to rules

philipp koehn

machine translation

23 july 2016

aligned tree pair

76

phrase structure grammar trees with word alignment

(german   english sentence pair.)

philipp koehn

machine translation

23 july 2016

prpimdshallvbbevbgpassingrpontotoprpyoudtsomennscommentsnp-appvp-avp-avp-asichpperwerdevafinihnenpperdieartentsprechendenadjanmerkungennnaush  ndigenvvfinnpvpsvpreordering rule

77

    subtree alignment

vp

np

...

pper

...

vvfin

aush  andigen

   

vp

vbg

passing

rp

on

pp

...

np

...

    synchronous grammar rule

vp     pper1 np2 aush  andigen | passing on pp1 np2

    note:

    one word aush  andigen mapped to two words passing on ok
    but: fully non-terminal rule not possible

(one-to-one mapping constraint for nonterminals)

philipp koehn

machine translation

23 july 2016

learning syntactic translation rules

78

=

pro

ihnen

pp

to

to

prp

you

philipp koehn

machine translation

23 july 2016

prp   imd   shallvb   bevbg    passingdt   somerp   onto   toprp   younns   commentsich   pperwerde   vafinihnen   pperdie   artentspr.   adjanm.   nnaush  nd.   vvfinnpppvpvpvpsnpvpvpsminimal rule extraction

79

align each node in the parse tree

philipp koehn

machine translation

23 july 2016

ishallbepassingontoyousomecommentsprpmdvbvbgrptoprpdtnnsnpppvpvpvpsichwerdeihnendieentsprechendenanmerkungenaush  ndigensyntax decoding

80

german input sentence with tree

philipp koehn

machine translation

23 july 2016

siepperwillvafineinearttassennkaffeenntrinkenvvinfnpvpsvbdrink   syntax decoding

81

purely lexical rule:    lling a span with a translation (a constituent in the chart)

philipp koehn

machine translation

23 july 2016

siepperwillvafineinearttassennkaffeenntrinkenvvinfnpvpsproshevbdrink      syntax decoding

82

purely lexical rule:    lling a span with a translation (a constituent in the chart)

philipp koehn

machine translation

23 july 2016

siepperwillvafineinearttassennkaffeenntrinkenvvinfnpvpsproshevbdrinknncoffee         syntax decoding

83

purely lexical rule:    lling a span with a translation (a constituent in the chart)

philipp koehn

machine translation

23 july 2016

siepperwillvafineinearttassennkaffeenntrinkenvvinfnpvpsproshevbdrinknncoffee            syntax decoding

84

complex rule: matching underlying constituent spans, and covering words

philipp koehn

machine translation

23 july 2016

siepperwillvafineinearttassennkaffeenntrinkenvvinfnpvpsproshevbdrinknn|cupin|ofnpppnnnpdet|anncoffee               syntax decoding

85

complex rule with reordering

philipp koehn

machine translation

23 july 2016

siepperwillvafineinearttassennkaffeenntrinkenvvinfnpvpsproshevbdrinknn|cupin|ofnpppnnnpdet|avbz|wantsvbvpvpnpto|tonncoffee                  syntax decoding

86

philipp koehn

machine translation

23 july 2016

siepperwillvafineinearttassennkaffeenntrinkenvvinfnpvpsproshevbdrinknn|cupin|ofnpppnnnpdet|avbz|wantsvbvpvpnpto|tonncoffeespro  vp                  syntactic decoding

87

inspired by monolingual syntactic chart parsing:

during decoding of the source sentence,

a chart with translations for the o(n2) spans has to be    lled

philipp koehn

machine translation

23 july 2016

siepperwillvafineinearttassennkaffeenntrinkenvvinfnpvpscomments

88

    syntax-based models proven to work well for german, chinese

    decoding more complex and slower

    needed: syntactic parser and hand-holding for each language pair

philipp koehn

machine translation

23 july 2016

89

in defense of sequence models

philipp koehn

machine translation

23 july 2016

evidence from human translators

90

    translation process studies (e.g., in casmacat)
    humans start translating after reading a few words

philipp koehn

machine translation

23 july 2016

left-to-right parsing

91

push down automaton

the

interesting

lecture

ends

soon

philipp koehn

machine translation

23 july 2016

left-to-right parsing

92

push down automaton

look up pos tag

interesting

lecture

ends

soon

the
det

philipp koehn

machine translation

23 july 2016

left-to-right parsing

93

push down automaton

look up pos tag

the
det

interesting

lecture

ends

soon

jj

det

philipp koehn

machine translation

23 july 2016

left-to-right parsing

94

push down automaton

look up pos tag

the
det

interesting

lecture

ends

soon

jj

det

n
jj

det

philipp koehn

machine translation

23 july 2016

left-to-right parsing

95

push down automaton

apply rule

the
det

interesting

jj

det

lecture

np

ends

soon

philipp koehn

machine translation

23 july 2016

left-to-right parsing

96

push down automaton

look up pos tag

the
det

interesting

jj

det

lecture

np

ends
vb
np

soon

philipp koehn

machine translation

23 july 2016

left-to-right parsing

97

push down automaton

look up pos tag

the
det

interesting

jj

det

lecture

np

ends
vb
np

soon
rb
vb
np

philipp koehn

machine translation

23 july 2016

left-to-right parsing

98

push down automaton

apply rule

the
det

interesting

jj

det

lecture

np

ends
vb
np

soon
vp
np

philipp koehn

machine translation

23 july 2016

left-to-right parsing

99

push down automaton

apply rule

the
det

interesting

jj

det

lecture

np

soon

s

ends
vb
np

philipp koehn

machine translation

23 july 2016

100

neural translation

philipp koehn

machine translation

23 july 2016

neural networks

101

    real valued vector representations
    multiple layers of computation
    non-linear functions

(cid:126)h = sigmoid(w (cid:126)x)
(cid:126)y = sigmoid(v (cid:126)h)

philipp koehn

machine translation

23 july 2016

id27s

102

philipp koehn

machine translation

23 july 2016

id27s

103

philipp koehn

machine translation

23 july 2016

why id4?

104

    id27s allow learning from similar examples

    condition on a lot of context without backoff schemes

    maybe there is something to non-linearity

philipp koehn

machine translation

23 july 2016

neural id165 language model

105

philipp koehn

machine translation

23 july 2016

word 1word 2word 3word 4word 5hidden layerrecurrent neural networks

106

philipp koehn

machine translation

23 july 2016

word 1word 2ec1hword 2word 3echhcopy valuesword 3word 4echhcopy valuesencoder-decoder translation model

107

philipp koehn

machine translation

23 july 2016

input wordembeddingsrecurrent nnrecurrent nnoutput wordsattention translation model

108

philipp koehn

machine translation

23 july 2016

input wordembeddingsleft-to-rightrecurrent nnright-to-leftrecurrent nnalignmentinput contexthidden statefjaijcisioutput words109

practical matters

philipp koehn

machine translation

23 july 2016

how good is mt?

110

portuguese:
a selec     ao portuguesa de futebol, que se sagrou no domingo pela primeira vez
campe  a europeia, ao vencer por 1-0 a franc  a na    nal, foi hoje recebida em euforia
por milhares de pessoas no aeroporto humberto delgado, em lisboa.
o avi  ao eusbio, que foi escoltado por dois avi  oes da forc  a area portuguesa desde a
entrada em territ  orio portugu  es, aterrou em lisboa `as 12:40, tendo passado por um
improvisado    arco do triunfo   , formado por dois jatos de   agua com as duas cores
principais da bandeira nacional.
google translate:
the portuguese national soccer team, which won on sunday for the    rst time
european champions by winning 1-0 to france in the    nal, was received today in
euphoria by thousands of people at the airport humberto delgado in lisbon.
the plane eusebius, who was escorted by two aircraft of the portuguese air force
since the entry into portuguese territory, landed in lisbon at 12:40, having gone
through a makeshift    triumphal arch   , formed by two water jets with two colors
main national    ag.

philipp koehn

machine translation

23 july 2016

how good is mt?

111

portuguese:
a selec     ao portuguesa de futebol, que se sagrou no domingo pela primeira vez
campe  a europeia, ao vencer por 1-0 a franc  a na    nal, foi hoje recebida em euforia
por milhares de pessoas no aeroporto humberto delgado, em lisboa.
o avi  ao eusbio, que foi escoltado por dois avi  oes da forc  a area portuguesa desde a
entrada em territ  orio portugu  es, aterrou em lisboa `as 12:40, tendo passado por um
improvisado    arco do triunfo   , formado por dois jatos de   agua com as duas cores
principais da bandeira nacional.
google translate:
the portuguese national soccer team, which won on sunday for the    rst time
european champions by winning 1-0 to france in the    nal, was received today in
euphoria by thousands of people at the airport humberto delgado in lisbon.
the plane eusebius, who was escorted by two aircraft of the portuguese air force
since the entry into portuguese territory, landed in lisbon at 12:40, having gone
through a makeshift    triumphal arch   , formed by two water jets with two colors
main national    ag.

philipp koehn

machine translation

23 july 2016

what works best?

112

    wmt evaluation campaign

    winner english   german (with of   cial ties)

x

system 2008
rule
phrase
syntax
neural

2009

2010

2011

2012

2013

2014

2015

2016

x

x
x

x
x

x
x

x

x
x

x
x

x

    for other language pairs, phrase-based systems dominated longer

philipp koehn

machine translation

23 july 2016

software

113

    moses id151 toolkit

    developed since 2006
    reference implementation of state-of-the art methods
    used in academia as benchmark and testbed
    extensive commercial deployment
    http://www.statmt.org/moses/

    dl4mt (or nematus) neural translation toolkit

    developed since 2016
    state-of-the-art performance in 2016
    https://github.com/rsennrich/nematus

philipp koehn

machine translation

23 july 2016

textbook

114

new chapter on id4:

http://mt-class.org/jhu/assets/papers/neural-network-models.pdf

philipp koehn

machine translation

23 july 2016

thank you

115

questions?

philipp koehn

machine translation

23 july 2016

