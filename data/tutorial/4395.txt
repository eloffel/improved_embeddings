   #[1]publisher [2]medium [3]alternate

   [4]homepage
   [5]homepage
   [6]sign in[7]get started

   [8]towards data science
     * [9]data science
     * [10]machine learning
     * [11]programming
     * [12]visualization
     * [13]ai
     * [14]data journalism
     * [15]contribute
     __________________________________________________________________

number plate detection with supervisely and tensorflow (part 1)

   [16]go to the profile of supervise.ly
   [17]supervise.ly (button) blockedunblock (button) followfollowing
   aug 11, 2017

   deep learning is widely used nowadays. there are a lot of interesting
   applications of neural networks in id161 tasks. this tutorial
   will introduce you to how you can easily build number plate detection
   system with [18]supervisely and [19]tensorflow.

   if you haven   t heard about supervisely, you can read more in our
   [20]introduction post.

   this step-by-step guide consists of two parts:
     * part 1: training neural network on artificially generated data.
     * part 2: fine-tuning neural network on real data.

   all sources are available at [21]github.
     __________________________________________________________________

what is supervisely?

   every data scientist knows what is [22]tensorflow. few days ago our
   team at [23]deep systems released [24]supervisely to make it easier for
   developers and researchers to work with training datasets.

   there are many open-sourced implementations of state of the art neural
   network architectures. but deep learning models are very    data-hungry   .

         deep learning algorithms have many parameters that need to be
     tuned and therefore need a lot of data in order to come up with
     somewhat generalizable models. so, in that sense, having a lot of
     data is key to coming up with good training sets for those
     approaches.   

     xavier amatriain, vp of engineering at quora.

   and it is not a secret that in most cases data scientist spends most of
   the time on training data preparation:
     * creating private datasets
     * merging their with several public datasets in different formats
     * adding various data augmentations

   and while he does these, there is a high id203 of making a lot of
   mistakes or doing something wrong during data preparation.
   [1*72ayj_x1btniyekmokgnda.png]
   source: [25]http://dilbert.com/strip/2014-05-07

   and
   [1*kao1-m7bepkotd1kvujlpw.jpeg]
   source: [26]https://9gag.com/gag/adobngk

   supervisely solves these problems. it offers the best of simplicity and
   performance         it is the web-based framework that allows to import all
   the most famous public datasets, to create own datasets with integrated
   annotation tool, merge and export datasets to different formats with
   various number of augmentations and much more.

   in this tutorial we will show you how you can use supervisely to solve
   real-world task of number plate detection.
     __________________________________________________________________

preview training data

   almost always it is hard and expensive to create big task-specific
   dataset with real data. and the common practice is to generate
   artificial dataset when it   s possible.

   fortunately, we can do this for our task. for tutorial purposes we
   generated 10k images dataset with number plates on random backgrounds
   with noise, small rotations and at different scales. for simplicity we
   will use grayscale images. this dataset is freely available in
   supervisely   s dataset library.
   [1*r_bkpe_irjzpgypjwulb1a.png]
   [1*ai9dk5w4hiwx0l713g7mqw.png]
   [1*oyxeviguerrkfysfz9hysq.png]
   [1*z6piur5g992tsjirwwutlw.png]
   here are the few examples of artificially generated images with
   number plates.

   to start using this dataset [27]create or [28]sign-in into
   [29]supervise.ly account.

   after registration you will see the following in your account:
   [1*bkxkrokrg4jmungxc4_icg.png]

   to start using    licence plates    dataset, click    import    tab and then
      dataset library    subtab. on this page you can see the list of
   available ready-to-go datasets (the list will be actively enriched).
   [1*jajetnd0j4fl4t5beqabeg.png]

   let   s click    licence plates    dataset. the next step is to type the name
   for created project. let   s call it as    anpr tutorial   :
   [1*lltjsp0ah8v0nhgu-adbkw.png]

   then click    next    button. select all check boxes and click    upload   .
   [1*uqz5bcpi3guhlmtm-deoba.png]

   you will be redirected to tasks list. the task of importing dataset
   from dataset library will be completed in a few seconds.

   now you can click    projects    tab in main menu. you will see the project
      anpr tutorial    (left screenshot) with single dataset    artificial   
   inside it (right screenshot):
   [1*tr4ceqpt2pzhqek5rowqqg.png]
   [1*afegnsgixygqwk6s4bw6jq.png]

   click on dataset to open annotation tool. the gif below shows some
   functionality of annotator tool. in this tutorial we will use it only
   to preview images.
   [1*hpzms9qje5ynmqyiozylia.gif]

   so. now we have account and project with one dataset. there is only one
   step left before we move on to model training. we should export this
   dataset.
     __________________________________________________________________

export training data

   let me say a few words about datasets export capabilities before we
   start. when we design neural network we think about it in terms of
   computational graph. this is the core abstraction behind popular deep
   learning frameworks. computational graph consists of math operations
   and variables.

   we developed the powerful dataset export tool that opens up the
   possibility to configure export with computational graphs. we can
   define the sequence of operations that will be applied to each image
   from selected datasets.

   just click    export    tab in main menu and paste json configuration
   (presented below) to the text box.
[
  {
    "dst": "$sample01",
    "src": [
      "anpr tutorial/artificial"
    ],
    "action": "data",
    "settings": {
      "classes_mapping": {
        "licence plate": "plate"
      }
    }
  },
  {
    "dst": "$sample_bb",
    "src": [
      "$sample01"
    ],
    "action": "bbox",
    "settings": {
      "classes_mapping": {
        "plate": "plate_bbox"
      }
    }
  },
  {
    "dst": [
      "$sample_train",
      "$sample_test"
    ],
    "src": [
      "$sample_bb"
    ],
    "action": "if",
    "settings": {
      "condition": {
        "id203": 0.98
      }
    }
  },
  {
    "dst": "$train_tagged",
    "src": [
      "$sample_train"
    ],
    "action": "tag",
    "settings": {
      "tag": "train",
      "action": "add"
    }
  },
  {
    "dst": "$test_tagged",
    "src": [
      "$sample_test"
    ],
    "action": "tag",
    "settings": {
      "tag": "test",
      "action": "add"
    }
  },
  {
    "dst": "artificial_samples",
    "src": [
      "$train_tagged",
      "$test_tagged"
    ],
    "action": "save",
    "settings": {
      "images": true,
      "annotations": true
    }
  }
]

   and the system will automatically generate such diagram on the right
   side:
   [1*gw0z_nh40ykr_bpzjviczw.jpeg]

   let   s take a look at our example. blue boxes are data variables, purple
   boxes are operations. detailed explanation of all available export
   layers you can find [30]here.

   in this example we take images from dataset    artificial    from project
      anpr tutorial   . all annotations for this dataset are polygons so i
   would like to convert them to bounding boxes. in this case it is not so
   important, but in other tutorials it will be very useful when, for
   example, we export bounding boxes around cars and pedestrians from
   cityscapes dataset (all annotations are presented as polygons).

   then we split dataset to train and test. each image falls into the
   training set with id203 of 98%. after that all train images will
   be saved with tags    test   , all test images         with tag    test   .

   well, let   s click    start exporting    button. you will be redirected to
   the page with exports tasks. wait a few seconds until the task
      artificial_samples    is completed.
   [1*qyqm6mt9_atomthmadhssq.jpeg]

   and now you can click    three dots    button or    download    icon and
   download the resulting archive with train/test images and annotations.

   the structure of this archive is the following:
   [1*efiqtjumubokybozxz2byq.jpeg]

   let   s see what it is. whole archive is the project ,    anpr
   tutorial__artificial    is the dataset.    img    directory contains images,
   and    ann    directory contains annotations for each image in json format.
     __________________________________________________________________

training the model

   requirements: computer with gpu and docker installed.

   first of all we should clone tutorial repository by typing the
   following command:
git clone [31]https://github.com/deepsystems/supervisely-tutorials.git && cd sup
ervisely-tutorials/anpr

   after that extract downloaded dataset to    data    directory . you should
   get the following    data    directory structure:
   [1*j_qfjzn25_w5jntn_cuxdw.jpeg]

   now let   s move on to the    docker    directory. it contains dockerfile and
   two scripts for building image and running container. run this commands
   inside    anpr/docker    directory:
./build.sh
./run.sh
# now you are inside the container.
jupyter notebook

   the output of    jupyter notebook    command will be the following:
   [1*-v1bzdnbbfh1xj_wstrobq.png]

   just copy last link and paste it to browser. token in your link will be
   different from mine. in you browser you will see:
   [1*1pogu4ki8ye_dq0ta-uxyw.png]

   let   s open    experiment1.ipynb   . click    cell->run all   . this example
   will:
     * load all train and test data
     * visualize some random images with annotations
     * train neural network and save it to    data/model_artif   
     * load model and test in on random test images
     * load model and test in on random train images

   output of cell [12] will be the following. it simply visualize some
   random images with their annotations from train set.
   [1*dhkyijiwmwflvdxnnri8fw.png]

   then model trains 20 epochs. output should be like:
epoch: 0, score: 632.081665, epoch per minute: 0.000000
epoch: 1, score: 0.031625, epoch per minute: 7.076456
epoch: 2, score: 0.020695, epoch per minute: 7.555644
epoch: 3, score: 0.015778, epoch per minute: 7.724735
epoch: 4, score: 0.011812, epoch per minute: 7.804142
epoch: 5, score: 0.007921, epoch per minute: 7.864671
epoch: 6, score: 0.005887, epoch per minute: 7.877275
epoch: 7, score: 0.003385, epoch per minute: 7.888540
epoch: 8, score: 0.002968, epoch per minute: 7.895694
epoch: 9, score: 0.002555, epoch per minute: 7.902217
epoch: 10, score: 0.002133, epoch per minute: 7.925616
epoch: 11, score: 0.001715, epoch per minute: 7.935624
epoch: 12, score: 0.001581, epoch per minute: 7.936112
epoch: 13, score: 0.001396, epoch per minute: 7.969603
epoch: 14, score: 0.001210, epoch per minute: 7.999257
epoch: 15, score: 0.001140, epoch per minute: 8.019996
epoch: 16, score: 0.001603, epoch per minute: 8.059043
epoch: 17, score: 0.001414, epoch per minute: 8.080978
epoch: 18, score: 0.001150, epoch per minute: 8.102449
epoch: 19, score: 0.001129, epoch per minute: 8.097572
epoch: 20, score: 0.001273, epoch per minute: 8.128981
epoch: 21, score: 0.001324, epoch per minute: 8.141784
epoch: 22, score: 0.000929, epoch per minute: 8.133494
epoch: 23, score: 0.001333, epoch per minute: 8.143423
epoch: 24, score: 0.000930, epoch per minute: 8.146000
epoch: 25, score: 0.000900, epoch per minute: 8.138766
epoch: 26, score: 0.000948, epoch per minute: 8.148882
epoch: 27, score: 0.000853, epoch per minute: 8.138941
epoch: 28, score: 0.001174, epoch per minute: 8.148271
epoch: 29, score: 0.000871, epoch per minute: 8.154097
epoch: 30, score: 0.000740, epoch per minute: 8.143948
finished in 221.023122 seconds.

   after that saved model is loaded and predicts bounding boxes for random
   test images. here we can see that the model does it quite well.
   [1*v8hu00_hvitrrpenb0rjva.png]

   let   s take a look at model predictions on random train images. the
   model perfectly predicts bounding boxes for train images.
   [1*aky5rene5n1zzin2w7ir-w.png]

   i hope that everything worked without problems for you. if not, feel
   free to ask questions in comments.

   now, let   s take a look at some script parts in detail. i would like to
   briefly discuss two key moments:
     * how i work with training data from supervisely
     * neural network architecture

   in next tutorials it will be useful to understand annotation format.
   for each image we have json file. here is an example:
{
    "name": "00009975_h314co08",
    "tags": [ ],
    "objects": [
        {
            "classtitle": "plate",
            "description": "",
            "tags": [
                "h314co08"
            ],
            "bitmap": null,
            "points": {
                "interior": [ ],
                "exterior": [
                    [
                        32,
                        24
                    ],
                    [
                        32,
                        40
                    ],
                    [
                        95,
                        40
                    ],
                    [
                        95,
                        24
                    ]
                ]
            }
        }
    ],
    "size": {
        "width": 128,
        "height": 64
    }
}

   this json file contains only one json object. now i will give you
   explanation of some fields :
     *    name   : corresponding image name
     *    tags   : image tags (array of strings).
     *    size   : object with    width    and    height    of image in pixels.
     *    objects   : array of annotations for a given image.

   fields for annotation objects:
     *    classtitle   : object class name. it this tutorial we have only one
       class, it is    plate   . but in our [32]other tutorials you will work
       with multiple classes.
     *    tags   : array of string tags for a given object. here we can see
       that i store ground truth number plate text to have an opportunity
       to do ocr in the future.
     *    points   : object with two fields. supervisely stores objects in
       specific format.    exterior    field is an outer contour of the
       object.    interior    field is an array of holes contours.

   it is a good time to discuss neural network architecture. this net is
   quite small, but it can easily detect number plates for our task with a
   good quality. also this model is very fast and can be used on embedded
   devices.

   here is the diagram with network computational graph:
   [1*jbx4fc16imupaeqdhufnrw.png]

   model is pretty simple: it is the sequence of basic convolution, relu
   and pooling operations and at the end there is a few fully connected
   layers. model predicts the coordinates of number plate bounding box.
     __________________________________________________________________

conclusion

   in this part of tutorial we have shown you how easily one can build a
   number plate detection system with supervisely and tensorflow. we use
   artificially generated data to train simple but effective neural
   network.

   in the next part of this tutorial we will fine-tune our model on real
   data. such two stage training is the common practice among deep
   learning researchers.

   detailed explanation of how to use supervisely for training data
   preparation will help us with data processing in future tutorials and
   everyday work.

   feel free to ask any questions in comments and subscribe to our blog.
   we will regularly add new tutorials and explanation of state of the art
   neural network architectures.

   thank you!

     * [33]machine learning
     * [34]deep learning
     * [35]artificial intelligence
     * [36]data science
     * [37]tensorflow

   (button)
   (button)
   (button) 801 claps
   (button) (button) (button) 11 (button) (button)

     (button) blockedunblock (button) followfollowing
   [38]go to the profile of supervise.ly

[39]supervise.ly

   first available ide for id161: supervise.ly (made in
   deepsystems.ai)

     (button) follow
   [40]towards data science

[41]towards data science

   sharing concepts, ideas, and codes.

     * (button)
       (button) 801
     * (button)
     *
     *

   [42]towards data science
   never miss a story from towards data science, when you sign up for
   medium. [43]learn more
   never miss a story from towards data science
   (button) get updatesget updates

references

   visible links
   1. https://plus.google.com/103654360130207659246
   2. https://towardsdatascience.com/osd.xml
   3. android-app://com.medium.reader/https/medium.com/p/e84c74d4382c
   4. https://medium.com/
   5. https://medium.com/
   6. https://medium.com/m/signin?redirect=https://towardsdatascience.com/number-plate-detection-with-supervisely-and-tensorflow-part-1-e84c74d4382c&source=--------------------------nav_reg&operation=login
   7. https://medium.com/m/signin?redirect=https://towardsdatascience.com/number-plate-detection-with-supervisely-and-tensorflow-part-1-e84c74d4382c&source=--------------------------nav_reg&operation=register
   8. https://towardsdatascience.com/?source=logo-lo_ivxrncunktvp---7f60cf5620c9
   9. https://towardsdatascience.com/data-science/home
  10. https://towardsdatascience.com/machine-learning/home
  11. https://towardsdatascience.com/programming/home
  12. https://towardsdatascience.com/data-visualization/home
  13. https://towardsdatascience.com/artificial-intelligence/home
  14. https://towardsdatascience.com/data-journalism/home
  15. https://towardsdatascience.com/contribute/home
  16. https://towardsdatascience.com/@deepsystems?source=post_header_lockup
  17. https://towardsdatascience.com/@deepsystems
  18. https://supervise.ly/
  19. https://www.tensorflow.org/
  20. https://medium.com/p/57b00f863040
  21. https://github.com/deepsystems/supervisely-tutorials
  22. https://www.tensorflow.org/
  23. https://deepsystems.ai/en/
  24. https://supervise.ly/
  25. http://dilbert.com/strip/2014-05-07
  26. https://9gag.com/gag/adobngk
  27. https://app.supervise.ly/signup
  28. https://app.supervise.ly/login
  29. https://supervise.ly/
  30. https://docs.supervise.ly/en/export/
  31. https://github.com/deepsystems/supervisely-tutorials.git
  32. https://github.com/deepsystems/supervisely-tutorials
  33. https://towardsdatascience.com/tagged/machine-learning?source=post
  34. https://towardsdatascience.com/tagged/deep-learning?source=post
  35. https://towardsdatascience.com/tagged/artificial-intelligence?source=post
  36. https://towardsdatascience.com/tagged/data-science?source=post
  37. https://towardsdatascience.com/tagged/tensorflow?source=post
  38. https://towardsdatascience.com/@deepsystems?source=footer_card
  39. https://towardsdatascience.com/@deepsystems
  40. https://towardsdatascience.com/?source=footer_card
  41. https://towardsdatascience.com/?source=footer_card
  42. https://towardsdatascience.com/
  43. https://medium.com/@medium/personalize-your-medium-experience-with-users-publications-tags-26a41ab1ee0c#.hx4zuv3mg

   hidden links:
  45. https://medium.com/p/e84c74d4382c/share/twitter
  46. https://medium.com/p/e84c74d4382c/share/facebook
  47. https://medium.com/p/e84c74d4382c/share/twitter
  48. https://medium.com/p/e84c74d4382c/share/facebook
