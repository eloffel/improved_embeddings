   #[1]publisher [2]medium [3]alternate

   [4]homepage
   [5]homepage
   [6]sign in[7]get started

   [8]hacker noon
     * [9]latest
     * [10]editors' choice
     * [11]terms faq
     * [12]sign up for 2.0
     * [13]future of search
     __________________________________________________________________

the unreasonable ineffectiveness of deep learning in nlu

on real world data, deep learning performance can be shallow

   [14]go to the profile of suman deb roy
   [15]suman deb roy (button) blockedunblock (button) followfollowing
   jun 13, 2017

   i often get pitched with a superior deep learning solution for natural
   language understanding (nlu). the plan appears prudent. after all,
   [16]deep learning is the disruptive new force in ai. a better nlu ai
   entices many useful advancements, ranging from [17]smarter id70
   and [18]virtual assistants to [19]news categorization, with an ultimate
   promise of better language comprehension.

state of the practice

   lets assume this superior deep learning (dl) "product    is called
   "(dot)ai   . their pitch deck will invariably have a bar chart that looks
   something like this         the claim being that the new dl topic
   classifier/tagger of (dot)ai is better than state of the art methods.
   [1*unp1qdkupssusa2-530zeg.png]
   in many industries, it is expected that production grade ml classifiers
   have more than 90% accuracy for quality assurance and a decent user
   experience. this is expected tolerance level for news categorization or
   conversational bots

   the chart presents an interesting proposition, even though performance
   is only slightly superior than state of the art. in any product, what
   constitutes    good enough    depends on tolerance for error specific to
   that industry. for example, a model   s best accuracy score might be
   reasonable for video recommenders or image transcription, but is
   outside the tolerance limits for news categorization.

     you don   t have to be a sceptic to ask the question: in the realm of
     natural language text classification, do dl techniques significantly
     outperform shallow methods, e.g [20]tf-idf or bag of words (bow)
     based approaches?

   the assumption often is a confident yes         that dl obliterates shallow
   methods in nlu. but does it? three recent trends underpin this
   illusion:
    1. in industry ai conferences, deep learning talks overwhelming relate
       to image/audio/video data, with almost zero talks on production
       level natural language tasks. why?
    2. the media and others continuously hype deep learning as a silver
       bullet, without perusing the actual results in papers. this can
       lead to confusion for practitioners trying to evaluate dl   s utility
       in their domain.
    3. a lot of results just squeeze a few percent of performance on some
       artificial benchmark, whereas robustness and applicability matter
       more.

   while dl has taken the computing world by storm, its impact on certain
   fundamental nlu tasks remains uncertain and performance is not always
   superior. to understand why, let me first describe the nlu task and
   then the state of the art models trying to solve it and how dl
   underperforms.

a fundamental nlu task

   a critical task in natural language understanding is to comprehend the
   topic of a sentence. the topic could be a tag (such as
   politics ,music,gaming , immigration or adventure-sports), but usually
   it isn   t merely [21]a named entity based task such as a person   s name
   or extracting location.
   [1*jr2vtmujbqw_njtzrldyga.png]
   a topic tagger will attempt to tag the first wftv article to    sports   ,
   while the second wftv article to    animals    although both mentions
   `tiger`. this can get complicated quickly due to things like [22]word
   sense disambiguation, as is shown in the [23]example on the right.

   this type of software is called topic taggers. their utility cannot be
   overstated. topics are key in extracting intent and formulating
   automated responses. consider id70         the most common problem bot
   companies face is the lack of any automated way to capture what their
   users are messaging about. the only way to estimate user intent from
   bot messages is either via human eye-balling or whatever matches
   pre-built regex scripts. both methods are suboptimal and cannot cover
   larger topics space.

   in fact, topic tagging at various semantic resolutions is a gateway
   solution approach to nlu for two reasons: (1) text classification into
   topics is a precursor to most higher level nlu tasks such as sentiment
   detection, discourse analysis, episodic memory, and even question
   answering ([24]the quintessential nlu task) (2) also, nlp pipelines are
   considerably prone to error propagation, i.e. an error in topic
   classification can jeopardize future analysis, such as [25]episodic
   memory modeling or discourse or even id31. thus, finding
   the right topic is crucial for nlu.

   iframe: [26]/media/af4ba876d1b63bf3341381d31c263372?postid=e4b4ce3a0da0

   what good is sentiment of a piece of news unless we know what exactly
   this sentiment is about? incorrect topic tagging can adversely affect
   sentiment utility.

   comprehending the topic is a first step in taking meaningful action. in
   reality, topic classification is a hard problem , which has been at
   times underestimated and overlooked by the ai community.

state of the art

   over the years, several technologies have tried to tackle the topic
   classification problem. there was [27]lsa, [28]lda and others like
   [29]plsi, [30]explicit semantic analysis etc. half of these are either
   not production grade or don   t scale well with messy real-world data.
   the other half has poor interpretability or needs considerable
   post-processing of whatever it outputs.

   new world models: today, two main solutions appear overwhelmingly in
   topic classification performance comparisons. (1) first is the very
   deep c[31]onvolutional neural net [did98] model from 2016, which
   proposes the use of very deep neural network architecture - a    state of
   the art in id161   . (2) second is the [32]fasttext approach
   (also 2016). its performance is almost as good as did98 but is orders of
   magnitude faster in training and evaluation than did98. some call
   fasttext the [33]tesla of nlp         whatever that means.

   both methods are elegant in their own way. the big difference is that
   fasttext is a shallow network whereas did98 is 29 layers deep neural
   net. fasttext does not fall in the    stereotype    of fancy deep neural
   nets. instead it uses id27s to solve the tag prediction task.
   [1*furmcm1jpmfc1cgvsccesg.gif]
   fasttext extends the basic [34]id27 idea to predict a topic
   label, instead of predicting the middle/missing word (which recall is
   the original [35]id97 task). this visualizes id97 word
   embeddings [[36]link]

   old world models: holding the ground for older/naive models are
   id165/bag of word based models and tfidf, which still find value in
   large-scale implementations.

   benchmark data: a final component in examination of state of the art is
   datasets on which these models are tested. benchmark datasets are key
   for reproducibility and comparative analysis. in topic classification
   tasks, three popular datasets are: [37]ag news, sogou news and yahoo!
   answers. they differ in corpus size and number of topics (classes)
   present in the data.
   [1*_ctx-gtoqgoqdqob8ojg9a.png]
   the three datasets marked in red rectangles are specifically used for
   topic classification. shown with arrow is one instance in the dataset.
   task is to predict the label by analyzing the sample.

deep (learning) impact?

   first, lets look at the results from the did98 dl paper and compare it
   with naive models. the numbers below indicate error rates when running
   a particular configuration of a model on the topic classification
   datasets.
   [1*gssp75ivqazywq_ce0wrda.png]
   this is table 4 from [38][did98] paper. topic classification datasets
   (mentioned above) are marked with rectangles. the corresponding
   comparable error values are marked with red ellipses.

   four main observations here:
    1. in 2 /3 topic classification datasets (ag+sogou), the naive/shallow
       methods perform better than deep learning.
    2. in the 3rd dataset (yah. ans), dl reduces the error by just ~1.63.
    3. the accuracy of the best model on (yah. ans) dataset is still at
       ~73, which is non-trivial and significantly lower than the
       tolerance level for most quality production systems.

     an important thing to note: all 3 datasets have a topic space less
     than 11, which is still somewhat synthetic. in real world natural
     language data (news streams or conversational messaging), topic
     spaces could easily exceed 20 or 25 different topics (or intents).
     this is key, because the next point hints topic space cardinality
     can have huge impact on accuracy.

   4. accuracy degradation: notice when the topic space grows from 4 to 10
   (ag vs. yah.ans), the error skyrockets to 28.26 from 7.64 with the same
   model. while its possible this is caused by spurious factors, such as
   imbalanced datasets, there is a good chance that a four-fold increase
   in error is due to complexities involved in [39]generalizing larger
   topic spaces.

   finally, lets look at fasttext performance on these datasets and
   compare it to did98 dl and the naive approaches:
   [1*dcl7u5ssfamvz6j0dnibqq.png]
   this is table 1 from [40]fasttext paper showing accuracy values on the
   three topic classification datasets, comparing fasttext with
   naive methods.

   three further observations with fasttext   s comparative results :

   5. once again, in 2/3 datasets fasttext performs better than deep
   learning model. in yah. ans dataset, fasttext is only inferior by ~1.1.

   6. the did98 deep learning method actually performs worse than naive
   models in the first two datasets (ag and sogou).

   7. and again, in 2/3 datasets, the naive model   s performance is
   comparable or better than fasttext

   in addition to these (stunning) results, recall that non-dl models are
   usually orders of magnitude faster to train and much much more
   interpretable.

why is this unreasonable?

   well, looks like when it comes to topic classifiers         the old world
   models (naive / shallower) aren   t ready to give up their throne just
   yet! this ineffectiveness of deep learning is somewhat unexpected. it
   is counterintuitive, given the new world dl models were produced at a
   company with tons of data, performance should be significantly better.

   however, we observe little difference in accuracy. naive/older models
   are better or comparable to dl models when classifying text into
   topics.
   [1*7xs1rwu4flerernrnvxvxa.png]
   from    [41]what data scientists should know about deep learning   ,
   performance beats older algorithms with sufficient data.

   deep learning might have deep problems in classifying language, but the
   objective here isn   t to disparage it or have anything to do with a
   [42]deep learning conspiracy. i think its impact is clear and
   promising. in id161 and [43]id103 and
   [44]playing games, dnn   s have taken us where we have never been before.

   but the reality is your mileage may vary when using deep learning for a
   basic natural language task like text classification. why this gap in
   performance between image/video/audio vs. language data? perhaps it has
   to do with the patterns of biological signal processing required to
      perceive    the former while the patterns of cultural context required
   to    comprehend    the latter? in any case, there is still much we have to
   learn about the intricacies of learning itself, especially with
   different forms of multimedia.
   [45][1*0hqoaabq7xgpt-oyngiubg.png]
   [46][1*vgw1jka6hgnvwztsfmlnpg.png]
   [47][1*gkbpq1ruui0fvk2um_i4tq.png]

     [48]hacker noon is how hackers start their afternoons. we   re a part
     of the [49]@ami family. we are now [50]accepting submissions and
     happy to [51]discuss advertising & sponsorship opportunities.

     if you enjoyed this story, we recommend reading our [52]latest tech
     stories and [53]trending tech stories. until next time, don   t take
     the realities of the world for granted!

   [1*35tcjopcvq6lbb3i6wegqw.jpeg]

     * [54]machine learning
     * [55]ai
     * [56]nlp
     * [57]deep learning
     * [58]topics

   (button)
   (button)
   (button) 160 claps
   (button) (button) (button) 2 (button) (button)

     (button) blockedunblock (button) followfollowing
   [59]go to the profile of suman deb roy

[60]suman deb roy

   algorithms, startups and media

     (button) follow
   [61]hacker noon

[62]hacker noon

   how hackers start their afternoons.

     * (button)
       (button) 160
     * (button)
     *
     *

   [63]hacker noon
   never miss a story from hacker noon, when you sign up for medium.
   [64]learn more
   never miss a story from hacker noon
   (button) get updatesget updates

references

   visible links
   1. https://plus.google.com/103654360130207659246
   2. https://hackernoon.com/osd.xml
   3. android-app://com.medium.reader/https/medium.com/p/e4b4ce3a0da0
   4. https://medium.com/
   5. https://medium.com/
   6. https://medium.com/m/signin?redirect=https://hackernoon.com/the-unreasonable-ineffectiveness-of-deep-learning-in-nlu-e4b4ce3a0da0&source=--------------------------nav_reg&operation=login
   7. https://medium.com/m/signin?redirect=https://hackernoon.com/the-unreasonable-ineffectiveness-of-deep-learning-in-nlu-e4b4ce3a0da0&source=--------------------------nav_reg&operation=register
   8. https://hackernoon.com/?source=logo-lo_pnjy4lkismib---3a8144eabfe3
   9. https://hackernoon.com/latest-tech-stories/home
  10. https://hackernoon.com/editors-top-tech-stories/home
  11. https://hackernoon.com/your-most-frequently-asked-questions-about-our-terms-of-service-how-to-opt-out-and-more-66abf239a151
  12. https://hackernoon.com/sign-up-for-hacker-noon-2-0-9ff1ea0b60cc
  13. https://community.hackernoon.com/t/what-will-replace-google-search/992/14
  14. https://hackernoon.com/@_roysd?source=post_header_lockup
  15. https://hackernoon.com/@_roysd
  16. https://trends.google.com/trends/explore?date=all&q=deep learning,id107,fuzzy logic
  17. https://chatbotsmagazine.com/what-bots-may-come-a35b2bb9bd58
  18. https://www.recode.net/2015/11/3/11620286/facebooks-virtual-assistant-m-is-super-smart-its-also-probably-a-human
  19. http://fortune.com/2017/04/21/bill-oreilly-auto-parts-stock/
  20. https://en.wikipedia.org/wiki/tf   idf
  21. https://github.com/karpathy/paper-notes/blob/master/wikireading.md
  22. https://en.wikipedia.org/wiki/word-sense_disambiguation
  23. https://www.theatlantic.com/technology/archive/2011/03/does-anne-hathaway-news-drive-berkshire-hathaways-stock/72661/
  24. http://uclmr.github.io/ai4exams/data.html
  25. https://medium.com/@aditinair/episodic-memory-modeling-for-conversational-agents-7c82e25b06b4
  26. https://hackernoon.com/media/af4ba876d1b63bf3341381d31c263372?postid=e4b4ce3a0da0
  27. https://en.wikipedia.org/wiki/latent_semantic_analysis
  28. https://en.wikipedia.org/wiki/latent_dirichlet_allocation
  29. https://en.wikipedia.org/wiki/probabilistic_latent_semantic_analysis
  30. https://en.wikipedia.org/wiki/explicit_semantic_analysis
  31. https://arxiv.org/abs/1606.01781
  32. https://arxiv.org/abs/1607.01759
  33. https://www.inverse.com/article/19878-facebook-fasttext-natural-language-processing-artificial-intelligence
  34. https://en.wikipedia.org/wiki/word_embedding
  35. https://en.wikipedia.org/wiki/id97
  36. http://www.anthonygarvan.com/wordgalaxy/
  37. http://www.di.unipi.it/~gulli/ag_corpus_of_news_articles.html
  38. https://arxiv.org/abs/1606.01781
  39. https://blog.acolyer.org/2017/05/11/understanding-deep-learning-requires-re-thinking-generalization/
  40. https://arxiv.org/abs/1607.01759
  41. https://www.slideshare.net/extractconf/andrew-ng-chief-scientist-at-baidu
  42. http://people.idsia.ch/~juergen/deep-learning-conspiracy.html
  43. https://medium.com/@ageitgey/machine-learning-is-fun-part-6-how-to-do-speech-recognition-with-deep-learning-28293c162f7a
  44. https://deepmind.com/research/publications/playing-atari-deep-reinforcement-learning/
  45. http://bit.ly/hackernoonfb
  46. https://goo.gl/k7xybx
  47. https://goo.gl/4ofytp
  48. http://bit.ly/hackernoon
  49. http://bit.ly/atamiatami
  50. http://bit.ly/hackernoonsubmission
  51. mailto:partners@amipublications.com
  52. http://bit.ly/hackernoonlatestt
  53. https://hackernoon.com/trending
  54. https://hackernoon.com/tagged/machine-learning?source=post
  55. https://hackernoon.com/tagged/ai?source=post
  56. https://hackernoon.com/tagged/nlp?source=post
  57. https://hackernoon.com/tagged/deep-learning?source=post
  58. https://hackernoon.com/tagged/topics?source=post
  59. https://hackernoon.com/@_roysd?source=footer_card
  60. https://hackernoon.com/@_roysd
  61. https://hackernoon.com/?source=footer_card
  62. https://hackernoon.com/?source=footer_card
  63. https://hackernoon.com/
  64. https://medium.com/@medium/personalize-your-medium-experience-with-users-publications-tags-26a41ab1ee0c#.hx4zuv3mg

   hidden links:
  66. https://medium.com/p/e4b4ce3a0da0/share/twitter
  67. https://medium.com/p/e4b4ce3a0da0/share/facebook
  68. https://medium.com/p/e4b4ce3a0da0/share/twitter
  69. https://medium.com/p/e4b4ce3a0da0/share/facebook
