   [1]back

markov chains

explained visually

   [2]tweet

   iframe:
   [3]//www.facebook.com/plugins/like.php?href=http%3a%2f%2fsetosa.io%2fev
   %2fmarkov-chains%2f&width=150&height=24&layout=button_count&action=like
   &show_faces=false&share=true

   by [4]victor powell

   with text by [5]lewis lehe

   markov chains, named after [6]andrey markov, are mathematical systems
   that hop from one "state" (a situation or set of values) to another.
   for example, if you made a markov chain model of a baby's behavior, you
   might include "playing," "eating", "sleeping," and "crying" as states,
   which together with other behaviors could form a 'state space': a list
   of all possible states. in addition, on top of the state space, a
   markov chain tells you the probabilitiy of hopping, or "transitioning,"
   from one state to any other state---e.g., the chance that a baby
   currently playing will fall asleep in the next five minutes without
   crying first.

   a simple, two-state markov chain is shown below.

   speed

   with two states (a and b) in our state space, there are 4 possible
   transitions (not 2, because a state can transition back into itself).
   if we're at 'a' we could transition to 'b' or stay at 'a'. if we're at
   'b' we could transition to 'a' or stay at 'b'. in this two state
   diagram, the id203 of transitioning from any state to any other
   state is 0.5.

   of course, real modelers don't always draw out markov chain diagrams.
   instead they use a "transition matrix" to tally the transition
   probabilities. every state in the state space is included once as a row
   and again as a column, and each cell in the matrix tells you the
   id203 of transitioning from its row's state to its column's
   state. so, in the matrix, the cells do the same job that the arrows do
   in the diagram.

   speed
   a b
   a
   p(a|a): {{ transitionmatrix[0][0] | number:2 }}
   p(b|a): {{ transitionmatrix[0][1] | number:2 }}
   b
   p(a|b): {{ transitionmatrix[1][0] | number:2 }}
   p(b|b): {{ transitionmatrix[1][1] | number:2 }}

   if the state space adds one state, we add one row and one column,
   adding one cell to every existing column and row. this means the number
   of cells grows quadratically as we add states to our markov chain.
   thus, a transition matrix comes in handy pretty quickly, unless you
   want to draw a jungle gym markov chain diagram.

   one use of markov chains is to include real-world phenomena in computer
   simulations. for example, we might want to check how frequently a new
   dam will overflow, which depends on the number of rainy days in a row.
   to build this model, we start out with the following pattern of rainy
   (r) and sunny (s) days:

   one way to simulate this weather would be to just say "half of the days
   are rainy. therefore, every day in our simulation will have a fifty
   percent chance of rain." this rule would generate the following
   sequence in simulation:

   did you notice how the above sequence doesn't look quite like the
   original? the second sequence seems to jump around, while the first one
   (the real data) seems to have a "stickyness". in the real data, if it's
   sunny (s) one day, then the next day is also much more likely to be
   sunny.

   we can minic this "stickyness" with a two-state markov chain. when the
   markov chain is in state "r", it has a 0.9 id203 of staying put
   and a 0.1 chance of leaving for the "s" state. likewise, "s" state has
   0.9 id203 of staying put and a 0.1 chance of transitioning to the
   "r" state.

   speed

   in the hands of metereologists, ecologists, computer scientists,
   financial engineers and other people who need to model big phenomena,
   markov chains can get to be quite large and powerful. for example, the
   algorithm google uses to determine the order of search results, called
   [7]id95, is a type of markov chain.

   iframe: [8]http://setosa.io/markov/playground.html

   above, we've included a markov chain "playground", where you can make
   your own markov chains by messing around with a transition matrix.
   here's a few to work from as an example: [9]ex1, [10]ex2, [11]ex3 or
   generate one [12]randomly. the transition matrix text will turn red if
   the provided matrix isn't a valid transition matrix. the rows of the
   transition matrix must total to 1. there also has to be the same number
   of rows as columns.

   you can also access a fullscreen version at [13]setosa.io/markov

   for more explanations, visit the explained visually [14]project
   homepage.

   or subscribe to our mailing list.

   ____________________
   ____________________
   subscribe

   please enable javascript to view the [15]comments powered by disqus.
   [16]comments powered by disqus

references

   1. http://setosa.io/ev/
   2. https://twitter.com/share
   3. http://www.facebook.com/plugins/like.php?href=http://setosa.io/ev/markov-chains/&width=150&height=24&layout=button_count&action=like&show_faces=false&share=true
   4. http://twitter.com/vicapow
   5. http://twitter.com/lewislehe
   6. https://en.wikipedia.org/wiki/andrey_markov
   7. https://en.wikipedia.org/wiki/id95
   8. http://setosa.io/markov/playground.html
   9. javascript:update_playground('long')
  10. javascript:update_playground('large')
  11. javascript:update_playground('three')
  12. javascript:update_playground('random')
  13. http://setosa.io/markov/index.html
  14. http://setosa.io/ev/
  15. http://disqus.com/?ref_noscript
  16. http://disqus.com/
