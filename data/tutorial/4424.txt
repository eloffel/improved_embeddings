   #[1]ahmet taspinar    feed [2]ahmet taspinar    reactiesfeed [3]ahmet
   taspinar    building convolutional neural networks with tensorflow
   reactiesfeed [4]classification with scikit-learn [5]using convolutional
   neural networks to detect features in satellite images [6]alternate
   [7]alternate

   [8]skip to content

[9]ahmet taspinar

     * [10]home
     * [11]about
     * [12]github
     * [13]contact

   ahmet taspinar

building convolutional neural networks with tensorflow

   posted on [14]augustus 15, 2017 [15]adminposted in [16]convolutional
   neural networks, [17]deep learning, [18]tensorflow

1. introduction

   in the past i have mostly written about    classical    machine learning,
   like [19]naive bayes classification, [20]id28, and the
   [21]id88 algorithm. in the past year i have also worked with deep
   learning techniques, and i would like to share with you how to make and
   train a convolutional neural network from scratch, using tensorflow.
   later on we can use this knowledge as a building block to make
   interesting deep learning applications.

   for this you will need to have tensorflow installed (see
   [22]installation instructions) and you should also have a basic
   understanding of python programming and the theory behind convolutional
   neural networks. after you have installed tensorflow, you can run the
   smaller neural networks without gpu, but for the deeper networks you
   will definitely need some gpu power.
   the internet is full with awesome websites and courses which explain
   how a convolutional neural network works. some of them have good
   visualisations which make it easy to understand [[23]click here for
   more info]. i don   t feel the need to explain the same things again, so
   before you continue, make sure you understand how a convolutional
   neural network works. for example,
     * what is a convolutional layer, and what is the filter of this
       convolutional layer?
     * what is an activation layer (relu layer (most widely used), sigmoid
       activation or tanh)?
     * what is a pooling layer (max pooling / average pooling), dropout?
     * how does stochastic id119 work?


   the contents of this blog-post is as follows:
    1. [24]tensorflow basics:
          + 1.1 constants and variables
          + 1.2 tensorflow graphs and sessions
          + 1.3 placeholders and feed_dicts
    2. [25]neural networks in tensorflow
          + 2.1 introduction
          + 2.2 loading in the data
          + 2.3 creating a (simple) 1-layer neural network:
          + 2.4 the many faces of tensorflow
          + 2.5 creating the lenet5 id98
          + 2.6 how the parameters affect the outputsize of an layer
          + 2.7 adjusting the lenet5 architecture
          + 2.8 impact of learning rate and optimizer
    3. [26]deep neural networks in tensorflow
          + 3.1 alexnet
          + 3.2 vgg net-16
          + 3.3 alexnet performance
    4. [27]final words


1. tensorflow basics:

   here i will give a short introduction to tensorflow for people who have
   never worked with it before. if you want to start building neural
   networks immediatly, or you are already familiar with tensorflow you
   can go ahead and skip to [28]section 2. if you would like to know more
   about tensorflow, you can also have a look at [29]this repository, or
   the notes of [30]lecture 1 and [31]lecture 2 of stanford   s cs20si
   course.

1.1 constants and variables

   the most basic units within tensorflow are constants, variables and
   placeholders.

   the difference between a tf.constant() and a tf.variable() should be
   clear; a constant has a constant value and once you set it, it cannot
   be changed.  the value of a variable can be changed after it has been
   set, but the type and shape of the variable can not be changed.
   python

     #we can create constants and variables of different types._
    #however, the different types do not mix well together.____
    a = tf.constant(2, tf.int16)_______________________________
    b = tf.constant(4, tf.float32)_____________________________
    c = tf.constant(8, tf.float32)_____________________________
   ____________________________________________________________
    d = tf.variable(2, tf.int16)_______________________________
    e = tf.variable(4, tf.float32)_____________________________
    f = tf.variable(8, tf.float32)_____________________________
   ____________________________________________________________
   #we can perform computations on variable of the same type: e
   #but the following can not be done: d + e___________________
   ____________________________________________________________
    #everything in tensorflow is a tensor, these can have diffe
    #0d, 1d, 2d, 3d, 4d, or nd-tensors_________________________
    g = tf.constant(np.zeros(shape=(2,2), dtype=np.float32)) #d
   ____________________________________________________________
    h = tf.zeros([11], tf.int16)_______________________________
    i = tf.ones([2,2], tf.float32)_____________________________
    j = tf.zeros([1000,4,3], tf.float64)_______________________
   ____________________________________________________________
    k = tf.variable(tf.zeros([2,2], tf.float32))_______________
    l = tf.variable(tf.zeros([5,6,5], tf.float32))_____________
   1
   2
   3
   4
   5
   6
   7
   8
   9
   10
   11
   12
   13
   14
   15
   16
   17
   18
   19
   20
   21
   22
   23
    #we can create constants and variables of different types.
   #however, the different types do not mix well together.
   a = tf.constant(2, tf.int16)
   b = tf.constant(4, tf.float32)
   c = tf.constant(8, tf.float32)

   d = tf.variable(2, tf.int16)
   e = tf.variable(4, tf.float32)
   f = tf.variable(8, tf.float32)

   #we can perform computations on variable of the same type: e + f
   #but the following can not be done: d + e

   #everything in tensorflow is a tensor, these can have different
   dimensions:
   #0d, 1d, 2d, 3d, 4d, or nd-tensors
   g = tf.constant(np.zeros(shape=(2,2), dtype=np.float32)) #does work

   h = tf.zeros([11], tf.int16)
   i = tf.ones([2,2], tf.float32)
   j = tf.zeros([1000,4,3], tf.float64)

   k = tf.variable(tf.zeros([2,2], tf.float32))
   l = tf.variable(tf.zeros([5,6,5], tf.float32))


   besides the tf.zeros() and tf.ones(), which create a tensor initialized
   to zero or one ([32]see here), there is also the tf.random_normal()
   function which create a tensor filled with values picked randomly from
   a normal distribution (the default distribution has a mean of 0.0 and
   stddev of 1.0).
   there is also the tf.truncated_normal() function, which creates an
   tensor with values randomly picked from a normal distribution, where
   two times the standard deviation forms the lower and upper limit.

   with this knowledge, we can already create weight matrices and bias
   vectors which can be used in a neural network.
   python

   weights = tf.variable(tf.truncated_normal([256 * 256, 10]))_
   biases = tf.variable(tf.zeros([10]))________________________
   print(weights.get_shape().as_list())________________________
   print(biases.get_shape().as_list())_________________________
   >>>[65536, 10]______________________________________________
   >>>[10]_____________________________________________________
   1
   2
   3
   4
   5
   6
   weights = tf.variable(tf.truncated_normal([256 * 256, 10]))
   biases = tf.variable(tf.zeros([10]))
   print(weights.get_shape().as_list())
   print(biases.get_shape().as_list())
   >>>[65536, 10]
   >>>[10]


1.2. tensorflow graphs and sessions

   in tensorflow, all of the different variables and the operations done
   on these variables are saved in a graph. after you have build a graph
   which contains all of the computational steps necessary for your model,
   you can run this graph within a session. this session then distributes
   all of the computations across the available cpu and gpu resources.
   python

   graph = tf.graph()__________________________________________
   with graph.as_default():____________________________________
       a = tf.variable(8, tf.float32)__________________________
       b = tf.variable(tf.zeros([2,2], tf.float32))____________
       ________________________________________________________
   with tf.session(graph=graph) as session:____________________
       tf.global_variables_initializer().run()_________________
       print(f)________________________________________________
       print(session.run(f))___________________________________
       print(session.run(k))___________________________________
   ____________________________________________________________
   >>> <tf.variable 'variable_2:0' shape=() dtype=int32_ref>___
   >>> 8_______________________________________________________
   >>> [[ 0.  0.]______________________________________________
   >>>  [ 0.  0.]]_____________________________________________
   1
   2
   3
   4
   5
   6
   7
   8
   9
   10
   11
   12
   13
   14
   15
   graph = tf.graph()
   with graph.as_default():
       a = tf.variable(8, tf.float32)
       b = tf.variable(tf.zeros([2,2], tf.float32))

   with tf.session(graph=graph) as session:
       tf.global_variables_initializer().run()
       print(f)
       print(session.run(f))
       print(session.run(k))

   >>> <tf.variable 'variable_2:0' shape=() dtype=int32_ref>
   >>> 8
   >>> [[ 0.  0.]
   >>>  [ 0.  0.]]


1.3 placeholders and feed_dicts

   we have seen the various forms in which we can create constants and
   variables. tensorflow also has placeholders; these do not require an
   initial value and only serve to allocate the necessary amount of
   memory. during a session, these placeholder can be filled in with
   (external) data with a feed_dict.

   below is an example of the usage of a placeholder.
   python

   list_of_points1_ = [[1,2], [3,4], [5,6], [7,8]]_____________
   list_of_points2_ = [[15,16], [13,14], [11,12], [9,10]]______
   list_of_points1 = np.array([np.array(elem).reshape(1,2) for 
   list_of_points2 = np.array([np.array(elem).reshape(1,2) for 
   ____________________________________________________________
   graph = tf.graph()__________________________________________
   with graph.as_default():   _________________________________
       #we should use a tf.placeholder() to create a variable w
       #this can be done by 'feeding' the data into the placeho
       #below we see an example of a method which uses two plac
   ____________________________________________________________
       point1 = tf.placeholder(tf.float32, shape=(1, 2))_______
       point2 = tf.placeholder(tf.float32, shape=(1, 2))_______
       ________________________________________________________
       def calculate_eucledian_distance(point1, point2):_______
           difference = tf.subtract(point1, point2)____________
           power2 = tf.pow(difference, tf.constant(2.0, shape=(
           add = tf.reduce_sum(power2)_________________________
           eucledian_distance = tf.sqrt(add)___________________
           return eucledian_distance___________________________
       ________________________________________________________
       dist = calculate_eucledian_distance(point1, point2)_____
       ________________________________________________________
   with tf.session(graph=graph) as session:____________________
       tf.global_variables_initializer().run()   ______________
       for ii in range(len(list_of_points1)):__________________
           point1_ = list_of_points1[ii]_______________________
           point2_ = list_of_points2[ii]_______________________
           feed_dict = {point1 : point1_, point2 : point2_}____
           distance = session.run([dist], feed_dict=feed_dict)_
           print("the distance between {} and {} -> {}".format(
   ____________________________________________________________
   >>> the distance between [[1 2]] and [[15 16]] -> [19.79899]
   >>> the distance between [[3 4]] and [[13 14]] -> [14.142136
   >>> the distance between [[5 6]] and [[11 12]] -> [8.485281]
   >>> the distance between [[7 8]] and [[ 9 10]] -> [2.8284271
   1
   2
   3
   4
   5
   6
   7
   8
   9
   10
   11
   12
   13
   14
   15
   16
   17
   18
   19
   20
   21
   22
   23
   24
   25
   26
   27
   28
   29
   30
   31
   32
   33
   34
   35
   36
   list_of_points1_ = [[1,2], [3,4], [5,6], [7,8]]
   list_of_points2_ = [[15,16], [13,14], [11,12], [9,10]]
   list_of_points1 = np.array([np.array(elem).reshape(1,2) for elem in
   list_of_points1_])
   list_of_points2 = np.array([np.array(elem).reshape(1,2) for elem in
   list_of_points2_])

   graph = tf.graph()
   with graph.as_default():
       #we should use a tf.placeholder() to create a variable whose value
   you will fill in later (during session.run()).
       #this can be done by 'feeding' the data into the placeholder.
       #below we see an example of a method which uses two placeholder
   arrays of size [2,1] to calculate the eucledian distance

       point1 = tf.placeholder(tf.float32, shape=(1, 2))
       point2 = tf.placeholder(tf.float32, shape=(1, 2))

       def calculate_eucledian_distance(point1, point2):
           difference = tf.subtract(point1, point2)
           power2 = tf.pow(difference, tf.constant(2.0, shape=(1,2)))
           add = tf.reduce_sum(power2)
           eucledian_distance = tf.sqrt(add)
           return eucledian_distance

       dist = calculate_eucledian_distance(point1, point2)

   with tf.session(graph=graph) as session:
       tf.global_variables_initializer().run()
       for ii in range(len(list_of_points1)):
           point1_ = list_of_points1[ii]
           point2_ = list_of_points2[ii]
           feed_dict = {point1 : point1_, point2 : point2_}
           distance = session.run([dist], feed_dict=feed_dict)
           print("the distance between {} and {} -> {}".format(point1_,
   point2_, distance))

   >>> the distance between [[1 2]] and [[15 16]] -> [19.79899]
   >>> the distance between [[3 4]] and [[13 14]] -> [14.142136]
   >>> the distance between [[5 6]] and [[11 12]] -> [8.485281]
   >>> the distance between [[7 8]] and [[ 9 10]] -> [2.8284271]


2. neural networks in tensorflow

2.1 introduction




   the graph containing the neural network (illustrated in the image
   above) should contain the following steps:
    1. the input datasets; the training dataset and labels, the test
       dataset and labels (and the validation dataset and labels).
       the test and validation datasets can be placed inside a
       tf.constant(). and the training dataset is placed in a
       tf.placeholder() so that it can be feeded in batches during the
       training (stochastic id119).
    2. the neural network model with all of its layers. this can be a
       simple fully connected neural network consisting of only 1 layer,
       or a more complicated neural network consisting of 5, 9, 16 etc
       layers.
    3. the weight matrices and bias vectors defined in the proper shape
       and initialized to their initial values. (one weight matrix and
       bias vector per layer.)
    4. the loss value: the model has as output the logit vector (estimated
       training labels) and by comparing the logit with the actual labels,
       we can calculate the loss value (with the softmax with
       cross-id178 function). the loss value is an indication of how
       close the estimated training labels are to the actual training
       labels and will be used to update the weight values.
    5. an optimizer, which will use the calculated loss value to update
       the weights and biases with id26.



2.2 loading in the data

   let   s load the dataset which are going to be used to train and test the
   neural networks. for this we will download the [33]mnist and
   the [34]cifar-10 dataset. the mnist dataset contains 60.000 images of
   handwritten digits, where each image size is 28 x 28 x 1 (grayscale).
   the cifar-10 dataset contains 60.000 colour images (3 channels)     size
   32 x 32 x 3     of 10 different objects (airplane, automobile, bird, cat,
   deer, dog, frog, horse, ship, truck). since there are 10 different
   objects in each dataset, both datasets contain 10 labels.



   first, lets define some methods which are convenient for loading and
   reshaping the data into the necessary format.


   python

   def randomize(dataset, labels):_____________________________
       permutation = np.random.permutation(labels.shape[0])____
       shuffled_dataset = dataset[permutation, :, :]___________
       shuffled_labels = labels[permutation]___________________
       return shuffled_dataset, shuffled_labels________________
   ____________________________________________________________
   def one_hot_encode(np_array):_______________________________
       return (np.arange(10) == np_array[:,none]).astype(np.flo
   ____________________________________________________________
   def reformat_data(dataset, labels, image_width, image_height
       np_dataset_ = np.array([np.array(image_data).reshape(ima
       np_labels_ = one_hot_encode(np.array(labels, dtype=np.fl
       np_dataset, np_labels = randomize(np_dataset_, np_labels
       return np_dataset, np_labels____________________________
   ____________________________________________________________
   def flatten_tf_array(array):________________________________
       shape = array.get_shape().as_list()_____________________
       return tf.reshape(array, [shape[0], shape[1] * shape[2] 
   ____________________________________________________________
   def accuracy(predictions, labels):__________________________
       return (100.0 * np.sum(np.argmax(predictions, 1) == np.a
   1
   2
   3
   4
   5
   6
   7
   8
   9
   10
   11
   12
   13
   14
   15
   16
   17
   18
   19
   20
   21
   def randomize(dataset, labels):
       permutation = np.random.permutation(labels.shape[0])
       shuffled_dataset = dataset[permutation, :, :]
       shuffled_labels = labels[permutation]
       return shuffled_dataset, shuffled_labels

   def one_hot_encode(np_array):
       return (np.arange(10) == np_array[:,none]).astype(np.float32)

   def reformat_data(dataset, labels, image_width, image_height,
   image_depth):
       np_dataset_ = np.array([np.array(image_data).reshape(image_width,
   image_height, image_depth) for image_data in dataset])
       np_labels_ = one_hot_encode(np.array(labels, dtype=np.float32))
       np_dataset, np_labels = randomize(np_dataset_, np_labels_)
       return np_dataset, np_labels

   def flatten_tf_array(array):
       shape = array.get_shape().as_list()
       return tf.reshape(array, [shape[0], shape[1] * shape[2] *
   shape[3]])

   def accuracy(predictions, labels):
       return (100.0 * np.sum(np.argmax(predictions, 1) ==
   np.argmax(labels, 1)) / predictions.shape[0])

   these are methods for one-hot encoding the labels, loading the data in
   a randomized array and a method for flattening an array (since a fully
   connected network needs an flat array as its input):


   after we have defined these necessary function, we can load the mnist
   and  cifar-10 datasets with:
   python

   mnist_folder = './data/mnist/'______________________________
   mnist_image_width = 28______________________________________
   mnist_image_height = 28_____________________________________
   mnist_image_depth = 1_______________________________________
   mnist_num_labels = 10_______________________________________
   ____________________________________________________________
   mndata = mnist(mnist_folder)________________________________
   mnist_train_dataset_, mnist_train_labels_ = mndata.load_trai
   mnist_test_dataset_, mnist_test_labels_ = mndata.load_testin
   ____________________________________________________________
   mnist_train_dataset, mnist_train_labels = reformat_data(mnis
   mnist_test_dataset, mnist_test_labels = reformat_data(mnist_
   ____________________________________________________________
   print("there are {} images, each of size {}".format(len(mnis
   print("meaning each image has the size of 28*28*1 = {}".form
   print("the training set contains the following {} labels: {}
   ____________________________________________________________
   print('training set shape', mnist_train_dataset.shape, mnist
   print('test set shape', mnist_test_dataset.shape, mnist_test
   ____________________________________________________________
   train_dataset_mnist, train_labels_mnist = mnist_train_datase
   test_dataset_mnist, test_labels_mnist = mnist_test_dataset, 
   ____________________________________________________________
   ############################################################
   ____________________________________________________________
   cifar10_folder = './data/cifar10/'__________________________
   train_datasets = ['data_batch_1', 'data_batch_2', 'data_batc
   test_dataset = ['test_batch']_______________________________
   c10_image_height = 32_______________________________________
   c10_image_width = 32________________________________________
   c10_image_depth = 3_________________________________________
   c10_num_labels = 10_________________________________________
   ____________________________________________________________
   with open(cifar10_folder + test_dataset[0], 'rb') as f0:____
       c10_test_dict = pickle.load(f0, encoding='bytes')_______
   ____________________________________________________________
   c10_test_dataset, c10_test_labels = c10_test_dict[b'data'], 
   test_dataset_cifar10, test_labels_cifar10 = reformat_data(c1
   ____________________________________________________________
   c10_train_dataset, c10_train_labels = [], []________________
   for train_dataset in train_datasets:________________________
       with open(cifar10_folder + train_dataset, 'rb') as f0:__
           c10_train_dict = pickle.load(f0, encoding='bytes')__
           c10_train_dataset_, c10_train_labels_ = c10_train_di
    ___________________________________________________________
           c10_train_dataset.append(c10_train_dataset_)________
           c10_train_labels += c10_train_labels________________
   ____________________________________________________________
   c10_train_dataset = np.concatenate(c10_train_dataset, axis=0
   train_dataset_cifar10, train_labels_cifar10 = reformat_data(
   del c10_train_dataset_______________________________________
   del c10_train_labels________________________________________
   ____________________________________________________________
   print("the training set contains the following labels: {}".f
   print('training set shape', train_dataset_cifar10.shape, tra
   print('test set shape', test_dataset_cifar10.shape, test_lab
   1
   2
   3
   4
   5
   6
   7
   8
   9
   10
   11
   12
   13
   14
   15
   16
   17
   18
   19
   20
   21
   22
   23
   24
   25
   26
   27
   28
   29
   30
   31
   32
   33
   34
   35
   36
   37
   38
   39
   40
   41
   42
   43
   44
   45
   46
   47
   48
   49
   50
   51
   52
   53
   54
   55
   56
   mnist_folder = './data/mnist/'
   mnist_image_width = 28
   mnist_image_height = 28
   mnist_image_depth = 1
   mnist_num_labels = 10

   mndata = mnist(mnist_folder)
   mnist_train_dataset_, mnist_train_labels_ = mndata.load_training()
   mnist_test_dataset_, mnist_test_labels_ = mndata.load_testing()

   mnist_train_dataset, mnist_train_labels =
   reformat_data(mnist_train_dataset_, mnist_train_labels_,
   mnist_image_size, mnist_image_size, mnist_image_depth)
   mnist_test_dataset, mnist_test_labels =
   reformat_data(mnist_test_dataset_, mnist_test_labels_,
   mnist_image_size, mnist_image_size, mnist_image_depth)

   print("there are {} images, each of size
   {}".format(len(mnist_train_dataset), len(mnist_train_dataset[0])))
   print("meaning each image has the size of 28*28*1 =
   {}".format(mnist_image_size*mnist_image_size*1))
   print("the training set contains the following {} labels:
   {}".format(len(np.unique(mnist_train_labels_)),
   np.unique(mnist_train_labels_)))

   print('training set shape', mnist_train_dataset.shape,
   mnist_train_labels.shape)
   print('test set shape', mnist_test_dataset.shape,
   mnist_test_labels.shape)

   train_dataset_mnist, train_labels_mnist = mnist_train_dataset,
   mnist_train_labels
   test_dataset_mnist, test_labels_mnist = mnist_test_dataset,
   mnist_test_labels

   #######################################################################
   ###############

   cifar10_folder = './data/cifar10/'
   train_datasets = ['data_batch_1', 'data_batch_2', 'data_batch_3',
   'data_batch_4', 'data_batch_5', ]
   test_dataset = ['test_batch']
   c10_image_height = 32
   c10_image_width = 32
   c10_image_depth = 3
   c10_num_labels = 10

   with open(cifar10_folder + test_dataset[0], 'rb') as f0:
       c10_test_dict = pickle.load(f0, encoding='bytes')

   c10_test_dataset, c10_test_labels = c10_test_dict[b'data'],
   c10_test_dict[b'labels']
   test_dataset_cifar10, test_labels_cifar10 =
   reformat_data(c10_test_dataset, c10_test_labels, c10_image_size,
   c10_image_size, c10_image_depth)

   c10_train_dataset, c10_train_labels = [], []
   for train_dataset in train_datasets:
       with open(cifar10_folder + train_dataset, 'rb') as f0:
           c10_train_dict = pickle.load(f0, encoding='bytes')
           c10_train_dataset_, c10_train_labels_ =
   c10_train_dict[b'data'], c10_train_dict[b'labels']
           c10_train_dataset.append(c10_train_dataset_)
           c10_train_labels += c10_train_labels_

   c10_train_dataset = np.concatenate(c10_train_dataset, axis=0)
   train_dataset_cifar10, train_labels_cifar10 =
   reformat_data(c10_train_dataset, c10_train_labels, c10_image_size,
   c10_image_size, c10_image_depth)
   del c10_train_dataset
   del c10_train_labels

   print("the training set contains the following labels:
   {}".format(np.unique(c10_train_dict[b'labels'])))
   print('training set shape', train_dataset_cifar10.shape,
   train_labels_cifar10.shape)
   print('test set shape', test_dataset_cifar10.shape,
   test_labels_cifar10.shape)


   you can download the mnist dataset from yann lecun   s [35]website.
   after you have downloaded and unzipped the files, you can load the data
   with the [36]python-mnist tool. cifar-10 can be downloaded from
   [37]here.


2.3 creating a (simple) 1-layer neural network

   the most simple form of a neural network is a 1-layer linear fully
   connected neural network (fid98). mathematically it consists of a matrix
   multiplication.
   it is best to start with such a simple nn in tensorflow, and later on
   look at the more complicated neural networks. when we start looking at
   these more complicated neural networks, only the model (step 2) and
   weights (step 3) part of the graph will change and the other steps will
   remain the same.

   we can make such an 1-layer fid98 as follows:
   python

   image_width = mnist_image_width_____________________________
   image_height = mnist_image_height___________________________
   image_depth = mnist_image_depth_____________________________
   num_labels = mnist_num_labels ______________________________
   ____________________________________________________________
   #the dataset________________________________________________
   train_dataset = mnist_train_dataset_________________________
   train_labels = mnist_train_labels __________________________
   test_dataset = mnist_test_dataset___________________________
   test_labels = mnist_test_labels ____________________________
   ____________________________________________________________
   #number of iterations and learning rate_____________________
   num_steps = 10001___________________________________________
   display_step = 1000_________________________________________
   learning_rate = 0.5_________________________________________
   ____________________________________________________________
   graph = tf.graph()__________________________________________
   with graph.as_default():____________________________________
       #1) first we put the input data in a tensorflow friendly
       tf_train_dataset = tf.placeholder(tf.float32, shape=(bat
       tf_train_labels = tf.placeholder(tf.float32, shape = (ba
       tf_test_dataset = tf.constant(test_dataset, tf.float32)_
     __________________________________________________________
       #2) then, the weight matrices and bias vectors are initi
       #as a default, tf.truncated_normal() is used for the wei
       weights = tf.variable(tf.truncated_normal([image_width *
       bias = tf.variable(tf.zeros([num_labels]), tf.float32)__
     __________________________________________________________
       #3) define the model:___________________________________
       #a one layered fccd simply consists of a matrix multipli
       def model(data, weights, bias):_________________________
           return tf.matmul(flatten_tf_array(data), weights) + 
   ____________________________________________________________
       logits = model(tf_train_dataset, weights, bias)_________
   ____________________________________________________________
       #4) calculate the loss, which will be used in the optimi
       loss = tf.reduce_mean(tf.nn.softmax_cross_id178_with_l
   ____________________________________________________________
       #5) choose an optimizer. many are available.____________
       optimizer = tf.train.gradientdescentoptimizer(learning_r
   ____________________________________________________________
       #6) the predicted values for the images in the train dat
       #it is only necessary if you want to know the accuracy b
       train_prediction = tf.nn.softmax(logits)________________
       test_prediction = tf.nn.softmax(model(tf_test_dataset, w
   ____________________________________________________________
   ____________________________________________________________
   with tf.session(graph=graph) as session:____________________
       tf.global_variables_initializer().run()_________________
       print('initialized')____________________________________
       for step in range(num_steps):___________________________
           _, l, predictions = session.run([optimizer, loss, tr
           if (step % display_step == 0):______________________
               train_accuracy = accuracy(predictions, train_lab
               test_accuracy = accuracy(test_prediction.eval(),
               message = "step {:04d} : loss is {:06.2f}, accur
               print(message)__________________________________
   1
   2
   3
   4
   5
   6
   7
   8
   9
   10
   11
   12
   13
   14
   15
   16
   17
   18
   19
   20
   21
   22
   23
   24
   25
   26
   27
   28
   29
   30
   31
   32
   33
   34
   35
   36
   37
   38
   39
   40
   41
   42
   43
   44
   45
   46
   47
   48
   49
   50
   51
   52
   53
   54
   55
   56
   57
   image_width = mnist_image_width
   image_height = mnist_image_height
   image_depth = mnist_image_depth
   num_labels = mnist_num_labels

   #the dataset
   train_dataset = mnist_train_dataset
   train_labels = mnist_train_labels
   test_dataset = mnist_test_dataset
   test_labels = mnist_test_labels

   #number of iterations and learning rate
   num_steps = 10001
   display_step = 1000
   learning_rate = 0.5

   graph = tf.graph()
   with graph.as_default():
       #1) first we put the input data in a tensorflow friendly form.
       tf_train_dataset = tf.placeholder(tf.float32, shape=(batch_size,
   image_width, image_height, image_depth))
       tf_train_labels = tf.placeholder(tf.float32, shape = (batch_size,
   num_labels))
       tf_test_dataset = tf.constant(test_dataset, tf.float32)

       #2) then, the weight matrices and bias vectors are initialized
       #as a default, tf.truncated_normal() is used for the weight matrix
   and tf.zeros() is used for the bias vector.
       weights = tf.variable(tf.truncated_normal([image_width *
   image_height * image_depth, num_labels]), tf.float32)
       bias = tf.variable(tf.zeros([num_labels]), tf.float32)

       #3) define the model:
       #a one layered fccd simply consists of a id127
       def model(data, weights, bias):
           return tf.matmul(flatten_tf_array(data), weights) + bias

       logits = model(tf_train_dataset, weights, bias)

       #4) calculate the loss, which will be used in the optimization of
   the weights
       loss =
   tf.reduce_mean(tf.nn.softmax_cross_id178_with_logits(logits=logits,
   labels=tf_train_labels))

       #5) choose an optimizer. many are available.
       optimizer =
   tf.train.gradientdescentoptimizer(learning_rate).minimize(loss)

       #6) the predicted values for the images in the train dataset and
   test dataset are assigned to the variables train_prediction and
   test_prediction.
       #it is only necessary if you want to know the accuracy by comparing
   it with the actual values.
       train_prediction = tf.nn.softmax(logits)
       test_prediction = tf.nn.softmax(model(tf_test_dataset, weights,
   bias))


   with tf.session(graph=graph) as session:
       tf.global_variables_initializer().run()
       print('initialized')
       for step in range(num_steps):
           _, l, predictions = session.run([optimizer, loss,
   train_prediction])
           if (step % display_step == 0):
               train_accuracy = accuracy(predictions, train_labels[:, :])
               test_accuracy = accuracy(test_prediction.eval(),
   test_labels)
               message = "step {:04d} : loss is {:06.2f}, accuracy on
   training set {:02.2f} %, accuracy on test set {:02.2f} %".format(step,
   l, train_accuracy, test_accuracy)
               print(message)


   >>> initialized_____________________________________________
   >>> step 0000 : loss is 2349.55, accuracy on training set 10
   >>> step 0100 : loss is 3612.48, accuracy on training set 89
   >>> step 0200 : loss is 2634.40, accuracy on training set 91
   >>> step 0300 : loss is 2109.42, accuracy on training set 91
   >>> step 0400 : loss is 2093.56, accuracy on training set 91
   >>> step 0500 : loss is 2325.58, accuracy on training set 91
   >>> step 0600 : loss is 22140.44, accuracy on training set 6
   >>> step 0700 : loss is 5920.29, accuracy on training set 83
   >>> step 0800 : loss is 9137.66, accuracy on training set 79
   >>> step 0900 : loss is 15949.15, accuracy on training set 6
   >>> step 1000 : loss is 1758.80, accuracy on training set 92
   1
   2
   3
   4
   5
   6
   7
   8
   9
   10
   11
   12
   >>> initialized
   >>> step 0000 : loss is 2349.55, accuracy on training set 10.43 %,
   accuracy on test set 34.12 %
   >>> step 0100 : loss is 3612.48, accuracy on training set 89.26 %,
   accuracy on test set 90.15 %
   >>> step 0200 : loss is 2634.40, accuracy on training set 91.10 %,
   accuracy on test set 91.26 %
   >>> step 0300 : loss is 2109.42, accuracy on training set 91.62 %,
   accuracy on test set 91.56 %
   >>> step 0400 : loss is 2093.56, accuracy on training set 91.85 %,
   accuracy on test set 91.67 %
   >>> step 0500 : loss is 2325.58, accuracy on training set 91.83 %,
   accuracy on test set 91.67 %
   >>> step 0600 : loss is 22140.44, accuracy on training set 68.39 %,
   accuracy on test set 75.06 %
   >>> step 0700 : loss is 5920.29, accuracy on training set 83.73 %,
   accuracy on test set 87.76 %
   >>> step 0800 : loss is 9137.66, accuracy on training set 79.72 %,
   accuracy on test set 83.33 %
   >>> step 0900 : loss is 15949.15, accuracy on training set 69.33 %,
   accuracy on test set 77.05 %
   >>> step 1000 : loss is 1758.80, accuracy on training set 92.45 %,
   accuracy on test set 91.79 %


   this is all there is too it! inside the graph, we load the data, define
   the weight matrices and the model, calculate the loss value from the
   logit vector and pass this to the optimizer which will update the
   weights for    num_steps    number of iterations.

   in the above fully connected nn, we have used the id119
   optimizer for optimizing the weights. however, there are many different
   [38]optimizers available in tensorflow. the most common used optimizers
   are the gradientdescentoptimizer, adamoptimizer and adagradoptimizer,
   so i would suggest to start with these if youre building a id98.
   sebastian ruder has a nice [39]blog post explaining the differences
   between the different optimizers which you can read if you want to know
   more about them.


2.4 the many faces of tensorflow

   tensorflow contains many layers, meaning the same operations can be
   done with different levels of abstraction. to give a simple example,
   the operation
   logits = tf.matmul(tf_train_dataset, weights) + biases,
   can also be achieved with
   logits = tf.nn.xw_plus_b(train_dataset, weights, biases).


   this is the best visible in the [40]layers api, which is an layer with
   a high level of abstraction and makes it very easy to create neural
   network consisting of many different layers. for example, the
   [41]conv_2d() or the [42]fully_connected() functions create
   convolutional and fully connected layers. with these functions, the
   number of layers, filter sizes / depths, type of activation function,
   etc can be specified as a parameter. the weights and bias matrices are
   then automatically created, as well as the additional activation
   functions and dropout id173 layers.

   for example, with the layers api, the following lines:

   import tensorflow as tf_____________________________________
   ____________________________________________________________
   w1 = tf.variable(tf.truncated_normal([filter_size, filter_si
   b1 = tf.variable(tf.zeros([filter_depth]))__________________
   ____________________________________________________________
   layer1_conv = tf.nn.conv2d(data, w1, [1, 1, 1, 1], padding='
   layer1_relu = tf.nn.relu(layer1_conv + b1)__________________
   layer1_pool = tf.nn.max_pool(layer1_pool, [1, 2, 2, 1], [1, 
   1
   2
   3
   4
   5
   6
   7
   8
   import tensorflow as tf

   w1 = tf.variable(tf.truncated_normal([filter_size, filter_size,
   image_depth, filter_depth], stddev=0.1))
   b1 = tf.variable(tf.zeros([filter_depth]))

   layer1_conv = tf.nn.conv2d(data, w1, [1, 1, 1, 1], padding='same')
   layer1_relu = tf.nn.relu(layer1_conv + b1)
   layer1_pool = tf.nn.max_pool(layer1_pool, [1, 2, 2, 1], [1, 2, 2, 1],
   padding='same')

   can be replaced with

   from tflearn.layers.conv import conv_2d, max_pool_2d________
   ____________________________________________________________
   layer1_conv = conv_2d(data, filter_depth, filter_size, activ
   layer1_pool = max_pool_2d(layer1_conv_relu, 2, strides=2)___
   1
   2
   3
   4
   from tflearn.layers.conv import conv_2d, max_pool_2d

   layer1_conv = conv_2d(data, filter_depth, filter_size,
   activation='relu')
   layer1_pool = max_pool_2d(layer1_conv_relu, 2, strides=2)


   as you can see, we don   t need to define the weights, biases or
   [43]id180. especially when youre building a neural
   network with many layers, this keeps the code succint and clean.

   however, if youre just starting out with tensorflow and want to learn
   how to build different kinds of neural networks, it is not ideal, since
   were letting tflearn do all the work.
   therefore we will not use the layers api in this blog-post, but i do
   recommend you to use it once you have a full understanding of how a
   neural network should be build in tensorflow.




2.5 creating the lenet5 id98

   let   s start with building more layered neural network.  for example the
   lenet5 convolutional neural network.

   the lenet5 id98 architecture was thought of by [44]yann lecun as early
   as in 1998 ([45]see paper). it is one of the earliest id98   s (maybe even
   the first?) and was specifically designed to classify handwritten
   digits. although it performs well on the mnist dataset which consist of
   grayscale images of size 28 x 28, the performance drops on other
   datasets with more images, with a larger resolution (larger image size)
   and more classes. for these larger datasets, deeper convnets (like
   alexnet, vggnet or resnet), will perform better.

   but since the lenet5 architecture only consists of 5 layers, it is a
   good starting point for learning how to build id98   s.

   the lenet5 architecture looks as follows:


   as we can see, it consists of 5 layers:
     * layer 1: a convolutional layer, with a sigmoid activation function,
       followed by an average pooling layer.
     * layer 2: a convolutional layer, with a sigmoid activation function,
       followed by an average pooling layer.
     * layer 3: a fully connected network (sigmoid activation)
     * layer 4: a fully connected network (sigmoid activation)
     * layer 5: the output layer


   this means that we need to create 5 weight and bias matrices, and our
   model will consists of 12 lines of code (5 layers + 2 pooling + 4
   id180 + 1 flatten layer).
   since this is quiet some code, it is best to define these in a seperate
   function outside of the graph.


   python

   lenet5_batch_size = 32______________________________________
   lenet5_patch_size = 5_______________________________________
   lenet5_patch_depth_1 = 6____________________________________
   lenet5_patch_depth_2 = 16___________________________________
   lenet5_num_hidden_1 = 120___________________________________
   lenet5_num_hidden_2 = 84____________________________________
   ____________________________________________________________
   def variables_lenet5(patch_size = lenet5_patch_size, patch_d
                        patch_depth2 = lenet5_patch_depth_2, __
                        num_hidden1 = lenet5_num_hidden_1, num_
                        image_depth = 1, num_labels = 10):_____
       ________________________________________________________
       w1 = tf.variable(tf.truncated_normal([patch_size, patch_
       b1 = tf.variable(tf.zeros([patch_depth1]))______________
   ____________________________________________________________
       w2 = tf.variable(tf.truncated_normal([patch_size, patch_
       b2 = tf.variable(tf.constant(1.0, shape=[patch_depth2]))
   ____________________________________________________________
       w3 = tf.variable(tf.truncated_normal([5*5*patch_depth2, 
       b3 = tf.variable(tf.constant(1.0, shape = [num_hidden1])
   ____________________________________________________________
       w4 = tf.variable(tf.truncated_normal([num_hidden1, num_h
       b4 = tf.variable(tf.constant(1.0, shape = [num_hidden2])
       ________________________________________________________
       w5 = tf.variable(tf.truncated_normal([num_hidden2, num_l
       b5 = tf.variable(tf.constant(1.0, shape = [num_labels]))
       variables = {___________________________________________
           'w1': w1, 'w2': w2, 'w3': w3, 'w4': w4, 'w5': w5,___
           'b1': b1, 'b2': b2, 'b3': b3, 'b4': b4, 'b5': b5____
       }_______________________________________________________
       return variables________________________________________
   ____________________________________________________________
   def model_lenet5(data, variables):__________________________
       layer1_conv = tf.nn.conv2d(data, variables['w1'], [1, 1,
       layer1_actv = tf.sigmoid(layer1_conv + variables['b1'])_
       layer1_pool = tf.nn.avg_pool(layer1_actv, [1, 2, 2, 1], 
   ____________________________________________________________
       layer2_conv = tf.nn.conv2d(layer1_pool, variables['w2'],
       layer2_actv = tf.sigmoid(layer2_conv + variables['b2'])_
       layer2_pool = tf.nn.avg_pool(layer2_actv, [1, 2, 2, 1], 
   ____________________________________________________________
       flat_layer = flatten_tf_array(layer2_pool)______________
       layer3_fccd = tf.matmul(flat_layer, variables['w3']) + v
       layer3_actv = tf.nn.sigmoid(layer3_fccd)________________
       ________________________________________________________
       layer4_fccd = tf.matmul(layer3_actv, variables['w4']) + 
       layer4_actv = tf.nn.sigmoid(layer4_fccd)________________
       logits = tf.matmul(layer4_actv, variables['w5']) + varia
       return logits___________________________________________
   1
   2
   3
   4
   5
   6
   7
   8
   9
   10
   11
   12
   13
   14
   15
   16
   17
   18
   19
   20
   21
   22
   23
   24
   25
   26
   27
   28
   29
   30
   31
   32
   33
   34
   35
   36
   37
   38
   39
   40
   41
   42
   43
   44
   45
   46
   47
   48
   49
   lenet5_batch_size = 32
   lenet5_patch_size = 5
   lenet5_patch_depth_1 = 6
   lenet5_patch_depth_2 = 16
   lenet5_num_hidden_1 = 120
   lenet5_num_hidden_2 = 84

   def variables_lenet5(patch_size = lenet5_patch_size, patch_depth1 =
   lenet5_patch_depth_1,
                        patch_depth2 = lenet5_patch_depth_2,
                        num_hidden1 = lenet5_num_hidden_1, num_hidden2 =
   lenet5_num_hidden_2,
                        image_depth = 1, num_labels = 10):

       w1 = tf.variable(tf.truncated_normal([patch_size, patch_size,
   image_depth, patch_depth1], stddev=0.1))
       b1 = tf.variable(tf.zeros([patch_depth1]))

       w2 = tf.variable(tf.truncated_normal([patch_size, patch_size,
   patch_depth1, patch_depth2], stddev=0.1))
       b2 = tf.variable(tf.constant(1.0, shape=[patch_depth2]))

       w3 = tf.variable(tf.truncated_normal([5*5*patch_depth2,
   num_hidden1], stddev=0.1))
       b3 = tf.variable(tf.constant(1.0, shape = [num_hidden1]))

       w4 = tf.variable(tf.truncated_normal([num_hidden1, num_hidden2],
   stddev=0.1))
       b4 = tf.variable(tf.constant(1.0, shape = [num_hidden2]))

       w5 = tf.variable(tf.truncated_normal([num_hidden2, num_labels],
   stddev=0.1))
       b5 = tf.variable(tf.constant(1.0, shape = [num_labels]))
       variables = {
           'w1': w1, 'w2': w2, 'w3': w3, 'w4': w4, 'w5': w5,
           'b1': b1, 'b2': b2, 'b3': b3, 'b4': b4, 'b5': b5
       }
       return variables

   def model_lenet5(data, variables):
       layer1_conv = tf.nn.conv2d(data, variables['w1'], [1, 1, 1, 1],
   padding='same')
       layer1_actv = tf.sigmoid(layer1_conv + variables['b1'])
       layer1_pool = tf.nn.avg_pool(layer1_actv, [1, 2, 2, 1], [1, 2, 2,
   1], padding='same')

       layer2_conv = tf.nn.conv2d(layer1_pool, variables['w2'], [1, 1, 1,
   1], padding='valid')
       layer2_actv = tf.sigmoid(layer2_conv + variables['b2'])
       layer2_pool = tf.nn.avg_pool(layer2_actv, [1, 2, 2, 1], [1, 2, 2,
   1], padding='same')

       flat_layer = flatten_tf_array(layer2_pool)
       layer3_fccd = tf.matmul(flat_layer, variables['w3']) +
   variables['b3']
       layer3_actv = tf.nn.sigmoid(layer3_fccd)

       layer4_fccd = tf.matmul(layer3_actv, variables['w4']) +
   variables['b4']
       layer4_actv = tf.nn.sigmoid(layer4_fccd)
       logits = tf.matmul(layer4_actv, variables['w5']) + variables['b5']
       return logits


   with the variables, and model defined seperately, we can adjust the the
   graph a little bit so that it uses these weights and model instead of
   the previous fully connected nn:


   python

   #parameters determining the model size______________________
   image_size = mnist_image_size_______________________________
   num_labels = mnist_num_labels_______________________________
   ____________________________________________________________
   #the datasets_______________________________________________
   train_dataset = mnist_train_dataset_________________________
   train_labels = mnist_train_labels___________________________
   test_dataset = mnist_test_dataset___________________________
   test_labels = mnist_test_labels_____________________________
   ____________________________________________________________
   #number of iterations and learning rate_____________________
   num_steps = 10001___________________________________________
   display_step = 1000_________________________________________
   learning_rate = 0.001_______________________________________
   ____________________________________________________________
   graph = tf.graph()__________________________________________
   with graph.as_default():____________________________________
       #1) first we put the input data in a tensorflow friendly
       tf_train_dataset = tf.placeholder(tf.float32, shape=(bat
       tf_train_labels = tf.placeholder(tf.float32, shape = (ba
       tf_test_dataset = tf.constant(test_dataset, tf.float32)_
   ____________________________________________________________
       #2) then, the weight matrices and bias vectors are initi
       <strong>variables = variables_lenet5(image_depth = image
   ____________________________________________________________
       #3. the model used to calculate the logits (predicted la
       <strong>model = model_lenet5</strong>___________________
       <strong>logits = model(tf_train_dataset, variables)</str
   ____________________________________________________________
       #4. then we compute the softmax cross id178 between th
       loss = tf.reduce_mean(tf.nn.softmax_cross_id178_with_l
       ________________________________________________________
       #5. the optimizer is used to calculate the gradients of 
       optimizer = tf.train.gradientdescentoptimizer(learning_r
   ____________________________________________________________
       # predictions for the training, validation, and test dat
       train_prediction = tf.nn.softmax(logits)________________
       test_prediction = tf.nn.softmax(model(tf_test_dataset, v
   1
   2
   3
   4
   5
   6
   7
   8
   9
   10
   11
   12
   13
   14
   15
   16
   17
   18
   19
   20
   21
   22
   23
   24
   25
   26
   27
   28
   29
   30
   31
   32
   33
   34
   35
   36
   37
   38
   #parameters determining the model size
   image_size = mnist_image_size
   num_labels = mnist_num_labels

   #the datasets
   train_dataset = mnist_train_dataset
   train_labels = mnist_train_labels
   test_dataset = mnist_test_dataset
   test_labels = mnist_test_labels

   #number of iterations and learning rate
   num_steps = 10001
   display_step = 1000
   learning_rate = 0.001

   graph = tf.graph()
   with graph.as_default():
       #1) first we put the input data in a tensorflow friendly form.
       tf_train_dataset = tf.placeholder(tf.float32, shape=(batch_size,
   image_width, image_height, image_depth))
       tf_train_labels = tf.placeholder(tf.float32, shape = (batch_size,
   num_labels))
       tf_test_dataset = tf.constant(test_dataset, tf.float32)

       #2) then, the weight matrices and bias vectors are initialized
       <strong>variables = variables_lenet5(image_depth = image_depth,
   num_labels = num_labels)</strong>

       #3. the model used to calculate the logits (predicted labels)
       <strong>model = model_lenet5</strong>
       <strong>logits = model(tf_train_dataset, variables)</strong>

       #4. then we compute the softmax cross id178 between the logits
   and the (actual) labels
       loss =
   tf.reduce_mean(tf.nn.softmax_cross_id178_with_logits(logits=logits,
   labels=tf_train_labels))

       #5. the optimizer is used to calculate the gradients of the loss
   function
       optimizer =
   tf.train.gradientdescentoptimizer(learning_rate).minimize(loss)

       # predictions for the training, validation, and test data.
       train_prediction = tf.nn.softmax(logits)
       test_prediction = tf.nn.softmax(model(tf_test_dataset, variables))


   python

   with tf.session(graph=graph) as session:____________________
       tf.global_variables_initializer().run()_________________
       print('initialized with learning_rate', learning_rate)__
       for step in range(num_steps):___________________________
   ____________________________________________________________
           #since we are using stochastic id119, we 
           #and training the convolutional neural network each 
           offset = (step * batch_size) % (train_labels.shape[0
           batch_data = train_dataset[offset:(offset + batch_si
           batch_labels = train_labels[offset:(offset + batch_s
           feed_dict = {tf_train_dataset : batch_data, tf_train
           _, l, predictions = session.run([optimizer, loss, tr
           ____________________________________________________
           if step % display_step == 0:________________________
               train_accuracy = accuracy(predictions, batch_lab
               test_accuracy = accuracy(test_prediction.eval(),
               message = "step {:04d} : loss is {:06.2f}, accur
               print(message)__________________________________
   1
   2
   3
   4
   5
   6
   7
   8
   9
   10
   11
   12
   13
   14
   15
   16
   17
   18
   with tf.session(graph=graph) as session:
       tf.global_variables_initializer().run()
       print('initialized with learning_rate', learning_rate)
       for step in range(num_steps):

           #since we are using stochastic id119, we are
   selecting  small batches from the training dataset,
           #and training the convolutional neural network each time with a
   batch.
           offset = (step * batch_size) % (train_labels.shape[0] -
   batch_size)
           batch_data = train_dataset[offset:(offset + batch_size), :, :,
   :]
           batch_labels = train_labels[offset:(offset + batch_size), :]
           feed_dict = {tf_train_dataset : batch_data, tf_train_labels :
   batch_labels}
           _, l, predictions = session.run([optimizer, loss,
   train_prediction], feed_dict=feed_dict)

           if step % display_step == 0:
               train_accuracy = accuracy(predictions, batch_labels)
               test_accuracy = accuracy(test_prediction.eval(),
   test_labels)
               message = "step {:04d} : loss is {:06.2f}, accuracy on
   training set {:02.2f} %, accuracy on test set {:02.2f} %".format(step,
   l, train_accuracy, test_accuracy)
               print(message)

   python

   >>> initialized with learning_rate 0.1______________________
   >>> step 0000 : loss is 002.49, accuracy on training set 3.1
   >>> step 1000 : loss is 002.29, accuracy on training set 21.
   >>> step 2000 : loss is 000.73, accuracy on training set 75.
   >>> step 3000 : loss is 000.41, accuracy on training set 81.
   >>> step 4000 : loss is 000.26, accuracy on training set 93.
   >>> step 5000 : loss is 000.28, accuracy on training set 87.
   >>> step 6000 : loss is 000.23, accuracy on training set 96.
   >>> step 7000 : loss is 000.18, accuracy on training set 90.
   >>> step 8000 : loss is 000.14, accuracy on training set 96.
   >>> step 9000 : loss is 000.35, accuracy on training set 90.
   >>> step 10000 : loss is 000.12, accuracy on training set 93
   1
   2
   3
   4
   5
   6
   7
   8
   9
   10
   11
   12
   >>> initialized with learning_rate 0.1
   >>> step 0000 : loss is 002.49, accuracy on training set 3.12 %,
   accuracy on test set 10.09 %
   >>> step 1000 : loss is 002.29, accuracy on training set 21.88 %,
   accuracy on test set 9.58 %
   >>> step 2000 : loss is 000.73, accuracy on training set 75.00 %,
   accuracy on test set 78.20 %
   >>> step 3000 : loss is 000.41, accuracy on training set 81.25 %,
   accuracy on test set 86.87 %
   >>> step 4000 : loss is 000.26, accuracy on training set 93.75 %,
   accuracy on test set 90.49 %
   >>> step 5000 : loss is 000.28, accuracy on training set 87.50 %,
   accuracy on test set 92.79 %
   >>> step 6000 : loss is 000.23, accuracy on training set 96.88 %,
   accuracy on test set 93.64 %
   >>> step 7000 : loss is 000.18, accuracy on training set 90.62 %,
   accuracy on test set 95.14 %
   >>> step 8000 : loss is 000.14, accuracy on training set 96.88 %,
   accuracy on test set 95.80 %
   >>> step 9000 : loss is 000.35, accuracy on training set 90.62 %,
   accuracy on test set 96.33 %
   >>> step 10000 : loss is 000.12, accuracy on training set 93.75 %,
   accuracy on test set 96.76 %


   as we can see the lenet5 architecture performs better on the mnist
   dataset than a simple fully connected nn.


2.6 how the parameters affect the outputsize of an layer

   generally it is true that the more layers a neural network has, the
   better it performs. we can add more layers, change id180
   and pooling layers, change the learning rate and see how each step
   affects the performance. since the input of layer i is the output of
   layer i - 1 , we need to know how the output size of layer i -1 is
   affected by its different parameters.

   to understand this, lets have a look at the [46]conv2d() function.

   it has four parameters:
     * the input image, a 4d tensor with dimensions [batch size,
       image_width, image_height, image_depth]
     * an weight matrix, a 4-d tensor with dimensions [filter_size,
       filter_size, image_depth, filter_depth]
     * the number of strides in each dimension.
     * padding (=    same    /    valid   )


   these four parameters determine the size of the output image.

   the first two parameters are the 4-d tensor containing the batch of
   input images and the 4-d tensor containing the weights of the
   convolutional filter.

   the third parameter is the stride of the convolution, i.e. how much the
   convolutional filter should skip positions in each of the four
   dimension. the first of these 4 dimensions indicates the image-number
   in the batch of images and since we dont want to skip over any image,
   this will always be 1. the last dimension indicates the image depth (no
   of color-channels; 1 for grayscale and 3 for rgb) and since we dont
   want to skip over any color-channels, this is also always 1. the second
   and  third dimension indicate the stride in the x and y direction
   (image width and height).  if we want to apply a stride, these are the
   dimensions in which the filter should skip positions. so for a stride
   of 1, we have to set the stride-parameter to [1, 1, 1, 1] and if we
   want a stride of 2, set it to [1, 2, 2, 1]. etc

   the last parameter indicates whether or not tensorflow should zero-pad
   the image in order to make sure the output size does not change size
   for a stride of 1. with padding =    same    the image does get zero-padded
   (and output size does not change), with padding =    valid    it does not.


   below we can see two examples of a convolutional filter (with filter
   size 5 x 5) scanning through an image (of size 28 x 28).
   on the left the padding parameter is set to    same   , the image is
   zero-padded and the last 4 rows / columns are included in the output
   image.
   on the right padding is set to    valid   , the image does not get
   zero-padded and the last 4 rows/columns are not included.
   gif


   as we can see, without zero-padding the last four cells are not
   included, because the convolutional filter has reached the end of the
   (non-zero padded) image. this means that, for an input size of 28 x 28,
   the output size becomes 24 x 24. if padding =    same   ,  the output size
   is 28 x 28.

   this becomes more clear if we write down the positions of the filter on
   the image while it is scanning through the image (for simplicity, only
   the x-direction). with a stride of 1, the x-positions are 0-5, 1-6,
   2-7, etc. if the stride is 2, the x-positions are 0-5, 2-7, 4-9, etc.

   if we do this for an image size of 28 x 28, filter size of 5 x 5 and
   strides 1 to 4, we will get the following table:



   as you can see, for a stride of 1, and zero-padding the output image
   size is 28 x 28. without zero-padding the output image size becomes 24
   x 24. for a filter with a stride of 2, these numbers are 14 x 14 and 12
   x 12, and for a filter with stride 3 it is 10 x 10 and 8 x 8. etc

   for any arbitrary chosen stride s, filter size k, image size w, and
   padding-size p, the output size will be

   o = 1 + (w - k + 2p) / s

   if padding =    same    in tensorflow, the numerator always adds up to 1
   and the output size is only determined by the stride s.


2.7 adjusting the lenet5 architecture

   in the original paper, a sigmoid activation function and average
   pooling were used in the lenet5 architecture. however, nowadays, it is
   much more common to use a relu activation function. so let   s change the
   lenet5 id98 a little bit to see if we can improve its accuracy. we will
   call this the lenet5-like architecture:


   python

   lenet5_like_batch_size = 32_________________________________
   lenet5_like_filter_size = 5_________________________________
   lenet5_like_filter_depth = 16_______________________________
   lenet5_like_num_hidden = 120________________________________
   ____________________________________________________________
   def variables_lenet5_like(filter_size = lenet5_like_filter_s
                             filter_depth = lenet5_like_filter_
                             num_hidden = lenet5_like_num_hidde
                             image_width = 28, image_depth = 1,
    ___________________________________________________________
       w1 = tf.variable(tf.truncated_normal([filter_size, filte
       b1 = tf.variable(tf.zeros([filter_depth]))______________
   ____________________________________________________________
       w2 = tf.variable(tf.truncated_normal([filter_size, filte
       b2 = tf.variable(tf.constant(1.0, shape=[filter_depth]))
    ___________________________________________________________
       w3 = tf.variable(tf.truncated_normal([(image_width // 4)
       b3 = tf.variable(tf.constant(1.0, shape = [num_hidden]))
   ____________________________________________________________
       w4 = tf.variable(tf.truncated_normal([num_hidden, num_hi
       b4 = tf.variable(tf.constant(1.0, shape = [num_hidden]))
    ___________________________________________________________
       w5 = tf.variable(tf.truncated_normal([num_hidden, num_la
       b5 = tf.variable(tf.constant(1.0, shape = [num_labels]))
       variables = {___________________________________________
                     'w1': w1, 'w2': w2, 'w3': w3, 'w4': w4, 'w
                     'b1': b1, 'b2': b2, 'b3': b3, 'b4': b4, 'b
                   }___________________________________________
       return variables________________________________________
   ____________________________________________________________
   def model_lenet5_like(data, variables):_____________________
       layer1_conv = tf.nn.conv2d(data, variables['w1'], [1, 1,
       layer1_actv = tf.nn.relu(layer1_conv + variables['b1'])_
       layer1_pool = tf.nn.avg_pool(layer1_actv, [1, 2, 2, 1], 
   ____________________________________________________________
       layer2_conv = tf.nn.conv2d(layer1_pool, variables['w2'],
       layer2_actv = tf.nn.relu(layer2_conv + variables['b2'])_
       layer2_pool = tf.nn.avg_pool(layer2_actv, [1, 2, 2, 1], 
    ___________________________________________________________
       flat_layer = flatten_tf_array(layer2_pool)______________
       layer3_fccd = tf.matmul(flat_layer, variables['w3']) + v
       layer3_actv = tf.nn.relu(layer3_fccd)___________________
       #layer3_drop = tf.nn.dropout(layer3_actv, 0.5)__________
    ___________________________________________________________
       layer4_fccd = tf.matmul(layer3_actv, variables['w4']) + 
       layer4_actv = tf.nn.relu(layer4_fccd)___________________
      #layer4_drop = tf.nn.dropout(layer4_actv, 0.5)___________
    ___________________________________________________________
       logits = tf.matmul(layer4_actv, variables['w5']) + varia
       return logits___________________________________________
   1
   2
   3
   4
   5
   6
   7
   8
   9
   10
   11
   12
   13
   14
   15
   16
   17
   18
   19
   20
   21
   22
   23
   24
   25
   26
   27
   28
   29
   30
   31
   32
   33
   34
   35
   36
   37
   38
   39
   40
   41
   42
   43
   44
   45
   46
   47
   48
   49
   50
   lenet5_like_batch_size = 32
   lenet5_like_filter_size = 5
   lenet5_like_filter_depth = 16
   lenet5_like_num_hidden = 120

   def variables_lenet5_like(filter_size = lenet5_like_filter_size,
                             filter_depth = lenet5_like_filter_depth,
                             num_hidden = lenet5_like_num_hidden,
                             image_width = 28, image_depth = 1, num_labels
   = 10):
       w1 = tf.variable(tf.truncated_normal([filter_size, filter_size,
   image_depth, filter_depth], stddev=0.1))
       b1 = tf.variable(tf.zeros([filter_depth]))

       w2 = tf.variable(tf.truncated_normal([filter_size, filter_size,
   filter_depth, filter_depth], stddev=0.1))
       b2 = tf.variable(tf.constant(1.0, shape=[filter_depth]))
       w3 = tf.variable(tf.truncated_normal([(image_width //
   4)*(image_width // 4)*filter_depth , num_hidden], stddev=0.1))
       b3 = tf.variable(tf.constant(1.0, shape = [num_hidden]))

       w4 = tf.variable(tf.truncated_normal([num_hidden, num_hidden],
   stddev=0.1))
       b4 = tf.variable(tf.constant(1.0, shape = [num_hidden]))
       w5 = tf.variable(tf.truncated_normal([num_hidden, num_labels],
   stddev=0.1))
       b5 = tf.variable(tf.constant(1.0, shape = [num_labels]))
       variables = {
                     'w1': w1, 'w2': w2, 'w3': w3, 'w4': w4, 'w5': w5,
                     'b1': b1, 'b2': b2, 'b3': b3, 'b4': b4, 'b5': b5
                   }
       return variables

   def model_lenet5_like(data, variables):
       layer1_conv = tf.nn.conv2d(data, variables['w1'], [1, 1, 1, 1],
   padding='same')
       layer1_actv = tf.nn.relu(layer1_conv + variables['b1'])
       layer1_pool = tf.nn.avg_pool(layer1_actv, [1, 2, 2, 1], [1, 2, 2,
   1], padding='same')

       layer2_conv = tf.nn.conv2d(layer1_pool, variables['w2'], [1, 1, 1,
   1], padding='same')
       layer2_actv = tf.nn.relu(layer2_conv + variables['b2'])
       layer2_pool = tf.nn.avg_pool(layer2_actv, [1, 2, 2, 1], [1, 2, 2,
   1], padding='same')
       flat_layer = flatten_tf_array(layer2_pool)
       layer3_fccd = tf.matmul(flat_layer, variables['w3']) +
   variables['b3']
       layer3_actv = tf.nn.relu(layer3_fccd)
       #layer3_drop = tf.nn.dropout(layer3_actv, 0.5)
       layer4_fccd = tf.matmul(layer3_actv, variables['w4']) +
   variables['b4']
       layer4_actv = tf.nn.relu(layer4_fccd)
      #layer4_drop = tf.nn.dropout(layer4_actv, 0.5)
       logits = tf.matmul(layer4_actv, variables['w5']) + variables['b5']
       return logits


   the main differences are that we are using a relu activation function
   instead of a sigmoid activation.

   besides the activation function, we can also change the used optimizers
   to see what the effect is of the different optimizers on accuracy.

2.8 impact of learning rate and optimizer

   lets see how these id98   s perform on the mnist and cifar-10 datasets.



   in the figures above, the accuracy on the test set is given as a
   function of the number of iterations. on the left for the one layer
   fully connected nn, in the middle for the lenet5 nn and on the right
   for the lenet5-like nn.

   as we can see, the lenet5 id98 works pretty good for the mnist dataset.
   which should not be such a big surprise, since it was specially
   designed to classify handwritten digits. the mnist dataset is quiet
   small and does not provide a big challenge, so even a one layer fully
   connected network performs quiet good.

   on the cifar-10 dataset however, the performance for the lenet5 nn
   drops significantly to accuracy values around 40%.

   to increase the accuracy, we can change the optimizer, or fine-tune the
   neural network by applying id173 or learning rate decay.


   as we can see, the adagradoptimizer, adamoptimizer and the
   rmspropoptimizer have a better performance than the
   gradientdescentoptimizer. these are adaptive optimizers which in
   general perform better than the (simple) gradientdescentoptimizer but
   need more computational power.

   with l2-id173 or exponential rate decay we can probably gain a
   bit more accuracy, but for much better results we need to go deeper.


3. deep neural networks in tensorflow

   so far we have seen the lenet5 id98 architecture. lenet5 contains two
   convolutional layers followed by fully connected layers and therefore
   could be called a shallow neural network. at that time (in 1998) gpu   s
   were not used for computational calculations, and the cpu   s were not
   even that powerful so for that time the two convolutional layers were
   already quiet innovative.

   later on, many other types of convolutional neural networks have been
   designed, most of them much deeper [[47]click here for more info].
   there is the famous [48]alexnet architecture (2012) by  alex krizhevsky
   et. al., the 7-layered [49]zf net (2013), and the 16-layered [50]vggnet
   (2014).
   in 2015 google came with 22-layered id98 with an inception module
   ([51]googlenet), and microsoft research asia created the 152-layered
   id98 called [52]resnet.


   now, with the things we have learned so far, lets see how we can create
   the alexnet and vggnet16 architectures in tensorflow.



3.1 alexnet

   although lenet5 was the first convnet, it is considered to be a shallow
   neural network. it performs well on the mnist dataset which consist of
   grayscale images of size 28 x 28, but the performance drops when we   re
   trying to classify larger images, with more resolution and more
   classes.

   the first deep id98 came out in 2012 and is called alexnet after its
   creators alex krizhevsky, ilya sutskever, and geoffrey hinton. compared
   to the most recent architectures alexnet can be considered simple, but
   at that time it was really succesfull. it won the id163 competition
   with a incredible test error rate of 15.4% (while the runner-up had an
   error of 26.2%) and started a [53]revolution ([54]also see this video)
   in the world of deep learning and ai.



   it consists of 5 convolutional layers (with relu activation), 3 max
   pooling layers, 3 fully connected layers and 2 dropout layers. the
   overall architecture looks as follows:
     * layer 0: input image of size 224 x 224 x 3
     * layer 1: a convolutional layer with 96 filters (filter_depth_1 =
       96) of size 11 x 11 (filter_size_1 = 11) and a stride of 4. it has
       a relu activation function.
       this is followed by max pooling and local response id172
       layers.
     * layer 2: a convolutional layer with 256 filters (filter_depth_2 =
       256) of size 5 x 5 (filter_size_2 = 5) and a stride of 1. it has a
       relu activation function.
       this layer is also followed by max pooling and local response
       id172 layers.
     * layer 3: a convolutional layer with 384 filters (filter_depth_3 =
       384) of size 3 x 3 (filter_size_3 = 3) and a stride of 1. it has a
       relu activation function.
     * layer 4: same as layer 3.
     * layer 5: a convolutional layer with 256 filters (filter_depth_4 =
       256) of size 3 x 3 (filter_size_4 = 3) and a stride of 1. it has a
       relu activation function.
     * layer 6-8: these convolutional layers are followed by fully
       connected layers with 4096 neurons each. in the original paper they
       are classifying a dataset with 1000 classes, but we will use the
       oxford17 dataset, which has 17 different classes (of flowers).


   note that this id98 (or other deep id98   s) cannot be used on the mnist or
   the cifar-10 dataset, because the images in these datasets are too
   small. as we have seen before, a pooling layer (or a convolutional
   layer with a stride of 2) reduces the image size by a factor of 2.
   alexnet has 3 max pooling layers and one convolutional layer with a
   stride of 4. this means that the original image size gets reduced by a
   factor of 2^5 . the images in the mnist dataset would simply get
   reduced to a size smaller than 0.


   therefore we need to load a dataset with larger images, preferably 224
   x 224 x 3 (as the original paper indicates). the 17 category flower
   dataset, aka [55]oxflower17 dataset is ideal since it contains images
   of exactly this size:
   python

   ox17_image_width = 224______________________________________
   ox17_image_height = 224_____________________________________
   ox17_image_depth = 3________________________________________
   ox17_num_labels = 17________________________________________
   ____________________________________________________________
   import tflearn.datasets.oxflower17 as oxflower17____________
   train_dataset_, train_labels_ = oxflower17.load_data(one_hot
   train_dataset_ox17, train_labels_ox17 = train_dataset_[:1000
   test_dataset_ox17, test_labels_ox17 = train_dataset_[1000:,:
   ____________________________________________________________
   print('training set', train_dataset_ox17.shape, train_labels
   print('test set', test_dataset_ox17.shape, test_labels_ox17.
   1
   2
   3
   4
   5
   6
   7
   8
   9
   10
   11
   12
   ox17_image_width = 224
   ox17_image_height = 224
   ox17_image_depth = 3
   ox17_num_labels = 17

   import tflearn.datasets.oxflower17 as oxflower17
   train_dataset_, train_labels_ = oxflower17.load_data(one_hot=true)
   train_dataset_ox17, train_labels_ox17 = train_dataset_[:1000,:,:,:],
   train_labels_[:1000,:]
   test_dataset_ox17, test_labels_ox17 = train_dataset_[1000:,:,:,:],
   train_labels_[1000:,:]

   print('training set', train_dataset_ox17.shape,
   train_labels_ox17.shape)
   print('test set', test_dataset_ox17.shape, test_labels_ox17.shape)


   lets try to create the weight matrices and the different layers present
   in alexnet. as we have seen before, we need as much weight matrices and
   bias vectors as the amount of layers, and each weight matrix should
   have a size corresponding to the filter size of the layer it belongs
   to.
   python

   alex_patch_depth_1, alex_patch_depth_2, alex_patch_depth_3, 
   alex_patch_size_1, alex_patch_size_2, alex_patch_size_3, ale
   alex_num_hidden_1, alex_num_hidden_2 = 4096, 4096___________
   ____________________________________________________________
   ____________________________________________________________
   def variables_alexnet(patch_size1 = alex_patch_size_1, patch
                         patch_size3 = alex_patch_size_3, patch
                         patch_depth1 = alex_patch_depth_1, pat
                         patch_depth3 = alex_patch_depth_3, pat
                         num_hidden1 = alex_num_hidden_1, num_h
                         image_width = 224, image_height = 224,
    ___________________________________________________________
       w1 = tf.variable(tf.truncated_normal([patch_size1, patch
       b1 = tf.variable(tf.zeros([patch_depth1]))______________
   ____________________________________________________________
       w2 = tf.variable(tf.truncated_normal([patch_size2, patch
       b2 = tf.variable(tf.constant(1.0, shape=[patch_depth2]))
   ____________________________________________________________
       w3 = tf.variable(tf.truncated_normal([patch_size3, patch
       b3 = tf.variable(tf.zeros([patch_depth3]))______________
   ____________________________________________________________
       w4 = tf.variable(tf.truncated_normal([patch_size4, patch
       b4 = tf.variable(tf.constant(1.0, shape=[patch_depth3]))
    ___________________________________________________________
       w5 = tf.variable(tf.truncated_normal([patch_size4, patch
       b5 = tf.variable(tf.zeros([patch_depth3]))______________
    ___________________________________________________________
       pool_reductions = 3_____________________________________
       conv_reductions = 2_____________________________________
       no_reductions = pool_reductions + conv_reductions_______
       w6 = tf.variable(tf.truncated_normal([(image_width // 2*
       b6 = tf.variable(tf.constant(1.0, shape = [num_hidden1])
   ____________________________________________________________
       w7 = tf.variable(tf.truncated_normal([num_hidden1, num_h
       b7 = tf.variable(tf.constant(1.0, shape = [num_hidden2])
    ___________________________________________________________
       w8 = tf.variable(tf.truncated_normal([num_hidden2, num_l
       b8 = tf.variable(tf.constant(1.0, shape = [num_labels]))
    ___________________________________________________________
       variables = {___________________________________________
                    'w1': w1, 'w2': w2, 'w3': w3, 'w4': w4, 'w5
                    'b1': b1, 'b2': b2, 'b3': b3, 'b4': b4, 'b5
                   }___________________________________________
       return variables________________________________________
   ____________________________________________________________
   ____________________________________________________________
   def model_alexnet(data, variables):_________________________
       layer1_conv = tf.nn.conv2d(data, variables['w1'], [1, 4,
       layer1_relu = tf.nn.relu(layer1_conv + variables['b1'])_
       layer1_pool = tf.nn.max_pool(layer1_relu, [1, 3, 3, 1], 
       layer1_norm = tf.nn.local_response_id172(layer1_
    ___________________________________________________________
       layer2_conv = tf.nn.conv2d(layer1_norm, variables['w2'],
       layer2_relu = tf.nn.relu(layer2_conv + variables['b2'])_
       layer2_pool = tf.nn.max_pool(layer2_relu, [1, 3, 3, 1], 
       layer2_norm = tf.nn.local_response_id172(layer2_
    ___________________________________________________________
       layer3_conv = tf.nn.conv2d(layer2_norm, variables['w3'],
       layer3_relu = tf.nn.relu(layer3_conv + variables['b3'])_
    ___________________________________________________________
       layer4_conv = tf.nn.conv2d(layer3_relu, variables['w4'],
       layer4_relu = tf.nn.relu(layer4_conv + variables['b4'])_
    ___________________________________________________________
       layer5_conv = tf.nn.conv2d(layer4_relu, variables['w5'],
       layer5_relu = tf.nn.relu(layer5_conv + variables['b5'])_
       layer5_pool = tf.nn.max_pool(layer4_relu, [1, 3, 3, 1], 
       layer5_norm = tf.nn.local_response_id172(layer5_
    ___________________________________________________________
       flat_layer = flatten_tf_array(layer5_norm)______________
       layer6_fccd = tf.matmul(flat_layer, variables['w6']) + v
       layer6_tanh = tf.tanh(layer6_fccd)______________________
       layer6_drop = tf.nn.dropout(layer6_tanh, 0.5)___________
    ___________________________________________________________
       layer7_fccd = tf.matmul(layer6_drop, variables['w7']) + 
       layer7_tanh = tf.tanh(layer7_fccd)______________________
       layer7_drop = tf.nn.dropout(layer7_tanh, 0.5)___________
    ___________________________________________________________
       logits = tf.matmul(layer7_drop, variables['w8']) + varia
       return logits___________________________________________
   1
   2
   3
   4
   5
   6
   7
   8
   9
   10
   11
   12
   13
   14
   15
   16
   17
   18
   19
   20
   21
   22
   23
   24
   25
   26
   27
   28
   29
   30
   31
   32
   33
   34
   35
   36
   37
   38
   39
   40
   41
   42
   43
   44
   45
   46
   47
   48
   49
   50
   51
   52
   53
   54
   55
   56
   57
   58
   59
   60
   61
   62
   63
   64
   65
   66
   67
   68
   69
   70
   71
   72
   73
   74
   75
   76
   77
   78
   79
   alex_patch_depth_1, alex_patch_depth_2, alex_patch_depth_3,
   alex_patch_depth_4 = 96, 256, 384, 256
   alex_patch_size_1, alex_patch_size_2, alex_patch_size_3,
   alex_patch_size_4 = 11, 5, 3, 3
   alex_num_hidden_1, alex_num_hidden_2 = 4096, 4096


   def variables_alexnet(patch_size1 = alex_patch_size_1, patch_size2 =
   alex_patch_size_2,
                         patch_size3 = alex_patch_size_3, patch_size4 =
   alex_patch_size_4,
                         patch_depth1 = alex_patch_depth_1, patch_depth2 =
   alex_patch_depth_2,
                         patch_depth3 = alex_patch_depth_3, patch_depth4 =
   alex_patch_depth_4,
                         num_hidden1 = alex_num_hidden_1, num_hidden2 =
   alex_num_hidden_2,
                         image_width = 224, image_height = 224,
   image_depth = 3, num_labels = 17):
       w1 = tf.variable(tf.truncated_normal([patch_size1, patch_size1,
   image_depth, patch_depth1], stddev=0.1))
       b1 = tf.variable(tf.zeros([patch_depth1]))

       w2 = tf.variable(tf.truncated_normal([patch_size2, patch_size2,
   patch_depth1, patch_depth2], stddev=0.1))
       b2 = tf.variable(tf.constant(1.0, shape=[patch_depth2]))

       w3 = tf.variable(tf.truncated_normal([patch_size3, patch_size3,
   patch_depth2, patch_depth3], stddev=0.1))
       b3 = tf.variable(tf.zeros([patch_depth3]))

       w4 = tf.variable(tf.truncated_normal([patch_size4, patch_size4,
   patch_depth3, patch_depth3], stddev=0.1))
       b4 = tf.variable(tf.constant(1.0, shape=[patch_depth3]))
       w5 = tf.variable(tf.truncated_normal([patch_size4, patch_size4,
   patch_depth3, patch_depth3], stddev=0.1))
       b5 = tf.variable(tf.zeros([patch_depth3]))
       pool_reductions = 3
       conv_reductions = 2
       no_reductions = pool_reductions + conv_reductions
       w6 = tf.variable(tf.truncated_normal([(image_width //
   2**no_reductions)*(image_height // 2**no_reductions)*patch_depth3,
   num_hidden1], stddev=0.1))
       b6 = tf.variable(tf.constant(1.0, shape = [num_hidden1]))

       w7 = tf.variable(tf.truncated_normal([num_hidden1, num_hidden2],
   stddev=0.1))
       b7 = tf.variable(tf.constant(1.0, shape = [num_hidden2]))
       w8 = tf.variable(tf.truncated_normal([num_hidden2, num_labels],
   stddev=0.1))
       b8 = tf.variable(tf.constant(1.0, shape = [num_labels]))
       variables = {
                    'w1': w1, 'w2': w2, 'w3': w3, 'w4': w4, 'w5': w5,
   'w6': w6, 'w7': w7, 'w8': w8,
                    'b1': b1, 'b2': b2, 'b3': b3, 'b4': b4, 'b5': b5,
   'b6': b6, 'b7': b7, 'b8': b8
                   }
       return variables


   def model_alexnet(data, variables):
       layer1_conv = tf.nn.conv2d(data, variables['w1'], [1, 4, 4, 1],
   padding='same')
       layer1_relu = tf.nn.relu(layer1_conv + variables['b1'])
       layer1_pool = tf.nn.max_pool(layer1_relu, [1, 3, 3, 1], [1, 2, 2,
   1], padding='same')
       layer1_norm = tf.nn.local_response_id172(layer1_pool)
       layer2_conv = tf.nn.conv2d(layer1_norm, variables['w2'], [1, 1, 1,
   1], padding='same')
       layer2_relu = tf.nn.relu(layer2_conv + variables['b2'])
       layer2_pool = tf.nn.max_pool(layer2_relu, [1, 3, 3, 1], [1, 2, 2,
   1], padding='same')
       layer2_norm = tf.nn.local_response_id172(layer2_pool)
       layer3_conv = tf.nn.conv2d(layer2_norm, variables['w3'], [1, 1, 1,
   1], padding='same')
       layer3_relu = tf.nn.relu(layer3_conv + variables['b3'])
       layer4_conv = tf.nn.conv2d(layer3_relu, variables['w4'], [1, 1, 1,
   1], padding='same')
       layer4_relu = tf.nn.relu(layer4_conv + variables['b4'])
       layer5_conv = tf.nn.conv2d(layer4_relu, variables['w5'], [1, 1, 1,
   1], padding='same')
       layer5_relu = tf.nn.relu(layer5_conv + variables['b5'])
       layer5_pool = tf.nn.max_pool(layer4_relu, [1, 3, 3, 1], [1, 2, 2,
   1], padding='same')
       layer5_norm = tf.nn.local_response_id172(layer5_pool)
       flat_layer = flatten_tf_array(layer5_norm)
       layer6_fccd = tf.matmul(flat_layer, variables['w6']) +
   variables['b6']
       layer6_tanh = tf.tanh(layer6_fccd)
       layer6_drop = tf.nn.dropout(layer6_tanh, 0.5)
       layer7_fccd = tf.matmul(layer6_drop, variables['w7']) +
   variables['b7']
       layer7_tanh = tf.tanh(layer7_fccd)
       layer7_drop = tf.nn.dropout(layer7_tanh, 0.5)
       logits = tf.matmul(layer7_drop, variables['w8']) + variables['b8']
       return logits


   now we can modify the id98 model to use the weights and layers of the
   alexnet model in order to classify images.


3.2 vgg net-16

   vgg net was created in 2014 by karen simonyan and andrew zisserman of
   the university of oxford. it contains much more layers (16-19 layers),
   but each layer is simpler in its design; all of the convolutional
   layers have filters of size 3 x 3 and stride of 1 and all max pooling
   layers have a stride of 2.
   so it is a deeper id98 but simpler.

   it comes in different configurations, with either 16 or 19 layers. the
   difference between these two different configurations is the usage of
   either 3 or 4 convolutional layers after the second, third and fourth
   max pooling layer (see below).

   the configuration with 16 layers (configuration d) seems to produce the
   best results, so lets try to create that in tensorflow.


   python

   #the vggnet neural network _________________________________
   vgg16_patch_size_1, vgg16_patch_size_2, vgg16_patch_size_3, 
   vgg16_patch_depth_1, vgg16_patch_depth_2, vgg16_patch_depth_
   vgg16_num_hidden_1, vgg16_num_hidden_2 = 4096, 1000_________
   ____________________________________________________________
   def variables_vggnet16(patch_size1 = vgg16_patch_size_1, pat
                          patch_size3 = vgg16_patch_size_3, pat
                          patch_depth1 = vgg16_patch_depth_1, p
                          patch_depth3 = vgg16_patch_depth_3, p
                          num_hidden1 = vgg16_num_hidden_1, num
                          image_width = 224, image_height = 224
       ________________________________________________________
       w1 = tf.variable(tf.truncated_normal([patch_size1, patch
       b1 = tf.variable(tf.zeros([patch_depth1]))______________
       w2 = tf.variable(tf.truncated_normal([patch_size1, patch
       b2 = tf.variable(tf.constant(1.0, shape=[patch_depth1]))
   ____________________________________________________________
       w3 = tf.variable(tf.truncated_normal([patch_size2, patch
       b3 = tf.variable(tf.constant(1.0, shape = [patch_depth2]
       w4 = tf.variable(tf.truncated_normal([patch_size2, patch
       b4 = tf.variable(tf.constant(1.0, shape = [patch_depth2]
       ________________________________________________________
       w5 = tf.variable(tf.truncated_normal([patch_size3, patch
       b5 = tf.variable(tf.constant(1.0, shape = [patch_depth3]
       w6 = tf.variable(tf.truncated_normal([patch_size3, patch
       b6 = tf.variable(tf.constant(1.0, shape = [patch_depth3]
       w7 = tf.variable(tf.truncated_normal([patch_size3, patch
       b7 = tf.variable(tf.constant(1.0, shape=[patch_depth3]))
   ____________________________________________________________
       w8 = tf.variable(tf.truncated_normal([patch_size4, patch
       b8 = tf.variable(tf.constant(1.0, shape = [patch_depth4]
       w9 = tf.variable(tf.truncated_normal([patch_size4, patch
       b9 = tf.variable(tf.constant(1.0, shape = [patch_depth4]
       w10 = tf.variable(tf.truncated_normal([patch_size4, patc
       b10 = tf.variable(tf.constant(1.0, shape = [patch_depth4
       ________________________________________________________
       w11 = tf.variable(tf.truncated_normal([patch_size4, patc
       b11 = tf.variable(tf.constant(1.0, shape = [patch_depth4
       w12 = tf.variable(tf.truncated_normal([patch_size4, patc
       b12 = tf.variable(tf.constant(1.0, shape=[patch_depth4])
       w13 = tf.variable(tf.truncated_normal([patch_size4, patc
       b13 = tf.variable(tf.constant(1.0, shape = [patch_depth4
       ________________________________________________________
       no_pooling_layers = 5___________________________________
   ____________________________________________________________
       w14 = tf.variable(tf.truncated_normal([(image_width // (
       b14 = tf.variable(tf.constant(1.0, shape = [num_hidden1]
       ________________________________________________________
       w15 = tf.variable(tf.truncated_normal([num_hidden1, num_
       b15 = tf.variable(tf.constant(1.0, shape = [num_hidden2]
      _________________________________________________________
       w16 = tf.variable(tf.truncated_normal([num_hidden2, num_
       b16 = tf.variable(tf.constant(1.0, shape = [num_labels])
       variables = {___________________________________________
           'w1': w1, 'w2': w2, 'w3': w3, 'w4': w4, 'w5': w5, 'w
           'w11': w11, 'w12': w12, 'w13': w13, 'w14': w14, 'w15
           'b1': b1, 'b2': b2, 'b3': b3, 'b4': b4, 'b5': b5, 'b
           'b11': b11, 'b12': b12, 'b13': b13, 'b14': b14, 'b15
       }_______________________________________________________
       return variables________________________________________
   ____________________________________________________________
   def model_vggnet16(data, variables):________________________
       layer1_conv = tf.nn.conv2d(data, variables['w1'], [1, 1,
       layer1_actv = tf.nn.relu(layer1_conv + variables['b1'])_
       layer2_conv = tf.nn.conv2d(layer1_actv, variables['w2'],
       layer2_actv = tf.nn.relu(layer2_conv + variables['b2'])_
       layer2_pool = tf.nn.max_pool(layer2_actv, [1, 2, 2, 1], 
   ____________________________________________________________
       layer3_conv = tf.nn.conv2d(layer2_pool, variables['w3'],
       layer3_actv = tf.nn.relu(layer3_conv + variables['b3']) 
       layer4_conv = tf.nn.conv2d(layer3_actv, variables['w4'],
       layer4_actv = tf.nn.relu(layer4_conv + variables['b4'])_
       layer4_pool = tf.nn.max_pool(layer4_pool, [1, 2, 2, 1], 
   ____________________________________________________________
       layer5_conv = tf.nn.conv2d(layer4_pool, variables['w5'],
       layer5_actv = tf.nn.relu(layer5_conv + variables['b5'])_
       layer6_conv = tf.nn.conv2d(layer5_actv, variables['w6'],
       layer6_actv = tf.nn.relu(layer6_conv + variables['b6'])_
       layer7_conv = tf.nn.conv2d(layer6_actv, variables['w7'],
       layer7_actv = tf.nn.relu(layer7_conv + variables['b7'])_
       layer7_pool = tf.nn.max_pool(layer7_actv, [1, 2, 2, 1], 
   ____________________________________________________________
       layer8_conv = tf.nn.conv2d(layer7_pool, variables['w8'],
       layer8_actv = tf.nn.relu(layer8_conv + variables['b8'])_
       layer9_conv = tf.nn.conv2d(layer8_actv, variables['w9'],
       layer9_actv = tf.nn.relu(layer9_conv + variables['b9'])_
       layer10_conv = tf.nn.conv2d(layer9_actv, variables['w10'
       layer10_actv = tf.nn.relu(layer10_conv + variables['b10'
       layer10_pool = tf.nn.max_pool(layer10_actv, [1, 2, 2, 1]
   ____________________________________________________________
       layer11_conv = tf.nn.conv2d(layer10_pool, variables['w11
       layer11_actv = tf.nn.relu(layer11_conv + variables['b11'
       layer12_conv = tf.nn.conv2d(layer11_actv, variables['w12
       layer12_actv = tf.nn.relu(layer12_conv + variables['b12'
       layer13_conv = tf.nn.conv2d(layer12_actv, variables['w13
       layer13_actv = tf.nn.relu(layer13_conv + variables['b13'
       layer13_pool = tf.nn.max_pool(layer13_actv, [1, 2, 2, 1]
       ________________________________________________________
       flat_layer  = flatten_tf_array(layer13_pool)____________
       layer14_fccd = tf.matmul(flat_layer, variables['w14']) +
       layer14_actv = tf.nn.relu(layer14_fccd)_________________
       layer14_drop = tf.nn.dropout(layer14_actv, 0.5)_________
       ________________________________________________________
       layer15_fccd = tf.matmul(layer14_drop, variables['w15'])
       layer15_actv = tf.nn.relu(layer15_fccd)_________________
       layer15_drop = tf.nn.dropout(layer15_actv, 0.5)_________
       ________________________________________________________
       logits = tf.matmul(layer15_drop, variables['w16']) + var
       return logits___________________________________________
   1
   2
   3
   4
   5
   6
   7
   8
   9
   10
   11
   12
   13
   14
   15
   16
   17
   18
   19
   20
   21
   22
   23
   24
   25
   26
   27
   28
   29
   30
   31
   32
   33
   34
   35
   36
   37
   38
   39
   40
   41
   42
   43
   44
   45
   46
   47
   48
   49
   50
   51
   52
   53
   54
   55
   56
   57
   58
   59
   60
   61
   62
   63
   64
   65
   66
   67
   68
   69
   70
   71
   72
   73
   74
   75
   76
   77
   78
   79
   80
   81
   82
   83
   84
   85
   86
   87
   88
   89
   90
   91
   92
   93
   94
   95
   96
   97
   98
   99
   100
   101
   102
   103
   104
   105
   106
   107
   108
   109
   #the vggnet neural network
   vgg16_patch_size_1, vgg16_patch_size_2, vgg16_patch_size_3,
   vgg16_patch_size_4 = 3, 3, 3, 3
   vgg16_patch_depth_1, vgg16_patch_depth_2, vgg16_patch_depth_3,
   vgg16_patch_depth_4 = 64, 128, 256, 512
   vgg16_num_hidden_1, vgg16_num_hidden_2 = 4096, 1000

   def variables_vggnet16(patch_size1 = vgg16_patch_size_1, patch_size2 =
   vgg16_patch_size_2,
                          patch_size3 = vgg16_patch_size_3, patch_size4 =
   vgg16_patch_size_4,
                          patch_depth1 = vgg16_patch_depth_1, patch_depth2
   = vgg16_patch_depth_2,
                          patch_depth3 = vgg16_patch_depth_3, patch_depth4
   = vgg16_patch_depth_4,
                          num_hidden1 = vgg16_num_hidden_1, num_hidden2 =
   vgg16_num_hidden_2,
                          image_width = 224, image_height = 224,
   image_depth = 3, num_labels = 17):

       w1 = tf.variable(tf.truncated_normal([patch_size1, patch_size1,
   image_depth, patch_depth1], stddev=0.1))
       b1 = tf.variable(tf.zeros([patch_depth1]))
       w2 = tf.variable(tf.truncated_normal([patch_size1, patch_size1,
   patch_depth1, patch_depth1], stddev=0.1))
       b2 = tf.variable(tf.constant(1.0, shape=[patch_depth1]))

       w3 = tf.variable(tf.truncated_normal([patch_size2, patch_size2,
   patch_depth1, patch_depth2], stddev=0.1))
       b3 = tf.variable(tf.constant(1.0, shape = [patch_depth2]))
       w4 = tf.variable(tf.truncated_normal([patch_size2, patch_size2,
   patch_depth2, patch_depth2], stddev=0.1))
       b4 = tf.variable(tf.constant(1.0, shape = [patch_depth2]))

       w5 = tf.variable(tf.truncated_normal([patch_size3, patch_size3,
   patch_depth2, patch_depth3], stddev=0.1))
       b5 = tf.variable(tf.constant(1.0, shape = [patch_depth3]))
       w6 = tf.variable(tf.truncated_normal([patch_size3, patch_size3,
   patch_depth3, patch_depth3], stddev=0.1))
       b6 = tf.variable(tf.constant(1.0, shape = [patch_depth3]))
       w7 = tf.variable(tf.truncated_normal([patch_size3, patch_size3,
   patch_depth3, patch_depth3], stddev=0.1))
       b7 = tf.variable(tf.constant(1.0, shape=[patch_depth3]))

       w8 = tf.variable(tf.truncated_normal([patch_size4, patch_size4,
   patch_depth3, patch_depth4], stddev=0.1))
       b8 = tf.variable(tf.constant(1.0, shape = [patch_depth4]))
       w9 = tf.variable(tf.truncated_normal([patch_size4, patch_size4,
   patch_depth4, patch_depth4], stddev=0.1))
       b9 = tf.variable(tf.constant(1.0, shape = [patch_depth4]))
       w10 = tf.variable(tf.truncated_normal([patch_size4, patch_size4,
   patch_depth4, patch_depth4], stddev=0.1))
       b10 = tf.variable(tf.constant(1.0, shape = [patch_depth4]))

       w11 = tf.variable(tf.truncated_normal([patch_size4, patch_size4,
   patch_depth4, patch_depth4], stddev=0.1))
       b11 = tf.variable(tf.constant(1.0, shape = [patch_depth4]))
       w12 = tf.variable(tf.truncated_normal([patch_size4, patch_size4,
   patch_depth4, patch_depth4], stddev=0.1))
       b12 = tf.variable(tf.constant(1.0, shape=[patch_depth4]))
       w13 = tf.variable(tf.truncated_normal([patch_size4, patch_size4,
   patch_depth4, patch_depth4], stddev=0.1))
       b13 = tf.variable(tf.constant(1.0, shape = [patch_depth4]))

       no_pooling_layers = 5

       w14 = tf.variable(tf.truncated_normal([(image_width //
   (2**no_pooling_layers))*(image_height //
   (2**no_pooling_layers))*patch_depth4 , num_hidden1], stddev=0.1))
       b14 = tf.variable(tf.constant(1.0, shape = [num_hidden1]))

       w15 = tf.variable(tf.truncated_normal([num_hidden1, num_hidden2],
   stddev=0.1))
       b15 = tf.variable(tf.constant(1.0, shape = [num_hidden2]))

       w16 = tf.variable(tf.truncated_normal([num_hidden2, num_labels],
   stddev=0.1))
       b16 = tf.variable(tf.constant(1.0, shape = [num_labels]))
       variables = {
           'w1': w1, 'w2': w2, 'w3': w3, 'w4': w4, 'w5': w5, 'w6': w6,
   'w7': w7, 'w8': w8, 'w9': w9, 'w10': w10,
           'w11': w11, 'w12': w12, 'w13': w13, 'w14': w14, 'w15': w15,
   'w16': w16,
           'b1': b1, 'b2': b2, 'b3': b3, 'b4': b4, 'b5': b5, 'b6': b6,
   'b7': b7, 'b8': b8, 'b9': b9, 'b10': b10,
           'b11': b11, 'b12': b12, 'b13': b13, 'b14': b14, 'b15': b15,
   'b16': b16
       }
       return variables

   def model_vggnet16(data, variables):
       layer1_conv = tf.nn.conv2d(data, variables['w1'], [1, 1, 1, 1],
   padding='same')
       layer1_actv = tf.nn.relu(layer1_conv + variables['b1'])
       layer2_conv = tf.nn.conv2d(layer1_actv, variables['w2'], [1, 1, 1,
   1], padding='same')
       layer2_actv = tf.nn.relu(layer2_conv + variables['b2'])
       layer2_pool = tf.nn.max_pool(layer2_actv, [1, 2, 2, 1], [1, 2, 2,
   1], padding='same')

       layer3_conv = tf.nn.conv2d(layer2_pool, variables['w3'], [1, 1, 1,
   1], padding='same')
       layer3_actv = tf.nn.relu(layer3_conv + variables['b3'])
       layer4_conv = tf.nn.conv2d(layer3_actv, variables['w4'], [1, 1, 1,
   1], padding='same')
       layer4_actv = tf.nn.relu(layer4_conv + variables['b4'])
       layer4_pool = tf.nn.max_pool(layer4_pool, [1, 2, 2, 1], [1, 2, 2,
   1], padding='same')

       layer5_conv = tf.nn.conv2d(layer4_pool, variables['w5'], [1, 1, 1,
   1], padding='same')
       layer5_actv = tf.nn.relu(layer5_conv + variables['b5'])
       layer6_conv = tf.nn.conv2d(layer5_actv, variables['w6'], [1, 1, 1,
   1], padding='same')
       layer6_actv = tf.nn.relu(layer6_conv + variables['b6'])
       layer7_conv = tf.nn.conv2d(layer6_actv, variables['w7'], [1, 1, 1,
   1], padding='same')
       layer7_actv = tf.nn.relu(layer7_conv + variables['b7'])
       layer7_pool = tf.nn.max_pool(layer7_actv, [1, 2, 2, 1], [1, 2, 2,
   1], padding='same')

       layer8_conv = tf.nn.conv2d(layer7_pool, variables['w8'], [1, 1, 1,
   1], padding='same')
       layer8_actv = tf.nn.relu(layer8_conv + variables['b8'])
       layer9_conv = tf.nn.conv2d(layer8_actv, variables['w9'], [1, 1, 1,
   1], padding='same')
       layer9_actv = tf.nn.relu(layer9_conv + variables['b9'])
       layer10_conv = tf.nn.conv2d(layer9_actv, variables['w10'], [1, 1,
   1, 1], padding='same')
       layer10_actv = tf.nn.relu(layer10_conv + variables['b10'])
       layer10_pool = tf.nn.max_pool(layer10_actv, [1, 2, 2, 1], [1, 2, 2,
   1], padding='same')

       layer11_conv = tf.nn.conv2d(layer10_pool, variables['w11'], [1, 1,
   1, 1], padding='same')
       layer11_actv = tf.nn.relu(layer11_conv + variables['b11'])
       layer12_conv = tf.nn.conv2d(layer11_actv, variables['w12'], [1, 1,
   1, 1], padding='same')
       layer12_actv = tf.nn.relu(layer12_conv + variables['b12'])
       layer13_conv = tf.nn.conv2d(layer12_actv, variables['w13'], [1, 1,
   1, 1], padding='same')
       layer13_actv = tf.nn.relu(layer13_conv + variables['b13'])
       layer13_pool = tf.nn.max_pool(layer13_actv, [1, 2, 2, 1], [1, 2, 2,
   1], padding='same')

       flat_layer  = flatten_tf_array(layer13_pool)
       layer14_fccd = tf.matmul(flat_layer, variables['w14']) +
   variables['b14']
       layer14_actv = tf.nn.relu(layer14_fccd)
       layer14_drop = tf.nn.dropout(layer14_actv, 0.5)

       layer15_fccd = tf.matmul(layer14_drop, variables['w15']) +
   variables['b15']
       layer15_actv = tf.nn.relu(layer15_fccd)
       layer15_drop = tf.nn.dropout(layer15_actv, 0.5)

       logits = tf.matmul(layer15_drop, variables['w16']) +
   variables['b16']
       return logits



3.3 alexnet performance


   as a comparison, have a look at the lenet5 id98 performance on the
   larger oxflower17 dataset:



4. final words

   the code is also available in my [56]github repository, so feel free to
   use it on your own dataset(s).


   there is much more to explore in the world of deep learning; recurrent
   neural networks, region-based id98   s, gan   s, id23,
   etc. in future blog-posts i   ll build these types of neural networks,
   and also build awesome applications with what we have already learned.
   so subscribe and stay tuned!

     __________________________________________________________________
     __________________________________________________________________
     __________________________________________________________________


   [1] if you feel like you need to refresh your understanding of id98   s,
   here are some good starting points to get you up to speed:
     * [57]machine learning is fun!
     * [58]an intuitive explanation of convolutional neural networks :
     * [59]cs231n convolutional neural networks for visual recognition :
     * [60]udacity   s deep learning course:
     * [61]neural networks and deep learning ch 6.

   [62]go back to top



   [2] if you want more information about the theory behind these
   different neural networks, adit deshpande   s [63]blog post provides a
   good comparison of them with links to the original papers. eugenio
   culurciello has a nice [64]blog and [65]article worth a read.  in
   addition to that, also have a look at [66]this github repository
   containing awesome deep learning papers, and [67]this github repository
   where deep learning papers are ordered by task and date.

   [68]go back to top

delen:

     * [69]klik om te delen met twitter (wordt in een nieuw venster
       geopend)
     * [70]klik om te delen op facebook (wordt in een nieuw venster
       geopend)
     * [71]klik om op google+ te delen (wordt in een nieuw venster
       geopend)
     *

   share this:

post navigation

   [72]classification with scikit-learn
   [73]using convolutional neural networks to detect features in satellite
   images

4 thoughts on    building convolutional neural networks with tensorflow   

    1.
   dolphin schreef:
       [74]augustus 17, 2017 om 5:43 pm
       a good example for a beginner like me
       [75]beantwoorden
    2. pingback: [76]using convolutional neural networks to detect
       features in sattelite images     ahmet taspinar
    3. pingback: [77]             |                                                                    | talkingdata's blog
    4. pingback: [78]building recurrent neural networks in tensorflow    
       ahmet taspinar

geef een reactie [79]reactie annuleren

   het e-mailadres wordt niet gepubliceerd. vereiste velden zijn
   gemarkeerd met *

   reactie
   _____________________________________________
   _____________________________________________
   _____________________________________________
   _____________________________________________
   _____________________________________________
   _____________________________________________
   _____________________________________________
   _____________________________________________

   naam * ______________________________

   e-mail * ______________________________

   website ______________________________

   reactie plaatsen

   u heeft javascript momenteel uitgeschakeld. om een reactie te kunnen
   plaatsen dient u javascript in te schakelen en cookies toe te staan,
   vernieuw vervolgens deze pagina. [80]klik hier voor uitleg over het
   inschakelen van javascript in uw browser.

   [ ] stuur mij een e-mail als er vervolgreacties zijn.

   [ ] stuur mij een e-mail als er nieuwe berichten zijn.

   zoeken naar: ____________________ zoeken

subscribe to this blog!

   e-mailadres ____________________

   subscribe!

meest recente berichten

     * [81]a guide for using the wavelet transform in machine learning
     * [82]building recurrent neural networks in tensorflow
     * [83]machine learning with signal processing techniques
     * [84]using convolutional neural networks to detect features in
       satellite images
     * [85]building convolutional neural networks with tensorflow

categorie  n

     * [86]classification
     * [87]convolutional neural networks
     * [88]data mining
     * [89]deep learning
     * [90]machine learning
     * [91]recurrent neural networks
     * [92]scikit-learn
     * [93]sentiment analytics
     * [94]stochastic signal analysis
     * [95]tensorflow
     * [96]twitter analytics
     * [97]uncategorized
     * [98]visualizations

meta

     * [99]inloggen
     * [100]berichten rss
     * [101]reacties rss
     * [102]wordpress.org

   [103]proudly powered by wordpress | theme: [104]sydney by athemes.

references

   visible links
   1. http://ataspinar.com/feed/
   2. http://ataspinar.com/comments/feed/
   3. http://ataspinar.com/2017/08/15/building-convolutional-neural-networks-with-tensorflow/feed/
   4. http://ataspinar.com/2017/05/26/classification-with-scikit-learn/
   5. http://ataspinar.com/2017/12/04/using-convolutional-neural-networks-to-detect-features-in-sattelite-images/
   6. http://ataspinar.com/wp-json/oembed/1.0/embed?url=http://ataspinar.com/2017/08/15/building-convolutional-neural-networks-with-tensorflow/
   7. http://ataspinar.com/wp-json/oembed/1.0/embed?url=http://ataspinar.com/2017/08/15/building-convolutional-neural-networks-with-tensorflow/&format=xml
   8. http://ataspinar.com/2017/08/15/building-convolutional-neural-networks-with-tensorflow/#content
   9. http://ataspinar.com/
  10. http://ataspinar.com/
  11. http://ataspinar.com/about/
  12. http://ataspinar.com/github/
  13. http://ataspinar.com/contact/
  14. http://ataspinar.com/2017/08/15/building-convolutional-neural-networks-with-tensorflow/
  15. http://ataspinar.com/author/admin/
  16. http://ataspinar.com/category/convolutional-neural-networks/
  17. http://ataspinar.com/category/deep-learning/
  18. http://ataspinar.com/category/tensorflow/
  19. http://ataspinar.com/2016/02/15/sentiment-analysis-with-the-naive-bayes-classifier/
  20. http://ataspinar.com/2016/03/28/regression-logistic-regression-and-maximum-id178/
  21. http://ataspinar.com/2016/12/22/the-id88/
  22. https://www.tensorflow.org/install/
  23. http://ataspinar.com/2017/08/15/building-convolutional-neural-networks-with-tensorflow/#id98_literature
  24. http://ataspinar.com/2017/08/15/building-convolutional-neural-networks-with-tensorflow/#ch1
  25. http://ataspinar.com/2017/08/15/building-convolutional-neural-networks-with-tensorflow/#ch2
  26. http://ataspinar.com/2017/08/15/building-convolutional-neural-networks-with-tensorflow/#ch3
  27. http://ataspinar.com/2017/08/15/building-convolutional-neural-networks-with-tensorflow/#ch4
  28. http://ataspinar.com/2017/08/15/building-convolutional-neural-networks-with-tensorflow/#ch2
  29. https://github.com/vahidk/effectivetensorflow?
  30. http://web.stanford.edu/class/cs20si/lectures/notes_01.pdf
  31. http://web.stanford.edu/class/cs20si/lectures/notes_02.pdf
  32. https://www.tensorflow.org/api_guides/python/constant_op
  33. http://yann.lecun.com/exdb/mnist/
  34. https://www.cs.toronto.edu/~kriz/cifar.html
  35. http://yann.lecun.com/exdb/mnist/
  36. https://github.com/sorki/python-mnist
  37. https://www.cs.toronto.edu/~kriz/cifar.html
  38. http://ataspinar.com/2017/08/15/building-convolutional-neural-networks-with-tensorflow/#https://www.tensorflow.org/api_guides/python/train#optimizers
  39. http://ruder.io/optimizing-gradient-descent/
  40. https://www.tensorflow.org/tutorials/layers
  41. http://tflearn.org/layers/conv/#convolution-2d
  42. http://tflearn.org/layers/core/#fully-connected
  43. https://www.tensorflow.org/versions/r0.12/api_docs/python/nn/activation_functions_
  44. http://yann.lecun.com/exdb/lenet/
  45. http://yann.lecun.com/exdb/publis/pdf/lecun-01a.pdf
  46. https://www.tensorflow.org/api_docs/python/tf/nn/conv2d
  47. http://ataspinar.com/2017/08/15/building-convolutional-neural-networks-with-tensorflow/#dl_literature
  48. https://papers.nips.cc/paper/4824-id163-classification-with-deep-convolutional-neural-networks.pdf
  49. http://arxiv.org/pdf/1311.2901v3.pdf
  50. http://arxiv.org/pdf/1409.1556v6.pdf
  51. http://www.cv-foundation.org/openaccess/content_cvpr_2015/papers/szegedy_going_deeper_with_2015_cvpr_paper.pdf
  52. https://arxiv.org/pdf/1512.03385v1.pdf
  53. https://qz.com/1034972/the-data-that-changed-the-direction-of-ai-research-and-possibly-the-world/
  54. https://www.youtube.com/watch?v=ggxdp_jwhwi
  55. http://www.robots.ox.ac.uk/~vgg/data/flowers/17/
  56. https://github.com/taspinar/sidl
  57. https://medium.com/@ageitgey/machine-learning-is-fun-part-3-deep-learning-and-convolutional-neural-networks-f40359318721
  58. https://ujjwalkarn.me/2016/08/11/intuitive-explanation-convnets/
  59. http://cs231n.github.io/convolutional-networks/
  60. https://www.udacity.com/course/deep-learning--ud730
  61. http://neuralnetworksanddeeplearning.com/chap6.html
  62. http://ataspinar.com/2017/08/15/building-convolutional-neural-networks-with-tensorflow/#contents
  63. https://adeshpande3.github.io/adeshpande3.github.io/the-9-deep-learning-papers-you-need-to-know-about.html
  64. https://medium.com/towards-data-science/neural-network-architectures-156e5bad51ba
  65. https://arxiv.org/abs/1605.07678
  66. https://github.com/terryum/awesome-deep-learning-papers
  67. https://github.com/sbrugman/deep-learning-papers
  68. http://ataspinar.com/2017/08/15/building-convolutional-neural-networks-with-tensorflow/#contents
  69. http://ataspinar.com/2017/08/15/building-convolutional-neural-networks-with-tensorflow/?share=twitter
  70. http://ataspinar.com/2017/08/15/building-convolutional-neural-networks-with-tensorflow/?share=facebook
  71. http://ataspinar.com/2017/08/15/building-convolutional-neural-networks-with-tensorflow/?share=google-plus-1
  72. http://ataspinar.com/2017/05/26/classification-with-scikit-learn/
  73. http://ataspinar.com/2017/12/04/using-convolutional-neural-networks-to-detect-features-in-sattelite-images/
  74. http://ataspinar.com/2017/08/15/building-convolutional-neural-networks-with-tensorflow/#comment-302
  75. http://ataspinar.com/2017/08/15/building-convolutional-neural-networks-with-tensorflow/?replytocom=302#respond
  76. http://ataspinar.com/2017/12/04/using-convolutional-neural-networks-to-detect-features-in-sattelite-images/
  77. http://blog.talkingdata.net/?p=5078
  78. http://ataspinar.com/2018/07/05/building-recurrent-neural-networks-in-tensorflow/
  79. http://ataspinar.com/2017/08/15/building-convolutional-neural-networks-with-tensorflow/#respond
  80. http://enable-javascript.com/
  81. http://ataspinar.com/2018/12/21/a-guide-for-using-the-wavelet-transform-in-machine-learning/
  82. http://ataspinar.com/2018/07/05/building-recurrent-neural-networks-in-tensorflow/
  83. http://ataspinar.com/2018/04/04/machine-learning-with-signal-processing-techniques/
  84. http://ataspinar.com/2017/12/04/using-convolutional-neural-networks-to-detect-features-in-sattelite-images/
  85. http://ataspinar.com/2017/08/15/building-convolutional-neural-networks-with-tensorflow/
  86. http://ataspinar.com/category/machine-learning/classification/
  87. http://ataspinar.com/category/convolutional-neural-networks/
  88. http://ataspinar.com/category/data-mining/
  89. http://ataspinar.com/category/deep-learning/
  90. http://ataspinar.com/category/machine-learning/
  91. http://ataspinar.com/category/recurrent-neural-networks/
  92. http://ataspinar.com/category/scikit-learn/
  93. http://ataspinar.com/category/machine-learning/sentiment-analytics/
  94. http://ataspinar.com/category/stochastic-signal-analysis/
  95. http://ataspinar.com/category/tensorflow/
  96. http://ataspinar.com/category/twitter-analytics/
  97. http://ataspinar.com/category/uncategorized/
  98. http://ataspinar.com/category/visualizations/
  99. http://ataspinar.com/wp-login.php
 100. http://ataspinar.com/feed/
 101. http://ataspinar.com/comments/feed/
 102. https://nl.wordpress.org/
 103. http://wordpress.org/
 104. https://athemes.com/theme/sydney

   hidden links:
 106. javascript:void(0);
 107. https://www.addtoany.com/add_to/facebook?linkurl=http%3a%2f%2fataspinar.com%2f2017%2f08%2f15%2fbuilding-convolutional-neural-networks-with-tensorflow%2f&linkname=building%20convolutional%20neural%20networks%20with%20tensorflow
 108. https://www.addtoany.com/add_to/twitter?linkurl=http%3a%2f%2fataspinar.com%2f2017%2f08%2f15%2fbuilding-convolutional-neural-networks-with-tensorflow%2f&linkname=building%20convolutional%20neural%20networks%20with%20tensorflow
 109. https://www.addtoany.com/add_to/reddit?linkurl=http%3a%2f%2fataspinar.com%2f2017%2f08%2f15%2fbuilding-convolutional-neural-networks-with-tensorflow%2f&linkname=building%20convolutional%20neural%20networks%20with%20tensorflow
 110. https://www.addtoany.com/add_to/linkedin?linkurl=http%3a%2f%2fataspinar.com%2f2017%2f08%2f15%2fbuilding-convolutional-neural-networks-with-tensorflow%2f&linkname=building%20convolutional%20neural%20networks%20with%20tensorflow
 111. https://www.addtoany.com/add_to/sina_weibo?linkurl=http%3a%2f%2fataspinar.com%2f2017%2f08%2f15%2fbuilding-convolutional-neural-networks-with-tensorflow%2f&linkname=building%20convolutional%20neural%20networks%20with%20tensorflow
 112. https://www.addtoany.com/share
