syntax and parsing

yoav goldberg
bar ilan university

goals

    what is parsing? why do we care? 

    phrase-based (constituency) trees 

    pid18, cky 

    dependency trees 

    graph parsers, transition parsers

natural language parsing

i sentences in natural language have structure.
i linguists create linguistic theories for de   ning this

structure.

i the parsing problem is recovering that structure.

2 / 47

john ate delicious pizza with friends

s

vp

vp

np

pp

np
john ate delicious pizza with friends

np

parsing

syntactic parsing

rcmod

rel

subj

xcomp

root

det

subj

aux acomp

acomp

the soup , which i expected to be good , was bad

syntactic parsing

rcmod

rel

subj

xcomp

root

det

subj

aux acomp

acomp

the soup , which i expected to be good , was bad

parsing

why parsing?

syntactic parsing

id31

rcmod

rel

subj

xcomp

root

det

subj

aux acomp

acomp

the soup , which i expected to be good , was bad

syntactic parsing

id31

rcmod

rel

subj

xcomp

root

det

subj

aux acomp

acomp

the soup , which i expected to be good , was bad

negative

syntactic parsing

id31

rcmod

rel

subj

xcomp

root

det

subj

aux acomp

acomp

the soup , which i expected to be good , was bad

negative

syntactic parsing

id31

rcmod

rel

subj

xcomp

root

det

subj

aux acomp

acomp

the soup , which i expected to be good , was bad

+

parsing

syntactic parsing
syntactic parsing

id31

rcmod
rcmod

rel
rel

subj
subj

xcomp
xcomp

root
root

det
det

subj
subj

aux acomp
aux acomp

acomp
acomp

the soup , which i expected to be good , was bad
the soup , which i expected to be good , was bad

+

parsing

knowing the structure of the sentence 

helps id31

machine translation

on all levels of the parse-tree.
on all levels of the parse-tree.
we suggest that id4 can also bene   t the incor-
we suggest that id4 can also bene   t the incor-
poration of syntactic knowledge, and propose a
poration of syntactic knowledge, and propose a
simple method of performing string-to-tree neu-
simple method of performing string-to-tree neu-
ral machine translation. our method is inspired
ral machine translation. our method is inspired
by recent works in syntactic parsing, which model
by recent works in syntactic parsing, which model
trees as sequences (vinyals et al., 2015; choe
trees as sequences (vinyals et al., 2015; choe
and charniak, 2016). namely, we translate a
and charniak, 2016). namely, we translate a
source sentence into a linearized, lexicalized con-
source sentence into a linearized, lexicalized con-
stituency tree, as demonstrated in figure 2. fig-
stituency tree, as demonstrated in figure 2. fig-
ure 1 shows an example output of our neural s2t
ure 1 shows an example output of our neural s2t
model compared to a standard id4 system, as
model compared to a standard id4 system, as
well as the attention-induced word alignments of
well as the attention-induced word alignments of
the two models.
the two models.

english
lstms are very capable learners

we present a simple method to incorporate
syntactic information about the target lan-
guage in a id4 sys-
tem by translating into linearized, lexical-
ized constituency trees. an experiment on
the wmt16 german-english news trans-
lation task resulted in a similar id7
score when compared to a syntax-agnostic
id4 baseline trained on the same dataset.
an analysis of the translations from the
syntax-aware system shows that it per-
forms much more reordering during trans-
lation in comparison to the baseline.

we present a simple method to incorporate
syntactic information about the target lan-
guage in a id4 sys-
tem by translating into linearized, lexical-
ized constituency trees. an experiment on
the wmt16 german-english news trans-
lation task resulted in a similar id7
score when compared to a syntax-agnostic
id4 baseline trained on the same dataset.
an analysis of the translations from the
syntax-aware system shows that it per-
german
forms much more reordering during trans-
lation in comparison to the baseline.
1 introduction and model
1
introduction and model
id4 (id4) (kalchbren-
id4 (id4) (kalchbren-
ner and blunsom, 2013; sutskever et al., 2014;
ner and blunsom, 2013; sutskever et al., 2014;
bahdanau et al., 2014) has recently became the
bahdanau et al., 2014) has recently became the
state-of-the-art approach to machine translation
state-of-the-art approach to machine translation
(bojar et al., 2016), while being much simpler than
(bojar et al., 2016), while being much simpler than
the previously dominant phrase-based statistical
the previously dominant phrase-based statistical
machine translation (smt) approaches (koehn,
machine translation (smt) approaches (koehn,
2010). id4 models usually do not make ex-
2010). id4 models usually do not make ex-
plicit use of syntactic information about the lan-
plicit use of syntactic information about the lan-
guages at hand. however, a large body of work
guages at hand. however, a large body of work
was dedicated to syntax-based smt (williams
was dedicated to syntax-based smt (williams
et al., 2016). one prominent approach to syntax-
et al., 2016). one prominent approach to syntax-
based smt is string-to-tree (s2t) translation (ya-
based smt is string-to-tree (s2t) translation (ya-
mada and knight, 2001, 2002), in which a source-
mada and knight, 2001, 2002), in which a source-

figure 1: top - a lexicalized tree translation pre-
figure 1: top - a lexicalized tree translation pre-
dicted by the bpe2tree model. bottom - a trans-

machine translation

on all levels of the parse-tree.
on all levels of the parse-tree.
we suggest that id4 can also bene   t the incor-
we suggest that id4 can also bene   t the incor-
poration of syntactic knowledge, and propose a
poration of syntactic knowledge, and propose a
simple method of performing string-to-tree neu-
simple method of performing string-to-tree neu-
ral machine translation. our method is inspired
ral machine translation. our method is inspired
by recent works in syntactic parsing, which model
by recent works in syntactic parsing, which model
trees as sequences (vinyals et al., 2015; choe
trees as sequences (vinyals et al., 2015; choe
and charniak, 2016). namely, we translate a
and charniak, 2016). namely, we translate a
source sentence into a linearized, lexicalized con-
source sentence into a linearized, lexicalized con-
stituency tree, as demonstrated in figure 2. fig-
stituency tree, as demonstrated in figure 2. fig-
ure 1 shows an example output of our neural s2t
ure 1 shows an example output of our neural s2t
model compared to a standard id4 system, as
model compared to a standard id4 system, as
well as the attention-induced word alignments of
well as the attention-induced word alignments of
the two models.
the two models.

english
lstms are very capable learners

we present a simple method to incorporate
syntactic information about the target lan-
guage in a id4 sys-
tem by translating into linearized, lexical-
ized constituency trees. an experiment on
the wmt16 german-english news trans-
lation task resulted in a similar id7
score when compared to a syntax-agnostic
id4 baseline trained on the same dataset.
an analysis of the translations from the
syntax-aware system shows that it per-
forms much more reordering during trans-
lation in comparison to the baseline.

we present a simple method to incorporate
syntactic information about the target lan-
guage in a id4 sys-
tem by translating into linearized, lexical-
ized constituency trees. an experiment on
the wmt16 german-english news trans-
lation task resulted in a similar id7
score when compared to a syntax-agnostic
id4 baseline trained on the same dataset.
an analysis of the translations from the
syntax-aware system shows that it per-
german
forms much more reordering during trans-
lation in comparison to the baseline.
1 introduction and model
1
introduction and model
id4 (id4) (kalchbren-
id4 (id4) (kalchbren-
ner and blunsom, 2013; sutskever et al., 2014;
ner and blunsom, 2013; sutskever et al., 2014;
bahdanau et al., 2014) has recently became the
bahdanau et al., 2014) has recently became the
state-of-the-art approach to machine translation
state-of-the-art approach to machine translation
(bojar et al., 2016), while being much simpler than
(bojar et al., 2016), while being much simpler than
the previously dominant phrase-based statistical
the previously dominant phrase-based statistical
machine translation (smt) approaches (koehn,
machine translation (smt) approaches (koehn,
2010). id4 models usually do not make ex-
2010). id4 models usually do not make ex-
plicit use of syntactic information about the lan-
plicit use of syntactic information about the lan-
guages at hand. however, a large body of work
guages at hand. however, a large body of work
was dedicated to syntax-based smt (williams
was dedicated to syntax-based smt (williams
et al., 2016). one prominent approach to syntax-
et al., 2016). one prominent approach to syntax-
based smt is string-to-tree (s2t) translation (ya-
based smt is string-to-tree (s2t) translation (ya-
mada and knight, 2001, 2002), in which a source-
mada and knight, 2001, 2002), in which a source-

figure 1: top - a lexicalized tree translation pre-
figure 1: top - a lexicalized tree translation pre-
dicted by the bpe2tree model. bottom - a trans-

machine translation

on all levels of the parse-tree.
on all levels of the parse-tree.
we suggest that id4 can also bene   t the incor-
we suggest that id4 can also bene   t the incor-
poration of syntactic knowledge, and propose a
poration of syntactic knowledge, and propose a
simple method of performing string-to-tree neu-
simple method of performing string-to-tree neu-
ral machine translation. our method is inspired
ral machine translation. our method is inspired
by recent works in syntactic parsing, which model
by recent works in syntactic parsing, which model
trees as sequences (vinyals et al., 2015; choe
trees as sequences (vinyals et al., 2015; choe
and charniak, 2016). namely, we translate a
and charniak, 2016). namely, we translate a
source sentence into a linearized, lexicalized con-
source sentence into a linearized, lexicalized con-
stituency tree, as demonstrated in figure 2. fig-
stituency tree, as demonstrated in figure 2. fig-
ure 1 shows an example output of our neural s2t
ure 1 shows an example output of our neural s2t
model compared to a standard id4 system, as
model compared to a standard id4 system, as
well as the attention-induced word alignments of
well as the attention-induced word alignments of
the two models.
the two models.

english
lstms are very capable learners

we present a simple method to incorporate
syntactic information about the target lan-
guage in a id4 sys-
tem by translating into linearized, lexical-
ized constituency trees. an experiment on
the wmt16 german-english news trans-
lation task resulted in a similar id7
score when compared to a syntax-agnostic
id4 baseline trained on the same dataset.
an analysis of the translations from the
syntax-aware system shows that it per-
forms much more reordering during trans-
lation in comparison to the baseline.

we present a simple method to incorporate
syntactic information about the target lan-
guage in a id4 sys-
tem by translating into linearized, lexical-
ized constituency trees. an experiment on
the wmt16 german-english news trans-
lation task resulted in a similar id7
score when compared to a syntax-agnostic
id4 baseline trained on the same dataset.
an analysis of the translations from the
syntax-aware system shows that it per-
german
forms much more reordering during trans-
lation in comparison to the baseline.
1 introduction and model
1
introduction and model
id4 (id4) (kalchbren-
id4 (id4) (kalchbren-
ner and blunsom, 2013; sutskever et al., 2014;
ner and blunsom, 2013; sutskever et al., 2014;
bahdanau et al., 2014) has recently became the
bahdanau et al., 2014) has recently became the
state-of-the-art approach to machine translation
state-of-the-art approach to machine translation
(bojar et al., 2016), while being much simpler than
(bojar et al., 2016), while being much simpler than
the previously dominant phrase-based statistical
the previously dominant phrase-based statistical
machine translation (smt) approaches (koehn,
machine translation (smt) approaches (koehn,
2010). id4 models usually do not make ex-
2010). id4 models usually do not make ex-
plicit use of syntactic information about the lan-
plicit use of syntactic information about the lan-
guages at hand. however, a large body of work
guages at hand. however, a large body of work
was dedicated to syntax-based smt (williams
was dedicated to syntax-based smt (williams
et al., 2016). one prominent approach to syntax-
et al., 2016). one prominent approach to syntax-
based smt is string-to-tree (s2t) translation (ya-
based smt is string-to-tree (s2t) translation (ya-
mada and knight, 2001, 2002), in which a source-
mada and knight, 2001, 2002), in which a source-

figure 1: top - a lexicalized tree translation pre-
figure 1: top - a lexicalized tree translation pre-
dicted by the bpe2tree model. bottom - a trans-

on all levels of the parse-tree.
on all levels of the parse-tree.
we suggest that id4 can also bene   t the incor-
we suggest that id4 can also bene   t the incor-
poration of syntactic knowledge, and propose a
poration of syntactic knowledge, and propose a
simple method of performing string-to-tree neu-
simple method of performing string-to-tree neu-
ral machine translation. our method is inspired
ral machine translation. our method is inspired
by recent works in syntactic parsing, which model
by recent works in syntactic parsing, which model
trees as sequences (vinyals et al., 2015; choe
trees as sequences (vinyals et al., 2015; choe
and charniak, 2016). namely, we translate a
and charniak, 2016). namely, we translate a
source sentence into a linearized, lexicalized con-
source sentence into a linearized, lexicalized con-
stituency tree, as demonstrated in figure 2. fig-
stituency tree, as demonstrated in figure 2. fig-
ure 1 shows an example output of our neural s2t
ure 1 shows an example output of our neural s2t
model compared to a standard id4 system, as
model compared to a standard id4 system, as
well as the attention-induced word alignments of
well as the attention-induced word alignments of
the two models.
the two models.

knowing the structure of a sentence  
helps to translate better

we present a simple method to incorporate
syntactic information about the target lan-
guage in a id4 sys-
tem by translating into linearized, lexical-
ized constituency trees. an experiment on
the wmt16 german-english news trans-
lation task resulted in a similar id7
score when compared to a syntax-agnostic
id4 baseline trained on the same dataset.
an analysis of the translations from the
syntax-aware system shows that it per-
forms much more reordering during trans-
lation in comparison to the baseline.

we present a simple method to incorporate
syntactic information about the target lan-
guage in a id4 sys-
tem by translating into linearized, lexical-
ized constituency trees. an experiment on
the wmt16 german-english news trans-
lation task resulted in a similar id7
score when compared to a syntax-agnostic
id4 baseline trained on the same dataset.
an analysis of the translations from the
syntax-aware system shows that it per-
forms much more reordering during trans-
lation in comparison to the baseline.
1 introduction and model
1
introduction and model
id4 (id4) (kalchbren-
id4 (id4) (kalchbren-
ner and blunsom, 2013; sutskever et al., 2014;
ner and blunsom, 2013; sutskever et al., 2014;
bahdanau et al., 2014) has recently became the
bahdanau et al., 2014) has recently became the
state-of-the-art approach to machine translation
state-of-the-art approach to machine translation
(bojar et al., 2016), while being much simpler than
(bojar et al., 2016), while being much simpler than
the previously dominant phrase-based statistical
the previously dominant phrase-based statistical
machine translation (smt) approaches (koehn,
machine translation (smt) approaches (koehn,
2010). id4 models usually do not make ex-
2010). id4 models usually do not make ex-
plicit use of syntactic information about the lan-
plicit use of syntactic information about the lan-
guages at hand. however, a large body of work
guages at hand. however, a large body of work
was dedicated to syntax-based smt (williams
was dedicated to syntax-based smt (williams
et al., 2016). one prominent approach to syntax-
et al., 2016). one prominent approach to syntax-
based smt is string-to-tree (s2t) translation (ya-
based smt is string-to-tree (s2t) translation (ya-
mada and knight, 2001, 2002), in which a source-
mada and knight, 2001, 2002), in which a source-

figure 1: top - a lexicalized tree translation pre-
figure 1: top - a lexicalized tree translation pre-
dicted by the bpe2tree model. bottom - a trans-

hypernymy extraction 

"tuvalu" is a country
"ninjaken" is a weapon
lstms are very capable learners
"chlamydophila" is a bacteria

embeddings:

lemma
pos
dependency label
direction

hypernymy
detection
extraction

and

x/noun/nsubj/> be/verb/root/-

y/noun/attr/<

x/noun/dobj/> define/verb/root/-

as/adp/prep/<

y/noun/pobj/<

(x, y)

classi   cation

(softmax)

~op

average
pooling

~vxy

~vwx

~vwy

figure 2: an illustration of term-pair classi   cation. each term-pair is represented by several paths. each path is a sequence of

path lstm

term-pair classi   er

experts often de   ne chlamydophila as any bacteria that

will

...

nsubj
advmod

prep

pobj
det

dobj

experts often de   ne chlamydophila as any bacteria that

will

...

parse

rel

mark

   nd tree path

nsubj
advmod

prep

pobj
det

dobj

rel

mark

experts often de   ne chlamydophila as any bacteria that

will

...

embeddings:

lemma
pos
dependency label
direction

x/noun/nsubj/> be/verb/root/-

y/noun/attr/<

x/noun/dobj/> define/verb/root/-

as/adp/prep/<

y/noun/pobj/<

(x, y)

classi   cation

(softmax)

~op

average
pooling

~vxy

~vwx

~vwy

path lstm

term-pair classi   er

figure 2: an illustration of term-pair classi   cation. each term-pair is represented by several paths. each path is a sequence of
edges, and each edge consists of four components: lemma, pos, dependency label and dependency direction. each edge vector
is fed in sequence into the lstm, resulting in a path embedding vector ~op. the averaged path vector becomes the term-pair   s
feature vector, used for classi   cation. the dashed ~vwx , ~vwy vectors refer to the integrated network described in section 3.2.

encode tree path as lstm

prep

nsubj
advmod

term-pair classi   cation each (x, y) term-pair
is represented by the multiset of lexico-syntactic
paths that connected x and y in the corpus, de-
noted as paths(x, y), while the supervision is
given for the term pairs. we represent each (x, y)
term-pair as the weighted-average of its path vec-
tors, by applying average pooling on its path vec-
tors, as follows:

dobj

rel

pobj
det

the 50-dimensional and 100-dimensional embed-
ding vectors and selected the ones that yield bet-
ter performance on the validation set.4 the other
embeddings, as well as out-of-vocabulary lemmas,
...
are initialized randomly. we update all embedding
vectors during training.

will

mark

3.2 integrated network

experts often de   ne chlamydophila as any bacteria that

embeddings:

lemma
pos
dependency label
direction

x/noun/nsubj/> be/verb/root/-

y/noun/attr/<

x/noun/dobj/> define/verb/root/-

as/adp/prep/<

y/noun/pobj/<

(x, y)

classi   cation

(softmax)

~op

average
pooling

~vxy

~vwx

~vwy

path lstm

term-pair classi   er

figure 2: an illustration of term-pair classi   cation. each term-pair is represented by several paths. each path is a sequence of
edges, and each edge consists of four components: lemma, pos, dependency label and dependency direction. each edge vector
is fed in sequence into the lstm, resulting in a path embedding vector ~op. the averaged path vector becomes the term-pair   s
feature vector, used for classi   cation. the dashed ~vwx , ~vwy vectors refer to the integrated network described in section 3.2.

encode tree path as lstm

prep

nsubj
advmod

term-pair classi   cation each (x, y) term-pair
is represented by the multiset of lexico-syntactic
paths that connected x and y in the corpus, de-
noted as paths(x, y), while the supervision is
given for the term pairs. we represent each (x, y)
term-pair as the weighted-average of its path vec-
tors, by applying average pooling on its path vec-
tors, as follows:

dobj

rel

pobj
det

the 50-dimensional and 100-dimensional embed-
ding vectors and selected the ones that yield bet-
ter performance on the validation set.4 the other
embeddings, as well as out-of-vocabulary lemmas,
...
are initialized randomly. we update all embedding
vectors during training.

will

mark

3.2 integrated network

experts often de   ne chlamydophila as any bacteria that

embeddings:

lemma
pos
dependency label
direction

x/noun/nsubj/> be/verb/root/-

y/noun/attr/<

x/noun/dobj/> define/verb/root/-

as/adp/prep/<

y/noun/pobj/<

(x, y)

classi   cation

(softmax)

~op

average
pooling

~vxy

~vwx

~vwy

path lstm

term-pair classi   er

figure 2: an illustration of term-pair classi   cation. each term-pair is represented by several paths. each path is a sequence of
edges, and each edge consists of four components: lemma, pos, dependency label and dependency direction. each edge vector
is fed in sequence into the lstm, resulting in a path embedding vector ~op. the averaged path vector becomes the term-pair   s
feature vector, used for classi   cation. the dashed ~vwx , ~vwy vectors refer to the integrated network described in section 3.2.

encode tree path as lstm

prep

nsubj
advmod

term-pair classi   cation each (x, y) term-pair
is represented by the multiset of lexico-syntactic
paths that connected x and y in the corpus, de-
noted as paths(x, y), while the supervision is
given for the term pairs. we represent each (x, y)
term-pair as the weighted-average of its path vec-
tors, by applying average pooling on its path vec-
tors, as follows:

dobj

rel

pobj
det

the 50-dimensional and 100-dimensional embed-
ding vectors and selected the ones that yield bet-
ter performance on the validation set.4 the other
embeddings, as well as out-of-vocabulary lemmas,
...
are initialized randomly. we update all embedding
vectors during training.

will

mark

3.2 integrated network

experts often de   ne chlamydophila as any bacteria that

based on parse-tree paths

based on 

id65
(which can also be aided by parsing)

embeddings:

lemma
pos
dependency label
direction

x/noun/nsubj/> be/verb/root/-

y/noun/attr/<

x/noun/dobj/> define/verb/root/-

as/adp/prep/<

y/noun/pobj/<

(x, y)

classi   cation

(softmax)

~op

average
pooling

~vxy

~vwx

~vwy

path lstm

term-pair classi   er

figure 2: an illustration of term-pair classi   cation. each term-pair is represented by several paths. each path is a sequence of
edges, and each edge consists of four components: lemma, pos, dependency label and dependency direction. each edge vector
is fed in sequence into the lstm, resulting in a path embedding vector ~op. the averaged path vector becomes the term-pair   s
feature vector, used for classi   cation. the dashed ~vwx , ~vwy vectors refer to the integrated network described in section 3.2.

term-pair classi   cation each (x, y) term-pair
is represented by the multiset of lexico-syntactic
paths that connected x and y in the corpus, de-

the 50-dimensional and 100-dimensional embed-
ding vectors and selected the ones that yield bet-
ter performance on the validation set.4 the other

based on parse-tree paths

based on 

id65
(which can also be aided by parsing)

embeddings:

lemma
pos
dependency label
direction

x/noun/nsubj/> be/verb/root/-

y/noun/attr/<

x/noun/dobj/> define/verb/root/-

as/adp/prep/<

y/noun/pobj/<

(x, y)

classi   cation

(softmax)

~op

average
pooling

~vxy

~vwx

~vwy

path lstm

term-pair classi   er

figure 2: an illustration of term-pair classi   cation. each term-pair is represented by several paths. each path is a sequence of
edges, and each edge consists of four components: lemma, pos, dependency label and dependency direction. each edge vector
is fed in sequence into the lstm, resulting in a path embedding vector ~op. the averaged path vector becomes the term-pair   s
feature vector, used for classi   cation. the dashed ~vwx , ~vwy vectors refer to the integrated network described in section 3.2.

substantially improves results on many lexical

id36 tasks and datasets

term-pair classi   cation each (x, y) term-pair
is represented by the multiset of lexico-syntactic
paths that connected x and y in the corpus, de-

the 50-dimensional and 100-dimensional embed-
ding vectors and selected the ones that yield bet-
ter performance on the validation set.4 the other

preposition sense disambiguation

improving preposition sense disambiguation

with representations learned from multilingual data

i met him for lunch
he paid for me
we sat there for hours

purpose
lstms are very capable learners
bene   ciary
duration

hila gonen and yoav goldberg
yoav.goldberg@gmail.com
hilagonen87@gmail.com

prepositions are very common, very ambiguous and tend to carry different 
meanings in different contexts. 

2. full model  

preposition-sense disambiguation is a task of assigning a category to a 
preposition in context: 

preposition

sense
   you should book a room for 2 nights            duration
   for some reason, he is not here yet            explanation 
   i went there to get a present for my mother           beneficiary

disambiguation

+

semisup on multilingual data
- can we improve performance by using unannotated data?
- are translations of prepositions to other languages predictive for this task? 
- how can we use multilingual corpora for learning a representation of the 

context that can be used for sense-disambiguation?

3. mlp-based model for preposition classification

(cid:1877)=argmax(cid:3037)(cid:1839)(cid:1838)(cid:1842)(cid:3046)(cid:3032)(cid:3041)(cid:3046)(cid:3032)((cid:2038)(cid:1871),(cid:1861))[(cid:1862)]

4. multilingual data

preposition sense disambiguation

improving preposition sense disambiguation

with representations learned from multilingual data

i met him for lunch
he paid for me
we sat there for hours

purpose
lstms are very capable learners
bene   ciary
duration

hila gonen and yoav goldberg
yoav.goldberg@gmail.com
hilagonen87@gmail.com

prepositions are very common, very ambiguous and tend to carry different 
meanings in different contexts. 

2. full model  

preposition-sense disambiguation is a task of assigning a category to a 
preposition in context: 

preposition

sense
   you should book a room for 2 nights            duration
   for some reason, he is not here yet            explanation 
   i went there to get a present for my mother           beneficiary

disambiguation

+

semisup on multilingual data
- can we improve performance by using unannotated data?
- are translations of prepositions to other languages predictive for this task? 
- how can we use multilingual corpora for learning a representation of the 

context that can be used for sense-disambiguation?

3. mlp-based model for preposition classification

(cid:1877)=argmax(cid:3037)(cid:1839)(cid:1838)(cid:1842)(cid:3046)(cid:3032)(cid:3041)(cid:3046)(cid:3032)((cid:2038)(cid:1871),(cid:1861))[(cid:1862)]

4. multilingual data

(cid:2038)((cid:1871),(cid:1861))     concatenation of 18 contextual features and the preposition   s embedding
preposition sense disambiguation

hila gonen and yoav goldberg
the features and the model:
yoav.goldberg@gmail.com

the features are similar to those 
2. full model  
used in previous works. features 
are extracted from:
    2-words-window
    head and modifier of the 

preposition

lstms are very capable learners

use them to build stuff

5. learning a context representation

encode the context as a concatenation of two lstms:
4. multilingual data

(cid:1855)(cid:1872)(cid:1876)(s,i)=(cid:1838)(cid:1845)(cid:1846)(cid:1839)(cid:3033)((cid:1875)(cid:2869):(cid:3036)(cid:2879)(cid:2869))   (cid:1838)(cid:1845)(cid:1846)(cid:1839)(cid:3029)((cid:1875)(cid:3041):(cid:3036)(cid:2878)(cid:2869))
(cid:1868)  =argmax(cid:3037)(cid:1839)(cid:1838)(cid:1842)(cid:3013)((cid:1855)(cid:1872)(cid:1876)(cid:1871),(cid:1861))[(cid:1862)]

parse-trees play a central role 

in many applications.

nice property of syntax     no need to understand

can recover structure without understanding the words

   the plumpets and goomps ghoked the kolp   

i there is something called a plumpet. more than 1.
i there is a similar thing called a goomp. more than 1.
i plumpets and goomps are together.
i there is an action called ghoking.
i . . .

automatic parsers get it right too

parsing is 

 id170

natural language parsing

previously

i structure is a sequence.
i each item can be tagged.
i we can mark some spans.

4 / 47

natural language parsing

previously

i structure is a sequence.
i each item can be tagged.
i we can mark some spans.

today

i hierarchical structure.

4 / 47

hierarchical structure?

5 / 47

structure
example 1: math

3*2+5*3

6 / 47

structure
example 1: math

add

3*2+5*3

mul

+

mul

3 * 2

5 * 3

6 / 47

structure
example 1: math

add

3*2+5*3

mul

+

mul

3 * 2

5 * 3

+

*

*

3 2

5 3

6 / 47

structure
example 2: language data

fruit    ies like a banana

7 / 47

structure
example 2: language data

fruit    ies like a banana

constituency structure

dependency structure

s

np

vp

adj

noun

fruit

flies

vb

like

np

det

noun

a

banana

like

   ies

banana

fruit

a

7 / 47

structure

constituency structure

i in this part we concentrate on constituency parsing:

many types of structures
constituency tree

mapping from sentences to trees with labeled nodes and
the sentence words at the leaves.

s

dt

the

np

jj

vp

nn

vbz

adjp

boring

stuff

is

rb

rb

jj

actually

quite

useful

8 / 47

why is parsing hard?
ambiguity

fat people eat candy

9 / 47

why is parsing hard?
ambiguity

fat people eat candy

s

np

vp

adj

nn

vb

fat

people

eat

np

nn

candy

9 / 47

why is parsing hard?
ambiguity

fat people eat candy

s

np

vp

adj

nn

vb

fat

people

eat

np

nn

candy

fat people eat accumulates

9 / 47

why is parsing hard?
ambiguity

fat people eat candy

s

np

vp

adj

nn

vb

fat

people

eat

np

nn

candy

fat people eat accumulates

s

np

adjp

vp

vb

nn

vb

accumulates

nn

fat

people

eat

9 / 47

why is parsing hard?
ambiguity

i i ate pizza with anchovies
i i ate pizza with friends

10 / 47

why is parsing hard?
real sentences are long. . .

   former beatle paul mccartney today was ordered to pay
nearly $50m to his estranged wife as their bitter divorce battle
came to an end .    

   welcome to our columbus hotels guide, where you   ll    nd
honest, concise hotel reviews, all discounts, a lowest rate
guarantee, and no booking fees.   

11 / 47

let   s learn how to parse

let   s learn how to parse . . . but    rst lets review some stuff from

automata and formal languages.

id18s

a id18 g = (n,    , r, s) where:

i n is a set of non-terminal symbols
i     is a set of terminal symbols
i r is a set of rules of the form x ! y1y2        yn
for n   0, x 2 n, yi 2 (n [    )
i s 2 n is a special start symbol

13 / 47

id18s

a simple grammar
n = {s, np, vp, adj, det, vb, noun}
    = {fruit,    ies, like, a, banana, tomato, angry}
s =   s   
r =

s ! np vp
np ! adj noun
np ! det noun
vp ! vb np
adj ! fruit
noun !    ies
vb ! like
det ! a
noun ! banana
noun ! tomato
adj ! angry

14 / 47

left-most derivations

left-most derivation is a sequence of strings s1,       , sn where
i s1 = s the start symbol
i sn 2       , meaning sn is only terminal symbols
i each si for i = 2       n is derived from si 1 by picking the

left-most non-terminal x in si 1 and replacing it by some  
where x !   is a rule in r.

15 / 47

left-most derivations

left-most derivation is a sequence of strings s1,       , sn where
i s1 = s the start symbol
i sn 2       , meaning sn is only terminal symbols
i each si for i = 2       n is derived from si 1 by picking the

left-most non-terminal x in si 1 and replacing it by some  
where x !   is a rule in r.
for example: [s],[np vp],[adj noun vp], [fruit noun vp], [fruit
   ies vp],[fruit    ies vb np],[fruit    ies like np], [fruit    ies like det
noun], [fruit    ies like a], [fruit    ies like a banana]

15 / 47

left-most derivation example

s

16 / 47

left-most derivation example

s
np vp

s ! np vp

16 / 47

left-most derivation example

s
np vp
adj noun vp

np ! adj noun

16 / 47

left-most derivation example

s
np vp
adj noun vp
fruit noun vp

adj ! fruit

16 / 47

left-most derivation example

s
np vp
adj noun vp
fruit noun vp
fruit    ies vp

noun !    ies

16 / 47

left-most derivation example

s
np vp
adj noun vp
fruit noun vp
fruit    ies vp
fruit    ies vb np

vp ! vb np

16 / 47

left-most derivation example

s
np vp
adj noun vp
fruit noun vp
fruit    ies vp
fruit    ies vb np
fruit    ies like np

vb ! like

16 / 47

left-most derivation example

s
np vp
adj noun vp
fruit noun vp
fruit    ies vp
fruit    ies vb np
fruit    ies like np
fruit    ies like det noun

np ! det noun

16 / 47

left-most derivation example

s
np vp
adj noun vp
fruit noun vp
fruit    ies vp
fruit    ies vb np
fruit    ies like np
fruit    ies like det noun
fruit    ies like a noun

det ! a

16 / 47

left-most derivation example

s
np vp
adj noun vp
fruit noun vp
fruit    ies vp
fruit    ies vb np
fruit    ies like np
fruit    ies like det noun
fruit    ies like a noun
fruit    ies like a banana

noun ! banana

16 / 47

left-most derivation example

s
np vp
adj noun vp
fruit noun vp
fruit    ies vp
fruit    ies vb np
fruit    ies like np
fruit    ies like det noun
fruit    ies like a noun
fruit    ies like a banana

i the resulting derivation can be written as a tree.

16 / 47

left-most derivation example

s
np vp
adj noun vp
fruit noun vp
fruit    ies vp
fruit    ies vb np
fruit    ies like np
fruit    ies like det noun
fruit    ies like a noun
fruit    ies like a banana

i the resulting derivation can be written as a tree.
i many trees can be generated.

16 / 47

id18s

a simple grammar
s ! np vp
np ! adj noun
np ! det noun
vp ! vb np
-
adj ! fruit
noun !    ies
vb ! like
det ! a
noun ! banana
noun ! tomato
adj ! angry
. . .

17 / 47

id18s

a simple grammar
s ! np vp
np ! adj noun
np ! det noun
vp ! vb np
-
adj ! fruit
noun !    ies
vb ! like
det ! a
noun ! banana
noun ! tomato
adj ! angry
. . .

example

s

np

vp

adj

noun

fruit

flies

vb

like

np

det

noun

a

banana

17 / 47

id18s

a simple grammar
s ! np vp
np ! adj noun
np ! det noun
vp ! vb np
-
adj ! fruit
noun !    ies
vb ! like
det ! a
noun ! banana
noun ! tomato
adj ! angry
. . .

example

s

np

vp

adj

noun

angry

flies

vb

like

np

det

noun

a

banana

17 / 47

id18s

a simple grammar
s ! np vp
np ! adj noun
np ! det noun
vp ! vb np
-
adj ! fruit
noun !    ies
vb ! like
det ! a
noun ! banana
noun ! tomato
adj ! angry
. . .

example

s

np

vp

adj

noun

angry

flies

vb

like

np

det

noun

a

tomato

17 / 47

id18s

a simple grammar
s ! np vp
np ! adj noun
np ! det noun
vp ! vb np
-
adj ! fruit
noun !    ies
vb ! like
det ! a
noun ! banana
noun ! tomato
adj ! angry
. . .

example

s

np

vp

adj

noun

vb

np

angry

banana

like

det

noun

a

tomato

17 / 47

id18s

a simple grammar
s ! np vp
np ! adj noun
np ! det noun
vp ! vb np
-
adj ! fruit
noun !    ies
vb ! like
det ! a
noun ! banana
noun ! tomato
adj ! angry
. . .

example

s

np

vp

det

noun

a

banana

vb

like

np

det

noun

a

tomato

17 / 47

id18s

a simple grammar
s ! np vp
np ! adj noun
np ! det noun
vp ! vb np
-
adj ! fruit
noun !    ies
vb ! like
det ! a
noun ! banana
noun ! tomato
adj ! angry
. . .

example

s

np

vp

det

noun

a

banana

vb

like

np

adj

noun

angry

banana

17 / 47

the parsing problem

given a string, recover the derivation.

18 / 47

parsing with (p)id18s

19 / 47

parsing with id18s

let   s assume. . .

i let   s assume natural language is generated by a id18.
i . . . and let   s assume we have the grammar.
i then parsing is easy: given a sentence,    nd the chain of

derivations starting from s that generates it.

20 / 47

parsing with id18s

let   s assume. . .

i let   s assume natural language is generated by a id18.
i . . . and let   s assume we have the grammar.
i then parsing is easy: given a sentence,    nd the chain of

derivations starting from s that generates it.

problem

i natural language is not generated by a id18.

i we can    nd anbncn structures, and many other arguments.

20 / 47

parsing with id18s

let   s assume. . .

i let   s assume natural language is generated by a id18.
i . . . and let   s assume we have the grammar.
i then parsing is easy: given a sentence,    nd the chain of

derivations starting from s that generates it.

problem

i natural language is not generated by a id18.

i we can    nd anbncn structures, and many other arguments.

solution

i we assume really hard that it is.

20 / 47

parsing with id18s

let   s assume. . .

i let   s assume natural language is generated by a id18.
i . . . and let   s assume we have the grammar.
i then parsing is easy: given a sentence,    nd the chain of

derivations starting from s that generates it.

problem

i we don   t have the grammar.

20 / 47

parsing with id18s

let   s assume. . .

i let   s assume natural language is generated by a id18.
i . . . and let   s assume we have the grammar.
i then parsing is easy: given a sentence,    nd the chain of

derivations starting from s that generates it.

problem

i we don   t have the grammar.

solution

i we   ll ask a genius linguist to write it!

20 / 47

parsing with id18s

let   s assume. . .

i let   s assume natural language is generated by a id18.
i . . . and let   s assume we have the grammar.
i then parsing is easy: given a sentence,    nd the chain of

derivations starting from s that generates it.

problem

i how do we    nd the chain of derivations?

20 / 47

parsing with id18s

let   s assume. . .

i let   s assume natural language is generated by a id18.
i . . . and let   s assume we have the grammar.
i then parsing is easy: given a sentence,    nd the chain of

derivations starting from s that generates it.

problem

i how do we    nd the chain of derivations?

solution

i with id145! (soon)

20 / 47

parsing with id18s

let   s assume. . .

i let   s assume natural language is generated by a id18.
i . . . and let   s assume we have the grammar.
i then parsing is easy: given a sentence,    nd the chain of

derivations starting from s that generates it.

problem

i real grammar: hundreds of possible derivations per

sentence.

20 / 47

parsing with id18s

let   s assume. . .

i let   s assume natural language is generated by a id18.
i . . . and let   s assume we have the grammar.
i then parsing is easy: given a sentence,    nd the chain of

derivations starting from s that generates it.

problem

i real grammar: hundreds of possible derivations per

sentence.

solution

i no problem! we   ll choose the best one. (sooner)

20 / 47

obtaining a grammar

let a genius linguist write it

i hard. many rules, many complex interactions.
i genius linguists don   t grow on trees !

21 / 47

obtaining a grammar

let a genius linguist write it

i hard. many rules, many complex interactions.
i genius linguists don   t grow on trees !

an easier way: ask a linguist to grow trees

i ask a linguist to annotate sentences with tree structure.
i (this need not be a genius   smart is enough.)
i then extract the rules from the annotated trees.

21 / 47

obtaining a grammar

let a genius linguist write it

i hard. many rules, many complex interactions.
i genius linguists don   t grow on trees !

an easier way: ask a linguist to grow trees

i ask a linguist to annotate sentences with tree structure.
i (this need not be a genius   smart is enough.)
i then extract the rules from the annotated trees.

treebanks

i english treebank: 40k sentences, manually annotated

with tree structure.

i other languages: often about 5k sentences.

21 / 47

treebank sentence example

( (s

(np-sbj

(np (nnp pierre) (nnp vinken) )
(, ,)
(adjp

(np (cd 61) (nns years) )
(jj old) )

(, ,) )

(vp (md will)

(vp (vb join)

(np (dt the) (nn board) )
(pp-clr (in as)

(np (dt a) (jj nonexecutive) (nn director) ))

(np-tmp (nnp nov.) (cd 29) )))

(. .) ))

22 / 47

supervised learning from a treebank

((fruit/adj    ies/nn) (like/vb
(a/det banana/nn)))
(time/nn (   ies/vb (like/in
(an/det (arrow/nn)))))

. . . . . . . . .
. . . . . . . . .

23 / 47

extracting id18 from trees

i the leafs of the trees de   ne    
i the internal nodes of the trees de   ne n
i add a special s symbol on top of all trees
i each node an its children is a rule in r

24 / 47

extracting id18 from trees

i the leafs of the trees de   ne    
i the internal nodes of the trees de   ne n
i add a special s symbol on top of all trees
i each node an its children is a rule in r

extracting rules

s

np

vp

adj

noun

fruit

flies

vb

like

np

det

noun

a

banana

24 / 47

extracting id18 from trees

i the leafs of the trees de   ne    
i the internal nodes of the trees de   ne n
i add a special s symbol on top of all trees
i each node an its children is a rule in r

extracting rules

s

np

vp

adj

noun

fruit

flies

vb

like

s ! np vp

np

det

noun

a

banana

24 / 47

extracting id18 from trees

i the leafs of the trees de   ne    
i the internal nodes of the trees de   ne n
i add a special s symbol on top of all trees
i each node an its children is a rule in r

extracting rules

s

np

vp

adj

noun

fruit

flies

vb

like

s ! np vp
np ! adj noun

np

det

noun

a

banana

24 / 47

extracting id18 from trees

i the leafs of the trees de   ne    
i the internal nodes of the trees de   ne n
i add a special s symbol on top of all trees
i each node an its children is a rule in r

extracting rules

s

np

vp

adj

noun

fruit

flies

vb

like

s ! np vp
np ! adj noun
adj ! fruit

np

det

noun

a

banana

24 / 47

from id18 to pid18

i english is not generated from id18 ) it   s generated by a

pid18!

25 / 47

from id18 to pid18

i english is not generated from id18 ) it   s generated by a
i pid18: probabilistic id18. just like a id18,

pid18!

but each rule has an associated id203.
i all probabilities for the same lhs sum to 1.

25 / 47

from id18 to pid18

i english is not generated from id18 ) it   s generated by a
i pid18: probabilistic id18. just like a id18,

pid18!

but each rule has an associated id203.
i all probabilities for the same lhs sum to 1.
i multiplying all the rule probs in a derivation gives the

id203 of the derivation.

i we want the tree with maximum id203.

25 / 47

from id18 to pid18

i english is not generated from id18 ) it   s generated by a
i pid18: probabilistic id18. just like a id18,

pid18!

but each rule has an associated id203.
i all probabilities for the same lhs sum to 1.
i multiplying all the rule probs in a derivation gives the

id203 of the derivation.

i we want the tree with maximum id203.

more formally

p(tree, sent) = yl!r2deriv(tree)

p(l ! r )

25 / 47

from id18 to pid18

i english is not generated from id18 ) it   s generated by a
i pid18: probabilistic id18. just like a id18,

pid18!

but each rule has an associated id203.
i all probabilities for the same lhs sum to 1.
i multiplying all the rule probs in a derivation gives the

id203 of the derivation.

i we want the tree with maximum id203.

more formally

p(tree, sent) = yl!r2deriv(tree)

p(l ! r )

tree = arg max

tree2trees(sent)

p(tree|sent) = arg max

tree2trees(sent)

p(tree, sent)

25 / 47

just structure prediction, really

score(tree) =

yl!r2deriv(tree)
score(tree) = xl!r2deriv(tree)
score(tree) = xl!r2deriv(tree)

decompose

p(l ! r)

log p(l ! r)

score(l ! r)

represent and   
score parts

pid18 example

a simple pid18
1.0 s ! np vp
0.3 np ! adj noun
0.7 np ! det noun
1.0 vp ! vb np
-
0.2 adj ! fruit
0.2 noun !    ies
1.0 vb ! like
1.0 det ! a
0.4 noun ! banana
0.4 noun ! tomato
0.8 adj ! angry

example

s

np

vp

adj

noun

fruit

flies

vb

like

np

det

noun

a

banana

1   0.3   0.2   0.7   1.0   0.2   1   1   0.4 =
0.0033

26 / 47

pid18 example

a simple pid18
1.0 s ! np vp
0.3 np ! adj noun
0.7 np ! det noun
1.0 vp ! vb np
-
0.2 adj ! fruit
0.2 noun !    ies
1.0 vb ! like
1.0 det ! a
0.4 noun ! banana
0.4 noun ! tomato
0.8 adj ! angry

example

s

np

vp

adj

noun

fruit

flies

vb

like

np

det

noun

a

banana

1   0.3   0.2   0.7   1.0   0.2   1   1   0.4 =
0.0033

26 / 47

pid18 example

a simple pid18
1.0 s ! np vp
0.3 np ! adj noun
0.7 np ! det noun
1.0 vp ! vb np
-
0.2 adj ! fruit
0.2 noun !    ies
1.0 vb ! like
1.0 det ! a
0.4 noun ! banana
0.4 noun ! tomato
0.8 adj ! angry

example

s

np

vp

adj

noun

fruit

flies

vb

like

np

det

noun

a

banana

1   0.3   0.2   0.7   1.0   0.2   1   1   0.4 =
0.0033

26 / 47

pid18 example

a simple pid18
1.0 s ! np vp
0.3 np ! adj noun
0.7 np ! det noun
1.0 vp ! vb np
-
0.2 adj ! fruit
0.2 noun !    ies
1.0 vb ! like
1.0 det ! a
0.4 noun ! banana
0.4 noun ! tomato
0.8 adj ! angry

example

s

np

vp

adj

noun

fruit

flies

vb

like

np

det

noun

a

banana

1   0.3   0.2   0.7   1.0   0.2   1   1   0.4 =
0.0033

26 / 47

parsing with pid18

i parsing with a pid18 is    nding the most probable

derivation for a given sentence.

i this can be done quite ef   ciently with dynamic

programming (the cky algorithm)

27 / 47

parsing with pid18

i parsing with a pid18 is    nding the most probable

derivation for a given sentence.

i this can be done quite ef   ciently with dynamic

programming (the cky algorithm)

obtaining the probabilities

i we estimate them from the treebank.
i p(lhs ! rhs) = count(lhs!rhs)
count(lhs!   )
i we can also add id188, as before.
i dealing with unknown words - like in the id48

27 / 47

the cky algorithm

28 / 47

the problem

input

i sentence (a list of words)

i n     sentence length

i id18 grammar (with weights on rules)
i g     number of non-terminal symbols

output

i a parse tree / the best parse tree

but. . .

i exponentially many possible parse trees!

solution

i id145!

29 / 47

cky

cocke kasami younger

30 / 47

cky

cocke kasami younger
196?

30 / 47

cky

cocke kasami younger
196?

1965

30 / 47

cky

cocke kasami younger
196?

1965

1967

30 / 47

3 interesting problems

i recognition

i parsing

i disambiguation

31 / 47

3 interesting problems

i recognition

i can this string be generated by the grammar?

i parsing

i disambiguation

31 / 47

3 interesting problems

i recognition

i can this string be generated by the grammar?

i parsing

i show me a possible derivation. . .

i disambiguation

31 / 47

3 interesting problems

i recognition

i can this string be generated by the grammar?

i parsing

i show me a possible derivation. . .

i disambiguation

i show me the best derivation

31 / 47

3 interesting problems

i recognition

i can this string be generated by the grammar?

i parsing

i show me a possible derivation. . .

i disambiguation

i show me the best derivation

cky can do all of these in polynomial time

31 / 47

3 interesting problems

i recognition

i can this string be generated by the grammar?

i parsing

i show me a possible derivation. . .

i disambiguation

i show me the best derivation

cky can do all of these in polynomial time

i for any cnf grammar

31 / 47

cnf
chomsky normal form

de   nition
a id18 is in cnf form if it only has rules like:
i a ! b c
i a !    
a,b,c are non terminal symbols
    is a terminal symbol (a word. . . )

i all terminal symbols are rhs of unary rules
i all non terminal symbols are rhs of binary rules

cky can be easily extended to handle also unary rules: a ! b

32 / 47

binarization

fact

i any id18 grammar can be converted to cnf form

33 / 47

binarization

fact

i any id18 grammar can be converted to cnf form

spe   cifally for natural language grammars
i we already have a !    

33 / 47

binarization

fact

i any id18 grammar can be converted to cnf form

spe   cifally for natural language grammars
i we already have a !    

i (a !       is also easy to handle)

33 / 47

binarization

fact

i any id18 grammar can be converted to cnf form

spe   cifally for natural language grammars
i we already have a !    
i unary rules (a ! b) are ok

i (a !       is also easy to handle)

33 / 47

binarization

fact

i any id18 grammar can be converted to cnf form

spe   cifally for natural language grammars
i we already have a !    
i unary rules (a ! b) are ok
i only problem:s ! np pp vp pp

i (a !       is also easy to handle)

33 / 47

binarization

fact

i any id18 grammar can be converted to cnf form

i (a !       is also easy to handle)

spe   cifally for natural language grammars
i we already have a !    
i unary rules (a ! b) are ok
i only problem:s ! np pp vp pp
binarization
! np np_pp-vp-pp
s
np_pp-vp-pp ! pp np-pp_vp-pp
np_pp-vp-pp ! vp np-pp-vp_pp

33 / 47

finally, cky

recognition

i main idea:

i build parse tree from bottom up
i combine built trees to form bigger trees using grammar

rules

i when left with a single tree, verify root is s

i exponentially many possible trees. . .

i search over all of them in polynomial time using dp
i shared structure     smaller trees

34 / 47

main idea

if we know:

i wi . . . wj is an np
i wj+1 . . . wk is a vp
and grammar has rule:
i s ! np vp
then we know:

i s can derive wi . . . wk

35 / 47

main idea

if we know:

i wi . . . wj is an np
i wj+1 . . . wk is a vp
and grammar has rule:
i s ! np vp
then we know:

i s can derive wi . . . wk

np

vp

...

wi wj wj+1

...

wk

35 / 47

main idea

if we know:

i wi . . . wj is an np
i wj+1 . . . wk is a vp
and grammar has rule:
i s ! np vp
then we know:

i s can derive wi . . . wk

s

np

vp

...

wi wj wj+1

...

wk

35 / 47

main idea

if we know:

i wi . . . wj is an np
i wj+1 . . . wk is a vp
and grammar has rule:
i s ! np vp
then we know:

i s can derive wi . . . wk

s

...

wk

wi

35 / 47

s

np

np

+

vp
vp

...

wi wj

wj+1

...

wk

wi

s

...

wk

data structure

(half a) two dimensional array (n x n)

36 / 47

data structure

on its side

37 / 47

data structure

each cell: all nonterminals than can derive word i to word j

sue

saw

her

girl

with

a

telescope

37 / 47

data structure

each cell: all nonterminals than can derive word i to word j
imagine each cell as a g dimensional array

sue

saw

her

girl

with

a

telescope

37 / 47

data structure

each cell: all nonterminals than can derive word i to word j
imagine each cell as a g dimensional array

s
np
vp
pp
adjp

s
np
vp
pp
adjp

sue

saw

her

girl

with

a

telescope

x 
x 
v 
x 
x

v 
v 
v 
x 
x

37 / 47

filling the table

sue

saw

her

girl

with

a

telescope

38 / 47

filling the table

sue

saw

her

girl

with

a

telescope

38 / 47

filling the table

sue

saw

her

girl

with

a

telescope

38 / 47

filling the table

s
noun
verb
pp
adjp

x 
v 
v 
x 
x

sue

saw

her

girl

with

a

telescope

38 / 47

filling the table

sue

saw

her

girl

with

a

telescope

38 / 47

filling the table

sue

saw

her

girl

with

a

telescope

38 / 47

filling the table

sue

saw

her

girl

with

a

telescope

38 / 47

filling the table

sue

saw

her

girl

with

a

telescope

38 / 47

filling the table

sue

saw

her

girl

with

a

telescope

38 / 47

filling the table

sue

saw

her

girl

with

a

telescope

38 / 47

filling the table

sue

saw

her

girl

with

a

telescope

38 / 47

filling the table

sue

saw

her

girl

with

a

telescope

38 / 47

filling the table

sue

saw

her

girl

with

a

telescope

38 / 47

filling the table

sue

saw

her

girl

with

a

telescope

38 / 47

filling the table

sue

saw

her

girl

with

a

telescope

38 / 47

filling the table

sue

saw

her

girl

with

a

telescope

38 / 47

filling the table

sue

saw

her

girl

with

a

telescope

38 / 47

handling unary rules?

sue

saw

her

girl

with

a

telescope

39 / 47

which order?

sue

saw

her

boy

with

a

telescope

40 / 47

which order?

when handling a cell, 
we need its potential 
parts to be complete.

sue

saw

her

boy

with

a

telescope

40 / 47

which order?

sue

saw

her

boy

with

a

telescope

40 / 47

which order?

sue

saw

her

boy

with

a

telescope

40 / 47

which order?

sue

saw

her

boy

with

a

telescope

40 / 47

which order?

sue

saw

her

boy

with

a

telescope

40 / 47

which order?

sue

saw

her

boy

with

a

telescope

40 / 47

which order?

sue

saw

her

boy

with

a

telescope

40 / 47

which order?

sue

saw

her

boy

with

a

telescope

40 / 47

which order?

sue

saw

her

boy

with

a

telescope

40 / 47

which order?

sue

saw

her

boy

with

a

telescope

40 / 47

which order?

"left corner parsing"

sue

saw

her

boy

with

a

telescope

40 / 47

complexity?

41 / 47

complexity?

i n2g cells to    ll

41 / 47

complexity?

i n2g cells to    ll
i g2n ways to    ll each one

41 / 47

complexity?

i n2g cells to    ll
i g2n ways to    ll each one

o(g3n3)

41 / 47

finding a parse

parsing     we want to actually    nd a parse tree

easy: also keep a possible split point for each nt

43 / 47

pid18 parsing and disambiguation

disambiguation     we want the best parse tree

easy: for each nt, keep best split point, and score.

44 / 47

pid18 parsing recap

    extract grammar + probabilities from treebank. 

    given a sentence, use cky to recover to highest 

scoring tree.

doesn't really work

    it recovers the best tree according to the grammar. 

    but these best trees are quite bad. 

    ~73 f1 score.

some limitations of pid18s

    not sensitive to words. 

    not sensitive to structural frequencies.

(a)

s

np

nns

workers

vp

vp

pp

vbd

np

in

np

dumped

nns

into

dt

sacks

a

nn

bin

(b)

s

np

nns

workers

vbd

dumped

vp

np

nns

sacks

np

pp

in

np

into

dt

a

nn

bin

(b)

s

sacks

a

bin

np

nns

workers

vbd

dumped

vp

np

nns

sacks

np

pp

in

np

into

dt

a

nn

bin

(example from mike collins)

(a)

s

np

nns

workers

vp

vp

pp

vbd

np

in

np

dumped

nns

into

dt

sacks

a

nn

bin

(b)

s

sacks

a

bin

np

nns

workers

vbd

dumped

vp

np

nns

sacks

np

pp

in

np

into

dt

a

nn

bin

(b)

s

np

nns

workers

vbd

dumped

(a)

vp

rules
s ! np vp
np ! nns
vp ! vp pp
vp ! vbd np
np ! nns
np
pp ! in np
np ! dt nn
nns ! workers
np
vbd ! dumped
nns ! sacks
nns
in
in ! into
dt ! a
nn ! bin

into

sacks

(a)

pp

rules
s ! np vp
np ! nns
vp ! vp pp
vp ! vbd np
np ! nns
pp ! in np
np ! dt nn
nns ! workers
vbd ! dumped
nns ! sacks
np
in ! into
dt ! a
nn
nn ! bin

rules
s ! np vp
np ! nns
np ! np pp
vp ! vbd np
np ! nns
pp ! in np
np ! dt nn
nns ! workers
vbd ! dumped
nns ! sacks
in ! into
dt ! a
nn ! bin

(b)

dt

a

bin

(b)

rules
s ! np vp
np ! nns
np ! np pp
vp ! vbd np
np ! nns
pp ! in np
np ! dt nn
nns ! workers
vbd ! dumped
nns ! sacks
in ! into
dt ! a
nn ! bin
(example from mike collins)

if q(np ! np pp) > q(vp ! vp pp) then (b) is more
if q(np ! np pp) > q(vp ! vp pp) then (b) is more
probable, else (a) is more probable.
probable, else (a) is more probable.
attachment decision is completely independent of the
attachment decision is completely independent of the

(a)

s

np

nns

workers

vp

vp

pp

vbd

np

in

np

dumped

nns

into

dt

sacks

a

nn

bin

(b)

s

sacks

a

bin

np

nns

workers

vbd

dumped

vp

np

nns

sacks

np

pp

in

np

into

dt

a

nn

bin

(b)

s

np

nns

workers

vbd

dumped

(a)

vp

rules
s ! np vp
np ! nns
vp ! vp pp
vp ! vbd np
np ! nns
np
pp ! in np
np ! dt nn
nns ! workers
np
vbd ! dumped
nns ! sacks
nns
in
in ! into
dt ! a
nn ! bin

into

sacks

rules
rules
s ! np vp
s ! np vp
np ! nns
np ! nns
vp ! vp pp
np ! np pp
only difference
vp ! vbd np
vp ! vbd np
np ! nns
np ! nns
pp ! in np
pp ! in np
(b)
np ! dt nn
np ! dt nn
attachment decision
nns ! workers
nns ! workers
independent of words!
vbd ! dumped
vbd ! dumped
nns ! sacks
nns ! sacks
np
in ! into
in ! into
dt ! a
dt ! a
nn
nn ! bin
nn ! bin

dt

(b)

(a)

pp

a

bin

rules
s ! np vp
np ! nns
np ! np pp
vp ! vbd np
np ! nns
pp ! in np
np ! dt nn
nns ! workers
vbd ! dumped
nns ! sacks
in ! into
dt ! a
nn ! bin
(example from mike collins)

if q(np ! np pp) > q(vp ! vp pp) then (b) is more
if q(np ! np pp) > q(vp ! vp pp) then (b) is more
probable, else (a) is more probable.
probable, else (a) is more probable.
attachment decision is completely independent of the
attachment decision is completely independent of the

np

cc

and

(a)

(b)

np

np

nns

dogs

pp

in

in

np

nns

houses

np

(b)

houses

np

np

nns

dogs

in

in

np

nns

cats

pp

np

nns

houses

np

cc

and

np

nns

cats

np

nns

dogs

in

in

pp

np

nns

houses

np

cc

and

np

nns

cats

(example from mike collins)

(b)

houses

np

np

nns

dogs

in

in

np

nns

cats

np

cc

and

(a)

(b)

np

np

nns

dogs

pp

in

in

np

nns

houses

np

pp

np

(a)

rules
np ! np cc np
np
np ! np pp
nns
np ! nns
in
pp ! in np
dogs
np ! nns
in
np ! nns
nns ! dogs
in ! in
nns ! houses
cc ! and
nns ! cats

rules
np ! np cc np
np ! np pp
np ! nns
pp ! in np
np ! nns
np ! nns
nns ! dogs
in ! in
nns ! houses
cc ! and
nns ! cats
here the two parses have identical rules, and
therefore have identical id203 under any
assignment of pid18 rule probabilities

houses

nns

nns

(b)

cats

and

np

np

cc

pp

np

nns

houses

np

cc

and

np

nns

cats

(a)

rules
np ! np cc np
np ! np pp
np ! nns
pp ! in np
np ! nns
np ! nns
nns ! dogs
in ! in
nns ! houses
cc ! and
nns ! cats

(b)

here the two parses have identical rules, and
therefore have identical id203 under any
assignment of pid18 rule probabilities

(example from mike collins)

(b)

houses

np

np

nns

dogs

in

in

np

nns

cats

np

cc

and

(a)

(b)

np

np

nns

dogs

pp

in

in

np

nns

houses

np

np

identical set of rules.
(b)

same score under any assignment
(a)

of pid18 rule probabilities.

pp

(a)

rules
np ! np cc np
np
np ! np pp
nns
np ! nns
in
pp ! in np
dogs
np ! nns
in
np ! nns
nns ! dogs
in ! in
nns ! houses
cc ! and
nns ! cats

rules
np ! np cc np
np ! np pp
np ! nns
pp ! in np
np ! nns
np ! nns
nns ! dogs
in ! in
nns ! houses
cc ! and
nns ! cats
here the two parses have identical rules, and
therefore have identical id203 under any
assignment of pid18 rule probabilities

houses

nns

nns

cats

and

np

np

cc

pp

np

nns

houses

np

cc

and

np

nns

cats

rules
np ! np cc np
np ! np pp
np ! nns
pp ! in np
np ! nns
np ! nns
nns ! dogs
in ! in
nns ! houses
cc ! and
nns ! cats

(b)

here the two parses have identical rules, and
therefore have identical id203 under any
assignment of pid18 rule probabilities

(example from mike collins)

structural preferences: close attachment

(a)

np

(b)

np

np

nn

pp

in

np

np

nn

pp

in

np

nn

np

nn

np

pp

pp

in

in

np

nn

np

nn

i example: president of a company in africa

i both parses have the same rules, therefore receive same

id203 under a pid18

i    close attachment    (structure (a)) is twice as likely in wall

street journal text.

(slide from mike collins)

lexicalized pid18s

pid18 problem 1
lack of sensitivity to lexical information (words)
solution

i make pid18 aware of words (lexicalized pid18)
i main idea: head words

14 / 1

head words

each constituent has one words which captures its    essence   .

15 / 1

head words

each constituent has one words which captures its    essence   .

i (s john saw the young boy with the large hat)

15 / 1

head words

each constituent has one words which captures its    essence   .

i (s john saw the young boy with the large hat)

15 / 1

head words

each constituent has one words which captures its    essence   .

i (s john saw the young boy with the large hat)
i (vp saw the young boy with the large hat)

15 / 1

head words

each constituent has one words which captures its    essence   .

i (s john saw the young boy with the large hat)
i (vp saw the young boy with the large hat)

15 / 1

head words

each constituent has one words which captures its    essence   .

i (s john saw the young boy with the large hat)
i (vp saw the young boy with the large hat)
i (np the young boy with the large hat)

15 / 1

head words

each constituent has one words which captures its    essence   .

i (s john saw the young boy with the large hat)
i (vp saw the young boy with the large hat)
i (np the young boy with the large hat)

15 / 1

head words

each constituent has one words which captures its    essence   .

i (s john saw the young boy with the large hat)
i (vp saw the young boy with the large hat)
i (np the young boy with the large hat)
i (np the large hat)

15 / 1

head words

each constituent has one words which captures its    essence   .

i (s john saw the young boy with the large hat)
i (vp saw the young boy with the large hat)
i (np the young boy with the large hat)
i (np the large hat)

15 / 1

head words

each constituent has one words which captures its    essence   .

i (s john saw the young boy with the large hat)
i (vp saw the young boy with the large hat)
i (np the young boy with the large hat)
i (np the large hat)
i (pp with the large hat)

15 / 1

head words

each constituent has one words which captures its    essence   .

i (s john saw the young boy with the large hat)
i (vp saw the young boy with the large hat)
i (np the young boy with the large hat)
i (np the large hat)
i (pp with the large hat)

15 / 1

head words

each constituent has one words which captures its    essence   .

i (s john saw the young boy with the large hat)
i (vp saw the young boy with the large hat)
i (np the young boy with the large hat)
i (np the large hat)
i (pp with the large hat)

15 / 1

head words

each constituent has one words which captures its    essence   .

i (s john saw the young boy with the large hat)
i (vp saw the young boy with the large hat)
i (np the young boy with the large hat)
i (np the large hat)
i (pp with the large hat)

i hat is the    semantic head   
i with is the    functional head   
i (it is common to choose the functional head)

15 / 1

more about heads

i each context-free rule has one    special    child that is the

head of the rule. e.g.,
s ) np vp
vp ) vt np
np ) dt nn nn

i a core idea in syntax

(vp is the head)
(vt is the head)
(nn is the head)

(e.g., see x-bar theory, head-driven phrase structure
grammar)

i some intuitions:

i the central sub-constituent of each rule.
i the semantic predicate in each rule.

(slide from mike collins)

adding headwords to trees

s

np

vp

dt

the

nn

lawyer

vt

np

questioned

dt

the

nn

witness

+

s(questioned)

np(lawyer)

vp(questioned)

dt(the)

nn(lawyer)

the

lawyer

vt(questioned)

np(witness)

questioned

dt(the)

nn(witness)

the

witness

(slide from mike collins)

adding headwords to trees (continued)

s(questioned)

np(lawyer)

vp(questioned)

dt(the)

nn(lawyer)

the

lawyer

vt(questioned)

np(witness)

questioned

dt(the)

nn(witness)

the

witness

i a constituent receives its headword from its head child.

s ) np vp
vp ) vt
np
np ) dt

nn

(s receives headword from vp)
(vp receives headword from vt)
(np receives headword from nn)

(slide from mike collins)

s(questioned)

np(lawyer)

vp(questioned)

dt(the)

nn(lawyer)

the

lawyer

vt(questioned)

np(witness)

questioned

dt(the)

nn(witness)

the

witness

(slide from mike collins)

20 / 1

chomsky normal form

a id18 g = (n,    , r, s) in chomsky normal
form is as follows

i n is a set of non-terminal symbols
i     is a set of terminal symbols
i r is a set of rules which take one of two forms:

i x ! y1y2 for x 2 n , and y1, y2 2 n
i x ! y for x 2 n , and y 2    

i s 2 n is a distinguished start symbol

we can    nd the highest scoring parse under a pid18 in
this form, in o(n3|n|3) time where n is the length of the
string being parsed.

(slide from mike collins)

lexicalized context-free grammars in chomsky
normal form

i n is a set of non-terminal symbols

i     is a set of terminal symbols

i r is a set of rules which take one of three forms:

i x(h) !1 y1(h) y2(w) for x 2 n, and y1, y2 2 n, and
i x(h) !2 y1(w) y2(h) for x 2 n, and y1, y2 2 n, and
i x(h) ! h for x 2 n, and h 2    

h, w 2    
h, w 2    

i s 2 n is a distinguished start symbol

(slide from mike collins)

an example

!2 np(man) vp(saw)
np(dog)
nn(man)
nn(dog)

s(saw)
vp(saw) !1 vt(saw)
np(man) !2 dt(the)
np(dog) !2 dt(the)
vt(saw) ! saw
dt(the) ! the
nn(man) ! man
nn(dog) ! dog

(slide from mike collins)

parsing with lexicalized id18s

i the new form of grammar looks just like a chomsky normal
form id18, but with potentially o(|   |2     |n|3) possible rules.

i naively, parsing an n word sentence using the dynamic

programming algorithm will take o(n3|   |2|n|3) time. but
|   | can be huge!!

i crucial observation: at most o(n2     |n|3) rules can be
applicable to a given sentence w1, w2, . . . wn of length n.
this is because any rules which contain a lexical item that is
not one of w1 . . . wn, can be safely discarded.

i the result: we can parse in o(n5|n|3) time.

(slide from mike collins)

accurate unlexicalized parsing

21 / 1

accurate unlexicalized parsing

pid18 problem 2
lack of sensitivity to structural information

22 / 1

accurate unlexicalized parsing

pid18 problem 2
lack of sensitivity to structural information
solution

i this problem is also solved by lexicalization.

i (maybe that   s the main problem that   s being solved by

lexicalization)

22 / 1

accurate unlexicalized parsing

pid18 problem 2
lack of sensitivity to structural information
solution

i this problem is also solved by lexicalization.

i (maybe that   s the main problem that   s being solved by

lexicalization)

i but can we do without lexicalizing the grammar?

22 / 1

(slide from chris manning)

  5. accurate unlexicalized parsing: pid18s and independence   the symbols in a pid18 define independence assumptions:   at any node, the material inside that node is independent of the material outside that node, given the label of that node.   any information that statistically connects behavior inside and outside a node must flow through that node.npsvps    np vpnp    dt nnnp(slide from chris manning)

  michael collins (2003, colt)(slide from chris manning)

  non-independence i   independence assumptions are often too strong.   example: the expansion of an np is highly dependent on the parent of the np (i.e., subjects vs. objects).11%9%6%np ppdt nnprp9%9%21%np ppdt nnprp7%4%23%np ppdt nnprpall npsnps under snps under vp(slide from chris manning)

  breaking up the symbols   we can relax independence assumptions by encoding dependencies into the pid18 symbols:   what are the most useful features to encode?parent annotation[johnson 98]marking possesive nps(slide from chris manning)

  a fully annotated tree(slide from chris manning)

  final test set results   beats    first generation    lexicalized parsers.parserlplrf1cb0 cbmagerman 9584.984.684.71.2656.6collins 9686.385.886.01.1459.9klein & m 0386.985.786.31.1060.3charniak 9787.487.587.41.0062.1collins 9988.788.688.60.9067.1automatic annotation 

latent variable grammars

(latent variable grammars) 

[matsuzaki et al.    05, petrov et al.    06]

...

parse tree  
sentence

derivations

parameters 

(slide from slav petrov)

constituency parsing

    decompose tree into parts (grammar rules) 

    assign score to each rule 

    find best scoring tree using cky 

    maybe do some tricks for better scoring of rules

id33

dependency representation

16 / 1

head words

each constituent has one words which captures its    essence   .

i (s john saw the young boy with the large hat)
i (vp saw the young boy with the large hat)
i (np the young boy with the large hat)
i (np the large hat)
i (pp with the large hat)

i hat is the    semantic head   
i with is the    functional head   
i (it is common to choose the functional head)

15 / 1

adding headwords to trees

s

np

vp

dt

the

nn

lawyer

vt

np

questioned

dt

the

nn

witness

+

s(questioned)

np(lawyer)

vp(questioned)

dt(the)

nn(lawyer)

the

lawyer

vt(questioned)

np(witness)

questioned

dt(the)

nn(witness)

the

witness

dependency representation

if we take the head-annotated trees and    forget    about the
constituents, we get a representation called    dependency
structure   .

dependency structure capture the relation between words in a
sentence.

17 / 1

dependency representation

s(questioned)

np(lawyer)

vp(questioned)

dt(the)

nn(lawyer)

the

lawyer

vt(questioned)

np(witness)

questioned

dt(the)

nn(witness)

the

witness

18 / 1

dependency representation

questioned

lawyer

questioned

the

lawyer

the

lawyer

questioned

witness

questioned

the

witness

the

witness

18 / 1

dependency representation

questioned

lawyer

questioned

the

lawyer

the

lawyer

questioned

witness

questioned

the

witness

the

witness

18 / 1

dependency representation

questioned

lawyer

witness

the

the

18 / 1

dependency representation

questioned

lawyer

witness

the

the

18 / 1

dependency representation

18 / 1

dependency representation

18 / 1

dependency representation
projectivity

projective tree (no crossing arcs):

(non-)projectivity

    crossing arcs needed to account for non-

projective constructions 

    fairly rare in english but can be common 

non-projective tree (crossing arcs):

in other languages (e.g. czech): 

18 / 1

dependency representations

there are many different dependency representations

i different choice of heads.
i different set of labels.
i each language usually has its own treebank, with own

choices

8 / 1

universal dependencies

i a multi-national project aiming at producing a consistent
set of dependency annotations in many (all!) languages.

9 / 1

universal dependencies

i a multi-national project aiming at producing a consistent
set of dependency annotations in many (all!) languages.

i abstract over linguistic differences.
i same set of parts-of-speech and morphology features.
i same dependency relations.
i same choice of heads.

9 / 1

three main approaches to id33

conversion

i parse to constituency structure.
i extract dependencies from the trees.

global optimization (graph based)

i de   ne a scoring function over <sentence,tree> pairs.
i search for best-scoring structure.
i simpler scoring ) easier search.
i (similar to how we do tagging, constituency parsing.)

greedy decoding (transition based)

i start with an unparsed sentence.
i apply locally-optimal actions until sentence is parsed.

23 / 1

graph-based parsing

the parsing problem

parse(x) = arg max
y2y(x)

score(y, x)

search over all possible parses  

and    nd the one with the highest score

the parsing problem

parse(x) = arg max
y2y(x)

score(y, x)

search over all possible parses  

and    nd the one with the highest score

training objective
score(y, x) > score(y0, x) 8y 6= y0

the parsing problem

parse(x) = arg max
y2y(x)

score(y, x)

search over all possible parses  

and    nd the one with the highest score

challenge: very hard search problem

the parsing problem

parse(x) = arg max
y2y(x)

score(y, x)

search over all possible parses  

and    nd the one with the highest score

challenge: very hard search problem
solution: decompose score:

score(y, x) =xp2y

score(p)

id170 recipe

predict(x) = arg max

y2y(x)xp2y

score( (p))

    decompose structure to local factors. 

    assign a score to each factor. 

    structure score = sum of local scores. 

    look for highest scoring structure.

id170 recipe

predict(x) = arg max

y2y(x)xp2y

score( (p))

decompose

represent

search

score

first-order parser ("mst")

    goal: predict a parse tree. 
    parts: <head, modi   er> pairs (arcs).

the/d

fox/n

who/p

likes/v apples/n jumped/v over/p

a/d

dog/n

parse(x) = arg max

y2y(x) x(h,m)2y

score( (h, m, x))

id170 recipe

predict(x) = arg max

y2y(x)xp2y

score( (p))

decompose

represent

search

score

decomposing

score(                                                                                  )  =                                                               

likes/v apples/n jumped/v over/p

the/d

fox/n

dog/n

who/p

a/d

=score(fox, the) 
   +score(fox, who) 
   +score(who, likes) 
   +score(likes, apples) 
   +score(jumped, fox) 
   +score(jumped, over) 
   +score(over, dog) 
   +score(dog, a)

graph-based parsing (id136)

input sentence:    they ate pizza   

root

)
y
e
h
t

!

t
o
o
r
(
e
r
o
c
s

they

score(ro

ot
!ate)

score(root!pizza)

s c ore ( ate

! t h e y )
s core(th ey

ate

! ate)

score(ate

score(pizza

!pizza)

!ate)

score(pizza!they )

score(they!pizza)

pizza

score each possible arc (n2)

eliyahu kiperwasser (bar-ilan university)

simple and accurate id33

logo-biu.png

6 / 42

graph-based parsing (id136)

root

)
y
e
h
t

!

t
o
o
r
(
e
r
o
c
s

they

score(ro

ot
!ate)

score(root!pizza)

s c ore ( ate

! t h e y )
s core(th ey

ate

! ate)

score(ate

score(pizza

!pizza)

!ate)

score(pizza!they )

score(they!pizza)

pizza

spanning tree with maximal score

eliyahu kiperwasser (bar-ilan university)

simple and accurate id33

logo-biu.png

7 / 42

id170 recipe

predict(x) = arg max

y2y(x)xp2y

score( (p))

decompose

represent

search

score

finding the best tree

    projective parsing:  

    the eisner algorithm (id145) 

    non-projective parsing: 

    directed spanning tree    

                                  (chu liu edmunds, tarjan)

eisner parsing algorithm

eisner parsing algorithm

    finding the best projective tree. 
    we can use the lexicalized version of cky 

    ... but this will give use n5 algorithm. 

    jason eisner (and giorgio satta) reduced this to n3 

using a more specialized algorithm. 

    main idea: decouple scoring of left and right 

modi   ers.

id33 algorithm - first-order model

 

+

m

h

r

r + 1

m

 

+

e

h

m

m

e

h

h

(slide from alexander rush)

base case

*

as

mcgwire

neared

,

fans

went

wild

(slide from alexander rush)

parsing

*

as

mcgwire

neared

,

fans

went

wild

(slide from alexander rush)

parsing

*

as

mcgwire

neared

,

fans

went

wild

(slide from alexander rush)

parsing

*

as

mcgwire

neared

,

fans

went

wild

(slide from alexander rush)

parsing

*

as

mcgwire

neared

,

fans

went

wild

(slide from alexander rush)

parsing

*

as

mcgwire

neared

,

fans

went

wild

(slide from alexander rush)

parsing

*

as

mcgwire

neared

,

fans

went

wild

(slide from alexander rush)

parsing

*

as

mcgwire

neared

,

fans

went

wild

(slide from alexander rush)

parsing

*

as

mcgwire

neared

,

fans

went

wild

(slide from alexander rush)

eisner's algorithm

    start with two triangles for each word. 
    combine two small triangles into a larger trapezoid,    

and add arc between the words. 

    combine trapezoid and triangle into larger triangle. 

    need an order that computes all smaller parts 

before larger ones.

algorithm key

i l; left-facing item

i r; right-facing item

i c; completed item (triangle)

i i; incomplete item (trapezoid)

algorithm

initialize:
for i in 0 . . . n do
   [c, l, i, i] = 0
   [c, r, i, i] = 0
   [i, l, i, i] = 0
   [i, r, i, i] = 0

inner loop:
for k in 1 . . . n do

for s in 0 . . . n do

t   k + s
if t   n then break
   [i, l, s, t] = maxr2s...t 1    [c, r, s, r ] +    [c, l, r + 1, t]
   [i, r, s, t] = maxr2s...t 1    [c, r, s, r ] +    [c , l, r + 1, t]
   [c, l, s, t] = maxr2s...t 1    [c, l, s, r ] +    [i, l, r , t]
   [c, r, s, t] = maxr2s+1...t    [i, r, s, r ] +    [c, r, r , t]

return    [c, r, 0, n]

id170 recipe

predict(x) = arg max

y2y(x)xp2y

score( (p))

decompose

represent

search

score

representing

predict(x) = arg max
predict(x) = arg max

y2y(x)xp2y
y2y(x)xp2y

score( (p))
score( (p))

    feature function extracts useful signals from parts.  

    most work traditionally goes into this component.

linear features

arc feature ideas for f(i,j,k)

 (saw, with)

    identities of the words wi and wj and the label lk 
    part-of-speech tags of the words wi and wj and the label lk 
    part-of-speech of words surrounding and between wi and wj 
    number of words between wi and wj , and their orientation 
    combinations of the above

*

as

mcgwire

mcgwire

neared

neared

linear features

went

fans

wild

went

fans

wild

,

,

a

m

n

e

,

f

a

w

w

s

e

i

l

n

d

t

c

a

g

r

e

d

w

i

r

e

n

s

[went]

 (saw, with)

[verb]

[went, as]

[vbd]

[as]

[vbd, adp]

[verb, in]

[adj, *, adp]

[nns, vbd, adp]

[nns, adp, nnp]

[adp, left, 5]

[jj, *, in]

[noun, verb, in]

[noun, in, noun]

[vbd, as, adp]

[vbd, *, adp]

[nns, vbd, *]

[nns, vbd, nnp]

[verb, as, in]

[verb, *, in]

[noun, verb, *]

[noun, verb, noun]

[as]

[in]

[went, verb]

[went, as, adp]

[vbd, adj, adp]

[adj, adp, nnp]

[went, left, 5]

[went, as, in]

[verb, jj, in]

[jj, in, noun]

[went, left, 5]

[adp]

[went, vbd]

[as, in]

[went, vbd, adp]

[vbd, adj, *]

[went]

[as, adp]

[went, as]

[went, vbd, as]

[nns, *, adp]

[vbd, adp, nnp]

[vbd, adj, nnp]

[vbd, left, 5]

[went, verb, in]

[verb, jj, *]

[as, left, 5]

[went, verb, as]

[noun, *, in]

[verb, in, noun]

[verb, jj, noun]

[verb, left, 5]

[as, left, 5]

[in, left, 5]

[went, vbd, as, adp]

[vbd, adj, *, adp]

[nns, vbd, *, adp]

[vbd, adj, adp, nnp]

[nns, vbd, adp, nnp]

[went, vbd, left, 5]

[as, adp, left, 5]

[went, as, left, 5]

[vbd, adp, left, 5]

[went, verb, as, in]

[went, verb, left, 5]

[verb, jj, *, in]

[noun, verb, *, in]

[verb, jj, in, noun]

[noun, verb, in, noun]

[as, in, left, 5]

[went, as, left, 5]

[verb, in, left, 5]

[vbd, as, adp, left, 5]

[went, as, adp, left, 5]

[went, vbd, adp, left, 5]

[went, vbd, as, left, 5]

[adj, *, adp, left, 5]

[vbd, *, adp, left, 5]

[vbd, adj, adp, left, 5]

[vbd, adj, *, left, 5]

[nns, *, adp, left, 5]

[nns, vbd, adp, left, 5]

[nns, vbd, *, left, 5]

[adj, adp, nnp, left, 5]

[vbd, adp, nnp, left, 5]

[vbd, adj, nnp, left, 5]

[nns, adp, nnp, left, 5]

[nns, vbd, nnp, left, 5]

[verb, as, in, left, 5]

[went, as, in, left, 5]

[went, verb, in, left, 5]

[went, verb, as, left, 5]

[jj, *, in, left, 5]

[verb, *, in, left, 5]

[verb, jj, in, left, 5]

[verb, jj, *, left, 5]

[noun, verb, *, left, 5]

[jj, in, noun, left, 5]

[verb, in, noun, left, 5]

[noun, verb, noun, left, 5]

[went, vbd, as, adp, left, 5]

[vbd, adj, *, adp, left, 5]

[noun, *, in, left, 5]

[noun, verb, in, left, 5]

[verb, jj, noun, left, 5]

[nns, vbd, *, adp, left, 5]

(slide from slav petrov)

[noun, in, noun, left, 5]

[vbd, adj, adp, nnp, left, 5]

[nns, vbd, adp, nnp, left, 5]

[went, verb, as, in, left, 5]

[verb, jj, *, in, left, 5]

[noun, verb, *, in, left, 5]

[verb, jj, in, noun, left, 5]

neural features (bi-lstm)

(kiperwasser and goldberg 2016)

 (x, jumped, f ox)

concat

bi

bi

bi

bi

bi

bi

bi

bi

bi

the/d

fox/n
fox/n

who/p

likes/v

apples/n

jumped/v
jumped/v

over/p

a/d

dog/n

score(h, m, x) = m lp ( (x, h, m))

 (x, h, m) = [birn n (x, h); birn n (x, m)]

id170 recipe

predict(x) = arg max

y2y(x)xp2y

score( (p))

decompose

represent

search

score

scoring
y2y(x)xp2y
y2y(x)xp2y

predict(x) = arg max
predict(x) = arg max

score( (p))
score( (p))

    a model (linear or not) assigns a score based on 

features

score( (h, m)) = w     (h, m)

scoring
y2y(x)xp2y
y2y(x)xp2y

predict(x) = arg max
predict(x) = arg max

score( (p))
score( (p))

    a model (linear or not) assigns a score based on 

features

linear:

non-linear:

score( (h, m)) = w     (h, m)
score( (h, m)) = w    tanh(u     (h, m))

scoring
y2y(x)xp2y
y2y(x)xp2y

predict(x) = arg max
predict(x) = arg max

score( (p))
score( (p))

    a model (linear or not) assigns a score based on 

features

linear:

non-linear:
bi-linear:

score( (h, m)) = w     (h, m)
score( (h, m)) = w    tanh(u     (h, m))
score( (h, m)) =  (h)w (m)

training  

(linear, structured id88)

    for each  gold pair             : 

(x, y)
    predict       based on x. 

  y
  y 6= y

    if               , update: 

w   w + xh,m2y

predict(x) = arg max

y2y(x) xh,m2y

w     (h, m)

 (h, m)   xh,m2  y

 (h, m)

training  

(linear, structured id88)

    for each  gold pair             : 

(x, y)
    predict       based on x. 

  y
  y 6= y

    if               , update: 

w   w + xh,m2y

predict(x) = arg max

y2y(x) xh,m2y

w     (h, m)

 (h, m)   xh,m2  y

 (h, m)

gold features

predicted features

at parsing time

    assign a score to each head,modi   er pair. 

    use eisner/cle to    nd best scoring tree.

transition-based parsing

29 / 1

transition-based (greedy) parsing

1. start with an unparsed sentence.
2. apply locally-optimal actions until sentence is parsed.

30 / 1

transition-based (greedy) parsing

1. start with an unparsed sentence.
2. apply locally-optimal actions until sentence is parsed.
3. use whatever features you want.
4. surprisingly accurate.
5. can be extremely fast.

30 / 1

intro to transition-based id33

an abstract machine composed of a stack and a buffer.

machine is initialized with the words of a sentence.

a set of actions process the words by moving them from buffer
to stack, removing them from the stack, or adding links between
them.

a speci   c set of actions de   ne a transition system.

31 / 1

the arc-eager transition system

i shift move    rst word from buffer

to stack.
(pre: buffer not empty.)

a a b c d

a a b c d

32 / 1

the arc-eager transition system

i shift move    rst word from buffer

to stack.
(pre: buffer not empty.)

i leftarclabel make    rst word in
buffer head of top of stack, pop
the stack.
(pre: stack not empty. top of stack does
not have a parent.)

a a b c d

a a b c d

32 / 1

the arc-eager transition system

i shift move    rst word from buffer

to stack.
(pre: buffer not empty.)

i leftarclabel make    rst word in
buffer head of top of stack, pop
the stack.
(pre: stack not empty. top of stack does
not have a parent.)

i rightarclabel make top of stack
head of    rst in buffer, move    rst
in buffer to stack.
(pre: buffer not empty.)

a a b c d

a a b c d

32 / 1

the arc-eager transition system

i shift move    rst word from buffer

to stack.
(pre: buffer not empty.)

i leftarclabel make    rst word in
buffer head of top of stack, pop
the stack.
(pre: stack not empty. top of stack does
not have a parent.)

i rightarclabel make top of stack
head of    rst in buffer, move    rst
in buffer to stack.
(pre: buffer not empty.)

i reduce pop the stack

(pre: stack not empty. top of stack has a
parent.)

a a b c d

a a b c d

32 / 1

parsing example

a

she ate pizza with pleasure

33 / 1

parsing example

a she

ate pizza with pleasure

33 / 1

parsing example

a she

ate pizza with pleasure

33 / 1

parsing example

a she ate

pizza with pleasure

33 / 1

parsing example

a she ate pizza with pleasure

33 / 1

parsing example

a she ate pizza with pleasure

33 / 1

parsing example

a she ate pizza with

pleasure

33 / 1

parsing example

a she ate pizza with pleasure

33 / 1

parsing example

a she ate pizza with pleasure

33 / 1

parsing example

a she ate pizza with pleasure

33 / 1

parsing example

a she ate pizza with pleasure

33 / 1

what do we know about the arc-eager transition
system?

i every sequence of actions result in a valid projective

structure.

i every projective tree is derivable by (at least one)

sequence of actions.

i given a tree,    nding a sequence of actions for deriving it.

("oracle")

we know these things also for the

arc-standard, arc-hybrid and other transition systems

34 / 1

this knowledge is quite powerful

parsing with an oracle sequence

sequence   oracle(sentence, tree)
con   guration   initialize(sentence)
while not con   guration.isfinal() do

action   sequence.next()
con   guration   con   guration.apply(action)

return con   guration.tree

   she ate pizza with pleasure   

35 / 1

this knowledge is quite powerful

parsing with an oracle sequence

sequence   oracle(sentence, tree)
con   guration   initialize(sentence)
while not con   guration.isfinal() do

action   sequence.next()
con   guration   con   guration.apply(action)

return con   guration.tree

   she ate pizza with pleasure   

sh left sh right re right right re re re

35 / 1

this knowledge is quite powerful

parsing with an oracle sequence

sequence   oracle(sentence, tree)
con   guration   initialize(sentence)
while not con   guration.isfinal() do

action   sequence.next()
con   guration   con   guration.apply(action)

return con   guration.tree

   she ate pizza with pleasure   

sh left sh right re right right re re re

a

she ate pizza with pleasure

35 / 1

this knowledge is quite powerful

parsing with an oracle sequence

sequence   oracle(sentence, tree)
con   guration   initialize(sentence)
while not con   guration.isfinal() do

action   sequence.next()
con   guration   con   guration.apply(action)

return con   guration.tree

   she ate pizza with pleasure   

sh left sh right re right right re re re

a

she ate pizza with pleasure

35 / 1

this knowledge is quite powerful

parsing with an oracle sequence

sequence   oracle(sentence, tree)
con   guration   initialize(sentence)
while not con   guration.isfinal() do

action   sequence.next()
con   guration   con   guration.apply(action)

return con   guration.tree

   she ate pizza with pleasure   

sh left sh right re right right re re re

a she

ate pizza with pleasure

35 / 1

this knowledge is quite powerful

parsing with an oracle sequence

sequence   oracle(sentence, tree)
con   guration   initialize(sentence)
while not con   guration.isfinal() do

action   sequence.next()
con   guration   con   guration.apply(action)

return con   guration.tree

   she ate pizza with pleasure   

sh left sh right re right right re re re

a she

ate pizza with pleasure

35 / 1

this knowledge is quite powerful

parsing with an oracle sequence

sequence   oracle(sentence, tree)
con   guration   initialize(sentence)
while not con   guration.isfinal() do

action   sequence.next()
con   guration   con   guration.apply(action)

return con   guration.tree

   she ate pizza with pleasure   

sh left sh right re right right re re re

a she

ate pizza with pleasure

35 / 1

this knowledge is quite powerful

parsing with an oracle sequence

sequence   oracle(sentence, tree)
con   guration   initialize(sentence)
while not con   guration.isfinal() do

action   sequence.next()
con   guration   con   guration.apply(action)

return con   guration.tree

   she ate pizza with pleasure   

sh left sh right re right right re re re

a she

ate pizza with pleasure

35 / 1

this knowledge is quite powerful

parsing with an oracle sequence

sequence   oracle(sentence, tree)
con   guration   initialize(sentence)
while not con   guration.isfinal() do

action   sequence.next()
con   guration   con   guration.apply(action)

return con   guration.tree

   she ate pizza with pleasure   

sh left sh right re right right re re re

a she ate

pizza with pleasure

35 / 1

this knowledge is quite powerful

parsing with an oracle sequence

sequence   oracle(sentence, tree)
con   guration   initialize(sentence)
while not con   guration.isfinal() do

action   sequence.next()
con   guration   con   guration.apply(action)

return con   guration.tree

   she ate pizza with pleasure   

sh left sh right re right right re re re

a she ate

pizza with pleasure

35 / 1

this knowledge is quite powerful

parsing with an oracle sequence

sequence   oracle(sentence, tree)
con   guration   initialize(sentence)
while not con   guration.isfinal() do

action   sequence.next()
con   guration   con   guration.apply(action)

return con   guration.tree

   she ate pizza with pleasure   

sh left sh right re right right re re re

a she ate pizza with pleasure

35 / 1

this knowledge is quite powerful

parsing with an oracle sequence

sequence   oracle(sentence, tree)
con   guration   initialize(sentence)
while not con   guration.isfinal() do

action   sequence.next()
con   guration   con   guration.apply(action)

return con   guration.tree

   she ate pizza with pleasure   

sh left sh right re right right re re re

a she ate pizza with pleasure

35 / 1

this knowledge is quite powerful

parsing with an oracle sequence

sequence   oracle(sentence, tree)
con   guration   initialize(sentence)
while not con   guration.isfinal() do

action   sequence.next()
con   guration   con   guration.apply(action)

return con   guration.tree

   she ate pizza with pleasure   

sh left sh right re right right re re re

a she ate pizza with pleasure

35 / 1

this knowledge is quite powerful

parsing with an oracle sequence

sequence   oracle(sentence, tree)
con   guration   initialize(sentence)
while not con   guration.isfinal() do

action   sequence.next()
con   guration   con   guration.apply(action)

return con   guration.tree

   she ate pizza with pleasure   

sh left sh right re right right re re re

a she ate pizza with pleasure

35 / 1

this knowledge is quite powerful

parsing with an oracle sequence

sequence   oracle(sentence, tree)
con   guration   initialize(sentence)
while not con   guration.isfinal() do

action   sequence.next()
con   guration   con   guration.apply(action)

return con   guration.tree

   she ate pizza with pleasure   

sh left sh right re right right re re re

a she ate pizza with

pleasure

35 / 1

this knowledge is quite powerful

parsing with an oracle sequence

sequence   oracle(sentence, tree)
con   guration   initialize(sentence)
while not con   guration.isfinal() do

action   sequence.next()
con   guration   con   guration.apply(action)

return con   guration.tree

   she ate pizza with pleasure   

sh left sh right re right right re re re

a she ate pizza with

pleasure

35 / 1

this knowledge is quite powerful

parsing with an oracle sequence

sequence   oracle(sentence, tree)
con   guration   initialize(sentence)
while not con   guration.isfinal() do

action   sequence.next()
con   guration   con   guration.apply(action)

return con   guration.tree

   she ate pizza with pleasure   

sh left sh right re right right re re re

a she ate pizza with pleasure

35 / 1

this knowledge is quite powerful

parsing with an oracle sequence

sequence   oracle(sentence, tree)
con   guration   initialize(sentence)
while not con   guration.isfinal() do

action   sequence.next()
con   guration   con   guration.apply(action)

return con   guration.tree

   she ate pizza with pleasure   

sh left sh right re right right re re re

a she ate pizza with pleasure

35 / 1

this knowledge is quite powerful

parsing with an oracle sequence

sequence   oracle(sentence, tree)
con   guration   initialize(sentence)
while not con   guration.isfinal() do

action   sequence.next()
con   guration   con   guration.apply(action)

return con   guration.tree

   she ate pizza with pleasure   

sh left sh right re right right re re re

a she ate pizza with pleasure

35 / 1

this knowledge is quite powerful

parsing with an oracle sequence

sequence   oracle(sentence, tree)
con   guration   initialize(sentence)
while not con   guration.isfinal() do

action   sequence.next()
con   guration   con   guration.apply(action)

return con   guration.tree

   she ate pizza with pleasure   

sh left sh right re right right re re re

a she ate pizza with pleasure

35 / 1

this knowledge is quite powerful

parsing with an oracle sequence

sequence   oracle(sentence, tree)
con   guration   initialize(sentence)
while not con   guration.isfinal() do

action   sequence.next()
con   guration   con   guration.apply(action)

return con   guration.tree

   she ate pizza with pleasure   

sh left sh right re right right re re re

a she ate pizza with pleasure

35 / 1

this knowledge is quite powerful

parsing with an oracle sequence

sequence   oracle(sentence, tree)
con   guration   initialize(sentence)
while not con   guration.isfinal() do

action   sequence.next()
con   guration   con   guration.apply(action)

return con   guration.tree

   she ate pizza with pleasure   

sh left sh right re right right re re re

a she ate pizza with pleasure

35 / 1

this knowledge is quite powerful

parsing with an oracle sequence

sequence   oracle(sentence, tree)
con   guration   initialize(sentence)
while not con   guration.isfinal() do

action   sequence.next()
con   guration   con   guration.apply(action)

return con   guration.tree

   she ate pizza with pleasure   

sh left sh right re right right re re re

a she ate pizza with pleasure

35 / 1

this knowledge is quite powerful

parsing with an oracle sequence

sequence   oracle(sentence, tree)
con   guration   initialize(sentence)
while not con   guration.isfinal() do

action   sequence.next()
con   guration   con   guration.apply(action)

return con   guration.tree

   she ate pizza with pleasure   

sh left sh right re right right re re re

a she ate pizza with pleasure

35 / 1

this knowledge is quite powerful

parsing without an oracle

sequence   oracle(sentence, tree)
con   guration   initialize(sentence)
while not con   guration.isfinal() do

action   sequence.next()
con   guration   con   guration.apply(action)

return con   guration.tree

36 / 1

this knowledge is quite powerful

parsing without an oracle

start with weight vector w
con   guration   initialize(sentence)
while not con   guration.isfinal() do

action   predict(w,  (con   guration))
con   guration   con   guration.apply(action)

return con   guration.tree

36 / 1

this knowledge is quite powerful

parsing without an oracle

summarize the con   guration

as a feature vector
start with weight vector w
con   guration   initialize(sentence)
while not con   guration.isfinal() do

action   predict(w,  (con   guration))
con   guration   con   guration.apply(action)

return con   guration.tree

36 / 1

this knowledge is quite powerful

parsing without an oracle

summarize the con   guration

as a feature vector
start with weight vector w
con   guration   initialize(sentence)
while not con   guration.isfinal() do

action   predict(w,  (con   guration))
con   guration   con   guration.apply(action)

return con   guration.tree

predict the action based on the features

36 / 1

this knowledge is quite powerful

parsing without an oracle

summarize the con   guration

as a feature vector
start with weight vector w
con   guration   initialize(sentence)
while not con   guration.isfinal() do

action   predict(w,  (con   guration))
con   guration   con   guration.apply(action)

return con   guration.tree

predict the action based on the features

need to learn the correct weights

36 / 1

this knowledge is quite powerful

parsing with an oracle sequence

sequence   oracle(sentence, tree)
con   guration   initialize(sentence)
while not con   guration.isfinal() do

action   sequence.next()
con   guration   con   guration.apply(action)

37 / 1

this knowledge is quite powerful

learning a parser (batch)

sequence   oracle(sentence, tree)
con   guration   initialize(sentence)
while not con   guration.isfinal() do

action   sequence.next()

con   guration   con   guration.apply(action)

37 / 1

this knowledge is quite powerful

learning a parser (online)
w   0
for sentence,tree pair in corpus do

sequence   oracle(sentence, tree)
con   guration   initialize(sentence)
while not con   guration.isfinal() do

action   sequence.next()
features    (con   guration)
predicted   predict(w,  (con   guration))
if predicted 6= action then
con   guration   con   guration.apply(action)

w.update( (con   guration), action, predicted)

return w

37 / 1

this knowledge is quite powerful

parsing time

con   guration   initialize(sentence)
while not con   guration.isfinal() do

action   predict(w,  (con   guration))
con   guration   con   guration.apply(action)

return con   guration.tree

38 / 1

in short

i summarize con   guration by a set of features.
i learn the best action to take at each con   guration.
i hope this generalizes well.

39 / 1

transition based parsing

i a different approach.
i very common.
i can be as accurate as    rst-order graph-based parsing.

i higher-order graph-based are still better.

i easy to implement.
i very fast. (o(n))
i can be improved further:

i easy-   rst
i dynamic oracle
i id125

41 / 1

summary

    syntax (hierarchical structure) 
    grammars, pid18, cky algorithm 

    head words 

    constituency to dependency with head-words 
    id33 

    graph based 
    transition based

parsers

    phrase based 

    berkeley parser 

    stanford parser 

    dependency 

    spacy 

    stanford parser 

    dependency + research 

    bist parser  (kiperwasser and goldberg) 

    id200 parser (dyer et al)

