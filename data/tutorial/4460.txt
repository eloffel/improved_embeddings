agenda
    deep learning on regular structures

    multi-view representation
    volumetric representation

    deep learning on meshes

    deep learning on point cloud and parametric models

1

agenda
    deep learning on regular structures

    multi-view representation
    volumetric representation

    deep learning on meshes

    deep learning on point cloud and parametric models

2

general idea

    convert irregular (3d) to regular (images)
    circumvent any geometric representation artifacts
(non-manifold geometry, polygon soups, no interior)

empty  inside!

    leverage pre-trained image-based id98s
    similarly to humans, analyze what can be seen: 
 
combine surface information from multiple views 

3

agenda

    deep learning review

    overview of 3d deep learning

    deep learning on multi-view representation

    classification
    segmentation
    reconstruction

4

task: 3d classification

this is a chair!

5

given an input shape  

hang su, subhransu maji, evangelos kalogerakis, erik learned-miller, 
"multi-view convolutional neural networks for 3d shape recognition", 
proceedings of iccv 2015

[credit: hang su]

6

render with multiple virtual cameras

view 1

view 2

view 3

view n

hang su, subhransu maji, evangelos kalogerakis, erik learned-miller, 
"multi-view convolutional neural networks for 3d shape recognition", 
proceedings of iccv 2015

[credit: hang su]

7

traditional approach: feature+linear classifier

view 1

view 2

view 3

view n

xi

   

softmax layer

yc = wc
pi,c =

txi + bc
t xi + bc)
exp(wc
exp(wj
t xi + bj)
   

maximize

w

log pi, li

   

i

8

the rendered images are passed through id981 
for image features

id981

id981

id981

   

   

   

.

.
 
.
 

   

id981

id981:  a  convnet  extracting 
image features

hang su, subhransu maji, evangelos kalogerakis, erik learned-miller, 
"multi-view convolutional neural networks for 3d shape recognition", 
proceedings of iccv 2015

[credit: hang su]

9

all image features are combined by view pooling 
   

view 
pooling

   

   

   

.

.
 
.
 

   

id981

view  pooling:  element-wise 
max-pooling across all views 

hang su, subhransu maji, evangelos kalogerakis, erik learned-miller, 
"multi-view convolutional neural networks for 3d shape recognition", 
proceedings of iccv 2015

[credit: hang su]

10

    and then passed through id982 and to 
generate final predictions

   

   

   

.

.
 
.
 

   

id981

view 
pooling

   

id982

softmax

id982:       a second convnet 
producing shape descriptors 

hang su, subhransu maji, evangelos kalogerakis, erik learned-miller, 
"multi-view convolutional neural networks for 3d shape recognition", 
proceedings of iccv 2015

[credit: hang su]

11

learning by fine-tuning
    neural network optimization is non-convex

    in general, training from more data converges at a better local minima

    however, what if your training dataset      is not big?

d

12

learning by fine-tuning (cont.)
pre-training

d'
    find a source of massive data      with similar statistics
    learn the network parameters from 

d'

fine-tuning

    starting from the learned parameters on      , minimize the network 
loss on 

d

d'

a technique for id21, quite effective in practice

13

training: network parameters are pre-trained on 
image classification    

   

   

   

.

.
 
.
 

   

id981

parameters  initialized  from 
vgg-m model [chatfield14]

view 
pooling

   

id982

softmax

[chatfield14] k. chatfield et. al.,    return of the devil in the details: delving deep into convolutional nets   , bmvc 2014

hang su, subhransu maji, evangelos kalogerakis, erik learned-miller, 
"multi-view convolutional neural networks for 3d shape recognition", 
proceedings of iccv 2015

[credit: hang su]

14

    and then fine-tuned on 3d datasets

   

   

   

.

.
 
.
 

   

id981

view 
pooling

   

id982

softmax

fine-tuning  
w/ back-prop

hang su, subhransu maji, evangelos kalogerakis, erik learned-miller, 
"multi-view convolutional neural networks for 3d shape recognition", 
proceedings of iccv 2015

[credit: hang su]

15

extract compact shape descriptor for other 
applications

   

   

   

.

.
 
.
 

   

id981

view 
pooling

   

id982

softmax

metric 
learning

shape descriptor can be extracted from id982, and  
a low-rank metric is learned w/ good&bad pairs

hang su, subhransu maji, evangelos kalogerakis, erik learned-miller, 
"multi-view convolutional neural networks for 3d shape recognition", 
proceedings of iccv 2015

[credit: hang su]

16

experiments     classification & retrieval
on modelnet40, compared against: 

    3 existing methods:
sph, lfd, 3d shapenets
    2 strong baselines:
fisher vectors, id98

classification retrieval
(accuracy)

method

sph [16]
lfd [5]
3d shapenets [37]
fv, 12 views
id98, 12 views
mvid98, 12 views
mvid98+metric, 12 views

mvid98, 80 views
mvid98+metric, 80 views

68.2%
75.5%
77.3%
84.8%
88.6%
89.9%
89.5%

90.1%
90.1%

(map)
33.3%
40.9%
49.2%
43.9%
62.8%
70.1%
80.2%

70.4%
79.5%

[credit: hang su]
17

visualization of saliency across views

[credit: hang su]
18

how do you use multi-view approach for point cloud?

sphere rendering images

multi-view 
image id98

[credit: cvpr 2016 spotlight]

19

practical multi-view id98
state-of-the-art performance for 3d mesh classification

issues:

    what viewpoints to select? in particular, where shall we place the
camera in a scene?
    what if the input is noisy and incomplete? e.g., point cloud

20

agenda

    deep learning review

    overview of 3d deep learning

    deep learning on multi-view representation

    classification
    segmentation
    reconstruction

21

3d segmentation

22

basic architecture

evangelos kalogerakis, melinos averkiou, subhransu maji, siddhartha chaudhuri,
   3d shape segmentation with projective convolutional networks   ,
cvpr2017

23

basic architecture

evangelos kalogerakis, melinos averkiou, subhransu maji, siddhartha chaudhuri,
   3d shape segmentation with projective convolutional networks   ,
cvpr2017

24

basic architecture

max

evangelos kalogerakis, melinos averkiou, subhransu maji, siddhartha chaudhuri,
   3d shape segmentation with projective convolutional networks   ,
cvpr2017

25

basic architecture

normal

geodesic

evangelos kalogerakis, melinos averkiou, subhransu maji, siddhartha chaudhuri,
   3d shape segmentation with projective convolutional networks   ,
cvpr2017

26

basic architecture

evangelos kalogerakis, melinos averkiou, subhransu maji, siddhartha chaudhuri,
   3d shape segmentation with projective convolutional networks   ,
cvpr2017

27

fully convolutional network (fcn)

segmentation:

learning deconvolution network for 
semantic segmentation

28

fully convolutional network (fcn) variations

output scores 

hxwxn

upsample

conv

input image 

hxwx3

skip links

output scores 

hxwxn

upconv

conv

input image 

hxwx3

output scores 

hxwxn

dilated 
conv

input image 

hxwx3

29

performance

30

performance (cont.)

    viewpoint selection to maximize surface coverage
    combination of view-based network with surface-based graphical model
    ~88% labeling accuracy on shapenet 
(trained per category, 50%-50% split, max 250 shapes for training)

challenges:
    view-based network does not process invisible points
    view-based representations have redundancy
    slow to train (~week for a few hundreds of shapes)
    aggregating view representations via max-pooling may lose information
 

31

surface correspondences with multi-view convnets

aggregates point-based descriptors across local views. trained such that similar 
points have similar descriptors based on synthetically generated correspondences.

contrastive 
loss

haibin huang, evangelos kalogerakis, siddhartha chaudhuri, duygu ceylan, vladimir kim, ersin yumer 
learning local shape descriptors with view-based convolutional neural network, acm tog (to appear)k 
view-based convolutional neural networks, tog 2017 

32

scan-to-shape matching
shows some robustness to noise, better performance than volumetric net (3dmatch)

(similar colors correspond to points with similar descriptors) 

33

3d reconstruction by multi-view decoder branches (shapemvd)

real / 
fake?   
(gan)

real / 
fake?   
(gan)

zhaoliang lun, matheus gadelha, evangelos kalogerakis, subhransu maji, 
rui wang,    3d shape reconstruction from sketches via  multi-view 
convolutional networks   , arxiv 2017

34

training data

synthetic line drawings

   

training depth and normal maps

35

consolidate multi-view depth and normal maps

36

consolidate multi-view depth and normal maps

optimization for fusion

    depth derivatives should

be consistent with normals

    corresponding depths and

normals across different
views should agree

37

poisson surface reconstruction (kazhdan et al. 2013)

38

reference   
shape

line   

drawings

shapemvd

tatarchenko
(same loss/fusion)

et al.

volumetric

reference   
shape

line   

drawings

nearest
 retrieval

shapemvd

tatarchenko

et al.

volumetric

(same loss/fusion)

nearest
 retrieval

reference   
shape

line   

drawings

reference   
shape

line   

drawings

shapemvd

tatarchenko
(same loss/fusion)

et al.

volumetric

nearest
 retrieval

shapemvd

tatarchenko

et al.

volumetric

nearest
 retrieval

(same loss/fusion)

single vs two input line drawings

41

key challenges for multi-view representation

    fusing information across viewpoints is not incorporated in the network (not trivial)

       cannot see through the surface   

    less redundancy than producing a surface for every possible continuous viewing   
  angle, yet surfaces across different viewpoints may not be consistent. 

42

agenda
    deep learning on regular structures

    multi-view representation
    volumetric representation

    deep learning on meshes

    deep learning on point cloud and parametric models

43

popular 3d volumetric data

fmri

ct

manufacturing 

(finite-element analysis)

voxelized 
cad models

geology

44

3d id98 on volumetric data

3d convolution uses 4d kernels

[credit: su et al. cvpr 2016]
45

early 3d id98s for shape classification

3dshapenets from princeton 

cvpr 2015

voxnet from cmu robotics 

ieee/rsj 2015

information loss in voxelization

3d id98
77.3%

3d id98
83.0%

cad model

occupancy grid

30x30x30

mvid98 from umass 

iccv 2015

rendering + 

2d id98
90.1%

46

3d id98 for volumetric data 

3d deconvolution uses 4d kernels

[credit: wu&zhang, et al. nips 2016]
47

volumetric id3

jiajun wu, chengkai zhang, et al. learning a probabilistic latent space of object shapes via 3d generative-adversarial 
modeling. nips 2016

48

learning 3d reconstruction from single-view

    depth based methods [eigen et al., saxena et al., etc]
    model based methods [su et al., kar et al., aubry et al., choy et al., etc]

49

recurrent 2d-3d id98 for volumetric reconstruction

christopher b. choy, danfei xu*, junyoung gwak*, kevin chen, silvio savarese, 
3d-r^2n^2: a unified approach for single and multi-view 3d object reconstruction 
eccv2016

50

recurrent 3d id98

51

recurrent 3d id98

3d convolutional lstm

52

recurrent 3d id98

53

supervised learning with ground truth 3d volumes

   voxel-wise cross id178 loss

   shapenet

   50k cad models
   render from arbitrary views
   random number of images w/ random order
   random background, translation

54

learning volumetric reconstruction by multi-view supervision

perspective transformer nets: learning single-view 3d object reconstruction without 3d 
supervision 
xinchen yan, jimei yang, ersin yumer, yijie guo, honglak lee, nips 2016 

56

perspective transformer layer (projecting 3d volume to 2d masks)

for each pixel on a mask, find the intersection of its corresponding ray and the input 
volume
1. sample points p = [x, y, 1, d] given the range of disparity d in [d_min, d_max] 

2. given a perspective transform matrix t, generate sampling points on the input volume v by q = t^-1 p (ray 

1. p = [x/d, y/d, 1/d, 1] 

sampling) 

3. generate the output volume u by bilinear sampling on the input volume v 
4. generate the mask s by max pooling over the depth dimension on u

57

perspective transformer nets

58

results

input						gt	(310)			gt	(130)		pr	(310)		pr	(130)		co	(310)	co	(130)		vo	(310)		vo	(130)
input

ground truth

ptn-comb

ptn-proj

id98-vol

59

learning from partial views

a narrow range of views

a set of sparsely sampled views

input 2d 
image i(1)

volume v

transformations 
{t(1),t(2),...t(n)}

input 2d 
image i(1)

s(3)

s(2)

target 2d 
mask s(1)

volume v

s(5)

transformations 
{t(1),t(2),...t(n)}

s(3)

target 2d 
mask s(1)

24 views (360 degree) 8 views (90 degree) 8 views (evenly sampled)

60

differentiable ray consistency

1. given a pair of observation and camera, trace the voxels for each pixel along the ray 

(nearest neighbor sampling) 

2. define ray termination id203 to determine the relationship between a pixel and 

voxel occupancy likelihood (differentiable) 

3. different types of multi-view observations e.g. foreground masks, depth, color images, 

semantics etc. as supervision.

multi-view supervision for single-view reconstruction via differentiable ray consistency. s. tulsiani, t. zhou, a. a. 
efros, j. malik. in cvpr, 2017

61

the sparsity characteristic of volumetric data

occupancy:
resolution:

32

64

128

62

store only the occupied grids
octree: recursively partition the space  
each internal node has exactly eight children

63

skip the computation of empty cells

gernot riegler, ali osman ulusoy, andreas geiger
   octnet: learning deep 3d representations at high resolutions   
cvpr2017

pengshuai wang, yang liu, yuxiao guo, chunyu sun, xin tong
   o-id98: octree-based convolutional neural network for understanding 3d shapes    
siggraph2017

64

octree-based convolutional neural network
define convolution and pooling along the octree

the challenge is how to implement efficiently     build a hash table to index the 
neighborhood
restrict the convolution stride to be 2

65

performance

66

towards higher spatial resolution

maxim tatarchenko, alexey dosovitskiy, thomas brox
   octree generating networks: efficient convolutional architectures for high-resolution 3d outputs   
arxiv (march, 2017)

67

progressive voxel refinement

3-way classification

68

results

69

