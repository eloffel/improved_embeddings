agenda
    deep learning on regular structures

    deep learning on meshes

    deep learning on point cloud and parametric models

    point cloud analysis
    point cloud synthesis
    primitive-based shapes

1

agenda
    deep learning on regular structures

    deep learning on meshes

    deep learning on point cloud and parametric models

    point cloud analysis
    point cloud synthesis
    primitive-based shapes

2

applications of point set analysis

    robot perception

what and where are the objects in a 
lidar scanned scene?

https://3dprint.com/116569/self-driving-cars-privacy/

applications of point set analysis

    molecular biology

can we infer an enzyme   s category (reactions 
they catalyze) from its structure?

ecorv restriction enzyme molecule, laguna design/science photo library

directly process point cloud data
end-to-end learning for unstructured, unordered point data 

pointnet

directly process point cloud data
end-to-end learning for unstructured, unordered point data  
unified framework for various tasks

pointnet

object classification
part segmentation
scene parsing

...

properties of a desired neural network on point clouds
point cloud: n orderless points, each represented by a d dim coordinate

d

n

2d array representation

properties of a desired neural network on point clouds
point cloud: n orderless points, each represented by a d dim coordinate

d

n

2d array representation

permutation invariance

transformation invariance

properties of a desired neural network on point clouds
point cloud: n orderless points, each represented by a d dim coordinate

d

d

n

represents the same set as 

n

2d array representation

permutation invariance

permutation invariance: symmetric function

f (x1,x2,   ,xn)     f (x  1,x  2,   ,x  n)

,

xi    !d

examples:

f (x1,x2,   ,xn) = max{x1,x2,   ,xn}
f (x1,x2,   ,xn) = x1 + x2 +   + xn
   

construct symmetric function family
observe: f (x1,x2,   ,xn) =  !g(h(x1),   ,h(xn)) is symmetric if      is symmetric

g

construct symmetric function family

observe:

f (x1,x2,   ,xn) =  !g(h(x1),   ,h(xn)) is symmetric if      is symmetric

g

h

(1,2,3)
(1,1,1)

(2,3,2)

(2,3,4)

construct symmetric function family

observe:

f (x1,x2,   ,xn) =  !g(h(x1),   ,h(xn)) is symmetric if      is symmetric

g

h

(1,2,3)
(1,1,1)

(2,3,2)

(2,3,4)

simple symmetric function
g

construct symmetric function family

observe:

f (x1,x2,   ,xn) =  !g(h(x1),   ,h(xn)) is symmetric if      is symmetric

g

h

(1,2,3)
(1,1,1)

(2,3,2)

(2,3,4)

simple symmetric function
g

  

pointnet (vanilla)

q: what symmetric functions can be constructed by pointnet?

symmetric functions

pointnet (vanilla)

a: universal approximation to continuous symmetric functions

theorem:
a hausdorff continuous symmetric function                    can be arbitrarily 
approximated by pointnet.

f :2x     !

s     !d ,

pointnet (vanilla)

pointnet architecture

results on object classification

object classification accuracy on modelnet40

results on object part segmentation

results on object part segmentation

part segmentation miou on shapenet part dataset

robustness to data corruption

robustness to data corruption

visualizing point functions

compact view:

expanded view:

1x3

1x3

fcs

fc

1x1024

64

fc

64

fc

64

fc

fc

128

1x1024

which input point will activate neuron j?

find the top-k points in a dense volumetric grid that activates neuron j.

visualizing point functions

visualizing global point cloud features

limitations of pointnet

hierarchical id171
 multiple levels of abstraction

global id171 

either one point or all points

3d id98 (wu et al.)

pointnet (vanilla) (qi et al.)

limitations of pointnet

hierarchical id171
 multiple levels of abstraction

global id171 

either one point or all points

no local context for each point!

3d id98 (wu et al.)

pointnet (vanilla) (qi et al.)

limitation of pointnet

lack of local context => artifacts in segmentation tasks

semantic segmentation of randomly 
translated table-cup scene

instance mask prediction in table-
chair-cup scene

limitation of pointnet

lack of local context => artifacts in segmentation tasks

global feature depends on absolute coordinate. hard to 
semantic segmentation of randomly 
translated table-cup scene

instance mask prediction in table-
chair-cup scene

generalize to unseen scene configurations!

pointnet++

use pointnet in local regions, aggregate local 
features by pointnet again 
        => hierarchical id171 

pointnet

pointnet++

use pointnet in local regions, aggregate local 
features by pointnet again 
        => hierarchical id171 

pointnet

common issue: inconsistent sampling density 
        => robust to non-uniform sampling density

hierarchical point set id171

(n,d+c)

(n1,k,d+c)

sampling & 
grouping

sampling: farthest point sampling (fps)
grouping: radius based ball query

hierarchical point set id171

(n,d+c)

(n1,k,d+c)

(n1,d+c1)

sampling & 
grouping

pointnet

set abstraction

shared pointnet applied in each 
local region using local coord.

hierarchical point set id171
recursively apply pointnet:

(n,d+c)

(n1,k,d+c)

(n1,d+c1)

(n2,k,d+c1)

(n2,d+c2)

sampling & 
grouping

pointnet

sampling & 
grouping

pointnet

set abstraction

set abstraction

pointnet layer v.s. convolution layer

pointnet layer

convolution layer

pointnet

input:

point set

dense array

operation:

pointnet (order invariant)

convolution (index-ordered)

neighborhood:

radius ball query 
(varying #points)

array index 
(fixed #pixel/voxel)

pointnet++ for classification and segmentation

skip link concatenation

(n 1,d+c 2+c 1)

(n 1,d+c 3)

(n,d+c 3+c)

(n,k)

hierarchical point set id171

segmentation

(n,d+c)

(n 1,k,d+c)

(n 1,d+c 1)

(n 2,k,d+c 1)

(n 2,d+c 2)

sampling & 
grouping

pointnet

sampling & 
grouping

pointnet

set abstraction

set abstraction

interpolate

classification

unit 
pointnet

(1,c4)

interpolate

unit 
pointnet

pointnet

fully connected layers

per-point 
scores

(k)

s
e
r
o
c
s
 
s
s
a
l
c

pointnet++ for classification and segmentation

hierarchical point set id171

segmentation

(n,d+c)

(n 1,k,d+c)

(n 1,d+c 1)

(n 2,k,d+c 1)

(n 2,d+c 2)

sampling & 
grouping

pointnet

sampling & 
grouping

pointnet

set abstraction

set abstraction

skip link concatenation

(n 1,d+c 2+c 1)

(n 1,d+c 3)

(n,d+c 3+c)

(n,k)

per-point 
scores

(k)

interpolate

classification

unit 
pointnet

(1,c4)

interpolate

unit 
pointnet

interpolation: inverted distance weighting.
unit pointnet: mlp on each point   s feature

s
e
r
o
c
s
 
s
s
a
l
c

pointnet

fully connected layers

pointnet++

use pointnet in local regions, aggregate local 
features by pointnet again 
        => hierarchical id171 

pointnet

common issue: inconsistent sampling density 
        => robust to non-uniform sampling density

non-uniform sampling density

density variation is a common issue of 3d point cloud

- perspective effect, radial density variation, motion etc.

density variation affects hierarchy 

    in id98, small kernels are usually better

karen simonyan & andrew zisserman, very deep convolutional networks 
for large-scale image recognition, iclr2015

    is it also true for point cloud learning?

density variation affects hierarchy 

we expect to trust regions with high sampling density; use larger 
field of view for sparse regions.

non-uniform sampling density

concat

concat

(a)

(b)

multi-scale grouping (msg) multi-res grouping (mrg)

during training: input point dropout with random dropout ratio

robust learning under varying sampling density

msg

mrg

original

pointnet++ results: classification

by hierarchical id171, we can achieve even better results than the original 
pointnet. by using normals, we can even beat best view-id98 based method.

pointnet++ results: scene parsing

much better generalizability in scene parsing. msg layer very helpful for 
point cloud with non-uniform densities.

pointnet++ results: non-euclidean space

for organic shape recognition, pointnet++ can generalize to non-euclidean space:

intrinsic point features (hks, wks, gaussian curvature)
intrinsic distance metric (geodesic)

pointnet++ feature visualization
trained on modelnet40 (mostly furniture)  we see structures of planes, double 
planes, lines, corners etc.   

first layer patterns

agenda
    deep learning on regular structures

    deep learning on meshes

    deep learning on point cloud and parametric models

    point cloud analysis
    point cloud synthesis
    primitive-based shapes

48

task: 3d reconstruction from a single image

49

monocular vision

a typical prey

a typical predator

cited from https://en.wikipedia.org/wiki/binocular_vision

monocular 3d perception by human

a core problem of id161
   1970 

one of earliest problems of id161.

over 40 years of history!

52

a data-driven solution: geometric prior learning

many 3d objects

apriori knowledge of 3d geometry

supervision from    synthesize for learning   

shapenet

renderer

54

supervision from    synthesize for learning   

    200k shapes from 2k categories
renderer
    10m images with groundtruth

shapenet

55

volumetric upconvolution?

input image

cons:

low resolution

error in structure

56

volumetric upconvolution?

input image

reason:
    geometric transformation is hard for upconv

low resolution

cons:

error in structure

57

another representation possibility: point clouds

transformation friendly for networks

usable as network output?
no prior works in deep learning community!

motivation            shapenet              pointnet            pointsetgeneration

cvpr    17, point set generation

58

3d prediction by point clouds

input
pioneer work on set generation in deep learning

reconstructed 3d point cloud

59

3d prediction by point clouds

input
pioneer work on set generation in deep learning

reconstructed 3d point cloud

60

comparison to direct 3d volumetric upconvolution

input

volumetric upconv

(eccv 2016, 3d-r2n2)

ours 

(post-processed to volumetric)

groundtruth

61

pipeline

network

prediction

nx3

   

   

nx3
groundtruth point set

loss
on
sets
(l)

62

set comparison

given two sets of points, measure their discrepancy

63

set comparison

given two sets of points, measure their discrepancy

key challenge: 

correspondence problem

64

correspondence (i): optimal assignment

given two sets of points, measure their discrepancy

a.k.a earth mover   s distance (emd)

65

correspondence (ii): closest point

given two sets of points, measure their discrepancy

a.k.a chamfer distance (cd)

66

required properties of distance metrics
geometric requirement

computational requirement

67

required properties of distance metrics
geometric requirement

    reflects natural shape differences
    induce a nice space for shape interpolations

computational requirement

68

how distance metric affects learning?
a fundamental issue: inherent ambiguity in prediction

69

how distance metric affects learning?
a fundamental issue: inherent ambiguity in prediction

70

how distance metric affects learning?
a fundamental issue: inherent ambiguity in prediction

71

how distance metric affects learning?
a fundamental issue: inherent ambiguity in prediction

    by loss minimization, the network tends to predict a    mean shape    that 
averages out uncertainty

72

distance metrics affect mean shapes
the mean shape carries characteristics of the distance metric

continuous 
hidden variable

(radius)

input

emd mean

chamfer mean

73

mean shapes from distance metrics
the mean shape carries characteristics of the distance metric

continuous 
hidden variable

(radius)

discrete 

hidden variable
(add-on location)

input

emd mean

chamfer mean

74

comparison of predictions by emd versus cd
chamfer

input

emd

pipeline

network

prediction

nx3

   

   

nx3
groundtruth point set

loss
on
sets
(l)

76

network design: respect natural statistics of geometry

    many local structures are common

77

network design: respect natural statistics of geometry

    many local structures are common

    also some intricate structures

78

two-branch architecture

conv

... 

upconv
branch

fc

branch

   

   

nx3

mx3

79

two-branch architecture

conv

... 

smooth
upconv
branch

fc

branch

non-smooth

   

   

nx3

mx3

80

two-branch architecture

conv

... 

smooth
upconv
branch

fc

branch

   

   

nx3

mx3

   

(m+n)x3

non-smooth

set union by array concatenation

81

which color corresponds to the upconv branch? fc branch?

input

prediction

82

design of upconvolution branch
smooth
upconv
branch

conv

... 

fc

branch

   

   

nx3

mx3

non-smooth

set union by array concatenation

83

design of upconvolution branch

coordinate map

upconv

... 

conv

... 

   

   

nx3

mx3

fc

branch

non-smooth

84

learns a surface parameterization
smooth parameterization from 2d to 3d

[image credit: keenan crane]

85

quantitative evaluation

)
r
o
r
r

e

(
 
e
c
n
a
t
s
d

i

f

 
r
e
m
a
h
c

1.8

1.35

0.9

0.45

0

3d volumetric

deconv

63% error reduction!

point cloud

baseline 

(mean shape)

[choy et. al, eccv16]

ours

86

quantitative evaluation

)
r
o
r
r

e

(
 
e
c
n
a
t
s
d

i

f

 
r
e
m
a
h
c

1.8

1.35

0.9

0.45

0

representation choice matters!

3d volumetric

deconv

point cloud

baseline 

(mean shape)

[choy et. al, eccv16]

ours

87

real-world results

input

observed view

  

input

observed view

  

88

generalization to unseen categories

input

observed view

  

input

observed view

  

out of training categories

89

extension: shape completion

input: incomplete shape

output: completed shape

90

open problems

a better metric that takes the best of chamfer and emd? 

how to add further structure constraints? 

how to extend the pipeline to scene level? 

how generalizable the method is?  

in principle, what is the generalizability of a geometry estimator? to what extend is 3d 
perception ability innate or learned? 

agenda
    deep learning on regular structures

    deep learning on meshes

    deep learning on point cloud and parametric models

    point cloud analysis
    point cloud synthesis
    primitive-based shapes

92

a historical overview

generalized cylinders, binford (1971)  

primitive-based assembly

learn to predict a corresponding shape composed by primitives.
it allows us to predict consistent compositions across objects.

approach

encoder

predict primitive parameters: size, rotation, translation of m cuboids. 

predictor

for primitive parameters

unsupervised parsing

each point is colored according to the assigned primitive

approach

predict primitive parameters: size, rotation, translation of m cuboids. 

variable number of parts? we predict    primitive existence id203   

id168

loss

id168 construction

basic idea: chamfer distance!

id168 construction

sample points on the groundtruth mesh and predicted assembly 
 

 

each point is a linear function of mesh/primitive vertex coordinates

differentiable!

id168 construction

sample points on the groundtruth mesh and predicted assembly 
 

 

each point is a linear function of mesh/primitive vertex coordinates

differentiable!

speed up the computation leveraging parameterization of primitives

consistent primitive configurations

primitive locations are consistent due to 

the smoothness of primitive prediction network

unsupervised parsing

mean accuracy (face area) on shape coseg chairs.

analysis

shapes become more parsimonious as training 

progresses (due to our parsimony reward)

image-based modeling

open problems

how to introduce other primitives types? 

towards image based modeling, how to add more operations to edit 
those primitives?  

    e.g., deform? extrude? loop cut? 

how to use it for design purposes? for example, with certain structural 
and functional constraints. 

ultimately, we expect to automate the modeling process from images, 
as artists do.

