intro to neural networks

part 1: what is a neural network

lisbon machine learning school

july 2017

what   s in this tutorial

    we will learn about

    what is a neural network
    what can neural networks model
    issues with learning
    some basic models: id98s and id56s

instructor

    bhiksha raj

professor,
language technologies institute
carnegie mellon univ.
    bhiksha@cs.cmu.edu

neural networks are taking over!

    neural networks have become one of the 

major thrust areas recently in various pattern 
recognition, prediction, and analysis problems

    in many problems they have established the 

state of the art
    often exceeding previous benchmarks by large 

margins

recent success with neural networks

    some recent successes with neural networks

    a bit of hyperbole, but still..

recent success with neural networks

    some recent successes with neural networks

recent success with neural networks

    some recent successes with neural networks

recent success with neural networks

    captions generated entirely by  a neural 

network

successes with neural networks

    and a variety of other problems:

    image recognition
    signal enhancement
    even predicting stock markets!

neural nets and the employment 

market

this guy didn   t know 
about neural networks 
(a.k.a deep learning)

this guy learned 
about neural networks 
(a.k.a deep learning)

so what are neural networks??

voice 
signal

n.net

transcription

image

n.net

text caption

game
state

n.net

next move

    what are these boxes?

so what are neural networks??

    it begins with this..

so what are neural networks??

   the thinker!   
by augustin rodin

    or even earlier.. with this..

the magical capacity of humans

    humans can

    learn
    solve problems
    recognize patterns
    create
    cogitate
       

    worthy of emulation
    but how do humans    work   ?

dante!

cognition and the brain..

       if the brain was simple enough to be 

understood - we would be too simple to 
understand it!    
    marvin minsky

early models of human cognition

    associationism

    humans learn through association

    400bc-1900ad: plato,  david hume,  ivan pavlov..

what are    associations   

    lightning is generally followed by thunder

    ergo        hey here   s a bolt of lightning,  we   re going to hear 

thunder   

    ergo        we just heard thunder; did someone get hit by 

lightning   ?

    association!

observation: the brain

    mid 1800s:  the brain is a mass of 

interconnected neurons

brain: interconnected neurons

    many neurons connect in to each neuron
    each neuron connects out to many neurons

enter connectionism

    alexander bain, philosopher, mathematician, logician, 

linguist, professor

    1873: the information is in the connections

    the mind and body (1873)

bain   s idea : neural groupings

    neurons excite and stimulate each other
    different combinations of inputs can result in 

different outputs

bain   s idea : neural groupings

    different intensities of 
activation of a lead to 
the differences in 
when x and y are 
activated

bain   s idea 2: making memories

       when two impressions concur, or closely 

succeed one another, the nerve currents find 
some bridge or place of continuity, better or 
worse, according to the abundance of nerve 
matter available for the transition.   

    predicts    hebbian    learning (half a century 

before hebb!)

bain   s doubts

   

   

   

   the fundamental cause of the trouble is that in the modern world 
the stupid are cocksure while the intelligent are full of doubt.   
    bertrand russell 

in 1873, bain postulated that there must be one million neurons and 
5 billion connections relating to 200,000    acquisitions   

in 1883, bain was concerned that he hadn   t taken into account the 
number of    partially formed associations    and the number of neurons 
responsible for recall/learning

    by the end of his life (1903), recanted all his ideas!

    too complex;  the brain would need too many neurons and connections

connectionism lives on..

    the human brain is a connectionist machine

    bain, a. (1873). mind and body. the theories of their 

relation. london: henry king.

    ferrier, d. (1876). the functions of the brain. london: 

smith, elder and co

    neurons connect to other neurons.  
the processing/capacity of the brain 
is a function of these connections

    connectionist machines emulate this structure

connectionist machines

    network of processing elements
    all world knowledge is stored in the connections 

between the elements

connectionist machines

    neural networks are connectionist machines

    as opposed to von neumann machines

von neumann/harvard machine

neural network

processor

processing
unit

program

data

memory

network

    the machine has many non-linear processing units
    the program is the connections between these units

    connections may also define memory

recap

    neural network based ai has taken over most ai tasks
    neural networks originally began as computational models 

of the brain
    or more generally, models of cognition

    the earliest model of cognition was associationism
    the more recent model of the brain is connectionist

    neurons connect to neurons
    the workings  of the brain are encoded in these connections

    current neural network models are connectionist machines

connectionist machines

    network of processing elements

    all world knowledge is stored in the 

connections between the elements

connectionist machines

    connectionist machines are networks of 

units..

    we need a model for the units

modelling the brain

    what are the units?
    a neuron:

soma

dendrites

axon

    signals come in through the dendrites into the soma
    a signal goes out via the axon to other neurons

    only one axon per neuron

    factoid that may only interest me: neurons do not undergo cell 

division

mccullough and pitts

    the doctor and the hobo..

    warren mcculloch:  neurophysician
    walter pitts: homeless wannabe logician who 

arrived at his door

the mcculloch and pitts model

a single neuron

    a mathematical model of a neuron

    mcculloch, w.s. & pitts, w.h. (1943). a logical 

calculus of the ideas immanent in nervous activity, 
bulletin of mathematical biophysics, 5:115-137, 1943

    pitts was only 20 years old at this time

    threshold logic

synaptic model

    excitatory synapse:  transmits weighted input 

to the neuron

    inhibitory synapse: any signal from an 

inhibitory synapse forces output to zero
    the activity of any inhibitory synapse absolutely 

prevents excitation of the neuron at that time.
    regardless of other inputs

simple    networks   
of neurons can perform
boolean operations

boolean gates

criticisms

    several..

    claimed their machine could emulate a turing

machine

    didn   t provide a learning mechanism..

donald hebb

       organization of behavior   , 1949
    a learning mechanism:

    neurons that fire together wire together

hebbian learning

axonal connection from
neuron x

dendrite of neuron y

   

   

if neuron          repeatedly triggers neuron     , the synaptic knob 
connecting          to      gets larger
in a mathematical model:

         =          +                 

    weight of     th neuron   s input to output neuron     

    this simple formula is actually the basis of many learning 

algorithms in ml

a better model

    frank rosenblatt

    psychologist, logician
    inventor of the solution to everything, aka the id88 (1958)

simplified mathematical model

    number of inputs combine linearly

    threshold logic:  fire if combined input exceeds 

threshold

     =    

1             

                 +      > 0

    

0

                

his    simple    id88

    originally assumed could represent any boolean circuit and 

perform any logic
       the embryo of an electronic computer that [the navy] expects 

will be able to walk, talk, see, write, reproduce itself and be 
conscious of its existence,    new york times (8 july) 1958

       frankenstein monster designed by navy that thinks,    tulsa, 

oklahoma times 1958

also provided a learning algorithm

     =      +                        (    )     

sequential learning:

          is the desired output in response to input     
          is the actual output in response to     

    boolean tasks
    update the weights whenever the id88 

output is wrong

    proved convergence

id88

1

1

x

y

2

x

y

1

1

x     y

-1

x

0

   x

1

x     y

    easily shown to mimic any boolean gate

    but   

id88

no solution for xor!
not universal!

?

?

x

y

?

x   y

    minsky and papert,  1968

a single neuron is not enough

    individual elements are weak computational elements
    marvin minsky and seymour papert, 1969,  id88s: 

an introduction to computational geometry

    networked elements are required

multi-layer id88!

x

y

1

-1

1

-1

1

-1

x     y

1

1

   x        y

hidden layer

2

x   y

    xor

    the first layer is a    hidden    layer

    also originally suggested by minsky and paper 1968

46

a more generic model

(     &        &     |     &         )&(      &      |     &     )

12

1

10

1

-1

2
1

1

1

12

1

x

1

y

1

1

1
1

-1

1

z

11

1

1
1

1

-1
1

a

    a    multi-layer    id88
    can compose arbitrarily complicated boolean 

functions!
    more on this in the next part

story so far

    neural networks began as computational models of the brain
    neural network models are connectionist machines

    the comprise networks of neural units

    mccullough and pitt model: neurons as boolean threshold units

    models the brain as performing id118
    but no learning rule

    hebb   s learning rule: neurons that fire together wire together

    unstable

    rosenblatt   s id88 : a variant of the mcculloch and pitt neuron with 

a provably convergent learning rule
    but individual id88s are limited in their capacity (minsky and papert)

    multi-layer id88s can model arbitrarily complex boolean functions

but our brain is not boolean

    we have real inputs
    we make non-boolean id136s/predictions

the id88 with real inputs

x1

x2

x3

xn

    x1   xn are real valued
    w1   wn are real valued
    unit    fires    if weighted input exceeds a threshold

the id88 with real inputs

and a real output

x1

x2

x3

xn

sigmoid

     =                             (   

                )

    

    x1   xn are real valued
    w1   wn are real valued
    the output y can also be real valued

    sometimes viewed as the    id203    of firing
    is useful to continue assuming boolean outputs though

a id88 on reals

x1

x2

x3

xn

1             

        x             

     =    

    
0                 

    a id88 operates on 

real-valued vectors
    this is a linear classifier

x2

0

1

x1

x2

w1x1+w2x2=t

x1

52

boolean functions with a real 

id88

1,1

0,1

x

1,1

0,1

x

1,1

0,1

y

0,0

y

1,0

0,0

y

1,0

0,0

x

1,0

    boolean id88s are also linear classifiers

    purple regions have output 1 in the figures
    what are these functions
    why can we not compose an xor?

composing complicated    decision    

boundaries

x2

can now be composed into
   networks    to compute arbitrary
classification    boundaries   

x1

    build a network of units with a single output 

that fires if the input is in the coloured area

54

booleans over the reals

x2

x1

x2

x1

    the network must fire if the input is in the 

coloured area 

55

booleans over the reals

x2

x1

x2

x1

    the network must fire if the input is in the 

coloured area 

56

booleans over the reals

x2

x1

x2

x1

    the network must fire if the input is in the 

coloured area 

57

booleans over the reals

x2

x1

x2

x1

    the network must fire if the input is in the 

coloured area 

58

booleans over the reals

x2

x1

x2

x1

    the network must fire if the input is in the 

coloured area 

59

booleans over the reals

3

4

3

4

3

4

x2
x2

5

4

3

x1
x1

4

3

y         5?

    

   
    =1
and

y1

y2 y3

y4

y5

x2

x1

    the network must fire if the input is in the 

coloured area 

60

more complex decision boundaries

or

and

and

x2

x1

x1

x2

    network to fire if the input is in the yellow area

       or    two polygons
    a third layer is required

61

complex decision boundaries

    can compose very complex decision boundaries

    how complex exactly?  more on this in the next class

62

complex decision boundaries

784 dimensions
(mnist)

2

                 

784 dimensions

    classification problems:  finding decision 

boundaries in high-dimensional space

63

story so far

    mlps are connectionist computational models

    individual id88s are computational equivalent of neurons
    the mlp is a layered composition of many id88s

    mlps can model boolean functions

    individual id88s can act as boolean gates
    networks of id88s are  boolean functions

    mlps are boolean machines

    they represent boolean functions over linear boundaries
    they can represent arbitrary  decision boundaries
    they can be used to classify data

64

so what does the id88 really 

model?

    is there a    semantic    interpretation?

lets look at the weights

     =    

1             

        x             

    
0                 

     =    1                               

0                 

x1
x2

x3

xn

    what do the weights tell us?

    the neuron fires if the inner product between the 

weights and the inputs exceeds a threshold

66

the weight as a    template   

x1
x2

x3

xn

                  >

             >     
    
    
     <                         
    

w

    the id88 fires if the input is within a specified angle 

of the weight

    neuron fires if the input  vector is close enough to the 

weight vector.
    if the input pattern matches the weight pattern closely enough

67

the weight as a template

w

x

x

     =    

1             

        x             

    
0                 

correlation = 0.57

correlation = 0.82

    if the correlation between the weight pattern 

and the inputs exceeds a threshold, fire

    the id88 is a correlation filter!

68

the mlp as a boolean function over 

feature detectors

digit or not?

    the input layer comprises    feature detectors   

    detect if certain patterns have occurred in the input

    the network is a boolean function over the feature detectors
   

i.e. it is important for the first layer to capture relevant patterns

69

the mlp as a cascade of feature 

detectors

digit or not?

    the network is a cascade of feature detectors
    higher level neurons compose complex templates 
from features represented by lower-level neurons

70

story so far

    multi-layer id88s are connectionist computational models
    mlps are boolean machines

    they can model boolean functions
    they can represent arbitrary  decision boundaries over real inputs

    id88s are correlation filters
    they detect patterns in the input

    mlps are boolean formulae over patterns detected by 

id88s
    higher-level id88s may also be viewed as feature detectors

    extra: mlp in classification

    the network will fire if the combination of  the detected basic features 

matches an    acceptable    pattern for a desired class of signal

    e.g.  appropriate combinations of (nose, eyes, eyebrows, cheek, chin)     face
71

mlp as a continuous-valued regression

x

1

1

t1
t1

t2

t2

1

+

-1

f(x)

t1 t2 x

    a simple 3-unit mlp with a    summing    output unit can 

generate a    square pulse    over an input
    output is 1 only if the input lies between t1 and t2
    t1 and t2 can be arbitrarily specified

72

mlp as a continuous-valued regression

x

1

1

1

-1

t1
t1

t2

t2

f(x)

t1 t2 x

   2

   1

       

x

      1

+

      2

          

    a simple 3-unit mlp can generate a    square pulse    over an input
    an mlp with many units can model an arbitrary function over an input

    to arbitrary precision

    simply make the individual pulses narrower

   

this generalizes to functions of any number of inputs (next part)

73

story so far

    multi-layer id88s are connectionist 

computational models

    mlps are classification engines

    they can identify classes in the data

    individual id88s are feature detectors

    the network will fire if the combination of  the 

detected basic features matches an    acceptable    
pattern for a desired class of signal

    mlp can also model continuous valued functions

74

neural networks: 

part 2: what can a network 

represent

recap: the id88

    1

    2
    3

.....

        

    

     =    

w    x             

    

     =    

1          z     0

0                 

    

+

       

x1

x2
x3

x    

    a threshold unit

       fires    if the weighted sum of inputs and the 

   bias    t is positive

the    soft    id88

    1

    

     =    

w    x             

    

     =

1

1 +                     

    

+

       

    2
    3

.....

        

x1

x2
x3

x    

    a    squashing    function instead of a threshold 

at the output
    the sigmoid    activation    replaces the threshold
    activation: the function that acts on the weighted 

combination of inputs (and threshold)

other    activations   

    1

    2
    3

.
.
.
.
.

        

x1
x2
x3

x    

    

    

+

    

sigmoid

tanh

    does not always have to be a squashing function
    we will continue to assume a    threshold    activation in this 

lecture

recap: the multi-layer id88

    a network of id88s

    generally    layered   

aside:  note on    depth   

    what is a    deep    network

deep structures

    in any directed network of computational 

elements with input source nodes and output 
sink nodes,    depth    is the length of the 
longest path from a source to a sink

    left: depth = 2.        right: depth = 3

deep structures

    layered deep structure

       deep        depth > 2

the multi-layer id88

    inputs are real or boolean stimuli
    outputs are real or boolean values

    can have multiple outputs for a single input 

    what can this network compute?

    what kinds of input/output relationships can it model?

mlps approximate functions

(     &        &     |     &         )&(      &      |     &     )

12

1

10

1

-1

2
1

1

1

12

1

x

1

y

1

1

1
1

-1

1

z

11

1

1
1

1

-1
1

a

   2

       

x

    mlps can compose boolean functions
    mlps can compose real-valued functions
    what are the limitations?

the mlp as a boolean function

    how well do mlps model boolean functions?

the id88 as a boolean gate

1

1

x

y

2

x

y

1

1

x     y

-1

x

0

   x

1

x     y

    a id88 can model any simple binary 

boolean gate

id88 as a boolean gate

1

1

1
-1
-1

-1

    1
    2
   
        
        +1
        +2
   
        

l

    

   
    =1

    
                
    =    +1

           

will fire only if x1 .. xl are all 1
and xl+1 .. xn are all 0

    the universal and gate

    and any number of inputs

    any subset of who may be negated

id88 as a boolean gate

1

1

1
-1
-1

-1

    1
    2
   
        
        +1
        +2
   
        

l-n+1

    

   
    =1

    
                
    =    +1

           

will fire only if any of x1 .. xl are 1
or any of xl+1 .. xn are 0

    the universal or gate

    or any number of inputs

    any subset of who may be negated

id88 as a boolean gate

1

1

1
-1
-1

-1

    1
    2
   
        
        +1
        +2
   
        

l-n+k

will fire only if the total number of
of x1 .. xl that are 1 or xl+1 .. xn that
are 0 is at least k

    universal or:

    fire if any k-subset of inputs is    on   

the id88 is not enough

?

?

x

y

?

x   y

    cannot compute an xor

multi-layer id88

1

-1

1

-1

x

y

1

-1

x     y

1

1

   x        y

hidden layer

    mlps can compute the xor

2

x   y

multi-layer id88

(     &        &     |     &         )&(      &      |     &     )

12

1

10

1

-1

2
1

1

1

12

1

x

1

y

1

1

1
1

-1

1

z

11

1

1
1

1

-1
1

a

    mlps can compute more complex boolean functions 

    mlps can compute any boolean function

    since they can emulate individual gates

    mlps are universal boolean functions

mlp as boolean functions

(     &        &     |     &         )&(      &      |     &     )

12

1

10

1

-1

2
1

1

1

12

1

x

1

y

1

1

1
1

-1

1

z

11

1

1
1

1

-1
1

a

    mlps are universal boolean functions

    any function over any number of inputs and any number 

of outputs

    but how many    layers    will they need?

how many layers for a boolean mlp?

truth table

truth table shows all input combinations
for which output is 1

x1 x2 x3 x4 x5 y
0
1

0

1

1

0

0

0

1

1

1

1

1

0

0

1

0

1

0

1

0

1

0

0

1

0

1

0

1

1

1

1

1

1

1

1

    expressed in disjunctive normal form

how many layers for a boolean mlp?

truth table

x1 x2 x3 x4 x5 y
0
1

0

1

1

0

truth table shows all input combinations
for which output is 1

     =        1        2    3    4        5 +        1    2        3    4    5 +        1    2    3        4        5 +

    1        2        3        4    5 +     1        2    3    4    5 +     1    2        3        4    5

0

0

1

1

1

1

1

0

0

1

0

1

0

1

0

1

0

0

1

0

1

0

1

1

1

1

1

1

1

1

    expressed in disjunctive normal form

how many layers for a boolean mlp?

truth table

x1 x2 x3 x4 x5 y
0
1

0

1

1

0

truth table shows all input combinations
for which output is 1

     =        1        2    3    4        5 +        1    2        3    4    5 +        1    2    3        4        5 +

    1        2        3        4    5 +     1        2    3    4    5 +     1    2        3        4    5

0

0

1

1

1

1

1

0

0

1

0

1

0

1

0

1

0

0

1

0

1

0

1

1

1

1

1

1

1

1

x1

x2

x3

x4

x5

    expressed in disjunctive normal form

how many layers for a boolean mlp?

truth table

x1 x2 x3 x4 x5 y
0
1

0

1

1

0

truth table shows all input combinations
for which output is 1

     =        1        2    3    4        5 +        1    2        3    4    5 +        1    2    3        4        5 +

    1        2        3        4    5 +     1        2    3    4    5 +     1    2        3        4    5

0

0

1

1

1

1

1

0

0

1

0

1

0

1

0

1

0

0

1

0

1

0

1

1

1

1

1

1

1

1

x1

x2

x3

x4

x5

    expressed in disjunctive normal form

how many layers for a boolean mlp?

truth table

x1 x2 x3 x4 x5 y
0
1

0

1

1

0

truth table shows all input combinations
for which output is 1

     =        1        2    3    4        5 +        1    2        3    4    5 +        1    2    3        4        5 +

    1        2        3        4    5 +     1        2    3    4    5 +     1    2        3        4    5

0

0

1

1

1

1

1

0

0

1

0

1

0

1

0

1

0

0

1

0

1

0

1

1

1

1

1

1

1

1

x1

x2

x3

x4

x5

    expressed in disjunctive normal form

how many layers for a boolean mlp?

truth table

x1 x2 x3 x4 x5 y
0
1

0

1

1

0

truth table shows all input combinations
for which output is 1

     =        1        2    3    4        5 +        1    2        3    4    5 +        1    2    3        4        5 +

    1        2        3        4    5 +     1        2    3    4    5 +     1    2        3        4    5

0

0

1

1

1

1

1

0

0

1

0

1

0

1

0

1

0

0

1

0

1

0

1

1

1

1

1

1

1

1

x1

x2

x3

x4

x5

    expressed in disjunctive normal form

how many layers for a boolean mlp?

truth table

x1 x2 x3 x4 x5 y
0
1

0

1

1

0

truth table shows all input combinations
for which output is 1

     =        1        2    3    4        5 +        1    2        3    4    5 +        1    2    3        4        5 +

    1        2        3        4    5 +     1        2    3    4    5 +     1    2        3        4    5

0

0

1

1

1

1

1

0

0

1

0

1

0

1

0

1

0

0

1

0

1

0

1

1

1

1

1

1

1

1

x1

x2

x3

x4

x5

    expressed in disjunctive normal form

how many layers for a boolean mlp?

truth table

x1 x2 x3 x4 x5 y
0
1

0

1

1

0

truth table shows all input combinations
for which output is 1

     =        1        2    3    4        5 +        1    2        3    4    5 +        1    2    3        4        5 +

    1        2        3        4    5 +     1        2    3    4    5 +     1    2        3        4    5

0

0

1

1

1

1

1

0

0

1

0

1

0

1

0

1

0

0

1

0

1

0

1

1

1

1

1

1

1

1

x1

x2

x3

x4

x5

    expressed in disjunctive normal form

how many layers for a boolean mlp?

truth table

x1 x2 x3 x4 x5 y
0
1

0

1

1

0

truth table shows all input combinations
for which output is 1

     =        1        2    3    4        5 +        1    2        3    4    5 +        1    2    3        4        5 +

    1        2        3        4    5 +     1        2    3    4    5 +     1    2        3        4    5

0

0

1

1

1

1

1

0

0

1

0

1

0

1

0

1

0

0

1

0

1

0

1

1

1

1

1

1

1

1

x1

x2

x3

x4

x5

    expressed in disjunctive normal form

how many layers for a boolean mlp?

truth table

x1 x2 x3 x4 x5 y
0
1

0

1

1

0

truth table shows all input combinations
for which output is 1

     =        1        2    3    4        5 +        1    2        3    4    5 +        1    2    3        4        5 +

    1        2        3        4    5 +     1        2    3    4    5 +     1    2        3        4    5

0

0

1

1

1

1

1

0

0

1

0

1

0

1

0

1

0

0

1

0

1

0

1

1

1

1

1

1

1

1

x1

x2

x3

x4

x5

    any truth table can be expressed in this manner!
    a one-hidden-layer mlp is a universal boolean function

but what is the largest number of id88s required in the 
single hidden layer for an n-input-variable function?

reducing a boolean function

yz

wx

00

01

11

10

00

01

11

10

this is a    karnaugh map   

it represents a truth table as a grid
filled boxes represent input combinations
for which output is 1; blank boxes have
output 0

adjacent boxes can be    grouped    to 
reduce the complexity of the dnf formula 
for the table

    dnf form:

    find groups
    express as reduced dnf

reducing a boolean function
00

01

11

10

basic dnf formula will require 7 terms

yz

wx

00

01

11

10

reducing a boolean function
00

01

11

10

     =                +                     +                   

yz

wx

00

01

11

10

    reduced dnf form:

    find groups
    express as reduced dnf

reducing a boolean function
00

01

11

10

     =                +                     +                   

yz

wx

00

01

11

10

    reduced dnf form:

w

x

y

z

    find groups
    express as reduced dnf

largest irreducible dnf?
yz

wx

00

01

11

10

00

01

11

10

    what arrangement of ones and zeros simply 

cannot be reduced further?

largest irreducible dnf?

yz

wx

00

01

11

10

00

01

11

10

    what arrangement of ones and zeros simply 

cannot be reduced further?

largest irreducible dnf?

yz

wx

00

01

11

10

00

01

11

10

how many neurons 
in a dnf (one-
hidden-layer) mlp 
for this boolean 
function?

    what arrangement of ones and zeros simply 

cannot be reduced further?

width of a single-layer boolean mlp

yz

wx

00

01

11

10

10

11

01
00 yz

00

01

11

10

uv

    how many neurons in a dnf (one-hidden-
layer) mlp for this boolean function of 6 
variables?

width of a single-layer boolean mlp

yz

wx

00

can be generalized: will require 2n-1
id88s in hidden layer
exponential in n

01

11

10

00

uv

01

11

10

11

01
00 yz

10

    how many neurons in a dnf (one-hidden-

layer) mlp for this boolean function

width of a single-layer boolean mlp

yz

wx

can be generalized: will require 2n-1
id88s in hidden layer
exponential in n

01

11

10

11

01
00 yz

how many units if we use multiple layers?

00

01

11

10

    how many neurons in a dnf (one-hidden-

layer) mlp for this boolean function

00

10

uv

width of a deep mlp

00

01

11

10

wx

yz

00

01

11

10

00

uv

01

11

10

10

11

01
yz

00

wx

yz

00

01

11

10

     =                                

     =                                                  

multi-layer id88 xor

x

y

1

-1

1

-1

1

-1

x     y

1

1

   x        y

hidden layer

2

x   y

    an xor takes three id88s

width of a deep mlp

00

01

11

10

9 id88s

wx

yz

00

01

11

10

     =                                

w

x

y

z

    an xor needs 3 id88s

    this network will require 3x3 = 9 id88s

width of a deep mlp

wx

yz

00

01

11

10

00

uv

01

11

10

10

11

01
yz

00

     =                                                  

u v

w x

y z

15 id88s

    an xor needs 3 id88s

    this network will require 3x5 = 15 id88s

width of a deep mlp

wx

yz

00

01

11

10

00

uv

01

11

10

10

11

01
yz

00

u v

w x

y z

     =                                                  

more generally, the xor of n 
variables will require 3(n-1) 
id88s!!

    an xor needs 3 id88s

    this network will require 3x5 = 15 id88s

width of a single-layer boolean mlp

yz

wx

single hidden layer: will require 2n-1+1 
id88s in all (including output unit)
exponential in n

01

11

00

10

10

11

01
00 yz

10

11

01

00

uv

    how many neurons in a dnf (one-hidden-

will require 3(n-1) id88s in a deep 
network
linear in n!!!
can be arranged in only 2log2(n) layers

layer) mlp for this boolean function

a better representation

     =     1         2                     

    1

        

    only 2 log2      layers

    by pairing terms
    2 layers per xor

     = (((((    1        2)     (    1        2))    

((    5        6)     (    7        8)))     (((   

the challenge of depth

    1

    1

      

        

        

     =     1         2                     
=     1         2                     

    using only k hidden layers will require o(2(n-k/2)) neurons in the kth layer

    because the output can be shown to be the xor of all the outputs of the k-1th 

hidden layer 

    i.e. reducing the number of layers below the minimum will result in an 

exponentially sized network to express the function fully

    a network with fewer than the required number of neurons cannot model the 

function

recap: the need for depth

    deep boolean mlps that scale linearly with 

the number of inputs    

        can become exponentially large if recast 

using only one layer

    it gets worse..

the need for depth

                                                 

a

b

c

d

e

f

x1

x2

x3

x4

x5

    the wide function can happen at any layer
    having a few extra layers can greatly reduce network 

size

network size: summary

    an mlp is a universal boolean function

    but can represent a given function only if

    it is sufficiently wide
    it is sufficiently deep
    depth can be traded off for (sometimes) exponential growth of the 

width of the network

    optimal width and depth depend on the number of variables and 

the complexity of the boolean function
    complexity:  minimal number of terms in dnf formula to represent it

story so far

    multi-layer id88s are universal boolean machines

    even a network with a single hidden layer is a universal 

boolean machine
    but a single-layer network may require an exponentially 

large number of id88s

    deeper networks may require far fewer neurons than 

shallower networks to express the same function
    could be exponentially smaller

the mlp as a classifier

784 dimensions
(mnist)

2

                 

784 dimensions

    mlp as a function over real inputs

    mlp as a function that finds a complex    decision 

boundary    over a space of reals

126

a id88 on reals

x1

x2

x3

xn

1             

        x             

     =    

    
0                 

    a id88 operates on 

real-valued vectors
    this is a linear classifier

x2

0

1

x1

x2

w1x1+w2x2=t

x1

127

booleans over the reals

3

4

3

4

3

4

x2
x2

5

4

3

x1
x1

4

3

y         5?

    

   
    =1
and

y1

y2 y3

y4

y5

x2

x1

    the network must fire if the input is in the 

coloured area 

128

more complex decision boundaries

or

and

and

x2

x1

x1

x2

    network to fire if the input is in the yellow area

       or    two polygons
    a third layer is required

129

complex decision boundaries

    can compose arbitrarily complex decision 

boundaries

130

complex decision boundaries

or

and

    can compose arbitrarily complex decision 

x1

x2

boundaries

131

complex decision boundaries

or

and

    can compose arbitrarily complex decision boundaries

x1

x2

    with only one hidden layer!

    how?

132

exercise: compose this with one 

hidden layer

x2

x1

x1

x2

    how would you compose the decision boundary 

to the left with only one hidden layer?

133

composing a square decision 

boundary

2

2

4

2

4

   
    =1

y         4?

2

y1

y2

y3

y4

x2

x1

    the polygon net

134

composing a pentagon

2

3

4

4

3

2

3

4

4

3

3

5

4

2

2

5

   
    =1

y         5?

y1

y2

y3

y4

y5

x2

x1

2

    the polygon net

135

composing a hexagon

3

3

4

4

5

5

4

3

5

6

5

3

3

3

4

5

5

4

    

   
    =1

y         6?

y1

y2

y3

y4

y5

y6

x2

x1

    the polygon net

136

how about a heptagon

3

4

3

4

5

6

5

5

6

4

6

4

6

7

5

3

6

4

5

6

6

4

5

5

    what are the sums in the different regions?

    a pattern emerges as we consider n > 6..

3

composing a polygon

    

   
    =1

y             ?

4

4

4

4

4

5

4

y1

y2

y3

y4

y5

x2

x1

5

5

5

6

5

5

5

    the polygon net

    increasing the number of sides reduces the area 

outside the polygon that have n/2 < sum < n

138

composing a circle

n

    

   
    =1

y             ?

n/2

    the circle net

    very large number of neurons

    sum is n inside the circle, n/2 outside everywhere
    circle can be of arbitrary diameter, at any location139

composing a circle

n/2

0

    

   
    =    

            

    
    

>     ?

       /2

1

    the circle net

    very large number of neurons

    sum is n/2 inside the circle, 0 outside everywhere
    circle can be of arbitrary diameter, at any location140

adding circles

        

   
    =    

                  >     ?

    the    sum    of two circles sub nets is exactly n/2 

inside either circle, and 0 outside

141

composing an arbitrary figure

        

   
    =    

            

        
    

>     ?

            

    just fit in an arbitrary number of circles

    more accurate approximation with greater number of 

smaller circles

    can achieve arbitrary precision

142

mlp: universal classifier

        

   
    =    

            

        
    

>     ?

            

    mlps can capture any classification boundary
    a one-layer mlp can model any classification 

boundary

    mlps are universal classifiers

143

depth and the universal classifier

x2

x1

x1

x2

    deeper networks can require far fewer neurons

optimal depth

        

   
    =    

            

        
    

>     ?

            

    a one-hidden-layer neural network will 

required infinite hidden neurons

optimal depth

    two layer network: 56 hidden neurons

optimal depth

    1

    5

    9

    2

    6

    3

    7

    10

    11

    13

    14

    15

    4

    8

    12

    16

    1     2     3

    16

    two layer network: 56 hidden neurons

    16 neurons in hidden layer 1

optimal depth

    two-layer network: 56 hidden neurons

    16 in hidden layer 1
    40 in hidden layer 2
    57 total neurons, including output neuron

optimal depth

    1

    5

    9

    2

    6

    3

    7

    10

    11

    13

    14

    15

    4

    8

    12

    16

    1     2     3

    16

    but this is just     1         2                 16

optimal depth

    but this is just     1         2                 16

    the xor net will require 16 + 15x3 = 61 neurons

    greater than the 2-layer network with only 52 neurons

optimal depth

        

   
    =    

            

        
    

>     ?

            

    a one-hidden-layer neural network will 

required infinite hidden neurons

actual linear units

    1     2     3

   .

    64

    64 basic linear feature detectors

optimal depth

   .
   .

    two hidden layers:  608 hidden neurons

    64 in layer 1
    544 in layer 2 

    609 total neurons (including output neuron)

optimal depth

   .   .   .   .   .   .

    xor network (12 hidden layers): 253 neurons
    the difference in size between the deeper optimal (xor) net and 

shallower nets increases with increasing pattern complexity

network size?

   

   

   

in this problem the 2-layer net
was quadratic in the number of
lines
    (     + 2)2/8 neurons in 2nd hidden layer
    not exponential
    even though the pattern is an xor
    why?
the data are two-dimensional!
    the pattern is exponential in the dimension of the input (two)!
for general case of      lines distributed over      dimensions, we will need up 

    

to 

1
2

    
    

+ 1

    increasing input dimensions can increase the worst-case size of the shallower 

network exponentially, but not the xor net

    the size of the xor net depends only on the number of first-level linear detectors (    )

depth: summary

    the number of neurons required in a shallow 

network is 
    polynomial in the number of basic patterns
    exponential in the dimensionality of the input
    (this is the worst case) 

story so far

    multi-layer id88s are universal boolean machines

    even a network with a single hidden layer is a universal boolean machine

    multi-layer id88s are universal classification functions
    even a network with a single hidden layer is a universal classifier

    but a single-layer network may require an exponentially large number 

of id88s than a deep one

    deeper networks may require exponentially fewer neurons than 

shallower networks to express the same function
    could be exponentially smaller
    deeper networks are more expressive

mlp as a continuous-valued regression

x

1

1

t1
t1

t2

t2

1

+

-1

f(x)

t1 t2 x

    a simple 3-unit mlp with a    summing    output unit can 

generate a    square pulse    over an input
    output is 1 only if the input lies between t1 and t2
    t1 and t2 can be arbitrarily specified

158

mlp as a continuous-valued regression

x

1

1

1

-1

t1
t1

t2

t2

f(x)

t1 t2 x

   2

   1

       

x

      1

+

      2

          

    a simple 3-unit mlp can generate a    square pulse    over an input
    an mlp with many units can model an arbitrary function over an input

    to arbitrary precision

    simply make the individual pulses narrower

    a one-layer mlp can model an arbitrary function of a single input

159

for higher-dimensional functions

n

+

n/2

    an mlp can compose a cylinder

    n in the circle,  n/2 outside

a    true    cylinder

n/2

0

+

-n/2

1

    an mlp can compose a true cylinder

    n/2 in the circle,  0 outside
    by adding a    bias   
    we will encounter bias terms again

    they are standard components of id88s

mlp as a continuous-valued function

      1

+

      2

          

   1

   2

    mlps can actually compose arbitrary functions

    even with only one layer

    as sums of scaled and shifted cylinders

    to arbitrary precision

    by making the cylinders thinner

    the mlp is a universal approximator!

       

162

the issue of depth

    previous discussion showed that a single-layer mlp is a 

universal function approximator
    can approximate any function to arbitrary precision
    but may require infinite neurons in the layer

    more generally, deeper networks will require far fewer 

neurons for the same approximation error
    the network is a generic map

    the same principles that apply for boolean networks apply here

    can be exponentially fewer than the 1-layer network

sufficiency of architecture

   ..

a network with 16 or more
neurons  in the first layer is 
capable of representing the 
figure to the right perfectly

a network with less than 
16 neurons  in the first 
layer cannot represent 
this pattern exactly
    with caveats..

a 2-layer network with 16 
neurons  in the first layer 
cannot represent the 
pattern with less than 41
neurons in the second layer

    a neural network can represent any function provided 

it has sufficient capacity

    i.e. sufficiently broad and deep to represent the function

    not all architectures can represent any function

sufficiency of architecture

   

the capacity of a network has various definitions

    information or storage capacity: how many patterns can it remember
    vc dimension

    bounded by the square of the number of weights in the network

    from our perspective: largest number of disconnected convex regions it can represent

    a network with insufficient capacity cannot exactly model a function that requires 

a greater minimal number of convex hulls than the capacity of the network

    but can approximate it with error

lessons

    mlps are universal boolean function
    mlps are universal classifiers
    mlps are universal function approximators

    a single-layer mlp can approximate anything to arbitrary precision

    but could be exponentially or even infinitely wide in its inputs size

    deeper mlps can achieve the same precision with far fewer 

neurons
    deeper networks are more expressive

learning the network

    the neural network can approximate any function
    but only if the function is known a priori

171

learning the network

    in reality, we will only get a few snapshots of the function 

to learn it from

    we must learn the entire function from these    training    

snapshots

general approach to training

blue lines: error when
function is below desired
output

black lines: error when
function is above desired
output

     =    

                 (        ,     ) 2

    

    define an error between the actual network output for 

any parameter value and the desired output
    error typically defined as the sum of the squared error over 

individual training instances

general approach to training

    problem:  network may just learn the values at the inputs

    learn the red curve instead of the dotted blue one

    given only the red vertical bars as inputs

    need    smoothness    constraints

data under-specification in learning

   

   

   

consider a binary 100-dimensional input
there are 2100=1030 possible inputs
complete specification of the function will require specification of 1030 output 
values

    a training set with only  1015 training instances will be off by a factor of 1015

175

data under-specification in learning

find the function!

   

   

   

consider a binary 100-dimensional input
there are 2100=1030 possible inputs
complete specification of the function will require specification of 1030 output 
values

    a training set with only  1015 training instances will be off by a factor of 1015

176

data under-specification in learning

    mlps naturally impose constraints

    mlps are universal approximators
    arbitrarily increasing size can give 

you arbitrarily wiggly functions

    the function will remain ill-defined 

on the majority of the space

    for a given number of parameters deeper networks 

impose more smoothness than shallow ones
    each layer works on the already smooth surface output by 

the previous layer

177

even when we get it all right

    typical results (varies with initialization)
    1000 training points many orders of magnitude more than 

you usually get

    all the training tricks known to mankind

178

but depth and training data help

3 layers

4 layers

3 layers

4 layers

6 layers

11 layers

6 layers

11 layers

    deeper networks seem to learn better, for the same 

number of total neurons

    implicit smoothness constraints

    as opposed to explicit constraints from more conventional 

classification models

10000 training instances

   

similar functions not learnable using more usual 
pattern-recognition models!!

179

part 3: learning the network

nnets in ai

    the network is a function

    given an input, it computes the function layer 

wise to predict an output

these tasks are functions

voice 
signal

n.net

transcription

image

n.net

text caption

game
state

n.net

next move

    each of these boxes is actually a function

    e.g f: image     caption

questions

something
odd

n.net

something
weird

    preliminaries:

    how do we represent the input?

    how do we represent the output?

    how do we compose the network that performs 

the requisite function?

183

questions

something
odd

n.net

something
weird

    preliminaries:

    how do we represent the input?

    how do we represent the output?

    how do we compose the network that performs 

the requisite function?

184

the network as a function

input

output

   

inputs are numeric vectors
    numeric representation of input, e.g. audio, image, game state, etc.

    outputs are numeric scalars or vectors

    numeric    encoding    of output from which actual output can be derived
    e.g. a score, which can be compared to a threshold to decide if the input is a face or not
    output may be multi-dimensional, if task requires it

    more on this later

questions

something
odd

n.net

something
weird

    preliminaries:

    how do we represent the input?

    how do we represent the output?

    how do we compose the network that performs 

the requisite function?

186

recap

    neural networks are universal function approximators

    can model any boolean function
    can model any classification boundary
    can model any continuous valued function

    provided the network satisfies minimal architecture constraints
    networks with fewer than required parameters can be very poor 

approximators

187

the mlp can represent anything

    the mlp can be constructed to represent anything
    but how do we construct it?

188

empirical risk minimization

di

xi

    get samples from          

    basically, get input-output pairs for a number of samples of input         

    many samples (        ,         ), where          =              

    very easy to do in most problems:  just gather training data

    e.g. images and labels
    speech and transcriptions

189

empirical risk minimization

     =     (    ;     )

   

estimate

        = argmin

    

   

                          ;      ,         

    

    what is div()

    reduce the empirical error over the drawn samples
    note that this is the empirical estimate of the true id168 

                           ;      ,     (    )

di

xi

190

overall setting for    learning    the mlp

    

    

    

    

    given a training set of input-output pairs 

    1,     1 ,     2,      ,     ,         ,             
    d  is the desired output of the network in response to     
         and      may both be vectors

       we must find the network parameters (weights and biases) such 

that the network produces the desired output for each training 
input
    the architecture of the network must be specified by us

191

procedural outline

    1,     2,     ,         

actual output of network:
         =                      ;         ,    

            ,     ,     

=             (        ;     1,     2,     ,         )

desired output of network:         
error on i-th training input:             (        ,         ;     1,     2,     ,         )

total training error:

            (    1,     2,     ,         ) =    
    

            (        ,         ;     1,     2,     ,         )

    optimize network parameters to minimize the 

total error over all training inputs

192

problem statement

    minimize the following function

            (    1,     2,     ,         )

=    

            (        ,         ;     1,     2,     ,         )

    

w.r.t      1,     2,     ,         

    this is a problem of function minimization

    an instance of optimization

193

    a crash course on function 

optimization

194

the problem of optimization

    general problem of 

optimization: find 
the value of w where 
f(w) is minimum

195

f(x)xglobal minimuminflection pointlocal minimumglobal maximumfinding the minimum of a function

f(w)

        (    )

        

= 0

w

   

   

find the value      at which        (    ) = 0
    solve

        (    )

        

= 0

the solution is a    turning point   
    derivatives go from positive to negative or vice versa at this point

    but is it a minimum? 

196

soln: finding the minimum or 

maximum of a function

        (    )

= 0

f(w)

        

x

   

find the value      at which        (    ) = 0:    solve

        (    )

= 0

        
the solution                      is a turning point

   
    check the double derivative at                      : compute

                                =

           (                    )

        

   

if                                 is positive                      is a minimum, otherwise it is a maximum

197

what about functions of multiple 

variables?

   

the optimum point is still     turning    point
    shifting in any direction will increase the value
    for smooth functions, miniscule shifts will not result in any change at all
    we must find a point where shifting in any direction by a microscopic 

amount will not change the value of the function

198

a brief note on derivatives of 

multivariate functions

199

the gradient of a scalar function

        (    )

        

    the gradient          (    ) of a scalar function     (    ) of a 
multi-variate input      is a multiplicative factor that 
gives us the change in     (    ) for tiny variations in     

        (    ) =         (    )        

200

gradients of scalar functions with 

multi-variate inputs

    consider           =          1,     2,     ,         

        (    ) =

        (    )
            

        (    )
            

   

        (    )
            

    check:

              =                       

=

        (    )
        1

        (    )
        2

        1 +

        2 +     +

the gradient is the direction of fastest increase in f(x)

        (    )
            

            

201

gradient

gradient
vector         (    )

202

gradient

gradient
vector         (    )

moving in this 

direction increases 

          fastest

203

gradient

           (    )

moving in this 

direction decreases 

          fastest

gradient
vector         (    )

moving in this 

direction increases 

    (    ) fastest

204

gradient

gradient here
is 0

gradient here
is 0

205

properties of gradient: 2

    the gradient vector         (    ) is perpendicular to the level curve

206

the hessian

    the hessian of a function     (    1,     2,     ,         ) is 

given by the second derivative 

207

  2f(x1,...,xn):=  2f  x12  2f  x1  x2..  2f  x1  xn  2f  x2  x1  2f  x22..  2f  x2  xn..........  2f  xn  x1  2f  xn  x2..  2f  xn2                                                            returning to direct optimization   

208

finding the minimum of a scalar 
function of a multi-variate input

    the optimum point is a turning point     the 

gradient will be 0

209

unconstrained minimization of 

function (multivariate)

1. solve for the      where the gradient equation equals to 

zero

2. compute the hessian matrix     2    (    ) at the candidate 

solution and verify that
    hessian is positive definite (eigenvalues positive)  -> to 

identify local minima 

    hessian is negative definite (eigenvalues negative) -> to 

identify local maxima

210

0)(      xfclosed form solutions are not always 

available

f(x)

x

    often it is not possible to simply solve               = 0

    the function to minimize/maximize may have an 

intractable form

    in these situations, iterative solutions are used
    begin with a    guess    for the optimal      and refine it 

iteratively until the correct value is obtained

211

iterative solutions

f(x)

x0 x1 x2

x3

x5
x4

x

    0

    2

    1

   

iterative solutions
    start from an initial guess     0 for the optimal     
    update the guess towards a (hopefully)    better    value of f(    )
    stop when f(    ) no longer decreases

    problems: 

    which direction to step in
    how big must the steps be

212

the approach of id119

    iterative solution:  
    start at some point
    find direction in which to shift this point to decrease error

    this can be found from the derivative of the function

    a positive derivative     moving left decreases error
    a negative derivative     moving right decreases error

    shift point in this direction

the approach of id119

e

e

   

iterative solution:  trivial algorithm
    initialize     0
    while                      0

   

if                                  

is positive:

            +1 =                              

    else

            +1 =          +                 

    what must step be to ensure we actually get to the optimum?

the approach of id119

e

e

    iterative solution:  trivial algorithm

    initialize     0
    while                      0

            +1 =                                               

.                 

    identical to previous algorithm

the approach of id119

e

e

    iterative solution:  trivial algorithm

    initialize     0
    while                     0

            +1 =                                      

             is the    step size   

id119/ascent (multivariate) 

    the id119/ascent method to find the 
minimum or maximum of a function      iteratively
    to find a maximum move in the direction of the 

gradient

        +1 =          +                               

    to find a minimum move exactly opposite the 

direction of the gradient

        +1 =                                            

    many solutions to choosing step size         

217

id119 algorithm

    in order to minimize any function           w.r.t.     
    initialize: 

        0
         = 0

    while               +1                   >     

            +1 =                                            
         =      + 1

11-755/18-797

218

    back to neural networks

219

recap

image

n.net

label

di

xi

    neural networks can model any function
    they must be trained to represent the function
   

in the usual setting, they must be trained from input-
output pairs

    we will use empirical risk minimization to learn network 

parameters

    we will use (variants of) id119 to learn them

220

typical problem statement

    we are given a number of    training    data instances
    e.g. images of digits, along with information about 

which digit the image represents

    tasks:

    binary recognition:   is this a    2    or not
    multi-class recognition:  which digit is this? is this a digit in 

the first place?

221

representing the output

   

   

   

if the desired output is real-valued, no special tricks are necessary
    scalar output : single output neuron

   

d = scalar (real value)

    vector output : as many output neurons as the dimension of the desired 

output

    d = [d1 d2 .. dn] (vector of real values)

if the desired output is binary (is this a cat or not), use a simple 1/0 output
    1 = yes it   s a cat
    0 = no it   s not a cat.
for multi-class outputs: one-hot representations
    for n classes, an n-dimensional binary vector of the form [0 0 0 1 0 0..]
    the single    1    in the k-th position represents an instance of the kth class

222

problem setting

(0,1)

    we design a network with the necessary number of inputs 

and outputs
    in our example we will consider a binary classification task

    is this    2    or not
    the network has only one output

    we will assume the structure of the network (no. of layers, no. 

of neurons in each layer) is given

    challenge: how to make this network recognize    2    (e.g.)

223

training data

(   , 0)
(   , 1)
(   , 0)

problem setting
(   , 1)
(   , 0)
(   , 1)

input: vector of
pixel values

    generic    training    setting:  

output: vector of
pixel values

    given, many positive and negative examples (training data),     
        learn all weights such that the network does the desired job

224

recap: procedural outline

    1,     2,     ,         

actual output of network:
            ,     ,     

     =          ;         ,    

=     (    ;     1,     2,     ,         )

desired output of network:     

error on t-th training input:

            (        ,         ;     1,     2,     ,         )

    given the network and input, the output is a function 

of the network parameters.

    for each training input, we can define an error 

between the network output and the desired output

    this is a function of network parameters

225

examples of divergence functions

    for real-valued output vectors, the l2 divergence is popular

                 ,      =               2 =    
    

                     

2

    for binary classifier with scalar output y     (0,1), d is (0/1), the kl 

divergence is popular

                 ,      =                      + 1          log(1         )

    multi-class classification:      is a id203 vector,      is a one-hot 

vector 

                 ,      =    

         log         

    

226

recap: procedural outline

    1,     2,     ,         

actual output of network:
            ,     ,     

     =          ;         ,    

=     (    ;     1,     2,     ,         )

desired output of network:     

error on t-th training input:

            (        ,         ;     1,     2,     ,         )

total training error:

             =    

            (        ,         ;     1,     2,     ,         )

    

   

   

error is a function of network parameters
find network parameters that minimize the total error over all training 
inputs
    with caveats..

227

id119 applied to mlps

training data

(   , 0)

(   , 1)

(   , 1)

(   , 0)

(   , 0)

(   , 1)

    1

(1)
    1,1

(1)
    1,2

(1)
    2,1

(1)
    2,2

(1)
    3,2

    2

(1)
    3,1
1

+

+

(2)
    1,1

(2)
    1,2

(2)
    2,1

(2)
    3,1
1

(2)
    2,2

(2)
    3,2

+

+

(3)
    1,1

+

(3)
    2,1

(3)
    3,1

    

1

each yellow ellipse
represents a id88

total training error:

             =    

            (        ,         ;     1,     2,     ,         )

    

    find the weights     1,     2,     ,          that minimize 

the total error             

228

recap: problem statement

    minimize the following function

             =    

            (        ,         ;     1,     2,     ,         )

    

w.r.t      1,     2,     ,         

    this is problem of function minimization

    an instance of optimization

    we will solve this through id119

229

recap: id119 algorithm

    in order to minimize any function           w.r.t.     
    initialize: 

        0
         = 0

    while               +1                   >     

            +1 =                                            
         =      + 1

11-755/18-797

230

training neural nets through gradient 

total training error:

descent

             =    

            (        ,         ;     1,     2,     ,         )

    

    id119 algorithm:

    initialize all weights     1,     2,     ,         
    do:

    for every layer      update:

             =                                          t

    until              has converged

231

training neural nets through gradient 

total training error:

descent

             =    

            (        ,         ;     1,     2,     ,         )

    

    id119 algorithm:

    initialize all weights     1,     2,     ,         
    do:

    for every layer      update:

             =                                                           ,         ; w1, w2,     , w    

    

    until              has converged

232

training neural nets through gradient 

total training error:

descent

             =    

            (        ,         ;     1,     2,     ,         )

    

    id119 algorithm:

    initialize all weights     1,     2,     ,         
    do:

    for every layer      update:

             =                                                           ,         ; w1, w2,     , w    

    

    until              has converged

233

computing the derivatives

    we use back propagation to compute the 

derivative

    assuming everyone knows how; will skip the 

details

does backprop do the right thing?

    is backprop always right?

    assuming it actually find the global minimum of the 

divergence function?

    in classification problems, the classification error is a 

non-differentiable function of  weights

    the divergence function minimized is only a proxy for 

classification error

    minimizing divergence may not minimize classification 

error

backprop fails to separate where 
    

id88 succeeds

(0,1), +1

(-1,0), -1

(1,0), +1

    brady, raghavan, slawny,    89

    

   

    

1

    simple problem, 3 training instances, single neuron

    id88 training rule trivially find a perfect solution

backprop vs. id88

(0,1), +1

(-1,0), -1

(1,0), +1

    back propagation using logistic function and     2

divergence  (             = (             )2)

    unique minimum trivially proved to exist, 

id26 finds it

    

    

   

    

1

unique solution exists

(0,1), +1

(-1,0), -1

(1,0), +1

    

    

   

   

   

let      =        1 1          .  
from the three points we get three independent equations:

    

1

        . 1 +         . 0 +      =     
        . 0 +         . 1 +      =     

        .    1 +         . 0 +      =        
    unique solution  (        =     ,          =     ,      = 0) exists

    represents a unique line regardless of the value of     

backprop vs. id88

(0,1), +1

(-1,0), -1

(1,0), +1

(0,-t), +1

    now add a fourth point

         is very large (point near       )

    id88 trivially finds a solution

    

    

   

    

1

backprop

notation:
     =           = logistic activation

(0,1), +1

(-1,0), -1

(1,0), +1

    consider backprop:
    contribution of fourth point 

to derivative of l2 error:

(0,-t), +1

            4 = 1                          +     

2

                 4
            
                 4

        

= 2 1                          +                              +          

=    2 1                          +                              +     

    

    

   

    

1

backprop

notation:
     =           = logistic activation

            4 = 1                          +     

2

                 4
            

                 4

        

= 2 1                          +                              +          

= 2 1                          +                              +          

    for very large positive     ,           >      (where      =         ,         ,      )

   

1                          +          1 as             

                            +          0 exponentially as             
    therefore, for very large positive     

                 4
            

=

                 4

        

= 0

backprop

(0,1), +1

(-1,0), -1

(1,0), +1

     very large

(0,-t), +1

    the fourth point at (0,        ) does not change the 

gradient of the l2 divergence anywhere

    

    

   

    

1

    the optimum solution is the same as the optimum 

solution with only the first three points!

backprop

(0,1), +1

(-1,0), -1

(1,0), +1

    

    

   

(0,-t), +1

    
    global optimum solution found by backprop

1

    does not separate the points even though the 

points are linearly separable!

backprop

(0,1), +1

(-1,0), -1

(1,0), +1

    

    

   

(0,-t), +1

    global optimum solution found by backprop
    does not separate the points even though the points are linearly 

    

1

separable!

    compare to the id88:  id26 fails to separate 

where the id88 succeeds

a more complex problem

    

    

   

    

1

    several linearly separable training examples

    simple setup: both backprop and id88 

algorithms find solutions

a more complex problem

    adding a    spoiler    (or a small number of spoilers)

    

    

   

    

1

    id88 finds the linear separator, 
    backprop does not find a separator

    a single additional input does not change the id168 

significantly

a more complex problem

    adding a    spoiler    (or a small number of spoilers)

    

    

   

    

1

    id88 finds the linear separator, 
    backprop does not find a separator

    a single additional input does not change the id168 

significantly

a more complex problem

    adding a    spoiler    (or a small number of spoilers)

    

    

   

    

1

    id88 finds the linear separator, 
    backprop does not find a separator

    a single additional input does not change the id168 

significantly

a more complex problem

    adding a    spoiler    (or a small number of spoilers)

    

    

   

    

1

    id88 finds the linear separator, 
    backprop does not find a separator

    a single additional input does not change the id168 

significantly

so what is happening here?

    the id88 may change greatly upon adding just a 

single new training instance
    but it fits the training data well
    the id88 rule has low bias 

    makes no errors if possible

    but high variance

    swings wildly in response to small changes to input

    backprop is minimally changed by new training 

instances
    prefers consistency over perfection
    it is a low-variance estimator, at the potential cost of bias

backprop fails to separate even when 

possible

    this is not restricted to single id88s

    in an mlp the lower layers    learn a representation    

that enables linear separation by higher layers

    more on this later

    adding a few    spoilers    will not change their behavior

backprop fails to separate even when 

possible

    this is not restricted to single id88s

    in an mlp the lower layers    learn a representation    

that enables linear separation by higher layers

    more on this later

    adding a few    spoilers    will not change their behavior

id26

    id26 will often not find a separating 
solution even though the solution is within the 
class of functions learnable by the network

    this is because the separating solution is not an 

optimum for the id168

    one resulting benefit is that a backprop-trained 

neural network classifier has lower variance than 
an optimal classifier for the training data

variance and depth

3 layers

4 layers

3 layers

4 layers

6 layers

11 layers

6 layers

11 layers

    dark figures show desired decision boundary (2d)

    1000 training points, 660 hidden neurons
    network heavily overdesigned even for shallow nets

    anecdotal: variance decreases with

10000 training instances

    depth
    data

254

convergence

    how fast does it converge?

    and where?

the error surface

    the example (and statements) 

earlier assumed the loss 
objective had a single global 
optimum that could be found

    statement about variance is 

assuming global optimum

    what about local optima

the error surface

    popular hypothesis:

    in large networks, saddle points are far more 

common than local minima

    frequency exponential in network size

    most local minima are equivalent

    and close to global minimum

    this is not true for small networks

    saddle point: a point where

    the slope is zero
    the surface increases in some directions, but 

decreases in others

    some of the eigenvalues of the hessian are positive; 

others are negative

    id119 algorithms like saddle points 

the controversial error surface

    baldi and hornik (89),    neural networks and principal component 

analysis: learning from examples without local minima    : an mlp with a 
single hidden layer has only saddle points and no local minima

    dauphin et. al (2015),    identifying and attacking the saddle point problem 
in high-dimensional non-id76    : an exponential number of 
saddle points in large networks

    chomoranksa et. al (2015),    the loss surface of multilayer networks    :  for 

large networks, most local minima lie in a band and are equivalent
    based on analysis of spin glass models

   

swirscz et. al. (2016),    local minima in training of deep networks   , in 
networks of finite size, trained on finite data, you can have horrible local 
minima

    watch this space   

story so far

    neural nets can be trained via id119 that minimizes a 

id168

    id26 can be used to derive the derivatives of the loss

    backprop is not guaranteed to find a    true    solution, even if it 

exists, and lies within the capacity of the network to model
    the optimum for the id168 may not be the    true    solution

    for large networks, the id168 may have a large number of 

unpleasant saddle points
    which id26 may find

convergence

    in the discussion so far we have assumed the 

training arrives at a local minimum

    does it always converge?
    how long does it take?

    hard to analyze for an mlp, so lets look at 

id76 instead

a quick tour of (convex) optimization

convex id168s

    a surface is    convex    if it is 

continuously curving upward
    we can connect any two points 

above the surface without 
intersecting it

    many mathematical definitions 

that are equivalent

    caveat: neural network error 
surface is generally not convex
    streetlight effect

contour plot of convex function

convergence of id119

    an iterative algorithm is said to 

converge to a solution if the weight 
updates arrive at a fixed point
    where the gradient is 0 and further 

updates do not change the weight

    the algorithm may not actually 

converge
    it may jitter around the local 

minimum

    it may even diverge

    conditions for convergence?

converging

jittering

diverging

convergence and convergence rate

converging

    convergence rate: how fast the 
iterations arrive at the solution

    generally quantified as

     =

         (    +1)                 
         (    )                 
        (    +1)is the k-th iteration
           is the optimal value of     

   

if      is a constant (or upper bounded), 
the convergence is linear
    in reality, its arriving at the solution 

exponentially fast

         (    )                  =                   (0)                 

convergence for quadratic surfaces

                                      =

        2 +          +     

1
2

w(    +1) = w(    )         

         w(    )

    w

id119 with fixed step size     
to estimate scalar parameter w

    id119 to find the 

optimum of a quadratic, 
starting from w(    )

    assuming fixed step size     
    what is the optimal step size 

     to get there fastest?

w(    )

convergence for quadratic surfaces
1
2

    any quadratic objective can be written as

        2 +          +     

     =      w(    ) +               w(    ) +

              w(    )

2

     =

1
2

w(    +1) = w(    )         

         w(    )

    w

    taylor expansion

    minimizing w.r.t     , we get

                 = w(    )            1    

    note:

         w(    )

    w

=     

    comparing to the id119 rule, we see 

that we can arrive at the optimum in a single 
step using the optimum step size

                 =        1

with non-optimal step size

w(    +1) = w(    )         

         w(    )

    w

id119 with fixed step size     
to estimate scalar parameter w

    for      <                  the algorithm 
will converge monotonically

    for 2                 >      >                  we 

have oscillating 
convergence

    for                           we get 

divergence

for generic differentiable convex 

objectives

approx

    any differentiable objective           can be approximated as

              w(    ) +          w(    )          w(    )
        

+

1
2

         w(    )

2     2     w(    )

        2

+    

    taylor expansion

    using the same logic as before, we get

                 =

    2     w(    )

   1

        2

    we can get divergence if          2                

for functions of multivariate inputs

     =           ,      is a vector      =     1,     2,     ,         

    consider a simple quadratic convex (paraboloid) function

     =

1
2

                 +              +     

    since          =      (     is scalar),       can always be made symmetric

    for convex     ,      is always positive definite, and has positive eigenvalues

    when      is diagonal:

     =

1
2

   

    

                    

2 +    
    

                 +     

    the         s are uncoupled
    for convex (paraboloid)     , the              values are all positive
    just an sum of      independent quadratic functions

multivariate quadratic with diagonal     

     =

1
2

                 +              +      =

1
2

   

    

                    

2 +    
    

                 +     

    equal-value contours will be parallel to the 

axis

multivariate quadratic with diagonal     

     =

1
2

                 +              +      =

1
2

   

    

                    

2 +    
    

                 +     

    equal-value contours will be parallel to the axis

    all    slices    parallel to an axis are shifted versions of one another 

     =

1
2

                    

2 +                  +      +     (          )

multivariate quadratic with diagonal     

     =

1
2

                 +              +      =

1
2

   

    

                    

2 +    
    

                 +     

    equal-value contours will be parallel to the axis

    all    slices    parallel to an axis are shifted versions of one another 

     =

1
2

                    

2 +                  +      +     (          )

   descents    are uncoupled

     =

1
2

2 +     1    1 +      +     (      1)

    11    1
   1
    1,             =     11

     =

1
2

    22    2

2 +     2    2 +      +     (      2)
   1
    2,             =     22

    the optimum of each coordinate is not affected by the other coordinates

    i.e. we could optimize each coordinate independently

    note: optimal learning rate is different for the different coordinates

vector update rule

    (    )

    (    +1)

    (    +1)         (    )                     

(    +1) =         

        

(    )         

(    )

                 
    w

    conventional vector update rules for id119: 

update entire vector against direction of gradient

    note : gradient is perpendicular to equal value contour

    the same learning rate is applied to all components

problem with vector update rule

    (    +1)         (    )                         

(    +1) =         

        

(    )         

(    )

                 
    w

        ,             =

(    )

    2             
2
            

   1

   1
=     22

    the learning rate must be lower than twice the smallest 

optimal learning rate for any component

     < 2 min

    

        ,            

    otherwise the learning will diverge

    this, however, makes the learning very slow

    and will oscillate in all directions where          ,                      < 2        ,            

dependence on learning rate

   

   

   

   

   

   

    1,             = 1;     2,             = 0.33

     = 2.1    2,            

     = 2    2,            

     = 1.5    2,            

     =     2,            

     = 0.75    2,            

dependence on learning rate

        1,             = 1;     2,             = 0.91;

     = 1.9     2,            

convergence

    convergence behaviors become increasingly 

unpredictable as dimensions increase

    for the fastest convergence, ideally, the learning rate     

must be close to both, the largest         ,             and the 
smallest         ,            
    to ensure convergence in every direction
    generally infeasible

    convergence is particularly slow if 

max

    

min

    

        ,            

        ,            

is large

    the    condition    number is small (more on this shortly)

more problems

    for quadratic (strongly) convex functions, id119 is 

exponentially fast
    linear convergence
    assuming learning rate is non-divergent

    for generic (lipschitz smooth) convex functions however, it is very slow

         (    )                     

1
    

         (0)                 

    and inversely proportional to learning rate

         (    )                     

1

2        

    (0)            

    takes o 1/     iterations to get to within      of the solution

    an inappropriate learning rate will destroy your happiness 

the reason for the problem

   

   

the objective function has different eccentricities in different directions
    resulting in different optimal learning rates for different directions

solution: normalize the objective to have identical eccentricity in all 
directions
    then all of them will have identical optimal learning rates
    easier to find a working learning rate

    2

solution: scale the axes

       2 =     2    2
       1 =     1    1

       2

        =

     =

       1
       2
    1
    2

    1

       1

     =

    1
0

0
    2

        =         

    scale the axes, such that all of them have identical (identity)    spread   

    equal-value contours are circular

    note: equation of a quadratic surface with circular equal-value 

contours can be written  as
1
2

     =

                    +                     +     

scaling the axes

    finding the right way to scale the axes is an art 

in itself

    instead, we will modify things differently: 

allow different step sizes in different directions

the momentum methods

figures from sebastian ruder

    conventional id119 follows the immediate gradient

    against local direction of steepest ascent
    constantly follows current local trend
this largely ignores global trend
    can take forever to get to optimum

   

    global trend is generally also a component of local trends

    momentum methods: increase contribution of global trends to step size by 

averaging across steps

the momentum method

plain gradient update

with acceleration

   

   

   

   

   remember    the previous step
the actual step is a linear combination of the previous step and the current batch 
gradient

            =                   1 +             (           1)

         =            1                

typical      value is 0.9
steps 

    get longer in directions where gradient stays in the same sign
    become shorter where the sign keeps flipping

nestorov   s method

    simple id119: only look at current trend
    momentum:  look at current trend and past trend
    better still: look at the future

    where you will go if you follow the momentum strategy

nestorov   s method

    location at t and direction vt to come here

nestorov   s method

    location at t and direction vt to come here
    guess to where we would go if we continued 

the way we came

nestorov   s method

    location at t and direction vt to come here
    guess to where we would go if we continued the way we 

came

    the gradient at that point

    how we would update through id119 from this 

future point

nestorov   s method

    location at t and direction vt to come here
    guess to where we would go if we continued the way we 

came

    the gradient at that point

    how we would update through id119 from this 

future point

    final update

nestorov   s accelerated gradient

    nestorov   s method

            =                   1 +             (           1                       1)

         =            1                

    based on guessing the future

nestorov   s accelerated gradient

   

from hinton
    instead of 

1.
2.
3.
    we
1.
2.
3.

computing current gradient
taking a (negative) step in the direction of the current gradient
adding (negative) acceleration term from there

take a (negative) step in the direction of acceleration
compute the gradient there
take a (negative) step in the direction of the gradient

    converges much faster

smoothing the trajectory

1

2

4

5

3

step

x component

y component

1

2

3

4

5

1

1

3

1

2

+2.5

-3

+2.5

-2

1.5

   

simple gradient and acceleration methods still demonstrate oscillatory 
behavior in some directions

    observation:  steps in    oscillatory    directions show large total movement
    in the example, total motion in the vertical direction is much greater than in 

the horizontal direction

   

improvement:  dampen step size in directions with high motion

292

variance-normalized step

   

in recent past
    total movement in y component of updates is high
    movement in x components is lower

    current update, modify usual gradient-based update:

    scale down y component
    scale up x component

    a variety of algorithms have been proposed on this premise

    we will see a popular example

293

rms prop

    notation:

    updates are by parameter

    sum derivative of divergence w.r.t any individual 

parameter      is shown as             

    the squared derivative is         

2      =              2

    the mean squared derivative is a running estimate of the 

average squared derivative. we will show this as              

2     

    modified update rule:  we want to 

    scale down updates with large mean squared derivatives
    scale up updates with large mean squared derivatives

294

rms prop

    this is a variant on the basic mini-batch sgd algorithm

    procedure:

    maintain a running estimate of the mean squared value of 

derivatives for each parameter

    scale update of the parameter by the inverse of the root mean 

squared derivative

             

2           =                  

2             1 + 1                  

2          

        +1 =             

    
2           +     

             

            

295

fast convergence remains a challenge

    newer methods: 

    adagrad
    adadelta
    rms prop
    adam

296

visualizing the optimizers

   

http://sebastianruder.com/optimizing-gradient-descent/index.html

297

a few additional tricks: gradient 

clipping

    often the derivative will be too high

    when the divergence has a steep slope
    this can result in instability

    gradient clipping: set a ceiling on derivative value

                      >                                   =     

    typical      value is 5

298

several other tricks are often required 

for good performance

    batch id172
    dropout

    other issues not covered:
    objective functions, speed up algorithms, 

generalization..

299

far from complete

    efficient training remains a challenge with 

much scope for advances..

300

