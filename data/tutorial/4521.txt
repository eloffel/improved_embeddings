representations
of relationships
in text
(and images)
...and some other stuff

hal daum   iii | university of maryland | me@hal3.name | @haldaume3

what is nlp?

    fundamental goal: deep understanding of text

    not just string processing or keyword matching

    end systems that we want to build

    simple: id147, text categorization, etc.
    complex: id103, machine translation, information 

extraction, dialog interfaces, id53

    unknown: human-level comprehension (more than just nlp?)

2 

hal daum   iii (me@hal3.name)

simons - representations

nlp via machine learning

arthur shall strike the blow that sets lucy free.

bilstm

hegemony

named-entity
recognition

person
arthur shall strike the blow that sets lucy free.

person

3 

hal daum   iii (me@hal3.name)

simons - representations

nlp via machine learning

arthur shall strike the blow that sets lucy free.

bilstm

hegemony

syntactic
parsing

4 

hal daum   iii (me@hal3.name)

simons - representations

nlp via machine learning

arthur shall strike the blow that sets lucy free.

bilstm

hegemony

machine
translation

es war arthurs hand, die lucy 
den weg zu den sternen ge  ffnet hat

5 

hal daum   iii (me@hal3.name)

simons - representations

nlp via machine learning

arthur shall strike the blow that sets lucy free.

who 
wrote 
this?

bilstm

hegemony

factoid
question
answering

bram stoker

6 

hal daum   iii (me@hal3.name)

simons - representations

nlp via machine learning

arthur shall strike the blow that sets lucy free.

what 
does lucy 
need to 
be freed 
from?

bilstm

hegemony

complex
question
answering

??????????????

7 

hal daum   iii (me@hal3.name)

simons - representations

what am i not going to talk about?
learning through interaction: 
    not so much representation stuff there
    changed my mind
    can see talk linked from my webpage

bag of id165s + id28: 

    my    go-to    representation
    can do better? probably
    do you always? no
    why is averaging enough? regularity?

8 

hal daum   iii (me@hal3.name)

simons - representations

narratives

account of events or experiences

fictitious or real

9 

hal daum   iii (me@hal3.name)

simons - representations

why relationships?

relationships are fundamental for understanding our 
social behavior

11 

hal daum   iii (me@hal3.name)

simons - representations

speaking of relationships...

snigdha chaturvedi
postdoc at uiuc

mohit iyyer

phd student at umd

12 

hal daum   iii (me@hal3.name)

simons - representations

existing character-centric approaches model roles

sometimes narratives are about relationships

* bamman et. al. acl 2013, bamman et. al. acl 2014, valls-vargas et.al. aiide 2014 

14 

hal daum   iii (me@hal3.name)

simons - representations

relationships are not static.

they evolve with the progress of the narrative.

15 

hal daum   iii (me@hal3.name)

simons - representations

how can we describe a 
fictional relationship between 
two characters?

16 

hal daum   iii (me@hal3.name)

simons - representations

tom  falls  in  love  with  becky  thatcher,  a  new  girl  in  town,  and 
persuades her to get    engaged    to him. 

their  romance  collapses  when  she  learns  that  tom  has  been 
   engaged    before   to a girl named amy lawrence. 
shortly after being shunned by becky, tom ...

back in school, tom gets himself back in becky   s favor after he nobly 
accepts the blame for a book that she has ripped. 
meanwhile,  tom  goes  on  a  picnic  to  mcdougal   s  cave  with  becky 
and their classmates.

17 

hal daum   iii (me@hal3.name)

simons - representations

problem statement

character 1

character 2

progress of the novel

sequence of 

relationship states

18 

hal daum   iii (me@hal3.name)

simons - representations

model not limited to fictional narratives 

cooperative
non-cooperative

network inferred from the wikipedia article on 

2003 invasion of iraq

19 

hal daum   iii (me@hal3.name)

simons - representations

multiple facets

real-world relationships have multiple facets

20 

hal daum   iii (me@hal3.name)

simons - representations

21 

arthur and lucy 

(dracula)

hal daum   iii (me@hal3.name)

simons - representations

states

trajectory
arthur and lucy 

(dracula)

hal daum   iii (me@hal3.name)

simons - representations

22 

why should humanities scholars care?

       distant reading    (moretti, 2005) can 
help rapidly collect examples of 
specific relationship types

do jane austen   s female and male protagonists 

have a pattern in their evolving relationships  
(e.g., mutual disdain followed by romantic love)? 

(butler, 1975; stovel, 1987; hinant, 2006)
do certain authors or novels portray 
relationships of desire more than others?

(polhemus, 1990)
can we detect positive or negative subtext 

underlying meals between two characters?
(foster, 2009; cognard-black et al., 2014)

23 

hal daum   iii (me@hal3.name)

simons - representations

a dataset of character interactions
for each pair of characters in a particular book, 
we extract all spans of text that contain mentions 
to both characters

t=0

t=1

t=2

   if anyone was ever minding his business, it was i," ignatius 
breathed. "please. we must stop. i think i'm going to have a 
hemorrhage.    "okay." mrs. reilly looked at her son's 
reddening face and realized that he would very happily 
collapse at her feet just to prove his point.   
   ignatius belched the gas of a dozen brownies trapped by his 
valve. "grant me a little peace.      
"you know i appreciate you, babe," mrs. reilly sniffed. "come 
on and gimme a little goodbye kiss like a good boy.   
mrs. reilly looked at her son slyly and asked, "ignatius, you 
sure you not a communist?    "oh, my god!" ignatius bellowed. 
"every day i am subjected to a mccarthyite witchhunt in this 
crumbling building. no!"

24 

hal daum   iii (me@hal3.name)

simons - representations

relationship modeling network (rmn)

recurrent autoencoder with dictionary learning

dictionary
matrix;

each row is

a state

violence
sadness
politics
love
suffering

0.0
0.2
0.0
0.7
0.1

id203
distribution
over states

   ignatius belched the gas of a dozen brownies 
trapped by his valve. "grant me a little peace.      
"you know i appreciate you, babe," mrs. reilly 
sniffed. "come on and gimme a little goodbye 
kiss like a good boy.   

25 

hal daum   iii (me@hal3.name)

simons - representations

relationship modeling network (rmn)
recurrent autoencoder with dictionary 
learning

dictionary matrix

nonlinear 

transformation

nonlinear 

nonlinear 

transformation

transformation

26 

hal daum   iii (me@hal3.name)

simons - representations

relationship modeling network (rmn)
recurrent autoencoder with dictionary 
learning

reconstruct inputs

27 

hal daum   iii (me@hal3.name)

simons - representations

6.  make  the  
reconstructed  
vector  close  to  
the  input  span  
vector

3.  a  recurrent  
connection  copies  
some  of  the  
previous  hidden  
state

1.  word  
embedding  
average

5.  multiply  the  hidden  
state  by  the  dictionary  
matrix  to  obtain  a  
reconstruction  of  the  
span  vector

4.  use  a  softmax  to  
make  the  hidden  
state  a  id203  
distribution  over  
states   

2.  mix  with  
embeddings  for  
characters  and  
books

most coherent relationship states

relationship modeling network

outdoors: outdoors trail trails hillside grassy slopes 
sadness: regretful rueful pity pained despondent  
education: teaching graduate year teacher attended
love: love delightful happiness enjoyed enjoyable
murder: autopsy arrested homicide murdered

baseline: hidden topic markov model (htmm)

crime: blood knife pain legs steal
food: kitchen mouth glass food bread
violence: sword shot blood shouted swung
boats: ship boat captain deck crew
outdoors: stone rock path darkness desert

29 

hal daum   iii (me@hal3.name)

simons - representations

most coherent relationship states

relationship modeling network

outdoors: outdoors trail trails hillside grassy slopes 
sadness: regretful rueful pity pained despondent  
education: teaching graduate year teacher attended
love: love delightful happiness enjoyed enjoyable
murder: autopsy arrested homicide murdered

baseline: hidden topic markov model (htmm)

crime: blood knife pain legs steal
food: kitchen mouth glass food bread
violence: sword shot blood shouted swung
boats: ship boat captain deck crew
outdoors: stone rock path darkness desert

30 

hal daum   iii (me@hal3.name)

simons - representations

word intrusion task

31 

hal daum   iii (me@hal3.name)

simons - representations

arthur and lucy    ground-truth   :
marriage -> sickness -> death -> murder

learned trajectories:

32 

hal daum   iii (me@hal3.name)

simons - representations

rmn contributions
humanities: 

    learns global relationship states from corpus of novels
    interpretable visualizations of relationship trajectories

machine learning: 

    novel combination of dictionary learning and neural 
networks
    unsupervised training promotes model interpretability

33 

hal daum   iii (me@hal3.name)

simons - representations

commonsense id136s

lex luthor   s limousine 
came late today.
the driver had overslept.

34 

hal daum   iii (me@hal3.name)

simons - representations

closure: the process by which we connect panels together

what is exploding, and why?

hal daum   iii (me@hal3.name)

simons - representations

35 

a dataset of comics to study closure

   4,000 comic books from the digital 
comics museum 
www.digitalcomicsmuseum.com
   books are from the    golden age of comics    
(1938-1954), in the public domain due to 
copyright expiration
1.2  million  panels with 2.5  million  textboxes

36 

hal daum   iii (me@hal3.name)

simons - representations

cloze tasks for testing closure

the simons workshop has been interesting so far.

i hope the rest of the week is just as ________

a.
b.
c.

boring
awful
compelling

37 

hal daum   iii (me@hal3.name)

simons - representations

task: predict dialogue in a panel 
given previous panels as context

38 

hal daum   iii (me@hal3.name)

simons - representations

task: predict dialogue in a panel 
given previous panels as context

a. alice! i   ve been 
looking all over for you!

b. hiya kid! all alone?

c. g-golly! i   m still 
alive    but where am i??

39 

hal daum   iii (me@hal3.name)

simons - representations

40 

hal daum   iii (me@hal3.name)

simons - representations

neural network 
to understand 
panel artwork

neural network 
to understand 
panel dialogue

41 

hal daum   iii (me@hal3.name)

simons - representations

neural network 
to understand 
panel transitions

42 

hal daum   iii (me@hal3.name)

simons - representations

dialogue candidates 
scored against network 
output

43 

hal daum   iii (me@hal3.name)

simons - representations

closure is hard!

model
random
image-only
text-only
image-text
   no context
image-text
   full context

human

cloze 
accuracy

33
48.7
51.9
59.6
63.4
84

44 

hal daum   iii (me@hal3.name)

simons - representations

comics recap

   new dataset & tasks that test a 
computer   s ability to make 
commonsense id136s
   deep learning can learn some degree 
of closure
   however, our best models lag behind 
humans despite huge amount of 
data

45 

hal daum   iii (me@hal3.name)

simons - representations

inductive bias in networks or data?

46 

hal daum   iii (me@hal3.name)

simons - representations

simultaneous machine interpretation

he he

alvin grissom ii

47 

hal daum   iii (me@hal3.name)

learning to be better than people

why simultaneous interpretation is hard
    human languages have vastly different word orders

    about half are ov, the other half are vo
    this comes with a lot more baggage than just verb-final

man-top store-loc go-past
the man went to the store

food-obj buy-desire man-top store-loc go-past
the man who wanted to buy food went to the store

48 

hal daum   iii (me@hal3.name)

learning to be better than people

general diffs of interp vs batch

    inversion

    segmentation into multiple sentences
    passivization of single sentence

    word generalization
    (lower retrieval time)

    summarization and omission

    (to catch up)

example (gen + segment)
(s)                                                                   
                                                                        
         

(t) one of the characteristics of honorific japanese 
is that it can not be adequately expressed when 
using a direct translation from english to japanese.

(i) now let me talk about the characteristic of the 
japanese polite expressions.   <segment/> and 
such expressions can not be expressed enough just 
by translating directly.

example (gen + passivize)
(s)                                                             
                                                                  
                         .

(t) in summary, we have devised a way for voice 
interaction systems to handle natural speech.

(i) and this is the summary of what i have so far 
stated. the spontaneous speech can be dealt with 
by the speech dialog method   <segment/> 
and that method was proposed.

example (gen + summarize)
(s)                                                             
                                                                  
                                  .

(t) its third characteristic is that its output is, 
as much as possible, in the natural language of 
spoken (( japanese )).

(i) and the third feature is that the translation 
could be produced in a very natural spoken 
language.

how can we integrate this 
information into a neural machine 
translation system?

53 

hal daum   iii (me@hal3.name)

simons - representations

rewriting the training data

54 

hal daum   iii (me@hal3.name)

simons - representations

transformation rules

55 

hal daum   iii (me@hal3.name)

simons - representations

accuracy at different delay levels

56 

hal daum   iii (me@hal3.name)

simons - representations

accuracy at different delay levels

57 

hal daum   iii (me@hal3.name)

simons - representations

learning with invariants
    mnist folks have been doing this for ages

    often much easier to talk about data invariants than 

trying to construct    better    hypothesis classes

    added benefit: can use highly optimized code

    can try to understand though lens of covariate shift:

   
 good

    more data 
    not-quite-right-data 

 bad   

    are there other ways to understand this?

58 

hal daum   iii (me@hal3.name)

simons - representations

discussion
    dictionary learning embedded in 
   
 interpretability

neural network 

    moving toward evaluating 

unsupervised learning via actual 
use cases

    not quite there on complex 

common-sense reasoning tasks

    invariants on outputs as a 
mechanism for additional 
supervision

    not sure how to analyze

snigdha
chaturvedi

mohit
iyyer

he
he

alvin
grissom ii

