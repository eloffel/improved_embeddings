   #[1]william vorhies's posts - data science central [2]comments -
   id23 part 3     challenges & considerations - data
   science central

   iframe: [3]https://www.googletagmanager.com/ns.html?id=gtm-t5w4wq

   ____________________ [4]search

     * [5]sign up
     * [6]sign in

[7]data science central

     * [8]home
          + [9]top content
          + [10]editorial guidelines
          + [11]user agreement
          + [12]cookie policy
     * [13]ai
     * [14]ml
     * [15]dl
     * [16]analytics
     * [17]statistics
     * [18]big data
     * [19]dataviz
     * [20]hadoop
     * [21]podcasts
     * [22]webinars
     * [23]forums
     * [24]jobs
     * [25]membership
          + [26]top content
     * [27]groups
     * [28]search
     * [29]contact

                       [30]subscribe to dsc newsletter

     * [31]all blog posts
     * [32]my blog
     * [33]add

id23 part 3     challenges & considerations

     * posted by [34]william vorhies on august 29, 2017 at 9:03am
     * [35]view blog

   summary:  in the first part of this series we described the basics of
   id23 (rl).  in this article we describe how deep
   learning is augmenting rl and a variety of challenges and
   considerations that need to be addressed in each implementation.


   [36][rlxkcd.png?width=275] in the first part of this series,
   [37]understanding basic rl models we described the basics of how
   id23 (rl) models are constructed and interpreted.

   rl systems can be constructed using policy gradient techniques which
   attempt to learn by directly mapping an observation to an action (the
   automated house look up table).  or they can be constructed using
   id24 in which we train a neural net to calculate the estimated q
   factor on the fly which is used when the state space gets large and
   complex.

   the q factor is the maximum discounted future reward when we perform
   action a in state s.  the q-function q(s,a) is interpreted as the
      policy    for what action to take next given state a.

   rl systems do not require neural nets but increasingly the most
   interesting problems like game play and self-driving cars represent
   such large and complex state spaces that the direct observation policy
   gradient approach is not practical.

   these id24 situations are also frequently defined by their use of
   images (pixel fields) as unlabeled inputs which are classified using a
   convolutional neural net (id98) with some differences from standard
   image classification.

   in this article we   ll describe id24 at a basic level and devote
   more time to exploring other practical complexities and challenges to
   implementing rl systems.


   four examples we   ll use

   to illustrate our points we   ll use these four hypothetical
   applications.

   the automated house:  actuators would include at least heating and
   cooling systems, light switches, and blinds.  sensors would include a
   thermometer, fire and smoke detectors, motion detectors and cameras,
   and of course a clock and calendar.  in our example we   ll limit
   ourselves to the goal of just trying to get the temperature right.

   self-driving cars:  this could be any physical robot but self-driving
   cars are the most talked about.  they typically have three systems that
   work together: 1.) an internal map allowing the car to place itself in
   space (on a road), 2.) a method of using that map to determine the best
   route to your destination, and most relevant to us 3.) a system of
   obstacle avoidance where rl is of most importance.  actuators are
   brakes, throttle, and steering angle inputs.  sensors are typically
   gps, inertial navigation, video, lidar/radar, and rangefinders.  the
   goal, get from a to b safely.

   chess:  a lot can be learned about rl from dissecting the automation of
   game play.  actuators are simply the legal rules-based moves made in
   allowed sequence.  sensor is simply the location of each piece on the
   board following each move     the current state of the    world   .  the
   goal, win the game.

   pong:  yes good ol    atari pong in which you compete with an ai to
   bounce the ball past the other player.  the actuator is moving the
   paddle up or down to connect with the ball.  the sensor is whether the
   ball passes by your opponent or by you to score.  the goal is to reach
   21 before your opponent.


   id24 basics

   of our sample problems, pong and self-driving cars clearly have image
   based pixel inputs and very large and complex state spaces.  chess
   could be approached as a table-based problem or an image based problem,
   either would work.  the automated house is simple enough that
   id24 is probably not necessary.

   the breakthrough that the id24 approach represents should not be
   under estimated.  deepmind, now part of google was the primary
   innovator in this area training rl systems to play atari games better
   than humans.  that is not to say that there is a single approach.  at
   this developmental point in rl application the literature is full of
   various tips and tricks that actually make this work.  in very
   simplified form however, here are the basics.

   the actual implementation of a id98 to estimate the q factor for each
   state/action pair is fairly straightforward except:  it might seem most
   logical to create a id98 that accepts state and action pair inputs and
   outputs a single q factor for that (s,a) pair (called the    on-policy   
   approach).  however, one of the clever work arounds that deepmind
   discovered is to build a id98 that just accepts a state, and outputs
   separate q-values for each possible action (called    off policy   
   approach).

   this is very efficient since we don   t need to run the network forward
   for every action to get all the possible q-values, just once to get the
   spread of q-values from which we can select a maxq(s,a).  still, we
   start with a random seed, and several thousand epochs later, if we   re
   good, we   re approaching a trained id98.

   [38][conv_agent.png?width=300] also, although we   re using a id98 as an
   image classifier, this is not image classification in the sense you may
   be used to.  we are training the id98 to output an action, not whether
   the image is a cat or a dog.

   as with normal image classification, by the time the image is processed
   through several convolutional and pooling steps it will not be
   recognizable to a human interpreter.  that may very well be a child
   darting out from between cars that caused the q-value driven action,
   but neither the rl system nor a human observer would be able to tell
   that was true.


   short term goals versus long term goals

   in the case of the automated house the short and long term goals are
   the same.  in this example from our last article the temperature sensor
   was evaluated every 10 minutes against the goal temperature and this
   cycle simply iterates over and over.  however in the case of game play
   like chess or pong, the strength of a single immediate move must be
   weighed against its overall effect on winning the game.

   this means that the    score    for the current learning cycle (the move in
   chess or the ball strike in pong) has to be evaluated twice and the
   second time may be many moves removed into the future.

   it also means that although your current move may be scored as a win,
   if you lose the game then all the related scores for the moves in that
   game may be scored as a loss causing all those moves, strong and weak,
   to be ignored in future learning.  if there are a great many moves
   between a scored win or loss then a great deal of experience may be
   lost as well.

   the effect is to stretch out the required time to train to thousands or
   even millions of iterations.  however, in the long run this long term
   view is effective so that only strong moves made in the context of a
   winning game are used for learning.  solutions to this problem are in
   the realm of temporal difference learning.

   on the topic of goals, it   s also possible to add complexity and thereby
   require more training by having multiple goals.  for example, mobileye
   is trying to adjust its rl self-driving systems so that not only is the
   accident avoided but also so that the action isn   t likely to create a
   separate accident for the cars around it.


   improving learning speeds with penalties as well as rewards

   [39][rlwithpenalty.png?width=350] in our automated house example,
   whenever the desired behavior was achieved we scored it a    1   , a win,
   in our table.  however, it   s easy to see how we could speed up the
   process and improve the id203 table if we also penalized the rl
   system for making the wrong choice.

   for example, in pong a score is generated every time the ball moves
   toward us and strikes or fails to strike the paddle but the strength of
   that play is only important if we succeed in getting the ball past our
   opponent.  if we do, that move gets a    1   .  if the ai opponent counters
   our move and returns the ball, we award our move a    0   .  however, if
   the ai opponent countered our move and scored against us, we could
   award a penalty    -1    to better differentiate the value of our move.

   similarly in self-driving cars, if the object avoidance rl keeps the
   car centered in the roadway that would be a    1   , a win.  however we
   could award several degrees of penalty (e.g. -1, -2, -3) depending on
   how far from the intended goal we judged that steering input.


   does it generalize

   the game of checkers has 500 billion billion potential moves.  the
   number of potential moves in chess has been calculated to be 10^120.
   that might just be within our computational capability to evaluate
   every single move possible but the reality is that when learning by
   experience we   re not going to examine every potential move, only those
   that are most common.

   when you extend this logic to self-driving cars and the goal of object
   avoidance using multiple sensor inputs, then clearly, only those that
   the system has experienced will be in the memory table.

   in rl, similar to the much simpler problem experienced with a/b testing
   or the slightly more complex multi-arm bandit strategy for ad
   presentation, it   s tempting to go with what   s working.  that is if the
   system has seen the situation sufficiently often to have a strong
   id203 in its table, then go with it.

   however, we always need to ask, does it generalize?  have we really
   seen everything?  and the answer in any system that is    sampled    is
   inevitably a qualified no.  the partial solution to this    exploration
   versus exploitation    problem is a factor in the rl agent typically
   called the    greedy theta (  )   .  greedy theta lets us adjust the rate at
   which the rl continues to explore instead of simply accept the most
   common already seen result.

   as the number of variables to be considered increases, the number of
   actuators, sensors, and even multiple overlapping goals increases rl
   systems fall prey to the same sort of combinatorial explosion seen in
   classical statistical modeling.  rl works best where dimensionality can
   be limited putting a premium on feature extraction and dimensionality
   reduction.


   rl systems have no imagination

   rl systems may learn to navigate or operate a system with known limits
   in a manner far superior to humans, whether that   s a car, a spacecraft,
   or a fusion reactor.  but faced with an input they have never seen
   before with no entry in the table or computable q-value, they will
   always fail.  this can be a simple under-sampling problem or more
   likely a situation identified as the problem of non-stationary
   environments, where discontinuities with the past occur often or at a
   rate too fast for training to recognize or keep up.


   don   t change those actuators or sensors

   this extends not only to novel environments (ice on the road, the child
   darting from between cars) but also to any changes in their actuators
   or sensors.

   the actuator and sensor issue is particularly sensitive in self-driving
   cars which is why developers have been selecting to work with only one
   or two models of vehicles.  in object avoidance for example, the
   steering angle inputs, as well as brakes and throttle would be
   particularly sensitive to the characteristics of the particular car,
   its mass, the distribution of that mass, its center of gravity, etc.
   so you could not take the object avoidance routine from a sports car
   and apply it directly to a minivan.  in system design, we would say
   these systems are brittle since, although they learn, they don   t
   tolerate changes to the actuators, sensors, or even previously unseen
   cases.


   how much training is necessary

   we started with the premise the rl systems are magical because you can
   make them work without training data.  in practice that   s not entirely
   true.  you may not have labeled training data but the systems still
   need time to learn.

   in the case of the automated house the external temperatures are
   repeatably stable on an annual cycle and most temperature adjustments
   will be limited to within a few degrees of what most people find
   comfortable.  given that, you could probably deploy with a year   s data
   especially since the penalty for getting the answer wrong is not
   particularly high.

   in the cases of chess or pong however the alternative moves represent a
   much larger number so much more training will be required.  this also
   illustrates whether training can be conducted on multiple platforms and
   then combined.

   in chess and pong, the answer is undoubtedly yes, the games are always
   uniform.  in the case of the automated house, maybe.  the physical
   characteristics of each house, internal volume, insulation, power of
   the heater, and external characteristics like geographic location are
   likely to be quite different.  faced with this problem you might choose
   to combine the tables or id24 of many different houses to get
   started but accept that those probabilities will need to be adjusted
   based on experience with the actual house to be controlled.

   this is the problem at work that keeps us from having self-driving cars
   today.  the amount of training and the complexity introduced by
   multiple sensors is staggeringly large.  the major developers have all
   deployed fleets of test vehicles to build up their experience tables.
   recently some developers have also taken to video gaming to train.  it
   turns out that the game grand theft auto is sufficiently realistic to
   use as a training simulator to build up rl id203 tables.  not
   that they want their self-driving car to respond that way in real life.

   like the house example, some aggregation of experience tables could be
   used if the vehicles were physically similar.  curiously the one area
   where sharing would be quite valuable is still a stumbling block for
   self-driving cars, [40]simultaneous localization and mapping (slam to
   the engineers working on the problem).

   sharing information car to car about immediate changes in road
   conditions such as the construction caused lane closure or the garbage
   can sitting in the middle of the residential street would be enormously
   valuable.  it would also allow self-driving cars to do a bit of
   negotiation when they encounter one another, for example when merging.
   the reality is that all this data is considered confidential for each
   manufacturer and it   s one area where a little early regulatory
   intervention might actually help.


   how often should the rl system learn and update

   in the design of an rl system you might think this would be easy.  for
   chess, it is after each move.  for pong, after each paddle strikes or
   fails to strike the ball.  for the automated house the 10 minute update
   is probably reasonable.  but for the self-driving car the system must
   update many times per second.

   to add to the complexity, at 60 mph the car is moving 88 ft./second and
   at 20 mph only 29 ft./second (a little over one car length per
   second).  however, the available actuators (brakes, steering angle
   input, and throttle) can   t be used the same way at 60 as at 20.  at
   freeway speeds there is no practical way within the rules of physics to
   avoid an obstacle that suddenly appears two car lengths ahead (the
   chair that fell off the truck ahead).  at 20 mph however your inputs
   can be more radical in terms of close-in obstacle avoidance so the
   system may actually need to cycle more frequently at lower speed, or at
   least be constrained not to make any radical actuator changes at 60
   mph.  so the answer is as often as is necessary to make a good sequence
   of decisions.


   finally

   this article was intentionally more about raising questions than
   offering definitive solutions.  as with any complex technology that is
   just emerging, the challenges are significant and the amount of
   creativity being applied by leading edge adopters is very impressive.
   these two articles taken together along with our introductory article
   are intended to give you a fairly quick lay of the land.  now you can
   dive in wherever your interest leads you.


   other articles in this series

   [41]id23 and ai

   [42]under the hood with id23     understanding basic rl
   models



   about the author:  bill vorhies is editorial director for data science
   central and has practiced as a data scientist since 2001.  he can be
   reached at:

   [43][email protected]


   views: 3879

   tags:
   [44]like
   [45]0 members like this

   [46]share [47]tweet [48]facebook
     * [49]< previous post
     * [50]next post >

   comment

you need to be a member of data science central to add comments!

   [51]join data science central

   [52]rss

   welcome to
   data science central

   [53]sign up
   or [54]sign in

resources

     * [55]join dsc
     * [56]free books
     * [57]forum discussions
     * [58]cheat sheets
     * [59]jobs
     * [60]search dsc
     * [61]dsc on twitter
     * [62]dsc on facebook

videos

     * [63]dsc webinar series: predictive analytics: practical
       applications

[64]dsc webinar series: predictive analytics: practical applications
       added by [65]tim matteson [66]0 comments [67]0 likes

     * [68]dsc webinar series: patterns for successful data science
       projects

[69]dsc webinar series: patterns for successful data science projects
       added by [70]tim matteson [71]0 comments [72]0 likes

     * [73]dsc webinar series: advanced mapping with tableau

[74]dsc webinar series: advanced mapping with tableau
       added by [75]tim matteson [76]0 comments [77]0 likes

     * [78]add videos
     * [79]view all
     * [80]facebook

      2019   data science central      powered by[81] website builder |
   create website | ning.com

   [82]badges  |  [83]report an issue  |  [84]privacy policy  |  [85]terms
   of service

hello, you need to enable javascript to use data science central.

   please check your browser settings or contact your system
   administrator.
     __________________________________________________________________

   most popular content on dsc

   to not miss this type of content in the future, [86]subscribe to our
   newsletter.

   technical
     * [87]free books and resources for dsc members
     * [88]learn machine learning coding basics in a weekend
     * [89]new machine learning cheat sheet | [90]old one
     * [91]advanced machine learning with basic excel
     * [92]12 algorithms every data scientist should know
     * [93]hitchhiker's guide to data science, machine learning, r, python
     * [94]visualizations: comparing tableau, spss, r, excel, matlab, js,
       pyth...
     * [95]how to automatically determine the number of clusters in your
       data
     * [96]new perspectives on statistical distributions and deep learning
     * [97]fascinating new results in the theory of randomness
     * [98]long-range correlations in time series: modeling, testing, case
       study
     * [99]fast combinatorial feature selection with new definition of
       predict...
     * [100]10 types of regressions. which one to use?
     * [101]40 techniques used by data scientists
     * [102]15 deep learning tutorials
     * [103]r: a survival guide to data science with r

   non technical

     * [104]advanced analytic platforms - incumbents fall - challengers
       rise
     * [105]difference between ml, data science, ai, deep learning, and
       statistics
     * [106]how to become a data scientist - on your own
     * [107]16 analytic disciplines compared to data science
     * [108]six categories of data scientists
     * [109]21 data science systems used by amazon to operate its business
     * [110]24 uses of statistical modeling
     * [111]33 unusual problems that can be solved with data science
     * [112]22 differences between junior and senior data scientists
     * [113]why you should be a data science generalist - and how to
       become one
     * [114]becoming a billionaire data scientist vs struggling to get a
       $100k job
     * [115]why do people with no experience want to become data
       scientists?

   articles from top bloggers

     * [116]kirk borne | [117]stephanie glen | [118]vincent granville
     * [119]ajit jaokar | [120]ronald van loon | [121]bernard marr
     * [122]steve miller | [123]bill schmarzo | [124]bill vorhies

   other popular resources

     * [125]comprehensive repository of data science and ml resources
     * [126]statistical concepts explained in simple english
     * [127]machine learning concepts explained in one picture
     * [128]100 data science interview questions and answers
     * [129]cheat sheets | [130]curated
       articles | [131]search | [132]jobs | [133]courses
     * [134]post a blog | [135]forum
       questions | [136]books | [137]salaries | [138]news

   archives: [139]2008-2014 | [140]2015-2016 | [141]2017-2019 | [142]book
   1 | [143]book 2 | [144]more

   follow us: [145]twitter | [146]facebook
     __________________________________________________________________

   most popular articles

     * [147]free book and resources for dsc members
     * [148]new perspectives on statistical distributions and deep
       learning
     * [149]time series, growth modeling and data science wizardy
     * [150]statistical concepts explained in simple english
     * [151]machine learning concepts explained in one picture
     * [152]comprehensive repository of data science and ml resources
     * [153]advanced machine learning with basic excel
     * [154]difference between ml, data science, ai, deep learning, and
       statistics
     * [155]selected business analytics, data science and ml articles
     * [156]how to automatically determine the number of clusters in your
       data
     * [157]fascinating new results in the theory of randomness
     * [158]hire a data scientist | [159]search dsc | [160]find a job
     * [161]post a blog | [162]forum questions

   [8fa427bf6de170faefe32330e3b4b102?n_seg=_technology&n_name=data science
   central]

references

   visible links
   1. https://www.datasciencecentral.com/profiles/blog/feed?user=0h5qapp2gbuf8&xn_auth=no
   2. https://www.datasciencecentral.com/profiles/comment/feed?attachedto=6448529:blogpost:614886&xn_auth=no
   3. https://www.googletagmanager.com/ns.html?id=gtm-t5w4wq
   4. https://www.datasciencecentral.com/profiles/blogs/reinforcement-learning-part-3-challenges-considerations
   5. https://www.datasciencecentral.com/main/authorization/signup?target=https://www.datasciencecentral.com/profiles/blogs/reinforcement-learning-part-3-challenges-considerations
   6. https://www.datasciencecentral.com/main/authorization/signin?target=https://www.datasciencecentral.com/profiles/blogs/reinforcement-learning-part-3-challenges-considerations
   7. https://www.datasciencecentral.com/
   8. https://www.datasciencecentral.com/
   9. https://www.datasciencecentral.com/page/most-popular-content-on-dsc
  10. https://www.datasciencecentral.com/page/editorial-guidelines
  11. https://www.datasciencecentral.com/page/user-agreement
  12. https://www.datasciencecentral.com/page/cookie-policy
  13. https://www.datasciencecentral.com/page/search?q=ai
  14. https://www.datasciencecentral.com/page/search?q=machine+learning
  15. https://www.datasciencecentral.com/page/search?q=deep+learning
  16. https://www.analyticbridge.datasciencecentral.com/
  17. https://www.statisticshowto.datasciencecentral.com/
  18. https://www.bigdatanews.datasciencecentral.com/
  19. https://www.datavizualization.datasciencecentral.com/
  20. https://www.hadoop360.datasciencecentral.com/
  21. https://www.datasciencecentral.com/video/video/listtagged?tag=dsc+podcast+series
  22. https://www.datasciencecentral.com/video/video/listfeatured
  23. https://www.datasciencecentral.com/forum
  24. https://www.analytictalent.datasciencecentral.com/
  25. https://www.datasciencecentral.com/profiles/blogs/check-out-our-dsc-newsletter
  26. https://www.datasciencecentral.com/page/most-popular-content-on-dsc
  27. https://www.datasciencecentral.com/groups/group/list
  28. https://www.datasciencecentral.com/page/search
  29. https://www.datasciencecentral.com/page/contact-us
  30. https://www.datasciencecentral.com/profiles/blogs/check-out-our-dsc-newsletter
  31. https://www.datasciencecentral.com/profiles/blog/list
  32. https://www.datasciencecentral.com/profiles/blog/list?my=1
  33. https://www.datasciencecentral.com/profiles/blog/new
  34. https://www.datasciencecentral.com/profile/williamvorhies
  35. https://www.datasciencecentral.com/profiles/blog/list?user=0h5qapp2gbuf8
  36. https://api.ning.com/files/5vrkdqxp-amzolnryws6pag8x6xjrxtnzz-ugdyvdpfm*hdwvxecj-p1zzcrnrmxtsnqiw5q2obxwlzu0wd4i3mvbmcz3c8y/rlxkcd.png
  37. https://www.datasciencecentral.com/profiles/blogs/under-the-hood-with-reinforcement-learning-understanding-basic-rl
  38. https://api.ning.com/files/5vrkdqxp-aoiz5r1vt3htynoogxdil1zxpoey3dfbqdkzmaax52n5mo1fzwsohayfnrjxgwu0ezzqvusyrohqfjv28qwqnkz/conv_agent.png
  39. https://api.ning.com/files/5vrkdqxp-aorh7u-mxvgojncfu5htvkfiz-smc2rfxiyyjbng*bfiy*icaalzujepnk9muicsfdjnmr848po9dl7paoqnzex/rlwithpenalty.png
  40. https://www.datasciencecentral.com/profiles/blogs/slam-the-sound-of-autonomous-vehicles-colliding
  41. https://www.datasciencecentral.com/profiles/blogs/reinforcement-learning-and-ai
  42. https://www.datasciencecentral.com/profiles/blogs/under-the-hood-with-reinforcement-learning-understanding-basic-rl
  43. https://www.datasciencecentral.com/cdn-cgi/l/email-protection#d391babfbf9397b2a7b280b0bab6bdb0b690b6bda7a1b2bffdb0bcbe
  44. https://www.datasciencecentral.com/profiles/blogs/reinforcement-learning-part-3-challenges-considerations
  45. https://www.datasciencecentral.com/profiles/blogs/reinforcement-learning-part-3-challenges-considerations
  46. https://www.datasciencecentral.com/main/sharing/share?id=6448529%3ablogpost%3a614886
  47. https://twitter.com/share
  48. https://www.facebook.com/share.php?u=https://www.datasciencecentral.com/profiles/blogs/reinforcement-learning-part-3-challenges-considerations?xg_source=facebook&t=id23 part 3     challenges & considerations on data science central
  49. https://www.datasciencecentral.com/profiles/blogs/under-the-hood-with-reinforcement-learning-understanding-basic-rl
  50. https://www.datasciencecentral.com/profiles/blogs/dealing-with-imbalanced-datasets
  51. https://www.datasciencecentral.com/main/authorization/signup?target=https://www.datasciencecentral.com/profiles/blogs/reinforcement-learning-part-3-challenges-considerations
  52. https://www.datasciencecentral.com/profiles/comment/feed?attachedto=6448529:blogpost:614886&xn_auth=no
  53. https://www.datasciencecentral.com/main/authorization/signup?target=https://www.datasciencecentral.com/profiles/blogs/reinforcement-learning-part-3-challenges-considerations
  54. https://www.datasciencecentral.com/main/authorization/signin?target=https://www.datasciencecentral.com/profiles/blogs/reinforcement-learning-part-3-challenges-considerations
  55. https://www.datasciencecentral.com/profiles/blogs/check-out-our-dsc-newsletter
  56. https://www.datasciencecentral.com/profiles/blogs/new-books-and-resources-for-dsc-members
  57. https://www.datasciencecentral.com/forum
  58. https://www.datasciencecentral.com/page/search?q=cheat+sheets
  59. https://www.analytictalent.datasciencecentral.com/
  60. https://www.datasciencecentral.com/page/search?q=one+picture
  61. https://twitter.com/datasciencectrl
  62. https://www.facebook.com/datasciencecentralcommunity/
  63. https://www.datasciencecentral.com/video/dsc-webinar-series-predictive-analytics-practical-applications
  64. https://www.datasciencecentral.com/video/dsc-webinar-series-predictive-analytics-practical-applications
  65. https://www.datasciencecentral.com/profile/2edcolrgc4o4b
  66. https://www.datasciencecentral.com/video/dsc-webinar-series-predictive-analytics-practical-applications#comments
  67. https://www.datasciencecentral.com/video/dsc-webinar-series-predictive-analytics-practical-applications
  68. https://www.datasciencecentral.com/video/dsc-webinar-series-patterns-for-successful-data-science-projects
  69. https://www.datasciencecentral.com/video/dsc-webinar-series-patterns-for-successful-data-science-projects
  70. https://www.datasciencecentral.com/profile/2edcolrgc4o4b
  71. https://www.datasciencecentral.com/video/dsc-webinar-series-patterns-for-successful-data-science-projects#comments
  72. https://www.datasciencecentral.com/video/dsc-webinar-series-patterns-for-successful-data-science-projects
  73. https://www.datasciencecentral.com/video/dsc-webinar-series-advanced-mapping-with-tableau
  74. https://www.datasciencecentral.com/video/dsc-webinar-series-advanced-mapping-with-tableau
  75. https://www.datasciencecentral.com/profile/2edcolrgc4o4b
  76. https://www.datasciencecentral.com/video/dsc-webinar-series-advanced-mapping-with-tableau#comments
  77. https://www.datasciencecentral.com/video/dsc-webinar-series-advanced-mapping-with-tableau
  78. https://www.datasciencecentral.com/video/video/chooseuploader
  79. https://www.datasciencecentral.com/video/video
  80. https://www.facebook.com/share.php?u=https://www.datasciencecentral.com/video/video?from=fb
  81. https://www.ning.com/
  82. https://www.datasciencecentral.com/main/embeddable/list
  83. https://www.datasciencecentral.com/main/authorization/signup?target=https://www.datasciencecentral.com/main/index/report
  84. https://www.datasciencecentral.com/main/authorization/privacypolicy?previousurl=https://www.datasciencecentral.com/profiles/blogs/reinforcement-learning-part-3-challenges-considerations
  85. https://www.datasciencecentral.com/main/authorization/termsofservice?previousurl=https://www.datasciencecentral.com/profiles/blogs/reinforcement-learning-part-3-challenges-considerations
  86. https://www.datasciencecentral.com/profiles/blogs/check-out-our-dsc-newsletter
  87. https://www.datasciencecentral.com/profiles/blogs/new-books-and-resources-for-dsc-members
  88. https://www.datasciencecentral.com/profiles/blogs/learn-machinelearning-coding-basics-in-a-weekend-a-new-approach
  89. https://www.datasciencecentral.com/profiles/blogs/new-data-science-cheat-sheet
  90. https://www.datasciencecentral.com/profiles/blogs/data-science-cheat-sheet
  91. https://www.datasciencecentral.com/profiles/blogs/advanced-machine-learning-with-basic-excel
  92. https://www.datasciencecentral.com/profiles/blogs/12-algorithms-every-data-scientist-should-know
  93. https://www.datasciencecentral.com/profiles/blogs/hitchhiker-s-guide-to-data-science-machine-learning-r-python
  94. https://www.datasciencecentral.com/profiles/blogs/visualizations-comparing-tableau-spss-r-excel-matlab
  95. https://www.datasciencecentral.com/profiles/blogs/how-to-automatically-determine-the-number-of-clusters-in-your-dat
  96. https://www.datasciencecentral.com/profiles/blogs/decomposition-of-statistical-distributions-using-mixture-models-a
  97. https://www.datasciencecentral.com/profiles/blogs/fascinating-new-results-in-the-theory-of-randomness
  98. https://www.datasciencecentral.com/profiles/blogs/long-range-correlation-in-time-series-tutorial-and-case-study
  99. https://www.datasciencecentral.com/profiles/blogs/feature-selection-based-on-predictive-power
 100. https://www.datasciencecentral.com/profiles/blogs/10-types-of-regressions-which-one-to-use
 101. https://www.datasciencecentral.com/profiles/blogs/40-techniques-used-by-data-scientists
 102. https://www.datasciencecentral.com/profiles/blogs/15-deep-learning-tutorials
 103. https://www.datasciencecentral.com/profiles/blogs/one-page-r-a-survival-guide-to-data-science-with-rone-page
 104. https://www.datasciencecentral.com/profiles/blogs/advanced-analytic-platforms-incumbents-fall-challengers-rise
 105. https://www.datasciencecentral.com/profiles/blogs/difference-between-machine-learning-data-science-ai-deep-learning
 106. https://www.datasciencecentral.com/profiles/blogs/how-to-become-a-data-scientist-for-free
 107. https://www.datasciencecentral.com/profiles/blogs/17-analytic-disciplines-compared
 108. https://www.datasciencecentral.com/profiles/blogs/six-categories-of-data-scientists
 109. https://www.datasciencecentral.com/profiles/blogs/20-data-science-systems-used-by-amazon-to-operate-its-business
 110. https://www.datasciencecentral.com/profiles/blogs/24-uses-of-statistical-modeling-part-ii
 111. https://www.datasciencecentral.com/profiles/blogs/33-unusual-problems-that-can-be-solved-with-data-science
 112. https://www.datasciencecentral.com/profiles/blogs/10-differences-between-junior-and-senior-data-scientist
 113. https://www.datasciencecentral.com/profiles/blogs/why-you-should-be-a-data-science-generalist
 114. https://www.datasciencecentral.com/profiles/blogs/becoming-a-billionaire-data-scientist-vs-struggling-to-get-a-100k
 115. https://www.datasciencecentral.com/profiles/blogs/why-do-people-with-no-experience-want-to-become-data-scientists
 116. https://www.analyticbridge.datasciencecentral.com/profiles/blog/list?user=1zo63k80n1dij
 117. https://www.datasciencecentral.com/profiles/blog/list?user=0lahn4b4odglr
 118. https://www.datasciencecentral.com/profiles/blogs/my-data-science-machine-learning-and-related-articles
 119. https://www.datasciencecentral.com/profiles/blog/list?user=32ac9fc41n4f4
 120. https://www.datasciencecentral.com/profiles/blog/list?user=3f0kgbtc91mum
 121. https://www.datasciencecentral.com/profiles/blog/list?user=00t05rv0ehb3k
 122. https://www.datasciencecentral.com/profiles/blog/list?user=00u6blr1dk4fz
 123. https://www.datasciencecentral.com/profiles/blog/list?user=0do9dajam14h1
 124. https://www.datasciencecentral.com/profiles/blog/list?user=0h5qapp2gbuf8
 125. https://www.datasciencecentral.com/profiles/blogs/comprehensive-repository-of-data-science-and-ml-resources
 126. https://www.datasciencecentral.com/page/search?q=statistical+concepts
 127. https://www.datasciencecentral.com/page/search?q=in+one+pictures
 128. https://www.datasciencecentral.com/profiles/blogs/100-data-science-interview-questions-and-answers
 129. https://www.datasciencecentral.com/page/search?q=cheat+sheets
 130. https://www.datasciencecentral.com/profiles/blogs/21-curated-blogs-about-deep-learning-and-data-science
 131. https://www.datasciencecentral.com/page/search?q=python
 132. http://www.analytictalent.com/
 133. https://www.datasciencecentral.com/page/search?q=courses
 134. https://www.datasciencecentral.com/profiles/blog/new
 135. https://www.datasciencecentral.com/forum/topic/new
 136. https://www.datasciencecentral.com/page/search?q=books
 137. https://www.datasciencecentral.com/page/search?q=salary
 138. https://www.bigdatanews.datasciencecentral.com/group/bdn-daily-press-releases/forum
 139. https://www.analyticbridge.datasciencecentral.com/page/links
 140. https://www.datasciencecentral.com/group/resources/forum/topics/selection-of-best-articles-from-our-past-weekly-digests
 141. https://www.datasciencecentral.com/page/previous-digests
 142. https://www.analyticbridge.datasciencecentral.com/group/data-science/forum/topics/data-science-e-book-first-draft-available-for-download
 143. https://www.datasciencecentral.com/profiles/blogs/my-data-science-book
 144. https://www.datasciencecentral.com/profiles/blogs/older-data-science-articles-still-of-great-value-today
 145. https://twitter.com/datasciencectrl
 146. https://www.facebook.com/datasciencecentralcommunity/
 147. https://www.datasciencecentral.com/profiles/blogs/new-books-and-resources-for-dsc-members
 148. https://www.datasciencecentral.com/profiles/blogs/decomposition-of-statistical-distributions-using-mixture-models-a
 149. https://www.datasciencecentral.com/profiles/blogs/data-science-wizardry
 150. https://www.datasciencecentral.com/page/search?q=statistical+concepts
 151. https://www.datasciencecentral.com/page/search?q=in+one+pictures
 152. https://www.datasciencecentral.com/profiles/blogs/comprehensive-repository-of-data-science-and-ml-resources
 153. https://www.datasciencecentral.com/profiles/blogs/advanced-machine-learning-with-basic-excel
 154. https://www.datasciencecentral.com/profiles/blogs/difference-between-machine-learning-data-science-ai-deep-learning
 155. https://www.datasciencecentral.com/profiles/blogs/my-data-science-machine-learning-and-related-articles
 156. https://www.datasciencecentral.com/profiles/blogs/how-to-automatically-determine-the-number-of-clusters-in-your-dat
 157. https://www.datasciencecentral.com/profiles/blogs/fascinating-new-results-in-the-theory-of-randomness
 158. http://careers.analytictalent.com/jobs/products
 159. https://www.datasciencecentral.com/page/search?q=python
 160. http://www.analytictalent.com/
 161. https://www.datasciencecentral.com/profiles/blog/new
 162. https://www.datasciencecentral.com/forum/topic/new

   hidden links:
 164. https://www.datasciencecentral.com/profile/williamvorhies
 165. https://www.datasciencecentral.com/forum
 166. https://www.datasciencecentral.com/page/search?q=cheat+sheets
 167. https://analytictalent.com/
