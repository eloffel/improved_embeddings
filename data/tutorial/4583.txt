    #[1]publisher [2]fortune    why deep learning is suddenly changing your
   life comments feed [3]alternate [4]alternate [5]fortune
   [6]wordpress.com

   main menu
   [7]

fortune.com

   [8]subscribe

   ____________________ (button)
   search

   [9]sign in

     *    2019 fortune media ip limited. all rights reserved.

     * e-mail
     * tweet
     * facebook
     * linkedin

   share icons
   by roger parloff
   illustration by justin metz
   september 28, 2016, 5:00 pm edt

why deep learning is suddenly changing your life

decades-old discoveries are now electrifying the computing industry and will
soon transform corporate america.

   over the past four years, readers have doubtlessly noticed quantum
   leaps in the quality of a wide range of everyday technologies.

   most obviously, the speech-recognition functions on our smartphones
   work much better than they used to. when we use a voice command to call
   our spouses, we reach them now. we aren   t connected to amtrak or an
   angry ex.

   in fact, we are increasingly interacting with our computers by just
   talking to them, whether it   s amazon   s alexa, apple   s siri, microsoft   s
   cortana, or the many voice-responsive features of google. chinese
   search giant baidu says customers have tripled their use of its speech
   interfaces in the past 18 months.

   machine translation and other forms of language processing have also
   become far more convincing, with [10]google [11]googl , [12]microsoft
   [13]msft , [14]facebook [15]fb , and baidu [16]bidu unveiling new
   tricks every month. google translate now renders spoken sentences in
   one language into spoken sentences in another for 32 pairs of
   languages, while offering text translations for 103 tongues, including
   cebuano, igbo, and zulu. google   s inbox app offers three ready-made
   replies for many incoming emails.

   then there are the advances in image recognition. the same four
   companies all have features that let you search or automatically
   organize collections of photos with no identifying tags. you can ask to
   be shown, say, all the ones that have dogs in them, or snow, or even
   something fairly abstract like hugs. the companies all have prototypes
   in the works that generate sentence-long descriptions for the photos in
   seconds.

   think about that. to gather up dog pictures, the app must identify
   anything from a chihuahua to a german shepherd and not be tripped up if
   the pup is upside down or partially obscured, at the right of the frame
   or the left, in fog or snow, sun or shade. at the same time it needs to
   exclude wolves and cats. using pixels alone. how is that possible?
   [17][lrn-10-01-16-neural-networks-e1474990995824.png] click to enlarge
   the graphic.

   the advances in image recognition extend far beyond cool social apps.
   medical startups claim they   ll soon be able to use computers to read
   x-rays, mris, and ct scans more rapidly and accurately than
   radiologists, to diagnose cancer earlier and less invasively, and to
   accelerate the search for life-saving pharmaceuticals. better image
   recognition is crucial to unleashing improvements in robotics,
   autonomous drones, and, of course, self-driving cars   a development so
   momentous that we made it a [18]cover story in june. [19]ford [20]f ,
   tesla [21]tsla , uber, baidu, and google parent alphabet are all
   testing prototypes of self-piloting vehicles on public roads today.

   but what most people don   t realize is that all these breakthroughs are,
   in essence, the same breakthrough. they   ve all been made possible by a
   family of artificial intelligence (ai) techniques popularly known as
   deep learning, though most scientists still prefer to call them by
   their original academic designation: deep neural networks.

   the most remarkable thing about neural nets is that no human being has
   programmed a computer to perform any of the stunts described above. in
   fact, no human could. programmers have, rather, fed the computer a
   learning algorithm, exposed it to terabytes of data   hundreds of
   thousands of images or years    worth of speech samples   to train it, and
   have then allowed the computer to figure out for itself how to
   recognize the desired objects, words, or sentences.

   in short, such computers can now teach themselves.    you essentially
   have software writing software,    says jen-hsun huang, ceo of graphics
   processing leader nvidia [22]nvda , which began placing a massive bet
   on deep learning about five years ago. (for more, read [23]fortune   s
   interview with nvidia ceo jen-hsun huang.)

   neural nets aren   t new. the concept dates back to the 1950s, and many
   of the key algorithmic breakthroughs occurred in the 1980s and 1990s.
   what   s changed is that today computer scientists have finally harnessed
   both the vast computational power and the enormous storehouses of
   data   images, video, audio, and text files strewn across the
   internet   that, it turns out, are essential to making neural nets work
   well.    this is deep learning   s cambrian explosion,    says frank chen, a
   partner at the andreessen horowitz venture capital firm, alluding to
   the geological era when most higher animal species suddenly burst onto
   the scene.

   that dramatic progress has sparked a burst of activity. equity funding
   of ai-focused startups reached an all-time high last quarter of more
   than $1 billion, according to the [24]cb insights research firm. there
   were 121 funding rounds for such startups in the second quarter of
   2016, compared with 21 in the equivalent quarter of 2011, that group
   says. more than $7.5 billion in total investments have been made during
   that stretch   with more than $6 billion of that coming since 2014. (in
   late september, five corporate ai leaders   amazon, facebook, google,
   ibm, and microsoft   formed the nonprofit [25]partnership on ai to
   advance public understanding of the subject and conduct research on
   ethics and best practices.)

   google had two deep-learning projects underway in 2012. today it is
   pursuing more than 1,000, according to a spokesperson, in all its major
   product sectors, including search, android, gmail, translation, maps,
   youtube, and self-driving cars. ibm   s [26]ibm watson system used ai,
   but not deep learning, when it beat two jeopardy champions in 2011.
   now, though, almost all of watson   s 30 component services have been
   augmented by deep learning, according to watson cto rob high.

   venture capitalists, who didn   t even know what deep learning was five
   years ago, today are wary of startups that don   t have it.    we   re now
   living in an age,    chen observes,    where it   s going to be mandatory for
   people building sophisticated software applications.    people will soon
   demand, he says,          where   s your natural-language processing version?   
      how do i talk to your app? because i don   t want to have to click
   through menus.         

                  for more on ai, watch this fortune video:

   some companies are already integrating deep learning into their own
   day-to-day processes. says peter lee, cohead of microsoft research:
      our sales teams are using neural nets to recommend which prospects to
   contact next or what kinds of product offerings to recommend.   

   the hardware world is feeling the tremors. the increased computational
   power that is making all this possible derives not only from moore   s
   law but also from the realization in the late 2000s that graphics
   processing units (gpus) made by nvidia   the powerful chips that were
   first designed to give gamers rich, 3d visual experiences   were 20 to 50
   times more efficient than traditional central processing units (cpus)
   for deep-learning computations. this past august, nvidia announced that
   quarterly revenue for its data center segment had more than doubled
   year over year, to $151 million. its chief financial officer told
   investors that    the vast majority of the growth comes from deep
   learning by far.    the term    deep learning    came up 81 times during the
   83-minute earnings call.

   chip giant [27]intel [28]intc isn   t standing still. in the past two
   months it has purchased [29]nervana systems (for more than $400
   million) and [30]movidius (price undisclosed), two startups that make
   technology tailored for different phases of deep-learning computations.

   for its part, google revealed in may that for over a year it had been
   secretly using its own tailor-made chips, called tensor processing
   units, or tpus, to implement applications trained by deep learning.
   (tensors are arrays of numbers, like matrices, which are often
   multiplied against one another in deep-learning computations.)

   indeed, corporations just may have reached another inflection point.
      in the past,    says andrew ng, chief scientist at baidu research,    a
   lot of s&p 500 ceos wished they had started thinking sooner than they
   did about their internet strategy. i think five years from now there
   will be a number of s&p 500 ceos that will wish they   d started thinking
   earlier about their ai strategy.   

   even the internet metaphor doesn   t do justice to what ai with deep
   learning will mean, in ng   s view.    ai is the new electricity,    he says.
      just as 100 years ago electricity transformed industry after industry,
   ai will now do the same.   

   think of deep learning as a subset of a subset.    artificial
   intelligence    encompasses a vast range of technologies   like traditional
   logic and rules-based systems   that enable computers and robots to solve
   problems in ways that at least superficially resemble thinking. within
   that realm is a smaller category called machine learning, which is the
   name for a whole toolbox of arcane but important mathematical
   techniques that enable computers to improve at performing tasks with
   experience. finally, within machine learning is the smaller subcategory
   called deep learning.

   one way to think of what deep learning does is as    a to b mappings,   
   says baidu   s ng.    you can input an audio clip and output the
   transcript. that   s id103.    as long as you have data to
   train the software, the possibilities are endless, he maintains.    you
   can input email, and the output could be: is this spam or not?    input
   loan applications, he says, and the output might be the likelihood a
   customer will repay it. input usage patterns on a fleet of cars, and
   the output could advise where to send a car next.

a glossary of artificial-intelligence terms

     * artificial intelligence
     * ai is the broadest term, applying to any technique that enables
       computers to mimic human intelligence, using logic, if-then rules,
       id90, and machine learning (including deep learning).
     * machine learning
     * the subset of ai that includes abstruse statistical techniques that
       enable machines to improve at tasks with experience. the category
       includes deep learning.
     * deep learning
     * the subset of machine learning composed of algorithms that permit
       software to train itself to perform tasks, like speech and image
       recognition, by exposing multilayered neural networks to vast
       amounts of data.

   deep learning, in that vision, could transform almost any industry.
      there are fundamental changes that will happen now that computer
   vision really works,    says jeff dean, who leads the google brain
   project. or, as he unsettlingly rephrases his own sentence,    now that
   computers have opened their eyes.   

   does that mean it   s time to brace for    the singularity      the
   hypothesized moment when superintelligent machines start improving
   themselves without human involvement, triggering a runaway cycle that
   leaves lowly humans ever further in the dust, with terrifying
   consequences?

   not just yet. neural nets are good at recognizing patterns   sometimes as
   good as or better than we are at it. but they can   t reason.

   the first sparks of the impending revolution began flickering in 2009.
   that summer microsoft   s principal researcher li deng invited neural
   nets pioneer geoffrey hinton, of the university of toronto, to visit.
   impressed with his research, deng   s group experimented with neural nets
   for id103.    we were shocked by the results,    lee says.    we
   were achieving more than 30% improvements in accuracy with the very
   first prototypes.

   in 2011, microsoft introduced deep-learning technology into its
   commercial speech-recognition products, according to lee. google
   followed suit in august 2012.

   but the real turning point came in october 2012. at a workshop in
   florence, italy, fei-fei li, the head of the stanford ai lab and the
   founder of the prominent annual id163 computer-vision contest,
   announced that two of hinton   s students had invented software that
   identified objects with almost twice the accuracy of the nearest
   competitor.    it was a spectacular result,    recounts hinton,    and
   convinced lots and lots of people who had been very skeptical before.   
   (in last year   s contest a deep-learning entrant surpassed human
   performance.)

   cracking image recognition was the starting gun, and it kicked off a
   hiring race. google landed hinton and the two students who had won that
   contest. facebook signed up french deep learning innovator yann lecun,
   who, in the 1980s and 1990s, had pioneered the type of algorithm that
   won the id163 contest. and baidu snatched up ng, a former head of
   the stanford ai lab, who had helped launch and lead the
   deep-learning-focused google brain project in 2010.

   the hiring binge has only intensified since then. today, says
   microsoft   s lee, there   s a    bloody war for talent in this space.    he
   says top-flight minds command offers    along the lines of nfl football
   players.   

   geoffrey hinton, 68, first heard of neural networks in 1972 when he
   started his graduate work in artificial intelligence at the university
   of edinburgh. having studied experimental psychology as an
   undergraduate at cambridge, hinton was enthusiastic about neural nets,
   which were software constructs that took their inspiration from the way
   networks of neurons in the brain were thought to work. at the time,
   neural nets were out of favor.    everybody thought they were crazy,    he
   recounts. but hinton soldiered on.

   neural nets offered the prospect of computers    learning the way
   children do   from experience   rather than through laborious instruction
   by programs tailor-made by humans.    most of ai was inspired by logic
   back then,    he recalls.    but logic is something people do very late in
   life. kids of 2 and 3 aren   t doing logic. so it seemed to me that
   neural nets were a much better paradigm for how intelligence would work
   than logic was.    (logic, as it happens, is one of the hinton family
   trades. he comes from a long line of eminent scientists and is the
   great-great-grandson of 19th-century mathematician george boole, after
   whom boolean searches, logic, and algebra are named.)

   during the 1950s and    60s, neural networks were in vogue among computer
   scientists. in 1958, cornell research psychologist frank rosenblatt, in
   a navy-backed project, built a prototype neural net, which he called
   the id88, at a lab in buffalo. it used a punch-card computer that
   filled an entire room. after 50 trials it learned to distinguish
   between cards marked on the left and cards marked on the right.
   reporting on the event, the new york times wrote,    the navy revealed
   the embryo of an electronic computer today that it expects will be able
   to walk, talk, see, write, reproduce itself and be conscious of its
   existence.   

   the id88, whose software had only one layer of neuron-like nodes,
   proved limited. but researchers believed that more could be
   accomplished with multilayer   or deep   neural networks.

   hinton explains the basic idea this way. suppose a neural net is
   interpreting photographic images, some of which show birds.    so the
   input would come in, say, pixels, and then the first layer of units
   would detect little edges. dark one side, bright the other side.    the
   next level of neurons, analyzing data sent from the first layer, would
   learn to detect    things like corners, where two edges join at an
   angle,    he says. one of these neurons might respond strongly to the
   angle of a bird   s beak, for instance.

   the next level    might find more complicated configurations, like a
   bunch of edges arranged in a circle.    a neuron at this level might
   respond to the head of the bird. at a still higher level a neuron might
   detect the recurring juxtaposition of beaklike angles near headlike
   circles.    and that   s a pretty good cue that it might be the head of a
   bird,    says hinton. the neurons of each higher layer respond to
   concepts of greater complexity and abstraction, until one at the top
   level corresponds to our concept of    bird.   

   to learn, however, a deep neural net needed to do more than just send
   messages up through the layers in this fashion. it also needed a way to
   see if it was getting the right results at the top layer and, if not,
   send messages back down so that all the lower neuron-like units could
   retune their activations to improve the results. that   s where the
   learning would occur.

   iframe:
   [31]https://s3.amazonaws.com/fortune.digital/2016/deep-learning-timelin
   e/key-moments.html?iframe_id=fortune-iframe-embed-07ef1c1b2185cd66c88a9
   84870ece03037e5569d

   in the early 1980s, hinton was working on this problem. so was a french
   researcher named yann lecun, who was just starting his graduate work in
   paris. lecun stumbled on a 1983 paper by hinton, which talked about
   multilayer neural nets.    it was not formulated in those terms,    lecun
   recalls,    because it was very difficult at that time actually to
   publish a paper if you mentioned the word    neurons    or    neural nets.   
   so he wrote this paper in an obfuscated manner so it would pass the
   reviewers. but i thought the paper was super-interesting.    the two met
   two years later and hit it off.

   in 1986, hinton and two colleagues wrote a seminal paper offering an
   algorithmic solution to the error-correction problem.    his paper was
   basically the foundation of the second wave of neural nets,    says
   lecun. it reignited interest in the field.

   after a post-doc stint with hinton, lecun moved to at&t   s bell labs in
   1988, where during the next decade he did foundational work that is
   still being used today for most image-recognition tasks. in the 1990s,
   [32]ncr [33]ncr , which was then a bell labs subsidiary, commercialized
   a neural-nets-powered device, widely used by banks, which could read
   handwritten digits on checks, according to lecun. at the same time, two
   german researchers   sepp hochreiter, now at the university of linz, and
   j  rgen schmidhuber, codirector of a swiss ai lab in lugano   were
   independently pioneering a different type of algorithm that today, 20
   years later, has become crucial for natural-language processing
   applications.

   despite all the strides, in the mid-1990s neural nets fell into
   disfavor again, eclipsed by what were, given the computational power of
   the times, more effective machine-learning tools. that situation
   persisted for almost a decade, until computing power increased another
   three to four orders of magnitude and researchers discovered gpu
   acceleration.

   but one piece was still missing: data. although the internet was awash
   in it, most data   especially when it came to images   wasn   t labeled, and
   that   s what you needed to train neural nets. that   s where fei-fei li, a
   stanford ai professor, stepped in.    our vision was that big data would
   change the way machine learning works,    she explains in an interview.
      data drives learning.   

   in 2007 she launched id163, assembling a free database of more than
   14 million labeled images. it went live in 2009, and the next year she
   set up an annual contest to incentivize and publish computer-vision
   breakthroughs.

   in october 2012, when two of hinton   s students won that competition, it
   became clear to all that deep learning had arrived.

   by then the general public had also heard about deep learning, though
   due to a different event. in june 2012, google brain published the
   results of a quirky project now known colloquially as the    [34]cat
   experiment.    it struck a comic chord and went viral on social networks.

   the project actually explored an important unsolved problem in deep
   learning called    unsupervised learning.    almost every deep-learning
   product in commercial use today uses    supervised learning,    meaning
   that the neural net is trained with labeled data (like the images
   assembled by id163). with    unsupervised learning,    by contrast, a
   neural net is shown unlabeled data and asked simply to look for
   recurring patterns. researchers would love to master unsupervised
   learning one day because then machines could teach themselves about the
   world from vast stores of data that are unusable today   making sense of
   the world almost totally on their own, like infants.

   in the cat experiment, researchers exposed a vast neural net   spread
   across 1,000 computers   to 10 million unlabeled images randomly taken
   from youtube videos, and then just let the software do its thing. when
   the dust cleared, they checked the neurons of the highest layer and
   found, sure enough, that one of them responded powerfully to images of
   cats.    we also found a neuron that responded very strongly to human
   faces,    says ng, who led the project while at google brain.

   yet the results were puzzling too.    we did not find a neuron that
   responded strongly to cars,    for instance, and    there were a lot of
   other neurons we couldn   t assign an english word to. so it   s
   difficult.   

   the experiment created a sensation. but unsupervised learning remains
   uncracked   a challenge for the future.

   not surprisingly, most of the deep-learning applications that have been
   commercially deployed so far involve companies like google, microsoft,
   facebook, baidu, and amazon   the companies with the vast stores of data
   needed for deep-learning computations. many companies are trying to
   develop more realistic and helpful    chatbots      automated
   customer-service representatives.

   iframe:
   [35]https://s3.amazonaws.com/fortune.digital/2016/deep-learning/index.h
   tml?iframe_id=fortune-iframe-embed-3fdce483a7ba4d1cf1eb408d0ee74315407f
   82b5

   companies like [36]ibm and microsoft are also helping business
   customers adapt deep-learning-powered applications   like
   speech-recognition interfaces and translation services   for their own
   businesses, while cloud services like amazon web services provide
   cheap, gpu-driven deep-learning computation services for those who want
   to develop their own software. plentiful open-source software   like
   caffe, google   s tensorflow, and amazon   s dsstne   have greased the
   innovation process, as has an open-publication ethic, whereby many
   researchers publish their results immediately on one database without
   awaiting peer-review approval.

   many of the most exciting new attempts to apply deep learning are in
   the medical realm (see sidebar). we already know that neural nets work
   well for image recognition, observes vijay pande, a stanford professor
   who heads andreessen horowitz   s biological investments unit, and    so
   much of what doctors do is image recognition, whether we   re talking
   about radiology, dermatology, ophthalmology, or so many other
      -ologies.         

deep learning and medicine

   startup [37]enlitic uses deep learning to analyze radiographs and ct
   and mri scans. ceo igor barani, formerly a professor of radiation
   oncology at the university of california in san francisco, says
   enlitic   s algorithms outperformed four radiologists in detecting and
   classifying lung nodules as benign or malignant. (the work has not been
   peer reviewed, and the technology has not yet obtained fda approval.)

   [38]merck is trying to use deep learning to accelerate drug discovery,
   as is a san francisco startup called [39]atomwise. neural networks
   examine 3d images   thousands of molecules that might serve as drug
   candidates   and predict their suitability for blocking the mechanism of
   a pathogen. such companies are using neural nets to try to improve what
   humans already do; others are trying to do things humans can   t do at
   all. gabriel otte, 27, who has a ph.d. in computational biology,
   started [40]freenome, which aims to diagnose cancer from blood samples.
   it examines dna fragments in the bloodstream that are spewed out by
   cells as they die. using deep learning, he asks computers to find
   correlations between cell-free dna and some cancers.    we   re seeing
   novel signatures that haven   t even been characterized by cancer
   biologists yet,    says otte.

   when andreessen horowitz was mulling an investment in freenome, ah   s
   pande sent otte five blind samples   two normal and three cancerous. otte
   got all five right, says pande, whose firm decided to invest.

   while a radiologist might see thousands of images in his life, a
   computer can be shown millions.    it   s not crazy to imagine that this
   image problem could be solved better by computers,    pande says,    just
   because they can plow through so much more data than a human could ever
   do.   

   the potential advantages are not just greater accuracy and faster
   analysis, but democratization of services. as the technology becomes
   standard, eventually every patient will benefit.

   the greatest impacts of deep learning may well be felt when it is
   integrated into the whole toolbox of other artificial intelligence
   techniques in ways that haven   t been thought of yet. google   s
   [41]deepmind, for instance, has already been accomplishing startling
   things by combining deep learning with a related technique called
   id23. using the two, it created [42]alphago, the
   system that, this past march, defeated the champion player of the
   ancient chinese game of go   widely considered a landmark ai achievement.
   unlike ibm   s deep blue, which defeated chess champion garry kasparov in
   1997, alphago was not programmed with id90, or equations on
   how to evaluate board positions, or with if-then rules.    alphago
   learned how to play go essentially from self-play and from observing
   big professional games,    says demis hassabis, deepmind   s ceo. (during
   training, alphago played a million go games against itself.)

   a game might seem like an artificial setting. but hassabis thinks the
   same techniques can be applied to real-world problems. in july, in
   fact, google reported that, by using approaches similar to those used
   by alphago, deepmind was able to increase the energy efficiency of
   google   s data centers by 15%.    in the data centers there are maybe 120
   different variables,    says hassabis.    you can change the fans, open the
   windows, alter the computer systems, where the power goes. you   ve got
   data from the sensors, the temperature gauges, and all that. it   s like
   the go board. through trial and error, you learn what the right moves
   are.

      so it   s great,    he continues.    you could save, say, tens of millions
   of dollars a year, and it   s also great for the environment. data
   centers use a lot of power around the world. we   d like to roll it out
   on a bigger scale now. even the national grid level.   

   chatbots are all well and good. but that would be a cool app.

   a version of this article appears in the october 1, 2016 issue of
   fortune with the headline    the deep-learning revolution.    this version
   contains updated figures from the cb insights research firm.

   [43]fortune 500 [44]auto [45]energy [46]finance [47]leadership [48]most
   powerful women [49]retail [50]tech [51]newsletters [52]rankings
   [53]video
   [54]subscribe
     *
     *
     *
     *

      2019 fortune media ip limited. all rights reserved.

   fortune.com is a part of the time.com network of sites.

   powered by [55]wordpress.com vip
   [56]ad choices [57]custom content [58]customer service [59]feedback
   [60]fortune datastore [61]media kit [62]privacy policy [63]your
   california privacy rights [64]reprints & permissions [65]site map
   [66]terms of use [67]work at fortune

   fortune may receive compensation for some links to products and
   services on this website. offers may be subject to change without
   notice.

   quotes delayed at least 15 minutes. market data provided
   by [68]interactive data.

   etf and mutual fund data provided by [69]morningstar, inc.

   dow jones terms &
   conditions: [70]http://www.djindexes.com/mdsidx/html/tandc/indexestandc
   s.html.

   s&p index data is the property of chicago mercantile exchange inc. and
   its licensors.  all rights reserved.

   [71]terms & conditions. powered and implemented by [72]interactive data
   managed solutions

      2019 fortune media ip limited. all rights reserved.

   fortune.com is a part of the time.com network of sites.

   powered by [73]wordpress.com vip

sign in

   email address or password is incorrect
   email/username ____________________ password ____________________
   sign in
   [ ] remember me [74]forgot password?

want the full story?

   [75]subscribe

get

   email
   ____________________ subscribe

   iframe: [76]fortune_newsletter_submit_message

   [77]privacy policy

   thank you for your interest in licensing fortune content. please find
   information on various licensing contacts below and choose the one that
   best suits your needs:
     * 1. to license fortune articles, excerpts, or headlines for
       republication in various media (including books, ebooks, film, web,
       newsletters, newspapers, magazines and others), please email
       syndication@timeinc.com.
     * 2. to license a fortune cover, order reprint or e-print copies of
       an article or cover, or license an accolade, please contact pars
       international at [78]www.timeincreprints.com.
     * 3. to license text only photocopies of fortunearticles as print or
       digital handouts in academic settings, or in academic coursepacks,
       please contact the copyright clearance center at
       [79]www.copyright.com


   ____________________________________________________________
   ____________________________________________________________
   ____________________________________________________________
   ____________________________________________________________
   post to
   [80]cancel reblog post

references

   visible links
   1. https://plus.google.com/+fortune
   2. http://fortune.com/ai-artificial-intelligence-deep-machine-learning/feed/
   3. https://public-api.wordpress.com/oembed/?format=json&url=http://fortune.com/ai-artificial-intelligence-deep-machine-learning/&for=wpcom-auto-discovery
   4. https://public-api.wordpress.com/oembed/?format=xml&url=http://fortune.com/ai-artificial-intelligence-deep-machine-learning/&for=wpcom-auto-discovery
   5. http://fortune.com/osd.xml
   6. https://s1.wp.com/opensearch.xml
   7. http://fortune.com/
   8. https://www.magazine.store/fortune/
   9. http://fortune.com/ai-artificial-intelligence-deep-machine-learning/#subscribe
  10. http://fortune.com/fortune500/alphabet/
  11. http://fortune.com/fortune500/alphabet/
  12. http://fortune.com/fortune500/microsoft/
  13. http://fortune.com/fortune500/microsoft/
  14. http://fortune.com/fortune500/facebook/
  15. http://fortune.com/fortune500/facebook/
  16. http://fortune.com/company/bidu/
  17. https://fortunedotcom.files.wordpress.com/2016/09/lrn-10-01-16-neural-networks-e1474990995824.png
  18. http://fortune.com/self-driving-cars-silicon-valley-detroit/
  19. http://fortune.com/fortune500/ford-motor/
  20. http://fortune.com/fortune500/ford-motor/
  21. http://fortune.com/fortune500/tesla/
  22. http://fortune.com/fortune500/nvidia/
  23. http://fortune.com/2016/03/22/artificial-intelligence-nvidia/
  24. https://www.cbinsights.com/blog/artificial-intelligence-funding-trends-q216/
  25. http://fortune.com/2016/09/28/ai-partnership-facebook-google-amazon/
  26. http://fortune.com/fortune500/ibm/
  27. http://fortune.com/fortune500/intel/
  28. http://fortune.com/fortune500/intel/
  29. http://fortune.com/2016/08/09/intel-machine-learning-nervana/
  30. http://fortune.com/2016/09/06/intel-movidius-vision/
  31. https://s3.amazonaws.com/fortune.digital/2016/deep-learning-timeline/key-moments.html?iframe_id=fortune-iframe-embed-07ef1c1b2185cd66c88a984870ece03037e5569d
  32. http://fortune.com/fortune500/ncr/
  33. http://fortune.com/fortune500/ncr/
  34. https://googleblog.blogspot.com/2012/06/using-large-scale-brain-simulations-for.html
  35. https://s3.amazonaws.com/fortune.digital/2016/deep-learning/index.html?iframe_id=fortune-iframe-embed-3fdce483a7ba4d1cf1eb408d0ee74315407f82b5
  36. http://fortune.com/fortune500/ibm/
  37. http://www.enlitic.com/
  38. http://fortune.com/fortune500/merck/
  39. https://www.atomwise.com/
  40. http://www.freenome.com/
  41. https://deepmind.com/
  42. https://googleblog.blogspot.com/2016/01/alphago-machine-learning-game-go.html
  43. http://fortune.com/fortune500/
  44. http://fortune.com/autos/
  45. http://fortune.com/energy/
  46. http://fortune.com/finance/
  47. http://fortune.com/leadership/
  48. http://fortune.com/mpw/
  49. http://fortune.com/retail/
  50. http://fortune.com/tech/
  51. http://fortune.com/newsletters/
  52. http://fortune.com/rankings/
  53. http://fortune.com/video/
  54. https://www.magazine.store/fortune/
  55. https://vip.wordpress.com/?utm_source=vip_powered_wpcom&utm_medium=web&utm_campaign=vip footer credit&utm_term=fortune.com
  56. http://subscription-assets.timeinc.com/prod/assets/themes/magazines/default/template-resources/html/legal/ti-corp-behavioral.html
  57. http://www.timeincnewsgroupcustompub.com/
  58. https://w1.buysub.com/servlet/id19ateway?cds_mag_code=for
  59. http://fortune.com/feedback/
  60. http://www.fortunedatastore.com/
  61. http://www.fortunemediakit.com/
  62. https://subscription.timeinc.com/storefront/privacy/fortune/generic_privacy_new.html?dnp-source=i
  63. https://subscription.timeinc.com/storefront/privacy/fortune/generic_privacy_new.html?dnp-source=i#california
  64. https://www.parsintl.com/publication/fortune/
  65. http://fortune.com/sitemap/
  66. https://subscription.timeinc.com/storefront/privacy/fortune/privacy_terms_service.html
  67. http://fortune.com/fortune-careers/
  68. http://www.interactivedata.com/
  69. http://www.morningstar.com/
  70. http://www.djindexes.com/mdsidx/html/tandc/indexestandcs.html
  71. http://www.interactivedata-rts.com/index.php/contents/show/content/quoteterms
  72. http://www.interactivedata.com/idms/
  73. https://vip.wordpress.com/?utm_source=vip_powered_wpcom&utm_medium=web&utm_campaign=vip footer credit&utm_term=fortune.com
  74. https://subscription.fortune.com/storefront/universalforgotpassword.ep?magcode=fo&origin=paywall
  75. https://www.magazine.store/fortune/
  76. javascript:false;
  77. https://subscription.timeinc.com/storefront/privacy/fortune/generic_privacy_new.html?dnp-source=g
  78. http://www.timeincreprints.com/
  79. http://www.copyright.com/
  80. http://fortune.com/ai-artificial-intelligence-deep-machine-learning/

   hidden links:
  82. mailto:?subject=the%20ai%20revolution%3a%20why%20deep%20learning%20is%20suddenly%20changing%20your%20life&body=thought%20you%20might%20be%20interested%20in%20this:%0d%0dand%20will%20soon%20transform%20corporate%20america.%0d%0dhttp%3a%2f%2ffortune.com%2fai-artificial-intelligence-deep-machine-learning%2f%3fxid%3dfor_em_sh
  83. https://twitter.com/share?url=http%3a%2f%2ffor.tn%2f2cwaqc9%3fxid%3dfor_tw_sh&text=why%20deep%20learning%20is%20suddenly%20changing%20your%20life+via+%40fortunemagazine
  84. http://www.facebook.com/sharer.php?u=http%3a%2f%2ffortune.com%2fai-artificial-intelligence-deep-machine-learning%2f%3fxid%3dfor_fb_sh&title=why%20deep%20learning%20is%20suddenly%20changing%20your%20life
  85. http://www.linkedin.com/sharearticle?mini=true&url=http%3a%2f%2ffortune.com%2fai-artificial-intelligence-deep-machine-learning%2f%3fxid%3dfor_li_sh&text=the%20ai%20revolution%3a%20why%20deep%20learning%20is%20suddenly%20changing%20your%20life&source=fortune
  86. https://www.linkedin.com/company/fortune-magazine
  87. https://www.facebook.com/fortunemagazine
  88. https://twitter.com/fortunemagazine
  89. http://fortune.com/feedback/
