   #[1]publisher [2]medium [3]alternate

   [4]homepage
   [5]homepage
   [6]deep learning journal
   [7]deep learning journal
   [8]sign in[9]get started
     __________________________________________________________________

   [1*2r2vbwx60_ycfi2utrp-ew.jpeg]

faster ai: lesson 1         tl;dr version of fast.ai part 1

   [10]go to the profile of kshitiz rimal
   [11]kshitiz rimal (button) blockedunblock (button) followfollowing
   aug 24, 2017
     __________________________________________________________________

     if you haven   t read [12]lesson 0 of this blog series, please go
     through that first. there i have covered why i am writing this
     series and what to expect from it and some necessary overview of
     this fast.ai part 1 course.

   this lesson is divided into 3 parts:
    1. software and hardware setup [time: [13]10:51]
    2. model we are going to build and data it uses [time: [14]52:57]
    3. pretrained model and concept of finetuning [time: [15]1:09:23]

1. software and hardware setup

   in order to run any deep learning application you would need two things
   at first, programming languages and frameworks using which the
   application is written and supporting hardware environment.

   lets start with the software part first. in this course you will need
   to install python language on your system, [16]numpy, a python package
   for matrix computations, [17]keras, a deep learning library for python
   programming language. in order to install them, you can open the video
   from that particular time from above. jeremy recommends installing them
   via [18]anaconda software package which will automatically install
   libraries like numpy and a special software called jupyter notebook
   which this course extensively uses to teach throughout the course. its
   basically an interactive notebook for python language, where you can
   write documentation of your code and execute the actual code at the
   same time and save the result for future reference.

   except these python libraries and software packages, this course also
   uses two separate python scripts, utils.py and vgg16.py. they are
   provided to you on the [19]github repo of the course. for the files
   such as pre-trained model files and weights, use this [20]link. i
   suggest you to download all the files on that repo including some excel
   files, as jeremy uses those files to explain most of the ideas of deep
   learning.

   here is a diagram jeremy drew while explaining how all these packages
   and software interact with each other
   [1*si_b3kfn4bcldjyiydv8rg.png]

   it basically shows that the separate vgg script leverages keras
   framework underneath. keras itself uses [21]theano, another deep
   learning framework as its backend for the computations and ultimately
   theano leverages the power of graphic processing units (gpus) by using
   cuda language provided by nvidia graphic cards. as of this moment, only
   nvidia cards with cuda capabilities are used for deep learning
   purposes.

   with software installed and all the necessary files downloaded, lets
   move on to the hardware part.

   it is recommended that you use a system with gpu access for deep
   learning. with that being said, its not entirely a necessity if you
   have small dataset, for example few number of images. you can train the
   model with that data on cpu as well but, it will take some time
   depending on your cpu and ram.

   in this course jeremy is using aws p2 instances with gpu access for
   training the model. there is entirely [22]a separate video on the
   playlist to teach you how to setup aws instances for this course.

   personally i tested the accuracy of the model using only the cpu of my
   laptop but i did so with few sample data. if you cannot get hold of aws
   instances there might be many alternatives on the internet but one i
   personally find very easy and effective is [23]floydhub cloud gpu.
   another great aspect of floydhub is, its free. free upto 2 hours of gpu
   time without you having to enter your credit card info. so, for the
   purpose of learning using gpu and follow along with this course you can
   totally use it and get the best result from your model leveraging full
   gpu power.

   start with its quick start guide
   [24]http://docs.floydhub.com/getstarted/quick_start/

   and move to the section to set up jupyter notebook on it
   [25]http://docs.floydhub.com/getstarted/quick_start_jupyter/

   many environments are supported by floydhub, what we need for this
   course is the one with keras with theano as a backend. you can check
   all the available environments and how to use them from here
   [26]http://docs.floydhub.com/guides/environments/

   now as the hardware and software portion is covered. lets move on to
   another section.

2. model we are going to build and data it uses

   for this lesson and future lessons to come, we will be using
   [27]kaggle   s dogs vs cats dataset to classify images. you can simply
   download the data from the website and open up lesson 1.ipynb file on
   jupyter notebook and follow along the course to train the model to
   classify between dogs and cats. make sure that the data is present in
   the same directory of the notebook files.

   if you are going to use floydhub, you wont be needing to download the
   data set as well. as many of the users on floydhub has already uploaded
   that data and you can simply use them by remotely mounting them on your
   project.

   here is the one with the same dataset on floydhub
   [28]https://www.floydhub.com/rarce/datasets/dogsvscats/1

   you can follow this guide to learn how to mount the remote dataset in
   your project
   [29]http://docs.floydhub.com/guides/data/mounting_data/

   one thing you need to make sure is that, the train and valid directory
   of your dataset need to have two sub folders called cats and dogs
   present in it with respective images. this is how keras determines the
   categories of the model.

   now the software is ready, hardware is ready, data is ready. lets move
   on to the real part.

3. pre-trained model and concept of fine tuning

   generally in deep learning we have some data and we have a model which
   uses some algorithm to learn from these data and with that it gives the
   result that we want.

   pre-trained models are the models which are already trained on millions
   of data and are much robust in nature. these models when again trained
   with the little of our own custom data, gives us more accurate result
   we want. there are many pre-trained models available on the internet,
   but depending on our need, we need to select an appropriate one.

   in our case we have data of cats and dogs. now to enhance the accuracy
   of our model we use pretrained model called vgg16.

   vgg16 is a convolutional neural network model, which is trained on
   id163 dataset. in general convolutional type neural networks are
   used when we have to deal with images.

   as this model is trained on [30]id163 dataset, which has thousands
   of images of not just cats and dogs but other natural objects as well.
   by utilizing this, we are enhancing the outcome that we would normally
   get by just using our little data.

   in short, with this approach our model will recognize images of cats
   and dogs more intelligibly than with only using our own data.

   but the problem with this particular pre-trained model is that, it
   gives the classification output of 1000 categories, which is what the
   id163 has and which is what this model is build for originally.

   to make this model to just give the classification of two categories,
   cats and dogs, we use the concept of finetuning. what finetuning does
   is, it train the pre-trained model using our new data and instead of
   giving output of 1000 categories, it uses the categories of our data
   and just classify between them. in our case we have 2 categories, so
   the result or output will be prediction between whether the given image
   is a cat or a dog. and this whole process can be done using this seven
   lines of code.
   [1*uanrtglnuq5lmzy-0_91pg.png]

   here, what its doing is, its defining the batch size, which means, how
   many images we would want to fed to the model at one go, in this case
   64.

   generally in deep learning we don   t feed images to the model one by
   one. we do so in a group or in a batch. that way, the gpu (graphical
   processing unit) will be fully utilized and model will work faster.

   then it initializes the model with the vgg model. then we separate
   batches of our training set and validation set.

   we need some data from our dataset to be used for actual training the
   model and some for testing its accuracy on this training.

   here training set is what the model is trained upon and validation set
   is used to check how properly the model is training on that training
   data. then we fine tune them according to our dataset and finally we
   fit them.

   with only this 7 lines of code our model can classify whether its cat
   or dog by above 90% accuracy.

   you can learn a great deal by just reading the [31]lesson notes as
   well.

   you can also check the [32]video timeline and jump to any particular
   topic on that video.

   on our next lesson we will dig deeper into these ideas and experiment
   with it even more as we move along. see you there.

[33]next post : lesson 2

     * [34]machine learning
     * [35]artificial intelligence
     * [36]deep learning

   (button)
   (button)
   (button) 322 claps
   (button) (button) (button) (button)

     (button) blockedunblock (button) followfollowing
   [37]go to the profile of kshitiz rimal

[38]kshitiz rimal

   ai developer, intel ai student ambassador, co-founder @ ai for
   development: ainepal.org, city ai ambassador: kathmandu

     (button) follow
   [39]deep learning journal

[40]deep learning journal

   deep learning lessons

     * (button)
       (button) 322
     * (button)
     *
     *

   [41]deep learning journal
   never miss a story from deep learning journal, when you sign up for
   medium. [42]learn more
   never miss a story from deep learning journal
   (button) get updatesget updates

references

   visible links
   1. https://plus.google.com/103654360130207659246
   2. https://medium.com/osd.xml
   3. android-app://com.medium.reader/https/medium.com/p/d63ad6b2993b
   4. https://medium.com/
   5. https://medium.com/
   6. https://medium.com/deep-learning-journals?source=avatar-lo_pfugdpbhqy33-aa98d6a0017e
   7. https://medium.com/deep-learning-journals?source=logo-lo_pfugdpbhqy33---aa98d6a0017e
   8. https://medium.com/m/signin?redirect=https://medium.com/deep-learning-journals/faster-ai-lesson-1-tl-dr-version-of-fast-ai-part-1-d63ad6b2993b&source=--------------------------nav_reg&operation=login
   9. https://medium.com/m/signin?redirect=https://medium.com/deep-learning-journals/faster-ai-lesson-1-tl-dr-version-of-fast-ai-part-1-d63ad6b2993b&source=--------------------------nav_reg&operation=register
  10. https://medium.com/@kshitizrimal?source=post_header_lockup
  11. https://medium.com/@kshitizrimal
  12. https://medium.com/deep-learning-journals/faster-ai-lesson-0-tl-dr-version-of-fast-ai-part-1-dd060ae7e319
  13. https://youtu.be/th_ckfbc6bi?t=651
  14. https://youtu.be/th_ckfbc6bi?t=3177
  15. https://youtu.be/th_ckfbc6bi?t=4163
  16. http://www.numpy.org/
  17. https://keras.io/
  18. https://www.continuum.io/downloads
  19. https://github.com/fastai/courses/tree/master/deeplearning1
  20. http://files.fast.ai/
  21. http://www.deeplearning.net/software/theano/
  22. https://www.youtube.com/watch?v=8rjrfw4jm2i&list=plfyubjixbdts2uqrzyrxmyvhogw0gmlsm&index=2
  23. http://floydhub.com/
  24. http://docs.floydhub.com/getstarted/quick_start/
  25. http://docs.floydhub.com/getstarted/quick_start_jupyter/
  26. http://docs.floydhub.com/guides/environments/
  27. https://www.kaggle.com/c/dogs-vs-cats
  28. https://www.floydhub.com/rarce/datasets/dogsvscats/1
  29. http://docs.floydhub.com/guides/data/mounting_data/
  30. http://image-net.org/explore
  31. http://wiki.fast.ai/index.php/lesson_1_notes
  32. http://wiki.fast.ai/index.php/lesson_1_timeline
  33. https://medium.com/deep-learning-journals/faster-ai-lesson-2-tl-dr-version-of-fast-ai-part-1-f803218ffe6d
  34. https://medium.com/tag/machine-learning?source=post
  35. https://medium.com/tag/artificial-intelligence?source=post
  36. https://medium.com/tag/deep-learning?source=post
  37. https://medium.com/@kshitizrimal?source=footer_card
  38. https://medium.com/@kshitizrimal
  39. https://medium.com/deep-learning-journals?source=footer_card
  40. https://medium.com/deep-learning-journals?source=footer_card
  41. https://medium.com/deep-learning-journals
  42. https://medium.com/@medium/personalize-your-medium-experience-with-users-publications-tags-26a41ab1ee0c#.hx4zuv3mg

   hidden links:
  44. https://medium.com/p/d63ad6b2993b/share/twitter
  45. https://medium.com/p/d63ad6b2993b/share/facebook
  46. https://medium.com/p/d63ad6b2993b/share/twitter
  47. https://medium.com/p/d63ad6b2993b/share/facebook
