   #[1]publisher [2]medium [3]alternate

   [4]homepage
   [5]homepage
   [6]sign in[7]get started

   [8]stats and bots
     * [9]data science
     * [10]analytics
     * [11]startups
     * [12]bots
     * [13]design
     * [14]subscribe
     * [15]     cube.js framework
     __________________________________________________________________

id3 (gans): engine and applications

how generative adversarial nets are used to make our life better

   [16]go to the profile of anton karazeev
   [17]anton karazeev (button) blockedunblock (button) followfollowing
   aug 17, 2017
   [1*nqmmrzflkmsx2bvxzzamea.png]
   [18]illustration source

   id3 (gans) are a class of neural networks
   that are used in unsupervised machine learning. they help to solve such
   tasks as image generation from descriptions, getting high resolution
   images from low resolution ones, predicting which drug could treat a
   certain disease, retrieving images that contain a given pattern, etc.

   the [19]statsbot team asked a data scientist, anton karazeev, to make
   the introduction to gans engine and their applications in everyday
   life.
     __________________________________________________________________

   gans were [20]introduced by ian goodfellow in 2014. they aren   t the
   only approach of neural networks in unsupervised learning. there   s also
   the id82 (geoffrey hinton and terry sejnowski, 1985) and
   autoencoders (dana h. ballard, 1987). both of them are dedicated to
   extract features from data by learning the identity function f(x) = x
   and both of them rely on markov chains to train or to generate samples.

   id3 were designed to avoid using markov
   chains because of the high computational cost of the latter. another
   advantage relative to id82s is that the generator function
   has much fewer restrictions (there are only a few id203
   distributions that admit markov chain sampling).

   in this article, we   ll tell you how generative adversarial nets work
   and what their most popular applications in real life are. we will also
   give you links to some helpful resources for getting deeper into these
   approaches.

the engine of generative adversarial nets

   to explain gans    concept let us use an analogy.
   [0*j0s58jhff6p2xago.]
   [21]illustration source

   imagine you want to buy good watches. if you never buy them it   s very
   likely that you can   t distinguish brand watches from fake ones. you
   have to be experienced to not let yourself be fooled by the seller.

   as you start to label most of the watches as fake (after a number of
   mistakes of course), the seller will start to    generate    more
   compelling copies of the watches. this example demonstrates the
   behavior of id3: discriminator (watches
   buyer) and generator (seller of fake watches).

   these two networks, discriminator and generator, are contesting with
   each other. this technique allows the generation of realistic objects
   (e.g. images). the generator is forced to generate samples that look
   real and the discriminator learns to distinguish generated samples and
   samples from real data.
   [1*l_pqmkmnj8j-sa0fx0qkpw.jpeg]
   [22]illustration source

   what   s the difference between discriminative and generative algorithms?
   in brief: discriminative algorithms learn the boundaries between
   classes (as the discriminator does) while generative algorithms learn
   the distribution of classes (as the generator does).

if you   re ready to go deeper

   to learn the generator   s distribution, p_g over data x, the
   distribution on input noise variables p_z(z) should be defined. then
   g(z,   _g) maps z from latent space z to data space and d(x,   _d)
   outputs a single scalar         id203 that x came from the real data
   rather than p_g.

   the discriminator is trained to maximize the id203 of assigning
   the correct label to both examples of real data and generated samples.
   while the generator is trained to minimize log(1         d(g(z))). in other
   words         to minimize the id203 of the discriminator   s correct
   answer.

   it is possible to consider such a training task as minimax game with
   value function v(g, d):
   [0*buhwzaudciac3bqt.]

   in other words         the generator tries harder to fool the discriminator
   and the discriminator becomes more captious in order to not be fooled
   by the generator.

        adversarial training is the coolest thing since sliced
     bread.            [23]yann lecun

   the process of training stops when the discriminator is unable to
   distinguish p_g and p_data, i.e. d(x,   _d) =    . equilibrium between
   errors of the generator and the discriminator is established.

id162 for historical archives

   an interesting example of gans applications is retrieving visually
   similar marks in    [24]prize papers,    one of the most valuable archives
   in the field of maritime history. adversarial nets make it easier to
   work with documents of historical importance containing information
   about the legitimacy of ship captures at sea.
   [0*hixmgxijcab9i1uf.]
   [25]adversarial training for sketch retrieval

   each query contains examples of merchant marks         unique identification
   of property of a merchant, sketch-like symbols that are similar to
   hieroglyphs.

   feature representation of every mark should be obtained, but there are
   some problems of applying conventional machine and deep learning
   methods (including convolutional neural networks):
     * they require a large amount of labelled images;
     * there are no labels for merchant marks;
     * marks are not segmented from the dataset.

   this new approach shows how to extract and learn features from images
   of the merchant marks using gans. after the representation of each mark
   is learned the visual search on scanned documents could be processed.

text translation into images

   other researchers showed that it   s possible to use descriptive
   properties of natural language to generate corresponding images. a
   method of text translation into images allows the illustration of the
   performance of generative models to mimic samples of real data.
   [0*6dusyhguzbmv_qtr.]
   [26]generative adversarial text to image synthesis

   the main problem of image generation is that image distribution is
   multimodal. for example, there are many correct samples that correctly
   illustrate the description. gans help to solve this problem.
   [0*2pq9p5-lgx3g04vo.]
   [27]illustration source

   let   s consider the following task of mapping the blue input dot to the
   green output dot (green dots are possible outputs to blue dot). this
   red arrow indicates the error of prediction and means that after some
   time the blue dot will be mapped to the mean of the green dots         this
   exact thing causes the blurry images we are trying to predict.

   generative adversarial nets don   t directly use pairs of inputs and
   outputs. instead, they learn how the inputs and outputs can be paired.

   here are the examples of generated images from text descriptions:
   [0*1hrx-30eicl4zp5k.]
   [28]generative adversarial text to image synthesis

   datasets that [29]were used to train gans:
     * caltech-ucsd-200   2011 is an image dataset with photos of 200 bird
       species. total number of images is 11,788;
     * oxford-102 flowers dataset consists of 102 flower categories with
       numbers between 40 and 258 images per category.

drug discovery

   while others apply id3 to images and
   videos, researchers from insilico medicine proposed an approach of
   artificially intelligent drug discovery using gans.

   the goal is to train the generator to sample drug candidates for a
   given disease as precisely as possible to existing drugs from a drug
   database.
   [0*--g8rqpr-hofpa8g.]
   [30]illustration source

   after training, it   s possible to generate a drug for a previously
   incurable disease using the generator, and using the discriminator to
   determine whether the sampled drug actually cures the given disease.

molecule development in oncology

   another research by insilico medicine showed the pipeline of generating
   new anticancer molecules with a defined set of parameters. the aim is
   to predict drug responses and compounds which are good at fighting
   against cancer cells.

   researchers proposed an adversarial autoencoder (aae) model for
   identification and generation of new compounds based on available
   biochemical data.
   [0*mbizmzn qi6enw.]
   [31]adversarial autoencoders

        to the best of our knowledge, this is the first application of gans
     techniques within the field of cancer drug discovery.            say the
     [32]researchers.

   there are many available biochemical data in databases such as
   [33]cancer cell line encyclopedia (ccle), [34]genomics of drug
   sensitivity in cancer (gdsc), and [35]nci-60 cancer cell line
   collection. all of them contain screening data for different drug
   experiments against cancer.
   [1*vczagbjayhywkay2ixxcga.jpeg]
   [36]gdsc website

   adversarial autoencoder was trained using growth inhibition percentage
   data (gi, which shows the reduction in the number of cancer cells after
   the treatment), drug concentrations, and fingerprints as inputs.

   the fingerprint of the molecule contains a fixed number of bits in
   which each bit represents the absence or presence of some feature.
   [0*fvygxa-yubc7q1nj.]

   the latent layer consists of 5 neurons, one of which is responsible for
   gi (efficiency against cancer cells) and the four others are
   discriminated with normal distribution. so, a regression term was added
   to the encoder cost function. furthermore, the encoder was restricted
   to map the same fingerprint to the same latent vector, independently
   from input concentration by additional manifold cost.
   [0*2ctb33kyy__qf0cu.]
   [37]illustration source

   after training, it is possible to generate molecules from a desired
   distribution and use a gi-neuron as a tuner of output compounds.

   [38]results of this work are the following: the trained aae model
   predicted compounds that are already proven to be anticancer agents and
   new untested compounds that should be validated with experiments on
   anticancer activity.

        our results suggest that the proposed aae model significantly
     enhances the capacity and efficiency of development of the new
     molecules with specific anticancer properties using the deep
     generative models.   

conclusion

   unsupervised learning is [39]a next frontier in [40]artificial
   intelligence and we are moving towards it.

   generative adversarial nets can be applied in many fields from
   generating images to predicting drugs, so don   t be afraid of
   experimenting with them. we believe they help in building a better
   future for machine learning.

   below, we give you a few helpful resources to learn more about
   adversarial nets.

   taken from    [41]generative adversarial nets   :
     * gans allow the model to learn that there are many correct answers
       (i.e. handling well on multimodal data);
     * semi-supervised learning: features from the discriminator or
       id136 net could improve performance of classifiers when limited
       labeled data is available;
     * one can use adversarial nets to implement a stochastic extension of
       the deterministic multi-prediction deep id82s;
     * a conditional generative model p(x|c) can be obtained by adding c
       as the input to both the generator and the discriminator.

further reading

     * [42]what is a variational autoencoder?
     * ian goodfellow about [43]gans for text on reddit
     *    [44]stackgan: text to photo-realistic image synthesis with stacked
       id3    by baidu research [[45]github]
     *    [46]generative visual manipulation on the natural image manifold   
       by adobe research [[47]github]
     *    [48]unsupervised cross-domain image generation    by facebook ai
       research [[49]github]
     *    [50]image-to-image translation with conditional adversarial
       networks    by berkeley ai research [[51]github]

   iframe: [52]/media/02231cd5403151a2a463e36cc3b88462?postid=f96291965b47

you   d also like:

   [53]etl vs elt: considering the advancement of data warehouses |
   statsbot blog
   with the advent of modern cloud-based data warehouses, such as bigquery
   or redshift, the traditional concept of etl is   statsbot.co
   [54]support vector machines tutorial
   learning id166s from examplesblog.statsbot.co
   [55]google analytics audit checklist and tools
   auditing a google analytics setup like a problog.statsbot.co
   [56]data structures related to machine learning algorithms
   a primer on data structures for data scientistsblog.statsbot.co

     * [57]machine learning
     * [58]gans
     * [59]neural networks
     * [60]data science
     * [61]adversarial nets

   (button)
   (button)
   (button) 1.4k claps
   (button) (button) (button) (button)

     (button) blockedunblock (button) followfollowing
   [62]go to the profile of anton karazeev

[63]anton karazeev

   [64]https://akarazeev.github.io

     (button) follow
   [65]stats and bots

[66]stats and bots

   data stories on machine learning and analytics. from statsbot   s makers.

     * (button)
       (button) 1.4k
     * (button)
     *
     *

   [67]stats and bots
   never miss a story from stats and bots, when you sign up for medium.
   [68]learn more
   never miss a story from stats and bots
   (button) get updatesget updates

references

   visible links
   1. https://plus.google.com/103654360130207659246
   2. https://blog.statsbot.co/osd.xml
   3. android-app://com.medium.reader/https/medium.com/p/f96291965b47
   4. https://medium.com/
   5. https://medium.com/
   6. https://medium.com/m/signin?redirect=https://blog.statsbot.co/generative-adversarial-networks-gans-engine-and-applications-f96291965b47&source=--------------------------nav_reg&operation=login
   7. https://medium.com/m/signin?redirect=https://blog.statsbot.co/generative-adversarial-networks-gans-engine-and-applications-f96291965b47&source=--------------------------nav_reg&operation=register
   8. https://blog.statsbot.co/?source=logo-lo_kjvvkxgwoeb1---cfc9f21a543a
   9. https://blog.statsbot.co/datascience/home
  10. https://blog.statsbot.co/analytics/home
  11. https://blog.statsbot.co/startups/home
  12. https://blog.statsbot.co/bots/home
  13. https://blog.statsbot.co/design/home
  14. https://blog.statsbot.co/statsbot-digest-b0d7372f842a
  15. https://cube.dev/
  16. https://blog.statsbot.co/@antonkarazeev?source=post_header_lockup
  17. https://blog.statsbot.co/@antonkarazeev
  18. https://arxiv.org/pdf/1612.03242.pdf
  19. http://statsbot.co/?utm_source=blog&utm_medium=article&utm_campaign=gans
  20. https://arxiv.org/pdf/1406.2661.pdf
  21. http://19359-presscdn.pagely.netdna-cdn.com/wp-content/uploads/2014/08/genuine-fake-turkey-8.jpg
  22. http://www.kdnuggets.com/2017/01/generative-adversarial-networks-hot-topic-machine-learning.html
  23. https://www.quora.com/session/yann-lecun/1
  24. http://www.brill.com/products/online-resources/prize-papers-online
  25. https://arxiv.org/pdf/1607.02748.pdf
  26. https://arxiv.org/pdf/1605.05396.pdf
  27. https://youtu.be/rvgyvhyt15e
  28. https://arxiv.org/pdf/1605.05396.pdf
  29. https://arxiv.org/pdf/1605.05396.pdf
  30. https://www.youtube.com/watch?v=xkchp_oojym
  31. https://arxiv.org/pdf/1511.05644.pdf
  32. http://www.impactjournals.com/oncotarget/index.php?journal=oncotarget&page=article&op=view&path[0]=14073&path[1]=44886
  33. http://software.broadinstitute.org/software/cprg/?q=node/11
  34. http://www.cancerrxgene.org/
  35. https://dtp.cancer.gov/discovery_development/nci-60/
  36. http://www.cancerrxgene.org/
  37. http://www.impactjournals.com/oncotarget/index.php?journal=oncotarget&page=article&op=view&path[0]=14073&path[1]=44886
  38. http://www.impactjournals.com/oncotarget/index.php?journal=oncotarget&page=article&op=view&path[0]=14073&path[1]=44886
  39. https://www.cs.cornell.edu/content/unsupervised-learning-next-frontier-ai
  40. https://blog.statsbot.co/3-types-of-artificial-intelligence-4fb7df20fdd8
  41. https://arxiv.org/pdf/1406.2661.pdf
  42. https://jaan.io/what-is-variational-autoencoder-vae-tutorial/
  43. https://www.reddit.com/r/machinelearning/comments/40ldq6/generative_adversarial_networks_for_text/
  44. https://arxiv.org/pdf/1612.03242.pdf
  45. https://github.com/hanzhanggit/stackgan
  46. https://arxiv.org/pdf/1609.03552v2.pdf
  47. https://github.com/junyanz/igan
  48. https://arxiv.org/pdf/1611.02200.pdf
  49. https://github.com/yunjey/domain-transfer-network
  50. https://arxiv.org/pdf/1611.07004.pdf
  51. https://github.com/phillipi/pix2pix
  52. https://blog.statsbot.co/media/02231cd5403151a2a463e36cc3b88462?postid=f96291965b47
  53. https://statsbot.co/blog/etl-vs-elt/
  54. https://blog.statsbot.co/support-vector-machines-tutorial-c1618e635e93
  55. https://blog.statsbot.co/google-analytics-audit-checklist-and-tools-fca7df2f2e7a
  56. https://blog.statsbot.co/data-structures-related-to-machine-learning-algorithms-5edf77c8bbf4
  57. https://blog.statsbot.co/tagged/machine-learning?source=post
  58. https://blog.statsbot.co/tagged/gans?source=post
  59. https://blog.statsbot.co/tagged/neural-networks?source=post
  60. https://blog.statsbot.co/tagged/data-science?source=post
  61. https://blog.statsbot.co/tagged/adversarial-nets?source=post
  62. https://blog.statsbot.co/@antonkarazeev?source=footer_card
  63. https://blog.statsbot.co/@antonkarazeev
  64. https://akarazeev.github.io/
  65. https://blog.statsbot.co/?source=footer_card
  66. https://blog.statsbot.co/?source=footer_card
  67. https://blog.statsbot.co/
  68. https://medium.com/@medium/personalize-your-medium-experience-with-users-publications-tags-26a41ab1ee0c#.hx4zuv3mg

   hidden links:
  70. https://statsbot.co/blog/etl-vs-elt/
  71. https://blog.statsbot.co/support-vector-machines-tutorial-c1618e635e93
  72. https://blog.statsbot.co/google-analytics-audit-checklist-and-tools-fca7df2f2e7a
  73. https://blog.statsbot.co/data-structures-related-to-machine-learning-algorithms-5edf77c8bbf4
  74. https://medium.com/p/f96291965b47/share/twitter
  75. https://medium.com/p/f96291965b47/share/facebook
  76. https://medium.com/p/f96291965b47/share/twitter
  77. https://medium.com/p/f96291965b47/share/facebook
