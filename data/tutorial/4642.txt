    #[1]sigmoidal    feed [2]sigmoidal    comments feed [3]sigmoidal    gan
   deep learning architectures     review comments feed [4]alternate
   [5]alternate

   [6]machine learning consulting and data science from sigmoidal.io
   machine learning consulting and data science from sigmoidal.io
   0

   [7]machine learning consulting and data science from sigmoidal.io
   machine learning consulting and data science from sigmoidal.io
     * blog

machine learning blog
       [8]see all entries
          + [9]natural language processing algorithms (nlp ai)
          + [10]artificial intelligence and machine learning for
            healthcare
          + [11]machine learning terms every manager should know
          + [12]machine learning for trading     topic overview
          + [13]deep learning for id161     going beyond image
            classification and regression
     * [14]company
     * use cases

ai business
use cases
          + [15]finance
            investment opportunities discovery
          + [16]trading
            ai choosing the most profitable portfolio
          + [17]ai in pharma
            finding drug side-effect reviews in social media
     * [18]contact us

   [19]schedule a call

gan deep learning architectures     review

introduction

   gan architectures source: [20]http://www.bulldozer-vfx.com/

   how do you teach a machine to draw a human face if it has never seen
   one? a computer can store petabytes of photos, but it has no idea what
   gives a bunch of pixels a meaning related to someone   s appearance.

   for many years this problem has been tackled by various generative
   models. they used different assumptions, often too strong to be
   practical, to model the underlying distribution of the data.

   the results were suboptimal for most of the tasks we have now. text
   generated with id48 was very dull and predictable,
   images from id5 were blurry and, despite the name,
   lacked variety. all those shortcomings called for an entirely new
   approach, and recently such method was invented.

   in this article, we aim to give a comprehensive introduction to general
   ideas behind id3 (gans), show you the main
   architectures that would be good starting points and provide you with
   an armory of tricks that would significantly improve your results.

towards the invention of gans

   the basic idea of a generative model is to take a collection of
   training examples and form a representation of their id203
   distribution. and the usual method for it was to infer a id203
   density function directly.

   when i was studying generative models the first time i couldn   t help
   but wonder     why bother with them when we have so many real life
   training examples already? the answer was quite compelling, here are
   just a few of possible applications that call for a good generative
   model:
    1. simulate possible outcomes of an experiment, cutting costs and
       speeding up the research.
    2. action planning using predicted future states     imagine a gan that
          knows    the road situation the next moment.
    3. generating missing data and labels     we often lack the clean data
       in the right format, and it causes overfitting.
    4. high-quality speech generation
    5. automated quality improvement for photos (image super-resolution)

   in 2014, ian goodfellow and his colleagues from university of montreal
   introduced id3 (gans). it was a novel
   method of learning an underlying distribution of the data that allowed
   generating artificial objects that looked strikingly similar to those
   from the real life.

   the idea behind the gans is very straightforward. two networks     a
   generator and a discriminator play a game against each other. the
   objective of the generator is to produce an object, say, a picture of a
   person, that would look like a real one. the goal of the discriminator
   is to be able to tell the difference between generated and real images.
   generator and discriminator source:
   [21]https://www.slideshare.net/xavigiro/deep-learning-for-computer-visi
   on-generative-models-and-adversarial-training-upc-2016

   this illustration gives a rough overview of the generative adversarial
   network. for the moment it   s most important to understand that the gan
   is rather a way to make two networks work together     and both generator
   and discriminator have their own architecture. to better understand
   where this idea came from we will need to recall some basic algebra and
   ask ourselves     how can we fool a neural network that classifies images
   better than most humans?

adversarial examples

   before we get to describing gans in details, let   s take a look at a
   similar topic. given a trained classifier, can we generate a sample
   that would fool the network? and if we do, how would it look like?

   it turns out, we can.

   even more     for virtually any given image classifier it   s possible to
   morph an image into another, which would be misclassified with high
   confidence while being visually indistinguishable from the original!
   such process is called an adversarial attack, and the simplicity of the
   generating method explains quite a lot about gans.
   an adversarial example in an example carefully computed with the
   purpose to be misclassified. here is an illustration of this process.
   the panda on the left in indistinguishable from the one on the right    
   and yet it   s classified as a gibbon.
   adversarial attack example source: goodfellow, 2017

   an image classifier is essentially a complex decision boundary in a
   high-dimensional space. of course, when it comes to classifying the
   images, we can   t draw this boundary. but what we can safely assume is
   that when the training is over, the network is not generalized for all
   images     only for those we had in the training set. such generalization
   is likely not a good approximation of real life. in other words, it
   overfits to our data     and we are going to exploit it.

   let   s start adding random noise to the image and keep it very close to
   zero. we can achieve that by controlling l2 norm of the noise.
   mathematical notation shouldn   t worry you     for all practical purposes
   you can think of l2 norm as of length of a vector. the trick here is
   the more pixels you have in an image     the bigger its average l2 norm
   is. so, if the norm of your noise is sufficiently low, you can expect
   it to be visually imperceptible, while the corrupted image will be very
   far from the original in the vector space.

   why is that so?

   well, if the hxw image is a vector, then hxw noise that we add to it is
   also a vector. the original image has all kinds of colors which are
   rather intensive     that increases the l2 norm. the noise, on the other
   hand, is a visually chaotic set of rather pale pixels     a vector with
   small norm. at the end we add them together, getting new vector for
   corrupted image which is comparatively close to the original     and yet
   misclassified!

   now, if the decision boundary for the original class dog is not that
   far (in terms of l2 norm), this additive noise puts the new image
   outside of the decision boundary.

   you don   t need to be a world class topologist to understand manifolds
   or decision boundaries of certain classes. as each image is just a
   vector in a high-dimensional space, a classifier trained on them
   defines    all monkeys    as    all image vectors in this high-dimensional
   blob that is described by hidden parameters   . we refer to that blob as
   to the decision boundary for the class.

   okay, so, you are saying we can easily fool a network by adding random
   noise. what does it have to do with generating new images?

generator and discriminator

   now that we have a grasp of adversarial examples, we are one step away
   from the gans! so, what if instead of the classifier in the previous
   part we had a network designed only for two classes        genuine    and
      fake   ? following the notation used in the original paper by goodfellow
   et al., we will call it a discriminator.

   let   s add another network that will learn to generate fake images that
   discriminator would misclassify as    genuine.    the procedure will be
   exactly like the one we have used in adversarial examples part. this
   network is called generator, and the process of adversarial training
   gives it fascinating properties.

   on every step of training we discriminator a bunch of images from the
   training set and a bunch of fake ones, so it gets better and better at
   distinguishing them. as you remember from statistical learning theory,
   that essentially means learning the underlying distribution of data.

   so, what does it get to fool a discriminator later on, when it becomes
   really good at spotting fake images? that   s right! to learn how to
   generate compelling fakes.
   discriminator flow source: goodfellow, 2017

   there   s an old but brilliant mathematical result (minimax theorem) that
   started the game theory as we know it and states that for two players
   in a zero-sum game the minimax solution is the same as the nash
   equilibrium.

   woah, that   s a mouthful!

   in simpler terms, when two players (d and g) are competing against each
   other (zero-sum game), and both play optimally assuming that their
   opponent is optimally (minimax strategy), the outcome is predetermined
   and none of the players can change it (nash equilibrium).
   minimax game source: goodfellow, 2017

   so, for our networks, it means that if we train them long enough, the
   generator will learn how to sample from true    distribution,    meaning
   that it will start generating real life-like images, and the
   discriminator will not be able to tell fake ones from genuine ones.

best architectures to start with

   when it comes to practice, especially in machine learning, many things
   just stop working. luckily, we gather some useful tips for achieving
   better results. in this article, we will start with reviewing some
   classic architectures and providing links to them.

   iframe: [22]https://www.youtube.com/embed/x1mun6dd8ue?rel=0

deep convolutional generative adversarial network (dcgan)

   for about a year after the first paper, training gans resembled art
   rather than science     the models were unstable and required a bunch of
   hacks to work. in 2016 radford et al. published the paper titled
      unsupervised representation learning with deep convolutional
   id3    describing the model that subsequently
   became famous as dcgan.
   deep convolutional generative adversarial network (dcgan) source:
   radford et al., 2015

   the most remarkable thing about dcgan was that this architecture was
   stable in most settings. it was one of the first papers to show the
   vector arithmetics as an intrinsic property of the representations
   learned by the generator: it   s the same trick as with the word vectors
   in id97, but with images!
   dcgan architecture to show the vector arithmetics source: radford et
   al., 2015

   dcgan is the simplest stable go-to model that we recommend to start
   with. we will add useful tips for training/implementation along with
   links to code examples further.

conditional gan

   this extension of a gan meta architecture was proposed to improve the
   quality of generated images, and you would be 100% right to call it
   just a smart trick. the idea is that if you have labels for some data
   points, you can use them to help the network build salient
   representations. it doesn   t matter what architecture you use     the
   extension is the same every time. all you need to do is to add another
   input to the generator.
   conditional gan source: mirza, 2014

   so, what happens now? let   s say your model can generate all kinds of
   animals, but you are really fond of cats. instead of passing generated
   noise into the generator and hoping for the best, you add a few labels
   to the second input, for example as the id of a class cat or just as
   word vectors. in this case, the generator is said to be conditioned on
   the class of expected input.

tips and tricks

   when it comes to practice, the descriptions you read in the papers are
   not enough. same for tutorials that give you an introductory view of an
   algorithm     more often their approach works only on the toy dataset
   they use for demonstration. in this article, we are aiming for
   providing you with a set of tools that will give you the ability to
   start your own research on gans or just building your own cool stuff
   right away.

   so, you have implemented your own gan or just cloned one from github
   (which is a development style i honestly can get behind!). there   s no
   consensus on which flavor of sgd works better, so the best way would be
   to use your favorite (i use adam) and carefully tune the learning rate
   before you commit to prolonged training     it will save you a lot of
   time. the general workflow looks very straightforward:
    1. sample a minibatch of training examples and compute the
       discriminator scorings for them
    2. generate a minibatch of samples and compute the discriminator
       scorings for them
    3. perform an update using the accumulated gradients from both steps

   it   s essential to process training and generated minibatches separately
   and compute the batch norms for different batches individually     going
   that ensures fast initial training of the discriminator.

   here   s an illustration of the correct way to form minibatches:

   sometimes it   s better to perform more than one step for discriminator
   per every step of a generator, so if your generator starts    winning    in
   terms of a id168, consider doing this.

   if you use batchnorm layers in a generator, it can cause strong
   intra-batch correlation, which you can see in the next figure:
   batchnorm source: goodfellow, 2016

   essentially, every batch will be producing the same thing with slight
   variations. how do you prevent that? one way would be to precompute the
   mean pixel and standard deviation and just use it every time, but it
   causes overfitting very often. instead, there   s a neat trick called
   virtual batch id172: predefine a batch before you start
   training (let   s call it r as in reference), and for each new batch x
   compute the id172 parameters using the concatenation of r and
   x.

   another interesting trick is to sample the input noise from a sphere
   rather than from a cube. an approximation of this can be achieved just
   by controlling the norm of a noise vector, but the real uniform
   sampling from a high-dimensional cube is preferable.

   the next trick is to avoid using sparse gradients, especially in
   generator. that can be achieved just by swapping certain layers to
   their    smooth    analogs, e.g.:
    1. relu -> leakyrelu
    2. maxpooling -> avgpooling, convolution + stride
    3. unpooling -> deconvolution
    conclusion
       in this article, we gave an explanation of generative adversarial
       networks along with practical tips for implementation and training.
       in the resources section, you will find the implementations of gans
       which will help you to start your experiments.
       in the upcoming posts, we plan to discuss advanced architectures
       and recent developments in gans. are you interested in how neural
       networks help to discover new drugs and prolong the lives? stay
       tuned!
       resources
    lectures

    1. [23]id3 @ nips 2016 by ian goodfellow
    2. [24]adversarial examples and adversarial training by ian goodfellow
    3. [25]how to train a gan @ nips 2016 by soumith chintala

tutorials

    1. [26]extensive tutorial from o   reilly     gans for beginners
    2. [27]minimalistic tutorial with lots of room to implement the hacks

repositories

    1. [28]dcgan in tensorflow
    2. [29]dcgan in pytorch
    3. [30]generating anime with conditional gan

papers

    1. [31]id3
    2. [32]unsupervised representation learning with deep convolutional
       id3
    3. [33]conditional generative adversarial nets

   the article by roman trusov
   tags: [34]deep learning image processing for id161
   [35]share on facebook [36]share on twitter
     __________________________________________________________________

0 comments

leave a reply [37]cancel

   you must be [38]logged in to post a comment.

more recent stories

   11/03/2017 [39]id164 deep learning [40]read more

   [41]how to be certain with uncertainty in deep learning
   09/08/2017 [42]variational dropout     uncertainty in deep learning?
   [43]read more

   sigmoidal llc
   733 3rd avenue, 15th floor
   new york, ny, 10017
          [44](347) 779 2050
            [45][email protected]
     *
     *
     *
     *

   [software-5.jpg]

   so glad to see you sticking around!

   want to be the first one to receive the new stuff?

   enter your email address below and we'll send you the goodies straight
   to your inbox.
   ____________________
   (button) subscribe

   thank you for subscribing

   this means the world to us!

   spamming is not included! pinky promise.

   iframe: [46]https://www.googletagmanager.com/ns.html?id=gtm-ngj2l8w

references

   visible links
   1. https://sigmoidal.io/feed/
   2. https://sigmoidal.io/comments/feed/
   3. https://sigmoidal.io/beginners-review-of-gan-architectures/feed/
   4. https://sigmoidal.io/wp-json/oembed/1.0/embed?url=https://sigmoidal.io/beginners-review-of-gan-architectures/
   5. https://sigmoidal.io/wp-json/oembed/1.0/embed?url=https://sigmoidal.io/beginners-review-of-gan-architectures/&format=xml
   6. https://sigmoidal.io/
   7. https://sigmoidal.io/
   8. https://sigmoidal.io/blog
   9. https://sigmoidal.io/boosting-your-solutions-with-nlp/
  10. https://sigmoidal.io/artificial-intelligence-and-machine-learning-for-healthcare/
  11. https://sigmoidal.io/machine-learning-terminology-explained-top-8-must-know-concepts/
  12. https://sigmoidal.io/machine-learning-for-trading/
  13. https://sigmoidal.io/dl-computer-vision-beyond-classification/
  14. https://sigmoidal.io/company/
  15. https://sigmoidal.io/use-case-investment-opportunities-discovery/
  16. https://sigmoidal.io/use-case-portfolio-analysis-ai-choosing-the-most-profitable-portfolio/
  17. https://sigmoidal.io/artificial-intelligence-pharma/
  18. https://sigmoidal.io/contact-us/
  19. https://sigmoidal.io/contact-us
  20. http://www.bulldozer-vfx.com/
  21. https://www.slideshare.net/xavigiro/deep-learning-for-computer-vision-generative-models-and-adversarial-training-upc-2016
  22. https://www.youtube.com/embed/x1mun6dd8ue?rel=0
  23. https://www.youtube.com/watch?v=ajvyzd0rqdc
  24. https://www.youtube.com/watch?v=cifsb_eysvi
  25. https://www.youtube.com/watch?v=x1mun6dd8ue
  26. https://www.oreilly.com/learning/generative-adversarial-networks-for-beginners
  27. https://github.com/uclaacmai/generative-adversarial-network-tutorial
  28. https://github.com/carpedm20/dcgan-tensorflow
  29. https://github.com/pytorch/examples/tree/master/dcgan
  30. https://github.com/m516825/conditional-gan
  31. https://arxiv.org/abs/1406.2661
  32. https://arxiv.org/abs/1511.06434
  33. https://arxiv.org/abs/1411.1784
  34. https://sigmoidal.io/tag/computer-vision/
  35. https://www.facebook.com/sharer/sharer.php?u=https://sigmoidal.io/beginners-review-of-gan-architectures/
  36. https://twitter.com/share?url=https://sigmoidal.io/beginners-review-of-gan-architectures/
  37. https://sigmoidal.io/beginners-review-of-gan-architectures/#respond
  38. https://sigmoidal.io/wp-login.php?redirect_to=https://sigmoidal.io/beginners-review-of-gan-architectures/
  39. https://sigmoidal.io/dl-computer-vision-beyond-classification/
  40. https://sigmoidal.io/dl-computer-vision-beyond-classification/
  41. https://sigmoidal.io/variational-dropout/
  42. https://sigmoidal.io/variational-dropout/
  43. https://sigmoidal.io/variational-dropout/
  44. tel:+1-347-779-2050
  45. https://sigmoidal.io/cdn-cgi/l/email-protection#b6dedff6c5dfd1dbd9dfd2d7da98dfd9
  46. https://www.googletagmanager.com/ns.html?id=gtm-ngj2l8w

   hidden links:
  48. https://sigmoidal.io/beginners-review-of-gan-architectures/
  49. https://sigmoidal.io/
  50. https://sigmoidal.io/beginners-review-of-gan-architectures/
  51. https://sigmoidal.io/beginners-review-of-gan-architectures/
  52. https://sigmoidal.io/dl-computer-vision-beyond-classification/
  53. https://www.linkedin.com/company/17914183/
  54. https://web.facebook.com/sigmoidal
  55. https://www.youtube.com/channel/uckhgompnzyvxg2g5txnknxw/videos
  56. https://twitter.com/sigmoidal_io
  57. https://sigmoidal.io/beginners-review-of-gan-architectures/#start
  58. https://sigmoidal.io/beginners-review-of-gan-architectures/
