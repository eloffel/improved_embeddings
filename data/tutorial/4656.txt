   (button) toggle navigation [1]w-nut
     * [2]home
     * [3]2017
     * [4]2016
     * [5]2015
     * [6]call
     * [7]shared-tasks
     * [8]committee

emerging and rare entity recognition

   this shared task focuses on identifying unusual, previously-unseen
   entities in the context of emerging discussions. named entities form
   the basis of many modern approaches to other tasks (like event
   id91 and summarisation), but recall on them is a real problem in
   noisy text - even among annotators. this drop tends to be due to novel
   entities and surface forms. take for example the tweet    so.. kktny in
   30 mins?    - even human experts find entity [9]kktny hard to detect and
   resolve. this task will evaluate the ability to detect and classify
   novel, emerging, singleton named entities in noisy text.

   the goal of this task is to provide a definition of emerging and of
   rare entities, and based on that, also datasets for detecting these
   entities.

goals

   detecting commonly-mentioned entities tends to be easier than the
   rarer, more unusual surface forms. similarly, entities with unusual
   surface forms, or that are simply rare, tend to be tougher to detect
   ([10]augenstein et al 2017), with recall being a significant problem in
   rapidly-changing text types ([11]derczynski et al 2015). however, the
   entities that are common in newly-emerging texts such as newswire or
   social media are often new, not having been mentioned in prior
   datasets. this poses a challenge to ner systems, where in many
   deployments, unusual, previously-unseen entities need to be detected
   reliably and with high recall. the wnut 2017 shared task poses this
   challenge directly to participants, with turbulent data containing few
   repeated entities, drawn from rapidly-changing text types or sources of
   non-mainstream entities.

evaluation

   the shared task evaluates against two measures. as well as classical
   entity-level precision, recall and their harmonic mean, f1, surface
   forms found in the emerging entities task are evaluated. the set of
   unique surface forms in the gold data and the submission are compared,
   and the precision, recall and f1 of these measured too. this latter
   measure measures how good systems are at correctly recognizing a
   diverse range of entities, rather than just the very frequent surface
   forms. for example, the classical measure would reward a system that
   always recognizes "london" accurately, and so such a system would get a
   high score on a corpus where 50% of the location entities are just
   "london". the second measure, though, would reward "london" just once,
   regardless of how many times it appeared in the text.

   systems are evaluated using a modified version of conlleval.py,
   downloadable here: [12]wnuteval.py.

   input is via stdin or filename parameter; try something like:
   ./wnuteval.py datafilename

   the system output data file takes the format token gold-label
   predicted-label.
   important dates

     training and dev data to be released: may/june 2017

     test data released: 21 june 2017

     result submission: 30 june 2017

     shared-task results and gold annotations for test data: 3 july 2017

     system description papers due: 7 july 2017

     reviews returned: 15 july 2017

     camera ready deadline: 21 july 2017

     workshop date: sep 7 2017

entity classes

    1. person
    2. location (including gpe, facility)
    3. corporation
    4. consumer good (tangible goods, or well-defined services)
    5. creative work (song, movie, book, and so on)
    6. group (subsuming music band, sports team, and non-corporate
       organisations)

downloads

   if you use this data, please cite the task paper:
     * leon derczynski, eric nichols, marieke van erp, nut limsopatham
       (2017) "results of the wnut2017 shared task on novel and emerging
       entity recognition", in proceedings of the 3rd workshop on noisy,
       user-generated text.

   training data: [13]wnut17train.conll

   development data: [14]emerging.dev.conll

   data readme: [15]readme.md

   eval script: [16]wnuteval.py

   test data (no tags): [17]emerging.test

   test data with tags: [18]emerging.test.annotated

   data is to be downloaded directly. links are given out via the [19]wnut
   mailing list and this page. all the data will be made available after
   the task has finished, as well as the team submissions. the data's in
   conll format; see the readme files in the downloads for more details.

   the dataset is kept live on github, including source data;
   [20]github.com/leondz/emerging_entities_17

results

       team      f1 (entity) f1 (surface form)
   arcada        39.98       37.77
   drexel-cci    26.30       25.26
   flytxt        38.85       36.31
   mic-cis       37.06       34.25
   sjtu-adapt    40.42       37.62
   spinningbytes 40.78       39.33
   uh-ritual     41.86       40.24

   you can also download the submissions:

shared task organizers

     * [21]leon derczynski (university of sheffield)
     * [22]marieke van erp (vu university amsterdam)
     * [23]eric nichols (honda research institute, japan)
     * [24]nut limsopatham (university of cambridge)

references

   visible links
   1. http://noisy-text.github.io/2017/index.html
   2. http://noisy-text.github.io/2017/emerging-rare-entities.html
   3. http://noisy-text.github.io/2017/index.html
   4. http://noisy-text.github.io/2016/index.html
   5. http://noisy-text.github.io/2015/index.html
   6. http://noisy-text.github.io/2017/emerging-rare-entities.html#call
   7. http://noisy-text.github.io/2017/emerging-rare-entities.html
   8. http://noisy-text.github.io/2017/emerging-rare-entities.html#committee
   9. http://noisy-text.github.io/2017/files/kourtney-and-kim-take-new-york.jpg
  10. https://arxiv.org/pdf/1701.02877.pdf
  11. http://www.eurecom.fr/~troncy/publications/derczynski_troncy-ipm15.pdf
  12. http://noisy-text.github.io/2017/files/wnuteval.py
  13. http://noisy-text.github.io/2017/files/wnut17train.conll
  14. http://noisy-text.github.io/2017/files/emerging.dev.conll
  15. http://noisy-text.github.io/2017/files/readme.md
  16. http://noisy-text.github.io/2017/files/wnuteval.py
  17. http://noisy-text.github.io/2017/files/emerging.test
  18. http://noisy-text.github.io/2017/files/emerging.test.annotated
  19. https://groups.google.com/forum/#!forum/wnut
  20. https://github.com/leondz/emerging_entities_17
  21. http://derczynski.com/sheffield/
  22. https://mariekevanerp.com/
  23. http://www.jp.honda-ri.com/english/
  24. http://www.mml.cam.ac.uk/nl347

   hidden links:
  26. http://noisy-text.github.io/2017/files/emerging-submissions.tar.bz2
