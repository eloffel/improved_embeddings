   #[1]publisher [2]medium [3]alternate

   [4]homepage
   [5]homepage
   [6]sign in[7]get started

   [8]towards data science
     * [9]data science
     * [10]machine learning
     * [11]programming
     * [12]visualization
     * [13]ai
     * [14]data journalism
     * [15]contribute
     __________________________________________________________________

   [1*axwgv2l-skhdvpk2ll6xhw.jpeg]

neural networks part 2: implementing a neural network function in python
using keras

this how to guide walks through the steps in building a standard neural
network using keras. in the end, your neural network will be easy to use and
will serve as a powerful tool going forward in your career as a data
scientist.

   [16]go to the profile of joe klein
   [17]joe klein (button) blockedunblock (button) followfollowing
   aug 31, 2017

   keras has made building neural networks (nn) simple and is a great
   place to start for upcoming data scientist interested in building nn.
   keras does not provide the same level of nn fine tuning as tensor flow,
   but for works fantastically for almost all of you nn needs.

   step 1: import your packages
   [1*8sb7ugekjdxuvzqoseldka.png]

   this includes all the packages necessary to run this code.

   step 2: scale your data
   [1*jfjxwgb3nvoy6z0zlqlivw.png]

   neural networks in keras need a specific target variable format. the
   easiest way to do so is to use their keras.utils package.

   step 3: build your neural network

   this is the most important step and can be changed to fit your neural
   network needs. the variable input need should remain the same as it
   needs to match your variable length, same goes for the target output.
   if these are not properly formatted you will get an error.
   [1*rk1h62zf6xyuyq4ar29b2q.png]
   read comments for more information

   step 4: run your neural network

   this step ties all the functions we set up early together and will
   output your predictions. the function takes three parameters, your x
   data, your target data, and the number of cross validations you would
   like to perform. in addition, i used a roc-auc score to test my models
   performance, but you can easily change this by importing a different
   scoring method.
   [1*hujdx3ah0tytdenjc_fw-g.png]
   [1*8txtugn4n2-lkib_e8rafa.png]

   your keras neural network is complete!

   time to run your final function.
   [1*6q38vs7tzepxfvd6zch5nw.png]

   a copyable version of the code is available below. please comment for
   questions.
import pandas as pd
import numpy as np
from keras import initializers
from keras.models import sequential
from keras.layers import dense, activation
from keras.utils import np_utils
from sklearn.model_selection import cross_val_score, kfold, train_test_split
from sklearn.metrics import roc_auc_score
from sklearn.preprocessing import standardscaler
def scale_nn(x_nn, y_nn):
    '''scale data to fit keras nn input format'''

    #import scaler to standardize variable data
    scaler = standardscaler()
    x_nn = scaler.fit_transform(x_nn)

    #use keras utils to format target data
    y_nn = np_utils.to_categorical(y_nn)

    return x_nn, y_nn


def build_nn(x_nn, y_nn, input_dim):
    '''build your neural network structure'''

    # train test split your data to prevent over fitting
    x_nn_train, x_nn_test, y_nn_train, y_nn_test = train_test_split(x_nn, y_nn)

    # initialize your sequential nn
    # you can change the model to something other than sequential, for more info
 check keras' documentation.
    model = sequential()

    # this part adds the number of id88s you would like to use in the firs
t layer
    # the input dimension is the number of variables you have in your data
    # the activation parameter is what kind of function you to use for your perc
eptron function
    # you can use a variety of different id88 functions but relu is very c
ommon
    model.add(dense(300, input_dim=input_dim, kernel_initializer='normal', activ
ation='relu'))

    # build the second layer of your neural network
    model.add(dense(300, kernel_initializer='normal', activation='relu'))

    # the last layer is your output layer so the number of perceptions must be e
qual to the
    # amount target classes your data set has.
    # softmax is a good function for binary data, but for more information check
 the keras
    # documentation.
    model.add(dense(y_nn_test.shape[1], kernel_initializer='normal', activation=
'softmax'))

    # lastly you want to define your id168, your optimizer and your metr
ic for scoring.
    # this will vary based on your goals, but for a binary target this parameter
 configuration
    # works well.
    model.compile(loss='binary_crossid178', optimizer='adam', metrics=['accura
cy'])

    # return your neural network
    return model
def run_nn(x_nn, y_nn, num_folds):
    '''run your neural network and output your prediction probabilities'''

    # initialize the roc-auc score running average list
    # initialize a count to print the number of folds
    av_roc = 0.
    count = 0

    # run the standard scaler function we defined before
    x_nn, y_nn = scale_nn(x_nn, y_nn)

    # initialize your cross vailidation
    # set shuffle equals true to randomize your splits on your training data
    kf = kfold(n_splits=num_folds, random_state=41, shuffle=true)

    # set up for loop to run for the number of cross vals you defined in your pa
rameter
    for train_index, test_index in kf.split(x_nn):
        count += 1
        print 'fold #: ', count

        # this indexs your train and test data for your cross validation and sor
ts them
        # in random order, since we used shuffle equals true
        x_nn_train, x_nn_test = x_nn[train_index], x_nn[test_index]
        y_nn_train, y_nn_test = y_nn[train_index], y_nn[test_index]

        # define your input dimension, which must equal the number of variables
in your
        # training data. if it does not you will get a goofy error.
        input_dim = x_nn_train.shape[1]

        # initialize your neural network structure we defined above to build you
r model
        print("building model...")
        model = build_nn(x_nn, y_nn, input_dim)

        # fit your model
        # you can select the number of epochs and and batch size you would like
to use
        # for your neural network.
        print("training model...")
        model.fit(x_nn_train, y_nn_train, epochs=15, batch_size=30, verbose=0)

        # your model is fit. time to predict our output and test our training da
ta
        print("evaluating model...")
        test_preds = model.predict_proba(x_nn_test, verbose=0)
        roc = roc_auc_score(y_nn_test, test_preds)
        scores = model.evaluate(x_nn_test, y_nn_test)
        print scores

        # print your model summary
        print model.summary()

        # print your roc-auc score for your kfold, and the running score average
        print 'roc: ', roc
        av_roc += roc
        print 'continued avg: ', av_roc/count
# print your final average roc-auc score and organize your models predictions in
 a dataframe
    print('average roc:', av_roc/num_folds)
    predict_proba_all = pd.dataframe(model.predict_proba(x_nn, verbose=0))
    return pd.dataframe(predict_proba_all)

     * [18]machine learning
     * [19]neural networks
     * [20]keras
     * [21]data science
     * [22]how to

   (button)
   (button)
   (button) 275 claps
   (button) (button) (button) 1 (button) (button)

     (button) blockedunblock (button) followfollowing
   [23]go to the profile of joe klein

[24]joe klein

   data scientist and forward thinker

     (button) follow
   [25]towards data science

[26]towards data science

   sharing concepts, ideas, and codes.

     * (button)
       (button) 275
     * (button)
     *
     *

   [27]towards data science
   never miss a story from towards data science, when you sign up for
   medium. [28]learn more
   never miss a story from towards data science
   (button) get updatesget updates

references

   visible links
   1. https://plus.google.com/103654360130207659246
   2. https://towardsdatascience.com/osd.xml
   3. android-app://com.medium.reader/https/medium.com/p/1ba80aba03df
   4. https://medium.com/
   5. https://medium.com/
   6. https://medium.com/m/signin?redirect=https://towardsdatascience.com/neural-networks-part-2-implementing-a-neural-network-function-in-python-using-keras-1ba80aba03df&source=--------------------------nav_reg&operation=login
   7. https://medium.com/m/signin?redirect=https://towardsdatascience.com/neural-networks-part-2-implementing-a-neural-network-function-in-python-using-keras-1ba80aba03df&source=--------------------------nav_reg&operation=register
   8. https://towardsdatascience.com/?source=logo-lo_saposncnsa7y---7f60cf5620c9
   9. https://towardsdatascience.com/data-science/home
  10. https://towardsdatascience.com/machine-learning/home
  11. https://towardsdatascience.com/programming/home
  12. https://towardsdatascience.com/data-visualization/home
  13. https://towardsdatascience.com/artificial-intelligence/home
  14. https://towardsdatascience.com/data-journalism/home
  15. https://towardsdatascience.com/contribute/home
  16. https://towardsdatascience.com/@jklein694?source=post_header_lockup
  17. https://towardsdatascience.com/@jklein694
  18. https://towardsdatascience.com/tagged/machine-learning?source=post
  19. https://towardsdatascience.com/tagged/neural-networks?source=post
  20. https://towardsdatascience.com/tagged/keras?source=post
  21. https://towardsdatascience.com/tagged/data-science?source=post
  22. https://towardsdatascience.com/tagged/how-to?source=post
  23. https://towardsdatascience.com/@jklein694?source=footer_card
  24. https://towardsdatascience.com/@jklein694
  25. https://towardsdatascience.com/?source=footer_card
  26. https://towardsdatascience.com/?source=footer_card
  27. https://towardsdatascience.com/
  28. https://medium.com/@medium/personalize-your-medium-experience-with-users-publications-tags-26a41ab1ee0c#.hx4zuv3mg

   hidden links:
  30. https://medium.com/p/1ba80aba03df/share/twitter
  31. https://medium.com/p/1ba80aba03df/share/facebook
  32. https://medium.com/p/1ba80aba03df/share/twitter
  33. https://medium.com/p/1ba80aba03df/share/facebook
