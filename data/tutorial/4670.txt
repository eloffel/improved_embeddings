   #[1]publisher [2]medium [3]alternate

   [4]homepage
   [5]homepage
   [6]sign in[7]get started

   [8]becoming human: artificial intelligence magazine
     * [9]     consulting
     * [10]     tutorials
     * [11]       submit an article
     * [12]     communities
     * [13]     our bot
     __________________________________________________________________

creating your own neural network using tensorflow

   [14]go to the profile of tharindra paranagama
   [15]tharindra paranagama (button) blockedunblock (button)
   followfollowing
   aug 31, 2017
   [0*1dqtru7wreonm9oa.png]
   [16]source

   a step by step approach

   tensorflow is a great and popular machine learning library which can be
   used to implement almost any machine learning algorithms in a
   convenient and efficient manner.

   in this blog post i will be showing you how to create a multi-layer
   neural network using tensorflow in a very simple manner.

   to start with we will have to import tensorflow as follows:

   iframe: [17]/media/bc483039c3a3e7968b886703e6e54d42?postid=fa8ca7cc4d0e

   tf is an alias we use simply to make coding easy. you can use any alias
   but as tf is a meaningful alias i will stick to it.

   next you must set the hyper-parameters of your network.it can be done
   in the following manner.

   iframe: [18]/media/586876502facc80db42686a1b98186bb?postid=fa8ca7cc4d0e

   we will now take a look at what each parameter means.
   [19]the chatbot conference
   the chatbot conference on september 12, chatbot's life, will host our
   first chatbot conference in san francisco. the   www.eventbrite.com

training epochs

   we say that an epoch is completed when we have used all our training
   data for the training process. training data consist of our training
   features and it   s corresponding training labels.here we have set
   training epochs to 500 which mean we train on our entire training data
   on 500 iterations. there is no ideal number of training epochs we could
   use.this depends on the complexity of your data.therefore you should do
   parameter tuning or basically try few parameter configurations to find
   the ideal/suitable value for this parameters.
     __________________________________________________________________

   since we are implementing a multi-layer neural network.it will consist
   of an input layer, two hidden layers and an output layer.

number of neurons in the hidden layers

   hidden layers are the layers which perform transforms on the input data
   to identify patterns and generalize our model.here i have used 30
   neurons each in my first and second hidden layers which was sufficient
   in achieving a decent accuracy. but as i explained earlier all
   hyper-parameters should be tuned in such a way that it improves your
   model.

learning rate

   this is the phase at which the algorithm learns.machine learning guru   s
   say that we should start with a high learning rate and gradually reduce
   it to achieve best results. further the learning rate is advised to be
   kept within the range of 0 & 1.

creating placeholders

   placeholder is a special type of data handler which facilitates
   receiving inputs during runtime.

   here we create two placeholders x & y. where x holds the input features
   and y holds the corresponding input labels/targets. x & y are both
   tensors(tensor is the central unit of data in tensorflow).

   iframe: [20]/media/6404dcbad5ec8a165182f9084e99d770?postid=fa8ca7cc4d0e

specifying weights and biases for the first layer

   weights allow you to change the steepness of the activation function in
   such a way that you will yield better results.while the biases allow
   you to shift your activation function left or right.both these
   parameters are important in most cases.

   truncated normal-outputs random values from a truncated normal
   distribution.the generated values follow a normal distribution with
   specified mean and standard deviation, except that values whose
   magnitude is more than 2 standard deviations from the mean are dropped
   and re-picked.

   iframe: [21]/media/7b7947860ca56c13dd444286cad17956?postid=fa8ca7cc4d0e

adding an activation function

   there are many popular id180 among them relu and sigmoid
   are in front. relu has the advantage of operating without been affected
   by the gradient vanishing problem which sigmoid is vulnerable to.

   the activation function to the first layer can be added as follows:

   iframe: [22]/media/b7f612479702c1de07c7f73b54651564?postid=fa8ca7cc4d0e

   here i will be using the sigmoid activation function.
   [1*5u_edvnqquh-nqo-fohwkq.gif]
   sigmoid graph

   i   ll also add the weights ,biases and the activation function for the
   second layer and the output layer as above.

   iframe: [23]/media/3d4614472d6a88ad5126defae8f48606?postid=fa8ca7cc4d0e

   for the output layer we will be using the softmax function which
   outputs a probabilistic value.

   iframe: [24]/media/d538831863d123d6a6872606ca4fdd38?postid=fa8ca7cc4d0e

setting up the cost function and optimizer

   here the cost function is based on the cross id178 calculation where
   the the actual label is multiplied by the log of the predicted label
   and the sum of that is derived. then reduce mean takes mean along
   dimensions while dimensions are reduced according to the reduction
   indices parameter value.

   train step is the optimization function(id119 in this
   scenario) that adjusts weights and biases by a fraction of the learning
   rate in the direction which results in a cost reduction.

   iframe: [25]/media/dd10bdb226df201f8a16e87a6462482f?postid=fa8ca7cc4d0e

accuracy calculation

   here we first match the prediction with the actual afterwards we
   compute the accuracy by checking the amount of total correct
   predictions over the total amount of data.

   iframe: [26]/media/5da8594eaadffd623bb441abc76f3f6a?postid=fa8ca7cc4d0e

training the model

   now since all are setup we can now train our model by feeding the
   values in the placeholder.we will be training the model over the number
   of iterations specified for the training-epochs variable.

   iframe: [27]/media/22b291c7cd9dd92eb92f61782fe267c2?postid=fa8ca7cc4d0e

summary

   so basically first we have to feed our data to placeholders.transform
   the data via the hidden layers ,output the probabilistic values via the
   output layer for each label.calculate the accuracy, minimize the cost
   throughout the training epochs by adjusting weights and biases.

   if you find this tutorial useful please share it among others who are
   interested in this area and be free to suggest any improvements or
   faults in this publication.

   iframe: [28]/media/c43026df6fee7cdb1aab8aaf916125ea?postid=fa8ca7cc4d0e

   [29][1*2f7oqe2ajk1ksrhkmd9zmw.png]
   [30][1*v-ppfkswhbvlwwamsvhhwg.png]
   [31][1*wt2auqisieaozxj-i7brdq.png]

     * [32]neural networks
     * [33]tensorflow
     * [34]python programming
     * [35]artificial intelligence
     * [36]ai

   (button)
   (button)
   (button) 228 claps
   (button) (button) (button) 3 (button) (button)

     (button) blockedunblock (button) followfollowing
   [37]go to the profile of tharindra paranagama

[38]tharindra paranagama

   tech enthusiast , blogger , software engineer , investor and traveler.

     (button) follow
   [39]becoming human: artificial intelligence magazine

[40]becoming human: artificial intelligence magazine

   latest news, info and tutorials on artificial intelligence, machine
   learning, deep learning, big data and what it means for humanity.

     * (button)
       (button) 228
     * (button)
     *
     *

   [41]becoming human: artificial intelligence magazine
   never miss a story from becoming human: artificial intelligence
   magazine, when you sign up for medium. [42]learn more
   never miss a story from becoming human: artificial intelligence
   magazine
   (button) get updatesget updates

references

   visible links
   1. https://plus.google.com/103654360130207659246
   2. https://becominghuman.ai/osd.xml
   3. android-app://com.medium.reader/https/medium.com/p/fa8ca7cc4d0e
   4. https://medium.com/
   5. https://medium.com/
   6. https://medium.com/m/signin?redirect=https://becominghuman.ai/creating-your-own-neural-network-using-tensorflow-fa8ca7cc4d0e&source=--------------------------nav_reg&operation=login
   7. https://medium.com/m/signin?redirect=https://becominghuman.ai/creating-your-own-neural-network-using-tensorflow-fa8ca7cc4d0e&source=--------------------------nav_reg&operation=register
   8. https://becominghuman.ai/?source=logo-lo_wecymbjhdh8a---5e5bef33608a
   9. https://becominghuman.ai/artificial-intelligence-software-developers-af09386dc05d
  10. https://becominghuman.ai/tagged/tutorial
  11. https://becominghuman.ai/write-for-us-48270209de63
  12. https://becominghuman.ai/artificial-intelligence-communities-c305f28e674c
  13. http://m.me/becominghumanai
  14. https://becominghuman.ai/@tharindra?source=post_header_lockup
  15. https://becominghuman.ai/@tharindra
  16. https://cloud.google.com/blog/big-data/2016/07/understanding-neural-networks-with-tensorflow-playground
  17. https://becominghuman.ai/media/bc483039c3a3e7968b886703e6e54d42?postid=fa8ca7cc4d0e
  18. https://becominghuman.ai/media/586876502facc80db42686a1b98186bb?postid=fa8ca7cc4d0e
  19. https://www.eventbrite.com/e/the-chatbot-conference-tickets-34868758395?aff=cbl
  20. https://becominghuman.ai/media/6404dcbad5ec8a165182f9084e99d770?postid=fa8ca7cc4d0e
  21. https://becominghuman.ai/media/7b7947860ca56c13dd444286cad17956?postid=fa8ca7cc4d0e
  22. https://becominghuman.ai/media/b7f612479702c1de07c7f73b54651564?postid=fa8ca7cc4d0e
  23. https://becominghuman.ai/media/3d4614472d6a88ad5126defae8f48606?postid=fa8ca7cc4d0e
  24. https://becominghuman.ai/media/d538831863d123d6a6872606ca4fdd38?postid=fa8ca7cc4d0e
  25. https://becominghuman.ai/media/dd10bdb226df201f8a16e87a6462482f?postid=fa8ca7cc4d0e
  26. https://becominghuman.ai/media/5da8594eaadffd623bb441abc76f3f6a?postid=fa8ca7cc4d0e
  27. https://becominghuman.ai/media/22b291c7cd9dd92eb92f61782fe267c2?postid=fa8ca7cc4d0e
  28. https://becominghuman.ai/media/c43026df6fee7cdb1aab8aaf916125ea?postid=fa8ca7cc4d0e
  29. https://becominghuman.ai/artificial-intelligence-communities-c305f28e674c
  30. https://upscri.be/8f5f8b
  31. https://becominghuman.ai/write-for-us-48270209de63
  32. https://becominghuman.ai/tagged/neural-networks?source=post
  33. https://becominghuman.ai/tagged/tensorflow?source=post
  34. https://becominghuman.ai/tagged/python-programming?source=post
  35. https://becominghuman.ai/tagged/artificial-intelligence?source=post
  36. https://becominghuman.ai/tagged/ai?source=post
  37. https://becominghuman.ai/@tharindra?source=footer_card
  38. https://becominghuman.ai/@tharindra
  39. https://becominghuman.ai/?source=footer_card
  40. https://becominghuman.ai/?source=footer_card
  41. https://becominghuman.ai/
  42. https://medium.com/@medium/personalize-your-medium-experience-with-users-publications-tags-26a41ab1ee0c#.hx4zuv3mg

   hidden links:
  44. https://www.eventbrite.com/e/the-chatbot-conference-tickets-34868758395?aff=cbl
  45. https://medium.com/p/fa8ca7cc4d0e/share/twitter
  46. https://medium.com/p/fa8ca7cc4d0e/share/facebook
  47. https://medium.com/p/fa8ca7cc4d0e/share/twitter
  48. https://medium.com/p/fa8ca7cc4d0e/share/facebook
