   [fire-texture.png]

   2017 ai grant recipient
   in-browser
   flaming-fast
   gpu-accelerated
   deep-learning

   tensorfire runs neural networks in the browser using webgl.

   sign up to get notified when we publish new demos.
   ____________________
   sign up
   we won't spam you or give your email to third parties.
       sucessfully signed up

   demos
   [dome.jpg]
   [thumb.gif]
   [687474703a2f2f672e7265636f726469742e636f2f6542756761366c6736742e676966
   ]
   what is tensorfire?

   tensorfire is a framework for running neural networks in the browser,
   accelerated by webgl.

   applications powered by tensorfire can utilize deep learning in almost
   any modern web browser with no setup or installation.

   tensorfire models run up to 100x faster than previous in-browser neural
   network libraries, at speeds comparable to highly-optimized native cpu
   code.
   how does it work?

   tensorfire has two parts: a low-level language based on glsl for easily
   writing massively parallel webgl shaders that operate on 4d tensors,
   and a high-level library for importing models trained with keras or
   tensorflow.

   it works on any gpu, whether or not it supports cuda. that means on
   computers with amd graphics, like the latest 2016 retina macbook pro,
   running networks in the browser with tensorfire can be faster than
   running it [1]natively with tensorflow.
   what can i build with tensorfire?

   with tensorfire, you can build applications which leverage the power of
   deep learning without forcing people to install native apps, without
   having to pay for expensive compute farms, nor waiting for a server to
   respond. rather than bringing the data to the model, you can deliver
   your model straight to your users, respecting their right to privacy.

   we   ve prototyped some demos, but it barely scratches the surface of
   what   s possible. tensorfire can run complex state-of-the-art networks
   like resnet-152, stylize photographs like famous paintings, generate
   text with a character-by-character recurrent model, and classify
   objects with your browser   s webcam in real time with squeezenet.

   the low-level api can also be used to do arbitrary parallel general
   purpose computation. we   ve used it to multiply matrices, solve linear
   systems of equations, and to compute id95, simulate cellular
   automata, transform and filter images, and more.
   what makes it fast?

   modern desktops, laptops, and phones contain powerful gpus optimized
   for highly-parallel computation.

   by transforming neural network weights into webgl textures and
   implementing common layers as fragment shaders, we can use the graphics
   capabilities of browsers designed for 3d games to speed up the
   execution of neural networks.

   unlike other webgl compute frameworks, we support [2]low-precision
   quantized tensors. this allows us to support browsers that don   t fully
   support the oes_texture_float extension, and run even faster with even
   smaller models.
   how do i get started?

   [3]sign up for updates! we   re still frantically mashing on our
   keyboards to document our apis, and you   ll be the first to hear once
   that   s ready. like all good things, it   ll be open source, and we   ll be
   depending on people like you to make cool stuff.

   we   re going to be launching more demos over the next couple weeks, and
   if there   s a bunch of people on that list we   ll feel really bad about
   disappointing all of you who have read this public promise to do so.
   who makes this?

   we   re a group of recent mit graduates who all think this whole    deep
   learning    thing is pretty neat.

   [4]kevin kwok and [5]guillermo webster have previously built things
   combining javascript and id161, like [6]project naptha    a
   browser extension that lets you seaid113ssly highlight, copy/paste, and
   translate text from within pictures, and [7]tesseract.js: a fully
   in-browser ocr library. [8]anish athalye and [9]logan engstrom have
   respectively built the first tensorflow implementations of gatys   
   [10]neural artistic style, and johnson   s [11]fast style transfer
   algorithms.

   emboldened by the [12]ai grant, we   ve spent some time putting together
   this framework, and we   ve had lots of fun building stuff on top of it.
   soon it will be your turn!

   contact us at [13][email protected].

   tensorfire is developed by [14]kevin kwok, [15]guillermo webster,
   [16]anish athalye, and [17]logan engstrom.

references

   visible links
   1. https://github.com/tensorflow/tensorflow/issues/22
   2. https://petewarden.com/2015/05/23/why-are-eight-bits-enough-for-deep-neural-networks/
   3. https://tenso.rs/#signup
   4. https://twitter.com/antimatter15
   5. https://twitter.com/biject
   6. https://projectnaptha.com/
   7. http://tesseract.projectnaptha.com/
   8. http://www.anishathalye.com/
   9. https://github.com/lengstrom
  10. https://github.com/anishathalye/neural-style
  11. https://github.com/lengstrom/fast-style-transfer
  12. https://aigrant.org/
  13. https://tenso.rs/cdn-cgi/l/email-protection#0a7e6f6b674a7e6f647965247879
  14. https://antimatter15.com/
  15. https://github.com/bijection
  16. http://www.anishathalye.com/
  17. https://github.com/lengstrom

   hidden links:
  19. https://aigrant.org/#finalists
  20. https://tenso.rs/demos/fast-neural-style
  21. https://tenso.rs/demos/rock-paper-scissors
  22. https://cyborg.tenso.rs/
