   #[1]delip rao    feed [2]delip rao    comments feed [3]delip rao    when
   (not) to use deep learning for nlp comments feed [4]the two tribes of
   language researchers [5]two recent results in id21 for
   music and speech [6]alternate [7]alternate

   [view?authtoken=zrgb&authtype=name&id=aaiaaabljmybxj3jdlzgsynkrd8qbcmar
   4z5sv4]

[8]navigation

   [9]delip rao

   [10]home
     * [11]home
     * [12]about

   [13]return to content

when (not) to use deep learning for nlp

   by [14]delip on september 4, 2017 in [15]deep learning, [16]natural
   language processing

   [view?authtoken=zrgb&authtype=name&id=aaiaaabljmybxj3jdlzgsynkrd8qbcmar
   4z5sv4]

   we are preparing for the second edition of our[17] pytorch-based deep
   learning for nlp training. it   s a two-day affair, crammed with a lot of
   learning and hands-on model building where we get to play the intricate
   dance of introducing the topics from the ground up while still making
   sure folks are not far from the state-of-the-art. compared to our first
   attempt at nyc this year, we are adding new content, changing existing
   content to explain some basic ideas well. one subtopic i am quite
   excited to add is a discussion of    when to use deep learning for nlp
   and when not to   . this post will be expanding on that.

   when to use deep learning for nlp? if you   ve attended any of the *cl
   conferences lately, the answer might seem to be a resounding    all the
   time   ! there is some truth to this. deep learning approaches to nlp
   have come a long way since 2014, and so have the software/hardware
   needed for it, to say that it is feasible to successfully apply dl
   approaches for many complex nlp problems. one emerging theme of 2017
   is, as a community, there is (relatively) more understanding of what
   the deep models do for language or at least an attempt at that. i see
   more papers on showing a certain natural language hypothesis holds or
   does not hold using model x than simply saying model x does better than
   model y for task z. so in a way, an overview of the recent literature
   gives a good picture of when to use deep learning for nlp and how. so,
   in this post, i will focus on the second question: when not to use deep
   learning for nlp? this written mostly from a practitioner   s point of
   view, i.e. someone who cares not just about building useful models but
   also wants to put them to use in real-life.

   scenario 1: when a simpler solution exists.

   this is the dl version of    if a regex solves a problem, don   t model
   it.    if simpler baselines work, implement/deploy them first. will a
   choice of simple input representations (tf, tf/idf etc) coupled with
   simple learners like naivebayes, logisticregression, id166s give you a
   usable system? if yes, do that first.

   scenario 2: when you are required to be cost sensitive while building
   solutions.

   some of the costs in building nlp systems include annotation costs,
   training costs, and system maintenance costs. while it is possible to
   throw a lot of resources at a problem to get more labeled data (thereby
   driving up your annotation costs), some of the most innovative works
   and breakthroughs happen when you are resource constrained. if you are
   leading a startup research group or, more likely, a small
   research/development team in a larger business trying to adopt nlp
   approaches in your work, your resources are finite and using them
   judiciously will determine if your product will see the light of the
   day. similarly, for most non-trivial models on production data, the
   training costs associated with deep learning are not negligible either.
   if you have another alternative that achieves similar metrics,
   insisting on using a deep model becomes more of dogma. regarding the
   last point of system maintenance costs, something curious is happening
   here. it is no longer the case that building, training, and deploying
   deep learning models require more software engineering resources than
   other approaches. this is primarily due to the large community interest
   in dl leading to better tools for model building with dl.

   scenario 3: when you are working with the wrong level of problem
   abstraction (or when    end-to-end    is not glamorous)

   this is probably the most important of the list and a bit nuanced, so
   it will require some explanation. deep learning (via the computation
   graph abstraction) gives an illusion of    general-purposeness    of the
   technique. if you can represent the input as a vector, the output as a
   vector, using a right combination of primitives (layers) in between,
   you can    transform    any input to any output, right? unfortunately, the
   answer is    it   s complicated   . to illustrate what i mean by    working at
   a wrong level of problem abstraction   , consider sorting. say you have
   sequences of numbers (x) and their sorted sequences (y). you can try
   modeling an end-to-end sort-learner as a sequence to sequence problem.
   this is exactly the wrong thing to do. the sorting problem can be
   decomposed into a high-level structural component (something you learn
   in algorithms textbooks) and a comparator that    knows    a rank order.
   having this insight about the problem will allow you to think at the
   right level of problem abstraction by learning an optimal comparator
   function from the data (the appropriate problem-abstraction here). this
   insight allows you to realize this is a less expensive learning-to-rank
   problem vs. a sequence modeling problem. parallels to this exist in nlp
   tasks too. for example, treating the dialog problem (chatbots!) as a
   sequence to sequence problem incurs high inefficiencies by not taking
   advantage of regularities in whatever task the dialog is in. a dialog
   engine could be built using insights from the task and the nature of
   language to learn patterns of semantic and pragmatic content. this
   could be as simple as modeling the relationship between utterances and
   underlying task state, or as complex as modeling the dialog structure
   and classifying each utterance to its corresponding rhetorical
   relation. in either case, blindly using a sequence-to-sequence model
   conflates the variance in language due to word choice with the variance
   due to task semantics.

   the above three scenarios are not exhaustive, but cover most situations
   in my experience.

   (credits: brian mcmahan for contributing to this discussion)

about delip

       (science     products)
   [18]view all posts by delip    
   [19]the two tribes of language researchers
   [20]two recent results in id21 for music and speech

      2016 delip rao. all rights reserved.

references

   1. http://deliprao.com/feed
   2. http://deliprao.com/comments/feed
   3. http://deliprao.com/archives/243/feed
   4. http://deliprao.com/archives/218
   5. http://deliprao.com/archives/251
   6. http://deliprao.com/wp-json/oembed/1.0/embed?url=http://deliprao.com/archives/243
   7. http://deliprao.com/wp-json/oembed/1.0/embed?url=http://deliprao.com/archives/243&format=xml
   8. http://deliprao.com/archives/243#navigation
   9. http://deliprao.com/
  10. http://deliprao.com/
  11. http://deliprao.com/
  12. http://deliprao.com/d
  13. http://deliprao.com/archives/243#top
  14. http://deliprao.com/archives/author/8272pwpadmin
  15. http://deliprao.com/archives/category/data-science/deep-learning
  16. http://deliprao.com/archives/category/data-science/natural-language-processing
  17. https://conferences.oreilly.com/artificial-intelligence/ai-ca/public/schedule/detail/61399
  18. http://deliprao.com/archives/author/8272pwpadmin
  19. http://deliprao.com/archives/218
  20. http://deliprao.com/archives/251
