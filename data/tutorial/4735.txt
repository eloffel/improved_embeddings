   #[1]github [2]recent commits to neuralamr:master

   [3]skip to content

   (button)

     * why github?
       [4]features    
          + [5]code review
          + [6]project management
          + [7]integrations
          + [8]actions
          + [9]team management
          + [10]social coding
          + [11]documentation
          + [12]code hosting
          + [13]customer stories    
          + [14]security    
     * [15]enterprise
     * explore
          + [16]explore github    

learn & contribute
          + [17]topics
          + [18]collections
          + [19]trending
          + [20]learning lab
          + [21]open source guides

connect with others
          + [22]events
          + [23]community forum
          + [24]github education
     * [25]marketplace
     * pricing
       [26]plans    
          + [27]compare plans
          + [28]contact sales
          + [29]nonprofit    
          + [30]education    

   ____________________
     * in this repository all github    
       jump to    

     * no suggested jump to results

     * in this repository all github    
       jump to    
     * in this repository all github    
       jump to    

   [31]sign in [32]sign up

     * [33]watch [34]3
     * [35]star [36]45
     * [37]fork [38]11

[39]sinantie/[40]neuralamr

   [41]code [42]issues 4 [43]pull requests 0 [44]projects 0 [45]insights
   (button) dismiss

join github today

   github is home to over 31 million developers working together to host
   and review code, manage projects, and build software together.
   [46]sign up
   sequence-to-sequence models for amr parsing and generation
   [47]http://www.ikonstas.net/code
   [48]amr [49]torch [50]parsing [51]generation
     * [52]38 commits
     * [53]1 branch
     * [54]0 releases
     * [55]fetching contributors

    1. [56]java 78.8%
    2. [57]lua 17.4%
    3. [58]shell 2.6%
    4. [59]perl 1.2%

   (button) java lua shell perl
   branch: master (button) new pull request
   [60]find file
   clone or download

clone with https

   use git or checkout with svn using the web url.
   https://github.com/s
   [61]download zip

downloading...

   want to be notified of new releases in sinantie/neuralamr?
   [62]sign in [63]sign up

launching github desktop...

   if nothing happens, [64]download github desktop and try again.

   (button) go back

launching github desktop...

   if nothing happens, [65]download github desktop and try again.

   (button) go back

launching xcode...

   if nothing happens, [66]download xcode and try again.

   (button) go back

launching visual studio...

   if nothing happens, [67]download the github extension for visual studio
   and try again.

   (button) go back
   [68]@sinantie
   [69]sinantie [70]merge pull request [71]#11 [72]from around1991/patch-1
   (button)    
fix amralignment.isempty

   latest commit [73]22998a0 nov 13, 2018
   [74]permalink
   type name latest commit message commit time
   failed to load latest commit information.
   [75]java/amrutils [76]fix amralignment.isempty aug 13, 2018
   [77]lib [78]bug fixes on recomputemetrics.sh script and xml build file
   oct 12, 2017
   [79]resources
   [80]s2sa
   [81]vocab
   [82].gitattributes
   [83].gitignore
   [84]readme.md
   [85]anondeanon_java.sh
   [86]anonparallel_java.sh
   [87]evaluate.lua
   [88]evaluate_server.lua
   [89]gen_parse_server.sh
   [90]generate_amr.sh
   [91]generate_amr_single.sh
   [92]multi-id7.perl [93]adding code for the processing of a whole amr
   corpus, as well as a de    sep 26, 2017
   [94]nerserver.sh
   [95]parse_amr.sh [96]adding parsing functionality. may 31, 2017
   [97]parse_amr_single.sh
   [98]rebuild_amrutils.sh [99]added java src code jul 5, 2017
   [100]recomputemetrics.sh
   [101]settings.properties

readme.md

neural amr

   [102]torch implementation of sequence-to-sequence models for amr
   parsing and generation based on the [103]harvard nlp framework. we
   provide the code for pre-processing, anonymizing, de-anonymizing,
   training and predicting from and to amr. we are also including
   pre-trained models on 20m sentences from gigaword and fine-tuned on the
   amr [104]ldc2015e86: deft phase 2 amr annotation r1 corpus. you can
   find all the details in the following paper:
     * [105]neural amr: sequence-to-sequence models for parsing and
       generation. (ioannis konstas, srinivasan iyer, mark yatskar, yejin
       choi, luke zettlemoyer. acl 2017)

requirements

   the pre-trained models only run on gpus, so you will need to have the
   following installed:
     * latest [106]nvidia driver
     * [107]cuda 8 toolkit
     * [108]cudnn (the nvidia cuda deep neural network library)
     * [109]torch

installation

     * install the following packages for torch using luarocks:

nn nngraph cutorch cunn cudnn

     * install the deepmind version of torch-hdf5 from [110]here.

   (only for training models)
     * install cudnn.torch from [111]here.
     * install the following packages for python 2.7:

pip install numpy h5py

   (only for downloading the pretrained models)
     * download and unzip the models from [112]here
     * export the cudnn library path (you can add it to your .bashrc or
       .profile):

export cudnn_path="path_to_cudnn/lib64/libcudnn.so"

     * or instead of the previous step you can copy the cudnn library
       files into /usr/local/cuda/lib64/ or to the corresponding folders
       in the cuda directory.

usage

amr generation

   you can generate text from amr graphs using our pre-trained model on
   20m sentences from gigaword, in two different ways:
     * by running an interactive tool that reads input from stdin:

./generate_amr_single.sh [stripped|full|anonymized]

     * by running the prediction on a single file, which contains an amr
       graph per line:

./generate_amr.sh input_file [stripped|full|anonymized]

   you can optionally provide an argument that tells the system to accept
   either full amr as described in the [113]annotation guidelines, or a
   stripped version, which removes variables, senses, parentheses from
   leaves, and assumes a simpler markup for named entities, date mentions,
   and numbers. you can also provide the input in anonymized format, i.e.,
   similar to stripped but with named entities, date mentions, and numbers
   anonymized.

   an example using the full format:
(h / hold-04 :arg0 (p2 / person :arg0-of (h2 / have-org-role-91 :arg1 (c2 / coun
try :name (n3 / name :op1 "united" :op2 "states")) :arg2 (o / official)))  :arg1
 (m / meet-03 :arg0 (p / person  :arg1-of (e / expert-01) :arg2-of (g / group-01
))) :time (d2 / date-entity :year 2002 :month 1) :location (c / city  :name (n /
 name :op1 "new" :op2 "york")))

   the same example using the stripped format:
hold :arg0 ( person :arg0-of ( have-org-role :arg1 (country :name "united states
") :arg2 official)) :arg1 (meet :arg0 (person  :arg1-of expert :arg2-of  group))
 :time (date-entity :year 2002 :month 1) :location (city :name "new york" )

   the same example using the anonymized format:
hold :arg0 ( person :arg0-of ( have-org-role :arg1 location_name_0 :arg2 officia
l ) ) :arg1 ( meet :arg0 ( person :arg1-of expert :arg2-of group ) ) :time ( dat
e-entity year_date-entity_0 month_date-entity_0 ) :location location_name_1

   for full details and more examples, see [114]here.

amr parsing

   you can also parse text to the corresponding amr graph, using our
   pre-trained model on 20m sentences from gigaword.

   similarly to amr generation, you can parse text in two ways:
     * by running an interactive tool that reads text from stdin:

./parse_amr_single.sh [text|textanonymized]

     * by running the prediction on a single file, which contains a
       sentence per line:

./parse_amr.sh input_file [text|textanonymized]

   you can optionally provide an argument to the scripts that inform them
   to either accept text and perform ne recognition and anonymization on
   it, or bypass this process entirely (textanonymized).

script options (generate_amr.sh, generate_amr_single.sh, parse_amr.sh,
parse_amr_single.sh)

     * interactive_mode [0,1]: set 0 for generating from a file, or 1 to
       generate from stdin.
     * model [str]: the path to the trained model.
     * input_type [stripped|full] (amr generation only): set full for
       standard amr graph input, or stripped which expects amr graphs with
       no variables, senses, parentheses from leaves, and assumes a
       simpler markup for named entities (for more details and examples,
       see [115]here).
     * src_file [str]: the path to the input file that contains amr
       graphs, one per line.
     * gpuid [int]: the gpu id number.
     * src_dict, targ_dict [str]: path to source and target dictionaries.
       these are usually generated during preprocessing of the corpus.
       ==note==: src_dict and targ_dict paths need to be reversed when
       generating text or parsing to amr.
     * beam [int]: the beam size of the decoder (default is 5).
     * replace_unk [0,1]: replace unknown words with either the input
       token that has the highest attention weight, or the word that maps
       to the input token as provided in srctarg_dict.
     * srctarg_dict [str]: path to source-target dictionary to replace
       unknown tokens. each line should be a source token and its
       corresponding target token, separated by ||| (see
       resources/training-amr-nl-alignments.txt).
     * max_sent_l [str]: maximum sentence length (default is 507, i.e.,
       the longest input amr graph or sentence (depending on the task) in
       number of tokens from the dev set). if any of the sequences in
       src_file are longer than this it will error out.

(de-)anonymization process

   the source code for the whole anonymization/deanonymization pipeline is
   provided under the java/amrutils folder. you can rebuild the code by
   running the script:
./rebuild_amrutils.sh

   this should create the executable lib/amrutils.jar. the
   (de-)anonymization tools are generally controlled using the following
   shell script command (==note== that it is automatically being called
   inside the lua code when parsing/generating, so generally you don't
   need to deal with it when running the scripts described above). the
   first argument denotes the specific (de-)anonymization to perform, the
   second argument specifies whether the input comes either from stdin or
   from a file, where each input is provided one per line:
./anondeanon_java.sh anonymizeamrstripped|anonymizeamrfull|deanonymizeamr|anonym
izetext|deanonymizetext input_isfile[true|false] input

     * ==note==: in order to anonymize text sentences, you need to run the
       stanford ner server first (you can just execute it in the
       background):
./nerserver.sh&

       optionally you can provide a port number as an argument.

   there are four main operations you can perform with the tools, namely
   anonymization of amr graphs, anonymization of text sentences,
   deanonymization of (predicted) sentences, and deanonymization of
   (predicted) amr graphs.:
     * anonymize an amr graph (anonymizeamrstripped, anonymizeamrfull) in
       this case, you provide an input representing a stripped or full amr
       graph, and the script outputs the anonymized graph (in the case of
       full it also strips it down, i.e., removes variable names,
       instance-of relations, most brackets, and simplifies
       nes/dates/number subgraphs of the input), the anonymization
       alignments (useful for deanonymizing the corresponding predicted
       sentence later), and the nodes/edges of the graph in an un-ordered
       json format (useful for visualization tools such as [116]vis.js).
       the three outputs are delimited using the special character #. for
       example:
./anondeanon_java.sh anonymizeamrfull false "(h / hello :arg1 (p / person :name
(n / name :op1 \"john\" :op2 \"doe\")))"

       should give the output:
hello :arg1 person_name_0#person_name_0|||name_john_doe#
"nodes":[{"id":1,"label":"hello"},{"id":2,"label":"person"},{"id":3,"label":"nam
e"},{"id":4,"label":"\"john\""},{"id":5,"label":"\"doe\""}],
"edges":[{"from":1,"to":2,"label":"arg1"},{"from":2,"to":3,"label":"name"},{"fro
m":3,"to":4,"label":"op1"},{"from":3,"to":5,"label":"op2"}]

       anonymization alignments have the format:
amr-anonymized-token|||type_concatenated-amr-tokens

       finally, multiple anonymization alignments for the same sentence,
       are tab-delimeted.
     * anonymize a text sentence (anonymizetext) remember that you need to
       have the ner server running, as explained above. in this example
       you simply provide the sentence as in input. for example:
./anondeanon_java.sh anonymizetext false "my name is john doe"

       should give the output:
my name is person_name_0#person_name_0|||john doe

       note that the anonymization alignments from text are slightly
       different than the ones from amr graphs; the second part is a span
       of the text separated with space.
     * de-anonymize an amr graph (deanonymizeamr) in this case, you
       provide an input representing a stripped amr graph, as well as the
       corresonding anonymization alignments provided from a previous run
       of the script using the ==anonymizetext== option, delimited by #,
       and the script outputs the de-anonymized amr graph, as well as the
       nodes/edges of the graph in an un-ordered json format (useful for
       visualization tools such as [117]vis.js). for example:
./anondeanon_java.sh deanonymizeamr false "hello :arg1 person_name_0#person_name
_0|||john doe"

       should give the output:
(h / hello :arg1 (p / person :name (n / name :op1 "john" :op2 "doe")))#
"nodes":[{"id":1,"label":"hello"},{"id":2,"label":"person"},{"id":3,"label":"nam
e"},{"id":4,"label":"\"john\""},{"id":5,"label":"\"doe\""}],
"edges":[{"from":1,"to":2,"label":"arg1"},{"from":2,"to":3,"label":"name"},{"fro
m":3,"to":4,"label":"op1"},{"from":3,"to":5,"label":"op2"}]

     * de-anonymize a text sentence (deanonymizetext) simply, provide the
       anonymized (predicted) text sentence, along with the anonymization
       alingmnets produced from a previous run of the tool using the
       ==anonymizeamrfull/stripped== option, delimited by #. the script
       should output the de-anonymized text sentence. for example:
./anondeanon_java.sh deanonymizetext false "my name is person_name_0#person_name
_0|||name_john_doe"

       should give the output:
my name is john doe

   finally, when running the tool with the input being in a file (provide
   the path as the 3rd argument of the script, and set the 2nd argument to
   true), you always need to provide the original files containing the amr
   graphs/sentences only. the tool will then automatically create the
   corresponding anonymized file (*.anonymized), as well as the
   anonymization alignments' file (*.alignments) during anonymization.
   similarly, when de-anonymizing it will automatically look for the
   (*.anonymized, and *.alignments) files and create a new resulting file
   with the extension (*.pred).

(de)-anonymizing parallel corpus (e.g., ldc versions)

   if you have a parallel corpus, such as the ldc2015e86 that was used to
   train the models in this work, or [118]little prince, which is included
   in this repository as well for convenience, then you need to follow a
   slightly different procedure.

   the idea is to use alignments between the amr graphs and corresponding
   text, in order to accurately identify the entities that will get
   anonymized. the alignments can be either obtained using the
   [119]unsupervised aligner by nima pourdamghani, or [120]jamr by jeff
   flanigan. if you are using the annotated ldc versions, then they should
   already be automatically aligned using the first aligner (use files
   under the folder alignments/). the code in this repository supports
   either or both types of alignments.
    1. in order to get alignments from jamr on the provided little prince
       corpus do the following:

     * first, concatenate the training, dev and test splits to a single
       file (e.g., little-prince-all.txt) for convenience.
     * change to the path you downloaded and installed jamr, and execute
       the command:

scripts/align.sh path/to/neuralamr/resources/sample-data/little-prince/little-pr
ince-all.txt > /path/to/neuralamr/resources/sample-data/little-prince/jamr-align
ments-all.txt

    2. open settings.properties and make sure amr.down.base and
       amr.jamr.alignments point to the right folders (they point to
       little prince directory by default). you can also enable or disable
       some pre-processing functionalities from here as well, such as
       whether to use named entity clusters (person, organization,
       location, and other instead of the fine-grained amr categories; you
       can alter the clusters through the property amr.concepts.ne) via
       the property amr.down.useneclusters (default is true for preparing
       the corpus for generation, and should be set to false for parsing).
       similarly, you might want to enable output of senses on concepts
       (e.g., say-01, instead of just say) via the property
       amr.down.outputsense (default is false for generation and true for
       parsing). another important property is amr.down.input which
       specifies which portion of the corpus to process (default is
       training,dev,test which are the folder names in the ldc corpora and
       little prince).
    3. preprocess and anonymize the corpus by executing the script:

./anonparallel_java.sh

   this will take care of the proper bracket pre-processing anonymization,
   and splitting of the corpus to training, dev and test source and target
   files that can be directly used for training and evaluating your
   models. there are three options to change there:
     * data_dir which points to a directory that will hold pre-processed
       files with many interesting meta-data, such as vocabularies,
       alignments, anonymization pairs, histograms and so on.
     * out_dir which refers to a directory which contains only the
       essential anonymized training, dev, test source and target files,
       as well as the anonymization alignments in separate files.
     * suffix which is a handy parameter for changing the name of out_dir
       directory.

    4. (generation only) de-anonymize and automatically evaluate the
       output of a model using averaged id7, meteor and multiid7 by
       executing the script:

./recomputemetrics.sh [input_path ref_path]

   the script contains three important options:
     * dataset which refers to the portion of the set to evaluate against;
       default is dev (the other option is test).
     * data_pathname which points to the preprocessed corpus directory
       created from the previous script, which contains the reference
       data. normally, it should be the same as out_dir from above.
     * input_path which is the folder containing the file(s) with
       anonymized predictions. in case there are multiple files, for
       example from different epoch runs, then the code automatically
       processes all of them and reports back the one with the highest
       multiid7 score.

     *    2019 github, inc.
     * [121]terms
     * [122]privacy
     * [123]security
     * [124]status
     * [125]help

     * [126]contact github
     * [127]pricing
     * [128]api
     * [129]training
     * [130]blog
     * [131]about

   (button) you can   t perform that action at this time.

   you signed in with another tab or window. [132]reload to refresh your
   session. you signed out in another tab or window. [133]reload to
   refresh your session.

   (button)

references

   visible links
   1. https://github.com/opensearch.xml
   2. https://github.com/sinantie/neuralamr/commits/master.atom
   3. https://github.com/sinantie/neuralamr#start-of-content
   4. https://github.com/features
   5. https://github.com/features/code-review/
   6. https://github.com/features/project-management/
   7. https://github.com/features/integrations
   8. https://github.com/features/actions
   9. https://github.com/features#team-management
  10. https://github.com/features#social-coding
  11. https://github.com/features#documentation
  12. https://github.com/features#code-hosting
  13. https://github.com/customer-stories
  14. https://github.com/security
  15. https://github.com/enterprise
  16. https://github.com/explore
  17. https://github.com/topics
  18. https://github.com/collections
  19. https://github.com/trending
  20. https://lab.github.com/
  21. https://opensource.guide/
  22. https://github.com/events
  23. https://github.community/
  24. https://education.github.com/
  25. https://github.com/marketplace
  26. https://github.com/pricing
  27. https://github.com/pricing#feature-comparison
  28. https://enterprise.github.com/contact
  29. https://github.com/nonprofit
  30. https://education.github.com/
  31. https://github.com/login?return_to=/sinantie/neuralamr
  32. https://github.com/join
  33. https://github.com/login?return_to=/sinantie/neuralamr
  34. https://github.com/sinantie/neuralamr/watchers
  35. https://github.com/login?return_to=/sinantie/neuralamr
  36. https://github.com/sinantie/neuralamr/stargazers
  37. https://github.com/login?return_to=/sinantie/neuralamr
  38. https://github.com/sinantie/neuralamr/network/members
  39. https://github.com/sinantie
  40. https://github.com/sinantie/neuralamr
  41. https://github.com/sinantie/neuralamr
  42. https://github.com/sinantie/neuralamr/issues
  43. https://github.com/sinantie/neuralamr/pulls
  44. https://github.com/sinantie/neuralamr/projects
  45. https://github.com/sinantie/neuralamr/pulse
  46. https://github.com/join?source=prompt-code
  47. http://www.ikonstas.net/code
  48. https://github.com/topics/amr
  49. https://github.com/topics/torch
  50. https://github.com/topics/parsing
  51. https://github.com/topics/generation
  52. https://github.com/sinantie/neuralamr/commits/master
  53. https://github.com/sinantie/neuralamr/branches
  54. https://github.com/sinantie/neuralamr/releases
  55. https://github.com/sinantie/neuralamr/graphs/contributors
  56. https://github.com/sinantie/neuralamr/search?l=java
  57. https://github.com/sinantie/neuralamr/search?l=lua
  58. https://github.com/sinantie/neuralamr/search?l=shell
  59. https://github.com/sinantie/neuralamr/search?l=perl
  60. https://github.com/sinantie/neuralamr/find/master
  61. https://github.com/sinantie/neuralamr/archive/master.zip
  62. https://github.com/login?return_to=https://github.com/sinantie/neuralamr
  63. https://github.com/join?return_to=/sinantie/neuralamr
  64. https://desktop.github.com/
  65. https://desktop.github.com/
  66. https://developer.apple.com/xcode/
  67. https://visualstudio.github.com/
  68. https://github.com/sinantie
  69. https://github.com/sinantie/neuralamr/commits?author=sinantie
  70. https://github.com/sinantie/neuralamr/commit/22998a0cc16e8ce18f3bbea5d4afd5a1fb83380e
  71. https://github.com/sinantie/neuralamr/pull/11
  72. https://github.com/sinantie/neuralamr/commit/22998a0cc16e8ce18f3bbea5d4afd5a1fb83380e
  73. https://github.com/sinantie/neuralamr/commit/22998a0cc16e8ce18f3bbea5d4afd5a1fb83380e
  74. https://github.com/sinantie/neuralamr/tree/22998a0cc16e8ce18f3bbea5d4afd5a1fb83380e
  75. https://github.com/sinantie/neuralamr/tree/master/java/amrutils
  76. https://github.com/sinantie/neuralamr/commit/9552cc2a4c32a7b7f98250bf6c116d974da580f2
  77. https://github.com/sinantie/neuralamr/tree/master/lib
  78. https://github.com/sinantie/neuralamr/commit/4cb35f9756c4d577da3816fe9b459e75ddae023a
  79. https://github.com/sinantie/neuralamr/tree/master/resources
  80. https://github.com/sinantie/neuralamr/tree/master/s2sa
  81. https://github.com/sinantie/neuralamr/tree/master/vocab
  82. https://github.com/sinantie/neuralamr/blob/master/.gitattributes
  83. https://github.com/sinantie/neuralamr/blob/master/.gitignore
  84. https://github.com/sinantie/neuralamr/blob/master/readme.md
  85. https://github.com/sinantie/neuralamr/blob/master/anondeanon_java.sh
  86. https://github.com/sinantie/neuralamr/blob/master/anonparallel_java.sh
  87. https://github.com/sinantie/neuralamr/blob/master/evaluate.lua
  88. https://github.com/sinantie/neuralamr/blob/master/evaluate_server.lua
  89. https://github.com/sinantie/neuralamr/blob/master/gen_parse_server.sh
  90. https://github.com/sinantie/neuralamr/blob/master/generate_amr.sh
  91. https://github.com/sinantie/neuralamr/blob/master/generate_amr_single.sh
  92. https://github.com/sinantie/neuralamr/blob/master/multi-id7.perl
  93. https://github.com/sinantie/neuralamr/commit/77367b213a8ed4eb346bd3abcce29bd44ab4329b
  94. https://github.com/sinantie/neuralamr/blob/master/nerserver.sh
  95. https://github.com/sinantie/neuralamr/blob/master/parse_amr.sh
  96. https://github.com/sinantie/neuralamr/commit/3c12e197fc120f00666fef1d17b8e51fc99fc8a7
  97. https://github.com/sinantie/neuralamr/blob/master/parse_amr_single.sh
  98. https://github.com/sinantie/neuralamr/blob/master/rebuild_amrutils.sh
  99. https://github.com/sinantie/neuralamr/commit/56056c7379be079719383d376c8dfc964d2e04ea
 100. https://github.com/sinantie/neuralamr/blob/master/recomputemetrics.sh
 101. https://github.com/sinantie/neuralamr/blob/master/settings.properties
 102. http://torch.ch/
 103. https://github.com/sinantie/neuralamr/edit/master/readme.md
 104. https://catalog.ldc.upenn.edu/ldc2015e86
 105. https://arxiv.org/abs/1704.08381
 106. http://www.nvidia.com/download/index.aspx
 107. https://developer.nvidia.com/cuda-toolkit
 108. https://developer.nvidia.com/cudnn
 109. http://torch.ch/docs/getting-started.html
 110. https://github.com/deepmind/torch-hdf5/blob/master/doc/usage.md
 111. https://github.com/soumith/cudnn.torch
 112. https://drive.google.com/file/d/0b0e2ghbz7ccic0p1sjrhlvr2bta/view?usp=sharing
 113. https://github.com/amrisi/amr-guidelines/blob/master/amr.md
 114. https://github.com/sinantie/neuralamr/blob/master
 115. https://github.com/sinantie/neuralamr/blob/master
 116. http://visjs.org/
 117. http://visjs.org/
 118. https://amr.isi.edu/download.html
 119. https://www.isi.edu/~damghani/papers/aligner.zip
 120. https://github.com/jflanigan/jamr
 121. https://github.com/site/terms
 122. https://github.com/site/privacy
 123. https://github.com/security
 124. https://githubstatus.com/
 125. https://help.github.com/
 126. https://github.com/contact
 127. https://github.com/pricing
 128. https://developer.github.com/
 129. https://training.github.com/
 130. https://github.blog/
 131. https://github.com/about
 132. https://github.com/sinantie/neuralamr
 133. https://github.com/sinantie/neuralamr

   hidden links:
 135. https://github.com/
 136. https://github.com/sinantie/neuralamr
 137. https://github.com/sinantie/neuralamr
 138. https://github.com/sinantie/neuralamr
 139. https://help.github.com/articles/which-remote-url-should-i-use
 140. https://github.com/sinantie/neuralamr#neural-amr
 141. https://github.com/sinantie/neuralamr#requirements
 142. https://github.com/sinantie/neuralamr#installation
 143. https://github.com/sinantie/neuralamr#usage
 144. https://github.com/sinantie/neuralamr#amr-generation
 145. https://github.com/sinantie/neuralamr#amr-parsing
 146. https://github.com/sinantie/neuralamr#script-options-generate_amrsh-generate_amr_singlesh-parse_amrsh-parse_amr_singlesh
 147. https://github.com/sinantie/neuralamr#de-anonymization-process
 148. https://github.com/sinantie/neuralamr#de-anonymizing-parallel-corpus-eg-ldc-versions
 149. https://github.com/
