controlling semantics 

m=<d,f> 
d={d1,d2,d3,d4} 
f(mia)=d2 
f(honey-bunny)=d1 
f(vincent)=d4 
f(yolanda)=d3 
f(customer)={d1,d2,d4} 
f(robber)={d3} 
f(love)=   

day 1: exploring models 
johan bos 

computational semantics 

       day 1: exploring models 
       day 2: meaning representations 
       day 3: computing meanings 
       day 4: drawing id136s 
       day 5: meaning banking 

truth verification 

bolt is faster than everyone else. yes 
bolt is in last position. no 

what is 
semantics 

about? 

i v e ?  
i n f o r m a t
  c o n s i s t e n t ?  

model-theoretic semantics 

lexical  
semantics 

compositional 

semantics 

discourse 
semantics 

models 

proofs 

model-theoretic semantics 

model  

extraction 

model  
checking 

model 
building 

lexical  
semantics 

compositional 

semantics 

discourse 
semantics 

models 

proofs 

models 

         model-theoretic semantics 
         alfred tarski 

 

models: simplifications of reality 

models: approximations of reality 

an example model 

an example model 

d6 

d7 

d4 

d3 

d2 

d5 

d8 

d1 

an example model 

d6 

d7 

d4 

d3 

d2 

d5 

d8 

d1 

(non-logical) symbols: 
man/1, woman/1, house/1, dog/1, 
bird/1, car/1, tree/1, happy/1, 
near/2, at/2 

an example model 

d6 

d7 

d4 

d3 

d2 

d5 

d8 

d1 

(non-logical) symbols: 
man/1, woman/1, house/1, dog/1, 
bird/1, car/1, tree/1, happy/1, 
near/2, at/2 

vocabulary 

an example model 

d6 

d7 

d4 

d3 

d2 

d5 

d8 

d1 

(non-logical) symbols: 
man/1, woman/1, house/1, dog/1, 
bird/1, car/1, tree/1, happy/1, 
near/2, at/2 

m=<d,f> 
d={d1,d2,d3,d4,d5,d6,d7,d8} 
f(man)={d1} 
f(woman)={d2} 
f(house)={d3,d4} 
f(dog)={d5} 
f(bird)={d6} 
f(tree)={d7} 
f(car)={d8} 
f(happy)={d1,d2} 
f(near)={(d5,d2),(d2,d5)} 
f(at)={(d6,d3)} 

a first-order model 

       a first-order model <d,f> has two parts: 
       d: a domain (the universe) of objects (entities) 
       f: an interpretation function 

       the interpretation functions maps symbols from our 
vocabulary to members of the domain 
       zero-place symbols (constants) are mapped to a single domain 

member 

       one-place symbols (predicates) are mapped to a set of domain 

members 

       two-place symbols (relations) are mapped to a set of ordered 

pairs of domain members 

an example model 

m=<d,f> 
d={d1,d2,d3,d4} 
f(mia)=d2 
f(honey-bunny)=d1 
f(vincent)=d4 
f(yolanda)=d3 
f(customer)={d1,d2,d4} 
f(robber)={d3} 
f(love)=   

a very small model 

m=<d,f> 
d={d5} 

a very large model 

m=<d,f> 
d={d1,d2,d3,d4,d5,d6,d7,d8,d9,d10 
f(man)={d1,d4,d12} 
f(woman)={d2,d3} 
f(car)={d14,d13}  
f(love)={(d2,d1), (d4,d4)} 
f(hate)={(d5,d1), (d1,d4),(d2,d2)} 
f(chopper)={d10} 
 

finite models 

       in practice we can only work with finite models 
(obviously) 
       but it is easy to find a description that is satisfiable    
but does not have a finite model 

herbrand models 

m=<d,f> 
d={d1,mia,d3,vincent} 
f(customer)={d1,mia,vincent} 
f(robber)={d3} 
f(love)={(d1,mia),(vincent,vincent)} 

first-order and second-order models 

       a first-order domain consists of entities 
       a second-order domain consists of entities and 
properties or relations: 

m=<d,f> 
de={d1,d2,d3} 
de     t={man,woman} 
f(man)={d1,d2} 
f(woman)={d3} 

alternative names for models 

       interpretation 
       structure 

model extraction 

       the task of mapping sensory input (an image, video, or 
audio) to a model   
 
      input: image   
   output: model 

m=<d,f> 
d={d1,d2,d3,d4,d5} 
f(jacket)={d2} 
f(longhair)={d3} 
f(has)={(d1,d3)} 
.... 

source: joo, wang & zhu (2013) 

grim: groningen image models 

grim 
       200 pictures annotated  
with first-order models 
       common vocabulary and  
standard representation  
format (blackburn & bos) 

identify the entities 

model extraction method 
1.   
2.    categorize the entities 
3.    add color terms 
4.   
5.    categorize the relations 
6.    check reflexive relations 

identify the relations 

example 

ambiguity 

28 

lexical ambiguity 
most words in natural languages have 
multiple possible meanings 
 

   pen    (noun) 
 

       the dog is in the pen. 
 
       the ink is in the pen. 

   take    (verb) 
 

       take one pill every morning. 
 
       take the first right past the stoplight. 

how many different senses for table are 
used in these five sentences? 

      
      
      
      
      

   see table 4.    
   it was a sturdy table.    
"i reserved a table at my favorite restaurant.    
   she sets a fine table.    
   he entertained the whole table with his witty remarks.    

what is a    sense    of a word? 

30 

      homonyms  
(same words, disconnected meanings)  
      polysemes  
(same words, connected meanings) 
      metonyms 
(systematically related meanings) 
 

 

31 

homonyms: disconnected meanings 

bank 

       financial institute 

bank 

       sloping land next  
to river 

32 

homonyms: disconnected meanings 

fan 

fan 

       device used to induce an 
airflow for the purpose of 
cooling or refreshing 
oneself 

       a person with a liking and 
enthusiasm for something 

hyponymy 

       a sense is a hyponym of another sense if the first sense 
is more specific than the other    
(i.e., forms a subclass)   

         dog     pet   
     falcon     bird   
     house     building   
company     organisation 

       note: similar to isa links in a knowledge base 

   
isa-hierarchy 

animal                     

                            bird                                 fish                      ... 

                                 

 
y
m
y
n
o
p
y
h

duck                       raptor           trout           shark 

eagle      buzzard            falcon       bateleur  

synonymy 

 
 

 
 

 
 

 

hyperonymy 

       a sense is a hyperonym of another sense if the first 
sense is more general than the other    
(i.e., forms a superclass)   

         dog     boxer   
     falcon     kestrel   
     house     villa    
company     agency 

       note: inverse of hyponomy 

   
36 

id138 
       a detailed database of semantic relationships between english 
words 
       developed by famous cognitive psychologist george miller and 
team at princeton university. 
       comprises about 155k english words. 
       nouns, adjectives, verbs, and adverbs grouped into about 117k 
synonym sets called synsets. 

id138 synsets 
       how are word meanings represented in id138? 

       by synsets (synonym sets) as basic units 
       a concept (word meaning) is represented by  

listing the word forms that can be used to express it 

example of id138 synset 
  two senses of board 
 

       sense 1: a piece of lumber:  

               {board, plank, ...} 
 
 
 

       sense 2: a group of people assembled  

               for some purpose 
               {board, committee, ...} 

id138: global organisation 

division of the lexicon into four main categories: 
 

       nouns 
       verbs 
       adjectives 
       adverbs 

id138: nouns 
noun 
       hyponym 
       hypernym 
       holonym 
       meronym 

41/27 

deep 

 
 

shallow 

all nouns go up to the root synset: {entity} 

selecting senses  
from id138 

d2 

d1 

f(n_car#1)={d1} 

cat 

selecting senses  
from id138 

d2 

d1 

f(n_car#1)={d1} 
f(n_cat#1)={d2} 

selecting senses  
from id138 

d2 

d1 

f(n_car#1)={d1} 
f(n_cat#1)={d2} 
f(a_green#1)={d1} 

first reminder for teacher:  
show some grim models  
(standard as well as grounded models) 

selecting senses  
from id138 

d2 

d1 

f(n_car#1)={d1} 
f(n_cat#1)={d2} 
f(a_green#1)={d1} 

n_whisker#2 

models as prolog terms 

d2 

d1 

f(n_car#1)={d1} 
f(n_cat#1)={d2} 
f(a_green#1)={d1} 

model([d1,d2], 
           [f(1,n_car_1,[d1]), 
            f(1,n_cat_1,[d2]), 
            f(1,a_green_1,[d1]), 
            f(2,supports,[(d1,d2)])]) 

lowercase letters because  
functors need to be atoms! 

spatial relations (in grim) 
       part-of 
       supports 
       touches 
       near 
       occludes 

spatial relations 
       x touches y:  
x and y have a point in common 

       x supports y:  
x and y have a point in common,  
and the position of y depends on  
the position of x 

 

id136 rules: 
x touches y       y touches x 
x supports y          y supports x 
x supports y       x touches y  
 

y 

z 

x 

x supports y 
x supports z 
y touches z 
z touches y 

x touches y 
x touches z 
y touches x 
z touches x 

vague spatial relations 
       x is_near y:  
x and y have no point in common, but their positions are 
relatively near to each other (in the real world?)  

 
 
 
 

id136 rules: 
x is_near y       y is_near x 
x is_near y          x touches y 
x is_near y          x supports y 
 

y 

z 

x 

x supports y 
x supports z 
y is_near z 
z is_near y 

second reminder for teacher:  
show some grim models with spatial 
relations 

events 
       so far we have only modelled static situations! 
       but what about dynamic situations? 

 

modeling emotional states 
m=<d,f>  
d={d1,d2,d3,d4} 
 
f(mia)=d1 
f(monday)=d2 
f(tuesday)=d3 
f(wednesday)=d4 
f(person)={d1} 
f(day)={d2,d3,d4} 
f(precedes)={(d2,d3),(d3,d4),(d2,d4)} 
f(happy)={(d1,d2),(d1,d4)} 

monday 

tuesday 

wednesday 

calvin 

m=<d,f> 
d={d1,d2,d3} 
f(calvin)=d1 
f(toaster)={d2} 
f(bread)={d3} 
f(in)=   

m=<d,f> 
d={d1,d2,d3} 
f(calvin)=d1 
f(toaster)={d2} 
f(bread)={d3} 
f(in)={(d3,d2)} 

calvin 

m=<d,f> 
d={d1,d2,d3} 
f(calvin)=d1 
f(toaster)={d2} 
f(bread)={d3} 
f(in)=   

m=<d,f> 
d={d5,d2,b6} 
f(calvin)=d5 
f(toaster)={d2} 
f(bread)={b6} 
f(in)={(b6,d2)} 

calvin 

m=<d,f> 
d={d1,d2,d3,t1,t2} 
f(before)={(t1,t2)} 
f(calvin)=d1 
f(toaster)={d2} 
f(bread)={d3} 
f(in)={(t2,d3,d2)} 
f(holding)={(t1,d1,d3)} 

calvin 

static  
predicates 

m=<d,f> 
d={d1,d2,d3,t1,t2} 
f(before)={(t1,t2)} 
f(calvin)=d1 
f(toaster)={d2} 
f(bread)={d3} 
f(in)={(t2,d3,d2)} 
f(holding)={(t1,d1,d3)} 

calvin 

m=<d,f> 
d={d1,d2,d3,t1,t2} 
f(before)={(t1,t2)} 
f(calvin)=d1 
f(toaster)={d2} 
f(bread)={d3} 
f(in)={(t2,d3,d2)} 
f(holding)={(t1,d1,d3)} 

dynamic 
predicates 

t1 

t2 

t3 

a person kicking something 
 
on t1: leg of person is near ball, but does not touch it 
on t2: leg of person touches ball 
on t3: ball is not near person 
 

t1 

t2 

t3 

m=<d,f>      d={d1,d2,d3,d4,t1,t2,t3} 
 
f(woman)={d1} 
f(ball)={d2} 
f(leg)={d3,d4} 
f(part-of)={(d3,d1),(d4,d1)} 
f(before)={(t1,t2),(t2,t3),(t1,t3)} 
f(abut)={(t1,t2),(t2,t3)} 
f(near)={(t1,d1,d3),(t1,d1,d3)} 
f(touches)={(t2,d1,d2),(t2,d3,d2),(t2,d2,d1),(t2,d2,d3)} 

the big picture 

natural 
language 
statement 

true 

or 

false 

real world 

the big picture 

natural 
language 
statement 

semantic 
semantic 
parsing 
parsing 

meaning 

true 

or 

false 

model 

checking 

model 

extraction 

model 

the big picture 

wednesday 

semantic 
semantic 
parsing 
parsing 

natural 
language 
statement 

true 

or 

false 

model 

extraction 

today 

meaning 

model 

checking 

model 

