learning from data

lecture 5: practice with new tasks and datasets

malvina nissim and johannes bjerva
m.nissim@rug.nl, j.bjerva@rug.nl

esslli, 26 august 2016

malvina & johannes

lfd     lecture 5

esslli, 26 august 2016

1 / 20

getting the updated code

start as soon as you enter the room! (please)

important as all the new datasets are in

approach 1: use git (updateable, recommended if you have git)

1

in your terminal, type:    git clone
https://github.com/bjerva/esslli-learning-from-data-students.git   

2 followed by    cd esslli-learning-from-data-students   
3 whenever the code is updated, type:    git pull   

approach 2: download a zip (static)

1 download the zip archive from: https://github.com/bjerva/

esslli-learning-from-data-students/archive/master.zip

2 whenever the code is updated, download the archive again.

malvina & johannes

lfd     lecture 5

esslli, 26 august 2016

2 / 20

general points

how to choose the    right    algorithm?

malvina & johannes

lfd     lecture 5

esslli, 26 august 2016

3 / 20

classi   cation vs regression

general points

classi   cation vs regression

create models of prediction from gathered data

classi   cation
the dependent variables are categorical

input x: feature vector
output: discrete class label

regression
the dependent variables are numerical

input x: feature vector
output y: continuous value

malvina & johannes

lfd     lecture 5

esslli, 26 august 2016

5 / 20

general points

supervised vs unsupervised

classi   cation and regression are the most standard ways of doing
supervised learning

malvina & johannes

lfd     lecture 5

esslli, 26 august 2016

6 / 20

supervised and unsupervised learning

general points

supervised vs unsupervised

information about the correct distribution/label of the training examples

in supervised learning it is known
       tting a model to labelled data which has the correct answer
associated to it

in unsupervised learning it is not known
       nding structure in unlabelled data

malvina & johannes

lfd     lecture 5

esslli, 26 august 2016

7 / 20

source: http://www.astroml.org/

source: http://www.astroml.org/

supervised learning

general points

unsupervised learning

supervised learning     classi   cation or regression

in training, instances are associated with their class label

based on features, the system must search for patterns and build a
model

the model must be able to predict the class of previously unseen
instances

malvina & johannes

lfd     lecture 5

esslli, 26 august 2016

10 / 20

unsupervised learning

general points

unsupervised learning

unsupervised learning     id91

partitioning instances into subsets (clusters) that share similar
characteristics

subsets are not prede   ned

a system can be told how many clusters it should form (id116
algorithm)

malvina & johannes

lfd     lecture 5

esslli, 26 august 2016

11 / 20

practice

datasets

(your) datasets

practice

ok cupid (4 tasks)

id51 in russian (4 words)

slovene regional language variants

pragmatic conditionals

malvina & johannes

lfd     lecture 5

esslli, 26 august 2016

14 / 20

learning from  okcupid datafilip klubi  kathe okcupid datasetthe okcupid datasetthe okcupid datasetexample of user feature vector   https://github.com/everett-wetchler/okcupid     http://www.stephenlee   scher.com/posts/scraping-okcupid-will-bot-for-lovethe okcupid dataset four tasks       predict gender       predict orientation       predict diet       predict sign  nb: there is one dataset per task wsd for russian nouns task: to predict word sense given context words: lavka (2), kran (2), kosak (4), ruchka (5) contexts:   - 185 - 200 for each word  - from the internet corpus  - about 10 words before and after the target word variations:   - left context / full context  - with lemmatization / without lemmatization   wsd for russian nouns lavka  kran  2  ruchka  1  2  4  3  5  2  1  1  1  2  3  4  kosak  wsd for russian nouns. datasets     lavka    left_tokenized       full_tokenized     left_tokenized_lemmatized             full_tokenized_lemmatized      label  text-cat  targetword-cat  2                                                                                                                               35                                                                                                                                                                                                                                                               classi   ca(on	
   of	
   slovene	
   regional	
   language	
   variants	
         dataset:	
   slovene	
   tweets	
   manually	
   annotated	
   by	
   user's	
   region	
   of	
   origin	
         4	
   out	
   of	
   7	
   slovene	
   regions	
   (gorenjska,	
   dolenjska,	
     tajerska,	
   primorska)	
         500	
   tweets	
   per	
   region	
   =	
   2000	
   tweets	
         task:	
   build	
   a	
   model	
   to	
   predict	
   the	
   regional	
   language	
   variant	
   of	
   slovene	
   tweets	
   pragmatic conditionals:    if p, q    (chi-h  e elder, c.elder@uea.ac.uk)

practice

categories

res = resultative (   if you take the class you will learn a lot   )
inf = inferential (   if it   s 6.30 the class must be over   )
pch = propositional content hedge (   if i remember rightly...   )
ifh = illocutionary force hedge (   ...if you see what i mean   )
tm = topic marker (   if you think about conditionals, they usually start
with    if   )
dir = directive (   if you could just pay attention...   )

features

   primary meaning    (the main message communicated)

- bare form    if p, q   ; p only; q only; enriched forms p(cid:48), q(cid:48), etc;

completely overridden logical form r

speech act type (a = assertive, d = directive, c = commissive)
conditionality of p and q (y/n)

malvina & johannes

lfd     lecture 5

esslli, 26 august 2016

15 / 20

practical session

practice

running experiments in small groups (2-3)

reporting on experiments (a couple of minutes per group, depending
on how many groups there are)

task
dataset
set up
features
classi   er
results
any re   ections

malvina & johannes

lfd     lecture 5

esslli, 26 august 2016

16 / 20

practice

general commands

general options

--max-train-size n (maximum number of training samples to look at)

--nchars n --nwords n --features x y z

visualisation options

--cm (print confusion matrix + classi   cation report)

--plot (shows cm)

algorithm-speci   c options

k-nearest neighbor (knn): --k n

decision tree (dt): --max-nodes n --min-samples n

example run
python run experiment.py --csv data/trainset-sentiment-extra.csv
--nchars 1 --algorithms id166 --cm
look into data folder for datasets    names (tasks with more datasets have own dir
under data)

malvina & johannes

lfd     lecture 5

esslli, 26 august 2016

17 / 20

datasets names

practice

ok cupid (4 tasks)

okcupid/okcupid data diet.csv
okcupid/okcupid data orientation.csv
okcupid/okcupid data sex.csv
okcupid/okcupid data sign.csv

id51 in russian (4 words)

look into russian wsd/: 16    les (4 di   erent settings per word)

slovene regional language variants

slovene-dialects.csv

pragmatic conditionals

trainif.csv

malvina & johannes

lfd     lecture 5

esslli, 26 august 2016

18 / 20

running on a real test set

practice

with a simple modi   cation you can apply to the run experiment.py
script, you can eventually evaluate your model on completely unseen data:
a 15% of the whole dataset that gets held out while you develop.

change:

#print(   \nresults on the test set:   )
#evaluate classifier(clf, test x, test y, args)

to

print(   \nresults on the test set:   )
evaluate classifier(clf, test x, test y, args)

malvina & johannes

lfd     lecture 5

esslli, 26 august 2016

19 / 20

bye bye

end

malvina: m.nissim@rug.nl
johannes: j.bjerva@rug.nl

repo: github.com/bjerva/esslli-learning-from-data-students

malvina & johannes

lfd     lecture 5

esslli, 26 august 2016

20 / 20

