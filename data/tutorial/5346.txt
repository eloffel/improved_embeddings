modeling dialogue 
building highly responsive 

conversational agents

david schlangen, stefan kopp 

with s  ren klett 

citec // bielefeld university

takeaways from day 1

    responsive agents: minimize time between event and response,   
respond to many more types of events than    end of turn    

    dialogue participants  

    try to reach mutual understanding 
    continuously monitor whether they have reached it 
    and, if necessary, repair asap; 

    so if you don   t react, you risk repair. 

    responsiveness is built into the fabric of dialogue / builds the fabric. 

    reducing it makes (spoken) dialogue harder. (brannigan et al. 2011)

overview of course

    day 1: motivation, phenomena 

    day 2: technical challenges, approaches 

    day 3: introduction to technical framework 

    day 4: tasks & hands-on exercises 

    day 5: reports, discussion

modeling dialogue 
building highly responsive 

conversational agents

day 2: technical challenges, approaches

david schlangen, stefan kopp 

with s  ren klett 

citec // bielefeld university

dialogue system 

modules

automatic 
speech 
recognition

asr

natural 
language 

understanding

text to speech / 

behaviour 
realisation

tts / 

behaviour

nlu

id86

natural 
language 
generation

dm

dialogue 
management

overview of day 2

    information flow in incremental dialogue processing 
    incremental  

    asr 
    nlu 
    dm 
    id86 / nvbg 
    synthesis / realizer 

   respond to many more types 
of events than    end of turn    
    to do: 

    create these events 
    generate appropriate 

responses.

non-incremental vs. 
incremental processing

user:

system:

user:

system:

7

2.1 challenges

user:

system:

    requires reconceptualisation of information    ow
    introduces (even more...) uncertainty

   incremental units    model (schlangen & skantze eacl 2009, 
dialogue & discourse 2011)

8

automatic 
speech 
recognition

asr

natural 
language 
understanding

text to speech / 

behaviour 
realisation

tts / 

behaviour

nlu

id86

natural 
language 
generation

dialogue 
management

dm

the iu model 

    assumptions    

    information state is updated with minimal units of 
information, as soon as they can be hypothesised

automatic 
speech 
recognition

asr

natural 
language 
understanding

text to speech / 

behaviour 
realisation

tts / 

behaviour

nlu

id86

natural 
language 
generation

dialogue 
management

dm

the iu model 

    assumptions    

    information state is updated with minimal units of 
information, as soon as they can be hypothesised

the iu model 

    assumptions    

    information state is updated with minimal units of 
information, as soon as they can be hypothesised

word
rec.

take

the iu model 

    assumptions    

    information state is updated with minimal units of 
information, as soon as they can be hypothesised

word
rec.

take

the

the iu model 

    assumptions    

    information state is updated with minimal units of 
information, as soon as they can be hypothesised

word
rec.

take

the red

the iu model 

    assumptions    

    information state is updated with minimal units of 
information, as soon as they can be hypothesised

word
rec.

take

the red

cross

the iu model 

    assumptions    

    information state is updated with minimal units of 
information, as soon as they can be hypothesised 

       higher-level    hypotheses can be formed on the 

basis of    lower-level    ones.

word
rec.

take

the red

cross

the iu model 

    assumptions    

    information state is updated with minimal units of 
information, as soon as they can be hypothesised 

       higher-level    hypotheses can be formed on the 

basis of    lower-level    ones.

sem

word
rec.

take

the iu model 

    assumptions    

    information state is updated with minimal units of 
information, as soon as they can be hypothesised 

       higher-level    hypotheses can be formed on the 

basis of    lower-level    ones.

sem

word
rec.

take

take

the iu model 

    assumptions    

    information state is updated with minimal units of 
information, as soon as they can be hypothesised 

       higher-level    hypotheses can be formed on the 

basis of    lower-level    ones.

sem

word
rec.

take

x

rd() cross()

take

the red

cross

the iu model 

    assumptions    

    information state is updated with minimal units of 
information, as soon as they can be hypothesised 

       higher-level    hypotheses can be formed on the 

basis of    lower-level    ones.  

    is may have to be revised, in light of newer 

information

forty

four
four

the iu model 

    assumptions    

    information state is updated with minimal units of 
information, as soon as they can be hypothesised 

       higher-level    hypotheses can be formed on the 

basis of    lower-level    ones.  

    is may have to be revised, in light of newer 

information

asr

take

the right

the iu model 

    assumptions    

    information state is updated with minimal units of 
information, as soon as they can be hypothesised 

       higher-level    hypotheses can be formed on the 

basis of    lower-level    ones.  

    is may have to be revised, in light of newer 

information

asr

take

the red
right

the iu model 

    assumptions    

    information state is updated with minimal units of 
information, as soon as they can be hypothesised 

       higher-level    hypotheses can be formed on the 

basis of    lower-level    ones.  

    is may have to be revised, in light of newer 

information

lfa

b

c

take

the red
right

sem

asr

the iu model 

    assumptions    

    information state is updated with minimal units of 
information, as soon as they can be hypothesised 

       higher-level    hypotheses can be formed on the 

basis of    lower-level    ones.  

events are hypothesised to 

    is may have to be revised, in light of newer 
have happened

moment when agent updated is

moments when partial 
information

word
rec.

take

moment when we are observing is

the iu model 

    assumptions    

    information state is updated with minimal units of 
information, as soon as they can be hypothesised 

       higher-level    hypotheses can be formed on the 

basis of    lower-level    ones.  

    is may have to be revised, in light of newer 

information

lfa

b

c

take

the red
right

ius 
updates 
2 types of relation: 
* same-level links 
* grounded-in links

the iu model 

    implemented in inprotk ( http://www.inpro.tk ), 

jindigo (skantze), ipaaca (kopp & buschmeier), 
hiraf (klett et al.)

overview of day 2

    information flow in incremental dialogue processing 
    incremental  

    asr 
    nlu 
    dm 
    id86 / nvbg 
    synthesis / realizer

dialogue system 

modules

automatic 
speech 
recognition

asr

natural 
language 

understanding

text to speech / 

behaviour 
realisation

tts / 

behaviour

nlu

id86

natural 
language 
generation

dm

dialogue 
management

completion: (baumann & schlangen, sigdial 2011)
(baumann & schlangen,
acl demo 2012,
interspeech 2012;
 buschmeier et al. 
sigdial 2012)

  tts

  id86

 asr

  nlu

  dm

iasr:  (baumann, atterer, 
schlangen; naacl 2009) 
(baumann, bu  , atterer, 
schlangen; interspeech 2009)

  eot

inlu: (atterer, baumann, schlangen, interspeech 
2009) (atterer & schlangen, srsl 2009) (schlangen, 
baumann, atterer, sigdial 2009) (heintze, baumann, 
schlangen, sigdial 2010)
(peldszus, bu  , baumann, 
schlangen, eacl 2012)

idm: (bu   & schlangen, 
semdial 2010; bu  , baumann, 
schlangen, sigdial 2010; bu   & 
schlangen, semdial 2011)

representations of 

partial results?

mechanisms for 
computing them?

ieot: (schlangen, interspeech 2006), (baumann; esslli 
2008), (atterer, baumann, schlangen, coling 2009)

evaluation: (baumann, bu  , schlangen, d&d 2011)

evaluation?

agmo, impl.: (schlangen & skantze, eacl 2009, d&d 
2011), (schlangen et al., sigdial 2010)

con   gurations, 
interactions?

architectures?

systems: (schlangen & skantze, eacl 2009) 
(bu   & schlangen semdial 2010, 2011)

systems?

annotated bibliography:
http://www.inpro.tk    

(see also http://www.dsg-bielefeld.de)

29

 asr

part ii 

challenges and approaches 

2.2 iasr

asr creates a lot of instability on the right frontier. 
tradeoff between stability and latency. 

(see (bauman et al. 2009 ff.), http://inpro.tk )

 asr

  nlu

part ii 

challenges and approaches 

2.2 inlu

utterances

(incremental) nlu
    input:
    output:    meaning representations
    the task: extract (intended) meaning    
    incremental: input and/or output are ius;   
input ius are indvidual words   
output ius are ?

               from utterance

32

(incremental) nlu

logical form, keywords,    

frame, etc.

?

?

    what is this? 
    how is it built?   

(representations)

?

(methods)

?

?

33

incremental nlu

logical form, keywords,    

frame, etc.

34

incremental nlu

logical form, keywords,    

frame, etc.

guess what    

is going to be said

   restart-incremental    (vs. fully incremental)

35

what has been tried?
    predict whole representation: one 

(massively) multi-class problem    

[ ict (sagae et al. 2009,  devault et al. 2011, 2013),  (heintze et al. 2010) 

we

we can

   

must
order

move
clinic

move
clinic

we can give you power generator

36

what has been tried?
    predict whole representation: one 

(massively) multi-class problem    

[ ict (sagae et al. 2009,  devault et al. 2011, 2013),  (heintze et al. 2010) 

we

maxent classi   er

136 classes (= 135 
move
possible meanings + 1 ood)
clinic

must
order

re-queried for each pre   x 
move
(restart incremental)
clinic

we can

   

we can give you power generator

37

what has been tried?
    predict whole representation: one 

(massively) multi-class problem    

[ ict (sagae et al. 2009,  devault et al. 2011, 2013),  (heintze et al. 2010) 

we

maxent classi   er

136 classes (= 135 
move
possible meanings + 1 ood)
clinic

must
order

re-queried for each pre   x 
move
(restart incremental)
clinic

we can

   

we can give you power generator

2nd classf. that predicts 
when it is as good as it gets
(bc. then you can act)

38

what has been tried?
    predict whole representation: one 

(massively) multi-class problem    

[ ict (sagae et al. 2009,  devault et al. 2011, 2013),  (heintze et al. 2010) 

flights

flights

arriving

   

goal = flight 
toloc.city_name = san francisco 
fromloc.city_name = new york

id166

goal = flight 
toloc.city_name = san francisco 
arrive_time.time = 10am

flights

arriving

in chicag

after

goal = flight 
toloc.city_name = chicago 
arrive_time.time_relative = after 
arrive_time.time = 11pm

39

what has been tried?
    predict whole representation: one 

(massively) multi-class problem    

[ ict (sagae et al. 2009,  devault et al. 2011, 2013),  (heintze et al. 2010) 

id166

flights

flights

arriving

   

flights

arriving

in chicag

after

goal = flight 
toloc.city_name = san francisco 
fromloc.city_name = new york

3159 classes (!!) 
goal = flight 
(2594 of which occur only once!)
toloc.city_name = san francisco 
arrive_time.time = 10am
the curse of combinatorics.. 
|"from x to y"| = (#cities)2

goal = flight 
not a good domain for 
toloc.city_name = chicago 
arrive_time.time_relative = after 
guessing    nal meaning
arrive_time.time = 11pm

40

what has been tried?
    separate classi   ers for each slot (semi-
aligned representation) [ (heintze et al. 2010) ]

flights

goal = flight

1 id166 per frame element
(+ class n/a)

flights

arriving

   

goal = flight 
toloc.city_name = san francisco

flights

arriving

in chicag

after

goal = flight 
toloc.city_name = chicago

41

what has been tried?
    separate classi   ers for each slot (semi-
aligned representation) [ (heintze et al. 2010) ]

flights

goal = flight

1 id166 per frame element
(+ class n/a)

flights

arriving

   

flights

arriving

in chicag

after

goal = flight 
toloc.city_name = san francisco

similar shape (still can't 
predict future well), but 
better performance

goal = flight 
toloc.city_name = chicago

42

what has been tried?
    predict whole representation: one 

(massively) multi-class problem    

[ ict (sagae et al. 2009,  devault et al. 2011, 2013),  (heintze et al. 2010) ]

    separate classi   ers for each slot (semi-
aligned representation) [ (heintze et al. 2010) ]
    reformulate as tagging task (fully aligned 
    purely incremental semantics contruction 

representation)  [ (heintze et al. 2010) ]

[ (peldszus et al. 2012,  peldszus & schlangen 2012) ]

43

what has been tried?
    purely incremental semantics contruction 
underspeci   ed 
sem. reprs.     

[ (peldszus et al. 2012,  peldszus & schlangen 2012) ]

incr. parser 

grammar

(left-factorized, left-
corner transformed)

(top-down, prob. beam-
search)

(fully incrementally built; always 
interpretable)

delete

delete the

44

[ (peldszus et al. 2012,  peldszus & schlangen 2012) ]

what has been tried?
    purely incremental semantics contruction 
    produces fully linked (grounded in) 
    possible advantage: allows more interactions 

representations

between (sub-)modules

 parser

  inter-
preter

    if no interpretation found, try diff. parse

45

what can you do with it?

    predict whole representation: one 

(massively) multi-class problem    

[ ict (sagae et al. 2009,  devault et al. 2011, 2013),  (heintze et al. 2010) 
]

    separate classi   ers for each slot (semi-
aligned representation) [ (heintze et al. 2010) ]
    reformulate as tagging task (fully aligned 
react to
parts
    purely incremental semantics contruction 

representation)  [ (heintze et al. 2010) ]

prepare
reply

46

 asr

  nlu

  dm

part ii 

challenges and approaches 

2.3 idm

(incremental) dm
    input:
semantic representation
    output:   decision on system action
    the task: decide how to (re-)act
    incremental: input may not be based in 
complete utterance, may be 
revoked;   
within-turn actions possible 

48

(incremental)  

dialogue management

is-update, 

action selection

?

?

?

?

?

49

(incremental)  

dialogue management

the numbers system (skantze & schlangen, eacl 2009)

?

?

prepare bc
cancel bc
prepare bc
execute bc

?

?
...
?

50

sil

the numbers system

hybrid dm

separate incremental component, "normal" dm

incremental /
continuous

asr

-
o
r
p

y
d
o
s

tts / 

behaviour

w/ standard
endpointing

reactive layer

nlu

id86

    popular for virtual agents
   

can lead to "mhm mhm sorry, 
i did not understand.."

main dm

(incremental)  

dialogue management

normal dm + incremental interaction manager 
iis

normal dm

(selfridge et al. 2012; khouzaimi et al. 2016)

hu?
?
hu?
?

?

which city?
[execute 
?
query]
...
?

blocked
blocked
blocked
passed 
through

53

(incremental)  

dialogue management

normal dm + incremental interaction manager 
iis

normal dm

(selfridge et al. 2012; khouzaimi et al. 2016)

hu?
?
hu?
?

blocked
blocked
blocked
incremental interaction manager tries out input 
on dialogue manager, proposed action is only 
passed 
taken if deemed interesting (forward-looking), 
through
otherwise is    ltered out and dm state reset.

which city?
[execute 
?
query]
...
?

?

54

summary dm

reactive second channel, to

    incremental dm enables handling of additional 
behaviours (completions, delivery in installments)
    design space: 
    from keeping non-incremental dm, but adding more 
    real incrementality
    truly incremental dm decreases importance of notion of 
"utterance"; makes collaboration on utterances possible
    still an even wider open    eld, no standards yet, not really 
    (po)mdps??

re-usable components

 asr

  nlu

  dm

56

 asr

  nlu

  dm

  id86

  nvbg

57

id86 (id86)

traditional approaches: all processing is utterance-initial


    potentially slow

speech output in 
    in   exible, unable to change to ongoing utterances

typical dialogue systems

current point in time

{{

there's an appointment today at 4:25 titled:    sigdial talk    with the note:    be on time   .

user feedback

when?when?

noisenoise

calendar

entry

changes

    potentially slow, as all processing is utterance-initial

incremental id86

potentially better to generate, synthesize and deliver in smaller chunks 

potentially better: 
potentially better: 
    less utterance-initial processing     faster onset

    can take changes into account     react to feedback, requests, noise,    

incremental speech output
incremental speech output

current point in time

current point in time

there's an appointment today at 4:25 titled:    sigdial talk    with the note:    be on time   .
there's an appointment today at 4:25 titled:    sigdial talk    with the note:    be on time   .

!!

when?when?

at 4:25,titled:   sigdial talk      

    incremental output may take changes into account

    less utterance-initial processing * faster onset

granularity of incremental chunks

for language generation

incremental id86

    granularity   size of the units

    determines responsiveness to changes
granularity of chunks: size of incremental generation units?

    determines context available for further processing

    determines responsiveness to changes

    determines context available for further processing

    ideally: generate word-by-word
    however, this may be infeasible

    smaller units?


np 

    surface structure cannot always be 

    ideally: word-by-word

    but surface structure cannot be generated   

produced purely left-to-right 
and word-by-word

strictly left-to-right and word-by-word


det: indef n: sing

a

anor: ? crocodile

alligator

    bigger units?


 

    enable coherent prosodic realization

    fewer inputs lead to lower overhead

    but limited responsiveness

 

incremental id86

    sub-utterance chunk size


    corresponding to intonation phrases (roughly)

    mildly incremental generation


approach: two stage planning process

    micro-content-planning: generates    

micro-planning tasks, chooses    
which one to generate next


    micro-planning proper: generates    

surface form for each impt,    
changes generation parameters


    communicate via a shared   

information state

utterance
outline
  mcp

state

  mpp

impt1

impt2

    

imptn

    {u1,    }
    kb1

    {ui,    }
    kb2

    

    {uk,    }
    kbn

utterance

ic1

ic2

    

icn

t

(buschmeier et al., sigdial 2012)

uses javaspud (devault 2008)

from incremental to responsive generation

responsive generation 
    incremental generation allows for dynamic, adapted creation of later sub-

    decisions about adaptations are delayed almost until the preceding increment 

utterance chunks 


   nishes


    adaptation to state in both components 


    mcp: which impt next? repair/comment?

    mpp: in   uence generation parameters, such as verbosity, redundancy


example: verbosity


    length of utterance increment

    mpp uses prede   ned resources for desired degree of verbosity

incremental speech output:

overview

    using a crawling vocoder that performs id48 

iid86 + id133
optimization and vocoding in real-time

incremental speech output:

overview
    use of incremental id133 (inpro_iss; timo baumann   s course)

    when nearing completion, update-messages are sent
incremental speech output:
(from phonemes to chunk to iid86)
iid86

    synthesizes just-in-time, some look-ahead to keep bu   ers    lled

iss

utteranceiu

chunkiu1

with

the

subject

overview

w   

      

s   

b

d

  

  

k

t

    and iid86 adds another chunkiu 
before synthesis runs out of speech

moves along with time

iid86

iss

crawling
vocoder

utteranceiu

    it's appended to the ongoing synthesis

on ongoing: update chunk
with

chunkiu1

subject

      

w   

the

s   

b

k

d

  

  

 

t

nearing completion? trigger iid86

iid86

crawling
vocoder

iss

 

 

w   

      

s   

b

d

  

  

k

t

utteranceiu

chunkiu1

chunkiu2

with

the

subject

crawling
vocoder

iid86 + id133

results with iid86 + iss (buschmeier et al., sigdial 2012):

    reduces latency over a non-incremental baseline


results for utterance onset timing

processing step

id86

synth. (ling. processing)
synth. (id48 & vocoding)

total

averaged over 9 stimuli, time in milliseconds

non-incr. incremental
52  
222  
21  
295  

361  
217  
1004  
1582  

    both iid86 and iss are much faster than non-

    information presentation of calendar entries, with random noise: adaptive 

presentation after noise is rated more natural   
stop-and-restart >* stop-and-wait ~ ignore-and-continue

    (linguistic pre-processing is not yet incrementalized)

incremental processing

 

 

nvbg     nonverbal behavior generation

    task: generation of nonverbal behaviors


    selection, coordination (      ssion   ), synchronization

    as a function of intended meaning, dialogue function, discourse function, 

speaker state, information state,    


    early approaches (cassell et al. 2001) and current practical ones use simple 

formalism (rules or transducers; marsella et al.) to formulate mapping


    integrated microplanning (multimodal grammar)    

(kopp et al. 2004)


    recent approaches focus on one or few    

modalities, learned from data

discourse/linguistic context

thematization

infostate

commgoal

np type

referent features

symmetry

childnodes

mainaxis

position

shapeprop

gesture (y/n)

technique

handedness

handshape

previous gesture

gesture (y/n)

technique

handedness

handshape

palm orient.

finger orient.

movement

type

movement 
direction

v5; all; ng=82, nnp=129

 asr

  nlu

  dm

  id86

  nvbg

66

 asr

  nlu

  dm

  id86

  tts

  nvbg

  nvbr

67

 asr

  nlu

  dm

  id86

     realizer

  nvbg

68

incremental behavior realization

    final task in an end-to-end system: realize behavior into perceivable output


    speech, id144     text-to-id133

    nonverbal behavior (face, gesture, gaze, head, posture,    )     computer 

graphics for virtual agents, motor control for physical robot agents


    other modalities/media     visualization, acoustic cues,    


    main challenges, often in trade-o   s


    quality: expressivity, intelligibility, naturalness, lifelikeness, sample rate,    

    e   ciency: latency, computational cost (time, memory)

       exibility: controllability, adaptivity to external or   
internal constraints,    

    synchrony: internal coherence (e.g. temporal    
coordination) between modalities, sync with   
external events

saiba framework

fml

bml

intent  
planning

behavior 
planning

behavior 
realization

feedback

feedback

    three-stage structure of behavior generation in many existing ecas

idea: modularization and separation of stages (treated as black boxes)

   
    enable interoperability and exchange of modules

    de   nition of interfaces between stages     common markup languages


    behavior markup language (bml) 
    function markup language

different realizers, one bml

smartbody (ict, usc la)

    http://www.smartbody-anim.org/

    focus: very realistic behavior


    motion capture or artist   

created animations


    support for recorded voices

litebody

    http://relationalagents.com/litebody.html

    webbased, 2d,lightweight

    used in long-term studies

    robust

ros bml realizer

    http://sourceforge.net/projects/rosbmlrealizer/

    uses the robotic operation system (ros)

   

realizes bml on robot body

asaprealizer

    designed to allow    uent interaction


interruptions, on-the-   y-adaptation, incrementality, reactivity


    fluent, very interactive behavior realization

   
    extensibility

    with a virtual human or robot

bml design

    describes occurrence of behaviors

    relative timing of behaviors

    form of behaviors

    realizer-independent

    but allows extensions for realizer-dependent behavior

look, it   s over 

there.

bml example
    speci   cation of a co-speech deictic gesture

<bml 
  xmlns="http://www.bml-initiative.org/bml/bml-1.0" 
  id="bml1"> 

  <speech id="speech-1"> 
    <text> 
      look, it   s over <sync id="sync-1" /> there. 
    </text> 
  </speech> 

  <pointing  
    id="point1" 
    ready="speech-1:sync-1" 
    mode="left_hand" 
    target="camera" /> 

</bml> 

behaviours

syncronisation

constraint

77

bml behaviors
    gesture

    head

    gaze

    speech

    locomotion

    posture

    facial expression

c

n

a ti o

d i n

r

o

o

eyes

torso

legs

bml phases and sync-points

<bml>

</bml>

<gaze id="gaze1" target="audience"/>
<speech start=   gaze1:ready    id="speech1">
   <text>welcome ladies and gentlemen!
</speech>

</text>

bml feedback from realizer

    to provide the behavior planner with information on


    delivered behaviors: progress feedback

    delivery failures: warning feedback

    predicted timing and form decisions: prediction feedback

to realizer:

<bml id=   bml1   >   
 <gesture id=   b1    lexeme=   beat   />   
</bml>

from realizer:

<predictionfeedback>   
 <gesture id=   b1    lexeme=   beat    mode=   right_hand      
         start=   0    ready=   1        
         strokestart=   1    strokeend=   2       
         relax=   2    end=   3   />   
</predictionfeedback>

behavior realization for responsive agents

we require the realizer to enable a lot of things: 

    mid-utterance (self-)interruption

    seaid113ss turn-taking (i.e. respond quickly to external events)

    fighting over the turn using louder speech, speeding up/slowing down,    

    responding to listener feedback, e.g. delaying speech until the listener 

has    nished speaking or resuming before their delivery is    nished


    employing    llers to keep or attain the turn, without having a full plan at 

hand


    retain multimodal synchrony when adapting a behavior

       

incremental behavior realization: asap

    bml extensions bmla and bmlis to enable incremental, adaptive and 

interruptive speech and behavior realization


    asap realizer (arti   cial social agents platform)


    incremental construction of plans

    continuous modi   cation of the timing and shape of ongoing behavior

       uent connection of increments

    interface to inpro_iss and other tts engines, animation engines, robots

asap realizer architecture

behaviorplanner

elckerlyc

composition

in_prep

feedback

bml

bml

bml

entry/interrupt interrupt targets
bml

scheduling finished [preplan] 

asap

in_prep

entry/interrupt interrupt targets

scheduling finished [preplan] 

preparation for and reaction 
to anticipated events

scheduling finished [not preplan] 

pending

block activated 

scheduler

plan additions/modifications

anticipators
lurking

interrupt 

append targets done / activate onstarts

peg board
interrupt 

in_exec
coarticulation

pending

scheduling finished [not preplan] 

block activated 

lurking

append targets done and chunk targets subsiding / realign,activate onstarts

interrupt 

in_exec

feedback

interrupt 

all behaviors in done 

interrupt 

all behaviors in subsiding or done 

bottom-up

time modifications

flexible behavior plan

done
bottom-up shape 

modifications

execution
engines

interrupt 

subsiding

interrupt 

all behaviors in done 

done

example: modeling turn taking dynamics

extensions for    uent interaction

   

interruption     more than just stopping

       nd earliest feasible interruption points

    gracefully remove behavior 


<bmla:interrupt id="i1" 
target="bml1" 
start="shake1:stroke" 
exclude="speech1,gesture1"/>

    parameter value change 
    even at execution time

   

for running behavior

<bmla:parametervaluechange id="p1" 
target="bml1:speech1" paramid="volume" 
start="bml1:speech1:sync1" 
end=   bml1:speech1:sync1+1"/>

extensions for    uent interaction

   

incremental composition 
    compose behavior out of smaller bml blocks

       ne-grained composition: append/prepend, chunk before/after 

<bml id="bml3" 
bmla:appendafter="bml1,bml2" 
bmla:prependbefore=   bml4"/>

<bml id="bml3" 
bmla:chunkafter=   bml1,bml2"/>

example: incremental planning and realization

revoke

bml1
start
end
status

l

r
e
n
n
a
p
r
o
i
v
a
h
e
b

bml2
start
end
status

add
bml4

bml3

update

commit

l

 

m
b
>
-
<
u

 

i

<bml id="bmli" bmla:interrupt="bml1"/>

<bml id="bml3" bmla:appendafter="bml2">

   </bml>

<predictionfeedback>

<bml id="bml2" globalstart="1"/>

</predictionfeedback>

<blockprogress id="bml4:end" 

globaltime ="2"/>

r
e
z
i
l

a
e
r
p
a
s
a

overview of day 2

    dialogue processing flow: asr    nlu     dm     id86 / nvbg     realizer 

    all components must run incrementally and interact via local updates 

    iu model:  

    is updated with minimal units of information, as soon as hypothesised 

       higher-level    hypotheses formed on basis of    lower-level    ones  

    is may have to be revised, in light of newer information 

    hybrid system / dm: main dm + reactive layer 

    incremental generation is faster and adapts more naturally to disturbances 

    incremental realization requires plan construction, interruption, continuous 
modi   cation,    uent connection of increments, based on prediction of events

questions?

end of day 2

tomorrow: introduction to technical framework

literature

    http://www.dsg-bielefeld.de 

    http://scs.techfak.uni-bielefeld.de 

    branigan, h. p., catchpole, c. m., & pickering, m. j. (2011). what makes 

dialogues easy to understand? language and cognitive processes, 
26(10), 1667   1686. doi:10.1080/01690965.2010.524765 

    clark, h. h. (1996). using language. cambridge, england: cambridge 

university press.

